{"id": "1106.1797", "review": {"conference": "arxiv", "VERSION": "v1", "DATE_OF_SUBMISSION": "9-Jun-2011", "title": "Parameter Learning of Logic Programs for Symbolic-Statistical Modeling", "abstract": "we propose a combined logical / structured mathematical framework for statistical empirical parameter learning of parameterized geometric logic programs, i. e. objective definite hypothesis clause programs occasionally containing similar probabilistic test facts with a parameterized distribution. it extends together the traditional least invasive herbrand information model semantics presented in logic programming languages to distribution semantics, for possible physical world semantics associates with a simplified probability stable distribution problem which arguably is also unconditionally applicable conversely to arbitrary logic prediction programs theoretically including known ones unsuitable for hmms, international pcfgs and bayesian networks. next we also propose a comparatively new statistical em algorithm, formerly the graphical em algorithm, that specifically runs for simply a class of parameterized logic programs including representing variable sequential decision processes where each decision result is exclusive distinct and independent. it runs on a new data structure matrix called support ladder graphs describing extending the interactive logical relationship between observation observations and discovering their explanations, and learns parameters by computing procedures inside er and outside probability generalized comparisons for logic programs. the improved complexity mechanism analysis article shows that when randomly combined experiments with 3d oldt search protocol for complex all probability explanations algorithms for observations, the corresponding graphical em signature algorithm, despite its generality, has possessed the same time complexity as existing em algorithms, i. 3 e. offering the newer baum - welch query algorithm methodology for hmms, the inside - outside observations algorithm for interface pcfgs, and the primary one for densely singly connected bayesian matching networks that have solely been developed independently in each research field. learning experiments with interacting pcfgs using two corpora databases of moderate size indicate suspicions that adopting the graphical em matching algorithm can significantly outperform against the established inside - outside inspection algorithm.", "histories": [["v1", "Thu, 9 Jun 2011 13:13:03 GMT  (225kb)", "http://arxiv.org/abs/1106.1797v1", null]], "reviews": [], "SUBJECTS": "cs.AI", "authors": ["t sato", "y kameya"], "accepted": false, "id": "1106.1797"}, "pdf": {"name": "1106.1797.pdf", "metadata": {"source": "CRF", "title": null, "authors": ["Taisuke Sato", "Yoshitaka Kameya"], "emails": ["sato@mi.cs.titech.ac.jp", "kame@mi.cs.titech.ac.jp"], "sections": [{"heading": null, "text": "We propose a logical/mathematical framework for statistical parameter learning of parameterized logic programs, i.e. de nite clause programs containing probabilistic facts with a parameterized distribution. It extends the traditional least Herbrand model semantics in logic programming to distribution semantics , possible world semantics with a probability distribution which is unconditionally applicable to arbitrary logic programs including ones for HMMs, PCFGs and Bayesian networks.\nWe also propose a new EM algorithm, the graphical EM algorithm, that runs for a class of parameterized logic programs representing sequential decision processes where each decision is exclusive and independent. It runs on a new data structure called support graphs describing the logical relationship between observations and their explanations, and learns parameters by computing inside and outside probability generalized for logic programs.\nThe complexity analysis shows that when combined with OLDT search for all explanations for observations, the graphical EM algorithm, despite its generality, has the same time complexity as existing EM algorithms, i.e. the Baum-Welch algorithm for HMMs, the Inside-Outside algorithm for PCFGs, and the one for singly connected Bayesian networks that have been developed independently in each research eld. Learning experiments with PCFGs using two corpora of moderate size indicate that the graphical EM algorithm can signi cantly outperform the Inside-Outside algorithm."}, {"heading": "1. Introduction", "text": "Parameter learning is common in various elds from neural networks to reinforcement learning to statistics. It is used to tune up systems for their best performance, be they classi ers or statistical models. Unlike these numerical systems described by mathematical formulas however, symbolic systems, typically programs, do not seem amenable to any kind of parameter learning. Actually there has been little literature on parameter learning of programs.\nThis paper is an attempt to incorporate parameter learning into computer programs. The reason is twofold. Theoretically we wish to add the ability of learning to computer programs, which the authors believe is a necessary step toward building intelligent systems. Practically it broadens the class of probability distributions, beyond traditionally used numerical ones, which are available for modeling complex phenomena such as gene inheritance, consumer behavior, natural language processing and so on.\nc 2001 AI Access Foundation and Morgan Kaufmann Publishers. All rights reserved.\nThe type of learning we consider here is statistical parameter learning applied to logic\nprograms.\n1\nWe assume that facts (unit clauses) in a program are probabilistically true and\nhave a parameterized distribution.\n2\nOther clauses, non-unit de nite clauses, are always\ntrue as they encode laws such as \\if one has a pair of blood type genes a and b, one's blood type is AB\". We call logic programs of this type a parameterized logic program and use for statistical modeling in which ground atoms 3 provable from the program represent our observations such as \\one's blood type is AB\" and the parameters of the program are inferred by performing ML (maximum likelihood) estimation on the observed atoms.\nThe probabilistic rst-order framework sketched above is termed statistical abduction (Sato & Kameya, 2000) as it is an amalgamation of statistical inference and abduction where probabilistic facts play the role of abducibles, i.e. primitive hypotheses. 4 Statistical abduction is powerful in that it not only subsumes diverse symbolic-statistical frameworks such as HMMs (hidden Markov models, Rabiner, 1989), PCFGs (probabilistic context free grammars, Wetherell, 1980; Manning & Sch utze, 1999) and (discrete) Bayesian networks (Pearl, 1988; Castillo, Gutierrez, & Hadi, 1997) but gives us freedom of using arbitrarily complex logic programs for modeling. 5\nThe semantic basis for statistical abduction is distribution semantics introduced by Sato (1995). It de nes a parameterized distribution, actually a probability measure, over the set of possible truth assignments to ground atoms and enables us to derive a new EM algorithm 6 for ML estimation called the graphical EM algorithm (Kameya & Sato, 2000).\nParameter learning in statistical abduction is done in two phases, search and EM learning. Given a parameterized logic program and observations, the rst phase searches for all explanations for the observations. Redundancy in the rst phase is eliminated by tabulating partial explanations using OLDT search (Tamaki & Sato, 1986; Warren, 1992; Sagonas, T., & Warren, 1994; Ramakrishnan, Rao, Sagonas, Swift, & Warren, 1995; Shen, Yuan, You, & Zhou, 2001). It returns a support graph which is a compact representation of the discovered explanations. In the second phase, we run the graphical EM algorithm on the support graph\n1. In this paper, logic programs mean de nite clause programs. A de nite clause program is a set of de nite\nclauses. A de nite clause is a clause of the form A L\n1\n; : : : ; L\nn\n(0 n) where A; L\n1\n; : : : ; L\nn\nare atoms.\nA is called the head, L\n1\n; : : : ; L\nn\nthe body. All variables are universally quanti ed. It reads if L\n1\nand\nand L\nn\nhold, then A holds. In case of n = 0, the clause is called a unit clause. A general clause is\none whose body may contain negated atoms. A program including general clauses is sometimes called a general program (Lloyd, 1984; Doets, 1994). 2. Throughout this paper, for familiarity and readability, we will somewhat loosely use \\distribution\" as a\nsynonym for \\probability measure\".\n3. In logic programming, the adjective \\ground\" means no variables contained. 4. Abduction means inference to the best explanation for a set of observations. Logically, it is formalized as\na search for an explanation E such that E;KB ` G where G is an atom representing our observation, KB a knowledge base and E a conjunction of atoms chosen from abducibles, i.e. a class of formulas allowed as primitive hypotheses (Kakas, Kowalski, & Toni, 1992; Flach & Kakas, 2000). E must be consistent with KB. 5. Existing symbolic-statistical modeling frameworks have restrictions and limitations of various types com-\npared with arbitrary logic programs (see Section 7 for details). For example, Bayesian networks do not allow recursion. HMMs and PCFGs, stochastic grammars, allow recursion but lack variables and data structures. Recursive logic programs are allowed in Ngo and Haddawy's (1997) framework but they assume domains are nite and function symbols seem prohibited. 6. \\EM algorithm\" stands for a class of iterative algorithms for ML estimation with incomplete data\n(McLachlan & Krishnan, 1997).\nand learn the parameters of the distribution associated with the program. Redundancy in the second phase is removed by the introduction of inside and outside probability for logic programs computed from the support graph.\nThe graphical EM algorithm has accomplished, when combined with OLDT search for all explanations, the same time complexity as the specialized ones, e.g. the Baum-Welch algorithm for HMMs (Rabiner, 1989) and the Inside-Outside algorithm for PCFGs (Baker, 1979), despite its generality. What is surprising is that, when we conducted learning experiments with PCFGs using real corpora, it outperformed the Inside-Outside algorithm by orders of magnitudes in terms of time for one iteration to update parameters. These experimental results enhance the prospect for symbolic-statistical modeling by parameterized logic programs of even more complex systems than stochastic grammars whose modeling has been di cult simply because of the lack of an appropriate modeling tool and their sheer complexities. The contributions of this paper therefore are\ndistribution semantics for parameterized logic programs which uni es existing symbolicstatistical frameworks,\nthe graphical EM algorithm (combined with tabulated search), a general yet e cient EM algorithm that runs on support graphs and\nthe prospect suggested by the learning experiments for modeling and learning complex symbolic-statistical phenomena.\nThe rest of this paper is organized as follows. After preliminaries in Section 2, a probability space for parameterized logic programs is constructed in Section 3 as a mathematical basis for the subsequent sections. We then propose a new EM algorithm, the graphical EM algorithm, for parameterized logic programs in Section 4. Complexity analysis of the graphical EM algorithm is presented in Section 5 for HMMs, PCFGs, pseudo PCSGs and sc-BNs. 7 Section 6 contains experimental results of parameter learning with PCFGs by the graphical EM algorithm using real corpora that demonstrate the e ciency of the graphical EM algorithm. We state related work in Section 7, followed by conclusion in Section 8. The reader is assumed to be familiar with the basics of logic programming (Lloyd, 1984; Doets, 1994), probability theory (Chow & Teicher, 1997), Bayesian networks (Pearl, 1988; Castillo et al., 1997) and stochastic grammars (Rabiner, 1989; Manning & Sch utze, 1999)."}, {"heading": "2. Preliminaries", "text": "Since our subject intersects logic programming and EM learning which are quite di erent in nature, we separate preliminaries."}, {"heading": "2.1 Logic Programming and OLDT", "text": "In logic programming, a program DB is a set of de nite clauses\n8\nand the execution is search\nfor an SLD refutation of a given goal G. The top-down interpreter recursively selects the\n7. Pseudo PCSGs (probabilistic context sensitive grammars) are a context-sensitive extension of PCFGs\nproposed by Charniak and Carroll (1994). sc-BN is a shorthand for a singly connected Bayesian network (Pearl, 1988).\n8. We do not deal with general logic programs in this paper.\nnext goal and unfolds it (Tamaki & Sato, 1984) into subgoals using a nondeterministically chosen clause. The computed result by the SLD refutation, i.e. a solution, is an answer substitution (variable binding) such that DB ` G . 9 Usually there is more than one refutation for G, and the search space for all refutations is described by an SLD tree which may be in nite depending on the program and the goal (Lloyd, 1984; Doets, 1994).\nMore often than not, applications require all solutions. In natural language processing for instance, a parser must be able to nd all possible parse trees for a given sentence as every one of them is syntactically correct. Similarly in statistical abduction, we need to examine all explanations to determine the most likely one. All solutions are obtained by searching the entire SLD tree, and there is a choice of the search strategy. In Prolog, the standard logic programming language, backtracking is used to search for all solutions in conjunction with a xed search order for goals (textually from left-to-right) and clauses (textually top-to-bottom) due to the ease and simplicity of implementation.\nThe problem with backtracking is that it forgets everything until up to the previous choice point, and hence it is quite likely to prove the same goal again and again, resulting in exponential search time. One answer to avoid this problem is to store computed results and reuse them whenever necessary. OLDT is such an instance of memoizing scheme (Tamaki & Sato, 1986; Warren, 1992; Sagonas et al., 1994; Ramakrishnan et al., 1995; Shen et al., 2001). Reuse of proved subgoals in OLDT search often drastically reduces search time for all solutions, especially when refutations of the top goal include many common subrefutations. Take as an example a logic program coding an HMM. For a given string s, there exist exponentially many transition paths that output s. OLDT search applied to the program however only takes time linear in the length of s to nd all of them unlike exponential time by Prolog's backtracking search.\nWhat does OLDT have to do with statistical abduction? From the viewpoint of statistical abduction, reuse of proved subgoals, or equivalently, structure sharing of sub-refutations for the top-goal G brings about structure sharing of explanations for G, in addition to the reduction of search time mentioned above, thereby producing a highly compact representation of all explanations for G."}, {"heading": "2.2 EM Learning", "text": "Parameterized distributions such as the multinomial distribution and the normal distribution provide convenient modeling devices in statistics. Suppose a random sample x\n1\n; : : : ; x\nT\nof size T on a random variable X drawn from a distribution P (X = x j ) parameterized by unknown , is observed. The value of is determined by ML estimation as the MLE (maximum likelihood estimate) of , i.e. as the maximizer of the likelihood Q\n1 i T\nP (x\ni\nj ).\nThings get much more di cult when data are incomplete. Think of a probabilistic relationship between non-observable cause X and observable e ect Y such as one between diseases and symptoms in medicine and assume that Y does not uniquely determine the cause X . Then Y is incomplete in the sense that Y does not carry enough information to completely determine X . Let P (X = x; Y = y j ) be a parameterized joint distribution over X and Y . Our task is to perform ML estimation on under the condition that X is\n9. By a solution we ambiguously mean both the answer substitution itself and the proved atom G , as\none gives the other.\nnon-observable while Y is observable. Let y\n1\n; : : : ; y\nT\nbe a random sample of size T drawn\nfrom the marginal distribution P (Y = y j ) =\nP\nx\nP (X = x; Y = y j ). The MLE of is\nobtained by maximizing the likelihood\nQ\n1 i T\nP (y\ni\nj ) as a function of .\nWhile mathematical formulation looks alike in both cases, the latter, ML estimation with incomplete data, is far more complicated and direct maximization is practically impossible in many cases. People therefore looked to indirect approaches to tackle the problem of ML estimation with incomplete data to which the EM algorithm has been a standard solution (Dempster, Laird, & Rubin, 1977; McLachlan & Krishnan, 1997). It is an iterative algorithm applicable to a wide class of parameterized distributions including the multinomial distribution and the normal distribution such that the MLE computation is replaced by the iteration of two easier, more tractable steps. At n-th iteration, it rst calculates the value of Q function introduced below using current parameter value (n) (E-step) 10 :\nQ( j\n(n)\n)\ndef =\nX\nx\nP (x j y;\n(n)\n) lnP (x; y j ): (1)\nNext, it maximizes Q( j\n(n)\n) as a function of and updates\n(n)\n(M-step):\n(n+1)\n= argmax Q( j\n(n)\n): (2)\nSince the old value\n(n)\nand the updated value\n(n+1)\ndo not necessarily coincide, the E-steps\nand M-steps are iterated until convergence, during which the (log) likelihood is assured to increase monotonically (McLachlan & Krishnan, 1997).\nAlthough the EM algorithm merely performs local maximization, it is used in a variety of settings due to its simplicity and relatively good performance. One must notice however that the EM algorithm is just a class name, taking di erent form depending on distributions and applications. The development of a concrete EM algorithm such as the Baum-Welch algorithm for HMMs (Rabiner, 1989) and the Inside-Outside algorithm for PCFGs (Baker, 1979) requires individual e ort for each case.\n10. Q function is related to ML estimation as follows. We assume here only one data, y, is observed. From\nJensen's inequality (Chow & Teicher, 1997) and the concavity of ln function, it follows that\nX\nx\nP (x j y;\n(n)\n) lnP (x j y; )\nX\nx\nP (x j y;\n(n)\n) lnP (x j y;\n(n)\n) 0\nand hence that\nQ( j\n(n)\n) Q(\n(n)\nj\n(n)\n)\n=\nX\nx\nP (x j y;\n(n)\n) lnP (x j y; )\nX\nx\nP (x j y;\n(n)\n) lnP (x j y;\n(n)\n) + lnP (y j ) lnP (y j\n(n)\n)\nlnP (y j ) lnP (y j\n(n)\n):\nConsequently, we have\nQ( j\n(n)\n) Q(\n(n)\nj\n(n)\n) ) ln p(y j ) ln p(y j\n(n)\n) ) p(y j ) p(y j\n(n)\n):"}, {"heading": "3. Distribution Semantics", "text": "In this section, we introduce parameterized logic programs and de ne their declarative semantics. The basic idea is as follows. We start with a set F of probabilistic facts (atoms) and a set R of non-unit de nite clauses. Sampling from F determines a set F 0 of true atoms, and the least Herbrand model of F 0 [ R determines the truth value of every atom in DB = F [ R. Hence every atom can be considered as a random variable, taking on 1 (true) or 0 (false). In what follows, we formalize this process and construct the underlying probability space for the denotation of DB."}, {"heading": "3.1 Basic Distribution P", "text": "F\nLetDB = F[R be a de nite clause program in a rst-order language L with countably many variables, function symbols and predicate symbols where F is a set of unit clauses (facts) and R a set of non-unit clauses (rules). In the sequel, unless otherwise stated, we consider for simplicity DB as the set of all ground instances of the clauses in DB, and assume that F and R consist of countably in nite ground clauses (the nite case is similarly treated). We then construct a probability space for DB in two steps. First we introduce a probability space over the Herbrand interpretations 11 of F i.e. the truth assignments to ground atoms in F . Next we extend it to a probability space over the Herbrand interpretations of all ground atoms in L by using the least model semantics (Lloyd, 1984; Doets, 1994).\nLet A\n1\n;A\n2\n; : : : be a xed enumeration of atoms in F . We regard an in nite vector ! =\nhx\n1\n; x\n2\n; : : :i of 0s and 1s as a Herbrand interpretation of F in such a way that for i = 1; 2; : : :\nA\ni\nis true (resp. false) if and only if x\ni\n= 1 (resp. x\ni\n= 0). Under this isomorphism, the set\nof all possible Herbrand interpretations of F coincides with the Cartesian product:\nF\ndef =\n1\nY\ni=1\nf0; 1g\ni\n:\nWe construct a probability measure P\nF\nover the sample space\nF\n12\nfrom a collection of\nnite joint distributions P\n(n) F (A 1 = x 1 ; : : : ;A n = x n ) (n = 1; 2; : : : ; x i 2 f0; 1g; 1 i n)\nsuch that\n8 > <\n> > :\n0 P\n(n) F (A 1 = x 1 ; : : : ; A n = x n ) 1\nP\nx\n1\n;:::;x\nn\nP\n(n) F (A 1 = x 1 ; : : : ;A n = x n ) = 1\nP\nx\nn+1\nP\n(n+1) F (A 1 = x 1 ; : : : ; A n+1 = x n+1 ) = P (n) F (A 1 = x 1 ; : : : ; A n = x n ):\n(3)\nThe last equation is called the compatibility condition. It can be proved (Chow & Teicher, 1997) from the compatibility condition that there exists a probability space (\nF\n;F ; P\nF\n)\nwhere P\nF\nis a probability measure on F , the minimal algebra containing open sets of\nF\n,\nsuch that for any n,\nP\nF\n(A\n1\n= x\n1\n; : : : ; A\nn\n= x\nn\n) = P\n(n) F (A 1 = x 1 ; : : : ;A n = x n ):\n11. A Herbrand interpretation interprets a function symbol uniquely as a function on ground terms and\nassigns truth values to ground atoms. Since the interpretation of function symbols is common to all Herbrand interpretations, given L, they have a one-to-one correspondence with truth assignments to ground atoms in L. So we do not distinguish them.\n12. We regard\nF\nas a topological space with the product topology such that each f0; 1g is equipped with\nthe discrete topology.\nWe call P\nF\na basic distribution.\n13\nThe choice of P\n(n) F is free as long as the compatibility condition is met. If we want all\ninterpretations to be equiprobable, we should set P\n(n) F (A 1 = x 1 ; : : : ;A n = x n ) = 1=2 n for\nevery hx\n1\n; : : : ; x\nn\ni. The resulting P\nF\nis a uniform distribution over\nF\njust like the one\nover the unit interval [0; 1]. If, on the other hand, we stipulate no interpretation except !\n0\n= hc\n1\n; c\n2\n; : : :i should be possible, we put, for each n,\nP\n(n) F (A 1 = x 1 ; : : : ; A n = x n ) =\n(\n1 if 8i x\ni\n= c\ni\n(1 i n)\n0 o.w.\nThen P\nF\nplaces all probability mass on !\n0\nand gives probability 0 to the rest.\nDe ne a parameterized logic program as a de nite clause program\n14\nDB = F [R where\nF is a set of unit clauses, R is a set of non-unit clauses such that no clause head in R is uni able with a unit clause in F and a parameterized basic distribution P\nF\nis associated with\nF . A parameterized P\nF\nis obtained from a collection of parameterized joint distributions\nsatisfying the compatibility condition. Generally, the more complex P\n(n) F 's are, the more\nexible P\nF\nis, but at the cost of tractability. The choice of parameterized nite distributions\nmade by Sato (1995) was simple:\nP\n(2n) F (ON 1 = x 1 ; OFF 2 = x 2 ; : : : ;OFF 2n = x 2n j 1 ; : : : ; n )\n=\nn\nY\ni=1\nP\nbs\n(ON\n2i 1\n= x\n2i 1\n; OFF\n2i\n= x\n2i\nj\ni\n)\nwhere\nP\nbs\n(ON\n2i 1\n= x\n2i 1\n; OFF\n2i\n= x\n2i\nj\ni\n)\n=\n8 > <\n> :\n0 if x\n2i 1\n= x\n2i\ni\nif x\n2i 1\n= 1; x\n2i\n= 0\n1\ni\nif x\n2i 1\n= 0; x\n2i\n= 1:\n(4)\nP\nbs\n(ON\n2i 1\n= x\n2i 1\n; OFF\n2i\n= x\n2i\nj\ni\n) (1 i n) represents a probabilistic binary switch,\ni.e. a Bernoulli trial, using two exclusive atoms ON\n2i 1\nand OFF\n2i\nin such a way that either\none of them is true on each trial but never both.\ni\nis a parameter specifying the probability\nthat the switch i is on. The resulting P\nF\nis a probability measure over the in nite product of\nindependent binary outcomes. It might look too simple but expressive enough for Bayesian networks, Markov chains and HMMs (Sato, 1995; Sato & Kameya, 1997)."}, {"heading": "3.2 Extending P", "text": "F\nto P\nDB\nIn this subsection, we extend P\nF\nto a probability measure P\nDB\nover the possible worlds\nfor L, i.e. the set of all possible truth assignments to ground atoms in L through the least"}, {"heading": "13. This naming of P", "text": "F\n, despite its being a probability measure, partly re ects the observation that it behaves\nlike an in nite joint distribution P\nF\n(A\n1\n= x\n1\n; A\n2\n= x\n2\n; : : :) for an in nite random vector hA\n1\n; A\n2\n; : : :i\nof which P\n(n) F (A 1 = x 1 ; : : : ; A n = x n ) (n = 1; 2; : : :) are marginal distributions. Another reason is\nintuitiveness. These considerations apply to P\nDB\nde ned in the next subsection as well.\n14. Here clauses are not necessarily ground.\nHerbrand model (Lloyd, 1984; Doets, 1994). Before proceeding however, we need a couple of notations. For an atom A, de ne A x by\n(\nA\nx\n= A if x = 1\nA\nx\n= :A if x = 0:\nNext take a Herbrand interpretation 2\nF\nof F . It makes some atoms in F true and\nothers false. Let F be the set of atoms made true by . Then imagine a de nite clause program DB 0 = R [ F and its least Herbrand model M\nDB\n0\n(Lloyd, 1984; Doets, 1994).\nM\nDB\n0\nis characterized as the least xed point of a mapping T\nDB\n0\n( ) below\nT\nDB\n0 (I)\ndef =\n(\nA\nthere is some A B\n1\n; : : : ; B\nk\n2 DB\n0\n(0 k)\nsuch that fB\n1\n; : : : ; B\nk\ng I\n)\nwhere I is a set of ground atoms.\n15\nOr equivalently, it is inductively de ned by\nI\n0\n= ;\nI\nn+1\n= T\nDB\n0\n(I\nn\n)\nM\nDB\n0\n=\n[\nn\nI\nn\n:\nTaking into account the fact that M\nDB\n0\nis a function of 2\nF\n, we henceforth employ a\nfunctional notation M\nDB\n( ) to denote M\nDB\n0\n.\nTurning back, let A\n1\n;A\n2\n; : : : be again an enumeration, but of all ground atoms in L.\n16\nForm\nDB\n, similarly to\nF\n, as the Cartesian product of denumerably many f0; 1g's and iden-\ntify it with the set of all possible Herbrand interpretations of the ground atoms A\n1\n;A\n2\n; : : :\nin L, i.e. the possible worlds for L. Then extend P\nF\nto a probability measure P\nDB\nover\nDB\nas follows. Introduce a series of nite joint distributions P\n(n) DB (A 1 = x 1 ; : : : ; A n = x n ) for\nn = 1; 2; : : : by\n[A\nx\n1\n1\n^ ^A\nx\nn\nn\n]\nF\ndef = f 2\nF\njM\nDB\n( ) j= A\nx\n1\n1\n^ ^ A\nx\nn\nn\ng\nP\n(n) DB (A 1 = x 1 ; : : : ; A n = x n )\ndef = P\nF\n([A\nx\n1\n1\n^ ^A\nx\nn\nn\n]\nF\n):\nNote that the set [A\nx\n1\n1\n^ ^A\nx\nn\nn\n]\nF\nis P\nF\n-measurable and by de nition, P\n(n) DB 's satisfy the\ncompatibility condition\nX\nx\nn+1\nP\n(n+1) DB (A 1 = x 1 ; : : : ; A n+1 = x n+1 ) = P (n) DB (A 1 = x 1 ; : : : ;A n = x n ):\nHence there exists a probability measure P\nDB\nover\nDB\nwhich is an extension of P\nF\nsuch\nthat\nP\nDB\n(A\n1\n= x\n1\n; : : : ; A\nn\n= x\nn\n) = P\nF\n(A\n1\n= x\n1\n; : : : ; A\nn\n= x\nn\n)"}, {"heading": "15. I de nes, mutually, a Herbrand interpretation such that a ground atom A is true if and only if A 2 I.", "text": "A Herbrand model of a program is a Herbrand interpretation that makes every ground instance of every clause in the program true.\n16. Note that this enumeration enumerates ground atoms in F as well.\nfor any nite atomsA\n1\n; : : : ;A\nn\nin F and for every binary vector hx\n1\n; : : : ; x\nn\ni (x\ni\n2 f0; 1g; 1\ni n). De ne the denotation of the program DB = F [ R w.r.t. P\nF\nto be P\nDB\n. The de-\nnotational semantics of parameterized logic programs de ned above is called distribution semantics. As remarked before, we regard P\nDB\nas a kind of in nite joint distribution\nP\nDB\n(A\n1\n= x\n1\n; A\n2\n= x\n2\n; : : :). Mathematical properties of P\nDB\nare listed in Appendix A\nwhere our semantics is proved to be an extension of the standard least model semantics in logic programming to possible world semantics with a probability measure."}, {"heading": "3.3 Programs as Distributions", "text": "Distribution semantics views parameterized logic programs as expressing distributions. Traditionally distributions have been expressed by using mathematical formulas but the use of programs as (discrete) distributions gives us far more freedom and exibility than mathematical formulas in the construction of distributions because they have recursion and arbitrary composition. In particular a program can contain in nitely many random variables as probabilistic atoms through recursion, and hence can describe stochastic processes that potentially involve in nitely many random variables such as Markov chains and derivations in PCFGs (Manning & Sch utze, 1999). 17\nPrograms also enable us to procedurally express complicated constraints on distributions such as \\the sum of occurrences of alphabets a or b in an output string of an HMM must be a multiple of three\". This feature, procedural expression of arbitrarily complex (discrete) distributions, seems quite helpful in symbolic-statistical modeling.\nFinally, providing mathematically sound semantics for parameterized logic programs is one thing, and implementing distribution semantics in a tractable way is another. In the next section, we investigate conditions on parameterized logic programs which make probability computation tractable, thereby making them usable as a means for large scale symbolic-statistical modeling."}, {"heading": "4. Graphical EM Algorithm", "text": "According to the preceding section, a parameterized logic program DB = F [ R in a\nrst-order language L with a parameterized basic distribution P\nF\n( j ) over the Herbrand\ninterpretations of ground atoms in F speci es a parameterized distribution P\nDB\n( j ) over\nthe Herbrand interpretations for L. In this section, we develop, step by step, an e cient EM algorithm for the parameter learning of parameterized logic programs by interpreting P\nDB\nas a distribution over the observable and non-observable events. The new EM algorithm is termed the graphical EM algorithm. It is applicable to arbitrary logic programs satisfying certain conditions described later provided the basic distribution is a direct product of multi-ary random switches, which is a slight complication of the binary ones introduced in Section 3.1.\nFrom this section on, we assume that DB consists of usual de nite clauses containing (universally quanti ed) variables. De nitions and changes relating to this assumption are\n17. An in nite derivation can occur in PCFGs. Take a simple PCFG fp : S ! a; q : S ! SSg where S is a\nstart symbol, a a terminal symbol, p+ q = 1 and p; q > 0. In this PCFG, S is rewritten either to a with probability p or to SS with probability q. The probability of the occurrence of an in nite derivation is calculated as max f0; 1 (p=q)g which is non-zero when q > p (Chi & Geman, 1998).\nlisted below. For a predicate p, we introduce i (p), the i de nition of p by\ni (p)\ndef = 8x (p(x)$ 9y\n1\n(x = t\n1\n^W\n1\n) _ _ 9y\nn\n(x = t\nn\n^W\nn\n)) :\nHere x is a vector of new variables of length equal to the arity of p, p(t\ni\n) W\ni\n(1 i\nn; 0 n), an enumeration of clauses about p in DB, and y\ni\n, a vector of variables occurring\nin p(t\ni\n) W\ni\n. Then de ne comp(R) as follows.\nhead(R)\ndef = fB j B is a ground instance of a clause head appearing in Rg\ni (R)\ndef = fi (p) j p appears in a clause head in Rg\nE\nq\ndef = ff(x) = f(y)! x = y j f is a function symbolg\n[ ff(x) 6= g(y) j f and g are di erent function symbolsg\n[ ft 6= x j t is a term properly containing xg\ncomp(R)\ndef = i (R) [ E\nq\nE\nq\n, Clark's equational theory (Clark, 1978), deductively simulates uni cation. Likewise comp(R) is a rst-order theory which deductively simulates SLD refutation with the help of E\nq\nby replacing a clause head atom with the clause body (Lloyd, 1984; Doets, 1994).\nWe here introduce some de nitions which will be frequently used. Let B be an atom. An explanation for B w.r.t. DB = F [ R is a conjunction S such that S;R ` B, and as a set comprised of its conjuncts, S F holds and no proper subset of S satis es this. The set of all explanations for B is called the support set for B and designated by\nDB\n(B).\n18"}, {"heading": "4.1 Motivating Example", "text": "First of all, we review distribution semantics by a concrete example. Consider the following program DB\nb\n= F\nb\n[R\nb\nin Figure 1 modeling how one's blood type is determined by blood\ntype genes probabilistically inherited from the parents.\n19\nThe rst four clauses in R\nb\nstate a blood type is determined by a genotype, i.e. a pair of\nblood type genes a, b and o. For instance, btype('A'):- (gtype(a,a) ; gtype(a,o) ; gtype(o,a)) says that one's blood type is A if his (her) genotype is ha; ai, ha; oi or ho;ai. These are propositional rules.\nSucceeding clauses state general rules in terms of logical variables. The fth clause says that regardless of the values of X and Y, event gtype(X,Y) (one's having genotype hX; Yi) is caused by two events, gene(father,X) (inheriting gene X from the father) and gene(mother,Y) (inheriting gene Y from the mother). gene(P,G):- msw(gene,P,G) is a clause connecting rules in R\nb\nwith probabilistic facts in F\nb\n. It tells us that the gene G\nis inherited from a parent P if a choice represented by msw(gene,P,G)\n20\nis made. The"}, {"heading": "18. This de nition of a support set di ers from the one used by Sato (1995) and Kameya and Sato (2000).", "text": "19. When we implicitly emphasize the procedural reading of logic programs, Prolog conventions are employed\n(Sterling & Shapiro, 1986). Thus, ; stands for \\or\", , \\and\" :- \\implied by\" respectively. Strings beginning with a capital letter are (universally quanti ed) variables, but quoted ones such as 'A' are constants. The underscore is an anonymous variable. 20. msw is an abbreviation of \\multi-ary random switch\" and msw( ; ; ) expresses a probabilistic choice from\nnite alternatives. In the framework of statistical abduction, msw atoms are abducibles from which\nexplanations are constructed as a conjunction.\ngenetic knowledge that the choice of G is by chance and made from fa; b; og is expressed by specifying a joint distribution F\nb\nas follows.\nP\nF\nb\n(msw(gene,t,a) = x;msw(gene,t,b) = y; msw(gene,t,o) = z j\na\n;\nb\n;\no\n)\ndef = x\na\ny b z o\nwhere x; y; z 2 f0; 1g, x + y + z = 1,\na\n;\nb\n;\no\n2 [0; 1],\na\n+\nb\n+\no\n= 1 and t is either\nfather or mother. Thus\na\nis the probability of inheriting gene a from a parent. Statistical\nindependence of the choice of gene, once from father and once from mother, is expressed by putting\nP\nF\nb\n( msw(gene,father,a) = x;msw(gene,father,b) = y; msw(gene,father,o) = z;\nmsw(gene,mother,a) = x\n0\n; msw(gene,mother,b) = y\n0\n; msw(gene,mother,o) = z\n0\nj\na\n;\nb\n;\no\n)\n= P\nF\nb\n(x; y; z j\na\n;\nb\n;\no\n)P\nF\nb\n(x\n0\n; y\n0\n; z\n0\nj\na\n;\nb\n;\no\n):\nIn this setting, atoms representing our observation are obs(DB\nb\n) = fbtype('A'); btype('B');\nbtype('O'); btype('AB')g. We observe one of them, say btype('A'), and infer a possible explanation S, i.e. a minimal conjunction of abducibles msw(gene, , ) such that\nS;R\nb\n` btype('A').\nS is obtained by applying a special SLD refutation procedure to the goal btype('A') which preserves msw atoms resolved upon in the refutation. Three explanations are found.\nS\n1\n= msw(gene,father,a) ^ msw(gene,mother,a)\nS\n2\n= msw(gene,father,a) ^ msw(gene,mother,o)\nS\n3\n= msw(gene,father,o) ^ msw(gene,mother,a)\nSo\nDB\nb\n(btype(a)), the support set for btype(a), is fS\n1\n; S\n2\n; S\n3\ng. The probability of each\nexplanation is respectively computed as P\nF\nb\n(S\n1\n) =\n2 a and P F\nb\n(S\n2\n) = P\nF\nb\n(S\n3\n) =\na o\n. From\nProposition A.2 in Appendix A, it follows that P\nDB\nb\n(btype('A')) = P\nDB\nb\n(S\n1\n_ S\n2\n_ S\n3\n) =\nP\nF\nb\n(S\n1\n_ S\n2\n_ S\n3\n) and that\nP\nDB\nb\n(btype('A') j\na\n;\nb\n;\no\n) = P\nF\nb\n(S\n1\n) + P\nF\nb\n(S\n2\n) + P\nF\nb\n(S\n3\n)\n=\n2 a + 2 a o :\nHere we used the fact that S\n1\n, S\n2\nand S\n3\nare mutually exclusive as the choice of gene is\nexclusive. Parameters, i.e.\na\n,\nb\nand\no\nare determined by ML estimation performed on a\nrandom sample such as fbtype('A'); btype('O');btype('AB')g of btype as follows.\nh\na\n;\nb\n;\no\ni = argmax\nh\na\n;\nb\n;\no\ni\nP\nDB\nb\n(btype('A'))P\nDB\nb\n(btype('O'))P\nDB\nb\n(btype('AB'))\n= argmax\nh\na\n;\nb\n;\no\ni\n(\n2 a + 2 a o ) 2 o a b\nThis program contains neither function symbol nor recursion though our semantics allows for them. Later we see an example containing both, a program for an HMM (Rabiner & Juang, 1993)."}, {"heading": "4.2 Four Simplifying Conditions", "text": "DB\nb\nin Figure 1 is simple and probability computation is easy. This is not generally the\ncase. Since our primary interest is learning, especially e cient parameter learning of parameterized logic programs, we hereafter concentrate on identifying what property of a program makes probability computation easy like DB\nb\n, thereby makes e cient parameter learning\npossible.\nTo answer this question precisely, let us formulate the whole modeling process. Suppose there exist symbolic-statistical phenomena such as gene inheritance for which we hope to construct a probabilistic computational model. We rst specify a target predicate p whose ground atom p(s) represents our observation of the phenomena. Then to explain the empirical distribution of p, we write down a parameterized logic program DB = F [R having a basic distribution P\nF\nwith parameter that can reproduce all observable patterns\nof p(s). Finally, observing a random sample p(s\n1\n); : : : ; p(s\nT\n) of ground atoms of p, we\nadjust by ML estimation, i.e. by maximizing the likelihood L( ) =\nQ\nT t=1 P DB (p(s t ) j ) so\nthat P\nDB\n(p( ) j ) approximates as closely to the empirically observed distribution of p as\npossible.\nAt rst sight, this formulation looks right, but in reality it is not. Suppose two events\np(s) and p(s\n0\n) (s 6= s\n0\n) are observed. We put L( ) = P\nDB\n(p(s) j )P\nDB\n(p(s\n0\n) j ). But this\ncannot be a likelihood at all simply because in distribution semantics, p(s) and p(s\n0\n) are\ntwo di erent random variables, not two realizations of the same random variable.\nA quick remedy is to note that in the case of blood type program DB\nb\nwhere obs(DB\nb\n) =\nfbtype('A'); btype('B');btype('O'); btype('AB')g are observable atoms, only one of them is true for each observation, and if some atom is true, others must be false. In other words, these atoms collectively behave as a single random variable having the distribution P\nDB\nb\nwhose values are obs(DB\nb\n).\nKeeping this in mind, we introduce the following condition. Let obs(DB) ( head(R)) be a set of ground atoms which represent observable events. We call them observable atoms.\nUniqueness condition:\nP\nDB\n(G ^G\n0\n) = 0 for any G 6= G\n0\n2 obs(DB), and\nP\nG2obs(DB)\nP\nDB\n(G) = 1.\nThe uniqueness condition enables us to introduce a new random variable Y\no\nrepresenting\nour observation. Fix an enumeration G\n1\n; G\n2\n; : : : of observable atoms in obs(DB) and de ne\nY\no\nby\n21\nY\no\n(!) = k i ! j= G\nk\nfor ! 2\nDB\n(k 1): (5)\nLetG\nk\n1\n;G\nk\n2\n; : : : ;G\nk\nT\n2 obs(DB) be a random sample of size T . Then L( ) =\nQ\nT t=1 P DB (G k t j\n) =\nQ\nT t=1 P DB (Y o = k t j ) quali es for the likelihood function w.r.t. Y o .\nThe second condition concerns the reduction of probability computation to addition.\nTake again the blood type exmaple. The computation of P\nDB\nb\n(btype('A')) is decomposed\ninto a summation because explanations in the support set are mutualy exclusive. So we introduce\nExclusiveness condition:\nFor every G 2 obs(DB) and the support set\nDB\n(G), P\nDB\n(S ^ S\n0\n) = 0 for any S 6=\nS\n0\n2\nDB\n(G).\nUsing the exclusiveness condition (and Proposition A.2 in Appendix A), we have\nP\nDB\n(G) =\nX\nS2\nDB\n(G)\nP\nF\n(S):\nFrom a modeling point of view, it means that while a single event, or a single observation, G, may have several (or even in nite) explanations\nDB\n(G), only one of\nDB\n(G) is allowed\nto be true for each observation.\nNow introduce\nDB\n, i.e. the set of all explanations relevant to obs(DB) by\nDB\ndef =\n[\nG2obs(DB)\nDB\n(G)\nand x an enumeration S\n1\n; S\n2\n; : : : of explanations in\nDB\n. It follows from Proposition A.2,\nthe uniqueness condition and the exclusiveness condition that\nP\nDB\n(S\ni\n^ S\nj\n) = 0 for i 6= j and\nX\nS2\nDB\nP\nDB\n(S) =\nX\nG2obs(DB)\nX\nS2\nDB\n(G)\nP\nDB\n(S)\n=\nX\nG2obs(DB)\nP\nDB\n(G)\n= 1:\nSo we are able to introduce under the uniqueness condition and the exclusiveness condition yet another random variable X\ne\n, representing an explanation for G, de ned by\nX\ne\n(!) = k i ! j= S\nk\nfor ! 2\nDB\n: (6)\nThe third condition concerns termination.\n21.\nP\nG2obs(DB)\nP\nDB\n(G) = 1 only guarantees that the measure of f! j ! j= G\nk\nfor some k ( 1)g is one, so\nthere can be some ! satisfying no G\nk\n's. In such case, we put Y\no\n(!) = 0. But values on a set of measure\nzero do not a ect any part of the discussion that follows. This also applies to the de nition of X\ne\nin (6).\nFinite support condition:\nFor every G 2 obs(DB)\nDB\n(G) is nite.\nP\nDB\n(G) is then computed from the support set\nDB\n(G) = fS\n1\n; : : : ; S\nm\ng (0 m), with\nthe help of the exclusiveness condition, as a nite summation\nP\nm i=1 P F (S i ). This condition\nprevents an in nite summation that is hardly computable.\nThe fourth condition simpli es the probability computation to multiplication. Recall\nthat an explanation S for G 2 obs(DB) is a conjunction a\n1\n^ ^ a\nm\nof some abducibles\nfa\n1\n; : : : ; a\nm\ng F (1 m). In order to reduce the computation of P\nF\n(S) = P\nF\n(a\n1\n^ ^a\nm\n)\nto the multiplication P\nF\n(a\n1\n) P\nF\n(a\nm\n), we assume\nDistribution condition:\nF is a set F\nmsw\nof ground atoms with a parameterized distribution P\nmsw\nspeci ed below.\nHere atom msw(i,n,v) is intended to simulate a multi-ary random switch whose name is i and whose outcome is v on trial n. It is a generalization of primitive probabilistic events such as coin tossing and dice rolling.\n1. F\nmsw\nconsists of probabilistic atoms msw(i,n,v). The arguments i, n and v are ground\nterms called switch name, trial-id and a value (of the switch i), respectively. We assume that a nite set V\ni\nof ground terms called the value set of i is associated with\neach i, and v 2 V\ni\nholds.\n2. Write V\ni\nas fv\n1\n; v\n2\n; : : : ; v\nm\ng (m = jV\ni\nj). Then, one of the ground atoms f msw(i,n,v\n1\n),\nmsw(i,n,v\n2\n), . . . , msw(i,n,v\nm\n)g becomes exclusively true (takes on value 1) on each\ntrial. With each i, a parameter\ni;v\n2 [0; 1] such that\nP\nv2V\ni\ni;v\n= 1 is associated.\ni;v\nis the probability of msw(i, ,v) being true (v 2 V\ni\n).\n3. For each ground terms i, i\n0\n, n, n\n0\n, v 2 V\ni\nand v\n0\n2 V\ni\n0\n, random variable msw(i,n,v) is\nindependent of msw(i\n0\n,n\n0\n,v\n0\n) if n 6= n\n0\nor i 6= i\n0\n.\nIn other words, we introduce a family of parameterized nite distributions P\n(i;n)\nsuch that\nP\n(i;n)\n(msw(i,n,v\n1\n) = x\n1\n; : : : ;msw(i,n,v\nm\n) = x\nm\nj\ni;v\n1\n; : : : ;\ni;v\nm\n)\ndef =\n(\nx\n1 i;v\n1\nx\nm\ni;v\nm\nif\nP\nm k=1 x k = 1\n0 o.w.\n(7)\nwhere m = jV\ni\nj, x\nk\n2 f0; 1g (1 k m), and de ne P\nmsw\nas their in nite product\nP\nmsw\ndef =\nY\ni;n\nP\n(i;n)\n:\nUnder this condition, we can compute P\nmsw\n(S), the probability of an explanation S, as the\nproduct of parameters. Suppose msw(i\nj\n,n,v) and msw(i\nj\n0\n,n\n0\n,v\n0\n) are di erent conjuncts in\nan explanation S = msw(i\n1\n,n\n1\n,v\n1\n) ^ ^ msw(i\nk\n,n\nk\n,v\nk\n). If either j 6= j\n0\nor n 6= n\n0\nholds,\nthey are independent by construction. Else if j = j\n0\nand n = n\n0\nbut v 6= v\n0\n, they are not\nindependent but P\nmsw\n(S) = 0 by construction. As a result, whichever condition may hold,\nP\nmsw\n(S) is computed from the parameters."}, {"heading": "4.3 Modeling Principle", "text": "Up to this point, we have introduced four conditions, the uniqueness condition, the exclusiveness condition, the nite support condition and the distribution condition, to simplify probability computation. The last one is easy to satisfy. We just adopt F\nmsw\ntogether with\nP\nmsw\n. So, from here on, we always assume that F\nmsw\nhas a parameterized distribution P\nmsw\nintroduced in the previous subsection. Unfortunately the rest are not satis ed automatically. According to our modeling experiences however, it is only mildly di cult to satisfy the uniqueness condition and the exclusiveness condition as long as we obey the following modeling principle.\nModeling principle: DB = F\nmsw\n[R describes a sequential decision process\n(modulo auxiliary computations) that uniquely produces an observable atom G 2 obs(DB) where each decision is expressed by some msw atom. 22\nTranslated into programming level, it says that we must take care when writing a pro-\ngram so that for any sample F\n0\nfrom P\nmsw\n, there must uniquely exist goal G (G 2 obs(DB))\nwhich has a successful refutation from DB\n0\n= F\n0\n[ R. We can con rm the principle by the\nblood type program DB\nb\n= F\nb\n[ R\nb\n. It describes a process of gene inheritance, and for\nan arbitrary sample F\n0 b from P msw , say F 0 b = fmsw(gene,father,a); msw(gene,mother,o)g,\nthere exists a unique goal, btype('A') in this case, that has a successful SLD refutation from F 0\nb\n[R\nb\n.\nThe idea behind this principle is that a decision process always produces some result (an observable atom), and di erent decision processes must di er at some msw thereby entailing mutually exclusive observable atoms. So the uniqueness condition and the exclusiveness condition will be automatically satis ed.\nSatisfying the nite support condition is more di cult as it is virtually equivalent to writing a program DB for which all solution search for G (G 2 obs(DB)) always terminates. Apparently we have no general solution to this problem, but as far as speci c models such as HMMs, PCFGs and Bayesian networks are concerned, it can be met. All programs for these models satisfy the nite support condition (and other conditions as well)."}, {"heading": "4.4 Four Conditions Revisited", "text": "In this subsection, we discuss how to relax the four simplifying conditions introduced in Subsection 4.2 for the purpose of exible modeling. We rst examine the uniqueness condition considering its crucial role in the adaptation of the EM algorithm to our semantics.\nThe uniqueness condition guarantees that there exists a (many-to-one) mapping from explanations to observations so that the EM algorithm is applicable (Dempster et al., 1977). It is possible, however, to relax the uniqueness condition while justifying the application of the EM algorithm. We assume the MAR (missing at random) condition introduced by Rubin (1976) which is a statistical condition on how a complete data (explanation) becomes an incomplete data (observation), and is customarily assumed implicitly or explicitly in statistics (see Appendix B). By assuming the MAR condition, we can apply our EM"}, {"heading": "22. Decisions made in the process are a nite subset of F", "text": "msw\n.\nalgorithm to non-exclusive observations O such that\nP\nO\nP (O) 1 where the uniqueness\ncondition is seemingly destroyed.\nLet us see the MAR condition in action with a simple example. Imagine we walk along a road in front of a lawn. We occasionally observe their state such as \\the road is dry but the lawn is wet\". Assume that the lawn is watered by a sprinkler running probabilistically. The program DB\nrl\n= R\nrl\n[ F\nrl\nin Figure 2 describes a sequential process which outputs\nan observation observed(road(x),lawn(y)) (\\the road is x and the lawn is y\") where x; y 2 fwet; dryg.\nThe basic distribution over F\nrl\nis speci ed like P\nF\nb\n( ) in Subsection 4.1, so we omit it.\nmsw(rain,once,A) in the program determines whether it rains (A = yes) or not (A = no), whereas msw(sprinkler,once,B) determines whether the sprinkler works ne (B = on) or not (B = off). Since for each sampled values of A = a (a 2 fyes; nog) and B = b (b 2 fon;offg), there uniquely exists an observation observed(road(x),lawn(y)) (x; y 2 fwet; dryg), there is a many-to-one mapping : (a; b) = hx; yi. In other words, we can apply the EM algorithm to the observations observed(road(x),lawn(y)) (x; y 2 fwet; dryg). What would happen if we observe exclusively either a state of the road or that of the lawn? Logically, this means we observe 9y observed(road(x),lawn(y)) or 9x observed(road(x),lawn(y)). Apparently the uniqueness condition is not met, because 9y observed(road(wet),lawn(y)) and 9x observed(road(x),lawn(wet)) are compatible (they are true when it rains). Despite the non-exclusiveness of the observations, we can still apply the EM algorithm to them under the MAR condition, which in this case translates into that we observe either the lawn or the road randomly regardless of their state.\nWe now brie y check other conditions. Basically they can be relaxed at the cost of increased computation. Without the exclusiveness condition for instance, we would need an additional process of transforming the support set\nDB\n(G) for a goal G into a set of exclusive\nexplanations. For instance, if G has explanations fmsw(a,n,v); msw(b,m,w)g, we have to transform it into fmsw(a,n,v); :msw(a,n,v) ^ msw(b,m,w)g and so on. 23 Clearly, this transformation is exponential in the number of msw atoms and e ciency concern leads to assuming the exclusiveness condition.\nThe nite support condition is in practice equivalent to the condition that the SLD tree\nfor G is nite. So relaxing this condition might induce in nite computation.\n23. :msw(a,n,v) is further transformed to a disjunction of exclusive msw atoms like\nW\nv\n0\n6=v;v\n0\n2V\na\nmsw(a,n,v\n0\n).\nRelaxing the distribution condition and accepting probability distributions other than\nP\nmsw\nserve to expand the horizon of the applicability of parameterized logic programs. In\nparticular the introduction of parameterized joint distributions P (v\n1\n; : : : ; v\nk\n) like Boltz-\nmann distributions over switches msw\n1\n; : : : ;msw\nk\nwhere v\n1\n; : : : ; v\nk\nare values of the switches,\nmakes them correlated. Such distributions facilitate writing parameterized logic programs for complicated decision processes in which decisions are not independent but interdependent. Obviously, on the other hand, they increase learning time, and whether the added\nexibility of distributions deserves the increased learning time or not is yet to be seen."}, {"heading": "4.5 Naive Approach to EM Learning", "text": "In this subsection, we derive a concrete EM algorithm for parameterized logic programs DB = F\nmsw\n[ R assuming that they satisfy the uniqueness condition, the exclusiveness\ncondition and the nite support condition.\nTo start, we introduce Y\no\n, a random variable representing our observations according\nto (5) based on a xed enumeration of observable atoms in obs(DB). We also introduce another random variable X\ne\nrepresenting their explanations according to (6) based on some\nxed enumeration of explanations in\nDB\n. Our understanding is that X\ne\nis non-observable\nwhile Y\no\nis observable, and they have a joint distribution P\nDB\n(X\ne\n= x; Y\no\n= y j ) where\ndenotes relevant parameters. It is then immediate, following (1) and (2) in Section 2, to\nderive a concrete EM algorithm from the Q function de ned by Q( j\n0\n)\ndef =\nP\nx\nP\nDB\n(x j\ny;\n0\n) lnP\nDB\n(x; y j ) whose input is a random sample of observable atoms and whose output\nis the MLE of .\nIn the following, for the sake of readability, we substitute an observable atom G (G 2\nobs(DB)) for Y\no\n= y and write P\nDB\n(G j ) instead of P\nDB\n(Y\no\n= y j ). Likewise we\nsubstitute an explanation S (S 2\nDB\n) for X\ne\n= x and write P\nDB\n(S;G j ) instead of\nP\nDB\n(X\ne\n= x; Y\no\n= y j ). Then it follows from the uniqueness condition that\nP\nDB\n(S;G j ) =\n(\n0 if S 62\nDB\n(G)\nP\nmsw\n(S j ) if S 2\nDB\n(G):\nWe need yet another notation here. For an explanation S, de ne the count of msw(i,n,v) in S by\ni;v\n(S)\ndef = jf n j msw(i,n,v) 2 Sgj :\nWe have done all preparations now. Suppose we make some observations G = G\n1\n; : : : ; G\nT\nwhere G\nt\n2 obs(DB) (1 t T ). Put\nI\ndef = fi j msw(i,n,v) 2 S 2\nDB\n(G\nt\n); 1 t Tg\ndef = f\ni;v\nj msw(i,n,v) 2 S 2\nDB\n(G\nt\n); 1 t Tg:\nI is a set of switch names that appear in some explanation for one of the G\nt\n's and denotes\nparameters associated with these switches. is nite due to the nite support condition.\nVarious probabilities and the Q function are computed by using Proposition A.2 in\nAppendix A together with our assumptions as follows.\nP\nDB\n(G\nt\nj ) = P\nDB\n_\nDB\n(G\nt\n)\n=\nX\nS2\nDB\n(G\nt\n)\nP\nmsw\n(S j ) (8)\nP\nmsw\n(S j ) =\nY\ni2I;v2V\ni\ni;v\n(S)\ni;v\nQ( j\n0\n)\ndef =\nT\nX\nt=1\nX\nS2\nDB\nP\nDB\n(S j G\nt\n;\n0\n) lnP\nDB\n(S;G\nt\nj )\n=\nX\ni2I;v2V\ni\n(i; v;\n0\n) ln\ni;v\nX\ni2I;v2V\ni\n(i; v;\n0\n) ln\n(i; v;\n0\n)\nP\nv\n0\n2V\ni\n(i; v\n0\n;\n0\n)\n!\n(9)\nwhere\n(i; v; )\ndef =\nT\nX\nt=1\n1\nP\nDB\n(G\nt\nj )\nX\nS2\nDB\n(G\nt\n)\nP\nmsw\n(S j )\ni;v\n(S)\nHere we used Jensen's inequality to obtain (9). Note that P\nDB\n(G\nt\nj )\n1\nP\nS2\nDB\n(G\nt\n)\nP\nmsw\n(S j )\ni;v\n(S) is the expected count of msw(i, ,v) in an SLD refutation of G\nt\n. Speaking\nof the likelihood function L( ) =\nQ\nT t=1 P DB (G t j ), it is already shown in Subsection 2.2\n(footnote) that Q( j\n0\n) Q(\n0\nj\n0\n) implies L( ) L(\n0\n). Hence from (9), we reach\nthe procedure learn-naive(DB,G) below that nds the MLE of the parameters. The array variable [i; v] stores (i; v; ) under the current .\n1: procedure learn-naive(DB;G) begin 2: Initialize with appropriate values and \" with a small positive number ; 3: (0) := P T\nt=1\nlnP\nDB\n(G\nt\nj ); % Compute the log-likelihood.\n4: repeat 5: foreach i 2 I; v 2 V\ni\ndo\n6: [i; v] :=\nT\nX\nt=1\n1\nP\nDB\n(G\nt\nj )\nX\nS2\nDB\n(G\nt\n)\nP\nmsw\n(S j )\ni;v\n(S);\n7: foreach i 2 I; v 2 V\ni\ndo\n8:\ni;v\n:=\n[i; v]\nP\nv\n0\n2V\ni\n[i; v\n0\n]\n; % Update the parameters.\n9: m := m+ 1;\n10:\n(m)\n:=\nP\nT t=1 lnP DB (G t j ) % Compute the log-likelihood again.\n11: until\n(m)\n(m 1)\n< \" % Terminate if converged.\n12: end\nThis EM algorithm is simple and correctly calculates the MLE of , but the calcula-\ntion of P\nDB\n(G\nt\nj ) and [i; v](Line 3, 6 and 10) may su er a combinatorial explosion of\nexplanations. That is, j\nDB\n(G\nt\n)j often grows exponentially in the complexity of the model.\nFor instance, j\nDB\n(G\nt\n)j for an HMM with N states is O(N\nL\n), exponential in the length L\nof an input/output string. Nonetheless, suppressing the explosion to realize e cient computation in a polynomial order is possible, under suitable conditions, by avoiding multiple computations of the same subgoal as we see next."}, {"heading": "4.6 Inside Probability and Outside Probability for Logic Programs", "text": "In this subsection, we generalize the notion of inside probability and outside probability (Baker, 1979; Lari & Young, 1990) to logic programs. Major computations in learn-naive(DB,G) are those of two terms in Line 6, P\nDB\n(G\nt\nj ) and\nP\nS2\nDB\n(G\nt\n)\nP\nmsw\n(S j )\ni;v\n(S). Computa-\ntional redundancy lurks in the naive computation of both terms. We show it by an example. Suppose there is a propositional program DB\np\n= F\np\n[R\np\nwhere F\np\n= fa;b; c; d;mg and\nR\np\n=\n8 > > > <\n> > > :\nf a ^ g f b ^ g g c g d ^ h h m:\n(10)\nHere f is an observable atom. We assume that a, b, c, d and m are independent and also that fa; bg and fc; dg are pair-wise exclusive. Then the support set for f is calculated as\nDB\np\n(f) = fa ^ c; a ^ d ^ m; b ^ c; b ^ d ^ m g:\nHence, in light of (8), we may compute P\nDB\np\n(f) as\nP\nDB\np\n(f) = P\nF\np\n(a ^ c) + P\nF\np\n(a ^ d ^ m) + P\nF\np\n(b ^ c) + P\nF\np\n(b ^ d ^ m): (11)\nThis computation requires 6 multiplications (because P\nF\np\n(a ^ c) = P\nF\np\n(a)P\nF\np\n(c) etc.) and\n3 additions. On the other hand, it is possible to compute P\nDB\np\n(f) much more e ciently by\nfactoring out common computations. Let A be a ground atom. De ne the inside probability\n(A) of A as\n(A)\ndef = P\nDB\n(A j ):\n24\n(12)\nThen by applying Theorem A.1 in Appendix A to\ncomp(R\np\n) ` f$ (a ^ g) _ (b ^ g); g$ c _ (d ^ h); h$ m (13)\nwhich unconditionally holds in our semantics, and by using the independent and the exclusiveness assumption made on F\np\n, the following equations about inside probability are\nderived.\n8 > <\n> :\n(f) = (a) (g) + (b) (g) (g) = (c) + (d) (h) (h) = (m)\n(14)\nP\nDB\np\n(f)(= (f)) is obtained by solving (14) about (f), for which only 3 multiplications\nand 2 additions are required.\nIt is quite straightforward to generalize (14) but before proceeding, look at a program\nDB\nq\n= fmg [ fg:-m ^ m; g:-mg where g is an observable atom and m the only msw atom.\nWe have g$ (m ^ m) _ m in our semantics, but to compute P (g) = P (m)P (m) + P (m) is clearly wrong as it ignores the fact that clause bodies for g, i.e. m^m and m are not mutually exclusive, and atoms in the clause body m^m are not independent (here P ( ) = P\nDB\nq\n( )).\nSimilarly, if we set a = b = c = d = m, the equation (14) will be totally incorrect.\n24. Note that if A is a fact in F , (A) = P\nmsw\n(A j ).\nWe therefore add, temporarily in this subsection, two assumptions on top of the exclusiveness condition and the nite support condition so that equations like (14) become mathematically correct. The rst assumption is that \\clause\" bodies are mutually exclusive i.e. if there are two clauses B W and B W 0 , P\nDB\n(W ^W\n0\nj ) = 0, and the\nsecond assumption is that body atoms are independent, i.e. if A B\n1\n^ ^B\nk\nis a rule,\nP\nDB\n(B\n1\n^ ^B\nk\nj ) = P\nDB\n(B\n1\nj ) P\nDB\n(B\nk\nj ) holds.\nPlease note that \\clause\" used in this subsection has a special meaning. It is intended to mean G where G is a goal and is a tabled explanation for G obtained by OLDT search both of which will be explained in the next subsection. 25 In other words, these additional conditions are not imposed on a source program but on the result of OLDT search. So clauses for auxiliary computations do not need to satisfy them.\nNow suppose clauses about A occur in DB like\nA B\n1;1\n^ ^B\n1;i\n1\nA B\nL;1\n^ ^B\nL;i\nL\nwhere B\nh;j\n(1 h L; 1 j i\nh\n) is an atom. Theorem A.1 in Appendix A and the above\nassumptions ensure\n(A) =\ni\n1\nY\nj=1\n(B\n1;j\n) + +\ni\nL\nY\nj=1\n(B\nL;j\n): (15)\n(15) suggests that (G\nt\n) can be considered as a function of (A) if these equations about\ninside probabilities are hierarchically organized in such a way that (G\nt\n) belongs to the top\nlayer and any (A) appearing on the left hand side only refers to (B)'s which belong to the lower layers. We refer to this condition as the acyclic support condition. Under the acyclic support condition, equations of the form (15) have a unique solution, and the computation of P\nDB\n(G j ) via inside probabilities allows us to take advantage of reusing intermediate\nresults stored as (A), thereby contributing to faster computation of P\nDB\n(G\nt\nj ).\nNext we tackle a more intricate problem, the computation of\nP\nS2\nDB\n(G\nt\n)\nP\nmsw\n(S j\n)\ni;v\n(S). Since the sum equals\nP\nn\nP\nmsw(i,n,v)2S2\nDB\n(G\nt\n)\nP\nmsw\n(S j ), we concentrate\non the computation of\n(G\nt\n; m)\ndef =\nX\nm2S2\nDB\n(G\nt\n)\nP\nmsw\n(S j )\nwhere m = msw(i,n,v). First we note that if an explanation S contains m like S = a\n1\n^ ^\na\nh\n^ m, then we have (S) = (a\n1\n) (a\nh\n) (m). So (G\nt\n;m) is expressed as\n(G\nt\n; m) = (G\nt\n; m) (m) (16)\nwhere (G\nt\n;m) =\n@ (G\nt\n;m)\n@ (m)\nand (G\nt\n; m) does not depend on (m). Generalizing this obser-\nvation to arbitrary ground atoms, we introduce the outside probability of ground atom A w.r.t. G\nt\nby\n(G\nt\n; A)\ndef =\n@ (G\nt\n)\n@ (A)\n25. The logical relationship (13) corresponds to (20) where f, g and h are table atoms.\nassuming the same conditions as inside probability. In view of (16), the problem of computing (G\nt\n;m) is now reduced to that of computing (G\nt\n;m), which is recursively computable\nas follows. Suppose A occurs in the ground program DB like\nB\n1\nA ^W\n1;1\n; ;B\n1\nA ^W\n1;i\n1\nB\nK\nA ^W\nK;1\n; ;B\nK\nA ^W\nK;i\nK\n:\nAs (G\nt\n) is a function of (B\n1\n); : : : ; (B\nK\n) by our assumption, the chain rule of derivatives\nleads to\n(G\nt\n; A) =\n@ (G\nt\n)\n@ (B\n1\n)\n@ (A ^W\n1;1\n)\n@ (A)\n+ +\n@ (G\nt\n)\n@ (B\nK\n)\n@ (A ^W\nK;i\nK\n)\n@ (A)\nand hence to\n26\n(G\nt\n; G\nt\n) = 1 (17)\n(G\nt\n;A) = (G\nt\n;B\n1\n)\ni\n1\nX\nj=1\n(W\n1;j\n) + + (G\nt\n;B\nK\n)\ni\nK\nX\nj=1\n(W\nK;j\n): (18)\nTherefore if all inside probabilities have already been computed, outside probabilities are recursively computed from the top (17) using (18) downward along the program layers. In the case of DB\np\nwith f and m being chosen atoms, we compute\n8 > > <\n> > :\n(f;f) = 1 (f;g) = (a) + (b) (f;h) = (f; g) (d) (f;m) = (f; h):\n(19)\nFrom (19), the desired sum (f; m) is calculated as\n(f; m) = (f; m) (m) = ( (a) + (b)) (d) (m)\nwhich requires only two multiplications and one addition compared to four multiplications and one addition in the naive computation.\nGains obtained by computing inside and outside probability may be small for this case, but as the problem size grows, they become enormous, and compensate enough for additional restrictions imposed on the result of OLDT search."}, {"heading": "4.7 OLDT Search", "text": "To compute inside and outside probability recursively like (15) or (17) and (18), we need at programming level a tabulation mechanism for structure-sharing of partial explanations"}, {"heading": "26. Because of the independence assumption on body atoms, W", "text": "h;j\n(1 h K; 1 j i\nh\n) and A are\nindependent. Therefore\n@ (A ^W\nh;j\n)\n@ (A)\n=\n@ (A) (W\nh;j\n)\n@ (A)\n= (W\nh;j\n):\nbetween subgoals. We henceforth deal with programs DB in which a set table(DB) of table predicates are declared in advance. A ground atom containing a table predicate is called a table atom. The purpose of table atoms is to store their support sets and eliminate the need of recomputation, and by doing so, to construct hierarchically organized explanations made up of the table atoms and the msw atoms.\nLet DB = F\nmsw\n[R be a parameterized logic program which satis es the nite support\ncondition and the uniqueness condition. Also let G\n1\n;G\n2\n; : : : ;G\nT\nbe a random sample of\nobservable atoms in obs(DB). We make the following additional assumptions.\nAssumptions:\nFor each t (1 t T ), there exists a nite set f\nt 1 ; : : : ; t\nK\nt\ng of table atoms associated\nwith conjunctions\ne S\nt k;j (0 k K t ; 1 j m k ) such that\ncomp(R) `\nG\nt\n$\ne S\nt 0;1 _ _ e S t 0;m\n0\n^\nt 1 $ e S t 1;1 _ _ e S t 1;m\n1\n^ ^\nt K\nt\n$\ne S\nt K\nt\n;1\n_ _\ne S\nt K\nt\n;m\nK\nt\n(20)\nwhere\neach\ne S\nt k;j (0 k K t ; 1 j m k ) is, as a set, a subset of F msw [ f k+1 ; : : : ; K t g\n(acyclic support condition). As a convention, we put\n0\n= G\nt\nand call respectively\nt DB\ndef = f\n0\n;\nt 1 ; : : : ; t\nK\nt\ng the set of table atoms for G\nt\nand\ne S\nt k;j (k 0) a t-explanation\nfor\nt k . 27 The set of all t-explanations for k is denoted by e DB ( t k ) and we consider\ne\nDB\n( ) as a function of table atoms.\nt-explanations are mutually exclusive, i.e. for each k (0 k K\nt\n), P\nDB\n(\ne S\nt k;j ^ e S t k;j 0 ) =\n0 (1 j 6= j\n0\nm\nk\n) (t exclusiveness condition).\ne S\nt k;j (0 k K t ; 1 j m k ) is a conjunction of independent atoms (independent\ncondition).\n28\nThese assumptions are aimed at e cient probability computation. Namely, the acyclic support condition makes dynamic programming possible, the t-exclusiveness condition reduces P\nDB\n(A_B) to P\nDB\n(A)+P\nDB\n(B) and the independent condition reduces P\nDB\n(A^B)\nto P\nDB\n(A)P\nDB\n(B). There is one more point concerning e ciency however. Note that the\ncomputation in dynamic programming proceeds following the partial order on\nt DB 29 im-\nposed by the acyclic support condition and access to the table atoms will be much simpli ed if they are linearly ordered. We therefore topologically sort t\nDB\nrespecting the said partial\norder and call the linearized\nt DB satisfying the three assumptions (the acyclic support con-\ndition, the t-exclusiveness condition and the independent condition) a hierarchical system of t-explanations for G\nt\n. We write it as\nt DB = h t 0 ; t 1 ; : : : ; t K\nt\ni (\n0\n= G\nt\n) assuming\ne\nDB\n( ) is\nimplicitly given.\n30\nOnce a hierarchical system of t-explanations for G\nt\nis successfully built"}, {"heading": "27. Pre x \\t-\" is an abbreviation of \\tabled-\".", "text": "28. The independence mentioned here only concerns positive propositions. For B\n1\n; B\n2\n2 head(DB), we say\nB\n1\nand B\n2\nare independent if P\nDB\n(B\n1\n^ B\n2\nj ) = P\nDB\n(B\n1\nj )P\nDB\n(B\n2\nj ) for any .\n29.\ni\nprecedes\nj\nif and only if the top-down execution of\ni\nw.r.t. DB invokes\nj\ndirectly or indirectly.\n30. So now it holds that if\ni\nprecedes\nj\nthen i < j.\nfrom the source program, equations on inside probability and outside probability such as (14) and (19) are automatically derived and solved in time proportional to the size of the equations. It plays a central role in our approach to e cient EM learning.\nOne way to obtain such t-explanations is to use OLDT search (Tamaki & Sato, 1986; Warren, 1992), a complete refutation method for logic programs. In OLDT search, when a goal G is called for the rst time, we set up an entry for G in a solution table and store its answer substitutions G there. When a call to an instance G 0 of G occurs later, we stop solving G 0 and instead try to retrieve an answer substitution G stored in the solution table by unifying G 0 with G . To record the remaining answer substitutions of G, we prepare a lookup table for G 0 and hold a pointer to them.\nFor self-containedness, we look at details of OLDT search using a sample program\nDB\nh\n= F\nh\n[R\nh\nin Figure 4\n31\nwhich depicts an HMM\n32\nin Figure 3. This HMM has two states\nfs0; s1g. At a state transition, it probabilistically chooses the next destination from fs0; s1g\n31. f1, f2, f3, h1, h2 and h3 are temporary marks, not part of the program. 32. An HMM de nes a probability distribution over strings in the given set of alphabets, and works as a\nstochastic string generator (Rabiner & Juang, 1993) such that an output string is a sample from the de ned distribution.\nand also an alphabet from fa; bg to emit. Note that to specify a fact set F\nh\nand the associ-\nated distribution compactly, we introduce here a new notation values(i,[v\n1\n,...,v\nm\n]). It\ndeclares that F\nh\ncontains msw atoms of the form msw(i,n,v) (v 2 fv\n1\n; : : : ; v\nm\ng) whose distri-\nbution is P\n(i;n)\ngiven by (7) in Subsection 4.2. For example, (f3), values(tr( ),[s0,s1])\nintroduces msw(tr(t),n,v) atoms into the program such that t can be any ground term, v 2 fs0;s1g and for a ground term n, they have a distribution\nP\n(tr(t);n)\n(msw(tr(t),n,s0) = x; msw(tr(t),n,s1) = y j\ni;s0\n;\ni;s1\n) =\nx i;s0\ny i;s1\nwhere i = tr(t), x; y 2 f0; 1g and x+ y = 1.\nThis program runs like a Prolog program. For a non-ground top-goal hmm(S), it functions as a stochastic string generator returning a list of alphabets such as [a,b,a] in the variable S as follows. The top-goal calls clause (h1) and (h1) selects the initial state by executing subgoal msw(init,once,Si) 33 which returns in Si an initial state probabilistically chosen from fs0, s1g. The second clause (h2) is called from (h1) with ground S and ground T. It makes a probabilistic choice of an output alphabet C by asking msw(out(S),T,C) and then determines NextS, the next state, by asking msw(tr(S),T,NextS). (h3) is there to stop the transition. For simplicity, the length of output strings is xed to three. This way of execution is termed as sampling execution because it corresponds to a random sampling from P\nDB\nh\n. If the top-goal is ground like hmm([a,b,a]), it works as an acceptor, i.e.\nreturning success (yes) or failure (no).\nIf all explanations for hmm([a,b,a]) are sought for, we keep all msw atoms resolved upon during the refutation as a conjunction (explanation), and repeat this process by backtracking until no more refutation is found. If we need t-explanations however, backtracking must be abandoned because sharing of partial explanations through t-explanations, the purpose of t-explanations itself, becomes impossible. We therefore instead use OLDT search for all\n33. If msw(i,n,V) is called with ground i and ground n, V, a logical variable, behaves like a random variable.\nIt is instantiated to some term v with probability\ni;v\nselected from the value set V\ni\ndeclared by a values\natom. If, on the other hand, V is a ground term v when called, the procedural semantics of msw(i,n,v) is equal to that of msw(i,n,V) ^ V = v.\nt-explanation search. In the case of the HMM program for example, to build a hierarchical system of t-explanations for hmm([a,b,a]) by OLDT search, we rst declare hmm=1 and hmm=3 as table predicate. 34 So a t-explanation will be a conjunction of hmm=1 atoms, hmm=3 atoms and msw atoms. We then translate the program into another logic program, analogously to the translation of de nite clause grammars (DCGs) in Prolog (Sterling & Shapiro, 1986). We add two arguments (which forms a D-list) to each predicate for the purpose of accumulating msw atoms and table atoms as conjuncts in a t-explanation. The translation applied to DB\nh\nyields the program in Figure 5.\nIn the translated program, clause (t1) corresponds to the top-goal hmm(l) with an input string l, and a t-explanation for the table atom hmm(l) will be returned in Ans. (t2) and (t3) are auxiliary clauses to add to the callee's D-list a table atom of the form hmm(l) and hmm(t,s,l) respectively (t: time step, s: state). In general, if p=n is a table predicate in the original program, p=(n+2) becomes a table predicate in the translated program and an auxiliary predicate tab p=(n+2) is inserted to signal the OLDT interpreter to check the solution table for p=n, i.e. to check if there already exist t-explanations for p=n. Likewise clauses (t4) and (t4') are a pair corresponding to (f1) which insert msw(init,T, ) to the callee's D-list with T = once. Clauses (t7), (t8) and (t9) respectively correspond to (h1), (h2) and (h3).\n34. In general, p=n means a predicate p with arity n. So although hmm=1 and hmm=3 share the predicate name\nhmm, they are di erent predicates.\nThen after translation, we apply OLDT search to top hmm([a,b,a],Ans) while noting (i) the added D-list does not in uence the OLDT procedure, and (ii) we associate with each solution of a table atom in the solution table a list of t-explanations. The resulting solution table is shown in Figure 6. The rst row reads that a call to hmm([a,b,a]) occurred and entered the solution table and its solution, hmm([a,b,a]) (no variable binding generated), has two t-explanations, msw(init,once,s0) ^ hmm(1,s0,[a,b,a]) and msw(init,once,s1) ^ hmm(1,s1,[a,b,a]). The remaining task is the topological sorting of the table atoms stored in the solution table respecting the acyclic support condition. This can be done by using depth- rst search (trace) of t-explanations from the top-goal for example. Thus we obtain a hierarchical system of t-explanations for hmm([a,b,a])."}, {"heading": "4.8 Support Graphs", "text": "Looking back, all we need to compute inside and outside probability is a hierarchical system of t-explanations, which essentially is a boolean combination of primitive events (msw atoms) and compound events (table atoms) and as such can be more intuitively representable as a graph. For this reason, and to help visualizing our learning algorithm, we introduce a new data-structure termed support graphs, though the new EM algorithm in the next subsection itself is described solely by the hierarchical system of t-explanations.\nAs illustrated in Figure 7 (a), the support graph for G\nt\nis a graphical representation of\nthe hierarchical system of t-explanations\nt DB = h t 0 ; t 1 ; : : : ; t K\nt\ni (\nt 0 = G t ) for G t in (20).\nIt consists of totally ordered disconnected subgraphs, each of which is labeled with the corresponding table atom t\nk\nin\nt DB (0 k K t ). A subgraph labeled t\nk\ncomprises two\nspecial nodes (the start node and the end node) and explanation graphs, each corresponding to a t-explanation e S t\nk;j\nin\ne\nDB\n(\nt k ) (1 j m k ).\nAn explanation graph of\ne S\nt k;j is a linear graph in which a node is labeled either with a\ntable atom or with a switch msw( , , ) in\ne S\nt k;j . They are called a table node and a switch\nnode respectively. Figure 7 (b) is the support graph for hmm([a,b,a]) obtained from the solution table in Figure 6. Each table node labeled refers to the subgraph labeled , so data-sharing is achieved through the distinct table nodes referring to the same subgraph."}, {"heading": "4.9 Graphical EM Algorithm", "text": "We describe here an e cient EM learning algorithm termed the graphical EM algorithm (Figure 8) introduced by Kameya and Sato (2000), that runs on support graphs. Suppose we have a random sample G = G\n1\n; : : : ;G\nT\nof observable atoms. Also suppose support\ngraphs for G\nt\n(1 t T ), i.e. hierarchical systems of t-explanations satisfying the acyclic\nsupport condition, the t-exclusiveness condition and the independent condition, have been successfully constructed from a parameterized logic program DB satisfying the uniqueness condition and the nite support condition.\nThe graphical EM algorithm re nes learn-naive(DB,G) by introducing two subroutines, get-inside-probs(DB, G) to compute inside probabilities and get-expectations(DB, G) to compute outside probabilities. They are called from the main routine learn-gEM(DB,G). When learning, we prepare four arrays for each support graph for G\nt\nin G:\nP [t; ] for the inside probability of , i.e. ( ) = P\nDB\n( j ) (see (12))\nQ[t; ] for the outside probability of w.r.t. G\nt\n, i.e. (G\nt\n; ) (see (17) and (18))\nR[t; ;\ne S] for the explanation probability of e S (2 e\nDB\n(\nt k )), i.e. P DB ( e S j )\n[t; i; v] for the expected count of msw(i, ,v), i.e.\nP\nS2\nDB\n(G\nt\n)\nP\nmsw\n(S j )\ni;v\n(S)\nand call the procedure learn-gEM(DB,G) in Figure 8. The main routine learn-gEM(DB,G) initially computes all inside probabilities (Line 4) and enters a loop in which get-expectations(DB,G) is called rst to compute the expected count [t; i; v] of msw(i, ,v) and parameters are updated (Line 11). Inside probabilities are renewed by using the updated parameters before entering the next loop (Line 12).\nThe subroutine get-inside-probs(DB,G) computes the inside probability ( ) = P\nDB\n( j )\n(and stores it in P [t; ]) of a table atom from the bottom layer up to the topmost layer\n0\n=\nG\nt\n(Line 4) of the hierarchical system of t-explanations for G\nt\n(see (20) in Subsection 4.6).\nIt takes a t-explanation\ne S in e\nDB\n(\nt k ) one by one (Line 7), decomposes e S into conjuncts and\nmultiplies their inside probabilities which are either known (Line 12) or already computed (Line 13).\nThe other subroutine get-expectations(DB,G) computes outside probabilities following the recursive de nitions (17) and (18) in Subsection 4.6 and stores the outside probability\n(G\nt\n; ) of a table atom in Q[t; ]. It rst sets the outside probability of the top-goal\n0\n= G\nt\nto 1:0 (Line 4) and computes the rest of outside probabilities (Line 6) going down\nthe layers of the t-explanation for G\nt\ndescribed by (20) in Subsection 4.6. (Line 10) adds\nQ[t;\nt k ] R[t; t k ; e S] = (G t ; t k ) ( e S) to [t; i; v], the expected count of msw(i, ,v), as a\ncontribution of msw(i, ,v) in\ne S through\nt k to [t; i; v]. (Line 11) increments the outside\nprobability Q[t;A\nl\n] = (G\nt\n;A\nl\n) of A\nl\naccording to the equation (18). Notice that Q[t;\nt k ]\nhas already been computed and R[t;\nt k ; e S]=P [t;A l ] = (W ) for e S = A l ^W . As shown in\nSubsection 4.5, learn-naive(DB,G) is the MLE procedure, hence the following theorem holds.\nTheorem 4.1 Let DB be a parameterized logic program, and G = G\n1\n; : : : ; G\nT\na ran-\ndom sample of observable atoms. Suppose the ve conditions (uniqueness, nite support (Subsection 4.2), acyclic support, t-exclusiveness and independence (Subsection 4.7)) are met. Then learn-gEM (DB;G) nds the MLE which (locally) maximizes the likelihood L(G j ) = Q T\nt=1\nP\nDB\n(G\nt\nj ).\n(Proof) Sketch.\n35\nSince the main routine learn-gEM(DB,G) is the same as learn-naive(DB,G)\nexcept the computation of [i; v] =\nP\nT t=1 [t; i; v], we show that [t; i; v] =\nP\nS2\nDB\n(G\nt\n)\nP\nmsw\n(S j\n)\ni;v\n(S) (=\nP\nn\nP\nmsw(i,n,v)2S2\nDB\n(G\nt\n)\nP\nmsw\n(S j )). However,\n[t; i; v] =\nX\n0 k K\nt\nX\nn\nX\nmsw(i,n,v)2\ne S2 e\nDB\n(\nt k )\n(G\nt\n;\nt k ) ( e S)\n(see (Line 10) in get-expectations(DB;G))\n=\nX\nn\n(G\nt\n;msw(i,n,v)) (msw(i,n,v))\n=\nX\nn\n(G\nt\n;msw(i,n,v)) (see the equation (16))\n=\nX\nn\nX\nmsw(i,n,v)2S2\nDB\n(G\nt\n)\nP\nmsw\n(S j ): Q.E.D.\nHere we used the fact that if\ne S contains msw(i,n,v) like e S = e S\n0\n^ msw(i,n,v), (\ne S) =\n(\ne S\n0\n) (msw(i,n,v)) holds, and hence\n(G\nt\n;\nt k ) ( e S) = (G t ; t k ) ( e S 0 ) (msw(i,n,v))\n= (contribution of msw(i,n,v) in\ne S through\nt k to (G t ; msw(i,n,v))) (msw(i,n,v)):\n35. A formal proof is given by Kameya (2000). It is proved there that under the common parameters , [i; v]\nin learn-naive(DB,G) coincides with [i; v] in learn-gEM(DB,G). So, the parameters are updated to the same values. Hence, starting with the same initial values, the parameters converge to the same values.\nThe ve conditions on the applicability of the graphical EM algorithm may look hard to satisfy at once. Fortunately, the modeling principle in Section 4.3 still stands, and with due care in modeling, it is likely to lead us to a program that meets all of them. Actually, we will see in the next section, programs for standard symbolic-statistical frameworks such as Bayesian networks, HMMs and PCFGs all satisfy the ve conditions."}, {"heading": "5. Complexity", "text": "In this section, we analyze the time complexity of the graphical EM algorithm applied to various symbolic-statistical frameworks including HMMs, PCFGs, pseudo PCSGs and Bayesian networks. The results show that the graphical EM algorithm is competitive with these specialized EM algorithms developed independently in each research eld."}, {"heading": "5.1 Basic Property", "text": "Since the EM algorithm is an iterative algorithm and since we are unable to predict when it converges, we measure time complexity by the time taken for one iteration. We therefore estimate time per iteration on the repeat loop of learn-gEM (DB;G) (G = G\n1\n; : : : ;G\nT\n). We\nobserve that in one iteration, each support graph for G\nt\n(1 t T ) is scanned twice, once\nby get-inside-probs(DB;G) and once by get-expectations(DB;G). In the scan, addition is performed on the t-explanations, and multiplication (possibly with division) is performed on the msw atoms and table atoms once for each. So time spent for G\nt\nper iteration by the\ngraphical EM algorithm is linear in the size of the support graph, i.e. the number of nodes in the support graph for G\nt\n. Put\ne\nt DB\ndef =\n[\n2\nt DB\ne\nDB\n( )\nnum\ndef = max\n1 t T\nj\ne\nt DB j\nmaxsize\ndef = max\n1 t T;\ne S2 e\nt DB\nj\ne Sj:\nRecall that\nt DB is the set of table atoms for G t , and hence e t DB is the set of all t-explanations\nappearing in the right hand side of (20) in Subsection 4.7. So\nnum\nis the maximum number\nof t-explanations in a support graph for the G\nt\n's and\nmaxsize\nthe maximum size of a t-\nexplanation for the G\nt\n's respectively. The following is obvious.\nProposition 5.1 The time complexity of the graphical EM algorithm per iteration is linear in the total size of support graphs, O(\nnum maxsize\nT ) in notation, which coincides with the\nspace complexity because the graphical EM algorithm runs on support graphs.\nThis is a rather general result, but when we compare the graphical EM algorithm with other EM algorithms, we must remember that the input to the graphical EM algorithm is support graphs (one for each observed atom) and our actual total learning time is\nOLDT time + (the number of iterations) O(\nnum maxsize\nT )\nwhere \\OLDT time\" denotes time to construct all support graphs for G. It is the sum of time for OLDT search and time for the topological sorting of the table atoms, but because the latter is part of the former order-wise, 36 we represent \\OLDT time\" by time for OLDT search. Also observe that the total size of support graphs does not exceed time for OLDT search for G order-wise.\nTo evaluate OLDT time for a speci c class of models such as HMMs, we need to know time for table operations. Observe that our OLDT search in this paper is special in the sense that table atoms are always ground when called and there is no resolution with solved goals. Accordingly a solution table is used only\nto check if a goal G already has an entry in the solution table, i.e. if it was called before, and\nto add a new searched t-explanation for G to the list of discovered t-explanations under G's entry.\nThe time complexity of these operations is equal to that of table access which depends\nboth on the program and on the implementation of the solution table.\n37\nWe rst suppose\nprograms are carefully written in such a way that the arguments of table atoms used as indecies for table access are integers. Actually all programs used in the subsequent complexity analysis (DB\nh\nin Subsection 4.7, DB\ng\nand DB\ng\n0\nin Subsection 5.3, DB\nG\nin Subsection 5.5)\nsatisfy or can satisfy this condition by replacing non-integer terms with appropriate integers. We also suppose that the solution table is implemented using an array so that table access can be done in O(1) time. 38\nIn what follows, we present a detailed analysis of the time complexity of the graphical EM algorithm applied to HMMs, PCFGs, pseudo PCSGs and Bayesian networks, assuming O(1) time access to the solution table. We remark by the way that their space complexity is just the total size of solution tables (support graphs)."}, {"heading": "5.2 HMMs", "text": "The standard EM algorithm for HMMs is the Baum-Welch algorithm (Rabiner, 1989; Rabiner & Juang, 1993). An example of HMM is shown in Figure 3 in Subsection 4.7. 39 Given T observations w 1 ; : : : ; w T of output string of length L, it computes in O(N 2 LT ) time in each iteration the forward probability t\nm\n(q) = P (o\nt 1 o t 2\no\nt m 1 ; q j ) and the backward\nprobability\nt m (q) = P (o t m o t\nm+1\no\nt L j q; ) for each state q 2 Q, time step m (1 m L)\nand a string w\nt\n= o\nt 1 o t 2\no\nt L (1 t T ), where Q is the set of states and N the number of\nstates. The factor N\n2\ncomes from the fact that every state has N possible destinations and\n36. Think of OLDT search for a top-goal G\nt\n. It searches for msw atoms and table atoms to create a so-\nlution table, while doing some auxiliary computations. Therefore its time complexity is never less than O(jthe number of msw atoms and table atoms in the support graph for G\nt\nj), which coincides with\nthe time we need to topologically sort table atoms in the solution table by depth- rst search from\n0\n= G\nt\n.\n37. Sagonas et al. (1994) and Ramakrishnan et al. (1995) discuss about the implementation of OLDT. 38. If arrays are not available, we may be able to use balanced trees, giving O(log n) access time where n\nis the number data in the solution table, or we may be able to use hashing, giving average O(1) time access under a certain condition (Cormen, Leiserson, & Rivest, 1990). 39. We treat here only \\state-emission HMMs\" which emit a symbol depending on the state. Another type,\n\\arc-emission HMMs\" in which the emitted symbol depends on the transition arc, is treated similarly.\nwe have to compute the forward and backward probability for every destination and every state. After computing all t\nm\n(q)'s and\nt m (q)'s, parameters are updated. So, the total\ncomputation time in each iteration of the Baum-Welch algorithm is estimated as O(N\n2\nLT )\n(Rabiner & Juang, 1993; Manning & Sch utze, 1999).\nTo compare this result with the graphical EM algorithm, we use the HMM program\nDB\nh\nin Figure 4 with appropriate modi cations to L, the length of a string, Q, the\nstate set, and declarations in F\nh\nfor the output alphabets. For a string w = o\n1\no\n2\no\nL\n,\nhmm(n,q,[o\nm\n; o\nm+1\n; : : : ; o\nL\n]) in DB\nh\nreads that the HMM is in state q 2 Q at time n and\nhas to output [o\nm\n,o\nm+1\n,...,o\nL\n] until it reaches the nal state. After declaring hmm=1 and\nhmm=3 as table predicate and translation (see Figure 5), we apply OLDT search to the goal\ntop hmm([o\n1\n,...,o\nL\n],Ans) w.r.t. the translated program to obtain all t-explanations\nfor hmm([o\n1\n,...,o\nL\n]). For a complexity argument however, the translated program and\nDB\nh\nare the same, so we talk in terms of DB\nh\nfor the sake of simplicity. In the search,\nwe x the search strategy to multi-stage depth- rst strategy (Tamaki & Sato, 1986). We assume that the solution table is accessible in O(1) time. 40 Since the length of the list in the third argument of hmm=3 decreases by one on each recursion, and there are only nitely many choices of the state transition and the output alphabet, the search terminates, leaving\nnitely many t-explanations in the solution table like Figure 6 that satisfy the acyclic sup-\nport condition respectively. Also the sampling execution of hmm(L) w.r.t. DB\nh\nis nothing\nbut a sequential decision process such that decisions made by msw atoms are exclusive, independent and generate a unique string, which means DB\nh\nsatis es the t-exclusiveness\ncondition, the independence condition and the uniqueness condition respectively. So, the graphical EM algorithm is applicable to the set of hierarchical systems of t-explanations for hmm(w t ) (1 t T ) produced by OLDT search for T observations w 1 ; : : : ; w T of output string. Put w t = o t\n1\no\nt 2\no\nt L . It follows from\nt DB\nh\n= fhmm(m,q,[o\nt m ,...,o t\nL\n]) j 1 m L+ 1; q 2 Qg [ fhmm([o\nt 1 ,...,o t\nL\n])g\ne\nDB\nh\n(hmm(m,q,[o\nt m ,...,o t\nL\n]))\n(1 m L)\n=\n(\nmsw(out(q),m,o\nm\n); msw(tr(q),m,q\n0\n);\nhmm(m+ 1,q\n0\n,[o\nt m+1 ,...,o t\nL\n])\nq\n0\n2 Q\n)\nthat for a top-goal hmm([o\nt 1 ,...,o t\nL\n]), there are at most O(NL) calling patterns of hmm=3\nand each call causes at most N calls to hmm=3, implying there occur O(NL N) = O(N\n2\nL)\ncalls to hmm=3. Since each call is computed once due to the tabling mechanism, we have\nnum\n= O(N\n2\nL). Also\nmaxsize\n= 3. Applying Proposition 5.1, we reach\nProposition 5.2 Suppose we have T strings of length L. Also suppose each table operation in OLDT search is done in O(1) time. OLDT time by DB\nh\nis O(N\n2\nLT ) and the graphical\nEM algorithm takes O(N\n2\nLT ) time per iteration where N is the number of states.\nO(N\n2\nLT ) is the time complexity of the Baum-Welch algorithm. So the graphical EM\nalgorithm runs as e ciently as the Baum-Welch algorithm.\n41\n40. O(1) is possible because in the translated program DB\nh\nin Section 4.7, we can identify a goal pattern of\nhmm( , , , , ) by the rst two arguments which are constants (integers).\n41. Besides, the Baum-Welch algorithm and the graphical EM algorithm whose input are support graphs\ngenerated by DB\nh\nupdate parameters to the same value if initial values are the same.\nBy the way, the Viterbi algorithm (Rabiner, 1989; Rabiner & Juang, 1993) provides for HMMs an e cient way of nding the most likely transition path for a given input/output string. A similar algorithm for parameterized logic programs that determines the most likely explanation for a given goal can be derived. It runs in time linear in the size of the support graph, thereby O(N 2 L) in the case of HMMs, the same complexity as the Viterbi algorithm (Sato & Kameya, 2000)."}, {"heading": "5.3 PCFGs", "text": "We now compare the graphical EM algorithm with the Inside-Outside algorithm (Baker, 1979; Lari & Young, 1990). The Inside-Outside algorithm is a well-known EM algorithm for PCFGs (Wetherell, 1980; Manning & Sch utze, 1999). 42 It takes a grammar in Chomsky normal form. Given N nonterminals, a production rule in the grammar takes the form i ! j; k (1 i; j; k N) (nonterminals are named by numbers from 1 to N and 1 is a starting symbol) or the form i! w where 1 i N and w is a terminal. In each iteration, it computes the inside probability and the outside probability of every partial parse tree of the given sentence to update parameters for these production rules. Time complexity is measured by time per iteration, and is described by N , the number of nonterminals, and L, the number of terminals in a sentence. It is O(N 3 L 3 T ) for T observed sentences (Lari & Young, 1990).\nTo compare the graphical EM algorithm with the Inside-Outside algorithm, we start\nfrom a propositional program DB\ng\n= F\ng\n[ R\ng\nbelow representing the largest grammar\ncontaining all possible rules i ! j; k in N nonterminals where nonterminal 1 is a starting symbol, i.e. sentence.\nDB\ng\nis an arti cial parsing program whose sole purpose is to measure the size of an\nOLDT tree\n43\ncreated by the OLDT interpreter when it parses a sentence w\n1\nw\n2\nw\nL\n. So\n42. A PCFG (probabilistic context free grammar) is a backbone CFG with probabilities (parameters) as-\nsigned to each production rule. For a nonterminal A having n production rules fA!\ni\nj 1 i ng, a\nprobability p\ni\nis assigned to A!\ni\n(1 i n) where\nP\nn i=1 p i = 1. The probability of a sentence s is\nthe sum of probabilities of each (leftmost) derivation of s. The latter is the product of probabilities of rules used in the derivation.\n43. To be more precise, an OLDT structure, but in this case, it is a tree because DB\ng\ncontains only constants\n(Datalog program) and there never occurs the need of creating a new root node.\nthe input sentence w\n1\nw\n2\nw\nL\nis embedded in the program separately as msw(i,d,w\nd+1\n)\n(0 d L 1) in the second clauses of R\ng\n(this treatment does not a ect the complexity ar-\ngument). q(i,d\n0\n,d\n1\n) reads that the i-th nonterminal spans from position d\n0\nto position d\n1\n,\ni.e. the substring w\nd\n0\n+1\nw\nd\n1\n. The rst clauses q(i,d\n0\n,d\n2\n) :- msw( , , ), q(j,d\n0\n,d\n1\n),\nq(k,d\n1\n,d\n2\n) are supposed to be textually ordered according to the lexicographic order for\ntuples hi; j; k; d\n0\n; d\n2\n; d\n1\ni. As a parser, the top-goal is set to q(1,0,L).\n44\nIt asks the\nparser to parse the whole sentence w\n1\nw\n2\nw\nL\nas the syntactic category \\1\" (sentence).\nWe make an exhaustive search for this query by OLDT search.\n45\nAs before, the multi-\nstage depth- rst search strategy and O(1) time access to the solution table are assumed. Then the time complexity of OLDT search is measured by the number of nodes in the\nOLDT tree. Let T\n(k) d be the OLDT tree for q(k,d,L). Figure 10 illustrates T (1) d for d\n(0 d L 3) where msw atoms are omitted. As can be seen, the tree has many similar subtrees, so we put them together (see Note in Figure 10). Due to the depth- rst strategy,\nT\n(1) d has a recursive structure and contains T (1) d+1 as a subtree. Nodes whose leftmost atom is not underlined are solution nodes, i.e. they solve their leftmost atoms for the rst time in the entire refutation process. The underlined atoms are already computed in the subtrees to their left. 46 They only check the solution table if there are their entries (= already"}, {"heading": "44. L here is not a Prolog variable but a constant denoting the sentence length.", "text": ""}, {"heading": "45. q is a table predicate.", "text": ""}, {"heading": "46. It can be inductively proved that T", "text": "(1)\nd+1\ncontains every computed q(i,d\n0\n,d\n00\n) (0 d L 3; d+1 d\n0\n<\nd\n00\nL; 1 i N; d\n00\nd\n0\nL d 2).\ncomputed) in O(1) time. Since all clauses are ground, such execution only generates a single child node.\nWe enumerate h\n(1) d , the number of nodes in T (1) d but not in T (k) d+1 (1 k N). From\nFigure 10, we see h\n(1) d = O(N 3 (L d) 2 ). 47 Let h (k) d (2 k N) be the number of nodes in\nT\n(k) d+1 not contained in T (1) d+1 . It is estimated as O(N 2 (L d 2)). Consequently, the number\nof nodes that are newly created in T\n(1) d is h (1) d +\nP\nN k=2 h\n(k) d = O(N 3 (L d) 2 ). As a result,\ntotal time for OLDT search is computed as\nP\nL 3 d=0 h d = O(N 3 L 3 ) 48 which is also the size of\nthe support graph.\nWe now consider a non-propositional parsing program DB\ng\n0 = F\ng\n0 [ R\ng\n0 in Figure 11\nwhose ground instances constitute the propositional program DB\ng\n. DB\ng\n0\nis a probabilistic\nvariant of DCG program (Pereira & Warren, 1980) in which q'/1, q'/6 and between/3 are declared as table predicate. Semantically DB\n0\nspeci es a probability distribution over the\nThe top-goal to parse a sentence S = [w\n1\n; : : : ; w\nL\n] is q'([w\n1\n; : : : ; w\nL\n]). It invokes\nq'(s\n1\n,0,D,0, ,[w\n1\n,: : :,w\nL\n]-[]) after measuring the length D of an input sentence S by\ncalling length=2.\n49 50\nIn general, q'(i,d\n0\n,d\n2\n,c\n0\n,c\n2\n,l\n0\n-l\n2\n) works identically to q(i,d\n0\n,d\n2\n)\nbut three arguments, c\n0\n, c\n2\nand l\n0\n-l\n2\n, are added. c\n0\nsupplies a unique trial-id for msws to be\nused in the body, c\n2\nthe latest trial-id in the current computation, and l\n0\n-l\n2\na D-list holding\na substring between d\n0\nand d\n2\n. Since the added arguments do not a ect the shape of the\n47. We here focus on the subtree T\n0 d . j, i 0 and j 0 range from 1 toN , and f(e; e 0 ) j d + 2 e 0 < e L 1g =\nO((L d)\n2\n). Hence, the number of nodes in T\n0 d is O(N 3 (L d) 2 ). The number of nodes in T\n(1) d but\nneither in T\n(1) d+1 nor in T 0 d is negligible, therefore h (1) d = O(N 3 (L d) 2 )."}, {"heading": "48. The number of nodes in T", "text": "(1) L 1 and T (1) L 2 is negligible.\n49. To make the program as simple as possible, we assume that an integer n is represented by a ground term\ns\nn\ndef =\n(n)\nz }| { s( s (0) ). We also assume that when D0 and D2 are ground, the goal between(D0, D1, D2)\nreturns an integer D1 between them in time proportional to jD1 D0j.\n50. We omit an obvious program for length(l,s\nn\n) which computes the length s\nn\nof a list l in O(jlj) time.\nsearch tree in Figure 10 and the extra computation caused by length=2 is O(L) and the one by the insertion of between(D0,D1,D2) is O(NL 3 ) respectively, 51 OLDT time remains O(N 3 L 3 ), and hence so is the size of the support graph.\nTo apply the graphical EM algorithm correctly, we need to con rm the ve conditions on its applicability. It is rather apparent however that the OLDT refutation of any topgoal of the form q'([w\n1\n,: : :,w\nL\n]) w.r.t. DB\ng\n0\nterminates, and leaves a support graph\nsatisfying the nite support condition and the acyclic support condition. The t-exclusiveness condition and the independent condition also hold because the refutation process faithfully simulates the leftmost stochastic derivation of w\n1\nw\nL\nin which the choice of a production\nrule made by msw(s\ni\n,s\nc\n,[s\nj\n,s\nk\n]) is exclusive and independent (trial-ids are di erent on\ndi erent choices).\nWhat remains is the uniqueness condition. To con rm it, let us consider another pro-\ngram DB\ng\n00\n, a modi cation of DB\ng\n0\nsuch that the rst goal length(S,D) in the body of the\nrst clause and the rst goal between(D0,D1,D2) in the second clause of R\ng\n0\nare moved to\nthe last position in their bodies respectively. DB\ng\n00\nand DB\ng\n0\nare logically equivalent, and\nsemantically equivalent as well from the viewpoint of distribution semantics. Then think of the sampling execution by the OLDT interpreter of a top-goal q'(S) w.r.t. DB\ng\n00\nwhere\nS is a variable, using the multi-stage depth- rst search strategy. It is easy to see rst that the execution never fails, and second that when the OLDT refutation terminates, a sentence [w\n1\n; : : : ; w\nL\n] is returned in S, and third that conversely, the set of msw atoms resolved upon\nin the refutation uniquely determines the output sentence [w\n1\n; : : : ; w\nL\n].\n52\nHence, if the\nsampling execution is guaranteed to always terminate, every sampling from P\nF\ng\n00\n(= P\nF\ng\n0\n)\nuniquely generates a sentence, an observable atom, so the uniqueness condition is satis ed by DB\ng\n00\n, and hence by DB\ng\n0\n.\nThen when is the sampling execution guaranteed to always terminate? In other words, when does the grammar only generate nite sentences? Giving a general answer seems di cult, but it is known that if the parameter values in a PCFG are obtained by learning from nite sentences, the stochastic derivation by the PCFG terminates with probability one (Chi & Geman, 1998). In summary, assuming appropriate parameter values, we can say that the parameterized logic program DB\ng\n0 for the largest PCFG with N nonterminal\nsymbols satis es all applicability conditions, and the OLDT time for a sentence of length L is O(N 3 L 3 ) 53 and this is also the size of the support graph. From Proposition 5.1, we conclude\nProposition 5.3 Let DB be a parameterized logic program representing a PCFG with N nonterminals in the form of DB 0\ng\nin Figure 11, and G = G\n1\n;G\n2\n; : : : ;G\nT\nbe the sampled atoms\nrepresenting sentences of length L. We suppose each table operation in OLDT search is done in O(1) time. Then OLDT search for G and one iteration in learn-gEM are respectively done in O(N 3 L 3 T ) time.\n51. between(D0,D1,D2) is called O(N(L d)\n2\n) times in T\n(1) d . So it is called\nP\nL 3 d=0 O(N(L d) 2 ) = O(NL 3 )\ntimes in T\n(1) 0 .\n52. Because the trial-ids used in the refutation record which rule is used at what step in the derivation of\nw\n1\nw\nL\n.\n53. In DB\ng\n0 , we represent integers by ground terms made out of 0 and s( ) to keep the program short. If\nwe use integers instead of ground terms however, the rst three arguments of q'( , , , , , ) are enough to check whether the goal is previously called or not, and this check can be done in O(1) time.\nO(N\n3\nL\n3\nT ) is also the time complexity of the Inside-Outside algorithm per iteration\n(Lari & Young, 1990), hence our algorithm is as e cient as the Inside-Outside algorithm."}, {"heading": "5.4 Pseudo PCSGs", "text": "PCFGs can be improved by making choices context-sensitive, and one of such attempts is pseudo PCSGs (pseudo probabilistic context sensitive grammars) in which a rule is chosen probabilistically depending on both the nonterminal to be expanded and its parent nonterminal (Charniak & Carroll, 1994).\nA pseudo PCSG is easily programmed. We add one extra-argument, N, representing the parent node, to the predicate q'(I,D0,D2,C0,C2,L0-L2) in Figure 11 and replace msw(I,C0,[J,K])with msw([N,I],C0,[J,K]). Since the (leftmost) derivation of a sentence from a pseudo PCSG is still a sequential decision process described by the modi ed program, the graphical EM algorithm applied to the support graphs generated from the modi ed program and observed sentences correctly performs the ML estimation of parameters in the pseudo PCSG.\nA pseudo PCSG is thought to be a PCFG with rules of the form [n; i] ! [i; j][i; k] (1 n; i; j; k N) where n is the parent nonterminal of i, so the arguments in the previous subsection are carried over with minor changes. We therefore have (details omitted)\nProposition 5.4 Let DB be a parameterized logic program for a pseudo PCSG with N nonterminals as shown above, and G = G\n1\n; G\n2\n; : : : ; G\nT\nthe observed atoms representing\nsampled sentences of length L. Suppose each table operation in OLDT search can be done in O(1) time. Then OLDT search for G and each iteration in learn-gEM is completed in O(N 4 L 3 T ) time."}, {"heading": "5.5 Bayesian Networks", "text": "A relationship between cause C and its e ect E is often probabilistic such as the one between diseases and symptoms, and as such it is mathematically captured as the conditional probability P (E = e j C = c) of e ect e given the cause c. What we wish to know however is the inverse, i.e. the probability of a candidate cause c given evidence e, i.e. P (C = c j E = e) which is calculated by Bayes' theorem as P (E = e j C = c)P (C = c)= P\nc\n0\nP (E = e j C =\nc\n0\n)P (C = c\n0\n). Bayesian networks are a representational/computational framework that ts\nbest this type of probabilistic inference (Pearl, 1988; Castillo et al., 1997).\nA Bayesian network is a graphical representation of a joint distribution P (X\n1\n= x\n1\n; : : : ;\nX\nN\n= x\nN\n) of nitely many random variables X\n1\n; : : : ; X\nN\n. The graph is a dag (directed\nacyclic graph) such as ones in Figure 12, and each node is a random variable.\n54\nIn the graph, a conditional probability table (CPT) representing P (X\ni\n= x\ni\nj\ni\n= u\ni\n)\n(1 i N) is associated with each node X\ni\nwhere\ni\nrepresents X\ni\n's parent nodes and u\ni\ntheir values. When X\ni\nhas no parent, i.e. a topmost node in the graph, the table is just a\nmarginal distribution P (X\ni\n= x\ni\n). The whole joint distribution is de ned as the product of\n54. We only deal with discrete cases.\nthese conditional distributions:\nP (X\n1\n= x\n1\n; : : : ; X\nN\n= x\nN\n)\n55\n=\nN\nY\ni=1\nP (X\ni\n= x\ni\nj\ni\n= u\ni\n): (21)\nThus the graph G\n1\nin Figure 12 de nes\nP\nG\n1\n(a; b; c; d; e; f) = P\nG\n1\n(a)P\nG\n1\n(b)P\nG\n1\n(c j a)P\nG\n1\n(d j a; b)P\nG\n1\n(e j d)P\nG\n1\n(f j d)\nwhere a, b, c, d, e and f are values of corresponding random variables A, B, C, D, E and F , respectively. 56 As mentioned before, one of the basic tasks of Bayesian networks is to compute marginal probabilities. For example, the marginal distribution P\nG\n1\n(c; d) is\ncomputed either by (22) or (23) below.\nP\nG\n1\n(c; d) =\nX\na;b;e;f\nP\nG\n1\n(a)P\nG\n1\n(b)P\nG\n1\n(c ja)P\nG\n1\n(d j a; b)P\nG\n1\n(e j d)P (f j d) (22)\n=\n0\n@\nX\na;b\nP\nG\n1\n(a)P\nG\n1\n(b)P\nG\n1\n(c ja)P\nG\n1\n(d j a; b)\n1\nA\n0\n@\nX\ne;f\nP\nG\n1\n(e jd)P\nG\n1\n(f jd)\n1\nA\n(23)\n(23) is clearly more e cient than (22). Observe that if the graph were like G\n2\nin\nFigure 12, there would be no way to factorize computations like (23) but to use (22) requiring exponentially many operations. The problem is that computing marginal probabilities is NP-hard in general, and factorization such as (23) is assured only when the graph is singly connected like G\n1\n, i.e. has no loop when viewed as an undirected graph. In such case, the\ncomputation is possible in O(jV j) time where V is the set of vertices in the graph (Pearl, 1988). Otherwise, the graph is called multiply-connected, and might need exponential time to compute marginal probabilities. In the sequel, we show the following.\nFor any discrete Bayesian network G de ning a distribution P\nG\n(x\n1\n; : : : ; x\nN\n), there is a\nparameterized logic programDB\nG\nfor a predicate bn( ) such that P\nDB\nG\n(bn(x\n1\n,: : :,x\nN\n))\n= P\nG\n(x\n1\n; : : : ; x\nN\n).\n55. Thanks to the acyclicity of the graph, without losing generality, we may assume that if X\ni\nis an ancestor\nnode of X\nj\n, then i < j holds.\n56. For notational simplicity, we shall omit random variables when no confusion arises.\nF\nG\nis comprised of msw atoms of the form msw(par(i,u\ni\n),once,x\ni\n) whose probability is\nexactly the conditional probability P\nG\n(X\ni\n= x\ni\nj\ni\n= u\ni\n). When X\ni\nhas no parents, u\ni\nis\nthe empty list []. R\nG\nis a singleton, containing only one clause whose body is a conjunction\nof msw atoms which corresponds to the product of conditional probabilities. Note that we intentionally identify random variables X\n1\n; : : : ; X\nN\nwith logical variables X\n1\n; : : : ; X\nN\nfor\nconvenience.\nProposition 5.5 DB\nG\ndenotes the same distributions as G.\n(Proof) Let hx\n1\n; : : : ; x\nN\ni be a realization of the random vector hX\n1\n; : : : ;X\nN\ni. It holds by\nconstruction that\nP\nDB\nG\n(bn(x\n1\n,: : :,x\nN\n)) =\nN\nY\nh=1\nP\nmsw\n(msw(par(i,u\ni\n),once,x\ni\n))\n=\nN\nY\nh=1\nP\nG\n(X\ni\n= x\ni\nj\ni\n= u\ni\n)\n= P\nG\n(x\n1\n; : : : ; x\nN\n): Q:E:D:\nIn the case of G\n1\nin Figure 12, the program becomes\n57\nbn(A,B,C,D,E,F) :- msw(par('A',[]),once,A), msw(par('B',[]),once,B),\nmsw(par('C',[A]),once,C), msw(par('D',[A,B]),once,D), msw(par('E',[D]),once,E), msw(par('F',[D]),once,F).\n57.\n0\nA\n0\n;\n0\nB\n0\n; : : : are Prolog constants used in place of integers.\nand the left-to-right sampling execution gives a sample realization of the random vector h A;B; C;D; E;F i. A marginal distribution is computed from bn(x\n1\n,: : :,x\nN\n) by adding a new\nclause to DB\nG\n. For example, to compute P\nG\n1\n(c; d), we add bn(C,D):- bn(A,B,C,D,E,F)\nto DB\nG\n1\n(let the result be DB\n0 G\n1\n) and then compute P\nDB\n0 G\n1\n(bn(c,d)) which is equal to\nP\nG\n1\n(c; d) because\nP\nDB\n0 G\n1\n(bn(c,d)) = P\nDB\nG\n1\n(9 a; b; e; f bn(a,b,c,d,e,f))\n=\nX\na;b;e;f\nP\nDB\nG\n1\n(bn(a,b,c,d,e,f))\n= P\nG\n1\n(c; d):\nRegrettably this computation corresponds to (22), not to the factorization (23). E cient probability computation using factorization is made possible by carrying out summations in a proper order.\nWe next sketch by an example how to carry out speci ed summations in a speci ed order by introducing new clauses. Suppose we have a joint distribution P (x; y; z; w) =\n1\n(x; y)\n2\n(y; z; w)\n3\n(x; z; w) such that\n1\n(x; y),\n2\n(y; z;w) and\n3\n(x; z;w) are respectively\ncomputed by atoms p\n1\n(X,Y), p\n2\n(Y,Z,W) and p\n3\n(X,Z,W). Suppose also that we hope to\ncompute the sum\nP (x) =\nX\ny\n1\n(x; y)\nX\nz;w\n2\n(y; z;w)\n3\n(x; z; w)\n!\nin which we rst eliminate z;w and then y. Corresponding to each elimination, we introduce two new predicates, q(X,Y) to compute\n4\n(x; y) =\nP\nz;w\n2\n(y; z; w)\n3\n(x; z; w) and p(X) to\ncompute P (x) =\nP\ny\n1\n(x; y)\n4\n(x; y) as follows.\np(X) :- p\n1\n(X,Y), q(X,Y).\nq(X,Y) :- p\n2\n(Y,Z,W), p\n3\n(X,Z,W).\nNote that the clause body of q=2 contains Z and W as (existentially quanti ed) local variables and the clause head q(X,Y) contains variables shared with other atoms. In view of the correspondence between P and 9, it is easy to con rm that this program realizes the required computation. It is also easy to see by generalizing this example, though we do not prove here, that there exists a parameterized logic program that carries out the given summations in the given order for an arbitrary Bayesian network, in particular we are able to simulate VE (variable elimination, Zhang & Poole, 1996; D'Ambrosio, 1999) in our approach.\nE cient computation of marginal distributions is not always possible but there is a well-known class of Bayesian networks, singly connected Bayesian networks, for which there exists an e cient algorithm to compute marginal distributions by message passing (Pearl, 1988; Castillo et al., 1997). We here show that when the graph is singly connected, we can construct an e cient tabled Bayesian network program DB\nG\nassigning a table predicate\nto each node. To avoid complications, we explain the construction procedure informally and concentrate on the case where we have only one interested variable. Let G be a singly\nconnected graph. First we pick up a node U whose probability P\nG\n(u) is what we seek. We\nconstruct a tree G with the root node U from G, by letting other nodes dangling from U . Figure 14 shows how G\n1\nis transformed to a tree when we select node B as the root node.\nTransformed graph G \u03c4 1\nA\nC\nE F\nD\nB\n1\n2\nU\n3\n. Then we visit X 's children, V\n1\nand V\n2\n. For a topmost node U\n3\nin the original graph,\nwe add clause (26).\ntbn(U\n1\n) :- msw(par('U\n1\n',[]),once,U\n1\n), call U\n1\nX(U\n1\n). (24)\ncall U\n1\nX(U\n1\n) :- val U\n2\n(U\n2\n), call X U\n2\n(U\n2\n),\nval U\n3\n(U\n3\n), call X U\n3\n(U\n3\n),\nmsw(par('X',[U\n1\n,U\n2\n,U\n3\n]),once,X),\ncall X V\n1\n(X), call X V\n2\n(X). (25)\ncall X U\n3\n(U\n3\n) :- msw(par('U\n3\n',[]),once,U\n3\n). (26)\nLet DB\nG\nbe the nal program containing clauses like (24), (25) and (26). Apparently\nDB\nG\ncan be constructed in time linear in the number of nodes in the network. Also\nnote that successive unfolding (Tamaki & Sato, 1984) of atoms of the form call ...( ) in the clause bodies that starts from (24) yields a program DB 0\nG\nsimilar to the one in\nFigure 13 which contains msw atoms but no call ...( )'s. As DB\nG\nand DB\n0 G de ne the\nsame distribution,\n58\nit can be proved from Proposition 5.5 that P\nG\n(u) = P\nDB\n0 G (bn(u)) =\nP\nDB\nG\n(tbn(u)) holds (details omitted). By the way, in Figure 15 we assume the construction\nstarts from the topmost node U\n1\nwhere the evidence u is given, but this is not necessary.\nSuppose we change to start from the inner node X. In that case, we replace clause (24) with call X U\n1\n(U\n1\n) :- msw(par('U\n1\n',[]),once,U\n1\n) just like (26). At the same time we\nreplace the head of clause (25) with tbn() and add a goal call X U\n1\n(u) to the body\nand so on. For the changed program DB\n00\nG\n, it is rather straightforward to prove that\nP\nDB\n00\nG\n(tbn()) = P\nG\n(u) holds. It is true that the construction of the tabled program\nDB\nG\nshown here is very crude and there is a lot of room for optimization, but it su ces\nto show that a parameterized logic program for a singly connected Bayesian network runs in O(jV j) time where V is the set of nodes.\nTo estimate time complexity of OLDT search w.r.t. DB\nG\n, we declare tbn and every\npredicate of the form call ...( ) as table predicate and verify the ve conditions on the applicability of the graphical EM algorithm (details omitted). We now estimate the time complexity of OLDT search for the goal tbn(u) w.r.t.DB\nG\n.\n59\nWe notice that calls occur\naccording to the pre-order scan (parents { the node { children) of the tree G , and calls to call Y X( ) occur val(Y ) times. Each call to call Y X( ) invokes calls to the rest of nodes, X's parents and X 's children in the graph G except the caller node, with di rent set of variable instantiations, but from the second call on, every call only refers to solutions stored in the solution table in O(1) time. Thus, the number of added computation steps in"}, {"heading": "58. Since distribution semantics is based on the least model semantics, and because unfold/fold transforma-", "text": "tion (Tamaki & Sato, 1984) preserves the least Herbrand model of the transformed program, unfold/fold transformation applied to parameterized logic programs preserves the denotation of the transformed program.\n59. DB\nG\nis further transformed for the OLDT interpreter to collect msw atoms like the case of the HMM\nprogram.\nOLDT search by X is bounded from above, by constant O(val(U1)val(U2)val(U3)val(X)) in the case of Figure 15. As a result OLDT time is proportional to the number of nodes in the original graph G (and so is the size of the support graph) provided that the number of edges connecting to a node, and that of values of a random variable are bounded from above. So we have\nProposition 5.6 Let G be a singly connected Bayesian network de ning distribution P\nG\n,"}, {"heading": "V the set of nodes, and DB", "text": "G\nthe tabled program derived as above. Suppose the number of\nedges connecting to a node, and that of values of a random variable are bounded from above by some constant. Also suppose table access can be done in O(1) time. Then, OLDT time for computing P\nG\n(u) for an observed value u of a random variable U by means of DB\nG\nis\nO(jV j) and so is time per iteration required by the graphical EM algorithm. If there are T observations, time complexity is O(jV jT ).\nO(jV j) is the time complexity required to compute a marignal distribution for a singly connected Bayesian network by a standard algorithm (Pearl, 1988; Castillo et al., 1997), and also is that of the EM algorithm using it. We therefore conclude that the graphical EM algorithm is as e cient as a specialzed EM algorithm for singly connected Bayesian networks. 60 We must also quickly add that the graphical EM algorithm is applicable to arbitrary Bayesian networks, 61 and what Proposition 5.6 says is that an explosion of the support graph can be avoided by appropriate programming in the case of singly connected Bayesian networks.\nTo summarize, the graphical EM algorithm, a single generic EM algorithm, is proved to have the same time complexity as specialized EM algorithms, i.e. the Baum-Welch algorithm for HMMs, the Inside-Outside algorithm for PCFGs, and the one for singly connected Bayesian networks that have been developed independently in each research eld.\nTable 1 summarizes the time complexity of EM learning using OLDT search and the graphical EM algorithm in the case of one observation. In the rst column, \\sc-BNs\" represents singly connected Bayesian networks. The second column shows a program to use. DB\nh\nis an HMM proram in Subsection 4.7, DB\ng\n0\na PCFG program in Subsection 5.3 and\nDB\nG\na transformed Bayesian network program in Subsection 5.5, respectively. OLDT time\nin the third column is time for OLDT search to complete the search of all t-explanations. gEM in the fourth column is time in one iteration taken by the graphical EM algorithm to update parameters. We use N , M , L and V respectively for the number of states in an HMM, the number of nonterminals in a PCFG, the length of an input string and the number of nodes in a Bayesian network. The last column is a standard (specialized) EM algorithm for each model."}, {"heading": "60. When a marginal distribution of P", "text": "G\nfor more than one variable is required, we can construct a similar\ntabled program that computes marginal probabilities still in O(jV j) time by adding extra-arguments that convey other evidence or by embedding other evidnece in the program.\n61. We check the ve conditions with DB\nG\nin Figure 13. The uniqueness condition is obvious as sampling\nalways uniquely generates a sampled value for each random variable. The nite support condition is satis ed because there are only a nite number of random variables and their values. The acyclic support condition is immediate because of the acyclicity of Bayesian networks. The t-exclusiveness condition and the independent condition are easy to verify."}, {"heading": "5.6 Modeling Language PRISM", "text": "We have been developing a symbolic-statistical modeling laguage PRISM since 1995 (URL = http://mi.cs.titech.ac.jp/prism/) as an implementation of distribution semantics (Sato, 1995; Sato & Kameya, 1997; Sato, 1998). The language is intented for modeling complex symbolic-statistical phenomena such as discourse interpretation in natural language processing and gene inheritance interacting with social rules. As a programming language, it looks like an extension of Prolog with new built-in predicates including the msw predicate and other special predicates for manipulating msw atoms and their parameters.\nA PRISM program is comprised of three parts, one for directives, one for modeling and one for utilities. The directive part contains declarations such as values, telling the system what msw atoms will be used in the execution. The modeling part is a set of non-unit de nite clauses that de ne the distribution (denotation) of the program by using msw atoms. The last part, the utility part, is an arbitary Prolog program which refers to predicates de ned in the modeling part. We can use in the utility part learn built-in predicate to carry out EM learning from observed atoms.\nPRISM provides three modes of execution. The sampling execution correponds to a random sampling drawn from the distribution de ned by the modeling part. The second one computes the probability of a given atom. The third one returns the support set for a given goal. These execution modes are available through built-in predicates.\nWe must report however that while the implementation of the graphical EM algorithm with a simpi ed OLDT search mechanism has been under way, it is not completed yet. So currently, only Prolog search and learn-naive(DB;G) in Section 4 are available for EM learning though we realized, partially, structrure sharing of explanations in the implemention of learn-naive(DB;G). Putting computational e ciecy aside however, there is no problem in expressing and learning HMMs, PCFGs, pseudo PCSGs, Bayesian networks and other probailistic models by the current version. The learning experiments in the next section used a parser as a substitute for the OLDT interpreter, and the independently implemented graphical EM algorithm."}, {"heading": "6. Learning Experiments", "text": "After complexity analysis of the graphical EM algorithm for popular symbolic-probabilistic models in the previous section, we look at an actual behavior of the graphical EM algorithm with real data in this section. We conducted learning experiments with PCFGs using two\ncorpora which have contrasting characters, and compared the performance of the graphical EM algorithm against that of the Inside-Outside algorithm in terms of time per iteration (= time for updating parameters). The results indicate that the graphical EM algorithm can outperform the Inside-Outside algorithm by orders of magnigude. Detalis are reported by Sato, Kameya, Abe, and Shirai (2001). Before proceeding, we review the Inside-Outside algorithm for completeness."}, {"heading": "6.1 The Inside-Outside Algorithm", "text": "The Inside-Outside algorithm was proposed by Baker (1979) as a generalization of the Baum-Welch algorithm to PCFGs. The algorithm is designed to estimate parameters for a CFG grammar in Chomsky normal form containing rules expressed by numbers like i! j; k (1 i; j; k N for N nonterminals, where 1 is a starting symbol). Suppose an input sentence w\n1\n; : : : ; w\nL\nis given. In each iteration, it rst computes in a bottom up manner\ninside probabilities e(s; t; i) = P (i ) w\ns\n; : : : ; w\nt\n) and then computes outside probabilities\nf(s; t; i) = P (S ) w\n1\n; : : : ; w\ns 1\ni w\nt+1\n; : : : ; w\nL\n) in a top-down manner for every s, t and\ni (1 s t L; 1 i N). After computing both probabilities, parameters are updated by using them, and this process iterates until some predetermined criterion such as a convergence of the likelihood of the input sentence is achieved. Although Baker did not give any analysis of the Inside-Outside algorithm, Lari and Young (1990) showed that it takes O(N 3 L 3 ) time in one iteration and La erty (1993) proved that it is the EM algorithm.\nWhile it is true that the Inside-Outside algorithm has been recognized as a standard EM algortihm for training PCFGs, it is notoriously slow. Although there is not much literature explicitly stating time required by the Inside-Outside algorithm (Carroll & Rooth, 1998; Beil, Carroll, Prescher, Riezler, & Rooth, 1999), Beil et al. (1999) reported for example that when they trained a PCFG with 5,508 rules for a corpus of 450,526 German subordinate clauses whose average ambiguity is 9,202 trees/clause using four machines (167MHz Sun UltraSPARC 2 and 296MHz Sun UltraSPARC-II 2), it took 2.5 hours to complete one iteration. We discuss later why the Inside-Outside algorithm is slow."}, {"heading": "6.2 Learning Experiments Using Two Corpora", "text": "We report here parameter learning of existing PCFGs using two corpora of moderate size and compare the graphical EM algorithm against the Inside-Outside algorithm in terms of time per iteration. As mentioned before, support graphs, input to the garphical EM algorithm, were generated by a parser, i.e. MSLR parser. 62 All measurements were made on a 296MHz Sun UltraSPARC-II with 2GB memory under Solaris 2.6 and the threshold for an increase of the log likelihood of input sentences was set to 10 6 as a stopping criterion for the EM algorithms.\nIn the experiments, we used ATR corpus and EDR corpus (each converted to a POS (part of speech)-tagged corpus). They are similar in size (about 10,000) but contrasting in their characters, sentence length and ambiguity of their grammars. The rst experiment employed ATR corpus which is a Japanese-English corpus (we used only the Japanese part) developed by ATR (Uratani, Takezawa, Matsuo, & Morita, 1994). It contains 10,995 short"}, {"heading": "62. MSLR parser is a Tomita (Generalized LR) parser developed by Tanaka-Tokunaga Laboratory in Tokyo", "text": "Institute of Technology (Tanaka, Takezawa, & Etoh, 1997).\nconversational sentences, whose minimum length, average length and maximum length are respectively 2, 9.97 and 49. As a skeleton of PCFG, we employed a context free grammar G\natr\ncomprising 860 rules (172 nonterminals and 441 terminals) manually developed for\nATR corpus (Tanaka et al., 1997) which yields 958 parses/sentence.\nBecause the Inside-Outside algorithm only accepts a CFG in Chomsky normal form, we\nconverted G\natr\ninto Chomsky normal form G\natr\n. G\natr\ncontains 2,105 rules (196 nonter-\nminals and 441 terminals). We then divided the corpus into subgroups of similar length like (L = 1; 2); (L = 3; 4); : : : ; (L = 25; 26), each containing randomly chosen 100 sentences. After these preparations, we compare at each length the graphical EM algorithm applied to G\natr\nand G\natr\nagainst the Inside-Outside algorithm applied to G\natr\nin terms of time per\niteration by running them until convergence.\nCurves in Figure 16 show the learning results where an x-axis is the length L of an input sentence and a y-axis is average time taken by the EM algorithm in one iteration to update all parameters contained in the support graphs generated from the chosen 100 sentences (other parameters in the grammar do not change). In the left graph, the Inside-Outside algorithm plots a cubic curve labeled \\I-O\". We omitted a curve drawn by the graphical EM algorithm as it drew the x-axis. The middle graph magni es the left graph. The curve labeled \\gEM (original)\" is plotted by the graphical EM algorithm applied to the original grammar G\natr\nwhereas the one labeled \\gEM (Chomsky NF)\" used G\natr\n. At length 10, the\naverage sentence length, it is measured that whichever grammar is employed, the graphical EM algorithm runs several hundreds times faster (845 times faster in the case of G\natr\nand 720 times faster in the case of G\natr\n) than the Inside-Outside algorithm per iteration.\nThe right graph shows (almost) linear dependency of updating time by the graphical EM algorithm within the measuared sentence length.\nAlthough some di erence is anticipated in their learning speed, the speed gap between the Inside-Outside algorithm and the graphical EM algorithm is unexpectedly large. The most conceivable reason is that ATR corpus only contains short sentences and G\natr\nis not\nmuch ambiguous so that parse trees are sparse and generated support graphs are small, which a ects favorably the perforamnce of the graphical EM algorithm.\nWe therefore conducted the same experiment with another corpus which contains much longer sentences using a more ambiguous grammar that generates dense parse trees. We used EDR Japanese corpus (Japan EDR, 1995) containing 220,000 Japanese news article sentences. It is however under the process of re-annotation, and only part of it (randomly sampled 9,900 sentences) has recently been made available as a labeled corpus. Compared with ATR corpus, sentences are much longer (the average length of 9,900 sentences is 20, the minimum length 5, the maximum length 63) and a CFG grammar G\nedr\n(2,687 rules,\nconverted to Chomsky normal form grammar G\nedr\ncontaining 12,798 rules) developed for\nit is very ambiguous (to keep a coverage rate), having 3:0 10\n8\nparses/sentence at length\n20 and 6:7 10\n19\nparses/sentence at length 38.\nFigure 17 shows the obtained curves from the experiments with EDR corpus (the graph-\nical EM algorithm applied to G\nedr\nvs. the Inside-Outside algorithm applied to G\nedr\n) under\nthe same condition as ATR corpus, i.e. plotting average time per iteration to process 100 sentences of the designated length, except that the plotted time for the Inside-Outside algorithm is the average of 20 iterations whereas that for the graphical EM algorithm is the average of 100 iterations. As is clear from the middle graph, this time again, the graphical EM algorithm runs orders of magnitude faster than the Inside-Outside algorithm. At average sentence length 20, the former takes 0.255 second whereas the latter takes 339 seconds, giving a speed ratio of 1,300 to 1. At sentence length 38, the former takes 2.541 seconds but the latter takes 4,774 seconds, giving a speed ratio of 1,878 to 1. Thus the speed ratio even widens compared to ATR corpus. This can be explained by the mixed e ects of O(L 3 ), time complexity of the Inside-Outside algorithm, and a moderate increase in the total size of support graphs w.r.t. L. Notice that the right graph shows how the total size of support graphs grows with sentence length L as time per iteration by the graphical EM algorithm is linear in the total size of support graphs.\nSince we implemented the Inside-Outside algorithm faithfully to Baker (1979), Lari and Young (1990), there is much room for improvement. Actually Kita gave a re ned InsideOutside algorithm (Kita, 1999). There is also an implementation by Mark Johnson of the Inside-Outside algorithm down-loadable from http://www.cog.brown.edu/%7Emj/. The use of such implementations may lead to di erent conclusions. We therefore conducted learning experiments with the entire ATR corpus using these two implementations and measured updating time per iteration (Sato et al., 2001). It turned out that both implementations run twice as fast as our naive implementation and take about 630 seconds per iteration while the graphical EM algorithm takes 0.661 second per iteration, which is still orders of magnitude faster than the former two. Regrettably a similar comparison using the entire EDR corpus available at the moment was abandoned due to memory over ow during parsing for the construction of support graphs.\nLearning experiments so far only compared time per iteration which ignore extra time for search (parsing) required by the graphical EM algorithm. So a question naturally arises w.r.t. comparison in terms of total learning time. Assuming 100 iterations for learning ATR corpus however, it is estimated that even considering parsing time, the graphical EM algorithm combined with MSLR parser runs orders of magnitude faster than the three implementations (ours, Kita's and Johnson's) of the Inside-Outside algorithm (Sato et al., 2001). Of course this estimation does not directly apply to the graphical EM algorithm combined with OLDT search, as the OLDT interpreter will take more time than a parser and how much more time is needed depends on the implementaiton of OLDT search. 63 Conversely, however, we may be able to take it as a rough indication of how far our approach, the graphical EM algorithm combined with OLDT search via support graphs, can go in the domain of EM learning of PCFGs."}, {"heading": "6.3 Examing the Performance Gap", "text": "In the previous subsection, we compared the performance of the graphical EM algorithm against the Inside-Outside algorithm when PCFGs are given, using two corpora and three implementations of the Inside-Outside algorithm. In all experiments, the graphical EM algorithm considerably outperformed the Inside-Outside algorithm despite the fact that both have the same time complexity. Now we look into what causes such a performance gap.\nSimply put, the Inside-Outside algorithm is slow (primarily) because it lacks parsing. Even when a backbone CFG grammar is explicitly given, it does not take any advantage of the constraints imposed by the grammar. To see it, it might help to review how the inside probability e(s; t;A), i.e. P(nonterminal A spans from s-th word to t-th word) (s t), is calculated by the Inside-Outside algorithm for the given grammar.\ne(s; t;A) =\nX\nB;C s.t. A!BC in the grammar\nr=t 1\nX\nr=s\nP(A! BC)e(s; r;B)e(r + 1; t; C)\nHere P(A! BC) is a probability associated with a production rule A! BC. Note that for a xed triplet (s; t;A), it is usual that the term P(A! BC)e(s; r;B)e(r+1; t; C) is non-zero\n63. We cannnot answer this question right now as the implementation of OLDT search is not completed.\nonly for a relatively small number of (B;C; r)'s determined from successful parses and the rest of combinations always give 0 to the term. Nonetheless the Inside-Outside algorithm attempts to compute the term in every iteration for all possible combinations of B, C and r and this is repeated for every possible (s; t; A), resulting in a lot of redundancy. The same kind of redundancy occurs in the computation of outside probability by the Inside-Outside algorithm.\nThe graphical EM algorithm is free of such redundancy because it runs on parse trees (a\nparse forest) represented by the support graph.\n64\nIt must be added, on the other hand, that\nsuperiority in learning speed of the graphical EM algorithm is realized at the cost of space complexity because while the Inside-Outside algorithm merely requires O(NL 2 ) space for its array to store probabilities, the graphical EM algorithm needs O(N 3 L 3 ) space to store the support graph where N is the number of nonterminals and L is the sentence length. This trade-o is understandable if one notices that the graphical EM algorithm applied to a PCFG can be considered as partial evaluation of the Inside-Outside algorithm by the grammar (and the introduction of appropriate data structure for the output).\nFinally we remark that the use of parsing as a preprocess for EM learning of PCFGs is not unique to the graphical EM algorithm (Fujisaki, Jelinek, Cocke, Black, & Nishino, 1989; Stolcke, 1995). These approaches however still seem to contain redundancies compared with the graphical EM algorithm. For instance Stolcke (1995) uses an Earley chart to compute inside and outside probability, but parses are implicitly reconstructed in each iteration dynamically by combining completed items."}, {"heading": "7. Related Work and Discussion", "text": ""}, {"heading": "7.1 Related Work", "text": "The work presented in this paper is at the crossroads of logic programming and probability theory, and considering an enormous body of work done in these elds, incompleteness is unavoidable when reviewing related work. Having said that, we look at various attempts made to integrate probability with computational logic or logic programming. 65 In reviewing, one can immediately notice there are two types of usage of probability. One type, constraint approach, emphasizes the role of probability as constraints and does not necessarily seek for a unique probability distribution over logical formulas. The other type, distribution approach, explicitly de nes a unique distribution by model theoretical means or proof theoretical means, to compute various probabilities of propositions.\nA typical constraint approach is seen in the early work of probabilistic logic by Nilsson (1986). His central problem, \\probabilistic entailment problem\", is to compute the upper and lower bound of probability P( ) of a target sentence in such a way that the bounds are compatible with a given knowledge base containing logical sentences (not necessarily logic programs) annotated with a probability. These probabilities work as constraints on\n64. We emphasize that the di erence between the Inside-Outside algorithm and the graphical EM algorithm\nis solely computational e ciency, and they converge to the same parameter values when starting from the same initial values. Linguistic evaluations of the estimated parameters by the graphical EM algorithm are also reported by Sato et al. (2001). 65. We omit literature leaning strongly toward logic. For logic(s) concerning uncertainty, see an overview\nby Kyburg (1994).\nthe possible range of P( ). He used the linear programming technique to solve this problem that inevitably delimits the applicability of his approach to nite domains.\nLater Lukasiewicz (1999) investigated the computational complexity of the probabilistic entailment problem in a slightly di erent setting. His knowledge base comprises statements of the form (H j G)[u\n1\n; u\n2\n] representing u\n1\nP(H j G) u\n2\n. He showed that inferring\n\\tight\" u\n1\n; u\n2\nis NP-hard in general, and proposed a tractable class of knowledge base called\nconditional constraint trees.\nAfter the in uential work of Nilsson, Frish and Haddawy (1994) introduced a deductive system for probabilistic logic that remedies \\drawbacks\" of Nilsson's approach, that of computational intractability and the lack of a proof system. Their system deduces a probability range of a proposition by rules of probabilistic inferences about unconditional and conditional probabilities. For instance, one of the rules infers P ( j ) 2 [0 y] from P ( _ j ) 2 [x y] where , and are propositional variables and [x y] (x y) designates a probability range.\nTurning to logic programming, probabilistic logic programming formalized by Ng and Subrahmanian (1992) and Dekhtyar and Subrahmanian (1997) was also a constraint approach. Their program is a set of annotated clauses of the form A : F\n1\n:\n1\n; : : : ; F\nn\n:\nn\nwhere A is an atom, F\ni\n(1 i n) a basic formula, i.e. a conjunction or a disjunction of\natoms, and\nj\n(0 j n) a sub-interval of [0; 1] indicating a probability range. A query\n9 (F\n1\n:\n1\n; : : : ; F\nn\n:\nn\n) is answered by an extension of SLD refutation. On formalization,\nit is assumed that their language contains only a nite number of constant and predicate symbols, and no function symbol is allowed.\nA similar framework was proposed by Lakshmanan and Sadri (1994) under the same syntactic restrictions ( nitely many constant and predicate symbols but no function symbols) in a di erent uncertainty setting. They used annotated clauses of the form A c B\n1\n; : : : ; B\nn\nwhere A and B\ni\n(1 i n) are atoms and c = h[ ; ]; [ ; ]i, a con dence level, represents\na belief interval [ ; ] (0 1) and a doubt interval [ ; ] (0 1), which an expert has in the clause.\nAs seen above, de ning a unique probability distribution is of secondary or no concern to the constraint approach. This is in sharp contrast with Bayesian networks as the whole discipline rests on the ability of the networks to de ne a unique probability distribution (Pearl, 1988; Castillo et al., 1997). Researchers in Bayesian networks have been seeking for a way of mixing Bayesian networks with a logical representation to increase their inherently propositional expressive power.\nBreese (1992) used logic programs to automatically build a Bayesian network from a query. In Breese's approach, a program is the union of a de nite clause program and a set of conditional dependencies of the form P(P j Q\n1\n^ ^ Q\nn\n) where P and Q\ni\ns are atoms.\nGiven a query, a Bayesian network is constructed dynamically that connects the query and relevant atoms in the program, which in turn de nes a local distribution for the connected atoms. Logical variables can appear in atoms but no function symbol is allowed.\nNgo and Haddawy (1997) extended Breese's approach by incorporating a mechanism\nre ecting context. They used a clause of the form P(A\n0\nj A\n1\n; : : : ; A\nn\n) = L\n1\n; : : : ; L\nk\n,\nwhere A\ni\n's are called p-atoms (probabilistic atoms) whereas L\nj\n's are context atoms disjoint\nfrom p-atoms, and computed by another general logic program (satisfying certain restric-\ntions). Given a query, a set of evidence and context atoms, relevant ground p-atoms are identi ed by resolving context atoms away by SLDNF resolution, and a local Bayesian network is built to calculate the probability of the query. They proved the soundness and completeness of their query evaluation procedure under the condition that programs are acyclic 66 and domains are nite.\nInstead of de ning a local distribution for each query, Poole (1993) de ned a global distribution in his \\probabilistic Horn abduction\". His program consists of de nite clauses and disjoint declarations of the form disjoint([h\n1\n:p\n1\n,...,h\nn\n:p\nn\n]) which speci es a probabil-\nity distribution over the hypotheses (abducibles) fh\n1\n; : : : ; h\nn\ng. He assigned probabilities to\nall ground atoms with the help of the theory of logic programming, and furthermore proved that Bayesian networks are representable in his framework. Unlike previous approaches, his language contains function symbols, but the acyclicity condition imposed on the programs for his semantics to be de nable seems to be a severe restriction. Also, probabilities are not de ned for quanti ed formulas.\nBacchus et al. (1996) used a much more powerful rst-order probabilistic language than clauses annotated with probabilities. Their language allows a statistically quanti ed term such as k (x)j (x) k\nx\nto denote the ratio of individuals in a nite domain satisfying (x)^\n(x) to those satisfying (x). Assuming that every world (interpretation for their language) is equally likely, they de ne the probability of a sentence ' under the given knowledge\nbase KB as the limit lim\nN!1\n#worlds\nN\n('^KB)\n#worlds\nN\n(KB)\nwhere #worlds\nN\n( ) is the number of\npossible worlds containing N individuals satisfying , and parameters used in judging approximations. Although the limit does not necessarily exist and the domain must be nite, they showed that their method can cope with di culties arising from \\direct inference\" and default reasoning.\nIn a more linguistic vein, Muggleton (1996, and others) formulated SLPs (stochastic logic programs) procedurally, as an extension of PCFGs to probabilistic logic programs. So, a clause C , which must be range-restricted, 67 is annotated with a probability p like p : C . The probability of a goal G is the product of such ps appearing in its refutation but with a modi cation such that if a subgoal g can invoke n clauses, p\ni\n: C\ni\n(1 i n) at\nsome refutation step, the probability of choosing k-th clause is normalized to p\nk\n=\nP\nn i=1 p i .\nMore recently, Cussens (1999, 2001) enriched SLPs by introducing a special class of log-linear models for SLD refutations w.r.t. a given goal. He for example considers all possible SLD refutations for the most general goal s(X) and de nes probability P(R) of a refutation R as P(R) = Z 1 exp ( P\ni\ni\n(R; i)). Here\ni\nis a number associated with\na clause C\ni\nand (R; i) is a feature, i.e. the number of occurrences of C\ni\nin R. Z is the\nnormalizing constant. Then, the probability assigned to s(a) is the sum of probabilities of refutation for s(a).\n66. The condition says that every ground atom A must be assigned a unique integer n(A) such that n(A) >\nn(B\n1\n); : : : ; n(B\nn\n) holds for any ground instance of a clause of the form A B\n1\n; : : : ; B\nn\n. Under this\ncondition, when a program includes p(X) q(X;Y ), we cannot write recursive clauses about q such as q(X; [HjY ]) q(X;Y ). 67. A syntactic property that variables appearing in the head also appear in the body of a clause. A unit\nclause must be ground."}, {"heading": "7.2 Limitations and Potential Problems", "text": "Approaches described so far have more or less similar limitations and potential problems. Descriptive power con ned to nite domains is the most common limitation, which is due to the use of the linear programming technique (Nilsson, 1986), or due to the syntactic restrictions not allowing for in nitely many constant, function or predicate symbols (Ng & Subrahmanian, 1992; Lakshmanan & Sadri, 1994). Bayesian networks have the same limitation as well (only a nite number of random variables are representable). 68 Also there are various semantic/syntactic restrictions on logic programs. For instance the acyclicity condition imposed by Poole (1993) and Ngo and Haddawy (1997) prevents the unconditional use of clauses with local variables, and the range-restrictedness imposed by Muggleton (1996) and Cussens (1999) excludes programs such as the usual membership Prolog program.\nThere is another type of problem, the possibility of assigning con icting probabilities to logically equivalent formulas. In SLPs, P(A) and P(A ^ A) do not necessarily coincide because A and A^A may have di erent refutations (Muggleton, 1996; Cussens, 1999, 2001). Consequently in SLPs, we would be in trouble if we naively interpret P(A) as the probability of A's being true. Also assigning probabilities to arbitrary quanti ed formulas seems out of scope of both approaches to SLPs.\nLast but not least, there is a big problem common to any approach using probabilities: where do the numbers come from? Generally speaking, if we use n binary random variables in a model, we have to determine 2 n probabilities to completely specify their joint distribution, and ful lling this requirement with reliable numbers quickly becomes impossible as n grows. The situation is even worse when there are unobservable variables in the model such as possible causes of a disease. Apparently parameter learning from observed data is a natural solution to this problem, but parameter learning of logic programs has not been well studied.\nDistribution semantics proposed by Sato (1995) was an attempt to solve these problems along the line of the global distribution approach. It de nes a distribution (probability measure) over the possible interpretations of ground atoms for an arbitrary logic program in any rst order language and assigns consistent probabilities to all closed formulas. Also distribution semantics enabled us to derive an EM algorithm for the parameter learning of logic programs for the rst time. As it was a naive algorithm however, dealing with large problems was di cult when there are exponentially many explanations for an observation like HMMs. We believe that the e ciency problem is solved to a large extent by the graphical EM algorithm presented in this paper."}, {"heading": "7.3 EM Learning", "text": "Since EM learning is one of the central issues in this paper, we separately mention work related to EM learning for symbolic frameworks. Koller and Pfe er (1997) used in their approach to KBMC (knowledge-based model construction) EM learning to estimate parameters labeling clauses. They express probabilistic dependencies among events by de - nite clauses annotated with probabilities, similarly to Ngo and Haddawy's (1997) approach, and locally build a Bayesian network relevant to the context and evidence as well as the"}, {"heading": "68. However, RPMs (recursive probability models) proposed by Pfe er and Koller (2000) as an extension", "text": "of Bayesian networks allow for in nitely many random variables. They are organized as attributes of classes and a probability measure over attribute values is introduced.\nquery. Parameters are learned by applying to the constructed network the specialized EM algorithm for Bayesian networks (Castillo et al., 1997).\nDealing with a PCFG by a statically constructed Bayesian network was proposed Pynadath and Wellman (1998), and it is possible to combine the EM algorithm with their method to estimate parameters in the PCFG. Unfortunately, the constructed network is not singly connected, and time complexity of probability computation is potentially exponential in the length of an input sentence.\nClosely related to our EM learning is parameter learning of log-linear models. Riezler (1998) proposed the IM algorithm in his approach to probabilistic constraint programming. The IM algorithm is a general parameter estimation algorithm from incomplete data for log-linear models whose probability function P(x) takes the form P(x) = Z 1 exp ( P n\ni=1\ni i\n(x)) p\n0\n(x) where (\n1\n; : : : ;\nn\n) are parameters to be estimated,\ni\n(x) the\ni-th feature of an observed object x and Z the normalizing constant. Since a feature can be any function of x, the log-linear model is highly exible and includes our distribution P\nmsw\nas a special case of Z = 1. There is a price to pay however; the computational cost\nof Z. It requires a summation over exponentially many terms. To avoid the cost of exact computation, approximate computation by a Monte Carlo method is possible. Whichever one may choose however, learning time increases compared to the EM algorithm for Z = 1.\nThe FAM (failure-adjusted maximization) algorithm proposed by Cussens (2001) is an EM algorithm applicable to pure normalized SLPs that may fail. It deals with a special class of log-linear models but is more e cient than the IM algorithm. Because the statistical framework of the FAM is rather di erent from distribution semantics, comparison with the graphical EM algorithm seems di cult.\nBeing slightly tangential to EM learning, Koller et al. (1997) developed a functional modeling language de ning a probability distribution over symbolic structures in which they showed \\cashing\" of computed results leads to e cient probability computation of singly connected Bayesian networks and PCFGs. Their cashing corresponds to the computation of inside probability in the Inside-Outside algorithm and the computation of outside probability is untouched."}, {"heading": "7.4 Future Directions", "text": "Parameterized logic programs are expected to be a useful modeling tool for complex symbolicstatistical phenomena. We have tried various types of modeling, besides stochastic grammars and Bayesian networks, such as the modeling of gene inheritance in the Kariera tribe (White, 1963) where the rules of bi-lateral cross-cousin marriage for four clans interact with the rules of genetic inheritance (Sato, 1998). The model was quite interdisciplinary, but the exibility of combining msw atoms by means of de nite clauses greatly facilitated the modeling process.\nAlthough satisfying the ve conditions in Section 4\nthe uniqueness condition (roughly, one cause yields one e ect)\nthe nite support condition (there are a nite number of explanations for one observation)\nthe acyclic support condition (explanations must not be cyclic)\nthe t-exclusiveness condition (explanations must be mutually exclusive)\nthe independence condition (events in an explanation must be independent)\nfor the applicability of the graphical EM algorithm seems daunting, our modeling experiences so far tell us that the modeling principle in Section 4 e ectively guides us to successful modeling. In return, we can obtain a declarative model described compactly by a high level language whose parameters are e ciently learnable by the graphical EM algorithm as shown in the preceding section.\nOne of the future directions is however to relax some of the applicability conditions, especially the uniqueness condition that prohibits a generative model from failure or from generating multiple observable events. Although we pointed out in Section 4.4 that the MAR condition in Appendix B adapted to our semantics can replace the uniqueness condition and validates the use of the graphical EM algorithm even when a complete data does not uniquely determine the observed data just like the case of \\partially bracketed corpora\" (Pereira & Schabes, 1992), we feel the need to do more research on this topic. Also investigating the role of the acyclicity condition seems theoretically interesting as the acyclicity is often related to the learning of logic programs (Arimura, 1997; Reddy & Tadepalli, 1998).\nIn this paper we only scratched the surface of individual research elds such as HMMs, PCFGs and Bayesian networks. Therefore, there remains much to be done about clarifying how experiences in each research eld are re ected in the framework of parameterized logic programs. For example, we need to clarify the relationship between symbolic approaches to Bayesian networks such as SPI (Li, Z. & D'Ambrosio, B., 1994) and our approach. Also it is unclear how a compiled approach using the junction tree algorithm for Bayesian networks can be incorporated into our approach. Aside from exact methods, approximate methods of probability computation specialized for parameterized logic programs must also be developed.\nThere is also a direction of improving learning ability by introducing priors instead of ML estimation to cope with data sparseness. The introduction of basic distributions that make probabilistic switches correlated seems worth trying in the near future. It is also important to take advantage of the logical nature of our approach to handle uncertainty. For example, it is already shown by Sato (2001) that we can learn parameters from negative examples such as \\the grass is not wet\" but the treatment of negative examples in parameterized logic programs is still in its infancy.\nConcerning developing complex statistical models based on the \\programs as distributions\" scheme, stochastic natural language processing which exploits semantic information seems promising. For instance, uni cation-based grammars such as HPSGs (Abney, 1997) may be a good target beyond PCFGs because they use feature structures logically describable, and the ambiguity of feature values seems to be expressible by a probability distribution.\nAlso building a mathematical basis for logic programs with continuous random variables\nis a challenging research topic."}, {"heading": "8. Conclusion", "text": "We have proposed a logical/mathematical framework for statistical parameter learning of parameterized logic programs, i.e. de nite clause programs containing probabilistic facts with a parameterized probability distribution. It extends the traditional least Herbrand model semantics in logic programming to distribution semantics , possible world semantics with a probability distribution over possible worlds (Herbrand interpretations) which is unconditionally applicable to arbitrary logic programs including ones for HMMs, PCFGs and Bayesian networks.\nWe also have presented a new EM algorithm, the graphical EM algorithm in Section 4, which learns statistical parameters from observations for a class of parameterized logic programs representing a sequential decision process in which each decision is exclusive and independent. It works on support graphs, a new data structure specifying a logical relationship between an observed goal and its explanations, and estimates parameters by computing inside and outside probability generalized for logic programs.\nThe complexity analysis in Section 5 showed that when OLDT search, a complete tabled refutation method for logic programs, is employed for the support graph construction and table access is done in O(1) time, the graphical EM algorithm, despite its generality, has the same time complexity as existing EM algorithms, i.e. the Baum-Welch algorithm for HMMs, the Inside-Outside algorithm for PCFGs and the one for singly connected Bayesian networks that have been developed independently in each research eld. In addition, for pseudo probabilistic context sensitive grammars with N nonterminals, we showed that the graphical EM algorithm runs in time O(N 4 L 3 ) for a sentence of length L.\nTo compare actual performance of the graphical EM algorithm against the InsideOutside algorithm, we conducted learning experiments with PCFGs in Section 6 using two real corpora with contrasting characters. One is ATR corpus containing short sentences for which the grammar is not much ambiguous (958 parses/sentence), and the other is EDR corpus containing long sentences for which the grammar is rather ambiguous (3:0 10 8 at average sentence length 20). In both cases, the graphical EM algorithm outperformed the Inside-Outside algorithm by orders of magnitude in terms of time per iteration, which suggests the e ectiveness of our approach to EM learning by the graphical EM algorithm.\nSince our semantics is not limited to nite domains or nitely many random variables but applicable to any logic programs of arbitrary complexity, the graphical EM algorithm is expected to give a general yet e cient method of parameter learning for models of complex symbolic-statistical phenomena governed by rules and probabilities."}, {"heading": "Acknowledgments", "text": "The authors wish to thank three anonymous referees for their comments and suggestions. Special thanks go to Takashi Mori and Shigeru Abe for stimulating discussions and learning experiments, and also to Tanaka-Tokunaga Laboratory for kindly allowing them to use MSLR parser and the linguistic data."}, {"heading": "Appendix A. Properties of P", "text": "DB\nIn this appendix, we list some properties of P\nDB\nde ned by a parameterized logic program\nDB = F [ R in a countable rst-order language L.\n69\nFirst of all, P\nDB\nassigns consistent\nprobabilities\n70\nto every closed formula in L by\nP\nDB\n( )\ndef = P\nDB\n(f! 2\nDB\nj ! j= g)\nwhile guaranteeing continuity in the sense that\nlim\nn!1\nP\nDB\n( (t\n1\n) ^ ^ (t\nn\n)) = P\nDB\n(8x (x))\nlim\nn!1\nP\nDB\n( (t\n1\n) _ _ (t\nn\n)) = P\nDB\n(9x (x))\nwhere t\n1\n; t\n2\n; : : : is an enumeration of ground terms in L.\nThe next proposition, Proposition A.1, relates P\nDB\nto the Herbrand model. To prove\nit, we need some terminology. A factor is a closed formula in prenex disjunctive normal form Q\n1\nQ\nn\nM where Q\ni\n(1 i n) is either an existential quanti cation or a universal\nquanti cation and M a matrix. The length of quanti cations n is called the rank of the factor. De ne as a set of formulas made out of factors, conjunctions and disjunctions. Associate with each formula in a multi-set r( ) of ranks by\nr( ) =\n8 > <\n> :\n; if is a factor with no quanti cation\nfng if is a factor with rank n\nr(\n1\n) ] r(\n2\n) if =\n1\n_\n2\nor =\n1\n^\n2\n:\nHere ] stands for the union of twomulti-sets. For instance f1; 2; 3g]f2; 3; 4g = f1; 2; 2; 3; 3; 4g. We use the multi-set ordering in the proof of Proposition A.1 because the usual induction on the complexity of formulas does not work.\nLemma A.1 Let be a boolean formula made out of ground atoms in L. P\nDB\n( ) =\nP\nF\n(f 2\nF\njM\nDB\n( ) j= g).\n(Proof) We have only to prove the lemma about a conjunction of atoms of the form D\nx\n1\n1\n^\n^D\nx\nn\nn\n(x\ni\n2 f0; 1g; 1 i n).\nP\nDB\n(D\nx\n1\n1\n^ ^D\nx\nn\nn\n) = P\nDB\n(f! 2\nDB\nj ! j=D\nx\n1\n1\n^ ^D\nx\nn\nn\ng)\n= P\nDB\n(D\n1\n= x\n1\n; : : : ; D\nn\n= x\nn\n)\n= P\nF\n(f 2\nF\njM\nDB\n( ) j= D\nx\n1\n1\n^ ^D\nx\nn\nn\ng) Q.E.D.\nProposition A.1 Let be a closed formula in L. P\nDB\n( ) = P\nF\n(f 2\nF\njM\nDB\n( ) j= g)."}, {"heading": "69. For de nitions of", "text": "F\n, P\nF\n, M\nDB\n( ),\nDB\n, P\nDB\nand others used below, see Section 3.\n70. By consistent, we mean probabilities assigned to logical formulas respect the laws of probability such as\n0 P (A) 1, P (:A) = 1 P (A) and P (A _B) = P (A) + P (B) P (A ^B).\n(Proof) Recall that a closed formula has an equivalent prenex disjunctive normal form that belongs to . We prove the proposition for formulas in by using induction on the multi-set ordering over fr( ) j 2 g. If r( ) = ;, has no quanti cation. So the proposition is correct by Lemma A.1. Suppose otherwise. Write = G[Q\n1\nQ\n2\nQ\nn\nF ]\nwhere Q\n1\nQ\n2\nQ\nn\nF indicates a single occurrence of a factor in G.\n71\nWe assume Q\n1\n= 9x\n(Q\n1\n= 8x is similarly treated). We also assume that bound variables are renamed to avoid\nname clash. Then G[9xQ\n2\nQ\nn\nF ] is equivalent to 9xG[Q\n2\nQ\nn\nF ] in light of the validity\nof (9xA) ^B = 9x(A ^B) and (9xA) _B = 9x(A _ B) when B contains no free x.\nP\nDB\n( ) = P\nDB\n(G[Q\n1\nQ\n2\nQ\nn\nF ])\n= P\nDB\n(9xG[Q\n2\nQ\nn\nF [x] ])\n= lim\nk!1\nP\nDB\n(G[Q\n2\nQ\nn\nF [t\n1\n]] _ _ G[Q\n2\nQ\nn\nF [t\nk\n] ])\n= lim\nk!1\nP\nDB\n(G[Q\n2\nQ\nn\nF [t\n1\n] _ _ Q\n2\nQ\nn\nF [t\nk\n] ])\n= lim\nk!1\nP\nF\n(f 2\nF\njM\nDB\n( ) j= G[Q\n2\nQ\nn\nF [t\n1\n] _ _Q\n2\nQ\nn\nF [t\nk\n] ]g)\n(by induction hypothesis)\n= P\nF\n(f 2\nF\njM\nDB\n( ) j= 9xG[Q\n2\nQ\nn\nF [x]]g)\n= P\nF\n(f 2\nF\njM\nDB\n( ) j= g) Q.E.D.\nWe next prove a theorem on the i de nition introduced in Section 4. Distribution semantics considers the program DB = F [ R as a set of in nitely many ground de nite clauses such that F is a set of facts (with a probability measure P\nF\n) and R a set of rules,\nand no clause head in R appears in F . Put\nhead(R)\ndef = fB j B appears in R as a clause headg:\nFor B 2 head(R), let B W\ni\n(i = 1; 2; : : :) be an enumeration of clauses about B in R.\nDe ne i (B), the i (if-and-only-if) form of rules about B in DB\n72\nby\ni (B)\ndef = B $W\n1\n_W\n2\n_\nSince M\nDB\n( ) is a least Herbrand model, the following is obvious.\nLemma A.2 For B in head(R) and 2\nF\n, M\nDB\n( ) j= i (B).\nTheorem A.1 below is about i (B). It states that at general level, both sides of the i\nde nition p(x) $ 9y\n1\n(x = t\n1\n^W\n1\n) _ _ 9y\nn\n(x = t\nn\n^W\nn\n) of p( ) coincide as random\nvariables whenever x is instantiated to a ground term.\nTheorem A.1 Let i (B) = B $W\n1\n_W\n2\n_ be the i form of rules about B 2 head(R).\nP\nDB\n(i (B)) = 1 and P\nDB\n(B) = P\nDB\n(W\n1\n_W\n2\n_ ).\n71. For an expression E, E[ ] means that may occur in the speci ed positions of E. If\n1\n_\n2\nin E[\n1\n_\n2\n]\nindicates a single occurrence of\n1\n_\n2\nin a positive boolean formula E, E[\n1\n_\n2\n] = E[\n1\n]_E[\n2\n] holds.\n72. This de nition is di erent from the usual one (Lloyd, 1984; Doets, 1994) as we are here talking at ground\nlevel. W\n1\n_W\n2\n_ is true if and only if one of the disjuncts is true.\n(Proof)\nP\nDB\n(i (B)) = P\nDB\n(f! 2\nDB\nj ! j= B ^ (W\n1\n_W\n2\n_ )g)\n+P\nDB\n(f! 2\nDB\nj ! j= :B ^ :(W\n1\n_W\n2\n_ )g)\n= lim\nk!1\nP\nDB\n(f! 2\nDB\nj ! j= B ^\nk\n_\ni=1\nW\ni\ng)\n+ lim\nk!1\nP\nDB\n(f! 2\nDB\nj ! j= :B ^ :\nk\n_\ni=1\nW\ni\ng)\n= lim\nk!1\nP\nF\n(f 2\nF\njM\nDB\n( ) j= B ^\nk\n_\ni=1\nW\ni\ng)\n+ lim\nk!1\nP\nF\n(f 2\nF\njM\nDB\n( ) j= :B ^ :\nk\n_\ni=1\nW\ni\ng)\n(Lemma A.1)\n= P\nF\n(f 2\nF\njM\nDB\n( ) j= i (B)g)\n= P\nF\n(\nF\n) (Lemma A.2)\n= 1\nIt follows from P\nDB\n(i (B)) = 1 that\nP\nDB\n(B) = P\nDB\n(B ^ i (B)) = P\nDB\n(W\n1\n_W\n2\n_ ): Q.E.D.\nWe then prove a proposition useful in probability computation. Let\nDB\n(B) be the\nsupport set for an atom B introduced in Section 4 (it is the set of all explanations for B). In the sequel, B is a ground atom. Write\nDB\n(B) = fS\n1\n; S\n2\n; : : :g and\nW\nDB\n(B) = S\n1\n_S\n2\n_\n73\nDe ne a set\nB\nby\nB\ndef = f! 2\nDB\nj ! j= B $\n_\nDB\n(B)g:\nProposition A.2 For every B 2 head(R), P\nDB\n(\nB\n) = 1 and P\nDB\n(B) = P\nDB\n(\nW\nDB\n(B)).\n(Proof) We rst prove P\nDB\n(\nB\n) = 1 but the proof exactly parallels that of Theorem A.1\nexcept that W\n1\n_W\n2\n_ is replaced by S\n1\n_S\n2\n_ using the fact that B $ S\n1\n_S\n2\n_\nis true in every least Herbrand model of the form M\nDB\n( ). Then from P\nDB\n(\nB\n) = 1, we\nhave\nP\nDB\n(B) = P\nDB\n(B ^ (B $\n_\nDB\n(B)))\n= P\nDB\n(\n_\nDB\n(B)): Q.E.D.\nFinally, we show that distribution semantics is a probabilistic extension of the traditional least Herbrand model semantics in logic programming by proving Theorem A.2. It says that the probability mass is distributed exclusively over possible least Herbrand models.\nDe ne as the set of least Herbrand models generated by xing R and varying a subset\nof F in the program DB = F [R. In symbols,\n73. For a set K = fE\n1\n; E\n2\n; : : :g of formulas,\nW\nK denotes a (-n in nite) disjunction E\n1\n_ E\n2\n_\ndef = f! 2\nDB\nj ! =M\nDB\n( ) for some 2\nF\ng:\nNote that as is merely a subset of\nDB\n, we cannot conclude P\nDB\n( ) = 1 a priori, but the\nnext theorem, Theorem A.2, states P\nDB\n( ) = 1, i.e. distribution semantics distributes the\nprobability mass exclusively over , i.e. possible least Herbrand models.\nTo prove the theorem, we need some preparations. Recalling that atoms outside head(R)[\nF have no chance of being proved from DB, we introduce\n0\ndef = f! 2\nDB\nj ! j= :D for every ground atom D 62 head(R) [ Fg:\nFor a Herbrand interpretation ! 2\nDB\n, !j\nF\n(2\nF\n) is the restriction of ! to those atoms\nin F .\nLemma A.3 Let ! 2\nDB\nbe a Herbrand interpretation.\n! =M\nDB\n( ) for some 2\nF\ni ! 2\n0\nand ! j= B $\nW\nDB\n(B) for every B 2 head(R).\n(Proof) Only-if part is immediate from the property of the least Herbrand model. For if-part, suppose ! satis es the right hand side. We show that ! = M\nDB\n(!j\nF\n). As ! and\nM\nDB\n(!j\nF\n) coincide w.r.t. atoms not in head(R), it is enough to prove that they also give\nthe same truth values to atoms in head(R). Take B 2 head(R) and write\nW\nDB\n(B) =\nS\n1\n_ S\n2\n_ Suppose ! j= B $ S\n1\n_ S\n2\n_ Then if ! j= B, we have ! j= S\nj\nfor some j,\nthereby !j\nF\nj= S\nj\n, and hence M\nDB\n(!j\nF\n) j= S\nj\n, which implies M\nDB\n(!j\nF\n) j= B. Otherwise\n! j= :B. So ! j= :S\nj\nfor every j. It follows that M\nDB\n(!j\nF\n) j= :B. Since B is arbitrary,\nwe conclude that ! and M\nDB\n(!j\nF\n) agree on the truth values assigned to atoms in head(R)\nas well. Q.E.D.\nTheorem A.2 P\nDB\n( ) = 1.\n(Proof) From Lemma A.3, we have\n= f! 2\nDB\nj ! =M\nDB\n( ) for some 2\nF\ng\n=\n0\n\\\n\\\nB2head(R)\nB\n:\nP\nDB\n(\nB\n) = 1 by Proposition A.2. To prove P\nDB\n(\n0\n) = 1, let D\n1\n; D\n2\n; : : : be an enumeration\nof atoms not belonging to head(R) [ F . They are not provable from DB = F [ R, and hence false in every least Herbrand model M\nDB\n( ) ( 2\nF\n). So\nP\nDB\n(\n0\n) = lim\nm!1\nP\nDB\n(f! 2\nDB\nj ! j= :D\n1\n^ ^ :D\nm\ng)\n= lim\nm!1\nP\nF\n(f 2\nF\njM\nDB\n( ) j= :D\n1\n^ ^ :D\nm\ng)\n= P\nF\n(\nF\n) = 1:\nSince a countable conjunction of measurable sets of probability measure one has also\nprobability measure one, it follows from P\nDB\n(\nB\n) = 1 for everyB 2 head(R) and P\nDB\n(\n0\n) =\n1 that P\nDB\n( ) = 1. Q.E.D."}, {"heading": "Appendix B. The MAR (missing at random) Condition", "text": "In the original formulation of the EM algorithm by Dempster et al. (1977), it is assumed that there exists a many-to-one mapping y = (x) from a complete data x to an incomplete (observed) data y. In the case of parsing, x is a parse tree and y is the input sentence and x uniquely determines y. In this paper, the uniqueness condition ensures the existence of such a many-to-one mapping from explanations to observations. We however sometimes face a situation where there is no such many-to-one mapping from complete data to incomplete data but nonetheless we wish to apply the EM algorithm.\nThis dilemma can be solved by the introduction of a missing-data mechanism which makes a complete data incomplete. The missing-data mechanism, m, has a distribution g (m j x) parameterized by and y, the observed data, is described as y =\nm\n(x). It says\nx becomes incomplete y by m. The correspondence between x and y, i.e. fhx; yi j 9m(y =\nm\n(x))g naturally becomes many-to-many.\nRubin (1976) derived two conditions on g (data are missing at random and data are observed at random) collectively called theMAR (missing at random) condition, and showed that if we assume a missing-data mechanism behind our observations that satis es the MAR condition, we may estimate parameters of the distribution over x by simply applying the EM algorithm to y, the observed data.\nWe adapt the MAR condition to parameterized logic programs as follows. We keep a generative model satisfying the uniqueness condition that outputs goals G such as parse trees. We further extend the model by additionally inserting a missing-data mechanism m between G and our observation O like O =\nm\n(G) and assume m satis es the MAR\ncondition. Then the extended model has a many-to-many correspondence between explanations and observations, and generates non-exclusive observations such that P (O^O 0 ) > 0 (O 6= O 0 ), which causes P\nO\nP (O) 1 where P (O) =\nP\nG:9m O=\nm\n(G)\nP\nDB\n(G). Thanks to\nthe MAR condition however, we are still allowed to apply the EM algorithm to such nonexclusive observations. Put it di erently, even if the uniqueness condition is seemingly destroyed, the EM algorithm is applicable just by (imaginarily) assuming a missing-data mechanism satisfying the MAR condition."}], "references": [{"title": "Stochastic attribute-value grammars", "author": ["S. Abney"], "venue": "Computational Linguistics, 23 (4), 597{618.", "citeRegEx": "Abney,? 1997", "shortCiteRegEx": "Abney", "year": 1997}, {"title": "Learning acyclic rst-order horn sentences from entailment", "author": ["H. Arimura"], "venue": "Proceedings of the Eighth International Workshop on Algorithmic Learning Theory. Ohmsha/Springer-Verlag.", "citeRegEx": "Arimura,? 1997", "shortCiteRegEx": "Arimura", "year": 1997}, {"title": "From statistical knowledge bases to degrees of belief", "author": ["F. Bacchus", "A. Grove", "J. Halpern", "D. Koller"], "venue": "Arti cial Intelligence,", "citeRegEx": "Bacchus et al\\.,? \\Q1996\\E", "shortCiteRegEx": "Bacchus et al\\.", "year": 1996}, {"title": "Trainable grammars for speech recognition", "author": ["J.K. Baker"], "venue": "Proceedings of Spring Conference of the Acoustical Society of America, pp. 547{550. 450", "citeRegEx": "Baker,? 1979", "shortCiteRegEx": "Baker", "year": 1979}, {"title": "Valence induction with a head-lexicalized PCFG", "author": ["G. Carroll", "M. Rooth"], "venue": null, "citeRegEx": "Carroll and Rooth,? \\Q1998\\E", "shortCiteRegEx": "Carroll and Rooth", "year": 1998}, {"title": "Probability Theory (3rd ed.)", "author": ["Y. Chow", "H. Teicher"], "venue": "Negation as failure", "citeRegEx": "Chow and Teicher,? \\Q1997\\E", "shortCiteRegEx": "Chow and Teicher", "year": 1997}, {"title": "Introduction to Algorithms", "author": ["T. Press. Cormen", "C. Leiserson", "R. Rivest"], "venue": null, "citeRegEx": "Cormen et al\\.,? \\Q1990\\E", "shortCiteRegEx": "Cormen et al\\.", "year": 1990}, {"title": "Maximum likelihood from incomplete", "author": ["A.P. Dempster", "N.M. Laird", "D.B. Rubin"], "venue": "International Conference on Logic Programming", "citeRegEx": "Dempster et al\\.,? \\Q1977\\E", "shortCiteRegEx": "Dempster et al\\.", "year": 1977}, {"title": "From Logic to Logic Programming", "author": ["K. Doets"], "venue": "EM algorithm. Royal Statistical Society,", "citeRegEx": "Doets,? \\Q1994\\E", "shortCiteRegEx": "Doets", "year": 1994}, {"title": "A probabilistic parsing", "author": ["T. Fujisaki", "F. Jelinek", "J. Cocke", "E. Black", "T. Nishino"], "venue": "Arti cial Intelligence,", "citeRegEx": "Fujisaki et al\\.,? \\Q1989\\E", "shortCiteRegEx": "Fujisaki et al\\.", "year": 1989}, {"title": "Abductive logic programming", "author": ["A.C. Kakas", "R.A. Kowalski", "F. Toni"], "venue": "Journal of Logic and Computation,", "citeRegEx": "Kakas et al\\.,? \\Q1992\\E", "shortCiteRegEx": "Kakas et al\\.", "year": 1992}, {"title": "Learning and Representation of Symbolic-Statistical Knowledge (in Japanese)", "author": ["Y. Kameya"], "venue": "Ph. D. dissertation, Tokyo Institute of Technology.", "citeRegEx": "Kameya,? 2000", "shortCiteRegEx": "Kameya", "year": 2000}, {"title": "E cient EM learning for parameterized logic programs", "author": ["Y. Kameya", "T. Sato"], "venue": "In Proceedings of the 1st Conference on Computational Logic (CL2000),", "citeRegEx": "Kameya and Sato,? \\Q2000\\E", "shortCiteRegEx": "Kameya and Sato", "year": 2000}, {"title": "Probabilistic Language Models (in Japanese)", "author": ["K. Kita"], "venue": "Tokyo Daigaku Syuppan-kai.", "citeRegEx": "Kita,? 1999", "shortCiteRegEx": "Kita", "year": 1999}, {"title": "E ective Bayesian inference for stochastic programs", "author": ["D. Koller", "D. McAllester", "A. Pfe er"], "venue": "In Proceedings of 15th National Conference on Arti cial Intelligence", "citeRegEx": "Koller et al\\.,? \\Q1997\\E", "shortCiteRegEx": "Koller et al\\.", "year": 1997}, {"title": "Learning probabilities for noisy rst-order rules", "author": ["D. Koller"], "venue": "Pfe er,", "citeRegEx": "Koller,? \\Q1997\\E", "shortCiteRegEx": "Koller", "year": 1997}, {"title": "Uncertainty logics", "author": ["H. Kyburg"], "venue": "Gabbay, D., Hogger, C., & Robinson, J. (Eds.), Handbook of Logics in Arti cial Intelligence and Logic Programming, pp. 397{438. Oxford Science Publications.", "citeRegEx": "Kyburg,? 1994", "shortCiteRegEx": "Kyburg", "year": 1994}, {"title": "A derivation of the Inside-Outside Algorithm from the EM algorithm", "author": ["J. La erty"], "venue": "Technical report, IBM T.J.Watson Research Center.", "citeRegEx": "erty,? 1993", "shortCiteRegEx": "erty", "year": 1993}, {"title": "Probabilistic deductive databases", "author": ["L.V.S. Lakshmanan", "F. Sadri"], "venue": "In Proceedings of the 1994 International Symposium on Logic Programming", "citeRegEx": "Lakshmanan and Sadri,? \\Q1994\\E", "shortCiteRegEx": "Lakshmanan and Sadri", "year": 1994}, {"title": "The estimation of stochastic context-free grammars using the Inside-Outside algorithm", "author": ["K. Lari", "S.J. Young"], "venue": "Computer Speech and Language,", "citeRegEx": "Lari and Young,? \\Q1990\\E", "shortCiteRegEx": "Lari and Young", "year": 1990}, {"title": "E cient inference in Bayes networks as a combinatorial optimization problem", "author": ["Z. Li", "B. D'Ambrosio"], "venue": "International Journal of Approximate Reasoning,", "citeRegEx": "Li and D.Ambrosio,? \\Q1994\\E", "shortCiteRegEx": "Li and D.Ambrosio", "year": 1994}, {"title": "Foundations of Logic Programming", "author": ["J.W. Lloyd"], "venue": "Springer-Verlag.", "citeRegEx": "Lloyd,? 1984", "shortCiteRegEx": "Lloyd", "year": 1984}, {"title": "Probabilistic deduction with conditional constraints over basic events", "author": ["T. Lukasiewicz"], "venue": "Journal of Arti cial Intelligence Research, 10, 199{241.", "citeRegEx": "Lukasiewicz,? 1999", "shortCiteRegEx": "Lukasiewicz", "year": 1999}, {"title": "Foundations of Statistical Natural Language Processing", "author": ["C.D. Manning", "H. Sch\u007futze"], "venue": null, "citeRegEx": "Manning and Sch\u007futze,? \\Q1999\\E", "shortCiteRegEx": "Manning and Sch\u007futze", "year": 1999}, {"title": "The EM Algorithm and Extensions", "author": ["G.J. McLachlan", "T. Krishnan"], "venue": null, "citeRegEx": "McLachlan and Krishnan,? \\Q1997\\E", "shortCiteRegEx": "McLachlan and Krishnan", "year": 1997}, {"title": "Stochastic logic programs", "author": ["S. Muggleton"], "venue": "de Raedt, L. (Ed.), Advances in Inductive Logic Programming, pp. 254{264. IOS Press.", "citeRegEx": "Muggleton,? 1996", "shortCiteRegEx": "Muggleton", "year": 1996}, {"title": "Probabilistic logic programming", "author": ["R. Ng", "V.S. Subrahmanian"], "venue": "Information and Computation,", "citeRegEx": "Ng and Subrahmanian,? \\Q1992\\E", "shortCiteRegEx": "Ng and Subrahmanian", "year": 1992}, {"title": "Answering queries from context-sensitive probabilistic knowledge bases", "author": ["L. Ngo", "P. Haddawy"], "venue": "Theoretical Computer Science,", "citeRegEx": "Ngo and Haddawy,? \\Q1997\\E", "shortCiteRegEx": "Ngo and Haddawy", "year": 1997}, {"title": "Probabilistic logic", "author": ["N.J. Nilsson"], "venue": "Arti cial Intelligence, 28, 71{87. 452", "citeRegEx": "Nilsson,? 1986", "shortCiteRegEx": "Nilsson", "year": 1986}, {"title": "Probabilistic Reasoning in Intelligent Systems", "author": ["J. Pearl"], "venue": "Morgan Kaufmann.", "citeRegEx": "Pearl,? 1988", "shortCiteRegEx": "Pearl", "year": 1988}, {"title": "Inside-Outside reestimation from partially bracketed corpora", "author": ["F.C.N. Pereira", "Y. Schabes"], "venue": "In Proceedings of the 30th Annual Meeting of the Association for Computational Linguistics", "citeRegEx": "Pereira and Schabes,? \\Q1992\\E", "shortCiteRegEx": "Pereira and Schabes", "year": 1992}, {"title": "De nite clause grammars for language analysis | a survey of the formalism and a comparison with augmented transition networks", "author": ["F.C.N. Pereira", "D.H.D. Warren"], "venue": "Arti cial Intelligence,", "citeRegEx": "Pereira and Warren,? \\Q1980\\E", "shortCiteRegEx": "Pereira and Warren", "year": 1980}, {"title": "Semantics and inference for recursive probability models", "author": ["A. Pfe er", "D. Koller"], "venue": "In Proceedings of the Seventh National Conference on Arti cial Intelligence", "citeRegEx": "er and Koller,? \\Q2000\\E", "shortCiteRegEx": "er and Koller", "year": 2000}, {"title": "Probabilistic Horn abduction and Bayesian networks", "author": ["D. Poole"], "venue": "Arti cial Intelligence, 64 (1), 81{129.", "citeRegEx": "Poole,? 1993", "shortCiteRegEx": "Poole", "year": 1993}, {"title": "Generalized queries on probabilistic context-free grammars", "author": ["D.V. Pynadath", "M.P. Wellman"], "venue": "IEEE Transaction on Pattern Analysis and Machine Intelligence,", "citeRegEx": "Pynadath and Wellman,? \\Q1998\\E", "shortCiteRegEx": "Pynadath and Wellman", "year": 1998}, {"title": "A tutorial on hidden markov models and selected applications in speech recognition", "author": ["L.R. Rabiner"], "venue": "Proceedings of the IEEE, 77 (2), 257{286.", "citeRegEx": "Rabiner,? 1989", "shortCiteRegEx": "Rabiner", "year": 1989}, {"title": "Foundations of Speech Recognition", "author": ["L.R. Rabiner", "B. Juang"], "venue": null, "citeRegEx": "Rabiner and Juang,? \\Q1993\\E", "shortCiteRegEx": "Rabiner and Juang", "year": 1993}, {"title": "E cient tabling mechanisms for logic programs", "author": ["I. Ramakrishnan", "P. Rao", "K. Sagonas", "T. Swift", "D. Warren"], "venue": "In Proceedings of the 12th International Conference on Logic Programming", "citeRegEx": "Ramakrishnan et al\\.,? \\Q1995\\E", "shortCiteRegEx": "Ramakrishnan et al\\.", "year": 1995}, {"title": "Learning rst-order acyclic horn programs from entailment", "author": ["C. Reddy", "P. Tadepalli"], "venue": "In Proceedings of the 15th International Conference on Machine Learning; (and Proceedings of the 8th International Conference on Inductive Logic Programming)", "citeRegEx": "Reddy and Tadepalli,? \\Q1998\\E", "shortCiteRegEx": "Reddy and Tadepalli", "year": 1998}, {"title": "Probabilistic Constraint Logic Programming", "author": ["S. Riezler"], "venue": "Ph.D. thesis, Universit\u007f", "citeRegEx": "Riezler,? 1998", "shortCiteRegEx": "Riezler", "year": 1998}, {"title": "Inference and missing data", "author": ["D. Rubin"], "venue": "Biometrika, 63 (3), 581{592.", "citeRegEx": "Rubin,? 1976", "shortCiteRegEx": "Rubin", "year": 1976}, {"title": "XSB as an e cient deductive database engine", "author": ["K. Sagonas", "S. T", "D. Warren"], "venue": "In Proceedings of the 1994 ACM SIGMOD International Conference on Management of Data,", "citeRegEx": "Sagonas et al\\.,? \\Q1994\\E", "shortCiteRegEx": "Sagonas et al\\.", "year": 1994}, {"title": "A statistical learning method for logic programs with distribution semantics", "author": ["T. Sato"], "venue": "Proceedings of the 12th International Conference on Logic Programming (ICLP'95), pp. 715{729.", "citeRegEx": "Sato,? 1995", "shortCiteRegEx": "Sato", "year": 1995}, {"title": "Modeling scienti c theories as PRISM programs", "author": ["T. Sato"], "venue": "Proceedings of ECAI'98 Workshop on Machine Discovery, pp. 37{45.", "citeRegEx": "Sato,? 1998", "shortCiteRegEx": "Sato", "year": 1998}, {"title": "Minimum likelihood estimation from negative examples in statistical abduction", "author": ["T. Sato"], "venue": "Proceedings of IJCAI-01 workshop on Abductive Reasoning, pp. 41{47.", "citeRegEx": "Sato,? 2001", "shortCiteRegEx": "Sato", "year": 2001}, {"title": "PRISM: a language for symbolic-statistical modeling", "author": ["T. Sato", "Y. Kameya"], "venue": "In Proceedings of the 15th International Joint Conference on Arti cial Intelligence", "citeRegEx": "Sato and Kameya,? \\Q1997\\E", "shortCiteRegEx": "Sato and Kameya", "year": 1997}, {"title": "A Viterbi-like algorithm and EM learning for statistical abduction", "author": ["T. Sato", "Y. Kameya"], "venue": "In Proceedings of UAI2000 Workshop on Fusion of Domain Knowledge with Data for Decision Support", "citeRegEx": "Sato and Kameya,? \\Q2000\\E", "shortCiteRegEx": "Sato and Kameya", "year": 2000}, {"title": "Fast EM learning of a family of PCFGs", "author": ["T. Sato", "Y. Kameya", "S. Abe", "K. Shirai"], "venue": "Titech technical report (Dept. of CS) TR01-0006,", "citeRegEx": "Sato et al\\.,? \\Q2001\\E", "shortCiteRegEx": "Sato et al\\.", "year": 2001}, {"title": "Linear tabulated resolution based on Prolog control strategy", "author": ["Y. Shen", "L. Yuan", "J. You", "N. Zhou"], "venue": "Theory and Practice of Logic Programming,", "citeRegEx": "Shen et al\\.,? \\Q2001\\E", "shortCiteRegEx": "Shen et al\\.", "year": 2001}, {"title": "The Art of Prolog", "author": ["L. Sterling", "E. Shapiro"], "venue": null, "citeRegEx": "Sterling and Shapiro,? \\Q1986\\E", "shortCiteRegEx": "Sterling and Shapiro", "year": 1986}, {"title": "An e cient probabilistic context-free parsing algorithm that computes pre x probabilities", "author": ["A. Stolcke"], "venue": "Computational Linguistics, 21 (2), 165{201.", "citeRegEx": "Stolcke,? 1995", "shortCiteRegEx": "Stolcke", "year": 1995}, {"title": "Unfold/fold transformation of logic programs", "author": ["H. Tamaki", "T. Sato"], "venue": "In Proceedings of the 2nd International Conference on Logic Programming (ICLP'84), Lecture Notes in Computer Science,", "citeRegEx": "Tamaki and Sato,? \\Q1984\\E", "shortCiteRegEx": "Tamaki and Sato", "year": 1984}, {"title": "OLD resolution with tabulation", "author": ["H. Tamaki", "T. Sato"], "venue": "In Proceedings of the 3rd International Conference on Logic Programming (ICLP'86),", "citeRegEx": "Tamaki and Sato,? \\Q1986\\E", "shortCiteRegEx": "Tamaki and Sato", "year": 1986}, {"title": "Japanese grammar for speech recognition considering the MSLR method", "author": ["H. Tanaka", "T. Takezawa", "J. Etoh"], "venue": "In Proceedings of the meeting of SIG-SLP (Spoken Language Processing),", "citeRegEx": "Tanaka et al\\.,? \\Q1997\\E", "shortCiteRegEx": "Tanaka et al\\.", "year": 1997}, {"title": "ATR integrated speech and language database", "author": ["N. Uratani", "T. Takezawa", "H. Matsuo", "C. Morita"], "venue": "Technical report TR-IT-0056,", "citeRegEx": "Uratani et al\\.,? \\Q1994\\E", "shortCiteRegEx": "Uratani et al\\.", "year": 1994}, {"title": "Memoing for logic programs", "author": ["D.S. Warren"], "venue": "Communications of the ACM, 35 (3), 93{111.", "citeRegEx": "Warren,? 1992", "shortCiteRegEx": "Warren", "year": 1992}, {"title": "Probabilistic languages: a review and some open questions", "author": ["C.S. Wetherell"], "venue": "Computing Surveys, 12 (4), 361{379.", "citeRegEx": "Wetherell,? 1980", "shortCiteRegEx": "Wetherell", "year": 1980}, {"title": "An Anatomy of Kinship", "author": ["H.C. White"], "venue": "Prentice-Hall.", "citeRegEx": "White,? 1963", "shortCiteRegEx": "White", "year": 1963}, {"title": "Exploiting causal independence in Bayesian network inference", "author": ["N. Zhang", "D. Poole"], "venue": "Journal of Arti cial Intelligence Research,", "citeRegEx": "Zhang and Poole,? \\Q1996\\E", "shortCiteRegEx": "Zhang and Poole", "year": 1996}], "referenceMentions": [{"referenceID": 29, "context": "4 Statistical abduction is powerful in that it not only subsumes diverse symbolic-statistical frameworks such as HMMs (hidden Markov models, Rabiner, 1989), PCFGs (probabilistic context free grammars, Wetherell, 1980; Manning & Sch\u007f utze, 1999) and (discrete) Bayesian networks (Pearl, 1988; Castillo, Gutierrez, & Hadi, 1997) but gives us freedom of using arbitrarily complex logic programs for modeling.", "startOffset": 278, "endOffset": 326}, {"referenceID": 42, "context": "The semantic basis for statistical abduction is distribution semantics introduced by Sato (1995). It de nes a parameterized distribution, actually a probability measure, over the set of possible truth assignments to ground atoms and enables us to derive a new EM algorithm 6", "startOffset": 85, "endOffset": 97}, {"referenceID": 55, "context": "Redundancy in the rst phase is eliminated by tabulating partial explanations using OLDT search (Tamaki & Sato, 1986; Warren, 1992; Sagonas, T., & Warren, 1994; Ramakrishnan, Rao, Sagonas, Swift, & Warren, 1995; Shen, Yuan, You, & Zhou, 2001).", "startOffset": 95, "endOffset": 241}, {"referenceID": 21, "context": "A program including general clauses is sometimes called a general program (Lloyd, 1984; Doets, 1994).", "startOffset": 74, "endOffset": 100}, {"referenceID": 8, "context": "A program including general clauses is sometimes called a general program (Lloyd, 1984; Doets, 1994).", "startOffset": 74, "endOffset": 100}, {"referenceID": 8, "context": "A program including general clauses is sometimes called a general program (Lloyd, 1984; Doets, 1994). 2. Throughout this paper, for familiarity and readability, we will somewhat loosely use \\distribution\" as a synonym for \\probability measure\". 3. In logic programming, the adjective \\ground\" means no variables contained. 4. Abduction means inference to the best explanation for a set of observations. Logically, it is formalized as a search for an explanation E such that E;KB ` G where G is an atom representing our observation, KB a knowledge base and E a conjunction of atoms chosen from abducibles, i.e. a class of formulas allowed as primitive hypotheses (Kakas, Kowalski, & Toni, 1992; Flach & Kakas, 2000). E must be consistent with KB. 5. Existing symbolic-statistical modeling frameworks have restrictions and limitations of various types compared with arbitrary logic programs (see Section 7 for details). For example, Bayesian networks do not allow recursion. HMMs and PCFGs, stochastic grammars, allow recursion but lack variables and data structures. Recursive logic programs are allowed in Ngo and Haddawy's (1997) framework but they assume domains are nite and function symbols seem prohibited.", "startOffset": 88, "endOffset": 1131}, {"referenceID": 35, "context": "the Baum-Welch algorithm for HMMs (Rabiner, 1989) and the Inside-Outside algorithm for PCFGs (Baker, 1979), despite its generality.", "startOffset": 34, "endOffset": 49}, {"referenceID": 3, "context": "the Baum-Welch algorithm for HMMs (Rabiner, 1989) and the Inside-Outside algorithm for PCFGs (Baker, 1979), despite its generality.", "startOffset": 93, "endOffset": 106}, {"referenceID": 21, "context": "The reader is assumed to be familiar with the basics of logic programming (Lloyd, 1984; Doets, 1994), probability theory (Chow & Teicher, 1997), Bayesian networks (Pearl, 1988; Castillo et al.", "startOffset": 74, "endOffset": 100}, {"referenceID": 8, "context": "The reader is assumed to be familiar with the basics of logic programming (Lloyd, 1984; Doets, 1994), probability theory (Chow & Teicher, 1997), Bayesian networks (Pearl, 1988; Castillo et al.", "startOffset": 74, "endOffset": 100}, {"referenceID": 29, "context": "The reader is assumed to be familiar with the basics of logic programming (Lloyd, 1984; Doets, 1994), probability theory (Chow & Teicher, 1997), Bayesian networks (Pearl, 1988; Castillo et al., 1997) and stochastic grammars (Rabiner, 1989; Manning & Sch\u007f utze, 1999).", "startOffset": 163, "endOffset": 199}, {"referenceID": 35, "context": ", 1997) and stochastic grammars (Rabiner, 1989; Manning & Sch\u007f utze, 1999).", "startOffset": 32, "endOffset": 74}, {"referenceID": 29, "context": "sc-BN is a shorthand for a singly connected Bayesian network (Pearl, 1988).", "startOffset": 61, "endOffset": 74}, {"referenceID": 21, "context": "9 Usually there is more than one refutation for G, and the search space for all refutations is described by an SLD tree which may be in nite depending on the program and the goal (Lloyd, 1984; Doets, 1994).", "startOffset": 179, "endOffset": 205}, {"referenceID": 8, "context": "9 Usually there is more than one refutation for G, and the search space for all refutations is described by an SLD tree which may be in nite depending on the program and the goal (Lloyd, 1984; Doets, 1994).", "startOffset": 179, "endOffset": 205}, {"referenceID": 55, "context": "OLDT is such an instance of memoizing scheme (Tamaki & Sato, 1986; Warren, 1992; Sagonas et al., 1994; Ramakrishnan et al., 1995; Shen et al., 2001).", "startOffset": 45, "endOffset": 148}, {"referenceID": 41, "context": "OLDT is such an instance of memoizing scheme (Tamaki & Sato, 1986; Warren, 1992; Sagonas et al., 1994; Ramakrishnan et al., 1995; Shen et al., 2001).", "startOffset": 45, "endOffset": 148}, {"referenceID": 37, "context": "OLDT is such an instance of memoizing scheme (Tamaki & Sato, 1986; Warren, 1992; Sagonas et al., 1994; Ramakrishnan et al., 1995; Shen et al., 2001).", "startOffset": 45, "endOffset": 148}, {"referenceID": 48, "context": "OLDT is such an instance of memoizing scheme (Tamaki & Sato, 1986; Warren, 1992; Sagonas et al., 1994; Ramakrishnan et al., 1995; Shen et al., 2001).", "startOffset": 45, "endOffset": 148}, {"referenceID": 35, "context": "The development of a concrete EM algorithm such as the Baum-Welch algorithm for HMMs (Rabiner, 1989) and the Inside-Outside algorithm for PCFGs (Baker, 1979) requires individual e ort for each case.", "startOffset": 85, "endOffset": 100}, {"referenceID": 3, "context": "The development of a concrete EM algorithm such as the Baum-Welch algorithm for HMMs (Rabiner, 1989) and the Inside-Outside algorithm for PCFGs (Baker, 1979) requires individual e ort for each case.", "startOffset": 144, "endOffset": 157}, {"referenceID": 21, "context": "Next we extend it to a probability space over the Herbrand interpretations of all ground atoms in L by using the least model semantics (Lloyd, 1984; Doets, 1994).", "startOffset": 135, "endOffset": 161}, {"referenceID": 8, "context": "Next we extend it to a probability space over the Herbrand interpretations of all ground atoms in L by using the least model semantics (Lloyd, 1984; Doets, 1994).", "startOffset": 135, "endOffset": 161}, {"referenceID": 42, "context": "The choice of parameterized nite distributions made by Sato (1995) was simple:", "startOffset": 55, "endOffset": 67}, {"referenceID": 42, "context": "It might look too simple but expressive enough for Bayesian networks, Markov chains and HMMs (Sato, 1995; Sato & Kameya, 1997).", "startOffset": 93, "endOffset": 126}, {"referenceID": 21, "context": "Herbrand model (Lloyd, 1984; Doets, 1994).", "startOffset": 15, "endOffset": 41}, {"referenceID": 8, "context": "Herbrand model (Lloyd, 1984; Doets, 1994).", "startOffset": 15, "endOffset": 41}, {"referenceID": 21, "context": "Then imagine a de nite clause program DB 0 = R [ F and its least Herbrand model M DB 0 (Lloyd, 1984; Doets, 1994).", "startOffset": 87, "endOffset": 113}, {"referenceID": 8, "context": "Then imagine a de nite clause program DB 0 = R [ F and its least Herbrand model M DB 0 (Lloyd, 1984; Doets, 1994).", "startOffset": 87, "endOffset": 113}, {"referenceID": 21, "context": "Likewise comp(R) is a rst-order theory which deductively simulates SLD refutation with the help of E q by replacing a clause head atom with the clause body (Lloyd, 1984; Doets, 1994).", "startOffset": 156, "endOffset": 182}, {"referenceID": 8, "context": "Likewise comp(R) is a rst-order theory which deductively simulates SLD refutation with the help of E q by replacing a clause head atom with the clause body (Lloyd, 1984; Doets, 1994).", "startOffset": 156, "endOffset": 182}, {"referenceID": 40, "context": "This de nition of a support set di ers from the one used by Sato (1995) and Kameya and Sato (2000).", "startOffset": 60, "endOffset": 72}, {"referenceID": 11, "context": "This de nition of a support set di ers from the one used by Sato (1995) and Kameya and Sato (2000). 19.", "startOffset": 76, "endOffset": 99}, {"referenceID": 7, "context": "The uniqueness condition guarantees that there exists a (many-to-one) mapping from explanations to observations so that the EM algorithm is applicable (Dempster et al., 1977).", "startOffset": 151, "endOffset": 174}, {"referenceID": 7, "context": "The uniqueness condition guarantees that there exists a (many-to-one) mapping from explanations to observations so that the EM algorithm is applicable (Dempster et al., 1977). It is possible, however, to relax the uniqueness condition while justifying the application of the EM algorithm. We assume the MAR (missing at random) condition introduced by Rubin (1976) which is a statistical condition on how a complete data (explanation) becomes an incomplete data (observation), and is customarily assumed implicitly or explicitly in statistics (see Appendix B).", "startOffset": 152, "endOffset": 364}, {"referenceID": 3, "context": "In this subsection, we generalize the notion of inside probability and outside probability (Baker, 1979; Lari & Young, 1990) to logic programs.", "startOffset": 91, "endOffset": 124}, {"referenceID": 55, "context": "One way to obtain such t-explanations is to use OLDT search (Tamaki & Sato, 1986; Warren, 1992), a complete refutation method for logic programs.", "startOffset": 60, "endOffset": 95}, {"referenceID": 11, "context": "We describe here an e cient EM learning algorithm termed the graphical EM algorithm (Figure 8) introduced by Kameya and Sato (2000), that runs on support graphs.", "startOffset": 109, "endOffset": 132}, {"referenceID": 11, "context": "A formal proof is given by Kameya (2000). It is proved there that under the common parameters , [i; v] in learn-naive(DB,G) coincides with [i; v] in learn-gEM(DB,G).", "startOffset": 27, "endOffset": 41}, {"referenceID": 35, "context": "The standard EM algorithm for HMMs is the Baum-Welch algorithm (Rabiner, 1989; Rabiner & Juang, 1993).", "startOffset": 63, "endOffset": 101}, {"referenceID": 40, "context": "Sagonas et al. (1994) and Ramakrishnan et al.", "startOffset": 0, "endOffset": 22}, {"referenceID": 37, "context": "(1994) and Ramakrishnan et al. (1995) discuss about the implementation of OLDT.", "startOffset": 11, "endOffset": 38}, {"referenceID": 35, "context": "By the way, the Viterbi algorithm (Rabiner, 1989; Rabiner & Juang, 1993) provides for HMMs an e cient way of nding the most likely transition path for a given input/output string.", "startOffset": 34, "endOffset": 72}, {"referenceID": 3, "context": "We now compare the graphical EM algorithm with the Inside-Outside algorithm (Baker, 1979; Lari & Young, 1990).", "startOffset": 76, "endOffset": 109}, {"referenceID": 56, "context": "The Inside-Outside algorithm is a well-known EM algorithm for PCFGs (Wetherell, 1980; Manning & Sch\u007f utze, 1999).", "startOffset": 68, "endOffset": 112}, {"referenceID": 29, "context": "Bayesian networks are a representational/computational framework that ts best this type of probabilistic inference (Pearl, 1988; Castillo et al., 1997).", "startOffset": 115, "endOffset": 151}, {"referenceID": 29, "context": "In such case, the computation is possible in O(jV j) time where V is the set of vertices in the graph (Pearl, 1988).", "startOffset": 102, "endOffset": 115}, {"referenceID": 29, "context": "E cient computation of marginal distributions is not always possible but there is a well-known class of Bayesian networks, singly connected Bayesian networks, for which there exists an e cient algorithm to compute marginal distributions by message passing (Pearl, 1988; Castillo et al., 1997).", "startOffset": 256, "endOffset": 292}, {"referenceID": 29, "context": "O(jV j) is the time complexity required to compute a marignal distribution for a singly connected Bayesian network by a standard algorithm (Pearl, 1988; Castillo et al., 1997), and also is that of the EM algorithm using it.", "startOffset": 139, "endOffset": 175}, {"referenceID": 42, "context": "jp/prism/) as an implementation of distribution semantics (Sato, 1995; Sato & Kameya, 1997; Sato, 1998).", "startOffset": 58, "endOffset": 103}, {"referenceID": 43, "context": "jp/prism/) as an implementation of distribution semantics (Sato, 1995; Sato & Kameya, 1997; Sato, 1998).", "startOffset": 58, "endOffset": 103}, {"referenceID": 11, "context": "Detalis are reported by Sato, Kameya, Abe, and Shirai (2001). Before proceeding, we review the Inside-Outside algorithm for completeness.", "startOffset": 30, "endOffset": 61}, {"referenceID": 3, "context": "The Inside-Outside algorithm was proposed by Baker (1979) as a generalization of the Baum-Welch algorithm to PCFGs.", "startOffset": 45, "endOffset": 58}, {"referenceID": 3, "context": "The Inside-Outside algorithm was proposed by Baker (1979) as a generalization of the Baum-Welch algorithm to PCFGs. The algorithm is designed to estimate parameters for a CFG grammar in Chomsky normal form containing rules expressed by numbers like i! j; k (1 i; j; k N for N nonterminals, where 1 is a starting symbol). Suppose an input sentence w 1 ; : : : ; w L is given. In each iteration, it rst computes in a bottom up manner inside probabilities e(s; t; i) = P (i ) w s ; : : : ; w t ) and then computes outside probabilities f(s; t; i) = P (S ) w 1 ; : : : ; w s 1 i w t+1 ; : : : ; w L ) in a top-down manner for every s, t and i (1 s t L; 1 i N). After computing both probabilities, parameters are updated by using them, and this process iterates until some predetermined criterion such as a convergence of the likelihood of the input sentence is achieved. Although Baker did not give any analysis of the Inside-Outside algorithm, Lari and Young (1990) showed that it takes O(N 3 L 3 ) time in one iteration and La erty (1993) proved that it is the EM algorithm.", "startOffset": 45, "endOffset": 963}, {"referenceID": 3, "context": "The Inside-Outside algorithm was proposed by Baker (1979) as a generalization of the Baum-Welch algorithm to PCFGs. The algorithm is designed to estimate parameters for a CFG grammar in Chomsky normal form containing rules expressed by numbers like i! j; k (1 i; j; k N for N nonterminals, where 1 is a starting symbol). Suppose an input sentence w 1 ; : : : ; w L is given. In each iteration, it rst computes in a bottom up manner inside probabilities e(s; t; i) = P (i ) w s ; : : : ; w t ) and then computes outside probabilities f(s; t; i) = P (S ) w 1 ; : : : ; w s 1 i w t+1 ; : : : ; w L ) in a top-down manner for every s, t and i (1 s t L; 1 i N). After computing both probabilities, parameters are updated by using them, and this process iterates until some predetermined criterion such as a convergence of the likelihood of the input sentence is achieved. Although Baker did not give any analysis of the Inside-Outside algorithm, Lari and Young (1990) showed that it takes O(N 3 L 3 ) time in one iteration and La erty (1993) proved that it is the EM algorithm.", "startOffset": 45, "endOffset": 1037}, {"referenceID": 3, "context": "The Inside-Outside algorithm was proposed by Baker (1979) as a generalization of the Baum-Welch algorithm to PCFGs. The algorithm is designed to estimate parameters for a CFG grammar in Chomsky normal form containing rules expressed by numbers like i! j; k (1 i; j; k N for N nonterminals, where 1 is a starting symbol). Suppose an input sentence w 1 ; : : : ; w L is given. In each iteration, it rst computes in a bottom up manner inside probabilities e(s; t; i) = P (i ) w s ; : : : ; w t ) and then computes outside probabilities f(s; t; i) = P (S ) w 1 ; : : : ; w s 1 i w t+1 ; : : : ; w L ) in a top-down manner for every s, t and i (1 s t L; 1 i N). After computing both probabilities, parameters are updated by using them, and this process iterates until some predetermined criterion such as a convergence of the likelihood of the input sentence is achieved. Although Baker did not give any analysis of the Inside-Outside algorithm, Lari and Young (1990) showed that it takes O(N 3 L 3 ) time in one iteration and La erty (1993) proved that it is the EM algorithm. While it is true that the Inside-Outside algorithm has been recognized as a standard EM algortihm for training PCFGs, it is notoriously slow. Although there is not much literature explicitly stating time required by the Inside-Outside algorithm (Carroll & Rooth, 1998; Beil, Carroll, Prescher, Riezler, & Rooth, 1999), Beil et al. (1999) reported for example that when they trained a PCFG with 5,508 rules for a corpus of 450,526 German subordinate clauses whose average ambiguity is 9,202 trees/clause using four machines (167MHz Sun UltraSPARC 2 and 296MHz Sun UltraSPARC-II 2), it took 2.", "startOffset": 45, "endOffset": 1411}, {"referenceID": 53, "context": "As a skeleton of PCFG, we employed a context free grammar G atr comprising 860 rules (172 nonterminals and 441 terminals) manually developed for ATR corpus (Tanaka et al., 1997) which yields 958 parses/sentence.", "startOffset": 156, "endOffset": 177}, {"referenceID": 13, "context": "Actually Kita gave a re ned InsideOutside algorithm (Kita, 1999).", "startOffset": 52, "endOffset": 64}, {"referenceID": 47, "context": "We therefore conducted learning experiments with the entire ATR corpus using these two implementations and measured updating time per iteration (Sato et al., 2001).", "startOffset": 144, "endOffset": 163}, {"referenceID": 47, "context": "Assuming 100 iterations for learning ATR corpus however, it is estimated that even considering parsing time, the graphical EM algorithm combined with MSLR parser runs orders of magnitude faster than the three implementations (ours, Kita's and Johnson's) of the Inside-Outside algorithm (Sato et al., 2001).", "startOffset": 286, "endOffset": 305}, {"referenceID": 3, "context": "Since we implemented the Inside-Outside algorithm faithfully to Baker (1979), Lari and Young (1990), there is much room for improvement.", "startOffset": 64, "endOffset": 77}, {"referenceID": 3, "context": "Since we implemented the Inside-Outside algorithm faithfully to Baker (1979), Lari and Young (1990), there is much room for improvement.", "startOffset": 64, "endOffset": 100}, {"referenceID": 50, "context": "Finally we remark that the use of parsing as a preprocess for EM learning of PCFGs is not unique to the graphical EM algorithm (Fujisaki, Jelinek, Cocke, Black, & Nishino, 1989; Stolcke, 1995).", "startOffset": 127, "endOffset": 192}, {"referenceID": 50, "context": "Finally we remark that the use of parsing as a preprocess for EM learning of PCFGs is not unique to the graphical EM algorithm (Fujisaki, Jelinek, Cocke, Black, & Nishino, 1989; Stolcke, 1995). These approaches however still seem to contain redundancies compared with the graphical EM algorithm. For instance Stolcke (1995) uses an Earley chart to compute inside and outside probability, but parses are implicitly reconstructed in each iteration dynamically by combining completed items.", "startOffset": 178, "endOffset": 324}, {"referenceID": 28, "context": "A typical constraint approach is seen in the early work of probabilistic logic by Nilsson (1986). His central problem, \\probabilistic entailment problem\", is to compute the upper and lower bound of probability P( ) of a target sentence in such a way that the bounds are compatible with a given knowledge base containing logical sentences (not necessarily logic programs) annotated with a probability.", "startOffset": 82, "endOffset": 97}, {"referenceID": 41, "context": "Linguistic evaluations of the estimated parameters by the graphical EM algorithm are also reported by Sato et al. (2001). 65.", "startOffset": 102, "endOffset": 121}, {"referenceID": 16, "context": "For logic(s) concerning uncertainty, see an overview by Kyburg (1994).", "startOffset": 56, "endOffset": 70}, {"referenceID": 21, "context": "Later Lukasiewicz (1999) investigated the computational complexity of the probabilistic entailment problem in a slightly di erent setting.", "startOffset": 6, "endOffset": 25}, {"referenceID": 21, "context": "Later Lukasiewicz (1999) investigated the computational complexity of the probabilistic entailment problem in a slightly di erent setting. His knowledge base comprises statements of the form (H j G)[u 1 ; u 2 ] representing u 1 P(H j G) u 2 . He showed that inferring \\tight\" u 1 ; u 2 is NP-hard in general, and proposed a tractable class of knowledge base called conditional constraint trees. After the in uential work of Nilsson, Frish and Haddawy (1994) introduced a deductive system for probabilistic logic that remedies \\drawbacks\" of Nilsson's approach, that of computational intractability and the lack of a proof system.", "startOffset": 6, "endOffset": 458}, {"referenceID": 21, "context": "Later Lukasiewicz (1999) investigated the computational complexity of the probabilistic entailment problem in a slightly di erent setting. His knowledge base comprises statements of the form (H j G)[u 1 ; u 2 ] representing u 1 P(H j G) u 2 . He showed that inferring \\tight\" u 1 ; u 2 is NP-hard in general, and proposed a tractable class of knowledge base called conditional constraint trees. After the in uential work of Nilsson, Frish and Haddawy (1994) introduced a deductive system for probabilistic logic that remedies \\drawbacks\" of Nilsson's approach, that of computational intractability and the lack of a proof system. Their system deduces a probability range of a proposition by rules of probabilistic inferences about unconditional and conditional probabilities. For instance, one of the rules infers P ( j ) 2 [0 y] from P ( _ j ) 2 [x y] where , and are propositional variables and [x y] (x y) designates a probability range. Turning to logic programming, probabilistic logic programming formalized by Ng and Subrahmanian (1992) and Dekhtyar and Subrahmanian (1997) was also a constraint approach.", "startOffset": 6, "endOffset": 1044}, {"referenceID": 21, "context": "Later Lukasiewicz (1999) investigated the computational complexity of the probabilistic entailment problem in a slightly di erent setting. His knowledge base comprises statements of the form (H j G)[u 1 ; u 2 ] representing u 1 P(H j G) u 2 . He showed that inferring \\tight\" u 1 ; u 2 is NP-hard in general, and proposed a tractable class of knowledge base called conditional constraint trees. After the in uential work of Nilsson, Frish and Haddawy (1994) introduced a deductive system for probabilistic logic that remedies \\drawbacks\" of Nilsson's approach, that of computational intractability and the lack of a proof system. Their system deduces a probability range of a proposition by rules of probabilistic inferences about unconditional and conditional probabilities. For instance, one of the rules infers P ( j ) 2 [0 y] from P ( _ j ) 2 [x y] where , and are propositional variables and [x y] (x y) designates a probability range. Turning to logic programming, probabilistic logic programming formalized by Ng and Subrahmanian (1992) and Dekhtyar and Subrahmanian (1997) was also a constraint approach.", "startOffset": 6, "endOffset": 1081}, {"referenceID": 18, "context": "A similar framework was proposed by Lakshmanan and Sadri (1994) under the same syntactic restrictions ( nitely many constant and predicate symbols but no function symbols) in a di erent uncertainty setting.", "startOffset": 36, "endOffset": 64}, {"referenceID": 29, "context": "(Pearl, 1988; Castillo et al., 1997).", "startOffset": 0, "endOffset": 36}, {"referenceID": 28, "context": "(Pearl, 1988; Castillo et al., 1997). Researchers in Bayesian networks have been seeking for a way of mixing Bayesian networks with a logical representation to increase their inherently propositional expressive power. Breese (1992) used logic programs to automatically build a Bayesian network from a query.", "startOffset": 1, "endOffset": 232}, {"referenceID": 27, "context": "Ngo and Haddawy (1997) extended Breese's approach by incorporating a mechanism re ecting context.", "startOffset": 0, "endOffset": 23}, {"referenceID": 32, "context": "Instead of de ning a local distribution for each query, Poole (1993) de ned a global distribution in his \\probabilistic Horn abduction\".", "startOffset": 56, "endOffset": 69}, {"referenceID": 2, "context": "Bacchus et al. (1996) used a much more powerful rst-order probabilistic language than clauses annotated with probabilities.", "startOffset": 0, "endOffset": 22}, {"referenceID": 28, "context": "Descriptive power con ned to nite domains is the most common limitation, which is due to the use of the linear programming technique (Nilsson, 1986), or due to the syntactic restrictions not allowing for in nitely many constant, function or predicate symbols (Ng & Subrahmanian, 1992; Lakshmanan & Sadri, 1994).", "startOffset": 133, "endOffset": 148}, {"referenceID": 25, "context": "In SLPs, P(A) and P(A ^ A) do not necessarily coincide because A and A^A may have di erent refutations (Muggleton, 1996; Cussens, 1999, 2001).", "startOffset": 103, "endOffset": 141}, {"referenceID": 26, "context": "Descriptive power con ned to nite domains is the most common limitation, which is due to the use of the linear programming technique (Nilsson, 1986), or due to the syntactic restrictions not allowing for in nitely many constant, function or predicate symbols (Ng & Subrahmanian, 1992; Lakshmanan & Sadri, 1994). Bayesian networks have the same limitation as well (only a nite number of random variables are representable). 68 Also there are various semantic/syntactic restrictions on logic programs. For instance the acyclicity condition imposed by Poole (1993) and Ngo and Haddawy (1997) prevents the unconditional use of clauses with local variables, and the range-restrictedness imposed by Muggleton (1996) and Cussens (1999) excludes programs such as the usual membership Prolog program.", "startOffset": 134, "endOffset": 562}, {"referenceID": 26, "context": "For instance the acyclicity condition imposed by Poole (1993) and Ngo and Haddawy (1997) prevents the unconditional use of clauses with local variables, and the range-restrictedness imposed by Muggleton (1996) and Cussens (1999) excludes programs such as the usual membership Prolog program.", "startOffset": 66, "endOffset": 89}, {"referenceID": 25, "context": "For instance the acyclicity condition imposed by Poole (1993) and Ngo and Haddawy (1997) prevents the unconditional use of clauses with local variables, and the range-restrictedness imposed by Muggleton (1996) and Cussens (1999) excludes programs such as the usual membership Prolog program.", "startOffset": 193, "endOffset": 210}, {"referenceID": 25, "context": "For instance the acyclicity condition imposed by Poole (1993) and Ngo and Haddawy (1997) prevents the unconditional use of clauses with local variables, and the range-restrictedness imposed by Muggleton (1996) and Cussens (1999) excludes programs such as the usual membership Prolog program.", "startOffset": 193, "endOffset": 229}, {"referenceID": 25, "context": "For instance the acyclicity condition imposed by Poole (1993) and Ngo and Haddawy (1997) prevents the unconditional use of clauses with local variables, and the range-restrictedness imposed by Muggleton (1996) and Cussens (1999) excludes programs such as the usual membership Prolog program. There is another type of problem, the possibility of assigning con icting probabilities to logically equivalent formulas. In SLPs, P(A) and P(A ^ A) do not necessarily coincide because A and A^A may have di erent refutations (Muggleton, 1996; Cussens, 1999, 2001). Consequently in SLPs, we would be in trouble if we naively interpret P(A) as the probability of A's being true. Also assigning probabilities to arbitrary quanti ed formulas seems out of scope of both approaches to SLPs. Last but not least, there is a big problem common to any approach using probabilities: where do the numbers come from? Generally speaking, if we use n binary random variables in a model, we have to determine 2 n probabilities to completely specify their joint distribution, and ful lling this requirement with reliable numbers quickly becomes impossible as n grows. The situation is even worse when there are unobservable variables in the model such as possible causes of a disease. Apparently parameter learning from observed data is a natural solution to this problem, but parameter learning of logic programs has not been well studied. Distribution semantics proposed by Sato (1995) was an attempt to solve these problems along the line of the global distribution approach.", "startOffset": 193, "endOffset": 1463}, {"referenceID": 15, "context": "Koller and Pfe er (1997) used in their approach to KBMC (knowledge-based model construction) EM learning to estimate parameters labeling clauses.", "startOffset": 0, "endOffset": 25}, {"referenceID": 15, "context": "Koller and Pfe er (1997) used in their approach to KBMC (knowledge-based model construction) EM learning to estimate parameters labeling clauses. They express probabilistic dependencies among events by de nite clauses annotated with probabilities, similarly to Ngo and Haddawy's (1997) approach, and locally build a Bayesian network relevant to the context and evidence as well as the", "startOffset": 0, "endOffset": 286}, {"referenceID": 15, "context": "However, RPMs (recursive probability models) proposed by Pfe er and Koller (2000) as an extension of Bayesian networks allow for in nitely many random variables.", "startOffset": 68, "endOffset": 82}, {"referenceID": 32, "context": "Dealing with a PCFG by a statically constructed Bayesian network was proposed Pynadath and Wellman (1998), and it is possible to combine the EM algorithm with their method to estimate parameters in the PCFG.", "startOffset": 78, "endOffset": 106}, {"referenceID": 32, "context": "Dealing with a PCFG by a statically constructed Bayesian network was proposed Pynadath and Wellman (1998), and it is possible to combine the EM algorithm with their method to estimate parameters in the PCFG. Unfortunately, the constructed network is not singly connected, and time complexity of probability computation is potentially exponential in the length of an input sentence. Closely related to our EM learning is parameter learning of log-linear models. Riezler (1998) proposed the IM algorithm in his approach to probabilistic constraint programming.", "startOffset": 78, "endOffset": 476}, {"referenceID": 32, "context": "Dealing with a PCFG by a statically constructed Bayesian network was proposed Pynadath and Wellman (1998), and it is possible to combine the EM algorithm with their method to estimate parameters in the PCFG. Unfortunately, the constructed network is not singly connected, and time complexity of probability computation is potentially exponential in the length of an input sentence. Closely related to our EM learning is parameter learning of log-linear models. Riezler (1998) proposed the IM algorithm in his approach to probabilistic constraint programming. The IM algorithm is a general parameter estimation algorithm from incomplete data for log-linear models whose probability function P(x) takes the form P(x) = Z 1 exp ( P n i=1 i i (x)) p 0 (x) where ( 1 ; : : : ; n ) are parameters to be estimated, i (x) the i-th feature of an observed object x and Z the normalizing constant. Since a feature can be any function of x, the log-linear model is highly exible and includes our distribution P msw as a special case of Z = 1. There is a price to pay however; the computational cost of Z. It requires a summation over exponentially many terms. To avoid the cost of exact computation, approximate computation by a Monte Carlo method is possible. Whichever one may choose however, learning time increases compared to the EM algorithm for Z = 1. The FAM (failure-adjusted maximization) algorithm proposed by Cussens (2001) is an EM algorithm applicable to pure normalized SLPs that may fail.", "startOffset": 78, "endOffset": 1424}, {"referenceID": 14, "context": "Being slightly tangential to EM learning, Koller et al. (1997) developed a functional modeling language de ning a probability distribution over symbolic structures in which they showed \\cashing\" of computed results leads to e cient probability computation of singly connected Bayesian networks and PCFGs.", "startOffset": 42, "endOffset": 63}, {"referenceID": 57, "context": "We have tried various types of modeling, besides stochastic grammars and Bayesian networks, such as the modeling of gene inheritance in the Kariera tribe (White, 1963) where the rules of bi-lateral cross-cousin marriage for four clans interact with the rules of genetic inheritance (Sato, 1998).", "startOffset": 154, "endOffset": 167}, {"referenceID": 43, "context": "We have tried various types of modeling, besides stochastic grammars and Bayesian networks, such as the modeling of gene inheritance in the Kariera tribe (White, 1963) where the rules of bi-lateral cross-cousin marriage for four clans interact with the rules of genetic inheritance (Sato, 1998).", "startOffset": 282, "endOffset": 294}, {"referenceID": 1, "context": "Also investigating the role of the acyclicity condition seems theoretically interesting as the acyclicity is often related to the learning of logic programs (Arimura, 1997; Reddy & Tadepalli, 1998).", "startOffset": 157, "endOffset": 197}, {"referenceID": 0, "context": "For instance, uni cation-based grammars such as HPSGs (Abney, 1997) may be a good target beyond PCFGs because they use feature structures logically describable, and the ambiguity of feature values seems to be expressible by a probability distribution.", "startOffset": 54, "endOffset": 67}, {"referenceID": 0, "context": "Also investigating the role of the acyclicity condition seems theoretically interesting as the acyclicity is often related to the learning of logic programs (Arimura, 1997; Reddy & Tadepalli, 1998). In this paper we only scratched the surface of individual research elds such as HMMs, PCFGs and Bayesian networks. Therefore, there remains much to be done about clarifying how experiences in each research eld are re ected in the framework of parameterized logic programs. For example, we need to clarify the relationship between symbolic approaches to Bayesian networks such as SPI (Li, Z. & D'Ambrosio, B., 1994) and our approach. Also it is unclear how a compiled approach using the junction tree algorithm for Bayesian networks can be incorporated into our approach. Aside from exact methods, approximate methods of probability computation specialized for parameterized logic programs must also be developed. There is also a direction of improving learning ability by introducing priors instead of ML estimation to cope with data sparseness. The introduction of basic distributions that make probabilistic switches correlated seems worth trying in the near future. It is also important to take advantage of the logical nature of our approach to handle uncertainty. For example, it is already shown by Sato (2001) that we can learn parameters from negative examples such as \\the grass is not wet\" but the treatment of negative examples in parameterized logic programs is still in its infancy.", "startOffset": 158, "endOffset": 1316}, {"referenceID": 21, "context": "This de nition is di erent from the usual one (Lloyd, 1984; Doets, 1994) as we are here talking at ground level.", "startOffset": 46, "endOffset": 72}, {"referenceID": 8, "context": "This de nition is di erent from the usual one (Lloyd, 1984; Doets, 1994) as we are here talking at ground level.", "startOffset": 46, "endOffset": 72}, {"referenceID": 7, "context": "In the original formulation of the EM algorithm by Dempster et al. (1977), it is assumed that there exists a many-to-one mapping y = (x) from a complete data x to an incomplete (observed) data y.", "startOffset": 51, "endOffset": 74}, {"referenceID": 40, "context": "Rubin (1976) derived two conditions on g (data are missing at random and data are observed at random) collectively called theMAR (missing at random) condition, and showed that if we assume a missing-data mechanism behind our observations that satis es the MAR condition, we may estimate parameters of the distribution over x by simply applying the EM algorithm to y, the observed data.", "startOffset": 0, "endOffset": 13}], "year": 2011, "abstractText": "We propose a logical/mathematical framework for statistical parameter learning of parameterized logic programs, i.e. de nite clause programs containing probabilistic facts with a parameterized distribution. It extends the traditional least Herbrand model semantics in logic programming to distribution semantics , possible world semantics with a probability distribution which is unconditionally applicable to arbitrary logic programs including ones for HMMs, PCFGs and Bayesian networks. We also propose a new EM algorithm, the graphical EM algorithm, that runs for a class of parameterized logic programs representing sequential decision processes where each decision is exclusive and independent. It runs on a new data structure called support graphs describing the logical relationship between observations and their explanations, and learns parameters by computing inside and outside probability generalized for logic programs. The complexity analysis shows that when combined with OLDT search for all explanations for observations, the graphical EM algorithm, despite its generality, has the same time complexity as existing EM algorithms, i.e. the Baum-Welch algorithm for HMMs, the Inside-Outside algorithm for PCFGs, and the one for singly connected Bayesian networks that have been developed independently in each research eld. Learning experiments with PCFGs using two corpora of moderate size indicate that the graphical EM algorithm can signi cantly outperform the Inside-Outside algorithm.", "creator": "dvi2ps"}}}