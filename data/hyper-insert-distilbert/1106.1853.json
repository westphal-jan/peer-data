{"id": "1106.1853", "review": {"conference": "arxiv", "VERSION": "v1", "DATE_OF_SUBMISSION": "9-Jun-2011", "title": "Intelligent decision: towards interpreting the Pe Algorithm", "abstract": "though the major human intelligence lies in considering the algorithm, namely the synthetic nature investigation of basic algorithms lies in the geometric classification, and the precise classification is hardly equal to outlier problem detection. this paper probably is directly based on presenting its initial past unpublished edition ( apr 2009 ), which discussed being an application part of ( pe ) algorithm in outlier detection problems for measuring time series data. the pe algorithm, nowadays also named differently as an rdd filtering algorithm, is originated essentially from behind the microsoft study articles on our general ai. frequently united with it, designed discrete modules can be used to realize kinds of tasks. creating a primary framework concerned both with the mind description through pe algorithm has been constructed in prior works. in publishing this concise paper, mostly we neglect complex background optimization and minor comparative description of the last early edition, carefully and directly discuss the data main geometric contents include complex longest k - turn distance subsequence delay problem, curve type outliers, futural directions constraints and related comments.", "histories": [["v1", "Thu, 9 Jun 2011 16:45:49 GMT  (454kb)", "http://arxiv.org/abs/1106.1853v1", null], ["v2", "Fri, 10 Jun 2011 13:53:05 GMT  (454kb)", "http://arxiv.org/abs/1106.1853v2", null], ["v3", "Tue, 23 Aug 2011 03:25:58 GMT  (578kb)", "http://arxiv.org/abs/1106.1853v3", "23pages, 12 figures, 7 tables"]], "reviews": [], "SUBJECTS": "cs.AI", "authors": ["ching-an hsiao", "xinchun tian"], "accepted": false, "id": "1106.1853"}, "pdf": {"name": "1106.1853.pdf", "metadata": {"source": "CRF", "title": "\u05e4 Algorithm: its past present, futue present and comments", "authors": ["Ching-an Hsiao", "Xinchun Tian"], "emails": ["xiao.qingan@nies.go.jp", "tianxc@fnal.gov"], "sections": [{"heading": null, "text": "The human intelligence lies in the algorithm, the nature of algorithms lies in the classification, and the classification is equal to outlier detection. This paper is based on its past unpublished edition (2009), which discussed an application of \u05e4 (pe) algorithm in outlier detection for time series data. The \u05e4 algorithm, also named as RDD algorithm, is originated from the study on general AI. United with it, designed modules can be used to realize kinds of tasks. A primary framework concerned with the mind through \u05e4 algorithm has been constructed in prior works. In this concise paper, we neglect background and minor description of the early edition, and directly discuss the main contents include longest k\u2013turn subsequence problem, curve type outliers, futural directions and related comments. In section \u201cPast Present\u201d, we keep all prior conclusions, though a little might be out of date."}, {"heading": "I. Past Present", "text": ""}, {"heading": "1. Relative deviation degree", "text": "A supplementary definition for outlier (Hsiao et al., 2008)\nDefinition 1: An outlier is an observation with a degree greater than a threshold in comparison\nwith other observations referred to or associated with one or more specified pattern.\nProblem 1: Given a time series data S1 as Fig. 1, suppose data match linear model, find out outliers. S1 = (3.1, 2.9, 2.85, 3, 3.05, 2.9, 3.2, 5.2, 8.5, 5.4, 5.3, 5.1, 3.1, 3.05, 3, 2.99, 3, 3.02, 3.2)\nFig.1. Regression lines for dataset S1\n0\n2\n4\n6\n8\n10\n0 2 4 6 8 10 12 14 16 18 20\ndata LS LTS\nBy classic LS regression, we get a line y=3.79-0.001x; and by robust LTS regression, line\ny=2.907+0.007x, as shown in Fig. 1. Based on the above definition, we present RDD (\u05e4) algorithm.\nGiven a time series data S = d1d2\u2026\u2026dN, denote point (i,di) by pi, and  pjpipk by  jik.\nRelative Deviant Degree: Algorithm 1 Input: time series data S Output: RDDs of S\n\u2022 Specify a similarity function sim(pk,(pi,pj))=exp(- jik^2/50), denoted by ij ks .\n\u2022 Specify an offset function off(pk,(pi,pj)): distance of k to line Lij, denoted by ij ko .\nfor ( i from 1 to N ) {\n   \n N\nip p\nN\nk\nip\nki sX 1 1\n   \n N\nip p\nN\nk\npi\nki sY 1 1\n}\nfor( i, j from 1 to N, j \u2260 i )\nwij = Xi  Yj\n\n\n\n\n\n\n\n\n\n\n\n N\nji\nij\nN\nji\nij\nij k\nN\nji\nij\nN\nji\nij\nij k\nk\nw\nwo\nw\nws\nRDD\n1,\n1,\n1,\n1,\n)()(\nln\nNotes\n1. Similarity function is used to evaluate the similar degree of point k related to the system of i\nand j.\n2. Offset function calculates the real distance between k and system of i and j. 3. wij is the weight of system of ij, denotes relative effective degree. 4. Relative deviant degree combines two measurements: similarity and real distance.\nBy this algorithm, to problem 1 we get RDD values in Table 1. Points at position 8, 9, 10, 11 and 12 have high values.\nThough the \u05e4 algorithm, similar with robust regressions, tries to evaluate others by choosing reliable \u201cgood\u201d data, it differs from robust ones at the point that we approach the problem from the inside structure of patterns and stress on a whole effect, thus with better balance. Note that the \u05e4 algorithm is with a highest breakdown point (50%) as same as the robust regressions. Now we modify our algorithm 1 to a general form. First, we introduce the definition of view.\nDefinition 2: Given a time series data S, a sub-series of S is also a time series where each element of it is an element of S. We denote e  S when e is a sub-series of S.\nDefinition 3: A view of S, V\u03b1, is a set of sub-series of S of the same length  , that is V\u03b1 = { e | e S, |e| =  }.\nAlgorithm 1\u2019: \u05e4 Algorithm\nInput: data set S Output: RDDs of S\n1. Let V\u03b1 be an evaluating view, e  V\u03b1 2. Give a similarity function sim: S\u00d7S \u03b1  [0,1], describing similar degree of each\nelement k in S by the view of V\u03b1, denoted by\n3. Give an offset function off: S\u00d7S \u03b1  , describing offset of each element k in S by\nthe view of V\u03b1, denoted by\n4. Define different weight we and RDDk by and 5. For any element e in V\u03b1\n\n0 R\ne\nkoff\ne ksim\ne ksim e koff\ncalculate we\n6. Calculate RDDk"}, {"heading": "2. Longest k \u2013turn subsequence", "text": "In this section, we present an expression for pattern \u201ccurve\u201d so that we can get a kind of view for \u05e4\nalgorithm. Outlier problem of time series data can be described as follows.\nProblem 2: Given a sequence S of length N, {d1, d2, \u2026 dN }, which matches pattern \u201ccurve\u201d, find outliers. An example is shown in Fig. 2.\nAs any curve can be expressed by several ordered sets hinged by several common points (turn points), we develop a dynamic programming algorithm to detect the order of curve type data, which can be traced to the longest increasing subsequence problem (Schensted, 1961). Firstly, we give a definition to \u201cturn\u201d.\nDefinition 4: Given a curve, except for boundary points, each extremum point is called a \u201cturn point\u201d; the number of extremum points is called turns. We denote maximum point by sign \u201c\uff0b\u201d, and minimum point by sign \u201c\uff0d \u201d. If a sequence S has t turns and the 1st one is a maximum/minimum points, then it is denoted by [\uff0b/\uff0d, t ]. [\uff0b, 0 ] denotes strictly increasing sequence, [\uff0d, 0 ] denotes strictly decreasing sequence.\nWe then introduce longest k-turn subsequence problem followed by the corresponding algorithm.\nProblem 3: Given a time series data S of length N, {d0, d1, \u2026, dN-1 }, with T turns, searching a longest subsequence having T turns by passing the first point p0 (0, d0).\nAlgorithm 2: The pseudo-code is shown below.\nDenote best + [i][t], the longest subsequence from point p0 to point pi with [\uff0b, t ] best \uff0d\n[i][t], the longest subsequence from point p0 to point pi with [\uff0d, t ]\nP + [i][t], predecessor point of pi in best + [i][t] P \uff0d [i][t], predecessor point of pi in best \uff0d [i][t]\nInput: time series data S Output: the longest T-turn subsequence starting from point p0.\nFunc route(S )\nInitialize best to {} for (t from 0 to T )\nfor (i from t +1 to N-1 )\nfor( j from t to i -1) {\nif(t==0&&j==0) { if(d[i]> d[j]) best + [i][t]={j, i}\nif(d[i]< d[j]) best \uff0d [i][t]={j, i} }\nif (d[i], d[j], d[P + [j][t]] is a strictly monotonic sequence)\nbest + [i][t]=max(best + [i][t], best + [j][t] {i})\nif (d[i], d[j], d[P + [j][t-1]] is not a monotonic sequence)\nbest + [i][t]=max(best + [i][t], best + [j][t-1] {i})\nif (d[i], d[j], d[P \uff0d [j][t]] is a strictly monotonic sequence)\nbest \uff0d [i][t]=max(best \uff0d [i][t], best \uff0d [j][t] {i})\nif (d[i], d[j], d[P \uff0d [j][t-1]] is not a monotonic sequence)\nbest \uff0d [i][t]=max(best \uff0d [i][t], best \uff0d [j][t-1] {i})\n}\nbest + [][T] = max(best + [i][T]) i=0,1,\u2026, N-1 best \uff0d [][T] = max(best \uff0d [i][T]) i=0,1,\u2026, N-1 Return max (best + [][T] , best \uff0d [][T] )\nAlgorithm 3 returns the longest T-turn subsequence by passing any point pi (i,di).\nAlgorithm 3:\nInput: time series data S Output: the longest T-turn subsequence by passing point pi.\n1. Divide the whole series data into two parts, S1: di, di-1,\u2026 d0; and S2: di, di+1,di+2, \u2026, dN-1. 2. Work out best1 + [][t] and best1 \uff0d [][t] in S1 on each t \u2264 T 3. Work out best2 + [][t] and best2 \uff0d [][t ]in S2 on each t \u2264 T 4. Combine them to identify the longest best + [][T] and best \uff0d [][T]\nReturn max(best + [][T], best \uff0d [][T] )"}, {"heading": "3. Time series data outlier", "text": "Following algorithm calculates the related RDD values for time series data.\nAlgorithm 4:\nDenote point(i, di) by pi, i=0, 1, \u2026, N-1 Specify a curve pattern [sign, T] Specify view: a curve with [sign, T] passing pi, Denote similarity function by , offset function by k=0, 1, \u2026, N-1\nInput: time series data S Output: RDDs of S\n1. To any pi , work out a subsequence P(S)i with T turns and maximum length by algorithm 3. 2. If P(S)i does not match pattern [sign, T]\n{\nLet = 0, = 0 (k \u2260 i)\n=1, = 0\n}\nElse\n{ if pk  P(S)i\n{ = 1, = 0 }\nelse\n{\ncalculate interpolation value of pk according to P(S)i, get vk. let = \u2223vk \uff0ddk \u2223 , let max=max(di) , min=min(di) i=0, 1, 2, \u2026, N-1 let coef=(max-min)/N normalize di, dk and vk by\n'\nid = (di -min) /coef\n'\nkd = (dk -min) /coef\n'\nkv = (vk -min) /coef\ndenote (i, ' id ) by pi\u2019, (k, ' kd ) by pk\u2019 and (k, ' kv ) by pj\u2019\ni ksim i koff\ni ksim i\nkoff i\nisim i ioff\ni koff\ni koff i ksim\ncalculating angle  pk\u2019 pi\u2019 pj\u2019 denoted by  j\u2019i\u2019k\u2019\n= exp (- j\u2019i\u2019k\u2019^2/50)\n}\n}\n3. Calculate RDDk by \u05e4 algorithm\nwith weight wi =\nand\n\n\n\n \n\n\n\n\n\n\n\n\n\n\n 1\n0\n1\n0\n1\n0\n1\n0\n)()(\nln N\ni\ni\nN\ni\ni\ni\nk\nN\ni\ni\nN\ni\ni\ni k\nk\nw\nwoff\nw\nwsim\nRDD\n4. Output outliers by Expanding Algorithm [Hsiao, 2010]\nNote: To any series sets, since outliers deviate from others, they may disturb some order of the sets. So we can use order or orders to descript the pattern. Definition 2 and corresponding algorithms hold true to any orders."}, {"heading": "4. Experiments and Discussion", "text": "Following experiments are based on the Algorithm 4. Original sine data are got from function )472sin( xy  , x is an integer in [0,47]. Outlier patches are introduced, size -1 to the x index 7, 8, 9, 10, and size +2 to the x index 28, 29, 30, 31, 32. Result is shown in Fig. 2. Table 2 lists corresponding RDD values of the related points. The first point whose IIR value is greater than 1.81\nFig.2. Synthetic data\n-1.5\n-1\n-0.5\n0\n0.5\n1\n1.5\n2\n0 10 20 30 40 50 60\nsi n e - o u tl ie r\n0\n2\n4\n6\n8\n10\n12\nR D D\nsin-outlier RDD\ni ksim\n \n\n1\n0\nN\nk\ni ksim\nis the 10 th point (calculating from 1), so all points above 10 (whose RDD values are not less than that of the10th) are confirmed as outliers. We see all outliers are correctly detected. T is equal to 2 here."}, {"heading": "1 29 11.6 -23.1 35 6715 -15.4", "text": ""}, {"heading": "2 33 11.6 -22.8 42 6425 -16.4", "text": ""}, {"heading": "3 30 11.5 -23.1 34 6275 4.0", "text": ""}, {"heading": "4 32 11.5 -23.1 44 3782 -10.1", "text": ""}, {"heading": "5 31 11.4 0.76 36 3304 -11.5", "text": ""}, {"heading": "6 8 5.7 -22.3 43 3025 -9.6", "text": ""}, {"heading": "7 11 5.6 -22.3 19 2480 11.7", "text": ""}, {"heading": "8 9 5.6 -22.5 30 557 0.7", "text": ""}, {"heading": "9 10 5.6 22.5 47 304 0.8", "text": ""}, {"heading": "10 48 0 0 4 149 -0.2", "text": "are listed in Fig. 3, Fig. 4, and Fig. 5. One is CO2 flux data, one is sensible heat flux data, and the other is latent heat flux data. Both achieved from Yucheng station, China.\nIn Fig. 3 and Fig. 4, apparent outliers (19, 34, 35, 36, 42, 43, 44 in Fig. 3 and 9,12,24,25 in Fig.\n4) are detected rightly. But point 30 in Fig. 3 and point 11 in Fig. 4 seem to be missed, though their RDD values are the closest ones to detected outliers (19 in Table 2 and 12 in Table 3). Did the algorithm fail? Actually, it would rather be said the two points do not appear so outstanding of the whole associated with the \u201cpattern\u201d we used than they are falsely undetected. And from following examples, we will see even in some hard cases our algorithm can work. It is undoubtedly that pattern \u201ccurve\u201d can not be completely expressed by order of data values. It includes other obvious or hidden patterns, like angle order etc. One aspect, we can only use data value order and so simply detect outliers; another aspect, if we exploit all patterns contained by curve, any tiny outliers must be detected correctly. It shows the power of \u05e4 algorithm. The \u05e4 algorithm treats outlier problem as pattern recognition problem, which is a view of wholism and makes both problems simplified. Following experiments furthermore indicate effectivity of \u05e4 algorithm.\nIn Fig. 5, points 17, 31, 25 are confirmed different from others. If not referred to a pattern, it is\nvery difficult to get such result. What we should note is that this time RDD values of 17, 31 and 25 are not so big, which indicates that the deviation to the whole is small.\nFig.3. Latent heat flux1 data\nFig.4. Sensible heat flux data\nFig.5. Co2 flux data\nThe last case is shown in Fig. 6, it is latent heat flux data of another day. The posterior half includes three outlier patches, respectively {35, 36}, {38, 39, 40, 41} and {43, 44, 45}, which makes the data\n-2500\n-2000\n-1500\n-1000\n-500\n0\n500\n1000\n1500\n2000\n0 10 20 30 40 50\nL E _7 5 0 0\n0\n1000\n2000\n3000\n4000\n5000\n6000\n7000\n8000\nR D D\nLE_7500 RDD\n-500\n-400\n-300\n-200\n-100\n0\n100\n0 10 20 30 40 50\nH _S at (W / m 2 )\n0\n500\n1000\n1500\n2000\n2500\nR D D\nH_Sat RDD\n-40\n-35\n-30\n-25\n-20\n-15\n-10\n-5\n0\n5\n10\n15\n0 10 20 30 40 50\nc o 2 - fl u x( \u03bc m o l/ m 2 )\n0\n5\n10\n15\n20\n25\n30\nR D D\nco2-flux RDD\nin a very mess. RDD and IIR values are listed in Table 4. Only point 39 and point 43 are identified. Other points in outlier patches have big RDD values, but it seems that they are masked. However, this mask effect is not same as others, because RDD values still reflect deviation correctly. In order to find out outliers completely, we might have two methods. One is to use the relationship among RDD values, RDDs\u2019 distribution and number N, which is our future work; another method is to do iterative calculation. After identifying outliers, remove them and calculate again until there is no outlier. In this way, we can get a serial of \u201cpure\u201d data. Such result to latent heat flux2 data is shown in Fig. 7. We can see a perfect 1-turn curve. Further study will work out a more effective method."}, {"heading": "6 39 96 -0.5 29 1.9 -1.1", "text": ""}, {"heading": "5 11 114 -0.5 22 2.1 -0.5", "text": ""}, {"heading": "4 12 382 5.1 30 2.6 0.8", "text": ""}, {"heading": "3 9 1409 17.2 25 3.7 2.2", "text": ""}, {"heading": "2 25 2019 -9.5 31 7.5 9.9", "text": ""}, {"heading": "1 24 2074 -22.0 17 12.6 4.9", "text": "Fig.7. Iterative result for Latent heat flux2 data"}, {"heading": "II. Futural Present", "text": ""}, {"heading": "1. A new example", "text": "The research was hanged up in 2009 for some special reasons. It is stimulated by a student in St. Louis. Here is a new example (Fig. 8), and the same algorithm is adpoted. We give a detailed analysis to complement past conclusions. Before giving the result, we can imagine our own answer. The disturbed points in our minds (natural principle) might be the fourth, 15 th , 16 th , 18 th , 22 nd , 24 th , 27 th , and the 36 th . If we remove these points, we can get a clean series like Fig. 9. One may have his own answer, based on his best principle.\nNow, let\u2019s see what the \u05e4 algorithm tells us. Table 4 lists all outliers with corresponding RDD\nvalues. When outliers are removed, the clean data look like Fig.10.\nFig.8. St. Louis data\n-3000\n-2500\n-2000\n-1500\n-1000\n-500\n0\n500\n1000\n1500\n2000\n0 10 20 30 40 50\nnormal outlier\n0\n0.1\n0.2\n0.3\n0.4\n0.5\n0.6\n0.7\n0.8\n0.9\n1\n0 10 20 30 40\nFig.9. Supposed clean St. Louis data\n0\n0.1\n0.2\n0.3\n0.4\n0.5\n0.6\n0.7\n0.8\n0.9\n0 10 20 30 40\nNow, let\u2019s see the difference and the reasons. The main difference lies in data of the 15 th , 16 th ,\n17 th and the 25 th . The reason that removes the 15 th , 16 th and 18 th data is that the 17 th datum keeps more consistent angle with others, however, in \u05e4 algorithm, this is not considered. From the view of longest sequence, the 15 th and 16 th data should be kept. Then why was the 25 th datum labelled as bad one? In fact, the algorithm was simplied in processing multiple equal length sequence, where a random one was selected. In this way, the 24 th and 25 th data are all in a position that is selected by half chance. What we have to note again is that conclusion is view-driven. The \u05e4 algorithm is the basis of general AI, all intelligent outputs can be verified by it and kinds of views equip the brain of AI. The \u05e4 algorithm is the hidden algorithm."}, {"heading": "2. Future work", "text": "It is predicted that when parellel equal-length sequences are treated impartially, the 24 th and 25 th data could be kept at the same time. And if angle consistency is considered, only the 24 th datum would be an outlier. In order to get a consitent result with human minds, we could increase necessary views. Once we are placed into a complete set, we get a complete knowledge. Other instant applications of \u05e4 algorithm lie in the fields of image processing, pattern recognition etc."}, {"heading": "III. Comments", "text": "We have to understand that there is no \u201cobjective\u201d outlier. If objectivity is expressed as main stream, we acknowledge that this kind of objectivity is a reasonable description. The Supreme Court has the power of final intepretation, the justice is nominted by the president, the president is selected by the all, and all are necessary to be honest. This is a kind of order. And this is what the \u05e4 algorithm tells us. What inner order we have, what external order we achieve. This is also what the Godel\u2019s Theorems show us. For an example, we might have incompatible academies, but never let them become a tomb towards Wall Street."}, {"heading": "Acknowledgements", "text": "The authors are grateful to Kelly Moor, and they would also like to thank Prof. Hsi-Chia Hsiao\nfor very useful discussion.\nReferences\nC.A. Hsiao, H. Chen, K. Furuse and N. Ohbo, 2008, A relative deviation detection for time series\ndata based on Equality, Proceedings of International Multi-Conference on Engineer and Computer Scientist Vol. 1, pp. 511-516.\nC.A. Hsiao, K. Furuse and N. Ohbo, 2009, Figure and ground: a complete approach to outlier\ndetection. IAENG Transactions on Engineering Technologies Vol. 1, Ao, S.-L., Chan, A. H.-S., Katagiri, H., Castillo, O. & Xu, L. (Eds.), 70-81, American Institute of Physics, New York.\nC.A. Hsiao, 2010, On classification from the view of outlier. IAENG International Journal of\nComputer Science, Vol. 37, 4.\nC. Schensted, 1961, Longest increasing and decreasing subsequence, Canad. J. Math., 13, 179-191."}], "references": [{"title": "A relative deviation detection for time series", "author": ["C.A. Hsiao", "H. Chen", "K. Furuse", "N. Ohbo"], "venue": null, "citeRegEx": "Hsiao et al\\.,? \\Q2008\\E", "shortCiteRegEx": "Hsiao et al\\.", "year": 2008}, {"title": "On classification from the view of outlier", "author": ["H. Katagiri", "O. Castillo", "L. Xu"], "venue": "American Institute of Physics, New York. C.A. Hsiao,", "citeRegEx": "Katagiri et al\\.,? \\Q2010\\E", "shortCiteRegEx": "Katagiri et al\\.", "year": 2010}], "referenceMentions": [{"referenceID": 0, "context": "A supplementary definition for outlier (Hsiao et al., 2008)", "startOffset": 39, "endOffset": 59}], "year": 2011, "abstractText": "The human intelligence lies in the algorithm, the nature of algorithms lies in the classification, and the classification is equal to outlier detection. This paper is based on its past unpublished edition (2009), which discussed an application of \u05e4 (pe) algorithm in outlier detection for time series data. The \u05e4 algorithm, also named as RDD algorithm, is originated from the study on general AI. United with it, designed modules can be used to realize kinds of tasks. A primary framework concerned with the mind through \u05e4 algorithm has been constructed in prior works. In this concise paper, we neglect background and minor description of the early edition, and directly discuss the main contents include longest k\u2013turn subsequence problem, curve type outliers, futural directions and related comments. In section \u201cPast Present\u201d, we keep all prior conclusions, though a little might be out of date.", "creator": "Microsoft\u00ae Office Word 2007"}}}