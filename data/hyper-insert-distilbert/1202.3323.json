{"id": "1202.3323", "review": {"conference": "NIPS", "VERSION": "v1", "DATE_OF_SUBMISSION": "15-Feb-2012", "title": "Mirror Descent Meets Fixed Share (and feels no regret)", "abstract": "we investigate comparative extensions of current well - known online learning algorithms involving such classics as fixed - share of andreas herbster and george warmuth ( 1998 ) though or against the cluster methods proposed by bousquet perrin and larry warmuth ( 2002 ). these algorithms use weight sharing compression schemes to adequately perform as well as the best numerical sequence models of experts begin with just a systematically limited coordination number patterns of behavioral changes. indeed here \u2014 we actually show, culminating with a single common, general, and simpler analysis, that individual weight sharing in fact achieves much more than exceeds what it was designed reasonably for. moreover we use both it to simultaneously prove brand new shifting constant regret bounds again for online convex optimization challenges on the compact simplex in terms of the partial total variation distance as and well above as verify new bounds for the related setting of adaptive dynamic regret. finally, we exhibit indeed the first infinite logarithmic constant shifting marko bounds for exp - connected concave loss functions on the simplex.", "histories": [["v1", "Wed, 15 Feb 2012 14:39:42 GMT  (45kb)", "http://arxiv.org/abs/1202.3323v1", null], ["v2", "Thu, 27 Sep 2012 19:39:42 GMT  (40kb)", "http://arxiv.org/abs/1202.3323v2", null]], "reviews": [], "SUBJECTS": "cs.LG stat.ML", "authors": ["nicol\u00f2 cesa-bianchi", "pierre gaillard", "g\u00e1bor lugosi", "gilles stoltz"], "accepted": true, "id": "1202.3323"}, "pdf": {"name": "1202.3323.pdf", "metadata": {"source": "CRF", "title": null, "authors": ["Pierre Gaillard", "Gilles Stoltz"], "emails": ["NICOLO.CESA-BIANCHI@UNIMI.IT", "PIERRE.GAILLARD@ENS.FR", "GABOR.LUGOSI@UPF.EDU", "GILLES.STOLTZ@ENS.FR"], "sections": [{"heading": null, "text": "ar X\niv :1\n20 2.\n33 23\nv1 [\ncs .L\nG ]"}, {"heading": "1. Introduction", "text": "Online convex optimization is a sequential prediction paradigm in which, at each time step, the learner chooses an element from a fixed convex set S and then is given access to a convex loss function defined on the same set. The value of the function on the chosen element is the learner\u2019s loss. Many problems such as prediction with expert advice, sequential investment, and online regression/classification can be viewed as special cases of this general framework. Online learning algorithms are designed to minimize the regret. The standard notion of regret is the difference between the learner\u2019s cumulative loss and the cumulative loss of the single best element in S . A much harder criterion to minimize is shifting regret, which is defined as the difference between the learner\u2019s cumulative loss and the cumulative loss of an arbitrary sequence of elements in S . Shifting regret bounds are typically expressed in terms of the shift, a notion of regularity measuring the length of the trajectory in S described by the comparison sequence (i.e., the sequence of elements against which the regret is evaluated).\nIn online convex optimization, shifting regret bounds for convex subsets S \u2286 Rd are obtained for the online mirror descent (or follow-the-regularized-leader) algorithm. In this case the shift is\n\u2020. CNRS \u2013 Ecole normale sup\u00e9rieure, Paris \u2013 INRIA, within the project-team CLASSIC \u2020. CNRS \u2013 Ecole normale sup\u00e9rieure, Paris \u2013 INRIA, within the project-team CLASSIC\nc\u00a9 2012 .\ntypically computed in terms of the p-norm of the difference of consecutive elements in the comparison sequence \u2014see Herbster and Warmuth (2001) and Cesa-Bianchi and Lugosi (2006). In this paper we focus on the important special case when S is the simplex, and investigate the online mirror descent with entropic regularizers. This family includes popular algorithms such as exponentially weighted average (EWA), Winnow, and exponentiated gradient. Proving general shifting bounds in this case is difficult due to the behavior of the regularizer at the boundary of the simplex. Herbster and Warmuth (2001) show shifting bounds for mirror descent with entropic regularizers using a 1-norm to measure the shift. In order to keep mirror descent from choosing points too close to the simplex boundary, they use a complex dynamic projection technique. When the comparison sequence is restricted to the corners of the simplex (which is the setting of prediction with expert advice), then the shift is naturally defined to be the number times the trajectory moves to a different corner. This problem is often called \u201ctracking the best expert\u201d \u2014see, e.g., Herbster and Warmuth (1998); Vovk (1999); Herbster and Warmuth (2001); Bousquet and Warmuth (2002); Gy\u00f6rgy et al. (2005), and it is well known that EWA with weight sharing, which corresponds to the fixedshare algorithm of Herbster and Warmuth (1998), achieves a good shifting bound in this setting. Bousquet and Warmuth (2002) introduce a generalization of the fixed-share algorithm, and prove various shifting bounds for any trajectory in the simplex. However, their bounds are expressed using a quantity that corresponds to a proper shift only for trajectories on the simplex corners.\nOur analysis unifies, generalizes (and simplifies) the previously quite different proof techniques and algorithms used in Herbster and Warmuth (1998) and Bousquet and Warmuth (2002). Our bounds are expressed in terms of a notion of shift based on the total variation distance. The generalization of the \u201csmall expert set\u201d result in Bousquet and Warmuth (2002) leads us to obtain better bounds when the sequence against which the regret is measured is sparse. When the trajectory is restricted to the corners of the simplex, we recover, and occasionally improve, the known shifting bounds for prediction with expert advice. Besides, our analysis also captures the setting of adaptive regret, a related notion of regret introduced by Hazan and Seshadhri (2009). It was known that shifting regret and adaptive regret had some connections but this connection is now seen to be even tighter, as both regrets can be viewed as instances of the same alma mater regret, which we minimize. Finally, we also show how to dynamically tune the parameters of our algorithms and review briefly the special case of exp-concave loss functions, exhibiting the first logarithmic shifting bounds for exp-concave loss functions on the simplex."}, {"heading": "2. Preliminaries", "text": "We first define the sequential learning framework we work with. Even though our results hold in the general setting of online convex optimization, we present them in the, somewhat simpler, online linear optimization setup. We point out in Section 6 how these results may be generalized. Online linear optimization may be cast as a repeated game between the forecaster and the environment as follows. We use \u2206d to denote the simplex { q \u2208 [0, 1]d : \u2016q\u20161 = 1 } .\nOnline linear optimization. For each round t = 1, . . . , T , 1. Forecaster chooses p\u0302t = (p\u03021,t, . . . , p\u0302d,t) \u2208 \u2206d ; 2. Environment chooses a loss vector \u2113t = (\u21131,t, . . . , \u2113d,t) \u2208 [0, 1]d ; 3. Forecaster suffers loss p\u0302\u22a4t \u2113t .\nA NEW LOOK AT SHIFTING REGRET\nThe goal of the forecaster is to minimize the accumulated loss L\u0302T = \u2211T t=1 p\u0302 \u22a4 t \u2113t. In the now classical problem of prediction with expert advice, the goal of the forecaster is to compete with the best fixed component (often called \u201cexpert\u201d) chosen in hindsight, that is, with mini=1,...,T \u2211T t=1 \u2113i,t. The focus of this paper is on more ambitious forecasters that compete with a richer class of sequences of components. Let [d] = {1, . . . , d}. We use iT1 = (i1, . . . , iT ) to denote a sequence in [d]T and let LT (iT1 ) = \u2211T t=1 \u2113it be the cumulative linear loss of the sequence i T 1 \u2208 [d]T .\nWe start by introducing our main algorithmic tool, a generalized share algorithm. It is parametrized by the \u201cmixing functions\u201d \u03c8t : [0, 1](t+1)d \u2192 \u2206d for t = 1, . . . , T that assign probabilities to past \u201cpre-weights\u201d as defined below. In all examples discussed in this paper, these mixing functions are quite simple but working with such a general model makes the main ideas more transparent. We then provide a simple lemma that serves as the starting point for analyzing different instances of the generalized share algorithm.\nAlgorithm 1: The generalized share algorithm.\nParameters: learning rate \u03b7 > 0 and mixing functions \u03c8t for t = 1, . . . , T Initialization: p\u03021 = v1 = (1/d, . . . , 1/d)\nFor each round t = 1, . . . , T , 1. Predict p\u0302t ; 2. Observe loss \u2113t \u2208 [0, 1]d ; 3. [loss update] For each j = 1, . . . , d define\nvj,t+1 = p\u0302j,t e\n\u2212\u03b7 \u2113j,t\n\u2211d i=1 p\u0302i,t e \u2212\u03b7 \u2113i,t the current pre-weights,\nVt+1 = [ vi,s ] i\u2208[d], 16s6t+1\nthe d\u00d7 (t+ 1) matrix of all past and current pre-weights; 4. [shared update] Define p\u0302t+1 = \u03c8t+1 ( Vt+1 ) .\nLemma 1 For all t > 1 and for all qt \u2208 \u2206d, Algorithm 1 satisfies\n( p\u0302t \u2212 qt )\u22a4 \u2113t 6 1\n\u03b7\nd\u2211\ni=1\nqi,t ln vi,t+1 p\u0302i,t + \u03b7 8 .\nProof By Hoeffding\u2019s inequality,\nd\u2211\nj=1\np\u0302j,t \u2113j,t 6 \u2212 1\n\u03b7 ln\n  d\u2211\nj=1\np\u0302j,t e \u2212\u03b7 \u2113j,t  + \u03b7\n8 . (1)\nBy definition of vi,t+1, for all i = 1, . . . , d we then have d\u2211\nj=1\np\u0302j,t e \u2212\u03b7 \u2113j,t =\np\u0302i,t e \u2212\u03b7 \u2113i,t\nvi,t+1 ,\nwhich entails p\u0302\u22a4t \u2113t 6 \u2113i,t + 1\n\u03b7 ln vi,t+1 p\u0302i,t + \u03b7 8 .\nThe proof is concluded by taking a convex aggregation with respect to qt."}, {"heading": "3. Shifting bounds", "text": "In this section we prove shifting regret bounds for the generalized share algorithm. We compare the cumulative loss \u2211T t=1 p\u0302 \u22a4 t \u2113t of the forecaster with the loss of an arbitrary sequence of\nvectors q1, . . . , qT in the simplex \u2206d, that is, with \u2211T t=1 q \u22a4 t \u2113t. The bounds we obtain depend, of course, on the \u201cregularity\u201d of the comparison sequence. In the now classical results on tracking the best expert (as in Herbster and Warmuth 1998; Vovk 1999; Herbster and Warmuth 2001; Bousquet and Warmuth 2002), this regularity is measured as the number of times qt 6= qt+1 (henceforth referred to as \u201chard shifts\u201d). The main results of this paper show not only that these results may be generalized to obtain bounds in terms of \u201csofter\u201d regularity measures but that the same algorithms that were proposed with hard shift tracking in mind achieve such, perhaps surprisingly good, performance. Building on the general formulation introduced in Section 2, we derive such regret bounds for the fixed-share algorithm of Herbster and Warmuth (1998) and for the algorithms of Bousquet and Warmuth (2002).\nIn fact, it is advantageous to extend our analysis so that we not only compare the performance of the forecaster with sequences q1, . . . , qT taking values in the simplex \u2206d of probability distributions but rather against arbitrary sequences u1, . . . ,uT \u2208 Rd+ of vectors with non-negative components. The loss of such a sequence is defined by \u2211T t=1 u \u22a4 t \u2113t. For fair comparison, we measure the cumu-\nlative loss of the forecaster by \u2211T\nt=1 p\u0302 \u22a4 t \u2113t\u2016ut\u20161. Of course, when ut \u2208 \u2206d, we recover the original\nnotion of regret. The norms \u2016u1\u20161 , . . . , \u2016uT \u20161 may be viewed as a sequence of weights that give more or less importance to the instantaneous loss suffered at each step. Of particular interest is the case when \u2016ut\u20161 \u2208 [0, 1] which is the setting of \u201ctime selection functions\u201d (see Blum and Mansour 2007, Section 6). In particular, considering sequences \u2016ut\u20161 \u2208 {0, 1} that include the zero vector will provide us a simple way of deriving \u201cadaptive\u201d regret bounds, a notion introduced by Hazan and Seshadhri (2009).\nThe first regret bounds derived below measure the regularity of the sequence uT1 = (u1, . . . ,uT ) in terms of the quantity\nm(uT1 ) = T\u22121\u2211\nt=1\nDTV(ut+1,ut) (2)\nwhere for x = (x1, . . . , xd),y = (y1, . . . , yd) \u2208 Rd+, we define DTV(x,y) = \u2211 xi>yi (xi \u2212 yi). Note that when x,y \u2208 \u2206d, we recover the total variation distance DTV(x,y) = 12 \u2016x\u2212 y\u20161, while for general x,y \u2208 Rd+, the quantity DTV(x,y) is not necessarily symmetric and is always bounded by \u2016x\u2212 y\u20161. Note that when the vectors ut are incidence vectors (0, . . . , 0, 1, 0, . . . , 0) \u2208 Rd of elements it \u2208 [d], then m(uT1 ) corresponds to the number of shifts of the sequence iT1 \u2208 [d]T , and we recover from the results stated below the classical bounds for tracking the best expert."}, {"heading": "3.1. Fixed-share update", "text": "We now analyze a specific instance of the generalized share algorithm corresponding to the update\np\u0302j,t+1 =\nd\u2211\ni=1\n(\u03b1 d + (1\u2212 \u03b1)1i=j ) vi,t+1 = \u03b1 d + (1\u2212 \u03b1)vj,t+1 , 0 6 \u03b1 6 1 . (3)\nA NEW LOOK AT SHIFTING REGRET\nDespite seemingly different statements, this update in Algorithm 1 can be seen to lead exactly to the fixed-share algorithm of Herbster and Warmuth (1998) for prediction with expert advice.\nProposition 2 With the above update, for all T > 1, for all sequences \u21131, . . . , \u2113T of loss vectors \u2113t \u2208 [0, 1]d, and for all u1, . . . ,uT \u2208 Rd+,\nT\u2211\nt=1\n\u2016ut\u20161 p\u0302\u22a4t \u2113t \u2212 T\u2211\nt=1\nu\u22a4t \u2113t 6 \u2016u1\u20161 ln d\n\u03b7 +\n\u03b7\n8\nT\u2211\nt=1\n\u2016ut\u20161\n+ m(uT1 )\n\u03b7 ln\nd \u03b1 +\n\u2211T t=1 \u2016ut\u20161 \u2212m(uT1 )\u2212 1\n\u03b7 ln\n1\n1\u2212 \u03b1 .\nWe emphasize that the fixed-share forecaster does not need to \u201cknow\u201d anything about the sequence of the norms \u2016ut\u2016. Of course, in order to minimize the obtained upper bound, the tuning parameters \u03b1, \u03b7 need to be optimized and their values will depend on the maximal value of m(uTi ) for the sequences one wishes to compete against. In particular, we obtain the following corollary, in which h(x) = \u2212x lnx\u2212 (1\u2212 x) ln(1\u2212 x) denotes the binary entropy function for x \u2208 [0, 1]. We recall 1 that h(x) 6 x ln(e/x) for x \u2208 [0, 1].\nCorollary 3 Suppose Algorithm 1 is run with the update (3). Let m0 > 0. For all T > 1, for all sequences \u21131, . . . , \u2113T of loss vectors \u2113t \u2208 [0, 1]d, and for all q1, . . . , qT \u2208 \u2206d with m(qT1 ) 6 m0,\nT\u2211\nt=1\np\u0302\u22a4t \u2113t \u2212 T\u2211\nt=1\nq\u22a4t \u2113t 6 \u221a\u221a\u221a\u221aT 2 ( (m0 + 1) ln d+ (T \u2212 1) h ( m0 T \u2212 1 )) ,\nwhenever \u03b7 and \u03b1 are optimally chosen in terms of m0 and T .\nIf we only consider vectors of the form qt = (0, . . . , 0, 1, 0, . . . , 0) then m(q T 1 ) corresponds to the number of times qt+1 6= qt in the sequence qT1 . We thus recover Herbster and Warmuth (1998, Theorem 1) and Bousquet and Warmuth (2002, Lemma 6) from the much more general Proposition 2.\nProof of Proposition 2 Applying Lemma 1 with qt = ut/ \u2016ut\u20161, and multiplying by \u2016ut\u20161, we get for all t > 1 and ut \u2208 Rd+\n\u2016ut\u20161 p\u0302\u22a4t \u2113t \u2212 u\u22a4t \u2113t 6 1\n\u03b7\nd\u2211\ni=1\nui,t ln vi,t+1 p\u0302i,t + \u03b7 8 \u2016ut\u20161 . (4)\nWe now examine\nd\u2211\ni=1\nui,t ln vi,t+1 p\u0302i,t\n= d\u2211\ni=1\n( ui,t ln 1\np\u0302i,t \u2212 ui,t\u22121 ln\n1\nvi,t\n) + d\u2211\ni=1\n( ui,t\u22121 ln 1\nvi,t \u2212 ui,t ln\n1\nvi,t+1\n) . (5)\nFor the first term on the right-hand side, we have\nd\u2211\ni=1\n( ui,t ln 1\np\u0302i,t \u2212 ui,t\u22121 ln\n1\nvi,t\n) =\n\u2211\ni :ui,t>ui,t\u22121\n( (ui,t \u2212 ui,t\u22121) ln 1\np\u0302i,t + ui,t\u22121 ln vi,t p\u0302i,t\n)\n1. As can be seen by noting that ln ( 1/(1\u2212 x) ) < x/(1\u2212 x)\n+ \u2211\ni : ui,t<ui,t\u22121\n( (ui,t \u2212 ui,t\u22121) ln 1\nvi,t\ufe38 \ufe37\ufe37 \ufe38 60\n+ui,t ln vi,t p\u0302i,t\n) . (6)\nIn view of the update (3), we have 1/p\u0302i,t 6 d/\u03b1 and vi,t/p\u0302i,t 6 1/(1 \u2212 \u03b1). Substituting in (6), we get\nd\u2211\ni=1\n( ui,t ln 1\np\u0302i,t \u2212 ui,t\u22121 ln\n1\nvi,t\n)\n6 \u2211\ni :ui,t>ui,t\u22121\n(ui,t \u2212 ui,t\u22121) ln d\n\u03b1 +\n  \u2211\ni: ui,t>ui,t\u22121\nui,t\u22121 + \u2211\ni: ui,t<ui,t\u22121\nui,t\n  ln 1\n1\u2212 \u03b1\n= DTV (ut,ut\u22121) ln d\n\u03b1 +\n  d\u2211\ni=1\nui,t \u2212 \u2211\ni : ui,t>ui,t\u22121\n(ui,t \u2212 ui,t\u22121)\n \n\ufe38 \ufe37\ufe37 \ufe38 =\u2016ut\u20161\u2212DTV (ut,ut\u22121)\nln 1\n1\u2212 \u03b1 .\nThe sum of the second term in (5) telescopes. Substituting the obtained bounds in the first sum of the right-hand side in (5), and summing over t = 2, . . . , T , leads to\nT\u2211\nt=2\nd\u2211\ni=1\nui,t ln vi,t+1 p\u0302i,t 6 m(uT1 ) ln d \u03b1 +\n( T\u2211\nt=2\n\u2016ut\u20161 \u2212 1\u2212m(uT1 ) ) ln 1\n1\u2212 \u03b1\n+\nd\u2211\ni=1\nui,1 ln 1\nvi,2 \u2212 ui,T ln\n1\nvi,T+1\ufe38 \ufe37\ufe37 \ufe38 60\n.\nWe hence get from (4), which we use in particular for t = 1,\nT\u2211\nt=1\n\u2016ut\u20161 p\u0302\u22a4t \u2113t \u2212 u\u22a4t \u2113t 6 1\n\u03b7\nd\u2211\ni=1\nui,1 ln 1\np\u0302i,1 +\n\u03b7\n8\nT\u2211\nt=1\n\u2016ut\u20161\n+ m(uT1 )\n\u03b7 ln\nd \u03b1 +\n\u2211T t=1 \u2016ut\u20161 \u2212 1\u2212m(uT1 )\n\u03b7 ln\n1\n1\u2212 \u03b1 ."}, {"heading": "3.2. Sparse sequences: Bousquet-Warmuth updates", "text": "Bousquet and Warmuth (2002) proposed forecasters that are able to efficiently compete with the best sequence of experts among all those sequences that only switch a bounded number of times and also take a small number of different values. Such \u201csparse\u201d sequences of experts appear naturally in many applications. In this section we show that their algorithms in fact work very well in comparison with a much larger class of sequences u1, . . . ,uT that are \u201cregular\u201d\u2014that is, m(uT1 ), defined in (2) is small\u2014and \u201csparse\u201d in the sense that the quantity\nn(uT1 ) =\nd\u2211\ni=1\nmax t=1,...,T ui,t\nA NEW LOOK AT SHIFTING REGRET\nis small. Note that when qt \u2208 \u2206d for all t, then two interesting upper bounds can be provided. First, denoting the union of the supports of these convex combinations by S \u2286 [d], we have n(qT1 ) 6 |S|, the cardinality of S. Also,\nn(qT1 ) 6 \u2223\u2223\u2223 { qt, t = 1, . . . , T }\u2223\u2223\u2223,\nthe cardinality of the pool of convex combinations. Thus, n(uT1 ) generalizes the notion of sparsity of Bousquet and Warmuth (2002).\nHere we consider a family of shared updates of the form\np\u0302j,t = (1\u2212 \u03b1)vj,t + \u03b1 wj,t Zt , 0 6 \u03b1 6 1 , (7)\nwhere the wj,t are nonnegative weights that may depend on past and current pre-weights and Zt = \u2211d i=1 wi,t is a normalization constant. Shared updates of this form were proposed by Bousquet and Warmuth (2002, Sections 3 and 5.2). Apart from generalizing the regret bounds of Bousquet and Warmuth (2002), we believe that the analysis given below is significantly simpler and more transparent. We are also able to slightly improve their original bounds.\nWe focus on choices of the weights wj,t that satisfy the following conditions: there exists a constant C > 1 such that for all j = 1, . . . , d and t = 1, . . . , T ,\nvj,t 6 wj,t 6 1 and C wj,t+1 > wj,t . (8)\nThe next result improves on Proposition 2 when T \u226a d and n(uT1 ) \u226a m(uT1 ), that is, when the dimension (or number of experts) d is large but the sequence uT1 is sparse.\nProposition 4 Suppose Algorithm 1 is run with the shared update (7) with weights satisfying the conditions (8). Then for all T > 1, for all sequences \u21131, . . . , \u2113T of loss vectors \u2113t \u2208 [0, 1]d, and for all sequences u1, . . . ,uT \u2208 Rd+,\nT\u2211\nt=1\n\u2016ut\u20161 p\u0302\u22a4t \u2113t \u2212 T\u2211\nt=1\nu\u22a4t \u2113t 6 n(uT1 ) ln d\n\u03b7 +\nn(uT1 )T lnC\n\u03b7 +\n\u03b7\n8\nT\u2211\nt=1\n\u2016ut\u20161\n+ m(uT1 )\n\u03b7 ln maxt6T Zt \u03b1 +\n\u2211T t=1 \u2016ut\u20161 \u2212m(uT1 )\u2212 1\n\u03b7 ln\n1\n1\u2212 \u03b1 .\nProof The beginning and the end of the proof are similar to the one of Proposition 2, as they do not depend on the specific weight update. In particular, inequalities (4) and (5) remain the same. The proof is modified after (6), which this time we upper bound using the first condition in (8),\nd\u2211\ni=1\n( ui,t ln 1\np\u0302i,t \u2212 ui,t\u22121 ln\n1\nvi,t\n) =\n\u2211\ni :ui,t>ui,t\u22121\n(ui,t \u2212 ui,t\u22121) ln 1\np\u0302i,t + ui,t\u22121 ln vi,t p\u0302i,t\n+ \u2211\ni :ui,t<ui,t\u22121 (ui,t \u2212 ui,t\u22121)\ufe38 \ufe37\ufe37 \ufe38 60\nln 1\nvi,t\ufe38 \ufe37\ufe37 \ufe38 >ln(1/wi,t)\n+ui,t ln vi,t p\u0302i,t . (9)\nBy definition of the shared update (7), we have 1/p\u0302i,t 6 Zt/(\u03b1wi,t) and vi,t/p\u0302i,t 6 1/(1\u2212 \u03b1). We then upper bound the quantity at hand in (9) by\n\u2211\ni : ui,t>ui,t\u22121\n(ui,t \u2212 ui,t\u22121) ln (\nZt \u03b1wi,t\n) +   \u2211\ni : ui,t>ui,t\u22121\nui,t\u22121 + \u2211\ni : ui,t<ui,t\u22121\nui,t\n  ln 1\n1\u2212 \u03b1\n+ \u2211\ni : ui,t<ui,t\u22121\n(ui,t \u2212 ui,t\u22121) ln 1\nwi,t\n= DTV(ut,ut\u22121) ln Zt \u03b1\n+ ( \u2016ut\u20161 \u2212DTV(ut,ut\u22121) ) ln 1 1\u2212 \u03b1 + d\u2211\ni=1\n(ui,t \u2212 ui,t\u22121) ln 1\nwi,t .\nProceeding as in the end of the proof of Proposition 2, we then get the claimed bound, provided that we can show that\nT\u2211\nt=2\nd\u2211\ni=1\n(ui,t \u2212 ui,t\u22121) ln 1\nwi,t 6 n(uT1 ) (ln d+ T lnC)\u2212 \u2016u1\u20161 ln d ,\nwhich we do next. Indeed, the left-hand side can be rewritten as\nT\u2211\nt=2\nd\u2211\ni=1\n( ui,t ln 1\nwi,t \u2212 ui,t ln\n1\nwi,t+1\n) + T\u2211\nt=2\nd\u2211\ni=1\n( ui,t ln 1\nwi,t+1 \u2212 ui,t\u22121 ln\n1\nwi,t\n)\n6\n( T\u2211\nt=2\nd\u2211\ni=1\nui,t ln C wi,t+1 wi,t\n) + ( d\u2211\ni=1\nui,T ln 1\nwi,T+1 \u2212\nd\u2211\ni=1\nui,1 ln 1\nwi,2\n)\n6\n( d\u2211\ni=1\n( max\nt=1,...,T ui,t\n) T\u2211\nt=2\nln C wi,t+1 wi,t\n) + ( d\u2211\ni=1\n( max\nt=1,...,T ui,t\n) ln\n1\nwi,T+1 \u2212\nd\u2211\ni=1\nui,1 ln 1\nwi,2\n)\n=\nd\u2211\ni=1\n( max\nt=1,...,T ui,t\n)( (T \u2212 1) lnC + ln 1\nwi,2\n) \u2212 d\u2211\ni=1\nui,1 ln 1\nwi,2 ,\nwhere we used C > 1 for the first inequality and the second condition in (8) for the second inequality. The proof is concluded by noting that (8) entails wi,2 > (1/C)wi,1 > (1/C)vi,1 = 1/(dC) and that the coefficient maxt=1,...,T ui,t \u2212 ui,1 in front of ln(1/wi,2) is nonnegative. We now generalize Corollaries 8 and 9 of Bousquet and Warmuth (2002) by showing two specific instances of the generic update (7) that satisfy (8). The first update uses wj,t = maxs6t vj,s. Then (8) is satisfied with C = 1. Moreover, since a sum of maxima of nonnegative elements is smaller than the sum of the sums, Zt 6 min{d, t} 6 T . This immediately gives the following result.\nCorollary 5 Suppose Algorithm 1 is run with the update (7) with wj,t = maxs6t vj,s. For all T > 1, for all sequences \u21131, . . . , \u2113T of loss vectors \u2113t \u2208 [0, 1]d, and for all q1, . . . , qT \u2208 \u2206d,\nT\u2211\nt=1\np\u0302\u22a4t \u2113t \u2212 T\u2211\nt=1\nq\u22a4t \u2113t 6 n(qT1 ) ln d\n\u03b7 +\n\u03b7 8 T +\nm(qT1 )\n\u03b7 ln\nT \u03b1 + T \u2212m(qT1 )\u2212 1 \u03b7 ln 1 1\u2212 \u03b1 .\nA NEW LOOK AT SHIFTING REGRET\nThe second update we discuss uses wj,t = maxs6t e\u03b3(s\u2212t)vj,s in (7) for some \u03b3 > 0. Both conditions in (8) are satisfied with C = e\u03b3 . One also has that\nZt 6 d and Zt 6 \u2211\n\u03c4>0\ne\u2212\u03b3\u03c4 = 1 1\u2212 e\u2212\u03b3 6 1 \u03b3\nas ex > 1 + x for all real x. The bound of Proposition 4 then instantiates as\nn(qT1 ) ln d\n\u03b7 +\nn(qT1 )T\u03b3\n\u03b7 +\n\u03b7 8 T +\nm(qT1 )\n\u03b7 ln min{d, 1/\u03b3} \u03b1 + T \u2212m(qT1 )\u2212 1 \u03b7 ln 1 1\u2212 \u03b1\nwhen sequences ut = qt \u2208 \u2206d are considered. This bound is best understood when \u03b3 is tuned optimally based on T and on two bounds m0 and n0 over the quantities m(qT1 ) and n(q T 1 ). Indeed, by optimizing n0T\u03b3 +m0 ln(1/\u03b3), i.e., by choosing \u03b3 = m0/(n0 T ), one gets a bound that improves on the one of the previous corollary:\nCorollary 6 Letm0, n0 > 0. Suppose Algorithm 1 is run with the update wj,t = maxs6t e\u03b3(s\u2212t)vj,s where \u03b3 = m0/(n0 T ). For all T > 1, for all sequences \u21131, . . . , \u2113T of loss vectors \u2113t \u2208 [0, 1]d, and for all q1, . . . , qT \u2208 \u2206d such that m(qT1 ) 6 m0 and n(qT1 ) 6 n0, we have\nT\u2211\nt=1\np\u0302\u22a4t \u2113t \u2212 T\u2211\nt=1\nq\u22a4t \u2113t 6 n0 ln d\n\u03b7 + m0 \u03b7\n( 1 + ln min { d, n0 T\nm0\n})\n+ \u03b7\n8 T + m0 \u03b7 ln 1 \u03b1 + T \u2212m0 \u2212 1 \u03b7 ln 1 1\u2212 \u03b1 .\nAs the factors e\u2212\u03b3t cancel out in the numerator and denominator of the ratio in (7), there is a straightforward implementation of the algorithm (not requiring the knowledge of T ) that needs to maintain only d weights.\nIn contrast, the corresponding algorithm of Bousquet and Warmuth (2002), using the updates p\u0302j,t = (1\u2212\u03b1)vj,t+\u03b1S\u22121t \u2211 s6t\u22121(s\u2212t)\u22121vj,s or p\u0302j,t = (1\u2212\u03b1)vj,t+\u03b1S\u22121t maxs6t\u22121(s\u2212t)\u22121vj,s, where St denote normalization factors, needs to maintain O(dT ) weights with a naive implementation, and O(d lnT ) weights with a more sophisticated one. In addition, the obtained bounds are slightly worse than the one stated above in Corollary 6 as an additional factor of m0 ln(1 + lnT ) is present in Bousquet and Warmuth (2002, Corollary 9)."}, {"heading": "4. Adaptive regret", "text": "Next we show how the results of the previous section, e.g., Proposition 2, imply guarantees in terms of adaptive regret \u2014a notion introduced by Hazan and Seshadhri (2009) as follows. For \u03c40 \u2208 {1, . . . , T}, the \u03c40-adaptive regret of a forecaster is defined by\nR\u03c40\u2212adaptT = max [r, s] \u2282 [1, T ] s+ 1\u2212 r 6 \u03c40\n{ s\u2211\nt=r\np\u0302\u22a4t \u2113t \u2212 min q\u2208\u2206d\ns\u2211\nt=r\nq\u22a4\u2113t } . (10)\nAdaptive regret is an alternative way to measure the performance of a forecaster against a changing environment. It is a straightforward observation that adaptive regret bounds also lead to shifting\nregret bounds (in terms of hard shifts). Here we show that these two notions of regret share an even tighter connection, as they can be both viewed as instances of the same alma mater bound, e.g., Proposition 2.\nHazan and Seshadhri (2009) essentially considered the case of online convex optimization with exp-concave loss function (see Section 6 below). In case of general convex functions, they also mentioned that the greedy projection forecaster of Zinkevich (2003) \u2014i.e., mirror descent with a quadratic regularizer\u2014 enjoys adaptive regret guarantees. This forecaster can be implemented on the simplex in time O(d) \u2014see, e.g., Duchi et al. (2008). We now show that the simpler fixed-share algorithm has a similar adaptive regret bound.\nProposition 7 Suppose that Algorithm 1 is run with the shared update (3). Then for all T > 1, for all sequences \u21131, . . . , \u2113T of loss vectors \u2113t \u2208 [0, 1]d, and for all \u03c40 \u2208 {1, . . . , T},\nR\u03c40\u2212adaptT 6 1\n\u03b7 ln\nd \u03b1 + \u03c40 \u2212 1 \u03b7 ln 1 1\u2212 \u03b1 + \u03b7 8 \u03c40 ."}, {"heading": "In particular, when \u03b7 and \u03b1 are chosen optimally (depending on \u03c40 and T )", "text": "R\u03c40\u2212adaptT 6 \u221a\n\u03c40 2\n( \u03c40 h ( 1\n\u03c40\n) + ln d ) 6 \u221a \u03c40 2 ln(ed\u03c40) .\nProof For 1 6 r 6 s 6 T and q \u2208 \u2206d, the regret in the right-hand side of (10) equals the regret considered in Proposition 2 against the sequence uT1 defined as ut = q for t = r, . . . , s and 0 = (0, . . . , 0) for the remaining t. When r > 2, this sequence is such that DTV (ur,ur\u22121) = DTV (q,0) = 1 and DTV (us+1,us) = DTV (0, q) = 0 so that m(uT1 ) = 1, while \u2016u1\u20161 = 0. When r = 1, we have \u2016u1\u20161 = 1 and m(uT1 ) = 0. In all cases, m(uT1 ) + \u2016u1\u20161 = 1. Specializing the bound of Proposition 2 to the thus defined sequence uT1 gives the result."}, {"heading": "5. Online tuning of the parameters", "text": "The forecasters studied above need their parameters \u03b7 and \u03b1 to be tuned according to various quantities, including the time horizon T . We show here how the trick of Auer et al. (2002) of having these parameters vary over time can be extended to our setting. For the sake of concreteness we focus on the fixed-share update, i.e., Algorithm 1 run with the update (3). We respectively replace steps 3 and 4 of its description by the loss and shared updates\nvj,t+1 = p\u0302\n\u03b7t \u03b7t\u22121\nj,t e \u2212\u03b7t\u2113j,t\n\u2211d i=1 p\u0302 \u03b7t \u03b7t\u22121 i,t e \u2212\u03b7t\u2113i,t\nand pj,t+1 = \u03b1t d + (1\u2212 \u03b1t) vj,t+1 , (11)\nfor all t > 1 and all j \u2208 [d], where (\u03b7\u03c4 ) and (\u03b1\u03c4 ) are two sequences of positive numbers, indexed by \u03c4 > 1. We also conventionally define \u03b70 = \u03b71. Proposition 2 is then adapted in the following way (when \u03b7t \u2261 \u03b7 and \u03b1t \u2261 \u03b1, Proposition 2 is exactly recovered).\nA NEW LOOK AT SHIFTING REGRET\nProposition 8 The forecaster based on the above updates (11) is such that whenever \u03b7t 6 \u03b7t\u22121 and \u03b1t 6 \u03b1t\u22121 for all t > 1, the following performance bound is achieved. For all T > 1, for all sequences \u21131, . . . , \u2113T of loss vectors \u2113t \u2208 [0, 1]d, and for all u1, . . . ,uT \u2208 Rd+,\nT\u2211\nt=1\n\u2016ut\u20161 p\u0302\u22a4t \u2113t \u2212 T\u2211\nt=1\nu\u22a4t \u2113t 6 ( \u2016ut\u20161 \u03b71 + T\u2211\nt=2\n\u2016ut\u20161 ( 1\n\u03b7t \u2212 1 \u03b7t\u22121\n)) ln d\n+ m(uT1 )\n\u03b7T ln d(1 \u2212 \u03b1T ) \u03b1T + T\u2211\nt=2\n\u2016ut\u20161 \u03b7t\u22121 ln 1 1\u2212 \u03b1t +\nT\u2211\nt=1\n\u03b7t\u22121 8 \u2016ut\u20161 .\nDue to space constraints, we only instantiate the obtained bound to the case of T -adaptive regret guarantees, when T is unknown and/or can increase without bounds. Corollary 9 The forecaster based on the above updates with \u03b7t = \u221a( ln(dt) ) /t for t > 3 and\n\u03b70 = \u03b71 = \u03b72 = \u03b73 on the one hand, \u03b1t = 1/t on the other hand, is such that for all T > 3 and for all sequences \u21131, . . . , \u2113T of loss vectors \u2113t \u2208 [0, 1]d,\nmax [r,s]\u2282[1,T ]\n{ s\u2211\nt=r\np\u0302\u22a4t \u2113t \u2212 min q\u2208\u2206d\ns\u2211\nt=r\nq\u22a4\u2113t } 6 \u221a 2T ln(dT ) + \u221a 3 ln(3d) .\nProof The sequence n 7\u2192 ln(n)/n is only non-increasing after round n > 3, so that the defined sequences of (\u03b1t) and (\u03b7t) are non-increasing, as desired. For a given pair (r, s) and a given q \u2208 \u2206d, we consider the sequence \u03bdT1 defined in the proof of Proposition 7; it satisfies that m(u T 1 ) 6 1 and \u2016ut\u20161 6 1 for all t > 1. Therefore, Proposition 8 ensures that\ns\u2211\nt=r\np\u0302\u22a4t \u2113t \u2212 min q\u2208\u2206d\ns\u2211\nt=r\nq\u22a4\u2113t 6 ln d\n\u03b7T +\n1\n\u03b7T ln d(1\u2212 \u03b1T ) \u03b1T\ufe38 \ufe37\ufe37 \ufe38 6dT +\nT\u2211\nt=2\n1\n\u03b7t\u22121 ln\n1\n1\u2212 \u03b1t \ufe38 \ufe37\ufe37 \ufe38\n6(1/\u03b7T ) \u2211T t=2 ln(t/(t\u22121))=(ln T )/\u03b7T\n+\nT\u2211\nt=1\n\u03b7t\u22121 8 .\nIt only remains to substitute the proposed values of \u03b7t and to note that\nT\u2211\nt=1\n\u03b7t\u22121 6 3\u03b73 + T\u22121\u2211\nt=3\n1\u221a t\n\u221a ln(dT ) 6 3\n\u221a ln(3d)\n3 + 2\n\u221a T \u221a ln(dT ) ."}, {"heading": "6. Online convex optimization and exp-concave loss functions", "text": "By using a standard reduction, the results of the previous sections can be applied to online convex optimization on the simplex. In this setting, at each step t the forecaster chooses p\u0302t \u2208 \u2206d and then is given access to a convex loss \u2113t : \u2206d \u2192 [0, 1]. Now, using Algorithm 1 with the loss vector \u2113t \u2208 \u2202\u2113t(p\u0302t) given by a subgradient of \u2113t leads to the desired bounds. Indeed, by the convexity of \u2113t, the regret at each time t with respect to any vector ut \u2208 Rd+ with \u2016ut\u20161 > 0 is then bounded as\n\u2016ut\u20161 ( \u2113t(p\u0302t)\u2212 \u2113t ( ut\n\u2016ut\u20161\n)) 6 ( \u2016ut\u20161 p\u0302t \u2212 ut )\u22a4 \u2113t ."}, {"heading": "6.1. Exp-concave loss functions", "text": "Recall that a loss function \u2113t is called \u03b70-exp-concave if e\u2212\u03b70 \u2113t is concave. (In particular, expconcavity implies convexity.) Bousquet and Warmuth (2002) study shifting regret for exp-concave loss functions. However, they define the regret of an element qT1 of the comparison class (a sequence of elements in \u2206d) by\nT\u2211\nt=1\n( \u2113t ( p\u0302t ) \u2212 q\u22a4t \u2113t ) (12)\nwhere \u2113t = ( \u2113t(e1), . . . , \u2113t(ed) ) and e1, . . . ,ed are the elements of the canonical basis of Rd. This corresponds to the linear optimization case studied in the previous sections. However, due to exp-concavity, (1) can be replaced by an application of Jensen\u2019s inequality, namely,\n\u2113t ( p\u0302t ) 6 \u2212 1\n\u03b70 ln\n  d\u2211\nj=1\np\u0302j,t e \u2212\u03b70 \u2113t(ej)   .\nHence the various propositions and corollaries of Sections 3 and 4 still hold true for the regret (12) up to some modifications (deletion of the terms linear in \u03b7, assumption of exp-concavity, boundedness no longer needed). For the sake of concreteness, we illustrate the required modifications on Proposition 4.\nProposition 10 Suppose Algorithm 1 is run with the shared update (7) with weights satisfying the conditions (8) and for the choice \u03b7 = \u03b70. Then for all T > 1, for all sequences \u21131, . . . , \u2113T of \u03b70\u2013exp-concave loss functions, and for all sequences u1, . . . ,uT \u2208 Rd+,\nT\u2211\nt=1\n\u2016ut\u20161 \u2113t ( p\u0302t ) \u2212 T\u2211\nt=1\nu\u22a4t \u2113t 6 (uT1 ) ln d\n\u03b70 +\nn(uT1 )T lnC\n\u03b70\n+ m(uT1 )\n\u03b70 ln maxt6T Zt \u03b1 +\n\u2211T t=1 \u2016ut\u20161 \u2212m(uT1 )\u2212 1\n\u03b70 ln\n1\n1\u2212 \u03b1 .\nWe now turn to the more ambitious goal of controlling regrets of the form \u2211T\nt=1 ( \u2113t ( p\u0302t ) \u2212\u2113t(qt) )\nwhere losses \u2113t are exp-concave. Hazan and Seshadhri (2009) constructed algorithms with T\u2013 adaptive regret of the order of O(ln2 T ) and running in time poly(d, log T ). They also constructed different algorithms with T\u2013adaptive regret bounded by O(lnT )) and running time poly(d, T ).\nNext, we show the first logarithmic shifting bounds for exp-concave loss functions. However, we only do so against sequences qT1 of elements in \u2206d, i.e., we offer here no general bound in terms of linear vectors uT1 that would unify here as well the view between tracking bounds and adaptive regret bounds. Besides, we get shifting bounds only in terms of hard shifts\ns(qT1 ) = \u2223\u2223{t = 2, . . . , T : qt 6= qt\u22121 }\u2223\u2223 .\nObviously, getting unifying bounds in terms of soft shifts of sequences uT1 of linear vectors is an important open question, which we leave for future research. To get our bound, we mix ideas of Herbster and Warmuth (1998) and Blum and Kalai (1997). We define a prior over the sequences of convex weight vectors as the distribution of the following homogeneous Markov chain Q1, Q2, . . .: The starting vector Q1 is drawn at random according to the uniform distribution \u00b5 over \u2206d. Then,\nA NEW LOOK AT SHIFTING REGRET\ngiven Qt\u22121, the next element Qt is equal to Qt\u22121 with probability 1 \u2212 \u03b1 and with probability \u03b1 is drawn at random according to \u00b5. In the sequel, all probabilities P and expectations E will be with respect to this Markov chain. Now, the convex weight vector used at time t > 1 by the forecaster is\np\u0302t = E\n[ Qt e \u2212\u03b70Lt\u22121(Q t\u22121 1 ) ]\nE [ e\u2212\u03b70Lt\u22121(Q t\u22121 1 ) ] , where Lt\u22121(Qt\u221211 ) =\nt\u22121\u2211\ns=1\n\u2113s(Qs) (13)\n(with the convention that an empty sum is null). For this forecaster, we get the following performance bound, whose proof can be found in appendix.\nProposition 11 For all T > 1, for all sequences \u21131, . . . , \u2113T of \u03b70\u2013exp-concave loss functions taking values in [0, L], the cumulative loss of the above forecaster is bounded for all sequences q1, . . . , qT \u2208 \u2206d by\nT\u2211\nt=1\n\u2113t(p\u0302t)\u2212 T\u2211\nt=1\n\u2113t(qt) 6\n( s(qT1 ) + 1 ) (d\u2212 1)\n\u03b7 max\n{ 1, ln\ne \u03b7 LT( s(qT1 ) + 1 ) (d\u2212 1)\n}\n+ s(qT1 )\n\u03b7 ln\n1 \u03b1 + T \u2212 s(qT1 )\u2212 1 \u03b7 ln 1 1\u2212 \u03b1 .\nUnder the imposition of a bound s0 on the numbers of hard shifts s(qT1 ) and up to a tuning of \u03b1 in terms of s0 and T , the last two terms of the bound are smaller than T h(s0/T ) 6 s0 ln(es0/T ) and therefore, the whole regret bound is O ( (ds0/\u03b70) lnT ) ."}, {"heading": "Appendix A. Proof of Proposition 8", "text": "We first adapt Lemma 1.\nLemma 12 The forecaster based on the loss and shared updates (11) satisfies, for all t > 1 and for all qt \u2208 \u2206d,\n( p\u0302t \u2212 qt )\u22a4 \u2113t 6 d\u2211\ni=1\nqi,t\n( 1\n\u03b7t\u22121 ln\n1 p\u0302i,t \u2212 1 \u03b7t ln 1 vi,t+1\n) + ( 1\n\u03b7t \u2212 1 \u03b7t\u22121\n) ln d+\n\u03b7t\u22121 8 ,\nwhenever \u03b7t 6 \u03b7t\u22121.\nProof By Hoeffding\u2019s inequality,\nd\u2211\nj=1\np\u0302j,t \u2113j,t 6 \u2212 1\n\u03b7t\u22121 ln\n  d\u2211\nj=1\np\u0302j,t e \u2212\u03b7t\u22121 \u2113j,t  + \u03b7t\u22121\n8 .\nBy Jensen\u2019s inequality, since \u03b7t 6 \u03b7t\u22121 and thus x 7\u2192 x \u03b7t\u22121 \u03b7t is convex,\n1\nd\nd\u2211\nj=1\np\u0302j,t e \u2212\u03b7t\u22121\u2113j,t =\n1\nd\nd\u2211\nj=1\n( p\u0302 \u03b7t \u03b7t\u22121\nj,t e \u2212\u03b7t\u2113j,t\n)\u03b7t\u22121 \u03b7t\n>  1 d d\u2211\nj=1\np\u0302\n\u03b7t \u03b7t\u22121\nj,t e \u2212\u03b7t\u2113j,t\n  \u03b7t\u22121 \u03b7t\n.\nSubstituting in Hoeffding\u2019s bound we get\np\u0302\u22a4t \u2113t 6 \u2212 1\n\u03b7t ln\n  d\u2211\nj=1\np\u0302\n\u03b7t \u03b7t\u22121\nj,t e \u2212\u03b7t\u2113j,t\n + ( 1\n\u03b7t \u2212 1 \u03b7t\u22121\n) ln d+\n\u03b7t\u22121 8 .\nNow, by definition of the loss update in (11), for all i \u2208 [d], d\u2211\nj=1\np\u0302\n\u03b7t \u03b7t\u22121\nj,t e \u2212\u03b7t\u2113j,t =\n1\nvi,t+1 p\u0302\n\u03b7t \u03b7t\u22121\ni,t e \u2212\u03b7t\u2113i,t ,\nwhich, after substitution in the previous bound leads to the inequality\np\u0302\u22a4t \u2113t 6 \u2113i,t + 1\n\u03b7t\u22121 ln\n1 p\u0302i,t \u2212 1 \u03b7t ln 1 vi,t+1 +\n( 1\n\u03b7t \u2212 1 \u03b7t\u22121\n) ln d+\n\u03b7t\u22121 8 ,\nvalid for all i \u2208 [d]. The proof is concluded by taking a convex aggregation over i with respect to qt.\nThe proof of Proposition 8 follows the steps of the one of Proposition 2; we sketch it below.\nProof of Proposition 8 Applying Lemma 12 with qt = ut/ \u2016ut\u20161, and multiplying by \u2016ut\u20161, we get for all t > 1 and ut \u2208 Rd+,\n\u2016ut\u20161 p\u0302\u22a4t \u2113t \u2212 u\u22a4t \u2113t 6 1\n\u03b7t\u22121\nd\u2211\ni=1\nui,t ln 1 p\u0302i,t \u2212 1 \u03b7t\nd\u2211\ni=1\nui,t ln 1\nvi,t+1\n+ \u2016ut\u20161 ( 1\n\u03b7t \u2212 1 \u03b7t\u22121\n) ln d+\n\u03b7t\u22121 8 \u2016ut\u20161 . (14)\nWe will sum these bounds over t > 1 to get the desired result but need to perform first some additional boundings for t > 2; in particular, we examine\n1\n\u03b7t\u22121\nd\u2211\ni=1\nui,t ln 1 p\u0302i,t \u2212 1 \u03b7t\nd\u2211\ni=1\nui,t ln 1\nvi,t+1\n= 1\n\u03b7t\u22121\nd\u2211\ni=1\n( ui,t ln 1\np\u0302i,t \u2212 ui,t\u22121 ln\n1\nvi,t\n) + d\u2211\ni=1\n( ui,t\u22121 \u03b7t\u22121 ln 1 vi,t \u2212 ui,t \u03b7t ln 1 vi,t+1 ) , (15)\nwhere the first difference in the right-hand side can be bounded as in (6) by\nd\u2211\ni=1\n( ui,t ln 1\np\u0302i,t \u2212 ui,t\u22121 ln\n1\nvi,t\n)\n6 \u2211\ni : ui,t>ui,t\u22121\n( (ui,t \u2212 ui,t\u22121) ln 1\np\u0302i,t + ui,t\u22121 ln vi,t p\u0302i,t\n) +\n\u2211\ni : ui,t<ui,t\u22121\nui,t ln vi,t p\u0302i,t\n6 DTV (ut,ut\u22121) ln d\n\u03b1t +\n( \u2016ut\u20161 \u2212DTV (ut,ut\u22121) ) ln 1\n1\u2212 \u03b1t 6 DTV (ut,ut\u22121) ln\nd(1\u2212 \u03b1T ) \u03b1T + \u2016ut\u20161 ln 1 1\u2212 \u03b1t , (16)\nwhere we used for the second inequality that the shared update in (11) is such that 1/p\u0302i,t 6 d/\u03b1t and vi,t/p\u0302i,t 6 1/(1 \u2212 \u03b1t), and for the third inequality, that \u03b1t > \u03b1T and x 7\u2192 (1 \u2212 x)/x is increasing on (0, 1]. Summing (15) over t = 2, . . . , T using (16) and the fact that \u03b7t > \u03b7T , we get\nT\u2211\nt=2\n( 1\n\u03b7t\u22121\nd\u2211\ni=1\nui,t ln 1 p\u0302i,t \u2212 1 \u03b7t\nd\u2211\ni=1\nui,t ln 1\nvi,t+1\n)\n6 m(uT1 )\n\u03b7T ln d(1 \u2212 \u03b1T ) \u03b1T +\nT\u2211\nt=2\n\u2016ut\u20161 \u03b7t\u22121 ln 1 1\u2212 \u03b1t +\nd\u2211\ni=1\n( ui,1 \u03b71 ln 1 vi,2 \u2212 ui,T \u03b7T ln 1\nvi,T+1\ufe38 \ufe37\ufe37 \ufe38 >0\n) .\nAn application of (14) \u2014including for t = 1, for which we recall that p\u0302i,1 = 1/d and \u03b71 = \u03b70 by convention\u2014 concludes the proof.\nA NEW LOOK AT SHIFTING REGRET"}, {"heading": "Appendix B. Proof of Proposition 11", "text": "Proof By the definition of exp-concavity and by application of Jensen\u2019s inequality to the distribution Pt over (\u2206d)t with density\nrt1 7\u2212\u2192 1\nE [ e\u2212\u03b70Lt\u22121(r t\u22121 1 ) ] e\u2212\u03b70Lt\u22121(r\nt\u22121 1\n) \u00d7 1\nwith respect to the marginal distribution of P over (\u2206d)t, we have that\nexp ( \u2212\u03b70 \u2113t(p\u0302t) ) = exp ( \u2212\u03b70 \u2113t ( Et[Qt] )) > Et [ exp ( \u2212\u03b70 \u2113t(Qt) )] = E\n[ e\u2212\u03b70Lt(Q t 1 ) ]\nE [ e\u2212\u03b70Lt\u22121(Q t\u22121 1 ) ] .\nThus, a telescoping sum appears,\nT\u2211\nt=1\n\u2113t(p\u0302t) =\nT\u2211\nt=1\n\u2212 1 \u03b70 ln e\u2212\u03b70\u2113t(p\u0302t) 6 \u2212 1 \u03b70\nlnE [ e\u2212\u03b70LT (Q T 1 ) ] .\nIt suffices to lower bound the expectation. To do so, we define for all sequences rk1 the set of the sequences of k weight vectors that only shift when rk1 does and that at each such shift are \u03b5\u2013close to the corresponding values of the rt:\nS\u03b5,rk 1\n= { sk1 \u2208 X k : \u2200t \u2208 {2, . . . , k}, st 6= st\u22121 \u21d2 rt 6= rt\u22121\nand \u2200t \u2208 {1, . . . , k}, st = (1\u2212 \u03b5)rt + \u03b5wt for some wt \u2208 X } .\nNote that the second defining constraint is equivalent to the same constraint only at the shifting times of rk1 , in view of the first constraint. Since exp-concave loss functions are in particular convex, we get that for all sT1 \u2208 S\u03b5,qT\n1\n,\nT\u2211\nt=1\n\u2113t(st) 6 (1\u2212 \u03b5) T\u2211\nt=1\n\u2113t(qt) + \u03b5\nT\u2211\nt=1\n\u2113t(wt) 6\nT\u2211\nt=1\n\u2113t(qt) + \u03b5LT .\nThus,\n\u2212 1 \u03b70\nlnE [ e\u2212\u03b70LT (Q T 1 ) ] 6 \u2212 1\n\u03b70 lnE\n[ e\u2212\u03b70LT (Q T 1 ) I{\nQT 1 \u2208S\n\u03b5,qT 1\n} ]\n6\nT\u2211\nt=1\n\u2113t(qt) + \u03b5LT \u2212 1\n\u03b70 lnP\n( S\u03b5,qT\n1\n) .\nFurthermore, we show by induction on t that for all t > 1,\nP ( S\u03b5,qt\n1\n) > \u03b5d\u22121(1\u2212 \u03b1)t\u2212s(qT1 )\u22121 ( \u03b1\u03b5d\u22121 )s(qT 1 ) .\nThis is true for t = 1 as S\u03b5,q1 = (1 \u2212 \u03b5)q1 + \u03b5X has a P\u2013probability given by its \u00b5\u2013probability, which is equal to \u03b5d\u22121 \u00b5(X ) = \u03b5d\u22121, and as by convention, s(q1) = 0. Besides, when t > 2, we have by definition of P (cf. its defining transition probability distributions) and S\u03b5,qt\n1 (cf. the st1 can only shift when the qt1 do) that\nP ( S\u03b5,qt\n1\n) >\n{ (1\u2212 \u03b1) P ( S\u03b5,qt\u22121\n1\n) when qt = qt\u22121\n\u03b1 P ( S\u03b5,qt\u22121\n1\n) \u00b5(S\u03b5,rt) = \u03b1 \u03b5 d\u22121 P ( S\u03b5,qt\u22121\n1\n) when qt 6= qt\u22121 ,\nwhich concludes the induction. Substituting the obtained bound, we have proved so far that\nT\u2211\nt=1\n\u2113t(p\u0302t)\u2212 T\u2211\nt=1\n\u2113t(qt) 6 \u03b5LT \u2212 1 \u03b70 ln ( \u03b5d\u22121(1\u2212 \u03b1)t\u2212s(qT1 )\u22121 ( \u03b1\u03b5d\u22121 )s(qT 1 )) .\n\u03b5 \u2208 [0, 1] is a parameter of the analysis, it can be optimized to minimize\n\u03b5LT +\n( s(qT1 ) + 1 ) (d\u2212 1)\n\u03b70 ln\n1\n\u03b5\nand get the claimed bound. This is achieved by choosing\n\u03b5 = min { 1, ( s(qT1 ) + 1 ) (d\u2212 1)\n\u03b70LT\n} ."}], "references": [{"title": "Adaptive and self-confident on-line learning algorithms", "author": ["P. Auer", "N. Cesa-Bianchi", "C. Gentile"], "venue": "Journal of Computer and System Sciences,", "citeRegEx": "Auer et al\\.,? \\Q2002\\E", "shortCiteRegEx": "Auer et al\\.", "year": 2002}, {"title": "Universal portfolios with and without transaction costs", "author": ["A. Blum", "A. Kalai"], "venue": "In Proceedings of the 10th Annual Conference on Learning Theory (COLT),", "citeRegEx": "Blum and Kalai.,? \\Q1997\\E", "shortCiteRegEx": "Blum and Kalai.", "year": 1997}, {"title": "From extermal to internal regret", "author": ["A. Blum", "Y. Mansour"], "venue": "Journal of Machine Learning Research,", "citeRegEx": "Blum and Mansour.,? \\Q2007\\E", "shortCiteRegEx": "Blum and Mansour.", "year": 2007}, {"title": "Tracking a small set of experts by mixing past posteriors", "author": ["O. Bousquet", "M.K. Warmuth"], "venue": "Journal of Machine Learning Research,", "citeRegEx": "Bousquet and Warmuth.,? \\Q2002\\E", "shortCiteRegEx": "Bousquet and Warmuth.", "year": 2002}, {"title": "Prediction, learning, and games", "author": ["N. Cesa-Bianchi", "G. Lugosi"], "venue": null, "citeRegEx": "Cesa.Bianchi and Lugosi.,? \\Q2006\\E", "shortCiteRegEx": "Cesa.Bianchi and Lugosi.", "year": 2006}, {"title": "Efficient projections onto the l1\u2013ball for learning in high dimensions", "author": ["J. Duchi", "S. Shalev-Shwartz", "Y. Singer", "T. Chandra"], "venue": "In Proceedings of the 25th International Conference on Machine Learning,", "citeRegEx": "Duchi et al\\.,? \\Q2008\\E", "shortCiteRegEx": "Duchi et al\\.", "year": 2008}, {"title": "Tracking the best of many experts", "author": ["A. Gy\u00f6rgy", "T. Linder", "G. Lugosi"], "venue": "In Proceedings of the 18th Annual Conference on Learning Theory (COLT),", "citeRegEx": "Gy\u00f6rgy et al\\.,? \\Q2005\\E", "shortCiteRegEx": "Gy\u00f6rgy et al\\.", "year": 2005}, {"title": "Efficient learning algorithms for changing environment", "author": ["E. Hazan", "C. Seshadhri"], "venue": "Proceedings of the 26th International Conference of Machine Learning (ICML),", "citeRegEx": "Hazan and Seshadhri.,? \\Q2009\\E", "shortCiteRegEx": "Hazan and Seshadhri.", "year": 2009}, {"title": "Tracking the best expert", "author": ["M. Herbster", "M. Warmuth"], "venue": "Machine Learning,", "citeRegEx": "Herbster and Warmuth.,? \\Q1998\\E", "shortCiteRegEx": "Herbster and Warmuth.", "year": 1998}, {"title": "Tracking the best linear predictor", "author": ["M. Herbster", "M. Warmuth"], "venue": "Journal of Machine Learning Research,", "citeRegEx": "Herbster and Warmuth.,? \\Q2001\\E", "shortCiteRegEx": "Herbster and Warmuth.", "year": 2001}, {"title": "Derandomizing stochastic prediction strategies", "author": ["V. Vovk"], "venue": "Machine Learning,", "citeRegEx": "Vovk.,? \\Q1999\\E", "shortCiteRegEx": "Vovk.", "year": 1999}, {"title": "Online convex programming and generalized infinitesimal gradient ascent", "author": ["M. Zinkevich"], "venue": "In Proceedings of the 20th International Conference on Machine Learning,", "citeRegEx": "Zinkevich.,? \\Q2003\\E", "shortCiteRegEx": "Zinkevich.", "year": 2003}], "referenceMentions": [{"referenceID": 7, "context": "Abstract We investigate extensions of well-known online learning algorithms such as fixed-share of Herbster and Warmuth (1998) or the methods proposed by Bousquet and Warmuth (2002).", "startOffset": 99, "endOffset": 127}, {"referenceID": 3, "context": "Abstract We investigate extensions of well-known online learning algorithms such as fixed-share of Herbster and Warmuth (1998) or the methods proposed by Bousquet and Warmuth (2002). These algorithms use weight sharing schemes to perform as well as the best sequence of experts with a limited number of changes.", "startOffset": 154, "endOffset": 182}, {"referenceID": 4, "context": "typically computed in terms of the p-norm of the difference of consecutive elements in the comparison sequence \u2014see Herbster and Warmuth (2001) and Cesa-Bianchi and Lugosi (2006).", "startOffset": 116, "endOffset": 144}, {"referenceID": 3, "context": "typically computed in terms of the p-norm of the difference of consecutive elements in the comparison sequence \u2014see Herbster and Warmuth (2001) and Cesa-Bianchi and Lugosi (2006). In this paper we focus on the important special case when S is the simplex, and investigate the online mirror descent with entropic regularizers.", "startOffset": 148, "endOffset": 179}, {"referenceID": 3, "context": "typically computed in terms of the p-norm of the difference of consecutive elements in the comparison sequence \u2014see Herbster and Warmuth (2001) and Cesa-Bianchi and Lugosi (2006). In this paper we focus on the important special case when S is the simplex, and investigate the online mirror descent with entropic regularizers. This family includes popular algorithms such as exponentially weighted average (EWA), Winnow, and exponentiated gradient. Proving general shifting bounds in this case is difficult due to the behavior of the regularizer at the boundary of the simplex. Herbster and Warmuth (2001) show shifting bounds for mirror descent with entropic regularizers using a 1-norm to measure the shift.", "startOffset": 148, "endOffset": 605}, {"referenceID": 3, "context": "typically computed in terms of the p-norm of the difference of consecutive elements in the comparison sequence \u2014see Herbster and Warmuth (2001) and Cesa-Bianchi and Lugosi (2006). In this paper we focus on the important special case when S is the simplex, and investigate the online mirror descent with entropic regularizers. This family includes popular algorithms such as exponentially weighted average (EWA), Winnow, and exponentiated gradient. Proving general shifting bounds in this case is difficult due to the behavior of the regularizer at the boundary of the simplex. Herbster and Warmuth (2001) show shifting bounds for mirror descent with entropic regularizers using a 1-norm to measure the shift. In order to keep mirror descent from choosing points too close to the simplex boundary, they use a complex dynamic projection technique. When the comparison sequence is restricted to the corners of the simplex (which is the setting of prediction with expert advice), then the shift is naturally defined to be the number times the trajectory moves to a different corner. This problem is often called \u201ctracking the best expert\u201d \u2014see, e.g., Herbster and Warmuth (1998); Vovk (1999); Herbster and Warmuth (2001); Bousquet and Warmuth (2002); Gy\u00f6rgy et al.", "startOffset": 148, "endOffset": 1175}, {"referenceID": 3, "context": "typically computed in terms of the p-norm of the difference of consecutive elements in the comparison sequence \u2014see Herbster and Warmuth (2001) and Cesa-Bianchi and Lugosi (2006). In this paper we focus on the important special case when S is the simplex, and investigate the online mirror descent with entropic regularizers. This family includes popular algorithms such as exponentially weighted average (EWA), Winnow, and exponentiated gradient. Proving general shifting bounds in this case is difficult due to the behavior of the regularizer at the boundary of the simplex. Herbster and Warmuth (2001) show shifting bounds for mirror descent with entropic regularizers using a 1-norm to measure the shift. In order to keep mirror descent from choosing points too close to the simplex boundary, they use a complex dynamic projection technique. When the comparison sequence is restricted to the corners of the simplex (which is the setting of prediction with expert advice), then the shift is naturally defined to be the number times the trajectory moves to a different corner. This problem is often called \u201ctracking the best expert\u201d \u2014see, e.g., Herbster and Warmuth (1998); Vovk (1999); Herbster and Warmuth (2001); Bousquet and Warmuth (2002); Gy\u00f6rgy et al.", "startOffset": 148, "endOffset": 1188}, {"referenceID": 3, "context": "typically computed in terms of the p-norm of the difference of consecutive elements in the comparison sequence \u2014see Herbster and Warmuth (2001) and Cesa-Bianchi and Lugosi (2006). In this paper we focus on the important special case when S is the simplex, and investigate the online mirror descent with entropic regularizers. This family includes popular algorithms such as exponentially weighted average (EWA), Winnow, and exponentiated gradient. Proving general shifting bounds in this case is difficult due to the behavior of the regularizer at the boundary of the simplex. Herbster and Warmuth (2001) show shifting bounds for mirror descent with entropic regularizers using a 1-norm to measure the shift. In order to keep mirror descent from choosing points too close to the simplex boundary, they use a complex dynamic projection technique. When the comparison sequence is restricted to the corners of the simplex (which is the setting of prediction with expert advice), then the shift is naturally defined to be the number times the trajectory moves to a different corner. This problem is often called \u201ctracking the best expert\u201d \u2014see, e.g., Herbster and Warmuth (1998); Vovk (1999); Herbster and Warmuth (2001); Bousquet and Warmuth (2002); Gy\u00f6rgy et al.", "startOffset": 148, "endOffset": 1217}, {"referenceID": 3, "context": ", Herbster and Warmuth (1998); Vovk (1999); Herbster and Warmuth (2001); Bousquet and Warmuth (2002); Gy\u00f6rgy et al.", "startOffset": 73, "endOffset": 101}, {"referenceID": 3, "context": ", Herbster and Warmuth (1998); Vovk (1999); Herbster and Warmuth (2001); Bousquet and Warmuth (2002); Gy\u00f6rgy et al. (2005), and it is well known that EWA with weight sharing, which corresponds to the fixedshare algorithm of Herbster and Warmuth (1998), achieves a good shifting bound in this setting.", "startOffset": 73, "endOffset": 123}, {"referenceID": 3, "context": ", Herbster and Warmuth (1998); Vovk (1999); Herbster and Warmuth (2001); Bousquet and Warmuth (2002); Gy\u00f6rgy et al. (2005), and it is well known that EWA with weight sharing, which corresponds to the fixedshare algorithm of Herbster and Warmuth (1998), achieves a good shifting bound in this setting.", "startOffset": 73, "endOffset": 252}, {"referenceID": 3, "context": ", Herbster and Warmuth (1998); Vovk (1999); Herbster and Warmuth (2001); Bousquet and Warmuth (2002); Gy\u00f6rgy et al. (2005), and it is well known that EWA with weight sharing, which corresponds to the fixedshare algorithm of Herbster and Warmuth (1998), achieves a good shifting bound in this setting. Bousquet and Warmuth (2002) introduce a generalization of the fixed-share algorithm, and prove various shifting bounds for any trajectory in the simplex.", "startOffset": 73, "endOffset": 329}, {"referenceID": 3, "context": ", Herbster and Warmuth (1998); Vovk (1999); Herbster and Warmuth (2001); Bousquet and Warmuth (2002); Gy\u00f6rgy et al. (2005), and it is well known that EWA with weight sharing, which corresponds to the fixedshare algorithm of Herbster and Warmuth (1998), achieves a good shifting bound in this setting. Bousquet and Warmuth (2002) introduce a generalization of the fixed-share algorithm, and prove various shifting bounds for any trajectory in the simplex. However, their bounds are expressed using a quantity that corresponds to a proper shift only for trajectories on the simplex corners. Our analysis unifies, generalizes (and simplifies) the previously quite different proof techniques and algorithms used in Herbster and Warmuth (1998) and Bousquet and Warmuth (2002).", "startOffset": 73, "endOffset": 739}, {"referenceID": 3, "context": ", Herbster and Warmuth (1998); Vovk (1999); Herbster and Warmuth (2001); Bousquet and Warmuth (2002); Gy\u00f6rgy et al. (2005), and it is well known that EWA with weight sharing, which corresponds to the fixedshare algorithm of Herbster and Warmuth (1998), achieves a good shifting bound in this setting. Bousquet and Warmuth (2002) introduce a generalization of the fixed-share algorithm, and prove various shifting bounds for any trajectory in the simplex. However, their bounds are expressed using a quantity that corresponds to a proper shift only for trajectories on the simplex corners. Our analysis unifies, generalizes (and simplifies) the previously quite different proof techniques and algorithms used in Herbster and Warmuth (1998) and Bousquet and Warmuth (2002). Our bounds are expressed in terms of a notion of shift based on the total variation distance.", "startOffset": 73, "endOffset": 771}, {"referenceID": 3, "context": ", Herbster and Warmuth (1998); Vovk (1999); Herbster and Warmuth (2001); Bousquet and Warmuth (2002); Gy\u00f6rgy et al. (2005), and it is well known that EWA with weight sharing, which corresponds to the fixedshare algorithm of Herbster and Warmuth (1998), achieves a good shifting bound in this setting. Bousquet and Warmuth (2002) introduce a generalization of the fixed-share algorithm, and prove various shifting bounds for any trajectory in the simplex. However, their bounds are expressed using a quantity that corresponds to a proper shift only for trajectories on the simplex corners. Our analysis unifies, generalizes (and simplifies) the previously quite different proof techniques and algorithms used in Herbster and Warmuth (1998) and Bousquet and Warmuth (2002). Our bounds are expressed in terms of a notion of shift based on the total variation distance. The generalization of the \u201csmall expert set\u201d result in Bousquet and Warmuth (2002) leads us to obtain better bounds when the sequence against which the regret is measured is sparse.", "startOffset": 73, "endOffset": 949}, {"referenceID": 3, "context": ", Herbster and Warmuth (1998); Vovk (1999); Herbster and Warmuth (2001); Bousquet and Warmuth (2002); Gy\u00f6rgy et al. (2005), and it is well known that EWA with weight sharing, which corresponds to the fixedshare algorithm of Herbster and Warmuth (1998), achieves a good shifting bound in this setting. Bousquet and Warmuth (2002) introduce a generalization of the fixed-share algorithm, and prove various shifting bounds for any trajectory in the simplex. However, their bounds are expressed using a quantity that corresponds to a proper shift only for trajectories on the simplex corners. Our analysis unifies, generalizes (and simplifies) the previously quite different proof techniques and algorithms used in Herbster and Warmuth (1998) and Bousquet and Warmuth (2002). Our bounds are expressed in terms of a notion of shift based on the total variation distance. The generalization of the \u201csmall expert set\u201d result in Bousquet and Warmuth (2002) leads us to obtain better bounds when the sequence against which the regret is measured is sparse. When the trajectory is restricted to the corners of the simplex, we recover, and occasionally improve, the known shifting bounds for prediction with expert advice. Besides, our analysis also captures the setting of adaptive regret, a related notion of regret introduced by Hazan and Seshadhri (2009). It was known that shifting regret and adaptive regret had some connections but this connection is now seen to be even tighter, as both regrets can be viewed as instances of the same alma mater regret, which we minimize.", "startOffset": 73, "endOffset": 1348}, {"referenceID": 2, "context": "In the now classical results on tracking the best expert (as in Herbster and Warmuth 1998; Vovk 1999; Herbster and Warmuth 2001; Bousquet and Warmuth 2002), this regularity is measured as the number of times qt 6= qt+1 (henceforth referred to as \u201chard shifts\u201d). The main results of this paper show not only that these results may be generalized to obtain bounds in terms of \u201csofter\u201d regularity measures but that the same algorithms that were proposed with hard shift tracking in mind achieve such, perhaps surprisingly good, performance. Building on the general formulation introduced in Section 2, we derive such regret bounds for the fixed-share algorithm of Herbster and Warmuth (1998) and for the algorithms of Bousquet and Warmuth (2002).", "startOffset": 129, "endOffset": 689}, {"referenceID": 2, "context": "In the now classical results on tracking the best expert (as in Herbster and Warmuth 1998; Vovk 1999; Herbster and Warmuth 2001; Bousquet and Warmuth 2002), this regularity is measured as the number of times qt 6= qt+1 (henceforth referred to as \u201chard shifts\u201d). The main results of this paper show not only that these results may be generalized to obtain bounds in terms of \u201csofter\u201d regularity measures but that the same algorithms that were proposed with hard shift tracking in mind achieve such, perhaps surprisingly good, performance. Building on the general formulation introduced in Section 2, we derive such regret bounds for the fixed-share algorithm of Herbster and Warmuth (1998) and for the algorithms of Bousquet and Warmuth (2002). In fact, it is advantageous to extend our analysis so that we not only compare the performance of the forecaster with sequences q1, .", "startOffset": 129, "endOffset": 743}, {"referenceID": 2, "context": "Of particular interest is the case when \u2016ut\u20161 \u2208 [0, 1] which is the setting of \u201ctime selection functions\u201d (see Blum and Mansour 2007, Section 6). In particular, considering sequences \u2016ut\u20161 \u2208 {0, 1} that include the zero vector will provide us a simple way of deriving \u201cadaptive\u201d regret bounds, a notion introduced by Hazan and Seshadhri (2009). The first regret bounds derived below measure the regularity of the sequence u1 = (u1, .", "startOffset": 111, "endOffset": 344}, {"referenceID": 8, "context": "Despite seemingly different statements, this update in Algorithm 1 can be seen to lead exactly to the fixed-share algorithm of Herbster and Warmuth (1998) for prediction with expert advice.", "startOffset": 127, "endOffset": 155}, {"referenceID": 3, "context": "Sparse sequences: Bousquet-Warmuth updates Bousquet and Warmuth (2002) proposed forecasters that are able to efficiently compete with the best sequence of experts among all those sequences that only switch a bounded number of times and also take a small number of different values.", "startOffset": 43, "endOffset": 71}, {"referenceID": 3, "context": "Thus, n(u1 ) generalizes the notion of sparsity of Bousquet and Warmuth (2002). Here we consider a family of shared updates of the form p\u0302j,t = (1\u2212 \u03b1)vj,t + \u03b1 wj,t Zt , 0 6 \u03b1 6 1 , (7) where the wj,t are nonnegative weights that may depend on past and current pre-weights and Zt = \u2211d i=1 wi,t is a normalization constant.", "startOffset": 51, "endOffset": 79}, {"referenceID": 3, "context": "Thus, n(u1 ) generalizes the notion of sparsity of Bousquet and Warmuth (2002). Here we consider a family of shared updates of the form p\u0302j,t = (1\u2212 \u03b1)vj,t + \u03b1 wj,t Zt , 0 6 \u03b1 6 1 , (7) where the wj,t are nonnegative weights that may depend on past and current pre-weights and Zt = \u2211d i=1 wi,t is a normalization constant. Shared updates of this form were proposed by Bousquet and Warmuth (2002, Sections 3 and 5.2). Apart from generalizing the regret bounds of Bousquet and Warmuth (2002), we believe that the analysis given below is significantly simpler and more transparent.", "startOffset": 51, "endOffset": 489}, {"referenceID": 3, "context": "We now generalize Corollaries 8 and 9 of Bousquet and Warmuth (2002) by showing two specific instances of the generic update (7) that satisfy (8).", "startOffset": 41, "endOffset": 69}, {"referenceID": 3, "context": "In contrast, the corresponding algorithm of Bousquet and Warmuth (2002), using the updates p\u0302j,t = (1\u2212\u03b1)vj,t+\u03b1S t \u2211 s6t\u22121(s\u2212t)vj,s or p\u0302j,t = (1\u2212\u03b1)vj,t+\u03b1S t maxs6t\u22121(s\u2212t)vj,s, where St denote normalization factors, needs to maintain O(dT ) weights with a naive implementation, and O(d lnT ) weights with a more sophisticated one.", "startOffset": 44, "endOffset": 72}, {"referenceID": 7, "context": ", Proposition 2, imply guarantees in terms of adaptive regret \u2014a notion introduced by Hazan and Seshadhri (2009) as follows.", "startOffset": 86, "endOffset": 113}, {"referenceID": 6, "context": "Hazan and Seshadhri (2009) essentially considered the case of online convex optimization with exp-concave loss function (see Section 6 below).", "startOffset": 0, "endOffset": 27}, {"referenceID": 6, "context": "Hazan and Seshadhri (2009) essentially considered the case of online convex optimization with exp-concave loss function (see Section 6 below). In case of general convex functions, they also mentioned that the greedy projection forecaster of Zinkevich (2003) \u2014i.", "startOffset": 0, "endOffset": 258}, {"referenceID": 5, "context": ", Duchi et al. (2008). We now show that the simpler fixed-share algorithm has a similar adaptive regret bound.", "startOffset": 2, "endOffset": 22}, {"referenceID": 0, "context": "We show here how the trick of Auer et al. (2002) of having these parameters vary over time can be extended to our setting.", "startOffset": 30, "endOffset": 49}, {"referenceID": 3, "context": ") Bousquet and Warmuth (2002) study shifting regret for exp-concave loss functions.", "startOffset": 2, "endOffset": 30}, {"referenceID": 6, "context": "Hazan and Seshadhri (2009) constructed algorithms with T\u2013 adaptive regret of the order of O(ln T ) and running in time poly(d, log T ).", "startOffset": 0, "endOffset": 27}, {"referenceID": 6, "context": "Hazan and Seshadhri (2009) constructed algorithms with T\u2013 adaptive regret of the order of O(ln T ) and running in time poly(d, log T ). They also constructed different algorithms with T\u2013adaptive regret bounded by O(lnT )) and running time poly(d, T ). Next, we show the first logarithmic shifting bounds for exp-concave loss functions. However, we only do so against sequences q1 of elements in \u2206d, i.e., we offer here no general bound in terms of linear vectors u1 that would unify here as well the view between tracking bounds and adaptive regret bounds. Besides, we get shifting bounds only in terms of hard shifts s(q1 ) = \u2223t = 2, . . . , T : qt 6= qt\u22121 }\u2223\u2223 . Obviously, getting unifying bounds in terms of soft shifts of sequences u1 of linear vectors is an important open question, which we leave for future research. To get our bound, we mix ideas of Herbster and Warmuth (1998) and Blum and Kalai (1997).", "startOffset": 0, "endOffset": 886}, {"referenceID": 1, "context": "To get our bound, we mix ideas of Herbster and Warmuth (1998) and Blum and Kalai (1997). We define a prior over the sequences of convex weight vectors as the distribution of the following homogeneous Markov chain Q1, Q2, .", "startOffset": 66, "endOffset": 88}], "year": 2017, "abstractText": "We investigate extensions of well-known online learning algorithms such as fixed-share of Herbster and Warmuth (1998) or the methods proposed by Bousquet and Warmuth (2002). These algorithms use weight sharing schemes to perform as well as the best sequence of experts with a limited number of changes. Here we show, with a common, general, and simpler analysis, that weight sharing in fact achieves much more than what it was designed for. We use it to simultaneously prove new shifting regret bounds for online convex optimization on the simplex in terms of the total variation distance as well as new bounds for the related setting of adaptive regret. Finally, we exhibit the first logarithmic shifting bounds for exp-concave loss functions on the simplex.", "creator": "LaTeX with hyperref package"}}}