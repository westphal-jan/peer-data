{"id": "1206.0918", "review": {"conference": "arxiv", "VERSION": "v1", "DATE_OF_SUBMISSION": "5-Jun-2012", "title": "Fuzzy Knowledge Representation Based on Possibilistic and Necessary Bayesian Networks", "abstract": "within discussions the interdisciplinary framework proposed in this resulting paper, we address perhaps the practical issue of extending the dynamic certain networks to function a fuzzy certain networks in such order presumably to initially cope with a quantitative vagueness and limitations of existing models advocated for human decision retrieval under imprecise and uncertain knowledge. this paper originally proposes a framework that ultimately combines two disciplines used to exploit their functional own security advantages described in uncertain and imprecise knowledge space representation problems. the framework proposed is a possibilistic relational logic based one mode in which distributed bayesian nodes and their properties matrices are represented by corresponding local necessity - valued knowledge base. structured data in properties statements are interpreted principally as this set of underlying valuated computation formulas. as in our contribution possibilistic bayesian networks have a qualitative structured part and a similar quantitative linear part, represented by local knowledge tree bases. the general idea is to indirectly study how allowing a computational fusion of selecting these variables two formalisms would someday permit structures representing compact random way to progressively solve efficiently problems for storing knowledge seek representation. we show at how steps to apply possibility and necessity measures to the problem of knowledge retrieval representation with large scale data. planning on considering the whole other party hand fuzzification of crisp certainty degrees to estimate fuzzy variables absolutely improves the quality of the associated network characteristics and tends to possibly bring total smoothness upward and robustness increased in the network performance. alternatively the expected general aim is poised to hopefully provide : a new approach for decision under constrained uncertainty that combines three applicable methodologies : statistical bayesian operational networks certainty involves distribution logic and fuzzy logic.", "histories": [["v1", "Tue, 5 Jun 2012 13:13:21 GMT  (645kb)", "http://arxiv.org/abs/1206.0918v1", "ISSN: 1790-0832"]], "COMMENTS": "ISSN: 1790-0832", "reviews": [], "SUBJECTS": "cs.AI", "authors": ["abdelkader heni", "mohamed nazih omri", "adel alimi"], "accepted": false, "id": "1206.0918"}, "pdf": {"name": "1206.0918.pdf", "metadata": {"source": "CRF", "title": "Fuzzy Knowledge Representation Based on Possibilistic and Necessary Bayesian Networks", "authors": ["ABDELKADER HENI"], "emails": ["abdelkader.heni@edunet.tn,", "nazih.omri@ipeim.rnu.tn,", "adel.alimi@enis.rnu.tn"], "sections": [{"heading": null, "text": "networks in order to cope with a vagueness and limitations of existing models for decision under imprecise and uncertain knowledge. This paper proposes a framework that combines two disciplines to exploit their own advantages in uncertain and imprecise knowledge representation problems. The framework proposed is a possibilistic logic based one in which Bayesian nodes and their properties are represented by local necessity-valued knowledge base. Data in properties are interpreted as set of valuated formulas. In our contribution possibilistic Bayesian networks have a qualitative part and a quantitative part, represented by local knowledge bases. The general idea is to study how a fusion of these two formalisms would permit representing compact way to solve efficiently problems for knowledge representation. We show how to apply possibility and necessity measures to the problem of knowledge representation with large scale data. On the other hand fuzzification of crisp certainty degrees to fuzzy variables improves the quality of the network and tends to bring smoothness and robustness in the network performance. The general aim is to provide a new approach for decision under uncertainty that combines three methodologies: Bayesian networks certainty distribution and fuzzy logic . Key-Words: - Possibilistic logic, Bayesian networks, Certain Bayesian networks, Local knowledge bases"}, {"heading": "1 Introduction", "text": "Bayesian networks have attracted much attention recently as a possible solution to complex problems related to decision support under uncertainty. These networks are systems for uncertain knowledge representation and have a big number of applications with efficient algorithms and have strong theoretical foundations [1],[2],[3],[4],[5] and [11]. They use graphs capturing causality notion between variables, and probability theory (statistic data) to express the causality power.\nAlthough the underlying theory has been around for a long time, the possibility of building and executing realistic models has only been made possible because of recent improvements on algorithms and the availability of fast electronic computers. On the other hand, one of the main limits of Bayesian networks is necessity to provide a large number of numeric data; a constraint often difficult to satisfy when the number of random variables grows up. The goal of this paper is to develop a qualitative framework where the uncertainty is represented in possibility theory; an ordinal theory for uncertainty developed since more than ten years [6], [7], and [8]. Our framework propose to define a qualitative notion of independence (alternative to the probability theory), to propose techniques of decomposition of\njoined possibility distributions, and to develop some efficient algorithms for the revision of beliefs. Thus, on the first hand limitations of quantitative structure in Bayesian networks that use simple random variables have been noted by many researches. These limitations have motivated a variety of recent research in hierarchical and composable Bayesian models.\nOn the other hand, another limitation of the use of probabilistic Bayesian networks in expert systems is difficulty of obtaining realistic probabilities. So to solve these problems we use a new modified possibilistic Bayesian method. Our new modified possibilistic Bayesian networks simultaneously make use of both possibilistic measures: necessity measure and possibility measure.\nOur work extends and refines these proposed frameworks in a number of crucial ways. The language defined in [12] [13] and in [15] has been modified to enhance usability and to support a more powerful system. We are trying in this paper to describe a language that provides the important capability of uncertainty modeling. We have also combined different element from works cited above to describe our possibilistic networks based on local necessity-valued knowledge bases.\nWSEAS TRANS. on INFORMATION SCIENCE & APPLICATIONS Issue 2, Volume 3, February 2006 ISSN: 1790-0832\n225\nIn this paper we consider a type of possibilistic network that is based on the context model interpretation of a degree of possibility and focused on imprecision [14]. The first section presents an overview of standard possibilistic networks and their extensions. The following section describes our contribution with the use of necessity-valued knowledge bases as quantitative representation for uncertainty in nodes. And eventually we will talk about the transformations between average fuzzyBayesian networks and average knowledge bases.\n2 Necessity-possibility measures and\npossibilistic networks\nIn order to be able to discuss our framework for possibilistic networks we shall in this section give a few preliminary definitions and notational conventions. At the same time, we present a brief outline of few important notations and ideas in possibility theory and possibilistic networks relevant to the subject of this paper."}, {"heading": "2.1 Possibilistic logic", "text": "Let L be a finite propositional language. p; q; r; . . . denote propositional formulae.\nand \u22a5, respectively, denote tautologies and contradictions. denotes the classical syntactic\ninference relation. \u2126 is the set of classical interpretations\n\u03c9 of L, and [p] is the set of classical models of p (i.e,\ninterpretations where p is true {\u03c9 | \u03c9 p}) [13].\n2.1.1 Possibility-necessity distributions and\npossibility-necessity measures\nThe basic element of possibility theory is the possibility\ndistribution \u220f which is a mapping from \u2126 to the interval\n[0 1]. The degree \u03c0(\u03c9) represents the compatibility of \u03c9 with the available information (or beliefs) about the real\nworld. By convention, \u03c0(\u03c9)= 0 means that the\ninterpretation \u03c9 is impossible, and \u03c0(\u03c9) = 1 means that\nnothing prevents \u03c9 from being the real world [13].\nGiven a possibility distribution \u03c0, two different ways of rank ordering formulae of the language are defined from this possibility distribution. This is obtained using two mappings grading, respectively, the possibility and the certainty of a formula p:\n\u2022 The possibility (or consistency) degree:\n\u220f(p) = max ( \u03c0 (\u03c9) : \u03c9 \u2208 [p]) (1)\nWhich evaluates the extent to which p is consistent with the available beliefs expressed by p [16]. It satisfies:\n\u2200p, \u2200q \u220f(p\u2228 q) = max (\u220f (p), \u220f (q)) (2)\n\u2022 The necessity (or certainty, entailment) degree\nN(P) = 1 - \u220f(\u00acp) (3) Which evaluates the extent to which p is entailed by the available beliefs. We have [17]: \u2200p, \u2200q N (p\u2227q) = max (N(p), N (q)) (4)\nTo note here that in our case, we consider that both necessity degree and possibility degrees for a given formulae should be given by an expert. On the other hand, when a data is required (a possibility degree or necessity degree) one should deduce it by applying equation (3)."}, {"heading": "2.1.2 Fuzzy knowledge base", "text": "A fuzzy formula is a tripley (\u03d5, \u03b1,\u03b2) where \u03d5 is a\nclassical first-order closed formula and (\u03b1,\u03b2 )\u2208 [0,1] are\na positive numbers. (\u03d5, \u03b1,\u03b2) expresses that \u03d5 is possible\nat least to the degree \u03b1 , and certain at least to the degree\n\u03b2 i.e. \u220f(\u03d5) \u2265 \u03b1 and \u03b2 N(\u03d5) \u2265 \u03b2, where \u220f and N are respectively a possibility and necessity measures modelling our possibly incomplete state of knowledge.\nThe right part of a possibilistic formula, i.e. \u03b1 and \u03b2, are respectively called the possibility and necessity weights of the formula.\nA fuzzy knowledge base \u2211 is defined as the set of weighted formulae [18]. More formally\n\u2211= {(\u03d5\u03b9 , \u03b1i,\u03b2 i) , i = 1\u2026.m} where \u03d5\u03b9 is a propositional formula \u03b1i is the higher bound of possibility and \u03b2I is the lower bound of necessity accorded to this formula (certainty degree)."}, {"heading": "3 Fuzzy Bayesian networks", "text": "A standard possibilistic network is a decomposition of a multivariate possibility distribution according to:\n\u03c0 (A1,\u2026..,An) = mini=1..n \u03c0 (Ai | parents(Ai)) (5)\nwhere parents(Ai) is the set of parents of variable Ai, which is made as small as possible by exploiting conditional independencies of the type indicated above [9] and [10]. Such a network is usually represented as a directed graph in which there is an edge from each of the parents to the conditioned variable.\nWSEAS TRANS. on INFORMATION SCIENCE & APPLICATIONS Issue 2, Volume 3, February 2006 ISSN: 1790-0832 226\nIn our work an average fuzzy Bayesian networks is considered as a graphical representation of uncertain information. It offers an alternative to probabilistic causal network when numerical data are not available.\nLet V= {A1,A2,..An} be a set of variables (i.e attributes or proprieties). The set of interpretations is the Cartesian product of all domains of attributes in V. When each\nattribute is binary, domains are denoted by Di={ai,\u00acai}.\nAn average fuzzy graph denoted by \u03a0GA is an acyclic\ngraph where nodes represents attributes i.e. a patient temperature and edges represent causal links between them. Uncertainty is represented by possibilities distribution, certainties distribution and conditional possibilities and necessities for each attribute explaining the link force between them. The conditional possibilities and necessities distributions are associated to the graph as follow:\nFor each root attribute Ai, we specify prior possibility distribution \u03a0(ai),\u03a0(\u00acai) and the prior normalization)\nand the prior necessity distribution N(ai), N(\u00acai) with the constraint that :\nN(ai) = 1 N(\u00acai) =0\n(6)\nN(\u00acai)=1 N(ai) =0\n- For other attributes Aj, we specify the conditional possibilities distribution \u03a0(aj|uj), \u03a0(\u00acaj|uj) with max(\u03a0(ai|uj), \u03a0(\u00acai| uj)) =1 where uj is an instance of aj parents and the conditional necessity distribution N(ai), N(\u00acai) with the constraint that :\nN(ai|uj) = 1 N(\u00acai)|uj) =0\n(7)\nN(\u00acai)|uj)=1 N(ai)|uj) =0\nExample: the next figure gives an example of possibilistic Bayesian networks with four nodes and their conditional possibilities.\nThe joint average distribution is obtained then by applying the chain rule:\nA(A1,.,An) = min( \u03c0 (Ai|U(Ai))*min (N(Ai|U(Ai)) (8)"}, {"heading": "Where:", "text": "- A(A1,.,An) is The joint average distribution. - min ( \u03c0(Ai | U(Ai)) is the lower bound of the possibilities degrees associated to (Ai|U(Ai)). - min (N(Ai|U(Ai)) is the lower bound of the necessities degrees associated to (Ai|U(Ai)\nExample: let the prior possibilities-necessities and the\nconditional possibilities-necessities be as described in table 1:\nBy the use of the chain rule defined by equation (8) we obtain the average distribution associated with the average fuzzy Bayesian network cited above as described in table."}, {"heading": "A B C D min\u03a0 minN A", "text": "a b c d 1 0.2 0.2 a b c \u00acd 0.5 0.3 0.15 a b \u00acc d 0.5 0.1 0.05 a b \u00acc \u00acd 0.3 0.3 0.09 a \u00acb c d 0.5 0.2 0.1 a \u00acb c \u00acd 0.5 0.1 0.05 a \u00acb \u00acc d 0.5 0.1 0.05\nWSEAS TRANS. on INFORMATION SCIENCE & APPLICATIONS Issue 2, Volume 3, February 2006 ISSN: 1790-0832\n227\na \u00acb \u00acc \u00acd 0.5 0.1 0.05 \u00aca b c d 0.5 0.1 0.05 \u00aca b c \u00acd 0.5 0.1 0.05 \u00aca b \u00acc d 0.4 0.1 0.04 \u00aca b \u00acc \u00acd 0.3 0.1 0.03 \u00aca \u00acb c d 0.3 0 0 \u00aca \u00acb c \u00acd 0.3 0 0 \u00aca \u00acb \u00acc d 0.3 0 0 \u00aca \u00acb \u00acc \u00acd 0.3 0 0\nTable 2: joint average possibility-necessity distribution\n4 Average possibilistic and necessary\nvalued knowledge base We would like to represent a class of possibilistic Bayesian networks using a local average fuzzyvalued knowledge base consisting of a collection of possibilistic logic sentences (formulae) in such a way that a network generated on the basis of the information contained in the knowledge base is isomorphic to a set of ground instances of the formulae. As the formal representation of the knowledge base, we use a set of possibilistic formulae. We represent random variables with necessities and possibilities weights and restrict ourselves to using only the average of these two measures.\nFormally an average necessity-possibility valued knowledge base is defined as the set :\n\u2211= {(\u03d5\u03b9 , \u03b1i, \u03b2i) , i = 1\u2026.m} (9)\nWhere \u03d5\u03b9 denotes a classical propositional formula, \u03b1i and \u03b2i denote respectively the lower bound of certainty (i.e necessity) and the lower bound of possibility.\nWe can represent the information contained in each node of a Bayesian network, as well as the quantitative information contained in the link matrices, if we can represent all the direct parent/child relations. We express the relation between each random variable and its parents over a class of networks with a collection of quantified formulae. The collection of formulae represents the relation between the random variable and its parents for any ground instantiation of the quantified variables. The network fragment consisting of a random variable and its parents with a set of formulae of the\nform (\u03d5 , \u03b1 ,\u03b2).\nWe give next some definitions inspired from [12] and [13].\nDefinition 1: Two average knowledge bases \u2211A1 and and \u2211 A 2 are said to be equivalent if their associated possibility distributions (respectively necessity distributions) are equal, namely:\n\u2200\u03c9 \u2208\u2126, \u03c0\u2211A1 (\u03c9) = \u03c0\u2211 A 2 (\u03c9) and (10) \u2200\u03c9 \u2208\u2126, N\u2211A1 (\u03c9) = N\u2211 A 2 (\u03c9)\nDefinition 2: Let (\u03d5 , \u03b1 ,\u03b2) a formula in \u2211A Then (\u03d5 , \u03b1 ,\u03b2) is said to be subsumed by \u2211A if \u2211A and \u2211A\\{(\u03d5 , \u03b1 ,\u03b2)} are equivalent knowledge bases.\nThis is means that each redundant formula should be removed from the average valued knowledge base since it can be deduced from the rest of formulae.\n5 From fuzzy Bayesian network to fuzzy\nknowledge base In this section, we describe the process that permit to deduce an average valued knowledge base from an average network.\nLet \u03a0GA be an average and necessary Bayesian network consisting of a set of labeled variables V= {A1,A2,..An}. Now let A be a binary variable and let (a \u00aca) be its instances.\nGiven the two measures \u03c0 (ai|ui) and N(ai|ui) witch represent respectively the local possibility degree and the local necessity degree associated with the variable A\nwhere ui \u2208 UA is an instance of parents(ai). the local average knowledge base associated with A should be defined using the next equation :\n\u2211AA = {( \u00acai \u2228 ui, \u03b1\u03b9, \u03b2i), \u03b1\u03b9 = 1- \u03c0 (ai|ui) \u2260 0 and \u03b2i =1- N(ai|ui) \u2260 0 } (11)"}, {"heading": "To note here that in [15] the authors prove the possibility to recover conditional possibilities from \u2211A where \u2211A is a possibilistic knowledge base.", "text": "Based o the results obtained in [15] , we can check in our case that it is possible to recover both conditional necessities from \u2211AA according to equations (12) and (13).\n1 if \u2200 (\u03d5i , \u03b1i) \u2208\u2211 \u03c9 \u03d5i\n\u03a0\u2211A (\u03c9) = (12)\n1- max { \u03b1i : \u03c9 \u03d5i } otherwise\nWSEAS TRANS. on INFORMATION SCIENCE & APPLICATIONS Issue 2, Volume 3, February 2006 ISSN: 1790-0832 228\nand\n1 if \u2200 (\u03d5i , \u03b1i) \u2208\u2211 \u03c9 \u03d5i\nN\u2211A (\u03c9) = (13) 0 otherwise\nExample: by applying equation (11), we get the average knowledge base associated to the average fuzzy Bayesian network described in section 3.\n\u2211AA = {(a, 0.5, 0.9 )} = {(a, 0.45 )} \u2211AB = {(b\u2228a,0.7),(b\u2228\u00aca,0.5,0.75)(\u00acb\u2228a,0.25, 0.8)}\n= {(b\u2228a, 0.7), (b\u2228\u00aca, 0.375) (\u00acb\u2228a, 0.2)}\n\u2211AC={(c\u2228a,0.6,0.9),(c\u2228\u00aca,0.4,0.9) (\u00acc\u2228a,0.3, 0.8)}\n= {(c\u2228a, 0.54), (c\u2228\u00aca, 0.36 0.9) (\u00acc\u2228a, 0.24)}\n\u2211AD = {{(d\u2228b\u2228c, 0.3, 0.8), (d\u2228b\u2228\u00acc, 0.3, 0.8), (d\u2228\u00acb\u2228c, 0.7, 0.9), (d\u2228\u00acb\u2228\u00acc, 0.5, 0.6 ), (\u00acd\u2228\u00acb\u2228c, 0.5, 0.9 )}\n= {{(d\u2228b\u2228c, 0.24), (d\u2228b\u2228\u00acc, 0.24), (d\u2228\u00acb\u2228c, 0.63),\n(d\u2228\u00acb\u2228\u00acc, 0.3 ), (\u00acd\u2228\u00acb\u2228c, 0.45 )}\nRemark: for each knowledge base the first equality represents the initial knowledge base weighted by possibilities and necessities when the other represents the average based knowledge base (namely average necessity-possibility valued knowledge base).\nNext section shows the other face of transformation between average valued knowledge base and average fuzzy Bayesian network.\n6 From Average valued knowledge base\nto average fuzzy Bayesian network In [15] the authors describe a process permitting to deduce a possibilistic network from a possibilistic knowledge base. In this section we follow the same way to transform our average necessity-valued knowledge bases into an average fuzzy Bayesian network.\nTo note here that the average possibilistic and necessary Bayesian network deduced from an average necessityvalued knowledge bases will have the same graphical structure as the starting network\nThe conditional average distributions are simply the ones associated with the average knowledge bases. More precisely, let Ai be variable and ui be an element of parents(Ai). Let\u2211 A Ai be the local average knowledge base associated with the node Ai. Then, the conditional average degree A(ai|ui) is defined by \u03c0 (ai|ui) = \u03c0 (ai\u2227ui)\n= \u03c0\u2211AAi(ai\u2227ui) and \u2211 A Ai(ai\u2227ui) is defined using equation (12) and equation (13).\nRespectively the conditional necessity degree N(ai|ui) is defined by N(ai|ui) = N(ai\u2227ui) = N\u2211 A Ai(ai\u2227ui)."}, {"heading": "Example:", "text": "From the average knowledge base associated to the node A and by the use of equations 11 and 12 \u2211AA = {(a, 0.5, 0.9 )} = {(a, 0.45)} We can deduce the conditional average table for node A by the use of equations 11 and 12\n\u03c0 N A\na 1 0.6 0.6\n\u00aca 0.5 0.1 0.05\nSame to rest of nodes we can deduce the rest of conditional averages associated to other nodes and so we can recover the average distribution presented in table 2.\n7 Fuzzy Bayesian networks based on\nfuzzy necessity distribution Logical formulae with a weight strictly greater than a\ngiven levels (lower bounds of necessity degrees) are immune to inconsistency and can be safely used in deductive reasoning [19]. However in order to perform reasoning for both imprecise and uncertain information, two important issues should be addressed. First, any improvement of the possibility level for a piece of information can only be achieved at the expense of the specificity of the information; second the accorded levels to the causality explained in terms of rules (case of fuzzy logic) and conditional dependencies (case of Bayesian networks) are somewhat expensive due to the fact that these confidence level is somewhat critical.\nWe propose so to combine these three approaches (Bayesian networks certainty distribution and fuzzy logic) to develop a method for uncertain and imprecise knowledge representation that may improve decision based systems.\nOur fuzzy beliefs are to emulate a certain Bayesian necessity measure. For simplicity each variable here has two states: the presence or absence of an entity. The belief that A is present takes the form of a fuzzy truth fA. The extent to witch the belief of variable state influences the state beliefs of parent or child is modelled by a fuzzy set membership function: one for each influence direction.\nWSEAS TRANS. on INFORMATION SCIENCE & APPLICATIONS Issue 2, Volume 3, February 2006 ISSN: 1790-0832\n229"}, {"heading": "Example:", "text": "Let our certain network be as described in figure\nrepresenting a Bayesian network in metastatic cancer.\nFig 2. A Bayesian network for metastatic cancer[20]\nFig. 2 shows a Bayesian network representing the above cause and effect relationships. Table 3 lists the causal influences in terms of fuzzy certainty distributions. Each variable is characterized by an unknown necessity degree given the state of its parents. For instance:"}, {"heading": "C \u2208 [0, 1] represents the dichotomy between having a brain tumor and not having one, c denotes the assertion", "text": "C = 1 or \u201cBrain tumor is present\u201d, and \u00acc is the\nnegation of c, namely, C =0. The root node, A, which has no parent, is characterized by its prior fuzzy certainty distribution."}, {"heading": "Example", "text": "Le the conditional fuzzy necessities associated to the graph presented in figure 2 be as described in table 3. For reason of simplicity we kept here four nodes only as in the graph presented in figure 1.\nFor instance N(d| b,\u00acc) cannot be 0.1 as described in\ntable 1 but rather is a fuzzy number say \u03c71 \u2208[\u03b2D|BC1 , \u03b2D|BC2 ] where \u03c71 = \u2135(d| b,\u00acc) is the fuzzy necessity\nassociated with the fuzzy formula (d| b,\u00acc) and is\nassociated with a membership function \u00b5 ( \u03c71 ) supposed to be a triangular function (respectively \u00b5 can be\ntrapezoid or other kind of functions). \u00b5 is represented as follow (figure 3):\nThen we can deduce the next possible representation of\n\u00b5(\u03c71) as:\n\u00b5(\u03c71) = k1 x (\u03c71 \u2013\u03b2D|BC1) \u2013 k2 x (|\u03c71 \u2013 \u03b2D|BC2| + \u03c71 \u2013 \u03b1)"}, {"heading": "Where:", "text": "- \u03b1, k1 and k2 are two defined constants.. - | * | is the absolute value of term *\nThe above expression and figure mean that the interval\nof \u03c71 is [\u03b2D|BC1 , \u03b2D|BC2 ]. If \u03c71 = \u03b1 then \u00b5(\u03c71)=1, implying that the fuzzy necessity \u03c71 = \u03b1 is the most possible situation. If \u03c71 \u2265 \u03b2D|BC2 or \u03c71\u2264 \u03b2D|BC1 then \u00b5(\u03c71) = 0, the possible manifestation of \u03c71.\n8. Transformation between FBN and\nfuzzy Knowledge bases Analogously, when the given necessities degree are fuzzy numbers as we described in section 5, the necessity distribution N(X) associated to a node X is considered as a fuzzy distribution defined by a membership function\n\u00b5 : [\u03b21, \u03b22] [0 1] (14)\n\u03c7 \u00b5 (\u03c7)\nExample: consider the graph of figure 2. For simplicity each variable here has two states: the presence or absence of an entity and we will define the same\nmembership function to a as to \u00aca.\na \u00aca\n[\u03b2A11 , \u03b2A12 ] [\u03b2A21 , \u03b2A22 ]\n\u00b51(\u03c7) \u00b51(\u03c7)\nBrain tumor\nIncreased total serum calcium\nMetastatic cancer\nB\nA\nD\nC\nE\nSevere headaches Coma\n\u00b5( \u03c71 )\n\u03b2D|BC2 \u03b2D|BC1\nWSEAS TRANS. on INFORMATION SCIENCE & APPLICATIONS Issue 2, Volume 3, February 2006 ISSN: 1790-0832 230"}, {"heading": "Let the different membership be as follow:", "text": "\u00b5i(\u03c7) = ki1 x (\u03c7 \u2013\u03b2ij1) \u2013 ki2 x (|\u03c7 \u2013 \u03b2ij2| + \u03c7 \u2013 \u03b1i)"}, {"heading": "Where:", "text": "- \u00b5i(\u03c7) is the membership function associated to the fuzzy variable \u03c7, supposed to be triangular.\n- ki1 and ki2 are the used constant in each membership function supposed to be triangular.\n- \u03b2ij1 and \u03b2ij2 are the two min and the max boundary of a necessity degree.\nFinally by maximization of each membership function, we can deduce an optimal value for the certainty degree associated to each fuzzy variable (i.e. proposition). Namely:\n\u2135( \u03c7 ) = \u00b5( \u03c7 ) = 1\nThen it will be easy to deduce the value of \u03c7 as follow:\n\u03bb + ki1 x \u03b2ij1 + ki2 x \u03b2ij2 +1 \u03c7 = (15)\nki1"}, {"heading": "By replacing \u03bb by 1 (the maximization of \u00b5( \u03c7 )), the", "text": "value of \u03c7 will be:\n\u03bb + ki1 x \u03b2ij1 + ki2 x \u03b2ij2 +1 \u03c7 = (16)\nki1\nAnalogously, the definition of the fuzzy joint necessity distribution is obtained by applying the fuzzy chain rule:\n\u2135(A1,...,An) = min(\u03c7i), \u03c7i = \u2135(Ai|U(Ai)\nFrom a semantic point of view, a certain knowledge base\n\u2211= {(\u03d5\u03b9 , \u03b1i) , i = 1\u2026.m} where each \u03b1i a crisp necessity value, is understood as the necessity distribution N\u2211\nrepresenting the fuzzy sets of models of \u2211 :\nN\u2211(\u03c9) = min max ( \u00b5[Pi](\u03c9), 1-\u03b1) where [Pi] denotes the set of models of Pi, so that :\n\u00b5[Pi] = \u03b1 if \u03c9 \u2208 Pi\n\u00b5[Pi] (\u03c9) = (17) 0 otherwise\nFrom (21) we can clearly deduce clearly that N\u2211(\u03c9) is naturally a fuzzy distribution applied to a crisp set of\nvalues and \u00b5[Pi] is the crisp membership function."}, {"heading": "9 Conclusion", "text": "This paper has presented a definition of fuzzy Bayesian networks and how to use them to deduce average knowledge bases and vice versa. Uncertainty in nodes in our models is represented by local knowledge bases.\nThe key benefits of this representation to the\npractitioner are that both knowledge declaration and possibilistic inference are modular. Individual knowledge bases should be separately compilable and query complete. Also this representation specifies an organized structure for elicitation of the graph structure. We only defined the transformation process for knowledge bases.\nCertain Bayesian networks with fuzzy knowledge bases approach in a natural way gives us the subsethood of the evidence for each logical formula. Although the methodology proposed in this paper, is aimed and illustrated by some typical examples, the developed techniques require experimental results.\nA future work is to extend this representation by\ndefinition of efficient algorithms for locally inferences.\nWSEAS TRANS. on INFORMATION SCIENCE & APPLICATIONS Issue 2, Volume 3, February 2006 ISSN: 1790-0832\n231"}, {"heading": "Quantitative Approches to Rreasoning and Uncertainty,", "text": "pages 108-121, Bad Honnef Germany, (1997). [11] J. Pearl. Probabilistic Reasoning in Intelligent Systems: Networks of Plausible Inference.Morgan Kaufmann Publishers, Palo Alto, (1988). [12] S. Benferhat, S. Smaoui. Hybrid possibilistic networks. in proceeding of the Twentieth National Conference on Artificial Intelligence (AAAI-05),AAAI Press. Pittsburgh, 2005. [13] S. Benferhat, D. Dubois, L. Garcia, H. Prade. On the transformation between possibilistic logic bases and possibilistic causal networks. International Journal of Approximate Reasoning, Vol. 29, N. 21, 35-173, 2002. [14] J. Gebhardt and R. Kruse. The context model an integrating view of vagueness and uncertainty Int. Journal of Approximate Reasoning 9 283\u2013314, 1993 [15] Salem Benferhat and Salma Smaoui Possibilistic networks with locally weighted knowledge bases 4th International Symposium on Imprecise Probabilities and Their Applications, Pittsburgh, Pennsylvania, 2005 [16] L.A. Zadeh, Fuzzy sets as a basis for a theory of possibility, Fuzzy Sets and Systems 1 (1978) pp 3-28. [17] D. Dubois, H. Prade, Fuzzy Sets and Systems: Theory and applications, Academic Press, New York, 1980. [18] Dubois D. (1986) Belief structures, possibility theory and decomposable confidence measure. on finite sets. Computers and Artificial Intelligence, 5(5), 403- 416. [19] Dubois and Prade Possibilistic logic : a retrospective and prospective view. Fuzzy Sets and Systems 144 (2004) pp 3-23. [20] Han-Lin Li and Han-Ying Kao. Constrained abductive reasoning with fuzzy parameters in Bayesian networks. Computers & Operations Research 32 (2005) 87\u2013105"}], "references": [{"title": "Bayesian networks : a model of selfactivated memory for evidential reasoning", "author": ["Pearl Judea"], "venue": "Cognitive Science Society, UC Irvine,", "citeRegEx": "1", "shortCiteRegEx": "1", "year": 1985}, {"title": "A constraint-propagation approach to probabilistic reasoning", "author": ["Pearl Judea"], "venue": "Uncertainty in Artificial Intelligence,", "citeRegEx": "2", "shortCiteRegEx": "2", "year": 1986}, {"title": "Fusion, propagation and structuring in belief networks. UCLA Computer Science Department Technical Report", "author": ["Pearl Judea"], "venue": "Artificial Intelligence,,", "citeRegEx": "3", "shortCiteRegEx": "3", "year": 1986}, {"title": "Graphoids : a graph-based logic for reasoning about relevance relations", "author": ["Pearl Judea", "A. Paz"], "venue": "UCLA Computer Science Department Technical Report 850038;", "citeRegEx": "4", "shortCiteRegEx": "4", "year": 1987}, {"title": "Influence diagrams and d-separation", "author": ["Pearl Judea", "T. Verma"], "venue": "UCLA Cognitive Systems Laboratory, Technical Report 880052,", "citeRegEx": "5", "shortCiteRegEx": "5", "year": 1988}, {"title": "A semantics for possibility theory based on likelihoods", "author": ["D. Dubois", "S. Moral", "H. Prade"], "venue": "J. Math. Anal. Appl", "citeRegEx": "6", "shortCiteRegEx": "6", "year": 1997}, {"title": "Fuzzy Sets and Systems: Theory and Applications", "author": ["D. Dubois", "H. Prade"], "venue": null, "citeRegEx": "7", "shortCiteRegEx": "7", "year": 1980}, {"title": "Qualitative possibilistic graphical models from independance to propagation algorithms", "author": ["N.Ben Amor"], "venue": "The\u0300se de doctorat,", "citeRegEx": "9", "shortCiteRegEx": "9", "year": 2002}, {"title": "Probabilistic Reasoning in Intelligent Systems: Networks of Plausible Inference.Morgan", "author": ["J. Pearl"], "venue": null, "citeRegEx": "11", "shortCiteRegEx": "11", "year": 1988}, {"title": "Hybrid possibilistic networks. in proceeding of the Twentieth", "author": ["S. Benferhat", "S. Smaoui"], "venue": "National Conference on Artificial Intelligence (AAAI-05),AAAI Press. Pittsburgh,", "citeRegEx": "12", "shortCiteRegEx": "12", "year": 2005}, {"title": "On the transformation between possibilistic logic bases and possibilistic causal networks", "author": ["S. Benferhat", "D. Dubois", "L. Garcia", "H. Prade"], "venue": "International Journal of Approximate Reasoning,", "citeRegEx": "13", "shortCiteRegEx": "13", "year": 2002}, {"title": "The context model an integrating view of vagueness and uncertainty Int", "author": ["J. Gebhardt", "R. Kruse"], "venue": "Journal of Approximate Reasoning", "citeRegEx": "14", "shortCiteRegEx": "14", "year": 1993}, {"title": "Possibilistic networks with locally weighted knowledge bases", "author": ["Salem Benferhat", "Salma Smaoui"], "venue": "4th International Symposium on Imprecise Probabilities and Their Applications, Pittsburgh, Pennsylvania,", "citeRegEx": "15", "shortCiteRegEx": "15", "year": 2005}, {"title": "Fuzzy sets as a basis for a theory of possibility", "author": ["L.A. Zadeh"], "venue": "Fuzzy Sets and Systems", "citeRegEx": "16", "shortCiteRegEx": "16", "year": 1978}, {"title": "Fuzzy Sets and Systems: Theory and applications", "author": ["D. Dubois", "H. Prade"], "venue": null, "citeRegEx": "17", "shortCiteRegEx": "17", "year": 1980}, {"title": "Belief structures, possibility theory and decomposable confidence", "author": ["D. Dubois"], "venue": "measure. on finite sets. Computers and Artificial Intelligence,", "citeRegEx": "18", "shortCiteRegEx": "18", "year": 1986}, {"title": "Possibilistic logic : a retrospective and prospective view", "author": ["Dubois", "Prade"], "venue": "Fuzzy Sets and Systems", "citeRegEx": "19", "shortCiteRegEx": "19", "year": 2004}, {"title": "Constrained abductive reasoning with fuzzy parameters in Bayesian networks", "author": ["Han-Lin Li", "Han-Ying Kao"], "venue": "Computers & Operations Research", "citeRegEx": "20", "shortCiteRegEx": "20", "year": 2005}], "referenceMentions": [{"referenceID": 0, "context": "These networks are systems for uncertain knowledge representation and have a big number of applications with efficient algorithms and have strong theoretical foundations [1],[2],[3],[4],[5] and [11].", "startOffset": 170, "endOffset": 173}, {"referenceID": 1, "context": "These networks are systems for uncertain knowledge representation and have a big number of applications with efficient algorithms and have strong theoretical foundations [1],[2],[3],[4],[5] and [11].", "startOffset": 174, "endOffset": 177}, {"referenceID": 2, "context": "These networks are systems for uncertain knowledge representation and have a big number of applications with efficient algorithms and have strong theoretical foundations [1],[2],[3],[4],[5] and [11].", "startOffset": 178, "endOffset": 181}, {"referenceID": 3, "context": "These networks are systems for uncertain knowledge representation and have a big number of applications with efficient algorithms and have strong theoretical foundations [1],[2],[3],[4],[5] and [11].", "startOffset": 182, "endOffset": 185}, {"referenceID": 4, "context": "These networks are systems for uncertain knowledge representation and have a big number of applications with efficient algorithms and have strong theoretical foundations [1],[2],[3],[4],[5] and [11].", "startOffset": 186, "endOffset": 189}, {"referenceID": 8, "context": "These networks are systems for uncertain knowledge representation and have a big number of applications with efficient algorithms and have strong theoretical foundations [1],[2],[3],[4],[5] and [11].", "startOffset": 194, "endOffset": 198}, {"referenceID": 5, "context": "The goal of this paper is to develop a qualitative framework where the uncertainty is represented in possibility theory; an ordinal theory for uncertainty developed since more than ten years [6], [7], and [8].", "startOffset": 191, "endOffset": 194}, {"referenceID": 6, "context": "The goal of this paper is to develop a qualitative framework where the uncertainty is represented in possibility theory; an ordinal theory for uncertainty developed since more than ten years [6], [7], and [8].", "startOffset": 196, "endOffset": 199}, {"referenceID": 9, "context": "The language defined in [12] [13] and in [15] has been modified to enhance usability and to support a more powerful system.", "startOffset": 24, "endOffset": 28}, {"referenceID": 10, "context": "The language defined in [12] [13] and in [15] has been modified to enhance usability and to support a more powerful system.", "startOffset": 29, "endOffset": 33}, {"referenceID": 12, "context": "The language defined in [12] [13] and in [15] has been modified to enhance usability and to support a more powerful system.", "startOffset": 41, "endOffset": 45}, {"referenceID": 11, "context": "In this paper we consider a type of possibilistic network that is based on the context model interpretation of a degree of possibility and focused on imprecision [14].", "startOffset": 162, "endOffset": 166}, {"referenceID": 10, "context": "e, interpretations where p is true {\u03c9 | \u03c9 p}) [13].", "startOffset": 46, "endOffset": 50}, {"referenceID": 0, "context": "1 Possibility-necessity distributions and possibility-necessity measures The basic element of possibility theory is the possibility distribution \u220f which is a mapping from \u03a9 to the interval [0 1].", "startOffset": 189, "endOffset": 194}, {"referenceID": 10, "context": "By convention, \u03c0(\u03c9)= 0 means that the interpretation \u03c9 is impossible, and \u03c0(\u03c9) = 1 means that nothing prevents \u03c9 from being the real world [13].", "startOffset": 139, "endOffset": 143}, {"referenceID": 13, "context": "\u220f(p) = max ( \u03c0 (\u03c9) : \u03c9 \u2208 [p]) (1) Which evaluates the extent to which p is consistent with the available beliefs expressed by p [16].", "startOffset": 128, "endOffset": 132}, {"referenceID": 14, "context": "We have [17]: \u2200p, \u2200q N (p\u2227q) = max (N(p), N (q)) (4)", "startOffset": 8, "endOffset": 12}, {"referenceID": 0, "context": "2 Fuzzy knowledge base A fuzzy formula is a tripley (\u03c6, \u03b1,\u03b2) where \u03c6 is a classical first-order closed formula and (\u03b1,\u03b2 )\u2208 [0,1] are a positive numbers.", "startOffset": 123, "endOffset": 128}, {"referenceID": 15, "context": "A fuzzy knowledge base \u2211 is defined as the set of weighted formulae [18].", "startOffset": 68, "endOffset": 72}, {"referenceID": 7, "context": "where parents(Ai) is the set of parents of variable Ai, which is made as small as possible by exploiting conditional independencies of the type indicated above [9] and [10].", "startOffset": 160, "endOffset": 163}, {"referenceID": 9, "context": "We give next some definitions inspired from [12] and [13].", "startOffset": 44, "endOffset": 48}, {"referenceID": 10, "context": "We give next some definitions inspired from [12] and [13].", "startOffset": 53, "endOffset": 57}, {"referenceID": 12, "context": "To note here that in [15] the authors prove the possibility to recover conditional possibilities from \u2211A where \u2211A is a possibilistic knowledge base.", "startOffset": 21, "endOffset": 25}, {"referenceID": 12, "context": "Based o the results obtained in [15] , we can check in our case that it is possible to recover both conditional", "startOffset": 32, "endOffset": 36}, {"referenceID": 12, "context": "6 From Average valued knowledge base to average fuzzy Bayesian network In [15] the authors describe a process permitting to deduce a possibilistic network from a possibilistic knowledge base.", "startOffset": 74, "endOffset": 78}, {"referenceID": 16, "context": "7 Fuzzy Bayesian networks based on fuzzy necessity distribution Logical formulae with a weight strictly greater than a given levels (lower bounds of necessity degrees) are immune to inconsistency and can be safely used in deductive reasoning [19].", "startOffset": 242, "endOffset": 246}, {"referenceID": 17, "context": "A Bayesian network for metastatic cancer[20]", "startOffset": 40, "endOffset": 44}, {"referenceID": 0, "context": "For instance: C \u2208 [0, 1] represents the dichotomy between having a brain tumor and not having one, c denotes the assertion C = 1 or \u201cBrain tumor is present\u201d, and \u00acc is the", "startOffset": 18, "endOffset": 24}, {"referenceID": 0, "context": "\u03bc : [\u03b21, \u03b22] [0 1] (14) \u03c7 \u03bc (\u03c7)", "startOffset": 13, "endOffset": 18}], "year": 2006, "abstractText": "Within the framework proposed in this paper, we address the issue of extending the certain networks to a fuzzy certain networks in order to cope with a vagueness and limitations of existing models for decision under imprecise and uncertain knowledge. This paper proposes a framework that combines two disciplines to exploit their own advantages in uncertain and imprecise knowledge representation problems. The framework proposed is a possibilistic logic based one in which Bayesian nodes and their properties are represented by local necessity-valued knowledge base. Data in properties are interpreted as set of valuated formulas. In our contribution possibilistic Bayesian networks have a qualitative part and a quantitative part, represented by local knowledge bases. The general idea is to study how a fusion of these two formalisms would permit representing compact way to solve efficiently problems for knowledge representation. We show how to apply possibility and necessity measures to the problem of knowledge representation with large scale data. On the other hand fuzzification of crisp certainty degrees to fuzzy variables improves the quality of the network and tends to bring smoothness and robustness in the network performance. The general aim is to provide a new approach for decision under uncertainty that combines three methodologies: Bayesian networks certainty distribution and fuzzy logic . Key-Words: Possibilistic logic, Bayesian networks, Certain Bayesian networks, Local knowledge bases", "creator": "PDFCREATOR Version 0.8.0"}}}