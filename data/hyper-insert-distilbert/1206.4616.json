{"id": "1206.4616", "review": {"conference": "ICML", "VERSION": "v1", "DATE_OF_SUBMISSION": "18-Jun-2012", "title": "A Hierarchical Dirichlet Process Model with Multiple Levels of Clustering for Human EEG Seizure Modeling", "abstract": "driven backwards by assessing the multi - terminal level structure function of human infant intracranial electroencephalogram ( ieeg ) recordings of epileptic seizures, later we could introduce a new variant of a hierarchical narrative dirichlet process - - - repeating the multi - processing level clustering hierarchical dirichlet process ( coordinated mlc - phase hdp ) - - - type that simultaneously includes clusters datasets depending on performing multiple levels. essentially our data seizure dataset contains verbal brain activity recorded in typically more than a medium hundred individual speech channels for each seizure model of each associated patient. executing the complex mlc - paced hdp model fits clusters over twelve channels - types, and seizure - types, and patient - acquired types simultaneously. we directly describe repeating this one model substantially and study its implementation in historical detail. we also see present again the good results of documenting a seizures simulation study comparing the spatial mlc - led hdp to a similar model, confirming the simple nested dirichlet process and finally demonstrate illustrating the aforementioned mlc - hdp's unique use criterion in modeling seizures across comparing multiple patients. we can find the clustered mlc - hdp's clustering to be comparable remarkably to some independent human physician clusterings. testify to our comprehensive knowledge, the inverted mlc - focused hdp model is thereby the decisive first element in building the epilepsy literature that capable especially of clustering total seizures seen within genes and relationships between patients.", "histories": [["v1", "Mon, 18 Jun 2012 15:02:12 GMT  (510kb)", "http://arxiv.org/abs/1206.4616v1", "ICML2012"]], "COMMENTS": "ICML2012", "reviews": [], "SUBJECTS": "stat.AP cs.LG stat.ML", "authors": ["drausin wulsin", "shane jensen", "brian litt"], "accepted": true, "id": "1206.4616"}, "pdf": {"name": "1206.4616.pdf", "metadata": {"source": "META", "title": "A Hierarchical Dirichlet Process Model with Multiple Levels of Clustering for Human EEG Seizure Modeling", "authors": ["Drausin Wulsin", "Shane Jensen", "Brian Litt"], "emails": ["wulsin@seas.upenn.edu", "stjensen@wharton.upenn.edu", "littb@mail.med.upenn.edu"], "sections": [{"heading": "1. Introduction", "text": "Our work is motivated by the structure of clinical intracranial electroencephalogram (iEEG) in the context of evaluating epilepsy patients for resective brain\nAppearing in Proceedings of the 29 th International Conference on Machine Learning, Edinburgh, Scotland, UK, 2012. Copyright 2012 by the author(s)/owner(s).\nsurgery. Consider a set of patients, each of whom has a number of seizures while being recorded in a hospital\u2019s epilepsy monitoring unit. The number of recorded seizures can range widely from only one to over fifty for a given patient, and the iEEG of each is defined by the activity of each recorded electrode channel. The number of channels and their placement can range widely from patient to patient, often with 100-200 individual channels per patient.\nCurrent clinical practice involves clinicians examining the dynamics of seizures to ascertain important clinical factors like how similar (or dissimilar) an individual patient\u2019s seizures are to each other. Such information helps the physicians identify which areas of the brain to remove. Almost all steps of this decision process are currently manual, performed by neurophysiology physicians, whose training and decision processes can vary greatly. One might say that this work up to epilepsy surgery is still quite \u201cmessy,\u201d which may help explain the mediocre outcomes of this surgery for extra-temporal lobe surgeries (de Tisi 2011).\nStatistical models can offer decision support for clinical questions like \u201cwhat are the types of seizures that a patient has\u201d and \u201cwhich other patients is this patient similar to.\u201d A challenge of the data is that every seizure of every patient is unique, though there are similarities between seizures and patients. Currently, most approaches create models in space or time of a single seizure.\nThis approach is not at all similar to a physician\u2019s when analyzing a seizure. A physician appreciates that the dynamics of each seizure are unique but does not forget about the other seizures of that patient or even the other seizures of other patients. The other seizures inform the physician\u2019s understanding of the\ncurrent seizure in some way or another. We believe that hierarchical Bayesian models are a good class of models for this problem since they allow for individual models over local data while still allowing global data to have some influence in the model. \u201cNonparametric\u201d Bayesian approaches are also attractive because they reduce the amount of necessary model selection.\nComparing seizures between patients is challenging because the number and placement of the iEEG channels is unique for every patient1. One approach to this problem is to use features of the data that generalize across an arbitrary number of channels. For example, (Schiff et al. 2005) present six intuitive features that seem to capture global properties of a seizure. While this approach is attractive because it is so straightforward, we believe that it is likely to miss the important dynamics that can occur in just a few channels out of a hundred. In many cases, it is just a few channels that are of most clinical interest to physicians.\nAn alternative approach to this problem is to treat each channel as an i.i.d. sample from an underlying distribution over the space of channel dynamics. In this setting, the number of channels actually present becomes less important, as they can just be thought of as observations from a channel distribution. Due to the complexity of neurophysiologic activity during a seizures, the distribution of channel behaviors will almost certainly be multi-modal. Mixture models are a straightforward approach to such density estimation, and in the case where our channel-features are continuous, we may use the familiar Gaussian Mixture Model (GMM).\nWe thus are interested in using a nonparametric hi-\n1The number of \u201cactive\u201d channels can even vary between seizures of the same patient because some channels drop in and out over time.\nerarchical Bayesian model that can incorporate something like a GMM at the base level. One such model is the Hierarchical Dirichlet Process (HDP) of (Teh et al. 2006), where the hierarchy affects the weights over a collection of base models (e.g., Gaussians). Yet inference in this model only yields clustering at the base level, i.e., the channels. While such channel clustering is potentially helpful for clinicians, seizure and patient level clustering is more in line with the most important clinical questions. Ideally, we would use a model that can cluster on all three levels at the same time. Figure 1 depicts such a scenario for 3 toy patients. Another model, the Nested Dirichlet Process (NDP) of (Rodr\u0301\u0131guez et al. 2008), is similar to the HDP but involves multiple levels of clustering. The nesting structure of the NDP means that higher-level atoms do not share the same lower-level atoms. In our seizure data application, that would mean that seizures of a different type would share no channel information, a trait that is unrealistic for multiple seizures, which may globally be \u201cdifferent\u201d but have subsets of channels that behave very similarly.\nWe thus present a new model that in a sense blends the desirable aspects of both the HDP and NDP models. We call this model the multi-level clustering hierarchical Dirichlet Process (MLC-HDP) because it simultaneously clusters on multiple levels of a dataset and also retains a hierarchical structure. The novel contributions of this work are:\n\u2022 a model capable of clustering on multiple levels that shares lower-level atoms among higher-level atoms,\n\u2022 demonstrations of how the MLC-HDP model surpasses state of the art NDP and DP models on tasks in simulated and human seizure datasets,\n\u2022 the ability of the MLC-HDP model to answer previously unattempted questions in the field of quantitative epilepsy research."}, {"heading": "2. Model description", "text": "Consider again the structure of our epilepsy data2, given in the schematic in Figure 1. This data has multiple levels on which we assume clustering occurs. Each level\u2019s clustering can be thought of as a finite collection of atoms, which are multinomial at\n2Of course, while this model is motivated by our seizure iEEG data, it generalizes to any data where multiple levels of clustering is reasonable. Furthermore, while our model contains three levels, extending it to more or reducing it to fewer levels is straightforward.\nthe higher levels and any arbitrary distribution at the base level. The seizure and patient levels\u2014levels 2 and 1, respectively\u2014are made up of multinomial atoms that represent priors over the atoms in the level below, so level-2 seizure atoms denote different seizure types, each of which is a prior over the base-atom channeltypes. Level-1 patient atoms denote different patient types, each of which is a prior over the level-2 seizuretypes.\nConsider a dataset with T patients, each t of which has Jt seizures, each j of which has Ntj channel observations, which we call xtji \u2208 Rd, where d is the feature-space dimension3. We model the observations {{{xtji}Ntji=1}Jtj=1}Tt=1 of all the seizures using a set of unique base-distribution atoms with prior measure H (and parameters \u03bb) for an arbitrary distribution F ,\nxtji \u223c F (\u03b8tji) (1) where \u03b8tji are the parameters of the model, which are equal to those of a unique base-level atom \u03c6k. In the rest of this paper, F is a multivariate Normal with diagonal covariance, F (\u03b8) = N (\u00b5,\u03c32) for \u00b5 \u2208 Rd,\u03c32 \u2208 Rd+. In this paper, we will assume all priors are conjugate and so for our two-parameter Normal base model will use a Normal scaled inverse-\u03c72 (N -Inv-\u03c72) joint prior on \u00b5 and \u03c32 forH. See the Supplementary Materials for more details on the resulting posterior distribution and its sufficient statistics.\nFor convenience, we use an indicator variable z (3) tji = k to describe which base-level atom models channel i\u2019s activity in seizure j of patient t. Superscripts in variables denote the data-level with which they are associated.\nThe set of base-atoms {\u03c6k}\u221ek=1 have a corresponding set of stick-breaking priors (which we shall often call weights). In a 2-level HDP model of a single patient\u2019s seizures, the parent/root DP G0 has its weights \u03b2, and each seizure DP Gj has its own set of weights \u03c0j \u223c DP(\u03b1,\u03b2), whose posterior is a balance between the parent DP\u2019s \u03b2 and the frequency with which the observations of seizure j occur in the various baselevel atoms. In our MLC-HDP version of the model, we have a set of multinomial weights atoms, {\u03c0(3)` }\u221e`=1, one of which we select to use for the base-level atom weights for seizure j.\nEach seizure-type atom, a prior over the base atoms, is a sample from a DP,\n\u03c0 (3) ` \u223c DP(\u03b1(3),\u03b2(3)) \u03b2(3) \u223c GEM(\u03b3(3)) (2)\n3In our simulation study d = 1, and in our epilepsy dataset d = 5.\nwhere \u03b2(3) is a distribution over the positive integers4. We let the indicator variable z (2) tj = ` denote which seizure-type patient t\u2019s seizure j belongs to. The patient-type atoms \u03c0 (2) l have a similar construction as do the weights \u03c0(1) of the patient population over the various patient types. The indicator variable z (1) t = l denotes which patient-type patient t belongs to.\nPutting it all together, we have\n\u03b2(1) \u223c GEM(\u03b3(1)) \u03c0(1) \u223c DP(\u03b1(1),\u03b2(1)) z (1) t \u223c \u03c0(1) \u03b2(2) \u223c GEM(\u03b3(2)) \u03c0\n(2) l \u223c DP(\u03b1(2),\u03b2(2)) z (2) tj \u223c \u03c0 (2)\nl=z (1) t\n\u03b2(3) \u223c GEM(\u03b3(3)) \u03c0\n(3) ` \u223c DP(\u03b1(3),\u03b2(3)) z (3) tji \u223c \u03c0 (3)\n`=z (2) tj\n\u03c6k \u223c H(\u03bb) xtji \u223c F (\u03c6k=z(3)tji )\n(3)\nwhere for us H(\u03bb) = N -Inv-\u03c72(n0,\u00b50,\u03bd0,\u03c320) and F (\u03c6k) = N (\u00b5k,\u03c32k). Note that the highest level of this model is equivalent to a standard DP. We depict this model schematically by the directed graphical model in Figure 2.\n4GEM stands for Griffiths, Engen, and McCloskey (Pitman 2006). We say \u03b2 \u223c GEM(\u03b3) if for \u03b2\u2032k \u223c Beta(1, \u03b3), we have \u03b2k = \u03b2 \u2032 k \u220fk\u22121 \u03ba=1(1\u2212 \u03b2 \u2032 \u03ba) for k = 1, . . . ,\u221e."}, {"heading": "3. Model implementation", "text": ""}, {"heading": "3.1. Notation", "text": "Our implementation is very similar to the collapsed Gibbs sampler used by (Teh et al. 2006) for the HDP5. For convenience, we introduce a counts variable n and a sampled variable6 m at each level of the model: n (3) `k denotes the number of observations in base-atom k (channel-type) across the seizures in level-2 atom `, with similar meanings for n (2) l` and n (1) l for levels 2 (seizure types) and 1 (patient types), respectively; m (3) `k denotes a sampled weight parameter on base-atom k for the level-2 atom `; m (2) l` and m (1) l are similar. A dot (\u00b7) in place of a subscript indicates a marginal count.\nWhile in theory the number of atoms at each level is infinite, the number that exist at any given point is finite because the number of data points in the model is finite. We thus use K to denote the current number of non-empty base-level atoms, and L(2) and L(1) to denote the current number of level-2 and level-1 atoms. For algorithmic elegance, we sometimes use L(3) in place of K. We also keep an extra, empty atom at each level to represent selecting a new atom, in which case another extra atom is appended to the list.\nWe explicitly sample the parameters \u03c6k = (\u00b5k,\u03c3 2 k) for our K base atoms, where \u03a6k describes the sufficient statistics for each base atom k \u2208 {1, . . . ,K} and let \u03a6K+1 describe those for new (empty) atom. The likelihood of x under atom k \u2208 {1, . . . ,K + 1} is given as fk(x) = N (x |\u00b5k,\u03c32k). For convenience, we denote the collection of channelactivities in a given seizure j of patient t as stj = {xtji}Ntji=1, whose joint likelihood is simply the product of the likelihoods of the individual channelobservations."}, {"heading": "3.2. Markov Chain Monte Carlo Sampling", "text": "One can see from Figure 2 that there are a number of parameters of the MLC-HDP that need to be sampled. We break these variables into three main groups: the atom indicators, z; the level parameters, \u03b2 and \u03c0; and the base parameters, \u03c6k. An optional fourth step is to place priors on the hyperparameters \u03b3 and \u03b1 and sample values for them as well. Of these steps, the first is usually the most computationally intensive. Below,\n5Specifically, see Section 5.3 6Our variables n and m are equivalent to the number of diners eating and the number of tables serving dish k in the Chinese Restaurant Process metaphor.\nwe briefly summarize each of these four steps.\nSampling atom indicators We sample atom indicators on each of the three levels using roughly the same technique: (a) calculate the prior weights over the atoms, (b) calculate the likelihood of each data point under each of the atoms7, (c) sample each data point\u2019s atom indicator from the posterior multinomial distribution, and (d) update the atom counts and sufficient statistics for the relevant base atoms if the atom indicator has changed. At the base level, each data point is an individual channel observation, whereas a seizurelevel \u201cdata point\u201d comprised of all the channel observations in that seizure. A patient \u201cdata point\u201d is similarly comprised of all the seizure data points for that patient.\nSampling level parameters As previously described, each level can be thought of as containing a set of multinomial atoms over a set of lower-level atoms (which we call \u201csub-atoms\u201d), so the seizure level contains seizure-type atoms, each of which is a particular distribution over the channel base-atoms. The patient level contains patient-type atoms, each of which is a particular distribution over the seizure-type atoms. Finally, we have a single \u201cpopulation\u201d distribution over the different patient-type atoms.\nFor each level, we first sample the m variables for each combination of sub-atom and level-atom and then use them in sampling the parent sub-atom weights, \u03b2. We could also sample the sub-atom weights, \u03c0, but again in practice use the RaoBlackwellized approach that integrates out \u03c0.\nSampling base parameters Sampling the base parameters \u03c6k for each base atom k will depend on the particular base distribution F used. The Supplementary Materials give these details for our choice of a multivariate Normal with diagonal covariance. We check if any observations have been assigned to the last base atom, and if they have, we add another (empty) base atom. With no data, the last empty atom\u2019s posterior is simply the base\n7In practice, we have found that following the method of (Teh et al. 2006) and when possible using a RaoBlackwellized Gibbs sampler (Casella & Robert 1996; Sudderth 2006) usually leads to lower autocorrelation and slightly improved model performance. We thus generally use this method as an alternative to the likelihood under each base atom\u2019s sampled parameters. The RaoBlackwellized sampler uses the posterior predictive likelihood instead.\nprior, so the parameters \u03c6k are sampled from the prior H(\u03bb).\nSampling level hyperparameters We sample each level\u2019s hyperparameters \u03b1 and \u03b3, which can have Gamma(a, b) priors. This step is performed after sampling the other level parameters.\nA single sampling iteration for the full MLC-HDP proceeds through sampling the atom indicators, the level parameters (and, optionally, also the hyperparameters), and the base parameters. Finally, any nonlast empty base- and level-atoms are removed (and the appropriate indicator variables decremented accordingly). The Supplementary Materials give explicit algorithms corresponding to these steps8."}, {"heading": "4. Experiments", "text": ""}, {"heading": "4.1. Simulated data", "text": "To explore some of the properties of the MLC-HDP in a controlled setting and to compare it with a similar model, we ran a 2-level version of it on the same simulated data presented in (Rodr\u0301\u0131guez et al. 2008) and implemented the Nested Dirichlet Process model described in their paper. Briefly, samples were generated from one of four distributions (T1-T4), each of which is a mixture of two to four Gaussians. The parameters of the Gaussians are given in Table 1.\nWe used a dataset with 5 samples from each of the four distributions, for 20 samples total. Each sample contained 100 observations from the particular distribution. We used the same hyperparameters described in (Rodr\u0301\u0131guez et al. 2008). Posterior inference for each model was run over 25 chains, each with a 5000 sample burn in and 10 sample thinning, gathering 400 samples for each chain or 10,000 samples total.\nWe found that the MLC-HDP gives better estimates of the four true GMM distributions than the NDP, as\n8See http://www.seas.upenn.edu/~wulsin for supplementary materials, code, and a link to the EEG dataset used.\nshown graphically on the left of Figure 3. The MLCHDP usually found three top-level atoms, whereas the NDP balanced roughly equally between two and three (supporting the result (Rodr\u0301\u0131guez et al. 2008) give in their Figure 3 for J = 20 and n = 100). The density function estimates of both methods for T3 and T4 are thus the same, since those two true distributions are the same except for a small additional mode at x = 10 in the fourth distribution. The Kullback-Liebler divergence9 of the true density function to the estimated density function for each method, shown on the right of Figure 3, also illustrates how the MLC-HDP estimates are closer to the true distributions. The major difference between the MLC-HDP and NDP models is the fact that higher-level atoms in the NDP have their own sets of base atoms, whereas higher-level atoms in the MLC-HDP share base atoms. In datasets where different group types may have observations from the same or similar base distributions (e.g., T1 and T2), the NDP must estimate those base distributions independently for each group-level atom whereas the MLCHDP estimates benefit from data across all groups.\nAnother difficulty of having separate sub-atoms for each higher-level atom is that the total number of base atoms can quickly become computationally infeasible as the model is extended from two to three or more levels. For example, a modest-sized model of K = 55, L(2) = 35, and L(1) = 35 (in the NDP truncated setting) would have roughly 67,000 base atoms to sample and calculate likelihoods under, a number we have anecdotally found to be far too large for practical use."}, {"heading": "4.2. Human seizures on intracranial EEG", "text": "We compiled a dataset of 193 intracranial EEG seizure records across 10 randomly-selected patients from the Children\u2019s Hospital of Philadelphia. These patients display attributes common in epilepsy datasets intracranial EEG: unique electrode placement, large discrepancies in the number of seizures per patient, and differences in the number of useable channels within\n9We used DKL(true || estimated).\nthe seizures of a patient. Table 2 describes the number of seizures per patient as well as whether a patient\u2019s seizures contain the same number of active electrodes.\nWe extracted all the channel activities10 from -30 to +90 seconds around the clinically-marked start of each seizure. We calculated a set of simple and intuitive features for each channel: the log10 power in four clinically relevant frequency bands (4-8, 8-13, 13-30, 30- 100 Hz) for each channel over the 120 seconds, using a sliding window of 500 ms with 50% overlap. These features were chosen because they closely resemble what we believe actual epileptologists look at when reading EEG. We concatenated the four features at each of the 479 time points to get a 1916-dimensional feature vector for each channel and subsequently reduced it to 5 dimensions using PCA over all seizures of all patients11.\n10In EEG, channel activities are referential voltages, usually on the scale of mV for intracranial recordings.\n11This reduction retained 67.7% of the original variance. Clearly, a lot of redundancy exists in the 1916-dimensional feature space for each channel.\nThe advantages of a hierarchical model In our first iEEG experiment, we examined how well the MLC-HDP model generalizes to held-out data compared with two standard Dirichlet Process (DP) models12. For a given patient t, the models were evaluated after each seizure j, where the seizures j+1, . . . , Jt after j were used as the held out testing set. The three models and their training data are described below\nM1 The channel-observations from seizures 1, . . . , j of patient t are used to train a standard DP mixture model.\nM2 The channel-observations from seizures 1, . . . , j of patient t and all the seizures j\u2032 \u2208 {1, . . . , Jt\u2032} of all the other patients t\u2032 6= t are used to train a standard DP mixture model.\nM3 The same data as M2 is used but organized in the full patient-seizure-channel hierarchy available in the MLC-HDP model.\nThe models were evaluated using the using the conditional perplexity (PP ) (Teh et al. 2006) of the future seizures j+1, . . . , Jt given the assigned base atoms for each channel,\nPP (sj+1, . . . , sJt | \u00b7 \u00b7 \u00b7 ) = exp ( \u2212 1Jt\u2212j \u2211Jt j\u2032=j+1 log p ( sj\u2032 | z(3)tj\u20321, . . . , z (3) tj\u2032Ntj\u2032 )) (4)\nwith\np ( sj\u2032 | z(3)tj\u20321, . . . , z (3) tj\u2032Ntj\u2032 ) = Ntj\u2032\u220f i=1 f (k=z (3) tj\u2032i) (xtj\u2032i) (5)\nLower perplexity values indicate better models. We ran 25 chains each of the three models at each time\n12This experiment is similar to one in (Teh et al. 2006).\npoint j = 1, . . . , Jt \u2212 1. We used used 500 samples for burn in and 20 sample spacing to get 200 samples per chain per time point in each model, or 5000 total samples per time point.\nThe results of these experiments for patient B are shown on the left side of Figure 4. Other patients had similar plots. In the DP model with only patient B\u2019s seizures (M1), the perplexity of the first two time points is quite high since the model has only the first few seizures as training data, and the subsequent seizures are somewhat to quite different from these. The DP model (M2) with all of the other seizures as training data in addition to those of M1 performs much better in the first few time points, but as M1 has more and more training seizures, its patient-specific model becomes better than the non-specific one (M2). Though it has the exact same training and testing data as the M2 model, the MLC-HDP (M3) model consistently performs better than both M1 and M2. We believe these results show the value of employing a hierarchical model organization when it is possible and appropriate. Such an organization allows a local model (such as one for a particular patient) to get information from other, related models (such as those for other patients) without being unduly influenced by them. Characteristics of epilepsy datasets like ours, where the number of seizures can vary widely between patients, make hierarchical models like this particularly appropriate. To our knowledge, this works describes the first ever use in the epilepsy community of hierarchical models to integrate information across multiple events and subjects. This experiment shows the improvements such models can have.\nSeizure clustering performance In our second iEEG experiment, we compared the MLC-HDP\u2019s seizure clustering (stored in the z (2) tj indicators variables) to those of a board-certified epileptologist and those of a standard DP mixture. Comparing seizures between patients is not exactly straightforward because their channels are located on the brain in completely different configurations. Even seizures of the same patient may have different numbers of active channels from seizure to seizure as some drop in and out (see Table 2). The MLC-HDP solves this problem by defining seizure types as distributions over channel types, so different numbers of channels are accommodated simply as a different number of observations from a complex, multi-modal density (which for us is a mixture of Gaussians). For models like the DP (which is currently the only alternative for nonparametric clustering of seizures), we need features of a seizure that to not depend on the number of chan-\nnels present. While various metrics have been proposed and used in the epilepsy literature, we believe the six features of (Schiff et al. 2005) capture most of the important dynamics of a seizure, namely, the synchronization of different areas of the brain and their frequency characteristics during a seizure. These features were calculated using the same 500 ms time window with 50% overlap. As with the channel features, we concatenated the six seizure features for each time point into a large vector (2874 dimensions) and then reduced them to 20 dimensions, retaining 72.3% of the variance.\nClustering seizures, even for board-certified epileptologists practicing in the same hospital, is an inherently subjective and uncertain task. We thus had two physicians cluster the same 193 seizures in our dataset (independantly from and blind to the MLC-HDP\u2019s clusterings) to get an idea of the potential variability from one human professional to another. For the sake of our subsequent analysis, we arbitrarily chose one to be the \u201cgold standard\u201d (though of course there is no such thing). The results we report do not substantially change when the other physician\u2019s markings were used as the standard instead. To assess the similarity between two clusterings, we used Rand\u2019s C-statistic (Rand 1971), which can accommodate different numbers and labels of clusters between two assignments of the same N points.\nThe average similarities of the DP, MLC-HDP, and human physician seizure clusters to those of the \u201cgold standard\u201d clusterings are shown on the right side of Figure 4. We notice first that the two physicians usually agree most closely with each other, as expected. Second, the MLC-HDP is almost always better than the DP and in some patients is very close to the other physician. In the one patient (patient H) where the MLC-HDP performs worse than the DP, the other doctor is even farther from the \u201cgold standard\u201d clustering. This difference results from the methods differing in how much they split the very similar-looking seizures of patient H. The \u201cgold standard\u201d doctor and DP split them less, whereas the MLC-HDP and other doctor split them more.\nWe attribute the performance difference between the two models mostly to the fact that the DP simply has a less descriptive form of the data\u2014one that ignores the behavior of individual channels in favor of that of the population\u2014than the humans and MLC-HDP. Anecdotally, the physicians both remarked that they sorted the seizures by often looking at the activity of just a handful of prominent channels. This fact, along with the superior clustering results shown in Figure\n4, leads us to believe that any approach to modeling seizures must begin by modeling channels and build up from there, as our MLC-HDP does. We believe that the absence of such methods until now explains the non-existence of seizure clustering in the epilepsy literature."}, {"heading": "5. Conclusion", "text": "We describe a new hierarchical Dirichlet Process variant, the multi-level clustering hierarchical Dirichlet Process (MLC-HDP), that simultaneously clusters on multiple levels of a dataset. In a simulation study we illustrate some advantages of this model over a similar model, the Nested Dirichlet Process. Finally, we demonstrate how the MLC-HDP allows us to build models of seizures that account for the importance of individual channels while also integrating information from many seizures within and between patients. Such a model allows us answer important clinical questions like \u201chow many seizure types does this patient have?\u201d and \u201cwhat seizures of other patients is this seizure similar to?,\u201d questions that to the best of our knowledge have hitherto been unanswerable in the field of quantitative epilepsy analysis."}, {"heading": "Acknowledgements", "text": "We thank Eric Marsh and Brenda Porter, of the Children\u2019s Hospital of Philadelphia, for the contin-\nuous iEEG records, manual seizure clustering, and helpful discussion as well as Emily Fox for her helpful ideas and discussion. This work was supported by NIH grants RO1-NS041811, RO1-NS48598, and 5U24NS063930-03, the Julies Hope Award from the Citizens United for Research in Epilepsy, and the Mirowski Discovery Fund for Epilepsy Research."}], "references": [{"title": "The long-term outcome of adult epilepsy surgery, patterns of seizure remission, and relapse: a cohort", "author": ["de Tisi"], "venue": "study. Lancet,", "citeRegEx": "Tisi,? \\Q2011\\E", "shortCiteRegEx": "Tisi", "year": 2011}, {"title": "Combinatorial Stochastic Processes", "author": ["Pitman", "Jim"], "venue": null, "citeRegEx": "Pitman and Jim.,? \\Q2006\\E", "shortCiteRegEx": "Pitman and Jim.", "year": 2006}, {"title": "The Nested Dirichlet Process", "author": ["Rod\u0155\u0131guez", "Abel", "Dunson", "David B", "Gelfand", "Alan E"], "venue": "Journal of the American Statistical Association,", "citeRegEx": "Rod\u0155\u0131guez et al\\.,? \\Q2008\\E", "shortCiteRegEx": "Rod\u0155\u0131guez et al\\.", "year": 2008}, {"title": "Neuronal spatiotemporal pattern discrimination: the dynamical evolution of seizures", "author": ["Schiff", "Steven J", "Sauer", "Tim", "Kumar", "Rohit", "Weinstein", "Steven L"], "venue": null, "citeRegEx": "Schiff et al\\.,? \\Q2005\\E", "shortCiteRegEx": "Schiff et al\\.", "year": 2005}, {"title": "Graphical models for visual object recognition and tracking", "author": ["E.B. Sudderth"], "venue": "PhD thesis,", "citeRegEx": "Sudderth,? \\Q2006\\E", "shortCiteRegEx": "Sudderth", "year": 2006}, {"title": "Hierarchical dirichlet processes", "author": ["Teh", "Yee Whye", "Jordan", "Michael I", "Beal", "Matthew J", "Blei", "David M"], "venue": "Journal of the American Statistical Association,", "citeRegEx": "Teh et al\\.,? \\Q2006\\E", "shortCiteRegEx": "Teh et al\\.", "year": 2006}], "referenceMentions": [{"referenceID": 3, "context": "For example, (Schiff et al. 2005) present six intuitive features that seem to capture global properties of a seizure.", "startOffset": 13, "endOffset": 33}, {"referenceID": 5, "context": "One such model is the Hierarchical Dirichlet Process (HDP) of (Teh et al. 2006), where the hierarchy affects the weights over a collection of base models (e.", "startOffset": 62, "endOffset": 79}, {"referenceID": 2, "context": "Another model, the Nested Dirichlet Process (NDP) of (Rod\u0155\u0131guez et al. 2008), is similar to the HDP but involves multiple levels of clustering.", "startOffset": 53, "endOffset": 76}, {"referenceID": 5, "context": "Our implementation is very similar to the collapsed Gibbs sampler used by (Teh et al. 2006) for the HDP.", "startOffset": 74, "endOffset": 91}, {"referenceID": 5, "context": "In practice, we have found that following the method of (Teh et al. 2006) and when possible using a RaoBlackwellized Gibbs sampler (Casella & Robert 1996; Sudderth 2006) usually leads to lower autocorrelation and slightly improved model performance.", "startOffset": 56, "endOffset": 73}, {"referenceID": 4, "context": "2006) and when possible using a RaoBlackwellized Gibbs sampler (Casella & Robert 1996; Sudderth 2006) usually leads to lower autocorrelation and slightly improved model performance.", "startOffset": 63, "endOffset": 101}, {"referenceID": 2, "context": "To explore some of the properties of the MLC-HDP in a controlled setting and to compare it with a similar model, we ran a 2-level version of it on the same simulated data presented in (Rod\u0155\u0131guez et al. 2008) and implemented the Nested Dirichlet Process model described in their paper.", "startOffset": 184, "endOffset": 207}, {"referenceID": 2, "context": "We used the same hyperparameters described in (Rod\u0155\u0131guez et al. 2008).", "startOffset": 46, "endOffset": 69}, {"referenceID": 2, "context": "The MLCHDP usually found three top-level atoms, whereas the NDP balanced roughly equally between two and three (supporting the result (Rod\u0155\u0131guez et al. 2008) give in their Figure 3 for J = 20 and n = 100).", "startOffset": 134, "endOffset": 157}, {"referenceID": 5, "context": "The models were evaluated using the using the conditional perplexity (PP ) (Teh et al. 2006) of the future seizures j+1, .", "startOffset": 75, "endOffset": 92}, {"referenceID": 5, "context": "This experiment is similar to one in (Teh et al. 2006).", "startOffset": 37, "endOffset": 54}, {"referenceID": 3, "context": "While various metrics have been proposed and used in the epilepsy literature, we believe the six features of (Schiff et al. 2005) capture most of the important dynamics of a seizure, namely, the synchronization of different areas of the brain and their frequency characteristics during a seizure.", "startOffset": 109, "endOffset": 129}], "year": 2012, "abstractText": "Driven by the multi-level structure of human intracranial electroencephalogram (iEEG) recordings of epileptic seizures, we introduce a new variant of a hierarchical Dirichlet Process\u2014the multi-level clustering hierarchical Dirichlet Process (MLC-HDP)\u2014that simultaneously clusters datasets on multiple levels. Our seizure dataset contains brain activity recorded in typically more than a hundred individual channels for each seizure of each patient. The MLC-HDP model clusters over channels-types, seizure-types, and patient-types simultaneously. We describe this model and its implementation in detail. We also present the results of a simulation study comparing the MLC-HDP to a similar model, the Nested Dirichlet Process and finally demonstrate the MLC-HDP\u2019s use in modeling seizures across multiple patients. We find the MLC-HDP\u2019s clustering to be comparable to independent human physician clusterings. To our knowledge, the MLCHDP model is the first in the epilepsy literature capable of clustering seizures within and between patients.", "creator": "LaTeX with hyperref package"}}}