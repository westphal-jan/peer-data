{"id": "1206.5260", "review": {"conference": "arxiv", "VERSION": "v1", "DATE_OF_SUBMISSION": "20-Jun-2012", "title": "Reasoning at the Right Time Granularity", "abstract": "for most functional real - world dynamic computing systems are basically composed basically of different components atoms that often continuously evolve seemingly at very comparatively different rates. similar in traditional temporal graphical models, such as classical dynamic bayesian networks, time is modeled at a fixed observed granularity, generally selected instead based strongly on the rate compared at optimal which moment the fastest component evolves. sequential inference pathways must then be continuously performed at providing this fastest granularity, far potentially possibly at significant computational information cost. continuous time bayesian networks ( ctbns ) avoid time - slicing holes in the representation by modeling the resultant system as evolving continuously over time. essentially the expectation - propagation ( ep ) inference algorithm of marc nodelman martin et... al. ( 2005 ) who can then positively vary the inference using granularity calculations over time, but also the same granularity adjustment is uniform across theoretically all parts completely of the system, and must be selected in software advance. early in passing this conceptual paper, we provide a potentially new robust ep adaptation algorithm that typically utilizes together a proprietary general elastic cluster graph architecture where clusters contain distributions that can overlap in somewhat both vector space ( given set of linear variables ) and some time. simply this architecture still allows many different parts of dividing the new system to be modeled efficiently at very different time granularities, according to their current mean rate phase of evolution. we also provide an adaptive information - theoretic criterion constructed for parameters dynamically re - partitioning the clusters during inference algorithms to tune the level estimation of approximation data to the default current rate indicator of its evolution. luckily this avoids providing the need to hand - select onto the appropriate granularity, normally and only allows adjusting the granularity to adapt as user information is frequently transmitted appropriately across the network. later we now present experiments results demonstrating that this optimization approach can result entirely in significant optimal computational savings.", "histories": [["v1", "Wed, 20 Jun 2012 15:00:31 GMT  (270kb)", "http://arxiv.org/abs/1206.5260v1", "Appears in Proceedings of the Twenty-Third Conference on Uncertainty in Artificial Intelligence (UAI2007)"]], "COMMENTS": "Appears in Proceedings of the Twenty-Third Conference on Uncertainty in Artificial Intelligence (UAI2007)", "reviews": [], "SUBJECTS": "cs.AI", "authors": ["suchi saria", "uri nodelman", "daphne koller"], "accepted": false, "id": "1206.5260"}, "pdf": {"name": "1206.5260.pdf", "metadata": {"source": "CRF", "title": "Reasoning at the Right Time Granularity", "authors": ["Suchi Saria", "Uri Nodelman", "Daphne Koller"], "emails": ["ssaria@cs.stanford.edu", "nodelman@cs.stanford.edu", "koller@cs.stanford.edu"], "sections": null, "references": [{"title": "A model for reasoning about persistence and causation", "author": ["T. Dean", "K. Kanazawa"], "venue": "Computational Intelligence,", "citeRegEx": "Dean and Kanazawa,? \\Q1989\\E", "shortCiteRegEx": "Dean and Kanazawa", "year": 1989}, {"title": "Nested junction trees", "author": ["U. Kjaerulff"], "venue": "UAI.", "citeRegEx": "Kjaerulff,? 1997", "shortCiteRegEx": "Kjaerulff", "year": 1997}, {"title": "Graphical models", "author": ["S. Lauritzen"], "venue": "Clarendon Press.", "citeRegEx": "Lauritzen,? 1996", "shortCiteRegEx": "Lauritzen", "year": 1996}, {"title": "Expectation propagation for approximate bayesian inference", "author": ["T. Minka"], "venue": "UAI (pp. 362\u2013369).", "citeRegEx": "Minka,? 2001", "shortCiteRegEx": "Minka", "year": 2001}, {"title": "Expectation propagation for continuous time Bayesian networks. UAI", "author": ["U. Nodelman", "D. Koller", "C. Shelton"], "venue": null, "citeRegEx": "Nodelman et al\\.,? \\Q2005\\E", "shortCiteRegEx": "Nodelman et al\\.", "year": 2005}, {"title": "Continuous time Bayesian networks", "author": ["U. Nodelman", "C. Shelton", "D. Koller"], "venue": "UAI (pp. 378\u2013387)", "citeRegEx": "Nodelman et al\\.,? \\Q2002\\E", "shortCiteRegEx": "Nodelman et al\\.", "year": 2002}, {"title": "Markov chains", "author": ["J. Norris"], "venue": "Cambridge Univ. Press.", "citeRegEx": "Norris,? 1997", "shortCiteRegEx": "Norris", "year": 1997}, {"title": "An introduction to hidden Markov models", "author": ["L.R. Rabiner", "B.H. Juang"], "venue": "IEEE ASSP Magazine,", "citeRegEx": "Rabiner and Juang,? \\Q1986\\E", "shortCiteRegEx": "Rabiner and Juang", "year": 1986}, {"title": "Nonparametric belief propagation", "author": ["E. Sudderth", "A. Ihler", "W. Freeman", "A. Willsky"], "venue": null, "citeRegEx": "Sudderth et al\\.,? \\Q2003\\E", "shortCiteRegEx": "Sudderth et al\\.", "year": 2003}], "referenceMentions": [{"referenceID": 4, "context": "The expectation-propagation (EP) inference algorithm of Nodelman et al. (2005) can then vary the inference granularity over time, but the granularity is uniform across all parts of the system, and must be selected in advance.", "startOffset": 56, "endOffset": 79}, {"referenceID": 5, "context": "The framework of continuous time Bayesian networks (CTBNs) (Nodelman et al., 2002) provides a representation for structured dynamic systems that avoids the use of a fixed time granularity.", "startOffset": 59, "endOffset": 82}, {"referenceID": 6, "context": "CTBNs build on the framework of homogeneous Markov processes (Norris, 1997), which provide a model of continuous-time evolution.", "startOffset": 61, "endOffset": 75}, {"referenceID": 3, "context": "(2005) present an approximate inference algorithm for CTBNs which is an instance of the expectation propagation (EP) algorithm (Minka, 2001).", "startOffset": 127, "endOffset": 140}, {"referenceID": 3, "context": "Nodelman et al. (2005) present an approximate inference algorithm for CTBNs which is an instance of the expectation propagation (EP) algorithm (Minka, 2001).", "startOffset": 0, "endOffset": 23}, {"referenceID": 4, "context": "We begin by briefly reviewing the key definitions of Markov processes and continuous time Bayesian networks, as presented by Nodelman et al. (2002).", "startOffset": 125, "endOffset": 148}, {"referenceID": 2, "context": "The resulting density over complete trajectories can be formulated within the framework of exponential families (see Lauritzen (1996)).", "startOffset": 117, "endOffset": 134}, {"referenceID": 4, "context": "In this section, we briefly review the algorithm of Nodelman et al. (2005) (NKS from now on), which forms the basis for our approach.", "startOffset": 52, "endOffset": 75}, {"referenceID": 3, "context": "NKS address this problem by using expectation propagation (EP) (Minka, 2001).", "startOffset": 63, "endOffset": 76}, {"referenceID": 1, "context": "This is similar to maintaining consistency across cluster boundaries since, essentially, we can view the sub-intervals as defining a chain-structured cluster graph, embedded in the larger cluster Cj (as in the nested junction tree of Kjaerulff (1997)).", "startOffset": 234, "endOffset": 251}, {"referenceID": 3, "context": "A similar problem is encountered in Gaussian-EP (Minka, 2001).", "startOffset": 48, "endOffset": 61}, {"referenceID": 8, "context": "In some cases, there may be a need for a richer, more flexible representation of the messages (one of the key motivations for the development of non-parametric belief propagation (Sudderth et al., 2003).", "startOffset": 179, "endOffset": 202}], "year": 2009, "abstractText": "Most real-world dynamic systems are composed of different components that often evolve at very different rates. In traditional temporal graphical models, such as dynamic Bayesian networks, time is modeled at a fixed granularity, generally selected based on the rate at which the fastest component evolves. Inference must then be performed at this fastest granularity, potentially at significant computational cost. Continuous Time Bayesian Networks (CTBNs) avoid time-slicing in the representation by modeling the system as evolving continuously over time. The expectation-propagation (EP) inference algorithm of Nodelman et al. (2005) can then vary the inference granularity over time, but the granularity is uniform across all parts of the system, and must be selected in advance. In this paper, we provide a new EP algorithm that utilizes a general cluster graph architecture where clusters contain distributions that can overlap in both space (set of variables) and time. This architecture allows different parts of the system to be modeled at very different time granularities, according to their current rate of evolution. We also provide an information-theoretic criterion for dynamically re-partitioning the clusters during inference to tune the level of approximation to the current rate of evolution. This avoids the need to hand-select the appropriate granularity, and allows the granularity to adapt as information is transmitted across the network. We present experiments demonstrating that this approach can result in significant computational savings.", "creator": "Adobe InDesign CS2 (4.0.4)"}}}