{"id": "1206.6420", "review": {"conference": "ICML", "VERSION": "v1", "DATE_OF_SUBMISSION": "27-Jun-2012", "title": "Distributed Parameter Estimation via Pseudo-likelihood", "abstract": "estimating finite statistical system models within sensor networks requires distributed analytic algorithms, notably in which both human data and computation are widely distributed across the nodes of shaping the distributed network. we propose starting a general approach for distributed computer learning based based on combining local estimators defined by pseudo - likelihood components, each encompassing a number of combination methods, and provide both theoretical and experimental analysis. we show advantages that simple dynamic linear aided combination approximation or max - voting methods, beneficial when combined only with discrete second - order statistics information, which are reasonably statistically consistently competitive with more socially advanced and otherwise costly sophisticated joint opt optimization. our algorithms however have generated many naturally attractive properties including low discrete communication variance and computational financial cost levels and \" any - time \" behavior.", "histories": [["v1", "Wed, 27 Jun 2012 19:59:59 GMT  (1650kb)", "http://arxiv.org/abs/1206.6420v1", "Appears in Proceedings of the 29th International Conference on Machine Learning (ICML 2012)"]], "COMMENTS": "Appears in Proceedings of the 29th International Conference on Machine Learning (ICML 2012)", "reviews": [], "SUBJECTS": "cs.LG cs.DC stat.ML", "authors": ["qiang liu", "alexander t ihler"], "accepted": true, "id": "1206.6420"}, "pdf": {"name": "1206.6420.pdf", "metadata": {"source": "META", "title": "Distributed Parameter Estimation via Pseudo-likelihood", "authors": ["Qiang Liu", "Alexander Ihler"], "emails": ["qliu1@uci.edu", "ihler@ics.uci.edu"], "sections": [{"heading": "1. Introduction", "text": "Wireless sensor networks are becoming ubiquitous, with applications including ecological monitoring, health care, and smart homes. Traditional centralized approaches to machine learning are not well-suited to sensor networks, due to the sensors\u2019 restrictive resource constraints. Sensors have limited local computing, memory, and power, and their wireless communication is expensive in terms of power consumption. These constraints make centralized data collection and processing difficult. Fault-tolerance and robustness are also critical features.\nGraphical models are a natural framework for distributed inference in sensor networks (e.g., Cetin et al., 2007). However, most learning algorithms are not distributed, requiring centralized data processing and storage. In this work, we provide a general framework for distributed parameter estimation, based on combining local and inexpensive estimators.\nAppearing in Proceedings of the 29 th International Conference on Machine Learning, Edinburgh, Scotland, UK, 2012. Copyright 2012 by the author(s)/owner(s).\nThis paper is organized as follows. Section 2 sets up background on graphical models for sensor networks and learning algorithms. In Section 3, we propose a framework for distributed learning based on intelligently combining results from disjoint local estimators. We give theoretic analysis in Section 4 and experiments in Section 5. We discuss related work in Section 6 and finally conclude the paper in Section 7."}, {"heading": "2. Background", "text": ""}, {"heading": "2.1. Graphical models for sensor networks", "text": "Consider a graphical model of a random vector x = [x1, . . . , xp] in exponential family form,\np(x|\u03b8) = exp(\u03b8Tu(x)\u2212 logZ(\u03b8)), (1)\nwhere \u03b8 = {\u03b8\u03b1}\u03b1\u2208I and u(x) = {u\u03b1(x\u03b1)}\u03b1\u2208I are vectors of the same size, and \u03b8Tu(x) is their inner product. I is a set of variable indexes and u\u03b1(x\u03b1) are local sufficient statistics. Z(\u03b8) is the partition function, which normalizes the distribution. The distribution is associated with a Markov graph G = (V,E), with node i \u2208 V denoting a variable xi and edge (ij) \u2208 E representing that xi and xj co-appear in some \u03b1, that is, {i, j} \u2282 \u03b1. Let \u03b2i = {\u03b1 \u2208 I|i \u2208 \u03b1} be the set of \u03b1 that includes i. In pairwise graphical models, I = E \u222a V .\nTo model a sensor network, we represent the i-th sensor\u2019s measurement by xi, and assume that the communication links between sensors are identical to the Markov graph G, that is, sensor i and j have communication link if and only if (ij) \u2208 E. Assume that n independent samples X = [x1, . . . , xn] are drawn from a true distribution p(x|\u03b8\u2217). Due to memory and communication constraints on sensors, the data are stored locally within the network: each sensor stores only data measured by itself and its neighbors, that is, XA(i) = [x 1 A(i), . . . , x n A(i)], where A(i) = {i} \u222a N (i) and N (i) is the neighborhood of node i. The goal is to design a distributed algorithm for estimating the true \u03b8\u2217, with minimum communication and low, balanced local computational costs at the sensor nodes.\nNotation. Unless specified otherwise, we take E(\u00b7), var(\u00b7), and cov(\u00b7) to mean the expectation, variance,\nand covariance matrix under the true distribution p(x|\u03b8\u2217). For a likelihood function `(\u03b8;x), \u2207`(\u03b8) and \u22072`(\u03b8) denote the gradient and Hessian matrix w.r.t. \u03b8, where we suppress the dependence of `(\u03b8, x) on x for compactness. We use \u201chat\u201d accents to denote empirical average estimates, e.g., \u02c6\u0300(\u03b8,X) = 1n \u2211n k=1 `(\u03b8, x k)."}, {"heading": "2.2. M-estimators", "text": "M-estimators are a broad class of parameter estimators; an M-estimator with criterion function `(\u03b8;x) is\n\u03b8\u0302 = arg max \u03b8\n\u02c6\u0300(\u03b8;X).\nIn this paper we assume that `(\u03b8, x) is continuous differentiable and has a unique maximum. If E[\u2207`(\u03b8\u2217)] = 0, then under mild conditions standard asymptotic statistics (van der Vaart, 1998) show that \u03b8\u0302 is asymptotically consistent and normal, that is, \u221a n(\u03b8\u0302\u2212 \u03b8\u2217) N (0, V ), with asymptotic variance (Godambe, 1960)\nV = H\u2212TJH\u22121,\nwhere J = var(\u2207`(\u03b8\u2217)) is the Fisher information matrix and H = \u2212E(\u22072`(\u03b8\u2217)) is the expected Hessian matrix. ` is said to be information-unbiased (Lindsay, 1988) if J = H. In this case, we have V = H\u22121 = J\u22121, i.e., the asymptotic variance equals the inverse Fisher information matrix or Hessian matrix. Let s be a random vector with s = H\u22121\u2207`(\u03b8\u2217, x). An important intuition for asymptotic analysis is that \u03b8\u0302 \u2248 \u03b8\u2217 + 1\u221a\nn s\nat the large sample limit, so that the asymptotic variance can be rewritten as V = var(s).\nEmpirically, one can assess the quality of an Mestimator by estimating its asymptotic covariance; this can be done by approximating the E(\u00b7) and var(\u00b7) with their empirical counterparts, and \u03b8\u2217 with \u03b8\u0302, e.g., the asymptotic variance is estimated by V\u0302 = H\u0302\u22121J\u0302H\u0302\u22121, where J\u0302 = 1n \u2211n k=1(\u2207`(\u03b8\u0302;xk))(\u2207`(\u03b8\u0302;xk))T and H\u0302 =\n\u2212 1n \u2211n k=1\u22072`(\u03b8\u0302;xk). If ` is information-unbiased, only the Fisher information J need be calculated, avoiding calculating the second derivatives. In practice, these variance estimators perform well only when the parameter dimension is much smaller than the sample size; they are usually not directly applicable to practically sized problems. In this work, we show that by splitting the global estimator into low-dimensional local estimators, we can use covariance estimation on the local estimators to provide important information for combining them."}, {"heading": "2.3. MLE and MPLE", "text": "The maximum likelihood estimator (MLE) is the most well-known M-estimator; it maximizes the likelihood,\n`mle(\u03b8;x) = log p(x|\u03b8).\nThe MLE is asymptotically consistent and normal, and achieves the Crame\u0301r-Rao lower bound (is asymptotically at least as efficient as any unbiased estimator). Unfortunately, the MLE is often difficult to compute, because the likelihood involves the partition function Z(\u03b8), which is hard to evaluate for general graphical models (Wainwright & Jordan, 2008).\nThe maximum pseudo-likelihood estimator (MPLE) (Besag, 1975) provides a computationally efficient alternative to MLE. The pseudo-likelihood is defined as\n`mple(\u03b8;x) = p\u2211 i=1 log p(xi|xN (i); \u03b8\u03b2i), (2)\nwhere due to the Markov property, each conditional likelihood component only depends on \u03b8\u03b2i , the parameters incident to i, and on XA(i), the data available to sensor i. MPLE remains asymptotically consistent and normal, but is usually statistically less efficient than MLE \u2013 a sacrifice for computational efficiency. However, cases exist in which the MPLE is also statistically more favorable than MLE, e.g., when the model is misspecified (e.g., Liang & Jordan, 2008).\nThere is a weaker version of MPLE, well known in sparse learning (e.g., Ravikumar et al., 2010), that disjointly maximizes the single conditional likelihood (CL) components in MPLE, and then combines the overlapping components using some simple method such as averaging. Very recently, the disjoint MPLE has started to attract attention in distributed estimation (Wiesel & Hero, 2012), by observing that the conditional likelihoods define local estimators well suited to distributed computing.\nOur work. We address the problem of distributed parameter learning within a paradigm motived by MPLE and disjoint MPLE, in which the sensor nodes locally calculate their own inexpensive local estimators, whose results are communicated to nearby sensors and combined. We provide a more general framework for combining the local estimators, including weighted linear combinations, a max-voting method, and more advanced joint optimization methods. Powered by asymptotic analysis, we propose efficient methods to set optimal weights for the linear and max combination methods, and provide a comprehensive comparison of the proposed algorithms. Surprisingly, we show that the simple linear and max combination methods, when leveraged by well-chosen weights, are able to outperform joint optimization in some cases. In particular, the max-voting method performs well on \u201cdegree-unbounded\u201d graph structures, such as stars or scale free networks, that are difficult for many existing methods. In addition, we show that the joint\nMPLE can be recast into a sequence of disjoint MPLE combinations via the alternating direction method of multipliers (ADMM), and we show that, once it is initialized properly, interrupting the iterative algorithm at any point provides \u201ccorrect\u201d estimates; this leads to an any-time algorithm that can flexibly trade off performance and resources, and is robust to interruptions such as sensor failure. Finally we provide extensive simulation to illustrate our theoretical results."}, {"heading": "3. A Distributed Paradigm", "text": "For each sensor i, let `ilocal(\u03b8\u03b2i ;xA(i)) be a criterion function that depends only on local data XA(i) and the parameter sub-vector \u03b8\u03b2i . This defines a M-estimator that is efficient to compute locally by sensor i,\n\u03b8\u0302i\u03b2i = arg max \u03b8\u03b2i \u02c6\u0300i local(\u03b8\u03b2i ;XA(i)). (3)\nWe assume that E(\u2207`ilocal(\u03b8\u2217\u03b2)) = 0 and that (3) has a unique maximum, which guarantee that \u03b8\u0302i\u03b2i is asymptotically consistent and normal under standard technical conditions. Further, assume \u222ai\u03b2i = I, so that each parameter component is covered by at least one local estimator and a valid global estimator can be constructed by combining them.\nAlthough our results apply more generally, in this work we mainly take `ilocal(\u03b8\u03b2i ;xA(i)) = log p(xi|xN (i); \u03b8\u03b2i), which satisfies the conditions listed above. Moreover, such `ilocal(\u03b8\u03b2i) are information unbiased, i.e., V i local= (J ilocal) \u22121 =(Hilocal) \u22121. One can estimate the asymptotic variance by V\u0302 ilocal = (J\u0302 i local)\n\u22121, where J\u0302 ilocal involves calculating the covariance of the gradient statistics and is efficient once |\u03b2i| is relatively small.\nIf a parameter \u03b8\u03b1 is shared by multiple sensors, performance can be boosted by combining their information. We propose two types of consensus methods, generalizing disjoint MPLE and MPLE respectively."}, {"heading": "3.1. One-Step Consensus.", "text": "For each parameter \u03b8\u03b1, let \u03b8\u0302\u03b1 = {\u03b8\u0302i\u03b1|i \u2208 \u03b1} be the collection of estimates given by the sensors incident to \u03b1. The goal is to construct a combined estimator \u03b8\u0302\u03b1 as a function of \u03b8\u0302\u03b1. Probably the simplest method is averaging, i.e., \u03b8\u0302\u03b1 = 1 |\u03b1| \u2211 i\u2208\u03b1 \u03b8\u0302 i \u03b1. Unfortunately, as we show in the sequel, this simple approach usually performs poorly, in part because it weights all the estimators equally and the worst estimator may greatly degrade the overall performance. Thus, it would be helpful to weight the estimators by their quality.\nLet w\u0302i\u03b1, as a function of XA(i) and \u03b8\u0302 i local, be an empirical measure of the quality of the i-th local estimator\nfor estimating parameter \u03b8\u03b1 \u2013 for example, w\u0302 i could be a function of V\u0302 ilocal.We introduce two methods to combine the estimators based on weight w\u0302i:\nlinear consensus: \u03b8\u0302linear\u03b1 = \u2211 i\u2208\u03b1 w\u0302i\u03b1\u03b8\u0302 i \u03b1/ \u2211 i\u2208\u03b1 w\u0302i\u03b1, (4)\nmax consensus:\n\u03b8\u0302max\u03b1 = \u03b8\u0302 i0 \u03b1 , where w\u0302 i0 \u03b1 \u2265 w\u0302i\u03b1 for all i \u2208 \u03b1, (5)\nwhere the linear consensus takes a soft combination of the local estimators, while the max consensus votes on the best one. It should be noted that the max consensus can be treated as a special linear consensus whose weights are taken be to be zero, except on one local estimator. However, as we show later, the max consensus has some attractive properties making it an efficient algorithm for many problems.\nWe prove that linear and max consensus are asymptotically consistent and normal, and provide their asymptotic variance. We also discuss the optimal setting of the weights, in the sense of minimizing the asymptotic mean square error. Remarkably, we show that the optimum weights, particularly for the max consensus, are surprisingly easy to estimate, making one-step methods competitive to more advanced consensus methods."}, {"heading": "3.2. Joint Optimization via ADMM", "text": "A more principled way to ensure consensus is to solve a joint optimization problem,\nmax \u03b8i\u03b2i ,\u03b8\u0304 n\u2211 i=1 \u02c6\u0300i local(\u03b8 i \u03b2i |XA(i)) s.t. \u03b8 i \u03b2i = \u03b8\u0304\u03b2i for all i (6)\nwhere we maximize the sum of \u02c6\u0300ilocal under the constraint that all the local estimators should be consistent with a global \u03b8\u0304; this exactly recovers the joint MPLE method in (2) when `ilocal are the conditional likelihoods. In this section, we derive a distributed algorithm for (6) that can be treated as an iterative version of the linear consensus introduced above.\nOur algorithm is based on the alternating direction method of multipliers (ADMM), which is well suited to distributed convex optimization (Boyd et al., 2011), particularly distributed consensus (Bertsekas & Tsitsiklis, 1989).\nFor notation, let f i(\u03b8i\u03b2i) = \u2212\u02c6\u0300 i local(\u03b8 i \u03b2i |XA(i)). We introduce an augmented Lagrangian function for (6),\np\u2211 i=1 { f i(\u03b8i\u03b2i) + \u03bb i \u03b2i T (\u03b8i\u03b2i \u2212 \u03b8\u0304\u03b2i) + \u2211 \u03b1\u2208\u03b2i \u03c1i\u03b1 2 |\u03b8i\u03b1 \u2212 \u03b8\u0304\u03b1|2 } ,\nwhere \u03bbi\u03b2i are Lagrange multipliers of the same size as \u03b8i\u03b2i and \u03c1 i \u03b2i\nare positive penalty constants. Performing an alternating direction procedure on the augmented Lagrangian yields the ADMM algorithm:\n\u03b8i\u03b2i \u2190 arg min{f i(\u03b8i\u03b2i) + \u03bb i \u03b2i T \u03b8i\u03b2i + \u2211 \u03b1\u2208\u03b2i \u03c1i\u03b1 2 ||\u03b8i\u03b1 \u2212 \u03b8\u0304\u03b1||2}\n\u03b8\u0304\u03b1 \u2190 \u2211 i\u2208\u03b1 \u03c1i\u03b1\u03b8 i \u03b1/ \u2211 i\u2208\u03b1 \u03c1i\u03b1, \u2200\u03b1 \u2208 I \u03bbi\u03b1 \u2190 \u03bbi\u03b1 + \u03c1i\u03b1(\u03b8i\u03b1 \u2212 \u03b8\u0304\u03b1), \u2200\u03b1 \u2208 \u03b2i,\nThis update has an intuitive statistical interpretation. First, \u03b8i\u03b2i can be treated as a posterior MAP estimation of the parameter subject to a Gaussian prior with mean (\u03b8\u0304\u03b2i \u2212 \u03bbi\u03b2i/\u03c1 i \u03b2i ), which biases the estimate towards the average value; \u03b8\u0304 is then re-evaluated by taking a linear consensus of the local estimators. Thus, the joint optimization can be recast into a sequence of linear consensus steps. Given this connection, it is reasonable to set \u03c1i\u03b1 to be the weights of linear consensus, that is, \u03c1i\u03b1 = w\u0302 i \u03b1 and initialize \u03b8\u0304 to be the corresponding one-step estimator. Since linear consensus estimators are asymptotically consistent, we have\nTheorem 3.1. If we set \u03b8\u0304 to be asymptotically consistent and \u03bbi\u03b2i = 0 in the initial step of ADMM, then \u03b8\u0304 remains asymptotically consistent at every iteration.\nTherefore, one can interrupt the algorithm and fetch a \u201ccorrect\u201d answer at any iteration, giving a flexible anytime framework that can not only save on computation and communication, but is also robust to accidental failures, such as battery depletion."}, {"heading": "4. Asymptotic Analysis", "text": "In this section, we give an asymptotic analysis of our methods, by which we provide methods to optimally set the weights of linear and max consensus. For notational convenience, we embed the local estimator \u03b8\u0302i\u03b2i = arg max \u02c6\u0300i local(\u03b8\u03b2i , X) into a (possibly degenerate) estimator of the whole parameter vector \u03b8\u0302i = arg max \u02c6\u0300i(\u03b8,X), by setting \u03b8\u0302i\u03b1 = 0 for \u03b1 /\u2208 \u03b2i. Denote by V i the asymptotic variance of the extended estimator, with V ilocal on its \u03b2i \u00d7 \u03b2i sub-matrix and zero otherwise. Similarly, let Hi extend Hilocal, and s i extend si\u03b2i def = Hilocal\n\u22121\u2207`ilocal(\u03b8\u2217\u03b2i). Our results will reflect the intuition that \u03b8\u0302i \u2248 \u03b8\u2217 + 1\u221a\nn si at the large\nsample limit.\nFor our results, we generalize to a matrix extension of the linear consensus (4), defined as\n\u03b8\u0302matrix = ( \u2211 i W\u0302 i)\u22121 \u2211 i W\u0302 i\u03b8\u0302i, (7)\nwhere W\u0302 i are matrix weights that are non-zero only on the \u03b2i \u00d7 \u03b2i sub-matrices; we require that ( \u2211 i W\u0302 i)\u22121 is invertible. Note that the matrix extension is not directly suitable for distributed implementation, since it involves a global matrix inverse, but it will provide performance bounds for linear and max consensus and has close connection to joint optimization estimators. Theorem 4.1 (Linear Consensus). Assume W\u0302 i p\u2192\nW i and \u2211 iW i is an invertible matrix. Then \u03b8\u0302matrix in (7) is asymptotically consistent and normal, with an asymptotic variance of var [ ( \u2211 iW i)\u22121 \u2211 iW isi ] .\nAssume H = \u2211 iH i is invertible, then the joint op-\ntimization consensus \u03b8\u0302joint = arg max \u2211 i \u02c6\u0300 i(\u03b8, x) is a non-degenerate estimator of the full parameter vector \u03b8. It turns out \u03b8\u0302joint is asymptotically equivalent to a matrix linear consensus with weights W\u0302 i = H\u0302i: Corollary 4.2. \u03b8\u0302matrix in (7) with W\u0302 i = H\u0302i has asymptotic variance of var[( \u2211 iH i)\u22121 \u2211 i\u2207`i(\u03b8\u2217)], which is the same as that of \u03b8\u0302joint.\nFor max consensus estimators, we have Theorem 4.3. The \u03b8\u0302max in (5) is asymptotically consistent. Further, for any \u03b1 \u2208 I, if w\u0302i\u03b1 p\u2192 wi\u03b1 and wi0\u03b1 > maxi\u2208\u03b1,i 6=i0 w i \u03b1, then \u03b8\u0302 max \u03b1 is asymptotically normal, with asymptotic variance equal to V i0\u03b1,\u03b1."}, {"heading": "4.1. Optimal Choice of Weights", "text": "In this section, we consider the problem of choosing the optimal weights, in the sense of minimizing the asymptotic mean square error (MSE). Note that E(||\u03b8\u0302 \u2212 \u03b8\u2217||2) \u2192 1n trV as n \u2192 +\u221e, where tr(V ) is the trace of the asymptotic covariance matrix, and so the problem can be reformed to minimize tr(V ). In the following, we discuss the optimal weights for the linear and max consensus separately.\nWeights for Max Consensus. The greedy nature of max consensus makes optimal weights relatively easy:\nProposition 4.4. For the max consensus estimator \u03b8\u0302max as defined in (5), the weight wi\u03b1 = 1/V i \u03b1,\u03b1 achieves minimum least square error asymptotically.\nIn practice, we can estimate the optimal weights simply by w\u0302i\u03b1 = 1/V\u0302 i \u03b1,\u03b1, which makes max consensus feasible in practice.\nWeights for Linear Consensus. By Theorem 4.1, the optimal weights for matrix linear consensus solve\nmin W i tr[var( \u2211 i W isi ) ] s.t.\n\u2211 i W i = 1, (8)\nwhere W i are non-zero only on the \u03b2i \u00d7 \u03b2i submatrix and 1 denotes the identity matrix of the same size\nas W i. Solving (8) is difficult in general, but if si are pairwise independent and \u03b8\u0302i are information-unbiased, the weights W i = Hi, asymptotically equivalent to \u03b8\u0302joint as shown in Corollary 4.2, achieves optimality.\nProposition 4.5. Assume \u03b8\u0302i are informationunbiased. If cov(si, sj) = 0 for all i 6= j, then \u03b8\u0302joint achieves the optimum MSE as defined in (8).\nThis implies that if the estimators are independent or weakly correlated, the joint optimization estimator \u03b8\u0302joint is guaranteed to perform no worse than the linear and max consensus methods (both suboptimal to the best matrix consensus). However, in the case that the local estimators are strongly correlated (usually the case in practice), there is the chance that linear or max consensus, with properly chosen weights, can outperform the joint optimization method.\nOn the other hand, when W i in (8) are constrained to be diagonal matrices, reducing to a set of vector weights wi\u03b1, the optimization becomes easier. Let w\u03b1 = {wi\u03b1}i\u2208\u03b1 and V\u03b1 be an |\u03b1| \u00d7 |\u03b1| matrix with V ij\u03b1 = cov(s i \u03b1, s j \u03b1), i.e., V\u03b1 is the covariance matrix between the local estimators on parameter \u03b8\u03b1. Then,\nProposition 4.6. For linear consensus estimator \u03b8\u0302linear as defined in (4), the weights w\u03b1 = V \u22121 \u03b1 e, where e is a column vector of all ones, achieves the minimum asymptotic least square error.\nIn other words, the optimal vector weights for linear consensus equal the column sums of V \u22121\u03b1 . In practice, these weights can be estimated by w\u0302\u03b1 = V\u0302 \u22121 \u03b1 e, where V\u0302 ij\u03b1 = 1 n \u2211n k=1 s i \u03b1(x\nk) \u00b7 sj\u03b1(xk), and sk\u03b1(xk) = (H\u0302i)\u22121\u2207`i(\u03b8\u0302i;xk). In the sensor network setting, calculating V ij\u03b1 requires a secondary communication step in which the sensors pass {si\u03b1(xk)}nk=1 to their neighbors. Note that this communication step may be expensive if the number of data n is large (although one can pass a subset of samples to get a rougher estimate).\nIt is interesting to compare to the optimal weights for max consensus in Proposition 4.4, where no communication step is required. This is because max consensus fundamentally ignores the correlation structure, while linear consensus must account for it. Some further useful insights arise by considering the cases of extremely weak or strong correlations.\nProposition 4.7. If cov(si, sj) = 0, \u2200i 6= j, then the \u03b8\u0302linear as defined in (4) achieves the lowest asymptotic MSE with weights wi\u03b1 = 1/V i \u03b1,\u03b1.\nThis suggests that w\u0302i\u03b1 = 1/V\u0302 i \u03b1,\u03b1, which is optimal for max consensus selection, might also be a reasonable choice for linear consensus. However, the independence assumption is always violated in practice. To\nsee what happens when the estimators are strongly correlated, consider the opposite extreme, in which the local estimators are deterministically correlated:\nProposition 4.8. If si (i = 1, . . . , p) are deterministically positively correlated, i.e., there exists a random vector s0, and constants vi\u03b1 \u2265 0, such that si\u03b1 = vi\u03b1s0\u03b1, then the optimal vector weights {wi\u03b1} for linear consensus, under the constraint wi\u03b1 \u2265 0, is wi\u03b1 = 1 if vi\u03b1 \u2264 vj\u03b1 for any j \u2208 \u03b1 and wi\u03b1 = 0 if otherwise.\nSince linear consensus with 0-1 weights reduces to max consensus, this result suggests that the optimal max consensus is not much worse than the optimal linear consensus when the estimators are strongly positively correlated. In practice, we find that the local estimators defined by conditional likelihoods are always positively correlated, justifying max consensus in practice."}, {"heading": "4.2. Illustration on One Parameter Case", "text": "In this section, we illustrate our asymptotic results in a toy example, providing intuitive comparison of our algorithms. Assume \u03b8 is a scale parameter, estimated by two information-unbiased estimators \u03b8\u0302i = arg max `i(\u03b8) (i = 1, 2). Let hi = \u2212E(\u22072`i(\u03b8\u2217)) and si = (hi)\u22121\u2207f i(\u03b8\u2217); then the asymptotic variance is vi = (hi)\u22121 = var(si). Let v12 = cov(s1, s2) be the correlation of the two estimators.\nLinear consensus with uniform weights: \u03b8\u0302linUnif = 1 2 (\u03b8\u0302 1 + \u03b8\u03022); the asymptotic variance is:\nvar (s1 + s2\n2\n) = 1\n4 (v1 + v2 + 2v12).\nLinear consensus with Hessian weights wi = hi: \u03b8\u0302linHessian = (h\u03021 + h\u03022)\u22121(h\u03021\u03b8\u03021 + h\u03022\u03b8\u03022). By Corollary 4.2, the asymptotic variance of \u03b8\u0302linHessian is the same as that of \u03b8\u0302joint = arg max\u03b8 \u2211 i \u02c6\u0300i(\u03b8), which is:\nvar(h1s1 + h2s2) = v1v2(v1 + v2 + 2v12)\n(v1 + v2)2 .\nLinear consensus with optimal weights \u03b8\u0302linOpt: By Proposition 4.6, the optimal weights for linear consensus are w1 \u2217 = v 2\u2212v12\nv1+v2\u2212v12 and w 2\u2217 = v 2\u2212v12 v1+v2\u2212v12 . The\nasymptotic variance is\nvar(w1 \u2217 s1 + w2 \u2217 s2) =\nv1v2 \u2212 v12\nv1 + v2 \u2212 2v12 .\nMax consensus with optimal weights \u03b8\u0302maxOpt. By Proposition 4.4, for max consensus the weights wi = hi are optimal. The asymptotic variance is min{v1, v2}.\nClaim 4.9. In the toy case, we have \u03b8\u0302linOpt \u03b8\u0302joint(= \u03b8\u0302linHessian) \u03b8\u0302linUnif and \u03b8\u0302linOpt \u03b8\u0302maxOpt, where \u03b8\u0302a \u03b8\u0302b means MSE(\u03b8\u0302a) \u2264 MSE(\u03b8\u0302b) asymptotically.\nProof. \u03b8\u0302joint \u03b8\u0302linUnif is shown by the arithmeticgeometric mean inequality, and the rest since \u03b8\u0302linHessian and \u03b8\u0302maxOpt are special forms of linear consensus.\nHowever, \u03b8\u0302linUnif or \u03b8\u0302joint are not necessarily inferior or superior to \u03b8\u0302maxOpt. Their relative performance depends on the correlation and the quality (variance) of the two local estimators. Let \u03c112 = v12/ \u221a v1v2 be the correlation coefficient of the estimators, and \u03b3=min{v1/v2, v2/v1} the ratio of their variances. Claim 4.10. In the toy case, \u03b8\u0302joint(= \u03b8\u0302linHessian) \u03b8\u0302maxOpt if and only if \u03c112 \u2264 12 \u221a \u03b3(\u03b3 + 1). Similarly, \u03b8\u0302linUnif \u03b8\u0302maxOpt if and only if \u03c112 \u2264 12\u221a\u03b3 (3\u03b3 \u2212 1);\nSee Fig. 1 for illustration; this highlights the relative performance of max vs. linear consensus. While \u03b8\u0302linHessian and \u03b8\u0302linUnif tend to work better when the local estimators perform similarly (\u03b3 \u2248 1) or when the local estimators have low or even negative correlations, \u03b8\u0302maxOpt tends to work well when one local estimator is much better than the others (\u03b3 1) or when the local estimators are strongly positively correlated. This robustness makes max consensus useful for learning in difficult graphs, such as scale free graphs, for which standard methods often perform poorly (Ravikumar et al., 2010; Liu & Ihler, 2011). Fig. 1(b) illustrates how the values of \u03b3 and \u03c112 are changed by varying the local potentials in a binary two-node model. Basically, \u03b8\u0302maxOpt tends to work better when the magnitudes of the local potentials differ greatly, i.e., when the model is heteroskedastic."}, {"heading": "5. Experiments", "text": "In this section, we test our algorithms on both small models (for which the asymptotic variance can be exactly calculated) and larger models of more practical size. We use a pairwise Ising model p(x) \u221d exp( \u2211 (ij)\u2208E \u03b8ijxixj + \u2211 i\u2208V \u03b8ixi), xi \u2208 {\u22121, 1}, with random true parameters generated by\n\u03b8ij \u223c N (0, \u03c3pair) and \u03b8i \u223c N (0, \u03c3singleton). We test the Joint-MPLE, and the linear consensus with uniform weights (Linear-Uniform), with diagonal weights w\u0302i\u03b1 = 1/V\u0302 i \u03b1,\u03b1 (Linear-Diagonal) and with the optimum vector weights given in Proposition 4.6 (Linear-Opt). We also test the max consensus with diagonal weights (Max-Diagonal(Opt)), which is optimal for max consensus (Proposition 4.4). We quantify the algorithms either by exactly calculated asymptotic efficiency, defined as tr(V )/tr(Vmle), or empirically by the MSE ||\u03b8\u0302 \u2212 \u03b8\u2217||2 calculated on simulated datasets."}, {"heading": "5.1. Small Models", "text": "Two small graphs are considered: star graphs and grids, which have opposite topological properties. For these small models, we estimate the pairwise parameters \u03b8ij with known singleton parameters \u03b8i.\nStar graphs. A star graph has an unbalanced degree distribution, peaked at the center node. There has been theoretical and empirical work showing that such degree-unbounded graphs are harder to learn than more regular graphs (e.g., Liu & Ihler, 2011). From our perspective, the difficulty arises because the local estimators of high-degree nodes tend to deteriorate the overall performance. As we suggest in Section 4, the max consensus method is suitable for such graphs, as it can identify and discard the bad estimators.\nThe simulation supports this expectation. In Fig. 2(a), as degree increases, the variance of the local estimator of the center node increases quickly compared to the leaves (averaged). Fig. 2(b) shows the exact (solid lines) and empirical (dashed) asymptotic efficiencies of the algorithms on star graphs of different sizes. Linear-Uniform performs worst, since it fails to discount the influence of the worst estimator. Joint-MPLE and Linear-Diagonal perform better but still deteriorate as degree increases, since they downweight the worse estimators, but only to some extent. In contrast, Max-Diagonal is robust to the increasing degree, and can identify and discard the worst estimators. As theoretically predicted, Linear-Opt outperforms Max-Diagonal, but only slightly in this case. Note Linear-Opt is more costly than Max-Diagonal due to the extra communication step. The exact and empirical values in Fig. 2(b) match closely, showing the correctness of our theoretical analysis.\nIn Fig. 2(c) we show the effect of singleton potentials. The performance of one-step consensus methods generally decreases with higher magnitude singleton potentials, while the Joint-MPLE stays the same. Intuitively, this is because the local estimators are not able to jointly infer the local potentials, causing prob-\nlems when those local potentials dominate. Since our analysis is mainly asymptotic, we evaluate how the algorithms perform for small sample sizes in Fig. 2(d). As can be seen, the finite sample performance is essentially consistent with the asymptotic analysis.\n4\u00d74 Grid. The algorithms\u2019 performance on grids have the opposite trends; see Fig. 3(a). Joint-MPLE performs best, while max-Diagonal performs relatively poorly. This is because grids have balanced degree, and all the local estimators perform equally well. We check the finite sample performance of the algorithms in Fig. 3(b), which again shows similar trends to our asymptotic results. Finally, we show the convergence of ADMM in Fig. 3(c), illustrating that our initialization increases the convergence speed greatly."}, {"heading": "5.2. Larger Models", "text": "We also test our algorithms on larger graphs, including a 100-node scale free network generated via the Baraba\u0301si-Albert model (Baraba\u0301si & Albert, 1999) and a 100-node Euclidean graph generated by connecting nearby sensors (distance \u2264 .15) uniformly placed on the [0, 1]\u00d7 [0, 1] plane; see Fig. 4. On these models, we estimate both the singleton and pairwise parameters. In Fig. 4(a)-(b) we see trends similar to their smaller analogues, the star graph and 4\u00d74 grid, verifying that our analysis remains useful on models of larger sizes."}, {"heading": "6. Related Work", "text": "A very recent, independently developed work (Wiesel & Hero, 2012) adopts a similar, but less general approach for Gaussian covariance estimation. They propose a similar linear consensus approach (using only uniform weights) and a similar parallel algorithm for joint MPLE, but do not discuss max consensus or lin-\near consensus with general weights, and do not provide a comprehensive theoretical analysis. Another recent work (Eidsvik et al., 2010) uses composite likelihood for parallel computing on spatial data. Bradley & Guestrin (2011) gave a sample complexity analysis for MPLE and disjoint MPLE, which may be extensible to our algorithms.\nAnother line of work approximates MLE by estimating the partition function with variational algorithms (e.g., Wainwright, 2006; Sutton & McCallum, 2009). These methods can perform well at prediction tasks even with a \u201cwrong\u201d model, and can take a messagepassing form potentially suitable to distributed settings. However, in terms of parameter estimation, these methods introduce a bias due to the approximate inference that is hard to estimate or control."}, {"heading": "7. Conclusion", "text": "In this work, we present a general framework for distributed parameter learning. We show that the smart one-step consensus methods of the local estimators, especially those that exploit local second-order information, are both computationally efficient and statistically competitive with iterative methods using joint optimization. Particularly, we show that the max combination method is well suited to scale-free networks, a well-identified problem for existing methods. Our theory of combining estimators is quite general, and can be applied to other contexts to boost statistical performance. Future directions include considering model misspecification, finite sample complexity analysis and extension to high-dimensional structure learning.\nAcknowledgements. Work supported in part by NSF IIS-1065618 and a Microsoft Research Fellowship."}], "references": [{"title": "Emergence of scaling in random networks", "author": ["Barab\u00e1si", "A.-L", "R. Albert"], "venue": "Science, 286(5439):509\u2013512,", "citeRegEx": "Barab\u00e1si et al\\.,? \\Q1999\\E", "shortCiteRegEx": "Barab\u00e1si et al\\.", "year": 1999}, {"title": "Parallel and distributed computation: numerical methods", "author": ["D. Bertsekas", "J. Tsitsiklis"], "venue": null, "citeRegEx": "Bertsekas and Tsitsiklis,? \\Q1989\\E", "shortCiteRegEx": "Bertsekas and Tsitsiklis", "year": 1989}, {"title": "Statistical analysis of non-lattice data", "author": ["J. Besag"], "venue": "J. Royal Stat. Soc. D,", "citeRegEx": "Besag,? \\Q1975\\E", "shortCiteRegEx": "Besag", "year": 1975}, {"title": "Distributed optimization and statistical learning via the alternating direction method of multipliers", "author": ["S. Boyd", "N. Parikh", "E. Chu", "B. Peleato", "J. Eckstein"], "venue": "Found. Trends in Machine Learn.,", "citeRegEx": "Boyd et al\\.,? \\Q2011\\E", "shortCiteRegEx": "Boyd et al\\.", "year": 2011}, {"title": "An asymptotic analysis of generative, discriminative, and pseudolikelihood estimators", "author": ["J.K. Bradley", "C. Guestrin"], "venue": "In AISTATS,", "citeRegEx": "Bradley and Guestrin,? \\Q2011\\E", "shortCiteRegEx": "Bradley and Guestrin", "year": 2011}, {"title": "Graphical models and fusion in sensor networks", "author": ["M. Cetin", "L. Chen", "J. Fisher III", "A. Ihler", "O. Kreidl", "R. Moses", "M. Wainwright", "J. Williams", "A. Willsky"], "venue": "Wireless Sensor Networks,", "citeRegEx": "Cetin et al\\.,? \\Q2007\\E", "shortCiteRegEx": "Cetin et al\\.", "year": 2007}, {"title": "Estimation and prediction in spatial models with block composite likelihoods using parallel computing", "author": ["J. Eidsvik", "B.A. Shaby", "B.J. Reich", "M. Wheeler", "J. Niemi"], "venue": null, "citeRegEx": "Eidsvik et al\\.,? \\Q2010\\E", "shortCiteRegEx": "Eidsvik et al\\.", "year": 2010}, {"title": "An asymptotic analysis of generative, discriminative, and pseudolikelihood estimators", "author": ["P. Liang", "M.I. Jordan"], "venue": "In ICML, pp", "citeRegEx": "Liang and Jordan,? \\Q2008\\E", "shortCiteRegEx": "Liang and Jordan", "year": 2008}, {"title": "Composite likelihood methods", "author": ["B.G. Lindsay"], "venue": "Contemporary Mathematics,", "citeRegEx": "Lindsay,? \\Q1988\\E", "shortCiteRegEx": "Lindsay", "year": 1988}, {"title": "Learning scale free networks by reweighted L1 regularization", "author": ["Q. Liu", "A. Ihler"], "venue": "In AISTATS, pp", "citeRegEx": "Liu and Ihler,? \\Q2011\\E", "shortCiteRegEx": "Liu and Ihler", "year": 2011}, {"title": "Highdimensional Ising model selection using L1-regularized logistic regression", "author": ["P. Ravikumar", "M.J. Wainwright", "J. Lafferty"], "venue": "Ann. Stat.,", "citeRegEx": "Ravikumar et al\\.,? \\Q2010\\E", "shortCiteRegEx": "Ravikumar et al\\.", "year": 2010}, {"title": "Piecewise training for structured prediction", "author": ["C. Sutton", "A. McCallum"], "venue": "Mach. Learn.,", "citeRegEx": "Sutton and McCallum,? \\Q2009\\E", "shortCiteRegEx": "Sutton and McCallum", "year": 2009}, {"title": "Estimating the wrong graphical model: Benefits in the computation-limited setting", "author": ["M. Wainwright"], "venue": "J. Machine Learn. Res.,", "citeRegEx": "Wainwright,? \\Q2006\\E", "shortCiteRegEx": "Wainwright", "year": 2006}, {"title": "Graphical models, exponential families, and variational inference", "author": ["M. Wainwright", "M. Jordan"], "venue": "Found. Trends Mach. Learn.,", "citeRegEx": "Wainwright and Jordan,? \\Q2008\\E", "shortCiteRegEx": "Wainwright and Jordan", "year": 2008}, {"title": "Distributed covariance estimation in Gaussian graphical models", "author": ["A. Wiesel", "A.O. Hero"], "venue": "IEEE Trans. Sig. Proc.,", "citeRegEx": "Wiesel and Hero,? \\Q2012\\E", "shortCiteRegEx": "Wiesel and Hero", "year": 2012}], "referenceMentions": [{"referenceID": 8, "context": "` is said to be information-unbiased (Lindsay, 1988) if J = H.", "startOffset": 37, "endOffset": 52}, {"referenceID": 2, "context": "The maximum pseudo-likelihood estimator (MPLE) (Besag, 1975) provides a computationally efficient alternative to MLE.", "startOffset": 47, "endOffset": 60}, {"referenceID": 3, "context": "Our algorithm is based on the alternating direction method of multipliers (ADMM), which is well suited to distributed convex optimization (Boyd et al., 2011), particularly distributed consensus (Bertsekas & Tsitsiklis, 1989).", "startOffset": 138, "endOffset": 157}, {"referenceID": 10, "context": "This robustness makes max consensus useful for learning in difficult graphs, such as scale free graphs, for which standard methods often perform poorly (Ravikumar et al., 2010; Liu & Ihler, 2011).", "startOffset": 152, "endOffset": 195}, {"referenceID": 6, "context": "Another recent work (Eidsvik et al., 2010) uses composite likelihood for parallel computing on spatial data.", "startOffset": 20, "endOffset": 42}, {"referenceID": 6, "context": "Another recent work (Eidsvik et al., 2010) uses composite likelihood for parallel computing on spatial data. Bradley & Guestrin (2011) gave a sample complexity analysis for MPLE and disjoint MPLE, which may be extensible to our algorithms.", "startOffset": 21, "endOffset": 135}], "year": 2012, "abstractText": "Estimating statistical models within sensor networks requires distributed algorithms, in which both data and computation are distributed across the nodes of the network. We propose a general approach for distributed learning based on combining local estimators defined by pseudo-likelihood components, encompassing a number of combination methods, and provide both theoretical and experimental analysis. We show that simple linear combination or max-voting methods, when combined with second-order information, are statistically competitive with more advanced and costly joint optimization. Our algorithms have many attractive properties including low communication and computational cost and \u201cany-time\u201d behavior.", "creator": "LaTeX with hyperref package"}}}