{"id": "1209.5549", "review": {"conference": "NIPS", "VERSION": "v1", "DATE_OF_SUBMISSION": "25-Sep-2012", "title": "Towards a learning-theoretic analysis of spike-timing dependent plasticity", "abstract": "this paper suggests a learning - model theoretic perspective on how synaptic signal plasticity benefits affected global brain cortex functioning. concurrently we briefly introduce a simplified model, labeled the selectron, that ( i ) arises today as the inverse fast time constant limit \u03b1 of leaky integrate - sink and - purge fire induced neurons generally equipped with intrinsic spiking coefficient timing dependent peak plasticity ( \u03b3 stdp ) and ( always ii ) failure is amenable and to theoretical analysis. meantime we show that the nonlinear selectron encodes reward expectation estimates into spikes and remember that satisfying an enhanced error corrected bound on spikes is hence controlled again by a spiking margin and measures the sum of those synaptic sensitivity weights. moreover, the efficacy of training spikes ( their compare usefulness to other reward maximizing selectrons ) also automatically depends less on total posterior synaptic strength. finally finally, based slightly on approximately our sensitivity analysis, we propose adopting a hierarchical regularized version of mammalian stdp, function and thus show the regularization improves thus the robustness attributes of mammalian neuronal learning environments when faced with multiple stimuli.", "histories": [["v1", "Tue, 25 Sep 2012 09:23:41 GMT  (123kb,D)", "http://arxiv.org/abs/1209.5549v1", "To appear in Adv. Neural Inf. Proc. Systems"]], "COMMENTS": "To appear in Adv. Neural Inf. Proc. Systems", "reviews": [], "SUBJECTS": "q-bio.NC cs.LG stat.ML", "authors": ["david balduzzi", "michel besserve"], "accepted": true, "id": "1209.5549"}, "pdf": {"name": "1209.5549.pdf", "metadata": {"source": "CRF", "title": "Towards a learning-theoretic analysis of spike-timing dependent plasticity", "authors": ["David Balduzzi"], "emails": ["david.balduzzi@inf.ethz.ch", "michel.besserve@tuebingen.mpg.de"], "sections": [{"heading": "1 Introduction", "text": "Finding principles underlying learning in neural networks is an important problem for both artificial and biological networks. An elegant suggestion is that global objective functions may be optimized during learning [1]. For biological networks however, the currently known neural plasticity mechanisms use a very restricted set of data \u2013 largely consisting of spikes and diffuse neuromodulatory signals. How a global optimization procedure could be implemented at the neuronal (cellular) level is thus a difficult problem.\nA successful approach to this question has been Rosenblatt\u2019s perceptron [2] and its extension to multilayer perceptrons via backpropagation [3]. Similarly, (restricted) Boltzmann machines, constructed from simple stochastic units, have provided a remarkably powerful approach to organizing distributed optimization across many layers [4]. By contrast, although there has been significant progress in developing and understanding more biologically realistic models of neuronal learning [5\u201310], these do not match the performance of simpler, more analytically and computationally tractable models in learning tasks.\nOverview. This paper constructs a bridge from biologically realistic to analytically tractable models. The selectron is a model derived from leaky integrate and fire neurons equipped with spiketiming dependent plasticity that is amenable to learning-theoretic analysis. Our aim is to extract some of the principles implicit in STDP by thoroughly investigating a limit case.\nSection \u00a72 introduces the selectron. We state a constrained reward maximization problem which implies that selectrons encode empirical reward estimates into spikes. Our first result, section \u00a73,\nar X\niv :1\n20 9.\n55 49\nv1 [\nqbi\no. N\nC ]\nis that the selectron arises as the fast time constant limit of well-established models of neuronal spiking and plasticity, suggesting that cortical neurons may also be encoding reward estimates into their spiketrains.\nTwo important questions immediately arise. First, what guarantees can be provided on spikes being reliable predictors of global (neuromodulatory) outcomes? Second, what guarantees can be provided on the usefulness of spikes to other neurons? Sections \u00a74 and \u00a75 answer these questions by providing an upper bound on a suitably defined 0/1 loss and a lower bound on the efficacy of a selectron\u2019s spikes, measured in terms of its contribution to the expected reward of a downstream selectron. Both bounds are controlled by the sum of synaptic weights \u2016w\u20161, thereby justifying the constraint introduced in \u00a72. Finally, motivated by our analysis, \u00a76 introduces a regularized STDP rule and shows that it learns more robustly than classical STDP. \u00a77 concludes the paper. Proofs of theorems are provided in the supplementary material.\nRelated work. Spike-timing dependent plasticity and its implications for the neural code have been intensively studied in recent years. The work closest in spirit to our own is Seung\u2019s \u201chedonistic\u201d synapses, which seek to increase average reward [6]. Our work provides guarantees on the finite sample behavior of a discrete-time analog of hedonistic neurons. Another related line of research derives from the information bottleneck method [9,11] which provides an alternate constraint to the one considered here. An information-theoretic perspective on synaptic homeostasis and metabolic cost, complementing the results in this paper, can be found in [12, 13]. Simulations combining synaptic renormalization with burst-STDP can be found in [14].\nImportant aspects of plasticity that we have not considered here are properties specific to continuoustime models, such as STDP\u2019s behavior as a temporal filter [15], and also issues related to convergence [8, 10].\nThe learning-theoretic properties of neural networks have been intensively studied, mostly focusing on perceptrons, see for example [16]. A non-biologically motivated \u201clarge-margin\u201d analog of the perceptron was proposed in [17]."}, {"heading": "2 The selectron", "text": "We introduce the selectron, which can be considered a biologically motivated adaptation of the perceptron, see \u00a73. The mechanism governing whether or not the selectron spikes is a Heaviside function acting on a weighted sum of synaptic inputs; our contribution is to propose a new reward function and corresponding learning rule.\nLet us establish some notation. Let X denote the set of N -dimensional {0, 1}-valued vectors forming synaptic inputs to a selectron, and Y = {0, 1} the set of outputs. A selectron spikes according to\ny = fw(x) := H (w \u1d40x\u2212 \u03d1) , where H(z) := { 1 if z > 0 0 else\n(1)\nis the Heaviside function and w is a [0, 1] \u2282 R valued N -vector specifying the selectron\u2019s synaptic weights. Let P (x) denote the probability of input x arising.\nTo model the neuromodulatory system we introduce random variable \u03bd : X\u2192 {\u22121, 0,+1}, where positive values correspond to desirable outcomes, negative to undesirable and zero to neutral. Let P (\u03bd|x) denote the probability of the release of neuromodulatory signal subsequent to input x. Definition 1. Define reward function\nR(x, fw, \u03bd) = \u03bd(x)\ufe38\ufe37\ufe37\ufe38 neuromodulators \u00b7 (w\u1d40x\u2212 \u03d1)\ufe38 \ufe37\ufe37 \ufe38 margin \u00b7 fw(x)\ufe38 \ufe37\ufe37 \ufe38 selectivity =\n{ \u03bd(x) \u00b7 (w\u1d40x\u2212 \u03d1) if y = 1 0 else.\n(2)\nThe reward consists in three components. The first term is the neuromodulatory signal, which acts as a supervisor. The second term is the total current w\u1d40x minus the threshold \u03d1. It is analogous to the margin in support vector machines or boosting algorithms, see section \u00a74 for a precise formulation.\nThe third term gates rewards according to whether or not the selectron spikes. The reward is thus selected1: neuromodulatory signals are ignored by the selectron\u2019s reward function when it does not spike, enabling specialization.\nConstrained reward maximization. The selectron solves the following optimization problem:\nmaximize: w R\u0302n := n\u2211 i=1 \u03bd(x(i)) \u00b7 (w\u1d40x(i) \u2212 \u03d1) \u00b7 fw(x(i)) (3)\nsubject to: \u2016w\u20161 \u2264 \u03c9 for some \u03c9 > 0.\nRemark 1 (spikes encode rewards). Optimization problem (3) ensures that selectrons spike for inputs that, on the basis of their empirical sample, reliably lead to neuromodulatory rewards. Thus, spikes encode expectations about rewards.\nThe constraint is motivated by the discussion after Theorem 1 and the analysis in \u00a74 and \u00a75. We postpone discussion of how to impose the constraint to \u00a76, and focus on reward maximization here. The reward maximization problem cannot be solved analytically in general. However, it is possible to use an iterative approach. Although fw(x) is not continuous, the reward function is a continuous function of w and is differentiable everywhere except for the \u201ccorner\u201d where w\u1d40x \u2212 \u03d1 = 0. We therefore apply gradient ascent by computing the derivative of (3) with respect to synaptic weights to obtain online learning rule\n\u2206wj = \u03b1 \u00b7 \u03bd(x) \u00b7 xj \u00b7 fw(x) = { \u03b1 \u00b7 \u03bd(x) if xj = 1 and y = 1 0 else\n(4)\nwhere update factor \u03b1 controls the learning rate.\nThe learning rule is selective: regardless of the neuromodulatory signal, synapse wjk is updated only if there is both an input xj = 1 and output spike y = fw(x) = 1.\nThe selectron is not guaranteed to find a global optimum. It is prone to initial condition dependent local optima because rewards depend on output spikes in learning rule (4). Although this is an undesirable property for an isolated learner, it is less important, and perhaps even advantageous, in large populations where it encourages specialization.\nRemark 2 (unsupervised setting). Define the unsupervised setting by \u03bd(x) = 1 for all x. The reward function reduces to R(x, fw) = (w\u1d40x\u2212 \u03d1) \u00b7 fw(x). Without the constraint synapses will saturate. Imposing the constraint yields a more interesting solution where the selectron finds a weight vector summing to \u03c9 which balances (i) frequent spikes and (ii) high margins.\nTheorem 1 (Controlling the frequency of spikes). Assuming synaptic inputs are i.i.d. Bernoulli variables with P (spike) = p, then\nP ( fw(x) = 1 ) \u2264 p \u00b7 ( \u2016w\u20161 \u03d1 )2 \u2264 p \u00b7 (\u03c9 \u03d1 )2 .\nThe Bernoulli regime is the discrete-time analog of the homogeneous Poisson setting used to prove convergence of reward-modulated STDP in [8]. Interestingly, in this setting the constraint provides a lever for controlling (lower bounding) rewards per spike{\nreward per spike } = R\u0302\nP (fw(x) = 1) \u2265 c1 \u00b7\nR\u0302 \u03c92 .\nIf inputs are not Bernoulli i.i.d., then P (y = 1) and \u03c9 still covary, although the precise relationship is more difficult to quantify. Although i.i.d. inputs are unrealistic, note that recent neurophysiological evidence suggests neuronal firing \u2013 even of nearby neurons \u2013 is uncorrelated [18].\n1The name \u201cselectron\u201d was chosen to emphasize this selective aspect."}, {"heading": "3 Relation to leaky integrate-and-fire neurons equipped with STDP", "text": "The literature contains an enormous variety of neuronal models, which vary dramatically in sophistication and the extent to which they incorporate the the details of the underlying biochemical processes. Similarly, there is a large menagerie of models of synaptic plasticity [19]. We consider two well-established models: Gerstner\u2019s Spike Response Model (SRM) which generalizes leaky integrate-and-fire neurons [20] and the original spike-timing dependent plasticity learning rule proposed by Song et al [5], and show that the selectron arises in the fast time constant limit of the two models.\nFirst let us recall the SRM. Suppose neuron nk last outputted a spike at time tk and receives input spikes at times tj from neuron nj . Neuron nk spikes or according to the Heaviside function applied to the membrane potential Mw:\nfw(t) = H (Mw(t)\u2212 \u03d1) where Mw(t) = \u03b7(t\u2212 tk) + \u2211 tj\u2264t wjk \u00b7 (t\u2212 tj) at time t \u2265 tk.\nInput and output spikes add (t\u2212 tj) = K [ e ( tj\u2212t \u03c4m ) \u2212 e ( tj\u2212t \u03c4s )] and \u03b7(t\u2212 tk) = \u03d1 [ K1e ( tk\u2212t \u03c4m ) \u2212K2 ( e ( tk\u2212t \u03c4m ) \u2212 e ( tk\u2212t \u03c4s ))] to the membrane potential for tj \u2264 t and tk \u2264 t respectively. Here \u03c4m and \u03c4s are the membrane and synapse time constants.\nThe original STDP update rule [5] is\n\u2206wjk = \u03b1+ \u00b7 e ( tj\u2212tk \u03c4+ ) if tj \u2264 tk\n\u2212\u03b1\u2212 \u00b7 e ( tk\u2212tj \u03c4\u2212 ) else\n(5)\nwhere \u03c4+ and \u03c4\u2212 are time constants. STDP potentiates input synapses that spike prior to output spikes and depotentiates input synapses that spike subsequent to output spikes. Theorem 2 (the selectron is the fast time constant limit of SRM + STDP). In the fast time constant limit, lim\u03c4\u2022 \u2192 0, the SRM transforms into a selectron with\nfw(t) = H ( Mw(t)\u2212 \u03d1 ) where Mw = \u2211 {j|tj\u2265tk} wjk \u00b7 \u03b4tk(t).\nMoreover, STDP transforms into learning rule (4) in the unsupervised setting with \u03bd(x) = 1 for all x. Finally, STDP arises as gradient ascent on a reward function whose limit is the unsupervised setting of reward function (2).\nTheorem 2 shows that STDP implicitly maximizes a time-discounted analog of the reward function in (3). We expect many models of reward-modulated synaptic plasticity to be analytically tractable in the fast time constant limit. An important property shared by STDP and the selectron is that synaptic (de)potentiation is gated by output spikes, see \u00a7A.1 for a comparison with the perceptron which does not gate synaptic learning"}, {"heading": "4 An error bound", "text": "Maximizing reward function (3) implies that selectrons encode reward estimates into their spikes. Indeed, it recursively justifies incorporating spikes into the reward function via the margin (w\u1d40x\u2212 \u03d1), which only makes sense if upstream spikes predict reward. However, in a large system where estimates pile on top of each other there is a tendency to overfit, leading to poor generalizations [21]. It is therefore crucial to provide guarantees on the quality of spikes as estimators.\nBoosting algorithms, where the outputs of many weak learners are aggregated into a classifier [22], are remarkably resistant to overfitting as the number of learners increases [23]. Cortical learning may be analogous to boosting: individual neurons have access to a tiny fraction of the total brain state, and so are weak learners; and in the fast time constant limit, neurons are essentially aggregators.\nWe sharpen the analogy using the selectron. As a first step towards understanding how the cortex combats overfitting, we adapt a theorem developed to explain the effectiveness of boosting [24]. The goal is to show how the margin and constraint on synaptic weights improve error bounds.\nDefinition 2. A selectron incurs a 0/1 loss if a spike is followed by negative neuromodulatory feedback\nl(x, fw, \u03bd) = 1\u2212fw(x)\u00b7\u03bd(x) = { 1 if y = 1 and \u03bd(x) = \u22121 0 else.\n(6)\nThe 0/1 loss fails to take the estimates (spikes) of other selectrons into account and is difficult to optimize, so we also introduce the hinge loss:\nh\u03ba(x, fw, \u03bd) := ( \u03ba\u2212 (w\u1d40x\u2212 \u03d1) \u00b7 \u03bd(x) ) + \u00b7 fw(x), where (x)+ := { x if x \u2265 0 0 else.\n(7)\nNote that l \u2264 h\u03ba for all \u03ba \u2265 1. Parameter \u03ba controls the saturation point, beyond which the size of the margin makes no difference to h\u03ba.\nAn alternate 0/1 loss2 penalizes a selectron if it (i) fires when it shouldn\u2019t, i.e. when \u03bd(x) = \u22121 or (ii) does not fire when it should, i.e. when \u03bd(x) = 1. However, since the cortex contains many neurons and spiking is metabolically expensive [25], we propose a conservative loss that only penalizes errors of commission (\u201cfirst, do no harm\u201d) and does not penalize specialization.\nTheorem 3 (spike error bound). Suppose each selectron has \u2264 N synapses. For any selectron nk, let Sk = {nk} \u222a {nj : nj \u2192 nk} denote a 2-layer feedforward subnetwork. For all \u03ba \u2265 1, with probability at least 1\u2212 \u03b4,\nE [ l(x, fw, \u03bd) ]\ufe38 \ufe37\ufe37 \ufe38 0/1 loss \u2264 1 n \u2211 i h\u03ba ( x(i), fw, \u03bd(x (i)) )\ufe38 \ufe37\ufe37 \ufe38 hinge loss +\u03c9 \u00b7 2B \u00b7 \u221a 8(N + 1) log(n+ 1) + 1\u221a n\ufe38 \ufe37\ufe37 \ufe38\ncapacity term\n+ 2B \u00b7 \u221a 2 log 2\u03b4 n\ufe38 \ufe37\ufe37 \ufe38\nconfidence term\nwhere B = \u03ba+ \u03c9 \u2212 \u03d1.\nRemark 3 (theoretical justification for maximizing margin and constraining \u2016w\u20161). The theorem shows how subsets of distributed systems can avoid overfitting. First, it demonstrates the importance of maximizing the margin (i.e. the empirical reward). Second, it shows the capacity term depends on the number of synapses N and the constraint \u03c9 on synaptic weights, rather than the capacity of Sk \u2013 which can be very large.\nThe hinge loss is difficult to optimize directly since gating with output spikes fw(x) renders it discontinuous. However, in the Bernoulli regime, Theorem 1 implies the bound in Theorem 3 can be rewritten as\nE [ l(x, fw, \u03bd) ] \u2264 p\u03ba\u03c9 2\n\u03d12 \u2212 R\u0302n\n( x(i), fw, \u03bd(x (i)) ) + \u03c9 \u00b7 { capacity term } + { confidence term } (8)\nand so \u03c9 again provides the lever required to control the 0/1 loss. The constraint \u2016w\u20161 \u2264 \u03c9 is best imposed offline, see \u00a76."}, {"heading": "5 A bound on the efficacy of inter-neuronal communication", "text": "Even if a neuron\u2019s spikes perfectly predict positive neuromodulatory signals, the spikes only matter to the extent they affect other neurons in cortex. Spikes are produced for neurons by neurons. It is therefore crucial to provide guarantees on the usefulness of spikes.\nIn this section we quantify the effect of one selectron\u2019s spikes on another selectron\u2019s expected reward. We demonstrate a lower bound on efficacy and discuss its consequences.\n2See \u00a7A.5 for an error bound.\nDefinition 3. The efficacy of spikes from selectron nj on selectron nk is\n\u03b4Rk \u03b4xj := E[Rk|xj = 1]\u2212 E[Rk|xj = 0] 1\u2212 0 ,\ni.e. the expected contribution of spikes from selectron nj to selectron nk\u2019s expected reward, relative to not spiking. The notation is intended to suggest an analogy with differentiation \u2013 the infinitesimal difference made by spikes on a single synapse.\nEfficacy is zero if E[Rk|xj = 1] = E[Rk|xj = 0]. In other words, if spikes from nj make no difference to the expected reward of nk.\nThe following theorem relies on the assumption that the average contribution of neuromodulators is higher after nj spikes than after it does not spike (i.e. upstream spikes predict reward), see \u00a7A.6 for precise statement. When the assumption is false the synapse wjk should be pruned. Theorem 4 (spike efficacy bound). Let pj := E[Y j ] denote the frequency of spikes from neuron nj . The efficacy of nj\u2019s spikes on nk is lower bounded by\nc2 \u00b7 \u03b4Rk\n\u03b4xj\ufe38\ufe37\ufe37\ufe38 efficacy\n\u2265 wj \u00b7 E[Y jY k]\npj\ufe38 \ufe37\ufe37 \ufe38 wj -weighted co-spike frequency\n+ 2E [ Y jY k \u00b7 ( (w Cj)\u1d40x\u2212 \u03d1 )] pj(1\u2212 pj)\ufe38 \ufe37\ufe37 \ufe38\nco-spike frequency\n\u2212 E [ Y k \u00b7 ( (w Cj)\u1d40x\u2212 \u03d1 )] 1\u2212 pj\ufe38 \ufe37\ufe37 \ufe38\nnk spike frequency\n(9)\nwhere c2 is described in \u00a7A.6 and w Cji := wi if i 6= j and 0 if i = j.\nThe efficacy guarantee is interpreted as follows. First, the guarantee improves as co-spiking by nj and nk increases. However, the denominators imply that increasing the frequency of nj\u2019s spikes worsens the guarantee, insofar as nj is not correlated with nk. Similarly, from the third term, increasing nk\u2019s spikes worsens the guarantee if they do not correlate with nj .\nAn immediate corollary of Theorem 4 is that Hebbian learning rules, such as STDP and the selectron learning rule (4), improve the efficacy of spikes. However, it also shows that naively increasing the frequency of spikes carries a cost. Neurons therefore face a tradeoff. In fact, in the Bernoulli regime, Theorem 1 implies (9) can be rewritten as\nc2 \u00b7 \u03b4Rk \u03b4xj \u2265 wj p \u00b7 E[Y jY k] + 2 p(1\u2212 p) E [ Y jY k \u00b7 ( (w Cj)\u1d40x\u2212 \u03d1 )] \u2212 p \u00b7 \u03c9 2 \u00b7 (\u03c9 \u2212 \u03d1) (1\u2212 p)\u03d12 , (10)\nso the constraint \u03c9 on synaptic strength can be used as a lever to improve guarantees on efficacy. Remark 4 (efficacy improved by pruning weak synapses). The 1st term in (9) suggests that pruning weak synapses increases the efficacy of spikes, and so may aid learning in populations of selectrons or neurons."}, {"heading": "6 Experiments", "text": "Cortical neurons are constantly exposed to different input patterns as organisms engage in different activities. It is therefore important that what neurons learn is robust to changing inputs [26, 27]. In this section, as proof of principle, we investigate a simple tweak of classical STDP involving offline regularization. We show that it improves robustness when neurons are exposed to more than one pattern.\nObserve that regularizing optimization problem (3) yields\nmaximize: w n\u2211 i=1 R ( x(i), fw, \u03bd(x (i)) ) \u2212 \u03b3 2 (\u2016w\u20161 \u2212 \u03c9)2 (11)\nlearning rule: \u2206wj = \u03b1 \u00b7 \u03bd(x) \u00b7 xj \u00b7 fw(x)\u2212 \u03b3 \u00b7 ( \u2016w\u20161 \u2212 \u03c9 ) \u00b7wj (12)\nincorporates synaptic renormalization directly into the update. However, (12) requires continuously re-evaluating the sum of synaptic weights. We therefore decouple learning into an online reward maximization phase and an offline regularization phase which resets the synaptic weights.\nA similar decoupling may occur in cortex. It has recently been proposed that a function of NREM sleep may be to regulate synaptic weights [28]. Indeed, neurophysiological evidence suggests that average cortical firing rates increase during wakefulness and decrease during sleep, possibly reflecting synaptic strengths [29, 30]. Experimental evidence also points to a net increase in dendritic spines (synapses) during waking and a net decrease during sleep [31].\nSetup. We trained a neuron on a random input pattern for 10s to 87% accuracy with regularized STDP. See \u00a7A.7 for details on the structure of inputs. We then performed 700 trials (350 classical and 350 regularized) exposing the neuron to a new pattern for 20 seconds and observed performance under classical and regularized STDP.\nSRM neurons with classical STDP. We used Gerstner\u2019s SRM model, recall \u00a73, with parameters chosen to exactly coincide with [32]: \u03c4m = 10, \u03c4s = 2.5, K = 2.2, K1 = 2, K2 = 4 and \u03d1 = 14#synapses. STDP was implemented via (5) with parameters \u03b1+ = 0.03125, \u03c4+ = 16.8, \u03b1\u2212 = 0.85\u03b1+ and \u03c4\u2212 = 33.7 also taken from [32]. Synaptic weights were clipped to fall in [0, 1].\nRegularized STDP consists of a small tweak of classical STDP in the online phase, and an additional offline regularization phase:\n\u2022 Online. In the online phase, reduce the depotentiation bias from 0.85\u03b1+ in the classical implementation to \u03b1\u2212 = 0.75\u03b1+.\n\u2022 Offline. In the offline phase, modify synapses once per second according to\n\u2206wj =\n{ \u03b3 \u00b7 ( 3 2 \u2212wj ) \u00b7 (\u03c9 \u2212 s) if \u03c9 < s\n\u03b3 \u00b7 (\u03c9 \u2212 s) else, (13)\nwhere s is output spikes per second, \u03c9 = 5Hz is the target rate and update factor \u03b3 = 0.6. The offline update rule is firing rate, and not spike, dependent.\nClassical STDP has a depotentiation bias to prevent runaway potentiation feedback loops leading to seizures [5]. Since synapses are frequently renormalized offline we incorporate a weak exploratory (potentiation) bias during the online phase which helps avoid local minima.3 This is in line with experimental evidence showing increased cortical activity during waking [30].\nSince computing the sum of synaptic weights is non-physiological, we draw on Theorem 1 and use the neuron\u2019s firing rate when responding to uncorrelated inputs as a proxy for \u2016w\u20161. Thus, in the offline phase, synapses receive inputs generated as in the online phase but without repeated patterns. Note that (12) has a larger pruning effect on stronger synapses, discouraging specialization. Motivated by Remark 4, we introduce bias ( 32 \u2212wj) in the offline phase to ensure weaker synapses are downscaled more than strong synapses. For example, a synapse with wi = 0.5 is downscaled by twice as much as a synapse with weight wj = 1.0.\nRegularized STDP alternates between 2 seconds online and 4 seconds offline, which suffices to renormalize synaptic strengths. The frequency of the offline phase could be reduced by decreasing the update factors \u03b1\u00b1, presenting stimuli less frequently (than 7 times per second), or adding inhibitory neurons to the system.\nResults. A summary of results is presented in the table below: accuracy quantifies the fraction of spikes that co-occur with each pattern. Regularized STDP outperforms classical STDP on both patterns on average. It should be noted that regularized neurons were not only online for 20 seconds but also offline \u2013 and exposed to Poisson noise \u2013 for 40 seconds. Interestingly, exposure to Poisson noise improves performance.\nAlgorithm Accuracy Pattern 1 Pattern 2\nClassical 54% 39%\nRegularized 59% 48%\n3The input stream contains a repeated pattern, so there is a potentiation bias in practice even though the net integral of STDP in the online phase is negative.\nFig. 1 provides a more detailed analysis. Each panel shows a 2D-histogram (darker shades of gray correspond to more trials) plotting accuracies on both patterns simultaneously, and two 1D histograms plotting accuracies on the two patterns separately. The 1D histogram for regularized STDP shows a unimodal distribution for pattern #2, with most of the mass over accuracies of 50-90%. For pattern #1, which has been \u201cunlearned\u201d for twice as long as the training period, most of the mass is over accuracies of 50% to 90%, with a significant fraction \u201cunlearnt\u201d. By contrast, classical STDP exhibits extremely brittle behavior. It completely unlearns the original pattern in about half the trials, and also fails to learn the new pattern in most of the trials.\nThus, as suggested by our analysis, introducing a regularization both improves the robustness of STDP and enables an exploratory bias by preventing runaway feedback leading to epileptic seizures."}, {"heading": "7 Discussion", "text": "The selectron provides a bridge between a particular model of spiking neurons \u2013 the Spike Response Model [20] with the original spike-timing dependent plasticity rule [5] \u2013 and models that are amenable to learning-theoretic analysis. Our hope is that the selectron and related models lead to an improved understanding of the principles underlying learning in cortex. It remains to be seen whether other STDP-based models also have tractable discrete-time analogs.\nThe selectron is an interesting model in its own right: it embeds reward estimates into spikes and maximizes a margin that improves error bounds. It imposes a constraint on synaptic weights that: concentrates rewards/spike, tightens error bounds and improves guarantees on spiking efficacy. Although the analysis does not apply directly to continuous-time models, experiments show that a tweak inspired by our analysis improves the performance of a more realistic model. An important avenue for future research is investigating the role of feedback in cortex, specifically NMDA synapses, which may have interesting learning-theoretic implications.\nAcknowledgements. We thank Timothe\u0301e Masquelier for generously sharing his source code [32] and Samory Kpotufe for useful discussions."}, {"heading": "Appendices", "text": ""}, {"heading": "A.1 The perceptron", "text": "We describe the perceptron to facilitate comparison with the selectron.\nThe perceptron\u2019s loss function and learning rule are most naturally expressed when inputs and outputs take values in {\u00b11}. We therefore present the perceptron in both \u00b11 and 0/1 \u201ccoordinate systems\u201d.\nLet us first relabel inputs and outputs from 0/1 to \u00b11: A = 2X\u2212 1 and B = 2Y \u2212 1. Given input a, the perceptron\u2019s output is determined according to\nb = \u03c1w(a) := sign (w\u1d40a) ,\nwhere w is a real-valued N -vector specifying the perceptron\u2019s synaptic weights.\nGiven supervisor \u03c3 : A \u2192 {\u00b11} that labels inputs as belonging to one of two classes, define 0/1-valued loss function for the perceptron as\nlp(a, \u03c1w, \u03c3) := 1\u2212\u03c1w\u00b7\u03c3(a) = { 0 if \u03c1w(a) = \u03c3(a) 1 else.\nThe following learning rule\n\u2206wj = \u03b1 \u00b7 aj \u00b7 ( \u03c3(a)\u2212 \u03c1w(a) ) = \u03b1 \u00b7  aj if \u03c3(a) = 1, \u03c1w(a) = \u22121 \u2212aj if \u03c3(a) = \u22121, \u03c1w(a) = 1 0 else\nconverges onto an optimal solution if the classes are linearly separable.\nThe perceptron in \u201c0/1 coordinates\u201d. For the sake of comparison, we reformulate the perceptron in \u201c0/1 coordinates\u201d. If wj \u2265 0 for all j, the mechanism of the perceptron is\ny = fw(x) := H\n( w\u1d40x\u2212 \u2016w\u20161\n2\n) . (A.14)\nSimilarly, we obtain loss function\nlp(x, fw, \u03c3) := 1\u2212(2fw(x)\u22121)\u00b7\u03c3(x) = { 0 if x = 1, \u03c3(x) = 1 or x = 0, \u03c3(x) = \u22121 1 else\nand learning rule\n\u2206wj = \u03b1 \u00b7 (2xj \u2212 1) \u00b7 ( \u03c3(x)\u2212 2fw(x) + 1 ) = \u03b1 \u00b7  aj if \u03c3(a) = 1, \u03c1w(a) = \u22121 \u2212aj if \u03c3(a) = \u22121, \u03c1w(a) = 1 0 else. (A.15)\nNon-biological features of the perceptron. We highlight two features of the perceptron. First, learning rule (A.15) is not selective. If the perceptron classifies an input incorrectly, it updates its synaptic weights regardless of whether it outputted a 0 or a 1. It is thus not an output spike-dependent learning rule. The main consequence of this is that the perceptron is forced to classify every input. The selectron, by contrast, actively ignores neuromodulatory signals when it does not spike.\nSecond, the perceptron requires a local error signal. Multilayer perceptrons are constructed by replacing the sign(\u2022) in (A.14) with a differentiable function, such as the sigmoid, and backpropagating errors. However, backpropagation requires two pathways: one for feedforward spikes and another for feedback errors. In other words, the perceptron requires local error signals. A dedicated error pathway is biologically implausible [33], suggesting that the cortex relies on alternate mechanisms."}, {"heading": "A.2 Proof of Theorem 1", "text": "The theorem requires computing the second moment of a selectron\u2019s total current, given i.i.d. Bernoulli inputs. We also compute the expectation and the variance since these are of intrinsic interest.\nLemma 5 (moments for i.i.d. Bernoulli inputs). For Bernoulli i.i.d. inputs on synapses, i.e. P (xj = 0) = p for all j, we have\nE[\u3008w,x\u3009 \u2212 \u03d1] = p \u00b7 \u2016w\u20161 \u2212 \u03d1 V[\u3008w,x\u3009 \u2212 \u03d1] = p(1\u2212 p) \u00b7 \u2016w\u201622\nE[\u3008w,x\u30092] = p(1\u2212 p) \u00b7 \u2016w\u201622 + p2 \u00b7 \u2016w\u201621.\nProof. For the mean,\nE [ \u3008w,x\u3009 ] = \u2211 x\u2208X P (x1) \u00b7 \u00b7 \u00b7P (xn) \u00b7  n\u2211 j=1 wj \u00b7 xj  =\nn\u2211 j=1 P (xj = 1) \u00b7wj = n\u2211 j=1 p \u00b7wj = p \u00b7 \u2016w\u20161,\nsince wj \u2265 0 for all j. For the variance,\nV [ \u3008w,x\u3009 ] = \u2211 x\u2208X P (x)\u3008w,x\u30092 \u2212 p2 \u00b7 \u2016w\u201621\n= \u2211 i 6=j p2 \u00b7wiwj + \u2211 j p \u00b7w2j \u2212 \u2211 j p2 \u00b7w2j + \u2211 i 6=j p2 \u00b7wiwj  = p(1\u2212 p) \u00b7 \u2016w\u201622.\nThe expression for E[\u3008w,x\u30092] follows immediately.\nTheorem 1. Assuming the inputs on each synapse are i.i.d. Bernoulli variables with P (spike) = p, we have\nP ( fw(x) = 1 ) \u2264 p \u00b7 ( \u2016w\u20161 \u03d1 )2 .\nProof. By Lemma 5, E\u3008w,x\u30092 = p(1 \u2212 p) \u00b7 \u2016w\u201622 + p2 \u00b7 \u2016w\u201621. Applying Chebyshev\u2019s equality, P (|X| > ) \u2264 EX 2 2 , obtains\nP ( fw(x) = 1 ) = P ( \u3008w,x\u3009 > \u03d1 ) \u2264 p(1\u2212 p) \u00b7 \u2016w\u2016 2 2 + p\n2 \u00b7 \u2016w\u201621 \u03d12 .\nThe result follows since \u2016w\u20162 \u2264 \u2016w\u20161."}, {"heading": "A.3 Proof of Theorem 2", "text": "We first compute the limit for STDP, and then move on to leaky integrate-and-fire neurons.\nLemma 6 (fast time constant limit of STDP). The fast time constant limit of STDP, recall (5), is\nlim \u03c4\u2022\u21920\n\u2206wjk = (\u03b1+ \u2212 \u03b1\u2212) \u00b7 \u03b40(\u2206t)\nwhere \u03b40 is the Dirac delta.\nProof. We start from the STDP curve:\n\u2206wjk := \u03b1+ \u03c4+ exp ( tj \u2212 tk \u03c4+ ) H(tk \u2212 tj)\u2212 \u03b1\u2212 \u03c4\u2212 exp ( tk \u2212 tj \u03c4\u2212 ) H(tj \u2212 tk)\n= \u03b1+ \u03c4+ exp ( \u2212\u2206t \u03c4+ ) H(\u2206t)\u2212 \u03b1\u2212 \u03c4\u2212 exp ( \u2206t \u03c4\u2212 ) H(\u2212\u2206t)\nwhere H is the Heaviside function. Note that we divide by \u03c4\u00b1 to ensure that the area is constant as \u03c4\u00b1 \u2192 0. An equivalent approach is to rescale \u03b1 and \u03c4 proportionately, so that both tend to zero. Let us now compute the limit, in the sense of distributions, as \u03c4\u00b1 \u2192 0. Let f be a test function in the Schwartz space. The linear form associated to\nS+(\u2206t) = \u03b1+ \u03c4+ exp ( \u2212\u2206t \u03c4+ ) H(\u2206t)\nis S+ : f(x) 7\u2192 \u222b S+(x)f(x)dx.\nThus,\nS+(f) = \u222b \u03b1+ \u03c4+ exp ( \u2212x \u03c4+ ) H(x)f(x)dx.\nIntegrating by parts obtains S+(f) = [ \u2212\u03b1+ exp ( \u2212x \u03c4+ ) f(x) ]\u221e 0 \u2212 \u222b \u221e 0 \u2212\u03b1+ exp ( \u2212x \u03c4+ ) f \u2032(x)dx so that S+(f) = \u03b1+ \u00b7 f(0) + \u03c4+ \u00b7 S+(f \u2032) and lim\u03c4+\u21920 [S+(f)] = \u03b1+ \u00b7 f(0) = \u03b1+ \u00b7 \u03b40(f). A similar argument holds for the negative part of the STDP curve, so the fast time constant limit is\n\u2206wjk = (\u03b1+ \u2212 \u03b1\u2212) \u00b7 \u03b40(\u2206t).\nRemark 5. If STDP incorporates a potentiation bias (in the sense that the net integral is positive [5]), then the fast time constant limit acts exclusively by potentiation.\nTheorem 2. In the fast time constant limit, lim\u03c4\u2022 \u2192 0, the SRM transforms into a selectron with fw(t) = H ( Mw(t)\u2212 \u03d1 ) where Mw = \u2211 {j|tj\u2265tk} wjk \u00b7 \u03b4tk(t).\nMoreover, STDP transforms into learning rule (4) in the unsupervised setting with \u03bd(x) = 1 for all x. Finally, STDP arises as gradient ascent on a reward function whose limit is the unsupervised setting of reward function (2).\nProof. Setting K1 = K2 = 0, \u03c4s = 12\u03c4m, 1 K = e \u22121 \u2212 e\u22122, and taking the limit \u03c4m \u2192 0 yields Mw(t) = \u2211\n{j|tj\u2265tk}\nwjk \u00b7 \u03b4tk(t).\nBy Lemma 6, taking limits \u03c4\u00b1 \u2192 0 transforms STDP into\n\u2206wjk = { (\u03b1+ \u2212 \u03b1\u2212) if tk = tj 0 else,\nwhich is a special case of the online learning rule for the selectron derived in \u00a72, where the neuromodulatory response is \u03bd(x) = 1 for all x.\nSTDP is easily seen to arise as gradient ascent on\narg max w \u2211 tk  \u2211 tk\u22121<tj\u2264tk wj \u00b7 e ( tj\u2212tk \u03c4+ ) \u2212 \u2211 tk<tj<tk+1 wj \u00b7 e ( tk\u2212tj \u03c4\u2212 ) . (A.16) Taking the limit of (A.16) yields the special case of (2) where \u03bd(x) = 1 for all x.\nEq. (A.16) can be expressed in the shorthand\narg max w [\u2211 tk ( w\u1d40 \u00b7 d(tk) ) \u00b7 fw(tk) ] , where dj(t) = e ( tj\u2212t \u03c4+ ) if tj \u2264 t \u2212e ( t\u2212tj \u03c4\u2212 ) else ."}, {"heading": "A.4 Proof of Theorem 3", "text": "To prove the theorem, we first recall an error bound from [24]. To state their result, we need the following notation. Let\nC\u03c9 = f(x) = sign  N\u2211 j=1 aj \u00b7 gj(x)  \u2223\u2223\u2223\u2223\u2223\u2223 aj \u2208 R, \u2016a\u20161 \u2264 \u03c9 and gj \u2208 C \nwhere C is a class of base classifiers taking values in \u00b11. Let \u03c6 : R \u2192 R+ be a nonnegative cost function such that 1x>0 \u2264 \u03c6(x), for example \u03c6(x) = (1\u2212 x)+. Define\nL(f) = E1\u2212f(X)Y <0 and L\u0302n(f) = 1\nn n\u2211 i=1 1\u2212f(Xi)Yi<0 (A.17)\nand\nA(f) = E\u03c6(\u2212f(X)Y ) and A\u0302n(f) = 1\nn n\u2211 i=1 \u03c6(\u2212f(Xi)Yi). (A.18)\nTheorem 7. Let f be a function chosen from C\u03c9 based on data (Xi, Yi)ni=1. With probability at least 1\u2212 \u03b4,\nL(f) \u2264 A\u0302(fn) + 2L\u03c6 \u00b7 ERadn(C(Xn1 |f = 1)) +B \u221a 2 log 1\u03b4 n , (A.19)\nwhere L\u03c6 is the Lipschitz constant of \u03c6, B is a uniform upper bound on \u03c6(\u2212f(x)y), and Rad ( C(Xn1 ) ) is the Rademacher complexity of C on data Xn1 .\nProof. See \u00a74.1 of [24].\nWe are interested in errors of commission, not omission, so we consider modified versions of (A.17),\nL(f) = E [ 1\u2212f(X)Y <0 \u00b7 1f>0 ] and L\u0302n(f) = 1\nn n\u2211 i=1 [ 1\u2212f(X)Y <0 \u00b7 1f>0 ] , (A.20)\nand (A.18),\nA(f) = E [\u03c6(\u2212f(X)Y ) \u00b7 1f>0] and A\u0302n(f) = 1\nn n\u2211 i=1 [\u03c6(\u2212f(Xi)Yi) \u00b7 1f>0] . (A.21)\nwhere we multiply by the indicator function 1f>0. This results in a discontinuous hinge function. We therefore have to modify the above theorem.\nTheorem 8. Let f be a function chosen from C\u03c9 based on data (Xi, Yi)ni=1. With probability at least 1\u2212 \u03b4,\nL(f) \u2264 A\u0302n(f) + 2(E[1f ] \u00b7 L\u03c6 +B) \u00b7 ERadn(C(Xn1 |f = 1)) + 2B \u221a 2 log 2\u03b4 n ,\nwhere L\u03c6 is the Lipschitz constant of \u03c6, B is a uniform upper bound on \u03c6(\u2212f(x)y), and Rad ( C(Xn1 ) ) is the Rademacher complexity of C on data Xn1 .\nProof. We adapt the proof in [24]. By definition it follows that\nL(f) \u2264 A(f) = A\u0302n(f) +A(f)\u2212 A\u0302n(f)\nNow observe that \u2211 x [p(x)f(x)1S ] = \u2211 x\u2208S p(x)f(x) = p(S) \u2211 x q(x)f(x), where q(x) := p(x|x \u2208 A). Thus, changing distributions from P (x) to Q(x) = P (x|f = 1), we can write\nL(f) \u2264 A\u0302n(f) + P (f = 1) \u00b7 EQ[\u03c6(\u2212f(X)Y )]\u2212 P\u0302n(f = 1) \u00b7 \u2211 {i:f(xi=1} \u03c6(\u2212f(xi)yi) |{i : f(xi = 1}|  = A\u0302n(f) + P (f = 1) \u00b7 [ AQ(f)\u2212 A\u0302Q\u0302n(f) ] + A\u0302Q\u0302n(f) \u00b7 [ EP f \u2212 EP\u0302nf\n] where P\u0302n(xi) = 1n is the empirical distribution, P\u0302n(f = 1) = |{i:f(xi=1}| n and Q\u0302n(xi) = 1 |{i:f(xi=1}| .\nContinuing,\nL(f) \u2264 A\u0302n(f) + EP [1f ] \u00b7 sup g\u2208C\n[ AQ(g)\u2212 A\u0302Q\u0302n(g) ] + A\u0302Q\u0302n(f) \u00b7 sup\ng\u2208C\n[ EP g \u2212 EP\u0302ng ] \u2264 A\u0302n(f) + 2E[1f ] \u00b7 L\u03c6 \u00b7 ERadn(C(Xn1 |f = 1))\n+ 2A\u0302Q\u0302n \u00b7 ERadn(C(X n 1 |f = 1)) + 2B \u221a 2 log 2\u03b4 n\n\u2264 A\u0302n(f) + 2(E[1f ] \u00b7 L\u03c6 +B) \u00b7 ERadn(C(Xn1 |f = 1)) + 2B \u221a 2 log 2\u03b4 n\nwhere we bound the two supremum\u2019s with high probability separately using Rademacher complexity and apply the union bound. The last inequality follows since \u03c6 \u2264 B.\nRemark 6. The change of distribution is not important, since the Rademacher complexity is bounded by the distribution free VC-dimension in Lemma 9.\nTo recover the setting of Theorem 3, we specialize to \u03c6\u03ba(f) = (\u03ba \u2212 f(X)Y )+, for \u03ba \u2265 1, so that the hinge loss can be written as h\u03ba = \u03c6\u03ba ( w\u1d40x\u2212 \u03d1 ) \u00b7 1f(X)>0. The Lipschitz constant is L\u03c6 = 1.\nNow let\nF\u03c9 = f(x) = H  N\u2211 j=1 wj \u00b7 gj(x)\u2212 \u03d1  \u2223\u2223\u2223\u2223\u2223\u2223 \u2016w\u20161 \u2264 \u03c9 and gj \u2208 F  ,\nwhere functions in F take values in 0/1. Function class F\u03c9 denotes functions implementable by a two-layer network of selectrons Sk = {nk} \u222a {nj : nj \u2192 nk}. The outputs of gj are aggregated, so that the function class F\u03c9 of subnetwork Sk is larger than that of selectrons considered individually, i.e. F . Lemma 9. The Rademacher complexity of F\u03c9 is upper bounded by\nRadn(F\u03c9) \u2264 \u03c9 \u00b7 \u221a\n2(N + 1) log(n+ 1) + 12\u221a n .\nProof. Given selectron fw(x) = \u2211 j wj \u00b7 gjw(x), let g\u0304j := 2gj \u2212 1 be the corresponding {\u00b11}- valued function. Then N\u2211 j=1 wjg j(x)\u2212 \u03d1 = 1 2 N\u2211 j=1 wj(g\u0304 j(x) + 1)\u2212 \u03d1 = 1 2 \u2016w\u20161 \u2212 \u03d1+ 1 2 N\u2211 j=1 wj g\u0304 j(x),\nsince wi \u2265 0 for all i. Thus, Radn(F\u03c9) \u2264 \u2223\u2223 1 2\u03c9 \u2212 \u03d1 \u2223\u2223 \u221a n + \u03c9 \u00b7 Radn(F).\nThe Rademacher complexity of F is upper bounded by the VC-dimension, Rad(F(Xn1 )) \u2264 \u221a\n2VF \u00b7 log(n+ 1) n\nwhich for a selectron with N synapses is at most N + 1.\nFinally, note that if \u03d1 < 0 then the selectron always spikes, and if \u03d1 > \u2016w\u20161 then it never spikes. We therefore assume that 0 \u2264 \u03d1 \u2264 \u03c9, which implies |2\u03d1\u2212 \u03c9| \u2264 \u03c9 and so\u2223\u2223 1 2\u03c9 \u2212 \u03d1 \u2223\u2223\n\u221a n\n\u2264 \u03c9 2 \u221a n .\nTheorem 3. Suppose each selectron has \u2264 N synapses. For any selectron nk, let Sk = {nk} \u222a {nj : nj \u2192 nk} denote a 2-layer feedforward subnetwork. For all \u03ba \u2265 1, with probability at least 1\u2212 \u03b4,\nE [ l(x, fw, \u03bd) ]\ufe38 \ufe37\ufe37 \ufe38 0/1 loss \u2264 1 n \u2211 i h\u03ba ( x(i), fw, \u03bd(x (i)) )\ufe38 \ufe37\ufe37 \ufe38 hinge loss +\u03c9 \u00b7 2B \u00b7 \u221a 8(N + 1) log(n+ 1) + 1\u221a n\ufe38 \ufe37\ufe37 \ufe38\ncapacity term\n+B \u00b7 \u221a 2 log 2\u03b4 n\ufe38 \ufe37\ufe37 \ufe38\nconfidence term\nwhere B = \u03ba+ \u03c9 \u2212 \u03d1.\nProof. Applying Theorem 8, Lemma 9, and noting that E[1f ] \u2264 1 \u2264 B = \u03ba + \u03c9 \u2212 \u03d1, where B is an upper bound on the hinge loss, obtains the result.\nA.5 An alternate error bound with hard margins\nFor the sake of completeness, we prove Corollary 11, an alternate to Theorem 3 that bounds a symmetric 0/1 loss:\n1(2fw(x)\u22121)\u00b7\u03bd(x)<0 =  1 if fw(x) = 1, \u03bd(x) = \u22121 1 if fw(x) = 0, \u03bd(x) = 1 0 else.\nThe loss penalizes the selectron when either (i) it fires when it shouldn\u2019t or (ii) it doesn\u2019t fire when it should.\nWe replace the modified hinge loss in Theorem 3 with a hard-margin loss. Following [24], let\nL\u0302\u03b3n(f) = 1\nn n\u2211 i=1 1f(Xi)Yi<\u03b3 and \u03c6 \u03b3(x) =  0 if x \u2264 \u2212\u03b3 1 if x \u2265 0 1 + x/\u03b3 else.\nThe following corollary of Theorem 7 is shown in [24]. Corollary 10. Let fn be a function chosen from C\u03c9 . For any \u03b3 > 0, with probability at least 1\u2212 \u03b4,\nL(fn) \u2264 L\u0302\u03b3n(fn) + \u03c9\n\u03b3\n\u221a 2VC log(n+ 1)\nn + \u221a 2 log 1\u03b4 n .\nwhere VC is the VC-dimension of C.\nWe use Corollary 10 to derive an alternate error bound for the selectron. Introduce hard-margin loss\n1( w\u1d40x\u2212\u03d1 ) \u00b7\u03bd(x)<\u03b3 = { 1 if sign(w\u1d40x\u2212 \u03d1) = sign(\u03bd(x)) and |w\u1d40x\u2212 \u03d1| > \u03b3 0 else\nThe following error bound exhibits a trade-off on the 0/1 loss of a selectron that is controlled by \u03b3.\nCorollary 11 (error bound with hard margins). For any \u03b3 > 0, with probability at least 1\u2212 \u03b4,\nE1(2fw(x)\u22121)\u00b7\u03bd(x)<0 \u2264 1\nn \u2211 i 1( w\u1d40x(i)\u2212\u03d1 ) \u00b7\u03bd(x(i))<\u03b3 + \u03c9 \u03b3 \u00b7 \u221a 8(N + 1) log(n+ 1) + 1\u221a n + \u221a 2 log 1\u03b4 n .\nProof. Follows from Lemma 9 and Corollary 10.\nAs \u03b3 increases, the size of the margin required to avoid counting towards a loss increases. However, the capacity term is multiplied by 1\u03b3 , and so reduces as the size of \u03b3 increases.\nThus, the larger the margin, on average, the higher the value we can choose for \u03b3 without incurring a penalty, and the better the bound in Corollary 11."}, {"heading": "A.6 Proof of Theorem 4", "text": "It is helpful to introduce some notation. Given x \u2208 X, let Sja = {x|xj = a}. Let \u03bdjk=11, defined by equation\n\u03bdjk=11 \u00b7 \u2211 x\u2208Sj1 P (x|xj = 1)(w\u1d40x\u2212 \u03d1)fw(x)  = \u2211 x\u2208Sj1 P (x|xj = 1)\u03bd(x)(w\u1d40x\u2212 \u03d1)fw(x),\nquantify the average contribution of neuromodulators when selectrons nj and nk both spike. Similarly, let \u03bdjk=01 quantify the average contribution of neuromodulators when nk spikes and nj does not, i.e. the sum over x \u2208 Sj0 . If upstream neurons are reward maximizers then spikes by nj should predict higher neuromodulatory rewards, on average, than not firing. We therefore assume\n\u03bdjk=11 \u2265 \u03bdj=10. (*)\nTheorem 4 Let pj := E[Y j ] denote the frequency of spikes from neuron nj . Under assumption (*), the efficacy of nj\u2019s spikes on nk is lower bounded by\n1 \u03bdjk=11 \u00b7 \u03b4R\nk \u03b4xj \u2265 wj \u00b7 E[Y jY k] pj +\n2E [ Y jY k \u00b7 ( (w Cj)\u1d40x\u2212 \u03d1 )] pj(1\u2212 pj) \u2212 E [ Y k \u00b7 ( (w Cj)\u1d40x\u2212 \u03d1 )] 1\u2212 pj\nwhere\nw Cji := { wi if i 6= j 0 else.\nProof.\n\u03b4Rk \u03b4xj = E[Rk|xj = 1]\u2212 E[Rk|xj = 0]\n= \u2211 x\u2208Sj1 P (x|xj = 1)\u03bd(x)(w\u1d40x\u2212 \u03d1)fw(x)\u2212 \u2211 x\u2208Sj0 P (x|xj = 0)\u03bd(x)(w\u1d40x\u2212 \u03d1)fw(x)\n= \u03bdjk=11 \u00b7 \u2211 x\u2208Sj1 P (x|xj = 1)(w\u1d40x\u2212 \u03d1)fw(x)\u2212 \u03bdjk=01 \u00b7 \u2211 x\u2208Sj0 P (x|xj = 0)(w\u1d40x\u2212 \u03d1)fw(x).\nAssumption (*) implies\n1 \u03bdjk=11 \u00b7 \u03b4R\nk \u03b4xj \u2265 \u2211 x\u2208Sj1 P (x|xj = 1)(w\u1d40x\u2212 \u03d1)fw(x)\u2212 \u2211 x\u2208Sj0 P (x|xj = 0)(w\u1d40x\u2212 \u03d1)fw(x)\n= \u2211 x\u2208Sj1 P (x) P (xj = 1) (w\u1d40x\u2212 \u03d1)fw(x)\u2212 \u2211 x\u2208Sj0 P (x) P (xj = 0) (w\u1d40x\u2212 \u03d1)fw(x)\n= 1 pj E [ Y jY k \u00b7 (w\u1d40x\u2212 \u03d1) ] \u2212 1 1\u2212 pj E [ (1\u2212 Y j)Y k \u00b7 (w\u1d40x\u2212 \u03d1) ]\nThe result follows by direct computation.\nA.7 Generation of Poisson spike trains\nSpike trains are generated following [32]. Neurons have 200 synaptic inputs. Time is discretized into 1ms bins. At each time step spikes are generated according to a Poisson process where the rate varies as follows:\n1. a synapse has probability r \u00b7 dt of emitting a spike where r is clipped in [0, 90]Hz. 2. dr = s \u00b7 dt where s is clipped in [\u22121800, 1800]Hz. 3. the rate of change ds of s is uniformly picked from [\u2212360, 360]Hz.\nThe resulting spike train has an average firing rate of about 44Hz. Masquelier et al also add a mechanism to ensure each synapse transmits a spike after at most 50mswhich we do not implement.\nRepeated patterns are sampled from the process above for 50ms. The pattern is then cut-and-paste over the original Poisson spike train for 13 of the total number of 50ms blocks. The cut-and-pasting is imposed on a randomly chosen (but fixed) subset containing 12 of the neuron\u2019s synapses."}], "references": [{"title": "A free energy principle for the brain", "author": ["K Friston", "J Kilner", "L Harrison"], "venue": "J. Phys. Paris", "citeRegEx": "1", "shortCiteRegEx": "1", "year": 2006}, {"title": "The perceptron: a probabilistic model for information storage and organization in the brain", "author": ["F Rosenblatt"], "venue": "Psychol Rev", "citeRegEx": "2", "shortCiteRegEx": "2", "year": 1958}, {"title": "Learning representations by back-propagating errors", "author": ["DE Rumelhart", "GE Hinton", "RJ Williams"], "venue": "Nature", "citeRegEx": "3", "shortCiteRegEx": "3", "year": 1986}, {"title": "A Fast Learning Algorithm for Deep Belief Nets", "author": ["G Hinton", "S Osindero", "YW Teh"], "venue": "Neural Computation", "citeRegEx": "4", "shortCiteRegEx": "4", "year": 2006}, {"title": "Competitive Hebbian learning through spike-timing-dependent synaptic plasticity", "author": ["S Song", "KD Miller", "LF Abbott"], "venue": "Nature Neuroscience", "citeRegEx": "5", "shortCiteRegEx": "5", "year": 2000}, {"title": "Learning in Spiking Neural Networks by Reinforcement of Stochastic Synaptic Transmission", "author": ["HS Seung"], "venue": "Neuron", "citeRegEx": "6", "shortCiteRegEx": "6", "year": 2003}, {"title": "Reducing spike train variability: A computational theory of spike-timing dependent plasticity", "author": ["SM Bohte", "MC Mozer"], "venue": "In Advances in Neural Information Processing Systems (NIPS)", "citeRegEx": "7", "shortCiteRegEx": "7", "year": 2005}, {"title": "A criterion for the convergence of learning with spike timing dependent plasticity", "author": ["R Legenstein", "W Maass"], "venue": "In Advances in Neural Information Processing Systems (NIPS)", "citeRegEx": "8", "shortCiteRegEx": "8", "year": 2006}, {"title": "Simplified rules and theoretical analysis for information bottleneck optimization and PCA with spiking neurons", "author": ["L Buesing", "W Maass"], "venue": "In Adv in Neural Information Processing Systems (NIPS)", "citeRegEx": "9", "shortCiteRegEx": "9", "year": 2007}, {"title": "Theoretical analysis of learning with reward-modulated spiketiming-dependent plasticity", "author": ["R Legenstein", "D Pecevski", "W Maass"], "venue": "In Advances in Neural Information Processing Systems (NIPS)", "citeRegEx": "10", "shortCiteRegEx": "10", "year": 2008}, {"title": "The information bottleneck method", "author": ["N Tishby", "F Pereira", "W Bialek"], "venue": "In Proc. of the 37-th Annual Allerton Conference on Communication, Control and Computing", "citeRegEx": "11", "shortCiteRegEx": "11", "year": 1999}, {"title": "What can neurons do for their brain? Communicate selectivity with spikes", "author": ["D Balduzzi", "G Tononi"], "venue": "To appear in Theory in Biosciences", "citeRegEx": "12", "shortCiteRegEx": "12", "year": 2012}, {"title": "Metabolic cost as an organizing principle for cooperative learning", "author": ["D Balduzzi", "PA Ortega", "M Besserve"], "venue": "Under review,", "citeRegEx": "13", "shortCiteRegEx": "13", "year": 2012}, {"title": "A neuromorphic architecture for object recognition and motion anticipation using burst-STDP", "author": ["A Nere", "U Olcese", "D Balduzzi", "G Tononi"], "venue": "PLoS One 2012,", "citeRegEx": "14", "shortCiteRegEx": "14", "year": 2012}, {"title": "Spike timing-dependent plasticity as dynamic filter", "author": ["J Schmiedt", "C Albers", "K Pawelzik"], "venue": "In Advances in Neural Information Processing Systems (NIPS)", "citeRegEx": "15", "shortCiteRegEx": "15", "year": 2010}, {"title": "Neural Network Learning: Theoretical Foundations", "author": ["M Anthony", "PL Bartlett"], "venue": null, "citeRegEx": "16", "shortCiteRegEx": "16", "year": 1999}, {"title": "RE: Large Margin Classification Using the Perceptron Algorithm", "author": ["Freund Y", "Schapire"], "venue": "Machine Learning", "citeRegEx": "17", "shortCiteRegEx": "17", "year": 1999}, {"title": "Decorrelated neuronal firing in cortical microcircuits", "author": ["AS Ecker", "P Berens", "GA Keliris", "M Bethge", "NK Logothetis", "AS Tolias"], "venue": "Science", "citeRegEx": "18", "shortCiteRegEx": "18", "year": 2010}, {"title": "Spike timing-dependent plasticity of neural circuits", "author": ["Y Dan", "MM Poo"], "venue": "Neuron", "citeRegEx": "19", "shortCiteRegEx": "19", "year": 2004}, {"title": "Time structure of the activity in neural network models", "author": ["W Gerstner"], "venue": "Phys. Rev. E", "citeRegEx": "20", "shortCiteRegEx": "20", "year": 1995}, {"title": "Neural Networks and the Bias/Variance Dilemma", "author": ["S Geman", "E Bienenstock", "R Doursat"], "venue": "Neural Comp", "citeRegEx": "21", "shortCiteRegEx": "21", "year": 1992}, {"title": "RE: Experiments with a New Boosting Algorithm", "author": ["Freund Y", "Schapire"], "venue": "In Machine Learning: Proceedings of the Thirteenth International Conference", "citeRegEx": "22", "shortCiteRegEx": "22", "year": 1996}, {"title": "Boosting the Margin: A New Explanation for the Effectiveness of Voting Methods", "author": ["RE Schapire", "Y Freund", "P Bartlett", "WS Lee"], "venue": "The Annals of Statistics", "citeRegEx": "23", "shortCiteRegEx": "23", "year": 1998}, {"title": "Theory of classification: A survey of some recent advances", "author": ["S Boucheron", "O Bousquet", "G Lugosi"], "venue": "ESAIM: PS", "citeRegEx": "24", "shortCiteRegEx": "24", "year": 2005}, {"title": "Metabolic cost as a unifying principle governing neuronal biophysics", "author": ["A Hasenstaub", "S Otte", "E Callaway", "TJ Sejnowski"], "venue": "Proc Natl Acad Sci U S A", "citeRegEx": "25", "shortCiteRegEx": "25", "year": 2010}, {"title": "Cascade Models of Synaptically Stored Memories", "author": ["S Fusi", "P Drew", "L Abbott"], "venue": "Neuron", "citeRegEx": "26", "shortCiteRegEx": "26", "year": 2005}, {"title": "Limits on the memory storage capacity of bounded synapses", "author": ["S Fusi", "L Abbott"], "venue": "Nature Neuroscience", "citeRegEx": "27", "shortCiteRegEx": "27", "year": 2007}, {"title": "Sleep function and synaptic homeostasis", "author": ["G Tononi", "C Cirelli"], "venue": "Sleep Med Rev", "citeRegEx": "28", "shortCiteRegEx": "28", "year": 2006}, {"title": "Molecular and electrophysiological evidence for net synaptic potentiation in wake and depression in sleep", "author": ["VV Vyazovskiy", "C Cirelli", "M Pfister-Genskow", "U Faraguna", "G Tononi"], "venue": "Nat Neurosci", "citeRegEx": "29", "shortCiteRegEx": "29", "year": 2008}, {"title": "Cortical firing and sleep homeostasis", "author": ["VV Vyazovskiy", "U Olcese", "Y Lazimy", "U Faraguna", "SK Esser", "JC Williams", "C Cirelli", "G Tononi"], "venue": "Neuron", "citeRegEx": "30", "shortCiteRegEx": "30", "year": 2009}, {"title": "Sleep and waking modulate spine turnover in the adolescent mouse cortex", "author": ["S Maret", "U Faraguna", "AB Nelson", "C Cirelli", "G Tononi"], "venue": "Nat Neurosci", "citeRegEx": "31", "shortCiteRegEx": "31", "year": 2011}, {"title": "Unsupervised learning of visual features through spike timing dependent plasticity", "author": ["T Masquelier", "SJ Thorpe"], "venue": "PLoS Comput Biol", "citeRegEx": "32", "shortCiteRegEx": "32", "year": 2007}], "referenceMentions": [{"referenceID": 0, "context": "An elegant suggestion is that global objective functions may be optimized during learning [1].", "startOffset": 90, "endOffset": 93}, {"referenceID": 1, "context": "A successful approach to this question has been Rosenblatt\u2019s perceptron [2] and its extension to multilayer perceptrons via backpropagation [3].", "startOffset": 72, "endOffset": 75}, {"referenceID": 2, "context": "A successful approach to this question has been Rosenblatt\u2019s perceptron [2] and its extension to multilayer perceptrons via backpropagation [3].", "startOffset": 140, "endOffset": 143}, {"referenceID": 3, "context": "Similarly, (restricted) Boltzmann machines, constructed from simple stochastic units, have provided a remarkably powerful approach to organizing distributed optimization across many layers [4].", "startOffset": 189, "endOffset": 192}, {"referenceID": 4, "context": "By contrast, although there has been significant progress in developing and understanding more biologically realistic models of neuronal learning [5\u201310], these do not match the performance of simpler, more analytically and computationally tractable models in learning tasks.", "startOffset": 146, "endOffset": 152}, {"referenceID": 5, "context": "By contrast, although there has been significant progress in developing and understanding more biologically realistic models of neuronal learning [5\u201310], these do not match the performance of simpler, more analytically and computationally tractable models in learning tasks.", "startOffset": 146, "endOffset": 152}, {"referenceID": 6, "context": "By contrast, although there has been significant progress in developing and understanding more biologically realistic models of neuronal learning [5\u201310], these do not match the performance of simpler, more analytically and computationally tractable models in learning tasks.", "startOffset": 146, "endOffset": 152}, {"referenceID": 7, "context": "By contrast, although there has been significant progress in developing and understanding more biologically realistic models of neuronal learning [5\u201310], these do not match the performance of simpler, more analytically and computationally tractable models in learning tasks.", "startOffset": 146, "endOffset": 152}, {"referenceID": 8, "context": "By contrast, although there has been significant progress in developing and understanding more biologically realistic models of neuronal learning [5\u201310], these do not match the performance of simpler, more analytically and computationally tractable models in learning tasks.", "startOffset": 146, "endOffset": 152}, {"referenceID": 9, "context": "By contrast, although there has been significant progress in developing and understanding more biologically realistic models of neuronal learning [5\u201310], these do not match the performance of simpler, more analytically and computationally tractable models in learning tasks.", "startOffset": 146, "endOffset": 152}, {"referenceID": 5, "context": "The work closest in spirit to our own is Seung\u2019s \u201chedonistic\u201d synapses, which seek to increase average reward [6].", "startOffset": 110, "endOffset": 113}, {"referenceID": 8, "context": "Another related line of research derives from the information bottleneck method [9,11] which provides an alternate constraint to the one considered here.", "startOffset": 80, "endOffset": 86}, {"referenceID": 10, "context": "Another related line of research derives from the information bottleneck method [9,11] which provides an alternate constraint to the one considered here.", "startOffset": 80, "endOffset": 86}, {"referenceID": 11, "context": "An information-theoretic perspective on synaptic homeostasis and metabolic cost, complementing the results in this paper, can be found in [12, 13].", "startOffset": 138, "endOffset": 146}, {"referenceID": 12, "context": "An information-theoretic perspective on synaptic homeostasis and metabolic cost, complementing the results in this paper, can be found in [12, 13].", "startOffset": 138, "endOffset": 146}, {"referenceID": 13, "context": "Simulations combining synaptic renormalization with burst-STDP can be found in [14].", "startOffset": 79, "endOffset": 83}, {"referenceID": 14, "context": "Important aspects of plasticity that we have not considered here are properties specific to continuoustime models, such as STDP\u2019s behavior as a temporal filter [15], and also issues related to convergence [8, 10].", "startOffset": 160, "endOffset": 164}, {"referenceID": 7, "context": "Important aspects of plasticity that we have not considered here are properties specific to continuoustime models, such as STDP\u2019s behavior as a temporal filter [15], and also issues related to convergence [8, 10].", "startOffset": 205, "endOffset": 212}, {"referenceID": 9, "context": "Important aspects of plasticity that we have not considered here are properties specific to continuoustime models, such as STDP\u2019s behavior as a temporal filter [15], and also issues related to convergence [8, 10].", "startOffset": 205, "endOffset": 212}, {"referenceID": 15, "context": "The learning-theoretic properties of neural networks have been intensively studied, mostly focusing on perceptrons, see for example [16].", "startOffset": 132, "endOffset": 136}, {"referenceID": 16, "context": "A non-biologically motivated \u201clarge-margin\u201d analog of the perceptron was proposed in [17].", "startOffset": 85, "endOffset": 89}, {"referenceID": 0, "context": "is the Heaviside function and w is a [0, 1] \u2282 R valued N -vector specifying the selectron\u2019s synaptic weights.", "startOffset": 37, "endOffset": 43}, {"referenceID": 7, "context": "The Bernoulli regime is the discrete-time analog of the homogeneous Poisson setting used to prove convergence of reward-modulated STDP in [8].", "startOffset": 138, "endOffset": 141}, {"referenceID": 17, "context": "inputs are unrealistic, note that recent neurophysiological evidence suggests neuronal firing \u2013 even of nearby neurons \u2013 is uncorrelated [18].", "startOffset": 137, "endOffset": 141}, {"referenceID": 18, "context": "Similarly, there is a large menagerie of models of synaptic plasticity [19].", "startOffset": 71, "endOffset": 75}, {"referenceID": 19, "context": "We consider two well-established models: Gerstner\u2019s Spike Response Model (SRM) which generalizes leaky integrate-and-fire neurons [20] and the original spike-timing dependent plasticity learning rule proposed by Song et al [5], and show that the selectron arises in the fast time constant limit of the two models.", "startOffset": 130, "endOffset": 134}, {"referenceID": 4, "context": "We consider two well-established models: Gerstner\u2019s Spike Response Model (SRM) which generalizes leaky integrate-and-fire neurons [20] and the original spike-timing dependent plasticity learning rule proposed by Song et al [5], and show that the selectron arises in the fast time constant limit of the two models.", "startOffset": 223, "endOffset": 226}, {"referenceID": 4, "context": "The original STDP update rule [5] is", "startOffset": 30, "endOffset": 33}, {"referenceID": 20, "context": "However, in a large system where estimates pile on top of each other there is a tendency to overfit, leading to poor generalizations [21].", "startOffset": 133, "endOffset": 137}, {"referenceID": 21, "context": "Boosting algorithms, where the outputs of many weak learners are aggregated into a classifier [22], are remarkably resistant to overfitting as the number of learners increases [23].", "startOffset": 94, "endOffset": 98}, {"referenceID": 22, "context": "Boosting algorithms, where the outputs of many weak learners are aggregated into a classifier [22], are remarkably resistant to overfitting as the number of learners increases [23].", "startOffset": 176, "endOffset": 180}, {"referenceID": 23, "context": "As a first step towards understanding how the cortex combats overfitting, we adapt a theorem developed to explain the effectiveness of boosting [24].", "startOffset": 144, "endOffset": 148}, {"referenceID": 24, "context": "However, since the cortex contains many neurons and spiking is metabolically expensive [25], we propose a conservative loss that only penalizes errors of commission (\u201cfirst, do no harm\u201d) and does not penalize specialization.", "startOffset": 87, "endOffset": 91}, {"referenceID": 25, "context": "It is therefore important that what neurons learn is robust to changing inputs [26, 27].", "startOffset": 79, "endOffset": 87}, {"referenceID": 26, "context": "It is therefore important that what neurons learn is robust to changing inputs [26, 27].", "startOffset": 79, "endOffset": 87}, {"referenceID": 27, "context": "It has recently been proposed that a function of NREM sleep may be to regulate synaptic weights [28].", "startOffset": 96, "endOffset": 100}, {"referenceID": 28, "context": "Indeed, neurophysiological evidence suggests that average cortical firing rates increase during wakefulness and decrease during sleep, possibly reflecting synaptic strengths [29, 30].", "startOffset": 174, "endOffset": 182}, {"referenceID": 29, "context": "Indeed, neurophysiological evidence suggests that average cortical firing rates increase during wakefulness and decrease during sleep, possibly reflecting synaptic strengths [29, 30].", "startOffset": 174, "endOffset": 182}, {"referenceID": 30, "context": "Experimental evidence also points to a net increase in dendritic spines (synapses) during waking and a net decrease during sleep [31].", "startOffset": 129, "endOffset": 133}, {"referenceID": 31, "context": "We used Gerstner\u2019s SRM model, recall \u00a73, with parameters chosen to exactly coincide with [32]: \u03c4m = 10, \u03c4s = 2.", "startOffset": 89, "endOffset": 93}, {"referenceID": 31, "context": "7 also taken from [32].", "startOffset": 18, "endOffset": 22}, {"referenceID": 0, "context": "Synaptic weights were clipped to fall in [0, 1].", "startOffset": 41, "endOffset": 47}, {"referenceID": 4, "context": "Classical STDP has a depotentiation bias to prevent runaway potentiation feedback loops leading to seizures [5].", "startOffset": 108, "endOffset": 111}, {"referenceID": 29, "context": "3 This is in line with experimental evidence showing increased cortical activity during waking [30].", "startOffset": 95, "endOffset": 99}], "year": 2012, "abstractText": "This paper suggests a learning-theoretic perspective on how synaptic plasticity benefits global brain functioning. We introduce a model, the selectron, that (i) arises as the fast time constant limit of leaky integrate-and-fire neurons equipped with spiking timing dependent plasticity (STDP) and (ii) is amenable to theoretical analysis. We show that the selectron encodes reward estimates into spikes and that an error bound on spikes is controlled by a spiking margin and the sum of synaptic weights. Moreover, the efficacy of spikes (their usefulness to other reward maximizing selectrons) also depends on total synaptic strength. Finally, based on our analysis, we propose a regularized version of STDP, and show the regularization improves the robustness of neuronal learning when faced with multiple stimuli.", "creator": "LaTeX with hyperref package"}}}