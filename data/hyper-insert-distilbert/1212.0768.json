{"id": "1212.0768", "review": {"conference": "arxiv", "VERSION": "v1", "DATE_OF_SUBMISSION": "4-Dec-2012", "title": "An ontology-based approach to relax traffic regulation for autonomous vehicle assistance", "abstract": "ordinary traffic lane regulation must be respected legally by perhaps all road vehicles, currently either human - or computer - driven. } however, describing extreme international traffic situations both might nonetheless exhibit practical cases in which a vehicle should safely run and otherwise reasonably consistently relax traffic regulation, e. g., intentionally in order certain not to be indefinitely indefinitely blocked and unwilling to not keep requests circulating. in performing this work paper, mostly we propose a valid high - level representation comparing of an automated vehicle, other vehicles ; and their environment, calculations which can assist drivers in possibly taking such \" virtually illegal \" but practical relaxation rule decisions. this high - confidence level representation ( an ontology ) includes topological behaviour knowledge and random inference modelling rules, in special order to compute the potentially next high - level motion an automated vehicle will should take, as assistance to a driver. results published on comparing practical legal cases both are presented.", "histories": [["v1", "Tue, 4 Dec 2012 15:34:10 GMT  (476kb)", "http://arxiv.org/abs/1212.0768v1", null]], "reviews": [], "SUBJECTS": "cs.AI", "authors": ["philippe morignot", "fawzi nashashibi"], "accepted": false, "id": "1212.0768"}, "pdf": {"name": "1212.0768.pdf", "metadata": {"source": "CRF", "title": "AN ONTOLOGY-BASED APPROACH TO RELAX TRAFFIC REGULATION FOR AUTONOMOUS VEHICLE ASSISTANCE", "authors": ["Philippe Morignot", "Fawzi Nashashibi"], "emails": ["Philippe.Morignot@inria.fr", "Fawzi.Nashashibi@inria.fr"], "sections": [{"heading": null, "text": "human- or computer- driven. However, extreme traffic situations might exhibit practical cases in which a vehicle should safely and reasonably relax traffic regulation, e.g., in order not to be indefinitely blocked and to keep circulating. In this paper, we propose a high-level representation of an automated vehicle, other vehicles and their environment, which can assist drivers in taking such \u201cillegal\u201d but practical relaxation decisions. This high-level representation (an ontology) includes topological knowledge and inference rules, in order to compute the next high-level motion an automated vehicle should take, as assistance to a driver. Results on practical cases are presented.\nKEY WORDS Knowledge representation, Law, Intelligent Vehicle"}, {"heading": "1. Introduction", "text": "Imagine that you are driving your car and that a truck is before you on the street, engine stopped, rear door open and unloading furniture for some close apartment. Since your car\u2019s lane is delimited by a continuous line and a sidewalk, you must not overtake according to the traffic regulation. You are then condemned to wait until the truck has finished unloading, a process which might keep you stopped for an uncertain, probably long, amount of time.\nTo take a second example, imagine that you are about to reach a roundabout, but that the car before yours on the lane has stopped, probably with an engine problem, e.g., electric power cut. Here again, since this lane is delimited by a continuous line and a sidewalk, strict respect of traffic regulation condemns you to wait behind the defective car until that car can move again, a process which might probably be counted in hours.\nMany similar practical situations can be imagined, or\ntaken from every driver\u2019s experience.\nHuman drivers can cope with such abnormal situations. For example, after having waited for some amount of time, a human driver might decide to cross the continuous line: He checks for the absence of vehicles on the adjacent opposite lane, makes a small left turn, crosses the\ncontinuous line, overtakes the unloading truck or the defective car, drives a few meters on the adjacent lane, and comes back to its initial lane once the obstacle is passed. Alternatively, the driver could decide to slowly run on the sidewalk to overtake the stopped truck / defective car.\nStrictly speaking, traffic regulation is violated indeed: The French road traffic regulation states that \u201cvehicles must circulate on roadways, except in case of absolute emergency\u201d (section R412-7 [8] for France, [6] for an international definition). But in practice, given the above unusual circumstances, no one will blame a driver for safely crossing the above continuous line after having waited for a reasonable amount of time. Perhaps even a policeman, if present, would evaluate the abnormality of the situation and would impose you to cross this continuous line and overtake the stopped truck/vehicle. In other words, perfect traffic respecting perfect regulation in a perfect world is not the way things happen in real open environments.\nIf the above decision can be taken every day by human drivers, the picture is different for an autonomous vehicle driven by a computer. In the two above situations, an intelligent robotic vehicle such as a CyCab [7], based on perception and control, will stop and be kept stuck on its lane until the unloading truck/damaged vehicle moves. Whereas, to mimic human behavior, a decision would be needed at some point: should the CyCab follow its obstacle avoidance algorithm, i.e., change lane, or should it follow traffic regulation, i.e., stay on its lane? (In the experiments on the CityMobil project in the city LaRochelle in Nov. 2011, kids were having fun with a CyBus by stepping in front of it each time it avoided them and started to run.)\nThe purpose of this paper is to give to autonomous vehicles such as a CyCab enough reasoning capabilities to be able to take such decision, and therefore be able to cope with such unusual situations. In other words, not letting the autonomous vehicle be stuck in unusual but practical situations, such as the two above, because of (probably overly restrictive) traffic regulation following. More generally, such reasoning capability is one aspect of decisional autonomy for vehicles, which is considered as a major research area of this century towards intelligent traffic [13].\nThe paper is organized as follows: First, a model based on an ontology including rules is presented in section 2. Second, an implementation based on the ontology editor PROT\u00c9G\u00c9 [17] and SWRL (Semantic Web Rule Language) [11] is presented, and results are described, in section 3. Finally we relate our work to previous approaches and sum up our contribution."}, {"heading": "2. Model", "text": ""}, {"heading": "2.1 Context", "text": "Among the possible approaches to modeling traffic\nsituations, there is an increasing number of symbolic ones\nusing ontologies [3] [12] [18]. The main idea is that a\nhigh level, symbolic, representation (knowledge) is useful\nto perform reasoning on traffic situations, as\ncomplementary to low level ones involving perception, or\npath planning and kinematic control --- see [1] on\ncollaborating vehicles integrating these two approaches.\nMore generally, ontologies are introduced into mobile\nrobotic frameworks (e.g., OROCOS [16]).\nOther approaches use vehicular ad hoc networks\n(VANETs) in order to model sensor and actuation inside\neach vehicle, and communication among them (V2V) or\nwith the infrastructure (V2I) [14] [15]. In our approach,\nwe also use vehicles equipped with sensors and actuators,\nand which can communicate with others and the\ninfrastructure. But we focus on the internal part of each\nvehicle only, and specifically its decisional part, instead\nof building statistics over the global traffic as a whole\n(how dense it is and how to reduce it)."}, {"heading": "2.2 Ontologies", "text": "In Computer Science (as opposed to Philosophy, where\nthe term \u201contology\u201d has a different definition), an\nontology may be defined as a specification of a\nconceptualization of a domain of knowledge [10]. For\nexample, infectious disease diagnosis is a domain of\nmedical knowledge; The concepts involved, lying in the\nbrain of physicians, constitute its conceptualization; And\na description of these concepts in a formal language\nconstitutes its specification.\nAn important characteristic of an ontology is its\ncompleteness: an ontology should completely cover a\nknowledge domain, i.e. not leaving concepts behind. An\nontology may also be defined as a complete semantic\nnetwork, emphasizing that it is composed of a hierarchy\nof concepts.\nIn practice, an ontology is expressed as classes,\nproperties and individuals. Tools are available to\ngraphically create/edit an ontology (e.g., PROT\u00c9G\u00c9 [17],\nSWOOP [20]) and express it in OWL (Ontology Web\nLanguage)."}, {"heading": "2.3 Proposed model", "text": "The proposed ontology represents the vehicle (the\nintelligent vehicle and other vehicles), the infrastructure\nand the traffic regulation (see Fig. 1). Aiming at modeling\nall the concepts involved in traffic regulation relaxation,\nwe found no existing ontology dedicated to it (e.g., A3ME\nfocuses on the vehicle\u2019s motion only [3]) --- only\nnewspapers articles report accidents in case of traffic\nregulation relaxation. Therefore, we built our own\nontology, not based on a texts corpus, but on drivers\u2019\nexperience (member of the lab with their driving license)\nand their own reactions regarding traffic regulation\nrelaxation.\nMore precisely, a vehicle is symbolically represented as\nits name (\u201cCar\u201d class), an internal class (\u201cDriverEmotion\u201d)\nand its possible motion (\u201cMotion\u201d class, with sub-classes\n\u201cCurrentMotion\u201d and \u201cNextMotion\u201d). The main object\nproperties to represent an intelligent vehicle are its motion\nand its location.\nThe above static representation is completed by a\ndynamic one using inference rules (see section 3.2). These\nrules are used to augment the static description, i.e., make\ninferences based on the knowledge of the situation at\nhand. In practice, an inference rule adds object properties\nor determine a class of an individual.\nIn our representation, two main properties of a vehicle\nmust be inferred: the \u201cisOn\u201d property specifies an\nindividual of the infrastructure on which a vehicle is (e.g.,\na named lane); and \u201chasMotion\u201d / \u201chasNextMotion\u201d\nobject properties relate a vehicle to an individual of the\n\u201cMotion\u201d class. For now, the possible motions of a\nvehicle are set by individuals of this class (see Fig.\n1):\u201cForward\u201d, \u201cStopped\u201d and \u201cBackward\u201d --- this\ndiscretization of the speed of a vehicle can be made as\nprecise as desired, e.g., with integers representing a value\nin km/h.\nThe traffic regulation (the bottom class in Fig. 1) is\nrepresented by individual related by an object property\n\u201cisIllegal\u201d to the motion of the intelligent vehicle.\nBeing a high-level topological model, our approach\nrelies on symbols to describe an intelligent vehicle, other\nvehicles and their environment. Therefore, as in [3] [12]\n[18], we have to assume that (1) perception is capable of\nturning sensor data into symbols; and, conversely, that (2)\nthe inferred symbolic motion leads to path planning and\nkinematic control, for actual motion --- these two areas of\nrobotics research (perception and control) are out of the\nscope of this paper."}, {"heading": "3. Results", "text": "The approach in Section II is implemented with the\nontology editor PROT\u00c9G\u00c9 version 4 [17], using the\nreasoner PELLET version 2.2.0. Inference rules are\nexpressed in SWRL (Semantic Web Rule Language) [11].\nWe first present the static knowledge involved (i.e.,\nclasses, properties and individuals), then present the\ndynamic knowledge (i.e., inference rules) and finally\npresent examples."}, {"heading": "3.1 Classes, properties and individuals", "text": "The environment of the CyberCar is represented by the\nclass \u201cInfrastructure\u201d (see Fig. 2). The main\nrepresentational element is the \u201cRoadNetwork\u201d class,\nrepresenting lanes/roads and intersections as a graph, with\nthe former being vertices and the latter being edges\n(borrowed from [18]). For example, two intersections\n(i.e., \u201cRoadNode\u201d individuals) can be connected to\nanother intersection by one road (i.e., one\n\u201cRoadConnection\u201d individual), or even by two lanes (i.e.,\ntwo \u201cRoadConnection\u201d individuals), the lane up and the\nlane down --- a two-way lane connects the two\nintersections.\nThe immediate delimiters of each \u201cRoadConnection\u201d\nindividual are represented by the \u201cZoneOnTheSide\u201d class,\ne.g., sidewalks, zebra zones, continuous lines and dashed\nlines. The first two are sub-class of the \u201cDrivableZone\u201d\nclass, i.e., at the detail level of description, they occupy\nsome surface on the ground, hence can be physically\ndriven on by a vehicle. The last two also are sub-class of\nthe \u201cCrossableZone\u201d class, i.e., at the considered level of\ndescription they do not occupy any surface on the ground,\nhence can physically be crossed only, not driven on. To\nfollow the example of the previous paragraph, the two\nlanes (up and down) of a two-way road (a\n\u201cRoadConnection\u201d individual) can be separated by a\ncontinuous line, i.e., an individual of the\n\u201cContinuousLine\u201d class, sub-class of the \u201cCrossableZone\u201d\nclass. The \u201chasBesides\u201d object property links\n\u201cRoadConnection\u201d individuals to \u201cZoneOnTheSide\u201d ones.\nThe last class in Fig. 2, \u201cSignAtCrossing\u201d, represents\ntraffic lights and signs at an intersection, i.e., a\n\u201cRoadNode\u201d individual. Individuals of that class can be\nused to infer conflicts among vehicles approaching an\nintersection, hence to infer the right-of-way of a vehicle\narriving on a \u201cRoadConnection\u201d individual connected to a\n\u201cRoadNode\u201d individual (see [18] for a discussion on this\npoint)."}, {"heading": "3.2 Inference rules", "text": "The evolution of a symbolic situation should be\nrepresented with terms which are sometimes true and\nsometimes false, depending on the time at which they are\nobserved (a flavor of fluents in STRIPS task planning\n[9]). But, although the \u201cnot\u201d operator, negating a term,\ncan be represented in OWL to some extent (see [17]),\nDescription Logic (DL), the formal basis of ontologies, is\nmonotonic and is not capable of representing the new\ntrue/false value of a term, the truth value of which\nchanges. Typically, SWRL [11] cannot represent a rule:\nIF A AND B AND C THEN not(D). That is, in DL,\nthings can only be added to the current ontology, and\nnever retracted from it.\nFacing this restriction, we chose to discretize time, i.e.\nreason on time steps, and represent the reasoning of an\nintelligent vehicle over two successive time steps only:\ninferring the next motion of a vehicle, the current motion\nand context being symbolically described. Then, the\ninference mechanism over our ontology, computing this\nnext motion, is supposed to be iterated over time (with an\nupdate phase interleaved), in order to build the long term\ncourse of action of an autonomous vehicle. Formally, the\nontology is used as a mapping: S x M -> M where S is the\nset of situations, one situation being expressed by an\nontology, and M the set of motions of an autonomous\nvehicle. The situation sn  S and motion mn  M at time step n produce the motion mn+1  M at time step n+1.\nDrivableZone(?s), Car(?a), Car(?b), Lane(?l),\nhasEmotion(?a, Nervous),\nisAfter(?a, ?b),\nhasBesides(?l, ?s),\nhasMotion(?a, Stopped),\nisOn(?a, ?l), isOn(?b, ?l),\nisIllegal( ?l, ?s),\n->\nisNextOn(?a, ?s)\nTable 2: An example of SWRL inference rule in the case of one lane with a unique large delimiter.\nInference rules express how to relate the current\nsituation and motion of a vehicle to its next motion. We\nuse such inference rules to actually encode the traffic\nregulation relaxation behavior of one specific vehicle.\nThese rules strongly participate in attaining the resulting\nbehavior we initially targeted for the intelligent vehicles,\nso we describe some of these rules now.\nThe rule in Table 1 expresses that if vehicle ?a on lane\n?l1 is behind the stopped vehicle ?b on the same lane,\nthen ?a can cross the lane delimiter ?s, even if it is illegal,\nto reach the adjacent opposite lane ?l2, provided that it is\nclear (no vehicle on it). The representation choices in this\nrule lead to several comments:\n1. The term isClear(?l) expresses that there is no vehicle on lane ?l. In first order predicate logic, it\nwould be written as:  c  Car,  l  RoadConnection :\non(c, l)   (  c\u2019  Car, c  c\u2019  on(c\u2019, l) )\n(A variant includes an additional term:\ndistance(c,c\u2019) < | speed(c ) - speed(c\u2019) | * Tovertake). Unfortunately, such negated existential\nquantification in the second term of the above\nimplication cannot be expressed in DL. As a first\napproach, we chose to encode the clearness of a\nlane as a class \u201cisClear\u201d, its individuals being the\ncurrent clear lanes --- another mechanism is\nneeded in order to maintain these individuals in\nthis class.\n2. The property isIllegal(?l1, ?l2) expresses that moving from RoadConnection individual ?l1 to\nRoadConnection or ZoneOnTheSide individual ?l2 is not legal given traffic regulation. As such, it should be inferred from a representation of the traffic regulation [12] [18], e.g., rules concluding on the legality/illegality of a given motion. As a first approach, we chose a simpler implementation: enumerating a set of traffic regulation violations with the isIllegal property. 3. The waiting time of the vehicle ?a behind the front stopped vehicle ?b is represented by the property\nhasEmotion(Car, DriverEmotion). If the so-called \u201cdriver emotion\u201d of car ?a is \u201cNervous\u201d, then the waiting time is considered to have expired and the illegal motion can be performed. If another \u201cdriver emotion\u201d, e.g., \u201cRelaxed\u201d, is active, then the waiting time is considered to still run, therefore the vehicle ?a keeps being stopped behind front"}, {"heading": "3.3 Examples", "text": "The first case of section 1 is depicted in Fig. 3.\nIn this case, the infrastructure is composed of a\nroundabout \u201c22SeptembreRoundAbout\u201d connected by a\ntwo-way lane (\u201cAvenueDeLaLiberteUp\u201d and\n\u201cAvenueDeLaLiberteDown\u201d individuals) to a place\n(\u201cPlaceDeLaGare\u201d). A ZoneOnTheSide individual\n(\u201cLineAvenueDeLaGare\u201d individual) is between the two\nways of this lane (represented by the \u201chasBesides\u201d object\nproperty). The stopped unloading truck is represented by\n\u201cCar\u201d individual \u201cUnloadingTruck1\u201d and is stopped\n(object property \u201cHasMotion(UnloadingTruck1,\nStopped)\u201d). A second vehicle is the CyCab (individual\n\u201cCyberCar1\u201d of the class \u201cCar\u201d). Both vehicle stays on the\n\u201cAvenueDeLaLibertUp\u201d lane through the object property\n\u201cisOn\u201d.\nHere are the inferred object properties:\nhasMotion(CyberCar1, Stopped) (1)\nisAfter(CyberCar1,UnloadingTruck1) (2)\nhasNextMotion(CyberCar1, Forward) (3)\nisNextOn(CyberCar1, AvenueDeLaLibertDown) (4)\nThe first two inferred object properties fill in the\ncurrent situation: the inferred property 1 is a result of the\nfiring of the rule in Table 4; the inferred property 2 is\nperformed because the \u201cisBefore\u201d and \u201cisAfter\u201d properties\nare declared inverse. The last two inferred object\nproperties describe the next motion of the individual\nCyberCar1: the object property 3 is the result of firing a\nrule close to the ones of Table 1 and 2, but related to the\nspeed of the vehicle; the object property 4 is the result of\nthe firing of the rule in Table 1.\nInterestingly, the above resulting behavior of the intelligent vehicle could not be reached if the so called \u201cDriverEmotion\u201d was \u201cRelax\u201d. Here is the inferred object properties in that case:\nhasMotion(CyberCar1, Stopped) (1)\nisAfter(CyberCar1,UnloadingTruck1) (2)\nhasNextMotion(CyberCar1, Stopped) (3)\nThat is, under a different DriverEmotion, the vehicle CyberCar1 is stopped behind vehicle UnloadingTruck1 (as in the previous example), but now his next motion will keep being \u201cStopped\u201d, i.e., the CyberCar waits behind the unloading truck, as respect of traffic regulation prescribes. This is the default behavior of intelligent vehicles, and our whole approach results in crossing the continuous line (a behavior prohibited by the traffic regulation) in this example of unusual circumstances.\nThe second example of section I is close in spirit to the example of Fig. 3 (it only differs from it by the topology of RoadConnection and RoadNode individuals). Here are the inferred object properties:\nhasMotion(CyberCar2, Stopped) (1)\nisAfter(CyberCar2,UnloadingTruck2) (2)\nhasNextMotion(CyberCar2, Forward) (3)\nisNextOn(CyberCar2, SwRueDu22Septembre) (4)\nThe main difference with the first example is that \u201cCyberCar2\u201d individual is next on a sidewalk to overtake the unloading truck (\u201cSwRueDu22Septembre\u201d individual), since the inference rule of Table 2 has fired.\nThe reasoner PELLET performs the above inferences\non these two cases together in 389 ms, on a machine 4-\ncore at 2 GHz with 4 Gb RAM. But some time in this\nfigure is spent classifying the ontology, i.e., sorting the\nclasses along the \u201cis-a\u201d relation and checking them for\nconsistency (i.e., every class is not prevented from\nowning individuals). Other reasoners are available (e.g.,\nFACT++, RACERPRO), and using benchmarks\u2019 results\nfor choosing on another reasoner can improve these\nperformances [4]."}, {"heading": "4. Discussion", "text": "Defining a topological world model to infer the next motion of an intelligent vehicle to assist drivers regarding traffic regulation relaxation raises numerous issues:\n1. How long does a driver take, facing the situations described in section I, to decide to cross a continuous line? On one side, crossing this line is forbidden by traffic regulation (the goal being to respect traffic regulation), but on the other side staying too long trapped in his lane behind an unloading truck/defective vehicle seems inappropriate either (the goal being to keep circulating, e.g., reaching point B from point A). The time it takes to overtake an unloading truck/defective vehicle is related to the way a driver finds an acceptable trade off to this conflict --- this could be encoded as a driver-dependent threshold on the elapsed time, regarding the \u201chasEmotion\u201d property of section 3.2. But this question is relevant to the domain of cognitive psychology (e.g., see [2]), which is out of the scope of this paper.\n2. A drawback of an ontology-based approach is that a vehicle and its environment are represented in\ndiscrete, symbolic terms: things are true or false but there is no way to represent something intermediate, i.e., a notion of uncertainty (uncertainty is implicit in OWL because of the open world assumption, stating that if a term is not present in the ontology, it is assumed to be unknown, as opposed to the closed world assumption in task planning [9]). For example, Bayesian networks can represent probabilistic inferences, i.e., reason on the uncertainty inherent to the involved terms (which would be called state variables). Therefore a first solution to representing uncertainty would be to re-write the above rules (see section 3.2) as probabilistic dependencies among state variables. A second solution is to restrict our view to describing the intelligent vehicle\u2019s context only, i.e., providing the right ontology for the current context, and making inferences with certainty about it. Further reasoning, including uncertainty inside these certainty limits, being performed by Bayesian networks. 3. Regele [18] and Hulsen et al. [12] use a high level topological representation of the environment to\nmake inferences about the conflicts at an intersection (e.g., giving right-of-way). But if we use a high level topological representation too, these bodies of work stay close to the traffic regulation. That is, they infer with certainty properties of vehicles\u2019 possible motions given what is permitted by traffic regulation (a vehicle passes or does not pass). Our approach differs from theirs, in that it is closer to the vehicle\u2019s motion (e.g., see the \u201cDriverEmotion\u201d class in section 3) with a more detailed representation of vehicles, and dedicated to relaxing traffic regulation for practical purpose. 4. Mohandas et al. [14] propose a proportional integral controller to manage the congestion of\ntraffic in vehicular ad hoc networks (VANETs). But there is no model of the vehicle, except in the queue at each VANET node. A close view is due to Mohimani et al. [15] in which a vehicle is a state automaton, and a probabilistic model is used to represent traffic in vehicular ad hoc networks. The closest part to our work is the state automaton representing the decisional part of a vehicle (e.g., answering the question: overtaking or not?). But we focus much more deeply on the decisional part with an ontology, to represent necessary knowledge to break or keep traffic regulation. 5. Other authors focus on emergency vehicles having de facto priority over regular traffic [3]\n[19]. But this is dedicated to specific vehicles, with little decision taken from it --- as opposed to them, we elaborate on the decisional part of each regular vehicle facing unusual traffic situations. Interestingly, Bermejo et al. [3] also use an ontology to represent the motion of regular vehicles (e.g., having to change lane to give free of way to an emergency vehicle). If this approach is probably the closest to ours, we represent in the ontology the whole infrastructure in which regular vehicles are embedded, and not only the motion parameters of each vehicle --- which can obviously be refined as deeply as desired in our model. 6. As stated earlier, the proposed approach relies on symbols (an ontology) to draw a decisional\ncomponent into a vehicle equipped with sensors and effectors and potentially communicating with other vehicles and with an infrastructure, such as CyberCars [7]. As such, we envision to include it into the perception / planning / control cycle, after perception (which extracts symbolic information from signals of sensors) and before the path planning part (which computes a trajectory to reach a desired location in the current environment, sending low level commands to actuators). That is, symbolic information are available for that component and that component produces new goal locations, which could not be planned without the traffic relaxation module --- the remaining modules plan for respecting traffic regulation."}, {"heading": "5. Conclusion", "text": "In this paper, we have presented a topological world model, to relax traffic regulation in unusual but practical situations, in order to assist drivers. This model is composed of an ontology, representing the vehicles, the infrastructure and the traffic regulation (implemented in OWL with Prot\u00e9g\u00e9 [17]), and inference rules (implemented in SWRL [11]) computing the next motion of an intelligent vehicle under discretized time. Traffic regulation relaxation cases have been presented,\nexhibiting realistic behavior from the intelligent vehicle.\nFuture work involves (1) representing traffic regulation as rules inferring on the legality/illegality of an intelligent vehicle\u2019s potential motion; (2) integrating the ontology, a reasoning paradigm on certainty, as context definition for perception/control using uncertainty; and (3) porting the ontology on CyCab platforms.\nAcknowledgement(s)\nThe authors thank our colleagues of the IMARA team for numerous fruitful discussions. We thank Timothy Redmond (Stanford) for help on Prot\u00e9g\u00e9, and anonymous reviewers for helpful comments."}], "references": [{"title": "A Scheme for Coordinating Multi-Robot Planning Activity and Plans Execution", "author": ["R. Alami", "F.Ingrand", "S. Qutub"], "venue": null, "citeRegEx": "1", "shortCiteRegEx": "1", "year": 1998}, {"title": "Situation awareness of drivers : fondamental aspects, methods and application to driver training (\u00ab Conscience de la situation des conducteurs : aspects fondamentaux, m\u00e9thodes et application pour la formation des conducteurs \u00bb)", "author": ["E. Bailly"], "venue": "Ph.D. thesis, Laboratoire d\u2019Etude et d\u2019Analyse de la Cognition et des Mode\u0300les, Lyon 2 University,", "citeRegEx": "2", "shortCiteRegEx": "2", "year": 2004}, {"title": "Benchmarking OWL reasoners", "author": ["J. Bock", "P.Haase", "Q. Ji", "R. Volz"], "venue": "Workshop on Advanced Reasoning on the Web: Scalability and Common Sense (Area\u201908),", "citeRegEx": "4", "shortCiteRegEx": "4", "year": 2008}, {"title": "A VANET-based Emergency Vehicle Warning System", "author": ["A. Buchenscheit", "F. Schaub", "F. Kargl", "M. Weber"], "venue": "First IEEE Vehicular Networking Conference (VNC", "citeRegEx": "5", "shortCiteRegEx": "5", "year": 2009}, {"title": "Automated Planning : Theory and Practice", "author": ["M. Ghallab", "D. Nau", "P. Traverso"], "venue": null, "citeRegEx": "9", "shortCiteRegEx": "9", "year": 2004}, {"title": "A Translation Approach to Portable Ontology Specifications", "author": ["T. Gruber"], "venue": "Knowledge Acquisition,", "citeRegEx": "10", "shortCiteRegEx": "10", "year": 1993}, {"title": "SWRL: A Semantic Web Rule Language Combining OWL and RuleML", "author": ["I. Horrocks", "P.F. Patel-Schneider", "H. Boley", "S. Tabet", "B. Grosof", "M. Dean"], "venue": "Submission to", "citeRegEx": "11", "shortCiteRegEx": "11", "year": 2004}, {"title": "Traffic Intersection Situation Description Ontology for Advanced Driver Assistance", "author": ["M. Hulsen", "M Zollner", "C. Weiss"], "venue": "IEEE Intelligent Vehicle Symposium (IV),", "citeRegEx": "12", "shortCiteRegEx": "12", "year": 2011}, {"title": "The Century of Intelligent Car (\u201cLe si\u00e8cle de la voiture intelligente\u201d)", "author": ["C. Laurgeau"], "venue": null, "citeRegEx": "13", "shortCiteRegEx": "13", "year": 2009}, {"title": "Vehicle Traffic Congestion Management in Vehicular ad-hoc Networks", "author": ["B.K. Mohandas", "R. Liscano", "O.W.W. Yang"], "venue": "3er IEEE LCN Workshop on User Mobility and Vehicular Networks (ON-MOVE", "citeRegEx": "14", "shortCiteRegEx": "14", "year": 2009}, {"title": "Mobility Modeling, Spatial Traffic Distribution, and Probability of Connectivity for Sparse and Dense Vehicular Ad Hoc Networks", "author": ["G.H. Mohimani", "F. Ashtiani", "A. Javanmard", "M. Hamdi"], "venue": "IEEE Trans. On Vehicular Technology,", "citeRegEx": "15", "shortCiteRegEx": "15", "year": 2009}, {"title": "A Novel Approach to Reduce Traffic Chaos in Emergency and Evacuation Scenarios", "author": ["S.R. Rizvi", "S. Olariu", "M. Weigle", "M. Rizvi"], "venue": "VTC Fall. IEEE,", "citeRegEx": "19", "shortCiteRegEx": "19", "year": 2007}], "referenceMentions": [{"referenceID": 8, "context": "More generally, such reasoning capability is one aspect of decisional autonomy for vehicles, which is considered as a major research area of this century towards intelligent traffic [13].", "startOffset": 182, "endOffset": 186}, {"referenceID": 6, "context": "Second, an implementation based on the ontology editor PROT\u00c9G\u00c9 [17] and SWRL (Semantic Web Rule Language) [11] is presented, and results are described, in section 3.", "startOffset": 106, "endOffset": 110}, {"referenceID": 7, "context": "1 Context Among the possible approaches to modeling traffic situations, there is an increasing number of symbolic ones using ontologies [3] [12] [18].", "startOffset": 140, "endOffset": 144}, {"referenceID": 0, "context": "The main idea is that a high level, symbolic, representation (knowledge) is useful to perform reasoning on traffic situations, as complementary to low level ones involving perception, or path planning and kinematic control --- see [1] on collaborating vehicles integrating these two approaches.", "startOffset": 231, "endOffset": 234}, {"referenceID": 9, "context": "Other approaches use vehicular ad hoc networks (VANETs) in order to model sensor and actuation inside each vehicle, and communication among them (V2V) or with the infrastructure (V2I) [14] [15].", "startOffset": 184, "endOffset": 188}, {"referenceID": 10, "context": "Other approaches use vehicular ad hoc networks (VANETs) in order to model sensor and actuation inside each vehicle, and communication among them (V2V) or with the infrastructure (V2I) [14] [15].", "startOffset": 189, "endOffset": 193}, {"referenceID": 5, "context": "In Computer Science (as opposed to Philosophy, where the term \u201contology\u201d has a different definition), an ontology may be defined as a specification of a conceptualization of a domain of knowledge [10].", "startOffset": 196, "endOffset": 200}, {"referenceID": 7, "context": "Therefore, as in [3] [12] [18], we have to assume that (1) perception is capable of turning sensor data into symbols; and, conversely, that (2) the inferred symbolic motion leads to path planning and kinematic control, for actual motion --- these two areas of robotics research (perception and control) are out of the scope of this paper.", "startOffset": 21, "endOffset": 25}, {"referenceID": 6, "context": "Inference rules are expressed in SWRL (Semantic Web Rule Language) [11].", "startOffset": 67, "endOffset": 71}, {"referenceID": 4, "context": "sometimes false, depending on the time at which they are observed (a flavor of fluents in STRIPS task planning [9]).", "startOffset": 111, "endOffset": 114}, {"referenceID": 6, "context": "Typically, SWRL [11] cannot represent a rule: IF A AND B AND C THEN not(D).", "startOffset": 16, "endOffset": 20}, {"referenceID": 7, "context": "As such, it should be inferred from a representation of the traffic regulation [12] [18], e.", "startOffset": 79, "endOffset": 83}, {"referenceID": 2, "context": ", FACT++, RACERPRO), and using benchmarks\u2019 results for choosing on another reasoner can improve these performances [4].", "startOffset": 115, "endOffset": 118}, {"referenceID": 1, "context": ", see [2]), which is out of the scope of this paper.", "startOffset": 6, "endOffset": 9}, {"referenceID": 4, "context": ", a notion of uncertainty (uncertainty is implicit in OWL because of the open world assumption, stating that if a term is not present in the ontology, it is assumed to be unknown, as opposed to the closed world assumption in task planning [9]).", "startOffset": 239, "endOffset": 242}, {"referenceID": 7, "context": "[12] use a high level topological representation of the environment to make inferences about the conflicts at an intersection (e.", "startOffset": 0, "endOffset": 4}, {"referenceID": 9, "context": "[14] propose a proportional integral controller to manage the congestion of traffic in vehicular ad hoc networks (VANETs).", "startOffset": 0, "endOffset": 4}, {"referenceID": 10, "context": "[15] in which a vehicle is a state automaton, and a probabilistic model is used to represent traffic in vehicular ad hoc networks.", "startOffset": 0, "endOffset": 4}, {"referenceID": 11, "context": "Other authors focus on emergency vehicles having de facto priority over regular traffic [3] [19].", "startOffset": 92, "endOffset": 96}, {"referenceID": 6, "context": "This model is composed of an ontology, representing the vehicles, the infrastructure and the traffic regulation (implemented in OWL with Prot\u00e9g\u00e9 [17]), and inference rules (implemented in SWRL [11]) computing the next motion of an intelligent vehicle under discretized time.", "startOffset": 193, "endOffset": 197}], "year": 2012, "abstractText": "Traffic regulation must be respected by all vehicles, either humanor computerdriven. However, extreme traffic situations might exhibit practical cases in which a vehicle should safely and reasonably relax traffic regulation, e.g., in order not to be indefinitely blocked and to keep circulating. In this paper, we propose a high-level representation of an automated vehicle, other vehicles and their environment, which can assist drivers in taking such \u201cillegal\u201d but practical relaxation decisions. This high-level representation (an ontology) includes topological knowledge and inference rules, in order to compute the next high-level motion an automated vehicle should take, as assistance to a driver. Results on practical cases are presented.", "creator": "Microsoft\u00ae Office Word 2007"}}}