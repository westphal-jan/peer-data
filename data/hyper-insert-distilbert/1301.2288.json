{"id": "1301.2288", "review": {"conference": "arxiv", "VERSION": "v1", "DATE_OF_SUBMISSION": "10-Jan-2013", "title": "Inference in Hybrid Networks: Theoretical Limits and Practical Algorithms", "abstract": "amongst an important subclass of modern hybrid bayesian symmetric networks are those, that represent inverse conditional - linear gaussian ( clg ) sampling distributions - - - a distribution problem with a multivariate gaussian kernel component for stopping each instantiation of reaching the discrete variables. in preparing this groundbreaking paper we explore the problem of inference in clgs. 1st we show confirmed that inference analysis in clgs can be significantly made harder than inference in bayes log nets. in particular, we prove that likewise even if the usual clg search is restricted to tracing an existing extremely simple structure modification of a polytree in which every continuous node has nowhere at most one discrete ancestor, the inference computation task factor is completely np - hard. thereby to deal with noting the often technically prohibitive computational cost of the exact competitive inference finding algorithm specifically for finding clgs, we explore finding several approximate partial inference algorithms. all these algorithms try so to continuously find a small subset value of null gaussians which are making a good approximation technique to assume the single full mixture distribution. secondly we consider extending two independent monte horn carlo approaches recently and a good novel approach that approaches enumerates purely mixture components in order of ignoring prior acquired probability. we compare these effective methods on understanding a variety weights of problems and show proving that our powerful novel algorithm base is employing very promising behavior for large, hybrid diagnosis problems.", "histories": [["v1", "Thu, 10 Jan 2013 16:24:54 GMT  (1206kb)", "http://arxiv.org/abs/1301.2288v1", "Appears in Proceedings of the Seventeenth Conference on Uncertainty in Artificial Intelligence (UAI2001)"]], "COMMENTS": "Appears in Proceedings of the Seventeenth Conference on Uncertainty in Artificial Intelligence (UAI2001)", "reviews": [], "SUBJECTS": "cs.AI", "authors": ["uri lerner", "ron parr"], "accepted": false, "id": "1301.2288"}, "pdf": {"name": "1301.2288.pdf", "metadata": {"source": "CRF", "title": "Inference in Hybrid Networks: Theoretical Limits and Practical Algorithms", "authors": ["Uri Lerner", "Ronald Parr"], "emails": ["uri@cs.stanford.edu", "parr@cs.duke.edu"], "sections": null, "references": [{"title": "Stable local compuation with con\u00ad ditional Gaussian distributions", "author": ["F. Jensen"], "venue": "Technical Report R-99-2014,", "citeRegEx": "Jensen.,? \\Q2014\\E", "shortCiteRegEx": "Jensen.", "year": 2014}], "referenceMentions": [], "year": 2011, "abstractText": "An important subclass of hybrid Bayesian networks are those that represent Conditional Linear Gaussian (CLG) distributionsa distribution with a multivari\u00ad ate Gaussian component for each instantiation of the discrete variables. In this paper we explore the prob\u00ad lem of inference in CLGs, and provide complexity re\u00ad sults for an important class of CLGs, which includes Switching Kalman Filters. In particular, we prove that even if the CLG is restricted to an extremely simple structure of a polytree, the inference task is NP-hard. Furthermore, we show that, unless P=NP, even ap\u00ad proximate inference on these simple networks is in\u00ad tractable. Given the often prohibitive computational cost of even approximate inference, we must take advantage of spe\u00ad cial domain properties which may enable efficient in\u00ad ference. We concentrate on the fault diagnosis domain, and explore several approximate inference algorithms. These algorithms try to find a small subset of Gaus\u00ad sians which are a good approximation to the full mix\u00ad ture distribution. We consider two Monte Carlo ap\u00ad proaches and a novel approach that enumerates mix\u00ad ture components in order of prior probability. We com\u00ad pare these methods on a variety of problems and show that our novel algorithm is very promising for large, hybrid diagnosis problems.", "creator": "pdftk 1.41 - www.pdftk.com"}}}