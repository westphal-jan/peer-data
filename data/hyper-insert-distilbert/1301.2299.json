{"id": "1301.2299", "review": {"conference": "arxiv", "VERSION": "v1", "DATE_OF_SUBMISSION": "10-Jan-2013", "title": "Approximating MAP using Local Search", "abstract": "map is the problem completion of problem finding and a most explicit probable instantiation of a set p of variables in basically a balanced bayesian graph network, otherwise given adequate evidence. unlike usual computing neural marginals, containing posteriors, \u03b1 and mpe ( a specialized special case of chaos map ), modeling the inherent time and probability space complexity of map is mostly not only exponential in the network treewidth, often but also in a larger distribution parameter known traditionally as using the \" constrained \" treewidth. in contemporary practice, this means that explicit computing neural map techniques can never be less orders of partial magnitude nor more expensive software than computingposteriors computation or distributed mpe. in thus, practitioners may generally avoid map computations, resorting instead to approximating dragging them together by using the most posterior likely information value factors for each map variableseparately, or by mpe. we additionally present quite a unique method for approximating discrete map using local search. actually this improved method has constant space complexity which is exponential since onlyin the treewidth, satisfying as is the required complexity expansion of each search complexity step. likewise we alternately investigate the effectiveness of producing different local progressive searchmethods and several initialization encoding strategies and compare them faster to these otherapproximation schemes. experimental results show directly that local slow search effort provides a much quicker more accurate cost approximation of map, while requiring several few direct search memory steps. doing practically, hopefully this means that the complexity index of local linear search is often exponential only in treewidth as opposed merely to overcoming the constrained treewidth, making approximating map as efficient commercially as other topological computations.", "histories": [["v1", "Thu, 10 Jan 2013 16:25:42 GMT  (951kb)", "http://arxiv.org/abs/1301.2299v1", "Appears in Proceedings of the Seventeenth Conference on Uncertainty in Artificial Intelligence (UAI2001)"]], "COMMENTS": "Appears in Proceedings of the Seventeenth Conference on Uncertainty in Artificial Intelligence (UAI2001)", "reviews": [], "SUBJECTS": "cs.AI", "authors": ["james d park", "adnan darwiche"], "accepted": false, "id": "1301.2299"}, "pdf": {"name": "1301.2299.pdf", "metadata": {"source": "CRF", "title": "Approximating MAP using Local Search", "authors": ["James D. Park"], "emails": ["}@cs.ucla.edu"], "sections": null, "references": [{"title": "Approximating probabilistic inference in bayesian belief networks is NP-hard", "author": ["Paul Dagum", "Michael Luby"], "venue": "Artificial Intelligence,", "citeRegEx": "3", "shortCiteRegEx": "3", "year": 1993}, {"title": "Any-space probabilistic infer\u00ad ence", "author": ["Adnan Darwiche"], "venue": "In 16th Conference on Uncertainty in Arti\u00ad ficial Intelligence,", "citeRegEx": "4", "shortCiteRegEx": "4", "year": 2000}, {"title": "A differential approach to infer\u00ad ence in bayesian networks", "author": ["Adnan Darwiche"], "venue": "In 16th Conference on Uncertainty in Artificial Intelligence,", "citeRegEx": "5", "shortCiteRegEx": "5", "year": 2000}, {"title": "Recursive conditioning", "author": ["Adnan Darwiche"], "venue": "Artifi\u00ad cial Intelligence,", "citeRegEx": "6", "shortCiteRegEx": "6", "year": 2001}, {"title": "Partial abductive inference in bayesian belief networks using a genetic algorithm", "author": ["L. de Campos", "J. Gamez", "S. Moral"], "venue": "Pattern Recognition Letters,", "citeRegEx": "Campos et al\\.,? \\Q1999\\E", "shortCiteRegEx": "Campos et al\\.", "year": 1999}, {"title": "Bucket elimination: A unifying framework for probabilistic inference", "author": ["Rina Dechter"], "venue": "In 12th Conference on Uncertainty in Artificial Intelli\u00ad gence,", "citeRegEx": "8", "shortCiteRegEx": "8", "year": 1996}, {"title": "Inference in belief networks: A procedural guide", "author": ["Cecil Huang", "Adnan Darwiche"], "venue": "In\u00ad ternational Journal of Approximate Reasoning,", "citeRegEx": "9", "shortCiteRegEx": "9", "year": 1996}, {"title": "Bayesian updating in recursive graphical models by local computation", "author": ["F.V. Jensen", "S.L. Lauritzen", "K.G. Olesen"], "venue": "Computational Statistics Quarterly,", "citeRegEx": "10", "shortCiteRegEx": "10", "year": 1990}, {"title": "Stochastic local search for bayesian networks", "author": ["K. Kask", "Rina Dechter"], "venue": "In Seventh International Workshop on Artificial Intelligence,", "citeRegEx": "11", "shortCiteRegEx": "11", "year": 1999}, {"title": "Triangulation of graphs-algorithms giving small total state space. Technical Report R-90-09", "author": ["U. Kjaerulff"], "venue": "Department of Mathematics and Com\u00ad puter Science,", "citeRegEx": "12", "shortCiteRegEx": "12", "year": 1990}, {"title": "Lo\u00ad cal computations with probabilities on graphical structures and their application to expert sys\u00ad tems", "author": ["L. Lauritzen", "D.J. Spiegelhalter"], "venue": "Journal of Royal Statistics Society, Series B,", "citeRegEx": "Lauritzen and Spiegelhalter.,? \\Q1988\\E", "shortCiteRegEx": "Lauritzen and Spiegelhalter.", "year": 1988}], "referenceMentions": [], "year": 2011, "abstractText": "MAP is the problem of finding a most prob\u00ad able instantiation of a set of variables in a Bayesian network, given (partial) evidence about the complement of that set. Unlike computing priors, posteriors, and MPE (a special case of MAP), the time and space complexity of MAP is not only exponen\u00ad tial in the network treewidth, but also in a larger parameter known as the \"constrained\" treewidth. In practice, this means that com\u00ad puting MAP can be orders of magnitude more expensive than computing priors, pos\u00ad teriors or MPE. For this reason, MAP com\u00ad putations are generally avoided or approxi\u00ad mated by practitioners. We have investigated the approximation of MAP using local search. The local search method has a space complexity which is ex\u00ad ponential only in the network treewidth, as is the complexity of each step in the search process. Our experimental results show that local search provides a very good approxima\u00ad tion of MAP, while requiring a small number of search steps. Practically, this means that the average case complexity of local search is often exponential only in treewidth as op\u00ad posed to the constrained treewidth, mak\u00ad ing approximating MAP as efficient as other computations.", "creator": "pdftk 1.41 - www.pdftk.com"}}}