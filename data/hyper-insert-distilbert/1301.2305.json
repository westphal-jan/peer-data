{"id": "1301.2305", "review": {"conference": "arxiv", "VERSION": "v1", "DATE_OF_SUBMISSION": "10-Jan-2013", "title": "Value-Directed Sampling Methods for POMDPs", "abstract": "we next consider demonstrating the problem above of performing approximate inverse belief - state initial monitoring feasible using particle filtering program for the purposes of implementing a policy update for a partially - observable markov decision process ( pomdp ). while particle filtering has earlier become commonly a widely - used enabling tool targeted in quantitative ai for monitoring concurrent dynamical systems, frequently rather scant attention focusing has been paid to their use in handling the context measurement of decision making. assuming the existence of only a stationary value function, we formally derive error bounds on decision quality limits associated with filtering using importance variable sampling. there we also then describe an adaptive procedure that can be therefore used to dynamically determine accurately the probable number of samples explicitly required but to indeed meet specific error measurement bounds. empirical evidence is well offered supporting this software technique as a frequently profitable means ahead of fully directing numerical sampling evaluation effort during where it is clearly needed to distinguish policies.", "histories": [["v1", "Thu, 10 Jan 2013 16:26:08 GMT  (1196kb)", "http://arxiv.org/abs/1301.2305v1", "Appears in Proceedings of the Seventeenth Conference on Uncertainty in Artificial Intelligence (UAI2001)"]], "COMMENTS": "Appears in Proceedings of the Seventeenth Conference on Uncertainty in Artificial Intelligence (UAI2001)", "reviews": [], "SUBJECTS": "cs.AI", "authors": ["pascal poupart", "luis e ortiz", "craig boutilier"], "accepted": false, "id": "1301.2305"}, "pdf": {"name": "1301.2305.pdf", "metadata": {"source": "CRF", "title": "Value-Directed Sampling Methods for Monitoring POMDPs", "authors": ["Pascal Poupart", "Craig Boutilier"], "emails": ["ppoupart@cs.", "leo@cs.", "cebly@cs."], "sections": null, "references": [{"title": "Tractable inference for complex stochastic processes", "author": ["Xavier Boyen", "Daphne Koller"], "venue": "In Proceedings of the Four\u00ad teenth Conference on Uncertainty in Artificial Intelligence,", "citeRegEx": "3", "shortCiteRegEx": "3", "year": 1998}, {"title": "Acting optimally in partially ob\u00ad servable stochastic domains", "author": ["Anthony R. Cassandra", "Leslie Pack Kaelbling", "Michael L. Littman"], "venue": "In Proceedings of the Twelfth National Conference on Artificial Intelligence,", "citeRegEx": "4", "shortCiteRegEx": "4", "year": 1994}, {"title": "On sequential monte carlo sampling methods for Bayesian filtering", "author": ["A. Doucet", "S.J. Godsill", "C. Andrieu"], "venue": "Statis\u00ad tics and Computing,", "citeRegEx": "6", "shortCiteRegEx": "6", "year": 2000}, {"title": "Rao-Blackwellised particle filtering for dynamic Bayesian networks", "author": ["Arnaud Doucet", "Nando de Freitas", "Kevin Murphy", "Stu\u00ad art Russell"], "venue": "In Proceedings of the Sixteenth Con\u00ad ference on Uncertainty in Artificial Intelligence,", "citeRegEx": "7", "shortCiteRegEx": "7", "year": 2000}, {"title": "Multiple Comparisons: Theory and Methods", "author": ["OJ Jason C. Hsu"], "venue": null, "citeRegEx": "Hsu.,? \\Q1996\\E", "shortCiteRegEx": "Hsu.", "year": 1996}, {"title": "CONDENSATION - con\u00ad ditional density propagation for visual tracking", "author": ["I I ] Michael Isard", "Andrew Blake"], "venue": "Interna\u00ad tional Journal of Computer Vision,", "citeRegEx": "Isard and Blake.,? \\Q1998\\E", "shortCiteRegEx": "Isard and Blake.", "year": 1998}, {"title": "Group Sequen\u00ad tial Methods with Applications to Clinical Trials", "author": ["Christopher Jennison", "Bruce W. Turnbull"], "venue": "Chapman & Hali/CRC,", "citeRegEx": "Jennison and Turnbull.,? \\Q2000\\E", "shortCiteRegEx": "Jennison and Turnbull.", "year": 2000}, {"title": "Approximate plan\u00ad ning for factored POMDPs using belief state simplification", "author": ["David McAIIester", "Satinder Singh"], "venue": "In Proceedings of the Fifteenth Conference on Uncertainty in Artificial Intelligence,", "citeRegEx": "McAIIester and Singh.,? \\Q1999\\E", "shortCiteRegEx": "McAIIester and Singh.", "year": 1999}, {"title": "Sampling methods for action selection in influence diagrams", "author": ["Luis E. Ortiz", "Leslie Pack Kaelbling"], "venue": "In Proceedings of the Seventeenth National Conference on Artificial Intelli\u00ad gence,", "citeRegEx": "Ortiz and Kaelbling.,? \\Q2000\\E", "shortCiteRegEx": "Ortiz and Kaelbling.", "year": 2000}, {"title": "Approximate value-directed belief state monitoring for partially observable Markov decision pro\u00ad cesses", "author": ["Pascal Poupart"], "venue": "Master's thesis,", "citeRegEx": "Poupart.,? \\Q2000\\E", "shortCiteRegEx": "Poupart.", "year": 2000}, {"title": "Vector-space analysis of belief state approximation for POMDPs", "author": ["Pascal Poupart", "Craig Boutilier"], "venue": "In Proceedings of the Seventeenth Conference on Uncertainty in Artificial In\u00ad telligence,", "citeRegEx": "Poupart and Boutilier.,? \\Q2001\\E", "shortCiteRegEx": "Poupart and Boutilier.", "year": 2001}, {"title": "The optimal control of partially observable Markov processes over a fi\u00ad nite horizon", "author": ["Richard D. Smallwood", "Edward J. Sondik"], "venue": "Operations Research,", "citeRegEx": "Smallwood and Sondik.,? \\Q1973\\E", "shortCiteRegEx": "Smallwood and Sondik.", "year": 1973}, {"title": "A prob\u00ad abilistic approach to concurrent mapping and localization for mobile robots", "author": ["Sebastian Thrun", "Dieter Fox", "Wolfram Burgard"], "venue": "Machine Learning,", "citeRegEx": "Thrun et al\\.,? \\Q1998\\E", "shortCiteRegEx": "Thrun et al\\.", "year": 1998}], "referenceMentions": [], "year": 2011, "abstractText": "We consider the problem of approximate belief-state monitoring using particle filtering for the purposes of implementing a policy for a partially observable Markov decision process (POMDP). While particle fil\u00ad tering has become a widely used tool in AI for monitor\u00ad ing dynamical systems, rather scant attention has been paid to their use in the context of decision making. As\u00ad suming the existence of a value function, we derive er\u00ad ror bounds on decision quality associated with filtering using importance sampling. We also describe an adap\u00ad tive procedure that can be used to dynamically deter\u00ad mine the number of samples required to meet specific error bounds. Empirical evidence is offered supporting this technique as a profitable means of directing sam\u00ad pling effort where it is needed to distinguish policies.", "creator": "pdftk 1.41 - www.pdftk.com"}}}