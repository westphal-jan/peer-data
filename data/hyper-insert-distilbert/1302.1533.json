{"id": "1302.1533", "review": {"conference": "arxiv", "VERSION": "v1", "DATE_OF_SUBMISSION": "6-Feb-2013", "title": "Model Reduction Techniques for Computing Approximately Optimal Solutions for Markov Decision Processes", "abstract": "we present secondly a method for consistently solving isolated implicit ( poorly factored ) intermittent markov decision processes ( mdps ) with very large state probability spaces. we firstly introduce on a property of two state space partitions which we call epsilon - euclidean homogeneity. more intuitively, putting an epsilon - homogeneous partition groups together observe states that behave approximately the same extent under all functions or some feasible subset of appropriate policies. borrowing steps from recent work on model error minimization in dynamic computer - aided software - verification, consider we present back an early algorithm approach that takes a factored mutual representation of \u00bb an mdp and an 0 & l lt ; = \u00bb epsilon & su lt ; = 1 \u00bb and simultaneous computes in a finite factored connected epsilon - homogeneous multiple partition of the contiguous state space. this partition roughly defines a finite family of related linear mdps - those mdps with state representation space constrained equal as to the blocks guarantee of satisfying the identity partition, and transition probabilities \" arise approximately \" like those regardless of any ( explicitly original inverse mdp ) state regions in the source block. to formally study reducing such families or of mdps, we accordingly introduce the fundamental new notion complexity of a \" generalized bounded implicit parameter cumulative mdp \" ( bmdp ), which further is a complexity family extension of ( traditional ) causal mdps methods defined by correctly specifying local upper and lower bounds on the primary transition distribution probabilities matrix and related rewards. we easily describe algorithms techniques that only operate on bmdps to find policies that are likewise approximately optimal with equal respect to crossing the larger original structural mdp. in combination, our method for reducing scaling a large implicit mdp collapses to a possibly much overly smaller bmdp using an epsilon - homogeneous composite partition, proving and demonstrating our corresponding methods for fully selecting simultaneous actions in interacting bmdps constitute a new modular approach for continuously analyzing any large implicit mdps. among its advantages, addressing this new integration approach provides insight into existing algorithms to solving limited implicit mutual mdps, provides commercially useful connections and to extended work in automata theory and optimal model minimization, provides and thus suggests methods, which notably involve varying the epsilon, to trade time differences and space ( specifically based in broad terms of estimated the size of the corresponding state space ) responsible for optimization solution quality.", "histories": [["v1", "Wed, 6 Feb 2013 15:54:52 GMT  (929kb)", "http://arxiv.org/abs/1302.1533v1", "Appears in Proceedings of the Thirteenth Conference on Uncertainty in Artificial Intelligence (UAI1997)"]], "COMMENTS": "Appears in Proceedings of the Thirteenth Conference on Uncertainty in Artificial Intelligence (UAI1997)", "reviews": [], "SUBJECTS": "cs.AI", "authors": ["thomas l dean", "robert givan", "sonia leach"], "accepted": false, "id": "1302.1533"}, "pdf": {"name": "1302.1533.pdf", "metadata": {"source": "CRF", "title": "Model Reduction Techniques for Computing Approximately Optimal Solutions for Markov Decision Processes", "authors": ["Thomas Dean", "Robert Givan", "Sonia Leach"], "emails": ["sml]@cs.brown.edu"], "sections": null, "references": [{"title": "D", "author": ["D.P. Bertsekas", "Castanon"], "venue": "A.", "citeRegEx": "Bertsekas and Castanon. 1989", "shortCiteRegEx": null, "year": 1989}, {"title": "Minimal state graph generation", "author": ["Bouajjani et al", "1992] Bouajjani", "J.\u00ad C. Fernandez", "N. Halbwachs", "P. Raymond", "C. Rate"], "venue": "Science of Computer Programming", "citeRegEx": "A. et al\\.,? \\Q1992\\E", "shortCiteRegEx": "A. et al\\.", "year": 1992}, {"title": "Craig and Dearden", "author": ["Boutilier"], "venue": "Richard", "citeRegEx": "Boutilier and Dearden. 1994", "shortCiteRegEx": null, "year": 1994}, {"title": "Planning under uncertainty: Structural as\u00ad sumptions and computational leverage", "author": ["Boutilier et al", "1995a] Boutilier", "Craig", "Thomas Dean", "Steve Hanks"], "venue": "In Proceed\u00ad ings of the Third European Workshop on Planning", "citeRegEx": "Craig et al\\.,? \\Q1995\\E", "shortCiteRegEx": "Craig et al\\.", "year": 1995}, {"title": "Exploit\u00ad ing structure in policy construction", "author": ["Boutilier et al", "1995b] Boutilier", "Craig", "Richard Dearden", "Moises Goldszmidt"], "venue": "In Proceedings IJCAI", "citeRegEx": "Craig et al\\.,? \\Q1995\\E", "shortCiteRegEx": "Craig et al\\.", "year": 1995}, {"title": "David; McMillan", "author": ["Jerry Burch", "Edmund M. Clarke", "Long"], "venue": "Kenneth L.; and Dill, David L.", "citeRegEx": "Burch et al.. 1994", "shortCiteRegEx": null, "year": 1994}, {"title": "Thomas and Givan", "author": ["Dean"], "venue": "Robert", "citeRegEx": "Dean and Givan. 1997", "shortCiteRegEx": null, "year": 1997}, {"title": "Thomas and Kanazawa", "author": ["Dean"], "venue": "Keiji", "citeRegEx": "Dean and Kanazawa. 1989", "shortCiteRegEx": null, "year": 1989}, {"title": "Sonia; and Dean", "author": ["Givan, Robert", "Leach"], "venue": "Thomas", "citeRegEx": "Givan et al.. 1997", "shortCiteRegEx": null, "year": 1997}, {"title": "J", "author": ["J.G. Kemeny", "Snell"], "venue": "L.", "citeRegEx": "Kemeny and Snell. 1960", "shortCiteRegEx": null, "year": 1960}, {"title": "Steve; and Weld", "author": ["Kushmerick, Nicholas", "Hanks"], "venue": "Daniel", "citeRegEx": "Kushmerick et al.. 1995", "shortCiteRegEx": null, "year": 1995}, {"title": "Online minimization of tran\u00ad", "author": ["nakakis", "Mihalis"], "venue": null, "citeRegEx": "nakakis and Mihalis,? \\Q1992\\E", "shortCiteRegEx": "nakakis and Mihalis", "year": 1992}, {"title": "Iter\u00ad ative aggregation-disaggregation procedures for dis\u00ad counted semi-Markov reward processes. Operations Research 33(3):589-605", "author": ["Schweitzer et al", "1985] Schweitzer", "Paul J", "Martin L. Puter\u00ad man", "Kyle W. Kindle"], "venue": null, "citeRegEx": "J. et al\\.,? \\Q1985\\E", "shortCiteRegEx": "J. et al\\.", "year": 1985}], "referenceMentions": [{"referenceID": 9, "context": "cesses has its origins in automata theory [Hartmanis and Stearns, 1966] and stochastic processes [Kemeny and Snell, 1960] and has surfaced more recently in the work on model checkin\ufffd in computer-aided verifica\u00ad tion [Burch et al.", "startOffset": 97, "endOffset": 121}, {"referenceID": 6, "context": "Building on the work of Lee and Yannakakis [ 1992], we have shown [Dean and Givan, 1997] that several existing algorithms are asymptotically equivalent to first constructing the minimal reduced MDP and then solving this MDP using traditional methods that op\u00ad erate on the flat (unfactored) representations.", "startOffset": 66, "endOffset": 88}, {"referenceID": 8, "context": "Although BMOPs are introduced here to represent approximate aggre\u00ad gations, they are interesting in their own right and are discussed in more detail in [Givan et al., 1997], The model reduction algorithms and bounded parameter MDP solution methods can be combined to find ap\u00ad proximately optimal solutions to large factored MOPs, varying E to trade time and space for solution quality.", "startOffset": 152, "endOffset": 172}, {"referenceID": 8, "context": "We will write of bounding the (optimal or policy specific) value of a state in a BMDP-by this we mean providing an up\u00ad per or lower bound on the corresponding state value over the entire family of MDPs :F M\u00b7 For a more thor\u00ad ough treatment of BMDPs, please see [Givan et al., 1997].", "startOffset": 261, "endOffset": 281}, {"referenceID": 10, "context": "Factored Representations In the remainder of this paper, we make use of Bayesian networks [Pearl, 1988] to encode implicit (or factored) representa\u00ad tions; however, our methods apply to other factored representations such as probabilistic STRIPS opera\u00ad tors [Kushmerick et al., 1995].", "startOffset": 258, "endOffset": 283}, {"referenceID": 7, "context": "[Dean and Kanazawa, 1989] The state-transition probabilities are now factored as", "startOffset": 0, "endOffset": 25}, {"referenceID": 8, "context": "Bounded parameter MDPs are interesting objects and we explore them at greater length in [Givan et al., 1997].", "startOffset": 88, "endOffset": 108}], "year": 2011, "abstractText": "We present a method for solving implicit (factored) Markov decision processes (MDPs) with very large state spaces. We intro\u00ad duce a property of state space partitions which we call f-homogeneity. Intuitively, an f-homogeneous partition groups together states that behave approximately the same under all or some subset of policies. Borrow\u00ad ing from recent work on model minimization in computer-aided software verification, we present an algorithm that takes a factored representation of an MDP and an 0 \ufffd f \ufffd I and computes a factored f-homogeneous par\u00ad tition of the state space. This partition defines a family of related MOPs-those MOP's with state space equal to the blocks of the partition, and transition probabilities \"appro:X:imately\" like those of any (original MDP) state in the source block. To formally study such families of MDPs, we introduce the new notion of a \"bounded parameter MDP\" (BMDP), which is a fam\u00ad ily of (traditional) MOPs defined by speci\u00ad fying upper and lower bounds on the transi\u00ad tion probabilities and rewards. We describe algorithms that operate on BMDPs to find policies that are approximately optimal with respect to the original MDP. In combination, our method for reducing a large implicit MDP to a possibly much smaller BMDP using an f-homogeneous par\u00ad tition, and our methods for selecting actions in BMDP's constitute a new approach for an\u00ad alyzing large implicit MOP's. Among its ad\u00ad vantages, this new approach provides insight into existing algorithms to solving implicit MDPs, provides useful connections to work in automata theory and model minimization, and suggests methods, which involve vary\u00ad ing f, to trade time and space (specifically in terms of the size of the corresponding state space) for solution quality.", "creator": "pdftk 1.41 - www.pdftk.com"}}}