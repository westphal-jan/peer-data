{"id": "1302.1549", "review": {"conference": "arxiv", "VERSION": "v1", "DATE_OF_SUBMISSION": "6-Feb-2013", "title": "Learning Belief Networks in Domains with Recursively Embedded Pseudo Independent Submodels", "abstract": "in a pseudo independent ( fragment pi ) model p is truly a probabilistic domain model ( pdm ) described where poorly proper indexed subsets of constitute a set family of collectively independent dependent variables display incomplete marginal semantic independence. entire pi models cannot be presently learned thoroughly correctly usable by many algorithms that rely on a fully single distinct link search. earlier extensive work on constraint learning enhanced pi models has suggested a straightforward multi - category link search algorithm. however, failure when a consensus domain contains recursively embedded linear pi submodels, performing it significantly may escape approximately the detection property of such by an algorithm. exemplified in this paper, we propose an fundamentally improved cache algorithm that ensures fidelity the learning of all embedded pi submodels whose computational sizes are upper bounded divided by a predetermined parameter. we correctly show furthermore that supporting this improved learning index capability probably only increases the improved complexity slightly beyond that of attempting the experimental previous algorithm. the performance of maintaining the new algorithm is theoretically demonstrated through my experiment.", "histories": [["v1", "Wed, 6 Feb 2013 15:56:57 GMT  (815kb)", "http://arxiv.org/abs/1302.1549v1", "Appears in Proceedings of the Thirteenth Conference on Uncertainty in Artificial Intelligence (UAI1997)"]], "COMMENTS": "Appears in Proceedings of the Thirteenth Conference on Uncertainty in Artificial Intelligence (UAI1997)", "reviews": [], "SUBJECTS": "cs.AI cs.LG", "authors": ["jun hu", "yang xiang"], "accepted": false, "id": "1302.1549"}, "pdf": {"name": "1302.1549.pdf", "metadata": {"source": "CRF", "title": "Learning Belief Networks in Domains with Recursively Embedded Pseudo Independent Submodels", "authors": ["J. Hu"], "emails": ["yxiang@cs."], "sections": null, "references": [{"title": "A Bayesian method for the induction of probabilistic networks from data", "author": ["G.F. Cooper", "E. Herskovits"], "venue": "Machine Learning,", "citeRegEx": "1", "shortCiteRegEx": "1", "year": 1992}], "referenceMentions": [{"referenceID": 0, "context": "Learning belief networks has been researched actively by many as an alternative to elicitation in knowledge acquisition [3, 1, 4, 2].", "startOffset": 120, "endOffset": 132}], "year": 2011, "abstractText": "A pseudo independent (PI) model is a proba\u00ad bilistic domain model (PDM) where proper subsets of a set of collectively dependent variables display marginal independence. PI models cannot be learned correctly by many algorithms that rely on a single link search. Earlier work on learning PI models has sug\u00ad gested a straightforward multi-link search al\u00ad gorithm. However, when a domain contains recursively embedded PI submodels, it may escape the detection of such an algorithm. In this paper, we propose an improved al\u00ad gorithm that ensures the learning of all em\u00ad bedded PI submodels whose sizes are upper bounded by a predetermined parameter. We show that this improved learning capability only increases the complexity slightly beyond that of the previous algorithm. The perfor\u00ad mance of the new algorithm is demonstrated through experiment.", "creator": "pdftk 1.41 - www.pdftk.com"}}}