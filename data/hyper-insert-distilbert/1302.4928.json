{"id": "1302.4928", "review": {"conference": "arxiv", "VERSION": "v1", "DATE_OF_SUBMISSION": "20-Feb-2013", "title": "Graphical Models for Preference and Utility", "abstract": "probabilistic operational independence can dramatically effectively simplify the task of visually eliciting, representing, and computing with certain probabilities predicted in two large domains. a second key technique advanced in achieving these benefits is the idea of graphical action modeling. we survey existing notions of independence for utility functions in computing a multi - layered attribute structure space, algorithms and suggest that these can gradually be used to achieve similar advantages. our respective new analysis results concern conditional nonlinear additive utility independence, utility which we show technically always has a certain perfect allocation representation as separation in an undirected graph ( a markov network ). conditional additive additive power independencies collectively entail a functional particular inference functional for excluding the utility function that is considered analogous essentially to a product decomposition of reducing a probability function, benefits and confers broadly analogous benefits. this functional form has just been utilized commercially in discovering the bayesian network algorithms and multiple influence interaction diagram framework literature, standardized but generally available without an artificial explanation in terms estimates of independence. applying the functional form likewise yields a decomposition of removing the simple utility function above that can greatly substantially speed up calculating expected utility of calculations, particularly when the utility graph presumably has a strongly similar topology needing to assume the hierarchical probabilistic incentive network actually being used.", "histories": [["v1", "Wed, 20 Feb 2013 15:18:51 GMT  (284kb)", "http://arxiv.org/abs/1302.4928v1", "Appears in Proceedings of the Eleventh Conference on Uncertainty in Artificial Intelligence (UAI1995)"]], "COMMENTS": "Appears in Proceedings of the Eleventh Conference on Uncertainty in Artificial Intelligence (UAI1995)", "reviews": [], "SUBJECTS": "cs.AI", "authors": ["fahiem bacchus", "adam j grove"], "accepted": false, "id": "1302.4928"}, "pdf": {"name": "1302.4928.pdf", "metadata": {"source": "CRF", "title": "Graphical models for preference and utility", "authors": ["Fahiem Bacchus", "Adam Grove"], "emails": ["tbacchus@logos.uwaterloo.ca", "grove@research.nj.nec.com"], "sections": [{"heading": null, "text": "1 Introduction\nWork over the past decade in artificial intelligence concern ing probabilities has been extremely successful. Charges of epistemological inadequacy [MH69] have become much easier to rebut since the advent of Bayesian networks and similar techniques.\nBut probabilities are not an end in themselves. Their most important purpose is in classical decision theory, as part of the maximum expected utility paradigm (see, e.g., [Fre88, GS88, Sav54]). This leads to the concern that other parts of decision theory might not be keeping pace with the new developments in probabilistic modeling. In particular, we are interested in the problem of representing, and reasoning about, utility and preference.\nThere are a number of important questions in this area,\nand here we report on our early observations and results and make a few conjectures about promising directions for future research. The approach we take is based on the idea of drawing a close analogy between probabilities and utilities. It is clear that some of the issues are similar:\n\u2022 The \"too many numbers!\" criticism of probability theory can apply to utilities as well. The number of possible worlds grows exponentially in the number of properties (i.e., attributes or variables) used to describe them. In principle, each world might require an inde pendently assigned utility. Of course, we may be lucky enough that a world's utility depends on just a few at tributes. In this case many different possible worlds will have the same utility and we will have far fewer distinct values to deal with. But we cannot rely on this in general.\n\u2022 Probabilities can be difficult to elicit and to compute with. For this reason, there have been many attempts to deal with uncertainty in a way that avoids proba bility, even though many (although not all) of these approaches are ad hoc and lack any solid foundation. Correspondingly, there are several common ways to describe how one wants a complex system to behave short of actually giving utilities: e.g., one can list pre ferred goals, impose hard or soft constraints on behav ior, and so on.\nGraphical models, such as Bayesian networks, address many of the perceived problems of probability in a fairly successful fashion (see, e.g., [Pea88, SP90] for an introduc tion to this area). The key trick, of course, is probabilistic independence. Independence can vastly reduce dimension ality, in the sense of the number of independent parameters we must discover. We can make many judgments of inde pendence based on a qualitative (typically causal) under standing of the domain, and afterwards elicit or learn the remaining conditional probabilities. But reduction of di mensionality is not the whole story: probabilistic indepen dence lends itself to graphical representations that greatly aid intuition and support relatively efficient computational techniques.\nCan a similar story be told for utilities? This is plausible because utility, like probability, is often highly structured.\n4 Bacchus and Grove\nFurthermore, much (but not all) of this structure can be de scribed in terms of independence, using one or all of several independence concepts that already exist in the literature. We begin this paper, in Section 2, with background mate rial including a brief survey of some existing independence concepts in utility theory. We note that these concepts are part of a well established field known as multiple-objective decision theory, for which [KR76] is an excellent reference.\nSo far as we are aware, the relevance of the results in this field for artificial intelligence is a largely unexplored topic (although [DW91, DSW9 1, DW94, DW92] are exceptions to this, and there is a growing collection of work concerned with other aspects of utility such as [Bou94, TP94]). Our main results in this paper are in Section 3 and concern con ditional additive independence (CA-independence), whose definition is reviewed in Section 2. This concept seems to strike a good balance between being too weak (thus lead ing to few useful conclusions) and too stringent (thus being infrequently applicable).\nOur first result in Section 3 shows that this notion has a precise representation as separation in undirected graphs. This result is closely related to the theory of graphoids and Markov fields; see [Pea88] for a description of these notions.\nA utility function satisfies a CA-independence if and only if it can be written in a particular functional form. This functional form is an additive decomposition of the utility function, that is analogous to a product decomposition of a probability function and leads to a similar reduction of dimensionality. Our results show how this functional form can be read directly from the graph that represents the CA independencies of the utility function.\nAs we briefly discuss in Section 3.1, an additive utility de composition can simplify expected utility and related com putations. Tatman and Shachter [ST90] show one way to take advantage of this phenomenon in influence diagram computation. If we are given a probabilistic network with a topology that is \"similar\" to our utility graph, the potential for computational speedup would appear to be especially great. This is implicitly reflected in Jensen et al.'s work [JJD94], which gives another technique for evaluating in fluence diagrams.\nBoth [JJD94] and [ST90] take an additive utility function as their starting point. They do not address the question of where the decomposition comes from. In that sense the results of this paper can be seen to be complementary to these works. We discuss the notions of utility independence that allow such decompositions of the utility function, and make a start at providing some graphical modeling tools for dealing with these notions of independence. The final part of this paper, Section 4, briefly mentions some topics that we believe are promising directions for future work.\n2 Preliminaries\nDecision theory is useful in a setting where the system (the world) may end up in one of several possible states. If we\nhave some control (via our actions) as to which state obtains, we need to know how to choose the best action. As is well known, there are several axiomatizations of \"rational\" decision making that lead to the maximum expected utility criterion (see, e.g., [Fre88, GS88, Sav54]). This says that we should attempt to maximize the sum, over all states, of the product of the probability and the utility of each state. So if the probability distribution depends on the action we take, this criterion can determine the best action. We begin with a very quick review of the relevant concepts, mainly to set up the necessary notation. This review is based on the following sources [Fis82, Fre88, KR76, KLST71].\nIf there are N states a probability distribution and util ity function have N -1 and N-2 independent parameters, respectively.1 Unfortunately N is often very large, expo nential in the number of attributes or variables we use to describe a state. Thus it is important that the utility function possess some structure so as to simplify the tasks of elici tation, representation, and computation. This is of course exactly what graphical models based on independence try to achieve for probabilities.\nAs in the probabilistic network literature, our first assump tion is that the set of states can be represented as a product space over some set of attributes or variables.\nNotation: Throughout this paper, we assume that V = { v1, . . \u2022 , v,.} is a fixed set of n variables. Each variable v has a domain d'IJ of two or more elements.2 We will generally use lower case letters to denote variables and upper case letters to denote sets of variables. (Note that this is somewhat nonstandard.) Where necessary, Greek letters will denote values for particular variables. The set of states S consists of the set of points in the product space fl:=t d'IJ,. Each s E Sis thus a vector of n values, one value for every variable. Clearly the size of S is exponential in the number of variables. If X \ufffd V then /(X) stands for some real valued function all of whose arguments are in X, i.e.,\nf(X) : II d'IJ -+ IR 'II EX\nThe general form of a utility function is u(V), which can thus require exponentially many independent utility assess ments.\nA utility function u induces a preference ordering \ufffd .. on lotterie\ufffd (probability distributions) overS as follows:"}, {"heading": "Pl \ufffd .. P2 iff LPt(s)u(s) \ufffd LP2(s)u(s),", "text": "1 Utility theory is invariant with respect to affine transforma tions of the utility function, which is why only N -2 independent utilities need be found.\n2Everything we say applies for infinite domains as well. Al though we implicitly assume that domains are finite in parts of the following, this is for notational and conceptual simplicity only.\n3\"Lotteries\" is one of the traditional terms. It can be misleading in that it tends to imply that the probabilistic structure arises from explicit randomization or \"objective\" randomness. This may be the case, but on the other hand the probabilities can also be an entirely subjective measure of uncertainty.\nwhere P1 and p2 are two distributions overS. That is, we prefer Pl to P2 if Pl induces greater expected utility. Thus utility serves to characterize not only the agent's values but also its attitudes towards risk: it ranks probabilistic gambles between various outcomes.\nIn the development of decision theory, it is natural to take the preference relation as primitive. Any relation satisfying fairly weak rationality conditions (which we don't repeat here, but see, e.g., [Sav54, Fis82, Fre88]) corresponds to some utility function exactly as above (that is, furthermore, unique up to affine transformations). This exact correspon dence between preference and utility is one of the fun damental theorems of decision theory. In the following, whenever we talk about a preference over V we mean a preference over lotteries overS= Ilvev d11 satisfying the standard rationality postulates.\nThe first definition of independence we consider is utility independence. Intuitively, a set of attributes X is utility independent of everything else, if when we hold every thing else fixed (i.e., the values of attributes V-X), the induced preference structure over X does not depend on the particular values that V -X are fixed to. Given utility independence we can assert preferences over (lotteries on) X that hold ceteris paribus-i.e., all else being equal.\nDefinition 2.1 : Consider preference!:: over V, X c V, Y = V-X. Let .:Y be any particular element of Ilv EY dv. That is, .:Y is a particular assignment of values to the vari ables in Y. Every probability distributionp over TivEX d11 corresponds to a distributionp\u2022 on S = TivEV d11 such that p* 's marginal on X is p and p\u2022 's marginal on Y gives prob ability 1 to ,:Y. We define the conditional preference over X given .:Y, \ufffd'Y. to be the preference ordering such that\np !::y q iff p* !:: q*'\nwhere p and q are any two distributions over Ilv EX d11\u2022 I\nDefinition 2.2: The set of attributes X is utility independent of V-X when conditional preferences for lotteries on X do not depend on the particular value given to V -X. That is,\n('</;,;' E II d11) p b\u00b7 q iffp !:'Y' q, vEV-X\nwhere p and q are any two distributions over Ilv EX dv. I\nUtility independence fails, for instance, if one has a pref erence reversal between two mixtures of the attributes X, when some attribute in V-X is changed. Judgments of utility independence would appear to be fairly natural and common; see [KR76] for a very extensive discussion. They are, at heart, judgments about relevance and people seem to be fairly good at this in general.\nExample 2.3: Say that there are only two attributes health, with values H and H (healthy and not healthy), and wealth with values W and W (wealthy and not wealthy). If the agent's utility function u is defined as u(HW) = 5, u(HW) = 2, u(HW) = 1, and u(HW) = 0, then it can\nGraphical models for preference and utility 5\nbe seen that for the agent health is utility independent of wealth and wealth is utility independent of health. Intu itively, no matter what the agent's wealth is fixed to, it will\u00b7 always prefer gambles that yield H with higher probability. That is, the agent's preference for being healthy is the same no matter if the agent is wealthy or not. The same can be said about its attitude towards being wealthy. I\nUtility independence is known to have several strong impli cations. We list a few, using [KR76] as our source. First, utility independence is equivalent to the existence of a utility function with a special functional form:\nProposition 2.4: X is utility independent of its complement in a preference structure!:: if and only if!: corresponds to some utility function of the form:\nU>-(V) = f(V -X)+ g(V -X)h(X)\nwhere g is positive. 4\nThus we must assess three functions, but each has fewer than lVI arguments. This may mean that there are far fewer independent numbers to learn and to store. Most of the interest in utility independence in standard decision theory concerns the case of mutual utility independence where every subset of variables is independent of its complement:\nProposition 2.5: Every subset of variables is independent of its complement in !:: if and only if there exists n functions j,(v,) (i.e., each f\u2022 t!epends on a single variable), such that either n\nut(X) = ITMvi)+c\nfor some constant c, or n\nut(X) = L li(v1).5 i=l\nThis is an extremely strong conclusion, allowing enormous simplification. The precondition of the theorem might seem to require 0(2n) utility independence conditions, but since utility independence satisfies various closure properties we do not need this many. There are in fact several sets of n independencies that suffice; see [KR76]. However, then assertions that each attribute individually is independent of the rest are not sufficient. In this case, the result is weaker:\nProposition 2.6: If every variable is utility independent of the rest there is a function /i ( v,) for each variable, such that u>-(V) is a multilinear combination of the f\u2022 's.\nThus we must assess n functions as well as (potentially exponentially many) constants to capture the interactions\n4 It is also clearly possible to arrange f and g so that h( X) = u>-(X,.:Y) where .:Y is an arbitrary fixed assignment to V-X. The function 'IL>-(X, .:Y) is sometimes called a conditional utility function. -\n51t is more usual to express the /i in terms of conditional conditional utility functions and multiplicative constants. This representation is easy to derive, or see [KR76].\n6 Bacchus and Grove\namong the /i 's. This may still represent a net gain. We suggest in Section 4 that this case might be important for artificial intelligence, and deserves future work.\nA much stronger form of independence is additive indepen dence. This can be defined in several ways, but the most useful for us is:\nDefinition 2.7: Let Z1, ... , z,. be a partition ofV. Z1, . .. , z,. is additively independent (for \ufffd) if, for any probability distributions Pl and P2 that have the same marginals on z, for all i, P1 and P2 are indifferent under \ufffd, i.e., P1 \ufffd P2 andp2 \ufffd Pl\u00b7 I\nIn other words, one's preference only depends on the marginal probabilities of the given sets of variables, and not on any correlation between them.\nExample 2.8: Consider the utility function given in Exam ple 2.3 involving health and wealth. As the previous exam ple pointed out, health was utility independent of wealth. However health is not additively independent of wealth. Consider the two probability functions P1 and P2\u00b7 where Pl(HW) = Pl(HW) = Pl(HW) = P1(HW) = 1/4, and P2(HW) = P2(HW) = 0, P2(HW) = P2(HW) = 1/2. We have Pl(H) = P2(H) = 1/2 and Pl(W) = P2(W) = 1/2. That is, P1 and P2 have identical marginals over health and wealth. Yet the expected utility under P1 is 2, while the expected utility under p2 is 5/2. This shows that there exists two distributions with the same marginals that are not indifferent under the given utility function. That is, health and wealth are not additively independent.\nIntuitively, the agent prefers being both healthy and wealthy more than might be suggested by considering the two at tributes separately. It thus displays a preference for proba bility distributions in which health and wealth are positively correlated. I\nProposition 2.9 : Z1, ... , z,. are additively independent for\ufffd iffu't can be written as\n\" u't(V) = L f(Z,)\ni=l\nfor some functions k\nNaturally, the most interesting case is where all variables are additively independent separately, so that we only need to find one single-argument function for each variable. In the rest of the paper, we will be interested in additive indepen dence for a partition of V into two parts, V = XU Y, unless we say otherwise. It would seem reasonable that these are easier to reason with than independence assertions about arbitrary partitions.\nConditional versions of both additive and utility indepen dence can be defined. The definitions require that the spec ified independence hold whenever some subset of variables are held fixed. For instance,\nDefinition 2.1 0 : X and Y are conditionally additively independent (CA-independent) given Z (X, Y, Z disjoint,\nX U Y U Z = V) iff, for any fixed value 1 of Z, X and Y are additively independent in the conditional preference structure over X U Y given -r. In this case, we write CAl (X, Z, Y). I\nProposition 2.1 1 : X and Y are additively independent givenZiffu't can be written in the formf(X, Z)+ f(Z, Y).\n3 Conditional Additive Independence\nOur main new results concern CA-independence and are presented in this section. As mentioned above, the concept of CA-independence has been defined in the literature, but we have found rather little development of the idea. We nevertheless feel that CA-independence is a useful notion for artificial intelligence. In particular, it is not as strong a requirement as additive independence: it is quite feasible that some variables that are not additively independent be come additively independent when the values of some other variables are fixed. Furthermore, while it is not as generally applicable as utility independence, utility independence of ten does not yield a decomposition of the utility function that is as computationally useful. In fact, the decomposition yielded by CA-independence can significantly improve the efficiency of computing expected utility (see Section 3.1).\nOur results here are that CA-independence is particularly well suited for graphical modeling. In brief, we show the following. First, every utility function has a perfect CA independence graph: a graph in which vertex separation corresponds exactly to CA-independence. And second, it is possible to read directly from the graph the most general functional form for utility functions satisfying the repre sented independencies. In the presence of nontrivial inde pendencies, this form typically has a much reduced \"dimen sionality\", making elicition, representation, and reasoning far easier.\nOur first definition defines the type of functional form we are after. We want the utility to be composed from functions with proper subsets of V as arguments-the fewer the argu ments the better, as the complexity of specifying a function explicitly (i.e., as a table) is exponential in the number of arguments. Furthermore, as mentioned above, the utility should be a linear combination of these subfunctions.\nDefinition 3.1 : Let Z1, ... , z,. be (not necessarily disjoint) subsets of V. A function f(V) has an additive decomposi tion over zl, ... ' z,. if\n\" f = Lf\u2022(Zi)\ni=l\nfor some functions f\u2022 . I\nClearly there is no loss of generality to assume that for no i ,j is z, \ufffd Zj.\nThis form of functional decomposition has been used before in the literature [JJD94, DDP88, ST90], but without any justification in terms of notions of utility independence. As\nProposition 2.11 shows a utility function can be written in this form only if some collection of CA-independencies hold.\nUsing this definition, we may rephrase Proposition 2.11 as saying that a utility function satisfies CAl (X, Z, Y) if and only if it has an additive decomposition over XU Z, Z U Y. Although we are ultimately interested in the components present in an additive decomposition (in particular, making them as few and as small as possible), proving the main theorems below sometimes requires that we focus on com ponents that are absent instead.\nDefinition 3.2: Let Z1, ... , z.,. be (not necessarily disjoint) subsets of V . A function f(V) has an additive decomposi tion that avoids Zt, ... , z.,. if\nl\nt = L:ti(Yi) i=l\nfor some fi and some l subsets Yi C V such that for no i, j is z i \ufffd lj.l\nIt is easy to verify using Proposition 2.1 1 that CAI(X, Z, Y) iff there is an additive decomposition avoiding all { :z, y} such that :z E X and y E Y ; we use this in the proofs below.\nIf u has a decomposition avoiding X, and another avoiding Y, dcies it have another decomposition avoiding both? It might seem plausible that there are functions in which an interaction term in either X or Y is necessary, but such that either one of these suffices. However, this is not in fact possible, and the answer to the question above is always yes. The next lemma, which generalizes this claim, will be used in several places subsequently.\nLemma 3.3: If a utility function u(V) has decompositions avoiding each of X1, X2, \u2022 \u2022 \u2022 , X.,. C V separately then it has a decomposition avoiding them all.\nProof: Omitted. I\nNow we are in a position to prove our first main result. This says that, for any utility function, there is an undirected graph G = (V, E) (i.e., the nodes are the attributes) such that CA/(X, Z, Y) (for X U Y U Z = V) if and only .if Z separates X from Y, i.e., every path from a node m X to a node in Y passes through some node in Z. In the terminology of [Pea88] such a graph is said to be a perfect map of the independence structure. Pearl and Paz [PP89] have given necessary and sufficient conditions for an independence relation to have such a map (see also [Pea88 ]), and we can simply apply this result in the proof below. Note that if follows that if two attributes are linked by an edge in a perfect graph for CA-independence, then we always care about the (probabilistic) correlation between their values. If there is no edge then, once all the remaining variables are given fixed values, we do not care whether the endpoint attributes are determined independently or not (i.e., this is irrelevant to our preferences).\nGraphical models for preference and utility 7\nTheorem 3.4: The set of CA-dependencies generated by any utility function has a perfect map.\nProof: It is sufficient to simply check each of the five conditions given by Pearl and Paz. The main difficulty is that these conditions concern expressions of the form I(X, Y, Z) in which X U Y U Z need not equal V, but we have not defined CA-independence in this case. So, for the purposes of this proof only, we make the following . definition. If R = V -X -Y -Z ::j:. 0, \ufffdhen CAl (X, Y, Z) holds iff there is some partition R = Rt U R2 such that CAI(X U Rt, Z, Y U R2). We now simply verify the con ditions, which must hold for all sets of disjoint arguments.\nSymmetry: CA/(X, Z, Y) => CAI(Y, Z,X). This is im mediate by the definition.\nDecomposition: CA/(X, Z, Y U W) => CA/(X, Z, Y) 1\\ CAl (X, Z, W). This follows from the extended defi nition give above (because we can choose R2 to contain W or Y as appropriate).\nIntersection: CAI(X, ZUW, Y)l\\ CAI(X, ZUY, W) => CAI(X,Z, Y U W). Let R = V-X-Y -Z-W. By assumption, there are two partitions of R, Rt. R2 and R\ufffd, R\ufffd say, such that CAI(X U Rt, Z U W, Y U R2) and CAI(X U R\ufffd, Z U Y, W U R\ufffd) hold. Let R\ufffd = R1 n R\ufffd and R\ufffd = R2 U R\ufffd; note that R\ufffd U R\ufffd = R. From the above it is easy to verify that, for each v1, v2 with v1 E X U R\ufffd and v2 E Y U W U R\ufffd, there is an additive decomposition avoiding { v1, v2} . By the lemma, there is an additive decomposition avoiding them all at once. Thus CAl (XU R\ufffd, Z, Y U W U R\ufffd). i.e., CAI(X, Z, Y U W) as required.\nStrong union: CAl (X, Z, Y) => CAl (Y, ZUW, X). This follows easily, because each v E W is either in Rt or R2 and so, according to the antecedent, the utility can be decomposed so that v appears with X U Z or Y U Z but not both. The consequent allows it to appear with both, and so is strictly weaker.\nTransitivity: CAI(X,Z,Y) => CAI(Y,Z,w) V CAI(w ,Z,Y) where w is any single variable. By disjointness, we do not consider w E Z. Otherwise, find Rt and R2 such that CAl (XUR11 Z, YUR2); these must exist by defi nition. But then w E R1 or w E R2, and in either case the result follows immediately using decomposition.\nThus, we can appeal to Pearl and Paz's result to conclude the proof. I\nIt follows from the proof of this theorem that any CA independence model induced by a utility function is a graphoid, in the sense of [PP89]. The book [Pea88] dis cusses graphoids, and their graphical maps, in considerable detail. Note that an undirected graphical model of the type we consider is also called a Markov network.\nPart of the utility of this theorem is that we can represent and reason about CA-independencies graphically, which is often far more natural. However, another benefit is that we can read the functional form of the utility function directly\n8 Bacchus and Grove\nfrom its corresponding Markov network in the standard fashion (i.e., by identifying the cliques of the graph).\nTheorem 3.5: G = (V, E) is a CA-independence map for a utility function u (i.e. , all independencies suggested by vertex separation in the graph hold of u ) if and only if u has an additive decomposition over the set of maximal cliques of G.\nProof: First, suppose u has such an additive decomposition, and let X, Y, Z be a partition of V such that Z separates X from Y in G. We must show that CAl (X, Z, Y) holds of u. But no clique in G can contain an element from both X andY (otherwise, no separator would exist). Thus, the hypothesized decomposition has no term involving vari ables from both X and Y. The result now follows from Proposition 2.11.\nConversely, suppose G is a CA-independence map of u. Let Y be a proper superset of any maximal clique. There exists an additive decomposition over cliques if there is a decomposition avoiding all such Y. By Lemma 3.3, it suffices to consider each Y separately. Suppose, for a con tradiction, that it is impossible to avoid Y. Let X C Y be a maximal clique. There must be some y E Y such that not all members of X are connected toy in G. (Otherwise, XU y is a larger clique). Let :z: E X not be connected to y by an edge. But then V- {:z:, y} separates z andy, and so CAl ( { :z:} , V- { :z:, y} , {y} ), hence there is a decompo sition avoiding {:z:, y}, and hence avoiding Y. This gives the necessary contradiction. I\nThis means that we can read a suitable function form di rectly from the graph, by finding cliques. Unless the graph is complete, this gives us a nontrivial decomposition of u. By Theorem 3.4, the procedure of finding a graph using CA-independence and then using it this way is capable of re vealing all the information inherent in CA-independencies. In a sense, this is quite a strong result. Probabilistic inde pendence does not always admit perfect Markov networks. Thus, while probabilistic independence maps are certainly a useful technique, they do not have the same power as if we were to just reason about independence directly. On the other hand, this contrast is a bit misleading. Although graphical models can capture CA-independence perfectly, the concept of CA-independence itself is somewhat weak.\nExample 3.6: Consider all utility functions over three vari ables of the form\nu(:z:, y, z ) = /(:z:, y) + f(y, z) + /(:z:, z) . It is easy to verify that there are no independencies (utility or additive, conditional or otherwise) that are common to all such functions. The CA-independence is a complete graph (a triangle) and so does not reflect the fact that u has quite a simple form. I\nThis shows that certain linear functional forms, that entail just the computational and representational advantages we seek, are not revealed by the independence concepts seen so far. Are there other concepts of independence that do not have this weakness? The answer is yes.\nDefinition 3.7: Let Z1, . . . , Z\ufffdc be sets of variables not necessarily disjoint such that V = U, z, . Z1, . . \u2022 , Z\ufffdc is generalized additively independent (for\ufffd) if, for any prob ability distributions Pl and p2 that have the same marginals on z, for all i, P1 and P2 are indifferent under \ufffd. I\nThis notion of independence is just like additive indepen dence except that the z, do not need to be disjoint. Now it can be shown that Proposition 2.9 still holds, but with generalized additive independence instead of additive inde pendence.\nProposition 3.8 : Zt, ... , Z\ufffdc are generalized additively independent for\ufffd iffut. can be written as\nk ut(V) = L f(Z,)\ni=l for some functions k\nIn other words, from Definition 3.1, the z, are generalized additive independent iff the utility function u has an additive decomposition over them.\nThis shows that any additive decomposition corresponds exactly to a single assertion of general independence. We have not seen the idea of generalized independence as given above defined explicitly in the literature, or Proposition 3.8 noted. We prove this proposition using the following de ceptively powerful result of Fishburn's [Fis82].\nTheorem 3.9: [Fishburn] Let\ufffd be a preference structure over some collection of states S' C S = II .. ev d..,. We say that some partition Z1, ... Z\ufffdc ofV are additively indepen dent over S' if all probability distributions P1 and P2 with support in S', that have the same marginals on z, for all i, are indifferent under \ufffd.\nThen Z1, ... , Z\ufffdc are additively independent overS' iff there exist functions f\u2022 such that\nk ut(V) =I: J, (z, )\ni=l is valid on S'.\nFishburn's theorem basically says that Proposition 2.9 con tinues to hold over subsets of the product space (with the appropriate notions restricted to that subset). The ability to restrict to a subset of the product space, and thus impose fixed interdependencies among the variables, is nontrivial; see [KLSTI 1] for other relevant discussion.\nProof of Proposition 3.8: Our proof utilizes a technique suggested by Fishburn in [Fis82]. Let S = II .. ev d..,, and consider any z, = { v11 \u2022 \u2022 \u2022 , vt} say. Corresponding to this, we can construct a new variable z,, whose do main is isomorphic to IJ!=l d;. Now consider the space T = IJ;=l z,. Each s E S corresponds to an element of T (because S implies a unique value for each of the sets of variables z, and thus for z,), and thus S corresponds\nto a subset T' ofT. Instead of probability and prefer ence overS, we can equivalently consider probability and preference over T'. But note that the marginal probabil ity of Zi in S is equal to the marginal probability over Zi in T'. Thus the assumption of Theorem 3.9 is in fact equivalent to the precondition of Proposition 3.8. Hence, the preference structure corresponds to a utility function u(V) = 2:::=1 f(zi) = 2:::=1 f(Zi). I\nOf course, even though any additive decomposition corre sponds to a single generalized independence assertion, it is probably unreasonable to try to discover the latter directly. Thus simpler but more accessible concepts such as (plain) CA-independence will remain important.\n3.1 Computation\nIt should be clear that an additively decomposable util ity function has advantageous computational implications. For instance, if we have no more concise representation of utility than just u(V), we must consider each possible state in lSI individually. This is true no matter how the prob ability distribution is given to us. But towards the other extreme, if u has an additive decomposition over v1, . . . , VA: (i.e., u(V) = 2::\ufffd=1 fi(vi)) then we only need to find n marginal probabilities, because the expected utility of u is the sum of the expected utilities of the fi, by linearity of ex pectation. Finding these probabilities can be very easy (for instance, linear time given a singly connected Bayesian net work; see [Pea88]). This example shows that the advantage of additive utility independence is not simply the reduction of dimensionality. Other decompositions may be as good in this respect, but not offer any clear benefits for compu tation; for example, consider the product utility functions that can be entailed by mutual utility independence (Propo sitions 2.5 and 2.6).\nTo show the possible advantages in somewhat more detail, consider probability distributions given by general Bayesian networks. One of the most popular ways of computing probabilities from a network is to form a join tree; see [LS88, Pea88]. Without going into details, we note that the join tree is a tree of sets of variables. If, for instance, C = v1, v2, \u2022 \u2022 \u2022 , VA: is a node in the join tree then the domain of cis just the product space n:=l d .. ,. Join trees can be used to maintain the marginal distribution over all nodes C; the complexity of this process is determined by the domain sizes of nodes such as C (which can of course be exponential, although in many cases will be of reasonable size).\nSuppose, however, that u is decomposable over Z1, \u2022 \u2022 \u2022 , Zk and each Zi is a subset of some node in the join tree. In this case, expected utility computations can be performed essentially for free, \"piggy-backing\" on the probability cal culations in the probabilistic join tree. Again, this is a consequence of linearity of expectation and the fact that the marginal over C is enough to calculate the expectation of any f(Zi) with Zi \ufffd C. If this containment property (see [DDP88]) property does not hold, we may need to add edges to the Bayesian network or join tree to establish it.\nGraphical models for preference and utility 9\nIn this case, the extra cost involved in calculating expected utility is a function of the number of edges we need to add. Roughly speaking, the greater the similarity between the Bayesian network (or join tree) and the utility graph, the less extra work will be required to compute expected util ity. The technique presented by Jensen et al. [JJD94] for evaluating influence diagrams uses such ideas, as does the somewhat related proposal of Dechter et al. [DDP88] in the context of constraint satisfaction.\nAnother very relevant work is [ST90], which also uses de composable utility functions (there called \"separable\") for evaluating influence diagrams. But this paper deals with both additive and multiplicative decompositions, and so perhaps does not offer as much potential savings as, say, Jensen et al.'s proposal. Finding out whether this is really so would be helped by a more precise analysis of how a utility independence independence structure, and its simi larity (or otherwise) to a given probabilistic independence structure, can affect computational efficiency. We hope to address this issue in future work.\n4 Conclusions and Future Work\nA direct extension of this work would be to investigate the possibility and usefulness of graphical models for other relevant concepts of independence. Von Stengel [vS88], utilizing the work of Gorman [Gor68], has shown that a utility function can be graphically represented as a com position tree that captures its utility independencies. The nodes of this tree are subsets of variables, with the root be ing equal to V. Besides this work on utility independence however, there seems to have been little else done in this area.\nFor instance, are there models using directed graphs (like Bayesian networks) for additive independence? What about generalized additive independence? The case of utility in dependence also deserves further attention. Gorman's com position tree approach leaves us with a graphical model that is quite distinct from graphical probabilistic models where the nodes represent single variables rather than sets of vari ables. Hence, it is not clear how such a model can be uti lized in conjunction with modern techniques of probability structuring.\nIt may turn out that the use of graphical models for utility representation only has a limited usefulness. On a broader level, though, we are convinced that decision theory is a critical part of artificial intelligence and thus there should be more work, in various directions, towards more sophisti cated utility modeling. Having said this, research in utility modeling need not start from nothing, but can and should draw on the considerable amount of existing ideas and tech niques in other disciplines.\nWe close by discussing one fairly speculative topic for fu ture research. Although we are firm believers in the standard decision theory paradigm, it is surely the case that utility (like, perhaps, probability) is not always a concept that the AI \"end-user\" should have to deal with directly. Utilities determine the purpose of a decision making process, but\n10 Bacchus and Grove\nit seems at least as common and sometimes more natural to specify this purpose using such concepts as goals, con straints, and so on. If we could give the idea of a \"goal\" clear and complete semantics in terms of utility functions, we could compile a specification in terms of goals into one in terms of utility (so that decision theory could then be used). But finding such semantics is certainly not a trivial task. We must cope with interacting and even contradic tory goals, conditional goals, and more. We should also interpret goals in a natural fashion, which is likely to de mand default reasoning of some sort. For instance, given two separate goals A and B, it is often reasonable that the conjunction A 1\\ B is a desirable thing to achieve as well, unless there is a specific reason to believe otherwise. This is something like a default assumption of independence over goals. Taking this idea literally would involve ideas such as Proposition 2.6, but there appear to be numerous complicating factors including: the rich structure of goals and preference stated in a logical language, which may not match the nice factorization of the state space assumed in Section 2; the implications of making this independence a default, and the interaction with all the other default as sumptions that might be necessary; the notion of condi tional goals and the various logical issues they raise; and so on. As we have said, some work in this direction exists [Bou94, DW91, DSW91, DW94, TP94], but there remains much to be done.\nReferences\n[Bou94] C. Boutilier. Towards a logic of qualitative de cision theory. In Principles of Knowledge Rep resentation and Reasoning: Proceedings of the 4'th International Conference (KR'94), 1994.\n[DDP88] R. Dechter, A. Dechter, and J. Pearl. Optimiza tion in constraint networks. In R. M. Oliver and J. Q. Smith, editors, Influence Diagrams Belief Nets and Decision Analysis, pages 411- 425. Wiley, 1988.\n[DSW91] J. Doyle, Y. Shoham, and M. P. Wellman. A logic of relative desire (preliminary report). In Proc. 6th International Symposium on Methe dologies for Intelligent Systems, pages 16-31, 1991.\n[DW91] J. Doyle and M. P. Wellman. Preferential se mantics for goals. In Proc. 9th National Con ference on Artificial Intelligence (AAAI '91), pages 698-703, 1991.\n[DW92] J. Doyle and M. P. Wellman. Modular utility representation for decision-theoretic planning. In Proc. 1st International Conference on Arti ficial Intelligence Planning Systems (A/PS-92), pages 236-242, 1992.\n[DW94] J. Doyle and M. P. Wellman. Representing preferences as ceteris paribus comparatives. In AAAI Spring Symposium on decision-theoretic planning, pages 69-75, 1994.\n[Fis82] P. C. Fishburn. The Foundations of Expected Utility. Reidel, Dordrecht, 1982.\n[Fre88] S. French. Decision Theory. Ellis Horwood, Chichester, West Sussex, England, 1988.\n[Gor68] W. M. Gorman. The structure of utility func tions. Review of Economic Studies, 35:367- 390, 1968.\n[GS88] P. Gardenfors and N. Sahlin, editors. Decision, Probabilility, and Utility: Selected Readings. Cambridge University Press, Cambridge, 1988.\n[JJD94] F. Jensen, F. V. Jensen, and S. Dittmer. From influence diagrams to junction trees. In Proc. Tenth Annual Conference on Uncertainty Artificial Intelligence, 1994.\n[KLST71] D. H. Krantz, R. D. Luce, P. Suppes, and A. Tversky. FoundationsofMeasurement. Aca demic Press, New York, 1971.\n[KR76] R. L. Keeney and H. Raiffa. Decisions with Mul tiple Objectives: Preferences and Value Trade offs. Wiley and Sons, New York, 1976.\n[LS88] S. L. Lauritzen and D. J. Spiegelhalter. Lo cal computations with probabilities on graph ical structures and their application to expert systems. Journal of the Royal Statistical Soci ety B, 50(2):240-265, 1988.\n[MH69] J. M. McCarthy and P. J. Hayes. Some philo sophical problems from the standpoint of artifi cial intelligence. In D. Michie, editor, Machine Intelligence 4, pages 463-502. Edinburgh Uni versity Press, Edinburgh, UK, 1969.\n[Pea88] J. Pearl. Probabilistic Reasoning in Intelligent Systems. Morgan Kaufmann, 1988.\n[PP89] J. Pearl and A. Paz. Graphoids: A graph based logic for reasoning about relevance re lations. In B. Du Boulay, editor, Advances in Artificial Intelligence-//. North-Holland, New York, 1989.\n[Sav54] L. J. Savage. The Foundations of Statistics. Dover, New York, 1954.\n[SP90] G. Shafer and J. Pearl, editors. Readings in Uncertain Reasoning. Morgan Kaufmann, San Mateo, CA, 1990.\n[ST90] R. D. Shachter and J. A. Tatman. Dynamic programming and influence diagrams. IEEE Transactions on Systems, Man, and Cybernet ics, 20(2):365-379, 1990.\n[TP94] S. Tan and J. Pearl. Qualitative decision theory. In Proc. 12th National Conference on Artificial Intelligence (AAAI '94 ), pages 928-932, 1994.\n[vS88] B. von Stengen. Decomposition of multiat tributeexpected-utility functions. Annals of Op eration Research, 16:161- 184, 1988."}], "references": [{"title": "Towards a logic of qualitative de\u00ad cision theory", "author": ["C. Boutilier"], "venue": "Principles of Knowledge Rep\u00ad resentation and Reasoning: Proceedings of the 4'th International Conference (KR'94)", "citeRegEx": "Bou94", "shortCiteRegEx": null, "year": 1994}, {"title": "Optimiza\u00ad tion in constraint networks", "author": ["R. Dechter", "A. Dechter", "J. Pearl"], "venue": "R. M. Oliver and J. Q. Smith, editors, Influence Diagrams Belief Nets and Decision Analysis, pages 411425. Wiley", "citeRegEx": "DDP88", "shortCiteRegEx": null, "year": 1988}, {"title": "A logic of relative desire (preliminary report)", "author": ["J. Doyle", "Y. Shoham", "M.P. Wellman"], "venue": "Proc. 6th International Symposium on Methe\u00ad dologies for Intelligent Systems, pages 16-31", "citeRegEx": "DSW91", "shortCiteRegEx": null, "year": 1991}, {"title": "Preferential se\u00ad mantics for goals", "author": ["J. Doyle", "M.P. Wellman"], "venue": "Proc. 9th National Con\u00ad ference on Artificial Intelligence (AAAI '91), pages 698-703", "citeRegEx": "DW91", "shortCiteRegEx": null, "year": 1991}, {"title": "Modular utility representation for decision-theoretic planning", "author": ["J. Doyle", "M.P. Wellman"], "venue": "Proc. 1st International Conference on Arti\u00ad ficial Intelligence Planning Systems (A/PS-92), pages 236-242", "citeRegEx": "DW92", "shortCiteRegEx": null, "year": 1992}, {"title": "Representing preferences as ceteris paribus comparatives", "author": ["J. Doyle", "M.P. Wellman"], "venue": "AAAI Spring Symposium on decision-theoretic planning, pages 69-75", "citeRegEx": "DW94", "shortCiteRegEx": null, "year": 1994}, {"title": "The Foundations of Expected Utility", "author": ["P.C. Fishburn"], "venue": "Reidel, Dordrecht", "citeRegEx": "Fis82", "shortCiteRegEx": null, "year": 1982}, {"title": "West Sussex", "author": ["Chichester"], "venue": "England,", "citeRegEx": "Fre88", "shortCiteRegEx": null, "year": 1988}, {"title": "The structure of utility func\u00ad tions", "author": ["W.M. Gorman"], "venue": "Review of Economic Studies,", "citeRegEx": "Gorman.,? \\Q1968\\E", "shortCiteRegEx": "Gorman.", "year": 1968}, {"title": "and Utility: Selected Readings", "author": ["Probabilility"], "venue": "Cambridge University Press, Cambridge,", "citeRegEx": "GS88", "shortCiteRegEx": null, "year": 1988}, {"title": "From influence diagrams to junction trees", "author": ["F. Jensen", "F.V. Jensen", "S. Dittmer"], "venue": "In Proc. Tenth Annual Conference on Uncertainty Artificial Intelligence,", "citeRegEx": "Jensen et al\\.,? \\Q1994\\E", "shortCiteRegEx": "Jensen et al\\.", "year": 1994}, {"title": "FoundationsofMeasurement", "author": ["D.H. Krantz", "R.D. Luce", "P. Suppes", "A. Tversky"], "venue": "Aca\u00ad demic Press, New York", "citeRegEx": "KLST71", "shortCiteRegEx": null, "year": 1971}, {"title": "San Mateo", "author": ["Uncertain Reasoning. Morgan Kaufmann"], "venue": "CA,", "citeRegEx": "SP90", "shortCiteRegEx": null, "year": 1990}, {"title": "Dynamic programming and influence diagrams", "author": ["R.D. Shachter", "J.A. Tatman"], "venue": "IEEE Transactions on Systems, Man, and Cybernet\u00ad ics,", "citeRegEx": "Shachter and Tatman.,? \\Q1990\\E", "shortCiteRegEx": "Shachter and Tatman.", "year": 1990}], "referenceMentions": [{"referenceID": 6, "context": "We prove this proposition using the following de\u00ad ceptively powerful result of Fishburn's [Fis82].", "startOffset": 90, "endOffset": 97}, {"referenceID": 6, "context": "8: Our proof utilizes a technique suggested by Fishburn in [Fis82].", "startOffset": 59, "endOffset": 66}, {"referenceID": 1, "context": "If this containment property (see [DDP88]) property does not hold, we may need to add edges to the Bayesian network or join tree to establish it.", "startOffset": 34, "endOffset": 41}, {"referenceID": 1, "context": "[DDP88] in the context of constraint satisfaction.", "startOffset": 0, "endOffset": 7}], "year": 2011, "abstractText": "Probabilistic independence can dramatically sim\u00ad plify the task of eliciting, representing, and com\u00ad puting with probabilities in large domains. A key technique in achieving these benefits is the idea of graphical modeling. We survey existing no\u00ad tions of independence for utility functions in a multi-attribute space, and suggest that these can be used to achieve similar advantages. Our new results concern conditional additive in\u00ad dependence, which we show always has a per\u00ad fect representation as separation in an undirected graph (a Markov network). Conditional addi\u00ad tive independencies entail a particular functional form for the utility function that is analogous to a product decomposition of a probability function, and confers analogous benefits. This functional form has been utilized in the Bayesian network and influence diagram literature, but generally without an explanation in terms of independence. The functional form yields a decomposition of the utility function that can greatly speed up expected utility calculations, particularly when the utility graph has a similar topology to the probabilistic network being used.", "creator": "pdftk 1.41 - www.pdftk.com"}}}