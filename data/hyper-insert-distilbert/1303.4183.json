{"id": "1303.4183", "review": {"conference": "arxiv", "VERSION": "v1", "DATE_OF_SUBMISSION": "18-Mar-2013", "title": "Generating extrema approximation of analytically incomputable functions through usage of parallel computer aided genetic algorithms", "abstract": "this paper first presents capabilities of using improved genetic algorithms to naturally find approximations and of probability function density extrema, constraints which cannot be found using analytic ways. referring to much enhance effectiveness optimization of algebraic calculations, algorithm algorithm generation has been parallelized substantially using openmp library. we gained much increase in speed on platforms using customized multithreaded processors compliant with shared machine memory free access. during analysis we manually used different modifications theories of genetic operator, using them we obtained custom varied evolution matching process algorithm of calculating potential analysis solutions. and results allow to make choose candidate best methods analyzed among are many applied in genetic navigation algorithms and observation of acceleration method on yorkfield, bloomfield, westmere - glen ex and recent most comparatively recent sandy bridge cores.", "histories": [["v1", "Mon, 18 Mar 2013 08:49:48 GMT  (1215kb)", "http://arxiv.org/abs/1303.4183v1", "16 pages, 13 figures"]], "COMMENTS": "16 pages, 13 figures", "reviews": [], "SUBJECTS": "cs.AI", "authors": ["lukasz swierczewski"], "accepted": false, "id": "1303.4183"}, "pdf": {"name": "1303.4183.pdf", "metadata": {"source": "CRF", "title": "GENERATING EXTREMA APPROXIMATION OF ANALYTICALLY INCOMPUTABLE FUNCTIONS THROUGH USAGE OF PARALLEL COMPUTER AIDED GENETIC ALGORITHMS", "authors": ["Lukasz Swierczewski"], "emails": ["luk.swierczewski@gmail.com"], "sections": [{"heading": "GENERATING EXTREMA APPROXIMATION OF ANALYTICALLY INCOMPUTABLE FUNCTIONS THROUGH USAGE OF PARALLEL COMPUTER AIDED GENETIC ALGORITHMS", "text": "Lukasz Swierczewski\nluk.swierczewski@gmail.com Computer Science and Automation Institute, College of Computer Science and Business\nAdministration in Lomza, Poland\nThis paper presents capabilities of using genetic algorithms to find approximations of function extrema, which cannot be found using analytic ways. To enhance effectiveness of calculations, algorithm has been parallelized using OpenMP library. We gained much increase in speed on platforms using multithreaded processors with shared memory free access. During analysis we used different modifications of genetic operator, using them we obtained varied evolution process of potential solutions. Results allow to choose best methods among many applied in genetic algorithms and observation of acceleration on Yorkfield, Bloomfield, Westmere-EX and most recent Sandy Bridge cores.\nKeywords: artificial intelligence, genetic algorithms, parallel algorithms, functions extremes"}, {"heading": "Introduction", "text": "Genetic algorithm (GA) is a type of algorithm inspired by the evolution of living organisms in the nature. It belongs to evolution algorithms whose idea was started by John Henry Holland, the American engineer and scientist. GA in a specific way searches in the area of solutions of a problem to find the best solution. The algorithm defines environment in which a specific population of specimens being possible solutions of the problem exists. Next, similarly to organisms in the nature, the specimens are cross-bred, mutated and selection of the best solutions based on the value of adaptation function occurs.\nIdeas of genetic algorithm were presented in Fig. 1.\nGenetic algorithms have distinctive features which distinguish them from other methods of calculation:\n\u2022 genetic operators are used which are adapted to the form of solutions, \u2022 processing of solution population allows to at the same time search in area of solutions from\ndifferent starting points in order to direct the searching process, \u2022 the quality of current solutions is the sufficient information, \u2022 random elements are introduced on purpose\nGenetic algorithms have enormous range of applications in the modern science and engineering. Due to their advantages, they are used when a method of solving problem is not precisely defined, but a method of evaluation of a solution in comparison with others is well known. The classic example is travelling salesman dilemma with whose solution standard algorithms manage relatively poor. GA are also widely used when designing electrical circuits. In such case, evaluation of each specimen is based on the amount of various elements and on their electrical features which can be easily calculated. Using GA, John R. Koza formulated new versions of PID [1] (proportionalintegral-derivative controller) which is frequently applied in automatics. Due to the development of FPGA, systems enabling programming structure of electrical circuit contained in them, an experimental project named Golem [2] was designed. It uses genetic algorithms for construction of robots without any support from man. Unfortunately, the project shown that the modern engineering cannot manage such issues and with the use of modern equipment too much time is required for the visible evolution to occur.\nConsiderably simpler, yet even more popular application of GA is finding extremes of functions. For this purpose also various numerical methods can be used, however, as it turns out, GA often provides good solutions in much shorter amount of time. In some cases, good effects may be obtained by using parallel programming and potential of the modern processors with several arithmetic and logic units. The aspect of genetic algorithms in connection with advanced parallel platforms was brought up in this work."}, {"heading": "Algorithm", "text": "The implementation of GA described and presented in the work is a fragment of Olib library. Its sources written in C/C++ language are available under [3] address. In genetic algorithm the following crossing methods were implemented:\n\u2022 One-point crossover, \u2022 Two-point crossover, \u2022 Three-point crossover, \u2022 Uniform crossover (Mixing Ratio = 0.5), \u2022 Uniform crossover (Random Mixing Ratio), \u2022 Half Uniform crossover, \u2022 Arithmetic crossover (functions: AND, OR, NOR, NAND, XOR, Random)\nOne-point crossover method was implemented in two ways. In the first implementation in the event of crossing the result is always one child. In the second implementation with 2/3 probability one child will be born, with 2/9 probability two children and with 1/9 probability three children. Pseudocode representing extension of the method was presented in Listing 1.1.\nThe most frequently encountered in literature and supported by the algorithm selection methods include:\n\u2022 Roulette, \u2022 Tournament, \u2022 Linear Ranking\nIn case of performance testing on various hardware configurations, the condition of stop of algorithm was defined with the number of generations. During the analysis of various genetic methods whose results were presented in Tab. 1, Tab. 2 and Tab. 3 the algorithm ended its operation if the condition was fulfilled:\nwhere: F(indiv_i) specifies value of adaptation function for i-specimen, n defines the number of specimens in population, F(best(indiv)) defines value of adaptation function of the best specimen in population.\nGenerally, it can be said that this condition determines stopping of the program execution when all specimens obtain the same, best value.\nListing 1.1. Pseudocode of the modified version of One-point crossover operator.\nvoid one_point_crossover(individuals_table[], individuals, lvl) {\nif(lvl < 3) {\nrandom_value = rand(); if(random_value % 3 == 0) {\nlvl++; one_point_crossover(individuals_table, individuals, lvl);\n}\n// One child is // created at this point.\n} }\none_point_crossover(individuals_table, individuals, 0);"}, {"heading": "Realization calculations", "text": "During the calculations the capabilities of parallel programming were used. Genetic operators were made parallel in such a way that they were executed according to the needs parallel on many specimens. The effect of making the executed instructions parallel was obtained through the use of OpenMP library which in a simple way allows to create new threads. This type of software fully\nutilises capabilities of the modern multi-core processors as well as multiple core platforms with common memory. All calculations were carried out in Linux OS environment and for compilation of programs Intel ICC 12.x version was used.\nGraphs in the range [2; 130] were presented in Fig. 2 and Fig. 3, respectively. Mainly in this range the focus was put on looking for maximum and minimum of the function. The algorithm was tested on four different calculating platforms:\n\u2022 Yorkfield: processor Intel Core 2 Quad Q8400 \u2022 Bloomfield: processor Intel i7 920 \u2022 Westmere-EX: processor Intel Xeon E7-4860 \u2022 Sandy Bridge: processor Intel i5-2400\nAdditionally, during calculations the impact of setting process affinity on the full time of processing data was checked. On Intel i7\\ 920 and Xeon E7-4860 processors the Hyper-Threading technology is available which enables increasing performance in result of duplication of some fragments of a processor (mainly registers). The actual impact on the calculations of HT technology was tested. Furthermore, some processors with a code name Sandy Bridge support Turbo Boost 2.0 technology. As it turned out, Intel Core i5-2400 processor using this technology had in some cases problems with achieving full performance.\nThe results concerning convergence of algorithm due to the application of various genetic algorithms.\nThe produced outcomes regarding capabilities of the implemented genetic algorithms and speed of their convergence for the function (1) were presented in Tab. 1 Analyses for the function (2) were contained in Tab. 2 and Tab. 3.\nIn case of the first function the genetic algorithm always, regardless of the applied methods, found the appropriate solution. In this instance, convergent outcomes could be very quickly obtained with Half Uniform crossover method, and the algorithm had to generate only 7 generations to fulfil the stop condition. Relatively good results were also obtained as a result of Two-point crossover method. Only 7 generations in case of looking for minimum and 33 in case of maximum is an interesting outcome as well. It is worth to consider results of two different implementations of Onepoint crossover method. In theory, the version recurrently performed at most three times and generating one to three children should provide better outcomes than the implementation which always creates only one child. However, in case of looking for the maximum it turns out that the situation during the carrying out of the tests looks completely differently and the simpler version of crossing is significantly more quickly convergent. Such result may signify a large impact of random factors on the operation of the entire program.\nIn Tab. 2 and Tab. 3 considerably more detailed outcomes of the function analysis were presented (2). In Fig. 2 it is possible to observe that the function has many distinctive local maximums and minimums. In this case, genetic algorithm considerably more easily may fall into local minimum or maximum which is not the best result. In conducted tests concerning various selection types the best outcomes were obtained with tournament selection when the size of the group was 10 specimens. In case of smaller tournament groups of 2 specimens, the algorithm was the least frequently finding the correct solution (only 4 times out of 24 trials). Linear Ranking and Roulette methods are\nsolutions marked with indirect effectiveness. Precise results are presented in the respective tables.\nIn case of function (2) it can also be noticed that different implementations of One-point crossover genetic operator are convergent, in accordance with the predictions, and the version generating according to distribution of probability maximally three children usually causes quicker end of the program operation.\nThe results concerning effectiveness of implementation of various genetic operators\nImplementations of various genetic operators are characterised by various calculation complexity. Intuitively, calculation complexity of Two-point crossover operator will be higher than One-point crossover due to division of chromosome in the larger number of points. On the other hand, complexity of all Arithmetic crossover operators will be comparable. Only Arithmetic crossover operating in Random mode (the arithmetic function applied in a case is always random) it may work noticeably slower due to the necessity of formulating a function generating a pseudorandom number.\nhe time of executing only various functions responsible for crossing in genetic algorithm was presented in Fig 4. A similar comparison for selection and comparison methods was presented in Fig. 5 and Fig. 6, respectively. In Fig. 7 it is possible to see execution of what functions constitutes the operation time of the whole program. According to the measurements, the most time of processor is devoted to selection: about 91%. Other operators of crossing and mutation consume only 3.6% and 1.2%, respectively. It proves that optimisation of genetic operator of selection can yield better gain of total performance.\nThe results achieved with the use of various hardware platforms\nOther, significantly more interesting aspect discussed in this work is the use of various hardware platforms for calculations based on genetic algorithms. In case of ordinary processors used at home, an actual acceleration was observed. The outcomes for Intel Core 2 Quad Q8400, i7\\ 920 and i52400 processors were presented in Fig. 8, Fig. 9 and Fig 10, respectively. The list includes Real Time \u2013 the time of program execution from the perspective of user (time of execution of the longest thread) as well as total time calculated for all threads \u2013 System Time. On all platforms the tests included execution of algorithm with 1 to 8 threads. Only in respect to Intel i7\\ 920 processor an increase of performance in comparison between four and eight threads was observed. This processor has physically only four cores but thanks to Hyper Threading technology it is recognised by the system as a configuration with eight cores. HT technology in case of this processor allows to reduce time by additional 740 seconds, that is about 29.5% in comparison with the ordinary time of use of four cores. The typical fall of performance when comparing times for four and five threads is most probably caused by platform\u2019s problems with assigning the excessive, fifth thread, to one of the four physical processors and its migration during operation of the program through various cores. The problem disappears in case of six and higher number of threads where the potential of Hyper-Threading technology is much better utilised. In case of Core 3 Quad Q8400 and i5-2400 processors, the time of execution falls only when four or less threads are used. Further threads created on these platforms are still executed by four processors. They have to be divided into smaller time quanta and properly assigned to processors which causes fall of performance. It is for this reason why usually it is presumed that the number of calculation threads in a program should be equal to the number of available processors in the system. In Fig. 10 an extreme fall of performance in the moment of moving from four to five threads in the case of i5-2400 processor can be seen. When the number of threads does not exceed the physical number of cores the processor works with\nfull clock rate amounting to 3100 MHz. When the number of threads was larger, Turbo Boost 2.0 technology set clock rate to 1600 MHz which caused a considerable fall of performance.\nA very advanced platform constructed with four ten-core Intel Xeon 7-4860 processors was used in the tests. These processors support Hyper-Threading technology which makes one unit to be seen by the system as 20 cores. The system is built from four such processors, therefore, in theory it enables running a program with 80 threads. For purely practical reasons performance measurements were carried out using only 1 to 40 threads. The results were presented in Fig. 11. The shortest execution time was obtained when the calculating capabilities of only 19 threads were used. The problem with performance scaling on computers with common memory is frequently that, while the number of processors may increase linearly, speed of operating memory does not increase linearly and it is memory which at some point becomes a bottleneck of the entire configuration.\nThe results obtained through changes in process affinity settings\nThe process affinity settings were also tested. Process affinity consists of locking processes to specific processors so the process does not have to lose time on migration between processors, during the execution. System planner typically deals with this task. As it turns out, improvement of performance achieved in result of process affinity is slight. For Intel i7 920 processors comparison of times of program execution with enabled and disabled affinity may be seen in Fig. 13. The largest gain was observed when 2 threads were used and it amounted to 106 seconds which is barely 2.9%.\nOn the other hand, a considerable gain was brought in case of 10 threads and a platform consisting of four Intel Xeon E7-4860 processors. In case of dividing threads to processors by system planner, the time of execution of the program amounted to 1995 seconds. When user manually made all threads to be executed by 10 cores organised within one processor, the time decreased to only 1303. The difference is 34.6% which is a perceptible value. The acceleration was shown in Fig. 12.\nTable. 1. A summary list of speed and correctness of convergence of different crossing methods for function (1).\nParameters of the program: Function (2); Range: [2; 1048578]; Searching Maximum; Population size: 16384; Probability of mutation = 100%; Crossover: Two-point crossover (probability = 50%); Selection: Roulette; Linear\nscaling; 10000 generations.\nParameters of the program: Function (2); Range: [2; 1048578]; Searching Maximum; Population size: 16384;\nMutation: Bit inversion (probability = 1%); Crossover: Two-point crossover (probability = 50%); Selection: Roulette; Linear scaling; 10000 generations.\nSystem time measured for eight threads processor Intel Core i7 920."}, {"heading": "Conclusion", "text": "Genetic operators analysed in the article can be divided into more and less demanding methods in respect to the executed operations. As regards crossing, Uniform crossover implementation proved to be the most complex, and in relation to selection this tournament method whose complexity raises with the increase of size of tournament group.\nGenetic algorithms relatively well undergo process of paralleling. The acceleration is perfectly noticeable on the modern multi-core processors. In case of more advanced platforms built from\nmany multi-core processors problems with appropriate performance scaling may occur.\nThe application of programmable graphic accelerators which in the recent years have become very popular may turn out to be a very interesting prospect. Properly utilised, they will certainly allow to even more quickly process data."}, {"heading": "Acknowledgment", "text": "The work has been prepared using the supercomputer resources provided by the Faculty of Mathematics, Physics and Computer Science of the Maria Curie-Sk\u0142odowska University in Lublin and Computer Science and Automation Institute of the College of Computer Science and Business Administration in Lomza."}, {"heading": "GENERACJA PRZYBLI\u017bE\u0143 EKSTREM\u00d3W FUNKCJI NIEOBLICZALNYCH ANALITYCZNIE DZI\u0118KI ZASTOSOWANIU ALGORYTM\u00d3W GENETYCZNYCH ZE WSPARCIEM KOMPUTER\u00d3W R\u00d3WNOLEG\u0141YCH", "text": "Praca prezentuje mo\u017cliwo\u015bci zastosowania algorytm\u00f3w genetycznych do odnajdywania przybli\u017ce\u0144 ekstrem\u00f3w funkcji, kt\u00f3rych nie mo\u017cna obliczy\u0107 w spos\u00f3b analityczny. Aby zwi\u0119kszy\u0107 efektywno\u015b\u0107 prowadzonych oblicze\u0144 algorytm poddano r\u00f3wnoleglizacji z wykorzystaniem biblioteki OpenMP. Uzyskano dzi\u0119ki temu zauwa\u017calne przy\u015bpieszenie na platformach o swobodnym dost\u0119pie do pami\u0119ci wsp\u00f3lnej wykorzystuj\u0105cych procesory wielordzeniowe. Podczas analiz wykorzystano r\u00f3\u017cne modyfikacje operator\u00f3w genetycznych, dzi\u0119ki kt\u00f3rym uzyskano zr\u00f3\u017cnicowane procesy ewolucji osobnik\u00f3w, b\u0119d\u0105cych potencjalnymi rozwi\u0105zaniami. Wyniki umo\u017cliwiaj\u0105 wyb\u00f3r najlepszych metod spo\u015br\u00f3d wielu stosowanych w algorytmach genetycznych oraz obserwacj\u0119 akceleracji na uk\u0142adach Yorkfield, Bloomfield, Westmere-EX oraz najnowocze\u015bniejszych Sandy Bridge.\nS\u0142owa kluczowe: sztuczna inteligencja, algorytmy genetyczne, algorytmy r\u00f3wnoleg\u0142e, ekstrema funkcji\nPraca zosta\u0142a przygotowana z wykorzystaniem zasob\u00f3w superkomputerowych udost\u0119pnionych przez Wydzia\u0142 Matematyki, Fizyki i Informatyki Uniwersytetu Marii Curie-Sk\u0142odowskiej w Lublinie oraz Instytutu Informatyki i Automatyki Pa\u0144stwowej Wy\u017cszej Szko\u0142y Informatyki i Przedsi\u0119biorczo\u015bci w \u0141om\u017cy."}], "references": [{"title": "Genetic Algorithms + Data Structures = Evolution Programs,SpringerVerlag", "author": ["Z. Michalewicz"], "venue": null, "citeRegEx": "4", "shortCiteRegEx": "4", "year": 1999}, {"title": "Parallel Genetic Algorithm Taxonomy", "author": ["R. Poli", "M. Nowostawski"], "venue": "Wydawnictwa Naukowo-Techniczne,", "citeRegEx": "5", "shortCiteRegEx": "5", "year": 2003}, {"title": "Genetic Programming \u2013 An Introduction", "author": ["W. Banzhaf", "P. Nordin", "R. Keller", "F. Francone"], "venue": null, "citeRegEx": "6", "shortCiteRegEx": "6", "year": 1998}, {"title": "An Introduction to Genetic Algorithms", "author": ["M. Mitchell"], "venue": null, "citeRegEx": "7", "shortCiteRegEx": "7", "year": 1996}, {"title": "Theory of Genetic Algorithms", "author": ["L. Schmitt"], "venue": "Theoretical Computer Science", "citeRegEx": "8", "shortCiteRegEx": "8", "year": 2001}, {"title": "Theory of Genetic Algorithms II: models for genetic operators over the stringtensor representation of populations and convergence to global optima for arbitrary fitness function under scaling", "author": ["L. Schmitt"], "venue": "Theoretical Computer Science", "citeRegEx": "9", "shortCiteRegEx": "9", "year": 2004}], "referenceMentions": [], "year": 2013, "abstractText": "This paper presents capabilities of using genetic algorithms to find approximations of function extrema, which cannot be found using analytic ways. To enhance effectiveness of calculations, algorithm has been parallelized using OpenMP library. We gained much increase in speed on platforms using multithreaded processors with shared memory free access. During analysis we used different modifications of genetic operator, using them we obtained varied evolution process of potential solutions. Results allow to choose best methods among many applied in genetic algorithms and observation of acceleration on Yorkfield, Bloomfield, Westmere-EX and most recent Sandy Bridge cores.", "creator": "Writer"}}}