{"id": "1305.4130", "review": {"conference": "arxiv", "VERSION": "v1", "DATE_OF_SUBMISSION": "17-May-2013", "title": "Belief Propagation for Linear Programming", "abstract": "robust belief valley propagation ( bp ) is a popular, distributed heuristic for performing map algorithm computations in graphical biological models. binary bp trees can precisely be interpreted, from a strictly variational perspective, as independently minimizing the canonical bethe rift free energy ( intrinsic bfe ). bp can also be be used globally to additionally solve a special recognition class of fuzzy linear spectral programming ( lp ) problems. possibly for modelling this class of functional problems, this map inference can be approximately stated as an integer lp with an lp cm relaxation that apparently coincides with minimization of the bfe trajectory at ` ` zero temperature \". we should generalize these initial prior results and establish a tight characterization solution of the explicit lp problems sequence that can be formulated as an equivalent lp relaxation of oracle map slice inference. note moreover, also we still suggest an efficient, iterative greedy annealing bp algorithm for solving \" this narrow broader wider class category of integer lp problems. further we demonstrate the underlying algorithm's upper performance bounds on a set f of weighted matching problems by successfully using it ourselves as class a cutting plane method able to better solve a greedy sequence p of lps * tightened \u2032 by adding ` ` black blossom'' s inequalities.", "histories": [["v1", "Fri, 17 May 2013 16:40:43 GMT  (176kb,D)", "http://arxiv.org/abs/1305.4130v1", "To appear in ISIT 2013"]], "COMMENTS": "To appear in ISIT 2013", "reviews": [], "SUBJECTS": "cs.AI cs.DS", "authors": ["andrew gelfand", "jinwoo shin", "michael chertkov"], "accepted": false, "id": "1305.4130"}, "pdf": {"name": "1305.4130.pdf", "metadata": {"source": "CRF", "title": "Belief Propagation for Linear Programming", "authors": ["Andrew E. Gelfand", "Jinwoo Shin", "Michael Chertkov"], "emails": ["agelfand@ics.uci.edu", "jshin@us.ibm.com", "chertkov@lanl.gov"], "sections": [{"heading": null, "text": "I. INTRODUCTION\nGraphical Models (GMs) provide a useful representation for reasoning in a range of scientific fields [1], [2], [3], [4]. Such models use a graph structure to encode a joint probability distribution, where vertices correspond to random variables and edges (or lack thereof) specify conditional independencies.\nAn important inference task in many applications involving GMs is finding the most likely assignment to the variables in a GM - the Maximum-A-Posteriori (MAP) configuration. Belief Propagation (BP) is a much celebrated algorithm for approximately solving the MAP inference problem. BP is an iterative, message passing algorithm that is exact on tree structured GMs, but has empirically been shown to give good results even on GMs with loops. Its main appeal is that it is naturally suited for a distributed implementation.\nIt was recently shown that BP is exact for a certain class of GMs with loops. This inspiring result was shown for GMs in which well known optimization problems - namely, the matching problem [5], [6] and min-cost network flow problem [7] - were posed as MAP inference tasks. In the weighted matching case, the original combinatorial optimization problem can can be expressed as a binary Integer Linear Program (ILP). In certain cases (e.g. in bi-partite graphs), solving the LP relaxation to the matching ILP yields an integral solution.\nThe MAP inference task can also be formulated as an ILP in GMs with discrete variables. The LP relaxation to the MAP ILP, which we refer to herein as BPLP, arises by relaxing the integrality constraint on the discrete variables. When the weighted matching problem is formulated as a MAP\ninference task, BPLP is equivalent to the relaxed matching ILP - explaining the success of BP in these GMs [5], [6], [8]! The connection between LP relaxations and BPLP (also called LPdecoding) has also been discussed in the coding literature [9], [10], [11], [12], [13].\nThis line of work established a solid theoretical link between message passing algorithms and optimization theory. It provides a practical certificate of exactness/integrality for MAP inference when using BP and has also suggested strategies for improving upon BP\u2019s results, by adding constraints that reduce the BPLP integrality gap [14], [15], [16].\nMotivated by this prior work, our manuscript characterizes the class of binary ILPs for which LP=BPLP, i.e. where the LP relaxation of an ILP is equivalent to BPLP, the LP relaxation of the MAP formulation of the problem. While standard BP is an approximation algorithm that is not guaranteed to converge to a correct answer for the LP, we provide an annealing version of BP that converges to the correct answer as long as LP=BPLP. Establishing this relationship allows us to use BP (or its variants) to efficiently approximate MAP inference in the special class of binary ILPs. We extend the work in [5], [6] by empirically demonstrating that annealing BP can be used to solve LP-relaxations to the weighted matching problems requiring Edmonds\u2019 blossom inequalities. In particular, we use annealing BP to solve a sequence of successively tightened LP relaxations. If coupled with the method for finding a tight LP relaxation of \u2018polynomial\u2019 size in [17], annealing BP could be used in a novel, distributed approximation algorithm for the weighted matching problem.\nThe material in the manuscript is organized as follows. Section II introduces GMs, BP and the class of LPs of interest. Section III provides our main result. Sections IV and V describe our annealed BP algorithm and demonstrate its utility as an LP-solver."}, {"heading": "II. PRELIMINARIES", "text": ""}, {"heading": "A. Graphical Model", "text": "Let Z = [Zi] be a collection of n random variables, each of which takes values in a finite alphabet Zi = zi \u2208 \u2126. Let the joint probability distribution of Z \u2208 \u2126n factor into a product of real-valued, positive functions {\u03c8\u03b1 : \u03b1 \u2208 F} each defined\nar X\niv :1\n30 5.\n41 30\nv1 [\ncs .A\nI] 1\n7 M\nay 2\n01 3\nover a subset of the variables: Pr[Z = z] \u221d \u220f \u03b1\u2208F \u03c8\u03b1(z\u03b1),\nwhere z\u03b1 = [zi : i \u2208 \u03b1] are the arguments of factor \u03b1. z is called a valid assignment if Pr[Z = z] > 0. The MAP assignment z\u2217 is defined as:\nz\u2217 = arg max z\u2208\u2126n Pr[Z = z]. (1)\nA Graphical Model (GM) represents the above factorization using a bi-partite graph, known as a Factor Graph [18], where each factor \u03b1 \u2208 F is connected to the variables in its argument. (See Figure 1 for an example).\nB. Integer Linear Programming as MAP\nConsider the following ILP (Integer Linear Program):\nILP : max c \u00b7 x s.t. Ax \u2264 d, xi \u2208 {0, 1} (2)\nwhere i = 1, \u00b7 \u00b7 \u00b7 , n, j = 1, \u00b7 \u00b7 \u00b7 , k, c = [ci], d = [dj ] are integer (column) vectors and A = [Aji] is an integer matrix.\nThe ILP in (2) can be formulated as a MAP inference task by constructing a suitable binary GM. Let X = [Xi] \u2208 {0, 1}n be a set of binary random variables associated with each variable in (2) and consider the probability distribution:\nPr[X = x] \u221d \u220f i ecixi \u220f j \u03c8j(xj ), (3)\n\u03c8j(xSj ) = { 1, if (Ax)j \u2264 dj 0, otherwise , (4)\nwhere every row of matrix A is associated with a factor \u03c8j defined over a subset of the variables xSj , where Sj = {i : Aji 6= 0}. It is clear that Pr[X = x] \u221d \u220f i e cixi for any \u2018feasible\u2019 assignment satisfying the linear constraints in (2) and Pr[X = x] = 0 otherwise. An illustration of this transformation is shown in Figure 1.\nThe LP relaxation of (2) replaces the integrality constraints with inequalities:\nLP : max c \u00b7 x s.t. Ax \u2264 d, 0 \u2264 xi \u2264 1. (5)\nThe LP relaxation of the ILP optimizes over a larger polytope. We will use the notation A \u2264 B to indicate that\nevery feasible point of polytope A is a feasible point of polytope B and A \u2265 B to indicate the converse. Note that while ILP \u2264 LP is true, ILP \u2265 LP is not true in general."}, {"heading": "C. Bethe Free Energy and BPLP", "text": "Belief Propagation (BP) is an algorithm for approximately computing marginals that works by sending messages along the edges of the factor graph. We describe the algorithm for the GM in (3). Messages from factor node j to variable node i are denoted mji and messages in the opposite direction are denoted mij . The messages are updated as follows: for each xi \u2208 {0, 1},\nmji(xi) \u2190 \u2211 xSj \\xi \u03c8j(xSj ) 1/T \u220f k\u2208Sj\\i mkj(xk)\nmij(xi) \u2190 exp (ci T xi ) \u220f k\u2208Ei\\j mki(xi)\nwhere we have introduced a parameter T > 0 (called temperature) and Ei = {j : Aji 6= 0}.\nEach factor or variable node in the factor graph is associated with a belief bj(xSj ) and bi(xi), respectively. The beliefs are calculated from the messages as:\nbj(xSj ) \u221d \u03c8j(xSj )1/T \u220f k\u2208Sj mkj(xk)\nbi(xi) \u221d exp (ci T xi ) \u220f k\u2208Ei mki(xi),\nwhere \u2211 xi bi(xi) = 1 and \u2211 xSj bj(xSj ) = 1.\nBP for the GM in (3) can be interpreted as a variational optimization procedure in which the messages and beliefs minimize the Bethe Free Energy (BFE) functional [1]\nF(b) = \u2212 \u2211 i cibi(xi = 1)\u2212 TS(b), (6)\n\u2212S(b) = \u2211 j \u2211 xSj bj(xSj ) log(bj(xSj ))\n+ \u2211 i (1\u2212 qi) \u2211 xi bi(xi) log(bi(xi)), (7)\nwhere qi = \u2211 j:Aji6=0\n1, subject to the following normalization and local consistency constraints:\u2211\nxSj :xi\nbj ( xSj ) = bi(xi), \u2200i \u2208 Sj (8)\nbj(xSj ) \u2265 0, \u2211 xSj bj(xSj ) = 1, (9)\nbj(xSj ) = 0, if \u2211 i\u2208Sj Ajixi > dj , \u2200j. (10)\nNote that we use bi(xi = 1) to mean bi(1).\nIt is known [1] that if BP converges, it finds a minimum (possibly local) of the BFE. Finding the global minimum of the\nBFE is desirable (as an approximation). This task is reduced at T = 0 to the following LP:\nBPLP : min\u2212 \u2211 i cibi(xi = 1), s.t. (8), (9), (10). (11)\nD. Illustrative Example: ILP and LP for Matching\nWe illustrate the ILP formulation and transformation to a GM described in Section II-B on the weighted matching problem. Given an (undirected) graph G = (V,E) with nonnegative edge weights {we : e \u2208 E}, we seek to find the matching of largest weight, where a matching is a subset of edges such that each vertex is incident to at most one edge. The problem is described by the following ILP:\nm-ILP: max \u2211 e\u2208E wexe (12)\ns.t. \u2211 e\u2208\u03b4(i) xe \u2264 1, \u2200i \u2208 V ; xe \u2208 {0, 1}.\nwhere \u03b4(i) = {e = (i, j) \u2208 E} is the set of edges adjacent to vertex i.\nThe straightforward LP relaxation of m-ILP is formed by replacing xe \u2208 {0, 1} by xe \u2208 [0, 1]. However, this LP is not tight in general - i.e. m-LP \u2265 m-ILP. The LP can be made tight, as famously shown by Edmonds [19], by adding a set of blossom inequalities:\nm-bl-LP : max \u2211 e\u2208E wexe (13)\ns.t. \u2211 e\u2208\u03b4(i) xe \u2264 1, \u2200i \u2208 V\u2211\ne\u2208E(S) xe \u2264 |S|\u22121\n2 , \u2200S \u2208 S xe \u2208 [0, 1].\nwhere E(S) = {(i, j) \u2208 E : i, j \u2208 S} is the set of edges with both ends in S and S \u2282 2V is the set of all odd-sized sets of vertices in G. The blossom inequalities imply that an odd cycle of length 2l + 1 can have l edges in a matching.\nThe weighted matching problem can be formulated as a MAP inference problem by associating a random variable with each edge X = [Xe] \u2208 {0, 1}|E| and constructing the following distribution:\nPr[X = x] \u221d \u220f e\u2208E ewexe \u220f i\u2208V \u03c8i(xi) \u220f S\u2208S \u03c8S(xS), (14)\n\u03c8i(xi) =\n{ 1, if \u2211 e\u2208\u03b4(i) xe \u2264 1\n0, otherwise (15)\n\u03c8S(xS) =\n{ 1, if \u2211 e\u2208E(S) xe \u2264 |S|\u22121 2\n0, otherwise . (16)\nwhere \u03c8i are functions defined over variables xi = {xe : e \u2208 \u03b4(i)} and \u03c8S are functions defined over xS = {xe : e \u2208 E(s)}. It is easy to see that (14) is equivalent to\nPr[X = x] \u221d { exp (w(x)) if x induces a matching in G 0 otherwise , (17) where w(x) := \u2211 e\u2208E wexe."}, {"heading": "III. EQUIVALENCE BETWEEN LP AND BPLP", "text": "Now we state the main result of the paper.\nTheorem III.1. For any (fixed) j, consider the polytope Pj : \u2211 i\u2208Sj Ajixi \u2264 dj , 0 \u2264 xi \u2264 1 \u2200i \u2208 Sj . (18)\nThen, the following properties hold:\n\u2022 If Pj has only 0-1 integral vertices (i.e., extreme points) for all j, then LP \u2264 BPLP. \u2022 LP \u2265 BPLP (without any conditions).\nTheorem III.1 implies the following corollary.\nCorollary III.2. If Aji \u2208 {\u22121, 0, 1} for all i, j, then LP = BPLP.\nProof: Corollary III.2 is proved using Theorem III.1 and the fact that each vertex of a polytope can be expressed as the unique solution to a system of \u2018face\u2019 linear equalities (see e.g. [20].\nNote that the condition of Corollary III.2 holds for mbl-LP. One also observes (arguing by contradiction) that the condition in Theorem III.1 for LP \u2264 BPLP is necessary. For example, suppose the number of rows of matrix A is one, S1 = {1, . . . , n} and the polytope P1 has a fractional vertex x = [xi]. Then there exists c = [ci] such that x is the unique solution of LP (5). However, [bi(1)] = [xi] cannot satisfy (8), (9) and (10) for any factor bj(\u00b7) because x is a fractional vertex of P1. Hence, LP > BPLP."}, {"heading": "A. Proof for LP \u2264 BPLP", "text": "Here we prove that if x = [xi] satisfies the constraints of LP (5), then there exists normalized beliefs {bj} such that [bi(1)] = [xi], [bi(0)] = [1 \u2212 xi] and {bi, bj} satisfies constraints of BPLP. From the condition of Theorem III.1, the polytope Pj has only 0-1 integral vertices. Then, according to the Carathe\u0301odory\u2019s theorem [21], any point [xi] in the polytope can be expressed as a convex combination of 0-1 vertices, where coefficients in the convex combination provide values of {bj}, and the variables bi(0) and bi(1) in the description of the BPLP polytope, correspond to the variables 1\u2212 xi and xi in the LP polytope, respectively. This completes the proof of LP \u2264 BPLP."}, {"heading": "B. Proof for LP \u2265 BPLP", "text": "Here we prove that if {bi, bj} satisfies the constraints of BPLP, then [xi = bi(1)] satisfies the constraints of LP as well. As mentioned above, bi(0) is redundant as bi(0) = 1\u2212 bi(1) within the BPLP polytope. From this, one derives\u2211\ni\u2208Sj Ajixi = \u2211 i\u2208Sj Aji \u2211\nxSj :xi=1\nbj ( xSj )\n= \u2211 i\u2208Sj Aji \u2211 xSj xibj ( xSj ) = \u2211 xSj \u2211 i\u2208Sj Ajixi  bj (xSj)\n\u2264 \u2211 xSj djbj ( xSj )\n= dj \u2211 xSj bj ( xSj ) = dj ,\nwhere (10) was used at the inequality stage. This completes the proof of LP \u2265 BPLP."}, {"heading": "IV. ANNEALING BP FOR SOLVING LPS", "text": "In this section, we propose the following annealing version of BP as an LP solver:\nmt+1ji (xi)\u2190 m t ji(xi) 1\u2212\u03b1t \u2211 xSj \\xi \u03c8j(xSj ) \u03b1t Tt \u220f k\u2208Sj\\i mtkj(xk) \u03b1t\nmt+1ij (xi)\u2190 m t ij(xi) 1\u2212\u03b1t exp ( \u03b1tci Tt xi ) \u220f k\u2208Ei\\j mtki(xi) \u03b1t\nbt+1j (xSj ) \u221d \u03c8j(xSj ) 1/Tt \u220f k\u2208Sj mtkj(xk)\nbt+1i (xi) \u221d exp ( ci Tt xi ) \u220f k\u2208Ei mtki(xi),\nwhere \u03b1t \u2208 (0, 1], Tt > 0, mtij ,mtji and btj , bti are a \u2018damping\u2019 parameter, a temperature parameter, messages and beliefs at the t-th iteration, respectively. We have the following conjecture.\nConjecture IV.1. If LP = BPLP and m0ij = m0ji = 1 for all i, j, then there exists a scheme with annealing schedule T0 \u2265 T1 \u2265 . . . with limt\u2192\u221e Tt = 0 and damping schedule \u03b10, \u03b11, . . . such that [bti(1)] converges to the solution of LP.\nWe now explain the rationale for the above conjecture. First, recall the following facts:\n\u2022 If BP converges, it finds a (possibly local) minimum of the BFE function. \u2022 The BFE minimization is equal to BPLP at T = 0.\nThe main difficulties in establishing the conjecture are (a) BP may not converge, and (b) BP may converge to a local (not global) minimum of the BFE functional. To overcome both issues, one can use a convex modification of the BFE function [22], and the known convergent variant to BP (providing sufficient damping), called CCCP, to find its minimum [23]. We believe that an appropriate annealing scheme can fix the convergence issue and that the natural initialization m0ij = m 0 ji = 1 can prevent annealing BP from converging to an undesirable local minimum of the BFE functional. Support for natural message initialization comes from [5], [6], [7], [24], where for certain GMs the natural initial messages are needed to prevent BP from converging to an undesirable fixed point. We empirically verify this conjecture for matching GMs in the following section.\n0 0.1 0.2 0.3 0.4 0.5 0.6 0.7 0.8 0.9 1 0\n0.1\n0.2\n0.3\n0.4\n0.5\n0.6\n0.7\n0.8\n0.9\n1\nTemperature\nb( x e\n= 1\n)\nBeliefs versus Temperature for Fractional Matching\n(0,2) (0,4) (1,3) (1,4) (2,3) (2,4) (3,4)\nEdges\n1 2 4 5\n2\n1 5\n0\n1\n2 3\n4\nFig. 2. Convergence of edge beliefs found by annealing BP to a fractional LP solution with total weight w(x) = 8.\n0 0.1 0.2 0.3 0.4 0.5 0.6 0.7 0.8 0.9 1 0\n0.1\n0.2\n0.3\n0.4\n0.5\n0.6\n0.7\n0.8\n0.9\n1\nTemperature\nb( x e\n= 1\n)\nBeliefs versus Temperature for Integral Matching \u2212 1 Blossom\n(0,2) (0,4) (1,3) (1,4) (2,3) (2,4) (3,4)\nEdges\n1 2 4 5\n2\n1 5\n0\n1\n2 3\n4\nFig. 3. Convergence of edge beliefs found by annealing BP to the integral LP solution with total weight w(x) = 7."}, {"heading": "V. EXPERIMENTS WITH MATCHINGS", "text": "In this section, we demonstrate that annealing BP with sufficient damping can be used to reliably solve sequential LP relaxations to the weighted matching problem introduced in section II-D. We note that our approach here differs from prior work on solving the weighted matching problem using BP because we consider the sum-product form of BP. The work in [5], [6] demonstrated that max-product BP will converge to the MAP solution (and therefore find the maximum weight matching) if the relaxation to the matching ILP without blossoms is tight. However, when this LP is not tight, maxproduct will fail to converge. The connection between BPLP and LP made in the previous section, tells us that the MAP solution will correspond to the solution to the LP involving blossoms (i.e. m-bl-LP). We demonstrate that annealed sumproduct BP can be used to solve m-bl-LP.\nFigures 2 and 3 plot the edge beliefs be(xe = 1) found by sum-product BP on a particular weighted matching problem instance with 5 vertices and 7 edges. The edge weights for this instance are depicted in the inlay of each figure. In both figures, T is annealed linearly from 1 to 0.01 over 100 steps\nand BP is run for 20 iterations at each temperature with \u03b1t = 12 for all t. The results in Figure 2 are for a GM corresponding to a non-tight relaxation of m-ILP. Notice as the temperature is annealed that the beliefs converge to a fractional solution with total weight w(x) = 8. In this plot, we see that vertices {1, 3, 4} constitute an odd set of vertices violating a blossom inequality. Adding an inequality for this blossom makes mbl-LP tight. The GM used in Figure 3 includes an additional factor enforcing the blossom inequality. The beliefs in the tight GM converge to an integral (and exact) solution with total weight w(x) = 7.\nFigure 4 demonstrates how annealing sum-product BP can be used to solve a much larger weighted matching problem, with 20 vertices and 80 edges. We use the same annealing and damping scheme as in the previous experiments. The leftmost figure plots edge beliefs as a function of temperature for the LP relaxation without blossoms. This relaxation is not tight, so several edge beliefs converge to b(xe = 1) = 12 . In the center plot we have added a single blossom constraint that also yields a fractional solution. However, the blossom tightens the LP relaxation, reducing the total weight from w(x) = 87.5 to w(x) = 86.5. The right-most plot depicts a tight LP relaxation (i.e. m-bl-LP = m-ILP). Notice that as temperature is annealed, all edge beliefs converge to either 0 or 1. In the exact matching w(x) = 86."}], "references": [{"title": "Constructing free-energy approximations and generalized belief propagation algorithms,", "author": ["J. Yedidia", "W. Freeman", "Y. Weiss"], "venue": "Info. Theory, IEEE Trans. on,", "citeRegEx": "1", "shortCiteRegEx": "1", "year": 2005}, {"title": "Modern Coding Theory", "author": ["T.J. Richardson", "R.L. Urbanke"], "venue": "Cambridge University Press", "citeRegEx": "2", "shortCiteRegEx": null, "year": 2008}, {"title": "Information", "author": ["M. Mezard", "A. Montanari"], "venue": "physics, and computation, ser. Oxford Graduate Texts. Oxford: Oxford Univ. Press", "citeRegEx": "3", "shortCiteRegEx": null, "year": 2009}, {"title": "Graphical models", "author": ["M.J. Wainwright", "M.I. Jordan"], "venue": "exponential families, and variational inference,\u201d Foundations and Trends in Machine Learning, vol. 1, no. 1, pp. 1\u2013305", "citeRegEx": "4", "shortCiteRegEx": null, "year": 2008}, {"title": "Max-product for maximum weight matching: Convergence, correctness, and lp duality,", "author": ["M. Bayati", "D. Shah", "M. Sharma"], "venue": "Info. Theory, IEEE Trans. on,", "citeRegEx": "5", "shortCiteRegEx": "5", "year": 2008}, {"title": "Belief propagation and lp relaxation for weighted matching in general graphs,", "author": ["S. Sanghavi", "D. Malioutov", "A. Willsky"], "venue": "Info. Theory, IEEE Trans. on,", "citeRegEx": "6", "shortCiteRegEx": "6", "year": 2011}, {"title": "and Y", "author": ["D. Gamarnik", "D. Shah"], "venue": "Wei, \u201cBelief propagation for min-cost network flow: convergence & correctness,\u201d in SODA", "citeRegEx": "7", "shortCiteRegEx": null, "year": 2010}, {"title": "Exactness of belief propagation for some graphical models with loops,", "author": ["M. Chertkov"], "venue": "Journal of Statistical Mechanics: Theory and Experiment,", "citeRegEx": "8", "shortCiteRegEx": "8", "year": 2008}, {"title": "Using linear programming to decode binary linear codes,", "author": ["J. Feldman", "M. Wainwright", "D. Karger"], "venue": "Info. Theory, IEEE Trans. on,", "citeRegEx": "9", "shortCiteRegEx": "9", "year": 2005}, {"title": "Towards low-complexity linearprogramming decoding,", "author": ["P.O. Vontobel", "R. Koetter"], "venue": "6th International ITG-Conference on Source and Channel Coding,", "citeRegEx": "10", "shortCiteRegEx": "10", "year": 2006}, {"title": "An efficient pseudocodeword search algorithm for linear programming decoding of LDPC codes,", "author": ["M. Chertkov", "M. Stepanov"], "venue": "Info. Theory, IEEE Trans. on,", "citeRegEx": "11", "shortCiteRegEx": "11", "year": 2008}, {"title": "and M", "author": ["A. Dimakis", "A. Gohari"], "venue": "Wainwright, \u201cGuessing facets: Polytope structure and improved lp decoder,\u201d Info. Theory, IEEE Trans. on, vol. 55, no. 8, pp. 3479 \u20133487", "citeRegEx": "13", "shortCiteRegEx": null, "year": 2009}, {"title": "Convex relaxation methods for graphical models: Lagrangian and maximum entropy approaches,", "author": ["J. Johnson"], "venue": "Ph.D. dissertation, MIT, Department of Electrical Engineering and Computer Science,", "citeRegEx": "14", "shortCiteRegEx": "14", "year": 2008}, {"title": "Approximate inference in graphical models using lp relaxations,", "author": ["D. Sontag"], "venue": "Ph.D. dissertation, MIT, Department of Electrical Engineering and Computer Science,", "citeRegEx": "15", "shortCiteRegEx": "15", "year": 2010}, {"title": "and M", "author": ["S. Kudekar", "J.K. Johnson"], "venue": "Chertkov, \u201cImproved linear programming decoding using frustrated cycles,\u201d CoRR, vol. abs/1105.4665", "citeRegEx": "16", "shortCiteRegEx": null, "year": 2011}, {"title": "and S", "author": ["K. Chandrasekaran", "L.A. V\u00e9gh"], "venue": "Vempala, \u201cThe cutting plane method is polynomial for perfect matchings,\u201d CoRR, vol. abs/1207.5813", "citeRegEx": "17", "shortCiteRegEx": null, "year": 2012}, {"title": "Factor graphs and the sum-product algorithm,", "author": ["F. Kschischang", "B. Frey", "H.-A. Loeliger"], "venue": "Info. Theory, IEEE Trans. on,", "citeRegEx": "18", "shortCiteRegEx": "18", "year": 2001}, {"title": "Paths", "author": ["J. Edmonds"], "venue": "trees, and flowers,\u201d Canadian Journal of mathematics, vol. 17, no. 3, pp. 449\u2013467", "citeRegEx": "19", "shortCiteRegEx": null, "year": 1965}, {"title": "Combinatorial Optimization : Polyhedra and Efficiency (Algorithms and Combinatorics)", "author": ["A. Schrijver"], "venue": null, "citeRegEx": "20", "shortCiteRegEx": "20", "year": 2004}, {"title": "Map estimation", "author": ["Y. Weiss", "C. Yanover", "T. Meltzer"], "venue": "linear programming, and belief propagation with convex free energies,\u201d in UAI", "citeRegEx": "22", "shortCiteRegEx": null, "year": 2007}, {"title": "Cccp algorithms to minimize the bethe and kikuchi free energies: Convergent alternatives to belief propagation,", "author": ["A.L. Yuille"], "venue": "Neural Computation,", "citeRegEx": "23", "shortCiteRegEx": "23", "year": 2002}, {"title": "and A", "author": ["S. Sanghavi", "D. Shah"], "venue": "Willsky, \u201cMessage-passing for max-weight independent set,\u201d in NIPS", "citeRegEx": "24", "shortCiteRegEx": null, "year": 2007}], "referenceMentions": [{"referenceID": 0, "context": "Graphical Models (GMs) provide a useful representation for reasoning in a range of scientific fields [1], [2], [3], [4].", "startOffset": 101, "endOffset": 104}, {"referenceID": 1, "context": "Graphical Models (GMs) provide a useful representation for reasoning in a range of scientific fields [1], [2], [3], [4].", "startOffset": 106, "endOffset": 109}, {"referenceID": 2, "context": "Graphical Models (GMs) provide a useful representation for reasoning in a range of scientific fields [1], [2], [3], [4].", "startOffset": 111, "endOffset": 114}, {"referenceID": 3, "context": "Graphical Models (GMs) provide a useful representation for reasoning in a range of scientific fields [1], [2], [3], [4].", "startOffset": 116, "endOffset": 119}, {"referenceID": 4, "context": "This inspiring result was shown for GMs in which well known optimization problems - namely, the matching problem [5], [6] and min-cost network flow problem [7] - were posed as MAP inference tasks.", "startOffset": 113, "endOffset": 116}, {"referenceID": 5, "context": "This inspiring result was shown for GMs in which well known optimization problems - namely, the matching problem [5], [6] and min-cost network flow problem [7] - were posed as MAP inference tasks.", "startOffset": 118, "endOffset": 121}, {"referenceID": 6, "context": "This inspiring result was shown for GMs in which well known optimization problems - namely, the matching problem [5], [6] and min-cost network flow problem [7] - were posed as MAP inference tasks.", "startOffset": 156, "endOffset": 159}, {"referenceID": 4, "context": "When the weighted matching problem is formulated as a MAP inference task, BPLP is equivalent to the relaxed matching ILP - explaining the success of BP in these GMs [5], [6], [8]! The connection between LP relaxations and BPLP (also called LPdecoding) has also been discussed in the coding literature [9], [10], [11], [12], [13].", "startOffset": 165, "endOffset": 168}, {"referenceID": 5, "context": "When the weighted matching problem is formulated as a MAP inference task, BPLP is equivalent to the relaxed matching ILP - explaining the success of BP in these GMs [5], [6], [8]! The connection between LP relaxations and BPLP (also called LPdecoding) has also been discussed in the coding literature [9], [10], [11], [12], [13].", "startOffset": 170, "endOffset": 173}, {"referenceID": 7, "context": "When the weighted matching problem is formulated as a MAP inference task, BPLP is equivalent to the relaxed matching ILP - explaining the success of BP in these GMs [5], [6], [8]! The connection between LP relaxations and BPLP (also called LPdecoding) has also been discussed in the coding literature [9], [10], [11], [12], [13].", "startOffset": 175, "endOffset": 178}, {"referenceID": 8, "context": "When the weighted matching problem is formulated as a MAP inference task, BPLP is equivalent to the relaxed matching ILP - explaining the success of BP in these GMs [5], [6], [8]! The connection between LP relaxations and BPLP (also called LPdecoding) has also been discussed in the coding literature [9], [10], [11], [12], [13].", "startOffset": 301, "endOffset": 304}, {"referenceID": 9, "context": "When the weighted matching problem is formulated as a MAP inference task, BPLP is equivalent to the relaxed matching ILP - explaining the success of BP in these GMs [5], [6], [8]! The connection between LP relaxations and BPLP (also called LPdecoding) has also been discussed in the coding literature [9], [10], [11], [12], [13].", "startOffset": 306, "endOffset": 310}, {"referenceID": 10, "context": "When the weighted matching problem is formulated as a MAP inference task, BPLP is equivalent to the relaxed matching ILP - explaining the success of BP in these GMs [5], [6], [8]! The connection between LP relaxations and BPLP (also called LPdecoding) has also been discussed in the coding literature [9], [10], [11], [12], [13].", "startOffset": 312, "endOffset": 316}, {"referenceID": 11, "context": "When the weighted matching problem is formulated as a MAP inference task, BPLP is equivalent to the relaxed matching ILP - explaining the success of BP in these GMs [5], [6], [8]! The connection between LP relaxations and BPLP (also called LPdecoding) has also been discussed in the coding literature [9], [10], [11], [12], [13].", "startOffset": 324, "endOffset": 328}, {"referenceID": 12, "context": "It provides a practical certificate of exactness/integrality for MAP inference when using BP and has also suggested strategies for improving upon BP\u2019s results, by adding constraints that reduce the BPLP integrality gap [14], [15], [16].", "startOffset": 219, "endOffset": 223}, {"referenceID": 13, "context": "It provides a practical certificate of exactness/integrality for MAP inference when using BP and has also suggested strategies for improving upon BP\u2019s results, by adding constraints that reduce the BPLP integrality gap [14], [15], [16].", "startOffset": 225, "endOffset": 229}, {"referenceID": 14, "context": "It provides a practical certificate of exactness/integrality for MAP inference when using BP and has also suggested strategies for improving upon BP\u2019s results, by adding constraints that reduce the BPLP integrality gap [14], [15], [16].", "startOffset": 231, "endOffset": 235}, {"referenceID": 4, "context": "We extend the work in [5], [6] by empirically demonstrating that annealing BP can be used to solve LP-relaxations to the weighted matching problems requiring Edmonds\u2019 blossom inequalities.", "startOffset": 22, "endOffset": 25}, {"referenceID": 5, "context": "We extend the work in [5], [6] by empirically demonstrating that annealing BP can be used to solve LP-relaxations to the weighted matching problems requiring Edmonds\u2019 blossom inequalities.", "startOffset": 27, "endOffset": 30}, {"referenceID": 15, "context": "If coupled with the method for finding a tight LP relaxation of \u2018polynomial\u2019 size in [17], annealing BP could be used in a novel, distributed approximation algorithm for the weighted matching problem.", "startOffset": 85, "endOffset": 89}, {"referenceID": 16, "context": "A Graphical Model (GM) represents the above factorization using a bi-partite graph, known as a Factor Graph [18], where each factor \u03b1 \u2208 F is connected to the variables in its argument.", "startOffset": 108, "endOffset": 112}, {"referenceID": 0, "context": "BP for the GM in (3) can be interpreted as a variational optimization procedure in which the messages and beliefs minimize the Bethe Free Energy (BFE) functional [1]", "startOffset": 162, "endOffset": 165}, {"referenceID": 0, "context": "It is known [1] that if BP converges, it finds a minimum (possibly local) of the BFE.", "startOffset": 12, "endOffset": 15}, {"referenceID": 0, "context": "The straightforward LP relaxation of m-ILP is formed by replacing xe \u2208 {0, 1} by xe \u2208 [0, 1].", "startOffset": 86, "endOffset": 92}, {"referenceID": 17, "context": "The LP can be made tight, as famously shown by Edmonds [19], by adding a set of blossom inequalities: m-bl-LP : max \u2211 e\u2208E wexe (13) s.", "startOffset": 55, "endOffset": 59}, {"referenceID": 0, "context": "\u2211 e\u2208\u03b4(i) xe \u2264 1, \u2200i \u2208 V \u2211 e\u2208E(S) xe \u2264 |S|\u22121 2 , \u2200S \u2208 S xe \u2208 [0, 1].", "startOffset": 60, "endOffset": 66}, {"referenceID": 18, "context": "[20].", "startOffset": 0, "endOffset": 4}, {"referenceID": 19, "context": "To overcome both issues, one can use a convex modification of the BFE function [22], and the known convergent variant to BP (providing sufficient damping), called CCCP, to find its minimum [23].", "startOffset": 79, "endOffset": 83}, {"referenceID": 20, "context": "To overcome both issues, one can use a convex modification of the BFE function [22], and the known convergent variant to BP (providing sufficient damping), called CCCP, to find its minimum [23].", "startOffset": 189, "endOffset": 193}, {"referenceID": 4, "context": "Support for natural message initialization comes from [5], [6], [7], [24], where for certain GMs the natural initial messages are needed to prevent BP from converging to an undesirable fixed point.", "startOffset": 54, "endOffset": 57}, {"referenceID": 5, "context": "Support for natural message initialization comes from [5], [6], [7], [24], where for certain GMs the natural initial messages are needed to prevent BP from converging to an undesirable fixed point.", "startOffset": 59, "endOffset": 62}, {"referenceID": 6, "context": "Support for natural message initialization comes from [5], [6], [7], [24], where for certain GMs the natural initial messages are needed to prevent BP from converging to an undesirable fixed point.", "startOffset": 64, "endOffset": 67}, {"referenceID": 21, "context": "Support for natural message initialization comes from [5], [6], [7], [24], where for certain GMs the natural initial messages are needed to prevent BP from converging to an undesirable fixed point.", "startOffset": 69, "endOffset": 73}, {"referenceID": 4, "context": "The work in [5], [6] demonstrated that max-product BP will converge to the MAP solution (and therefore find the maximum weight matching) if the relaxation to the matching ILP without blossoms is tight.", "startOffset": 12, "endOffset": 15}, {"referenceID": 5, "context": "The work in [5], [6] demonstrated that max-product BP will converge to the MAP solution (and therefore find the maximum weight matching) if the relaxation to the matching ILP without blossoms is tight.", "startOffset": 17, "endOffset": 20}], "year": 2013, "abstractText": "Belief Propagation (BP) is a popular, distributed heuristic for performing MAP computations in Graphical Models. BP can be interpreted, from a variational perspective, as minimizing the Bethe Free Energy (BFE). BP can also be used to solve a special class of Linear Programming (LP) problems. For this class of problems, MAP inference can be stated as an integer LP with an LP relaxation that coincides with minimization of the BFE at \u201czero temperature\u201d. We generalize these prior results and establish a tight characterization of the LP problems that can be formulated as an equivalent LP relaxation of MAP inference. Moreover, we suggest an efficient, iterative annealing BP algorithm for solving this broader class of LP problems. We demonstrate the algorithm\u2019s performance on a set of weighted matching problems by using it as a cutting plane method to solve a sequence of LPs tightened by adding \u201cblossom\u201d inequalities.", "creator": "LaTeX with hyperref package"}}}