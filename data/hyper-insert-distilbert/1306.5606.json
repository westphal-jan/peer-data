{"id": "1306.5606", "review": {"conference": "arxiv", "VERSION": "v1", "DATE_OF_SUBMISSION": "24-Jun-2013", "title": "Proteus: A Hierarchical Portfolio of Solvers and Transformations", "abstract": "- in recent 60 years, quantitative portfolio adaptation approaches to theoretically solving sat constraint problems and csps have become equally increasingly common. there are basically also a number of distinct different automated techniques for converting purely sat problems into csps. in this 1993 paper, we leverage cognitive advances in both areas and now present demonstrated a novel reverse hierarchical portfolio - based approach likened to csp convex solving difficulty that strictly does not totally rely perhaps purely strictly on csp compute solvers, but may effectively convert a problem to binary sat constraints choosing a task conversion technique and employing the accommodating sat problems solver. our experimental evaluation relies on competition csp instances and ideally uses eight csp system solvers, including three sat encodings and eighteen incomplete sat solvers. we demonstrate that individually significant performance improvements also can be completely obtained externally by considering potentially alternative cumulative view - spanning points of a combinatorial problem.", "histories": [["v1", "Mon, 24 Jun 2013 13:11:54 GMT  (188kb,D)", "https://arxiv.org/abs/1306.5606v1", null], ["v2", "Mon, 17 Feb 2014 12:26:45 GMT  (123kb,D)", "http://arxiv.org/abs/1306.5606v2", "11th International Conference on Integration of AI and OR Techniques in Constraint Programming for Combinatorial Optimization Problems. The final publication is available at link.springer.com"]], "reviews": [], "SUBJECTS": "cs.AI", "authors": ["barry hurley", "lars kotthoff", "yuri malitsky", "barry o'sullivan"], "accepted": false, "id": "1306.5606"}, "pdf": {"name": "1306.5606.pdf", "metadata": {"source": "CRF", "title": "Proteus: A Hierarchical Portfolio of Solvers and Transformations", "authors": ["Barry Hurley", "Lars Kotthoff", "Yuri Malitsky", "Barry O\u2019Sullivan"], "emails": ["b.hurley@4c.ucc.ie", "l.kotthoff@4c.ucc.ie", "y.malitsky@4c.ucc.ie", "b.osullivan@4c.ucc.ie"], "sections": [{"heading": "1 Introduction", "text": "The pace of development in both csp and sat solver technology has been rapid. Combined with portfolio and algorithm selection technology impressive performance improvements over systems that have been developed only a few years previously have been demonstrated. Constraint satisfaction problems and satisfiability problems are both NP-complete and, therefore, there exist polynomialtime transformations between them. We can leverage this fact to convert csps into sat problems and solve them using sat solvers.\nIn this paper we exploit the fact that different sat solvers have different performances on different encodings of the same csp. In fact, the particular choice of encoding that will give good performance with a particular sat solver is dependent on the problem instance to be solved. We show that, in addition to using dedicated csp solvers, to achieve the best performance for solving a csp the best course of action might be to translate it to sat and solve it using a sat solver. We name our approach Proteus, after the Greek god Proteus, the shape-shifting water deity that can foretell the future.\nOur approach offers a novel perspective on using sat solvers for constraint solving. The idea of solving csps as sat instances is not new; the solvers Sugar, Azucar, and CSP2SAT4J are three examples of sat-based csp solving. Sugar [29]\nar X\niv :1\n30 6.\n56 06\nv2 [\ncs .A\nI] 1\n7 Fe\nb 20\nhas been very competitive in recent csp solver competitions. It converts the csp to sat using a specific encoding, known as the order encoding, which will be discussed in more detail later in this paper. Azucar [30] is a related satbased csp solver that uses the compact order encoding. However, both Sugar and Azucar use a single predefined solver to solve the encoded csp instances. Our work does not assume that conversion using a specific encoding to sat is the best way of solving a problem, but considers multiple candidate encodings and solvers. CSP2SAT4J [21] uses the SAT4J library as its sat back-end and a set of static rules to choose either the direct or the support encoding for each constraint. For intensional and extensional binary constraints that specify the supports, it uses the support encoding. For all other constraints, it uses the direct encoding. Our approach does not have predefined rules but instead chooses the encoding and solver based on features of the problem instance to solve.\nOur approach employs algorithm selection techniques to dynamically choose whether to translate to sat, and if so, which sat encoding and solver to use, otherwise it selects which csp solver to use. There has been a great deal of research in the area of algorithm selection and portfolios; we refer the reader to a recent survey of this work [20]. We note three contrasting example approaches to algorithm selection for the constraint satisfaction and satisfiability problems: CPhydra (csp), SATzilla (sat), and isac (sat). CPhydra [24] contains an algorithm portfolio of csp solvers which partitions CPU-Time between components of the portfolio in order to maximize the probability of solving a given problem instance within a fixed time limit. SATzilla [34], at its core, uses costsensitive decision forests that vote on the sat solver to use for an instance. In addition to that, it contains a number of practical optimizations, for example running a pre-solver to quickly solve the easy instances. isac [17] is a clusterbased approach that groups instances based on their features and then finds the best solver for each cluster. The Proteus approach is not a straightforward application of portfolio techniques. In particular, there is a series of decisions to make that affect not only the solvers that will be available, but also the information that can be used to make the decision. Because of this, the different choices of conversions, encodings and solvers cannot simply be seen as different algorithms or different configurations of the same algorithm.\nThe remainder of this paper is organised as follows. Section 2 motivates the need to choose the representation and solver in combination. In Section 3 we summarise the necessary background on csp and sat to make the paper self-contained and present an overview of the main sat encodings of csps. The detailed evaluation of our portfolio is presented in Section 4. We create a portfolio-based approach to csp solving that employs four csp solvers, three sat encodings, and six sat solvers. Finally, we conclude in Section 5."}, {"heading": "2 Multiple Encodings and Solvers", "text": "To motivate our work, we performed a detailed investigation for two solvers to assess the relationship between solver and problem encoding with features of\nthe problem to be solved. For this experiment we considered uniform random binary (urb) csps with a fixed number of variables, domain size and number of constraints, and varied the constraint tightness. The constraint tightness t is a measure of the proportion of forbidden to allowed possible assignments to the variables in the scope of the constraint. We vary it from 0 to 1, where 0 means that all assignments are allowed and 1 that no assignments are part of a solution, in increments of 0.005. At each tightness the mean run-time of the solver on 100 random csp instances is reported. Each instance contains 30 variables with domain size 20 and 300 constraints. This allowed us to study the performance of sat encodings and solvers across the phase transition.\nFigure 1 plots the run-time for MiniSat and Clasp on uniformly random binary csps that have been translated to sat using three different encodings. Observe that in Figure 1(a) there is a distinct difference in the performance of MiniSat on each of the encodings, sometimes an order of magnitude. Before the phase transition, we see that the order encoding achieves the best performance\nand maintains this until the phase transition. Beginning at constraint tightness 0.41, the order encoding gradually starts achieving poorer performance and the support encoding now achieves the best performance.\nNotably, if we rank the encodings based on their performance, the ranking changes after the phase transition. This illustrates that there is not just a single encoding that will perform best overall and that the choice of encoding matters, but also that this choice is dependent on problem characteristics such as constraint tightness.\nAround the phase transition, we observe contrasting performance for Clasp, as illustrated in Figure 1(b). Using Clasp, the ranking of encodings around the phase transition is direct support order; whereas for MiniSat the ranking is order direct support. Note also that the peaks at the phase transition differ in magnitude between the two solvers. These differences underline the importance of the choice of solver, in particular in conjunction with the choice of encoding \u2013 making the two choices in isolation does not consider the interdependencies that affect performance in practice.\nIn addition to the random csp instances, our analysis also comprises 1493 challenging benchmark problem instances from the csp solver competitions that involve global and intensional constraints. Figure 2 illustrates the respective performance of the best csp-based and sat-based methods on these instances. Unsurprisingly the dedicated csp methods often achieve the best performance. There are, however, numerous cases where considering sat-based methods has the potential to yield significant performance improvements. In particular, there are a number of instances that are unsolved by any csp solver but can be solved quickly using sat-based methods. The Proteus approach aims to unify the best of both worlds and take advantage of the potential performance gains."}, {"heading": "3 Background", "text": ""}, {"heading": "3.1 The Constraint Satisfaction Problem", "text": "Constraint satisfaction problems (csp) are a natural means of expressing and reasoning about combinatorial problems. They have a large number of practical applications such as scheduling, planning, vehicle routing, configuration, network design, routing and wavelength assignment [26]. An instance of a csp is represented by a set of variables, each of which can be assigned a value from its domain. The assignments to the variables must be consistent with a set of constraints, where each constraint limits the values that can be assigned to variables.\nFinding a solution to a csp is typically done using systematic search based on backtracking. Because the general problem is NP-complete, systematic search algorithms have exponential worst-case run times, which has the effect of limiting the scalability of these methods. However, thanks to the development of effective heuristics and a wide variety of solvers with different strengths and weaknesses, many problems can be solved efficiently in practice."}, {"heading": "3.2 The Satisfiability Problem", "text": "The satisfiability problem (sat) consists of a set of Boolean variables and a propositional formula over these variables. The task is to decide whether or not there exists a truth assignment to the variables such that the propositional formula evaluates to true, and, if this is the case, to find this assignment.\nsat instances are usually expressed in conjunctive normal form (cnf). The representation consists of a conjunction of clauses, where each clause is a disjunction of literals. A literal is either a variable or its negation. Each clause is a logical or of its literals and the formula is a logical and of each clause. The following sat formula is in cnf:\n(x1 \u2228 x2 \u2228 \u00acx4) \u2227 (\u00acx2 \u2228 \u00acx3) \u2227 (x3 \u2228 x4)\nThis instance consists of four sat variables. One assignment to the variables which would satisfy the above formula would be to set x1 = true, x2 = false, x3 = true and x4 = true.\nsat, like csp, has a variety of practical real world applications such as hardware verification, security protocol analysis, theorem proving, scheduling, rout-\ning, planning, digital circuit design [5]. The application of sat to many of these problems is made possible by transformations from representations like the constraint satisfaction problem. We will study three transformations into sat that can benefit from this large collection of solvers.\nThe following sections explain the direct, support, and direct-order encodings that we use. We will use the following notation. The set of csp variables is represented by the set X . We use uppercase letters to denote csp variables in X ; lowercase xi and xv refer to sat variables. The domain of a csp variable X is denoted D(X) and has size d."}, {"heading": "3.3 Direct Encoding", "text": "Translating a csp variable X into sat using the direct encoding [32], also known as the sparse encoding, creates a sat variable for each value in its domain: x1, x2, . . . , xd. If xv is true in the resulting sat formula, then X = v in the csp solution. This means that in order to represent a solution to the csp, exactly one of x1, x2, . . . , xd must be assigned true. We add an at-least-one clause to the sat formula for each csp variable as follows:\n\u2200X \u2208 X : (x1 \u2228 x2 \u2228 . . . \u2228 xd).\nConversely, to ensure that only one of these can be set to true, we add at-mostone clauses. For each pair of distinct values in the domain of X, we add a binary clause to enforce that at most one of the two can be assigned true. The series of these binary clauses ensure that only one of the sat variables representing the variable will be assigned true, i.e.\n\u2200v, w \u2208 D(X) : (\u00acxv \u2228 \u00acxw).\nConstraints between csp variables are represented in the direct encoding by enumerating the conflicting tuples. For binary constraints for example, we add clauses as above to forbid both values being used at the same time for each disallowed assignment. For a binary constraint between a pair of variables X and Y , we add the conflict clause (\u00acxv \u2228 \u00acyw) if the tuple \u3008X = v, Y = w\u3009 is forbidden. For intensionally specified constraints, we enumerate all possible tuples and encode the disallowed assignments.\nExample 1 (Direct Encoding). Consider a simple csp with three variables X = {X,Y, Z}, each with domain \u30081, 2, 3\u3009. We have an all-different constraint over the variables: alldifferent(X,Y, Z), which we represent by encoding the pairwise disequalities. Table 1 shows the complete direct-encoded cnf formula for this csp. The first 12 clauses encode the domains of the variables, the remaining clauses encode the constraints between X, Y , and Z. There is an implicit conjunction between these clauses."}, {"heading": "3.4 Support Encoding", "text": "The support encoding [9,18] uses the same mechanism as the direct encoding to encode csp domains into sat \u2013 each value in the domain of a csp variable is encoded as a sat variable which represents whether or not it takes that value. However, the support encoding differs on how the constraints between variables are encoded. Given a constraint between two variables X and Y , for each value v in the domain of X, let SY,X=v \u2282 D(Y ) be the subset of the values in the domain of Y which are consistent with assigning X = v. Either xv is false or one of the consistent assignments from y1 . . . yd must be true. This is encoded in the support clause\n\u00acxv \u2228  \u2228 i\u2208SY,X=v yi  . Conversely, for each value w in the domain of Y , a support clause is added for the supported values in X which are consistent with assigning Y = w.\nAn interesting property of the support encoding is that if a constraint has no consistent values in the corresponding variable, a unit-clause will be added, thereby pruning the values from the domain of a variable which cannot exist in any solution. Also, a solution to a sat formula without the at-most-one constraint in the support encoding represents an arc-consistent assignment to the csp. Unit propagation on this sat instance establishes arc-consistency in optimal worst-case time for establishing arc-consistency [9].\nExample 2 (Support Encoding). Table 2 gives the complete support-encoded cnf formula for the simple csp given in Example 1. The first 12 clauses encode the domains and the remaining ones the support clauses for the constraints. There is an implicit conjunction between clauses."}, {"heading": "3.5 Order Encoding", "text": "Unlike the direct and support encoding, which model X = v as a sat variable for each value v in the domain of X, the order encoding (also known as the regular encoding [2]) creates sat variables to represent X \u2264 v. If X is less than or equal to v (denoted x\u2264v), then X must also be less than or equal to v + 1\n(x\u2264v+1). Therefore, we add clauses to enforce this consistency across the domain as follows: \u2200d\u22121v : (\u00acx\u2264v \u2228 x\u2264v+1). This linear number of clauses is all that is needed to encode the domain of a csp variable into sat in the order encoding. In contrast, the direct and support encodings require a quadratic number of clauses in the domain size.\nThe order encoding is naturally suited to modelling inequality constraints. To state X \u2264 3, we would just post the unit clause (x\u22643). If we want to model the constraint X = v, we could rewrite it as (X \u2264 v \u2227 X \u2265 v). X \u2265 v can then be rewritten as \u00acX \u2264 (v \u2212 1). To state that X = v in the order encoding, we would encode (x\u2264v \u2227\u00acx\u2264v\u22121). A conflicting tuple between two variables, for example \u3008X = v, Y = w\u3009 can be written in propositional logic and simplified to a cnf clause using De Morgan\u2019s Law:\n\u00ac((x\u2264v \u2227 x\u2265v) \u2227 (y\u2264w \u2227 y\u2265w)) \u00ac((x\u2264v \u2227 \u00acx\u2264v\u22121) \u2227 (y\u2264w \u2227 \u00acy\u2264w\u22121)) \u00ac(x\u2264v \u2227 \u00acx\u2264v\u22121) \u2228 \u00ac(y\u2264w \u2227 \u00acy\u2264w\u22121)\n(\u00acx\u2264v \u2228 x\u2264v\u22121 \u2228 \u00acy\u2264w \u2228 y\u2264w\u22121)\nExample 3 (Order Encoding). Table 3 gives the complete order-encoded cnf formula for the simple csp specified in Example 1. There is an implicit conjunction between clauses in the notation."}, {"heading": "3.6 Combining the Direct and Order Encodings", "text": "The direct encoding and the order encoding can be combined to produce a potentially more compact encoding. A variable\u2019s domain is encoded in both representations and clauses are added to chain between them. This gives flexibility in the representation of each constraint. Here, we choose the encoding which gives the most compact formula. For example, for inequalities we use the order encoding since it is naturally suited, but for a (dis)equality we would use the direct encoding. This encoding is referred to as direct-order throughout the paper."}, {"heading": "3.7 Algorithm Portfolios", "text": "The Algorithm Selection Problem [25] is to select the most appropriate algorithm for solving a particular problem. It is especially relevant in the context of algorithm portfolios [11,16], where a single solver is replaced with a set of solvers and a mechanism for selecting a subset to use on a particular problem.\nAlgorithm portfolios have been used with great success for solving both sat and csp instances in systems such as SATzilla [34], isac [17] or CPhydra [24]. Most approaches are similar in that they relate the characteristics of a problem to solve to the performance of the algorithms in the portfolio. The aim of an algorithm selection model is to provide a prediction as to which algorithm should be used to solve the problem. The model is usually induced using some form of machine learning.\nThere are three main approaches to using machine learning to build algorithm selection models. First, the problem of predicting the best algorithm can be treated as a classification problem where the label to predict is the algorithm. Second, the training data can be clustered and the algorithm with the best performance on a particular cluster assigned to it. The cluster membership of any new data decides the algorithm to use. Finally, regression models can be trained to predict the performance of each portfolio algorithm in isolation. The best algorithm for a problem is chosen based on the predicted performances.\nOur approach makes a series of decisions \u2013 whether a problem should be solved as a csp or a sat problem, which encoding should be used for converting into sat, and finally which solver should be assigned to tackle the problem. Approaches that make a series of decisions are usually referred to as hierarchical models. [33] and [12] use hierarchical models in the context of a sat portfolio. They first predict whether the problem to be solved is expected to be satisfiable or not and then choose a solver depending on that decision. Our approach is closer to [10], which first predicts what level of consistency the alldifferent constraint should achieve before deciding on its implementation.\nTo the best of our knowledge, no portfolio approach that potentially transforms the representation of a problem in order to be able to solve it more efficiently exists at present."}, {"heading": "4 Experimental Evaluation", "text": ""}, {"heading": "4.1 Setup", "text": "The hierarchical model we present in this paper consists of a number of layers to determine how the instance should be solved. At the top level, we decide whether to solve the instance using as a csp or using a sat-based method. If we choose to leave the problem as a csp, then one of the dedicated csp solvers must be chosen. Otherwise, we must choose the sat encoding to apply, followed by the choice of sat solver to run on the sat-encoded instance.\nEach decision of the hierarchical approach aims to choose the direction which has the potential to achieve the best performance in that sub-tree. For example, for the decision to choose whether to solve the instance using a sat-based method or not, we choose the sat-based direction if there is a sat solver and encoding that will perform faster than any csp solver would. Whether this particular encoding-solver combination will be selected subsequently depends on the performance of the algorithm selection models used in that sub-tree of our decision mechanism. For regression models, the training data is the best performance of any solver under that branch of the tree. For classification models, it is the label of the sub-branch with the virtual best performance.\nThis hierarchical approach presents the opportunity to employ different decision mechanisms at each level. We consider 6 regression, 19 classification, and 3 clustering algorithms, which are listed below. For each of these algorithms, we evaluate the performance using 10-fold cross-validation. The dataset is split into 10 partitions with approximately the same size and the same distribution of the best solvers. One partition is used for testing and the remaining 9 partitions as the training data for the model. This process is repeated with a different partition considered for testing each time until every partition has been used for testing. We measure the performance in terms of PAR10 score. The PAR10 score for an instance is the time it takes the solver to solve the instance, unless the solver times out. In this case, the PAR10 score is ten times the timeout value. The sum over all instances is divided by the number of instances.\nInstances. In our evaluation, we consider csp problem instances from the csp solver competitions [1]. Of these, we consider all instances defined using global and intensional constraints that are not trivially solved during 2 seconds of feature computation. We also exclude all instances which were not solved by any csp or sat solver within the time limit of 1 hour. Altogether, we obtain 1,493 non-trivial instances from problem classes such as Timetabling, Frequency Assignment, Job-Shop, Open-Shop, Quasi-group, Costas Array, Golomb Ruler, Latin Square, All Interval Series, Balanced Incomplete Block Design, and many others. This set includes both small and large arity constraints and all of the\nglobal constraints used during the csp solver competitions: all-different, element, weighted sum, and cumulative.\nFor the sat-based approaches, Numberjack [15] was used to translate a csp instance specified in xcsp format [27] into sat (cnf).\nFeatures. A fundamental requirement of any machine learning algorithm is a set of representative features. We explore a number of different feature sets to train our models: i) features of the original csp instance, ii) features of the direct-encoded sat instance, iii) features of the support-encoded sat instance, iv) features of the direct-order-encoded sat instance and v) a combination of all four feature sets. These features are described in further detail below.\nWe computed the 36 features used in CPhydra for each csp instance using Mistral; for reasons of space we will not enumerate them all here. The set includes static features like statistics about the types of constraints used, average and maximum domain size; and dynamic statistics recorded by running Mistral for 2 seconds: average and standard deviation of variable weights, number of nodes, number of propagations and a few others. Instances which are solved by Mistral during feature computation are filtered out from the dataset.\nIn addition to the csp features, we computed the 54 sat features used by SATzilla [34] for each of the encoded instances and different encodings. The features encode a wide range of different information on the problem such as problem size, features of the graph-based representation, balance features, the proximity to a Horn formula, DPLL probing features and local search probing features.\nConstraint Solvers. Our csp models are able to choose from 4 complete csp solvers:\n\u2013 Abscon [22], \u2013 Choco [31],\n\u2013 Gecode [8], and \u2013 Mistral [14].\nSatisfiability Solvers. We considered the following 6 complete sat solvers:\n\u2013 clasp [7], \u2013 cryptominisat [28], \u2013 glucose [3],\n\u2013 lingeling [4], \u2013 riss [23], and \u2013 MiniSat [6].\nLearning Algorithms. We evaluate a number of regression, classification, and clustering algorithms using WEKA [13]. All algorithms, unless otherwise stated use the default parameters. The regression algorithms we used were LinearRegression, PaceRegression, REPTree, M5Rules, M5P, and SMOreg. The classification algorithms were BayesNet, BFTree, ConjunctiveRule, DecisionTable, FT, HyperPipes, IBk (nearest neighbour) with 1, 3, 5 and 10 neighbours, J48, J48graft, JRip, LADTree, MultilayerPerceptron, OneR, PART, RandomForest, RandomForest with 99 random trees, RandomTree, REPTree, and SimpleLogistic. For clustering, we considered EM, FarthestFirst, and SimplekMeans. The FarthestFirst and SimplekMeans algorithms require the number of clusters to\nbe given as input. We evaluated with multiples of 1 through 5 of the number of solvers in the respective data set given as the number of clusters. The number of clusters is represented by 1n, 2n and so on in the name of the algorithm, where n stands for the number of solvers.\nWe use the LLAMA toolkit [19] to train and test the algorithm selection models."}, {"heading": "4.2 Portfolio and Solver Results", "text": "The performance of each of the 6 sat solvers was evaluated on the three sat encodings of 1,493 csp competition benchmarks with a time-out of 1 hour and limited to 2GB of RAM. The 4 csp solvers were evaluated on the original csps. Our results report the PAR10 score and number of instances solved for each of the algorithms we evaluate. The PAR10 is the sum of the runtimes over all instances, counting 10 times the timeout if that was reached. Data was collected on a cluster of Intel Xeon E5430 Processors (2.66Ghz) running CentOS 6.4. This data is available online.1\nThe performance of a number of hierarchical approaches is given in Table 4. The hierarchy of algorithms which produced the best overall results for our dataset involves M5P regression with csp features at the root node to choose sat or csp, M5P regression with csp features to select the csp solver, LinearRegression with csp features to select the sat encoding, LinearRegression with csp features to select the sat solver for the direct encoded instance, LinearRegression with csp features to select the sat solver for the direct-order 1 http://4c.ucc.ie/~bhurley/proteus/\nencoded instance, and LinearRegression with the direct-order features to select the sat solver for the support encoded instance. The hierarchical tree of specific machine learning approaches we found to deliver the best overall performance on our data set is labelled Proteus and is depicted in Figure 3.\nWe would like to point out that in many solver competitions the difference between the top few solvers is fewer than 10 additional instances solved. In the 2012 sat Challenge for example, the difference between the first and second place single solver was only 3 instances and the difference among the top 4 solvers was only 8 instances. The results we present in Table 4 are therefore very significant in terms of the gains we are able to achieve.\nOur results demonstrate the power of Proteus. The performance it delivers is very close to the virtual best (VBS), that is the best performance possible if an oracle could identify the best choice of representation, encoding, and solver, on an instance by instance basis. The improvements we achieve over other approaches are similarly impressive. The results conclusively demonstrate that having the option to convert a csp to sat does not only have the potential to achieve significant performance improvements, but also does so in practice.\nAn interesting observation is that the csp features are consistently used in each of the top performing approaches. One reason for this is that it is quicker to compute only the csp features instead of the csp features, then converting to sat and computing the sat features in addition. The additional overhead of computing sat features is worthwhile in some cases though, for example for LinearRegression, which is at its best performance using all the different feature sets. Note that for the best tree of models (cf. Figure 3), it is better to use the features of the direct-order encoding for the decision of which solver to choose for a support-encoded sat instance despite the additional overhead.\nWe also compare the hierarchical approach to that of a flattened setting with a single portfolio of all solvers and encoding solver combinations. The flattened portfolio includes all possible combinations of the 3 encodings and the 6 sat\nsolvers and the 4 csp solvers for a total of 22 solvers. Table 5 shows these results. The regression algorithm LinearRegression with all features gives the best performance using this approach. However, it is significantly worse than the performance achieved by the hierarchical approach of Proteus."}, {"heading": "4.3 Greater than the Sum of its Parts", "text": "Given the performance of Proteus, the question remains as to whether a different portfolio approach that considers just csp or just sat solvers could do better. Table 6 summarizes the virtual best performance that such portfolios could achieve. We use all the csp and sat solvers for the respective portfolios to give us VB CSP and VB SAT, respectively. The former is the approach that always chooses the best csp solver for the current instance, while the latter chooses the best sat encoding/solver combination. VB Proteus is the portfolio that chooses the best overall approach/encoding. We show the actual performance of Proteus for comparison. Proteus is better than the virtual bests for all portfolios that consider only one encoding. This result makes a very strong point for the need to consider encoding and solver in combination.\nProteus outperforms four other VB portfolios. Specifically, the VB CPhydra is the best possible performance that could be obtained from that portfolio if a perfect choice of solver was made. Neither SATzilla nor isac-based portfolios consider different sat encodings. Therefore, the best possible performance either of them could achieve for a specific encoding is represented in the last three lines of Table 6.\nThese results do not only demonstrate the benefit of considering the different ways of solving csps, but also eliminate the need to compare with existing portfolio systems since we are computing the best possible performance that any\nof those systems could theoretically achieve. Proteus impressively demonstrates its strengths by significantly outperforming oracle approaches that use only a single encoding."}, {"heading": "5 Conclusions", "text": "We have presented a portfolio approach that does not rely on a single problem representation or set of solvers, but leverages our ability to convert between problem representations to increase the space of possible solving approaches. To the best of our knowledge, this is the first time a portfolio approach like this has been proposed. We have shown that, to achieve the best performance on a constraint satisfaction problem, it may be beneficial to translate it to a satisfiability problem. For this translation, it is important to choose both the encoding and satisfiability solver in combination. In doing so, the contrasting performance among solvers on different representations of the same problem can be exploited. The overall performance can be improved significantly compared to restricting the portfolio to a single problem representation.\nWe demonstrated empirically the significant performance improvements Proteus can achieve on a large set of diverse benchmarks using a portfolio based on a range of different state-of-the-art solvers. We have investigated a range of different csp to sat encodings and evaluated the performance of a large number of machine learning approaches and algorithms. Finally, we have shown that the performance of Proteus is close to the very best that is theoretically possible for solving csps and significantly outperforms the theoretical best for portfolios that consider only a single problem encoding.\nIn this work, we make a general decision to encode the entire problem using a particular encoding. A natural extension would be to mix and vary the encoding depending on attributes of the problem. An additional avenue for future work would be to generalize the concepts in this paper to other problem domains where transformations, like csp to sat, exist.\nAcknowledgements. This work is supported by Science Foundation Ireland (SFI) Grant 10/IN.1/I3032 and FP7 FET-Open Grant 284715. The Insight Centre for Data Analytics is supported by SFI Grant SFI/12/RC/2289."}], "references": [{"title": "Mapping Problems with Finite-Domain Variables into Problems with Boolean Variables", "author": ["C. Ans\u00f3tegui", "F. Many\u00e0"], "venue": "The 7th International Conference on Theory and Applications of Satisfiability Testing \u2014 SAT\u201904", "citeRegEx": "2", "shortCiteRegEx": null, "year": 2004}, {"title": "Glucose 2.3 in the SAT 2013 Competition", "author": ["G. Audemard", "L. Simon"], "venue": "Proceedings of SAT Competition 2013 p", "citeRegEx": "3", "shortCiteRegEx": "3", "year": 2013}, {"title": "Lingeling, Plingeling and Treengeling Entering the SAT Competition 2013", "author": ["A. Biere"], "venue": "Proceedings of SAT Competition 2013", "citeRegEx": "4", "shortCiteRegEx": null, "year": 2013}, {"title": "Handbook of Satisfiability, Frontiers in Artificial Intelligence and Applications, vol", "author": ["A. Biere", "M.J.H. Heule", "H. van Maaren", "Walsh", "T. (eds."], "venue": "185. IOS Press", "citeRegEx": "5", "shortCiteRegEx": null, "year": 2009}, {"title": "clasp: A conflict-driven answer set solver", "author": ["M. Gebser", "B. Kaufmann", "A. Neumann", "T. Schaub"], "venue": "Logic Programming and Nonmonotonic Reasoning 2007. pp. 260\u2013265. Springer", "citeRegEx": "7", "shortCiteRegEx": null, "year": 2007}, {"title": "Arc Consistency in SAT", "author": ["I.P. Gent"], "venue": "Proceedings of the 15th European Conference on Artificial Intelligence \u2014 ECAI\u20192002. pp. 121\u2013125", "citeRegEx": "9", "shortCiteRegEx": null, "year": 2002}, {"title": "Machine learning for constraint solver design \u2013 a case study for the alldifferent constraint", "author": ["I.P. Gent", "L. Kotthoff", "I. Miguel", "P. Nightingale"], "venue": "3rd Workshop on Techniques for implementing Constraint Programming Systems (TRICS). pp. 13\u2013 25", "citeRegEx": "10", "shortCiteRegEx": null, "year": 2010}, {"title": "Algorithm portfolios", "author": ["C.P. Gomes", "B. Selman"], "venue": "Artificial Intelligence 126(1-2), 43\u2013 62", "citeRegEx": "11", "shortCiteRegEx": null, "year": 2001}, {"title": "Restart strategy selection using machine learning techniques", "author": ["S. Haim", "T. Walsh"], "venue": "Proceedings of the 12th International Conference on Theory and Applications of Satisfiability Testing \u2014 SAT\u201909. pp. 312\u2013325. Springer-Verlag, Berlin, Heidelberg", "citeRegEx": "12", "shortCiteRegEx": null, "year": 2009}, {"title": "The WEKA data mining software: An update", "author": ["M. Hall", "E. Frank", "G. Holmes", "B. Pfahringer", "P. Reutemann", "I.H. Witten"], "venue": "SIGKDD Explor. Newsl. 11(1), 10\u201318", "citeRegEx": "13", "shortCiteRegEx": null, "year": 2009}, {"title": "Mistral, a Constraint Satisfaction Library", "author": ["E. Hebrard"], "venue": "Proceedings of the Third International CSP Solver Competition", "citeRegEx": "14", "shortCiteRegEx": null, "year": 2008}, {"title": "Constraint Programming and Combinatorial Optimisation in Numberjack", "author": ["E. Hebrard", "E. O\u2019Mahony", "B. O\u2019Sullivan"], "venue": "Integration of AI and OR Techniques in Constraint Programming for Combinatorial Optimization Problems, 7th International Conference, CPAIOR 2010. pp. 181\u2013185", "citeRegEx": "15", "shortCiteRegEx": null, "year": 2010}, {"title": "An economics approach to hard computational problems", "author": ["B.A. Huberman", "R.M. Lukose", "T. Hogg"], "venue": "Science 275(5296), 51\u201354", "citeRegEx": "16", "shortCiteRegEx": null, "year": 1997}, {"title": "ISAC \u2013 Instance-Specific Algorithm Configuration", "author": ["S. Kadioglu", "Y. Malitsky", "M. Sellmann", "K. Tierney"], "venue": "Coelho, H., Studer, R., Wooldridge, M. (eds.) ECAI. Frontiers in Artificial Intelligence and Applications, vol. 215, pp. 751\u2013756. IOS Press", "citeRegEx": "17", "shortCiteRegEx": null, "year": 2010}, {"title": "On the Parallel Complexity of Discrete Relaxation in Constraint Satisfaction Networks", "author": ["S. Kasif"], "venue": "Artificial Intelligence", "citeRegEx": "18", "shortCiteRegEx": "18", "year": 1990}, {"title": "LLAMA: leveraging learning to automatically manage algorithms", "author": ["L. Kotthoff"], "venue": "Tech. Rep. arXiv:1306.1031,", "citeRegEx": "19", "shortCiteRegEx": "19", "year": 2013}, {"title": "Algorithm Selection for Combinatorial Search Problems: A Survey", "author": ["L. Kotthoff"], "venue": "AI Magazine", "citeRegEx": "20", "shortCiteRegEx": "20", "year": 2014}, {"title": "CSP2SAT4J: A Simple CSP to SAT Translator", "author": ["D. Le Berre", "I. Lynce"], "venue": "Proceedings of the Second International CSP Solver Competition", "citeRegEx": "21", "shortCiteRegEx": null, "year": 2008}, {"title": "Abscon 112, Toward more Robustness", "author": ["C. Lecoutre", "S. Tabary"], "venue": "Proceedings of the Third International CSP Solver Competition", "citeRegEx": "22", "shortCiteRegEx": null, "year": 2008}, {"title": "The SAT Solver RISS3G at SC 2013", "author": ["N. Manthey"], "venue": "Proceedings of SAT Competition 2013 p. 72", "citeRegEx": "23", "shortCiteRegEx": null, "year": 2013}, {"title": "Using Casebased Reasoning in an Algorithm Portfolio for Constraint Solving", "author": ["E. O\u2019Mahony", "E. Hebrard", "A. Holland", "C. Nugent", "B. O\u2019Sullivan"], "venue": "Proceeding of the 19th Irish Conference on Artificial Intelligence and Cognitive Science", "citeRegEx": "24", "shortCiteRegEx": null, "year": 2008}, {"title": "The algorithm selection problem", "author": ["J.R. Rice"], "venue": "Advances in Computers 15, 65\u2013118", "citeRegEx": "25", "shortCiteRegEx": null, "year": 1976}, {"title": "Handbook of Constraint Programming", "author": ["F. Rossi", "P. van Beek", "T. Walsh"], "venue": "Foundations of Artificial Intelligence, Elsevier, New York, NY, USA", "citeRegEx": "26", "shortCiteRegEx": null, "year": 2006}, {"title": "XML Representation of Constraint Networks: Format XCSP", "author": ["O. Roussel", "C. Lecoutre"], "venue": null, "citeRegEx": "27", "shortCiteRegEx": "27", "year": 2009}, {"title": "System Description of a SAT-based CSP Solver Sugar", "author": ["N. Tamura", "T. Tanjo", "M. Banbara"], "venue": "Proceedings of the Third International CSP Solver Competition. pp. 71\u201375", "citeRegEx": "29", "shortCiteRegEx": null, "year": 2009}, {"title": "Azucar: A SAT-Based CSP Solver Using Compact Order Encoding \u2014 (Tool Presentation)", "author": ["T. Tanjo", "N. Tamura", "M. Banbara"], "venue": "Proceedings of the 15th International Conference on Theory and Applications of Satisfiability Testing \u2014 SAT\u201912. pp. 456\u2013462. Springer", "citeRegEx": "30", "shortCiteRegEx": null, "year": 2012}, {"title": "SAT v CSP", "author": ["T. Walsh"], "venue": "Principles and Practice of Constraint Programming \u2014 CP 2000. vol. 1894, pp. 441\u2013456. Springer-Verlag", "citeRegEx": "32", "shortCiteRegEx": null, "year": 2000}, {"title": "Hierarchical hardness models for SAT", "author": ["L. Xu", "H.H. Hoos", "K. Leyton-Brown"], "venue": "Principles and Practice of Constraint Programming \u2014 CP\u201907. pp. 696\u2013711", "citeRegEx": "33", "shortCiteRegEx": null, "year": 2007}, {"title": "SATzilla: Portfolio-based Algorithm Selection for SAT", "author": ["L. Xu", "F. Hutter", "H.H. Hoos", "K. Leyton-Brown"], "venue": "Journal of Artificial Intelligence Research pp. 565\u2013606", "citeRegEx": "34", "shortCiteRegEx": null, "year": 2008}], "referenceMentions": [{"referenceID": 24, "context": "Sugar [29] ar X iv :1 30 6.", "startOffset": 6, "endOffset": 10}, {"referenceID": 25, "context": "Azucar [30] is a related satbased csp solver that uses the compact order encoding.", "startOffset": 7, "endOffset": 11}, {"referenceID": 17, "context": "CSP2SAT4J [21] uses the SAT4J library as its sat back-end and a set of static rules to choose either the direct or the support encoding for each constraint.", "startOffset": 10, "endOffset": 14}, {"referenceID": 16, "context": "There has been a great deal of research in the area of algorithm selection and portfolios; we refer the reader to a recent survey of this work [20].", "startOffset": 143, "endOffset": 147}, {"referenceID": 20, "context": "CPhydra [24] contains an algorithm portfolio of csp solvers which partitions CPU-Time between components of the portfolio in order to maximize the probability of solving a given problem instance within a fixed time limit.", "startOffset": 8, "endOffset": 12}, {"referenceID": 28, "context": "SATzilla [34], at its core, uses costsensitive decision forests that vote on the sat solver to use for an instance.", "startOffset": 9, "endOffset": 13}, {"referenceID": 13, "context": "isac [17] is a clusterbased approach that groups instances based on their features and then finds the best solver for each cluster.", "startOffset": 5, "endOffset": 9}, {"referenceID": 22, "context": "They have a large number of practical applications such as scheduling, planning, vehicle routing, configuration, network design, routing and wavelength assignment [26].", "startOffset": 163, "endOffset": 167}, {"referenceID": 3, "context": "ing, planning, digital circuit design [5].", "startOffset": 38, "endOffset": 41}, {"referenceID": 26, "context": "Translating a csp variable X into sat using the direct encoding [32], also known as the sparse encoding, creates a sat variable for each value in its domain:", "startOffset": 64, "endOffset": 68}, {"referenceID": 5, "context": "The support encoding [9,18] uses the same mechanism as the direct encoding to encode csp domains into sat \u2013 each value in the domain of a csp variable is encoded as a sat variable which represents whether or not it takes that value.", "startOffset": 21, "endOffset": 27}, {"referenceID": 14, "context": "The support encoding [9,18] uses the same mechanism as the direct encoding to encode csp domains into sat \u2013 each value in the domain of a csp variable is encoded as a sat variable which represents whether or not it takes that value.", "startOffset": 21, "endOffset": 27}, {"referenceID": 5, "context": "Unit propagation on this sat instance establishes arc-consistency in optimal worst-case time for establishing arc-consistency [9].", "startOffset": 126, "endOffset": 129}, {"referenceID": 0, "context": "Unlike the direct and support encoding, which model X = v as a sat variable for each value v in the domain of X, the order encoding (also known as the regular encoding [2]) creates sat variables to represent X \u2264 v.", "startOffset": 168, "endOffset": 171}, {"referenceID": 21, "context": "The Algorithm Selection Problem [25] is to select the most appropriate algorithm for solving a particular problem.", "startOffset": 32, "endOffset": 36}, {"referenceID": 7, "context": "It is especially relevant in the context of algorithm portfolios [11,16], where a single solver is replaced with a set of solvers and a mechanism for selecting a subset to use on a particular problem.", "startOffset": 65, "endOffset": 72}, {"referenceID": 12, "context": "It is especially relevant in the context of algorithm portfolios [11,16], where a single solver is replaced with a set of solvers and a mechanism for selecting a subset to use on a particular problem.", "startOffset": 65, "endOffset": 72}, {"referenceID": 28, "context": "Algorithm portfolios have been used with great success for solving both sat and csp instances in systems such as SATzilla [34], isac [17] or CPhydra [24].", "startOffset": 122, "endOffset": 126}, {"referenceID": 13, "context": "Algorithm portfolios have been used with great success for solving both sat and csp instances in systems such as SATzilla [34], isac [17] or CPhydra [24].", "startOffset": 133, "endOffset": 137}, {"referenceID": 20, "context": "Algorithm portfolios have been used with great success for solving both sat and csp instances in systems such as SATzilla [34], isac [17] or CPhydra [24].", "startOffset": 149, "endOffset": 153}, {"referenceID": 27, "context": "[33] and [12] use hierarchical models in the context of a sat portfolio.", "startOffset": 0, "endOffset": 4}, {"referenceID": 8, "context": "[33] and [12] use hierarchical models in the context of a sat portfolio.", "startOffset": 9, "endOffset": 13}, {"referenceID": 6, "context": "Our approach is closer to [10], which first predicts what level of consistency the alldifferent constraint should achieve before deciding on its implementation.", "startOffset": 26, "endOffset": 30}, {"referenceID": 11, "context": "For the sat-based approaches, Numberjack [15] was used to translate a csp instance specified in xcsp format [27] into sat (cnf).", "startOffset": 41, "endOffset": 45}, {"referenceID": 23, "context": "For the sat-based approaches, Numberjack [15] was used to translate a csp instance specified in xcsp format [27] into sat (cnf).", "startOffset": 108, "endOffset": 112}, {"referenceID": 28, "context": "In addition to the csp features, we computed the 54 sat features used by SATzilla [34] for each of the encoded instances and different encodings.", "startOffset": 82, "endOffset": 86}, {"referenceID": 18, "context": "\u2013 Abscon [22], \u2013 Choco [31], \u2013 Gecode [8], and \u2013 Mistral [14].", "startOffset": 9, "endOffset": 13}, {"referenceID": 10, "context": "\u2013 Abscon [22], \u2013 Choco [31], \u2013 Gecode [8], and \u2013 Mistral [14].", "startOffset": 57, "endOffset": 61}, {"referenceID": 4, "context": "\u2013 clasp [7], \u2013 cryptominisat [28], \u2013 glucose [3], \u2013 lingeling [4], \u2013 riss [23], and \u2013 MiniSat [6].", "startOffset": 8, "endOffset": 11}, {"referenceID": 1, "context": "\u2013 clasp [7], \u2013 cryptominisat [28], \u2013 glucose [3], \u2013 lingeling [4], \u2013 riss [23], and \u2013 MiniSat [6].", "startOffset": 45, "endOffset": 48}, {"referenceID": 2, "context": "\u2013 clasp [7], \u2013 cryptominisat [28], \u2013 glucose [3], \u2013 lingeling [4], \u2013 riss [23], and \u2013 MiniSat [6].", "startOffset": 62, "endOffset": 65}, {"referenceID": 19, "context": "\u2013 clasp [7], \u2013 cryptominisat [28], \u2013 glucose [3], \u2013 lingeling [4], \u2013 riss [23], and \u2013 MiniSat [6].", "startOffset": 74, "endOffset": 78}, {"referenceID": 9, "context": "We evaluate a number of regression, classification, and clustering algorithms using WEKA [13].", "startOffset": 89, "endOffset": 93}, {"referenceID": 15, "context": "We use the LLAMA toolkit [19] to train and test the algorithm selection models.", "startOffset": 25, "endOffset": 29}], "year": 2014, "abstractText": "In recent years, portfolio approaches to solving SAT problems and CSPs have become increasingly common. There are also a number of different encodings for representing CSPs as SAT instances. In this paper, we leverage advances in both SAT and CSP solving to present a novel hierarchical portfolio-based approach to CSP solving, which we call Proteus, that does not rely purely on CSP solvers. Instead, it may decide that it is best to encode a CSP problem instance into SAT, selecting an appropriate encoding and a corresponding SAT solver. Our experimental evaluation used an instance of Proteus that involved four CSP solvers, three SAT encodings, and six SAT solvers, evaluated on the most challenging problem instances from the CSP solver competitions, involving global and intensional constraints. We show that significant performance improvements can be achieved by Proteus obtained by exploiting alternative view-points and solvers for combinatorial problem-solving.", "creator": "LaTeX with hyperref package"}}}