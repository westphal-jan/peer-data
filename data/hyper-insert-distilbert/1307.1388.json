{"id": "1307.1388", "review": {"conference": "arxiv", "VERSION": "v1", "DATE_OF_SUBMISSION": "4-Jul-2013", "title": "Introducing Memory and Association Mechanism into a Biologically Inspired Visual Model", "abstract": "a famous biologically socially inspired hierarchical cognition model sketch firstly repeatedly proposed twice by riesenhuber schneider and roberto poggio has somehow been successfully applied to multiple neural visual association recognition systems tasks. the cellular model metaphor is theoretically able mainly to effectively achieve thus a set of concurrent position - and scale - tolerant recognition, which is a central psychological problem theme in pattern recognition. in interpreting this paper, based on some other biological experimental results, respectively we introduce the memory and dynamic association mechanisms into the above biologically inspired the model. the main experimental motivations of the work are ( essentially a ) basically to loosely mimic quite the active memory and association utilization mechanism and add the'top, down'adjustment to the above previous biologically inspired secondary hierarchical model and ( b ) to patiently build up much an algorithm which can truly save the space presented and usually keep a good information recognition performance. indeed the new comprehensive model tool is also periodically applied additionally to object recognition processes. the desired primary experimental results might show that our method is efficient with much no less memory depth requirement.", "histories": [["v1", "Thu, 4 Jul 2013 16:08:56 GMT  (1948kb)", "http://arxiv.org/abs/1307.1388v1", "9 pages, 10 figures"]], "COMMENTS": "9 pages, 10 figures", "reviews": [], "SUBJECTS": "cs.AI", "authors": ["qiao hong", "li yinlin", "tang tang", "wang peng"], "accepted": false, "id": "1307.1388"}, "pdf": {"name": "1307.1388.pdf", "metadata": {"source": "CRF", "title": "Introducing Memory and Association Mechanism Into a Biologically Inspired Visual Model", "authors": ["Hong Qiao", "Peng Wang"], "emails": ["hong.qiao@ia.ac.cn)."], "sections": [{"heading": null, "text": "ar X\niv :1\n30 7.\n13 88\nv1 [\ncs .A\nI] 4\nJ ul\n2 01\n3 1\nIn this paper, based on some other biological experimental results, we introduce the Memory and Association Mechanisms into the above biologically inspired model. The main motivations of the work are (a) to mimic the active memory and association mechanism and add the \u2019top down\u2019 adjustment to the above biologically inspired hierarchical model and (b) to build up an algorithm which can save the space and keep a good recognition performance.\nMore details of the work could be explained as follows:\n(1) In objects memorizing process: Our proposed model mimics some characteristics of human\u2019s memory mechanism as follows: (a) In our model, one object is memorized by semantic attributes and special image patches (corresponding to episodic memory). The semantic attributes describe each part of the object with clear physical meaning, for example, if eyes and mouths of faces are \u2019big\u2019 or \u2019small\u2019 and so on. One special patch is selected if the value of the corresponding semantic feature is far from average one. The patch should be the most prominent part of the object. (b) In our model, different features (semantic attributes and special patches) of one object are stored in distributed places and the common feature of different objects is saved aggregately, which can learn to classify the difference of similar features of different objects. The similarity thresholds to each object can be learnt when new objects are learnt. (2) In object recognition process: In biological process, the associated recognition including familiarity discrimination and recollective matching. In our proposed model, firstly mimicking familiarity discrimination (\u2019knowing\u2019 though the episode), we compare the special patches of candidates with that of saved objects using above mentioned biologically inspired hierarchical model, where the candidates and saved objects have the same prominent semantic features. Then mimicking recollective matching, the comparison results of special patches are combined with semantic feature comparison.\nThe new model is also applied to object recognition processes. The primary experimental results show that our method is efficient with much less memory requirement.\nIndex Terms\u2014Memory, Association, object recognition, biologically inspired visual model.\nManuscript received July 3, 2013; revised. H. Qiao is with the Institute of Automation, Chinese Academy of Sciences, Beijing 100190, China (e-mail: hong.qiao@ia.ac.cn). Y.L. Li and T. Tang are with the Graduate School and the State Key Laboratory of Management and Control for Complex Systems, Institute of Automation, Chinese Academy of Sciences.\nI. INTRODUCTION\nMANY researchers have established a series of neuralcomputational models for vision processes based on the biological mechanism and showed that the models can be well applied to pattern recognition [1], [2], [3], [4]. More importantly, recently, biological research with information technology integration is an important trend of research in all over the world.\nIn particular, in 1999, Riesenhuber and Poggio proposed a famous neural computational model for vision process [2]. This model is a hierarchical feed-forward model of the ventral stream of primate visual cortex, which is briefly called as HMAX. The model is closely related to biological results. Each level in the model was designed according to data of anatomy and physiology experiments, which mimicked the architecture and response characteristics of the visual cortex.\nFurthermore, Giese and Poggio have extended the above model to biological motion recognition [5]. They established a hierarchical neural model with two parallel process streams, i.e. form pathway and motion pathway. A series of extended models have given very good performance in biological motion recognition in cluster [6] and are compared with psychophysics results [7]. The model was also extended to a computational model for general object recognition tasks [8], which can output a set of position and scale invariance features by alternating between a template matching and a maximum pooling operation corresponding to S1-C2 layers. Some other researchers introduced sparsification, feedback and lateral inhibition [9], [10]into HMAX. The series works have demonstrated very good performance in a range of recognition tasks which is competitive with the state of art approaches, such as face recognition [11], scene classification [12] and handwritten digit recognition [13].\nFrom another point of view, Itti established a visual attention model [3], [14], which is inspired by the behavioral and neural architecture of the early primate visual system. Itti and Poggio et al [15] merged the saliency-based attention model proposed in the previous work [3] to HMAX in order to modify the activity of the S2 layer. Here the S2 layer mimics the response characters of V4 in the primate visual cortex, which shows an attention modulation in electrophysiology and psychophysics experiments.\nSaliency based visual attention models are further compared with behavioral experiments [16] and showed that the models could account for a significant portion of human gaze behavior in a naturalistic, interactive setting. A series of visual attention\n2 models [17] have demonstrated successful applications in computer vision [18], mobile robotics [19], and cognitive systems [20].\nSome other work has tried to combine HMAX and Deep Belief Networks. The HMAX model could extract position and scale invariance features with a feed-forward hierarchical architecture, but the lack of feedback limits its performance in pure classification tasks. Deep Belief Networks (DBN) [21] has shown the state of the art performance in a range of recognition tasks [22], [23]. DBN uses generative learning algorithms, utilizes feedback at all levels and provides ability to reconstruct complete or sample sensory data, but DBN lacks the position and scale invariance in the HMAX. Therefore, combing DBN with the HMAX may be meaningful to extract more accurate features for pattern recognition.\nThe above models are all biologically inspired models and have been successfully applied in practical work. In this paper, based on other biological results, we try to introduce the Memory and Association into the HMAX. Our method can reduce memory requirement and achieve comparable accuracy to the state of art approaches.\nII. RELATED WORKS\nIn this paper, we propose a model based on HMAX and some basic facts about the memory and association mechanism established over the last decade by several physiological studies of cortex [24], [25], [26], [27]. The accumulated evidences points are summarized as follows.\n(1). The Memory About an Object Includes the Episodic and Semantic Memory Tulving et al. proposed that episodic memory and semantic memory are two subsystems of declarative memory [27]. Though the two systems share many features, semantic memory is considered as the basis of episodic memory which has additional capabilities that semantic memory does not have. In the memory encoding process, information is encoded into semantic memory first and can then be encoded into episodic memory through semantic memory, as shown in Fig. 1.\n(2). An Object Concept May be Represented by Discrete Cortical Regions Brain imaging studies show that object representation is related to different cortical regions, forming a distributed network that is parallel to the organization of sensory and motor systems [25]. For example, in the word generation experiments, ventral and lateral regions of the posterior temporal cortex have been found eliciting differentially with different types of information retrieved [28]. In other related behavioral experiments in which the subjects are required to name an action or a color, the specialization of different cortical regions has also been observed [28].\n(3). Neurons Responding to the Common Feature of Different Objects Aggregate Together Researchers believe that the brain tends to process common features from different objects in the same areas [25]. One supporting fact for the assertion is the existence of the cortical region responding to the shape attributes of different visual categories. In the related behavioral experiments, when the subject was required to perform same task with different object categories as stimuli, the ventral occipitotemporal cortex was consistently activated and encoded the object forms with distinct neural response patterns [25]. Another body of evidence comes from studies of cortical lesions [29], [30]. The damage to temporal lobes is found to be strongly associated with the impairment of abilities to recognize objects and retrieve information about object-specific characteristics [29], [30]. This implies that the temporal lobe is the region in which object-specific information from all categories is commonly stored. Functional column may provide the anatomical basis accounting for the above phenomena, and recent studies suggest that the functional column is a basic processing architecture spreading over visual neural systems [31], [32], [33]. On the surface of infratemporal cortex that activated by faces, neurons with common preference were found aggregating in patches specifying different stimuli [31]. Similar organization was also seen in the area of posterior TE that is responsive to simple two-dimensional shapes [32]. It is inferred that such a columnar organization would produce stimulus invariance [34] and also provides a visual alphabet from which numerous complex objects can be efficiently represented as a distributed code [33].\n(4). Recognition Memory Includes Familiarity and Recollection Components As a basic functional part of memory, recognition memory has its use in identifying and judging whether the presented object has ever been captured consciously [35], [26]. It is widely accepted that two components make up the recognition memory: One is the familiarity discrimination that determines \u2019knowing\u2019 though the episode in which the object has appeared may not be recalled, and the other is the recollective matching that means\n3 remembering both the presence of the object and the related episode. Different mechanisms have been proposed to explain the two recognition experiences. Some researchers argue that the only difference between familiarity discrimination and recollection matching is the trace strength, in term of which the former is weaker than the latter [36], [37], [38], while others regard the two processes as qualitatively different modes of recognition memory, which may be executed by hippocampus and perirhinal cortex, respectively [35], [26].\n(5). Familiarity Recognition is Rapid and Accurate and Only Needs a Small Number of Neurons From the evolutionary perspective, owning a simplified recognition system focusing on familiarity is likely to have advantage in speed of response to novelty by saving time of deep recalling. This hypothesis has been confirmed in some related experiments, in which subjects made familiarity decisions faster than recollect decisions [39], [40], [27]. The computational efficiency of a recognition system dedicated for familiarity discrimination has also been demonstrated by the simulated neural networks [41]. Compared with systems relying on associative learning, familiarity decision can be made accurate and faster by a specially designed network with smaller size of neuron population.\nAll of above works form the basis of our model which would be explained in Section III.\nIII. THE NEW MODEL-INTRODUCTION MEMORY AND ASSOCIATION INTO BIOLOGICALLY INSPIRED MODEL\nThe new model is presented in Fig. 2. This section includes 5 parts, which introduce the framework of our model and algorithms related to sub processes."}, {"heading": "A. The Framework of Our Model", "text": "A1 to Am represent various common semantic attributes of different objects. Sx is a library for special episodic patches of different objects. A common attribute of different objects is stored in the same regions, for example, a11 \u2212 a1n is the first feature of different objects (i = 1, . . . n) which are stored together, called as A1. A1 not only has clear biological area but also has learning ability. For example, the similarity sensitivity would be learnt when new objects are saved. This memory mechanism has clear biological evidences [34], [25] 3) Recognition of One Candidate (Block3) Tt represents a candidate. The semantic features a1t to amt and episodic patch feature sxt are extracted before recognition. 4) Familiarity Discrimination (Block4) Familiarity discrimination is achieved through the HMAX model. Both Sx and sxt are extracted in the C1 layer of HMAX model. The saved object can be ordered by comparing similarity between the candidate and the saved objects in the C2 layer of HMAX model. This process corresponds to the familiarity discrimination (\u2019knowing\u2019 through the episode) in biological recognition memory [35]. 5) Recollective matching (Block5) Recollective matching is achieved through integration of semantic feature and episode feature similarity analysis. We compare the semantic features of the candidate with those of the top saved objects according to familiarity discrimination. If the difference between the candidate and the closest object does not exceed the threshold which we have learnt during the memory process, we consider that the candidate \u2019is\u2019 the object. This procedure is illuminated by recollective matching in recognition memory [35]."}, {"heading": "B. Encoding Episodic and Semantic Features (Block 1)", "text": "As we know, memory is the process by which information is encoded, stored, and retrieved, and the memory to an object with conscious process is called declarative memory, which can be divided into semantic memory and episodic memory [24], [42]. Semantic memory refers to the memory which is learned by people, such as meanings, understandings, concept-based knowledge and work-related skills and facts [43]. Episodic memory refers to the memory which is explicitly located in the past involving the specific events and situations, such as times, places, associated emotions and other contextual knowledge [44], [45].\nIn this paper, the features of a saved object i include descriptive attributes a1i to ami and special patch sxi (Fig. 3), where descriptive attributes correspond to semantic features, and special patches correspond to episodic features.\n1) Semantic Features: In biological process, human would memorize an object using semantic features. In computational process, semantic features can reduce the memory size requirement. However, in order to get semantic features, a big dataset and learning ability are needed, which correspond to the prior knowledge.\n4\nA simplified algorithm is presented as follows. First, we need to extract patches gji with clear physical meaning (such as the images of eyes, months of one face) for each object i. Then, we can get an average view g\u0304j of each feature gji. At last, we compare gji and g\u0304j(j = 1, . . .m) to obtain the semantic attribute aji of a particular object. The detailed algorithm is given in Algorithm 1.\nTake face recognition as an example. In this paper, the active shape model (ASM) is used to extract typical points from faces. Avoiding to describe one part \u2019big\u2019 or \u2019small\u2019, which can be vague, in this paper, we compute effective geometric features of each part related declarative features of eyes, nose\nAlgorithm 1: Extracting semantic attributes. Input: objects oi, i = 1 . . . n\nfeatures gji, j = 1 . . .m 1: Extract geometric features (j = 1, . . .m) from object oi 2: Compute a common view for each feature\ng\u0304j = f(gj1, gj2, . . . gjn) 3: Compute semantic attributes aji = f(gji, g\u0304j)\nOutput: Semantic attributes aji.\nand mouth (Table I). We could establish an average value for each geometric feature. By comparing each individual with the average face, we can get the computational semantic attributes for each part.\nIn experiments, we would show that these geometric features have coincidence with general semantic meaning, such as \u2019the eyes are large\u2019 and so on.\nIt should be noted that representing the geometric features of\n5 a face component should consider the influences of expression, view direction, light and even subjective feeling of an observer. In order to get fair results, our current dataset is collected with frontal faces with less expression, and the geometric attributes are normalized as gji =\ngji\u2212uj \u03c3j\n, where uj is the average of the jth geometric feature and \u03c3j is the standard deviation of the jth geometric feature.\nFor one person, many other attributes, such as gender, race and age can be included in further research. Some events and their relationships can enrich the memory processes.\n2) Episodic Patches: In order to mimic episodic memory, we need to find out the dominant patches of an object through finding out the most prominent semantic features of the object I (Equation 3-2).\nTake face recognition as an example again. First, we need to find out the most prominent semantic feature for physical parts, for example, eyes, nose and mouth:\nJi = argmax j=1,2,...m (\u2016a1i\u2212a\u03042\u20162, \u2016a2i\u2212a\u03041\u20162, . . . \u2016ami\u2212a\u0304m\u20162) (1)\nwhere Ji is the dominant semantic feature of the ith object, aji is the jth semantic feature of the ith object, and a\u0304ji is the jth average semantic feature. Special episodic patches could be extracted, which corresponds to Ji of the object Oi and are put into HMAX model proposed by [2], which can extract a set of position and scale tolerant features.\nDifferent from the original HMAX model, only episodic patches corresponding to the prominent part of a candidate are put into the model, and only those of the \u2019known\u2019 objects are stored in a library."}, {"heading": "C. Distributed Memory Structures (Block 2)", "text": "How to remember and organize different features is a key problem in the memory process. It would also influence the retrieval and association processes. This is also an important part of our framework.\nThe studies of cognitive sciences have indicated that the extraction, storage and retrieval of different features are realized by the distributed cortical areas. As we have listed in section II, many data and evidence proved that an object concept may be represented by the discrete cortical regions [28] and neurons responding to the common feature of different objects aggregate together [34].\nIn this paper, we mimic this distributed structure to memorize and retrieve features. Suppose there are m visual cortical regions A1 to Am(Fig. 4), which are sensitive to different kinds of features a1,t to am,t. Thus candidate which have feature ai,t will active a distinctive response in region Ai.\nThis kind of distributed structures has great advantages. The visual cortical region Ai(i = 1, . . . ,m) can be more and more sensitive and effective through comparing different ai,t. Two similarity thresholds for semantic attributes and episodic patches which would decide if a candidate is a \u2019known\u2019 object are learned when a new object is memorized. In the further work, the attributes of one object would also be connected and influence each other.\nFig. 4: Distributed memory structure."}, {"heading": "D. Recognition based on Familiarity Discrimination and Recollective Matching (Block 3)", "text": "As shown in Section II, there are two processes in the recognition memory: familiarity discrimination and recollective matching [35], and their combination is useful for a fast and accurate human recognition task. In the proposed framework, we also have two processes, corresponding to familiarity discrimination and recollective matching.\n1) Familiarity Discrimination: In block 1, we established a library of episodic patches {Sx} of different \u2019known\u2019 objects in the memory process. In the familiarity discrimination of the association process, a special episodic patch sxt of the candidate Tt is extracted and put into the C1 layer of the HMAX model. Then we compute the S2 and C2 level features of the candidate and the \u2019known\u2019 objects which have the same prominent semantic attribute. Finally, we sort the \u2019known\u2019 objects through their C2 feature similarity compared with the candidate.\nThis process corresponds to the familiarity discrimination in recognition memory [35].\n2) Recollective Matching: We compare the semantic features ai,t(i = 1, . . . ,m) of the candidate with those of the top \u2019known\u2019 objects obtained from familiarity discrimination. If the smallest dissimilarity does not exceed the thresholds which we have learnt during memory process, the candidate is \u2019recognized\u2019 as the closest \u2019known\u2019 object. Otherwise, we regard the candidate as a new one. This procedure is illuminated by re-collective matching in recognition memory [35].\nThe whole algorithm is given as algorithm 2:\nIV. EXPERIMENT\nIn this section, we conduct experiments to demonstrate the effectiveness of our model through introducing biologically inspired memory and association mechanism into HMAX. We first establish a dataset which consists of front faces of 7 persons (Fig. 5). The first 5 persons\u2019 face images are used in both the memory and association phases and other 2 persons\u2019 face images are only used in the recognition phase. Some of the samples in the dataset are shown in Fig. 6:\nThe experimental details are given as follows."}, {"heading": "A. Special Patches Evaluation", "text": "The first person\u2019s 8 candidate images are presented in Fig. 7. Responses of the C2 units in HMAX model are used for\n6 Algorithm 2: Memory and retrieval process memory process : semantic attributes, episodic patch\nfeatures, dominant attributes, and similarity thresholds of the training objects\nRetrieval Process: A candidate 1: Extracting semantic attributes, dominant attributes and\nthe episodic patch 2: Familiarity Discrimination: finding the training objects\nwhich have the same prominent attribute j, and using their stored patches library Sj to get the C2 layer features for both fC2test and f C2 i , and sort the candidates by \u2016fC2test \u2212 f C2 i \u20162\n3: Recollective Matching: comparing the detailed semantic features of the test object with those of the top candidate training objects\nsimilarityi = argmin i\u2208top3\nm\u2211\nj=1\n(\u2016ajtest \u2212 aji\u20162)\n4: Zero-shooting object memorizing: Store feature set of the test object\nthe dissimilarity analysis of special patches. Although light, expression, scales and other factors would influence the similarity analysis, the experimental results show that the similarity of the special patches through HAMX primarily matches the semantic description. For example, one candidate\u2019s special patch is more similar to that with the same semantic description, that is, the big eyes have high similarity with big eyes and low similarity with small eyes.\nIn the memory process, the special patches of the first 3 persons\u2019 images are all eyes. The eyes images are scaled with 4 and 6, and the first 2 with \u2019big\u2019 eyes and the third one with \u2019small\u2019 eyes (Fig. 8).\nIn recognition process, three other pictures of the first 3 persons are used(see Fig. 9).\nThe similarity analysis and rank are presented in Table II. Where, Patchij represents an eye patch with scale j \u00d7 j of the ith person. The patches are ranked according to their average values from the C2 layer.\nIt is not surprising that the eye patches of the first two persons generate higher values with portraits having bigger eyes, while the patches of the third person prefer the smaller ones. This rule always holds even in some cases that the eyes of the first two identities are confused.\nThe results above demonstrate that the low-level features used in the model are reliable indicators of visual properties.\nFig. 6: The first person\u2019s 8 pictures used in the memory process.\nFig. 7: The first person\u2019s 8 candidate images.\nBy combining a sufficient number of such features, visual objects can be efficiently represented by the response patterns, just like the neural activities in certain cortical regions by which they are encoded."}, {"heading": "B. Familiarity Discrimination", "text": "The purpose of familiarity discrimination is to \u2019feel\u2019 if \u2019knowing\u2019 the subject. After a special patch similarity analysis, it is necessary to decide if the subject is \u2019known\u2019 rapidly. Then the problem is how to design the threshold of each saved subject which can be used to decide if the candidate is the saved subject.\nIn this paper, the threshold for a \u2019known\u2019 face image i is given as follows,\nthres1i = argmax i\n(\u2016f qi \u2212 f\u0304i\u20162)\nthres2i = argmax j,j 6=i\n(\u2016f qi \u2212 f\u0304j\u20162)\nthres = thres1i + \u2016thres2i \u2212 thres1i\u2016/\u03bb\n(2)\nwhere f represents the semantic features or C2 features of special patches, f qi is the qth image feature of the ith object (ith object has q images), f\u0304i is the average features of q images belonging to ith object, thres1i is the intra-class maximum difference, thres2i is the inter-class minimum difference, \u03bb is the ratio of thres1i and thres2i and thres is the final similarity threshold.\nClearly, the larger the threshold is, the more insensitive the image is. \u2016thres2i\u2212 thres1i\u2016/\u03bb is used to adjust the thres1i to make it more flexible.\nThe thresholds for 5 persons\u2019 images are shown in following Table III:\nThe dissimilarities between 3 other persons\u2019 images and 5 \u2019known\u2019 persons\u2019 images are given in Table IV.\nIt can be seen that the dissimilarities between three other persons\u2019 images and five \u2019known\u2019 persons\u2019 images are all larger than the threshold. Therefore the three other persons\u2019 can be recognized as \u2019unknown\u2019 rapidly.\nHowever, instead of presenting the result of the familiarity process by \u2019yes\u2019 (the dissimilarity value is smaller than thres ) and \u2019no\u2019 (the dissimilarity value is larger than thres), in this paper, the process result is presented by the probability of one candidate being a \u2019known\u2019 subject that computed by (3)\n7\np(ci|x) = p(x|ci)p(ci)\u2211n i=1 p(x|ci)p(ci)\n(3)\nAs we assume all p(ci) are the same, the identities are actually sorted by p(x|ci) = exp(\u2212d), where d is the Euclidean distance between features of the learned face and the incoming face.\nBased on (3), the first five persons\u2019 images used for recognition are compared with their images used for memory. The probability and the corresponding ranks are given in Table V(only the results of 4 persons\u2019 3 images are listed here).\nIt can be seen that each person\u2019s other images are close to themselves through familiarity matching. Three \u2019known\u2019 objects among top three matching probability are reserved for further recognition."}, {"heading": "C. Recognition by recollection matching", "text": "In this process, the similarity in semantic meaning is compared.\nIn this paper, the controlled points of faces are obtained by the Active Shape Model (ASM) or manually. One sample (68 control points can be obtained from 1632*1632 image) is given in Fig. 10.\nThe main parts of a face include eyes, nose and mouths. The semantic presentation has 15 attributes as shown in Section\nIII-B1. Therefore, one \u2019known\u2019 face is saved by 15 semantic attributes, 1 prominent attribute which determines the part of special patch, 1 special patch and thresholds (See Table VI).\nThe attribute thresholds computed by function 4-1 for 5 persons are shown in following Table VII:\nBy computing the difference between the test image and the three candidate persons\u2019 attributes in turn, and compared with the attributes thresholds. We could give the final label for each test image.\nThe recognition results are listed in Table VIII.\nV. CONCLUSION\nIn this paper, the biologically inspired memory and association model has been proposed. The typical features of the model based on biological work include:\n(a) in both the memory and recognition processes, the objects have semantic and episodic features and episodic patch is extracted according to semantic feature. (b) The sensitivities to the semantic and episodic features are learnt during the process. (c) In association process, the semantic and episodic features are separately compared and the results are integrated, which correspond to familiarity and recognitive matching.\nThrough six blocks, the above model is introduced to the HMAX and the corresponding algorithms are given. The memory and association mechanism provides \u2019top-down\u2019 control function in the process, which can active select the important features in memory and association and influence the recognition process.\nThe experimental results show that with the new method, the required memory is very small and recognition performance is very good.\nIn the future work, the combined model would be further improved with more learning ability.\nACKNOWLEDGMENT\nThe authors would gratefully thank Dr. Wei Wu and Dr. Tianshi Chen for their kindly help to improve this paper.\nMouth Eyes 1 2 4 3 5\nPatch thres 0.5406 0.5203 1.5492 0.4174 0.4861 6 1 0.596875 0.923608 1.771417 0.869486 0.75737 6 2 0.709693 0.870208 1.681255 1.155204 1.031485 6 3 1.101026 1.380079 2.12309 0.654594 0.655111 7 1 0.821075 0.94641 1.785884 0.922266 0.917094 7 2 0.760753 0.780838 1.828294 0.701748 0.822338 7 3 0.589346 0.888509 2.171345 0.44176 0.785486\n[5] M. A. Giese and T. Poggio, \u201cNeural mechanisms for the recognition of biological movements,\u201d Nature Reviews Neuroscience, vol. 4, no. 3, pp. 179\u2013192, 2003. [6] R. Sigala, T. Serre, T. Poggio, and M. Giese, \u201cLearning features of intermediate complexity for the recognition of biological motion,\u201d in Artificial Neural Networks: Biological Inspirations\u2013ICANN 2005. Springer, 2005, pp. 241\u2013246. [7] A. Casile and M. A. Giese, \u201cCritical features for the recognition of biological motion,\u201d Journal of Vision, vol. 5, no. 4, pp. 348\u2013360, 2005. [8] T. Serre, L. Wolf, S. Bileschi, M. Riesenhuber, and T. Poggio, \u201cRobust object recognition with cortex-like mechanisms,\u201d Ieee Transactions on Pattern Analysis and Machine Intelligence, vol. 29, no. 3, pp. 411\u2013426, 2007. [9] Y. Huang, K. Huang, D. Tao, T. Tan, and X. Li, \u201cEnhanced biologically inspired model for object recognition,\u201d Ieee Transactions on Systems Man and Cybernetics Part B-Cybernetics, vol. 41, no. 6, pp. 1668\u20131680, 2011. [10] J. Mutch and D. G. Lowe, \u201cMulticlass object recognition with sparse, localized features,\u201d in Computer Vision and Pattern Recognition, 2006 IEEE Computer Society Conference on, vol. 1. IEEE, 2006, pp. 11\u201318. [11] E. Meyers and L. Wolf, \u201cUsing biologically inspired features for face processing,\u201d International Journal of Computer Vision, vol. 76, no. 1, pp. 93\u2013104, 2008. [12] K. Huang, D. Tao, Y. Yuan, X. Li, and T. Tan, \u201cBiologically inspired features for scene classification in video surveillance,\u201d Ieee Transactions on Systems Man and Cybernetics Part B-Cybernetics, vol. 41, no. 1, pp. 307\u2013313, 2011. [13] M. Hamidi and A. Borji, \u201cInvariance analysis of modified c2 features: case study-handwritten digit recognition,\u201d Machine Vision and Applications, vol. 21, no. 6, pp. 969\u2013979, 2010. [14] L. Itti and C. Koch, \u201cComputational modelling of visual attention,\u201d Nature Reviews Neuroscience, vol. 2, no. 3, pp. 194\u2013203, 2001. [15] D. Walther, L. Itti, M. Riesenhuber, T. Poggio, and C. Koch, \u201cAttentional selection for object recognitiona gentle way,\u201d in Biologically Motivated Computer Vision. Springer, 2002, pp. 472\u2013479. [16] R. J. Peters and L. Itti, \u201cApplying computational tools to predict gaze direction in interactive visual environments,\u201d Acm Transactions on Applied Perception, vol. 5, no. 2, 2008. [17] A. Borji and L. Itti, \u201cState-of-the-art in visual attention modeling,\u201d Ieee Transactions on Pattern Analysis and Machine Intelligence, vol. 35, no. 1, pp. 185\u2013207, 2013. [18] Y. F. Ma, X. S. Hua, L. Lu, and H. J. Zhang, \u201cA generic framework of\n9 user attention model and its application in video summarization,\u201d Ieee Transactions on Multimedia, vol. 7, no. 5, pp. 907\u2013919, 2005.\n[19] S. Lang, M. Kleinehagenbrock, S. Hohenner, J. Fritsch, G. A. Fink, and G. Sagerer, \u201cProviding the basis for human-robot-interaction: A multimodal attention system for a mobile robot,\u201d in Proceedings of the 5th international conference on Multimodal interfaces. ACM, 2003, pp. 28\u201335. [20] S. Frintrop, E. Rome, and H. I. Christensen, \u201cComputational visual attention systems and their cognitive foundations: A survey,\u201d Acm Transactions on Applied Perception, vol. 7, no. 1, 2010. [21] G. E. Hinton, S. Osindero, and Y.-W. Teh, \u201cA fast learning algorithm for deep belief nets,\u201d Neural Computation, vol. 18, no. 7, pp. 1527\u20131554, 2006. [22] H. Lee, R. Grosse, R. Ranganath, and A. Y. Ng, \u201cConvolutional deep belief networks for scalable unsupervised learning of hierarchical representations,\u201d in Proceedings of the 26th Annual International Conference on Machine Learning. ACM, 2009, pp. 609\u2013616. [23] A.-r. Mohamed, G. E. Dahl, and G. Hinton, \u201cAcoustic modeling using deep belief networks,\u201d Ieee Transactions on Audio Speech and Language Processing, vol. 20, no. 1, pp. 14\u201322, 2012. [24] E. Tulving and H. J. Markowitsch, \u201cEpisodic and declarative memory: Role of the hippocampus,\u201d Hippocampus, vol. 8, no. 3, pp. 198\u2013204, 1998. [25] A. Martin and L. L. Chao, \u201cSemantic memory and the brain: structure and processes,\u201d Current Opinion in Neurobiology, vol. 11, no. 2, pp. 194\u2013201, 2001. [26] L. R. Squire, J. T. Wixted, and R. E. Clark, \u201cRecognition memory and the medial temporal lobe: A new perspective,\u201d Nature Reviews Neuroscience, vol. 8, no. 11, pp. 872\u2013883, 2007. [27] B. McElree, P. O. Dolan, and L. L. Jacoby, \u201cIsolating the contributions of familiarity and source information to item recognition: A time course analysis,\u201d Journal of Experimental Psychology-Learning Memory and Cognition, vol. 25, no. 3, pp. 563\u2013582, 1999. [28] A. Martin, J. V. Haxby, F. M. Lalonde, C. L. Wiggs, and L. G. Ungerleider, \u201cDiscrete cortical regions associated with knowledge of color and knowledge of action,\u201d Science, vol. 270, no. 5233, pp. 102\u2013 105, 1995. [29] J. Hart and B. Gordon, \u201cDelineation of single-word semantic comprehension deficits in aphasia, with anatomical correlation,\u201d Annals of Neurology, vol. 27, no. 3, pp. 226\u2013231, 1990. [30] J. R. Hodges, K. Patterson, S. Oxbury, and E. Funnell, \u201cSemantic dementia - progressive fluent aphasia with temporal-lobe atrophy,\u201d Brain, vol. 115, pp. 1783\u20131806, 1992, 6. [31] G. Wang, K. Tanaka, and M. Tanifuji, \u201cOptical imaging of functional organization in the monkey inferotemporal cortex,\u201d Science, vol. 272, no. 5268, pp. 1665\u20131668, 1996. [32] I. Fujita, K. Tanaka, M. Ito, and K. Cheng, \u201cColumns for visual features of objects in monkey inferotemporal cortex,\u201d Nature, vol. 360, no. 6402, pp. 343\u2013346, 1992. [33] M. P. Stryker, \u201cNeurobiology - elements of visual-perception,\u201d Nature, vol. 360, no. 6402, pp. 301\u2013302, 1992. [34] M. J. Tovee, \u201cIs face processing special?\u201d Neuron, vol. 21, no. 6, pp. 1239\u20131242, 1998. [35] M. W. Brown and J. P. Aggleton, \u201cRecognition memory: What are the roles of the perirhinal cortex and hippocampus?\u201d Nature Reviews Neuroscience, vol. 2, no. 1, pp. 51\u201361, 2001. [36] F. Haist, A. P. Shimamura, and L. R. Squire, \u201cOn the relationship between recall and recognition memory,\u201d Journal of experimental psychology. Learning, memory, and cognition, vol. 18, no. 4, pp. 691\u2013702, 1992. [37] E. Hirshman and S. Master, \u201cModeling the conscious correlates of recognition memory: Reflections on the remember-know paradigm,\u201d Memory and Cognition, vol. 25, no. 3, pp. 345\u2013351, 1997. [38] W. Donaldson, \u201cThe role of decision processes in remembering and knowing,\u201d Memory and Cognition, vol. 24, no. 4, pp. 523\u2013533, 1996. [39] M. Seeck, C. M. Michel, N. Mainwaring, R. Cosgrove, H. Blume, J. Ives, T. Landis, and D. L. Schomer, \u201cEvidence for rapid face recognition from human scalp and intracranial electrodes,\u201d Neuroreport, vol. 8, no. 12, pp. 2749\u20132754, 1997. [40] D. L. Hintzman, D. A. Caulton, and D. J. Levitin, \u201cRetrieval dynamics in recognition and list discrimination: Further evidence of separate processes of familiarity and recall,\u201d Memory and Cognition, vol. 26, no. 3, pp. 449\u2013462, 1998. [41] R. Bogacz, M. W. Brown, and C. Giraud Carrier, \u201cHigh capacity neural networks for familiarity discrimination,\u201d in Artificial Neural Networks, 1999. ICANN 99. Ninth International Conference on, vol. 2. IET, 1999, pp. 773\u2013778.\n[42] L. R. Squire and S. M. Zola, \u201cEpisodic memory, semantic memory, and amnesia,\u201d Hippocampus, vol. 8, no. 3, pp. 205\u2013211, 1998. [43] D. Saumier and H. Chertkow, \u201cSemantic memory,\u201d Current neurology and neuroscience reports, vol. 2, no. 6, pp. 516\u201322, 2002. [44] H. Eichenbaum, \u201cA cortical-hippocampal system for declarative memory,\u201d Nature Reviews Neuroscience, vol. 1, no. 1, pp. 41\u201350, 2000. [45] M. A. Conway, \u201cEpisodic memories,\u201d Neuropsychologia, vol. 47, no. 11, pp. 2305\u20132313, 2009."}], "references": [{"title": "Receptive fields, binocular interaction and functional architecture in cats visual cortex", "author": ["D.H. Hubel", "T.N. Wiesel"], "venue": "Journal of Physiology London, vol. 160, no. 1, p. 106, 1962.", "citeRegEx": "1", "shortCiteRegEx": null, "year": 1962}, {"title": "Hierarchical models of object recognition in cortex", "author": ["M. Riesenhuber", "T. Poggio"], "venue": "Nature Neuroscience, vol. 2, no. 11, pp. 1019\u20131025, 1999.", "citeRegEx": "2", "shortCiteRegEx": null, "year": 1999}, {"title": "A model of saliency-based visual attention for rapid scene analysis", "author": ["L. Itti", "C. Koch", "E. Niebur"], "venue": "Ieee Transactions on Pattern Analysis and Machine Intelligence, vol. 20, no. 11, pp. 1254\u20131259, 1998.", "citeRegEx": "3", "shortCiteRegEx": null, "year": 1998}, {"title": "How mt cells analyze the motion of visual patterns", "author": ["N.C. Rust", "V. Mante", "E.P. Simoncelli", "J.A. Movshon"], "venue": "Nature Neuroscience, vol. 9, no. 11, pp. 1421\u20131431, 2006.  Features Dimensions Geometric attributes 15 Prominent attributes  1 Special patch  scale [4, 6, 8, 10]\u00d7 8 Attributes similarity threshold 1 C2 similarity threshold  1 TABLE VI: Attributes for one \u2019known\u2019 face. identity 1  2  4  3  5 attri thres 4.5946 4.1696 4.0039 4.4526 3.5100 TABLE VII: The thresholds for attributes", "citeRegEx": "4", "shortCiteRegEx": null, "year": 2006}, {"title": "Neural mechanisms for the recognition of biological movements", "author": ["M.A. Giese", "T. Poggio"], "venue": "Nature Reviews Neuroscience, vol. 4, no. 3, pp. 179\u2013192, 2003.", "citeRegEx": "5", "shortCiteRegEx": null, "year": 2003}, {"title": "Learning features of intermediate complexity for the recognition of biological motion", "author": ["R. Sigala", "T. Serre", "T. Poggio", "M. Giese"], "venue": "Artificial Neural Networks: Biological Inspirations\u2013ICANN 2005. Springer, 2005, pp. 241\u2013246.", "citeRegEx": "6", "shortCiteRegEx": null, "year": 2005}, {"title": "Critical features for the recognition of biological motion", "author": ["A. Casile", "M.A. Giese"], "venue": "Journal of Vision, vol. 5, no. 4, pp. 348\u2013360, 2005.", "citeRegEx": "7", "shortCiteRegEx": null, "year": 2005}, {"title": "Robust object recognition with cortex-like mechanisms", "author": ["T. Serre", "L. Wolf", "S. Bileschi", "M. Riesenhuber", "T. Poggio"], "venue": "Ieee Transactions on Pattern Analysis and Machine Intelligence, vol. 29, no. 3, pp. 411\u2013426, 2007.", "citeRegEx": "8", "shortCiteRegEx": null, "year": 2007}, {"title": "Enhanced biologically inspired model for object recognition", "author": ["Y. Huang", "K. Huang", "D. Tao", "T. Tan", "X. Li"], "venue": "Ieee Transactions on Systems Man and Cybernetics Part B-Cybernetics, vol. 41, no. 6, pp. 1668\u20131680, 2011.", "citeRegEx": "9", "shortCiteRegEx": null, "year": 2011}, {"title": "Multiclass object recognition with sparse, localized features", "author": ["J. Mutch", "D.G. Lowe"], "venue": "Computer Vision and Pattern Recognition, 2006 IEEE Computer Society Conference on, vol. 1. IEEE, 2006, pp. 11\u201318.", "citeRegEx": "10", "shortCiteRegEx": null, "year": 2006}, {"title": "Using biologically inspired features for face processing", "author": ["E. Meyers", "L. Wolf"], "venue": "International Journal of Computer Vision, vol. 76, no. 1, pp. 93\u2013104, 2008.", "citeRegEx": "11", "shortCiteRegEx": null, "year": 2008}, {"title": "Biologically inspired features for scene classification in video surveillance", "author": ["K. Huang", "D. Tao", "Y. Yuan", "X. Li", "T. Tan"], "venue": "Ieee Transactions on Systems Man and Cybernetics Part B-Cybernetics, vol. 41, no. 1, pp. 307\u2013313, 2011.", "citeRegEx": "12", "shortCiteRegEx": null, "year": 2011}, {"title": "Invariance analysis of modified c2 features: case study-handwritten digit recognition", "author": ["M. Hamidi", "A. Borji"], "venue": "Machine Vision and Applications, vol. 21, no. 6, pp. 969\u2013979, 2010.", "citeRegEx": "13", "shortCiteRegEx": null, "year": 2010}, {"title": "Computational modelling of visual attention", "author": ["L. Itti", "C. Koch"], "venue": "Nature Reviews Neuroscience, vol. 2, no. 3, pp. 194\u2013203, 2001.", "citeRegEx": "14", "shortCiteRegEx": null, "year": 2001}, {"title": "Attentional selection for object recognitiona gentle way", "author": ["D. Walther", "L. Itti", "M. Riesenhuber", "T. Poggio", "C. Koch"], "venue": "Biologically Motivated Computer Vision. Springer, 2002, pp. 472\u2013479.", "citeRegEx": "15", "shortCiteRegEx": null, "year": 2002}, {"title": "Applying computational tools to predict gaze direction in interactive visual environments", "author": ["R.J. Peters", "L. Itti"], "venue": "Acm Transactions on Applied Perception, vol. 5, no. 2, 2008.", "citeRegEx": "16", "shortCiteRegEx": null, "year": 2008}, {"title": "State-of-the-art in visual attention modeling", "author": ["A. Borji", "L. Itti"], "venue": "Ieee Transactions on Pattern Analysis and Machine Intelligence, vol. 35, no. 1, pp. 185\u2013207, 2013.", "citeRegEx": "17", "shortCiteRegEx": null, "year": 2013}, {"title": "A generic framework of  9 user attention model and its application in video summarization", "author": ["Y.F. Ma", "X.S. Hua", "L. Lu", "H.J. Zhang"], "venue": "Ieee Transactions on Multimedia, vol. 7, no. 5, pp. 907\u2013919, 2005.", "citeRegEx": "18", "shortCiteRegEx": null, "year": 2005}, {"title": "Providing the basis for human-robot-interaction: A multimodal attention system for a mobile robot", "author": ["S. Lang", "M. Kleinehagenbrock", "S. Hohenner", "J. Fritsch", "G.A. Fink", "G. Sagerer"], "venue": "Proceedings of the 5th international conference on Multimodal interfaces. ACM, 2003, pp. 28\u201335.", "citeRegEx": "19", "shortCiteRegEx": null, "year": 2003}, {"title": "Computational visual attention systems and their cognitive foundations: A survey", "author": ["S. Frintrop", "E. Rome", "H.I. Christensen"], "venue": "Acm Transactions on Applied Perception, vol. 7, no. 1, 2010.", "citeRegEx": "20", "shortCiteRegEx": null, "year": 2010}, {"title": "A fast learning algorithm for deep belief nets", "author": ["G.E. Hinton", "S. Osindero", "Y.-W. Teh"], "venue": "Neural Computation, vol. 18, no. 7, pp. 1527\u20131554, 2006.", "citeRegEx": "21", "shortCiteRegEx": null, "year": 2006}, {"title": "Convolutional deep belief networks for scalable unsupervised learning of hierarchical representations", "author": ["H. Lee", "R. Grosse", "R. Ranganath", "A.Y. Ng"], "venue": "Proceedings of the 26th Annual International Conference on Machine Learning. ACM, 2009, pp. 609\u2013616.", "citeRegEx": "22", "shortCiteRegEx": null, "year": 2009}, {"title": "Acoustic modeling using deep belief networks", "author": ["A.-r. Mohamed", "G.E. Dahl", "G. Hinton"], "venue": "Ieee Transactions on Audio Speech and Language Processing, vol. 20, no. 1, pp. 14\u201322, 2012.", "citeRegEx": "23", "shortCiteRegEx": null, "year": 2012}, {"title": "Episodic and declarative memory: Role of the hippocampus", "author": ["E. Tulving", "H.J. Markowitsch"], "venue": "Hippocampus, vol. 8, no. 3, pp. 198\u2013204, 1998.", "citeRegEx": "24", "shortCiteRegEx": null, "year": 1998}, {"title": "Semantic memory and the brain: structure and processes", "author": ["A. Martin", "L.L. Chao"], "venue": "Current Opinion in Neurobiology, vol. 11, no. 2, pp. 194\u2013201, 2001.", "citeRegEx": "25", "shortCiteRegEx": null, "year": 2001}, {"title": "Recognition memory and the medial temporal lobe: A new perspective", "author": ["L.R. Squire", "J.T. Wixted", "R.E. Clark"], "venue": "Nature Reviews Neuroscience, vol. 8, no. 11, pp. 872\u2013883, 2007.", "citeRegEx": "26", "shortCiteRegEx": null, "year": 2007}, {"title": "Isolating the contributions of familiarity and source information to item recognition: A time course analysis", "author": ["B. McElree", "P.O. Dolan", "L.L. Jacoby"], "venue": "Journal of Experimental Psychology-Learning Memory and Cognition, vol. 25, no. 3, pp. 563\u2013582, 1999.", "citeRegEx": "27", "shortCiteRegEx": null, "year": 1999}, {"title": "Discrete cortical regions associated with knowledge of color and knowledge of action", "author": ["A. Martin", "J.V. Haxby", "F.M. Lalonde", "C.L. Wiggs", "L.G. Ungerleider"], "venue": "Science, vol. 270, no. 5233, pp. 102\u2013 105, 1995.", "citeRegEx": "28", "shortCiteRegEx": null, "year": 1995}, {"title": "Delineation of single-word semantic comprehension deficits in aphasia, with anatomical correlation", "author": ["J. Hart", "B. Gordon"], "venue": "Annals of Neurology, vol. 27, no. 3, pp. 226\u2013231, 1990.", "citeRegEx": "29", "shortCiteRegEx": null, "year": 1990}, {"title": "Semantic dementia - progressive fluent aphasia with temporal-lobe atrophy", "author": ["J.R. Hodges", "K. Patterson", "S. Oxbury", "E. Funnell"], "venue": "Brain, vol. 115, pp. 1783\u20131806, 1992, 6.", "citeRegEx": "30", "shortCiteRegEx": null, "year": 1806}, {"title": "Optical imaging of functional organization in the monkey inferotemporal cortex", "author": ["G. Wang", "K. Tanaka", "M. Tanifuji"], "venue": "Science, vol. 272, no. 5268, pp. 1665\u20131668, 1996.", "citeRegEx": "31", "shortCiteRegEx": null, "year": 1996}, {"title": "Columns for visual features of objects in monkey inferotemporal cortex", "author": ["I. Fujita", "K. Tanaka", "M. Ito", "K. Cheng"], "venue": "Nature, vol. 360, no. 6402, pp. 343\u2013346, 1992.", "citeRegEx": "32", "shortCiteRegEx": null, "year": 1992}, {"title": "Neurobiology - elements of visual-perception", "author": ["M.P. Stryker"], "venue": "Nature, vol. 360, no. 6402, pp. 301\u2013302, 1992.", "citeRegEx": "33", "shortCiteRegEx": null, "year": 1992}, {"title": "Tovee, \u201cIs face processing special?", "author": ["J. M"], "venue": "Neuron, vol. 21,", "citeRegEx": "34", "shortCiteRegEx": "34", "year": 1998}, {"title": "Recognition memory: What are the roles of the perirhinal cortex and hippocampus?", "author": ["M.W. Brown", "J.P. Aggleton"], "venue": "Nature Reviews Neuroscience,", "citeRegEx": "35", "shortCiteRegEx": "35", "year": 2001}, {"title": "On the relationship between recall and recognition memory", "author": ["F. Haist", "A.P. Shimamura", "L.R. Squire"], "venue": "Journal of experimental psychology. Learning, memory, and cognition, vol. 18, no. 4, pp. 691\u2013702, 1992.", "citeRegEx": "36", "shortCiteRegEx": null, "year": 1992}, {"title": "Modeling the conscious correlates of recognition memory: Reflections on the remember-know paradigm", "author": ["E. Hirshman", "S. Master"], "venue": "Memory and Cognition, vol. 25, no. 3, pp. 345\u2013351, 1997.", "citeRegEx": "37", "shortCiteRegEx": null, "year": 1997}, {"title": "The role of decision processes in remembering and knowing", "author": ["W. Donaldson"], "venue": "Memory and Cognition, vol. 24, no. 4, pp. 523\u2013533, 1996.", "citeRegEx": "38", "shortCiteRegEx": null, "year": 1996}, {"title": "Evidence for rapid face recognition from human scalp and intracranial electrodes", "author": ["M. Seeck", "C.M. Michel", "N. Mainwaring", "R. Cosgrove", "H. Blume", "J. Ives", "T. Landis", "D.L. Schomer"], "venue": "Neuroreport, vol. 8, no. 12, pp. 2749\u20132754, 1997.", "citeRegEx": "39", "shortCiteRegEx": null, "year": 1997}, {"title": "Retrieval dynamics in recognition and list discrimination: Further evidence of separate processes of familiarity and recall", "author": ["D.L. Hintzman", "D.A. Caulton", "D.J. Levitin"], "venue": "Memory and Cognition, vol. 26, no. 3, pp. 449\u2013462, 1998.", "citeRegEx": "40", "shortCiteRegEx": null, "year": 1998}, {"title": "High capacity neural networks for familiarity discrimination", "author": ["R. Bogacz", "M.W. Brown", "C. Giraud Carrier"], "venue": "Artificial Neural Networks, 1999. ICANN 99. Ninth International Conference on, vol. 2. IET, 1999, pp. 773\u2013778.", "citeRegEx": "41", "shortCiteRegEx": null, "year": 1999}, {"title": "Episodic memory, semantic memory, and amnesia", "author": ["L.R. Squire", "S.M. Zola"], "venue": "Hippocampus, vol. 8, no. 3, pp. 205\u2013211, 1998.", "citeRegEx": "42", "shortCiteRegEx": null, "year": 1998}, {"title": "Semantic memory", "author": ["D. Saumier", "H. Chertkow"], "venue": "Current neurology and neuroscience reports, vol. 2, no. 6, pp. 516\u201322, 2002.", "citeRegEx": "43", "shortCiteRegEx": null, "year": 2002}, {"title": "A cortical-hippocampal system for declarative memory", "author": ["H. Eichenbaum"], "venue": "Nature Reviews Neuroscience, vol. 1, no. 1, pp. 41\u201350, 2000.", "citeRegEx": "44", "shortCiteRegEx": null, "year": 2000}, {"title": "Episodic memories", "author": ["M.A. Conway"], "venue": "Neuropsychologia, vol. 47, no. 11, pp. 2305\u20132313, 2009.", "citeRegEx": "45", "shortCiteRegEx": null, "year": 2009}], "referenceMentions": [{"referenceID": 0, "context": "MANY researchers have established a series of neural computational models for vision processes based on the biological mechanism and showed that the models can be well applied to pattern recognition [1], [2], [3], [4].", "startOffset": 199, "endOffset": 202}, {"referenceID": 1, "context": "MANY researchers have established a series of neural computational models for vision processes based on the biological mechanism and showed that the models can be well applied to pattern recognition [1], [2], [3], [4].", "startOffset": 204, "endOffset": 207}, {"referenceID": 2, "context": "MANY researchers have established a series of neural computational models for vision processes based on the biological mechanism and showed that the models can be well applied to pattern recognition [1], [2], [3], [4].", "startOffset": 209, "endOffset": 212}, {"referenceID": 3, "context": "MANY researchers have established a series of neural computational models for vision processes based on the biological mechanism and showed that the models can be well applied to pattern recognition [1], [2], [3], [4].", "startOffset": 214, "endOffset": 217}, {"referenceID": 1, "context": "In particular, in 1999, Riesenhuber and Poggio proposed a famous neural computational model for vision process [2].", "startOffset": 111, "endOffset": 114}, {"referenceID": 4, "context": "Furthermore, Giese and Poggio have extended the above model to biological motion recognition [5].", "startOffset": 93, "endOffset": 96}, {"referenceID": 5, "context": "A series of extended models have given very good performance in biological motion recognition in cluster [6] and are compared with psychophysics results [7].", "startOffset": 105, "endOffset": 108}, {"referenceID": 6, "context": "A series of extended models have given very good performance in biological motion recognition in cluster [6] and are compared with psychophysics results [7].", "startOffset": 153, "endOffset": 156}, {"referenceID": 7, "context": "The model was also extended to a computational model for general object recognition tasks [8], which can output a set of position and scale invariance features by alternating between a template matching and a maximum pooling operation corresponding to S1-C2 layers.", "startOffset": 90, "endOffset": 93}, {"referenceID": 8, "context": "Some other researchers introduced sparsification, feedback and lateral inhibition [9], [10]into HMAX.", "startOffset": 82, "endOffset": 85}, {"referenceID": 9, "context": "Some other researchers introduced sparsification, feedback and lateral inhibition [9], [10]into HMAX.", "startOffset": 87, "endOffset": 91}, {"referenceID": 10, "context": "The series works have demonstrated very good performance in a range of recognition tasks which is competitive with the state of art approaches, such as face recognition [11], scene classification [12] and handwritten digit recognition [13].", "startOffset": 169, "endOffset": 173}, {"referenceID": 11, "context": "The series works have demonstrated very good performance in a range of recognition tasks which is competitive with the state of art approaches, such as face recognition [11], scene classification [12] and handwritten digit recognition [13].", "startOffset": 196, "endOffset": 200}, {"referenceID": 12, "context": "The series works have demonstrated very good performance in a range of recognition tasks which is competitive with the state of art approaches, such as face recognition [11], scene classification [12] and handwritten digit recognition [13].", "startOffset": 235, "endOffset": 239}, {"referenceID": 2, "context": "From another point of view, Itti established a visual attention model [3], [14], which is inspired by the behavioral and neural architecture of the early primate visual system.", "startOffset": 70, "endOffset": 73}, {"referenceID": 13, "context": "From another point of view, Itti established a visual attention model [3], [14], which is inspired by the behavioral and neural architecture of the early primate visual system.", "startOffset": 75, "endOffset": 79}, {"referenceID": 14, "context": "Itti and Poggio et al [15] merged the saliency-based attention model proposed in the previous work [3] to HMAX in order to modify the activity of the S2 layer.", "startOffset": 22, "endOffset": 26}, {"referenceID": 2, "context": "Itti and Poggio et al [15] merged the saliency-based attention model proposed in the previous work [3] to HMAX in order to modify the activity of the S2 layer.", "startOffset": 99, "endOffset": 102}, {"referenceID": 15, "context": "Saliency based visual attention models are further compared with behavioral experiments [16] and showed that the models could account for a significant portion of human gaze behavior in a naturalistic, interactive setting.", "startOffset": 88, "endOffset": 92}, {"referenceID": 16, "context": "models [17] have demonstrated successful applications in computer vision [18], mobile robotics [19], and cognitive systems [20].", "startOffset": 7, "endOffset": 11}, {"referenceID": 17, "context": "models [17] have demonstrated successful applications in computer vision [18], mobile robotics [19], and cognitive systems [20].", "startOffset": 73, "endOffset": 77}, {"referenceID": 18, "context": "models [17] have demonstrated successful applications in computer vision [18], mobile robotics [19], and cognitive systems [20].", "startOffset": 95, "endOffset": 99}, {"referenceID": 19, "context": "models [17] have demonstrated successful applications in computer vision [18], mobile robotics [19], and cognitive systems [20].", "startOffset": 123, "endOffset": 127}, {"referenceID": 20, "context": "Deep Belief Networks (DBN) [21] has shown the state of the art performance in a range of recognition tasks [22], [23].", "startOffset": 27, "endOffset": 31}, {"referenceID": 21, "context": "Deep Belief Networks (DBN) [21] has shown the state of the art performance in a range of recognition tasks [22], [23].", "startOffset": 107, "endOffset": 111}, {"referenceID": 22, "context": "Deep Belief Networks (DBN) [21] has shown the state of the art performance in a range of recognition tasks [22], [23].", "startOffset": 113, "endOffset": 117}, {"referenceID": 23, "context": "In this paper, we propose a model based on HMAX and some basic facts about the memory and association mechanism established over the last decade by several physiological studies of cortex [24], [25], [26], [27].", "startOffset": 188, "endOffset": 192}, {"referenceID": 24, "context": "In this paper, we propose a model based on HMAX and some basic facts about the memory and association mechanism established over the last decade by several physiological studies of cortex [24], [25], [26], [27].", "startOffset": 194, "endOffset": 198}, {"referenceID": 25, "context": "In this paper, we propose a model based on HMAX and some basic facts about the memory and association mechanism established over the last decade by several physiological studies of cortex [24], [25], [26], [27].", "startOffset": 200, "endOffset": 204}, {"referenceID": 26, "context": "In this paper, we propose a model based on HMAX and some basic facts about the memory and association mechanism established over the last decade by several physiological studies of cortex [24], [25], [26], [27].", "startOffset": 206, "endOffset": 210}, {"referenceID": 26, "context": "proposed that episodic memory and semantic memory are two subsystems of declarative memory [27].", "startOffset": 91, "endOffset": 95}, {"referenceID": 23, "context": "1: Sketch of the relationship between semantic and episodic memory [24] (2).", "startOffset": 67, "endOffset": 71}, {"referenceID": 24, "context": "Brain imaging studies show that object representation is related to different cortical regions, forming a distributed network that is parallel to the organization of sensory and motor systems [25].", "startOffset": 192, "endOffset": 196}, {"referenceID": 27, "context": "For example, in the word generation experiments, ventral and lateral regions of the posterior temporal cortex have been found eliciting differentially with different types of information retrieved [28].", "startOffset": 197, "endOffset": 201}, {"referenceID": 27, "context": "In other related behavioral experiments in which the subjects are required to name an action or a color, the specialization of different cortical regions has also been observed [28].", "startOffset": 177, "endOffset": 181}, {"referenceID": 24, "context": "Objects Aggregate Together Researchers believe that the brain tends to process common features from different objects in the same areas [25].", "startOffset": 136, "endOffset": 140}, {"referenceID": 24, "context": "In the related behavioral experiments, when the subject was required to perform same task with different object categories as stimuli, the ventral occipitotemporal cortex was consistently activated and encoded the object forms with distinct neural response patterns [25].", "startOffset": 266, "endOffset": 270}, {"referenceID": 28, "context": "Another body of evidence comes from studies of cortical lesions [29], [30].", "startOffset": 64, "endOffset": 68}, {"referenceID": 29, "context": "Another body of evidence comes from studies of cortical lesions [29], [30].", "startOffset": 70, "endOffset": 74}, {"referenceID": 28, "context": "The damage to temporal lobes is found to be strongly associated with the impairment of abilities to recognize objects and retrieve information about object-specific characteristics [29], [30].", "startOffset": 181, "endOffset": 185}, {"referenceID": 29, "context": "The damage to temporal lobes is found to be strongly associated with the impairment of abilities to recognize objects and retrieve information about object-specific characteristics [29], [30].", "startOffset": 187, "endOffset": 191}, {"referenceID": 30, "context": "Functional column may provide the anatomical basis accounting for the above phenomena, and recent studies suggest that the functional column is a basic processing architecture spreading over visual neural systems [31], [32], [33].", "startOffset": 213, "endOffset": 217}, {"referenceID": 31, "context": "Functional column may provide the anatomical basis accounting for the above phenomena, and recent studies suggest that the functional column is a basic processing architecture spreading over visual neural systems [31], [32], [33].", "startOffset": 219, "endOffset": 223}, {"referenceID": 32, "context": "Functional column may provide the anatomical basis accounting for the above phenomena, and recent studies suggest that the functional column is a basic processing architecture spreading over visual neural systems [31], [32], [33].", "startOffset": 225, "endOffset": 229}, {"referenceID": 30, "context": "On the surface of infratemporal cortex that activated by faces, neurons with common preference were found aggregating in patches specifying different stimuli [31].", "startOffset": 158, "endOffset": 162}, {"referenceID": 31, "context": "Similar organization was also seen in the area of posterior TE that is responsive to simple two-dimensional shapes [32].", "startOffset": 115, "endOffset": 119}, {"referenceID": 33, "context": "It is inferred that such a columnar organization would produce stimulus invariance [34] and also provides a visual alphabet from which numerous complex objects can be efficiently represented as a distributed code [33].", "startOffset": 83, "endOffset": 87}, {"referenceID": 32, "context": "It is inferred that such a columnar organization would produce stimulus invariance [34] and also provides a visual alphabet from which numerous complex objects can be efficiently represented as a distributed code [33].", "startOffset": 213, "endOffset": 217}, {"referenceID": 34, "context": "As a basic functional part of memory, recognition memory has its use in identifying and judging whether the presented object has ever been captured consciously [35], [26].", "startOffset": 160, "endOffset": 164}, {"referenceID": 25, "context": "As a basic functional part of memory, recognition memory has its use in identifying and judging whether the presented object has ever been captured consciously [35], [26].", "startOffset": 166, "endOffset": 170}, {"referenceID": 35, "context": "Some researchers argue that the only difference between familiarity discrimination and recollection matching is the trace strength, in term of which the former is weaker than the latter [36], [37], [38], while others regard the two processes as qualitatively different modes of recognition memory, which may be executed by hippocampus and perirhinal cortex, respectively [35], [26].", "startOffset": 186, "endOffset": 190}, {"referenceID": 36, "context": "Some researchers argue that the only difference between familiarity discrimination and recollection matching is the trace strength, in term of which the former is weaker than the latter [36], [37], [38], while others regard the two processes as qualitatively different modes of recognition memory, which may be executed by hippocampus and perirhinal cortex, respectively [35], [26].", "startOffset": 192, "endOffset": 196}, {"referenceID": 37, "context": "Some researchers argue that the only difference between familiarity discrimination and recollection matching is the trace strength, in term of which the former is weaker than the latter [36], [37], [38], while others regard the two processes as qualitatively different modes of recognition memory, which may be executed by hippocampus and perirhinal cortex, respectively [35], [26].", "startOffset": 198, "endOffset": 202}, {"referenceID": 34, "context": "Some researchers argue that the only difference between familiarity discrimination and recollection matching is the trace strength, in term of which the former is weaker than the latter [36], [37], [38], while others regard the two processes as qualitatively different modes of recognition memory, which may be executed by hippocampus and perirhinal cortex, respectively [35], [26].", "startOffset": 371, "endOffset": 375}, {"referenceID": 25, "context": "Some researchers argue that the only difference between familiarity discrimination and recollection matching is the trace strength, in term of which the former is weaker than the latter [36], [37], [38], while others regard the two processes as qualitatively different modes of recognition memory, which may be executed by hippocampus and perirhinal cortex, respectively [35], [26].", "startOffset": 377, "endOffset": 381}, {"referenceID": 38, "context": "This hypothesis has been confirmed in some related experiments, in which subjects made familiarity decisions faster than recollect decisions [39], [40], [27].", "startOffset": 141, "endOffset": 145}, {"referenceID": 39, "context": "This hypothesis has been confirmed in some related experiments, in which subjects made familiarity decisions faster than recollect decisions [39], [40], [27].", "startOffset": 147, "endOffset": 151}, {"referenceID": 26, "context": "This hypothesis has been confirmed in some related experiments, in which subjects made familiarity decisions faster than recollect decisions [39], [40], [27].", "startOffset": 153, "endOffset": 157}, {"referenceID": 40, "context": "The computational efficiency of a recognition system dedicated for familiarity discrimination has also been demonstrated by the simulated neural networks [41].", "startOffset": 154, "endOffset": 158}, {"referenceID": 23, "context": "These two kinds of features are just corresponding to the semantic and episodic memory of declarative memory in cognitive science [24] 2) Features of One Object are Saved in Distributed Memory and of and Common Features of Various Objects Are Stored Aggregately (Block2) A1 to Am represent various common semantic attributes of different objects.", "startOffset": 130, "endOffset": 134}, {"referenceID": 33, "context": "This memory mechanism has clear biological evidences [34], [25] 3) Recognition of One Candidate (Block3) Tt represents a candidate.", "startOffset": 53, "endOffset": 57}, {"referenceID": 24, "context": "This memory mechanism has clear biological evidences [34], [25] 3) Recognition of One Candidate (Block3) Tt represents a candidate.", "startOffset": 59, "endOffset": 63}, {"referenceID": 34, "context": "This process corresponds to the familiarity discrimination (\u2019knowing\u2019 through the episode) in biological recognition memory [35].", "startOffset": 124, "endOffset": 128}, {"referenceID": 34, "context": "This procedure is illuminated by recollective matching in recognition memory [35].", "startOffset": 77, "endOffset": 81}, {"referenceID": 23, "context": "As we know, memory is the process by which information is encoded, stored, and retrieved, and the memory to an object with conscious process is called declarative memory, which can be divided into semantic memory and episodic memory [24], [42].", "startOffset": 233, "endOffset": 237}, {"referenceID": 41, "context": "As we know, memory is the process by which information is encoded, stored, and retrieved, and the memory to an object with conscious process is called declarative memory, which can be divided into semantic memory and episodic memory [24], [42].", "startOffset": 239, "endOffset": 243}, {"referenceID": 42, "context": "Semantic memory refers to the memory which is learned by people, such as meanings, understandings, concept-based knowledge and work-related skills and facts [43].", "startOffset": 157, "endOffset": 161}, {"referenceID": 43, "context": "Episodic memory refers to the memory which is explicitly located in the past involving the specific events and situations, such as times, places, associated emotions and other contextual knowledge [44], [45].", "startOffset": 197, "endOffset": 201}, {"referenceID": 44, "context": "Episodic memory refers to the memory which is explicitly located in the past involving the specific events and situations, such as times, places, associated emotions and other contextual knowledge [44], [45].", "startOffset": 203, "endOffset": 207}, {"referenceID": 1, "context": "Special episodic patches could be extracted, which corresponds to Ji of the object Oi and are put into HMAX model proposed by [2], which can extract a set of position and scale tolerant features.", "startOffset": 126, "endOffset": 129}, {"referenceID": 27, "context": "As we have listed in section II, many data and evidence proved that an object concept may be represented by the discrete cortical regions [28] and neurons responding to the common feature of different objects aggregate together [34].", "startOffset": 138, "endOffset": 142}, {"referenceID": 33, "context": "As we have listed in section II, many data and evidence proved that an object concept may be represented by the discrete cortical regions [28] and neurons responding to the common feature of different objects aggregate together [34].", "startOffset": 228, "endOffset": 232}, {"referenceID": 34, "context": "As shown in Section II, there are two processes in the recognition memory: familiarity discrimination and recollective matching [35], and their combination is useful for a fast and accurate human recognition task.", "startOffset": 128, "endOffset": 132}, {"referenceID": 34, "context": "This process corresponds to the familiarity discrimination in recognition memory [35].", "startOffset": 81, "endOffset": 85}, {"referenceID": 34, "context": "This procedure is illuminated by re-collective matching in recognition memory [35].", "startOffset": 78, "endOffset": 82}], "year": 2013, "abstractText": "A famous biologically inspired hierarchical model firstly proposed by Riesenhuber and Poggio has been successfully applied to multiple visual recognition tasks. The model is able to achieve a set of positionand scale-tolerant recognition, which is a central problem in pattern recognition. In this paper, based on some other biological experimental results, we introduce the Memory and Association Mechanisms into the above biologically inspired model. The main motivations of the work are (a) to mimic the active memory and association mechanism and add the \u2019top down\u2019 adjustment to the above biologically inspired hierarchical model and (b) to build up an algorithm which can save the space and keep a good recognition performance. More details of the work could be explained as follows: (1) In objects memorizing process: Our proposed model mimics some characteristics of human\u2019s memory mechanism as follows: (a) In our model, one object is memorized by semantic attributes and special image patches (corresponding to episodic memory). The semantic attributes describe each part of the object with clear physical meaning, for example, if eyes and mouths of faces are \u2019big\u2019 or \u2019small\u2019 and so on. One special patch is selected if the value of the corresponding semantic feature is far from average one. The patch should be the most prominent part of the object. (b) In our model, different features (semantic attributes and special patches) of one object are stored in distributed places and the common feature of different objects is saved aggregately, which can learn to classify the difference of similar features of different objects. The similarity thresholds to each object can be learnt when new objects are learnt. (2) In object recognition process: In biological process, the associated recognition including familiarity discrimination and recollective matching. In our proposed model, firstly mimicking familiarity discrimination (\u2019knowing\u2019 though the episode), we compare the special patches of candidates with that of saved objects using above mentioned biologically inspired hierarchical model, where the candidates and saved objects have the same prominent semantic features. Then mimicking recollective matching, the comparison results of special patches are combined with semantic feature comparison. The new model is also applied to object recognition processes. The primary experimental results show that our method is efficient with much less memory requirement.", "creator": "LaTeX with hyperref package"}}}