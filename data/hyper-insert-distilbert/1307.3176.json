{"id": "1307.3176", "review": {"conference": "AAAI", "VERSION": "v1", "DATE_OF_SUBMISSION": "11-Jul-2013", "title": "Fast Gradient Descent for Drifting Least Squares Regression, with Application to Bandits", "abstract": "we improve the efficient computational sparse complexity problem of online learning meditation algorithms that require to often readily recompute least squares posterior regression estimates loss of smoothing parameters. we additionally propose two stochastic gradient descent schemes deal with randomisation in order to efficiently exactly track the true solutions of the increasing regression problems except achieving an o ( \u00d7 d ) improvement curve in complexity, essentially where d is the common dimension of the data. the first algorithm assumes avoiding strong convexity limit in reducing the infinite regression linear problem, when and alternately we provide bounds on the gibbs error both in decreasing expectation and high probability ( the methodology latter name is often needed to provide limited theoretical guarantees for higher level algorithms ). the algorithm second algorithms algorithm successfully deals solely with cases where strong convexity stability of the regression problem cannot be guaranteed and uses polynomial adaptive regularisation. we never again give error bounds in both expectation correction and assuming high noise probability. we apply our initial approaches to the linear bandit algorithms pege and independent confidenceball heap and conversely demonstrate significant gains lacking in complexity in virtually both cases. indeed since strong convexity computation is guaranteed by the specific pege algorithm, otherwise we lose therefore only logarithmic correlation factors interfering in the regret performance of reducing the filter algorithm. on the three other note hand, in the single confidenceball gradient algorithm we easily adaptively regularise to further ensure their strong convexity, and this efficient results is in an experimental o ( @ n ^ { { 1 / ( 5 } ) graded deterioration pattern of causing the regret.", "histories": [["v1", "Thu, 11 Jul 2013 16:36:29 GMT  (27kb)", "http://arxiv.org/abs/1307.3176v1", null], ["v2", "Wed, 19 Feb 2014 00:27:18 GMT  (1545kb,D)", "http://arxiv.org/abs/1307.3176v2", null], ["v3", "Thu, 24 Jul 2014 14:29:52 GMT  (3757kb,D)", "http://arxiv.org/abs/1307.3176v3", null], ["v4", "Thu, 20 Nov 2014 12:40:48 GMT  (104kb,D)", "http://arxiv.org/abs/1307.3176v4", null]], "reviews": [], "SUBJECTS": "cs.LG stat.ML", "authors": ["nathaniel korda", "prashanth l a", "r\u00e9mi munos"], "accepted": true, "id": "1307.3176"}, "pdf": {"name": "1307.3176.pdf", "metadata": {"source": "CRF", "title": "Online gradient descent for least squares regression: Non-asymptotic bounds and application to bandits", "authors": ["Nathaniel Korda"], "emails": ["nathaniel.korda@inria.fr", "prashanth.la@inria.fr", "remi.munos@inria.fr"], "sections": [{"heading": null, "text": "ar X\niv :1\n30 7.\n31 76\nv1 [\ncs .L\nG ]\n1 1\nJu l 2"}, {"heading": "1 Introduction", "text": "Often in learning algorithms an unknown parameter must be estimated from data arriving sequentially in pairs, (xn, yn). We consider settings where the points xn are chosen by a higher level algorithm and the outputs yn satisfy the dynamics yn = xTn\u03b8\n\u2217 + \u03ben, where \u03ben is i.i.d., zero-mean noise, and \u03b8\u2217 is the unknown parameter. Typically, in such cases a least squares regression estimate is used for \u03b8\u2217, and finding this estimate is often the most computationally intensive part of the higher level algorithm. We provide two Stochastic Gradient Descent (SGD) algorithms that achieve a significant saving in complexity in big data settings where either the dimension of the data, d, is very large, or both d and the number of samples, n, is large. Furthermore we provide an application of both of these algorithms to significantly reduce complexity in linear bandit problems.\nThe solution to the least squares regression problem is the minimizer of the least square error, i.e.,\n\u03b8\u0302n = argmin \u03b8\n1\n2\nn\u2211\ni=1\n(yi \u2212 \u03b8Txi)2.\nIt is well-known that \u03b8\u0302n = A\u0304\u22121n b\u0304n, where\nA\u0304n = 1\nn\nn\u22121\u2211\ni=1\nxix T i and b\u0304n = 1\nn\nn\u22121\u2211\ni=1\nxiyi.\n1 O\u0303(\u00b7) is the usual O(.) notation with the log factors hidden.\nAssuming that the features xi evolve in compact subset D of Rd, the complexity of solving one regression problem with the above approach is O(d2), where the inverse of A\u0304n is computed iteratively using the Sherman-Morrison lemma (using the Strassen algorithm or the Coppersmith-Winograd algorithm gives a complexity of O(d2.807) and O(d2.375) respectively).\nAn alternative to this approach is to use an online SGD scheme to approximate \u03b8\u0302n. The advantage of such an approach is that the costly inversion of the A\u0304n matrix is replaced by an iterative scheme. We randomise the samples in order to apply online SGD schemes and this reduces the complexity of each iteration to O(d). Furthermore, to cope with situations where strong convexity of the A\u0304n matrix cannot be guaranteed by the higher level algorithm, we propose an adaptive regularisation. For both schemes we provide error bounds both in expectation and in high probability. Such bounds are essential for giving theoretical guarantees when using a randomised SGD scheme to replace the matrix inversion approach to the regression problem in a higher level learning algorithm.\nUnlike the traditional SGD setting where the pairs (xn, yn) are samples drawn from some unknown joint probability distribution, we assume that the samples, xn, are chosen by a higher level learning algorithm and the problem is to find a good enough approximation to \u03b8\u2217 for its purposes. This poses a new difficulty for the analysis of such SGD schemes, and we propose here two solutions to this problem. First we show that under a strong convexity assumption on the matrices A\u0304n, the analysis can be achieved by adapting methods from the literature. In this case we bound directly the error in approximating \u03b8\u2217.\nWhen no strong convexity can be guaranteed we choose to regularise the regression problem. However since our data is growing with time we introduce a regularisation, \u03bbn, that adapts to the sample size n as follows:\n\u03b8\u0303n := argmin \u03b8\n1\n2n\nn\u2211\ni=1\n(yi \u2212 \u03b8Txi)2 + \u03bbn \u2016\u03b8\u201622 .\nOur second iteration scheme tracks the regression solutions, \u03b8\u0303n, and we bound the error in approximating these solutions. This introduces a drift error into the overall error of the iterative scheme that reflects the fact that the regularisation \u03bbn changes at each time step.\nAs examples of a higher level learning algorithm using regression as a subroutine, we consider two linear bandit algorithms, the PEGE algorithm of [7] and the ConfidenceBall algorithm of [2]. In a linear bandit problem the values xn represent actions taken by an agent and the values yn = xTn\u03b8\n\u2217 + \u03ben are interpreted as losses with unknown parameter \u03b8\u2217. At each time the agent can choose to take any action x \u2208 D, where D is some compact subset of Rd, and the agent\u2019s goal is to maximise the expected sum of losses. This goal would be achieved by choosing xn = x\u2217 := argminx{xT\u03b8\u2217}, \u2200n. However, since one does not know the value of \u03b8\u2217 one needs to estimate it, and a tradeoff appears between sampling pairs (xn, yn) that will improve the estimate of \u03b8\u2217, and gaining the best short term losses possible by exploiting the current information available about \u03b8\u2217. Typically the performance of a bandit algorithm is measured by its expected cumulative regret: Rn = \u2211n i=1(x\n\u2217 \u2212 xi)T\u03b8\u2217. The PEGE algorithm of [7] is designed for action sets D satisfying a strong convexity property (see assumption (A4) in Section 3). The algorithm splits time into exploration phases and exploitation phases. During the exploitation phases the algorithm acts greedily using least squares estimates of \u03b8\u2217 calculated from data gathered during the exploration phases. During the exploration phases data is gathered in such a way that A\u0304n matrices are always strongly convex. The regret performance of this algorithm is O(dn1/2), and we find that if we replace the least squares estimates with SGD iterates with no regularisation, we achieve an improvement of order O(d) in complexity, while suffering a loss of only log factors in the regret performance.\nThe ConfidenceBall algorithm requires only that D be compact, i.e., the action sets are not necessarily strongly convex. It continually updates a least squares estimate of \u03b8\u2217, and a confidence region, Bn, around\nthat estimate based on all the past data. It then chooses xn = argmaxxmax\u03b8\u2208Bn{xT\u03b8\u2217}, and its regret performance is O\u0303(dn1/2). Since strong convexity of the matrices A\u0304n cannot be guaranteed for this algorithm, we incorporate adaptive regularisation based SGD scheme and the resulting drift error due to the timevarying regularisation parameter \u03bbn induces a loss in the regret performance. Using our algorithm we are able to achieve an O(d) improvement in complexity with an order O(n1/5) deterioration in the regret."}, {"heading": "Main Contributions", "text": "\u2022 We propose two online algorithms - both employing randomisation of samples, one without regularization and another with adaptive regularization. These algorithms track the corresponding least squares solution \u03b8\u0302n and can be viewed as SGD schemes. The former converges at the rate of O ( n\u22121/2 ) .\nThe rate of convergence of the latter depends on the rate of convergence of the regularised least squares solution, which in turn is problem dependent. Both incur a computational cost of only O(d) per iteration.\n\u2022 We demonstrate the usefulness of our algorithms by applying them to the linear bandit setting, using them instead of solving the least squares regression steps. For the PEGE algorithm of [7] our result achieves an O(d) improvement in complexity, while incurring only a logarithmic deterioration in the regret. For the ConfidenceBall algorithm of [2] we again achieve a complexity improvement of O(d), while incurring an O(n1/5) deterioration in the regret.\n\u2022 We provide finite time analysis of all our schemes including bounds both in high probability as well as in expectation. In particular, we observe that under a step-size choice of O(n\u22121), the non regularised algorithm is within O ( n1/2 ) of the least squares solution \u03b8\u0302n under a strong convexity assumption on\nA\u0304n. By contrast, using larger step sizes O(n\u2212\u03b1), \u03b1 \u2208 (1/2, 1), the regularised algorithm exhibits slightly worse bounds in expectation, and bounds in high probability dependent on the rate of convergence of the regularised least squares estimates, but does not require the strong convexity assumption.\nRelated work Stochastic gradient descent is a popular approach for optimizing a function given noisy observations, while incurring low computational complexity. Non-asymptotic bounds in expectation for SGD schemes have been provided in [1]. In the machine learning community, several algorithms have been proposed for minimizing the regret, for instance, [9, 5, 6] and these can be converted to find the minimizer of a (usually convex) function. A closely related field is stochastic approximation (SA) and concentration bounds for SA algorithms have been provided in [4]. Adaptive regularisation in the context of least squares regression has been analysed in [8].\nIn general, none of the schemes proposed above are directly applicable in our setting due to two difficulties: (a) our data {(xi, yi)}ni=1 do not arrive from a distribution, but instead are chosen by a higher level algorithm, and (b) an efficient online scheme is required to track the solution of a least squares regression problem with growing data to be used by the higher level algorithm. This is often true in practice, for instance, in linear bandit problems which are used to model news-recommendation engines.\nThe rest of the paper is organized as follows: In Section 2 we present the online algorithms - with and without regularisation - for solving least squares regression. In Section 3, we apply the first algorithm in a linear bandit setting with strongly convex arms, while in Section 4, we apply the regularised variant (the second algorithm) to a linear bandit setting where the arms are not necessarily from a strongly convex space. Finally, in Section 5 we provide the concluding remarks."}, {"heading": "2 Algorithms", "text": "We first present in Section 2.1 an online incremental algorithm that solves a least squares regression problem at each step. We next extend this algorithm to include (adaptive) regularization in Section 2.2. For each of these algorithms, we provide the non-asymptotic bounds that includes both high probability as well as bounds in expectation on the distance of online algorithm iterate from the (unknown) parameter \u03b8\u2217."}, {"heading": "2.1 Random Online", "text": "Recall that \u03b8\u0302n := min \u03b8 1 2\nn\u2211 i=1 (yi \u2212 \u03b8Txi)2."}, {"heading": "Assumptions", "text": "(A1) Boundedness of xn, i.e., supn \u2016xn\u20162 \u2264 1.\n(A2) The noise {\u03ben} is i.i.d. and |\u03ben| \u2264 1,\u2200n2.\n(A3) For all n, \u03bbmin(A\u0304n) \u2265 \u00b5, where \u03bbmin(\u00b7) denotes the smallest eigenvalue of a matrix. While the first two assumptions are standard in the context of least squares, the third assumption is made necessary due to the fact that we do not regularise the problem.\nUpdate Rule The online SGD procedure attempts to shadow \u03b8\u0302n using a stochastic gradient scheme which updates the iterate \u03b8n as follows:\n\u03b8n = \u03b8n\u22121 + \u03b3n(yin \u2212 \u03b8Tn\u22121xin)xin where in \u223c U({1, . . . , n})3, (1) and \u03b80 is an arbitrary fixed value. Note that the samples (xin , yin) passed to (1) are uniformly randomly from the set {(x1, y1), . . . , (xn, yn)}. We establish in the following that the iterate \u03b8n obtained after running n steps of (1) is close to the least squares solution \u03b8\u0302n.\nResults We let zn := \u03b8n \u2212 \u03b8\u2217. Then Theorem 1. Under (A1)-(A2), for all n \u2265 1, we have\nP (\u2016zn\u20162 \u2212 E \u2016zn\u20162 \u2265 \u01eb) \u2264 exp\n\n   \u2212 \u01eb\n2\n2 n\u2211\ni=1 L2i\n\n   , where Li \u25b3 = \u03b3i\n\n\nn\u22121\u220f\nj=i\n(1 + \u03b32j+1 \u2212 2\u00b5\u03b3j+1)\n\n\n1/2\n.\nTheorem 2. Under (A1)-(A3), for all n \u2265 1, we have\nE \u2016zn\u20162 \u2264 exp(\u2212\u00b5\u0393n) \u2016z0\u20162 \ufe38 \ufe37\ufe37 \ufe38\ninitial error\n+\n( n\u22121\u2211\nk=1\n\u03b32k+1h(k) exp(\u22122\u00b5(\u0393n \u2212 \u0393k+1)) ) 1 2\n\ufe38 \ufe37\ufe37 \ufe38\nsampling error\nwhere h(k) = 2 [ \u03c32\u03be + 2(\u2016z0\u20162 + \u0393k)2 ] , and \u03c3\u03be = E\u03be[\u03be2] < \u221e is the variance of the noise.\nThe starting point \u03b80 of the algorithm impacts the initial error, while the sampling error comes from a martingale difference sequence.\n2We believe that the analysis of this paper can be extended to a setting with unbounded noise that satisfies a sub-Gaussian property.\n3 U(S) denotes the uniform distribution on the set S.\nChoice of step-sizes Fix \u03b3n = c/n. For this choice of step size, in Theorem 1\nn\u2211\ni=1\nL2i =\nn\u2211\ni=1\nc2 i2\nn\u220f\nj=i\n(1 + c2 j2 \u2212 2\u00b5c j ) \u2264\nn\u2211\ni=1\nKc i2 exp\n \u22122\u00b5c n\u2211\nj=i\n1\nj\n  \u2264 Kcn\u22122\u00b5c \u221e\u2211\ni=1\ni\u22122(1\u2212\u00b5c),\nwhere Kc := c2 exp( c 2\u03c02\n6 ). We now have three regimes for the rate of convergence, based on the choice of\nc: \u2211n\ni=1 L 2 i \u2264\n[\n1 + 11\u22122\u00b5c\n]\nKcn \u22122\u00b5c when \u00b5c \u2208 (0, 1/2), \u2211ni=1 L2i \u2264 Kcn\u22121 lnn when \u00b5c = 1/2, and\n\u2211n i=1 L 2 i \u2264 2 2\u00b5c\u22121 2\u00b5c\u22121Kcn \u22121 when \u00b5c \u2208 (1/2, 1). (We have used comparisons with integrals to bound the summations.) Thus, the optimal rate for the high probability bound from Theorem 1 with (\u00b5c > 1/2) is\nP (\u2016zn\u20162 \u2212 E \u2016zn\u20162 \u2265 \u01eb) \u2264 exp ( \u2212 \u01eb 2n\n2K\u00b5,c\n)\n, where K\u00b5,c := 22\u00b5c\u22121\n2\u00b5c\u2212 1Kc. (2)\nThe sampling error (second term in Theorem 2) is bounded as follows:\nn\u22121\u2211\nk=1\nh(k)\u03b32k+1 exp (\u22122\u00b5(\u0393n \u2212 \u0393k+1)) \u2264 c2n\u22122\u00b5c n\u2211\nk=1\nh(k)k\u22122(1\u2212\u00b5c)\nComparing the sum with the integral yields the following rates for the bound in expectation:\nE \u2016zn\u20162 \u2264 (\u2016z0\u20162\nn\u00b5c +\nh1(n)\nn\u00b5c\u22271/2\n)\n4, (3)\nwhere h1(n) hides ln factors. Thus, the initial error goes down at an exponential rate, while the sampling error decays at the rate n\u22121/2.\nRemark 1. Ensuring the optimal rate here requires knowledge of the strong convexity constant \u00b5. In our application to linear bandits in Section 3 we know this constant. However, we can use Polyak averaging together with the step size \u03b3n = cn\u2212\u03b1 to arrive at an optimal rate independent of the choice of c. We give further details in Appendix A.4"}, {"heading": "2.2 Random Online with Regularisation", "text": "Ideally an online algorithm would not need to satisfy an assumption such as (A3). Indeed we can get rid of this dependency by introducing a regularisation parameter. In an offline setting the natural regularisation parameter would be \u03bb/T for some \u03bb > 0, where T is the size of the batch. However in an online setting we envisage obtaining arbitrary amounts of information, and so we need to regularize adaptively at each time step by \u03bbn. Recall \u03b8\u0303n := argmin\u03b8 12n \u2211n i=1(yi \u2212 \u03b8Txi)2 + \u03bbn \u2016\u03b8\u201622.\nUpdate Rule The following algorithm attempts to shadow the solutions \u03b8\u0303n more and more closely as n \u2192 \u221e:\n\u03b8n = \u03b8n\u22121 + \u03b3n((yin \u2212 \u03b8Tn\u22121xin)xin \u2212 \u03bbn\u03b8n\u22121), where in \u223c U(1, . . . , n). (4) 4 a \u2227 b denotes the minimum of a and b.\nResults Once again, we let zn := \u03b8n \u2212 \u03b8\u2217. Then, the high probability bound in Theorem 1 holds with\nthe Lipschitz constants Li := \u03b3i\n( n\u22121\u220f\nj=i (1 + \u03b32j+1 \u2212 2\u03bbj+1\u03b3j+1)\n)1/2\n. However, it is difficult to obtain an\nanalogue of Theorem 2 that bounds zn directly owing to the fact that we regularise with a time-varying \u03bbn. Instead, we first bound the distance of the iterate \u03b8n to the least squares solution \u03b8\u0303n below. The final bound on zn is provided indirectly by a combination of triangle inequality and bounds on \u03b8n\u2212 \u03b8\u0303n and \u03b8\u0303n\u2212 \u03b8\u2217 (see Theorem 4 below).\nTheorem 3. Let z\u0303n = \u03b8n \u2212 \u03b8\u0303n. Then, under (A1)-(A2), for all n \u2265 1, we have\nE \u2016z\u0303n\u20162 \u2264\u2016z\u03030\u20162 exp(\u2212\u0393\u2032n) \ufe38 \ufe37\ufe37 \ufe38\ninitial error\n+ \u2225 \u2225 \u2225(\u03b8\u0303n \u2212 \u03b8\u03030) \u2225 \u2225 \u2225 2 + n\u2211\nk=1\n\u03b3k\u03bbk \u2225 \u2225 \u2225\u03b8\u0303k \u2212 \u03b8\u03030 \u2225 \u2225 \u2225 2 exp(\u2212(\u0393\u2032n \u2212 \u0393\u2032k))\n\ufe38 \ufe37\ufe37 \ufe38\ndrift error\n+\n( n\u2211\nk=1\nh(k)\u03b32k exp(\u22122(\u0393\u2032n \u2212 \u0393\u2032k)) )1/2\n\ufe38 \ufe37\ufe37 \ufe38\nsampling error\n,\nwhere \u0393\u2032n := \u2211n k=1 \u03bbk\u03b3k, \u03b8\u03030 is arbitrary and h(n) = 2\u03c3 2 \u03be + 8\n( (g(n))2 + \u03bb2n \u2016\u03b8\u2217\u201622 + 2\u03bbn \u2016\u03b8\u2217\u20162 g(n) )2 ,\nwith g(n) := \u2016z\u03030\u20162 + (\u2211n k=1 \u03b3 2 k exp(\u22122(\u0393\u2032n \u2212 \u0393\u2032k)) ) 1 2 \u03c3\u03be + \u0393 \u2032 n \u2016\u03b8\u2217\u20162.\nThe initial and sampling errors are of the same nature as in the random online algorithm, whereas the drift error is caused by adaptively regularizing the problem using a varying \u03bbn. This is evident from the following observation: the drift error is obtained by a discrete integration by parts of \u2225 \u2225 \u2225 \u2211n\nk=1 \u03a0\u0303n\u03a0\u0303 \u22121 k (\u03b8\u0302k \u2212 \u03b8\u0302k\u22121) \u2225 \u2225 \u2225 2 ,\nwhere \u03a0\u0303n := \u220fn\nk=1\n( I \u2212 \u03b3k(A\u0304k + \u03bbkI) ) (See Appendix A.2).\nChoice of step-sizes We note two difficulties in the choice of step-sizes and regularisation parameters: (a) In order to recover exactly the Theorem 1 and 2 we would need to set \u03bbn = \u00b5. However this regularisation would be too strong, and the solutions \u03b8\u0303n could fail to converge to the true \u03b8\u2217. We also require \u0393\u2032n \u2192 \u221e for Theorem 3 to be useful. (b) We fix \u03b3n = c/n\u03b1 and \u03bbn = \u00b5/n1\u2212\u03b1, with \u03b1 \u2208 (1/2, 1). While this choice takes care of the initial and sampling errors in the bound in expectation, handling the drift error is still problematic. We overcome this by bounding the drift error with high probability and this turns out to be sufficient for analysis of the linear bandit problems (see Section 4).\nUnder the choice (b) above, we have \u2211n\ni=1 L 2 i \u2264 n\u22122\u00b5c \u2211n i=1 i\n\u22122(\u03b1\u2212\u00b5c). When c and \u00b5 are chosen so that \u00b5c > \u03b1\u2212 1/2, we obtain the following high probability bound:\nP (\u2016z\u0303n\u20162 \u2212 E \u2016z\u0303n\u20162 \u2265 \u01eb) \u2264 exp ( \u2212\u01eb 2n2\u03b1\u22121\n\u03b1K\u00b5,c\n)\n, (5)\nwhere K\u00b5,c = K\u00b5,c(\u03b1) := 22\u00b5c\u2212(2\u03b1\u22121) 2\u00b5c\u2212 (2\u03b1 \u2212 1)Kc, and Kc = exp (\u2211\u221e i=1 ci \u22122\u03b1 ) .\nBound on E \u2016z\u0303n\u20162: The initial and sampling errors (first and the last terms in (3)) of the bound in expectation can be seen to be of the order O (n\u2212\u00b5c) and O ( h1(n)\nn\u03b1\u22121/2\n)\n, respectively. The drift error is seen to\nbe of the order O ( h2(n)\nn\u2212\u03b1/4+1/2\n)\nwith high probability. Thus, we have with probability 1\u2212 \u03b4,\nE \u2016zn\u20162 \u2264 (\u2016z\u03030\u20162\nn\u00b5c +\nh2(n)\nn\u2212\u03b1/4+1/2 +\nh1(n)\nn\u03b1\u22121/2\n)\n.\nFor the bandit application, we need to bound the distance between the iterate \u03b8n and the unknown parameter \u03b8\u2217 in the An norm, where An = \u2211n\u22121 i=1 xix T\ni + n\u03bbnId. We provide this bound in Theorem 4 below. It is possible to migrate to l2 norm from this result and we skip this owing to space constraints.\nTheorem 4. Recall zn := \u03b8n\u2212 \u03b8\u2217. Under (A1)-(A2), with \u03b80 = 0 and step-sizes \u03b3n = c\nn\u03b1 with c >\n1\n2\u00b5 and\nregularisation parameter \u03bbn = \u00b5/n1\u2212\u03b1, with \u03b1 \u2208 (1/2, 1), we have for any \u03b4 > 0\nP ( \u2016\u03b8n \u2212 \u03b8\u2217\u2016An,2 \u2264 \u221a 2n\u03ban + \u221a \u03b2n + n \u03b1/4 ) \u2265 1\u2212 \u03b4,\nwhere\n\u03ban =\n\u221a\nK\u00b5,c n2\u03b1\u22121 log 1 \u03b4 +\n(\nC\u03b8\u2217\u221a n +\n\u221a\n\u03b2n n + h2(n) n\u2212\u03b1/4+1/2 + h1(n) n\u03b1\u22121/2\n)\n,\nC\u03b8\u2217 bounds \u2016\u03b8\u2217\u20162, h2(n) = 2( \u221a \u03b2nn \u2212\u03b1/4 + 1) and \u03b2n = max\n(\n128d log n log n2\n\u03b4 ,\n( 8\n3 log\nn2\n\u03b4\n)2 )\n.\nThe proof of this theorem is a combination of a simple triangle inequality and bounds on \u2225 \u2225 \u2225\u03b8n \u2212 \u03b8\u0302n \u2225 \u2225 \u2225 An,2\nand \u2225 \u2225 \u2225\u03b8\u0302n \u2212 \u03b8\u2217 \u2225 \u2225 \u2225 An,2 provided by Lemmas 5 and 6 below. The detailed proof is provided in Appendix A.3.\nLemma 5. Under the conditions of Theorem 4, we have\nP (\u2225 \u2225 \u2225\u03b8n \u2212 \u03b8\u0302n \u2225 \u2225 \u2225 An,2 \u2264 \u221a 2n\u03ban ) \u2265 1\u2212 \u03b4.\nLemma 6. Under the conditions of Theorem 4, we have\nP (\u2225 \u2225 \u2225\u03b8\u0302n \u2212 \u03b8\u2217 \u2225 \u2225 \u2225 An,2 \u2264 \u221a \u03b2n + n \u03b1/4 ) \u2265 1\u2212 \u03b4."}, {"heading": "3 Linear Bandits with Strongly Convex Arms", "text": "In a linear bandit problem the set D \u2282 Rd is interpreted as an action set from which the higher level algorithm chooses an action xn at each time instant. The observations yn = ln(xn) are interpreted as loses satisfying E[ ln(xn)| xn] = xTn\u03b8\u2217, where \u03b8\u2217 is an unknown parameter. The aim is to minimise the expected cumulative regret: Rn = \u2211n i=1 x T i \u03b8 \u2217 \u2212minx\u2208D xT\u03b8\u2217 .\nIn this section, we assume that D is a strongly convex set (see (A3\u2019) below) and the \u201dbest action\u201d function, denoted by G(\u03b8), is assumed to be smooth in the unknown parameter \u03b8 that governs the losses of the bandit algorithm (see (A4) below).\nPhased Exploration and Greedy Exploitation (PEGE) of [7] is a well-known algorithm in this setting. PEGE consists of exploration phases and exploitation phases: during each exploration phase the algorithm samples once each element of a basis for D and then computes a least squares estimate of \u03b8\u2217 using all the data gathered during exploration phases; the exploration phases are separated by exploitation phases of growing length during which the algorithm acts greedily according to the most recently calculated estimate for \u03b8\u2217.\nSince strong convexity in the regression problem is artificially guaranteed by the algorithm we propose a new algorithm which replaces the calculation of the least squares estimate with the Random Online algorithm from Section 2.1 (see Algorithm 3 below). Whereas, after m exploration phases, PEGE has incurred a complexity of O(md3), our algorithm has incurred an improved complexity of only O(md3). Further, the computational gains come at only logarithmic cost in the order of the regret.\nAlgorithm 1 PEGE with Online GD Input and Initialisation:\nGet a basis {b1, . . . , bd} \u2208 D for Rd. Set c = 4d3\u03bbmin(\u2211di=1 bibTi ) and \u03b80 = 0.\nfor m = 1 to \u221e do Exploration Phase for n = (m\u2212 1)d to md\u2212 1 do\nChoose arm xn = bn mod md and observe yn. Update \u03b8 as follows: \u03b8n = \u03b8n\u22121 + cn((yj \u2212 \u03b8Tn\u22121xj)xj), where j \u223c U(1, . . . , n).\nend for Exploitation Phase Find x = G(\u03b8md) := argminx\u2208D{\u03b8Tmdx}. Choose arm x m times consecutively.\nend for"}, {"heading": "3.1 Analysis", "text": "We require the following extra assumptions from [7]:\n(A3\u2019) A basis {b1, . . . , bd} \u2208 D for Rd is made known to the algorithm.\n(A4) The function G : \u03b8 \u2192 argminx\u2208D{\u03b8Tx} is J-Lipschitz. The assumption (A4) is satisfied, for example, when D is the unit sphere. However it is not satisfied when D is discrete. We provide a slightly modified version of Theorem 3.1 of [7]: Theorem 7. Under the assumptions (A1), (A2), (A3\u2019), and (A4), the cumulative regret of PEGE with Online GD satisfies\nRn \u2264 C1(\u2016\u03b8\u2217\u20162 + \u2016\u03b8\u2217\u2016 \u22121 2 )h3(n)dn 1/2,\nwhere C1 is a constant depending on \u03bbmin( \u2211d i=1 bib T i ) and J , and h3 hides log factors.\nProof. Note that for all n > d,\n\u03bbmin(A\u0304n) \u2265 \u03bbmin ( (n mod d) \u2211d i=1 bib T i\n[(n mod d) + 1]d\n)\n\u2265 \u03bbmin\n( \u2211d\ni=1 bib T i\n)\n2d .\nSo from equation (3), taking \u03b3n = 4d3n\u03bbmin( \u2211d i=1 bib T i ) we have for any n \u2265 d\nE \u2016\u03b8n \u2212 \u03b8\u2217\u201622 \u2264 (\u2016z0\u20162 + h1(n))2/n. (6) Now to complete the proof we only need to reprove Lemma 3.6 of [7]:\nLemma 8. For all n \u2265 d, E \u2016\u03b8\u2217(G(\u03b8\u2217)\u2212G(\u03b8md))\u20162 \u2264 h3(n) m\u2016\u03b8\u2217\u2016\n2\nwhere h3(n) hides log factors.\nProof. Note that\n\u2016\u03b8\u2217(G(\u03b8\u2217)\u2212G(\u03b8md))\u20162 = \u2016(\u03b8\u2217 \u2212 \u03b8md)TG(\u03b8\u2217) + (G(\u03b8\u2217)\u2212G(\u03b8md))T\u03b8md + (\u03b8md \u2212 \u03b8\u2217)G(\u03b8md)\u20162\n\u2264 \u2016(\u03b8\u2217 \u2212 \u03b8md)T(G(\u03b8\u2217)\u2212G(\u03b8md))\u20162 = \u2225 \u2225 \u2225 \u2225 G ( \u03b8\u2217\n\u2016\u03b8\u2217\u20162\n) \u2212G (\n\u03b8md \u2016\u03b8md\u20162 )\u2225 \u2225 \u2225 \u2225 2 \u2264 2J \u2016\u03b8 \u2217 \u2212 \u03b8md\u201622 \u2016\u03b8\u2217\u20162 ,\nwhere the second equality follows from the fact that G(\u03b8) = G(x\u03b8) for all x > 0, and for the second inequality we have used (A4) and Lemma 3.5 of [7]. The lemma follows from (6).\nThe rest of the proof follows the scheme of the proof of Theorem 3.1 of [7]."}, {"heading": "4 Linear Bandits with Non-Strongly Convex Arms", "text": "The setting here is similar to that of the previous section, except that assumptions (A3\u2019) and (A4) do not hold. In other words, the arms are not assumed to belong to a strongly convex subset of Rd - a property that is not known to hold in many practical settings such as news recommendation engines where the arms are discrete. The well-known confidence ball algorithm of [2] works by constructing a least squares estimate \u03b8\u0302 using {(xi, yi)}ni=1 around \u03b8\u2217 and using this estimate to pick an arm greedily, i.e., argminx\u2208D minv\u2208B2n{v\nTx}. The regret Rn with this algorithm was shown to be of the order O( \u221a dn lnn) in [2].\nWe propose an enhancement to the confidence ball algorithm, where at each step we use the regularized version of the random online algorithm to shadow the empirical estimator (which is the solution to a least squares problem). This new algorithm (see Algorithm 4 below for details) has a complexity O(nd), where d is the dimension of the arm space, D = Rd. A vanilla confidence ball algorithm has a complexity O(nd2) per time step, and so our proposed enhancement has significantly improved complexity. On the other hand, the computational gains come at the cost of a loss of n1/5 in the regret Rn.\nAlgorithm 2 Confidence Ball with Online GD Input and Initialisation:\nChoose \u00b5 and c so that \u00b5c > 1/2, \u03b1 \u2208 (1/2, 1) and set \u03b80 = 0. for n = 1 to \u221e do\nFind xn = argminx\u2208D minv\u2208B2n v Tx, where B2n =\n{ v : \u2016v \u2212 \u03b8t\u2016An,2 \u2264 \u221a 2n\u03ban + \u221a \u03b2n + n \u03b1/4 } .\nChoose arm xt and observe yt. Update \u03b8n: \u03b8n = \u03b8n\u22121 + cn\u2212\u03b1((yin \u2212 \u03b8Tn\u22121xin)xin \u2212 \u00b5n\u03b1\u22121\u03b8n\u22121) where in \u223c U(1, . . . , n).\nend for"}, {"heading": "4.1 Analysis", "text": "We make the following extra assumption: (A4\u2019) An upper bound, C\u03b8\u2217 , for \u2016\u03b8\u2217\u20162 is known. Choose the step-sizes to be \u03b3n = cn\u2212\u03b1 with \u00b5c > 1/2, and adaptive regularisation parameters \u03bbn = \u00b5/n1\u2212\u03b1, where \u03b1 \u2208 (1/2, 1). Then using Theorem 4 we can define a confidence region,\nB2n = { v : \u2016v \u2212 \u03b8n\u2016An,2 \u2264 \u03b7n } ,\nwhere \u03b7n = \u221a 2n\u03ban + \u221a \u03b2n + n \u03b1/4. In our setting, Theorem 4 serves as an analogue to Theorem 5 of [2].\nTheorem 9. Under (A1), (A2), and (A4\u2019), with probability 1\u2212 \u03b4, we have Rn \u2264 (n4d\u03b7n lnn) 1 2 .\nProof. We break the proof into three steps:\nStep 1: Bound the instantaneous regret Let An be defined as in Section 2.2. First note that, for all \u03b8 \u2208 B2n,\n|(\u03b8 \u2212 \u03b8\u0302n)Tx| \u2264 \u2225 \u2225 \u2225 \u2225 ( A \u2212 1 2 n (\u03b8 \u2212 \u03b8\u0302n) ) T \u2225 \u2225 \u2225 \u2225 2 \u2225 \u2225 \u2225 \u2225 A \u2212 1 2 n x \u2225 \u2225 \u2225 \u2225 2 \u2264 \u03b7n \u221a xTA\u22121n x\nwhere we have used Cauchy-Schwarz for the first inequality, and the definition of B2n, for the second. Define wn := (x T nA \u22121 n xn) 1/2. Then we have\nrn := x T n\u03b8 \u2217 \u2212min x\u2208C xT\u03b8\u2217 \u2264 xTn(\u03b8\u2217 \u2212 \u03b8\u0303) + xTn(\u03b8\u0302n \u2212 \u03b8\u0303) \u2264 2\u03b7nwn where \u03b8\u0303 := arg min \u03b8\u2208B2n xTn\u03b8.\nStep2: Bound the widths For this part we first note that det(An+1) = \u220ft\n\u03c4=1(1 + n(\u03bbn+1 \u2212 \u03bbn) + w2n): We can show this from\ndet(An+1) = det(An) det((1 + n(\u03bbn+1 \u2212 \u03bbn))I +A \u2212 1 2 n xn(A \u2212 1 2 n xn) T)\n= det(An) det((1 + n(\u03bbn+1 \u2212 \u03bbn))I + vnvTn),\nwhere vn := A \u2212 1 2 n xn. Now vn is an eigenvector of (1 + n(\u03bbn+1 \u2212 \u03bbn))I + vnvTn, and its corresponding eigenvalue is 1 + n(\u03bbn+1 \u2212 \u03bbn) + w2n. Moreover all the other eigenvalues of this matrix are 1, since the matrix has rank one. Furthermore, trace(An) = d\u03bbn + \u2211n k=1 \u2016xk\u201622 \u2264 2dn. Using this as a constraint on the eigenvalues of An we can derive that det(An) \u2264 n2d. Hence, using that for all 0 \u2264 y \u2264 1, ln(1 + y) \u2265 y/2, we have that n\u2211\nk=1\nw2k \u2227 1 \u2264 n\u2211\nk=1\n2 ln(1 + w2k) \u2264 n\u2211\nk=1\n2 ln(1 + n(\u03bbn+1 \u2212 \u03bbn) + w2k) = 2 ln(det(An+1)) \u2264 4d ln n.\nStep 3: Bound the regret From the above we know that when \u03b8\u2217 \u2208 B2n, for all n,\nRT \u2264 ( T T\u2211\nn=1\nr2n\n) 1 2 \u2264 ( T T\u2211\nn=1\n2\u03b72n(w 2 n \u2227 1)\n) 1 2\n\u2264 ( T4d\u03b72T lnT ) 1 2 .\nApplying Theorem 4 gives the result.\nCorollary 10. Under the conditions of Theorem 9, setting \u03b3n = c/n\u03b1 and \u03bbn = \u00b5/n1\u2212\u03b1, where \u03b1 = 4/5, the regret RT \u2264 2d \u221a lnT T 1/2+1/5.\nProof. Follows from the analysis in Section 2.2 and Theorem 9."}, {"heading": "5 Conclusions", "text": "We proposed two SGD schemes with randomisation for the problem of reducing complexity in least squares regression problems where the samples do not come from a probability distribution, but are instead given to us by a higher level learning algorithm. In particular, when the higher level algorithm can guarantee strong convexity in the data, we proposed a non-regularised scheme, and otherwise we proposed an adaptively regularised scheme. We provided error bounds both in expectation and in high probability for the two schemes. To demonstrate the applicability of these results we applied both schemes to the linear bandit problem, the non-regularised scheme in the PEGE algorithm, and the regularised scheme in the ConfidenceBall algorithm. We found that since strong convexity of the data is guaranteed by the PEGE algorithm we obtained a speed up of O(d) at a cost of only logarithmic factors in the regret. However for the ConfidenceBall algorithm, although we achieved a speed up of O(d) here as well, we lost O(n1/5) in the regret.\nThe difference between the two regret performances appears to be a result of adaptive regularisation. PEGE is only applicable when the action set of the linear bandit is strongly convex, which allows the algorithm to guarantee strong convexity in the data set. This is a strong condition, making the learning problem an easier one to solve. ConfidenceBall is applicable in any compact action set, but cannot guarantee strong convexity in the data as a result. One solution is to regularise the problem, however this introduces a drift error into the regression problem that is difficult to control. Whether this gap in the regret bound for linear bandits with compact action sets can be eliminated remains an open question for future research."}, {"heading": "A Appendix", "text": ""}, {"heading": "A.1 Random Online", "text": ""}, {"heading": "Proof of Theorem 1", "text": "We use the proof technique from [4] in arriving at the high-probability bounds.\nStep 1 Let Hi := {(xj , yj)}ij=1 \u222a {\u03b80}. We decompose \u2016zn\u201622 \u2212 E \u2016zn\u2016 2 2 into a sum of martingale differences as follows:\n\u2016zn\u20162 \u2212 E \u2016zn\u20162 = n\u2211\ni=1\nE[\u2016zn\u20162 |Hi ]\u2212 E[\u2016zn\u20162 |Hi\u22121 ]\n=\nn\u2211\ni=1\nE[\u2016zn\u20162 |\u03b8i ]\u2212 E[E(\u2016zn\u20162 |\u03b8i ) |Hi\u22121 ] = n\u2211\ni=1\nDi, (7)\nwhere Di \u25b3 = gi \u2212 E[gi |Hi\u22121 ] and gi =\nn\u2211 i=1 E[\u2016zn\u20162 |\u03b8i ].\nStep 2 We establish that the functions gi are Lipschitz continuous with constants Li.\nProposition 1. The functions gi are Lipschitz continuous with constants\nLi := \u03b3 1/2 i\nn\u22121\u220f j=i (1 + \u03b32j+1 \u2212 2\u00b5\u03b3j+1)1/2.\nProof. Denote fn(\u03b8) := 12 (\u03bein \u2212 (\u03b8 \u2212 \u03b8\u2217)Txin)2. The update (1) can be re-written as\n\u03b8n = \u03b8n\u22121 \u2212 \u03b3n(F \u2032n(\u03b8n\u22121)\u2212\u2206Mn),\nwhere Fn(\u03b8) := Ein [fn(\u03b8) | Hn] and \u2206Mn+1 is the associated martingale difference sequence defined as \u2206Mn+1(\u03b8) = F \u2032 n(\u03b8)\u2212 f \u2032n(\u03b8).\nLet \u0398ij(\u03b8) denote the mapping that returns the value of the iterate updated according to (1) at instant j, \u03b8j , given that \u03b8i = \u03b8. Then, we have\n\u2225 \u2225\u0398ij+1(\u03b8) \u2212\u0398ij+1(\u03b8\u2032) \u2225 \u2225 2 2 = \u2225 \u2225\u0398ij(\u03b8)\u2212\u0398ij(\u03b8\u2032)\u2212 \u03b3j+1[f \u2032j+1(\u0398ij(\u03b8))\u2212 f \u2032j+1(\u0398ij(\u03b8\u2032))] \u2225 \u2225 2 2\n\u2264(1 + \u03b32j+1) \u2225 \u2225\u0398ij(\u03b8)\u2212\u0398ij(\u03b8\u2032) \u2225 \u2225 2\n2\n\u2212 2\u03b3j+1\u3008\u0398ij(\u03b8)\u2212\u0398ij(\u03b8\u2032), F \u2032n(\u0398ij(\u03b8))\u2212 F \u2032n(\u0398ij(\u03b8\u2032))\u3009 + 2\u03b3j+1\u3008\u0398ij(\u03b8)\u2212\u0398ij(\u03b8\u2032),\u2206Mj+1(\u03b8)\u2212\u2206Mj+1(\u03b8\u2032)\u3009,\nThe inequality above follows from the Lipschitz continuity of f \u2032j in the noise, as shown below:\n\u2200\u03b8, \u2225 \u2225(\u03bej \u2212 (\u03b8 \u2212 \u03b8\u2217)Txj)xj)\u2212 (\u03be\u2032j \u2212 (\u03b8 \u2212 \u03b8\u2217)Txj)xj) \u2225 \u2225 2 \u2264 \u2225 \u2225(\u03bej \u2212 \u03be\u2032j) \u2225 \u2225 2 ,\nwhere the inequality follows from (A1). As a consequence of (A3), we obtain F \u2032\u2032n (\u03b8) \u2265 \u00b5I (or F is \u00b5strongly convex), and hence\n\u2225 \u2225\u0398ij+1(\u03b8)\u2212\u0398ij+1(\u03b8\u2032) \u2225 \u2225 2 2 \u2264(1 + \u03b32j+1 \u2212 2\u03b3j+1\u00b5) \u2225 \u2225\u0398ij(\u03b8)\u2212\u0398ij(\u03b8\u2032) \u2225 \u2225 2 2\n+ 2\u03b3j+1\u3008\u0398ij(\u03b8)\u2212\u0398ij(\u03b8\u2032),\u2206Mj+1(\u03b8)\u2212\u2206Mj+1(\u03b8\u2032)\u3009,\nA repeated application of this inequality, followed by taking expectations yields the following\nE [\u2225 \u2225\u0398in(\u03b8)\u2212\u0398in(\u03b8\u2032) \u2225 \u2225 2\n2\n]\n\u2264 \u2225 \u2225\u03b8 \u2212 \u03b8\u2032 \u2225 \u22252\n2\nn\u22121\u220f\nj=i\n(1 + \u03b32j+1 \u2212 2\u03b3j+1\u00b5).\nFinally putting all this together we have\n\u2016E [\u2016\u03b8n \u2212 \u03b8\u2217\u20162 |\u03b8i\u22121, \u03beii = \u03be ] \u2212E [ \u2016\u03b8n \u2212 \u03b8\u2217\u20162 \u2223 \u2223\u03b8i\u22121, \u03beii = \u03be \u2032 ]\u2225 \u2225 2\n\u2264 E [\u2225 \u2225\u0398in (\u03b8)\u2212\u0398in ( \u03b8\u2032 )\u2225 \u2225 2 ] \u2264\n\n\u03b3i\nn\u22121\u220f\nj=i\n(1 + \u03b32j+1 \u2212 2\u03b3j+1\u00b5) 1 2\n\n \u2225 \u2225\u03be \u2212 \u03be\u2032 \u2225 \u2225 2 = Li \u2225 \u2225\u03be \u2212 \u03be\u2032 \u2225 \u2225 2 .\nStep 3 The last step of the proof is to invoke a concentration bound for sum of martingale differences Di.\nP (\u2016zn\u20162 \u2212 E \u2016zn\u20162 \u2265 \u01eb) =P ( n\u2211\ni=1\nDi \u2265 \u01eb ) \u2264 exp(\u2212\u03bb\u01eb)E ( exp ( \u03bb n\u2211\ni=1\nDi\n))\n= exp(\u2212\u03bb\u01eb)E ( exp ( \u03bb n\u22121\u2211\ni=1\nDi\n)\nE\n( exp(\u03bbDn |Hn\u22121 ) ))\nThe first equality above follows from (7), while the inequality follows from Markov inequality. Since \u03bei are bounded by (A2), we have the following property that holds for every 1-Lipschitz function g, we have\nE (exp(\u03bbg(\u03be1))) \u2264 exp ( \u03bb2\n2\n)\n.\nNoting that gi is Lipschitz with constant Li by Proposition 1, we apply the above inequality to obtain\nE (exp(\u03bbDn |Hn\u22121 )) \u2264 exp ( \u03bb2L2n 2 ) ,\nand so\nP (\u2016zn\u20162 \u2212 E \u2016zn\u20162 \u2265 \u01eb) \u2264 exp(\u2212\u03bb\u01eb) exp ( \u03b1\u03bb2\n2\nn\u2211\ni=1\nL2i\n)\nThe claim follows by optimizing over \u03bb in the above."}, {"heading": "Proof of Theorem 2", "text": "We define F\u0303n(\u03b8) \u25b3 = E\u03be(Fn(\u03b8)) = E\u03ben,in [f \u2032 n(\u03b8) | Hn], and \u2206M\u0303n+1(\u03b8) = F\u0303 \u2032n(\u03b8) \u2212 fn(\u03b8). First we extract a martingale from the sequence (zn)n\u22651, and recover a recursive procedure for zn involving the martingale differences \u2206M\u0303n:\nzn =zn\u22121 \u2212 \u03b3n ( F\u0303 \u2032n(\u03b8n\u22121)\u2212\u2206M\u0303n ) = zn\u22121 \u2212 \u03b3n ( A\u0304nzn \u2212\u2206M\u0303n )\n= ( 1\u2212 \u03b3nA\u0304n ) zn\u22121 + \u03b3n\u2206M\u0303n =\nn\u220f\nk=1\n( I \u2212 \u03b3kA\u0304k ) z0 \u2212\nn\u2211\nk=1\n\u03b3k\n\n\nn\u220f\nj=k+1\n( I \u2212 \u03b3jA\u0304j )\n\n\u2206M\u0303k,\nBy Jensen\u2019s inequality\nE \u2225 \u2225 \u2225 \u2225 \u2225 \u03a0\u0303nz0 + n\u2211\nk=1\n\u03b3k\u03a0\u0303n\u03a0\u0303 \u22121 k \u2206M\u0303k \u2225 \u2225 \u2225 \u2225 \u2225 2 \u2264 ( \u2225 \u2225 \u2225\u03a0\u0303nz0 \u2225 \u2225 \u2225 2 2 + n\u2211 k=1 \u03b32kE \u2225 \u2225 \u2225\u03a0\u0303n\u03a0\u0303 \u22121 k \u2206M\u0303k \u2225 \u2225 \u2225 2 2 )1/2\n(8)\nwhere \u03a0\u0303n := \u220fn\nk=1\n( I \u2212 \u03b3kA\u0304k ) . Notice that A\u0304n \u2212 \u00b5I is positive definite by (A3) and hence\n\u2225 \u2225 \u2225\u03a0\u0303n\u03a0\u0303 \u22121 k \u2225 \u2225 \u2225 2 = \u2225 \u2225 \u2225 \u2225 \u2225 \u2225 n\u220f\nj=k+1\n( I \u2212 \u03b3jA\u0304j ) \u2225 \u2225 \u2225 \u2225 \u2225 \u2225 2 \u2264 n\u220f j=k+1 \u2225 \u2225(1\u2212 \u03b3j\u00b5)I \u2212 \u03b3j(A\u0304j \u2212 \u00b5I) \u2225 \u2225 2\n\u2264 n\u220f\nj=k+1\n\u2016(1\u2212 \u03b3j\u00b5)I\u20162 \u2264 n\u220f\nj=k+1\n(1\u2212 \u03b3j\u00b5) \u2264 exp (\u2212\u00b5(\u0393n \u2212 \u0393k)) , (9)\nFinally we need to bound square the martingale difference:\nE[ \u2225 \u2225 \u2225\u2206M\u0303n \u2225 \u2225 \u2225 2\n2 ] = E\u03be,it\u3008f \u2032it(\u03b8t\u22121), f \u2032it(\u03b8t\u22121)\u3009 \u2212 \u3008F\u0303 \u2032n(\u03b8t\u22121), F\u0303 \u2032n(\u03b8t\u22121)\u3009\nUsing (A1) and (A2), a calculation shows that\nE\u03be,it\u3008f \u2032it(\u03b8t\u22121), f \u2032it(\u03b8t\u22121)\u3009 \u2264\u03c32\u03be + \u2016zt\u2016 2 2 & \u3008F\u0303 \u2032n(\u03b8t\u22121), F\u0303 \u2032n(\u03b8t\u22121)\u3009 \u2264 \u2016zt\u2016 2 2\nwhere \u03c32\u03be := V ar(\u03be) < \u221e (\u03be is distributed according to the noise distribution). Now\n\u2016zt\u20162 = \u2225 \u2225 \u2225 \u2225 \u2225 \u2225 [ t\u220f\nk=1\n(I \u2212 \u03b3kxikxTk) ] z0 + t\u2211\nk=1\n\u03b3k\n\n\nt\u220f\nj=k\n(I \u2212 \u03b3jxijxTj )\n\n \u03bekxk \u2225 \u2225 \u2225 \u2225 \u2225 \u2225 2\n\u2264\u2016z0\u20162 + t\u2211\nk=1\n\u03b3k \u2264 \u2016z0\u20162 + ln t.\nand so E[ \u2225 \u2225 \u2225\u2206M\u0303t \u2225 \u2225 \u2225 2\n2 ] \u2264 h(t) where h(t) = 2\n[ \u03c32\u03be + 2(\u2016z0\u20162 + ln t)2 ] .\nWe conclude that\nE \u2016zn\u20162 \u2264 ( \u2016z0\u201622 exp(\u22122\u00b5\u0393n) + n\u2211\nk=1\nh(k)\u03b32k exp(\u22122\u00b5(\u0393n \u2212 \u0393k)) )1/2 ."}, {"heading": "A.2 Regularized Random Online", "text": "The proof of the high probability bound for the (adaptive) regularized setting follows in a similar manner as the proof of Theorem 1 and uses the fact that each F \u2032n is \u03bbn-strongly convex. On the other hand, the proof of the bound in expectation in this setting is more complicated than that of Theorem 1 owing to the adaptive regularization parameters \u03bbn. We first prove that the iterate \u03b8n is close to the corresponding regularized solution \u03b8\u0303n at instant n. Let zn = \u03b8n \u2212 \u03b8\u0303n. Then,\nzn =\u03b8n \u2212 \u03b8\u0303n\u22121 + \u03b8\u0303n\u22121 \u2212 \u03b8\u0303n =zn\u22121 \u2212 \u03b3n ( F\u0303 \u2032n(\u03b8n\u22121)\u2212\u2206M\u0303n ) + (\u03b8\u0303n\u22121 \u2212 \u03b8\u0303n)\n=zn\u22121 \u2212 \u03b3n ( (A\u0304n + \u03bbnI)zn\u22121 \u2212\u2206M\u0303n ) + (\u03b8\u0303n\u22121 \u2212 \u03b8\u0303n) = ( 1\u2212 \u03b3n(A\u0304n + \u03bbnI) ) zn\u22121 + \u03b3n\u2206M\u0303n + (\u03b8\u0303n\u22121 \u2212 \u03b8\u0303n)\n=\nn\u220f\nk=1\n( I \u2212 \u03b3k(A\u0304k + \u03bbkI) ) z0 \u2212\nn\u2211\nk=1\n\n\nn\u220f\nj=k+1\n( I \u2212 \u03b3j(A\u0304j + \u03bbkI) )\n\n (\u03b3k\u2206M\u0303k + (\u03b8\u0303k \u2212 \u03b8\u0303k\u22121))\n=\u03a0\u0303nz0 \u2212 n\u2211\nk=1\n\u03a0\u0303n\u03a0\u0303 \u22121 k (\u03b8\u0303k \u2212 \u03b8\u0303k\u22121) +\nn\u2211\nk=1\n\u03b3k\u03a0\u0303n\u03a0\u0303 \u22121 k \u2206M\u0303k,\nwhere \u03a0\u0303n := \u220fn\nk=1\n( I \u2212 \u03b3k(A\u0304k + \u03bbkI) ) . By Jensen\u2019s inequality, we obtain\nE \u2016zn\u20162 \u2264 \u2225 \u2225 \u2225 \u2225 \u2225 \u03a0\u0303nz0 + n\u2211\nk=1\n\u03a0\u0303n\u03a0\u0303 \u22121 k (\u03b8\u0303k+1 \u2212 \u03b8\u0303k) \u2225 \u2225 \u2225 \u2225 \u2225 2 + ( n\u2211 k=1 \u03b32kE \u2225 \u2225 \u2225\u03a0\u0303n\u03a0\u0303 \u22121 k \u2206M\u0303k \u2225 \u2225 \u2225 2 2 )1/2\n(10)\nUsing the fact that A\u0304n \u2212 \u03bbnI is positive definite, we obtain\n\u2225 \u2225 \u2225\u03a0\u0303n\u03a0\u0303 \u22121 k \u2225 \u2225 \u2225 2 = \u2225 \u2225 \u2225 \u2225 \u2225 \u2225 n\u220f\nj=k+1\n( I \u2212 \u03b3j(A\u0304j + \u03bbjI) ) \u2225 \u2225 \u2225 \u2225 \u2225 \u2225 2 \u2264 n\u220f j=k+1 \u2016(1\u2212 \u03b3j\u03bbj)I\u20162 \u2264 exp ( \u2212(\u0393\u2032n \u2212 \u0393\u2032k) ) , (11)\nWe now bound each of the terms in (10) as follows: First term It is easy to see that \u2225 \u2225 \u2225\u03a0\u0303nz0\n\u2225 \u2225 \u2225 2 \u2264 \u2016z0\u20162 exp(\u2212\u0393\u2032n).\nSecond term Using a discrete integration by parts, we obtain\nn\u2211\nk=1\n\u03a0\u0303n\u03a0\u0303 \u22121 k (\u03b8\u0303k \u2212 \u03b8\u0303k\u22121) = (\u03b8\u0303n \u2212 \u03b8\u03030) +\nn\u2211\nk=1\n\u03b3k\u03bbk(\u03b8\u0303k \u2212 \u03b8\u03030)\u03a0\u0303n\u03a0\u0303\u22121k , (12)\nwhere \u03b8\u03030 is chosen arbitrarily. Thus, \u2225 \u2225 \u2225 \u2225 \u2225 n\u2211\nk=1\n\u03a0\u0303n\u03a0\u0303 \u22121 k (\u03b8\u0303k \u2212 \u03b8\u0303k\u22121) \u2225 \u2225 \u2225 \u2225 \u2225 2 \u2264 \u2225 \u2225 \u2225(\u03b8\u0303n \u2212 \u03b8\u03030) \u2225 \u2225 \u2225 2 + n\u2211 k=1 \u03b3k\u03bbk \u2225 \u2225 \u2225\u03b8\u0303k \u2212 \u03b8\u03030 \u2225 \u2225 \u2225 2 exp(\u2212(\u0393\u2032n \u2212 \u0393\u2032k)), (13)\nLast term The martingale difference (last term in (10)) is bounded as below:\nE[ \u2225 \u2225 \u2225\u2206M\u0303n \u2225 \u2225 \u2225 2\n2 ] \u2264 2\n( E\u3008f \u2032in(\u03b8n\u22121), f \u2032in(\u03b8n\u22121)\u3009+ E\u3008F\u0303 \u2032n(\u03b8n\u22121), F\u0303 \u2032n(\u03b8n\u22121)\u3009 )\nUsing (A1) and (A2), a simple calculation shows that\nE\u3008f \u2032in(\u03b8n\u22121), f \u2032in(\u03b8n\u22121)\u3009 \u2264\u03c32\u03be + 2(E \u2016zn\u2016 2 2 + \u03bb 2 n \u2016\u03b8\u2217\u201622 + 2\u03bbn \u2016\u03b8\u2217\u20162 E \u2016zn\u20162)\n& E\u3008F\u0303 \u2032n(\u03b8n\u22121), F\u0303 \u2032n(\u03b8n\u22121)\u3009 \u22642(E \u2016zn\u201622 + \u03bb2n \u2016\u03b8\u2217\u2016 2 2 + 2\u03bbn \u2016\u03b8\u2217\u20162 E \u2016zn\u20162)\nwhere \u03c32\u03be := V ar(\u03be) < \u221e (\u03be is distributed according to the noise distribution). Now\nE \u2016zn\u20162 =E \u2225 \u2225 \u2225 \u2225 \u2225 [ n\u220f\nk=1\n(I \u2212 \u03b3k(xikxTik + \u03bbkI)) ] z0\n+ n\u2211\nk=1\n\u03b3k\n\n\nn\u220f\nj=k+1\n(I \u2212 \u03b3j(xijxTij + \u03bbjI))\n\n (\u03bekxik + \u03bbk\u03b8 \u2217) \u2225 \u2225 \u2225 \u2225 \u2225 \u2225 2\n\u2264\u2016z0\u20162 + ( n\u2211\nk=1\n\u03b32k exp(\u22122(\u0393\u2032n \u2212 \u0393\u2032k)) ) 1 2 \u03c3\u03be + \u0393 \u2032 n \u2016\u03b8\u2217\u20162 =: g(n).\nand so E[ \u2225 \u2225 \u2225\u2206M\u0303n \u2225 \u2225 \u2225 2\n2 ] \u2264 h(n) where h(n) = 2\u03c32\u03be + 8\n( (g(n))2 + \u03bb2n \u2016\u03b8\u2217\u201622 + 2\u03bbn \u2016\u03b8\u2217\u20162 g(n) )2 .\nPutting it all together, (10) simplifies to the following form:\nE \u2016zn\u20162 \u2264\u2016z0\u20162 exp(\u2212\u0393\u2032n) + \u2225 \u2225 \u2225(\u03b8\u0303n \u2212 \u03b8\u03030) \u2225 \u2225 \u2225 2 + n\u2211\nk=1\n\u03b3k\u03bbk \u2225 \u2225 \u2225\u03b8\u0303k \u2212 \u03b8\u03030 \u2225 \u2225 \u2225 2 exp(\u2212(\u0393\u2032n \u2212 \u0393\u2032k))\n+\n( n\u2211\nk=1\nh(k)\u03b32k exp(\u22122(\u0393\u2032n \u2212 \u0393\u2032k)) )1/2 ."}, {"heading": "A.3 Proof of Theorem 4", "text": ""}, {"heading": "Proof of Lemma 5", "text": "Proof. Using the analysis from Section 2.1 for the choice of step-sizes \u03b3n = c\nn\u03b1 with c >\n1\n2\u00b5 and \u03bbn =\n\u00b5/n1\u2212\u03b1, with \u03b1 \u2208 (1/2, 1), we obtain the following bound from (2.2)\nP (\u2225 \u2225 \u2225\u03b8n \u2212 \u03b8\u0303n \u2225 \u2225 \u2225 2 \u2212 E \u2225 \u2225 \u2225\u03b8n \u2212 \u03b8\u0303n \u2225 \u2225 \u2225 2 \u2265 \u01eb ) \u2264 exp ( \u2212\u01eb 2n2\u03b1\u22121\nK\u00b5,c\n)\n\u21d4P ( \u2225 \u2225 \u2225\u03b8n \u2212 \u03b8\u0303n\n\u2225 \u2225 \u2225 2 \u2212 E \u2225 \u2225 \u2225\u03b8n \u2212 \u03b8\u0303n \u2225 \u2225 \u2225 2 \u2264\n\u221a\nK\u00b5,c n2\u03b1\u22121 log 1 \u03b4\n)\n\u2265 1\u2212 \u03b4\nLetting \u03b8\u03030 = \u03b8\u2217, the drift error (second term in the bound in expectation from Theorem 3) can be simplified as follows: With probability 1\u2212 \u03b4, we have\n\u2225 \u2225 \u2225(\u03b8\u0303n \u2212 \u03b8\u2217) \u2225 \u2225 \u2225 2 +\nn\u2211\nk=1\n\u03b3k\u03bbk \u2225 \u2225 \u2225\u03b8\u0303k \u2212 \u03b8\u2217 \u2225 \u2225 \u2225 2 exp(\u2212(\u0393\u2032n \u2212 \u0393\u2032k))\n\u2264 \u221a\n\u03b2n n\n+ n\u03b1/4\u22121/2 + n\u2212\u00b5c n\u2211\nk=1\n1 k (\n\u221a\n\u03b2k k + k\u03b1/4\u22121/2)k\u00b5c \u2264 h1(n)n\u03b1/4\u22121/2\nwhere the first inequality follows from Lemma 6 and the following change of norm inequality \u2016zn\u20162An,2 \u2264 2n \u2016zn\u201622. The latter is true because \u2016zn\u2016 2 An,2 = zTnAnzn = un diag(An)un, where An is factorized as P TnAnPn and un = Pnzn. Thus, \u2016zn\u20162An,2 \u2264 \u03bbmax \u2016un\u2016 2 2 = \u03bbmax \u2016zn\u2016 2 2, where \u03bbmax is the largest eigen value of An. By the definition of An, it is evident that \u03bbmax \u2264 2n. The other two terms in Theorem 3 can be bound in a straightforward manner to finally obtain with probability 1\u2212 \u03b4 the following:\nE \u2016zn\u20162 \u2264 ( C\u03b8\u2217\nn\u00b5c +\nh2(n)\nn\u2212\u03b1/4+1/2 +\nh1(n)\nn\u03b1\u22121/2\n)\nThus, we obtain\nP (\u2016\u03b8n \u2212 \u03b8\u2217\u20162 \u2264 \u03ban) \u2265 1\u2212 \u03b4. (14)\nThe claim now follows by a changing to An norm in (14)."}, {"heading": "Proof of Lemma 6", "text": "Proof. Let Vn = An(\u03b8\u0303n \u2212 \u03b8\u2217). Note that Vn can also be written as Vt = n\u22121\u2211\ni=1 \u03b7ixi \u2212 \u03bb\u0303n\u03b8\u2217, where \u03b7i =\nyn \u2212 xTn\u03b8\u2217 and \u03bb\u0303n \u25b3 = n\u03bbn. We first bound z\u0303n \u25b3 = \u2225 \u2225 \u2225\u03b8\u0303n \u2212 \u03b8\u2217 \u2225 \u2225 \u2225 An,2 = (\u03b8\u0303n \u2212 \u03b8\u2217)An(\u03b8\u0303t \u2212 \u03b8\u2217) below:\nz\u0303n+1 =Vn+1A\u22121n+1Vn+1 =(Vn + \u03b7nxn \u2212 dn+1\u03b8\u2217)TA\u22121n+1(Vn + \u03b7nxn \u2212 dn+1\u03b8\u2217) =VTnA\u22121n+1Vn + 2\u03b7nxTnA\u22121n+1Vn + \u03b72nx2Tn A\u22121n+1xn + d2n+1\u03b8\u2217TA\u22121n+1\u03b8\u2217 \u2212 2dn+1A\u22121n+1(Vn + \u03b7nxn)\n\u2264VTnA\u22121n+1Vn + 2\u03b7nxTnA\u22121n+1Vn + \u03b72nx2Tn A\u22121n+1xn \u2212 d2n+1\nn+ \u03bb\u0303n+1 \u2016\u03b8\u201622 \u2212 2dn+1\u03b8\u2217T(\u03b8\u0303n \u2212 \u03b8\u2217), (15)\nwhere the last inequality holds because \u2016An+1\u20162 n+ \u03bb\u0303n+1 by (A2). A\u22121n+1 can be simplified as follows:\nA\u22121n+1 = (An + xnx T n + dn+1Id) \u22121 = (An + xnx T n) \u22121 \u2212 dn+1(An + xnxTn)\u22121A\u22121n+1\n\u2264 (\n1\u2212 dn+1 n+ \u03bb\u0303n+1\n)\n(An + xnx T n) \u22121 \u2264\n(\n1\u2212 dn+1 n+ \u03bb\u0303n+1\n)(\nA\u22121n \u2212 A\u22121n xnx T nA \u22121 n\n1 + w2n\n)\n(16)\nwhere the second equality follows from the identity (M+cI)\u22121 = M\u22121\u2212cM\u22121(M+cI)\u22121 for any square matrix M and constant c, the first inequality follows from the fact that \u2016An+1\u20162 n + \u03bb\u0303n+1, and the second inequality follows by Sherman-Morrison lemma. Note that wn \u25b3 = xTnA \u22121 n xn. Plugging (16) into (15), we obtain\nz\u0303n+1 \u2264 (\n1\u2212 dn+1 n+ \u03bb\u0303n+1\n)[\nz\u0303n + 2\u03b7n xTn(\u03b8\u0303n \u2212 \u03b8\u2217)\n1 + w2t +\n\u03b72nw 2 n\n1 + w2n\n]\n\u2212 d 2 n+1\nn+ \u03bb\u0303n+1 \u2016\u03b8\u2217\u201622 \u2212 2dn+1\u03b8\u2217T(\u03b8\u0303n \u2212 \u03b8\u2217).\nUnrolling the above recursion and noting that z\u03031 \u2264 d, we obtain\nz\u0303n \u2264d+ n\u2211\nk=1\n(\n2\u03b7k xTk(\u03b8\u0303k \u2212 \u03b8\u2217)\n1 + w2k + \u03b72k w2k 1 + w2k\n)\n\u2212 n\u2211\nk=1\nd2k+1\nk + \u03bb\u0303k+1 \u2016\u03b8\u2217\u201622 \u2212 2\nn\u2211\nk=1\ndk+1\u03b8 \u2217T(\u03b8\u0303k \u2212 \u03b8\u2217).\n\u2264d+ n\u2211\nk=1\n(\n2\u03b7k xTk(\u03b8\u0303k \u2212 \u03b8\u2217)\n1 + w2k + \u03b72k w2k 1 + w2k\n)\n\u2212 2 n\u2211\nk=1\n((k + 1)\u03b1 \u2212 k\u03b1))\u03b8\u2217T(\u03b8\u0303k \u2212 \u03b8\u2217). (17)\nIn arriving at the first equality, we have used the fact that n\u220f\nk=1\n(\n1\u2212 dk+1 k+\u03bb\u0303k+1\n)\n\u2264 1, while the second inequality (17) follows since the term removed is positive. In (17), we have also used for the regularisation parameter \u03bb\u0303n, the choice of \u03bb\u0303n = n\u03b1, for some \u03b1 \u2208 (1/2, 1).\nWe now bound each of the terms in (17) below:\n\u2022 Let Mk = \u03b7k xTk(\u03b8\u0303k \u2212 \u03b8\u2217)\n1 + w2k . It can be seen that Mk is a martingale difference sequence. An application of\nFreedman\u2019s concentration result to n\u22121\u2211\nk=1\nMk establishes that with high probability, say 1\u2212\u03b4, n\u22121\u2211\nk=1 Mk \u2264 \u03b2k/2, for all k. \u2022 By assumption, we have \u2016\u03b7i\u20162 \u2264 1. Further, w2k\n1 + w2k \u2264 2d ln n.\n\u2022 We bound the last term in (17) as follows: \u2225 \u2225 \u2225dk+1\u03b8\n\u2217T(\u03b8\u0303k \u2212 \u03b8\u2217) \u2225 \u2225 \u2225 2 C-S \u2264 dk+1 \u2016\u03b8\u2217\u20162 \u2225 \u2225 \u2225\u03b8\u0303k \u2212 \u03b8\u2217 \u2225 \u2225 \u2225 2 \u2264 dk+1\u221a\n\u03bb\u0303k+1\n\u2016\u03b8\u2217\u20162 \u221a \u03b2k\nThe last inequality above holds because \u2225 \u2225 \u2225\u03b8\u0303n \u2212 \u03b8\u2217 \u2225 \u2225 \u2225 An,2 \u2264 \u221a\u03b2n and \u2016z\u20162 \u2264 \u2016z\u2016An,2 \u221a \u03bb\u0303n since \u2016An\u20162 \u2265 \u03bb\u0303n by definition. By comparing the summation with the integral, we claim n\u2211\nk=1\n((k + 1)\u03b1 \u2212 k\u03b1) (k + 1)\u03b1/2 \u221a \u03b2k \u2264 C3(n+ 1)\u03b1/2,\nwhere C3 hides log factors. Putting it all together, we have the following simplified form of (17):\nz\u0303n \u2264 d+ \u03b2n 2 + 2d ln n+ C3(n+ 1) \u03b1/2 (18)\nThe claim follows.\nA.4 Iterate Averaging\nHere we incorporate the well-known Polyak-Ruppert scheme to average the iterates, which when coupled with larger step-sizes cn\u2212\u03b1 with \u03b1 \u2208\n( 1 2 , 1 ) leads to a convergence rate of the order O(n\u22121/2) irrespective\nof the choice of c in the step-sizes:\nDefine \u03b8\u0304n+1 \u25b3 = (\u03b81 + . . . + \u03b8n)/n and let zn = \u03b8\u0304n+1 \u2212 \u03b8\u2217 denote the approximation error as before.\nThen, we have the following bound in high probability:\nTheorem 11. Under (A1)-(A3) we have, for Li \u25b3 = \u03b3i n\n(\n1 + n\u22121\u2211\nl=i+1\nl\u220f\nj=i\n( 1 + \u03b32j+1 \u2212 2\u00b5\u03b3j+1) )1/2\n)\n,\n\u2200n \u2265 1,\u2200\u01eb \u2265 0, P (\u2016zn\u20162 \u2212 E \u2016zn\u20162 \u2265 \u01eb) \u2264 exp\n\n   \u2212 \u01eb\n2\n2 n\u2211\ni=1 L2i\n\n   .\nChoice of step-sizes Fix \u03b3n := cn\u2212\u03b1, for some \u03b1 \u2208 (1/2, 1). Then we have in Theorem 11:\nn\u2211\ni=1\nL2i \u2264 K\u00b5,c,\u03b1\nn where K\u00b5,c,\u03b1 = c\n3 exp\n( c2\n2\u03b1\u2212 1\n) \n\n( \u221a 2\n\u00b53/2c exp\n(\u221a 2\n\u00b5\n))2\n+\n(\n3 + 2\nc\n)2 \n\n(See Lemma 21 below for a derivation). So, the high probability bound from Theorem 11 is\nP (\u2016zn\u20162 \u2212 E \u2016zn\u20162 \u2265 \u01eb) \u2264 exp ( \u2212 \u01eb 2n\n2K\u00b5,c,\u03b1\n)\n.\nAveraging the bound in expectation obtained in Theorem 2, we obtain the following: \u2200\u03b7 > 0,\nE \u2016zn\u20162 \u2264 K\u0303\u00b5,c,\u03b1 \u2016z0\u20162 n + h\u0303(n) \u03b72n\u03b1\u22121/2\u2212\u03b7\nwhere K\u0303\u00b5,c,\u03b1 := \u2211\u221e\nk=1 exp(\u2212\u00b5ck1\u2212\u03b1/(1 \u2212 \u03b1)). Thus, it is possible to remove the dependency on the knowledge of \u00b5 for the choice of c through averaging of the iterates. However, as suggested by earlier works on stochastic approximation, it is preferred to average after a few iterations since the initial condition \u2016z0\u20162 is not forgotten exponentially fast with averaging.\nProof of Theorem 11. As in Theorem 1, we first decompose \u2016zn\u201622 \u2212 E \u2016zn\u2016 2 2 into a sum of martingale differences as follows:\n\u2016zn\u20162 \u2212 E \u2016zn\u20162 = n\u2211\ni=1\nDi, (19)\nwhere Di \u25b3 = gi \u2212 E[gi |Hi\u22121 ] and gi =\nn\u2211 i=1 E[\u2016zn\u20162 \u2223 \u2223\u03b6i = (\u03b6 1 i , \u03b6 2 i ) ]. Here \u03b6 1 i is the value of the averaged\niterate \u03b8\u0304i+1 at instant i and \u03b62i is the value of the iterate \u03b8i at instant i. The next step is to prove that the functions gi are Lipschitz continuous with constants\nLi \u25b3 = \u03b3i n\n\n1 +\nn\u22121\u2211\nl=i+1\nl\u220f\nj=i\n( 1 + \u03b32j+1 \u2212 2\u00b5\u03b3j+1) )1/2\n\n .\nLet \u0398\u0304ij(\u03b6) denote the mapping that returns the value of the averaged iterate at instant j, \u03b8j , given that \u03b8\u0304i+1 = \u03b6 1 and \u03b8i = \u03b62. Then, we have\nE [\u2225 \u2225\u0398\u0304in(\u03b6)\u2212 \u0398\u0304in(\u03b6 \u2032) \u2225 \u2225 2 ] \u2264 i+ 1\nn\n\u2225 \u2225\u03b61 \u2212 \u03b6 \u20321 \u2225 \u2225 2 + 1\nn\nn\u22121\u2211\nl=i+1\nl\u220f\nj=i\n( 1 + \u03b32j+1 \u2212 2\u00b5\u03b3j+1) )1/2 \u2225 \u2225\u03b62 \u2212 \u03b6 \u20322 \u2225 \u2225 2 (20)\nUsing the sub-Gaussian property of noise \u03be, we obtain for every \u03bb > 0\nE ( exp(\u03bbgi(\u03b8\u0304i+1, \u03b8i) \u2223 \u2223\u03b6i\u22121 = (\u03b6 1, \u03b62) ) =E\n(\nexp(\u03bbgi( i\ni+ 1 \u03b8\u0304i +\n1\ni+ 1 \u03b8i, \u03b8i)\n\u2223 \u2223(\u03b61, \u03b62)\n)\n\u2264 exp(\u03bbgi) exp (\n\u03bb2L2f 2\n)\n,\nwhere Lf is the Lipschitz constant of the function f defined as\nf(\u03be) = gi\n( i\ni+ 1 \u03b61 +\n1 i+ 1 \u03b62 \u2212 \u03b3i i+ 1 f \u2032i(\u03b6\n2), \u03b62 \u2212 \u03b3if \u2032i(\u03b62) ) .\nAs a consequence of (20), we obtain Lf = \u03b3i n\n(\n1 + n\u22121\u2211\nl=i+1\nl\u220f\nj=i\n( 1 + \u03b32j+1 \u2212 2\u00b5\u03b3j+1) )1/2\n)\n. The rest of the\nproof follows in a similar manner to the proof of Theorem 1.\nLemma 12. When \u03b3i = cn\u03b1 for some \u03b1 \u2208 ( 1 2 , 1 ) , we have\nn\u2211\ni=1\nL2i \u2264 cKc,\u03b1 \u00b5\n(\n2\n( 2\u03b1\n\u00b5 )1\u2212\u03b1 (1\u2212 \u03b1 \u00b5c ) exp\n(( 2\u03b1\n\u00b5\n)1\u2212\u03b1 )\n1 n + 3 + 2 c\n)2 1\nn (21)\nProof. The main ingredients of this derivation can be found in the argument of page 15 in [3], however here we manage to give all the constants explicitly. We perform the calculation:\nn\u2211\ni=1\nL2i = n\u2211\ni=1\n\n \u03b3i n\n 1 + n\u22121\u2211\nl=i+1\nl\u220f\nj=i\n( 1 + \u03b32j+1 \u2212 2\u00b5\u03b3j+1) )1/2\n\n\n\n\n2\n\u2264 exp\n(\n2 \u2211\n\u03b32j\n)\n(\u00b5n)2\nn\u2211\ni=1\n[\n\u03b3i\n(\n1 + n\u22121\u2211\nl=i+1\nexp\n(\n\u2212\u00b5 n\u2211\nl=i+1\n\u03b3l\n))]2\n\u2264 exp\n(\n2 \u2211\n\u03b32j\n)\n(\u00b5n)2\nn\u2211\ni=1\n[\n\u03b3i\u03b3 \u22121 i+2 + \u03b3i\nn\u22121\u2211\nl=i+1\nexp(\u2212\u00b5 n\u2211\nl=i+1\n\u03b3l)(\u03b3 \u22121 l+2 \u2212 \u03b3\u22121l+1)\n]2\n\u2264 K2\u00b5,c (\u00b5n)2 n\u2211\ni=1\n[( i+ 2\ni\n)\u03b1\n+ 1\ni\u03b1\nn\u22121\u2211\nl=i+1\nexp\n(\n\u2212\u00b5(l 1\u2212\u03b1 \u2212 i1\u2212\u03b1) 1\u2212 \u03b1\n) ((l + 2)\u03b1 \u2212 (l + 1)\u03b1) ]2\n\u2264 K2\u00b5,c (\u00b5n)2\n \n\n\u230a2\u03b1/\u00b5\u230b \u2211\ni=1\n[\n3\u03b1 + 2 ( \u00b5\n2\u03b1 )\u03b1 ( 1\u2212 \u03b1 \u00b5c )2 exp\n(( 2\u03b1\n\u00b5\n)1\u2212\u03b1 )]2\n+ n\u2211\n\u23082\u03b1/\u00b5\u2309\n[\n3\u03b1 +\n( 2\nc\n)\u03b1]2  \n\nIn the second inequality we have used an Abel transform (see page 15 in [3], display (2.2), for details). For the third inequality we have substituted \u03b3i = cn\u2212\u03b1, set K\u00b5,c = exp ( \u2211 \u03b3j), and used a comparison with an integral. For the last inequality we have noted, as in page 15 in [3], that\n(A) :=\nn\u22121\u2211\nl=i+1\nexp\n(\n\u2212\u00b5 l1\u2212\u03b1\u2212i1\u2212\u03b1\n1\u2212 \u03b1\n)\n((l + 2)\u03b1 \u2212 (l + 1)\u03b1)\n\u2264 exp ( \u00b5i1\u2212\u03b1\n1\u2212 \u03b1\n)\u222b n1\u2212\u03b1\n(i+1)1\u2212\u03b1 exp\n( \u00b5l\n1\u2212 \u03b1\n)\nl 2\u03b1\u22121 1\u2212\u03b1 dl.\nNow, by taking the derivative and setting it to zero, we find that l 7\u2192 exp (\n\u00b5l 1\u2212\u03b1\n)\nl 2\u03b1 1\u2212\u03b1 is decreasing on\n[2\u03b1/\u00b5,\u221e), and so we deduce that (A) \u2264 (i + 1)\u03b1; this provides the bound on (A) when i \u2265 2\u03b1/\u00b5. When i < 2\u03b1/\u00b5 we upper bound (A) by substituting worst case values for i in each term."}], "references": [{"title": "Non-asymptotic analysis of stochastic approximation algorithms for machine learning", "author": ["Francis Bach", "Eric Moulines"], "venue": "Advances in Neural Information Processing Systems (NIPS),", "citeRegEx": "1", "shortCiteRegEx": "1", "year": 2011}, {"title": "Stochastic linear optimization under bandit feedback", "author": ["Varsha Dani", "Thomas P Hayes", "Sham M Kakade"], "venue": "In Proceedings of the 21st Annual Conference on Learning Theory (COLT),", "citeRegEx": "2", "shortCiteRegEx": "2", "year": 2008}, {"title": "Transport-entropy inequalities and deviation estimates for stochastic approximation schemes", "author": ["Max Fathi", "Noufel Frikha"], "venue": "arXiv preprint arXiv:1301.7740,", "citeRegEx": "3", "shortCiteRegEx": "3", "year": 2013}, {"title": "Concentration Bounds for Stochastic Approximations", "author": ["Noufel Frikha", "Stphane Menozzi"], "venue": "Electron. Commun. Probab.,", "citeRegEx": "4", "shortCiteRegEx": "4", "year": 2012}, {"title": "Beyond the regret minimization barrier: an optimal algorithm for stochastic strongly-convex optimization", "author": ["Elad Hazan", "Satyen Kale"], "venue": "Journal of Machine Learning Research-Proceedings Track,", "citeRegEx": "5", "shortCiteRegEx": "5", "year": 2011}, {"title": "Making gradient descent optimal for strongly convex stochastic optimization", "author": ["Alexander Rakhlin", "Ohad Shamir", "Karthik Sridharan"], "venue": "arXiv preprint arXiv:1109.5647,", "citeRegEx": "6", "shortCiteRegEx": "6", "year": 2011}, {"title": "Linearly parameterized bandits", "author": ["Paat Rusmevichientong", "John N. Tsitsiklis"], "venue": "Math. Oper. Res.,", "citeRegEx": "7", "shortCiteRegEx": "7", "year": 2010}, {"title": "Online learning as stochastic approximation of regularization paths", "author": ["Pierre Tarr\u00e8s", "Yuan Yao"], "venue": "arXiv preprint arXiv:1103.5538,", "citeRegEx": "8", "shortCiteRegEx": "8", "year": 2011}], "referenceMentions": [{"referenceID": 6, "context": "As examples of a higher level learning algorithm using regression as a subroutine, we consider two linear bandit algorithms, the PEGE algorithm of [7] and the ConfidenceBall algorithm of [2].", "startOffset": 147, "endOffset": 150}, {"referenceID": 1, "context": "As examples of a higher level learning algorithm using regression as a subroutine, we consider two linear bandit algorithms, the PEGE algorithm of [7] and the ConfidenceBall algorithm of [2].", "startOffset": 187, "endOffset": 190}, {"referenceID": 6, "context": "The PEGE algorithm of [7] is designed for action sets D satisfying a strong convexity property (see assumption (A4) in Section 3).", "startOffset": 22, "endOffset": 25}, {"referenceID": 6, "context": "For the PEGE algorithm of [7] our result achieves an O(d) improvement in complexity, while incurring only a logarithmic deterioration in the regret.", "startOffset": 26, "endOffset": 29}, {"referenceID": 1, "context": "For the ConfidenceBall algorithm of [2] we again achieve a complexity improvement of O(d), while incurring an O(n1/5) deterioration in the regret.", "startOffset": 36, "endOffset": 39}, {"referenceID": 0, "context": "Non-asymptotic bounds in expectation for SGD schemes have been provided in [1].", "startOffset": 75, "endOffset": 78}, {"referenceID": 4, "context": "In the machine learning community, several algorithms have been proposed for minimizing the regret, for instance, [9, 5, 6] and these can be converted to find the minimizer of a (usually convex) function.", "startOffset": 114, "endOffset": 123}, {"referenceID": 5, "context": "In the machine learning community, several algorithms have been proposed for minimizing the regret, for instance, [9, 5, 6] and these can be converted to find the minimizer of a (usually convex) function.", "startOffset": 114, "endOffset": 123}, {"referenceID": 3, "context": "A closely related field is stochastic approximation (SA) and concentration bounds for SA algorithms have been provided in [4].", "startOffset": 122, "endOffset": 125}, {"referenceID": 7, "context": "Adaptive regularisation in the context of least squares regression has been analysed in [8].", "startOffset": 88, "endOffset": 91}, {"referenceID": 6, "context": "Phased Exploration and Greedy Exploitation (PEGE) of [7] is a well-known algorithm in this setting.", "startOffset": 53, "endOffset": 56}, {"referenceID": 6, "context": "1 Analysis We require the following extra assumptions from [7]: (A3\u2019) A basis {b1, .", "startOffset": 59, "endOffset": 62}, {"referenceID": 6, "context": "1 of [7]: Theorem 7.", "startOffset": 5, "endOffset": 8}, {"referenceID": 6, "context": "6 of [7]: Lemma 8.", "startOffset": 5, "endOffset": 8}, {"referenceID": 6, "context": "5 of [7].", "startOffset": 5, "endOffset": 8}, {"referenceID": 6, "context": "1 of [7].", "startOffset": 5, "endOffset": 8}, {"referenceID": 1, "context": "The well-known confidence ball algorithm of [2] works by constructing a least squares estimate \u03b8\u0302 using {(xi, yi)}i=1 around \u03b8\u2217 and using this estimate to pick an arm greedily, i.", "startOffset": 44, "endOffset": 47}, {"referenceID": 1, "context": "The regret Rn with this algorithm was shown to be of the order O( \u221a dn lnn) in [2].", "startOffset": 79, "endOffset": 82}, {"referenceID": 1, "context": "In our setting, Theorem 4 serves as an analogue to Theorem 5 of [2].", "startOffset": 64, "endOffset": 67}, {"referenceID": 0, "context": "References [1] Francis Bach, Eric Moulines, et al.", "startOffset": 11, "endOffset": 14}, {"referenceID": 1, "context": "[2] Varsha Dani, Thomas P Hayes, and Sham M Kakade.", "startOffset": 0, "endOffset": 3}, {"referenceID": 2, "context": "[3] Max Fathi and Noufel Frikha.", "startOffset": 0, "endOffset": 3}, {"referenceID": 3, "context": "[4] Noufel Frikha and Stphane Menozzi.", "startOffset": 0, "endOffset": 3}, {"referenceID": 4, "context": "[5] Elad Hazan and Satyen Kale.", "startOffset": 0, "endOffset": 3}, {"referenceID": 5, "context": "[6] Alexander Rakhlin, Ohad Shamir, and Karthik Sridharan.", "startOffset": 0, "endOffset": 3}, {"referenceID": 6, "context": "[7] Paat Rusmevichientong and John N.", "startOffset": 0, "endOffset": 3}, {"referenceID": 7, "context": "[8] Pierre Tarr\u00e8s and Yuan Yao.", "startOffset": 0, "endOffset": 3}, {"referenceID": 3, "context": "1 Random Online Proof of Theorem 1 We use the proof technique from [4] in arriving at the high-probability bounds.", "startOffset": 67, "endOffset": 70}, {"referenceID": 2, "context": "The main ingredients of this derivation can be found in the argument of page 15 in [3], however here we manage to give all the constants explicitly.", "startOffset": 83, "endOffset": 86}, {"referenceID": 2, "context": "In the second inequality we have used an Abel transform (see page 15 in [3], display (2.", "startOffset": 72, "endOffset": 75}, {"referenceID": 2, "context": "For the last inequality we have noted, as in page 15 in [3], that", "startOffset": 56, "endOffset": 59}], "year": 2017, "abstractText": "We improve the computational complexity of online learning algorithms that require to often recompute least squares regression estimates of parameters. We propose two stochastic gradient descent schemes with randomisation in order to efficiently track the true solutions of the regression problems achieving an O(d) improvement in complexity, where d is the dimension of the data. The first algorithm assumes strong convexity in the regression problem, and we provide bounds on the error both in expectation and high probability (the latter is often needed to provide theoretical guarantees for higher level algorithms). The second algorithm deals with cases where strong convexity of the regression problem cannot be guaranteed and uses adaptive regularisation. We again give error bounds in both expectation and high probability. We apply our approaches to the linear bandit algorithms PEGE and ConfidenceBall and demonstrate significant gains in complexity in both cases. Since strong convexity is guaranteed by the PEGE algorithm, we lose only logarithmic factors in the regret performance of the algorithm. On the other hand, in the ConfidenceBall algorithm we adaptively regularise to ensure strong convexity, and this results in an \u00d5(n1/5)1 deterioration of the regret.", "creator": "LaTeX with hyperref package"}}}