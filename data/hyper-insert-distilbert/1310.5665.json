{"id": "1310.5665", "review": {"conference": "icml", "VERSION": "v1", "DATE_OF_SUBMISSION": "21-Oct-2013", "title": "Learning Theory and Algorithms for Revenue Optimization in Second-Price Auctions with Reserve", "abstract": "second - price auctions with reserve play a critical bargaining role crucial for modern technological search engine technology and launching popular public online pricing sites commercially since the revenue feeds of these companies often generate directly de - pends on selecting the outcome of such competing auctions. the ultimate choice of choosing the reserve price is the main mechanism through which the new auction market revenue can sometimes be influenced fundamentally in these complex electronic markets. accordingly we cast the problem of publicly selecting the reserve price exclusively to individually optimize revenue as alternatively a popular learning problem arises and present a highly full or theoretical formal analysis that dealing with the complex properties of the corresponding minimum loss function. we further give novel algorithms for solving either this mathematics problem and report onto the results of several prior experiments demonstrating their effectiveness.", "histories": [["v1", "Mon, 21 Oct 2013 18:27:25 GMT  (188kb,D)", "http://arxiv.org/abs/1310.5665v1", "Under revision for ICML 2014"], ["v2", "Mon, 13 Jan 2014 18:31:04 GMT  (182kb,D)", "http://arxiv.org/abs/1310.5665v2", "Accepted at ICML 2014"], ["v3", "Tue, 2 Dec 2014 20:42:17 GMT  (172kb,D)", "http://arxiv.org/abs/1310.5665v3", "Accepted at ICML 2014"]], "COMMENTS": "Under revision for ICML 2014", "reviews": [], "SUBJECTS": "cs.LG", "authors": ["mehryar mohri", "andres mu\\~noz medina"], "accepted": true, "id": "1310.5665"}, "pdf": {"name": "1310.5665.pdf", "metadata": {"source": "CRF", "title": "Learning Theory and Algorithms for Revenue Optimization in Second-Price Auctions with Reserve", "authors": ["Mehryar Mohri"], "emails": ["mohri@cims.nyu.edu", "munoz@cims.nyu.edu"], "sections": [{"heading": null, "text": "Second-price auctions with reserve play a critical role for modern search engine and popular online sites since the revenue of these companies often directly depends on the outcome of such auctions. The choice of the reserve price is the main mechanism through which the auction revenue can be influenced in these electronic markets. We cast the problem of selecting the reserve price to optimize revenue as a learning problem and present a full theoretical analysis dealing with the complex properties of the corresponding loss function. We further give novel algorithms for solving this problem and report the results of several experiments demonstrating their effectiveness."}, {"heading": "1 Introduction", "text": "Over the past few years, advertisement has gradually moved away from the traditional printed promotion to the more tailored and directed online publicity. The advantages of online advertisement are clear: since most modern search engine and popular online sites companies such as as Microsoft, Facebook, Google, eBay, or Amazon, may collect information about the users\u2019 behavior, advertisers can better target the population sector their brand is intended for.\nMore recently, a new method for selling advertisements has gained momentum. Unlike the standard contracts between publishers and advertisers where some amount of impressions is required to be fulfilled by the publisher, an Ad Exchange works in a way similar to a financial exchange where advertisers bid and compete between each other for an ad slot. The winner then pays the publisher and his ad is displayed.\nThe design of such auctions and their properties are crucial since they generate a large fraction of the revenue of popular online sites. These questions have motivated extensive research on the topic of auctioning in the last decade or so, particularly in the theoretical computer science and economic theory communities. Much of this work has focused on the analysis of mechanism design, either to prove some useful property of an existing auctioning mechanism, to analyze its computational efficiency, or to search for an optimal revenue maximization truthful mechanism (see [14] for a good discussion of key research problems related to Ad Exchange and references to a fast growing literature therein).\nOne important problem is that of determining an auction mechanism that achieves optimal revenue [14]. In the ideal scenario where the distribution of all bidders is given, this is known to be achievable (see for example [15]), but even good approximations of such distributions are not known in practice. Game theoretical approaches to the design of auctions have resulted in a series of interesting results including [18, 12, 15, 16], all of them based on some assumptions about the distribution of the bidders, e.g., the monotone hazard rate assumption.\nar X\niv :1\n31 0.\n56 65\nv1 [\ncs .L\nG ]\n2 1\nO ct\nThe results of the recent publications have nevertheless set the basis for most Ad Exchanges in practice: the mechanism widely adopted for selling ad slots is that of a Vickrey [24] auctions or second-price auctions with reserve price r [7]. In such auctions, the winning bidder (if any) pays the maximum of the second-place bid and the reserve price r. The reserve price can be set by the publisher or automatically by the exchange. It is clear that the revenue of the publisher depends greatly on how the reserve price is set: if set too low, the winner of the auction might end up paying only a small amount even if his bid was really high; on the other hand, if it is set too high, then bidders may not bid higher than the reserve price and the ad slot will not be sold.\nWe propose a machine learning approach to the problem of determining the reserve price to optimize revenue in such auctions. The general idea is to leverage the information gained from past auctions to predict a beneficial reserve price. Since every transaction on an Exchange is logged, it is natural to seek to exploit that data. This could be used to estimate the probability distribution of the bidders, which can then be used indirectly to come up with the optimal reserve price [15, 17]. Instead, we will seek a discriminative method making use of the loss function related to the problem and taking advantage of existing user features.\nMachine learning methods have already been used for the related problems of designing incentive compatible auction mechanisms [2, 4], for algorithmic bidding [25, 1] and even for predicting bid landscapes [6]. But, to our knowledge, no prior work has used historical data in combination with user features for the sole purpose of revenue optimization in this context. In fact, the only publications we are aware of that are directly related to our objective are [17] and the stimulating work of Cesa-Bianchi et al. [5] which considers a more general case than [17] . The scenario studied by [5] is that of censored information, which motivates their use of a bandit model to optimize the revenue of the seller. Our analysis assumes instead access to full information. We argue that this is in fact a more realistic scenario since most companies do have access to the full historical data.\nThe learning scenario we consider is more general since it includes the use of features, as is standard in supervised learning. Since user information is sent to advertisers and bids are made based on this information, it is only natural to include user features in our learning solution. A special case of our analysis coincides with the no-feature scenario considered in [5], assuming full information. But, our results further extend those of [5] even in that scenario. In particular, we present an O(m logm) algorithm for solving a key optimization problem used as a subroutine by [5], for which they do not seem to give an algorithm. We also do not require an i.i.d. assumption about the bidders, although this is needed in [5] only for the bandit approach.\nThe theoretical and algorithmic analysis of this learning problem raises several non-trivial technical issues. This is because, unlike some common problems in machine learning, here, the use of a convex surrogate loss cannot be successful. Instead, we must derive an alternative non-convex surrogate requiring novel theoretical guarantees (Section 3) and a new algorithmic solution (Section 4). We present a detailed analysis of possible surrogate losses and select a continuous loss that we prove to be calibrated and for which we give generalization bounds. This leads to an optimization problem cast as a DC-programming problem whose solutions are examined in detail: we first present an efficient combinatorial algorithm for solving that optimization in the no-feature case, next we combine that solution with the DC algorithm (DCA) [21] to solve the general case. Section 5 reports the results of our experiments with synthetic data in both the no-feature case and the general case. We first introduce the problem of selecting the reserve price to optimize revenue and cast it as a learning problem (Section 2)."}, {"heading": "2 Reserve price selection problem", "text": "As already discussed, the choice of the reserve price r is the main mechanism through which a seller can influence the auction revenue. To specify the results of a second-price auction we need only the vector of first and second highest bids which we denote by b = (b1, b2) \u2208 B \u2282 R2. For a given reserve price r and bid pair b, the revenue of an auction is given by\nRevenue(r,b) = b21r<b2 + r1b2\u2264r\u2264b1 . (1)\nThe simplest setup is one where there are no features associated with the auction. In that case, the objective is to select r to optimize the expected revenue:\nE b [Revenue(r,b)] = \u222b \u221e r P[b2 > t]dt+ r P[b1 \u2265 r]. (2)\nThe derivation of this equality can be obtained using integration by parts and can be found in [5]. In fact this expression is precisely the one optimized by the authors. If we now associate with each auction a feature vector x \u2208 X , the so-called public information, and set the reserve price to h(x), where h : X \u2192 R+ is our reserve price hypothesis function, the problem can be formulated as that of selecting out of some hypothesis set H a hypothesis h with large expected revenue:\nE (x,b)\u223cD [Revenue(h(x),b)] (3)\nwhere D is the unknown distribution according to which the pairs (x,b) are drawn. Instead of the revenue, we will consider a loss function L defined by L(r,b) = \u2212Revenue(r,b) for all (r,b) and will seek a hypothesis h with small expected loss L(h) = E(x,b)\u223cD[L(h(x),b)]. As in standard supervised learning scenarios, we assume access to a training sample S = ((x1,b1), . . . , (xm,bm)) of size m \u2265 1 drawn i.i.d. according to D and denote by L\u0302S(h) the empirical loss 1m \u2211m i=1 L(h(xi,bi). In the next sections, we present a detailed study of this learning problem."}, {"heading": "3 Learning guarantees", "text": "Let X denote the set of feature vectors and B that of bid vectors. To derive generalization bounds for the learning problem formulated, we need to analyze the complexity of the family of functions LH mapping X \u00d7B to R defined by LH = {(x,b) 7\u2192 L(h(x),b) : h \u2208 H}. The loss function L is neither Lipschitz continuous nor convex (see Figure 1). To analyze its complexity, we decompose L as a sum of two loss functions l1 and l2 with more convenient properties. We have L = l1 + l2 with l1 and l2 defined for all (x,b) \u2208 X \u00d7 B by\nl1(r,b) = \u2212b21r<b2 \u2212 r1b2\u2264r\u2264b1 \u2212 b11r>b1 and l2(r,b) = b11r>b1 . Note that for a fixed b, the function r 7\u2192 l1(r,b) is 1-Lipschitz since the slope of the lines defining the function is at most 1. We will consider the corresponding family of loss functions: l1H = {(x,b) 7\u2192 l1(h(x),b) : h \u2208 H} and l2H = {(x,b) 7\u2192 l2(h(x),b) : h \u2208 H} and use the notions of empirical and average Rademacher complexity. For a family of functions G and finite sample S = (z1, . . . , zm) of size m, the empirical Rademacher complexity is defined by R\u0302S(G) = E\u03c3 [ supg\u2208G 1 m \u2211m i=1 \u03c3ig(zi) ] , where \u03c3 = (\u03c31, . . . , \u03c3m)>, with \u03c3is independent uniform random variables taking values in {\u22121,+1}. The Rademacher complexity of G is defined as Rm(G) = ES\u223cDm [R\u0302S(G)]. Proposition 1. For any hypothesis set H and any sample S = ((x1,b1), . . . , (xm,bm)), the empirical Rademacher complexity of l1H can be bounded as follows:\nR\u0302S(l1H) \u2264 R\u0302S(H).\nProof. By definition of the empirical Rademacher complexity, we can write R\u0302S(l1H) = 1 m E\u03c3[suph\u2208H \u2211m i=1 \u03c3il1(h(xi),bi)] = 1 m E\u03c3[suph\u2208H \u2211m i=1 \u03c3i(\u03c8i \u25e6 h)(xi)], where, for all i \u2208 [1,m], \u03c8i is the function defined by \u03c8i : r 7\u2192 l1(r,bi). For any i \u2208 [1,m], \u03c8i is 1-Lipschitz, thus, by the contraction lemma 12, a variant of Talagrand\u2019s contraction lemma [11][p. 112] with our definition of Rademacher complexity, we have R\u0302S(l1H) \u2264 1m E\u03c3[suph\u2208H \u2211m i=1 \u03c3ih(xi)] = R\u0302S(H).\nProposition 2. Let M = supb\u2208B b1. Then, for any hypothesis set H with pseudo-dimension d = Pdim(H) and any sample S = ((x1,b1), . . . , (xm,bm)), the empirical Rademacher complexity of l2H can be bounded as follows:\nR\u0302S(l2H) \u2264 \u221a\n2d log emd m .\nProof. By definition of the empirical Rademacher complexity, we can write\nR\u0302S(l2H) = 1\nm E \u03c3 [ sup h\u2208H m\u2211 i=1 \u03c3ib 1 i1h(xi)>b1i ] = 1 m E \u03c3 [ sup h\u2208H m\u2211 i=1 \u03c3i\u03a8i(1h(xi)>b1i ) ] ,\nwhere for all i \u2208 [1,m], \u03a8i is the M -Lipschitz function x 7\u2192 b1ix. Thus, by Lemma 12 combined with Massart\u2019s lemma (see for example [13]):\nR\u0302S(l2H) \u2264 M\nm E \u03c3 [ sup h\u2208H m\u2211 i=1 \u03c3i1h(xi)>b1i ] \u2264M \u221a 2d\u2032 log emd\u2032 m ,\nwhere d\u2032 = VCdim({(x,b) 7\u2192 1h(x)\u2212b1>0 : (x,b) \u2208 X \u00d7 B}). Since the second bid component b2 plays no role in this definition, d\u2032 coincides with the VCdim({(x, b1) 7\u2192 1h(x)\u2212b1>0 : (x, b1) \u2208 X \u00d7 B1}), where B1 is the projection of B \u2286 R2 onto its first component, and is upper-bounded by VCdim({(x, t) 7\u2192 1h(x)\u2212t>0 : (x, t) \u2208 X \u00d7R}), which is exactly the pseudo-dimension of H .\nTheorem 3. Let M = supb\u2208B b1 and let H be a hypothesis set with pseudo-dimension d = Pdim(H). Then, for any \u03b4 > 0, with probability at least 1 \u2212 \u03b4 over the choice of a sample S of size m, the following inequality holds for all h \u2208 H:\nL(h) \u2264 L\u0302S(h) + 2Rm(H) + 2M \u221a\n2d log emd m +M \u221a log 1\u03b4 2m . (4)\nProof. By Propositions 1 and 2, since L = l1 + l2, the Rademacher complexity of LH can be bounded as follows:\nRm(LH) \u2264 Rm(l1H) + Rm(l2H) \u2264 Rm(H) +M \u221a\n2d log emd m .\nThe result then follows by the application of a standard Rademacher complexity bound [10].\nThis learning bound invites us to consider an algorithm minimizing the empirical loss L\u0302S(h), h \u2208 H , while controlling the complexity, Rademacher complexity and pseudo-dimension, of the hypothesis setH . However, as in the familiar case of binary classification, in general, minimizing this empirical loss is a computationally hard problem. Thus, in the next section, we study the question of using a surrogate loss instead of the original loss L."}, {"heading": "3.1 Surrogate loss", "text": "As pointed out earlier, the loss function L does not admit some common useful properties: for any fixed b, L(\u00b7,b) is not differentiable at two points, is not convex, and is not Lipschitz, in fact it is discontinuous. For any fixed b, L(\u00b7,b) is quasi-convex, a property that is often desirable since there exist several solutions for quasi-convex optimization problems. However, unfortunately, in general, a sum of quasi-convex functions, such as the sum \u2211m i=1 L(\u00b7,bi) appearing in the definition of the empirical loss, is not quasi-convex and a fortiori not convex.1 In fact, in general, such a sum may admit exponentially many local minima. This leads us to seek a surrogate loss function with more favorable optimization properties.\nA standard method in machine learning consists of replacing the loss function Lwith a convex upper bound [3]. A natural candidate in our case is the piecewise linear convex function shown in Figure 1(b). However, while this convex loss function is convenient for optimization, it is not calibrated\n1It is known that under some separability condition if a finite sum of quasi-convex functions on an open convex set is quasi-convex then all but perhaps one of them is convex [8].\nand does not provide a useful surrogate. The calibration problem is illustrated by Figure 2(a) in dimension one, where the true objective function to be minimized \u2211m i=1 L(r,bi) is compared with the sum of the surrogate losses. As can be seen from the figure, the convex surrogate loss is in fact a very poor upper bound on the sum of the true losses. This is mainly due to the fact that the bid vectors bi, i \u2208 [1,m], may be in general quite diverse, which is in fact observed in practice. Other convex surrogate losses seem to share the same issue or not even offer a good approximation for a single term. This leads us to consider alternative non-convex loss functions, thus not ideal for optimization, but that can still lead to simpler optimization problems than the original one using L. Perhaps, the most natural surrogate loss is then L\u2032\u03b3 , an upper bound on L defined for all \u03b3 > 0 by:\nL\u2032\u03b3(r,b) = \u2212b21r\u2264b2 \u2212 r1b2<r\u2264(1\u2212\u03b3)b1 + 1\u2212 \u03b3 \u03b3 (r \u2212 b1)1(1\u2212\u03b3)b1<r\u2264b1 . (5)\nand shown in Figure 3(b). However, this turns out to be also a poor choice because L\u2032\u03b3 is a loose upper bound of L in the most critical region, that is around the minimum of the loss L. This furthermore results in a loss that in general is not calibrated, that is, for a hypothesis set H , we may not have in general infh\u2208H E(x,b)\u223cD[L\u2032\u03b3(h(x),b)] \u2192 infh\u2208H E(x,b)\u223cD[L(h(x),b)] as \u03b3 \u2192 0, depending on the distribution D.2 Thus, instead, we will consider, for any \u03b3 > 0, the loss function L\u03b3 defined as follows:\nL\u03b3(r,b) = \u2212b21r\u2264b2 \u2212 r1b2<r\u2264b1 + 1\n\u03b3 (r \u2212 (1 + \u03b3)b1)1b1<r\u2264(1+\u03b3)b1 , (6)\nand shown in Figure 3(a).3 A comparison between the sum of L-losses and the sum of L\u03b3-losses is shown in Figure 2(b). Observe that the fit is considerably better than when using a piecewise linear convex surrogate loss. A possible concern associated with the loss function L\u03b3 is that it is a lower bound for L. One might think then that minimizing it would not lead to an informative solution. However, we argue that this problem arises significantly with upper bounding losses such as the convex surrogate, which we showed not to lead to a useful minimizer, or L\u2032\u03b3 , which is a poor approximation of L near its minimum. By matching the original loss L in the region of interest, around the minimal value, the loss function L\u03b3 leads to more informative solutions in this problem. We further analyze the difference of the expectations of L and L\u03b3 and show that L\u03b3 is calibrated. We will use for any h \u2208 H , the notation L\u03b3(h) = E(x,b)\u223cD[L\u03b3(h(x),b)]. Theorem 4. Let H be a reproducing kernel Hilbert space associated with a positive definite kernel K. Denote by h\u2217\u03b3 the solution of min\u2016h\u2016K\u2264\u039b L\u03b3(h). If supb\u2208B = M <\u221e, then\nL(h\u2217\u03b3)\u2212 L\u03b3(h\u2217\u03b3) \u2264 \u03b3M.\nTo prove this proposition we require some definitions first.\n2Technically, this is related to the fact that the difference E[L\u2032\u03b3(h(x),b) \u2212 L(h(x),b)] can be expressed and bounded in terms of P [ h(x) \u2208 ((1\u2212 \u03b3)b1, b1] ] and to the closeness of the interval ((1\u2212 \u03b3)b1, b1] at b1.\n3Note that, technically, the theoretical and algorithmic results we present for L\u03b3 could be developed in a somewhat similar way for L\u2032\u03b3 with the absence of the calibration property and other related properties.\nDefinition 5. For any h \u2208 H define the following subsets of X \u00d7 B: I1(h) = {(x,b)|h(x) \u2264 b2} I2(h) = {(x,b)|h(x) \u2208 (b2, b1]} I3(h) = {(x,b)|h(x) \u2208 (b1, (1 + \u03b3)b1]} I4(h) = {(x,b)|h(x) > (1 + \u03b3)b1}\nThis sets represent the different regions where L\u03b3 is defined. In each region the function is affine. When the reference to h is clear we will simply denote this sets by I1, I2, I3 and I4. We will now prove a technical lemma necessary for the proof of Theorem 4.\nLemma 6. Under the conditions of Theorem 4,\nE x,b\n[ h\u2217\u03b3(x)1I2 ] \u2265 1 \u03b3 E x,b [ h\u2217\u03b3(x)1I3 ] .\nProof. Let 0 < \u03bb < 1, because \u2016\u03bbh\u2217\u03b3\u2016K < \u039b and because h\u2217\u03b3 is a minimizer we must have:\nEx,b [ L\u03b3(h \u2217 \u03b3(x),b) ] \u2264 Ex,b [ L\u03b3(\u03bbh \u2217 \u03b3(x),b) ] . (7)\nIf h\u2217(x) < 0, then L\u03b3(h\u2217(x),b) = L\u03b3(\u03bbh\u2217(x)) = \u2212b2 by definition. If on the other hand h\u2217(x) > 0, because \u03bbh\u2217\u03b3(x) < h \u2217 \u03b3(x) we must have that for (x,b) \u2208 I1(h\u2217\u03b3) L\u03b3(h\u2217\u03b3(x),b) = L\u03b3(\u03bbh \u2217 \u03b3(x),b) = \u2212b2 too. Also because L\u03b3 \u2264 0 and L\u03b3(h\u2217\u03b3(x),b) = 0 for (x,b) \u2208 I4(h\u2217\u03b3) it is immediate that L\u03b3(h\u2217\u03b3(x),b) \u2265 L\u03b3(\u03bbh\u2217\u03b3(x),b) for (x,b) \u2208 I4(h\u2217\u03b3). The following inequality then trivially holds:\nE x,b\n[ L\u03b3(h \u2217 \u03b3(x),b)(1I1 + 1I4) ] \u2265 E x,b [ L\u03b3(\u03bbh \u2217 \u03b3(x),b)(1I1 + 1I4) ] . (8)\nSubstracting (8) from (7) we obtain\nE x,b\n[ L\u03b3(h \u2217 \u03b3(x),b)(1I2 + 1I3) ] \u2264 E x,b [ L\u03b3(\u03bbh \u2217 \u03b3(x),b)(1I2 + 1I3) ] .\nBy rearranging terms we can see this inequality is equivalent to\nE x,b\n[ (L\u03b3(h \u2217 \u03b3(x),b)\u2212 L\u03b3(\u03bbh\u2217\u03b3(x),b))1I2 ] \u2264 E x,b [ (L\u03b3(\u03bbh \u2217 \u03b3(x),b)\u2212 L\u03b3(h\u2217\u03b3(x),b))1I3 ] (9)\nNotice that if (x,b) \u2208 I2(h\u2217\u03b3), then L\u03b3(h\u2217\u03b3(x),b) = \u2212h\u2217\u03b3(x). If \u03bbh\u2217\u03b3(x) > b2 too then L\u03b3(\u03bbh \u2217 \u03b3(x),b) = \u2212\u03bbh\u2217\u03b3(x). On the other hand if \u03bbh\u2217\u03b3(x) \u2264 b2 then L\u03b3(\u03bbh\u2217\u03b3(x),b) = \u2212b2 \u2264 \u2212\u03bbh\u2217\u03b3(x). Thus\n(L\u03b3(h \u2217 \u03b3(x),b)\u2212 L\u03b3(\u03bbh\u2217\u03b3(x),b))1I2 \u2265 (\u03bb\u2212 1)h\u2217\u03b3(x)1I2 (10)\nThis gives a lower bound for the left hand side of inequality (9). We will attempt to obtain an upper bound on the right hand side now. To do this we analyze two different cases: 1)\u03bbh\u2217\u03b3(x) \u2264 b1 and 2) \u03bbh\u2217\u03b3(x) > b 1.\nFor the first case we know that L\u03b3(h\u2217\u03b3(x),b) = 1 \u03b3 (h \u2217 \u03b3(x)\u2212(1+\u03b3)b1) > \u2212b1 (because (x,b) \u2208 I3). Furthermore if \u03bbh\u2217\u03b3(x) \u2264 b1 then by definitionL\u03b3(\u03bbh\u2217\u03b3(x),b) = min(\u2212b2,\u2212\u03bbh\u2217\u03b3(x)) \u2264 \u2212\u03bbh\u2217\u03b3(x). Thus, we must have:\nL\u03b3(\u03bbh \u2217 \u03b3(x),b)\u2212 L\u03b3(h\u2217\u03b3(x),b) < b1 \u2212 \u03bbh\u2217\u03b3(x) < (1\u2212 \u03bb)b1 \u2264 (1\u2212 \u03bb)M. (11)\nWhere we used the fact that h\u2217\u03b3(x) > b 1 for the second inequality.\nWe analyze the second case now. If \u03bbh\u2217\u03b3(x) > b 1, then for (x, b) \u2208 I3 we have L\u03b3(\u03bbh\u2217\u03b3(x),b) \u2212 L\u03b3(h \u2217 \u03b3(x),b) = 1 \u03b3 (\u03bb\u2212 1)h\u2217\u03b3(x). Thus we can bound the right hand side of (9) as:\nE x,b\n[ (L\u03b3(\u03bbh \u2217 \u03b3(x),b)\u2212 L\u03b3(h\u2217\u03b3(x),b))1I3 ] (12)\n= E x,b\n[ (L\u03b3(\u03bbh \u2217 \u03b3(x),b)\u2212 L\u03b3(h\u2217\u03b3(x),b))1I31{\u03bbh\u2217\u03b3(x)>b1} ] (13)\n+ E x,b\n[ (L\u03b3(\u03bbh \u2217 \u03b3(x),b)\u2212 L\u03b3(h\u2217\u03b3(x),b))1I31{\u03bbh\u2217\u03b3(x)\u2264b1} ] \u2264 \u03bb\u2212 1\n\u03b3 E x,b\n[ h\u2217\u03b3(x)1I3(\u03bbh\u2217\u03b3) ] + (1\u2212 \u03bb)BP [ h\u2217\u03b3(x) > b 1 \u2265 \u03bbh\u2217\u03b3(x) ]\n(14)\nWhere we have used (11) to bound the second summand. Combining inequalities (9), (10) and (14) and dividing by (\u03bb\u2212 1) we obtain the bound\nEx,b [ h\u2217\u03b3(x)1I2 ] \u2265 1 \u03b3 Ex,b [ h\u2217\u03b3(x)1I3(\u03bbh\u2217\u03b3) ] \u2212BP (h\u2217\u03b3(x) > b1 \u2265 \u03bbh\u2217\u03b3(x))\nWhere we have reverted the inequality since (\u03bb \u2212 1) < 0. Finally, taking the limit as \u03bb \u2192 1 we obtain\nEx,b [ h\u2217\u03b3(x)1I2 ] \u2265 1 \u03b3 Ex,b [ h\u2217\u03b3(x)1I3(h\u2217\u03b3) ] .\nWhere the passing of the limit inside the expectation is justified by the bounded convergence theorem and P (h\u2217\u03b3(x) > b 1 \u2265 \u03bbh\u2217\u03b3(x))\u2192 0 by the continuity of probability measures.\nWe now proceed to prove the original theorem.\nProof. Since the functions L and L\u03b3 agree everywhere except in I3, the following holds:\nE x,b\n[ L(h\u2217\u03b3(x),b)\u2212 L\u03b3(h\u2217\u03b3(x),b) ] = 4\u2211 k=1 E x,b [ (L(h\u2217\u03b3(x),b)\u2212 L\u03b3(h\u2217\u03b3(x),b))1Ik ] = E\nx,b\n[ (L(h\u2217\u03b3(x),b)\u2212 L\u03b3(h\u2217\u03b3(x),b))1I3 ] = E\nx,b [ 1 \u03b3 ((1 + \u03b3)b1 \u2212 h\u2217\u03b3(x))1I3) ] . (15)\nFurthermore, for (x,b) \u2208 I3 we know that b1 < h\u2217\u03b3(x). Hence, we can bound (15) by Ex,b[h\u2217\u03b3(x)1I3 ]. According to Lemma 6 this quantity is less than \u03b3 Ex,b [ h\u2217\u03b3(x)1I2 ] . Thus, we\ncan write\nE x,b\n[ L(h\u2217\u03b3(x),b) ] \u2212 E\nx,b\n[ L\u03b3(h \u2217 \u03b3(x),b) ] \u2264 \u03b3 E\nx,b\n[ h\u2217\u03b3(x)1I2 ] \u2264 \u03b3 E\nx,b\n[ b11I2 ] \u2264 \u03b3M.\nsince for (x,b) \u2208 I2 h\u2217\u03b3(x) \u2264 b1.\nNotice that, since L \u2265 L\u03b3 for all \u03b3 \u2265 0, it follows easily from the proposition that L\u03b3(h\u2217\u03b3) \u2192 L\u03b3(h\u2217). Where h\u2217 is the best hypothesis in class for the real loss. This shows that the loss L\u03b3 is indeed consistent.\nThe 1/\u03b3-Lipschitzness of L\u03b3 can be used to prove the following generalization bound (see supplementary material). Theorem 7. If \u03b3 \u2208 (0, 1] is fixed and S denotes a sample of size m, then for any \u03b4 > 0, with probability at least 1\u2212 \u03b4 over the choice of the sample S\nL\u03b3(h) \u2264 L\u0302\u03b3(h) + 2\n\u03b3 Rm(H) +M \u221a log 1\u03b4 2m , (16)\nfor all h \u2208 H . The theorem can be used to derive a learning bound that holds uniformly for all \u03b3 \u2208 (0, 1], at the price of an additional term of the form O( \u221a log log(1/\u03b3)/m) (see Corollary 13 in the Appendix). These results are reminiscent of the standard margin bounds with \u03b3 playing the role of a margin. The situation here is however somewhat different. Our learning bounds suggest, for a fixed \u03b3 \u2208 (0, 1], to seek a hypothesis h minimizing the empirical loss L\u0302\u03b3(h) while controlling a complexity term upper bounding Rm(H), which in the case of a family of linear hypotheses could be \u2016h\u20162K for some PSD kernel K. Since the bound of Corollary 13 holds uniformly for all \u03b3, we can use it to select \u03b3 out of a finite set of possible grid search values. Alternatively, \u03b3 can be set via cross-validation.\nWe conclude this section with a stronger consistency result than Theorem 4 presenting a stronger form of consistency. We will show that we can lower bound the risk of the best hypothesis in class L\u2217 := L(h\u2217). By the risk of the empirical minimizer of L\u03b3 , h\u0302\u03b3 := argmin\u2016h\u2016K L\u0302\u03b3(h). Theorem 8. Let M = supb\u2208B b1 and let H be a hypothesis set with pseudo-dimension d = Pdim(H). Then for any \u03b4 > 0 and a fixed value of \u03b3 > 0, with probability at least 1 \u2212 \u03b4 over the choice of a sample S of size m, the following inequality holds:\nL(h\u0302\u03b3) \u2264 L\u2217 + 2\u03b3 + 2\n\u03b3 Rm(H) + \u03b3M2M\n\u221a 2d log md\nm + 2M \u221a log 2\u03b4 2m\nProof. According to Theorem 3 with probability at least 1\u2212 \u03b4/2 the following is true:\nL(h\u0302\u03b3) \u2264 L\u0302S(h\u0302\u03b3) + 2Rm(H) + 2M \u221a\n2d log md m +M \u221a log 2\u03b4 2m . (17)\nFurthermore, applying Lemma 6 for the empirical measure induced by the sample we can bound L\u0302S(h\u0302\u03b3) by L\u0302\u03b3(h\u0302\u03b3)+\u03b3M . The first term of the previous expression is less than L\u0302\u03b3(h\u2217\u03b3) by definition of h\u0302\u03b3 . Finally, the same analysis used in Theorem 7 shows that with probability 1\u2212 \u03b4/2\nL\u0302\u03b3(h\u2217\u03b3) \u2264 L\u03b3(h\u2217\u03b3) + 2\n\u03b3 Rm(H) +M \u221a log 2\u03b4 2m .\nAgain, by definition of h\u2217\u03b3 we know that L\u03b3(h\u2217\u03b3) \u2264 L\u03b3(h\u2217) \u2264 L(h\u2217). Where the last inequality is true since L is an upperbound on L\u03b3 . Hence\nL\u0302S(h\u0302\u03b3) \u2264 L(h\u2217\u03b3) + 1\n\u03b3 Rm(H) +M \u221a log 2\u03b4 2m + \u03b3M. (18)\nUsing the union bound and combining inequalities (17) and (18) we obtain the result.\nThis bound can be made to hold uniformly on \u03b3 as in Corollary 13. Thus, we have shown that for appropiate choices of \u03b3 and m (for instance \u03b3 1/m1/4) we have convergence of L\u03b3(h\u0302\u03b3) to L\u2217, which is a stronger form of consistency."}, {"heading": "4 Algorithms", "text": "In this section we present algorithms for solving the optimization problem for selecting the reserve price. We start with no-feature case and then treat the general case."}, {"heading": "4.1 No feature case", "text": "We present a general algorithm to optimize sums of functions similar to L\u03b3 or L in the onedimensional case.\nDefinition 9. We will say that function V : R+ \u00d7 B \u2192 R is a v-function if it admits the following form: V (r,b) = \u2212a11r\u2264b2 \u2212 a2r1b2<r\u2264b1 + (a3r \u2212 a4)1b1<r<(1+\u03b7)b1 , with a1 > 0 and \u03b7 > 0 constants and a1, a2, a4 defined by a1 = \u03b7a3b2, a2 = \u03b7a3, and a4 = a3(1 + \u03b7)b1.\nFigure 4(a) illustrates this family of loss functions. A v-function is a generalization of L\u03b3 . Indeed, any v-function V satisfies V (r,b) \u2264 0 and attains its minimum at b1. Finally, as can be seen straightforwardly from Figure 3, L\u03b3 is a v-function for any \u03b3 \u2265 0. We consider the following general problem of minimizing a sum of v-functions:\nmin r\u22650 F (r) := m\u2211 i=1 Vi(r,bi). (19)\nObserve that this is not a trivial problem since, for any fixed bi, Vi(\u00b7,bi) is non-convex and that, in general, a sum of m such functions may admit many local minima. The following proposition shows that the minimum is attained at one of the highest bids, which matches the intuition.\nProposition 10. Problem (19) admits a solution r\u2217 that satisfies r\u2217 = b1i for some i \u2208 [1,m].\nThe problem can thus be reduced to examining the value of the function for the m arguments b1i , i \u2208 [1,m]. This yields a straightforward method for solving the optimization which consists of computing F (b1i ) for all i and taking the minimum. But, since the computation of each F (b 1 i ) takes O(m), the overall computational cost is in O(m2), which can be prohibitive for even moderately large values of m.\nInstead, we have devised a more efficient combinatorial algorithm that can be used to solve the problem in O(m logm) time. The algorithm consists of first sorting all boundary points, that is the points in N = \u22c3i{b1i , b2i , (1 + \u03b7)b1i } associated with the functions Vi(\u00b7,bi), i \u2208 [1,m]. We then show that for the ordered sequence (n1, . . . , n3m), F (nk+1) can be computed from F (nk) in constant time, using the fact that Vi(\u00b7, bi) can only change at boundary points (see Figure 4(b)). A more detailed description and the proof of the correctness of the algorithm are given in the Appendix.\nFurthermore, the algorithm can be straightforwardly extended to solve the minimization of F over a set of r-values bounded by \u039b, that is {r : 0 \u2264 r \u2264 \u039b}. Indeed, we then only need to compute F (b1i ) for i \u2208 [1,m] such that b1i < \u039b and of course also F (\u039b), thus the computational complexity in that regularized case remains O(m logm).\nProposition 11. There exists an algorithm to solve the optimization problem (19) in O(m logm).\nProof. The pseudocode for the desired algorithm is presented in Algorithm 1. Where a1i , ..., a 4 i denote the parameters defining the functions Vi(r,bi).\nAlgorithm 1 Sorting N := \u22c3mi=1{b1i , b2i , (1 + \u03b7)b1i }; (n1, ..., n3m) =Sort(N ); Set ci := (c1i , c 2 i , c 3 i , c 4 i ) = 0 for i = 1, ..., 3m;\nSet c11 = \u2212 \u2211m i=1 a 1 i ; for j = 2, ..., 3m do Set cj = cj\u22121; if nj\u22121 = b2i for some i then c1j = c 1 j + a 1 i ;\nc2j = c 2 j \u2212 a2i ;\nelse if nj\u22121 = b1i for some i then c2j = c 1 j + a 2 i ;\nc3j = c 3 j + a 3 i ; c4j = c 1 j \u2212 a4i ;\nelse c3j = c 3 j \u2212 a3i ;\nc4j = c 1 j + a 4 i ;\nend if end for\nWe will prove that after running the algorithm 1 we can evaluate F (nj) in constant time in the following way:\nF (nj) = c 1 j + c 2 jnj + c 3 jnj + c 4 j . (20) This trivial for n1 as by construction n1 \u2264 b2i for all i and by definition then F (n1) = \u2212 \u2211m i=1 a 1 i . Now assume that equation (20) is true for j, we prove that then it must be true for j + 1. Suppose nj = b 2 i for some i (the cases nj = b 1 i and nj = (1 + \u03b7)b 1 i can be handled in the same way). Then Vi(nj ,bi) = \u2212a1i and we can write\u2211 k 6=i Vk(nj ,bk) = F (nj)\u2212 V (nj ,bi) = (c1j + c2jnj + c3jnj + c4j ) + a1i .\nThus, by construction we would have:\nc1j+1 + c 2 j+1nj+1 + c 3 j+1nj+1 + c 4 j+1 = c 1 j + a 1 i + (c 2 j \u2212 a2i )nj+1 + c3jnj+1 + c4j\n= (c1j + c 2 jnj+1 + c 3 jnj+1 + c 4 j ) + a 1 i \u2212 a2inj+1 = \u2211 k 6=i Vk(nj+1,bk)\u2212 a2inj+1,\nwhere the last equality holds since the definition of Vk(r,bk) does not change for r \u2208 [nj , nj+1]. Finally, since nj was a boundary point, the definition of Vi(r,bi) must change from \u2212a1i to \u2212a2i r, thus the last equation is indeed equal to F (nj+1) as we wanted. The reader should be convinced that a similar argument can be given if nj = b1i or nj = (1 + \u03b7)b 1 i . Let us analyze the complexity of the algorithm: sorting the set N can be done in O(m logm) whereas every iteration of the cycle takes constant time. Thus the evaluation of all points can be done in linear time. Once all evaluations are done, finding the minimum can again be done in linear time. Hence the total complexity of the algorithm is O(m logm)."}, {"heading": "4.2 General case", "text": "We first consider the case of a hypothesis set H of linear functions x 7\u2192 w \u00b7 x with bounded norm, \u2016w\u2016 \u2264 \u039b, for some \u039b \u2265 0. This is not a loss of generality since for any kernel K, we can consider hypotheses of the form h = \u2211n i=1 \u03b1iK(xi, \u00b7) which is a linear function of \u03b1. Thus any result in this section can be extended to arbitrary PSD kernels.\nThe results of Theorem 7 and Corollary 13 suggest seeking, for a fixed \u03b3 \u2265 0, the vector w solution of the following optimization problem: min\u2016w\u2016\u2264\u039b \u2211m i=1 L\u03b3(w \u00b7xi,bi). Replacing the original loss L with L\u03b3 helped us remove the discontinuity of the loss. But, we still face an optimization problem based on a sum of non-convex functions. This problem can be formulated as a DC-programming (difference of convex functions programming) problem. Indeed, L\u03b3 can be decomposed as follows for all (r,b) \u2208 X \u00d7 B: L\u03b3(r,b) = u(r,b)\u2212 v(r,b), with the convex functions u and v defined by\nu(r,b) = \u2212r1r<b1 + r \u2212 (1 + \u03b3)b1\n\u03b3 1r\u2265b1\nv(r,b) = (\u2212r + b2)1r<b2 + r \u2212 (1 + \u03b3)b1\n\u03b3 1r>b1 .\nUsing the decomposition L\u03b3 = u\u2212 v, our optimization problem can be formulated as follows: min w\u2208RN U(w)\u2212 V (w) subject to \u2016w\u2016 \u2264 \u039b, (21)\nwhere U(w) = \u2211m i=1 u(w \u00b7 xi,bi) and V (w) = \u2211m i=1 v(w \u00b7 xi,bi), which shows it can be formulated as a DC-programming problem. The global minimum of the optimization problem (21) can be found using a cutting plane method [9], but that method only converges in the limit and does not admit known algorithmic convergence guarantees.4 There exists also a branch-and-bound algorithm with exponential convergence for DC-programming [9] for finding the global minimum. Nevertheless, in [20], it is pointed out that this type of combinatorial algorithms fail to solve real life DC programs in high dimensions. In fact our implementation of this algorithm shows that the convergence of the algorithm in practice is extremely slow for even moderately high-dimensional problems. An other attractive solution for finding the global solution of a DC-programming problem over a polyhedral convex set is the combinatorial solution of Hoang Tuy [22]. However, casting the problem as an instance of that problem requires in our context explicitly specifying the slope and offsets for the piecewise linear function corresponding to a sum of L\u03b3 losses, which requires exponential time and space.\nAn alternative consists of using the DC algorithm, a primal-dual sub-differential method of Dinh Tao and Hoai An [21], (see also [20] for a good survey). This algorithm is applicable when u and v are proper lower semi-continuous convex functions as in our case. When v is differentiable, the DC algorithm coincides with the CCCP algorithm of Yuille and Rangarajan [27], which has been used in several contexts in machine learning and analyzed by [19].\nThe general proof of convergence of the DC algorithm was given by [21]. In some special cases, the DC algorithm can be used to find the global minimum of the problem as in the trust region problem [21], but, in general, the DC algorithm or its special case CCCP are only guaranteed to converge to a local minimum [21, 19]. Nevertheless, the number of iterations of the DC algorithm is relatively small. Its convergence has been shown to be in fact linear for DC-programming problems such as ours [26].\nThe algorithm we are proposing goes one step further than that of [21]: we use DCA to find a local minimum but then restart our algorithm with a new seed that is guaranteed to reduce the objective function. Unfortunately, we are not in the same regime as in the trust region problem of Dinh Tao and Hoai An [21] where the number of local minima is linear in the size of the input. Indeed, here the number of local minima can be exponential in the number of dimensions of the feature space and it is not clear to us how the combinatorial structure of the problem could help us rule out some local minima faster and make the optimization more tractable.\n4Some claims of [9], e.g., Proposition 4.4 used in support of the cutting plane algorithm, are incorrect [23].\nIn the following, we describe more in detail the solution we propose for solving the DCprogramming problem (21). The functions v and V are not differentiable in our context but they admit a sub-gradient at all points. We will denote by \u03b4V (w) an arbitrary element of the sub-gradient \u2202V (w), which coincides with\u2207V (w) at points w where V is differentiable. The DC algorithm then coincides with CCCP, modulo the replacement of the gradient of V by \u03b4V (w). It consists of starting with a weight vector w0 \u2264 \u039b and of iteratively solving a sequence of convex optimization problems obtained by replacing V with its linear approximation giving wt as a function of wt\u22121, for t = 1, . . . , T : wt \u2208 argmin\u2016w\u2016\u2264\u039b U(w) \u2212 \u03b4V (wt\u22121) \u00b7w. This problem can be rewritten in our context as the following:\nmin \u2016w\u2016\u2264\u039b,s m\u2211 i=1 si \u2212 \u03b4V (wt\u22121) \u00b7w (22)\nsubject to (si \u2265 \u2212w \u00b7 xi) \u2227 [ si \u2265 1\n\u03b3\n( w \u00b7 xi \u2212 (1 + \u03b3)b1i )] .\nThe problem is equivalent to a QP (quadratic-programming) problem since the quadratic constraint can be replaced by a term of the form \u03bb\u2016w\u20162 in the objective and thus can be tackled using any standard QP solver. We propose an algorithm that iterates along different local minima, but with the guarantee of reducing the function at every change of local minimum. The algorithm is simple and is based on the observation that the function L\u03b3 is positive homogeneous: for any \u03b7 > 0 and (r,b),\nL\u03b3(\u03b7r, \u03b7b) = \u2212\u03b7b21\u03b7r<\u03b7b2 \u2212 \u03b7r1\u03b7b2\u2264\u03b7r\u2264\u03b7b1\n+ \u03b7r \u2212 (1 + \u03b3)\u03b7b1\n\u03b3 1\u03b7b1<\u03b7r<\u03b7(1+\u03b3)b1 = \u03b7L\u03b3(r,b).\nMinimizing the objective function of (21) in a fixed direction u, \u2016u\u2016 = 1, can be reformulated as follows: min0\u2264\u03b7\u2264\u039b \u2211m i=1 L\u03b3(\u03b7u \u00b7 xi,bi). Since for u \u00b7 xi \u2264 0 the function \u03b7 \u2192 L\u03b3(\u03b7u \u00b7 xi,bi)\nis constant equal to \u2212b2i the problem is equivalent to solving min0\u2264\u03b7\u2264\u039b \u2211\nu\u00b7xi>0 L\u03b3(\u03b7u \u00b7 xi,bi). Moreover, because L\u03b3 is positive homogeneous, for all i \u2208 [1,m] with u \u00b7xi > 0, L\u03b3(\u03b7u \u00b7xi,bi) = (u \u00b7 xi)L\u03b3(\u03b7,bi/(u \u00b7 xi)). But \u03b7 7\u2192 L\u03b3(\u03b7,bi/(u \u00b7 xi)) is a v-function and thus the problem can efficiently optimized using the combinatorial algorithm for the no-feature case (Section 4.1). This leads to the optimization algorithm shown in Figure 5. The last step each iteration of our algorithm can be viewed as a line search and this is in fact the step that reduces the objective function the most in practice. This is because we are then precisely minimizing the objective function even though this is for some fixed direction. Since in general this line search does not find a local minimum (we are likely to decrease the objective value in other directions that are not the one in which the line search was performed) running DCA helps us find a better direction for the next iteration of the line search."}, {"heading": "5 Experiments", "text": "Here, we report the results of some preliminary experiments demonstrating the benefits of our algorithm. All of our experiments are done on synthetic data, this is becasue despite the fact that experiments with data from online auctions exist in the literature [6], this data is not available to the public for confidentiality reasons. To the best of our knowledge no publicly available data set is available for online auctions and none has available features.\nThe first test we perform evaluates the speed of our algorithm in the simple non-feature case. Figure 6 depicts the time needed for our sorting algorithm to find the optimal solution compared to the na\u0131\u0308ve approach of evaluating the loss at each point on a 4-Core 2.6 GHz AMD processor with 7GB of RAM. The time our algorithm takes to solve the problem with 2000 points is less than a second, whereas the na\u0131\u0308ve approach required more than 10 minutes to find the solution. This shows the potential for scalability of our algorithm. Running our algorithm to solve the problem using 20,000 points required only 2.26 seconds.\nSince there is no published baseline to compare our algorithm with when using features, we instead present the results of experiments carried out with different loss functions. We propose the following experimental setup: points xi are sampled from a standard Gaussian distribution in R200. A \u201clabeling\u201d vector w \u2208 R200, also sampled from a standard Gaussian, is used to generate bi = (|w \u00b7 xi|, 12 |w \u00b7 xi|). Notice that the use of the absolute value makes the dependency between\nfeatures and bids no longer linear. This setup does not introduce any noise in the bids, we deal with this scenario later on.\nWe compare our algorithm against three other natural ways of solving this problem.\n1. Using ridge regression to learn the highest bid b1. 2. Using the convex surrogate depicted in Figure 1(b):\nL\u03b1(r,b) =\n{ \u2212r r < b1 + \u03b1(b2 \u2212 b1)(\n(1\u2212\u03b1)b1+\u03b1b2 \u03b1(b1\u2212b2)\n) (r \u2212 b1) otherwise.\n3. Minimizing the loss ignoring the values of xi, i.e. solve the following problem minr\u2264\u039b \u2211n i=1 L(r,bi).\nIt is worth mentioning that the third approach is really similar to what advertisement exchanges currently do to suggest reserve prices to publishers. In fact, in view of equation (1), this is equivalent to estimating the empirical distribution of bids and optimizing the expected revenue with respect to this empirical distribution as it is done in [17] and [5].\nFor all our experiments, the parameters \u039b, \u03b3 and \u03b1 were tuned via 10-fold cross validation. The test set was a collection of 20, 000 examples drawn from the same distribution. The experiment was repeated 20 times and the results shown in Figure 7 are the mean performance of each learning algorithm.\nBecause the algorithm presented in this paper converges to a local minimum, the choice of a good starting point is important. The initial point used here was the solution to\nmin \u2016w\u2016\u2264\u039b n\u2211 i=1 L\u03b1(w \u00b7 xi,bi).\nBecause the square loss used in ridge regression is clearly not calibrated with respect to L (it is symmetric around b1 whereas L is not), we would expect the performance of this algorithm to be bad. Indeed, it can be seen in Figure 7 that the test error is in fact the worst of the four algorithms. What is surprising is that all the competing algorithms behave in a similar way for big values of m. This emprical evaluation supports the argument against convex surrogate losses presented in Section 3.1, it also presents a convincing argument in favor of the use of features.\nBy using our better calibrated loss L\u03b3 we see an improvement on performance of as much as 30% . This results are impressive considering that we are optimizing a non-convex function with potentially an exponential number of local minima.\nWe also present results on the performance of the DC algorithm as a function of the parameter \u03b3. As the theory suggestes, smaller values of \u03b3 account for a greater variance whereas greater values of \u03b3 reduce the variance of the test error but on average perform worse. Our algorithm also converges faster for bigger values of \u03b3. This is also expected because a greater value of \u03b3 makes the function L\u03b3 smoother and hence easier to optimize.\nFinally, to analyze how our algorithm performs in the presence of noise we sampled the feature vectors xi from a uniform distribution in the cube [0, 1]50 we chose our \u201clabeling\u201d functions to be w1 =\n1\u221a 50 1, where 1 is the vector with all coordinates equal to 1 and w2 = 12w1. The bids for our\nexperiments are generated as follows: b1i = max ( (w1 \u00b7 xi + \u03c3 )+, (wT2 \u00b7 xi + \u03c3 )+ ) b2i = min ( (w1 \u00b7 xi + \u03c3 )+, (w2 \u00b7 xi + \u03c3 )+ ) ,"}, {"heading": "100 10\u22121 10\u22122 10\u22123 10\u22124 10\u22125", "text": "size 6400\n\u03c3 0 .1 .2 .3 .4 .5\nwhere z+ := max(z, 0), \u223c N (0, 1) is a Gaussian random variable, and \u03c3 takes values in the set {0, .1, . . . , .5}.. We measured the performance of our learning algorithm as a function of the noise added to the features. Our algorithm was trained on a sample of size 8,000 points and tested on a sample of 8,000 points. Table 1 shows the mean revenue for different algorithm. The first row corresponds to the case where no reserve price is set. The second row represents the revenue made when using our simple sorting algorithm that ignores the feature vectors. Row three shows the performance of our algorithm and the last row shows the maximal possible mean revenue, i.e. the mean of the highest bids. The results of Table 1 show that in the separable case our algorithm achieves perfect performance, as it was expected. Furthermore, when using features to learn, the revenue obtained is increased by 20%, confirming the idea that learning with with features is beneficial.\nAs the amount of noise increases in the sample, the features become less relevant and the improvement in performance becomes smaller but never zero. This problem affects all learning algorithms, as no learning algorithm can perform well if the features are irrelevant to the learning task at hand."}, {"heading": "6 Conclusion", "text": "We presented a comprehensive theoretical and algorithmic analysis of the learning problem of revenue optimization in second-price auctions with reserve. The specific properties of the loss function for this problem required a new analysis and new learning guarantees. The algorithmic solutions we presented are practically applicable to revenue optimization problems for this type of auctions in most realistic settings. Our experimental results further demonstrate their effectiveness. Much of the analysis, in particular our calibration study, and algorithms presented can also be of interest in other learning areas."}, {"heading": "Acknowledgments", "text": "We thank Afshin Rostamizadeh and Umar Syed for numerous discussions about the topic of this work.This work was partly funded by the NSF award IIS-1117591."}, {"heading": "A Proofs for learning guarantees", "text": "A.1 Contraction lemma\nThe following is a version of Talagrand\u2019s contraction lemma [11]. Since our definition of Rademacher complexity does not use absolute values as in [11], we give an explicit proof below.\nLemma 12. Let H be a hypothesis set of functions mapping X to R and \u03a81, . . . ,\u03a8m, \u00b5-Lipschitz functions for some \u00b5 > 0. Then, for any sample S of m points x1, . . . , xm \u2208 X , the following inequality holds\n1 m E \u03c3 [ sup h\u2208H m\u2211 i=1 \u03c3i(\u03a8i \u25e6 h)(xi) ] \u2264 \u00b5 m E \u03c3 [ sup h\u2208H m\u2211 i=1 \u03c3ih(xi) ] = \u00b5 R\u0302S(H).\nProof. The proof is similar to the case where the functions \u03a8i are all equal. Fix a sample S = (x1, . . . , xm). Then, we can rewrite the empirical Rademacher complexity as follows:\n1 m E \u03c3 [ sup h\u2208H m\u2211 i=1 \u03c3i(\u03a8i \u25e6 h)(xi) ] = 1 m E \u03c31,...,\u03c3m\u22121 [ E \u03c3m [ sup h\u2208H um\u22121(h) + \u03c3m(\u03a8m \u25e6 h)(xm) ]] ,\nwhere um\u22121(h) = \u2211m\u22121 i=1 \u03c3i(\u03a8i \u25e6h)(xi). Assume that the suprema can be attained and let h1, h2 \u2208 H be the hypotheses satisfying\num\u22121(h1) + \u03a8m(h1(xm)) = sup h\u2208H um\u22121(h) + \u03a8m(h(xm))\num\u22121(h2)\u2212\u03a8m(h2(xm)) = sup h\u2208H um\u22121(h)\u2212\u03a8m(h(xm)).\nWhen the suprema are not reached, a similar argument to what follows can be given by considering instead hypotheses that are -close to the suprema for any > 0.\nBy definition of expectation and because \u03c3m is uniform in {\u22121,+1} we have\nE \u03c3m [ sup h\u2208H um\u22121(h) + \u03c3m(\u03a8m \u25e6 h)(xm) ]\n= [1\n2 sup h\u2208H\num\u22121(h) + (\u03a8m \u25e6 h)(xm) + 1\n2 sup h\u2208H\num\u22121(h)\u2212 (\u03a8m \u25e6 h)(xm) ]\n= 1\n2 [um\u22121(h1) + (\u03a8m \u25e6 h1)(xm)] +\n1 2 [um\u22121(h2)\u2212 (\u03a8m \u25e6 h2)(xm)].\nLet s = sgn(h1(xm)\u2212 h2(xm)). Then, the previous equality implies\nE \u03c3m [ sup h\u2208H um\u22121(h) + \u03c3m(\u03a8m \u25e6 h)(xm) ]\n= 1\n2 [um\u22121(h1) + um\u22121(h2) + s\u00b5(h1(xm)\u2212 h2(xm))]\n= 1\n2 [um\u22121(h1) + s\u00b5h1(xm)] +\n1 2 [um\u22121(h2)\u2212 s\u00b5h2(xm)]\n\u2264 1 2 sup h\u2208H [um\u22121(h) + s\u00b5h(xm)] + 1 2 sup h\u2208H [um\u22121(h)\u2212 s\u00b5h(xm)]\n= E \u03c3m [ sup h\u2208H um\u22121(h) + \u03c3m\u00b5h(xm) ] .\nWhere we have used the fact that \u03a8m is \u00b5\u2212Lipchitz for the first equality , whereas the last equality is true by definition of expectation over \u03c3m.\nProceeding in the same way for all other \u03c3is (i 6= m) proves the lemma.\nA.2 Margin bounds\nTheorem 7. If \u03b3 \u2208 (0, 1] is fixed and S denotes a sample of size m, then for any \u03b4 > 0, with probability at least 1\u2212 \u03b4 over the choice of the sample S\nL(h) \u2264 L\u0302\u03b3(h) + 2\n\u03b3 Rm(H) +M \u221a log 1\u03b4 2m , (23)\nfor all h \u2208 H .\nProof. Let L\u03b3,H denote the family of functions {(x,b)\u2192 L\u03b3(h(x), b) : h \u2208 H}. The loss function L\u03b3 is 1\u03b3 -Lipschitz since the slope of the lines defining it is at most 1 \u03b3 . Thus, using the contraction lemma (Lemma 12) as in the proof of Proposition 1 gives Rm(L\u03b3,H) \u2264 1\u03b3Rm(H). The application of a standard Rademacher complexity bound to the family of functions L\u03b3,H then shows that for any \u03b4 > 0, with probability at least 1\u2212 \u03b4, for any h \u2208 H , the following holds:\nL\u03b3(h) \u2264 L\u0302\u03b3(h) + 2\n\u03b3 Rm(H) +M \u221a log 1\u03b4 2m .\nCorollary 13. For any \u03b4 > 0, with probability at least 1 \u2212 \u03b4 over the choice of a sample S of size m, the following holds for all \u03b3 \u2208 (0, 1] and h \u2208 H:\nL\u03b3(h) \u2264 L\u0302\u03b3(h) + 2\n\u03b3 Rm(H) +M K(\u03b3)\u221a m + \u221a log 1\u03b4 2m  . (24) With K(\u03b3) = \u221a log log2 1/\u03b3.\nProof. Consider two sequences (\u03b3k)k\u22651 and ( k)k\u22651, with k \u2208 (0, 1). By theorem 7, for any fixed k \u2265 1,\nP [ L(h)\u2212 L\u0302\u03b3k(h)> 2\n\u03b3k Rm(H) +M k\n] \u2264 exp(\u22122m 2k). (25)\nChoose k = + \u221a log k m , then, by the union bound,\nP [ \u2203k : L(h)\u2212 L\u0302\u03b3k(h) > 1\n\u03b3k Rm(H) +M k ] \u2264 \u2211 k\u22651 exp [ \u2212 2m( + \u221a (log k)/m)2 ] \u2264 (\u2211 k\u22651 1/k2 ) exp(\u22122m 2)\n= \u03c02\n6 exp(\u22122m 2) \u2264 2 exp(\u22122m 2).\nFor any \u03b3 \u2208 (0, 1], there exists k \u2265 1 such that \u03b3 \u2208 (\u03b3k, \u03b3k\u22121) with \u03b3k = 1/2k. For such a k, 1 \u03b3k\u22121 \u2264 1\u03b3 , \u03b3k\u22121 \u2264 \u03b3 2 , and \u221a log(k \u2212 1) = \u221a log log2(1/\u03b3k\u22121) \u2264 \u221a log log2(1/\u03b3). Since for any h \u2208 H , L\u03b3k\u22121(h) \u2264 L\u03b3(h), we can write\nP [ \u2203k : L(h)\u2212L\u0302\u03b3(h)> 2\n\u03b3 Rm(H)+M\n( K(\u03b3) + )] \u2264 exp(\u22122m 2),\nwhich concludes the proof."}, {"heading": "B Combinatorial algorithm", "text": "B.1 Solution property\nWe will show that problem (19) admits a solution r\u2217 = b1i for some i. We will need the following definition. Definition 14. For a value of r \u2208 R, define the following subset of R:\n\u2126(r) = { |r < b1i \u2194 r + \u2264 b1i }\nWe will drop the dependency on r when it is understood what value of r we are referring to. Lemma 15. Let r 6= b1i for all i. If > 0 is such that [\u2212 , ] \u2282 \u2126(r) then F (r + ) < F (r) or F (r \u2212 ) \u2264 F (r). The condition that r 6= b1i for all i implies that there exists small enough that satisfies \u2208 \u2126(r).\nProof. Let vi = Vi(r,bi) and vi( ) = Vi(r+ ,bi). For \u2208 \u2126(r) define the setsD( ) = {i | vi( ) \u2264 vi} and I( ) = {i | vi( ) > vi}. If\u2211\ni\u2208D( ) vi + \u2211 i\u2208I( ) vi > \u2211 i\u2208D( ) vi( ) + \u2211 i\u2208I( ) vi( )\nThen by definition, F (r) > F (r + ) and the result is proven. If this inequality is not satisfied, then by grouping indices in D( ) and I( ) we must have that\u2211\ni\u2208D( ) vi \u2212 vi( ) \u2264 \u2211 i\u2208I( ) vi( )\u2212 vi (26)\nNotice that vi( ) \u2264 vi if and only if vi(\u2212 ) \u2265 vi. Indeed, the function Vi(r + \u03b7,bi) is monotone for \u03b7 \u2208 [\u2212 , ] as long as [\u2212 , ] \u2282 \u2126 which is true by the choice of . This fact can easily be seen in Figure 8. Hence D( ) = I(\u2212 ), similarly I( ) = D(\u2212 ) Furthermore, because Vi(r + \u03b7,bi) is also concave for \u03b7 \u2208 [\u2212 , ]. We must have\n1 2 (vi(\u2212 ) + vi( )) \u2264 vi. (27)\nFrom equation (27) we can obtain the following inequalities:\nvi(\u2212 )\u2212 vi \u2264 vi \u2212 vi( ) for i \u2208 D( ) (28) vi( )\u2212 vi \u2264 vi \u2212 vi(\u2212 ) for i \u2208 I( ) (29)\nCombining inequalities (28), (26) and (29) we obtain\u2211 i\u2208I(\u2212 ) vi(\u2212 )\u2212 vi \u2264 \u2211 i\u2208D(\u2212 ) vi \u2212 vi(\u2212e).\nBy rearranging the terms in the inequality we can easily see that F (r \u2212 ) \u2264 F (r). Lemma 16. Under the conditions of Lemma 15, if F (r + ) \u2264 F (r) then F (r + \u03bb ) \u2264 F (r) for every \u03bb that satisfies \u03bb \u2208 \u2126 if and only if \u2208 \u2126.\nProof. The proof follows the same ideas used in the previous lemma. By hypothesis we know that\u2211 D( ) vi \u2212 vi( ) \u2265 \u2211 i\u2208I( ) vi( )\u2212 vi. (30)\nIt is also clear that I( ) = I(\u03bb ) and D( ) = D(\u03bbe). Furthermore, the same concavity argument of lemma 15 also yields:\nvi( ) \u2265 \u03bb\u2212 1 \u03bb vi + 1 \u03bb vi(\u03bb ). (31)\nApplying inequality (31) in (30) we obtain\n1\n\u03bb \u2211 D(\u03bb ) vi \u2212 vi(\u03bb ) \u2265 1 \u03bb \u2211 I(\u03bb ) vi(\u03bb )\u2212 vi\nBecause \u03bb > 0 we can multiply the inequality by \u03bb to get an inequality similar to (30) which implies that F (r + \u03bb ) \u2264 F (r).\nProposition 10. Problem (19) admits a solution r\u2217 that satisfies r\u2217 = b1i for some i \u2208 [1,m].\nProof. Let r 6= b1i for every i. By Lemma 15, we can choose 6= 0 small enough with F (r + ) \u2264 F (r). Furthermore if \u03bb = mini b 1 i\u2212r | | then \u03bb satisfies the hypotheses of Lemma 16. Hence, F (r) \u2265 F (r + \u03bb ) = F (bi\u2217), where i\u2217 is the minimizer of b 1 i\u2212r ."}], "references": [], "referenceMentions": [], "year": 2017, "abstractText": "Second-price auctions with reserve play a critical role for modern search engine<lb>and popular online sites since the revenue of these companies often directly de-<lb>pends on the outcome of such auctions. The choice of the reserve price is the<lb>main mechanism through which the auction revenue can be influenced in these<lb>electronic markets. We cast the problem of selecting the reserve price to optimize<lb>revenue as a learning problem and present a full theoretical analysis dealing with<lb>the complex properties of the corresponding loss function. We further give novel<lb>algorithms for solving this problem and report the results of several experiments<lb>demonstrating their effectiveness.", "creator": "LaTeX with hyperref package"}}}