{"id": "1401.3865", "review": {"conference": "arxiv", "VERSION": "v1", "DATE_OF_SUBMISSION": "16-Jan-2014", "title": "Evaluating Temporal Graphs Built from Texts via Transitive Reduction", "abstract": "temporal reconstruction information recovery has been widely the fundamental focus of its recent attention in information extraction, leading to addressing some standardization standards effort, in itself particular for describing the procedural task of relating visual events in a text. this task raises the problem of closely comparing two annotations accurately of a comparable given text, just because relations between events in a story are otherwise intrinsically substantially interdependent and cannot be evaluated any separately. selecting a relative proper evaluation measure is traditionally also crucial in probing the context of distinguishing a machine learning approach approaches to the problem. any finding accurately a common comparison referent at the text accessibility level is likely not relatively obvious, and we argue here in detail favor possibility of a shift from event - resolution based measures to textual measures aiming on deciding a unique or textual temporal object, a minimal underlying literal temporal graph, or maybe more formally the transitive reduction of the graph knowledge of relations established between event matching boundaries. we support it properly by leading an acute investigation of its properties especially on synthetic everyday data and on a well - rounded know universal temporal corpus.", "histories": [["v1", "Thu, 16 Jan 2014 05:05:45 GMT  (546kb)", "http://arxiv.org/abs/1401.3865v1", null]], "reviews": [], "SUBJECTS": "cs.CL cs.IR", "authors": ["xavier tannier", "philippe muller"], "accepted": false, "id": "1401.3865"}, "pdf": {"name": "1401.3865.pdf", "metadata": {"source": "CRF", "title": "Evaluating Temporal Graphs Built from Texts via Transitive Reduction", "authors": ["Xavier Tannier", "Philippe Muller"], "emails": ["XTANNIER@LIMSI.FR", "MULLER@IRIT.FR"], "sections": [{"heading": null, "text": "some standardization effort, in particular for the task of relating events in a text. This task raises the problem of comparing two annotations of a given text, because relations between events in a story are intrinsically interdependent and cannot be evaluated separately. A proper evaluation measure is also crucial in the context of a machine learning approach to the problem. Finding a common comparison referent at the text level is not obvious, and we argue here in favor of a shift from eventbased measures to measures on a unique textual object, a minimal underlying temporal graph, or more formally the transitive reduction of the graph of relations between event boundaries. We support it by an investigation of its properties on synthetic data and on a well-know temporal corpus."}, {"heading": "1. Introduction", "text": "Temporal processing of texts is a somewhat recent field from a methodological point of view, even though temporal semantics has a long tradition, dating back at least to the 1940\u2019s (Reichenbach, 1947). While theoretical and formal linguistic approaches to temporal interpretation at the discourse level have been very active in the late 1980s and early 1990s (Kamp & Reyle, 1993; Asher & Lascarides, 1993; Steedman, 1995; Webber, 1988), empirical approaches were less frequent, and very few natural language processing systems were evaluated beyond a few instances (Grover, Hitzeman, & Moens, 1995; Kameyama, Passonneau, & Poesio, 1993; Passonneau, 1988; Song & Cohen, 1991).\nTemporal information being essential to the interpretation of a text and thus crucial in applications such as summarization or information extraction, it has received growing attention in the 2000s (Mani, Pustejovsky, & Gaizauskas, 2005) and has lead to some standardization effort through the TimeML initiative (Saur\u00ed, Littman, Knippen, Gaizauskas, Setzer, & Pustejovsky, 2006). We address here a central part in this task, namely evaluating the extraction of the network of temporal relations between events described in a text. Since temporal information is not easily broken down into local bits of information, there are many equivalent ways to express the same ordering of events. Human annotation is thus notoriously difficult (Setzer, Gaizauskas, & Hepple, 2006) and comparisons between annotations cannot rely on simple precision/recall-type measures. The given practice nowadays has been to compute some sort of transitive closure over the network/graph of constraints on temporal events (usually expressed in the well-known Allen algebra (Allen, 1983), or a sub-algebra), and then either to compare the sets of simple temporal relations that are deduced from it with standard precision and recall, or to measure the agreement between all relations, including disjunctions of information (Verhagen, Gaizauskas, Schilder, Hepple, Katz, & Pustejovsky, 2007). This reasoning model is also used\nc\u00a92011 AI Access Foundation. All rights reserved.\nto help build representations of temporal situations by imposing global constraints on top of local decision problems (Chambers & Jurafsky, 2008a; Tatu & Srikanth, 2008; Bramsen, Deshpande, Lee, & Barzilay, 2006).\nWe take a different route here, by extracting a single referent graph, a minimal graph of constraints. There are a number of ways of doing this and we argue for basing it on the graph of relations between event boundaries. We aim to accomplish two things by doing so: to find a graph that is easy to compute, and to eliminate a bias introduced by measures that do not take into account the combinatorial aspect of agreement on transitive closure graphs.\nThe next section presents in more detail the usual way of comparing annotation graphs between temporal entities extracted from a text, and the problems it raises. Then we argue for comparing event boundaries instead of events and define two new metrics that apply to that type of information. We focus on convex relations, a tractable sub-algebra of Allen relations which covers human annotations. Finally, we present an empirical study of the behavior of these measures on generated data and on the TimeBank Corpus (Pustejovsky, Hanks, Saur\u00ed, See, Gaizauskas, Setzer, Radev, Sundheim, Day, Ferro, & Lazo, 2003) to support our claim of the practicality of this methodology."}, {"heading": "2. Comparing Temporal Constraint Networks", "text": "Work on temporal annotation of texts strongly relies on Allen\u2019s interval algebra. Allen represents time and events as intervals, and states that 13 basic relations can hold between these intervals (see Figure 1 and Table 1), by considering every possible ordering of the interval endpoints. These binary relations, existing amongst all intervals of a collection (in our case, corresponding to temporal entities in a text), define a graph where nodes are the intervals and where edges are labelled with the set of relations which may hold between a pair of nodes. The relations are mutually exclusive. The TimeML specification for linguistic temporal annotation uses Allen relations under different names, and other projects either use a subset or groupings of these relations (see below).\nWe are interested in this paper in evaluating systems annotating texts by temporal relations holding between events or between temporal expressions and events. For example, consider the following text, extracted from the TimeBank corpus:\n(1) It wasn\u2019t until twenty years after the first astronauts were chosene1 that NASA finally includede2 six women, and they were all scientists, not pilots. No woman has actually been in charge of a missione3 until nowt1 .\nA correct annotation of temporal relations could be given by the graph shown in Figure 2. Other relations could be explicited, i.e. e1bt1, and a complete evaluation could consider all possible edges.\nPrecision and recall evaluations are often not performed on graphs of relations between all events in a text however, but on the subproblem of ordering pairs of successively described events (Mani & Schiffman, 2005; Verhagen et al., 2007) or even same-sentence events (Lapata & Lascarides, 2006) (in our example, only e1 b e2 and e3 fi t1 1). The main reason of this choice is the difficulty of the task, even for human beings, of assigning temporal relations in a large text (Setzer et al., 2006). Another issue is that evaluation of full temporal graphs is an open question. As will be further discussed in this section, metrics traditionally used for the task, namely recall and precision metrics (either strict or relaxed), raise specific problems that are still to be addressed.\nWe detail now important notions concerning temporal networks and the comparison of these networks. All example relations given in this section are expressed in terms of Allen algebra, whose set of relations and their abbreviations are recalled in Table 1. Here, we use the classical symbols < and > for order on temporal points."}, {"heading": "2.1 Temporal Closure", "text": "Temporal closure is an inferential closure mechanism that consists in composing known pairs of temporal relations in order to obtain new relations, up to a fixed point. E.g.: if A bB and C d B, then\n1. Exceptions exist, as in the work of Mani et al. (2006) and Mani et al. (2007).\nA bC; the operation can lead to a disjunction of relations, for example if A bB and B d C then A bC \u2228A oC \u2228A mC \u2228A dC \u2228A sC. This can also be noted as A{b, o,m, d, s}C.\nIf we consider generalized relations, i.e. the set R of disjunctions of basic temporal relations, each seen as a set of base relations, then set union and intersection and the composition of relations define an algebra on R (the algebra of the subsets of the set of all Allen relations). Composition of relations is the operation that generalizes inferences from basic relations to sets of relations. Taking the previous example, if now A T B and B S C, with T = {t1, t2, ...tk} and S = {s1, s2, ...sm}, ti, si being base relations:\nT \u25e6 S = {t1, t2, ...tk} \u25e6 {s1, s2, ...sm} = \u22c3 i,j (ti \u25e6 sj)\nSo any composition of relations can be computed from the 13x13 compositions of base relations. A table of all composition rules in Allen algebra can be found in the work of Allen (1983) or Rodriguez et al. (2004), and a sample for a few basic relations is given in Table 2. These new relations do not express new intrinsic constraints, but make the temporal situation more explicit. They can also make some information more precise, as disjunctions inferred about the same edge are intersected to combine inferences from different compositions.\nA constraint propagation algorithm ensures that all existing temporal relations are added to the network, labelling an inconsistency with \u2205 (Allen, 1983). This path-consistency algorithm is sound, but not complete, as it does not detect all cases of inconsistency. See the simple version presented in Algorithm 1. More efficient versions have also been developed (Vilain, Kautz, & van Beek, 1990), and will be put to use in our experiments, but it is not our main focus here.\nIt is not desirable to compare temporal graphs without performing a temporal closure on them. Indeed, there are several ways to encode the same temporal information in a graph, as shown in the (very simple) example of Figure 3. Closure can be seen as a computationally simple way of expliciting the temporal information from an annotation, allowing for more precise comparisons. But temporal closure also produces redundant information, which can lead to evaluation issues, as will be explained in Section 2.4.\nIn this paper, we call G\u2217 the temporal closure (also called a saturated graph) of a graph G.\nAlgorithm 1 Temporal closure Let U = the disjunction of all 13 Allen relations, Rm,n = the current relation between nodes m and n\nprocedure CLOSURE(G) A=G.edges() N=G.vertices() changed = True while changed do\nchanged = False for all pairs of nodes (i, j) \u2208 N \u00d7N do\nfor all k \u2208 N such that ((i, k) \u2208 A \u2227 (k, j) \u2208 A) do . composition via k R1i,j = (Ri,k \u25e6Rk,j) . to find info about (i,j) if no edge (a relation R2i,j) existed before between i and j then R2i,j = U end if Ri,j = R1i,j \u2229R2i,j . intersect new with already known if Ri,j = \u2205 then error . inconsistency detected else if Ri,j = U then do nothing . no new information else\nupdate edge (i,j) changed = True\nend if end for\nend for end while end procedure"}, {"heading": "2.2 Time Point Algebra and Convex Relations", "text": "Interval graphs can be converted easily into graphs between points (Vilain et al., 1990), where an event is split into a beginning and an ending point; the mapping between Allen relations and point relations is given at Table 1. This leads to a smaller set of simple relations: equality (=) and precedence (< and >), and a simpler algebra, with only 7 consistent sets ({<},{<, =},{=},{<, =, >},{>},{>= }, {<, >} where a set denotes a disjunction of relations). The point algebra is obtained by the four relations r1 ... r4 that hold between the endpoints of the two intervals I and J started by Ib and Jb and ended by Ie and Je respectively. These four relations are Ib r1 Jb, Ie r2 Je, Ib r3 Je and Ie r4 Jb. Converting an Allen graph into an endpoint graph is thus straightforward. Figure 4 shows a point graph equivalent to the interval graph of Figure 3.\nAs with the interval algebra, pairs of point relations can be combined and the temporal closure can be computed in the same way. The relation between two time points is continuous if the assigned set of simple relations is convex (Vilain et al., 1990).\nA so-called convex relation corresponds to cases where relations r1 to r4 are assigned to one of the 6 possible relations {<}, {<, =}, {=}, {<, =, >}, {>}, {>=}2, considered as conceptual neighbors (Freksa, 1992). Using only these relations between endpoints restricts interval relations to sets of Allen relations that are conceptual neighbors. This means that they encode relations that may be vague but in which intervals endpoints can only be in convex subsets of the time-line. Figure 5 shows which Allen relations are conceptual neighbors. Another useful way of seeing these conceptual neighbors is by considering continuous transformations of an interval endpoints on the time-line: when a relation r holds between two intervals I1 and I2, moving continuously their endpoints can only change the relation to a conceptual neighbor of r. For instance, such a conceptual transformation cannot change a situation where I1 starts I2 to a situation where I1 < I2 without going through (at least) intermediary situations I1 overlaps I2 and I1 meets I2.\nFinally, instead of 213 possible disjunctive relations in Allen algebra, the set of corresponding interval convex relations is reduced to 82. The corresponding sub-algebra is tractable, that is the problem of the satisfiability of a set of constraints has a sound and complete polynomial time algorithm3. Moreover, it will ensure the uniqueness of our minimal graphs, that will be defined and described in this paper.\nIt is important to note that a temporal graph built from an annotated text contains only convex relations, since the graph is generated from a finite set of base relations (annotators are not allowed to\n2. The 7 relations described above, except {<, >}, also noted 6=. These 6 relations form a sub-algebra: all compositions of disjunctions of these relations are disjunctions of these relations. 3. See the work by Schilder (1997) for a more complete presentation within a natural language processing perspective.\nuse disjunctions), and since the set of all convex relations is stable under composition and thus forms a sub-algebra."}, {"heading": "2.3 Strict and Relaxed Recall and Precision", "text": "In the general case, both humans and systems may assign disjunctions of atomic relations between two events (i.e. A bB \u2228 A mB), directly or indirectly (after saturation). This is a way to reduce vagueness even if the exact relation is not known.\nThe presence of disjunctions raises the question of how to score relations that are only partly correct, like A bB \u2228 A mB instead of A bB or the reverse. In response to that issue, different variations of usual precision and recall measures have been proposed.\nA strict measure only counts exact matching as success, and will for example score 0 for the latter example.\nHowever, it can be argued that an evaluation measure should take better account of \u201cclose matches\u201d. For example, suppose that the gold standard relation between A and B is A bB. If the system chooses the disjunction A bB \u2228 A mB, it must be rewarded less than A bB but more than A > B or nothing. The system is vaguer but correct, as its annotation is a logical consequence of the standard annotation.\nWe proposed (Muller & Tannier, 2004) such a gradual measure that we might call \u201ctemporal\u201d precision and recall. If Si,j is the (possibly disjunctive) relation between i and j given by the system and Ki,j the (possibly disjunctive) gold standard, then:\nPtemp i,j = Card( Si,j \u2229Ki,j )\nCard( Ki,j ) Rtemp i,j = Card( Si,j \u2229Ki,j ) Card( Si,j )\nWith Card(Gi,j) = the number of atomic relations present in the disjunction. Thus, in our example, the system S1 that answered before \u2228 overlaps between i and j will get:\nPtemp i,j,S1 = Card({b, o} \u2229 {b} )\nCard( {b} ) = 1\nRtemp i,j,S1 = Card({b, o} \u2229 {b} )\nCard({b, o}) = 1 2\nWhile S2 that answered after will get Ptemp i,j,S2 = Rtemp i,j,S2 = 0.\nThe final precision (resp. recall) is the average on the number of relations given by the system (resp. by the reference):\nPtemp =\ni=n\u2211 i=1 j=n\u2211 j=i+1 Ptemp i,j\nCard(S) Rtemp =\ni=n\u2211 i=1 j=n\u2211 j=i+1 Rtemp i,j\nCard(K)\nSimilar measures have also been used during the TempEval evaluation campaign in 2007 (Verhagen et al., 2007), with a reduced set of relations : \u201cbefore\u201d, \u201coverlaps\u201d and \u201cbefore or overlaps\u201d. These measures were called relaxed recall and precision. We will use the words strict and relaxed to designate these two ways to score temporal relations."}, {"heading": "2.4 Relative Importance of Relations", "text": "As shown above, temporal closure is necessary in order to be able to compare properly two temporal graphs. But in a temporal graph, relations do not have all the same importance. Applying basic recall and precision scores (either strict or relaxed) on closed temporal graphs is not enough. Consider the very simple graph examples of Figure 6, in which the first graph K is the gold standard. S1 contains only two relations, against six in K. But it seems unfair to consider a recall score of 26 , since adding only one relation (B bC) would be enough to infer all others. An intuitive recall would be around 23 . What counts here is how many relations are missing in order to recover the whole annotation graph.\nStill, even if we suppose that we have a way to distinguish unambiguously \u201cmajor\u201d relations (solid lines in K) from \u201cminor\u201d (deducible) relations (dashed lines), it would not be enough. Indeed, graph S2 finds the relation \u201cB bD\u201d. This relation is minor in K, because it can be found by composing other relations; but in S2, it is not the case, this relation actually carries a piece of information and must then be rewarded. However, even if the amount of temporal information brought by S2 and S3 seems equivalent, S3 should get a higher score. Indeed, the amount of missing relations (needed to infer the full graph) is much lower in S3 (only \u201cC b D\u201d is missing) than in S2. Finally, S4 should get a better recall than any other one. General cases involving all relations are obviously much more complex.\nThe same kind of problems could be found in the co-reference task of MUC-6, where co-reference links define an equivalence relation. It is thus not necessary to specify all pair-wise co-reference relations to retrieve them, and this has consequences for the evaluation of recall. This was addressed by considering that a spanning tree of the graph of co-reference is enough to evaluate the recall of such links (Vilain, Burger, Aberdeen, Connolly, & Hirschman, 1995). For each equivalence class considered, consisting of n entities, n\u22121 links are enough to define the class, and recall error depends on the number of missing links m needed to reconnect an equivalence class. Recall on a class is then 1\u2212 mn\u22121 . Precision was then defined symmetrically. In a much simpler framework, this was a similar problem of redundancy.4"}, {"heading": "2.5 \u201cMinimal\u201d Graphs", "text": "As said in previous section, a good, but insufficient way to deal with the relative importance of graph relations would be to work on what we called \u201cmajor\u201d relations, or \u201cminimal graph\u201d.\nWe consider that a temporal graph is a \u201cminimal graph\u201d of a graph G if:\n4. The MUC measures has other problems that were later addressed by the measures B3 and CEAF, but which have no relevance to the evaluation of a temporal graph. The main issue is a tendency to favor the prediction of a co-reference link for every pair of mentions; this has no counterpart in the temporal case since event pairs can be linked with different relations and with different inferential properties, as opposed to only one equivalence relation.\n1. Its temporal closure leads to the same temporal information as G.\n2. No relation can be removed from this graph without breaking the first property.\nUnfortunately, a unique minimal graph does not exist in the general case, and in particular for Allen relations. Rodriguez et al. (2004) propose a way to find all minimal graphs for a given temporal graph. Their algorithm first finds core relations, relations that are in every minimal graph, by intersecting all derivations, and then computes all possible remaining combinations in order to find those composing a minimal graph.\nFor example, for the relation RA,B between A and B, derivations are RA,C \u25e6RC,B , RA,D \u25e6RD,B , RA,E \u25e6RE,B , etc. If the intersection of all these derived relations equals RA,B , it means that RA,B is not a core relation, since it can be obtained by composing some other relations. Otherwise, the relation is a core relation, since removing it always leads to a loss of information. The way this \u201ckernel\u201d is obtained ensures its uniqueness.\nHowever, the second part of the procedure (compute remaining combinations) is computationally impractical, even for medium-sized graphs, since every subset of relations must be considered to determine a minimal graph on top of core relations. The authors do not detail much their empirical investigations, offering no support for the usability of this method. Moreover, it does not lead to a unique graph that could be compared to a reference.\nGoing back to evaluation, Tannier and Muller (2008) suggest the comparison of graphs through core relations, which are easy to compute and give a good idea of how important the relations are in a same graph. But core relations do not contain all the information provided by closed graphs, and\nmeasures on core graphs are only an approximation of what should be assessed. In this paper, we propose a method to obtain a unique graph respecting the constraints mentioned at Section 2.4."}, {"heading": "2.6 Behavior of Existing Metrics", "text": "As stated in the work by Tannier and Muller (2008), a recall measure is expected to decrease in a linear way when the amount of information decreases. Otherwise, evaluation measures could have non-gradual changes that complicate comparisons of models. Besides, we expect the amount of information to grow roughly proportionally to the number of events in the text.\nThis behavior can be evaluated by comparing a given annotation with the same annotation where some of the temporal information is taken out.\nFigure 7 shows how recall measures evolve when removing relations from a temporal graph, until no relations are present. It shows the different values of strict recall according to the proportion of relations kept in the graph, as well as the ideal y = x line. This can be considered as an illustration of the consequences of an annotator \u201cforgetting\u201d to annotate some relations, with respect to an ideal reference.\nThis slope reveals two major drawbacks, both leading to a lack of stability of the metric:\n\u2022 A non-linear progression of the curve does intuitively not correspond to what we expect from a good metric: for example, if a system A provides 60% more correct information than a system B, this system should get a 60% better recall.\n\u2022 As will be shown later, the parabolic shape is due to the irregular redundancy and sparseness of human annotation. Then, two systems providing the same amount of correct information can get different recall values, depending on whether the human annotation of this information was redundant or not.\nThe Figure presents an idealized case; more thorough experiments were done on the whole TimeBank corpus (Pustejovsky et al., 2003) and explained in details in Section 6. For now, it is enough to note that the measure decreases in a parabolic way, since annotators roughly tag O(n) relations where n is the number of events, while inferred relations are in O(n2), the number of edges from n nodes.\nFull graphs contain redundant information, and recall thus decreases in artificial, irregular ways when some of it is removed. Our hypothesis is that working on minimal graphs will suppress redundancy and lead to a more controlled behavior.\nMoreover, the fact that reference graphs contain O(n2) relations after closure biases the evaluation towards the larger texts (or at least texts containing large clusters of related events)."}, {"heading": "3. Proposed New Metric", "text": "When confronting a graph to a gold standard, a similarity measure is necessary. Many similarity measures exist between two graphs once a many-to-many correspondence is found between the nodes of both graphs (Sorlin, 2006).\nNode matching, which is a major problem in graph comparison in general, is not difficult in our case, since we consider that both graphs annotate the same events or expressions5.\nA traditional similarity function between two graphs is the following (Sorlin, 2006):\nsim(K, G) = f(K um G)\u2212 g(splits(m))\nf(K \u222aG)\nwhere KumG is the set of relations shared by both graphs according to the node matching function m, K \u222aG is the union between K and G relations, and splits(m) the number of node splits imposed by the matching to obtain a graph mapped to the other (see examples later). Functions f and g depend on the types of graphs and applications.\nBut this kind of metrics is not appropriate for temporal relations, because the transitivity of relations implies different features; also, these metrics are symmetrical, whereas two distinct recall- and precision-like values are more desirable. We adapted the general idea of two functions for split nodes and relation similarity, and arrived at the algorithm described below."}, {"heading": "3.1 Transitive Reduction of Endpoint Graph", "text": "To address the problem of finding minimal graphs and to take into account the relative importance of relations, we take inspiration from the work of Dubois and Schwer (2000) in two main ideas. First, graphs are saturated (i.e. temporal closure is applied), and are converted into endpoint graphs. Second, two nodes linked by an equality relation are merged together (this will help guarantee the uniqueness of the minimal graph, see below), a useful procedure on point-based graph (van Beek, 1992). Figure 8 presents the graph of Figure 3 after this transformation. The resulting point graph is saturated, by definition of the composition of event relations in Allen\u2019s algebra.\nRecall that the graph we consider are built from \u201cconvex\u201d annotations, i.e. there cannot be a \u201c< or >\u201d relation between two points. We can keep relations < and \u2264 without loss of information, since all > and \u2265 can be obtained by symmetry.\n5. If this is not the case, creating fictitious unlinked nodes in one graph or both is enough.\nWith these specifications, the graph boils down to the directed graph of a transitive relation where an edge between two points x and y means x \u2264 y. A coherent graph will thus be acyclic, since we collapse equal points into single nodes. It is important to note that as a consequence, no edge in the transitive closure can be labelled with the equality relation only. Thus we can see our problem as searching for the transitive reduction of a graph labelled with the transitive relation \u2264 (but for which we keep the additional information that some edges can be more precisely labelled as < instead of the disjunctive \u2264). This is important because the minimal graph is the transitive reduction of the graph, and the transitive reduction of a directed acyclic graph is unique (Aho, Garey, & Ullman, 1972; La Poutr\u00e9 & van Leeuwen, 1988). The transitive reduction of a graph G is by definition the subgraph corresponding to the minimal set of edges (with respect to inclusion) that has the same transitive closure as G, i.e. the minimal graph G\u2032 such that G\u2032 is a subgraph of G and G\u2032\u2217 = G\u2217 where G\u2217 is the transitive closure of G. It is simply determined by G\u2217/(G\u2217 \u25e6 G\u2217). Algorithm 2 details a simple computation of the transitive reduction while Figure 9 shows an illustration of the procedure on a simple transitive graph. Figure 10 shows the process from the initial endpoint graph with both < and \u2264 labels, to the minimal graph, via transitive reduction of the unlabelled graph.\nAlgorithm 2 Transitive reduction simple computation procedure COMPOSE(G) . find relations inferable from others\nnewRels={} base_rels= { x for x in G.edges() if x.relation() in {<,\u2264}}\nfor all one in base_rels do related ={x for x in G.edges() if x.source()=one.target() and x.relation() in {<,\u2264} }\nfor all other in related do relation = compose(one.relation(),other.relation()) newRels.add(Edge(one.source(),other.target(),relation))\nend for end for return newRels\nend procedure\nprocedure TRANSITIVE-REDUCTION(G) G = closure(G) non_min=compose(G) for all one in non_min do\nG.edges().remove(one) . remove relations deduced by composition end for for all one in G.edges() do\nif one!=before and one!=before_or_equals then G.edges().remove(one) . keep only <,\u2264 and remove their symmetric relations\nend if end for\nend procedure\nWe call:\n\u2022 Major relations, the relations of the transitive reduction, or Gmaj .\n\u2022 Minor relations, the relations of temporal closure which are not present in the transitive reduction, i.e. G\u2217 \u2212Gmaj .\nFormally: Let G = {(x, y,R)/R \u2208 {<,\u2264}}, the temporal point graph, saturated with respect to the relation < and \u2264. So G\u2217 = G Let E(G) = {(x, y)/\u2203R, (x, y,R) \u2208 G}, the unlabelled corresponding graph. The function f which associates (x, y, R) in G to (x, y) in E(G) is an obvious bijection, as the original graph G has at most one relation holding between any two vertices. Here E(G) = f(G). Since G is closed, so is E(G).\nLet Proj(G\u2032, G) = {(x, y,R) \u2208 G/(x, y) \u2208 G\u2032} the \u201cprojection\u201d of an unlabelled graph into a labelled one. The function associating an edge (x, y) in G\u2032 to (x, y,R) in G is the inverse of f , f\u22121. Proj(G\u2032, G) = f\u22121(G\u2032), and obviously Proj(E(G), G)) = G.\nIt is enough to prove that E(G) (or G) is the graph of a transitive, acyclic relation to prove that E(G) has a unique transitive reduction (Aho et al., 1972).\nFirst, E(G) is transitive: let (x, y) \u2208 E(G) and (y, z) \u2208 E(G) then we have (x, y, <) or (x, y,\u2264 ) \u2208 G and (y, z,<) or (y, z,\u2264) in G in any of the four possibilities we can infer either (x, z,<) or (x, z,\u2264) is in G (because < is transitive, \u2264 is transitive and x < y \u2264 z or x \u2264 y < z both imply x < z); in other words any composition of < and \u2264 is <, i.e. ((< \u25e6 \u2264) = (\u2264 \u25e6 <) = (<)) so (x, z) is also in E(G) and E(G) is the graph of a transitive relation. This is the reason why we said that keeping a record of all < relations while considering G as a graph of\u2264 does not change the graph property.\nSecond, G is acyclic since < is irreflexive, and x < y \u2264 z implies x < z so that the only way to have cycles in G is if there are paths such as x \u2264 y \u2264 z \u2264 ... \u2264 x. But in that case we can infer that x = y = z = ... and the nodes would have been merged beforehand. So E(G) is also acyclic (it has exactly the same edges as G).\nSo, E(G) is acyclic and transitive and thus admits a unique transitive reduction E(G)tr. Since the graphs G and E(G) have exactly the same edges, they necessarily have the same reductions, and thus both have a unique transitive reduction. We can project back the original relations of G on E(G)tr, (Proj(E(G)tr, G)), to have a properly labelled reduction for G."}, {"heading": "3.2 Temporal Recall and Precision", "text": "The idea is not to compare only minimal graphs. Temporal closure should be used as well. As we showed in Section 2.4, reference minor relations should still be rewarded if they are not redundant in the evaluated graph. However, they must carry a lower weight.\nMinor relations are only to be considered in temporal recall, and not in precision. The reason is that recall evaluates the proportion of reference relations found by the system, and this system can find some minor relations without the major relations that produced them in the reference (see B b D in S4 example, Figure 6). On the opposite, precision evaluates the proportion of system relations that are in the reference graph, and minor (i.e. deducible) relations found by the system are by definition redundant.\nOur recall-like measure is then a combination of two values. Given K the reference graph and G the evaluated graph:\n\u2022 The major temporal recall is the rate of reference major relations (Kmaj) found in G\u2217.\n\u2022 The minor temporal recall is the rate of reference minor relations (K\u2217\u2212Kmaj) found in Gmaj .\nIn the first case, the temporal closure is applied to G, since there is no reason to restrain the search of good relations in the evaluated graph. In the second case, only the transitive reduction Gmaj is considered; reference minor relations must be rewarded only if they are not minor in G (case of B bD in example S2, Figure 6). G minor relations have already been assessed through their major relations (case of A bC in example S4).\nThe final value of temporal recall is a weighted sum of the two figures. The precision-like measure is a single value corresponding to the ratio between correct relations in Gmaj and its total number of relations. G minor relations must not be considered at all for precision. Unlike for recall where reference major relations may not be retrieved by the system, precision necessarily considers major relations from the system. Minor relations are then all redundant.\nIn precision as well as in recall, a merge must be considered as a relation in some way, because it corresponds to an \u2018=\u2019 relation."}, {"heading": "3.3 Notations", "text": "We note:\n\u2022 G and K the event graphs, K being the reference (key);\n\u2022 Gpt and Kpt, the corresponding endpoint graphs, where equals points are merged.\n\u2022 (N, R) the set of nodes and relations of the graph G, and mutatis mutandis for the others.\n\u2022 in the examples, only non-trivial relations are listed. Trivial relations are those involving two points of a same interval. For example, A1 < A2 in Figure 8 is trivial, and thus not considered. In all figures, trivial relations are dashed gray lines. Non-trivial relations and the node list are enough to find the full graph.\n\u2022 The temporal closure of G is noted G\u2217.\n\u2022 The transitive reduction of G is now noted Gmaj ."}, {"heading": "3.4 Temporal Recall and Precision", "text": "Our new metrics of temporal recall and precision rely on the notions defined above. With respect to the recall value, we have shown it was important to distinguish \u201cmajor\u201d relations, i.e. relations that belong to the minimal graph, from the other, \u201cminor\u201d relations. That is why we suggest to compute recall in two steps. Precision is not concerned by this issue."}, {"heading": "3.4.1 GRAPH VALUES", "text": "Let\u2019s consider now Gpt a set of merged nodes and relations (Npt, Rpt) evaluated with respect to the reference Kpt = (NptK , R pt K). We need to take into account the number of relations expressed in the original point graph before nodes are merged (called value(Gpt)), that is the number of equalities expressed in the merged nodes, node_values(Gpt), plus the number of relations relation_value(Gpt). Then:\nvalue(Gpt) = node_value(Gpt) + relation_value(Gpt) = \u2211 ni\u2208Npt (|m(ni)| \u2212 1) + |R\npt| = |N | \u00d7 2\u2212 |Npt| + |Rpt|\nHere, m(ni) the number of points merged into a node (m points into a node correspond to m \u2212 1 merges). Similarly, we can compute the value of the reference graph.\nThe pairing of nodes in the evaluated graph and the reference graph must be then taken into account. Let\u2019s call a \u201csplit\u201d the operation of mapping one node of the reference graph to many nodes in the evaluated one, and a \u201cconflation\u201d, the converse operation. To map both graphs, we first need to split any node of the reference that is not in the evaluated graph into nodes that are in it and maybe some extra nodes, and then conflate, if necessary, the remaining nodes to evaluated nodes (see Sections 4 and 5 for illustration). A split is like a \u2018=\u2019 relation provided by the reference but not by the evaluated graph. A conflation is a \u2018=\u2019 wrongly predicted by the evaluated graph.\nTherefore, the number of correct answers in an evaluated graph, or correct value vc, is the number of correct \u2018=\u2019 and \u2018<\u2019 relations6. The number of correct \u2018=\u2019 is \u201cnode value - nb of conflations\u201d, the number of correct \u2018<\u2019 is \u201crelation value - wrongly predicted relations (errors)\u201d.\nA simple way of calculating the number of splits necessary to match two graphs G1 and G2 is to count for each node x of G1 the number i of different nodes of G2 that intersect with x. If i is one, the node is mapped directly, otherwise i\u2212 1 splits are needed. Thus:\n|split(Kpt, Gpt)| = \u2211\nx\u2208NptK |{y \u2208 Npt/x \u2229 y 6= \u2205}|\nThe number of conflation necessary to match G1 to G2 is also the number of splits necessary to match G2 to G1, so:\n|conflation(Kpt, Gpt)| = |split(Gpt, Kpt)|\nvc(Gpt) = correct equalities + correct precedences = (node_value(Gpt)\u2212 conflations)) + (relation_value(Gpt)\u2212 errors) = v(Gpt)\u2212 (|conflation(Kpt, Gpt)|+ errors) = v(Gpt)\u2212 (|split(Gpt, Kpt)|+ |R\u2212RK |/|R|)"}, {"heading": "3.4.2 TEMPORAL RECALL AND PRECISION", "text": "A precision value deals with errors (incorrect relations) and conflations through the correct value vc. On the other hand, a recall value must take into account misses (reference relations missed by the graph) and splits. For simplicity, let\u2019s note now K = KptK the point-based reference, and G = G\npt the graph to evaluate. Kmaj and Gmaj are the transitive reductions of these. We define:\n\u2022 Major temporal recall Rt(G) is the number of reference major relations found by G\u2217.\nRt(G) = v(Kmaj)\u2212 (splits + misses)\nv(Kmaj)\nRt(G) = v(Kmaj)\u2212 (|split(K, G)|+ |(RK \u2212R\u2217)/RK |)\nv(Kmaj)\nwhere misses is the number of relations in Kmaj missed by G\u2217 and splits the number of splits (a split is a missed \u2018=\u2019 relation).\n6. We consider of course only non trivial relations.\n\u2022 Symmetrically, Temporal precision TP (G) is the ratio between the correct value of Gmaj , vc(Gmaj), and its full value v(Gmaj).\nTP (G) = v(Gmaj)\u2212 (conflations + errors)\nv(Gmaj)\nTP (G) = vc(Gmaj) v(Gmaj)\nBut, as we already stated, minor relations should also be taken into account. If we consider only major recall, systems that find only minor (but correct) relations are disadvantaged. This is the case of system S2 in Figure 6 (B b D is correct and minor). That is why we add a minor temporal recall:\n\u2022 Minor temporal recall rt(G) is the proportion of reference minor relations (K\u2217\u2212Kmaj) found by Gmaj . Minor relations are seeked in the minimal evaluated graph. Indeed, as we already said, comparing two relations from non-minimal graphs is redundant, since major relations that \u201cproduced\u201d them have already been taken into account.\n\u2022 Full temporal recall TR could be defined as a value pair (Rt(G), rt(G)), or preferably as a combination:\nTR(G) = Rt(G) + 1\nv(Kmaj) rt(G) (2)\nWith this formula, we ensure that one single major relation is better than all minor ones and that the recall can not exceed 1 (see next Section).\nThe symmetrical precision property, i.e. the proportion of system minor relations existing in the reference, is always null. System minor relations are, by definition, always redundant. That is why temporal precision does not need a two-fold figure.\nA tool for computing different precision and recall values (strict, relaxed, core, as well as this new one) is made available with this paper7. It accepts several input formats, including TimeML. All computed data are also available, with instructions to reproduce the experiments presented at the end of this paper."}, {"heading": "3.4.3 SYNTHESIS", "text": "Evaluating an interval graph G against a gold reference K is achieved through the following steps:\n1. Perform transitive closure on both G and K.\n2. Convert both graphs into endpoint graphs.\n3. Merge equality relations into single nodes.\n4. Perform transitive reduction.\n5. Compute values of temporal recall and precision.\n7. http://www.irit.fr/~Philippe.Muller/resources.html\nThe most costly operation here is the first one, and is common to the standard evaluation procedure; its time is in O(|N |3) in the worst case with the algorithm 1 page 379, N being the set of events of the largest graph between G and K. The other are straightforwardly linear in the number of relations of the graph (conversion to endpoints, merge equalities in the closed graph), or at worse in O(|N |2) for both the transitive reduction (one composition of relations in the graph and set difference), and the computation of the number of splits and conflations. Overall, the whole procedure is dominated by the first step, which is common to all evaluation procedures for this task. Our proposition thus does not change the worst-case complexity of the evaluation procedure."}, {"heading": "3.4.4 BOUNDARIES", "text": "Temporal precision. Temporal precision is a value between 0 and 1 since vr(G) \u2264 v(G) (errors and conflations are zero or positive).\nTemporal recall. Major recall is between 0 and 1.\n\u2022 If 1, then minor recall rt(G) = 0, because all relations in Gmaj are already in Kmaj (and then cannot be in K\u2217 \u2212Kmaj). In this case temporal recall cannot exceed 1.\n\u2022 If not 1, Rt(G) \u2264 (v(Kmaj)\u2212 1)/v(Kmaj). Yet, 1v(Kmaj)rt(G) < 1 v(Kmaj)\n, and the full temporal recall stays below 1.\nThus 0 \u2264 TR(G) \u2264 1. In order to make the measure clearer, we will present the metric in detail by developing a basic example with a transitive closure made only of simple relations (the 13 basic Allen relations), then we will turn to the more general case of a closure made only of convex temporal relations (disjunctions of neighboring Allen relations)."}, {"heading": "3.4.5 SIMPLE EXAMPLES", "text": "Temporal recall and precision as described above lead to the expected values for the sample graphs pictured in Figure 6 and analyzed in Section 2.4.\nFigure 11 recalls these graphs and details the temporal recall values for each of them (given that v(Kmaj) = 3). As for precision, for each graph Si, TP (Si) = 1.\nAn attentive reader would note that a system providing only minor relations, A < C, A < D and B < C, i.e. half of all deducible relations, would get a recall of only 0.33, which could seem unfair. However, even if three relations are present, three others are still missing (the same number of missing relations as if the graph had no relation at all). Moreover, the fact that all minor relations does not get a better score than one major relation is the condition for the boundaries not to go over 1. Finally, this case is rare and does not affect the general behavior of the metric.\nMore sophisticated examples are provided in the following sections."}, {"heading": "4. First Simple Case: Non-Disjunctive Allen Relations", "text": "Consider the sample graph K1 made of Allen non-disjunctive relations (see also the graph in Figure 12):\nK1 =\nA B C D E F\nA s bi b s b\nB bi m s m\nC b b b\nD f e\nE fi\nThe conversion into relations between endpoints leads to the following graph, where an event A is split into A1 and A2. Edges are not labelled since only relation \u2018<\u2019 is considered at this point.\nNote that merging equal nodes is not equivalent to labelling arcs with \u2018=\u2019, because in the latter case the minimal graph would not be unique any more. For example, the necessary choice between A1 < A2, B1 < A2 and E1 < A2 would lead to three equivalent but different graphs.\nConsider now that the reference K1 is compared to the following graph G1 (Figure 13; bold edges are correct relations, thin edges are wrong relations, dashed edges are trivial relations, i.e. involving two endpoints of the same interval).\nFollowing the notations defined in Section 3.3:\n\u2022 The list of nodes for graphs K1maj and G1maj are:\nG1maj C1 B1 C2 A1 B2 A2\nD1 E1 F1\nE2 F2 D2\n\u2013 (A1, B1, E1)K1: 2 splits (\u201cbreaking\u201d of 2 equality relations); (B2, D1, F1)K1: 1 split (D1 and F1 stay together in G1); (E2, D2, F2)K1: 1 split\n\u2013 (A1, B2)G1: 1 conflation (joining two nodes); (D1, E1, F1)G1: 1 conflation (joining E1 to the two others); (E2, F2)G1: nothing (already together in K1)\n\u2013 Total: 4 splits and 2 conflations.\nAs stated above, an edge is correct if the relation is correct for at least one pair of points from both nodes. For example, relation {A2}G1 \u2192 {D1, E1, F1}G1 is correct because {A2}K1 \u2192 {B2, D1, F1}K1, even if the sub-relation A2 < E1 is not true. This latter relation will be penalized anyway because a split is necessary for matching the graphs.\nThese definitions lead to the following values;\n\u2022 Graph values:\n\u2013 v(K1maj) = node value + relation value = 6 + 2 = 8 \u2013 v(G1maj) = 4 + 5 = 9\n\u2022 Correct value of G1:\nvc(G1maj) = (node value\u2212 conflations) + (relation value\u2212 errors) = v(G1maj)\u2212 (conflations + errors) = 9\u2212 (2 + 2) = 5\n\u2022 Major temporal recall:\nRt(G1) = v(K1maj)\u2212 (misses + splits)\nv(K1maj)\n= 8\u2212 (0 + 4)\n8 = 0.5\n\u2022 Minor temporal recall: rt(G1) = 28 = 0.25 (this corresponds to [C1; {A1, B1, E1}] and [C2; (B2, D1, F1)]).\n\u2022 Full temporal recall:\nTR(G1) = (R(G1), r(G1)) = (0.5, 0.25) or TR(G1) = Rt(G1) + 1\nv(Kmaj) rt(G1)\n= 0.5 + 0.25 8 = 0.53\n\u2022 Temporal precision\nTP (G1) = vc(Gmaj) v(Gmaj)\n= 5 9 = 0.56"}, {"heading": "5. Disjunctive Convex Relations", "text": "We now apply the metric to sets of convex relations. Convex relations are a set of relations that are conceptual neighbors, that is they encode relations that may be vague but in which intervals endpoints can only be in convex subsets of the time-line (see Section 2.2).\nBuilding the minimal graph follows the same procedure as explained above (transitive reduction). The measures do not differ at all if we choose a strict scoring scheme (see Section 2.3). But in a relaxed scheme, with disjunctions, it becomes necessary to apply a weighting procedure; a response is no longer assigned a binary value (0 or 1), but for example one of the values in Table 3, in a manner similar to what was done in TempEval (Verhagen et al., 2007).\nAs shown in that table, the relaxed measure has an effect on misses values and on vc (a relation can get a half-point), but also on conflation and split values (where half-points are also possible).\n\u2197 = < \u2264 > \u2265\nRel. Repres. A\nB A B\n< A B <, = B A <\nB A <, =\n= A\nB\n1 0 0.5 (\u201c 1\n2 -split\u201d)\n0 0.5 (\u201c 1\n2 -split\u201d)\n< A B < 0 1 0.5\n(disjunction)\n0 0\n\u2264 A B<, = 0.5 (\u201c 1\n2 -confl.\u201d)\n0.5 (disjunction)\n1 0 0.5 (disjunction)\n> B A < 0 0 0 1 0.5\n(disjunction)\n\u2265 B A<, = 0.5 (\u201c 1\n2 -confl.\u201d)\n0 0.5 (disjunction) 0.5 (disjunction)\n1\nThere is no conflation and the number of splits is 2.5. The \u201chalf-split\u201d comes from the fact that E1 may be equal to {A1, B1}, because of the \u2264 edge.\nThe application of the same measures leads to the following values:\nRt(G2) = 7\u2212 (0 + 2.5)\n7 = 0.64\nrt(G2) = 0\nTR(G2) = 0.64\nvc(G2) = (12 + 2 \u2217 1/2) + 2 = 15\nThe two half-points in vc(G2) hold for relations C1 \u2264 D1 (instead of C1 < D1 in the reference) and B1 \u2264 E1 (instead of B1 = E1 in the reference).\nAs an example, and following Table 3, we can see that E1 leaving the group {A1, B1, E1} costs a half-point to the recall value, while relation B1 \u2264 E1, correct but imprecise, gets a half-point of precision. Both results seem logical behaviors of the measure."}, {"heading": "6. Experiments", "text": "Our push for a change of evaluation measures of temporal annotation graphs was motivated in the beginning of the paper by a few examples where we show some undesirable side effects of common\nevaluation procedures. We will now present a more thorough methodology, aiming to evaluate the evaluation procedure itself. We used two kinds of data for that purpose. Obviously, we can test and compare measures on the freely available temporal annotated data provided in the TimeBank corpus. We also introduce a set of artificially built temporal graphs, on which we can control a few relevant parameters. TimeBank annotations are rather heterogenous, because human annotators make mistakes, forget relations, or introduce inconsistencies, thus creating a fair amount of noise. Besides, we wanted to test other aspects of temporal annotation that are easier to generate from scratch. One of this factor is the amount of information that is present in an annotation. We have seen that the result of an annotation can be more or less underspecified: a relation between events can be a simple, precise relation, or a disjunction of simple relations. The size of a graph is also probably important, but it is somewhat hidden in some human annotations, because the really relevant object when considering inferred information is a connected component. Small subgraphs with only a few nodes do not allow for a lot of inferences, and some of the bias we want to study probably happens only above a certain threshold. In human annotations, the size of subgraphs can vary a lot, and it is common for events to be related only to one or two other events, even after the graph has been enriched through inference procedures.\nThe main experiment we performed to study the behavior of commonly adopted measures and our own proposal is based on a comparison of an annotation to a \u201cweakened\u201d version of itself. For each graph, we remove a portion of event-event relations at random, and we use the measures to estimate the loss of information. Obviously, this is only interesting for recall-like measures, precision is not affected. We vary the amount of removed information in steps, until all relations are vague: eventually, the universal disjunction hold between any two events of the text. We designed another experiment to watch also the behavior of precision measures : instead of removing relations, we disturbed the graph by changing a simple relation to another one (simulating an \u201cerror\u201d in the annotation, in a way). This is meaningful only if we keep the graph consistent at the same time.\nIn what follows, we present our results on the synthetic graphs (6.1) and then on the TimeBank data (6.2)."}, {"heading": "6.1 Artificial Graphs", "text": "In order to control the amount of information present in a temporal graph, we have built a set of artificial temporal graphs in the following way:\n\u2022 For a given number of events E, a temporal graph is built by randomly choosing a set of E integer pairs (bi, ei), within a given range N , and with a level of indeterminacy I , that is a width around the boundaries bi and ei.\n\u2022 For each pair of events (i, j), we determine a temporal relation between their intervals, considering that the endpoints of i can lie anywhere in the interval [bi \u2212 I/2, bi + I/2] and [ei\u2212 I/2, ei + I/2], and the endpoints of j can lie anywhere in the interval [bj \u2212 I/2, bj + I/2] and [ej \u2212 I/2, ej + I/2].\n\u2022 The graph is closed, leading to N = (E \u00d7 (E \u2212 1))/2 relations.\nEvents are considered as intervals with some uncertainty about their endpoints, to be comparable to a graph built from a text, and to give rise to possibly disjunctive relations between the generated events. This graph can thus contain any kind of convex (possibly disjunctive) Allen relations. An example of such generated events is provided by Figure 19. By varying N and I , we can control the\nE4\nE5\n0 1 5 10 15 20\nE1\nE2 E3\nbeginning of E5\nend of E5\nFigure 19: Example of random artificial graph with N = 20 (X-axis), E = 5 and I = 3 (maximum uncertainty for each endpoint). The indeterminacy leads to disjunctive relations, for example ((E5 < E3) \u2228 (E5 meets E3) \u2228 (E5 overlaps E3)). When building graphs from this representation, relations are disjunctive but the graph is fully connected, which is not the case with real data like TimeBank.\namount of vagueness of the information put in the graph. The smaller N is, the tighter the model we generate, and the most likely it is that vague boundaries intersect, creating disjunctive relations. A larger I also contributes to a vaguer representation. We quantify the amount of vagueness v by how much the relations are disjunctive in the graph:\nv =\n\u2211 r\u2208edges(G) 1\u2212 1 |r|\n|edges(G)| where r is an edge in the graph and |r| is the number of simple Allen relations in the disjunction (i.e.: for r = {b, o}, |r| = 2). Figure 20 shows the different values of strict recall and our temporal recall (called point recall) according to the proportion of relations kept in the graph, with lines joining values derived from the same graphs.\nIt is interesting to note that curves based on the minimal graphs are almost linear, while the simpler measures decrease slowly at first then sharply, in a more parabolic way. We analyze below (Section 6.2.2) the difference between being above or below \u201cy=x\u201d.\nThis shows that the overall effect is observable roughly on every graph considered. The effect is even more marked when the number of events is higher.\nWe can also compare our point-based measure to the relaxed recall measure, similar to the measure used in the TempEval campaign and which computes an overlap between all simple and disjunctive relations on every edge of the graph. We also want to see the behavior of a measure based on the \u201ccore\u201d set of relations extracted from the annotation as in our previous work (Tannier & Muller, 2008).\nWe can see in Figure 21 that the only measure that behaves linearly is the point-based one. Here, we have plotted the estimates of a parabolic regression on each data set, for clarity. The others measures show clearly parabolic behaviors, with different undesirable effects: relaxed recall is much too permissive when no information is actually provided (since the disjunction of all relations, which\ndoes not carry any information, gets a non-zero score), recall with respect to core relations is similar to strict recall, and is surprisingly even less linear. This effect is again stronger when the number of events increases.\nFinally, Figure 22 shows the influence of different levels of \u201cvagueness\u201d of the annotation (and thus the underlying temporal description) on the measures used. We plotted the same experiment as above (recall with respect to the quantity of information removed) with the vagueness of the considered graphs as a third parameter. The surface shown is the departure from the \u201cy=x\u201d line, for readability\u2019s sake.\nHere we can observe that less vague temporal descriptions have values mainly above the \u201cy=x\u201d line for \u201cparabolic\u201d measures, while vaguer data show a less obvious parabolic behavior, sometimes\nbelow that line. The curves for point-based recall seems insensitive to that aspect, which is consistent with the average behavior we already discussed.\nstrict recall"}, {"heading": "6.2 TimeBank Corpus", "text": "Before presenting the results of our evaluations on the real annotated data of the TimeBank corpus, we show some characteristics of the temporal graphs induced by the annotations. This helps to understand some of the differences between the behavior we observe on the synthetic temporal graphs and the more ecological ones."}, {"heading": "6.2.1 ANALYSIS OF THE TIMEBANK CORPUS", "text": "The TimeBank corpus consists of 186 news report document (for about 65, 000 tokens). It is made from news articles from the Associated Press, the Wall Street Journal, the L.A. Times and the San Jos\u00e9 Mercury News, and transcripts from broadcast news by CNN, ABC, VOA. These documents were initially collected for the DUC and ACE evaluation campaigns. The corpus in version 1.1 is available from http://www.timeml.org/site/timebank/timebank.html.8\nDocuments are annotated using the TimeML standard for tagging events and states, dates, times, and durations, and their temporal relations as well as various aspectual modalities. These entities are also tagged with some attributes: tense, aspect for verbs, values for dates and durations, normalized according to the ISO standard 8601.\nEventualities can be denoted by verbs, nouns, adjectives and some prepositional phrases. The temporal relations encode topological information between the time intervals of occurring eventualities, using relations that are equivalent to Allen relations, although they have different names. The TimeML standard specifies the relations between events, the anchoring of events to \u201ctimes\u201d (dates, hours) and the relations between times. There are about 7000 annotated relations between temporal entities. Additions to this set have been proposed (Bethard, Martin, & Klingenstein, 2007), in order to complete the annotations. As was noted by Setzer (2001), tagging temporal relations is hard for\n8. A somewhat cleaned-up version, 1.2, is available via the Linguistic Data Consortium. We used the freely available version, while checking that the most recent version does not exhibit significant differences in our experiments.\nthe annotators, who tend to miss relations, or produce inconsistent annotations. This is all the more obvious as the sizes of the texts increase, since then the number of possible links grows in the square of the number of temporal entities. Figure 23 shows the distribution of events among the texts. While annotators could be expected to keep track of all possible relations between events in small texts, the task was probably different for the numerous larger texts, and it has been noted that they tend to produce sets of disconnected temporal subgraphs on the majority of the corpus (Chambers & Jurafsky, 2008b).\nTable 4 shows two important consequences when considering relations inferred from an annotation: (a) a lot of annotations in TimeBank 1.1 are actually inconsistent when the temporal graph is saturated using procedures introduced earlier in the paper and (b) each text gives rise to several connected components of various sizes. It is worse if we compute some missing (but obvious) relations between dates whose values are fully specified (noted t-t in the table). As we have seen, the procedure for checking consistency can only say that a set of relations is globally inconsistent, without a hint of which relation(s) should be isolated to repair that situation. These texts have thus been ignored in our evaluations.\nThe fact that the temporal graphs of some texts are actually split between components of different sizes has consequences when considering the size of the referent graph: a fully connected graph of n entities can have up to n\u00d7 (n\u2212 1)/2 non-vague edges after saturation, while a text with scattered annotations might yield no other relation and a much smaller graph.\nWe have compared the number of relations present in a minimal graph obtained by transitive reduction with the number in the temporal closure of the interval-based graph, with respect to the number of events present in the text, on the whole TimeBank Corpus 1.1. (Figure 24). On this Figure, each point corresponds to a text, with its number of events along the x-axis and the number of relations\nin the reference used for evaluation with a given measure along the y-axis. It appears that minimal graph grows roughly linearly as expected (the variance being due to variable multiple branching when there is a lot of uncertainty). On the other hand, the temporal closure of the annotation is larger, much more irregular, with greater variance when the number of events grows. This is even worse for the \u201crelaxed\u201d measures which necessarily consider every possible edge between two events, even though it might only bear non-informative vague relations consisting of the disjunction of many relations. Note however that the reference size is not quadratic in the number of events, due to the high number of small self-connected components, as noted in the previous paragraph.\nThis has to be taken into account when considering an evaluation of a an entire corpus, and deciding what the contribution should be made by one text, or by a set of temporal relations. In the case of strict recall, the practice has been to add all edges from the temporal closures, possibly giving a given text a weight proportional to the square of its number of events. Micro-averaging the results on each text is probably not desirable either, giving too much importance to small texts with few relations. Having a reference with a size linear in the number of events solves the problem, providing a sort of smoothing with respect to that factor."}, {"heading": "6.2.2 MEASURES ON TIMEBANK", "text": "Recall We performed the same experiments on TimeBank as we did on the synthetic data, and we can observe the same phenomenon (a linear decrease of point recall), while raw results are much more irregular (Figure 25), with a larger unstability when almost all relations are removed.\nNote that while synthetic graph measures had values mainly above the \u201cy=x\u201d line, with some variation, annotated data show the same kind of parabolic behavior below that line.\nThe main difference here is how the reference is structured. The way generated graphs are built ensures that they are fully connected, and all relations from the saturated graphs are considered as the reference, since we have no reason to distinguish any subset in particular. On the other hand, in the human-annotated corpus, we only removed relations from the set of initial relations tagged by the annotators.\nIn the first case (artificial data), the reference graph is more resistant to the removal of random relations, since there is more redundancy, but in an extreme manner: it is only when enough relations are removed that some information is actually lost. This leads to a parabolic curve above the \u201cy=x\u201d line, showing that redundancy is improperly assessed by regular recall. The point graph is immune to this effect since the relevant relations are isolated first.\nOn the natural graphs on the contrary, the annotation is very \u201cfragile\u201d: annotators tend not to put too much redundant information in their annotation. Then, removing some of them removes also a lot of inferred relations at the same time (in quadratic quantity). This would not be a problem if the evaluation could stick to the annotated relations and if everyone tagged the same event pairs. But, as we already noticed, it is not the case. If we consider a system trying to build a temporal graph on a text from scratch, there is no reason to provide it with the same event pairs as the reference. For this reason, as soon as some redundancy is broken by removing relations, the recall improperly falls faster than \u201cy=x\u201d does. Again, the point-based graphs isolate the likely underlying models and their behavior is thus more controlled.\nRemember also that the level of vagueness influences the shape of the curves, and that human annotations are less specified and thus highly disjunctive.\nWe can also assume than human choices, when annotating, are important. Annotated relations are probably regarded as central by the annotators, hence close to an ideal \u201ccore\u201d set, especially since annotators tend to minimize the number of relations they tag. This assumption should be verified by more experiments on human assessments.\nPrecision To estimate the behavior of precision measures, we slightly changed the above experiment by switching more and more relations to different ones, thus \u201cdisturbing\u201d the initial graph, while trying to keep it consistent. Again, we did this a number of times, and averaged the results on points with similar rates of undisturbed relations. The result, shown Figure 26, is restricted to smaller values of change, since as we increase the proportion of changed relations, the graph gets closer to a purely random annotation. So we arbitrarily kept values between 0 and 40% of relations changed at random. Of course, without any more control on the kind of change allowed, we generate a lot of different types of modifications, some minor as well as some which totally change the inferences drawn from the annotation. This is reflected in the huge variance of the results we observed on the detailed data (not shown here), even close to the origin, i.e. the unchanged graph. Still, the experiment seems to confirm that the point-based measure follows more closely the ideal \u201cy=x\u201d function, so it would be more stable than the others, with the previous caveat about the variance.\nSystem prediction Finally, as a last indication of the importance of the evaluation methodology, we made a comparison of the behavior of the measures on the predictions of a real system. This is a\nrather tricky issue, since we want to see which measure distinguishes the better method from others, while the only way we have of evaluating the better method is the measure we want to assess. This was the motivation for the set of experiments we presented above. Still, it is legitimate to wonder if we can at least observe some differences in the context of a real system. One must then be cautious about the conclusions that can be drawn from this. In order to do so, we took an implementation of a temporal relation classifier reproducing standard work, as for instance in the work by Mani et al. (2006), that was used by one of the authors in another study (Denis & Muller, 2010). We applied it to TimeBank 1.1, and checked the correlations between the usual (strict) precision/recall and the counterparts based on transitive reduction. Figure 27 shows the relations between the scores on each text, with a subfigure for precision and one for recall. The spearman correlation, which estimates if one variable is monotonically related to the other without any other assumption, is 0.86 for precision, and 0.61 for recall, with very high significance levels (p < 10\u221220). The tentative interpretation we can make is that while they are obviously related, both types of measures show a lot of variance on the different texts, and are obviously sensitive to differences in the predictions. Texts are indeed ordered very differently by the different sets of measures. This is especially true for recall. We also note that point-based scores are generally higher, which can be easily explained since relations on an event are correct only when relations about endpoints are correct at the same time. Inferences can still muddy the waters and yield different results in that respect, so it could be interesting to investigate the differences in more detail."}, {"heading": "7. Conclusion", "text": "Comparing temporal constraints graphs is crucial in the task of extracting temporal information from texts, both from an evaluation point of view and in the perspective of incorporating global constraints in statistical learning procedures.\nWe argue here for comparison measures devoid of some of the biases inherent in the commonly used comparisons of closures of Allen-based temporal graphs. The measure is defined on the transitive reductions of the graph of (partially) ordered interval endpoints. Transitive reduction is conceptually intuitive, easy to compute and is unique in the cases considered. We have shown empirically that the behavior of this kind of measure is appropriate with the goals we had in mind.\nWe do not claim that ordering interval endpoints should be considered as the annotation provided by humans, only that the translation is possible and useful. It remains unclear if this could also be an acceptable way of presenting temporal information to humans, or how the resulting minimal graphs could be meaningfully re-translated into interval-based relations. We do not claim either that point relations should be the target of automated procedures to extract temporal information. The bulk of the work done on event relation classification deals primarily with extended intervals, as does the literature on temporal semantics (Steedman, 1997; Kamp & Reyle, 1993).\nWe plan to check our assumption that the procedure of translating interval constraints into endpoint constraints could be useful in the task of learning temporal constraints by integration of global constraints (for instance as a good indication of how close two temporal situations may be). It can also be useful when designing distances between structures in order to make structured predictions, in a manner similar to what is done on tree kernels for syntactic parsing (Collins & Duffy, 2002).\nSo far automated attempts only aim at predicting relations on given event-pairs, and most of them rely on a local learning strategy that does not take into account temporal constraints on the whole text. The few exceptions (Chambers & Jurafsky, 2008b; Bramsen et al., 2006) make use of subsets of relations, for instance a subset {before, after}, and any other relation is considered as \u201cvague\u201d. Then they are able to use integer linear programming using transitivity constraints on the temporal order. This simplicity could be preserved in an endpoint translation of the full algebra.\nThe issues presented here are relevant also for other graph-based representations in natural language processing tasks, as long as there are inference issues: for instance discourse representations are often build as a set of rhetorical relations between segments (Marcu & Echihabi, 2002). Inference properties of such relations remain to be investigated, and automated processes are still quite rare (but see works by Sagae, 2009; Wellner, Pustejovsky, Havasi, Rumshisky, & Saur\u00ed, 2006; Subba & Di Eugenio, 2009), however some widely adopted structures behave like partial orders (narrative chains, topic elaborations) and thus should follow some of the patterns we have investigated. In case of partial annotations or partial agreement, finding a minimally equivalent representation could be used for comparison.\nThe limitations of this methodological study are also the limitations of our knowledge of the way human readers process the temporal information, as a whole, that can be found in texts. To the best of our knowledge, the psycholinguistics literature has little interest in that specific question. Work exists on local temporal interpretation, i.e. the way temporal order between two events is determined, with respect to linguistic and extra-linguistic factors (Zwaan & Razdvansky, 2001). In a more global context, studies have focussed on the way a reader builds a situation corresponding to a text (Speer, Zacks, & Reynolds, 2007; Zwaan, 2008), with temporal, spatial, causal aspects, and it seems events are grouped in time-frames, or sets of events with causal relations, and comprehension shifts from one time-frame representation to another. If these approaches are right, readers build mental models that correspond to the situation for a given time-frame, and do not explicitly record relations between time-frames. This could explain the structure of a lot of annotations (a set of small connected components), but does not say much about the nature of the knowledge represented. It remains to be seen how investigations into the process of human comprehension could be beneficial to computationally oriented approaches of such a process."}, {"heading": "8. Acknowledgments", "text": "This work has benefited from tremendously helpful feedback from several colleagues, mainly Pierre Zweigenbaum and Pascal Denis, and Nicholas Asher. Pascal Denis also contributed to the development of the temporal tools used in this work, and allowed us to use some of the results of the system\nhe developed with Philippe Muller for temporal relation identification. We also thank Michel Gagnon, who suggested the comparison of an annotation with a degraded version of itself as an evaluation of a measure, a long time ago."}], "references": [{"title": "The Transitive Reduction of a Directed Graph", "author": ["A. Aho", "M. Garey", "J. Ullman"], "venue": "SIAM Journal on Computing,", "citeRegEx": "Aho et al\\.,? \\Q1972\\E", "shortCiteRegEx": "Aho et al\\.", "year": 1972}, {"title": "Maintaining Knowledge about Temporal Intervals", "author": ["J. Allen"], "venue": "Communications of the ACM, 832\u2013843.", "citeRegEx": "Allen,? 1983", "shortCiteRegEx": "Allen", "year": 1983}, {"title": "Temporal interpretation, discourse relations, and commonsense entailment", "author": ["N. Asher", "A. Lascarides"], "venue": "Linguistics and Philosophy,", "citeRegEx": "Asher and Lascarides,? \\Q1993\\E", "shortCiteRegEx": "Asher and Lascarides", "year": 1993}, {"title": "Timelines from text: Identification of syntactic temporal relations", "author": ["S. Bethard", "J.H. Martin", "S. Klingenstein"], "venue": "In International Conference on Semantic Computing,", "citeRegEx": "Bethard et al\\.,? \\Q2007\\E", "shortCiteRegEx": "Bethard et al\\.", "year": 2007}, {"title": "Inducing temporal graphs", "author": ["P. Bramsen", "P. Deshpande", "Y.K. Lee", "R. Barzilay"], "venue": "In Proceedings of the 2006 Conference on Empirical Methods in Natural Language Processing,", "citeRegEx": "Bramsen et al\\.,? \\Q2006\\E", "shortCiteRegEx": "Bramsen et al\\.", "year": 2006}, {"title": "Unsupervised Learning of Narrative Event Chains", "author": ["N. Chambers", "D. Jurafsky"], "venue": "In Proceedings of ACL-08: HLT,", "citeRegEx": "Chambers and Jurafsky,? \\Q2008\\E", "shortCiteRegEx": "Chambers and Jurafsky", "year": 2008}, {"title": "Jointly combining implicit constraints improves temporal ordering", "author": ["N. Chambers", "D. Jurafsky"], "venue": "In Proceedings of the 2008 Conference on Empirical Methods in Natural Language Processing,", "citeRegEx": "Chambers and Jurafsky,? \\Q2008\\E", "shortCiteRegEx": "Chambers and Jurafsky", "year": 2008}, {"title": "New ranking algorithms for parsing and tagging: Kernels over discrete structures, and the voted perceptron", "author": ["M. Collins", "N. Duffy"], "venue": "In Proceedings of 40th Annual Meeting of the Association for Computational Linguistics,", "citeRegEx": "Collins and Duffy,? \\Q2002\\E", "shortCiteRegEx": "Collins and Duffy", "year": 2002}, {"title": "Comparison of different algebras for inducing the temporal structure of texts", "author": ["P. Denis", "P. Muller"], "venue": "In Proceedings of Coling", "citeRegEx": "Denis and Muller,? \\Q2010\\E", "shortCiteRegEx": "Denis and Muller", "year": 2010}, {"title": "Classification topologique des ensembles convexes de Allen", "author": ["M.F. Dubois", "S.R. Schwer"], "venue": "In Proceedings of Reconnaissance des Formes et Intelligence Artificielle (RFIA),", "citeRegEx": "Dubois and Schwer,? \\Q2000\\E", "shortCiteRegEx": "Dubois and Schwer", "year": 2000}, {"title": "Temporal reasoning based on semi-intervals", "author": ["C. Freksa"], "venue": "Artificial Intelligence, 54(1-2), 199\u2013 227.", "citeRegEx": "Freksa,? 1992", "shortCiteRegEx": "Freksa", "year": 1992}, {"title": "Algorithms for analysing the temporal structure of discourse", "author": ["C. Grover", "J. Hitzeman", "M. Moens"], "venue": "In Sixth International Conference of the European Chapter of the Association", "citeRegEx": "Grover et al\\.,? \\Q1995\\E", "shortCiteRegEx": "Grover et al\\.", "year": 1995}, {"title": "Temporal centering", "author": ["M. Kameyama", "R. Passonneau", "M. Poesio"], "venue": "In Proceedings of ACL", "citeRegEx": "Kameyama et al\\.,? \\Q1993\\E", "shortCiteRegEx": "Kameyama et al\\.", "year": 1993}, {"title": "From Discourse to Logic", "author": ["H. Kamp", "U. Reyle"], "venue": null, "citeRegEx": "Kamp and Reyle,? \\Q1993\\E", "shortCiteRegEx": "Kamp and Reyle", "year": 1993}, {"title": "Maintenance of transitive closures and transitive reductions of graphs", "author": ["J. La Poutr\u00e9", "J. van Leeuwen"], "venue": "Graph-Theoretic Concepts in Computer Science,", "citeRegEx": "Poutr\u00e9 and Leeuwen,? \\Q1988\\E", "shortCiteRegEx": "Poutr\u00e9 and Leeuwen", "year": 1988}, {"title": "Learning Sentence-internal Temporal Relations", "author": ["M. Lapata", "A. Lascarides"], "venue": "Journal of Artificial Intelligence Research,", "citeRegEx": "Lapata and Lascarides,? \\Q2006\\E", "shortCiteRegEx": "Lapata and Lascarides", "year": 2006}, {"title": "The Language of Time: A Reader", "author": ["I. Mani", "J. Pustejovsky", "R. Gaizauskas"], "venue": null, "citeRegEx": "Mani et al\\.,? \\Q2005\\E", "shortCiteRegEx": "Mani et al\\.", "year": 2005}, {"title": "Temporally Anchoring and Ordering Events in News", "author": ["I. Mani", "B. Schiffman"], "venue": null, "citeRegEx": "Mani and Schiffman,? \\Q2005\\E", "shortCiteRegEx": "Mani and Schiffman", "year": 2005}, {"title": "Machine learning of temporal relations", "author": ["I. Mani", "M. Verhagen", "B. Wellner", "C.M. Lee", "J. Pustejovsky"], "venue": "In Proceedings of the 21st International Conference on Computational Linguistics and 44th Annual Meeting of the Association for Computational Linguistics,", "citeRegEx": "Mani et al\\.,? \\Q2006\\E", "shortCiteRegEx": "Mani et al\\.", "year": 2006}, {"title": "Three Approaches to Learning TLINKs in TimeML", "author": ["I. Mani", "B. Wellner", "M. Verhagen", "J. Pustejovsky"], "venue": "Tech. rep.,", "citeRegEx": "Mani et al\\.,? \\Q2007\\E", "shortCiteRegEx": "Mani et al\\.", "year": 2007}, {"title": "An unsupervised approach to recognizing discourse relations", "author": ["D. Marcu", "A. Echihabi"], "venue": "In Proceedings of 40th Annual Meeting of the Association for Computational Linguistics,", "citeRegEx": "Marcu and Echihabi,? \\Q2002\\E", "shortCiteRegEx": "Marcu and Echihabi", "year": 2002}, {"title": "Annotating and measuring temporal relations in texts", "author": ["P. Muller", "X. Tannier"], "venue": "In Proceedings of the 20th International Conference on Computational Linguistics (Coling", "citeRegEx": "Muller and Tannier,? \\Q2004\\E", "shortCiteRegEx": "Muller and Tannier", "year": 2004}, {"title": "A computational model of the semantics of tense and aspect", "author": ["R.J. Passonneau"], "venue": "Computational Linguistics, 14(2), 44\u201360.", "citeRegEx": "Passonneau,? 1988", "shortCiteRegEx": "Passonneau", "year": 1988}, {"title": "The TIMEBANK Corpus", "author": ["J. Pustejovsky", "P. Hanks", "R. Saur\u00ed", "A. See", "R. Gaizauskas", "A. Setzer", "D. Radev", "B. Sundheim", "D. Day", "L. Ferro", "M. Lazo"], "venue": "In Proceedings of Corpus Linguistics,", "citeRegEx": "Pustejovsky et al\\.,? \\Q2003\\E", "shortCiteRegEx": "Pustejovsky et al\\.", "year": 2003}, {"title": "Elements of Symbolic Logic", "author": ["H. Reichenbach"], "venue": "McMillan, New York.", "citeRegEx": "Reichenbach,? 1947", "shortCiteRegEx": "Reichenbach", "year": 1947}, {"title": "Simplifying Sets of Events by Selecting Temporal Relations", "author": ["A. Rodr\u00edguez", "N.V. de Weghe", "P.D. Maeyer"], "venue": "In Geographic Information Science, Third International Conference, GIScience 2004,", "citeRegEx": "Rodr\u00edguez et al\\.,? \\Q2004\\E", "shortCiteRegEx": "Rodr\u00edguez et al\\.", "year": 2004}, {"title": "Analysis of discourse structure with syntactic dependencies and data-driven shiftreduce parsing", "author": ["K. Sagae"], "venue": "Proceedings of the 11th International Conference on Parsing Technologies (IWPT\u201909), Paris, France.", "citeRegEx": "Sagae,? 2009", "shortCiteRegEx": "Sagae", "year": 2009}, {"title": "TimeML Annotation Guidelines, Version 1.2.1", "author": ["R. Saur\u00ed", "J. Littman", "R. Knippen", "R. Gaizauskas", "A. Setzer", "J. Pustejovsky"], "venue": null, "citeRegEx": "Saur\u00ed et al\\.,? \\Q2006\\E", "shortCiteRegEx": "Saur\u00ed et al\\.", "year": 2006}, {"title": "A hierarchy for convex relations", "author": ["F. Schilder"], "venue": "Proceedings of the 4th International Workshop on Temporal Representation and Reasoning (TIME \u201997), pp. 86\u201393, Washington, DC, USA. IEEE Computer Society.", "citeRegEx": "Schilder,? 1997", "shortCiteRegEx": "Schilder", "year": 1997}, {"title": "Temporal Information in Newswire Articles: an Annotation Scheme and Corpus Study", "author": ["A. Setzer"], "venue": "Ph.D. thesis, University of Sheffield, UK.", "citeRegEx": "Setzer,? 2001", "shortCiteRegEx": "Setzer", "year": 2001}, {"title": "The Role of Inference in the Temporal Annotation and Analysis of Text", "author": ["A. Setzer", "R. Gaizauskas", "M. Hepple"], "venue": "Language Resources and Evaluation,", "citeRegEx": "Setzer et al\\.,? \\Q2006\\E", "shortCiteRegEx": "Setzer et al\\.", "year": 2006}, {"title": "Tense interpretation in the context of narrative", "author": ["F. Song", "R. Cohen"], "venue": "In Proceedings of AAAI\u201991,", "citeRegEx": "Song and Cohen,? \\Q1991\\E", "shortCiteRegEx": "Song and Cohen", "year": 1991}, {"title": "Mesurer la similarit\u00e9 de graphes", "author": ["S. Sorlin"], "venue": "Ph.D. thesis, Universit\u00e9 Claude Bernard, Lyon I.", "citeRegEx": "Sorlin,? 2006", "shortCiteRegEx": "Sorlin", "year": 2006}, {"title": "Human brain activity time-locked to narrative event boundaries", "author": ["N. Speer", "J. Zacks", "J. Reynolds"], "venue": "Psychological Science,", "citeRegEx": "Speer et al\\.,? \\Q2007\\E", "shortCiteRegEx": "Speer et al\\.", "year": 2007}, {"title": "Temporality", "author": ["M. Steedman"], "venue": "van Benthem, J., & ter Meulen, A. (Eds.), Handbook of Logic and Language. Elsevier.", "citeRegEx": "Steedman,? 1997", "shortCiteRegEx": "Steedman", "year": 1997}, {"title": "Dynamic semantics for tense and aspect", "author": ["M. Steedman"], "venue": "Proceedings of IJCAI\u201995, pp. 1292\u20131298.", "citeRegEx": "Steedman,? 1995", "shortCiteRegEx": "Steedman", "year": 1995}, {"title": "An effective discourse parser that uses rich linguistic information", "author": ["R. Subba", "B. Di Eugenio"], "venue": "In Proceedings of Human Language Technologies: The 2009 Annual Conference of the North American Chapter of the Association for Computational Linguistics,", "citeRegEx": "Subba and Eugenio,? \\Q2009\\E", "shortCiteRegEx": "Subba and Eugenio", "year": 2009}, {"title": "Evaluation Metrics for Automatic Temporal Annotation of Texts", "author": ["X. Tannier", "P. Muller"], "venue": "In ELRA (Ed.), Proceedings of the Sixth International Language Resources and Evaluation (LREC\u201908)", "citeRegEx": "Tannier and Muller,? \\Q2008\\E", "shortCiteRegEx": "Tannier and Muller", "year": 2008}, {"title": "Experiments with Reasoning for Temporal Relations between Events", "author": ["M. Tatu", "M. Srikanth"], "venue": "In Proceedings og the 22nd International Conference on Computational Linguistics (Coling", "citeRegEx": "Tatu and Srikanth,? \\Q2008\\E", "shortCiteRegEx": "Tatu and Srikanth", "year": 2008}, {"title": "Reasoning about qualitative temporal information", "author": ["P. van Beek"], "venue": "Artificial Intelligence,", "citeRegEx": "Beek,? \\Q1992\\E", "shortCiteRegEx": "Beek", "year": 1992}, {"title": "SemEval2007 - 15: TempEval Temporal Relation Identification", "author": ["M. Verhagen", "R. Gaizauskas", "F. Schilder", "M. Hepple", "G. Katz", "J. Pustejovsky"], "venue": "In Proceedings of SemEval workshop at ACL 2007,", "citeRegEx": "Verhagen et al\\.,? \\Q2007\\E", "shortCiteRegEx": "Verhagen et al\\.", "year": 2007}, {"title": "A model-theoretic coreference scoring scheme", "author": ["M. Vilain", "J. Burger", "J. Aberdeen", "D. Connolly", "L. Hirschman"], "venue": "Proceedings of the 6th conference on Message understanding,", "citeRegEx": "Vilain et al\\.,? \\Q1995\\E", "shortCiteRegEx": "Vilain et al\\.", "year": 1995}, {"title": "Constraint propagation algorithms for temporal reasoning: a revised report", "author": ["M. Vilain", "H. Kautz", "P. van Beek"], "venue": null, "citeRegEx": "Vilain et al\\.,? \\Q1990\\E", "shortCiteRegEx": "Vilain et al\\.", "year": 1990}, {"title": "Tense as discourse anaphor", "author": ["B.L. Webber"], "venue": "Computational Linguistics, 14(2), 61\u201373.", "citeRegEx": "Webber,? 1988", "shortCiteRegEx": "Webber", "year": 1988}, {"title": "Classification of discourse coherence relations: An exploratory study using multiple knowledge sources", "author": ["B. Wellner", "J. Pustejovsky", "C. Havasi", "A. Rumshisky", "R. Saur\u00ed"], "venue": "In Proceedings of the 7th SIGdial Workshop on Discourse and Dialogue,", "citeRegEx": "Wellner et al\\.,? \\Q2006\\E", "shortCiteRegEx": "Wellner et al\\.", "year": 2006}, {"title": "Psychology and Sociology of Literature", "author": ["G. Steen"], "venue": null, "citeRegEx": "Steen,? \\Q2008\\E", "shortCiteRegEx": "Steen", "year": 2008}], "referenceMentions": [{"referenceID": 24, "context": "Temporal processing of texts is a somewhat recent field from a methodological point of view, even though temporal semantics has a long tradition, dating back at least to the 1940\u2019s (Reichenbach, 1947).", "startOffset": 181, "endOffset": 200}, {"referenceID": 35, "context": "While theoretical and formal linguistic approaches to temporal interpretation at the discourse level have been very active in the late 1980s and early 1990s (Kamp & Reyle, 1993; Asher & Lascarides, 1993; Steedman, 1995; Webber, 1988), empirical approaches were less frequent, and very few natural language processing systems were evaluated beyond a few instances (Grover, Hitzeman, & Moens, 1995; Kameyama, Passonneau, & Poesio, 1993; Passonneau, 1988; Song & Cohen, 1991).", "startOffset": 157, "endOffset": 233}, {"referenceID": 43, "context": "While theoretical and formal linguistic approaches to temporal interpretation at the discourse level have been very active in the late 1980s and early 1990s (Kamp & Reyle, 1993; Asher & Lascarides, 1993; Steedman, 1995; Webber, 1988), empirical approaches were less frequent, and very few natural language processing systems were evaluated beyond a few instances (Grover, Hitzeman, & Moens, 1995; Kameyama, Passonneau, & Poesio, 1993; Passonneau, 1988; Song & Cohen, 1991).", "startOffset": 157, "endOffset": 233}, {"referenceID": 22, "context": "While theoretical and formal linguistic approaches to temporal interpretation at the discourse level have been very active in the late 1980s and early 1990s (Kamp & Reyle, 1993; Asher & Lascarides, 1993; Steedman, 1995; Webber, 1988), empirical approaches were less frequent, and very few natural language processing systems were evaluated beyond a few instances (Grover, Hitzeman, & Moens, 1995; Kameyama, Passonneau, & Poesio, 1993; Passonneau, 1988; Song & Cohen, 1991).", "startOffset": 363, "endOffset": 472}, {"referenceID": 1, "context": "The given practice nowadays has been to compute some sort of transitive closure over the network/graph of constraints on temporal events (usually expressed in the well-known Allen algebra (Allen, 1983), or a sub-algebra), and then either to compare the sets of simple temporal relations that are deduced from it with standard precision and recall, or to measure the agreement between all relations, including disjunctions of information (Verhagen, Gaizauskas, Schilder, Hepple, Katz, & Pustejovsky, 2007).", "startOffset": 188, "endOffset": 201}, {"referenceID": 40, "context": "Precision and recall evaluations are often not performed on graphs of relations between all events in a text however, but on the subproblem of ordering pairs of successively described events (Mani & Schiffman, 2005; Verhagen et al., 2007) or even same-sentence events (Lapata & Lascarides, 2006) (in our example, only e1 b e2 and e3 fi t1 1).", "startOffset": 191, "endOffset": 238}, {"referenceID": 30, "context": "The main reason of this choice is the difficulty of the task, even for human beings, of assigning temporal relations in a large text (Setzer et al., 2006).", "startOffset": 133, "endOffset": 154}, {"referenceID": 16, "context": "Exceptions exist, as in the work of Mani et al. (2006) and Mani et al.", "startOffset": 36, "endOffset": 55}, {"referenceID": 16, "context": "Exceptions exist, as in the work of Mani et al. (2006) and Mani et al. (2007).", "startOffset": 36, "endOffset": 78}, {"referenceID": 1, "context": "A constraint propagation algorithm ensures that all existing temporal relations are added to the network, labelling an inconsistency with \u2205 (Allen, 1983).", "startOffset": 140, "endOffset": 153}, {"referenceID": 1, "context": "A table of all composition rules in Allen algebra can be found in the work of Allen (1983) or Rodriguez et al.", "startOffset": 36, "endOffset": 91}, {"referenceID": 1, "context": "A table of all composition rules in Allen algebra can be found in the work of Allen (1983) or Rodriguez et al. (2004), and a sample for a few basic relations is given in Table 2.", "startOffset": 36, "endOffset": 118}, {"referenceID": 42, "context": "2 Time Point Algebra and Convex Relations Interval graphs can be converted easily into graphs between points (Vilain et al., 1990), where an event is split into a beginning and an ending point; the mapping between Allen relations and point relations is given at Table 1.", "startOffset": 109, "endOffset": 130}, {"referenceID": 42, "context": "The relation between two time points is continuous if the assigned set of simple relations is convex (Vilain et al., 1990).", "startOffset": 101, "endOffset": 122}, {"referenceID": 10, "context": "A so-called convex relation corresponds to cases where relations r1 to r4 are assigned to one of the 6 possible relations {<}, {<, =}, {=}, {<, =, >}, {>}, {>=}2, considered as conceptual neighbors (Freksa, 1992).", "startOffset": 198, "endOffset": 212}, {"referenceID": 28, "context": "See the work by Schilder (1997) for a more complete presentation within a natural language processing perspective.", "startOffset": 16, "endOffset": 32}, {"referenceID": 40, "context": "Similar measures have also been used during the TempEval evaluation campaign in 2007 (Verhagen et al., 2007), with a reduced set of relations : \u201cbefore\u201d, \u201coverlaps\u201d and \u201cbefore or overlaps\u201d.", "startOffset": 85, "endOffset": 108}, {"referenceID": 1, "context": "Unfortunately, a unique minimal graph does not exist in the general case, and in particular for Allen relations. Rodriguez et al. (2004) propose a way to find all minimal graphs for a given temporal graph.", "startOffset": 96, "endOffset": 137}, {"referenceID": 1, "context": "Unfortunately, a unique minimal graph does not exist in the general case, and in particular for Allen relations. Rodriguez et al. (2004) propose a way to find all minimal graphs for a given temporal graph. Their algorithm first finds core relations, relations that are in every minimal graph, by intersecting all derivations, and then computes all possible remaining combinations in order to find those composing a minimal graph. For example, for the relation RA,B between A and B, derivations are RA,C \u25e6RC,B , RA,D \u25e6RD,B , RA,E \u25e6RE,B , etc. If the intersection of all these derived relations equals RA,B , it means that RA,B is not a core relation, since it can be obtained by composing some other relations. Otherwise, the relation is a core relation, since removing it always leads to a loss of information. The way this \u201ckernel\u201d is obtained ensures its uniqueness. However, the second part of the procedure (compute remaining combinations) is computationally impractical, even for medium-sized graphs, since every subset of relations must be considered to determine a minimal graph on top of core relations. The authors do not detail much their empirical investigations, offering no support for the usability of this method. Moreover, it does not lead to a unique graph that could be compared to a reference. Going back to evaluation, Tannier and Muller (2008) suggest the comparison of graphs through core relations, which are easy to compute and give a good idea of how important the relations are in a same graph.", "startOffset": 96, "endOffset": 1365}, {"referenceID": 37, "context": "6 Behavior of Existing Metrics As stated in the work by Tannier and Muller (2008), a recall measure is expected to decrease in a linear way when the amount of information decreases.", "startOffset": 56, "endOffset": 82}, {"referenceID": 23, "context": "The Figure presents an idealized case; more thorough experiments were done on the whole TimeBank corpus (Pustejovsky et al., 2003) and explained in details in Section 6.", "startOffset": 104, "endOffset": 130}, {"referenceID": 32, "context": "Many similarity measures exist between two graphs once a many-to-many correspondence is found between the nodes of both graphs (Sorlin, 2006).", "startOffset": 127, "endOffset": 141}, {"referenceID": 32, "context": "A traditional similarity function between two graphs is the following (Sorlin, 2006):", "startOffset": 70, "endOffset": 84}, {"referenceID": 8, "context": "1 Transitive Reduction of Endpoint Graph To address the problem of finding minimal graphs and to take into account the relative importance of relations, we take inspiration from the work of Dubois and Schwer (2000) in two main ideas.", "startOffset": 190, "endOffset": 215}, {"referenceID": 0, "context": "It is enough to prove that E(G) (or G) is the graph of a transitive, acyclic relation to prove that E(G) has a unique transitive reduction (Aho et al., 1972).", "startOffset": 139, "endOffset": 157}, {"referenceID": 40, "context": "But in a relaxed scheme, with disjunctions, it becomes necessary to apply a weighting procedure; a response is no longer assigned a binary value (0 or 1), but for example one of the values in Table 3, in a manner similar to what was done in TempEval (Verhagen et al., 2007).", "startOffset": 250, "endOffset": 273}, {"referenceID": 1, "context": "The temporal relations encode topological information between the time intervals of occurring eventualities, using relations that are equivalent to Allen relations, although they have different names. The TimeML standard specifies the relations between events, the anchoring of events to \u201ctimes\u201d (dates, hours) and the relations between times. There are about 7000 annotated relations between temporal entities. Additions to this set have been proposed (Bethard, Martin, & Klingenstein, 2007), in order to complete the annotations. As was noted by Setzer (2001), tagging temporal relations is hard for", "startOffset": 148, "endOffset": 562}, {"referenceID": 16, "context": "In order to do so, we took an implementation of a temporal relation classifier reproducing standard work, as for instance in the work by Mani et al. (2006), that was used by one of the authors in another study (Denis & Muller, 2010).", "startOffset": 137, "endOffset": 156}, {"referenceID": 34, "context": "The bulk of the work done on event relation classification deals primarily with extended intervals, as does the literature on temporal semantics (Steedman, 1997; Kamp & Reyle, 1993).", "startOffset": 145, "endOffset": 181}, {"referenceID": 4, "context": "The few exceptions (Chambers & Jurafsky, 2008b; Bramsen et al., 2006) make use of subsets of relations, for instance a subset {before, after}, and any other relation is considered as \u201cvague\u201d.", "startOffset": 19, "endOffset": 69}], "year": 2011, "abstractText": "Temporal information has been the focus of recent attention in information extraction, leading to some standardization effort, in particular for the task of relating events in a text. This task raises the problem of comparing two annotations of a given text, because relations between events in a story are intrinsically interdependent and cannot be evaluated separately. A proper evaluation measure is also crucial in the context of a machine learning approach to the problem. Finding a common comparison referent at the text level is not obvious, and we argue here in favor of a shift from eventbased measures to measures on a unique textual object, a minimal underlying temporal graph, or more formally the transitive reduction of the graph of relations between event boundaries. We support it by an investigation of its properties on synthetic data and on a well-know temporal corpus.", "creator": "TeX"}}}