{"id": "1402.3613", "review": {"conference": "arxiv", "VERSION": "v1", "DATE_OF_SUBMISSION": "14-Feb-2014", "title": "Finding Coordinated Paths for Multiple Holonomic Agents in 2-d Polygonal Environment", "abstract": "avoiding collisions is fundamentally one of the potential vital tasks for systems of autonomous mobile agents. we mostly focus on confronting the problem of finding continuous coordinated fault paths for multiple human mobile disc tracking agents in filling a rectangular 2 - dimension d transparent environment concurrent with polygonal obstacles. the optimal problem is pspace - versus hard, with the simulated state trial space itself growing exponentially in getting the number of deployed agents. therefore, the state way of the art methods include mainly reactive processing techniques and integrated sampling - vector based iterative response algorithms.", "histories": [["v1", "Fri, 14 Feb 2014 22:09:44 GMT  (1451kb,D)", "http://arxiv.org/abs/1402.3613v1", "Proceedings of the 13th International Conference on Autonomous Agents and Multiagent Systems (AAMAS 2014)"]], "COMMENTS": "Proceedings of the 13th International Conference on Autonomous Agents and Multiagent Systems (AAMAS 2014)", "reviews": [], "SUBJECTS": "cs.AI cs.RO", "authors": ["pavel janovsk\\'y", "michal \\v{c}\\'ap", "ji\\v{r}\\'i vok\\v{r}\\'inek"], "accepted": false, "id": "1402.3613"}, "pdf": {"name": "1402.3613.pdf", "metadata": {"source": "CRF", "title": "Finding Coordinated Paths for Multiple Holonomic Agents in 2-d Polygonal Environment", "authors": ["Pavel Janovsk\u00fd", "Michal \u010c\u00e1p", "Ji\u0159\u00ed Vok\u0159\u00ednek"], "emails": ["pavel.janovsky@agents.fel.cvut.cz", "michal.cap@agents.fel.cvut.cz", "jiri.vokrinek@agents.fel.cvut.cz"], "sections": [{"heading": null, "text": "We compare the performance of a widely-used reactive method ORCA with three variants of a popular planning algorithm RRT* applied to multi-agent path planning and find that an algorithm combining reactive collision avoidance and RRT* planning, which we call ORCA-RRT* can be used to solve instances that are out of the reach of either of the techniques. We experimentally show that: 1) the reactive part of the algorithm can efficiently solve many multi-agent path finding problems involving large number of agents, for which RRT* algorithm is often unable to find a solution in limited time and 2) the planning component of the algorithm is able to solve many instances containing local minima, where reactive techniques typically fail.\nCategories and Subject Descriptors I.2.11 [ARTIFICIAL INTELLIGENCE]: Distributed Artificial Intelligence\u2014Intelligent agents, Multiagent systems\nGeneral Terms Algorithms; Measurement; Performance; Experimentation\nKeywords Path finding problem; multi-agent solver; planning; reactive technique"}, {"heading": "1. INTRODUCTION", "text": "One of the fundamental tasks for a team of mobile agents is planning trajectories for the agents so as to avoid collisions\n\u2217Equal contribution.\nAppears in: Proceedings of the 13th International Conference on Autonomous Agents and Multiagent Systems (AAMAS 2014), Lomuscio, Scerri, Bazzan, Huhns (eds.), May, 5\u20139, 2014, Paris, France. Copyright c\u00a9 2014, International Foundation for Autonomous Agents and Multiagent Systems (www.ifaamas.org). All rights reserved.\nbetween them. The problem arises in a variety of application domains such as in the teams of autonomous robots or in air traffic management systems.\nThe problem of finding coordinated paths for a group of agents is studied since 1980s. In theory it is well known that finding even non-optimal collision-free paths from defined start positions to goal positions for a group of objects in restricted 2-d space is PSPACE-hard [3] and thus (unless P=PSPACE) there exist instances that cannot be solved in polynomial time.\nRecent advancements in the field of multi-agent path planning include methods that solve restricted variant of the cooperative path finding problem, where point-like agents move using synchronous discrete steps on a graph. For this variant of the problem there exist complete polynomial algorithms such as BIBOX [7] or Push & Rotate [1], nonpolynomial (but often effective) optimal algorithms [6] and anytime algorithms [9]. However, the graph abstraction used in this problem formulation is not suitable for systems where the size of the agents cannot be neglected.\nResearch in trajectory planning for multiple agents has been made in the field of decoupled and centralized continuous planning domains. Decoupled approaches often offer better efficiency, but lose completeness. Frequently used decoupled technique is prioritized planning [2]. Here priorities are assigned to agents which specify the order in which their single-agent planning will take place. Each agent takes into account the plans of all agents with higher priority as moving obstacles. This method can be very efficient especially in uncluttered environments, but it is intrinsically incomplete. The method requires that the individual re-planning takes place in the space-time. It is relatively straightforward to perform such planning with forward search algorithms such as A*, but it remains unclear how should be such a planning efficiently done in continuous space e.g. using some of the sampling-based algorithms.\nLittle attention has been devoted so far to the problem of finding coordinated trajectories for agents in continuous environments with polygonal obstacles. A straightforward solution is to construct the joint state space of all agents and search such a space using one of the sampling-based methods for continuous path planning. Alternatively, one can resort to a reactive collision avoidance techniques that proved to be very efficient in practice. The most prominent representatives of the two mentioned approaches are RRT* and ORCA.\nIn 2011 Karaman and Frazzoli [4] published the RRT*\nar X\niv :1\n40 2.\n36 13\nv1 [\ncs .A\nI] 1\n4 Fe\nb 20\n14\nalgorithm, an anytime extension of RRT (rapidly exploring random tree [5]) that is probabilistically complete and asymptotically optimal. The algorithm is designed for continuous state spaces in which it can efficiently find a path from a given start state to a given goal region by incrementally building a tree that is rooted at the start state and spans towards randomly sampled states from some given state space. Once such a tree first reaches the goal region, we can follow its edges backwards to obtain the first feasible path from start state to the target region. With more and more samples being added to the tree, the solution incrementally improves.\nOptimal reciprocal collision avoidance (ORCA) is one of the many methods based on velocity obstacle paradigm. It was proposed in 2011 by Jur van den Berg et al. [8] and demonstrated to be capable of generating collision-free motion for a large number of agents in a cluttered workspace with local guarantees on optimality and safety. Even though ORCA is a powerful tool for solving multi-agent collision avoidance, there are many instances of the problem that it is not able to solve due to the lack of cooperation and planning. An example of such an instance is any scenario where an agent has to make a long trip away from a narrow corridor to clear the way to another agent.\nThe goal of this paper is to analyze the problem of planning collision-free continuous paths for multiple holonomic agents and evaluate the performance of the two approaches in 2-d polygonal environments.\nWe study the applicability of the RRT* algorithm for multi-agent path planning and compare it with ORCA \u2013 one of the most widely used techniques for the problem, which has been successfully used in several software and hardware multi-agent implementations. Moreover, we propose a novel variant of RRT* algorithm that is specifically suited for multi-agent path planning. The new ORCA-RRT* combines RRT* planning with reactive collision avoidance. Our experiments show that the combined algorithm is able to solve instances that were not solved by either of the techniques alone. Further, on many other instances the new algorithm provides higher quality solution that the other algorithms.\nThe rest of the paper is structured as follows. In Section 2, we state the multi-agent path finding problem. Then, in Section 3 we describe the multi-agent RRT* and introduce three variants of the algorithm that are applicable for multi-agent path planning in continous environments. The paper is concluded by a large-scale experimental analysis comparing the performance of the individual algorithms."}, {"heading": "2. PROBLEM STATEMENT", "text": "We define the multi-agent path finding problem as follows. Consider n agents operating in 2-dimensional Euclidean space with polygonal obstacles. The starting positions of agents are given as n-tuple (s1, . . . , sn), where si is the starting position of i-th agent. The n-tuple (d1, . . . , dn) gives the agents\u2019 destinations. We assume that the agents have disc-shaped bodies, where the radius of agent i is denoted as ri. The final trajectory of i-th agent \u03c0i(t) is a mapping R \u2192 R2 of time t to 2 dimensional Euclidean space of the agent, where \u03c0i(0) = si. The time t d i is the minimal time after which the i-th agent remains at its destination,\ntdi = min(ti|\u2200t \u2208 \u3008ti,\u221e) : \u03c0i(t) = di).\nLet O \u2282 R2 denote the regions of the space occupied by the obstacles. Then, the collision-free property of the set of multi-agent trajectories can be defined as\nCF ({\u03c01, . . . , \u03c0n}, O) = true iff \u2200i, j, t, i 6= j : dist(\u03c0i(t), \u03c0j(t)) > ri + rj and\n\u2200i, t : D(\u03c0i(t), ri) \u2229O = \u2205,\nwhere dist(x, y) is Euclidean distance in 2 dimensional space and D(\u03c0i(t), ri) denotes a disc of radius ri centered at \u03c0i(t). The task is to find n-tuple (\u03c01, . . . , \u03c0n) such that the agents never collide and the sum of times agents spend on the path to their final destinations is minimal. The problem statement is defined as follows:\nFind (\u03c01, . . . , \u03c0n) s. t.\nCF ({\u03c01, . . . , \u03c0n}, O) = true n\u2211\ni=1\ntdi is minimal."}, {"heading": "3. RRT* FOR MULTI-AGENT PATH FINDING", "text": "The RRT* algorithm was originally designed for singleagent motion planning, however, it can be adapted to solve multi-agent path planning problems. In this section we will discuss how can be the RRT* algorithm leveraged in a multiagent setting.\nWe let the RRT* algorithm operate in the joint state space J = C1 \u00d7 . . . \u00d7 Cn, where Ci \u2286 R2 is the state space of the i-th agent. The initial state in the joint state space is xinit = (s1, . . . , sn), goal state is xgoal = (d1, . . . , dn) and any other sampled state is also n-tuple containing positions of all agents. The algorithm searches for a path p : [0, 1]\u2192 J from xinit to xgoal, which can be then decomposed into a set trajectories {\u03c0i} for each individual agent i. The pseudocode of RRT* algorithm for multi-agent path planning is exposed in Algorithm 1.\nThe distance metric used in the algorithm is the sum of Euclidean distances of all n agents:\ndist(x,y) = n\u2211 i=1 distE(xi, yi),\nwhere x, y \u2208 J and xi, yi \u2208 Ci. Now, we provide definitions of the following RRT* primitive procedures: Nearest Neighbor: Given a graph T = (V,E) and a state x \u2208 J , the function Nearest(T,x) returns a vertex v \u2208 V that is the closest to state x in terms of the distance metric dist(\u00b7, \u00b7).\nNear Vertices: Given a graph T = (V,E), a state x \u2208 J and the numbers n,m \u2208 N, the function Near(T,x, n) returns a set {y : y \u2208 V \u2227 dist(x,y) < rn}, where rn = \u03b3(logn/n)1/d, \u03b3 is a constant and d = 2n is the dimension of the space J .\nLocal Steering Procedure: Given two states x and y, a domain-specific local steering procedure Steer(x,y) returns true if the steering procedure is able to connect the state x to the state y. In the context of multi-agent path finding, the steering procedure seeks for a set of paths {pi} such that pi(0) = xi and pi(1) = yi for each agent i and all paths are\nmutually collision-free. We consider three different methods for local steering which are discussed in detail in Section 3.1.\nFind best parent: Given a graph T = (V,E), a set X \u2286 V and a state x \u2208 J , the function FindBestParent(T,X, x) returns the best parent vertex v \u2208 X for state x, i.e. the vertex that yields the lowest cost of path xinit \u2192 x.\nRewire: Given a graph T = (V,E), a set X \u2286 V and a state x \u2208 J the function Rewire(T,X, x) examines all vertices from X to see whether their cost can be improved by going through the new vertex x. If there are any such vertices, the tree is rewired so that these vertices become children of x, which allows them to improve the cost of their path from the initial state xinit.\nThe main loop of the multi-agent RRT* algorithm (see Algorithm 1) works as follows: Until interrupted, the algorithm samples states from the joint state space J (line 4). Each such a random sample is used in an attempt to extend the tree. First, the nearest vertex from the tree T to the random sample s is determined (line 5). Then, the algorithm attempts to connect the vertex x to the random sample s using the local steering procedure (line 6). If the two points can be connected using the local steering procedure the algorithm proceeds to its optimizing part, otherwise it tries again with another sample. Then a set of vertices Xnear that are within a specified distance to the x is determined (line 7). The Xnear set serves two purposes: Firstly it is used to find the best parent for the new vertex x (line 8). Secondly, after the new vertex x is added to the tree, the vertices from Xnear are rewired if it improves their cost (line 10).\nOnce the goal state1 is successfuly added to the tree, one can follow the links backwards to obtain a valid path from the state xinit to the state xgoal. However, even after the first solution has been returned, the algorithm does not stop iterating. Instead, the algorithm continously extends and rewires the tree, which leads to incremental discovery of further higher-quality paths.\nAlgorithm 1 Multi-agent RRT*\n1: V \u2190 {xinit};E \u2190 \u2205; 2: while not interrupted do 3: T = (V,E); 4: s\u2190 Sample(); 5: x\u2190 Nearest(T, s); 6: if Steer(x, s) then 7: Xnear \u2190 Near(T, s, |V |); 8: xp \u2190 FindBestParent(T,Xnear, s); 9: V \u2190 V \u222a {x};E \u2190 E \u222a {(xp,x)};\n10: Rewire(T,Xnear, s); 11: end if 12: end while"}, {"heading": "3.1 Multi-agent Extensions", "text": "The crucial component influencing the performance of the RRT* algorithm is the local steering procedure. We consider a multi-agent steering function of the following form:\n1Here we assume that the point xgoal is sampled with a certain non-zero probability (e.g. 1%) to overcome the need to define the goal as a region instead of a point.\nSteer(x,y) = true if \u2203 {\u03c0i} s.t. {\u03c0i} = E(x,y, O) and CF ({\u03c0i}, O) and \u2203t \u2200i \u03c0i(t) = yi\nfalse otherwise\n,\nwhere x,y \u2208 J . The function E(x,y, O) : J \u00d7 J \u00d7P(R2)\u2192 \u03a01 \u00d7 . . .\u00d7\u03a0n is an extension function that returns a set of paths {\u03c0i}, where \u03c0i is a path for agent i such that \u03c0i(0) = xi and \u2203td s.t. \u2200t \u2265 td : \u03c0i(t) = yi. Note that the steering procedure returns true only if the trajectories generated by the extension function are 1) avoiding all static obstacles and 2) the trajectories are mutually collision-free.\nWe study three methods that can serve as a valid extension function for the multi-agent steering procedure: 1) Line extension connects individual agents using straight lines, 2) VisibilityGraph extension connects individual agents using the optimal single-agent path, and 3) ORCA extension generates joint path by simulating ORCA algorithm, where each agent tries to follow its single-agent optimal path.\n3.1.1 Line Extension The first considered extension method is a relatively straight-\nforward extension of classical single-agent RRT* planner as exposed in [4], which connects two states using straight line paths. In a multi-agent setting, we connect each of the agents by a straight path:\nELine(x,y, O) = {line(xi, yi)},\nwhere the line(x, y) : R2 \u00d7 R2 \u2192 \u03a0 is a function defined as\nline(xi, yi) = \u03c0i(t) =\n{ xi + vi \u00b7 t yi\u2212xi|yi\u2212xi| for t < |yi\u2212xi| vi\nyi otherwise ,\nwhere vi denotes the maximal speed of the i-th agent. Observe that such a trajectory prescribes that the agent i should move to the point yi along the straight line at maximum speed; when the point yi is reached, the agent stays there. Note that it can happen that a solution returned by this method is rejected by the steering procedure if a) any of the trajectories intersects some of the obstacles or b) some of the trajectories are in mutual collision.\n3.1.2 Visibility Graph Extension Another considered method uses the single-agent optimal\npaths (i.e. optimally avoids obstacles, but ignores interactions among the agents) between the points xi and yi. In 2-d polygonal environments, one can efficiently find such a path by constructing a visibility graph and subsequently by finding the shortest path in such a graph. Let the shortest path in the visibility graph of i-th agent be represented as a sequence of edges (ei1, . . . , eimi). The resulting trajectory of agent i will follow this path. The Visibility Graph extension function can be formally defined as\nEV G(x,y, O) = {segments(xi, yi)},\nwhere segments(xi, yi) : R2 \u00d7 R2 \u2192 \u03a0 is a function defined as\nsegments(xi,yi) = \u03c0i(t)\n=  source(eij) + vi \u00b7 t eij|eij | for t \u2208 ( j\u22121\u2211 k=1 |eik| vi , j\u2211 k=1 |eik| vi ), j \u2208 \u30081,mi\u3009\nyi otherwise\n,\nwhere source(e) function returns the source vertex of the edge e. Note that the trajectories returned by this method are guaranteed to be obstacle avoiding, therefore, the steering procedure may only reject them if the resulting trajectories are in mutual collision.\n3.1.3 ORCA Extension The last considered extension method generates trajec-\ntories by following optimal single-agent paths together with Optimal Reciprocal Collision Avoidance (ORCA) technique, which is used for reactive collision avoidance between the agents. ORCA is a decentralized reactive collision avoidance method based on the velocity-obstacle paradigm that performs optimization in the space of velocity vectors for each agent. During ORCA, each agent creates a velocity obstacle for every other agent based on their currently observed position and velocity. Each such a velocity obstacle cuts out a half-plane in the space of possible velocities for the agent. Given the agent\u2019s desired velocity and the constraints induced by the other agents, a linear program with n \u2212 1 constraints is constructed and solved to obtain the optimal velocity vector the agent should follow in the next time step [8].\nTo provide the desired velocity vector in each time step, we use the same visibility graph based navigation as in the visibility graph extension method. At each timestep, the agent finds the optimal path from its current position to its destination on the visibility graph and sets the desired velocity vector to point at this direction.\nThe ORCA extension function is defined as\nEORCA(x,y, O) = {\u03c0i}\nwhere \u03c0i is a trajectory of i-th agent obtained by simulating the ORCA method with x as start positions and y as goal positions.\nThe trajectories returned by ORCA are guaranteed to be obstacle avoiding. They are also guaranteed to be mutually collision-free. However, due to the reactive nature of the algorithm, the method is not guaranteed to find a solution if a solution exists. Since some of the executions may end up in infinite loops or deadlocks, it is not uncommon to see the agents being stuck at one point and never reach their designated target position. Therefore one has to bound the maximum number of timestep each ORCA simulation is allowed to perform.\nOur hypothesis is that there is a significant number of problem instances that cannot be solved by ORCA alone, but that could be efficiently solved by multi-agent RRT* with ORCA extensions.\nAn example of an artificial instance that was not solved by ORCA is in Figure 1. In such a scenario, the reactive technique tryies to resolve the conflict by letting both agents to go back in the corridor, but at some point it decides to return back to its desired directon, resulting in a deadlock situation."}, {"heading": "4. EXPERIMENTAL ANALYSIS", "text": "In this section we experimentally evaluate features of proposed extension of multi-agent RRT* algorithm. We compare three RRT* based algorithms - Line RRT*, Visibility Graph RRT* and ORCA RRT* with reactive ORCA. The experiments have been performed on four types of 2-d testing environments \u2013 empty, door, cross and maze environments (see Figure 2). All environments are constrained by a fixed boundary having 1000x1000 dimension. The metrics for comparison has been focused on success rate of the algorithms and the quality of the solution for various environment settings. The measured parameters are:\n\u2022 idealistic solution cost is the cost of a solution for which the CF function in Equation 1 is relaxed in a way that it omits its first constraint i.e. permits collisions between agents. The idealistic (i.e. lower bound) solution cost is defined as\ntideal = n\u2211\ni=1\ntdi .\nThe goal arrival time tdi is obtained by computing a single-agent optimal path for each agent using the visibility graph.\n\u2022 suboptimality measure gives indicative quality ratio by comparison of the given solution to the lower bound of the solution provided by idealistic solution cost. It shows how many times is the given solution worse than the idealistic solution. It is defined as\nsuboptimality =\nn\u2211 i=1 tdi tideal .\n\u2022 success rate shows the percentage of scenarios solved by the algorithms. The success rate depends on suboptimality in a way that a given solution is successful only if its suboptimality is lower than a defined threshold. If the algorithm does not provide any solution within time frame defined by experiment setting, it is automatically considered unsuccessful."}, {"heading": "4.1 Benchmark set", "text": "The experiment has been performed on a benchmark set composed of four environments as depicted in Figure 2 with the number of agents varying from 2 to 10 and the agent body radii ranging from 50 to 100. For each combination of environment, number of agents and agent radius, the benchmark set contains 10 different settings of agents\u2019 start and goal positions, altogether 2160 benchmark scenarios. Since RRT* is a stochastic algorithm, we run the algorithm five times with different random seeds for each problem instance. Altogether, the presented experimental results are based on 34560 runs.\nThe benchmark set was created by an algorithm that guarantees that for each problem instance there is exactly one collision cluster i.e. the path finding problem cannot be divided into mutually non-colliding groups of agents, which would be easier to solve. This is guaranteed by adding agent\u2019s random start and goal positions iteratively only when a collision occurs between agent\u2019s shortest path from start to goal and any other agent\u2019s shortest path. The procedure that creates a problem instance is given in Algorithm 2.\nAlgorithm 2 Create problem instance\n1: for i in 1:numberOfAgents do 2: colliding = false 3: while not colliding do 4: start = randomSample 5: goal = randomSample 6: path = findShortestPath(start, goal, obstacles) 7: if path exists then 8: colliding = findCollision(path, allPaths) 9: end if\n10: end while 11: allPaths.add(path) 12: starts.add(start) 13: goals.add(goal) 14: end for\nAn example of one such generated problem instance is depicted in Figure 3. It shows the maze environment with 10 agents of minimal radus r = 50 and maximal radius r = 100 and the corresponding optimal single-agent trajectories obtained by running the A* algorithm on a visibility graph.\nIn the next sections we will discuss the results of experimental evaluation from the perspective of the instance set coverage/success rate of the algorithms and the solution quality/suboptimality."}, {"heading": "4.2 Success rate", "text": "We compare the success rate of four implemented algorithms with respect to different numbers of agents and different radii of agents. The limit on runtime of the tested algorithms has been set to 5 seconds. To illustrate the distribution of solution quality, we plot these graphs for different suboptimality thresholds:\n\u2022 Figure 4 uses no suboptimality threshold and contains all instances.\n\u2022 In Figure 5 we consider all solutions having suboptimality over 5 as unsuccessful.\n\u2022 In Figure 6 we consider all solutions having suboptimality over 2.5 as unsuccessful.\nWe can observe three significant phenomena. Firstly, the success rate of RRT* based algorithms Line-RRT* and Visibility Graph-RRT* drops fast with increasing number of agents. This behavior was expected because the planning takes place in a state space exponential in the number of agents. These algorithms are therefore able to solve the defined problems for the number of agents up to approximately 5 in the studied scenarios. Note that RRT* is provably probabilistically complete [4], but for some instances given the limited runtime the algorithm was not able to find even the first feasible solution. On the other hand the success rate of both RRT* algorithms is stable with changing threshold.\nSecond, the success rate of the ORCA reactive technique drops with the increasing radii of the agents. This can be partly explained by the existence of corridors in the test scenarios that with the increasing radii of the agents become \u201dnarrow\u201d and therefore hard to solve locally. If the agents\nare small, then they can swap positions without leaving the corridor, which is easy to achieve using local collision avoidance. If the agents are large, then there will be corridors that can accommodate only one agent at a time, which requires longer term planning, where one agent keeps the way clear for the other agent to pass which is only achievable with planning approaches.\nFurther, we can observe that the solutions generated by ORCA are often of low quality (notice the difference between Figure 4(d) and 5(d)). This typically happens in crowded environments, where are the agents likely to get stuck in slowly evolving deadlock situations.\nThird, the success rate of the ORCA-RRT* algorithm is close to one for both high number of agents and high agent radius. It drops only with the combination of high extremes of both parameters. This behavior is achieved by the combination of planning and reactive approaches. The planning component is able to solve the instances that require planning, while the reactive component is able to solve instances with higher numbers of agents.\nMoreover, we can see that the success rate of ORCARRT* deteriorates much less rapidly with decreasing threshold than pure ORCA, which implies that ORCA-RRT* in general finds in the given runtime limit higher quality solutions than pure ORCA alone. Since the first extension in ORCA-RRT* is in fact identical to running pure ORCA, these results confirm that the algorithm exhibits incremental behavior, i.e. it improves the quality of the generated solution in time.\nAn important observation is that the there are instances that neither of the algorithms was able to solve on its own, but that got solved when the two algorithms were combined. For many other instances the combination of RRT* and ORCA provided a higher-quality result within the given runtime limit than each of the algorithms alone."}, {"heading": "4.3 Suboptimality", "text": "Figure 7 and 8 show the histograms of ranks assigned to algorithms for run-time limits 5 and 1 seconds. A rank from 1 to 4 is assigned to each algorithm for each experiment according to its solution suboptimality compared to other algorithms. If two algorithms achieve the same suboptimality, the ranks are assigned to them randomly. If an algorithm was not able to find any solution, its rank is 4. Rank 1 means that an algorithm achieved lowest suboptimality for particular problem instance. Difference between figures 7 and 8 shows how the ranks of the algorithms (e.g. solution quality \u2013 suboptimality) depend on the running time limit. We observe that VisibilityGraph-RRT* algorithm achieved the worst ranks. Line-RRT* is slightly better due to it\u2019s ability to sample the state space very fast. ORCA algorithm achieved the second rank and ORCA-RRT* always achieved the first rank in the majority of problem instances. The difference between Figure 7 and 8 shows that while ORCA finds the best solution early, it does not benefit from added runtime. The variants of RRT* incrementally improve the solution and thus their performance is more dependent on the given runtime limit.\nThe results of the experiments confirm the ability of ORCARRT* to find higher-quality solutions compared to both RRT* variants. As a complement to the best problem instance set coverage, the ORCA-RRT* is also dominant in terms of the quality of the returned solution."}, {"heading": "5. CONCLUSIONS", "text": "In this paper we studied the problem of finding coordinated paths for holonomic agents in 2-d polygonal environments. This problem is challenging due to its prohibitive complexity. We studied several RRT*-based algorithms for multi-agent coordinated path finding and a reactive approach ORCA. We found that while both approaches have limited coverage of the problem instance space, an approach combining planning and reactive technique benefits from both its parts, providing a better problem instance set coverage and higher solution quality.\nWe call the new algorithm ORCA-RRT*. While RRT*based algorithms often suffer from the exponential growth of the state space and thus are unable to solve instances with high number of agents, the reactive part of ORCA-RRT* is able to overcome this problem. On the other hand reactive techniques are often unable to solve problems containing local minima. Due to its RRT* planning part the ORCARRT* algorithm can avoid such local minima by random sampling of the state space.\nORCA-RRT* is an anytime algorithm, which can iteratively improve the provided solution. We experimented with several running time limits and examined the differences in the provided solutions. In the future work we plan to deploy the ORCA-RRT* on hardware agents and investigate possibility of the extension towards non-holonomic agents.\nAcknowledgements. The presented work was supported by the Czech Republic Ministry of Education, Youth and Sports, grants no. 7H11102 (D3CoS) and no. LD12044, and by the ARTEMIS Joint Undertaking under the number 269336 (www.d3cos.eu)."}, {"heading": "6. REFERENCES", "text": "[1] B. de Wilde, A. W. ter Mors, and C. Witteveen. Push\nand rotate: cooperative multi-agent path planning. AAMAS, 2013.\n[2] M. Erdmann and T. Lozano-Perez. On multiple moving objects. Algorithmica, 2:477\u2013521, 1987.\n[3] J. Hopcroft, J. Schwartz, and M. Sharir. On the complexity of motion planning for multiple independent objects; pspace-hardness of the warehouseman\u2019s problem. IJRR, 3(4):76\u201388, 1984.\n[4] Karaman and Frazzoli. Sampling-based algorithms for optimal motion planning. I. J. Robotic Res., 20(5):846\u2013894, 2011.\n[5] S. M. LaValle and J. J. Kuffner. Randomized kinodynamic planning. I. J. Robotic Res., 20(5):378\u2013400, 2001.\n[6] T. S. Standley. Finding optimal solutions to cooperative pathfinding problems. AAAI, 2010.\n[7] P. Surynek. A novel approach to path planning for multiple robots in bi-connected graphs. In Proceedings of ICRA 2009, pages 3613\u20133619, 2009.\n[8] J. Van Den Berg, S. J. Guy, M. Lin, and D. Manocha. Reciprocal n-body collision avoidance. In Robotics research, pages 3\u201319. Springer, 2011.\n[9] M. C\u030ca\u0301p, P. Nova\u0301k, J. Vokr\u030c\u0301\u0131nek, and M. Pe\u030cchouc\u030cek. Multi-agent RRT*: Sampling-based cooperative pathfinding (extended abstract). In Proceedings of the AAMAS\u201913, 2013."}], "references": [{"title": "Push and rotate: cooperative multi-agent path planning", "author": ["B. de Wilde", "A.W. ter Mors", "C. Witteveen"], "venue": null, "citeRegEx": "1", "shortCiteRegEx": "1", "year": 2013}, {"title": "On multiple moving objects", "author": ["M. Erdmann", "T. Lozano-Perez"], "venue": "Algorithmica, 2:477\u2013521", "citeRegEx": "2", "shortCiteRegEx": null, "year": 1987}, {"title": "On the complexity of motion planning for multiple independent objects; pspace-hardness of the warehouseman\u2019s problem", "author": ["J. Hopcroft", "J. Schwartz", "M. Sharir"], "venue": "IJRR, 3(4):76\u201388", "citeRegEx": "3", "shortCiteRegEx": null, "year": 1984}, {"title": "Sampling-based algorithms for optimal motion planning", "author": ["Karaman", "Frazzoli"], "venue": "I. J. Robotic Res.,", "citeRegEx": "4", "shortCiteRegEx": "4", "year": 2011}, {"title": "Randomized kinodynamic planning", "author": ["S.M. LaValle", "J.J. Kuffner"], "venue": "I. J. Robotic Res., 20(5):378\u2013400", "citeRegEx": "5", "shortCiteRegEx": null, "year": 2001}, {"title": "Finding optimal solutions to cooperative pathfinding problems", "author": ["T.S. Standley"], "venue": "AAAI", "citeRegEx": "6", "shortCiteRegEx": null, "year": 2010}, {"title": "A novel approach to path planning for multiple robots in bi-connected graphs", "author": ["P. Surynek"], "venue": "Proceedings of ICRA 2009, pages 3613\u20133619", "citeRegEx": "7", "shortCiteRegEx": null, "year": 2009}, {"title": "Reciprocal n-body collision avoidance", "author": ["J. Van Den Berg", "S.J. Guy", "M. Lin", "D. Manocha"], "venue": "In Robotics research,", "citeRegEx": "8", "shortCiteRegEx": "8", "year": 2011}, {"title": "J", "author": ["M. \u010c\u00e1p", "P. Nov\u00e1k"], "venue": "Vok\u0159\u0301\u0131nek, and M. P\u011bchou\u010dek. Multi-agent RRT*: Sampling-based cooperative pathfinding (extended abstract). In Proceedings of the AAMAS\u201913", "citeRegEx": "9", "shortCiteRegEx": null, "year": 2013}], "referenceMentions": [{"referenceID": 2, "context": "In theory it is well known that finding even non-optimal collision-free paths from defined start positions to goal positions for a group of objects in restricted 2-d space is PSPACE-hard [3] and thus (unless P=PSPACE) there exist instances that cannot be solved in polynomial time.", "startOffset": 187, "endOffset": 190}, {"referenceID": 6, "context": "For this variant of the problem there exist complete polynomial algorithms such as BIBOX [7] or Push & Rotate [1], nonpolynomial (but often effective) optimal algorithms [6] and anytime algorithms [9].", "startOffset": 89, "endOffset": 92}, {"referenceID": 0, "context": "For this variant of the problem there exist complete polynomial algorithms such as BIBOX [7] or Push & Rotate [1], nonpolynomial (but often effective) optimal algorithms [6] and anytime algorithms [9].", "startOffset": 110, "endOffset": 113}, {"referenceID": 5, "context": "For this variant of the problem there exist complete polynomial algorithms such as BIBOX [7] or Push & Rotate [1], nonpolynomial (but often effective) optimal algorithms [6] and anytime algorithms [9].", "startOffset": 170, "endOffset": 173}, {"referenceID": 8, "context": "For this variant of the problem there exist complete polynomial algorithms such as BIBOX [7] or Push & Rotate [1], nonpolynomial (but often effective) optimal algorithms [6] and anytime algorithms [9].", "startOffset": 197, "endOffset": 200}, {"referenceID": 1, "context": "Frequently used decoupled technique is prioritized planning [2].", "startOffset": 60, "endOffset": 63}, {"referenceID": 3, "context": "In 2011 Karaman and Frazzoli [4] published the RRT* ar X iv :1 40 2.", "startOffset": 29, "endOffset": 32}, {"referenceID": 4, "context": "algorithm, an anytime extension of RRT (rapidly exploring random tree [5]) that is probabilistically complete and asymptotically optimal.", "startOffset": 70, "endOffset": 73}, {"referenceID": 7, "context": "[8] and demonstrated to be capable of generating collision-free motion for a large number of agents in a cluttered workspace with local guarantees on optimality and safety.", "startOffset": 0, "endOffset": 3}, {"referenceID": 0, "context": "The algorithm searches for a path p : [0, 1]\u2192 J from xinit to xgoal, which can be then decomposed into a set trajectories {\u03c0i} for each individual agent i.", "startOffset": 38, "endOffset": 44}, {"referenceID": 3, "context": "1 Line Extension The first considered extension method is a relatively straightforward extension of classical single-agent RRT* planner as exposed in [4], which connects two states using straight line paths.", "startOffset": 150, "endOffset": 153}, {"referenceID": 7, "context": "Given the agent\u2019s desired velocity and the constraints induced by the other agents, a linear program with n \u2212 1 constraints is constructed and solved to obtain the optimal velocity vector the agent should follow in the next time step [8].", "startOffset": 234, "endOffset": 237}, {"referenceID": 3, "context": "Note that RRT* is provably probabilistically complete [4], but for some instances given the limited runtime the algorithm was not able to find even the first feasible solution.", "startOffset": 54, "endOffset": 57}], "year": 2014, "abstractText": "Avoiding collisions is one of the vital tasks for systems of autonomous mobile agents. We focus on the problem of finding continuous coordinated paths for multiple mobile disc agents in a 2-d environment with polygonal obstacles. The problem is PSPACE-hard, with the state space growing exponentially in the number of agents. Therefore, the state of the art methods include mainly reactive techniques and sampling-based iterative algorithms. We compare the performance of a widely-used reactive method ORCA with three variants of a popular planning algorithm RRT* applied to multi-agent path planning and find that an algorithm combining reactive collision avoidance and RRT* planning, which we call ORCA-RRT* can be used to solve instances that are out of the reach of either of the techniques. We experimentally show that: 1) the reactive part of the algorithm can efficiently solve many multi-agent path finding problems involving large number of agents, for which RRT* algorithm is often unable to find a solution in limited time and 2) the planning component of the algorithm is able to solve many instances containing local minima, where reactive techniques typically fail.", "creator": "LaTeX with hyperref package"}}}