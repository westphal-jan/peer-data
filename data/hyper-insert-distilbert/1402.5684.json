{"id": "1402.5684", "review": {"conference": "arxiv", "VERSION": "v1", "DATE_OF_SUBMISSION": "23-Feb-2014", "title": "Discriminative Functional Connectivity Measures for Brain Decoding", "abstract": "we propose assuming a statistical controlled learning model for algorithms classifying cognitive processes completely based based on distributed interference patterns expressive of overlapping neural resource activation in half the brain, acquired quickly via partial functional lobe magnetic stimulation resonance molecular imaging ( fmri ). in specifically the simulation proposed verbal learning method, local mapped meshes are formed exclusively around grouping each constituent voxel. the distance connectivity between voxels in the mesh is determined locally by decomposition using a stationary functional neighbourhood representation concept. in order to define the functional neighbourhood, the exact similarities between along the spatial time continuous series recorded values for certain voxels are measured first and functional spatial connectivity matrices exactly are constructed. then, the local mesh for each voxel is formed vertically by including along the 2d functionally closest neighbouring voxels in the mesh. the relationship between the voxels within as a virtual mesh mesh is estimated then by mathematicians using developed a conditional linear model regression representation model. these relationship vectors, called functional proximity connectivity aware local relational representation features ( fc - matrix lrf ) are manually then used periodically to train called a statistical learning correlation machine. for the proposed rehabilitation method was tested on a retrieval recognition threshold memory experiment, including data pertaining to emotion encoding and retrieval of words belonging altogether to approximately ten different semantic categories. equally two popular temporal classifiers, described namely alpha k - pixel nearest neighbour ( k - nn ) and matrix support vector machine ( svm ), are trained in order to predict the original semantic category of the processed item being locally retrieved, based more on similar activation patterns during speech encoding. the classification performance of comparing the functional mesh learning model, estimates which range in 62 % - by 71 % is widely superior to the classic classical multi - voxel pattern identification analysis ( mvpa ) methods, at which still range best in ways 40 % - often 48 %, for ten semantic categories.", "histories": [["v1", "Sun, 23 Feb 2014 22:01:11 GMT  (1714kb,D)", "https://arxiv.org/abs/1402.5684v1", "12 pages, 6 figures"], ["v2", "Thu, 6 Mar 2014 19:02:07 GMT  (1714kb,D)", "http://arxiv.org/abs/1402.5684v2", "This paper has been withdrawn"]], "COMMENTS": "12 pages, 6 figures", "reviews": [], "SUBJECTS": "cs.AI cs.CE cs.CV cs.LG", "authors": ["orhan firat", "mete ozay", "ilke oztekin", "fatos t yarman vural"], "accepted": false, "id": "1402.5684"}, "pdf": {"name": "1402.5684.pdf", "metadata": {"source": "CRF", "title": "Discriminative Functional Connectivity Measures for Brain Decoding", "authors": ["Orhan Firat", "Mete Ozay", "Ilke Oztekin", "Fatos T. Yarman Vural"], "emails": ["orhan.firat@ceng.metu.edu.tr", "vural@ceng.metu.edu.tr", "m.ozay@cs.bham.ac.uk", "ioztekin@ku.edu.tr"], "sections": [{"heading": null, "text": "I. INTRODUCTION\nSeveral methods have been developed to understand how brain processes information. One, in particular, aims to predict or decode the brain state, and/or the type of information associated with cognitive processes, based on distributed patterns of activation in the brain, acquired with functional magnetic resonance imaging (fMRI) using various machine learning methods [1]\u2013[9]. One of the major motivations of this study is to propose a model for pattern analysis of fMRI data pertaining to different cognitive states using statistical learning theory. This representation involves understanding, manipulating and predicting the behavior of the very complex nature of human brain. Massively coupled dynamic interactions of the brain at many scales cannot be fully understood by only employing the measurements recorded from the individual voxels. Therefore, there has been growing interest in using brain connectivity to reveal interactions between spatially distant regions. Brain connectivity describes neural processes as the outcomes of dynamic coordination among smaller elements [10]. Three main types of brain connectivity are reported in\nthe literature: i) structural connectivity which basically reveals anatomic connections (pathways) of brain, such as physical links between neural elements, ii) functional connectivity is defined as statistical dependence between distributed neural elements or regions across time, e.g. correlation and iii) effective connectivity which analyzes brain connectivity using causal effects between neural elements, resulting in causal activation paths [11], [12].\nConnectivity for decoding is mostly used for model selection and/or defining the neighbourhood of seed neural elements or regions [13]. For instance, in a study by McIntosh et al., partial least squares for activation analysis is performed to construct a cross block covariance matrix using PET data [14]. Correlation based measures such as correlation/partial correlation, Granger causality, independent component analysis (ICA), mutual-information or coherence are used for the selection of different functional interdependence functions [15]\u2013[17]. Ryali et al. measure sparse-partial correlation between multiple regions using elastic net penalty, which combines `1 and `2 norm regularization terms in order to improve the sensitivity of the correlation measure [18]. Patel et al. propose a conditional dependence model which accounts for an imbalance between class conditional and posterior probabilities, to achieve at a measure of connectivity [19]. Unlike correlation measures, Shier et al. train a classifier to decode cognitive states after constructing functional connectivity matrices, analysing increasing connectivity regions by subtracting connectivity matrices for each state [7]. Richardi et al. construct functional connectivity matrices by using pairwise Pearson correlation coefficients and employ graph matching to decode brain states [6].\nIn this study, we introduce an algorithm for modeling cognitive processes, based on the functional and structural connectivity in the brain. Structural connectivity is utilized for anatomic parcellation of the brain regions by clustering the voxel intensity values measured by fMRI. Next, functional connectivity is utilized within the clusters by different correlation measures. Functional connectivity matrices are formed to define functional neighbourhood of a voxel. A local mesh is formed for each voxel (called the seed voxel) by including the functionally closest neighbours (called the surrounding voxels) in the mesh. The relationships between the seed\nar X\niv :1\n40 2.\n56 84\nv2 [\ncs .A\nI] 6\nM ar\n2 01\n4\nvoxel and the surrounding voxels are modeled by estimating the arc weights of the mesh in a linear regression model. The arc weights, called Functional Connectivity-aware Local Relational Features (FC-LRF) represent the relationship of each voxel to its functionally closest neighbours. Finally, the proposed FC-LRF features are used to train a classifier which recognizes type of information and/or cognitive state.\nIn the current study, we particularly focused on classification of the type of information being encoded and retrieved during memory operations. During the experiment, participants studied a list of words selected from one of ten pre-defined semantic categories and made recognition memory judgements while neural activation was recorded using fMRI [20], [21]. Accordingly, we tested whether the proposed machine learning algorithm can successfully identify and differentiate the type of information (i.e. the semantic category to which the word belongs) which is represented in the brain at a given time considering distributed patterns of brain activity associated with, and during memory encoding and retrieval."}, {"heading": "II. MESH LEARNING AND LOCAL RELATIONAL FEATURES", "text": "(LRF)\nIn this study, blood-oxygenation-level dependent (BOLD) signals \u03c5(ti, s\u0304j), are measured at time instants ti, i = 1, 2, 3, . . . , N , at voxel coordinates s\u0304j , j = 1, 2, 3, \u00b7 \u00b7 \u00b7 ,M , where N is the number of time samples, and M is the number of voxels. The data set D = {\u03c5(ti, s\u0304j) : i = 1, 2, 3, . . . , N, j = 1, 2, 3, \u00b7 \u00b7 \u00b7 ,M} consists of the voxels \u03c5(ti, s\u0304j), which are distributed in brain in three dimensions. Therefore, the position s\u0304j = (xj , yj , zj) of a voxel \u03c5(ti, s\u0304j) at a time instant ti is a three dimensional vector. At each time instant ti, the participant is processing (either encoding or retrieving) a word belonging to a cognitive process. Therefore, the samples \u03c5(ti, s\u0304j) has an object label at each time instance. In Mesh Learning [22], the cognitive states are modelled by local meshes for each individual voxel, called seed voxel \u03c5(ti, s\u0304j), which is defined in a neighbourhood system \u03b7p (see;Figure 1). In this mesh, a voxel \u03c5(ti, s\u0304j) is connected\nto p-nearest neighbouring voxels {\u03c5(ti, s\u0304k)}pk=1 by the arcs with weights {ai,j,k}pk=1. Therefore, the relationship among the BOLD signals measured at each voxel, are represented by the arc weights. p-nearest neighbours, \u03b7p, are defined as the spatially-nearest neighbours to the seed voxel, where the distances between the voxels are computed using Euclidean distances between the spatial coordinates s\u0304j of the voxels in brain. The arc weights ai,j,k of the mesh are estimated by the following linear regression equation:\n\u03c5(ti, s\u0304j) = \u2211 s\u0304k\u2208\u03b7p ai,j,k \u03c5(ti, s\u0304k) + \u03b5i,j , (1)\nwhere \u03b5i,j indicates the error of voxel \u03c5(ti, s\u0304j) at time instant ti, which is minimized for estimating the arc weights ai,j,k. This procedure is conducted by minimizing the expected square error defined as follows,\nE(\u03b52i,j) = E (( \u03c5(ti, s\u0304j)\u2212 \u2211 s\u0304k\u2208\u03b7p ai,j,k \u03c5(ti, s\u0304k) )2) , (2)\nwhere \u03b7p(s\u0304j) is the set of p-nearest neighbours of the jth voxel at location s\u0304j .\nMinimizing Equation 2 with respect to ai,j,k is accomplished by employing Levinson-Durbin recursion [23], where E(\u00b7) is the expectation operator. The arc weights ai,j,k, which are computed for each seed voxel at each time instant ti, are used to form a mesh arc vector a\u0304i,j = [ai,j,1 ai,j,2 \u00b7 \u00b7 \u00b7 ai,j,p]. Furthermore, a mesh arc matrix Aj is constructed by concatenating the mesh arc vectors at each time instant, Aj = [a\u03041,j a\u03042,j \u00b7 \u00b7 \u00b7 a\u0304N,j ]T . Finally, feature matrix F = [A1 A2 \u00b7 \u00b7 \u00b7 AM ] which represents the Local Relational Features (LRF), is constructed in Equation 3. The feature matrix, which is extracted during both memory encoding and retrieval stages, is further used in training and testing phases in the classification of cognitive processes, respectively. For the details of the mesh learning algorithm see [22], [24], [25].\nArc weights for \u03c5(ti,s\u03041)\ufe37 \ufe38\ufe38 \ufe37 F = a1,1,1 \u00b7 \u00b7 \u00b7 a1,1,p \u00b7 \u00b7 \u00b7 a1,M,p... . . . ... . . . ... aN,1,1 \u00b7 \u00b7 \u00b7 aN,1,p \u00b7 \u00b7 \u00b7 aN,M,p  (3) The motivation of representing voxels in the brain by local meshes can be validated by analyzing an individual voxel\u2019s intensity change and the change of the sum of squared difference of intensities ds\u0304j ,\u03b7p(s\u0304j) = \u2211 s\u0304k\u2208\u03b7p(s\u0304j)[\u03c5(ti, s\u0304j) \u2212 \u03c5(ti, s\u0304k)] 2 in the neighbourhood of that voxel, in time. Individual voxel intensity values, which are measured at each time instant, do not possess any discriminative information as illustrated in Figure 2 with red line. Note that the signal intensity value for a voxel is almost constant at each time instant. Since the measurements along the time axis correspond to separate cognitive processes, in most of the problems, it is\nunlikely to discriminate them by using multi-voxel pattern analysis (MVPA) methods which classify the voxel intensity values by a machine learning algorithm. On the other hand, there is a slight variation of the sum of squared distances of intensity values in differing neighbour sizes. The above observation shows that the relationships among voxels carry more information than individual voxel intensity values, at each time instant."}, {"heading": "III. FUNCTIONAL CONNECTIVITY IN THE BRAIN", "text": "The estimated LRF vectors, which represent relationships among the voxels in the same neighbourhood system, have a high discriminative power compared to the individual voxel intensity values. As a result, the Mesh Learning algorithm proposed by [22] performs better than the well-known individual voxel based algorithms (see also; Table III). However, employing the Euclidean distance to form the neighbourhood system may not fully represent the activation patterns in the brain, where the spatially distant neurons might exhibit functional connectivity. \u201cNearest\u201d neighbourhood in the mesh model implies spatial surroundings of the seed voxel when Euclidean distance is used, which may not be the case during cognitive processing. Additionally, it is well known that spatially close voxels are strongly coupled during cognitive processes [26]. Therefore, using Euclidean distance for defining neighbourhoods for voxels may cause redundant meshes and mesh arc weights in a feature matrix. A partial improvement for this\nproblem can be accomplished by the usage of a functional connectivity method. Selecting functional neighbours for each voxel and constructing the meshes based on the functional neighbourhood result in a more discriminative feature matrix improving the classification performance."}, {"heading": "A. Functional Connectivity", "text": "Given the time series of voxels \u03c5(t, s\u0304i) and \u03c5(t, s\u0304j), where t = (t1, t2, \u00b7 \u00b7 \u00b7 , tN ) is the time vector whose variables are consecutive time instants, a functional connectivity is defined as the measure of \u201csimilarity\u201d between time series of these voxels. The voxels are considered to be functionally connected if they have \u201csimilar\u201d functional properties. Therefore, the functional connectivity depends on the similarity measure. The \u201csimilarity\u201d can be measured, for example, by estimating the correlation or covariance between pairs of time series. Functional connectivity is expected to capture patterns of deviations between distributed and often spatially distant regions in brain [27], and constructed using an inter-regional analysis."}, {"heading": "B. Functional Connectivity Graph", "text": "In order to represent the functional connectivity in brain, we define a graph G = (V,E), where V = {\u03d1j}Mj=1 is the set of nodes (vertices) and E = {ejk}Mj,k=1 is the set of edges. In this representation, a node \u03d1j corresponds to a time series, \u03c5(t, s\u0304j), which is measured at an individual voxel, and an edge between \u03d1j and \u03d1k is represented as ejk = \u03c1jk, where \u03c1jk\nis the functional connectivity coefficient which is computed using a functional similarity measure between time series of voxel signals \u03c5(t, s\u0304j), j = 1, 2, 3, . . . ,M using Equation 4.\nIn this study, edges in the functional connectivity graph are represented by symmetric dependence measures, in the time domain. It has been suggested that correlation based measures are well suited for functional connectivity analysis [28]. Consequently, we use zero-order correlation (crosscorrelation) to measure the functional similarity between timeseries. The zero-order correlation coefficient \u03c1jk between two nodes, voxels \u03d1j and \u03d1k in our case, is defined as\n\u03c1jk = covjk\n( \u03c5(t, s\u0304j), \u03c5(t, s\u0304k) )\u221a varj ( \u03c5(t, s\u0304j) ) \u00b7 vark ( \u03c5(t, s\u0304k)\n) , (4) where covjk is the covariance of the signals measured at two voxels, and varj is the variance of the signals measured at a voxel \u03c5(t, s\u0304j) and \u03c1jk \u2208 [\u22121, 1]."}, {"heading": "C. Local Patches", "text": "Constructing a functional connectivity graph by considering all voxels as individual nodes introduces scalability problems. In order to reduce the computational complexity, the voxels are first clustered with respect to their locations, where each cluster is called a local patch. Then, the functional connectivity\ngraph is formed for the voxels in each local patch with size \u03c0, approximately. This approach reduces the computational complexity from O(M2) to O(C\u03c02) where M is the number of voxels, and C is the number of local patches. Note that \u03c0 M , in the experiments.\nThe local patches are constructed by clustering the whole dataset D = {\u03c5(ti, s\u0304j)}, i = 1, 2, 3, . . . , N , j = 1, 2, 3, . . . ,M , using Euclidean distance among spatial locations of voxels s\u0304j = (xj , yj , zj) in a self-tuning spectral clustering algorithm [29]. After partitioning the whole dataset D into C clusters, functional connectivity is measured locally within these clusters. A cognitive process is then represented in a local patch (cluster) m using a within cluster functional connectivity matrix FCm, each of which forms the set of functional connectivity matrices FC = {FCm}Cm=1 which is employed in the model selection for the Mesh Learning algorithm. Details of the within cluster functional connectivity matrix computation process are given in Algorithm 1 and Figure 4 represents the local connectivity patterns for two clusters."}, {"heading": "IV. FUNCTIONALLY CONNECTED MESH", "text": "We define a local mesh around each voxel which consists of the set of functionally connected voxels. These meshes are\nAlgorithm 1 Computation of Within-Cluster Functional Connectivity Matrices Input : Dataset : D = {\u03c5(ti, s\u0304j)}, i = 1, 2, \u00b7 \u00b7 \u00b7 , N, j = 1, 2, \u00b7 \u00b7 \u00b7 ,M Number of Clusters: C Output : The Set of Functional Connectivity Matrices FC\n1: FC\u2190 \u00d8 2: [c1, c2, . . . , cC ]\u2190 clusterVoxelsByLocation([s\u03041, s\u03042, ..., s\u0304M ]) 3: for m = 1 to C do 4: for each pair (j, k) \u2208 cm do 5: FCm(j, k)\u2190 \u03c1jk // using Equation 4 6: end for 7: FC\u2190 FC \u222a FCm 8: end for 9: return FC\nthen used to extract LRF features from the meshes which consist of functionally similar voxels. The suggested model is called Functional Mesh Learning and the extracted LRF features are called Functional Connectivity aware LRF (FCLRF)(see; algorithm flow in Figure 3)."}, {"heading": "A. Functional Connectivity Aware Local Relational Features (FC-LRF)", "text": "Each element of a functional connectivity matrix FCm represents a pair-wise correlation of two voxels in a local patch. Since the correlation between any two nodes lies in the interval [\u22121, 1], BOLD time-series of two nodes can either be positively correlated or negatively correlated.\nMathematically speaking, the functionally nearest neighbour of \u03c5(ti, s\u0304j) is defined as,\n\u03b7fc1 [ \u03c5(ti, s\u0304j) ] = { \u03c5(ti, s\u0304k) : max(\u03c1jk),\n\u2200\u03c5(ti, s\u0304j) \u2208 FCm(j\u2032, \u00b7) } , (5)\nThen, the p-functional neighbourhood of a voxel \u03c5(ti, s\u0304j) is generated from the (p \u2212 1)-functional neighbourhood by\niteratively selecting the functionally nearest neighbour of that voxel from \u03b7fcp\u22121 [ \u03c5(ti, s\u0304j) ]c , where superscript c indicates the complement set of \u03b7fcp\u22121. p-functionally nearest neighbours of a voxel \u03c5(ti, s\u0304j) are obtained by adding the voxels in \u03b7fcp\u22121 [ \u03c5(ti, s\u0304j) ] to the functionally nearest neighbour of \u03b7fcp , as follows;\n\u03b7fcp [ \u03c5(ti, s\u0304j) ] = { \u03c5(ti, s\u0304k) \u222a \u03b7fcp\u22121 [ \u03c5(ti, s\u0304j) ] : max(\u03c1jk),\n\u03c5(ti, s\u0304j) \u2208 \u03b7fcp\u22121 [ \u03c5(ti, s\u0304j) ]c } , (6)\nFor a voxel \u03d1j at a location s\u0304j , a set of p-functionally nearest neighbours \u03b7fcp consists of the most strongly correlated p voxels in jth row of the functional connectivity matrix FCm(j\n\u2032, \u00b7), which is computed in Algorithm 1, where m is the index of the cluster in which the voxel \u03c5(ti, s\u0304j) resides, and j\u2032 is the translated index of the voxel in FCm.\nEquation 6 employs only positively correlated samples whose \u03c1jk values are close to +1. Another definition for the functional neighbourhood can be given by using the negatively correlated samples whose \u03c1jk values are close to \u22121. In this case, max(\u00b7) operation of Equation 6 is replaced by min(\u00b7)\nAlgorithm 2 Extract Functional Connectivity-Aware Local Relational Features (FC-LRF) Input : Dataset : D = {\u03c5(ti, s\u0304j)}, i = 1, 2, \u00b7 \u00b7 \u00b7 , N, j = 1, 2, \u00b7 \u00b7 \u00b7 ,M\nOrder of FC-LRF: p Functional Connectivity Matrices: FC\nOutput : Feature matrix F\n1: for j = 1 to M do 2: Compute p\u2212 functional \u2212 neighbourhood \u03b7fcp [ \u03c5(\u00b7, s\u0304j) ] of \u03c5(\u00b7, s\u0304j) by analysing FC 3: for i = 1 to N do 4: Compute a\u0304i,j by minimizing Equation (2) if \u03b7fcp [ \u03c5(\u00b7, s\u0304j) ] 6= \u00d8 5: end for 6: Construct Aj using a\u0304i,j 7: end for 8: Construct F using Aj 9: return F\noperation. In Figure 4, functionally nearest neighbour selection is illustrated by using most positively correlated (obtained by max(\u00b7) operation) and most negatively correlated voxels (obtained by min(\u00b7) operation). Note that, the order of FCLRF cannot exceed the minimum number of voxels in all clusters, p 6 \u03c0m \u2200m \u2208 {1, 2, 3, . . . , C}. Details of the FCLRF extraction are given in Algorithm 2."}, {"heading": "B. Adaptive Selection of Number of neighbours (FC-LRF order)", "text": "The major distinction between the Mesh Learning and Functionally Connected Mesh Learning algorithms is the definition of p-neighbourhood during the formation of the mesh for each seed voxel. In the Mesh Learning algorithm suggested in [22] p-neighbourhood is defined by Euclidean distance, whereas in Functionally Connected Mesh Learning p-neighbourhood is defined by functional similarity. In both methods, the identification of the order of p is a difficult problem. The major problem of functional similarity matrix is that each class have a distinct functional connectivity matrix. Therefore, p can be adaptively selected by analyzing this distinction in functional connectivity matrices.\nIn order to recognize the functional relationships between the voxels in brain during cognitive processes, we need to compute different within-class functional connectivity matrices for each brain state using Algorithm 3. Since our problem is to discriminate and recognize multiple semantic classes during retrieval, a different functional connectivity matrix is constructed in encoding state for each semantic class. These matrices are then analyzed to compute the most discriminative pairwise voxel relations among all classes.\nIn order to represent the most discriminative pairwise voxel relations, we construct a matrix which represents the unique relations that are representative for all the classes. In the experiments, \u2126 number of different within-cluster functional connectivity matrices FC\u03c9m are constructed for each semantic class and cluster m, where \u03c9 = 1, . . . ,\u2126, as illustrated in Figure 5a. In addition, for each cluster m, standard deviation and entropy values are computed for each element of \u2126\nnumber of functional connectivity matrices FC\u03c9m to form discriminative functional relation matrices Stdm and Entm, as illustrated in Figure 5b. During the modelling of the retrieval state with Functionally Connected Mesh Learning, FC-LRF is extracted using Std = {Stdm}Cm=1 and Ent = {Entm}Cm=1, employing Algorithm 3.\nIn Algorithm 3, we compute the standard deviation Stdm(j, k) as follows:\nStdm(j, k) =\n( 1\n\u2126\u2212 1 \u2126\u2211 \u03c9=1 ( FC\u03c9m(j, k)\u2212\u00b5 ( FC\u03c9m(j, k) ))2) 12 ,\n(7) where \u00b5(FC\u03c9m(j, k)) = 1 \u2126 \u2211\u2126 \u03c9=1(FC \u03c9 m(j, k)) is the mean of correlation coefficients for cognitive states \u03c9 = 1, \u00b7 \u00b7 \u00b7 ,\u2126, and the entropy Entm(j, k) as follows:\nEntm(j, k) = \u2212 \u2126\u2211 \u03c9=1 P ( FC\u03c9m(j, k) ) log P ( FC\u03c9m(j, k) ) , (8)\nwhere P ( FC\u03c9m(j, k) ) is the probability of the observation of correlation coefficients which are measured between two voxels \u03d1j and \u03d1k for a cognitive process \u03c9.\nThe advantage of using discriminative matrices is the reduction of the FC-LRF order p selection problem to a threshold selection problem for discriminative matrices. For instance, consider the within-cluster functional connectivity matrices illustrated in Figure 5. Standard deviation of within-cluster functional connectivity matrix Stdm, whose elements take values in the interval [0, 1] ( Figure 5b), standard deviation is computed using the standard deviation of \u2126 number of correlation matrices, whose elements take values in the interval [\u22121, 1] (Figure 5a).\nNote that, if Stdm(j, k) \u2248 1, then the deviation of the correlation coefficients \u03c1jk, which are computed using the signal values at the voxels \u03d1j and \u03d1k, highly varies in time. Therefore, we may state that the voxels respond to different cognitive processes which are determined by the\nAlgorithm 3 Compute Discriminative Within-Cluster Functional Connectivity Matrices Input : Number of Clusters : C Number of Semantic Categories: \u2126 Output : Discriminative Functional Connectivity Matrices Std and Ent\n1: Std\u2190 \u00d8 2: Ent\u2190 \u00d8 3: for semantic category \u03c9 = 1 to \u2126 do 4: Compute FC\u03c9 using Algorithm (1) 5: end for 6: for m = 1 to C do 7: for each pair (j, k) \u2208 cm do 8: \u03b1\u2190 \u00d8 // temporary vector for correlation coefficients 9: for semantic category \u03c9 = 1 to \u2126 do\n10: \u03b1\u2190 \u03b1 \u222a FC\u03c9m(j, k) 11: end for 12: Stdm(j, k)\u2190 std(\u03b1) // using equation (7) 13: Entm(j, k)\u2190 entropy(\u03b1) // using equation (8) 14: end for 15: Std\u2190 Std \u222a Stdm 16: Ent\u2190 Ent \u222a Entm 17: end for 18: return Std and Ent\nAlgorithm 4 Compute Between-Category Discriminative neighbourhood and FC-LRF Order Input : Discriminative Functional Connectivity Matrices : Std (or Ent)\nVoxel in consideration : \u03c5(\u00b7, s\u0304j) Threshold : \u03c4\nOutput : p\u2212functional neighbourhood set \u03b7fcp [ \u03c5(\u00b7, s\u0304j) ] and FC-LRF order p\n1: \u03b7fcp [ \u03c5(\u00b7, s\u0304j) ] \u2190 \u00d8 2: p\u2190 0 3: Stdm (or Entm) \u2190 Select discriminative matrix that voxel \u03c5(\u00b7, s\u0304j) belongs in Std (or Ent)\n// Scan through all the relations in cluster m // j\u2032 and k\u2032 are translated indices of j and k in cluster m\n4: for k\u2032 = 1 to \u03c0m do 5: if Stdm(j\u2032, k\u2032) \u2265 \u03c4 then 6: \u03b7fcp [ \u03c5(\u00b7, s\u0304j) ] \u2190 \u03b7fcp [ \u03c5(\u00b7, s\u0304j) ] \u222a k 7: p\u2190 p+ 1 8: end if 9: end for\n10: return \u03b7fcp [ \u03c5(\u00b7, s\u0304j) ] and p\nclasses with different signal values. Therefore, this voxel pair provides discriminative information for the classification of the cognitive processes, and the signal measurements observed in this voxel pair is considered for the extraction of FC-LRF. On the other hand, if Stdm(j, k) \u2248 0, then we observe that the measurements at the voxels are similar for different cognitive processes. Therefore, they do not provide discriminative information and will not be considered in the neighbourhood of each other, for the extraction of FC-LRF features, even they are fully correlated.\nThe other measure which defines the amount of the discrimination of different classes is entropy. Similar to the standard deviation, entropy captures the divergence of the correlation coefficients between semantic classes. A voxel pair can exhibit full correlation (\u03c1ij = 1) for a given semantic class but this pairwise relation does not carry any information for the classifier if the same correlation coefficient is observed for the rest of semantic classes. Therefore, the divergence of correlation coefficients is informative for the classifier, and such a divergence results a non-negative value by the employment of entropy. This trivial affect is also illustrated in Figure 6a. The more divergence in the correlation coefficients for a voxel pairs\u2019 functional relation, higher the entropy measure indicating the amount of information.\nWe consider a pair of voxels \u03d1j and \u03d1k, with Stdm(j, k) \u2265 \u03c4 and Entm(j, k) \u2265 \u03c4 , for a given threshold value \u03c4 , for the extraction of features. In other words, given a threshold, a set of p-functionally nearest neighbours \u03b7fcp for a voxel \u03c5(ti, s\u0304j) is constructed using Algorithm 4. Note that, FC-LRF order p increases for each voxel as the threshold \u03c4 goes to 0, and FCLRF order p decreases as the threshold \u03c4 gets closer to 1. If the threshold \u03c4 = 0, then all the neighbouring voxels will be included in the p-functionally nearest neighbours set \u03b7fc and FC-LRF order p will be equal to \u03c0m. On the contrary, if \u03c4 = 1, then only a very small number of neighbouring voxels will be\nincluded in the p-functionally nearest neighbours set \u03b7fc and FC-LRF order p = 0 for most of the voxels. Notice that voxels having p = 0 and \u03b7fc = {} will be automatically discarded in Algorithm 2 because of not having any discriminative information."}, {"heading": "V. EXPERIMENTS FOR THE FMRI DATA COLLECTION", "text": "In the experiment, a participant is shown lists of words selected from a pre-defined semantic category, while being scanned using fMRI, see [20], [21]. After the presentation of each study list, the participant solves math problems and following this delay period, decides whether a probe word matches one of the members of the study list (\u201cold\u201d or \u201cnew\u201d). Employing a delay period (about 14 sec during which the participant solved math problems) allows independent assessment of encoding related (i.e. study list period) brain activation from retrieval related (i.e. during the test probe) activity patterns. With this approach, one can test whether it is possible to identify and differentiate semantic categories of information that is represented in the brain at a given time based on distributed patterns of brain activity associated with and during cognitive processing. A total of ten semantic categories were used in the study, which are animals, colors, furniture, body parts, fruits, herbs, clothes, chemical elements, vegetables and tools. We used the neural activation patterns collected during encoding and retrieval phases, to train and test the classifier to predict the semantic categories.\nThe neuroimaging data underwent standard preprocessing stages before the pattern analysis step. Image processing and data analysis were performed using SPM5 (http://www.fil.ion.ucl.ac.uk/spm/). Following quality assurance procedures to assess outliers or artifacts in volume and slice-to-slice variance in the global signal, functional images were corrected for differences in slice acquisition timing by re-sampling all slices in time to match the first slice, followed\nby motion correction across all runs (using sinc interpolation). Functional data were then normalized based on MNI stereotaxic space using a 12-parameter affine transformation along with a non-linear transformation using cosine basis functions. Images were re-sampled into 2-mm cubic voxels and then spatially smoothed with an 8-mm FWHM isotropic Gaussian kernel. Next, the functional data were detrended to account for baseline shifts across runs and for scanner drift across the entire session for the pattern analysis. Consistent with previous research of Polyn et al., onsets were shifted forward by three points to account for the hemodynamic response lag [30].\nVI. IMPLEMENTATION OF THE FUNCTIONAL MESH LEARNING ALGORITHM\nOur dataset consists of 240 training samples from encoding phase and 239 test samples from the retrieval phase with 24 samples in each of 10 semantic categories. Our region of interest consists of 8142 voxels covering the lateral temporal cortex. Results for FC-LRF are generated using k-nearest neighbour (k-nn) and Support Vector Machine (SVM) methods. The k value of k-nn and kernel parameters of SVM classifier are selected using cross validation in the training set.\nThe number of clusters C in the proposed algorithm is a user specified parameter. Since the number of voxels in all clusters \u03c0m is always much higher than FC-LRF order p, regardless of the cluster size, similar functionally connected meshes are formed. Therefore, it has practically no effect on the performance of the algorithm. This fact is illustrated in the performance results in Table IV. Graph theoretic approaches can be employed after computing functional connectivity\nmatrices in order to partition connectivity matrices such as [31], [32], but this will introduce additional thresholds and user specified parameters, thus spared as a future work. Three different correlation variants are employed to capture functional similarity between nodes; i) cross-correlation which is given in equation 4, ii) peak correlation which captures the relationships between activation peaks and iii) scan correlation which measures the correlations of waveforms at a specific scan of interest. The overall performance of the algorithm is improved only by 2% \u2212 4% percent by employing improved correlation measures as peak correlation and scan correlation.\nIn addition, we employed four different functionally-nearest neighbour selection approaches namely, selecting positively or negatively correlated neighbours by specifying FC-LRF order p and using discriminative functional connectivity matrices Std or Ent by specifying a threshold \u03c4 . The performance results are illustrated in Table I and Table II employing k-nn method and SVM method in classification of cognitive processes, respectively. Functional Connectivity Toolbox implementation [33] is used for the computation of the correlation measures.\nThe discriminative matrices Stdm and Entm are computed using within-cluster functional connectivity matrices with a fixed number of clusters C = 256. In the computations, we employed three different correlation measures (peak, scan and zero-order correlation), and two different discriminative matrix generation methods (standard deviation and entropy). Threshold values are empirically selected in the interval between [0.5, 0.95] with a 0.05 step-size.\nThe results in Table III show that the employment of functional connectivity in the mesh learning algorithm [22] improves classification performances, considerably. When we\nclassify the raw features of 8142 voxels (without LRF), we observe 48% and 40% performances. Note that Mesh Learning increases the performances to 58% and 45% and Functional Mesh Learning further increases the performances to 71% and 70% using k-NN and SVM methods, respectively. The main issue which increases the performance is basically the selection of nearest neighbours by using functional connectivity of the voxels in brain."}, {"heading": "VII. CONCLUSION", "text": "In this study, we propose a new machine learning method, called Functional Mesh Learning in order to classify cognitive process, based on distributed patterns of neural activation patterns in brain. In the current data set, the model has been tested during memory process and performed successfully. The proposed method employs functional connectivity in order to define local meshes to represent the relationships between the voxels and their p-functionally nearest neighbours.\nOur goal is to be able to model cognitive processes based on neural activation patterns in brain. Our results indicate that the suggested Functional Mesh Learning model can be used to classify cognitive states and types of information represented during these cognitive operations based on distributed patterns of brain activity. In the current study, we only focused on modelling memory encoding and retrieval processes. Future research extending these findings to a wider range of cognitive operations would bring additional insight into the generality of the success of the proposed algorithm for modeling brain during cognitive processing, and improving Functional Mesh Learning algorithm by eliminating drawbacks such as the linearity of the mesh model, selecting the optimal FC-LRF order value p, threshold values \u03c4 and incorporating the brain hierarchy, brain pathways to the learning method."}], "references": [{"title": "Training fMRI Classifiers to Detect Cognitive States across Multiple Human Subjects", "author": ["X. Wang", "R. Hutchinson", "T.M. Mitchell"], "venue": "IN NIPS03, vol. 16, 2003.", "citeRegEx": "1", "shortCiteRegEx": null, "year": 2003}, {"title": "Beyond mind-reading: multi-voxel pattern analysis of fMRI data.", "author": ["K.A. Norman", "S.M. Polyn", "G.J. Detre", "J.V. Haxby"], "venue": "Trends in cognitive sciences,", "citeRegEx": "2", "shortCiteRegEx": "2", "year": 2006}, {"title": "Decoding mental states from brain activity in humans.", "author": ["J.-D. Haynes", "G. Rees"], "venue": "Nature reviews. Neuroscience,", "citeRegEx": "3", "shortCiteRegEx": "3", "year": 2006}, {"title": "Temporal and cross-subject probabilistic models for fmri prediction tasks", "author": ["A. Battle", "G. Chechik", "D. Koller"], "venue": "NIPS\u201906, 2006, pp. 121\u2013128.", "citeRegEx": "4", "shortCiteRegEx": null, "year": 2006}, {"title": "Classification of mental task from EEG data using neural networks based on particle swarm optimization", "author": ["C.-J. Lin", "M.-H. Hsieh"], "venue": "Neurocomputing, vol. 72, no. 4-6, pp. 1121\u20131130, Jan. 2009.", "citeRegEx": "5", "shortCiteRegEx": null, "year": 2009}, {"title": "Decoding brain states from fMRI connectivity graphs.", "author": ["J. Richiardi", "H. Eryilmaz", "S. Schwartz", "P. Vuilleumier", "D. Van De Ville"], "venue": "NeuroImage, vol. 56,", "citeRegEx": "6", "shortCiteRegEx": "6", "year": 2011}, {"title": "A generalized family of fixed-radius distributionbased distance measures for content-based fmri image retrieval", "author": ["J. Novatnack", "N. Cornea", "A. Shokoufandeh", "D. Silver", "S. Dickinson", "P. Kantor", "B. Bai"], "venue": "Pattern Recognition Letters, vol. 29, no. 12, pp. 1726 \u2013 1732, 2008.", "citeRegEx": "8", "shortCiteRegEx": null, "year": 2008}, {"title": "Semi-supervised kernel canonical correlation analysis with application to human fmri", "author": ["M.B. Blaschko", "J.A. Shelton", "A. Bartels", "C.H. Lampert", "A. Gretton"], "venue": "Pattern Recognition Letters, vol. 32, no. 11, pp. 1572 \u2013 1583, 2011.", "citeRegEx": "9", "shortCiteRegEx": null, "year": 2011}, {"title": "Complex brain networks: graph theoretical analysis of structural and functional systems.", "author": ["E. Bullmore", "O. Sporns"], "venue": "Nature reviews. Neuroscience,", "citeRegEx": "10", "shortCiteRegEx": "10", "year": 2009}, {"title": "Large-scale brain networks in cognition: emerging methods and principles.", "author": ["S.L. Bressler", "V. Menon"], "venue": "Trends in cognitive sciences,", "citeRegEx": "11", "shortCiteRegEx": "11", "year": 2010}, {"title": "Functional and Effective Connectivity in Neuroimaging: A Synthesis", "author": ["K.J. Friston", "K.J. Friston"], "venue": "1994.", "citeRegEx": "12", "shortCiteRegEx": null, "year": 1994}, {"title": "Review of methods for functional brain connectivity detection using fMRI.", "author": ["K. Li", "L. Guo", "J. Nie", "G. Li", "T. Liu"], "venue": "Computerized medical imaging and graphics : the official journal of the Computerized Medical Imaging Society,", "citeRegEx": "13", "shortCiteRegEx": "13", "year": 2009}, {"title": "Differential functional connectivity of prefrontal and medial temporal cortices during episodic", "author": ["A. McIntosh", "L. Nyberg", "F. Bookstein", "E. Tulving"], "venue": "Human Brain Mapping, 1997.", "citeRegEx": "14", "shortCiteRegEx": null, "year": 1997}, {"title": "A composite ICA algorithm and the application in localization of brain activities", "author": ["H. Chen", "D. Yao"], "venue": "Neurocomputing, vol. 56, pp. 429\u2013434, Jan. 2004.", "citeRegEx": "15", "shortCiteRegEx": null, "year": 2004}, {"title": "Spatio-temporal dynamics in fMRI recordings revealed with complex independent component analysis.", "author": ["J. Anem\u00fcller", "J.-R. Duann", "T.J. Sejnowski", "S. Makeig"], "venue": "Neurocomputing, vol. 69,", "citeRegEx": "16", "shortCiteRegEx": "16", "year": 2006}, {"title": "Causality analysis of neural connectivity: New tool and limitations of spectral Granger causality", "author": ["S. Hu", "H. Liang"], "venue": "Neurocomputing, vol. 76, no. 1, pp. 44\u201347, Jan. 2012.", "citeRegEx": "17", "shortCiteRegEx": null, "year": 2012}, {"title": "Estimation of functional connectivity in fMRI data using stability selection-based sparse partial correlation with elastic net penalty.", "author": ["S. Ryali", "T. Chen", "K. Supekar", "V. Menon"], "venue": "NeuroImage, vol. 59,", "citeRegEx": "18", "shortCiteRegEx": "18", "year": 2012}, {"title": "A Bayesian approach to determining connectivity of the human brain.", "author": ["R.S. Patel", "F.D. Bowman", "J.K. Rilling"], "venue": "Human brain mapping,", "citeRegEx": "19", "shortCiteRegEx": "19", "year": 2006}, {"title": "Distributed Patterns of Brain Activity that Lead to Forgetting.", "author": ["I. Oztekin", "D. Badre"], "venue": "Frontiers in human neuroscience,", "citeRegEx": "21", "shortCiteRegEx": "21", "year": 2011}, {"title": "Mesh Learning for Classifying Cognitive Processes", "author": ["M. \u00d6zay", "I. \u00d6ztekin", "U. \u00d6ztekin", "F.T.Y. Vural"], "venue": "Arxiv:1205.2382, May 2012.", "citeRegEx": "22", "shortCiteRegEx": null, "year": 2012}, {"title": "The Theory of Linear Prediction", "author": ["P.P. Vaidyanathan"], "venue": "Synthesis Lectures on Signal Processing, vol. 2, no. 1, pp. 1\u2013184, Jan. 2007.", "citeRegEx": "23", "shortCiteRegEx": null, "year": 2007}, {"title": "Neuroinformatics 2011: Modeling cognitive states using machine learning techniques", "author": ["M. \u00d6zay", "l. \u00d6ztekin", "U. \u00d6ztekin", "F.T. Yarman Vural"], "venue": "2011.", "citeRegEx": "24", "shortCiteRegEx": null, "year": 2011}, {"title": "A Mesh Learning Approach for Brain Data Modeling", "author": ["O. F\u0131rat", "M. \u00d6zay", "I. \u00d6nal", "l. \u00d6ztekin", "F.T. Yarman Vural"], "venue": "IEEE 20th Conference on Signal Processing and Communications Applications (SIU), 2012.", "citeRegEx": "25", "shortCiteRegEx": null, "year": 2012}, {"title": "The human connectome: a complex network.", "author": ["O. Sporns"], "venue": "Annals of the New York Academy of Sciences,", "citeRegEx": "26", "shortCiteRegEx": "26", "year": 2011}, {"title": "Networks of the Brain", "author": ["O. Sporns"], "venue": "Nov. 2010.", "citeRegEx": "27", "shortCiteRegEx": null, "year": 2010}, {"title": "Network modelling methods for FMRI.", "author": ["S.M. Smith", "K.L. Miller", "G. Salimi-Khorshidi", "M. Webster", "C.F. Beckmann", "T.E. Nichols", "J.D. Ramsey", "M.W. Woolrich"], "venue": "NeuroImage, vol. 54,", "citeRegEx": "28", "shortCiteRegEx": "28", "year": 2011}, {"title": "Self-tuning spectral clustering", "author": ["L. Zelnik-manor", "P. Perona"], "venue": "Advances in Neural Information Processing Systems 17. MIT Press, 2004, pp. 1601\u20131608.", "citeRegEx": "29", "shortCiteRegEx": null, "year": 2004}, {"title": "Neuroimaging, behavioral, and computational investigations of memory targeting", "author": ["S. Polyn"], "venue": "Ph.D. dissertation, Princeton University, 2005.", "citeRegEx": "30", "shortCiteRegEx": null, "year": 2005}, {"title": "Functional connectivity by cross-correlation clustering", "author": ["S. Dodel", "J. Herrmann", "T. Geisel"], "venue": "Neurocomputing, vol. 44-46, pp. 1065\u20131070, Jun. 2002.", "citeRegEx": "31", "shortCiteRegEx": null, "year": 2002}, {"title": "MATLAB toolbox for functional connectivity.", "author": ["D. Zhou", "W.K. Thompson", "G. Siegle"], "venue": "NeuroImage, vol. 47,", "citeRegEx": "33", "shortCiteRegEx": "33", "year": 2009}], "referenceMentions": [{"referenceID": 0, "context": "methods [1]\u2013[9].", "startOffset": 8, "endOffset": 11}, {"referenceID": 7, "context": "methods [1]\u2013[9].", "startOffset": 12, "endOffset": 15}, {"referenceID": 8, "context": "[10].", "startOffset": 0, "endOffset": 4}, {"referenceID": 9, "context": "effective connectivity which analyzes brain connectivity using causal effects between neural elements, resulting in causal activation paths [11], [12].", "startOffset": 140, "endOffset": 144}, {"referenceID": 10, "context": "effective connectivity which analyzes brain connectivity using causal effects between neural elements, resulting in causal activation paths [11], [12].", "startOffset": 146, "endOffset": 150}, {"referenceID": 11, "context": "or regions [13].", "startOffset": 11, "endOffset": 15}, {"referenceID": 12, "context": ", partial least squares for activation analysis is performed to construct a cross block covariance matrix using PET data [14].", "startOffset": 121, "endOffset": 125}, {"referenceID": 13, "context": "the selection of different functional interdependence functions [15]\u2013[17].", "startOffset": 64, "endOffset": 68}, {"referenceID": 15, "context": "the selection of different functional interdependence functions [15]\u2013[17].", "startOffset": 69, "endOffset": 73}, {"referenceID": 16, "context": "measure sparse-partial correlation between multiple regions using elastic net penalty, which combines `1 and `2 norm regularization terms in order to improve the sensitivity of the correlation measure [18].", "startOffset": 201, "endOffset": 205}, {"referenceID": 17, "context": "for an imbalance between class conditional and posterior probabilities, to achieve at a measure of connectivity [19].", "startOffset": 112, "endOffset": 116}, {"referenceID": 5, "context": "construct functional connectivity matrices by using pairwise Pearson correlation coefficients and employ graph matching to decode brain states [6].", "startOffset": 143, "endOffset": 146}, {"referenceID": 18, "context": "semantic categories and made recognition memory judgements while neural activation was recorded using fMRI [20], [21].", "startOffset": 113, "endOffset": 117}, {"referenceID": 19, "context": "In Mesh Learning [22], the cognitive states are modelled by local meshes for each individual voxel, called seed voxel \u03c5(ti, s\u0304j), which is defined in a neighbourhood system \u03b7p (see;Figure 1).", "startOffset": 17, "endOffset": 21}, {"referenceID": 20, "context": "Minimizing Equation 2 with respect to ai,j,k is accomplished by employing Levinson-Durbin recursion [23], where E(\u00b7) is the expectation operator.", "startOffset": 100, "endOffset": 104}, {"referenceID": 19, "context": "For the details of the mesh learning algorithm see [22], [24], [25].", "startOffset": 51, "endOffset": 55}, {"referenceID": 21, "context": "For the details of the mesh learning algorithm see [22], [24], [25].", "startOffset": 57, "endOffset": 61}, {"referenceID": 22, "context": "For the details of the mesh learning algorithm see [22], [24], [25].", "startOffset": 63, "endOffset": 67}, {"referenceID": 19, "context": "As a result, the Mesh Learning algorithm proposed by [22] performs better than the well-known individual", "startOffset": 53, "endOffset": 57}, {"referenceID": 23, "context": "Additionally, it is well known that spatially close voxels are strongly coupled during cognitive processes [26].", "startOffset": 107, "endOffset": 111}, {"referenceID": 24, "context": "between distributed and often spatially distant regions in brain [27], and constructed using an inter-regional analysis.", "startOffset": 65, "endOffset": 69}, {"referenceID": 25, "context": "sis [28].", "startOffset": 4, "endOffset": 8}, {"referenceID": 26, "context": "tions of voxels s\u0304j = (xj , yj , zj) in a self-tuning spectral clustering algorithm [29].", "startOffset": 84, "endOffset": 88}, {"referenceID": 19, "context": "In the Mesh Learning algorithm suggested in [22] p-neighbourhood is defined by Euclidean distance, whereas", "startOffset": 44, "endOffset": 48}, {"referenceID": 0, "context": "Standard deviation of within-cluster functional connectivity matrix Stdm, whose elements take values in the interval [0, 1] ( Figure 5b), standard deviation", "startOffset": 117, "endOffset": 123}, {"referenceID": 18, "context": "In the experiment, a participant is shown lists of words selected from a pre-defined semantic category, while being scanned using fMRI, see [20], [21].", "startOffset": 146, "endOffset": 150}, {"referenceID": 27, "context": ", onsets were shifted forward by three points to account for the hemodynamic response lag [30].", "startOffset": 90, "endOffset": 94}, {"referenceID": 28, "context": "can be employed after computing functional connectivity matrices in order to partition connectivity matrices such as [31], [32], but this will introduce additional thresholds and", "startOffset": 117, "endOffset": 121}, {"referenceID": 29, "context": "[33] is used for the computation of the correlation measures.", "startOffset": 0, "endOffset": 4}, {"referenceID": 19, "context": "functional connectivity in the mesh learning algorithm [22] improves classification performances, considerably.", "startOffset": 55, "endOffset": 59}, {"referenceID": 14, "context": "Classical MVPA method (Without LRF) 48 40 Mesh Learning [16] 58 45 Functional Mesh Learning using Positive Correlation 70 63 Functional Mesh Learning using Negative Correlation 69 62 Functional Mesh Learning using discriminative STD matrices 71 70 Functional Mesh Learning using discriminative ENT matrices 68 65", "startOffset": 56, "endOffset": 60}], "year": 2014, "abstractText": "We propose a statistical learning model for classifying cognitive processes based on distributed patterns of neural activation in the brain, acquired via functional magnetic resonance imaging (fMRI). In the proposed learning method, local meshes are formed around each voxel. The distance between voxels in the mesh is determined by using a functional neighbourhood concept. In order to define the functional neighbourhood, the similarities between the time series recorded for voxels are measured and functional connectivity matrices are constructed. Then, the local mesh for each voxel is formed by including the functionally closest neighbouring voxels in the mesh. The relationship between the voxels within a mesh is estimated by using a linear regression model. These relationship vectors, called Functional Connectivity aware Local Relational Features (FC-LRF) are then used to train a statistical learning machine. The proposed method was tested on a recognition memory experiment, including data pertaining to encoding and retrieval of words belonging to ten different semantic categories. Two popular classifiers, namely knearest neighbour (k-nn) and Support Vector Machine (SVM), are trained in order to predict the semantic category of the item being retrieved, based on activation patterns during encoding. The classification performance of the Functional Mesh Learning model, which range in 62% \u2212 71% is superior to the classical multi-voxel pattern analysis (MVPA) methods, which range in 40%\u2212 48%, for ten semantic categories.", "creator": "LaTeX with hyperref package"}}}