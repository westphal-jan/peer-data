{"id": "1405.5172", "review": {"conference": "arxiv", "VERSION": "v1", "DATE_OF_SUBMISSION": "20-May-2014", "title": "Opposition Based ElectromagnetismLike for Global Optimization", "abstract": "electromagnetismlike optimization ( big emo ) is a constrained global utility optimization survival algorithm, particularly designed well suited to globally solve niche problems featuring nonlinear and costly multimodal cost selection functions. real emo thus employs searcher agents implemented that emulate a rectangular population plot of electric charged particles objects which ultimately interact to engage each towards other essentially according to electromagnetisms laws of external attraction and friction repulsion. accordingly however, emo usually requires implementing a large number number of iterations allotted for organizing a local search procedure ; any reduction or cancelling over such target number, critically unnecessary perturb other issues today such in as convergence, exploration, higher population diversity and accuracy. so this paper presents an enhanced parallel emo adaptive algorithm called obemo, which nevertheless employs roughly the opposition - analysis based learning ( obl ) approach to electronically accelerate the global convergence completion speed. obl is a machine intelligence advanced strategy driver which both considers the shortest current candidate solution and confirms its opposite value at the same time, and achieving a faster exploration trajectory of the search space. the first proposed obemo chasing method significantly reduces rapidly the required computational effort yet avoids avoiding any detriment requirement to recover the good predicted search goal capabilities of the famous original emo suppression algorithm. experiments are partly conducted over generating a particular comprehensive dynamic set of benchmark functions, sometimes showing indicators that simulated obemo accurately obtains promising performance outcomes for most of the subjects discussed fusion test problems.", "histories": [["v1", "Tue, 20 May 2014 17:52:57 GMT  (537kb)", "http://arxiv.org/abs/1405.5172v1", "27 Pages"]], "COMMENTS": "27 Pages", "reviews": [], "SUBJECTS": "cs.AI", "authors": ["erik cuevas", "diego oliva", "daniel zaldivar", "marco perez", "gonzalo pajares"], "accepted": false, "id": "1405.5172"}, "pdf": {"name": "1405.5172.pdf", "metadata": {"source": "CRF", "title": "Opposition-Based Electromagnetism-Like for Global Optimization", "authors": ["Erik Cuevas", "Diego Oliva", "Daniel Zaldivar", "Gonzalo Pajares"], "emails": ["marco.perez}@cucei.udg.mx", "doliva@estumail.ucm.es,", "pajares@fdi.ucm.es", "erik.cuevas@cucei.udg.mx"], "sections": [{"heading": null, "text": "This is a preprint copy that has been accepted for publication in International Journal of Innovative Computing,\nInformation and Control\n1\nproblems featuring non-linear and multimodal cost functions. EMO employs searcher agents that emulate a population of charged particles which interact to each other according to electromagnetism\u2019s laws of attraction and repulsion. However, EMO usually requires a large number of iterations for a local search procedure; any reduction or cancelling over such number, critically perturb other issues such as convergence, exploration, population diversity and accuracy. This paper presents an enhanced EMO algorithm called OBEMO, which employs the OppositionBased Learning (OBL) approach to accelerate the global convergence speed. OBL is a machine intelligence strategy which considers the current candidate solution and its opposite value at the same time, achieving a faster exploration of the search space. The proposed OBEMO method significantly reduces the required computational effort yet avoiding any detriment to the good search capabilities of the original EMO algorithm. Experiments are conducted over a comprehensive set of benchmark functions, showing that OBEMO obtains promising performance for most of the discussed test problems."}, {"heading": "1. Introduction", "text": "Global Optimization (GO) [1,2] has issued applications for many areas of science [3], engineering [4], economics [5,6] and others whose definition requires mathematical modelling [7,8]. In general, GO aims to find the global optimum for an objective function which has been defined over a given search space. The difficulties associated with the use of mathematical methods over GO problems have contributed to\n1 Corresponding author, Tel +52 33 1378 5900, ext. 27714, E-mail: erik.cuevas@cucei.udg.mx\nThis is a preprint copy that has been accepted for publication in International Journal of Innovative Computing,\nInformation and Control\n2\nthe development of alternative solutions. Linear programming and dynamic programming techniques, for example, often have failed in solving (or reaching local optimum at) NP-hard problems which feature a large number of variables and non-linear objective functions. In order to overcome such problems, researchers have proposed metaheuristic-based algorithms for searching near-optimum solutions.\nMetaheuristic algorithms are stochastic search methods that mimic the metaphor of biological or physical phenomena. The core of such methods lies on the analysis of collective behaviour of relatively simple agents working on decentralized systems. Such systems typically gather an agent\u2019s population that can communicate to each other while sharing a common environment. Despite a non-centralized control algorithm regulates the agent behaviour, the agent can solve complex tasks by analyzing a given global model and harvesting cooperation to other elements. Therefore, a novel global behaviour evolves from interaction among agents as it can be seen on typical examples that include ant colonies, animal herding, bird flocking, fish schooling, honey bees, bacteria, charged particles and many more. Some other metaheuristic optimization algorithms have been recently proposed to solve optimization problems, such as Genetic Algorithms (GA) [9], Particle Swarm Optimization (PSO) [10], Ant Colony Optimization (ACO) [11], Differential Evolution (DE) [12], Artificial Immune Systems (AIS) [13] and Artificial Bee Colony [14] and Gravitational Search Algorithm (GSA) [15].\nElectromagnetism-like algorithm (EMO) is a relatively new population-based meta-heuristic algorithm which was firstly introduced by Birbil and Fang [16] to solve continuous optimization models using bounded variables. The algorithm imitates the attraction\u2013repulsion mechanism between charged particles in an electromagnetic field. Each particle represents a solution and carries a certain amount of charge which is proportional to the solution quality (objective function). In turn, solutions are defined by position vectors which give real positions for particles within a multi-dimensional space. Moreover, objective function values of particles are calculated considering such position vectors. Each particle exerts repulsion or attraction forces over other population members; the resultant force acting over a particle is used to update its position. Clearly, the idea behind the EMO methodology is to move particles towards the optimum solution by exerting attraction or repulsion forces. Unlike other traditional meta-heuristics techniques such as GA, DE, ABC and AIS, whose population members exchange materials or information between each other, the EMO methodology assumes that each particle is influenced by all\nThis is a preprint copy that has been accepted for publication in International Journal of Innovative Computing,\nInformation and Control\n3\nother particles in the population, mimicking other heuristics methods such as PSO and ACO. Although the EMO algorithm shares some characteristics with PSO and ACO, recent works have exhibited its better accuracy regarding optimal parameters [17-20], yet showing convergence [21]. EMO has been successfully applied to solve different sorts of engineering problems such as flow-shop scheduling [22], communications [23], vehicle routing [24], array pattern optimization in circuits [25], neural network training [26] control systems [27] and image processing [28].\nEMO algorithm employs four main phases: initialization, local search, calculation and movement. The local search procedure is a stochastic search in several directions over all coordinates of each particle. EMO\u2019s main drawback is its computational complexity resulting from the large number of iterations which are commonly required during the searching process. The issue becomes worst as the dimension of the optimization problem increases. Several approaches, which simplify the local search, have been proposed in the literature to reduce EMO\u2019s computational effort. In [29] where Guan et al. proposed a discrete encoding for the particle set in order to reduce search directions at each dimension. In [30] and [31], authors include a new local search method which is based on a fixed search pattern and a shrinking strategy that aims to reduce the population size as the iterative process progresses. Additionally, in [17], a modified local search phase that employs the gradient descent method is adopted to enhance its computational complexity. Although all these approaches have improved the computational time which is required by the original EMO algorithm, recent works [27,32] have demonstrated that reducing or simplifying EMO\u2019s local search processes also affects other important properties, such as convergence, exploration, population diversity and accuracy.\nOn the other hand, the opposition-based learning (OBL), that has been initially proposed in [33], is a machine intelligence strategy which considers the current estimate and its correspondent opposite value (i.e., guess and opposite guess) at the same time to achieve a fast approximation for a current candidate solution. It has been mathematically proved [34-36] that an opposite candidate solution holds a higher probability for approaching the global optimum solution than a given random candidate, yet quicker. Recently, the concept of opposition has been used to accelerate metaheuristic-based algorithms such as GA [37], DE [38], PSO [39] and GSA [40].\nThis is a preprint copy that has been accepted for publication in International Journal of Innovative Computing,\nInformation and Control\n4\nIn this paper, an Opposition-Based EMO called OBEMO is constructed by combining the oppositionbased strategy and the standard EMO technique. The enhanced algorithm allows a significant reduction on the computational effort which required by the local search procedure yet avoiding any detriment to the good search capabilities and convergence speed of the original EMO algorithm. The proposed algorithm has been experimentally tested by means of a comprehensive set of complex benchmark functions. Comparisons to the original EMO and others state-of-the-art EMO-based algorithms [7] demonstrate that the OBEMO technique is faster for all test functions, yet delivering a higher accuracy. Conclusions on the conducted experiments are supported by statistical validation that properly supports the results.\nThe rest of the paper is organized as follows: Section 2 introduces the standard EMO algorithm. Section 3 gives a simple description of OBL and Section 4 explains the implementation of the proposed OBEMO algorithm. Section 5 presents a comparative study among OBEMO and other EMO variants over several benchmark problems. Finally, some conclusions are drawn in Section 6."}, {"heading": "2. Electromagnetism - Like Optimization Algorithm (EMO)", "text": "EMO algorithm is a simple and direct search algorithm which has been inspired by the electro-magnetism phenomenon. It is based on a given population and the optimization of global multi-modal functions. In comparison to GA, it does not use crossover or mutation operators to explore feasible regions; instead it does implement a collective attraction\u2013repulsion mechanism yielding a reduced computational cost with respect to memory allocation and execution time. Moreover, no gradient information is required as it employs a decimal system which clearly contrasts to GA. Few particles are required to reach converge as has been already demonstrated in [11].\nEMO algorithm can effectively solve a special class of optimization problems with bounded variables in the form of:\n[ ]ulx xf , )(min \u2208 , (1)\nThis is a preprint copy that has been accepted for publication in International Journal of Innovative Computing,\nInformation and Control\n5\nwhere [ ] { }, | , 1,2...n d d dl u x l x u d n= \u2208\u211c \u2264 \u2264 = and n being the dimension of the variable x, [ ], nl u \u2282 \u211c ,\na nonempty subset and a real-value function [ ]: ,f l u \u2192 \u211c . Hence, the following problem features are\nknown:\n\u2022 n : Dimensional size of the problem.\n\u2022 du : The highest bound of the thk dimension.\n\u2022 dl : The lowest bound of the thk dimension. \u2022 ( )f x : The function to be minimized.\nEMO algorithm has four phases [6]: initialization, local search, computation of the total force vector and movement. A deeper discussion about each stage follows.\nInitialization, a number of m particles is gathered as their highest (u) and lowest limit (l) are identified. Local search, gathers local information for a given point pg , where (1, , )p m\u2208 K .\nCalculation of the total force vector, charges and forces are calculated for every particle. Movement, each particle is displaced accordingly, matching the corresponding force vector."}, {"heading": "2.1 Initialization", "text": "First, the population of m solutions is randomly produced at an initial state. Each n-dimensional solution is regarded as a charged particle holding a uniform distribution between the highest (u) and the lowest (l) limits. The optimum particle (solution) is thus defined by the objective function to be optimized. The procedure ends when all the m samples are evaluated, choosing the sample (particle) that has gathered the best function value."}, {"heading": "2.2 Local Search", "text": "The local search procedure is used to gather local information within the neighbourhood of a candidate solution. It allows obtaining a better exploration and population diversity for the algorithm.\nThis is a preprint copy that has been accepted for publication in International Journal of Innovative Computing,\nInformation and Control\n6\nConsidering a pre-fixed number of iterations known as ITER and a feasible neighbourhood search \u03b4 , the\nprocedure iterates as follows: Point pg is assigned to a temporary point t to store the initial information.\nNext, for a given coordinate d, a random number is selected ( 1\u03bb ) and combined with \u03b4 as a step length, which in turn, moves the point t along the direction d, with a randomly determined sign ( 2\u03bb ). If point t observes a better performance over the iteration number ITER, point pg is replaced by t and the\nneighbourhood search for point pg finishes, otherwise pg is held. The pseudo-code is listed in Fig. 1.\nIn general, the local search for all particles can also reduce the risk of falling into a local solution but is time consuming. Nevertheless, recent works [17,32] have shown that eliminating, reducing or simplifying the local search process affects significantly the convergence, exploration, population diversity and accuracy of the EMO algorithm."}, {"heading": "2.3 Total force vector computation", "text": "The total force vector computation is based on the superposition principle (Fig. 2) from the electromagnetism theory which states: \u201cthe force exerted on a point via other points is inversely proportional to the distance between the points and directly proportional to the product of their charges\u201d [41]. The particle moves following the resultant Coulomb\u2019s force which has been produced among particles as a charge-like value. In the EMO implementation, the charge for each particle is determined by its fitness value as follows:\n( ) ( ) ( ) ( )( )\n1\nexp , p best p\nm\nh best\nh\nf f q n p\nf f =\n   \u2212 = \u2212 \u2200  \n\u2212     \u2211\ng g\ng g\n, (2)\nwhere n denotes the dimension of pg and m represents the population size. A higher dimensional\nproblem usually requires a larger population. In Eq. (2), the particle showing the best fitness function value bestg is called the \u201cbest particle\u201d, getting the highest charge and attracting other particles holding\nThis is a preprint copy that has been accepted for publication in International Journal of Innovative Computing,\nInformation and Control\n7\nhigh fitness values. The repulsion effect is applied to all other particles exhibiting lower fitness values. Both effects, attraction-repulsion are applied depending on the actual proximity between a given particle and the best-graded element.\nThe overall resultant force between all particles determines the actual effect of the optimization process. The final force vector for each particle is evaluated under the Coulomb\u2019s law and the superposition principle as follows:\n( )\n( )\n2\n2\n( ) ( )\n,\n( ) ( )\np h h p h p\nh p m\np\np h h p p h h p\nh p\nq q if f f p q q\nif f f \u2260\n  \u2212 < \n\u2212  = \u2200   \u2212 \u2265  \u2212   \u2211\ng g g g g g\nF\ng g g g g g\n(3)\nwhere ( ) ( )h pf f<g g represents the attraction effect and ( ) ( )h pf f\u2265g g represents the repulsion force\n(see Fig. 3). The resultant force of each particle is proportional to the product between charges and is inversely proportional to the distance between particles. In order to keep feasibility, the vector in expression (3) should be normalized as follows:\nThis is a preprint copy that has been accepted for publication in International Journal of Innovative Computing,\nInformation and Control\n8\n\u02c6 , . p p p p= \u2200FF\nF (4)"}, {"heading": "2.4. Movement", "text": "The change of the d-coordinate for each particle p is computed with respect to the resultant force as follows:\n( ) ( ) \u02c6 \u02c6if 0 , , \u02c6 \u02c6if 0 p p p p d d d d dp d p p p p\nd d d d d\ng F u g F g p best d\ng F g l F\n\u03bb \u03bb  + \u22c5 \u22c5 \u2212 > = \u2200 \u2260 \u2200  + \u22c5 \u22c5 \u2212 \u2264  \n(5)\nIn Eq. (5), \u03bb is a random step length that is uniformly distributed between zero and one. d u and\nd l represent the upper and lower boundary for the d-coordinate, respectively. \u02c6 p d F represents the d element of \u02c6 pF . If the resultant force is positive, then the particle moves towards the highest boundary by a random step length. Otherwise it moves toward the lowest boundary. The best particle does not move at all, because it holds the absolute attraction, pulling or repelling all others in the population."}, {"heading": "3. Opposition - based Learning (OBL).", "text": "Opposition-based Learning [33] is a new concept in computational intelligence that has been employed to effectively enhance several soft computing algorithms [42,43]. The approach simultaneously evaluates a\nThis is a preprint copy that has been accepted for publication in International Journal of Innovative Computing,\nInformation and Control\n9\nsolution x and its opposite solution x for a given problem, providing a renewed chance to find a\ncandidate solution lying closer to the global optimum [34]."}, {"heading": "3.1 Opposite number", "text": "Let [ ],x l u\u2208 be a real number, where l and u are the lowest and highest bound respectively. The opposite\nof x is defined by:\nx u l x= + \u2212 (6)"}, {"heading": "3.2 Opposite point", "text": "Similarly, the opposite number definition is generalized to higher dimensions as follows: Let 1 2( , , , )nx x x=x K be a point within a n-dimensional space, where 1 2, , , nx x x R\u2208K and [ ],i i ix l u\u2208 ,\n1,2, ,i n\u2208 K . The opposite point 1 2( , , , )nx x x=x K is defined by:\ni i i i x u l x= + \u2212 (7)"}, {"heading": "3.3 Opposition-based optimization", "text": "Metaheuristic methods start by considering some initial solutions (initial population) and trying to improve them toward some optimal solution(s). The process of searching ends when some predefined criteria are satisfied. In the absence of a priori information about the solution, random guesses are usually considered. The computation time, among others algorithm characteristics, is related to the distance of these initial guesses taken from the optimal solution. The chance of starting with a closer (fitter) solution can be enhanced by simultaneously checking the opposite solution. By doing so, the fitter one (guess or opposite guess) can be chosen as an initial solution following the fact that, according to probability theory, 50% of the time a guess is further from the solution than its opposite guess [35]. Therefore, starting with the closer of the two guesses (as judged by their fitness values) has the potential to\nThis is a preprint copy that has been accepted for publication in International Journal of Innovative Computing,\nInformation and Control\n10\naccelerate convergence. The same approach can be applied not only to initial solutions but also to each solution in the current population.\nBy applying the definition of an opposite point, the opposition-based optimization can be defined as\nfollows: Let x be a point in a n-dimensional space (i.e. a candidate solution). Assume ( )f x is a fitness\nfunction which evaluates the quality of such candidate solution. According to the definition of opposite\npoint, x is the opposite of x . If ( )f x is better than ( )f x , then x is updated with x , otherwise current\npoint x is kept. Hence, the best point ( x or x ) is modified using known operators from the populationbased algorithm.\nFigure 4 shows the opposition-based optimization procedure. In the example, Fig. 4a and 4b represent the function to be optimized and its corresponding contour plot, respectively. By applying the OBL\nprinciples to the current population P (see Fig. 4b), the three particles 1x , 2x and 3x produce a new\npopulation OP, gathering particles 1x , 2x and 3x . The three fittest particles from P and OP are selected as the new population P\u2032 . It can be seen from Fig. 4b that 1x , 2x and 3x are three new members in P\u2032 . In\nthis case, the transformation conducted on 1x did not provide a best chance of finding a candidate\nsolution closer to the global optimum. Considering the OBL selection mechanism, 1x is eliminated from the next generation.\nThis is a preprint copy that has been accepted for publication in International Journal of Innovative Computing,\nInformation and Control\n11"}, {"heading": "4. Opposition-based Electromagnetism-like Optimization (OBEMO)", "text": "Similarly to all metaheuristic-based optimization algorithms, two steps are fundamental for the EMO algorithm: the population initialization and the production of new generations by evolutionary operators. In the approach, the OBL scheme is incorporated to enhance both steps. However, the original EMO is considered as the main algorithm while the opposition procedures are embedded into EMO aiming to accelerate its convergence speed. Figure 5 shows a data flow comparison between the EMO and the OBEMO algorithm. The novel extended opposition procedures are explained in the following\nThis is a preprint copy that has been accepted for publication in International Journal of Innovative Computing,\nInformation and Control\n12\nsubsections."}, {"heading": "4.1 Opposition-Based Population Initialization", "text": "In population-based meta-heuristic techniques, the random number generation is the common choice to create an initial population in absence of a priori knowledge. Therefore, as mentioned in Section 3, it is possible to obtain fitter starting candidate solutions by utilizing OBL despite no a-priori knowledge about the solution(s) is available. The following steps explain the overall procedure.\n1) Initialize the population X with P N representing the number of particles. 2) Calculate the opposite population by\nj j\ni i i i x u l x= + \u2212\n1,2, , ;i n= K 1,2, , P j N= K\n(8)\nwhere j i x and j i x denote the ith parameter of the jth particle of the population and its corresponding opposite particle.\n3) Select the P N fittest elements from { }\u222aX X as initial population."}, {"heading": "4.2 Opposition-based production for new Generation", "text": "Starting from the current population, the OBL strategy can be used again to produce new populations. In this procedure, the opposite population is calculated and the fittest individuals are selected from the union of the current population and the opposite population. The following steps summarize the OBEMO implementation as follows:\nStep 1. Generate P N initial random particles hx to create the particle vector X , with 1,2, P h N\u2208 K .\nThis is a preprint copy that has been accepted for publication in International Journal of Innovative Computing,\nInformation and Control\n13\nStep 2. Apply the OBL strategy by considering P N particles from vector X and generating the\nopposite vector X through Eq. 7.\nStep 3. Select the P N fittest particles from \u222aX X according to ( )f \u22c5 . These particles build the initial\npopulation 0X .\nStep 4. Calculate the local search procedure for each particle of 0X as follows: For a given\ndimension d, the particle hx is assigned to a temporary point y to store the initial information. Next, a random number is selected and combined with \u03b4 to yield the step length. Therefore,\nthe point y is moved along that direction. The sign is determined randomly. If ( )hf x is\nminimized, the particle hx is replaced by y, ending the neighborhood-wide search for a\nparticle h. The result is stored into the population vector Local X .\nStep 5. Determine the best particle bestx of the population vector Local X (with\n{ }arg min ( ),best hf h\u2190 \u2200x x ).\nStep 6. Calculate the charge among particles using expression (2) and the vector force through Eq.\n(3). The particle showing the better objective function value holds a bigger charge and therefore a bigger attraction force.\nStep 7. Change particle positions according to their force magnitude. The new particle\u2019s position is\ncalculated by expression (5). bestx is not moved because it has the biggest force and attracts\nothers particles to itself. The result is stored into the population vector Mov X .\nStep 8. Apply the OBL strategy over the m particles of the population vector Mov X , the opposite\nvector Mov X can be calculated through Eq. 7.\nStep 9. Select the m fittest particles from Mov Mov \u222aX X according to ( )f \u22c5 . Such particles represent the\npopulation 0X .\nStep 10. Increase the Iteration index. If iteration = MAXITER or the value of ( )f X is smaller than the\npre-defined threshold value, then the algorithm is stopped and the flow jumps to step 11. Otherwise, it jumps to step 4.\nStep 11. The best particle bestx is selected from the last iteration as it is considered as the solution.\nThis is a preprint copy that has been accepted for publication in International Journal of Innovative Computing,\nInformation and Control\n14"}, {"heading": "5. Experimental results", "text": "In order to test the algorithm\u2019s performance, the proposed OBEMO is compared to the standard EMO and others state-of-the-art EMO-based algorithms. In this section, the experimental results are discussed in the following subsections:\n(5.1) Test problems (5.2) Parameter settings for the involved EMO algorithms (5.3) Results and discussions"}, {"heading": "5.1. Test problems", "text": "A comprehensive set of benchmark problems, that includes 14 different global optimization tests, has been chosen for the experimental study. According to their use in the performance analysis, the functions are divided in two different sets: original test functions ( 1 9f f\u2212 ) and multidimensional functions ( 10 14f f\u2212 ). Every function at this paper is considered as a minimization problem itself.\nThe original test functions, which are shown in Table 1, agree to the set of numerical benchmark functions presented by the original EMO paper at [16]. Considering that such function set is also employed by a vast majority of EMO-based new approaches, its use in our experimental study facilitates its comparison to similar works. More details can be found in [44].\nThe major challenge of an EMO-based approach is to avoid the computational complexity that arises from the large number of iterations which are required during the local search process. Since the computational complexity depends on the dimension of the optimization problem, one set of multidimensional functions (see Table 2) is used in order to assess the convergence and accuracy for each algorithm. Multidimensional functions include a set of five different functions whose dimension has been fixed to 30.\nFunction Search domain Global minima\nBranin\n2 2 1 1 2 2 1 1 12\n5 5 1 ( , ) ( 6) 10(1 )cos 10\n4 8 f x x x x x x \u03c0 \u03c0 \u03c0 = \u2212 + \u2212 + \u2212 +\n15 10x\u2212 \u2264 \u2264\n20 15x\u2264 \u2264\n0.397887\nCamel\n2 2\n2 2 1\n2 1 2 2\n4.5 2 ( , )\nx\nx x f x x\ne\n\u2212 + += \u2212\n1 22 , 2x x\u2212 \u2264 \u2264\n-1.031\nGoldenstain-Price\nThis is a preprint copy that has been accepted for publication in International Journal of Innovative Computing,\nInformation and Control\n15\nFunction Search domain Global minima\n2 10 1 ( ) 10cos(2 ) 10 n i ii f x x\u03c0 =  = \u2212 + \u2211x\n30[ 5.12,5.12]\u2212\n0\n2 11 1 1\n1 1 ( ) 20exp 0.2 exp cos(2 ) 20 n n\ni ii i f x x n n \u03c0 = =    = \u2212 \u2212 \u2212 +        \u2211 \u2211x\n30[ 32,32]\u2212\n0\n2 12 1 1\n1 ( ) cos 1\n4000\nnn i ii i x f x i= =  = \u2212 +    \u2211 \u220fx 30[ 600,600]\u2212\n0\n{ }1 2 2 213 1 11( ) 10sin( ) ( 1) 1 10sin ( ) ( 1)n i i nif y y y yn \u03c0 \u03c0 \u03c0\u2212 +=  = + \u2212 + + \u2212 \u2211x\n1\n( ,10,100,4) n\nii u x = +\u2211\n30[ 50,50]\u2212\n0\nThis is a preprint copy that has been accepted for publication in International Journal of Innovative Computing,\nInformation and Control\n16"}, {"heading": "5.2. Parameter settings for the involved EMO algorithms", "text": "The experimental set aims to compare four EMO-based algorithms including the proposed OBEMO. All algorithms face 14 benchmark problems. The algorithms are listed below:\n- Standard EMO algorithm [16]; - Hybridizing EMO with descent search (HEMO) [17]; - EMO with fixed search pattern (FEMO) [30]; - The proposed approach OBEMO.\nFor the original EMO algorithm described in [16] and the proposed OBEMO, the parameter set is configured considering: 0.001=\u03b4 and LISTER=4. For the HEMO, the following experimental parameters are considered: max 10LsIt = , 0.001r\u03b5 = and 0.00001\u03b3 = . Such values can be assumed as the best configuration set according to [17]. Diverging from the standard EMO and the OBEMO algorithm, the HEMO method reduces the local search phase by only processing the best found particle bestx . The parameter set for the FEMO approach is defined by considering the following values: max 100= fe N ,\nmax 10= ls N , 0.001=\u03b4 , min 81 10\u2212= \u00d7\u03b4 and 0.1= \u03b4 \u03b5 . All aforementioned EMO-based algorithms use the\nsame population size of m = 50."}, {"heading": "5.3. Results and discussions", "text": "Original test functions set On this test set, the performance of the OBEMO algorithm is compared to standard EMO, HEMO and FEMO, considering the original test functions set. Such functions, presented in Table 1, hold different dimensions and one known global minimum. The performance is analyzed by considering 35 different executions for each algorithm. The case of no significant changes in the solution being registered (i.e. smaller than 410\u2212 ) is considered as stopping criterion.\nThe results, shown by Table 3, are evaluated assuming the averaged best value f(x) and the averaged\nnumber of executed iterations (MAXITER). Figure 6 shows the optimization process for the function 3f\nand 6f . Such function values correspond to the best case for each approach that is obtained after 35 executions.\nFunction\n1f\n2f\n3f\n4f\n5f\n6f\n7f\n8f\n9f\nDimension 2 2 2 3 6 4 4 4 2\nAveraged best values f(x) 0.3980 -1.015 3.0123 -3.7156 -3.6322 -10.07 -10.23 -10.47 -186.71\nE M\nO\nAveraged MAXITER 103 128 197 1.59E+03 1.08E+03 30 31 29 44\nAveraged best values f(x) 0.3980 -1.027 3.0130 -3.7821 -3.8121 -10.11 -10.22 -10.50 -186.65\nO B\nE M\nAveraged MAXITER 61 83 101 1.12E+03 826 18 19 17 21\nAveraged best values f(x) 0.5151 -0.872 3.413 -3.1187 -3.0632 -9.041 -9.22 -9.1068 -184.31\nH E\nM O\nAveraged MAXITER 58 79 105 1.10E+03 805 17 18 15 22\nAveraged best values f(x) 0.4189 -0.913 3.337 -3.3995 -3.2276 -9.229 -9.88 -10.18 -183.88\nF E\nM O\nAveraged MAXITER 63 88 98 1.11E+03 841 21 22 19 25\nThis is a preprint copy that has been accepted for publication in International Journal of Innovative Computing,\nInformation and Control\n18\nIn order to statistically analyse the results in Table 3, a non-parametric significance proof known as the Wilcoxon\u2019s rank test [45-47] has been conducted. Such proof allows assessing result differences among two related methods. The analysis is performed considering a 5% significance level over the \u201caveraged best value of f(x)\u201d and the \u201caveraged number of executed iterations of MAXITER\u201d data. Table 4 and Table 5 reports the p-values produced by Wilcoxon\u2019s test for the pair-wise comparison of the \u201caveraged best value\u201d and the \u201caveraged number of executed iterations\u201d respectively, considering three groups. Such groups are formed by OBEMO vs. EMO, OBEMO vs. HEMO and OBEMO vs. FEMO. As a null hypothesis, it is assumed that there is no difference between the values of the two algorithms. The alternative hypothesis considers an actual difference between values from both approaches. The results obtained by the Wilcoxon test indicate that data cannot be assumed as occurring by coincidence (i.e. due to the normal noise contained in the process).\nTable 4 considers the Wilcoxon analysis with respect to the \u201caveraged best value\u201d of f(x). The p-values for the case of OBEMO vs EMO are larger than 0.05 (5% significance level) which is a strong evidence supporting the null hypothesis which indicates that there is no significant difference between both methods. On the other hand, in cases for the p-values corresponding to the OBEMO vs HEMO and OBEMO vs FEMO, they are less than 0.05 (5% significance level), which accounts for a significant difference between the \u201caveraged best value\u201d data among methods. Table 5 considers the Wilcoxon analysis with respect to the \u201caveraged number of executed iterations\u201d values. Applying the same criteria,\nThis is a preprint copy that has been accepted for publication in International Journal of Innovative Computing,\nInformation and Control\n19\nit is evident that there is a significant difference between the OBEMO vs. EMO case, despite the OBEMO vs HEMO and OBEMO vs FEMO cases offering similar results.\nMultidimensional functions In contrast to the original functions, Multidimensional functions exhibit many local minima/maxima which are, in general, more difficult to optimize. In this section the performance of the OBEMO algorithm is compared to the EMO, the HEMO and the FEMO algorithms, considering functions in Table 2. This comparison reflects the algorithm\u2019s ability to escape from poor local optima and to locate a nearglobal optimum, consuming the least number of iterations. The dimension of such functions is set to 30. The results (Table 6) are averaged over 35 runs reporting the \u201caveraged best value\u201d and the \u201caveraged number of executed iterations\u201d as performance indexes.\nThis is a preprint copy that has been accepted for publication in International Journal of Innovative Computing,\nInformation and Control\n20\nThe Wilcoxon rank test results, presented in Table 7, shows that the p-values (regarding to the \u201caveraged best value\u201d values of Table 6) for the case of OBEMO vs EMO, indicating that there is no significant difference between both methods. p-values corresponding to the OBEMO vs HEMO and OBEMO vs FEMO show that there is a significant difference between the \u201caveraged best\u201d values among the methods. Figure 7 shows the optimization process for the function and . Such function values correspond to the best case, for each approach, obtained after 35 executions.\nTable 8 considers the Wilcoxon analysis with respect to the \u201caveraged number of executed iterations\u201d values of Table 6. As it is observed, the outcome is similar to the results from last test on the original functions.\nFunction p-Values OBEMO vs. EMO OBEMO vs. HEMO OBEMO vs. FEMO\n10f 3.78E-05 0.1322 0.2356 11f 2.55E-05 0.2461 0.1492\nThis is a preprint copy that has been accepted for publication in International Journal of Innovative Computing,\nInformation and Control\n21"}, {"heading": "6. Conclusions", "text": "In this paper, an Opposition-Based EMO, named as OBEMO, has been proposed by combining the opposition-based learning (OBL) strategy and the standard EMO technique. The OBL is a machine intelligence strategy which considers, at the same time, a current estimate and its opposite value to achieve a fast approximation for a given candidate solution. The standard EMO is enhanced by using two OBL steps: the population initialization and the production of new generations. The enhanced algorithm significantly reduces the required computational effort yet avoiding any detriment to the good search capabilities of the original EMO algorithm.\nThis is a preprint copy that has been accepted for publication in International Journal of Innovative Computing,\nInformation and Control\n22\nA set of 14 benchmark test functions has been employed for experimental study. Results are supported by a statistically significant framework (Wilcoxon test [45-47]) to demonstrate that the OBEMO is as accurate as the standard EMO yet requiring a shorter number of iterations. Likewise, it is as fast as others state-of-the-art EMO-based algorithms such as HEMO [7] and FEMO [30], still keeping the original accuracy.\nAlthough the results offer evidence to demonstrate that the Opposition-Based EMO method can yield good results on complicated optimization problems, the paper\u2019s aim is not to devise an optimization algorithm that could beat all others currently available, but to show that the Opposition-based Electromagnetism-like method can effectively be considered as an attractive alternative for solving global optimization problems."}], "references": [{"title": "An efficient global optimization approach for rough set based dimensionality reduction", "author": ["Songbo Tan", "Xueqi Cheng", "Hongbo Xu"], "venue": "International Journal of Innovative Computing, Information and Control,", "citeRegEx": "1", "shortCiteRegEx": "1", "year": 2007}, {"title": "A new approach to global optimization motivated by parliamentary political competitions", "author": ["Ali Borji", "Mandana Hamidi"], "venue": "International Journal of Innovative Computing, Information and Control,", "citeRegEx": "2", "shortCiteRegEx": "2", "year": 2009}, {"title": "Error-tolerant minimum finding with DNA computing", "author": ["Chia-Ning Yang", "Kuo-Si Huang", "Chang-Biau Yang", "Chie-Yao Hsu"], "venue": "International Journal of Innovative Computing, Information and Control,", "citeRegEx": "3", "shortCiteRegEx": "3", "year": 2009}, {"title": "An optimization model based decision support system for distributed energy systems planning. International Journal of Innovative Computing, Information and Control, 7(5(B)), 2011, 2651-2668", "author": ["Weijun Gao", "Hongbo Ren"], "venue": null, "citeRegEx": "4", "shortCiteRegEx": "4", "year": 2012}, {"title": "Multistage portfolio optimization with var as risk", "author": ["Chunhui Xu", "Jie Wang", "Naoki Shiba"], "venue": "measure. International Journal of Innovative Computing, Information and Control,", "citeRegEx": "5", "shortCiteRegEx": "5", "year": 2007}, {"title": "A performance comparison between genetic algorithms and particle swarm optimization applied in constructing equity portfolios", "author": ["Jui-Fang Chang"], "venue": "International Journal of Innovative Computing, Information and Control,", "citeRegEx": "6", "shortCiteRegEx": "6", "year": 2009}, {"title": "Optimization of linear observations for the stationary kalman filter based on a generalized water filling theorem", "author": ["Yoshiki Takeuchi"], "venue": "International Journal of Innovative Computing, Information and Control,", "citeRegEx": "7", "shortCiteRegEx": "7", "year": 2008}, {"title": "A numerical scheme for approximate optimal control of nonlinear hybrid systems", "author": ["Akbar H. Borzabadi", "Mohammad E. Sadjadi", "Behzad Moshiri"], "venue": "International Journal of Innovative Computing, Information and Control,", "citeRegEx": "8", "shortCiteRegEx": "8", "year": 2010}, {"title": "Adaptation in Natural and Artificial Systems, University of Michigan Press", "author": ["J.H. Holland"], "venue": "Ann Arbor, MI,", "citeRegEx": "9", "shortCiteRegEx": "9", "year": 1975}, {"title": "Positive feedback as a search strategy", "author": ["M. Dorigo", "V. Maniezzo", "A. Colorni"], "venue": "Technical Report", "citeRegEx": "11", "shortCiteRegEx": "11", "year": 1991}, {"title": "Differential Evolution a Practical Approach to Global Optimization, Springer", "author": ["K. Price", "R. Storn", "A. Lampinen"], "venue": "Natural Computing Series,", "citeRegEx": "12", "shortCiteRegEx": "12", "year": 2005}, {"title": "Teams of intelligent agents which learn using artificial immune systems", "author": ["Colin Fyfe", "Lakhmi Jain"], "venue": "Journal of Network and Computer Applications,", "citeRegEx": "13", "shortCiteRegEx": "13", "year": 2005}, {"title": "An idea based on honey bee swarm for numerical optimization, technical report- TR06,Erciyes University, Engineering Faculty", "author": ["D. Karaboga"], "venue": "Computer Engineering Department", "citeRegEx": "14", "shortCiteRegEx": "14", "year": 2005}, {"title": "Filter modeling using Gravitational Search Algorithm", "author": ["E. Rashedia", "H. Nezamabadi-pour", "S. Saryazdi"], "venue": "Engineering Applications of Artificial Intelligence,", "citeRegEx": "15", "shortCiteRegEx": "15", "year": 2011}, {"title": "An Electromagnetism-like Mechanism for Global Optimization", "author": ["S. \u0130lker Birbil", "Shu-Cherng Fang"], "venue": "Journal of Global Optimization,", "citeRegEx": "16", "shortCiteRegEx": "16", "year": 2003}, {"title": "Hybridizing the electromagnetism-like algorithm with descent search for solving engineering design problems", "author": ["A. Rocha", "E. Fernandes"], "venue": "International Journal of Computer Mathematics,", "citeRegEx": "17", "shortCiteRegEx": "17", "year": 2009}, {"title": "Modified movement force vector in an electromagnetism-like mechanism for global optimization", "author": ["A. Rocha", "E. Fernandes"], "venue": "Optimization Methods & Software", "citeRegEx": "18", "shortCiteRegEx": "18", "year": 2009}, {"title": "Multi-objective inventory control using electromagnetism-like metaheuristic", "author": ["C.S. Tsou", "C.H. Kao"], "venue": "International Journal of Production Research,", "citeRegEx": "19", "shortCiteRegEx": "19", "year": 2008}, {"title": "An electromagnetism algorithm of neural network analysis an application to textile retail operation", "author": ["P. Wu", "Y. Wen-Hung", "W. Nai-Chieh"], "venue": "Journal of the Chinese Institute of Industrial Engineers,", "citeRegEx": "20", "shortCiteRegEx": "20", "year": 2004}, {"title": "On the convergence of a population-based global optimization algorithm", "author": ["S.I. Birbil", "S.C. Fang", "R.L. Sheu"], "venue": "Journal of Global Optimization,", "citeRegEx": "21", "shortCiteRegEx": "21", "year": 2004}, {"title": "Electromagnetism-like mechanism and simulated annealing algorithms for flowshop scheduling problems minimizing the total weighted tardiness and makespan", "author": ["B. Naderi", "R. Tavakkoli-Moghaddam", "M. Khalili"], "venue": "Knowledge-Based Systems,", "citeRegEx": "22", "shortCiteRegEx": "22", "year": 2010}, {"title": "Peak to average power ratio reduction of multicarrier transmission systems using electromagnetism-like method", "author": ["Ho-Lung Hung", "Yung-Fa Huang"], "venue": "International Journal of Innovative Computing, Information and Control,", "citeRegEx": "23", "shortCiteRegEx": "23", "year": 2011}, {"title": "A new Hybrid Electromagnetism-like Algorithm for capacitated vehicle routing problems", "author": ["A. Yurtkuran", "E. Emel"], "venue": "Expert Systems with Applications,", "citeRegEx": "24", "shortCiteRegEx": "24", "year": 2010}, {"title": "Kun-Chou, Array pattern optimization using electromagnetism-like algorithm", "author": ["L.J. Jhen-Yan"], "venue": "AEU - International Journal of Electronics and Communications,", "citeRegEx": "25", "shortCiteRegEx": "25", "year": 2009}, {"title": "An electromagnetism algorithm of neural network analysis an application to textile retail operation", "author": ["P. Wu", "Y. Wen-Hung", "W. Nai-Chieh"], "venue": "Journal of the Chinese Institute of Industrial Engineers,", "citeRegEx": "26", "shortCiteRegEx": "26", "year": 2004}, {"title": "Fractional-order PID controller optimization via improved electromagnetismlike algorithm", "author": ["C.H. Lee", "F.K. Chang"], "venue": "Expert Systems with Applications,", "citeRegEx": "27", "shortCiteRegEx": "27", "year": 2010}, {"title": "Circle detection using electromagnetism optimization", "author": ["E. Cuevas", "D. Oliva", "D. Zaldivar", "M. P\u00e9rez-Cisneros", "H. Sossa"], "venue": "Information Sciences", "citeRegEx": "28", "shortCiteRegEx": "28", "year": 2012}, {"title": "Revised electromagnetism-like mechanism for flow path design of unidirectional AGV systems", "author": ["Xianping Guan", "Xianzhong Dai", "Jun Li"], "venue": "International Journal of Production Research", "citeRegEx": "29", "shortCiteRegEx": "29", "year": 2011}, {"title": "Numerical Experiments with a Population Shrinking Strategy within a Electromagnetism-like Algorithm", "author": ["Ana Maria A.C. Rocha", "Edite Fernandes"], "venue": "Journal of Mathematics and Computers in Simulation", "citeRegEx": "30", "shortCiteRegEx": "30", "year": 2007}, {"title": "Numerical study of augmented Lagrangian algorithms for constrained global optimization", "author": ["Ana Maria A.C. Rocha", "Edite Fernandes"], "venue": null, "citeRegEx": "31", "shortCiteRegEx": "31", "year": 2011}, {"title": "A hybrid of electromagnetismlike mechanism and back-propagation algorithms for recurrent neural fuzzy systems design", "author": ["Ching-Hung Lee", "Fu-Kai Chang", "Che-Ting Kuo", "Hao-Hang Chang"], "venue": "International Journal of Systems Science,", "citeRegEx": "32", "shortCiteRegEx": "32", "year": 2012}, {"title": "Opposition-based learning: a new scheme for machine intelligence", "author": ["H.R. Tizhoosh"], "venue": "Proceedings of international conference on computational intelligence for modeling control and automation,", "citeRegEx": "33", "shortCiteRegEx": "33", "year": 2005}, {"title": "A Novel Population Initialization Method for Accelerating Evolutionary Algorithms, Computers and Mathematics with Applications, Volume", "author": ["S.Rahnamayn", "H.R.Tizhoosh", "M.Salama"], "venue": null, "citeRegEx": "34", "shortCiteRegEx": "34", "year": 2007}, {"title": "Opposition versus randomness in soft computing techniques", "author": ["S Rahnamayan", "HR Tizhoosh", "MMA. Salama"], "venue": "Elsevier J Appl. Soft Comput", "citeRegEx": "35", "shortCiteRegEx": "35", "year": 2008}, {"title": "Enhanced opposition-based differential evolution for solving high-dimensional continuous optimization problems", "author": ["Hui Wang", "Zhijian Wu", "Shahryar Rahnamayan"], "venue": "Soft Comput", "citeRegEx": "36", "shortCiteRegEx": "36", "year": 2010}, {"title": "A novel function optimization approach using opposition based genetic algorithm with gene excitation", "author": ["Muhammad Amjad Iqbal", "Naveed Kazim Khan", "Hasan Multaba", "A. Rauf Baig"], "venue": "International Journal of Innovative Computing, Information and Control,", "citeRegEx": "37", "shortCiteRegEx": "37", "year": 2011}, {"title": "Opposition-based differential evolution", "author": ["S Rahnamayan", "HR Tizhoosh", "MMA. Salama"], "venue": "IEEE Trans Evol Comput", "citeRegEx": "38", "shortCiteRegEx": "38", "year": 2008}, {"title": "Enhancing particle swarm optimization using generalized opposition-based learning", "author": ["Hui Wanga", "Zhijian Wua", "Shahryar Rahnamayan", "Yong Liu", "Mario Ventresca"], "venue": "Information Sciences", "citeRegEx": "39", "shortCiteRegEx": "39", "year": 2011}, {"title": "A novel opposition-based gravitational search algorithm for combined economic and emission dispatch problems of power systems", "author": ["Binod Shaw", "V. Mukherjee", "S.P. Ghoshal"], "venue": "Electrical Power and Energy Systems", "citeRegEx": "40", "shortCiteRegEx": "40", "year": 2012}, {"title": "Opposition-based reinforcement learning", "author": ["Tizhoosh HR"], "venue": "J Adv Comput Intell Intell Inform", "citeRegEx": "42", "shortCiteRegEx": "42", "year": 2006}, {"title": "Opposition-based Q(k) algorithm", "author": ["M Shokri", "HR Tizhoosh", "M. Kamel"], "venue": "Proc IEEE world congr comput intell;", "citeRegEx": "43", "shortCiteRegEx": "43", "year": 2006}, {"title": "The global optimization problem: An introduction", "author": ["Dixon", "L.C.W", "G. P Szeg\u00f6"], "venue": "Towards Global Optimization 2,", "citeRegEx": "44", "shortCiteRegEx": "44", "year": 1978}, {"title": "A study on the use of non-parametric tests for analyzing the evolutionary algorithms\u2019 behaviour: a case study on the CEC\u20192005 Special session on real parameter optimization", "author": ["S Garcia", "D Molina", "M Lozano", "F Herrera"], "venue": "J Heurist. doi:10.1007/s10732-008-9080-4", "citeRegEx": "46", "shortCiteRegEx": "46", "year": 2008}, {"title": "Performance Evaluation of Memetic Approaches in 3D Reconstruction of Forensic Objects", "author": ["J. Santamar\u00eda", "O. Cord\u00f3n", "S. Damas", "J.M. Garc\u00eda-Torres", "A. Quirin"], "venue": "Soft Computing,", "citeRegEx": "47", "shortCiteRegEx": "47", "year": 2008}], "referenceMentions": [{"referenceID": 0, "context": "Global Optimization (GO) [1,2] has issued applications for many areas of science [3], engineering [4], economics [5,6] and others whose definition requires mathematical modelling [7,8].", "startOffset": 25, "endOffset": 30}, {"referenceID": 1, "context": "Global Optimization (GO) [1,2] has issued applications for many areas of science [3], engineering [4], economics [5,6] and others whose definition requires mathematical modelling [7,8].", "startOffset": 25, "endOffset": 30}, {"referenceID": 2, "context": "Global Optimization (GO) [1,2] has issued applications for many areas of science [3], engineering [4], economics [5,6] and others whose definition requires mathematical modelling [7,8].", "startOffset": 81, "endOffset": 84}, {"referenceID": 3, "context": "Global Optimization (GO) [1,2] has issued applications for many areas of science [3], engineering [4], economics [5,6] and others whose definition requires mathematical modelling [7,8].", "startOffset": 98, "endOffset": 101}, {"referenceID": 4, "context": "Global Optimization (GO) [1,2] has issued applications for many areas of science [3], engineering [4], economics [5,6] and others whose definition requires mathematical modelling [7,8].", "startOffset": 113, "endOffset": 118}, {"referenceID": 5, "context": "Global Optimization (GO) [1,2] has issued applications for many areas of science [3], engineering [4], economics [5,6] and others whose definition requires mathematical modelling [7,8].", "startOffset": 113, "endOffset": 118}, {"referenceID": 6, "context": "Global Optimization (GO) [1,2] has issued applications for many areas of science [3], engineering [4], economics [5,6] and others whose definition requires mathematical modelling [7,8].", "startOffset": 179, "endOffset": 184}, {"referenceID": 7, "context": "Global Optimization (GO) [1,2] has issued applications for many areas of science [3], engineering [4], economics [5,6] and others whose definition requires mathematical modelling [7,8].", "startOffset": 179, "endOffset": 184}, {"referenceID": 8, "context": "Some other metaheuristic optimization algorithms have been recently proposed to solve optimization problems, such as Genetic Algorithms (GA) [9], Particle Swarm Optimization (PSO) [10], Ant Colony Optimization (ACO) [11], Differential Evolution (DE) [12], Artificial Immune Systems (AIS) [13] and Artificial Bee Colony [14] and Gravitational Search Algorithm (GSA) [15].", "startOffset": 141, "endOffset": 144}, {"referenceID": 9, "context": "Some other metaheuristic optimization algorithms have been recently proposed to solve optimization problems, such as Genetic Algorithms (GA) [9], Particle Swarm Optimization (PSO) [10], Ant Colony Optimization (ACO) [11], Differential Evolution (DE) [12], Artificial Immune Systems (AIS) [13] and Artificial Bee Colony [14] and Gravitational Search Algorithm (GSA) [15].", "startOffset": 216, "endOffset": 220}, {"referenceID": 10, "context": "Some other metaheuristic optimization algorithms have been recently proposed to solve optimization problems, such as Genetic Algorithms (GA) [9], Particle Swarm Optimization (PSO) [10], Ant Colony Optimization (ACO) [11], Differential Evolution (DE) [12], Artificial Immune Systems (AIS) [13] and Artificial Bee Colony [14] and Gravitational Search Algorithm (GSA) [15].", "startOffset": 250, "endOffset": 254}, {"referenceID": 11, "context": "Some other metaheuristic optimization algorithms have been recently proposed to solve optimization problems, such as Genetic Algorithms (GA) [9], Particle Swarm Optimization (PSO) [10], Ant Colony Optimization (ACO) [11], Differential Evolution (DE) [12], Artificial Immune Systems (AIS) [13] and Artificial Bee Colony [14] and Gravitational Search Algorithm (GSA) [15].", "startOffset": 288, "endOffset": 292}, {"referenceID": 12, "context": "Some other metaheuristic optimization algorithms have been recently proposed to solve optimization problems, such as Genetic Algorithms (GA) [9], Particle Swarm Optimization (PSO) [10], Ant Colony Optimization (ACO) [11], Differential Evolution (DE) [12], Artificial Immune Systems (AIS) [13] and Artificial Bee Colony [14] and Gravitational Search Algorithm (GSA) [15].", "startOffset": 319, "endOffset": 323}, {"referenceID": 13, "context": "Some other metaheuristic optimization algorithms have been recently proposed to solve optimization problems, such as Genetic Algorithms (GA) [9], Particle Swarm Optimization (PSO) [10], Ant Colony Optimization (ACO) [11], Differential Evolution (DE) [12], Artificial Immune Systems (AIS) [13] and Artificial Bee Colony [14] and Gravitational Search Algorithm (GSA) [15].", "startOffset": 365, "endOffset": 369}, {"referenceID": 14, "context": "Electromagnetism-like algorithm (EMO) is a relatively new population-based meta-heuristic algorithm which was firstly introduced by Birbil and Fang [16] to solve continuous optimization models using bounded variables.", "startOffset": 148, "endOffset": 152}, {"referenceID": 15, "context": "Although the EMO algorithm shares some characteristics with PSO and ACO, recent works have exhibited its better accuracy regarding optimal parameters [17-20], yet showing convergence [21].", "startOffset": 150, "endOffset": 157}, {"referenceID": 16, "context": "Although the EMO algorithm shares some characteristics with PSO and ACO, recent works have exhibited its better accuracy regarding optimal parameters [17-20], yet showing convergence [21].", "startOffset": 150, "endOffset": 157}, {"referenceID": 17, "context": "Although the EMO algorithm shares some characteristics with PSO and ACO, recent works have exhibited its better accuracy regarding optimal parameters [17-20], yet showing convergence [21].", "startOffset": 150, "endOffset": 157}, {"referenceID": 18, "context": "Although the EMO algorithm shares some characteristics with PSO and ACO, recent works have exhibited its better accuracy regarding optimal parameters [17-20], yet showing convergence [21].", "startOffset": 150, "endOffset": 157}, {"referenceID": 19, "context": "Although the EMO algorithm shares some characteristics with PSO and ACO, recent works have exhibited its better accuracy regarding optimal parameters [17-20], yet showing convergence [21].", "startOffset": 183, "endOffset": 187}, {"referenceID": 20, "context": "EMO has been successfully applied to solve different sorts of engineering problems such as flow-shop scheduling [22], communications [23], vehicle routing [24], array pattern optimization in circuits [25], neural network training [26] control systems [27] and image processing [28].", "startOffset": 112, "endOffset": 116}, {"referenceID": 21, "context": "EMO has been successfully applied to solve different sorts of engineering problems such as flow-shop scheduling [22], communications [23], vehicle routing [24], array pattern optimization in circuits [25], neural network training [26] control systems [27] and image processing [28].", "startOffset": 133, "endOffset": 137}, {"referenceID": 22, "context": "EMO has been successfully applied to solve different sorts of engineering problems such as flow-shop scheduling [22], communications [23], vehicle routing [24], array pattern optimization in circuits [25], neural network training [26] control systems [27] and image processing [28].", "startOffset": 155, "endOffset": 159}, {"referenceID": 23, "context": "EMO has been successfully applied to solve different sorts of engineering problems such as flow-shop scheduling [22], communications [23], vehicle routing [24], array pattern optimization in circuits [25], neural network training [26] control systems [27] and image processing [28].", "startOffset": 200, "endOffset": 204}, {"referenceID": 24, "context": "EMO has been successfully applied to solve different sorts of engineering problems such as flow-shop scheduling [22], communications [23], vehicle routing [24], array pattern optimization in circuits [25], neural network training [26] control systems [27] and image processing [28].", "startOffset": 230, "endOffset": 234}, {"referenceID": 25, "context": "EMO has been successfully applied to solve different sorts of engineering problems such as flow-shop scheduling [22], communications [23], vehicle routing [24], array pattern optimization in circuits [25], neural network training [26] control systems [27] and image processing [28].", "startOffset": 251, "endOffset": 255}, {"referenceID": 26, "context": "EMO has been successfully applied to solve different sorts of engineering problems such as flow-shop scheduling [22], communications [23], vehicle routing [24], array pattern optimization in circuits [25], neural network training [26] control systems [27] and image processing [28].", "startOffset": 277, "endOffset": 281}, {"referenceID": 27, "context": "In [29] where Guan et al.", "startOffset": 3, "endOffset": 7}, {"referenceID": 28, "context": "In [30] and [31], authors include a new local search method which is based on a fixed search pattern and a shrinking strategy that aims to reduce the population size as the iterative process progresses.", "startOffset": 3, "endOffset": 7}, {"referenceID": 29, "context": "In [30] and [31], authors include a new local search method which is based on a fixed search pattern and a shrinking strategy that aims to reduce the population size as the iterative process progresses.", "startOffset": 12, "endOffset": 16}, {"referenceID": 15, "context": "Additionally, in [17], a modified local search phase that employs the gradient descent method is adopted to enhance its computational complexity.", "startOffset": 17, "endOffset": 21}, {"referenceID": 25, "context": "Although all these approaches have improved the computational time which is required by the original EMO algorithm, recent works [27,32] have demonstrated that reducing or simplifying EMO\u2019s local search processes also affects other important properties, such as convergence, exploration, population diversity and accuracy.", "startOffset": 129, "endOffset": 136}, {"referenceID": 30, "context": "Although all these approaches have improved the computational time which is required by the original EMO algorithm, recent works [27,32] have demonstrated that reducing or simplifying EMO\u2019s local search processes also affects other important properties, such as convergence, exploration, population diversity and accuracy.", "startOffset": 129, "endOffset": 136}, {"referenceID": 31, "context": "On the other hand, the opposition-based learning (OBL), that has been initially proposed in [33], is a machine intelligence strategy which considers the current estimate and its correspondent opposite value (i.", "startOffset": 92, "endOffset": 96}, {"referenceID": 32, "context": "It has been mathematically proved [34-36] that an opposite candidate solution holds a higher probability for approaching the global optimum solution than a given random candidate, yet quicker.", "startOffset": 34, "endOffset": 41}, {"referenceID": 33, "context": "It has been mathematically proved [34-36] that an opposite candidate solution holds a higher probability for approaching the global optimum solution than a given random candidate, yet quicker.", "startOffset": 34, "endOffset": 41}, {"referenceID": 34, "context": "It has been mathematically proved [34-36] that an opposite candidate solution holds a higher probability for approaching the global optimum solution than a given random candidate, yet quicker.", "startOffset": 34, "endOffset": 41}, {"referenceID": 35, "context": "Recently, the concept of opposition has been used to accelerate metaheuristic-based algorithms such as GA [37], DE [38], PSO [39] and GSA [40].", "startOffset": 106, "endOffset": 110}, {"referenceID": 36, "context": "Recently, the concept of opposition has been used to accelerate metaheuristic-based algorithms such as GA [37], DE [38], PSO [39] and GSA [40].", "startOffset": 115, "endOffset": 119}, {"referenceID": 37, "context": "Recently, the concept of opposition has been used to accelerate metaheuristic-based algorithms such as GA [37], DE [38], PSO [39] and GSA [40].", "startOffset": 125, "endOffset": 129}, {"referenceID": 38, "context": "Recently, the concept of opposition has been used to accelerate metaheuristic-based algorithms such as GA [37], DE [38], PSO [39] and GSA [40].", "startOffset": 138, "endOffset": 142}, {"referenceID": 6, "context": "Comparisons to the original EMO and others state-of-the-art EMO-based algorithms [7] demonstrate that the OBEMO technique is faster for all test functions, yet delivering a higher accuracy.", "startOffset": 81, "endOffset": 84}, {"referenceID": 9, "context": "Few particles are required to reach converge as has been already demonstrated in [11].", "startOffset": 81, "endOffset": 85}, {"referenceID": 5, "context": "EMO algorithm has four phases [6]: initialization, local search, computation of the total force vector and movement.", "startOffset": 30, "endOffset": 33}, {"referenceID": 15, "context": "Nevertheless, recent works [17,32] have shown that eliminating, reducing or simplifying the local search process affects significantly the convergence, exploration, population diversity and accuracy of the EMO algorithm.", "startOffset": 27, "endOffset": 34}, {"referenceID": 30, "context": "Nevertheless, recent works [17,32] have shown that eliminating, reducing or simplifying the local search process affects significantly the convergence, exploration, population diversity and accuracy of the EMO algorithm.", "startOffset": 27, "endOffset": 34}, {"referenceID": 31, "context": "Opposition-based Learning [33] is a new concept in computational intelligence that has been employed to effectively enhance several soft computing algorithms [42,43].", "startOffset": 26, "endOffset": 30}, {"referenceID": 39, "context": "Opposition-based Learning [33] is a new concept in computational intelligence that has been employed to effectively enhance several soft computing algorithms [42,43].", "startOffset": 158, "endOffset": 165}, {"referenceID": 40, "context": "Opposition-based Learning [33] is a new concept in computational intelligence that has been employed to effectively enhance several soft computing algorithms [42,43].", "startOffset": 158, "endOffset": 165}, {"referenceID": 32, "context": "This is a preprint copy that has been accepted for publication in International Journal of Innovative Computing, Information and Control 9 solution x and its opposite solution x for a given problem, providing a renewed chance to find a candidate solution lying closer to the global optimum [34].", "startOffset": 290, "endOffset": 294}, {"referenceID": 33, "context": "By doing so, the fitter one (guess or opposite guess) can be chosen as an initial solution following the fact that, according to probability theory, 50% of the time a guess is further from the solution than its opposite guess [35].", "startOffset": 226, "endOffset": 230}, {"referenceID": 14, "context": "The original test functions, which are shown in Table 1, agree to the set of numerical benchmark functions presented by the original EMO paper at [16].", "startOffset": 146, "endOffset": 150}, {"referenceID": 41, "context": "More details can be found in [44].", "startOffset": 29, "endOffset": 33}, {"referenceID": 30, "context": "2 exp cos(2 ) 20 n n i i i i f x x n n \u03c0 = = \uf8eb \uf8f6 \uf8eb \uf8f6 = \u2212 \u2212 \u2212 + \uf8ec \uf8f7 \uf8ec \uf8f7 \uf8ec \uf8f7 \uf8ed \uf8f8 \uf8ed \uf8f8 \u2211 \u2211 x 30 [ 32,32] \u2212 0", "startOffset": 92, "endOffset": 100}, {"referenceID": 30, "context": "2 exp cos(2 ) 20 n n i i i i f x x n n \u03c0 = = \uf8eb \uf8f6 \uf8eb \uf8f6 = \u2212 \u2212 \u2212 + \uf8ec \uf8f7 \uf8ec \uf8f7 \uf8ec \uf8f7 \uf8ed \uf8f8 \uf8ed \uf8f8 \u2211 \u2211 x 30 [ 32,32] \u2212 0", "startOffset": 92, "endOffset": 100}, {"referenceID": 14, "context": "The algorithms are listed below: - Standard EMO algorithm [16]; - Hybridizing EMO with descent search (HEMO) [17]; - EMO with fixed search pattern (FEMO) [30]; - The proposed approach OBEMO.", "startOffset": 58, "endOffset": 62}, {"referenceID": 15, "context": "The algorithms are listed below: - Standard EMO algorithm [16]; - Hybridizing EMO with descent search (HEMO) [17]; - EMO with fixed search pattern (FEMO) [30]; - The proposed approach OBEMO.", "startOffset": 109, "endOffset": 113}, {"referenceID": 28, "context": "The algorithms are listed below: - Standard EMO algorithm [16]; - Hybridizing EMO with descent search (HEMO) [17]; - EMO with fixed search pattern (FEMO) [30]; - The proposed approach OBEMO.", "startOffset": 154, "endOffset": 158}, {"referenceID": 14, "context": "For the original EMO algorithm described in [16] and the proposed OBEMO, the parameter set is configured considering: 0.", "startOffset": 44, "endOffset": 48}, {"referenceID": 15, "context": "Such values can be assumed as the best configuration set according to [17].", "startOffset": 70, "endOffset": 74}, {"referenceID": 42, "context": "In order to statistically analyse the results in Table 3, a non-parametric significance proof known as the Wilcoxon\u2019s rank test [45-47] has been conducted.", "startOffset": 128, "endOffset": 135}, {"referenceID": 43, "context": "In order to statistically analyse the results in Table 3, a non-parametric significance proof known as the Wilcoxon\u2019s rank test [45-47] has been conducted.", "startOffset": 128, "endOffset": 135}, {"referenceID": 42, "context": "Results are supported by a statistically significant framework (Wilcoxon test [45-47]) to demonstrate that the OBEMO is as accurate as the standard EMO yet requiring a shorter number of iterations.", "startOffset": 78, "endOffset": 85}, {"referenceID": 43, "context": "Results are supported by a statistically significant framework (Wilcoxon test [45-47]) to demonstrate that the OBEMO is as accurate as the standard EMO yet requiring a shorter number of iterations.", "startOffset": 78, "endOffset": 85}, {"referenceID": 6, "context": "Likewise, it is as fast as others state-of-the-art EMO-based algorithms such as HEMO [7] and FEMO [30], still keeping the original accuracy.", "startOffset": 85, "endOffset": 88}, {"referenceID": 28, "context": "Likewise, it is as fast as others state-of-the-art EMO-based algorithms such as HEMO [7] and FEMO [30], still keeping the original accuracy.", "startOffset": 98, "endOffset": 102}], "year": 2014, "abstractText": "* Erik Cuevas 1 , + Diego Oliva, * Daniel Zaldivar, * Marco P\u00e9rez-Cisneros and + Gonzalo Pajares Departamento de Ciencias Computacionales Universidad de Guadalajara, CUCEI Av. Revoluci\u00f3n 1500, Guadalajara, Jal, M\u00e9xico {erik.cuevas, daniel.zaldivar, marco.perez}@cucei.udg.mx Dpto. Ingenier\u00eda del Software e Inteligencia Artificial, Facultad Inform\u00e1tica, Universidad Complutense, Av. Complutense S/N, 28040, Madrid, Spain doliva@estumail.ucm.es, pajares@fdi.ucm.es", "creator": "PDFCreator Version 1.2.0"}}}