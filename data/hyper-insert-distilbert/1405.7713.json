{"id": "1405.7713", "review": {"conference": "arxiv", "VERSION": "v1", "DATE_OF_SUBMISSION": "16-Jan-2014", "title": "Using Local Alignments for Relation Recognition", "abstract": "this paper discusses the mathematical problem of marrying structural similarity detectors with semantic relatedness for information concerning extraction from composite text. aiming at accurate recognition patterns of relations, consequently we introduce local variable alignment kernels generally and eagerly explore altogether various modeling possibilities of research using them for using this integration task. we give a basic definition of a local cluster alignment ( indeed la ) kernel based precisely on specifically the smith - stuart waterman score estimated as a sequence similarity measure generator and proceed with a range free of possibilities for computing similarity between the elements of sequences. we nonetheless show how regular distributional similarity measures obtained continuously from unlabeled data can now be rapidly incorporated into the blended learning task well as promoting semantic knowledge. our aforementioned experiments suggest further that the right la kernel yields comparatively promising results working on considering various biomedical corpora outperforming two scientific baselines by above a large margin. additional series of experiments have been steadily conducted on the data storing sets of seven sample general relation types, precisely where nonetheless the performance ability of the appropriate la metric kernel is comparable due to the current state - worth of - the - art computing results.", "histories": [["v1", "Thu, 16 Jan 2014 04:51:47 GMT  (727kb)", "http://arxiv.org/abs/1405.7713v1", null]], "reviews": [], "SUBJECTS": "cs.CL cs.IR cs.LG", "authors": ["sophia katrenko", "pieter adriaans", "maarten van someren"], "accepted": false, "id": "1405.7713"}, "pdf": {"name": "1405.7713.pdf", "metadata": {"source": "CRF", "title": "Using Local Alignments for Relation Recognition", "authors": ["Sophia Katrenko", "Pieter Adriaans", "Maarten van Someren"], "emails": ["S.Katrenko@uva.nl", "P.W.Adriaans@uva.nl", "M.W.vanSomeren@uva.nl"], "sections": [{"heading": "1. Introduction", "text": "Despite the fact that much work has been done on automatic relation extraction (or recognition) in the past few decades, it remains a popular research topic. The main reason for the keen interest in relation recognition lies in its utility. Once concepts and semantic relations are identified, they can be used for a variety of applications such as question answering (QA), ontology construction, hypothesis generation and others.\nIn ontology construction, the relation that is studied most is the is-a relation (or hypernymy), which organizes concepts in a taxonomy (Snow, Jurafsky, & Ng, 2006). In information retrieval, semantic relations are used in two ways, to refine queries before actual retrieval, or to manipulate the output that is returned by a search engine (e.g. identifying whether a fragment of text contains a given relation or not). The most widely used relations for query expansion are hypernymy (or broader terms from a thesaurus) and synonymy. Semantic relations can also be useful at different stages of question answering. They have to be taken into account when identifying the type of a question and they have to be considered at actual answer extraction time (van der Plas, 2008). Yet another application of relations is constructing a new scientific hypothesis given the evidence found in text. This type of knowledge discovery from text is often based on co-occurrence analysis and, in many cases, was corroborated via experiments in laboratories (Swanson & Smalheiser, 1999).\nAnother reason why extraction of semantic relations is of interest lies in the diversity of relations. Different relations need different extraction methods. Many existing information extraction systems were originally designed to work for generic data (Grishman & Sundheim, 1996), but it became evident that domain knowledge is often necessary for successful\nc\u00a92010 AI Access Foundation. All rights reserved.\nKatrenko, Adriaans, & van Someren\nextraction. For instance, relation extraction in the biomedical domain would require an accurate recognition of named entities such as gene names (Clegg, 2008), and in the area of food it needs information on relevant named entities such as toxic substances.\nAlso for generic relations syntactic information is often not sufficient. Consider, for instance, the following sentences (with the arguments of the relations written in italics):\n(1) Mary looked back and whispered: \u201cI know every tree in this forest, every scent\u201d. (Part-Whole relation)\n(2) A person infected with a particular flu virus strain develops antibodies against that virus. (Cause-Effect relation)\n(3) The apples are in the basket. (Content-Container relation)\nAll these sentences exemplify binary relations, namely Part-Whole (tree is part of a forest), Cause-Effect (virus causes flu) and Content-Container (apples are contained in basket). We can easily notice that the syntactic context in (1) and (3) is the same, namely, the arguments in both cases are connected to each other by the preposition \u2018in\u2019. However, this context is highly ambiguous because even though it allows us to reduce the number of potential semantic relations, it is still not sufficient to be able to discriminate between Part - Whole and Content - Container relation. In other words, world knowledge about \u2018trees\u2019, \u2018forests\u2019, \u2018apples\u2019 and \u2018baskets\u2019 is necessary to classify relations correctly. The situation changes even more drastically if we consider example (2). Here, there is no explicit indication for causation. Nevertheless, by knowing what \u2018a flu\u2019 and \u2018a virus\u2019 is, we are able to infer that Cause - Effect relation holds.\nThe examples in (1), (2) and (3) highlight several difficulties that characterize semantic relation extraction. Generic relations very often occur in nominal complexes such as \u2018flu virus\u2019 in (2) and lack of sentential context boosts such approaches as paraphrasing (Nakov, 2008). However, even for noun compounds one has to combine world knowledge with the compound\u2019s context to arrive at the correct interpretation.\nComputational approaches to the relation recognition problem often rely on a two-step procedure. First, the relation arguments are identified. Depending on the relation at hand, this step often involves named entity recognition of the arguments of the relations. The second step is to check whether the relation holds. If relation arguments are provided (e.g., \u2018basket\u2019 and \u2018apples\u2019 in (3)), relation extraction is reduced to the second step. Previous work on relation extraction suggests that in this case the accuracy of relation recognition is much higher than in the case when they have to be discovered automatically (Bunescu et al., 2005). Furthermore, most existing solutions to relation extraction (including work presented in this paper) focus on relation examples that occur within a single sentence and do not consider discourse (McDonald, 2005). Recognizing relations from a wider scope is an interesting enterprise, but it would require to take into account anaphora resolution and other types of linguistic analysis.\nApproaches to relation extraction that are based on hand-written patterns are timeconsuming and in many cases need an expert to formulate and test the patterns. Although patterns are often precise, they usually produce poor recall (Thomas et al., 2000). In general, hand-written patterns can be of two types. The first type is sequential and based\nUsing Local Alignments for Relation Recognition\non frequently occurring sequences of words in a sentence. Hand-written sequential patterns were initially used for extraction of Hypernymy (Hearst, 1992), with several attempts to extend them to other relations. The second type of patterns (Khoo, Chan, & Niu, 2000) take the syntactic structure of a sentence into account. The dependency structure of a sentence can usually be represented as a tree and the patterns then become subtrees. Such patterns are sometimes referred to as graphical patterns. To identify examples of the Cause-Effect relation, Khoo et al. (2000) applied this type of patterns to texts in the medical domain. This study showed that graphical patterns are sensitive to the errors made by the parsers, do not cover all examples in the test data and extract many spurious instances.\nAn alternative to using hand-written patterns is supervised Machine Learning. Then, relations are labeled and used to train a classifier that can recognize these relations in new texts. One approach is to learn generalized extraction patterns where patterns are expressed as characters, words or syntactic categories of words. Other approaches involve clustering based on co-occurrence (Davidov & Rappoport, 2008). In recent years kernel-based methods have become popular because they can handle high-dimensional problems (Zelenko et al., 2003; Bunescu & Mooney, 2006; Airola et al., 2008). These methods transform text fragments, complete sentences or segments around named entitites or verbs, to vectors, and apply Support Vector Machines to classify new fragments.\nSome Machine Learning methods use prior knowledge that is given to the system in addition to labeled examples (Scho\u0308lkopf, 1997, p. 17). The use of prior knowledge is often motivated by, for example, poor quality of data and data sparseness. Prior knowledge can be used in many ways, from changing the representation of existing training examples to adding more examples from unlabelled data. For NLP tasks, prior knowledge exists in the form of manually (or automatically) constructed ontologies or large collections of unannotated data. These enrich the textual data and thereby improve the recognition of relations (Sekimizu, Park, & Tsujii, 1998; Tribble & Fahlman, 2007). Recently, Zhang et al. (2008) showed that semantic correlation of words can be learned from unlabelled text collections, transferred among documents and used further to improve document classification. In general, while use of large collections of text allows us to derive almost any information needed, it is done with varying accuracy. In contrast, existing resources created by humans can provide very precise information, but it is less likely that they will cover all possible areas of interest.\nIn this paper, as in the work of Bunescu and Mooney (2006), we use the syntactic structure of sentences, in particular, dependency paths. This stems from the observation that linguistic units are organized in complex structures and understanding how words or word senses relate to each other often requires contextual information. Relation extraction is viewed as a supervised classification problem. A training set consists of examples of a given relation and the goal is to construct a model that can be applied to a new, unseen data set, to recognize all instances of the given relation in this new data set. For recognition of relations we use a kernel-based classifier that is applied to dependency paths. However, instead of a vector-based kernel we directly use similarity between dependency paths and show how information from existing ontologies or large text corpora can be employed.\nThe paper is organized as follows. We start by reviewing existing kernel methods that work on sequences (Section 2). In Section 3, we give the definition of a local alignment kernel based on the Smith-Waterman measure. We proceed by discussing how it can be used in the context of natural language processing (NLP) tasks, and particularly for extracting\nKatrenko, Adriaans, & van Someren\nrelations from text (Section 3.2). Once the method is described, we report on two types of the data sets (biomedical and generic) used in the experiments (Section 4) and elaborate on our experiments (Sections 5 and 6). Section 7 discusses our findings in more detail. Section 8 concludes the paper by discussing possible future directions."}, {"heading": "2. Kernel Methods", "text": "The past years have witnessed a boost of interest in kernel methods, their theoretical analysis and practical applications in various fields (Burges, 1998; Shawe-Taylor & Christianini, 2000). The idea of having a method that works with different structures and representations, starting from the simplest representation using a limited number of attributes to complex structures such as trees, seems indeed very attractive.\nBefore we define a kernel function, recall the standard setting for supervised classification. For a training set S of n objects (instances) (x1, y1), . . . , (xn, yn) where x1, . . . ,xn \u2208 X are input examples in the input space X with their corresponding labels y1, . . . , yn \u2208 {0,1}, the goal is to infer a function h : X \u2192 {0, 1} such that it approximates a target function t. However, h can still err on the data which has to be reflected in a loss function, l(h(xi), yi). Several loss functions have been proposed in the literature so far, the best known of which is the zero-one loss. This loss is a function that outputs 1 each time a method errs on a data point (h(xi) 6= yi), and 0 otherwise.\nThe key idea of kernel methods lies in the implicit mapping of objects to a highdimensional space (by using some mapping function \u03c6) and considering their inner product (similarity) k(xi,xj) =< \u03c6(xi), \u03c6(xj) >, rather than representing them explicitly. Functions that can be used in kernel methods have to be symmetric and positive semi-definite, whereby positive semi-definiteness is defined by \u2211n i=1 \u2211n j=1 cicjk(xi,xj) \u2265 0 for any n > 0, any objects x1, . . . ,xn \u2208 X , and any choice of real numbers c1, . . . , cn \u2208 R. If a function is not positive semi-definite, the algorithm may not find the global optimal solution. If the requirements w.r.t. symmetry and positive semi-definiteness are met, a kernel is called valid.\nUsing the idea of a kernel mapping, Cortes and Vapnik (1995) introduced support vector machines (SVM) as a method which seeks the linear separation between two classes of the input points by a function f(x) such that f(x) = wT\u03c6(x) + b, wT \u2208 Rp, b \u2208 R and h(x) = sign(f(x)). Here, wT stands for the slope of the linear function and b for its offset. Often, there can exist several functions that separate data well, but not all of them are equally good. A hyperplane that separates mapped examples with the largest possible margin would be the best option (Vapnik, 1982).\nSVMs solve the following optimization problem:\nargmin f(x)=wT x+b 1 2 \u2016 w \u20162 +C n\u2211 i=1 l(h(xi), yi) (4)\nIn Equation 4, the first part of the equation corresponds to the margin maximization (by minimizing 12 \u2016 w \u2016\n2), while the second takes into account the error on the training set which has to be minimized (where C is a penalty term). The hyperplane that is found may correspond to a non-linear boundary in the original input space. There exist a number\nUsing Local Alignments for Relation Recognition\nof standard kernels such as the linear kernel, the Gaussian kernel and others. Information about the data or the problem can motivate the choice of a particular kernel. It has been shown by Haussler (1999) that a complex kernel (referred to as a convolution kernel) can be defined using simpler kernels.\nOther forms of machine learning representations for using prior knowledge were defined along with the methods for exploiting it. Inductive logic programming offers one possible solution to use it explicitly, in the form of additional Horn clauses (Camacho, 1994). In the Bayesian learning paradigm information on the hypothesis without seeing any data is encoded in a Bayesian prior (Mitchell, 1997) or in a higher level distribution in a hierarchical Bayesian setting. It is less obvious though how to represent and use prior knowledge in other learning frameworks. In the case of SVMs, there are three possible ways of incorporating prior knowledge (Lauer & Bloch, 2008). These are named sampling methods (prior knowledge is used here to generate new data), kernel methods (prior knowledge is incorporated in the kernel function by, for instance, creating a new kernel), and optimization methods (prior knowledge is used to reformulate the optimization problem by, for example, adding additional constraints). The choice of a kernel can be based on general statistical properties of the domain, but an attractive possibility is to incorporate explicit domain knowledge into the kernel. This can improve a kernel by \u201csmoothing\u201d the space: instances that are more similar have a higher probability of belonging to the same class than with a kernel without prior knowledge.\nIn what follows, we review a number of kernels on strings that have been proposed in the research community over the past years. A very natural domain to look for them is the biomedical field where many problems can be formulated as string classification (protein classification and amino acid sequences, to name a few). Sequence representation is, however, not only applicable to the biomedical area, but can also be considered for many natural language processing tasks. After introducing kernels that have been used in biomedicine, we move to the NLP domain and present recent work on relation extraction employing kernel methods."}, {"heading": "2.1 The Spectrum Kernel", "text": "Leslie, Eskin, and Noble (2002) proposed a discriminative approach to protein classification. For any sequence x \u2208 X , the authors define the m-spectrum as the set S of all contiguous subsequences of x whose length is equal to m. All possible m-long subsequences q \u2208 S are indexed by the frequency of their occurrence (\u03c6q(x)). Consequently, a feature map for a sequence x and alphabet A equals \u03a6m(x) = (\u03c6q(x))q\u2208Am . The spectrum kernel for two sequences x and y is defined as the inner product between the corresponding feature maps: kS(x, y) =< \u03a6m(x),\u03a6m(y) >.\nNow, even assuming contiguous subsequences for small m, the feature space to consider is very large. The authors propose to detect all subsequences of length m by using a suffix tree method which guarantees fast computation of the kernel matrix. The spectrum kernel was tested on the task of protein homology detection, where the best results were achieved by setting m to a relatively small number (3). The novelty of Leslie et al.\u2019s (2002) method lies in its generality and its low computational complexity.\nKatrenko, Adriaans, & van Someren"}, {"heading": "2.2 Mismatch Kernels", "text": "The mismatch kernel that was introduced later by Leslie et al. (2004) is essentially an extension of the latter. An obvious limitation of the spectrum kernel is that all considered subsequences are contiguous and should match exactly. In the mismatch kernel the contiguity is preserved while the match criterion is changed. In other words, instead of looking for all possible subsequences of length m for a given subsequence, one is searching for all possible subsequences of length m allowing up to r mismatches. Such a comparison will result in a larger subset of subsequences, but the kernels defined in this way can still be calculated rather fast. The kernel is formulated similarly to the spectrum kernel and the only major difference is in computing the feature map for all sequences. More precisely, a feature map for a sequence x is defined as \u03a6m,r(x) = \u2211 q\u2208S \u03a6m,r(q) where \u03a6m,r(q) = (\u03c6\u03b2(q))\u03b2\u2208Am . \u03c6\u03b2(q) is binary and indicates whether sequence \u03b2 belongs to the set of m-length sequences that differ from q at most in r elements (1) or it does not (0). It is clear that if r is set to 0, the mismatch kernel is reduced to the spectrum kernel. The complexity of the mismatch kernel computation is linear with respect to the sum of the sequence lengths.\nThe authors also show that the mismatch kernel not only yields state-of-the-art performance on a protein classification task but also outputs subsequences that are informative from a biological point of view."}, {"heading": "2.3 Kernel Methods and NLP", "text": "One of the merits of kernel methods is the possibility of designing kernels for different structures, such as strings or trees. In the NLP field (and in relation extraction, in particular) most work roughly falls into two categories. In the first, kernels are defined over the plain text using sequences of words. The second uses linguistic structures such as dependency paths or trees or the output of shallow parsing. In this short review we do not take a chronological perspective but rather start with the methods that are based on sequences and proceed with the approaches that make use of syntactic information.\nIn the same year in which the spectrum kernel was designed, Lodhi et al. (2002) introduced string subsequence kernels that provide flexible means to work with text data. In particular, subsequences are not necessarily contiguous and are weighted according to their length (using a decay factor \u03bb). The length of the subsequences is fixed in advance. The authors claim that even without the use of any linguistic information their kernels are able to capture semantic information. This is reflected in the better performance on the text classification task compared to the bag-of-words approach. While Lodhi et al.\u2019s (2002) kernel works on sequences of characters, a kernel proposed by Cancedda et al. (2003) is applied to word sequences. String kernels can be also extended to syllable kernels which proved to do well on text categorization (Saunders, Tschach, & Shawe-Taylor, 2002).\nBecause all these kernels can be defined recursively, their computation is efficient. For instance, the time complexity of Lodhi et al.\u2019s (2002) kernel is O(n|s||t|), where n is the length of the subsequence, and t and s are documents."}, {"heading": "2.3.1 Subsequence Kernels", "text": "In the recognition of binary relations, the most natural way is to consider words located around and between relation arguments. This approach was taken by Bunescu and Mooney\nUsing Local Alignments for Relation Recognition\n(2005b) whose choice of sequences was motivated by textual patterns found in corpora. For instance, they observed that some relations are expressed by \u2018subject-verb-object\u2019 constructions while others are part of the noun and prepositional phrases. As a result, three types of sequences were considered: fore-between (words before and between two named entities), between (words only between two entities) and between-after (words between and after two entities). The length of sequences is restricted. To handle data sparseness, the authors generalize over existing sequences using PoS tags, entity types and WordNet synsets. A generalized subsequence kernel is recursively defined as the number of weighted sparse subsequences that two sequences share. In the absence of syntactic information, an assumption is made that long subsequences are not likely to represent positive examples and as such are penalized. This subsequence kernel is computed for all three types of sequences and the resulting relation kernel is defined as a sum over the three subkernels. Experimental results on a biomedical corpus are encouraging, showing that the relation kernel performs better than manually written patterns and an approach based on longest common subsequences.\nA method proposed by Giuliano et al. (2006) was largely inspired by the work of Bunescu and Mooney (2005b). However, instead of looking for subsequences in three types of sequences, the authors treat them as a bag-of-words and define what is called a global kernel as follows. First, each sequence type (pattern) P is represented by a vector whose elements are counts of how many times each token was used in P . A local kernel is defined similarly but only using words surrounding named entities (left and right context). A final shallow linguistic kernel is defined as the combination of the global and the local kernels. Experiments on biomedical corpora suggest that this kernel outperforms the subsequence kernel by Bunescu and Mooney."}, {"heading": "2.3.2 Distributional Kernels", "text": "Recently, O\u0301 Se\u0301aghdha and Copestake (2008) introduced distributional kernels on co- occurrence probability distributions. The co-occurrence statistics they use are in the form of either syntactic relations or n-grams. They show that it is possible to derive kernels from such distances as Jensen-Shannon divergence (JSD) or Euclidean distance (L2) (Lee, 1999). JSD is a smoothed version of the Kullback-Leibler divergence, an information-theoretic measure of the dissimilarity between two probability distributions. The main motivation behind this approach lies in the fact that distributional similarity measures proved to be useful for NLP tasks. To extract co-occurrence information, the authors use two corpora, the British National Corpus (BNC) and the Web 1T 5-Gram Corpus (which contains 5-grams with their observed frequency counts and was collected from the Web). Distributional kernels proved to be successful for a number of tasks such as compound interpretation, relation extraction and verb classification. On all of them, the JSD kernel clearly outperforms Gaussian and linear kernels. Moreover, estimating distributional similarity on the BNC corpus yields performance similar to the results obtained on the Web 1T 5-Gram Corpus. This is an interesting finding because the BNC corpus was used to estimate similarity from syntactic relations whereas the latter corpus contains n-grams only. Most importantly, the method of O\u0301 Se\u0301aghdha and Copestake provides empirical support for the claim that using distributional similarity is beneficial for relation extraction.\nKatrenko, Adriaans, & van Someren"}, {"heading": "2.3.3 Kernels for Syntactic Structures", "text": "Kernels defined for unpreprocessed text data seem attractive because they can be applied directly to text from any language. However, as general as they are, they can lose precision when compared to the methods that use syntactic analysis. Re-ranking parsing trees (Collins & Duffy, 2001) was one of the first applications of kernel methods to NLP problems. To accomplish this goal, the authors rely on the subtrees that a pair of trees have in common. Later on, Moschitti (2006) explored convolution kernels on dependency and constituency structures to do semantic role labeling and question classification. This work introduces a novel kernel which is called a partial tree kernel (PT). It is essentially built on two kernels proposed before, the subtree kernel (ST) that contains all descendant nodes from a target root (including leaves) and the subset tree kernel (SST) that is more flexible and allows internal subtrees which do not necessarily encompass leaves. A partial tree is a generalization of a subset tree whereby partial structures of a grammar are allowed (i.e., parts of the production rules such as [VP [V]] form a valid PT). Moschitti demonstrated that PTs obtain better performance on dependency structures than SSTs, but the latter yield better results on constituent trees."}, {"heading": "2.3.4 Kernel on Shallow Parsing Output", "text": "Zelenko et al. (2003) use shallow parsing and designed kernels to extract relations from text. In contrast to full parsing, shallow parsing produces partial interpretations of sentences. Each node in such a tree is enriched with information on roles (that correspond to the arguments of a relation). The similarity of two trees is determined by the similarity of their nodes. Depending on how similarity is computed, Zelenko et al. define two types of kernels, contiguous subtree kernels and sparse kernels. Both types were tested on two types of relations, \u2018person-affiliation\u2019 and \u2018organization-location\u2019 exhibiting good performance. In particular, sparse kernels outperform contiguous subtree kernels leading to the conclusion that partial matching is important when dealing with typically sparse natural language data. However, the computation of the sparse kernel takes O(mn3) time (where m and n are the number of children of two relation examples, i.e. shallow trees, under consideration, m \u2265 n), while the algorithm for the contiguous subtree kernel runs in time O(mn)."}, {"heading": "2.3.5 Shortest Path Kernel", "text": "Bunescu and Mooney\u2019s (2005a) shortest path kernel represents yet another approach for relation extraction that is kernel-based and relies on information found in dependency trees. A main assumption here is that not the entire dependency structure is relevant, and one can focus on the path that is connecting two relation arguments instead. The more similar these paths are, the more likely two relation examples belong to the same category. In spirit with their previous work, Bunescu and Mooney seek generalizations over existing paths by adding information sources like part of speech (PoS) categories or named entity types.\nThe shortest path between relation arguments is extracted and a kernel between two sequences (paths) x = {x1, . . . , xn} and x\u2032 = {x\u20321, . . . , x\u2032m} is computed as follows:\nUsing Local Alignments for Relation Recognition\nkB(x,x\u2032) = {\n0 m 6= n\u220fn i=1 f(xi, x \u2032 i) m = n\n(5)\nIn Equation 5, f(xi, x\u2032i) is the number of features shared by xi and x \u2032 i. Bunescu and Mooney (2005a) use several features such as word (e.g., protesters), part of speech tag (e.g., NNS), generalized part of speech tag (e.g., Noun), and entity type (e.g., PERSON) if applicable. In addition, a direction feature (\u2192 or \u2190) is employed. Here we reproduce an example from their paper.\nExample 1 Given two dependency paths that exemplify the relation Located such as \u2018his \u2192 actions \u2190 in \u2190 Brcko\u2019 and \u2018his \u2192 arrival \u2190 in \u2190 Beijing\u2019, both paths are expanded by additional features as those mentioned above. It is easy to see that comparing path (6) to path (7) gives us a score of 18 (3\u00d71\u00d71\u00d71\u00d72\u00d71\u00d73 = 18).\n hisPRP PERSON \u00d7 [\u2192]\u00d7  actionsNNS Noun \u00d7 [\u2190]\u00d7 [ in IN ] \u00d7 [\u2190]\u00d7  Brcko NNP Noun LOCATION  (6)\n hisPRP PERSON \u00d7 [\u2192]\u00d7  arrivalNN Noun \u00d7 [\u2190]\u00d7 [ in IN ] \u00d7 [\u2190]\u00d7  Beijing NNP Noun LOCATION  (7) The time complexity of the shortest path kernel is O(n), where n stands for the length\nof the dependency path.\nDependency paths are also considered in other recent work on relation recognition (Erkan, O\u0308zgu\u0308r, & Radev, 2007). Here, Erkan et al. (2007) use dependency paths as input and compare them by means of cosine similarity or edit distance. The authors motivate their choice by the need to compare dependency paths of different length. Further, various machine learning methods are used to do classification, including SVM and transuctive SVM (TSVM), which is an extension of SVM (Joachims, 1999). In particular, TSVM makes use of labeled and unlabeled data by first classifying the unlabeled examples and then searching for the maximum margin that separates positive and negative instances from both sets. The authors conclude that edit distance performs better than the cosine similarity measure, and that TSVM slightly outperforms SVM.\nAirola et al. (2008) propose a graph kernel which makes use of the entire dependency structure. In their work, each sentence is represented by two subgraphs, one of which is built from the dependency analysis, and the other corresponds to the linear structure of the sentence. Further, a kernel is defined on all paths between any two vertices in the graph. The method by Airola et al. (2008) achieves state-of-the-art performance on biomedical data sets, and is further discussed, together with the shortest path kernel and the work\nKatrenko, Adriaans, & van Someren\nby Erkan et al. (2007), in Section 5 on relation extraction in the biomedical domain in this paper.\nFinally, kernels can be defined not only on graphs of syntactic structures, but also on graphs of a semantic network. This is illustrated by O\u0301 Se\u0301aghdha (2009), who uses graph kernels on the graph built from the hyponymy relations in WordNet. Even though no syntactic information is utilized, such kernels proved to perform well on the extraction of various generic relations.\nAll kernels that we reviewed in this section deal with sequences or trees albeit in different ways. The empirical findings suggest that kernels that allow partial matching usually perform better when compared to methods where similarity is defined on an exact match. To alleviate the problem of exact matching, some researchers suggested generalizing over elements in existing structures (Bunescu & Mooney, 2005a) while others opted for a flexible comparison. In our view, these types of methods can complement each other (Saunders et al., 2002). As flexible as the partial matching methods are, they may suffer from low precision when the penalization of the mismatch is low. The same holds for approaches that use generalization strategies because they may easily overgeneralize. A possible solution would be to combine both, provided that mismatches are penalized well and generalizations are semantically plausible rather than based on part of speech categories. This idea is further explored in the present paper and evaluated on the relation recognition task.\nIn a nutshell, the goals of this paper are the following: (i) a study of the possibilities of using the local alignment kernel for relation extraction from text, (ii) an exploration of the use of prior knowledge in the alignment kernel and (iii) an extensive evaluation with automatic recognition of two types of relations, biomedical and generic."}, {"heading": "3. A Local Alignment Kernel", "text": "One can note from our short overview of the kernels designed for NLP above that many researchers use partial structures and propose variants such as subsequence kernels (Bunescu & Mooney, 2005b), a partial tree kernel (Moschitti, 2006), or a kernel on shallow parsing output (Zelenko et al., 2003) for relation extraction. In this paper we focus on dependency paths as input and formulate the following requirements for a kernel function:\n\u2022 it should allow partial matching so that the similarity can be measured for paths of different length\n\u2022 it should be possible to incorporate prior knowledge\nRecall that by prior knowledge we mean information that comes either from larger corpora or from existing resources such as ontologies. For instance, knowing that \u2018development\u2019 is synonymous to \u2018evolution\u2019 in some contexts can help to recognize that two different words are close semantically. Such information is especially useful if the meaning is relevant for detecting relations that may differ in form.\nIn the following subsection we will define a local alignment kernel that satisfies these requirements and show how to incorporate prior knowledge.\nUsing Local Alignments for Relation Recognition"}, {"heading": "3.1 Smith-Waterman Measure and Local Alignments", "text": "Our work here is motivated by the recent advances in the biomedical field. It has been shown that it is possible to design valid kernels based on a similarity measure for strings (Saigo, Vert, & Akutsu, 2006). For example, Saigo, Vert, Ueda, and Akutsu (2004) consider the Smith-Waterman (SW) similarity measure (Smith & Waterman, 1981) (see below) to measure the similarity between two sequences of amino acids.\nString distance measures can be divided into measures based on terms, edit-distance and Hidden Markov models (HMM) (Cohen, Ravikumar, & Fienberg, 2003). Term-based distances such as measures based on the TF-IDF score, consider a pair of word sequences as two sets of words ignoring their order. In contrast, string edit distances (or string similarity measures) treat entire sequences and compare them using transformation operations, which convert a sequence x into a sequence x\u2032. Examples of these are the Levenshtein distance, and the Needleman-Wunsch (Needleman & Wunsch, 1970) and Smith-Waterman (Smith & Waterman, 1981) measures. The Levenshtein distance has been used in the natural language processing field as a component in a variety of tasks, including semantic role labeling (Sang et al., 2005), construction of paraphrase corpora (Dolan, Quirk, & Brockett, 2004), evaluation of machine translation output (Leusch, Ueffing, & Ney, 2003), and others. The Smith-Waterman measure is mostly used in the biological domain, there are, however, some applications of a modified Smith-Waterman measure to text data as well (Monge & Elkan, 1996; Cohen et al., 2003). HMM-based measures present probabilistic extensions of edit distances (Smith, Yeganova, & Wilbur, 2003).\nOur hypothesis is that string similarity measures are the best basis for a kernel for relation extraction. In this case, the order in which words appear is likely to be relevant and sparse data usually prevents estimation of probabilities (as in the work of Smith et al., 2003). In general, two sequences can be aligned in several possible ways. It is possible to search either for an alignment which spans entire sequences (global alignment), or for an alignment which is based on similar subsequences (local alignment). Both in the case of sequences of amino acids and in relation extraction, local patterns are likely to be the most important factor that determines similarity. Therefore we need a similarity measure that emphasizes local alignments.\nFormally, we define a pairwise alignment \u03c0 of at most L elements for two sequences x = x1x2 . . . xn and x\u2032 = x\u20321x \u2032 2 . . . x \u2032 m, as a pairing \u03c0 = {\u03c0l(i, j)}, l = 1, . . . , L, 1 \u2264 i \u2264 n, 1 \u2264 j \u2264 m, 1 \u2264 l \u2264 n, 1 \u2264 l \u2264 m. In Example 2 (ii), the third element of the first sequence is aligned with the first element of the second one, which is denoted by \u03c01(3, 1).\nExample 2 Given the sequences x=abacde and x\u2032=ace, two possible alignments (with gaps indicated by \u2018-\u2019) are as follows.\n(i) global alignment\na b a c d e a - - c - e\nAlignment: \u03c0 = {\u03c01(1, 1), \u03c02(4, 2), \u03c03(6, 3)}\n(ii) local alignment\na b a c d e - - a c - e\nAlignment: \u03c0 = {\u03c01(3, 1), \u03c02(4, 2), \u03c03(6, 3)}\nKatrenko, Adriaans, & van Someren\nIn this example, the number of gaps inserted in x\u2032 to align it with x and the number of elements that match is the same in both cases. Yet, both in the biological and in the linguistic context we may prefer alignment (ii), because closely matching substrings, local alignments, are a better indicator for similarity than shared items that are far apart. It is, therefore, better to use a measure that puts less or no weight on gaps before the start or after the end of strings (as in Example 2 (ii)). This can be done using a local alignment mechanism that searches for the most similar subsequences in two sequences. Local alignments are employed when sequences are dissimilar and are of different length, while global alignments are considered when sequences are of roughly the same length. From the measures we have mentioned above, the Smith-Waterman measure is a local alignment measure, and the Needleman-Wunsch measure compares two sequences based on global alignments.\nDefinition 1 (Global alignment) Given two sequences x = x1 . . . xn and x\u2032 = x\u20321 . . . x \u2032 m, their global alignment is a pair of sequences y and y\u2032 both of the same length, which are obtained by inserting zero or more gaps before the first element of either x or x\u2032, and after each element of x and of x\u2032.\nDefinition 2 (Local alignment) Given two sequences x = x1 . . . xn and x\u2032 = x\u20321 . . . x \u2032 m, their local alignment is a pair of subsequences \u03b1 of x and \u03b3 of x\u2032, whose similarity is maximal.\nTo clarify what we mean by local and global alignments, we give a definition of both the Smith-Waterman and Needleman-Wunsch measures. Given two sequences x = x1x2 . . . xn and x\u2032 = x\u20321x \u2032 2 . . . x \u2032 m of length n andm respectively, the Smith-Waterman measure is defined as a similarity score of their best local alignment:\nsw(x,x\u2032) = max \u03c0\u2208A(x,x\u2032) s(x,x\u2032, \u03c0) (8)\nIn the equation above, s(x,x\u2032, \u03c0) is a score of a local alignment \u03c0 of sequence x and x\u2032 and A denotes the set of all possible alignments. The best local alignment can be efficiently found using dynamic programming. To do this, one fills in a matrix SW with partial alignments as follows:\nSW 1\u2264i\u2264n, 1\u2264j\u2264m (i, j) = max  0 SW(i\u2212 1, j \u2212 1) + d(xi, x\u2032j) SW(i\u2212 1, j)\u2212G SW(i, j \u2212 1)\u2212G\n(9)\nIn Equation 9, d(xi, x\u2032j) denotes a substitution score between two elements xi and x \u2032 j and G stands for a gap penalty. Using this equation it is possible to find partial alignments, that are stored in a matrix in which the cell (i, j) reflects the score for alignment between x1 . . . xi\nUsing Local Alignments for Relation Recognition\nand x\u20321 . . . x \u2032 j . The cell with the largest value in the matrix contains the Smith-Waterman score. The Needleman-Wunsch measure, which searches for global alignments, is defined similarly, except for the fact that the cells in a matrix can contain negative scores:\nNW 1\u2264i\u2264n, 1\u2264j\u2264m (i, j) = max  NW(i\u2212 1, j \u2212 1) + d(xi, x\u2032j) NW(i\u2212 1, j)\u2212G NW(i, j \u2212 1)\u2212G\n(10)\nThe Smith-Waterman measure can be seen as a modification of the Needleman-Wunsch method. By disallowing negative scores in a matrix, the regions of high dissimilarity are avoided and, as a result, local alignments are preferred. Moreover, while the NeedlemanWunsch score equals the largest value in the last column or last row, the Smith-Waterman similarity score corresponds to the largest value in the matrix.\nLet us reconsider Example 2 and show how the global and local alignments for alignments for two sequences x=abacde and x\u2032=ace are obtained. To arrive at actual alignments, one has to set the gap parameter G and the substitution scores. Assume we use the following settings: a gap G = 1, substitution score d(xi, x\u2032j) = 2 for xi = x \u2032 j , and d(xi, x \u2032 j) = \u22121 for xi 6= x\u2032j . These values have been chosen for illustrative purpose only, but in a realistic case, e.g., alignment of protein sequences, the choice of the substitution scores is usually motivated by biological evidence. For gapping, Smith and Waterman (1981) suggested to use a gap value which is at least equal to the difference between a match (d(xi, x\u2032j), xi = x\u2032j) and a mismatch (d(xi, x \u2032 j), xi 6= x\u2032j). Then, the Smith-Waterman and NeedlemanWunsch similarity scores between x and x\u2032 can be calculated according to Equation 9 and Equation 10 as given in Table 1.\nFirst, the first row and the first column in the matrix are initialized to 0. Then, the matrix is filled in by computing the maximum score for each cell as defined in Equation 9 and Equation 10. The score of the best local alignment is equal to the largest element in\nKatrenko, Adriaans, & van Someren\nthe matrix (5), and the Needleman-Wunsch score is 3. Note that it is possible to trace back which steps are taken to arrive at the final alignment (the cells in boldface). A left-right step corresponds to an insertion, a top-down step to a deletion (these lead to gaps), and a diagonal step implies an alignment of two sequences\u2019 elements.\nSince we prefer to use local alignments on dependency paths, a natural choice would be to use the Smith-Waterman measure as a kernel function. However, Saigo et al. (2004) observed that the Smith-Waterman measure may not result in a valid kernel because it may not be positive semi-definite. They give a definition of the LA kernel, which states that two sequences are similar if they have many local alignments with high scores, as in Equation 11.\nkL(x,x\u2032) = \u2211\n\u03c0\u2208A(x,x\u2032)\ne\u03b2\u00b7s(x,x \u2032,\u03c0) (11)\nHere, s(x,x\u2032, \u03c0) is a local alignment score and \u03b2(\u2265 0) is a scaling parameter. To define the LA kernel kL (as in Equation 11) for two sequences x and x\u2032, it is needed to take into account all transformation operations that are used in local alignments. First, one has to define a kernel on elements that corresponds to individual alignments, ka. Second, since this type of alignment allows gaps, there should be another kernel for gapping, kg. Last but not least, recall that by local alignments only parts of the sequences may be aligned, and some elements of x and x\u2032 may be left out. These elements do not influence the alignment score and a kernel used in these cases, k0, can be set to a constant, k0(x,x\u2032) = 1. Finally, the LA kernel is a composition of several kernels (k0, ka, and kg), which is in the spirit of convolution kernels (Haussler, 1999).\nAccording to Saigo et al. (2004), similarity of the aligned sequences\u2019 elements (ka kernel) is defined as follows:\nka(x,x\u2032) = {\n0 if |x| 6= 1 or |x\u2032| 6= 1 e\u03b2\u00b7d(x,x \u2032) otherwise (12)\nIf either x, or x\u2032 has more than one element, this kernel would result in 0. Otherwise, it is calculated using the substitution score d(x,x\u2032) of x and x\u2032. This score reflects how similar two sequences\u2019 elements are and, depending on the domain, can be computed using prior knowledge from the given domain.\nThe \u2018gapping\u2019 kernel is defined similarly to the alignment kernel in Equation 12, whereby the scaling parameter \u03b2 is preserved, but the gap penalties are used instead of a similarity function between two elements:\nkg(x,x\u2032) = e\u03b2(g(|x|)+g(|x \u2032|)) (13)\nHere, g stands for the gap function. Naturally, for a gap of length 0 this function returns zero. For gaps of length n, it is reasonable to define a gap in terms of a gap opening o and a gap extension e, g(n) = o+ e \u2217 (n\u2212 1). In this case it is possible to decide whether longer gaps should be penalized more than the shorter ones, and how much. For instance, if there\nUsing Local Alignments for Relation Recognition\nare three consecutive gaps in the alignment, the first gap is counted as a gap opening, and the other two as a gap extension. If in consecutive gaps (i.e., gaps of length n > 1) each gap is of equal importance, the gap opening has to be equal to the gap extension. If, however, the length of gaps does not matter, one would prefer to penalize the gap opening more, and to give a little weight to the gap extension.\nAll these kernels can be combined as follows:\nk(r)(x,x \u2032) = k0 \u2217 (ka \u2217 kg)r\u22121 \u2217 ka \u2217 k0 (14)\nIn Equation 14, k(r)(x,x\u2032) stands for an alignment of r elements in x and x\u2032 with possibly r\u2212 1 gaps. Similarity of the aligned elements is calculated by ka, and gapping by kg. Since there could be up to r \u2212 1 gaps, this corresponds to the following part of the equation: (ka \u2217kg)r\u22121. Further, because there is the rth aligned element, one more ka is added. Given the discussion above, k0 is added to the initial and final part. As follows from Equation 14, if there are no elements in x and x\u2032 aligned, k(r) equals k0, which is 1. If all elements of x and x\u2032 are aligned with no gaps, the value of k(r) is (ka)r.\nFinally, the LA kernel is equal to the sum taken over all possible local alignments for sequences x and x\u2032:\nkL(x,x\u2032) = \u221e\u2211 i=0 k(i)(x,x \u2032) (15)\nThe results in the biological domain suggest that kernels based on the Smith-Waterman distance are more relevant for the comparison of amino acids than string kernels (Saigo et al., 2006). It is not clear whether this holds when applied to natural language processing tasks. In our view, it could depend on the parameters which are used, such as the substitution matrix and the penalty gaps."}, {"heading": "3.1.1 Computational complexity", "text": "The LA kernel, as many other kernels discussed in Section 2, can be efficiently calculated using dynamic programming. For any two sequences x and x\u2032, of length n and m respectively, its complexity is proportional to n \u00d7 m. Additional costs may come from the substitution matrix, which, unlike in the biomedical domain, can become very large. However, the look-up of the substitution scores can be done in an efficient manner as well, which leads to fast kernel computation. For instance, calculating a kernel matrix for the largest data set used in this paper, AImed (3,763 instances), takes 805 seconds on a 2.93 GHz Intel(R) Core(TM)2 machine."}, {"heading": "3.2 Designing a Local Alignment Kernel for Relation Extraction", "text": "The Smith-Waterman measure is based on transformations, in particular deletions of elements that are different between strings. However, elements that are different may still be similar to some degree. These similarities can be used as part of the similarity measure. For example, if two elements are words that are different but that are synonyms, then we count them as less different than when they are completely unrelated. We will call these\nKatrenko, Adriaans, & van Someren\nsimilarities \u201csubstitution scores\u201d (Equation 12) and define them in two different ways: on the basis of distributional similarity and on the basis of semantic relatedness in an ontology. For Example 1 we would like to be able to infer that \u2018Brcko\u2019 is similar to \u2018Beijing\u2019, even though these two words do not match exactly. Furthermore, if we have phrases \u201chis arrival in Beijing\u201d and \u201chis arrival in January\u201d, then we would like our kernel to say that \u2018Brcko\u2019 is more similar to \u2018Beijing\u2019 than to \u2018January\u2019. The use of such information as prior knowledge makes it possible to measure similarity between two words, one in the test set and the other in the training set, even if they do not match exactly. Below we review two types of measures that are based on statistical distributions and on relatedness in WordNet."}, {"heading": "3.2.1 Distributional Similarity Measures", "text": "There are a number of distributional similarity measures proposed over the years, including Cosine, Dice and Jaccard coefficients. Distributional similarity measures have been extensively studied before (Lee, 1999; Weeds, Weir, & McCarthy, 2004). The main hypothesis behind distributional measures is that words occurring in the same context should have similar meaning (Firth, 1957). Context can be defined either using proximity in text, or employing grammatical relations. In this paper, we use the first option where context is a sequence of words in text and its length is set in advance.\nWe have chosen the following measures: Dice, Cosine and L2 (Euclidean) whose definitions are given in Table 2. In the definition of Cosine and L2, it is possible to use either frequency counts or probability estimates derived from unsmoothed relative frequencies. Here, we adopt the definitions given by Lee (1999), which are based on probability estimates P . Recall that x and x\u2032 are two sequences we would wish to compare, with their corresponding elements xi and x\u2032j . Further, c stands for a context. In the definition of the Dice coefficient, F (xi) = {c : P (c|xi) > 0}. We are mainly interested in symmetric measures (d(xi, x\u2032j) = d(x \u2032 j , xi)) because a symmetric positive semi-definite matrix is required by kernel methods. The Euclidean measure as defined in Table 2 does not necessarily vary from 0 to 1. For this reason, given a list of pairs of words (xi, x\u2032j) where xi is fixed and j = 1, . . . , s with their corresponding L2 score, the maximum value maxj d(xi, x\u2032j) is detected and used to normalize all scores on the list. Furthermore, unlike Dice and Cosine, which return 1 in the case two words are equal, the Euclidean score equals 0. In the next step, we substract the obtained normalized value from 1 to ascertain that all scores are within an interval [0, 1]\nUsing Local Alignments for Relation Recognition\nand the largest value (1) is assigned to identical words. In our view, this procedure will make a comparison of the selected distributional similarity measures with respect to their influence on the LA kernel more transparent.\nDistributional similarity measures are very suitable if no other information is available. In the case that data is annotated by means of some taxonomy (e.g., WordNet), it is possible to consider measures defined over this taxonomy. Availability of hand-crafted resources, such as WordNet, that comprise various relations between concepts, enables making distinctions between different concepts in a subtle way."}, {"heading": "3.2.2 WordNet Relatedness Measures", "text": "For generic relations, the most commonly used resource is WordNet (Fellbaum, 1998), which is a lexical database for English. In WordNet, words are grouped together in synsets where a synset \u201cconsists of a list of synonymous words or collocations (e.g., \u2018fountain pen\u2019), and pointers that describe the relations between this synset and other synsets\u201d (Fellbaum, 1998). WordNet can be employed for different purposes such as studying semantic constraints for certain relation types (Girju, Badulescu, & Moldovan, 2006; Katrenko & Adriaans, 2008), or enriching the training set (Giuliano et al., 2007; Nulty, 2007).\nTo compare two concepts given their synsets c1 and c2 we use five different measures that have been proposed in the past years. Most of them rely on the notions of the length of the shortest path between two concepts c1 and c2, len(c1, c2), the depth of a node in the WordNet hierarchy (which is equal to the length of the path from the root to the given synset ci), dep(ci), and a least common subsumer (or lowest super-ordinate) between c1 and c2, lcs(c1, c2), which in turn is a synset. To the measures that are exclusively based on these notions belong conceptual similarity proposed by Palmer and Wu (1995) (simwup in Equation 16) and the formula of scaled semantic similarity introduced by Leacock and Chodorow (1998) (simlch in Equation 17). 1 The major difference between them lies in the fact that simlch does not consider the least common subsumer of c1 and c2 but uses the maximum depth of the WordNet hierarchy instead. Conceptual similarity ignores this and focuses on the subhierarchy that includes both synsets.\nsimwup(c1, c2) = 2 \u2217 dep(lcs(c1, c2))\nlen(c1, lcs(c1, c2)) + len(c2, lcs(c1, c2)) + 2 \u2217 dep(lcs(c1, c2)) (16)\nsimlch(c1, c2) = \u2212 log len(c1, c2)\n2 \u2217maxc\u2208WordNet dep(c) (17)\nAiming at combining information from several sources, Resnik (1995) introduced yet another measure that is grounded in information content (simres in Equation 18). Intuitively, if two synsets c1 and c2 are located deeper in the hierarchy and the path from one synset to another is short, they should be similar. If the path between two synsets is long and their least common subsumer is placed relatively close to the root, this indicates that the synsets\n1. In all equations of similarity measures defined over WordNet, subscripts refer to the similarity measure itself (e.g., lch, wup in simlch and in simwup, respectively)\nKatrenko, Adriaans, & van Someren\nc1 and c2 do not have much in common. To quantify this intuition, it is necessary to derive a probability estimate for lcs(c1, c2) which can be done by employing existing corpora. More precisely, p(lcs(c1, c2)) stands for the probability of encountering an instance of a concept lcs(c1, c2).\nsimres(c1, c2) = \u2212 log p(lcs(c1, c2)) (18)\nOne of the biggest shortcomings of Resnik\u2019s method is the fact that only the least common subsumer appears in Equation 18. One can easily imagine a full-blown hierarchy where the relatedness of the concepts subsumed by the same lcs(ci, cj) can heavily vary. In other words, by using lcs only, one is not able to make subtle distinctions between two pairs of concepts that share the least common subsumer. To overcome this, Jiang and Conrath (1997) proposed a solution that takes into account information about the synsets being compared (simjcn in Equation 19). By comparing Equation 19 against Equation 18, we will notice that now the equation incorporates not only the probability of encountering lcs(c1, c2), but also the probability estimates for c1 and c2.\nsimjcn(c1, c2) = 2 log p(lcs(c1, c2))\u2212 (log p(c1) + log p(c2)) (19)\nLin (1998) defined the similarity between two concepts using how much commonality and differences between them are involved. Similarly to the two previous approaches, he uses information theoretic notions and derives the similarity measure simlin given in Equation 20.\nsimlin(c1, c2) = 2 \u2217 log p(lcs(c1, c2)) log p(c1) + log p(c2)\n(20)\nIn the past, semantic relatedness measures were evaluated on different NLP tasks (Budanitsky & Hirst, 2006; Ponzetto & Strube, 2007) and it can be concluded that no measure performs the best for all problems. In our evaluation, we use semantic relatedness for the validation of generic relations and study in depth how they contribute to the final results."}, {"heading": "3.2.3 Substitution Matrix for Relation Extraction", "text": "Until now, we have discussed two possible ways of calculating the substitution score d(\u00b7, \u00b7), by using either distributional similarity measures, or measures defined on WordNet. However, dependency paths which are generated by parsers may contain not only words (or lemmata), but also syntactic functions such as subjects, objects, modifiers, and others. To take this into account, we revise the definition of d(\u00b7, \u00b7). We assume sequences x = x1x2 . . . xn and x\u2032 = x\u20321x \u2032 2 . . . x \u2032 m to contain words (xi \u2208W where W refers to a set of words) and syntactic functions accompanied by direction (xi /\u2208 W ). The elements of W are unique words (or lemmata) which are found in the dependency paths, for instance, for the paths \u2018his \u2192 actions \u2190 in \u2190 Brcko\u2019 and \u2018his \u2192 arrival \u2190 in \u2190 Beijing\u2019 in Example (1) in Section 2.3.5, W= {his, actions, in, Brcko, arrival, Beijing}. The dependency paths we use in the present work include information on syntactic functions, for instance \u2018awareness\nprep from\u2190 come nsubj\u2192 joy\u2019. In this case, W= {awareness, come, joy} and W\u0304 = {prep from\u2190 , nsubj\u2192 }.\nUsing Local Alignments for Relation Recognition\nThen,\nd\u2032(xi, x\u2032j) =  d(xi, x\u2032j) xi, x \u2032 j \u2208W 1 xi, x\u2032j /\u2208W & xi = x\u2032j 0 xi, x\u2032j /\u2208W & xi 6= x\u2032j 0 xi \u2208W & x\u2032j /\u2208W 0 xi /\u2208W & x\u2032j \u2208W\n(21)\nEquation (21) states that whenever the element xi of the sequence x is compared against the element x\u2032j of the sequence x\n\u2032, their substitution score is equal either to (i) the similarity score in the case both elements are words (lemmata), or to (ii) 1, if both elements are the same syntactic function, or to (iii) 0, in any other case.\nAs follows from our discussion on similarity measures above, there are two ways to define d(xi, x\u2032j), using either distributional similarity between xi and x \u2032 j (Section 3.2.1), or their WordNet similarity, provided that they are annotated with WordNet synsets (Section 3.2.2)."}, {"heading": "4. Experimental Set-up", "text": "In this section, we describe the data sets that we have used in the experiments and provide information on the data collections used for estimating distributional similarity."}, {"heading": "4.1 Data", "text": "To evaluate the performance of the LA kernel, we consider two types of text data, domainspecific data, which comes from the biomedical domain and generic or domain-independent data which represents a variety of well-known and widely used relations such as PartWhole and Cause-Effect.\nLike other work, we extract a dependency path between two nodes corresponding to the arguments of a binary relation. We also assume that each analysis results in a tree and since it is an acyclic graph, there exists a unique path between each pair of nodes. We do not consider, however, other structures that might be derived from the full syntactic analysis as in, for example, subtrees (Moschitti, 2006)."}, {"heading": "4.1.1 Biomedical Relations", "text": "Corpora We use three corpora that come from the biomedical field and contain annotations of either interacting proteins - BC-PPI2 (1,000 sentences), AImed (Bunescu & Mooney, 2005b) or the interactions among proteins and genes LLL (77 sentences in the training set and 87 in the test set, Ne\u0301dellec, 2005). The BC-PPI corpus was created by sampling sentences from the BioCreAtive challenge, the AImed corpus was sampled from the Medline collection. The LLL corpus was composed by querying Medline with the term Bacillus subtilis. The difference among all three corpora lies in the directionality of interactions. As Table 3 shows, relations in the AImed corpus are strictly symmetric, in LLL they are asymmetric and BC-PPI contains both types. The differences in the number of training instances for the AImed corpus can be explained by the fact that they correspond to the dependency\n2. Available from http://www2.informatik.hu-berlin.de/~hakenber/.\nKatrenko, Adriaans, & van Someren\npaths between named entities. If parsing fails or produces several disconnected graphs per sentence, no dependency path is extracted.\nThe goal of relation extraction in all three cases is to output all correct interactions between biomedical entities (genes and proteins) that can be found in the input data. The biomedical entities are already provided, so there is no need for named entity recognition.\nThere is a discrepancy between the training and the test sets used for the LLL challenge. Unlike the training set, where each sentence has an example of at least one interaction, the test set contains sentences with no interaction. The organizers of the LLL challenge distinguish between sentences with and without coreferences. Sentences with coreferences are usually appositions, as shown in one of the examples below. The first sentence in (4.1.1) is an example of a sentence without coreferences (with interaction between \u2018ykuD\u2019 and \u2018SigK\u2019), whereas the second one is a sentence with coreference (with interaction between \u2018spoIVA\u2019 and \u2018sigmaE\u2019). More precisely, \u2018spoIVA\u2019 refers to the phrase \u2018one or more genes\u2019 which are known to interact with \u2018sigmaE\u2019. We can therefore infer that \u2018spoIVA\u2019 interacts with \u2018sigmaE\u2019. Sentences without coreferences form a subset, which we refer to as LLL-nocoref, and sentences with coreferences are part of the separate subset LLL-coref.\n(22) ykuD was transcribed by SigK RNA polymerase from T4 of sporulation.\n(23) Finally, we show that proper localization of SpoIVA required the expression of one or more genes which, like spoIVA, are under the control of the mother cell transcription factor sigmaE.\nIt is assumed here that relations in the sentences with coreferences are harder to recognize. To show how the LA kernel performs on both subsets, we report the experimental results on the full set of test data (LLL-all), and on its subsets (LLL-coref and LLL-nocoref).\nSyntactic analysis We analyzed the BC-PPI corpus with the Stanford parser. The LLL corpus has already been preprocessed by the LinkParser and its output was checked by experts. To enable comparison with the previous work, we used the AImed corpus parsed\nUsing Local Alignments for Relation Recognition\nby the Stanford parser 3 and by the Enju parser 4 (which exactly correspond to the input in the experiments by Erkan et al., 2007 and S\u00e6tre et al., 2008). Unlike the Stanford parser, Enju is based on a Head-driven Phrase Structure Grammar (HPSG). The output of the Enju parser can be presented in two ways, either as predicate argument structure or as a phrase structure tree. Predicate argument structures describe relations between words in a sentence, while phrase structure presents a sentence structure in the form of clauses and phrases. In addition, Enju was trained on the GENIA corpus and includes a model for parsing biomedical texts.\n(24) Cbf3 contains three proteins, Cbf3a, Cbf3b and Cbf3c.\nFigure 1 shows a dependency tree obtained by the Stanford parser for the sentence in (24). This sentence mentions three interactions among proteins, more precisely, between \u2018Cbf3\u2019 and \u2018Cbf3a\u2019, \u2018Cbf3\u2019 and \u2018Cbf3b\u2019, and \u2018Cbf3\u2019 and \u2018Cbf3c\u2019. All three dependency paths contain words (lemmata) and syntactic functions (such as subj for a subject) plus the direction of traversing the tree. Figure 2 presents the output for the same sentence provided by the Enju parser. The upper part refers to the phrase structure tree and the lower part shows the paths extracted from the predicate argument structure. The two parsers clearly differ in their output. First, the Stanford parser conveniently generates the same paths for all three interaction pairs while the Enju analyzer does not. Second, the output of the Stanford parser excludes prepositions or conjunctions that are attached to the syntactic functions whereas the Enju analyzer lists them in the parsing results. Such differences\n3. Available from http://nlp.stanford.edu/software/lex-parser.shtml. 4. Available from http://www-tsujii.is.s.u-tokyo.ac.jp/enju/.\nKatrenko, Adriaans, & van Someren\nlead to different input sequences that are later fed into the LA kernel. Consequently, the variations in input may translate into differences in the final performance.\nIn addition, in most work employing AImed, the dependency paths such as these in Figure 1 and Figure 2 are preprocessed in the following way. The actual named entities that are the arguments of the relation are replaced by a label, e.g. PROTEIN. Consequently, the first path in Figure 1 becomes \u2018PROTEIN\nnsubj\u2192 contains dobj\u2190 proteins conj and\u2190 PROTEIN\u2019. To be able to compare our results on AImed with the performance reported in the work of Erkan et al. (2007) and S\u00e6tre et al. (2008), we use exactly the same dependency paths with argument labels. However, to study whether using labels instead of actual named entities has an impact on the final results for the LLL data set, we carry out two experiments. In the first one, the dependency paths contain named entities, whereas in the second they contain labels. The second experiment is referred to by adding a word \u2018LABEL\u2019 to its name (as LLL-all-LABEL in Table 7)."}, {"heading": "4.1.2 Generic Relations", "text": "The second type of relations that we consider are generic relations. Their arguments are sometimes annotated using external resources such as WordNet, which makes it possible to use semantic relatedness measures defined over them. An example of such an approach is\nUsing Local Alignments for Relation Recognition\ndata used for the SemEval-2007 challenge, \u201cTask 04: Classification of Semantic Relations between Nominals\u201d (Girju et al., 2009).\nThe goal of Task 4 was to classify seven semantic relations (Cause - Effect, Instrument - Agency, Product - Producer, Origin - Entity, Theme - Tool, Part - Whole and Content - Container), whose examples were collected from the Web using some predefined queries. In other words, given a set of examples and a relation, the expected output would be a binary classification of whether an example belongs to the given relation or not. The arguments of the relation were annotated by synsets from the WordNet hierarchy, as in Figure 3. Given this sentence and a pair (spiritual awareness, joy) with the corresponding synsets joy%1:12:00 and awareness%1:09:00, this would mean that a classifier has to decide whether this pair is an example of the Cause-Effect relation. This particular sentence was retrieved by quering the Web with the phrase \u201cjoy comes from *\u201d. The synsets were manually selected from the WordNet hierarchy. There are seven semantic relations used in this challenge, which gives seven binary classification problems.\nSyntactic analysis To generate dependency paths, all seven data sets used in SemEval - 2007, Task 4, were analyzed by the Stanford parser. The dependency path for the sentence in Figure 3 is given in (25).\nKatrenko, Adriaans, & van Someren\n(25) awareness#n#1 prep from\u2190 come nsubj\u2192 joy#n#1\nHere, words annotated with WordNet have their PoS tag attached, followed by the sense. For instance, \u2018awareness\u2019 is a noun and in the current context its first sense is used, which corresponds to \u2018awareness#n#1\u2019."}, {"heading": "4.2 Substitution Matrix", "text": "To build a substitution matrix for the LA kernel, we use either distributional similarity or WordNet semantic relatedness measures. For a data set of dependency paths, which contains t unique elements (words and syntactic functions), the size of the matrix is t \u00d7 t. If k elements out of t are words, the number of substitution scores to be computed by distributional similarity (or semantic relatedness) measures equals k(k + 1)/2. This is due to the fact that the measures we use are symmetric. The substitution matrix is built for each corpus we used in the experiments, which results in three substitution matrices for the biomedical domain (for BC-PPI, LLL, and AImed) and seven substitution matrices for generic relations. In what follows, we discuss the settings which were used for calculating the substitution matrix in more detail.\nDistributional similarity can be estimated either by using contextual information (O\u0301 Se\u0301aghdha & Copestake, 2008), or by exploring grammatical relations between words (Lee, 1999). In this work we opt for contextual information. This is motivated by the presence of words belonging to different parts of speech in the dependency paths. For instance, even though, according to dependency grammar theory (Mel\u2019c\u030cuk, 1988), adjectives do not govern other words, they may still occur in the dependency paths. In other words, even if parsing does not fail, it may produce unreliable syntactic structures. To be able to compare words of any part of speech, we have decided to estimate distributional similarity based on contextual information, rather than on grammatical relations.\nWhile computing distributional similarity, it may happen that a given word xi does not occur in the corpus. To handle such cases, we always set d(xi, xi) = 1 (the largest possible similarity score), and d(xi, x\u2032j) = 0 when xi 6= x\u2032j (the lowest possible similarity score)."}, {"heading": "4.2.1 Biomedical domain", "text": "To estimate distributional similarity for the biomedical domain, we use the TREC 2006 Genomics collection (Hersch, Cohen, Roberts, & Rakapalli, 2006) which contains 162,259 documents from 49 journals. All documents have been preprocessed by removing HTMLtags, citations in the text and reference sections and stemmed by the Porter stemmer (van Rijsbergen, Robertson, & Porter, 1980). Furthermore, the query-likelihood approach with Dirichlet smoothing (Chen & Goodman, 1996) is used to retrieve document passages given a query. All passages are ranked according to their likelihood of generating the query. Dirichlet smoothing is used to avoid zero probabilities and poor probability estimates (which may happen when words do not occur in the documents). All k unique words occurring in the set of dependency paths sequences are fed as queries to collect a corpus for estimating similarity. Immediate context surrounding each pair of words is used to calculate the distributional similarity of these words. We set the context window to \u00b12 (2 tokens to the right and 2\nUsing Local Alignments for Relation Recognition\ntokens to the left of a word in focus) and do not perform any kind of further preprocessing such as PoS tagging."}, {"heading": "4.2.2 Generic relations", "text": "For generic relations, we use all WordNet relatedness measures described in Section 3.2.2. We have already shown that the WordNet relatedness measures work only on synsets, which assumes that all words have to be manually annotated with information from WordNet. Since this is done only for the relations\u2019 arguments (see the example in Figure 3), and for no other words in sentences (and, correspondingly, in the dependency paths), we build a substitution matrix as follows. For any two words annotated with WordNet, their substitution score equals a value returned by a relatedness measure being used. For any other word pair, it equals 1 whenever the words are identical, and 0 otherwise. 5 For example, if we consider the words in the dependency path in (25) and the Wu-Palmer (wup) relatedness measure, the substitution scores that we obtain are as follows:\nIn the dependency path (25), there are 5 unique elements (t), 2 of which are annotated with WordNet synsets (k). Consequently, there are 5*6/2 = 15 substitution scores in total, 3 of which are computed using WordNet relatedness.\nTo compute WordNet relatedness, we use the WordNet::Similarity package for WordNet 3.0 (Pedersen, Patwardhan, & Michelizzi, 2004)."}, {"heading": "4.3 Baselines and Kernel Settings", "text": "In this section, we discuss two baselines and kernel settings."}, {"heading": "4.3.1 Baselines", "text": "To test how well local alignment kernels perform compared to kernels proposed in the past, we implemented the shortest path kernel described in the work of Bunescu and Mooney\n5. This also applies to the cases when the relation arguments could not have been annotated with WordNet information.\nKatrenko, Adriaans, & van Someren\n(2005a) (Section 2.3.5) as one of the baselines (Baseline I). This method seems to be the most natural choice because it operates on the same data structures (dependency paths). Similarly to Bunescu and Mooney\u2019s (2005a) work, in our experiments we use lemma, part of speech tag and direction, but we do not consider entity type or negative polarity of items.\nThe choice of the LA kernel in this paper was motivated not only by its ability to compare sequences in a flexible way, but also because of the possibility to explore additional information (not present in the training set) via a substitution matrix. The other baseline, Baseline II, is used to test whether the choice of similarity measures affects the results. In this case, the substitution scores d(\u00b7, \u00b7) are not calculated using distributional similarity or WordNet relatedness, but generated randomly within the interval [0, 1]."}, {"heading": "4.3.2 Kernel settings", "text": "The kernels we compute are used together with the support vector machine tool LibSVM (Chang & Lin, 2001) to detect hyperplanes separating positive examples from negative ones. Before plugging all kernel matrices for 10-fold cross-validation into LibSVM, they are normalized as in Equation 26.\nk(x \u2032 , y \u2032 ) = k(x, y)\u221a k(x, x)k(y, y)\n(26)\nTo handle imbalanced data sets (most notably AImed and BC-PPI), the examples are weighted using inverse-class probability (i.e. all training examples of class A are weighted 1/prob(A) where prob(A) is the fraction of training examples with class A). All significance tests were done using a two-tailed paired t-test with confidence level 95% (\u03b1 = 0.05).\nIn addition, in all experiments we tuned the penalty parameter C (Equation 4) in the range (2\u22126, 2\u22124, . . . , 212).\nTo use the LA kernel, one has to set the following parameters: the gap opening cost, the gap extension cost, and the scaling parameter \u03b2. In our cross-validation experiments, the gap opening cost is set to 1.2, the extension cost to 0.2 and the scaling parameter \u03b2 to 1. The choice of the scaling value was motivated by the experiments on amino acids in the biological domain (Saigo et al., 2004). After initial experiments, we present here a further study where the parameter values are varied."}, {"heading": "5. Experiment I: Domain-Specific Relations", "text": "The goal of this evaluation is to study the behavior of the LA kernel on domain-specific relations in the biomedical domain. In this section, we report on the experiments conducted on three biomedical corpora using the LA kernel based on the distributional similarity measures, two baselines and results published previously (e.g., using the graph kernel by Airola et al., 2008 or the tree kernel by S\u00e6tre et al., 2008). To the best of our knowledge, string kernels have not been applied to dependency paths yet. However, a gap-weighted string kernel (described in Section 2) also allows gapping and can be thus compared to the LA kernel. To test how Lodhi et al.\u2019s (2002) kernel performs on dependency paths, we use it\nUsing Local Alignments for Relation Recognition\non all three corpora. We have not tuned parameters of this string kernel and set the length of subsequences to 4 and the decay factor \u03bb to 0.5. 6\n5.1 LLL and BC-PPI Data Sets\nThis subsection presents results on two biomedical data sets, BC-PPI and LLL. Whenever possible, we also discuss the performance previously reported in the literature.\nThe 10-fold cross-validation results on the BC-PPI corpus are presented in Table 5 and on the LLL training data set in Table 6. The LA kernel based on the distributional similarity measures (LA-Dice, LA-Cosine and LA-L2) performs significantly better than the two baselines. Recall that Baseline I corresponds to the shortest path approach (Section 2.3.5) and Baseline II is the LA kernel with the randomly generated substitution scores. In contrast to Baseline I, it is able to handle sequences of different lengths including gaps. According to Equation 5, a comparison of any two sequences of different lengths results in the 0-score. Nevertheless, it still yields high recall, while precision is much lower. This can be explained by the fact that the shortest path uses PoS tags. Even though two sequences of the same length can be very different, their comparison may still result in a non-zero score, provided that their part of speech tags match. Furthermore, Baseline II suggests that accurate estimation of substitution scores is important for achieving good performance. Baseline II may yield better results than Baseline I, but randomly generated substitution scores degrade the performance.\nAt first glance, the choice of the distributional similarity measures does not affect the overall performance yielded by the LA kernel. On the BC-PPI data, the method based on the L2 measure outperforms the methods based on Dice (p\u2264.07) and on Cosine, but the differences in the latter case are not significant. No statistically significant differences were observed between the method based on Dice and Cosine.\nIn contrast to the BC-PPI data set, the kernels which use Dice and Cosine measures on the LLL data set significantly outperform the one based on L2 (at p\u22641.22\u00d710\u22127 and p\u22641.33\u00d710\u22126, respectively).\nOn both data sets, the LA method using distributional similarity measures significantly outperforms the baselines. Interestingly, the gap-weighted string kernel by Lodhi et al. (2002) yields good performance too and seems to be a better choice than the subsequence\n6. Lodhi et al. (2002) have mentioned in their paper that \u201cthe F1 numbers (with respect to SSK) seem to peak at a subsequence length between 4 and 7\u201d.\nKatrenko, Adriaans, & van Someren\nkernel based on shallow linguistic information (Giuliano et al., 2006). Recent work on LLL (Fundel, Kueffner, & Zimmer, 2007) employs dependency information but, in contrast to our method, it serves as the representation on which extraction rules are defined. Airola et al. (2008) apply a graph kernel-based approach to extract interactions and use, among others, the LLL and AImed data sets. As can be seen in Table 6, their method yields results which are comparable to the gap-weighted string kernel on the dependency paths. To the best of our knowledge, the performance achieved by the LA kernel on the LLL training set is the highest (in terms of the F-score) among the results which have been reported in the literature.\nWe also apply our method to the LLL test data (Table 7). 7 Even though the performance on the test set is poorer, LA-Dice outperforms both baselines. In addition, the gap-weighted string kernel (Lodhi et al., 2002) seems to perform much worse on the test set. For the LA kernel, precision is high, while recall decreases (and most drastically for the data subset which includes co-references). This might be due to the fact that for some sentences only incomplete parses are generated and, consequently, no dependency paths between the entities are found. For 91 out of 567 possible interaction pairs generated on the test data, there is no dependency path extracted. In contrast, the approach reported by Giuliano et al. (2006) does not make use of syntactic information, and on the data subset without coreferences achieves higher recall.\nOn the other hand, lower recall can also be caused by using actual names of proteins and genes as arguments. In the work reported before, the relation arguments and other named entities are often replaced by their types (e.g., PROTEIN) and these are used as input for the learning algorithm. We conducted additional experiments using named entity types in the dependency paths, which led to a great improvement in terms of recall and F-score (Table 7, LLL-coref-LABEL, LLL-nocoref-LABEL, LLL-coref-LABEL). Our method clearly outperforms the shallow linguistic kernel and also achieves better results than the best-performing system in the LLL competition (Sbest), which, according to Ne\u0301dellec (2005), applied Markov logic to the syntactic paths.\n7. Airola et al. (2008) do not report on the performance on the LLL data set and, for this reason, information on the graph all-paths kernel is not included in Table 7.\n5.2 AImed Data Set\nYet another data set that we consider is AImed. This data set has often been used for experiments on relation extraction in the biomedical domain, which enables comparison with other methods. It should be noted, however, that in this particular case, a corpus is a collection of documents (abstracts). This may lead to two ways of performing 10-fold cross-validation. One possibility lies in randomly splitting data in 10 parts, while the other is to do cross-validation on the level of documents. The experiments we report here are done using the first setting and can be directly compared against the methods described in the work of S\u00e6tre et al. (2008), Erkan et al. (2007) and Giuliano et al. (2006). In addition, we use the same dependency paths for the LA kernel as the ones employed by S\u00e6tre et al. and Erkan et al.. The results by Airola et al. (2008) and by Bunescu (2007) are obtained by cross-validating on the level of documents.\nWe conducted experiments by setting the distributional measure to Dice, referred to as LA-Dice in Table 8. In the upper part of the table we used dependency paths generated by the Stanford parser and in the lower part those obtained by Enju. As we discussed in Section 2, Erkan et al. (2007) use similarity measures to compare dependency paths, but they do not consider any additional sources whose information can be incorporated into the learning procedure. They, however, experiment with supervised (SVM) and semi-supervised learning (TSVM), where the number of training instances is varied. Table 8 shows the best performance that was achieved by Erkan et al.\u2019s (2007) method. Among models based on SVM, the one with Cosine distance, SVM-Cos, yields the best results. In the TSVM setting, the one with the Edit measure performs the best. We observe that LA-Dice slightly outperforms both and has, in particular, high precision.\nIn their work, S\u00e6tre et al. (2008) explore several parsers and combinations of features. The features include not only paths from Enju, but also word dependencies generated by data-driven KSDEP parser, and word features. KSDEP parser is based on a probabilistic\nKatrenko, Adriaans, & van Someren\nshift-reduce algorithm (Sagae & Tsujii, 2007). In general, the method by S\u00e6tre et al. also uses SVM, but in this case it focuses on tree kernels (discussed in Section 2.3.3). To make a fair comparison, we conducted experiments on the paths obtained by deep syntactic analysis (Enju parser) and compared our scores against S\u00e6tre et al.\u2019s (2008) results. In contrast to the previous experiments, we achieve higher recall but lower precision. Overall, the LA kernel yields better performance than the one reported by S\u00e6tre et al. However, when different sets of features are combined (parses from Enju and KSDEP plus word features - \u2018Enju+KSDEP+W\u2019 in Table 8), the overall performance can be improved.\nBunescu (2007) reports the evaluation results on the AImed corpus in the form of a precision-recall curve. If we consider the highest precision that was obtained in our experiments (69.09 or 71.16, depending on the input), this roughly corresponds to a recall of 35% in his plot (referred to as Baseline I in Table 8). In sum, the shortest path approach never approaches performance of the LA kernel on any of the biomedical data sets that were studied here. The other baseline, Baseline II, achieves the lowest scores from all the methods presented here.\nTable 8 illustrates that not only various methods have been trained on the AImed corpus, but also many different parsers have been used. It should be noted that the graph kernel has been trained and tested on the syntactic representation generated by the Charniak-Lease parser, and the shortest path kernel has explored dependency paths obtained from the Collins parser. The Charniak-Lease parser is a statistical parser trained on the biomedical data (Lease & Charniak, 2005), whose phrase structures can be transformed into dependencies. Likewise, the Collins parser is a statistical parser (Collins, 1999). This leads to the question whether the choice of syntactic parser has a significant impact on the extraction results. To compare the impact of the syntactic parsers on relation extraction for AImed, Miyao et al. (2008) have conducted a complex study with eight parsers (including the Stanford analyzer) and five parse representations 8. They consider two cases. In the first one, parsers have not been trained on biomedical data. Regardless of the parser being used in their experiments, accuracy for the extraction task is similar. In the second experiment,\n8. These are either various dependency tree formats (e. g., in the Stanford dependency format), or phrase structures, or predicate-arguments structures.\nUsing Local Alignments for Relation Recognition\nparsers have been re-trained on domain-specific data. In this case, it has been shown that the relation extraction results can be improved. The actual gain, however, can vary from one parser to another.\nFor the AImed data, the LA kernel with the Dice measure gives state-of-the-art results. It is outperformed only by approaches that use more information than just dependency paths."}, {"heading": "5.3 LA Kernel Parameters", "text": "Saigo et al. (2004) have already shown that the scaling parameter \u03b2 (Equation 11) has a significant impact on accuracy. We have also carried out additional experiments by varying gap values and the value of \u03b2. Results are visualized in Figure 5. The opening and extension gap values are separated by the slash symbol and the values on the X-axis in the form \u2018a/b\u2019 should be read as \u201cthe opening gap is set to a and the extension gap is equal to b\u201d. The kernel matrices were normalized and all examples were weighted. According to our previous experiments, the results yielded by the Dice measure do not significantly differ from the ones achieved by the Cosine measure and we selected the Dice measure to conduct all experiments. The performance on the BC-PPI data set is shown in Figure 5.\nKatrenko, Adriaans, & van Someren\nUsing Local Alignments for Relation Recognition\nThe results in Figure 5 indicate that decreasing \u03b2 leads to a decrease in overall performance. Moreover, varying gap values causes subtle changes in the F-score, but these changes are not as drastic as changes due to the lower \u03b2.\nChanges in the F-score are more likely to be explained by variances in precision and recall. To investigate this matter, we look at how both measures depend on parameter changes. If \u03b2 is set to a low value, one can expect that this will nearly diminish the impact of the substitution matrix, i.e. similarity among elements. For this reason we hypothesize that larger values of the scaling parameter \u03b2 should result in higher recall. Indeed, Figure 7 supports this hypothesis and the recall plot resembles the one for the F-score. Varying parameter values has a much lower impact on precision (Figure 6) but nonetheless precision does decrease as the \u03b2 parameter becomes larger.\nOverall, \u03b2 seems to influence the final results the most, although gap values make a contribution as well. According to the results we obtained, setting an extension gap e to a large value (or equal to the opening gap o) is undesirable. Since the scaling parameter \u03b2 is applied not only to the substitution matrix but to the gap values as well, setting \u03b2 below 0.5 decreases the effects of gap penalization and similarity of elements. Consequently, the best performance is achieved by setting \u03b2 to 1. This suggests that the final performance of the LA kernel is influenced by a combination of parameters and their choice is crucial for obtaining good performance."}, {"heading": "6. Experiment II: Generic Relations", "text": "Another series of experiments was carried out on seven generic relations from the SemEval - 2007 challenge, Task 4. The choice of the data sets in this case was motivated by two factors. First, semantic relations used here differ from the relations from the biomedical domain. Second, since the arguments of relations are annotated with WordNet, it becomes possible to explore information from WordNet and use it as prior knowledge for the LA kernel.\nMany participants of this challenge considered WordNet either explicitly (Tribble & Fahlman, 2007; Kim & Baldwin, 2007), or as a part of a complex system (Giuliano et al., 2007). Since it is not always obvious how to use WordNet so that it yields the best performance, many researchers have made additional decisions such as use of supersenses (Hendrickx et al., 2007), selection of a predefined number of high-level concepts (Nulty, 2007), or cutting the WordNet hierarchy at a certain level (Bedmar et al., 2007). Some other systems such as the one by Nakov (2007) were based solely on information collected from the Web. Even though it became evident that the best performing systems used WordNet, the variance in the results is remarkable and it is not clear whether this difference in performance can be explained by the machine learning methods being used, the combination of features, or by some other factors.\nThe SemEval-2007 Task-4 data set includes some relation examples which are nominal compounds (like \u2018coffee maker\u2019), and this greatly reduces availability of information between two arguments in the dependency paths. The relation arguments in this case are linked by one grammatical relation (e.g., \u2018coffee\u2019 and \u2018maker\u2019 are linked by the grammatical relation \u2018nn\u2019, which corresponds to \u2018noun compound\u2019). We assume, therefore, information coming from WordNet to be especially helpful when the dependency paths are that short. In all our\nKatrenko, Adriaans, & van Someren\nexperiments we used 5 relatedness measures defined earlier in Section 3.2 plus one additional measure which is called \u2018random\u2019. The random measure indicates that the relatedness values between any two relation arguments were generated randomly (within [0, 1]) and is thus very suitable as a baseline (Baseline II). Similarly to the experiments in the biomedical domain, another baseline is the shortest path kernel (Baseline I). Note that in the Task 4 overview paper, Girju et al. (2007) reported on three baselines, which, in their case, were (i) guessing \u2018true\u2019 or \u2018false\u2019 for all examples, depending on which class is the majority class in the test set (Baseline III), (ii) always guessing \u2018true\u2019 (Baseline IV), and (iii) guessing \u2018true\u2019 or \u2018false\u2019 with the probability that corresponds to the class distribution in the test set (Baseline V).\nThe first question of interest is what implications the choice of semantic relatedness measure has for the performance of the LA kernel. To answer this question, we perform 10-fold cross-validation on the training set (Figure 9, Figure 10 and Figure 11). Among all 5 measures only jcn and resnik fail to perform better than the random score. In most cases, the Resnik score is outperformed by other measures. The behaviour of the LeacockChodorow score (lch) and jcn varies from one semantic relation to another. For instance, use of jcn seems to boost precision for Cause-Effect, Part-Whole, Product - Producer, and Theme - Tool. For the remaining three relations it is clearly not the best-performing measure.\nTo check whether there are differences between relatedness measures, we have carried out significance tests comparing all measures for all relations. Our findings are summarized in Table 9. Here, the symbol \u223c between two relatedness measures stands for the measure equivalence, or, in other words, indicates that there is no significant difference. Similarly to the experiments in the biomedical field, all significance tests were conducted using a two-tailed paired t-test with confidence level 95%. In addition, for any two measures a and b, a > b means that a performs significantly better than b. For instance, the ranking for Cause - Effect in Table 9 should be read as follows. The two best performing measures are wup and lch, which significantly outperform lin, followed by random and res, which, in turn, yield significantly better results than jcn. It can be seen from this table that wup and lch are clearly the best performing measures for all seven relations (each of them is the best measure for six out of seven relations).\nUsing Local Alignments for Relation Recognition\nFor each relation, we applied the best performing measure on the training set for this particular relation to the test data. The results are reported in Table 10. On average, the LA kernel employing the WordNet relatedness measures significantly outperforms two baselines. Moreover, when compared to the best results of the SemEval-2007 competition (Beamer et al., 2007), our method approaches performance yielded by the best system (bestSV ). This system used not only various lexical, syntactic, and semantic feature sets, but also expanded the training set by adding examples from many different sources. We have already mentioned in Section 2 that the recent work by O\u0301 Se\u0301aghdha (2009) explores WordNet structure and graph kernels to classify semantic relations. The overall performance which is achieved by this method (Table 10) is comparable to the one by the LA kernel, but it is unclear whether there are any semantic relations for which one of the approaches performs better.\nIn addition, we report results on the SemEval Task 4 test set per relatedness measure (Table 11), which are averages over all seven relations. Similarly to our findings on the training set, wup and lch are the best performing measures on test data as well.\nOne would expect that the optimal use of prior knowledge should allow us to reduce the number of training instances without significant changes in performance. To study how (and whether) the amount of training data influences the results on the test set, we split the training set in several subsets, creating a model for each subset and applying it to the SemEval-2007, Task 4 test data. The split corresponds to the split used by the challenge organizers. As Figure 8 9 suggests, most relations are recognized well even when a relatively small data sample is used. The exception is the Theme-Tool relation where increasing the\n9. The model trained on only 35 Origin-Entity examples classifies none of the test examples as positive, for this reason there is no point in Figure 8 for this relation given 35 training examples.\nKatrenko, Adriaans, & van Someren\ntraining data clearly helps. This finding is in line with the results of Giuliano et al. (2007) whose system was a combination of kernels on the same data. Their results also indicate that all relations but one (Theme-Tool) are extracted well, even if only a quarter of the training set is used.\nSome other recent work on the SemEval Task 4 data set includes investigation of distributional kernels (O\u0301 Se\u0301aghdha & Copestake, 2008), pattern clusters (Davidov & Rappoport, 2008), relational similarity (Nakov & Hearst, 2008), and WordNet kernels. Unlike WordNet kernels, the first three approaches do not use WordNet. O\u0301 Se\u0301aghdha and Copestake (2008) report an accuracy of 70.7 and the F-score of 67.5 as the best results yielded by distributional kernels and the best performance of Davidov and Rappoport\u2019s (2008) method is an accuracy of 70.1, and the F-score of 70.6. WordNet kernels, similarly to our findings with the LA kernel, yield better accuracy than methods not using WordNet (74.1), but the\nUsing Local Alignments for Relation Recognition\nKatrenko, Adriaans, & van Someren\nUsing Local Alignments for Relation Recognition\nF-score is comparable to the performance reported by O\u0301 Se\u0301aghdha and Copestake (2008) and by Davidov and Rappoport (2008)."}, {"heading": "7. Discussion", "text": "In this section we revisit the goals that were stated at the end of Section 2 and discuss our findings in more detail."}, {"heading": "7.1 The LA Kernel for Relation Extraction", "text": "We have introduced the LA kernel, which has proven to be effective for biomedical problems, in the NLP domain and showed that it is well suited for relation extraction. In particular, the experiments in two different domains either outperform existing methods or yield performance on par with existing state-of-the-art kernels.\nOne of the motivations for using the LA kernel in the relation extraction task is to exploit prior knowledge. Here, we explore two possibilities, distributional similarity and information provided by WordNet."}, {"heading": "7.1.1 Distributional Similarity Measures", "text": "In our setting, we consider three distributional measures that have already been studied before. For instance, Lee (1999) uses them to detect similar nouns based on verb-object co-occurrence pairs. The results suggest the Jaccard coefficient (which is related to the Dice measure) to be one of the best performing measures followed by some others including Cosine. Euclidean distance fell into the group with the largest error rates. Given previous work by Lee (1999), one would expect Euclidean distance to achieve worse results than\nKatrenko, Adriaans, & van Someren\nthe other two measures. Indeed, on the LLL corpus, the LA kernel employing L2 shows a significant decrease in performance. As to the other measures, the method using Dice significantly outperforms the one based on the L2 measure only on the LLL corpus while there is no significant improvement on the BC-PPI data set. Based on the experiments we have conducted, we conclude that the LA kernel using Dice and Cosine measures performs similarly on the LLL data set and the BC-PPI corpus. Given the results on various biomedical corpora (and different settings we have experimented with), we obtained experimental support for choosing the Dice or Cosine measure over the Euclidean distance."}, {"heading": "7.1.2 WordNet Similarity Measures", "text": "For generic relations, semantic relatedness plays a significant role. The difference in the F-score between models that use semantic relatedness and the kernel where the relatedness values are generated randomly (Baseline II) amounts to nearly 20%. All measures exhibit different performance on the seven generic relations that we have considered. We can observe, for instance, that wup, lch, and lin almost always yield the best results, no matter what relation is considered. We found the Resnik score and Jiang and Conrath\u2019s measure to yield lower results than other measures. Even though the F-scores per relation vary quite substantially (by placing Cause-Effect, Theme-Tool, Origin-Entity among the most difficult relations to extract), two measures, wup and lch, are the top-performing measures for all seven relations. These two measures explore the WordNet taxonomy using a length of the paths between two concepts, or their depth in the WordNet hierarchy and, consequently, belong to the path-based measures. The other three measures, res, lin and jcn are information content based measures, and here relatedness between two concepts is defined through the amount of information they share. Our experiments with the LA kernel on generic relation recognition suggest that, in this particular case, the path-based measures should be preferred over the information content based measures.\nWe should stress, however, that this is the evaluation of the semantic relatedness measures in the context of relation recognition, and one can by no means draw a conclusion that the top measures for other NLP tasks will stay the same. For example, Budanitsky and Hirst (2006) use semantic relatedness measures to detect malapropism and show that Jiang and Conrath\u2019s measure (jcn) yields the best results, followed by Lin\u2019s measure (lin), and the one by Leacock and Chodorow (lch), and then by Resnik\u2019s measure (res). Our results are quite similar to their findings if we consider the res measure, but jcn is not on the top of the accuracy ranking list for any of the seven semantic relations that we have studied."}, {"heading": "7.2 Factors and Parameters that Influence the LA Kernel Performance", "text": "Our experiments in two domains have shown that the LA kernel either outperforms existing methods on the same corpora, or yields performance on par with existing state-of-the-art kernels."}, {"heading": "7.2.1 Baselines", "text": "An advantage of the LA kernel over the Bunescu shortest path method (Baseline I) is that it is capable of handling paths of different lengths. By allowing gaps and penalizing them,\nUsing Local Alignments for Relation Recognition\nthe final kernel matrix becomes less sparse. The shortest path approach also attempts to generalize over the dependency paths, but it usually overgeneralizes which leads to high recall scores (Table 5 and Table 6) but to poor overall performance. One explanation for overgeneralization may be that this method accounts well for structural similarity (provided sequences are of the same length) but fails to provide finer distinctions among dependency paths. Consider, for example, two sequences \u2018trip \u2190 makes \u2192 tram\u2019 and \u2018coffee \u2190 makes \u2192 guy\u2019, whereby the first path represents a negative instance of the Product-Producer relation and the second path corresponds to a positive one. Even though they do not match exactly, the elements that do not match are all nouns in singular. Consequently, comparison according to the shortest path method will result in a relatively high similarity score. In contrast, the LA kernel will consider similarity of the elements and the pairs \u2018trip\u2019-\u2018coffee\u2019 and \u2018tram\u2019-\u2018guy\u2019 will obtain low scores.\nIn addition, Baseline II, which is based on randomly generated substitution scores, performs poor for all data sets (or comparable to Baseline I). This leads us to the conclusion that accurate estimation of similarities is another reason why the LA kernel performs well on relation extraction."}, {"heading": "7.2.2 Comparison with Other Methods", "text": "As we have already pointed out, the obvious shortcoming of Baseline I is its inability to handle dependency paths of different length. For this reason, we have also applied the gap-weighted string kernel (Lodhi et al., 2002) to all data sets. In this case, dependency paths can be compared in a flexible way because gapping is allowed, but no other additional information is used. This kernel outperforms Baseline I by increasing precision of relation extraction while preserving a relatively high recall. The only data set where it fails to yield good results is the LLL test data, and we believe this is due to the differences in the LLL training and test data. For all data sets, the LA kernel achieves better performance than the gap-weighted string kernel. The margin, however, is different for different data sets. In the biomedical domain, the differences between the two methods can more clearly be seen on the BC-PPI and LLL data sets, while the results on the AImed corpus are comparable. However, other methods tested on AImed do not get higher scores unless they use more features than just dependency paths. This holds for both types of cross-validation used on this corpus. For generic relations, the difference between the LA kernel and the gapweighted string kernel is much larger. In particular, in the case of the gap-weighted kernel, precision is high, but recall is much lower. This can be explained by the fact that generic relations benefit from the knowledge found in WordNet and recall achieved by the LA kernel is, therefore, high. The gap-weighted kernel has access only to information found in the dependency paths and, for this reason, fails to find more relations.\nThe LA kernel also achieves the best performance on the LLL training set, outperforming the graph kernel (Airola et al., 2008), the shallow linguistic kernel (Giuliano et al., 2006) and the rule-based system by Fundel et al. (2007). All three have used different input for their methods, varying from plain text to dependency structures. For this reason, a direct comparison is unfortunately not possible, but we can conclude that the methods employing dependency information always are among the best performing approaches.\nKatrenko, Adriaans, & van Someren\nTwo other approaches whose performance has been reported on the AImed data set include the tree kernel (S\u00e6tre et al., 2008) and TSVM (Erkan et al., 2007). Both of them explore syntactic information in different ways. While S\u00e6tre et al. consider subtrees, the method of Erkan et al. has more similarities with our approach because it relies on the dependency path comparison. To do this comparison, they only use information already available in the dependency paths (SVM setting), or more dependency paths (TSVM setting). According to Lauer and Bloch (2008), TSVMs fall into the category using prior knowledge by \u2018sampling methods\u2019, because it explores prior knowledge by generating new examples. In contrast, we employ information from large unlabeled text sources in order to enable finer comparison of the dependency paths and always work in the supervised learning setting. Using the same evaluation procedure as in the work of S\u00e6tre et al. and Erkan et al. we show that the LA kernel outperforms both methods, but the differences on this data set are much smaller than on the other data sets we have used."}, {"heading": "7.2.3 The LA Parameters", "text": "We have demonstrated that the choice of LA parameters is crucial for achieving good performance. In our experiments, the scaling parameter \u03b2 contributes to the overall performance at most, but the other parameters such as gap values have to be taken into account as well. When \u03b2 approaches infinity, the LA kernel approximates the Smith-Waterman distance, but increasing \u03b2 does not necessarily have a positive impact on the final performance. This finding is in line with the results reported by Saigo et al. (2004) on the homology detection task. The best performance is yielded by setting the scaling parameter to 1 or a bit higher, and by penalizing the gap extension less than the gap opening."}, {"heading": "8. Conclusions and Future Work", "text": "We have presented a novel approach to relation extraction that is based on the local alignments of sequences. Using an LA kernel provides us an opportunity to explore various sources of information and to study their role in relation recognition. Possible future directions include, therefore, an examination of other distributional similarity measures, studying their impact on the extraction of generic relations, and looking for other sources of information which could be helpful for relation recognition. It may be interesting to consider relational similarity (Turney, 2006), which looks for the correspondence between relation instances. In this case, one should be able to infer that \u2018doctor\u2019 corresponds to \u2018scalpel\u2019 in a similar way as \u2018fisherman\u2019 to \u2018net\u2019 (where both (scalpel, doctor) and (net, fisherman) are examples of Instrument - Agency).\nDespite the sparseness problem that might occur when WordNet-based measures are used, these measures have an advantage over the distributional measures by treating elements to be compared as concepts rather than words. In the NLP community, a few steps have been already taken to solve this problem by clustering words in large corpora aiming at word sense discovery (Pennacchiotti & Pantel, 2006). Recently, Mohammad (2008) in his thesis investigated the compatibility of distributional measures with ontological ones. By using corpus statistics and a thesaurus, the author introduced distributional profiles of senses and defined distance measures on them. Even though this new approach to calculat-\nUsing Local Alignments for Relation Recognition\ning similarity was tested on generic corpora, it would be of a certain interest to apply it to domain-specific data.\nOverall, local alignment kernels provide a flexible means to work with data sequences. First, they allow a partial match between sequences which is particularly important when dealing with text. Second, it is possible to incorporate prior knowledge in the learning process while preserving kernel validity. In general, LA kernels can be applied to other NLP problems as long as the input data is in the form of sequences."}, {"heading": "Acknowledgments", "text": "The authors wish to thank Simon Carter and Gerben de Vries for their comments and proofreading, and three anonymous reviewers for their highly valuable feedback. They also acknowledge the input from the Adaptive Information Management (AIM) group at the University of Amsterdam. The preliminary version of this work has been dicussed at the 22nd International Conference on Computational Linguistics (CoLing 2008) and at the Seventh International Tbilisi Symposium on Language, Logic and Computation (2007). This work was carried out in the context of the Virtual Laboratory for e-Science project (www.vl-e.nl). This project is supported by a BSIK grant from the Dutch Ministry of Education, Culture and Science (OC&W) and is part of the ICT innovation program of the Ministry of Economic Affairs (EZ)."}], "references": [{"title": "Allpaths graph kernel for protein-protein interaction extraction with evaluation of crosscorpus learning", "author": ["A. Airola", "S. Pyysalo", "J. Bj\u00f6rne", "T. Pahikkala", "F. Ginter", "T. Salakoski"], "venue": "BMC Bioinformatics,", "citeRegEx": "Airola et al\\.,? \\Q2008\\E", "shortCiteRegEx": "Airola et al\\.", "year": 2008}, {"title": "UIUC: A Knowledge-rich Approach to Identifying Semantic Relations between Nominals", "author": ["B. Beamer", "S. Bhat", "B. Chee", "A. Fister", "A. Rozovskaya", "R. Girju"], "venue": "In Proceedings of the Workshop on Semantic Evaluations (SemEval),", "citeRegEx": "Beamer et al\\.,? \\Q2007\\E", "shortCiteRegEx": "Beamer et al\\.", "year": 2007}, {"title": "UC3M: Classification of semantic relations between nominals using sequential minimal optimization", "author": ["I.S. Bedmar", "D. Samy", "J.L. Martinez"], "venue": null, "citeRegEx": "Bedmar et al\\.,? \\Q2007\\E", "shortCiteRegEx": "Bedmar et al\\.", "year": 2007}, {"title": "Evaluating WordNet-based measures of lexical semantic relatedness", "author": ["A. Budanitsky", "G. Hirst"], "venue": "Computational Linguistics,", "citeRegEx": "Budanitsky and Hirst,? \\Q2006\\E", "shortCiteRegEx": "Budanitsky and Hirst", "year": 2006}, {"title": "Learning for Information Extraction", "author": ["R.C. Bunescu"], "venue": "Ph.D. thesis, Department of Computer Sciences, University of Texas at Austin.", "citeRegEx": "Bunescu,? 2007", "shortCiteRegEx": "Bunescu", "year": 2007}, {"title": "Comparative experiments on learning information extractors for proteins and their interactions", "author": ["R.C. Bunescu", "R. Ge", "R.J. Kate", "E.M. Marcotte", "R.J. Mooney", "A.K. Ramani", "Y.W. Wong"], "venue": "Artificial Intelligence in Medicine,", "citeRegEx": "Bunescu et al\\.,? \\Q2005\\E", "shortCiteRegEx": "Bunescu et al\\.", "year": 2005}, {"title": "A shortest path dependency kernel for relation extraction", "author": ["R.C. Bunescu", "R.J. Mooney"], "venue": "In Joint Conference on Human Language Technology / Empirical Methods in Natural Language Processing (HLT/EMNLP),", "citeRegEx": "Bunescu and Mooney,? \\Q2005\\E", "shortCiteRegEx": "Bunescu and Mooney", "year": 2005}, {"title": "Subsequence kernels for relation extraction", "author": ["R.C. Bunescu", "R.J. Mooney"], "venue": "In Proceedings of the 19th Conference on Neural Information Processing Systems,", "citeRegEx": "Bunescu and Mooney,? \\Q2005\\E", "shortCiteRegEx": "Bunescu and Mooney", "year": 2005}, {"title": "Text Mining and Natural Language Processing, chap. Extracting Relations from Text", "author": ["R.C. Bunescu", "R.J. Mooney"], "venue": "From Word Sequences to Dependency Paths. Springer", "citeRegEx": "Bunescu and Mooney,? \\Q2006\\E", "shortCiteRegEx": "Bunescu and Mooney", "year": 2006}, {"title": "A tutorial on support vector machines for pattern recognition", "author": ["C.J.C. Burges"], "venue": "Data Mining and Knowledge Discovery, 2 (2), 121\u2013167.", "citeRegEx": "Burges,? 1998", "shortCiteRegEx": "Burges", "year": 1998}, {"title": "The use of background knowledge in inductive logic programming", "author": ["R. Camacho"], "venue": "Report.", "citeRegEx": "Camacho,? 1994", "shortCiteRegEx": "Camacho", "year": 1994}, {"title": "LIBSVM: a library for support vector machines. Software available at http://www.csie.ntu.edu.tw/~cjlin/libsvm", "author": ["Chang", "C.-C", "Lin", "C.-J"], "venue": null, "citeRegEx": "Chang et al\\.,? \\Q2001\\E", "shortCiteRegEx": "Chang et al\\.", "year": 2001}, {"title": "An empirical study of smoothing techniques for language modeling", "author": ["S.F. Chen", "J. Goodman"], "venue": null, "citeRegEx": "Chen and Goodman,? \\Q1996\\E", "shortCiteRegEx": "Chen and Goodman", "year": 1996}, {"title": "Computational-Linguistic Approaches to Biological Text Mining", "author": ["A.B. Clegg"], "venue": "Ph.D. thesis, University of London.", "citeRegEx": "Clegg,? 2008", "shortCiteRegEx": "Clegg", "year": 2008}, {"title": "A comparison of string distance metrics for name-matching tasks", "author": ["W.W. Cohen", "P. Ravikumar", "S. Fienberg"], "venue": "IIWeb", "citeRegEx": "Cohen et al\\.,? \\Q2003\\E", "shortCiteRegEx": "Cohen et al\\.", "year": 2003}, {"title": "Head-Driven Statistical Models for Natural Language Parsing", "author": ["M. Collins"], "venue": "Ph.D. thesis, University of Pennsylvania.", "citeRegEx": "Collins,? 1999", "shortCiteRegEx": "Collins", "year": 1999}, {"title": "Convolution kernels for natural language", "author": ["M. Collins", "N. Duffy"], "venue": "In Advances in Neural Information Processing Systems", "citeRegEx": "Collins and Duffy,? \\Q2001\\E", "shortCiteRegEx": "Collins and Duffy", "year": 2001}, {"title": "Support vector networks", "author": ["C. Cortes", "V. Vapnik"], "venue": "Machine Learning,", "citeRegEx": "Cortes and Vapnik,? \\Q1995\\E", "shortCiteRegEx": "Cortes and Vapnik", "year": 1995}, {"title": "Classification of semantic relationships between nominals using pattern clusters", "author": ["D. Davidov", "A. Rappoport"], "venue": "In Proceedings of ACL-08:HLT,", "citeRegEx": "Davidov and Rappoport,? \\Q2008\\E", "shortCiteRegEx": "Davidov and Rappoport", "year": 2008}, {"title": "Unsupervised construction of large paraphrase corpora: Exploiting massively parallel news sources", "author": ["W.B. Dolan", "C. Quirk", "C. Brockett"], "venue": "COLING", "citeRegEx": "Dolan et al\\.,? \\Q2004\\E", "shortCiteRegEx": "Dolan et al\\.", "year": 2004}, {"title": "Semi-supervised classification for extracting protein interaction sentences using dependency parsing", "author": ["G. Erkan", "A. \u00d6zg\u00fcr", "D.R. Radev"], "venue": "Joint Conference on Empirical Methods in Natural Language Processing and Computational Natural Language Learning,", "citeRegEx": "Erkan et al\\.,? \\Q2007\\E", "shortCiteRegEx": "Erkan et al\\.", "year": 2007}, {"title": "WordNet: An Electronic Lexical Database", "author": ["C. Fellbaum"], "venue": "MIT Press.", "citeRegEx": "Fellbaum,? 1998", "shortCiteRegEx": "Fellbaum", "year": 1998}, {"title": "A synopsis of linguistic theory 1930\u20131955", "author": ["J.R. Firth"], "venue": "Studies in Linguistic Analysis. Philological Society, Oxford. Reprinted in Palmer, F. (ed.), 1968.", "citeRegEx": "Firth,? 1957", "shortCiteRegEx": "Firth", "year": 1957}, {"title": "RelEx - relation extraction using dependency parse", "author": ["K. Fundel", "R. Kueffner", "R. Zimmer"], "venue": "trees. Bioinformatics,", "citeRegEx": "Fundel et al\\.,? \\Q2007\\E", "shortCiteRegEx": "Fundel et al\\.", "year": 2007}, {"title": "Automatic discovery of part-whole relations", "author": ["R. Girju", "A. Badulescu", "D. Moldovan"], "venue": "Computational Linguistics,", "citeRegEx": "Girju et al\\.,? \\Q2006\\E", "shortCiteRegEx": "Girju et al\\.", "year": 2006}, {"title": "SemEval2007 Task 04: Classification of semantic relations between nominals", "author": ["R. Girju", "P. Nakov", "V. Nastase", "S. Szpakowicz", "P. Turney", "D. Yuret"], "venue": null, "citeRegEx": "Girju et al\\.,? \\Q2007\\E", "shortCiteRegEx": "Girju et al\\.", "year": 2007}, {"title": "Classification of semantic relations between nominals", "author": ["R. Girju", "P. Nakov", "V. Nastase", "S. Szpakowicz", "P. Turney", "D. Yuret"], "venue": "Language Resources and Evaluation,", "citeRegEx": "Girju et al\\.,? \\Q2009\\E", "shortCiteRegEx": "Girju et al\\.", "year": 2009}, {"title": "FBK-IRST: Kernel methods for semantic relation extraction", "author": ["C. Giuliano", "A. Lavelli", "D. Pighin", "L. Romano"], "venue": null, "citeRegEx": "Giuliano et al\\.,? \\Q2007\\E", "shortCiteRegEx": "Giuliano et al\\.", "year": 2007}, {"title": "Exploiting shallow linguistic information for relation extraction from biomedical literature", "author": ["C. Giuliano", "A. Lavelli", "L. Romano"], "venue": null, "citeRegEx": "Giuliano et al\\.,? \\Q2006\\E", "shortCiteRegEx": "Giuliano et al\\.", "year": 2006}, {"title": "Message Understanding Conference - 6: A brief history", "author": ["R. Grishman", "B. Sundheim"], "venue": "In Proceedings of the 16th International Conference on Computational Linguistics", "citeRegEx": "Grishman and Sundheim,? \\Q1996\\E", "shortCiteRegEx": "Grishman and Sundheim", "year": 1996}, {"title": "Convolution kernels on discrete structures", "author": ["D. Haussler"], "venue": "Tech. rep. UCS-CRL-99-10, UC Santa Cruz.", "citeRegEx": "Haussler,? 1999", "shortCiteRegEx": "Haussler", "year": 1999}, {"title": "Automatic acquisition of hyponyms from large text data", "author": ["M. Hearst"], "venue": "Proceedings of COLING-92, pp. 539\u2013545.", "citeRegEx": "Hearst,? 1992", "shortCiteRegEx": "Hearst", "year": 1992}, {"title": "ILK: Machine learning of semantic relations with shallow features and almost no data", "author": ["I. Hendrickx", "R. Morante", "C. Sporleder", "A. van den Bosch"], "venue": null, "citeRegEx": "Hendrickx et al\\.,? \\Q2007\\E", "shortCiteRegEx": "Hendrickx et al\\.", "year": 2007}, {"title": "TREC 2006 genomics track overview", "author": ["W. Hersch", "A.M. Cohen", "P. Roberts", "H.K. Rakapalli"], "venue": "In Proceedings of the 15th Text Retrieval Conference", "citeRegEx": "Hersch et al\\.,? \\Q2006\\E", "shortCiteRegEx": "Hersch et al\\.", "year": 2006}, {"title": "Semantic similarity based on corpus statistics and lexical taxonomy", "author": ["J.J. Jiang", "D.W. Conrath"], "venue": "In Proceedings of International Conference on Research in Computational Linguistics (ROCLING X),", "citeRegEx": "Jiang and Conrath,? \\Q1997\\E", "shortCiteRegEx": "Jiang and Conrath", "year": 1997}, {"title": "Transductive inference for text classification using Support Vector Machines", "author": ["T. Joachims"], "venue": "Proceedings of ICML.", "citeRegEx": "Joachims,? 1999", "shortCiteRegEx": "Joachims", "year": 1999}, {"title": "Semantic types of some generic relation arguments: Detection and evaluation", "author": ["S. Katrenko", "P. Adriaans"], "venue": "In Proceedings of the 46th Annual Meeting of the Association for Computational Linguistics: Human Language Technologies (ACL/HLT),", "citeRegEx": "Katrenko and Adriaans,? \\Q2008\\E", "shortCiteRegEx": "Katrenko and Adriaans", "year": 2008}, {"title": "Extracting causal knowledge from a medical database using graphical patterns", "author": ["C.S.G. Khoo", "S. Chan", "Y. Niu"], "venue": "In Proceedings of the 38th Annual Meeting on Association for Computational Linguistics,", "citeRegEx": "Khoo et al\\.,? \\Q2000\\E", "shortCiteRegEx": "Khoo et al\\.", "year": 2000}, {"title": "MELB-KB: Nominal classifications as noun compound interpretation", "author": ["S.N. Kim", "T. Baldwin"], "venue": null, "citeRegEx": "Kim and Baldwin,? \\Q2007\\E", "shortCiteRegEx": "Kim and Baldwin", "year": 2007}, {"title": "Incorporating Prior Knowledge in Support Vector Machines for Classification: a Review", "author": ["F. Lauer", "G. Bloch"], "venue": null, "citeRegEx": "Lauer and Bloch,? \\Q2008\\E", "shortCiteRegEx": "Lauer and Bloch", "year": 2008}, {"title": "Combining local context and WordNet similarity for word sense identification", "author": ["C. Leacock", "M. Chodorow"], "venue": null, "citeRegEx": "Leacock and Chodorow,? \\Q1998\\E", "shortCiteRegEx": "Leacock and Chodorow", "year": 1998}, {"title": "Parsing biomedical literature", "author": ["M. Lease", "E. Charniak"], "venue": "In Proceedings of IJCNLP", "citeRegEx": "Lease and Charniak,? \\Q2005\\E", "shortCiteRegEx": "Lease and Charniak", "year": 2005}, {"title": "Measures of distributional similarity", "author": ["L. Lee"], "venue": "Proceedings of the 37th annual meeting of the Association for Computational Linguistics on Computational Linguistics, pp. 25\u201332.", "citeRegEx": "Lee,? 1999", "shortCiteRegEx": "Lee", "year": 1999}, {"title": "Mismatch string kernels for discriminative protein", "author": ["C. Leslie", "E. Eskin", "A. Cohen", "J. Weston", "W.S. Noble"], "venue": "classification. Bioinformatics,", "citeRegEx": "Leslie et al\\.,? \\Q2004\\E", "shortCiteRegEx": "Leslie et al\\.", "year": 2004}, {"title": "The spectrum kernel: A string kernel for SVM protein classification", "author": ["C. Leslie", "E. Eskin", "W.S. Noble"], "venue": "In Pacific Symposium on Biocomputing", "citeRegEx": "Leslie et al\\.,? \\Q2002\\E", "shortCiteRegEx": "Leslie et al\\.", "year": 2002}, {"title": "A novel string-to-string distance measure with applications to machine translation evaluation", "author": ["G. Leusch", "N. Ueffing", "H. Ney"], "venue": "In Machine Translation Summit IX,", "citeRegEx": "Leusch et al\\.,? \\Q2003\\E", "shortCiteRegEx": "Leusch et al\\.", "year": 2003}, {"title": "An information-theoretic definition of similarity", "author": ["D. Lin"], "venue": "Proceedings of the 15th International Conference on Machine Learning, pp. 296\u2013304.", "citeRegEx": "Lin,? 1998", "shortCiteRegEx": "Lin", "year": 1998}, {"title": "Text classification using string kernels", "author": ["H. Lodhi", "C. Saunders", "J. Shawe-Taylor", "N. Christianini", "C. Watkins"], "venue": "Journal of Machine Learning Research,", "citeRegEx": "Lodhi et al\\.,? \\Q2002\\E", "shortCiteRegEx": "Lodhi et al\\.", "year": 2002}, {"title": "Extracting relations from unstructured text", "author": ["R. McDonald"], "venue": "Tech. rep. MS-CIS-0506, UPenn.", "citeRegEx": "McDonald,? 2005", "shortCiteRegEx": "McDonald", "year": 2005}, {"title": "Dpendency syntax: theory and practice", "author": ["I. Mel\u2019\u010duk"], "venue": null, "citeRegEx": "Mel.\u010duk,? \\Q1988\\E", "shortCiteRegEx": "Mel.\u010duk", "year": 1988}, {"title": "Machine Learning", "author": ["T. Mitchell"], "venue": "McGraw Hill.", "citeRegEx": "Mitchell,? 1997", "shortCiteRegEx": "Mitchell", "year": 1997}, {"title": "Task-oriented evaluation of syntactic parsers and their representations", "author": ["Y. Miyao", "R. S\u00e6tre", "K. Sagae", "T. Matsuzaki", "J. Tsuji"], "venue": "In Proceedings of ACL-08:HLT,", "citeRegEx": "Miyao et al\\.,? \\Q2008\\E", "shortCiteRegEx": "Miyao et al\\.", "year": 2008}, {"title": "Measuring Semantic Distance using distributional profiles of concepts", "author": ["S. Mohammad"], "venue": "Ph.D. thesis, Graduate Department of Computer Science of University of Toronto.", "citeRegEx": "Mohammad,? 2008", "shortCiteRegEx": "Mohammad", "year": 2008}, {"title": "The field matching problem: Algorithms and applications", "author": ["A.E. Monge", "C. Elkan"], "venue": "KDD", "citeRegEx": "Monge and Elkan,? \\Q1996\\E", "shortCiteRegEx": "Monge and Elkan", "year": 1996}, {"title": "Efficient convolution kernels for dependency and constituent syntactic trees", "author": ["A. Moschitti"], "venue": "ECML 2006, pp. 318\u2013329.", "citeRegEx": "Moschitti,? 2006", "shortCiteRegEx": "Moschitti", "year": 2006}, {"title": "UCB: System description for SemEval task #4", "author": ["P. Nakov"], "venue": "SemEval-2007.", "citeRegEx": "Nakov,? 2007", "shortCiteRegEx": "Nakov", "year": 2007}, {"title": "Paraphrasing verbs for noun compound interpretation", "author": ["P. Nakov"], "venue": "Proceedings of the Workshop on Multiword Expressions (MWE\u201908), in conjunction with the Language Resources and Evaluation conference, Marrakech, Morocco, 2008.", "citeRegEx": "Nakov,? 2008", "shortCiteRegEx": "Nakov", "year": 2008}, {"title": "Solving relational similarity problems using the web as a corpus", "author": ["P. Nakov", "M.A. Hearst"], "venue": "In Proceedings of ACL-08:HLT", "citeRegEx": "Nakov and Hearst,? \\Q2008\\E", "shortCiteRegEx": "Nakov and Hearst", "year": 2008}, {"title": "Learning Language in Logic - Genic Interaction Extraction Challenge", "author": ["C. N\u00e9dellec"], "venue": "Proceedings of the Learning Language in Logic workshop.", "citeRegEx": "N\u00e9dellec,? 2005", "shortCiteRegEx": "N\u00e9dellec", "year": 2005}, {"title": "A general method applicable to the search for similarities in the amino acid sequence of two proteins", "author": ["S.B. Needleman", "C.D. Wunsch"], "venue": "Journal of Molecular Biology,", "citeRegEx": "Needleman and Wunsch,? \\Q1970\\E", "shortCiteRegEx": "Needleman and Wunsch", "year": 1970}, {"title": "UCD-PN: Classification of semantic relations between nominals using WordNet and web counts", "author": ["P. Nulty"], "venue": "SemEval-2007.", "citeRegEx": "Nulty,? 2007", "shortCiteRegEx": "Nulty", "year": 2007}, {"title": "Semantic classification with WordNet kernels", "author": ["D. \u00d3 S\u00e9aghdha"], "venue": "Proceedings of the North American Chapter of the Association for Computational Linguistics - Human Language Technologies Conference (NAACL-HLT), Boulder, CO.", "citeRegEx": "S\u00e9aghdha,? 2009", "shortCiteRegEx": "S\u00e9aghdha", "year": 2009}, {"title": "Semantic classification with distributional kernels", "author": ["D. \u00d3 S\u00e9aghdha", "A. Copestake"], "venue": "In Proceedings of CoLing", "citeRegEx": "S\u00e9aghdha and Copestake,? \\Q2008\\E", "shortCiteRegEx": "S\u00e9aghdha and Copestake", "year": 2008}, {"title": "Verb semantics for English-Chinese translation", "author": ["M. Palmer", "Z. Wu"], "venue": "Tech. rep., Technical Report No. MS-CIS-95-39,", "citeRegEx": "Palmer and Wu,? \\Q1995\\E", "shortCiteRegEx": "Palmer and Wu", "year": 1995}, {"title": "WordNet::Similarity - Measuring the Relatedness of Concepts", "author": ["T. Pedersen", "S. Patwardhan", "J. Michelizzi"], "venue": "In Proceedings of the Nineteenth National Conference on Artificial Intelligence", "citeRegEx": "Pedersen et al\\.,? \\Q2004\\E", "shortCiteRegEx": "Pedersen et al\\.", "year": 2004}, {"title": "Ontologizing semantic relations", "author": ["M. Pennacchiotti", "P. Pantel"], "venue": "Proceedings of the 21st International Conference on Computational Linguistics and the 44th annual meeting of the Association for Computational Linguistics,", "citeRegEx": "Pennacchiotti and Pantel,? \\Q2006\\E", "shortCiteRegEx": "Pennacchiotti and Pantel", "year": 2006}, {"title": "Knowledge Derived from Wikipedia for Computing Semantic Relatedness", "author": ["S.P. Ponzetto", "M. Strube"], "venue": "Journal of Artificial Intelligence Research,", "citeRegEx": "Ponzetto and Strube,? \\Q2007\\E", "shortCiteRegEx": "Ponzetto and Strube", "year": 2007}, {"title": "Using information content to evaluate semantic similarity", "author": ["P. Resnik"], "venue": "Proceedings of the 14th International Joint Conference on Artificial Intelligence, pp. 448\u2013453.", "citeRegEx": "Resnik,? 1995", "shortCiteRegEx": "Resnik", "year": 1995}, {"title": "Syntactic features for protein-protein interaction extraction", "author": ["R. S\u00e6tre", "K. Sagae", "J. Tsuji"], "venue": "In 2nd International Symposium on Languages in Biology and Medicine,", "citeRegEx": "S\u00e6tre et al\\.,? \\Q2008\\E", "shortCiteRegEx": "S\u00e6tre et al\\.", "year": 2008}, {"title": "Dependency parsing and domain adaptation with LR models and parser ensembles", "author": ["K. Sagae", "J. Tsujii"], "venue": "In Proceedings of EMNLP-CoNLL", "citeRegEx": "Sagae and Tsujii,? \\Q2007\\E", "shortCiteRegEx": "Sagae and Tsujii", "year": 2007}, {"title": "Optimizing amino acid substitution matrices with a local alignment kernel", "author": ["H. Saigo", "Vert", "J.-P", "T. Akutsu"], "venue": "BMC Bioinformatics,", "citeRegEx": "Saigo et al\\.,? \\Q2006\\E", "shortCiteRegEx": "Saigo et al\\.", "year": 2006}, {"title": "Protein homology detection using string alignment", "author": ["H. Saigo", "Vert", "J.-P", "N. Ueda", "T. Akutsu"], "venue": "kernels. Bioinformatics,", "citeRegEx": "Saigo et al\\.,? \\Q2004\\E", "shortCiteRegEx": "Saigo et al\\.", "year": 2004}, {"title": "Applying spelling error correction techniques for improving semantic role labeling", "author": ["Sang", "E.F.T. K", "S. Canisius", "A. van den Bosch", "T. Bogers"], "venue": "In Proceedings of the Ninth Conference on Natural Language Learning,", "citeRegEx": "Sang et al\\.,? \\Q2005\\E", "shortCiteRegEx": "Sang et al\\.", "year": 2005}, {"title": "Syllables and other string kernel extensions", "author": ["C. Saunders", "H. Tschach", "J. Shawe-Taylor"], "venue": null, "citeRegEx": "Saunders et al\\.,? \\Q2002\\E", "shortCiteRegEx": "Saunders et al\\.", "year": 2002}, {"title": "Support vector learning", "author": ["B. Sch\u00f6lkopf"], "venue": "Ph.D. thesis, Berlin Technical University.", "citeRegEx": "Sch\u00f6lkopf,? 1997", "shortCiteRegEx": "Sch\u00f6lkopf", "year": 1997}, {"title": "Identifying the interaction between genes and gene products based on frequently seen verbs in Medline abstracts", "author": ["T. Sekimizu", "H.S. Park", "J. Tsujii"], "venue": "Genome Informatics,", "citeRegEx": "Sekimizu et al\\.,? \\Q1998\\E", "shortCiteRegEx": "Sekimizu et al\\.", "year": 1998}, {"title": "Support Vector Machines and Other KernelBased Learning Methods", "author": ["J. Shawe-Taylor", "N. Christianini"], "venue": null, "citeRegEx": "Shawe.Taylor and Christianini,? \\Q2000\\E", "shortCiteRegEx": "Shawe.Taylor and Christianini", "year": 2000}, {"title": "Hidden Markov models and optimized sequence alignment", "author": ["L.H. Smith", "L. Yeganova", "W.J. Wilbur"], "venue": "Computational Biology and Chemistry,", "citeRegEx": "Smith et al\\.,? \\Q2003\\E", "shortCiteRegEx": "Smith et al\\.", "year": 2003}, {"title": "Identification of common molecular subsequences", "author": ["T.F. Smith", "M.S. Waterman"], "venue": "Journal of Molecular Biology,", "citeRegEx": "Smith and Waterman,? \\Q1981\\E", "shortCiteRegEx": "Smith and Waterman", "year": 1981}, {"title": "Learning named entity hyponyms for question answering", "author": ["R. Snow", "D. Jurafsky", "A.Y. Ng"], "venue": "In Proceedings of COLING/ACL", "citeRegEx": "Snow et al\\.,? \\Q2006\\E", "shortCiteRegEx": "Snow et al\\.", "year": 2006}, {"title": "Implicit text linkages between Medline records: Using Arrowsmith as an aid to scientific discovery", "author": ["D.R. Swanson", "N.R. Smalheiser"], "venue": "Library Trends,", "citeRegEx": "Swanson and Smalheiser,? \\Q1999\\E", "shortCiteRegEx": "Swanson and Smalheiser", "year": 1999}, {"title": "Automatic extraction of protein interactions from scientific abstracts", "author": ["J. Thomas", "D. Milward", "C. Ouzounis", "S. Pulman"], "venue": "In Proceedings of Pacific Symposium on Biocomputing", "citeRegEx": "Thomas et al\\.,? \\Q2000\\E", "shortCiteRegEx": "Thomas et al\\.", "year": 2000}, {"title": "CMU-AT: Semantic distance and background knowledge for identifying semantic relations", "author": ["A. Tribble", "S.E. Fahlman"], "venue": null, "citeRegEx": "Tribble and Fahlman,? \\Q2007\\E", "shortCiteRegEx": "Tribble and Fahlman", "year": 2007}, {"title": "Similarity of semantic relations", "author": ["P.D. Turney"], "venue": "Computational Linguistics, 32 (3), 379\u2013416.", "citeRegEx": "Turney,? 2006", "shortCiteRegEx": "Turney", "year": 2006}, {"title": "Automatic Lexico-Semantic Acquisition for Question Answering", "author": ["L. van der Plas"], "venue": "Ph.D. thesis,", "citeRegEx": "Plas,? \\Q2008\\E", "shortCiteRegEx": "Plas", "year": 2008}, {"title": "New models in probabilistic information retrieval", "author": ["C.J. van Rijsbergen", "S.E. Robertson", "M.F. Porter"], "venue": "Tech. rep. 5587,", "citeRegEx": "Rijsbergen et al\\.,? \\Q1980\\E", "shortCiteRegEx": "Rijsbergen et al\\.", "year": 1980}, {"title": "Estimation of Dependences Based on Empirical Data", "author": ["V. Vapnik"], "venue": "New York: SPringer Verlag.", "citeRegEx": "Vapnik,? 1982", "shortCiteRegEx": "Vapnik", "year": 1982}, {"title": "Characterising measures of lexical distributional similarity", "author": ["J. Weeds", "D. Weir", "D. McCarthy"], "venue": "In Proceedings of CoLing", "citeRegEx": "Weeds et al\\.,? \\Q2004\\E", "shortCiteRegEx": "Weeds et al\\.", "year": 2004}, {"title": "Kernel methods for relation extraction", "author": ["D. Zelenko", "C. Aone", "A. Richardella"], "venue": "Journal of Machine Learning Research,", "citeRegEx": "Zelenko et al\\.,? \\Q2003\\E", "shortCiteRegEx": "Zelenko et al\\.", "year": 2003}, {"title": "Learning the semantic correlation: An alternative way to gain from unlabeled text", "author": ["Y. Zhang", "J. Schneider", "A. Dubrawski"], "venue": "In Proceedings of the 22nd Conference on Neural Information Processing Systems,", "citeRegEx": "Zhang et al\\.,? \\Q2008\\E", "shortCiteRegEx": "Zhang et al\\.", "year": 2008}], "referenceMentions": [{"referenceID": 13, "context": "For instance, relation extraction in the biomedical domain would require an accurate recognition of named entities such as gene names (Clegg, 2008), and in the area of food it needs information on relevant named entities such as toxic substances.", "startOffset": 134, "endOffset": 147}, {"referenceID": 56, "context": "Generic relations very often occur in nominal complexes such as \u2018flu virus\u2019 in (2) and lack of sentential context boosts such approaches as paraphrasing (Nakov, 2008).", "startOffset": 153, "endOffset": 166}, {"referenceID": 5, "context": "Previous work on relation extraction suggests that in this case the accuracy of relation recognition is much higher than in the case when they have to be discovered automatically (Bunescu et al., 2005).", "startOffset": 179, "endOffset": 201}, {"referenceID": 48, "context": "Furthermore, most existing solutions to relation extraction (including work presented in this paper) focus on relation examples that occur within a single sentence and do not consider discourse (McDonald, 2005).", "startOffset": 194, "endOffset": 210}, {"referenceID": 81, "context": "Although patterns are often precise, they usually produce poor recall (Thomas et al., 2000).", "startOffset": 70, "endOffset": 91}, {"referenceID": 31, "context": "Hand-written sequential patterns were initially used for extraction of Hypernymy (Hearst, 1992), with several attempts to extend them to other relations.", "startOffset": 81, "endOffset": 95}, {"referenceID": 88, "context": "In recent years kernel-based methods have become popular because they can handle high-dimensional problems (Zelenko et al., 2003; Bunescu & Mooney, 2006; Airola et al., 2008).", "startOffset": 107, "endOffset": 174}, {"referenceID": 0, "context": "In recent years kernel-based methods have become popular because they can handle high-dimensional problems (Zelenko et al., 2003; Bunescu & Mooney, 2006; Airola et al., 2008).", "startOffset": 107, "endOffset": 174}, {"referenceID": 26, "context": "Hand-written sequential patterns were initially used for extraction of Hypernymy (Hearst, 1992), with several attempts to extend them to other relations. The second type of patterns (Khoo, Chan, & Niu, 2000) take the syntactic structure of a sentence into account. The dependency structure of a sentence can usually be represented as a tree and the patterns then become subtrees. Such patterns are sometimes referred to as graphical patterns. To identify examples of the Cause-Effect relation, Khoo et al. (2000) applied this type of patterns to texts in the medical domain.", "startOffset": 82, "endOffset": 513}, {"referenceID": 0, "context": ", 2003; Bunescu & Mooney, 2006; Airola et al., 2008). These methods transform text fragments, complete sentences or segments around named entitites or verbs, to vectors, and apply Support Vector Machines to classify new fragments. Some Machine Learning methods use prior knowledge that is given to the system in addition to labeled examples (Sch\u00f6lkopf, 1997, p. 17). The use of prior knowledge is often motivated by, for example, poor quality of data and data sparseness. Prior knowledge can be used in many ways, from changing the representation of existing training examples to adding more examples from unlabelled data. For NLP tasks, prior knowledge exists in the form of manually (or automatically) constructed ontologies or large collections of unannotated data. These enrich the textual data and thereby improve the recognition of relations (Sekimizu, Park, & Tsujii, 1998; Tribble & Fahlman, 2007). Recently, Zhang et al. (2008) showed that semantic correlation of words can be learned from unlabelled text collections, transferred among documents and used further to improve document classification.", "startOffset": 32, "endOffset": 937}, {"referenceID": 0, "context": ", 2003; Bunescu & Mooney, 2006; Airola et al., 2008). These methods transform text fragments, complete sentences or segments around named entitites or verbs, to vectors, and apply Support Vector Machines to classify new fragments. Some Machine Learning methods use prior knowledge that is given to the system in addition to labeled examples (Sch\u00f6lkopf, 1997, p. 17). The use of prior knowledge is often motivated by, for example, poor quality of data and data sparseness. Prior knowledge can be used in many ways, from changing the representation of existing training examples to adding more examples from unlabelled data. For NLP tasks, prior knowledge exists in the form of manually (or automatically) constructed ontologies or large collections of unannotated data. These enrich the textual data and thereby improve the recognition of relations (Sekimizu, Park, & Tsujii, 1998; Tribble & Fahlman, 2007). Recently, Zhang et al. (2008) showed that semantic correlation of words can be learned from unlabelled text collections, transferred among documents and used further to improve document classification. In general, while use of large collections of text allows us to derive almost any information needed, it is done with varying accuracy. In contrast, existing resources created by humans can provide very precise information, but it is less likely that they will cover all possible areas of interest. In this paper, as in the work of Bunescu and Mooney (2006), we use the syntactic structure of sentences, in particular, dependency paths.", "startOffset": 32, "endOffset": 1467}, {"referenceID": 9, "context": "The past years have witnessed a boost of interest in kernel methods, their theoretical analysis and practical applications in various fields (Burges, 1998; Shawe-Taylor & Christianini, 2000).", "startOffset": 141, "endOffset": 190}, {"referenceID": 86, "context": "A hyperplane that separates mapped examples with the largest possible margin would be the best option (Vapnik, 1982).", "startOffset": 102, "endOffset": 116}, {"referenceID": 9, "context": "The past years have witnessed a boost of interest in kernel methods, their theoretical analysis and practical applications in various fields (Burges, 1998; Shawe-Taylor & Christianini, 2000). The idea of having a method that works with different structures and representations, starting from the simplest representation using a limited number of attributes to complex structures such as trees, seems indeed very attractive. Before we define a kernel function, recall the standard setting for supervised classification. For a training set S of n objects (instances) (x1, y1), . . . , (xn, yn) where x1, . . . ,xn \u2208 X are input examples in the input space X with their corresponding labels y1, . . . , yn \u2208 {0,1}, the goal is to infer a function h : X \u2192 {0, 1} such that it approximates a target function t. However, h can still err on the data which has to be reflected in a loss function, l(h(xi), yi). Several loss functions have been proposed in the literature so far, the best known of which is the zero-one loss. This loss is a function that outputs 1 each time a method errs on a data point (h(xi) 6= yi), and 0 otherwise. The key idea of kernel methods lies in the implicit mapping of objects to a highdimensional space (by using some mapping function \u03c6) and considering their inner product (similarity) k(xi,xj) =< \u03c6(xi), \u03c6(xj) >, rather than representing them explicitly. Functions that can be used in kernel methods have to be symmetric and positive semi-definite, whereby positive semi-definiteness is defined by \u2211n i=1 \u2211n j=1 cicjk(xi,xj) \u2265 0 for any n > 0, any objects x1, . . . ,xn \u2208 X , and any choice of real numbers c1, . . . , cn \u2208 R. If a function is not positive semi-definite, the algorithm may not find the global optimal solution. If the requirements w.r.t. symmetry and positive semi-definiteness are met, a kernel is called valid. Using the idea of a kernel mapping, Cortes and Vapnik (1995) introduced support vector machines (SVM) as a method which seeks the linear separation between two classes of the input points by a function f(x) such that f(x) = wT\u03c6(x) + b, wT \u2208 Rp, b \u2208 R and h(x) = sign(f(x)).", "startOffset": 142, "endOffset": 1916}, {"referenceID": 10, "context": "Inductive logic programming offers one possible solution to use it explicitly, in the form of additional Horn clauses (Camacho, 1994).", "startOffset": 118, "endOffset": 133}, {"referenceID": 50, "context": "In the Bayesian learning paradigm information on the hypothesis without seeing any data is encoded in a Bayesian prior (Mitchell, 1997) or in a higher level distribution in a hierarchical Bayesian setting.", "startOffset": 119, "endOffset": 135}, {"referenceID": 29, "context": "It has been shown by Haussler (1999) that a complex kernel (referred to as a convolution kernel) can be defined using simpler kernels.", "startOffset": 21, "endOffset": 37}, {"referenceID": 43, "context": "The novelty of Leslie et al.\u2019s (2002) method lies in its generality and its low computational complexity.", "startOffset": 15, "endOffset": 38}, {"referenceID": 43, "context": "The mismatch kernel that was introduced later by Leslie et al. (2004) is essentially an extension of the latter.", "startOffset": 49, "endOffset": 70}, {"referenceID": 46, "context": "The second uses linguistic structures such as dependency paths or trees or the output of shallow parsing. In this short review we do not take a chronological perspective but rather start with the methods that are based on sequences and proceed with the approaches that make use of syntactic information. In the same year in which the spectrum kernel was designed, Lodhi et al. (2002) introduced string subsequence kernels that provide flexible means to work with text data.", "startOffset": 16, "endOffset": 384}, {"referenceID": 46, "context": "The second uses linguistic structures such as dependency paths or trees or the output of shallow parsing. In this short review we do not take a chronological perspective but rather start with the methods that are based on sequences and proceed with the approaches that make use of syntactic information. In the same year in which the spectrum kernel was designed, Lodhi et al. (2002) introduced string subsequence kernels that provide flexible means to work with text data. In particular, subsequences are not necessarily contiguous and are weighted according to their length (using a decay factor \u03bb). The length of the subsequences is fixed in advance. The authors claim that even without the use of any linguistic information their kernels are able to capture semantic information. This is reflected in the better performance on the text classification task compared to the bag-of-words approach. While Lodhi et al.\u2019s (2002) kernel works on sequences of characters, a kernel proposed by Cancedda et al.", "startOffset": 16, "endOffset": 927}, {"referenceID": 46, "context": "The second uses linguistic structures such as dependency paths or trees or the output of shallow parsing. In this short review we do not take a chronological perspective but rather start with the methods that are based on sequences and proceed with the approaches that make use of syntactic information. In the same year in which the spectrum kernel was designed, Lodhi et al. (2002) introduced string subsequence kernels that provide flexible means to work with text data. In particular, subsequences are not necessarily contiguous and are weighted according to their length (using a decay factor \u03bb). The length of the subsequences is fixed in advance. The authors claim that even without the use of any linguistic information their kernels are able to capture semantic information. This is reflected in the better performance on the text classification task compared to the bag-of-words approach. While Lodhi et al.\u2019s (2002) kernel works on sequences of characters, a kernel proposed by Cancedda et al. (2003) is applied to word sequences.", "startOffset": 16, "endOffset": 1012}, {"referenceID": 46, "context": "The second uses linguistic structures such as dependency paths or trees or the output of shallow parsing. In this short review we do not take a chronological perspective but rather start with the methods that are based on sequences and proceed with the approaches that make use of syntactic information. In the same year in which the spectrum kernel was designed, Lodhi et al. (2002) introduced string subsequence kernels that provide flexible means to work with text data. In particular, subsequences are not necessarily contiguous and are weighted according to their length (using a decay factor \u03bb). The length of the subsequences is fixed in advance. The authors claim that even without the use of any linguistic information their kernels are able to capture semantic information. This is reflected in the better performance on the text classification task compared to the bag-of-words approach. While Lodhi et al.\u2019s (2002) kernel works on sequences of characters, a kernel proposed by Cancedda et al. (2003) is applied to word sequences. String kernels can be also extended to syllable kernels which proved to do well on text categorization (Saunders, Tschach, & Shawe-Taylor, 2002). Because all these kernels can be defined recursively, their computation is efficient. For instance, the time complexity of Lodhi et al.\u2019s (2002) kernel is O(n|s||t|), where n is the length of the subsequence, and t and s are documents.", "startOffset": 16, "endOffset": 1333}, {"referenceID": 23, "context": "A method proposed by Giuliano et al. (2006) was largely inspired by the work of Bunescu and Mooney (2005b).", "startOffset": 21, "endOffset": 44}, {"referenceID": 4, "context": "(2006) was largely inspired by the work of Bunescu and Mooney (2005b). However, instead of looking for subsequences in three types of sequences, the authors treat them as a bag-of-words and define what is called a global kernel as follows.", "startOffset": 43, "endOffset": 70}, {"referenceID": 42, "context": "They show that it is possible to derive kernels from such distances as Jensen-Shannon divergence (JSD) or Euclidean distance (L2) (Lee, 1999).", "startOffset": 130, "endOffset": 141}, {"referenceID": 59, "context": "Recently, \u00d3 S\u00e9aghdha and Copestake (2008) introduced distributional kernels on co- occurrence probability distributions.", "startOffset": 12, "endOffset": 42}, {"referenceID": 15, "context": "Re-ranking parsing trees (Collins & Duffy, 2001) was one of the first applications of kernel methods to NLP problems. To accomplish this goal, the authors rely on the subtrees that a pair of trees have in common. Later on, Moschitti (2006) explored convolution kernels on dependency and constituency structures to do semantic role labeling and question classification.", "startOffset": 26, "endOffset": 240}, {"referenceID": 4, "context": "Bunescu and Mooney (2005a) use several features such as word (e.", "startOffset": 0, "endOffset": 27}, {"referenceID": 35, "context": "Further, various machine learning methods are used to do classification, including SVM and transuctive SVM (TSVM), which is an extension of SVM (Joachims, 1999).", "startOffset": 144, "endOffset": 160}, {"referenceID": 19, "context": "Here, Erkan et al. (2007) use dependency paths as input and compare them by means of cosine similarity or edit distance.", "startOffset": 6, "endOffset": 26}, {"referenceID": 0, "context": "Airola et al. (2008) propose a graph kernel which makes use of the entire dependency structure.", "startOffset": 0, "endOffset": 21}, {"referenceID": 0, "context": "Airola et al. (2008) propose a graph kernel which makes use of the entire dependency structure. In their work, each sentence is represented by two subgraphs, one of which is built from the dependency analysis, and the other corresponds to the linear structure of the sentence. Further, a kernel is defined on all paths between any two vertices in the graph. The method by Airola et al. (2008) achieves state-of-the-art performance on biomedical data sets, and is further discussed, together with the shortest path kernel and the work", "startOffset": 0, "endOffset": 393}, {"referenceID": 73, "context": "In our view, these types of methods can complement each other (Saunders et al., 2002).", "startOffset": 62, "endOffset": 85}, {"referenceID": 19, "context": "by Erkan et al. (2007), in Section 5 on relation extraction in the biomedical domain in this paper.", "startOffset": 3, "endOffset": 23}, {"referenceID": 19, "context": "by Erkan et al. (2007), in Section 5 on relation extraction in the biomedical domain in this paper. Finally, kernels can be defined not only on graphs of syntactic structures, but also on graphs of a semantic network. This is illustrated by \u00d3 S\u00e9aghdha (2009), who uses graph kernels on the graph built from the hyponymy relations in WordNet.", "startOffset": 3, "endOffset": 259}, {"referenceID": 54, "context": "One can note from our short overview of the kernels designed for NLP above that many researchers use partial structures and propose variants such as subsequence kernels (Bunescu & Mooney, 2005b), a partial tree kernel (Moschitti, 2006), or a kernel on shallow parsing output (Zelenko et al.", "startOffset": 218, "endOffset": 235}, {"referenceID": 88, "context": "One can note from our short overview of the kernels designed for NLP above that many researchers use partial structures and propose variants such as subsequence kernels (Bunescu & Mooney, 2005b), a partial tree kernel (Moschitti, 2006), or a kernel on shallow parsing output (Zelenko et al., 2003) for relation extraction.", "startOffset": 275, "endOffset": 297}, {"referenceID": 72, "context": "The Levenshtein distance has been used in the natural language processing field as a component in a variety of tasks, including semantic role labeling (Sang et al., 2005), construction of paraphrase corpora (Dolan, Quirk, & Brockett, 2004), evaluation of machine translation output (Leusch, Ueffing, & Ney, 2003), and others.", "startOffset": 151, "endOffset": 170}, {"referenceID": 14, "context": "The Smith-Waterman measure is mostly used in the biological domain, there are, however, some applications of a modified Smith-Waterman measure to text data as well (Monge & Elkan, 1996; Cohen et al., 2003).", "startOffset": 164, "endOffset": 205}, {"referenceID": 78, "context": "For gapping, Smith and Waterman (1981) suggested to use a gap value which is at least equal to the difference between a match (d(xi, xj), xi = xj) and a mismatch (d(xi, x \u2032 j), xi 6= xj).", "startOffset": 13, "endOffset": 39}, {"referenceID": 70, "context": "However, Saigo et al. (2004) observed that the Smith-Waterman measure may not result in a valid kernel because it may not be positive semi-definite.", "startOffset": 9, "endOffset": 29}, {"referenceID": 30, "context": "Finally, the LA kernel is a composition of several kernels (k0, ka, and kg), which is in the spirit of convolution kernels (Haussler, 1999).", "startOffset": 123, "endOffset": 139}, {"referenceID": 30, "context": "Finally, the LA kernel is a composition of several kernels (k0, ka, and kg), which is in the spirit of convolution kernels (Haussler, 1999). According to Saigo et al. (2004), similarity of the aligned sequences\u2019 elements (ka kernel) is defined as follows:", "startOffset": 124, "endOffset": 174}, {"referenceID": 70, "context": "The results in the biological domain suggest that kernels based on the Smith-Waterman distance are more relevant for the comparison of amino acids than string kernels (Saigo et al., 2006).", "startOffset": 167, "endOffset": 187}, {"referenceID": 42, "context": "Distributional similarity measures have been extensively studied before (Lee, 1999; Weeds, Weir, & McCarthy, 2004).", "startOffset": 72, "endOffset": 114}, {"referenceID": 22, "context": "The main hypothesis behind distributional measures is that words occurring in the same context should have similar meaning (Firth, 1957).", "startOffset": 123, "endOffset": 136}, {"referenceID": 42, "context": "Here, we adopt the definitions given by Lee (1999), which are based on probability estimates P .", "startOffset": 40, "endOffset": 51}, {"referenceID": 21, "context": "For generic relations, the most commonly used resource is WordNet (Fellbaum, 1998), which is a lexical database for English.", "startOffset": 66, "endOffset": 82}, {"referenceID": 21, "context": ", \u2018fountain pen\u2019), and pointers that describe the relations between this synset and other synsets\u201d (Fellbaum, 1998).", "startOffset": 99, "endOffset": 115}, {"referenceID": 27, "context": "WordNet can be employed for different purposes such as studying semantic constraints for certain relation types (Girju, Badulescu, & Moldovan, 2006; Katrenko & Adriaans, 2008), or enriching the training set (Giuliano et al., 2007; Nulty, 2007).", "startOffset": 207, "endOffset": 243}, {"referenceID": 60, "context": "WordNet can be employed for different purposes such as studying semantic constraints for certain relation types (Girju, Badulescu, & Moldovan, 2006; Katrenko & Adriaans, 2008), or enriching the training set (Giuliano et al., 2007; Nulty, 2007).", "startOffset": 207, "endOffset": 243}, {"referenceID": 21, "context": "For generic relations, the most commonly used resource is WordNet (Fellbaum, 1998), which is a lexical database for English. In WordNet, words are grouped together in synsets where a synset \u201cconsists of a list of synonymous words or collocations (e.g., \u2018fountain pen\u2019), and pointers that describe the relations between this synset and other synsets\u201d (Fellbaum, 1998). WordNet can be employed for different purposes such as studying semantic constraints for certain relation types (Girju, Badulescu, & Moldovan, 2006; Katrenko & Adriaans, 2008), or enriching the training set (Giuliano et al., 2007; Nulty, 2007). To compare two concepts given their synsets c1 and c2 we use five different measures that have been proposed in the past years. Most of them rely on the notions of the length of the shortest path between two concepts c1 and c2, len(c1, c2), the depth of a node in the WordNet hierarchy (which is equal to the length of the path from the root to the given synset ci), dep(ci), and a least common subsumer (or lowest super-ordinate) between c1 and c2, lcs(c1, c2), which in turn is a synset. To the measures that are exclusively based on these notions belong conceptual similarity proposed by Palmer and Wu (1995) (simwup in Equation 16) and the formula of scaled semantic similarity introduced by Leacock and Chodorow (1998) (simlch in Equation 17).", "startOffset": 67, "endOffset": 1225}, {"referenceID": 21, "context": "For generic relations, the most commonly used resource is WordNet (Fellbaum, 1998), which is a lexical database for English. In WordNet, words are grouped together in synsets where a synset \u201cconsists of a list of synonymous words or collocations (e.g., \u2018fountain pen\u2019), and pointers that describe the relations between this synset and other synsets\u201d (Fellbaum, 1998). WordNet can be employed for different purposes such as studying semantic constraints for certain relation types (Girju, Badulescu, & Moldovan, 2006; Katrenko & Adriaans, 2008), or enriching the training set (Giuliano et al., 2007; Nulty, 2007). To compare two concepts given their synsets c1 and c2 we use five different measures that have been proposed in the past years. Most of them rely on the notions of the length of the shortest path between two concepts c1 and c2, len(c1, c2), the depth of a node in the WordNet hierarchy (which is equal to the length of the path from the root to the given synset ci), dep(ci), and a least common subsumer (or lowest super-ordinate) between c1 and c2, lcs(c1, c2), which in turn is a synset. To the measures that are exclusively based on these notions belong conceptual similarity proposed by Palmer and Wu (1995) (simwup in Equation 16) and the formula of scaled semantic similarity introduced by Leacock and Chodorow (1998) (simlch in Equation 17).", "startOffset": 67, "endOffset": 1337}, {"referenceID": 67, "context": "Aiming at combining information from several sources, Resnik (1995) introduced yet another measure that is grounded in information content (simres in Equation 18).", "startOffset": 54, "endOffset": 68}, {"referenceID": 34, "context": "To overcome this, Jiang and Conrath (1997) proposed a solution that takes into account information about the synsets being compared (simjcn in Equation 19).", "startOffset": 18, "endOffset": 43}, {"referenceID": 54, "context": "We do not consider, however, other structures that might be derived from the full syntactic analysis as in, for example, subtrees (Moschitti, 2006).", "startOffset": 130, "endOffset": 147}, {"referenceID": 20, "context": "To be able to compare our results on AImed with the performance reported in the work of Erkan et al. (2007) and S\u00e6tre et al.", "startOffset": 88, "endOffset": 108}, {"referenceID": 20, "context": "To be able to compare our results on AImed with the performance reported in the work of Erkan et al. (2007) and S\u00e6tre et al. (2008), we use exactly the same dependency paths with argument labels.", "startOffset": 88, "endOffset": 132}, {"referenceID": 26, "context": "data used for the SemEval-2007 challenge, \u201cTask 04: Classification of Semantic Relations between Nominals\u201d (Girju et al., 2009).", "startOffset": 107, "endOffset": 127}, {"referenceID": 42, "context": "Distributional similarity can be estimated either by using contextual information (\u00d3 S\u00e9aghdha & Copestake, 2008), or by exploring grammatical relations between words (Lee, 1999).", "startOffset": 166, "endOffset": 177}, {"referenceID": 49, "context": "For instance, even though, according to dependency grammar theory (Mel\u2019\u010duk, 1988), adjectives do not govern other words, they may still occur in the dependency paths.", "startOffset": 66, "endOffset": 81}, {"referenceID": 4, "context": "Similarly to Bunescu and Mooney\u2019s (2005a) work, in our experiments we use lemma, part of speech tag and direction, but we do not consider entity type or negative polarity of items.", "startOffset": 13, "endOffset": 42}, {"referenceID": 71, "context": "The choice of the scaling value was motivated by the experiments on amino acids in the biological domain (Saigo et al., 2004).", "startOffset": 105, "endOffset": 125}, {"referenceID": 0, "context": ", using the graph kernel by Airola et al., 2008 or the tree kernel by S\u00e6tre et al., 2008). To the best of our knowledge, string kernels have not been applied to dependency paths yet. However, a gap-weighted string kernel (described in Section 2) also allows gapping and can be thus compared to the LA kernel. To test how Lodhi et al.\u2019s (2002) kernel performs on dependency paths, we use it", "startOffset": 28, "endOffset": 343}, {"referenceID": 47, "context": "80 Gap-weighted string kernel (Lodhi et al., 2002) 72.", "startOffset": 30, "endOffset": 50}, {"referenceID": 46, "context": "On both data sets, the LA method using distributional similarity measures significantly outperforms the baselines. Interestingly, the gap-weighted string kernel by Lodhi et al. (2002) yields good performance too and seems to be a better choice than the subsequence", "startOffset": 108, "endOffset": 184}, {"referenceID": 47, "context": "Lodhi et al. (2002) have mentioned in their paper that \u201cthe F1 numbers (with respect to SSK) seem to peak at a subsequence length between 4 and 7\u201d.", "startOffset": 0, "endOffset": 20}, {"referenceID": 28, "context": "kernel based on shallow linguistic information (Giuliano et al., 2006).", "startOffset": 47, "endOffset": 70}, {"referenceID": 0, "context": "Airola et al. (2008) apply a graph kernel-based approach to extract interactions and use, among others, the LLL and AImed data sets.", "startOffset": 0, "endOffset": 21}, {"referenceID": 0, "context": "76 Graph kernel (Airola et al., 2008) 72.", "startOffset": 16, "endOffset": 37}, {"referenceID": 47, "context": "8 Gap-weighted string kernel (Lodhi et al., 2002) 83.", "startOffset": 29, "endOffset": 49}, {"referenceID": 28, "context": "88 Shallow linguistic kernel (Giuliano et al., 2006) 62.", "startOffset": 29, "endOffset": 52}, {"referenceID": 23, "context": "70 Rule-based method (Fundel et al., 2007) 68 83 75", "startOffset": 21, "endOffset": 42}, {"referenceID": 47, "context": "In addition, the gap-weighted string kernel (Lodhi et al., 2002) seems to perform much worse on the test set.", "startOffset": 44, "endOffset": 64}, {"referenceID": 27, "context": "In contrast, the approach reported by Giuliano et al. (2006) does not make use of syntactic information, and on the data subset without coreferences achieves higher recall.", "startOffset": 38, "endOffset": 61}, {"referenceID": 27, "context": "In contrast, the approach reported by Giuliano et al. (2006) does not make use of syntactic information, and on the data subset without coreferences achieves higher recall. On the other hand, lower recall can also be caused by using actual names of proteins and genes as arguments. In the work reported before, the relation arguments and other named entities are often replaced by their types (e.g., PROTEIN) and these are used as input for the learning algorithm. We conducted additional experiments using named entity types in the dependency paths, which led to a great improvement in terms of recall and F-score (Table 7, LLL-coref-LABEL, LLL-nocoref-LABEL, LLL-coref-LABEL). Our method clearly outperforms the shallow linguistic kernel and also achieves better results than the best-performing system in the LLL competition (Sbest), which, according to N\u00e9dellec (2005), applied Markov logic to the syntactic paths.", "startOffset": 38, "endOffset": 873}, {"referenceID": 0, "context": "Airola et al. (2008) do not report on the performance on the LLL data set and, for this reason, information on the graph all-paths kernel is not included in Table 7.", "startOffset": 0, "endOffset": 21}, {"referenceID": 28, "context": "LLL-coref Shallow linguistic kernel (Giuliano et al., 2006) 29.", "startOffset": 36, "endOffset": 59}, {"referenceID": 28, "context": "0 LLL-nocoref Shallow linguistic kernel (Giuliano et al., 2006) 54.", "startOffset": 40, "endOffset": 63}, {"referenceID": 28, "context": "6 LLL-all Shallow linguistic kernel (Giuliano et al., 2006) 56.", "startOffset": 36, "endOffset": 59}, {"referenceID": 47, "context": "6 LLL-all Gap-weighted string kernel (Lodhi et al., 2002) 56.", "startOffset": 37, "endOffset": 57}, {"referenceID": 58, "context": "LLL-all Sbest (N\u00e9dellec, 2005) 60.", "startOffset": 14, "endOffset": 30}, {"referenceID": 63, "context": "The experiments we report here are done using the first setting and can be directly compared against the methods described in the work of S\u00e6tre et al. (2008), Erkan et al.", "startOffset": 138, "endOffset": 158}, {"referenceID": 18, "context": "(2008), Erkan et al. (2007) and Giuliano et al.", "startOffset": 8, "endOffset": 28}, {"referenceID": 18, "context": "(2008), Erkan et al. (2007) and Giuliano et al. (2006). In addition, we use the same dependency paths for the LA kernel as the ones employed by S\u00e6tre et al.", "startOffset": 8, "endOffset": 55}, {"referenceID": 0, "context": "The results by Airola et al. (2008) and by Bunescu (2007) are obtained by cross-validating on the level of documents.", "startOffset": 15, "endOffset": 36}, {"referenceID": 0, "context": "The results by Airola et al. (2008) and by Bunescu (2007) are obtained by cross-validating on the level of documents.", "startOffset": 15, "endOffset": 58}, {"referenceID": 0, "context": "The results by Airola et al. (2008) and by Bunescu (2007) are obtained by cross-validating on the level of documents. We conducted experiments by setting the distributional measure to Dice, referred to as LA-Dice in Table 8. In the upper part of the table we used dependency paths generated by the Stanford parser and in the lower part those obtained by Enju. As we discussed in Section 2, Erkan et al. (2007) use similarity measures to compare dependency paths, but they do not consider any additional sources whose information can be incorporated into the learning procedure.", "startOffset": 15, "endOffset": 410}, {"referenceID": 0, "context": "The results by Airola et al. (2008) and by Bunescu (2007) are obtained by cross-validating on the level of documents. We conducted experiments by setting the distributional measure to Dice, referred to as LA-Dice in Table 8. In the upper part of the table we used dependency paths generated by the Stanford parser and in the lower part those obtained by Enju. As we discussed in Section 2, Erkan et al. (2007) use similarity measures to compare dependency paths, but they do not consider any additional sources whose information can be incorporated into the learning procedure. They, however, experiment with supervised (SVM) and semi-supervised learning (TSVM), where the number of training instances is varied. Table 8 shows the best performance that was achieved by Erkan et al.\u2019s (2007) method.", "startOffset": 15, "endOffset": 791}, {"referenceID": 0, "context": "The results by Airola et al. (2008) and by Bunescu (2007) are obtained by cross-validating on the level of documents. We conducted experiments by setting the distributional measure to Dice, referred to as LA-Dice in Table 8. In the upper part of the table we used dependency paths generated by the Stanford parser and in the lower part those obtained by Enju. As we discussed in Section 2, Erkan et al. (2007) use similarity measures to compare dependency paths, but they do not consider any additional sources whose information can be incorporated into the learning procedure. They, however, experiment with supervised (SVM) and semi-supervised learning (TSVM), where the number of training instances is varied. Table 8 shows the best performance that was achieved by Erkan et al.\u2019s (2007) method. Among models based on SVM, the one with Cosine distance, SVM-Cos, yields the best results. In the TSVM setting, the one with the Edit measure performs the best. We observe that LA-Dice slightly outperforms both and has, in particular, high precision. In their work, S\u00e6tre et al. (2008) explore several parsers and combinations of features.", "startOffset": 15, "endOffset": 1085}, {"referenceID": 68, "context": "In general, the method by S\u00e6tre et al. also uses SVM, but in this case it focuses on tree kernels (discussed in Section 2.3.3). To make a fair comparison, we conducted experiments on the paths obtained by deep syntactic analysis (Enju parser) and compared our scores against S\u00e6tre et al.\u2019s (2008) results.", "startOffset": 26, "endOffset": 297}, {"referenceID": 4, "context": "02 Baseline I (Bunescu, 2007) Collins 69.", "startOffset": 14, "endOffset": 29}, {"referenceID": 20, "context": "07 SVM-Cos (Erkan et al., 2007) Stanford 61.", "startOffset": 11, "endOffset": 31}, {"referenceID": 20, "context": "09 TSVM-Edit (Erkan et al., 2007) Stanford 59.", "startOffset": 13, "endOffset": 33}, {"referenceID": 47, "context": "96 Gap-weighted string kernel (Lodhi et al., 2002) Stanford 67.", "startOffset": 30, "endOffset": 50}, {"referenceID": 68, "context": "40 Tree kernel (S\u00e6tre et al., 2008) Enju 76.", "startOffset": 15, "endOffset": 35}, {"referenceID": 68, "context": "0 Tree kernel (S\u00e6tre et al., 2008) Enju+KSDEP+W 78.", "startOffset": 14, "endOffset": 34}, {"referenceID": 0, "context": "5 Graph kernel (Airola et al., 2008) Charniak-Lease 52.", "startOffset": 15, "endOffset": 36}, {"referenceID": 28, "context": "4 Shallow linguistic kernel (Giuliano et al., 2006) none 60.", "startOffset": 28, "endOffset": 51}, {"referenceID": 15, "context": "Likewise, the Collins parser is a statistical parser (Collins, 1999).", "startOffset": 53, "endOffset": 68}, {"referenceID": 27, "context": "Many participants of this challenge considered WordNet either explicitly (Tribble & Fahlman, 2007; Kim & Baldwin, 2007), or as a part of a complex system (Giuliano et al., 2007).", "startOffset": 154, "endOffset": 177}, {"referenceID": 32, "context": "Since it is not always obvious how to use WordNet so that it yields the best performance, many researchers have made additional decisions such as use of supersenses (Hendrickx et al., 2007), selection of a predefined number of high-level concepts (Nulty, 2007), or cutting the WordNet hierarchy at a certain level (Bedmar et al.", "startOffset": 165, "endOffset": 189}, {"referenceID": 60, "context": ", 2007), selection of a predefined number of high-level concepts (Nulty, 2007), or cutting the WordNet hierarchy at a certain level (Bedmar et al.", "startOffset": 65, "endOffset": 78}, {"referenceID": 2, "context": ", 2007), selection of a predefined number of high-level concepts (Nulty, 2007), or cutting the WordNet hierarchy at a certain level (Bedmar et al., 2007).", "startOffset": 132, "endOffset": 153}, {"referenceID": 2, "context": ", 2007), selection of a predefined number of high-level concepts (Nulty, 2007), or cutting the WordNet hierarchy at a certain level (Bedmar et al., 2007). Some other systems such as the one by Nakov (2007) were based solely on information collected from the Web.", "startOffset": 133, "endOffset": 206}, {"referenceID": 24, "context": "Note that in the Task 4 overview paper, Girju et al. (2007) reported on three baselines, which, in their case, were (i) guessing \u2018true\u2019 or \u2018false\u2019 for all examples, depending on which class is the majority class in the test set (Baseline III), (ii) always guessing \u2018true\u2019 (Baseline IV), and (iii) guessing \u2018true\u2019 or \u2018false\u2019 with the probability that corresponds to the class distribution in the test set (Baseline V).", "startOffset": 40, "endOffset": 60}, {"referenceID": 1, "context": "Moreover, when compared to the best results of the SemEval-2007 competition (Beamer et al., 2007), our method approaches performance yielded by the best system (bestSV ).", "startOffset": 76, "endOffset": 97}, {"referenceID": 1, "context": "Moreover, when compared to the best results of the SemEval-2007 competition (Beamer et al., 2007), our method approaches performance yielded by the best system (bestSV ). This system used not only various lexical, syntactic, and semantic feature sets, but also expanded the training set by adding examples from many different sources. We have already mentioned in Section 2 that the recent work by \u00d3 S\u00e9aghdha (2009) explores WordNet structure and graph kernels to classify semantic relations.", "startOffset": 77, "endOffset": 416}, {"referenceID": 47, "context": "4 Gap-weighted string kernel (Lodhi et al., 2002) 61.", "startOffset": 29, "endOffset": 49}, {"referenceID": 27, "context": "This finding is in line with the results of Giuliano et al. (2007) whose system was a combination of kernels on the same data.", "startOffset": 44, "endOffset": 67}, {"referenceID": 30, "context": "Some other recent work on the SemEval Task 4 data set includes investigation of distributional kernels (\u00d3 S\u00e9aghdha & Copestake, 2008), pattern clusters (Davidov & Rappoport, 2008), relational similarity (Nakov & Hearst, 2008), and WordNet kernels. Unlike WordNet kernels, the first three approaches do not use WordNet. \u00d3 S\u00e9aghdha and Copestake (2008) report an accuracy of 70.", "startOffset": 212, "endOffset": 351}, {"referenceID": 18, "context": "5 as the best results yielded by distributional kernels and the best performance of Davidov and Rappoport\u2019s (2008) method is an accuracy of 70.", "startOffset": 84, "endOffset": 115}, {"referenceID": 60, "context": "F-score is comparable to the performance reported by \u00d3 S\u00e9aghdha and Copestake (2008) and by Davidov and Rappoport (2008).", "startOffset": 55, "endOffset": 85}, {"referenceID": 18, "context": "F-score is comparable to the performance reported by \u00d3 S\u00e9aghdha and Copestake (2008) and by Davidov and Rappoport (2008).", "startOffset": 92, "endOffset": 121}, {"referenceID": 42, "context": "For instance, Lee (1999) uses them to detect similar nouns based on verb-object co-occurrence pairs.", "startOffset": 14, "endOffset": 25}, {"referenceID": 42, "context": "For instance, Lee (1999) uses them to detect similar nouns based on verb-object co-occurrence pairs. The results suggest the Jaccard coefficient (which is related to the Dice measure) to be one of the best performing measures followed by some others including Cosine. Euclidean distance fell into the group with the largest error rates. Given previous work by Lee (1999), one would expect Euclidean distance to achieve worse results than", "startOffset": 14, "endOffset": 371}, {"referenceID": 3, "context": "For example, Budanitsky and Hirst (2006) use semantic relatedness measures to detect malapropism and show that Jiang and Conrath\u2019s measure (jcn) yields the best results, followed by Lin\u2019s measure (lin), and the one by Leacock and Chodorow (lch), and then by Resnik\u2019s measure (res).", "startOffset": 13, "endOffset": 41}, {"referenceID": 47, "context": "For this reason, we have also applied the gap-weighted string kernel (Lodhi et al., 2002) to all data sets.", "startOffset": 69, "endOffset": 89}, {"referenceID": 0, "context": "The LA kernel also achieves the best performance on the LLL training set, outperforming the graph kernel (Airola et al., 2008), the shallow linguistic kernel (Giuliano et al.", "startOffset": 105, "endOffset": 126}, {"referenceID": 28, "context": ", 2008), the shallow linguistic kernel (Giuliano et al., 2006) and the rule-based system by Fundel et al.", "startOffset": 39, "endOffset": 62}, {"referenceID": 0, "context": "The LA kernel also achieves the best performance on the LLL training set, outperforming the graph kernel (Airola et al., 2008), the shallow linguistic kernel (Giuliano et al., 2006) and the rule-based system by Fundel et al. (2007). All three have used different input for their methods, varying from plain text to dependency structures.", "startOffset": 106, "endOffset": 232}, {"referenceID": 68, "context": "Two other approaches whose performance has been reported on the AImed data set include the tree kernel (S\u00e6tre et al., 2008) and TSVM (Erkan et al.", "startOffset": 103, "endOffset": 123}, {"referenceID": 20, "context": ", 2008) and TSVM (Erkan et al., 2007).", "startOffset": 17, "endOffset": 37}, {"referenceID": 20, "context": ", 2008) and TSVM (Erkan et al., 2007). Both of them explore syntactic information in different ways. While S\u00e6tre et al. consider subtrees, the method of Erkan et al. has more similarities with our approach because it relies on the dependency path comparison. To do this comparison, they only use information already available in the dependency paths (SVM setting), or more dependency paths (TSVM setting). According to Lauer and Bloch (2008), TSVMs fall into the category using prior knowledge by \u2018sampling methods\u2019, because it explores prior knowledge by generating new examples.", "startOffset": 18, "endOffset": 442}, {"referenceID": 46, "context": "In our experiments, the scaling parameter \u03b2 contributes to the overall performance at most, but the other parameters such as gap values have to be taken into account as well. When \u03b2 approaches infinity, the LA kernel approximates the Smith-Waterman distance, but increasing \u03b2 does not necessarily have a positive impact on the final performance. This finding is in line with the results reported by Saigo et al. (2004) on the homology detection task.", "startOffset": 27, "endOffset": 419}, {"referenceID": 83, "context": "It may be interesting to consider relational similarity (Turney, 2006), which looks for the correspondence between relation instances.", "startOffset": 56, "endOffset": 70}, {"referenceID": 52, "context": "Recently, Mohammad (2008) in his thesis investigated the compatibility of distributional measures with ontological ones.", "startOffset": 10, "endOffset": 26}, {"referenceID": 46, "context": "The preliminary version of this work has been dicussed at the 22nd International Conference on Computational Linguistics (CoLing 2008) and at the Seventh International Tbilisi Symposium on Language, Logic and Computation (2007). This work was carried out in the context of the Virtual Laboratory for e-Science project (www.", "startOffset": 109, "endOffset": 228}], "year": 2010, "abstractText": "This paper discusses the problem of marrying structural similarity with semantic relatedness for Information Extraction from text. Aiming at accurate recognition of relations, we introduce local alignment kernels and explore various possibilities of using them for this task. We give a definition of a local alignment (LA) kernel based on the Smith-Waterman score as a sequence similarity measure and proceed with a range of possibilities for computing similarity between elements of sequences. We show how distributional similarity measures obtained from unlabeled data can be incorporated into the learning task as semantic knowledge. Our experiments suggest that the LA kernel yields promising results on various biomedical corpora outperforming two baselines by a large margin. Additional series of experiments have been conducted on the data sets of seven general relation types, where the performance of the LA kernel is comparable to the current state-of-the-art results.", "creator": "TeX"}}}