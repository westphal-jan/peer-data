{"id": "1409.0553", "review": {"conference": "arxiv", "VERSION": "v1", "DATE_OF_SUBMISSION": "1-Sep-2014", "title": "Sampling-based Approximations with Quantitative Performance for the Probabilistic Reach-Avoid Problem over General Markov Processes", "abstract": "this article equally deals favorably with stochastic processes automatically endowed with the markov ( memoryless ) property and actively evolving over general ( uncountable ) state configuration spaces. the improved models further depend on a non - deterministic quantity in the usual form capable of a control parameter input, typically which can typically be selected to accurately affect studying the probabilistic dynamics. we address the approximate synthesis concerns of optimal controllers theories that maximize the probability associated to a rather general property of optimal interest, possibly known as constructing the \" reach - avoid avoid \" specification. continuing the reach - avoid specification deals with assessing raising the likelihood that terminating any finite - horizon trajectory of the entire model system enters over a appropriately given goal set, while avoiding a similarly given response set consists of globally undesired discrete states ( previously both somewhat arbitrary subsets admit of violating the closed state - space ). again equivalently, the property can be expressed directly as randomly entering a generic goal set, interpreted while currently dwelling within a set of allowed states. the reach - avoid property is a well historically known specification that arguably lies at the core of a number complex of sophisticated modal logics traditionally used in applying the field of formal geometry verification, named and which is theoretically relevant for specialized safety - critical algorithms applications therefore ranging internally from cellular robotics control to improving air traffic management. this article by newly explicitly provides for an approximate computational sample scheme reconstructed for the reach - avoid modification specification based on the earlier fitted value - iteration algorithm, \u2020 which hinges strictly on efficient random sample extractions, and newly derives on new formal probabilistic deviation bounds on executing the previous error statement made by adding the robust approximation algorithm : as are such, the output of the updated numerical screening scheme version is quantitatively assessed and considers thus purely meaningful for safety - critical applications independently of the property of interest. furthermore, this contribution provides tighter formal sample - based mathematical probabilistic error bounds for the computation result of triggering the partial reach - avoid compensation problem based on the fitted fitted value iteration. the overall algorithms computational scheme is put in relationship with specific alternative trajectory approximation algorithms in solving the literature, that and finally establishing its detection performance is once practically assessed over purely a reliable benchmark case literature study.", "histories": [["v1", "Mon, 1 Sep 2014 20:03:48 GMT  (538kb)", "https://arxiv.org/abs/1409.0553v1", null], ["v2", "Wed, 9 Sep 2015 20:20:13 GMT  (540kb)", "http://arxiv.org/abs/1409.0553v2", null]], "reviews": [], "SUBJECTS": "cs.SY cs.LG", "authors": ["sofie haesaert", "robert babuska", "alessandro abate"], "accepted": false, "id": "1409.0553"}, "pdf": {"name": "1409.0553.pdf", "metadata": {"source": "CRF", "title": "Sampling-based Approximations with Quantitative Performance for the Probabilistic Reach-Avoid Problem over General Markov Processes", "authors": ["Sofie Haesaert", "Robert Babuska"], "emails": ["s.haesaert@tue.nl", "r.babuska@tudelft.nl", "alessandro.abate@cs.ox.ac.uk"], "sections": [{"heading": null, "text": "ar X\niv :1\n40 9.\n05 53\nv2 [\nKeywords: General state-space processes, reach-avoid problem, dynamic programming, fitted value iteration, computational approximation with error bounds."}, {"heading": "1. Introduction", "text": "This contribution concerns a problem grounded in concepts from a few different areas: we deal with probabilistic processes evolving over continuous (and in particular uncountable) state spaces \u2013 this leads to the use of measure-theoretical material from Stochastic Processes and Probability Theory (Meyn and Tweedie, 1993); we work with models endowed with a\ncontrol input and investigate control synthesis, which relate to a broad literature in Control Theory (Bertsekas and Shreve, 1996); furthermore, we are interested in quantifying the probability associated to a dynamical property, known as reach-avoid, which corresponds to a widely used model specification in the field of Formal Verification (Baier and Katoen, 2008); and finally we employ a sampling-based algorithm to approximately compute the likelihood associated to the above specification. The algorithm, known as Fitted Value Iteration (FVI) (Munos and Szepesvari, 2008), is a regression scheme developed in Machine Learning.\nWe focus on stochastic processes endowed with the Markov property (where the future is independent of the past, conditional on the present) and, aiming for generality, we deal with processes evolving over a continuous state space. We are further interested in a class of such models known as stochastic hybrid systems (SHS) (Abate et al., 2008), which are endowed with a \u201chybrid\u201d (that is, both continuous and discrete) state space, which are relevant for a number of applications in Engineering and the Life Sciences (Blom and Lygeros, 2006; Cassandras and J. Lygeros, 2006). This work investigates the problem of controller synthesis over these models, namely the selection of sequences of control inputs (which in particular can be functions of the states of the model) over a finite time horizon, in order to optimise a given figure of merit.\nAs for the figure of merit of interest in this work, we choose to go beyond the classical properties investigated in Systems and Control theory, which by and large deal with known and standard problems of stability, regulation, and tracking. Instead, we focus on the reachavoid specification, a property that is well known and central within the Formal Verification field (Baier and Katoen, 2008). Notice that classical results in Formal Verification deal with simple models \u2013 usually finite-state transition systems or Markov chains \u2013 which allow for the development of computational results, and which mostly deal with verification tasks that do not involve policy synthesis. In this work instead we consider reach-avoid specifications over models with continuous stochastic transitions and endowed with control inputs.\nThe reach-avoid problem deals with computing the likelihood that, within a given finite time horizon, a trajectory of the model enters a goal set, while avoiding a given set of undesired states (both sets are arbitrary measurable subsets of the state space). Equivalently, the property can be expressed as the probability that the process enters a goal set while dwelling within a set of allowed states. The reach-avoid property is a generalization of widely studied properties, such as reachability and invariance, and represents a known specification (denoted as \u201cbounded until\u201d) that lies at the core of a number of modal logics used in the field of formal verification, such as Linear Temporal Logic and Computational Time Logic (Baier and Katoen, 2008). From a controller synthesis perspective, the goal becomes that of either maximizing or minimizing the above specification over the given time horizon.\nIn the context of probabilistic models evolving over continuous domains and in discrete time (which is the framework considered in this work), the probabilistic reachability and reach-avoid specifications have been investigated in (Abate et al., 2008; Summers and Lygeros, 2010). These results have recently led to the study of other properties, either richer (Abate et al., 2011) or defined over unbounded time horizons (Tkachev and Abate, 2014). These results have focused on the theoretical characterization of the specifications/properties\nof interest: of course it is also of much interest to provide algorithms that can numerically compute these figures. Computational approaches to probabilistic reachability have been studied in (Abate et al., 2010; Esmaeil Zadeh Soudjani and Abate, 2013): the strength of these results is that the proposed numerical schemes have explicitly quantified error bounds. This is unlike other, known approximation schemes in the literature (Koutsoukos and Riley, 2006; Kushner and Dupuis, 2001; Prandini and Hu, 2006), which provide results with properties that are only known asymptotically.\nThis article provides a new approximate computational scheme for the reach-avoid specification based on the Fitted Value Iteration algorithm, which hinges on random sample extractions. This work originally derives formal probabilistic bounds on the error made by the approximation algorithm. In order to do so, the FVI scheme is tailored to the characterization of the reach-avoid problem, which leads to Dynamic Programming (DP) recursions based on a sum-multiplicative form that is non-standard since it departs from the classical additive (possibly discounted) cost functions (Bertsekas and Shreve, 1996). Starting from the regression bounds in Munos and Szepesvari (2008), this work includes new results on the error for the FVI approximation and a-priori performance guarantees. Additionally, novel and tighter probabilistic error bounds for dynamic programming solutions of the reach-avoid problem based on samples extraction are presented. As a comparison to the alternative techniques in the literature (Abate et al., 2010; Esmaeil Zadeh Soudjani and Abate, 2013), we show the related techniques provide bounds that are valid deterministically, whereas the proposed result yields tighter results in general that are valid with a certain (tunable) confidence. The outcomes lead to an approach providing controller synthesis with a certified performance, which is relevant for safety-critical applications (Blom and Lygeros, 2006). The proofs of the statements are included in the Appendix."}, {"heading": "2. Probabilistic Reach-Avoid Problem over General Markov Processes", "text": "Definition 1 (General Markov process) A discrete-time general Markov process is comprised of:\n\u2022 A continuous (uncountable) state space X \u2282 Rn;\n\u2022 An action space A = {a1, . . . , am} consisting of a finite number of actions;\n\u2022 A Borel-measurable stochastic kernel Tx, which assigns to each state-action pair x \u2208 X and a \u2208 A a probability distribution Tx (\u00b7 | x, a) over X .\nWe denote with (X ,B(X ), P ) a probability structure on X , where B(X ) is the \u03c3-algebra associated to X and P is characterized as P (y \u2208A|x\u2208X , a\u2208A)= \u222b\nA Tx(dy|x, a). We assume that the stochastic kernels admit densities so that \u222b\nA Tx (dy | x, a) = \u222b A tx (y | x, a) dy.\nDefinition 2 (Markov policy) A Markov policy \u00b5 over horizon [0, Nt] is a sequence \u00b5 = (\u00b50, \u00b51, . . . , \u00b5Nt\u22121) of universally measurable maps, \u00b5k : X \u2192 A, k = 0, 1, . . . , Nt \u2212 1, from the state space X to the action space A. The set of Markov policies is denoted as M.\nThe evolution of the general Markov process is considered over a finite horizon k = 0, 1, . . . , Nt, with Nt \u2208 N. Consider a discrete-time general Markov process, a Markov policy \u00b5, a deterministic initial state x0 \u2208 X and a finite time horizon Nt: an execution of the process characterizes a state trajectory given as {xk|k = 0, 1, . . . , Nt}. The process evolves over the product space (X )Nt+1, which is again endowed with a (product) \u03c3-algebra and allows computing probability associated to events over trajectories \u2013 we denote this probability by P, and further define the probabilities Px0 ,P \u00b5 x0 as P conditioned on an initial state and on an initial state and a policy, respectively. The state at the (k + 1)-st time instant, xk+1, is obtained as a realization of the controlled Borel-measurable stochastic kernel Tx (\u00b7 | xk, \u00b5k(xk)). The model can be initialized according to an initial probability measure P0 \u2208 M(X ), where M(\u00b7) denotes the collection of probability distributions over a given set."}, {"heading": "2.1 Probabilistic Reach-Avoid Problem: Definition", "text": "Let us define the probabilistic reach-avoid problem, also known as constrained reachability (Baier and Katoen, 2008), and provide its characterization. Consider a safe set A \u2208 B(X ), a target set K \u2208 B(X ), and a finite time horizon Nt \u2208 N. A given state trajectory {xk|k = 0, 1, . . . , Nt} verifies the reach-avoid property if it reaches the target set K within the time horizon, while staying inside the safe set A. This property can be expressed as\n\u2203j \u2208 [0, Nt] : xj \u2208 K \u2227 \u2200i \u2208 [0, j \u2212 1] : xi \u2208 A \\K.\nLet us now consider the probabilistic reach-avoid property for a general stochastic system, defined as the probability that an execution associated with a fixed Markov policy \u00b5 \u2208 M and an initial condition x0 \u2208 X reaches the target set K while avoiding X \\ A. Formally,\nr\u00b5x0(K,A) = P \u00b5 x0 {\u2203j \u2208 [0, Nt] : xj \u2208 K \u2227 \u2200i \u2208 [0, j \u2212 1] : xi \u2208 A \\K} , (1)\nwhere the states x0, x1, . . . , xNt \u2208 X are sampled via the stochastic kernel Tx under policy \u00b5. The formula contained in (1) can be written as a boolean expression using indicator functions, which leads to an expectation over the state trajectories as\nr\u00b5x0(K,A) = E \u00b5 x0\n[\n\u2211\nj\u2208[0,Nt]\n(\n\u220fj\u22121 i=0 1A\\K(xi)\n)\n1K(xj)\n]\n,\nwhere 1B(x) = 1 if x \u2208 B, else it is equal to 0. The reach-avoid problem subsumes other known problems widely studied in System and Control Theory and in Formal Verification, such as that of reachability of set K, which is simply obtained by selecting A = X , or that of invariance within a set B, which is characterized as the dual of the reachability problem over set X \\B.\nFor a given policy \u00b5, the time-dependent value function Wk : X \u2192 [0, 1], defined as\nW \u00b5k (x)= E \u00b5\n[\n\u2211\nj\u2208[k+1,Nt]\n(\nj\u22121 \u220f\ni=k+1\n1A\\K(xi)\n)\n1K(xj)\n\u2223 \u2223 \u2223 \u2223 xk = x ] ,\nis the probability that the state trajectory {xk+1, . . . , xNt}, starting from xk, will reach the target set K within the time horizon [k,Nt], while staying within the safe set A. This function allows expressing the reach-avoid probability backward recursively, as follows.\nProposition 3 Given a policy \u00b5 = (\u00b50, \u00b51, . . . , \u00b5Nt\u22121), define function W \u00b5 k : X \u2192 [0, 1] by backward recursion\nW \u00b5k (x) = E \u00b5k x [ 1K(xk+1) + 1A\\K(xk+1)W \u00b5 k+1(xk+1) ] ,\nand initialized with W \u00b5Nt(x) = 0. Then for any initial state x0 \u2208 X , the probabilistic reachavoid property r\u00b5x0(K,A) can be expressed as\nr\u00b5x0(K,A) = 1K(x0) + 1A\\K(x0)W \u00b5 0 (x0) .\nProof The proof follows (Summers and Lygeros, 2010, Lemma 4), where the above statement is proven for a value function V \u00b5k (x) = 1K(x) + 1A\\K(x)W \u00b5 k (x).\nNotice that, while the probabilistic reach-avoid problem has been formulated above via DP recursions, it hinges on a sum-multiplicative characterization which is non-standard: much of the analytical and computational results in DP are formulated for additive (possibly discounted) cost functions (Bertsekas and Shreve, 1996).\nRather than selecting and fixing a policy \u00b5 as done above, we now focus on the controller synthesis problem, which seeks the Markov policy \u00b5\u2217 that maximizes the probabilistic reach-avoid property, and which is such that r\u2217x0(K,A) = sup\u00b5\u2208M r \u00b5 x0(K,A). Let us emphasize that the optimization is over finite-action policies, which are however functions of the continuous state space. The optimal policy can be characterized as follows.\nProposition 4 Define functions W \u2217k : X \u2192 [0, 1], by the backward recursions\nW \u2217k (x) = max a\u2208A Eax [ 1K(xk+1) + 1A\\K(xk+1)W \u2217 k+1(xk+1) ] ,\nwith xk+1 \u223c Tx (\u00b7 | x, a) for k = Nt \u2212 1, Nt \u2212 2, . . . , 0, and initialized by W \u2217Nt(x) = 0. Then for any initial state x0 \u2208 X the optimal probabilistic reach-avoid property r\u2217x0(K,A) can be expressed as\nr\u2217x0(K,A) = 1K(x0) + 1A\\K(x0)W \u2217 0 (x0).\nFurthermore, \u00b5\u2217k : X \u2192 A for k = Nt \u2212 1, Nt \u2212 2, . . . , 0, is such that \u2200x \u2208 X :\n\u00b5\u2217k(x) = argmax a\u2208A Eax [ 1K(xk+1)+1A\\K(xk+1)W \u2217 k+1(xk+1) ]\nand \u00b5\u2217 = (\u00b5\u22170, \u00b5 \u2217 1, . . . , \u00b5 \u2217 Nt\u22121 ) is the optimal probabilistic reach-avoid Markov policy.\nProof See again (Summers and Lygeros, 2010, Theorem 6) and (Abate et al., 2008).\nFor a given time horizon Nt, the computation of r \u2217 x0(K,A), as in Proposition 4, can be seen as the application ofNt mappings. More precisely, let us define a dynamic programming operator T as W \u2217k = TW \u2217 k+1, such that for all states x \u2208 X , the function W \u2217k : X \u2192 [0, 1] is defined as\nW \u2217k (x) = ( TW \u2217k+1 ) (x) (2)\n= max a\u2208A\nEax [ 1K(xk+1)+1A\\K(xk+1)W \u2217 k+1(xk+1) ] .\nThe value of the optimal probabilistic reach-avoid property can be written as the composition of Nt mappings,\nr\u2217x0(K,A) = 1K(x0) + 1A\\K(x0) ( T NtW \u2217Nt ) (x0)."}, {"heading": "2.2 Computation of the Reach-Avoid Probability", "text": "Notice that generally it is not possible to solve the above recursions exactly: in order to determine the backwards iteration at a single point xi \u2208 X , namely W \u2217k (xi) = ( TW \u2217k+1 )\n(xi), one should exactly solve (2). The exact solution of (2) however is seldom analytical and can possibly result in computationally expensive procedures. The absence of an analytical representation for W \u2217k : X \u2192 [0, 1] leads to the use of approximation techniques, which can be categorized in two families:\n1. Numerical approximation techniques, which provide an approximation of the optimal probabilistic reach-avoid problem with actual error bounds. More precisely, for a given error bound \u2206 > 0 we seek a numerical scheme that obtains an approximation r\u0302\u2217x0(K,A), which is such that |r\u0302\u2217x0(K,A) \u2212 r\u2217x0(K,A)| \u2264 \u2206. This approach is taken in (Abate et al., 2010; Esmaeil Zadeh Soudjani and Abate, 2013), and the scheme is prone to suffer from the curse of dimensionality, since it approximates a general stochastic system with a Markov chain by partitioning the state space. 2. Probabilistic approximation techniques, which approximate the original problem with probabilistic guarantees. The obtained approximation scheme r\u0302\u2217x0(K,A) for r \u2217 x0(K,A)\ndepends on a finite number of samples or sampled paths of the underlying model. For a given error bound\u2206 > 0 and confidence 1\u2212\u03b4\u2206, the probability that the approximation is not close to the the optimal value can be bounded probabilistically as\nP { \u2223 \u2223r\u0302\u2217x0(K,A) \u2212 r\u2217x0(K,A) \u2223 \u2223 > \u2206 } \u2264 \u03b4\u2206. (3)\nIn this work, we newly pursue the second approach by focusing on results from the area of learning, and in particular on algorithms for functional approximations. A learning approach is suitable for complex systems, such as general Markov processes, since it replaces model-based evaluations by model-free, sample-based evaluations (Busoniu et al., 2010). We adopt the Fitted Value Iteration scheme (FVI) (Munos and Szepesvari, 2008), a learning algorithm fit in particular for finite horizon settings. In practice, bounds for probabilistic approximation methods (3) can be divided into two groups. Firstly, general model-free and sample-free bounds, which provide a-priori guarantees on the achievable accuracy for a finite sample set. Though they can show convergence in probability up to a bias term, their generality can render them conservative when used\nas a tool to assign an accuracy guarantee. Alternatively, model-based and sample-based bounds: these bounds verify the accuracy of a dynamic programming scheme by drawing samples of the model and using available information from the model, and from the specific reach-avoid property under study. In the analysis of the algorithm these bounds can be perceived as complementary. A-priori and sample-free bounds are derived in Section 4 based on model-free/distribution-free notions, whereas model-based and sample-based bounds are given in Section 5."}, {"heading": "3. Fitted Value Iteration", "text": "In this section we consider a learning algorithm that has been developed to solve additivecost optimal control problems, and adapt it to the reach-avoid optimal control setting. Known as FVI Munos and Szepesvari (2008), the algorithm extracts a finite number of samples from the underlying model to numerically approximate the value recursions in (2). More precisely, the scheme generalizes the information gathered from the samples to approximate the \u201cexact\u201d optimal value function W \u2217k as W\u0302 \u2217 k in two steps: first by estimating W \u2217k over a finite number of states, thereafter fitting the analytical function W\u0302 \u2217 k \u2208 W to the estimate. We define W to be a strict subset of B(X ; 1), the class of measurable functions defined over X , lower bounded by 0 and upper bounded by 1.\nAlgorithm 1: Sample generation for the FVI algorithm\nGiven a safe set A, a target set K, a time horizon Nt, and distribution \u03b7, generate N base points, and M samples at each base point as follows:\n1. Draw N base points ( xik ) 1\u2264i\u2264N from the distribution \u03b7 in A \\K; 2. Draw M samples at each base point xik and at each actions a \u2208 A from the stochastic kernel Tx, and denote the set of samples as ( xi,a,jk+1 )\n1\u2264j\u2264M .\nThe FVI algorithm employs samples that are generated by the underlying model. Samples referred to as \u201cbase points\u201d are taken from a chosen distribution \u03b7, and additional samples are drawn at the base points from the transition kernel. Algorithm 1 summarizes the sample generation. Let us remark that at each iteration k = Nt \u2212 1, . . . , 0, a new set of samples is generated and used. We denote as \u201csample complexity\u201d the cardinality of the sample generation, namely N and M .\nAt each (backward) iteration k = Nt \u2212 1, . . . , 0, the algorithm executes two steps in order to approximate the exact recursion in (2):\n1. The first step consists of estimating the value of the backward mapping (TW\u0302 \u2217k+1)(x i k)\nat N base points xik. The recursion (TW\u0302 \u2217 k+1)(x i k) is estimated by an empirical operator T\u0302 as follows:\n( T\u0302W\u0302 \u2217k+1 ) (xik) = max a\u2208A\n1\nM\nM \u2211\nj=1\n1K(x i,a,j k+1) + 1A\\K(x i,a,j k+1)W\u0302 \u2217 k+1(x i,a,j k+1). (4)\nHere xi,a,jk+1 represent M independent and identically distributed realizations obtained from Tx ( \u00b7 | xik, a ) . Hence, j \u2208 [1,M ], i \u2208 [1, N ], and a \u2208 A. For an increasing number\nof samples xi,a,jk+1 , the estimate (T\u0302W\u0302 \u2217 k+1)(x i k) converges to (TW\u0302 \u2217 k+1)(x i k) with probability 1, by the law of large numbers.\n2. In the second step, function W\u0302 \u2217k \u2208 W is estimated as the solution of\nW\u0302 \u2217k = arg min w\u2208W\nN \u2211\ni=1\n\u2223 \u2223 \u2223 w(xik)\u2212 T\u0302W\u0302 \u2217k+1(xik) \u2223 \u2223 \u2223 p . (5)\nWe assume that the argument of the minimum belongs to the function class (this fact will be further discussed below). The base points (xik)1\u2264i\u2264N are independently drawn from a distribution \u03b7 supported over the set A \\K. The power factor p \u2265 1 is a given positive number. Given a function w(x) and an increasing value of N , the summation in (5) converges to \u222b\nA\\K |w(x)\u2212T\u0302W\u0302 \u2217k+1(x)|p\u03b7(x)dx, by the law of large numbers. This leads (cf. Section 4) to the convergence of the argument W\u0302 \u2217k to the optimal fit that minimizes the distance between T\u0302W\u0302 \u2217k+1 and the functions w \u2208 W with respect to the p-norm, weighted by a distribution with density \u03b7 and supported over the set A \\K, namely\n\u2016W\u0302 \u2217k \u2212T\u0302W\u0302 \u2217k+1\u2016p,\u03b7 = ( \u222b\nA\\K\n|W\u0302 \u2217k (x)\u2212T\u0302W\u0302 \u2217k+1(x)|p\u03b7(x)dx )\n1 p\n.\nThe overall FVI algorithm is summarized in Algorithm 2. The iterations are initialized as W\u0302 \u2217Nt(x) = 0, x \u2208 X , and updated over the functions W\u0302 \u2217Nt\u22121, W\u0302 \u2217Nt\u22122, . . . , W\u0302 \u22171 . Finally the value function at k = 0 is approximated at the initial condition x0 with a sample-based integration, similar to (4), using M0 independent and identically distributed realizations of Tx (\u00b7 | x0, a) for all a \u2208 A.\nAlgorithm 2: Fitted Value Iteration algorithm\nGiven an initial condition x0 \u2208 X , a safe set A, a target set K, a time horizon Nt, a set of N base points and of M samples at each base point (for each iteration k), a number p and a distribution \u03b7, perform:\n1. Initialize W\u0302 \u2217Nt(x) = 0, \u2200x \u2208 X ; 2. For k = Nt \u2212 1 to 1 do\n(a) Collect samples (cfr. Algorithm 1); (b) Estimate TW\u0302 \u2217k+1 as ( T\u0302W\u0302 \u2217k+1 )\n(xik) (cfr. (4)) (c) Find the function that minimizes the empirical p-norm as\nW\u0302 \u2217k = arg min w\u2208W\nN \u2211\ni=1\n\u2223 \u2223 \u2223 w(xik)\u2212 T\u0302W\u0302 \u2217k+1(xik) \u2223 \u2223 \u2223 p ;\n3. Collect M0 samples for the single initial condition x0 and for every action a \u2208 A, and estimate W\u0302 \u22170 (x0) as in step (2)(b); 4. Return reach-avoid probability\nr\u0302\u2217x0(K,A) = 1K(x0) + 1A\\K(x0)W\u0302 \u2217 0 (x0), \u2200x0 \u2208 X .\nRemark 5 (Approximately Optimal Policy) The FVI algorithm can be extended to include the synthesis of a policy a = \u00b5\u0302k(x). At every iteration in Algorithm 2, first the policy is estimated at all the base points xik, as the argument of (2)(b). Secondly a classification algorithm is used, providing an approximately optimal policy \u00b5\u0302k : X \u2192 A for each k."}, {"heading": "4. A-Priori Probabilistic Error Bounds", "text": "Let us recall the accuracy of the FVI algorithm as in (3): we say that the FVI algorithm has an accuracy \u2206, with a confidence 1\u2212 \u03b4\u2206, if the probability that the error made by the approximate solution r\u0302\u2217x0(K,A) is larger than \u2206, is upper-bounded by \u03b4\u2206. We explicitly quantify the accuracy in (3) and analyse it in two steps: first by computing a bound on the error of a single iteration (Sec. 4.1); then by studying the propagation of the singlestep error over multiple iterations (Sec. 4.2). Notice that this section provides a-priori bounds which are model- and distribution-free, hence computable before applying the FVI algorithm. Alternatively, a-posteriori error bounds based on an additional sample set are proposed in Section 5."}, {"heading": "4.1 Error Bounds on a Single Iteration of the FVI", "text": "Let TW\u0302 \u2217k+1 : X \u2192 [0, 1] be an unknown map, and consider a function class W \u2282 B(X ; 1). Recall that at each iteration k = Nt\u22121, Nt\u22122, ..., 1, the objective of the learning algorithm is to find a function w \u2208 W that is close to TW\u0302 \u2217k+1 with respect to the following weighted, p-norm:\n\u2016w \u2212 TW\u0302 \u2217k+1\u2016p,\u03b7 = ( \u222b\nX\n\u2223 \u2223 \u2223 w \u2212 TW\u0302 \u2217k+1 \u2223 \u2223 \u2223 p \u03b7(x)dx\n) 1 p\n. (6)\nNotice that if TW\u0302 \u2217k+1 6\u2208 W, the optimal approximation infw\u2208W \u2016w \u2212 TW\u0302 \u2217k+1\u2016p,\u03b7 provides only a lower bound on this error: the presence of this non-zero bias error indicates that the FVI scheme is not asymptotically consistent, namely that the error does not converge to zero for an increasing sample size. Of interest to this work, a general upper bound on infw\u2208W \u2016w \u2212 TW\u0302 \u2217k+1\u2016p,\u03b7 is derived as\ndp,\u03b7(TW,W) = sup g\u2208W inf f\u2208W \u2016f \u2212 Tg\u2016p,\u03b7. (7)\nIn (Munos and Szepesvari, 2008) the bias dp,\u03b7(TW,W) is referred to as the inherent Bellman error of the function space W.\nAs discussed, the FVI algorithm employs empirical estimates, given in (4)-(5), of the quantity in (6). Therefore, the single step error hinges both on the inherent Bellman error, and on the deviations caused by using estimates of the recursion step TW\u0302 \u2217k+1 over the base points (cfr. Section 4.1.1) and of the norm \u2016 \u00b7 \u2016p,\u03b7 as the integral in (6) (cfr. Section 4.1.2). The error contributions depend on the number of samples used (N,M) and on the capacity of the function class W (Section 4.1.2, and Appendix B), whereas they do not depend on the distribution \u03b7, nor on the stochastic state transitions characterizing the model dynamics: as such the bounds are general and \u201cdistribution-free\u201d.\nIn the following subsections, two lemmas are derived, which are necessary to obtain a general upper bound for the single step error. First (Section 4.1.1), the error introduced by\nusing the estimation T\u0302W\u0302 \u2217k+1 of the recursion step is bounded using Hoeffding\u2019s inequality (Hoeffding, 1963). Then in Section 4.1.2 the maximal deviation of the empirical evaluation of the integral in (6) is bounded using methods from Statistical Learning Theory (Vapnik, 1998)."}, {"heading": "4.1.1 Accuracy of the Estimation of TW\u0302 \u2217k+1", "text": "Recall that the estimate ( T\u0302W\u0302 \u2217k+1 ) (xik) of the exact recursion ( TW\u0302 \u2217k+1 ) (xik) uses, for a given state-action pair (xik, a), the individual Monte-Carlo estimates\n1\nM\nM \u2211\nj=1\n1K(x i,a,j k+1) + 1A\\K(x i,a,j k+1)W\u0302 \u2217 k+1(x i,a,j k+1)\nof Ea xi k\n[\n1K(xk+1) + 1A\\K(xk+1)W\u0302 \u2217 k+1(xk+1)\n]\n. Since the cardinality of the action space A is finite, a bound on the error of the estimates for a given state-action pair can lead to a bound on the error over the states xik: we elaborate on this idea next.\nThe M random quantities for 1 \u2264 j \u2264 M , 1K(xi,a,jk+1) + 1A\\K(x i,a,j k+1)W\u0302 \u2217 k+1(x i,a,j k+1), are obtained via independent and identically distributed realizations over the closed interval [0, 1]. Hoeffding\u2019s inequality (Hoeffding, 1963) leads to an upper bound on the deviation of the estimate from the expected value as follows:\nP { \u2223 \u2223\n\u2223 Eaxi\nk\n[\n1K(xk+1) + 1A\\K(xk+1)W\u0302 \u2217 k+1(xk+1)\n]\n\u2212 1 M\nM \u2211\nj=1\n[\n1K(x i,a,j k+1) + 1A\\K(x i,a,j k+1)W\u0302 \u2217 k+1(x i,a,j k+1)\n] \u2223\n\u2223 \u2223 \u2264 \u01eb1\n}\n\u2265 1\u2212 2e\u22122M(\u01eb1)2 ,\nwhere \u01eb1 is the bound on the error. We can then provide a lower bound on the probability that the deviation incurred by the quantity (\nT\u0302W\u0302 \u2217k+1 ) (xik) is bounded by \u01eb1 via the joint probability of |A| independent events, as follows:\nP {\u2223 \u2223\n\u2223 TW\u0302 \u2217k+1(x i k)\u2212 T\u0302W\u0302 \u2217k+1(xik)\n\u2223 \u2223 \u2223 \u2264 \u01eb1 }\n\u2265 \u220f\na\u2208A\nP {\u2223 \u2223\n\u2223 Eaxi\nk\n[\n1K(xk+1) + 1A\\K(xk+1)W\u0302 \u2217 k+1(xk+1)\n]\n\u2212 1 M\nM \u2211\nj=1\n[ 1K(x i,a,j k+1)+1A\\K(x i,a,j k+1)W\u0302 \u2217 k+1(x i,a,j k+1) ]\n\u2223 \u2223 \u2223 \u2264 \u01eb1 } .\nLet us now extend the above probabilistic bound for the error computed at a single point xik to a bound for the error over all the N base points: we can express this bound via an empirical p-norm defined over the base points, as follows:\n\u2016TW\u0302 \u2217k+1\u2212T\u0302W\u0302 \u2217k+1\u2016p,\u03b7\u0302 = ( 1\nN\nN \u2211\ni=1\n\u2223 \u2223 \u2223 TW\u0302 \u2217k+1(x i k)\u2212 T\u0302W\u0302 \u2217k+1(xik) \u2223 \u2223 \u2223 p )1/p . (8)\nThis leads to the following result.\nLemma 6 For a given error bound \u01eb1 and sample complexity N and M , the estimation error can be probabilistically bounded as follows:\nP { \u2016TW\u0302 \u2217k+1 \u2212 T\u0302W\u0302 \u2217k+1\u2016p,\u03b7\u0302 \u2264 \u01eb1 } \u2265 1\u2212 \u03b41, (9)\nwhere \u03b41 = 1\u2212 (1\u2212 2e\u22122M(\u01eb1)2)|A|N , as long as 0 < 2e\u22122M(\u01eb1)2 \u2264 1. Notice that for an increasing number of samples M , by Lemma 6 the empirical norm of the error as in (8) is less than \u01eb1 with a probability that increases to 1."}, {"heading": "4.1.2 Accuracy of the Empirical Norm", "text": "Let TW\u0302 \u2217k+1 : X \u2192 [0, 1] be an unknown function and \u03b7 a probability measure on X , \u03b7 \u2208 M(X ). The objective is to find a function w \u2208 W that is close to TW\u0302 \u2217k+1 with respect to the following expected loss:\ninf w\u2208W \u2016w\u2212TW\u0302 \u2217k+1\u2016pp,\u03b7= inf w\u2208W\n\u222b\nX\n|w(x)\u2212TW\u0302 \u2217k+1(x)|p\u03b7(x)dx.\nThis section provides a bound for the error originating from the use of a finite number of samples to evaluate the loss: this empirical loss is defined as\n\u2016w \u2212 TW\u0302 \u2217k+1\u2016pp,\u03b7\u0302 = 1\nN\nN \u2211\ni=1\n|w(xik)\u2212 TW\u0302 \u2217k+1(xik)|p,\nfor a given set of N random variables drawn independently over A \\K according to xik \u223c \u03b7. Let us express a probabilistic bound on this error that holds uniformly over all functions w \u2208 W as follows:\nP {\nsup w\u2208W\n\u2223 \u2223\u2016w \u2212 TW\u0302 \u2217k+1\u2016pp,\u03b7\u2212\u2016w\u2212TW\u0302 \u2217k+1\u2016pp,\u03b7\u0302 \u2223 \u2223 \u2265 \u01ebp2 } \u2264 \u03b42.\nObserve that since the expected and the empirical losses can be reformulated respectively as the mean and the empirical mean of a loss function, defined informally as f(x) = |w(x) \u2212 TW\u0302 \u2217k+1(x)|p, the above problem can be framed as the uniform convergence of a standard learning problem (Haussler, 1992; Pollard, 1984; Vapnik, 1998). Resorting to related literature, results on bounds for the error probability of the regression of real-valued functions employ capacity concepts (including Rademacher averages, covering numbers, and pseudo dimensions) of a function class (Bartlett et al., 2005; Hoeffding, 1963). We focus on pseudo dimensions to deal with the capacity (or the complexity) of the function class. By results in (Haussler, 1992) and (Pollard, 1984), we obtain the following uniform convergence bound.\nLemma 7 Let W be a set of finitely parameterized, measurable functions on X taking values in the interval [0, 1] with pseudo dimension dimp (W) = d < \u221e. Let (xik)1\u2264i\u2264N be generated by N independent draws according to any distribution \u03b7 on A \\K and let p \u2265 1. Then for any \u01eb2 > 0 we have that\nP\n{\nsup w\u2208W\n\u2223 \u2223\u2016w \u2212 TW\u0302 \u2217k+1\u2016pp,\u03b7 \u2212 \u2016w \u2212 TW\u0302 \u2217k+1\u2016pp,\u03b7\u0302 \u2223 \u2223 \u2265 \u01ebp2 } \u2264 4e(d + 1) ( 32e\n\u01ebp2\n)d\ne\u2212 N\u01eb\n2p 2\n128 . (10)\nThe characterization and computability of the pseudo dimension of a function class is given in Appendix B."}, {"heading": "4.1.3 Global Accuracy of Single Iterations", "text": "The error bounds introduced in Lemmas 6 and 7, together with the inherent Bellman error, yield an upper bound on the error introduced at each iteration, which is recapitulated in the following statement. Since the bounds are independent of the distributions \u03b7 and Tx (\u00b7 | x, a), they are in fact distribution-free bounds (Bartlett et al., 2005).\nTheorem 8 Consider a reach-avoid property defined over a general stochastic system with continuous state space X and finite action space A. Let A \u2282 X and K \u2282 X be Borel measurable sets and fix p \u2265 1, the distribution \u03b7 \u2208 M(A \\K) and W \u2282 B(X ; 1). Pick any W\u0302 \u2217k+1 \u2208 B(X ; 1) and let T\u0302W\u0302 \u2217k+1 and W\u0302 \u2217k be calculated using (4) and (5). For given upper bounds on\nP { \u2016TW\u0302 \u2217k+1 \u2212 T\u0302W\u0302 \u2217k+1\u2016p,\u03b7\u0302 > \u01eb1 } \u2264 \u03b41, and (11) P {\nsup w\u2208W\n\u2223 \u2223\u2016w \u2212 TW\u0302 \u2217k+1\u2016pp,\u03b7 \u2212 \u2016w \u2212 TW\u0302 \u2217k+1\u2016pp,\u03b7\u0302 \u2223 \u2223 > \u01ebp2 } \u2264 \u03b42, (12)\nthe bound on a single step update is as follows:\nP { \u2016W\u0302 \u2217k \u2212 TW\u0302 \u2217k+1\u2016p,\u03b7 > dp,\u03b7(TW\u0302 \u2217k+1,W) + \u01eb } \u2264 \u03b41 + \u03b42, (13)\nwhere the optimal approximation is given as a biasing term defined as dp,\u03b7(TW\u0302 \u2217 k+1,W) = infw\u2208W \u2016w \u2212 TW\u0302 \u2217k+1\u2016p,\u03b7, and the error \u01eb is given as \u01eb = 2\u01eb1 + 2\u01eb2.\nNote that the statement assumes that W\u0302 \u2217k is the unique solution to the optimization problem in (5). This strict assumption can be weakened by adding a tolerance term to the theorem. The quantity dp,\u03b7(TW\u0302 \u2217 k+1,W) admits the inherent Bellman error dp,\u03b7(TW,W) in (7) as a general upper bound."}, {"heading": "4.2 Error Propagation and Global Error Bounds", "text": "We express a global bound on the accuracy of the FVI algorithm \u2223 \u2223r\u0302\u2217x0(K,A) \u2212 r\u2217x0(K,A) \u2223 \u2223 by using the probabilistic bounds (derived in Section 4.1) on the errors introduced by the approximate one-step mappings | (\nT\u0302W\u0302 \u22171 ) (x0) \u2212 ( TW\u0302 \u22171 ) (x0)|, as well as \u2016W\u0302 \u22171 \u2212 TW\u0302 \u22172 \u2016p,\u03b7, \u2016W\u0302 \u22172 \u2212TW\u0302 \u22173 \u2016p,\u03b7, . . . , \u2016W\u0302 \u2217Nt\u22121\u2212TW\u0302 \u2217Nt\u2016p,\u03b7, and by propagating the error introduced by each single iteration to the successive value iterations, as done in the next statement. More precisely, in the following lemma we show that the deviation of the approximate value function W\u0302 \u2217k from the optimal value function T\nNt\u2212kW \u2217Nt can be expressed as a function of this deviation at step k + 1, plus the approximation error introduced at the (Nt \u2212 k)th iteration (which has been bounded above). Recall that the optimal value functions can be written as W \u2217k = T Nt\u2212kW \u2217Nt and that by definition W \u2217 Nt = W\u0302 \u2217Nt .\nLemma 9 Let \u03b7 be the density of a probability distribution with support on A \\K and tx be the density function of the stochastic kernel Tx. Then\n\u2016W\u0302 \u2217k \u2212 TNt\u2212kW\u0302 \u2217Nt\u2016p,\u03b7 \u2264 \u2016W\u0302 \u2217k \u2212 TW\u0302 \u2217k+1\u2016p,\u03b7 +B 1 p\n\u2225 \u2225 \u2225 W\u0302 \u2217k+1 \u2212 TNt\u2212(k+1)W\u0302 \u2217Nt \u2225 \u2225 \u2225\np,\u03b7 ,\nfor k = 0, 1, . . . , Nt \u2212 1, and where B is defined as\nB = sup xk+1\u2208A\\K\n\u222b\nA\\K\nmax a\u2208A tx (xk+1 |xk, a) \u03b7(xk) \u03b7(xk+1) dxk.\nPutting all the pieces together, the following theorem provides an expression for the global FVI error bound as the accumulation of the errors from the single iterations over the whole time horizon.\nTheorem 10 Consider a reach-avoid problem defined on a Markov process with a continuous state space X and a finite action space A. The optimal reach-avoid probability r\u2217x0(K,A) for a given target set K, safe set A, initial state x0, and time horizon Nt, is approximated by the quantity r\u0302\u2217x0(K,A) obtained with the FVI Algorithm in Algorithm 2, which has an accuracy of \u2206 and a confidence \u03b4\u2206, as stated in (3), if the following holds:\nP\n{\nB0\nNt\u22121 \u2211\nk=1\nB k\u22121 p \u2016W\u0302 \u2217k \u2212 TW\u0302 \u2217k+1\u2016p,\u03b7 (14)\n+ |W\u0302 \u22170 (x0)\u2212 TW\u0302 \u22171 (x0)| > \u2206 } \u2264 \u03b4\u2206, (15)\nwhere B is given in (14), B0 is defined as\nB0 = sup x1\u2208A\\K max a\u2208A tx (x1 | x0, a) \u03b7(x1) , (16)\nand where \u03b7 is the density of a probability distribution supported on A \\ K and tx is the density of the stochastic kernel Tx of the given Markov process.\nRemark 11 Notice that the scaling factor B has a significant influence on the error propagation. It is related to the notion of concentrability of the future-state distribution (Munos and Szepesvari, 2008; Farahmand et al., 2010). If B > 1 the error of the algorithm will increase exponentially with the time horizon, whereas if B < 1 the accuracy of the algorithm will depend mostly on the errors in the last few iterations (backwards in time). It B expresses the maximal concentration of the dynamics (relative to \u03b7) over the relevant set A \\ K after one transition starting from distribution \u03b7.\nThe case study discussed in Section 6 displays a choice of a density function \u03b7 leading to bounded values for B and B0, respectively. The relation between the scaling factor B and the model dynamics for the considered Markov process is also analyzed."}, {"heading": "4.2.1 Discussion on the Global Error Bounds", "text": "Suppose that we require that the error in the estimation of r\u2217x0(K,A), with a confidence at least equal to \u03b1, is less than \u2206, as per (3). Let us assume that there exist positive values \u01eb0, \u01eb1, \u01eb2 such that the approximation error \u2206 can be split up into individual bounds based on Theorem 8 and 10 as follows:\n\u2206 =B0 Nt\u22121 \u2211\nk=1\nB k\u22121 p dp,\u03b7 (TW,W) + 2B0\nNt\u22121 \u2211\nk=1\nB k\u22121 p (\u01eb1)\n+ 2B0 Nt\u22121 \u2211\nk=1\nB k\u22121 p (\u01eb2) + \u01eb0,\naccounting for, respectively, the inherent Bellman error (Section 4.1); the error on the estimation of TW\u0302 \u2217k+1 (Section 4.1.1); the error on the empirical norm (Section 4.1.2); and the error related to |W\u0302 \u22170 (x0) \u2212 TW\u0302 \u22171 (x0)|. We compute a lower bound on the confidence that the approximation error is bounded by\u2206 by upper bounding the complementary event. Using a union bounding argument on the probability of invalidating any of the bounding terms in the above equation, we obtain that the probability that the overall error is larger than \u2206 is upper bounded with \u03b4\u2206, as\n\u03b4\u2206 =0 + (Nt \u2212 1) ( 1\u2212 (1\u2212 2e\u22122M(\u01eb1)2)|A|N )\n(17)\n+ (Nt \u2212 1) ( 4e(d + 1) (\n32e \u01ebp2\n)d e\u2212\nN\u01eb 2p 2\n128\n)\n+ 1\u2212 (1\u2212 2e\u22122M0(\u01eb0)2)|A|,\nwith respectively the inherent Bellman error (Section 4.1), the confidence terms from Lemma 6 with sample complexity M and N , from Lemma 7 with dimp (W) = d < \u221e, and from Lemma 6 with M = M0 and N = 1. Eqn. (17) holds as long as 0 < 2e\n\u22122M(\u01eb1)2 \u2264 1 and 0 < 2e\u22122M0(\u01eb0)\n2 \u2264 1. We can observe that it is possible to find finite values for N ,M ,M0 such that 1 \u2212 \u03b1 > \u03b4\u2206. Moreover for each choice of positive \u01eb0, \u01eb1, \u01eb2 > 0 and confidence 0 \u2264 \u03b1 < 1, the necessary number of samples can be upper bounded by polynomials in 1 \u01eb0 , 1\u01eb1 , 1 \u01eb2 and 11\u2212\u03b1 , as follows:\nN = \u2308 128 ( ln(4e(d+ 1)) + d ln(32e) ) ( 1\n\u01eb2\n)2p\n(18a)\n+ 128dp ( 1\n\u01eb2\n)2p\nln ( 1\n\u01eb2\n) + 128 ( 1\n\u01eb2\n)2p\nln ( 1\n\u03b42\n)\u2309\n,\nM = \u2308 1\n2\n(\n1 \u01eb1\n)2(\nln(2|A|) + ln( 1 \u03b41 ) + ln(N)\n)\u2309\n, (18b)\nM0 = \u2308 1\n2\n(\n1 \u01eb0\n)2(\nln ( 2|A| ) + ln ( 1\n\u03b40\n)\n)\u2309\n, (18c)\nwith positive parameters \u03b40, \u03b41, \u03b42 > 0 such that 1 \u2212 \u03b1 = \u03b40 + (Nt \u2212 1)\u03b41 + (Nt \u2212 1)\u03b42 (derivation in Appendix F).\nNote that the above accuracy does not depend on the dimensionality n of the state space. Therefore the accuracy for models with higher state space dimension will directly depend on the complexity of the function class employed to approximate given value functions. This is unlike standard grid-based numerical approximation techniques, such as that proposed in (Esmaeil Zadeh Soudjani and Abate, 2013), which are known to break down over models with large state-space dimensionality.\nLet us add a few comments on the dependency of the accuracy from several design variables of the FVI algorithm. Firstly, the choice of function class affects both the inherent Bellman error and the pseudo dimension: while the former gives a measure of how well the the function class W can represent the value functions W \u2217k , the latter is directly related to the complexity of the function class. The objective is to obtain a low complexity function\nclass that is capable to accurately fit the given value functions. A good accuracy can be hard to attain when a bad choice of the function class leads to both a large bias (due to the inherent Bellman error) and to a large number of samples. Secondly, the sample distribution \u03b7 defines, together with the state transitions, the scaling factors B and B0. In order to minimize the error propagation caused by B, the distribution \u03b7 should be \u201caligned\u201d with the model dynamics characterized by the density of the transition kernel. Finally, the parameters N,M,M0 follow from the required accuracy demands, which are reformulated as polynomial functions depending on \u01eb0, \u01eb1, \u01eb2 and \u03b40, \u03b41, \u03b42, e.g. as in (18a).\nWith regards to the single-step errors, Lemmas 6 and 7 determine a bound uniformly over the whole function class and for any possible probability distribution. The used distributionfree notions lead to conservative bounds (Bartlett et al., 2005), which then result in a large set of required samples. Notice however that the construction allows to compute the bounds a-priori, before any sample is drawn from the system.\nIn conclusion, the formal probabilistic bounds on the error made by the approximation algorithm show that the algorithm converges in probability to the best approximation for an increasing cardinality of the samples."}, {"heading": "5. Sample-Based Error Bounds", "text": "In this section, a probabilistic bound on the error of the approximated reach-avoid probability is developed according to a model- and sample-based philosophy. This bound can be computed after the reach-avoid probability has been obtained via dynamic programming as time-dependent, approximate value functions W\u0302 \u2217k for 0 \u2264 k \u2264 Nt \u2212 1. The obtained bounds are not only sample dependent but also distribution dependent, since knowledge of the transition kernel is necessary to compute scaling factors such as (14). Throughout the section it is assumed that the used samples are not correlated with W\u0302 \u2217k , in other words if the estimated value functions W\u0302 \u2217k are a result of a sampled-based optimization, then the samples used for the bounds in this section are drawn anew and independently.\nThe probabilistic bound on the accuracy P { | r\u0302\u2217x0(K,A) \u2212 r\u2217x0(K,A) | > \u2206 } \u2264 \u03b4\u2206, as given in (3), and computed now in a sample-based manner, includes an empirical estimate of the quantity | r\u0302\u2217x0(K,A) \u2212 r\u2217x0(K,A) |. This sample-based estimate is computed as follows:\na. collect samples (xi)1\u2264i\u2264N\u0303 according to (1) in Algorithm1 (with N = N\u0303), and subse-\nquently use (2) with M = M\u0303 to draw both (yi,a,j1 )1\u2264j\u2264M\u0303 and (y i,a,j 2 )1\u2264j\u2264M\u0303 ;\nb. estimate the single step error (19) for each k; c. estimate the bias (21) for each k; d. compute the multi-step error as a propagation and a composition of the estimates in\n(b.) and (c.). The single step error is estimated as\n\u2225 \u2225W\u0302 \u2217k \u2212 T\u0302W\u0302 \u2217k+1 \u2225 \u2225 1,\u03b7\u0303 = 1\nN\u0303\nN\u0303 \u2211\ni=1\n\u2223 \u2223W\u0302 \u2217k (x i)\u2212max a\u2208A T\u0302 a 1W\u0302 \u2217 k+1(x i) \u2223 \u2223 (19)\nfor all 1 \u2264 k \u2264 Nt\u22121. The term on the right is the empirical 1-norm and can be written as a 1-norm with weighting \u03b7\u0303, which is the empirical distribution of \u03b7 resulting from (xi)1\u2264i\u2264N\u0303 .\nLet the operator T\u0302a\u03b1 be, for \u03b1 = 1, 2,\nT\u0302 a \u03b1W\u0302 \u2217 k+1(x i)= 1 M\u0303\nM\u0303 \u2211 j=1 1K(y i,a,j \u03b1 )+1A\\K(y i,a,j \u03b1 )W\u0302 \u2217k+1(y i,a,j \u03b1 ). (20)\nThe estimate in (19) is biased due to the maximization over the action space, therefore as a second step we estimate a bound on this bias. The combination of the two sample sets (yi,a,j1 )1\u2264j\u2264M\u0303 and (y i,a,j 2 )1\u2264j\u2264M\u0303 , for each x\ni and a, allows us to estimate this bias for 1 \u2264 k \u2264 Nt \u2212 1 as\n\u2225 \u2225 \u2225 max a\u2208A \u2223 \u2223T\u0302 a 1W\u0302 \u2217 k+1 \u2212 T\u0302a2W\u0302 \u2217k+1 \u2223 \u2223 \u2225 \u2225 \u2225 1,\u03b7\u0303 . (21)\nIn the following theorem, an expression for the bound on P { | r\u0302\u2217x0(K,A) \u2212 r\u2217x0(K,A) | > \u2206 } \u2264 \u03b4\u2206 is derived, employing the error propagation technique first used in Section 4.2, the estimates of the single step error above, and the bias (21) in combination with Hoeffding\u2019s inequality (Hoeffding, 1963).\nTheorem 12 Consider a reach-avoid problem defined on a Markov process with a continuous state space X and a finite action space A. The optimal reach-avoid probability r\u2217x0(K,A) for a given target set K, safe set A, initial state x0, and time horizon Nt, is approximated by the quantity r\u0302\u2217x0(K,A) obtained with the FVI Algorithm in Algorithm 2, which has an accuracy of \u2206 and a confidence \u03b4\u2206, as stated in (3), if the following holds:\n\u2206 = B0 Nt\u22121 \u2211\nk=1\nBk\u22121 ( \u2225 \u2225\n\u2225 W\u0302 \u2217k \u2212 T\u0302W\u0302 \u2217k+1\n\u2225 \u2225 \u2225\n1,\u03b7\u0303 +\n\u2225 \u2225 \u2225 maxa\u2208A \u2223 \u2223 \u2223 T\u0302 a 1W\u0302 \u2217 k+1 \u2212 T\u0302a2W\u0302 \u2217k+1 \u2223 \u2223 \u2223 \u2225 \u2225 \u2225\n1,\u03b7\u0303\n)\n+B0\u01eb+ \u01eb0,\n(22a)\n\u03b4\u2206 = e \u22122 N\u0303\u01eb\n2\nL2 \u2212 \u03b40, (22b)\nwith L = 2 \u2211Nt\u22121 k=1 B k\u22121, and sample sizes M\u0303 and N\u0303 according to the sample sets drawn according to the distribution \u03b7. Equation (22a) includes the estimated error as a combination of (19) and (21). The scaling factors B and B0 are computed as in (14) and (16) for the same sampling distribution \u03b7. The factors \u03b40 and \u01eb0 are computed as in Lemma 6 with M = M0 and N = 1.\nThe accuracy \u2206 depends on two terms, the propagation of the estimated single-step and bias errors over the time horizon up to k = 1, and the estimation errors B0\u01eb+ \u01eb0 for k = 0, related to the confidence \u03b4\u2206.\nSuppose that a close-to-optimal policy is given, for example a policy as detailed in Remark 5 and computed from the series of estimated value functions W\u0302 \u2217k . Then we know that r\u2217x0(K,A) \u2265 r \u00b5\u0302\u2217 x0 (K,A), therefore a lower bound on the value of r \u00b5\u0302\u2217 x0 (K,A) is also a lower bound on r\u2217x0(K,A). Note that for a policy \u00b5, the closed-loop Markov process is time dependent. This allows us to estimate r\u00b5x0(K,A) directly from traces of this autonomous Markov process. The deviation of this empirical mean can be bounded probabilistically using Hoeffding\u2019s inequality. Additionally an upper bound on the deviation |r\u0302\u2217x0(K,A) \u2212 r\u00b5x0(K,A)| can be computed. The combination of the bound in Theorem 12 and of the bound on |r\u0302\u2217x0(K,A)\u2212 r \u00b5 x0(K,A)| provide a bound on the performance deviation of r\u00b5x0(K,A): the\ntriangle inequality leads to |r\u2217x0(K,A)\u2212 r \u00b5 x0(K,A)| \u2264 |r\u2217x0(K,A)\u2212 r\u0302\u2217x0(K,A)|+ |r\u0302\u2217x0(K,A)\u2212 r\u00b5x0(K,A)|. In comparison to the a-priori bound derived in Section 4, the sample-based bounds do not depend on the inherent Bellman error and can be shown to be less conservative in general. Moreover, they provide insight into the accuracy of the iterations steps. However, they give no information about the expected convergence of the algorithm, and they can only be computed after a run of the algorithm. Similarly to the a-priori bounds, they do not depend on the dimensionality of the state space and are expected to scale better than those used for grid-based approaches such as (Esmaeil Zadeh Soudjani and Abate, 2013)."}, {"heading": "6. Case Study and Numerical Experiments", "text": "We consider a case study from the literature (Fehnker and Ivanc\u030cic\u0301, 2004), where the goal is to maximize the probability that the temperature of two interconnected rooms, while staying within a comfortable range, reaches a smaller target range within a given finite time horizon. The temperature can be affected using local heaters. A reach-avoid problem is set up by selecting as the safe set A = [17.5 22]2, as the target set K = [19.25 20.25]2, and a fixed time horizon Nt = 10. The case study was implemented in Matlab R2013b on a notebook with 2.6 GHz Intel Core i5 and 16 GB of RAM."}, {"heading": "6.1 Model", "text": "The dynamics of the temperature in the two rooms is described by a Markov model, with the temperature of the rooms making up the state space X = R2, and where the possible configurations {OFF,ON} = {0, 1} of the two heaters form the finite action space A. Hence A = {0, 1}\u00d7{0, 1}, and as an example the action related to the first heater in the ON mode and the second in the OFF one is given as a = [1 0]T \u2208 A. The dynamics at discrete time k is characterized by the following stochastic difference equation:\nxk+1 = Axk +Ba+C+ nk, where (23) A= [\n1\u2212b1\u2212a1,2 a1,2 a2,1 1\u2212b2\u2212a2,1\n] , C = [\nb1xa b2xa\n]\n, and B = [ c1 0 0 c2 ] ,\nand with the following parameters: xa is the ambient temperature (assumed to be constant), bi \u2265 0 is a constant for the average heat loss rate of room i to the environment; aij \u2265 0 is a constant for the average heat exchange rate of room i to room j 6= i; ci \u2265 0 is a constant for the rate of heat supplied by the heater in room i. The parameters re instantiated as b1 = 0.0375, c1 = 0.65, xa = 6, b2 = 0.025, c2 = 0.6, and aij = 0.0625. The noise process nk is a realization of zero-mean Gaussian random variables with covariance \u03bd\n2I2\u00d72 (2-dimensional identity matrix I2\u00d72) and \u03bd = 0.5. Let N (\u00b7 | \u00b5,\u03a3) be a 2-dimensional multivariate normal distribution over (X ,B(X )) with mean \u00b5 and covariance matrix \u03a3, then the stochastic kernel Tx is given as\nTx (\u00b7 | x, a) = N ( \u00b7 | Ax+Ba+C, \u03bd2I2\u00d72 )\n(24)\nand characterises the probability distribution of the stochastic transitions in (23). The stochastic kernel (24) admits the probability density\ntx (y | x, a) = 1 \u221a\n|\u03a3|(2\u03c0)2 e(\u2212 1 2 (y\u2212\u00b5\u0304)T\u03a3\u22121(y\u2212\u00b5\u0304)), (25)\nwhere | \u00b7 | denotes the determinant of a matrix, and as before the covariance matrix equals \u03a3 = \u03bd2I2\u00d72 and the mean value is \u00b5\u0304 = Ax+Ba+C."}, {"heading": "6.2 Application of the Fitted Value Iteration Algorithm", "text": "The FVI scheme is implemented as in Algorithm 2, and approximates the solution of the reach-avoid problem. We obtain an approximation of r\u2217x0(K,A) = T 10W\u0302 \u221710(x0) by T\u0302W\u0302 \u2217 1 (x0), while using the auxiliary functions W\u0302 \u22179 , . . . , W\u0302 \u2217 1 to approximate TW\u0302 \u2217 10, . . . ,TW\u0302 \u2217 2 in the FVI scheme \u2013 equivalently, function W\u0302 \u2217k approximates T Nt\u2212kW\u0302 \u2217Nt . For a given temperature xk at time instant k, the function W\u0302 \u2217k (xk) gives the approximate probability that the consecutive temperature values xk+1, . . . , xNt will reach the temperature range [19.25, 20.25]\n2 within Nt \u2212 k time steps, while staying inside the safe set [17.5, 22]2 .\nIn order to apply the FVI algorithm, we select a uniform distribution \u03b7 over A \\K to sample from, then select a function class W and a value for p \u2265 1 to solve (5). We consider a function class W composed of Gaussian radial basis function (RBF) neural networks with 50 RBFs with a uniform width of 0.7. The neural network toolbox of Matlab is used to solve the regression problem in (5) as a least-square problem (with p = 2). A neural network with a single layer of hidden units of Gaussian type radial basis functions is proved to be a universal approximator for real-valued functions (Hartman et al., 1990). Furthermore the pseudo dimension of an artificial neural network with W free parameters and k hidden nodes has been upper bounded by O(W 2k2) (Karpinski and Macintyre, 1997; Anthony and Bartlett, 1999). This means that for any desired precision the required number of samples is bounded by a polynomial in the number of hidden nodes.\nThe following quantities are obtained for the sample complexities: N = 600, M = 103, M0 = 10 3. The approximate value functions for W\u0302 \u22179 , W\u0302 \u2217 5 , and W\u0302 \u2217 1 are displayed in Fig. 1. On the top plots, a point on the state space is associated with a probability for the reach-avoid property over the given time horizon. At the bottom, the contour plots (level sets) characterize the set of points that verify the reach-avoid property with a probability at least equal to the given level.\nFig. 2 displays a suboptimal policy \u00b5\u0302\u2217 that is obtained via the FVI algorithm as discussed in Remark 5, by employing the tree classification method ClassificationTree.fit of Matlab. Observe that policy \u00b5\u0302\u22179 for k = 9 is not accurate over the flat regions of W\u0302 \u2217 9 (corresponding to the blue spots in the left side of Fig. 2 - left plot), which are far away from the reach set K. Since the average heat loss rate of room 1 is the highest, we expect that the heating should be turned on relatively longer. Fig. 2 confirms this, i.e. the red (ON,ON) region is not square-shaped as the heaters stay ON for higher temperatures in room 1 than in room 2."}, {"heading": "6.3 Performance of the Fitted Value Iteration", "text": "We are interested in the performance of the FVI algorithm and in analyzing how the computed accuracy deteriorates over the iterations from Nt\u22121 to 1. Note that the last iteration is of little interest, since it does not include the fitting step. The accuracy is computed using the model-based and sample-based bounds of Section 5. Fig. 3 plots the sample-based estimates of the single step error (19), namely \u2016W\u0302 \u2217k \u2212 T\u0302W\u0302 \u2217k+1\u20161,\u03b7\u0303 and of the bias (21), namely\n\u2225 \u2225maxa\u2208A \u2223 \u2223T\u0302 a 1W\u0302 \u2217 k+1\u2212 T\u0302a2W\u0302 \u2217k+1 \u2223 \u2223 \u2225 \u2225 1,\u03b7\u0303 . Observe that the values of both (19) and (21) fall in the interval between 3\u00d7 10\u22123 and 5\u00d7 10\u22123. The bias estimate (21) appears distributed all over this interval, whereas there is a noticeable trend in the plot of (19), which suggests that the first iterations can be fitted more easily. In Fig. 4, the accuracy of the FVI algorithm propagated over the iterations is given, starting from the first iteration \u2016W\u0302 \u22179 \u2212 TW \u2217Nt\u2016\u03b7 until the last iteration \u2016W\u0302 \u22171 \u2212 TNtW \u2217Nt\u2016\u03b7. This accuracy is computed using Theorem 12. The estimates in Fig. 3 are used to compute the estimate of the accuracy \u2016W\u0302 \u2217k \u2212 TW \u2217Nt\u2016\u03b7 and the accuracy \u2206 for a given \u03b4\u2206. For each iteration step, it can be observed in Fig. 3 that the error caused by estimating the dynamic programming operator T and by fitting a function is relatively small (< 10\u22122). However, the error grows exponentially over the whole horizon: as expected, the accuracy of the algorithm depends strongly on B, which has been computed numerically and amounts to 3.07."}, {"heading": "7. Conclusions and Future Work", "text": "This article has investigated the performance of a sample-based approximation scheme for the synthesis of optimal controllers maximizing the probability of the known \u201creach-avoid\u201d specification. The approximate computational scheme is based on the Fitted Value Iteration\nalgorithm, which hinges on random sample extractions. We are interested in the non-trivial extension to continuous control spaces, as well as in the assessment of the performance of synthesized approximate policies over the concrete model. Finally, the development of better sampling distributions that minimize the error propagation can lead to tighter errors, which can be more relevant in practice. To this end, the optimal sampling distribution should be used to optimize the scaling factors by resembling more closely the local stochastic kernels."}, {"heading": "Appendix A. Proof of Lemma 6: Bound on Estimation Error", "text": "We employ results on the concentration of random variables (Anthony, 2002), which in general raise conditions on a random variable ensuring its realizations to be concentrated around its expectation, in the sense that the probability of a deviation from the expectation is exponentially small (as a function of the deviation). Of interest to this work is a known bound holding for sums of bounded and independent random variables Hoeffding (1963).\nProposition 13 (Hoeffding\u2019s inequality, Hoeffding (1963)) Suppose that Xi, for i = 1, 2, . . . , N, are independent random variables supported on [0, 1]. Then\nP {\u2223 \u2223\n\u2223 \u2211N i=1 x i k \u2212E \u2211N i=1Xi\n\u2223 \u2223 \u2223 \u2265 N\u01eb } \u2264 2e\u22122N\u01eb2 ,\nwhere E \u2211N i=1 Xi is the mean of the random variable \u2211 i Xi, whereas the empirical mean is defined as \u2211N\ni=1 x i k, where x i k is a realization of Xi.\nUsing Proposition 13 the proof of Lemma 6 is provided as follows.\nProof Let us express a probabilistic error bound on the accuracy of the estimate T\u0302W\u0302 \u2217k+1 at each base point xik and given any a \u2208 A as\nP { \u2016TW\u0302 \u2217k+1 \u2212 T\u0302W\u0302 \u2217k+1\u2016p,\u03b7\u0302 > \u01eb1 }\n\u2264 \u03b41, where we have used the empirical norm based on \u03b7\u0302. We obtain\nP { \u2016TW\u0302 \u2217k+1 \u2212 T\u0302W\u0302 \u2217k+1\u2016p,\u03b7\u0302 \u2264 \u01eb1 } = P { \u2016TW\u0302 \u2217k+1 \u2212 T\u0302W\u0302 \u2217k+1\u2016pp,\u03b7\u0302 \u2264 \u01eb p 1 }\nvia definition of the empirical norm in (8)\n= P\n{\n1\nN\nN \u2211\ni=1\n\u2223 \u2223TW\u0302 \u2217k+1(x i k)\u2212 T\u0302W\u0302 \u2217k+1(xik) \u2223 \u2223 p \u2264 \u01ebp1 }\nNote the mutual independence between the sample sets at different base points xik given as \u22c3\na\u2208A\n( xi,a,jk+1 )\n1\u2264j\u2264M\n\u2265 P { N \u22c2\ni=1\n{ \u2223\n\u2223 \u2223 TW\u0302 \u2217k+1\n( xik ) \u2212 T\u0302W\u0302 \u2217k+1(xik) \u2223 \u2223 \u2223 p \u2264 \u01ebp1 }\n}\n= N \u220f i=1 P { \u2223 \u2223 \u2223 TW\u0302 \u2217k+1 ( xik ) \u2212 T\u0302W\u0302 \u2217k+1(xik) \u2223 \u2223 \u2223 \u2264 \u01eb1 } .\nLet us now express the argument of the probability operator as follows \u2223 \u2223 \u2223 TW\u0302 \u2217k+1 ( xik ) \u2212 T\u0302W\u0302 \u2217k+1(xik) \u2223 \u2223 \u2223\n= \u2223 \u2223\n\u2223 max a\u2208A Exk+1\n[\n1K(xk+1) + 1A\\K(xk+1)W\u0302 \u2217 k+1(xk+1)\n]\n\u2212max a\u2208A\n1\nM\nM \u2211 j=1 [1K(x i,a,j k+1) + 1A\\K(x i,a,j k+1)W\u0302 \u2217 k+1(x i,a,j k+1)] \u2223 \u2223 \u2223\nW.r.t Exk+1 defined over random variable xk+1 \u223c Tx ( \u00b7 | xik, a )\n\u2264 max a\u2208A\n\u2223 \u2223 \u2223 Exk+1 [ 1K(xk+1) + 1A\\K(xk+1)W\u0302 \u2217 k+1(xk+1) ]\n\u2212 1 M\nM \u2211 j=1 [1K(x i,a,j k+1) + 1A\\K(x i,a,j k+1)W\u0302 \u2217 k+1(x i,a,j k+1)] \u2223 \u2223 \u2223 .\nTherefore the probability of the last event above can be lower bounded by the probability associated to several independent events over the finite action space, as follows:\nP { \u2223 \u2223\n\u2223 TW\u0302 \u2217k+1\n( xik ) \u2212 T\u0302W\u0302 \u2217k+1(xik) \u2223 \u2223 \u2223 \u2264 \u01eb1 }\n\u2265 \u220f a\u2208A\nP { \u2223 \u2223\n\u2223 Exk+1\n[\n1K(xk+1) + 1A\\K(xk+1)W\u0302 \u2217 k+1(xk+1)\n]\n\u2212 1 M\nM \u2211\nj=1\n[\n1K(x i,a,j k+1) + 1A\\K(x i,a,j k+1)W\u0302 \u2217 k+1(x i,a,j k+1)\n] \u2223\n\u2223 \u2223 \u2264 \u01eb1\n}\n.\nFor a given base point xik \u2208 X , action a \u2208 A, and function W\u0302 \u2217k+1 \u2208 W, define random variables Zj via their realizations 1K(x i,a,j k+1) + 1A\\K(x i,a,j k+1)W\u0302 \u2217 k+1(x i,a,j k+1), with j = 1, . . . ,M . Since each xi,a,jk+1 is independently drawn from Tx ( \u00b7 | xik, a )\n, the random variables Zj are independent, identically distributed, and take values within the closed interval [0, 1]. By application of Hoeffding\u2019s inequality (as in Proposition 13), the concentration of the M samples around the expected value of Zj can be expressed as\nP { \u2223\n\u2223Exk+1\n[\n1K(xk+1) + 1A\\K(xk+1)W\u0302 \u2217 k+1(xk+1)\n]\n\u2212 1 M\nM \u2211\nj=1\n[\n1K(x i,a,j k+1) + 1A\\K(x i,a,j k+1)W\u0302 \u2217 k+1(x i,a,j k+1)\n]\n\u2223 \u2223\u01eb1\n}\n\u2264 2e\u22122M(\u01eb1)2 .\nTherefore as long as 0 \u2264 2e\u22122M(\u01eb1)2 \u2264 1, it follows that P { \u2016TW\u0302 \u2217k+1 \u2212 T\u0302W\u0302 \u2217k+1\u2016p,\u03b7\u0302 \u2264 \u01eb1 }\n\u2265 (\n1\u2212 2e\u22122M(\u01eb1)2 )N |A| .\nRemark 14 As long as we only know that the random variables Zj are bounded, the use of Hoeffding\u2019s inequality is sufficient. If we further have information on the variance of Zj , one can leverage the inequalities of Chebyshev and of Bienaym-Chebyshev (Hoeffding, 1963), or alternatively Bernstein\u2019s inequality (Peshkin and Mukherjee, 2001): the former bounds are only function of the variance, whereas the latter inequality depends not only on variance of Zj but also on its bounded domain. Upper bounds on either the variance of Zj or on its range can be derived exploiting prior knowledge on properties of the function space W and of the distribution Tx (\u00b7 | x, a)."}, {"heading": "Appendix B. Proof of Lemma 7", "text": "We derive a general, analytical bound on the error of a single backward recursion using notions from statistical learning theory (Haussler, 1992; Pollard, 1984). The error bound takes into account that, for any TW\u0302 \u2217k+1, the optimal fit can be anywhere in the function class. Furthermore the bound will be distribution-free, namely holding for any Markov process (with dynamics characterized by Tx) and any sample distribution \u03b7 over the set A \\K.\nWe exclusively consider function classes W \u2282 B(X ; 1) endowed with a finite pseudodimension: this includes all finitely-parameterized function classes (Munos and Szepesvari, 2008). The notion of pseudo dimension (Pollard, 1984; Anthony, 2002; Haussler, 1992) expresses the capability of a function class W to the fit a set of samples. Proof In order to prove Lemma 7, we show that the inequality in (10) holds for any W\u0302 \u2217k+1 \u2208 W at any time instant k = 0, . . . , Nt \u2212 1. For the sake of notation in the following we substitute W\u0302 \u2217k+1 by W , and instead of considering the set of base points (x i k)1\u2264i\u2264N drawn at the time instant k we simply introduce ~x = (x1, . . . , xN ) as a sequence of N independent realizations drawn from a distribution over A \\K with density \u03b7.\nFor any given function W \u2208 W , induce a new function class lW = {|w\u2212TW |p : w \u2208 W} with elements lw \u2208 lW : lw = |w \u2212 TW |p. The inequality in (10) can be rewritten over the function class lW as follows\nP {\nsup w\u2208W\n\u2223 \u2223\u2016w \u2212 TW\u2016pp,\u03b7 \u2212 \u2016w \u2212 TW\u2016pp,\u03b7\u0302 \u2223 \u2223 \u2265 \u01ebp2 } = P {\nsup lw\u2208lW\n\u2223 \u2223E\u03b7 [lw]\u2212 1\nN\nN \u2211 i=1 lw(x i) \u2223 \u2223 \u2265 \u01ebp2 } ,\nwhere E\u03b7 denotes the expected value with respect to \u03b7. This allows us to use a result in (Pollard, 1984), which provides an upper-bound on the probability of the above event as a function of the covering number of the metric space ((lW)~x, \u2016 \u00b7 \u20161).\nProposition 15 (Pollard (1984)) Let F be a permissable set of functions on X with 0 \u2264 f(x) \u2264 K for all f \u2208 F and x \u2208 X . Let ~x = (x1, . . . , xN ) be a sequence of N samples drawn independently from X according to any distribution on X . Then for all \u01eb > 0\nP { \u2200f \u2208 F : \u2223\n\u2223Ef \u2212 1N \u2211 ~x f(xi) \u2223 \u2223 \u2265 \u01eb } \u2264 4EN (\u01eb/16, F|~x, \u2016 \u00b7 \u20161)e\u2212 N\u01eb2 128K2 , (26)\nwhere the quantity N will be introduced shortly and where the definition of a permissible set of functions (Pollard, 1984) includes all finitely parameterized functions.\nLet us introduce the concept of covering number of a metric space (Haussler, 1992). Given a (pseudo-)metric space (A, \u03c1) and a subset S of A, we say that the set T \u2286 A is an \u01eb-cover for S (where \u01eb > 0) if, for every s \u2208 S there is a t \u2208 T such that \u03c1(s, t) < \u01eb. For a given \u01eb > 0 we denote the covering number N (\u01eb, S, \u03c1) (Haussler, 1992) as the cardinality of the smallest \u01eb-cover of S.\nFor a given set of samples xi with i = 1, . . . , N , the evaluation of a function lw \u2208 lW over each of these samples is given as the N dimensional vector in [0, 1] N : (lw)|~x = (lw(x 1), lw(x 2), . . . , lw(x N )). The induced set of vectors is\n(lW)|~x = {(lw)|~x = (lw(x1), lw(x2), . . . , lw(xN )), lw \u2208 lW} \u2286 [0, 1]N .\nThe minimal \u01eb-cover of ((lW )|~x, \u2016 \u00b7 \u20161) is denoted as N (\u01eb, (lW )|~x, \u2016 \u00b7 \u20161). The deviation of the expected value from the empirical mean can be bounded using Pollard\u2019s proposition (Pollard, 1984)\nP {\nsuplw\u2208lW \u2223 \u2223Ex [lw(x)]\u2212 1N \u2211N i=1 lw(xi) \u2223 \u2223 \u2265 \u01ebp2 } \u2264 4E [ N (\u01ebp2/16, (lW)|~x , \u2016 \u00b7 \u20161) ] e\u2212 N(\u01eb2)\n2p\n128 .\nThe expected value of N (\u01ebp2/16, (lW)|~x , \u2016 \u00b7 \u20161) is computed over the samples xi of ~x, drawn independently from a probability distribution with density \u03b7. Since there is a trivial isometry (Haussler, 1992) between (lW|~x, \u2016 \u00b7 \u20161) and (lW , \u2016 \u00b7 \u20161,\u03b7\u0302), both spaces have equal covering numbers\nN (\u01ebp2/16, lW|~x, \u2016 \u00b7 \u20161) = N (\u01eb p 2/16, lW , \u2016 \u00b7 \u20161,\u03b7\u0302).\nIn practice a value for E [N (\u01ebp2/16, lW , \u2016 \u00b7 \u20161,\u03b7\u0302)] can be obtained by upper bounding N (\u01ebp2/16, lW , \u2016 \u00b7 \u20161,\u03b7\u0302) independently of the sample distribution. For this we introduce the pseudo dimension of a function class, formally defined as follows Pollard (1984); Anthony (2002); Haussler (1992). Suppose F is a class of functions, f \u2208 F , f : X \u2192 [0, 1]. Then S \u2286 X is shattered by F if there are numbers rx \u2208 [0, 1] for x \u2208 S such that for every T \u2286 S there is some fT \u2208 F with the property that fT \u2265 rx if x \u2208 T and fT < rx if x \u2208 S \\T . We say that F has a finite pseudo dimension dimp (F) = d if d is the maximum cardinality of a shattered set.\nFor any distribution P \u2208 M(X ), the packing number (Haussler, 1992) and therefore also tho covering number of the metric space (lW , \u2016 \u00b7 \u20161,P ) can be upper bounded as a function of the pseudo-dimension and the base of the natural logarithm e: for any \u01eb > 0,\nN (\u01eb, lW , \u2016 \u00b7 \u20161,P ) \u2264 e(d+ 1) ( 2e \u01eb )d , with dimp(lW) = d.\nWe have proved that a sufficient upper bound is given as\nP {\nsupw\u2208W \u2223 \u2223\u2016w \u2212 TW\u2016pp,\u03b7 \u2212 \u2016w \u2212 TW\u2016pp,\u03b7\u0302 \u2223 \u2223 \u2265 \u01ebp2 } \u2264 4e(d+ 1) (\n32e \u01ebp2\n)d e\u2212 N(\u01eb2) 2p 128 .\nThe proof can be concluded by showing that the pseudo dimension d of the induced class lW is the same as the pseudo dimension of W. Let {w \u2212 TW : w \u2208 W} be a new function class induced from W. The invariance properties of the pseudo dimension dimp(W) shown in (Haussler, 1992) allow to conclude that dimp( { w \u2212 TW \u2223 \u2223w \u2208 W }\n) = dimp(W). The induced function class lW can then be defined as follows: lW = { |k|p \u2223 \u2223k \u2208 {w \u2212 TW : w \u2208 W} }\n. Since it was shown in (Kearns and Schapire, 1994) that the pseudo dimension is invariant over function composition (|\u00b7|p), we conclude that the pseudo dimension is dimp(lW) = dimp({w \u2212 TW : w \u2208 W}) = dimp(W) = d.\nRemark 16 (Computing the pseudo-dimension) When the function class W is a vector space of real-valued functions, the pseudo dimension is equal to the dimensionality of the function class (Anthony and Bartlett, 1999, Theorem 11.4). (Anthony and Bartlett, 1999) elaborates the details of the computation of pseudo dimensions of parameterized function classes, especially for function classes defined over neural networks.\nSince it is possible to bound the pseudo dimension of lW (as introduced in the proof) by the pseudo dimension of W, this capacity concept has been used to bound the error caused by using an empirical estimate of the weighted p-norm. Notice that for non-parametric function classes, concepts such as covering number or Rademacher average of the function class lW can be used instead (Bartlett et al., 2005).\nLet us shortly discuss how the derived bounds can be tightened. A first option is to circumvent the notion of pseudo dimension and work with the covering numbers in Pollard inequality (Proposition 15), however the increase in assumptions on the function class and in overall computations make the gain in accuracy undeserving. A second option is to explore alternatives over Pollard inequality in (15) with better constants (Bartlett et al., 2005). An alternative concentration inequality based on Bernstein\u2019s inequality is used in (Peshkin and Mukherjee, 2001). Hoeffding inequality gives a concentration inequality on the sum of bounded random variables, whereas Bernstein inequality gives a tighter bound based on knowledge of both the boundness and the variance of the random variables. Even with improved constants or alternative inequalities, the error bounds can still result to be conservative for reasonable sample complexities."}, {"heading": "Appendix C. Proof of Theorem 8", "text": "The proof of Theorem 8 is adapted from the proof of the single-step error bound for Fitted Value Iteration with multiple sample batches in (Munos and Szepesvari, 2008). Proof Let us introduce a simplified notation for W\u0302 \u2217k+1 by replacing it with a general functionW \u2032 \u2208 W that minimizes the empirical norm asW \u2032 = argminw\u2208W \u2016w\u2212T\u0302W\u2016p,\u03b7\u0302. Let us further define a space \u2126 for the batch of samples drawn at any of the iterations, such that\nat any instant k the realized sample batch \u03c9 := \u22c3\ni\u2208{1,...,N}\n( xik \u222a ( \u22c3 a\u2208A ( xi,a,jk+1 )\n1\u2264j\u2264M\n))\nis an element of the sample space, \u03c9 \u2208 \u2126. For any given \u01eb\u2032 > 0, consider a function w\u2217 \u2208 W such that \u2016w\u2217\u2212TW\u2016p,\u03b7 \u2264 infw\u2208W \u2016w\u2212 TW\u2016p,\u03b7 + \u01eb\u2032 (this in particular holds since W has been assumed to be close and bounded). The error bound in (13) holds for a sample realization \u03c9 if the following sequence of inequalities holds simultaneously:\n\u2016W \u2032 \u2212 TW\u2016p,\u03b7 \u2264 \u2016W \u2032 \u2212 TW\u2016p,\u03b7\u0302 + \u01eb2 (27a) \u2264 \u2016W \u2032 \u2212 T\u0302W\u2016p,\u03b7\u0302 + \u01eb1 + \u01eb2 (27b) \u2264 \u2016w\u2217 \u2212 T\u0302W\u2016p,\u03b7\u0302 + \u01eb1 + \u01eb2 (27c) \u2264 \u2016w\u2217 \u2212 TW\u2016p,\u03b7\u0302 + 2\u01eb1 + \u01eb2 (27d) \u2264 \u2016w\u2217 \u2212 TW\u2016p,\u03b7 + 2\u01eb1 + 2\u01eb2. (27e)\nAs long as the previous sequence of inequalities is true, the following one also holds:\n\u2016W \u2032 \u2212 TW\u2016p,\u03b7 \u2264 inf w\u2208W \u2016w \u2212 TW\u2016p,\u03b7 + 2\u01eb1 + 2\u01eb2 + \u01eb\u2032.\nWe claim that the sequence of inequalities holds with a probability at least 1\u2212(\u03b41+\u03b42). Since there exists a function w\u2217 for any \u01eb\u2032 > 0 it follows with a probability at least 1 \u2212 (\u03b41 + \u03b42) that \u2016W \u2032 \u2212 TW\u2016p,\u03b7 \u2264 dp,\u03b7(TW,W) + 2\u01eb1 + 2\u01eb2. By the union bound argument (Anthony, 2002), the probability of the union of events can be bounded by the sum of the probabilities of the single events. Using this argument it is possible to define a lower bound on the probability associated with the simultaneous\noccurrence of the five inequalities in (27). We first show that the third inequality is always true. Then we give the probability associated to the first inequality (27a) and the fifth (27e) (this is based on (12)). Afterwards we provide an upper bound on the probability associated to the second and fourth inequalities (27b),(27d), based on the bound given in (11).\nThe third inequality (27c) is true for the whole sample space \u2126 due to the choice of W \u2032. For all functions w in W it follows that \u2016W \u2032 \u2212 T\u0302W\u2016p,\u03b7\u0302 \u2264 \u2016w \u2212 T\u0302W\u2016p,\u03b7\u0302 holds, because W \u2032 = argminw\u2208W \u2016w \u2212 T\u0302W\u2016p,\u03b7\u0302.\nThe first and last inequalities (27a),(27e) bound the deviation between the empirical loss and the expected loss. This can be bounded with the worst case error. Firstly we observe that the inequality\n\u2223 \u2223 \u2223 \u2016w \u2212 TW\u2016p,\u03b7\u0302 \u2212 \u2016w \u2212 TW\u2016p,\u03b7 \u2223 \u2223 \u2223 p \u2264 \u2223 \u2223 \u2223 \u2016w \u2212 TW\u2016pp,\u03b7 \u2212 \u2016w \u2212 TW\u2016pp,\u03b7\u0302 \u2223 \u2223 \u2223\nis always true. In the case that \u2016w \u2212 TW\u2016p,\u03b7\u0302 \u2264 \u2016w \u2212 TW\u2016p,\u03b7 then \u2223\n\u2223 \u2223 \u2016w \u2212 TW\u2016p,\u03b7\u0302 \u2212 \u2016w \u2212 TW\u2016p,\u03b7\n\u2223 \u2223 \u2223 = \u2016w \u2212 TW\u2016p,\u03b7\u0302 \u2212 \u2016w \u2212 TW\u2016p,\u03b7\n\u2016w \u2212 TW\u2016p,\u03b7\u0302 = (\u2016w \u2212 TW\u2016p,\u03b7\u0302 \u2212 \u2016w \u2212 TW\u2016p,\u03b7) + \u2016w \u2212 TW\u2016p,\u03b7 \u2016w \u2212 TW\u2016pp,\u03b7\u0302 = ((\u2016w \u2212 TW\u2016p,\u03b7\u0302 \u2212 \u2016w \u2212 TW\u2016p,\u03b7) + \u2016w \u2212 TW\u2016p,\u03b7) p \u2016w \u2212 TW\u2016pp,\u03b7\u0302 \u2265 (\u2016w \u2212 TW\u2016p,\u03b7\u0302 \u2212 \u2016w \u2212 TW\u2016p,\u03b7) p + \u2016w \u2212 TW\u2016pp,\u03b7\n\u2016w \u2212 TW\u2016pp,\u03b7\u0302 \u2212 \u2016w \u2212 TW\u2016pp,\u03b7 \u2265 (\u2016w \u2212 TW\u2016p,\u03b7\u0302 \u2212 \u2016w \u2212 TW\u2016p,\u03b7) p\n\u2223 \u2223 \u2223 \u2016w \u2212 TW\u2016pp,\u03b7\u0302 \u2212 \u2016w \u2212 TW\u2016pp,\u03b7 \u2223 \u2223 \u2223 \u2265 \u2223 \u2223 \u2223 \u2016w \u2212 TW\u2016p,\u03b7\u0302 \u2212 \u2016w \u2212 TW\u2016p,\u03b7 \u2223 \u2223 \u2223 p\nOn the other hand, for the case when \u2016w\u2212TW\u2016p,\u03b7\u0302 > \u2016w\u2212TW\u2016p,\u03b7 a similar argument can be used. We can then observe that\n\u2223 \u2223 \u2223 \u2016w\u2217 \u2212 TW\u2016p,\u03b7\u0302 \u2212 \u2016w\u2217 \u2212 TW\u2016p,\u03b7 \u2223 \u2223 \u2223 p \u2264 sup\nw\u2208W\n\u2223 \u2223 \u2223 \u2016w \u2212 TW\u2016pp,\u03b7 \u2212 \u2016w \u2212 TW\u2016pp,\u03b7\u0302 \u2223 \u2223 \u2223 ,\nand that \u2223\n\u2223 \u2223 \u2016W \u2032 \u2212 TW\u2016p,\u03b7 \u2212 \u2016W \u2032 \u2212 TW\u2016p,\u03b7\u0302\n\u2223 \u2223 \u2223 p \u2264 sup\nw\u2208W\n\u2223 \u2223 \u2223 \u2016w \u2212 TW\u2016pp,\u03b7 \u2212 \u2016w \u2212 TW\u2016pp,\u03b7\u0302 \u2223 \u2223 \u2223 .\nGiven two functions w\u2217 and W \u2032 define events A1 and A2\nA1 : \u01eb p 2 <\n\u2223 \u2223 \u2223 \u2016w\u2217 \u2212 TW\u2016p,\u03b7\u0302 \u2212 \u2016w\u2217 \u2212 TW\u2016p,\u03b7 \u2223 \u2223 \u2223 p , A2 : \u01eb p 2 < \u2223 \u2223 \u2223 \u2016W \u2032 \u2212 TW\u2016p,\u03b7 \u2212 \u2016W \u2032 \u2212 TW\u2016p,\u03b7\u0302 \u2223 \u2223 \u2223 p .\nObserve that the event sets A1 and A2 are subsets of the more general event B defined as\nB : \u01ebp2 < sup w\u2208W\n\u2223 \u2223 \u2223 \u2016w \u2212 TW\u2016pp,\u03b7 \u2212 \u2016w \u2212 TW\u2016pp,\u03b7\u0302 \u2223 \u2223 \u2223 .\nThus it follows that for any \u01eb2 > 0: P {A1 \u222aA2} \u2264 P {B} and, based on (12), we have\nP {{ \u2223 \u2223\u2016W \u2032 \u2212 TW\u2016p,\u03b7 \u2212 \u2016W \u2032 \u2212 TW\u2016p,\u03b7\u0302 \u2223 \u2223 > \u01eb2 } \u222a { \u2223 \u2223\u2016w\u2217 \u2212 TW\u2016p,\u03b7\u0302 \u2212 \u2016w\u2217 \u2212 TW\u2016p,\u03b7 \u2223 \u2223 > \u01eb2 }}\n\u2264 P {\nsup w\u2208W\n\u2223 \u2223\u2016w \u2212 TW\u2016pp,\u03b7 \u2212 \u2016w \u2212 TW\u2016pp,\u03b7\u0302 \u2223 \u2223 > \u01ebp2\n}\n\u2264 \u03b42.\nThus the probability that the inequalities (27a) and (27e) do not hold is less then \u03b42.\nThe second and fourth inequalities (27b),(27d) depend the accuracy of the estimation of the backward recursion at each base point xik. Employing the inequality |\u2016w \u2212 g\u2016p,\u03b7\u0302 \u2212 \u2016w \u2212 h\u2016p,\u03b7\u0302| \u2264 \u2016g \u2212 h\u2016p,\u03b7\u0302, we can see that\n\u2223 \u2223 \u2223 \u2016W \u2032 \u2212 TW\u2016p,\u03b7\u0302 \u2212 \u2016W \u2032 \u2212 T\u0302W\u2016p,\u03b7\u0302 \u2223 \u2223 \u2223 \u2264 \u2016TW \u2212 T\u0302W\u2016p,\u03b7\u0302,\nand \u2223\n\u2223 \u2223 \u2016w\u2217 \u2212 T\u0302W\u2016p,\u03b7\u0302 \u2212 \u2016w\u2217 \u2212 TW\u2016p,\u03b7\u0302\n\u2223 \u2223 \u2223 \u2264 \u2016TW \u2212 T\u0302W\u2016p,\u03b7\u0302.\nFor every sample set \u03c9 the inequalities (27b),(27d) apply if \u2016TW \u2212 T\u0302W\u2016p,\u03b7\u0302 \u2264 \u01eb1. Thus\nP {{ \u2016W \u2032 \u2212 TW\u2016p,\u03b7\u0302 \u2212 \u2016W \u2032 \u2212 T\u0302W\u2016p,\u03b7\u0302 > \u01eb1 } \u222a { \u2016w\u2217 \u2212 T\u0302W\u2016p,\u03b7\u0302 \u2212 \u2016w\u2217 \u2212 TW\u2016p,\u03b7\u0302 > \u01eb1 }}\n\u2264 P { \u2016TW \u2212 T\u0302W\u2016p,\u03b7\u0302 > \u01eb1 }\n\u2264 \u03b41. (28)\nThe probability that at least one of the inequalities in (27) does not hold can be expressed using the union bound as \u03b41 + \u03b42. Thus the sequence of inequalities holds with at least a probability of 1\u2212 \u03b41 \u2212 \u03b42."}, {"heading": "Appendix D. Proof of Lemma 9", "text": "Proof Let us set up the following chain of inequalities:\n\u2016TNt\u2212kW\u0302 \u2217Nt \u2212 W\u0302 \u2217k \u2016p,\u03b7 = [ Add and subtract function TW\u0302 \u2217k+1 ]\n= \u2016T (\nT Nt\u2212k\u22121W\u0302 \u2217Nt \u2212 W\u0302 \u2217k+1 + W\u0302 \u2217k+1\n)\n\u2212 W\u0302 \u2217k \u2016p,\u03b7 = [ Definition of T in (2), where we have considered a single xk \u223c \u03b7 ] = \u2225 \u2225\n\u2225 max a\u2208A\nE [ 1K(xk+1) + 1A\\K(xk+1) ( T Nt\u2212k\u22121W\u0302 \u2217Nt \u2212 W\u0302 \u2217k+1 + W\u0302 \u2217k+1 ) (xk+1) \u2223 \u2223xk+1 \u223c Tx (\u00b7 | xk, a) ]\n\u2212 W\u0302 \u2217k \u2225 \u2225 \u2225\np,\u03b7\n= [ maxE[\u03be1 + \u03be2] \u2264 maxE|\u03be1|+maxE|\u03be2| ] \u2264 \u2225 \u2225 \u2225\n\u2225 max a\u2208A\nE \u2223 \u2223\n\u2223 1A\\K(xk+1)\n(\nT Nt\u2212k\u22121W\u0302 \u2217Nt \u2212 W\u0302 \u2217k+1\n) (xk+1)|xk+1 \u223c Tx (\u00b7 | xk, a) \u2223 \u2223 \u2223\n+max a\u2208A\nE \u2223 \u2223\n\u2223 1K(xk+1) + 1A\\K(xk+1)W\u0302 \u2217 k+1(xk+1)|xk+1 \u223c Tx (\u00b7 | xk, a)\n\u2223 \u2223 \u2223 \u2212 W\u0302 \u2217k\n\u2225 \u2225 \u2225 \u2225\np,\u03b7\n= [ Triangular inequality] \u2264 \u2225 \u2225 \u2225\n\u2225 max a\u2208A\nE \u2223 \u2223\n\u2223 1A\\K(xk+1)\n(\nT Nt\u2212k\u22121W\u0302 \u2217Nt \u2212 W\u0302 \u2217k+1\n) (xk+1)|xk+1 \u223c Tx (\u00b7 | xk, a) \u2223 \u2223 \u2223\n\u2225 \u2225 \u2225 \u2225\np,\u03b7\n+\n\u2225 \u2225 \u2225 \u2225\nmax a\u2208A\nE \u2223 \u2223\n\u2223 1K(xk+1) + 1A\\K(xk+1)W\u0302 \u2217 k+1(xk+1)|xk+1 \u223c Tx (\u00b7 | xk, a)\n\u2223 \u2223 \u2223 \u2212 W\u0302 \u2217k\n\u2225 \u2225 \u2225 \u2225\np,\u03b7\n= [ Definition of T in (2) ]\n=\n\u2225 \u2225 \u2225 \u2225\nmax a\u2208A\nE [ \u2223 \u2223\n\u2223 1A\\K(xk+1)\n(\nT Nt\u2212k\u22121W\u0302 \u2217Nt \u2212 W\u0302 \u2217k+1\n) (xk+1) \u2223 \u2223 \u2223 |xk+1 \u223c Tx (\u00b7 | xk, a) ]\n\u2225 \u2225 \u2225 \u2225\np,\u03b7\n+ \u2225 \u2225\n\u2225 TW\u0302 \u2217k+1 \u2212 W\u0302 \u2217k\n\u2225 \u2225 \u2225\np,\u03b7\n= [ Introduce density function tx (xk+1 | xk, a) for kernel Tx ]\n=\n\u2225 \u2225 \u2225 \u2225\nmax a\u2208A\n\u222b\nX\n\u2223 \u2223 \u2223 1A\\K(xk+1) ( T Nt\u2212k\u22121W\u0302 \u2217Nt \u2212 W\u0302 \u2217k+1 ) (xk+1) \u2223 \u2223 \u2223 tx(xk+1|xk, a)dxk+1\n\u2225 \u2225 \u2225 \u2225\np,\u03b7\n\u2225 \u2225 \u2225 TW\u0302 \u2217k+1 \u2212 W\u0302 \u2217k \u2225 \u2225 \u2225\np,\u03b7 .\nLet us now show that the first term is bounded by B 1 p\n\u2225 \u2225 \u2225 T Nt\u2212k\u22121W\u0302 \u2217Nt \u2212 W\u0302 \u2217k+1 \u2225 \u2225 \u2225\np,\u03b7 :\n\u2225 \u2225 \u2225 \u2225\nmax a\u2208A\n\u222b\nX\n\u2223 \u2223 \u2223 1A\\K(xk+1) ( T Nt\u2212k\u22121W\u0302 \u2217Nt \u2212 W\u0302 \u2217k+1 ) \u2223 \u2223 \u2223 tx(xk+1|xk, a)dxk+1\n\u2225 \u2225 \u2225 \u2225\np,\u03b7\n= [ monotonicity of Lp-norms with respect to a probability measure ] \u2264 \u2225 \u2225 \u2225\n\u2225 \u2225 max a\u2208A\n( \u222b\nX\n\u2223 \u2223 \u2223 1A\\K(xk+1) ( T Nt\u2212k\u22121W\u0302 \u2217Nt \u2212 W\u0302 \u2217k+1 )\u2223 \u2223 \u2223 p tx(xk+1|xk, a)dxk+1\n) 1 p\n\u2225 \u2225 \u2225 \u2225 \u2225\np,\u03b7\n= [ Express the \u03b7-weighted p-norm over A \\K ]\n=\n(\n\u222b\nA\\K\n\u2223 \u2223 \u2223 \u2223 maxa\u2208A \u2223 \u2223 \u2223 \u222b A\\K \u2223 \u2223 \u2223 T Nt\u2212k\u22121W\u0302 \u2217Nt \u2212 W\u0302 \u2217k+1 \u2223 \u2223 \u2223 p tx(xk+1|xk, a)dxk+1 \u2223 \u2223 \u2223 1 p \u2223 \u2223 \u2223 \u2223\np\n\u03b7(xk)dxk\n) 1 p\n=\n(\n\u222b\nA\\K maxa\u2208A\n\u2223 \u2223 \u2223 \u2223 \u2223 \u2223 \u2223 \u222b A\\K \u2223 \u2223 \u2223 T Nt\u2212k\u22121W\u0302 \u2217Nt \u2212 W\u0302 \u2217k+1 \u2223 \u2223 \u2223 p tx(xk+1|xk, a)dxk+1 \u2223 \u2223 \u2223 1 p \u2223 \u2223 \u2223 \u2223\np\n\u03b7(xk)dxk\n) 1 p\n= ( \u222b\nA\\K maxa\u2208A \u222b A\\K\n\u2223 \u2223 \u2223 T Nt\u2212k\u22121W\u0302 \u2217Nt \u2212 W\u0302 \u2217k+1 \u2223 \u2223 \u2223 p tx(xk+1|xk, a)dxk+1\u03b7(xk)dxk\n) 1 p\n\u2264 ( \u222b\nA\\K\n\u222b\nA\\K maxa\u2208A\n( \u2223\n\u2223 \u2223 T Nt\u2212k\u22121W\u0302 \u2217Nt \u2212 W\u0302 \u2217k+1\n\u2223 \u2223 \u2223 p tx(xk+1|xk, a) ) dxk+1\u03b7(xk)dxk\n) 1 p\n= [ Introduce dummy term \u03b7(xk+1) \u03b7(xk+1) , which is defined over xk+1 \u2208 A \\K ]\n= ( \u222b\nA\\K\n\u222b\nA\\K maxa\u2208A\n( \u2223\n\u2223 \u2223 T Nt\u2212k\u22121W\u0302 \u2217Nt \u2212 W\u0302 \u2217k+1\n\u2223 \u2223 \u2223 p tx(xk+1|xk, a) )\n\u03b7(xk) \u03b7(xk+1) dxk\u03b7(xk+1)dxk+1\n) 1 p\n= [ Recall that \u2223 \u2223\n\u2223 T Nt\u2212k\u22121W\u0302 \u2217Nt \u2212 W\u0302 \u2217k+1\n\u2223 \u2223 \u2223 p is only a function of xk+1 ]\n= ( \u222b\nA\\K\n\u2223 \u2223 \u2223 T Nt\u2212k\u22121W\u0302 \u2217Nt \u2212 W\u0302 \u2217k+1 \u2223 \u2223 \u2223 p \u222b A\\K ( maxa\u2208A tx(xk+1|xk,a)\u03b7(xk)\n\u03b7(xk+1)\n)\ndxk\u03b7(xk+1)dxk+1\n) 1 p .\nIntroduce now the upper bound on \u222b\nA\\K\n(\nmaxa\u2208A tx(xk+1|xk,a)\u03b7(xk)\n\u03b7(xk+1)\n)\ndxk over the domain\nA \\K as B = supxk+1\u2208A\\K \u222b A\\K maxa\u2208A tx(xk+1|xk,a)\u03b7(xk) \u03b7(xk+1) dxk, obtaining\n\u2264 ( \u222b\nA\\K\n\u2223 \u2223 \u2223 T Nt\u2212k\u22121W\u0302 \u2217Nt \u2212 W\u0302 \u2217k+1 \u2223 \u2223 \u2223 p B\u03b7(xk+1)dxk+1 ) 1 p = B 1 p \u2016TNt\u2212k\u22121W\u0302 \u2217Nt \u2212 W\u0302 \u2217k+1\u2016p,\u03b7.\nWe have finally shown that \u2225 \u2225\n\u2225 T Nt\u2212kW\u0302 \u2217Nt \u2212 W\u0302 \u2217k\n\u2225 \u2225 \u2225\np,\u03b7 \u2264\n\u2225 \u2225 \u2225 TW\u0302 \u2217k+1 \u2212 W\u0302 \u2217k \u2225 \u2225 \u2225\np,\u03b7 +B\n1 p\n\u2225 \u2225 \u2225 T Nt\u2212k\u22121W\u0302 \u2217Nt \u2212 W\u0302 \u2217k+1 \u2225 \u2225 \u2225\np,\u03b7 ."}, {"heading": "Appendix E. Proof of Theorem 10", "text": "Proof If we estimate the quantity r\u2217x0(K,A) = ( T NtW \u2217Nt ) (x0) = ( T NtW\u0302 \u2217Nt )\n(x0) by (\nT\u0302W\u0302 \u22171\n)\n(x0), then we have that r\u0302 \u2217 x0(K,A) = 1K(x0)+1A\\K(x0)\n(\nT\u0302W\u0302 \u22171\n)\n(x0). The absolute\ndeviation of the approximated r\u0302\u2217x0(K,A) from the exact r \u2217 x0(K,A) is given as\n\u2223 \u2223r\u0302\u2217x0(K,A) \u2212 r\u2217x0(K,A) \u2223\n\u2223 = \u2223 \u2223\n\u2223\n(\nT NtW\u0302 \u2217Nt\n) (x0)\u2212 ( T\u0302W\u0302 \u22171 ) (x0) \u2223 \u2223 \u2223 .\nThe objective is to present this error as a function of the errors introduced by the\napproximate mappings \u2223 \u2223\n\u2223\n(\nT NtW\u0302 \u2217Nt\n) (x0)\u2212 ( T\u0302W\u0302 \u22171 ) (x0) \u2223 \u2223 \u2223 , as well as of the quantities \u2016W\u0302 \u22171 \u2212\nTW\u0302 \u22172 \u2016p,\u03b7, \u2016W\u0302 \u22172 \u2212 TW\u0302 \u22173 \u2016p,\u03b7, . . . , \u2016W\u0302 \u2217Nt\u22121 \u2212 TW\u0302 \u2217Nt\u2016p,\u03b7. To this end, we first express a bound on \u2223 \u2223\n\u2223\n(\nT NtW\u0302 \u2217Nt\n) (x0)\u2212 ( T\u0302W\u0302 \u22171 ) (x0) \u2223 \u2223 \u2223 as a function\nof | ( T\u0302 (\nTW\u0302 \u22171\n) (x0)\u2212 W\u0302 \u22171 ) (x0)| and of \u2225 \u2225 \u2225 T Nt\u22121W\u0302 \u2217Nt \u2212 W\u0302 \u22171 \u2225 \u2225 \u2225\np,\u03b7 . Then Lemma 9 is used to\nexpress \u2016TNt\u22121W\u0302 \u2217Nt \u2212 W\u0302 \u22171 \u2016p,\u03b7 as a function of the errors introduced by the approximate mappings. Similar to the first chain of inequality in the proof of Lemma 9 applied at step k = 0 and point x0, we obtain that\n\u2223 \u2223 \u2223 (\nT NtW\u0302 \u2217Nt\n) (x0)\u2212 ( T\u0302W\u0302 \u22171 ) (x0) \u2223 \u2223 \u2223\n\u2264 max a\u2208A\n\u222b\nA\\K\n\u2223 \u2223 \u2223 T Nt\u22121W\u0302 \u2217Nt(x1)\u2212 W\u0302 \u22171 (x1) \u2223 \u2223 \u2223 tx (x1 | x0, a) dx1 + \u2223 \u2223 \u2223 ( TW\u0302 \u22171 ) (x0)\u2212 ( T\u0302W\u0302 \u22171 ) (x0) \u2223 \u2223 \u2223 .\nLet us now introduce a measure for the maximum concentration of the density function tx (x1 | x0, a) over x1 \u2208 A \\K, for any a \u2208 A, defined relative to the density of the distribution \u03b7 in (16), as B0 = supx1\u2208A\\K maxa\u2208A tx(x1|x0,a) \u03b7(x1)\n. Since B0\u03b7(x1) \u2265 tx (x1 | x0, a), it follows that\nmax a\u2208A\n\u222b\nA\\K\n\u2223 \u2223 \u2223 T Nt\u22121W\u0302 \u2217Nt(x1)\u2212 W\u0302 \u22171 (x1) \u2223 \u2223 \u2223 tx (x1 | x0, a) dx1 \u2264 B0\n\u222b\nA\\K\n\u2223 \u2223 \u2223 T Nt\u22121W\u0302 \u2217Nt(x1)\u2212 W\u0302 \u22171 (x1) \u2223 \u2223 \u2223 \u03b7(x1)dx1.\nThe last expression corresponds to a 1-norm with respect to a probability measure \u03b7 over A \\K. Exploiting the monotonicity of the p-norm with respect to a probability measure, a more general expression for the approximation error is obtained as \u2223 \u2223 \u2223 (\nT NtW\u0302 \u2217Nt\n) (x0)\u2212 T\u0302W\u0302 \u22171 (x0) \u2223 \u2223 \u2223 \u2264 \u2223 \u2223 \u2223 ( T\u0302W\u0302 \u22171 ) (x0)\u2212 ( TW\u0302 \u22171 ) (x0) \u2223 \u2223 \u2223 +B0 \u2225 \u2225 \u2225 ( T Nt\u22121W\u0302 \u2217Nt ) \u2212 W\u0302 \u22171 \u2225 \u2225 \u2225\np,\u03b7 .\nThe second term can be expressed as a function of the weighted p-norm of the approximations by applying Lemma 9. This leads to the expression for an upper bound on the approximation error as\n\u2223 \u2223r\u0302\u2217x0(K,A) \u2212 r\u2217x0(K,A) \u2223\n\u2223 \u2264 \u2223 \u2223\n\u2223\n(\nT\u0302W\u0302 \u22171\n) (x0)\u2212 ( TW\u0302 \u22171 ) (x0) \u2223 \u2223 \u2223 +B0 \u2211Nt\u22121 k=1 B k\u22121 p \u2225 \u2225 \u2225 W\u0302 \u2217k \u2212 TW\u0302 \u2217k+1 \u2225 \u2225 \u2225\np,\u03b7 .\nFrom the above expression, a sufficient condition the accuracy in (3) to hold is\nP { \u2223 \u2223\n\u2223\n(\nT\u0302W\u0302 \u22171\n) (x0)\u2212 ( TW\u0302 \u22171 ) (x0) \u2223 \u2223 \u2223 +B0\nNt\u22121 \u2211\nk=1\nB k\u22121 p\n\u2225 \u2225 \u2225 W\u0302 \u2217k \u2212 TW\u0302 \u2217k+1 \u2225 \u2225 \u2225\np,\u03b7 > \u2206\n}\n\u2264 \u03b4\u2206."}, {"heading": "Appendix F. Sample Complexities", "text": "Given \u01eb0,1,2 and \u03b1, select \u03b40,1,2 > 0 such that 1\u2212 \u03b1 = \u03b40 + (Nt \u2212 1)\u03b41 + (Nt \u2212 1)\u03b42, and let us pick values for N ,M , M0 such that\n\u03b40 \u2264 2|A|e\u22122M0(\u01eb0) 2 , \u03b41 \u2264 2|A|Ne\u22122M(\u01eb1) 2 , \u03b42 \u2264 4e(d + 1)\n(32e\n\u01ebp2\n)d e\u2212\nN\u01eb 2p 2\n128 .\nNote that the first two inequalities are approximated with first order approximation for which we know that 1\u2212 (1\u22122e\u22122M0(\u01eb0)2)|A| \u2264 2|A|e\u22122M0(\u01eb0)2 and 1\u2212 (1\u22122e\u22122M(\u01eb1)2)|A|N \u2264 2|A|Ne\u22122M(\u01eb1)2 . The obtained integer values for N ,M , M0 are given as \n    \n    \nN = \u2308 128 (ln(4e(d + 1)) + d ln(32e)) (\n1 \u01eb2\n)2p + 128dp (\n1 \u01eb2\n)2p ln (\n1 \u01eb2\n) + 128 (\n1 \u01eb2\n)2p ln (\n1 \u03b42\n)\u2309\n,\nM = \u2308\n1 2\n(\n1 \u01eb1\n)2 (\nln(2|A|) + ln( 1\u03b41 ) + ln(N) ) \u2309 ,\nM0 = \u2308 1 2 ( 1 \u01eb0\n)2 (\nln(2|A|) + ln( 1\u03b40 ) )\u2309 ,\n.\nThe use of the obtained M,M0, N in (17) leads to a confidence of at least \u03b1."}, {"heading": "Appendix G. Proof of Theorem 12", "text": "Proof The proof of Theorem 12 is built observing that (a.) the single step error \u2016W\u0302 \u2217k \u2212 TW\u0302 \u2217k+1\u20161,\u03b7 is bounded by the sum of the expectations of (19) and (21); that (b.) the propagation of the single step errors gives a bound on the overall approximation error, see Theorem 10 \u2013 hence the expected value of the estimates, propagated over the time horizon, also gives a bound on the approximation error; and that (c.) the one-sided application of the Hoeffding\u2019s inequality provides a probabilistic upper bound on the deviation of the estimate from its mean, and therefore also bounds the approximation error probabilistically. Part (a.)\n\u2016W\u0302 \u2217k \u2212 TW\u0302 \u2217k+1\u20161,\u03b7 = Ex [ \u2223 \u2223 \u2223 W\u0302 \u2217k (x)\u2212 TW\u0302 \u2217k+1(x) \u2223 \u2223 \u2223 ] with Ex [f(x)] the mean of f(x) for x \u223c \u03b7.\nDefine a set of i.i.d. random variables ~y1 = [y a,1 1 , y a,2 1 , . . . , y a,M\u0303 1 ] drawn from the distribution ya,j1 \u223c Tx (\u00b7 | x, a). Introduce E~y1 [ maxa\u2208A T\u0302 a 1W\u0302 \u2217 k+1(x)|x ]\nas an auxiliary variable with T\u0302a1 the estimated operator as defined in (20) and computed over the ~y1.\n= Ex [ \u2223 \u2223 \u2223 \u2223W\u0302 \u2217 k (x)\u2212 E~y1 [\nmax a\u2208A\nT\u0302 a 1W\u0302 \u2217 k+1(x)|x\n]\n+ E~y1\n[\nmax a\u2208A\nT\u0302 a 1W\u0302 \u2217 k+1(x)|x\n]\n\u2212 TW\u0302 \u2217k+1(x) \u2223 \u2223 \u2223 \u2223 ]\n\u2264 Ex [\u2223 \u2223 \u2223 \u2223 W\u0302 \u2217k (x)\u2212 E~y1 [\nmax a\u2208A\nT\u0302 a 1W\u0302 \u2217 k+1(x)|x ]\u2223 \u2223 \u2223 \u2223 ] +Ex [\u2223 \u2223 \u2223 \u2223 E~y1 [\nmax a\u2208A\nT\u0302 a 1W\u0302 \u2217 k+1(x)|x\n]\n\u2212 TW\u0302 \u2217k+1(x) \u2223 \u2223 \u2223 \u2223 ]\n\u2264 Ex, ~y1 [\u2223 \u2223 \u2223 \u2223W\u0302 \u2217 k (x)\u2212max\na\u2208A T\u0302 a 1W\u0302 \u2217 k+1(x)\n\u2223 \u2223 \u2223 \u2223 ]\n\ufe38 \ufe37\ufe37 \ufe38\n[ Single step error ]\n+Ex [\u2223 \u2223 \u2223 \u2223E~y1 [\nmax a\u2208A\nT\u0302 a 1W\u0302 \u2217 k+1(x)|x\n]\n\u2212 TW\u0302 \u2217k+1(x) \u2223 \u2223 \u2223 \u2223 ]\n\ufe38 \ufe37\ufe37 \ufe38\n[ Bias term ]\n.\nObserve that the single step error, Ex, ~y1\n[\n\u2223 \u2223W\u0302 \u2217k (x)\u2212maxa\u2208A T\u0302a1W\u0302 \u2217k+1(x) \u2223 \u2223\n]\nis equal to \u2016W\u0302 \u2217k \u2212 T\u0302W\u0302 \u2217k+1\u20161,\u03b7 and E\u2016W\u0302 \u2217k \u2212 T\u0302W\u0302 \u2217k+1\u20161,\u03b7\u0303. The bias term gives the bias introduced by using an estimate of the operator and it can be rewritten as the expected value of (21). Note that maxa\u2208AEy [Vk+1(y)|x, a] is a function of x, a and |E~y1 [f(~y)] | \u2264 E~y1 [|f(~y)|], thus it follows that\n[ Bias term ] \u2264 ExE~y1 [ \u2223 \u2223 \u2223 \u2223 max a\u2208A T\u0302 a 1W\u0302 \u2217 k+1(x)\u2212 TW\u0302 \u2217 k+1(x) \u2223 \u2223 \u2223 \u2223 \u2223 \u2223 \u2223 \u2223 x ] \u2264 ExE~y1 [ max a\u2208A \u2223 \u2223 \u2223T\u0302 a 1W\u0302 \u2217 k+1(x) \u2212E~y2 [ T\u0302 a 2W\u0302 \u2217 k+1(x)|x ]\u2223 \u2223 \u2223 \u2223 \u2223 \u2223 \u2223 x ] .\nThe second inequality follows from introducing a secondary set of random variables ~y2 = [ya,12 , y a,2 2 , . . . , y a,1M\u0303 2 ] for which the elements are i.i.d. as y a,1 2 \u223c Tx (\u00b7 | x, a) and which are independent of ~y1. Substituting TW\u0302 \u2217 k+1(x) with maxa\u2208AE~y2 [ T\u0302 a 2W\u0302 \u2217 k+1(x)|x, a ] we have\n[ Bias term ] \u2264 ExE~y1\n[\nmax a\u2208A E~y2\n[\u2223 \u2223 \u2223T\u0302\na 1W\u0302 \u2217 k+1(x)\u2212 T\u0302 a 2W\u0302 \u2217 k+1(x) \u2223 \u2223 \u2223 |x, a, ~y1 ] |x\n]\n= Ex,~y1,~y2\n[\nmax a\u2208A\n\u2223 \u2223 \u2223T\u0302 a 1W\u0302 \u2217 k+1(x)\u2212 T\u0302 a 2W\u0302 \u2217 k+1(x) \u2223 \u2223 \u2223\n]\n.\nThe last equality is equal to the expected value of the estimated bias E \u2225 \u2225maxa\u2208A \u2223 \u2223T\u0302 a 1W\u0302 \u2217 k+1\u2212\nT\u0302 a 2W\u0302 \u2217 k+1\n\u2223 \u2223 \u2225 \u2225\n1,\u03b7\u0303 . This proves statement (a.).\nPart (b.) & (c.) Based on Theorem 10 r\u0302\u2217x0(K,A) has accuracy \u2206 with probability \u03b4\u2206 if\nP\n{\n|W\u0302 \u22170 (x0)\u2212 TW\u0302 \u2217 1 (x0)|+ B0\nNt\u22121\u2211\nk=1\nBk\u22121E [\u2223 \u2223 \u2223 \u2223 W\u0302 \u2217k (x) \u2212max\na\u2208A T\u0302 a 1W\u0302 \u2217 k+1(x)\n\u2223 \u2223 \u2223 \u2223 +max\na\u2208A\n\u2223 \u2223 \u2223T\u0302 a 1W\u0302 \u2217 k+1(x)\u2212 T\u0302 a 2W\u0302 \u2217 k+1(x) \u2223 \u2223 \u2223\n]\n\u2265 \u2206 }\n< \u03b4\u2206.\nWhich holds under a union bounding argument if\nP\n{\n|W\u0302 \u22170 (x0)\u2212 TW\u0302 \u2217 1 (x0)| \u2265 \u01eb0\n}\n< \u03b40 (29)\nP\n \n\nB0 \u2211Nt\u22121\nk=1 B k\u22121E [\u2223 \u2223 \u2223W\u0302 \u2217k (x)\u2212maxa\u2208A T\u0302 a 1W\u0302 \u2217 k+1(x) \u2223 \u2223 \u2223 +maxa\u2208A \u2223 \u2223 \u2223T\u0302 a 1W\u0302 \u2217 k+1(x)\u2212 T\u0302 a 2W\u0302 \u2217 k+1(x) \u2223 \u2223 \u2223 ] \u2265 B0\u01eb\n+B0 \u2211Nt\u22121\nk=1 B k\u22121 (\u2225 \u2225 \u2225W\u0302 \u2217k \u2212 T\u0302W\u0302 \u2217 k+1 \u2225 \u2225 \u2225 1,\u03b7\u0303 + \u2225 \u2225 \u2225maxa\u2208A \u2223 \u2223 \u2223T\u0302 a 1W\u0302 \u2217 k+1 \u2212 T\u0302 a 2W\u0302 \u2217 k+1 \u2223 \u2223 \u2223 \u2225 \u2225 \u2225 1,\u03b7\u0303 )\n \n\n< e \u22122 N\u0303\u01eb\n2\nL2\n(30)\nand \u2206 and \u03b4\u2206 are given as (22a) and (22b). The probabilistic bound (29) follows from Lemma 8 for the estimation error of an empirical norm with accuracy \u01eb0, \u03b40 obtained for p = 1, M = M0 and N = 1 as long as 0 < 2e\n\u22122M0\u01eb20 < 1. The probabilistic bound (30) follows from a one-sided Hoeffding\u2019s inequality (Hoeffding, 1963) with random variable\n\u2211Nt\u22121 k=1 B\nk\u22121 (\u2223 \u2223\n\u2223 W\u0302 \u2217k (x)\u2212maxa\u2208A T\u0302a1W\u0302 \u2217k+1(x)\n\u2223 \u2223 \u2223 +maxa\u2208A \u2223 \u2223 \u2223 T\u0302 a 1W\u0302 \u2217 k+1(x)\u2212 T\u0302a2W\u0302 \u2217k+1(x) \u2223 \u2223 \u2223 ) ,\nobtained from the combination of random variable x \u223c \u03b7 and conditional random variables ~y1 and ~y2 and taking values in the range [0, 2 \u2211Nt\u22121 k=1 B\nk\u22121]. Note that its estimated of interest over N\u0303 samples can be rewritten in the form of (22a),\n\u2211Nt\u22121 k=1 B\nk\u22121 ( \u2225\n\u2225W\u0302 \u2217k \u2212 T\u0302W\u0302 \u2217k+1 \u2225 \u2225 1,\u03b7\u0303 + \u2225 \u2225maxa\u2208A\n\u2223 \u2223 \u2223 T\u0302 a 1W\u0302 \u2217 k+1 \u2212 T\u0302a2W\u0302 \u2217k+1 \u2223 \u2223 \u2223 \u2225 \u2225\n1,\u03b7\u0303\n)\n.\nThis concludes the proof of Theorem 12."}, {"heading": "Appendix H. Scaling factor for case study", "text": "Compute B as in (14) using the given density distribution of the transitions (25), as\nB = sup y\u2208A\\K\n\u222b\nA\\K\n1 \u221a\n|\u03a3|(2\u03c0)2 max a\u2208A\n( exp ( \u2212 12 (y \u2212 \u00b5) T \u03a3\u22121 (y \u2212 \u00b5) ) \u03b7(x)\n\u03b7(y)\n)\ndx\n= [ \u00b5 is a function of a and x, and \u03b7(\u00b7) is constant over A \\K ]\n= sup y\u2208A\\K\n\u222b\nA\\K\n1 \u221a\n|\u03a3|(2\u03c0)2 max a\u2208A exp\n(\n\u22121 2 (y \u2212 \u00b5)T \u03a3\u22121 (y \u2212 \u00b5)\n)\ndx\n= [Suppose A is invertible, and define \u00b5\u0304(y, a) = A\u22121y \u2212A\u22121Ba\u2212A\u22121C, \u03a3\u0304 = A\u22121\u03a3A\u2212T ]\n= sup y\u2208A\\K\n1\n|A|\n\u222b\nA\\K\n1 \u221a\n|\u03a3\u0304|(2\u03c0)2 max a\u2208A exp\n(\n\u22121 2 (x\u2212 \u00b5\u0304(y, a))T \u03a3\u0304\u22121 (x\u2212 \u00b5\u0304(y, a))\n)\ndx\n\u2264 sup y\u2208A\\K\n1\n|A|\n\u222b\nA\\K\n1 \u221a |\u03a3\u0304|(2\u03c0)2 \u2211\na\u2208A\n(\nexp\n(\n\u22121 2 (x\u2212 \u00b5\u0304(y, a))T \u03a3\u0304\u22121 (x\u2212 \u00b5\u0304(y, a))\n))\ndx\n= sup y\u2208A\\K\n1\n|A|\n(\n\u2211\na\u2208A\n\u222b\nA\\K\n1 \u221a\n|\u03a3\u0304|(2\u03c0)2 exp\n(\n\u22121 2 (x\u2212 \u00b5\u0304(y, a))T \u03a3\u0304\u22121 (x\u2212 \u00b5\u0304(y, a))\n)\ndx\n)\n.\nThe integral is rewritten as one over a scaled 2-dimension multivariate Gaussian density distribution with mean \u00b5\u0304 and covariance \u03a3\u0304. With this result, it can be deduced that B is smaller than 1|A| |A| as\nB \u2264 sup y\u2208A\\K\n1 |A| ( \u2211\na\u2208A\n\u222b\nX\n1\u221a |\u03a3\u0304|(2\u03c0)2\nexp (\n\u221212 (x\u2212 \u00b5\u0304(y, a)) T \u03a3\u0304\u22121 (x\u2212 \u00b5\u0304(y, a))\n) dx )\n(31)\n\u2264 sup y\u2208A\\K\n1\n|A| \u2211 a\u2208A 1 = 1|A| |A|."}], "references": [{"title": "Probabilistic reachability and safety for controlled discrete time stochastic hybrid systems", "author": ["A. Abate", "M. Prandini", "J. Lygeros", "S. Sastry"], "venue": null, "citeRegEx": "Abate et al\\.,? \\Q2008\\E", "shortCiteRegEx": "Abate et al\\.", "year": 2008}, {"title": "Approximate model checking of stochastic hybrid systems", "author": ["A. Abate", "J.P. Katoen", "J. Lygeros", "M. Prandini"], "venue": "European Journal of Control,", "citeRegEx": "Abate et al\\.,? \\Q2010\\E", "shortCiteRegEx": "Abate et al\\.", "year": 2010}, {"title": "Quantitative automata model checking of autonomous stochastic hybrid systems", "author": ["A. Abate", "J.-P. Katoen", "A. Mereacre"], "venue": "In Proceedings of the 14th ACM international conference on Hybrid Systems: computation and control,", "citeRegEx": "Abate et al\\.,? \\Q2011\\E", "shortCiteRegEx": "Abate et al\\.", "year": 2011}, {"title": "Uniform Glivenko-Cantelli theorems and concentration of measure in the mathematical modelling of learning", "author": ["M. Anthony"], "venue": "Research report, Department of Mathematics London School of Economics,", "citeRegEx": "Anthony.,? \\Q2002\\E", "shortCiteRegEx": "Anthony.", "year": 2002}, {"title": "Neural Network Learning: Theoretical Foundations", "author": ["M. Anthony", "P.L. Bartlett"], "venue": "cambridge university press,", "citeRegEx": "Anthony and Bartlett.,? \\Q1999\\E", "shortCiteRegEx": "Anthony and Bartlett.", "year": 1999}, {"title": "Principles of Model Checking", "author": ["C. Baier", "J.-P. Katoen"], "venue": null, "citeRegEx": "Baier and Katoen.,? \\Q2008\\E", "shortCiteRegEx": "Baier and Katoen.", "year": 2008}, {"title": "Local Rademacher Complexities", "author": ["P.L. Bartlett", "O. Bousquet", "S. Mendelson"], "venue": "Annals of Statistics,", "citeRegEx": "Bartlett et al\\.,? \\Q2005\\E", "shortCiteRegEx": "Bartlett et al\\.", "year": 2005}, {"title": "Stochastic Optimal Control: The discrete time case", "author": ["D.P. Bertsekas", "S.E. Shreve"], "venue": "Athena Scientific,", "citeRegEx": "Bertsekas and Shreve.,? \\Q1996\\E", "shortCiteRegEx": "Bertsekas and Shreve.", "year": 1996}, {"title": "Stochastic Hybrid Systems: Theory and Safety Critical Applications. Number 337 in Lecture Notes in Control and Information Sciences", "author": ["H.A.P. Blom", "J. Lygeros"], "venue": null, "citeRegEx": "Blom and Lygeros.,? \\Q2006\\E", "shortCiteRegEx": "Blom and Lygeros.", "year": 2006}, {"title": "Reinforcement Learning and Dynamic Programming Using Function Approximators. Automation and Control Engineering", "author": ["L. Busoniu", "R. Babuska", "B.D. Schutter", "D. Ernst"], "venue": null, "citeRegEx": "Busoniu et al\\.,? \\Q2010\\E", "shortCiteRegEx": "Busoniu et al\\.", "year": 2010}, {"title": "Stochastic Hybrid Systems. Number 24 in Control Engineering", "author": ["C.G. Cassandras", "J. Lygeros"], "venue": "CRC Press, Boca Raton,", "citeRegEx": "Cassandras and Lygeros.,? \\Q2006\\E", "shortCiteRegEx": "Cassandras and Lygeros.", "year": 2006}, {"title": "Adaptive and sequential gridding procedures for the abstraction and verification of stochastic processes", "author": ["S. Esmaeil Zadeh Soudjani", "A. Abate"], "venue": "SIAM Journal on Applied Dynamical Systems,", "citeRegEx": "Soudjani and Abate.,? \\Q2013\\E", "shortCiteRegEx": "Soudjani and Abate.", "year": 2013}, {"title": "Error Propagation for Approximate Policy and Value Iteration", "author": ["A.M. Farahmand", "R. Munos", "C. Szepesvari"], "venue": "In Neural Information Processing Systems,", "citeRegEx": "Farahmand et al\\.,? \\Q2010\\E", "shortCiteRegEx": "Farahmand et al\\.", "year": 2010}, {"title": "Benchmarks for hybrid systems verification", "author": ["A. Fehnker", "F. Ivan\u010di\u0107"], "venue": "In Hybrid Systems: Computation and Control (HSCC", "citeRegEx": "Fehnker and Ivan\u010di\u0107.,? \\Q2004\\E", "shortCiteRegEx": "Fehnker and Ivan\u010di\u0107.", "year": 2004}, {"title": "Layered neural networks with gaussian hidden units as universal approximations", "author": ["E.J. Hartman", "J.D. Keeler", "J.M. Kowalski"], "venue": "Neural computation,", "citeRegEx": "Hartman et al\\.,? \\Q1990\\E", "shortCiteRegEx": "Hartman et al\\.", "year": 1990}, {"title": "Decision theoretic generalizations of the PAC model for neural net and other learning applications", "author": ["D. Haussler"], "venue": "Information and Computation/information and Control,", "citeRegEx": "Haussler.,? \\Q1992\\E", "shortCiteRegEx": "Haussler.", "year": 1992}, {"title": "Probability inequalities for sums of bounded random variables", "author": ["W. Hoeffding"], "venue": "Journal of the American Statistical Association,", "citeRegEx": "Hoeffding.,? \\Q1963\\E", "shortCiteRegEx": "Hoeffding.", "year": 1963}, {"title": "Polynomial bounds for VC dimension of sigmoidal and general Pfaffian neural networks", "author": ["M. Karpinski", "A. Macintyre"], "venue": "Journal of Computer and System Sciences,", "citeRegEx": "Karpinski and Macintyre.,? \\Q1997\\E", "shortCiteRegEx": "Karpinski and Macintyre.", "year": 1997}, {"title": "Efficient distribution-free learning of probabilistic concepts", "author": ["M.J. Kearns", "R.E. Schapire"], "venue": "Journal of Computer and System Sciences,", "citeRegEx": "Kearns and Schapire.,? \\Q1994\\E", "shortCiteRegEx": "Kearns and Schapire.", "year": 1994}, {"title": "Computational methods for reachability analysis of stochastic hybrid systems", "author": ["K. Koutsoukos", "D. Riley"], "venue": "Hybrid Systems: Computation and Control,", "citeRegEx": "Koutsoukos and Riley.,? \\Q2006\\E", "shortCiteRegEx": "Koutsoukos and Riley.", "year": 2006}, {"title": "Numerical Methods for Stochastic Control Problems in Continuous Time", "author": ["H.J. Kushner", "P.G. Dupuis"], "venue": null, "citeRegEx": "Kushner and Dupuis.,? \\Q2001\\E", "shortCiteRegEx": "Kushner and Dupuis.", "year": 2001}, {"title": "reach-avoid decision problem", "author": ["I. Tkachev", "A. Abate"], "venue": null, "citeRegEx": "Tkachev and Abate.,? \\Q1951\\E", "shortCiteRegEx": "Tkachev and Abate.", "year": 1951}, {"title": "Proof of Lemma 6: Bound on Estimation Error We employ results on the concentration of random variables (Anthony, 2002), which in general raise conditions on a random variable ensuring its realizations to be concentrated around its expectation, in the sense that the probability of a deviation from the expectation", "author": ["Haesaert", "Babuska", "Abate Appendix A"], "venue": null, "citeRegEx": "Haesaert et al\\.,? \\Q2002\\E", "shortCiteRegEx": "Haesaert et al\\.", "year": 2002}, {"title": "Remark 16 (Computing the pseudo-dimension) When the function class W is a vector space of real-valued functions, the pseudo dimension is equal to the dimensionality of the function class (Anthony and Bartlett, 1999, Theorem 11.4)", "author": [], "venue": "(Anthony and Bartlett,", "citeRegEx": "d.,? \\Q1999\\E", "shortCiteRegEx": "d.", "year": 1999}, {"title": "dp,\u03b7(TW,W) + 2\u01eb1 + 2\u01eb2. By the union bound argument (Anthony, 2002), the probability of the union of events can be bounded by the sum of the probabilities of the single events. Using this argument it is possible to define a lower bound on the probability associated with the simultaneous 28", "author": ["\u2212 TW\u2016p"], "venue": null, "citeRegEx": "TW.p and \u2264,? \\Q2002\\E", "shortCiteRegEx": "TW.p and \u2264", "year": 2002}], "referenceMentions": [{"referenceID": 7, "context": "Haesaert, Babuska and Abate control input and investigate control synthesis, which relate to a broad literature in Control Theory (Bertsekas and Shreve, 1996); furthermore, we are interested in quantifying the probability associated to a dynamical property, known as reach-avoid, which corresponds to a widely used model specification in the field of Formal Verification (Baier and Katoen, 2008); and finally we employ a sampling-based algorithm to approximately compute the likelihood associated to the above specification.", "startOffset": 130, "endOffset": 158}, {"referenceID": 5, "context": "Haesaert, Babuska and Abate control input and investigate control synthesis, which relate to a broad literature in Control Theory (Bertsekas and Shreve, 1996); furthermore, we are interested in quantifying the probability associated to a dynamical property, known as reach-avoid, which corresponds to a widely used model specification in the field of Formal Verification (Baier and Katoen, 2008); and finally we employ a sampling-based algorithm to approximately compute the likelihood associated to the above specification.", "startOffset": 371, "endOffset": 395}, {"referenceID": 0, "context": "We are further interested in a class of such models known as stochastic hybrid systems (SHS) (Abate et al., 2008), which are endowed with a \u201chybrid\u201d (that is, both continuous and discrete) state space, which are relevant for a number of applications in Engineering and the Life Sciences (Blom and Lygeros, 2006; Cassandras and J.", "startOffset": 93, "endOffset": 113}, {"referenceID": 8, "context": ", 2008), which are endowed with a \u201chybrid\u201d (that is, both continuous and discrete) state space, which are relevant for a number of applications in Engineering and the Life Sciences (Blom and Lygeros, 2006; Cassandras and J. Lygeros, 2006).", "startOffset": 181, "endOffset": 238}, {"referenceID": 5, "context": "Instead, we focus on the reachavoid specification, a property that is well known and central within the Formal Verification field (Baier and Katoen, 2008).", "startOffset": 130, "endOffset": 154}, {"referenceID": 5, "context": "The reach-avoid property is a generalization of widely studied properties, such as reachability and invariance, and represents a known specification (denoted as \u201cbounded until\u201d) that lies at the core of a number of modal logics used in the field of formal verification, such as Linear Temporal Logic and Computational Time Logic (Baier and Katoen, 2008).", "startOffset": 329, "endOffset": 353}, {"referenceID": 0, "context": "In the context of probabilistic models evolving over continuous domains and in discrete time (which is the framework considered in this work), the probabilistic reachability and reach-avoid specifications have been investigated in (Abate et al., 2008; Summers and Lygeros, 2010).", "startOffset": 231, "endOffset": 278}, {"referenceID": 2, "context": "These results have recently led to the study of other properties, either richer (Abate et al., 2011) or defined over unbounded time horizons (Tkachev and Abate, 2014).", "startOffset": 80, "endOffset": 100}, {"referenceID": 1, "context": "Computational approaches to probabilistic reachability have been studied in (Abate et al., 2010; Esmaeil Zadeh Soudjani and Abate, 2013): the strength of these results is that the proposed numerical schemes have explicitly quantified error bounds.", "startOffset": 76, "endOffset": 136}, {"referenceID": 19, "context": "This is unlike other, known approximation schemes in the literature (Koutsoukos and Riley, 2006; Kushner and Dupuis, 2001; Prandini and Hu, 2006), which provide results with properties that are only known asymptotically.", "startOffset": 68, "endOffset": 145}, {"referenceID": 20, "context": "This is unlike other, known approximation schemes in the literature (Koutsoukos and Riley, 2006; Kushner and Dupuis, 2001; Prandini and Hu, 2006), which provide results with properties that are only known asymptotically.", "startOffset": 68, "endOffset": 145}, {"referenceID": 7, "context": "In order to do so, the FVI scheme is tailored to the characterization of the reach-avoid problem, which leads to Dynamic Programming (DP) recursions based on a sum-multiplicative form that is non-standard since it departs from the classical additive (possibly discounted) cost functions (Bertsekas and Shreve, 1996).", "startOffset": 287, "endOffset": 315}, {"referenceID": 1, "context": "As a comparison to the alternative techniques in the literature (Abate et al., 2010; Esmaeil Zadeh Soudjani and Abate, 2013), we show the related techniques provide bounds that are valid deterministically, whereas the proposed result yields tighter results in general that are valid with a certain (tunable) confidence.", "startOffset": 64, "endOffset": 124}, {"referenceID": 8, "context": "The outcomes lead to an approach providing controller synthesis with a certified performance, which is relevant for safety-critical applications (Blom and Lygeros, 2006).", "startOffset": 145, "endOffset": 169}, {"referenceID": 0, "context": "Computational approaches to probabilistic reachability have been studied in (Abate et al., 2010; Esmaeil Zadeh Soudjani and Abate, 2013): the strength of these results is that the proposed numerical schemes have explicitly quantified error bounds. This is unlike other, known approximation schemes in the literature (Koutsoukos and Riley, 2006; Kushner and Dupuis, 2001; Prandini and Hu, 2006), which provide results with properties that are only known asymptotically. This article provides a new approximate computational scheme for the reach-avoid specification based on the Fitted Value Iteration algorithm, which hinges on random sample extractions. This work originally derives formal probabilistic bounds on the error made by the approximation algorithm. In order to do so, the FVI scheme is tailored to the characterization of the reach-avoid problem, which leads to Dynamic Programming (DP) recursions based on a sum-multiplicative form that is non-standard since it departs from the classical additive (possibly discounted) cost functions (Bertsekas and Shreve, 1996). Starting from the regression bounds in Munos and Szepesvari (2008), this work includes new results on the error for the FVI approximation and a-priori performance guarantees.", "startOffset": 77, "endOffset": 1145}, {"referenceID": 5, "context": "1 Probabilistic Reach-Avoid Problem: Definition Let us define the probabilistic reach-avoid problem, also known as constrained reachability (Baier and Katoen, 2008), and provide its characterization.", "startOffset": 140, "endOffset": 164}, {"referenceID": 7, "context": "Notice that, while the probabilistic reach-avoid problem has been formulated above via DP recursions, it hinges on a sum-multiplicative characterization which is non-standard: much of the analytical and computational results in DP are formulated for additive (possibly discounted) cost functions (Bertsekas and Shreve, 1996).", "startOffset": 296, "endOffset": 324}, {"referenceID": 0, "context": "Proof See again (Summers and Lygeros, 2010, Theorem 6) and (Abate et al., 2008).", "startOffset": 59, "endOffset": 79}, {"referenceID": 1, "context": "This approach is taken in (Abate et al., 2010; Esmaeil Zadeh Soudjani and Abate, 2013), and the scheme is prone to suffer from the curse of dimensionality, since it approximates a general stochastic system with a Markov chain by partitioning the state space.", "startOffset": 26, "endOffset": 86}, {"referenceID": 9, "context": "A learning approach is suitable for complex systems, such as general Markov processes, since it replaces model-based evaluations by model-free, sample-based evaluations (Busoniu et al., 2010).", "startOffset": 169, "endOffset": 191}, {"referenceID": 23, "context": "Quantitative Approximations for Reach-Avoid over General Markov Processes as a tool to assign an accuracy guarantee. Alternatively, model-based and sample-based bounds: these bounds verify the accuracy of a dynamic programming scheme by drawing samples of the model and using available information from the model, and from the specific reach-avoid property under study. In the analysis of the algorithm these bounds can be perceived as complementary. A-priori and sample-free bounds are derived in Section 4 based on model-free/distribution-free notions, whereas model-based and sample-based bounds are given in Section 5. 3. Fitted Value Iteration In this section we consider a learning algorithm that has been developed to solve additivecost optimal control problems, and adapt it to the reach-avoid optimal control setting. Known as FVI Munos and Szepesvari (2008), the algorithm extracts a finite number of samples from the underlying model to numerically approximate the value recursions in (2).", "startOffset": 42, "endOffset": 868}, {"referenceID": 16, "context": "Haesaert, Babuska and Abate using the estimation T\u0302\u0174 \u2217 k+1 of the recursion step is bounded using Hoeffding\u2019s inequality (Hoeffding, 1963).", "startOffset": 121, "endOffset": 138}, {"referenceID": 16, "context": "Hoeffding\u2019s inequality (Hoeffding, 1963) leads to an upper bound on the deviation of the estimate from the expected value as follows: P { \u2223 \u2223", "startOffset": 23, "endOffset": 40}, {"referenceID": 15, "context": "Observe that since the expected and the empirical losses can be reformulated respectively as the mean and the empirical mean of a loss function, defined informally as f(x) = |w(x) \u2212 T\u0174 \u2217 k+1(x)|, the above problem can be framed as the uniform convergence of a standard learning problem (Haussler, 1992; Pollard, 1984; Vapnik, 1998).", "startOffset": 286, "endOffset": 331}, {"referenceID": 6, "context": "Resorting to related literature, results on bounds for the error probability of the regression of real-valued functions employ capacity concepts (including Rademacher averages, covering numbers, and pseudo dimensions) of a function class (Bartlett et al., 2005; Hoeffding, 1963).", "startOffset": 238, "endOffset": 278}, {"referenceID": 16, "context": "Resorting to related literature, results on bounds for the error probability of the regression of real-valued functions employ capacity concepts (including Rademacher averages, covering numbers, and pseudo dimensions) of a function class (Bartlett et al., 2005; Hoeffding, 1963).", "startOffset": 238, "endOffset": 278}, {"referenceID": 15, "context": "By results in (Haussler, 1992) and (Pollard, 1984), we obtain the following uniform convergence bound.", "startOffset": 14, "endOffset": 30}, {"referenceID": 6, "context": "Since the bounds are independent of the distributions \u03b7 and Tx (\u00b7 | x, a), they are in fact distribution-free bounds (Bartlett et al., 2005).", "startOffset": 117, "endOffset": 140}, {"referenceID": 12, "context": "It is related to the notion of concentrability of the future-state distribution (Munos and Szepesvari, 2008; Farahmand et al., 2010).", "startOffset": 80, "endOffset": 132}, {"referenceID": 6, "context": "The used distributionfree notions lead to conservative bounds (Bartlett et al., 2005), which then result in a large set of required samples.", "startOffset": 62, "endOffset": 85}, {"referenceID": 16, "context": "2, the estimates of the single step error above, and the bias (21) in combination with Hoeffding\u2019s inequality (Hoeffding, 1963).", "startOffset": 110, "endOffset": 127}, {"referenceID": 13, "context": "Case Study and Numerical Experiments We consider a case study from the literature (Fehnker and Ivan\u010di\u0107, 2004), where the goal is to maximize the probability that the temperature of two interconnected rooms, while staying within a comfortable range, reaches a smaller target range within a given finite time horizon.", "startOffset": 82, "endOffset": 109}, {"referenceID": 14, "context": "A neural network with a single layer of hidden units of Gaussian type radial basis functions is proved to be a universal approximator for real-valued functions (Hartman et al., 1990).", "startOffset": 160, "endOffset": 182}, {"referenceID": 17, "context": "Furthermore the pseudo dimension of an artificial neural network with W free parameters and k hidden nodes has been upper bounded by O(W 2k2) (Karpinski and Macintyre, 1997; Anthony and Bartlett, 1999).", "startOffset": 142, "endOffset": 201}, {"referenceID": 4, "context": "Furthermore the pseudo dimension of an artificial neural network with W free parameters and k hidden nodes has been upper bounded by O(W 2k2) (Karpinski and Macintyre, 1997; Anthony and Bartlett, 1999).", "startOffset": 142, "endOffset": 201}, {"referenceID": 3, "context": "Proof of Lemma 6: Bound on Estimation Error We employ results on the concentration of random variables (Anthony, 2002), which in general raise conditions on a random variable ensuring its realizations to be concentrated around its expectation, in the sense that the probability of a deviation from the expectation is exponentially small (as a function of the deviation).", "startOffset": 103, "endOffset": 118}, {"referenceID": 3, "context": "Proof of Lemma 6: Bound on Estimation Error We employ results on the concentration of random variables (Anthony, 2002), which in general raise conditions on a random variable ensuring its realizations to be concentrated around its expectation, in the sense that the probability of a deviation from the expectation is exponentially small (as a function of the deviation). Of interest to this work is a known bound holding for sums of bounded and independent random variables Hoeffding (1963). Proposition 13 (Hoeffding\u2019s inequality, Hoeffding (1963)) Suppose that Xi, for i = 1, 2, .", "startOffset": 104, "endOffset": 491}, {"referenceID": 3, "context": "Proof of Lemma 6: Bound on Estimation Error We employ results on the concentration of random variables (Anthony, 2002), which in general raise conditions on a random variable ensuring its realizations to be concentrated around its expectation, in the sense that the probability of a deviation from the expectation is exponentially small (as a function of the deviation). Of interest to this work is a known bound holding for sums of bounded and independent random variables Hoeffding (1963). Proposition 13 (Hoeffding\u2019s inequality, Hoeffding (1963)) Suppose that Xi, for i = 1, 2, .", "startOffset": 104, "endOffset": 549}, {"referenceID": 16, "context": "If we further have information on the variance of Zj , one can leverage the inequalities of Chebyshev and of Bienaym-Chebyshev (Hoeffding, 1963), or alternatively Bernstein\u2019s inequality (Peshkin and Mukherjee, 2001): the former bounds are only function of the variance, whereas the latter inequality depends not only on variance of Zj but also on its bounded domain.", "startOffset": 127, "endOffset": 144}, {"referenceID": 15, "context": "Proof of Lemma 7 We derive a general, analytical bound on the error of a single backward recursion using notions from statistical learning theory (Haussler, 1992; Pollard, 1984).", "startOffset": 146, "endOffset": 177}, {"referenceID": 3, "context": "The notion of pseudo dimension (Pollard, 1984; Anthony, 2002; Haussler, 1992) expresses the capability of a function class W to the fit a set of samples.", "startOffset": 31, "endOffset": 77}, {"referenceID": 15, "context": "The notion of pseudo dimension (Pollard, 1984; Anthony, 2002; Haussler, 1992) expresses the capability of a function class W to the fit a set of samples.", "startOffset": 31, "endOffset": 77}, {"referenceID": 15, "context": "Let us introduce the concept of covering number of a metric space (Haussler, 1992).", "startOffset": 66, "endOffset": 82}, {"referenceID": 15, "context": "For a given \u01eb > 0 we denote the covering number N (\u01eb, S, \u03c1) (Haussler, 1992) as the cardinality of the smallest \u01eb-cover of S.", "startOffset": 60, "endOffset": 76}, {"referenceID": 22, "context": ", where E\u03b7 denotes the expected value with respect to \u03b7. This allows us to use a result in (Pollard, 1984), which provides an upper-bound on the probability of the above event as a function of the covering number of the metric space ((lW)~x, \u2016 \u00b7 \u20161). Proposition 15 (Pollard (1984)) Let F be a permissable set of functions on X with 0 \u2264 f(x) \u2264 K for all f \u2208 F and x \u2208 X .", "startOffset": 11, "endOffset": 282}, {"referenceID": 15, "context": "Since there is a trivial isometry (Haussler, 1992) between (lW|~x, \u2016 \u00b7 \u20161) and (lW , \u2016 \u00b7 \u20161,\u03b7\u0302), both spaces have equal covering numbers N (\u01ebp2/16, lW|~x, \u2016 \u00b7 \u20161) = N (\u01eb p 2/16, lW , \u2016 \u00b7 \u20161,\u03b7\u0302).", "startOffset": 34, "endOffset": 50}, {"referenceID": 15, "context": "For any distribution P \u2208 M(X ), the packing number (Haussler, 1992) and therefore also tho covering number of the metric space (lW , \u2016 \u00b7 \u20161,P ) can be upper bounded as a function of the pseudo-dimension and the base of the natural logarithm e: for any \u01eb > 0, N (\u01eb, lW , \u2016 \u00b7 \u20161,P ) \u2264 e(d+ 1) ( 2e \u01eb d , with dimp(lW) = d.", "startOffset": 51, "endOffset": 67}, {"referenceID": 14, "context": "Since there is a trivial isometry (Haussler, 1992) between (lW|~x, \u2016 \u00b7 \u20161) and (lW , \u2016 \u00b7 \u20161,\u03b7\u0302), both spaces have equal covering numbers N (\u01ebp2/16, lW|~x, \u2016 \u00b7 \u20161) = N (\u01eb p 2/16, lW , \u2016 \u00b7 \u20161,\u03b7\u0302). In practice a value for E [N (\u01ebp2/16, lW , \u2016 \u00b7 \u20161,\u03b7\u0302)] can be obtained by upper bounding N (\u01ebp2/16, lW , \u2016 \u00b7 \u20161,\u03b7\u0302) independently of the sample distribution. For this we introduce the pseudo dimension of a function class, formally defined as follows Pollard (1984); Anthony (2002); Haussler (1992).", "startOffset": 35, "endOffset": 460}, {"referenceID": 3, "context": "For this we introduce the pseudo dimension of a function class, formally defined as follows Pollard (1984); Anthony (2002); Haussler (1992).", "startOffset": 108, "endOffset": 123}, {"referenceID": 3, "context": "For this we introduce the pseudo dimension of a function class, formally defined as follows Pollard (1984); Anthony (2002); Haussler (1992). Suppose F is a class of functions, f \u2208 F , f : X \u2192 [0, 1].", "startOffset": 108, "endOffset": 140}, {"referenceID": 15, "context": "The invariance properties of the pseudo dimension dimp(W) shown in (Haussler, 1992) allow to conclude that dimp( { w \u2212 TW \u2223 w \u2208 W } ) = dimp(W).", "startOffset": 67, "endOffset": 83}, {"referenceID": 18, "context": "Since it was shown in (Kearns and Schapire, 1994) that the pseudo dimension is invariant over function composition (|\u00b7|), we conclude that the pseudo dimension is dimp(lW) = dimp({w \u2212 TW : w \u2208 W}) = dimp(W) = d.", "startOffset": 22, "endOffset": 49}, {"referenceID": 4, "context": "(Anthony and Bartlett, 1999) elaborates the details of the computation of pseudo dimensions of parameterized function classes, especially for function classes defined over neural networks.", "startOffset": 0, "endOffset": 28}, {"referenceID": 6, "context": "Notice that for non-parametric function classes, concepts such as covering number or Rademacher average of the function class lW can be used instead (Bartlett et al., 2005).", "startOffset": 149, "endOffset": 172}, {"referenceID": 6, "context": "A second option is to explore alternatives over Pollard inequality in (15) with better constants (Bartlett et al., 2005).", "startOffset": 97, "endOffset": 120}, {"referenceID": 3, "context": "By the union bound argument (Anthony, 2002), the probability of the union of events can be bounded by the sum of the probabilities of the single events.", "startOffset": 28, "endOffset": 43}, {"referenceID": 16, "context": "The probabilistic bound (30) follows from a one-sided Hoeffding\u2019s inequality (Hoeffding, 1963) with random variable \u2211Nt\u22121 k=1 B k\u22121 (\u2223 \u2223", "startOffset": 77, "endOffset": 94}], "year": 2015, "abstractText": "This article deals with stochastic processes endowed with the Markov (memoryless) property and evolving over general (uncountable) state spaces. The models further depend on a non-deterministic quantity in the form of a control input, which can be selected to affect the probabilistic dynamics. We address the computation of maximal reach-avoid specifications, together with the synthesis of the corresponding optimal controllers. The reach-avoid specification deals with assessing the likelihood that any finite-horizon trajectory of the model enters a given goal set, while avoiding a given set of undesired states. This article newly provides an approximate computational scheme for the reach-avoid specification based on the Fitted Value Iteration algorithm, which hinges on random sample extractions, and gives a-priori computable formal probabilistic bounds on the error made by the approximation algorithm: as such, the output of the numerical scheme is quantitatively assessed and thus meaningful for safety-critical applications. Furthermore, we provide tighter probabilistic error bounds that are sample-based. The overall computational scheme is put in relationship with alternative approximation algorithms in the literature, and finally its performance is practically assessed over a benchmark case study.", "creator": "LaTeX with hyperref package"}}}