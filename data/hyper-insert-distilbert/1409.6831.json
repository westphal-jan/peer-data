{"id": "1409.6831", "review": {"conference": "arxiv", "VERSION": "v1", "DATE_OF_SUBMISSION": "24-Sep-2014", "title": "The Application of Differential Privacy for Rank Aggregation: Privacy and Accuracy", "abstract": "the potential risk of privacy leakage prevents users from sharing basically their honest id opinions reporting on social reconnaissance platforms. this paper simply addresses the problem of privacy preservation if the query file returns the average histogram threshold of rankings. the neural framework of absolute differential privacy is applied to rank aggregation. naturally the error judgment probability of the aggregated resource ranking factor is analyzed independently as a a result means of acoustic noise added in normal order to achieve differential descriptive privacy. upper bounds on the linear error rates for taking any robust positional ranking rule then are strictly derived only under, the stated assumption that user profiles are consequently uniformly distributed. good simulation results are provided to validate purely the probabilistic analysis.", "histories": [["v1", "Wed, 24 Sep 2014 05:19:32 GMT  (123kb,D)", "http://arxiv.org/abs/1409.6831v1", "Fusion 2014"]], "COMMENTS": "Fusion 2014", "reviews": [], "SUBJECTS": "cs.AI cs.CR", "authors": ["shang shang", "tiance wang", "paul cuff", "sanjeev kulkarni"], "accepted": false, "id": "1409.6831"}, "pdf": {"name": "1409.6831.pdf", "metadata": {"source": "CRF", "title": "The Application of Differential Privacy for Rank Aggregation: Privacy and Accuracy", "authors": ["Shang Shang", "Tiance Wang", "Paul Cuff", "Sanjeev Kulkarni"], "emails": ["kulkarni}@princeton.edu"], "sections": [{"heading": null, "text": "Keywords\u2014Rank Aggregation, Privacy, Accuracy\nI. INTRODUCTION\nWith the increasing interest in social networks and the availability of large datasets, rank aggregation has been studied intensively in the context of social choice. From the NBA\u2019s Most Valuable Player to Netflix\u2019s movie recommendations, from web search to presidential elections, voting and ranking are ubiquitous. Informally, rank aggregation is the problem of combining a set of full or partial rankings of a set of alternatives into a single consensus ranking. In recommender systems, users are motivated to submit their rankings in order to receive personalized services. On the other hand, they may also be concerned about the risk of possible privacy leakage.\nEven accumulated or anonymized datasets are not as \u201csafe\u201d as they seem to be. Information on individual rankings or preferences can still be learned even if the querier only has access to global statistics. In 2006, Netflix launched a data competition with 100 million movie ratings from half a million anonymized users. However, researchers subsequently demonstrated that individual users from this \u201csanitized\u201d dataset could be identified by matching with the Internet Movie Database (IMDb). This raises the privacy concerns about sharing honest opinions.\nDifferential privacy is a framework that aims to obscure individuals\u2019 appearances in the database. It makes no assumptions on the attacker\u2019s background knowledge. Mathematical guarantees are provided in [1] and [2]. Differential privacy has gained popularity in various applications, such as social networks [3], recommendations [4], advertising [5], etc. However, there is a trade-off between the accuracy of the query results and the privacy of the individuals included in the statistics. In [6], the authors showed that good private social recommendations are achievable only for a small subset of users in the social network.\nIn this paper, we apply the framework of differential privacy to rank aggregation. Privacy is protected by adding noise to the query of ranking histograms. The user can then apply a rank aggregation rule to the \u201cnoisy\u201d query results. In general, stronger noise guarantees better differential privacy. However, excessive noise reduces the utility of the query results. We measure the utility by the probability that the aggregated ranking is accurate. A summary of the contributions of this paper is as follows: \u2022 A privacy-preserving algorithm for rank aggregation is\nproposed. Instead of designing differential privacy for each individual ranking rule, we propose to add noise to the ranking histogram, irrespective of the ranking rules to be used. \u2022 General upper bounds on the ranking error rate are derived for all positional ranking rules. Moreover, we show that the asymptotic error rate approaches zero when the number of voters goes to infinity for any ranking rules with a fixed number of candidates. \u2022 An example using Borda count is given to show how to extend the proposed analysis to derive a tighter upper bound on the error rate for a specific positional rule. Simulations are performed to validate the analysis.\nThe rest of the paper is organized as follows. We define the problem of rank aggregation, introduce the definition of differential privacy, and describe the privacy preserving algorithm in Section 2. We then discuss the accuracy of the algorithm, and provide analytical upper bounds on the error rates in Section 3, followed by simulation results in Section 4, and conclusions in Section 5."}, {"heading": "II. DIFFERENTIAL PRIVACY IN RANK AGGREGATION", "text": ""}, {"heading": "A. Rank Aggregation: Definitions and Notations", "text": "Let C = {1, ...,M} be a finite set of M candidates, M \u2265 3. Denote the set of permutations on C by TM . Denote the number of voters by N . Each ballot xi, i = 1, ..., N is an element of TM , or a strict linear ordering. A rank aggregation algorithm, or a ranking rule is a function g : TNM \u2192 TM . The input (x1, . . . , xN ) is called a profile.\nA ranking rule g is neutral if it commutes with permutations on C [7]. Intuitively, a neutral ranking method is not biased in favor of or against any candidate.\nA ranking rule g is anonymous if the \u201cnames\u201d of the voters do not matter [7], i.e.\ng(x1, ..., xN ) = g(\u03c0(x1, ..., xN )) (1)\nar X\niv :1\n40 9.\n68 31\nv1 [\ncs .A\nI] 2\n4 Se\np 20\n14\n2 for any permutation \u03c0 on 1, ..., N . For an anonymous ranking method, we use the anonymized profile, a vector q \u2208 NM !, instead of the complete profile (x1, . . . , xN ) as the input. Let q denote the histogram of rankings: It counts the number of appearances of each ranking in all n rankings. The rank aggregation function can therefore be rewritten as g : NM ! \u2192 TM .\nAn anonymous ranking rule is scale invariant if the output depends only on the empirical distribution of votes v = q/N , not the number of voters N . That is,\ng(q) = g(\u03b1q) (2)\nfor any \u03b1 > 0. There are many different neutral and scale invariant rank aggregation algorithms. Popular ones include plurality, Borda count, instant run-off, the Kemeny-Young method and so on. Each algorithm has its own merits and disadvantages. For example, the Kemeny-Young method satisfies the Condorcet criterion (a candidate preferred to any other candidate by a strict majority of voters must be ranked first) but is computationally expensive. In fact it is NP-Hard even for M = 4 [8]. This is especially an issue for recommender systems since the number of items to be recommended can be large.\nA class of ranking rules, known as the positional rules, has an edge in computational complexity. A positional rule takes complete rankings as input, and assigns a score to each candidate according to their position in a ranking. The candidates are sorted by their total scores summed up from all rankings. The time complexity is only O(MN +M logM), where the M logM term comes from sorting. All positional rules satisfy anonymity and neutrality but fail the Condorcet criterion [9]. A positional rule with M candidates has M parameters: s1 \u2265 \u00b7 \u00b7 \u00b7 \u2265 sM , where si is the score assigned to the ith highest-ranked candidate. We can further normalize the scores without affecting the ranking rule so that s1 = 1, sM = 0. Borda count, a widely used positional rule, is specified by si = (M \u2212 i)/(M \u2212 1). Note that plurality is a positional rule with si = 0 for i \u2265 2. Plurality is popular due to its simplicity. However, it is not ideal as a rank aggregation algorithm because it discards too much information. In this paper, we specifically focus on positional rules because of their computational efficiency and ease of error rate analysis."}, {"heading": "B. Differential Privacy", "text": "In this paper, we consider a strong notion of privacy, differential privacy [1]. Intuitively, a randomized algorithm has good differential privacy if its output distribution is not sensitive to a single entity\u2019s information. For any dataset A, let N (A) denote the set of neighboring datasets, each differing from A by at most one record, i.e., if A\u2032 \u2208 N (A), then A\u2032 has exactly one entry more or one entry less than A.\nDefinition 1. [2] A random algorithm M satisfies ( , \u03b4)differential privacy if for any neighboring datasets A and A\u2032, and any subset S of possible outcomes Range(M),\nPr[M(A) \u2208 S] \u2264 exp( )\u00d7 Pr[M(A\u2032) \u2208 S] + \u03b4. (3)\nRemark: ( , \u03b4)-differential privacy is a slight relaxation from the -differential privacy in that the ratio\nPr[M(A) \u2208 S]/Pr[M(A\u2032) \u2208 S]\nneed not be bounded if both probabilities are very small. Differential privacy has been widely used in various applications [4], [5]."}, {"heading": "C. Privacy Preserving Algorithms", "text": "Much work has been done on developing differentially private algorithms [10], [11]. Let D denote the set of all datasets, and f is an operation on the dataset, such as sum, count, etc.\nDefinition 2. The l2-sensitivity \u2206f of a function f : D \u2192 Rd is\n\u2206f(A) = max A\u2032\u2208N (A)\n\u2016f(A)\u2212 f(A\u2032)\u20162\nfor all A\u2032 \u2208 N (A) differing in at most one element, and A,A\u2032 \u2208 D.\nTheorem 1. [2] Define M(A) to be f(A) + N (0, \u03c32Id\u00d7d). M provides ( , \u03b4)-differential privacy, whenever\n\u03c32 \u2265 2 ln( 2\u03b4 )\n2 \u00b7 max A\u2032\u2208N (A) \u2016f(A)\u2212 f(A\u2032)\u201622, (4)\nfor all A\u2032 \u2208 N (A) differing in at most one element, and A,A\u2032 \u2208 D.\nIn our model, f(A) is the histogram of all rankings, i.e. the input vector q defined in Section II-A. It is clear that the l2 sensitivity of f(A) is 1, since adding or removing a vote can only affect one element of q by 1. In the exposition, we will denote the private data and released data by x and x\u0302 respectively. When we add noise n to a variable x, we write x\u0302 = x+ noise. Thus\nq\u0302 = q +N (0, \u03c32IM !\u00d7M !) (5)\nwhere \u03c32 = 2 ln(2\u03b4 )/ 2, and M is the number of candidates. We use Gaussian instead of Laplacian noise which achieves stronger -privacy [1], because Gaussian noise enjoys the nice property that any linear combination of jointly Gaussian random variables is Gaussian.\nNote that there is a positive probability that q\u0302i < 0 for some index i. This does not harm our analysis since positional rules are well defined even if we allow negative vote counts.\nFinally, we define the error rate of a privacy preserving rank aggregation algorithm on ranking. The error rate is the probability that the aggregated ranking changes after adding noise. This probability depends on the ranking rule, the noise distribution, and the distribution of profiles.\nDefinition 3. The error rate PMe of a privacy preserving rank aggregation algorithm g with M candidates is defined as E1{g(q)6=g(q\u0302)}.\n3"}, {"heading": "III. GENERAL ERROR BOUNDS", "text": "In this section, we discuss the error rates in the rank aggregation problem. We give the expression for the general error rate and derive upper bounds on the error rate for all positional ranking rules under the assumption that profiles are uniformly distributed."}, {"heading": "A. Geometric Perspective of Positional Ranking Systems", "text": "We normalize the anonymous profile by dividing by the number of voters N . The resulting vector v = q/N is the empirical distribution of votes, v \u2208 [0, 1]M !. All empirical distributions are contained in a unit simplex, called the rank simplex:\nV = {v \u2208 RM ! : M !\u2211 i=1 vi = 1 and vi \u2265 0 for \u2200i}. (6)\nA rank simplex with M candidates has a dimension of M !\u2212 1. We assume that the normalized profile v is uniformly distributed on the rank simplex V .\nGeometrically, a ranking rule is a partition of the rank simplex. For positional ranking rules, the rank simplex is partitioned into M ! congruent polytopes by ( M 2 ) hyperplanes. Each polytope represents a ranking, and each hyperplane represents the equality of the score of two candidates. Moreover, each polytope is uniquely defined by M \u2212 1 hyperplanes and the faces of the rank simplex V . An example of how to define the hyperplane from given ranking rule will be given in Section IV.\nTo maintain neutrality, we break ties randomly when there is a tie. For example, if the score of candidate a and b happens to be equal, then we rank a ahead of b with probability one half. We only mention tie as a side remark since it does not have an affect on the probability analysis.\nProposition 1. Let v\u0302 = v + \u03c9 (7)\nwhere \u03c9 is a M !-dimensional random variable with distribution\nN (0, \u03c3\u03022IM !\u00d7M !),\nwhere \u03c3\u03022 = 2 ln (2/\u03b4) 2N2 . We have\nE1{g(q)6=g(q\u0302)} = E1{g(v)6=g(v\u0302)}.\nProof: This follows directly from the scale invariant property of the ranking rules.\nRemark: Note that v\u0302 may not be in the probability simplex. The ranking result of v\u0302 is uniquely defined by the cone formed by M \u2212 1 hyperplanes representing the equality of scores of two candidates."}, {"heading": "B. An Upper Bound on the General Error Rate", "text": "Rather than providing different upper bounds for each and every positional rule, we derive a general bound that works for any positional rule. Therefore, the user can decide which positional rule to apply to the queried noisy histogram, and the\nsystem has some guarantee on the error rate given the privacy level.\nIf noise switches the order of the scores of any two candidates, then the final ranking necessarily changes. Let Si(v), Sj(v) denote the score of candidate i and j for an arbitrary positional rule given the profile v. As mentioned in Section III-A, there are ( M 2 ) hyperplanes separating the simplex into M ! polytopes. The hyperplanes are defined by Si = Sj for any pair of candidates i, j, and there are ( M 2 ) such pairs. Let \u03b2ij denote the unit normal vector of hyperplane Hij : Si = Sj . That is,\n||\u03b2ij ||2 = 1 (8)\nThen \u03b2ij \u00b7 w is the scalar projection of \u03b2ij for vector w. Let Dij(v) be the distance from v to hyperplane Hij . Given the uniform distribution of v over the rank simplex, Dij(v) is a continuous random variable that takes values on [\u2212 \u221a 2, \u221a 2] ( \u221a\n2 is the edge length of the probability simplex). The sign indicates on which side of the hyperplane v locates. Let pD denote the probability density function of Dij . By the neutrality of positional rules, pD is identical for any i 6= j and pD(l) = pD(\u2212l). By symmetry,\u222b \u221a2\n0\npD(l)dl = 1\n2 . (9)\nGeometrically, pD(l) is proportional to the (M !\u2212 2)-measure of the cross section of the hyperplane Hij(l) with the simplex, where Hij(l) is parallel to Hij with distance l. Lemma 1. Let pD be as defined as above. Then pD is maximal at 0 on [0, \u221a 2] for any positional rule.\nProof: Let H be the hyperplane defined by the equality of the score of two candidates for an arbitrary positional rule, and \u03b2 be the unit normal vector of H. That is, H = {v \u2208 RM ! : \u03b2v = 0}. Let H + s\u03b2 denote the hyperplane \u03b2v = s. Let X1, . . . , XM ! be i.i.d. random variables with the following density function:\nf(x) = { e\u2212x if x \u2265 0 0 otherwise.\n(10)\nThat is, Xj\u2019s are independent exponential random variables with parameter \u03bb = 1. The density of the random variable Y = \u2211M ! i=1 \u03b2jXj is [12]\nG(s) = \u222b H+s\u03b2 M !\u220f j=1 f(x)dVolH (11)\nwhere VolH denotes the Lebesgue measure on H. It is shown in [12] that\nVolM !\u22122(H \u2229 V) = \u221a M !\n\u0393(M !\u2212 1) \u222b H M !\u220f j=1 f(x)dVolH (12)\nwhere VolM !\u22122 denotes M !\u22122 - dimensional volume, V is the unit regular M ! \u2212 1 - simplex embedded in RM !, as defined in Equation (6). This result is shown in [12] for H passing\n4 through the origin and centroid, but it holds for any hyperplane, i.e.,\nVolM !\u22122 ( (H+ s\u03b2) \u2229 V ) =\n\u221a M !\n\u0393(M !\u2212 1) G(s). (13)\nThe characteristic function of Y is\n\u03c6Y (t) = M !\u220f j=1 \u03c6Xj (\u03b2jt) = M !\u220f j=1 (1 + i\u03b2jt) \u22121. (14)\nNote that for any entry j, there is a corresponding entry j\u2032 such that the j\u2032th ranking is the reversed order of the jth ranking. By symmetry, \u03b2j = \u2212\u03b2j\u2032 , (1 + i\u03b2jt)(1 + i\u03b2j\u2032t) = 1 + \u03b22j t2. Without loss of generality, suppose \u03b2j > 0 for 1 \u2264 j \u2264M !/2, then\n\u03c6Y (t) = M !/2\u220f j=1 (1 + \u03b22j t 2)\u22121. (15)\nSince \u03c6Y (t) is always real and positive, by Bochner\u2019s theorem [13], G(s) is a positive-definite function, i.e.,\n|G(s)| \u2264 G(0).\nThis is also easy to prove by directly applying the inverse Fourier Transform:\n|G(s)| = \u2223\u2223\u2223\u2223 12\u03c0 \u222b +\u221e \u2212\u221e \u03c6Y (t)e \u2212istds \u2223\u2223\u2223\u2223 \u2264 1\n2\u03c0 \u222b +\u221e \u2212\u221e \u2223\u2223\u03c6Y (t)e\u2212ist\u2223\u2223 ds = 1\n2\u03c0 \u222b +\u221e \u2212\u221e \u03c6Y (t) \u2223\u2223e\u2212ist\u2223\u2223 ds\n= 1\n2\u03c0 \u222b +\u221e \u2212\u221e \u03c6Y (t)ds\n= G(0). (16)\nThus we have, VolM !\u22122 ( (H+ s\u03b2) \u2229 V ) \u2264 VolM !\u22122(H \u2229 V).\nLemma 2. The ranking error rate PMe satisfies\nPMe \u2264 ( M\n2\n) \u00b7 2 \u03c4\u222b 0 pD(l)Q ( l \u03c3\u0302 ) dl +Q ( \u03c4 \u03c3\u0302 ) ,\u2200\u03c4 > 0,\nfor all positional ranking aggregation algorithms with M candidates and N voters, taking input from the ( , \u03b4)-differentially private system defined in Section II-C.\nProof: The main idea of the proof is as follows. Divide the rank simplex into two parts: a \u201chigh error\u201d region, denoted as RH , and a \u201clow error\u201d region, denoted as RL, as shown in Figure 1. RH consists of the thin slices of the simplex close to the boundary hyperplanes. RL occupies most of the simplex, but P (error|v \u2208 RL) is upper bounded by the error rate at the point closest to the boundary. We choose an appropriate\nthickness \u03c4 of RH such that the sum of the error rate of the two parts is minimized. Thus we have,\nPMe =P M e in RH + P M e in RL \u2264 ( M\n2\n) \u00b7 P (Si, Sj switches order in RH) + PMe in RL\n=\n( M\n2\n) \u00b7 2 \u03c4\u222b 0 pD(l)P (\u03b2ij \u00b7 \u03c9 > l)dl + PMe in RL\n=\n( M\n2\n) \u00b7 2 \u03c4\u222b 0 pD(l)Q ( l \u03c3\u0302||\u03b2ij ||2 ) dl + PMe in RL (17)\nQ(\u00b7) is the tail probability of the standard normal distribution and is decreasing on [0,+\u221e). Thus for the \u201clow error\u201d region, we have,\nPMe in RL < P (v \u2208 RL) \u00b7Q (\n\u03c4\n\u03c3\u0302||\u03b2ij ||2 ) < Q ( \u03c4\n\u03c3\u0302||\u03b2ij ||2\n) (18)\nFrom Equation (8), (17), and (18), we have,\nPMe \u2264 ( M\n2\n) \u00b7 2 \u03c4\u222b 0 pD(l)Q ( l \u03c3\u0302 ) dl +Q ( \u03c4 \u03c3\u0302 ) . (19)\nTheorem 2. For any positional ranking aggregation algorithm with M candidates and N voters, taking input from the ( , \u03b4)differentially private system defined in Section II-C, the ranking error rate PMe (N) satisfies\nPMe (N) \u2264 ( M\n2\n) M !\u2212 1\u221a\n2 \u03c4 +Q\n( N\u03c4\u221a\n2 ln(2/\u03b4)\n) ,\u2200\u03c4 > 0.\nProof: By Lemma 2, we have,\nPMe \u2264 ( M\n2\n) \u00b7 2 \u03c4\u222b 0 pD(l)Q ( l \u03c3\u0302 ) dl +Q ( \u03c4 \u03c3\u0302 )\n\u2264 ( M\n2\n) \u00b7 2 \u03c4\u222b 0 pD(l)Q(0)dl +Q ( \u03c4 \u03c3\u0302 )\n=\n( M\n2\n) \u00b7 \u03c4\u222b\n0\npD(l)dl +Q ( \u03c4 \u03c3\u0302 ) (20)\nBy Lemma 1, for any positional rules, pD(l) \u2264 pD(0). Hence we have,\nPMe \u2264 ( M\n2\n) \u00b7 \u03c4\u222b\n0\npD(0)dl +Q ( \u03c4 \u03c3\u0302 ) = ( M\n2\n) \u00b7 pD(0)\u03c4 +Q ( \u03c4 \u03c3\u0302 ) (21)\n5 For positional rules, all hyperplanes Hij pass through the (M ! \u2212 1)-simplex centroid for any i, j \u2208 {1, . . . ,M} since the profile at the centroid must be a tie for all candidates due to symmetry. From the literature in high dimensional geometry [12], we know that the largest cross section through the centroid of a regular M ! \u2212 1-simplex is exactly the slice that contains M ! \u2212 2 of its vertices and the midpoint of the remaining two vertices. The (M ! \u2212 2)-measure of the cross section is \u221a M !/ (\u221a 2(M !\u2212 2)! ) for the probability simplex. Since the (M ! \u2212 1)-measure of the probability simplex is\u221a M !/(M !\u2212 1)!, we have,\npD(0) \u2264 \u221a M !/\n(\u221a 2(M !\u2212 2)! ) \u221a M !/(M !\u2212 1)! = M !\u2212 1\u221a 2 (22)\nFrom Equations (21) and (22), and the fact that \u03c3\u03022 = 2 ln( 2\u03b4 )/ 2N2, we have\nPMe (N) \u2264 ( M\n2\n) M !\u2212 1\u221a\n2 \u03c4 +Q ( \u03c4 \u03c3\u0302 ) = ( M\n2\n) M !\u2212 1\u221a\n2 \u03c4 +Q\n( N\u03c4\u221a\n2 ln(2/\u03b4)\n) (23)\nBy taking the derivative with respect to \u03c4 , we can show that the right side of Equation (23) is minimized when\n\u03c4 =\n\u221a 2 ln(2/\u03b4)\nN\n\u221a \u22122 ln \u221a \u03c0 ln(2/\u03b4)M(M \u2212 1)(M !\u2212 1)\u221a\n2 N .\n(24) Remark: To better understand this upper bound, we can use a Q-function approximation to represent the result of Theorem 2. It is known that\nQ(x) \u2264 e \u2212 x22 \u221a\n2\u03c0x ,\u2200x > 0. (25)\nThis is a good approximation when x is large [14]. Thus we can rewrite Equation (23) as\nPMe (N) \u2264 ( M\n2\n) M !\u2212 1\u221a\n2 \u03c4 +\n\u221a ln(2/\u03c3\u0302)\n2 \u221a \u03c0 N\u03c4\ne\u2212 ( N\u03c4)2\n4 ln(2/\u03c3\u0302) ,\u2200\u03c4 > 0. (26)\nWe can further simplify the expression by letting \u03c4 = 2 \u221a lnN ln(2/\u03b4)/( N):\nPMe (N) \u2264 1\nN\n(( M 2 ) (M !\u2212 1) \u221a 2 lnN ln(2/\u03b4)\n+\n1\n2 \u221a \u03c0 lnN\n) .\n(27) It is shown in (27) that the error rate goes to 0 at least as fast as O( \u221a lnN N ) for fixed \u03b4, ."}, {"heading": "C. Asymptotic Error Rate", "text": "In this section, we analyze the asymptotic error rate for any positional ranking rule. We start by showing a tighter bound on the general error rate that can be derived from the proof of Theorem 2.\nFig. 1: An example of Petrie polygon (skew orthogonal projections) of three candidates. Three hyperplanes, under Borda count ranking rule, separate the simplex into six polytopes.\nLemma 3. An upper bound for the ranking error rate of any ( , \u03b4)-differentially private positional ranking system with M candidates and N voters is( M\n2\n)\u221a 2(M !\u2212 1)Q ( N\u03c4\n2 \u221a 2 ln(2/\u03b4)\n) \u03c4 +Q ( N\u03c4\u221a\n2 ln(2/\u03b4) ) for \u2200\u03c4 > 0.\nProof: Since the Q-function is convex on [0,+\u221e), by Jensen\u2019s Inequality, from Lemma 1 and Lemma 2, we have\nPMe (N) \u2264 ( M\n2\n) \u00b7 2 \u03c4\u222b 0 pD(l)Q ( l \u03c3\u0302 ) dl +Q ( \u03c4 \u03c3\u0302 )\n\u2264 ( M\n2\n) \u00b7 2 \u03c4\u222b 0 pD(0)Q ( l \u03c3\u0302 ) dl +Q ( \u03c4 \u03c3\u0302 ) \u2264 ( M\n2\n) \u00b7 2pD(0)Q ( \u03c4 2\u03c3\u0302 ) +Q ( \u03c4 \u03c3\u0302 ) = ( M\n2\n)\u221a 2(M !\u2212 1)Q ( N\u03c4\n2 \u221a 2 ln(2/\u03b4)\n) \u03c4\n+Q ( N\u03c4\u221a\n2 ln(2/\u03b4)\n) . (28)\nLemma 3 slightly improves the bound in Theorem 2. We use this lemma to assist the proof of the following Theorem.\nTheorem 3. For any positional ranking aggregation algorithm with M candidates, taking input from the ( , \u03b4)-differentially private system defined in Section II-C,\nlim N\u2192\u221e\nPMe (N) = 0\n6 for any given and \u03b4.\nProof: This directly follows from Lemma 3 and the Bounded Convergence Theorem."}, {"heading": "IV. SIMULATION RESULTS", "text": "In this section, we use Borda count with three candidates as an example. Once the ranking rule is known, we can derive a tighter bound than the general error rate bound in Section III, because we know exactly what the pairwise comparison boundaries are. We will compare all upper bounds with the simulation error rates.\nIn Borda count, for every vote the candidate ranked first receives 1 point, the second receives 0.5 points, and the bottom candidate receives no points. The aggregated rank is sorted according to the total points each candidate receives. We list 3! = 6 permutations in the following order, and we will stick to this order for the rest of this paper: abc, acb, cab, cba, bca, bac. Let\nM =\n( 1 1 0.5 0 0 0.5\n0.5 0 0 0.5 1 1 0 0.5 1 1 0.5 0\n) . (29)\nThen we have ( Sa Sb Sc ) = Mv, (30)\nwhere v is defined in Section III-A and Sa, Sb, Sc are the aggregated score of candidates a, b and c respectively. The hyperplane Hab satisfies Sa = Sb,\n2v1 + 2v2 + v3 + v6 = v1 + v4 + 2v5 + 2v6 (31)\ni.e. Hab : v1 + 2v2 + v3 \u2212 v4 \u2212 2v5 \u2212 v6 = 0 (32)\nSimilarly, we have\nHbc : v1 \u2212 v2 \u2212 2v3 \u2212 v4 + v5 + 2v6 = 0 (33)\nHac : 2v1 + v2 \u2212 v3 \u2212 2v4 \u2212 v5 + v6 = 0 (34)\nWith Equations (32), (33) and (34), we can compute the volume of the cross section made by the hyperplane cutting through the probability simplex (6), using methods proposed in [15]. Then an upper bound specifically for Borda count can be derived with a similar approach as Theorem 2 or Lemma 3.\nFigure 2 shows the simulation results of Borda count with 3 candidates and 2,000 voters, repeated 100,000 times. We set \u03b4 = 5\u00d7 10\u22124 (which is 0.1 divided by the number of voters), and plot the graph of error rate with taking values between 0.05 and 0.24. We compare the simulation results with the general upper bound derived in Theorem 2 and the improved upper bound in Lemma 3, as well as the ranking rule-specific upper bound described above.\nFigure 3 shows the simulation results for Borda count with 3 candidates with fixed , repeated 20,000 times. We set = 0.1 and \u03b4 = 0.1/N , where N is the number of voters. The number of voters varies from 1,000 to 100,000. The error vanishes fast with a growing number of voters, even if we set \u03b4 to be inversely proportional to the number of voters. We also\ncompare the simulation results with the general upper bound derived in Theorem 2 and the improved upper bound in Lemma 3, as well as the ranking rule-specific upper bound described above."}, {"heading": "V. CONCLUSIONS", "text": "In this paper, we apply the framework of differential privacy to rank aggregation by adding noise in the votes. We analyze the probability that the aggregated ranking becomes inaccurate due to the noise and derive upper bounds on the error rates of ranking for all positional ranking rules under the assumption that profiles are uniformly distributed. The bounds can be tightened using techniques in high dimensional polytope volume computation if we are given a specific ranking rule. Our results provide insights into the trade-offs between privacy and accuracy in rank aggregation.\n7"}, {"heading": "VI. ACKNOWLEDGMENTS", "text": "This research was supported in part by the Center for\nScience of Information (CSoI), a National Science Foundation (NSF) Science and Technology Center, under grant agreement CCF-0939370, by NSF under the grant CCF-1116013, by Air Force Office of Scientific Research, under the grant FA955012-1-0196, and by a research grant from Deutsche Telekom AG."}], "references": [{"title": "Differential privacy", "author": ["Cynthia Dwork"], "venue": "Automata, languages and programming, pp. 1\u201312. Springer, 2006.", "citeRegEx": "1", "shortCiteRegEx": null, "year": 2006}, {"title": "Our data, ourselves: Privacy via distributed noise generation", "author": ["Cynthia Dwork", "Krishnaram Kenthapadi", "Frank McSherry", "Ilya Mironov", "Moni Naor"], "venue": "Advances in Cryptology-EUROCRYPT 2006, pp. 486\u2013503. Springer, 2006.", "citeRegEx": "2", "shortCiteRegEx": null, "year": 2006}, {"title": "A guide to differential privacy theory in social network analysis", "author": ["Christine Task", "Chris Clifton"], "venue": "Proceedings of the 2012 International Conference on Advances in Social Networks Analysis and Mining (ASONAM 2012). IEEE Computer Society, 2012, pp. 411\u2013417.", "citeRegEx": "3", "shortCiteRegEx": null, "year": 2012}, {"title": "Differentially private recommender systems: building privacy into the net", "author": ["Frank McSherry", "Ilya Mironov"], "venue": "Proceedings of the 15th ACM SIGKDD international conference on Knowledge discovery and data mining. ACM, 2009, pp. 627\u2013636.", "citeRegEx": "4", "shortCiteRegEx": null, "year": 2009}, {"title": "A practical application of differential privacy to personalized online advertising", "author": ["Yehuda Lindell", "Eran Omri"], "venue": "IACR Cryptology ePrint Archive, vol. 2011, pp. 152, 2011.", "citeRegEx": "5", "shortCiteRegEx": null, "year": 2011}, {"title": "Personalized social recommendations: accurate or private", "author": ["Ashwin Machanavajjhala", "Aleksandra Korolova", "Atish Das Sarma"], "venue": "Proceedings of the VLDB Endowment, vol. 4, no. 7, pp. 440\u2013450, 2011.", "citeRegEx": "6", "shortCiteRegEx": null, "year": 2011}, {"title": "A fourier-theoretic perspective on the condorcet paradox and arrow\u2019s theorem", "author": ["Gil Kalai"], "venue": "Advances in Applied Mathematics, vol. 29, no. 3, pp. 412\u2013426, 2002.", "citeRegEx": "7", "shortCiteRegEx": null, "year": 2002}, {"title": "Improved bounds for computing kemeny rankings", "author": ["Vincent Conitzer", "Andrew Davenport", "Jayant Kalagnanam"], "venue": "AAAI, 2006, vol. 6, pp. 620\u2013626.", "citeRegEx": "8", "shortCiteRegEx": null, "year": 2006}, {"title": "Rank aggregation methods for the web", "author": ["Cynthia Dwork", "Ravi Kumar", "Moni Naor", "Dandapani Sivakumar"], "venue": "Proceedings of the 10th international conference on World Wide Web. ACM, 2001, pp. 613\u2013622.", "citeRegEx": "9", "shortCiteRegEx": null, "year": 2001}, {"title": "Calibrating noise to sensitivity in private data analysis", "author": ["Cynthia Dwork", "Frank McSherry", "Kobbi Nissim", "Adam Smith"], "venue": "Theory of Cryptography, pp. 265\u2013284. Springer, 2006.", "citeRegEx": "10", "shortCiteRegEx": null, "year": 2006}, {"title": "Privacy, accuracy, and consistency too: a holistic solution to contingency table release", "author": ["Boaz Barak", "Kamalika Chaudhuri", "Cynthia Dwork", "Satyen Kale", "Frank McSherry", "Kunal Talwar"], "venue": "Proceedings of the twenty-sixth ACM SIGMOD-SIGACT-SIGART symposium on Principles of database systems. ACM, 2007, pp. 273\u2013282.", "citeRegEx": "11", "shortCiteRegEx": null, "year": 2007}, {"title": "Central slices of the regular simplex", "author": ["Simon Webb"], "venue": "Geometriae Dedicata, vol. 61, no. 1, pp. 19\u201328, 1996.", "citeRegEx": "12", "shortCiteRegEx": null, "year": 1996}, {"title": "An improved approximation for the gaussian q-function", "author": ["George K Karagiannidis", "Athanasios S Lioumpas"], "venue": "Communications Letters, IEEE, vol. 11, no. 8, pp. 644\u2013646, 2007.", "citeRegEx": "14", "shortCiteRegEx": null, "year": 2007}, {"title": "Polytope volume computation", "author": ["Jim Lawrence"], "venue": "Mathematics of Computation, vol. 57, no. 195, pp. 259\u2013271, 1991.", "citeRegEx": "15", "shortCiteRegEx": null, "year": 1991}], "referenceMentions": [{"referenceID": 0, "context": "Mathematical guarantees are provided in [1] and [2].", "startOffset": 40, "endOffset": 43}, {"referenceID": 1, "context": "Mathematical guarantees are provided in [1] and [2].", "startOffset": 48, "endOffset": 51}, {"referenceID": 2, "context": "Differential privacy has gained popularity in various applications, such as social networks [3], recommendations [4], advertising [5], etc.", "startOffset": 92, "endOffset": 95}, {"referenceID": 3, "context": "Differential privacy has gained popularity in various applications, such as social networks [3], recommendations [4], advertising [5], etc.", "startOffset": 113, "endOffset": 116}, {"referenceID": 4, "context": "Differential privacy has gained popularity in various applications, such as social networks [3], recommendations [4], advertising [5], etc.", "startOffset": 130, "endOffset": 133}, {"referenceID": 5, "context": "In [6], the authors showed that good private social recommendations are achievable only for a small subset of users in the social network.", "startOffset": 3, "endOffset": 6}, {"referenceID": 6, "context": "A ranking rule g is neutral if it commutes with permutations on C [7].", "startOffset": 66, "endOffset": 69}, {"referenceID": 6, "context": "A ranking rule g is anonymous if the \u201cnames\u201d of the voters do not matter [7], i.", "startOffset": 73, "endOffset": 76}, {"referenceID": 7, "context": "In fact it is NP-Hard even for M = 4 [8].", "startOffset": 37, "endOffset": 40}, {"referenceID": 8, "context": "All positional rules satisfy anonymity and neutrality but fail the Condorcet criterion [9].", "startOffset": 87, "endOffset": 90}, {"referenceID": 0, "context": "In this paper, we consider a strong notion of privacy, differential privacy [1].", "startOffset": 76, "endOffset": 79}, {"referenceID": 1, "context": "[2] A random algorithm M satisfies ( , \u03b4)differential privacy if for any neighboring datasets A and A\u2032, and any subset S of possible outcomes Range(M), Pr[M(A) \u2208 S] \u2264 exp( )\u00d7 Pr[M(A\u2032) \u2208 S] + \u03b4.", "startOffset": 0, "endOffset": 3}, {"referenceID": 3, "context": "Differential privacy has been widely used in various applications [4], [5].", "startOffset": 66, "endOffset": 69}, {"referenceID": 4, "context": "Differential privacy has been widely used in various applications [4], [5].", "startOffset": 71, "endOffset": 74}, {"referenceID": 9, "context": "Much work has been done on developing differentially private algorithms [10], [11].", "startOffset": 72, "endOffset": 76}, {"referenceID": 10, "context": "Much work has been done on developing differentially private algorithms [10], [11].", "startOffset": 78, "endOffset": 82}, {"referenceID": 1, "context": "[2] Define M(A) to be f(A) + N (0, \u03c3Id\u00d7d).", "startOffset": 0, "endOffset": 3}, {"referenceID": 0, "context": "We use Gaussian instead of Laplacian noise which achieves stronger -privacy [1], because Gaussian noise enjoys the nice property that any linear combination of jointly Gaussian random variables is Gaussian.", "startOffset": 76, "endOffset": 79}, {"referenceID": 0, "context": "The resulting vector v = q/N is the empirical distribution of votes, v \u2208 [0, 1] .", "startOffset": 73, "endOffset": 79}, {"referenceID": 11, "context": "The density of the random variable Y = \u2211M ! i=1 \u03b2jXj is [12]", "startOffset": 56, "endOffset": 60}, {"referenceID": 11, "context": "It is shown in [12] that", "startOffset": 15, "endOffset": 19}, {"referenceID": 11, "context": "This result is shown in [12] for H passing", "startOffset": 24, "endOffset": 28}, {"referenceID": 11, "context": "From the literature in high dimensional geometry [12], we know that the largest cross section through the centroid of a regular M ! \u2212 1-simplex is exactly the slice that contains M ! \u2212 2 of its vertices and the midpoint of the remaining two vertices.", "startOffset": 49, "endOffset": 53}, {"referenceID": 12, "context": "This is a good approximation when x is large [14].", "startOffset": 45, "endOffset": 49}, {"referenceID": 13, "context": "Hbc : v1 \u2212 v2 \u2212 2v3 \u2212 v4 + v5 + 2v6 = 0 (33) Hac : 2v1 + v2 \u2212 v3 \u2212 2v4 \u2212 v5 + v6 = 0 (34) With Equations (32), (33) and (34), we can compute the volume of the cross section made by the hyperplane cutting through the probability simplex (6), using methods proposed in [15].", "startOffset": 267, "endOffset": 271}], "year": 2014, "abstractText": "The potential risk of privacy leakage prevents users from sharing their honest opinions on social platforms. This paper addresses the problem of privacy preservation if the query returns the histogram of rankings. The framework of differential privacy is applied to rank aggregation. The error probability of the aggregated ranking is analyzed as a result of noise added in order to achieve differential privacy. Upper bounds on the error rates for any positional ranking rule are derived under the assumption that profiles are uniformly distributed. Simulation results are provided to validate the probabilistic analysis. Keywords\u2014Rank Aggregation, Privacy, Accuracy", "creator": "LaTeX with hyperref package"}}}