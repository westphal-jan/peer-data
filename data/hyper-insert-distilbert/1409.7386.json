{"id": "1409.7386", "review": {"conference": "arxiv", "VERSION": "v1", "DATE_OF_SUBMISSION": "25-Sep-2014", "title": "Performance of Stanford and Minipar Parser on Biomedical Texts", "abstract": "in this experimental paper, the performance error of a two dependency graph parsers, namely stanford and yale minipar, on biomedical typing texts typing has again been reported. the performance of concurrent te - parsers struggling to evaluate assignm dependencies applied between two biomedical concepts that are already being proved to be connected is not satisfying. when both stanford products and minipar, being statistical parsers, do fail to assign no dependency relation between two connected concepts if precisely they are named distant relatives by noting at least one relational clause. minipar's performance, in terms best of linear precision, recall index and the f - sigma score of decreasing the attachment dependency score ( e. g., correctly identified head in a dependency ), efforts to parse basic biomedical abstracts text types is also weakly measured taking forth the applicable stanford'ps s as a joint gold standard. alternatively the results shown suggest that minipar methodology is not already suitable enough yet to further parse simple biomedical query texts. in recent addition, being a qualitative investigation now reveals that the inverse difference between working behavior principles of the parsers also may play play a vital role for rendering minipar'c s degraded performance.", "histories": [["v1", "Thu, 25 Sep 2014 15:35:27 GMT  (734kb)", "http://arxiv.org/abs/1409.7386v1", null]], "reviews": [], "SUBJECTS": "cs.CL", "authors": ["rushdi shams"], "accepted": false, "id": "1409.7386"}, "pdf": {"name": "1409.7386.pdf", "metadata": {"source": "CRF", "title": "Performance of Stanford and Minipar Parser on Biomedical Texts", "authors": ["Rushdi Shams"], "emails": ["rshams@uwo.ca"], "sections": [{"heading": "In this paper, the performance of two dependency parsers, namely Stanford and Minipar, on biomedical texts has", "text": "been reported. The performance of the parsers to assign dependencies between two biomedical concepts that are already proved to be connected is not satisfying. Both Stanford and Minipar, being statistical parsers, fail to assign dependency relation between two connected concepts if they are distant by at least one clause. Minipar\u2019s performance, in terms of precision, recall and the F-Score of the attachment score (e.g., correctly identified head in a dependency), to parse biomedical text is also measured taking the Stanford\u2019s as a gold standard. The results suggest that Minipar is not suitable yet to parse biomedical texts. In addition, a qualitative investigation reveals that the difference between working principles of the parsers also play a vital role for Minipar\u2019s degraded performance.\nKeywords: Dependency Parse, Stanford Parser, Minipar Parser, F-Score, Attachment Score.\nI. Introduction\nDependency parsers, unlike constituency parsers, follow the dependency grammar that is inspired by a basic assumption that the syntactic structure comprises words linked by some binary and asymmetrical relations called dependency relations. Most of the dependency parsers express the relation between two words in the form of a triplet like dependency (head, dependent), where dependency is the relation and head is the word that has been modified by the dependent. Dependency parsers, now-a-days, are popular in natural language processing for a number of reasons: as they provide an implicit predicate-argument structure of the sentences, they play an important role in machine translation and information extraction; people with limited knowledge on linguistics can achieve a deeper understanding on the usage of language and its development; and last but not the least, dependency parsers lead to the development of effective syntactic parsers for a number of domains [1] like biomedical and bioinformatics. The extraction of connected biomedical concepts (i.e., disease, treatment, genes) from texts has drawn the attention of the scientists interested in finding functional similarity (i.e., identification of genes involved in human diseases) [2]. To achieve this, researchers are currently not only using dependency parsers for their ability to extract the links among the words but also developing dependency grammar based corpora like BioInfer [3].\nAlthough the underlying theory of the dependency parsers is the same, their working principles vary for a number of reasons: some dependency parsers, like Stanford Parser, modified the original grammar rules to introduce semantics [4]; several parsers, like Stanford, Minipar and Link parsers, use different techniques to find the heads of a sentence [5]; the size and the domain of the training corpus of the parsers vary- like Stanford is trained on the large Penn Wall Street Journal Corpus and Susanne, a wide coverage-small sized corpus was used to train Minipar [6]. Such different working principles have subtle impact on the performances of these dependency parsers. For instance, Comelles et al. [7] reported a comparative and a qualitative analysis on five popular dependency parsers where they found several linguistic errors produced by the parsers. Besides, although Katrenko and Adriaans [8] sustained several drawbacks of\nthe use of the dependency parsers in a specific domain (e.g., parsing biomedical text), domain-specific use of the parsers has been reported in number of research [9-12].\nThis paper reports a quantitative and a qualitative analysis on two dependency parsers, namely Stanford and Minipar, to evaluate their performance in parsing biomedical text. Given a set of 40 pairs of connected concepts from four biomedical texts [13], the parsers are tested to see if they are able to find out the concepts as connected. The comparison reports that Stanford parser performed better than Minipar in finding connected concepts. For every pair of connected concepts in this set, the sentences of the text that contain both of them are fed to the parsers to get the dependencies in a triplet form like dependency (head, dependent). Taking this output of the Stanford Parser as a gold standard, the attachment score of Minipar parser, which is the percentage of words that have the correct head, is measured. Then, the F-score (e.g., the equally weighted harmonic mean of the precision and recall) of the attachment scores is calculated. The results show that Minipar performed consistently for the whole set of the connected concepts but its performance on biomedical text is not satisfactory.\nIn the remainder of the paper, brief introductions to dependency grammar and the chosen parsers are provided in Section II. Section III describes the performance of the parsers on the biomedical texts. Finally, Section IV concludes the paper."}, {"heading": "II. Background", "text": "In this section, a brief description of dependency grammar and the working principles of the parsers considered for this experimentation, namely Stanford and Minipar, are presented."}, {"heading": "A. Dependency Grammar", "text": "Since the commencement of the idea to present syntactic structure of a sentence by linking words with a number of dependencies, many variations are proposed. But the basic assumption of dependency grammar remains unchanged: it is possible to relate the words in a sentence by a number of asymmetric and binary dependency relations. Moreover, the words have very specific roles in a dependency relation with one another: the constituent word of a dependency relation can be either a head or a dependent that modifies the head. If we take the sentence Economic news had little effects on financial markets as an example, then the dependency relations can be derived from the Direct Acyclic Graph (DAG) drawn from the sentence. The DAG drawn for every sentence has some properties: the words in the sentence are the nodes of the graph and their relations are asymmetric edges that connect them. However, according to the theory of dependency grammar, a word can modify more than one word but can be modified by at most one word. So, in the DAG, a word can have many outgoing edges to the words that it is modifying but can have only one incoming edge from the word that modifies it. Fig. 1 shows the DAG drawn for the sentence in our example [1].\nFrom Fig. 1, we see that the DAG contains a ROOT, known as the head of the sentence in the dependency grammar, is a mandatory node in the tree and does not modify any word but can be modified by others. In Fig. 1, we account many dependency relations which are the labels of the arcs. For example, news is the dependent that modifies the head called economic by a dependency relation ATT (shorthand for attribute). In dependency grammar, such a relation is written in the form of a triplet: dependency (head, dependent) or dependency (dependent, head). Therefore, the dependency between economic and news will be expressed as ATT (economic, news) or ATT (news, economic). The corresponding phrase structure tree, used by most of the constituency parsers, of the given sentence can be seen in Fig. 2 [1].\nThe difference between two representations is obvious: dependency grammar represents the head-dependent relations among the words by classifying them with functional categories like subject and object while the phrase structure grammar represents the relations among constituents or phrases by classifying them into structural categories like noun phrase (NP) or verb phrase (VP)."}, {"heading": "B. The Stanford and Minipar Parsers", "text": "Several parsers have been developed to represent the dependency relations in a sentence. Minipar, a statistical parser, descended from its previous installment called Principar [6] and it works based on the basic principles of dependency grammar. It was developed in 1998 and immediately went under strict evaluation on the Susanne Corpus. The evaluation outcome was satisfying as it extracted 79 percent of the dependency relations in the corpus with a high precision of 89 percent. The key advantages of Minipar are: it uses the basic principles of dependency grammar without any modifications, its availability, its simplicity, its performance and its training corpus which was a subset of Brown Corpus that makes it a wide-coverage parser [6]. Minipar drew the attention of the researchers as soon as its performance is published and till to date, its use is manifolds: to parse domain specific texts, to compete in natural language parsers\u2019 evaluations and to be counted as a gold standard in many other parser evaluations.\nThe developers of the Stanford parser originally developed it in 2003 as a statistical constituency parser but its working principle significantly changed when Stanford Dependency (SD) scheme was developed in 2006. The idea of creating a scheme like SD, which is a modified modern version of the early dependency grammar, was revolutionary and the parser started to produce more significant and meaningful dependency relations. Several evaluations on SD also reveal that the scheme not only brings appropriate syntactic dependency relations but also is capable of relating words semantically. The SD scheme is now reported as a widely used grammar scheme for parsing the texts of the domains like biomedical and bioinformatics.\nA brief summary of the Stanford and Minipar parsers is provided in Table 1."}, {"heading": "III. Performance of the Parsers on Biomedical Texts", "text": ""}, {"heading": "A. Setup", "text": "To test the parsers, the set of connected pairs of biomedical concepts from four scholarly articles has been used. For every pair in the set, the sentences of the papers that contain both of these concepts will be fed to the parsers. However, the parsers are not trained with biomedical corpora. That is why if we use the Part of Speech (POS) taggers of these parsers to tag biomedical text, then it is likely that they might assign wrong POS assignments. Fig. 3, for example, shows that glutamate is said to be an adjective (JJ) by the Stanford Tagger though it is a chemical component and a noun (NN) tag will be appropriate.\nTherefore, before feeding the sentences to the parsers, the sentences are tagged with Genia POS Tagger [14], which is trained with biomedical corpora and designed specifically for tagging biomedical text. The working procedure that is followed during this experiment is shown in Fig. 4."}, {"heading": "B. Quantitative Analysis", "text": "First, for every pair of concepts in the given set, the sentences containing both of the concepts are fed to the parsers to assess the ability of them to find out the pairs of concepts as connected. For example, for the connected concepts Ischemia and Glutamate, the sentences containing both of them are fed to the parsers and individual record of the parsers has been kept when the parsers find a triplet like dependency (Ischemia, Glutamate) or dependency (Glutamate, Ischemia).\nThe detailed record on the parsers\u2019 ability to find the given concepts as connected with a dependency relation is shown in Table 2.\nConnection Total\nSentences Stanford Minipar\nIschemiaGlutamate 23 2 0 LevelsIschemia 15 2 0 LevelsGlutamate 16 11 8 GlutamateNeurons 9 0 0 10MinIschemia 17 10 7 CA4Glutamate 8 0 0 IncreaseGlutamate 11 0 0 10MinGlutamate 13 0 0 5Min-Ischemia 6 5 3 5MinGlutamate 5 0 0\nConnection Total\nSentences Stanford Minipar\nFriedreichAtaxia 11 8 6 PDHC-Ataxia 9 1 0 ActivityFriedreich 7 0 0 Patients-Ataxia 7 3 1 Activity-Ataxia 7 1 0 PDHCFriedreich 7 1 0 PreparationsAtaxia 4 0 0 PreparationsFriedreich 4 0 0 Pyruvate-Ataxia 5 1 0 PatientsFriedreich 6 1 0\n(a) (b)\nConnection Total\nSentences Stanford Minipar\nAAS-Treatment 11 1 0 Use-AAS 17 9 2 AASTestosterone 8 2 1 GonadotropinTreatment 9 0 0 TestosteroneTreatment 10 4 3 LevelsTestosterone 12 7 2 AAS-Conditions 5 0 0 Treatment-HCG 5 1 0 ReplacementTherapy 5 3 3 TreatmentTherapy 5 2 2\nConnection Total\nSentences Stanford Minipar\nInhibitionGABA 33 23 11 GABA-Synapse 20 1 0 NeuronsSynapse 9 0 0 InhibitionHippocampus 6 1 0 SynapseChange 5 0 0 Neurons-GABA 16 3 1 PropertiesGABA 3 0 0 GABA-Change 3 0 0 GABA-Number 4 2 1 Cl-Gradient 3 3 3\n(c) (d)\nTable 2. The Ability of Stanford and Minipar to find the Dependencies among Connected Concepts from Paper on (a) Ischemia and Glutamate (b) Ataxia and Dehydrogenase (c) Hypogonadism and Gonadotropin (d) Epilepsy and GABA\nFrom Table 2, we can see that the parsers found dependencies between the connected concepts more often if the distance between the given concepts is short, to be more exact, if they are in the same clause. For example, Glutamate-Levels, Friedreich-Ataxia, Use-AAS and Inhibition-GABA are the four pairs of concepts that the parsers\nfound to be connected most of the times. From careful observations, we can see that the pairs of concepts maintain a very short syntactic distance with each other: Glutamate mostly acts as a noun compound modifier of Levels (e.g., the Glutamate levels increased during the 10 minute Ischemia), Friedreich mostly is a lexical modifier of Ataxia (e.g., the Friedreich\u2019s Ataxia is a kind of brain disease), AAS is a steroid and is mostly modified by Use (e.g., the use of AAS can affect the release of testosterone), and GABA mostly acts as a noun compound modifier of Inhibition (e.g., the GABA inhibition was manifested during the observation). From this observation, we can come to a decision that statistical parsers struggle to find the relations between two words if they are at least one clause away from each other.\nThe previous work [13] assumed that it would find the concepts that hold explicit or implicit semantic connections but it came up with some pairs of concepts that hardly hold such semantic connections. However, the pairs of concepts in\nTable 2 to which the parsers could not assign any dependency relation have higher possibilities to hold the semantic relations. For example, the pairs Ischemia-Glutamate, PDHC-Ataxia, AAS-Testosterone and Inhibition-Hippocampus are semantically connected according to the UMLS Semantic Relations Networks [15] but the parsers have a low success in relating them with a dependency relation.\nSecond, the output of the Stanford Parser (henceforth, Key) has been considered as the gold standard and the output of Minipar Parser (henceforth, Answer) has been compared with the Key to find out the percentage of words that have the correct heads (e.g., Attachment Score). For example, if the Answer has the head Ischemia, so has the Key, then Ischemia is called correctly identified head in the Answer (e.g., Attachment score of Answer increases). As both of the parsers have different sets of dependency relations, only the head but both of the head and the relation, is considered to calculate the attachment score.\nAfter calculating the attachment score of the Answer for any given pair of connected concepts, the precision and recall of the attachment score is calculated. The precision of the score is:\n(1)\nWhere, are the number of heads present both in the Answer and the Key and are the number of heads present in the Answer but in the Key.\nThe recall of the score is:\n(2)\nWhere, are the number of heads present in the Answer but in the Key.\nFinally, the F-Score of the Answer, which is the equally weighted harmonic mean of the precision and the recall, has been measured:\n(3)\nFor every pair of connected concepts in the set, Table 3 shows the precision, the recall, and the F-score.\nThe F-Score of the attachment scores of Minipar shows that the parser maintains a consistent precision and recall throughout the papers. However, its low precision and recall in this case compared to the evaluation on Susanne corpus suggests that the parser is not ready yet to effectively parse biomedical texts."}, {"heading": "C. Qualitative Analysis", "text": "Both Stanford and Minipar parsers are trained on corpora in which not many questions occur [5] [6]. Although in biomedical texts not many interrogative sentences occur, but when occur, the output of the parsers differ largely that contributes to the low attachment score of Minipar. For example, the parser outputs for an interrogative sentence are shown in Fig. 5. The Stanford dependency trees are generated by a modified visualization tool offered by Athar [16] and the Minipar dependency trees are generated by a visualization tool offered by University of Zurich [17].\nUnlike Stanford, Minipar considers quotation marks while parsing but its dependency tree begins to differ with Stanford as it comes across such sentences. Fig. 6 shows how the dependency tree differs when the parsers parse sentences with quotation marks.\n(a)\nMinipar struggles to generate proper dependency tree and assign wrong dependency relations when it comes across sentences with conjunctions, especially in the form of NP and NP of NP. Stanford Parser performs better than Minipar in such cases. Fig. 7 shows how the parsers generate different dependency tree when they parse sentence with such form.\nMoreover, the parsers differ in producing dependency trees and assigning proper dependencies for the sentences containing WH-clauses as a complement of a preposition. In Fig. 8, we see that the parser outputs begin to differ as soon as they find WH-clause as a complement of a preposition.\nBesides the difference in working principles of the parsers, the POS tagging of Genia POS tagger is sometimes responsible for inappropriate parsing as well. For example, Genia POS tagger tags the sentence The thermocouple probe was inserted in the brain striatum as follows-\nThe/DT thermocouple/JJ probe/NN was/VBD inserted/VBN in/IN the/DT brain/NN striatum/NN\nMany would argue, though, to assign thermocouple an NN tag. Improper tagging leads the parsers to select different heads.\nDependency parsers parse the text and instead of making a clause-structure, develop a Direct Acyclic Graph or DAG. However, Stanford Parser modifies this and is able to produce a DAG with cycles. Minipar does not produce such cyclic DAG. When two parsers in evaluation differ on this aspect of creating cyclic DAG for particular cases, their performance differs as well. For example, Stanford Parser produces a cyclic DAG in Fig. 9. The cycle is manifested for the relations rcmod (patients, treated) and nsubjpass (treated, patients).\nAnother reason for the degraded performance of Minipar to parse biomedical texts is our strict evaluation technique. The set of connected concepts was generated without any morphological analysis (e.g., stemming). So, neuron and neurons are not treated as same word. Though Stanford Parser treats it in the same way, Minipar takes the stem of every word. Therefore, if Stanford Parser selects neurons as head of a dependency, Minipar selects neuron as its head. In this experiment, strict evaluation is considered- if the heads selected by the parsers did not match fully, it was not counted as an attachment.\nLast but not the least, previous research on dependency parser evaluation reported that dependency parsers perform best at the domain of their training corpora [7]. Neither Stanford nor Minipar was trained with a biomedical corpus. This definitely decreases their performances in this domain."}, {"heading": "IV. Conclusions", "text": "In this paper, a quantitative and a qualitative analysis on the performance of dependency parsers, namely Stanford and Minipar, to parse biomedical texts have been reported. The experiments showed that the parsers are less successful to find out dependencies between biomedical concepts that are already proved to be connected. The reason for this low success of the parsers is that being statistical parsers, both of them, they cannot find out dependency between words that maintain a decent syntactic distance. The parsing ability for biomedical texts by Minipar was also measured taking the Stanford\u2019s as a gold standard in terms of attachment score. The precision, recall and F-Score of the attachment score of Minipar suggest that the parser is not yet ready to parse biomedical texts. However, it is also firmly believed that Minipar\u2019s performance on this domain will increase if it is trained with biomedical corpora."}], "references": [], "referenceMentions": [], "year": 2011, "abstractText": "In this paper, the performance of two dependency parsers, namely Stanford and Minipar, on biomedical texts has been reported. The performance of the parsers to assign dependencies between two biomedical concepts that are already proved to be connected is not satisfying. Both Stanford and Minipar, being statistical parsers, fail to assign dependency relation between two connected concepts if they are distant by at least one clause. Minipar\u2019s performance, in terms of precision, recall and the F-Score of the attachment score (e.g., correctly identified head in a dependency), to parse biomedical text is also measured taking the Stanford\u2019s as a gold standard. The results suggest that Minipar is not suitable yet to parse biomedical texts. In addition, a qualitative investigation reveals that the difference between working principles of the parsers also play a vital role for Minipar\u2019s degraded performance.", "creator": "Microsoft\u00ae Office Word 2007"}}}