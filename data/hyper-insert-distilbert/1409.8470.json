{"id": "1409.8470", "review": {"conference": "arxiv", "VERSION": "v1", "DATE_OF_SUBMISSION": "30-Sep-2014", "title": "Interference Effects in Quantum Belief Networks", "abstract": "various probabilistic graphical models theories such as symbolic bayesian statistics networks are considered one unit of practically the single most powerful structures known simultaneously by the entire computer popular science computational community for deriving probabilistic inferences. however, modern cognitive psychology has thus revealed observations that making human decisions could not merely follow the rules of classical objective probability reduction theory, because humans cannot process large amounts required of data in order to can make judgements. consequently, precisely the real inferences getting performed are based totally on classical limited graphical data banks coupled with several heuristics, leading themselves to violations of governing the expected law of total expected probability. this means that probabilistic graphical real models theoretically based on modern classical basic probability theory are too limited to fully themselves simulate people and explain various aspects learned of human decision making.", "histories": [["v1", "Tue, 30 Sep 2014 10:43:30 GMT  (1619kb,D)", "http://arxiv.org/abs/1409.8470v1", null]], "reviews": [], "SUBJECTS": "cs.AI", "authors": ["catarina moreira", "andreas wichert"], "accepted": false, "id": "1409.8470"}, "pdf": {"name": "1409.8470.pdf", "metadata": {"source": "CRF", "title": "Interference Effects in Quantum Belief Networks", "authors": ["Catarina Moreira", "Andreas Wichert"], "emails": ["catarina.p.moreira@ist.utl.pt", "andreas.wichert@ist.utl.pt"], "sections": [{"heading": null, "text": "Quantum probability theory was developed in order to accommodate the paradoxical findings that the classical theory could not explain. Recent findings in cognitive psychology revealed that quantum probability can fully describe human decisions in an elegant framework. Their findings suggest that, before taking a decision, human thoughts are seen as superposed waves that can interfere with each other, influencing the final decision.\nIn this work, we propose a new Bayesian Network based on the psychological findings of cognitive scientists. We made experiments with two very well known Bayesian Networks from the literature. The results obtained revealed that the quantum like Bayesian Network can affect drastically the probabilistic inferences, specially when the levels of uncertainty of the network are very high (no pieces of evidence observed). When the levels of uncertainty are very low, then the proposed quantum like network collapses to its classical counterpart.\nThis work was supported by national funds through FCT - Fundac\u0327a\u0303o para a Cie\u0302ncia e a Tecnologia, under project PEst-OE/EEI/LA0021/2013\nar X\niv :1\n40 9.\n84 70\nv1 [\ncs .A\nI] 3\n0 Se"}, {"heading": "1 Introduction", "text": "The problem of violations of the axioms of probability go back to the early 60s. [32] published a work that influenced modern psychology by showing that humans violate the laws of probability theory when making decisions under risk. The principle that humans were constantly violating is defined by The Sure Thing Principle. It is a concept widely used in game theory and was originally introduced by [64]. This principle is fundamental in Bayesian probability theory and states that if one prefers action A over B under state of the world X , and if one also prefers A over B under the complementary state of the world X , then one should always prefer action A over B even when the state of the world is unspecified.\nCognitive psychologists A. Tversky and D. Khamenman also explored more situations where classical probability theory could not be accommodated in human decisions. In their pioneering work, [69] realised that the beliefs expressed by humans could not follow the rules of Boolean logic or classical probability theory, because humans cannot process large amounts of data in order to make estimations or judgements. Consequently, the inferences performed are based on limited data coupled with several heuristics, leading to a violation on one of the most important laws in bayesian theory: the law of total probability.\nOne of the key differences between classical and quantum theories is the way how information is processed. According to classical decision making, a person changes beliefs at each moment in time, but it can only be in one precise state with respect to some judgement. So, at each moment, a person is favouring a specific belief. The process of human inference deterministically either jumps between definite states or stays in a single definite state across time [17]. Most computer science, cognitive and decision systems are modelled according to this single path trajectory principle. Figure 1 illustrates this idea.\nIn quantum information processing, on the other hand, information (and consequently beliefs) are modelled via wave functions and therefore they cannot be in definite states. Instead, they are in an indefinite quantum state called the superposition state. That is, all beliefs are occurring on the human mind at the same time. According to cognitive scientists, this effect is responsible for making people experience uncertainties, ambiguities or even confusion before making a decision. At each moment, one belief can be more favoured than another, but all beliefs are available at the same time. In this sense, quantum theory enables the modelling of the cognitive system as it was a wave moving across time over a state space until a final decision is made. From this superposed state, uncertainty can produce different waves coming from opposite directions that can crash into each other, causing an interference distribution. This phenomena can never be obtained in a classical setting. Figure 2 exemplifies this. When the final decision is made, then there is no more uncertainty. The wave collapses into a definite state. Thus, quantum information processing deals with both definite and indefinite states [17]."}, {"heading": "1.1 Motivation: Violations in The Two-Stage Gamblings", "text": "[71] were one of the first researchers to test the veracity of Savage\u2019s principle under human cognition in a gambling game. In their experiment, participants were asked at each stage to make the decision of whether or not to play a gamble that has an equal chance of winning $200 or losing $100. Figure 3 illustrates the experiment. Three conditions were verified:\n1. Participants were informed if they had won the first gamble;\n2. Participants were informed if they had lost the first gamble;\n3. Participants did not know the outcome of the first gamble;\nThe two-stage gambling game was one of the first experiments used in order to determine if the Sure Thing Principle would be verified even with people that did not know about the existence of this principle. The results obtained in [71] experiment showed that this principle is constantly being violated and consequently humans do not perform inferences according to the laws of probability theory and Boolean logic.\nThe overall results revealed that participants who knew that they won the first gamble, decided to play again. Participants who knew that they lost the first gamble, also decided to play again. Through Savage\u2019s sure thing principle, it was expected that the participants would choose to play again, even if they did not know the outcome of the first gamble. However, the results obtained revealed something different. If the participants did not know the outcome of the first gamble, then many of them decided not to play the second one.\nSeveral researchers replicated this experiment. The overall results are specified in Table 1. Why did the findings reported in Table 1 generate so much controversy in the scientific community? Because, the data observed is not in accordance with the classical law of total probability. In Tversky and Shafir\u2019s experiment [71], the probability of a participant playing the second gamble, given that the outcome of the first gamble is unknown, Pr(G|U), can be computed through the law of total probability:\nPr( G |U ) = Pr( W |U ) \u00b7Pr( G |W )+Pr( L |U ) \u00b7Pr( G | L ) (1)\nIn Equation 1, Pr(W |U) corresponds to the probability of a player winning the first gamble, given that (s)he participated on the game in the first place. Pr(G|W ) is the probability of playing the second gamble, given that it is known that the player won the first one. Pr(L|U) corresponds to the probability of losing the first gamble, given that the participant decided to play the game in the first place. And finally, Pr(G|L) is the probability of a participant playing the second gamble, given that it is known that (s)he lost the first one.\nFollowing the law of total probability in Equation 1, the probability of playing the second gamble, given that the player did not know the outcome of the first one, should be between the following values [17]:\nPr( G |W )\u2265 Pr( G |U )\u2265 Pr( G | L ) (2)\nThe findings reported by [71], however, revealed a different relation. Equation 3 demonstrates that this relation is violating one of the most fundamental laws of Bayesian probability theory:\nPr( G |W ) = 0.69\u2265 Pr( G | L ) = 0.58\u2265 Pr( G |U ) = 0.37 (3)\n[71] explained these findings in the following way: when the participants knew that they won, then they had extra house money to play with and decided to play the second round. If the participants knew that they lost, then they chose to play again with the hope of recovering the\nlost money. But, when the participants did not know if they had won or lost the first gamble, then these thoughts, for some reason, did not emerge in their minds and consequently they decided not to play the second gamble. Other works in the literature also replicated this twostage gambling experiment [65, 50, 51], also reporting similar results to [71]. Their results are summarised in Table 1.\nThere have been different works in the literature trying to explain and model this phenomena [17, 61, 21]. Although the models in the literature diverge, they all agree in one thing: one cannot use classical probability theory to model this phenomena, since the most important rules are being violated. This two stage gambling game experiment was one of the most important works that motivated the use of different theories outside of classical bayesian theory and boolean logic, more specifically the usage of quantum probability theory."}, {"heading": "1.2 Research Questions", "text": "Recent findings in the cognitive psychology literature revealed that humans are constantly violating the law of total probability when making decisions under risk [14, 21, 22]. These researchers also showed that quantum probability theory enables the development of decision models that are able to simulate human decisions. Given that most of the systems that are used nowadays are based on Bayesian probability theory, is it possible to achieve better inference mechanisms in these systems using quantum probability theory? For instance, many medical diagnosing systems are based in classical probabilistic graphical models such as Bayesian Networks. Can one achieve better performances in diagnosing patients using quantum probability?\nGenerally speaking, a Bayesian Network is a probabilistic graphical model that represents a set of random variables and their conditional dependencies via a directed acyclic graph.\nThere are two main works in the literature that have contributed to the development and understanding of Quantum Bayesian Networks. One belongs to [68] and the other to [53].\nIn the work of [68], it is argued that any classical Bayesian Network can be extended to a quantum one by replacing real probabilities with quantum complex amplitudes. This means that the factorisation should be performed in the same way as in a classical Bayesian Network. One big problem with Tucci\u2019s work is concerned with the inexistence of any methods to set the phase parameters. The author states that, one could have infinite Quantum Bayesian Networks representing the same classical Bayesian Network depending on the values that one chooses to set the parameters. This requires that one knows a priori which parameters would lead to the desired solution for each node queried in the network (which we never know).\nIn the work of [53], the authors argue that, in order to develop a quantum Bayesian Network, it is required a quantum version of probability distributions, quantum marginal probabilities and quantum conditional probabilities. The proposed model fails to provide any advantage relatively to the classical models, because it cannot take into account interference effects between unobserved random variables. In the end, both models provide no advantages in modelling decision making problems that try to predict decisions that violate the laws of total probability.\nIn this paper, the core of the proposed Bayesian Network is based on the psychological findings uncovered in the works of [21, 22, 17, 61] and on quantum information processing. These authors show that, before taking a decision, human thoughts are seen as superposed waves that can interfere with each other, influencing the final decision. In Bayesian Networks, nodes can either be query variables, evidences or simply unknown. Given that we do not observe the unknown nodes of a Bayesian Network, since we do not know for sure what values\nthey can take, then what would happen to the inference process if these nodes are put in a representation of a quantum superposition and interfere with each other (Figure 4)? Can a better inference process be achieved? These are the main research questions that this paper aims at answering. So far, to the best of our knowledge, there is no previous work in the Computer Science community that attempts to map these psychological findings into computer science decision making systems, such as Bayesian Networks.\nIn order to validate our hypothesis, we performed experiments with well known classical Bayesian Networks from the literature. We first create a quantum Bayesian Network that can accommodate the paradoxical findings in the two-stage gambling game. We then generalise our quantum Bayesian Network in order to deal with larger and more complex datasets that are used in the literature: the well known Burglar/Alarm Bayesian Network from [63] and the Lung Cancer Bayesian Network from [59]."}, {"heading": "1.3 Outline", "text": "Before describing the proposed model, we first need to introduce some quantum probability concepts for the understanding of this work. Sections 2 and 3 present the main differences between classical and quantum probability theory. Instead of just presenting a set of formulas, we show this difference by means of an illustrative example, just like proposed in [17]. In Section 4, we describe how beliefs can act like waves and interfere with each other. We show mathematically how this interference term can be derived by using well known rules of complex numbers. Section 5 addresses the main works of the literature that contributed for the development of the interference term. It also introduces a new interference formula that will be applied in the proposed quantum probabilistic graphical models. Section 6 presents a comparison between a classical Bayesian Network model against the proposed quantum interference Bayesian Network applied to the problem of two-stage gambles. Section 7 presents another\ncomparison between the classical and quantum Bayesian Networks, but for a more complex network from the literature. In Section 8, it is made a discussion about the results obtained in the experiments performed in Section 7. Section 9 presents an additional experiment over another Bayesian Network in order to study the impact of the quantum interference parameters in different scenarios. Section 10 presents the most relevant works of the literature. Finally, Section 11 presents the main conclusions of this work."}, {"heading": "2 Probability Axioms of Classical and Quantum Theory", "text": "In this section, we describe the main differences between classical theory and quantum probability theory through examples. The example analyzed concerns jury duty. Suppose you are a juror and you must decide whether a defendant is guilty or innocent. The following sections describe how the classical and quantum theory evolve in the inference process. All this analysis is based on the book of [17]."}, {"heading": "2.1 Space", "text": "In classical probability theory, events are contained in Sample Spaces. A Sample Space \u2126 corresponds to the set of all possible outcomes of an experiment or random trial [31]. For example, when judging whether a defendant is guilty or innocent, the sample space is given by \u2126 = {Guilty, Innocent}. Figure 5 presents a diagram showing the sample space of a defendant being guilty or innocent.\nIn quantum probability theory, events are contained in the so called Hilbert Spaces. A Hilbert Space H can be viewed as a generalisation and extension of the Euclidean space into spaces with any finite or infinite number or dimensions. It can be see as a vector space of complex numbers and offers the structure of an inner product to enable the measurement of angles and lengths [40]. The space is spanned by a set of orthonormal basis vectors H = {Guilty, Innocent}. Together, these vectors form a basis for the space. Figure 6 presents a diagram showing the Hilbert space of a defendant being guilty or innocent [17]. Since a Hilbert space enables the usage of complex numbers, then, in order to represent the events Guilty and Innocent, one would need two dimensions for each event (one for the real part and another for the imaginary part). In quantum theory, one usually ignores the imaginary component in order to be able to visualise geometrically all vectors in a 2-dimensional space."}, {"heading": "2.2 Events", "text": "In classical probability theory, events can be defined by a set of outcomes to which a probability is assigned. They correspond to a subset of the sample space \u2126 from which they are contained in. Events can be mutually exclusive and they obey to set theory. This means that operations such as intersection or union of events are well defined. Since they respect set theory, the distributive axiom is also defined between sets. In our example, Guilty or Innocent can be seen as two mutually exclusive events.\nAccording to quantum probability theory, events correspond to a subspace spanned by a subset of the basis vectors contained in the Hilbert Space. Events can be orthogonal, that is, they can be mutually exclusive. Operations such as intersection and union of events are well defined if the events are spanned by the same basis vector [17]. In quantum theory, all events contained in a Hilbert Space are defined through a superposition state which is represented by a state vector S comprising the occurrence of all events. In our example, Guilty and Innocent correspond to column vectors representing the main axis of the circle in Figure 7. They are defined as follows:\nGuilty = [\n1 0\n] Innocent = [ 0 1 ]\nIn Figure 7, the superposition state S can be defined as follows.\nS = ei\u03b8G\u221a\n2 Guilty+ ei\u03b8I\u221a 2 Innocent (4)\nIn Equation 4, one might be wondering what the e i\u03b8 \u221a\n2 values mean. They are called probability\namplitudes. They correspond to the amplitudes of a wave and are described by complex numbers. The ei\u03b8 term is defined as the phase of the amplitude. It can be seen as a shift of the wave. These amplitudes are related to classical probability by taking the squared magnitude of these amplitudes. This is achieved by multiplying the amplitude with its complex conjugate (represented by the symbol \u2217).\nPr(Guilty) = \u2223\u2223\u2223\u2223ei\u03b8G\u221a2 \u2223\u2223\u2223\u22232 = (ei\u03b8G\u221a2 ) \u00b7 ( ei\u03b8G\u221a 2 )\u2217 = ei\u03b8G\u221a 2 \u00b7 e \u2212i\u03b8G \u221a 2 = ei(\u03b8G\u2212\u03b8G) ( 1\u221a 2 )2 = 0.5 (5)\nIn quantum theory, it is required that the sum of the squared magnitudes of each amplitude equals 1. This axiom is called the normalization axiom and corresponds to the classical theory constraint that the probability of all events in a sample space should sum to one.\u2223\u2223\u2223\u2223ei\u03b8G\u221a2 \u2223\u2223\u2223\u22232 + \u2223\u2223\u2223\u2223ei\u03b8I\u221a2 \u2223\u2223\u2223\u22232 = 1 (6)"}, {"heading": "2.3 System State", "text": "A system state is nothing more than a probability function Pr which maps events into probability numbers, i.e., positive real numbers between 0 and 1.\nIn classical theory, the system state corresponds to exactly its definition. There is a function that is responsible to assign a probability value to the outcome of an event. If the event corresponds to the sample space, then the system state assigns a probability value of 1 to the event. If the event is empty, then it assigns a probability of 0. In our example, if nothing else is told to the juror, then the probability of the defendant being guilty is Pr(Guilty) = 0.5.\nIn quantum theory, the probability of a defendant being Guilty is given by the squared magnitude of the projection from the superposition state S to the subspace containing the observed event Guilty. Figure 8 shows an example. If nothing is told to the juror about the guiltiness of a defendant, then according to quantum theory, we start with a superposition state S.\nS = ei\u03b8G\u221a\n2 Guilty+ ei\u03b8I\u221a 2 Innocent\nWhen someone asks whether the defendant is guilty, then we project the superposition state S into the relevant subspace, in this case the Guilty subspace (PG), just like shown in Figure 8. The probability is simply the squared magnitude of the projection, that is:\nPr(Guilty) = |PG|2 = \u2223\u2223\u2223\u2223ei\u03b8G\u221a2 \u2223\u2223\u2223\u22232 = 0.5 Which has exactly the same outcome as in the classical theory."}, {"heading": "2.4 State Revision", "text": "State revision corresponds to the situation where after observing an event, we are interested in observing other events given that the previous one has occurred.\nIn classical theory, this is addressed through the conditional probability formula Pr(B|A) = Pr(A\u2229B)\nPr(B) . So, returning to our example, suppose that some evidence has been given to the juror proving that the defendant is actually guilty, then what is the probability of him being innocent? This is computed in the following way.\nPr(Innocent|Guilty) = Pr(Innocent \u2229Guilty) Pr(Guilty) = 0\nSince the events Guilty and Innocent are mutually exclusive, then their intersection is empty, leading to a zero probability value.\nIn quantum theory, the state revision is given by first projecting the superposition state S into the subspace representing the observed event. Then, the projection is normalised such that the resulting vector is unit length. Again, if we want to determine the probability of a defendant being innocent, given he was found guilty, the calculations are performed as follows. We first start in the superposition state vector S.\nS = ei\u03b8G\u221a\n2 Guilty+ ei\u03b8I\u221a 2 Innocent\nThen, we observe that the defendant is guilty, so we project the state vector S into the Guilty subspace and normalise the resulting projection.\nSG = (ei\u03b8G/ \u221a 2) Guilty\u221a\u2223\u2223\u2223ei\u03b8G/\u221a2\u2223\u2223\u22232\nSG = ei\u03b8G Guilty+0 Innocent\nFrom the resulting state, we just extract the probability of being innocent by simply squaring the respective probability amplitude. Again, we obtain the same results as the classical theory.\nPr(Innocent|Guilty) = | 0 |2 = 0"}, {"heading": "3 The Path Trajectory Principle", "text": "In order to describe direct dependencies between a set of variables, path diagrams are generally used. This section shows how to compute quantum probabilities in a Markov model using Feynman\u2019s path rules, just like presented in the work of [21]."}, {"heading": "3.1 Single Trajectories", "text": "Consider the diagram represented in Figure 10.\ntrajectory Figure 11: Multiple\nindistinguishable paths\nThe computation of the probability of transiting from an initial state A to a final state C, transiting from an intermediate state B, can be achieved through a classical Markov model. The probability can be computed by making the product of the individual probabilities for each transition, from one state to another, through the usage of conditional probabilities. According to Figure 10, the probability of transiting from state A, followed by state B and ending in state C, that is, Pr(A\u2192 B\u2192C), is given by:\nPr( A\u2192 B\u2192C ) = Pr( A ) \u00b7Pr( B | A ) \u00b7Pr( C | B ) (7)\nIn a quantum path diagram model, the computation of the probabilities for a single path trajectory is similar to the classical Markov model. The calculation can be performed using Feynman\u2019s first rule, which asserts that the probability of a single path trajectory consists in the product of the squared magnitudes of the amplitudes for each transition from one state to the next along the path. This means that the quantum probability value of a single path trajectory is the same as the classical Markov probability for the same path. In Equation 8 and through the rest of this work, complex probability amplitudes will be represented by the symbol \u03c8 .\nPr( A\u2192 B\u2192C ) = | \u03c8A|2 \u00b7 | \u03c8 B | A |2 \u00b7 | \u03c8 C | B |2 = Pr(A) \u00b7Pr( B | A ) \u00b7Pr( C | B ) (8)"}, {"heading": "3.2 Multiple Indistinguishable Trajectories", "text": "An indistinguishable path consists in transiting from an initial state A to a final state D by transiting from multiple possible paths without knowing for certain which path was taken to reach the goal state. Figure 11 shows an example of multiple indistinguishable trajectories.\nIn a classical Markov model, if one does not observe which path was taken to reach the final state D, then one simply computes this probability by summing the individual probabilities of each path. This is known as the single path principle and is in accordance with the law of total probability. So, following Figure 11, in order to reach state D starting in state A, one can take the path A\u2192 B\u2192 D or the path A\u2192C\u2192 D. The final probability is given by:\nPr( A\u2192 D ) = Pr( A ) \u00b7Pr( B | A ) \u00b7Pr( D | B )+Pr( A ) \u00b7Pr( C | A ) \u00b7Pr( D |C ) (9)\nQuantum probability theory rejects the single path trajectory principle. If one does not observe which path was taken to reach the goal state, then one cannot assume that one of each possible paths was used. Instead, quantum probability argues that, when the path is unobserved, then the goal state can be reached through a superposition of path trajectories. This is known as Feynman\u2019s second rule, which states that the amplitude of transiting from an initial state A to a final state D, taking multiple indistinguishable paths, is given by the sum of all amplitudes for each path. This rule is in accordance with the law of total amplitude and the probability is computed by taking the squared magnitude of this sum. This probability is not equal to the classical Markov model.\nPr( A\u2192 D ) = |\u03c8A \u00b7\u03c8B | A \u00b7\u03c8D | B +\u03c8A \u00b7\u03c8 C | A \u00b7 \u03c8 D | C |2 =\n= |\u03c8A \u00b7\u03c8B | A \u00b7\u03c8 D | B |2+|\u03c8A \u00b7\u03c8C | A \u00b7 \u03c8D | C |2+2 \u00b7|\u03c8A \u00b7\u03c8B | A \u00b7 \u03c8D | B | \u00b7 |\u03c8A \u00b7\u03c8C | A \u00b7 \u03c8D | C |cos(\u03b8) (10)\nThe term cos(\u03b8) is the inner product between the vectors formed by | \u03c8B | A \u00b7 \u03c8 D | B | and | \u03c8C | A \u00b7 \u03c8D | C |. It comes from Euler\u2019s rule: cos(\u03b8) = ( ei\u03b8 + e\u2212i\u03b8 ) /2 and corresponds to a quantum interference term that does not exist in classical probability theory. Section 4 details how this term is derived. Since the interference term can lead to estimations with values higher than 1, then it is necessary to normalize this value in order to obtain a probability value.\nWhen the path is observed, quantum probability theory collapses to the classical Markov model. This is know as Feynman\u2019s third rule and states that the probability amplitude of observed multiple path trajectories corresponds to the sum of the amplitudes of each individual path. The probabilities are then taken by making the squared magnitude of each individual path. Figure 12 illustrates this example:\nPr( A\u2192 D ) = | \u03c8A \u00b7\u03c8B | A \u00b7 \u03c8 D | B |2 + | \u03c8A \u00b7\u03c8 C | A \u00b7 \u03c8 D | C |2 =\n= Pr(A) \u00b7Pr( B | A ) \u00b7 Pr( D | B )+Pr(A) \u00b7Pr( C | A ) \u00b7Pr( D |C ) (11)"}, {"heading": "4 The Interference Term", "text": "Quantum theory enables the modeling of the decision system as a wave moving across time over a state space until a final decision is made. Under this perspective, interference can be regarded as a chain of waves in a superposition state, coming from different directions. When these waves crash, one can experience a destructive effect (one wave destroys the other) or\na constructive effect (one wave merges with another). In either case, the final probabilities of each wave is affected. Psychological findings showed that this not only occurs in a microscopic scale (such as electrons), but also occurs at a macroscopic setting [44, 61, 22].\nIn this section we show how to derive the interference term by just taking into account well known properties of complex numbers [48]. The interference term can be derived in two different ways: (1) from the general probability formula of the union of N mutually exclusive events and (2) through the total law of probability."}, {"heading": "4.1 Deriving the Interference Term from the Union of N Mutually Exclusive Events", "text": "For simplicity, we will start by deriving the interference term for 2 events and then we will generalize for N events. The classical probability formula of the union of two mutual exclusive events is given by:\nPr(A\u222aB) = Pr(A)+Pr(B) (12)\nAnd the relation between a classical probability density function and a quantum probability amplitude is given by Born\u2019s rule, that is:\nPr(A) = | ei\u03b8A\u03c8A |2 (13)\nAgain, |ei\u03b8A\u03c8A|2 corresponds to the square magnitude of a complex amplitude. It is obtained by multiplying the probability amplitude with its complex conjugate. That is, | ei\u03b8A\u03c8A |2 = ei\u03b8A\u03c8Ae\u2212i\u03b8A\u03c8A.\nTaking into account Equation 13, one can write a superposition state between two mutual exclusive events A and B in the following way:\n\u03c8A+B = ei\u03b8A\u03c8A + ei\u03b8B\u03c8B (14)\nThe relation of this superposed state with classical probability theory remains:\nPr(A\u222aB) = Pr( A )+Pr( B ) \u221d | ei\u03b8A\u03c8A + ei\u03b8B\u03c8B |2 = |\u03c8A+B|2 (15)\nThe quantum counterpart of the classical probability of the union of two mutually exclusive events, when we do not observe them, collapses to Feynmann\u2019s second rule, that is:\nPr(A\u222aB) = | ei\u03b8A\u03c8A + ei\u03b8B\u03c8B |2 = ( ei\u03b8A\u03c8A + ei\u03b8B\u03c8B ) \u00b7 ( ei\u03b8A\u03c8A + ei\u03b8B\u03c8B )\u2217\n| ei\u03b8A\u03c8A+ei\u03b8B\u03c8B |2 = ei\u03b8A\u03c8A \u00b7 e\u2212i\u03b8A\u03c8A+ei\u03b8A\u03c8A \u00b7 e\u2212i\u03b8B\u03c8B+ei\u03b8B\u03c8B \u00b7 e\u2212i\u03b8A\u03c8A+ei\u03b8B\u03c8B \u00b7 e\u2212i\u03b8B\u03c8B\n| ei\u03b8A\u03c8A + ei\u03b8B\u03c8B |2 = | \u03c8A |2 + | \u03c8B |2 + ei\u03b8A\u03c8A \u00b7 e\u2212i\u03b8B\u03c8B + ei\u03b8B\u03c8B \u00b7 e\u2212i\u03b8A\u03c8A (16)\nThe classical probability of the union of two mutual exclusive events is P(A\u222aB) = Pr(A)+ Pr(B). In Equation 16, the amplitude | \u03c8A |2 corresponds to Pr(A) and | \u03c8B |2 corresponds to Pr(B). So, what is the additional term, ei\u03b8A\u03c8A \u00b7 e\u2212i\u03b8B\u03c8B + ei\u03b8B\u03c8B \u00b7 e\u2212i\u03b8B\u03c8A, that we\nderived in Equation 16? This term does not exist in classical probability theory and is called the interference term. The interference term can be rewritten like in Equation 17:\nei\u03b8A\u03c8A \u00b7 e\u2212i\u03b8B\u03c8B + ei\u03b8B\u03c8B \u00b7 e\u2212i\u03b8A\u03c8A = | \u03c8A ||\u03c8B|ei(\u03b8A\u2212\u03b8B)+ | \u03c8A ||\u03c8B|ei(\u03b8B\u2212\u03b8A) (17)\nKnowing that,\ncos(\u03b81\u2212\u03b82) = ei(\u03b81\u2212\u03b82)+ ei(\u2212\u03b81+\u03b82)\n2 Then Equation 17 can be rewritten as:\nei\u03b8A\u03c8A \u00b7 e\u2212i\u03b8B\u03c8B + ei\u03b8B\u03c8B \u00b7 e\u2212i\u03b8A\u03c8A = 2| \u03c8A ||\u03c8B|cos(\u03b8A\u2212\u03b8B) (18)\nSo, the complete quantum probability formula for the union of 2 mutually exclusive events is given by:\n\u03c8AB=| ei\u03b8A\u03c8A + ei\u03b8B\u03c8B |2 = | \u03c8A |2 + | \u03c8B |2 +2 | \u03c8A | |\u03c8B|cos(\u03b8A\u2212\u03b8B) (19)\nIn the above formula, the angle \u03b8A \u2212 \u03b8B corresponds to the phase of the inner product between | \u03c8A | and | \u03c8B |.\nEquation 19 only computes the probability of the union of 2 mutually exclusive events. In classical probability theory, if we want to compute the probability of the union of N mutually exclusive events, then we use a generalization of Equation 12, that is:\nPr(A1\u222aA2\u222a\u00b7\u00b7 \u00b7\u222aAN) = N\n\u2211 i=1 Pr(Ai) (20)\nIn quantum theory, we make an analogous calculation. In order to compute the probability of the union of N mutually exclusive events, then one needs to generalize Equation 14. The outcome is given by the following formula:\nPr(A1\u222aA2\u222a\u00b7\u00b7 \u00b7\u222aAN) = |\u03c8A1 +\u03c8A2 + \u00b7 \u00b7 \u00b7+\u03c8AN | 2 = \u2223\u2223\u2223\u2223\u2223 N\u2211i=1 \u03c8Ai \u2223\u2223\u2223\u2223\u2223 2\n|ei\u03b81\u03c8A1 + e i\u03b82\u03c8A2 + \u00b7 \u00b7 \u00b7+ e i\u03b8AN \u03c8N |2 = N\n\u2211 i=1 |\u03c8Ai|\n2 +2 N\u22121\n\u2211 i=1\nN\n\u2211 j=i+1 |\u03c8Ai||\u03c8A j |cos(\u03b8i\u2212\u03b8 j) (21)"}, {"heading": "4.2 Deriving the Interference Term from the Law of Total Probability", "text": "This interference term can also be derived directly from the law of total probability. Suppose that events A1,A2, . . . ,AN form a set of mutually disjoint events, such that their union is all in the sample space, \u2126, for any other event B. Then, the classical law of total probability can be formulated like in Equation 22.\nPr(B) = N\n\u2211 i=1\nPr(Ai)Pr(B|Ai) where: N\n\u2211 i=1 Pr(Ai) = 1 (22)\nThe quantum interference law of total probability can be derived through Equation 22 by applying Born\u2019s rule (Equation 13). That is:\nPr(B) = \u2223\u2223\u2223\u2223\u2223 N\u2211x=1 ei\u03b8x\u03c8Ax\u03c8B|Ax \u2223\u2223\u2223\u2223\u2223 2\nwhere: N\n\u2211 x=1 \u2223\u2223\u2223ei\u03b8x\u03c8Ax\u2223\u2223\u22232 = 1 (23) For simplicity, we will expand Equation 23 for N = 3 and only later we will find the general\nformula for N events:\nPr(B) = \u2223\u2223\u2223ei\u03b81\u03c8A1\u03c8B|A1 + ei\u03b82\u03c8A2\u03c8B|A2 + ei\u03b83\u03c8A3\u03c8B|A3\u2223\u2223\u22232 (24)\nPr(B)= (\nei\u03b81\u03c8A1\u03c8B|A1 + e i\u03b82\u03c8A2\u03c8B|A2 + e i\u03b83\u03c8A3\u03c8B|A3 )( ei\u03b81\u03c8A1\u03c8B|A1 + e i\u03b82\u03c8A2\u03c8B|A2 + e i\u03b83\u03c8A3\u03c8B|A3 )\u2217\n(25)\nPr(B)= (\nei\u03b81\u03c8A1\u03c8B|A1 + e i\u03b82\u03c8A2\u03c8B|A2 + e i\u03b83\u03c8A3\u03c8B|A3 )( e\u2212i\u03b81\u03c8A1\u03c8B|A1 + e \u2212i\u03b82\u03c8A2\u03c8B|A2 + e \u2212i\u03b83\u03c8A3\u03c8B|A3 )\n(26)\nPr(B)= ei\u03b81\u03c8A1\u03c8B|A1e \u2212i\u03b81\u03c8A1\u03c8B|A1 +e i\u03b81\u03c8A1\u03c8B|A1e \u2212i\u03b82\u03c8A2\u03c8B|A2 +e i\u03b81\u03c8A1\u03c8B|A1e \u2212i\u03b83\u03c8A3\u03c8B|A3+\n+ei\u03b82\u03c8A2\u03c8B|A2e \u2212i\u03b81\u03c8A1\u03c8B|A1 + e i\u03b82\u03c8A2\u03c8B|A2e \u2212i\u03b82\u03c8A2\u03c8B|A2 + e i\u03b82\u03c8A2\u03c8B|A2e \u2212i\u03b83\u03c8A3\u03c8B|A3+\n+ei\u03b83\u03c8A3\u03c8B|A3e \u2212i\u03b81\u03c8A1\u03c8B|A1 + e i\u03b83\u03c8A3\u03c8B|A3e \u2212i\u03b82\u03c8A2\u03c8B|A2 + e i\u03b83\u03c8A3\u03c8B|A3e \u2212i\u03b83\u03c8A3\u03c8B|A3\n(27) Simplifying Equation 27, we obtain:\nPr(B) = \u2223\u2223\u03c8A1\u03c8B|A1\u2223\u22232 + \u2223\u2223\u03c8A2\u03c8B|A2\u2223\u22232 + \u2223\u2223\u03c8A3\u03c8B|A3\u2223\u22232 + Inter f erence (28)\nIn Equation 28, one can see that it is composed by the classical law of total probability and by an interference term. This interference term comes from Equation 27 and corresponds to:\nInter f erence = ei\u03b81\u2212i\u03b82\u03c8A1\u03c8B|A1\u03c8A2\u03c8B|A2 + e i\u03b82\u03c8A2\u03c8B|A2e \u2212i\u03b81\u03c8A1\u03c8B|A1+\n+ei\u03b81\u2212i\u03b83\u03c8A1\u03c8B|A1\u03c8A3\u03c8B|A3 + e i\u03b83\u2212i\u03b81\u03c8A3\u03c8B|A3\u03c8A1\u03c8B|A1+\n+ei\u03b82\u2212i\u03b83\u03c8A2\u03c8B|A2\u03c8A3\u03c8B|A3 + e i\u03b83\u2212i\u03b82\u03c8A3\u03c8B|A3\u03c8A2\u03c8B|A2 (29)\nKnowing that\ncos(\u03b8) = ei\u03b8 + e\u2212i\u03b8\n2 \u21d2 cos(\u03b81\u2212\u03b82) =\nei\u03b81\u2212i\u03b82 + ei\u03b82\u2212i\u03b81\n2\nThen, Equation 28 becomes\nPr(B) = \u2223\u2223\u03c8A1\u03c8B|A1\u2223\u22232 + \u2223\u2223\u03c8A2\u03c8B|A2\u2223\u22232 + \u2223\u2223\u03c8A3\u03c8B|A3\u2223\u22232 +2\u03c8A1\u03c8B|A1\u03c8A2\u03c8B|A2 cos(\u03b81\u2212\u03b82)+\n+2\u03c8A1\u03c8B|A1\u03c8A3\u03c8B|A3 cos(\u03b81\u2212\u03b83)+2\u03c8A2\u03c8B|A2\u03c8A3\u03c8B|A3 cos(\u03b82\u2212\u03b83) (30)\nGeneralizing Equation 30 for N events, the final probabilistic interference formula, derived from the law of total probability, is given by:\nPr(B) = N\n\u2211 i=1 \u2223\u2223\u03c8Ai\u03c8B|Ai\u2223\u22232 +2 N\u22121\u2211 i=1 N \u2211 j=i+1 \u03c8Ai\u03c8B|Ai\u03c8A j\u03c8B|A j cos(\u03b8i\u2212\u03b8 j) (31)\nFollowing Equation 31, when cos(\u03b8i\u2212\u03b8 j) equals zero, then it is straightforward that quantum probability theory converges to its classical counterpart, because the interference term will be zero.\nFor non-zero values, Equation 31 will produce interference effects that can affect destructively the classical probability ( when interference term in smaller than zero ) or constructively ( when it is bigger than zero ). Additionally, Equation 31 will lead to a large amount of \u03b8 parameters when the number of events increases. For N binary random variables, we will end up with 2N parameters to tune."}, {"heading": "5 The Role of the Interference Term in the Literature", "text": "In the 20th century, the physicist Max Born proposed a problem related to quantum probabilities, which was later known as the The Inverse Born Problem. The problem consisted in constructing a probabilistic representation of data from different sources (physics, psychology, economy, etc), by a complex probability amplitude, which could match Born\u2019s rule (already presented in Equation 13).\nThe probabilistic interference formula for the law of total probability, derived in the previous section (Equation 31), can be seen as an answer to the Inverse Born Problem. The most important works in the literature that contributed for the derivation of this interference term, through the law of total probability, correspond to the works of A. Khrennikov [47, 44, 48, 39, 43, 24]. These authors address the interference term as |\u03bb (B|A)|. In the situations where |\u03bb (B|A)| \u2264 1, then one can apply the trigonometric formula derived in Equation 31. However, there are some data where this condition is not verified. Therefore, when |\u03bb (B|A)| \u2265 1, the authors propose the usage of a hyperbolic interference term, to act like an upper boundary in order to constraint the probability value to a maximum value of 1. This would require the usage of Hyperbolic Hilbert Spaces instead of the complex ones.\nIn this paper, we argue that there is no need to represent probabilities in a Hyperbolic Hilbert Space in order to avoid non-probability values. Since we will be dealing with probabilistic graphical models, we will always be required to normalise the probability amplitudes when performing probabilistic inferences. For this work, we follow the same probabilistic paradigm used in traditional Bayesian Networks. Thus, we constrain Equation 32 and Equation 33 by a normalisation factor \u03b1 that will guarantee that the computed values will always be probabilities lesser or equal than one. This normalisation factor corresponds to Feynman\u2019s conjecture [33] that an electron can follow any path. Thus, in order to compute the probability Pr(B) that a\nparticle ends up at a point B , one must sum over all possible paths that the particle can go through. Since the interference term can lead to estimations with values higher than 1, then it is necessary to normalise in order to obtain a probability value.\nPr(B)=\u03b1\n[ N\n\u2211 i=1 \u2223\u2223\u03c8Ai\u03c8B|Ai\u2223\u22232 +2 N\u22121\u2211 i=1 N \u2211 j=i+1 \u03c8Ai\u03c8B|Ai\u03c8A j\u03c8B|A j cos(\u03b8i\u2212\u03b8 j)\n] where \u03b1 =\n1 Pr(B)+Pr(\u00acB)\n(32)\nPr(A1 + \u00b7 \u00b7 \u00b7+AN) = \u03b1\n[ N\n\u2211 i=1 |\u03c8Ai|\n2 +2 N\u22121\n\u2211 i=1\nN\n\u2211 j=i+1 |\u03c8Ai||\u03c8A j |cos(\u03b8i\u2212\u03b8 j)\n] (33)\nwhere \u03b1 = 1\nPr(A1 + \u00b7 \u00b7 \u00b7+AN)+Pr(\u00acA1 + \u00b7 \u00b7 \u00b7+\u00acAN) Through the triangular inequality, we can also prove that the proposed interference term is also always positive. This way, the axioms of probability theory that state that 0 \u2264 Pr(A) \u2264 1 will always be satisfied. By applying the triangular inequality, one can easily demonstrate that Equation 33 and, consequently, Equation 32 have always to be positive.\nThrough the triangular inequality, Equation 33 can be related to:\n|\u03c8A1 +\u03c8A2 + \u00b7 \u00b7 \u00b7+\u03c8AN | 2 \u2264 (|\u03c8A1|+ |\u03c8A2|+ \u00b7 \u00b7 \u00b7+ |\u03c8AN |) 2 (34)\nN\n\u2211 i=1 |\u03c8Ai|\n2 +2 N\u22121\n\u2211 i=1\nN\n\u2211 j=i+1\n|\u03c8Ai||\u03c8A j |cos(\u03b8i\u2212\u03b8 j)\u2264 N\n\u2211 i=1 |\u03c8Ai|\n2 +2 N\u22121\n\u2211 i=1\nN\n\u2211 j=i+1 |\u03c8Ai||\u03c8A j | (35)\nN\u22121\n\u2211 i=1\nN\n\u2211 j=i+1\n|\u03c8Ai||\u03c8A j |cos(\u03b8i\u2212\u03b8 j)\u2264 N\u22121\n\u2211 i=1\nN\n\u2211 j=i+1 |\u03c8Ai||\u03c8A j | (36)\n\u2212 N\u22121\n\u2211 i=1\nN\n\u2211 j=i+1\n|\u03c8Ai||\u03c8A j |cos(\u03b8i\u2212\u03b8 j)+ N\u22121\n\u2211 i=1\nN\n\u2211 j=i+1 |\u03c8Ai||\u03c8A j | \u2265 0 (37)\nN\u22121\n\u2211 i=1\nN\n\u2211 j=i+1\n|\u03c8Ai||\u03c8A j | [ 1\u2212 cos(\u03b8i\u2212\u03b8 j) ] \u2265 0 (38)\nThe maximum value that cos(\u03b8i\u2212 \u03b8 j) can have is 1 and the minimum value is \u22121. So, the minimum value that the term 1\u2212 cos(\u03b8i\u2212 \u03b8 j) can have is 0 (when the cosine achieves its maximum value). Given that \u03c8A1 , \u03c8A2, . . . , \u03c8AN are always positive numbers, then it is straightforward that Equation 32 has to be always positive."}, {"heading": "6 Classical vs Quantum Bayeisan Network to Model Two", "text": "Stage Gambles"}, {"heading": "6.1 Classical Bayesian Networks", "text": "A classical Bayesian Network can be defined by a directed acyclic graph structure in which each node represents a different random variable from a specific domain and each edge represents\na direct influence from the source node to the target node. The graph represents independence relationships between variables and each node is associated with a conditional probability table which specifies a distribution over the values of a node given each possible joint assignment of values of its parents. This idea of a node depending directly from its parent nodes is the core of Bayesian Networks. Once the values of the parents are known, no information relating directly or indirectly to its parents or other ancestors can influence the beliefs about it [49]."}, {"heading": "6.1.1 Classical Conditional Independece", "text": "Associated to Bayesian Networks there is always the concept of conditional independence. Two random variables X and Y are conditionally independent given a third random variable Z if and only if they are independent in their conditional probability distribution given Z. In other words, X and Y are conditionally independent given Z, (X = x\u22a5Y = y|Z), if and only if, given any value of Z, the probability distribution of X is the same for all values of Y and the probability distribution of Y is the same for all values of X .\nThis means that an independence statement over random variables is a universal quantification over all possible values of random variables [49]. Therefore, a probability distribution Pr satisfies (X \u22a5 Y |Z) if and only if:\nPr(X ,Y |Z) = Pr(X |Z)Pr(Y |Z) (39)"}, {"heading": "6.1.2 Classical Random Variables", "text": "In classical probability theory, a random variable X is defined by a function that associates a value to each outcome in the sample space \u2126, X : \u2126\u2192 R."}, {"heading": "6.1.3 Example of Application in the Two-Stage Gambling Game", "text": "In the two-stage gambling game, the random variables correspond to the nodes and their respective conditional probability tables of the Bayesian Network in Figure 13. That is, the variable\nU corresponds to a player willing or not to participate in the game. Variable G1 corresponds to the variable winning or losing the first gamble. Variable G2 corresponds to a player playing or not the second gamble."}, {"heading": "6.1.4 Classical Full Joint Distributions", "text": "In classical probability theory, the full joint distribution over a set of n random variables \u03c7 = { X1, X2, ..., Xn} defined over the same sample space, Pr(X1,X2, ...,Xn), is the distribution that assigns probabilities to events that are specified in terms of these random variable [49].Then, the full joint distribution of a Bayesian Network, where X is the list of variables, is given by [63]:\nPr(X1, . . . ,Xn) = n\n\u220f i=1 Pr(Xi|Parents(Xi)) (40)"}, {"heading": "6.1.5 Example of Application in the Two-Stage Gambling Game", "text": "Using Equation 40, the full joint distribution of Figure 13 corresponds to the calculations discriminated in Tables 2."}, {"heading": "6.1.6 Classical Marginalization", "text": "Given a query random variable X and let Y be the unobserved variables in the network, the marginal distribution of X is simply the probability distribution of X averaging over the information about Y . The marginal probability for discrete random variables, can be defined by Equation 41. The summation is over all possible y, i.e., all possible combinations of values of the unobserved variables y. The term \u03b1 corresponds to a normalization factor for the distribution Pr(X) [63].\nPr(X = x) = \u03b1 \u2211 y Pr(X = x,Y = y) = \u03b1 \u2211 y Pr(X = x|Y = y)Pr(Y = y), where \u03b1 = 1 \u2211x\u2208X Pr(X = x)\n(41)"}, {"heading": "6.1.7 Example of Application in the Two-Stage Gambling Game", "text": "After computing the full joint distribution, we need to sum out all the variables that are unknown, in this case, the variable corresponding to the outcome of the first gamble: G1. This is achieved by applying the marginal probability formula in Equation 41.\nPr(G2 = Play |U = Play) = \u03b1 \u2211 g\u2208G1 Pr(U = Play,G1 = g,G2 = Play)\nPr(G2 =Play |U =Play)=\u03b1 Pr(U =Play) \u2211 g\u2208G1 Pr(G1 = g |U =Play) Pr(G2 =Play |G1 = g)\nPr(G2 =Play |U =Play)=\u03b1 Pr(U =Play) [Pr(G1 =win |U =Play) Pr(G2 =Play |G1 =win) + + Pr(G1 = lose |U = Play) Pr(G2 = Play | G1 = lose)]\nPr(G2 = Play |U = Play) = \u03b10.295 Pr(G2 = Not Play |U = Play) = \u03b10.205\nThe parameter \u03b1 corresponds to a normalisation factor and, for this example, is given by:\n\u03b1 = 1\nPr(G2 = Play |U = Play)+Pr(G2 = Not Play |U = Play) = 1 0.295+0.205 = 1\n0.5 So, the final normalised classical probabilities for the two-stage gambling game correspond\nto: Pr(G2 = play |U = play) = 0.59\nPr(G2 = Not Play |U = Play) = 0.41 The probabilities computed are not in accordance with the probabilistic findings reported by [71], because it was empirically observed that Pr(G2 = play |U = play) = 0.42. Therefore, a classical Bayesian Network can never be used to model such experiments, because of the relation already presented in Equation 3."}, {"heading": "6.2 The Quantum Interference Bayesian Network", "text": "Following the work of [53], a Quantum Bayesian Network can be defined by a pair (G,\u03c1v), where G = (V,E) is a directed acyclic graph, and each vertex v\u2208V is associated with a quantum system with a Hilbert space Hv and \u03c1v is a quantum state on HV = Hv1\u2297Hv2\u2297 \u00b7\u00b7 \u00b7 \u2297Hvn. The state \u03c1v satisfies the same conditional independence constraints as in a classical Bayesian Network. Note that the definition of a classical Bayesian Network can be directly obtained by replacing the word quantum system by random variable.\nThe symbol \u2297 is defined by tensor product and corresponds to a mathematical method that enables the construction of a Hilbert space from the combination of individual Hilbert spaces. Suppose that we have 2 different 2-dimensional Hilbert spaces Hx and Hy, where Hx = {x1,x2} and Hy = {y1,y2}. Then, their tensor product would be:\n[ x1 x2 ] \u2297 [ y1 y2 ] =  x1 y1 x1 y2 x2 y1 x2 y2 "}, {"heading": "6.2.1 Quantum Random Variables", "text": "In quantum theory, random variables are associated to a set of N quantum systems V = {v1,v2, ...,vN}, each associated with a Hilbert space with a specific dimension[53]. Consequently, all values contained in the conditional probability tables associated to the random variables are complex numbers."}, {"heading": "6.2.2 Example of Application in the Two-Stage Gambling Game", "text": "Each node on the Bayesian Network in Figure 14 can be seen as a subsystem belonging to a specific Hilbert space. For instance, the first node U can be represented in a Hilbert subspace Hu in the following way:\nU = ei\u03b8U 1\u221a 2 Play+ ei\u03b8U 1\u221a 2 Not Play\nWhere Play and Not Play are column vectors corresponding to the basis of the subspace Hu: Play = [\n1 0\n] Not Play = [ 0 1 ] Since our goal is to compare the quantum Bayesian Network with its classical counterpart, we will convert the conditional probability tables in Figure 13 into conditional amplitude tables. That is, we simply convert classical probabilities into complex amplitudes through the relation in Equation 13.\nPr(A) = |ei\u03b8A\u03c8A|2\u2192 \u03c8A = ei\u03b8A \u221a Pr(A) (42)"}, {"heading": "6.2.3 Quantum State", "text": "The representation of a general state in a Bayesian Network can be described by a bipartite state. Suppose that H = HX \u2297HY \u2297HZ is a Hilbert space defined by the composition of three Hilbert spaces HX , HY and HZ . Then, a quantum state SXY Z is designated bipartite if it can be specified with respect to the random variables X , Y and Z. For Xi, Yj and Zk as basis in HX , HY and HZ , respectively, the bipartite state is given by Equation 43.\nSXY Z = \u2211 i, j,k \u03c8Xi\u03c8Y j\u03c8ZkXi\u2297Yj\u2297Zk (43)\nIn Equation 43, \u03c8Xi\u03c8Y j\u03c8Zk corresponds to the amplitudes of states Xi, Yj and Zk, respectively. The states Xi, Yj and Zk correspond to column vectors representing basis vectors:\nX0 = Y0 = Z0 = [\n1 0\n] , X1 = Y1 = Z1 = [ 0 1 ]"}, {"heading": "6.2.4 Example of Application in the Two-Stage Gambling Game", "text": "The general quantum state represented by the Bayesian Network in Figure 14 is given by quantum bipartite states. Reformulating Equation 43 for the problem of two step gambles, we obtain:\nSU,G1,G2 = \u2211 i jk \u03c8Ui\u03c8G1 j\u03c8G2kUi\u2297G1 j\u2297G2k (44)\nFor simplicity, we will write \u03c8Ui\u03c8G1 j\u03c8G2k as \u03c8i jk. So, expanding Equation 44,\nSU,G1,G2 =\u03c8000 U0G10G20ei(\u03b8U0+\u03b8G10+\u03b8G20)+\u03c8001 U0G10G21ei(\u03b8U0+\u03b8G10+\u03b8G21)+\u03c8010 U0G11G20ei(\u03b8U0+\u03b8G11+\u03b8G20)+\n+\u03c8011 U0G11G21ei(\u03b8U0+\u03b8G11+\u03b8G21)+\u03c8100 U1G10G20ei(\u03b8U1+\u03b8G10+\u03b8G20)+\u03c8101 U1G10G21ei(\u03b8U1+\u03b8G10+\u03b8G21)+\n+\u03c8110 U1G11G20ei(\u03b8U1+\u03b8G11+\u03b8G20)+\u03c8111 U1G11G21ei(\u03b8U1+\u03b8G11+\u03b8G21) (45)\nNote that UiG1 jG2k are basis column vectors representing the axis of the Hilbert Space,\nU0G10G20 =  1 0 0 0 0 0 0 0  , U0G10G21 =  0 1 0 0 0 0 0 0  , U0G11G20 =  0 0 1 0 0 0 0 0  , . . . U1G11G21 =  0 0 0 0 0 0 0 1  ,\nFollowing the quantum Bayesian Network in Figure 14, we compute the values of \u03c8Ui\u03c8G1 j\u03c8G2k by multiplying the correspondent values in the conditional probability tables. For example, \u03c8000 corresponds to the product of the variables U = Play with G1 = Win | U = Play with G2 = Play | G1 = Win. On the other hand, the entry \u03c8110 corresponds to the product of the variables U = Not Play with G1 = Lose |U = Not Play with G2 = Play | G1 = Lose. Replacing Equation 45 by the conditional probability values in Figure 14, we obtain:\nSU,G1,G2 = ei(\u03b8U0+\u03b8G10+\u03b8G20) 1\u221a 2 1\u221a 2 \u221a 17 5 U0G10G20+ei(\u03b8U0+\u03b8G10+\u03b8G21) 1\u221a 2 1\u221a 2 \u221a 8 5 U0G10G21+ei(\u03b8U0+\u03b8G11+\u03b8G20) 1\u221a 2 1\u221a 2 1\u221a 2 U0G11G20+\n+ei(\u03b8U0+\u03b8G11+\u03b8G21) 1\u221a 2 1\u221a 2 1\u221a 2 U0G11G21+ei(\u03b8U1+\u03b8G10+\u03b8G20) 1\u221a 2 1\u221a 2 \u221a 17 5 U1G10G20+ei(\u03b8U1+\u03b8G10+\u03b8G21) 1\u221a 2 1\u221a 2 \u221a 8 5 U1G10G21\n+ei(\u03b8U1+\u03b8G11+\u03b8G20) 1\u221a 2 1\u221a 2 1\u221a 2 U1G11G20 + ei(\u03b8U1+\u03b8G11+\u03b8G21) 1\u221a 2 1\u221a 2 1\u221a 2 U1G11G21\nSU,G1,G2 = 0.4123 U0G10G20+0.2828 U0G10G21+0.3536 U0G11G20+0.3536 U0G11G21+\n+0.4123 U1G10G20 +0.2828\n\u221a 8\n5 U1 G10G21 +0.3536 U1G11G20 +0.3536 U1G11G21\nNote that the sum of the squares of all probability amplitudes \u03c8Ui\u03c8G1 j\u03c8G2k sum to 1,\n\u2211 i jk \u2223\u2223\u03c8Ui\u03c8G1 j\u03c8G2k\u2223\u22232 = 1 This bipartite state represents a quantum superposition over all possible states. We can\nthink of this as various wave functions that are occurring at the same time."}, {"heading": "6.2.5 Quantum Full Joint Distribution", "text": "In quantum probability theory, a full joint distribution is given by a density matrix. This matrix provides the probability distribution of all states that a Bayesian Network can have. In our quantum Bayesian Network model, the density matrix \u03c1 corresponds to the multiplication of the bipartite state described in Equation 43 with itself (the symbol \u2020 corresponds to the conjugate transpose):\n\u03c1 = SXY ZS \u2020 XY Z (46)\nThe reason why one multiplies the same state with itself is to obtain the probability value out of the amplitude. Note that the bipartite state contains amplitudes instead of probability values. Knowing that the probability value is obtained by taking the squared magnitude of the amplitude, then, by multiplying a state with its conjugate transpose, one can obtain the full joint probability distribution."}, {"heading": "6.2.6 Example of Application in the Two-Stage Gambling Game", "text": "From the bipartite state, one can compute the density matrix by applying Equation 46 to this calculation. The density matrix will be useful for later calculations and enables the calculation of the probability distribution of the bipartite state.\n\u03c1UG1G2 = SUG1G2 \u00b7 S\u2020UG1G2 (47)\nIn this two step gambling game, Equation 47 produces an 8 x 8 density matrix:\n\u03c1UG1G2 =  |\u03c8000|2 0 0 . . . 0 0 |\u03c8001|2 0 . . . 0 0 0 |\u03c8010|2 . . . 0 ... ... ... . . . ...\n0 0 0 . . . |\u03c8111|2\n =  0.1700 0 0 0 0 0 0 0 0 0.0800 0 0 0 0 0 0 0 0 0.1250 0 0 0 0 0 0 0 0 0.1250 0 0 0 0 0 0 0 0 0.1700 0 0 0 0 0 0 0 0 0.0800 0 0 0 0 0 0 0 0 0.1250 0 0 0 0 0 0 0 0 0.1250  (48)"}, {"heading": "6.2.7 Quantum Marginalization", "text": "The concept of quantum marginalization is analogous to the one in classical probability theory. Given two quantum random variables X and Y , the general idea is to compute the average of the probability distribution of X over the information about Y . This is performed by using the partial trace operator, which basically consists in accessing certain positions of the density matrix \u03c1 .\nXi j = \u03b1 \u2211 y\u2208Y \u03c1[iy, jy] (49)\nIn Equation 49, the parameter \u03b1 corresponds to the normalization factor, which is also present in the classical Bayesian Network inference."}, {"heading": "6.2.8 Example of Application in the Two-Stage Gambling Game", "text": "Considering the two-stage gambling game that we are analyzing, imagining that we want to determine the probability of a participant playing the second gamble, Pr(G200), given that we verified that the player participated in the game in the first place (u = 0). That is, we will be summing out variable G1. Through Equation 49, one would proceed in the following way:\nG2i j = G200 = \u03b1 \u2211 g\u2208G1 \u03c1[ugi,ug j] = \u03b1(\u03c1[000,000]+\u03c1[010,010]) = \u03b10.2950\u2192 0.59\nAnd in the same way for G211:\nG211 = \u03b1 \u2211 g\u2208G1,u\u2208U \u03c1[ugi,ug j] = \u03b1(\u03c1[001,001]+\u03c1[011,011]) = \u03b10.2050\u2192 0.41\nNote that the indexes of the density matrix are encoded. The assignment 000 corresponds to index 0, the assignments 001 to index 1, . . . , and the assignment 111 corresponds to the index 8.\nThe normalised results correspond to the same probabilities obtained in classical theory. Therefore, we need to incorporate the interference terms found in cognitive psychology into the quantum marginalization formula in order to obtain different results."}, {"heading": "6.2.9 Quantum Marginalization with Interference", "text": "A quantum interference effect will occur when performing the marginalization of a random variable. If we do not observe a random variable, then it can be in represented by superposition and perform interferences in other random variables, changing the final outcome.\nThe quantum interference marginalization formula proposed in this work consists in merging the equation that presents the interference term (Equation 21) with the formula of quantum marginalization (Equation 49). This leads to Equation 50:\nXi j = \u03b1 \u2223\u2223\u2223\u2223\u2223\u2211y\u2208Y \u03c1[iy, jy] \u2223\u2223\u2223\u2223\u2223 2\nXi j = \u03b1\n( N\n\u2211 i |\u03c8i|2 +2\nN\u22121\n\u2211 i\nN\n\u2211 j=i+1 |\u03c8i||\u03c8 j|cos(\u03b8i\u2212\u03b8 j)\n) , where |\u03c8i|2 = \u2211\ny\u2208Y \u03c1[iy, jy] (50)"}, {"heading": "6.2.10 Example of Application in the Two-Stage Gambling Game", "text": "Following the experiment performed by [71], we want to determine the probability of a participant playing the second gamble, given that (s)he does not know the outcome of the first gamble.\nThrough Equation 50, this can be computed in the following way:\nG2i j = \u03b1 \u2223\u2223\u2223\u2223\u2223 \u2211u\u2208U,g\u2208G1 \u03c1[iug, jug]\u00b7 \u2223\u2223\u2223\u2223\u2223 2\nGiven that we want to know the probability of a participant playing the second gamble, then we know for certain that (s)he accepted to play. Thus, we will fix the variable U , representing that a participant accepted to play the game in the first place, U = 0:\nG2i j = \u03b1 \u2223\u2223\u2223\u2223\u2223 \u2211g\u2208G1 \u03c1[i0g, j0g] \u2223\u2223\u2223\u2223\u2223 2\n(51)\nExpanding Equation 51,\nG200 = \u03b1 |\u03c1[000,000]+\u03c1[010,010]|2\nG200 = \u03b1 |0.17+0.125|2 = \u03b1(0.17+0.125+2 \u221a 0.17 \u221a 0.125cos(\u03b81\u2212\u03b82)) (52)\nComputing the probability of a participant deciding to not play the second gamble, given that he does not know the outcome of the first play, we obtain:\nG211 = \u03b1 |\u03c1[001,001]+\u03c1[011,011]|2\nG211 = \u03b1 |0.08+0.125|2 = \u03b1(0.08+0.125+2 \u221a 0.08 \u221a 0.125cos(\u03b81\u2212\u03b82)) (53)\nThe normalization factor \u03b1 is computed by summing the results when G2 = Play and G2 = Not Play, that is, summing Equation 52 with Equation 53:\n\u03b1 = 1\n0.5+2 \u221a 0.17 \u221a 0.125cos(\u03b81\u2212\u03b82)+2 \u221a 0.08 \u221a 0.125cos(\u03b81\u2212\u03b82) = 1 0.5+0.4915cos(\u03b81\u2212\u03b82)\nThen, the normalized results are given by:\nG200 = 0.2950+2\n\u221a 0.17 \u221a\n0.125cos(\u03b81\u2212\u03b82) 0.5+0.4915cos(\u03b81\u2212\u03b82)\n(54)\nG211 = 0.2050+2\n\u221a 0.08 \u221a\n0.125cos(\u03b81\u2212\u03b82) 0.5+0.4915cos(\u03b81\u2212\u03b82)\n(55)\nThe aim of this quantum interference Bayesian Network is to simulate the averaged results reported in Table 1. More specifically, we are interested in simulating the value corresponding to the probability of the participant playing the second gamble, given that (s)he does not know the outcome of the first one. In Table 1, this value corresponds to 0.42 and cannot be obtained through classical probability theory, since the law of total probability is violated. In our model, we can tune the angle \u03b8 of the interference term in order to obtain such results. Calculations showed that in order to achieve a probability of 42%, cos(\u03b8) must be equal to \u22120.998853, which corresponds to an angle of 177.3\u25e6 or 3.09 radians.\nG200 = 0.2950+2\n\u221a 0.17 \u221a\n0.125cos(3.09) 0.5+0.4915cos(3.09) = 0.42 (56)\nG211 = 0.2050+2\n\u221a 0.08 \u221a\n0.125cos(3.09) 0.5+0.4915cos(3.09) = 0.58 (57)\nThis section described the application of the proposed quantum interference Bayesian Network to explain the puzzling findings in the two-stage gambling game, that could not be explained through classical probability theory. Equations 56 and 57 showed that the proposed approach is able to simulate the human decisions observed in the works of [71, 65, 50, 51]."}, {"heading": "6.3 The Impact of the Phase \u03b8", "text": "The interference term that we show in this paper for the two-stage gambling game, was proposed by cognitive psychologists in order to explain their observations. That is, they manually tuned this parameter \u03b8 to fit their data. In this work, we look at this parameter from a different perspective: what happens to the quantum computed probabilities if we vary this angle \u03b8? Can better inferences be achieved? In this section, we make use of the probabilistic interference term proposed in the cognitive psychology literature [61, 22], and investigate the impact that the phase parameter \u03b8 can have,when computing quantum probabilities in the two step gambling game.\nIn the previous section, the general probability formula of a player willing to play the second gamble, given that the outcome of the first gamble was unknown, was given by Equation 54. In order to analyze the consequences of the angle \u03b8 in the final probability, we varied \u03b8 from 0 to 2\u03c0 in steps of 0.0001 radians. The results obtained are discriminated in Figure 15.\nFigure 15: The various quantum probability values that can be achieved by variying the angle \u03b8 in Equation 54. Note that quantum probability can achieve much higher/lower values than\nthe classical probability.\nFigure 15 reveals that quantum probabilities can achieve much higher values than the classical probability theory. The quantum probability can reach a maximum of 0.5915 where the classical probability can only have a fixed value of 0.59.\nFigure 15 is also supporting the quantum information processing theory already mentioned in Section 1 of this work: information is modeled via wave functions and therefore, they cannot be in a definite state (only when a final decision is made, a definite state emerges). One can look at all values that this parameter \u03b8 as all possible probabilities (or outcomes) that a player has when deciding to whether or not to play the second gamble. Since in quantum theory\nwe model the participant\u2019s beliefs by wave functions, then the superposed states can produce different waves coming from opposite directions that can crash into each other. When they crash, the waves can either unite or be destroyed. When they unite, it causes a constructive interference effect that will cause a bigger wave, leading to a maximum or minimum quantum probability value, depending on the phase of the wave (Figure 16). When the waves crash and are destroyed, then a destructive interference effect occurs (Figure 17).\nIn conclusion, quantum probability enables the free choice of parameters in order to obtain a desired probability value. The two-stage gambling game is just a small example where the proposed model could be applied. In the next section, we turn to the task of burglary detection. We will analyse a more complex Bayesian Network that will determine the probability of a burglary occurring, given that the neighbours think that they heard an alarm."}, {"heading": "7 Inference in More Complex Networks: The Burglar/Alarm", "text": "Network\nIn this section, we compare classical inferences in Bayesian Networks with the proposed quantum model. The example that we will examine correspond to a modified version of the Burglar/Alarm network, which is very used in the scope of Artificial Intelligence [59, 63].\nThe network proposed in the book of [63] is inspired in the following scenario. Imagine that a person installed a new burglar alarm in his house. The alarm has a big credibility in what concerns detecting burglaries. The person has two neighbours: Mary and John. They have promised to call the person, whenever they think they heard the alarm. John always calls the police, when he hears the alarm, however, he sometimes confuses the sound of the alarm with the ringtone of his phone, resulting in a misleading phone call to the police. Mary, on the other hand, cannot hear the alarm very often, because she likes to hear very loud music. Given the evidence of who has or has not called the police, we want to represent in a Bayesian Network the probability of a burglary occurring [63].\nFigure 18 represents a classical Bayesian Network to account for burglary detection. It\u2019s quantum counterpart corresponds to Figure 19. In order to make a fair comparison between both networks, the quantum Bayesian Network was built in the same way as the classical one,\nbut we replaced the real probability values by quantum complex amplitudes, just like proposed in [68] and [53].\nFigure 18: Burglar/Alarm classical Bayesian Network proposed in the book of [63]\nFigure 19: Quantum counterpart of the Burglar/Alarm Bayesian Network proposed in the book of [63]\nWe also performed a set of queries so we could compare the classical Bayesian Network with the proposed quantum interference Bayesian Network. Table 3 presents the final probabilities computed over the classical Bayesian Network of Figure 18 and Table 4 presents the results for the quantum Bayesian network (Figure 19).\nIn the experiment of the two-stage gambling game, we saw that the parameter \u03b8 plays an important role in determining the final probability value of a variable. For the Burglar/Alarm Bayesian Network, in order to find the best parameter for each query, we varied \u03b8 between 0 and 2\u03c0 , in steps of 0.1 radians, and collected the \u03b8 that would maximize most variables in the network. Equation 58 represents the interference formula that we used to maximize the probability with respect to parameter \u03b8 .\nPr(A) = argmax\u03b8 \u03b1\n[ N\n\u2211 i=1 |\u03c8i|2 +2\nN\u22121\n\u2211 i=1\nN\n\u2211 j=i+1 |\u03c8i||\u03c8 j|cos(\u03b8i\u2212\u03b8 j)\n] (58)\nIn the next section, we will analyse the results specified in Tables 3 and 4 for each single query."}, {"heading": "8 Discussion of Experimental Results", "text": "Tables 3 and 4 present the results obtained for different queries performed over the classical Bayesian Network (Figure 18) and the proposed quantum interference Bayesian Network (Figure 19), respectively.\nAnalysing the first row of both tables, when we provide no piece of evidence to the network, the proposed model was able to increase, on average, the probabilities of the query variables about 270.625%. In the case where nothing is observed, the proposed network achieves its maximum level of uncertainty: all variables are interfering with each other causing both destructive and constructive interference effects on the final probabilities. It is interesting to notice that when the classical probabilities computed for each query variable are very low, then the quantum Bayesian Network cannot greatly increase these probabilities. If the probabilities in a classical setting are very low, then the quantum Network is able to keep those probabilities low as well.\nFigures 20-23 illustrate all possible values that each query variable could have, by varying the \u03b8 parameters. These graphs were plotted in the following way: for each query, we found the set of all \u03b8 \u2019s that would lead to a maximum and a minimum probability value. We then compared the set of \u03b8 \u2019s and realised that in the majority of the cases there were components that shared the same parameters. Given this situation, we fixed 6 of the parameters which were common and varied the remaining parameters, leading to a 3-dimensional graph.\nThe moment we start to provide pieces of evidence to the network, the uncertainty starts to decrease. Analyzing the situation where we observe that the Alarm variable is true, then an interesting phenomena occurs: the probabilities of the proposed quantum Bayesian Network collapse to the same probability values as in its classical counterpart. If one observes the variable Alarm, then the variables Burglar, MaryCalls and JohnCalls become independent of each other. This means that there is no possible way that these variables can interfere with each other. Since the variables do not provoke any interferences among them, then the interference term will be zero and will collapse to the classical probability. This independence phenomena\nin quantum Bayesian Networks has also been noticed in the work of [53]. For a mathematical proof of why this phenomena also occurs in a quantum setting, please refer to their work. This means that, whenever we observe the variable Alarm, the interference term will always be null and consequently all probabilities will be exactly the same as in a classical Bayesian Network inference.\nIn the case where we observe the Burglar variable, then, according to the scenario of the Bayesian Network, the Alarm variable should also increase. The variable JohnCalls is highly correlated with the variable Alarm. In its conditional probability table, there is a chance of 90% of the variable JohnCalls occurring when the variable Alarm is true. So in this situation, the quantum Bayesian Network is able to give more strength to that correlation. On average, the probabilities of all queries increased 22.8% when the variable Burglar is observed, when compared to the respective classical setting.\nWhen we observe that the variable JohnCalls is true, then it is expected that the probability of the Alarm variable increases as well, according to the scenario of the Bayesian Network. When we observe the variable MaryCalls the variable Alarm increases even more when com-\npared to the situation where JohnCalls = t or its classical counterpart. This means that the correlation between the Alarm variable and the variable JohnCalls is not as strong as when we observe MaryCalls. According to the scenario, John always calls the police, leading to many misleading calls. Consequently, the Alarm variable cannot be increased too much. However, when MaryCalls is observed, then, according to the Bayesian scenario, it is almost certain that she heard the alarm and therefore, a strict correlation exists between these two variables. The quantum Bayesian Network was able to represent the correlations between variables in a more realistic and reliable way than its classical counterpart.\nFinally, when we start to provide 2 pieces of evidence to the network, then the uncertainty levels start to decrease. Consequently, the probabilities computed in a quantum setting start to converge to the ones computed in a classical Bayesian Network. This means that, there are two situations there the proposed quantum Bayesian Network converges to its classical counterpart: (1) when the variables of the network become independent of each other and (2) when there are very low levels of uncertainty, because too many evidences were provided to the network."}, {"heading": "9 The Optimum Value for \u03b8 to Maximize Quantum Infer-", "text": "ences in Bayesian Networks\nIn this section, we perform a study on the impact of the \u03b8 parameters in the context of medical decision making. Consider the Classical Bayesian Network of Figure 24, which corresponds to a slightly modified version of the Bayesian Network proposed in the book of [59]. Figure 25 corresponds to its quantum counterpart.\nAgain, in order to determine the maximum probability value, we varied the \u03b8 parameters between 0 and 2\u03c0 in steps of 0.1 radians. The method that we used to compute these parameters in described in Appendix A. We then performed the following queries: Pr( Smoke = true ), Pr( Dyspnea = true ), Pr( Cough = high ) and Pr( Lung Cancer = positive ). The results obtained are discriminated in Figure 26.\nAnalysing Figure 26, one can observe that again, the quantum probability values tend to overcome their classical counterparts. A special note goes to the quantum probabilities verified for the query Pr( Cancer = positive ). The increase verified in this probability was much higher\nthan any other value achieved by the other quantum probabilities. Since the Lung Cancer random variable is located at the centered position of the Bayesian Network, then, when nothing is observed, its probability is influenced by the probabilities of all nodes in the network.\nIn order to determine the impact of the \u03b8 parameters, Table 5 shows the parameters that were used in the Burglar/Alarm and Lung Cancer Bayesian Networks.\nFigures 27-30 also show all the possible probability values that the variables from the lung cancer Bayesian network can achieve, when nothing is known.\nWhen we are at a maximum level of uncertainty, classical probabilities tend to assume that events are equiprobable, that is, the probability of their outcome is always the same no matter their context. Quantum theory, on the other hand, provides a more relaxed framework. When nothing is known, then there are more degrees of freedom that enable the outcome of any event to be any possible value. This way, by analysing the context of certain events (for example, a medical decision scenario, a gambling game, etc), the quantum parameters \u03b8 can be modelled in such a way that they can simulate reality more accurately and more precisely than its classical counterpart.\nIn this sense, in order to develop more accurate quantum Bayesian Networks, a study of the context of the problem is required in order to start the search for the optimum \u03b8 parameters.\nTechniques to search for these optimum quantum parameters is still an open research question and an unexplored field in the literature of quantum cognition and quantum decision models."}, {"heading": "10 Related Work", "text": "Since the preliminary findings of [69], cognitive scientists began to use alternative theories, such as quantum probability theory, in an attempt to explain the paradoxical findings that classical probability theory could not explain. Given the flexibility of the quantum probabilistic framework, several researchers applied these concepts in several fields outside of physics. In this section, we present some of the topics in which quantum probability has made some impacts in the literature."}, {"heading": "10.1 Violations of Probability Theory", "text": "In what concerns violations of probability theory, there are many paradoxical situations where classical probability is unable to model. The most important paradoxes consist in violations in\nthe Sure Thing principle. Examples of such violations correspond to the Ellsberg paradox [32], the two-stage gambling game [71, 50, 51] and the prisoner\u2019s dilemma game [71, 26, 54, 18, 41, 25].\nIn what concerns the prisoner\u2019s dilemma game, many works in the literature have been proposed, which formalise the problem in a quantum approach. For instance, [61] proposed a quantum dynamic Markov Model for the prisoner\u2019s dilemma game. In their model, the authors represented the players beliefs and actions as a superposition in a quantum state vector. When the player knew the information about the opponent\u2019s action, the superposition state collapsed to a new state that was compatible with the action chosen by the opponent. When the player did not know about the opponent\u2019s move, then the system involved through the application of unitary transformations. In [15], the authors focus on irrational choices and developed a model based on the quantum superposition and interference principles for the prisoner dilemma game. After each play, the state is updated until it reaches an equilibrium. In [23], the authors analysed quantum conditional probabilities in the prisoner\u2019s dilemma game. There are also works that consider that the probabilities in the prisoner\u2019s dilemma game correspond to different contexts and these contexts can be incompatible. The authors argue that the probabilities observed in the prisoner\u2019s dilemma game were not classical, but were not quantum either in the sense of traditional quantum mechanics theory. So the author introduced the quantum-like approach and suggested a new trigonometric interference term [47, 48]. [72] proposed quantum model which incorporated entangled decisions and explained the violations of the Sure Thing principle through interference effects between intentions. In [1], the authors explored the impact of these violations in economics and analyse the two-stage gambling game and the prisoner\u2019s dilemma game under a quantum probabilistic point of view, by proposing a quantum Markov Model to explain the paradoxical observations in these games. Finally, [14] proposed a quantum bayesian updating scheme based on the formalisms of quantum mechanics that represents mental states on a Hilbert state. Through the usage of projections, they were able to introduce a model that could explain the paradoxical findings of the two-stage gambling game [71]. Another similar work that compares Bayes rule to its quantum counterpart corresponds to [20]."}, {"heading": "10.2 Conjunction and Diskunction Errors", "text": "Other situations, in which the laws of probability are being violated, correspond to disjunction or conjunction fallacies. A conjunction error occurs when it is assumed that specific conditions are more probable than a single general one. A disjunction error, on the other hand, consists in assuming that the disjunction of two events is at least as likely as either of the events individually. Several works in the literature used quantum probabilistic models to address these fallacies. For instance, [34] developed a quantum probabilistic model to explain fallacies when making preferences over a set of events, more specifically, the conjunction fallacy. [19] also focused on quantum models to explain conjunction and [26] focused on disjunction fallacies. The first experiments where these fallacies were observed to occur were performed by [71]. An alternative model for conjunction and disjunction errors correspond to [70]. The authors used support theory as a subjective probabilistic model that describes the way people make probability judgments. The main problem of their model is that support theory is able to successfully describe conjunction errors, but fails at explaining disjunction errors. Other models correspond to [37, 36]. [72] also addressed the problem of conjunction and disjunction fallacies. They proposed quantum model which incorporated entangled decisions. [44] also modelled mental\nprocesses through quantum probabilities, where the interference process plays an important role in the process of recognising images[24]. Other interesting works of this author applying similar quantum formalisms correspond to [47, 46, 45, 67]."}, {"heading": "10.3 Quantum Probabilistic Graphical Models", "text": "In what concerns quantum probabilistic graphical models, there are various contributions. For example, in [68] the model proposed by the author is exactly the same as a classical Bayesian Network. The only difference is that it uses complex numbers in the conditional probability tables instead of real values. A similar model has been proposed by [57], but for Markov Networks. In [53], the author proposed a quantum Bayesian Network by replacing the classical formulas used to perform the inference process by their quantum counterpart. [22], [18] and [21] proposed a quantum dynamic Markov model based on the findings of cognitive psychologists and interference terms."}, {"heading": "10.4 General Applications of Quantum Probabilities", "text": "One of the first and most influential models that applied quantum probability for decision making belongs to [3]. In their work, the authors proposed the \u03b5-model, which can be defined as a quantum machine that corresponds to a two dimensional Hilbert space. Given an event in this quantum machine one can compute quantum like probabilities. The model also makes use of a parameter \u03b5 that measures the total amount of uncertainty when computing the probabilities. Other works related to this model can be found in [8, 9, 7, 2, 10, 11, 2, 12, 13, 35, 4].\n[14] proposed a quantum bayesian updating scheme based on the formalisms of quantum mechanics that represents mental states on a Hilbert state. Through the usage of projections, they were able to introduce a model that could explain the paradoxical findings of the two-stage gambling game [71]. Another similar work that compares Bayes rule to its quantum counterpart corresponds to [20].\nThere is also an increasing interest in applying quantum like models to subjects outside of psychology. In game theory there have been works exploring the uncertainties of a player towards another through quantum probabilistic models. For instance, [15] focus on irrational choices and developed a model based on the quantum superposition and interference principles for the Prisoner Dilemma game. After each play, the state is updated until it reaches an equilibrium. [23] used the data collected by [71] and analysed quantum conditional probabilities. [56] generalised the classical expected utility and proposed a quantum projective expected utility function that does not violate the laws of classical probability theory and can accommodate Allais and Ellsberg paradoxes. [27] made a formalisation of the structure of quantum probability theory and [28] also applied these formalists to expected utilities. [60] applied quantum theory to the fields of economics and game theory and developed a principle to minimise financial risks [6] modelled how a person updates its beliefs in the liar\u2019s paradox. [44] also modelled mental processes through quantum probabilities, where the interference process plays an important role in the process of recognising images[24]. Other interesting works of this author applying similar quantum formalisms correspond to [47, 48, 46, 45, 42, 39]. [52] developed a quantum mechanics based framework in order to model agents preferences under uncertainty.\nMore recently, [62] published a work that generated discussions over the scientific literature, about whether or not, quantum probability can provide a new direction to compute quan-\ntum probabilistic inferences. In their work, they summarised the main areas where quantum probability has made some impact (conjunction/disjunction errors, sure thing principle, etc). A deep analysis of the differences between classical and quantum probability is also made in this work.\n[5] also shares a similar opinion that quantum probability can, in fact, provide a new framework to explain several situations in which the laws of probability are violated. However, they defend that the usage of quantum probability should be more close to its real meaning in quantum mechanics and proposes to explain the phenomena, such as contextually, entanglement, observables and Flock spaces.\nThe work of, [62] has stimulated some discussions on the implications of quantum probability in functional brain networks. For instance, [66] have discussed the similarities between the vector representations of quantum states with a vector symbolic architecture, which is used to model realistic biological neural models. In this sense, biological neural models can also incorporate the quantum probabilistic framework and also introduce quantum interference effects, as a mathematical and geometric alternative framework, without taking into account the true meaning that is given these effects under quantum physics. Other authors also support this idea of representing neuronal model using the quantum probabilistic framework [16, 38, 30, 29]."}, {"heading": "11 Conclusions", "text": "This work was motivated by the preliminary experiments of [71] about violations of the classical probability theory on the sure thing principle. This principle states that if one chooses action A over B in a state of the world X , and if one also chooses action A over B under the complementary state of the world X , then one should always choose action A over B, even when the state of the world in unspecified. When humans need to make decisions under risk, several heuristics are used, since humans cannot process large amounts of data. These decisions coupled with heuristics lead to violations on the law of total probability.\nRecent work in cognitive psychology revealed that quantum probability theory provides another method of computing probabilities without falling into the restrictions that classical probability have in modelling cognitive systems of decision making. Quantum probability theory can also be seen as a generalisation of classical probability theory, since it also includes the classical probabilities as a special case (when the interference term is zero).\nThe main difference between quantum and classical probability lies in the fact that on quantum probability we are constantly updating some beliefs when making a decision, while in classical probability all beliefs are assumed to have a definite value before a decision is made, and this value is the outcome of the decision [3].\nThe main research question for this work was how could these quantum probabilities affect probabilistic graphical models, such as Bayesian Networks, since many of nowadays decision making systems are based on such structures (medical diagnosis, spam filtering, image segmentation, etc).\nIn this work, we proposed a novel Bayesian Network for the Computer Science community based on quantum probabilities. Our method can accommodate puzzling observations that the classical probability failed to explain (for instance, the two-step gambling game). When the nodes of the proposed Bayesian Network are represented as a superposition state, then one can look at this state as many waves moving across in different directions. These waves can crash\ninto each other causing waves to be bigger or to cancel each other. This is the interference phenomena that the proposed Bayesian Network offers and that has direct implications when making inferences. Therefore, the proposed network represents and simulates quantum aspects motivated by Feynman\u2019s path integrals.\nExperimental results revealed that the proposed quantum Bayesian Network enables many degrees of freedom in choosing the final outcome of the probabilities. If we had a real scenario, with real observations, one could use the present model to fit it to the observed data, by simply tuning the parameter \u03b8 . This parameter can open a door into machine learning approaches. Learning algorithms using the proposed method might produce better prediction models, since the quantum probability amplitudes are able to fully represent real word data. For future work, we intend to explore machine learning algorithms under quantum probabilistic graphical model formalisms.\nThe overall results also suggested that when the classical probability of some variable is already high, then the quantum probability tends to increase it even more. When the classical probability is very low, then the proposed model tends to lower it.\nWhen there are many unobserved nodes in the network then the levels of uncertainty are very high. But, in the opposite scenario, when there are very few unobserved nodes, then the proposed quantum model tends to collapse into its classical counterpart, since the uncertainty levels are very low.\nThe proposed Bayesian Network can integrate human thoughts by representing a person\u2019s beliefs in an N-dimensional unit length quantum state vector. In the same way, the proposed quantum structure is general enough to represent any other context in which there is a need to formalise uncertainty, including prediction problems in data fusion. In the context of Bayesian Networks, data fusion is introduced in the work of [58]. The author argues that, just like people, Bayesian Networks are structures that integrate data from multiple sources of evidence and enable the generation of a coherent interpretation of that data through a reasoning process. The fusion of all these multiple data sources can be done using Bayes theorem. When a data source is unknown, then the Bayes rule is extended in order to sum out all possible values of the probability distribution representing the unknown data source. The proposed Quantum Bayesian Network takes advantage of these uncertainties by representing them in a superposition state, which enables the fusion of the data sources through quantum interference effects. These effects produce changes in the final likelihoods of the outcomes and provide a promising way to perform predictions more accurately according to reality. So, the Quantum Bayesian Network that is proposed in this work is potentially relevant and applicable in any behavioural situation in which uncertainty is involved."}, {"heading": "A A Grid Search Approach to Find Quantum Parameters", "text": "The most naive approach of parameter search is the grid search method. In this approach, it is placed a grid over the parameter space and the data is evaluated at every grid intersection, returning the parameters, which lead to the maximum performance of an algorithm [55]. However, grid search has the problem of being unbounded, since an infinite set of parameters are available to be tested. In the scope of this work, this is not a problem, because we always have a boundary. The values of a cosine function can all be specified for angles between the range [0,2\u03c0].\nThe grid search approach is a very naive method for finding parameters in the parameter space. In fact, there are several advanced parameter search algorithms in the literature, which do not have a heavy computational cost. The motivation behind the usage of the grid search approach in this work is that the computational time required by any of the other advanced methods is almost the same as using grid search. In addition, many of the advanced search parameter methods in the literature perform approximations, which can be avoided by the direct parameter search of the grid search approach [55].\nAlgorithm 1 Grid Search to find \u03b8 parameters Require: classical probability when it is true ( Pr(A = t ) ), Pr Ct,\ninterference term correspondent to Pr Ct, Inter f erence t, classical probability when it is true ( Pr(A = f ) ), Pr C f , interference term correspondent to Pr C f ,Inter f erence f ,\nEnsure: Maximum quantum probabilities, List of \u03b8 parameters that maximise the quantum probability\n1: max probability\u2190\u22121 // initialise variable that will store the maximum probability found\n2: list parameters\u2190 empty // initialise variable that will store all theta parameters that maximise the probability\n3: // Create a for-cycle for each quantum parameter necessary to compute the probability 4: for \u03b81 = 0;\u03b81 \u2264 2\u03c0;\u03b81 = \u03b81 +0.01 do 5: for \u03b82 = 0;\u03b82 \u2264 2\u03c0;\u03b82 = \u03b82 +0.01 do 6: ... // Add other for-cycles to compute the other \u03b8 parameters\n7: Pr positive\u2190 Pr Ct + Interference t, \u00b7 cos(\u03b81\u2212\u03b82); 8: Pr negative\u2190 Pr Cf + Interference f, \u00b7 cos(\u03b81\u2212\u03b82);\n9: Pr positive norm\u2190 Pr positive / ( Pr positive + Pr negative ); 10: Pr negative norm\u2190 Pr negative / ( Pr positive + Pr negative );\n11: if Pr positive norm > max probability then 12: max probability\u2190 Pr positive norm; 13: list parameters\u2190 [\u03b81, \u03b82]; 14: end if\n15: end for 16: end for\n17: return max probability , list parameters;"}], "references": [{"title": "Quantum markov model for data from shafir-tversky experiments in cognitive psychology", "author": ["Luigi Accardi", "Andrei Khrennikov", "Masanori Ohya"], "venue": "Journal of Open Systems and Information Dynamics,", "citeRegEx": "1", "shortCiteRegEx": "1", "year": 2009}, {"title": "Quantum structures: An attempt to explain the origin of their appearence in nature", "author": ["Diederik Aerts"], "venue": "International Journal of Theoretical Physics,", "citeRegEx": "2", "shortCiteRegEx": "2", "year": 1995}, {"title": "Quantum structure in cognition", "author": ["Diederik Aerts"], "venue": "Journal of Mathematical Psychology,", "citeRegEx": "3", "shortCiteRegEx": "3", "year": 2009}, {"title": "A case for applying an abstracted quantum formalism to cognition", "author": ["Diederik Aerts", "Jan Broekaert", "Liane Gabora"], "venue": "Journal of New Ideas in Psychology,", "citeRegEx": "4", "shortCiteRegEx": "4", "year": 2011}, {"title": "Quantum structure and human thought", "author": ["Diederik Aerts", "Jan Broekaert", "Liane Gabora", "Sandro Sozzo"], "venue": "Journal of Brain and Behavioral Sciences,", "citeRegEx": "5", "shortCiteRegEx": "5", "year": 2013}, {"title": "A quantum structure description of the liar paradox", "author": ["Diederik Aerts", "Jan Broekaert", "Sonja Smets"], "venue": "International Journal of Theoretical Physics,", "citeRegEx": "6", "shortCiteRegEx": "6", "year": 2004}, {"title": "Quantum, classical and intermediate, an illustrative example", "author": ["Diederik Aerts", "Thomas Durt"], "venue": "Foundations of Physics,", "citeRegEx": "7", "shortCiteRegEx": "7", "year": 1994}, {"title": "A physical example of quantum fuzzy sets and the classical limit", "author": ["Diederik Aerts", "Thomas Durt", "Bruno Van Bogaert"], "venue": "Tatra Mountains Mathematical Publications,", "citeRegEx": "8", "shortCiteRegEx": "8", "year": 1993}, {"title": "Quantum probability, the classical limit and nonlocality", "author": ["Diederik Aerts", "Thomas Durt", "Bruno Van Bogaert"], "venue": "In Proceedings of the International Symposium on the Foundations of Modern Physics,", "citeRegEx": "9", "shortCiteRegEx": "9", "year": 1993}, {"title": "A theory of concepts and their combinations i: The structure of the sets of contexts and properties", "author": ["Diederik Aerts", "Liane Gabora"], "venue": "Journal of Kybernetes,", "citeRegEx": "10", "shortCiteRegEx": "10", "year": 2005}, {"title": "A theory of concepts and their combinations ii: A hilbert space representation", "author": ["Diederik Aerts", "Liane Gabora"], "venue": "Journal of Kybernetes,", "citeRegEx": "11", "shortCiteRegEx": "11", "year": 2005}, {"title": "Conditinal probabilities with a quantal and kolmogorovian limit", "author": ["Sven Aerts"], "venue": "International Journal of Theoretical Physics,", "citeRegEx": "12", "shortCiteRegEx": "12", "year": 1996}, {"title": "Interactive probability models: Inverse problems on the sphere", "author": ["Sven Aerts"], "venue": "International Journal of Theoretical Physics,", "citeRegEx": "13", "shortCiteRegEx": "13", "year": 1998}, {"title": "Quantum-like generalization of the bayesian updating scheme for objective and subjective mental uncertainties", "author": ["Masanari Asano", "Irina Basieva", "Andrei Khrennikov", "Masanori Ohya", "Yoshiharu Tanaka"], "venue": "Journal of Mathematical Psychology,", "citeRegEx": "14", "shortCiteRegEx": "14", "year": 2012}, {"title": "Quantum-like model for decision making process in two players game, a non-kolmogorovian model", "author": ["Masanari Asano", "Masanori Ohya", "Andrei Khrennikov"], "venue": "Journal of Foundations of Physics,", "citeRegEx": "15", "shortCiteRegEx": "15", "year": 2010}, {"title": "Can quantum probability help analyze the behaviour of functional brain networks", "author": ["Arpan Banerjee", "Barry Horwitz"], "venue": "Journal of Behavioral and,", "citeRegEx": "16", "shortCiteRegEx": "16", "year": 2013}, {"title": "Quantum Model of Cognition and Decision", "author": ["Jerome Busemeyer", "Peter Bruza"], "venue": null, "citeRegEx": "17", "shortCiteRegEx": "17", "year": 2012}, {"title": "A quantum information processing explanation of disjunction effects", "author": ["Jerome Busemeyer", "Marvin Matthew", "Zheng Wang"], "venue": "In Proceedings of the 28th Annual COnference of the Cognitive Science Society,", "citeRegEx": "18", "shortCiteRegEx": "18", "year": 2006}, {"title": "A quantum theoretical explanation for probability judgment errors", "author": ["Jerome Busemeyer", "Emmanuel Pothos", "Riccardo Franco", "Jennifer Trueblood"], "venue": "Journal of Psychology Review,", "citeRegEx": "19", "shortCiteRegEx": "19", "year": 2011}, {"title": "Comparison of quantum and bayesian inference models", "author": ["Jerome Busemeyer", "Jennifer Trueblood"], "venue": "In Proceedings of the 3rd International Symposium on QUantum Interaction,", "citeRegEx": "20", "shortCiteRegEx": "20", "year": 2009}, {"title": "Empirical comparison of markov and quantum models of decision making", "author": ["Jerome Busemeyer", "Zheng Wang", "Ariane Lambert-Mogiliansky"], "venue": "Journal of Mathematical Psychology,", "citeRegEx": "21", "shortCiteRegEx": "21", "year": 2009}, {"title": "Quantum dynamics of human decision making", "author": ["Jerome Busemeyer", "Zheng Wang", "James Townsend"], "venue": "Journal of Mathematical Psychology,", "citeRegEx": "22", "shortCiteRegEx": "22", "year": 2006}, {"title": "Interference and inequality in quantum decision theory", "author": ["Taksu Cheon", "Taiki Tahahashi"], "venue": "Journal of Physics Letters A,", "citeRegEx": "23", "shortCiteRegEx": "23", "year": 2010}, {"title": "Mental states follow quantum mechanics during perception and cognition of ambiguous figures", "author": ["Elio Conte", "Andrei Khrennikov", "Orlando Todarello", "Antonio Federici", "Leonardo Mendolicchio", "Joseph Zbilut"], "venue": "Journal of Open Systems and Information Dynamics,", "citeRegEx": "24", "shortCiteRegEx": "24", "year": 2009}, {"title": "Some remarks on an experiment suggesting quantum like behavior of cognitive entities and formulation of an abstract quantum mechanical formalism to describe cognitive entity and its dynamics", "author": ["Elio Conte", "Orlando Todarello", "Antonio Federici", "Francesco Vitiello", "Michele Lopane", "Andrei Khrennikov", "Joseph Zbilut"], "venue": "Journal of Chaos, Solitons and Fractals,", "citeRegEx": "25", "shortCiteRegEx": "25", "year": 2007}, {"title": "The disjunction effect and reason-based choice in games", "author": ["Ratchel Croson"], "venue": "Journal of Organizational and Human Decision Processes,", "citeRegEx": "26", "shortCiteRegEx": "26", "year": 1999}, {"title": "Measurable systems and behavioral sciences", "author": ["Vladimir Danilov", "Ariane Lambert-Mogiliansky"], "venue": "Journal of Mathematical Social Sciences,", "citeRegEx": "27", "shortCiteRegEx": "27", "year": 2008}, {"title": "Expected utility theory under nonclassical uncertainty", "author": ["Vladimir Danilov", "Ariane Lambert-Mogiliansky"], "venue": "Journal of Theory and Decision,", "citeRegEx": "28", "shortCiteRegEx": "28", "year": 2010}, {"title": "Quantum-like model of behavioral response computation using neural oscillators", "author": ["Jos\u00e9 Acacio de Barros"], "venue": "Journal of BioSystems,", "citeRegEx": "29", "shortCiteRegEx": "29", "year": 2012}, {"title": "Quantum mechanics, interference, and the brain", "author": ["Jose Acacio de Barros", "Patrick Suppes"], "venue": "Journal of Mathematical Psychology,", "citeRegEx": "30", "shortCiteRegEx": "30", "year": 2009}, {"title": "Probability and Statistics", "author": ["Morris DeGroot", "Mark Schervish"], "venue": "Pearson Education (4th Edition),", "citeRegEx": "31", "shortCiteRegEx": "31", "year": 2011}, {"title": "Risk, ambiguity and the savage axioms", "author": ["Daniel Ellsberg"], "venue": "Quaterly Journal of Economics,", "citeRegEx": "32", "shortCiteRegEx": "32", "year": 1961}, {"title": "The conjunction fallacy and interference effects", "author": ["Riccardo Franco"], "venue": "Journal of Mathematical Psychology,", "citeRegEx": "34", "shortCiteRegEx": "34", "year": 2009}, {"title": "Contextualizing concepts using a mathematical generalization of the quantum formalism", "author": ["Liane Gabora", "Diederik Aerts"], "venue": "Journal of Experimental & Theoretical Artificial Intelligence,", "citeRegEx": "35", "shortCiteRegEx": "35", "year": 2002}, {"title": "Reasoning the fast and frugal way: Models of bounded rationality", "author": ["Gerd Gigerenzer", "Daniel G. Goldstein"], "venue": "Journal of Psychological Review,", "citeRegEx": "36", "shortCiteRegEx": "36", "year": 1996}, {"title": "How to improve bayesian reasoning without instruction: Frequency formats", "author": ["Gerd Gigerenzer", "Ulrich Hoffrage"], "venue": "Journal of Psychological Review,", "citeRegEx": "37", "shortCiteRegEx": "37", "year": 1995}, {"title": "How quantum brain biology can rescue conscious free will", "author": ["Stuart Hameroff"], "venue": "Journal of Frontiers in Integrative Neuroscience,", "citeRegEx": "38", "shortCiteRegEx": "38", "year": 2012}, {"title": "Quantum Social Science", "author": ["Emmanuel Haven", "Andrei Khrennikov"], "venue": null, "citeRegEx": "39", "shortCiteRegEx": "39", "year": 2013}, {"title": "Quantum Computing (Second Edition)", "author": ["Mika Hirvensalo"], "venue": null, "citeRegEx": "40", "shortCiteRegEx": "40", "year": 2003}, {"title": "Disjunction effect in prisonner\u2019s dilemma: Evidences from an eye-tracking study", "author": ["Evgenia Hristova", "Maurice Grinberg"], "venue": "In Proceedings of the 30th Annual Conference of the Cognitive Science Society,", "citeRegEx": "41", "shortCiteRegEx": "41", "year": 2008}, {"title": "Classical and quantum mechanics on information spaces with applications to cognitive psychological, social and anomalous phenomena", "author": ["Andrei Khrennikov"], "venue": "Foundations of Physics,", "citeRegEx": "42", "shortCiteRegEx": "42", "year": 1999}, {"title": "Interference of probabilities in the classical probabilistic framework", "author": ["Andrei Khrennikov"], "venue": "Journal of Fuzzy Sets and Systems,", "citeRegEx": "43", "shortCiteRegEx": "43", "year": 2005}, {"title": "Quantum-like brain: Interference of minds", "author": ["Andrei Khrennikov"], "venue": "Journal of BioSystems,", "citeRegEx": "44", "shortCiteRegEx": "44", "year": 2006}, {"title": "Can quantum information be processed by macroscopic systems", "author": ["Andrei Khrennikov"], "venue": "Quantum Information Processing,", "citeRegEx": "45", "shortCiteRegEx": "45", "year": 2007}, {"title": "Description of composite quantum systems by means of classical random fields", "author": ["Andrei Khrennikov"], "venue": "Foundations of Physics,", "citeRegEx": "46", "shortCiteRegEx": "46", "year": 2009}, {"title": "Quantum-like model of cognitive decision making and information processing", "author": ["Andrei Khrennikov"], "venue": "Journal of BioSystems,", "citeRegEx": "47", "shortCiteRegEx": "47", "year": 2009}, {"title": "Quantum mechanics and violations of the sure-thing principle: The use of probability interference and other concepts", "author": ["Andrei Khrennikov", "Emmanuel Haven"], "venue": "Journal of Mathematical Psychology,", "citeRegEx": "48", "shortCiteRegEx": "48", "year": 2009}, {"title": "Probabilistic Graphical Models: Principles and Techniques", "author": ["Daphne Koller", "Nir Friedman"], "venue": null, "citeRegEx": "49", "shortCiteRegEx": "49", "year": 2009}, {"title": "The disjunction effect: Does it exist for two-step gambles", "author": ["Anton Kuhberger", "Dagmara Komunska", "Perner Josef"], "venue": "Organizational Behavior and Human Decision Processes,", "citeRegEx": "50", "shortCiteRegEx": "50", "year": 2001}, {"title": "The disjunction effect reexamined: Relevant methodological issues and the fallacy of unspecified percentage comparisons", "author": ["Charles Lambdin", "Charles Burdsal"], "venue": "Organizational Behavior and Human Decision Processes,", "citeRegEx": "51", "shortCiteRegEx": "51", "year": 2007}, {"title": "Type indeterminacy: A model for the kt(kahneman-tversky)-man", "author": ["Ariane Lambert-Mogiliansky", "Shmuel Zamir", "Herve Zwirn"], "venue": "Journal of Mathematics Psychology,", "citeRegEx": "52", "shortCiteRegEx": "52", "year": 2009}, {"title": "Quantum graphical models and belief propagation", "author": ["Mathew Leifer", "David Poulin"], "venue": "Annals of Physics Journal,", "citeRegEx": "53", "shortCiteRegEx": "53", "year": 2008}, {"title": "Examining whether there is a disjunction effect in prisoner\u2019s dilemma game", "author": ["Shu Li", "John Taplin"], "venue": "Chinese Journal of Psychology,", "citeRegEx": "54", "shortCiteRegEx": "54", "year": 2002}, {"title": "Linear feature-based models for information retrieval", "author": ["Donald Metzler", "W. Bruce Croft"], "venue": "Information Retrieval,", "citeRegEx": "55", "shortCiteRegEx": "55", "year": 2007}, {"title": "Projective expected utility", "author": ["Pierfrancesco La Mura"], "venue": "Journal of Mathematical Psychology,", "citeRegEx": "56", "shortCiteRegEx": "56", "year": 2009}, {"title": "Swiatczak. Markov entangled networks", "author": ["Pierfrancesco La Mura", "Lukasz"], "venue": "Technical report, AAAI Spring Symposium,", "citeRegEx": "57", "shortCiteRegEx": "57", "year": 2007}, {"title": "Fusion, propagation, and structuring in belief networks", "author": ["Judea Pearl"], "venue": "Journal of Artificial Intelligence,", "citeRegEx": "58", "shortCiteRegEx": "58", "year": 1986}, {"title": "Probabilistic Reasoning in Intelligent Systems: Networks of Plausible Inference", "author": ["Judea Pearl"], "venue": null, "citeRegEx": "59", "shortCiteRegEx": "59", "year": 1988}, {"title": "Quantum-like approach to financial risk: Quantum anthropic principle", "author": ["Edward Piotrowski"], "venue": "Acta Physica Polonica B,", "citeRegEx": "60", "shortCiteRegEx": "60", "year": 2001}, {"title": "A quantum probability explanation for violations of rational decision theory", "author": ["Emmanuel Pothos", "Jerome Busemeyer"], "venue": "Proceedings of the Royal Society B,", "citeRegEx": "61", "shortCiteRegEx": "61", "year": 2009}, {"title": "Can quantum probability provide a new direction for cognitive modeling", "author": ["Emmanuel Pothos", "Jerome Busemeyer"], "venue": "Journal of Brain and Behavioral Science,", "citeRegEx": "62", "shortCiteRegEx": "62", "year": 2013}, {"title": "Artificial Intelligence: A Modern Approach", "author": ["Sturat Russel", "Peter Norvig"], "venue": "Pearson Education (3rd Edition),", "citeRegEx": "63", "shortCiteRegEx": "63", "year": 2010}, {"title": "The Foundations of Statistics", "author": ["Leonard Savage"], "venue": "John Wiley,", "citeRegEx": "64", "shortCiteRegEx": "64", "year": 1954}, {"title": "Thinking through uncertainty: nonconsequential reasoning and choice", "author": ["Eldar Shafir", "Amos Tversky"], "venue": "Cognitive Psychology,", "citeRegEx": "65", "shortCiteRegEx": "65", "year": 1992}, {"title": "Realistic neurons can compute the operations needed by quantum probability theory and other vector symbolic architectures", "author": ["Terrence Stewart", "Chris Eliasmith"], "venue": "Journal of Brain and Behavioral Science,", "citeRegEx": "66", "shortCiteRegEx": "66", "year": 2013}, {"title": "On the determinants of the conjunction fallacy: Confirmation versus probability", "author": ["Katya Tentori", "Vincenzo Crupi", "Selena Russo"], "venue": "Journal of Experimental Psychology: General,", "citeRegEx": "67", "shortCiteRegEx": "67", "year": 2013}, {"title": "Quantum bayesian nets", "author": ["Robert Tucci"], "venue": "International Journal of Modern Physics B,", "citeRegEx": "68", "shortCiteRegEx": "68", "year": 1995}, {"title": "Judgment under uncertainty: Heuristics and biases", "author": ["Amos Tversky", "Daniel Kahnenman"], "venue": "Science, 185:1124\u20131131,", "citeRegEx": "69", "shortCiteRegEx": "69", "year": 1974}, {"title": "Support theory: A nonextensional representation of subjective probability", "author": ["Amos Tversky", "Derek Koehler"], "venue": "Journal of Psychological Review,", "citeRegEx": "70", "shortCiteRegEx": "70", "year": 1994}, {"title": "The disjunction effect in choice under uncertainty", "author": ["Amos Tversky", "Eldar Shafir"], "venue": "Journal of Psychological Science,", "citeRegEx": "71", "shortCiteRegEx": "71", "year": 1992}], "referenceMentions": [{"referenceID": 31, "context": "[32] published a work that influenced modern psychology by showing that humans violate the laws of probability theory when making decisions under risk.", "startOffset": 0, "endOffset": 4}, {"referenceID": 62, "context": "It is a concept widely used in game theory and was originally introduced by [64].", "startOffset": 76, "endOffset": 80}, {"referenceID": 67, "context": "In their pioneering work, [69] realised that the beliefs expressed by humans could not follow the rules of Boolean logic or classical probability theory, because humans cannot process large amounts of data in order to make estimations or judgements.", "startOffset": 26, "endOffset": 30}, {"referenceID": 16, "context": "The process of human inference deterministically either jumps between definite states or stays in a single definite state across time [17].", "startOffset": 134, "endOffset": 138}, {"referenceID": 16, "context": "Thus, quantum information processing deals with both definite and indefinite states [17].", "startOffset": 84, "endOffset": 88}, {"referenceID": 69, "context": "[71] were one of the first researchers to test the veracity of Savage\u2019s principle under human cognition in a gambling game.", "startOffset": 0, "endOffset": 4}, {"referenceID": 69, "context": "The results obtained in [71] experiment showed that this principle is constantly being violated and consequently humans do not perform inferences according to the laws of probability theory and Boolean logic.", "startOffset": 24, "endOffset": 28}, {"referenceID": 69, "context": "In Tversky and Shafir\u2019s experiment [71], the probability of a participant playing the second gamble, given that the outcome of the first gamble is unknown, Pr(G|U), can be computed through the law of total probability:", "startOffset": 35, "endOffset": 39}, {"referenceID": 69, "context": "Figure 3: The two-stage gambling experiment proposed by [71]", "startOffset": 56, "endOffset": 60}, {"referenceID": 69, "context": "Literature Pr(Play Again |Won 1st Play) Pr(Play Again | Lost 1st Play) Pr(Play Again | Unknown 1st Play) [71] 69% 58% 37% [50] 72% 47% 48% [51] 63% 45% 41% Average 68% 50% 42%", "startOffset": 105, "endOffset": 109}, {"referenceID": 48, "context": "Literature Pr(Play Again |Won 1st Play) Pr(Play Again | Lost 1st Play) Pr(Play Again | Unknown 1st Play) [71] 69% 58% 37% [50] 72% 47% 48% [51] 63% 45% 41% Average 68% 50% 42%", "startOffset": 122, "endOffset": 126}, {"referenceID": 49, "context": "Literature Pr(Play Again |Won 1st Play) Pr(Play Again | Lost 1st Play) Pr(Play Again | Unknown 1st Play) [71] 69% 58% 37% [50] 72% 47% 48% [51] 63% 45% 41% Average 68% 50% 42%", "startOffset": 139, "endOffset": 143}, {"referenceID": 16, "context": "Following the law of total probability in Equation 1, the probability of playing the second gamble, given that the player did not know the outcome of the first one, should be between the following values [17]:", "startOffset": 204, "endOffset": 208}, {"referenceID": 69, "context": "Pr( G |W )\u2265 Pr( G |U )\u2265 Pr( G | L ) (2) The findings reported by [71], however, revealed a different relation.", "startOffset": 65, "endOffset": 69}, {"referenceID": 69, "context": "37 (3) [71] explained these findings in the following way: when the participants knew that they won, then they had extra house money to play with and decided to play the second round.", "startOffset": 7, "endOffset": 11}, {"referenceID": 63, "context": "Other works in the literature also replicated this twostage gambling experiment [65, 50, 51], also reporting similar results to [71].", "startOffset": 80, "endOffset": 92}, {"referenceID": 48, "context": "Other works in the literature also replicated this twostage gambling experiment [65, 50, 51], also reporting similar results to [71].", "startOffset": 80, "endOffset": 92}, {"referenceID": 49, "context": "Other works in the literature also replicated this twostage gambling experiment [65, 50, 51], also reporting similar results to [71].", "startOffset": 80, "endOffset": 92}, {"referenceID": 69, "context": "Other works in the literature also replicated this twostage gambling experiment [65, 50, 51], also reporting similar results to [71].", "startOffset": 128, "endOffset": 132}, {"referenceID": 16, "context": "There have been different works in the literature trying to explain and model this phenomena [17, 61, 21].", "startOffset": 93, "endOffset": 105}, {"referenceID": 59, "context": "There have been different works in the literature trying to explain and model this phenomena [17, 61, 21].", "startOffset": 93, "endOffset": 105}, {"referenceID": 20, "context": "There have been different works in the literature trying to explain and model this phenomena [17, 61, 21].", "startOffset": 93, "endOffset": 105}, {"referenceID": 13, "context": "Recent findings in the cognitive psychology literature revealed that humans are constantly violating the law of total probability when making decisions under risk [14, 21, 22].", "startOffset": 163, "endOffset": 175}, {"referenceID": 20, "context": "Recent findings in the cognitive psychology literature revealed that humans are constantly violating the law of total probability when making decisions under risk [14, 21, 22].", "startOffset": 163, "endOffset": 175}, {"referenceID": 21, "context": "Recent findings in the cognitive psychology literature revealed that humans are constantly violating the law of total probability when making decisions under risk [14, 21, 22].", "startOffset": 163, "endOffset": 175}, {"referenceID": 66, "context": "One belongs to [68] and the other to [53].", "startOffset": 15, "endOffset": 19}, {"referenceID": 51, "context": "One belongs to [68] and the other to [53].", "startOffset": 37, "endOffset": 41}, {"referenceID": 66, "context": "In the work of [68], it is argued that any classical Bayesian Network can be extended to a quantum one by replacing real probabilities with quantum complex amplitudes.", "startOffset": 15, "endOffset": 19}, {"referenceID": 51, "context": "In the work of [53], the authors argue that, in order to develop a quantum Bayesian Network, it is required a quantum version of probability distributions, quantum marginal probabilities and quantum conditional probabilities.", "startOffset": 15, "endOffset": 19}, {"referenceID": 20, "context": "In this paper, the core of the proposed Bayesian Network is based on the psychological findings uncovered in the works of [21, 22, 17, 61] and on quantum information processing.", "startOffset": 122, "endOffset": 138}, {"referenceID": 21, "context": "In this paper, the core of the proposed Bayesian Network is based on the psychological findings uncovered in the works of [21, 22, 17, 61] and on quantum information processing.", "startOffset": 122, "endOffset": 138}, {"referenceID": 16, "context": "In this paper, the core of the proposed Bayesian Network is based on the psychological findings uncovered in the works of [21, 22, 17, 61] and on quantum information processing.", "startOffset": 122, "endOffset": 138}, {"referenceID": 59, "context": "In this paper, the core of the proposed Bayesian Network is based on the psychological findings uncovered in the works of [21, 22, 17, 61] and on quantum information processing.", "startOffset": 122, "endOffset": 138}, {"referenceID": 61, "context": "We then generalise our quantum Bayesian Network in order to deal with larger and more complex datasets that are used in the literature: the well known Burglar/Alarm Bayesian Network from [63] and the Lung Cancer Bayesian Network from [59].", "startOffset": 187, "endOffset": 191}, {"referenceID": 57, "context": "We then generalise our quantum Bayesian Network in order to deal with larger and more complex datasets that are used in the literature: the well known Burglar/Alarm Bayesian Network from [63] and the Lung Cancer Bayesian Network from [59].", "startOffset": 234, "endOffset": 238}, {"referenceID": 16, "context": "Instead of just presenting a set of formulas, we show this difference by means of an illustrative example, just like proposed in [17].", "startOffset": 129, "endOffset": 133}, {"referenceID": 16, "context": "All this analysis is based on the book of [17].", "startOffset": 42, "endOffset": 46}, {"referenceID": 30, "context": "A Sample Space \u03a9 corresponds to the set of all possible outcomes of an experiment or random trial [31].", "startOffset": 98, "endOffset": 102}, {"referenceID": 38, "context": "It can be see as a vector space of complex numbers and offers the structure of an inner product to enable the measurement of angles and lengths [40].", "startOffset": 144, "endOffset": 148}, {"referenceID": 16, "context": "Figure 6 presents a diagram showing the Hilbert space of a defendant being guilty or innocent [17].", "startOffset": 94, "endOffset": 98}, {"referenceID": 16, "context": "Operations such as intersection and union of events are well defined if the events are spanned by the same basis vector [17].", "startOffset": 120, "endOffset": 124}, {"referenceID": 0, "context": "They are defined as follows: Guilty = [ 1 0 ] Innocent = [ 0 1 ]", "startOffset": 38, "endOffset": 45}, {"referenceID": 0, "context": "They are defined as follows: Guilty = [ 1 0 ] Innocent = [ 0 1 ]", "startOffset": 57, "endOffset": 64}, {"referenceID": 20, "context": "This section shows how to compute quantum probabilities in a Markov model using Feynman\u2019s path rules, just like presented in the work of [21].", "startOffset": 137, "endOffset": 141}, {"referenceID": 42, "context": "Psychological findings showed that this not only occurs in a microscopic scale (such as electrons), but also occurs at a macroscopic setting [44, 61, 22].", "startOffset": 141, "endOffset": 153}, {"referenceID": 59, "context": "Psychological findings showed that this not only occurs in a microscopic scale (such as electrons), but also occurs at a macroscopic setting [44, 61, 22].", "startOffset": 141, "endOffset": 153}, {"referenceID": 21, "context": "Psychological findings showed that this not only occurs in a microscopic scale (such as electrons), but also occurs at a macroscopic setting [44, 61, 22].", "startOffset": 141, "endOffset": 153}, {"referenceID": 46, "context": "In this section we show how to derive the interference term by just taking into account well known properties of complex numbers [48].", "startOffset": 129, "endOffset": 133}, {"referenceID": 45, "context": "Khrennikov [47, 44, 48, 39, 43, 24].", "startOffset": 11, "endOffset": 35}, {"referenceID": 42, "context": "Khrennikov [47, 44, 48, 39, 43, 24].", "startOffset": 11, "endOffset": 35}, {"referenceID": 46, "context": "Khrennikov [47, 44, 48, 39, 43, 24].", "startOffset": 11, "endOffset": 35}, {"referenceID": 37, "context": "Khrennikov [47, 44, 48, 39, 43, 24].", "startOffset": 11, "endOffset": 35}, {"referenceID": 41, "context": "Khrennikov [47, 44, 48, 39, 43, 24].", "startOffset": 11, "endOffset": 35}, {"referenceID": 23, "context": "Khrennikov [47, 44, 48, 39, 43, 24].", "startOffset": 11, "endOffset": 35}, {"referenceID": 47, "context": "Once the values of the parents are known, no information relating directly or indirectly to its parents or other ancestors can influence the beliefs about it [49].", "startOffset": 158, "endOffset": 162}, {"referenceID": 47, "context": "This means that an independence statement over random variables is a universal quantification over all possible values of random variables [49].", "startOffset": 139, "endOffset": 143}, {"referenceID": 47, "context": ",Xn), is the distribution that assigns probabilities to events that are specified in terms of these random variable [49].", "startOffset": 116, "endOffset": 120}, {"referenceID": 61, "context": "Then, the full joint distribution of a Bayesian Network, where X is the list of variables, is given by [63]:", "startOffset": 103, "endOffset": 107}, {"referenceID": 61, "context": "The term \u03b1 corresponds to a normalization factor for the distribution Pr(X) [63].", "startOffset": 76, "endOffset": 80}, {"referenceID": 69, "context": "41 The probabilities computed are not in accordance with the probabilistic findings reported by [71], because it was empirically observed that Pr(G2 = play |U = play) = 0.", "startOffset": 96, "endOffset": 100}, {"referenceID": 51, "context": "Following the work of [53], a Quantum Bayesian Network can be defined by a pair (G,\u03c1v), where G = (V,E) is a directed acyclic graph, and each vertex v\u2208V is associated with a quantum system with a Hilbert space Hv and \u03c1v is a quantum state on HV = Hv1\u2297Hv2\u2297 \u00b7\u00b7 \u00b7 \u2297Hvn.", "startOffset": 22, "endOffset": 26}, {"referenceID": 51, "context": ",vN}, each associated with a Hilbert space with a specific dimension[53].", "startOffset": 68, "endOffset": 72}, {"referenceID": 0, "context": "Play = [ 1 0 ] Not Play = [ 0 1 ]", "startOffset": 7, "endOffset": 14}, {"referenceID": 0, "context": "Play = [ 1 0 ] Not Play = [ 0 1 ]", "startOffset": 26, "endOffset": 33}, {"referenceID": 0, "context": "X0 = Y0 = Z0 = [ 1 0 ] , X1 = Y1 = Z1 = [ 0 1 ]", "startOffset": 15, "endOffset": 22}, {"referenceID": 0, "context": "X0 = Y0 = Z0 = [ 1 0 ] , X1 = Y1 = Z1 = [ 0 1 ]", "startOffset": 40, "endOffset": 47}, {"referenceID": 69, "context": "Following the experiment performed by [71], we want to determine the probability of a participant playing the second gamble, given that (s)he does not know the outcome of the first gamble.", "startOffset": 38, "endOffset": 42}, {"referenceID": 69, "context": "Equations 56 and 57 showed that the proposed approach is able to simulate the human decisions observed in the works of [71, 65, 50, 51].", "startOffset": 119, "endOffset": 135}, {"referenceID": 63, "context": "Equations 56 and 57 showed that the proposed approach is able to simulate the human decisions observed in the works of [71, 65, 50, 51].", "startOffset": 119, "endOffset": 135}, {"referenceID": 48, "context": "Equations 56 and 57 showed that the proposed approach is able to simulate the human decisions observed in the works of [71, 65, 50, 51].", "startOffset": 119, "endOffset": 135}, {"referenceID": 49, "context": "Equations 56 and 57 showed that the proposed approach is able to simulate the human decisions observed in the works of [71, 65, 50, 51].", "startOffset": 119, "endOffset": 135}, {"referenceID": 59, "context": "In this work, we look at this parameter from a different perspective: what happens to the quantum computed probabilities if we vary this angle \u03b8? Can better inferences be achieved? In this section, we make use of the probabilistic interference term proposed in the cognitive psychology literature [61, 22], and investigate the impact that the phase parameter \u03b8 can have,when computing quantum probabilities in the two step gambling game.", "startOffset": 297, "endOffset": 305}, {"referenceID": 21, "context": "In this work, we look at this parameter from a different perspective: what happens to the quantum computed probabilities if we vary this angle \u03b8? Can better inferences be achieved? In this section, we make use of the probabilistic interference term proposed in the cognitive psychology literature [61, 22], and investigate the impact that the phase parameter \u03b8 can have,when computing quantum probabilities in the two step gambling game.", "startOffset": 297, "endOffset": 305}, {"referenceID": 57, "context": "The example that we will examine correspond to a modified version of the Burglar/Alarm network, which is very used in the scope of Artificial Intelligence [59, 63].", "startOffset": 155, "endOffset": 163}, {"referenceID": 61, "context": "The example that we will examine correspond to a modified version of the Burglar/Alarm network, which is very used in the scope of Artificial Intelligence [59, 63].", "startOffset": 155, "endOffset": 163}, {"referenceID": 61, "context": "The network proposed in the book of [63] is inspired in the following scenario.", "startOffset": 36, "endOffset": 40}, {"referenceID": 61, "context": "Given the evidence of who has or has not called the police, we want to represent in a Bayesian Network the probability of a burglary occurring [63].", "startOffset": 143, "endOffset": 147}, {"referenceID": 66, "context": "but we replaced the real probability values by quantum complex amplitudes, just like proposed in [68] and [53].", "startOffset": 97, "endOffset": 101}, {"referenceID": 51, "context": "but we replaced the real probability values by quantum complex amplitudes, just like proposed in [68] and [53].", "startOffset": 106, "endOffset": 110}, {"referenceID": 61, "context": "Figure 18: Burglar/Alarm classical Bayesian Network proposed in the book of [63] Figure 19: Quantum counterpart of the Burglar/Alarm Bayesian Network proposed in the book of [63]", "startOffset": 76, "endOffset": 80}, {"referenceID": 61, "context": "Figure 18: Burglar/Alarm classical Bayesian Network proposed in the book of [63] Figure 19: Quantum counterpart of the Burglar/Alarm Bayesian Network proposed in the book of [63]", "startOffset": 174, "endOffset": 178}, {"referenceID": 51, "context": "in quantum Bayesian Networks has also been noticed in the work of [53].", "startOffset": 66, "endOffset": 70}, {"referenceID": 57, "context": "Consider the Classical Bayesian Network of Figure 24, which corresponds to a slightly modified version of the Bayesian Network proposed in the book of [59].", "startOffset": 151, "endOffset": 155}, {"referenceID": 57, "context": "Figure 24: Classical representation of a Lung Cancer Bayesian Network inspired in the book of [59].", "startOffset": 94, "endOffset": 98}, {"referenceID": 57, "context": "Figure 25: Quantum representation of a Lung Cancer Bayesian Network inspired in the book of [59].", "startOffset": 92, "endOffset": 96}, {"referenceID": 67, "context": "Since the preliminary findings of [69], cognitive scientists began to use alternative theories, such as quantum probability theory, in an attempt to explain the paradoxical findings that classical probability theory could not explain.", "startOffset": 34, "endOffset": 38}, {"referenceID": 31, "context": "Examples of such violations correspond to the Ellsberg paradox [32], the two-stage gambling game [71, 50, 51] and the prisoner\u2019s dilemma game [71, 26, 54, 18, 41, 25].", "startOffset": 63, "endOffset": 67}, {"referenceID": 69, "context": "Examples of such violations correspond to the Ellsberg paradox [32], the two-stage gambling game [71, 50, 51] and the prisoner\u2019s dilemma game [71, 26, 54, 18, 41, 25].", "startOffset": 97, "endOffset": 109}, {"referenceID": 48, "context": "Examples of such violations correspond to the Ellsberg paradox [32], the two-stage gambling game [71, 50, 51] and the prisoner\u2019s dilemma game [71, 26, 54, 18, 41, 25].", "startOffset": 97, "endOffset": 109}, {"referenceID": 49, "context": "Examples of such violations correspond to the Ellsberg paradox [32], the two-stage gambling game [71, 50, 51] and the prisoner\u2019s dilemma game [71, 26, 54, 18, 41, 25].", "startOffset": 97, "endOffset": 109}, {"referenceID": 69, "context": "Examples of such violations correspond to the Ellsberg paradox [32], the two-stage gambling game [71, 50, 51] and the prisoner\u2019s dilemma game [71, 26, 54, 18, 41, 25].", "startOffset": 142, "endOffset": 166}, {"referenceID": 25, "context": "Examples of such violations correspond to the Ellsberg paradox [32], the two-stage gambling game [71, 50, 51] and the prisoner\u2019s dilemma game [71, 26, 54, 18, 41, 25].", "startOffset": 142, "endOffset": 166}, {"referenceID": 52, "context": "Examples of such violations correspond to the Ellsberg paradox [32], the two-stage gambling game [71, 50, 51] and the prisoner\u2019s dilemma game [71, 26, 54, 18, 41, 25].", "startOffset": 142, "endOffset": 166}, {"referenceID": 17, "context": "Examples of such violations correspond to the Ellsberg paradox [32], the two-stage gambling game [71, 50, 51] and the prisoner\u2019s dilemma game [71, 26, 54, 18, 41, 25].", "startOffset": 142, "endOffset": 166}, {"referenceID": 39, "context": "Examples of such violations correspond to the Ellsberg paradox [32], the two-stage gambling game [71, 50, 51] and the prisoner\u2019s dilemma game [71, 26, 54, 18, 41, 25].", "startOffset": 142, "endOffset": 166}, {"referenceID": 24, "context": "Examples of such violations correspond to the Ellsberg paradox [32], the two-stage gambling game [71, 50, 51] and the prisoner\u2019s dilemma game [71, 26, 54, 18, 41, 25].", "startOffset": 142, "endOffset": 166}, {"referenceID": 59, "context": "For instance, [61] proposed a quantum dynamic Markov Model for the prisoner\u2019s dilemma game.", "startOffset": 14, "endOffset": 18}, {"referenceID": 14, "context": "In [15], the authors focus on irrational choices and developed a model based on the quantum superposition and interference principles for the prisoner dilemma game.", "startOffset": 3, "endOffset": 7}, {"referenceID": 22, "context": "In [23], the authors analysed quantum conditional probabilities in the prisoner\u2019s dilemma game.", "startOffset": 3, "endOffset": 7}, {"referenceID": 45, "context": "So the author introduced the quantum-like approach and suggested a new trigonometric interference term [47, 48].", "startOffset": 103, "endOffset": 111}, {"referenceID": 46, "context": "So the author introduced the quantum-like approach and suggested a new trigonometric interference term [47, 48].", "startOffset": 103, "endOffset": 111}, {"referenceID": 0, "context": "In [1], the authors explored the impact of these violations in economics and analyse the two-stage gambling game and the prisoner\u2019s dilemma game under a quantum probabilistic point of view, by proposing a quantum Markov Model to explain the paradoxical observations in these games.", "startOffset": 3, "endOffset": 6}, {"referenceID": 13, "context": "Finally, [14] proposed a quantum bayesian updating scheme based on the formalisms of quantum mechanics that represents mental states on a Hilbert state.", "startOffset": 9, "endOffset": 13}, {"referenceID": 69, "context": "Through the usage of projections, they were able to introduce a model that could explain the paradoxical findings of the two-stage gambling game [71].", "startOffset": 145, "endOffset": 149}, {"referenceID": 19, "context": "Another similar work that compares Bayes rule to its quantum counterpart corresponds to [20].", "startOffset": 88, "endOffset": 92}, {"referenceID": 32, "context": "For instance, [34] developed a quantum probabilistic model to explain fallacies when making preferences over a set of events, more specifically, the conjunction fallacy.", "startOffset": 14, "endOffset": 18}, {"referenceID": 18, "context": "[19] also focused on quantum models to explain conjunction and [26] focused on disjunction fallacies.", "startOffset": 0, "endOffset": 4}, {"referenceID": 25, "context": "[19] also focused on quantum models to explain conjunction and [26] focused on disjunction fallacies.", "startOffset": 63, "endOffset": 67}, {"referenceID": 69, "context": "The first experiments where these fallacies were observed to occur were performed by [71].", "startOffset": 85, "endOffset": 89}, {"referenceID": 68, "context": "An alternative model for conjunction and disjunction errors correspond to [70].", "startOffset": 74, "endOffset": 78}, {"referenceID": 35, "context": "Other models correspond to [37, 36].", "startOffset": 27, "endOffset": 35}, {"referenceID": 34, "context": "Other models correspond to [37, 36].", "startOffset": 27, "endOffset": 35}, {"referenceID": 42, "context": "[44] also modelled mental", "startOffset": 0, "endOffset": 4}, {"referenceID": 23, "context": "processes through quantum probabilities, where the interference process plays an important role in the process of recognising images[24].", "startOffset": 132, "endOffset": 136}, {"referenceID": 45, "context": "Other interesting works of this author applying similar quantum formalisms correspond to [47, 46, 45, 67].", "startOffset": 89, "endOffset": 105}, {"referenceID": 44, "context": "Other interesting works of this author applying similar quantum formalisms correspond to [47, 46, 45, 67].", "startOffset": 89, "endOffset": 105}, {"referenceID": 43, "context": "Other interesting works of this author applying similar quantum formalisms correspond to [47, 46, 45, 67].", "startOffset": 89, "endOffset": 105}, {"referenceID": 65, "context": "Other interesting works of this author applying similar quantum formalisms correspond to [47, 46, 45, 67].", "startOffset": 89, "endOffset": 105}, {"referenceID": 66, "context": "For example, in [68] the model proposed by the author is exactly the same as a classical Bayesian Network.", "startOffset": 16, "endOffset": 20}, {"referenceID": 55, "context": "A similar model has been proposed by [57], but for Markov Networks.", "startOffset": 37, "endOffset": 41}, {"referenceID": 51, "context": "In [53], the author proposed a quantum Bayesian Network by replacing the classical formulas used to perform the inference process by their quantum counterpart.", "startOffset": 3, "endOffset": 7}, {"referenceID": 21, "context": "[22], [18] and [21] proposed a quantum dynamic Markov model based on the findings of cognitive psychologists and interference terms.", "startOffset": 0, "endOffset": 4}, {"referenceID": 17, "context": "[22], [18] and [21] proposed a quantum dynamic Markov model based on the findings of cognitive psychologists and interference terms.", "startOffset": 6, "endOffset": 10}, {"referenceID": 20, "context": "[22], [18] and [21] proposed a quantum dynamic Markov model based on the findings of cognitive psychologists and interference terms.", "startOffset": 15, "endOffset": 19}, {"referenceID": 2, "context": "One of the first and most influential models that applied quantum probability for decision making belongs to [3].", "startOffset": 109, "endOffset": 112}, {"referenceID": 7, "context": "Other works related to this model can be found in [8, 9, 7, 2, 10, 11, 2, 12, 13, 35, 4].", "startOffset": 50, "endOffset": 88}, {"referenceID": 8, "context": "Other works related to this model can be found in [8, 9, 7, 2, 10, 11, 2, 12, 13, 35, 4].", "startOffset": 50, "endOffset": 88}, {"referenceID": 6, "context": "Other works related to this model can be found in [8, 9, 7, 2, 10, 11, 2, 12, 13, 35, 4].", "startOffset": 50, "endOffset": 88}, {"referenceID": 1, "context": "Other works related to this model can be found in [8, 9, 7, 2, 10, 11, 2, 12, 13, 35, 4].", "startOffset": 50, "endOffset": 88}, {"referenceID": 9, "context": "Other works related to this model can be found in [8, 9, 7, 2, 10, 11, 2, 12, 13, 35, 4].", "startOffset": 50, "endOffset": 88}, {"referenceID": 10, "context": "Other works related to this model can be found in [8, 9, 7, 2, 10, 11, 2, 12, 13, 35, 4].", "startOffset": 50, "endOffset": 88}, {"referenceID": 1, "context": "Other works related to this model can be found in [8, 9, 7, 2, 10, 11, 2, 12, 13, 35, 4].", "startOffset": 50, "endOffset": 88}, {"referenceID": 11, "context": "Other works related to this model can be found in [8, 9, 7, 2, 10, 11, 2, 12, 13, 35, 4].", "startOffset": 50, "endOffset": 88}, {"referenceID": 12, "context": "Other works related to this model can be found in [8, 9, 7, 2, 10, 11, 2, 12, 13, 35, 4].", "startOffset": 50, "endOffset": 88}, {"referenceID": 33, "context": "Other works related to this model can be found in [8, 9, 7, 2, 10, 11, 2, 12, 13, 35, 4].", "startOffset": 50, "endOffset": 88}, {"referenceID": 3, "context": "Other works related to this model can be found in [8, 9, 7, 2, 10, 11, 2, 12, 13, 35, 4].", "startOffset": 50, "endOffset": 88}, {"referenceID": 13, "context": "[14] proposed a quantum bayesian updating scheme based on the formalisms of quantum mechanics that represents mental states on a Hilbert state.", "startOffset": 0, "endOffset": 4}, {"referenceID": 69, "context": "Through the usage of projections, they were able to introduce a model that could explain the paradoxical findings of the two-stage gambling game [71].", "startOffset": 145, "endOffset": 149}, {"referenceID": 19, "context": "Another similar work that compares Bayes rule to its quantum counterpart corresponds to [20].", "startOffset": 88, "endOffset": 92}, {"referenceID": 14, "context": "For instance, [15] focus on irrational choices and developed a model based on the quantum superposition and interference principles for the Prisoner Dilemma game.", "startOffset": 14, "endOffset": 18}, {"referenceID": 22, "context": "[23] used the data collected by [71] and analysed quantum conditional probabilities.", "startOffset": 0, "endOffset": 4}, {"referenceID": 69, "context": "[23] used the data collected by [71] and analysed quantum conditional probabilities.", "startOffset": 32, "endOffset": 36}, {"referenceID": 54, "context": "[56] generalised the classical expected utility and proposed a quantum projective expected utility function that does not violate the laws of classical probability theory and can accommodate Allais and Ellsberg paradoxes.", "startOffset": 0, "endOffset": 4}, {"referenceID": 26, "context": "[27] made a formalisation of the structure of quantum probability theory and [28] also applied these formalists to expected utilities.", "startOffset": 0, "endOffset": 4}, {"referenceID": 27, "context": "[27] made a formalisation of the structure of quantum probability theory and [28] also applied these formalists to expected utilities.", "startOffset": 77, "endOffset": 81}, {"referenceID": 58, "context": "[60] applied quantum theory to the fields of economics and game theory and developed a principle to minimise financial risks [6] modelled how a person updates its beliefs in the liar\u2019s paradox.", "startOffset": 0, "endOffset": 4}, {"referenceID": 5, "context": "[60] applied quantum theory to the fields of economics and game theory and developed a principle to minimise financial risks [6] modelled how a person updates its beliefs in the liar\u2019s paradox.", "startOffset": 125, "endOffset": 128}, {"referenceID": 42, "context": "[44] also modelled mental processes through quantum probabilities, where the interference process plays an important role in the process of recognising images[24].", "startOffset": 0, "endOffset": 4}, {"referenceID": 23, "context": "[44] also modelled mental processes through quantum probabilities, where the interference process plays an important role in the process of recognising images[24].", "startOffset": 158, "endOffset": 162}, {"referenceID": 45, "context": "Other interesting works of this author applying similar quantum formalisms correspond to [47, 48, 46, 45, 42, 39].", "startOffset": 89, "endOffset": 113}, {"referenceID": 46, "context": "Other interesting works of this author applying similar quantum formalisms correspond to [47, 48, 46, 45, 42, 39].", "startOffset": 89, "endOffset": 113}, {"referenceID": 44, "context": "Other interesting works of this author applying similar quantum formalisms correspond to [47, 48, 46, 45, 42, 39].", "startOffset": 89, "endOffset": 113}, {"referenceID": 43, "context": "Other interesting works of this author applying similar quantum formalisms correspond to [47, 48, 46, 45, 42, 39].", "startOffset": 89, "endOffset": 113}, {"referenceID": 40, "context": "Other interesting works of this author applying similar quantum formalisms correspond to [47, 48, 46, 45, 42, 39].", "startOffset": 89, "endOffset": 113}, {"referenceID": 37, "context": "Other interesting works of this author applying similar quantum formalisms correspond to [47, 48, 46, 45, 42, 39].", "startOffset": 89, "endOffset": 113}, {"referenceID": 50, "context": "[52] developed a quantum mechanics based framework in order to model agents preferences under uncertainty.", "startOffset": 0, "endOffset": 4}, {"referenceID": 60, "context": "More recently, [62] published a work that generated discussions over the scientific literature, about whether or not, quantum probability can provide a new direction to compute quan-", "startOffset": 15, "endOffset": 19}, {"referenceID": 4, "context": "[5] also shares a similar opinion that quantum probability can, in fact, provide a new framework to explain several situations in which the laws of probability are violated.", "startOffset": 0, "endOffset": 3}, {"referenceID": 60, "context": "The work of, [62] has stimulated some discussions on the implications of quantum probability in functional brain networks.", "startOffset": 13, "endOffset": 17}, {"referenceID": 64, "context": "For instance, [66] have discussed the similarities between the vector representations of quantum states with a vector symbolic architecture, which is used to model realistic biological neural models.", "startOffset": 14, "endOffset": 18}, {"referenceID": 15, "context": "Other authors also support this idea of representing neuronal model using the quantum probabilistic framework [16, 38, 30, 29].", "startOffset": 110, "endOffset": 126}, {"referenceID": 36, "context": "Other authors also support this idea of representing neuronal model using the quantum probabilistic framework [16, 38, 30, 29].", "startOffset": 110, "endOffset": 126}, {"referenceID": 29, "context": "Other authors also support this idea of representing neuronal model using the quantum probabilistic framework [16, 38, 30, 29].", "startOffset": 110, "endOffset": 126}, {"referenceID": 28, "context": "Other authors also support this idea of representing neuronal model using the quantum probabilistic framework [16, 38, 30, 29].", "startOffset": 110, "endOffset": 126}, {"referenceID": 69, "context": "This work was motivated by the preliminary experiments of [71] about violations of the classical probability theory on the sure thing principle.", "startOffset": 58, "endOffset": 62}, {"referenceID": 2, "context": "The main difference between quantum and classical probability lies in the fact that on quantum probability we are constantly updating some beliefs when making a decision, while in classical probability all beliefs are assumed to have a definite value before a decision is made, and this value is the outcome of the decision [3].", "startOffset": 324, "endOffset": 327}, {"referenceID": 56, "context": "In the context of Bayesian Networks, data fusion is introduced in the work of [58].", "startOffset": 78, "endOffset": 82}], "year": 2014, "abstractText": "Probabilistic graphical models such as Bayesian Networks are one of the most powerful structures known by the Computer Science community for deriving probabilistic inferences. However, modern cognitive psychology has revealed that human decisions could not follow the rules of classical probability theory, because humans cannot process large amounts of data in order to make judgements. Consequently, the inferences performed are based on limited data coupled with several heuristics, leading to violations of the law of total probability. This means that probabilistic graphical models based on classical probability theory are too limited to fully simulate and explain various aspects of human decision making. Quantum probability theory was developed in order to accommodate the paradoxical findings that the classical theory could not explain. Recent findings in cognitive psychology revealed that quantum probability can fully describe human decisions in an elegant framework. Their findings suggest that, before taking a decision, human thoughts are seen as superposed waves that can interfere with each other, influencing the final decision. In this work, we propose a new Bayesian Network based on the psychological findings of cognitive scientists. We made experiments with two very well known Bayesian Networks from the literature. The results obtained revealed that the quantum like Bayesian Network can affect drastically the probabilistic inferences, specially when the levels of uncertainty of the network are very high (no pieces of evidence observed). When the levels of uncertainty are very low, then the proposed quantum like network collapses to its classical counterpart. This work was supported by national funds through FCT Funda\u00e7\u00e3o para a Ci\u00eancia e a Tecnologia, under project PEst-OE/EEI/LA0021/2013 1 ar X iv :1 40 9. 84 70 v1 [ cs .A I] 3 0 Se p 20 14", "creator": "LaTeX with hyperref package"}}}