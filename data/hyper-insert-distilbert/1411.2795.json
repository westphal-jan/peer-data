{"id": "1411.2795", "review": {"conference": "arxiv", "VERSION": "v1", "DATE_OF_SUBMISSION": "11-Nov-2014", "title": "Speaker Identification From Youtube Obtained Data", "abstract": "an efficient, robust and largely intuitive algorithm is presented necessary for selecting the process identification of speakers from a long dataset ( like web youtube long discussion, cocktail party recorded, audio or directed video ). generally the goal of conducting automatic dynamic speaker identification is believed to rapidly identify the variable number fields of different speakers interacting and prepare each a definitive model for that speaker by extraction, characterization and speaker - detector specific input information processing contained in the transmitted speech filtered signal. it seemingly has many diverse application specially accomplished in combining the field method of noisy surveillance, immigrations at helsinki airport, cyber security, target transcription in multi - source translation of similar sound sensory source, where it is difficult entirely to assign such transcription meanings arbitrary. the tool most commonly speech parametrization used in speaker verification, typically k - mean, cepstral analysis, is overly detailed. typically gaussian mixture hybrid modeling, or which is lacking the speaker modeling technique is available then indirectly explained. gaussian model mixture conversion models ( gmm ), perhaps the perhaps most commonly robust computer machine learning algorithm but has been introduced examine students and judge out carefully speaker identification effects in sample text independent. adjusting the application expectations or employment success of specific gaussian variable mixture models functions for monitoring & amp ; analysing for speaker identity tests is well encouraged by explaining the relative familiarity, awareness, or understanding findings gained through experience that enable gaussian gibbs spectrum depict exhibit the anatomical characteristics of speaker'original s spectral field conformational vibration pattern and displayed remarkable ability of gmm to construct minimum capricious densities well after see that we dramatically illustrate'expectation maximization'an iterative ensemble algorithm which takes guess some arbitrary value here in initial estimation and carry on creating the corresponding iterative estimation process until somehow the convergence of variable value is observed, so by doing various number manipulation of experiments we basically are able to obtain maximum 79 ~ 82 % of identification uncertainty rate using vector quantization curve and 85 ~ 1000 92. 6 % bit of identification information rate using gmm hybrid modeling characterised by expectation maximization parameter estimation ratios depending on variation of parameter.", "histories": [["v1", "Tue, 11 Nov 2014 13:20:19 GMT  (290kb)", "http://arxiv.org/abs/1411.2795v1", "7 pages, 5 figures, 1 Table, Signal &amp; Image Processing : An International Journal (SIPIJ) Vol.5, No.5, October 2014"]], "COMMENTS": "7 pages, 5 figures, 1 Table, Signal &amp; Image Processing : An International Journal (SIPIJ) Vol.5, No.5, October 2014", "reviews": [], "SUBJECTS": "cs.SD cs.LG", "authors": ["nitesh kumar chaudhary"], "accepted": false, "id": "1411.2795"}, "pdf": {"name": "1411.2795.pdf", "metadata": {"source": "CRF", "title": "SPEAKER IDENTIFICATION FROM YOUTUBE OBTAINED DATA", "authors": ["Nitesh Kumar Chaudhary", "Shraddha Srivastav"], "emails": [], "sections": [{"heading": null, "text": "DOI : 10.5121/sipij.2014.5503 27\nAn efficient, and intuitive algorithm is presented for the identification of speakers from a long dataset (like YouTube long discussion, Cocktail party recorded audio or video).The goal of automatic speaker identification is to identify the number of different speakers and prepare a model for that speaker by extraction, characterization and speaker-specific information contained in the speech signal. It has many diverse application specially in the field of Surveillance , Immigrations at Airport , cyber security , transcription in multi-source of similar sound source, where it is difficult to assign transcription arbitrary. The most commonly speech parameterization used in speaker verification, K-mean, cepstral analysis, is detailed. Gaussian mixture modeling, which is the speaker modeling technique is then explained. Gaussian mixture models (GMM), perhaps the most robust machine learning algorithm has been introduced to examine and judge carefully speaker identification in text independent. The application or employment of Gaussian mixture models for monitoring & Analysing speaker identity is encouraged by the familiarity, awareness, or understanding gained through experience that Gaussian spectrum depict the characteristics of speaker's spectral conformational pattern and remarkable ability of GMM to construct capricious densities after that we illustrate 'Expectation maximization' an iterative algorithm which takes some arbitrary value in initial estimation and carry on the iterative process until the convergence of value is observed We have tried to obtained 85 ~ 95% of accuracy using speaker modeling of vector quantization and Gaussian Mixture model ,so by doing various number of experiments we are able to obtain 79 ~ 82% of identification rate using Vector quantization and 85 ~ 92.6% of identification rate using GMM modeling by Expectation maximization parameter estimation depending on variation of parameter.\nKEYWORDS\nMFCC, Vector Quantization (VQ), Gaussian Mixture Model (GMM), K-mean, Maximum Likelihood, Expectation maximization."}, {"heading": "1. INTRODUCTION", "text": "Speaker identification have two categories: text-dependent and text-independent. Essentially, we are more interested and involved in the research of text independent speaker identification / verification with the reason that it doesn't impose as a necessity and demands regarding the utterances obtained from speaker that means there is no restriction over the words , it can be anything in any order, so the first basic steps involve the feature extraction from speech sample in the enrolment process of a speaker , extracted feature are collected in the database as a training data utterances. For the better accuracy, every time we are updating our training dataset while preparing training dataset for new utterances with previous stored data in our database, in this way model of each speaker is trained. Now in identification process with the help of probabilistic model a measurement of identification has to be done, the feature vectors of testing utterances is measured with feature vectors of training dataset and decision has to be made whether it belongs to a group of dataset or not."}, {"heading": "2. FEATURE EXTRACTION FROM VOCAL TRACT", "text": "Human's vocal tract, the airway used in the production of speech is the organs above the vocal folds, especially the passage above the larynx, including the pharynx, mouth, and nasal cavities. which is formed of the oral part (pharynx, tongue, lips, and jaw) , olfactory nerves, and the nasal tract. When the glottal pulses signal generated by the vibration of the vocal folds passes through the vocal tract, it is modified. Human\u2019s vocal tract is performing like a filter, and its frequency characteristics is dependent upon the resonance peak from the vocal tract and vocal tract configuration can be obtained from the spectral shape such as formant position and spectral inclination of the speech signal. These features can be obtained from the spectrogram of the speech signal and we are using Mel-Frequency Cepstral Coefficients (MFCC) features in speaker identification as it combines the advantages of the cepstrum analysis with a perceptual frequency scale based on critical bands. Although the speech signal is non-stationary, but can be assumed as stationary for a short duration of time, so analysis is done by framing the speech signal; the frame width is about 20\u221230 milliseconds, and the frames are shifted by about 10 milliseconds.\nThe number of feature vector that we get from utterances is usually large so for computation and the number of feature vectors can diminished without lose by K-means clustering method. This results in a small set of vectors called as codebook vector and a codebook is obtained for each speaker utterances using K-means. A codebook consist of many different vectors, which depict the important characteristics of each speaker. Each codebook is obtained as follows: Given a set of training set of MFCC feature vectors of 16-point vector for each frame of the utterance, which represent the speaker, find a decomposition of the feature vector space. Each decoposed region contains a cluster of vectors, which depict the same kind of basic sound. This region is represented by the centroid vector, which is the vector, which causes the minimum distortion when vectors in the region are mapped to it. Thus, each speaker has a codebook with a number of centroids which is prepared with the help of K-mean Clustering."}, {"heading": "3. MODELING USING VECTOR QUANTIZATION AND IDENTIFICATION", "text": "Vector quantization (VQ) is one of the simplest text-independent speaker models. VQ is often used for computational speed-up techniques and lightweight practical implementations. Vector\nquantization (VQ) is a ancient well-known quantization skills from signal processing which allows the modeling of probability density functions by the classification of prototype vectors. VQ is generally used by classifying a large se of (MFCC)feature vector dataset in small groups vectors having same number of points closet to the denser value i.e. means of codebook of training dataset\nFor Identification average quantization distortion is computed for the test utterance feature vectors by X = {x1,x2....xT}and the reference vectors by \u024c={r1,r2\u2026.rk} .\nWhere d(.,.) is a distance measure such as the Euclidean distance ||xt-rk||. A smaller value DQ indicates higher likelihood for X and R originating from the same speaker.\nAbove Diagram1 shows speaker identification using Vector quantization modeling, the upper region is enrolment process while in lower region feature has been extracted from test utterance. Diagram2 shows the Vector quantization distortion measurements plot when the speaker identification\u2019s test has been performed for 8 speakers. For K = 16 variations of distortion measurement from speaker i to speaker i utterances lies between (3.4561 to 7.0723) and from speaker i to speaker j lies between (13.1892 to 29.9038), where i, j \u03f5 (1 to 8).\nDiagram 4\nTable1. Performance of Vector quantization modeling with MFCC feature extraction\nTraining Utterances No. of Clustering (K mean) Identification rate (%)\n8 Speaker utterances K = 32 82\n8 Speaker utterances K = 16 82\n8 Speaker utterances K = 8 80\nTotal Number of speaker\u2019s utterances = 75"}, {"heading": "4. MODELING USING GAUSSIAN MIXTURE MODEL", "text": "A Gaussian Mixture Model (GMM) is a parametric probability density function represented as a weighted sum of Gaussian component densities. It is generally used as a parametric model of the probability distribution of continuous spectrum. GMM parameters are computed by 'Expectation maximization' an iterative algorithm which takes some arbitrary value in initial estimation and carry on the iterative process until the convergence of value is observed and the whole Gaussian mixture model is defined by these parameters namely mean vectors (\u00b5i), covariance matrices(\u03c3i) and mixture weights(pi) from all different components, and the weighted sum of M Component density is given by\nwhere \u03c7 is a D-dimensional continuous-valued feature vector (in our case 16 dimensional), pi , i = 1, . . . ,M, are the mixture weights, and g(\u03c7/\u00b5i,\u03c3i) are component densities. Each component density is a D-dimensional Gaussian function of the form,\nGMM based speaker identification model is shown below, the upper region is extraction of features from training dataset and preparing a mixture model using expectation maximization while in lower region feature has been extracted from test utterance, and finally with GMM parameter and extracted features from test utterances identification measurement has been done by using probability generation function\nOne of the powerful attributes of the GMM is its ability to form smooth approximations to arbitrarily shaped densities. There are several techniques available for estimating the parameters of a GMM i.e (\u00b5, \u03c3, p) and most popular and well-established method is maximum likelihood (ML) estimation. Since the equation of joint probability is nonlinear function of parameter \u03bb so we can\u2019t solve it easily because number of unknown variables are more than number of equations , so the parameter of ML is estimated iteratively by expectation maximization . The basic idea of the EM algorithm is, beginning with an initial model \u03bbi to estimate a new model \u03bbj such that p(\u03c7/ \u03bbj) \u2265 p(\u03c7/ \u03bbi), where j > i . The new model then becomes the initial model for the next iteration and the process is repeated until some convergence threshold is reached, so by using number of utterances = 10 can give you a good approximated parameters (\u00b5, \u03c3, p) of GMM.\nTable2. Performance of GMM with MFCC feature based identification\nTraining data in seconds Testing data in seconds No. of component No. of Iterations for EM Rate of correct identification (%)\n6 6 2 6 78.8342\n6 6 4 6 76.6654"}, {"heading": "12 6 4 8 83.6723", "text": ""}, {"heading": "20 6 4 10 84.4348", "text": "30 4 to 10 4 12 87.4382\n30 4 to 10 5 12 89.5630\n60 4 to 10 6 12 92.6643\n120 4 to 10 7 14 92.1273\nTotal Number of speaker\u2019s utterances = 75"}, {"heading": "5. CONCLUSION", "text": "In this paper, we have introduced a text-dependent speaker identification system, we have investigated that Gaussian mixture models (GMMs) have proven extremely successful for textindependent speaker identification for long dataset of different speakers. Identification performance of the Gaussian mixture speaker model is insensitive to the method of model initialization however we have estimated the parameter using expectation maximization and Identification rate is very sensitive to number of cluster and number of iteration of expectation maximization we have performed the experiments in Matlab R2014a (The Language of Technical Computing), this model is currently being evaluated on a 75 speaker's utterances and the results indicate that Gaussian mixture models provide a robust speaker representation for the difficult task of speaker identification using corrupted, unconstrained speech of cocktail party or YouTube dataset The models are computationally inexpensive and easily implemented on a real-time platform."}], "references": [{"title": "Likelihood normalization for speaker verification using a phoneme- and speaker-independent model", "author": ["T.Matsui", "S. Furui"], "venue": "Speech Communication, vol. 17, no. 1-2, pp. 109\u2013116, 1995.", "citeRegEx": "1", "shortCiteRegEx": null, "year": 1995}, {"title": "A Gaussian mixture modeling approach to text independent speaker identification", "author": ["D.A. Reynolds"], "venue": "Ph.D. thesis, Georgia Institute of Technology,", "citeRegEx": "2", "shortCiteRegEx": "2", "year": 1992}, {"title": "Speaker identification and verification using Gaussian mixture speaker models", "author": ["D.A. Reynolds"], "venue": "Speech Communication, vol. 17, no. 1-2, pp. 91\u2013108, 1995.", "citeRegEx": "3", "shortCiteRegEx": null, "year": 1995}, {"title": "A TMS32020-Based Real Time, Text-Independent, Automatic Speaker Verification System", "author": ["J. Attili", "M. Savic", "J. Campbell"], "venue": "International Conference on Acoustics, Speech, and Signal Processing in New York, IEEE, pp. 599-602, 1988", "citeRegEx": "4", "shortCiteRegEx": null, "year": 1988}, {"title": "Interactive Clustering Techniques for Selecting Speaker-Independent Techniques for Selecting Speaker-Independent Reference Templates for Isolated Word Recognition", "author": ["Levinson", "S . E.", "L.R. Rabiner", "A.E. Rosenberg", "J.G. Wilson"], "venue": "IEEE Trans. ASSP. Vol. 27, pp. 134-141,1979.", "citeRegEx": "5", "shortCiteRegEx": null, "year": 1979}, {"title": "Speaker recognition: a tutorial", "author": ["J. Campbell"], "venue": "Proc. IEEE", "citeRegEx": "8", "shortCiteRegEx": "8", "year": 1997}, {"title": "Combining feature sets with support vector machines: application to speaker recognition", "author": ["A. Hatch", "A. Stolcke", "B. Peskin"], "venue": "IEEE Workshop on Automatic Speech Recognition and Understanding (ASRU),", "citeRegEx": "9", "shortCiteRegEx": "9", "year": 2005}, {"title": "Speaker Verification Using Adapted Gaussian Mixture Models.", "author": ["D. Reynolds"], "venue": "Digital Signal Processing", "citeRegEx": "10", "shortCiteRegEx": "10", "year": 2000}, {"title": "Methods of combining multiple classifiers with different features and their application to text-independent speaker identification,", "author": ["K. Chen", "L. Wang", "H. Chi"], "venue": "International Journal of Pattern Recognition and Artificial Intelligence,", "citeRegEx": "11", "shortCiteRegEx": "11", "year": 1997}, {"title": "An investigation of dependencies between frequency components and speaker characteristics for text-independent speaker identification", "author": ["X. Lu", "J. Dang"], "venue": "Speech Communication,", "citeRegEx": "13", "shortCiteRegEx": "13", "year": 2008}, {"title": "Mel filter bank energy-based slope feature and its application to speaker recognition", "author": ["S.R. Madikeri", "H.A. Murthy"], "venue": "In Proc. National Conference on Communications,", "citeRegEx": "14", "shortCiteRegEx": "14", "year": 2011}, {"title": "Large margin gaussian mixture modeling for phonetic classification and recognition", "author": ["F. Sha", "L.K. Saul"], "venue": "Image Processing : An International Journal (SIPIJ) Vol.5,", "citeRegEx": "16", "shortCiteRegEx": "16", "year": 2006}], "referenceMentions": [], "year": 2014, "abstractText": "An efficient, and intuitive algorithm is presented for the identification of speakers from a long dataset (like YouTube long discussion, Cocktail party recorded audio or video).The goal of automatic speaker identification is to identify the number of different speakers and prepare a model for that speaker by extraction, characterization and speaker-specific information contained in the speech signal. It has many diverse application specially in the field of Surveillance , Immigrations at Airport , cyber security , transcription in multi-source of similar sound source, where it is difficult to assign transcription arbitrary. The most commonly speech parameterization used in speaker verification, K-mean, cepstral analysis, is detailed. Gaussian mixture modeling, which is the speaker modeling technique is then explained. Gaussian mixture models (GMM), perhaps the most robust machine learning algorithm has been introduced to examine and judge carefully speaker identification in text independent. The application or employment of Gaussian mixture models for monitoring & Analysing speaker identity is encouraged by the familiarity, awareness, or understanding gained through experience that Gaussian spectrum depict the characteristics of speaker's spectral conformational pattern and remarkable ability of GMM to construct capricious densities after that we illustrate 'Expectation maximization' an iterative algorithm which takes some arbitrary value in initial estimation and carry on the iterative process until the convergence of value is observed We have tried to obtained 85 ~ 95% of accuracy using speaker modeling of vector quantization and Gaussian Mixture model ,so by doing various number of experiments we are able to obtain 79 ~ 82% of identification rate using Vector quantization and 85 ~ 92.6% of identification rate using GMM modeling by Expectation maximization parameter estimation depending on variation of parameter.", "creator": "PScript5.dll Version 5.2.2"}}}