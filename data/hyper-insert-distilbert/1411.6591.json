{"id": "1411.6591", "review": {"conference": "NIPS", "VERSION": "v1", "DATE_OF_SUBMISSION": "31-Oct-2014", "title": "A Latent Source Model for Online Collaborative Filtering", "abstract": "consequently despite the vast prevalence of structured collaborative filtering in recommendation systems, there has commonly been little theoretical development on questioning why it and how well defined it works, differing especially in the \" typical online \" setting, where different items requested are easily recommended to users well over time. we address this widening theoretical gap by informally introducing a model for explaining online recommendation systems, cast item processing recommendation under - the model as just a learning problem, and analyze explicitly the current performance of a competing cosine - similarity enabled collaborative filtering method. in our optimization model, each of $ n $ 2000 users initially either likes or erroneously dislikes each piece of $ 180 m $ 97 items. we often assume there might to be $ k $ types of users, and all the users of a relatively given internet type pair share a satisfying common resource string of probabilities similarly determining the chance of even liking each anonymous item. at each exposure time step, we explicitly recommend an item submitted to each user, where additionally a key distinction from related optimization bandit of literature too is that once a user independently consumes it an attractive item ( e. g., watches a movie ), then realized that hidden item cannot now be deliberately recommended upon to encounter the same user again. the goal is aiming to maximize precisely the average number of previously likable items recommended to your users personally over time. our main result page establishes states that running after nearly $ \\ log ( km ) $ from initial eliminating learning time starvation steps, a simple collaborative filtering scraping algorithm achieves essentially optimal user performance without secretly knowing $ 9 k $. arguably the chase algorithm subsequently has also an exploit exploitation foraging step that uses cosine similarity and two types of each exploration skill steps, hiring one another to dramatically explore the space of items ( standard in sweeping the literature ) and engage the then other to explore similarity between users ( similarly novel to this work ).", "histories": [["v1", "Fri, 31 Oct 2014 19:59:59 GMT  (554kb,D)", "http://arxiv.org/abs/1411.6591v1", "Advances in Neural Information Processing Systems (NIPS 2014)"]], "COMMENTS": "Advances in Neural Information Processing Systems (NIPS 2014)", "reviews": [], "SUBJECTS": "cs.LG cs.IR stat.ML", "authors": ["guy bresler", "george h chen", "devavrat shah"], "accepted": true, "id": "1411.6591"}, "pdf": {"name": "1411.6591.pdf", "metadata": {"source": "CRF", "title": "A Latent Source Model for Online Collaborative Filtering", "authors": ["Guy Bresler", "George H. Chen", "Devavrat Shah"], "emails": ["gbresler@mit.edu", "georgehc@mit.edu", "devavrat@mit.edu"], "sections": [{"heading": "1 Introduction", "text": "Recommendation systems have become ubiquitous in our lives, helping us filter the vast expanse of information we encounter into small selections tailored to our personal tastes. Prominent examples include Amazon recommending items to buy, Netflix recommending movies, and LinkedIn recommending jobs. In practice, recommendations are often made via collaborative filtering, which boils down to recommending an item to a user by considering items that other similar or \u201cnearby\u201d users liked. Collaborative filtering has been used extensively for decades now including in the GroupLens news recommendation system [20], Amazon\u2019s item recommendation system [17], the Netflix Prize winning algorithm by BellKor\u2019s Pragmatic Chaos [16, 24, 19], and a recent song recommendation system [1] that won the Million Song Dataset Challenge [6].\nMost such systems operate in the \u201conline\u201d setting, where items are constantly recommended to users over time. In many scenarios, it does not make sense to recommend an item that is already consumed. For example, once Alice watches a movie, there\u2019s little point to recommending the same movie to her again, at least not immediately, and one could argue that recommending unwatched movies and already watched movies could be handled as separate cases. Finally, what matters is whether a likable item is recommended to a user rather than an unlikable one. In short, a good online recommendation system should recommend different likable items continually over time.\nar X\niv :1\n41 1.\n65 91\nv1 [\ncs .L\nG ]\n3 1\nO ct\nDespite the success of collaborative filtering, there has been little theoretical development to justify its effectiveness in the online setting. We address this theoretical gap with our two main contributions in this paper. First, we frame online recommendation as a learning problem that fuses the lines of work on sleeping bandits and clustered bandits. We impose the constraint that once an item is consumed by a user, the system can\u2019t recommend the item to the same user again. Our second main contribution is to analyze a cosine-similarity collaborative filtering algorithm. The key insight is our inclusion of two types of exploration in the algorithm: (1) the standard random exploration for probing the space of items, and (2) a novel \u201cjoint\u201d exploration for finding different user types. Under our learning problem setup, after nearly log(km) initial time steps, the proposed algorithm achieves near-optimal performance relative to an oracle algorithm that recommends all likable items first. The nearly logarithmic dependence is a result of using the two different exploration types. We note that the algorithm does not know k.\nOutline. We present our model and learning problem for online recommendation systems in Section 2, provide a collaborative filtering algorithm and its performance guarantee in Section 3, and give the proof idea for the performance guarantee in Section 4. An overview of experimental results is given in Section 5. We discuss our work in the context of prior work in Section 6."}, {"heading": "2 A Model and Learning Problem for Online Recommendations", "text": "We consider a system with n users and m items. At each time step, each user is recommended an item that she or he hasn\u2019t consumed yet, upon which, for simplicity, we assume that the user immediately consumes the item and rates it +1 (like) or \u22121 (dislike).1 The reward earned by the recommendation system up to any time step is the total number of liked items that have been recommended so far across all users. Formally, index time by t \u2208 {1, 2, . . . }, and users by u \u2208 [n] , {1, . . . , n}. Let \u03c0ut \u2208 [m] , {1, . . . ,m} be the item recommended to user u at time t. Let Y (t)ui \u2208 {\u22121, 0,+1} be the rating provided by user u for item i up to and including time t, where 0 indicates that no rating has been given yet. A reasonable objective is to maximize the expected reward r(T ) up to time T :\nr(T ) , T\u2211 t=1 n\u2211 u=1 E[Y (T )u\u03c0ut ] = m\u2211 i=1 n\u2211 u=1 E[Y (T )ui ].\nThe ratings are noisy: the latent item preferences for user u are represented by a length-m vector pu \u2208 [0, 1]m, where user u likes item i with probability pui, independently across items. For a user u, we say that item i is likable if pui > 1/2 and unlikable if pui < 1/2. To maximize the expected reward r(T ), clearly likable items for the user should be recommended before unlikable ones.\nIn this paper, we focus on recommending likable items. Thus, instead of maximizing the expected reward r(T ), we aim to maximize the expected number of likable items recommended up to time T :\nr (T ) + , T\u2211 t=1 n\u2211 u=1 E[Xut] , (1)\nwhere Xut is the indicator random variable for whether the item recommended to user u at time t is likable, i.e., Xut = +1 if pu\u03c0ut > 1/2 and Xut = 0 otherwise. Maximizing r\n(T ) and r(T )+ differ since the former asks that we prioritize items according to their probability of being liked.\nRecommending likable items for a user in an arbitrary order is sufficient for many real recommendation systems such as for movies and music. For example, we suspect that users wouldn\u2019t actually prefer to listen to music starting from the songs that their user type would like with highest probability to the ones their user type would like with lowest probability; instead, each user would listen to songs that she or he finds likable, ordered such that there is sufficient diversity in the playlist to keep the user experience interesting. We target the modest goal of merely recommending likable items, in any order. Of course, if all likable items have the same probability of being liked and similarly for all unlikable items, then maximizing r(T ) and r(T )+ are equivalent.\n1In practice, a user could ignore the recommendation. To keep our exposition simple, however, we stick to this setting that resembles song recommendation systems like Pandora that per user continually recommends a single item at a time. For example, if a user rates a song as \u201cthumbs down\u201d then we assign a rating of \u22121 (dislike), and any other action corresponds to +1 (like).\nThe fundamental challenge is that to learn about a user\u2019s preference for an item, we need the user to rate (and thus consume) the item. But then we cannot recommend that item to the user again! Thus, the only way to learn about a user\u2019s preferences is through collaboration, or inferring from other users\u2019 ratings. Broadly, such inference is possible if the users preferences are somehow related.\nIn this paper, we assume a simple structure for shared user preferences. We posit that there are k < n different types of users, where users of the same type have identical item preference vectors. The number of types k represents the heterogeneity in the population. For ease of exposition, in this paper we assume that a user belongs to each user type with probability 1/k. We refer to this model as a latent source model, where each user type corresponds to a latent source of users. We remark that there is evidence suggesting real movie recommendation data to be well modeled by clustering of both users and items [21]. Our model only assumes clustering over users.\nOur problem setup relates to some versions of the multi-armed bandit problem. A fundamental difference between our setup and that of the standard stochastic multi-armed bandit problem [23, 8] is that the latter allows each item to be recommended an infinite number of times. Thus, the solution concept for the stochastic multi-armed bandit problem is to determine the best item (arm) and keep choosing it [3]. This observation applies also to \u201cclustered bandits\u201d [9], which like our work seeks to capture collaboration between users. On the other hand, sleeping bandits [15] allow for the available items at each time step to vary, but the analysis is worst-case in terms of which items are available over time. In our setup, the sequence of items that are available is not adversarial. Our model combines the collaborative aspect of clustered bandits with dynamic item availability from sleeping bandits, where we impose a strict structure on how items become unavailable."}, {"heading": "3 A Collaborative Filtering Algorithm and Its Performance Guarantee", "text": "This section presents our algorithm COLLABORATIVE-GREEDY and its accompanying theoretical performance guarantee. The algorithm is syntactically similar to the \u03b5-greedy algorithm for multiarmed bandits [22], which explores items with probability \u03b5 and otherwise greedily chooses the best item seen so far based on a plurality vote. In our algorithm, the greedy choice, or exploitation, uses the standard cosine-similarity measure. The exploration, on the other hand, is split into two types, a standard item exploration in which a user is recommended an item that she or he hasn\u2019t consumed yet uniformly at random, and a joint exploration in which all users are asked to provide a rating for the next item in a shared, randomly chosen sequence of items. Let\u2019s fill in the details.\nAlgorithm. At each time step t, either all the users are asked to explore, or an item is recommended to each user by choosing the item with the highest score for that user. The pseudocode is described in Algorithm 1. There are two types of exploration: random exploration, which is for exploring the space of items, and joint exploration, which helps to learn about similarity between users. For a pre-specified rate \u03b1 \u2208 (0, 4/7], we set the probability of random exploration to be \u03b5R(n) = 1/n\u03b1\nAlgorithm 1: COLLABORATIVE-GREEDY Input: Parameters \u03b8 \u2208 [0, 1], \u03b1 \u2208 (0, 4/7]. Select a random ordering \u03c3 of the items [m]. Define\n\u03b5R(n) = 1\nn\u03b1 , and \u03b5J(t) =\n1\nt\u03b1 .\nfor time step t = 1, 2, . . . , T do With prob. \u03b5R(n): (random exploration) for each user, recommend a random item that the user has not rated. With prob. \u03b5J(t): (joint exploration) for each user, recommend the first item in \u03c3 that the user has not rated. With prob. 1\u2212 \u03b5J(t)\u2212 \u03b5R(n): (exploitation) for each user u, recommend an item j that the user has not rated and that maximizes score p\u0303(t)uj , which depends on threshold \u03b8. end\n(decaying with the number of users), and the probability of joint exploration to be \u03b5J(t) = 1/t\u03b1 (decaying with time).2\nNext, we define user u\u2019s score p\u0303(t)ui for item i at time t. Recall that we observe Y (t) ui = {\u22121, 0,+1} as user u\u2019s rating for item i up to time t, where 0 indicates that no rating has been given yet. We define\np\u0303 (t) ui ,  \u2211 v\u2208N\u0303 (t)u 1{Y (t)vi = +1}\u2211 v\u2208N\u0303 (t)u 1{Y (t)vi 6= 0} if \u2211 v\u2208N\u0303 (t)u 1{Y (t)vi 6= 0} > 0,\n1/2 otherwise,\nwhere the neighborhood of user u is given by\nN\u0303 (t)u , {v \u2208 [n] : \u3008Y\u0303 (t)u , Y\u0303 (t)v \u3009 \u2265 \u03b8|supp(Y\u0303 (t)u ) \u2229 supp(Y\u0303 (t)v )|},\nand Y\u0303 (t)u consists of the revealed ratings of user u restricted to items that have been jointly explored. In other words,\nY\u0303 (t) ui =\n{ Y\n(t) ui if item i is jointly explored by time t,\n0 otherwise.\nThe neighborhoods are defined precisely by cosine similarity with respect to jointed explored items. To see this, for users u and v with revealed ratings Y\u0303 (t)u and Y\u0303 (t) v , let \u2126uv , supp(Y\u0303 (t) u )\u2229supp(Y\u0303 (t)v ) be the support overlap of Y\u0303 (t)u and Y\u0303 (t) v , and let \u3008\u00b7, \u00b7\u3009\u2126uv be the dot product restricted to entries in \u2126uv . Then \u3008Y\u0303 (t)u , Y\u0303 (t)v \u3009 |\u2126uv| = \u3008Y\u0303 (t)u , Y\u0303 (t)v \u3009\u2126uv\u221a\n\u3008Y\u0303 (t)u , Y\u0303 (t)u \u3009\u2126uv \u221a \u3008Y\u0303 (t)v , Y\u0303 (t)v \u3009\u2126uv ,\nwhich is the cosine similarity of revealed rating vectors Y\u0303 (t)u and Y\u0303 (t) v restricted to the overlap of their supports. Thus, users u and v are neighbors if and only if their cosine similarity is at least \u03b8.\nTheoretical performance guarantee. We now state our main result on the proposed collaborative filtering algorithm\u2019s performance with respect to the objective stated in equation (1). We begin with two reasonable, and seemingly necessary, conditions under which our the results will be established.\nA1 No \u2206-ambiguous items. There exists some constant \u2206 > 0 such that\n|pui \u2212 1/2| \u2265 \u2206 for all users u and items i. (Smaller \u2206 corresponds to more noise.)\nA2 \u03b3-incoherence. There exist a constant \u03b3 \u2208 [0, 1) such that if users u and v are of different types, then their item preference vectors pu and pv satisfy\n1 m \u30082pu \u2212 1, 2pv \u2212 1\u3009 \u2264 4\u03b3\u22062,\nwhere 1 is the all ones vector. Note that a different way to write the left-hand side is E[ 1m \u3008Y \u2217u , Y \u2217v \u3009], where Y \u2217u and Y \u2217v are fully-revealed rating vectors of users u and v, and the expectation is over the random ratings of items.\nThe first condition is a low noise condition to ensure that with a finite number of samples, we can correctly classify each item as either likable or unlikable. The incoherence condition asks that the different user types are well-separated so that cosine similarity can tease apart the users of different types over time. We provide some examples after the statement of the main theorem that suggest the incoherence condition to be reasonable, allowing E[\u3008Y \u2217u , Y \u2217v \u3009] to scale as \u0398(m) rather than o(m). We assume that the number of users satisfies n = O(mC) for some constant C > 1. This is without loss of generality since otherwise, we can randomly divide the n users into separate population\n2For ease of presentation, we set the two explorations to have the same decay rate \u03b1, but our proof easily extends to encompass different decay rates for the two exploration types. Furthermore, the constant 4/7 \u2265 \u03b1 is not special. It could be different and only affects another constant in our proof.\npools, each of size O(mC) and run the recommendation algorithm independently for each pool to achieve the same overall performance guarantee.\nFinally, we define \u00b5, the minimum proportion of likable items for any user (and thus any user type):\n\u00b5 , min u\u2208[n]\n\u2211m i=1 1{pui > 1/2}\nm .\nTheorem 1. Let \u03b4 \u2208 (0, 1) be some pre-specified tolerance. Take as input to COLLABORATIVEGREEDY \u03b8 = 2\u22062(1 + \u03b3) where \u03b3 \u2208 [0, 1) is as defined in A2, and \u03b1 \u2208 (0, 4/7]. Under the latent source model and assumptions A1 and A2, if the number of users n = O(mC) satisfies\nn = \u2126 ( km log 1 \u03b4 + (4 \u03b4 )1/\u03b1) ,\nthen for any Tlearn \u2264 T \u2264 \u00b5m, the expected proportion of likable items recommended by COLLABORATIVE-GREEDY up until time T satisfies\nr (T ) + Tn \u2265 ( 1\u2212 Tlearn T ) (1\u2212 \u03b4),\nwhere\nTlearn = \u0398\n(( log km\u2206\u03b4 \u22064(1\u2212 \u03b3)2 )1/(1\u2212\u03b1) + (4 \u03b4 )1/\u03b1) .\nTheorem 1 says that there are Tlearn initial time steps for which the algorithm may be giving poor recommendations. Afterward, for Tlearn < T < \u00b5m, the algorithm becomes near-optimal, recommending a fraction of likable items 1\u2212\u03b4 close to what an optimal oracle algorithm (that recommends all likable items first) would achieve. Then for time horizon T > \u00b5m, we can no longer guarantee that there are likable items left to recommend. Indeed, if the user types each have the same fraction of likable items, then even an oracle recommender would use up the \u00b5m likable items by this time. Meanwhile, to give a sense of how long the learning period Tlearn is, note that when \u03b1 = 1/2, we have Tlearn scaling as log2(km), and if we choose \u03b1 close to 0, then Tlearn becomes nearly log(km). In summary, after Tlearn initial time steps, the simple algorithm proposed is essentially optimal.\nTo gain intuition for incoherence condition A2, we calculate the parameter \u03b3 for three examples. Example 1. Consider when there is no noise, i.e., \u2206 = 12 . Then users\u2019 ratings are deterministic given their user type. Produce k vectors of probabilities by drawing m independent Bernoulli( 12 ) random variables (0 or 1 with probability 12 each) for each user type. For any item i and pair of users u and v of different types, Y \u2217ui \u00b7 Y \u2217vi is a Rademacher random variable (\u00b11 with probability 12 each), and thus the inner product of two user rating vectors is equal to the sum of m Rademacher\nrandom variables. Standard concentration inequalities show that one may take \u03b3 = \u0398 (\u221a\nlogm m\n) to\nsatisfy \u03b3-incoherence with probability 1\u2212 1/poly(m). Example 2. We expand on the previous example by choosing an arbitrary \u2206 > 0 and making all latent source probability vectors have entries equal to 12 \u00b1\u2206 with probability 12 each. As before let user u and v are from different type. Now E[Y \u2217ui \u00b7Y \u2217vi] = (12 + \u2206)2 + ( 12 \u2212\u2206)2\u2212 2( 14 \u2212\u22062) = 4\u22062 if pui = pvi and E[Y \u2217ui \u00b7 Y \u2217vi] = 2( 14 \u2212 \u22062) \u2212 ( 12 + \u2206)2 \u2212 ( 12 \u2212 \u2206)2 = \u22124\u22062 if pui = 1 \u2212 pvi. The value of the inner product E[\u3008Y \u2217u , Y \u2217v \u3009] is again equal to the sum of m Rademacher random variables, but this time scaled by 4\u22062. For similar reasons as before, \u03b3 = \u0398 (\u221a logm m ) suffices to satisfy \u03b3-incoherence with probability 1\u2212 1/poly(m). Example 3. Continuing with the previous example, now suppose each entry is 12 +\u2206 with probability \u00b5 \u2208 (0, 1/2) and 12 \u2212 \u2206 with probability 1 \u2212 \u00b5. Then for two users u and v of different types, pui = pvi with probability \u00b52 + (1 \u2212 \u00b5)2. This implies that E[\u3008Y \u2217u , Y \u2217v \u3009] = 4m\u22062(1 \u2212 2\u00b5)2. Again, using standard concentration, this shows that \u03b3 = (1\u22122\u00b5)2 +\u0398 (\u221a logm m ) suffices to satisfy \u03b3-incoherence with probability 1\u2212 1/poly(m)."}, {"heading": "4 Proof of Theorem 1", "text": "Recall that Xut is the indicator random variable for whether the item \u03c0ut recommended to user u at time t is likable, i.e., pu\u03c0ut > 1/2. Given assumption A1, this is equivalent to the event that pu\u03c0ut \u2265 12 + \u2206. The expected proportion of likable items is\nr (T ) +\nTn =\n1\nTn T\u2211 t=1 n\u2211 u=1 E[Xut] = 1 Tn T\u2211 t=1 n\u2211 u=1 P(Xut = 1).\nOur proof focuses on lower-bounding P(Xut = 1). The key idea is to condition on what we call the \u201cgood neighborhood\u201d event Egood(u, t):\nEgood(u, t) = {\nat time t, user u has \u2265 n 5k neighbors from the same user type (\u201cgood neighbors\u201d), and \u2264 \u2206tn 1\u2212\u03b1\n10km neighbors from other user types (\u201cbad neighbors\u201d)\n} .\nThis good neighborhood event will enable us to argue that after an initial learning time, with high probability there are at most \u2206 as many ratings from bad neighbors as there are from good neighbors.\nThe proof of Theorem 1 consists of two parts. The first part uses joint exploration to show that after a sufficient amount of time, the good neighborhood event Egood(u, t) holds with high probability. Lemma 1. For user u, after\nt \u2265 ( 2 log(10kmn\u03b1/\u2206) \u22064(1\u2212 \u03b3)2 )1/(1\u2212\u03b1)\ntime steps,\nP(Egood(u, t)) \u2265 1\u2212 exp ( \u2212 n\n8k\n) \u2212 12 exp ( \u2212 \u2206\n4(1\u2212 \u03b3)2t1\u2212\u03b1 20\n) .\nIn the above lower bound, the first exponentially decaying term could be thought of as the penalty for not having enough users in the system from the k user types, and the second decaying term could be thought of as the penalty for not yet clustering the users correctly.\nThe second part of our proof to Theorem 1 shows that, with high probability, the good neighborhoods have, through random exploration, accurately estimated the probability of liking each item. Thus, we correctly classify each item as likable or not with high probability, which leads to a lower bound on P(Xut = 1). Lemma 2. For user u at time t, if the good neighborhood event Egood(u, t) holds and t \u2264 \u00b5m, then\nP(Xut = 1) \u2265 1\u2212 2m exp ( \u2212 \u2206 2tn1\u2212\u03b1\n40km ) \u2212 1 t\u03b1 \u2212 1 n\u03b1 .\nHere, the first exponentially decaying term could be thought of as the cost of not classifying items correctly as likable or unlikable, and the last two decaying terms together could be thought of as the cost of exploration (we explore with probability \u03b5J(t) + \u03b5R(n) = 1/t\u03b1 + 1/n\u03b1).\nWe defer the proofs of Lemmas 1 and 2 to Appendices A.1 and A.2. Combining these lemmas and choosing appropriate constraints on the numbers of users and items, we produce the following lemma. Lemma 3. Let \u03b4 \u2208 (0, 1) be some pre-specified tolerance. If the number of users n and items m satisfy\nn \u2265 max { 8k log 4 \u03b4 , (4 \u03b4 )1/\u03b1} ,\n\u00b5m \u2265 t \u2265 max {( 2 log(10kmn\u03b1/\u2206) \u22064(1\u2212 \u03b3)2 )1/(1\u2212\u03b1) , ( 20 log(96/\u03b4) \u22064(1\u2212 \u03b3)2 )1/(1\u2212\u03b1) , (4 \u03b4 )1/\u03b1} ,\nnt1\u2212\u03b1 \u2265 40km \u22062\nlog (16m\n\u03b4\n) ,\nthen P(Xut = 1) \u2265 1\u2212 \u03b4.\nProof. With the above conditions on n and t satisfied, we combine Lemmas 1 and 2 to obtain\nP(Xut = 1) \u2265 1\u2212 exp ( \u2212 n\n8k\n) \u2212 12 exp ( \u2212 \u2206\n4(1\u2212 \u03b3)2t1\u2212\u03b1 20\n) \u2212 2m exp ( \u2212 \u2206 2tn1\u2212\u03b1\n40km ) \u2212 1 t\u03b1 \u2212 1 n\u03b1 \u2265 1\u2212 \u03b4 4 \u2212 \u03b4 8 \u2212 \u03b4 8 \u2212 \u03b4 4 \u2212 \u03b4 4 = 1\u2212 \u03b4.\nTheorem 1 follows as a corollary to Lemma 3. As previously mentioned, without loss of generality, we take n = O(mC). Then with number of users n satisfying\nO(mC) = n = \u2126 ( km log 1 \u03b4 + (4 \u03b4 )1/\u03b1) ,\nand for any time step t satisfying \u00b5m \u2265 t \u2265 \u0398 ((\nlog km\u2206\u03b4 \u22064(1\u2212 \u03b3)2 )1/(1\u2212\u03b1) + (4 \u03b4 )1/\u03b1) , Tlearn ,\nwe simultaneously meet all of the conditions of Lemma 3. Note that the upper bound on number of users n appears since without it, Tlearn would depend on n (observe that in Lemma 3, we ask that t be greater than a quantity that depends on n). Provided that the time horizon satisfies T \u2264 \u00b5m, then\nr (T ) +\nTn \u2265 1 Tn T\u2211 t=Tlearn n\u2211 u=1 P(Xut = 1) \u2265 1 Tn T\u2211 t=Tlearn n\u2211 u=1 (1\u2212 \u03b4) = (T \u2212 Tlearn)(1\u2212 \u03b4) T ,\nyielding the theorem statement."}, {"heading": "5 Experimental Results", "text": "We provide only a summary of our experimental results here, deferring full details to Appendix A.3. We simulate an online recommendation system based on movie ratings from the Movielens10m and Netflix datasets, each of which provides a sparsely filled user-by-movie rating matrix with ratings out of 5 stars. Unfortunately, existing collaborative filtering datasets such as the two we consider don\u2019t offer the interactivity of a real online recommendation system, nor do they allow us to reveal the rating for an item that a user didn\u2019t actually rate. For simulating an online system, the former issue can be dealt with by simply revealing entries in the user-by-item rating matrix over time. We address the latter issue by only considering a dense \u201ctop users vs. top items\u201d subset of each dataset. In particular, we consider only the \u201ctop\u201d users who have rated the most number of items, and the \u201ctop\u201d items that have received the most number of ratings. While this dense part of the dataset is unrepresentative of the rest of the dataset, it does allow us to use actual ratings provided by users without synthesizing any ratings. A rigorous validation would require an implementation of an actual interactive online recommendation system, which is beyond the scope of our paper.\nFirst, we validate that our latent source model is reasonable for the dense parts of the two datasets we consider by looking for clustering behavior across users. We find that the dense top users vs. top movies matrices do in fact exhibit clustering behavior of users and also movies, as shown in Figure 1(a). The clustering was found via Bayesian clustered tensor factorization, which was previously shown to model real movie ratings data well [21].\nNext, we demonstrate our algorithm COLLABORATIVE-GREEDY on the two simulated online movie recommendation systems, showing that it outperforms two existing recommendation algorithms Popularity Amongst Friends (PAF) [4] and a method by Deshpande and Montanari (DM) [12]. Following the experimental setup of [4], we quantize a rating of 4 stars or more to be +1 (likable), and a rating less than 4 stars to be \u22121 (unlikable). While we look at a dense subset of each dataset, there are still missing entries. If a user u hasn\u2019t rated item j in the dataset, then we set the corresponding true rating to 0, meaning that in our simulation, upon recommending item j to user u, we receive 0 reward, but we still mark that user u has consumed item j; thus, item j can no longer be recommended to user u. For both Movielens10m and Netflix datasets, we consider the top n = 200 users and the top m = 500 movies. For Movielens10m, the resulting user-by-rating matrix has 80.7% nonzero entries. For Netflix, the resulting matrix has 86.0% nonzero entries. For an algorithm that\nrecommends item \u03c0ut to user u at time t, we measure the algorithm\u2019s average cumulative reward up to time T as 1n \u2211T t=1 \u2211n u=1 Y (T ) u\u03c0ut , where we average over users. For all four methods, we recommend items until we reach time T = 500, i.e., we make movie recommendations until each user has seen all m = 500 movies. We disallow the matrix completion step for DM to see the users that we actually test on, but we allow it to see the the same items as what is in the simulated online recommendation system in order to compute these items\u2019 feature vectors (using the rest of the users in the dataset). Furthermore, when a rating is revealed, we provide DM both the thresholded rating and the non-thresholded rating, the latter of which DM uses to estimate user feature vectors over time. We discuss choice of algorithm parameters in Appendix A.3. In short, parameters \u03b8 and \u03b1 of our algorithm are chosen based on training data, whereas we allow the other algorithms to use whichever parameters give the best results on the test data. Despite giving the two competing algorithms this advantage, COLLABORATIVE-GREEDY outperforms the two, as shown in Figure 1(b). Results on the Netflix dataset are similar."}, {"heading": "6 Discussion and Related Work", "text": "This paper proposes a model for online recommendation systems under which we can analyze the performance of recommendation algorithms. We theoretical justify when a cosine-similarity collaborative filtering method works well, with a key insight of using two exploration types.\nThe closest related work is by Biau et al. [7], who study the asymptotic consistency of a cosinesimilarity nearest-neighbor collaborative filtering method. Their goal is to predict the rating of the next unseen item. Barman and Dabeer [4] study the performance of an algorithm called Popularity Amongst Friends, examining its ability to predict binary ratings in an asymptotic informationtheoretic setting. In contrast, we seek to understand the finite-time performance of such systems. Dabeer [11] uses a model similar to ours and studies online collaborative filtering with a moving horizon cost in the limit of small noise using an algorithm that knows the numbers of user types and item types. We do not model different item types, our algorithm is oblivious to the number of user types, and our performance metric is different. Another related work is by Deshpande and Montanari [12], who study online recommendations as a linear bandit problem; their method, however, does not actually use any collaboration beyond a pre-processing step in which offline collaborative filtering (specifically matrix completion) is solved to compute feature vectors for items.\nOur work also relates to the problem of learning mixture distributions (c.f., [10, 18, 5, 2]), where one observes samples from a mixture distribution and the goal is to learn the mixture components and weights. Existing results assume that one has access to the entire high-dimensional sample or that the samples are produced in an exogenous manner (not chosen by the algorithm). Neither assumption holds in our setting, as we only see each user\u2019s revealed ratings thus far and not the user\u2019s entire preference vector, and the recommendation algorithm affects which samples are observed (by choosing which item ratings are revealed for each user). These two aspects make our setting more challenging than the standard setting for learning mixture distributions. However, our goal is more modest. Rather than learning the k item preference vectors, we settle for classifying them as likable or unlikable. Despite this, we suspect having two types of exploration to be useful in general for efficiently learning mixture distributions in the active learning setting.\nAcknowledgements. This work was supported in part by NSF grant CNS-1161964 and by Army Research Office MURI Award W911NF-11-1-0036. GHC was supported by an NDSEG fellowship."}, {"heading": "A Appendix", "text": "Throughout our derivations, if it is clear from context, we omit the argument (t) indexing time, for example writing Yu instead of Yu(t)."}, {"heading": "A.1 Proof of Lemma 1", "text": "We reproduce Lemma 1 below for ease of presentation. Lemma 1. For user u, after\nt \u2265 ( 2 log(10kmn\u03b1/\u2206) \u22064(1\u2212 \u03b3)2 )1/(1\u2212\u03b1)\ntime steps,\nP(Egood(u, t)) \u2265 1\u2212 exp ( \u2212 n\n8k\n) \u2212 12 exp ( \u2212 \u2206\n4(1\u2212 \u03b3)2t1\u2212\u03b1 20\n) .\nTo derive this lower bound on the probability that the good neighborhood event Egood(u, t) occurs, we prove four lemmas (Lemmas 4, 5, 6, and 7). Before doing so, we define a constant that will appear several times: \u03b2 , exp(\u2212\u22064(1\u2212 \u03b3)2t1\u2212\u03b1). We begin by ensuring that enough users from each of the k user types are in the system. Lemma 4. For a user u,\nP (\nuser u\u2019s type has \u2264 n 2k\nusers ) \u2264 exp ( \u2212 n\n8k\n) .\nProof. Let N be the number of users from user u\u2019s type. User types are equiprobable, so N \u223c Bin(n, 1k ). By a Chernoff bound,\nP ( N \u2264 n\n2k\n) \u2264 exp ( \u2212 1\n2 (nk \u2212 n2k )2 n k\n) = exp ( \u2212 n\n8k\n) .\nNext, we ensure that sufficiently many items have been jointly explored across all users. This will subsequently be used for bounding both the number of good neighbors and the number of bad neighbors. Lemma 5. After t time steps,\nP(fewer than t1\u2212\u03b1/2 jointly explored items) \u2264 exp(\u2212t1\u2212\u03b1/20).\nProof. Let Zs be the indicator random variable for the event that the algorithm jointly explores at time s. Thus, the number of jointly explored items up to time t is \u2211t s=1 Zs. By our choice for the time-varying joint exploration probability \u03b5J , we have P(Zs = 1) = \u03b5J(s) = 1s\u03b1 and P(Zs = 0) = 1\u2212 1s\u03b1 . Note that the centered random variable Z\u0304s = E[Zs]\u2212Zs = 1s\u03b1 \u2212Zs has zero mean, and |Z\u0304s| \u2264 1 with probability 1. Then,\nP ( t\u2211 s=1 Zs < 1 2 t1\u2212\u03b1 ) = P ( t\u2211 s=1 Z\u0304s > t\u2211 s=1 E[Zs]\u2212 1 2 t1\u2212\u03b1 ) (i) \u2264 P ( t\u2211 s=1 Z\u0304s > 1 2 t1\u2212\u03b1 ) (ii)\n\u2264 exp ( \u2212\n1 8 t 2(1\u2212\u03b1)\u2211t s=1 E[Z\u03042s ] + 1 6 t 1\u2212\u03b1\n) (iii) \u2264 exp ( \u2212\n1 8 t\n2(1\u2212\u03b1)\nt1\u2212\u03b1 1\u2212\u03b1 + 1 6 t 1\u2212\u03b1 ) = exp ( \u2212 3(1\u2212 \u03b1)t 1\u2212\u03b1\n4(7\u2212 \u03b1)\n) (iv)\n\u2264 exp(\u2212t1\u2212\u03b1/20),\nwhere step (i) uses the fact that \u2211t s=1 E[Zs] = \u2211t s=1 1/s\n\u03b1 \u2265 t/t\u03b1 = t1\u2212\u03b1, step (ii) is Bernstein\u2019s inequality, step (iii) uses the fact that \u2211t s=1 E[Z\u03042s ] \u2264 \u2211t s=1 E[Z2s ] = \u2211t s=1 1/s\n\u03b1 \u2264 t1\u2212\u03b1/(1\u2212\u03b1), and step (iv) uses the fact that \u03b1 \u2264 4/7. (We remark that the choice of constant 4/7 isn\u2019t special; changing it would simply modify the constant in the decaying exponentially to potentially no longer be 1/20).\nAssuming that the bad events for the previous two lemmas do not occur, we now provide a lower bound on the number of good neighbors that holds with high probability.\nLemma 6. Suppose that there are no \u2206-ambiguous items, that there are more than n2k users of user u\u2019s type, and that all users have rated at least t1\u2212\u03b1/2 items as part of joint exploration. For user u, let ngood be the number of \u201cgood\u201d neighbors of user u. If \u03b2 \u2264 110 , then\nP ( ngood \u2264 (1\u2212 \u03b2) n\n4k\n) \u2264 10\u03b2.\nWe defer the proof of Lemma 6 to Appendix A.1.1.\nFinally, we verify that the number of bad neighbors for any user is not too large, again conditioned on there being enough jointly explored items.\nLemma 7. Suppose that the minimum number of rated items in common between any pair of users is t1\u2212\u03b1/2 and suppose that \u03b3-incoherence holds for some \u03b3 \u2208 [0, 1). For user u, let nbad be the number of \u201cbad\u201d neighbors of user u. Then\nP(nbad \u2265 n \u221a \u03b2) \u2264 \u221a \u03b2.\nWe defer the proof of Lemma 7 to Appendix A.1.2.\nWe now prove Lemma 1, which union bounds over the four bad events of Lemmas 4, 5, 6, and 7. Recall that the good neighborhood event Egood(u, t) holds if at time t, user u has more than n5k good neighbors and less than \u2206tn 1\u2212\u03b1\n10km bad neighbors. By assuming that the four bad events don\u2019t happen, then Lemma 6 tells us that there are more than (1 \u2212 \u03b2) n4k good neighbors provided that \u03b2 \u2264 110 . Thus, to ensure that there are more than n5k good neighbors, it suffices to have (1 \u2212 \u03b2) n4k \u2265 n5k , which happens when \u03b2 \u2264 15 , but we already require that \u03b2 \u2264 110 . Similarly, Lemma 7 tells us that there are fewer than n \u221a \u03b2 bad neighbors, so to ensure that there are fewer than \u2206tn 1\u2212\u03b1\n10km bad neighbors it suffices to have n \u221a \u03b2 \u2264 \u2206tn1\u2212\u03b110km , which happens when \u03b2 \u2264 ( \u2206t10kmn\u03b1 )2. We can satisfy all constraints on \u03b2 by asking that \u03b2 \u2264 ( \u220610kmn\u03b1 )2, which is tantamount to asking that\nt \u2265 ( 2 log(10kmn\u03b1/\u2206) \u22064(1\u2212 \u03b3)2 )1/(1\u2212\u03b1)\nsince \u03b2 = exp(\u2212\u22064(1\u2212 \u03b3)2t1\u2212\u03b1). Finally, with t satisfying the inequality above, the union bound over the four bad events can be further bounded to complete the proof:\nP(Egood(u, t)) \u2265 1\u2212 exp ( \u2212 n\n8k\n) \u2212 exp(\u2212t1\u2212\u03b1/20)\u2212 10\u03b2 \u2212 \u221a \u03b2\n\u2265 1\u2212 exp ( \u2212 n\n8k\n) \u2212 12 exp ( \u2212 \u2206\n4(1\u2212 \u03b3)2t1\u2212\u03b1 20\n) ."}, {"heading": "A.1.1 Proof of Lemma 6", "text": "We begin with a preliminary lemma that upper-bounds the probability of two users of the same type not being declared as neighbors.\nLemma 8. Suppose that there are no \u2206-ambiguous items for any of the user types. Let users u and v be of the same type, and suppose that they have rated at least \u03930 items in common (explored jointly). Then for \u03b8 \u2208 (0, 4\u22062),\nP(users u and v are not declared as neighbors) \u2264 exp ( \u2212 (4\u2206\n2 \u2212 \u03b8)2 2 \u03930\n) .\nProof. Let us first suppose that users u and v have rated exactly \u03930 items in common. The two users are not declared to be neighbors if \u3008Y\u0303u, Y\u0303v\u3009 < \u03b8\u03930. Let \u2126 \u2286 [m] such that |\u2126| = \u03930. We have\nE [ \u3008Y\u0303u, Y\u0303v\u3009 \u2223\u2223supp(Y\u0303u) \u2229 supp(Y\u0303v) = \u2126] = \u2211 i\u2208\u2126 E[Y\u0303uiY\u0303vi | Y\u0303ui 6= 0, Y\u0303vi 6= 0]\n= \u2211 i\u2208\u2126 (p2ui + (1\u2212 pui)2 \u2212 2pui(1\u2212 pui))\n= 4 \u2211 i\u2208\u2126 ( pui \u2212 1 2 )2 . (2)\nSince \u3008Y\u0303u, Y\u0303v\u3009 = \u2211 i\u2208\u2126 Y\u0303uiY\u0303vi is the sum of terms {Y\u0303uiY\u0303vi}i\u2208\u2126 that are each bounded within [\u22121, 1], Hoeffding\u2019s inequality yields\nP ( \u3008Y\u0303u, Y\u0303v\u3009 \u2264 \u03b8\u03930 \u2223\u2223 supp(Y\u0303u) \u2229 supp(Y\u0303v) = \u2126) \u2264 exp(\u2212 [ equation (2)\ufe37 \ufe38\ufe38 \ufe37 4 \u2211 i\u2208\u2126 ( pgi \u2212 12 )2\u2212\u03b8\u03930]2 2\u03930 ) . (3)\nAs there are no \u2206-ambiguous items, \u2206 \u2264 |pui \u2212 1/2| for all users u and items i. Thus, our choice of \u03b8 guarantees that\n4 \u2211 i\u2208\u2126 ( pui \u2212 1 2 )2 \u2212 \u03b8\u03930 \u2265 4\u03930\u22062 \u2212 \u03b8\u03930 = (4\u22062 \u2212 \u03b8)\u03930 \u2265 0. (4)\nCombining inequalities (3) and (4), and observing that the above holds for all subsets \u2126 of cardinality \u03930, we obtain the desired bound on the probability that users u and v are not declared as neighbors:\nP(\u3008Y\u0303u, Y\u0303v\u3009 \u2264 \u03b8\u03930 | |supp(Y\u0303u) \u2229 supp(Y\u0303v)| = \u03930) \u2264 exp ( \u2212 (4\u2206\n2 \u2212 \u03b8)2 2 \u03930\n) . (5)\nNow to handle the case that users u and v have jointly rated more than \u03930 items, observe that, with shorthand \u0393uv , |supp(Y\u0303u) \u2229 supp(Y\u0303v)|,\nP(u and v not declared neighbors | pu = pv,\u0393uv \u2265 \u03930) = P(\u3008Y\u0303u, Y\u0303v\u3009 < \u03b8\u0393uv | pu = pv, \u0393uv \u2265 \u03930)\n= P(\u3008Y\u0303u, Y\u0303v\u3009 \u2264 \u03b8\u0393uv,\u0393uv \u2265 \u03930 | pu = pv)\nP(\u0393uv \u2265 \u03930 | pu = pv)\n=\n\u2211m `=\u03930\nP(\u3008Y\u0303u, Y\u0303v\u3009 \u2264 \u03b8`,\u0393uv = ` | pu = pv) P(\u0393uv \u2265 \u03930 | pu = pv)\n=\n\u2211m `=\u03930 [ P(\u0393uv = ` | pu = pv) \u00b7P(\u3008Y\u0303u, Y\u0303v\u3009 \u2264 \u03b8` | pu = pv,\u0393uv = `)\n] P(\u0393uv \u2265 \u03930 | pu = pv)\n\u2264 \u2211m `=\u03930 P(\u0393uv = ` | pu = pv) exp ( \u2212 (4\u2206 2\u2212\u03b8)2 2 \u03930 ) P(\u0393uv \u2265 \u03930 | pu = pv)\nby inequality (5) = exp ( \u2212 (4\u2206\n2 \u2212 \u03b8)2 2 \u03930\n) .\nWe now prove Lemma 6.\nSuppose that the event in Lemma 4 holds. Let G be n2k users from the same user type as user u; there could be more than n2k such users but it suffices to consider n 2k of them. We define an indicator random variable\nGv , 1{users u and v are neighbors} = 1{\u3008Y\u0303 (t)u , Y\u0303 (t)v \u3009 \u2265 \u03b8t1\u2212\u03b1/2}.\nThus, the number of good neighbors of user u is lower-bounded by W = \u2211 v\u2208G Gv . Note that the Gv\u2019s are not independent. To arrive at a lower bound for W that holds with high probability, we use Chebyshev\u2019s inequality:\nP(W \u2212 E[W ] \u2264 \u2212E[W ]/2) \u2264 4Var(W ) (E[W ])2 . (6)\nLet \u03b2 = exp(\u2212(4\u22062 \u2212 \u03b8)2\u03930/2) be the probability bound from Lemma 8, where by our choice of \u03b8 = 2\u22062(1 + \u03b3) and with \u03930 = t1\u2212\u03b1/2, we have \u03b2 = exp(\u2212\u22064(1\u2212 \u03b3)2t1\u2212\u03b1). Applying Lemma 8, we have E[W ] \u2265 (1\u2212 \u03b2) n2k , and hence\n(E[W ])2 \u2265 (1\u2212 2\u03b2) n 2\n4k2 . (7)\nWe now upper-bound Var(W ) = \u2211 v\u2208G Var(Gv) + \u2211 v 6=w Cov(Gv, Gw).\nSince Gv = G2v , Var(Gv) = E[Gv]\u2212 E[Gv]2 = E[Gv]\ufe38 \ufe37\ufe37 \ufe38\n\u22641\n(1\u2212 E[Gv]) \u2264 \u03b2,\nwhere the last step uses Lemma 8.\nMeanwhile,\nCov(Gv, Gw) = E[GvGw]\u2212 E[Gv]E[Gw] \u2264 1\u2212 (1\u2212 \u03b2)2 \u2264 2\u03b2. Putting together the pieces,\nVar(W ) \u2264 n 2k \u00b7 \u03b2 + n 2k \u00b7 ( n 2k \u2212 1 ) \u00b7 2\u03b2 \u2264 n 2 2k2 \u00b7 \u03b2. (8)\nPlugging (7) and (8) into (6) gives\nP(W \u2212 E[W ] \u2264 \u2212E[W ]/2) \u2264 8\u03b2 1\u2212 2\u03b2 \u2264 10\u03b2,\nprovided that \u03b2 \u2264 110 . Thus, ngood \u2265W \u2265 E[W ]/2 \u2265 (1\u2212 \u03b2) n4k with probability at least 1\u2212 10\u03b2."}, {"heading": "A.1.2 Proof of Lemma 7", "text": "We begin with a preliminary lemma that upper-bounds the probability of two users of different types being declared as neighbors. Lemma 9. Let users u and v be of different types, and suppose that they have rated at least \u03930 items in common via joint exploration. Further suppose \u03b3-incoherence is satisfied for \u03b3 \u2208 [0, 1). If \u03b8 \u2265 4\u03b3\u22062, then\nP(users u and v are declared to be neighbors) \u2264 exp ( \u2212 (\u03b8 \u2212 4\u03b3\u2206 2)2\n2 \u03930\n) .\nProof. As with the proof of Lemma 8, we first analyze the case where users u and v have rated exactly \u03930 items in common. Users u and v are declared to be neighbors if \u3008Y\u0303u, Y\u0303v\u3009 \u2265 \u03b8\u03930. We now crucially use the fact that joint exploration chooses these \u03930 items as a random subset of the m items. For our random permutation \u03c3 of m items, we have \u3008Y\u0303u, Y\u0303v\u3009 =\n\u2211\u03930 i=1 Y\u0303u,\u03c3(i)Y\u0303v,\u03c3(i) =\u2211\u03930\ni=1 Yu,\u03c3(i)Yv,\u03c3(i), which is the sum of terms {Yu,\u03c3(i)Yv,\u03c3(i)}\u03930i=1 that are each bounded within [\u22121, 1] and drawn without replacement from a population of all possible items. Hoeffding\u2019s inequality (which also applies to the current scenario of sampling without replacement [14]) yields\nP ( \u3008Y\u0303u, Y\u0303v\u3009 \u2265 \u03b8\u03930 | pu 6= pv ) \u2264 exp ( \u2212 ( \u03b8\u03930 \u2212 E[\u3008Y\u0303u, Y\u0303v\u3009 | pu 6= pv] )2 2\u03930 ) . (9)\nBy \u03b3-incoherence and our choice of \u03b8, \u03b8\u03930 \u2212 E [ \u3008Y\u0303u, Y\u0303v\u3009 | pu 6= pv ] \u2265 \u03b8\u03930 \u2212 4\u03b3\u22062\u03930 = (\u03b8 \u2212 4\u03b3\u22062)\u03930 \u2265 0. (10)\nAbove, we used the fact that \u03930 randomly explored items are a random subset ofm items, and hence E [\n1 \u0393 0 \u3008Y\u0303u, Y\u0303v\u3009\n] = E [ 1 m \u3008Yu, Yv\u3009 ] ,\nwith Yu, Yv representing the entire (random) vector of preferences of u and v respectively.\nCombining inequalities (9) and (10) yields\nP ( \u3008Y\u0303u, Y\u0303v\u3009 \u2265 \u03b8\u03930 | pu 6= pv ) \u2264 exp ( \u2212 (\u03b8 \u2212 4\u03b3\u2206 2)2\n2 \u03930\n) .\nA similar argument as the ending of Lemma 8\u2019s proof establishes that the bound holds even if users u and v have jointly explored more than \u03930 items.\nWe now prove Lemma 7.\nLet \u03b2 = exp(\u2212(\u03b8\u2212 4\u03b3\u22062)2\u03930/2) be the probability bound from Lemma 9, where by our choice of \u03b8 = 2\u22062(1 + \u03b3) and with \u03930 = t1\u2212\u03b1/2, we have \u03b2 = exp(\u2212\u22064(1\u2212 \u03b3)2t1\u2212\u03b1). By Lemma 9, for a pair of users u and v with at least t1\u2212\u03b1/2 items jointly explored, the probability that they are erroneously declared neighbors is upper-bounded by \u03b2.\nDenote the set of users of type different from u by B, and write nbad = \u2211 v\u2208B 1{u and v are declared to be neighbors},\nwhence E[nbad] \u2264 n\u03b2. Markov\u2019s inequality gives\nP(nbad \u2265 n \u221a \u03b2) \u2264 E[nbad]\nn \u221a \u03b2 \u2264 n\u03b2 n \u221a \u03b2\n= \u221a \u03b2 ,\nproving the lemma."}, {"heading": "A.2 Proof of Lemma 2", "text": "We reproduce Lemma 2 below. Lemma 2. For user u at time t, if the good neighborhood event Egood(u, t) holds and t \u2264 \u00b5m, then\nP(Xut = 1) \u2265 1\u2212 2m exp ( \u2212 \u2206 2tn1\u2212\u03b1\n40km ) \u2212 1 t\u03b1 \u2212 1 n\u03b1 .\nWe begin by checking that when the good neighborhood event Egood(u, t) holds for user u, the items have been rated enough times by the good neighbors. Lemma 10. For user u at time t, suppose that the good neighborhood event Egood(u, t) holds. Then for a given item i,\nP ( item i has \u2264 tn 1\u2212\u03b1\n10km ratings from good neighbors of u\n) \u2264 exp ( \u2212 tn 1\u2212\u03b1\n40km\n) .\nProof. The number of user u\u2019s good neighbors who have rated item i stochastically dominates a Bin( n5k , \u03b5R(n)t m ) random variable, where \u03b5R(n)t m = t mn\u03b1 (here, we have critically used the lower bound on the number of good neighbors user u has when the good neighborhood event Egood(u, t) holds). By a Chernoff bound,\nP ( Bin ( n\n5k ,\nt\nmn\u03b1\n) \u2264 tn 1\u2212\u03b1\n10km\n) \u2264 exp ( \u2212 1\n2\n( tn 1\u2212\u03b1 5km \u2212 tn 1\u2212\u03b1 10km ) 2\ntn1\u2212\u03b1\n5km\n) \u2264 exp ( \u2212 tn 1\u2212\u03b1\n40km\n) .\nNext, we show a sufficient condition for which the algorithm correctly classifies every item as likable or unlikable for user u.\nLemma 11. Suppose that there are no \u2206-ambiguous items. For user u at time t, suppose that the good neighborhood event Egood(u, t) holds. Provided that every item i \u2208 [m] has more than tn 1\u2212\u03b1\n10km\nratings from good neighbors of user u, then with probability at least 1 \u2212 m exp(\u2212\u22062tn1\u2212\u03b120km ), we have that for every item i \u2208 [m],\np\u0303ui > 1\n2 if item i is likable by user u,\np\u0303ui < 1\n2 if item i is unlikable by user u.\nProof. Let A be the number of ratings that good neighbors of user u have provided. Suppose item i is likable by user u. Then when we condition on A = a0 , d tn 1\u2212\u03b1 10km e, p\u0303ui stochastically dominates\nqui , Bin(a0, pui) a0 + \u2206a0 = Bin(a0, pui) (1 + \u2206)a0 ,\nwhich is the worst-case variant of p\u0303ui that insists that all \u2206a0 bad neighbors provided rating \u201c\u22121\u201d for likable item i (here, we have critically used the upper bound on the number of bad neighbors user u has when the good neighborhood event Egood(u, t) holds). Then\nP(qui \u2264 1\n2 | A = a0) = P\n( Bin(a0, pui) \u2264\n(1 + \u2206)a0 2 \u2223\u2223\u2223\u2223 A = a0) = P ( a0pui \u2212 Bin(a0, pui) \u2265 a0 ( pui \u2212 1\n2 \u2212 \u2206 2 ) \u2223\u2223\u2223\u2223 A = a0) (i)\n\u2264 exp ( \u2212 2a0 ( pui \u2212 1\n2 \u2212 \u2206 2 )2) (ii)\n\u2264 exp ( \u2212 1\n2 a0\u2206\n2 )\n(iii) \u2264 exp ( \u2212 \u2206 2tn1\u2212\u03b1\n20km\n) ,\nwhere step (i) is Hoeffding\u2019s inequality, step (ii) follows from item i being likable by user u (i.e., pui \u2265 12 + \u2206), and step (iii) is by our choice of a0. Conclude then that\nP(p\u0303ui \u2264 1\n2 | A = a0) \u2264 exp\n( \u2212 \u2206 2tn1\u2212\u03b1\n20km\n) .\nFinally,\nP ( p\u0303ui \u2264 1\n2 \u2223\u2223\u2223 A \u2265 tn1\u2212\u03b1 10km ) = \u2211\u221e a=a0 P(A = a)P(p\u0303ui \u2264 12 | A = a) P(A \u2265 tn1\u2212\u03b110km )\n\u2264 \u2211\u221e a=a0\nP(A = a) exp(\u2212\u22062tn1\u2212\u03b120km ) P(A \u2265 tn1\u2212\u03b110km )\n= exp ( \u2212 \u2206 2tn1\u2212\u03b1\n20km\n) .\nA similar argument holds for when item i is unlikable. Union-bounding over all m items yields the claim.\nWe now prove Lemma 2. First off, provided that t \u2264 \u00b5m, we know that there must still exist an item likable by user u that user u has yet to consume. For user u at time t, supposing that event Egood(u, t) holds, then every item has been rated more than tn 1\u2212\u03b1\n10km times by the good neighbors of user u with probability at least 1 \u2212 m exp(\u2212 tn1\u2212\u03b140km ). This follows from union-bounding over the m items with Lemma 10. Applying Lemma 11, and noting that we only exploit with probability 1\u2212 \u03b5J(t)\u2212 \u03b5R(n) = 1\u2212 1/t\u03b1 \u2212 1/n\u03b1, we finish the proof:\nP(Xut = 1) \u2265 1\u2212m exp ( \u2212 tn 1\u2212\u03b1\n40km\n) \u2212m exp ( \u2212 \u2206 2tn1\u2212\u03b1\n20km ) \u2212 1 t\u03b1 \u2212 1 n\u03b1\n\u2265 1\u2212 2m exp ( \u2212 \u2206 2tn1\u2212\u03b1\n40km ) \u2212 1 t\u03b1 \u2212 1 n\u03b1 ."}, {"heading": "A.3 Experimental Results", "text": "We demonstrate our algorithm COLLABORATIVE-GREEDY on two datasets, showing that they have comparable performance and that they both outperform two existing recommendation algorithms Popularity Amongst Friends (PAF) [4] and Deshpande and Montanari\u2019s method (DM) [12]. At each time step, PAF finds nearest neighbors (\u201cfriends\u201d) for every user and recommends to a user the \u201cmost popular\u201d item, i.e., the one with the most number of +1 ratings, among the user\u2019s friends. DM doesn\u2019t do any collaboration beyond a preprocessing step that computes item feature vectors via matrix completion. Then during online recommendation, DM learns user feature vectors over time with the help of item feature vectors and recommends an item to each user based on whether it aligns well with the user\u2019s feature vector.\nWe simulate an online recommendation system based on movie ratings from the Movielens10m and Netflix datasets, each of which provides a sparsely filled user-by-movie rating matrix with ratings out of 5 stars. Unfortunately, existing collaborative filtering datasets such as the two we consider don\u2019t offer the interactivity of a real online recommendation system, nor do they allow us to reveal the rating for an item that a user didn\u2019t actually rate. For simulating an online system, the former issue can be dealt with by simply revealing entries in the user-by-item rating matrix over time. We address the latter issue by only considering a dense \u201ctop users vs. top items\u201d subset of each dataset. In particular, we consider only the \u201ctop\u201d users who have rated the most number of items, and the \u201ctop\u201d items that have received the most number of ratings. While this dense part of the dataset is unrepresentative of the rest of the dataset, it does allow us to use actual ratings provided by users without synthesizing any ratings.\nAn initial question to ask is whether the dense movie ratings matrices we consider could be reasonably explained by our latent source model. We automatically learn the structure of these matrices using the method by Grosse et al. [13] and find Bayesian clustered tensor factorization (BCTF) to accurately model the data. This finding isn\u2019t surprising as BCTF has previously been used to model movie ratings data [21]. BCTF effectively clusters both users and movies so that we get structure such as that shown in Figure 1(a) for the Movielens10m \u201ctop users vs. top items\u201d matrix. Our latent source model could reasonably model movie ratings data as it only assumes clustering of users.\nFollowing the experimental setup of [4], we quantize a rating of 4 stars or more to be +1 (likeable), and a rating of 3 stars or less to be \u22121 (unlikeable). While we look at a dense subset of each dataset, there are still missing entries. If a user u hasn\u2019t rated item j in the dataset, then we set the corresponding true rating to 0, meaning that in our simulation, upon recommending item j to user u, we receive 0 reward, but we still mark that user u has consumed item j; thus, item j can no longer be recommended to user u. For both Movielens10m and Netflix datasets, we consider the top n = 200 users and the top m = 500 movies. For Movielens10m, the resulting user-by-rating matrix has 80.7% nonzero entries. For Netflix, the resulting matrix has 86.0% nonzero entries. For an algorithm that recommends item \u03c0ut to user u at time t, we measure the algorithm\u2019s average cumulative reward up to time T as\n1\nn T\u2211 t=1 n\u2211 u=1 Y (T )u\u03c0ut ,\nwhere we average over users.\nFor all methods, we recommend items until we reach time T = 500, i.e., we make movie recommendations until each user has seen all m = 500 movies. We disallow the matrix completion step for DM to see the users that we actually test on, but we allow it to see the the same items as what is in the simulated online recommendation system in order to compute these items\u2019 feature vectors (using the rest of the users in the dataset). Furthermore, when a rating is revealed, we provide DM both the thresholded rating and the non-thresholded rating, the latter of which DM uses to estimate user feature vectors over time.\nParameters \u03b8 and \u03b1 for and COLLABORATIVE-GREEDY are chosen using training data: We sweep over the two parameters on training data consisting of 200 users that are the \u201cnext top\u201d 200 users, i.e., ranked 201 to 400 in number movie ratings they provided. For simplicity, we discretize our search space to \u03b8 \u2208 {0.0, 0.1, . . . , 1.0} and \u03b1 \u2208 {0.1, 0.2, 0.3, 0.4, 0.5}. We choose the parameter setting achieving the highest area under the cumulative reward curve. For both Movielens10m and Netflix datasets, this corresponded to setting \u03b8 = 0.0 and \u03b1 = 0.5 for COLLABORATIVE-GREEDY.\nIn contrast, the parameters for PAF and DM are chosen to be the best parameters for the test data among a wide range of parameters. The results are shown in Figure 2. We find that our algorithm COLLABORATIVE-GREEDY outperforms PAF and DM. We remark that the curves are roughly concave, which is expected since once we\u2019ve finished recommending likeable items (roughly around time step 300), we end up recommending mostly unlikeable items until we\u2019ve exhausted all the items."}], "references": [{"title": "A preliminary study on a recommender system for the million songs dataset challenge", "author": ["Fabio Aiolli"], "venue": "In Proceedings of the Italian Information Retrieval Workshop,", "citeRegEx": "1", "shortCiteRegEx": "1", "year": 2013}, {"title": "Tensor decompositions for learning latent variable", "author": ["Anima Anandkumar", "Rong Ge", "Daniel Hsu", "Sham M. Kakade", "Matus Telgarsky"], "venue": null, "citeRegEx": "2", "shortCiteRegEx": "2", "year": 2012}, {"title": "Finite-time analysis of the multiarmed bandit problem", "author": ["Peter Auer", "Nicol\u00f2 Cesa-Bianchi", "Paul Fischer"], "venue": "Machine Learning,", "citeRegEx": "3", "shortCiteRegEx": "3", "year": 2002}, {"title": "Analysis of a collaborative filter based on popularity amongst neighbors", "author": ["Kishor Barman", "Onkar Dabeer"], "venue": "IEEE Transactions on Information Theory,", "citeRegEx": "4", "shortCiteRegEx": "4", "year": 2012}, {"title": "Polynomial learning of distribution families", "author": ["Mikhail Belkin", "Kaushik Sinha"], "venue": "In Foundations of Computer Science (FOCS),", "citeRegEx": "5", "shortCiteRegEx": "5", "year": 2010}, {"title": "The million song dataset", "author": ["Thierry Bertin-Mahieux", "Daniel P.W. Ellis", "Brian Whitman", "Paul Lamere"], "venue": "In Proceedings of the 12th International Conference on Music Information Retrieval", "citeRegEx": "6", "shortCiteRegEx": "6", "year": 2011}, {"title": "Statistical analysis of k-nearest neighbor collaborative recommendation", "author": ["G\u00e9rard Biau", "Beno\u0131\u0302t Cadre", "Laurent Rouvi\u00e8re"], "venue": "The Annals of Statistics,", "citeRegEx": "7", "shortCiteRegEx": "7", "year": 2010}, {"title": "Regret analysis of stochastic and nonstochastic multi-armed bandit problems", "author": ["S\u00e9bastien Bubeck", "Nicol\u00f2 Cesa-Bianchi"], "venue": "Foundations and Trends in Machine Learning,", "citeRegEx": "8", "shortCiteRegEx": "8", "year": 2012}, {"title": "Learning mixtures of product distributions using correlations and independence", "author": ["Kamalika Chaudhuri", "Satish Rao"], "venue": "In Conference on Learning Theory,", "citeRegEx": "10", "shortCiteRegEx": "10", "year": 2008}, {"title": "Adaptive collaborating filtering: The low noise regime", "author": ["Onkar Dabeer"], "venue": "In IEEE International Symposium on Information Theory, pages 1197\u20131201,", "citeRegEx": "11", "shortCiteRegEx": "11", "year": 2013}, {"title": "Linear bandits in high dimension and recommendation", "author": ["Yash Deshpande", "Andrea Montanari"], "venue": null, "citeRegEx": "12", "shortCiteRegEx": "12", "year": 2013}, {"title": "Exploiting compositionality to explore a large space of model structures", "author": ["Roger B. Grosse", "Ruslan Salakhutdinov", "William T. Freeman", "Joshua B. Tenenbaum"], "venue": "In Uncertainty in Artificial Intelligence,", "citeRegEx": "13", "shortCiteRegEx": "13", "year": 2012}, {"title": "Probability inequalities for sums of bounded random variables", "author": ["Wassily Hoeffding"], "venue": "Journal of the American statistical association,", "citeRegEx": "14", "shortCiteRegEx": "14", "year": 1963}, {"title": "Regret bounds for sleeping experts and bandits", "author": ["Robert Kleinberg", "Alexandru Niculescu-Mizil", "Yogeshwer Sharma"], "venue": "Machine Learning,", "citeRegEx": "15", "shortCiteRegEx": "15", "year": 2010}, {"title": "The BellKor solution to the Netflix grand prize. http://www.netflixprize.com/ assets/GrandPrize2009_BPC_BellKor.pdf", "author": ["Yehuda Koren"], "venue": null, "citeRegEx": "16", "shortCiteRegEx": "16", "year": 2009}, {"title": "Amazon.com recommendations: item-to-item collaborative filtering", "author": ["Greg Linden", "Brent Smith", "Jeremy York"], "venue": "IEEE Internet Computing,", "citeRegEx": "17", "shortCiteRegEx": "17", "year": 2003}, {"title": "Settling the polynomial learnability of mixtures of gaussians", "author": ["Ankur Moitra", "Gregory Valiant"], "venue": "Proceedings of the 51st Annual IEEE Symposium on Foundations of Computer Science,", "citeRegEx": "18", "shortCiteRegEx": "18", "year": 2010}, {"title": "The pragmatic theory solution to the netflix grand prize", "author": ["Martin Piotte", "Martin Chabbert"], "venue": "http:// www.netflixprize.com/assets/GrandPrize2009_BPC_PragmaticTheory.pdf,", "citeRegEx": "19", "shortCiteRegEx": "19", "year": 2009}, {"title": "Grouplens: An open architecture for collaborative filtering of netnews", "author": ["Paul Resnick", "Neophytos Iacovou", "Mitesh Suchak", "Peter Bergstrom", "John Riedl"], "venue": "In Proceedings of the 1994 ACM Conference on Computer Supported Cooperative Work, CSCW", "citeRegEx": "20", "shortCiteRegEx": "20", "year": 1994}, {"title": "Modelling relational data using bayesian clustered tensor factorization", "author": ["Ilya Sutskever", "Ruslan Salakhutdinov", "Joshua B. Tenenbaum"], "venue": "In NIPS,", "citeRegEx": "21", "shortCiteRegEx": "21", "year": 2009}, {"title": "Reinforcement Learning: An Introduction", "author": ["Richard S. Sutton", "Andrew G. Barto"], "venue": null, "citeRegEx": "22", "shortCiteRegEx": "22", "year": 1998}, {"title": "On the Likelihood that one Unknown Probability Exceeds", "author": ["William R. Thompson"], "venue": "Another in View of the Evidence of Two Samples. Biometrika,", "citeRegEx": "23", "shortCiteRegEx": "23", "year": 1933}], "referenceMentions": [{"referenceID": 18, "context": "Collaborative filtering has been used extensively for decades now including in the GroupLens news recommendation system [20], Amazon\u2019s item recommendation system [17], the Netflix Prize winning algorithm by BellKor\u2019s Pragmatic Chaos [16, 24, 19], and a recent song recommendation system [1] that won the Million Song Dataset Challenge [6].", "startOffset": 120, "endOffset": 124}, {"referenceID": 15, "context": "Collaborative filtering has been used extensively for decades now including in the GroupLens news recommendation system [20], Amazon\u2019s item recommendation system [17], the Netflix Prize winning algorithm by BellKor\u2019s Pragmatic Chaos [16, 24, 19], and a recent song recommendation system [1] that won the Million Song Dataset Challenge [6].", "startOffset": 162, "endOffset": 166}, {"referenceID": 14, "context": "Collaborative filtering has been used extensively for decades now including in the GroupLens news recommendation system [20], Amazon\u2019s item recommendation system [17], the Netflix Prize winning algorithm by BellKor\u2019s Pragmatic Chaos [16, 24, 19], and a recent song recommendation system [1] that won the Million Song Dataset Challenge [6].", "startOffset": 233, "endOffset": 245}, {"referenceID": 17, "context": "Collaborative filtering has been used extensively for decades now including in the GroupLens news recommendation system [20], Amazon\u2019s item recommendation system [17], the Netflix Prize winning algorithm by BellKor\u2019s Pragmatic Chaos [16, 24, 19], and a recent song recommendation system [1] that won the Million Song Dataset Challenge [6].", "startOffset": 233, "endOffset": 245}, {"referenceID": 0, "context": "Collaborative filtering has been used extensively for decades now including in the GroupLens news recommendation system [20], Amazon\u2019s item recommendation system [17], the Netflix Prize winning algorithm by BellKor\u2019s Pragmatic Chaos [16, 24, 19], and a recent song recommendation system [1] that won the Million Song Dataset Challenge [6].", "startOffset": 287, "endOffset": 290}, {"referenceID": 5, "context": "Collaborative filtering has been used extensively for decades now including in the GroupLens news recommendation system [20], Amazon\u2019s item recommendation system [17], the Netflix Prize winning algorithm by BellKor\u2019s Pragmatic Chaos [16, 24, 19], and a recent song recommendation system [1] that won the Million Song Dataset Challenge [6].", "startOffset": 335, "endOffset": 338}, {"referenceID": 0, "context": "The ratings are noisy: the latent item preferences for user u are represented by a length-m vector pu \u2208 [0, 1], where user u likes item i with probability pui, independently across items.", "startOffset": 104, "endOffset": 110}, {"referenceID": 19, "context": "We remark that there is evidence suggesting real movie recommendation data to be well modeled by clustering of both users and items [21].", "startOffset": 132, "endOffset": 136}, {"referenceID": 21, "context": "A fundamental difference between our setup and that of the standard stochastic multi-armed bandit problem [23, 8] is that the latter allows each item to be recommended an infinite number of times.", "startOffset": 106, "endOffset": 113}, {"referenceID": 7, "context": "A fundamental difference between our setup and that of the standard stochastic multi-armed bandit problem [23, 8] is that the latter allows each item to be recommended an infinite number of times.", "startOffset": 106, "endOffset": 113}, {"referenceID": 2, "context": "Thus, the solution concept for the stochastic multi-armed bandit problem is to determine the best item (arm) and keep choosing it [3].", "startOffset": 130, "endOffset": 133}, {"referenceID": 13, "context": "On the other hand, sleeping bandits [15] allow for the available items at each time step to vary, but the analysis is worst-case in terms of which items are available over time.", "startOffset": 36, "endOffset": 40}, {"referenceID": 20, "context": "The algorithm is syntactically similar to the \u03b5-greedy algorithm for multiarmed bandits [22], which explores items with probability \u03b5 and otherwise greedily chooses the best item seen so far based on a plurality vote.", "startOffset": 88, "endOffset": 92}, {"referenceID": 0, "context": "Algorithm 1: COLLABORATIVE-GREEDY Input: Parameters \u03b8 \u2208 [0, 1], \u03b1 \u2208 (0, 4/7].", "startOffset": 56, "endOffset": 62}, {"referenceID": 19, "context": "The clustering was found via Bayesian clustered tensor factorization, which was previously shown to model real movie ratings data well [21].", "startOffset": 135, "endOffset": 139}, {"referenceID": 3, "context": "Next, we demonstrate our algorithm COLLABORATIVE-GREEDY on the two simulated online movie recommendation systems, showing that it outperforms two existing recommendation algorithms Popularity Amongst Friends (PAF) [4] and a method by Deshpande and Montanari (DM) [12].", "startOffset": 214, "endOffset": 217}, {"referenceID": 10, "context": "Next, we demonstrate our algorithm COLLABORATIVE-GREEDY on the two simulated online movie recommendation systems, showing that it outperforms two existing recommendation algorithms Popularity Amongst Friends (PAF) [4] and a method by Deshpande and Montanari (DM) [12].", "startOffset": 263, "endOffset": 267}, {"referenceID": 3, "context": "Following the experimental setup of [4], we quantize a rating of 4 stars or more to be +1 (likable), and a rating less than 4 stars to be \u22121 (unlikable).", "startOffset": 36, "endOffset": 39}, {"referenceID": 6, "context": "[7], who study the asymptotic consistency of a cosinesimilarity nearest-neighbor collaborative filtering method.", "startOffset": 0, "endOffset": 3}, {"referenceID": 3, "context": "Barman and Dabeer [4] study the performance of an algorithm called Popularity Amongst Friends, examining its ability to predict binary ratings in an asymptotic informationtheoretic setting.", "startOffset": 18, "endOffset": 21}, {"referenceID": 9, "context": "Dabeer [11] uses a model similar to ours and studies online collaborative filtering with a moving horizon cost in the limit of small noise using an algorithm that knows the numbers of user types and item types.", "startOffset": 7, "endOffset": 11}, {"referenceID": 10, "context": "Another related work is by Deshpande and Montanari [12], who study online recommendations as a linear bandit problem; their method, however, does not actually use any collaboration beyond a pre-processing step in which offline collaborative filtering (specifically matrix completion) is solved to compute feature vectors for items.", "startOffset": 51, "endOffset": 55}, {"referenceID": 8, "context": ", [10, 18, 5, 2]), where one observes samples from a mixture distribution and the goal is to learn the mixture components and weights.", "startOffset": 2, "endOffset": 16}, {"referenceID": 16, "context": ", [10, 18, 5, 2]), where one observes samples from a mixture distribution and the goal is to learn the mixture components and weights.", "startOffset": 2, "endOffset": 16}, {"referenceID": 4, "context": ", [10, 18, 5, 2]), where one observes samples from a mixture distribution and the goal is to learn the mixture components and weights.", "startOffset": 2, "endOffset": 16}, {"referenceID": 1, "context": ", [10, 18, 5, 2]), where one observes samples from a mixture distribution and the goal is to learn the mixture components and weights.", "startOffset": 2, "endOffset": 16}], "year": 2014, "abstractText": "Despite the prevalence of collaborative filtering in recommendation systems, there has been little theoretical development on why and how well it works, especially in the \u201conline\u201d setting, where items are recommended to users over time. We address this theoretical gap by introducing a model for online recommendation systems, cast item recommendation under the model as a learning problem, and analyze the performance of a cosine-similarity collaborative filtering method. In our model, each of n users either likes or dislikes each of m items. We assume there to be k types of users, and all the users of a given type share a common string of probabilities determining the chance of liking each item. At each time step, we recommend an item to each user, where a key distinction from related bandit literature is that once a user consumes an item (e.g., watches a movie), then that item cannot be recommended to the same user again. The goal is to maximize the number of likable items recommended to users over time. Our main result establishes that after nearly log(km) initial learning time steps, a simple collaborative filtering algorithm achieves essentially optimal performance without knowing k. The algorithm has an exploitation step that uses cosine similarity and two types of exploration steps, one to explore the space of items (standard in the literature) and the other to explore similarity between users (novel to this work).", "creator": "LaTeX with hyperref package"}}}