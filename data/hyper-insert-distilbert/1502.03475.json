{"id": "1502.03475", "review": {"conference": "NIPS", "VERSION": "v1", "DATE_OF_SUBMISSION": "11-Feb-2015", "title": "Combinatorial Bandits Revisited", "abstract": "this original paper too investigates stochastic greedy and adversarial combinatorial partial multi - sided armed maximum bandit problems. in attempting the pure stochastic setting, while we first derive problem - requiring specific regret noise lower bounds, and analyze how nearly these poor bounds scale with extending the dimension of the decision error space. we then additionally propose combucb, algorithms suitable that efficiently weakly exploit the corresponding combinatorial arithmetic structure of the problem, and derive finite - variance time marko upper bound optimal on extending their regrets. these derived bounds improve over purely regret upper set bounds of actual existing problem algorithms, although and we best show numerically thatcombucb significantly outperforms any other alternative algorithm. check in for the adversarial greedy setting, and we only propose fundamentally two simple algorithms, namely combexp - 1 and ultimately combexp - - 2 for semi - bandit and bandit feedback, respectively. their regrets graphs have suffered similar scaling restrictions as actual state - but of - the - art algorithms, in relative spite possible of utilizing the shared simplicity of attempting their respective implementation.", "histories": [["v1", "Wed, 11 Feb 2015 22:35:50 GMT  (2512kb,D)", "http://arxiv.org/abs/1502.03475v1", "28 pages"], ["v2", "Tue, 7 Apr 2015 15:07:54 GMT  (2616kb,D)", "http://arxiv.org/abs/1502.03475v2", "29 pages"], ["v3", "Fri, 6 Nov 2015 00:53:37 GMT  (4523kb,D)", "http://arxiv.org/abs/1502.03475v3", "30 pages, Advances in Neural Information Processing Systems 28 (NIPS 2015)"]], "COMMENTS": "28 pages", "reviews": [], "SUBJECTS": "cs.LG math.OC stat.ML", "authors": ["richard combes", "mohammad sadegh talebi", "alexandre prouti\u00e8re", "marc lelarge"], "accepted": true, "id": "1502.03475"}, "pdf": {"name": "1502.03475.pdf", "metadata": {"source": "META", "title": "Stochastic and Adversarial Combinatorial Bandits", "authors": ["Richard Combes", "Marc Lelarge", "Alexandre Proutiere", "Sadegh Talebi"], "emails": ["RICHARD.COMBES@SUPELEC.FR", "MARC.LELARGE@ENS.FR", "ALEPRO@KTH.SE", "MSTMS@KTH.SE"], "sections": null, "references": [{"title": "Asymptotically efficient allocation rules for the multiarmed bandit problem with multiple plays-part i: iid rewards", "author": ["References Anantharam", "Venkatachalam", "Varaiya", "Pravin", "Walrand", "Jean"], "venue": "Automatic Control, IEEE Transactions on,", "citeRegEx": "Anantharam et al\\.,? \\Q1987\\E", "shortCiteRegEx": "Anantharam et al\\.", "year": 1987}, {"title": "Regret in online combinatorial optimization", "author": ["Audibert", "Jean-Yves", "Bubeck", "S\u00e9bastien", "Lugosi", "G\u00e1bor"], "venue": "Mathematics of Operations Research,", "citeRegEx": "Audibert et al\\.,? \\Q2013\\E", "shortCiteRegEx": "Audibert et al\\.", "year": 2013}, {"title": "Finite time analysis of the multiarmed bandit problem", "author": ["P. Auer", "N. Cesa-Bianchi", "P. Fischer"], "venue": "Machine Learning,", "citeRegEx": "Auer et al\\.,? \\Q2002\\E", "shortCiteRegEx": "Auer et al\\.", "year": 2002}, {"title": "The nonstochastic multiarmed bandit problem", "author": ["P. Auer", "N. Cesa-Bianchi", "Y. Freund", "R.E. Schapire"], "venue": "SIAM Journal on Computing,", "citeRegEx": "Auer et al\\.,? \\Q2002\\E", "shortCiteRegEx": "Auer et al\\.", "year": 2002}, {"title": "Regret analysis of stochastic and nonstochastic multi-armed bandit problems", "author": ["S. Bubeck", "N. Cesa-Bianchi"], "venue": "Foundations and Trends in Machine Learning,", "citeRegEx": "Bubeck and Cesa.Bianchi,? \\Q2012\\E", "shortCiteRegEx": "Bubeck and Cesa.Bianchi", "year": 2012}, {"title": "Towards minimax policies for online linear optimization with bandit feedback", "author": ["Bubeck", "S\u00e9bastien", "Cesa-Bianchi", "Nicolo", "Kakade", "Sham M"], "venue": "arXiv preprint arXiv:1202.3079,", "citeRegEx": "Bubeck et al\\.,? \\Q2012\\E", "shortCiteRegEx": "Bubeck et al\\.", "year": 2012}, {"title": "Combinatorial bandits", "author": ["N. Cesa-Bianchi", "G. Lugosi"], "venue": "Journal of Computer and System Sciences,", "citeRegEx": "Cesa.Bianchi and Lugosi,? \\Q2012\\E", "shortCiteRegEx": "Cesa.Bianchi and Lugosi", "year": 2012}, {"title": "Prediction, learning, and games, volume 1", "author": ["Cesa-Bianchi", "Nicolo", "Lugosi", "G\u00e1bor"], "venue": null, "citeRegEx": "Cesa.Bianchi et al\\.,? \\Q2006\\E", "shortCiteRegEx": "Cesa.Bianchi et al\\.", "year": 2006}, {"title": "Combinatorial multi-armed bandit: General framework and applications", "author": ["Chen", "Wei", "Wang", "Yajun", "Yuan", "Yang"], "venue": "In Proceedings of The 30th International Conference on Machine Learning,", "citeRegEx": "Chen et al\\.,? \\Q2013\\E", "shortCiteRegEx": "Chen et al\\.", "year": 2013}, {"title": "Unimodal bandits: Regret lower bounds and optimal algorithms", "author": ["Combes", "Richard", "Proutiere", "Alexandre"], "venue": "[cs.LG],", "citeRegEx": "Combes et al\\.,? \\Q2014\\E", "shortCiteRegEx": "Combes et al\\.", "year": 2014}, {"title": "Information theory and statistics: A tutorial", "author": ["I. Csisz\u00e1r", "P.C. Shields"], "venue": "Now Publishers Inc,", "citeRegEx": "Csisz\u00e1r and Shields,? \\Q2004\\E", "shortCiteRegEx": "Csisz\u00e1r and Shields", "year": 2004}, {"title": "Learning multiuser channel allocations in cognitive radio networks: A combinatorial multi-armed bandit formulation", "author": ["Gai", "Yi", "Krishnamachari", "Bhaskar", "Jain", "Rahul"], "venue": "In New Frontiers in Dynamic Spectrum,", "citeRegEx": "Gai et al\\.,? \\Q2010\\E", "shortCiteRegEx": "Gai et al\\.", "year": 2010}, {"title": "Combinatorial network optimization with unknown variables: Multiarmed bandits with linear rewards and individual observations", "author": ["Gai", "Yi", "Krishnamachari", "Bhaskar", "Jain", "Rahul"], "venue": "IEEE/ACM Transactions on Networking (TON),", "citeRegEx": "Gai et al\\.,? \\Q2012\\E", "shortCiteRegEx": "Gai et al\\.", "year": 2012}, {"title": "The kl-ucb algorithm for bounded stochastic bandits and beyond", "author": ["A. Garivier", "O. Capp\u00e9"], "venue": "In Proceedings of Conference On Learning Theory COLT,", "citeRegEx": "Garivier and Capp\u00e9,? \\Q2011\\E", "shortCiteRegEx": "Garivier and Capp\u00e9", "year": 2011}, {"title": "Asymptotically efficient adaptive choice of control laws in controlled markov chains", "author": ["T.L. Graves", "T.L. Lai"], "venue": "SIAM J. Control and Optimization,", "citeRegEx": "Graves and Lai,? \\Q1997\\E", "shortCiteRegEx": "Graves and Lai", "year": 1997}, {"title": "The shortest path problem under partial monitoring", "author": ["Gy\u00f6rgy", "Andras", "Linder", "Tamas", "Ottucsak", "Gyorgy"], "venue": "Learning Theory, volume 4005 of Lecture Notes in Computer Science,", "citeRegEx": "Gy\u00f6rgy et al\\.,? \\Q2006\\E", "shortCiteRegEx": "Gy\u00f6rgy et al\\.", "year": 2006}, {"title": "The on-line shortest path problem under partial monitoring", "author": ["Gy\u00f6rgy", "Andr\u00e1s", "Linder", "Tam\u00e1s", "Lugosi", "G\u00e1bor", "Ottucs\u00e1k"], "venue": "Journal of Machine Learning Research,", "citeRegEx": "Gy\u00f6rgy et al\\.,? \\Q2007\\E", "shortCiteRegEx": "Gy\u00f6rgy et al\\.", "year": 2007}, {"title": "Learning permutations with exponential weights", "author": ["Helmbold", "David P", "Warmuth", "Manfred K"], "venue": "J. Mach. Learn. Res.,", "citeRegEx": "Helmbold et al\\.,? \\Q2009\\E", "shortCiteRegEx": "Helmbold et al\\.", "year": 2009}, {"title": "Non-stochastic bandit slate problems", "author": ["S. Kale", "L. Reyzin", "R. Schapire"], "venue": "Advances in Neural Information Processing Systems, pp", "citeRegEx": "Kale et al\\.,? \\Q2010\\E", "shortCiteRegEx": "Kale et al\\.", "year": 2010}, {"title": "Matroid bandits: Fast combinatorial optimization with learning", "author": ["Kveton", "Branislav", "Wen", "Zheng", "Ashkan", "Azin", "Eydgahi", "Hoda", "Eriksson", "Brian"], "venue": null, "citeRegEx": "Kveton et al\\.,? \\Q2014\\E", "shortCiteRegEx": "Kveton et al\\.", "year": 2014}, {"title": "Asymptotically efficient adaptive allocation rules", "author": ["T.L. Lai", "H. Robbins"], "venue": "Advances in Applied Mathematics,", "citeRegEx": "Lai and Robbins,? \\Q1985\\E", "shortCiteRegEx": "Lai and Robbins", "year": 1985}, {"title": "Lipschitz bandits: Regret lower bounds and optimal algorithms", "author": ["Magureanu", "Stefan", "Combes", "Richard", "Proutiere", "Alexandre"], "venue": "COLT 2014,", "citeRegEx": "Magureanu et al\\.,? \\Q2014\\E", "shortCiteRegEx": "Magureanu et al\\.", "year": 2014}, {"title": "On cliques in graphs. Israel", "author": ["J.W. Moon", "L. Moser"], "venue": "Journal of Mathematics,", "citeRegEx": "Moon and Moser,? \\Q1965\\E", "shortCiteRegEx": "Moon and Moser", "year": 1965}, {"title": "An efficient algorithm for learning with semi-bandit feedback", "author": ["Neu", "Gergely", "Bart\u00f3k", "G\u00e1bor"], "venue": "In Algorithmic Learning Theory,", "citeRegEx": "Neu et al\\.,? \\Q2013\\E", "shortCiteRegEx": "Neu et al\\.", "year": 2013}, {"title": "Some aspects of the sequential design of experiments", "author": ["Robbins", "Herbert"], "venue": "In Herbert Robbins Selected Papers,", "citeRegEx": "Robbins and Herbert.,? \\Q1985\\E", "shortCiteRegEx": "Robbins and Herbert.", "year": 1985}, {"title": "Combinatorial Optimization: Polyhedra and Efficiency", "author": ["Schrijver", "Alexander"], "venue": null, "citeRegEx": "Schrijver and Alexander.,? \\Q2003\\E", "shortCiteRegEx": "Schrijver and Alexander.", "year": 2003}], "referenceMentions": [{"referenceID": 7, "context": ", (Bubeck & Cesa-Bianchi, 2012; Cesa-Bianchi et al., 2006).", "startOffset": 2, "endOffset": 58}, {"referenceID": 0, "context": "Some research contributions concern problems where the set of arms exhibits very specific structures, such as m-set (Anantharam et al., 1987), matroid (Kveton et al.", "startOffset": 116, "endOffset": 141}, {"referenceID": 19, "context": ", 1987), matroid (Kveton et al., 2014), or matching in bi-partite graphs (Gai et al.", "startOffset": 17, "endOffset": 38}, {"referenceID": 11, "context": ", 2014), or matching in bi-partite graphs (Gai et al., 2010).", "startOffset": 42, "endOffset": 60}, {"referenceID": 12, "context": "Generic combinatorial problems have been investigated in (Gai et al., 2012) and Algorithm Regret LLR (Gai et al.", "startOffset": 57, "endOffset": 75}, {"referenceID": 12, "context": ", 2012) and Algorithm Regret LLR (Gai et al., 2012) O ( md\u2206max \u2206min log(T ) )", "startOffset": 33, "endOffset": 51}, {"referenceID": 8, "context": "CUCB (Chen et al., 2013) O ( md \u2206min log(T ) )", "startOffset": 5, "endOffset": 24}, {"referenceID": 8, "context": "(Chen et al., 2013).", "startOffset": 0, "endOffset": 19}, {"referenceID": 1, "context": "When \u03bc \u22121 min = O(poly(d)), which happens in several specific problems of interest, the regret under COMBEXP-1 matches the regret minimax lower bound \u221a mdT up to a logarithmic factor (Audibert et al., 2013).", "startOffset": 183, "endOffset": 206}, {"referenceID": 1, "context": "Note that a known regret minimax lower bound is \u03a9(m \u221a dT ) (Audibert et al., 2013), and hence the regret gap between COMBEXP-2 and this lower bound scales at most as m up to a logarithmic factor.", "startOffset": 59, "endOffset": 82}, {"referenceID": 1, "context": "Adversarial combinatorial bandits have been extensively investigated recently, see (Audibert et al., 2013) and references therein.", "startOffset": 83, "endOffset": 106}, {"referenceID": 15, "context": "shortest-path routing (Gy\u00f6rgy et al., 2006; 2007) or m-sets (Kale et al.", "startOffset": 22, "endOffset": 49}, {"referenceID": 18, "context": ", 2006; 2007) or m-sets (Kale et al., 2010).", "startOffset": 24, "endOffset": 43}, {"referenceID": 1, "context": "For generic combinatorial problems, known regret lower bounds scale as \u03a9 (\u221a mdT ) and \u03a9 ( m \u221a dT ) (if d \u2265 2m) in the case of semi-bandit and bandit feedback, respectively (Audibert et al., 2013).", "startOffset": 172, "endOffset": 195}, {"referenceID": 1, "context": "In the case of semibandit feedback, (Audibert et al., 2013) proposes OSMD, an algorithm whose regret upper bound matches the lower bound.", "startOffset": 36, "endOffset": 59}, {"referenceID": 1, "context": "Stochastic and Adversarial Combinatorial Bandits Algorithm Regret Lower Bound (Audibert et al., 2013) \u03a9 (\u221a mdT )", "startOffset": 78, "endOffset": 101}, {"referenceID": 1, "context": "OSMD (Audibert et al., 2013) O (\u221a mdT )", "startOffset": 5, "endOffset": 28}, {"referenceID": 5, "context": "(Bubeck et al., 2012) addresses generic linear optimization with bandit feedback and the proposed algorithm, referred to as EXP2 WITH JOHN\u2019S EXPLORATION, has a regret scaling at most as O(m \u221a dT log(d/m)) in the case of combinatorial structure.", "startOffset": 0, "endOffset": 21}, {"referenceID": 1, "context": "Stochastic and Adversarial Combinatorial Bandits Algorithm Regret Lower Bound (Audibert et al., 2013) \u03a9 ( m \u221a dT ) , if d \u2265 2m COMBAND (Cesa-Bianchi & Lugosi, 2012) O ( m \u221a dT log |M| ( 1 + 2m d\u03bbmin ))", "startOffset": 78, "endOffset": 101}, {"referenceID": 5, "context": "EXP2 WITH JOHN\u2019S EXPLORATION (Bubeck et al., 2012) O (\u221a m3dT log ( d m ))", "startOffset": 29, "endOffset": 50}, {"referenceID": 0, "context": "Furher remark that ifM is the set of singletons (classical bandit), Theorem 1 reduces to the Lai-Robbins bound (Lai & Robbins, 1985) and ifM is the set of m-sets (bandit with multiple plays), Theorem 1 reduces to the lower bound of (Anantharam et al., 1987).", "startOffset": 232, "endOffset": 257}, {"referenceID": 0, "context": "Indeed, in the case of m-sets, there exists an algorithm with O(d\u2206\u22121 min log(T )) regret (Anantharam et al., 1987).", "startOffset": 89, "endOffset": 114}, {"referenceID": 21, "context": "The proof of statement (ii) is based on a concentration inequality on sums of empirical KL divergences proven in (Magureanu et al., 2014).", "startOffset": 113, "endOffset": 137}, {"referenceID": 8, "context": "A close look at cM (n) reveals that the indexes proposed in (Chen et al., 2013) and (Gai et al.", "startOffset": 60, "endOffset": 79}, {"referenceID": 12, "context": ", 2013) and (Gai et al., 2012) are too conservative to be optimal: there the \u201cconfidence bonus\u201d \u2211d i=1 Mi ti(n) was replaced by (at least) m \u2211d i=1 Mi ti(n) .", "startOffset": 12, "endOffset": 30}, {"referenceID": 21, "context": "A concentration inequality We first recall Lemma 1, a concentration inequality derived in (Magureanu et al., 2014)[Theorem].", "startOffset": 90, "endOffset": 114}, {"referenceID": 19, "context": "2 in the main document, in this case the regret of CUCB takes the form O( d \u2206min log(T )) = O( N \u2206min log(T )) on the account of (Kveton et al., 2014).", "startOffset": 129, "endOffset": 150}], "year": 2017, "abstractText": "This paper investigates stochastic and adversarial combinatorial multi-armed bandit problems. In the stochastic setting, we first derive problem-specific regret lower bounds, and analyze how these bounds scale with the dimension of the decision space. We then propose COMBUCB, algorithms that efficiently exploit the combinatorial structure of the problem, and derive finite-time upper bound on their regrets. These bounds improve over regret upper bounds of existing algorithms, and we show numerically thatCOMBUCB significantly outperforms any other algorithm. In the adversarial setting, we propose two simple algorithms, namely COMBEXP-1 and COMBEXP-2 for semi-bandit and bandit feedback, respectively. Their regrets have similar scaling as state-of-the-art algorithms, in spite of the simplicity of their implementation.", "creator": "LaTeX with hyperref package"}}}