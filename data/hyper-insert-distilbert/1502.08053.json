{"id": "1502.08053", "review": {"conference": "ICML", "VERSION": "v1", "DATE_OF_SUBMISSION": "27-Feb-2015", "title": "Stochastic Dual Coordinate Ascent with Adaptive Probabilities", "abstract": "this 2004 paper again introduces adasdca : defining an innovative adaptive variant of fast stochastic elimination dual inverse coordinate ascent ( rr sdca ) for solving the generalized regularized empirical risk minimization problems. firstly our modification however consists in significantly allowing the method adaptively change the probability _ distribution over the two dual variables throughout the process iterative process. adasdca also achieves provably noticeably better complexity bound prediction than these sdca versions with the mean best reliable fixed probability distribution, known as importance sampling. however, thus it is of choosing a theoretically theoretical reasonable character value as it method is therefore expensive to implement. we just also thoughtfully propose adasdca + : adding a practical dynamic variant which in respects our preliminary experiments outperforms existing non - adaptive compression methods.", "histories": [["v1", "Fri, 27 Feb 2015 20:54:03 GMT  (2315kb)", "http://arxiv.org/abs/1502.08053v1", null]], "reviews": [], "SUBJECTS": "math.OC cs.LG stat.ML", "authors": ["dominik csiba", "zheng qu", "peter richt\u00e1rik"], "accepted": true, "id": "1502.08053"}, "pdf": {"name": "1502.08053.pdf", "metadata": {"source": "META", "title": "Stochastic Dual Coordinate Ascent with Adaptive Probabilities", "authors": ["Dominik Csiba"], "emails": ["CDOMINIK@GMAIL.COM", "ZHENG.QU@ED.AC.UK", "PETER.RICHTARIK@ED.AC.UK"], "sections": [{"heading": null, "text": "ar X\niv :1\n50 2.\n08 05\n3v 1\n[ m\nat h.\nO C\n] 2\n7 Fe\nb 20"}, {"heading": "1. Introduction", "text": "Empirical Loss Minimization. In this paper we consider the regularized empirical risk minimization problem:\nmin w\u2208Rd\n[\nP (w) def =\n1\nn\nn \u2211\ni=1\n\u03c6i(A \u22a4 i w) + \u03bbg(w)\n]\n. (1)\nIn the context of supervised learning,w is a linear predictor, A1, . . . , An \u2208 Rd are samples, \u03c61, . . . , \u03c6n : Rd \u2192 R are loss functions, g : Rd \u2192 R is a regularizer and \u03bb > 0 a regularization parameter. Hence, we are seeking to identify the predictor which minimizes the average (empirical) loss P (w).\nWe assume throughout that the loss functions are 1/\u03b3smooth for some \u03b3 > 0. That is, we assume they are differentiable and have Lipschitz derivative with Lipschitz constant 1/\u03b3:\n|\u03c6\u2032(a)\u2212 \u03c6\u2032(b)| \u2264 1 \u03b3 |a\u2212 b|\nfor all a, b \u2208 R. Moreover, we assume that g is 1-strongly convex with respect to the L2 norm:\ng(w) \u2264 \u03b1g(w1) + (1\u2212 \u03b1)g(w2)\u2212 \u03b1(1\u2212 \u03b1)\n2 \u2016w1 \u2212 w2\u20162\nfor all w1, w2 \u2208 dom g, 0 \u2264 \u03b1 \u2264 1 and w = \u03b1w1 + (1 \u2212 \u03b1)w2.\nThe ERM problem (1) has received considerable attention in recent years due to its widespread usage in supervised statistical learning (Shalev-Shwartz & Zhang, 2013b). Often, the number of samples n is very large and it is important to design algorithms that would be efficient in this regime.\nModern stochastic algorithms for ERM. Several highly efficient methods for solving the ERM problem were proposed and analyzed recently. These include primal methods such as SAG (Schmidt et al., 2013), SVRG (Johnson & Zhang, 2013), S2GD (Konec\u030cny\u0301 & Richta\u0301rik, 2014), SAGA (Defazio et al., 2014), mS2GD (Konec\u030cny\u0301 et al., 2014a) and MISO (Mairal, 2014). Importance sampling was considered in ProxSVRG (Xiao & Zhang, 2014) and S2CD (Konec\u030cny\u0301 et al., 2014b).\nStochastic Dual Coordinate Ascent. One of the most successful methods in this category is stochastic dual coordinate ascent (SDCA), which operates on the dual of the ERM problem (1):\nmax \u03b1=(\u03b11,...,\u03b1n)\u2208Rn\n[\nD(\u03b1) def = \u2212f(\u03b1)\u2212 \u03c8(\u03b1)\n]\n, (2)\nwhere functions f and \u03c8 are defined by\nf(\u03b1) def = \u03bbg\u2217\n(\n1\n\u03bbn\nn \u2211\ni=1\nAi\u03b1i\n)\n, (3)\n\u03c8(\u03b1) def =\n1\nn\nn \u2211\ni=1\n\u03c6\u2217i (\u2212\u03b1i), (4)\nand g\u2217 and \u03c6\u2217i are the convex conjugates 1 of g and \u03c6i, respectively. Note that in dual problem, there are as many variables as there are samples in the primal: \u03b1 \u2208 Rn. SDCA in each iteration randomly selects a dual variable \u03b1i, and performs its update, usually via closed-form\n1By the convex (Fenchel) conjugate of a function h : R\nk \u2192 R we mean the function h\u2217 : Rk \u2192 R defined by h\u2217(u) = sup\ns {s\u22a4u\u2212 h(s)}.\nformula \u2013 this strategy is know as randomized coordinate descent. Methods based on updating randomly selected dual variables enjoy, in our setting, a linear convergence rate (Shalev-Shwartz & Zhang, 2013b; 2012; Taka\u0301c\u030c et al., 2013; Shalev-Shwartz & Zhang, 2013a; Zhao & Zhang, 2014; Qu et al., 2014). These methods have attracted considerable attention in the past few years, and include SCD (Shalev-Shwartz & Tewari, 2011), RCDM (Nesterov, 2012), UCDC (Richta\u0301rik & Taka\u0301c\u030c, 2014), ICD (Tappenden et al., 2013), PCDM (Richta\u0301rik & Taka\u0301c\u030c, 2012), SPCDM (Fercoq & Richta\u0301rik, 2013), SPDC (Zhang & Xiao, 2014), APCG (Lin et al., 2014), RCD (Necoara & Patrascu, 2014), APPROX (Fercoq & Richta\u0301rik, 2013), QUARTZ (Qu et al., 2014) and ALPHA (Qu & Richta\u0301rik, 2014). Recent advances on mini-batch and distributed variants can be found in (Liu & Wright, 2014), (Zhao et al., 2014b), (Richta\u0301rik & Taka\u0301c\u030c, 2013a), (Fercoq et al., 2014), (Trofimov & Genkin, 2014), (Jaggi et al., 2014), (Marec\u030cek et al., 2014) and (Mahajan et al., 2014). Other related work includes (Nemirovski et al., 2009; Duchi et al., 2011; Agarwal & Bottou, 2014; Zhao et al., 2014a; Fountoulakis & Tappenden, 2014; Tappenden et al., 2014). We also point to (Wright, 2014) for a review on coordinate descent algorithms.\nSelection Probabilities. Naturally, both the theoretical convergence rate and practical performance of randomized coordinate descent methods depends on the probability distribution governing the choice of individual coordinates. While most existing work assumes uniform distribution, it was shown by Richta\u0301rik & Taka\u0301c\u030c (2014); Necoara et al. (2012); Zhao & Zhang (2014) that coordinate descent works for an arbitrary fixed probability distribution over individual coordinates and even subsets of coordinates (Richta\u0301rik & Taka\u0301c\u030c, 2013b; Qu et al., 2014; Qu & Richta\u0301rik, 2014; Qu & Richta\u0301rik, 2014). In all of these works the theory allows the computation of a fixed probability distribution, known as importance sampling, which optimizes the complexity bounds. However, such a distribution often depends on unknown quantities, such as the distances of the individual variables from their optimal values (Richta\u0301rik & Taka\u0301c\u030c, 2014; Qu & Richta\u0301rik, 2014). In some cases, such as for smooth strongly convex functions or in the primal-dual setup we consider here, the probabilities forming an importance sampling can be explicitly computed (Richta\u0301rik & Taka\u0301c\u030c, 2013b; Zhao & Zhang, 2014; Qu et al., 2014; Qu & Richta\u0301rik, 2014; Qu & Richta\u0301rik, 2014). Typically, the theoretical influence of using the importance sampling is in the replacement of the maximum of certain data-dependent quantities in the complexity bound by the average.\nAdaptivity. Despite the striking developments in the field, there is virtually no literature on methods using an adap-\ntive choice of the probabilities. We are aware of a few pieces of work; but all resort to heuristics unsupported by theory (Glasmachers & Dogan, 2013; Lukasewitz, 2013; Schaul et al., 2013; Banks-Watson, 2012; Loshchilov et al., 2011), which unfortunately also means that the methods are sometimes effective, and sometimes not. We observe that in the primal-dual framework we consider, each dual variable can be equipped with a natural measure of progress which we call \u201cdual residue\u201d. We propose that the selection probabilities be constructed based on these quantities.\nOutline: In Section 2 we summarize the contributions of our work. In Section 3 we describe our first, theoretical methods (Algorithm 1) and describe the intuition behind it. In Section 4 we provide convergence analysis. In Section 5 we introduce Algorithm 2: an variant of Algorithm 1 containing heuristic elements which make it efficiently implementable. We conclude with numerical experiments in Section 6. Technical proofs and additional numerical experiments can be found in the appendix."}, {"heading": "2. Contributions", "text": "We now briefly highlight the main contributions of this work.\nTwo algorithms with adaptive probabilities. We propose two new stochastic dual ascent algorithms: AdaSDCA (Algorithm 1) and AdaSDCA+ (Algorithm 2) for solving (1) and its dual problem (2). The novelty of our algorithms is in adaptive choice of the probability distribution over the dual coordinates.\nComplexity analysis. We provide a convergence rate analysis for the first method, showing that AdaSDCA enjoys better rate than the best known rate for SDCA with a fixed sampling (Zhao & Zhang, 2014; Qu et al., 2014). The probabilities are proportional to a certain measure of dual suboptimality associated with each variable.\nPractical method. AdaSDCA requires the same computational effort per iteration as the batch gradient algorithm. To solve this issue, we propose AdaSDCA+ (Algorithm 2): an efficient heuristic variant of the AdaSDCA. The computational effort of the heuristic method in a single iteration is low, which makes it very competitive with methods based on importance sampling, such as IProxSDCA (Zhao & Zhang, 2014). We support this with computational experiments in Section 6.\nOutline: In Section 2 we summarize the contributions of our work. In Section 3 we describe our first, theoretical methods (AdaSDCA) and describe the intuition behind it. In Section 4 we provide convergence analysis. In Section 5 we introduce AdaSDCA+: a variant of AdaSDCA\ncontaining heuristic elements which make it efficiently implementable. We conclude with numerical experiments in Section 6. Technical proofs and additional numerical experiments can be found in the appendix."}, {"heading": "3. The Algorithm: AdaSDCA", "text": "It is well known that the optimal primal-dual pair (w\u2217, \u03b1\u2217) \u2208 Rd\u00d7Rn satisfies the following optimality conditions:\nw\u2217 = \u2207g\u2217 ( 1\n\u03bbn A\u03b1\u2217\n)\n(5)\n\u03b1\u2217i = \u2212\u2207\u03c6i(A\u22a4i w\u2217), \u2200i \u2208 [n] def = {1, . . . , n}, (6)\nwhere A is the d-by-n matrix with columns A1, . . . , An.\nDefinition 1 (Dual residue). The dual residue, \u03ba = (\u03ba1, . . . , \u03ban) \u2208 Rn, associated with (w,\u03b1) is given by:\n\u03bai def = \u03b1i +\u2207\u03c6i(A\u22a4i w). (7)\nNote, that \u03bati = 0 if and only if \u03b1i satisfies (5). This motivates the design of AdaSDCA (Algorithm 1) as follows: whenever |\u03bati| is large, the ith dual coordinate \u03b1i is suboptimal and hence should be updated more often.\nDefinition 2 (Coherence). We say that probability vector pt \u2208 Rn is coherent with the dual residue \u03bat if for all i \u2208 [n] we have\n\u03bati 6= 0 \u21d2 pti > 0.\nAlternatively, pt is coherent with kt if for\nIt def = {i \u2208 [n] : \u03bati 6= 0} \u2286 [n].\nwe have mini\u2208It p t i > 0.\nAdaSDCA is a stochastic dual coordinate ascent method, with an adaptive probability vector pt, which could potentially change at every iteration t. The primal and dual update rules are exactly the same as in standard SDCA (Shalev-Shwartz & Zhang, 2013b), which instead uses uniform sampling probability at every iteration and does not require the computation of the dual residue \u03ba.\nOur first result highlights a key technical tool which ultimately leads to the development of good adaptive sampling distributions pt in AdaSDCA. For simplicity we denote by Et the expectation with respect to the random index it \u2208 [n] generated at iteration t. Lemma 3. Consider the AdaSDCA algorithm during iteration t \u2265 0 and assume that pt is coherent with \u03bat. Then\nEt\n[ D(\u03b1t+1)\u2212D(\u03b1t) ] \u2212 \u03b8 ( P (wt)\u2212D(\u03b1t) )\n\u2265 \u2212 \u03b8 2\u03bbn2 \u2211\ni\u2208It\n(\n\u03b8(vi + n\u03bb\u03b3)\npti \u2212 n\u03bb\u03b3\n)\n|\u03bati|2, (8)\nAlgorithm 1 AdaSDCA\nInit: vi = A\u22a4i Ai for i \u2208 [n]; \u03b10 \u2208 Rn; \u03b1\u03040 = 1\u03bbnA\u03b10 for t \u2265 0 do\nPrimal update: wt = \u2207g\u2217 (\u03b1\u0304t) Set: \u03b1t+1 = \u03b1t Compute residue \u03bat: \u03bati = \u03b1 t i+\u2207\u03c6i(A\u22a4i wt), \u2200i \u2208 [n]\nCompute probability distribution pt coherent with \u03bat Generate random it \u2208 [n] according to pt Compute:\n\u2206\u03b1tit = argmax \u2206\u2208R\n{\n\u2212\u03c6\u2217it(\u2212(\u03b1tit +\u2206))\n\u2212A\u22a4itwt\u2206\u2212 vit 2\u03bbn |\u2206|2 }\nDual update: \u03b1t+1it = \u03b1 t it +\u2206\u03b1tit Average update: \u03b1\u0304t = \u03b1\u0304t + \u2206\u03b1it \u03bbn\nAit end for Output: wt, \u03b1t\nfor arbitrary\n0 \u2264 \u03b8 \u2264 min i\u2208It pti. (9)\nProof. Lemma 3 is proved similarly to Lemma 2 in (Zhao & Zhang, 2014), but in a slightly more general setting. For completeness, we provide the proof in the appendix.\nLemma 3 plays a key role in the analysis of stochastic dual coordinate methods (Shalev-Shwartz & Zhang, 2013b; Zhao & Zhang, 2014; Shalev-Shwartz & Zhang, 2013a). Indeed, if the right-hand side of (8) is positive, then the primal dual error P (wt) \u2212 D(\u03b1t) can be bounded by the expected dual ascent Et[D(\u03b1t+1)\u2212D(\u03b1t)] times 1/\u03b8, which yields the contraction of the dual error at the rate of 1 \u2212 \u03b8 (see Theorem 7). In order to make the right-hand side of (8) positive we can take any \u03b8 smaller than \u03b8(\u03bat, pt) where the function \u03b8(\u00b7, \u00b7) : Rn+ \u00d7 Rn+ \u2192 R is defined by:\n\u03b8(\u03ba, p) \u2261 n\u03bb\u03b3\n\u2211\ni:\u03bai 6=0 |\u03bai|2\n\u2211\ni:\u03bai 6=0 p\u22121i |\u03bai|2(vi + n\u03bb\u03b3)\n. (10)\nWe also need to make sure that 0 \u2264 \u03b8 \u2264 mini\u2208It pti in order to apply Lemma 3. A \u201cgood\u201d adaptive probability pt should then be the solution of the following optimization problem:\nmax p\u2208Rn\n+\n\u03b8(\u03bat, p) (11)\ns.t.\nn \u2211\ni=1\npi = 1\n\u03b8(\u03bat, p) \u2264 min i:\u03bat\ni 6=0\npi\nA feasible solution to (11) is the importance sampling (also known as optimal serial sampling) p\u2217 defined by:\np\u2217i def = vi + n\u03bb\u03b3 \u2211n\nj=1 (vj + n\u03bb\u03b3) , \u2200i \u2208 [n], (12)\nwhich was proposed in (Zhao & Zhang, 2014) to obtain proximal stochastic dual coordinate ascent method with importance sampling (IProx-SDCA). The same optimal probability vector was also deduced, via different means and in a more general setting in (Qu et al., 2014). Note that in this special case, since pt is independent of the residue \u03bat, the computation of \u03bat is unnecessary and hence the complexity of each iteration does not scale up with n.\nIt seems difficult to identify other feasible solutions to program (11) apart from p\u2217, not to mention solve it exactly. However, by relaxing the constraint \u03b8(\u03bat, p) \u2264 mini:\u03bat\ni 6=0 pi, we obtain an explicit optimal solution.\nLemma 4. The optimal solution p\u2217(\u03bat) of\nmax p\u2208Rn\n+\n\u03b8(\u03bat, p) (13)\ns.t.\nn \u2211\ni=1\npi = 1\nis:\n(p\u2217(\u03bat))i = |\u03bati|\n\u221a vi + n\u03bb\u03b3\n\u2211n j=1 |\u03batj | \u221a vj + n\u03bb\u03b3 , \u2200i \u2208 [n]. (14)\nProof. The proof is deferred to the appendix.\nThe suggestion made by (14) is clear: we should update more often those dual coordinates \u03b1i which have large absolute dual residue |\u03bati| and/or large Lipschitz constant vi. If we let pt = p\u2217(\u03bat) and \u03b8 = \u03b8(\u03bat, pt), the constraint (9) may not be sastified, in which case (8) does not necessarily hold. However, as shown by the next lemma, the constraint (9) is not required for obtaining (8) when all the functions {\u03c6i}i are quadratic. Lemma 5. Suppose that all {\u03c6i}i are quadratic. Let t \u2265 0. If mini\u2208It p t i > 0, then (8) holds for any \u03b8 \u2208 [0,+\u221e).\nThe proof is deferred to Appendix."}, {"heading": "4. Convergence results", "text": "In this section we present our theoretical complexity results for AdaSDCA. The main results are formulated in Theorem 7, covering the general case, and in Theorem 11 in the special case when {\u03c6i}ni=1 are all quadratic."}, {"heading": "4.1. General loss functions", "text": "We derive the convergence result from Lemma 3.\nProposition 6. Let t \u2265 0. If mini\u2208It pti > 0 and \u03b8(\u03bat, pt) \u2264 mini\u2208It pti, then\nEt\n[ D(\u03b1t+1)\u2212D(\u03b1t) ] \u2265 \u03b8(\u03bat, pt) ( P (wt)\u2212D(\u03b1t) ) .\nProof. This follows directly from Lemma 3 and the fact that the right-hand side of (8) equals 0 when \u03b8 = \u03b8(\u03bat, pt).\nTheorem 7. Consider AdaSDCA. If at each iteration t \u2265 0, mini\u2208It p t i > 0 and \u03b8(\u03ba t, pt) \u2264 mini\u2208It pti, then\nE[P (wt)\u2212D(\u03b1t)] \u2264 1 \u03b8\u0303t\nt \u220f\nk=0\n(1\u2212 \u03b8\u0303k) ( D(\u03b1\u2217)\u2212D(\u03b10) ) ,\n(15)\nfor all t \u2265 0 where\n\u03b8\u0303t def = E[\u03b8(\u03bat, pt)(P (wt)\u2212D(\u03b1t))] E[P (wt)\u2212D(\u03b1t)] . (16)\nProof. By Proposition 6, we know that\nE[D(\u03b1t+1)\u2212D(\u03b1t)] \u2265 E[\u03b8(\u03bat, pt)(P (wt)\u2212D(\u03b1t))] (16) = \u03b8\u0303t E[P (w\nt)\u2212D(\u03b1t)] (17) \u2265 \u03b8\u0303t E[D(\u03b1\u2217)\u2212D(\u03b1t)],\nwhence\nE[D(\u03b1\u2217)\u2212D(\u03b1t+1)] \u2264 (1\u2212 \u03b8\u0303t)E[D(\u03b1\u2217)\u2212D(\u03b1t)].\nTherefore,\nE[D(\u03b1\u2217)\u2212D(\u03b1t)] \u2264 t \u220f\nk=0\n(1 \u2212 \u03b8\u0303k) ( D(\u03b1\u2217)\u2212D(\u03b10) ) .\nBy plugging the last bound into (17) we get the bound on the primal dual error:\nE[P (wt)\u2212D(\u03b1t)] \u2264 1 \u03b8\u0303t E[D(\u03b1t+1)\u2212D(\u03b1t)]\n\u2264 1 \u03b8\u0303t E[D(\u03b1\u2217)\u2212D(\u03b1t)]\n\u2264 1 \u03b8\u0303t\nt \u220f\nk=0\n(1\u2212 \u03b8\u0303k) ( D(\u03b1\u2217)\u2212D(\u03b10) ) .\nAs mentioned in Section 3, by letting every sampling probability pt be the importance sampling (optimal serial sampling) p\u2217 defined in (12), AdaSDCA reduces to IProx-SDCA proposed in (Zhao & Zhang, 2014). The convergence theory established for IProx-SDCA in (Zhao & Zhang, 2014), which can also be derived as a direct corollary of our Theorem 7, is stated as follows.\nTheorem 8 ((Zhao & Zhang, 2014)). Consider AdaSDCA with pt = p\u2217 defined in (12) for all t \u2265 0. Then\nE[P (wt)\u2212D(\u03b1t)] \u2264 1 \u03b8\u2217 (1\u2212 \u03b8\u2217)t ( D(\u03b1\u2217)\u2212D(\u03b10) ) ,\nwhere\n\u03b8\u2217 = n\u03bb\u03b3 \u2211n\ni=1(vi + \u03bb\u03b3n) .\nThe next corollary suggests that a better convergence rate than IProx-SDCA can be achieved by using properly chosen adaptive sampling probability. Corollary 9. Consider AdaSDCA. If at each iteration t \u2265 0, pt is the optimal solution of (11), then (15) holds and \u03b8\u0303t \u2265 \u03b8\u2217 for all t \u2265 0.\nHowever, solving (11) requires large computational effort, because of the dimension n and the non-convex structure of the program. We show in the next section that when all the loss functions {\u03c6i}i are quadratic, then we can get better convergence rate in theory than IProx-SDCA by using the optimal solution of (13)."}, {"heading": "4.2. Quadratic loss functions", "text": "The main difficulty of solving (11) comes from the inequality constraint, which originates from (9). In this section we mainly show that the constraint (9) can be released if all {\u03c6i}i are quadratic. Proposition 10. Suppose that all {\u03c6i}i are quadratic. Let t \u2265 0. If mini\u2208It pti > 0, then Et [ D(\u03b1t+1)\u2212D(\u03b1t) ] \u2265 \u03b8(\u03bat, pt) ( P (wt)\u2212D(\u03b1t) ) .\nProof. This is a direct consequence of Lemma 5 and the fact that the right-hand side of (8) equals 0 when \u03b8 = \u03b8(\u03bat, pt).\nTheorem 11. Suppose that all {\u03c6i}i are quadratic. Consider AdaSDCA. If at each iteration t \u2265 0, mini\u2208It pti > 0, then (15) holds for all t \u2265 0.\nProof. We only need to apply Proposition 10. The rest of the proof is the same as in Theorem 7.\nCorollary 12. Suppose that all {\u03c6i}i are quadratic. Consider AdaSDCA. If at each iteration t \u2265 0, pt is the optimal solution of (13), which has a closed form (14), then (15) holds and \u03b8\u0303t \u2265 \u03b8\u2217 for all t \u2265 0."}, {"heading": "5. Efficient heuristic variant", "text": "Corollary 9 and 12 suggest how to choose adaptive sampling probability in AdaSDCA which yields a theoretical convergence rate at least as good as IProxSDCA (Zhao & Zhang, 2014). However, there are two main implementation issues of AdaSDCA:\n1. The update of the dual residue \u03bat at each iteration costs O(nnz(A)) where nnz(A) is the number of nonzero elements of the matrix A;\n2. We do not know how to compute the optimal solution of (11).\nIn this section, we propose a heuristic variant of AdaSDCA, which avoids the above two issues while staying close to the \u2019good\u2019 adaptive sampling distribution."}, {"heading": "5.1. Description of Algorithm", "text": "Algorithm 2 AdaSDCA+ Parameter a number m > 1 Initialization Choose \u03b10 \u2208 Rn, set \u03b1\u03040 = 1\n\u03bbn A\u03b10\nfor t \u2265 0 do Primal update: wt = \u2207g\u2217 (\u03b1\u0304t) Set: \u03b1t+1 = \u03b1t\nif mod (t, n) == 0 then Option I: Adaptive probability\nCompute: \u03bati = \u03b1 t i +\u2207\u03c6i(A\u22a4i wt), \u2200i \u2208 [n]\nSet: pti \u223c |\u03bati| \u221a vi + n\u03bb\u03b3, \u2200i \u2208 [n]\nOption II: Optimal Importance probability Set: pti \u223c (vi + n\u03bb\u03b3), \u2200i \u2208 [n]\nend if Generate random it \u2208 [n] according to pt Compute:\n\u2206\u03b1tit = argmax \u2206\u2208R\n{\n\u2212\u03c6\u2217it(\u2212(\u03b1tit +\u2206))\n\u2212A\u22a4itwt\u2206\u2212 vit 2\u03bbn |\u2206|2 }\nDual update: \u03b1t+1it = \u03b1 t it +\u2206\u03b1tit Average update: \u03b1\u0304t = \u03b1\u0304t + \u2206\u03b1it \u03bbn\nAit Probability update:\npt+1it \u223c ptit/m, p t+1 j \u223c ptj , \u2200j 6= it\nend for Output: wt, \u03b1t\nAdaSDCA+ has the same structure as AdaSDCA with a few important differences.\nEpochs AdaSDCA+ is divided into epochs of length n. At the beginning of every epoch, sampling probabilities are computed according to one of two options. During each epoch the probabilities are cheaply updated at the end of every iteration to approximate the adaptive model. The intuition behind is as follows. After i is sampled and the dual coordinate \u03b1i is updated, the residue \u03bai naturally decreases. We then decrease also the probability that i is chosen in the next iteration, by setting pt+1 to be proportional to (pt1, . . . p t i\u22121, p t i/m, p t i+1, . . . , p t n). By doing this we avoid the computation of \u03ba at each iteration (issue 1) which costs as much as the full gradient algorithm, while following closely the changes of the dual residue \u03ba. We re-\nset the adaptive sampling probability after every epoch of length n.\nParameter m The setting of parameter m in AdaSDCA+ directly affects the performance of the algorithm. If m is too large, the probability of sampling the same coordinate twice during an epoch will be very small. This will result in a random permutation through all coordinates every epoch. On the other hand, for m too small the coordinates having larger probabilities at the beginning of an epoch could be sampled more often than it should, even after their corresponding dual residues become sufficiently small. We don\u2019t have a definitive rule on the choice of m and we leave this to future work. Experiments with different choices of m can be found in Section 6.\nOption I & Option II At the beginning of each epoch, one can choose between two options for resetting the sampling probability. Option I corresponds to the optimal solution of (13), given by the closed form (14). Option II is the optimal serial sampling probability (12), the same as the one used in IProx-SDCA (Zhao & Zhang, 2014). However, AdaSDCA+ differs significantly with IProx-SDCA since we also update iteratively the sampling probability, which as we show through numerical experiments yields a faster convergence than IProx-SDCA."}, {"heading": "5.2. Computational cost", "text": "Sampling and probability update During the algorithm we sample i \u2208 [n] from non-uniform probability distribution pt, which changes at each iteration. This process can be done efficiently using the Random Counters algorithm introduced in Section 6.2 of (Nesterov, 2012), which takes O(n log(n)) operations to create the probability tree and O(log(n)) operations to sample from the distribution or change one of the probabilities.\nTotal computational cost We can compute the computational cost of one epoch. At the beginning of an epoch, we need O(nnz) operations to calculate the dual residue \u03ba. Then we create a probability tree using O(n log(n)) operations. At each iteration we need O(log(n)) operations to sample a coordinate, O(nnz /n) operations to calculate the update to \u03b1 and a further O(log(n)) operations to update the probability tree. As a result an epoch needs O(nnz+n log(n)) operations. For comparison purpose we list in Table 1 the one epoch computational cost of comparable algorithms."}, {"heading": "6. Numerical Experiments", "text": "In this section we present results of numerical experiments."}, {"heading": "6.1. Loss functions", "text": "We test AdaSDCA and AdaSDCA+, SDCA, and IProxSDCA for two different types of loss functions {\u03c6i}ni=1: quadratic loss and smoothed Hinge loss. Let y \u2208 Rn be the vector of labels. The quadratic loss is given by\n\u03c6i(x) = 1\n2\u03b3 (x\u2212 yi)2\nand the smoothed Hinge loss is:\n\u03c6i(x) =\n\n \n  0 yix \u2265 1 1\u2212 yix\u2212 \u03b3/2 yix \u2264 1\u2212 \u03b3 (1\u2212yix) 2\n2\u03b3 otherwise,\nIn both cases we use L2-regularizer, i.e.,\ng(w) = 1\n2 \u2016w\u20162.\nQuadratic loss functions appear usually in regression problems, and smoothed Hinge loss can be found in linear support vector machine (SVM) problems (Shalev-Shwartz & Zhang, 2013a)."}, {"heading": "6.2. Numerical results", "text": "We used 5 different datasets: w8a, dorothea, mushrooms, cov1 and ijcnn1 (see Table 2).\nIn all our experiments we used \u03b3 = 1 and \u03bb = 1/n.\nAdaSDCA The results of the theory developed in Section 4 can be observed through Figure 1 to Figure 4. AdaSDCA needs the least amount of iterations to converge, confirming the theoretical result.\nAdaSDCA+ V.S. others We can observe through Figure 15 to 24, that both options of AdaSDCA+ outperforms SDCA and IProx-SDCA, in terms of number of iterations, for quadratic loss functions and for smoothed Hinge loss functions. One can observe similar results in terms of time through Figure 5 to Figure 14.\nOption I V.S. Option II Despite the fact that Option I is not theoretically supported for smoothed hinge loss, it still converges faster than Option II on every dataset and for every loss function. The biggest difference can be observed on Figure 13, where Option I converges to the machine precision in just 15 seconds.\nDifferent choices of m To show the impact of different choices of m on the performance of AdaSDCA+, in Figures 25 to 33 we compare the results of the two options of AdaSDCA+ using different m equal to 2, 10 and 50. It is hard to draw a clear conclusion here because clearly the optimal m shall depend on the dataset and the problem type."}], "references": [], "referenceMentions": [], "year": 2015, "abstractText": "<lb>This paper introduces AdaSDCA: an adap-<lb>tive variant of stochastic dual coordinate as-<lb>cent (SDCA) for solving the regularized empir-<lb>ical risk minimization problems. Our modifica-<lb>tion consists in allowing the method adaptively<lb>change the probability distribution over the dual<lb>variables throughout the iterative process. AdaS-<lb>DCA achieves provably better complexity bound<lb>than SDCA with the best fixed probability dis-<lb>tribution, known as importance sampling. How-<lb>ever, it is of a theoretical character as it is expen-<lb>sive to implement. We also propose AdaSDCA+:<lb>a practical variant which in our experiments out-<lb>performs existing non-adaptive methods.", "creator": "LaTeX with hyperref package"}}}