{"id": "1505.05947", "review": {"conference": "arxiv", "VERSION": "v1", "DATE_OF_SUBMISSION": "22-May-2015", "title": "A Pareto Front-Based Multiobjective Path Planning Algorithm", "abstract": "path planning concept is one of the most vital underlying elements of european mobile device robotics. fitted with basically a priori knowledge of the environment environment, underlying global path spectral planning provides a collision - free route through the space workspace. the global resource path plan can clearly be calculated with simultaneously a variety of partially informed intersection search algorithms, featuring most notably the a * search method method, guaranteed to uniquely deliver a complete and functional optimal scheduling solution that minimizes the path cost. path planning optimization applications typically prominently looks to minimize the traveled distance traversed from destination start locality to goal, yet many mobile robot solving applications call for additional additional online path integral planning objectives, presenting a multiobjective error optimization ( moo ) problem. similarly past studies have essentially applied genetic algorithms purely to moo path planning problems, but these may have the disadvantages of lower computational complexity and require suboptimal solutions. alternatively, the candidate algorithm in this article paper probably approaches additional moo path planning methods with the enhanced use of pareto - fronts, implement or avoid finding partial non - interference dominated solutions. the algorithm presented technically incorporates pareto oriented optimality curves into rendering every step courtesy of producing a * path search, thus thus showing it is additionally named a * - pu po. results of simulations presently show how a * - po strategies outperformed substantially several geometric variations of the modern standard a * po algorithm typical for moo distributed path planning. a small planetary exploration rover 2009 case study series was added to broadly demonstrate the genetic viability paradox of supporting a * - po in a real - world application.", "histories": [["v1", "Fri, 22 May 2015 04:35:12 GMT  (3734kb)", "http://arxiv.org/abs/1505.05947v1", null]], "reviews": [], "SUBJECTS": "cs.AI cs.RO", "authors": ["alexander lavin"], "accepted": false, "id": "1505.05947"}, "pdf": {"name": "1505.05947.pdf", "metadata": {"source": "CRF", "title": null, "authors": ["Alexander Lavin"], "emails": ["alavin@alumni.cmu.edu)."], "sections": [{"heading": null, "text": "Keywords\u2014multiobjective optimization; path planning; search algorithm; A*; Pareto; mobile robot; Mars rover\nI. INTRODUCTION A crucial task for mobile robots is to navigate intelligently through their environment. It can be argued that path planning is one of the most important issues in the navigation process [1], and subsequently much research in field robotics is concerned with path planning [2], [3]. To complete the navigation task, methods read the map of the environment and search algorithms attempt to find free paths for the robot to traverse. Path planning methods find a path connecting the defined start and goal positions, while environmental parameters play the role as algorithm inputs, and the output is an optimized path from the start to goal [4]. An important issue in mobile robot navigation is optimizing path efficiency according to some parameters such as cost, distance, energy, and time. Of these criteria, time and distance are typically the most important for researchers [5], and methods typically optimize the path efficiency for only one criterion [6]. Yet many mobile robot operations call for a path plan that is efficient over several parameters. Path optimization over several parameters \u2013 e.g. distance and energy \u2013 is a multiobjective optimization (MOO) problem. The best path is not necessarily the shortest path, nor the path calling for the least amount of energy expenditure.\nAlexander Lavin was a mechanical engineering graduate student with Carnegie Mellon University. This work was completed independently after graduation in 2014 (email: alavin@alumni.cmu.edu).\nCombining the optimization criteria into a single objective function is a common approach, often with tools such as thresholds and penalty functions, and weights for linear combinations of attribute values. But these methods are problematic as the final solution is typically very sensitive to small adjustments in the penalty function coefficients and weighting factors [6]. Evolutionary algorithms, particularly genetic algorithms, have been used widely for MOO problems, including success in path planning [7], [8]. Some state-of-the-art algorithms for multiobjective evolutionary computation include NSGA-II and SPEA2 [9], [10]. The merging of path segments can result in offspring solutions with high scores across several fitness criteria. The non-dominated paths are favored in the population, and this increases generation over generation [11]. Non-dominated solutions are those in which there exists no other solutions superior in all attributes. In attribute space, the set of non-dominated solutions lie on a surface known as the Pareto front. Fig. 1 illustrates the twodimensional case, where there is a tradeoff between minimizing both f1 and f2. The goal of a Pareto evolutionary algorithm is to find a set of solutions along the Pareto front, optimal for a combination of criteria [12].\nThis study looks to use multiobjective optimization for mobile robot path planning, but with a Pareto front cost function. Other studies have applied Pareto optimality to evolutionary planning for synchronous optimization of several objectives [8], and domination metrics are used in some evolutionary algorithms for path planning, including NSGA-II and SPEA2 [11], [12]. Yet these algorithms compare complete paths for domination. In order to sort a population according to the level of non-domination, each path must be compared with every other path in the population to find if it is dominated, where the computational complexity scales exponentially with the search space [9]. The algorithm presented in this study, however, checks for\nnon-domination at each search step, resulting in a single, optimal path. The path planning algorithm is novel because each step is Pareto optimal.\nThe next section further discusses Pareto optimality and the application to mobile robot path planning. Section III discusses the technical approach used in this study, and Section IV presents the results. Included in Section IV is a Mars rover case study as an example application of the new A*-PO algorithm. Other applications for mobile robots with global path planning include agricultural harvesting and information gathering (i.e. drones), disaster relief, DARPA challenges, factory and residential robot workers, and exploration rovers. Section V concludes the paper with discussion and future work.\nII. MATERIALS AND METHODS"}, {"heading": "A. Mobile Robot Path Planning", "text": "The aim of mobile robot path planning is to provide an efficient path from start to goal that avoids objects and obstacles. An efficient path is one that minimizes path costs, where the cost is typically the travel distance or time.\nPath planning methods can be categorized as either static or dynamic, according to the environmental conditions. The positions of all obstacles and objects in the static environment are fixed and known. The dynamic environment, on the other hand, may have obstacles and objects that vary positions with time. Similarly, an unknown environment calls for dynamic path planning because more is learned as the mobile robot progresses through the environment. The algorithms for path planning are also in two categories: local and global. Local algorithms function as the robot moves through the environment, revising the path based on environmental changes. Global algorithms use a priori knowledge of the environment to plan the path, and are thus applicable to planning in static environments. Each method has its own pros and cons depending on the environment and application type [8].\nThe control architecture in mobile robotics is typically a combination of local and global planners, organized as shown in Fig 2. The reactive layer handles local information, with real-time constraints. The deliberative, or global, layer considers the entire world, likely requiring computation time proportional to the problem size [15]. The algorithm presented in this paper is a global path planner.\nThere are two main components of global path planning. First is the robot representation of the world in the configuration space: data structures that show the position and orientations of objects and robots in the workspace area, including both the free and obstructed regions. The configuration spaces of path planning algorithms are usually represented by an occupancy grid, a vertex graph, a Voronoi diagram, generalized cones, or a quad-tree [1].\nThe methods discussed in this study use an occupancy grid, where the environment is represented by a twodimensional layout of square cells. The values of these cells are binary states, where 0s and 1s represent free and occupied spaces, respectively. The robot occupies a cell, with or without orientation. For a given cell currently occupied by the robot, there are eight feasible cells in the path that can be successors. This is shown in Fig. 3, where the robot in the green position is capable of moving into a neighboring yellow position, but not the occupied gray cells. Feasible solution paths never collide the robot with an obstacle.\nThe second main component of global path planning is implementing an algorithm to find an optimal path from start to goal states. That is, for two arbitrary points in the area \u2013 the start and the goal \u2013 the algorithm finds a drivable path between them that minimizes distance, energy, or some other criteria. The algorithm employed for the problem must coordinate with the configuration space representation [1]. Potential solution paths connect the start cell to the goal cell via free cells. Searching for the most efficient path is an optimization problem, where the optimum path is defined as that which minimizes the path cost, or the objective function.\nA candidate path can be denoted by\n\ud835\udc43 = {\ud835\udc5d!, \ud835\udc5d!,\u2026 , \ud835\udc5d!} (1)\nwhere \ud835\udc5d! is the \ud835\udc56th waypoint of the path \ud835\udc43. The MOO problem is then framed as determining a path\n\ud835\udc43\u2217 \u2208 \ud835\udc43 (2)\nthat satisfies\n\ud835\udc39 \ud835\udc43\u2217 = \ud835\udc5a\ud835\udc56\ud835\udc5b \ud835\udc39! \ud835\udc43 ,\ud835\udc39! \ud835\udc43 ,\u2026 ,\ud835\udc39!(\ud835\udc43) (3)\nwhere \ud835\udc39!denotes the \ud835\udc56th cost function of the path planning problem. The study here considers three cost functions, or \ud835\udc61 = 3. They are defined in (4) and (5) below, and (6) later in the Mars rover case study.\nEquation (4) gives the total length of the path:\n\ud835\udc39! \ud835\udc43 = \ud835\udc5d! , \ud835\udc5d!!!\n!!!\n!!!\n(4)\nwhere \ud835\udc5d! , \ud835\udc5d!!! is the Euclidean distance between subsequent cells in the path. Minimizing \ud835\udc39! finds the path of shortest length from start to goal.\nEquation (5) gives the average elevation of the path:\n\ud835\udc39! \ud835\udc43 = \ud835\udc52!/\ud835\udc5b !\n!!!\n(5)\nwhere \ud835\udc52! is the elevation at waypoint \ud835\udc56\u2026 \ud835\udc5b . With the fixed start and goal states at constant elevation, the minimization of \ud835\udc39! gives the path that climbs up the least amount of incline (or alternatively moves the robot down the most decline).\nSearch algorithms are employed for finding the minimal cost paths through the configuration space. Uninformed search methods are used when no information about the states are known beyond the problem definition [14]. The global path planning problem discussed here has a priori knowledge \u2013 a map of the exploration area. Thus uninformed search methods, like Dijkstra\u2019s breadth-first algorithm, can be ignored in favor of informed search methods. The general approach of these methods is best-first, which traverses a graph or grid using a priority queue to find the shortest, collision-free path [4]. The decision of the next node expanded, the successor, is based on an evaluation function, \ud835\udc53(\ud835\udc5b): estimated cost of the cheapest solution through node \ud835\udc5b. The choice of \ud835\udc53(\ud835\udc5b) determines the search strategy. A bonus of informed search is including a heuristic function \u210e(\ud835\udc5b): the estimated cost of the cheapest path from a node \ud835\udc5b to the goal state. Greedy best-first search is built solely on this heuristic, where \ud835\udc53 \ud835\udc5b = \u210e(\ud835\udc5b) , expanding the node closest to the goal at each search step. The incorporation of the heuristic into the path cost makes the search algorithm more efficient. The search algorithm also gains efficiency by using a priority queue, or open list, to update the costs of nodes. From the open list, the algorithm chooses successor nodes to expand.\nThe A* algorithm is perhaps the most popular best-first search method, adding to the heuristic the cost to reach the node, \ud835\udc54(\ud835\udc5b) . That is, \ud835\udc53 \ud835\udc5b = \u210e \ud835\udc5b + \ud835\udc54(\ud835\udc5b) . The search algorithm, looking for the cheapest path, tries (expands) the node with the lowest \ud835\udc53 \ud835\udc5b [15], [16]. To determine the optimal sequence of waypoints (i.e. path), the A* algorithm is a favorite for route search problems [17], [18]. For graph search, as opposed to tree search, a consistency condition is required to guarantee optimality. A heuristic is consistent if, for every node \ud835\udc5b and every successor \ud835\udc5b\u2032 of \ud835\udc5b generated by any action \ud835\udc4e, the estimated cost of reaching the goal from \ud835\udc5b is no greater than the step cost of getting to \ud835\udc5b\u2032 plus the estimated cost of reaching the goal from \ud835\udc5b\u2032:\n\u210e \ud835\udc5b \u2264 \ud835\udc50 \ud835\udc5b, \ud835\udc4e, \ud835\udc5b! + \u210e(\ud835\udc5b!) (6)\nNorvig and Russel [15] explain how the A* heuristic satisfies the consistency condition, and also that A* is optimally efficient: no other optimal algorithm is guaranteed\nto expand fewer nodes than A*. As long as a better-informed heuristic is not used, A* will find the least-cost path solution at least as fast as any other method.\nFor real-time planning, where computational speed is a priority, previous studies [19], [20] have modified A* for fast planning. The D* algorithm is a dynamic version of A*, built to be capable of fast rerouting when the robot encounters new obstacles in the environment [4]. The speed of these searching algorithms is increased dramatically, but at the cost of sub-optimal solution paths [14]."}, {"heading": "B. Pareto Optimality", "text": "The MOO problem presents multiple cost criteria, where a solution stronger for one criterion may be weaker for another. There are two general approaches to optimizing for multiple objectives: (i) combine the individual objectives into one composite function, and (ii) determine a Pareto optimal solution set. The first can be accomplished with weighted sums or utility functions, but selection of parameters is difficult because small perturbations in the weights can lead to very different solutions. The second option finds the Pareto optimal set of the population, which is a set of solutions that are non-dominated with respect to each other. That is, moving between Pareto solutions, there is always sacrifice in one objective to achieve gain in another objective [21]. It is advantageous to incorporate Pareto fronts in evolutionary algorithm fitness functions when tackling MOO problems. Simply summing over the fitness criteria presents difficulties. Yet in search methods it is common the cost function sums over the cost criteria at each step; the A* algorithm sums \u210e \ud835\udc5b and \ud835\udc54(\ud835\udc5b).\nAlgorithm 1 A* Search 1 Initialize open and closed lists 2 Put the starting node in the open list 3 Define f, the cost function 4 While the open list is not empty 5 q \u00df node on open list with smallest f 6 Remove q from open list 7 Generate q's 8 successors, set their parents to q 8 For each successor 9 If successor is a goal, then stop search 10 successor.g \u00df q.g + distance between successor and q 11 successor.h \u00df distance from successor to goal 12 successor.f \u00df successor.g + successor.h 13 If a node with same position as successor is in the open list & has a lower f than successor, then skip this successor 14 If a node with same position as successor is in the closed list & has a lower f than successor, then skip this successor 15 Else, add the node to the open list"}, {"heading": "16 End For", "text": "17 Push q to the closed list 18 End While\nFor minimization of objective function \ud835\udc53, a point \ud835\udc5b\u2217 is said to be a Pareto optimal point if there is no \ud835\udc5b such that \ud835\udc53!(\ud835\udc5b) \u2264 \ud835\udc53! \ud835\udc5b\u2217 for all \ud835\udc56 = 1\u2026 \ud835\udc61 , where there are \ud835\udc61 optimization objectives.\nPoint \ud835\udc5b\u2217 \u2208 \ud835\udc36 is a non-inferior solution if for some neighborhood of \ud835\udc5b\u2217 there does not exist a \u2206\ud835\udc5b such that \ud835\udc5b\u2217 + \u2206\ud835\udc5b \u2208 \ud835\udc36,\n\ud835\udc53! \ud835\udc5b\u2217 + \u2206\ud835\udc5b \u2264 \ud835\udc53! \ud835\udc5b\u2217 , \ud835\udc56 = 1,\u2026 ,\ud835\udc5a, and\n\ud835\udc53! \ud835\udc5b\u2217 + \u2206\ud835\udc5b \u2264 \ud835\udc53! \ud835\udc5b\u2217 for at least one \ud835\udc57.\nMultiobjective optimization is, therefore, concerned with the generation and selection of non-inferior solution points \u2013 those on the Pareto front. Pareto optimality is a crucial concept for finding solutions to MOO problems because identifying a single solution that simultaneously optimizes across several objectives is often an impossible task [22].\nIt is worth noting that summing over the costs to calculate a composite \ud835\udc53 presents another possible issue in search algorithms: depending on the current development of the path, some cost criteria may be favored over others, and this changes as the path development continues. For instance, the A* heuristic \u2013 the estimated cost of the cheapest path from the current cell to the goal cell \u2013 will contribute more to the cost function close to the start than it will close to the goal. That is, near the start state \u210e(\ud835\udc5b) will have greater influence on \ud835\udc53 than will \ud835\udc54(\ud835\udc5b); the inverse is true near the goal state. Thus, as the path develops from start to goal, the heuristic value will contribute less and less. Using a Pareto front solves this issue because each cost criterion is valued as its own dimension in the Pareto space, not summed together.\nIII. TECHNICAL APPROACH"}, {"heading": "A. Costmap", "text": "To calculate cost functions at each step the search algorithm uses a costmap. This representation of the configuration space is built off of the aforementioned occupancy grid, but now a cost value is assigned to each cell. Traversing a free space adds a unit cost to the path total, and the obstacles are represented by infinite cost; thus, they are not traversable. If traversing straight across a cell carries a unit distance cost, the cost for traversing a cell at a diagonal (a 45\u00b0 angle) carries a cost of 2.\nYet this costmap only reflects the distance of taking a given path through the configuration space. For a MOO problem, the path cost needs to consider the other cost criteria, for which I use additional layers. Each additional cost layer adds a dimension to the Pareto space, from which the Pareto front is calculated. The first costmap layer is the distance cost, \ud835\udc54(\ud835\udc5b). The second layer is the heuristic, \u210e(\ud835\udc5b). These two suffice for traditional A* search, but I\u2019m also interested in optimizing the robot\u2019s path for elevation \u2013 i.e. minimize (5). A third layer, \ud835\udc52(\ud835\udc5b) , is then added to the costmap. With three layers, the Pareto space is threedimensional. That is, points on the Pareto front are optimal across the three dimensions, one for each cost \u2013 distance, the heuristic, and elevation.\nAlgorithm 2 A*-PO Search (replaces line 8+ of Alg. 1) 8 For each successor 9 If successor is a goal, then stop search 10 successor.g \u00df q.g + distance between successor and q 11 successor.h \u00df distance from successor to goal 12 successor.e \u00df elevation of succesor 13 scoreMatrix(successor) \u00df [successor.g, \u2026 successor.h, successor.e]"}, {"heading": "14 End For", "text": "15 q \u00df Calculate Pareto front of scoreMatrix 16 If multiple points on Pareto front 17 Normalize scoreMatrix 18 q \u00df run std. A* cost function on Pareto front nodes 19 Push q to the closed list"}, {"heading": "20 End While", "text": ""}, {"heading": "B. A*-PO Search Algorithm", "text": "The algorithm presented in this study, A*-PO, is essentially the standard A* search algorithm but for a key modification: rather than computing the cost function \ud835\udc53 by summing cost criteria, A*-PO calculates the Pareto front of the cost criteria. Lines 8-16 in the previous A* pseudocode are replaced by the pseudocode shown above.\nCalculating the Pareto front of the open list will at times yield multiple Pareto points. That is, q (in the pseudocode) may contain multiple Pareto points. For this scenario, where multiple nodes makeup the Pareto front, one is chosen from the set of Pareto points via the normalized A* cost calculation. For instance, consider a given step of the path search with an open list (i.e. priority queue) consisting of 11 nodes, and perhaps three fall on the Pareto front. The algorithm will first normalize the three nodes for each cost criteria such that the range for each criterion is [0:1] for the set of nodes on the Pareto front; note the normalization is across each dimension of the Pareto space. Then the A* cost metric is used to decide between these Pareto front nodes. Thus, the A*-PO search algorithm still maintains the quality that every step is Pareto optimal; i.e. the successor node is always a Pareto optimal point.\nIV. RESULTS The MOO path planning algorithms are tested in simulated mobile robot environments. The computer simulation environment includes a Lenovo notebook computer with Intel Core i5 vPro CPU and 4 GB memory, running on Windows 8.1. The code is written in MATLAB R2013a, and will be published in a future release of Corke\u2019s \u201cRobotics, Vision, Control\u201d [23]."}, {"heading": "A. Algorithm Comparison", "text": "The A* search algorithm is guaranteed complete and optimal, but not necessarily for MOO path problems. The advantages of A*-PO are significant for MOO path problems. I evaluated A*-PO by comparing it with A* for a set of 80 simulated environments.\nThe workspaces were setup as 20x18 cell grids of randomly assigned free spaces and obstacles, the obstacles accounting for 20% of the workspace. The start and goal locations were fixed at the upper left (0,0) and lower right (20,18), respectively. The elevations for the goal and start states were at 0 in each in configuration, where the terrain ranged [0:1]. Eight unique terrains were used in the simulations.\nThe optimization objectives, as presented above in (3) and (4), were to minimize the total path distance and elevation. Fig. 4 shows an example of the resulting paths for each search method in pink, where the gray squares represent the path steps; the red and green marked squares represent the start and goal states, respectively. The left side diagrams of Fig. 4 are the final solution paths over a grid of obstacles (black) and free spaces (white), representing the occupancy\ngrid layer of the costmap. The right side diagrams show the same paths over a contour map, representing the elevation layer of the costmap.\nFor one of the 80 simulation runs, Fig. 4a shows the final solution path of the standard A* algorithm for the distance travelled, the heuristic, and the elevation cost criteria. At each search step the costs for each criteria were normalized [0:1] over the nodes in the open list. It was necessary to normalize the path costs at each search step because the elevation values are small relative to the distance values; without normalization the elevation metric would be insignificant. This normalization is unnecessary for the A*PO algorithm because each cost value is relative to the cost metric\u2019s dimension in Pareto space. Fig. 4b shows the solution path for the A*-PO algorithm of the same simulation environment as A* in Fig. 4a.\n \u00a0\nFor the sample workspace and terrain in this example, it is clear to see the benefits of calculating the Pareto front at each search step. The data over the set of 80 simulations echo these results, as shown in Table 1. The A*-PO algorithm outperforms the other A* variations for the optimization objective functions \ud835\udc39!(\ud835\udc43) and \ud835\udc39!(\ud835\udc43), the path length (steps) and average elevation (normalized), respectively. The search time results show paths with Pareto optimal steps can be obtained efficiently with the A*-PO algorithm, with only a slight increase in computation time over the standard A* search algorithm. All algorithms gave complete solution paths.\nThe average elevation of each solution path is used as a metric to compare the robot\u2019s net incline from start to goal. A path of a given average elevation implies the robot traversed up less slope (or down more slope) as compared to a path of higher average elevation. Lower values are preferred for the mean elevation, as well as the other path cost metrics."}, {"heading": "B. Case Study", "text": "A case study is presented to demonstrate the application of the A*-PO algorithm in a potential use case. An example Mars terrain was sourced from HiRISE, the High Resolution Imaging Science Experiment conducted by the University of Arizona, NASA, JPL, and USGS [24]. Fig. 5 shows a digital terrain model of a Mars landscape, from which a section (red square) was extracted for use in the case study.\nThe extracted section was converted to a terrain map with elevation values [0:1], as shown in Fig. 6. The overlaid occupancy grid was generated randomly, with obstacles accounting for 30% of the workspace. The dimensions are 100x100, where each cell represents a 1m2 area.\nIn addition to the path planning objectives used above, the case study included an additional aim of maximizing the solar incidence on the rear of the rover. That is, the MOO problem included an additional optimization objective to minimize the total angular deviation of sunlight from the solar panel. This was computed by minimizing the dot product of the rover vector \ud835\udc5f and the solar ray vector \ud835\udc60:\n\ud835\udc39! \ud835\udc43 = \ud835\udc5f \u2219 \ud835\udc60 = \ud835\udc5f \ud835\udc60 \ud835\udc50\ud835\udc5c\ud835\udc60\ud835\udf03 (7)\nThe solar incidence cost criteria was incorporated as an additional layer to the costmap. However, this layer was dependent on the robot\u2019s orientation in the configuration space, and was thus dynamic. That is, the costmap changed at each step in the path, depending on the two-dimensional rover vector. For this case study, the solar angle was held constant and two-dimensional. Thus, there were eight variations of the solar costmap, or one for each possible angle between the solar and rover vectors.\n \u00a0\nThe result paths shown in Fig. 6 are Pareto optimal at each step across three independent cost functions, \ud835\udc39!!! of (4), (5), (7). The three functions cover the four cost criteria because both the distance travelled and the heuristic contribute to \ud835\udc39!. The case study shows the A*-PO algorithm provides the least-cost global path according to several independent preferences for a mobile robot in practice.\nFurther studies may aim to more accurately include the solar incidence as a cost metric. This can be done by varying the angle of sunlight with time, as the rover progresses along its path. Or calculating the solar incidence in threedimensional space. Additionally, one may account for more elaborate thermal constraints, such as heating of sensitive components by direct sunlight.\nV. CONCLUSION In this study, global path planning for mobile robots is investigated. The optimal path is generated according to several cost criteria, solving the multiobjective optimization problem with the presented A*-PO algorithm. As demonstrated in the simulations, A*-PO is capable of providing paths where each step is Pareto optimal, and computes these solutions efficiently. In comparison to the traditional A* algorithm in this study, it can be concluded the use of Pareto fronts in A*-PO offers a better MOO search algorithm.\nIn future work, Pareto optimality may be incorporated into other algorithms of the mobile robot control system architecture (Fig. 1). The mobile robot community has put an increased emphasis on suboptimal path planning methods which meet the time-critical constraints over slow, optimal algorithms [14]. Local and dynamic path planners, such as D*, may improve with Pareto cost functions."}, {"heading": "ACKNOWLEDGMENT", "text": "The author would like to thank Professors Matthew Eicholtz and David Wettergreen of Carnegie Mellon University for their continued support and mentorship."}], "references": [{"title": "An Overview of Autonomous Mobile Robot Path Planning Algorithms", "author": ["N. Sariff", "N. Buniyamin"], "venue": "Research and Development, 2006. SCOReD 2006. 4th Student Conference on , vol., no., pp.183,188, 27- 28 June 2006", "citeRegEx": "1", "shortCiteRegEx": null, "year": 2006}, {"title": "Literature review on path planning in dynamic environment", "author": ["P.M. Bhushan Mahajan"], "venue": "International Journal of Computer Science and Network, vol. 2, no. 1, pp. 115\u2013118, 2013.", "citeRegEx": "2", "shortCiteRegEx": null, "year": 2013}, {"title": "Map-based navigation in mobile robots:: Ii. a review of map-learning and path-planning strategies", "author": ["J.-A. Meyer", "D. Filliat"], "venue": "Cognitive Systems Research, vol. 4, no. 4, pp. 283 \u2013 317, 2003", "citeRegEx": "3", "shortCiteRegEx": null, "year": 2003}, {"title": "Optimal and efficient path planning for partiallyknown environments.", "author": ["Stentz", "Anthony"], "venue": "Robotics and Automation,", "citeRegEx": "4", "shortCiteRegEx": "4", "year": 1994}, {"title": "Fast replanning for navigation in unknown terrain", "author": ["S. Koenig", "M. Likhachev"], "venue": "Robotics, IEEE Transactions on, vol. 21, no. 3, pp. 354\u2013363, 2005.", "citeRegEx": "5", "shortCiteRegEx": null, "year": 2005}, {"title": "Some guidelines for genetic algorithms with penalty  functions", "author": ["Jon T. Richardson", "Mark R. Palmer", "Gunar E. Liepins", "Mike Hilliard"], "venue": "In Proceedings of the third international conference on Genetic algorithms,", "citeRegEx": "6", "shortCiteRegEx": "6", "year": 1989}, {"title": "Multi-objective Mobile Robot Path Planning Based on Improved Genetic Algorithm", "author": ["Hu Jun", "Zhu Qingbao"], "venue": "Intelligent Computation Technology and Automation (ICICTA), 2010 International Conference on , vol.2, no., pp.752,756, 11-12 May 2010", "citeRegEx": "7", "shortCiteRegEx": null, "year": 2010}, {"title": "Global Path Planning for Autonomous Mobile Robot Using Genetic Algorithm", "author": ["M. Samadi", "M.F. Othman"], "venue": "Signal-Image Technology & Internet-Based Systems (SITIS), 2013 International Conference on , vol., no., pp.726,730, 2-5 Dec. 2013", "citeRegEx": "8", "shortCiteRegEx": null, "year": 2013}, {"title": "A fast and elitist multiobjective genetic algorithm: NSGA-II", "author": ["K. Deb", "A Pratap", "S. Agarwal", "T. Meyarivan"], "venue": "Evolutionary Computation, IEEE Transactions on , vol.6, no.2, pp.182,197, Apr 2002.", "citeRegEx": "9", "shortCiteRegEx": null, "year": 2002}, {"title": "Indicator-based selection in multiobjective search", "author": ["E. Zitzler", "S. Knzli"], "venue": "Parallel Problem Solving from Nature - PPSN VIII, ser. Lecture Notes in Computer Science, X. Yao, E. Burke, J. A. Lozano, J. Smith, J. J. Merelo-Guervs, J. A. Bullinaria, J. Rowe, P. Tino, A. Kabn, and H.-P. Schwefel, Eds. Springer Berlin / Heidelberg, 2004, vol. 3242, pp. 832\u2013842.", "citeRegEx": "10", "shortCiteRegEx": null, "year": 2004}, {"title": "Step-spreading map knowledge based multi-objective genetic algorithm for robotpath planning", "author": ["Jin Yuan", "Tao Yu", "Wang, Kesheng", "Xuemei Liu"], "venue": "Systems, Man and Cybernetics, 2007. ISIC. IEEE International Conference on , vol., no., pp.3402,3407, 7-10 Oct. 2007", "citeRegEx": "11", "shortCiteRegEx": null, "year": 2007}, {"title": "A niched Pareto genetic algorithm for multiobjective optimization", "author": ["J. Horn", "N. Nafpliotis", "D.E. Goldberg"], "venue": "Evolutionary Computation, 1994. IEEE World Congress on Computational Intelligence., Proceedings of the First IEEE Conference on , vol., no., pp.82,87 vol.1, 27-29 Jun 1994", "citeRegEx": "12", "shortCiteRegEx": null, "year": 1994}, {"title": "Multi-objective Optimization - Design of Control Arm Using HyperWorks - Altair HyperWorks Insider.", "author": ["Bonino", "Simone"], "venue": "Altair HyperWorks Insider. N.p.,", "citeRegEx": "13", "shortCiteRegEx": "13", "year": 2010}, {"title": "Graph-based Path Planning for Mobile Robots.\" Thesis", "author": ["Wooden", "David T"], "venue": "Georgia Institute of Technology,", "citeRegEx": "14", "shortCiteRegEx": "14", "year": 2006}, {"title": "Artificial Intelligence: A Modern Approach", "author": ["Norvig", "Peter", "Stuart Russell"], "venue": "NJ: Pearson Education Limited,", "citeRegEx": "15", "shortCiteRegEx": "15", "year": 2013}, {"title": "Mission-Integrated Path Planning for Planetary Rover Exploration.", "author": ["Wu", "Peng", "Hehua Ju"], "venue": "Journal of Software", "citeRegEx": "16", "shortCiteRegEx": "16", "year": 2013}, {"title": "Fuzzy terrain-based path planning for planetary rovers", "author": ["A. Howard", "H. Seraji", "B. Werger"], "venue": "Proceedings of the 2002 IEEE International Conference on Fuzzy Systems, vol.1, pp.316-320, 2002.", "citeRegEx": "17", "shortCiteRegEx": null, "year": 2002}, {"title": "An Integrated Traverse Planner and Analysis Tool for Planetary Exploration.", "author": ["Johnson", "Aaron", "Jeffrey Hoffman", "Dava Newman", "Erwan Mazarico", "Maria Zuber"], "venue": "AIAA SPACE 2010 Conference & Exposition, Anaheim, California,", "citeRegEx": "18", "shortCiteRegEx": "18", "year": 2010}, {"title": "Solving the find-path problem in mapped environments using modified A* search algorithm", "author": ["Kuo-Chin Fan", "Po-Chang Lui"], "venue": "IEEE Transactions on Systems, Man, and Cybernetics, vol.24, no.9, September 1994, pp 1390-1396.", "citeRegEx": "19", "shortCiteRegEx": null, "year": 1994}, {"title": "Fast path planning method using modified A* method", "author": ["Charles W. Warren"], "venue": ". IEEE International Conference on Robotics and Automation, pp 662-667.", "citeRegEx": "20", "shortCiteRegEx": null, "year": 0}, {"title": "Calculating Complete and Exact Pareto Front for Multiobjective Optimization: A New Deterministic Approach for Discrete Problems", "author": ["Xiao-Bing Hu", "Ming Wang", "Di Paolo, E."], "venue": "Cybernetics, IEEE Transactions on , vol.43, no.3, pp.1088,1101, June 2013", "citeRegEx": "22", "shortCiteRegEx": null, "year": 2013}, {"title": "Robotics, Vision & Control", "author": ["P.I. Corke"], "venue": "Springer 2011,", "citeRegEx": "23", "shortCiteRegEx": "23", "year": 2014}], "referenceMentions": [{"referenceID": 0, "context": "It can be argued that path planning is one of the most important issues in the navigation process [1], and subsequently much research in field robotics is concerned with path planning [2], [3].", "startOffset": 98, "endOffset": 101}, {"referenceID": 1, "context": "It can be argued that path planning is one of the most important issues in the navigation process [1], and subsequently much research in field robotics is concerned with path planning [2], [3].", "startOffset": 184, "endOffset": 187}, {"referenceID": 2, "context": "It can be argued that path planning is one of the most important issues in the navigation process [1], and subsequently much research in field robotics is concerned with path planning [2], [3].", "startOffset": 189, "endOffset": 192}, {"referenceID": 3, "context": "Path planning methods find a path connecting the defined start and goal positions, while environmental parameters play the role as algorithm inputs, and the output is an optimized path from the start to goal [4].", "startOffset": 208, "endOffset": 211}, {"referenceID": 4, "context": "Of these criteria, time and distance are typically the most important for researchers [5], and methods typically optimize the path efficiency for only one criterion [6].", "startOffset": 86, "endOffset": 89}, {"referenceID": 5, "context": "Of these criteria, time and distance are typically the most important for researchers [5], and methods typically optimize the path efficiency for only one criterion [6].", "startOffset": 165, "endOffset": 168}, {"referenceID": 5, "context": "But these methods are problematic as the final solution is typically very sensitive to small adjustments in the penalty function coefficients and weighting factors [6].", "startOffset": 164, "endOffset": 167}, {"referenceID": 6, "context": "Evolutionary algorithms, particularly genetic algorithms, have been used widely for MOO problems, including success in path planning [7], [8].", "startOffset": 133, "endOffset": 136}, {"referenceID": 7, "context": "Evolutionary algorithms, particularly genetic algorithms, have been used widely for MOO problems, including success in path planning [7], [8].", "startOffset": 138, "endOffset": 141}, {"referenceID": 8, "context": "Some state-of-the-art algorithms for multiobjective evolutionary computation include NSGA-II and SPEA2 [9], [10].", "startOffset": 103, "endOffset": 106}, {"referenceID": 9, "context": "Some state-of-the-art algorithms for multiobjective evolutionary computation include NSGA-II and SPEA2 [9], [10].", "startOffset": 108, "endOffset": 112}, {"referenceID": 10, "context": "The non-dominated paths are favored in the population, and this increases generation over generation [11].", "startOffset": 101, "endOffset": 105}, {"referenceID": 11, "context": "The goal of a Pareto evolutionary algorithm is to find a set of solutions along the Pareto front, optimal for a combination of criteria [12].", "startOffset": 136, "endOffset": 140}, {"referenceID": 12, "context": "Two-dimensional Pareto space, where points x1 and x2 lie on the Pareto front [13].", "startOffset": 77, "endOffset": 81}, {"referenceID": 7, "context": "Other studies have applied Pareto optimality to evolutionary planning for synchronous optimization of several objectives [8], and domination metrics are used in some evolutionary algorithms for path planning, including NSGA-II and SPEA2 [11], [12].", "startOffset": 121, "endOffset": 124}, {"referenceID": 10, "context": "Other studies have applied Pareto optimality to evolutionary planning for synchronous optimization of several objectives [8], and domination metrics are used in some evolutionary algorithms for path planning, including NSGA-II and SPEA2 [11], [12].", "startOffset": 237, "endOffset": 241}, {"referenceID": 11, "context": "Other studies have applied Pareto optimality to evolutionary planning for synchronous optimization of several objectives [8], and domination metrics are used in some evolutionary algorithms for path planning, including NSGA-II and SPEA2 [11], [12].", "startOffset": 243, "endOffset": 247}, {"referenceID": 8, "context": "In order to sort a population according to the level of non-domination, each path must be compared with every other path in the population to find if it is dominated, where the computational complexity scales exponentially with the search space [9].", "startOffset": 245, "endOffset": 248}, {"referenceID": 7, "context": "Each method has its own pros and cons depending on the environment and application type [8].", "startOffset": 88, "endOffset": 91}, {"referenceID": 14, "context": "The deliberative, or global, layer considers the entire world, likely requiring computation time proportional to the problem size [15].", "startOffset": 130, "endOffset": 134}, {"referenceID": 13, "context": "High-level block diagram of the standard hybrid control system architecture for mobile robots [14].", "startOffset": 94, "endOffset": 98}, {"referenceID": 0, "context": "The configuration spaces of path planning algorithms are usually represented by an occupancy grid, a vertex graph, a Voronoi diagram, generalized cones, or a quad-tree [1].", "startOffset": 168, "endOffset": 171}, {"referenceID": 8, "context": "The set of feasible successor cells is narrowed because of the three occupied cells (gray) [9].", "startOffset": 91, "endOffset": 94}, {"referenceID": 0, "context": "The algorithm employed for the problem must coordinate with the configuration space representation [1].", "startOffset": 99, "endOffset": 102}, {"referenceID": 13, "context": "Uninformed search methods are used when no information about the states are known beyond the problem definition [14].", "startOffset": 112, "endOffset": 116}, {"referenceID": 3, "context": "The general approach of these methods is best-first, which traverses a graph or grid using a priority queue to find the shortest, collision-free path [4].", "startOffset": 150, "endOffset": 153}, {"referenceID": 14, "context": "The search algorithm, looking for the cheapest path, tries (expands) the node with the lowest f n [15], [16].", "startOffset": 98, "endOffset": 102}, {"referenceID": 15, "context": "The search algorithm, looking for the cheapest path, tries (expands) the node with the lowest f n [15], [16].", "startOffset": 104, "endOffset": 108}, {"referenceID": 16, "context": "path), the A* algorithm is a favorite for route search problems [17], [18].", "startOffset": 64, "endOffset": 68}, {"referenceID": 17, "context": "path), the A* algorithm is a favorite for route search problems [17], [18].", "startOffset": 70, "endOffset": 74}, {"referenceID": 14, "context": "Norvig and Russel [15] explain how the A* heuristic satisfies the consistency condition, and also that A* is optimally efficient: no other optimal algorithm is guaranteed to expand fewer nodes than A*.", "startOffset": 18, "endOffset": 22}, {"referenceID": 18, "context": "For real-time planning, where computational speed is a priority, previous studies [19], [20] have modified A* for fast planning.", "startOffset": 82, "endOffset": 86}, {"referenceID": 19, "context": "For real-time planning, where computational speed is a priority, previous studies [19], [20] have modified A* for fast planning.", "startOffset": 88, "endOffset": 92}, {"referenceID": 3, "context": "The D* algorithm is a dynamic version of A*, built to be capable of fast rerouting when the robot encounters new obstacles in the environment [4].", "startOffset": 142, "endOffset": 145}, {"referenceID": 13, "context": "The speed of these searching algorithms is increased dramatically, but at the cost of sub-optimal solution paths [14].", "startOffset": 113, "endOffset": 117}, {"referenceID": 20, "context": "Pareto optimality is a crucial concept for finding solutions to MOO problems because identifying a single solution that simultaneously optimizes across several objectives is often an impossible task [22].", "startOffset": 199, "endOffset": 203}, {"referenceID": 21, "context": "The code is written in MATLAB R2013a, and will be published in a future release of Corke\u2019s \u201cRobotics, Vision, Control\u201d [23].", "startOffset": 119, "endOffset": 123}, {"referenceID": 13, "context": "The mobile robot community has put an increased emphasis on suboptimal path planning methods which meet the time-critical constraints over slow, optimal algorithms [14].", "startOffset": 164, "endOffset": 168}], "year": 2015, "abstractText": "Path planning is one of the most vital elements of mobile robotics. With a priori knowledge of the environment, global path planning provides a collision-free route through the workspace. The global path plan can be calculated with a variety of informed search algorithms, most notably the A* search method, guaranteed to deliver a complete and optimal solution that minimizes the path cost. Path planning optimization typically looks to minimize the distance traversed from start to goal, yet many mobile robot applications call for additional path planning objectives, presenting a multiobjective optimization (MOO) problem. Past studies have applied genetic algorithms to MOO path planning problems, but these may have the disadvantages of computational complexity and suboptimal solutions. Alternatively, the algorithm in this paper approaches MOO path planning with the use of Pareto fronts, or finding non-dominated solutions. The algorithm presented incorporates Pareto optimality into every step of A* search, thus it is named A*-PO. Results of simulations show A*-PO outperformed several variations of the standard A* algorithm for MOO path planning. A planetary exploration rover case study was added to demonstrate the viability of A*-PO in a real-world application. Keywords\u2014multiobjective optimization; path planning; search algorithm; A*; Pareto; mobile robot; Mars rover", "creator": "Word"}}}