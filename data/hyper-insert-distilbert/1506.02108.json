{"id": "1506.02108", "review": {"conference": "NIPS", "VERSION": "v1", "DATE_OF_SUBMISSION": "6-Jun-2015", "title": "Deeply Learning the Messages in Message Passing Inference", "abstract": "deep supervised structured output learning currently shows moderately great promise in tasks like random semantic dynamic image length segmentation. we proffer a new, generally efficient deep structured model validation learning scheme, research in which information we show around how deep and convolutional neural networks ( cs cnns ) can be used to estimate among the distributed messages in message filter passing inference for an structured filter prediction with distributed conditional random fields ( crfs ). with such cnn message detection estimators, we obviate out the need to learn or evaluate potential functions independently for message traffic calculation. this confers significant efficiency for reward learning, namely since thinking otherwise when considered performing quantum structured learning for calculating a linear crf with cnn intervention potentials unknown it is normally necessary repeatedly to undertake expensive waterfall inference for every incoming stochastic gradient training iteration. the network output parameter dimension for raw message variability estimation estimation is often the same same as the number of variable classes, measured in nice contrast to the network output tensor for general networks cnn decision potential production functions than in crfs, which is exponential in the order element of the potentials. practically hence cnn immediate message learning has fewer network parameters and there is also more scalable, for cases < that keep a large number } of classes are well involved. we apply together our method to semantic transformed image structure segmentation on the pascal voc supervised 2012 dataset. we clearly achieve an intersection - over - union score set of 73. 4 on its test test set, on which is the best frequently reported result for methods using the voc training images set alone. conversely this total impressive performance demonstrates the perceived effectiveness benefits and usefulness of our cnn instant message event learning reduction method.", "histories": [["v1", "Sat, 6 Jun 2015 02:52:38 GMT  (6473kb,D)", "https://arxiv.org/abs/1506.02108v1", "11 pages"], ["v2", "Wed, 10 Jun 2015 06:49:06 GMT  (6473kb,D)", "http://arxiv.org/abs/1506.02108v2", "11 pages. Fixed a typo"], ["v3", "Tue, 8 Sep 2015 04:29:45 GMT  (18kb)", "http://arxiv.org/abs/1506.02108v3", "11 pages. Appearing in Proc. The Twenty-ninth Annual Conference on Neural Information Processing Systems (NIPS), 2015, Montreal, Canada"]], "COMMENTS": "11 pages", "reviews": [], "SUBJECTS": "cs.CV cs.LG stat.ML", "authors": ["guosheng lin", "chunhua shen", "ian d reid 0001", "anton van den hengel"], "accepted": true, "id": "1506.02108"}, "pdf": {"name": "1506.02108.pdf", "metadata": {"source": "CRF", "title": "Deeply Learning the Messages in Message Passing Inference", "authors": ["Guosheng Lin Chunhua Shen", "Ian Reid", "Anton van den Hengel"], "emails": ["firstname.lastname@adelaide.edu.au"], "sections": [{"heading": null, "text": "ar X\niv :1\n50 6.\n02 10\n8v 3\n[ cs\n.C V\n] 8\nS ep\nAppearing in Proc. The Twenty-ninth Annual Conference on Neural Information Processing Systems (NIPS), 2015, Montreal, Canada.\nThis work was in part supported by Data to Decisions CRC Centre. The authors would like to thank NVIDIA for the donations of the K40 graphic cards.\nCorrespondence should be addressed to C. Shen.\nContents"}, {"heading": "1 Introduction 3", "text": "1.1 Related work . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 3"}, {"heading": "2 Learning CRF with CNN potentials 4", "text": ""}, {"heading": "3 Learning CNN message estimators 5", "text": "3.1 CNN message estimators . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 6\n3.2 Details for message estimator networks . . . . . . . . . . . . . . . . . . . . . . 7\n3.3 Training CNN message estimators . . . . . . . . . . . . . . . . . . . . . . . . 8\n3.4 Message learning with inference-time budgets . . . . . . . . . . . . . . . . . . 8"}, {"heading": "4 Experiments 9", "text": "5 Conclusion 10"}, {"heading": "1 Introduction", "text": "Learning deep structured models has attracted considerable research attention recently. One popular approach to deep structured model is formulating conditional random fields (CRFs) using deep Convolutional Neural Networks (CNNs) for the potential functions. This combines the power of CNNs for feature representation learning and of the ability for CRFs to model complex relations. The typical approach for the joint learning of CRFs and CNNs [1, 2, 3, 4, 5], is to learn the CNN potential functions by optimizing the CRF objective, e.g., maximizing the log-likelihood. The CNN and CRF joint learning has shown impressive performance for semantic image segmentation.\nFor the joint learning of CNNs and CRFs, stochastic gradient descent (SGD) is typically applied for optimizing the conditional likelihood. This approach requires the marginal inference for calculating the gradient. For loopy graphs, marginal inference is generally expensive even when using approximate solutions. Given that learning the CNN potential functions typically requires a large number of gradient iterations, repeated marginal inference would make the training intractably slow. Applying an approximate training objective is a solution to avoid repeat inference; pseudo-likelihood learning [6] and piecewise learning [7, 3] are examples of this kind of approach. In this work, we advocate a new direction for efficient deep structured model learning.\nIn conventional CRF approaches, the final prediction is the result of inference based on the learned potentials. However, our ultimate goal is the final prediction (not the potentials themselves), so we propose to directly optimize the inference procedure for the final prediction. Our focus here is on the extensively studied message passing based inference algorithms. As discussed in [8], we can directly learn message estimators to output the required messages in the inference procedure, rather than learning the potential functions as in conventional CRF learning approaches. With the learned message estimators, we then obtain the final prediction by performing message passing inference.\nOur main contributions are as follows.\n\u2022 We explore a new direction for efficient deep structured learning. We propose to directly learn the messages in message passing inference as training deep CNNs in an end-to-end learning fashion. Message learning does not require any inference step for the gradient calculation, which allows efficient training. It can be cast into traditional classification problems.\nThe network output dimension for message estimation is the same as the number of classes (K), while the network output for general CNN potential functions in CRFs is Ka, which is exponential in the order (a) of the potentials (for example, a = 2 for pairwise potentials, a = 3 for triple-cliques, etc). Hence CNN based message learning has significantly fewer network parameters and thus is more scalable, especially in the cases of a large number of classes involved.\n\u2022 The number of iterations in message passing inference can be explicitly taken into consideration in the message learning procedure. In this paper, we are particularly interested in learning messages that are able to offer high-quality CRF prediction results with only one message passing iteration, making the message passing inference very fast.\n\u2022 We apply our method to semantic image segmentation on the PASCAL VOC 2012 dataset and achieve impressive performance."}, {"heading": "1.1 Related work", "text": "Combining the strengths of CNNs and CRFs for segmentation has been explored in several recent methods. Some methods resort to a simple combination of CNN classifiers and CRFs without joint learning. DeepLab-CRF in [9] first train fully CNN for pixel classification and applies a dense CRF [10] method as a post-processing step. Later the method in [2] extends DeepLab by jointly learning the dense CRFs and CNNs. RNN-CRF in [1] also performs joint learning of CNNs and the dense CRFs. They implement the mean-field inference\nas Recurrent Neural Networks which facilitates the end-to-end learning. These methods usually use CNNs for modelling the unary potentials only. The work in [3] trains CNNs to model both the unary and pairwise potentials in order to capture contextual information. Jointly learning CNNs and CRFs has also been explored for other applications like depth estimation [4, 11]. The work in [5] explores joint training of Markov random fields and deep networks for predicting words from noisy images and image classification.\nAll these above-mentioned methods that combine CNNs and CRFs are based upon conventional CRF approaches. They aim to jointly learn or incorporate pre-trained CNN potential functions, and then perform inference/prediction using the potentials. In contrast, our method here directly learns CNN message estimators for the message passing inference, rather than learning the potentials.\nThe inference machine proposed in [8] is relevant to our work in that it has discussed the idea of directly learning message estimators instead of learning potential functions for structured prediction. They train traditional logistic regressors with hand-crafted features as message estimators. Motivated by the tremendous success of CNNs, we propose to train deep CNNs based message estimators in an end-to-end learning style without using handcrafted features. Unlike the approach in [8] which aims to learn variable-to-factor message estimators, our proposed method aims to learn the factor-to-variable message estimators. Thus we are able to naturally formulate the variable marginals, which is the ultimate goal for CRF inference, as the training objective (see Sec. 3.3). The approach in [12] jointly learns CNNs and CRFs for pose estimation, in which they learn the marginal likelihood of body parts but ignore the partition function in the likelihood. Message learning is not discussed in this work, and the exact relation between this pose estimation approach and message learning remains unclear."}, {"heading": "2 Learning CRF with CNN potentials", "text": "Before describing our message learning method, we review the CRF-CNN joint learning approach and discuss limitations. An input image is denoted by x \u2208 X and the corresponding labeling mask is denoted by y \u2208 Y. The energy function is denoted by E(y,x), which measures the score of the prediction y given the input image x. We consider the following form of conditional likelihood:\nP (y|x) = 1\nZ(x) exp [\u2212E(y,x)] =\nexp [\u2212E(y,x)] \u2211\ny\u2032 exp [\u2212E(y \u2032,x)]\n. (1)\nHere Z is the partition function. The CRF model is decomposed by a factor graph over a set of factors F. Generally, the energy function is written as a sum of potential functions (factor functions):\nE(y,x) = \u2211\nF\u2208F EF (yF ,xF ). (2)\nHere F indexes one factor in the factor graph; yF denotes the variable nodes which are connected to the factor F ; EF is the (log-) potential function (factor function). The potential function can be a unary, pairwise, or high-order potential function. The recent method in [3] describes examples of constructing general CNN based unary and pairwise potentials.\nTake semantic image segmentation as an example. To predict the pixel labels of a test image, we can find the mode of the joint label distribution by solving the maximum a posteriori (MAP) inference problem: y\u22c6 = argmax y P (y|x). We can also obtain the final prediction by calculating the label marginal distribution of each variable, which requires to solve a marginal inference problem:\n\u2200p \u2208 N : P (yp|x) = \u2211\ny\\yp P (y|x). (3)\nHere y\\yp indicates the output variables y excluding yp. For a general CRF graph with cycles, the above inference problems is known to be NP-hard, thus approximate inference algorithms are applied. Message passing is a type of widely applied algorithms for approximate inference: loopy belief propagation (BP) [13], tree-reweighted message passing [14] and mean-field approximation [13] are examples of the message passing methods.\nCRF-CNN joint learning is to learn CNN potential functions by optimizing the CRF objective, typically, the negative conditional log-likelihood, which is:\n\u2212 log P (y|x; \u03b8) = E(y,x; \u03b8) + log Z(x; \u03b8). (4)\nThe energy function E(y,x) is constructed by CNNs, for which all the network parameters are denoted by \u03b8. Adding regularization, minimizing negative log-likelihood for CRF learning is:\nmin\u03b8 \u03bb 2 \u2016\u03b8\u2016 2 2 + \u2211N i=1[E(y (i),x(i); \u03b8) + log Z(x(i); \u03b8)]. (5)\nHere x(i), y(i) denote the i-th training image and its segmentation mask; N is the number of training images; \u03bb is the weight decay parameter. We can apply stochastic gradient descent (SGD) to optimize the above problem for learning \u03b8. The energy function E(y,x; \u03b8) is constructed from CNNs, and its gradient \u2207\u03b8E(y,x; \u03b8) can be easily computed by applying the chain rule as in conventional CNNs. However, the partition function Z brings difficulties for optimization. Its gradient is:\n\u2207\u03b8 log Z(x; \u03b8) = \u2211\ny\nexp [\u2212E(y,x; \u03b8)] \u2211\ny\u2032 exp [\u2212E(y \u2032,x; \u03b8)]\n\u2207\u03b8[\u2212E(y,x; \u03b8)]\n=\u2212 E y\u223cP (y|x;\u03b8)\u2207\u03b8E(y,x; \u03b8). (6)\nDirect calculation of the above gradients is computationally infeasible for general CRF graphs. Usually it is necessary to perform approximate marginal inference to calculate the gradients at each SGD iteration [13]. However, repeated marginal inference can be extremely expensive, as discussed in [3]. CNN training usually requires a huge number of SGD iterations (hundreds of thousands, or even millions), hence this inference based learning approach is in general not scalable or even infeasible."}, {"heading": "3 Learning CNN message estimators", "text": "In conventional CRF approaches, the potential functions are first learned, and then inference is performed based on the learned potential functions in order to generate the final prediction. In contrast, our approach directly optimizes the inference procedure for final prediction. We propose to learn CNN estimators to directly output the required intermediate values in an inference algorithm.\nHere we focus on the message passing based inference algorithm which has been extensively studied and widely applied. In the CRF prediction procedure, the \u201cmessage\u201d vectors are recursively calculated based on the learned potentials. We propose to construct and learn CNNs to directly estimate these messages in the message passing procedure, rather than learning the potential functions. In particular, we directly learn factor-to-variable message estimators. Our message learning framework is general and can accommodate all message passing based algorithms such as loopy belief propagation (BP) [13], mean-field approximation [13] and their variants. Here we discuss using loopy BP for calculating variable marginals. As shown by Yedidia et al. [15], loopy BP has a close relation with Bethe free energy approximation.\nTypically, the message is a K-dimensional vector (K is the number of classes) which encodes the information of the label distribution. For each variable-factor connection, we need to recursively compute the variable-to-factor message: \u03b2p\u2192F \u2208 R K , and the factor-to-variable message: \u03b2F\u2192p \u2208 R K . For numerical reasons, the log operation is applied to the marginals before deriving message passing algorithms. The unnormalized variable-to-factor message is computed as:\n\u03b2\u0304p\u2192F (yp) = \u2211 F \u2032\u2208Fp\\F \u03b2F \u2032\u2192p(yp). (7)\nHere Fp is a set of factors connected to the variable p; Fp\\F is the set of factors Fp excluding the factor F . For loopy graph, the variable-to-factor message is normalized in each iteration:\n\u03b2p\u2192F (yp) = log exp \u03b2\u0304p\u2192F (yp) \u2211\ny\u2032p exp \u03b2\u0304p\u2192F (y \u2032 p)\n(8)\nThe factor-to-variable message is computed as:\n\u03b2F\u2192p(yp) = log \u2211\ny\u2032 F \\y\u2032p,y \u2032 p=yp\nexp\n[\n\u2212 EF (y \u2032 F ) +\n\u2211\nq\u2208NF \\p\n\u03b2q\u2192F (y \u2032 q)\n]\n. (9)\nHere NF is a set of variables connected to the factor F ; NF \\p is the set of variables NF excluding the variable p. Once we get all the factor-to-variable messages of one variable node, we are able to calculate the marginal distribution (beliefs) of that variable:\nP (yp|x) = \u2211\ny\\yp\nP (y|x) = 1\nZp exp\n[\n\u2211\nF\u2208Fp\n\u03b2F\u2192p(yp)\n]\n, (10)\nin which Zp is a normalizer: Zp = \u2211\nyp exp [\n\u2211\nF\u2208Fp \u03b2F\u2192p(yp)]."}, {"heading": "3.1 CNN message estimators", "text": "The calculation of factor-to-variable message \u03b2F\u2192p depends on the variable-to-factor messages \u03b2p\u2192F . Substituting the definition of \u03b2p\u2192F in (8), \u03b2F\u2192p can be re-written as:\n\u03b2F\u2192p(yp) = log \u2211\ny\u2032 F \\y\u2032p,y \u2032 p=yp\nexp\n{\n\u2212 EF (y \u2032 F ) +\n\u2211\nq\u2208NF \\p\n[\nlog exp \u03b2\u0304q\u2192F (y\n\u2032 q)\n\u2211\ny\u2032\u2032q exp \u03b2\u0304q\u2192F (y \u2032\u2032 q )\n]}\n= log \u2211\ny\u2032 F \\y\u2032q,y \u2032 p=yp\nexp\n{\n\u2212 EF (y \u2032 F ) +\n\u2211\nq\u2208NF \\p\n[\nlog exp\n\u2211\nF \u2032\u2208Fq\\F \u03b2F \u2032\u2192q(y \u2032 q)\n\u2211\ny\u2032\u2032q exp\n\u2211\nF \u2032\u2208Fq\\F \u03b2F \u2032\u2192q(y \u2032\u2032 q )\n]}\n(11)\nHere q denotes the variable node which is connected to the node p by the factor F in the factor graph. We refer to the variable node q as a neighboring node of q. NF \\p is a set of variables connected to the factor F excluding the node p. Clearly, for a pairwise factor which only connects to two variables, the set NF \\p only contains one variable node. The above equations show that the factor-to-variable message \u03b2F\u2192p depends on the potential EF and \u03b2F \u2032\u2192q. Here \u03b2F \u2032\u2192q is the factor-to-variable message which is calculated from a neighboring node q and a factor F \u2032 6= F .\nConventional CRF learning approaches learn the potential function then follow the above equations to compute the messages for calculating marginals. As discussed in [8], given that the goal is to estimate the marginals, it is not necessary to exactly follow the above equations, which involve learning potential functions, to calculate messages. We can directly learn message estimators, rather than indirectly learning the potential functions as in conventional methods.\nConsider the calculation in (11). The message \u03b2F\u2192p depends on the observation xpF and the messages \u03b2F \u2032\u2192q. Here xpF denotes the observations that correspond to the node p and the factor F . We are able to formulate a factor-to-variable message estimator which takes xpF and \u03b2F \u2032\u2192q as inputs and outputs the message vector, and we directly learn such estimators. Since one message \u03b2F\u2192p depends on a number of previous messages \u03b2F \u2032\u2192q, we can formulate a sequence of message estimators to model the dependence. Thus the output from a previous message estimator will be the input of the following message estimator.\nThere are two message passing strategies for loopy BP: synchronous and asynchronous passing. We here focus on the synchronous message passing, for which all messages are computed before passing them to the neighbors. The synchronous passing strategy results in much simpler message dependences than the asynchronous strategy, which simplifies the training procedure. We define one inference iteration as one pass of the graph with the synchronous passing strategy.\nWe propose to learn CNN based factor-to-variable message estimator. The message estimator models the interaction between neighboring variable nodes. We denote by M a message estimator. The factor-to-variable message is calculated as:\n\u03b2F\u2192p(yp) = MF (xpF ,dpF , yp). (12)\nWe refer to dpF as the dependent message feature vector which encodes all dependent messages from the neighboring nodes that are connected to the node p by F . Note that the dependent messages are the output of message estimators at the previous inference iteration. In the case of running only one message passing iteration, there is no dependent messages for MF , and thus we do not need to incorporate dpF . To have a general exposition, we here describe the case of running arbitrarily many inference iterations.\nWe can choose any effective strategy to generate the feature vector dpF from the dependent messages. Here we discuss a simple example. According to (11), we define the feature vector dpF as a K-dimensional vector which aggregates all dependent messages. In this case, dpF is computed as:\ndpF (y) = \u2211\nq\u2208NF \\p\n[\nlog exp\n\u2211\nF \u2032\u2208Fq\\F MF \u2032(xqF \u2032 ,dqF \u2032 , y)\n\u2211 y\u2032 exp \u2211 F \u2032\u2208Fq\\F MF \u2032(xqF \u2032 ,dqF \u2032 , y\u2032)\n]\n. (13)\nWith the definition of dpF in (13) and \u03b2F\u2192p in (12), it clearly shows that the message estimation requires evaluating a sequence of message estimators. Another example is to concatenate all dependent messages to construct the feature vector dpF .\nThere are different strategies to formulate the message estimators in different iterations. The simple strategy is using the same message estimator across all inference iteration. In this case the message estimator becomes a recursive function, and thus the CNN based estimator becomes a recurrent neural network (RNN). Another strategy is to formulate different estimator for each inference iteration."}, {"heading": "3.2 Details for message estimator networks", "text": "We formulate the estimator MF as a CNN, thus the estimation is the network outputs:\n\u03b2F\u2192p(yp) = MF (xpF ,dpF , yp; \u03b8F ) = \u2211K k=1\u03b4(k = yp)zpF,k(x,dpF ; \u03b8F ). (14)\nHere \u03b8F denotes the network parameter which we need to learn. \u03b4(\u00b7) is the indicator function, which equals 1 if the input is true and 0 otherwise. We denote by zpF \u2208 R K as the K-dimensional output vector (K is the number of classes) of the message estimator network for the node p and the factor F ; zpF,k is the k-th value in the network output zpF corresponding to the k-th class.\nWe can consider any possible strategies for implementing zpF with CNNs. For example, we here describe a strategy which is analogous to the network design in [3]. We denote by C(1) as a fully convolutional network (FCNN) [16] for convolutional feature generation, and C(2) as a traditional fully connected network for message estimation.\nGiven an input image x, the network output C(1)(x) \u2208 RN1\u00d7N2\u00d7r is a convolutional feature map, in which N1 \u00d7N2 = N is the feature map size and r is the dimension of one feature vector. Each spatial position (each feature vector) in the feature map C(1)(x) corresponds to one variable node in the CRF graph. We denote by C(1)(x, p) \u2208 Rr as the feature vector corresponding to the variable node p. Likewise, C(1)(x,NF \\p) \u2208 R\nr is the averaged vector of the feature vectors that correspond to the set of nodes NF \\p. Recall that NF \\p is a set of nodes connected by the factor F excluding the node p. For pairwise factors, NF \\p contains only one node.\nWe construct the feature vector zC (1)\npF \u2208 R 2r for the node-factor pair (p, F ) by concatenating\nC(1)(x, p) and C(1)(x,NF \\p). Finally, we concatenate the node-factor feature vector z C(1)\npF\nand the dependent message feature vector dpF as the input for the second network C (2). Thus the input dimension for C(2) is (2r + K). For running only one inference iteration, the input for C(2) is zC (1)\npF alone. The final output from the second network C (2) is the\nK-dimensional message vector zpF . To sum up, we generate the final message vector zpF as:\nzpF = C (2){ [ C(1)(x, p)\u22a4; C(1)(x,NF \\p ) \u22a4; d\u22a4pF ] \u22a4 }. (15)\nFor a general CNN based potential function in conventional CRFs, the potential network is usually required to have a large number of output units (exponential in the order of the potentials). For example, it requiresK2 (K is the number of classes) outputs for the pairwise potentials [3]. A large number of output units would significantly increase the number of network parameters. It leads to expensive computations and tend to over-fit the training data. In contrast, for learning our CNN message estimator, we only need to formulate K output units for the network. Clearly it is more scalable in the cases of a large number of classes."}, {"heading": "3.3 Training CNN message estimators", "text": "Our goal is to estimate the variable marginals in (3), which can be re-written with the estimators:\nP (yp|x) = \u2211\ny\\yp\nP (y|x) = 1\nZp exp\n[\n\u2211\nF\u2208Fp\n\u03b2F\u2192p(yp)\n]\n= 1\nZp exp\n\u2211\nF\u2208Fp\nMF (xpF ,dpF , yp; \u03b8F ).\nHere Zp is the normalizer. The ideal variable marginal has the probability of 1 for the ground truth class and 0 for the remaining classes. Here we consider the cross entropy loss between the ideal marginal and the estimated marginal.\nJ(x, y\u0302; \u03b8) = \u2212 \u2211\np\u2208N\nK \u2211\nyp=1\n\u03b4(yp = y\u0302p) log P (yp|x; \u03b8)\n= \u2212 \u2211\np\u2208N\nK \u2211\nyp=1\n\u03b4(yp = y\u0302p) log exp\n\u2211\nF\u2208Fp MF (xpF ,dpF , yp; \u03b8F )\n\u2211\ny\u2032p exp\n\u2211\nF\u2208Fp MF (xpF ,dpF , y\u2032p; \u03b8F )\n, (16)\nin which y\u0302p is the ground truth label for the variable node p. Given a set ofN training images and label masks, the optimization problem for learning the message estimator network is:\nmin\u03b8 \u03bb 2 \u2016\u03b8\u2016 2 2 + \u2211N i=1 J(x (i), y\u0302(i); \u03b8). (17)\nThe work in [8] propose to learn the variable-to-factor message (\u03b2p\u2192F ). Unlike their approach, we aim to learn the factor-to-variable message (\u03b2F\u2192p), for which we are able to naturally formulate the variable marginals, which is the ultimate goal for prediction, as the training objective. Moreover, for learning \u03b2p\u2192F in their approach, the message estimator will depend on all neighboring nodes (connected by any factors). Given that variable nodes will have different number of neighboring nodes, they only consider a fixed number of neighboring nodes (e.g., 20) and concatenate their features to generate a fixed-length feature vector for classification. In our case for learning \u03b2F\u2192p, the message estimator only depends a fixed number of neighboring nodes (connected by one factor), thus we do not have this problem. Most importantly, they learn message estimators by training traditional probabilistic classifiers (e.g., simple logistic regressors) with hand-craft features, and in contrast, we train deep CNNs in an end-to-end learning style without using hand-craft features."}, {"heading": "3.4 Message learning with inference-time budgets", "text": "One advantage of message learning is that we are able to explicitly incorporate the expected number of inference iteration into the learning procedure. The number of inference iteration defines the learning sequence of message estimators. This is particular useful if we aim to learn the estimators which are able to have high-quality prediction for only running a few number of inference iterations. In contrast, the conventional potential function learning in CRFs are not able to directly incorporate the expected number of inference iterations.\nWe are particularly interested in learning message estimators for using only one message passing iteration, for which the inference can be very fast. In this case it might be preferable to have large-range neighborhood connections, for which the large range interaction can be captured by running one inference pass."}, {"heading": "4 Experiments", "text": "We evaluate the proposed CNN message learning method for semantic image segmentation. We use the publicly available PASCAL VOC 2012 dataset [19]. There are 20 object categories and one background category in the dataset. Its contains 1464 images in the training set, 1449 images in the \u201cval\u201d set and 1456 images in the test set. Following the common setting in [20, 9], the training set is augmented to 10582 images by including the extra annotations provided in [21] for the VOC images. We use intersection-over-union (IoU) score [19] to evaluate the segmentation performance. For the learning and prediction of our method, we only use one message passing iteration.\nThe recent work in [3] (referred to as ContextDCRF) learns multi-scale fully convolutional CNNs (FCNNs) for unary and pairwise potential functions to capture contextual information. We follow this CRF learning method and replace the potential functions by the proposed message estimators. We consider 2 types of spatial relations for constructing the pairwise connections of variable nodes. One is the \u201csurrounding\u201d spatial relation, for which one node is connected to its surround nodes. The other one is the \u201cabove/below\u201d spatial relation, for which one node is connected to the nodes that lie above. For the pairwise connections, the neighborhood size is defined by a range box. We learn one type of unary message estimator and 3 types of pairwise message estimators in total. One type of pairwise message estimator is for the \u201csurrounding\u201d spatial relations, and the other two are for the \u201cabove/below\u201d spatial relations. We formulate one network for one type of message estimator.\nWe formulate our message estimators as multi-scale FCNNs, for which we apply a similar network configuration as in [3]. The network C(1) (see Sec.3.2 for details) has 6 convolution blocks and C(2) has 2 fully connected layers (with K output units). Our networks are initialized using the VGG-16 model [22]. We train all layers using back-propagation.\nWe first evaluate our method on the VOC 2012 \u201cval\u201d set. We compare with several recent CNN based methods with available results on the \u201cval\u201d set. Results are shown in Table 1. Our method achieves the best performance. As mentioned, ContextDCRF learns CNN based potential functions in CRFs to capture contextual information. ContextDCRF follows a conventional CRF learning and prediction scheme: They first learn potentials and then perform inference based on the learned potentials to output final predictions. The result shows that learning the CNN message estimators is able to achieve similar performance compared to learning CNN potential functions in CRFs. Note that here we only use one message passing iteration for the training and prediction, the inference time cost is almost negligible. Hence our method enables much more efficient inference.\nTo further improve the performance, we perform simple data augmentation in training. We generate extra 4 scales ([0.8, 0.9, 1.1, 1.2]) of the training images and their flipped images for training. This result is denoted by \u201cours+\u201d in the result table.\nWe further evaluate our method on the VOC 2012 test set. We compare with recent stateof-the-art CNN methods with competitive performance. The results are described in Table 3. Since the ground truth labels are not available for the test set, we evaluate our method through the VOC evaluation server. We achieve impressive performance on the test set:\n73.4 IoU score1, which is the so far best performance compared to the methods that use the same augmented VOC dataset [21] (marked as \u201cVOC extra\u201d in the table). These results validate the effectiveness of direct message learning with CNNs.\nWe also include the comparison with the methods which are trained on the much larger COCO dataset (around 133K training images). Our performance is comparable with these methods, while our method uses much less number of training images.\nThe results for each category is shown in Table 2. We compare with several recent methods which transfer layers from the same VGG-16 model and use the same training data. Our method performs the best for most categories."}, {"heading": "5 Conclusion", "text": "We have proposed a new deep message learning framework for structured CRF prediction. Learning deep message estimators for the message passing inference reveals a new direction for learning deep structured model. Learning CNN message estimators is efficient, which does not involve expensive inference steps for gradient calculation. The network output dimension for message estimation is the same as the number of classes, which does not increase with the order of the potentials, and thus CNN message learning has less network parameters and is more scalable in the number of classes compared to conventional potential function learning. Our impressive performance for semantic segmentation demonstrates the effectiveness and usefulness of the proposed deep message learning. Our framework is general and can be readily applied to other structured prediction applications."}], "references": [{"title": "Conditional random fields as recurrent neural networks", "author": ["S. Zheng", "S. Jayasumana", "B. Romera-Paredes", "V. Vineet", "Z. Su", "D. Du", "C. Huang", "P. Torr"], "venue": "2015. [Online]. Available: http://arxiv.org/abs/1502.03240", "citeRegEx": "1", "shortCiteRegEx": null, "year": 2015}, {"title": "Fully connected deep structured networks", "author": ["A. Schwing", "R. Urtasun"], "venue": "2015. [Online]. Available: http://arxiv.org/abs/1503.02351 1 The result link provided by VOC evaluation server: http://host.robots.ox.ac.uk:8080/anonymous/DBD0SI.html 10", "citeRegEx": "2", "shortCiteRegEx": null, "year": 2015}, {"title": "Efficient piecewise training of deep structured models for semantic segmentation", "author": ["G. Lin", "C. Shen", "I. Reid", "A. van den Hengel"], "venue": "2015. [Online]. Available: http://arxiv.org/abs/1504.01013", "citeRegEx": "3", "shortCiteRegEx": null, "year": 2015}, {"title": "Deep convolutional neural fields for depth estimation from a single image", "author": ["F. Liu", "C. Shen", "G. Lin"], "venue": "Proc. IEEE Conf. Comp. Vis. Pattern Recogn., 2015.", "citeRegEx": "4", "shortCiteRegEx": null, "year": 2015}, {"title": "Learning deep structured models", "author": ["L. Chen", "A. Schwing", "A. Yuille", "R. Urtasun"], "venue": "2014. [Online]. Available: http://arxiv.org/abs/1407.2538", "citeRegEx": "5", "shortCiteRegEx": null, "year": 2014}, {"title": "Efficiency of pseudolikelihood estimation for simple Gaussian fields", "author": ["J. Besag"], "venue": "Biometrika, 1977.", "citeRegEx": "6", "shortCiteRegEx": null, "year": 1977}, {"title": "Piecewise training for undirected models", "author": ["C. Sutton", "A. McCallum"], "venue": "Proc. Conf. Uncertainty Artificial Intelli, 2005.", "citeRegEx": "7", "shortCiteRegEx": null, "year": 2005}, {"title": "Learning message-passing inference machines for structured prediction", "author": ["S. Ross", "D. Munoz", "M. Hebert", "J. Bagnell"], "venue": "Proc. IEEE Conf. Comp. Vis. Pattern Recogn., 2011.", "citeRegEx": "8", "shortCiteRegEx": null, "year": 2011}, {"title": "Semantic image segmentation with deep convolutional nets and fully connected CRFs", "author": ["L. Chen", "G. Papandreou", "I. Kokkinos", "K. Murphy", "A. Yuille"], "venue": "2014. [Online]. Available: http://arxiv.org/abs/1412.7062", "citeRegEx": "9", "shortCiteRegEx": null, "year": 2014}, {"title": "Efficient inference in fully connected CRFs with Gaussian edge potentials", "author": ["P. Kr\u00e4henb\u00fchl", "V. Koltun"], "venue": "Proc. Adv. Neural Info. Process. Syst., 2012.", "citeRegEx": "10", "shortCiteRegEx": null, "year": 2012}, {"title": "Learning depth from single monocular images using deep convolutional neural fields", "author": ["F. Liu", "C. Shen", "G. Lin", "I. Reid"], "venue": "2015. [Online]. Available: http://arxiv.org/abs/1502.07411", "citeRegEx": "11", "shortCiteRegEx": null, "year": 2015}, {"title": "Joint training of a convolutional network and a graphical model for human pose estimation", "author": ["J. Tompson", "A. Jain", "Y. LeCun", "C. Bregler"], "venue": "Proc. Adv. Neural Info. Process. Syst., 2014.", "citeRegEx": "12", "shortCiteRegEx": null, "year": 2014}, {"title": "Structured learning and prediction in computer vision", "author": ["S. Nowozin", "C. Lampert"], "venue": "Found. Trends. Comput. Graph. Vis., 2011.", "citeRegEx": "13", "shortCiteRegEx": null, "year": 2011}, {"title": "Convergent tree-reweighted message passing for energy minimization", "author": ["V. Kolmogorov"], "venue": "IEEE T. Pattern Analysis & Machine Intelligence, 2006.", "citeRegEx": "14", "shortCiteRegEx": null, "year": 2006}, {"title": "Generalized belief propagation", "author": ["J.S. Yedidia", "W.T. Freeman", "Y. Weiss"], "venue": "Proc. Adv. Neural Info. Process. Syst., 2000.", "citeRegEx": "15", "shortCiteRegEx": null, "year": 2000}, {"title": "Fully convolutional networks for semantic segmentation", "author": ["J. Long", "E. Shelhamer", "T. Darrell"], "venue": "Proc. IEEE Conf. Comp. Vis. Pattern Recogn., 2015.", "citeRegEx": "16", "shortCiteRegEx": null, "year": 2015}, {"title": "Feedforward semantic segmentation with zoom-out features", "author": ["M. Mostajabi", "P. Yadollahpour", "G. Shakhnarovich"], "venue": "2014. [Online]. Available: http://arxiv.org/abs/1412.0774", "citeRegEx": "17", "shortCiteRegEx": null, "year": 2014}, {"title": "BoxSup: exploiting bounding boxes to supervise convolutional networks for semantic segmentation", "author": ["J. Dai", "K. He", "J. Sun"], "venue": "2015. [Online]. Available: http://arxiv.org/abs/1503.01640", "citeRegEx": "18", "shortCiteRegEx": null, "year": 2015}, {"title": "The pascal visual object classes (VOC) challenge", "author": ["M. Everingham", "L.V. Gool", "C. Williams", "J. Winn", "A. Zisserman"], "venue": "Int. J. Comp. Vis., 2010.", "citeRegEx": "19", "shortCiteRegEx": null, "year": 2010}, {"title": "Simultaneous detection and segmentation", "author": ["B. Hariharan", "P. Arbel\u00e1ez", "R. Girshick", "J. Malik"], "venue": "Proc. European Conf. Computer Vision, 2014.", "citeRegEx": "20", "shortCiteRegEx": null, "year": 2014}, {"title": "Semantic contours from inverse detectors", "author": ["B. Hariharan", "P. Arbelaez", "L. Bourdev", "S. Maji", "J. Malik"], "venue": "Proc. Int. Conf. Comp. Vis., 2011.", "citeRegEx": "21", "shortCiteRegEx": null, "year": 2011}, {"title": "Very deep convolutional networks for large-scale image recognition", "author": ["K. Simonyan", "A. Zisserman"], "venue": "2014. [Online]. Available: http://arxiv.org/abs/1409.1556", "citeRegEx": "22", "shortCiteRegEx": null, "year": 2014}, {"title": "Learning deconvolution network for semantic segmentation", "author": ["H. Noh", "S. Hong", "B. Han"], "venue": "Proc. IEEE Conf. Comp. Vis. Pattern Recogn., 2015.", "citeRegEx": "23", "shortCiteRegEx": null, "year": 2015}, {"title": "Weakly-and semi-supervised learning of a DCNN for semantic image segmentation", "author": ["G. Papandreou", "L. Chen", "K. Murphy", "A. Yuille"], "venue": "2015. [Online]. Available: http://arxiv.org/abs/1502.02734 11", "citeRegEx": "24", "shortCiteRegEx": null, "year": 2015}], "referenceMentions": [{"referenceID": 0, "context": "The typical approach for the joint learning of CRFs and CNNs [1, 2, 3, 4, 5], is to learn the CNN potential functions by optimizing the CRF objective, e.", "startOffset": 61, "endOffset": 76}, {"referenceID": 1, "context": "The typical approach for the joint learning of CRFs and CNNs [1, 2, 3, 4, 5], is to learn the CNN potential functions by optimizing the CRF objective, e.", "startOffset": 61, "endOffset": 76}, {"referenceID": 2, "context": "The typical approach for the joint learning of CRFs and CNNs [1, 2, 3, 4, 5], is to learn the CNN potential functions by optimizing the CRF objective, e.", "startOffset": 61, "endOffset": 76}, {"referenceID": 3, "context": "The typical approach for the joint learning of CRFs and CNNs [1, 2, 3, 4, 5], is to learn the CNN potential functions by optimizing the CRF objective, e.", "startOffset": 61, "endOffset": 76}, {"referenceID": 4, "context": "The typical approach for the joint learning of CRFs and CNNs [1, 2, 3, 4, 5], is to learn the CNN potential functions by optimizing the CRF objective, e.", "startOffset": 61, "endOffset": 76}, {"referenceID": 5, "context": "Applying an approximate training objective is a solution to avoid repeat inference; pseudo-likelihood learning [6] and piecewise learning [7, 3] are examples of this kind of approach.", "startOffset": 111, "endOffset": 114}, {"referenceID": 6, "context": "Applying an approximate training objective is a solution to avoid repeat inference; pseudo-likelihood learning [6] and piecewise learning [7, 3] are examples of this kind of approach.", "startOffset": 138, "endOffset": 144}, {"referenceID": 2, "context": "Applying an approximate training objective is a solution to avoid repeat inference; pseudo-likelihood learning [6] and piecewise learning [7, 3] are examples of this kind of approach.", "startOffset": 138, "endOffset": 144}, {"referenceID": 7, "context": "As discussed in [8], we can directly learn message estimators to output the required messages in the inference procedure, rather than learning the potential functions as in conventional CRF learning approaches.", "startOffset": 16, "endOffset": 19}, {"referenceID": 8, "context": "DeepLab-CRF in [9] first train fully CNN for pixel classification and applies a dense CRF [10] method as a post-processing step.", "startOffset": 15, "endOffset": 18}, {"referenceID": 9, "context": "DeepLab-CRF in [9] first train fully CNN for pixel classification and applies a dense CRF [10] method as a post-processing step.", "startOffset": 90, "endOffset": 94}, {"referenceID": 1, "context": "Later the method in [2] extends DeepLab by jointly learning the dense CRFs and CNNs.", "startOffset": 20, "endOffset": 23}, {"referenceID": 0, "context": "RNN-CRF in [1] also performs joint learning of CNNs and the dense CRFs.", "startOffset": 11, "endOffset": 14}, {"referenceID": 2, "context": "The work in [3] trains CNNs to model both the unary and pairwise potentials in order to capture contextual information.", "startOffset": 12, "endOffset": 15}, {"referenceID": 3, "context": "Jointly learning CNNs and CRFs has also been explored for other applications like depth estimation [4, 11].", "startOffset": 99, "endOffset": 106}, {"referenceID": 10, "context": "Jointly learning CNNs and CRFs has also been explored for other applications like depth estimation [4, 11].", "startOffset": 99, "endOffset": 106}, {"referenceID": 4, "context": "The work in [5] explores joint training of Markov random fields and deep networks for predicting words from noisy images and image classification.", "startOffset": 12, "endOffset": 15}, {"referenceID": 7, "context": "The inference machine proposed in [8] is relevant to our work in that it has discussed the idea of directly learning message estimators instead of learning potential functions for structured prediction.", "startOffset": 34, "endOffset": 37}, {"referenceID": 7, "context": "Unlike the approach in [8] which aims to learn variable-to-factor message estimators, our proposed method aims to learn the factor-to-variable message estimators.", "startOffset": 23, "endOffset": 26}, {"referenceID": 11, "context": "The approach in [12] jointly learns CNNs and CRFs for pose estimation, in which they learn the marginal likelihood of body parts but ignore the partition function in the likelihood.", "startOffset": 16, "endOffset": 20}, {"referenceID": 2, "context": "The recent method in [3] describes examples of constructing general CNN based unary and pairwise potentials.", "startOffset": 21, "endOffset": 24}, {"referenceID": 12, "context": "Message passing is a type of widely applied algorithms for approximate inference: loopy belief propagation (BP) [13], tree-reweighted message passing [14] and mean-field approximation [13] are examples of the message passing methods.", "startOffset": 112, "endOffset": 116}, {"referenceID": 13, "context": "Message passing is a type of widely applied algorithms for approximate inference: loopy belief propagation (BP) [13], tree-reweighted message passing [14] and mean-field approximation [13] are examples of the message passing methods.", "startOffset": 150, "endOffset": 154}, {"referenceID": 12, "context": "Message passing is a type of widely applied algorithms for approximate inference: loopy belief propagation (BP) [13], tree-reweighted message passing [14] and mean-field approximation [13] are examples of the message passing methods.", "startOffset": 184, "endOffset": 188}, {"referenceID": 12, "context": "Usually it is necessary to perform approximate marginal inference to calculate the gradients at each SGD iteration [13].", "startOffset": 115, "endOffset": 119}, {"referenceID": 2, "context": "However, repeated marginal inference can be extremely expensive, as discussed in [3].", "startOffset": 81, "endOffset": 84}, {"referenceID": 12, "context": "Our message learning framework is general and can accommodate all message passing based algorithms such as loopy belief propagation (BP) [13], mean-field approximation [13] and their variants.", "startOffset": 137, "endOffset": 141}, {"referenceID": 12, "context": "Our message learning framework is general and can accommodate all message passing based algorithms such as loopy belief propagation (BP) [13], mean-field approximation [13] and their variants.", "startOffset": 168, "endOffset": 172}, {"referenceID": 14, "context": "[15], loopy BP has a close relation with Bethe free energy approximation.", "startOffset": 0, "endOffset": 4}, {"referenceID": 7, "context": "As discussed in [8], given that the goal is to estimate the marginals, it is not necessary to exactly follow the above equations, which involve learning potential functions, to calculate messages.", "startOffset": 16, "endOffset": 19}, {"referenceID": 2, "context": "For example, we here describe a strategy which is analogous to the network design in [3].", "startOffset": 85, "endOffset": 88}, {"referenceID": 15, "context": "We denote by C as a fully convolutional network (FCNN) [16] for convolutional feature generation, and C as a traditional fully connected network for message estimation.", "startOffset": 55, "endOffset": 59}, {"referenceID": 2, "context": "For example, it requiresK (K is the number of classes) outputs for the pairwise potentials [3].", "startOffset": 91, "endOffset": 94}, {"referenceID": 7, "context": "The work in [8] propose to learn the variable-to-factor message (\u03b2p\u2192F ).", "startOffset": 12, "endOffset": 15}, {"referenceID": 2, "context": ") IoU val set ContextDCRF [3] VOC extra 10k 70.", "startOffset": 26, "endOffset": 29}, {"referenceID": 16, "context": "3 Zoom-out [17] VOC extra 10k 63.", "startOffset": 11, "endOffset": 15}, {"referenceID": 1, "context": "5 Deep-struct [2] VOC extra 10k 64.", "startOffset": 14, "endOffset": 17}, {"referenceID": 8, "context": "1 DeepLab-CRF [9] VOC extra 10k 63.", "startOffset": 14, "endOffset": 17}, {"referenceID": 8, "context": "7 DeepLap-MCL [9] VOC extra 10k 68.", "startOffset": 14, "endOffset": 17}, {"referenceID": 17, "context": "7 BoxSup [18] VOC extra 10k 63.", "startOffset": 9, "endOffset": 13}, {"referenceID": 17, "context": "8 BoxSup [18] VOC extra + COCO 133k 68.", "startOffset": 9, "endOffset": 13}, {"referenceID": 18, "context": "We use the publicly available PASCAL VOC 2012 dataset [19].", "startOffset": 54, "endOffset": 58}, {"referenceID": 19, "context": "Following the common setting in [20, 9], the training set is augmented to 10582 images by including the extra annotations provided in [21] for the VOC images.", "startOffset": 32, "endOffset": 39}, {"referenceID": 8, "context": "Following the common setting in [20, 9], the training set is augmented to 10582 images by including the extra annotations provided in [21] for the VOC images.", "startOffset": 32, "endOffset": 39}, {"referenceID": 20, "context": "Following the common setting in [20, 9], the training set is augmented to 10582 images by including the extra annotations provided in [21] for the VOC images.", "startOffset": 134, "endOffset": 138}, {"referenceID": 18, "context": "We use intersection-over-union (IoU) score [19] to evaluate the segmentation performance.", "startOffset": 43, "endOffset": 47}, {"referenceID": 2, "context": "The recent work in [3] (referred to as ContextDCRF) learns multi-scale fully convolutional CNNs (FCNNs) for unary and pairwise potential functions to capture contextual information.", "startOffset": 19, "endOffset": 22}, {"referenceID": 2, "context": "We formulate our message estimators as multi-scale FCNNs, for which we apply a similar network configuration as in [3].", "startOffset": 115, "endOffset": 118}, {"referenceID": 21, "context": "Our networks are initialized using the VGG-16 model [22].", "startOffset": 52, "endOffset": 56}, {"referenceID": 8, "context": "p o tt ed sh ee p so fa tr a in tv DeepLab-CRF [9] 66.", "startOffset": 47, "endOffset": 50}, {"referenceID": 8, "context": "2 DeepLab-MCL [9] 71.", "startOffset": 14, "endOffset": 17}, {"referenceID": 15, "context": "7 FCN-8s [16] 62.", "startOffset": 9, "endOffset": 13}, {"referenceID": 0, "context": "1 CRF-RNN [1] 72.", "startOffset": 10, "endOffset": 13}, {"referenceID": 2, "context": ") IoU test set ContextDCRF [3] VOC extra 10k 70.", "startOffset": 27, "endOffset": 30}, {"referenceID": 16, "context": "7 Zoom-out [17] VOC extra 10k 64.", "startOffset": 11, "endOffset": 15}, {"referenceID": 15, "context": "4 FCN-8s [16] VOC extra 10k 62.", "startOffset": 9, "endOffset": 13}, {"referenceID": 19, "context": "2 SDS [20] VOC extra 10k 51.", "startOffset": 6, "endOffset": 10}, {"referenceID": 22, "context": "6 DeconvNet-CRF [23] VOC extra 10k 72.", "startOffset": 16, "endOffset": 20}, {"referenceID": 8, "context": "5 DeepLab-CRF [9] VOC extra 10k 66.", "startOffset": 14, "endOffset": 17}, {"referenceID": 8, "context": "4 DeepLab-MCL [9] VOC extra 10k 71.", "startOffset": 14, "endOffset": 17}, {"referenceID": 0, "context": "6 CRF-RNN [1] VOC extra 10k 72.", "startOffset": 10, "endOffset": 13}, {"referenceID": 23, "context": "0 DeepLab-CRF [24] VOC extra + COCO 133k 70.", "startOffset": 14, "endOffset": 18}, {"referenceID": 23, "context": "4 DeepLab-MCL [24] VOC extra + COCO 133k 72.", "startOffset": 14, "endOffset": 18}, {"referenceID": 17, "context": "7 BoxSup (semi) [18] VOC extra + COCO 133k 71.", "startOffset": 16, "endOffset": 20}, {"referenceID": 0, "context": "0 CRF-RNN [1] VOC extra + COCO 133k 74.", "startOffset": 10, "endOffset": 13}, {"referenceID": 20, "context": "4 IoU score, which is the so far best performance compared to the methods that use the same augmented VOC dataset [21] (marked as \u201cVOC extra\u201d in the table).", "startOffset": 114, "endOffset": 118}], "year": 2015, "abstractText": "Deep structured output learning shows great promise in tasks like semantic image segmentation. We proffer a new, efficient deep structured model learning scheme, in which we show how deep Convolutional Neural Networks (CNNs) can be used to directly estimate the messages in message passing inference for structured prediction with Conditional Random Fields (CRFs). With such CNN message estimators, we obviate the need to learn or evaluate potential functions for message calculation. This confers significant efficiency for learning, since otherwise when performing structured learning for a CRF with CNN potentials it is necessary to undertake expensive inference for every stochastic gradient iteration. The network output dimension of message estimators is the same as the number of classes, rather than exponentially growing in the order of the potentials. Hence it is more scalable for cases that a large number of classes are involved. We apply our method to semantic image segmentation and achieve impressive performance, which demonstrates the effectiveness and usefulness of our CNN message learning method. Appearing in Proc. The Twenty-ninth Annual Conference on Neural Information Processing Systems (NIPS), 2015, Montreal, Canada. This work was in part supported by Data to Decisions CRC Centre. The authors would like to thank NVIDIA for the donations of the K40 graphic cards. Correspondence should be addressed to C. Shen.", "creator": "LaTeX with hyperref package"}}}