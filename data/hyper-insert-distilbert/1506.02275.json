{"id": "1506.02275", "review": {"conference": "EMNLP", "VERSION": "v1", "DATE_OF_SUBMISSION": "7-Jun-2015", "title": "Confounds and Consequences in Geotagged Twitter Data", "abstract": "map twitter is often used in several quantitative studies that identify geographically - particularly preferred social topics, often writing linguistic styles, and cognitive entities. sometimes these studies rely on varying either gps coordinates commonly attached to defining individual messages, or on the user - computer supplied graphical location field in each message profile. in this paper, periodically we both compare these data acquisition techniques techniques uniquely and best quantify the biases used that they themselves introduce ; today we also measure their predict effects modelled on naive linguistic asset analysis and text - based geolocation. gps - tagging and uniquely self - reported character locations yield errors measurably representing different corpora, accents and these hidden linguistic differences are computed partially automatically attributable to differences developed in dataset composition mediated by language age and gender. using a generic latent variable positioning model to properly induce ambiguity age structure and gender, typically we show briefly how these ambiguous demographic variables interact with geography indicators to sometimes affect language memory use. we also show that the directional accuracy of text - based geolocation varies with population demographics, giving the best results, for men comfortably above the age of above 40.", "histories": [["v1", "Sun, 7 Jun 2015 15:29:26 GMT  (148kb,D)", "https://arxiv.org/abs/1506.02275v1", "in review at EMNLP 2015"], ["v2", "Sat, 22 Aug 2015 15:25:59 GMT  (1051kb,D)", "http://arxiv.org/abs/1506.02275v2", "final version for EMNLP 2015"]], "COMMENTS": "in review at EMNLP 2015", "reviews": [], "SUBJECTS": "cs.CL", "authors": ["umashanthi pavalanathan", "jacob eisenstein"], "accepted": true, "id": "1506.02275"}, "pdf": {"name": "1506.02275.pdf", "metadata": {"source": "META", "title": "Confounds and Consequences in Geotagged Twitter Data", "authors": ["Umashanthi Pavalanathan"], "emails": ["jacobe}@gatech.edu"], "sections": [{"heading": "1 Introduction", "text": "Social media data such as Twitter is frequently used to identify the unique characteristics of geographical regions, including topics of interest (Hong et al., 2012), linguistic styles and dialects (Eisenstein et al., 2010; Gonc\u0327alves and Sa\u0301nchez, 2014), political opinions (Caldarelli et al., 2014), and public health (Broniatowski et al., 2013). Social media permits the aggregation of datasets that are orders of magnitude larger than could be assembled via traditional survey techniques, enabling analysis that is simultaneously fine-grained and global in scale. Yet social media is not a representative sample of any \u201creal world\u201d population, aside from social media itself. Using\nsocial media as a sample therefore risks introducing both geographic and demographic biases (Mislove et al., 2011; Hecht and Stephens, 2014; Longley et al., 2015; Malik et al., 2015).\nThis paper examines the effects of these biases on the geo-linguistic inferences that can be drawn from Twitter. We focus on the ten largest metropolitan areas in the United States, and consider three sampling techniques: drawing an equal number of GPS-tagged tweets from each area; drawing a county-balanced sample of GPS-tagged messages to correct Twitter\u2019s urban skew (Hecht and Stephens, 2014); and drawing a sample of location-annotated messages, using the location field in the user profile. Leveraging self-reported first names and census statistics, we show that the age and gender composition of these datasets differ significantly.\nNext, we apply standard methods from the literature to identify geo-linguistic differences, and test how the outcomes of these methods depend on the sampling technique and on the underlying demographics. We also test the accuracy of textbased geolocation (Cheng et al., 2010; Eisenstein et al., 2010) in each dataset, to determine whether the accuracies reported in recent work will generalize to more balanced samples.\nThe paper reports several new findings about geotagged Twitter data:\n\u2022 In comparison with tweets with self-reported locations, GPS-tagged tweets are written more often by young people and by women. \u2022 There are corresponding linguistic dif-\nferences between these datasets, with GPS-tagged tweets including more geographically-specific non-standard words. \u2022 Young people use significantly more\ngeographically-specific non-standard words. Men tend to mention more geographicallyspecific entities than women, but these\nar X\niv :1\n50 6.\n02 27\n5v 2\n[ cs\n.C L\n] 2\n2 A\nug 2\n01 5\ndifferences are significant only for individuals at the age of 30 or older. \u2022 Users who GPS-tag their tweets tend to write\nmore, making them easier to geolocate. Evaluating text-based geolocation on GPS-tagged tweets probably overestimates its accuracy. \u2022 Text-based geolocation is significantly more\naccurate for men and for older people.\nThese findings should inform future attempts to generalize from geotagged Twitter data, and may suggest investigations into the demographic properties of other social media sites.\nWe first describe the basic data collection principles that hold throughout the paper (\u00a7 2). The following three sections tackle demographic biases (\u00a7 3), their linguistic consequences (\u00a7 4), and the impact on text-based geolocation (\u00a7 5); each of these sections begins with a discussion of methods, and then presents results. We then summarize related work and conclude."}, {"heading": "2 Dataset", "text": "This study is performed on a dataset of tweets gathered from Twitter\u2019s streaming API from February 2014 to January 2015. During an initial filtering step we removed retweets, repetitions of previously posted messages which contain the \u201cretweeted status\u201d metadata or \u201cRT\u201d token which is widely used among Twitter users to indicate a retweet. To eliminate spam and automated accounts (Yardi et al., 2009), we removed tweets containing URLs, user accounts with more than 1000 followers or followees, accounts which have tweeted more than 5000 messages at the time of data collection, and the top 10% of accounts based on number of messages in our dataset. We also removed users who have written more than 10% of their tweets in any language other than English, using Twitter\u2019s lang metadata field. Exploration of code-switching (Solorio and Liu, 2008) and the role of second-language English speakers (Eleta and Golbeck, 2014) is left for future work.\nWe consider the ten largest Metropolitan Statistical Areas (MSAs) in the United States, listed in Table 1. MSAs are defined by the U.S. Census Bureau as geographical regions of high population with density organized around a single urban core; they are not legal administrative divisions. MSAs include outlying areas that may be substantially less urban than the core itself. For example, the Atlanta MSA is centered on Fulton\nCounty (1750 people per square mile), but extends to Haralson County (100 people per square mile), on the border of Alabama. A per-county analysis of this data therefore enables us to assess the degree to which Twitter\u2019s skew towards urban areas biases geo-linguistic analysis."}, {"heading": "3 Representativeness of geotagged Twitter data", "text": "We first assess potential biases in sampling techniques for obtaining geotagged Twitter data. In particular, we compare two possible techniques for obtaining data: the location field in the user profile (Poblete et al., 2011; Dredze et al., 2013), and the GPS coordinates attached to each message (Cheng et al., 2010; Eisenstein et al., 2010)."}, {"heading": "3.1 Methods", "text": "To build a dataset of GPS-tagged messages, we extracted the GPS latitude and longitude coordinates reported in the tweet, and used GIS-TOOLS1 reverse geocoding to identify the corresponding counties. This set of geotagged messages will be denoted DG. Only 1.24% of messages contain geo-coordinates, and it is possible that the individuals willing to share their GPS comprise a skewed population. We therefore also considered the userreported location field in the Twitter profile, focusing on the two most widely-used patterns: (1) city name, (2) city name and two letter state name (e.g. Chicago and Chicago, IL). Messages that matched any of the ten largest MSAs were grouped into a second set, DL.\nWhile the inconsistencies of writing style in the Twitter location field are well-known (Hecht et al., 2011), analysis of the intersection between DG andDL found that the two data sources agreed the overwhelming majority of the time, suggesting that most self-provided locations are accurate. Of course, there may be many false negatives \u2014 profiles that we fail to geolocate due to the use of non-standard toponyms like Pixburgh and ATL. If so, this would introduce a bias in the population sample in DL. Such a bias might have linguistic consequences, with datasets based on the location field containing less non-standard language overall.\n1https://github.com/DrSkippy/ Data-Science-45min-Intros/blob/master/ gis-tools-101/gis_tools.ipynb"}, {"heading": "3.1.1 Subsampling", "text": "The initial samples DG and DL were then resampled to create the following balanced datasets:\nGPS-MSA-BALANCED FromDG, we randomly sampled 25,000 tweets per MSA as the message-balanced sample, and all the tweets from 2,500 users per MSA as the userbalanced sample. Balancing across MSAs ensures that the largest MSAs do not dominate the linguistic analysis.\nGPS-COUNTY-BALANCED We resampled DG based on county-level population (obtained from the U.S. Census Bureau), and again obtained message-balanced and userbalanced samples. These samples are more geographically representative of the overall population distribution across each MSA.\nLOC-MSA-BALANCED From DL, we randomly sampled 25,000 tweets per MSA as the message-balanced sample, and all the tweets from 2,500 users per MSA as the userbalanced sample. It is not possible to obtain county-level geolocations in DL, as exact geographical coordinates are unavailable."}, {"heading": "3.1.2 Age and gender identification", "text": "To estimate the distribution of ages and genders in each sample, we queried statistics from the Social Security Administration, which records the number of individuals born each year with each given name. Using this information, we obtained the probability distribution of age values for each given name. We then matched the names against the first token in the name field of each user\u2019s\nprofile, enabling us to induce approximate distributions over ages and genders. Unlike Facebook and Google+, Twitter does not have a \u201creal name\u201d policy, so users are free to give names that are fake, humorous, etc. We eliminate user accounts whose names are not sufficiently common in the social security database (i.e. first names which are at least 100 times more frequent in Twitter than in the social security database), thereby omitting 33% of user accounts, and 34% of tweets. While some individuals will choose names not typically associated with their gender, we assume that this will happen with roughly equal probability in both directions. So, with these caveats in mind, we induce the age distribution for the GPSMSA-BALANCED sample and the LOC-MSABALANCED sample as,\np(a | name = n) = count(name = n, age = a)\u2211 a\u2032 count(name = n, age = a\u2032) (1)\npD(a) \u221d \u2211 i\u2208D p(a | name = ni). (2)\nWe induce distributions over author gender in much the same way (Mislove et al., 2011). This method does not incorporate prior information about the ages of Twitter users, and thus assigns too much probability to the extremely young and old, who are unlikely to use the service. While it would be easy to design such a prior \u2014 for example, assigning zero prior probability to users under the age of five or above the age of 95 \u2014 we see no principled basis for determining these cutoffs. We therefore focus on the differences between the estimated pD(a) for each sample D."}, {"heading": "3.2 Results", "text": "Geographical biases in the GPS Sample We first assess the differences between the true population distributions over counties, and the pertweet and per-user distributions. Because counties vary widely in their degree of urbanization and other demographic characteristics, this measure is a proxy for the representativeness of GPSbased Twitter samples (county information is not available for the LOC-MSA-BALANCED sample). Population distributions for New York and Atlanta are shown in Figure 1. In Atlanta, Fulton County is the most populous and most urban, and is overrepresented in both geotagged tweets and user accounts; most of the remaining counties are correspondingly underrepresented. This coheres with the urban bias noted earlier by Hecht and Stephens (2014). In New York, Kings County (Brooklyn) is the most populous, but is underrepresented in both the number of geotagged tweets and user accounts, at the expense of New York County (Manhattan). Manhattan is the commercial and entertainment center of the New York MSA, so residents of outlying counties may be tweeting from their jobs or social activities.\nTo quantify the representativeness of each sample, we use the L1 distance ||x\u2212 y||1 = \u2211 c |pc\u2212 tc|, where pc is the proportion of the MSA population residing in county c and tc is the proportion of tweets (Table 1). County boundaries are determined by states, and their density varies: for example, the Los Angeles MSA covers only two counties, while the smaller Atlanta MSA is spread over 28 counties. The table shows that while New York is the most extreme example, most MSAs feature an asymmetry between county population and Twitter adoption.\nUsage Next, we turn to differences between the GPS-based and profile-based techniques for obtaining ground truth data. As shown in Figure 2, the LOC-MSA-BALANCED sample contains more low-volume users than either the GPSMSA-BALANCED or GPS-COUNTY-BALANCED samples. We can therefore conclude that the county-level geographical bias in the GPS-based data does not impact usage rate, but that the difference between GPS-based and profile-based sampling does; the linguistic consequences of this difference will be explored in the following sections.\nDemographics Table 2 shows the expected age and gender for each dataset, with bootstrap confidence intervals. Users in the LOC-MSABALANCED dataset are on average two years older than in the GPS-MSA-BALANCED and GPSCOUNTY-BALANCED datasets, which are statistically indistinguishable. Focusing on the difference between GPS-MSA-BALANCED and LOCMSA-BALANCED, we plot the difference in age probabilities in Figure 3, showing that GPSMSA-BALANCED includes many more teens and people in their early twenties, while LOC-MSABALANCED includes more people at middle age and older. Young people are especially likely to use social media on cellphones (Lenhart, 2015), where location tagging would be more relevant than when Twitter is accessed via a personal computer. Social media users in the age brackets 18- 29 and 30-49 are also more likely to tag their locations in social media posts than social media users in the age brackets 50-64 and 65+ (Zickuhr, 2013), with women and men tagging at roughly equal rates. Table 2 shows that the GPS-MSABALANCED and GPS-COUNTY-BALANCED sam-\n0 20 40 60 80 100\nples contain significantly more women than LOCMSA-BALANCED, though all three samples are close to 50%."}, {"heading": "4 Impact on linguistic generalizations", "text": "Many papers use Twitter data to draw conclusions about the relationship between language and geography. What role do the demographic differences identified in the previous section have on the linguistic conclusions that emerge? We measure the differences between the linguistic corpora obtained by each data acquisition approach. Since the GPS-MSA-BALANCED and GPS-COUNTYBALANCED methods have nearly identical patterns of usage and demographics, we focus on the difference between GPS-MSA-BALANCED and LOC-MSA-BALANCED. These datasets differ in age and gender, so we also directly measure the impact of these demographic factors on the use of geographically-specific linguistic variables."}, {"heading": "4.1 Methods", "text": "Discovering geographical linguistic variables We focus on lexical variation, which is relatively easy to identify in text corpora. Monroe et al. (2008) survey a range of alternative statistics for finding lexical variables, demonstrating that a regularized log-odds ratio strikes a good balance between distinctiveness and robustness. A similar approach is implemented in SAGE (Eisenstein et\nal., 2011a)2, which we use here. For each sample \u2014 GPS-MSA-BALANCED and LOC-MSABALANCED \u2014 we apply SAGE to identify the twenty-five most salient lexical items for each metropolitan area.\nKeyword annotation Previous research has identified two main types of geographical lexical variables. The first are non-standard words and spellings, such as hella and yinz, which have been found to be very frequent in social media (Eisenstein, 2015). Other researchers have focused on the \u201clong tail\u201d of entity names (Roller et al., 2012). A key question is the relative importance of these two variable types, since this would decide whether geo-linguistic differences are primarily topic-based or stylistic. It is therefore important to know whether the frequency of these two variable types depends on properties of the sample. To test this, we take the lexical items identified by SAGE (25 per MSA, for both the GPS-MSA-BALANCED and LOCMSA-BALANCED samples), and annotate them as NONSTANDARD-WORD, ENTITY-NAME, or OTHER. Annotation for ambiguous cases is based on the majority sense in randomly-selected examples. Overall, we identify 24 NONSTANDARDWORDs and 185 ENTITY-NAMEs.\nInferring author demographics As described in \u00a7 3.1.2, we can obtain an approximate distribution over author age and gender by linking selfreported first names with aggregate statistics from the United States Census. To sharpen these estimates, we now consider the text as well, building a simple latent variable model in which both the name and the word counts are drawn from distributions associated with the latent age and gender (Chang et al., 2010). The model is shown in Figure 4, and involves the following generative process:\nFor each user i \u2208 {1...N}, (a) draw the age, ai \u223c Categorical(\u03c0)\n2https://github.com/jacobeisenstein/jos-gender-2014\n(b) draw the gender, gi \u223c Categorical(0.5) (c) draw the author\u2019s given name, ni \u223c\nCategorical(\u03c6ai,gi) (d) draw the word counts, wi \u223c\nMultinomial(\u03b8ai,gi),\nwhere we elide the second parameter of the multinomial distribution, the total word count. We use expectation-maximization to perform inference in this model, binning the latent age variable into four groups: 0-17, 18-29, 30-39, above 40.3 Because the distribution of names given demographics is available from the Social Security data, we clamp the value of \u03c6 throughout the EM procedure. Other work in the domain of demographic prediction often involves more complex methods (Nguyen et al., 2014; Volkova and Durme, 2015), but since it is not the focus of our research, we take a relatively simple approach here, assuming no labeled data for demographic attributes."}, {"heading": "4.2 Results", "text": "Linguistic differences by dataset We first consider the impact of the data acquisition technique on the lexical features associated with each city. The keywords identified in GPS-MSABALANCED dataset feature more geographicallyspecific non-standard words, which occur at a rate of 3.9 \u00d7 10\u22124 in GPS-MSA-BALANCED, versus 2.6\u00d710\u22124 in LOC-MSA-BALANCED; this difference is statistically significant (p < .05, t = 3.2).4\n3Binning is often employed in work on text-based age prediction (Garera and Yarowsky, 2009; Rao et al., 2010; Rosenthal and McKeown, 2011); it enables word and name counts to be shared over multiple ages, and avoids the complexity inherent in regressing a high-dimensional textual predictors against a numerical variable.\n4We employ a paired t-test, comparing the difference in frequency for each word across the two datasets. Since we\nFor entity names, the difference between datasets was not significant, with a rate of 4.0 \u00d7 10\u22123 for GPS-MSA-BALANCED, and 3.7\u00d710\u22123 for LOCMSA-BALANCED. Note that these rates include only the non-standard words and entity names detected by SAGE as among the top 25 most distinctive for one of the ten largest cities in the US; of course there are many other relevant terms that are below this threshold.\nIn a pilot study of the GPS-COUNTYBALANCED data, we found few linguistic differences from GPS-MSA-BALANCED, in either the aggregate word-group frequencies or the SAGE word lists \u2014 despite the geographical imbalances shown in Table 1 and Figure 1. Informal examination of specific counties shows some expected differences: for example, Clayton County, which hosts Atlanta\u2019s Hartsfield-Jackson airport, includes terms related to air travel, and other counties include mentions of local cities and business districts. But the aggregate statistics for underrepresented counties are not substantially different from those of overrepresented counties, and are largely unaffected by county-based resampling.\ncannot test the complete set of entity names or non-standard words, this quantifies whether the observed difference is robust across the subset of the vocabulary that we have selected.\nDemographics Aggregate linguistic statistics for demographic groups are shown in Figure 5. Men use significantly more geographicallyspecific entity names than women (p .01, t = 8.0), but gender differences for geographicallyspecific non-standard words are not significant (p \u2248 .2).5 Younger people use significantly more geographically-specific non-standard words than older people (ages 0\u201329 versus 30+, p .01, t = 7.8), and older people mention significantly more geographically-specific entity names (p .01, t = 5.1). Of particular interest is the intersection of age and gender: the use of geographically-specific non-standard words decreases with age much more profoundly for men than for women; conversely, the frequency of mentioning geographically-specific entity names increases dramatically with age for men, but to a much lesser extent for women. The observation that high-level patterns of geographically-oriented language are more age-dependent for men than for women suggests an intriguing site for future research on the intersectional construction of linguistic identity.\nFor a more detailed view, we apply SAGE to identify the most salient lexical items for each MSA, subgrouped by age and gender. Table 3 shows word lists for New York (the largest MSA) and Dallas (the 5th-largest MSA), using the GPSMSA-BALANCED sample. Non-standard words tend to be used by the youngest authors: ilysm (\u2019I love you so much\u2019), ight (\u2019alright\u2019), oomf (\u2019one of my followers\u2019). Older authors write more about local entities (manhattan, nyc, houston), with men focusing on sports-related entities (harden, watt, astros, mets, texans), and women above the\n5But see Bamman et al. (2014) for a much more detailed discussion of gender and standardness.\nage of 40 emphasizing religiously-oriented terms (proverb, islam, rejoice, psalm)."}, {"heading": "5 Impact on text-based geolocation", "text": "A major application of geotagged social media is to predict the geolocation of individuals based on their text (Eisenstein et al., 2010; Cheng et al., 2010; Wing and Baldridge, 2011; Hong et al., 2012; Han et al., 2014). Text-based geolocation has obvious commercial implications for location-based marketing and opinion analysis; it is also potentially useful for researchers who want to measure geographical phenomena in social media, and wish to access a larger set of individuals than those who provide their locations explicitly.\nPrevious research has obtained impressive accuracies for text-based geolocation: for example, Hong et al. (2012) report a median error of 120 km, which is roughly the distance from Los Angeles to San Diego, in a prediction space over the entire continental United States. These accuracies are computed on test sets that were acquired through the same procedures as the training data, so if the acquisition procedures have geographic and demographic biases, then the resulting accuracy estimates will be biased too. Consequently, they may be overly optimistic (or pessimistic!) for some types of authors. In this section, we explore where these text-based geolocation methods are most and least accurate."}, {"heading": "5.1 Methods", "text": "Our data is drawn from the ten largest metropolitan areas in the United States, and we formulate text-based geolocation as a ten-way classification problem, similar to Han et al. (2014).6 Using our\n6Many previous papers have attempted to identify the precise latitude and longitude coordinates of individual authors, but obtaining high accuracy on this task involves much more\nuser-balanced samples, we apply ten-fold cross validation, and tune the regularization parameter on a development fold, using the vocabulary of the sample as features."}, {"heading": "5.2 Results", "text": "Many author-attribute prediction tasks become substantially easier as more data is available (Burger et al., 2011), and text-based geolocation is no exception. Since GPS-MSABALANCED and LOC-MSA-BALANCED have very different usage rates (Figure 2), perceived differences in accuracy may be purely attributable to the amount of data available per user, rather than to users in one group being inherently harder to classify than another. For this reason, we bin users by the number of messages in our sample of their timeline, and report results separately for each bin. All errorbars represent 95% confidence intervals.\nGPS versus location As seen in Figure 6a, there is little difference in accuracy across sampling techniques: the location-based sample is slightly easier to geolocate at each usage bin, but the difference is not statistically significant. However, due to the higher average usage rate in GPSMSA-BALANCED(see Figure 2), the overall accuracy for a sample of users will appear to be higher on this data.\nDemographics Next, we measure classification accuracy by gender and age, using the posterior distribution from the expectation-maximization algorithm to predict the gender of each user (broadly similar results are obtained by using the prior distribution). For this experiment, we focus on the GPS-MSA-BALANCED sample. As shown in Figure 6b, text-based geolocation is consistently more accurate for male authors, across almost the entire spectrum of usage rates. As shown in Figure 6c, older users also tend to be easier to geolocate: at each usage level, the highest accuracy goes to one of the two older groups, and the difference is significant in almost every case. As discussed in \u00a7 4, older male users tend to mention many entities, particularly sports-related terms; these terms are apparently more predictive than\ncomplex methods, such as latent variable models (Eisenstein et al., 2010; Hong et al., 2012), or multilevel grid structures (Cheng et al., 2010; Roller et al., 2012). Tuning such models can be challenging, and the resulting accuracies might be affected by initial conditions or hyperparameters. We therefore focus on classification, employing the familiar and well-understood method of logistic regression.\nthe non-standard spellings and slang favored by younger authors."}, {"heading": "6 Related Work", "text": "Several researchers have studied how adoption of Internet technology varies with factors such as socioeconomic status, age, gender, and living conditions (Zillien and Hargittai, 2009). Hargittai and Litt (2011) use a longitudinal survey methodology to compare the effects of gender, race, and topics of interest on Twitter usage among young adults. Geographic variation in Twitter adoption has been considered both internationally (Kulshrestha et al., 2012) and within the United States, using both the Twitter location field (Mislove et al., 2011) and per-message GPS coordinates (Hecht and Stephens, 2014). Aggregate demographic statistics of Twitter users\u2019 geographic census blocks were computed by O\u2019Connor et al. (2010) and Eisenstein et al. (2011b); Malik et al. (2015) use census demographics in spatial error model. These papers draw similar conclusions, showing that the the distribution of geotagged tweets over the US population is not random, and that higher usage is correlated with urban areas, high income, more ethnic minorities, and more young people. However, this prior work did not consider the biases introduced by relying on geotagged messages, nor the consequences for geo-linguistic analysis.\nTwitter has often been used to study the geographical distribution of linguistic information, and of particular relevance are Twitter-based studies of regional dialect differences (Eisenstein et al., 2010; Doyle, 2014; Gonc\u0327alves and Sa\u0301nchez, 2014; Eisenstein, 2015) and text-based geolocation (Cheng et al., 2010; Hong et al., 2012; Han et al., 2014). This prior work rarely considers the impact of the demographic confounds, or of the geographical biases mentioned in \u00a7 3. Recent research shows that accuracies of core language technology tasks such as part-of-speech tagging are correlated with author demographics such as author age (Hovy and S\u00f8gaard, 2015); our results on location prediction are in accord with these findings. Hovy (2015) show that including author demographics can improve text classification, a similar approach might improve text-based geolocation as well.\nWe address the question about the impact of geographical biases and demographic confounds by measuring differences between three sampling\ntechniques, in both language use and in the accuracy of text-based geolocation. Recent unpublished work proposes reweighting Twitter data to correct biases in political analysis (Choy et al., 2012) and public health (Culotta, 2014). Our results suggest that the linguistic differences between user-supplied profile locations and permessage geotags are more significant, and that accounting for the geographical biases among geotagged messages is not sufficient to offer a representative sample of Twitter users."}, {"heading": "7 Discussion", "text": "Geotagged Twitter data offers an invaluable resource for studying the interaction of language and geography, and is helping to usher in a new generation of location-aware language technology. This makes critical investigation of the nature of this data source particularly important. This paper uncovers demographic confounds in the linguistic analysis of geo-located Twitter data, but is limited to demographics that can be readily induced from given names. A key task for future work is to quantify the representativeness of geotagged Twitter data with respect to factors such as race and socioeconomic status, while holding geography constant. However, these features may be more difficult to impute from names alone. Another crucial task is to expand this investigation beyond the United States, as the varying patterns of use for social media across countries (Pew Research Center, 2012) implies that the findings here cannot be expected to generalize to every international context.\nAcknowledgments Thanks to the anonymous reviewers for their useful and constructive feedback on our submission. The following members of the Georgia Tech Computational Linguistics Laboratory offered feedback throughout the research process: Naman Goyal, Yangfeng Ji, Vin-\nodh Krishan, Ana Smith, Yijie Wang, and Yi Yang. This research was supported by the National Science Foundation under awards IIS-1111142 and RI-1452443, by the National Institutes of Health under award number R01GM112697-01, and by the Air Force Office of Scientific Research. The content is solely the responsibility of the authors and does not necessarily represent the official views of these sponsors."}], "references": [{"title": "Gender identity and lexical variation in social media", "author": ["David Bamman", "Jacob Eisenstein", "Tyler Schnoebelen."], "venue": "Journal of Sociolinguistics, 18(2):135\u2013160.", "citeRegEx": "Bamman et al\\.,? 2014", "shortCiteRegEx": "Bamman et al\\.", "year": 2014}, {"title": "National and local influenza surveillance through twitter: An analysis of the 2012-2013 influenza epidemic", "author": ["David A Broniatowski", "Michael J Paul", "Mark Dredze."], "venue": "PloS one, 8(12):e83672.", "citeRegEx": "Broniatowski et al\\.,? 2013", "shortCiteRegEx": "Broniatowski et al\\.", "year": 2013}, {"title": "Discriminating gender on twitter", "author": ["John D. Burger", "John Henderson", "George Kim", "Guido Zarrella."], "venue": "Proceedings of the Conference on Empirical Methods in Natural Language Processing.", "citeRegEx": "Burger et al\\.,? 2011", "shortCiteRegEx": "Burger et al\\.", "year": 2011}, {"title": "A multi-level geographical study of Italian political elections from Twitter Data", "author": ["Guido Caldarelli", "Alessandro Chessa", "Fabio Pammolli", "Gabriele Pompa", "Michelangelo Puliga", "Massimo Riccaboni", "Gianni Riotta."], "venue": "PloS one, 9(5):e95809.", "citeRegEx": "Caldarelli et al\\.,? 2014", "shortCiteRegEx": "Caldarelli et al\\.", "year": 2014}, {"title": "ePluribus: Ethnicity on social networks", "author": ["Jonathan Chang", "Itamar Rosenn", "Lars Backstrom", "Cameron Marlow."], "venue": "Proceedings of the International Conference on Web and Social Media (ICWSM), pages 18\u201325, Menlo Park, California. AAAI Pub-", "citeRegEx": "Chang et al\\.,? 2010", "shortCiteRegEx": "Chang et al\\.", "year": 2010}, {"title": "You are where you tweet: a content-based approach to geo-locating twitter users", "author": ["Zhiyuan Cheng", "James Caverlee", "Kyumin Lee."], "venue": "Proceedings of the International Conference on Information and Knowledge Management (CIKM), pages 759\u2013768.", "citeRegEx": "Cheng et al\\.,? 2010", "shortCiteRegEx": "Cheng et al\\.", "year": 2010}, {"title": "Reducing sampling bias in social media data for county health inference", "author": ["Aron Culotta."], "venue": "Joint Statistical Meetings Proceedings.", "citeRegEx": "Culotta.,? 2014", "shortCiteRegEx": "Culotta.", "year": 2014}, {"title": "Mapping dialectal variation by querying social media", "author": ["Gabriel Doyle."], "venue": "Proceedings of the European Chapter of the Association for Computational Linguistics (EACL), pages 98\u2013106, Stroudsburg, Pennsylvania. Association for Computational", "citeRegEx": "Doyle.,? 2014", "shortCiteRegEx": "Doyle.", "year": 2014}, {"title": "Carmen: A Twitter geolocation system with applications to public health", "author": ["Mark Dredze", "Michael J Paul", "Shane Bergsma", "Hieu Tran."], "venue": "AAAI Workshop on Expanding the Boundaries of Health Informatics Using Artificial Intelligence, pages 20\u2013", "citeRegEx": "Dredze et al\\.,? 2013", "shortCiteRegEx": "Dredze et al\\.", "year": 2013}, {"title": "A latent variable model for geographic lexical variation", "author": ["Jacob Eisenstein", "Brendan O\u2019Connor", "Noah A. Smith", "Eric P. Xing"], "venue": "In Proceedings of Empirical Methods for Natural Language Processing (EMNLP),", "citeRegEx": "Eisenstein et al\\.,? \\Q2010\\E", "shortCiteRegEx": "Eisenstein et al\\.", "year": 2010}, {"title": "Sparse additive generative models of text", "author": ["Jacob Eisenstein", "Amr Ahmed", "Eric P. Xing."], "venue": "Proceedings of the International Conference on Machine Learning (ICML), pages 1041\u20131048, Seattle, WA.", "citeRegEx": "Eisenstein et al\\.,? 2011a", "shortCiteRegEx": "Eisenstein et al\\.", "year": 2011}, {"title": "Discovering sociolinguistic associations with structured sparsity", "author": ["Jacob Eisenstein", "Noah A. Smith", "Eric P. Xing."], "venue": "Proceedings of the Association for Computational Linguistics (ACL), pages 1365\u20131374, Portland, OR.", "citeRegEx": "Eisenstein et al\\.,? 2011b", "shortCiteRegEx": "Eisenstein et al\\.", "year": 2011}, {"title": "Written dialect variation in online social media", "author": ["Jacob Eisenstein."], "venue": "Charles Boberg, John Nerbonne, and Dom Watt, editors, Handbook of Dialectology. Wiley.", "citeRegEx": "Eisenstein.,? 2015", "shortCiteRegEx": "Eisenstein.", "year": 2015}, {"title": "Multilingual use of twitter: Social networks at the language frontier", "author": ["Irene Eleta", "Jennifer Golbeck."], "venue": "Computers in Human Behavior, 41:424\u2013432.", "citeRegEx": "Eleta and Golbeck.,? 2014", "shortCiteRegEx": "Eleta and Golbeck.", "year": 2014}, {"title": "Modeling latent biographic attributes in conversational genres", "author": ["Nikesh Garera", "David Yarowsky."], "venue": "Proceedings of the Association for Computational Linguistics (ACL), pages 710\u2013718, Suntec, Singapore.", "citeRegEx": "Garera and Yarowsky.,? 2009", "shortCiteRegEx": "Garera and Yarowsky.", "year": 2009}, {"title": "Crowdsourcing dialect characterization through twitter", "author": ["Bruno Gon\u00e7alves", "David S\u00e1nchez."], "venue": "PloS one, 9(11):e112074.", "citeRegEx": "Gon\u00e7alves and S\u00e1nchez.,? 2014", "shortCiteRegEx": "Gon\u00e7alves and S\u00e1nchez.", "year": 2014}, {"title": "Text-based twitter user geolocation prediction", "author": ["Bo Han", "Paul Cook", "Timothy Baldwin."], "venue": "Journal of Artificial Intelligence Research (JAIR), 49:451\u2013500.", "citeRegEx": "Han et al\\.,? 2014", "shortCiteRegEx": "Han et al\\.", "year": 2014}, {"title": "The tweet smell of celebrity success: Explaining variation in twitter adoption among a diverse group of young adults", "author": ["Eszter Hargittai", "Eden Litt."], "venue": "New Media & Society, 13(5):824\u2013842.", "citeRegEx": "Hargittai and Litt.,? 2011", "shortCiteRegEx": "Hargittai and Litt.", "year": 2011}, {"title": "A tale of cities: Urban biases in volunteered geographic information", "author": ["Brent Hecht", "Monica Stephens."], "venue": "Proceedings of the International Conference on Web and Social Media (ICWSM), pages 197\u2013205, Menlo Park, California. AAAI Publica-", "citeRegEx": "Hecht and Stephens.,? 2014", "shortCiteRegEx": "Hecht and Stephens.", "year": 2014}, {"title": "Tweets from Justin Bieber\u2019s heart: the dynamics of the location field in user profiles", "author": ["Brent Hecht", "Lichan Hong", "Bongwon Suh", "Ed H Chi."], "venue": "Proceedings of Human Factors in Computing Systems (CHI), pages 237\u2013246.", "citeRegEx": "Hecht et al\\.,? 2011", "shortCiteRegEx": "Hecht et al\\.", "year": 2011}, {"title": "Discovering geographical topics in the twitter stream", "author": ["Liangjie Hong", "Amr Ahmed", "Siva Gurumurthy", "Alexander J. Smola", "Kostas Tsioutsiouliklis."], "venue": "Proceedings of the Conference on WorldWide Web (WWW), pages 769\u2013778, Lyon, France.", "citeRegEx": "Hong et al\\.,? 2012", "shortCiteRegEx": "Hong et al\\.", "year": 2012}, {"title": "Tagging performance correlates with author age", "author": ["Dirk Hovy", "Anders S\u00f8gaard."], "venue": "Proceedings of the Association for Computational Linguistics (ACL), pages 483\u2013488, Beijing, China.", "citeRegEx": "Hovy and S\u00f8gaard.,? 2015", "shortCiteRegEx": "Hovy and S\u00f8gaard.", "year": 2015}, {"title": "Demographic factors improve classification performance", "author": ["Dirk Hovy."], "venue": "Proceedings of the Association for Computational Linguistics (ACL), pages 752\u2013762, Beijing, China.", "citeRegEx": "Hovy.,? 2015", "shortCiteRegEx": "Hovy.", "year": 2015}, {"title": "Geographic Dissection of the Twitter Network", "author": ["Juhi Kulshrestha", "Farshad Kooti", "Ashkan Nikravesh", "Krishna P. Gummadi."], "venue": "Proceedings of the International Conference on Web and Social Media (ICWSM), Menlo Park, California. AAAI Publi-", "citeRegEx": "Kulshrestha et al\\.,? 2012", "shortCiteRegEx": "Kulshrestha et al\\.", "year": 2012}, {"title": "Mobile access shifts social media use and other online activities", "author": ["Amanda Lenhart."], "venue": "Technical report, Pew Research Center, April.", "citeRegEx": "Lenhart.,? 2015", "shortCiteRegEx": "Lenhart.", "year": 2015}, {"title": "The geotemporal demographics of twitter usage", "author": ["P.A. Longley", "M. Adnan", "G. Lansley."], "venue": "Environment and Planning A, 47(2):465\u2013484.", "citeRegEx": "Longley et al\\.,? 2015", "shortCiteRegEx": "Longley et al\\.", "year": 2015}, {"title": "Population bias in geotagged tweets", "author": ["Momin Malik", "Hemank Lamba", "Constantine Nakos", "J\u00fcrgen Pfeffer."], "venue": "Papers from the 2015 ICWSM Workshop on Standards and Practices in LargeScale Social Media Research, pages 18\u201327. The", "citeRegEx": "Malik et al\\.,? 2015", "shortCiteRegEx": "Malik et al\\.", "year": 2015}, {"title": "Understanding the demographics of twitter users", "author": ["Alan Mislove", "Sune Lehmann", "Yong-Yeol Ahn", "JukkaPekka Onnela", "J. Niels Rosenquist."], "venue": "Proceedings of the International Conference on Web and Social Media (ICWSM), pages 554\u2013557, Menlo", "citeRegEx": "Mislove et al\\.,? 2011", "shortCiteRegEx": "Mislove et al\\.", "year": 2011}, {"title": "Fightin\u2019words: Lexical feature selection and evaluation for identifying the content of political conflict", "author": ["Burt L Monroe", "Michael P Colaresi", "Kevin M Quinn."], "venue": "Political Analysis, 16(4):372\u2013403.", "citeRegEx": "Monroe et al\\.,? 2008", "shortCiteRegEx": "Monroe et al\\.", "year": 2008}, {"title": "Why gender and age prediction from tweets is hard: Lessons from a crowdsourcing experiment", "author": ["Dong Nguyen", "Dolf Trieschnigg", "A Seza Dogru\u00f6z", "Rilana Gravel", "Mari\u00ebt Theune", "Theo Meder", "Franciska de Jong."], "venue": "Proceedings of the Inter-", "citeRegEx": "Nguyen et al\\.,? 2014", "shortCiteRegEx": "Nguyen et al\\.", "year": 2014}, {"title": "A mixture model of demographic lexical variation", "author": ["Brendan O\u2019Connor", "Jacob Eisenstein", "Eric P. Xing", "Noah A. Smith"], "venue": "In Proceedings of NIPS Workshop on Machine Learning", "citeRegEx": "O.Connor et al\\.,? \\Q2010\\E", "shortCiteRegEx": "O.Connor et al\\.", "year": 2010}, {"title": "Social networking popular across globe", "author": ["Pew Research Center."], "venue": "Technical report, December.", "citeRegEx": "Center.,? 2012", "shortCiteRegEx": "Center.", "year": 2012}, {"title": "Do all birds tweet the same? characterizing Twitter around the world", "author": ["Barbara Poblete", "Ruth Garcia", "Marcelo Mendoza", "Alejandro Jaimes."], "venue": "Proceedings of the International Conference on Information and Knowledge Management (CIKM),", "citeRegEx": "Poblete et al\\.,? 2011", "shortCiteRegEx": "Poblete et al\\.", "year": 2011}, {"title": "Classifying latent user attributes in twitter", "author": ["Delip Rao", "David Yarowsky", "Abhishek Shreevats", "Manaswi Gupta."], "venue": "Proceedings of Workshop on Search and mining user-generated contents.", "citeRegEx": "Rao et al\\.,? 2010", "shortCiteRegEx": "Rao et al\\.", "year": 2010}, {"title": "Supervised text-based geolocation using language models on an adaptive grid", "author": ["Stephen Roller", "Michael Speriosu", "Sarat Rallapalli", "Benjamin Wing", "Jason Baldridge."], "venue": "Proceedings of Empirical Methods for Natural Language Processing", "citeRegEx": "Roller et al\\.,? 2012", "shortCiteRegEx": "Roller et al\\.", "year": 2012}, {"title": "Age prediction in blogs: A study of style, content, and online behavior in pre- and Post-Social media generations", "author": ["Sara Rosenthal", "Kathleen McKeown."], "venue": "Proceedings of the Association for Computational Linguistics (ACL), pages 763\u2013772, Port-", "citeRegEx": "Rosenthal and McKeown.,? 2011", "shortCiteRegEx": "Rosenthal and McKeown.", "year": 2011}, {"title": "Learning to predict code-switching points", "author": ["Thamar Solorio", "Yang Liu."], "venue": "Proceedings of Empirical Methods for Natural Language Processing (EMNLP), pages 973\u2013981, Honolulu, HI, October. Association for Computational Linguistics.", "citeRegEx": "Solorio and Liu.,? 2008", "shortCiteRegEx": "Solorio and Liu.", "year": 2008}, {"title": "Online bayesian models for personal analytics in social media", "author": ["Svitlana Volkova", "Benjamin Van Durme."], "venue": "Proceedings of the National Conference on Artificial Intelligence (AAAI), pages 2325\u2013 2331.", "citeRegEx": "Volkova and Durme.,? 2015", "shortCiteRegEx": "Volkova and Durme.", "year": 2015}, {"title": "Simple supervised document geolocation with geodesic grids", "author": ["Benjamin Wing", "Jason Baldridge."], "venue": "Proceedings of the Association for Computational Linguistics (ACL), pages 955\u2013964, Portland, OR.", "citeRegEx": "Wing and Baldridge.,? 2011", "shortCiteRegEx": "Wing and Baldridge.", "year": 2011}, {"title": "Detecting spam in a twitter network", "author": ["Sarita Yardi", "Daniel Romero", "Grant Schoenebeck"], "venue": "First Monday,", "citeRegEx": "Yardi et al\\.,? \\Q2009\\E", "shortCiteRegEx": "Yardi et al\\.", "year": 2009}, {"title": "Location-based services", "author": ["Kathryn Zickuhr."], "venue": "Technical report, Pew Research Center, Septmeber.", "citeRegEx": "Zickuhr.,? 2013", "shortCiteRegEx": "Zickuhr.", "year": 2013}, {"title": "Digital distinction: Status-specific types of internet usage", "author": ["Nicole Zillien", "Eszter Hargittai."], "venue": "Social Science Quarterly, 90(2):274\u2013291.", "citeRegEx": "Zillien and Hargittai.,? 2009", "shortCiteRegEx": "Zillien and Hargittai.", "year": 2009}], "referenceMentions": [{"referenceID": 20, "context": "Social media data such as Twitter is frequently used to identify the unique characteristics of geographical regions, including topics of interest (Hong et al., 2012), linguistic styles and dialects (Eisenstein et al.", "startOffset": 146, "endOffset": 165}, {"referenceID": 9, "context": ", 2012), linguistic styles and dialects (Eisenstein et al., 2010; Gon\u00e7alves and S\u00e1nchez, 2014), political opinions (Caldarelli et al.", "startOffset": 40, "endOffset": 94}, {"referenceID": 15, "context": ", 2012), linguistic styles and dialects (Eisenstein et al., 2010; Gon\u00e7alves and S\u00e1nchez, 2014), political opinions (Caldarelli et al.", "startOffset": 40, "endOffset": 94}, {"referenceID": 3, "context": ", 2010; Gon\u00e7alves and S\u00e1nchez, 2014), political opinions (Caldarelli et al., 2014), and public health (Broniatowski et al.", "startOffset": 57, "endOffset": 82}, {"referenceID": 1, "context": ", 2014), and public health (Broniatowski et al., 2013).", "startOffset": 27, "endOffset": 54}, {"referenceID": 27, "context": "Using social media as a sample therefore risks introducing both geographic and demographic biases (Mislove et al., 2011; Hecht and Stephens, 2014; Longley et al., 2015; Malik et al., 2015).", "startOffset": 98, "endOffset": 188}, {"referenceID": 18, "context": "Using social media as a sample therefore risks introducing both geographic and demographic biases (Mislove et al., 2011; Hecht and Stephens, 2014; Longley et al., 2015; Malik et al., 2015).", "startOffset": 98, "endOffset": 188}, {"referenceID": 25, "context": "Using social media as a sample therefore risks introducing both geographic and demographic biases (Mislove et al., 2011; Hecht and Stephens, 2014; Longley et al., 2015; Malik et al., 2015).", "startOffset": 98, "endOffset": 188}, {"referenceID": 26, "context": "Using social media as a sample therefore risks introducing both geographic and demographic biases (Mislove et al., 2011; Hecht and Stephens, 2014; Longley et al., 2015; Malik et al., 2015).", "startOffset": 98, "endOffset": 188}, {"referenceID": 18, "context": "We focus on the ten largest metropolitan areas in the United States, and consider three sampling techniques: drawing an equal number of GPS-tagged tweets from each area; drawing a county-balanced sample of GPS-tagged messages to correct Twitter\u2019s urban skew (Hecht and Stephens, 2014); and drawing a sample of location-annotated messages, using the location field in the user profile.", "startOffset": 258, "endOffset": 284}, {"referenceID": 5, "context": "We also test the accuracy of textbased geolocation (Cheng et al., 2010; Eisenstein et al., 2010) in each dataset, to determine whether the accuracies reported in recent work will generalize to more balanced samples.", "startOffset": 51, "endOffset": 96}, {"referenceID": 9, "context": "We also test the accuracy of textbased geolocation (Cheng et al., 2010; Eisenstein et al., 2010) in each dataset, to determine whether the accuracies reported in recent work will generalize to more balanced samples.", "startOffset": 51, "endOffset": 96}, {"referenceID": 39, "context": "To eliminate spam and automated accounts (Yardi et al., 2009), we removed tweets containing URLs, user accounts with more than 1000 followers or followees, accounts which have tweeted more than 5000 messages at the time of data collection, and the top 10% of accounts based on number of messages in our dataset.", "startOffset": 41, "endOffset": 61}, {"referenceID": 36, "context": "Exploration of code-switching (Solorio and Liu, 2008) and the role of second-language English speakers (Eleta and Golbeck, 2014) is left for future work.", "startOffset": 30, "endOffset": 53}, {"referenceID": 13, "context": "Exploration of code-switching (Solorio and Liu, 2008) and the role of second-language English speakers (Eleta and Golbeck, 2014) is left for future work.", "startOffset": 103, "endOffset": 128}, {"referenceID": 32, "context": "In particular, we compare two possible techniques for obtaining data: the location field in the user profile (Poblete et al., 2011; Dredze et al., 2013), and the GPS coordinates attached to each message (Cheng et al.", "startOffset": 109, "endOffset": 152}, {"referenceID": 8, "context": "In particular, we compare two possible techniques for obtaining data: the location field in the user profile (Poblete et al., 2011; Dredze et al., 2013), and the GPS coordinates attached to each message (Cheng et al.", "startOffset": 109, "endOffset": 152}, {"referenceID": 5, "context": ", 2013), and the GPS coordinates attached to each message (Cheng et al., 2010; Eisenstein et al., 2010).", "startOffset": 58, "endOffset": 103}, {"referenceID": 9, "context": ", 2013), and the GPS coordinates attached to each message (Cheng et al., 2010; Eisenstein et al., 2010).", "startOffset": 58, "endOffset": 103}, {"referenceID": 19, "context": "While the inconsistencies of writing style in the Twitter location field are well-known (Hecht et al., 2011), analysis of the intersection between DG andDL found that the two data sources agreed the overwhelming majority of the time, suggesting that most self-provided locations are accurate.", "startOffset": 88, "endOffset": 108}, {"referenceID": 27, "context": "We induce distributions over author gender in much the same way (Mislove et al., 2011).", "startOffset": 64, "endOffset": 86}, {"referenceID": 18, "context": "This coheres with the urban bias noted earlier by Hecht and Stephens (2014). In New York, Kings County (Brooklyn) is the most populous, but is underrepresented in both the number of geotagged tweets and user accounts, at the expense of New York County (Manhattan).", "startOffset": 50, "endOffset": 76}, {"referenceID": 24, "context": "Young people are especially likely to use social media on cellphones (Lenhart, 2015), where location tagging would be more relevant than when Twitter is accessed via a personal computer.", "startOffset": 69, "endOffset": 84}, {"referenceID": 40, "context": "Social media users in the age brackets 1829 and 30-49 are also more likely to tag their locations in social media posts than social media users in the age brackets 50-64 and 65+ (Zickuhr, 2013), with women and men tagging at roughly equal rates.", "startOffset": 178, "endOffset": 193}, {"referenceID": 10, "context": "A similar approach is implemented in SAGE (Eisenstein et al., 2011a)2, which we use here.", "startOffset": 42, "endOffset": 68}, {"referenceID": 24, "context": "Monroe et al. (2008) survey a range of alternative statistics for finding lexical variables, demonstrating that a regularized log-odds ratio strikes a good balance between distinctiveness and robustness.", "startOffset": 0, "endOffset": 21}, {"referenceID": 12, "context": "The first are non-standard words and spellings, such as hella and yinz, which have been found to be very frequent in social media (Eisenstein, 2015).", "startOffset": 130, "endOffset": 148}, {"referenceID": 34, "context": "Other researchers have focused on the \u201clong tail\u201d of entity names (Roller et al., 2012).", "startOffset": 66, "endOffset": 87}, {"referenceID": 4, "context": "To sharpen these estimates, we now consider the text as well, building a simple latent variable model in which both the name and the word counts are drawn from distributions associated with the latent age and gender (Chang et al., 2010).", "startOffset": 216, "endOffset": 236}, {"referenceID": 29, "context": "Other work in the domain of demographic prediction often involves more complex methods (Nguyen et al., 2014; Volkova and Durme, 2015), but since it is not the focus of our research, we take a relatively simple approach here, assuming no labeled data for demographic attributes.", "startOffset": 87, "endOffset": 133}, {"referenceID": 37, "context": "Other work in the domain of demographic prediction often involves more complex methods (Nguyen et al., 2014; Volkova and Durme, 2015), but since it is not the focus of our research, we take a relatively simple approach here, assuming no labeled data for demographic attributes.", "startOffset": 87, "endOffset": 133}, {"referenceID": 14, "context": "Binning is often employed in work on text-based age prediction (Garera and Yarowsky, 2009; Rao et al., 2010; Rosenthal and McKeown, 2011); it enables word and name counts to be shared over multiple ages, and avoids the complexity inherent in regressing a high-dimensional textual predictors against a numerical variable.", "startOffset": 63, "endOffset": 137}, {"referenceID": 33, "context": "Binning is often employed in work on text-based age prediction (Garera and Yarowsky, 2009; Rao et al., 2010; Rosenthal and McKeown, 2011); it enables word and name counts to be shared over multiple ages, and avoids the complexity inherent in regressing a high-dimensional textual predictors against a numerical variable.", "startOffset": 63, "endOffset": 137}, {"referenceID": 35, "context": "Binning is often employed in work on text-based age prediction (Garera and Yarowsky, 2009; Rao et al., 2010; Rosenthal and McKeown, 2011); it enables word and name counts to be shared over multiple ages, and avoids the complexity inherent in regressing a high-dimensional textual predictors against a numerical variable.", "startOffset": 63, "endOffset": 137}, {"referenceID": 0, "context": "But see Bamman et al. (2014) for a much more detailed discussion of gender and standardness.", "startOffset": 8, "endOffset": 29}, {"referenceID": 9, "context": "A major application of geotagged social media is to predict the geolocation of individuals based on their text (Eisenstein et al., 2010; Cheng et al., 2010; Wing and Baldridge, 2011; Hong et al., 2012; Han et al., 2014).", "startOffset": 111, "endOffset": 219}, {"referenceID": 5, "context": "A major application of geotagged social media is to predict the geolocation of individuals based on their text (Eisenstein et al., 2010; Cheng et al., 2010; Wing and Baldridge, 2011; Hong et al., 2012; Han et al., 2014).", "startOffset": 111, "endOffset": 219}, {"referenceID": 38, "context": "A major application of geotagged social media is to predict the geolocation of individuals based on their text (Eisenstein et al., 2010; Cheng et al., 2010; Wing and Baldridge, 2011; Hong et al., 2012; Han et al., 2014).", "startOffset": 111, "endOffset": 219}, {"referenceID": 20, "context": "A major application of geotagged social media is to predict the geolocation of individuals based on their text (Eisenstein et al., 2010; Cheng et al., 2010; Wing and Baldridge, 2011; Hong et al., 2012; Han et al., 2014).", "startOffset": 111, "endOffset": 219}, {"referenceID": 16, "context": "A major application of geotagged social media is to predict the geolocation of individuals based on their text (Eisenstein et al., 2010; Cheng et al., 2010; Wing and Baldridge, 2011; Hong et al., 2012; Han et al., 2014).", "startOffset": 111, "endOffset": 219}, {"referenceID": 20, "context": "Previous research has obtained impressive accuracies for text-based geolocation: for example, Hong et al. (2012) report a median error of 120 km, which is roughly the distance from Los Angeles to San Diego, in a prediction space over the entire continental United States.", "startOffset": 94, "endOffset": 113}, {"referenceID": 16, "context": "Our data is drawn from the ten largest metropolitan areas in the United States, and we formulate text-based geolocation as a ten-way classification problem, similar to Han et al. (2014).6 Using our", "startOffset": 168, "endOffset": 186}, {"referenceID": 2, "context": "Many author-attribute prediction tasks become substantially easier as more data is available (Burger et al., 2011), and text-based geolocation is no exception.", "startOffset": 93, "endOffset": 114}, {"referenceID": 9, "context": "complex methods, such as latent variable models (Eisenstein et al., 2010; Hong et al., 2012), or multilevel grid structures (Cheng et al.", "startOffset": 48, "endOffset": 92}, {"referenceID": 20, "context": "complex methods, such as latent variable models (Eisenstein et al., 2010; Hong et al., 2012), or multilevel grid structures (Cheng et al.", "startOffset": 48, "endOffset": 92}, {"referenceID": 5, "context": ", 2012), or multilevel grid structures (Cheng et al., 2010; Roller et al., 2012).", "startOffset": 39, "endOffset": 80}, {"referenceID": 34, "context": ", 2012), or multilevel grid structures (Cheng et al., 2010; Roller et al., 2012).", "startOffset": 39, "endOffset": 80}, {"referenceID": 41, "context": "Several researchers have studied how adoption of Internet technology varies with factors such as socioeconomic status, age, gender, and living conditions (Zillien and Hargittai, 2009).", "startOffset": 154, "endOffset": 183}, {"referenceID": 23, "context": "Geographic variation in Twitter adoption has been considered both internationally (Kulshrestha et al., 2012) and within the United States, using both the Twitter location field (Mislove et al.", "startOffset": 82, "endOffset": 108}, {"referenceID": 27, "context": ", 2012) and within the United States, using both the Twitter location field (Mislove et al., 2011) and per-message GPS coordinates (Hecht and Stephens, 2014).", "startOffset": 76, "endOffset": 98}, {"referenceID": 18, "context": ", 2011) and per-message GPS coordinates (Hecht and Stephens, 2014).", "startOffset": 40, "endOffset": 66}, {"referenceID": 13, "context": "Hargittai and Litt (2011) use a longitudinal survey methodology to compare the effects of gender, race, and topics of interest on Twitter usage among young adults.", "startOffset": 0, "endOffset": 26}, {"referenceID": 13, "context": "Hargittai and Litt (2011) use a longitudinal survey methodology to compare the effects of gender, race, and topics of interest on Twitter usage among young adults. Geographic variation in Twitter adoption has been considered both internationally (Kulshrestha et al., 2012) and within the United States, using both the Twitter location field (Mislove et al., 2011) and per-message GPS coordinates (Hecht and Stephens, 2014). Aggregate demographic statistics of Twitter users\u2019 geographic census blocks were computed by O\u2019Connor et al. (2010) and Eisenstein et al.", "startOffset": 0, "endOffset": 540}, {"referenceID": 9, "context": "(2010) and Eisenstein et al. (2011b); Malik et al.", "startOffset": 11, "endOffset": 37}, {"referenceID": 9, "context": "(2010) and Eisenstein et al. (2011b); Malik et al. (2015) use census demographics in spatial error model.", "startOffset": 11, "endOffset": 58}, {"referenceID": 9, "context": "Twitter has often been used to study the geographical distribution of linguistic information, and of particular relevance are Twitter-based studies of regional dialect differences (Eisenstein et al., 2010; Doyle, 2014; Gon\u00e7alves and S\u00e1nchez, 2014; Eisenstein, 2015) and text-based geolocation (Cheng et al.", "startOffset": 180, "endOffset": 265}, {"referenceID": 7, "context": "Twitter has often been used to study the geographical distribution of linguistic information, and of particular relevance are Twitter-based studies of regional dialect differences (Eisenstein et al., 2010; Doyle, 2014; Gon\u00e7alves and S\u00e1nchez, 2014; Eisenstein, 2015) and text-based geolocation (Cheng et al.", "startOffset": 180, "endOffset": 265}, {"referenceID": 15, "context": "Twitter has often been used to study the geographical distribution of linguistic information, and of particular relevance are Twitter-based studies of regional dialect differences (Eisenstein et al., 2010; Doyle, 2014; Gon\u00e7alves and S\u00e1nchez, 2014; Eisenstein, 2015) and text-based geolocation (Cheng et al.", "startOffset": 180, "endOffset": 265}, {"referenceID": 12, "context": "Twitter has often been used to study the geographical distribution of linguistic information, and of particular relevance are Twitter-based studies of regional dialect differences (Eisenstein et al., 2010; Doyle, 2014; Gon\u00e7alves and S\u00e1nchez, 2014; Eisenstein, 2015) and text-based geolocation (Cheng et al.", "startOffset": 180, "endOffset": 265}, {"referenceID": 5, "context": ", 2010; Doyle, 2014; Gon\u00e7alves and S\u00e1nchez, 2014; Eisenstein, 2015) and text-based geolocation (Cheng et al., 2010; Hong et al., 2012; Han et al., 2014).", "startOffset": 95, "endOffset": 152}, {"referenceID": 20, "context": ", 2010; Doyle, 2014; Gon\u00e7alves and S\u00e1nchez, 2014; Eisenstein, 2015) and text-based geolocation (Cheng et al., 2010; Hong et al., 2012; Han et al., 2014).", "startOffset": 95, "endOffset": 152}, {"referenceID": 16, "context": ", 2010; Doyle, 2014; Gon\u00e7alves and S\u00e1nchez, 2014; Eisenstein, 2015) and text-based geolocation (Cheng et al., 2010; Hong et al., 2012; Han et al., 2014).", "startOffset": 95, "endOffset": 152}, {"referenceID": 21, "context": "Recent research shows that accuracies of core language technology tasks such as part-of-speech tagging are correlated with author demographics such as author age (Hovy and S\u00f8gaard, 2015); our results on location prediction are in accord with these findings.", "startOffset": 162, "endOffset": 186}, {"referenceID": 5, "context": ", 2010; Doyle, 2014; Gon\u00e7alves and S\u00e1nchez, 2014; Eisenstein, 2015) and text-based geolocation (Cheng et al., 2010; Hong et al., 2012; Han et al., 2014). This prior work rarely considers the impact of the demographic confounds, or of the geographical biases mentioned in \u00a7 3. Recent research shows that accuracies of core language technology tasks such as part-of-speech tagging are correlated with author demographics such as author age (Hovy and S\u00f8gaard, 2015); our results on location prediction are in accord with these findings. Hovy (2015) show that including author demographics can improve text classification, a similar approach might improve text-based geolocation as well.", "startOffset": 96, "endOffset": 546}, {"referenceID": 6, "context": ", 2012) and public health (Culotta, 2014).", "startOffset": 26, "endOffset": 41}], "year": 2015, "abstractText": "Twitter is often used in quantitative studies that identify geographically-preferred topics, writing styles, and entities. These studies rely on either GPS coordinates attached to individual messages, or on the user-supplied location field in each profile. In this paper, we compare these data acquisition techniques and quantify the biases that they introduce; we also measure their effects on linguistic analysis and textbased geolocation. GPS-tagging and selfreported locations yield measurably different corpora, and these linguistic differences are partially attributable to differences in dataset composition by age and gender. Using a latent variable model to induce age and gender, we show how these demographic variables interact with geography to affect language use. We also show that the accuracy of text-based geolocation varies with population demographics, giving the best results for men above the age of 40.", "creator": "TeX"}}}