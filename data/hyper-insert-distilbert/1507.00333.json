{"id": "1507.00333", "review": {"conference": "arxiv", "VERSION": "v1", "DATE_OF_SUBMISSION": "30-Jun-2015", "title": "Notes on Low-rank Matrix Factorization", "abstract": "low - rank matrix method factorization ( spatial mf ) formulation is potentially an important technique in data science. as the key intuitive idea of mf adaptation is that there exists residual latent structures together in the data, by purposely uncovering which we prefer could instead obtain a less compressed representation possibility of modifying the sensor data. alternatively by simply factorizing an effective original matrix to low - numerical rank matrices, mf provides a unified representation method for inducing dimesion correlation reduction, clustering, correlation and matrix formulation completion. in illustrating this article we review several important variants thinking of mf, ideally including : uniformly basic mf, axial non - negative mf, orthogonal decomposition non - negative mf. as accurate can they be seen from recording their names, non - dual negative tensor mf polynomials and orthogonal domain non - negative mf transforms are derived variants because of basic mf with non - invariant negativity loads and / or orthogonality associated constraints. avoiding such performance constraints are often useful targets in specific senarios. there in the first part of heading this article, whereupon we simply introduce, hence for each segment of these models, the application / scenarios, the distinctive residual properties, artifacts and thereby the optimizing method. by properly scaling adapting square mf, we can actually go beyond the computational problem of clustering and matrix method completion. in the second part of, this article, we will extend euclidean mf to sparse matrix algorithm compeletion, enhance matrix compeletion since using various regularization methods, integrate and finally make sophisticated use of the mf for ( avoiding semi - ) supervised learning lessons by introducing latent generalized space reinforcement models and regression transformation. we tomorrow will obviously see that mf mesh is not really only a useful learning model but rather also as a flexible framework now that effectively is applicable directly for establishing various approximate prediction problems.", "histories": [["v1", "Tue, 30 Jun 2015 20:47:34 GMT  (14kb)", "http://arxiv.org/abs/1507.00333v1", null], ["v2", "Mon, 26 Oct 2015 20:44:46 GMT  (14kb)", "http://arxiv.org/abs/1507.00333v2", null], ["v3", "Fri, 6 May 2016 10:35:36 GMT  (15kb)", "http://arxiv.org/abs/1507.00333v3", null]], "reviews": [], "SUBJECTS": "cs.NA cs.IR cs.LG", "authors": ["yuan lu", "jie yang"], "accepted": false, "id": "1507.00333"}, "pdf": {"name": "1507.00333.pdf", "metadata": {"source": "CRF", "title": "Notes on Low-rank Matrix Factorization", "authors": ["Jie Yang"], "emails": ["j.yang-3@tudelft.nl."], "sections": [{"heading": null, "text": "ar X\niv :1\n50 7.\n00 33\n3v 1\n[ cs\n.N A\n] 3\n0 Ju\nn 20\n15\nNotes on Low-rank Matrix Factorization\nJie Yang\u2217\nFaculty of EEMCS,\nDelft University of Technology,\nMekelweg 4, 2628 CD Delft, the Netherlands.\n\u2217 Email: j.yang-3@tudelft.nl.\nDedicated to Yuanyuan, Xiao Baobao and Tu Daye."}, {"heading": "1 Introduction", "text": "Low-rank matrix factorization (MF) is an important technique in data science. The key idea of MF is that there exists latent structures in the data, by uncovering which we could obtain a compressed representation of the data. By factorizing an original matrix to low-rank matrices, MF provides a unified method for dimesion reduction, clustering, and matrix completion.\nMF has several nice properties: 1) it uncovers latent structures in the data, while addressing the data sparseness problem [11]; 2) it has an elegant probabilistic interpretation [15]; 3) it can be easily extended with domain specific prior knowledge (e.g., homophily in linked data [19]), thus suitable for various real-world problems; 4) many optimization methods such as (stochastic) gradient-based methods can be applied to find a good solution.\nIn this article we review several important variants of MF, including:\n\u2022 Basic MF,\n\u2022 Non-negative MF,\n\u2022 Orthogonal non-negative MF.\nAs can be seen from their names, non-negativeMF and orthogonal non-negative MF are variants of basic MF with non-negativity and/or orthogonality constraints. Such constraints are useful in specific senarios. In the first part of this article, we introduce, for each of these models, the application scenarios, the distinctive properties, and the optimizing method. Note that for the optimizing method, we mainly use the alternative algorithm, as similar to [4, 19]. We will derive the updating rules, and prove the correctness and convergence. For reference, matrix operation and optimization can be referred to [2] and [1] respectively.\nBy properly adapting MF, we can go beyond the problem of clustering and matrix completion. In the second part of this article, we will extend MF to sparse matrix compeletion, enhance matrix compeletion using various regularization methods, and make use of MF for (semi-)supervised learning by introducing latent space reinforcement and transformation. We will see that MF is not only a useful model but also as a flexible framework that is applicable for various prediction problems."}, {"heading": "2 Theory", "text": "This section introduces the theory in low-rank matrix factorization. As introduced before, we will go through the following three MF variations: basic MF, non-negative MF, orthogonal non-negative MF."}, {"heading": "2.1 Basic MF", "text": "We start with the basic MF model, formulated as\nmin U,V\n\u2016X\u2212UVT \u2016+ L(U,V), (1)\nwhere X \u2208 Rm\u00d7n is the data matrix to be approximated, and U \u2208 Rm\u00d7k,V \u2208 R\nn\u00d7k are two low-dimensional matrices (k \u226a min(m,n)). L(U,V) is a regularization part to avoid overfitting. Regularization is usually necessary in prediction for bias-variance trade-off [9]."}, {"heading": "2.1.1 Gradient Descent Optimization", "text": "We instantiate Eq. 1 as follows\nmin U,V\nO = \u2016X\u2212UVT \u20162F + \u03b1\u2016U\u2016 2 F + \u03b2\u2016V\u2016 2 F . (2)\nThe reason of using Frobenius Norm is that it has a Guassian noise interpretation, and that the objective function can be easily transformed to a matrix trace version:\nmin U,V\nO = Tr(XTX+VUTUVT \u2212 2XTUVT )+\u03b1Tr(UTU)+\u03b2Tr(VTV). (3)\nHere the matrix calculation rule \u2016A\u2016F = \u221a\nTr(ATA) is used in the transformation. Note that trace has many good properties such as Tr(A) = Tr(AT ) and Tr(AB) = Tr(BA), which will be used in the following derivations.\nAccording to trace derivatives \u2202Tr(AB)\u2202A = B T and the following rules:\n\u2202ATAB\n\u2202A = A(BT +B),\n\u2202AATB\n\u2202A = (BT +B)A\n(4)\n(see more in [2]), we have the following derivatives for U and V,\n\u2202O \u2202U =\n\u2202Tr(VUTUVT \u2212 2XTUVT ) + \u03b1Tr(UTU)\n\u2202U\n= \u2202Tr(UTUVTV \u2212 2UVTXT ) + \u03b1Tr(UTU)\n\u2202U\n= 2(UVTV \u2212XV + \u03b1U),\n\u2202O \u2202V =\n\u2202Tr(VUTUVT \u2212 2XTUVT ) + \u03b2Tr(VTV)\n\u2202V\n= \u2202Tr(VTVUTU\u2212 2VTXTU) + \u03b2Tr(VTV)\n\u2202V\n= 2(VUTU\u2212XTU+ \u03b2V).\n(5)\nUsing these two derivatives, we can alternatively update U and V in each iteration of gradient descent algorithm.\nNote that the derivation can also be performed elementarily for each entry in matrix U,V \u2013 this is, in fact, the original definition of matrix calculus. Such element-wise derivation is especially useful in stochastic optimization. We will touch this in a brief discussion of different algorithm schemes next."}, {"heading": "2.1.2 Algorithm Schemes in CF and Others", "text": "For collaborative filtering, usually we take one subset of rated entries in X as training set, and the rest rated entries as validation set. Detailed algorithm can be find in [18]. An important implementation strategy is that, for each rated entry in the training set, we update an entire row of U and an entire column of VT , as the whole row or column is involved in approximating the rated entry. Same updating mechanism could be applied in stochastic algorithm.\nIn the meanwhile, similarly to stochastic algorithm, this type of updating does not fully utilize the data matrix in each updating iteration. The reason is that, not only an entire row of U ( and a column of VT ) is involved in a single entry in data matrix X, but also that a row of U (and a column of VT ) influences an entire row (column) of X. Therefore for faster convergence, we recommend to update the matrix U and V by fully using data matrix X.\nAs the objective function is non-convex caused by the coupling between U and V, we can choose to alternatively update U and V in each iteration as in [4, 19]. Detailed algorithm is similar to the one in [19]. Within any of these matrices, updating should be performed simultaneously as in all gradient-based methods. Note that, we still need to choose a small learning rate to ensure that the objective function is monotonically decreasing. Interestingly, the alternative optimization scheme is even more suitable for non-negative MF [13, 14, 5, 4], as we will see in the following subsections."}, {"heading": "2.2 Non-negative MF", "text": "Non-negativeMF [13] seeks to approximate data matrixXwith low-dimensional matrices U,V whose entries are all non-negative, i.e., U,V \u2265 0. The new problem becomes:\nmin U,V\nO = \u2016X\u2212UVT \u20162F + \u03b1\u2016U\u2016 2 F + \u03b2\u2016V\u2016 2 F\ns.t. U \u2265 0,V \u2265 0. (6)\nNon-negativity constaint is originated from parts-of-whole interpretation [13]. As we can think of, many real-world data are non-negative, such as link strength, favorite strength, etc. Non-negative MF may uncover the important parts, which sometimes can not be achieved by non-constrained MF [13].\nApart from the advantage of uncovering parts, non-negative MF has its own computational advantage: there is a relatively fixed method to find a learning\nrate larger than common gradient-based methods. To illustrate this, we will first derive the updating rule for Eq. 6 as an example, then show the general approach for proving the convergence of updating rules derived from the relatively fixed method."}, {"heading": "2.2.1 Updating Rule Derivation", "text": "The basic idea is using KKT complementary slackness conditions to enforce the non-negativity constraint. Based on this, we can directly obtain updating rules.\nThe Lagrangian function of Eq. 6 is\nL = \u2016X\u2212UVT \u20162F + \u03b1\u2016U\u2016 2 F + \u03b2\u2016V\u2016 2 F \u2212 Tr(\u039b1U T )\u2212 Tr(\u039b2V T ). (7)\nWe have the following KKT condition,\n\u039b1 \u25e6U = 0, \u039b2 \u25e6V = 0, (8)\nwhere \u25e6 denotes the Hadamard product. We then have\n\u2202L \u2202U =\n\u2202Tr(VUTUVT \u2212 2XTUVT ) + \u03b1Tr(UTU)\u2212 Tr(\u039b1U T )\n\u2202U\n= 2(UVTV \u2212XV + \u03b1U)\u2212 \u039b1,\n\u2202L \u2202V =\n\u2202Tr(VUTUVT \u2212 2XTUVT ) + \u03b2Tr(VTV)\u2212 Tr(\u039b2V T )\n\u2202V\n= 2(VUTU\u2212XTU+ \u03b2V) \u2212 \u039b2.\n(9)\nLet \u2202L\u2202U = 0 and \u2202L \u2202V = 0 as another KKT condition, we have\n\u039b1 = 2(UV TV \u2212XV + \u03b1U), \u039b2 = 2(VU TU\u2212XTU+ \u03b2V).\n(10)\nNow we combine Eq. 8 and Eq. 10, we have\n(UVTV \u2212XV + \u03b1U) \u25e6U = 0,\n(VUTU\u2212XTU+ \u03b2V) \u25e6V = 0. (11)\nfrom which, we have the final updating rules,\nU(i, j) \u2190 U(i, j)\n\u221a\n(XV)(i, j)\n(UVTV + \u03b1U)(i, j) ,\nV(i, j) \u2190 V(i, j)\n\u221a\n(XTU)(i, j)\n(VUTU+ \u03b2V)(i, j) .\n(12)\nDetailed algorithm using these rules is similar to the one in [19]. We can see that, instead of manually setting small learning rates \u039b\u2019s, Eq. 12 directly offer updating rules that can usually lead to faster convergence.\nThe correctness of these updating rules is straightforward to find out. Taking U as an example, from Eq. 12 we have either U = 0 or UVTV\u2212XV+\u03b1U = 0, which combined together, exactly equal to Eq. 11. The convergence, however, is somehow more difficult to be proved. We leave this to the next subsubsection."}, {"heading": "2.2.2 Proof of Convergence", "text": "We prove the convergence of the updating rules in Eq. 12 with the standard auxiliary function approach, which is proposed in [14] and extended in [5, 4]. Our proof is mainly based on [5, 4], although the objective function Eq. 6 is slightly different.\nAn auxiliary function G(U,Ut) of function L(U) is a function that satisfies\nG(U,U) = L(U), G(U,Ut) \u2265 L(U). (13)\nThen, if we take Ut+1 such that\nUt+1 = arg min U G(U,Ut), (14)\nwe have L(Ut+1) \u2264 G(Ut+1,Ut) \u2264 G(Ut,Ut \u2264 L(Ut)). (15)\nThis proves that L(U) is monotonically decreasing. Turn back to our problem, we need to take two steps using auxiliary function to prove the convergence of updating rules: 1) find an appropriate auxiliary function, and 2) find the global minima of the auxiliary function. As a remark, the auxiliary function approach in principle is similar to Expectation-Maximization approach that is widely used in statistical inference. Now let us complete the proof by taking the above two steps.\nStep 1 - Finding an appropriate auxiliary function needs to take advantage of two inequalities,\nz \u2265 1 + logz, \u2200z > 0, (16)\nm \u2211\ni=1\nk \u2211\nj=1\n(AS\u2032B)(i, j)S(i, j)2\nS\u2032(i, j) \u2265 Tr(STASB),\n\u2200A \u2208 Rm\u00d7m+ ,B \u2208 R k\u00d7k + ,S \u2032 \u2208 Rm\u00d7k+ ,S \u2208 R m\u00d7k + . (17)\nThe proof for Eq. 17 can be found in [5] (Proposition 6). After removing irrelevant terms, the objective function Eq. 6 in terms of U\ncan be written as\nTr(VUTUVT \u2212 2XTUVT ) + \u03b1Tr(UTU)\n=Tr(UTUVTV \u2212 2UTXV) + \u03b1Tr(UTU) (18)\nWe now propose an auxiliary function\nG(U,Ut) = \u22122 \u2211\ni,j\n(XV)(i, j)Ut(i, j)(1 + log U(i, j)\nUt(i, j) )\n+ \u2211\ni,j\n(UtVTV)(i, j)U(i, j)2\nUt(i, j) + \u03b1\n\u2211\ni,j\nUt(i, j)U(i, j)2\nUt(i, j) .\n(19)\nCombining the two inequalities Eq. 16, 17, it is straightforward to see that Eq. 19 is a legal auxiliary function for Eq. 18, i.e., the two conditions in Eq. 13 are satisfied. Now we procceed to find Ut+1 that satisfies condition Eq. 14.\nStep 2 - Finding Ut+1 can be achieved by obtaining the global minima of Eq. 19. First, we have\n\u2202G(U,Ut)\n\u2202U(i, j) = \u22122(XV)(i, j)\nUt(i, j) U(i, j) + 2 (UtVTV)(i, j)U(i, j) Ut(i, j) + 2\u03b1U(i, j).\n(20)\nLet \u2202G(U,U t)\n\u2202U(i,j) = 0 we have\n(XV)(i, j) Ut(i, j)\nUt+1(i, j) = (\n(UtVTV)(i, j)\nUt(i, j) + \u03b1)Ut+1(i, j), (21)\nfrom which we directly have\nUt+1(i, j) = Ut(i, j)\n\u221a\n(XV)(i, j)\n(UtVTV + \u03b1Ut)(i, j) , (22)\nwhich is exactly the updating rule for U in Eq. 12. Similar result can be obtained for V.\nGeneral observation If we go over the entire derivation process, by comparing Eq. 22 and Eq. 11, we can observe that the only thing that matters for the final updating rules is the signs of the terms in Eq. 11."}, {"heading": "2.3 Orthogonal Non-negative MF", "text": "Orthogonality is another important constraint to MF. First of all, we formulate the problem as\nmin U,V\nO = \u2016X\u2212UVT \u20162F\ns.t. U,V \u2265 0,UTU = I,VTV = I. (23)\nNote that here we do not add regularization due to the orthogonality constraint.\nIt is proved in [3, 5] ([5] gives more mature proof) that this problem is equivalent to K-means clustering: V\u2032 is an indication matrix with V\u2032(i, j) = 0 if xi belongs to the j th (1 \u2264 j \u2264 k) cluster. Here V = V\u2032(V\u2032 T V\u2032)\u22121/2, i.e., V is a normalized version of V\u2032: V\u2032 is a constant scaling of corresponding row of V, and \u2016V(:, j)\u201622 = 1."}, {"heading": "2.3.1 3-factor MF vs. 2-factor MF", "text": "We call Eq. 23 1-sided 2-factor orthogonal non-negative MF, as only one factorized matrix needs to be orthogonal, and there are in total two factorized matrices. It is recommended that, to simultaneously cluster rows and columns in X, we need 3-factor bi-orthogonal non-negative MF, i.e., both U and V being orthogonal:\nmin U,H,V\nO = \u2016X\u2212UHVT \u20162F\ns.t. U,H,V \u2265 0,UTU = I,VTV = I. (24)\nIt is proved that, compared to 3-factor bi-orthogonal non-negative MF, 2- factor bi-orthogonal non-negative MF is too restrictive, and will lead to poor approximation [5].\n3-factor bi-orthogonal non-negative MF is useful in document-word clustering [5], outperforming K-means (i.e., 1-sided 2-factor orthogonal non-negative MF). It has been applied for tasks such as sentiment analysis [10]."}, {"heading": "2.3.2 Updating Rule Derivation", "text": "We now derive updating rules for Eq. 24, as we did before for non-negative MF.\nThe Lagrangian function for Eq. 24 is\nL =\u2016X\u2212UHVT \u20162F \u2212 Tr(\u039bUU T )\u2212 Tr(\u039bHH T )\u2212 Tr(\u039bV V T )\n+Tr(\u0393U (U TU\u2212 I)) + Tr(\u0393V (V TV \u2212 I)) (25)\nWe then compute the updating rules for H,U,V sequentially. Computation of H\n\u2202L \u2202H =\n\u2202Tr(VHTUTUHVT \u2212 2XVHTUT )\u2212 Tr(\u039bHH T )\n\u2202H\n= 2UTUHVTV \u2212 2UTXV \u2212 \u039bH ,\n(26)\nWe have the following KKT conditions,\n\u2202L \u2202H = 0\n\u039bH \u25e6H = 0. (27)\nCombining the above three equations, we have\n(UTUHVTV \u2212UTXV) \u25e6H = 0. (28)\nTherefore we have the following updating rule for H,\nH(i, j) \u2190 H(i, j)\n\u221a\n(UTXV)(i, j)\n(UTUHVTV)(i, j) . (29)\nNote that UTU 6= I during the optimizing process. Computation of U,V Due to the orthogonality constraint, obtaining the updating rules for U,V needs to eliminate both \u039b and \u0393 in the final updating rules. This will need the following equality,\nUT\u039bU = 0 \u21d0 \u039bU \u25e6U = 0 (30)\nThe latter will automatically be satisifed according to KKT conditions as we will see below.\n\u2202L \u2202U =\n\u2202Tr(VHTUTUHVT \u2212 2XVHTUT )\u2212 Tr(\u039bUU T ) + Tr(\u0393U (U TU\u2212 I))\n\u2202U\n= 2UHVTVHT \u2212 2XVHT \u2212 \u039bU + 2U\u0393U ,\n(31)\nWe have the following KKT conditions,\n\u2202L \u2202U = 0\n\u039bU \u25e6U = 0. (32)\nCombining the above three equations we have\n(UHVTVHT \u2212XVHT +U\u0393U ) \u25e6U = 0 (33)\nand\n\u0393U = U TXVHT \u2212HVTVHT . (34)\nNote that here we can have UTU = I as we only want an expression for \u0393U . Further note that for \u039b we have the constraint \u039b > 0 (according to KKT condition) while for \u0393 we do not have such constraint. Therefore we need to split \u0393 into two parts,\n\u0393U = \u0393 + U \u2212 \u0393 \u2212 U \u0393+U = (|\u0393U |+ \u0393U )/2 \u0393\u2212U = (|\u0393U | \u2212 \u0393U )/2.\n(35)\nUsing this division we rewrite Eq. 33, we then have\n(UHVTVHT \u2212XVHT +U\u0393+U \u2212U\u0393 \u2212 U ) \u25e6 \u039bU = 0. (36)\nTherefore the final updating rule for U is\nU(i, j) \u2190 U(i, j)\n\u221a\n(XVHT +U\u0393\u2212U )(i, j)\n(UHVTVHT +U\u0393+U )(i, j) . (37)\nwhere \u0393+U and \u0393 \u2212\nU is defined in Eq. 34 and 35. If we go over the same process again for V, we have the following updating\nrules, Therefore the final updating rule for U is\nV(i, j) \u2190 V(i, j)\n\u221a\n(XTUH+V\u0393\u2212V )(i, j)\n(VHTUTUH+V\u0393+V )(i, j) . (38)\nwhere \u0393+V ,\u0393 \u2212\nV are defined similarly as in Eq. 35 (replace U with V), and \u0393V is defined as\n\u0393V = V TXTUH+HTUTUH. (39)\nChoice of 2/3-factor MF How do we choose between 2-factor or 3-factor MF in real-world applications? A general principle is that: if we only need to place regularizations on one latent matrix, i.e. either U or V, then we can use 2-factorMF; if both U and V are to be regularized, either explictly or implictly, 3-factor MF might be a better choice."}, {"heading": "3 Adapatations and Applications", "text": "MF has been used for a wide range of applications in social computing, including collaborative filtering (CF), link prediction (LP), sentiment analysis, etc. It can not only provide as a single model for matrix completeion or clutering, but also as a framework for solving almost all categories of prediction problems.\nIn this part we will extend MF to highly sparse cases. For the cases in which we have additional data, e.g. link data between users (in CF, or addtional links in LP) or description data of users and items, we can incorporate different regularization techniques to enhace the matrix completion performance. Moreover, by properly manipulating latent factors derived from MF, we can adapt MF to (semi-)supervised learning."}, {"heading": "3.1 Sparse Matrix Completion", "text": "Here we address the problem of using MF for collborative filtering, link prediction and clustering. We start with a basic assumption, which makes the\npreviously introduced models unsuitable. This basic assumption is: high portion of the data is missing, i.e. data matrix is incomplete. Such assumption is very common in real-world cases [12].\nThe problem is solved by modeling directly the observed data. Eq. 1 is modified as follows:\nmin U,V\nO = \u2016O \u25e6 (X\u2212UV T )\u20162F + \u03b1\u2016U\u2016 2 F + \u03b2\u2016V\u2016 2 F , (40)\nin which O poses constraints on only these observed data entries, i.e. O(i, j) = 1 if entry (i, j) is observed, and O(i, j) = 0 otherwise.\nIn this case, the objective function is transformed as follows:\nmin U,V\nO = Tr((OT \u25e6XT )(O \u25e6X) + (OT \u25e6VUT )(O \u25e6UVT )\n\u2212 2(OT \u25e6XT )(O \u25e6UVT )) + \u03b1Tr(UTU) + \u03b2Tr(VTV). (41)\nAnd the gradients become:\n\u2202O \u2202U =\n\u2202Tr((OT \u25e6VUT )(O \u25e6UVT )\u2212 2(OT \u25e6XT )(O \u25e6UVT )) + \u03b1Tr(UTU)\n\u2202U\n= \u2202Tr(UT (O \u25e6O \u25e6UVT )V \u2212 2(OT \u25e6OT \u25e6XT )UVT ) + \u03b1Tr(UTU)\n\u2202U\n= 2((O \u25e6O \u25e6UVT )V \u2212 (O \u25e6O \u25e6X)V + \u03b1U),\n\u2202O \u2202V = 2((OT \u25e6OT \u25e6VUT )U\u2212 (OT \u25e6OT \u25e6XT )U+ \u03b2V).\n(42)\nIn the derivation above we use the following rule of Hadamard product:\n(OT \u25e6AT )(O \u25e6A) = AT (O \u25e6O \u25e6A). (43)\nThe upodating rules for non-negative MF and orthogonal non-negative MF is straightforward: the methods of getting \u039b,\u0393 are exactly the same as what we did in Theory Section. For updating rules of non-negative MF and orthogonal non-negative MF, the reader can refer to [7] and [8], respectively."}, {"heading": "3.1.1 Calculating Memory Occupation", "text": "Note that the updating rules above are again purely matrix-wise \u2013 this is to be consistent with the style of this article. In matrix completion, however, sometimes the size of the data matrix is bigger than memory size, making stochasitc gradient descent algorithm more suitable than the matrix-wise method.\nThe question here is, how do we calculate the size of a matrix to see if it fits to memory. Here is a easy way to make such a calculation. Assume we have a 10K \u00d7 10K matrix, with each entry allocated a 32bit float (e.g. float32 in python), then the memory allocation for the whole matrix can be roughtly calculated as\n(104 \u00d7 104 \u00d7 4)/106 = 400M.\nSo for a computer with 4G memory, we can fit a matrix 100K\u00d7 10K matrix into memory. For a computer with 32G memory, we can fit a matrix of size 100K \u00d7 80K (10\u00d7 8\u00d7 400M = 32G)."}, {"heading": "3.2 Enhanced Matrix Completion", "text": "We looked atMF with different constraints, e.g. non-negativity and orthogality, and one type of regularization which prevents the entries in low-rank matrices being too large. This subsection considers other kinds of regularization when external data source becomes avaiable, i.e. goes beyond the data matrix X. Usually this is the real-world case, since most social media data contains rich data sources.\nIn this subsection we consider two types of regularization with corresponding addtional data:\n1. self-regularization when we have additional linked data between users (in CF, or addtional link type in LP);\n2. 2-sided regularization when we have description data of users and items.\nWe further point to two publications [19] and [8], to demonstrate the above two types of regularization, respectively."}, {"heading": "3.2.1 Enhancing Matrix Completion with Self-regularization", "text": "By self-reguarization, we refer to the regularization of rows in low-rank matrix U or V. Assume now we are dealing with a LP problem, in which we would like to predict if a user trust another \u2013 trust relation are common in review sites like Epinions. Usually there exist another type of links between users, i.e. social relation. Can we use social relation to boost the performance of trust relation prediction? This is exactly the research question proposed in [19].\nIt turns out the answer is yes \u2013 as expected, users with social relation tend to share similar preferences. The basic idea to incorporate this into trust prediction is by adding the regularization term Eq. 44 into the general MF framework. In Eq. 44, \u03be is the entries in the additional link matrix Z and D is the diagonal matrix with D(i, i) = Zmj=1(j, i), thus L is the Laplacian matrix of D. It is interesting that, using trace operator, the regularization Eq. 44 become such simple.\nSocial relation is common in social computing, the similarity in people with social relation has a specific name in social theory - \u2018homophily\u2019, making this type of regularization applicable to a lot of social computing scenarios. If we generalize a bit, we may assume that many linked objects, not necessarily web users, have similarities, in terms of their entries of data matrix X that we would like to predict. For instance, while predicting the sentiment of articles, we may assume that articles authored by the same users tend to express similar sentiment, e.g. political reviewers expressing negative sentiment in their news\nreviewing articles. We will see that this type of regularization is used in a sentiment analysis paper [10], which we will analyze later.\n1\n2\nm \u2211\ni=1\nm \u2211\nj=1\n\u03be(i, j)\u2016U(i, :)\u2212U(j, :)\u201622\n= 1\n2\nm \u2211\ni=1\nm \u2211\nj=1\nk \u2211\nd=1\n\u03be(i, j)(U(i, k)\u2212U(j, k))2\n= 1\n2\nm \u2211\ni=1\nm \u2211\nj=1\nk \u2211\nd=1\n\u03be(i, j)(U2(i, k)\u2212 2U(i, k)U(j, k) +U2(j, k))\n= m \u2211\ni=1\nm \u2211\nj=1\nk \u2211\nd=1\n\u03be(i, j)U2(i, k)\u2212 m \u2211\ni=1\nm \u2211\nj=1\nk \u2211\nd=1\n\u03be(i, j)U(i, k)U(j, k)\n=\nk \u2211\nd=1\nUT (:, k)(D\u2212Z)U(:, k)\n=Tr(UTLU)\n(44)\nRegularization and Sparseness More regularization sometimes can conquer the data sparsity problem, to some extent. On the other hand, modelling the error only on observed data entries, as what O does in previous subsection, could be also very effective."}, {"heading": "3.2.2 Enhancing Matrix Completion with 2-sided regularization", "text": "Here we consider placing regularization on both U and V together, which we call 2-sided regularization.\nBefore we start, we review orthogonal non-negative MF a bit. Orthogonality constraint in orthogonal non-negative MF is similar to a 2-sided regularization:\nTr(\u0393TU (U TU\u2212 I)), T r(\u0393TV (V TV \u2212 I))\nare two equality constraints over low-rank matrices. Such equality needs to be strictily satisfied. Regularization, differing from constraints, however can be viewed as a soft type of constraints: it only needs to be satisfied to some extend, while constraints need to be strictly satisified. This is the reason why we consider non-negativity and orthogonality constraints, while call homophily regularization.\nNow let us turn our attention back to 2-sided regularization, basing the example from [8], which considers POI recommendation in location-based social network (LBSN). The first data we have is a check-in data X that encodes the interaction between users and POI\u2019s. We are further given some desription data A of user interest, and B of POI property, both in the form of word vectors.\nQuestion here is, how do we make use of A and B to enhance the matrix completion problem for interacting matrix X?\nSince we are coping with 2-sided regularization, we use 3-factor MF:\nmin U,H,V\nO = \u2016X\u2212UHVT \u20162F \u2212 Tr(\u039bUU T )\u2212 Tr(\u039bHH T ) +R\u2032s. (45)\nThe only thing here is, how to add the 2-sided regularization terms R\u2019s, as we did for orthogonality constraints.\nTo utilize A and B, we assume that there are some connections between them, such that they can be used to regularize U and V. In the context of LBSN, we may assume that A and B have similar vocabulary, in which the words have similar latent space. Therefore we can approximate A and B with 2-factor MF:\nA \u2248 UGT ,B \u2248 VG\u2217T (46)\nwith connection \u2016G\u2212G\u2217\u20161 \u2248 0. (47)\nEq. 47 is important since it really connect U with V, forming a 2-sided regularization. The final objective function now becomes:\nmin U,H,V\nO = \u2016X\u2212UHVT \u20162F \u2212 Tr(\u039bUU T )\u2212 Tr(\u039bHH T )\n+ \u03bbA\u2016A\u2212UG T \u20162F + \u03bbB\u2016B\u2212UG \u2217T \u20162F + \u03b4\u2016G\u2212G \u2217\u20161 + \u03b1(\u2016U\u20162F + \u2016V\u2016 2 F + \u2016H\u2016 2 F + \u2016G\u2016 2 F ).\n(48)\nThe last line is to regularize in approximating A,B; note that since here we use regularization, instead of constraints as in non-negative orthogonal MF, we can add regualrization to U,V,H.\nFactorization vs. Regularization We remark here that the idea of cofactoring two matrices (X,A) with shared factors (U) originates from collective matrix facterization [17], which has many applications in CF [16]. A interesting comparative study between collective facterization and self-regularization can be found in [20]."}, {"heading": "3.3 From Clustering to (Semi-)supervised Learning", "text": "Although different type of extra data is used in enhanced MF, the purpose remains to be matrix completion. This subsection, however, considers other types of machine learning problems, i.e. (semi-)supervised learning. The essential assumption of using MF for (semi-)supervised learning is that the latent row(column) is predictable for some response.\nTo make use of the predictability, we need mechanisms to connect the latent vectors to responses. Following are the two mechanisms:\n1. reinforcement directly enforce the latent space to be the response space;\n2. transformation transform the latent space to response space. This is similar as what people do in machine learning.\nWe point to publications [10] and [6] for the demonstration of the above two methods, respectively."}, {"heading": "3.3.1 Enforcing Latent Factor to be Response", "text": "In previous regularizations, we do not force the latent space to be interpretable space. For instance, in the 2-sided regularization, we do not specify the meaning of U that is used in both X and A factorization. However, (un,semi-)supervised learning requires the latent space to be interpretable. The method, still, is regularization.\n[10] deals with the problem of sentiment analysis, for which the authors use 3-factor non-negative orthogonal MF. The input is a post-word matrix X. In addition, we are given emotion indication in some of the posts. \u201cThe key idea of modeling post-level emotion indication is to make the sentiment polarity of a post as close as possible to the emotion indication of the post.\u201d, formulated as\nGu\u2016U\u2212U0\u2016 2 F ,\nin which U \u2208 Rm\u00d72 is the post-sentiment matrix, i.e. U(i, :) = (1, 0) representing that the ith post has a positive sentiment, and U0 \u2208 R\nm\u00d72 is the post-emotion indication matrix, i.e. U0(i, :) = (1, 0) meaning the ith post contains positive emotion indication. Similar regularization is applied to V as well.\nSuch an idea is quite simple, however it explictly poses a notable question: is it computationally feasible that we strictly enforce the U,V to any pre-defined space, i.e. sentiment space in this case. Based on Proposition 1 in [5], we know that the answer is no. However, as we see in this sentiment analysis work [10], regularization is always possible!\nIn fact, the enforcement regularization that we see in this work is the most constrained regularization: it is 2-sided regularization for both U,V, and it is enforcement without any transformation coefficients. We will see next how to regularize for supervised learning by tranformation."}, {"heading": "3.3.2 Transforming Latent Factor to Response", "text": "As we pointed out, the essential idea of supervised learning is to transform the latent variables to some response variable. To see this, we start directly with the application of [6]. We would like to model a user\u2019 attitude towards some controversial topic, reflected by his opinion, sentiment and retweeting action. We are given a retweeting matrix X representing users\u2019 retweeting action to some tweets, and we would like to predict users\u2019 opinion O and sentiment P, and the task is to predict these three variables given the user feature F.\nWe first introduce how the model is built in [6], then discuss other alternatives. To train such a model, the authors propose the following model\nmin W,V\nO = \u2016X\u2212 (FWT )VT \u20162F + \u03bb1\u2016FW T \u2212O\u20162F + \u03bb2\u2016(FW T )S\u2212P\u20162F\n+ \u03bb3\u2016W\u20161 + \u03b1\u2016W\u2016 2 F + \u03b2\u2016V\u2016 2 F + \u03b3\u2016S\u2016 2 F \u2212 Tr(\u039b1U T )\u2212 Tr(\u039b2V T ),\n(49)\nin which \u03bb1\u2016FW T \u2212O\u20162F and \u03bb3\u2016W\u20161 models opinion from the user feature by bringing in the classical linear regression model lasso. We can see that modelling the sentiment is also straightforward: \u03bb2\u2016FW\nTS\u2212P\u20162F simply transfers again the user feature with a linear transformation S. The retweeting matrix X, similarily, also using FWT as the latent vectors.\nTo summarize, the model Eq. 49 bases the prediction of retweeting action, opinion and sentiment all on the user feature. If we make \u03bb1 to be infinitely large, meaning that we enforce FWT = O, we can see that in fact, X \u2248 OVT and OS \u2248 P. Such choice is based on the assumption that opinion drives both the retweeting action and sentiment.\nModel Eq. 49 is an unified model, in the sense that the subtask of matrix completion, supervised learning are fused together, by basing all prediction on user feature transformation. What if we are not given the use feature information, instead, we directly model the relation between retweeting action, opinion and sentiment. A straightforward model could be\nmin U,V\nO = \u2016X\u2212UVT \u20162F + \u03bb1\u2016U\u2212O\u2016 2 F + \u03bb2\u2016US\u2212P\u2016 2 F\n+ \u03b1\u2016U\u20162F + \u03b2\u2016V\u2016 2 F + \u03b3\u2016S\u2016 2 F \u2212 Tr(\u039b1U T )\u2212 Tr(\u039b2V T ).\n(50)\nIn this model, the relation between the three response variable is more clearly shown. Futhermore, the difference between reinforcement and transformation is also straightforward: \u03bb1\u2016U \u2212 O\u2016 2 F is reinforcement, while \u03bb2\u2016US \u2212 P\u2016 2 F is transformation."}], "references": [{"title": "The matrix reference manual", "author": ["Mike Brookes"], "venue": "Imperial College London,", "citeRegEx": "2", "shortCiteRegEx": "2", "year": 2005}, {"title": "On the equivalence of nonnegative matrix factorization and spectral clustering", "author": ["Chris Ding", "Xiaofeng He", "Horst D Simon"], "venue": "In SDM\u201905,", "citeRegEx": "3", "shortCiteRegEx": "3", "year": 2005}, {"title": "Nonnegative matrix factorization for combinatorial optimization: Spectral clustering, graph matching, and clique finding", "author": ["Chris Ding", "Tao Li", "Michael I Jordan"], "venue": "In ICDM\u201908,", "citeRegEx": "4", "shortCiteRegEx": "4", "year": 2008}, {"title": "Orthogonal nonnegative matrix t-factorizations for clustering", "author": ["Chris Ding", "Tao Li", "Wei Peng", "Haesun Park"], "venue": "In KDD\u201906,", "citeRegEx": "5", "shortCiteRegEx": "5", "year": 2006}, {"title": "Modeling user attitude toward controversial topics in online social media", "author": ["Huiji Gao", "Jalal Mahmud", "Jilin Chen", "Jeffrey Nichols", "Michelle Zhou"], "venue": "In ICWSM\u201914,", "citeRegEx": "6", "shortCiteRegEx": "6", "year": 2014}, {"title": "Exploring temporal effects for location recommendation on location-based social networks", "author": ["Huiji Gao", "Jiliang Tang", "Xia Hu", "Huan Liu"], "venue": "In RecSys\u201913,", "citeRegEx": "7", "shortCiteRegEx": "7", "year": 2013}, {"title": "Content-aware point of interest recommendation on location-based social networks", "author": ["Huiji Gao", "Jiliang Tang", "Xia Hu", "Huan Liu"], "venue": "In AAAI\u201915,", "citeRegEx": "8", "shortCiteRegEx": "8", "year": 2015}, {"title": "The elements of statistical learning", "author": ["Trevor Hastie", "Robert Tibshirani", "Jerome Friedman"], "venue": null, "citeRegEx": "9", "shortCiteRegEx": "9", "year": 2009}, {"title": "Unsupervised sentiment analysis with emotional signals", "author": ["Xia Hu", "Jiliang Tang", "Huiji Gao", "Huan Liu"], "venue": "In WWW\u201913,", "citeRegEx": "10", "shortCiteRegEx": "10", "year": 2013}, {"title": "Factorization meets the neighborhood: a multifaceted collaborative filtering model", "author": ["Yehuda Koren"], "venue": "In KDD\u201908,", "citeRegEx": "11", "shortCiteRegEx": "11", "year": 2008}, {"title": "Matrix factorization techniques for recommender systems", "author": ["Yehuda Koren", "Robert Bell", "Chris Volinsky"], "venue": null, "citeRegEx": "12", "shortCiteRegEx": "12", "year": 2009}, {"title": "Learning the parts of objects by non-negative matrix factorization", "author": ["Daniel D Lee", "H Sebastian Seung"], "venue": null, "citeRegEx": "13", "shortCiteRegEx": "13", "year": 1999}, {"title": "Algorithms for non-negative matrix factorization", "author": ["Daniel D Lee", "H Sebastian Seung"], "venue": "In NIPS\u201901,", "citeRegEx": "14", "shortCiteRegEx": "14", "year": 2001}, {"title": "Probabilistic matrix factorization", "author": ["Andriy Mnih", "Ruslan Salakhutdinov"], "venue": "In NIPS\u201907,", "citeRegEx": "15", "shortCiteRegEx": "15", "year": 2007}, {"title": "Collaborative filtering beyond the user-item matrix: A survey of the state of the art and future challenges", "author": ["Yue Shi", "Martha Larson", "Alan Hanjalic"], "venue": "ACM Computing Surveys (CSUR),", "citeRegEx": "16", "shortCiteRegEx": "16", "year": 2014}, {"title": "Relational learning via collective matrix factorization", "author": ["Ajit P Singh", "Geoffrey J Gordon"], "venue": "In KDD\u201908,", "citeRegEx": "17", "shortCiteRegEx": "17", "year": 2008}, {"title": "Matrix factorization and neighbor based algorithms for the netflix prize problem", "author": ["G\u00e1bor Tak\u00e1cs", "Istv\u00e1n Pil\u00e1szy", "Botty\u00e1n N\u00e9meth", "Domonkos Tikk"], "venue": "In RecSys\u201908,", "citeRegEx": "18", "shortCiteRegEx": "18", "year": 2008}, {"title": "Exploiting homophily effect for trust prediction", "author": ["Jiliang Tang", "Huiji Gao", "Xia Hu", "Huan Liu"], "venue": "In WSDM\u201913,", "citeRegEx": "19", "shortCiteRegEx": "19", "year": 2013}, {"title": "Factorization vs. regularization: fusing heterogeneous social relationships in top-n recommendation", "author": ["Quan Yuan", "Li Chen", "Shiwan Zhao"], "venue": "In Recsys\u201911,", "citeRegEx": "20", "shortCiteRegEx": "20", "year": 2011}], "referenceMentions": [{"referenceID": 9, "context": "MF has several nice properties: 1) it uncovers latent structures in the data, while addressing the data sparseness problem [11]; 2) it has an elegant probabilistic interpretation [15]; 3) it can be easily extended with domain specific prior knowledge (e.", "startOffset": 123, "endOffset": 127}, {"referenceID": 13, "context": "MF has several nice properties: 1) it uncovers latent structures in the data, while addressing the data sparseness problem [11]; 2) it has an elegant probabilistic interpretation [15]; 3) it can be easily extended with domain specific prior knowledge (e.", "startOffset": 179, "endOffset": 183}, {"referenceID": 17, "context": ", homophily in linked data [19]), thus suitable for various real-world problems; 4) many optimization methods such as (stochastic) gradient-based methods can be applied to find a good solution.", "startOffset": 27, "endOffset": 31}, {"referenceID": 2, "context": "Note that for the optimizing method, we mainly use the alternative algorithm, as similar to [4, 19].", "startOffset": 92, "endOffset": 99}, {"referenceID": 17, "context": "Note that for the optimizing method, we mainly use the alternative algorithm, as similar to [4, 19].", "startOffset": 92, "endOffset": 99}, {"referenceID": 0, "context": "For reference, matrix operation and optimization can be referred to [2] and [1] respectively.", "startOffset": 68, "endOffset": 71}, {"referenceID": 7, "context": "Regularization is usually necessary in prediction for bias-variance trade-off [9].", "startOffset": 78, "endOffset": 81}, {"referenceID": 0, "context": "(see more in [2]), we have the following derivatives for U and V,", "startOffset": 13, "endOffset": 16}, {"referenceID": 16, "context": "Detailed algorithm can be find in [18].", "startOffset": 34, "endOffset": 38}, {"referenceID": 2, "context": "As the objective function is non-convex caused by the coupling between U and V, we can choose to alternatively update U and V in each iteration as in [4, 19].", "startOffset": 150, "endOffset": 157}, {"referenceID": 17, "context": "As the objective function is non-convex caused by the coupling between U and V, we can choose to alternatively update U and V in each iteration as in [4, 19].", "startOffset": 150, "endOffset": 157}, {"referenceID": 17, "context": "Detailed algorithm is similar to the one in [19].", "startOffset": 44, "endOffset": 48}, {"referenceID": 11, "context": "Interestingly, the alternative optimization scheme is even more suitable for non-negative MF [13, 14, 5, 4], as we will see in the following subsections.", "startOffset": 93, "endOffset": 107}, {"referenceID": 12, "context": "Interestingly, the alternative optimization scheme is even more suitable for non-negative MF [13, 14, 5, 4], as we will see in the following subsections.", "startOffset": 93, "endOffset": 107}, {"referenceID": 3, "context": "Interestingly, the alternative optimization scheme is even more suitable for non-negative MF [13, 14, 5, 4], as we will see in the following subsections.", "startOffset": 93, "endOffset": 107}, {"referenceID": 2, "context": "Interestingly, the alternative optimization scheme is even more suitable for non-negative MF [13, 14, 5, 4], as we will see in the following subsections.", "startOffset": 93, "endOffset": 107}, {"referenceID": 11, "context": "2 Non-negative MF Non-negativeMF [13] seeks to approximate data matrixXwith low-dimensional matrices U,V whose entries are all non-negative, i.", "startOffset": 33, "endOffset": 37}, {"referenceID": 11, "context": "Non-negativity constaint is originated from parts-of-whole interpretation [13].", "startOffset": 74, "endOffset": 78}, {"referenceID": 11, "context": "Non-negative MF may uncover the important parts, which sometimes can not be achieved by non-constrained MF [13].", "startOffset": 107, "endOffset": 111}, {"referenceID": 17, "context": "Detailed algorithm using these rules is similar to the one in [19].", "startOffset": 62, "endOffset": 66}, {"referenceID": 12, "context": "12 with the standard auxiliary function approach, which is proposed in [14] and extended in [5, 4].", "startOffset": 71, "endOffset": 75}, {"referenceID": 3, "context": "12 with the standard auxiliary function approach, which is proposed in [14] and extended in [5, 4].", "startOffset": 92, "endOffset": 98}, {"referenceID": 2, "context": "12 with the standard auxiliary function approach, which is proposed in [14] and extended in [5, 4].", "startOffset": 92, "endOffset": 98}, {"referenceID": 3, "context": "Our proof is mainly based on [5, 4], although the objective function Eq.", "startOffset": 29, "endOffset": 35}, {"referenceID": 2, "context": "Our proof is mainly based on [5, 4], although the objective function Eq.", "startOffset": 29, "endOffset": 35}, {"referenceID": 3, "context": "17 can be found in [5] (Proposition 6).", "startOffset": 19, "endOffset": 22}, {"referenceID": 1, "context": "It is proved in [3, 5] ([5] gives more mature proof) that this problem is equivalent to K-means clustering: V is an indication matrix with V(i, j) = 0 if xi belongs to the j th (1 \u2264 j \u2264 k) cluster.", "startOffset": 16, "endOffset": 22}, {"referenceID": 3, "context": "It is proved in [3, 5] ([5] gives more mature proof) that this problem is equivalent to K-means clustering: V is an indication matrix with V(i, j) = 0 if xi belongs to the j th (1 \u2264 j \u2264 k) cluster.", "startOffset": 16, "endOffset": 22}, {"referenceID": 3, "context": "It is proved in [3, 5] ([5] gives more mature proof) that this problem is equivalent to K-means clustering: V is an indication matrix with V(i, j) = 0 if xi belongs to the j th (1 \u2264 j \u2264 k) cluster.", "startOffset": 24, "endOffset": 27}, {"referenceID": 3, "context": "It is proved that, compared to 3-factor bi-orthogonal non-negative MF, 2factor bi-orthogonal non-negative MF is too restrictive, and will lead to poor approximation [5].", "startOffset": 165, "endOffset": 168}, {"referenceID": 3, "context": "3-factor bi-orthogonal non-negative MF is useful in document-word clustering [5], outperforming K-means (i.", "startOffset": 77, "endOffset": 80}, {"referenceID": 8, "context": "It has been applied for tasks such as sentiment analysis [10].", "startOffset": 57, "endOffset": 61}, {"referenceID": 10, "context": "Such assumption is very common in real-world cases [12].", "startOffset": 51, "endOffset": 55}, {"referenceID": 5, "context": "For updating rules of non-negative MF and orthogonal non-negative MF, the reader can refer to [7] and [8], respectively.", "startOffset": 94, "endOffset": 97}, {"referenceID": 6, "context": "For updating rules of non-negative MF and orthogonal non-negative MF, the reader can refer to [7] and [8], respectively.", "startOffset": 102, "endOffset": 105}, {"referenceID": 17, "context": "We further point to two publications [19] and [8], to demonstrate the above two types of regularization, respectively.", "startOffset": 37, "endOffset": 41}, {"referenceID": 6, "context": "We further point to two publications [19] and [8], to demonstrate the above two types of regularization, respectively.", "startOffset": 46, "endOffset": 49}, {"referenceID": 17, "context": "Can we use social relation to boost the performance of trust relation prediction? This is exactly the research question proposed in [19].", "startOffset": 132, "endOffset": 136}, {"referenceID": 8, "context": "We will see that this type of regularization is used in a sentiment analysis paper [10], which we will analyze later.", "startOffset": 83, "endOffset": 87}, {"referenceID": 6, "context": "Now let us turn our attention back to 2-sided regularization, basing the example from [8], which considers POI recommendation in location-based social network (LBSN).", "startOffset": 86, "endOffset": 89}, {"referenceID": 15, "context": "Regularization We remark here that the idea of cofactoring two matrices (X,A) with shared factors (U) originates from collective matrix facterization [17], which has many applications in CF [16].", "startOffset": 150, "endOffset": 154}, {"referenceID": 14, "context": "Regularization We remark here that the idea of cofactoring two matrices (X,A) with shared factors (U) originates from collective matrix facterization [17], which has many applications in CF [16].", "startOffset": 190, "endOffset": 194}, {"referenceID": 18, "context": "A interesting comparative study between collective facterization and self-regularization can be found in [20].", "startOffset": 105, "endOffset": 109}, {"referenceID": 8, "context": "We point to publications [10] and [6] for the demonstration of the above two methods, respectively.", "startOffset": 25, "endOffset": 29}, {"referenceID": 4, "context": "We point to publications [10] and [6] for the demonstration of the above two methods, respectively.", "startOffset": 34, "endOffset": 37}, {"referenceID": 8, "context": "[10] deals with the problem of sentiment analysis, for which the authors use 3-factor non-negative orthogonal MF.", "startOffset": 0, "endOffset": 4}, {"referenceID": 3, "context": "Based on Proposition 1 in [5], we know that the answer is no.", "startOffset": 26, "endOffset": 29}, {"referenceID": 8, "context": "However, as we see in this sentiment analysis work [10], regularization is always possible! In fact, the enforcement regularization that we see in this work is the most constrained regularization: it is 2-sided regularization for both U,V, and it is enforcement without any transformation coefficients.", "startOffset": 51, "endOffset": 55}, {"referenceID": 4, "context": "To see this, we start directly with the application of [6].", "startOffset": 55, "endOffset": 58}, {"referenceID": 4, "context": "We first introduce how the model is built in [6], then discuss other alternatives.", "startOffset": 45, "endOffset": 48}], "year": 2017, "abstractText": null, "creator": "LaTeX with hyperref package"}}}