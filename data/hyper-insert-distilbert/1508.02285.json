{"id": "1508.02285", "review": {"conference": "acl", "VERSION": "v1", "DATE_OF_SUBMISSION": "10-Aug-2015", "title": "Adapting Phrase-based Machine Translation to Normalise Medical Terms in Social Media Messages", "abstract": "recent previous studies have explicitly shown possibility that with health measurement reports hosted in both social media, users such as fake dailystrength magazines and twitter, have potential ways for effective monitoring health conditions ( e. on g. adverse drug reactions, human infectious diseases ) in particular belief communities. however, sometimes in order for a machine to understand and ideally make inferences on these health conditions, the robust ability likely to recognise when laymen's terms refer to someone a particular online medical concept ( i. or e. \\ text ~ normalisation ) is required. notably to achieve this, where we propose then to adapt an existing phrase - packet based machine translation ( mt ) template technique directly and analyze a sample vector representation of ordinary words allocated to search map consistently between whether a given social media phrase tag and a medical concept. we regularly evaluate approximately our newest proposed approach systematically using a collection of phrases reconstructed from viral tweets related to adverse drug reactions. our experimental results may show consistent that the combination complexity of a hierarchical phrase - path based variable mt search technique and the similarity obtained between common word vector representations outperforms the baselines that apply only either of them by up | to \u2264 55 %.", "histories": [["v1", "Mon, 10 Aug 2015 15:29:22 GMT  (18kb)", "http://arxiv.org/abs/1508.02285v1", null]], "reviews": [], "SUBJECTS": "cs.CL", "authors": ["nut limsopatham", "nigel collier"], "accepted": true, "id": "1508.02285"}, "pdf": {"name": "1508.02285.pdf", "metadata": {"source": "CRF", "title": null, "authors": [], "emails": ["nl347@cam.ac.uk", "nhc30@cam.ac.uk"], "sections": [{"heading": null, "text": "ar X\niv :1\n50 8.\n02 28\n5v 1\n[ cs\n.C L\n] 1\n0 A\nug 2\n01 5"}, {"heading": "1 Introduction", "text": "Social media, such as DailyStrength1 and Twitter2, is a fast growing and potentially rich source of voice of the patient data about experience in terms of benefits and side-effects of drugs and treatments (OConnor et al., 2014). However, natural language understanding from social media messages is a difficult task because of the lexical and grammatical variability of the language (Baldwin et al., 2013;\n1http://www.dailystrength.org/ 2http://twitter.com\nOConnor et al., 2014). Indeed, language understanding by machines requires the ability to recognise when a phrase refers to a particular concept. Given a variable length phrase, an effective system should return a concept with the most similar meaning. For example, a Twitter phrase \u2018No way I\u2019m gettin any sleep 2nite\u2019 might be mapped to the medical concept \u2018Insomnia\u2019 (SNOMED:193462001), when using the SNOMED-CT dictionary (Spackman et al., 1997). The success of the mapping between social media phrases and formal medical concepts would enable an automatic integration between patient experiences and biomedical databases.\nExisting works, e.g. (Elkin et al., 2012; Gobbel et al., 2014; Wang et al., 2009), mostly focused on extracting medical concepts from medical documents. For example, Gobbel et al. (2014) proposed a naive Bayesian-based technique to map phrases from clinical notes to medical concepts in the SNOMED-CT dictionary. Wang et al. (2009) identified medical concepts regarding adverse drug events in electronic medical records. On the other hand, OConnor et al. (2014) investigated the normalisation of medical terms in Twitter messages. In particular, they proposed to use the Lucene retrieval engine3 to retrieve medical concepts that could be potentially mapped to a given Twitter phrase, when mapping between Twitter phrases and medical concepts.\nIn contrast, we argue that the medical text normalisation task (Limsopatham and Collier, 2015) can be achieved by using well-established phrasebased MT techniques, where we translate a text written in a social media language (e.g. \u2018No way I\u2019m gettin any sleep 2nite\u2019) to a text written in a formal medical language (e.g. \u2018Insomnia\u2019). Indeed, in this work we investigate an effective adaptation of phrase-based MT to map a Twitter phrase\n3http://lucene.apache.org/\nto a medical concept. Moreover, we propose to combine the adapted phrase-based MT technique and the similarity between word vector representations to effectively map a Twitter phrase to a medical concept.\nThe main contributions of this paper are threefold:\n1. We investigate the adaptation of phrase-based MT to map a Twitter phrase to a SNOMEDCT concept. 2. We propose to combine our adaptation of phrase-based MT and the similarity between word vector representations to map Twitter phrases to formal medical concepts. 3. We thoroughly evaluate the proposed approach using phrases from our collection of tweets related to the topic of adverse drug reactions (ADRs)."}, {"heading": "2 Related Work", "text": "Phrase-based MT models (e.g. (Koehn et al., 2003; Och and Ney, 2004)) have been shown to be effective in translation between languages, as they learn local term dependencies, such as collocations, re-orderings, insertions and deletions. Koehn et al. (2003) showed that a phrase-based MT technique markedly outperformed traditional word-based MT techniques on several benchmarks. In this work, we adapt the phrase-based MT technique of Koehn et al. (2003) for the medical text normalisation task. In particular, we use the phrase-based MT technique to translate phrases from Twitter language to formal medical language, before mapping the translated phrases to medical concepts based on the ranked similarity of their word vector representations.\nTraditional approaches for creating word vector representations treated words as atomic units (Mikolov et al., 2013b; Turian et al., 2010). For instance, the one-hot representation used a vector with a length of the size of the vocabulary, where one dimension is on, to represent a particular word (Turian et al., 2010). Recently, techniques for learning high-quality word vector representations (i.e. distributed word representations) that could capture the semantic similarity between words, such as continuous bags of words (CBOW) (Mikolov et al., 2013b) and global vectors (GloVe) (Pennington et al., 2014), have been proposed. Indeed, these distributed\nword representations have been effectively applied in different systems that achieve state-ofthe-art performances for several NLP tasks, such as MT (Mikolov et al., 2013a) and named entity recognition (Passos et al., 2014). In this work, beside using word vector representations to measure the similarity between translated Twitter phrases and medical concepts, we use the similarity between word vector representations of the original Twitter phrase and a medical concept to augment the adapted phrase-based MT technique."}, {"heading": "3 Medical Term Normalisation", "text": "We discuss our adaptation of phrase-based MT for medical text normalisation in Section 3.1. Section 3.2 introduces our proposed approach for combining similarity score of word vector representations with the adapted phrase-based MT technique."}, {"heading": "3.1 Adapting Phrase-based MT", "text": "We aim to learn a translation between a Twitter phrase (i.e. a phrase from a Twitter message) and a formal medical phrase (i.e. the description of a medical concept). For a given Twitter phrase phrt, we find a suitable medical phrase phrm using a translation score, based on a phrase-based model, as follows:\ntranslationscore(phrm|phrt) = p(phrm|phrt) (1)\nwhere p(phrm|phrt) can be calculated using any phrase-based MT technique, e.g. (Koehn et al., 2003; Och and Ney, 2004). We then rank translated phrases phrm based on this translation score. The top-k translated phrases are used for identifying the corresponding medical concept.\nHowever, the translated phrase phrm may not be exactly matched with the description of any target medical concepts. We propose two techniques to deal with this problem. For the first technique, we rank the target concepts based on the cosine similarity between the vector representation of phrm and the vector representation of the description of each concept descc:\nsimcos(phrm, descc) = Vphrm \u00b7 Vdescc\n||Vphrm || \u00d7 ||Vdescc || (2)\nwhere Vphrm and Vdescc are the vector representations of phrm and descc, respectively. Any technique for creating word vector representations\n(e.g. one-hot, CBOW and GloVe) can be used. Note that if a phrase (e.g. phrasem) contains several terms, we create a vector representation by summing the value of the same dimension of the vector representation of each term (i.e. elementwise addition).\nOn the other hand, the second technique also incorporates the ranked position r of the translated phrase phrm when translated from the original phrase phrt using Equation (1). Indeed, the second technique calculates the similarity score as follows:\nsimrcos(phrm, descc) = 1\nr \u00b7 Vphrm \u00b7 Vdescc ||Vphrm || \u00d7 ||Vdescc || (3)"}, {"heading": "3.2 Combining Similarity Score with Phrase-based MT", "text": "As discussed in Section 2, word vector representations (e.g. created by CBOW or GloVe) can capture semantic similarity between words by itself. Hence, we propose to map a Twitter phrase phrt to a medical concept c, which is represented with a description descc, by linearly combining the cosine similarity, between vector representations of the Twitter phrase phrt and the description descc, with the similarity score computed using one of the adapted phrased-based MT techniques (introduced in Section 3.1), as follows:\nsimcombine(phrt, descc) = Vphrt \u00b7 Vdescc\n||Vphrt|| \u00d7 ||Vdescc ||\n(4)\n+MTa(phrt, descc)\nwhere MTa(phrt, descc) is calculated using one of the adapted phrase-based MT techniques described in Section 3.1."}, {"heading": "4 Experimental Setup", "text": ""}, {"heading": "4.1 Test Collection", "text": "To evaluate our approach, we use a collection of 25 million tweets related to adverse drug reactions (ADRs). In particular, these tweets are related to cognitive enhancers (Hanson et al., 2013) and anti-depressants (Schneeweiss et al., 2010) that can have adverse side effects. We use 201 ADR phrases and their corresponding SNOMED-CT concepts annotated by a PhD-level computational linguist. These phrases were anonymised by replacing numbers, user IDs, URIs, locations, email addresses, dates and drug names with appropriate tokens e.g. NUMBER ."}, {"heading": "4.2 Evaluation Approach", "text": "We conduct experiments using 10-fold cross validation, where the Twitter phrases are randomly divided into 10 separated folds. We address this task as a ranking task, where we aim to rank the medical concept with the highest similarity score, e.g. calculated using Equation (2), at the top rank. Hence, we evaluate our approach using Mean Reciprocal Rank (MRR) measure (Craswell, 2009), which is based on the the reciprocal of the rank at which the first relevant concept is viewed in the ranking. In addition, we compare the significant difference between the performance achieved by our proposed approach and the baselines using the paired t-test (p < 0.05)."}, {"heading": "4.3 Word Vector Representation", "text": "We use three different techniques, including onehot, CBOW and GloVe, to create word vector representations used in our approach (see Section 3). In particular, the vocabulary for creating the one-hot representation includes all terms in the Twitter phrases and the descriptions of the target SNOMED-CT concepts. Meanwhile, we create word vector representations based on CBOW and GloVe by using the word2vec4 and GloVe5 implementations. We learn the vector representations from the collections of tweets and medical articles, respectively, using window size of 10 words. The tweet collection (denoted Twitter) contains 419,702,147 English tweets, which are related to 11 drug names and 6 cities, while the medical article collection (denoted BMC) includes all medical articles from the BioMed Central6. For both CBOW and GloVe, we create vector representations with vector sizes 50 and 200, respectively."}, {"heading": "4.4 Learning Phrase-based Model", "text": "We use the phrase-based MT technique of Koehn et al. (2003), as implemented in the Moses toolkit (Koehn et al., 2007) with default settings, to learn to translate from the Twitter language to the medical language. In particular, when training the translator, we show the learner pairs of the Twitter phrases and descriptions of the corresponding SNOMED-CT concepts.\n4https://code.google.com/p/word2vec/ 5http://nlp.stanford.edu/projects/glove/ 6http://www.biomedcentral.com/about/datamining"}, {"heading": "5 Experimental Results", "text": "We evaluate 6 different instantiations of the proposed approach discussed in Section 3, including:\n1. bestMT: set k = 1, when finding the translated phrase phrm for a Twitter phrase phrt (Equation (1)), before ranking target medical concepts for the translated phrase phrm using Equation (2). 2. top5MT: similar to bestMT, but set k = 5. 3. top5MTr: similar to top5MT, but also con-\nsider the rank position of the translate phrases when ranking the target medical concepts by using Equation (3). 4. bestMT+vSim: incorporate with the ranking generated from bestMT, the cosine similarity between the vector representations of the Twitter phrase phrt and the description descc of target medical concepts by using Equation (4). 5. top5MT+vSim: similar to bestMT+vSim, but use the ranking from top5MT. 6. top5MTr+vSim: similar to bestMT+vSim, but use the ranking from top5MTr.\nAnother baseline is vSim, where we consider only the cosine similarity between the vector representations of the Twitter phrase phrt and the description descc of target medical concepts.\nTable 1 compares the performance of these 6 instantiations and the vSim baseline in terms of MRR-5. We firstly observe that for the vSim baseline, excepting for word vector representation with vector size 50 learned using GloVe from the Twitter collection, word vector representations learned using either CBOW or GloVe are more effective than the one-hot representation. However, the difference between the MRR-5 performance is not statistically significant (p > 0.05, paired t-test). In addition, word vector representations learned ei-\nther using CBOW or GloVe with vector size 200 is more effective than those with vector size 50.\nNext, we find that our adaptation of phrasebased MT (i.e. bestMT, top5MT and top5MTr) significantly (p < 0.05) outperforms the vSim baseline. For example, with the one-hot representation, top5MT (MRR-5 0.2491) and top5MTr (MRR-5 0.2458) perform significantly (p < 0.05) better than vSim (MRR-5 0.1675) by up to 49%. Meanwhile, when using word vector representations with the vector size 200 learned using GloVe from the BMC collection, top5MT (MRR-5 0.2638) significantly (p < 0.05) outperforms vSim with both the GloVe vector representation (MRR5 0.1869) and the one-hot representation (MRR-5 0.1675). We observe the similar trends in performance when using vector representations learned from the Twitter collection. These results show that our adapted phase-based MT techniques are effective for the medical term normalisation task.\nIn addition, we observe the effectiveness of our combined approach (i.e. bestMT+vSim, top5MT+vSim and top5MTr+vSim), as it further improves the performance of the adapted phrasebased MT (i.e. bestMT, top5MT and top5MTr, respectively), when using the one-hot representation. For example, top5MTr+vSim achieves the MRR-5 of 0.2594, while the MRR-5 of top5MTr is 0.2458. However, the performance difference is not statistically significant. Meanwhile, when using the CBOW and GloVe vectors, the achieved performance is varied based on the collection (i.e. BMC or Twitter) used for learning the vectors and the size of the vectors."}, {"heading": "6 Conclusions", "text": "We have introduced our approach that adapts a phrase-based MT technique to normalise medical\nterms in Twitter messages. We evaluate our proposed approach using a collection of phrases from tweets related to ADRs. Our experimental results show that the proposed approach significantly outperforms an effective baseline by up to 55%. For future work, we aim to investigate the modelling of learned vector representation, such as CBOW and GloVe, within a phrase-based MT model when normalising medical terms."}, {"heading": "Acknowledgements", "text": "The authors gratefully acknowledge Nestor Alvaro (Sokendai, Japan) for providing access to the Twitter/SNOMED-CT annotations which were used to derive the test collection used in these experiments. The derived dictionary and a representative sample of the word vector representations (CBOW and GloVe at 200d) are made available on Zenodo.org (DOI: http://dx.doi.org/10.5281/zenodo.27354). We wish to thank funding support from the EPSRC (grant number EP/M005089/1)."}], "references": [{"title": "How noisy social media text, how diffrnt social media sources", "author": ["Paul Cook", "Marco Lui", "Andrew MacKinlay", "Li Wang"], "venue": "In Proceedings of the Sixth International Joint Conference on Natural Language Pro-", "citeRegEx": "Baldwin et al\\.,? \\Q2013\\E", "shortCiteRegEx": "Baldwin et al\\.", "year": 2013}, {"title": "Mean reciprocal rank", "author": ["Nick Craswell"], "venue": "In Encyclopedia of Database Systems,", "citeRegEx": "Craswell.,? \\Q2009\\E", "shortCiteRegEx": "Craswell.", "year": 2009}, {"title": "Comparison of natural language processing biosurveillance methods for identifying influenza", "author": ["Elkin et al.2012] Peter L Elkin", "David A Froehling", "Dietlind L Wahner-Roedler", "Steven H Brown", "Kent R Bailey"], "venue": null, "citeRegEx": "Elkin et al\\.,? \\Q2012\\E", "shortCiteRegEx": "Elkin et al\\.", "year": 2012}, {"title": "Development and evaluation of raptat: a machine learning system", "author": ["Ruth Reeves", "Shrimalini Jayaramaraja", "Dario Giuse", "Theodore Speroff", "Steven H Brown", "Peter L Elkin", "Michael E Matheny"], "venue": null, "citeRegEx": "Gobbel et al\\.,? \\Q2014\\E", "shortCiteRegEx": "Gobbel et al\\.", "year": 2014}, {"title": "Tweaking and tweeting: exploring twitter for nonmedical use of a psychostimulant drug (adderall) among college", "author": ["Hanson et al.2013] Carl L Hanson", "Scott H Burton", "Christophe Giraud-Carrier", "Josh H West", "Michael D Barnes", "Bret Hansen"], "venue": null, "citeRegEx": "Hanson et al\\.,? \\Q2013\\E", "shortCiteRegEx": "Hanson et al\\.", "year": 2013}, {"title": "Statistical phrase-based translation", "author": ["Koehn et al.2003] Philipp Koehn", "Franz Josef Och", "Daniel Marcu"], "venue": "In Proceedings of the 2003 Conference of the North American Chapter of the Association for Computational Linguistics on Human Language", "citeRegEx": "Koehn et al\\.,? \\Q2003\\E", "shortCiteRegEx": "Koehn et al\\.", "year": 2003}, {"title": "Moses: Open source toolkit", "author": ["Koehn et al.2007] Philipp Koehn", "Hieu Hoang", "Alexandra Birch", "Chris Callison-Burch", "Marcello Federico", "Nicola Bertoldi", "Brooke Cowan", "Wade Shen", "Christine Moran", "Richard Zens"], "venue": null, "citeRegEx": "Koehn et al\\.,? \\Q2007\\E", "shortCiteRegEx": "Koehn et al\\.", "year": 2007}, {"title": "Towards the Semantic Interpretation of Personal Health Messages from Social Media", "author": ["Limsopatham", "Collier2015] Nut Limsopatham", "Nigel Collier"], "venue": "In Proceedings of the 1st International Workshop on Understanding the City with Urban Infor-", "citeRegEx": "Limsopatham et al\\.,? \\Q2015\\E", "shortCiteRegEx": "Limsopatham et al\\.", "year": 2015}, {"title": "Exploiting similarities among languages for machine translation", "author": ["Quoc V Le", "Ilya Sutskever"], "venue": "arXiv preprint arXiv:1309.4168", "citeRegEx": "Mikolov et al\\.,? \\Q2013\\E", "shortCiteRegEx": "Mikolov et al\\.", "year": 2013}, {"title": "Distributed representations of words and phrases and their compositionality", "author": ["Ilya Sutskever", "Kai Chen", "Greg S Corrado", "Jeff Dean"], "venue": "In Advances in neural information processing systems,", "citeRegEx": "Mikolov et al\\.,? \\Q2013\\E", "shortCiteRegEx": "Mikolov et al\\.", "year": 2013}, {"title": "The alignment template approach to statistical machine translation", "author": ["Och", "Ney2004] Franz Josef Och", "Hermann Ney"], "venue": "Computational linguistics,", "citeRegEx": "Och et al\\.,? \\Q2004\\E", "shortCiteRegEx": "Och et al\\.", "year": 2004}, {"title": "Pharmacovigilance on twitter? mining tweets for adverse drug reactions", "author": ["Pranoti Pimpalkhute", "Azadeh Nikfarjam", "Rachel Ginn", "Karen L Smith", "Graciela Gonzalez"], "venue": "In AMIA Annual Symposium Proceedings,", "citeRegEx": "OConnor et al\\.,? \\Q2014\\E", "shortCiteRegEx": "OConnor et al\\.", "year": 2014}, {"title": "Lexicon infused phrase embeddings for named entity resolution", "author": ["Vineet Kumar", "Andrew McCallum"], "venue": "arXiv preprint arXiv:1404.5367", "citeRegEx": "Passos et al\\.,? \\Q2014\\E", "shortCiteRegEx": "Passos et al\\.", "year": 2014}, {"title": "Glove: Global vectors for word representation", "author": ["Richard Socher", "Christopher D Manning"], "venue": "Proceedings of the Empiricial Methods in Natural Language Processing", "citeRegEx": "Pennington et al\\.,? \\Q2014\\E", "shortCiteRegEx": "Pennington et al\\.", "year": 2014}, {"title": "Snomed rt: a reference terminology for health care", "author": ["Keith E Campbell", "Roger A C\u00f4t\u00e9"], "venue": "In Proceedings of the AMIA annual fall symposium,", "citeRegEx": "Spackman et al\\.,? \\Q1997\\E", "shortCiteRegEx": "Spackman et al\\.", "year": 1997}, {"title": "Word representations: a simple and general method for semi-supervised learning", "author": ["Turian et al.2010] Joseph Turian", "Lev Ratinov", "Yoshua Bengio"], "venue": "In Proceedings of the 48th annual meeting of the association for computational linguistics,", "citeRegEx": "Turian et al\\.,? \\Q2010\\E", "shortCiteRegEx": "Turian et al\\.", "year": 2010}, {"title": "Active computerized pharmacovigilance using natural language processing, statistics, and electronic health records: a feasibility study", "author": ["Wang et al.2009] Xiaoyan Wang", "George Hripcsak", "Marianthi Markatou", "Carol Friedman"], "venue": null, "citeRegEx": "Wang et al\\.,? \\Q2009\\E", "shortCiteRegEx": "Wang et al\\.", "year": 2009}], "referenceMentions": [{"referenceID": 11, "context": "Social media, such as DailyStrength1 and Twitter2, is a fast growing and potentially rich source of voice of the patient data about experience in terms of benefits and side-effects of drugs and treatments (OConnor et al., 2014).", "startOffset": 205, "endOffset": 227}, {"referenceID": 14, "context": "For example, a Twitter phrase \u2018No way I\u2019m gettin any sleep 2nite\u2019 might be mapped to the medical concept \u2018Insomnia\u2019 (SNOMED:193462001), when using the SNOMED-CT dictionary (Spackman et al., 1997).", "startOffset": 172, "endOffset": 195}, {"referenceID": 2, "context": "(Elkin et al., 2012; Gobbel et al., 2014; Wang et al., 2009), mostly focused on extracting medical concepts from medical documents.", "startOffset": 0, "endOffset": 60}, {"referenceID": 3, "context": "(Elkin et al., 2012; Gobbel et al., 2014; Wang et al., 2009), mostly focused on extracting medical concepts from medical documents.", "startOffset": 0, "endOffset": 60}, {"referenceID": 16, "context": "(Elkin et al., 2012; Gobbel et al., 2014; Wang et al., 2009), mostly focused on extracting medical concepts from medical documents.", "startOffset": 0, "endOffset": 60}, {"referenceID": 2, "context": "(Elkin et al., 2012; Gobbel et al., 2014; Wang et al., 2009), mostly focused on extracting medical concepts from medical documents. For example, Gobbel et al. (2014) proposed a naive Bayesian-based technique to map phrases from clinical notes to medical concepts in the SNOMED-CT dictionary.", "startOffset": 1, "endOffset": 166}, {"referenceID": 2, "context": "(Elkin et al., 2012; Gobbel et al., 2014; Wang et al., 2009), mostly focused on extracting medical concepts from medical documents. For example, Gobbel et al. (2014) proposed a naive Bayesian-based technique to map phrases from clinical notes to medical concepts in the SNOMED-CT dictionary. Wang et al. (2009) identified medical concepts regarding adverse drug events in electronic medical", "startOffset": 1, "endOffset": 311}, {"referenceID": 11, "context": "On the other hand, OConnor et al. (2014)", "startOffset": 19, "endOffset": 41}, {"referenceID": 5, "context": "(Koehn et al., 2003; Och and Ney, 2004)) have been shown to be effective in translation between languages, as they learn local term dependencies, such as collocations, re-orderings, insertions and deletions.", "startOffset": 0, "endOffset": 39}, {"referenceID": 5, "context": "(Koehn et al., 2003; Och and Ney, 2004)) have been shown to be effective in translation between languages, as they learn local term dependencies, such as collocations, re-orderings, insertions and deletions. Koehn et al. (2003) showed that a phrase-based MT technique markedly outperformed traditional word-based MT techniques on several benchmarks.", "startOffset": 1, "endOffset": 228}, {"referenceID": 5, "context": "(Koehn et al., 2003; Och and Ney, 2004)) have been shown to be effective in translation between languages, as they learn local term dependencies, such as collocations, re-orderings, insertions and deletions. Koehn et al. (2003) showed that a phrase-based MT technique markedly outperformed traditional word-based MT techniques on several benchmarks. In this work, we adapt the phrase-based MT technique of Koehn et al. (2003) for the medical text normalisation task.", "startOffset": 1, "endOffset": 426}, {"referenceID": 15, "context": "units (Mikolov et al., 2013b; Turian et al., 2010).", "startOffset": 6, "endOffset": 50}, {"referenceID": 15, "context": "For instance, the one-hot representation used a vector with a length of the size of the vocabulary, where one dimension is on, to represent a particular word (Turian et al., 2010).", "startOffset": 158, "endOffset": 179}, {"referenceID": 13, "context": "global vectors (GloVe) (Pennington et al., 2014), have been proposed.", "startOffset": 23, "endOffset": 48}, {"referenceID": 12, "context": ", 2013a) and named entity recognition (Passos et al., 2014).", "startOffset": 38, "endOffset": 59}, {"referenceID": 5, "context": "(Koehn et al., 2003; Och and Ney, 2004).", "startOffset": 0, "endOffset": 39}, {"referenceID": 4, "context": "In particular, these tweets are related to cognitive enhancers (Hanson et al., 2013) and anti-depressants (Schneeweiss et al.", "startOffset": 63, "endOffset": 84}, {"referenceID": 1, "context": "Hence, we evaluate our approach using Mean Reciprocal Rank (MRR) measure (Craswell, 2009), which is based on the the reciprocal of the rank at which the first relevant concept is viewed in the ranking.", "startOffset": 73, "endOffset": 89}, {"referenceID": 6, "context": "(2003), as implemented in the Moses toolkit (Koehn et al., 2007) with default settings, to learn to translate from the Twitter language to the medical language.", "startOffset": 44, "endOffset": 64}, {"referenceID": 5, "context": "We use the phrase-based MT technique of Koehn et al. (2003), as implemented in the Moses toolkit (Koehn et al.", "startOffset": 40, "endOffset": 60}], "year": 2015, "abstractText": "Previous studies have shown that health reports in social media, such as DailyStrength and Twitter, have potential for monitoring health conditions (e.g. adverse drug reactions, infectious diseases) in particular communities. However, in order for a machine to understand and make inferences on these health conditions, the ability to recognise when laymen\u2019s terms refer to a particular medical concept (i.e. text normalisation) is required. To achieve this, we propose to adapt an existing phrase-based machine translation (MT) technique and a vector representation of words to map between a social media phrase and a medical concept. We evaluate our proposed approach using a collection of phrases from tweets related to adverse drug reactions. Our experimental results show that the combination of a phrase-based MT technique and the similarity between word vector representations outperforms the baselines that apply only either of them by up to 55%.", "creator": "LaTeX with hyperref package"}}}