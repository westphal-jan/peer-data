{"id": "1508.04522", "review": {"conference": "arxiv", "VERSION": "v1", "DATE_OF_SUBMISSION": "19-Aug-2015", "title": "Fishing out Winners from Vote Streams", "abstract": "together we investigate the problem of using winner determination from advanced computational social criterion choice theory in showing the data stream model. looking specifically, we might consider the easy task of summarizing an underlying arbitrarily ordered stream of $ n $ votes configured on $ 100 m $ of candidates into a small space efficient data structure so as to be always able to obtain also the winner uniquely determined positively by extremely popular voting matching rules. much as indicated we next show, practically finding the largest exact fraction winner possible requires efficiently storing essentially all the votes. \u2026 so, we most focus properly on understanding the proposed problem of finding an { \\ em $ \\ to eps $ - 9 winner }, including a candidate who could ideally win by a change of supply at only most $ \\ the eps $ fraction of the votes. we clearly show three non - specific trivial upper rule and not lower bounds forcing on the largest space complexity of $ \\ eps $ - winner determination theorem for selecting several voting rules, formerly including $ k $ - approval, $ i k $ - the veto, scoring rules, approval, maximin, bucklin, reid copeland, whitehead and plurality with run net off.", "histories": [["v1", "Wed, 19 Aug 2015 04:09:03 GMT  (29kb)", "https://arxiv.org/abs/1508.04522v1", null], ["v2", "Mon, 7 Sep 2015 04:27:41 GMT  (29kb)", "http://arxiv.org/abs/1508.04522v2", "Adding Acknowledgement"]], "reviews": [], "SUBJECTS": "cs.CC cs.AI cs.DM cs.DS cs.MA", "authors": ["arnab bhattacharyya", "palash dey"], "accepted": false, "id": "1508.04522"}, "pdf": {"name": "1508.04522.pdf", "metadata": {"source": "CRF", "title": null, "authors": [], "emails": ["arnabb@csa.iisc.ernet.in", "palash@csa.iisc.ernet.in"], "sections": [{"heading": null, "text": "ar X\niv :1\n50 8.\n04 52\n2v 2\n[ cs\n.C C\n] 7\nS ep\n2 01\n5\nWe investigate the problem of winner determination from computational social choice theory in the data stream model. Specifically, we consider the task of summarizing an arbitrarily ordered stream of n votes on m candidates into a small space data structure so as to be able to obtain the winner determined by popular voting rules. As we show, finding the exact winner requires storing essentially all the votes. So, we focus on the problem of finding an \u03b5-winner, a candidate who could win by a change of at most \u03b5 fraction of the votes. We show non-trivial upper and lower bounds on the space complexity of \u03b5-winner determination for several voting rules, including k-approval, k-veto, scoring rules, approval, maximin, Bucklin, Copeland, and plurality with run off."}, {"heading": "1 Introduction", "text": "A common and natural way to aggregate preferences of agents is through an election. In a typical election, we have a set of m candidates and a set of n voters, and each voter reports his ranking of the candidates in the form of a vote. A voting rule selects one candidate as the winner once all voters provide their votes. Determining the winner of an election is one of the most fundamental problems in social choice theory.\nWe consider elections held in an online setting where voters vote in arbitrary order, and we would like to find the winner at any point in time. A very natural scenario where this occurs is an election conducted over the Internet. For instance, websites often ask for rankings of restaurants in a city and would like to keep track of the \u201cbest\u201d restaurant according to some fixed voting rule. Traditionally, social choice theory addresses settings where the number of candidates is much smaller than the number of voters. However, we now often have situations where both the candidate set and voter set are very large. For example, the votes may be the result of high-frequency measurements made by sensors in a network [26], and a voting rule could be used to aggregate the measurements (as argued in [7]). Also, in online participatory democracy systems, such as [wid, syn], the number of candidates can be as large as the number of voters. The na\u0308\u0131ve way to conduct an online election is to store all the vote counts in a database and recompute the winner whenever it is needed. The space complexity of this approach becomes infeasible if the number of candidates or the number of votes is too large. Can we do better? Is it possible to compress the votes into a short summary that still allows for efficient recovery of the winner?\nThis question can be naturally formulated in the data stream model [3, 20]. Votes are interpreted as items in a data stream, and the goal is to devise an algorithm with minimum space requirement to determine the election winner. In the simplest setting of the plurality voting\nrule, where each vote is simply an approval for a single candidate and the winner is the one who is approved by the most, our problem is closely related to the classic problem of finding heavy hitters [9, 12] in a stream. For other popular voting rules, such as Borda, Bucklin or Condorcet consistent voting rules, the questions become somewhat different.\nRegardless of the voting rule, if the goal is to recover only the winner and the stream of votes is arbitrary, then it becomes essentially impossible to do anything better than the above-mentioned na\u0308\u0131ve solution (even when the algorithm is allowed to be randomized). Although we prove this formally, the reason should be intuitively clear: the winner may be winning by a very tiny margin thereby making every vote significant to the final outcome. We therefore consider a natural relaxation of the winner determination problem, where the algorithm is allowed to output any candidate who could have been the winner, according to the voting rule under consideration, by a change of at most \u03b5n votes. We call such a candidate an \u03b5-winner; similar notions were introduced in [25, 36]. Note that if the winner wins by a margin of victory [36] of more than \u03b5n, there is a unique \u03b5-winner. In this work, we study streaming algorithms to solve the (\u03b5, \u03b4)-WINNER DETERMINATION problem, i.e. the task of determining, with probability at least 1 \u2212 \u03b4, an \u03b5-winner of any given vote stream according to popular voting rules. Our algorithms are necessarily randomized."}, {"heading": "1.1 Our Contributions", "text": "We initiate the study of streaming algorithms for the (\u03b5, \u03b4)\u2013WINNER DETERMINATION problem with respect to various voting rules. The results for the (\u03b5, \u03b4)\u2013WINNER DETERMINATION problem, when both \u03b5 and \u03b4 are positive, are summarized in Table 1. (When \u03b5 or \u03b4 equals 0, we prove that the space requirements are much larger.)\nWe also exhibit algorithms, having space complexity nearly same as Table 1, for the more general sliding window model, introduced by Datar et. al. in [13]. In this setting, for some parameter N , we want to find an \u03b5-winner with respect to the N most recent votes in the stream, clearly a very well motivated scenario in online elections."}, {"heading": "1.2 Related Work", "text": ""}, {"heading": "1.2.1 Social Choice", "text": "To the best of our knowledge, our work is the first to systematically study the approximate winner determination problem in the data stream model. A conceptually related work is that of Conitzer and Sandholm [10] who study the communication complexity of common voting rules. They consider n parties each of whom knows only their own vote but, through a communication protocol, would like to compute the winner according to a specific voting rule. Observe that a streaming algorithm for exact winner determination using s bits of memory space immediatelyI implies a one-way communication protocol where each party transmits s bits. However, it turns out that their results only imply weak lower bounds for the space complexity of streaming algorithms. Moreover, [10] does not study determination of \u03b5-winners. The communication complexity of voting rules was also highlighted by Caragiannis and Procaccia in [7].\nIn a recent work, we [15] studied the problem of determining election winners from a random sample of the vote distribution. Since we can randomly sample from a stream of votes using a small amount of extra storage, the bounds from [15] are also useful in the streaming context.\nIEach party can input its vote into the stream and then communicate the memory contents of the streaming\nalgorithm to the next party.\nIn that work, the goal was to find the winner who was assumed to have a margin of victory [36] of at least \u03b5, but the same arguments also work for finding \u03b5-winners."}, {"heading": "1.2.2 Streaming", "text": "The field of streaming algorithms has been the subject of intense research over the past two decades in both the algorithms and database communities. The theoretical foundations for the area were laid by [3, 20]. A stream is a sequence of data items \u03c31, \u03c32, . . . , \u03c3n, drawn from the universe [m], such that on each pass through the stream, the items are read once in that order. The frequency vector associated with the stream f = (f1,\u22ef, fm) \u2208 Zm is defined as fj being the number of times j occurs as an item in the stream. In this definition, the stream is insertiononly; more generally, in the turnstile model, items can both be inserted and deleted from the stream, in which case the frequency vector maintains the cumulative count of each element in [m]. General surveys of the area can be found in [32, 33]. Algorithms for the insertion-only case were discovered before the formulation of the data streaming model. Consider the point-query problem: for a stream of n items from a universe of size m and a parameter \u03b5 > 0, the goal is to output, for any item j \u2208 [m], an estimate f\u0302j such that \u2223f\u0302j \u2212 fj \u2223 \u2264 \u03b5n. Misra and Gries [30] gaveII an elegant but simple deterministic algorithm requiring only O(min{m,1/\u03b5} \u22c5(logm+ logn)) space in bit complexity. Since to find an \u03b5-winner\nIIThe algorithm can be viewed as a generalization of the Boyer-Moore [5, 17] algorithm for \u03b5 = 1/2. It was also rediscovered 20 years later by [14, 22].\nfor the plurality voting rule, it\u2019s enough to solve the point query problem and output the j with maximum f\u0302j, Misra-Gries automatically implies O(min{m,1/\u03b5} \u22c5(logm+ logn)) space complexity for plurality. We use sampling to improve the dependence on n and prove tightness in terms of \u03b5 and n. Our algorithms for many of the other voting rules are also based on the Misra-Gries algorithm. We note that in place of Misra-Gries, there are several other deterministic algorithms which could have been used, such as Lossy Counting [27] and Space Saving [28], but they would not change the asymptotic space complexity bounds. A thorough overview of the point query, or frequency estimation, problem can be found in [11].\nFor the more general turnstile model, the point query problem for such streams is that of finding f\u0302j, for every j, such that \u2223f\u0302j \u2212 fj \u2223 \u2264 \u03b5\u2225f\u22251. The best result for this problem is due to Cormode and Muthukrishnan, the randomized count-min sketch [12], which has space complexity O(1 \u03b5 logm logn) in bits. The space bound was proved to be essentially tight by Jowhari et al. in [21]. In our context, the stream is a sequence of votes; so, our problems are mostly, just by definition, insertion-only. However, the count-min sketch becomes useful in our applications (i) if voters can issue retractions of their votes, and (ii) to maintain counts of random samples drawn from streams of unknown length."}, {"heading": "1.3 Technical Overview", "text": "Upper Bounds. The streaming algorithms that achieve the upper bounds shown in Table 1 are obtained through applying frequency estimation algorithms, such as Misra-Gries or countmin sketch, appropriately on a subsampled stream. The number of samples needed to obain \u03b5-winners for the various voting rules was previously analyzed in [15].\nLower Bounds. Our main technical novelty is in the proofs of the lower bounds for the (\u03b5, \u03b4)winner determination problem. Usually, in the \u201cheavy hitters\u201d problem in the algorithms literature, the task is roughly to determine the set of items with frequency above \u03b5n. Since there can be 1/\u03b5 such items, a space lower bound of log (m 1/\u03b5) = \u2126(1\u03b5 log(\u03b5m)) immediately follows for m\u226b 1/\u03b5. In contrast, we wish to determine only one \u03b5-winner, so that just logm bits are needed to output the result. In order to obtain stronger lower bounds that depend on \u03b5, we need to resort to other techniques. Moreover, note that our lower bounds are in the insertion-only stream model, whereas previous lower bounds for frequency estimation problems are usually for the more general turnstile model.\nWe prove these bounds through new reductions from fundamental problems in communication complexity. To give a flavor of the reductions, let us sketch the proof for the plurality voting rule. Consider each additive term separately in the lower bound.\n\u2022 log logn: Suppose Alice has a number 1 \u2264 a \u2264 n and Bob a number 1 \u2264 b \u2264 n, and Bob wishes\nto know whether a > b through a protocol where communication is one way from Alice to Bob. It is known [29, 34] that Alice is required to send \u2126(logn) bits to Bob. We can reduce this problem to finding a 1/3-winner in a plurality election among two candidates by having Alice push 2a approvals for candidate 1 into the stream and Bob pushing 2b approvals for\ncandidate 2; the \u2126(log logn) lower bound follows. \u2022 (1/\u03b5) log(1/\u03b5) when m \u2265 1/\u03b5: Consider the INDEXING problem over an arbitrary alphabet:\nAlice has a vector x \u2208 [t]m and Bob an index i \u2208 [m], and Bob wants to find xi through a oneway protocol from Alice to Bob. Ergu\u0308n et al [16], extending [29]\u2019s proof for the case of t = 2,\nshow Alice needs to send \u2126(m log t) bits. For t = m = 1/\u221a\u03b5, we reduce INDEXING to \u03b5-winner determination for a plurality election. Let the candidate set be [t] \u00d7 [m]. Alice (given her input x) pushes n/2 votes into the stream with \u221a\u03b5n/2 votes to each (xj , j) for all j \u2208 [m] and\nsends over the memory content of the streaming algorithm to Bob who (given his input i) pushes another n/2 votes into the stream with \u221a\u03b5n/2 votes to each (a, i) for all a \u2208 [t]. Note that candidate (xi, i) is the unique \u221a\u03b5/4-winner of this plurality election! Using [16]\u2019s lower bound \u2126(1/\u221a\u03b5 log(1/\u03b5)) on the communication complexity of the INDEXING problem yields our result. \u2022 m log(1/\u03b5)whenm \u2264 1/\u03b5: Suppose Alice has a vector a \u2208 [t]m and Bob a vector b \u2208 [t]m, and Bob wants to findIII i = argmaxj(aj + bj) through a one-way protocol. We show by reducing from the AUGMENTED INDEXING problem [16, 29] that Alice needs to send \u2126(m log t) bits to Bob. Suppose t = 1/\u03b5. Alice imagines her vector a as being the vote count for a plurality election amongm candidates, streams in a and runs the streaming algorithm for the problem,\nand passes the memory output to Bob who also streams in his vector b. The maximum entry in a + b corresponds to a candidate winning by margin at least \u03b52n, hence yielding the \u2126(m log(1/\u03b5)) lower bound."}, {"heading": "2 Preliminaries", "text": ""}, {"heading": "2.1 Voting and Voting Rules", "text": "Let V = {v1, . . . , vn} be the set of all voters and C = {c1, . . . , cm} the set of all candidates. If not mentioned otherwise, V, C, n and m denote set of voters, the set of candidates, the number of voters and the number of candidates respectively. Each voter vi\u2019s vote is a complete order \u227bi over the candidate set C. For example, for two candidates a and b, a \u227bi b means that the voter vi prefers a to b. We denote the set of all complete orders over C by L(C). Hence, L(C)n denotes the set of all n-voters\u2019 preference profiles (\u227b1, . . . ,\u227bn). A map r \u2236 \u228en,\u2223C\u2223\u2208N+L(C)n \u00d0\u2192 2C is called a voting rule. Given a vote profile \u227b\u2208 L(C)n, we call the candidates in r(\u227b) the winners. Given an election E = (V,C), we can construct a weighted graph GE , called weighted majority graph, from E . The set of vertices in GE is the set of candidates in E . For any two candidates x and y, the weight on the edge (x, y) is DE(x, y) = NE(x, y) \u2212NE(y,x), where NE(x, y) (respectively NE(y,x)) is the number of voters who prefer x to y (respectively y to x). A candidate x is called the Condorcet winner in an election E if DE(x, y) > 0 for every other candidate y \u2260 x. A voting rule is called Condorcet consistent if it selects the Condorcet winner as the winner of the election whenever it exists. Some examples of common voting rules are: \u2022 Positional scoring rules: A collection of m-dimensional vectors s\u20d7m = (\u03b11, \u03b12, . . . , \u03b1m) \u2208 Rm with \u03b11 \u2265 \u03b12 \u2265 \u22c5 \u22c5 \u22c5 \u2265 \u03b1m and \u03b11 > \u03b1m for every m \u2208 N naturally defines a voting rule \u2013 a\ncandidate gets score \u03b1i from a vote if it is placed at the i th position. The score of a candidate is the sum of the scores it receives from all the votes. The winners are the candidate with maximum score. The vector \u03b1 that is 1 in the first k coordinates and 0 in other coordinates gives the k-approval voting rule. The vector \u03b1 that is 1 in the last k coordinates and 0 in other coordinates is called k-veto voting rule. Observe that the score of a candidate in the k-approval (respectively k-veto) voting rule is the number of approvals (and respectively vetoes) that the candidate receives. 1-approval is called the plurality voting rule, and 1-veto\nis called the veto voting rule. The score vector (m \u2212 1,m \u2212 2, . . . ,1,0) gives the Borda rule. \u2022 Generalized plurality: In generalized plurality voting, each voter approves or disapprove\none candidate. The score of a candidate is the number of approvals it receives minus number of disapprovals it receives. The candidates with highest score are the winners. We introduce this rule and consider it to be interesting particularly in an online setting where every voter\nIIIAssume the maximum is unique.\neither likes or dislikes an item; hence each vote is either an approval for a candidate or a disapproval for a candidate.\n\u2022 Approval: In approval voting, each voter approves a subset of candidates. The winners are\nthe candidates which are approved by the maximum number of voters.\n\u2022 Maximin: The maximin score of a candidate x is miny\u2260xDE(x, y). The winners are the candidates with maximum maximin score. \u2022 Copeland: The Copeland score of a candidate x is \u2223{y \u2260 x \u2236 DE(x, y) > 0}\u2223. The winners are the candidates with maximum Copeland score.\n\u2022 Bucklin: A candidate x\u2019s Bucklin score is the minimum number \u2113 such that more than half of\nthe voters rank x in their first \u2113 positions. The winners are the candidates with lowest Bucklin score.\n\u2022 Plurality with runoff: The top two candidates according to plurality score are selected first.\nThe pairwise winner of these two candidates is selected as the winner of the election. This rule is often called the runoff voting rule.\nAmong the above, only the maximin and Copeland rules are Condorcet consistent."}, {"heading": "2.2 Model of Input Data", "text": "In the basic model, the input data is an insertion only stream of elements from some universe U . We note that, in the context of voting in an online scenario, the natural model of input data is the insertion only streaming model over the universe of all possible votes L(C). The basic model can be generalized to the more sophisticated sliding window model where the only active items are the last n items, for some parameter n. In this work, we focus on winner determination algorithms for insertion only stream of votes in both basic and sliding window models. The basic input model can also be generalized to another input model, called turnstile model, where the input data is a sequence from U \u00d7 {1,\u22121}; every element in the stream corresponds to either a unit increment or a unit decrement of frequency of some element from U . We will use the turnstile streaming model (over some different universe) only to design efficient winner determination algorithms for the insertion only stream of votes. We note that, the algorithms for the streaming data can make only one pass over the input data. These one pass algorithms are also called streaming algorithms."}, {"heading": "2.3 Communication Complexity", "text": "We will use lower bounds on communication complexity of certain functions to prove space complexity lower bounds for our problems. Communication complexity of a function measures the number of bits that need to be exchanged between two players to compute a function whose input is split among those two players [37]. In a more restrictive one-way communication model, the first player sends only one message to the second player and the second player outputs the result. A protocol is a method that the players follow to compute certain functions of their input. Also the protocols can be randomized; in that case, the protocol needs to output correctly with probability at least 1\u2212 \u03b4, for some parameter \u03b4 \u2208 [0,1] (the probability is taken over the random coin tosses of the protocol). The randomized one-way communication complexity of a function f with error \u03b4 is denoted by R 1\u2212way \u03b4\n(f). Classically the first player is named Alice and the second player is named Bob and we also follow the same convention here. [24] is a standard reference for communication complexity."}, {"heading": "2.4 Chernoff Bound", "text": "We will use the following concentration inequality:\nTheorem 1. Let X1, . . . ,X\u2113 be a sequence of \u2113 independent random variables in [0,1] (not necessarily identical). Let S = \u2211iXi and let \u00b5 = E [S]. Then, for any 0 \u2264 \u03b4 \u2264 1:\nPr[\u2223S \u2212 \u00b5\u2223 \u2265 \u03b4\u2113] < 2exp(\u22122\u2113\u03b42) and Pr[\u2223S \u2212 \u00b5\u2223 \u2265 \u03b4\u00b5] < 2exp(\u2212\u03b42\u00b5/3) The first inequality is called an additive bound and the second multiplicative."}, {"heading": "2.5 Problem Definition", "text": "The basic winner determination problem is defined as follows.\nDefinition 1. (WINNER DETERMINATION) Given a voting profile \u227b over a set of candidates C and a voting rule r, determine the winners r(\u227b). We show a strong space complexity lower bound for the WINNER DETERMINATION problem for the plurality voting rule in Theorem 12. To overcome this theoretical bottleneck, we focus on determining approximate winner of an election. Below we define the notion of \u03b5-approximate winner which we also call \u03b5-winner.\nDefinition 2. (\u03b5-WINNER) Given an n-voter voting profile \u227b over a set of candidates C and a voting rule r, a candidate w is called an \u03b5\u2013winner if w can be made winner by changing at most \u03b5n votes in \u227b.\nNotice that there always exist an \u03b5-winner in every election since a winner is also an \u03b5-winner. We show that finding even an \u03b5-winner deterministically requires large space when the number of votes is large [see Theorem 14]. However, we design space efficient randomized algorithms which outputs an \u03b5-winner of an election with probability at least 1 \u2212 \u03b4. The problem that we study here is called (\u03b5, \u03b4)-WINNER DETERMINATION problem and is defined as follows. Definition 3. ((\u03b5, \u03b4)-WINNER DETERMINATION) Given a voting profile \u227b over a set of candidates C and a voting rule r, determine an \u03b5\u2013winner with probability at least 1 \u2212 \u03b4. (The probability is taken over the internal coin tosses of the algorithm.)"}, {"heading": "3 Upper Bounds", "text": "In this section, we present the algorithms for the (\u03b5, \u03b4)-Winner Determination problem for various voting rules. Before embarking on specific algorithms, we first prove a few supporting results that will be used crucially in our algorithms later. We begin with the following space efficient algorithm for picking an item uniformly at random from a universe of size n below.\nObservation 1. There is an algorithm for choosing an item with probability 1 n that uses O(log logn) bits of memory and uses fair coin as its only source of randomness.\nProof. First let us assume, for simplicity, that n is a power of 2. We toss a fair coin log2 n many times and choose the item, say x, only if the coin comes head all the times. Hence the probability that the item x gets chosen is 1 n . We need O(log logn) space to toss the fair coin log2 n times (to keep track of the number of times we have tossed the coin so far). If n is not a power of 2 then, toss the fair coin \u2308log2 n\u2309 many times and we choose the item x only if the coin comes head in all the tosses conditioned on some event E. The event E contains exactly n outcomes including the all heads outcome.\nWe remark that Observation 1 is tight in terms of space complexity. We state the claim formally below, as it may be interesting in its own right.\nProposition 1. Any algorithm that chooses an item from a set of size n with probability p, for 0 < p \u2264 1 n , using a fair coin as its only source of randomness, must use \u2126(log logn) bits of memory.\nProof. The algorithm tosses the fair coin some number of times (the number of times it tosses the coin may also depend on the outcome of the previous tosses) and finally picks an item from the set. Consider a run R of the algorithm where it chooses the item, say x, with smallest number of coin tosses; say it tosses the coin t many times in this run R. This means that in any other run of the algorithm where the item x is chosen, the algorithm must toss the coin at least t number of times. Let the outcome of the coin tosses in R be r1,\u22ef, rt. Let si be the memory content of the algorithm immediately after it tosses the coin ith time, for i \u2208 [t], in the run R. First notice that if t < log2 n, then the probability with which the item x is chosen is more than 1 n , which would be a contradiction. Hence, t \u2265 log2 n. Now we claim that all the si\u2019s must be different. Indeed otherwise, let us assume si = sj for some i < j. Then the algorithm chooses the item x after tossing the coin t \u2212 (j \u2212 i) (which is strictly less than t) many times when the outcome of the coin tosses are r1,\u22ef, ri, rj+1,\u22ef, rt. This contradicts the assumption that the run R we started with chooses the item x with smallest number of coin tosses.\nAn essential ingredient in our algorithms is calculating the approximate frequencies of all the elements in a universe in an input data stream. The following result (due to [30]) provides a space efficient algorithm for that job.\nTheorem 2. Given an insertion only stream of length n over a universe of size m, there is a deterministic one pass algorithm to find the frequencies of all the items in the stream within an additive approximation of \u03b5n using O (min{1 \u03b5 (logm + logn) ,m log n}) bits of memory, for every \u03b5 > 0.\nProof. The O (1 \u03b5 (logm + logn)) space algorithm is due to [30]. On the other hand, notice that with spaceO (m logn), we can exactly count the frequency of every element, even in the turnstile model of stream, by simply keeping an array of length m (indexed by ids of the elements from the universe) each entry of which is capable of storing integers up to n.\nWe now describe streaming algorithms for the (\u03b5, \u03b4)\u2013WINNER DETERMINATION problem for various voting rules. The general idea is to sample certain number of votes uniformly at random from the stream of votes using the algorithm of Observation 1 and generate another stream of elements over some different universe. The number of votes sampled and the universe of the stream generated depend on the specific voting rule we are considering. After that, we approximately calculate the frequencies of the elements in the generated stream using Theorem 2. For simplicity, we assume that the number of votes in known in advance up to some constant factor (only to be able to apply Observation 1). We will see in Section 3.1 how to get rid of this assumption, without affecting space complexity of any of the algorithms much. We begin with the k-approval and k-veto voting rules below.\nTheorem 3. Assume that the number of votes is known to be within [c1n, c2n] for some constants c1 and c2 in advance. Then there is a one pass algorithm for the (\u03b5, \u03b4)\u2013WINNER DETERMINATION problem for the k-approval voting rule that uses O (min{k\n\u03b5 (logm + log 1 \u03b5 + log log 1 \u03b4 ) ,m(log log(k+1) \u03b5 + log log 1 \u03b4 )} + log logn) bits of memory and\nfor the k-veto voting rule that uses O(min{k \u03b5 (logm + log 1 \u03b5 + log log 1 \u03b4 ) ,m( log log(m\u2212k+1) \u03b5 + log log 1 \u03b4 )} + log logn) bits of memory.\nProof. Let us first consider the case of the k-approval voting rule. We pick the current vote in the stream with probability p (the value of p will be decided later) independent of other votes. Suppose we sample \u2113 many votes; let S = {vi \u2236 i \u2208 [\u2113]} be the set of votes sampled. From the set of sampled votes S, we generate a stream T over the universe C as follows. For i \u2208 [\u2113], let the vote vi be c1 \u227b c2 \u227b \u22ef \u227b cm. From the vote vi, we add k candidates c1,\u22ef, ck in the stream T . We know that there is a \u2113 = O( log(k+1) \u03b52 log 1 \u03b4 ) (and thus a corresponding p = \u2126( 1 n )) which ensures that for every candidate x \u2208 C, \u2223s(x) n \u2212 s\u0302(x) \u2113 \u2223 < \u03b5 3 with probability at least 1 \u2212 \u03b4 2 [15], where s(\u22c5) and s\u0302(\u22c5) are the scores of the candidates in the input stream of votes and in S respectively. Now we count s\u0302(x) for every candidate x \u2208 C within an additive approximation of \u03b5\u2113\n3 and the result\nfollows from Theorem 2 (notice that the length of the stream T is k\u2113).\nFor the k-veto voting rule, we approximately calculate the number of vetoes that every candidate gets using the same technique as above. However, for the k-veto voting rule, the corresponding bound for \u2113 is O( log(m\u2212k+1) \u03b52 log 1 \u03b4 ) which implies the result.\nBy similar techniques, we have the following algorithm for the generalized plurality rule.\nTheorem 4. Assume that the number of votes is known to be within [c1n, c2n] for any constants c1 and c2 in advance. Then there is a one pass algorithm for the (\u03b5, \u03b4)\u2013WINNER DETERMINATION problem for the generalized plurality voting rule that uses O (1\n\u03b5 (logm + log 1 \u03b5 + log log 1 \u03b4 ) + log logn)\nbits of memory.\nProof. We sample \u2113 = O( 1 \u03b52 log 1 \u03b4 ) many votes uniformly at random from the input stream of votes using the technique used in the proof of Theorem 3. For every candidate, we count both the number of approvals and disapprovals that it gets within an additive approximation of \u03b5\u2113 10 which is enough to get an \u03b5-winner. Now the space complexity follows form Theorem 2.\nWe generalize Theorem 3 to the class of scoring rules next. We need the following result in the subsequent proof which is due to [15].\nLemma 1. Let \u03b1 = (\u03b11,\u22ef, \u03b1m) be an arbitrary score vector and w the winner of an \u03b1\u2013election E . Let x be any candidate which is not a \u03b5\u2013winner. Then, s(w) \u2212 s(x) \u2265 \u03b11\u03b5n. With Lemma 1 at hand, we now present the algorithm for the scoring rules.\nTheorem 5. Assume that the number of votes is known to be within [c1n, c2n] for any constants c1 and c2 in advance. Let \u03b1 = (\u03b11,\u22ef, \u03b1m) be a score vector such that \u03b1i \u2265 0 for every i \u2208 [m]. Then there is a one pass algorithm for the (\u03b5, \u03b4)\u2013WINNER DETERMINATION problem for the \u03b1-scoring rule that uses O (\u2211mi=1 \u03b1i\n\u03b11 (log logm + log 1 \u03b5 + log log 1 \u03b4 ) + log logn), which is\nO (m (log logm + log 1 \u03b5 + log log 1 \u03b4 ) + log logn), bits of memory. Proof. Let \u03b1 = (\u03b11,\u22ef, \u03b1m) be an arbitrary score vector with \u03b1i \u2265 0 for every i \u2208 [m]. We define \u03b1\u2032i =\n\u03b1i \u2211mi=j \u03b1j (which is in [0,1]), for every i \u2208 [m]. Since scoring rules remain same even if we multiply every \u03b1i with any positive constant \u03bb, the score vectors \u03b1 and \u03b1 \u2032 correspond to same\nvoting rule. We pick the current vote in the stream with probability p (the value of p will be decided later) independent of other votes. Suppose we sample \u2113many votes; let S = {vi \u2236 i \u2208 [\u2113]} be the set of votes sampled. For i \u2208 [\u2113], let the vote vi be c1 \u227b c2 \u227b \u22ef \u227b cm. We pick the candidate ci from the vote vi with probability \u03b1 \u2032 i and define it to be ai. We compute the frequencies of the candidates in the stream S\u0304 = {ai \u2236 i \u2208 [\u2113]} within an additive factor of \u03b5\u2032n, where \u03b5\u2032 = \u03b53 . For every candidate x \u2208 C, let s(x) be the \u03b1\u2032\u2013score of the candidate x in the input stream of votes and s\u0302(x) be n\n\u2113 times the \u03b1\u2032\u2013score of the candidate x in the sampled votes S. We know that there\nexists an \u2113 = O( 1 \u03b52 log m \u03b4 ) (and thus a corresponding p = \u2126( 1 n )) which ensures that, for every candidate x \u2208 C, \u2223s(x) \u2212 s\u0302(x)\u2223 < \u03b1\u20321\u03b5\u2032n with probability at least 1 \u2212 \u03b42 [15]. Let s\u0304(x) be n\u2113 times the frequency of the candidate x \u2208 C in the stream S\u0304. We now prove the following claim from which the result follows immediately.\nClaim 1.\nPr[\u2200x \u2208 C, \u2223s\u0304(x) \u2212 s\u0302(x)\u2223 \u2264 \u03b1\u20321\u03b5\u2032n] \u2265 1 \u2212 \u03b4 2\nProof. For every candidate x \u2208 C and every i \u2208 [\u2113], we define a random variable Xi(x) to be 1 if ai = x and 0 otherwise. Then, s\u0304(x) = n\u2113 \u2211i\u2208[\u2113]Xi(x). We have, E [s\u0304(x)] = s\u0302(x). Now using Chernoff bound from Theorem 1, we have the following:\nPr[\u2223s\u0304(x) \u2212 s\u0302(x)\u2223 > \u03b1\u20321\u03b5\u2032n] = Pr[\u2223n\u2113 \u2211 i\u2208[\u2113] Xi(x) \u2212 s\u0302(x)\u2223 > \u03b1\u20321\u03b5\u2032n]\n= Pr[\u2223 \u2211 i\u2208[\u2113] Xi(x) \u03b1\u20321 \u2212 \u2113s\u0302(x) \u03b1\u20321n \u2223 > \u03b5\u2032\u2113] \u2264 2exp{\u2212\u03b52\u03b1\u20321n\u2113 3s\u0302(x) } \u2264 2exp{\u2212\u03b52\u2113 3\n} The fourth inequality follows from the fact that s\u0302(x) \u2264 \u03b1\u20321n for every candidate x \u2208 C. Now we use the union bound to get the following.\nPr[\u2200x \u2208 C, \u2223s\u0304(x) \u2212 s\u0302(x)\u2223 \u2264 \u03b1\u20321\u03b5\u2032n] \u2265 1 \u2212 \u2211 x\u2208C 2exp{\u2212\u03b52\u2113 3 } \u2265 1 \u2212 \u03b4 2\nThe second inequality follows from an appropriate choice of \u2113 = O( 1 \u03b52 log m \u03b4 ).\nWe estimate the frequency of every candidate in S\u0304 within an additive approximation ratio of \u03b1\u20321\u03b5\u2113 and output the candidate w with maximum estimated frequency as the winner of the election. The candidate w is an \u03b5\u2013 winner (follows from Lemma 1) with probability at least 1\u2212\u03b4 (follows from Claim 1). The space complexity of this algorithm follows from Theorem 2 (since 1 \u03b1\u2032 1 = \u2211mi=1 \u03b1i \u03b11 \u2264 m\u03b11 \u03b11 =m) and Observation 1.\nWe present next the streaming algorithm for the approval voting rule. It is again obtained by running a frequency estimation algorithm on samples from a stream.\nTheorem 6. Assume that the number of votes is known to be within [c1n, c2n] in advance, for some constants c1 and c2. Then there is a one pass algorithm for the (\u03b5, \u03b4)\u2013WINNER DETERMINATION problem for the approval voting rule that uses O (m (log logm + log 1\n\u03b5 + log log 1 \u03b4 ) + log logn) bits\nof memory.\nProof. We sample \u2113 many votes using the algorithm described in Observation 1 and technique described in the proof of Theorem 5. The total number of approvals in those sampled votes is at most m\u2113 and we estimate the number of approvals that every candidate receives within an additive approximation of \u03b5\u2113 2 . The result now follows from the upper bound on \u2113 [15] and Theorem 2.\nNow we move on to maximin, Copeland, Bucklin, and plurality with run off voting rules. We provide two algorithms for these voting rules, which trade off between the number of candidates m and the approximation factor \u03b5. The algorithm in Theorem 7 below, which has better space complexity when 1 \u03b5 is small compared to m, simply stores all the sampled votes. Theorem 7. Assume that the number of votes is known to be within [c1n, c2n] in advance, for some constants c1 and c2. Then there is a one pass algorithm for the (\u03b5, \u03b4)\u2013WINNER DETERMINATION problem for the maximin, Bucklin, and plurality with run off voting rules that use O (m log2 m log 1\u03b4 \u03b52\n+ log logn) bits of memory and for the Copeland voting rule that uses O (m log4 m log 1\u03b4\n\u03b52 + log logn) bits of memory.\nProof. We sample \u2113 many votes from the input stream of votes uniformly at random and simply store all of them. Notice that we can store a vote using space O(m logm). The result now follows from the upper bound on \u2113 [15] and Observation 1.\nNext we consider the case when 1 \u03b5 is large compared to m. Theorem 8. Assume that the number of votes is known to be within [c1n, c2n] in advance, for some constants c1 and c2. Then there is a one pass algorithm for the (\u03b5, \u03b4)\u2013WINNER DETERMINATION problem for the maximin, Copeland, Bucklin, and plurality with runoff voting rules that uses O (m2 (log logm + log 1 \u03b5 + log log 1 \u03b4 ) + log logn) bits of memory. Proof. For each voting rule mentioned in the statement, we sample \u2113many votes S = {vi \u2236 i \u2208 [\u2113]} uniformly at random from the input stream of votes using the algorithm used in Observation 1 and the technique used in the proof of Theorem 5. From S, we generate another stream S\u0304 of elements belonging to a different universe U (which depends on the voting rule under consideration). Finally, we calculate the frequencies of the elements of S\u0304, using Theorem 2, within an additive approximation of \u03b5\u2113 2 for maximin, Bucklin, and plurality with runoff voting rules and \u03b5\u2113 2 logm for the Copeland voting rule. The difference of approximation factor is due to [15]. We know that \u2113 = O ( log m\u03b4 \u03b52\n) for maximin, Bucklin, and plurality with run off voting rules and \u2113 = O ( log3 m\u03b4\n\u03b52 ) for the Copeland voting rule [15]. This bounds on \u2113 prove the result once we\ndescribe S\u0304 and U . Below, we describe the stream S\u0304 and the universe U for individual voting rules. Let the vote vi be c1 \u227b c2 \u227b \u22ef \u227b cm.\n\u2022 maximin, Copeland: U = C \u00d7 C. From the vote vi, we put (cj , ck) in S\u0304 for every j < k. \u2022 Bucklin: U = C \u00d7 [m]. From the vote vi, we put (cj , k) in S\u0304 for every j \u2264 k. \u2022 plurality with runoff: U = C \u00d7 C. From the vote vi, we put (cj , ck) in S\u0304 for every j < k and(c1, c1). In the plurality with runoff voting rule, we need to estimate the plurality score of\nevery candidate which we do by estimating the frequencies of the elements of the (x,x) in S\u0304. We also need to estimate DE(x, y) for every candidate x, y \u2208 C which we do by estimating the frequencies of the elements of the form (x, y)."}, {"heading": "3.1 Unknown stream length", "text": "Now we consider the case when the number of voters is not known beforehand. The idea is to use reservoir sampling ([35]) along with approximate counting ([18, 31]) to pick an element from the stream almost uniformly at random. The following result shows that we can do so in a space efficient manner.\nTheorem 9. (Theorem 7 of [19]) Given an insertion only stream of length n (n is not known to the algorithm beforehand) over a universe of sizem, there is a randomized one pass algorithm that outputs, with probability at least 1 \u2212 \u03b4, the element at a random position X \u2208 [n] such that, for every i \u2208 [n], \u2223Pr{X = i}\u2212 1\nn \u2223 \u2264 \u03b5 n using O(log 1 \u03b4 + log 1 \u03b5 + log logn+ logm) bits of memory, for every\n\u03b5 \u2208 (0,1] and \u03b4 > 0. Recall that Theorem 2 only works for insertion only streams. However, as the stream progresses, the element chosen by Theorem 9 changes; so, we cannot invoke Misra-Gries to do frequency estimation on a set of samples given by Theorem 9. For streams with both insertions and deletions, we have the following result which is due to count-min sketch [12].\nTheorem 10. Given a turnstile stream of length n over a universe of size m, there is a randomized one pass algorithm to find the frequencies of the items in the stream within an additive approximation of \u03b5n with probability at least 1 \u2212 \u03b4 using O ( logm \u03b5 log(1 \u03b4 ) (logm + logn)) bits of memory, for every \u03b5 > 0 and \u03b4 > 0.\nFrom Theorem 9 and 10 and from the proofs of Theorem 2, 4 to 6 and 8, we get the following.\nCorollary 1. Assume that the number of votes n is not known beforehand. Then there is a one pass algorithm for the (\u03b5, \u03b4)\u2013WINNER DETERMINATION problem for k-approval, k-veto, generalized plurality, approval, maximin, Copeland, Bucklin, and plurality with run off voting rules that uses logm log 1 \u03b4 times more space than the corresponding algorithms when n is known beforehand upto a constant factor.\nProof. We use reservoir sampling with approximate counting from Theorem 9. The resulting stream that we generate have both positive and negative updates (since in reservoir sampling, we sometimes replace an item we previously sampled). Now we approximately estimate the frequency of every item in the generated stream using Theorem 10.\nAgain from Theorem 7 and 9, we get the following result which provides a better space upper bound than Corollary 1 when the number of candidates m is large.\nCorollary 2. Assume that the number of votes n is not known beforehand. Then there is a one pass algorithm for the (\u03b5, \u03b4)\u2013WINNER DETERMINATION problem for the maximin, Bucklin, and plurality with run off voting rules that use O (m log2 m log 1\u03b4\n\u03b52 + log logn) bits of memory and for the\nCopeland voting rule that uses O (m log4 m log 1\u03b4 \u03b52 + log logn) bits of memory."}, {"heading": "3.2 Sliding Window Model", "text": "Suppose we want to compute an \u03b5-winner of the last n many votes in an infinite stream of votes for various voting rules. The following result shows that there is an algorithm, with space complexity same as Theorem 9, to sample a vote from the last n votes in a stream.\nTheorem 11. ([6]) Given an insertion only stream over a universe of sizem, there is a randomized one pass algorithm that outputs, with probability at least 1 \u2212 \u03b4, the element at a random position X from last n positions such that, for every i \u2208 [n], \u2223Pr{X = i} \u2212 1 n \u2223 \u2264 \u03b5 n using O(log 1 \u03b4 + log 1 \u03b5 + log logn + logm) bits of memory, for every \u03b5 \u2208 (0,1] and \u03b4 > 0. Theorem 11 immediately provides results same as Corollary 1 and 2, where n is the window size."}, {"heading": "4 Lower Bounds", "text": "In this section, we prove space complexity lower bounds for the (\u03b5, \u03b4)\u2013WINNER DETERMINATION problem for various voting rules. We reduce certain communication problems to the (\u03b5, \u03b4)\u2013WINNER DETERMINATION problem for proving space complexity lower bounds. Let us first introduce those communication problems with necessary results."}, {"heading": "4.1 Communication Complexity", "text": "Definition 4. (AUGMENTED-INDEXINGm,t) Let t and m be positive integers. Alice is given a string x = (x1,\u22ef, xt) \u2208 [m]t. Bob is given an integer i \u2208 [t] and (x1,\u22ef, xi\u22121). Bob has to output xi. The following communication complexity lower bound result is due to [16] by a simple extension of the arguments of Bar-Yossef et al [4].\nLemma 2. R 1\u2212way \u03b4 (AUGMENTED-INDEXINGm,t) = \u2126((1 \u2212 \u03b4)t logm) for any \u03b4 < 1 \u2212 32m . Also, we recall the multi-party version of the set-disjointness problem.\nDefinition 5. (DISJ promise m,t ) We have t sets X1,\u22ef,Xt each a subset of [m]. We have t players and player i is holding the set Xi. We are also given the promise that either Xi \u2229Xj = \u2205 for every i \u2260 j or there exist an element y \u2208 [m] such that y \u2208 Xi for every i \u2208 [t] and (Xi\u2216{y})\u2229(Xj \u2216{y}) = \u2205 for every i \u2260 j. The output DISJ\npromise m,t (X1,\u22ef,Xt) is 1 if Xi \u2229Xj = \u2205 for every i \u2260 j and 0 else.\nLemma 3 (Proved in [4, 8].). R 1\u2212way \u03b4 (DISJpromisem,t ) = \u2126(mt ), for any \u03b4 \u2208 [0,1) and t. The following communication problem is very useful for us.\nDefinition 6. (MAX-SUMm,t) Alice is given a string x = (x1, x2,\u22ef, xt) \u2208 [m]t of length t over universe [m]. Bob is given another string y = (y1, y2,\u22ef, yt) \u2208 [m]t of length t over the same universe [m]. The strings x and y is such that the index i that maximizes xi + yi is unique. Bob has to output the index i \u2208 [t] which satisfies xi + yi =maxj\u2208[t]{xj + yj}. We establish the following one way communication complexity lower bound for the MAX-SUMm,t problem by reducing it from the AUGMENTED-INDEXING2,t log m problem.\nLemma 4. R 1\u2212way \u03b4 (MAX-SUMm,t) = \u2126(t logm), for every \u03b4 < 14 .\nProof. We reduce the AUGMENTED-INDEXING2,t log m problem to MAX-SUM8m,t+1 problem thereby proving the result. Let the inputs to Alice and Bob in the AUGMENTED-INDEXING2,t log m instance be (a1, a2,\u22ef, at logm) \u2208 {0,1}t logm and (a1,\u22ef, ai\u22121) respectively. The idea is to construct a corresponding instance of the MAX-SUM8m,t+1 problem that outputs t + 1 if and only if ai = 0. We achieve this as follows. Alice starts execution of the MAX-SUM8m,t+1 protocol using the vector x = (x1, x2,\u22ef, xt+1) \u2208 [8m]t+1 which is defined as follows: the binary representation of xj is (0,0, a(j\u22121) logm+1, a(j\u22121) logm+2, a(j\u22121) logm+3,\u22ef, aj logm,0)2, for every j \u2208 [t], and xt+1 is 0. Bob participates in the MAX-SUM8m,t+1 protocol with the vector y = (y1, y2,\u22ef, yt+1) \u2208 [8m]t+1 which is defined as follows. Let us define \u03bb = \u2308 i logm\n\u2309. We define yj = 0, for every j \u2209 {\u03bb, t + 1}. The binary representation of y\u03bb is (1,0, a(\u03bb\u22121) logm+1, a(\u03bb\u22121) logm+2,\u22ef, ai\u22121,1,0,0,\u22ef,0, 0, 1)2 . Let us define an integer T whose binary representation is (0,0, a(\u03bb\u22121) logm+1, a(\u03bb\u22121) logm+2,\u22ef, ai\u22121,0,1,1,\u22ef,1)2 . We define yt+1 to be T + y\u03bb. First notice that the output of the MAX-SUM8m,t+1 instance is either \u03bb or t + 1, by the construction of y. Now observe that if ai = 1 then, x\u03bb > T and thus the output of the MAXSUM8m,t+1 instance should be \u03bb. On the other hand, if ai = 0 then, x\u03bb < T and thus the output of the MAX-SUM8m,t+1 instance should be t + 1.\nFinally, we also consider the GREATER-THAN problem.\nDefinition 7. (GREATER-THANn) Alice is given an integer x \u2208 [n] and Bob is given an integer y \u2208 [n], y \u2260 x. Bob has to output 1 if x > y and 0 otherwise.\nThe following result is due to [29, 34]. We provide a simple proof of it that seems to be missingIV in the literature.\nLemma 5. R 1\u2212way \u03b4 (GREATER-THANn) = \u2126(logn), for every \u03b4 < 14 . Proof. We reduce the AUGMENTED-INDEXING2,\u2308log n\u2309+1 problem to the GREATER-THANn problem thereby proving the result. Alice runs the GREATER-THANn protocol with its input number whose representation in binary is a = (x1x2\u22efx\u2308logn\u23091)2. Bob participates in the GREATER-THANn protocol with its input number whose representation in binary is b = (x1x2\u22efxi\u221211 0\u22ef0\u00b1\n(\u2308logn\u2309\u2212i+1) 0\u2032s )2. Now xi = 1 if and only if a > b."}, {"heading": "4.2 Reductions", "text": ""}, {"heading": "4.2.1 The cases \u03b5 = 0 and \u03b4 = 0", "text": "We begin with the problem where we have to find the winner (i.e., 0-winner) for a plurality election. Notice that, we can find the winner by exactly computing the plurality score of every candidate. This requiresO(m log n) bits of memory. We prove below that, when n is much larger than m, this space complexity is almost optimal even if we are allowed to use randomization, by reducing it from the MAX-SUMn,m problem. This strengthens a similar result proved in Karp et al. [22] only for deterministic algorithms.\nTheorem 12. Any one pass (0, \u03b4)\u2013WINNER DETERMINATION algorithm for the plurality and generalized plurality election must use \u2126(m log(n/m)) bits of memory, for any \u03b4 \u2208 [0, 1\n4 ).\nIVA similar proof appears in [23] but theirs gives a weaker lower bound.\nProof. We prove the result for (0, \u03b4)\u2013WINNER DETERMINATION problem for the plurality election. This gives the result for the generalized plurality election since every plurality election is also a generalized plurality election. Consider the MAX-SUMn,m problem where Alice is given a string x = (x1,\u22ef, xm) \u2208 [n]m and Bob is given another string y = (y1,\u22ef, ym) \u2208 [n]m. The candidate set of our election is [m]. The votes would be such that the only winner will be the candidate i such that i \u2208 argmaxj\u2208[m]{xj + yj}. Moreover, the winner would be known to Bob, thereby proving the result. Thus Bob can output xi correctly whenever our (0, \u03b4)\u2013WINNER DETERMINATION algorithm outputs correctly. Alice generates xj many plurality votes for the candidate j, for every j \u2208 [m]. Alice now sends the memory content to Bob. Bob resumes the run of the algorithm by generating yj many plurality votes for the candidate j, for every j \u2208 [m]. The plurality score of candidate j is (xj + yj) and thus the plurality winner will be a candidate i such that i \u2208 argmaxj\u2208[m]{xj + yj}. Notice that the total number of votes is at most 2mn. The result now follows from Lemma 4.\nFor the case when m and n are comparable, the following result is stronger. We prove this by exhibiting a reduction from the DISJ promise m,3 problem. Theorem 13. Any one pass (0, \u03b4)\u2013WINNER DETERMINATION algorithm for the plurality and generalized plurality election must use \u2126(min{m,n}) bits of memory, for any \u03b4 \u2208 [0,1). Proof. Suppose we have a one pass (0, \u03b4)\u2013WINNER DETERMINATION algorithm for the plurality election that uses s bits of memory. We will demonstrate a one-way three party protocol to compute DISJ promise m,3 function using 2s bits of communication thus proving the result. We have the candidate set [m + 1]. The protocol is as follows. Player 1 starts running the one pass (0, \u03b4)\u2013WINNER DETERMINATION algorithm on the input X1 \u222a {m + 1}. Once player 1 is done reading all its input, it sends its memory content to player 2. This needs at most s bits of communication. Player 2 resumes the run of the algorithm with input X2 \u222a {m + 1} and sends its memory content to player 3. Again this needs at most s bits of communication. Player 3 resumes the run of the algorithm on input X3 and output 1 if and only if the winner is m + 1 and 0 else. Notice that, if the Xi \u2229 Xj = \u2205 for every i \u2260 j then, the only winner of the votes (X1,m + 1,X2,m + 1,X3) is the candidate m + 1 with a plurality score of two. On the other hand, if there exist an element y \u2208 [m] such that y \u2208 Xi for every i \u2208 [t] and (Xi \u2216 {y}) \u2229 (Xj \u2216 {y}) = \u2205 for every i \u2260 j then, the only winner of the votes(X1,m + 1,X2,m + 1,X3) is the candidate y with a plurality score of three. The number of candidates in the election above is m + 1 and the number of votes n is \u2223X1\u2223 +\u2223X2\u2223+ \u2223X3\u2223+ 2(m + 1) = \u0398(m). This gives a space complexity lower bound of \u2126(min{m,n}). Theorem 12 and 13 give space complexity lower bounds for the case \u03b5 = 0. Next, we consider the other extreme case: deterministically find an \u03b5-winner, corresponding to \u03b4 = 0.\nTheorem 14. Assume \u03b5 < 1 5 . Then any one pass (\u03b5,0)\u2013WINNER DETERMINATION algorithm for the plurality election must use \u2126(logn) bits of memory, even if the number of voters is known up to a factor of 2 and the number of candidates is only 2. The same applies for generalized plurality, scoring rules, maximin, Copeland, Bucklin, and plurality with run off voting rules.\nProof. For the sake of contradiction, we assume that the number of possible memory contents of the algorithm is o(n), since otherwise the algorithm uses \u2126(logn) space and we have nothing to prove. Our candidate set is {0,1}. We will generate two vote streams, say R1 and R2, in such a way that the final state of the algorithm would be same; however \u03b5\u2013winner would be different for the two streams thus providing the contradiction we are looking for.\nLet s0 be the starting state of the algorithm. Consider the stream of votes for 1 and let the algorithm repeats its state for the first time after reading i many 1 votes. Let the state of the algorithm after reading ith 1 vote be same as the state the algorithm was after it read jth 1 vote. Let us call \u00b5 = i \u2212 j. Clearly \u00b5 = o(n). Then there exist \u03b41, \u03b42 = o(n) such that the state the algorithm will be after reading n\n4 \u2212 \u03b41 many votes for 1 is same as the state it will be after\nreading 3n 4 + \u03b42 many votes for 1. Let R1 be the stream of n 4 \u2212 \u03b41 many votes for 1 followed by n 2 many votes for 0. Let R2 be the stream of 3n 4 + \u03b42 many votes for 1 followed by n 2 many votes for 0. By construction the output of the algorithm is same for both the streams R1 and R2. However, candidate 1 is only \u03b5-winner in R1 and candidate 0 is only \u03b5-winner in R2. For elections with two candidates, scoring rules, maximin, Copeland, Bucklin, and plurality with run off voting rules are same as the plurality voting rule."}, {"heading": "4.2.2 Lower Bounds for Approximate and Randomized algorithms", "text": "Now we move on and show space complexity lower bounds for general (\u03b5, \u03b4)\u2013WINNER DETERMINATION problem for various voting rules. The observation below immediately follows from the fact that the algorithm has to output a candidate as an \u03b5-winner.\nObservation 2. Every (\u03b5, \u03b4)\u2013WINNER DETERMINATION algorithm, for all the voting rules considered in this paper, needs \u2126(logm) bits of memory. We show next a space complexity lower bound of \u2126(1\n\u03b5 log 1 \u03b5 ) bits for the (\u03b5, \u03b4)\u2013WINNER DETER-\nMINATION problem for various voting rules.\nTheorem 15. Suppose the number of candidatesm is at least 1 \u03b5 . Any one pass (\u03b5, \u03b4)\u2013WINNER DETERMINATION algorithm for approval, k-approval, for k = O(m\u03bb) for every \u03bb \u2208 [0,1), generalized plurality, Borda, maximin, Copeland, and plurality with run off elections must use \u2126((1\u2212\u03b4)1\n\u03b5 log 1 \u03b5 )\nbits of memory, even when the number of votes are exactly known beforehand, for every 1 \u2212 \u03b4 > 3\u03b5 2 . Proof. We will show that, when m \u2265 1 \u03b5 , we need \u2126( 1\u221a \u03b5 log 1 \u03b5 ) bits of memory for solving the (\u221a\u03b5 8 , \u03b4)\u2013WINNER DETERMINATION problem, thereby proving the result. Consider the AUGMENTED-INDEXING1/\u221a\u03b5,1/\u221a\u03b5 problem where Alice is given a string x = (x1, x2,\u22ef, x1/\u221a\u03b5) \u2208 [1/\u221a\u03b5]1/\u221a\u03b5 and Bob is given an integer i \u2208 [1/\u221a\u03b5] and (x1,\u22ef, xi\u22121). The candidate set of the election, that we generate, is [1/\u221a\u03b5] \u00d7 [1/\u221a\u03b5]. The overview of the technique is as follows: Alice generates a stream of votes and runs the algorithm, then sends the memory content to Bob, and Bob resumes the run of the algorithm with another stream of votes (both the streams of votes depend on the voting rule under consideration) in such a way that the only \u221a \u03b5\n8 \u2013winner will be\nthe candidate (xi, i). Thus Bob can output xi correctly if and only if the (\u221a\u03b5/8, \u03b4)\u2013WINNER DETERMINATION algorithm outputs correctly. Now the result follows from Lemma 2. The elections for specific voting rules are as follows. Let n be the number of votes.\n\u2022 k-approval for k = O(m\u03bb) for every \u03bb \u2208 [0,1), approval, and generalized plurality: It is enough to prove the result for the k-approval voting rule for k = O(m\u03bb) for every \u03bb \u2208 [0,1), since every k-approval election is also an approval election. For k = 1, we get the result\nfor the plurality voting rule and thus for the generalized plurality voting rule, since every plurality election is also a generalized plurality election. \u2013 Case 1: k \u2264 \u221a m: Alice generates a stream of n\n2 votes in such a way that the k-approval score of every candidate in {(xj , j) \u2236 j \u2208 [1/\u221a\u03b5]} is at least \u230ak\u221a\u03b5n/2\u230b and the k-approval score of any other candidate is 0. Alice now sends the memory content of the algorithm to Bob. Bob resumes the run of the algorithm by generating another stream of n/2 votes\nin such a way that the k-approval score of every candidate in {(j, i) \u2236 j \u2208 [1/\u221a\u03b5]} is at least \u230ak\u221a\u03b5n/2\u230b and the k-approval score of any other candidate is 0. The score of the candidate (xi, i) is at least \u230ak\u221a\u03b5n\u230b where as the score of every other candidate is at most \u2308k\u221a\u03b5n/2\u2309. Hence the only \u221a \u03b5/8\u2013winner is (xi, i).\n\u2013 Case 2: k > \u221a m and k = O(m\u03bb) for any \u03bb \u2208 [0.5,1): Alice generates a stream of n\n2 votes\nin such a way that the k-approval score of every candidate in {(xj , j) \u2236 j \u2208 [ 1\u221a\u03b5]} is at least n 2 and the k-approval score of any other candidate is at most \u2308(k \u2212 1\u221a \u03b5 )n/ ( 2\u221a \u03b5 ( 1\u221a \u03b5 \u2212 1))\u2309, which is at most n 2 \u2212 \u221a \u03b5 2 n for sufficiently small constant \u03b5 (depending on \u03bb). Alice now sends the memory content of the algorithm to Bob. Bob resumes the run of the algorithm by generating another stream of n 2 votes in such a way that the k-approval score of every candidate in {(j, i) \u2236 j \u2208 [ 1\u221a \u03b5 ]} is at least n 2 and the k-approval score of any other candidate is \u2308(k \u2212 1\u221a \u03b5 ) n2\u221a\n\u03b5 ( 1\u221a \u03b5 \u22121)\u2309. In this case also the only\n\u221a \u03b5\n8 \u2013winner is (xi, i).\n\u2022 Borda, Bucklin: Alice generates a stream of n 2 votes where the candidates in {(x\u2113, \u2113), \u2113 \u2208[1/\u221a\u03b5]} are uniformly distributed in top 1/\u221a\u03b5 positions of the votes and the rest of the candi-\ndates are uniformly distributed in bottom 1/\u03b5 \u2212 1/\u221a\u03b5 positions of the votes. Alice now sends the memory content to Bob and Bob resumes the run of the algorithm by generating another stream of n/2 votes where the candidates in {(\u2113, i), \u2113 \u2208 [1/\u221a\u03b5]} are uniformly distributed in top 1/\u221a\u03b5 positions of the votes and the rest of the candidates are uniformly distributed in bottom 1/\u03b5 \u2212 1/\u221a\u03b5 positions of the votes. The Borda score of the candidate (xi, i) is (1/\u03b5 \u2212 1/2\u221a\u03b5)n whereas the Borda score of every other candidate is at most (1/2\u03b5 \u2212 1/4\u221a\u03b5)n. Hence, the only\u221a \u03b5/8\u2013winner for the Borda voting rule is (xi, i), since each vote change can reduce or increase the Borda score of any candidate by at most 1/\u03b5. The candidate (xi, i) is ranked within top 2/3\u221a\u03b5 positions in 2n/3 many votes, whereas any other candidate is ranked within top 2/3\u221a\u03b5 positions in at most n/3 many votes. Hence the only \u221a \u03b5/8\u2013winner for the Bucklin voting rule is (xi, i). \u2022 Any Condorcet consistent voting rule, Plurality with runoff: Let us define X = {(x\u2113, \u2113) \u2236 \u2113 \u2208 [1/\u221a\u03b5]}, Y = [1/\u221a\u03b5] \u00d7 [1/\u221a\u03b5] \u2216X. Suppose \u00d0\u2192X and \u00d0\u2192Y are arbitrary but fixed ordering of the candidates in X and Y respectively. For every \u2113 \u2208 [1/\u221a\u03b5], Alice generates \u221a\u03b5n/4 votes of the form (x\u2113, \u2113) \u227b \u00d0\u00d0\u00d0\u00d0\u00d0\u00d0\u00d0\u00d0\u2192X \u2216 {(x\u2113, \u2113)} \u227b \u00d0\u2192Y and another \u221a\u03b5n/4 votes of the form \u2190\u00d0\u00d0\u00d0\u00d0\u00d0\u00d0X \u2216 (x\u2113, \u2113) \u227b (x\u2113, \u2113) \u227b \u00d0\u2192Y , where \u2190\u00d0X is the reverse order of \u00d0\u2192X . Alice now sends the memory content to Bob. Let us define A = {(\u2113, i) \u2236 \u2113 \u2208 [1/\u221a\u03b5]} and B = [1/\u221a\u03b5] \u00d7 [1/\u221a\u03b5] \u2216A. Suppose \u00d0\u2192A and \u00d0\u2192B are arbitrary but fixed ordering of A and B respectively. Bob resumes the run of the algorithm\nby generating another \u221a \u03b5n/4 votes of the form (\u2113, i) \u227b \u00d0\u00d0\u00d0\u00d0\u00d0\u2192A \u2216 (\u2113, i) \u227b \u00d0\u2192B and another \u221a\u03b5n/4 votes of the form \u2190\u00d0\u00d0\u00d0\u00d0\u00d0 A \u2216 (\u2113, i) \u227b (\u2113, i) \u227b\u00d0\u2192B for every \u2113 \u2208 [1/\u221a\u03b5], where \u2190\u00d0A is the reverse order of \u00d0\u2192A . The candidate (xi, i) defeats every other candidate in pairwise election by a margin of at least n4 . Also the plurality score of the candidate (xi, i) is more than the plurality score of every other candidate by at least \u221a \u03b5n. Hence the only \u221a \u03b5/8\u2013winner is (xi, i). We can prove a space lower bound of \u2126(m\u03b5 log 1 \u03b5 ) for one pass (\u03b5, \u03b4)\u2013WINNER DETERMINATION algorithms for Borda, Bucklin, Copeland, and maximin voting rules by reducing it from AUGMENTED-INDEXING1/\u03b5,m in the proof of Theorem 15. We summarize this observation below. Corollary 3. Suppose the number of candidates m is at least 1 \u03b5 . Any one pass (\u03b5, \u03b4)\u2013WINNER DETERMINATION algorithm for Borda, maximin, Copeland, and plurality with run off elections must use \u2126((1 \u2212 \u03b4)m log 1 \u03b5 ) bits of memory, even when the number of votes are exactly known beforehand, for every 1 \u2212 \u03b4 > 3\u03b5 2 .\nFor the k-veto voting rule, we prove below, again by reducing from AUGMENTED-INDEXING, a slightly weaker space complexity lower bound compared to the bounds of Theorem 15.\nTheorem 16. Suppose the number of candidates m is at least 1 \u03b5 . Any one pass (\u03b5, \u03b4)\u2013WINNER DETERMINATION algorithm for the k-veto voting rule for k = O(m\u03bb), for every \u03bb \u2208 [0,1), must use \u2126( 1\n\u03b5\u00b5 log 1 \u03b5 ), for every constant \u00b5 < 1, bits of memory, even when the number of votes are exactly\nknown beforehand, for every 1 \u2212 \u03b4 > 3\u03b5 2 . Proof. We prove the result for ( \u03b5 5 , \u03b4)\u2013WINNER DETERMINATION problem. Consider the AUGMENTED-INDEXING 1 \u03b51\u2212\u00b5 , 1 \u03b5\u00b5 problem where the first player Alice is given a string x \u2208 [ 1\n\u03b51\u2212\u00b5 ] 1\u03b5\u00b5 , while the second player Bob is given an integer i \u2208 [ 1\n\u03b5\u00b5 ] and xj for every j < i. The candidate\nset of our election is [ 1 \u03b51\u2212\u00b5 ] \u00d7 [ 1\u03b5\u00b5 ]. The votes would be such that the only \u03b55\u2013winner will be the candidate (xi, i), thereby proving the result. Thus Bob can output xi correctly whenever our (\u03b5, \u03b4)\u2013WINNER DETERMINATION algorithm outputs correctly. Alice generates a stream of n\n2\nvotes (assume n to be sufficiently large) in such a way that for every a, b \u2208 {(xj , j) \u2236 j \u2208 1\u03b5\u00b5} and x, y \u2208 [ 1\n\u03b51\u2212\u00b5 ] \u00d7 [ 1\u03b5\u00b5 ] \u2216 {(xj , j) \u2236 j \u2208 1\u03b5\u00b5}, we have s(a) \u2212 s(x) \u2265 \u03b5n2 , s(b) \u2212 1 \u2264 s(a) \u2264 s(b) + 1, and s(y) \u2212 1 \u2264 s(x) \u2264 s(y) + 1, where s(\u22c5) is the number of vetoes that a candidate receives (which is always negative or zero). This is possible since k = O(m\u03bb) for \u03bb \u2208 [0,1). Alice now sends the memory content of the algorithm. Bob resumes the run of the algorithm by generating another stream of n 2 votes in such a way that for every a\u2032, b\u2032 \u2208 {(z, i) \u2236 z \u2208 1\n\u03b51\u2212\u00b5 } and x\u2032, y\u2032 \u2208 [ 1\n\u03b51\u2212\u00b5 ] \u00d7 [ 1\u03b5\u00b5 ] \u2216 {(z, i) \u2236 z \u2208 1\u03b51\u2212\u00b5 }, we have s(a\u2032) \u2212 s(x\u2032) \u2265 \u03b5n2 , s(b\u2032) \u2212 1 \u2264 s(a\u2032) \u2264 s(b\u2032) + 1, and s(y\u2032) \u2212 1 \u2264 s(x\u2032) \u2264 s(y\u2032) + 1. Now the score of (xi, i) is more than the score of every other candidate by at least \u03b5n\n2 . Hence, the candidate (xi, i) is the unique \u03b55\u2013winner.\nFor the k-approval voting rule, we provide a stronger space complexity lower bound of \u2126(k \u03b5 log 1 \u03b5 ), when the number of candidates m is at least k \u03b52 , by reducing from AUGMENTEDINDEXING 1 \u03b5 , k \u03b5 . Theorem 17. Assume that the number of candidates m is at least k \u03b52 . Then any one pass (\u03b5, \u03b4)\u2013 WINNER DETERMINATION algorithm for the k-approval voting rule must use \u2126(k \u03b5 log 1 \u03b5 ) bits of memory.\nProof. We prove the result for ( \u03b5 5 , \u03b4)\u2013WINNER DETERMINATION problem. Consider the AUGMENTED-INDEXING 1 \u03b5 , k \u03b5 problem where Alice is given (x1,\u22ef, x k \u03b5 ) \u2208 [1 \u03b5 ]k\u03b5 and Bob is given (x1,\u22ef, xi\u22121). We will create a k-approval election in such a way that the \u03b55 -winner will reveal xi to Bob. The candidate set of our election is [1\n\u03b5 ]\u00d7 [k \u03b5 ]. For every j \u2208 [k], Alice generates \u03b5n 2 many\nvotes approving candidates in {(xk(j\u22121)+1, k(j \u2212 1) + 1), (xk(j\u22121)+2, k(j \u2212 1) + 2),\u22ef, (xkj , kj)}. Alice now sends the memory content to Bob. Let X = {(j, i) \u2236 j \u2208 [1\n\u03b5 ]}. If k \u2264 1 \u03b5 then, Bob\ngenerates n 2 votes in such a way that every candidate in X gets at least k\u03b5n 2 many approvals and the candidates in [1 \u03b5 ] \u00d7 [k \u03b5 ] \u2216 X does not get any approval from the votes that Bob generates. Now, the k-approval score of the candidate (xi, i) is at least (k + 1)\u03b5n2 , whereas every other candidate gets at most k\u03b5n\n2 many approvals. Hence, (xi, i) is the unique \u03b55 -winner. If k > 1\u03b5\nthen, Bob generates n 2 votes in such a way that every candidate in X gets n 2 many approvals and every candidate in [1 \u03b5 ] \u00d7 [k \u03b5 ] \u2216 X gets at most (k \u2212 1 \u03b5 )n 2 1 k/\u03b52\u22121/\u03b5 \u2264 n 2 \u03b52 many approvals from the votes that Bob generates. Here again the k-approval score of the candidate (xi, i) is at least(1 + \u03b5)n 2 , where as the k-approval score of every other candidate is at most \u03b5n 2 . Hence, (xi, i) is the unique \u03b5 5 -winner.\nFor the generalized plurality voting rule, we provide a \u2126( 1\u221a \u03b5 logm) space complexity lower bound, again by reducing from AUGMENTED-INDEXINGm, 1\u221a \u03b5 . This bound is better than the lower bound of Theorem 15 when m is exponentially larger compared to 1 \u03b5 . Theorem 18. Suppose the number of candidates m is at least 1\u221a \u03b5 . Any one pass (\u03b5, \u03b4)\u2013WINNER DETERMINATION algorithm for the generalized plurality rule must use \u2126( 1\u221a \u03b5 logm) bits of memory, for every 1 \u2212 \u03b4 > 3\u03b5 2 . Proof. We prove the result for ( \u03b5 5 , \u03b4)\u2013WINNER DETERMINATION problem. Consider the\nAUGMENTED-INDEXINGm, 1\u221a \u03b5 problem where Alice is given a string x = (x1,\u22ef, x 1\u221a \u03b5 ) \u2208 [m] 1\u221a\u03b5 and Bob is given an integer i \u2208 [ 1\u221a\n\u03b5 ] and (x1,\u22ef, xi\u22121). The candidate set of our election is [m]\u00d7[ 1\u221a\u03b5].\nThe votes would be such that the only \u03b5 5 \u2013winner will be the candidate (xi, i), thereby proving the result. Thus Bob can output xi correctly whenever our ( \u03b55 , \u03b4)\u2013WINNER DETERMINATION algorithm outputs correctly. Alice generates ( 1\u221a\n\u03b5 \u2212 j)\u03b5n many approvals for candidate (xj , j), for\nevery j < 1\u221a \u03b5 . Alice now sends the memory content of the algorithm. Bob resumes the run of the algorithm by generating ( 1\u221a \u03b5 \u2212 j)\u03b5n many approvals for candidate (xj, j), for every j < i. Notice that, the only \u03b5 5 -winner is the candidate (xi, i). Now the space complexity lower bound follows from Lemma 2.\nThe space complexity lower bound in Theorem 15 for the plurality voting rule matches with the upper bound of Theorem 3, when 1 \u03b5 \u2264 m \u2264 1 \u03b5O(1) . For the case when m \u2264 1 \u03b5 , we now show a matching space complexity lower bound for the plurality voting rule. We prove this result by exhibiting a reduction from the MAX-SUM 1 \u03b5 ,m problem. Theorem 19. Assume that the number of candidates m is at most 1 \u03b5 . Then any one pass (\u03b5, \u03b4)\u2013 WINNER DETERMINATION algorithm for the plurality, generalized plurality, approval, k-approval for k = O(m\u03bb), for any \u03bb \u2208 [0,1), maximin, Copeland, Bucklin, plurality with run off voting rules must use \u2126(m log 1\n\u03b5 ) bits of memory.\nProof. First, let us prove the result for the plurality voting rule. Suppose we have a one pass (\u03b5, \u03b4)\u2013WINNER DETERMINATION algorithm for the plurality election which uses s(n, \u03b5) bits of memory. Consider the communication problem MAX-SUM 1\n\u03b5 ,m. Let the inputs to Alice and Bob\nin the MAX-SUM 1 \u03b5 ,m instance be x = (x1, x2,\u22ef, xm) \u2208 [1\u03b5 ]m and y = (y1, y2,\u22ef, ym) \u2208 [1\u03b5 ]m respectively. The candidate set of the election is [m]. Alice generates xi many plurality vote for the candidate i, for every i \u2208 [m]. Alice now sends the memory content of the algorithm to Bob. Bob resumes the run of the algorithm by generating yi many plurality votes for the candidate i, for every i \u2208 [m]. Suppose i = argmaxj\u2208[m]{xj +yj} (recall from Definition 6 that there exist unique element i that maximizes xi + yi) and \u2113 \u2260 argmaxj\u2208[m]{xj + yj}. Then we have the following:\n(xi + yi) \u2212 (x\u2113 + y\u2113) \u2211j\u2208[m](xj + yj) \u2265 \u03b5 2m \u2265 \u03b52 2\nThe first inequality follows from the fact that (xi + yi) \u2212 (x\u2113 + y\u2113) \u2265 1 and \u2211j\u2208[m] xj + yj \u2264 2m\u03b5 . The second inequality follows from the assumption that m \u2264 1\n\u03b5 . Hence, whenever the (\u03b52 5 , \u03b4)\u2013\nWINNER DETERMINATION algorithm outputs an \u03b5 2\n5 -winner, Bob also outputs correctly in the\nMAX-SUM 1 \u03b5 ,m problem instance.\nFor the other voting rules, the idea is the same as above: we will generate votes in such a way that ensures that the candidate i wins if i = argmaxj\u2208[m]{xj + yj} by a margin of at least one. Below, we only specify the votes to be generated for other voting rules.\n\u2022 Generalized plurality, approval: Follows immediately from the fact that every plurality\nelection is a valid generalized plurality and approval election too.\n\u2022 k-approval for k = O(m\u03bb), for any \u03bb \u2208 [0,1): Alice (respectively Bob) generates xi (respectively yi) many votes such that candidate i gets xi many approvals and the rest (k \u2212 1)xi many approvals are equally distributed among other m \u2212 1 candidates.\n\u2022 Borda, maximin, Copeland, Bucklin, plurality with run off: Alice (respectively Bob) gen-\nerates xi (respectively yi) many votes of the form i \u227b \u00d0\u2192 C\u2212i and another xi (respectively yi)\nmany votes of the form i \u227b \u2190\u00d0 C\u2212i, where \u00d0\u2192 C\u2212i is an arbitrary but fixed order of the candidates in\nC \u2216 {i} and \u2190\u00d0C\u2212i is the reverse order of \u00d0\u2192C\u2212i. Now we show space complexity lower bounds that depend on the number of votes n. The result below is obtained by reducing from the GREATER-THANn problem. The lower bound is tight in the number of votes n.\nTheorem 20. Any one pass (\u03b5, \u03b4)\u2013WINNER DETERMINATION algorithm for the plurality voting rule must use \u2126(log logn) memory bits, even if the number of candidates is only 2, for every \u03b4 < 1\n4 .\nThe same applies for generalized plurality, scoring rules, maximin, Copeland, Bucklin, and plurality with run off voting rules.\nProof. Suppose we have a one pass (\u03b5, \u03b4)\u2013WINNER DETERMINATION algorithm for the plurality election which uses s(n) bits of space. Using this algorithm, we will show a communication protocol for the GREATER-THANn problem whose communication coplexity is s(2n) thereby proving the statement. The candidate set is {0,1}. Alice generates a stream of 2x many plurality votes for the candidate 1. Alice now sends the memory content of the algorithm. Bob resumes the run of the algorithm by generating a stream of 2y many plurality votes for the candidate 0. If x > y then the candidate 1 is the only \u03b5-winner; whereas if x < y then the candidate 0 is the only \u03b5-winner.\nFor elections with two candidates, generalized plurality, scoring rules, maximin, Copeland, Bucklin, and plurality with run off voting rules are same as the plurality voting rule."}, {"heading": "5 Conclusions and Future Work", "text": "In this work, we studied the space complexity for determining approximate winners in the setting where votes are inserted continually into a data stream. We showed that allowing randomization and approximation indeed allows for much more space-efficient algorithms. Moreover, our bounds are tight in certain parameter ranges.\nThe most immediate open question is to close the gaps between the upper and lower bounds. In particular, even for plurality, the dependence on m and \u03b5 is not tight when m is large. Also, for the other voting rules, are there more sophisticated algorithms which improve our upper bounds? In a different vein, it may be interesting to implement these streaming algorithms for use in practice (say, for participatory democracy experiments or for online social networks) and investigate how they perform. Finally, instead of having the algorithm be passive, could we improve performance by having the algorithm actively query the voters as they appear in the stream?\nAcknowledgement: We thank David Woodruff for helpful conversations about the heavy hitters problem."}], "references": [{"title": "The space complexity of approximating the frequency moments", "author": ["N. Alon", "Y. Matias", "M. Szegedy"], "venue": "Journal of Computer and System Sciences,", "citeRegEx": "3", "shortCiteRegEx": "3", "year": 1999}, {"title": "An information statistics approach to data stream and communication complexity", "author": ["Z. Bar-Yossef", "T. Jayram", "R. Kumar", "D. Sivakumar"], "venue": "In Foundations of Computer Science,", "citeRegEx": "4", "shortCiteRegEx": "4", "year": 2002}, {"title": "MJRTY- a fast majority vote algorithm", "author": ["R.S. Boyer", "J.S. Moore"], "venue": null, "citeRegEx": "5", "shortCiteRegEx": "5", "year": 1991}, {"title": "Optimal sampling from sliding windows", "author": ["V. Braverman", "R. Ostrovsky", "C. Zaniolo"], "venue": "In Proceedings of the Twenty-eighth ACM SIGMOD-SIGACT-SIGART Symposium on Principles of Database Systems,", "citeRegEx": "6", "shortCiteRegEx": "6", "year": 2009}, {"title": "Voting almost maximizes social welfare despite limited communication", "author": ["I. Caragiannis", "A.D. Procaccia"], "venue": "Artificial Intelligence,", "citeRegEx": "7", "shortCiteRegEx": "7", "year": 2011}, {"title": "Near-optimal lower bounds on the multiparty communication complexity of set disjointness", "author": ["A. Chakrabarti", "S. Khot", "X. Sun"], "venue": "In Computational Complexity,", "citeRegEx": "8", "shortCiteRegEx": "8", "year": 2003}, {"title": "Finding frequent items in data streams", "author": ["M. Charikar", "K. Chen", "M. Farach-Colton"], "venue": "Theoretical Computer Science,", "citeRegEx": "9", "shortCiteRegEx": "9", "year": 2004}, {"title": "Communication complexity of common voting rules", "author": ["V. Conitzer", "T. Sandholm"], "venue": "In Proceedings of the 6th ACM conference on Electronic commerce,", "citeRegEx": "10", "shortCiteRegEx": "10", "year": 2005}, {"title": "Finding frequent items in data streams", "author": ["G. Cormode", "M. Hadjieleftheriou"], "venue": "Proceedings of the VLDB Endowment,", "citeRegEx": "11", "shortCiteRegEx": "11", "year": 2008}, {"title": "An improved data stream summary: the count-min sketch and its applications", "author": ["G. Cormode", "S. Muthukrishnan"], "venue": "Journal of Algorithms,", "citeRegEx": "12", "shortCiteRegEx": "12", "year": 2005}, {"title": "Maintaining stream statistics over sliding windows", "author": ["M. Datar", "A. Gionis", "P. Indyk", "R. Motwani"], "venue": "SIAM Journal on Computing,", "citeRegEx": "13", "shortCiteRegEx": "13", "year": 2002}, {"title": "Frequency estimation of internet packet streams with limited space", "author": ["E.D. Demaine", "A. L\u00f3pez-Ortiz", "J.I. Munro"], "venue": "In ESA,", "citeRegEx": "14", "shortCiteRegEx": "14", "year": 2002}, {"title": "Sample complexity for winner prediction in elections", "author": ["P. Dey", "A. Bhattacharyya"], "venue": "In Proceeding of the 14th International Conference on Autonomous Systems and Multiagent Systems (AAMAS-15)", "citeRegEx": "15", "shortCiteRegEx": "15", "year": 2015}, {"title": "Periodicity in streams", "author": ["F. Erg\u00fcn", "H. Jowhari", "M. Sa\u011flam"], "venue": "In APPROX and RANDOM,", "citeRegEx": "16", "shortCiteRegEx": "16", "year": 2010}, {"title": "Finding a majority among n votes: Solution to problem 81-5", "author": ["M.J. Fischer", "S.L. Salzburg"], "venue": "Journal of Algorithms,", "citeRegEx": "17", "shortCiteRegEx": "17", "year": 1982}, {"title": "Approximate counting: a detailed analysis", "author": ["P. Flajolet"], "venue": "BIT Numerical Mathematics,", "citeRegEx": "18", "shortCiteRegEx": "18", "year": 1985}, {"title": "Applying approximate counting for computing the frequency moments of long data streams", "author": ["A. Gronemeier", "M. Sauerhoff"], "venue": "Theory Comput. Syst.,", "citeRegEx": "19", "shortCiteRegEx": "19", "year": 2009}, {"title": "External memory algorithms. chapter Computing on Data Streams, pages 107\u2013118", "author": ["M.R. Henzinger", "P. Raghavan", "S. Rajagopalan"], "venue": "American Mathematical Society,", "citeRegEx": "20", "shortCiteRegEx": "20", "year": 1999}, {"title": "Tight bounds for lp samplers, finding duplicates in streams, and related problems", "author": ["H. Jowhari", "M. Sa\u011flam", "G. Tardos"], "venue": "In Proceedings of the Thirtieth ACM SIGMODSIGACT-SIGART Symposium on Principles of Database Systems,", "citeRegEx": "21", "shortCiteRegEx": "21", "year": 2011}, {"title": "A simple algorithm for finding frequent elements in streams and bags", "author": ["R.M. Karp", "S. Shenker", "C.H. Papadimitriou"], "venue": "ACM Transactions on Database Systems (TODS),", "citeRegEx": "22", "shortCiteRegEx": "22", "year": 2003}, {"title": "On randomized one-round communication complexity", "author": ["I. Kremer", "N. Nisan", "D. Ron"], "venue": "Computational Complexity,", "citeRegEx": "23", "shortCiteRegEx": "23", "year": 1999}, {"title": "Communication Complexity", "author": ["E. Kushilevitz", "N. Nisan"], "venue": null, "citeRegEx": "24", "shortCiteRegEx": "24", "year": 1997}, {"title": "Crowdsourcing for participatory democracies: Efficient elicitation of social choice functions", "author": ["D.T. Lee", "A. Goel", "T. Aitamurto", "H. Landemore"], "venue": "In Proceedings of the Seconf AAAI Conference on Human Computation and Crowdsourcing,", "citeRegEx": "25", "shortCiteRegEx": "25", "year": 2014}, {"title": "Distributed sensor networks: A multiagent perspective, volume 9", "author": ["V. Lesser", "C.L. Ortiz Jr.", "M. Tambe"], "venue": null, "citeRegEx": "26", "shortCiteRegEx": "26", "year": 2012}, {"title": "Approximate frequency counts over data streams", "author": ["G.S. Manku", "R. Motwani"], "venue": "In Proceedings of the 28th international conference on Very Large Data Bases,", "citeRegEx": "27", "shortCiteRegEx": "27", "year": 2002}, {"title": "Efficient computation of frequent and top-k elements in data streams", "author": ["A. Metwally", "D. Agrawal", "A. El Abbadi"], "venue": "In Database Theory-ICDT", "citeRegEx": "28", "shortCiteRegEx": "28", "year": 2005}, {"title": "On data structures and asymmetric communication complexity", "author": ["P.B. Miltersen", "N. Nisan", "S. Safra", "A. Wigderson"], "venue": "J. Comput. Syst. Sci.,", "citeRegEx": "29", "shortCiteRegEx": "29", "year": 1998}, {"title": "Counting large numbers of events in small registers", "author": ["R. Morris"], "venue": "Commun. ACM,", "citeRegEx": "31", "shortCiteRegEx": "31", "year": 1978}, {"title": "Data streams: Algorithms and applications", "author": ["S. Muthukrishnan"], "venue": null, "citeRegEx": "32", "shortCiteRegEx": "32", "year": 2005}, {"title": "Sketching and streaming algorithms for processing massive data. XRDS: Crossroads, The ACM Magazine for Students, 19(1):14\u201319", "author": ["J. Nelson"], "venue": null, "citeRegEx": "33", "shortCiteRegEx": "33", "year": 2012}, {"title": "Shannon\u2019s information methods for lower bounds for probabilistic communication", "author": ["D. Smirnov"], "venue": null, "citeRegEx": "34", "shortCiteRegEx": "34", "year": 1988}, {"title": "Random sampling with a reservoir", "author": ["J.S. Vitter"], "venue": "ACM Trans. Math. Softw.,", "citeRegEx": "35", "shortCiteRegEx": "35", "year": 1985}, {"title": "Computing the margin of victory for various voting rules", "author": ["L. Xia"], "venue": "In Proceedings of the 13th ACM Conference on Electronic Commerce,", "citeRegEx": "36", "shortCiteRegEx": "36", "year": 2012}, {"title": "Some complexity questions related to distributive computing (preliminary report)", "author": ["Yao", "A.C.-C"], "venue": "In Proceedings of the eleventh annual ACM symposium on Theory of computing,", "citeRegEx": "37", "shortCiteRegEx": "37", "year": 1979}], "referenceMentions": [], "year": 2015, "abstractText": "We investigate the problem of winner determination from computational social choice theory in the data stream model. Specifically, we consider the task of summarizing an arbitrarily ordered stream of n votes on m candidates into a small space data structure so as to be able to obtain the winner determined by popular voting rules. As we show, finding the exact winner requires storing essentially all the votes. So, we focus on the problem of finding an \u03b5-winner, a candidate who could win by a change of at most \u03b5 fraction of the votes. We show non-trivial upper and lower bounds on the space complexity of \u03b5-winner determination for several voting rules, including k-approval, k-veto, scoring rules, approval, maximin, Bucklin, Copeland, and plurality with run off.", "creator": "LaTeX with hyperref package"}}}