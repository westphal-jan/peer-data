{"id": "1509.04513", "review": {"conference": "arxiv", "VERSION": "v1", "DATE_OF_SUBMISSION": "15-Sep-2015", "title": "On Reasoning with RDF Statements about Statements using Singleton Property Triples", "abstract": "the singleton property ( sp ) approach has been proposed originally for digitally representing and querying hierarchical metadata databases about rdf triples such ( as spectral provenance, time, operational location, date and linguistic evidence. in learning this special approach, one singleton property is created to locally uniquely represent a relationship matched in a physically particular context, and in as general, only generates a globally large computational property hierarchy assisting in determining the schema. measuring it consequently has repeatedly become the subject of potentially important moral questions from semantic web systems practitioners. can an existing software reasoner easily recognize the singleton class property triples? and how? asks if the singleton d property reference triples describe a lone data triple, then how can a reasoner infer this data query triple from the usual singleton property triples? or would the large - property hierarchy affect reacting the reasoners differently in some minor way? if we address these technical questions in both this comprehensive paper and even present our study method about explaining the reasoning quantum aspects of the singleton properties. we propose taking a computational simple mechanism to easily enable existing human reasoners to recognize the singleton property confidence triples, as well? as to infer roughly the data triples described centrally by the singleton relational property correlation triples. gradually we further evaluate the useful effect of the singleton chained property triples used in refining the reasoning processes by comparing the performance on singleton rdf content datasets mostly with local and without singleton price properties. first our query evaluation uses devices as benchmark the finite lubm singleton datasets and the lubm - sp datasets derived purely from lubm with temporal valued information quantities added through singleton properties.", "histories": [["v1", "Tue, 15 Sep 2015 12:10:37 GMT  (30kb)", "http://arxiv.org/abs/1509.04513v1", null]], "reviews": [], "SUBJECTS": "cs.AI cs.DB", "authors": ["vinh nguyen", "olivier bodenreider", "krishnaprasad thirunarayan", "gang fu", "evan bolton", "n\\'uria queralt rosinach", "laura i furlong", "michel dumontier", "amit sheth"], "accepted": false, "id": "1509.04513"}, "pdf": {"name": "1509.04513.pdf", "metadata": {"source": "CRF", "title": "On Reasoning with RDF Statements about Statements using Singleton Property Triples", "authors": ["Vinh Nguyen", "Olivier Bodenreider", "Krishnaprasad Thirunarayan", "Gang Fu", "Evan Bolton", "N\u00faria Queralt Rosinach", "Laura I. Furlong", "Michel Dumontier", "Amit Sheth"], "emails": ["vinh@knoesis.org", "tkprasad@knoesis.org", "amit@knoesis.org", "olivier@nlm.nih.gov", "gang.fu@nih.gov,", "bolton@ncbi.nih.gov", "nqueralt@imim.es", "lfurlong@imim.es", "michel.dumontier@stanford.edu"], "sections": [{"heading": null, "text": "ar X\niv :1\n50 9.\n04 51\n3v 1\n[ cs"}, {"heading": "1 Introduction", "text": "\u201cThe basic model contains just the concept of an assertion, and the concept of quotation - making assertions about assertions. This is introduced because (a) it will be needed later anyway and (b) most of the initial RDF applications are for data about data (metadata) in which assertions about assertions are basic,\neven before logic.\u201d (Tim Berners-Lee, Semantic6, 1998). Note that in Semantic Web, the term assertion can be used interchangeably for triple or statement.\nThe RDF data model contains two basic concepts: the concept of triples and the concept of triples about triples. An RDF triple t consists of a subject s, a predicate p, and an object o. This concept of an RDF triple is intuitive and formally defined within the latest W3C Recommendations such as the RDF 1.1 concept and abstract syntax [6], and the RDF 1.1 formal semantics [15]. For triples about triples, RDF reification was previously presented as a standard in the W3C 2004 Recommendations [14]. However, this RDF reification has been withdrawn from the normative sections in the latest RDF Recommendation [15] and has become non-standard because of its limitations. Therefore, the concept of triples about triples has not yet been formally defined in the latest W3C RDF Recommendations. Representing triples about triples is a basic requirement for the RDF data model but remains an unresolved problem.\nTo further motivate the need for a good mechanism to represent triples about triples and reason on them, we use the following running example.\nMotivating example. We adopt the example from the popular Lehigh University Benchmark (LUBM) [10]. Consider the worksFor relationship between professors and universities: it does not represent the duration of the relationship, which is very common in a real world setting. We add the temporal dimension into this LUBM example as provided in Table 1 (prefixes are eliminated for readability).\nNext, we discuss some kinds of metadata about the triples that are commonly used across various domains.\nTime and Space. Knowledge evolves over time, and a proposition may only hold at a specific time point, duration, or interval [13]. An event may happen at one specific time and location. In the example at hand, the fact that ProfessorA works for University1 only holds during the period from 1994 to\n6 http://www.w3.org/DesignIssues/Semantic.html\n2006. Time-sensitive data across multiple fields such as news, stocks, shopping carts, banking transactions, sensor networks, and social media networks are very common on the Web. The capability of representing time and space dimensions is essential in many real world systems and applications, especially in the systems extracting knowledge from the Web such as Knowledge Vault [8] recently created by Google, and YAGO2S [16]. Other smart applications that use sensors, such as real-time remote monitoring of patients diagnosed with congestive heart failure, can benefit from temporal information [17]. Temporal and spatial databases have been researched over decades [12,21,26] and supported by various commercial database systems. Enabling the representation of time and space in which RDF statements hold true is crucial to the development of various Semantic Web applications addressing such real world requirements of spatio-temporal content.\nProvenance. Provenance provides information about the origin of an artifact or a piece of data. It involves entities, activities, and people/software/agents in the process of producing a piece of data. When it comes to Semantic Web, the provenance of an RDF assertion becomes important for integrating data from multiple sources. Data provenance can also be used for forming assessments about data quality, reliability, and trustworthiness. For example, is an assertion verified by a researcher more significant than one being reported in the literature? Tracking the lineage of data is essential in scientific workflows because it allows reproducibility. Reproducible datasets with explicit provenance information are usually considered more reliable, and hence, encouraged for sharing and publishing to the Web. Provenance is studied in various applications across different domains like biomedicine [2,27,31,32], geoscience [7,30], and others [25].\nAs metadata about triples is very common in modeling data, we believe that many Semantic Web datasets such as PubChem [3], Bio2RDF [1], and DisGeNET [22] will benefit from a concensus on a standard method for representing triples about triples recommended by the W3C. However, such a concensus has yet to be reached.\nSeveral attempts have been made in recent years to address the problem of representing metadata (e.g., provenance, time, and space) about RDF triples. [4,9,20,23]. These approaches can be classified into three main groups: triple (reification [14], singleton property[20]), quadruple (named graph [5]), and quintuple (RDF+ [24]). Among these approaches, the RDF reification, named graph, and RDF+ have been studied in depth, but have failed to emerge as a standard for representing metadata about triples. While these approaches are intuitive, they all have certain limitations.\nAn RDF triple is reified by creating an instance of RDF Statement class and pointing this instance to the subject, predicate, and object of the RDF triple. The reification of a triple does not entail the triple, and is not entailed by it [14]. As the presence of the reified triple is not bound to the triple itself, it is not possible to reason about the metadata of the triple through the reified triple.\nThe named graph [5] originally introduced a fourth element to represent the provenance of the graph. Later, it was generalized to denote a set of RDF triples. A named graph can thus be used for annotating a triple and can serve as a unique\nidentifier for this triple, which is not intuitive and represents a departure from the original intended use.\nThe RDF+ approach [24] creates an internal identifier for each triple and uses it for asserting metadata about this triple. This approach defines abstract syntax and formal semantics for RDF+ statements, creates mappings from RDF to RDF+ and vice versa, and extends SPARQL to support RDF+ statements. Therefore, it is incompatible with the Semantic Web standards.\nRecently, the singleton property (SP) approach [20] has been proposed to address some of these outstanding problems. It creates one singleton property instance for each context to uniquely identify the triple, then uses this property instance to assert the metadata for this triple. For example, if ProfessorA works for University1 from 1994 to 2006, then we create a singleton property instance worksFor#1 and assert the temporal information for this property instance. Table 2 displays how the motivating example is represented in RDF using the singleton property approach.\nUnlike RDF+, the SP approach represents metadata about triples in the form of triples, making it directly compatible with existing Semantic Web standards such as RDF and SPARQL. Furthermore, the current model-theoretic semantics can also be extended to include the semantics of singleton properties. This approach seems to be a potential candidate for representing metadata about triples. However, one inherent characteristic of this approach is that it generates a large property hierarchy in the schema because it relies on contextualized predicates, i.e., predicates used only once (\u201csingleton\u201d) in a specific context. This large property hierarchy may raise some important questions about its handling by the reasoners and query engines.\n1. How are the singleton triples related to the data triples they represent? If the singleton triples describe temporal information about a data triple, then how does a reasoner infer that data triple from the singleton triples? For example,\nthe set (T0, T1, T2, T3) describes data triple M0. How does one infer M0 from (T0, T1, T2, T3)? Similarly, if the set of data triples serves to infer a new data triple, can this data triple also be inferred by the singleton triples describing these data triples? In the motivating example at hand, the two triplesM0 and M7 serve to infer a new data tripleM8: ProfessorA memberOf University1 according to the rule rdfs7 [15]. Can this data triple M8 also be inferred by applying the rule rdfs7 to the triple M7 and the singleton triples (T0, T1, T2, T3) describing the data triple M0? 2. If we load the singleton property triples in Table 2 into a SPARQL endpoint, would the SPARQL engine be able to find the answers for the query with a mix of regular data triple patterns and singleton triple patterns as follows? SELECT ?professor\nWHERE {?professor worksFor University2 . ?student ?sp ?professor . ?sp singletonPropertyOf hasAdvisor . ?sp since \"2009\" .}\n3. Does the large singleton property hierarchy affect the performance of the reasoning and query answering tasks?\nWe believe that these questions are critical and should be addressed for representing RDF statements about statements. It is also beneficial for data publishers and developers in the Semantic Web community to consider adopting this approach given its benefits compared to competing proposals. As the reasoning aspect was not tackled in our previous paper [20], our goal here is to address these reasoning-related questions and perform a comprehensive evaluation.\nOur contributions in this paper include:\n\u2022 A simple mechanism to enable existing reasoners to recognize the singleton triples and perform relevant reasoning tasks (Section 2). We discuss the implementation of this mechanism and demonstrate it in the two reasoners, Oracle and Jena (Section 3). \u2022 The benchmark LUBM-SP extended from LUBM to include singleton properties for representing temporal information (Section 4). \u2022 Evaluation of the effect of singleton property triples on reasoning and query answering tasks (Section 5).\nWe discuss related work in Section 6, future work in Section 7, and conclude with Section 8.\nThe data generator for the LUBM-SP datasets, together with its queries and the Jena package that are used in our evaluation are open source and available at http://wiki.knoesis.org/index.php/Singleton_Property_Reasoning."}, {"heading": "2 Reasoning Mechanism with Singleton Property", "text": "We start with a brief review of the singleton property [20]."}, {"heading": "2.1 Background", "text": "A singleton property is defined as a property instance identifying the unique relationship between the subject and the object. For example, in order to represent the fact that ProfessorA worked for two universities at different times, we create two singleton property instances worksFor#1 and worksFor#2, i.e., two instances of the property worksFor. In general, given any triple t: (s, p, o) described by the contextual information represented by the pairs of meta property and meta value (mpj , m v j ) with j \u2208 1..n, we create the following RDF representation summarized in Table 3. First, we create a singleton property instance pi\nof the generic property p (1), which we use to represent the unique relationship between s and o (2), and finally we assert the contextual information using this property instance pi (3).\nThe extension of the singleton property pi is the unique pair of subject and object (s, o), while the extension of the generic property p is the set of all subject and object pairs associated with the singleton properties derived from it. In our example, the extension of the singleton property worksFor#1 is the pair (ProfessorA, University1), while the extension of the property worksFor is the set of two pairs {(ProfessorA, University1), (ProfessorA, University2)}.\nThe property rdf:singletonPropertyOf is defined in the RDF vocabulary by the formal semantics for singleton properties described in [20], together with the list of primitive triples as follows:\nrdf:singletonPropertyOf rdf:type rdf:Property rdf:singletonPropertyOf rdf:type rdf:Resource rdf:singletonPropertyOf rdfs:domain rdf:SingletonProperty rdf:singletonPropertyOf rdfs:range rdf:Property rdf:SingletonProperty rdf:type rdfs:Class rdf:SingletonProperty rdfs:subClassOf rdf:Property .\nNext, we present the simple mechanism to enable reasoning on singleton property triples."}, {"heading": "2.2 Primitive Axiom for SingletonPropertyOf", "text": "First, let us have a closer look at the nature of the singletonPropertyOf property. A generic property is more generic than all of its sub-properties. A generic property is also more generic than its singleton properties. For instance,\nthe generic property worksFor is more generic than the singleton property worksFor#1. So one may ask if the singletonPropertyOf property is equivalent to the property subPropertyOf. However, the extension of a singleton property, e.g. worksFor#1, has only one element (ProfessorA, University1). Therefore, the singleton property not only carries the semantics of its generic property (as sub-properties do), but it also carries the semantics of singletonness through its extension. Therefore, singletonPropertyOf is not equivalent to subPropertyOf.\nIf the two properties singletonPropertyOf and subPropertyOf are not equivalent, then what could be the relationship between them? As singleton property can be considered as a specialization, or sub property of a generic property, that suggests the new relationship as follows:\nTriple Subject Predicate Object\n(4) singletonPropertyOf subPropertyOf subPropertyOf\nFrom the new triple (4) and the three triples (1), (2), and (3) in Table 3, we next show how the data triple can be derived."}, {"heading": "2.3 Deriving Data Triples", "text": "Back to the example from Section 1, how do we derive the triple M0: ProfessorA worksFor University1 from the example set of singleton property triples? Or, more generally, how do we derive the triple (s, p, o) from the set of triples (1), (2), (3), and (4)? In practice, the data triples can be derived from singleton property triples in two passes.\nIn the first pass, we consider the two triples\n(1) pi singletonPropertyOf p (4) singletonPropertyOf subPropertyOf subPropertyOf\nto derive a new triple (5) according to the rule rdfs7.\n(5) pi subPropertyOf p\nIn the second pass, we combine the two triples\n(2) s pi o (5) pi subPropertyOf p\nto derive the data triple (6) also using rule rdfs7.\n(6) s p o\nTherefore, after applying rule rdfs7 twice to the singleton property triples and the newly proposed axiom (4), we obtain the data triple (6): s p o.\nIn our example, by applying the rule rdfs7 to the triples T1 and (4), we get T10: worksFor#1 subPropertyOf worksFor. Then, we apply the rule rdfs7 again to the triple T10 and T0, to obtain the triple M0: ProfessorA worksFor University1.\nFurthermore, one can also infer the triple M8 from the subPropertyOf rule.\nM0: ProfessorA worksFor University1 M7: worksFor subPropertyOf memberOf M8: ProfessorA memberOf University1\nNote that, as the data triple (6) is inferred from the singleton triples with certain contextual constraints, these contraints are also applicable to the data triple. In our example, the fact that ProfessorA worksFor University1 only holds during the time from 1994 to 2006, as it is inferred from the singleton property triples that express the duration constraint. How to further enforce the contraints on the data triple when it is involved in other deduction rules is another complex reasoning problem and is beyond the scope of this paper."}, {"heading": "2.4 Querying regular data pattern on singleton triples", "text": "A dataset with metadata about the assertions would enable data consumers to represent and reason about the data quality or trust. However, not every query requires metadata about triples. We can think of the metadata about triples as optional information to query. In practice, a query may use only regular triple patterns, or only singleton triple patterns, or both. For example, one can query the list of universities which ProfessorA works for (regardless of time information) as follows:\nSELECT ?university\nWHERE { ProfessorA worksFor ?university }\nThis query contains only one regular data triple pattern. Another query example specifying both types of triple patterns is the following query:\nSELECT ?professor WHERE { ?professor worksFor University2 . ?student ?sp ?professor . ?sp singletonPropertyOf hasAdvisor . ?sp since \"2009\" . }\nIt asks for the list of professors who work for University2 and have student advisees since 2009. In both examples, a regular data triple pattern is specified in the queries. How would such queries be handled?\nWe consider two possibilities here. Dataset without data triples. If the dataset contains only the singleton triples, the SPARQL queries like the above example may return an empty result set because the data triples are not present. In order to get the results, two conditions must be met. First, the query must be executed in an RDFS inference-enabled query engine that is able to compute the RDFS closure. Our evaluation confirms that Jena and Oracle support this feature. We have not thoroughly evaluated other query engines. Second, the axiom rdf:singletonPropertyOf rdfs:subPropertyOf rdfs:subPropertyOf must be added to the schema to make the query reasoner precompute the inferred data triples from the singleton triples using RDFS rules. Here we explain how\nwe implement this approach in Jena and Oracle. In Oracle, after loading the singleton property datasets into the RDF model, one must insert the singleton property axiom into this RDF model before creating any RDFS entailment rule index on this model. By default, the Oracle inference engine will run until the RDFS closure is reached. In Jena, we can simply create an in-memory OntModel with the spec RDFS MEM RDFS RULE. The RDFS closure will include all data triples inferred from the singleton property triples. We will discuss details about where/how to add the singleton property axiom in Section 3.\nDataset with data triples. If the dataset includes the set of data triples and the set of singleton triples, answering the query with the data triple pattern is trivial to any query engine. However, the question here is whether we should include the data triples as part of the dataset. On the one hand, including data triples will speed up the execution for queries with data triple patterns. On the other hand, as data triples can be inferred from the singleton property triples, these data triples become redundant and may increase the risk of becoming inconsistent. If, for any reason, a data triple is removed from the dataset while the corresponding singleton property triples representing this data triple still remain in the dataset, then an inconsistency may result. However, this is a faulty update in the presence of singleton properties, not a problem with reasoning with singleton properties."}, {"heading": "3 Implementation", "text": "We have presented a simple mechanism for adding the singleton property axioms in order to entail the data triple represented by the singleton property triples. The singleton property axioms can be incorporated at any of the following levels.\nApplication. One can add singleton property axioms into the application schema and perform reasoning tasks using reasoners that compute the RDFS closure, such as Jena or the Oracle inference engine [28,29,33]. Although this addition is straightforward, it requires the support of the tools being employed.\nReasoner tools. Providing the support for the singleton property within a reasoner can also be done by the tool\u2019s creators. We have chosen Jena for our implementation because Jena is a popular open source Java API for RDF. We added the RDF SingletonProperty class and singletonPropertyOf property into the Java class RDF. We also added the primitive axioms and rules we propose for supporting singleton property reasoning to the rule bases. We have built a new package for jena-core and used this package in our evaluation. Using this package, one does not need to further add the singleton property axioms into the application schema because it is already integrated into the rulebases. If there are singleton property triples in the knowledge base, the tool will recognize them and run the inference rules.\nLanguage Specification. Supporting singleton property as part of the RDF language specification will be the most effective level from the perspective of long-term standardization. We have seen enthusiasm from many Semantic Web practioners to implement this approach for their datasets. Others have been\nmore reluctant because this approach is not standard. We are confident about the prospects of the wider adoption of this approach because the syntax and semantics of the singleton property are compatible with the current syntax and semantics of RDF, RDFS, and SPARQL.We have also explored the compatibility of the singleton property with OWL. This new capability can be incorporated into OWL by adding (i) the rdf:singletonPropertyOf to the RDF vocabulary, and (ii) the singleton property axioms into the RDF schema. With these enhancements, the singleton property approach will be compatible with all Semantic Web standards, and will significantly enhance the quality and efficency of the meta reasoning."}, {"heading": "4 Knowledge Base Benchmark", "text": "In order to provide a benchmark for evaluating different aspects of the singleton property approach, as well as for future comparison with other approaches, we developed LUBM-SP by extending the LUBM data generator [10]."}, {"heading": "4.1 Data Generator", "text": "In the LUBM knowledge bases, relationships are described among instances of 43 classes including Faculty, Student, Course, Publication, and Organization. Relationships asserted between two instances do not carry any contextual information, such as the duration or the source. LUBM has been extended to include the time dimension for RDF triples as in [19] by stamping triples with dynamic or static temporal properties. However, the representation of this extended knowledge base is not in the standard form of RDF triples. Therefore, it cannot be used for evaluating tasks involving RDF or SPARQL.\nWhile we also share the goal of enriching the LUBM knowledge base with the temporal information for the assertions, our approach differs from [19] in that we represent the temporally-enriched LUBM using just RDF triples. We employ the singleton property approach for this purpose.\nWe modified the LUBM data generator to generate two different knowledge bases per run. The first one is the original LUBM knowledge base (KB). In the\nsecond one, for each triple of LUBM-SP that has temporal information attached, we replace this triple with the singleton property graph. All the information captured remains the same in the two knowledge bases. The only difference between them is representation, i.e., that one uses regular triples, while the other uses singleton property triples and temporal properties. For example, if the LUBM KB contains the data triple M0, then the LUBM-SP KB represents it as a set of triples (T0, T1, T2, and T3) as provided in Table 2.\nTable 4 lists the number of triples in the LUBM and LUBM-SP knowledge bases for increasing numbers of universities (50, 500, 1000, and 5000). It also shows the corresponding number of singleton properties in the LUBM-SP KBs. From the sample, the size of the LUBM-SP datasets is approximately twice the size of the LUBM datasets. Out of 17 relations defined in LUBM, 10 relations are selected for singleton property representation. Five of them have two temporal properties and five of them have one temporal property."}, {"heading": "4.2 Queries", "text": "We create one set of SPARQL queries for each of the two types of query: data triple pattern query and mixed triple pattern query.\nData triple pattern queries. LUBM comes with an original set of 14 SPARQL queries which contain only data triple patterns. We use the same set of queries for evaluating the performance of both LUBM and LUBM-SP. It allows us to measure the extra time taken for inferring and querying singleton properties. From this set of queries, we create an equivalent set of SEMMATCH queries to be executed in Oracle. For every query, we tested that the result sets obtained from LUBM and LUBM-SP had the same size as expected.\nMixed triple pattern queries. This query type has data triple patterns mixed with singleton property triple patterns and temporal properties. We create this set of queries by appending the singleton property triple pattern and temporal properties to the set of data triple pattern queries."}, {"heading": "5 Evaluation", "text": "This section presents our experiments on evaluating the impact of the singleton property representation on the reasoning tasks. In particular, we evaluate the performance of the reasoning tasks at the RDFS level on both in-memory (Jena) and storage-persistent (Oracle) reasoners. We measure the time taken for computing the RDFS closure and the number of inferred triples in each knowledge base. We measure the query answering performance by running the same query on both knowledge bases and recording the execution time."}, {"heading": "5.1 Experiment setup", "text": "We used a single machine running Ubuntu 12.04 LTS with 256GB RAM and three hard drives. On this machine, we deployed the newly built jena-core package with singleton property support as explained in Section 3. We also installed\nOracle 12c Release 1 on this machine. We used the Automatic Memory Management feature and spread tablespaces across different hard drives. This setting serves our evaluation purpose since we deploy the different knowledge bases onto the same system and database configuration, so that the difference in performance can be attributed to the impact of the singleton property representation.\nDisclaimer: Oracle does not have official support for Ubuntu. Although we succeeded in installing Oracle 12c on Ubuntu 12.02 LTS and setting it up to work for the experiments, we did not attempt to tune the system to get the best performance out of Oracle database. Therefore, the results should be taken as an academic exercise rather than a performance benchmark for Oracle databases."}, {"heading": "5.2 Loading and Indexing Entailment Rules", "text": "We created six knowledge bases (KBs). Each KB consists of either a LUBM or LUBM-SP dataset generated as described in Section 4, the Univ-bench ontology and the singleton property axiom triple rdf:singletonPropertyOf rdfs:subPropertyOf rdfs:subPropertyOf. In Oracle, we loaded each KB into one RDF model. For each model, we ran the PL/SQL procedure SEM APIS.CREAT ENTAILMENT to create an RDFS rulebase index with default options. Table 5 shows the number of inferred triples and the time taken for each index. The number of inferred triples in the LUBM-SP KBs is larger than the one in the corresponding LUBM KBs. The time taken for creating the entailment index also increases in proportion with the number of inferred triples. We observed that the performance was bound to the heavy I/O accesses during the indexing processes. Therefore, increasing the number of disks may help increase the degree of parallelism, thereby improving the performance.\nIn Jena, we loaded each KB into an OntModel. The singleton property axiom need not be loaded into Jena models because it already has built-in support from our updated jena-core package. The average loading time after three runs is 35 seconds for LUBM 50 and 79 seconds for LUBM-SP 50. The average preparation time after three runs for initial processing and caching is 20 seconds for LUBM 50 and 99 seconds for LUBM-SP 50."}, {"heading": "5.3 Query Answering", "text": "We used the set of queries described in Section 4. Queries with mixed triple patterns are not applicable (N/A) to LUBM KBs because these KBs do not have singleton property triple patterns. We ran the set of queries on each model with a fresh database. Table 6 reports the average execution time after three runs for both Jena and Oracle.\nOn average, the queries executed on the LUBM-SP KBs take 10% (Jena) and 12% (Oracle) longer than the ones executed on the LUBM KBs. This is expected due to the size of the KBs. In Jena, queries running longer than two hours were aborted. Queries 8 and 9, that are reported to have timed out in [10] running Jena in-memory with LUBM 1 (generated with 1 university), also did time out in our case. Compared to Jena, these long queries are executed much faster in Oracle. The performance per query from LUBM and LUBM-SP KBs is not as consistent in Oracle as it is in Jena, because of the cache supported by Oracle. Subsequent queries may benefit from the cache loaded for prior queries. This is applicable to both original LUBM queries and the new mixed queries.\nSummary. Our evaluation shows the overall costs of reasoning tasks for KBs with and without singleton property representation. In general, the size of knowledge bases LUBM-SP with the singleton property representation is twice the size of knowledge bases LUBM with the data triple representation. The number of inferred triples determines the loading time and the execution time for creating rule indices. On average, the queries in LUBM-SP KBs take 10% to 12% longer than in LUBM KBs."}, {"heading": "6 Related Work", "text": "Representing metadata about triples has received much attention and several approaches have been proposed. We can classify these approaches into three categories: triple-based (reification [14], singleton property), quadruple-based (named graph [5]), and quintuple-based (RDF+ [24]) as explained in Section 1. Our work is developed on top of the singleton property approach. One major advantage of the singleton property approach over reification is that the original data triple can be inferred by the singleton property triples describing it.\nTo the best of our knowledge, this is the first approach that allows the RDF data triple described by RDF triples to be inferred by an RDFS reasoner. This kind of reasoning differs from the stream reasoning [19] where the temporal dimension is not represented directly with RDF. It also differs from the temporal RDF [11] where temporal reasoning is incorporated into RDF using reification. In contrast to these approaches, we demonstrated that temporal information can be incorporated into RDF through singleton properties to enable temporal reasoning."}, {"heading": "7 Future Work", "text": "In the near future, we plan to address the following aspects:\nPerformance optimization. In the implementation and evaluation, our goal was to support singleton property reasoning. We have not attempted to optimize the reasoning performance. However, the singleton property hierarchy is usually large and better reasoning performance is always desirable for scalability. Evaluating this singleton property reasoning with more highly optimized RDF stores should also be done.\nTemporal RDF. As the singleton property approach provides a mechanism for incorporating metadata such as temporal dimension into the RDF triples, work [11,18] on reasoning about temporal RDF can also be revisited and reimplemented on top of singleton properties. Similarly, reasoning about other kinds of metadata describing triples should also be explored.\nPerformance comparison. We plan to compare the inference-enabled query performance with that of other approaches such as N-ary and Nanopub using life science KBs such as PubChem, Bio2RDF, and DisGeNET."}, {"heading": "8 Conclusion", "text": "We have presented a simple mechanism for reasoning with RDF statements about statements. We have shown that this mechanism is in compliance with all Semantic Web standards and technically straightforward to implement. Our evaluation results also show acceptable overhead in the reasoning tasks involving the knowledge bases enriched with metadata such as time, location, and provenance for assertions, especially considering the conceptual simplicity and theoretical soundness."}], "references": [{"title": "Bio2rdf: towards a mashup to build bioinformatics knowledge systems", "author": ["F. Belleau", "M. Nolin", "N. Tourigny", "P. Rigault", "J. Morissette"], "venue": "Journal of biomedical informatics, 41(5):706\u2013716,", "citeRegEx": "1", "shortCiteRegEx": null, "year": 2008}, {"title": "Provenance information in biomedical knowledge repositories-a use case", "author": ["O. Bodenreider"], "venue": "In SWPM. Citeseer,", "citeRegEx": "2", "shortCiteRegEx": null, "year": 2009}, {"title": "Pubchem: integrated platform of small molecules and biological activities", "author": ["E.E. Bolton", "Y. Wang", "P.A. Thiessen", "S.H. Bryant"], "venue": "Annual reports in computational chemistry, 4:217\u2013241,", "citeRegEx": "3", "shortCiteRegEx": null, "year": 2008}, {"title": "Ovopub: Modular data publication with minimal provenance", "author": ["A. Callahan", "M. Dumontier"], "venue": "arXiv preprint arXiv:1305.6800,", "citeRegEx": "4", "shortCiteRegEx": null, "year": 2013}, {"title": "Named graphs", "author": ["J.J. Carroll", "C. Bizer", "P. Hayes", "P. Stickler"], "venue": "Web Semantics: Science, Services and Agents on the World Wide Web, 3(4):247\u2013267,", "citeRegEx": "5", "shortCiteRegEx": null, "year": 2005}, {"title": "and M", "author": ["R. Cyganiak", "D. Wood"], "venue": "Lanthaler. Rdf 1.1 concepts and abstract syntax. World Wide Web Consortium, http://www.w3.org/TR/rdf11-concepts/,", "citeRegEx": "6", "shortCiteRegEx": null, "year": 2014}, {"title": "Geoscience data provenance: An overview", "author": ["L. Di", "P. Yue", "H.K. Ramapriyan", "R.L. King"], "venue": "Geoscience and Remote Sensing, IEEE Transactions on, 51(11):5065\u2013 5072,", "citeRegEx": "7", "shortCiteRegEx": null, "year": 2013}, {"title": "Knowledge vault: A web-scale approach to probabilistic knowledge fusion", "author": ["X. Dong", "E. Gabrilovich", "G. Heitz", "W. Horn", "N. Lao", "K. Murphy", "T. Strohmann", "S. Sun", "W. Zhang"], "venue": "In Proceedings of the 20th ACM SIGKDD international conference on Knowledge discovery and data mining, pages 601\u2013610. ACM,", "citeRegEx": "8", "shortCiteRegEx": null, "year": 2014}, {"title": "The anatomy of a nanopublication", "author": ["P. Groth", "A. Gibson", "J. Velterop"], "venue": "Information Services and Use, 30(1):51\u201356,", "citeRegEx": "9", "shortCiteRegEx": null, "year": 2010}, {"title": "Lubm: A benchmark for owl knowledge base systems", "author": ["Y. Guo", "Z. Pan", "J. Heflin"], "venue": "Web Semantics: Science, Services and Agents on the World Wide Web, 3(2):158\u2013 182,", "citeRegEx": "10", "shortCiteRegEx": null, "year": 2005}, {"title": "Temporal rdf", "author": ["C. Gutierrez", "C. Hurtado", "A. Vaisman"], "venue": "In The Semantic Web: Research and Applications, pages 93\u2013107. Springer,", "citeRegEx": "11", "shortCiteRegEx": null, "year": 2005}, {"title": "An introduction to spatial database systems", "author": ["R.H. G\u00fcting"], "venue": "The VLDB JournalThe International Journal on Very Large Data Bases, 3(4):357\u2013399,", "citeRegEx": "12", "shortCiteRegEx": null, "year": 1994}, {"title": "A catalog of temporal theories", "author": ["P. Hayes"], "venue": "Artificial Intelligence Technical Report UIUC-BI-AI-96-01, University of Illinois at Urbana-Champaign,", "citeRegEx": "13", "shortCiteRegEx": null, "year": 1996}, {"title": "and B", "author": ["P. Haye"], "venue": "McBride. Rdf semantics,", "citeRegEx": "14", "shortCiteRegEx": null, "year": 2004}, {"title": "Rdf 1.1 semantics", "author": ["P. Hayes", "P. Patel-Schneider"], "venue": "w3c recommendation (february", "citeRegEx": "15", "shortCiteRegEx": "15", "year": 2014}, {"title": "Yago2: a spatially and temporally enhanced knowledge base from wikipedia", "author": ["J. Hoffart", "F.M. Suchanek", "K. Berberich", "G. Weikum"], "venue": "Artificial Intelligence,", "citeRegEx": "16", "shortCiteRegEx": null, "year": 2012}, {"title": "Ontology-driven monitoring of patients vital signs enabling personalized medical detection and alert", "author": ["A. Hristoskova", "V. Sakkalis", "G. Zacharioudakis", "M. Tsiknakis", "F. De Turck"], "venue": "Sensors, 14(1):1598\u20131628,", "citeRegEx": "17", "shortCiteRegEx": null, "year": 2014}, {"title": "Reasoning with temporal constraints in RDF", "author": ["C. Hurtado", "A. Vaisman"], "venue": "Springer,", "citeRegEx": "18", "shortCiteRegEx": null, "year": 2006}, {"title": "Slubm: An extended lubm benchmark for stream reasoning", "author": ["T.N. Nguyen", "W. Siberski"], "venue": "In OrdRing@ ISWC, pages 43\u201354,", "citeRegEx": "19", "shortCiteRegEx": null, "year": 2013}, {"title": "Don\u2019t like rdf reification?: Making statements about statements using singleton property", "author": ["V. Nguyen", "O. Bodenreider", "A. Sheth"], "venue": "In Proceedings of the 23rd International Conference on World Wide Web, WWW \u201914, pages 759\u2013770,", "citeRegEx": "20", "shortCiteRegEx": null, "year": 2014}, {"title": "Literature review of spatio-temporal database models", "author": ["N. Pelekis", "B. Theodoulidis", "I. Kopanakis", "Y. Theodoridis"], "venue": "The Knowledge Engineering Review, 19(03):235\u2013 274,", "citeRegEx": "21", "shortCiteRegEx": null, "year": 2004}, {"title": "Disgenet: a discovery platform for the dynamical exploration of human diseases and their genes", "author": ["J. Pi\u00f1ero", "N. Queralt-Rosinach", "\u00c0. Bravo", "J. Deu-Pons", "A. Bauer-Mehren", "M. Baron", "F. Sanz", "L.I. Furlong"], "venue": "Database, 2015:bav028,", "citeRegEx": "22", "shortCiteRegEx": null, "year": 2015}, {"title": "A unified framework for managing provenance information in translational research", "author": ["S. Sahoo", "V. Nguyen", "O. Bodenreider", "P. Parikh", "T. Minning", "A. Sheth"], "venue": "BMC Bioinformatics,", "citeRegEx": "23", "shortCiteRegEx": null, "year": 2011}, {"title": "Querying for meta knowledge", "author": ["B. Schueler", "S. Sizov", "S. Staab", "D.T. Tran"], "venue": "In Proceedings of the 17th international conference on World Wide Web, pages 625\u2013634. ACM,", "citeRegEx": "24", "shortCiteRegEx": null, "year": 2008}, {"title": "Modelling provenance in hydrologic science: a case study on streamflow forecasting", "author": ["Y. Shu", "K. Taylor", "P. Hapuarachchi", "C. Peters"], "venue": "Journal of Hydroinformatics, 14(4):944\u2013959,", "citeRegEx": "25", "shortCiteRegEx": null, "year": 2012}, {"title": "Temporal databases", "author": ["R.T. Snodgrass"], "venue": "In IEEE computer. Citeseer,", "citeRegEx": "26", "shortCiteRegEx": null, "year": 1986}, {"title": "Systems chemical biology and the semantic web: what they mean for the future of drug discovery research", "author": ["D.J. Wild", "Y. Ding", "A.P. Sheth", "L. Harland", "E.M. Gifford", "M.S. Lajiness"], "venue": "Drug discovery today, 17(9):469\u2013474,", "citeRegEx": "27", "shortCiteRegEx": null, "year": 2012}, {"title": "Implementing an inference engine for rdfs/owl constructs and user-defined rules in oracle", "author": ["Z. Wu", "G. Eadon", "S. Das", "E.I. Chong", "V. Kolovski", "M. Annamalai", "J. Srinivasan"], "venue": "In Data Engineering, 2008. ICDE 2008. IEEE 24th International Conference on, pages 1239\u20131248. IEEE,", "citeRegEx": "28", "shortCiteRegEx": null, "year": 2008}, {"title": "Advancing the enterprise-class owl inference engine in oracle database", "author": ["Z. Wu", "K. Rieb", "G. Eadon", "A. Khandelwal", "V. Kolovski"], "venue": "In ORE. Citeseer,", "citeRegEx": "29", "shortCiteRegEx": null, "year": 2012}, {"title": "A linked data approach for geospatial data provenance", "author": ["J. Yuan", "P. Yue", "J. Gong", "M. Zhang"], "venue": "Geoscience and Remote Sensing, IEEE Transactions on, 51(11):5105\u2013 5112,", "citeRegEx": "30", "shortCiteRegEx": null, "year": 2013}, {"title": "Annotating, linking and browsing provenance logs for e-science", "author": ["J. Zhao", "C. Goble", "M. Greenwood", "C. Wroe", "R. Stevens"], "venue": "In Proc. of the Workshop on Semantic Web Technologies for Searching and Retrieving Scientific Data, pages 158\u2013176. Citeseer,", "citeRegEx": "31", "shortCiteRegEx": null, "year": 2003}, {"title": "Semantically linking and browsing provenance logs for e-science", "author": ["J. Zhao", "C. Goble", "R. Stevens", "S. Bechhofer"], "venue": "Semantics of a Networked World, pages 158\u2013176,", "citeRegEx": "32", "shortCiteRegEx": null, "year": 2004}, {"title": "Making the most of your triple store: query answering in owl 2 using an rl reasoner", "author": ["Y. Zhou", "B. Cuenca Grau", "I. Horrocks", "Z. Wu", "J. Banerjee"], "venue": "In Proceedings of the 22nd international conference on World Wide Web, pages 1569\u20131580. International World Wide Web Conferences Steering Committee,", "citeRegEx": "33", "shortCiteRegEx": null, "year": 2013}], "referenceMentions": [{"referenceID": 5, "context": "1 concept and abstract syntax [6], and the RDF 1.", "startOffset": 30, "endOffset": 33}, {"referenceID": 14, "context": "1 formal semantics [15].", "startOffset": 19, "endOffset": 23}, {"referenceID": 13, "context": "For triples about triples, RDF reification was previously presented as a standard in the W3C 2004 Recommendations [14].", "startOffset": 114, "endOffset": 118}, {"referenceID": 14, "context": "However, this RDF reification has been withdrawn from the normative sections in the latest RDF Recommendation [15] and has become non-standard because of its limitations.", "startOffset": 110, "endOffset": 114}, {"referenceID": 9, "context": "We adopt the example from the popular Lehigh University Benchmark (LUBM) [10].", "startOffset": 73, "endOffset": 77}, {"referenceID": 12, "context": "Knowledge evolves over time, and a proposition may only hold at a specific time point, duration, or interval [13].", "startOffset": 109, "endOffset": 113}, {"referenceID": 7, "context": "The capability of representing time and space dimensions is essential in many real world systems and applications, especially in the systems extracting knowledge from the Web such as Knowledge Vault [8] recently created by Google, and YAGO2S [16].", "startOffset": 199, "endOffset": 202}, {"referenceID": 15, "context": "The capability of representing time and space dimensions is essential in many real world systems and applications, especially in the systems extracting knowledge from the Web such as Knowledge Vault [8] recently created by Google, and YAGO2S [16].", "startOffset": 242, "endOffset": 246}, {"referenceID": 16, "context": "Other smart applications that use sensors, such as real-time remote monitoring of patients diagnosed with congestive heart failure, can benefit from temporal information [17].", "startOffset": 170, "endOffset": 174}, {"referenceID": 11, "context": "Temporal and spatial databases have been researched over decades [12,21,26] and supported by various commercial database systems.", "startOffset": 65, "endOffset": 75}, {"referenceID": 20, "context": "Temporal and spatial databases have been researched over decades [12,21,26] and supported by various commercial database systems.", "startOffset": 65, "endOffset": 75}, {"referenceID": 25, "context": "Temporal and spatial databases have been researched over decades [12,21,26] and supported by various commercial database systems.", "startOffset": 65, "endOffset": 75}, {"referenceID": 1, "context": "Provenance is studied in various applications across different domains like biomedicine [2,27,31,32], geoscience [7,30], and others [25].", "startOffset": 88, "endOffset": 100}, {"referenceID": 26, "context": "Provenance is studied in various applications across different domains like biomedicine [2,27,31,32], geoscience [7,30], and others [25].", "startOffset": 88, "endOffset": 100}, {"referenceID": 30, "context": "Provenance is studied in various applications across different domains like biomedicine [2,27,31,32], geoscience [7,30], and others [25].", "startOffset": 88, "endOffset": 100}, {"referenceID": 31, "context": "Provenance is studied in various applications across different domains like biomedicine [2,27,31,32], geoscience [7,30], and others [25].", "startOffset": 88, "endOffset": 100}, {"referenceID": 6, "context": "Provenance is studied in various applications across different domains like biomedicine [2,27,31,32], geoscience [7,30], and others [25].", "startOffset": 113, "endOffset": 119}, {"referenceID": 29, "context": "Provenance is studied in various applications across different domains like biomedicine [2,27,31,32], geoscience [7,30], and others [25].", "startOffset": 113, "endOffset": 119}, {"referenceID": 24, "context": "Provenance is studied in various applications across different domains like biomedicine [2,27,31,32], geoscience [7,30], and others [25].", "startOffset": 132, "endOffset": 136}, {"referenceID": 2, "context": "As metadata about triples is very common in modeling data, we believe that many Semantic Web datasets such as PubChem [3], Bio2RDF [1], and DisGeNET [22] will benefit from a concensus on a standard method for representing triples about triples recommended by the W3C.", "startOffset": 118, "endOffset": 121}, {"referenceID": 0, "context": "As metadata about triples is very common in modeling data, we believe that many Semantic Web datasets such as PubChem [3], Bio2RDF [1], and DisGeNET [22] will benefit from a concensus on a standard method for representing triples about triples recommended by the W3C.", "startOffset": 131, "endOffset": 134}, {"referenceID": 21, "context": "As metadata about triples is very common in modeling data, we believe that many Semantic Web datasets such as PubChem [3], Bio2RDF [1], and DisGeNET [22] will benefit from a concensus on a standard method for representing triples about triples recommended by the W3C.", "startOffset": 149, "endOffset": 153}, {"referenceID": 3, "context": "[4,9,20,23].", "startOffset": 0, "endOffset": 11}, {"referenceID": 8, "context": "[4,9,20,23].", "startOffset": 0, "endOffset": 11}, {"referenceID": 19, "context": "[4,9,20,23].", "startOffset": 0, "endOffset": 11}, {"referenceID": 22, "context": "[4,9,20,23].", "startOffset": 0, "endOffset": 11}, {"referenceID": 13, "context": "These approaches can be classified into three main groups: triple (reification [14], singleton property[20]), quadruple (named graph [5]), and quintuple (RDF [24]).", "startOffset": 79, "endOffset": 83}, {"referenceID": 19, "context": "These approaches can be classified into three main groups: triple (reification [14], singleton property[20]), quadruple (named graph [5]), and quintuple (RDF [24]).", "startOffset": 103, "endOffset": 107}, {"referenceID": 4, "context": "These approaches can be classified into three main groups: triple (reification [14], singleton property[20]), quadruple (named graph [5]), and quintuple (RDF [24]).", "startOffset": 133, "endOffset": 136}, {"referenceID": 23, "context": "These approaches can be classified into three main groups: triple (reification [14], singleton property[20]), quadruple (named graph [5]), and quintuple (RDF [24]).", "startOffset": 158, "endOffset": 162}, {"referenceID": 13, "context": "The reification of a triple does not entail the triple, and is not entailed by it [14].", "startOffset": 82, "endOffset": 86}, {"referenceID": 4, "context": "The named graph [5] originally introduced a fourth element to represent the provenance of the graph.", "startOffset": 16, "endOffset": 19}, {"referenceID": 23, "context": "The RDF approach [24] creates an internal identifier for each triple and uses it for asserting metadata about this triple.", "startOffset": 17, "endOffset": 21}, {"referenceID": 19, "context": "Recently, the singleton property (SP) approach [20] has been proposed to address some of these outstanding problems.", "startOffset": 47, "endOffset": 51}, {"referenceID": 14, "context": "How does one infer M0 from (T0, T1, T2, T3)? Similarly, if the set of data triples serves to infer a new data triple, can this data triple also be inferred by the singleton triples describing these data triples? In the motivating example at hand, the two triplesM0 and M7 serve to infer a new data tripleM8: ProfessorA memberOf University1 according to the rule rdfs7 [15].", "startOffset": 368, "endOffset": 372}, {"referenceID": 19, "context": "As the reasoning aspect was not tackled in our previous paper [20], our goal here is to address these reasoning-related questions and perform a comprehensive evaluation.", "startOffset": 62, "endOffset": 66}, {"referenceID": 19, "context": "We start with a brief review of the singleton property [20].", "startOffset": 55, "endOffset": 59}, {"referenceID": 19, "context": "The property rdf:singletonPropertyOf is defined in the RDF vocabulary by the formal semantics for singleton properties described in [20], together with the list of primitive triples as follows:", "startOffset": 132, "endOffset": 136}, {"referenceID": 27, "context": "One can add singleton property axioms into the application schema and perform reasoning tasks using reasoners that compute the RDFS closure, such as Jena or the Oracle inference engine [28,29,33].", "startOffset": 185, "endOffset": 195}, {"referenceID": 28, "context": "One can add singleton property axioms into the application schema and perform reasoning tasks using reasoners that compute the RDFS closure, such as Jena or the Oracle inference engine [28,29,33].", "startOffset": 185, "endOffset": 195}, {"referenceID": 32, "context": "One can add singleton property axioms into the application schema and perform reasoning tasks using reasoners that compute the RDFS closure, such as Jena or the Oracle inference engine [28,29,33].", "startOffset": 185, "endOffset": 195}, {"referenceID": 9, "context": "In order to provide a benchmark for evaluating different aspects of the singleton property approach, as well as for future comparison with other approaches, we developed LUBM-SP by extending the LUBM data generator [10].", "startOffset": 215, "endOffset": 219}, {"referenceID": 18, "context": "LUBM has been extended to include the time dimension for RDF triples as in [19] by stamping triples with dynamic or static temporal properties.", "startOffset": 75, "endOffset": 79}, {"referenceID": 18, "context": "While we also share the goal of enriching the LUBM knowledge base with the temporal information for the assertions, our approach differs from [19] in that we represent the temporally-enriched LUBM using just RDF triples.", "startOffset": 142, "endOffset": 146}, {"referenceID": 9, "context": "Queries 8 and 9, that are reported to have timed out in [10] running Jena in-memory with LUBM 1 (generated with 1 university), also did time out in our case.", "startOffset": 56, "endOffset": 60}, {"referenceID": 13, "context": "We can classify these approaches into three categories: triple-based (reification [14], singleton property), quadruple-based (named graph [5]), and quintuple-based (RDF [24]) as explained in Section 1.", "startOffset": 82, "endOffset": 86}, {"referenceID": 4, "context": "We can classify these approaches into three categories: triple-based (reification [14], singleton property), quadruple-based (named graph [5]), and quintuple-based (RDF [24]) as explained in Section 1.", "startOffset": 138, "endOffset": 141}, {"referenceID": 23, "context": "We can classify these approaches into three categories: triple-based (reification [14], singleton property), quadruple-based (named graph [5]), and quintuple-based (RDF [24]) as explained in Section 1.", "startOffset": 169, "endOffset": 173}, {"referenceID": 18, "context": "This kind of reasoning differs from the stream reasoning [19] where the temporal dimension is not represented directly with RDF.", "startOffset": 57, "endOffset": 61}, {"referenceID": 10, "context": "It also differs from the temporal RDF [11] where temporal reasoning is incorporated into RDF using reification.", "startOffset": 38, "endOffset": 42}, {"referenceID": 10, "context": "As the singleton property approach provides a mechanism for incorporating metadata such as temporal dimension into the RDF triples, work [11,18] on reasoning about temporal RDF can also be revisited and reimplemented on top of singleton properties.", "startOffset": 137, "endOffset": 144}, {"referenceID": 17, "context": "As the singleton property approach provides a mechanism for incorporating metadata such as temporal dimension into the RDF triples, work [11,18] on reasoning about temporal RDF can also be revisited and reimplemented on top of singleton properties.", "startOffset": 137, "endOffset": 144}], "year": 2016, "abstractText": "The Singleton Property (SP) approach has been proposed for representing and querying metadata about RDF triples such as provenance, time, location, and evidence. In this approach, one singleton property is created to uniquely represent a relationship in a particular context, and in general, generates a large property hierarchy in the schema. It has become the subject of important questions from Semantic Web practitioners. Can an existing reasoner recognize the singleton property triples? And how? If the singleton property triples describe a data triple, then how can a reasoner infer this data triple from the singleton property triples? Or would the large property hierarchy affect the reasoners in some way? We address these questions in this paper and present our study about the reasoning aspects of the singleton properties. We propose a simple mechanism to enable existing reasoners to recognize the singleton property triples, as well as to infer the data triples described by the singleton property triples. We evaluate the effect of the singleton property triples in the reasoning processes by comparing the performance on RDF datasets with and without singleton properties. Our evaluation uses as benchmark the LUBM datasets and the LUBM-SP datasets derived from LUBM with temporal information added through singleton properties.", "creator": "LaTeX with hyperref package"}}}