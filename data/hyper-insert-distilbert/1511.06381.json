{"id": "1511.06381", "review": {"conference": "arxiv", "VERSION": "v1", "DATE_OF_SUBMISSION": "19-Nov-2015", "title": "Manifold Regularized Deep Neural Networks using Adversarial Examples", "abstract": "learning meaningful continuous representations using classical deep tuned neural networks involves designing sufficiently efficient training schemes and forming well - structured networks. currently, combining the adaptive method library of stochastic gradient proportional descent algorithm that directly has a probability momentum boundary with dropout depth is one ancestor of the most popular training protocols. based significantly on that, several more explicitly advanced methods ( eps i., e., maxout and batch normalization ) have been effectively proposed theoretically in recent years, but most groups still suffer solely from nonlinear performance degradation caused partially by sufficiently small perturbations, also known as adversarial examples. determined to address this implementation issue, we essentially propose manifold highly regularized signal networks ( locally mrnet ) filters that typically utilize a novel computational training objective comparison function that gradually minimizes the substantial difference contribution between multi - layer embedding results of samples and those strictly adversarial. combining our experimental work results has demonstrated ensured that mrnet is more sufficiently resilient to purely adversarial convex examples structures and helps us to generalize representations centered on closed manifolds. fortunately furthermore, combining mrnet and dropout allowed guiding us to nonetheless obtain immediate improvements over utilizing the best consistent published results for releasing three clearly well - known analytic benchmarks : mnist, cifar - 10, owl and svhn.", "histories": [["v1", "Thu, 19 Nov 2015 21:10:29 GMT  (7007kb)", "http://arxiv.org/abs/1511.06381v1", "Submitted to ICLR 2016"], ["v2", "Thu, 14 Jan 2016 16:35:11 GMT  (2493kb,D)", "http://arxiv.org/abs/1511.06381v2", "Figure 2, 5, 7, and several descriptions revised"]], "COMMENTS": "Submitted to ICLR 2016", "reviews": [], "SUBJECTS": "cs.LG cs.CV", "authors": ["taehoon lee", "minsuk choi", "sungroh yoon"], "accepted": false, "id": "1511.06381"}, "pdf": {"name": "1511.06381.pdf", "metadata": {"source": "CRF", "title": null, "authors": ["Taehoon Lee", "Minsuk Choi"], "emails": ["taehoonlee@snu.ac.kr", "minsuk0523@snu.ac.kr", "sryoon@snu.ac.kr"], "sections": [{"heading": null, "text": "ar X\niv :1\n51 1.\n06 38\n1v 1\n[ cs\n.L G\n] 1\n9 N\nov 2"}, {"heading": "1 INTRODUCTION", "text": "Deep neural networks have been used successfully to learn meaningful representations on a variety of tasks (Hinton & Salakhutdinov, 2006; Krizhevsky et al., 2012). By adding more hidden units or layers, we can learn more complicated relationships between sensory data and desired outputs. However, increasing the model complexity incurs an enormous solution space. Thus, regularization techniques have been normally combined with deep neural networks to obtain acceptable solutions.\nPrevious regularization techniques involve designing efficient training schemes [i.e., dropout (Srivastava et al., 2014), DropConnect (Wan et al., 2013), and Batch Normalization (Ioffe & Szegedy, 2015)] and well-structured networks [i.e., Network In Network (Lin et al., 2014), and Inception (Szegedy et al., 2015)]. Even with these cutting-edge techniques, deep neural networks are still prone to performance degradation when certain small perturbations are injected to samples. The perturbations, which are barely perceptible to humans but make neural networks easily less confident, are called adversarial examples (Szegedy et al., 2014; Goodfellow et al., 2015; Nguyen et al., 2015). This phenomenon occurs due to fewer training examples than parameters and the inner products of high-dimensional vectors (Goodfellow et al., 2015). In the case of fully connected layers, activation grows by \u01ebn in the worst-case, when n components of an inner product are changed by \u01eb. As shown in Fig. 1(a), decision boundaries constructed by deep networks are wiggly and sensitive to adversarial perturbations.\nIn Goodfellow et al. (2015) in particular, adversarial training was proposed to minimize classification loss both on given samples and adversarial examples. This type of training helps neural networks to increase the confident scores of corrupted samples and generalize across different clean examples. However, the gradients of a discriminative objective function may vanish when the gradients of both the original and adversarial examples are aggregated.\nTo address this issue, we present a new network called manifold regularized networks (MRnet), which regularizes deep neural networks based on the concept of manifold learning. Manifold learning refers to methodologies based on the manifold hypothesis in which nearest samples in a\nhigh-dimensional input space are also nearest pairs on a manifold of much lower dimensionality. As traditional manifold learning [i.e., ISOMAP (Tenenbaum et al., 2000), Locally Linear Embedding (Roweis & Saul, 2000), and t-SNE (Van der Maaten & Hinton, 2008)] are well-formulated to find transformation preserving geodesic distances in high-dimensional space, they demonstrate limited performance in practice because of insufficient nearest training samples (Fig. 1(b)). There have been many attempts (Reed et al., 2014; Tomar & Rose, 2014; Yuan et al., 2015) to unify deep learning and manifold learning. These studies have common limitations inherited from those of the original manifold learning.\nIn this paper, we generate adversarial examples and make neural networks insensitive to the direction of adversarial perturbations by adding a manifold penalty term. Similar to popular deep learning techniques, the manifold penalty can be applied easily to gradient-based optimization. We demonstrate that our method can find appropriate manifold representations for three benchmark datasets we tested."}, {"heading": "2 RELATED WORK", "text": ""}, {"heading": "2.1 DEEP MANIFOLD LEARNING", "text": "Despite the recent success of deep networks, their ultimate goal has not yet been reached, which is generalizing lower-dimensional manifolds. Researchers anticipate that neural networks with multiple layers could learn a manifold embedding and classifier simultaneously (Bengio et al., 2013). However, traditional loss terms, such as a reconstruction or classification error, are not sufficient to capture local variations on manifolds. To support the manifold hypothesis, we need to employ another type of cost function that makes neighborhoods have a similar representation. Hence, there have been many attempts to combine both functional concepts of deep and manifold learning.\nAttempts to unify deep and manifold learning can be divided into two categories: manifold learningbased unifying and deep learning-based unifying. The former finds a hierarchical manifold embedding with layer-wise manifold learning in the same way as pre-training in deep belief networks. For example, Locally Linear Embedding (Roweis & Saul, 2000) was used as a base unit for a deep architecture (Yuan et al., 2015). The latter incorporates an additional objective from the manifold learning perspective into a framework of deep learning. For instance, the following objective was proposed in Reed et al. (2014):\n\u2211\n(hi,hj)\u2208Dsim\n\u2016hi \u2212 hj\u2016 2 2 +\n\u2211\n(hi,hk)\u2208Ddis\nmax(0, \u03b2 \u2212 \u2016hi \u2212 hk\u20162) 2, (1)\nwhere {h1, . . . , hn} is a set of hidden representations obtained from forward operations of deep neural networks. Two sets Dsim and Ddis denote the sets of data pairs with the same labels and different labels, respectively. Another form is defined in Tomar & Rose (2014) as follows: \u2211\nDsim wij\u2016hi \u2212 hj\u2016\n2 \u2212 \u2211\nDdis wik\u2016hi \u2212 hk\u2016 2 where wij = exp(\u2212\u2016xi \u2212 xj\u20162/\u03c1). Other variations [i.e., Lu et al. (2015)] are also possible; however, variations still have limitations inherited from\nthe original manifold learning. Training set neighborhood information may be problematic because most nearest samples have too little in common in high-dimensional Euclidean spaces (Bengio et al., 2013)."}, {"heading": "2.2 ADVERSARIAL EXAMPLES", "text": "In our study, we incorporate an explicit loss term to preserve neighborhood relationships into deep neural networks. As mentioned earlier, neighborhood information based on only training samples may cause inappropriate embedding. Because the samples are sufficiently densely populated in most cases, we generate adversarial examples that are sufficiently closed to original samples on manifolds. An example of an adversarial perturbation is shown in Fig. 2 [retrieved from Goodfellow et al. (2015)].\nWe can obtain these adversarial perturbations easily by updating a sample instead of parameters. While the parameter updating performs \u03b8 := \u03b8 \u2212 \u03b7\u2207\u03b8J(\u03b8;x, y), the sample updating calculates x := x+ \u03b7\u2207xJ(\u03b8;x, y), where \u03b7 is a learning rate. The opposite signs in the two update equations mean that the former minimizes a classification loss but the latter maximizes a classification loss. Given a panda image with a high confidence score (see Fig. 2), the direction can be calculated by making the neural network less confident. We can produce a new image that a human cannot distinguish from the original, but the neural network believes the image is a gibbon with 99.3% confidence.\nThe problem of adversarial perturbations arises in several learning models as well as state-of-the-art deep networks, such as AlexNet (Krizhevsky et al., 2012) or GoogLeNet (Szegedy et al., 2015). An ensemble of different deep architectures trained on different subsets of the training data also misclassify the same adversarial example. This suggests that adversarial examples expose fundamental blind spots in our objective functions (Szegedy et al., 2014). Thus, we need to make neural networks resist directions of adversarial perturbations by introducing an explicit loss term to minimize differences between original and adversarial samples."}, {"heading": "3 MANIFOLD REGULARIZED NETWORKS", "text": "Given a data set X = {x1, . . . , xn} with corresponding labels y = {y1, . . . , yn}, we consider the following objective loss function:\nJ(\u03b8;X ,y) = L(\u03b8;X ,y) + \u03bb\u2126(\u03b8) (2)\nwhere L(\u00b7) is a classification loss and \u2126(\u00b7) is defined to maximize a prior p(\u03b8). For the two terms L(\u00b7) and \u2126(\u00b7), the cross entropy and L2 weight decay are most popular choices in a supervised setting. L2 decay works well in practice; however, these forms of neural networks have intrinsic blind spots due to the huge number of parameters and linear functions using them. Hence, we propose an additional manifold loss term that exploits the characteristics of blind spots.\nSuppose we have a neural network with L+ 1 layers. The last (L+ 1)-th layer is an softmax layer. Let l \u2208 {1, . . . , L + 1} be a layer index and a(l) an activation of the l-th layer (a(1) = x). The proposed objective can be defined as:\nJm(\u03b8;X ,y) = L(\u03b8;X ,y) + \u03bb\u2126(\u03b8) + \u03bbm\u03a6(X ,X \u2032), (3)\n\u03a6(X ,X \u2032) = 1\nn\n\u2211\nn\n\u03a6(xn, x \u2032 n) =\n1\n2n\n\u2211\nn\n\u2016a(L)n \u2212 a \u2032(L) n \u2016 2 2, (4)\nx\u2032n = xn + \u03b2\u2207xnL(\u03b8;xn, yn)/\u2016\u2207xnL(\u03b8;xn, yn)\u2016 \ufe38 \ufe37\ufe37 \ufe38\n\u2206xn\n(5)\nwhere \u03a6 is a manifold loss and \u03bbm is a hyper-parameter for the manifold loss. Both a (L) n and a \u2032(L) n are the last hidden layer\u2019s activations using a standard feed-forward operation. Equation (5) denotes the generation of an adversarial example x\u2032n from xn.\nFig. 3 shows an overview of the proposed methodology. To make a deep neural network robust to adversarial perturbations, we regard the activations of the last hidden layer as a manifold representation and minimize the difference between the two manifold embeddings of x and x\u2032 as shown in Fig. 3(a). The proposed forward and backward operations to solve (3) are presented in Fig. 3(b). The forward operation is the same as in a standard neural network:\na(l+1) = f(z(l+1)) = f(W (l)a(l) + b(l)), if l-th layer is fully-connected, (6) [ a(l+1) ]\nj = f(\n[ z(l+1) ]\nj ) = f(\n\u2211\ni\n[ a(l) ]\ni \u2217W (l) ij + b (l) j ), if l-th layer is convolutional (7)\nwhere f(\u00b7) is an activation function (chosen to be the rectified linear unit in this paper) and \u2217 is the convolutional operation of a valid size. For a convolutional layer, [a(l)]i and [a(l+1)]j are the i-th and j-th feature map in the l-th layer and (l+1)-th layer, respectively. W (l)ij is a convolutional filter between [a(l)]i and [a(l+1)]j . The following backwardadv is also the same as standard backpropagation except that an adversarial perturbation \u2207xL(\u03b8;x, y) is computed in the first layer:\n\u2207xL(\u03b8;x, y) = ( \u03b4(2) \u25e6 g(a(2)) ) W (1), if 1-st layer is fully-connected, (8)\n[ \u2207xL(\u03b8;x, y) ]\ni =\n\u2211\nj\n([ \u03b4(2) ]\nj \u25e6 g(\n[ a(2) ] j ) ) \u22c6 W (1) ij , if 1-st layer is convolutional (9)\nwhere g(\u00b7) is the derivative of an activation function, \u22c6 is the convolutional operation of the full size, and \u25e6 is the Hadamard product (an element-wise multiplication).\nNext, another forward operation is performed to obtain all the activations of an adversarial example a\u2032(1) = x\u2032 = x+\u2206x and calculate \u2207\u03b8\u03a6(X ,X \u2032). Recall that \u03a6(xn, x\u2032n) is the squared error between the original a(L)n and its adversarial a \u2032(L) n :\n\u03a6(xn, x \u2032 n) = (1/2)\u2016a (L) n \u2212 a \u2032(L) n \u2016 2 2 = (1/2)(a (L) n \u2212 a \u2032(L) n ) T (a(L)n \u2212 a \u2032(L) n ). (10)\nSimilar to the backpropagation algorithm, we first compute error terms \u03b4(L)1 and \u03b4 (L) 2 :\n\u03b4 (L) 1 = \u2212(a \u2032(L) \u2212 a(L)), \u03b4 (L) 2 = \u2212(a (L) \u2212 a\u2032(L)). (11)\nThe error \u03b4(L)1 is the difference of a \u2032(L) with respect to a(L), and the error \u03b4(L)2 is the difference of a(L) with respect to a\u2032(L). Now, we can present the gradients and back-propagation for the manifold\nloss term \u03a6 for each layer l = L, . . . , 2. If the l-th layer is fully-connected, the rules are as follows:\n\u2207W (l\u22121)\u03a6(X ,X \u2032) =\n1\nn\n(( \u03b4 (l) 1 \u25e6 g(a (l)) ) (a(l\u22121))T + ( \u03b4 (l) 2 \u25e6 g(a \u2032(l)) ) (a\u2032(l\u22121))T ) , (12)\n\u2207b(l\u22121)\u03a6(X ,X \u2032) =\n1\nn\n(( \u03b4 (l) 1 \u25e6 g(a (l)) ) 1+ ( \u03b4 (l) 2 \u25e6 g(a \u2032(l)) ) 1 ) , (13)\n\u03b4 (l\u22121) 1 = (W (l))T \u03b4 (l) 1 , \u03b4 (l\u22121) 2 = (W (l))T \u03b4 (l) 2 . (14)\nThe rules for a convolutional layer are as follows: [\n\u2207W (l\u22121)\u03a6(X ,X \u2032) ]\ni =\n1\nn\n\u2211\nj\n(\na(l\u22121) \u2217 ( \u03b4 (l) 1 \u25e6 g(a (l)) ) + a\u2032(l\u22121) \u2217 ( \u03b4 (l) 2 \u25e6 g(a \u2032(l)) )) , (15)\n[ \u2207b(l\u22121)\u03a6(X ,X \u2032) ]\ni =\n1\nn\n\u2211\nrow\n\u2211\ncol\n\u2211\nn\n(( \u03b4 (l) 1 \u25e6 g(a (l)) ) + ( \u03b4 (l) 2 \u25e6 g(a \u2032(l)) )) , (16)\n[ \u03b4 (l\u22121) 1 ] i =\n\u2211\nj\n[ \u03b4 (l) 1 ] j \u22c6 W (l) ij , [ \u03b4 (l\u22121) 2 ] i =\n\u2211\nj\n[ \u03b4 (l) 2 ] j \u22c6 W (l) ij . (17)"}, {"heading": "4 EXPERIMENTS", "text": "The optimization of the proposed method was conducted using standard stochastic gradient descent. The mini-batch size and the momentum were set to 100 and 0.9, respectively. The learning rate was annealed as described in Wan et al. (2013). For each subsection, we present an initial learning rate and three numbers of epochs, such as 0.001 (100-20-10). We trained models with the initial rate for the first number of epochs. Then, we multiplied by 0.1 for the second epochs followed by 0.5 again for the third epochs. For example, the learning schedule 0.001 (100-20-10) denotes a learning rate of 0.001 for 100 epochs followed by 0.0001 for 20 epochs and 0.00005 for 10 epochs.\nWe evaluated the proposed regularization on three benchmark datasets: MNIST (LeCun et al., 1998), CIFAR-10 (Krizhevsky & Hinton, 2009), and SVHN (Netzer et al., 2011), as depicted in Fig. 4. In the case of the CIFAR and SVHN, we preprocessed the data using zero-phase component analysis (ZCA) whitening and local contrast normalization; the same techniques as Goodfellow et al. (2013) and Zeiler & Fergus (2013), respectively. These preprocessing techniques are known for normalizing the extreme brightness and color variations efficiently.\nOur implementation was based on Caffe (Jia et al., 2014), which is one of the most popular deep learning frameworks. We added new forward-backward steps and customized four types of layers: convolutional, pooling, response normalization (Hinton et al., 2012), and fully-connected layers. The codes and all the details of hyper-parameters [i.e., weight decay and the number of hidden nodes] are available on our GitHub page 1. For each case, we presented a mean value with a standard deviation among 10 runs as a format of \u00b5 \u00b1 \u03c3. For the generation of adversarial examples, we had to maintain an appropriate noise level \u03b2. This is shown in detail in the appendix and Fig. 7.\n1https://github.com/taehoonlee/caffe"}, {"heading": "4.1 IMPROVED CLASSIFICATION PERFORMANCE", "text": "MNIST The MNIST (LeCun et al., 1998) dataset is one of the most popular benchmarks and consists of a set of 28\u00d7 28 grayscale images with corresponding labels 0\u20139. Because these images have high contrast like binary images, typically they have been tested without any pre-processing. To obtain desirable representations in the manifold space, we tested two types of models.\nFirst, we trained models with two fully connected layers each with 800 hidden units, followed by a softmax layer. We used a learning schedule of 0.1 (40-40-20) and obtained a test accuracy of 98.848\u00b1 0.052%, which is the best record over the published results with only two hidden layers. DropConnect (Wan et al., 2013) and dropout (Srivastava et al., 2014) produced 98.800 \u00b1 0.034% and 98.720\u00b1 0.040%, respectively.\nAdditionally, we conducted MRnet with two convolutional layers followed by two fully connected layers. The results are summarized in Table 1. The top four methods were performed 10 times using our implementation while the results of the bottom five methods were reported in the literature. The previous best published result is the 99.55% test accuracy of Maxout (Goodfellow et al., 2013). Among the alternatives compared, MRnet achieved the state-of-the-art discriminative performance: 99.536\u00b1 0.045% (best: 99.58%).\nCIFAR-10 The CIFAR-10 (Krizhevsky & Hinton, 2009) dataset is a set of 32 \u00d7 32 color images of 10 classes. There are 50,000 training and 10,000 test images. We applied ZCA preprocessing (\u01eb = 0.01) similar to Goodfellow et al. (2013). To be consistent with previous work, we evaluated our method with 24 \u00d7 24 random cropping and horizontal flipping augmentation. The learning schedule was set to 0.001 (100-10-10).\nThe results of Caffe runs and the literature are summarized in Table 2. Note that a locally connected layer in the description column is a weight-unshared convolutional layer. We can achieve a test accuracy of 91.082\u00b1 0.237%, which sets a new performance record.\nSVHN The SVHN (Netzer et al., 2011) dataset is composed of 604,388 training and 26,032 test images of 10 classes. Following Zeiler & Fergus (2013), we conducted local contrast normalization with a 3 \u00d7 3 filter and 28 \u00d7 28 random cropping. The structure and parameters used in the SVHN are the same as those used for the CIFAR-10, which consists of three or four convolutional layers followed by two fully connected layers. For this dataset, we obtained a test accuracy of 97.521 \u00b1 0.052 with a learning schedule of 0.001 (20-20-20). A summary with the alternatives is provided in Table 2."}, {"heading": "4.2 DISENTANGLEMENT AND GENERALIZATION", "text": "The proposed manifold loss \u03a6 minimizes the 2-norm difference between a(L) and a\u2032(L). In other words, the difference in the last hidden layer\u2019s activations between an original and its adversarial sample is minimized. However, an adversarial perturbation at the beginning of training is meaningless. Thus, we applied \u03a6 after training a vanilla neural network with several iterations, in a similar way to the pre-training phase of deep belief networks. Fig. 5 shows the variation of \u2016a(L) \u2212 a\u2032(L)\u20162 over the number of iterations. The iteration 0 denotes the point at which \u03a6 is applied.\nAs illustrated in Fig. 5, MRnet minimized the manifold distances more successfully than a vanilla network. The final value of \u2016a(L) \u2212 a\u2032(L)\u20162 was 3.57. In the network we tested, the number of hidden nodes in the last hidden layer was 1024, and the average difference of individual activation values can be calculated approximately as 0.1 (= \u221a\n3.572/1024). Because each activation value in the last hidden layer ranged from 0 to 2.74, the average difference 0.1 means that a(L)\u2019s and a\u2032(L)\u2019s were projected into very closed regions by the proposed multi-layer manifold embedding.\nWe also visualized a(L) of the CIFAR-10 test set to examine the effect of the proposed manifold loss \u03a6. Fig. 6(a-c) and Fig. 6(d-f) show the embedding results without and with \u03a6, respectively. As shown in Fig. 6(d), \u03a6 increases the contrast of pairwise distances between intra-classes (blockdiagonal elements) and inter-classes (other elements) compared with Fig. 6(a). The contrast can be quantified using two clustering evaluation metrics: the silhouette coefficients \u2208 [\u22121, 1] (Rousseeuw, 1987) and the Dunn index (Dunn, 1973). As clusters are separated better, both metrics produce higher values. Without and with \u03a6, the average values of silhouette coefficients do not exhibit significant differences. However, the Dunn indices without and with \u03a6 were 0.0297 and 0.0433, respectively. Because the denominator of the Dunn index is the maximum distance within a cluster (Dunn, 1973), we argue the Dunn index can present more appropriate quantification of the contrast, and obtained 31.45% improved contrast.\nA similar effect can be found in the 2-D visualization with t-SNE (Van der Maaten & Hinton, 2008) [see Fig. 6(b) and (e)]. Without \u03a6, two boxed chunks of the automobile class are separated and one is closed to the ship and truck classes. However, \u03a6 can make instances of the automobile class be grouped into one chunk as depicted in Fig. 6(e). Finally, Fig. 6(c) and Fig. 6(f) present a few query images and the top 10 nearest neighbors on the manifold embedding space. The 10-th closest bird image of the dog and the 9-th closest bird image of the deer were eliminated in the list of nearest neighbors after applying \u03a6."}, {"heading": "5 CONCLUSION", "text": "We have proposed a novel methodology, unifying deep learning and manifold learning, called manifold regularized networks (MRnet). Traditional neural networks, even state-of-the art deep networks, have intrinsic blind spots due to a huge number of parameters and linear function components using them. We tested MRnet and confirmed its improved generalization performance underpinned by the proposed manifold loss term on deep architectures. By exploiting the characteristics of blind spots, the proposed MRnet can be extended to the discovery of true representations on manifolds in various learning tasks."}], "references": [{"title": "Representation learning: A review and new perspectives", "author": ["Bengio", "Yoshua", "Courville", "Aaron", "Vincent", "Pierre"], "venue": "IEEE TPAMI,", "citeRegEx": "Bengio et al\\.,? \\Q2013\\E", "shortCiteRegEx": "Bengio et al\\.", "year": 2013}, {"title": "A fuzzy relative of the isodata process and its use in detecting compact wellseparated clusters", "author": ["Dunn", "Joseph C"], "venue": "Journal of cybernetics,", "citeRegEx": "Dunn and C.,? \\Q1973\\E", "shortCiteRegEx": "Dunn and C.", "year": 1973}, {"title": "Explaining and harnessing adversarial examples", "author": ["Goodfellow", "Ian", "Shlens", "Jonathon", "Szegedy", "Christian"], "venue": "In ICLR,", "citeRegEx": "Goodfellow et al\\.,? \\Q2015\\E", "shortCiteRegEx": "Goodfellow et al\\.", "year": 2015}, {"title": "Reducing the dimensionality of data with neural networks", "author": ["Hinton", "Geoffrey E", "R.R. Salakhutdinov"], "venue": null, "citeRegEx": "Hinton et al\\.,? \\Q2006\\E", "shortCiteRegEx": "Hinton et al\\.", "year": 2006}, {"title": "Improving neural networks by preventing co-adaptation of feature detectors", "author": ["Hinton", "Geoffrey E", "Srivastava", "Nitish", "Krizhevsky", "Alex", "Sutskever", "Ilya", "Salakhutdinov", "Ruslan R"], "venue": "arXiv preprint,", "citeRegEx": "Hinton et al\\.,? \\Q2012\\E", "shortCiteRegEx": "Hinton et al\\.", "year": 2012}, {"title": "Batch normalization: Accelerating deep network training by reducing internal covariate shift", "author": ["Ioffe", "Sergey", "Szegedy", "Christian"], "venue": "In ICML,", "citeRegEx": "Ioffe et al\\.,? \\Q2015\\E", "shortCiteRegEx": "Ioffe et al\\.", "year": 2015}, {"title": "What is the best multi-stage architecture for object recognition", "author": ["Jarrett", "Kevin", "Kavukcuoglu", "Koray", "Ranzato", "Marc\u2019Aurelio", "LeCun", "Yann"], "venue": "In ICCV,", "citeRegEx": "Jarrett et al\\.,? \\Q2009\\E", "shortCiteRegEx": "Jarrett et al\\.", "year": 2009}, {"title": "Caffe: Convolutional architecture for fast feature embedding", "author": ["Jia", "Yangqing", "Shelhamer", "Evan", "Donahue", "Jeff", "Karayev", "Sergey", "Long", "Jonathan", "Girshick", "Ross", "Guadarrama", "Sergio", "Darrell", "Trevor"], "venue": "In Proceedings of the ACM International Conference on Multimedia,", "citeRegEx": "Jia et al\\.,? \\Q2014\\E", "shortCiteRegEx": "Jia et al\\.", "year": 2014}, {"title": "Learning multiple layers of features from tiny images", "author": ["Krizhevsky", "Alex", "Hinton", "Geoffrey"], "venue": null, "citeRegEx": "Krizhevsky et al\\.,? \\Q2009\\E", "shortCiteRegEx": "Krizhevsky et al\\.", "year": 2009}, {"title": "Imagenet classification with deep convolutional neural networks", "author": ["Krizhevsky", "Alex", "Sutskever", "Ilya", "Hinton", "Geoffrey E"], "venue": "In NIPS,", "citeRegEx": "Krizhevsky et al\\.,? \\Q2012\\E", "shortCiteRegEx": "Krizhevsky et al\\.", "year": 2012}, {"title": "Gradient-based learning applied to document recognition", "author": ["LeCun", "Yann", "Bottou", "Leon", "Bengio", "Yoshua", "Haffner", "Patrick"], "venue": "Proceedings of the IEEE,", "citeRegEx": "LeCun et al\\.,? \\Q1998\\E", "shortCiteRegEx": "LeCun et al\\.", "year": 1998}, {"title": "Multi-manifold deep metric learning for image set classification", "author": ["Lu", "Jiwen", "Wang", "Gang", "Deng", "Weihong", "Moulin", "Pierre", "Zhou", "Jie"], "venue": "In CVPR,", "citeRegEx": "Lu et al\\.,? \\Q2015\\E", "shortCiteRegEx": "Lu et al\\.", "year": 2015}, {"title": "Reading digits in natural images with unsupervised feature learning. In NIPS workshop on deep learning and unsupervised feature learning", "author": ["Netzer", "Yuval", "Wang", "Tao", "Coates", "Adam", "Bissacco", "Alessandro", "Wu", "Bo", "Ng", "Andrew Y"], "venue": null, "citeRegEx": "Netzer et al\\.,? \\Q2011\\E", "shortCiteRegEx": "Netzer et al\\.", "year": 2011}, {"title": "Deep neural networks are easily fooled: High confidence predictions for unrecognizable images", "author": ["Nguyen", "Anh", "Yosinski", "Jason", "Clune", "Jeff"], "venue": "In CVPR,", "citeRegEx": "Nguyen et al\\.,? \\Q2015\\E", "shortCiteRegEx": "Nguyen et al\\.", "year": 2015}, {"title": "Learning to disentangle factors of variation with manifold interaction", "author": ["Reed", "Scott", "Sohn", "Kihyuk", "Zhang", "Yuting", "Lee", "Honglak"], "venue": "In ICML,", "citeRegEx": "Reed et al\\.,? \\Q2014\\E", "shortCiteRegEx": "Reed et al\\.", "year": 2014}, {"title": "Silhouettes: a graphical aid to the interpretation and validation of cluster analysis", "author": ["Rousseeuw", "Peter J"], "venue": "Journal of computational and applied mathematics,", "citeRegEx": "Rousseeuw and J.,? \\Q1987\\E", "shortCiteRegEx": "Rousseeuw and J.", "year": 1987}, {"title": "Nonlinear dimensionality reduction by locally linear embedding", "author": ["S.T. Roweis", "L.K. Saul"], "venue": null, "citeRegEx": "Roweis and Saul,? \\Q2000\\E", "shortCiteRegEx": "Roweis and Saul", "year": 2000}, {"title": "Dropout: A simple way to prevent neural networks from overfitting", "author": ["Srivastava", "Nitish", "Hinton", "Geoffrey", "Krizhevsky", "Alex", "Sutskever", "Ilya", "Salakhutdinov", "Ruslan"], "venue": "Journal of Machine Learning Research,", "citeRegEx": "Srivastava et al\\.,? \\Q1929\\E", "shortCiteRegEx": "Srivastava et al\\.", "year": 1929}, {"title": "Intriguing properties of neural networks", "author": ["Szegedy", "Christian", "Zaremba", "Wojciech", "Sutskever", "Ilya", "Bruna", "Joan", "Erhan", "Dumitru", "Goodfellow", "Ian", "Fergus", "Rob"], "venue": "In ICLR,", "citeRegEx": "Szegedy et al\\.,? \\Q2014\\E", "shortCiteRegEx": "Szegedy et al\\.", "year": 2014}, {"title": "Going deeper with convolutions", "author": ["Szegedy", "Christian", "Liu", "Wei", "Jia", "Yangqing", "Sermanet", "Pierre", "Reed", "Scott", "Anguelov", "Dragomir", "Erhan", "Dumitru", "Vanhoucke", "Vincent", "Rabinovich", "Andrew"], "venue": "In CVPR,", "citeRegEx": "Szegedy et al\\.,? \\Q2015\\E", "shortCiteRegEx": "Szegedy et al\\.", "year": 2015}, {"title": "A global geometric framework for nonlinear dimensionality reduction", "author": ["Tenenbaum", "Joshua B", "De Silva", "Vin", "Langford", "John C"], "venue": null, "citeRegEx": "Tenenbaum et al\\.,? \\Q2000\\E", "shortCiteRegEx": "Tenenbaum et al\\.", "year": 2000}, {"title": "Manifold regularized deep neural networks", "author": ["Tomar", "Vikrant Singh", "Rose", "Richard C"], "venue": "In Proceedings of InterSpeech, pp", "citeRegEx": "Tomar et al\\.,? \\Q2014\\E", "shortCiteRegEx": "Tomar et al\\.", "year": 2014}, {"title": "Visualizing data using t-sne", "author": ["Van der Maaten", "Laurens", "Hinton", "Geoffrey"], "venue": "Journal of Machine Learning Research,", "citeRegEx": "Maaten et al\\.,? \\Q2008\\E", "shortCiteRegEx": "Maaten et al\\.", "year": 2008}, {"title": "Regularization of neural networks using dropconnect", "author": ["Wan", "Li", "Zeiler", "Matthew D", "Zhang", "Sixin", "LeCun", "Yann", "Fergus", "Robert"], "venue": "In ICML,", "citeRegEx": "Wan et al\\.,? \\Q2013\\E", "shortCiteRegEx": "Wan et al\\.", "year": 2013}, {"title": "Scene recognition by manifold regularized deep learning architecture", "author": ["Y. Yuan", "L. Mou", "X. Lu"], "venue": "IEEE TNNLS,", "citeRegEx": "Yuan et al\\.,? \\Q2015\\E", "shortCiteRegEx": "Yuan et al\\.", "year": 2015}, {"title": "Stochastic pooling for regularization of deep convolutional neural networks", "author": ["Zeiler", "Matthew", "Fergus", "Robert"], "venue": "In ICLR,", "citeRegEx": "Zeiler et al\\.,? \\Q2013\\E", "shortCiteRegEx": "Zeiler et al\\.", "year": 2013}], "referenceMentions": [{"referenceID": 9, "context": "Deep neural networks have been used successfully to learn meaningful representations on a variety of tasks (Hinton & Salakhutdinov, 2006; Krizhevsky et al., 2012).", "startOffset": 107, "endOffset": 162}, {"referenceID": 23, "context": ", 2014), DropConnect (Wan et al., 2013), and Batch Normalization (Ioffe & Szegedy, 2015)] and well-structured networks [i.", "startOffset": 21, "endOffset": 39}, {"referenceID": 19, "context": ", 2014), and Inception (Szegedy et al., 2015)].", "startOffset": 23, "endOffset": 45}, {"referenceID": 18, "context": "The perturbations, which are barely perceptible to humans but make neural networks easily less confident, are called adversarial examples (Szegedy et al., 2014; Goodfellow et al., 2015; Nguyen et al., 2015).", "startOffset": 138, "endOffset": 206}, {"referenceID": 2, "context": "The perturbations, which are barely perceptible to humans but make neural networks easily less confident, are called adversarial examples (Szegedy et al., 2014; Goodfellow et al., 2015; Nguyen et al., 2015).", "startOffset": 138, "endOffset": 206}, {"referenceID": 13, "context": "The perturbations, which are barely perceptible to humans but make neural networks easily less confident, are called adversarial examples (Szegedy et al., 2014; Goodfellow et al., 2015; Nguyen et al., 2015).", "startOffset": 138, "endOffset": 206}, {"referenceID": 2, "context": "This phenomenon occurs due to fewer training examples than parameters and the inner products of high-dimensional vectors (Goodfellow et al., 2015).", "startOffset": 121, "endOffset": 146}, {"referenceID": 2, "context": ", 2014; Goodfellow et al., 2015; Nguyen et al., 2015). This phenomenon occurs due to fewer training examples than parameters and the inner products of high-dimensional vectors (Goodfellow et al., 2015). In the case of fully connected layers, activation grows by \u01ebn in the worst-case, when n components of an inner product are changed by \u01eb. As shown in Fig. 1(a), decision boundaries constructed by deep networks are wiggly and sensitive to adversarial perturbations. In Goodfellow et al. (2015) in particular, adversarial training was proposed to minimize classification loss both on given samples and adversarial examples.", "startOffset": 8, "endOffset": 495}, {"referenceID": 20, "context": ", ISOMAP (Tenenbaum et al., 2000), Locally Linear Embedding (Roweis & Saul, 2000), and t-SNE (Van der Maaten & Hinton, 2008)] are well-formulated to find transformation preserving geodesic distances in high-dimensional space, they demonstrate limited performance in practice because of insufficient nearest training samples (Fig.", "startOffset": 9, "endOffset": 33}, {"referenceID": 14, "context": "There have been many attempts (Reed et al., 2014; Tomar & Rose, 2014; Yuan et al., 2015) to unify deep learning and manifold learning.", "startOffset": 30, "endOffset": 88}, {"referenceID": 24, "context": "There have been many attempts (Reed et al., 2014; Tomar & Rose, 2014; Yuan et al., 2015) to unify deep learning and manifold learning.", "startOffset": 30, "endOffset": 88}, {"referenceID": 0, "context": "Researchers anticipate that neural networks with multiple layers could learn a manifold embedding and classifier simultaneously (Bengio et al., 2013).", "startOffset": 128, "endOffset": 149}, {"referenceID": 24, "context": "For example, Locally Linear Embedding (Roweis & Saul, 2000) was used as a base unit for a deep architecture (Yuan et al., 2015).", "startOffset": 108, "endOffset": 127}, {"referenceID": 0, "context": "Researchers anticipate that neural networks with multiple layers could learn a manifold embedding and classifier simultaneously (Bengio et al., 2013). However, traditional loss terms, such as a reconstruction or classification error, are not sufficient to capture local variations on manifolds. To support the manifold hypothesis, we need to employ another type of cost function that makes neighborhoods have a similar representation. Hence, there have been many attempts to combine both functional concepts of deep and manifold learning. Attempts to unify deep and manifold learning can be divided into two categories: manifold learningbased unifying and deep learning-based unifying. The former finds a hierarchical manifold embedding with layer-wise manifold learning in the same way as pre-training in deep belief networks. For example, Locally Linear Embedding (Roweis & Saul, 2000) was used as a base unit for a deep architecture (Yuan et al., 2015). The latter incorporates an additional objective from the manifold learning perspective into a framework of deep learning. For instance, the following objective was proposed in Reed et al. (2014): \u2211", "startOffset": 129, "endOffset": 1152}, {"referenceID": 11, "context": ", Lu et al. (2015)] are also possible; however, variations still have limitations inherited from", "startOffset": 2, "endOffset": 19}, {"referenceID": 19, "context": "Figure 2: An example of adversarial perturbation applied to GoogLeNet (Szegedy et al., 2015) [retrieved from Goodfellow et al.", "startOffset": 70, "endOffset": 92}, {"referenceID": 2, "context": ", 2015) [retrieved from Goodfellow et al. (2015)].", "startOffset": 24, "endOffset": 49}, {"referenceID": 0, "context": "Training set neighborhood information may be problematic because most nearest samples have too little in common in high-dimensional Euclidean spaces (Bengio et al., 2013).", "startOffset": 149, "endOffset": 170}, {"referenceID": 9, "context": "The problem of adversarial perturbations arises in several learning models as well as state-of-the-art deep networks, such as AlexNet (Krizhevsky et al., 2012) or GoogLeNet (Szegedy et al.", "startOffset": 134, "endOffset": 159}, {"referenceID": 19, "context": ", 2012) or GoogLeNet (Szegedy et al., 2015).", "startOffset": 21, "endOffset": 43}, {"referenceID": 18, "context": "This suggests that adversarial examples expose fundamental blind spots in our objective functions (Szegedy et al., 2014).", "startOffset": 98, "endOffset": 120}, {"referenceID": 2, "context": "2 [retrieved from Goodfellow et al. (2015)].", "startOffset": 18, "endOffset": 43}, {"referenceID": 10, "context": "We evaluated the proposed regularization on three benchmark datasets: MNIST (LeCun et al., 1998), CIFAR-10 (Krizhevsky & Hinton, 2009), and SVHN (Netzer et al.", "startOffset": 76, "endOffset": 96}, {"referenceID": 12, "context": ", 1998), CIFAR-10 (Krizhevsky & Hinton, 2009), and SVHN (Netzer et al., 2011), as depicted in Fig.", "startOffset": 56, "endOffset": 77}, {"referenceID": 7, "context": "Our implementation was based on Caffe (Jia et al., 2014), which is one of the most popular deep learning frameworks.", "startOffset": 38, "endOffset": 56}, {"referenceID": 4, "context": "We added new forward-backward steps and customized four types of layers: convolutional, pooling, response normalization (Hinton et al., 2012), and fully-connected layers.", "startOffset": 120, "endOffset": 141}, {"referenceID": 17, "context": "The learning rate was annealed as described in Wan et al. (2013). For each subsection, we present an initial learning rate and three numbers of epochs, such as 0.", "startOffset": 47, "endOffset": 65}, {"referenceID": 2, "context": "In the case of the CIFAR and SVHN, we preprocessed the data using zero-phase component analysis (ZCA) whitening and local contrast normalization; the same techniques as Goodfellow et al. (2013) and Zeiler & Fergus (2013), respectively.", "startOffset": 169, "endOffset": 194}, {"referenceID": 2, "context": "In the case of the CIFAR and SVHN, we preprocessed the data using zero-phase component analysis (ZCA) whitening and local contrast normalization; the same techniques as Goodfellow et al. (2013) and Zeiler & Fergus (2013), respectively.", "startOffset": 169, "endOffset": 221}, {"referenceID": 23, "context": "DropConnect (Wan et al., 2013) 99.", "startOffset": 12, "endOffset": 30}, {"referenceID": 6, "context": "53 Lasso in F-layers (Jarrett et al., 2009) 99.", "startOffset": 21, "endOffset": 43}, {"referenceID": 23, "context": "DropConnect (Wan et al., 2013) 2C + 2L + 1F 90.", "startOffset": 12, "endOffset": 30}, {"referenceID": 10, "context": "MNIST The MNIST (LeCun et al., 1998) dataset is one of the most popular benchmarks and consists of a set of 28\u00d7 28 grayscale images with corresponding labels 0\u20139.", "startOffset": 16, "endOffset": 36}, {"referenceID": 23, "context": "DropConnect (Wan et al., 2013) and dropout (Srivastava et al.", "startOffset": 12, "endOffset": 30}, {"referenceID": 2, "context": "01) similar to Goodfellow et al. (2013). To be consistent with previous work, we evaluated our method with 24 \u00d7 24 random cropping and horizontal flipping augmentation.", "startOffset": 15, "endOffset": 40}, {"referenceID": 12, "context": "SVHN The SVHN (Netzer et al., 2011) dataset is composed of 604,388 training and 26,032 test images of 10 classes.", "startOffset": 14, "endOffset": 35}, {"referenceID": 12, "context": "SVHN The SVHN (Netzer et al., 2011) dataset is composed of 604,388 training and 26,032 test images of 10 classes. Following Zeiler & Fergus (2013), we conducted local contrast normalization with a 3 \u00d7 3 filter and 28 \u00d7 28 random cropping.", "startOffset": 15, "endOffset": 147}], "year": 2015, "abstractText": "Learning meaningful representations using deep neural networks involves designing efficient training schemes and well-structured networks. Currently, the method of stochastic gradient descent that has a momentum with dropout is one of the most popular training protocols. Based on that, more advanced methods (i.e., Maxout and Batch Normalization) have been proposed in recent years, but most still suffer from performance degradation caused by small perturbations, also known as adversarial examples. To address this issue, we propose manifold regularized networks (MRnet) that utilize a novel training objective function that minimizes the difference between multi-layer embedding results of samples and those adversarial. Our experimental results demonstrated that MRnet is more resilient to adversarial examples and helps us to generalize representations on manifolds. Furthermore, combining MRnet and dropout allowed us to obtain improvements over the best published results for three well-known benchmarks: MNIST, CIFAR-10, and SVHN.", "creator": "LaTeX with hyperref package"}}}