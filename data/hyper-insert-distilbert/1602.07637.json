{"id": "1602.07637", "review": {"conference": "arxiv", "VERSION": "v1", "DATE_OF_SUBMISSION": "24-Feb-2016", "title": "A Survey on Domain-Specific Languages for Machine Learning in Big Data", "abstract": "simultaneously the amount of data generated dramatically in the modern society is keeping increasing rapidly. new problems and novel approaches of data capture, storage, array analysis technique and image visualization are globally responsible for illustrating the emergence of the big data research intensive field. machine learning compression algorithms always can be used in creating big science data gathering to make better and more accurate logical inferences. however, because much of the challenges big end data imposes, these algorithms need today to be adapted correctly and optimized broadly to specific experimental applications. traditionally one important decision point made by modern software technical engineers alike is the continuous choice of the broad language methodology that is easily used continuously in the implementation of these useful algorithms. starting therefore, here this literature binding survey identifies and describes domain - specific languages and frameworks used professionally for machine learning in storing big 1 data. by doing around this, our software engineering engineers can then obviously make more informed choices and beginners have an overview approach of combining the main languages used efficiently in this larger domain.", "histories": [["v1", "Wed, 24 Feb 2016 18:58:34 GMT  (369kb)", "http://arxiv.org/abs/1602.07637v1", null], ["v2", "Tue, 8 Mar 2016 19:34:37 GMT  (366kb)", "http://arxiv.org/abs/1602.07637v2", null]], "reviews": [], "SUBJECTS": "cs.SE cs.AI", "authors": ["ivens portugal", "paulo alencar", "donald cowan"], "accepted": false, "id": "1602.07637"}, "pdf": {"name": "1602.07637.pdf", "metadata": {"source": "CRF", "title": "A Survey on Domain-Specific Languages for Machine Learning in Big Data", "authors": ["Ivens Portugal", "David R. Cheriton", "Paulo Alencar", "Donald Cowan"], "emails": ["iportugal@uwaterloo.ca", "palencar@cs.uwaterloo.ca", "dcowan@csg.uwaterloo.ca"], "sections": [{"heading": null, "text": "Keywords\u2014literature survey; domain-specific languages; DSL;"}, {"heading": "Machine Learning; ML; Big Data; BD", "text": "I. INTRODUCTION The evolution of technology in the last decades caused a major data revolution [72]. Every second, smartphones, tablets, cars, websites, and systems generate a massive amount of data, and users and software engineers have access to a subset of that data to perform their activities. For example, a user who is about to start a trip may inspect a digital map with the visual displacement of roads and cities to decide the best route to take, based on real-time traffic and weather information. In addition, a software engineer may have access to a user\u2019s previous trips and routes taken, to develop a system that is capable of recommending the best route based on that information. This recent phenomenon of the generation of a high volume of digital data that is available to be processed is called Big Data [4].\nBig Data not only accounts for the large volume of data, but also for the unstructured nature of that data, known as variety, and the need of immediate processing of this data, known as velocity. These three V\u2019s of Big Data were introduced by Doug Laney [21] and are generally used to define Big Data and its characteristics. Big Data also created new challenges in data management. Traditional ways of data storage and analysis do not scale well to this amount of data, which can reach hundreds of terabytes or more, and new approaches are being developed to address these issues [36].\nAnalyzing this data is relevant because it gives insights about the reasons and the context that data is generated [55]. Additionally, it helps analysts estimate future trends about the use or the context of data. For instance, when analyzing data generated by smartphone sensors (accelerometer, gyroscope, heart monitor), a system can discover the exercise patters of a user. Inferences about this data can help suggest better exercise approaches, as well as warn about incorrect exercises.\nMachine Learning is one technique of processing data and making inferences about it [59]. This research area is being widely used to discover patterns, identify trends, suggest actions, and optimize output. Because Machine Learning techniques make better inferences and predictions when more relevant data is available, applying these techniques to Big Data field is of major interest [56].\nHowever, applications of Machine Learning in Big Data have to overcome several Big Data challenges [38]. Data storage and processing should be carefully considered, and algorithms may be described in a parallel way [2]. Data may be scattered across different machines, perhaps distant from each other, and computations may be performed locally at each machine, to later be aggregated and to generate an output.\nThe implementation of Machine Learning techniques in Big Data may have additional challenges. Some approaches that ease this implementation are required. One of these approaches is the use of a Domain-specific Language for the implementation of the aforementioned techniques. Domainspecific Languages are languages whose instructions are easy and intuitive for a specific domain [23]. For example, HTML and SQL are considered domain-specific languages for respectively webpages creation and relation database querying. Languages that are specifically created to account for the development of Machine Learning techniques in Big Data have high-level abstractions that reduce the focus on overcoming low-level challenges.\nThis work presents a survey on Domain-specific Languages for Machine Learning in Big Data. It identifies and discusses some languages that were developed for this purpose. This is relevant for software engineers that are about to start the implementation of a system or application that uses Machine Learning techniques in massive amounts of data. This work is\nalso especially relevant for beginners in the field, who do not have experience with the languages and need to choose one to learn. In both scenarios, software engineers can make more informed choices based on this overview of the languages.\nThis document is organized as follows. In Section 2, it is discussed the Big Data research field, its applications and challenges. In Section 3, the Machine Learning research field is defined and described, as well as the importance of its relationship with Big Data. In Section 4, this work explains Domain-specific Languages, gives some examples, and presents the classification used in the survey. Section 5 lists the languages used in the survey and provide a description about them. Section 6 concludes this work with some insights and future work.\nII. BIG DATA The Big Data research field emerged from the evolution of technology [4]. In the past, the number of digital devices was not significant, when compared to the quantity of smartphones or tablets (and other so called smart devices) that exist in today\u2019s world [53]. As a consequence, the amount of digital data produced was relatively low. Web services and scientific computation produced less data and were slower [30][57] decades ago. The scientific breakthroughs of the recent years made possible the generation of a massive amount of data and in a fast pace, that needs to be stored, analyzed and visualized. In Big Data, traditional approaches of data storage, analysis, and visualization do not work well because they do not scale up, and thus new approaches are being created and studied. In an effort to characterize Big Data, Doug Laney introduced a 3V model [21]:\n\u2022 Volume - relates to the amount of data generated, which can be in the order of hundreds of terabytes.\n\u2022 Variety - relates to the number of sources and formats of data, which can be text, images, videos, and even streams of data.\n\u2022 Velocity - relates to the speed of data processing, which can be as fast as real time\nAs examples, Walmart, the chain of hypermarkets and grocery stores, registers 267 million transactions each day [15] across its 6000 stores worldwide. Additionaly, the Large Hadron Collider (LHC), the particle collider built on the border between France and Switzerland to study and test several theories of particle physics, generates 60 terabytes of data each day [9], that needs to be processed for scientific purposes.\nBig Data has applications in several domains that range from Geography to Business. The analysis of data is important and is being used to predict trends in society, or estimate and optimize costs and profits. Some examples of works being developed in Big Data research field focus on making better weather prediction [11], helping in traffic management [43], creating smart cities [34], helping in analysis of diseases [58][61] and social networks [33][69], and helping decision making in business intelligence [22][42].\nTo handle the massive amount of data efficiently, the Big Data research field has several challenges, which relates to data\ncapture, storage, analysis, and visualization [15][29]. Data capture challenges are mainly associated with devices not always being able to produce data, or data in the real world that is difficult to capture. For example, the GPS device on a smartphone may not be always working because the low coverage in the region where the user currently is in. Moreover, an application that monitors the amount of calories consumed by users may find that the calorie intake data of a user is difficult to measure. Overcoming these challenges is of extreme importance, because data capture is the first step to deliver services or to make analysis.\nData storage challenges refers to ways of storing huge amounts of data in databases. The traditional relational databases do not scale well to Big Data and novel approaches are being used. Research in both distributed storage, in which the database is split in several disks or even in several machines, and NoSQL databases, in which some database properties are relaxed for storage and query, are being developed to account for these challenges. Once data is stored, it is analyzed for insights.\nData analysis challenges relates to processing and generating insights from the massive amount of data stored. It can be particularly difficult and inefficient to process hundreds of entries in a database to find specific information requested by the use of a system. For example, a user, typically a data scientist, who wants to find a list of users interested in a particular product, for marketing purposes, may query the system, say a social network, to return users who mentioned a certain brand in their messages in the last year. The system may have to check all the messages sent in the last year by all users of the social network, and look specifically for the string containing the name of the brand to be advertised. To address this challenge, studies are being developed in the areas of parallel, distributed and cloud computing, where computations like the query exemplified before is replicated in several processors, disks or even machines.\nData visualization challenges refers to ways of representing knowledge intuitively and efficiently, using different graphs. Visualizing data is the primary and most important way of having insights about the present and future of some phenomena. However, with the amount of data generated in Big Data, visualization needs to be carefully planned and executed. A well-constructed graph can show where, when, or how (temporal, spatial, or situational condition) data behave. Scientists then are able to draw conclusions and predict trends. Research on these visualization challenges can be found on [54][64][75].\nIn the near future, two areas are increasingly relevant to Big Data researchers: privacy and Internet of Things. Several applications of Big Data collect and process user data, either to provide services for the user, such as recommendation systems or information search, or analysis, such as testing scientific theories or decision-making in business intelligence. For that reason, several studies analyze the privacy implications [16][40][60] of these approaches, and ethical questions about data ownership. As a result, some limits of data collection may arise. Another future direction [14] shows that Big Data will become even more important with the development of the\nInternet of Things (IoT) research area in the next few years. In IoT, there are several systems and sensors connect to deliver better results to users. For example, buses and taxis can have an embedded GPS device generating location data, which can be presented to users on a mobile application. Users then have access to real time location of buses and taxis, and are able to plan a trip to another city more efficiently. In IoT, even more data will be generated and more studies in Big Data needs to be performed to account for the new challenges.\nIII. MACHINE LEARNING The Machine Learning research area has roots in the middle of last century, but just became popular in the 1990s. Today, it is one of the most important research fields. Scientific achievements in this area are changing the way humans interact with computers and promising results are to come in the next decades.\nA useful, and somewhat formal, definition of Machine Learning made by Tom Mitchel [48] states: \u201cA computer program is said to learn from experience E with respect to some classes of tasks T and performance measure P, if its performance at tasks in T, as measured by P, improves with experience E\u201d. This definition clearly states that there is a positive correlation between performance and experience in Machine Learning. This means that Machine Learning applications may increase their performance and accuracy according to the amount of data they are exposed to.\nMachine Learning applications are currently present in many domains that go from entertainment to the analysis of businesses. Microsoft\u2019s Kinect [44], for example, is a very popular movement recognition device for Microsoft\u2019s Xbox [45]. It has Machine Learning algorithms that can identify body parts of users using a camera. The main applications of this technology is in the video game industry, but other research studies use it, for instance, to detect Parkinson\u2019s disease [65], improve limb rehabilitation [19], or study balance and risk of falling in older adults [37]. Autonomous driving [20][32] is another application of machine learning techniques that has been under investigation and is generating interesting results. Major car companies and manufactures around the world are heavily researching and investing in this technology. Recommendation systems also use Machine Learning in their workings to better recommend items to users. Several studies in the literature [39][66][74] describe approaches in this direction.\nMachine Learning algorithms are classified in supervised, unsupervised, and reinforcement learning [56]. Supervised learning algorithms have a training phase, where labeled data, i.e. data with the expected output, is fed into the algorithm, so it can learn. On a second phase, the algorithm is executed having unlabeled data as input and generating output. Some examples of algorithms are Logistic Regression [24] and Neural Networks [76]. Unsupervised learning algorithms works on unlabeled data only and uncover hidden patters. Some algorithms that can be used in unsupervised learning are Clustering [50] and k-means [28]. Reinforcement learning algorithms receive feedback from the real world at each output, and based on it, they may improve their future outputs. An analogy is learning from the mistakes. Some examples of\nreinforcement learning algorithms are Bandits [31] and Qlearning [70].\nApplying Machine Learning in the Big Data field is desired and beneficial [73]. The assumption is that the more data is available to be processed, the better are the accuracy of algorithms in predictions. However, such algorithms have to overcome Big Data problems of storage and processing. Because data is large in size and amount, they are stored in different locations and its retrieval is not easy. Moreover, processing that data may not be efficient, and algorithms have to be adapted and optimized to specific cases [2][26].\nOne key element in the development of Machine Learning algorithms in Big Data is the language used. Depending on the choice of the development language, some abstractions may be easy represented and quickly described. For example, a library that helps software engineers execute distributed matrix multiplication speeds up algorithm development, since the software engineer do not need to spend time or effort into overcoming Big Data low-level challenges for this operation. To account for challenges like this one, this document surveys Domain-specific Languages used in the development of Machine Learning algorithms that work on Big Data. More details are explained in the next section.\nIV. DOMAIN-SPECIFIC LANGUAGES One fundamental part of development of systems in computer science is the communication of ideas, either between humans or from humans to machines. To represent these ideas, software engineers use a language. Although most of the languages used by software engineers are programming languages, such as C or Java, the set of useful languages are not limited to only this type. Software engineers may use modeling languages to represent a system, or communicate a concept among them. Modeling languages can be described using figures or drawings made by hand or with the aid of computer software. Moreover, prior to the development of a system, software engineers communicate the requirements of the system, i.e. a description of the needs of the stakeholders that the system to be developed will solve or address. Requirements are often written in natural language, but alternatively they can be written using formal language. Languages in computer science can be separated into generalpurpose languages (GPL) or domain-specific languages (DSL). GPLs are languages that are used to solve problems in several domains of computer science. Some examples of GPLs are C, Java, or Python. These languages can be used to create a system to manage academic information in a university, or to control equipment in the space. In contrast, DSLs are languages created to address problems of a specific domain. Their expressiveness is focused into a specific class of applications [23]. Some popular DSLs are SQL, HTML, Lisp, and OpenGL. These languages focus on a subset of the whole problem space in computer science. SQL, for example, is used to retrieve data from a relational database. Its expressiveness is limited to the most useful operations in this domain. This limited expressiveness has a positive point. It moves the software engineer away from low-level details that are not the focus of the system in development, and let them target at the work of the solution for the problem at hand. In reality, there is\na fuzzy boundary in the classification between GPLs and DSLs, so an agreement may not always be possible. For example, a so-called GPL that has several libraries to facilitate and automate graph processing may be considered a DSL for the network domain.\nDomain-specific languages have several advantages over general-purpose languages [17]. DSLs offer pre-defined abstractions to represent concepts from the application domain. This representation may be more clear and intuitive. Moreover, DSL compilers may optimize the code written for the specific domain, and they can perform error detection more efficiently. Lastly, DSLs may have more specific tool support that help software engineers increase their productivity.\nThis document shows a survey on DSLs used in the domain of Machine Learning in Big Data. The choice of limiting the target of the survey only to DSLs is to identify some languages that are used in the domain, but are not well known as the GPLs. However, a survey on the GPLs used in this domain is planned as a future work. Additionally, this survey considers three types of languages: programming, modeling, and requirements.\nTo describe the languages selected to this survey, a research on the classification of DSLs was performed. The features described in three different publications [23][67][68] compose the classification scheme that is used in this survey. The DSLs considered in this survey are described according to the features explained as follows. DSLs may assume the three following types: requirements, programming, or modeling. Requirement languages express what must be present in a system, while programming languages are used to implement the system. Modeling languages are usually graphical languages used to express ideas, algorithms or components of a system, and languages of this type are also considered in this survey. The nature of the language may be textual or graphical, depending on the way it is expressed. DSLs can be internal or external. The former one uses a host language to be developed. Most of the times, an external DSL inherits part of the GPLs syntax, and leverage the GPLs\u2019 tools such as the compiler, and the running environment. The host language is usually, but not necessarily, a GPL. In contrast, external DSLs are languages created from scratch. The developer of the language has the freedom to specify the syntax, the default library, and the intuitiveness of the language. Because external languages do not have a base language, its developer has to decide the language\u2019s target platform, which is usually a compiler, and its execution engine. DSLs are also classified into dynamically typed, when variable type checking is done at runtime, or statically typed, when that operation is done in compilation time. According to the way DSLs are structured, they can be imperative or declarative. Imperative DSLs have instructions that describe how data is manipulated during execution as a sequence of steps. Declarative DSLs, although still a cloudy term, refer to the languages that move away from imperative style and express what should be executed, putting less attention to how it is done. For that reason, DSLs are considered to be in a higher level of abstraction. Finally, domain-specific programming languages can be translated or interpreted to machine code. Translation, or compilation, is the process of applying syntax and semantic analysis of the code,\nas well as some optimization routines, prior to generating the final executing code. Interpretation uses pre-compiled routines to quickly and immediately execute each line of code written. Domain-specific modeling languages also have two ways to be classified. Descriptive modeling refers to models that express concepts of a system. They abstract some aspects of the system, such as components, calculations, or the relationship with users, and emphasize others. Alternatively, a prescriptive modeling relates to models that can be used to automatically construct the target system. This means that a prescriptive modeling language may be written in a level of formality that enables the software engineer to generate programming code that will likely be used in the development of the system.\nV. THE SURVEY This paper presents a survey on Domain-specific Languages for Machine Learning in Big Data. DSLs ease the implementation of Machine Learning algorithms with the use of high-level abstractions or reusable pieces of code that hides low-level details from software engineers, letting them focus on the main problem at hand. By analyzing languages that are focused in this domain, software engineers can make more informed choices before starting an implementation of an algorithm, and beginners may learn what are the most used and main languages of the domain. Table I, at the end of this paper, lists the DSLs that were identified and summarizes the classification of the languages using the properties explained in the previous section. Each DSL of the list is described in the following paragraphs.\nOptiML [12][25][62] is a DSL designed as a research project from Stanford University\u2019s Pervasive Parallelism Laboratory with the goal of enabling Machine Learning algorithms to take advantage of parallelism. Its authors expect to bridge the gap between Machine Learning and heterogeneous hardware of Big Data without compromising the productivity of software engineers, neither the performance of the algorithm. OptiML is a textual programming language built on top of Scala, another DSL that is explained in more detail later. Variables in OptiML have their types specified before execution, which means that the language is statically typed. Moreover, OptiML is declarative because its high-level code constructions hide low-level parallelization concerns, which makes the code clear and efficient. OptiML runs on top of Delite [63], a compiler framework developed by the same research team, and supports operations with the basic three types: vector, matrix, and graph. Its operations supports parallel executions (using the MapReduce programming model [18]) in heterogeneous machines, which are machines that have more than one type of processor or core. One limitation of the language is its lack of support for a distributed environment or executions in the cloud.\nScalOps [8][71] is a DSL with the goal of enabling Machine Learning algorithms to run on a cloud computing environment and overcoming a limitation of the traditional MapReduce programming model: the lack of iteration. ScalOps is a textual programming DSL developed in jointly by the University of California, Irvine and Santa Cruz, and the division Yahoo! Research. The DSL also has Scala language serving as a host language, which means that ScalOps is an\ninternal DSL. Its high-level syntax makes it a declarative language, and as the type checking happens in compilationtime, ScalOps is considered a statically typed. ScalOps needs to be compiled to generate lower level code, which makes it be classified as a translated language, according to the analysis of this survey. Additionally, the language supports vector, matrix, and graph operations in both parallel and cloud computing environment. To support iterations in MapReduce, ScalOps designers introduced an enhanced version of the programming model called Map-Reduce-Update [8]. This new version consists of three user-defined functions called map, reduce, and update. The map function receives read-only global state values and is applied to training data points in parallel. The reduce function aggregates the output of the map function. Finally, the update function receives the aggregated value and produces a new global state value for the next iteration. Alternatively, when appropriate, the update function indicates that no additional iteration is necessary.\nScala [49] is a DSL developed by Martin Odersky and released in 2004. The language was designed to be concise, although having a broad applicability. Scala is a textual programming languages classified as an internal DSL, having Java as its host language. The name of the language is a union of the words \u201cscalable\u201d and \u201clanguage\u201d, meaning that the language grows following the demands of the user. Scala, like Java, is statically typed and imperative. It uses a Scala compiler to translate Scala code into Java bytecode, which can be run in Java Virtual Machine (JVM). Scala has built-in support to parallel code development, including vector operations. However, matrix and graph operations are not natively supported. Another limitation of the language is its lack of support for execution of algorithms in distributed and cloud environments.\nPig Latin [51] was also developed by Yahoo! Research. Released in 2008, the language has the goal of abstracting MapReduce implementation and turning it easy to program and to perform. Pig Latin runs on top of Apache Pig, a platform developed by Apache and it implements Apache Hadoop [3]. Hadoop is the framework used by Pig to execute MapReduce. Pig Latin is a textual programming DSL that has no host language, which means that it is classified as an external DSL. The language is dynamically typed, and variables can assume the form of an atom, for atomic values, tuple, for a sequence of fields, bag, for a collection of tuples, or map, for a collection of data items where each item has an associated key. Although Pig Latin follows the declarative style of SQL, it is considered a procedural language because of the way software engineers describe operations on data. Pig Latin features a compiler that translates the DSL code into MapReduce jobs, which are then executed using the existing Apache Hadoop infrastructure under Apache Pig platform. Pig Latin offers built-in support for vector and matrix operations. It also assists parallel execution of algorithms. Machine Learning algorithms can be implemented using user-defined functions, which can be written in the following languages: Java, Python, Javascript, Ruby, or Groovy. Pig Latin also supports distributed and cloud computing by leveraging from Apache Hadoop Cluster [3], a framework for distributed storage and processing of very large data sets.\nSCOPE [13] is a DSL developed by Microsoft to account for the distributed and cloud computing challenges in querying and managing data. SCOPE stands for Structured Computations Optimized for Parallel Execution, and was also released in 2008. The language simplifies parallel processing of massive data sets without compromising efficiency. It is a textual programming language and an external DSL, with its own syntax and no host language. Regarding SCOPE\u2019s syntax, it is similar to SQL with very similar instructions such as select, from, where, group by, and order by. SCOPE is dynamically typed, i.e. its variables have types assigned during execution time. Custom user-defined functions are written in C#, which is a GPL and is not considered in this survey of the literature. SCOPE is a declarative DSL, which means that it have abstractions to allow software engineers to focus on data transformations that are required to solve the problems at hand and it also mean that the syntax of the language hide the complexity of the underlying platform and some implementation details. SCOPE code is compiled by a SCOPE compiler and executed by Cosmos Execution Environment. Data is stored in Cosmos Storage System [13], also developed by Microsoft. Parallel computations are supported by SCOPE, and they are executed using a MapReduce-like programming model. The new model uses two native functions: process, which takes row sets as inputs, processes it, and outputs another sequence of rows; and reduce, which groups data columns, process them, and outputs zero, one or multiple rows per group. Only vector and matrix operations are natively supported by SCOPE, but computations may happen in parallel, distributed, or cloud environments.\nSawzall [52] is a DSL developed by engineers at Google. It addresses the problem of retrieving and processing data separated across several disks in a MapReduce fashion, with filters and aggregators. Sawzall is a textual programming DSL first described in 2003. The language is an external DSL, having no host language, and statically typed. According to the authors, the reason for creating the language with a static type model is to avoid rework in case of type error. Executing scripts in Sawzall, and in Big Data in general, can be very time-consuming and the cost of a late-arising dynamically typed error is very expensive. Sawzall is also classified as an imperative language, which means that code written should describe how data is manipulated, and not what is done to manipulate the it. Sawzall code is interpreted into low-level language, and only the Sawzall runtime, called szl, was open sourced. The Sawzall engine remains proprietary. Data manipulated in Sawzall are stored in the Google File System (GFS), a proprietary distributed file system created by Google to store the large amount of data the company deals with. Finally, Sawzall language offers parallel, distributed, and even cloud computations, and supports the basic types vector and matrix.\nThe next language in the list did not have a name associated with it, and it was decided to refer to it as VisuML [6]. VisuML is a language aimed at representing, in high-level, Machine Learning systems that handle Big Data. The language is based on abstractions of other modeling languages and some language constructs, namely graphical models [27], factor graphs [5], plates[10], and gates [46]. The author of VisuML\nexplains the syntax of the language but do not offer a translation to any programming language. Instead, the author only suggests a way of implementing VisuML\u2019s constructions in C#. The actual implementation is left as future work. Therefore, VisuML is classified as a modeling DSL. It uses its own symbols to express domain-specific concepts, which makes it an external DSL. Finally, because its symbols cannot generate code, VisuML is said to have a descriptive model.\nGraphical models [27] are a language to describe probabilistic models visually. Circles represent random variables and the relationship between them, which is expressed with directed line segments, represents joint distributions. The language is widely used to describe Bayesian networks, which is a probabilistic model used to perform inference and learning in data. Graphical models are classified as a graphical and modeling DSL that do not have a host language, which means it is external. Additionally, the language has a descriptive model, since its graphical representation is not meant to automatically generate code.\nThis survey\u2019s goal is to identify DSLs that address problems in the domain of Machine Learning in Big Data. However, another important component of the solutions for these problems is the framework that works in the execution of the language. It was decided to include in this survey a brief description of some frameworks found in the literature, as it can help in the decision of the language used to express or develop systems in the domain addressed by this work. Table II, also shown at the end of this document, lists the frameworks alongside its characteristics. A more detailed explanation is given in the following paragraphs.\nInfer.net [47] is a framework created by Microsoft Research Cambridge aimed at running Bayesian inference in graphical models. Users write their textual codes in any .NET language, such as C#, C++, F#, or IronPython, and then they run their code to make inferences on data. The framework offers built-in support for vector and matrix operations, but lacks to assist users in parallel, distributed or even cloud computing.\nGraphlab [41] is a framework for the implementation of Machine Learning algorithms, developed jointly by researchers in Carnegie Mellon University and the University of California Berkeley. Its main focus is to provide parallelization of Machine Learning algorithms and thus increase the efficiency of their executions. Algorithms are written using textual code in C++ or Python. Although the framework originally offered assistance to only graph operations, its creators later added support to vector and matrix operations. The framework also supports code execution in parallel, distributed, and cloud computing environments. Years after GraphLab framework project was started, in 2009, it was managed by the startup GraphLab.Inc. Today, the startup evolved to Dato.Inc, and the framework has a commercial version called GraphLab Create.\nTensorFlow [1] is a framework introduced by Google Research in 2015 to express and execute Machine Learning algorithms efficiently in scalable manner. The need for efficiency and scalability is to address the Big Data challenges explained in previous sections. Internal services at Google use TensorFlow, and according to the authors the execution of\nalgorithms process data containing hundreds of billions of parameters and in hundreds of heterogeneous machines. Machine Learning algorithms in TensorFlow are written in either C++ or Python. The framework supports users with vector, matrix, and graph operations for parallel execution. Distributed and cloud computing are also assisted by TensorFlow.\nVI. CONCLUSIONS In the last decade, the number of digital data generated by devices, services, and scientific applications increased significantly and new problems associated with this phenomenon arose. Traditional methods for data capture, storage, analysis, and visualization did not scale well to the new reality, and research on novel methods is being performed to address the new problems. These problems, their discussion, and the solutions proposed in the literature created a new research area called Big Data. Big Data is mainly characterized by the presence of a large amounts data (volume), but also by the great number of sources and formats (variety), and by the speed of processing required (velocity). Data have important properties and relationships that are key to new research opportunities and for business strategy. Therefore, analyzing and inferring these properties is paramount researchers and practitioners for the near future.\nMachine Learning is a research area that is reshaping the way humans leverage from computational analysis. It describes algorithms that not only analyzes data, but also predict trends, and recommend decisions to be taken. These algorithms are mathematically efficient, but have to deal with Big Data problems when implemented. Data size is large and may be stored in several disks, which belong to several machines, geographically distant. Additionally, computations may have to be distributed in this infrastructure especially for performance issues. Therefore, in most of the times, code needs be optimized to each application being developed, so efficient methods of data retrieval and processing are used by the algorithms. When adapting the Machine Learning algorithms, one important choice that software engineers need to make is the language that will be used. This survey identifies and characterizes DSLs for Machine Learning in Big Data, so software engineers can make better and more informed choices, and beginners can be introduced to some of the languages being used.\nThis survey identified eight languages published in the literature or being used in the domain of Machine Learning in Big Data, and described them using a classification created from publications about DSL found in the literature. Most of the identified languages are programming DSLs, and no DSL was found target to expressing requirements for systems in this domain. Half of the six programing languages of this survey were indirectly built on top of Java, and the remaining ones define its own syntax, i.e. they are external DSLs. The number of statically and dynamically typed languages is also balanced, and so is the number of declarative or imperative DSLs. However, the great majority of them are translated (compiled) when generating low level code, while only one is interpreted. All programming languages offers parallel execution of the code that was written, but not all supports distributed or cloud\ncomputing. Domain-specific modeling languages considered in this survey are graphical and have a descriptive model, which means that they only express the system, but do not automatically generate its code.\nAs an additional contribution, this survey also identified and described some frameworks used in the domain of Machine Learning in Big Data. Software engineers can program algorithms in several languages, but based on the languages used by the frameworks researched in this survey, one can conclude that there is a trend of using C++ and Python for the implementation of Machine Learning algorithms in the domain surveyed. Support for vector, matrix, and graph operations in a parallel environment is also observed as a trend, especially among the most recent frameworks described. Finally, recent frameworks are assisting users with distributed and cloud computing.\nThis survey is not extensive, and more languages and frameworks can be described and added in the near future. One future work in this direction is to survey general-purpose languages used in the domain of Machine Learning in Big Data. These languages, although not specifically created for the domain, have may have some properties that are critical to some types of applications, such as real time Machine Learning in Big Data. The identification of the languages and frameworks in this survey represents an important step in the knowledge of the domain, which can improve and revolutionize the way society interact with computers in the future.\nVII. ACKNOWLEDGMENTS The authors would like to thank the Natural Sciences and Engineering Research Council of Canada (NSERC), the Ontario Research Fund of the Ontario Ministry of Research and Innovation, SAP, and the Centre for Community Mapping (COMAP) for their financial support to this research.\nREFERENCES [1] Abadi, M., Agarwal, A., Barham, P., Brevdo, E., Chen, Z., Citro, C.,\nCorrado, G. S., Davis, A., Dean, J., Matthieu, D., Ghemawat, S., Goodfellow, I., Harp, A., Irving G., Isard, M., Jia, Y., Jozefowicz, R., Kaiser, L., Kudlur, M., Levenberg, J., Man\u00e9, D., Monga, R., Moore, S., Murray, D., Olah, C., Schuster, M., Shlens, J., Steiner, B., Sutskever, I., Talwar, K., Tucker, P., Vanhoucke, V., Vasudevan, V., Vi\u00e9gas, F., Vinyals, O., Warden, P., Wattenberg, M., Wicke, M., Yu, Y., & Zheng, X. TensorFlow: Large-Scale Machine Learning on Heterogeneous Systems.\n[2] Al-Jarrah, O. Y., Yoo, P. D., Muhaidat, S., Karagiannidis, G. K., & Taha, K. (2015). Efficient Machine Learning for Big Data: A Review. Big Data Research, 2(3), 87-93.\n[3] The Apache Software Foundation (Apache). (2015). Welcome to Apache Hadoop!. Retrieved from https://hadoop.apache.org. Accessed on December 12th, 2015.\n[4] Benjelloun, F. Z., Lahcen, A. A., & Belfkih, S. (2015). An overview of big data opportunities, applications and tools. In Intelligent Systems and Computer Vision (ISCV), 2015 (pp. 1-6). IEEE.\n[5] Bishop, C. M. (2006). Pattern recognition and machine learning. Springer.\n[6] Breuker, D. (2014). Towards Model-Driven Engineering for Big Data Analytics--An Exploratory Analysis of Domain-Specific Languages for Machine Learning. In System Sciences (HICSS), 2014 47th Hawaii International Conference on (pp. 758-767). IEEE.\n[7] Bryant, B. R., Gray, J., & Mernik, M. (2010, November). Domainspecific software engineering. In Proceedings of the FSE/SDP workshop on Future of woftware engineering research (pp. 65-68). ACM.\n[8] Borkar, V., Bu, Y., Carey, M. J., Rosen, J., Polyzotis, N., Condie, T., Weimer, M., & Ramakrishnan, R. (2012). Declarative Systems for Large-Scale Machine Learning. IEEE Bulletin of the Technical Committee on Data Engineering, 35(2), 24-32.\n[9] Brumfiel, G. (2011). High-energy physics: Down the petabyte highway. Nature News, 469(7330), 282-283.\n[10] Buntine, W. L. (1994). Operations for learning with graphical models. Journal of Artificial Intelligent Research, 2, 159-225.\n[11] Buszta, A., & Mazurkiewicz, J. (2015). Climate Changes Prediction System Based on Weather Big Data Visualisation. In Theory and Engineering of Complex Systems and Dependability (pp. 75-86). Springer International Publishing.\n[12] Chafi, H., Sujeeth, A. K., Brown, K. J., Lee, H., Atreya, A. R., & Olukotun, K. (2011). A Domain-Specific Approach to Heterogeneous Parallelism. ACM SIGPLAN Notices, 46(8), 35-46.\n[13] Chaiken, R., Jenkins, B., Larson, P. \u00c5., Ramsey, B., Shakib, D., Weaver, S., & Zhou, J. (2008). SCOPE: Easy and Efficient Parallel Processing of Massive Data Sets. Proceedings of the VLDB Endowment, 1(2), 1265-1276.\n[14] Chang, N. (2015). Marrying IoT and Big Data: Are You Ready?. Hitachi Review, 64(5), 255-258.\n[15] Chen, C. P., & Zhang, C. Y. (2014). Data-intensive applications, challenges, techniques and technologies: A survey on Big Data. Information Sciences, 275, 314-347.\n[16] Colombo, P., & Ferrari, E. (2015). Privacy aware access control for Big Data: a research roadmap. Big Data Research, 2(4), 145-154.\n[17] Czarnecki, K. (2005). Overview of generative software development. In Unconventional Programming Paradigms (pp. 326-341). Springer Berlin Heidelberg.\n[18] Dean, J., & Ghemawat, S. (2008). MapReduce: simplified data processing on large clusters. Communications of the ACM, 51(1), 107- 113.\n[19] Ding, W., Zheng, Y., Su, Y., Li, X., & Wei, X. (2015). Research and Development of a Kinect-based Virtual System for Upper Limb Rehabilitation. Journal of Biomedical Engineering, 32(3), 563-568.\n[20] Dogan, \u00dc., Edelbrunner, J., & Iossifidis, I. (2011). Autonomous driving: A comparison of machine learning techniques by means of the prediction of lane change behavior. In Robotics and Biomimetics (ROBIO), 2011 IEEE International Conference on (pp. 1837-1843). IEEE.\n[21] Doug, L. (2001). 3D Data Management: Controlling Data Volume, Velocity, and Variety. Application Delivery Strategies, META Group, (949).\n[22] Fan, S., Lau, R. Y., & Zhao, J. L. (2015). Demystifying Big Data Analytics for Business Intelligence Through the Lens of Marketing Mix. Big Data Research, 2(1), 28-32.\n[23] Fowler, M. (2010). Domain-specific languages. Pearson Education. [24] Freedman, D. A. (2009). Statistical models: theory and practice.\nCambridge University Press. [25] Haller, P., & Miller, H. (2011). Parallelizing Machine Learning-\nFunctionally: A Framework and Abstractions for Parallel Graph Processing. In 2nd Annual Scala Workshop (No. EPFL-CONF-165111).\n[26] He, Q., Li, N., Luo, W. J., & Shi, Z. Z. (2014). A Survey of Machine Learning Algorithms for Big Data. Pattern Recognition and Artificial Intelligence, 27(4), 327-336.\n[27] Heckerman, D. (1998). A tutorial on learning with Bayesian networks (pp. 301-354). Springer Netherlands.\n[28] Jain, A. K. (2010). Data clustering: 50 years beyond K-means. Pattern recognition letters, 31(8), 651-666.\n[29] Jin, X., Wah, B. W., Cheng, X., & Wang, Y. (2015). Significance and challenges of big data research. Big Data Research, 2(2), 59-64.\n[30] Joubert, G. R. (2015). Big Data: Insights and the Scientific Method. Advances in Parallel Computing, 25, 3-17.\n[31] Katehakis, M. N., & Veinott Jr, A. F. (1987). The multi-armed bandit problem: decomposition and computation. Mathematics of Operations Research, 12(2), 262-268.\n[32] Kr\u00f6del, M., & Kuhnert, K. D. (2001). Autonomous driving through intelligent image processing and machine learning. In Computational Intelligence. Theory and Applications (pp. 712-718). Springer Berlin Heidelberg.\n[33] Leung, C. K. S., & Jiang, F. (2015). Big Data Analytics of Social Networks for the Discovery of \u201cFollowing\u201d Patterns. In Big Data Analytics and Knowledge Discovery (pp. 123-135). Springer International Publishing.\n[34] Li, D. R., Cao, J. J., & Yao, Y. (2015). Big Data in Smart Cities. Science China Information Sciences, 58(10), 1-12.\n[35] Li, J., Xu, Z., Jiang, Y., & Zhang, R. (2014). The overview of big data storage and management. In 2014 IEEE 13th International Conference on Cognitive Informatics & Cognitive Computing (ICCI* CC) (pp. 510- 513). IEEE.\n[36] Li, X., & Wang, S. (2014). Big data and its challenges. WIT Transactions on Information and Communication Technologies, 46(1), 799-804.\n[37] Lim, D., Kim, C., Jung, H., Jung, D., & Chun, K. J. (2015). Use of the Microsoft Kinect system to characterize balance ability during balance training. Clinical interventions in aging, 10, 1077.\n[38] Lin, J., & Kolcz, A. (2012). Large-scale machine learning at twitter. In Proceedings of the 2012 ACM SIGMOD International Conference on Management of Data (pp. 793-804). ACM.\n[39] Liu, H., Qiao, M., Greenia, D., Akkiraju, R., Dill, S., Nakamura, T., Song, Y., & Nezhad, H. M. (2014). A Machine Learning Approach to Combining Individual Strength and Team Features for Team Recommendation. In Machine Learning and Applications (ICMLA), 2014 13th International Conference on (pp. 213-218). IEEE.\n[40] Liu, Y., Zhang, T., Jin, X., & Cheng, X. (2015). Personal Privacy Protection in the Era of Big Data. Computer Research and Development, 52(1), 229-247.\n[41] Low, Y., Gonzalez, J. E., Kyrola, A., Bickson, D., Guestrin, C. E., & Hellerstein, J. (2014). Graphlab: A New Framework For Parallel Machine Learning. arXiv:1408.2041.\n[42] Lu, Q., Li, Z., Zhang, W., & Yang, L. T. (2015). Autonomic deployment decision making for big data analytics applications in the cloud. Soft Computing, 1-12.\n[43] Lv, Y., Duan, Y., Kang, W., Li, Z., & Wang, F. Y. (2015). Traffic Flow Prediction With Big Data: A Deep Learning Approach. Intelligent Transportation Systems, IEEE Transactions on, 16(2), 865-873.\n[44] Microsoft. (2015). Kinect for Xbox One. Microsoft Xbox. Retrieved from http://www.xbox.com/kinect. Accessed on December 12th, 2015.\n[45] Microsft. (2015). Microsoft Xbox One. Microsoft Xbox. Retrieved from http://www.xbox.com/. Accessed on December 12th, 2015.\n[46] Minka, T., & Winn, J. (2008). Gates: A graphical notation for mixture models. In Neural Information Processing Systems (NIPS) (pp. 1073- 1080).\n[47] Minka, T., Winn, J., Guiver, J., Webster, S., Zaykov, Y., Yangel, B., Spengler, A., Bronskill, J. (2014). Infer.NET 2.6, Microsoft Research Cambridge, 2014.\n[48] Mitchell, T. M. (1997). Machine learning. 1997. Burr Ridge, IL: McGraw Hill, 45.\n[49] Odersky, M., Spoon, L., & Venners, B. (2005). Programming in Scala. \u00c9cole Polytechnique F\u00e9d\u00e9rale de Lausanne.\n[50] Omran, M. G. H., Engelbrecht, A. P., & Salman, A. (2007). An Overview of Clustering Methods. Intelligent Data Analysis, 11(6), 583- 605.\n[51] Olston, C., Reed, B., Srivastava, U., Kumar, R., & Tomkins, A. (2008). Pig Latin: A Not-So-Foreign Language for Data Processing. In Proceedings of the 2008 ACM SIGMOD International Conference on Management of Data (pp. 1099-1110). ACM.\n[52] Pike, R., Dorward, S., Griesemer, R., & Quinlan, S. (2005). Interpreting the data: Parallel analysis with Sawzall. Scientific Programming, 13(4), 277-298.\n[53] Preden, J., Pahtma, R., Tomson, T., & Motus, L. (2014). Solving Big Data: Distributing Computation Among Smart Devices. In Databases and Information Systems VIII: Selected Papers from the Eleventh International Baltic Conference, DB&IS 2014 (Vol. 270, p. 245). IOS Press.\n[54] Qi, Y., Shi, G., Yu, X., & Li, Y. (2015). Visualization in media big data analysis. In Computer and Information Science (ICIS), 2015 IEEE/ACIS 14th International Conference on (pp. 571-574). IEEE.\n[55] Qin, H. F., & Li, Z. H. (2013). Research on the Method of Big Data Analysis. Information Technology Journal, 12(10), 1974-1980.\n[56] Rajaraman, A., & Ullman, J. D. (2012). Mining of massive datasets (Vol. 77). Cambridge: Cambridge University Press.\n[57] Rezk, E., & Foufou, S. (2014). A survey of semantic web concepts applied in web services and big data. In Computer Systems and Applications (AICCSA), 2014 IEEE/ACS 11th International Conference on (pp. 767-772). IEEE.\n[58] Shen, H., Meng, J., Licheng, Y., Fang, X., Chen, T., Yan, H., & Hou, H. (2014). A quantitative quality control method of big data in cancer patients using artificial neural network. In Cloud Computing and Intelligence Systems (CCIS), 2014 IEEE 3rd International Conference on (pp. 499-504). IEEE.\n[59] Simovici, D. (2015). Intelligent Data Analysis Techniques\u2014Machine Learning and Data Mining. In Artificial Intelligent Approaches in Petroleum Geosciences (pp. 1-51). Springer International Publishing.\n[60] Sokolova, M., & Matwin, S. (2016). Personal Privacy Protection in Time of Big Data. In Challenges in Computational Statistics and Data Mining (pp. 365-380). Springer International Publishing.\n[61] Stringer, B., Dijkstra, M., Feenstra, A., Abeln, S., & Heringa, J. (2015). Explaining disease using big data: How valid is your pathway?. In High Performance Computing & Simulation (HPCS), 2015 International Conference on (pp. 662-664). IEEE.\n[62] Sujeeth, A., Lee, H., Brown, K., Rompf, T., Chafi, H., Wu, M., Atreya A. & Odersky, M., Olukotun, K. (2011). OptiML: an implicitly parallel domain-specific language for machine learning. In Proceedings of the 28th International Conference on Machine Learning (ICML-11) (pp. 609-616).\n[63] Sujeeth, A. K., Brown, K. J., Lee, H., Rompf, T., Chafi, H., Odersky, M., & Olukotun, K. (2014). Delite: A Compiler Architecture for Performance-Oriented Embedded Domain-Specific Languages. ACM Transactions on Embedded Computing Systems (TECS), 13(4s), 134.\n[64] Teng, P., Li, H., & Zhang, X. (2015). Survey on Visualization Layout for Big Data. In Intelligence Science and Big Data Engineering. Big Data and Machine Learning Techniques (pp. 384-394). Springer International Publishing.\n[65] \u0164upa, O., Proch\u00e1zka, A., Vy\u0161ata, O., Sch\u00e4tz, M., Mare\u0161, J., Vali\u0161, M., & Ma\u0159\u00edk, V. (2015). Motion tracking and gait feature estimation for recognising Parkinson\u2019s disease using MS Kinect. Biomedical engineering online, 14(1), 97.\n[66] Tsuji, K., Yoshikane, F., Sato, S., & Itsumura, H. (2014, August). Book Recommendation Using Machine Learning Methods Based on Library Loan Records and Bibliographic Information. In Advanced Applied Informatics (IIAIAAI), 2014 IIAI 3rd International Conference on (pp. 76-79). IEEE.\n[67] Van Deursen, A., Klint, P., & Visser, J. (2000). Domain-Specific Languages: An Annotated Bibliography. Sigplan Notices, 35(6), 26-36.\n[68] V\u00f6elter, M., Benz, S., Dietrich, C., Engelmann, B., Helander, M., Kats, L. C., Visser, E., & Wachsmuth, G. (2013). DSL Engineering: Designing, Implementing and Using Domain-Specific Languages. CreateSpace Independent Publishing Platform.\n[69] Wang, Y., & Wiebe, V. J. (2014). Big Data Analyses for Collective Opinion Elicitation in Social Networks. In Trust, Security and Privacy in Computing and Communications (TrustCom), 2014 IEEE 13th International Conference on (pp. 630-637). IEEE.\n[70] Watkins, C. J., & Dayan, P. (1992). Q-learning. Machine learning, 8(3- 4), 279-292.\n[71] Weimer, M., Condie, T., & Ramakrishnan, R. (2011). Machine learning in ScalOps, a higher order cloud computing language. In NIPS 2011 Workshop on Parallel and Large-scale Machine Learning (BigLearn) (Vol. 9, pp. 389-396).\n[72] Wu, X., Chen, H., Wu, G., Liu, J., Zheng, Q., He, X., Aoying, Z., Zhao, Z., Wei, B., Gao, M., Li, Y., Zhang, Q., Zhang, S., Lu, R., & Zheng, N. (2015). Knowledge Engineering with Big Data. Intelligent Systems, IEEE, 30(5), 46-55.\n[73] Xue, C. Y. (2014). Development Direction of Machine Learning in the Era of Big Data. In Advanced Materials Research (Vol. 971, pp. 1590- 1593).\n[74] Yang, H. W., Pan, Z. G., & Zhang, M. (2004). Machine learning-based intelligent recommendation in virtual mall. In Machine Learning and\nCybernetics, 2004. Proceedings of 2004 International Conference on (Vol. 4, pp. 2634-2639). IEEE.\n[75] Zhang, T., Zhang, J., Zhang, J., Pan, H., & Satianpakiranakorn, K. (2015). Visualization Analysis for 3D Big Data Modeling. In Intelligent Computation in Big Data Era (pp. 220-227). Springer Berlin Heidelberg.\n[76] Zou, J., Han, Y., & So, S. S. (2009). Overview of artificial neural networks. In Artificial Neural Networks (pp. 14-22). Humana Press."}], "references": [{"title": "Efficient Machine Learning for Big Data: A Review", "author": ["O.Y. Al-Jarrah", "P.D. Yoo", "S. Muhaidat", "G.K. Karagiannidis", "K. Taha"], "venue": "Big Data Research,", "citeRegEx": "2", "shortCiteRegEx": "2", "year": 2015}, {"title": "An overview of big data opportunities, applications and tools", "author": ["F.Z. Benjelloun", "A.A. Lahcen", "S. Belfkih"], "venue": "In Intelligent Systems and Computer Vision (ISCV),", "citeRegEx": "4", "shortCiteRegEx": "4", "year": 2015}, {"title": "Pattern recognition and machine", "author": ["C.M. Bishop"], "venue": null, "citeRegEx": "5", "shortCiteRegEx": "5", "year": 2006}, {"title": "Towards Model-Driven Engineering for Big Data Analytics--An Exploratory Analysis of Domain-Specific Languages for Machine Learning", "author": ["D. Breuker"], "venue": "In System Sciences (HICSS),", "citeRegEx": "6", "shortCiteRegEx": "6", "year": 2014}, {"title": "November). Domainspecific software engineering", "author": ["B.R. Bryant", "J. Gray", "M. Mernik"], "venue": "In Proceedings of the FSE/SDP workshop on Future of woftware engineering research (pp. 65-68)", "citeRegEx": "7", "shortCiteRegEx": "7", "year": 2010}, {"title": "Declarative Systems for Large-Scale Machine Learning", "author": ["V. Borkar", "Y. Bu", "M.J. Carey", "J. Rosen", "N. Polyzotis", "T. Condie", "M. Weimer", "R. Ramakrishnan"], "venue": "IEEE Bulletin of the Technical Committee on Data Engineering,", "citeRegEx": "8", "shortCiteRegEx": "8", "year": 2012}, {"title": "High-energy physics: Down the petabyte highway", "author": ["G. Brumfiel"], "venue": "Nature News,", "citeRegEx": "9", "shortCiteRegEx": "9", "year": 2011}, {"title": "Operations for learning with graphical models", "author": ["W.L. Buntine"], "venue": "Journal of Artificial Intelligent Research,", "citeRegEx": "10", "shortCiteRegEx": "10", "year": 1994}, {"title": "Climate Changes Prediction System Based on Weather Big Data Visualisation", "author": ["A. Buszta", "J. Mazurkiewicz"], "venue": "In Theory and Engineering of Complex Systems and Dependability (pp", "citeRegEx": "11", "shortCiteRegEx": "11", "year": 2015}, {"title": "A Domain-Specific Approach to Heterogeneous Parallelism", "author": ["H. Chafi", "A.K. Sujeeth", "K.J. Brown", "H. Lee", "A.R. Atreya", "K. Olukotun"], "venue": "ACM SIGPLAN Notices,", "citeRegEx": "12", "shortCiteRegEx": "12", "year": 2011}, {"title": "SCOPE: Easy and Efficient Parallel Processing of Massive Data Sets", "author": ["R. Chaiken", "B. Jenkins", "P.\u00c5. Larson", "B. Ramsey", "D. Shakib", "S. Weaver", "J. Zhou"], "venue": "Proceedings of the VLDB Endowment,", "citeRegEx": "13", "shortCiteRegEx": "13", "year": 2008}, {"title": "Marrying IoT and Big Data: Are You Ready", "author": ["N. Chang"], "venue": "Hitachi Review,", "citeRegEx": "14", "shortCiteRegEx": "14", "year": 2015}, {"title": "Data-intensive applications, challenges, techniques and technologies: A survey on Big Data", "author": ["C.P. Chen", "C.Y. Zhang"], "venue": "Information Sciences,", "citeRegEx": "15", "shortCiteRegEx": "15", "year": 2014}, {"title": "Privacy aware access control for Big Data: a research roadmap", "author": ["P. Colombo", "E. Ferrari"], "venue": "Big Data Research,", "citeRegEx": "16", "shortCiteRegEx": "16", "year": 2015}, {"title": "Overview of generative software development", "author": ["K. Czarnecki"], "venue": null, "citeRegEx": "17", "shortCiteRegEx": "17", "year": 2005}, {"title": "MapReduce: simplified data processing on large clusters", "author": ["J. Dean", "S. Ghemawat"], "venue": "Communications of the ACM,", "citeRegEx": "18", "shortCiteRegEx": "18", "year": 2008}, {"title": "Research and Development of a Kinect-based Virtual System for Upper Limb Rehabilitation", "author": ["W. Ding", "Y. Zheng", "Y. Su", "X. Li", "X. Wei"], "venue": "Journal of Biomedical Engineering,", "citeRegEx": "19", "shortCiteRegEx": "19", "year": 2015}, {"title": "Autonomous driving: A comparison of machine learning techniques by means of the prediction of lane change behavior", "author": ["\u00dc. Dogan", "J. Edelbrunner", "I. Iossifidis"], "venue": "In Robotics and Biomimetics (ROBIO),", "citeRegEx": "20", "shortCiteRegEx": "20", "year": 2011}, {"title": "3D Data Management: Controlling Data Volume, Velocity, and Variety", "author": ["L. Doug"], "venue": "Application Delivery Strategies,", "citeRegEx": "21", "shortCiteRegEx": "21", "year": 2001}, {"title": "Demystifying Big Data Analytics for Business Intelligence Through the Lens of Marketing Mix", "author": ["S. Fan", "R.Y. Lau", "J.L. Zhao"], "venue": "Big Data Research,", "citeRegEx": "22", "shortCiteRegEx": "22", "year": 2015}, {"title": "Domain-specific languages. Pearson Education", "author": ["M. Fowler"], "venue": null, "citeRegEx": "23", "shortCiteRegEx": "23", "year": 2010}, {"title": "Statistical models: theory and practice", "author": ["D.A. Freedman"], "venue": null, "citeRegEx": "24", "shortCiteRegEx": "24", "year": 2009}, {"title": "Parallelizing Machine Learning- Functionally: A Framework and Abstractions for Parallel Graph Processing", "author": ["P. Haller", "H. Miller"], "venue": "In 2nd Annual Scala Workshop (No. EPFL-CONF-165111)", "citeRegEx": "25", "shortCiteRegEx": "25", "year": 2011}, {"title": "A Survey of Machine Learning Algorithms for Big Data", "author": ["Q. He", "N. Li", "W.J. Luo", "Z.Z. Shi"], "venue": "Pattern Recognition and Artificial Intelligence,", "citeRegEx": "26", "shortCiteRegEx": "26", "year": 2014}, {"title": "A tutorial on learning with Bayesian networks (pp. 301-354)", "author": ["D. Heckerman"], "venue": null, "citeRegEx": "27", "shortCiteRegEx": "27", "year": 1998}, {"title": "Data clustering: 50 years beyond K-means", "author": ["A.K. Jain"], "venue": "Pattern recognition letters,", "citeRegEx": "28", "shortCiteRegEx": "28", "year": 2010}, {"title": "Significance and challenges of big data research", "author": ["X. Jin", "B.W. Wah", "X. Cheng", "Y. Wang"], "venue": "Big Data Research,", "citeRegEx": "29", "shortCiteRegEx": "29", "year": 2015}, {"title": "Big Data: Insights and the Scientific Method", "author": ["G.R. Joubert"], "venue": "Advances in Parallel Computing,", "citeRegEx": "30", "shortCiteRegEx": "30", "year": 2015}, {"title": "The multi-armed bandit problem: decomposition and computation", "author": ["M.N. Katehakis", "A.F. Veinott Jr."], "venue": "Mathematics of Operations Research,", "citeRegEx": "31", "shortCiteRegEx": "31", "year": 1987}, {"title": "Autonomous driving through intelligent image processing and machine learning", "author": ["M. Kr\u00f6del", "K.D. Kuhnert"], "venue": "In Computational Intelligence. Theory and Applications (pp", "citeRegEx": "32", "shortCiteRegEx": "32", "year": 2001}, {"title": "Big Data Analytics of Social Networks for the Discovery of \u201cFollowing", "author": ["C.K.S. Leung", "F. Jiang"], "venue": null, "citeRegEx": "33", "shortCiteRegEx": "33", "year": 2015}, {"title": "Big Data in Smart Cities", "author": ["D.R. Li", "J.J. Cao", "Y. Yao"], "venue": "Science China Information Sciences,", "citeRegEx": "34", "shortCiteRegEx": "34", "year": 2015}, {"title": "The overview of big data storage and management", "author": ["J. Li", "Z. Xu", "Y. Jiang", "R. Zhang"], "venue": "In 2014 IEEE 13th International Conference on Cognitive Informatics & Cognitive Computing (ICCI* CC) (pp", "citeRegEx": "35", "shortCiteRegEx": "35", "year": 2014}, {"title": "Big data and its challenges", "author": ["X. Li", "S. Wang"], "venue": "WIT Transactions on Information and Communication Technologies,", "citeRegEx": "36", "shortCiteRegEx": "36", "year": 2014}, {"title": "Use of the Microsoft Kinect system to characterize balance ability during balance training", "author": ["D. Lim", "C. Kim", "H. Jung", "D. Jung", "K.J. Chun"], "venue": "Clinical interventions in aging,", "citeRegEx": "37", "shortCiteRegEx": "37", "year": 2015}, {"title": "Large-scale machine learning at twitter", "author": ["J. Lin", "A. Kolcz"], "venue": "In Proceedings of the 2012 ACM SIGMOD International Conference on Management of Data (pp. 793-804)", "citeRegEx": "38", "shortCiteRegEx": "38", "year": 2012}, {"title": "A Machine Learning Approach to Combining Individual Strength and Team Features for Team Recommendation", "author": ["H. Liu", "M. Qiao", "D. Greenia", "R. Akkiraju", "S. Dill", "T. Nakamura", "Y. Song", "H.M. Nezhad"], "venue": "In Machine Learning and Applications (ICMLA), 2014 13th International Conference on (pp. 213-218)", "citeRegEx": "39", "shortCiteRegEx": "39", "year": 2014}, {"title": "Personal Privacy Protection in the Era of Big Data", "author": ["Y. Liu", "T. Zhang", "X. Jin", "X. Cheng"], "venue": "Computer Research and Development,", "citeRegEx": "40", "shortCiteRegEx": "40", "year": 2015}, {"title": "Graphlab: A New Framework For Parallel Machine Learning. arXiv:1408.2041", "author": ["Y. Low", "J.E. Gonzalez", "A. Kyrola", "D. Bickson", "C.E. Guestrin", "J. Hellerstein"], "venue": null, "citeRegEx": "41", "shortCiteRegEx": "41", "year": 2014}, {"title": "Autonomic deployment decision making for big data analytics applications in the cloud", "author": ["Q. Lu", "Z. Li", "W. Zhang", "L.T. Yang"], "venue": "Soft Computing,", "citeRegEx": "42", "shortCiteRegEx": "42", "year": 2015}, {"title": "Traffic Flow Prediction With Big Data: A Deep Learning Approach", "author": ["Y. Lv", "Y. Duan", "W. Kang", "Z. Li", "F.Y. Wang"], "venue": "Intelligent Transportation Systems, IEEE Transactions on,", "citeRegEx": "43", "shortCiteRegEx": "43", "year": 2015}, {"title": "Gates: A graphical notation for mixture models", "author": ["T. Minka", "J. Winn"], "venue": "In Neural Information Processing Systems (NIPS) (pp", "citeRegEx": "46", "shortCiteRegEx": "46", "year": 2008}, {"title": "Pig Latin: A Not-So-Foreign Language for Data Processing", "author": ["C. Olston", "B. Reed", "U. Srivastava", "R. Kumar", "A. Tomkins"], "venue": "In Proceedings of the 2008 ACM SIGMOD International Conference on Management of Data (pp. 1099-1110)", "citeRegEx": "51", "shortCiteRegEx": "51", "year": 2008}, {"title": "Interpreting the data: Parallel analysis with Sawzall", "author": ["R. Pike", "S. Dorward", "R. Griesemer", "S. Quinlan"], "venue": "Scientific Programming,", "citeRegEx": "52", "shortCiteRegEx": "52", "year": 2005}, {"title": "Solving Big Data: Distributing Computation Among Smart Devices", "author": ["J. Preden", "R. Pahtma", "T. Tomson", "L. Motus"], "venue": "In Databases and Information Systems VIII: Selected Papers from the Eleventh International Baltic Conference,", "citeRegEx": "53", "shortCiteRegEx": "53", "year": 2014}, {"title": "Visualization in media big data analysis", "author": ["Y. Qi", "G. Shi", "X. Yu", "Y. Li"], "venue": "In Computer and Information Science (ICIS),", "citeRegEx": "54", "shortCiteRegEx": "54", "year": 2015}, {"title": "Mining of massive datasets (Vol. 77)", "author": ["A. Rajaraman", "J.D. Ullman"], "venue": null, "citeRegEx": "56", "shortCiteRegEx": "56", "year": 2012}, {"title": "A survey of semantic web concepts applied in web services and big data", "author": ["E. Rezk", "S. Foufou"], "venue": "In Computer Systems and Applications (AICCSA),", "citeRegEx": "57", "shortCiteRegEx": "57", "year": 2014}, {"title": "A quantitative quality control method of big data in cancer patients using artificial neural network", "author": ["H. Shen", "J. Meng", "Y. Licheng", "X. Fang", "T. Chen", "H. Yan", "H. Hou"], "venue": "In Cloud Computing and Intelligence Systems (CCIS),", "citeRegEx": "58", "shortCiteRegEx": "58", "year": 2014}, {"title": "Intelligent Data Analysis Techniques\u2014Machine Learning and Data Mining. In Artificial Intelligent Approaches in Petroleum Geosciences (pp. 1-51)", "author": ["D. Simovici"], "venue": null, "citeRegEx": "59", "shortCiteRegEx": "59", "year": 2015}, {"title": "Personal Privacy Protection in Time of Big Data. In Challenges in Computational Statistics and Data Mining (pp. 365-380)", "author": ["M. Sokolova", "S. Matwin"], "venue": null, "citeRegEx": "60", "shortCiteRegEx": "60", "year": 2016}, {"title": "Explaining disease using big data: How valid is your pathway", "author": ["B. Stringer", "M. Dijkstra", "A. Feenstra", "S. Abeln", "J. Heringa"], "venue": "In High Performance Computing & Simulation (HPCS), 2015 International Conference on (pp. 662-664)", "citeRegEx": "61", "shortCiteRegEx": "61", "year": 2015}, {"title": "OptiML: an implicitly parallel domain-specific language for machine learning", "author": ["A. Sujeeth", "H. Lee", "K. Brown", "T. Rompf", "H. Chafi", "M. Wu", "Atreya A", "M. Odersky", "K. Olukotun"], "venue": "In Proceedings of the 28th International Conference on Machine Learning", "citeRegEx": "62", "shortCiteRegEx": "62", "year": 2011}, {"title": "Delite: A Compiler Architecture for Performance-Oriented Embedded Domain-Specific Languages", "author": ["A.K. Sujeeth", "K.J. Brown", "H. Lee", "T. Rompf", "H. Chafi", "M. Odersky", "K. Olukotun"], "venue": "ACM Transactions on Embedded Computing Systems (TECS),", "citeRegEx": "63", "shortCiteRegEx": "63", "year": 2014}, {"title": "Survey on Visualization Layout for Big Data. In Intelligence Science and Big Data Engineering. Big Data and Machine Learning Techniques (pp. 384-394)", "author": ["P. Teng", "H. Li", "X. Zhang"], "venue": null, "citeRegEx": "64", "shortCiteRegEx": "64", "year": 2015}, {"title": "Motion tracking and gait feature estimation for recognising Parkinson\u2019s disease using MS Kinect", "author": ["O. \u0164upa", "A. Proch\u00e1zka", "O. Vy\u0161ata", "M. Sch\u00e4tz", "J. Mare\u0161", "M. Vali\u0161", "V. Ma\u0159\u00edk"], "venue": "Biomedical engineering online,", "citeRegEx": "65", "shortCiteRegEx": "65", "year": 2015}, {"title": "Book Recommendation Using Machine Learning Methods Based on Library Loan Records and Bibliographic Information", "author": ["K. Tsuji", "F. Yoshikane", "S. Sato", "Itsumura", "August"], "venue": "In Advanced Applied Informatics (IIAIAAI),", "citeRegEx": "66", "shortCiteRegEx": "66", "year": 2014}, {"title": "Domain-Specific Languages: An Annotated Bibliography", "author": ["A. Van Deursen", "P. Klint", "J. Visser"], "venue": "Sigplan Notices,", "citeRegEx": "67", "shortCiteRegEx": "67", "year": 2000}, {"title": "DSL Engineering: Designing, Implementing and Using Domain-Specific Languages. CreateSpace Independent Publishing Platform", "author": ["M. V\u00f6elter", "S. Benz", "C. Dietrich", "B. Engelmann", "M. Helander", "L.C. Kats", "E. Visser", "G. Wachsmuth"], "venue": null, "citeRegEx": "68", "shortCiteRegEx": "68", "year": 2013}, {"title": "Big Data Analyses for Collective Opinion Elicitation in Social Networks", "author": ["Y. Wang", "V.J. Wiebe"], "venue": "In Trust, Security and Privacy in Computing and Communications (TrustCom),", "citeRegEx": "69", "shortCiteRegEx": "69", "year": 2014}, {"title": "Machine learning in ScalOps, a higher order cloud computing language", "author": ["M. Weimer", "T. Condie", "R. Ramakrishnan"], "venue": "In NIPS 2011 Workshop on Parallel and Large-scale Machine Learning (BigLearn) (Vol", "citeRegEx": "71", "shortCiteRegEx": "71", "year": 2011}, {"title": "Knowledge Engineering with Big Data", "author": ["X. Wu", "H. Chen", "G. Wu", "J. Liu", "Q. Zheng", "X. He", "Z. Aoying", "Z. Zhao", "B. Wei", "M. Gao", "Y. Li", "Q. Zhang", "S. Zhang", "R. Lu", "N. Zheng"], "venue": "Intelligent Systems,", "citeRegEx": "72", "shortCiteRegEx": "72", "year": 2015}, {"title": "Development Direction of Machine Learning in the Era of Big Data", "author": ["C.Y. Xue"], "venue": "In Advanced Materials Research (Vol", "citeRegEx": "73", "shortCiteRegEx": "73", "year": 2014}, {"title": "Machine learning-based intelligent recommendation in virtual mall", "author": ["H.W. Yang", "Z.G. Pan", "M. Zhang"], "venue": "In Machine Learning and  Cybernetics,", "citeRegEx": "74", "shortCiteRegEx": "74", "year": 2004}, {"title": "Visualization Analysis for 3D Big Data Modeling. In Intelligent Computation in Big Data Era (pp. 220-227)", "author": ["T. Zhang", "J. Zhang", "H. Pan", "K. Satianpakiranakorn"], "venue": null, "citeRegEx": "75", "shortCiteRegEx": "75", "year": 2015}, {"title": "Overview of artificial neural networks", "author": ["J. Zou", "Y. Han", "S.S. So"], "venue": "In Artificial Neural Networks (pp. 14-22). Humana Press.  TABLE I. DSLS FOR MACHINE LEARNING IN BIG DATA Language", "citeRegEx": "76", "shortCiteRegEx": "76", "year": 2009}], "referenceMentions": [{"referenceID": 61, "context": "The evolution of technology in the last decades caused a major data revolution [72].", "startOffset": 79, "endOffset": 83}, {"referenceID": 1, "context": "This recent phenomenon of the generation of a high volume of digital data that is available to be processed is called Big Data [4].", "startOffset": 127, "endOffset": 130}, {"referenceID": 18, "context": "These three V\u2019s of Big Data were introduced by Doug Laney [21] and are generally used to define Big Data and its characteristics.", "startOffset": 58, "endOffset": 62}, {"referenceID": 33, "context": "Traditional ways of data storage and analysis do not scale well to this amount of data, which can reach hundreds of terabytes or more, and new approaches are being developed to address these issues [36].", "startOffset": 198, "endOffset": 202}, {"referenceID": 49, "context": "Machine Learning is one technique of processing data and making inferences about it [59].", "startOffset": 84, "endOffset": 88}, {"referenceID": 46, "context": "Because Machine Learning techniques make better inferences and predictions when more relevant data is available, applying these techniques to Big Data field is of major interest [56].", "startOffset": 178, "endOffset": 182}, {"referenceID": 35, "context": "However, applications of Machine Learning in Big Data have to overcome several Big Data challenges [38].", "startOffset": 99, "endOffset": 103}, {"referenceID": 0, "context": "Data storage and processing should be carefully considered, and algorithms may be described in a parallel way [2].", "startOffset": 110, "endOffset": 113}, {"referenceID": 20, "context": "Domainspecific Languages are languages whose instructions are easy and intuitive for a specific domain [23].", "startOffset": 103, "endOffset": 107}, {"referenceID": 1, "context": "The Big Data research field emerged from the evolution of technology [4].", "startOffset": 69, "endOffset": 72}, {"referenceID": 44, "context": "In the past, the number of digital devices was not significant, when compared to the quantity of smartphones or tablets (and other so called smart devices) that exist in today\u2019s world [53].", "startOffset": 184, "endOffset": 188}, {"referenceID": 27, "context": "Web services and scientific computation produced less data and were slower [30][57] decades ago.", "startOffset": 75, "endOffset": 79}, {"referenceID": 47, "context": "Web services and scientific computation produced less data and were slower [30][57] decades ago.", "startOffset": 79, "endOffset": 83}, {"referenceID": 18, "context": "In an effort to characterize Big Data, Doug Laney introduced a 3V model [21]:", "startOffset": 72, "endOffset": 76}, {"referenceID": 12, "context": "As examples, Walmart, the chain of hypermarkets and grocery stores, registers 267 million transactions each day [15] across its 6000 stores worldwide.", "startOffset": 112, "endOffset": 116}, {"referenceID": 6, "context": "Additionaly, the Large Hadron Collider (LHC), the particle collider built on the border between France and Switzerland to study and test several theories of particle physics, generates 60 terabytes of data each day [9], that needs to be processed for scientific purposes.", "startOffset": 215, "endOffset": 218}, {"referenceID": 8, "context": "Some examples of works being developed in Big Data research field focus on making better weather prediction [11], helping in traffic management [43], creating smart cities [34], helping in analysis of diseases [58][61] and social networks [33][69], and helping decision making in business intelligence [22][42].", "startOffset": 108, "endOffset": 112}, {"referenceID": 40, "context": "Some examples of works being developed in Big Data research field focus on making better weather prediction [11], helping in traffic management [43], creating smart cities [34], helping in analysis of diseases [58][61] and social networks [33][69], and helping decision making in business intelligence [22][42].", "startOffset": 144, "endOffset": 148}, {"referenceID": 31, "context": "Some examples of works being developed in Big Data research field focus on making better weather prediction [11], helping in traffic management [43], creating smart cities [34], helping in analysis of diseases [58][61] and social networks [33][69], and helping decision making in business intelligence [22][42].", "startOffset": 172, "endOffset": 176}, {"referenceID": 48, "context": "Some examples of works being developed in Big Data research field focus on making better weather prediction [11], helping in traffic management [43], creating smart cities [34], helping in analysis of diseases [58][61] and social networks [33][69], and helping decision making in business intelligence [22][42].", "startOffset": 210, "endOffset": 214}, {"referenceID": 51, "context": "Some examples of works being developed in Big Data research field focus on making better weather prediction [11], helping in traffic management [43], creating smart cities [34], helping in analysis of diseases [58][61] and social networks [33][69], and helping decision making in business intelligence [22][42].", "startOffset": 214, "endOffset": 218}, {"referenceID": 30, "context": "Some examples of works being developed in Big Data research field focus on making better weather prediction [11], helping in traffic management [43], creating smart cities [34], helping in analysis of diseases [58][61] and social networks [33][69], and helping decision making in business intelligence [22][42].", "startOffset": 239, "endOffset": 243}, {"referenceID": 59, "context": "Some examples of works being developed in Big Data research field focus on making better weather prediction [11], helping in traffic management [43], creating smart cities [34], helping in analysis of diseases [58][61] and social networks [33][69], and helping decision making in business intelligence [22][42].", "startOffset": 243, "endOffset": 247}, {"referenceID": 19, "context": "Some examples of works being developed in Big Data research field focus on making better weather prediction [11], helping in traffic management [43], creating smart cities [34], helping in analysis of diseases [58][61] and social networks [33][69], and helping decision making in business intelligence [22][42].", "startOffset": 302, "endOffset": 306}, {"referenceID": 39, "context": "Some examples of works being developed in Big Data research field focus on making better weather prediction [11], helping in traffic management [43], creating smart cities [34], helping in analysis of diseases [58][61] and social networks [33][69], and helping decision making in business intelligence [22][42].", "startOffset": 306, "endOffset": 310}, {"referenceID": 12, "context": "To handle the massive amount of data efficiently, the Big Data research field has several challenges, which relates to data capture, storage, analysis, and visualization [15][29].", "startOffset": 170, "endOffset": 174}, {"referenceID": 26, "context": "To handle the massive amount of data efficiently, the Big Data research field has several challenges, which relates to data capture, storage, analysis, and visualization [15][29].", "startOffset": 174, "endOffset": 178}, {"referenceID": 45, "context": "Research on these visualization challenges can be found on [54][64][75].", "startOffset": 59, "endOffset": 63}, {"referenceID": 54, "context": "Research on these visualization challenges can be found on [54][64][75].", "startOffset": 63, "endOffset": 67}, {"referenceID": 64, "context": "Research on these visualization challenges can be found on [54][64][75].", "startOffset": 67, "endOffset": 71}, {"referenceID": 13, "context": "For that reason, several studies analyze the privacy implications [16][40][60] of these approaches, and ethical questions about data ownership.", "startOffset": 66, "endOffset": 70}, {"referenceID": 37, "context": "For that reason, several studies analyze the privacy implications [16][40][60] of these approaches, and ethical questions about data ownership.", "startOffset": 70, "endOffset": 74}, {"referenceID": 50, "context": "For that reason, several studies analyze the privacy implications [16][40][60] of these approaches, and ethical questions about data ownership.", "startOffset": 74, "endOffset": 78}, {"referenceID": 11, "context": "Another future direction [14] shows that Big Data will become even more important with the development of the", "startOffset": 25, "endOffset": 29}, {"referenceID": 55, "context": "The main applications of this technology is in the video game industry, but other research studies use it, for instance, to detect Parkinson\u2019s disease [65], improve limb rehabilitation [19], or study balance and risk of falling in older adults [37].", "startOffset": 151, "endOffset": 155}, {"referenceID": 16, "context": "The main applications of this technology is in the video game industry, but other research studies use it, for instance, to detect Parkinson\u2019s disease [65], improve limb rehabilitation [19], or study balance and risk of falling in older adults [37].", "startOffset": 185, "endOffset": 189}, {"referenceID": 34, "context": "The main applications of this technology is in the video game industry, but other research studies use it, for instance, to detect Parkinson\u2019s disease [65], improve limb rehabilitation [19], or study balance and risk of falling in older adults [37].", "startOffset": 244, "endOffset": 248}, {"referenceID": 17, "context": "Autonomous driving [20][32] is another application of machine learning techniques that has been under investigation and is generating interesting results.", "startOffset": 19, "endOffset": 23}, {"referenceID": 29, "context": "Autonomous driving [20][32] is another application of machine learning techniques that has been under investigation and is generating interesting results.", "startOffset": 23, "endOffset": 27}, {"referenceID": 36, "context": "Several studies in the literature [39][66][74] describe approaches in this direction.", "startOffset": 34, "endOffset": 38}, {"referenceID": 56, "context": "Several studies in the literature [39][66][74] describe approaches in this direction.", "startOffset": 38, "endOffset": 42}, {"referenceID": 63, "context": "Several studies in the literature [39][66][74] describe approaches in this direction.", "startOffset": 42, "endOffset": 46}, {"referenceID": 46, "context": "Machine Learning algorithms are classified in supervised, unsupervised, and reinforcement learning [56].", "startOffset": 99, "endOffset": 103}, {"referenceID": 21, "context": "Some examples of algorithms are Logistic Regression [24] and Neural Networks [76].", "startOffset": 52, "endOffset": 56}, {"referenceID": 65, "context": "Some examples of algorithms are Logistic Regression [24] and Neural Networks [76].", "startOffset": 77, "endOffset": 81}, {"referenceID": 25, "context": "Some algorithms that can be used in unsupervised learning are Clustering [50] and k-means [28].", "startOffset": 90, "endOffset": 94}, {"referenceID": 28, "context": "Some examples of reinforcement learning algorithms are Bandits [31] and Qlearning [70].", "startOffset": 63, "endOffset": 67}, {"referenceID": 62, "context": "Applying Machine Learning in the Big Data field is desired and beneficial [73].", "startOffset": 74, "endOffset": 78}, {"referenceID": 0, "context": "Moreover, processing that data may not be efficient, and algorithms have to be adapted and optimized to specific cases [2][26].", "startOffset": 119, "endOffset": 122}, {"referenceID": 23, "context": "Moreover, processing that data may not be efficient, and algorithms have to be adapted and optimized to specific cases [2][26].", "startOffset": 122, "endOffset": 126}, {"referenceID": 20, "context": "Their expressiveness is focused into a specific class of applications [23].", "startOffset": 70, "endOffset": 74}, {"referenceID": 14, "context": "Domain-specific languages have several advantages over general-purpose languages [17].", "startOffset": 81, "endOffset": 85}, {"referenceID": 20, "context": "The features described in three different publications [23][67][68] compose the classification scheme that is used in this survey.", "startOffset": 55, "endOffset": 59}, {"referenceID": 57, "context": "The features described in three different publications [23][67][68] compose the classification scheme that is used in this survey.", "startOffset": 59, "endOffset": 63}, {"referenceID": 58, "context": "The features described in three different publications [23][67][68] compose the classification scheme that is used in this survey.", "startOffset": 63, "endOffset": 67}, {"referenceID": 9, "context": "OptiML [12][25][62] is a DSL designed as a research project from Stanford University\u2019s Pervasive Parallelism Laboratory with the goal of enabling Machine Learning algorithms to take advantage of parallelism.", "startOffset": 7, "endOffset": 11}, {"referenceID": 22, "context": "OptiML [12][25][62] is a DSL designed as a research project from Stanford University\u2019s Pervasive Parallelism Laboratory with the goal of enabling Machine Learning algorithms to take advantage of parallelism.", "startOffset": 11, "endOffset": 15}, {"referenceID": 52, "context": "OptiML [12][25][62] is a DSL designed as a research project from Stanford University\u2019s Pervasive Parallelism Laboratory with the goal of enabling Machine Learning algorithms to take advantage of parallelism.", "startOffset": 15, "endOffset": 19}, {"referenceID": 53, "context": "OptiML runs on top of Delite [63], a compiler framework developed by the same research team, and supports operations with the basic three types: vector, matrix, and graph.", "startOffset": 29, "endOffset": 33}, {"referenceID": 15, "context": "Its operations supports parallel executions (using the MapReduce programming model [18]) in heterogeneous machines, which are machines that have more than one type of processor or core.", "startOffset": 83, "endOffset": 87}, {"referenceID": 5, "context": "ScalOps [8][71] is a DSL with the goal of enabling Machine Learning algorithms to run on a cloud computing environment and overcoming a limitation of the traditional MapReduce programming model: the lack of iteration.", "startOffset": 8, "endOffset": 11}, {"referenceID": 60, "context": "ScalOps [8][71] is a DSL with the goal of enabling Machine Learning algorithms to run on a cloud computing environment and overcoming a limitation of the traditional MapReduce programming model: the lack of iteration.", "startOffset": 11, "endOffset": 15}, {"referenceID": 5, "context": "To support iterations in MapReduce, ScalOps designers introduced an enhanced version of the programming model called Map-Reduce-Update [8].", "startOffset": 135, "endOffset": 138}, {"referenceID": 42, "context": "Pig Latin [51] was also developed by Yahoo! Research.", "startOffset": 10, "endOffset": 14}, {"referenceID": 10, "context": "SCOPE [13] is a DSL developed by Microsoft to account for the distributed and cloud computing challenges in querying and managing data.", "startOffset": 6, "endOffset": 10}, {"referenceID": 10, "context": "Data is stored in Cosmos Storage System [13], also developed by Microsoft.", "startOffset": 40, "endOffset": 44}, {"referenceID": 43, "context": "Sawzall [52] is a DSL developed by engineers at Google.", "startOffset": 8, "endOffset": 12}, {"referenceID": 3, "context": "The next language in the list did not have a name associated with it, and it was decided to refer to it as VisuML [6].", "startOffset": 114, "endOffset": 117}, {"referenceID": 24, "context": "The language is based on abstractions of other modeling languages and some language constructs, namely graphical models [27], factor graphs [5], plates[10], and gates [46].", "startOffset": 120, "endOffset": 124}, {"referenceID": 2, "context": "The language is based on abstractions of other modeling languages and some language constructs, namely graphical models [27], factor graphs [5], plates[10], and gates [46].", "startOffset": 140, "endOffset": 143}, {"referenceID": 7, "context": "The language is based on abstractions of other modeling languages and some language constructs, namely graphical models [27], factor graphs [5], plates[10], and gates [46].", "startOffset": 151, "endOffset": 155}, {"referenceID": 41, "context": "The language is based on abstractions of other modeling languages and some language constructs, namely graphical models [27], factor graphs [5], plates[10], and gates [46].", "startOffset": 167, "endOffset": 171}, {"referenceID": 24, "context": "Graphical models [27] are a language to describe probabilistic models visually.", "startOffset": 17, "endOffset": 21}, {"referenceID": 38, "context": "Graphlab [41] is a framework for the implementation of Machine Learning algorithms, developed jointly by researchers in Carnegie Mellon University and the University of California Berkeley.", "startOffset": 9, "endOffset": 13}], "year": 2016, "abstractText": "The amount of data generated in the modern society is increasing rapidly. New problems and novel approaches of data capture, storage, analysis and visualization are responsible for the emergence of the Big Data research field. Machine Learning algorithms can be used in Big Data to make better and more accurate inferences. However, because of the challenges Big Data imposes, these algorithms need to be adapted and optimized to specific applications. One important decision made by software engineers is the choice of the language that is used in the implementation of these algorithms. Therefore, this literature survey identifies and describes domain-specific languages and frameworks used for Machine Learning in Big Data. By doing this, software engineers can then make more informed choices and beginners have an overview of the main languages used in this domain. Keywords\u2014literature survey; domain-specific languages; DSL; Machine Learning; ML; Big Data; BD", "creator": "Word"}}}