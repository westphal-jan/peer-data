{"id": "1603.09473", "review": {"conference": "arxiv", "VERSION": "v1", "DATE_OF_SUBMISSION": "31-Mar-2016", "title": "Learning Compatibility Across Categories for Heterogeneous Item Recommendation", "abstract": "identifying relationships between items positively is a key finding task of an online recommender accreditation system, in order to help users discover items that are functionally complementary or visually compatible. in domains like clothing recommendation, establishing this task is particularly fairly challenging since ultimately a less successful system assessment should be capable when of handling a large potential corpus diversity of items, while a huge quantitative amount required of identifiable relationships among providing them, as well both as the underlying high - dimensional and mutually semantically reasonably complicated pattern features involved. furthermore, noticing the intrinsic human notion of \" for compatibility \" item that we know need quickly to capture goes beyond limiting mere similarity : so for even two digital items to be compatible - - - discover whether jeans and a t - shirt, panties or one a laptop belt and a charger - - - think they should be typically similar in some remarkable ways, but look systematically different appear in four others.", "histories": [["v1", "Thu, 31 Mar 2016 07:22:30 GMT  (4709kb,D)", "https://arxiv.org/abs/1603.09473v1", "10 pages, 5 figures"], ["v2", "Mon, 26 Sep 2016 07:25:36 GMT  (4734kb,D)", "http://arxiv.org/abs/1603.09473v2", "11 pages, 5 figures"], ["v3", "Thu, 29 Sep 2016 00:43:21 GMT  (4734kb,D)", "http://arxiv.org/abs/1603.09473v3", "11 pages, 5 figures"]], "COMMENTS": "10 pages, 5 figures", "reviews": [], "SUBJECTS": "cs.IR cs.CV cs.LG", "authors": ["ruining he", "charles packer", "julian mcauley"], "accepted": false, "id": "1603.09473"}, "pdf": {"name": "1603.09473.pdf", "metadata": {"source": "CRF", "title": "Learning Compatibility Across Categories for Heterogeneous Item Recommendation", "authors": ["Ruining He", "Charles Packer", "Julian McAuley"], "emails": ["jmcauley}@cs.ucsd.edu"], "sections": [{"heading": null, "text": "In this paper we propose a novel method, Monomer, to learn complicated and heterogeneous relationships between items in product recommendation settings. Recently, scalable methods have been developed that address this task by learning similarity metrics on top of the content of the products involved. Here our method relaxes the metricity assumption inherent in previous work and models multiple localized notions of \u2018relatedness,\u2019 so as to uncover ways in which related items should be systematically similar, and systematically different. Quantitatively, we show that our system achieves state-ofthe-art performance on large-scale compatibility prediction tasks, especially in cases where there is substantial heterogeneity between related items. Qualitatively, we demonstrate that richer notions of compatibility can be learned that go beyond similarity, and that our model can make effective recommendations of heterogeneous content.\nKeywords-Recommender Systems; Visual Compatibility; Metric Learning\nI. INTRODUCTION\nIdentifying and understanding relationships between items is a key component of any modern recommender system. Knowing which items are \u2018similar,\u2019 or which otherwise may be substitutable or complementary, is key to building systems that can understand a user\u2019s context, recommend alternative items from the same style [11], or generate bundles of items that are compatible [18, 22, 34].\nTypically, identifying these relationships means defining (or otherwise learning from training data) an appropriate distance or similarity measure between items. This is appropriate when the goal is to learn some notion of \u2018equivalence\u2019 between items, e.g. in order to recommend an item that may be a natural alternative to the one currently being considered. However, identifying such a similarity measure may be insufficient when there is substantial heterogeneity between the items being considered. For example, the characteristics\nthat make clothing items, electronic components, or even romantic partners compatible exhibit substantial heterogeneity: for a pair of such items to be compatible they should be systematically similar in some ways, but systematically different in others.\nRecently, a line of work has aimed to model such heterogeneous relationships, e.g. to model co-purchasing behavior between products based on their visual appearance or textual descriptions [21, 22, 31]. In spite of the substantial heterogeneity in the data used for training (a large dataset of co-purchase \u2018dyads\u2019 from Amazon) and the complexity of the models used, these works ultimately follow an established metric-learning paradigm: (1) Collect a large dataset of related (and unrelated) items; (2) Propose a parameterized similarity function; and (3) Train the parameterized function such that related items are more similar than non-related items. Such metric-learning approaches can be incredibly flexible and powerful, and have been used to identify similarities between items ranging from music [27] to members of the same tribe [7]. Such methods work to some extent even in the presence of heterogeneity, since they learn to \u2018ignore\u2019 dimensions where similarity should not be preserved. But we argue that ignoring such dimensions discards valuable information that ought to be used for prediction and recommendation.\nIn this paper, we propose new models and algorithms to identify relationships between items in product recommendation settings. In particular, we relax the metricity assumption present in recent work, by proposing more flexible notions of \u2018relatedness\u2019 while maintaining the same levels of speed and scalability. Specifically, we hope to overcome the following limitations of previous work: \u2022 The similarity measures learned by previous approaches\nultimately project categories as clusters into a metric space (albeit potentially via a complex embedding), since an item is inherently more similar to those from the same category than others (as we show later in Figure 5). This means that cross-category recommendations can only be made by exploiting an explicit category tree (e.g. \u2018find the shoes nearest to these jeans\u2019). Not only do such approaches require explicit category labels, but they are also subject to any noise or deficiencies in the category data. Our method can make cross-category recommendations without any depen-\nar X\niv :1\n60 3.\n09 47\n3v 3\n[ cs\n.I R\n] 2\n9 Se\np 20\n16\ndence on the presence (or quality) of explicit category information. \u2022 Other assumptions made by metric learning approaches are also too strict for recommendation: an item is not necessarily compatible with itself (identity), nor are the types of relationships we want to learn necessarily symmetric (e.g. a spare battery is a good add-on item for a laptop, but not vice-versa). Other assumptions hidden in previous approaches (such as transitivity) may also be too strict, e.g. an iPhone is dissimilar from a Surface, though both are related to an iPad. Our approach is flexible enough to capture such complex and non-metric relationships. \u2022 Previous approaches learned a single \u2018global\u2019 (albeit complex) notion of relatedness, neglecting any \u2018local\u2019 notions that could be equally important. In contrast, we capture multiple (and possibly competing) notions of \u2018relatedness\u2019 simultaneously. This is also key to generating diverse sets of recommendations. E.g. a shirt may be compatible with (a) a similar shirt from a different brand, (b) a similar shirt with a different color, (c) a complementary pair of pants, or (d) a complementary pair of shoes. By learning \u2018relatedness\u2019 as a mixture of multiple competing notions, we can handle diverse sets of recommendations naturally.\nWe propose a novel method, Mixtures of Non-Metric Embeddings for Recommendation, or Monomer for short, that addresses the above limitations. We demonstrate our idea in Figure 1 (we later show an example on real data in Figure 2). Here we embed the first item x (the query) into one space (the \u2018anchor space\u2019), and embed its potential match y into a series of N additional spaces. Now, the relatedness between x and y is measured in terms of multiple notions, each captured by one of the N spaces involved. Furthermore, the N spaces are weighted according to a\nmixtures-of-experts type framework, determining to what extent each of the N embeddings is \u2018relevant\u2019 to a particular query.\nNote in particular that the method described in Figure 1 can learn non-metric relationships since we are measuring the distance between two different embeddings. The learned relationships are not necessarily symmetric, nor do identity and transitivity necessarily hold; on the other hand the model is flexible enough such that a metric embedding could be learned if that was what the data supported.\nFor clarity, our contributions are summarized as follows: 1) We propose a new scalable method, Monomer, for\nheterogeneous item-to-item recommendation. The presented mixtures-of-embeddings framework allows it to learn non-metric relationships, thereby overcoming multiple limitations present in existing work. 2) We demonstrate quantitatively that Monomer is effective at learning notions of \u2018relatedness\u2019 from heterogeneous dyads of co-purchases from Amazon, and in particular that it does so more accurately than recent approaches based on metric/similarity learning. 3) We qualitatively show that Monomer can effectively learn multiple, semantically complex notions of \u2018relatedness,\u2019 and that these can be useful to generate rich, heterogeneous, and diverse sets of recommendations.\nCode and data can be found at https://sites.google.com/a/ eng.ucsd.edu/ruining- he/."}, {"heading": "II. RELATED WORK", "text": "The most closely related branches of work to ours are (1) Those that deal with the item-to-item recommendation problem, e.g. systems that generate recommendations by modeling relationships between items; and (2) Works that deal with metric (or relationship) learning in general, whether or not for recommendation.\nItem-to-Item Recommendation. Identifying relationships among items is a fundamental part of many real-world recommender systems, e.g. to generate recommendations of the form \u2018people who viewed x also viewed y\u2019 on Amazon. Such methods may be based on collaborative filtering, e.g. counting the overlap between users who have clicked on / bought both items, as in Amazon\u2019s own solution [18]. Latent-factor approaches aim to model user-item relationships in terms of low-dimensional factors, such that \u2018similar\u2019 items are those with close embeddings. See (e.g.) [1, 17] for surveys, and [18], [11], and [34] for specific systems that make use of Amazon, Etsy, and Ebay data.\nOf more interest to us are systems that predict itemto-item relationships based on the content (e.g. images/text/metadata) of the items themselves. Various systems have been proposed to address specific settings, e.g. to identify relationships between members of \u2018urban tribes\u2019 [25], tweets [28], text [2, 4], or music [27]. Several methods\nhave also been used to model visual data [3, 9, 15, 26, 32], though typically in settings where the metric assumption is well-founded (e.g. similar image retrieval).\nOur work follows recent examples that aim to model copurchase and co-browsing relationships, using a recently introduced dataset from Amazon [21, 22, 31]. While we extend (and compare quantitatively against) such work, our main contribution here is that we substantially relax the model assumptions to allow for more complex relationships than mere similarity between items.\nAlso of interest are a few works that model clothing data, particularly in recommendation settings, e.g. a few recent works that aim to capture some notion of \u2018style\u2019 include [8, 10, 13, 16, 19, 33]. However the specific tasks considered there are quite different from the item-to-item recommendation task in which we are interested.\nMetric (and non-metric) Learning. Outside of the recommendation scenarios considered here, learning the features that describe relationships between objects is a vast topic. Typically, one is given some collection of putative relationships between items (i.e., a training set), and the goal is then to identify a (parameterized) function that can be tuned to fit these relationships, i.e., to assign observed relationships a higher likelihood or score than non-relationships. Stateof-the-art methods identify hidden variables or factors that describe relationships among items [7, 29], e.g. by factorizing the matrix of links between items [23]. Again, the main contributions we hope to make over such approaches are (1) to relax the assumption of metricity, and (2) to allow for multiple notions of \u2018relatedness\u2019 to compete and interact. While a few approaches have recently been proposed to learn non-metric relationships (e.g. [5]), we are unaware of any that allow for the scale of the data (thousands of features, millions of items and relationships) that we consider."}, {"heading": "III. THE MODEL", "text": "Formally, we are given a dataset D comprising a large corpus of objects (or \u2018items\u2019) and the pairwise relationships R between items from different subcategories, i.e., if (x, y) \u2208 R then (1) item x and y are related, and (2) x and y are not from the same subcategory (e.g. a shirt and a matching pair of pants). We choose such crosscategory recommendations to highlight the ability of our model to generate recommendations between heterogeneous pairs of items. This matches the training instance selection approach from [31]. Additionally, a high-dimensional feature vector fx associated with each item x is also provided (encoding e.g. its image or the text of its reviews). We seek a scalable method to model such relationships with a set of parameterized transform functions d(x, y) such that related objects ((x, y) \u2208 R) are assigned higher probabilities than non-related ones ((x, y) /\u2208 R). Notation used throughout the paper is summarized in Table I."}, {"heading": "A. Preliminaries", "text": "Visual Features. In this paper, we mainly consider the case of using high-level visual features for relationship prediction. This is particularly useful for clothing recommendation (for example), a natural domain in which learning heterogeneous relationships between items across categories is particularly important.\nOur visual features are extracted from a deep convolutional neural network pre-trained on 1.2 million ImageNet (ILSVRC2010) images. In particular, we used the Caffe reference model [14], which has 5 convolutional layers followed by 3 fully-connected layers, to extract F = 4096 dimensional visual features from the second fully-connected layer (i.e., FC7).\nNote however that our proposed method is agnostic to the type of features used, and as we show later can handle other types of features (e.g. text) in order to address more general settings.\nMahalanobis Transform. In order to model subtle notions like \u2018compatibility\u2019 upon the raw visual features, we need expressive transformations that are capable of relating feature dimensions to explain the relationships between pairs of items. To this end, we follow the approach from [22]: there, a Mahalanobis Distance is used to measure the distance (or \u2018dissimilarity\u2019) between items within the feature space according to the knowledge of how different feature dimensions relate to each other. Let M denote the matrix that parameterizes the Mahalanobis Distance, then the distance between an item pair (x, y) is defined by\ndM(x, y) = (fx \u2212 fy)TM(fx \u2212 fy), (1)\nwhere fx and fy are the features vectors of x and y respectively. Although such an approach defines a distance function (and therefore suffers from the issues we are hoping to address), we use this method as a building block and ultimately relax its limitations.\nMixtures-of-Experts. Mixtures of experts (MoEs) are a classical machine learning method to aggregate the predictions of a set of \u2018weak\u2019 learners, known as experts [12]. What is particularly elegant about this approach is that it allows each learner to \u2018focus\u2019 on classifying instances about which it is relevant (i.e., expert), without being penalized for making misclassifications elsewhere.\nFor regression tasks such as the one we consider, each learner (denoted by l) outputs a prediction value Pred l(X) for the given input X . These predictions are then aggregated to generate the final prediction by associating weighted \u2018confidence\u2019 scores with each learner. Here we are interested in probabilistically modeling such confidences to be proportional to the expertise of the learners:\nPred(X)\ufe38 \ufe37\ufe37 \ufe38 final prediction = \u2211 l confidence in l\u2019s expertise\ufe37 \ufe38\ufe38 \ufe37 P (l|X) \u00b7Pred l(X)\ufe38 \ufe37\ufe37 \ufe38 l\u2019s prediction . (2)\nIn our model, each \u2018expert\u2019 shall correspond to a single notion of \u2018relatedness\u2019 between items. Thus, for a given pair of items that are potentially related, we can determine (a) which notions of relatedness are relevant for these items (P (l|X)); and (b) whether or not they are related according to that notion (Pred l(X)). These two functions are learned jointly, such that the model automatically uncovers multiple notions of \u2018relatedness\u2019 simultaneously."}, {"heading": "B. Model Specifics", "text": "First we describe how Mahalanobis transforms have previously been applied to this task, and can be used as a building block for this task, before describing our proposed non-metric method.\n1) Low-rank Mahalanobis Metric: Considering the high dimensionality of the visual features we are modeling (feature dimension F = 4096 in our case), learning a full rank positive semi-definite matrix M as in Eq. (1) is neither computationally tractable for existing solvers nor practical given the size of the dataset.\nRecently it was shown in [22] that a low-rank approximation of a Mahalanobis matrix works very well on visual datasets for the tasks considered in this paper. Specifically, the F \u00d7 F Mahalanobis matrix is approximated by M \u2248 EET, where E is an F \u00d7K matrix and K F . Then the distance between a pair (x, y) is calculated by\ndE(x, y) = (fx\u2212 fy)TEET (fx\u2212 fy) = ||ET fx\u2212ET fy||22. (3) This can be viewed as embedding the high-dimensional feature space (F -d) into a much lower-dimensional one (Kd) within which the Euclidean distance is measured. Note that the low rank property reduces the number of model parameters and increases the training efficiency significantly.\n2) Multiple, Non-Metric Embeddings: There are two key limitations from using a low-rank Mahalanobis embedding approach like the one above. First, it can capture only a single set of dimensions (or the \u2018statistically dominant reason\u2019) that determines whether two given items are related or not. However, there might be multiple reasons relevant to the link discrimination task in question. For example, a shirt and a pair of pants might go well together due to complementary colors, compatible textures, or simply some common characteristics they share (such as both having pockets/buttons, etc.). This drives us to use a group of embeddings, parameterized by N matrices E1, . . . ,EN each with dimensionality F\u00d7K for the prediction task, with each capturing a different set of factors or \u2018reasons\u2019 that items may be related.\nAnother limitation of the single Mahalanobis embedding method, or more generally any metric-based method, is that it assumes that the closest neighbor of a given item is always itself, which is inappropriate for our task of placing many different categories of items close to the target. To overcome this shortcoming, we propose to use an anchor embedding (denoted by E0, again, with dimensionality F \u00d7K) to learn the feature mappings in a non-metric manner.\nIn our model, E0 projects item x to a reference point ET0 fx in the corresponding space, referred to as the anchor space as it will be used as the basis for further comparisons. Next, embeddings Ek (for k = 1, 2, . . . , N ) map the potential match y and correspond to a particular notion of relatedness, such that ET0 fx will be close to E T k fy (for some k) if x and y are related. That is, the predicted distance dk(x, y) by the k-th learner is\ndk(x, y) = || x\u2019s position in the anchor space\ufe37 \ufe38\ufe38 \ufe37 ET0 fx\u2212ETk fy\ufe38 \ufe37\ufe37 \ufe38\ny\u2019s position in the k-th \u2018pseudo\u2019 space\n||22. (4)\nFor clarity, we call the N spaces defined by Ek (k > 0) \u2018pseudo\u2019 spaces as all distance calculations are still performed within one actual space, i.e., the anchor space.\nThe above definition supports learning directed relationships as the model is not required to be symmetric; but, it is flexible enough to learn symmetric (or even metric) embeddings if such structures are exhibited by the data.\n3) Probabilistic Mixtures of Embeddings: Now we introduce how we aggregate the predictions from different embeddings. Given an item pair (x, y), we build our model upon the MoE framework to learn a probabilistic gating function to \u2018switch\u2019 among different embeddings. Considering our asymmetric setting where the query item x in the pair is used as the reference point, we model the probability that the k-th embedding is used for the given pair (x, y)\nwith a softmax formulation:\nP (k|(x, y)\ufe38 \ufe37\ufe37 \ufe38 the given item pair ) =\nonly depends on x\ufe37 \ufe38\ufe38 \ufe37 P (k|x) =\nexp(UT:,kfx)\u2211 i exp(U T :,ifx) , (5)\nwhere U is a newly-introduced F \u00d7 N parameter matrix with U:,k being its k-th column. Briefly, the idea is to compute the probability distribution over the N learners given the characteristics of the \u2018pivot\u2019 item x. Note that our formulation is efficient as it only introduces a small number of parameters given that N is usually a small number (e.g. on the order of 4 or 5 in our experiments).\nFinally, our model calculates the \u2018distance\u2019 of an item pair (x, y) by the probabilistic expectation:\nd(x, y) = N\u2211 k P (k|(x, y)) \u00b7 dk(x, y). (6)\nNote that our \u2018distance\u2019 definition is a non-metric method as it only preserves the non-negativity and is relaxing the symmetry, identity, and triangle inequality properties."}, {"heading": "C. Learning the Model", "text": "With the \u2018distance\u2019 function defined above, we model the probability that a pair is related by a shifted sigmoid function (in a way similar to [22]):\nP ((x, y) \u2208 R) = \u03c3c(\u2212d(x, y)) = 1\n1 + exp(d(x, y)\u2212 c) .\n(7) Next, we need to randomly select a negative set of relationships R\u0304. To this end, we use a procedure from [24] which randomly rewires the positive set in such a way that (1) the degree sequence of items is preserved and (2) each negative pair consists of items from two categories.\nThen we proceed by fitting the parameters by maximizing the log-likelihood of the training corpus:\n\u0398\u0302 = arg max \u0398 L(R, R\u0304|\u0398) = \u2211 (x,y)\u2208R log(P ((x, y) \u2208 R))\n+ \u2211\n(x,y)\u2208R\u0304\nlog(1\u2212 P ((x, y) \u2208 R)) + \u2126(\u0398),\n(8)\nwhere \u0398 is the full parameter set {E0,E1, . . . ,EN ,U, c}, and \u2126(\u0398) is an L2-regularizer to avoid overfitting. The total number of parameters is F \u00d7 (N \u00d7 K + K + N) + 1. Since N and K are small numbers (see Section IV), the log-likelihood as well as the derivatives can be computed efficiently.\nMonomer is learned with L-BFGS [20], a quasi-Newton method for non-linear optimization of problems with a large number of variables. Our log-likelihood and the full derivative computations can be na\u0131\u0308vely parallelized over all training pairs (x, y) \u2208 R \u222a R\u0304. This means the optimization can easily benefit from multi-threading and even\nparallelization across multiple machines (e.g. [6]). Note that Monomer and the single-embedding method share the same time complexity when using the same amount of embedding parameters (see Appendix for a detailed analysis)."}, {"heading": "IV. EXPERIMENTS", "text": ""}, {"heading": "A. Dataset", "text": "To fully evaluate the ability of Monomer to handle realworld tasks, we want to experiment on the largest dataset available. To this end, we adopt the dataset from Amazon recently introduced by [22]. We focus on five large toplevel categories under the category tree rooted with \u2018Clothing Shoes & Jewelry\u2019, i.e., Men\u2019s, Women\u2019s, Boys\u2019, Girls\u2019, and Baby\u2019s Clothing & Accessories. Statistics are shown in Table II.\nFor each of the above categories, we experiment with two important types of relationships: \u2018users who bought x also bought y,\u2019 and \u2018users who viewed x also viewed y,\u2019 denoted by \u2018also bought\u2019 and \u2018also viewed\u2019 respectively for brevity. Such relationships are a key source of data to learn from in order to recommend items of potential interests to customers. Ground-truth for these relationships is also introduced in [22], and are originally derived from co-purchase and cobrowsing data from Amazon.\nRecall that our objective is to learn heterogeneous relationships so as to support cross-category recommendation. Across the entire dataset, such relationships are noisy, sparse, and not always meaningful. To address issues of noise and sparsity to some extent, it\u2019s sensible to focus on the relationships within the scope of a particular top-level category, e.g. Women\u2019s Clothing, Men\u2019s Clothing etc. We then consider relationships between \u20182nd-level\u2019 categories, e.g. women\u2019s shirts, women\u2019s shoes, etc.\nIn summary, our evaluation protocol is as follows: 1) A single experiment consists of a specific cate-\ngory (e.g. Men\u2019s Clothing) and a graph type (e.g. \u2018also bought\u2019). 2) For each experiment, the relationships (R) and a random sample of non-relationships (R\u0304, see Section III-C) are pairs of items connecting different subcategories of the category we are experimenting on. Note\nthat |R|= |R\u0304| and they share the same distribution over the items. 3) For each experiment, we use an 80/10/10 random split of the dataset (R \u222a R\u0304) with the training set being at most two million pairs. Our goal is then to predict the relationships and non-relationships correctly, i.e., link prediction. 4) For all methods, the validation set is used for tuning the regularization hyperparameters, and finally the learned models are evaluated on the test set in terms of error/misclassification rate.\nFor example, one experiment is to predict \u2018also bought\u2019 relationships for Men\u2019s Clothing. There are 56 subcategories under Men\u2019s Clothing (see Table II), so our goal is to distinguish edges from non-edges connecting items from among these subcategories.\nAll experiments were performed on a single machine with 64GB memory and 8 cores. Our largest experiment required around 40 hours to train, though most were completed in a few hours."}, {"heading": "B. Comparison Methods", "text": "Weighted Nearest Neighbor (WNN): This method uses a weighted Euclidean distance in the raw feature space to measure similarity between items: dw(x, y) = \u2016w \u25e6 (fx \u2212 fy)\u201622. Here \u25e6 is the Hadamard product and w is a weighting vector that is learned from the data. Category Tree (CT): This method computes a matrix of co-occurrences between subcategories from the training data. Then a pair (x, y) is predicted to be positive if the subcategory of y is one of the top 50% most commonly connected subcategories to the subcategory of x. Low-rank Mahalanobis Transform (LMT): LMT [22] is a state-of-the-art method for learning visual similarities among different items (possibly between categories) on large-scale datasets. LMT learns a single low-rank Mahalanobis embedding matrix to embed all items into a low-dimensional space. Then it predicts the links between a given pair based on the Euclidean distance within the embedded space (i.e., Eq. (3)). Mixtures of Non-metric Embeddings (Monomer): Our method. This method learns a mixture of low-rank transforms/embeddings to uncover groups of underlying reasons that explain the relationships between items. It measures the \u2018distance\u2019 (or dissimilarity) between items in a non-metric manner (i.e., Eq. (6)).\nUltimately, our baselines are designed to demonstrate that (a) the raw feature space is not directly suitable for learning the notions of relationships (WNN); (b) using category metadata directly and not using other features (CT) results in relatively poor performance; and that (c) our proposed model is an improvement over the state-of-the-art method on our task (LMT)."}, {"heading": "C. Performance & Quantitative Analysis", "text": "Error rates on the test set for all experiments are reported in Table III. To perform a fair comparison between LMT and Monomer, the following setting is used for all experiments in this paper:\n1) It has been shown by [22] that LMT can achieve better accuracy when using a reasonably large number of embedding dimensions (K). Therefore in all cases we choose K large enough such that LMT obtains the best possible (validation) performance. 2) In all cases we try to compare LMT and Monomer under the same total number of model parameters. For example, if we set the number of dimensions K to 100 for LMT, then a fair setting for Monomer would be K = 20 and N = 4. This way both of them are using 100F embedding parameters. Recall that N is the number of embeddings (excluding the anchor embedding).\nFor experiments on \u2018also bought\u2019 relationships, LMT uses K = 100 dimensions and Monomer uses K = 20 and N = 4. While for experiments on \u2018also viewed\u2019 relationships, K is set to 50 for LMT and K = 10 and N = 4 for Monomer. Note that \u2018also viewed\u2019 relationships are almost twice as sparse as \u2018also bought\u2019 relationships (and thus a model with fewer parameters performed better at validation time), as shown in Table II. We make a few observations to explain and understand our findings as follows:\n1) WNN is particularly inaccurate for our task. We also observed relatively high training errors with this method for most experiments. This confirms our conjecture that raw similarity is inappropriate for our task, and that in order to learn the relationships across\n(sub)categories, some sort of expressive transforms are needed for manipulating the raw features. 2) The counting method (CT) performs considerably worse than other methods. This reveals that the predictive information used by the other models goes beyond the categories of the products, i.e., that the imagebased models are learning relationships between finergrained attributes. 3) Note that all models perform better at predicting \u2018also viewed\u2019 than \u2018also bought\u2019 relationships. This is reasonable since intuitively items that are \u201calso viewed\u201d indeed tend to share more common characteristics compared to the \u201calso bought\u201d scenario. The greater heterogeneity between training pairs in the latter task makes it comparatively harder to address. 4) Monomer outperforms LMT significantly for all experiments, especially for the harder task of predicting co-purchase dyads.\nD. Visualization of the Embeddings\nNext, we proceed by demonstrating the embeddings learned from our largest dataset, Women\u2019s Clothing, by Monomer. We take the same model trained on co-purchase relationships from the previous subsection and visualize it in Figure 2. In this figure, we show each of the 5 visual spaces by a 2-d visualization with t-SNE [30]. Images are a random sample of size 50,000 from the Women\u2019s Clothing\ndataset and projected (using the learned embedding matrices) to each visual space to demonstrate the underlying structure.\nAs analyzed in Section III, each embedding (i.e., learner) is capturing a specific notion of relatedness that explains the relationships of pairs of items in the corpus. In other words, it means that the nearest neighbors in each of the N \u2018pseudo\u2019 spaces should be related to the query according to the specific notion captured. Therefore those neighbors should be recommended as potential matches to the query item, as shown by the example in Figure 2. For the query image (a t-shirt) in this example, Monomer recommends bundles of similar t-shirts, pants, shoes, and accessories (watches etc.) that resemble the query in terms of patterns (e.g. space 1), colors (e.g. space 2), and more generally \u2018styles\u2019 (e.g. space 3 and 4).1 Such matching between a query image and nearby items in alternate spaces directly facilitates the task of recommending visually consistent outfits, where modeling and understanding the visual compatibility across categories is essential.\nE. Visualization of the Visual Dimensions\nNext we demonstrate the visual dimensions learned by Monomer, i.e., what kind of characteristics the model is capturing to explain the relationships among items. A simple way to visualize these dimensions is to show items that\n1The second patch actually contains a few men\u2019s clothing items due to data deficiency\u2014an intrinsic problem suffered by Amazon.\nexhibit maximal values for each dimension. In other words, we select items according to\narg max x\nET:,ifx,\nwhere E:,i is the i-th column of the embedding matrix E, corresponding to a visual dimension i. Intuitively, this informs us of items that are most representative of a particular visual aspect discovered by the model.\nWe trained Monomer on Men\u2019s Clothing (K = 10, N = 4), predicting co-purchase relationships. Due to limited space, we randomly select one embedding and demonstrate its 10 visual dimensions in Figure 3. From the figure we can see that (1) Monomer seems to uncover meaningful visual dimensions, each of which highlights certain fine-grained item types (e.g. plaid tees and jeans in row 1 and 5); (2) human notions seem to have been captured, e.g. casual versus formal in rows 2 and 9; and (3) subtle differences between different characteristics can be distinguished (e.g. tees in rows 2 and 6). Monomer\u2019s ability to discover and model the correlations among visual characteristics explains its success.\nF. Visual Recommendation & Analysis\nBeyond achieving high prediction accuracy, we want to test the ability of Monomer to generate useful recommendations. Again, we mainly compare to the state-of-the-art metric-based method, LMT. Both methods are able to learn relationships from the data, so one common setting is to retrieve \u2018similar\u2019 items (i.e., maximum probability of being related) to a given query.\nFirst we train LMT and Monomer on Women\u2019s Clothing to predict \u2018also bought\u2019 relationships, under the same setting as in Table III. This way the two models will learn\ntheir own similarity (or distance) functions from the data. Next, from Women\u2019s Clothing we randomly select a few query items, for each of which LMT and Monomer will retrieve its highest-probability links according to their own similarity functions. Figure 4 demonstrates such queries and the retrieved connections (in all cases ranked in decreasing order in terms of the probability of the link) by the two models.\nAs shown in Figure 4, the metric-based method (LMT) tends to recommend items that are very similar to the query, even though for this task it is trained to predict complementary relationships (i.e., \u2018also bought\u2019). Indeed it is very difficult for a metric-based method to project items from different subcategories to be nearer than items from the same category; presumably such methods are limited by their underlying assumption that the most similar item to a given query is always itself. In [22] this was addressed to some extent by making explicit use of the category information at test time (e.g. \u2018find the shirt closest to this pair of shoes\u2019), though our model is able to make diverse sets of recommendations without such a dependence on explicit category information.\nRecall that LMT learns an embedding within which the Euclidean distance is used to distinguish relationships from non-relationships. Visualizing such spaces can help understand the behavior of LMT. Again we uniformly sample 10,000 items from the dataset and use t-SNE [30] to visualize their positions in the embedded space. We are particularly interested in the distribution of different subcategories of items over the space. Therefore we assign a unique color to each subcategory in the dataset. Figure 5 shows results on two representative datasets, Men\u2019s and Women\u2019s Clothing.\nFrom Figure 5 we find that subcategories of items tend to become \u2018clusters\u2019 in the embedded space. This can be problematic especially for recommending related items across subcategories:\n1) From a recommendation perspective, there will be a \u2018limited coverage\u2019 issue because given a query LMT tends to recommend only those items on the boundaries of the clusters. There is no way that items located near the center of a cluster will ever be recommended, since the closest item outside the query\u2019s own category cluster will be on the fringe of a different category cluster. 2) Recommendations will suffer from \u2018mislabeling\u2019 issues. Note that LMT relies heavily on the taxonomy metadata at test time to filter out items from the same subcategory as the query. However, even a tiny number of mislabeled items in the dataset can poison recommendations, and certainly some such examples exist in the Amazon dataset [31]. Unexpected items may appear on the recommendation list when there are mislabeled items that actually come from the same subcategory as the query.\nNote that Monomer doesn\u2019t suffer from either of above issues since it has already successfully \u2018blended\u2019 different subcategories, as shown by the nearest neighbors in Figure 4."}, {"heading": "G. Learning Compatibility from Textual Features", "text": "In previous sections, we have shown that Monomer not only performs very well on link prediction tasks but also that it recommends highly diverse sets of items. However, above we only considered scenarios in which relationships like copurchasing can be predicted from visual features. Following this, a natural question would be \u201cIs Monomer able to learn relationships from non-visual features and achieve similarly competitive performance?\u201d\nTo answer the above question, we perform further experiments on Bag-of-Words (BoW) features extracted from the text of product reviews, which are also available in the Amazon dataset. In particular, we experiment with a variety of top-level Amazon categories, i.e, Electronics, Automotive, Video Games, Movies & TV, Office Products, Home &\nKitchen, and Cell Phones & Accessories (denoted by \u2018Elect\u2019, \u2018Auto\u2019, \u2018Games\u2019, \u2018Movies\u2019, \u2018Office\u2019, \u2018Home\u2019, and \u2018Phones\u2019 resp.). Statistics of these datasets are shown in Table IV.\nFor each category (e.g. Electronics) we use the following procedure to generate BoW features for all its items: (1) Remove stop-words and construct a dictionary. Our dictionary consists of 5000 nouns or adjectives or adjective-noun bigrams that appear most frequently in the review corpus being considered. (2) For each item i, a document di is generated by bagging all the reviews it has received. (3) The 5000-d BoW feature vector fi of each item i is computed by normalizing the raw word counts of document di to sum to 1. (4) Items without any reviews attached are seen as invalid items and are dropped from the dataset. In the following experiments, we use the same evaluation protocol as in the previous visual feature experiments.\nLatent Dirichlet Allocation + WNN (LDA): Here we add another baseline for further comparison. This method first obtains 100 topics with LDA with a vocabulary of size 5000,2 and then uses WNN to distinguish relationships from non-relationships within the 100-d topic space.\nResults and Analysis. Table V summarizes the error rates on the test sets for all experiments. We observe that (1) basic methods like WNN and LDA are not particularly accurate for the task; (2) Monomer outperforms LMT considerably especially on the harder tasks, which demonstrates its ability to handle textual features; and (3) the comparative hardness of \u2018also bought\u2019 over \u2018also viewed\u2019 prediction now seems to be dependent on the dataset in question, presumably due to different semantics of the two link types, or different patterns of customer behavior, among different categories."}, {"heading": "V. CONCLUSION", "text": "In this paper, we presented Monomer, a method to model heterogeneous relationships for item-to-item recommendation tasks. We noted that existing methods for item-to-item recommendation suffer from a few limitations when dealing with heterogeneous data, due mainly to their reliance on metricity or \u2018nearest-neighbor\u2019 type assumptions. To overcome these limitations, our method made use of \u2018mixtures\u2019 of non-metric embeddings, which allows us to relax the identity and symmetry assumptions of existing metric-based methods. The proposed scalable approach generates diverse and cross-category recommendations effectively that capture more complex relationships than mere visual similarity. We showed quantitatively that Monomer is accurate at link prediction tasks using co-purchase and co-browsing dyads from Amazon, and qualitatively that it is able to generate diverse recommendations that are consistent with a particular visual style.\n2We adopted the implementation in Gensim (default parameters kept): https://radimrehurek.com/gensim/\nAPPENDIX\nComplexity Analysis: In Monomer, each embedding matrix has F \u00d7K parameters, which means there are in total F \u00d7 K\u00d7(N+1) embedding parameters. Since Monomer doesn\u2019t need to use more embedding parameters to outperform LMT (see Section IV), we focus on comparing Monomer and LMT under the same total number of embedding parameters, in terms of the amount of multiplications involved.\nFor complete clarity, we denote the embedding dimension of LMT and Monomer by K \u2032 and K respectively (F \u00d7 K \u2032 = F \u00d7 K \u00d7 (N + 1)). For each training pair (x, y), LMT takes O(F \u00d7 K \u2032) to compute the distance between them and the corresponding derivatives. While for Monomer, it takes O(F \u00d7 K \u2032) to project x and y to the multiple spaces. Afterwards the \u2018distance\u2019 will be calculated in O(N \u00d7 K) + O(N \u00d7 F ), where the former is for computing N distance components and the latter is spent on the probabilistic weights. In total, it takes O(F \u00d7 K \u2032) + O(N \u00d7 K) + O(N \u00d7 F ) = O(F \u00d7 K \u2032) for Monomer to finish \u2018distance\u2019 computation. Likewise, it\u2019s easy to verify that the corresponding derivatives can also be computed in O(F\u00d7K \u2032) time. To sum up, training Monomer and LMT will have the same time complexity when using the same amount of embedding parameters."}], "references": [{"title": "Toward the next generation of recommender systems: A survey of the state-of-the-art and possible extensions", "author": ["G. Adomavicius", "A. Tuzhilin"], "venue": "TKDD,", "citeRegEx": "1", "shortCiteRegEx": "1", "year": 2005}, {"title": "Block-LDA: Jointly modeling entity-annotated text and entity-entity links", "author": ["R. Balasubramanyan", "W. Cohen"], "venue": "In SDM,", "citeRegEx": "2", "shortCiteRegEx": "2", "year": 2011}, {"title": "Supervised learning of semantic classes for image annotation and retrieval", "author": ["G. Carneiro", "A.B. Chan", "P.J. Moreno", "N. Vasconcelos"], "venue": "IEEE Trans. on PAMI,", "citeRegEx": "3", "shortCiteRegEx": "3", "year": 2007}, {"title": "Relational topic models for document networks", "author": ["J. Chang", "D. Blei"], "venue": "In AISTATS,", "citeRegEx": "4", "shortCiteRegEx": "4", "year": 2009}, {"title": "Similarity component analysis", "author": ["S. Changpinyo", "K. Liu", "F. Sha"], "venue": "In NIPS,", "citeRegEx": "5", "shortCiteRegEx": "5", "year": 2013}, {"title": "Large-scale l-bfgs using mapreduce", "author": ["W. Chen", "Z. Wang", "J. Zhou"], "venue": "In NIPS,", "citeRegEx": "6", "shortCiteRegEx": "6", "year": 2014}, {"title": "Latent coincidence analysis: A hidden variable model for distance metric learning", "author": ["M. Der", "L. Saul"], "venue": "In NIPS,", "citeRegEx": "7", "shortCiteRegEx": "7", "year": 2012}, {"title": "Style finder: Fine-grained clothing style detection and retrieval", "author": ["W. Di", "C. Wah", "A. Bhardwaj", "R. Piramuthu", "N. Sundaresan"], "venue": "In CVPR Workshops,", "citeRegEx": "8", "shortCiteRegEx": "8", "year": 2013}, {"title": "Ups and downs: Modeling the visual evolution of fashion trends with one-class collaborative filtering", "author": ["R. He", "J. McAuley"], "venue": "In WWW,", "citeRegEx": "10", "shortCiteRegEx": "10", "year": 2016}, {"title": "Style in the long tail: Discovering unique interests with latent variable models in large scale social e-commerce", "author": ["D.J. Hu", "R. Hall", "J. Attenberg"], "venue": "In KDD,", "citeRegEx": "11", "shortCiteRegEx": "11", "year": 2014}, {"title": "Adaptive mixtures of local experts", "author": ["R.A. Jacobs", "M.I. Jordan", "S.J. Nowlan", "G.E. Hinton"], "venue": "Neural computation,", "citeRegEx": "12", "shortCiteRegEx": "12", "year": 1991}, {"title": "Large scale visual recommendations from street fashion images", "author": ["V. Jagadeesh", "R. Piramuthu", "A. Bhardwaj", "W. Di", "N. Sundaresan"], "venue": null, "citeRegEx": "13", "shortCiteRegEx": "13", "year": 2014}, {"title": "Caffe: Convolutional architecture for fast feature embedding", "author": ["Y. Jia", "E. Shelhamer", "J. Donahue", "S. Karayev", "J. Long", "R.B. Girshick", "S. Guadarrama", "T. Darrell"], "venue": "In MM,", "citeRegEx": "14", "shortCiteRegEx": "14", "year": 2014}, {"title": "Reinforced similarity integration in image-rich information", "author": ["X. Jin", "J. Luo", "J. Yu", "G. Wang", "D. Joshi", "J. Han"], "venue": null, "citeRegEx": "15", "shortCiteRegEx": "15", "year": 2013}, {"title": "Getting the look: Clothing recognition and segmentation for automatic product suggestions in everyday photos", "author": ["Y. Kalantidis", "L. Kennedy", "L.-J. Li"], "venue": "In ICMR,", "citeRegEx": "16", "shortCiteRegEx": "16", "year": 2013}, {"title": "Advances in collaborative filtering", "author": ["Y. Koren", "R. Bell"], "venue": "In Recommender Systems Handbook. Springer,", "citeRegEx": "17", "shortCiteRegEx": "17", "year": 2011}, {"title": "Amazon.com recommendations: Item-to-item collaborative filtering", "author": ["G. Linden", "B. Smith", "J. York"], "venue": "IEEE Internet Computing,", "citeRegEx": "18", "shortCiteRegEx": "18", "year": 2003}, {"title": "Hi, magic closet, tell me what to wear", "author": ["S. Liu", "J. Feng", "Z. Song", "T. Zhang", "H. Lu", "C. Xu", "S. Yan"], "venue": "In MM,", "citeRegEx": "19", "shortCiteRegEx": "19", "year": 2012}, {"title": "On centroidal voronoi tessellation\u2014 energy smoothness and fast computation", "author": ["Y. Liu", "W. Wang", "B. L\u00e9vy", "F. Sun", "D.-M. Yan", "L. Lu", "C. Yang"], "venue": "ACM Transactions on Graphics (ToG),", "citeRegEx": "20", "shortCiteRegEx": "20", "year": 2009}, {"title": "Inferring networks of substitutable and complementary products", "author": ["J.J. McAuley", "R. Pandey", "J. Leskovec"], "venue": "In KDD,", "citeRegEx": "21", "shortCiteRegEx": "21", "year": 2015}, {"title": "Image-based recommendations on styles and substitutes", "author": ["J.J. McAuley", "C. Targett", "Q. Shi", "A. van den Hengel"], "venue": "In SIGIR,", "citeRegEx": "22", "shortCiteRegEx": "22", "year": 2015}, {"title": "Link prediction via matrix factorization", "author": ["A.K. Menon", "C. Elkan"], "venue": "In ECML,", "citeRegEx": "23", "shortCiteRegEx": "23", "year": 2011}, {"title": "On the uniform generation of random graphs with prescribed degree sequences", "author": ["R. Milo", "N. Kashtan", "S. Itzkovitz", "M.E.J. Newman", "U. Alon"], "venue": "Arxiv preprint cond-mat/0312028,", "citeRegEx": "24", "shortCiteRegEx": "24", "year": 2003}, {"title": "Urban tribes: Analyzing group photos from a social perspective", "author": ["A.C. Murillo", "I.S. Kwak", "L. Bourdev", "D. Kriegman", "S. Belongie"], "venue": "In CVPR Workshops,", "citeRegEx": "25", "shortCiteRegEx": "25", "year": 2012}, {"title": "Data-driven visual similarity for cross-domain image matching", "author": ["A. Shrivastava", "T. Malisiewicz", "A. Gupta", "A.A. Efros"], "venue": "ACM Trans. of Graphics,", "citeRegEx": "26", "shortCiteRegEx": "26", "year": 2011}, {"title": "Learning a metric for music similarity", "author": ["M. Slaney", "K. Weinberger", "W. White"], "venue": "In ICMIR,", "citeRegEx": "27", "shortCiteRegEx": "27", "year": 2008}, {"title": "Learning similarity functions for topic detection in online reputation monitoring", "author": ["D. Spina", "J. Gonzalo"], "venue": "In SIGIR,", "citeRegEx": "28", "shortCiteRegEx": "28", "year": 2014}, {"title": "Large margin component analysis", "author": ["L. Torresani", "K. chih Lee"], "venue": "In NIPS,", "citeRegEx": "29", "shortCiteRegEx": "29", "year": 2007}, {"title": "Accelerating t-SNE using treebased", "author": ["L. van der Maaten"], "venue": null, "citeRegEx": "30", "shortCiteRegEx": "30", "year": 2014}, {"title": "Learning visual clothing style with heterogeneous dyadic co-occurrences", "author": ["A. Veit", "B. Kovacs", "S. Bell", "J. McAuley", "K. Bala", "S. Belongie"], "venue": "In ICCV,", "citeRegEx": "31", "shortCiteRegEx": "31", "year": 2015}, {"title": "Boosting multi-kernel locality-sensitive hashing for scalable image retrieval", "author": ["H. Xia", "P. Wu", "S. Hoi", "R. Jin"], "venue": "In SIGIR,", "citeRegEx": "32", "shortCiteRegEx": "32", "year": 2012}, {"title": "Paper doll parsing: Retrieving similar styles to parse clothing items", "author": ["K. Yamaguchi", "M.H. Kiapour", "T.L. Berg"], "venue": "In ICCV,", "citeRegEx": "33", "shortCiteRegEx": "33", "year": 2013}, {"title": "Substitutes or complements: another step forward in recommendations", "author": ["J. Zheng", "X. Wu", "J. Niu", "A. Bolivar"], "venue": "In EC,", "citeRegEx": "34", "shortCiteRegEx": "34", "year": 2009}], "referenceMentions": [{"referenceID": 9, "context": "Knowing which items are \u2018similar,\u2019 or which otherwise may be substitutable or complementary, is key to building systems that can understand a user\u2019s context, recommend alternative items from the same style [11], or generate", "startOffset": 206, "endOffset": 210}, {"referenceID": 16, "context": "bundles of items that are compatible [18, 22, 34].", "startOffset": 37, "endOffset": 49}, {"referenceID": 20, "context": "bundles of items that are compatible [18, 22, 34].", "startOffset": 37, "endOffset": 49}, {"referenceID": 32, "context": "bundles of items that are compatible [18, 22, 34].", "startOffset": 37, "endOffset": 49}, {"referenceID": 19, "context": "to model co-purchasing behavior between products based on their visual appearance or textual descriptions [21, 22, 31].", "startOffset": 106, "endOffset": 118}, {"referenceID": 20, "context": "to model co-purchasing behavior between products based on their visual appearance or textual descriptions [21, 22, 31].", "startOffset": 106, "endOffset": 118}, {"referenceID": 29, "context": "to model co-purchasing behavior between products based on their visual appearance or textual descriptions [21, 22, 31].", "startOffset": 106, "endOffset": 118}, {"referenceID": 25, "context": "Such metric-learning approaches can be incredibly flexible and powerful, and have been used to identify similarities between items ranging from music [27] to members of the same tribe [7].", "startOffset": 150, "endOffset": 154}, {"referenceID": 6, "context": "Such metric-learning approaches can be incredibly flexible and powerful, and have been used to identify similarities between items ranging from music [27] to members of the same tribe [7].", "startOffset": 184, "endOffset": 187}, {"referenceID": 16, "context": "counting the overlap between users who have clicked on / bought both items, as in Amazon\u2019s own solution [18].", "startOffset": 104, "endOffset": 108}, {"referenceID": 0, "context": ") [1, 17] for surveys, and [18], [11], and [34] for specific systems that make use of Amazon, Etsy, and Ebay data.", "startOffset": 2, "endOffset": 9}, {"referenceID": 15, "context": ") [1, 17] for surveys, and [18], [11], and [34] for specific systems that make use of Amazon, Etsy, and Ebay data.", "startOffset": 2, "endOffset": 9}, {"referenceID": 16, "context": ") [1, 17] for surveys, and [18], [11], and [34] for specific systems that make use of Amazon, Etsy, and Ebay data.", "startOffset": 27, "endOffset": 31}, {"referenceID": 9, "context": ") [1, 17] for surveys, and [18], [11], and [34] for specific systems that make use of Amazon, Etsy, and Ebay data.", "startOffset": 33, "endOffset": 37}, {"referenceID": 32, "context": ") [1, 17] for surveys, and [18], [11], and [34] for specific systems that make use of Amazon, Etsy, and Ebay data.", "startOffset": 43, "endOffset": 47}, {"referenceID": 23, "context": "to identify relationships between members of \u2018urban tribes\u2019 [25], tweets [28], text [2, 4], or music [27].", "startOffset": 60, "endOffset": 64}, {"referenceID": 26, "context": "to identify relationships between members of \u2018urban tribes\u2019 [25], tweets [28], text [2, 4], or music [27].", "startOffset": 73, "endOffset": 77}, {"referenceID": 1, "context": "to identify relationships between members of \u2018urban tribes\u2019 [25], tweets [28], text [2, 4], or music [27].", "startOffset": 84, "endOffset": 90}, {"referenceID": 3, "context": "to identify relationships between members of \u2018urban tribes\u2019 [25], tweets [28], text [2, 4], or music [27].", "startOffset": 84, "endOffset": 90}, {"referenceID": 25, "context": "to identify relationships between members of \u2018urban tribes\u2019 [25], tweets [28], text [2, 4], or music [27].", "startOffset": 101, "endOffset": 105}, {"referenceID": 2, "context": "have also been used to model visual data [3, 9, 15, 26, 32], though typically in settings where the metric assumption is well-founded (e.", "startOffset": 41, "endOffset": 59}, {"referenceID": 13, "context": "have also been used to model visual data [3, 9, 15, 26, 32], though typically in settings where the metric assumption is well-founded (e.", "startOffset": 41, "endOffset": 59}, {"referenceID": 24, "context": "have also been used to model visual data [3, 9, 15, 26, 32], though typically in settings where the metric assumption is well-founded (e.", "startOffset": 41, "endOffset": 59}, {"referenceID": 30, "context": "have also been used to model visual data [3, 9, 15, 26, 32], though typically in settings where the metric assumption is well-founded (e.", "startOffset": 41, "endOffset": 59}, {"referenceID": 19, "context": "Our work follows recent examples that aim to model copurchase and co-browsing relationships, using a recently introduced dataset from Amazon [21, 22, 31].", "startOffset": 141, "endOffset": 153}, {"referenceID": 20, "context": "Our work follows recent examples that aim to model copurchase and co-browsing relationships, using a recently introduced dataset from Amazon [21, 22, 31].", "startOffset": 141, "endOffset": 153}, {"referenceID": 29, "context": "Our work follows recent examples that aim to model copurchase and co-browsing relationships, using a recently introduced dataset from Amazon [21, 22, 31].", "startOffset": 141, "endOffset": 153}, {"referenceID": 7, "context": "a few recent works that aim to capture some notion of \u2018style\u2019 include [8, 10, 13, 16, 19, 33].", "startOffset": 70, "endOffset": 93}, {"referenceID": 8, "context": "a few recent works that aim to capture some notion of \u2018style\u2019 include [8, 10, 13, 16, 19, 33].", "startOffset": 70, "endOffset": 93}, {"referenceID": 11, "context": "a few recent works that aim to capture some notion of \u2018style\u2019 include [8, 10, 13, 16, 19, 33].", "startOffset": 70, "endOffset": 93}, {"referenceID": 14, "context": "a few recent works that aim to capture some notion of \u2018style\u2019 include [8, 10, 13, 16, 19, 33].", "startOffset": 70, "endOffset": 93}, {"referenceID": 17, "context": "a few recent works that aim to capture some notion of \u2018style\u2019 include [8, 10, 13, 16, 19, 33].", "startOffset": 70, "endOffset": 93}, {"referenceID": 31, "context": "a few recent works that aim to capture some notion of \u2018style\u2019 include [8, 10, 13, 16, 19, 33].", "startOffset": 70, "endOffset": 93}, {"referenceID": 6, "context": "Stateof-the-art methods identify hidden variables or factors that describe relationships among items [7, 29], e.", "startOffset": 101, "endOffset": 108}, {"referenceID": 27, "context": "Stateof-the-art methods identify hidden variables or factors that describe relationships among items [7, 29], e.", "startOffset": 101, "endOffset": 108}, {"referenceID": 21, "context": "by factorizing the matrix of links between items [23].", "startOffset": 49, "endOffset": 53}, {"referenceID": 4, "context": "[5]), we are unaware of any that allow for the scale of the data (thousands of features, millions of items and relationships) that we consider.", "startOffset": 0, "endOffset": 3}, {"referenceID": 29, "context": "This matches the training instance selection approach from [31].", "startOffset": 59, "endOffset": 63}, {"referenceID": 12, "context": "In particular, we used the Caffe reference model [14], which has 5 convolutional layers followed by 3 fully-connected layers, to extract F = 4096 dimensional visual features from the second fully-connected layer (i.", "startOffset": 49, "endOffset": 53}, {"referenceID": 20, "context": "To this end, we follow the approach from [22]: there, a Mahalanobis Distance is used to measure the", "startOffset": 41, "endOffset": 45}, {"referenceID": 10, "context": "Mixtures of experts (MoEs) are a classical machine learning method to aggregate the predictions of a set of \u2018weak\u2019 learners, known as experts [12].", "startOffset": 142, "endOffset": 146}, {"referenceID": 20, "context": "Recently it was shown in [22] that a low-rank approximation of a Mahalanobis matrix works very well on visual datasets for the tasks considered in this paper.", "startOffset": 25, "endOffset": 29}, {"referenceID": 20, "context": "With the \u2018distance\u2019 function defined above, we model the probability that a pair is related by a shifted sigmoid function (in a way similar to [22]):", "startOffset": 143, "endOffset": 147}, {"referenceID": 22, "context": "To this end, we use a procedure from [24] which randomly rewires the positive set in such a way that (1) the degree sequence of items is preserved and (2) each negative pair consists of items from two categories.", "startOffset": 37, "endOffset": 41}, {"referenceID": 18, "context": "Monomer is learned with L-BFGS [20], a quasi-Newton method for non-linear optimization of problems with a", "startOffset": 31, "endOffset": 35}, {"referenceID": 5, "context": "[6]).", "startOffset": 0, "endOffset": 3}, {"referenceID": 20, "context": "To this end, we adopt the dataset from Amazon recently introduced by [22].", "startOffset": 69, "endOffset": 73}, {"referenceID": 20, "context": "Ground-truth for these relationships is also introduced in [22], and are originally derived from co-purchase and cobrowsing data from Amazon.", "startOffset": 59, "endOffset": 63}, {"referenceID": 20, "context": "Low-rank Mahalanobis Transform (LMT): LMT [22] is a state-of-the-art method for learning visual similarities among different items (possibly between categories) on large-scale datasets.", "startOffset": 42, "endOffset": 46}, {"referenceID": 20, "context": "1) It has been shown by [22] that LMT can achieve better accuracy when using a reasonably large number of embedding dimensions (K).", "startOffset": 24, "endOffset": 28}, {"referenceID": 28, "context": "Each visual space is demonstrated by a 2-d t-SNE grid view [30] (each cell randomly selects one image in overlapping cases).", "startOffset": 59, "endOffset": 63}, {"referenceID": 28, "context": "In this figure, we show each of the 5 visual spaces by a 2-d visualization with t-SNE [30].", "startOffset": 86, "endOffset": 90}, {"referenceID": 28, "context": "For visualization, we use t-SNE [30] to further embed this space into 2-d.", "startOffset": 32, "endOffset": 36}, {"referenceID": 20, "context": "In [22] this was addressed to some extent by making explicit use of the category information at test time (e.", "startOffset": 3, "endOffset": 7}, {"referenceID": 28, "context": "Again we uniformly sample 10,000 items from the dataset and use t-SNE [30] to visualize their positions in the embedded space.", "startOffset": 70, "endOffset": 74}, {"referenceID": 29, "context": "However, even a tiny number of mislabeled items in the dataset can poison recommendations, and certainly some such examples exist in the Amazon dataset [31].", "startOffset": 152, "endOffset": 156}], "year": 2016, "abstractText": "Identifying relationships between items is a key task of an online recommender system, in order to help users discover items that are functionally complementary or visually compatible. In domains like clothing recommendation, this task is particularly challenging since a successful system should be capable of handling a large corpus of items, a huge amount of relationships among them, as well as the high-dimensional and semantically complicated features involved. Furthermore, the human notion of \u201ccompatibility\u201d to capture goes beyond mere similarity: For two items to be compatible\u2014whether jeans and a t-shirt, or a laptop and a charger\u2014they should be similar in some ways, but systematically different in others. In this paper we propose a novel method, Monomer, to learn complicated and heterogeneous relationships between items in product recommendation settings. Recently, scalable methods have been developed that address this task by learning similarity metrics on top of the content of the products involved. Here our method relaxes the metricity assumption inherent in previous work and models multiple localized notions of \u2018relatedness,\u2019 so as to uncover ways in which related items should be systematically similar, and systematically different. Quantitatively, we show that our system achieves state-ofthe-art performance on large-scale compatibility prediction tasks, especially in cases where there is substantial heterogeneity between related items. Qualitatively, we demonstrate that richer notions of compatibility can be learned that go beyond similarity, and that our model can make effective recommendations of heterogeneous content. Keywords-Recommender Systems; Visual Compatibility; Metric Learning", "creator": "LaTeX with hyperref package"}}}