{"id": "1605.04553", "review": {"conference": "arxiv", "VERSION": "v1", "DATE_OF_SUBMISSION": "15-May-2016", "title": "A Proposal for Linguistic Similarity Datasets Based on Commonality Lists", "abstract": "similarity is a subjective core notion process that is used in empirical psychology, theoretical logic and computational linguistics. the similarity datasets considered that come from the two fields differ in discourse design : psychological survey datasets are focused merely around a certain topic, such as referencing fruit buds names ; linguistic datasets contain words from reflecting various functional categories. the task later makes certain humans assign low similarity numerical scores to complement the words stated that have nothing evident in immediate common preference and to designate the words that have contrast strengths in meaning, suggesting making similarity ranking scores seem ambiguous. in this work we generally discuss the similarity content collection procedure for a multi - type category reconciliation dataset that which avoids score assignment ambiguity and consistently suggest specific changes assigned to the same evaluation procedure to reflect beyond the insights of psychological clinical literature for improving word, phrase and sentence similarity. we often suggest us to often ask why humans to positively provide visually a generic list picture of commonalities and differences instead of assign numerical similarity identification scores and employ emphasizing the structure of human judgements beyond pairwise memory similarity. we believe that the proposed approach will give the rise initially to datasets showing that test meaning representation models more thoroughly matched with respect only to describing the human treatment of similarity.", "histories": [["v1", "Sun, 15 May 2016 14:00:06 GMT  (25kb)", "https://arxiv.org/abs/1605.04553v1", null], ["v2", "Fri, 17 Jun 2016 16:55:20 GMT  (21kb)", "http://arxiv.org/abs/1605.04553v2", null]], "reviews": [], "SUBJECTS": "cs.CL", "authors": ["dmitrijs milajevs", "sascha griffiths"], "accepted": false, "id": "1605.04553"}, "pdf": {"name": "1605.04553.pdf", "metadata": {"source": "CRF", "title": "A Proposal for Linguistic Similarity Datasets Based on Commonality Lists", "authors": ["Dmitrijs Milajevs"], "emails": ["d.milajevs@qmul.ac.uk", "s.griffiths@qmul.ac.uk"], "sections": [{"heading": null, "text": "ar X\niv :1\n60 5.\n04 55\n3v 2\n[ cs\n.C L\n] 1\n7 Ju\nn 20\nSimilarity is a core notion that is used in psychology and two branches of linguistics: theoretical and computational. The similarity datasets that come from the two fields differ in design: psychological datasets are focused around a certain topic such as fruit names, while linguistic datasets contain words from various categories. The later makes humans assign low similarity scores to the words that have nothing in common and to the words that have contrast in meaning, making similarity scores ambiguous. In this work we discuss the similarity collection procedure for a multi-category dataset that avoids score ambiguity and suggest changes to the evaluation procedure to reflect the insights of psychological literature for word, phrase and sentence similarity. We suggest to ask humans to provide a list of commonalities and differences instead of numerical similarity scores and employ the structure of human judgements beyond pairwise similarity for model evaluation. We believe that the proposed approach will give rise to datasets that test meaning representation models more thoroughly with respect to the human treatment of similarity."}, {"heading": "1 Introduction", "text": "Similarity is the degree of resemblance between two objects or events (Hahn, 2014) and plays a crucial role in psychological theories of knowledge and behaviour, where it is used to explain such phenomena as classification and conceptualisation. Fruit is a category because it is a practical generalisation. Fruits are sweet and constitute deserts, so when one is presented with an unknown\nfruit, one can hypothesise that it is served toward the end of a dinner.\nGeneralisations are extremely powerful in describing a language as well. The verb runs requires its subject to be singular. Verb, subject and singular are categories that are used to describe English grammar. When one encounters an unknown word and is told that it is a verb, one will immediately have an idea about how to use it assuming that it is used similarly to other English verbs.\nThe semantic formalisation of similarity is based on two ideas. The occurrence pattern of a word defines its meaning (Firth, 1957), while the difference in occurrence between two words quantifies the difference in their meaning (Harris, 1970). From a computational perspective, this motivates and guides development of similarity components that are embedded into natural language processing systems that deal with tasks such as word sense disambiguation (Schu\u0308tze, 1998), information retrieval (Salton et al., 1975; Milajevs et al., 2015), machine translation (Dagan et al., 1993), dependency parsing (Hermann and Blunsom, 2013; Andreas and Klein, 2014), and dialogue act tagging (Kalchbrenner and Blunsom, 2013; Milajevs and Purver, 2014).\nBecause it is difficult to measure performance of a single (similarity) component in a pipeline, datasets that focus on similarity are popular among computational linguists. Apart from a pragmatic attempt to alleviate the problems of evaluating similarity components, these datasets serve as an empirical test of the hypotheses of Firth and Harris, bringing together our understanding of human mind, language and technology.\nTwo datasets, namely MEN (Bruni et al., 2012) and SimLex-999 (Hill et al., 2015), are currently widely used. They are designed especially for meaning representation evaluation and surpass datasets stemming from psychology (Tversky and Hutchinson, 1986), information retrieval\n(Finkelstein et al., 2002) and computational linguistics (Rubenstein and Goodenough, 1965) in quantity by having more entries and, in case of SimLex-999, attention to the evaluated relation by distinguishing similarity from relatedness. The datasets provide similarity (relatedness) scores between word pairs.\nIn contrast to linguistic datasets which contain randomly paired words from a broad selection, datasets that come from psychology contain entries that belong to a single category such as verbs of judging (Fillenbaum and Rapoport, 1974) or animal terms (Henley, 1969). The reason for category oriented similarity studies is that \u201cstimuli can only be compared in so far as they have already been categorised as identical, alike, or equivalent at some higher level of abstraction\u201d (Turner et al., 1987). Moreover, because of the extension effect (Medin et al., 1993), the similarity of two entries in a context is less than the similarity between the same entries when the context is extended. \u201cFor example, black and white received a similarity rating of 2.2 when presented by themselves; this rating increased to 4.0 when black was simultaneously compared with white and red (red only increased 4.2 to 4.9)\u201d (Medin et al., 1993). In the first case black and white are more dissimilar because they are located on the extremes of the greyscale, but in the presence of red they become more similar because they are both monochromes.\nBoth MEN and SimLex-999 provide pairs that do not share any similarity to control for false positives, and they do not control for the comparison scale. This makes similarity judgements ambiguous as it is not clear what low similarity values mean: incomparable notions, contrast in meaning or even the difference in comparison context. SimLex-999 assigns low similarity scores to the incomparable pairs (0.48, trick and size) and to antonymy (0.55, smart and dumb), but smart and dumb have relatively much more in common than trick and size!\nThe present contribution investigates how a similarity dataset with multiple categories should be built and considers what sentence similarity means in this context."}, {"heading": "2 Dataset Construction", "text": "Human similarity judgements To build a similarity dataset that contains non-overlapping categories, one needs to avoid comparison of incomparable pairs. However, that itself requires an a priori knowledge of item similarity or belongingness to a category, making the problem circular.\nTo get out of this vicious circle, one might erroneously refer to an already existing taxonomy such as WordNet (Miller, 1995). But in case of similarity, as Turney (2012) points out, categories that emerge from similarity judgements are different from taxonomies. For example, traffic and water might be considered to be similar because of a functional similarity exploited in hydrodynamic models of traffic, but their lowest common ancestor in WordNet is entity.\nSince there is no way of deciding upfront whether there is a similarity relation between two words, the data collection procedure needs to test for both: relation existence and its strength. Numerical values, as has been shown in the introduction, do not fit this role due to ambiguity. One way to avoid the issue is to avoid asking humans for numerical similarity judgements, but instead to ask them to list commonalities and differences between the objects. As one might expect, similarity scores correlate with the number of listed commonalities (Markman and Gentner, 1991; Markman and Gentner, 1996; Medin et al., 1993). For incomparable pairs, the commonality list should be empty, but the differences will enumerate properties that belong to one entity, but not to another (Markman and Gentner, 1991; Medin et al., 1993).\nVerbally produced features (norms) for empirically derived conceptual representation of McRae et al. (2005) is a good example of what and how the data should be collected. But in contrast to McRae et al. (2005)\u2014where explicit comparison of concepts was avoided\u2014participants should be asked to produce commonalities as part of similarity comparison.\nThe entries in the dataset So far, we have proposed a similarity judgement collection method that is robust to incomparable pairings. It also naturally gives rise to categories, because the absence of a relation between two entries means the absence of a common category. It still needs to be decided which words to include in the dataset.\nTo get a list of words that constitute the dataset, one might think of categories such as sports, fruits, vegetables, judging verbs, countries, colours and so on. Note, that at this point its acceptable to think of categories, because later the arbitrary category assignments will be reevaluated. Once the list of categories is ready, each of them is populated with category instances, e.g. plum, banana and lemon are all fruits.\nWhen the data is prepared, humans are asked to provide commonalities and differences between all pairs of every group. First, all expected sim-\nilarities are judged, producing a dataset that can be seen as a merged version of category specific datasets. At this point, a good similarity model should provide meaning representation that are easily split to clusters: fruit members and sport members have to be separable.\nIntra-category comparisons should be also performed, but because it is impractical to collect all possible pairwise judgements between the number of words of magnitude of hundreds, a reasonable sample should be taken. The intra-category comparisons will lead to unexpected category pairings, such as food that contains vegetables and fruits, so the sampling procedure might be directed by the discovery of comparable pairs: when a banana and potato are said to be similar, fruits and vegetables members should be more likely to be assessed.\nGiven the dynamic nature of score collection, we suggest setting up a game with a purpose (see Venhuizen et al. (2013) an example) where players are rewarded for contributing their commonality lists. Another option would be to crowdsource the human judgements (Keuleers and Balota, 2015).\nEvaluation beyond proximity Human judgements validate the initial category assignment of items and provide new ones. If a category contains a superordinate, similarity judgements arrange category members around it (Tversky and Hutchinson, 1986). For example, similarity judgements given by humans arrange fruit names around the word fruit in such a way that it is their nearest neighbour, making fruit the focal point of the category of fruits.\nAs an additional evaluation method, the model should be able to retrieve focal points. Therefore, a precaution should be taken before human judgement collection. If possible, categories should contain a superordinate.\nSimilarity evaluation needs to focus on how well a model is able to recover human similarity intuitions expressed as groupings, possibly around their focal points. We propose to treat it as a soft multi-class clustering problem (White et al., 2015), where two entities belong to the same class if there is a similarity judgement for them (e.g. apple and banana are similar because they are fruits) and the strength is proportional to the number of such judgements, so we could express that apple is more a fruit than it is a company.\nIn contrast to the current evaluation based on correlation, models also need to be tested on the geometric arrangement of subordinates around the focal points, as only the proximity based evalua-\ntion does not capture this (Tversky and Hutchinson, 1986)."}, {"heading": "3 Sentence Similarity", "text": "The question of sentence similarity is more complex because sentences in many ways are different entities than words. Or are they? Linguistics has recently often pointed toward a continuum which exists between words and sentences (Jackendoff, 2012). Jackendoff and Pinker (2005), for example, point out that there is good evidence that \u201chuman memory must store linguistic expressions of all sizes.\u201d These linguistic expressions of variable size are often called constructions. Several computational approaches to constructions have been proposed (Gaspers et al., 2011; Chang et al., 2012), but to the authors\u2019 best knowledge they do not yet feature prominently in natural language processing.\nTo be able to measure the similarity of phrases and sentences in the proposed framework, we need to be able to identify what could serve as commonalities between them. So what are they? First of all, words, sentences and other constructions draw attention to states of affairs around us. Also, sentences are similar to others with respect to the functions they perform (Winograd, 1983, p. 288).\nPrototype effects As Tomasello (2009) points out, speakers of English can make sense of phrases like X floosed Y the Z and X was floosed by Y. This is due to their similarity to sentences such as John gave Mary the book and Mary was kissed by John respectively. Thus, X floosed Y the Z is clearly a transfer of possession or dative (Bresnan et al., 2007).\nThe amount in which sentences are similar, at least to a certain extent, corresponds to the function of a given sentence (the ideational function (Winograd, 1983, p. 288) especially). Tomasello (1998) points out that sentence-level constructions show prototype effects similar to those discussed above for lexical systems (e.g. colours). Consider the following sentences:\n\u2022 John gave Mary the book. is a example of an Agent Causes Transfer construction. These usually are build around words such as give, pass, hand, toss, bring, etc. \u2022 John promised Mary the book. is a example of an Conditional transfer construction. These usually are build around words such as promise, guarantee, owe, etc.\nAs soon as one has such a prototype network, one can actually decide sentence similarity as one\ncan say with respect to what prototypes sentences and utterances are similar. In this case, a common sentence prototype serves the same role as commonality between words.\nSimilarity in context However, prototype categories work on the semantic-grammatical level, and might be handled by similarity in context: a noun phrase can be similar to a noun as in female lion and lioness, and to another noun phrases as in yellow car and cheap taxi. The same similarity principle can be applied to phrases as to words. In this case, similarity is measured in context, but it is still a comparison of the phrases\u2019 head words of which meaning is modified by arguments they appear with (Kintsch, 2001; Mitchell and Lapata, 2008; Mitchell and Lapata, 2010; Dinu and Lapata, 2010; Baroni and Zamparelli, 2010; Thater et al., 2011; Se\u0301aghdha and Korhonen, 2011). With verbs this idea can be applied to compare transitive verbs with intransitive. For example, to cycle is similar to to ride a bicycle.\nSentential similarity might be treated as the similarity of the heads in the contexts. That is, the similarity between sees and notices in John sees Mary and John notices a woman. This approach abstracts away from grammatical differences between the sentences and concentrates on semantics and fits the proposed model as the respect for the head, which is a lexical entity, has to be found (Corbett and Fraser, 1993).\nAttention attraction But still, what about pragmatics? As Steels (2008) points out, sentences and words direct attention and do not always directly point or refer to entities and actions in the world. For example, he points to the fact that if a person asks another person to pass the wine they are actually asking for the bottle. The speaker just attracts attention to an object of perception in a given situation.\nGrammaticalisaton and lexicalisaton There are several ways in which a sentence can both be grammaticalised and lexicalised. For example, No and I\u2019ve seen John eating them are similar sentences because they lexicalise the same answer to the question Do we have cookies? More generally, this gives rise to dialogue act tags: for another way of utterance categorisation, refer to the work of Kalchbrenner and Blunsom (2013) and Milajevs and Purver (2014).\nThus, questions which the sentences answer, are valid respects for similarity explanation, as well as entailment, paraphrase (White et al., 2015) or spatial categories (Ritter et al., 2015). This also mo-\ntivates the approach of treating sentences on their own and encoding the meaning of a sentence into a vector in such a way that similar sentences are clustered together (Coecke et al., 2010; Baroni et al., 2014; Socher et al., 2012; Wieting et al., 2015; Hill et al., 2016).\nDiscourse fit If one conceptualises sentence similarity with respect to a discourse, then one might ask how different sentences fit in to such a discourse. Griffiths et al. (2015) tried to construct two versions of the same dialogue using a bottomup method. They deconstructed a certain dialogue in a given domain\u2014a receptionist scenario\u2014into greetings, directions and farewells. They used a small custom made corpus for this purpose and created the two dialogues by having people rate the individual utterances by friendliness. The resulting two dialogues were surprisingly uneven. The dialogue was supposed to give instructions to a certain location within a building. The \u201cfriendly version\u201d was very elaborated and consisted of several sentences:\n(1) The questionnaire is located in room Q2-102. That is on the second floor. If you turn to your right and walk down the hallway. At the end of the floor you will find the stairs. Just walk up the stairs to the top floor and go through the fire door. The room is then straight ahead.\nThe sentence which served the same purpose in the \u201cneutral version\u201d was a fairly simple sentence:\n(2) The questionnaire is located in Q2-102.\nOften the same function of a given sentence in a dialogue can be performed by as little as one word or several phrases or a different sentence or even a complete story.\nLanguage sub-systems and strategies Steels (2010) introduces the idea of language subsystems and language strategies. A language subsystem are the means of expressing certain related or similar meanings. Examples of such subsystems include:\n\u2022 Lexical systems which express colours. \u2022 Morphological devices to encode tenses. \u2022 Usage of word order to express relations be-\ntween agent and patient. The later is an illustration of a language strategy. In English agent-patient relations are mainly encoded by syntax whereas German would use intonation and a combination or articles and case to convey the same information. Russian, in contrast,\nwill use morphological devices for the same purpose. Hence, for some purposes the entities which are similar may not be of clearly delineated categories such as \u201cword\u201d or \u201csentence\u201d but may be of chunks of language which belong to the same sub-system.\nAbove we identified seven criteria by which sentence similarity can be compared. The instructions for the sentence similarity judgement tasks may incorporate the criteria as hints for human participants during data collection."}, {"heading": "4 Conclusion", "text": "In this contribution we discussed the notion of similarity from an interdisciplinary perspective. We contrasted properties of the similarity relation described in the field of psychology with the characteristics of similarity datasets used in computational linguistics. This lead to the recommendations on how to improve the later by removing low score ambiguity in a multi-category similarity dataset.\nIn the future, a multi-category similarity dataset should be build that allow evaluation of vector space models of meaning by not only measuring proximity between the points, but also their arrangement with respect to clusters. The same ideas can be used to build phrase- and sentencelevel datasets. However, we leave the exact sentence similarity criteria selection for future work in this area.\nOn a broader perspective, this work highlights psychological phenomena that being incorporated into the models of meaning are expected to improve their performance."}, {"heading": "Acknowledgements", "text": "We thank the anonymous reviewers for their comments. Support from EPSRC grant EP/J002607/1 is gratefully acknowledged by Dmitrijs Milajevs. Sascha Griffiths is supported by ConCreTe: the project ConCreTe acknowledges the financial support of the Future and Emerging Technologies (FET) programme within the Seventh Framework Programme for Research of the European Commission, under FET grant number 611733."}], "references": [{"title": "How much do word embeddings encode about syntax? In Proceedings of the 52nd Annual Meeting of the Association for Computational Linguistics (Volume", "author": ["Jacob Andreas", "Dan Klein"], "venue": null, "citeRegEx": "Andreas and Klein.,? \\Q2014\\E", "shortCiteRegEx": "Andreas and Klein.", "year": 2014}, {"title": "Nouns are vectors, adjectives are matrices: Representing adjective-noun constructions in semantic space", "author": ["Marco Baroni", "Roberto Zamparelli."], "venue": "Proceedings of the 2010 Conference on Empirical Methods in Natural Language Processing, EMNLP", "citeRegEx": "Baroni and Zamparelli.,? 2010", "shortCiteRegEx": "Baroni and Zamparelli.", "year": 2010}, {"title": "Frege in space: A program of compositional distributional semantics", "author": ["Marco Baroni", "Raffaela Bernardi", "Roberto Zamparelli."], "venue": "LiLT (Linguistic Issues in Language Technology), 9.", "citeRegEx": "Baroni et al\\.,? 2014", "shortCiteRegEx": "Baroni et al\\.", "year": 2014}, {"title": "Predicting the dative alternation", "author": ["Joan Bresnan", "Anna Cueni", "Tatiana Nikitina", "R Harald Baayen."], "venue": "pages 69\u201394. Royal Netherlands Academy of Arts and Sciences, Amsterdam.", "citeRegEx": "Bresnan et al\\.,? 2007", "shortCiteRegEx": "Bresnan et al\\.", "year": 2007}, {"title": "Distributional semantics in technicolor", "author": ["Elia Bruni", "Gemma Boleda", "Marco Baroni", "NamKhanh Tran."], "venue": "Proceedings of the 50th Annual Meeting of the Association for Computational Linguistics: Long Papers - Volume 1, ACL \u201912, pages 136\u2013", "citeRegEx": "Bruni et al\\.,? 2012", "shortCiteRegEx": "Bruni et al\\.", "year": 2012}, {"title": "Computational Construction Grammar: Comparing ECG and FCG", "author": ["Nancy C Chang", "Joachim De Beule", "Vanessa Micelli."], "venue": "Luc Steels, editor, Computational Issues in Fluid Construction Grammar, pages 259\u2013288. Springer Verlag, Berlin.", "citeRegEx": "Chang et al\\.,? 2012", "shortCiteRegEx": "Chang et al\\.", "year": 2012}, {"title": "Mathematical foundations for a compositional distributional model of meaning", "author": ["Bob Coecke", "Mehrnoosh Sadrzadeh", "Stephen Clark."], "venue": "CoRR, abs/1003.4394.", "citeRegEx": "Coecke et al\\.,? 2010", "shortCiteRegEx": "Coecke et al\\.", "year": 2010}, {"title": "Heads in grammatical theory", "author": ["Greville G Corbett", "Norman M Fraser."], "venue": "Cambridge University Press.", "citeRegEx": "Corbett and Fraser.,? 1993", "shortCiteRegEx": "Corbett and Fraser.", "year": 1993}, {"title": "Contextual word similarity and estimation from sparse data", "author": ["Ido Dagan", "Shaul Marcus", "Shaul Markovitch."], "venue": "Proceedings of the 31st Annual Meeting on Association for Computational Linguistics, ACL \u201993, pages 164\u2013171, Stroudsburg, PA,", "citeRegEx": "Dagan et al\\.,? 1993", "shortCiteRegEx": "Dagan et al\\.", "year": 1993}, {"title": "Measuring distributional similarity in context", "author": ["Georgiana Dinu", "Mirella Lapata."], "venue": "Proceedings of the 2010 Conference on Empirical Methods in Natural Language Processing, EMNLP \u201910, pages 1162\u20131172, Stroudsburg, PA, USA. Association for", "citeRegEx": "Dinu and Lapata.,? 2010", "shortCiteRegEx": "Dinu and Lapata.", "year": 2010}, {"title": "Verbs of judging, judged: A case study", "author": ["Samuel Fillenbaum", "Amnon Rapoport."], "venue": "Journal of Verbal Learning and Verbal Behavior, 13(1):54 \u2013 62.", "citeRegEx": "Fillenbaum and Rapoport.,? 1974", "shortCiteRegEx": "Fillenbaum and Rapoport.", "year": 1974}, {"title": "Placing search in context: The concept revisited", "author": ["Lev Finkelstein", "Evgeniy Gabrilovich", "Yossi Matias", "Ehud Rivlin", "Zach Solan", "Gadi Wolfman", "Eytan Ruppin."], "venue": "ACM Trans. Inf. Syst., 20(1):116\u2013 131, January.", "citeRegEx": "Finkelstein et al\\.,? 2002", "shortCiteRegEx": "Finkelstein et al\\.", "year": 2002}, {"title": "A Synopsis of Linguistic Theory, 1930-1955", "author": ["John R. Firth."], "venue": "Studies in Linguistic Analysis, pages 1\u2013", "citeRegEx": "Firth.,? 1957", "shortCiteRegEx": "Firth.", "year": 1957}, {"title": "An unsupervised algorithm for the induction of constructions", "author": ["Judith Gaspers", "Philipp Cimiano", "Sascha S Griffiths", "Britta Wrede."], "venue": "2011 IEEE International Conference on Development and Learning (ICDL), pages 1\u20136. IEEE, August.", "citeRegEx": "Gaspers et al\\.,? 2011", "shortCiteRegEx": "Gaspers et al\\.", "year": 2011}, {"title": "Perception of Artificial Agents and Utterance Friendliness in Dialogue", "author": ["Sascha Griffiths", "Friederike Eyssel", "Anja Philippsen", "Christian Pietsch", "Sven Wachsmuth."], "venue": "Maha Salem, Astrid Weiss, Paul Baxter, and Kerstin Dautenhahn, editors, Pro-", "citeRegEx": "Griffiths et al\\.,? 2015", "shortCiteRegEx": "Griffiths et al\\.", "year": 2015}, {"title": "Similarity", "author": ["Ulrike Hahn."], "venue": "Wiley Interdisciplinary Reviews: Cognitive Science, 5(3):271\u2013280.", "citeRegEx": "Hahn.,? 2014", "shortCiteRegEx": "Hahn.", "year": 2014}, {"title": "Papers in Structural and Transformational Linguistics, chapter Distributional Structure, pages 775\u2013794", "author": ["Zellig S. Harris"], "venue": null, "citeRegEx": "Harris,? \\Q1970\\E", "shortCiteRegEx": "Harris", "year": 1970}, {"title": "A psychological study of the semantics of animal terms", "author": ["Nancy M. Henley."], "venue": "Journal of Verbal Learning and Verbal Behavior, 8(2):176 \u2013 184.", "citeRegEx": "Henley.,? 1969", "shortCiteRegEx": "Henley.", "year": 1969}, {"title": "The role of syntax in vector space models of compositional semantics", "author": ["Karl Moritz Hermann", "Phil Blunsom."], "venue": "Proceedings of the 51st Annual Meeting of the Association for Computational Linguistics (Volume 1: Long Papers), pages 894\u2013904,", "citeRegEx": "Hermann and Blunsom.,? 2013", "shortCiteRegEx": "Hermann and Blunsom.", "year": 2013}, {"title": "Simlex-999: Evaluating semantic models with genuine similarity estimation", "author": ["Felix Hill", "Roi Reichart", "Anna Korhonen."], "venue": "Comput. Linguist., 41(4):665\u2013695, December.", "citeRegEx": "Hill et al\\.,? 2015", "shortCiteRegEx": "Hill et al\\.", "year": 2015}, {"title": "Learning distributed representations of sentences from unlabelled data", "author": ["Felix Hill", "Kyunghyun Cho", "Anna Korhonen."], "venue": "CoRR, abs/1602.03483.", "citeRegEx": "Hill et al\\.,? 2016", "shortCiteRegEx": "Hill et al\\.", "year": 2016}, {"title": "The nature of the language faculty and its implications for evolution of language (Reply to Fitch, Hauser, and Chomsky)", "author": ["Ray Jackendoff", "Steven Pinker."], "venue": "Cognition, 97(2):211\u2013225.", "citeRegEx": "Jackendoff and Pinker.,? 2005", "shortCiteRegEx": "Jackendoff and Pinker.", "year": 2005}, {"title": "Language", "author": ["Ray Jackendoff."], "venue": "Keith Frankish and William Ramsey, editors, The Cambridge Handbook of Cognitive Science. Cambridge University Press, Cambridge, MA.", "citeRegEx": "Jackendoff.,? 2012", "shortCiteRegEx": "Jackendoff.", "year": 2012}, {"title": "Recurrent convolutional neural networks for discourse compositionality", "author": ["Nal Kalchbrenner", "Phil Blunsom."], "venue": "Proceedings of the Workshop on Continuous Vector Space Models and their Compositionality, pages 119\u2013126, Sofia, Bulgaria, August. Asso-", "citeRegEx": "Kalchbrenner and Blunsom.,? 2013", "shortCiteRegEx": "Kalchbrenner and Blunsom.", "year": 2013}, {"title": "Megastudies, crowdsourcing, and large datasets in psycholinguistics: An overview of recent developments", "author": ["Emmanuel Keuleers", "David A. Balota."], "venue": "The Quarterly Journal of Experimental Psychology, 68(8):1457\u20131468. PMID: 25975773.", "citeRegEx": "Keuleers and Balota.,? 2015", "shortCiteRegEx": "Keuleers and Balota.", "year": 2015}, {"title": "Predication", "author": ["Walter Kintsch."], "venue": "Cognitive Science, 25(2):173 \u2013 202.", "citeRegEx": "Kintsch.,? 2001", "shortCiteRegEx": "Kintsch.", "year": 2001}, {"title": "Commonalities, differences and the alignment of conceptual frames during similarity judgments", "author": ["Arthur B. Markman", "Dedre Gentner."], "venue": "Proceedings of the 13th Annual Meeting of the Cognitive Science Society, USA, pages 287\u2013292.", "citeRegEx": "Markman and Gentner.,? 1991", "shortCiteRegEx": "Markman and Gentner.", "year": 1991}, {"title": "Commonalities and differences in similarity comparisons", "author": ["Arthur B. Markman", "Dedre Gentner."], "venue": "Memory & Cognition, 24(2):235\u2013249.", "citeRegEx": "Markman and Gentner.,? 1996", "shortCiteRegEx": "Markman and Gentner.", "year": 1996}, {"title": "Semantic feature production norms for a large set of living and nonliving things", "author": ["Ken McRae", "George S. Cree", "Mark S. Seidenberg", "Chris McNorgan."], "venue": "Behavior Research Methods, 37(4):547\u2013 559.", "citeRegEx": "McRae et al\\.,? 2005", "shortCiteRegEx": "McRae et al\\.", "year": 2005}, {"title": "Respects for similarity", "author": ["Douglas L Medin", "Robert L Goldstone", "Dedre Gentner."], "venue": "Psychological review, 100(2):254.", "citeRegEx": "Medin et al\\.,? 1993", "shortCiteRegEx": "Medin et al\\.", "year": 1993}, {"title": "Investigating the contribution of distributional semantic information for dialogue act classification", "author": ["Dmitrijs Milajevs", "Matthew Purver."], "venue": "Proceedings of the 2nd Workshop on Continuous Vector Space Models and their Compositionality (CVSC),", "citeRegEx": "Milajevs and Purver.,? 2014", "shortCiteRegEx": "Milajevs and Purver.", "year": 2014}, {"title": "IR Meets NLP: On the Semantic Similarity Between Subject-Verb-Object Phrases", "author": ["Dmitrijs Milajevs", "Mehrnoosh Sadrzadeh", "Thomas Roelleke."], "venue": "Proceedings of the 2015 International Conference on Theory of Information Retrieval, ICTIR \u201915,", "citeRegEx": "Milajevs et al\\.,? 2015", "shortCiteRegEx": "Milajevs et al\\.", "year": 2015}, {"title": "Wordnet: A lexical database for english", "author": ["George A. Miller."], "venue": "Commun. ACM, 38(11):39\u201341, November.", "citeRegEx": "Miller.,? 1995", "shortCiteRegEx": "Miller.", "year": 1995}, {"title": "Vector-based models of semantic composition", "author": ["Jeff Mitchell", "Mirella Lapata."], "venue": "Proceedings of ACL-08: HLT, pages 236\u2013244, Columbus, Ohio, June. Association for Computational Linguistics.", "citeRegEx": "Mitchell and Lapata.,? 2008", "shortCiteRegEx": "Mitchell and Lapata.", "year": 2008}, {"title": "Composition in distributional models of semantics", "author": ["Jeff Mitchell", "Mirella Lapata."], "venue": "Cognitive Science, 34(8):1388\u20131429.", "citeRegEx": "Mitchell and Lapata.,? 2010", "shortCiteRegEx": "Mitchell and Lapata.", "year": 2010}, {"title": "Leveraging preposition ambiguity to assess compositional distributional models of semantics", "author": ["Samuel Ritter", "Cotie Long", "Denis Paperno", "Marco Baroni", "Matthew Botvinick", "Adele Goldberg."], "venue": "Proceedings of the Fourth Joint Conference on", "citeRegEx": "Ritter et al\\.,? 2015", "shortCiteRegEx": "Ritter et al\\.", "year": 2015}, {"title": "Contextual correlates of synonymy", "author": ["Herbert Rubenstein", "John B. Goodenough."], "venue": "Commun. ACM, 8(10):627\u2013633, October.", "citeRegEx": "Rubenstein and Goodenough.,? 1965", "shortCiteRegEx": "Rubenstein and Goodenough.", "year": 1965}, {"title": "A vector space model for automatic indexing", "author": ["G. Salton", "A. Wong", "C.S. Yang."], "venue": "Commun. ACM, 18(11):613\u2013620, November.", "citeRegEx": "Salton et al\\.,? 1975", "shortCiteRegEx": "Salton et al\\.", "year": 1975}, {"title": "Automatic word sense discrimination", "author": ["Hinrich Sch\u00fctze."], "venue": "Comput. Linguist., 24(1):97\u2013123, March.", "citeRegEx": "Sch\u00fctze.,? 1998", "shortCiteRegEx": "Sch\u00fctze.", "year": 1998}, {"title": "Probabilistic models of similarity in syntactic context", "author": ["Diarmuid \u00d3 S\u00e9aghdha", "Anna Korhonen."], "venue": "Proceedings of the Conference on Empirical Methods in Natural Language Processing, EMNLP \u201911, pages 1047\u20131057, Stroudsburg, PA, USA. As-", "citeRegEx": "S\u00e9aghdha and Korhonen.,? 2011", "shortCiteRegEx": "S\u00e9aghdha and Korhonen.", "year": 2011}, {"title": "Semantic compositionality through recursive matrix-vector spaces", "author": ["Richard Socher", "Brody Huval", "Christopher D. Manning", "Andrew Y. Ng."], "venue": "Proceedings of the 2012 Joint Conference on Empirical Methods in Natural Language Process-", "citeRegEx": "Socher et al\\.,? 2012", "shortCiteRegEx": "Socher et al\\.", "year": 2012}, {"title": "The symbol grounding problem has been solved, so what\u2019s next? In Manuel de Vega, Arthur M Glenberg, and Arthur C Graesser, editors, Symbols and Embodiment: Debates on Meaning and Cognition, pages 223\u2013244", "author": ["Luc Steels."], "venue": "Oxford University Press,", "citeRegEx": "Steels.,? 2008", "shortCiteRegEx": "Steels.", "year": 2008}, {"title": "Can Evolutionary Linguistics Become a Science", "author": ["Luc Steels"], "venue": "Journal for Evolutionary Linguistics,", "citeRegEx": "Steels.,? \\Q2010\\E", "shortCiteRegEx": "Steels.", "year": 2010}, {"title": "Word meaning in context: A simple and effective vector model", "author": ["Stefan Thater", "Hagen F\u00fcrstenau", "Manfred Pinkal."], "venue": "Proceedings of 5th International Joint Conference on Natural Language Processing, pages 1134\u20131143, Chiang Mai, Thailand,", "citeRegEx": "Thater et al\\.,? 2011", "shortCiteRegEx": "Thater et al\\.", "year": 2011}, {"title": "The return of constructions", "author": ["Michael Tomasello."], "venue": "Journal of Child Language, 25(02):431\u2013442.", "citeRegEx": "Tomasello.,? 1998", "shortCiteRegEx": "Tomasello.", "year": 1998}, {"title": "The cultural origins of human cognition", "author": ["Michael Tomasello."], "venue": "Harvard University Press, Cambridge, MA.", "citeRegEx": "Tomasello.,? 2009", "shortCiteRegEx": "Tomasello.", "year": 2009}, {"title": "Rediscovering the social group: A selfcategorization theory", "author": ["John C Turner", "Michael A Hogg", "Penelope J Oakes", "Stephen D Reicher", "Margaret S Wetherell."], "venue": "Basil Blackwell.", "citeRegEx": "Turner et al\\.,? 1987", "shortCiteRegEx": "Turner et al\\.", "year": 1987}, {"title": "Domain and function: A dual-space model of semantic relations and compositions", "author": ["Peter D Turney."], "venue": "Journal of Artificial Intelligence Research, pages 533\u2013585. Amos Tversky and J. Wesley Hutchinson. 1986. Near-", "citeRegEx": "Turney.,? 2012", "shortCiteRegEx": "Turney.", "year": 2012}, {"title": "Gamification for word sense labeling", "author": ["Noortje Venhuizen", "Valerio Basile", "Kilian Evang", "Johan Bos."], "venue": "Proceedings of the 10th International Conference on Computational Semantics (IWCS 2013) \u2013 Short Papers, pages 397\u2013403, Potsdam,", "citeRegEx": "Venhuizen et al\\.,? 2013", "shortCiteRegEx": "Venhuizen et al\\.", "year": 2013}, {"title": "How well sentence embeddings capture meaning", "author": ["Lyndon White", "Roberto Togneri", "Wei Liu", "Mohammed Bennamoun."], "venue": "Proceedings of the 20th Australasian Document Computing Symposium, ADCS \u201915, pages 9:1\u20139:8, New York, NY,", "citeRegEx": "White et al\\.,? 2015", "shortCiteRegEx": "White et al\\.", "year": 2015}, {"title": "From paraphrase database to compositional paraphrase model and back", "author": ["John Wieting", "Mohit Bansal", "Kevin Gimpel", "Karen Livescu."], "venue": "arXiv preprint arXiv:1506.03487.", "citeRegEx": "Wieting et al\\.,? 2015", "shortCiteRegEx": "Wieting et al\\.", "year": 2015}, {"title": "Language as a cognitive process (Vol", "author": ["Terry Winograd."], "venue": "1): Syntax. Addison-Wesley, Reading, MA.", "citeRegEx": "Winograd.,? 1983", "shortCiteRegEx": "Winograd.", "year": 1983}], "referenceMentions": [{"referenceID": 15, "context": "Similarity is the degree of resemblance between two objects or events (Hahn, 2014) and plays a crucial role in psychological theories of knowledge and behaviour, where it is used to explain such phenomena as classification and conceptual-", "startOffset": 70, "endOffset": 82}, {"referenceID": 12, "context": "The occurrence pattern of a word defines its meaning (Firth, 1957), while", "startOffset": 53, "endOffset": 66}, {"referenceID": 16, "context": "the difference in occurrence between two words quantifies the difference in their meaning (Harris, 1970).", "startOffset": 90, "endOffset": 104}, {"referenceID": 38, "context": "From a computational perspective, this motivates and guides development of similarity components that are embedded into natural language processing systems that deal with tasks such as word sense disambiguation (Sch\u00fctze, 1998), in-", "startOffset": 211, "endOffset": 226}, {"referenceID": 37, "context": "formation retrieval (Salton et al., 1975; Milajevs et al., 2015), machine translation (Dagan et al.", "startOffset": 20, "endOffset": 64}, {"referenceID": 31, "context": "formation retrieval (Salton et al., 1975; Milajevs et al., 2015), machine translation (Dagan et al.", "startOffset": 20, "endOffset": 64}, {"referenceID": 8, "context": ", 2015), machine translation (Dagan et al., 1993), dependency parsing (Hermann and Blunsom, 2013; Andreas and Klein, 2014), and di-", "startOffset": 29, "endOffset": 49}, {"referenceID": 18, "context": ", 1993), dependency parsing (Hermann and Blunsom, 2013; Andreas and Klein, 2014), and di-", "startOffset": 28, "endOffset": 80}, {"referenceID": 0, "context": ", 1993), dependency parsing (Hermann and Blunsom, 2013; Andreas and Klein, 2014), and di-", "startOffset": 28, "endOffset": 80}, {"referenceID": 23, "context": "alogue act tagging (Kalchbrenner and Blunsom, 2013; Milajevs and Purver, 2014).", "startOffset": 19, "endOffset": 78}, {"referenceID": 30, "context": "alogue act tagging (Kalchbrenner and Blunsom, 2013; Milajevs and Purver, 2014).", "startOffset": 19, "endOffset": 78}, {"referenceID": 4, "context": "Two datasets, namely MEN (Bruni et al., 2012) and SimLex-999 (Hill et al.", "startOffset": 25, "endOffset": 45}, {"referenceID": 19, "context": ", 2012) and SimLex-999 (Hill et al., 2015), are currently widely used.", "startOffset": 23, "endOffset": 42}, {"referenceID": 11, "context": "(Finkelstein et al., 2002) and computational linguistics (Rubenstein and Goodenough, 1965) in quantity by having more entries and, in case of SimLex-999, attention to the evaluated relation by distinguishing similarity from relatedness.", "startOffset": 0, "endOffset": 26}, {"referenceID": 36, "context": ", 2002) and computational linguistics (Rubenstein and Goodenough, 1965) in quantity by having more entries and, in case of SimLex-999, attention to the evaluated relation by distinguishing similarity from relatedness.", "startOffset": 38, "endOffset": 71}, {"referenceID": 10, "context": "tries that belong to a single category such as verbs of judging (Fillenbaum and Rapoport, 1974) or animal terms (Henley, 1969).", "startOffset": 64, "endOffset": 95}, {"referenceID": 17, "context": "tries that belong to a single category such as verbs of judging (Fillenbaum and Rapoport, 1974) or animal terms (Henley, 1969).", "startOffset": 112, "endOffset": 126}, {"referenceID": 46, "context": "only be compared in so far as they have already been categorised as identical, alike, or equivalent at some higher level of abstraction\u201d (Turner et al., 1987).", "startOffset": 137, "endOffset": 158}, {"referenceID": 29, "context": "Moreover, because of the extension effect (Medin et al., 1993), the similarity of two entries in a context is less than the similarity between the same entries when the context is extended.", "startOffset": 42, "endOffset": 62}, {"referenceID": 29, "context": "9)\u201d (Medin et al., 1993).", "startOffset": 4, "endOffset": 24}, {"referenceID": 32, "context": "To get out of this vicious circle, one might erroneously refer to an already existing taxonomy such as WordNet (Miller, 1995).", "startOffset": 111, "endOffset": 125}, {"referenceID": 32, "context": "To get out of this vicious circle, one might erroneously refer to an already existing taxonomy such as WordNet (Miller, 1995). But in case of similarity, as Turney (2012) points out, categories that emerge from similarity judgements are different from taxonomies.", "startOffset": 112, "endOffset": 171}, {"referenceID": 26, "context": "(Markman and Gentner, 1991; Medin et al., 1993).", "startOffset": 0, "endOffset": 47}, {"referenceID": 29, "context": "(Markman and Gentner, 1991; Medin et al., 1993).", "startOffset": 0, "endOffset": 47}, {"referenceID": 26, "context": "(Markman and Gentner, 1991; Medin et al., 1993). Verbally produced features (norms) for empirically derived conceptual representation of McRae et al. (2005) is a good example of what and how", "startOffset": 1, "endOffset": 157}, {"referenceID": 28, "context": "But in contrast to McRae et al. (2005)\u2014where explicit comparison of concepts was avoided\u2014participants should be asked to produce commonalities as part of similarity comparison.", "startOffset": 19, "endOffset": 39}, {"referenceID": 48, "context": "Given the dynamic nature of score collection, we suggest setting up a game with a purpose (see Venhuizen et al. (2013) an example) where players are rewarded for contributing their commonality", "startOffset": 95, "endOffset": 119}, {"referenceID": 24, "context": "Another option would be to crowdsource the human judgements (Keuleers and Balota, 2015).", "startOffset": 60, "endOffset": 87}, {"referenceID": 49, "context": "We propose to treat it as a soft multi-class clustering problem (White et al., 2015), where two entities belong to the same class if there is a similarity judgement for them (e.", "startOffset": 64, "endOffset": 84}, {"referenceID": 22, "context": "recently often pointed toward a continuum which exists between words and sentences (Jackendoff, 2012).", "startOffset": 83, "endOffset": 101}, {"referenceID": 13, "context": "Several computational approaches to constructions have been proposed (Gaspers et al., 2011; Chang et al., 2012), but to the authors\u2019 best knowledge they do not yet feature prominently in natural language processing.", "startOffset": 69, "endOffset": 111}, {"referenceID": 5, "context": "Several computational approaches to constructions have been proposed (Gaspers et al., 2011; Chang et al., 2012), but to the authors\u2019 best knowledge they do not yet feature prominently in natural language processing.", "startOffset": 69, "endOffset": 111}, {"referenceID": 19, "context": "Jackendoff and Pinker (2005), for example, point out that there is good evidence that \u201chuman memory must store linguistic expressions of all sizes.", "startOffset": 0, "endOffset": 29}, {"referenceID": 44, "context": "Prototype effects As Tomasello (2009) points out, speakers of English can make sense of phrases like X floosed Y the Z and X was floosed by Y.", "startOffset": 21, "endOffset": 38}, {"referenceID": 3, "context": "Thus, X floosed Y the Z is clearly a transfer of possession or dative (Bresnan et al., 2007).", "startOffset": 70, "endOffset": 92}, {"referenceID": 44, "context": "Tomasello (1998) points out that sentence-level constructions show prototype effects similar to those discussed above for lexical systems (e.", "startOffset": 0, "endOffset": 17}, {"referenceID": 25, "context": "In this case, similarity is measured in context, but it is still a comparison of the phrases\u2019 head words of which meaning is modified by arguments they appear with (Kintsch, 2001; Mitchell and Lapata, 2008; Mitchell and Lapata, 2010; Dinu and Lapata, 2010; Baroni and Zamparelli, 2010; Thater et al., 2011; S\u00e9aghdha and Korhonen, 2011).", "startOffset": 164, "endOffset": 335}, {"referenceID": 33, "context": "In this case, similarity is measured in context, but it is still a comparison of the phrases\u2019 head words of which meaning is modified by arguments they appear with (Kintsch, 2001; Mitchell and Lapata, 2008; Mitchell and Lapata, 2010; Dinu and Lapata, 2010; Baroni and Zamparelli, 2010; Thater et al., 2011; S\u00e9aghdha and Korhonen, 2011).", "startOffset": 164, "endOffset": 335}, {"referenceID": 34, "context": "In this case, similarity is measured in context, but it is still a comparison of the phrases\u2019 head words of which meaning is modified by arguments they appear with (Kintsch, 2001; Mitchell and Lapata, 2008; Mitchell and Lapata, 2010; Dinu and Lapata, 2010; Baroni and Zamparelli, 2010; Thater et al., 2011; S\u00e9aghdha and Korhonen, 2011).", "startOffset": 164, "endOffset": 335}, {"referenceID": 9, "context": "In this case, similarity is measured in context, but it is still a comparison of the phrases\u2019 head words of which meaning is modified by arguments they appear with (Kintsch, 2001; Mitchell and Lapata, 2008; Mitchell and Lapata, 2010; Dinu and Lapata, 2010; Baroni and Zamparelli, 2010; Thater et al., 2011; S\u00e9aghdha and Korhonen, 2011).", "startOffset": 164, "endOffset": 335}, {"referenceID": 1, "context": "In this case, similarity is measured in context, but it is still a comparison of the phrases\u2019 head words of which meaning is modified by arguments they appear with (Kintsch, 2001; Mitchell and Lapata, 2008; Mitchell and Lapata, 2010; Dinu and Lapata, 2010; Baroni and Zamparelli, 2010; Thater et al., 2011; S\u00e9aghdha and Korhonen, 2011).", "startOffset": 164, "endOffset": 335}, {"referenceID": 43, "context": "In this case, similarity is measured in context, but it is still a comparison of the phrases\u2019 head words of which meaning is modified by arguments they appear with (Kintsch, 2001; Mitchell and Lapata, 2008; Mitchell and Lapata, 2010; Dinu and Lapata, 2010; Baroni and Zamparelli, 2010; Thater et al., 2011; S\u00e9aghdha and Korhonen, 2011).", "startOffset": 164, "endOffset": 335}, {"referenceID": 39, "context": "In this case, similarity is measured in context, but it is still a comparison of the phrases\u2019 head words of which meaning is modified by arguments they appear with (Kintsch, 2001; Mitchell and Lapata, 2008; Mitchell and Lapata, 2010; Dinu and Lapata, 2010; Baroni and Zamparelli, 2010; Thater et al., 2011; S\u00e9aghdha and Korhonen, 2011).", "startOffset": 164, "endOffset": 335}, {"referenceID": 7, "context": "This approach abstracts away from grammatical differences between the sentences and concentrates on semantics and fits the proposed model as the respect for the head, which is a lexical entity, has to be found (Corbett and Fraser, 1993).", "startOffset": 210, "endOffset": 236}, {"referenceID": 41, "context": "Attention attraction But still, what about pragmatics? As Steels (2008) points out, sentences and words direct attention and do not always directly point or refer to entities and actions in the world.", "startOffset": 58, "endOffset": 72}, {"referenceID": 23, "context": "For example, No and I\u2019ve seen John eating them are similar sentences because they lexicalise the same answer to the question Do we have cookies? More generally, this gives rise to dialogue act tags: for another way of utterance categorisation, refer to the work of Kalchbrenner and Blunsom (2013) and Milajevs and Purver (2014).", "startOffset": 265, "endOffset": 297}, {"referenceID": 23, "context": "For example, No and I\u2019ve seen John eating them are similar sentences because they lexicalise the same answer to the question Do we have cookies? More generally, this gives rise to dialogue act tags: for another way of utterance categorisation, refer to the work of Kalchbrenner and Blunsom (2013) and Milajevs and Purver (2014). Thus, questions which the sentences answer, are", "startOffset": 265, "endOffset": 328}, {"referenceID": 49, "context": "valid respects for similarity explanation, as well as entailment, paraphrase (White et al., 2015) or spatial categories (Ritter et al.", "startOffset": 77, "endOffset": 97}, {"referenceID": 35, "context": ", 2015) or spatial categories (Ritter et al., 2015).", "startOffset": 30, "endOffset": 51}, {"referenceID": 6, "context": "This also motivates the approach of treating sentences on their own and encoding the meaning of a sentence into a vector in such a way that similar sentences are clustered together (Coecke et al., 2010; Baroni et al., 2014; Socher et al., 2012; Wieting et al., 2015; Hill et al., 2016).", "startOffset": 181, "endOffset": 285}, {"referenceID": 2, "context": "This also motivates the approach of treating sentences on their own and encoding the meaning of a sentence into a vector in such a way that similar sentences are clustered together (Coecke et al., 2010; Baroni et al., 2014; Socher et al., 2012; Wieting et al., 2015; Hill et al., 2016).", "startOffset": 181, "endOffset": 285}, {"referenceID": 40, "context": "This also motivates the approach of treating sentences on their own and encoding the meaning of a sentence into a vector in such a way that similar sentences are clustered together (Coecke et al., 2010; Baroni et al., 2014; Socher et al., 2012; Wieting et al., 2015; Hill et al., 2016).", "startOffset": 181, "endOffset": 285}, {"referenceID": 50, "context": "This also motivates the approach of treating sentences on their own and encoding the meaning of a sentence into a vector in such a way that similar sentences are clustered together (Coecke et al., 2010; Baroni et al., 2014; Socher et al., 2012; Wieting et al., 2015; Hill et al., 2016).", "startOffset": 181, "endOffset": 285}, {"referenceID": 20, "context": "This also motivates the approach of treating sentences on their own and encoding the meaning of a sentence into a vector in such a way that similar sentences are clustered together (Coecke et al., 2010; Baroni et al., 2014; Socher et al., 2012; Wieting et al., 2015; Hill et al., 2016).", "startOffset": 181, "endOffset": 285}, {"referenceID": 14, "context": "Griffiths et al. (2015) tried to construct two versions of the same dialogue using a bottomup method.", "startOffset": 0, "endOffset": 24}, {"referenceID": 41, "context": "Language sub-systems and strategies Steels (2010) introduces the idea of language sub-", "startOffset": 36, "endOffset": 50}], "year": 2016, "abstractText": "Similarity is a core notion that is used in psychology and two branches of linguistics: theoretical and computational. The similarity datasets that come from the two fields differ in design: psychological datasets are focused around a certain topic such as fruit names, while linguistic datasets contain words from various categories. The later makes humans assign low similarity scores to the words that have nothing in common and to the words that have contrast in meaning, making similarity scores ambiguous. In this work we discuss the similarity collection procedure for a multi-category dataset that avoids score ambiguity and suggest changes to the evaluation procedure to reflect the insights of psychological literature for word, phrase and sentence similarity. We suggest to ask humans to provide a list of commonalities and differences instead of numerical similarity scores and employ the structure of human judgements beyond pairwise similarity for model evaluation. We believe that the proposed approach will give rise to datasets that test meaning representation models more thoroughly with respect to the human treatment of similarity.", "creator": "dvips(k) 5.991 Copyright 2011 Radical Eye Software"}}}