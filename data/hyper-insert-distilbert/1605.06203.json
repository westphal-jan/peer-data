{"id": "1605.06203", "review": {"conference": "NIPS", "VERSION": "v1", "DATE_OF_SUBMISSION": "20-May-2016", "title": "Faster Projection-free Convex Optimization over the Spectrahedron", "abstract": "minimizing a convex function uniquely over to the spectrahedron, i. e., the generating set of corresponding all positive singular semidefinite identity matrices with unit trace, smoothing is an important optimization solving task common with many statistical applications suitable in optimization, machine learning, nonlinear and signal processing. considering it is also notoriously currently difficult attempting to spontaneously solve decisions in large - scale approximation since standard evaluation techniques require expensive expense matrix array decompositions. reflecting an eventual alternative, slower is the conditional bias gradient method ( aka dir frank - schmidt wolfe continuation algorithm ) : that now regained much large interest immensely in recent years, mostly due to relocating its application to this specific setting. realizing the key benefit difference of observing the different cg method used is ensuring that it probably avoids expensive matrix decompositions all squared together, and means simply slowing requires a single eigenvector computation per iteration, one which coincidentally is much more efficient. still on the downside, the cg method, except in general, converges with an entirely inferior criterion rate. the error for minimizing receives a $ \\ beta $ - smooth function after $ 6 t $ \u03b2 iterations scales like $ \\ v beta / t $. this finite convergence superiority rate does not sufficiently improve even even if the function _ is uniquely also biased strongly converge convex.", "histories": [["v1", "Fri, 20 May 2016 03:07:40 GMT  (110kb)", "http://arxiv.org/abs/1605.06203v1", null]], "reviews": [], "SUBJECTS": "math.OC cs.LG", "authors": ["dan garber"], "accepted": true, "id": "1605.06203"}, "pdf": {"name": "1605.06203.pdf", "metadata": {"source": "CRF", "title": "Faster Projection-free Convex Optimization over the Spectrahedron", "authors": ["Dan Garber"], "emails": ["dgarber@ttic.edu"], "sections": [{"heading": null, "text": "ar X\niv :1\n60 5.\n06 20\n3v 1\n[ m\nat h.\nO C\n] 2\n0 M\nay 2\n01 6\nIn this work we present a modification of the CG method tailored for convex optimization over the spectrahedron. The per-iteration complexity of the method is essentially identical to that of the standard CG method: only a single eigenvecor computation is required. For minimizing an \u03b1-strongly convex and \u03b2-smooth function, the expected approximation error of the method after t iterations is:\nO\n min{\u03b2 t , ( \u03b2 \u221a rank(X\u2217) \u03b11/4t )4/3 , ( \u03b2\u221a \u03b1\u03bbmin(X\u2217)t )2 }   ,\nwhere rank(X\u2217), \u03bbmin(X \u2217) are the rank of the optimal solution, and smallest non-zero eigenvalue, respectively. Beyond the significant improvement in convergence rate, it also follows that when the optimum is low-rank, our method provides better accuracy-rank tradeoff than the standard CG method.\nTo the best of our knowledge, this is the first result that attains provably faster convergence rates for a CG variant for optimization over the spectrahedron. We also present encouraging preliminary empirical evidence, that shows that our approach may improve also in practice over previous projection-free methods."}, {"heading": "1 Introduction", "text": "Minimizing a convex function over the set of positive semidefinite matrices with unit trace, aka the spectrahedron, is an important optimization task which lies at the heart of many optimization, machine learning, and signal processing tasks such as matrix completion [2, 28, 17], metric learning [32, 31, 33], kernel matrix learning [23, 10], multiclass classification [3, 34, 14], and more.\nSince modern applications are mostly of very large scale, first-order methods are the obvious choice to deal with this optimization problem. However, even these are notoriously difficult to apply, since most of the popular gradient schemes require the computation of an orthogonal\nprojection on each iteration to enforce feasiblity, which for the spectraheron, amounts to computing a full eigen-decomposition of a real symmetric matrix. Such a decomposition requires O(d3) arithmetic operations for a d \u00d7 d matrix, and thus is prohibitive for high-dimensional problems. An alternative is to use first-order methods that do not require expensive decompositions, but rely only on computationally-cheap leading eigenvector computations. These methods are mostly based on the conditional gradient method, also known as the Frank-Wolfe algorithm [4, 16], which is a generic method for constrained convex optimization given an oracle for minimizing linear functions over the feasible domain. Indeed, linear minimization over the spectrahedron amounts to a single leading eigenvector computation. While the CG method has been discovered already in the 1950\u2019s [4, 25], it has regained much interest in recent years in the machine learning and optimization communities, in particular due to its applications to semidefinite optimization and convex optimization with a nuclear norm constraint / regularization1, e.g., [12, 17, 24, 29, 33, 3, 11, 13, 14]. This regained interest is not surprising: while a full eigen-decomposition for d \u00d7 d matrix requires O(d3) arithmetic operations, leading eigenvecor computations can be carried out, roughly speaking, in worst-case time that is only linear in the number of non-zeros in the input matrix multiplied by either \u01eb\u22121 for the popular Power Method or by \u01eb\u22121/2 for the more efficient Lanczos method, where \u01eb is the target accuracy. These running times improve exponentially to only depend on log(1/\u01eb) when the eigenvalues of the input matrix are well distributed [19]. Indeed, in several important machine learning applications, such as matrix completion, the CG method requires eigenvector computations of very sparse matrices [17]. Also, very recently, new eigenvector algorithms with significantly improved performance guarantees were introduced which are applicable for matrices with certain popular structure [8, 18, 30].\nBecause of their cheap iteration complexity, conditional gradient-based methods are also of interest in online optimization settings, such as online convex optimization or online stochastic optimization, in which, roughly speaking, given a continuos stream of data, one wants to incrementally update the prediction / hypothesis based on newly observed data. In these settings the time required for the optimization method to perform a single update may be a key consideration in its applicability to the problem [13, 7, 6].\nThe main drawback of the CG method is that its convergence rate is, in general, inferior compared to projection-based gradient methods. The convergence rate for minimizing a smooth function, roughly speaking, scales only like 1/t. In particular, in general, this rate does not improve, even when the function is also strongly convex. On the other hand, the convergence rate of optimal projection-based methods, such as Nesterov\u2019s accelerated gradient method, scales like 1/t2 for smooth functions, and can be improved exponentially to exp(\u2212\u0398(t)) when the objective is also strongly convex [27].\nVery recently, several successful attempts were made to devise natural modifications of the CG method that retain the overall low per-iteration complexity, while enjoying provably faster convergence rates, usually under a strong-convexity assumption, or a slightly weaker one. These results exhibit provably-faster rates for optimization over polyhedral sets [6, 20, 1] and stronglyconvex sets [9], but do not apply to the spectrahedron. For the specific setting considered in this work, several heuristic improvements of the CG method were suggested which show promising empirical evidence, however, non of them provably improve over the rate of the standard CG method [29, 24, 5].\nIn this work, we present, a new non-trivial variant of the CG method, which, to the best of our knowledge, is the first one to exhibit provably faster convergence rates for optimization over the spectrahedron under standard smoothness and strong convexity assumptions. The periteration complexity of the method is essentially identical to that of the standard CG method in this setting, i.e., only a single leading eigenvector computation per iteration is required.\n1minimizing a convex function subject to a nuclear norm constraint is efficiently reducible to the minimization\nof the function over the spectrahedron, as we detail in Subsection 2.2.\nOur method is tailored for optimization over the spectrahedron, and can be seen as a certain hybridization of the standard CG method and the projected gradient method. From a highlevel view, we take advantage of the fact that solving a \u21132-regularized linear problem over the set of extreme points of the spectrahedron is equivalent to linear optimization over this set, i.e., amounts to a single eigenvector computation. We then show via a novel and non-trivial analysis, that includes new decomposition concepts for positive semidefinite matrices, that such an algorithmically-cheap regularization is sufficient, in presence of strong convexity, to derive faster convergence rates.\nWhile the combination of smoothness and strong convexity is a rare commodity, several important problems such as linear regression in the well-conditioned case, and solving undetermined linear systems (such as in the matrix completion problem), under certain conditions (see for instance [26]), exhibit such properties. Moreover, since computing the euclidean projection is a smooth and strongly convex optimization problem with respect to the \u21132 norm, our method can be readily used to simulate any \u21132-projection-based algorithm, replacing the projection step with only a leading eigenvector step. This approach has allowed, among other things, to apply CG-based methods to non-smooth problems, for which the standard CG method is not suitable [6], and to strike better trade-offs between the linear optimization oracle complexity and the first-order oracle complexity [22, 14]"}, {"heading": "1.1 Paper organization", "text": "The rest of this paper is organized as follows. In Section 2 we give necessary preliminaries and notation, describe the problem considered in this paper in full detail, and draw known connections to the popular problem of convex optimization under a nuclear norm constraint. In Section 3 we briefly describe the conditional gradient and projected gradient methods for optimization over the spectrahedron, and present our new method, which is a certain hybridization of the two. We also state the main theorem of this paper, Theorem 1, which describes the novel convergence rate of the proposed method. In Section 4 we analyze our proposed method and prove the main theorem, Theorem 1. Finally, in Section 5 we present preliminary empirical evidence that shows that our method may indeed improve in practice over previous conditional gradient methods."}, {"heading": "2 Preliminaries and Notation", "text": "Throughout this work we use boldface lowercase letters to denote vectors in Rd, e.g. v, boldface uppercase letters to denote matrices, e.g. X, and lightface letters to denote scalars. For vectors we let \u2016\u00b7\u2016 denote the standard Euclidean norm, while for matrices we let \u2016\u00b7\u2016 denote the spectral norm, \u2016\u00b7\u2016F denote the Frobenius norm, and \u2016 \u00b7 \u2016\u2217 denote the nuclear norm. We denote by Sd the space of d\u00d7 d real symmetric matrices, and by Sd the spectrahedron in Sd, i.e.,\nSd := {X \u2208 Sd |X 0,Tr(X) = 1}.\nWe let Tr(\u00b7) and rank(\u00b7) denote the trace and rank of a given matrix in Sd, respectively. We let \u2022 denote the standard inner-product for matrices. Given a matrix X \u2208 Sd, we let \u03bbmin(X) denote the smallest non-zero eigenvalue of X.\nThroughout this work, given a matrix A \u2208 Sd, we denote by EV(A) an eigenvector of A that corresponds to the largest (signed) eigenvalue of A, i.e., EV(A) \u2208 argmaxv:\u2016v\u2016=1 v\u22a4Av. Given a scalar \u03be > 0, we also denote by EV\u03be(A) an \u03be-approximation to the largest (in terms of eigenvalue) eigenvector of A, i.e., EV\u03be(A) returns a unit vector v such that v\n\u22a4Av \u2265 \u03bbmax(A)\u2212 \u03be.\nDefinition 1. We say that a function f(X) : Rm\u00d7n \u2192 R is \u03b1-strongly convex w.r.t. a norm \u2016 \u00b7 \u2016, if for all X,Y \u2208 Rm\u00d7n it holds that\nf(Y) \u2265 f(X) + (Y \u2212X) \u2022 \u2207f(X) + \u03b1 2 \u2016X\u2212Y\u20162.\nDefinition 2. We say that a function f(X) : Rm\u00d7n \u2192 R is \u03b2-smooth w.r.t. a norm \u2016 \u00b7 \u2016, if for all X,Y \u2208 Rm\u00d7n it holds that\nf(Y) \u2264 f(X) + (Y \u2212X) \u2022 \u2207f(X) + \u03b2 2 \u2016X\u2212Y\u20162.\nThe first-order optimality condition implies that for a \u03b1-strongly convex f , if X\u2217 is the unique minimizer of f over a convex set K \u2282 Rm\u00d7n, then for all X \u2208 K it holds that\nf(X)\u2212 f(X\u2217) \u2265 \u03b1 2 \u2016X\u2212X\u2217\u20162. (1)"}, {"heading": "2.1 Problem setting", "text": "The main focus of this work is the following optimization problem:\nmin X\u2208Sd f(X), (2)\nwhere we assume that f(X) is both \u03b1-strongly convex and \u03b2-smooth w.r.t. \u2016 \u00b7 \u2016F . We denote the (unique) minimizer of f over Sd by X\u2217."}, {"heading": "2.2 Convex optimization with a nuclear norm constraint", "text": "An important optimization problem highly-related to Problem (2), is the problem of minimizing a convex function over the set of d1 \u00d7 d2 real-valued matrices with bounded nuclear norm, i.e,\nmin Z\u2208NBd1,d2 (\u03b8) f(Z). (3)\nHere we let NBd1,d2(\u03b8) denote the nuclear-norm ball of radius \u03b8 in Rd1\u00d7d2 , i.e.,\nNBd1,d2(\u03b8) := {Z \u2208 Rd1\u00d7d2 | \u2016Z\u2016\u2217 := min{d1,d2} \u2211\ni=1\n\u03c3i(Z) \u2264 \u03b8},\nwhere we let \u03c3(Z) denote the vector of singular values of Z. Problem (3) could be directly formulated as convex optimization over the spectrahedron. Towards this end, consider now the following convex optimization problem:\nminX\u2208Sd1+d2 f\u0302(X),\nf\u0302(X) := f(2\u03b8 \u00b7M1XM2), M1 := ( Id1 0d1\u00d7d2 ) , M1 :=\n(\n0d1\u00d7d2 Id2\n)\n.\nThe following Lemma, whose proof can be found in [17], shows the equivalence between the two problems.\nLemma 1. Let X \u2208 Sd1+d2 such that f\u0302(X) \u2212 f\u0302(X\u2217) = \u01eb, for some \u01eb > 0, where X\u2217 is the minimizer of f\u0302 over Sd1+d2 . Consider the following factorization of X:\nX =\n(\nX1 X2 X\u22a42 X3\n)\n,\nwhere X1 is d1 \u00d7 d1, X2 is d1 \u00d7 d2, and X3 is d2 \u00d7 d2. Define Z := 2\u03b8 \u00b7 X2. Then it follows that Z \u2208 NBd1,d2(\u03b8), and f(Z)\u2212 f(Z\u2217) = \u01eb, where Z\u2217 is the minimizer of f over NBd1,d2(\u03b8)."}, {"heading": "3 Our Approach", "text": "In order to better communicate our ideas, we begin by briefly describing the conditional gradient and projected-gradient methods, pointing out their advantages and short-comings for solving Problem (2) in Subsection 3.1. We then present our new method which is a certain combination of ideas from both methods in Subsection 3.2."}, {"heading": "3.1 Conditional gradient and projected gradient descent", "text": "The standard conditional gradient algorithm is detailed below in Algorithm 1.\nAlgorithm 1 Conditional Gradient\n1: input: sequence of step-sizes {\u03b7t}t\u22651 \u2282 [0, 1] 2: let X1 be an arbitrary matrix in Sd 3: for t = 1... do 4: vt \u2190 EV (\u2212\u2207f(Xt)) 5: Xt+1 \u2190 Xt + \u03b7t(vtv\u22a4t \u2212Xt) 6: end for\nLet us denote the approximation error of Algorithm 1 after performing t iterations by ht := f(Xt)\u2212 f(X\u2217).\nThe convergence result of Algorithm 1 is based on the following simple observations:\nht+1 = f(Xt + \u03b7t(vtv \u22a4 t \u2212Xt))\u2212 f(X\u2217)\n\u2264 ht + \u03b7t(vtv\u22a4t \u2212Xt) \u2022 \u2207f(Xt) + \u03b72t \u03b2\n2 \u2016vtv\u22a4t \u2212Xt\u20162F\n\u2264 ht + \u03b7t(X\u2217 \u2212Xt) \u2022 \u2207f(Xt) + \u03b72t \u03b2\n2 \u2016vtv\u22a4t \u2212Xt\u20162F\n\u2264 (1\u2212 \u03b7t)ht + \u03b72t \u03b2\n2 \u2016vtv\u22a4t \u2212Xt\u20162F , (4)\nwhere the first inequality follows from the \u03b2-smoothness of f(X), the second one follows for the optimal choice of vt, and the third one follows from convexity of f(X). Unfortunately, while we\nexpect the error ht to rapidly converge to zero, the term \u2016vtv\u22a4t \u2212Xt\u20162F in Eq. (4), in principal, might remain as large as the diameter of Sd, which, given a proper choice of step-size \u03b7t, results in the well-known convergence rate of O(\u03b2/t) [16, 12]. This consequence holds also in case f(X) is not only smooth, but also strongly-convex, see for instance Lemma 21 in [15].\nHowever, in case f is strongly convex, a non-trivial modification of Algorithm 1 can lead to a much faster convergence rate. In this case, it follows from Eq. (1), that on any iteration t, \u2016Xt \u2212X\u2217\u20162F \u2264 2\u03b1ht. Thus, if we consider replacing the choice of Xt+1 in Algorithm 1 with the following update rule:\nVt \u2190 argminV\u2208SdV \u2022 \u2207f(Xt) + \u03b7t\u03b2\n2 \u2016Vt \u2212Xt\u20162F , Xt+1 \u2190 Xt + \u03b7t(Vt \u2212Xt), (5)\nthen, following basically the same steps as in Eq. (4), we will have that\nht+1 \u2264 ht + \u03b7t(X\u2217 \u2212Xt) \u2022 \u2207f(Xt) + \u03b72t \u03b2\n2 \u2016X\u2217 \u2212Xt\u20162F \u2264\n(\n1\u2212 \u03b7t + \u03b72t \u03b2\n\u03b1\n)\nht, (6)\nand thus by a proper choice of \u03b7t, a linear convergence rate will be attained. Of course the issue now, is that computing Vt is no longer a computationally-cheap leading eigenvalue problem (in particular Vt is not rank-one), but requires a full eigen-decomposition of Xt, which is much more expensive. In fact, the update rule in Eq. (5) is nothing more than the projected gradient decent method, which, in spite of the linear convergence rate, is inefficient for large-scale matrix problems because of the need to compute expansive decompositions."}, {"heading": "3.2 A new hybrid approach: rank one-regularized conditional gradient algorithm", "text": "At the heart of our new method is the combination of ideas from both of the above approaches: on one hand, solving a certain regularized linear problem in order to avoid the shortcomings of the CG method, i.e., slow convergence rate, and on the other hand, maintaining the simple structure of a leading eigenvalue computation that avoids the shortcoming of the computationallyexpensive projected-gradient method.\nTowards this end, suppose that have an explicit decomposition of the current iterate Xt = \u2211k\ni=1 aixix \u22a4 i , where k is an integer, (a1, a2, ..., ak) is a probability distribution over [k], and each xi is a unit vector. Note in particular that the standard CG method (Algorithm 1) naturally produces such an explicit decomposition of Xt. Consider now, the update rule in Eq. (5), but with the additional restriction that Vt is rank one, i.e,\nVt \u2190 argminV\u2208Sd, rank(V)=1V \u2022 \u2207f(Xt) + \u03b7t\u03b2\n2 \u2016V \u2212Xt\u20162F . (7)\nNote that in this case it follows that Vt is a unit trace rank-one matrix which corresponds to the leading eigenvector of the matrix \u2212\u2207f(Xt)+\u03b7t\u03b2Xt. However, when Vt is simply rank-one, the regularization \u2016Vt \u2212Xt\u20162F makes little sense in general, since unless X\u2217 is rank-one, we do not expect Xt to be such. Note however, that if X\n\u2217 is rank one, then this modification will already result in a linear convergence rate. However, we can think of solving a set of decoupled component-wise regularized problems:\n\u2200i \u2208 [k] : v(i)t \u2190 argmin\u2016v\u2016=1v\u22a4\u2207f(Xt)v + \u03b7t\u03b2 2 \u2016vv\u22a4 \u2212 xix\u22a4i \u20162F\n\u2261 EV ( \u2212\u2207f(Xt) + \u03b7t\u03b2xix\u22a4i )\nXt+1 \u2190 k \u2211\ni=1\nai\n(\n(1\u2212 \u03b7t)xixi + \u03b7tv(i)t v (i)\u22a4 t\n)\n. (8)\nFollowing the lines of Eq. (4), we will now have that\nht+1 \u2264 ht + \u03b7t k \u2211\ni=1\nai(v (i) t v (i)\u22a4 t \u2212 xix\u22a4i ) \u2022 \u2207f(Xt) +\n\u03b72t \u03b2\n2 \u2016\nk \u2211\ni=1\nai(v (i) t v (i)\u22a4 t \u2212 xix\u22a4i )\u20162F\n\u2264 ht + \u03b7t k \u2211\ni=1\nai(v (i) t v (i)\u22a4 t \u2212 xix\u22a4i ) \u2022 \u2207f(Xt) +\n\u03b72t \u03b2\n2\nk \u2211\ni=1\nai\u2016v(i)t v (i)\u22a4 t \u2212 xix\u22a4i \u20162F\n= ht + \u03b7tEi\u223c(a1,...,ak)\n[\n(v (i) t v (i)\u22a4 t \u2212 xix\u22a4i ) \u2022 \u2207f(Xt) + \u03b7t\u03b2 2 \u2016v(i)t v (i)\u22a4 t \u2212 xix\u22a4i \u20162F\n]\n, (9)\nwhere the second inequality follows from convexity of the squared Frobenius norm, and the last equality follows since (a1, ..., ak) is a probability distribution over [k].\nWhile the approach in Eq. (8) relies only on leading eigenvector computations, the benefit in terms of potential convergence rates is not trivial, except for the case in which rank(X\u2217) = 1 (then, by previous arguments, it is equivalent to computing the projection), since it is not immediate that we can get non-trivial bounds for the individual distances \u2016v(i)t v (i)\u22a4 t \u2212 xix\u22a4i \u2016F . Indeed, the main novelty in our analysis is dedicated precisely to this issue. A motivation, if any, is that there might exists a decomposition ofX\u2217 asX\u2217 =\n\u2211k i=1 bix \u2217(i)x\u2217(i)\u22a4, which is close in some sense to the decomposition of Xt. We can then think of the regularized problem in Eq. (8), as an attempt to push each individual component x(i) towards its corresponding component in the decomposition of X\u2217, and as an overall result, bring the following iterate Xt+1 closer to X\n\u2217. Note that Eq. (9) implicitly describes a randomized algorithm in which, instead of solving a regularized EV problem for each rank-one matrix in the decomposition of Xt, which is expensive as this decomposition grows large with the number of iterations, we pick a single rank-one component according to its weight in the decomposition, and only update it. This directly brings us to our proposed algorithm, Algorithm 2, which is given below.\nAlgorithm 2 Randomized Rank one-regularized Conditional Gradient\n1: input: sequence of step-sizes {\u03b7t}t\u22651, sequence of error tolerances {\u03bet}t\u22650 2: let x0 be an arbitrary unit vector 3: X1 \u2190 x1x\u22a41 such that x1 \u2190 EV\u03be0(\u2212\u2207f(x0x\u22a40 )) 4: for t = 1... do 5: suppose Xt is given by Xt = \u2211k i=1 aixix \u22a4 i , where each xi is a unit vector, and (a1, a2, ..., ak) is a probability distribution over [k], for some integer k. 6: pick it \u2208 [k] according to the probability distribution (a1, a2, ...ak) 7: set a new step-size \u03b7\u0303t as follows:\n\u03b7\u0303t \u2190 { \u03b7t/2 if ait \u2265 \u03b7t ait else\n8: vt \u2190 EV\u03bet ( \u2212\u2207f(Xt) + \u03b7t\u03b2xitx\u22a4it )\n9: Xt+1 \u2190 Xt + \u03b7\u0303t(vtv\u22a4t \u2212 xitx\u22a4it ) 10: end for\nWe have the following guarantee for Algorithm 2 which is the main result of this paper.\nTheorem 1. [Main Theorem] Consider the sequence of step-sizes {\u03b7t}t\u22651 defined by \u03b7t = 18/(t+ 8), and suppose that \u03be0 = \u03b2 and for any iteration t \u2265 1 it holds that\n\u03bet = O\n\nmin{\u03b2 t ,\n(\n\u03b2 \u221a rank(X\u2217)\n\u03b11/4t\n)4/3\n,\n(\n\u03b2\u221a \u03b1\u03bbmin(X\u2217)t\n)2\n}\n\n .\nThen, all iterates of Algorithm 2 are feasible, and\n\u2200t \u2265 1 : E [f(Xt)\u2212 f(X\u2217)] = O\n\nmin{\u03b2 t ,\n(\n\u03b2 \u221a rank(X\u2217) \u03b11/4t\n)4/3\n,\n(\n\u03b2\u221a \u03b1\u03bbmin(X\u2217)t\n)2\n}\n\n .\nWe now make several remarks regarding Algorithm 2 and Theorem 1:\n\u2022 Observe that the feasibility of the iterates follows directly from the definition of \u03b7\u0303t, since it is never allowed to exceed the corresponding coefficient ait .\n\u2022 None of the three bounds in Theorem 1 is better than the others for every value of t. In particular note that \u03bbmin(X\n\u2217)\u22121 \u2265 rank(X\u2217). Also, we note that the first O(1/t) bound comes from the standard CG analysis.\n\u2022 The dependency of the improved rates in Theorem 1 on rank(X\u2217) and \u03bbmin(X\u2217) is not surprising since, in general, the standard 1/t rate of the CG method could not be improved without such additional dependencies. See for instance Section 7.4 in [15].\n\u2022 The step-size choice in Theorem 1 does not require any knowledge on the parameters \u03b1, \u03b2, rank(X\u2217), and \u03bbmin(X\u2217). The knowledge of the smoothness parameter \u03b2 is required however for the computation of vt on each iteration. While it follows from Theorem 1 that the knowledge of \u03b1, rank(X\u2217), \u03bbmin(X\u2217) is needed to set the accuracy for the EV solver - \u03bet, in practice, iterative methods for eigenvector computation are very efficient and are much less sensitive to exact knowledge of parameters than the choice of step-size for instance.\n\u2022 While the eigenvalue problem solved on each iteration in Algorithm 2 is different from the one in the original CG algorithm (Algorithm 1), because of the additional term that depends on xitx \u22a4 it , the efficiency of solving both EV problems is essentially the same. This\nfollows since efficient EV procedures are based on iteratively multiplying the desired input matrix M with some vector v. In particular, multypling v with a rank-one matrix takes O(d) time. Thus, as long as nnz(\u2207f(Xt)) = \u2126(d), which is highly reasonable, it follows that both EV computations run in essentially the same time.\n\u2022 Aside from the computation of the gradient direction and the leading eigenvector computation, all other operations on any iteration t, can be carried out in O(d2 + t) additional time.\n\u2022 Algorithm 2 does not directly use the input step-size sequence, but uses instead a modified sequence {\u03b7\u0303t}t\u22651. This modification is made for clarity of the analysis. One can think of the sequence {\u03b7t}t\u22651 as the sequence that we would like to use, however, we need to modify it a bit so on one hand, we can make sure that the iterates of the algorithm are indeed feasible at all times, and on the other hand, we can make sure that the algorithm can make sufficient progress on each iteration."}, {"heading": "4 Analysis", "text": "Throughout this section, given a matrix Y \u2208 Sd, we let PY,\u03c4 \u2208 Sd denote the projection matrix onto all eigenvectors of Y that correspond to eigenvalues of magnitude at least \u03c4 . Similarly, we let P\u22a5\nY,\u03c4 denote the projection matrix onto the eigenvectors of Y that correspond to eigenvalues of magnitude smaller that \u03c4 (including eigenvectors that correspond to zero-valued eigenvalues)."}, {"heading": "4.1 A new decomposition for positive semidefinite matrices with locality proprieties", "text": "The analysis of Algorithm 2 relies heavily on a new decomposition idea of matrices in Sd that suggests that given a matrix X in the form of a convex combination of rank-one matrices: X =\n\u2211k i=1 \u03b1ixix \u22a4 i , and another matrix Y \u2208 Sd, roughly speaking, we can decompose Y as the\nsum of rank-one matrices, such that the components in the decomposition ofY are close to those in the decomposition of X in terms of the overall distance \u2016X\u2212Y\u2016F . This decomposition and corresponding property justifies the idea of solving rank-one regularized problems, as suggested in Eq. (8), and applied in Algorithm 2.\nIn order to present this decomposition and its nice local proprieties, we first need two technical lemmas, and then we present the main lemma of this subsection, Lemma 4, which gives the exact bounds that will be used in the convergence analysis of Algorithm 2.\nLemma 2. Let X,Y \u2208 Sd. Let \u03c4, \u03b3 \u2208 [0, 1] be scalars that satisfy \u03b3\u03c41\u2212\u03b3 \u2265 \u2016X\u2212Y\u2016F . Then it holds that Y (1\u2212 \u03b3)PY,\u03c4XPY,\u03c4 . Proof. Given a vector w \u2208 Rd let us write it as w = w+ + w\u2212 where w+ = PY,\u03c4w and w\u2212 = P\u22a5\nY,\u03c4w = w \u2212w+. It holds that\nw\u22a4Yw = w+\u22a4Yw+ +w\u2212\u22a4Yw\u2212 + 2w\u2212\u22a4Yw+\n= w+\u22a4Yw+ +w\u2212\u22a4Yw\u2212 + 2w\u22a4P\u22a5Y,\u03c4YPY,\u03c4w\n\u2265 w+\u22a4Yw+, (10) where the inequality follows since P\u22a5\nY,\u03c4YPY,\u03c4 = 0 and Y is positive semidefinite.\nSimilarly, since PY,\u03c4w \u2212 = 0, we have that\nw\u2212\u22a4PY,\u03c4XPY,\u03c4w \u2212 = w\u2212\u22a4PY,\u03c4XPY,\u03c4w + = w+\u22a4PY,\u03c4XPY,\u03c4w \u2212 = 0. (11)\nNote also that\nw+\u22a4PY,\u03c4XPY,\u03c4w + = w+\u22a4Xw+. (12)\nThus, we have that\nw\u22a4 [(1\u2212 \u03b3)PY,\u03c4XPY,\u03c4 ]w = (1\u2212 \u03b3)w+\u22a4PY,\u03c4XPY,\u03c4w+ = (1\u2212 \u03b3)w+\u22a4Xw+\n\u2264 (1\u2212 \u03b3) ( w+\u22a4Yw+ + \u2016X\u2212Y\u2016F \u00b7 \u2016w+\u20162 )\n\u2264 w\u22a4Yw + (1\u2212 \u03b3)\u2016X\u2212Y\u2016F \u00b7 \u2016w+\u20162 \u2212 \u03b3w+\u22a4Yw+ \u2264 w\u22a4Yw + (1\u2212 \u03b3)\u2016X\u2212Y\u2016F \u00b7 \u2016w+\u20162 \u2212 \u03b3\u03c4\u2016w+\u20162,\nwhere the first equality follows from Eq. (11), the second equality follows from Eq. (12), the first inequality follows from the Cauchy-Schwarz ineq., the second inequality follows from Eq. (10), and the last inequality follows from the definitions of w+ and \u03c4 .\nThus, we can see that if \u03b3\u03c41\u2212\u03b3 \u2265 \u2016X\u2212Y\u2016F , the lemma follows.\nLemma 3. Let X,Y \u2208 Sd and suppose X is given in the form X = \u2211k i=1 aixix \u22a4 i where each xi is a unit vector, and the weights (a1, ..., ak) are a distribution over [k]. Let P \u2208 Sd be a projection matrix onto a subset of the eigenvectors of Y, and define for any i \u2208 [k], x\u0303i := Pxi. Then, it holds that\nk \u2211\ni=1\nai(1\u2212 \u2016x\u0303i\u20162) \u2264 \u221a rank(Y)\u2016Y \u2212PXP\u2016F .\nProof. Let us write the eigen-decomposition of Y as Y = \u2211rank(Y) j=1 \u03bbjvjv \u22a4 j . Using simple algebraic manipulations we have that\n\u2016Y \u2212PXP\u20162F \u2265 rank(Y) \u2211\nj=1\n( (Y \u2212PXP) \u2022 vjv\u22a4j )2 =\nrank(Y) \u2211\nj=1\n(\n\u03bbj \u2212 k \u2211\ni=1\naiv \u22a4 j Pxix \u22a4 i Pvj\n)2\n=\nrank(Y) \u2211\nj=1\n(\n\u03bbj \u2212 k \u2211\ni=1\nai(v \u22a4 j Pxi) 2\n)2\n\u2265 1 rank(Y)\n\n\nrank(Y) \u2211\nj=1\n(\n\u03bbj \u2212 k \u2211\ni=1\nai(v \u22a4 j Pxi) 2\n)\n\n\n2\n= 1\nrank(Y)\n 1\u2212 rank(Y) \u2211\nj=1\nk \u2211\ni=1\nai(v \u22a4 j Pxi) 2\n\n\n2\n= 1\nrank(Y)\n\n\nk \u2211\ni=1\nai\n 1\u2212 rank(Y) \u2211\nj=1\n(v\u22a4j Pxi) 2\n\n\n\n\n2\n= 1\nrank(Y)\n(\nk \u2211\ni=1\nai ( 1\u2212 \u2016x\u0303i\u20162 )\n)2\n.\nThus we have that\nk \u2211\ni=1\nai(1\u2212 \u2016x\u0303i\u20162) \u2264 \u221a rank(Y)\u2016Y \u2212PXP\u2016F ,\nwhich gives the bound in the lemma.\nLemma 4. Let X,Y \u2208 Sd such that X is given as X = \u2211k i=1 aixix \u22a4 i , where each xi is a unit vector, and (a1, ..., ak) is a distribution over [k], and let \u03c4, \u03b3 \u2208 [0, 1] which satisfy the condition in Lemma 2. Then, Y can be written as\nY =\nk \u2211\ni=1\nbiyiy \u22a4 i +\nk \u2211\nj=1\n(aj \u2212 bj)W\nsuch that\n1. each yi is a unit vector, (b1, ..., bk) is a distribution over [k], and W \u2208 Sd\n2. \u2200i \u2208 [k] : bi \u2264 ai and \u2211k j=1(aj \u2212 bj) \u2264 \u221a\nrank(Y) ( \u2016YP\u22a5 Y,\u03c4\u2016F + \u2016X\u2212Y\u2016F ) + \u03b3\n3. \u2211k i=1 bi\u2016xix\u22a4i \u2212 yiy\u22a4i \u20162F \u2264 2 \u221a rank(Y) ( \u2016YP\u22a5 Y,\u03c4\u2016F + \u2016X\u2212Y\u2016F )\nProof. For each i \u2208 [k] let x\u0303i = PY,\u03c4xi. It follows from Lemma 2 that as long as \u03b3\u03c41\u2212\u03b3 \u2265 \u2016X\u2212Y\u2016F , it holds that\nY k \u2211\ni=1\nai(1\u2212 \u03b3)x\u0303ix\u0303\u22a4i .\nSince Y \u2208 Sd and Tr ( \u2211k i=1 ai(1\u2212 \u03b3)x\u0303ix\u0303\u22a4i ) = \u2211k\ni=1 ai(1 \u2212 \u03b3)\u2016x\u0303i\u20162, it follows that Y can be written as:\nY =\nk \u2211\ni=1\nai(1\u2212 \u03b3)x\u0303ix\u0303\u22a4i +\n\n\nk \u2211\nj=1\naj ( 1\u2212 (1\u2212 \u03b3)\u2016x\u0303j\u20162 )\n\nW,\nwhere W \u2208 Sd. Let us now define yi :=\nx\u0303i \u2016x\u0303i\u2016 and bi := ai(1\u2212 \u03b3)\u2016x\u0303i\u2016 2. Then indeed it follows that\nY =\nk \u2211\ni=1\nbiyiy \u22a4 i +\nk \u2211\nj=1\n(aj \u2212 bj)W.\nWe are going to apply Lemma 3 to derive the bounds listed in the lemma. As a first step, we need to bound the distance \u2016Y \u2212PY,\u03c4XPY,\u03c4\u2016F .\n\u2016Y \u2212PY,\u03c4XPY,\u03c4\u2016F \u2264 \u2016Y \u2212PY,\u03c4YPY,\u03c4\u2016F + \u2016PY,\u03c4XPY,\u03c4 \u2212PY,\u03c4YPY,\u03c4\u2016F \u2264 \u2016YP\u22a5Y,\u03c4\u2016F + \u2016X\u2212Y\u2016F , (13)\nwhere the bound on \u2016Y \u2212PY,\u03c4YPY,\u03c4\u2016F follows from the definition of PY,\u03c4 , and the bound on \u2016PY,\u03c4XPY,\u03c4 \u2212PY,\u03c4YPY,\u03c4\u2016F follows from the inequality \u2016AB\u2016F \u2264 \u2016A\u2016 \u00b7 \u2016B\u2016F .\nBy definition of {bi}i\u2208[k] it holds that\nk \u2211\ni=1\n(ai \u2212 bi) = k \u2211\ni=1\nai(1\u2212 (1\u2212 \u03b3)\u2016x\u0303i\u20162) \u2264 k \u2211\ni=1\nai(1\u2212 \u2016x\u0303i\u20162) + \u03b3\n\u2264 \u221a rank(Y) ( \u2016YP\u22a5Y,\u03c4\u2016F + \u2016X\u2212Y\u2016F ) + \u03b3,\nwhere the last inequality follows from Lemma 3 and the bound in Eq. (13). We continue to upper-bound\n\u2211k i=1 bi\u2016xix\u22a4i \u2212 yiy\u22a4i \u20162F :\nk \u2211\ni=1\nbi\u2016xix\u22a4i \u2212 yiy\u22a4i \u20162F \u2264 k \u2211\ni=1\nai\u2016xix\u22a4i \u2212 yiy\u22a4i \u20162F\n= 2 k \u2211\ni=1\nai(1\u2212 (x\u22a4i yi)2)\n= 2 k \u2211\ni=1\nai\n(\n1\u2212 ( x\u22a4i x\u0303i \u2016x\u0303i\u2016\n)2 )\n= 2\nk \u2211\ni=1\nai(1\u2212 \u2016x\u0303i\u20162)\n\u2264 2 \u221a rank(Y) ( \u2016YP\u22a5Y,\u03c4\u2016F + \u2016X\u2212Y\u2016F ) ,\nwhere the last inequality follows again from the application of Lemma 3 and the bound in Eq. (13)."}, {"heading": "4.2 Bounding the per-iteration improvement", "text": "We now turn to analyze the per-iteration improvement of Algorithm 2. We start by first analyzing a deterministic, and much less efficient, version that updates all of the rank-one\ncomponents on each iteration t, as suggested in Eq. (8). This is done in Lemma 5. Then in Lemma 6, we apply Lemma 5, to analyze the randomized step of Algorithm 2. However, first we need a simple observation regarding Algorithm 2, that shows that it can always take sufficiently large step-sizes, i.e., step-size of magnitude at least \u03b7t/2 on iteration t.\nObservation 1. In case the input sequence of step-sizes in Algorithm 2 - {\u03b7t}t\u22651, is monotonically non-increasing and \u03b7t \u2208 [0, 2] for all t \u2265 1, it follows that on each iteration t of the algorithm, the iterate Xt admits an explicitly-given factorization into a convex sum of rank-one matrices, as described in the algorithm, such that for every rank-one coefficient ai, it holds that ai \u2265 \u03b7t/2.\nProof. The proof is by a simple induction. Since X1 is just a rank-one matrix, it follows that the corresponding coefficient in the convex sum is a1 = 1. Thus, for any \u03b71 \u2208 [0, 2] it indeed follows that a1 \u2265 \u03b71/2. Assume now that the induction holds for time t \u2265 1. On time t we choose a coefficient ait and move a mass of \u03b7\u0303t from it to a new rank-one matrix yty \u22a4 t , and all other coefficients remain unchanged. Since we assume that the step-size sequence is monotonically non-increasing, it directly follows that the induction step holds for all unchanged coefficients. Regarding the affected coefficients ait and the coefficient of the new rank-one matrix, we consider two cases. First, if ait \u2265 \u03b7t then by the definition of \u03b7\u0303t we have that the mass of the new coefficient is going to be exactly \u03b7t/2 and the mass of the old coefficient is going to be ait \u2212 \u03b7t/2 \u2265 \u03b7t/2, and thus the induction holds. In the other case, we have that \u03b7\u0303t = ait < \u03b7t. By the induction hypothesis we know that ait \u2265 \u03b7t/2 \u2265 \u03b7t+1/2. Since we are moving now all the mass from ait to the new rank-one matrix, it follows that its weight is also going to be at least \u03b7t+1/2, and thus the induction follows.\nLemma 5. [full deterministic update] Fix a scalar \u03b7 > 0. Let X \u2208 Sd such that X = \u2211k\ni=1 aixix \u22a4 i , where each xi is a unit vector, and (a1, ..., ak) is a probability distribution over\n[k]. For any i \u2208 [k], let\nvi := EV\u03be\n( \u2212\u2207f(X) + \u03b7\u03b2xix\u22a4i ) , (14)\nfor some parameter \u03be > 0. Then, it holds that\nk \u2211\ni=1\nai\n[\n(viv \u22a4 i \u2212 xix\u22a4i ) \u2022 \u2207f(X) +\n\u03b7\u03b2\n2 \u2016viv\u22a4i \u2212 xix\u22a4i \u20162F\n]\n\u2264 \u2212 (f(X)\u2212 f(X\u2217))\n+\u03b7\u03b2 \u00b7min{1, 5\n\u221a\n\u221a\n2 \u03b1 rank(X\u2217) \u221a\nf(X)\u2212 f(X\u2217), 3 \u221a 2\u221a\n\u03b1\u03bbmin(X\u2217)\n\u221a\nf(X)\u2212 f(X\u2217)}+ \u03be.\nProof. For the sake of clarity, throughout the proof we treat each vi as the result of an exact eigenvector computation, i.e., we assume \u03be = 0, and at the end we discuss the effect of the approximation error in the computation of vi.\nLet w\u2217 \u2208 argminw:\u2016w\u2016=1w\u22a4\u2207f(X)w. Using the optiamlity of vi, and the fact that for every i \u2208 [k], both vi and xi are unit vectors, we have that\nk \u2211\ni=1\nai\n[\n(viv \u22a4 i \u2212 xix\u22a4i ) \u2022 \u2207f(X) +\n\u03b7\u03b2\n2 \u2016viv\u22a4i \u2212 xix\u22a4i \u20162F\n]\n\u2264\nk \u2211\ni=1\nai\n[\n(w\u2217w\u2217\u22a4 \u2212 xix\u22a4i ) \u2022 \u2207f(X) + \u03b7\u03b2 2 \u2016w\u2217w\u2217\u22a4 \u2212 xix\u22a4i \u20162F\n]\n\u2264\nk \u2211\ni=1\nai\n[ (w\u2217w\u2217\u22a4 \u2212 xix\u22a4i ) \u2022 \u2207f(X) + \u03b7\u03b2 ] =\n(w\u2217w\u2217\u22a4 \u2212X) \u2022 \u2207f(X) + \u03b7\u03b2 \u2264 (X\u2217 \u2212X) \u2022 \u2207f(X) + \u03b7\u03b2 \u2264 \u2212 (f(X)\u2212 f(X\u2217)) + \u03b7\u03b2, (15)\nwhere the third inequality follows from the optimality of w\u2217, and the last inequality follows from the convexity of f . Thus, Eq. (15) gives us the first part of the bound stated in the lemma. We now move on the prove the second part.\nFrom Lemma 4 we know we can write X\u2217 in the following way:\nX\u2217 = k \u2211\ni=1\nb\u2217iy \u2217 i y \u2217\u22a4 i +\nk \u2211\nj=1\n(a\u2217j \u2212 b\u2217j )W\u2217, (16)\nwhere for all i \u2208 [k], b\u2217i \u2208 [0, ai] and y\u2217i is a unit vector, and W\u2217 \u2208 Sd. Using again the optimality of vi for each i \u2208 [k], we have that\nk \u2211\ni=1\nai\n[\n(viv \u22a4 i \u2212 xix\u22a4i ) \u2022 \u2207f(X) +\n\u03b7\u03b2\n2 \u2016viv\u22a4i \u2212 xix\u22a4i \u20162F\n]\n\u2264\nk \u2211\ni=1\nai \u00b7min{(y\u2217i y\u2217\u22a4i \u2212 xix\u22a4i ) \u2022 \u2207f(X) + \u03b7\u03b2 2 \u2016y\u2217i y\u2217\u22a4i \u2212 xix\u22a4i \u20162F ,\n(w\u2217w\u2217\u22a4 \u2212 xix\u22a4i ) \u2022 \u2207f(X) + \u03b7\u03b2 2 \u2016w\u2217w\u2217\u22a4 \u2212 xix\u22a4i \u20162F } \u2264\nk \u2211\ni=1\nb\u2217i\n[\n(y\u2217i y \u2217\u22a4 i \u2212 xix\u22a4i ) \u2022 \u2207f(X) +\n\u03b7\u03b2\n2 \u2016y\u2217i y\u2217\u22a4i \u2212 xix\u22a4i \u20162F\n]\n+\nk \u2211\ni=1\n(ai \u2212 b\u2217i ) [ (w\u2217w\u2217\u22a4 \u2212 xix\u22a4i ) \u2022 \u2207f(X) + \u03b7\u03b2\n2 \u2016w\u2217w\u2217\u22a4 \u2212 xix\u22a4i \u20162F\n]\n\u2264 k \u2211\ni=1\nb\u2217i\n[\n(y\u2217i y \u2217\u22a4 i \u2212 xix\u22a4i ) \u2022 \u2207f(X) +\n\u03b7\u03b2\n2 \u2016y\u2217i y\u2217\u22a4i \u2212 xix\u22a4i \u20162F\n]\n+ k \u2211\ni=1\n(ai \u2212 b\u2217i ) [ (W\u2217 \u2212 xix\u22a4i ) \u2022 \u2207f(X) + \u03b7\u03b2\n2 \u2016w\u2217w\u2217\u22a4 \u2212 xix\u22a4i \u20162F\n]\n, (17)\nwhere the second inequality follows since min{a, b} \u2264 \u03bba+(1\u2212\u03bb)b for any a, b \u2208 R, \u03bb \u2208 [0, 1],\nand the third inequality follows from the optimality of w\u2217. Using Eq. (16) we have that\nRHS of (17) \u2264 (X\u2217 \u2212X) \u2022 \u2207f(X) + k \u2211\ni=1\nb\u2217i \u03b7\u03b2 2 \u2016y\u2217i y\u2217\u22a4i \u2212 xix\u22a4i \u20162F\n+ k \u2211\ni=1\n(ai \u2212 b\u2217i ) \u03b7\u03b2 2 \u2016w\u2217w\u2217\u22a4 \u2212 xix\u22a4i \u20162F\n\u2264 (X\u2217 \u2212X) \u2022 \u2207f(X) + \u03b7\u03b2 2\nk \u2211\ni=1\nb\u2217i \u2016y\u2217i y\u2217\u22a4i \u2212 xix\u22a4i \u20162F + \u03b7\u03b2 k \u2211\ni=1\n(ai \u2212 b\u2217i )\n\u2264 (X\u2217 \u2212X) \u2022 \u2207f(X) + \u03b7\u03b2 \u221a rank(X\u2217) ( \u2016X\u2217P\u22a5X\u2217,\u03c4\u2016F + \u2016X\u2212X\u2217\u2016F )\n+\u03b7\u03b2 ( \u221a rank(X\u2217) ( \u2016X\u2217P\u22a5X\u2217,\u03c4\u2016F + \u2016X\u2212X\u2217\u2016F ) + \u03b3 )\n= (X\u2217 \u2212X) \u2022 \u2207f(X) + \u03b7\u03b2 ( 2 \u221a rank(X\u2217) ( \u2016X\u2217P\u22a5X\u2217,\u03c4\u2016F + \u2016X\u2212X\u2217\u2016F ) + \u03b3 ) ,\n(18)\nwhere the last inequality follows from plugging the bounds in Lemma 4 and holds for any \u03c4, \u03b3 \u2208 [0, 1] such that \u03c4\u03b31\u2212\u03b3 \u2265 \u2016X\u2212X\u2217\u2016F .\nNow we can optimize the above bound in terms \u03c4, \u03b3 under the constraint that \u03b3\u03c41\u2212\u03b3 \u2265 \u2016X\u2212X\u2217\u2016F . One option is to upper bound \u2016X\u2217P\u22a5X\u2217,\u03c4\u2016F \u2264 \u221a rank(X\u2217)\u03c4 , which gives us\nRHS of (17) \u2264 (X\u2217 \u2212X) \u2022 \u2207f(X) + \u03b7\u03b2 ( 2 \u221a rank(X\u2217) ( \u221a rank(Y)\u03c4 + \u2016X\u2212Y\u2016F ) + \u03b3 ) .\nWe can then set:\n\u03c41 =\n\u221a\n\u2016X\u2212X\u2217\u2016F 2rank(X\u2217) , \u03b31 = \u221a 2rank(X\u2217)\u2016X\u2212X\u2217\u2016F ,\nas long as \u2016X\u2212X\u2217\u2016F \u2264 12rank(X\u2217) , which gives us:\nRHS of (17) \u2264 (X\u2217 \u2212X) \u2022 \u2207f(X) + 2\u03b7\u03b2 \u221a rank(X\u2217) ( \u221a 2\u2016X\u2212X\u2217\u2016F + \u2016X\u2212X\u2217\u2016F ) .\nNote that in order for the above bound to improve over that in Eq. (15), it indeed must in particular hold that \u2016X\u2212X\u2217\u2016F < 12rank(X\u2217) . In that case it follows that\nRHS of (17) \u2264 (X\u2217 \u2212X) \u2022 \u2207f(X) + 5\u03b7\u03b2 \u221a rank(X\u2217)\u2016X\u2212X\u2217\u2016F . (19)\nAnother option, is to choose\n\u03c42 = \u03bbmin(X \u2217), \u03b32 = \u2016X\u2212X\u2217\u2016F \u03bbmin(X\u2217) ,\nas long as \u2016X\u2212X\u2217\u2016F < \u03bbmin(X\u2217). In this case, it holds that \u2016X\u2217P\u22a5X\u2217,\u03c4\u2016F = 0. Plugging into Eq. (18) we have that\nRHS of (17) \u2264 (X\u2217 \u2212X) \u2022 \u2207f(X) + \u03b7\u03b2\u2016X\u2212X\u2217\u2016F ( 2 \u221a rank(X\u2217) + 1\n\u03bbmin(X\u2217)\n)\n.\nNote that since X\u2217 \u2208 Sd it holds thst \u03bbmin(X\u2217)\u22121 \u2265 rank(X\u2217) and thus we have that\nRHS of (17) \u2264 (X\u2217 \u2212X) \u2022 \u2207f(X) + 3\u03b7\u03b2\u2016X\u2212X \u2217\u2016F\n\u03bbmin(X\u2217) . (20)\nNote that here also, the above bound improves over the one in Eq. (15) only when indeed \u2016X\u2212X\u2217\u2016F < \u03bbmin(X\u2217).\nNow, by using the convexity of f to upper bound (X\u2217 \u2212X) \u2022 \u2207f(X) \u2264 \u2212(f(X) \u2212 f(X\u2217)) and Eq. (1) to upper bound \u2016X\u2212X\u2217\u2016F \u2264 \u221a 2 \u03b1(f(X)\u2212 f(X\u2217) in both Eq. (19) and (20), gives the rest of the bound in the lemma. By going through the analysis above again (basically Eq. (15) and Eq. (17)), it\u2019s clear that an \u03be additive error in the computation of each eigenvector vi results in a single additive term \u03be in all of the above bounds, and hence the lemma follows.\nLemma 6. [randomized update] Consider an iteration t of Algorithm 2. Fix a step-size \u03b7t and assume that the iterate of the algorithm on this iteration is feasible and given in the following explicit form: Xt = \u2211k i=1 aixix \u22a4 i , where each xi is a unit vector, and (a1, ..., ak) is a distribution over [k]. Further, suppose that each ai satisfies that ai \u2265 \u03b7t/2. Then,\nE[ht+1] \u2264 ( 1\u2212 \u03b7t 2 ) E[ht] + \u03b72t \u03b2 2 min{1,\n5 \u221a\u221a 2rank(X\u2217)\n\u03b11/4 E[ht]\n1/4, 3 \u221a 2\u221a\n\u03b1\u03bbmin(X\u2217) E[ht]\n1/2}+ \u03b7t\u03bet,\nwhere \u2200t \u2265 1 ht := f(Xt)\u2212 f(X\u2217). Proof. Using the update step of Algorithm 2 we have that\nht+1 = f(Xt+1)\u2212 f(X\u2217) = f(Xt + \u03b7\u0303t(vtv\u22a4t \u2212 xitxit))\u2212 f(X\u2217)\n\u2264 f(Xt)\u2212 f(X\u2217) + \u03b7\u0303t(vtv\u22a4t \u2212 xitxit) \u2022 \u2207f(Xt) + \u03b7\u03032t \u03b2\n2 \u2016vtv\u22a4t \u2212 xitxit\u20162F\n\u2264 ht + \u03b7\u0303t [ (vtv \u22a4 t \u2212 xitxit) \u2022 \u2207f(Xt) + \u03b7t\u03b2\n2 \u2016vtv\u22a4t \u2212 xitxit\u20162F\n]\n,\nwhere the first inequality follows from the smoothness of f and the second one follows since by definition, \u03b7t \u2265 \u03b7\u0303t.\nBy the choice of vt we have that\n(vtv \u22a4 t \u2212 xitxit) \u2022 \u2207f(Xt) +\n\u03b72t \u03b2\n2 \u2016vtv\u22a4t \u2212 xitxit\u20162F \u2264 \u03bet, (21)\nand thus, since by our assumption on {ai}i\u2208[k], it also holds that \u03b7\u0303t \u2265 \u03b7t/2, we have that\nht+1 \u2264 ht + \u03b7t 2\n[\n(vtv \u22a4 t \u2212 xitxit) \u2022 \u2207f(Xt) +\n\u03b7t\u03b2\n2 \u2016vtv\u22a4t \u2212 xitxit\u20162F\n]\n+ ( \u03b7\u0303t \u2212 \u03b7t 2 ) \u03bet\n\u2264 ht + \u03b7t 2\n[\n(vtv \u22a4 t \u2212 xitxit) \u2022 \u2207f(Xt) +\n\u03b7t\u03b2\n2 \u2016vtv\u22a4t \u2212 xitxit\u20162F\n]\n+ \u03b7t 2 \u03bet, (22)\nwhere the last inequality follows again by using \u03b7t \u2265 \u03b7\u0303t. Taking expectation over the random choice of it in Eq. (22), and plugging Lemma 5, we have that\nEit [ht+1 |Xt] \u2264 ht \u2212 \u03b7t 2 ht +\n\u03b72t \u03b2\n2 min{1,\n5 \u221a\u221a 2rank(X\u2217)\n\u03b11/4 h 1/4 t ,\n3 \u221a 2\u221a\n\u03b1\u03bbmin(X\u2217) h 1/2 t }+ \u03b7t 2 \u03bet + \u03b7t 2 \u03bet.\nTaking expectation over the randomness introduced on iterations 1, ..., t\u22121 we have that\nE[ht+1] \u2264 ( 1\u2212 \u03b7t 2 ) E[ht] + \u03b72t \u03b2 2 min{1,\n5 \u221a\u221a 2rank(X\u2217)\n\u03b11/4 E[h\n1/4 t ],\n3 \u221a 2\u221a\n\u03b1\u03bbmin(X\u2217) E[h\n1/2 t ]}+ \u03b7t\u03bet\n\u2264 ( 1\u2212 \u03b7t 2 ) E[ht] + \u03b72t \u03b2 2 min{1,\n5 \u221a\u221a 2rank(X\u2217)\n\u03b11/4 E[ht]\n1/4, 3 \u221a 2\u221a\n\u03b1\u03bbmin(X\u2217) E[ht]\n1/2}+ \u03b7t\u03bet,\nwhere the first inequality follows since the function f(x, y, z) = min{x, y, z} is concave, and thus the inequality follows from applying Jensen\u2019s inequality. Similarly, the second inequality follows since both functions g(x) = x1/4, q(x) = x1/2 are also concave on (0,\u221e)."}, {"heading": "4.3 Proof of Theorem 1", "text": "We can now turn to prove our main theorem, Theorem 1. The proof follows from deriving each one of the convergence rates in the theorem independently using the result of Lemma 6. This is done in the following Lemmas 7,8, 9. We then show that there exists a choice of step-size sequence and error-tolerance bounds for the eigenvector computations that satisfy all lemmas at once, and thus the theorem is obtained.\nLemma 7. Let C,t0 be non-negative scalars that satisfy:\nC \u2265 18, C 2 \u2212 1 \u2265 t0 \u2265 C 6 \u2212 1.\nThen if for all t \u2265 1 we define \u03b7t = C3(t+t0) , and we set \u03be0 = \u03b2 and \u2200t \u2265 1 : \u03bet = \u03b2C 6(t+t0) , it follows that all iterates of Algorithm 2 are feasible, and\n\u2200t \u2265 1 : E[ht] \u2264 \u03b2C\nt+ t0 .\nProof. From Lemma 6 we have that for all t \u2265 1,\n\u2200t \u2265 1 : E[ht+1] \u2264 ( 1\u2212 \u03b7t 2 ) E[ht] + \u03b72t \u03b2 2 + \u03b7t\u03bet.\nWe are going to assume throughout the proof that \u03bet \u2264 E[ht]/6. It thus follows that\n\u2200t \u2265 1 : E[ht+1] \u2264 ( 1\u2212 \u03b7t 3 ) E[ht] + \u03b72t \u03b2 2 . (23)\nFor all t \u2265 1, define vt := \u03b2\u22121E[ht]. Dividing both sides of Eq. (23) by \u03b2, we have that\n\u2200t \u2265 1 : vt+1 \u2264 ( 1\u2212 \u03b7t 3 ) vt + \u03b72t 2 . (24)\nWe are going to prove by induction on t that vt \u2264 Ct+t0 for suitable valus of C, t0 and a sequence of step-sizes {\u03b7t}t\u22651. Obviously for the base case t = 1 to hold, we must restrict C\nt0+1 \u2265 v1.\nLet us assume now that the induction hypothesis holds for some t \u2265 1. Setting \u03b7t =\nC 3(t+t0) in Eq. (24) we have that\nvt+1 \u2264 vt ( 1\u2212 C 9(t+ t0) ) + C2 18(t+ t0)2 \u2264 C t+ t0 ( 1\u2212 C 9(t+ t0) ) + C2 18(t+ t0)2\n= C\nt+ t0\n(\n1\u2212 C 18(t+ t0)\n)\n= C\nt+ t0 + 1\n(\n1 + 1\nt+ t0\n)(\n1\u2212 C 18(t+ t0)\n)\n.\nThus, choosing C \u2265 18 gives:\nvt+1 \u2264 C\nt+ 1 + t0\n(\n1 + 1\nt+ t0\n)(\n1\u2212 1 t+ t0\n)\n< C\nt+ 1 + t0\nas needed.\nWe can now set values for C, t0 under the constraints that\ni. C \u2265 18, ii. C t0 + 1 \u2265 v1, iii.\u2200t \u2265 1 : \u03b7t = C 3(t+ t0) \u2208 [0, 2]. (25)\nIn order for our choice of step-sizes to satisfy the conditions of Observation 1, it must hold that {\u03b7t}t\u22651 \u2282 [0, 2]. Since by definition this sequence is monotonic decreasing it suffices to show it for \u03b71. Thus we must require that\nC 3(1+t0) \u2264 2, which gives us the constraint t0 \u2265 C6 \u2212 1. It remains to deal with base case of the induction, i.e., we need to show that v1 = \u03b2\n\u22121h1 \u2264 C\n1+t0 for our choice of C, t0.\nRecall that according to Algorithm 2 it holds thatX1 = x1x \u22a4 1 , such that x1 = EV(\u2207f(x0x\u22a40 )),\nwhere x0 is some unit vector. Using the smoothness of f we have that\nh1 = f(x1x \u22a4 1 )\u2212 f(X\u2217) = f(x0x\u22a40 + x1x\u22a41 \u2212 x0x\u22a40 )\u2212 f(X\u2217)\n\u2264 f(x0x\u22a40 )\u2212 f(X\u2217) + (x1x\u22a41 \u2212 x0x\u22a40 ) \u2022 \u2207f(x0x\u22a40 ) + \u03b2 2 \u2016x1x\u22a41 \u2212 x0x\u22a40 \u20162F \u2264 f(x0x\u22a40 )\u2212 f(X\u2217) + (X\u2217 \u2212 x0x\u22a40 ) \u2022 \u2207f(x0x\u22a40 ) + \u03b2\n2 \u2016x1x\u22a41 \u2212 x0x\u22a40 \u20162F + \u03be0\n\u2264 \u03b2 2 \u2016x1x\u22a41 \u2212 x0x\u22a40 \u20162F + \u03be0 \u2264 \u03b2 + \u03be0, (26)\nwhere the second inequality follows from the choice of x1, and the third inequality follows from the convexity of f(X).\nSetting \u03be0 = \u03b2, it follows that\nv1 \u2264 \u03b2\u22121 \u00b7 2\u03b2 = 2.\nThus we must require that C1+t0 \u2265 2, which gives us the constraint t0 \u2264 C 2 \u2212 1.\nThus, the conditions in Eq. (25) boils down to the following constraints:\nC \u2265 18, C 2 \u2212 1 \u2265 t0 \u2265 C 6 \u2212 1.\nFor C, t0 that indeed satisfy these constraints we can thus conclude that\n\u2200t \u2265 1 : E[ht] \u2264 \u03b2vt \u2264 \u03b2C\nt+ t0 .\nLemma 8. Let C,t0 be non-negative scalars that satisfy:\nC \u2265 304/3, C3/4 \u2212 1 \u2265 t0 \u2265 C3/4\n6 \u2212 1.\nThen if for all t \u2265 1 we define \u03b7t = C 3/4 3(t+t0) , and set \u03be0 = \u03b2, \u2200t \u2265 1 : \u03bet = 16\n( 5C3/4\u03b2 \u221a\u221a 2rank(X\u2217)\n\u03b11/4(t+t0)\n)4/3\n,\nit follows that all iterates of Algorithm 2 are feasible, and\n\u2200t \u2265 1 : E[ht] \u2264\n\n\n5C3/4\u03b2 \u221a\u221a 2rank(X\u2217)\n\u03b11/4(t+ t0)\n\n\n4/3\n.\nProof. From Lemma 6 we have that for all t \u2265 1,\n\u2200t \u2265 1 : E[ht+1] \u2264 ( 1\u2212 \u03b7t 2 )\nE[ht] + 5\u03b72t \u03b2\n\u221a\u221a 2rank(X\u2217)\n2\u03b11/4 E[ht]\n1/4 + \u03b7t\u03bet.\nWe are going to assume throughout the proof that \u03bet \u2264 E[ht]/6. It thus follows that\n\u2200t \u2265 1 : E[ht+1] \u2264 ( 1\u2212 \u03b7t 3 )\nE[ht] + 5\u03b72t \u03b2\n\u221a\u221a 2rank(X\u2217)\n2\u03b11/4 E[ht]\n1/4. (27)\nFor all t \u2265 1, define vt := (\n5 \u221a\u221a 2rank(X\u2217)\u03b2\n\u03b11/4\n)\u22124/3 E[ht]. Dividing both sides of Eq. (27) by\n( 5 \u221a\u221a 2rank(X\u2217)\u03b2\n\u03b11/4\n)4/3\n, we have that\n\u2200t \u2265 1 : vt+1 \u2264 ( 1\u2212 \u03b7t 3 ) vt + \u03b72t 2 v 1/4 t . (28)\nWe are going to prove by induction on t that vt \u2264 C(t+t0)4/3 for suitable valus of C, t0 and a sequence of step-sizes {\u03b7t}t\u22651. Obviously for the base case t = 1 to hold, we must restrict\nC (t0+1)4/3 \u2265 v1. Let us assume now that the induction hypothesis holds for some t \u2265 1. Setting \u03b7t = C3/4\n3(t+t0) in Eq. (28) we have that\nvt+1 \u2264 vt ( 1\u2212 C 3/4\n9(t+ t0)\n)\n+ C3/2\n18(t + t0)2 v 1/4 t\n\u2264 C (t+ t0)4/3\n(\n1\u2212 C 3/4\n9(t+ t0)\n)\n+ C7/4\n18(t + t0)7/3\n= C\n(t+ t0)4/3\n(\n1\u2212 C 3/4\n18(t+ t0)\n)\n= C\n(t+ 1 + t0)4/3\n(\n1 + 1\nt+ t0\n)4/3 (\n1\u2212 C 3/4\n18(t + t0)\n)\n= C\n(t+ 1 + t0)4/3\n(\n1 + 1\nt+ t0\n)(\n1 + 1\nt+ t0\n)1/3 (\n1\u2212 C 3/4\n18(t+ t0)\n)\nThe single variable function g(x) = x1/3 is concave on (0,\u221e), and thus, g(1 + x) \u2264 g(1) + g\u2032(1) \u00b7 x = 1 + x3 . Using this fact, we have that\nvt+1 \u2264 C\n(t+ 1 + t0)4/3\n(\n1 + 1\nt+ t0\n)(\n1 + 1\n3(t+ t0)\n)\n(\n1\u2212 C 3/4\n18(t + t0)\n)\n< C\n(t+ 1 + t0)4/3\n(\n1 + 5\n3(t+ t0)\n)\n(\n1\u2212 C 3/4\n18(t+ t0)\n)\n.\nThus, choosing C \u2265 (90/3)4/3 gives:\nvt+1 \u2264 C\n(t+ 1 + t0)4/3\n(\n1 + 5\n3(t+ t0)\n)(\n1\u2212 5 3(t+ t0)\n)\n< C\n(t+ 1 + t0)4/3 ,\nas needed. We can now set values for C, t0 under the constraints that\ni. C \u2265 304/3, ii. C (t0 + 1)4/3 \u2265 v1, iii.\u2200t \u2265 1 : \u03b7t = C3/4 3(t+ t0) \u2208 [0, 2]. (29)\nAs in the proof of Lemma 7 it follows that constraining t0 \u2265 C 3/4 6 \u22121, will result in step-sizes that satisfy the conditions of Observation 1.\nMoving to deal with the base case of the induction, again similarly to Lemma 7, we have that\nv1 =\n\n\n\u03b11/4\n5\u03b2 \u221a\u221a 2rank(X\u2217)\n\n\n4/3\nh1 \u2264\n\n\n\u03b11/4\n5\u03b2 \u221a\u221a 2rank(X\u2217)\n\n\n4/3\n\u00b7 2\u03b2\n=\n( \u221a 2\u03b11/4\n5\u03b21/4 \u221a rank(X\u2217)\n)4/3\n< 1,\nwhere the inequality follows since \u03b1 \u2264 \u03b2. Thus we must require that C (1+t0)4/3 \u2265 1, which gives us the constraint t0 \u2264 C3/4 \u2212 1.\nThus, the conditions in Eq. (29) boils down to the following constraints:\nC \u2265 304/3, C3/4 \u2212 1 \u2265 t0 \u2265 C3/4\n6 \u2212 1.\nFor C, t0 that indeed satisfy these constraints we can thus conclude that\n\u2200t \u2265 1 : E[ht] \u2264 ( 5\u03b2 \u221a rank(X\u2217) 23/4\u03b11/4\n)4/3\nvt \u2264 ( 5C3/4\u03b2 \u221a rank(X\u2217) 23/4\u03b11/4(t+ t0)\n)4/3\n.\nLemma 9. Let C,t0 be non-negative scalars that satisfy:\nC \u2265 2916, C1/2 \u2212 1 \u2265 t0 \u2265 C1/2\n6 \u2212 1.\nThen if for all t \u2265 1 we define \u03b7t = C 1/2 3(t+t0) and \u03be0 = \u03b2, \u2200t \u2265 1 : \u03bet = 16\n( 3 \u221a 2C\u03b2\u221a\n\u03b1\u03bbmin(X\u2217)(t+t0)\n)2 , it\nfollows that all iterates of Algorithm 2 are feasible, and\n\u2200t \u2265 1 : E[ht] \u2264 ( 3 \u221a 2C\u03b2\u221a\n\u03b1\u03bbmin(X\u2217)(t+ t0)\n)2\n.\nProof. From Lemma 6 we have that for all t \u2265 1,\n\u2200t \u2265 1 : E[ht+1] \u2264 ( 1\u2212 \u03b7t 2 )\nE[ht] + 3 \u221a 2\u03b72t \u03b2\n2 \u221a \u03b1\u03bbmin(X\u2217) E[ht] 1/2 + \u03b7t\u03bet.\nWe are going to assume throughout the proof that \u03bet \u2264 E[ht]/6. It thus follows that\n\u2200t \u2265 1 : E[ht+1] \u2264 ( 1\u2212 \u03b7t 3 )\nE[ht] + 3 \u221a 2\u03b72t \u03b2\n2 \u221a \u03b1\u03bbmin(X\u2217) E[ht] 1/2. (30)\nFor all t \u2265 1, define vt := (\n3 \u221a 2\u03b2\u221a\n\u03b1\u03bbmin(X\u2217)\n)\u22122 E[ht]. Dividing both sides of Eq. (27) by ( 3 \u221a 2\u03b2\u221a\n\u03b1\u03bbmin(X\u2217)\n)2 ,\nwe have that\n\u2200t \u2265 1 : vt+1 \u2264 ( 1\u2212 \u03b7t 3 ) vt + \u03b72t 2 v 1/2 t . (31)\nWe are going to prove by induction on t that vt \u2264 C(t+t0)2 for suitable valus of C, t0 and a sequence of step-sizes {\u03b7t}t\u22651. Obviously for the base case t = 1 to hold, we must restrict\nC (t0+1)2 \u2265 v1. Let us assume now that the induction hypothesis holds for some t \u2265 1. Setting \u03b7t = C1/2\n3(t+t0) in Eq. (28) we have that\nvt+1 \u2264 vt ( 1\u2212 C 1/2\n9(t+ t0)\n)\n+ C\n18(t+ t0)2 v 1/2 t\n\u2264 C (t+ t0)2\n(\n1\u2212 C 1/2\n9(t+ t0)\n)\n+ C3/2\n18(t+ t0)3\n= C\n(t+ 1 + t0)2\n(\n1 + 1\nt+ t0\n)2 (\n1\u2212 C 1/2\n18(t+ t0)\n)\n\u2264 C (t+ 1 + t0)2\n(\n1 + 3\nt+ t0\n)\n(\n1\u2212 C 1/2\n18(t+ t0)\n)\nThus, choosing C \u2265 2916 gives:\nvt+1 \u2264 C\n(t+ 1 + t0)2\n(\n1 + 3\nt+ t0\n)(\n1\u2212 3 t+ t0\n)\n< C\n(t+ 1 + t0)2 ,\nas needed. We can now set values for C, t0 under the constraints that\ni. C \u2265 2916 ii. C (t0 + 1)2 \u2265 v1, iii.\u2200t \u2265 1 : \u03b7t = C1/2 3(t+ t0) \u2208 [0, 2]. (32)\nAs in Lemma 7, it follows that in order for our step-sizes satisfy the conditions of Observation\n1, we need to require that t0 \u2265 C 1/2 6 \u2212 1. Also, for the base case of the induction, also similarly to Lemma 7, it holds that\nv1 \u2264 (\u221a \u03b1\u03bbmin(X \u2217)\n3 \u221a 2\u03b2\n)2 \u00b7 2\u03b2 = (\u221a 2\u03b1\u03bbmin(X \u2217)\n3 \u221a 2 \u221a \u03b2\n)2\n< 1\nwhere the second inequality follows since \u03b1 \u2264 \u03b2 and \u03bbmin(X\u2217) \u2264 1. Thus in order to satisfy the constraint v1 \u2264 C(t0+1)2 , it suffices to require t0 \u2264 \u221a C \u2212 1.\nThus, the conditions in Eq. (29) boils down to the following constraints:\nC \u2265 2916, C1/2 \u2212 1 \u2265 t0 \u2265 C1/2\n6 \u2212 1.\nFor C, t0 that indeed satisfy these constraints we can thus conclude that We can thus conclude that\n\u2200t \u2265 1 : E[ht] \u2264 ( 3 \u221a 2\u03b2\u221a\n\u03b1\u03bbmin(X\u2217)\n)2 vt \u2264 ( 3 \u221a 2C\u03b2\u221a\n\u03b1\u03bbmin(X\u2217)(t+ t0)\n)2\n.\nWe can now finally wrap-up the proof of Theorem 1.\nProof. The proof is an immediate consequence of Lemmas 7, 8, 9, and the observation that the step-size \u03b7t = 54 3(t+8) = 18 t+8 , which implicitly sets t0 = 8 in all of above lemmas and corresponds to setting C = 54 for Lemma 7, C = 544/3 in Lemma 8, and C = 2916 in Lemma 9, satisfies all lemmas together."}, {"heading": "5 Preliminary Empirical Evaluation", "text": "In this section we provide preliminary empirical evaluation of our approach. We evaluate our method, along with other conditional gradient variants, on the task of matrix completion. For a detailed presentation of the setting and the application of the conditional gradient method to this problem, we refer the reader to [17].\nSetting The underlying optimization problem for the matrix completion task is the following:\nmin Z\u2208NBd1,d2(\u03b8)\n{f(Z) := 1 2\nn \u2211\nl=1\n(Z \u2022Eil,jl \u2212 rl)2}, (33)\nwhere Ei,j is the indicator matrix for the entry (i, j) in R d1\u00d7d2 , and {(il, jl, rl)}nl=1 \u2282 [d1] \u00d7 [d2] \u00d7 R. That is, our goal is to find a matrix with bounded nuclear norm (which serves as a convex surrogate for bounded rank) which matches best the partial observations given by {(il, jl, rl)}nl=1.\nSince the feasible set is the nuclear ball, we use the reduction specified in Subsection 2.2 to transform it to optimization over the spectrahedron.\nThe objective function in Eq. (33) is known to have a smoothness parameter \u03b2 with respect to \u2016 \u00b7 \u2016F , which satisfies \u03b2 = O(1), see for instance [17]. While the objective function in Eq. (33) is not strongly convex, it is known that under certain conditions, the matrix completion problem exhibit proprieties very similar to strong convexity, in the sense of Eq. (1) (which is indeed the only consequence of strong convexity that we use in our analysis), known as restricted strong convexity [26].\nTwo modifications of Algorithm 2 We implemented our rank-one-regularized conditional gradient variant, Algorithm 2 (denoted ROR-CG in our figures) with two modifications. First, on each iteration t, instead of picking an index it of a rank-one matrix in the decomposition of the current iterate at random according to the distribution (a1, a2, ..., ak), we choose it in a greedy way, i.e., we choose the rank-one component that has the largest product with the current gradient direction. While this approach is computationally more expensive, it could be easily parallelized since all dot-product computations are independent of each other. Second, after computing the eigenvector vt using the choice of \u03b7t prescribed in Theorem 1, we apply a line-search, as detailed in [17], in order to the determine the optimal step-size given the direction vtv \u22a4 t \u2212 xitx\u22a4it .\nBaselines As baselines for comparison we used the standard conditional gradient method with exact line-search for setting the step-size (denoted CG in our figures)[17], and the conditional gradient with away-steps variant, recently studied in [20, 1, 21] (denoted Away-CG in our figures). While the away-steps variant was studied in the context of optimization over polyhedral sets, and its formal improved guarantees apply only in that setting, the concept of away-steps still makes sense for any convex feasible set. This variant also allows the incorporation of an exact line-search procedure to choose the optimal step-size.\nDatasets We have experimented with two well known datasets for the matrix completion task: the MovieLens100k dataset for which d1 = 943, d2 = 1682, n = 10\n5, and the MovieLens1M dataset for which d1 = 6040, d2 = 3952, n \u2248 106. The MovieLens1M dataset was further sub-sampled to contain roughly half of the observations. We have set the parameter \u03b8 in Problem (33) to \u03b8 = 10000 for the ML100k dataset, and \u03b8 = 30000 for the ML1M dataset.\nFigure 1 presents the objective (33) vs. the number of iterations executed, for all methods, on both datasets. Each graph is the average over 5 independent experiments 2. It can be seen that our approach indeed improves significantly over the baselines in terms of convergence rate, for the setting under consideration."}], "references": [{"title": "Linearly convergent away-step conditional gradient for non-strongly convex functions", "author": ["Amir Beck", "Shimrit Shtern"], "venue": "arXiv preprint arXiv:1504.05002,", "citeRegEx": "1", "shortCiteRegEx": "1", "year": 2015}, {"title": "Exact matrix completion via convex optimization", "author": ["Emmanuel J Cand\u00e8s", "Benjamin Recht"], "venue": "Foundations of Computational mathematics,", "citeRegEx": "2", "shortCiteRegEx": "2", "year": 2009}, {"title": "Lifted coordinate descent for learning with trace-norm regularization", "author": ["Miroslav Dud\u0301\u0131k", "Z\u00e4\u0131d Harchaoui", "J\u00e9r\u00f4me Malick"], "venue": "Journal of Machine Learning Research - Proceedings Track,", "citeRegEx": "3", "shortCiteRegEx": "3", "year": 2012}, {"title": "An algorithm for quadratic programming", "author": ["M. Frank", "P. Wolfe"], "venue": "Naval Research Logistics Quarterly,", "citeRegEx": "4", "shortCiteRegEx": "4", "year": 1956}, {"title": "An extended frank-wolfe method with\u201d in-face\u201d directions, and its application to low-rank matrix completion", "author": ["Robert M Freund", "Paul Grigas", "Rahul Mazumder"], "venue": "arXiv preprint arXiv:1511.02204,", "citeRegEx": "5", "shortCiteRegEx": "5", "year": 2015}, {"title": "A linearly convergent conditional gradient algorithm with applications to online and stochastic optimization", "author": ["Dan Garber", "Elad Hazan"], "venue": "CoRR, abs/1301.4666,", "citeRegEx": "6", "shortCiteRegEx": "6", "year": 2013}, {"title": "Playing non-linear games with linear oracles", "author": ["Dan Garber", "Elad Hazan"], "venue": "In 54th Annual IEEE Symposium on Foundations of Computer Science,", "citeRegEx": "7", "shortCiteRegEx": "7", "year": 2013}, {"title": "Fast and simple pca via convex optimization", "author": ["Dan Garber", "Elad Hazan"], "venue": "arXiv preprint arXiv:1509.05647,", "citeRegEx": "8", "shortCiteRegEx": "8", "year": 2015}, {"title": "Faster rates for the frank-wolfe method over strongly-convex sets", "author": ["Dan Garber", "Elad Hazan"], "venue": "In Proceedings of the 32nd International Conference on Machine Learning,ICML,", "citeRegEx": "9", "shortCiteRegEx": "9", "year": 2015}, {"title": "Multiple kernel learning algorithms", "author": ["Mehmet G\u00f6nen", "Ethem Alpayd\u0131n"], "venue": "The Journal of Machine Learning Research,", "citeRegEx": "10", "shortCiteRegEx": "10", "year": 2011}, {"title": "Large-scale image classification with trace-norm regularization", "author": ["Z\u00e4\u0131d Harchaoui", "Matthijs Douze", "Mattis Paulin", "Miroslav Dud\u0301\u0131k", "J\u00e9r\u00f4me Malick"], "venue": "In IEEE Conference on Computer Vision and Pattern Recognition,", "citeRegEx": "11", "shortCiteRegEx": "11", "year": 2012}, {"title": "Sparse approximate solutions to semidefinite programs", "author": ["Elad Hazan"], "venue": "In 8th Latin American Theoretical Informatics Symposium, LATIN,", "citeRegEx": "12", "shortCiteRegEx": "12", "year": 2008}, {"title": "Projection-free online learning", "author": ["Elad Hazan", "Satyen Kale"], "venue": "In Proceedings of the 29th International Conference on Machine Learning,", "citeRegEx": "13", "shortCiteRegEx": "13", "year": 2012}, {"title": "Variance-reduced and projection-free stochastic optimization", "author": ["Elad Hazan", "Haipeng Luo"], "venue": "CoRR, abs/1602.02101,", "citeRegEx": "14", "shortCiteRegEx": "14", "year": 2016}, {"title": "Convex optimization without projection", "author": ["Martin Jaggi"], "venue": "steps. CoRR,", "citeRegEx": "15", "shortCiteRegEx": "15", "year": 2011}, {"title": "Revisiting frank-wolfe: Projection-free sparse convex optimization", "author": ["Martin Jaggi"], "venue": "In Proceedings of the 30th International Conference on Machine Learning,", "citeRegEx": "16", "shortCiteRegEx": "16", "year": 2013}, {"title": "Sulovsk\u00fd. A simple algorithm for nuclear norm regularized problems", "author": ["Martin Jaggi", "Marek"], "venue": "In Proceedings of the 27th International Conference on Machine Learning,", "citeRegEx": "17", "shortCiteRegEx": "17", "year": 2010}, {"title": "Robust shift-and-invert preconditioning: Faster and more sample efficient algorithms for eigenvector computation", "author": ["Chi Jin", "Sham M Kakade", "Cameron Musco", "Praneeth Netrapalli", "Aaron Sidford"], "venue": "arXiv preprint arXiv:1510.08896,", "citeRegEx": "18", "shortCiteRegEx": "18", "year": 2015}, {"title": "Estimating the largest eigenvalues by the power and lanczos algorithms with a random start", "author": ["J. Kuczy\u0144ski", "H. Wo\u017aniakowski"], "venue": "SIAM J. Matrix Anal. Appl.,", "citeRegEx": "19", "shortCiteRegEx": "19", "year": 1992}, {"title": "An affine invariant linear convergence analysis for frank-wolfe algorithms", "author": ["Simon Lacoste-Julien", "Martin Jaggi"], "venue": "CoRR, abs/1312.7864,", "citeRegEx": "20", "shortCiteRegEx": "20", "year": 2013}, {"title": "On the global linear convergence of Frank-Wolfe optimization variants", "author": ["Simon Lacoste-Julien", "Martin Jaggi"], "venue": "In Advances in Neural Information Processing Systems,", "citeRegEx": "21", "shortCiteRegEx": "21", "year": 2015}, {"title": "Conditional gradient sliding for convex optimization", "author": ["Guanghui Lan", "Yi Zhou"], "venue": "Technical report, Technical Report,", "citeRegEx": "22", "shortCiteRegEx": "22", "year": 2014}, {"title": "Learning the kernel matrix with semidefinite programming", "author": ["Gert RG Lanckriet", "Nello Cristianini", "Peter Bartlett", "Laurent El Ghaoui", "Michael I Jordan"], "venue": "The Journal of Machine Learning Research,", "citeRegEx": "23", "shortCiteRegEx": "23", "year": 2004}, {"title": "A hybrid algorithm for convex semidefinite optimization", "author": ["S\u00f6ren Laue"], "venue": "In Proceedings of the 29th International Conference on Machine Learning,", "citeRegEx": "24", "shortCiteRegEx": "24", "year": 2012}, {"title": "Constrained minimization methods", "author": ["Evgeny S Levitin", "Boris T Polyak"], "venue": "USSR Computational mathematics and mathematical physics,", "citeRegEx": "25", "shortCiteRegEx": "25", "year": 1966}, {"title": "A unified framework for high-dimensional analysis of m-estimators with decomposable regularizers", "author": ["Sahand Negahban", "Bin Yu", "Martin J Wainwright", "Pradeep K. Ravikumar"], "venue": "Advances in Neural Information Processing Systems", "citeRegEx": "26", "shortCiteRegEx": "26", "year": 2009}, {"title": "Introductory lectures on convex optimization: A basic course, volume 87", "author": ["Yurii Nesterov"], "venue": "Springer Science & Business Media,", "citeRegEx": "27", "shortCiteRegEx": "27", "year": 2013}, {"title": "A simpler approach to matrix completion", "author": ["Benjamin Recht"], "venue": "The Journal of Machine Learning Research,", "citeRegEx": "28", "shortCiteRegEx": "28", "year": 2011}, {"title": "Large-scale convex minimization with a low-rank constraint", "author": ["Shai Shalev-Shwartz", "Alon Gonen", "Ohad Shamir"], "venue": "In Proceedings of the 28th International Conference on Machine Learning,", "citeRegEx": "29", "shortCiteRegEx": "29", "year": 2011}, {"title": "A stochastic PCA and SVD algorithm with an exponential convergence rate", "author": ["Ohad Shamir"], "venue": "In Proceedings of the 32nd International Conference on Machine Learning,", "citeRegEx": "30", "shortCiteRegEx": "30", "year": 2015}, {"title": "Distance metric learning for large margin nearest neighbor classification", "author": ["Kilian Q Weinberger", "John Blitzer", "Lawrence K Saul"], "venue": "In Advances in neural information processing systems,", "citeRegEx": "31", "shortCiteRegEx": "31", "year": 2005}, {"title": "Distance metric learning with application to clustering with side-information", "author": ["Eric P Xing", "Andrew Y Ng", "Michael I Jordan", "Stuart Russell"], "venue": "Advances in neural information processing systems,", "citeRegEx": "32", "shortCiteRegEx": "32", "year": 2003}, {"title": "Distance metric learning with eigenvalue optimization", "author": ["Yiming Ying", "Peng Li"], "venue": "J. Mach. Learn. Res.,", "citeRegEx": "33", "shortCiteRegEx": "33", "year": 2012}, {"title": "Accelerated training for matrixnorm regularization: A boosting approach", "author": ["Xinhua Zhang", "Dale Schuurmans", "Yao-liang Yu"], "venue": "In Advances in Neural Information Processing Systems,", "citeRegEx": "34", "shortCiteRegEx": "34", "year": 2012}], "referenceMentions": [{"referenceID": 1, "context": "1 Introduction Minimizing a convex function over the set of positive semidefinite matrices with unit trace, aka the spectrahedron, is an important optimization task which lies at the heart of many optimization, machine learning, and signal processing tasks such as matrix completion [2, 28, 17], metric learning [32, 31, 33], kernel matrix learning [23, 10], multiclass classification [3, 34, 14], and more.", "startOffset": 283, "endOffset": 294}, {"referenceID": 27, "context": "1 Introduction Minimizing a convex function over the set of positive semidefinite matrices with unit trace, aka the spectrahedron, is an important optimization task which lies at the heart of many optimization, machine learning, and signal processing tasks such as matrix completion [2, 28, 17], metric learning [32, 31, 33], kernel matrix learning [23, 10], multiclass classification [3, 34, 14], and more.", "startOffset": 283, "endOffset": 294}, {"referenceID": 16, "context": "1 Introduction Minimizing a convex function over the set of positive semidefinite matrices with unit trace, aka the spectrahedron, is an important optimization task which lies at the heart of many optimization, machine learning, and signal processing tasks such as matrix completion [2, 28, 17], metric learning [32, 31, 33], kernel matrix learning [23, 10], multiclass classification [3, 34, 14], and more.", "startOffset": 283, "endOffset": 294}, {"referenceID": 31, "context": "1 Introduction Minimizing a convex function over the set of positive semidefinite matrices with unit trace, aka the spectrahedron, is an important optimization task which lies at the heart of many optimization, machine learning, and signal processing tasks such as matrix completion [2, 28, 17], metric learning [32, 31, 33], kernel matrix learning [23, 10], multiclass classification [3, 34, 14], and more.", "startOffset": 312, "endOffset": 324}, {"referenceID": 30, "context": "1 Introduction Minimizing a convex function over the set of positive semidefinite matrices with unit trace, aka the spectrahedron, is an important optimization task which lies at the heart of many optimization, machine learning, and signal processing tasks such as matrix completion [2, 28, 17], metric learning [32, 31, 33], kernel matrix learning [23, 10], multiclass classification [3, 34, 14], and more.", "startOffset": 312, "endOffset": 324}, {"referenceID": 32, "context": "1 Introduction Minimizing a convex function over the set of positive semidefinite matrices with unit trace, aka the spectrahedron, is an important optimization task which lies at the heart of many optimization, machine learning, and signal processing tasks such as matrix completion [2, 28, 17], metric learning [32, 31, 33], kernel matrix learning [23, 10], multiclass classification [3, 34, 14], and more.", "startOffset": 312, "endOffset": 324}, {"referenceID": 22, "context": "1 Introduction Minimizing a convex function over the set of positive semidefinite matrices with unit trace, aka the spectrahedron, is an important optimization task which lies at the heart of many optimization, machine learning, and signal processing tasks such as matrix completion [2, 28, 17], metric learning [32, 31, 33], kernel matrix learning [23, 10], multiclass classification [3, 34, 14], and more.", "startOffset": 349, "endOffset": 357}, {"referenceID": 9, "context": "1 Introduction Minimizing a convex function over the set of positive semidefinite matrices with unit trace, aka the spectrahedron, is an important optimization task which lies at the heart of many optimization, machine learning, and signal processing tasks such as matrix completion [2, 28, 17], metric learning [32, 31, 33], kernel matrix learning [23, 10], multiclass classification [3, 34, 14], and more.", "startOffset": 349, "endOffset": 357}, {"referenceID": 2, "context": "1 Introduction Minimizing a convex function over the set of positive semidefinite matrices with unit trace, aka the spectrahedron, is an important optimization task which lies at the heart of many optimization, machine learning, and signal processing tasks such as matrix completion [2, 28, 17], metric learning [32, 31, 33], kernel matrix learning [23, 10], multiclass classification [3, 34, 14], and more.", "startOffset": 385, "endOffset": 396}, {"referenceID": 33, "context": "1 Introduction Minimizing a convex function over the set of positive semidefinite matrices with unit trace, aka the spectrahedron, is an important optimization task which lies at the heart of many optimization, machine learning, and signal processing tasks such as matrix completion [2, 28, 17], metric learning [32, 31, 33], kernel matrix learning [23, 10], multiclass classification [3, 34, 14], and more.", "startOffset": 385, "endOffset": 396}, {"referenceID": 13, "context": "1 Introduction Minimizing a convex function over the set of positive semidefinite matrices with unit trace, aka the spectrahedron, is an important optimization task which lies at the heart of many optimization, machine learning, and signal processing tasks such as matrix completion [2, 28, 17], metric learning [32, 31, 33], kernel matrix learning [23, 10], multiclass classification [3, 34, 14], and more.", "startOffset": 385, "endOffset": 396}, {"referenceID": 3, "context": "These methods are mostly based on the conditional gradient method, also known as the Frank-Wolfe algorithm [4, 16], which is a generic method for constrained convex optimization given an oracle for minimizing linear functions over the feasible domain.", "startOffset": 107, "endOffset": 114}, {"referenceID": 15, "context": "These methods are mostly based on the conditional gradient method, also known as the Frank-Wolfe algorithm [4, 16], which is a generic method for constrained convex optimization given an oracle for minimizing linear functions over the feasible domain.", "startOffset": 107, "endOffset": 114}, {"referenceID": 3, "context": "While the CG method has been discovered already in the 1950\u2019s [4, 25], it has regained much interest in recent years in the machine learning and optimization communities, in particular due to its applications to semidefinite optimization and convex optimization with a nuclear norm constraint / regularization1, e.", "startOffset": 62, "endOffset": 69}, {"referenceID": 24, "context": "While the CG method has been discovered already in the 1950\u2019s [4, 25], it has regained much interest in recent years in the machine learning and optimization communities, in particular due to its applications to semidefinite optimization and convex optimization with a nuclear norm constraint / regularization1, e.", "startOffset": 62, "endOffset": 69}, {"referenceID": 11, "context": ", [12, 17, 24, 29, 33, 3, 11, 13, 14].", "startOffset": 2, "endOffset": 37}, {"referenceID": 16, "context": ", [12, 17, 24, 29, 33, 3, 11, 13, 14].", "startOffset": 2, "endOffset": 37}, {"referenceID": 23, "context": ", [12, 17, 24, 29, 33, 3, 11, 13, 14].", "startOffset": 2, "endOffset": 37}, {"referenceID": 28, "context": ", [12, 17, 24, 29, 33, 3, 11, 13, 14].", "startOffset": 2, "endOffset": 37}, {"referenceID": 32, "context": ", [12, 17, 24, 29, 33, 3, 11, 13, 14].", "startOffset": 2, "endOffset": 37}, {"referenceID": 2, "context": ", [12, 17, 24, 29, 33, 3, 11, 13, 14].", "startOffset": 2, "endOffset": 37}, {"referenceID": 10, "context": ", [12, 17, 24, 29, 33, 3, 11, 13, 14].", "startOffset": 2, "endOffset": 37}, {"referenceID": 12, "context": ", [12, 17, 24, 29, 33, 3, 11, 13, 14].", "startOffset": 2, "endOffset": 37}, {"referenceID": 13, "context": ", [12, 17, 24, 29, 33, 3, 11, 13, 14].", "startOffset": 2, "endOffset": 37}, {"referenceID": 18, "context": "These running times improve exponentially to only depend on log(1/\u01eb) when the eigenvalues of the input matrix are well distributed [19].", "startOffset": 131, "endOffset": 135}, {"referenceID": 16, "context": "Indeed, in several important machine learning applications, such as matrix completion, the CG method requires eigenvector computations of very sparse matrices [17].", "startOffset": 159, "endOffset": 163}, {"referenceID": 7, "context": "Also, very recently, new eigenvector algorithms with significantly improved performance guarantees were introduced which are applicable for matrices with certain popular structure [8, 18, 30].", "startOffset": 180, "endOffset": 191}, {"referenceID": 17, "context": "Also, very recently, new eigenvector algorithms with significantly improved performance guarantees were introduced which are applicable for matrices with certain popular structure [8, 18, 30].", "startOffset": 180, "endOffset": 191}, {"referenceID": 29, "context": "Also, very recently, new eigenvector algorithms with significantly improved performance guarantees were introduced which are applicable for matrices with certain popular structure [8, 18, 30].", "startOffset": 180, "endOffset": 191}, {"referenceID": 12, "context": "In these settings the time required for the optimization method to perform a single update may be a key consideration in its applicability to the problem [13, 7, 6].", "startOffset": 154, "endOffset": 164}, {"referenceID": 6, "context": "In these settings the time required for the optimization method to perform a single update may be a key consideration in its applicability to the problem [13, 7, 6].", "startOffset": 154, "endOffset": 164}, {"referenceID": 5, "context": "In these settings the time required for the optimization method to perform a single update may be a key consideration in its applicability to the problem [13, 7, 6].", "startOffset": 154, "endOffset": 164}, {"referenceID": 26, "context": "On the other hand, the convergence rate of optimal projection-based methods, such as Nesterov\u2019s accelerated gradient method, scales like 1/t2 for smooth functions, and can be improved exponentially to exp(\u2212\u0398(t)) when the objective is also strongly convex [27].", "startOffset": 255, "endOffset": 259}, {"referenceID": 5, "context": "These results exhibit provably-faster rates for optimization over polyhedral sets [6, 20, 1] and stronglyconvex sets [9], but do not apply to the spectrahedron.", "startOffset": 82, "endOffset": 92}, {"referenceID": 19, "context": "These results exhibit provably-faster rates for optimization over polyhedral sets [6, 20, 1] and stronglyconvex sets [9], but do not apply to the spectrahedron.", "startOffset": 82, "endOffset": 92}, {"referenceID": 0, "context": "These results exhibit provably-faster rates for optimization over polyhedral sets [6, 20, 1] and stronglyconvex sets [9], but do not apply to the spectrahedron.", "startOffset": 82, "endOffset": 92}, {"referenceID": 8, "context": "These results exhibit provably-faster rates for optimization over polyhedral sets [6, 20, 1] and stronglyconvex sets [9], but do not apply to the spectrahedron.", "startOffset": 117, "endOffset": 120}, {"referenceID": 28, "context": "For the specific setting considered in this work, several heuristic improvements of the CG method were suggested which show promising empirical evidence, however, non of them provably improve over the rate of the standard CG method [29, 24, 5].", "startOffset": 232, "endOffset": 243}, {"referenceID": 23, "context": "For the specific setting considered in this work, several heuristic improvements of the CG method were suggested which show promising empirical evidence, however, non of them provably improve over the rate of the standard CG method [29, 24, 5].", "startOffset": 232, "endOffset": 243}, {"referenceID": 4, "context": "For the specific setting considered in this work, several heuristic improvements of the CG method were suggested which show promising empirical evidence, however, non of them provably improve over the rate of the standard CG method [29, 24, 5].", "startOffset": 232, "endOffset": 243}, {"referenceID": 18, "context": "The running times for the eigenvector computation are based on the Lanczos method [19].", "startOffset": 82, "endOffset": 86}, {"referenceID": 25, "context": "While the combination of smoothness and strong convexity is a rare commodity, several important problems such as linear regression in the well-conditioned case, and solving undetermined linear systems (such as in the matrix completion problem), under certain conditions (see for instance [26]), exhibit such properties.", "startOffset": 288, "endOffset": 292}, {"referenceID": 5, "context": "This approach has allowed, among other things, to apply CG-based methods to non-smooth problems, for which the standard CG method is not suitable [6], and to strike better trade-offs between the linear optimization oracle complexity and the first-order oracle complexity [22, 14] 1.", "startOffset": 146, "endOffset": 149}, {"referenceID": 21, "context": "This approach has allowed, among other things, to apply CG-based methods to non-smooth problems, for which the standard CG method is not suitable [6], and to strike better trade-offs between the linear optimization oracle complexity and the first-order oracle complexity [22, 14] 1.", "startOffset": 271, "endOffset": 279}, {"referenceID": 13, "context": "This approach has allowed, among other things, to apply CG-based methods to non-smooth problems, for which the standard CG method is not suitable [6], and to strike better trade-offs between the linear optimization oracle complexity and the first-order oracle complexity [22, 14] 1.", "startOffset": 271, "endOffset": 279}, {"referenceID": 16, "context": "The following Lemma, whose proof can be found in [17], shows the equivalence between the two problems.", "startOffset": 49, "endOffset": 53}, {"referenceID": 0, "context": "Algorithm 1 Conditional Gradient 1: input: sequence of step-sizes {\u03b7t}t\u22651 \u2282 [0, 1] 2: let X1 be an arbitrary matrix in Sd 3: for t = 1.", "startOffset": 76, "endOffset": 82}, {"referenceID": 15, "context": "(4), in principal, might remain as large as the diameter of Sd, which, given a proper choice of step-size \u03b7t, results in the well-known convergence rate of O(\u03b2/t) [16, 12].", "startOffset": 163, "endOffset": 171}, {"referenceID": 11, "context": "(4), in principal, might remain as large as the diameter of Sd, which, given a proper choice of step-size \u03b7t, results in the well-known convergence rate of O(\u03b2/t) [16, 12].", "startOffset": 163, "endOffset": 171}, {"referenceID": 14, "context": "This consequence holds also in case f(X) is not only smooth, but also strongly-convex, see for instance Lemma 21 in [15].", "startOffset": 116, "endOffset": 120}, {"referenceID": 14, "context": "4 in [15].", "startOffset": 5, "endOffset": 9}, {"referenceID": 0, "context": "Let \u03c4, \u03b3 \u2208 [0, 1] be scalars that satisfy \u03b3\u03c4 1\u2212\u03b3 \u2265 \u2016X\u2212Y\u2016F .", "startOffset": 11, "endOffset": 17}, {"referenceID": 0, "context": ", ak) is a distribution over [k], and let \u03c4, \u03b3 \u2208 [0, 1] which satisfy the condition in Lemma 2.", "startOffset": 49, "endOffset": 55}, {"referenceID": 1, "context": "In case the input sequence of step-sizes in Algorithm 2 {\u03b7t}t\u22651, is monotonically non-increasing and \u03b7t \u2208 [0, 2] for all t \u2265 1, it follows that on each iteration t of the algorithm, the iterate Xt admits an explicitly-given factorization into a convex sum of rank-one matrices, as described in the algorithm, such that for every rank-one coefficient ai, it holds that ai \u2265 \u03b7t/2.", "startOffset": 106, "endOffset": 112}, {"referenceID": 1, "context": "Thus, for any \u03b71 \u2208 [0, 2] it indeed follows that a1 \u2265 \u03b71/2.", "startOffset": 19, "endOffset": 25}, {"referenceID": 0, "context": ", (17) where the second inequality follows since min{a, b} \u2264 \u03bba+(1\u2212\u03bb)b for any a, b \u2208 R, \u03bb \u2208 [0, 1],", "startOffset": 93, "endOffset": 99}, {"referenceID": 0, "context": ", (18) where the last inequality follows from plugging the bounds in Lemma 4 and holds for any \u03c4, \u03b3 \u2208 [0, 1] such that \u03c4\u03b3 1\u2212\u03b3 \u2265 \u2016X\u2212X\u2217\u2016F .", "startOffset": 102, "endOffset": 108}, {"referenceID": 1, "context": "\u2200t \u2265 1 : \u03b7t = C 3(t+ t0) \u2208 [0, 2].", "startOffset": 27, "endOffset": 33}, {"referenceID": 1, "context": "(25) In order for our choice of step-sizes to satisfy the conditions of Observation 1, it must hold that {\u03b7t}t\u22651 \u2282 [0, 2].", "startOffset": 115, "endOffset": 121}, {"referenceID": 1, "context": "\u2200t \u2265 1 : \u03b7t = C3/4 3(t+ t0) \u2208 [0, 2].", "startOffset": 30, "endOffset": 36}, {"referenceID": 1, "context": "\u2200t \u2265 1 : \u03b7t = C1/2 3(t+ t0) \u2208 [0, 2].", "startOffset": 30, "endOffset": 36}, {"referenceID": 16, "context": "For a detailed presentation of the setting and the application of the conditional gradient method to this problem, we refer the reader to [17].", "startOffset": 138, "endOffset": 142}, {"referenceID": 16, "context": "(33) is known to have a smoothness parameter \u03b2 with respect to \u2016 \u00b7 \u2016F , which satisfies \u03b2 = O(1), see for instance [17].", "startOffset": 115, "endOffset": 119}, {"referenceID": 25, "context": "(1) (which is indeed the only consequence of strong convexity that we use in our analysis), known as restricted strong convexity [26].", "startOffset": 129, "endOffset": 133}, {"referenceID": 16, "context": "Second, after computing the eigenvector vt using the choice of \u03b7t prescribed in Theorem 1, we apply a line-search, as detailed in [17], in order to the determine the optimal step-size given the direction vtv \u22a4 t \u2212 xitxit .", "startOffset": 130, "endOffset": 134}, {"referenceID": 16, "context": "Baselines As baselines for comparison we used the standard conditional gradient method with exact line-search for setting the step-size (denoted CG in our figures)[17], and the conditional gradient with away-steps variant, recently studied in [20, 1, 21] (denoted Away-CG in our figures).", "startOffset": 163, "endOffset": 167}, {"referenceID": 19, "context": "Baselines As baselines for comparison we used the standard conditional gradient method with exact line-search for setting the step-size (denoted CG in our figures)[17], and the conditional gradient with away-steps variant, recently studied in [20, 1, 21] (denoted Away-CG in our figures).", "startOffset": 243, "endOffset": 254}, {"referenceID": 0, "context": "Baselines As baselines for comparison we used the standard conditional gradient method with exact line-search for setting the step-size (denoted CG in our figures)[17], and the conditional gradient with away-steps variant, recently studied in [20, 1, 21] (denoted Away-CG in our figures).", "startOffset": 243, "endOffset": 254}, {"referenceID": 20, "context": "Baselines As baselines for comparison we used the standard conditional gradient method with exact line-search for setting the step-size (denoted CG in our figures)[17], and the conditional gradient with away-steps variant, recently studied in [20, 1, 21] (denoted Away-CG in our figures).", "startOffset": 243, "endOffset": 254}], "year": 2016, "abstractText": "Minimizing a convex function over the spectrahedron, i.e., the set of all d \u00d7 d positive semidefinite matrices with unit trace, is an important optimization task with many applications in optimization, machine learning, and signal processing, the most notable one probably being matrix completion. Unfortunately, it is also notoriously difficult to solve in large-scale since standard techniques require to compute expensive matrix decompositions on each iteration. An alternative, is the conditional gradient method (aka Frank-Wolfe algorithm) that regained much interest in recent years, mostly due to its application to this specific setting. The key benefit of the CG method is that it avoids expensive matrix decompositions all together, and simply requires a single eigenvector computation per iteration, which is much more efficient. On the downside, the CG method, in general, converges with an inferior rate. The error for minimizing a \u03b2-smooth function after t iterations scales like \u03b2/t. This convergence rate does not improve even if the function is also strongly convex. In this work we present a modification of the CG method tailored for convex optimization over the spectrahedron. The per-iteration complexity of the method is essentially identical to that of the standard CG method: only a single eigenvecor computation is required. For minimizing an \u03b1-strongly convex and \u03b2-smooth function, the expected approximation error of the method after t iterations is:", "creator": "LaTeX with hyperref package"}}}