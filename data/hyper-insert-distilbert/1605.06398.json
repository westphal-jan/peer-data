{"id": "1605.06398", "review": {"conference": "NIPS", "VERSION": "v1", "DATE_OF_SUBMISSION": "20-May-2016", "title": "Stochastic Variance Reduction Methods for Saddle-Point Problems", "abstract": "we successfully consider naturally convex - fixed concave saddle - point algorithms problems where the objective estimation functions may be simultaneously split in many components, and extend historically recent stochastic variance reduction methods ( algorithms such as svrg or saga ) to progressively provide some the first large - scale linearly convergent algorithms for interpreting this weaker class of problems. which is traditionally common in classical machine learning. while currently the algorithmic extension effort is straightforward, specifically it routinely comes with challenges and opportunities : ( category a ) the convex minimization type analysis does specifically not apply and we use unlike the notion itself of monotone operators to actively prove optimal convergence, showing in particular that hence the technically same rigorous algorithm applies successfully to understanding a larger class of problems, such places as variational induced inequalities, ( especially b ) where there undoubtedly are still two notions both of splits, competing in terms of scaling functions, or only in relative terms of partial elastic derivatives, ( particularly c ) additionally the split does unfortunately need revision to be efficiently done automatically with suitable convex - concave terms, ( d ) non - destructive uniform sampling computation is key to an incredibly efficient algorithm, applied both in theory specification and training practice, and ( e ) conversely these recent incremental filter algorithms can be exceptionally easily accelerated upon using instead a simple extension of the \" catalyst \" framework, necessarily leading to an algorithm methodology which is always superior overall to accelerated batch convergence algorithms.", "histories": [["v1", "Fri, 20 May 2016 15:16:29 GMT  (207kb)", "http://arxiv.org/abs/1605.06398v1", null], ["v2", "Thu, 3 Nov 2016 10:24:55 GMT  (211kb)", "http://arxiv.org/abs/1605.06398v2", "Neural Information Processing Systems (NIPS), 2016, Barcelona, Spain"]], "reviews": [], "SUBJECTS": "cs.LG math.OC", "authors": ["balamurugan palaniappan", "francis r bach"], "accepted": true, "id": "1605.06398"}, "pdf": {"name": "1605.06398.pdf", "metadata": {"source": "CRF", "title": null, "authors": [], "emails": [], "sections": [{"heading": null, "text": "ar X\niv :1\n60 5.\n06 39\n8v 1\n[ cs\n.L G\n] 2"}, {"heading": "1 Introduction", "text": "When using optimization in machine learning, leveraging the natural separability of the objective functions has led to many algorithmic advances; the most common example is the separability as a sum of individual loss terms corresponding to individual observations, which leads to stochastic gradient descent techniques. Several lines of work have shown that the plain Robbins-Monro algorithm could be accelerated for strongly-convex finite sums, e.g., SAG [1], SDCA [2], SVRG [3], SAGA [4]. However, these only apply to separable objective functions.\nIn order to tackle non-separable losses or regularizers, we consider the saddle-point problem:\nmin x\u2208Rd max y\u2208Rn K(x, y) +M(x, y), (1)\nwhere the functions K and M are \u201cconvex-concave\u201d, that is, convex with respect to the first variable, and concave with respect to the second variable, with M potentially non-smooth but \u201csimple\u201d (e.g., for which the proximal operator is easy to compute), and K smooth. These problems occur naturally within convex optimization through Lagrange or Fenchel duality [5]; for example the bilinear saddlepoint problem minx\u2208Rd maxy\u2208Rn f(x) + y\n\u22a4Kx\u2212 g(y) corresponds to a supervised learning problem with design matrix K, a loss function g\u2217 (the Fenchel conjugate of g) and a regularizer f .\nWe assume that the function K may be split into a potentially large number of components. Many problems in machine learning exhibit that structure in the saddle-point formulation, but not in the associated convex minimization and concave maximization problems (see examples in Section 2.1).\nLike for convex minimization, gradient-based techniques that are blind to this separable structure need to access all the components at every iteration. We show that algorithms such as SVRG [3] and SAGA [4] may be readily extended to the saddle-point problem. While the algorithmic extension is straightforward, it comes with challenges and opportunities. We make the following contributions:\n\u2013 We provide the first convergence analysis for these algorithms for saddle-point problems, which differs significantly from the associated convex minimization set-up. In particular, we use in Section 6 the interpretation of saddle-point problems as finding the zeros of a monotone operator, and only use the monotonicity properties to show linear convergence of our algorithms, thus showing that they extend beyond saddle-point problems, e.g., to variational inequalities [6, 7].\n\u2013 We show that the saddle-point formulation (a) allows two different notions of splits, in terms of functions, or in terms of partial derivatives, (b) does need splits into convex-concave terms (as opposed to convex minimization), and (c) that non-uniform sampling is key to an efficient algorithm, both in theory and practice (see experiments in Section 7).\n\u2013 We show in Section 5 that these incremental algorithms can be easily accelerated using a simple extension of the \u201ccatalyst\u201d framework of [8], thus leading to an algorithm which is always superior to accelerated batch algorithms."}, {"heading": "2 Composite Decomposable Saddle-Point Problems", "text": "We consider the saddle-point problem defined in Eq. (1), with the following assumptions:\n(A) M is strongly (\u03bb, \u03b3)-convex-concave, that is, the function (x, y) 7\u2192 M(x, y) \u2212 \u03bb2 \u2016x\u20162 + \u03b3 2 \u2016y\u20162 is\nconvex-concave. Moreover, we assume that we may compute the proximal operator of M , i.e., for any (x\u2032, y\u2032) \u2208 Rn+d:\nprox\u03c3M (x \u2032, y\u2032) = arg min\nx\u2208Rd max y\u2208Rn\n\u03c3M(x, y) + \u03bb2 \u2016x\u2212 x\u2032\u20162 \u2212 \u03b3 2\u2016y \u2212 y\u2032\u20162. (2)\nThe values of \u03bb and \u03b3 lead to the definition of a weighted Euclidean norm on Rn+d defined as \u2126(x, y)2 = \u03bb\u2016x\u20162 + \u03b3\u2016y\u20162, with dual norm defined through \u2126\u2217(x, y)2 = \u03bb\u22121\u2016x\u20162 + \u03b3\u22121\u2016y\u20162. Dealing with the two different scaling factors \u03bb and \u03b3 is crucial for good performance, as these may be very different, depending on the many arbitrary ways to set-up a saddle-point problem.\n(B) K is convex-concave and has Lipschitz-continuous gradients; it is natural to quantify this by considering the gradient operator B : Rn+d \u2192 Rn+d defined as B(x, y) = (\u2202xK(x, y),\u2212\u2202yK(x, y)) \u2208 R\nn+d and to consider L = sup\u2126(x\u2212x\u2032,y\u2212y\u2032)=1 \u2126 \u2217(B(x, y) \u2212B(x\u2032, y\u2032)). The quantity L represents\nthe condition number of the problem.\n(C) The vector-valued function B(x, y) = (\u2202xK(x, y),\u2212\u2202yK(x, y)) \u2208 Rn+d may be split into a family of vector-valued functions as B = \u2211\ni\u2208I Bi, where the only constraint is that each Bi is Lipschitzcontinuous (with constant Li). There is no need to assume the existence of Ki : R\nn+d \u2192 R such that Bi = (\u2202xKi,\u2212\u2202yKi). We will also consider splits which are adapted to the saddle-point nature of the problem, that is, of the form B(x, y) = ( \u2211\nk\u2208K B x k (x, y),\n\u2211 j\u2208J B y j (x, y)\n)\n, which is a subcase of the above with\nI = J \u00d7 K, Bjk(x, y) = (pjBxk (x, y), qkB y j (x, y)), for p and q sequences that sum to one. This substructure, which we refer to as \u201cfactored\u201d, will only make a difference when storing the values of these operators in Section 4 for our SAGA algorithm.\nGiven assumptions (A)-(B), the saddle-point problem in Eq. (1) has a unique solution (x\u2217, y\u2217) such that K(x\u2217, y)+M(x\u2217, y) 6 K(x\u2217, y\u2217)+M(x\u2217, y\u2217) 6 K(x, y\u2217)+M(x, y\u2217), for all (x, y); moreover minx\u2208Rd maxy\u2208Rn K(x, y) +M(x, y) = maxy\u2208Rn minx\u2208Rd K(x, y) +M(x, y) (see, e.g., [9, 5]).\nThe main generic examples for the functions K(x, y) and M(x, y) are:\n\u2013 Bilinear saddle-point problems: K(x, y) = y\u22a4Kx for a matrix1 K \u2208 Rn\u00d7d, for which the vector-valued function B(x, y) is linear, i.e., B(x, y) = (K\u22a4y,\u2212Kx). Then L = \u2016K\u2016op/ \u221a \u03b3\u03bb,\nwhere \u2016K\u2016op is the largest singular value of K. There are two natural potential splits with I = {1, . . . , n}\u00d7{1, . . . , k}, with B = \u2211nj=1 \u2211d k=1 Bjk: (a) the split into individual elements Bjk(x, y) = Kjk(yj ,\u2212xk), where every element is the gradient operator of a bi-linear function, and (b) the \u201cfactored\u201d split into rows/columns Bjk(x, y) = (qkyjK \u22a4 j\u00b7 ,\u2212pjxkK\u00b7k), where Kj\u00b7 and K\u00b7k are the j-th row and k-th column of K, p and q are any set of vectors summing to one, and every element is not the gradient operator of any function. These splits correspond to several \u201csketches\u201d of the matrix K [10], adapted to subsampling of K, but other sketches could be considered.\n\u2013 Separable functions: M(x, y) = f(x) \u2212 g(y) where f is any \u03bb-strongly-convex and g is \u03b3strongly convex, for which the proximal operators prox\u03c3f (x \u2032) = argminx\u2208Rd \u03c3f(x) + \u03bb 2 \u2016x \u2212 x\u2032\u20162\nand prox\u03c3g (y \u2032) = argmaxy\u2208Rd \u2212\u03c3g(y) \u2212 \u03b32\u2016y \u2212 y\u2032\u20162 are easy to compute. In this situation, prox\u03c3M (x \u2032, y\u2032) = (prox\u03c3f (x \u2032), prox\u03c3g (y \u2032)). Following the usual set-up of composite optimization [11], no smoothness assumption is made on M and hence on f or g."}, {"heading": "2.1 Examples in machine learning", "text": "Many learning problems are formulated as convex optimization problems, and hence by duality as saddle-point problems. We now give examples where our new algorithms are particularly adapted.\nSupervised learning with non-separable losses or regularizers. For regularized linear supervised learning, with n d-dimensional observations put in a design matrix K \u2208 Rn\u00d7d, the predictions are parameterized by a vector x \u2208 Rd and lead to a vector of predictions Kx \u2208 Rn. Given a loss function defined through its Fenchel conjugate g\u2217 from Rn to R, and a regularizer f(x), we obtain exactly a bi-linear saddle-point problem. When the loss g\u2217 or the regularizer f is separable, i.e., a sum of functions of individual variables, we may apply existing fast gradient-techniques [1, 3, 4] to the primal problem minx\u2208Rd g\n\u2217(Kx) + f(x) or the dual problem maxy\u2208Rn \u2212g(y)\u2212 f\u2217(K\u22a4y), as well as methods dedicated to separable saddle-point problems [12]. When the loss g\u2217 and the regularizer f are not separable (but have a simple proximal operator), our new fast algorithms are the only ones that can be applied from the class of large-scale linearly convergent algorithms.\nNon-separable losses may occur when (a) predicting by affine functions of the inputs and not penalizing the constant terms (in this case defining the loss functions as the minimum over the constant term, which becomes non-separable) or (b) using structured output prediction methods that lead to convex surrogates to the area under the ROC curve (AUC) or other precision/recall quantities [13, 14, 15]. These come often with efficient proximal operators (see Section 7 for an example).\nNon-separable regularizers with available efficient proximal operators are numerous, such as groupednorms with potentially overlapping groups, norms based on submodular functions, or total variation (see [16] and references therein, and an example in Section 7).\nRobust optimization. The framework of robust optimization [17] aims at optimizing an objective function with uncertain data. Given that the aim is then to minimize the maximal value of the objective function given the uncertainty, this leads naturally to saddle-point problems.\n1We identify here a matrix with the associated bilinear function.\nConvex relaxation of unsupervised learning. Unsupervised learning leads to convex relaxations which often exhibit structures naturally amenable to saddle-point problems, e.g, for discriminative clustering [18] or matrix factorization [19]."}, {"heading": "2.2 Existing batch algorithms", "text": "In this section, we review existing algorithms aimed at solving the composite saddle-point problem in Eq. (1), without using the sum-structure. Note that it is often possible to apply batch algorithms for the associated primal or dual problems (which are not separable in general).\nForward-backward (FB) algorithm. The main iteration is\n(xt, yt) = prox \u03c3 M\n[ (xt\u22121, yt\u22121)\u2212 \u03c3 (1/\u03bb 0 0 1/\u03b3 ) B(xt\u22121, yt\u22121) ]\n= prox\u03c3M ( xt\u22121 \u2212 \u03c3\u03bb\u22121\u2202xK(xt\u22121, yt\u22121), yt\u22121 + \u03c3\u03b3\u22121\u2202yK(xt\u22121, yt\u22121)). Intuitively, the algorithm aims at simultaneously minimizing with respect to x while maximizing with respect to y (when M(x, y) is the sum of isotropic quadratic terms and indicator functions, we get simultaneous projected gradient descent). This algorithm is known not to converge in general [9], but is linearly convergent for strongly-convex-concave problems, when \u03c3 = 1/L2, with the rate (1 \u2212 1/(1 + L2))t [20] (see simple proof in Appendix B.1). This is the one we are going to adapt to stochastic variance reduction.\nWhenM(x, y) = f(x)\u2212g(y), we obtain the two parallel updates xt = prox\u03c3f ( xt\u22121\u2212\u03bb\u22121\u03c3\u2202xK(xt\u22121, yt\u22121 )) and yt = prox \u03c3 g ( yt\u22121+\u03b3\u22121\u03c3\u2202yK(xt\u22121, yt\u22121 )) , which can de done serially by replacing the second one by yt = prox \u03c3 g ( yt\u22121 + \u03b3\u22121\u03c3\u2202yK(xt, yt\u22121 ))\n. This is often referred to as the Arrow-Hurwicz method (see [21] and references therein).\nExtragradient algorithm. When M is not assumed to be strongly convex-concave, the forwardbackward algorithm may not be convergent. The extragradient algorithm performs two updates at each iteration (see, e.g., [22, 23]), and is then convergent. It is convergent for our problem with a similar worst-case convergence rate [23], but is more robust to step-size selection.\nAccelerated forward-backward algorithm. The forward-backward algorithm may be accelerated by a simple extrapolation step, similar to Nesterov\u2019s acceleration for convex minimization [24]. The algorithm from [21], which only applies to bilinear functions K, and which we extend from separable M to our more general set-up in Appendix B.2, has the following iteration:\n(xt, yt) = prox \u03c3 M\n[ (xt\u22121, yt\u22121)\u2212 \u03c3 (1/\u03bb 0 0 1/\u03b3 ) B(xt\u22121 + \u03b8(xt\u22121 \u2212 xt\u22122), yt\u22121 + \u03b8(yt\u22121 \u2212 yt\u22122)) ] .\nWith \u03c3 = 1/(2L) and \u03b8 = L/(L+ 1), we get an improved convergence rate, where (1\u22121/(1 + L2))t is replaced by (1\u2212 1/(1 + 2L))t. This is always a strong improvement when L is large (ill-conditioned problems), as illustrated in Section 7. Note that our acceleration technique in Section 5 may be extended to get a similar rate for the batch set-up for non-linear K."}, {"heading": "2.3 Existing stochastic algorithms", "text": "Forward-backward algorithms have been studied with added noise [25], leading to a convergence rate in O(1/t) after t iterations for strongly-convex-concave problems. In our setting, we replace B(x, y) in our algorithm with 1\u03c0iBi(x, y), where i \u2208 I is sampled from the probability vector (\u03c0i)i. We have EBi(x, y) = B(x, y); the main iteration is then\n(xt, yt) = prox \u03c3t M\n[ (xt\u22121, yt\u22121)\u2212 \u03c3t (1/\u03bb 0 0 1/\u03b3 ) 1 \u03c0it Bit(xt\u22121, yt\u22121) ] ,\nwith it selected independently at random in I with probability vector \u03c0. In Appendix C, we show that using \u03c3t = 2/(t+1+8L\u0304(\u03c0)\n2) leads to a convergence rate in O(1/t), where L\u0304(\u03c0) is a smoothness constant explicited below. For saddle-point problems, it leads to the complexities shown in Table 1. Like for convex minimization, it is fast early on but the performance levels off. Such schemes are typically used in sublinear algorithms [26]."}, {"heading": "2.4 Sampling probabilities, convergence rates and running-time complexities", "text": "In order to characterize running-times, we denote by T (A) the complexity of computing A(x, y) for any operator A and (x, y) \u2208 Rn+d, while we denote by Tprox(M) the complexity of computing prox\u03c3M (x, y). In our motivating example of bilinear functions K(x, y), we assume that Tprox(M) takes times proportional to n+ d and getting a single element of K is O(1).\nIn order to characterize the convergence rate, we need the Lipschitz-constant L defined earlier as well as a smoothness constant adapted to our sampling schemes:\nL\u0304(\u03c0)2 = sup(x,y,x\u2032,y\u2032) \u2211 i\u2208I 1 \u03c0i \u2126\u2217(Bi(x, y)\u2212 Bi(x\u2032, y\u2032))2 such that \u2126(x\u2212 x\u2032, y \u2212 y\u2032)2 6 1.\nWe always have the bounds L2 6 L\u0304(\u03c0)2 6 maxi\u2208I L2i \u00d7 \u2211 i\u2208I 1 \u03c0i . However, in structured situations (like in bilinear saddle-point problems), we get much improved bounds, as described below. Bi-linear saddle-point. The constant L is equal to \u2016K\u2016op/ \u221a \u03bb\u03b3, and we will consider as well the Frobenius norm \u2016K\u2016F defined through \u2016K\u20162F = \u2211 j,k K 2 jk, and the norm \u2016K\u2016max defined as \u2016K\u20162max = max{supj(KK\u22a4) 1/2 jj , supk(K \u22a4K)1/2kk }. Among the norms above, we always have:\n\u2016K\u2016max 6 \u2016K\u2016op 6 \u2016K\u2016F 6 \u221a max{n, d}\u2016K\u2016max 6 \u221a max{n, d}\u2016K\u2016op, (3)\nwhich allows to show below that some algorithms have better bounds than others.\nThere are several schemes to choose the probabilities \u03c0jk (individual splits) and \u03c0jk = pjqk (factored splits). For the factored formulation where we select random rows and columns, we consider the nonuniform schemes pj = (KK \u22a4)jj/\u2016K\u20162F and qk = (K\u22a4K)kk/\u2016K\u20162F , leading to L\u0304(\u03c0) 6 \u2016K\u2016F/ \u221a \u03bb\u03b3, or uniform, leading to L\u0304(\u03c0) 6 \u221a max{n, d}\u2016K\u2016max/ \u221a \u03bb\u03b3. For the individual formulation where we select random elements, we consider \u03c0jk = K 2 jk/\u2016K\u20162F , leading to L\u0304(\u03c0) 6 \u221a max{n, d}\u2016K\u2016F/ \u221a \u03bb\u03b3,\nor uniform, leading to L\u0304(\u03c0) 6 \u221a nd\u2016K\u2016max/ \u221a \u03bb\u03b3 (in these situations, it is important to select several elements simultaneously, which our analysis supports).\nWe characterize convergence with the quantity \u03b5 = \u2126(x \u2212 x\u2217, y \u2212 y\u2217)2/\u2126(x0 \u2212 x\u2217, y0 \u2212 y\u2217)2, where (x0, y0) is the initialization of our algorithms (typically (0, 0) for bilinear saddle-points). In Table 1 we give a summary of the complexity of all algorithms discussed in this paper: we recover the same type of speed-ups as for convex minimization. A few points are worth mentioning:\n\u2013 Given the bounds between the various norms on K in Eq. (3), SAGA/SVRG with non-uniform sampling always has convergence bounds superior to SAGA/SVRG with uniform sampling, which is always superior to batch forward-backward. Note however, that in practice, SAGA/SVRG with uniform sampling may be inferior to accelerated batch method (see Section 7).\n\u2013 Accelerated SVRG with non-uniform sampling is the most efficient method, which is confirmed in our experiments."}, {"heading": "3 SVRG: Stochastic Variance Reduction for Saddle Points", "text": "Following [3, 27], we consider a stochastic-variance reduced estimation of the finite sum B(x, y) = \u2211\ni\u2208I Bi(x, y). This is achieved by assuming that we have an iterate (x\u0303, y\u0303) with a known value of B(x\u0303, y\u0303), and we consider the estimate of B(x, y):\nB(x\u0303, y\u0303) + 1\u03c0iBi(x, y)\u2212 1 \u03c0i Bi(x\u0303, y\u0303),\nwhich has the correct expectation when i is sampled from I with probability \u03c0, but with a reduced variance. Since we need to refresh (x\u0303, y\u0303) regularly, the algorithm works in epochs (we allow to sample m elements per updates, i.e., a mini-batch of size m), with an algorithm that shares the same structure than SVRG for convex minimization; see Algorithm 1. Note that we provide an explicit number of iterations per epoch, proportional to (L2 + 3L\u03042/m). We have the following theorem, shown in Appendix D.1 (see also a dicussion of the proof in Section 6).\nTheorem 1 Assume (A)-(B)-(C). After v epochs of Algorithm 2, we have:\nE [ \u2126(xv \u2212 x\u2217, yv \u2212 y\u2217)2 ] 6 (3/4)v\u2126(x0 \u2212 x\u2217, y0 \u2212 y\u2217)2.\nThe computational complexity to reach precision \u03b5 is proportional to [ T (B)+(mL2+L\u03042)maxi\u2208I T (Bi)+ (1+L2+ L\u03042/m)Tprox(M) ]\nlog 1\u03b5 . Note that by taking m large, we can alleviate the complexity of the proximal operator proxM if too large. Moreover, if L\n2 is too expensive to compute, we may replace it by L\u03042 but with a worse complexity bound.\nBilinear saddle-point problems. When using a mini-batch size m = 1 with the factored updates, or m = n + d for the individual updates, we get the same complexities proportional to [nd + max{n, d}\u2016K\u20162F/(\u03bb\u03b3)] log(1/\u03b5) for non-uniform sampling, which improve significantly over (nonaccelerated) batch methods (see Table 1)."}, {"heading": "4 SAGA: Online Stochastic Variance Reduction for Saddle", "text": "Points\nFollowing [4], we consider a stochastic-variance reduced estimation of B(x, y) = \u2211\ni\u2208I Bi(x, y). This\nis achieved by assuming that we store values gi = Bi(x old(i), yold(i)) for an old iterate (xold(i), yold(i)),\nAlgorithm 1 SVRG: Stochastic Variance Reduction for Saddle Points\nInput: Functions (Ki)i, M , probabilities (\u03c0i)i, smoothness L\u0304(\u03c0) and L, iterate (x, y) number of epochs v, number of updates per iteration (mini-batch size) m\nSet \u03c3 = [ L2 + 3L\u03042/m ]\u22121 for u = 1 to v do Initialize (x\u0303, y\u0303) = (x, y) and compute B(x\u0303, y\u0303) for k = 1 to log 4\u00d7 (L2 + 3L\u03042/m) do Sample i1, . . . , im \u2208 I from the probability vector (\u03c0i)i with replacement (x, y) \u2190 prox\u03c3M [ (x, y)\u2212 \u03c3 (1/\u03bb 0 0 1/\u03b3 )( B(x\u0303, y\u0303) + 1m \u2211m k=1 { 1 \u03c0ik Bik(x, y)\u2212 1\u03c0ik Bik(x\u0303, y\u0303) })]\nend for end for\nOutput: Approximate solution (x, y)\nand we consider the estimate of B(x, y):\n\u2211\nj\u2208I g j + 1\u03c0iBi(x, y)\u2212 1 \u03c0i gi,\nwhich has the correct expectation when i is sampled from I with probability \u03c0. At every iteration, we also refresh the operator values gi \u2208 Rn+d, for the same index i or with a new index i sampled uniformly at random. This leads to Algorithm 2, and we have the following theorem showing linear convergence, proved in Appendix D.2. Note that for bi-linear saddle-points, the initialization at (0, 0) has zero cost (which is not possible for convex minimization).\nTheorem 2 Assume (A)-(B)-(C). After t iterations of Algorithm 2 (with the option of resampling when using non-uniform sampling), we have:\nE [ \u2126(xt \u2212 x\u2217, yt \u2212 y\u2217)2 ] 6 2 ( 1\u2212 (max{ 3|I|2m , 1 + L 2 \u00b52 + 3 L\u03042 m\u00b52 })\u22121 )t \u2126(x0 \u2212 x\u2217, y0 \u2212 y\u2217)2.\nResampling or re-using the same gradients. For the bound above to be valid for non-uniform sampling, like for convex minimization [28], we need to resample m operators after we make the iterate update. In our experiments, following [28], we considered a mixture of uniform and nonuniform sampling, without a resampling step.\nSAGA vs. SVRG. The difference between the two algorithms is the same as for convex minimization (see, e.g., [29] and references therein), that is SVRG has no storage, but works in epochs and requires slightly more accesses to the oracles, while SAGA is a pure online method with fewer parameters but requires some storage (for bi-linear saddle-point problems, we only need to store O(n+d) elements for the factored splits, while we need O(dn) for the individual splits). Overall they have the same running-time complexity for individual splits; for factored splits, see Appendix D.4.\nFactored splits. When using factored splits, we need to store the two parts of the operator values separately and update them independently, leading in Theorem 2 to replacing |I| by max{|J|, |K|}."}, {"heading": "5 Acceleration", "text": "Following the \u201ccatalyst\u201d framework of [8], we consider a sequence of saddle-point problems with added regularization; namely, given (x\u0304, y\u0304), we use SVRG to solve approximately\nmin x\u2208Rd max y\u2208Rn\nK(x, y) +M(x, y) + \u03bb\u03c42 \u2016x\u2212 x\u0304\u20162 \u2212 \u03b3\u03c4 2 \u2016y \u2212 y\u0304\u20162, (4)\nAlgorithm 2 SAGA: Online Stochastic Variance Reduction for Saddle Points\nInput: Functions (Ki)i, M , probabilities (\u03c0i)i, smoothness L\u0304(\u03c0) and L, iterate (x, y) number of iterations t, number of updates per iteration (mini-batch size) m\nSet \u03c3 = [ max{ 3|I|2m \u2212 1, L2 + 3 L\u0304 2 m } ]\u22121 Initialize gi = Bi(x, y) for all i \u2208 I and G = \u2211 i\u2208I g i for u = 1 to t do Sample i1, . . . , im \u2208 I from the probability vector (\u03c0i)i with replacement Compute hk = Bik(x, y) for k \u2208 {1, . . . ,m} (x, y) \u2190 prox\u03c3M [ (x, y)\u2212 \u03c3 (1/\u03bb 0 0 1/\u03b3 )( G+ 1m \u2211m k=1 { 1 \u03c0ik hk \u2212 1\u03c0ik g ik })]\n(optional) Sample i1, . . . , im \u2208 I uniformly with replacement (optional) Compute hk = Bik(x, y) for k \u2208 {1, . . . ,m} Replace G \u2190 G\u2212\u2211mk=1{gik \u2212 hk} and gik \u2190 hk for k \u2208 {1, . . . ,m}\nend for Output: Approximate solution (x, y)\nfor well-chosen \u03c4 and (x\u0304, y\u0304). The main iteration of the algorithm differs from the original SVRG by the presence of the iterate (x\u0304, y\u0304) and different step-sizes (see details in Appendix D.3). The complexity to get an approximate solution of Eq. (4) (forgetting the complexity of the proximal operator and for a single update), up to logarithmic terms, is proportional, to T (B) + L\u03042(1 + \u03c4)\u22122 maxi\u2208I T (Bi).\nThe key difference with the convex optimization set-up is that the analysis is simpler, without the need for Nesterov acceleration machinery [24] to define a good value of (x\u0304, y\u0304); indeed, the solution of Eq. (4) is one iteration of the proximal-point algorithm, which is known to converge linearly [30] with rate (1+\u03c4\u22121)\u22121 = (1\u2212 11+\u03c4 ). Thus the overall complexity is up to logarithmic terms equal to T (B)(1+ \u03c4) + L\u03042(1 + \u03c4)\u22121 maxi\u2208I T (Bi). The trade-off in \u03c4 is optimal for 1 + \u03c4 = L\u0304 \u221a maxi\u2208I T (Bi)/T (B), showing that there is a potential acceleration when L\u0304 \u221a\nmaxi\u2208I T (Bi)/T (B) > 1, leading to a com-\nplexity L\u0304 \u221a\nT (B)maxi\u2208I T (Bi).\nSince the SVRG algorithm already works in epochs, this leads to a simple modification where every log(1 + \u03c4) epochs, we change the values of (x\u0304, y\u0304). See Algorithm 3 in Appendix D.3. Moreover, we can adaptively update (x\u0304, y\u0304) more aggressively to speed-up the algorithm.\nThe following theorem gives the convergence rate of the method (see proof in Appendix D.3). With the value of \u03c4 defined above (corresponding to \u03c4 = max {\n0, \u2016K\u2016F\u221a \u03bb\u03b3 \u221a max{n\u22121, d\u22121} \u2212 1 } for bilinear\nproblems), we get the complexity L\u0304 \u221a\nT (B)maxi\u2208I T (Bi), up to the logarithmic term log(1+\u03c4). For bilinear problems, this provides a significant acceleration, as shown in Table 1.\nTheorem 3 Assume (A)-(B)-(C). After v epochs of Algorithm 3, we have, for any positive \u03c4 :\nE [ \u2126(xv \u2212 x\u2217, yv \u2212 y\u2217)2 ] 6 ( 1\u2212 1\u03c4+1 )v \u2126(x0 \u2212 x\u2217, y0 \u2212 y\u2217)2.\nWhile we provide a proof only for SVRG, the same scheme should work for SAGA. Moreover, the same idea also applies to the batch setting (by simply considering |I| = 1, i.e., a single function), leading to an acceleration, but now valid for all functions K (not only bilinear)."}, {"heading": "6 Extension to Monotone Operators", "text": "In this paper, we have chosen to focus on saddle-point problems because of their ubiquity in machine learning. However, it turns out that our algorithm, and, more importantly, our analysis extend to all set-valued monotone operators [9, 31]. We thus consider a maximal strongly-monotone operator A on a Euclidean space E, as well as a finite family of Lipschitz-continuous (not necessarily monotone) operators Bi, i \u2208 I, with B = \u2211\ni\u2208I Bi monotone. Our algorithm then finds the zeros of A + \u2211\ni\u2208I Bi = A+B, from the knowledge of the resolvent (\u201cbackward\u201d) operator (I +\u03c3A) \u22121 (for a well chosen \u03c3 > 0) and the forward operators Bi, i \u2208 I. There several interesting examples (on which our algorithms apply):\n\u2013 Saddle-point problems: We assume for simplicity that \u03bb = \u03b3 = \u00b5 (this can be achieved by a simple change of variable). If we denote B(x, y) = (\u2202xK(x, y),\u2212\u2202yK(x, y)) and the multi-valued operator A(x, y) = (\u2202xM(x, y),\u2212\u2202yM(x, y)), then the proximal operator prox\u03c3M may be written as (\u00b5I + \u03c3A)\u22121(\u00b5x, \u00b5y), and we recover exactly our framework from Section 2.\n\u2013 Convex minimization: A = \u2202g and Bi = \u2202fi for a strongly-convex function g and smooth functions fi: we recover proximal-SVRG [27] and SAGA [4], to minimize minz\u2208E g(z)+ \u2211\ni\u2208I fi(z). However, this is a situation where the operators Bi have an extra property called co-coercivity [7], which we are not using because it is not satisfied for saddle-point problems. The extension of SAGA and SVRG to monotone operators was proposed earlier by [32], but only co-coercive operators are considered, and thus only convex minimization is considered (with important extensions beyond plain SAGA and SVRG), while our analysis covers a much broader set of problems. In particular, the step-sizes obtained with co-coercivity lead to divergence in the general setting.\nBecause we do not use co-coercivity, applying our results directly to convex minimization, we would get slower rates, while, as shown in Section 2.1, they can be easily cast as a saddle-point problem if the proximal operators of the functions fi are known, and we then get the same rates than existing fast techniques which are dedicated to this problem [1, 2, 3, 4].\n\u2013 Variational inequality problems, which are notably common in game theory (see, e.g., [6])."}, {"heading": "7 Experiments", "text": "We consider binary classification problems with design matrix K and label vector in {\u22121, 1}n, a nonseparable strongly-convex regularizer with an efficient proximal operator (the sum of the squared norm \u03bb\u2016x\u20162/2 and the clustering-inducing term \u2211i6=j |xi\u2212xj |, for which the proximal operator may be computed in O(n log n) by isotonic regression [33]) and a non-separable smooth loss (a surrogate to the area under the ROC curve, defined as proportional to \u2211\ni+\u2208I+ \u2211 i\u2212\u2208I\u2212(1 \u2212 yi + yj) 2, where\nI+/I\u2212 are sets with positive/negative labels, for a vector of prediction y, for which an efficient proximal operator may be computed as well, see Appendix E).\nOur upper-bounds depend on the ratio \u2016K\u20162F/(\u03bb\u03b3) where \u03bb is the regularization strength and \u03b3 \u2248 n in our setting where we minimize an average risk. Setting \u03bb = \u03bb0 = \u2016K\u20162F/n2 corresponds to a regularization proportional to the average squared radius of the data divided by 1/n which is standard in this setting [1]. We also experiment with smaller regularization (i.e., \u03bb/\u03bb0 = 10\n\u22121), to make the problem more ill-conditioned (it turns out that the corresponding testing losses are sometimes slightly better). We consider two datasets, sido (n = 10142, d = 4932, non-separable losses and regularizers presented above) and rcv1 (n = 20242, d = 47236, separable losses and regularizer described in Appendix F, so that we can compare with SAGA run in the primal). We report below the squared distance to optimizers which appears in our bounds, as a function of the number of passes on the data (for more details and experiments with primal-dual gaps and testing losses, see Appendix F). Unless otherwise specified, we always use non-uniform sampling.\n0 100 200 300 400 500\n10 \u22125\n10 0\nsido \u2212 distance to optimizers \u2212 \u03bb/\u03bb 0 =1.00\nfb\u2212acc fb\u2212sto saga saga (unif) svrg svrg\u2212acc fba\u2212primal\n0 100 200 300 400 500 10\n\u22125\n10 0\nsido \u2212 distance to optimizers \u2212 \u03bb/\u03bb 0 =0.10\nfb\u2212acc fb\u2212sto saga saga (unif) svrg svrg\u2212acc fba\u2212primal\n0 100 200 300 400 500 10\n\u221215\n10 \u221210\n10 \u22125\n10 0\nrcv1 \u2212 distance to optimizers \u2212 \u03bb/\u03bb 0 =1.00\nfb\u2212acc fb\u2212sto saga saga (unif) svrg svrg\u2212acc fba\u2212primal saga\u2212primal\nWe see that uniform sampling for SAGA does not improve on batch methods, SAGA and accelerated SVRG improve significantly over the existing methods, with a stronger gain for the accelerated version for ill-conditioned problems (middle vs. left plot). On the right plot, we compare to primal methods on a separable loss, showing that primal methods (here \u201cfba-primal\u201d, which is Nesterov acceleration) that do not use separability (and can thus be applied in all cases) are inferior, while SAGA run on the primal remains faster (but cannot be applied for non-separable losses)."}, {"heading": "8 Conclusion", "text": "We proposed the first linearly convergent incremental gradient algorithms for saddle-point problems, which improve both in theory and practice over existing batch or stochastic algorithms. While we currently need to know the strong convexity-concavity constants, we plan to explore in future work adaptivity to these constants like already obtained for convex minimization [4], paving the way to an analysis without strong convexity-concavity."}, {"heading": "Acknowledgements", "text": "We would like to thank Simon Lacoste-Julien and Jalal Fadili for fruitful discussions related to saddle-point problems and monotone operators."}, {"heading": "A Formalization through Monotone Operators", "text": "Throughout the proofs, we will consider only maximal monotone operators on a Euclidean space E, that is A is assumed to be a \u00b5-strongly monotone (corresponding to M for saddle-points) and potentially set-valued, while B is monotone and L-Lipschitz-continuous with respect to the Euclidean norm (and hence single-valued). For an introduction to monotone operators, see [9, 31].\nFor simplicity, in this appendix, we will only consider a single-valued operator A (noting that the proof extends to any set-valued operator A), and we will mostly focus here on the monotonicity properties (noting that the \u201cmaximal\u201d can be treated rigorously [9], in particular to ensure that the resolvent operator is defined everywhere). An operator is monotone if and only if for all (z, z\u2032), (A(z)\u2212A(z\u2032))\u22a4(z \u2212 z\u2032) > 0. The most basic example is the subdifferential of a convex function. In this paper, we focus on saddle-point problems.\nApplication to saddle-point problems. For the saddle-point problems defined in Section 2 of the main paper, where we have z = (x, y), we need to make a change of variable because of the two potentially different scaling factors \u03bb and \u03b3. We consider the operators\nB(x, y) = (\u03bb\u22121/2\u2202xK(\u03bb \u22121/2x, \u03b3\u22121/2y),\u2212\u03b3\u22121/2\u2202yK(\u03bb\u22121/2x, \u03b3\u22121/2y)) A(x, y) = (\u03bb\u22121/2\u2202xM(\u03bb \u22121/2x, \u03b3\u22121/2y),\u2212\u03b3\u22121/2\u2202yM(\u03bb\u22121/2x, \u03b3\u22121/2y)).\nThe solutions of A(x, y) + B(x, y) = 0 are exactly the solutions of the problem in Eq. (1), rescaled by \u03bb1/2 and \u03b31/2. Moreover, the operator A is 1-monotone, i.e., for any z, z\u2032, we have (A(z) \u2212 A(z\u2032))\u22a4(z \u2212 z\u2032) > \u2016z\u2212 z\u2032\u20162. Finally, our definition of the smoothness constants for B and Bi in the main paper, exactly leads to a Lipschitz-constant of L with respect to the natural Euclidean norm (a similar result holds for the constant L\u0304(\u03c0) defined later). Moreover, convergence results in the Euclidean norm here transfer to convergence results in the norm \u2126 defined in the main paper. Note that because of our proofs through operators, it is not easily possible to get bounds on the primal and dual gaps.\nProperties of monotone operators and resolvents. Given a maximal monotone operator A, we may define its resolvent operator as z\u2032 = (I + \u03c3A)\u22121(z), which is defined as finding z\u2032 such that z\u2032 + \u03c3A(z\u2032) = z. When A is the operator associated to the saddle-point function M as described above, then the resolvent operator is exactly the proximal operator of M defined in Eq. (2) of the main paper. Note that care has to be taken with the scaling factors \u03bb and \u03b3.\nWe will use the following properties (on top of Lipschitz-continuity) [9, 31]:\n\u2013 Monotonicity property: for any (z, z\u2032), (B(z)\u2212B(z\u2032), z \u2212 z\u2032) > 0.\n\u2013 Contractivity of the resolvent operator for A \u00b5-strongly-monotone: for any (z, z\u2032), \u2016(I+\u03c3A)\u22121(z)\u2212 (I + \u03c3A)\u22121(z\u2032)\u2016 6 (1 + \u03c3\u00b5)\u22121\u2016z \u2212 z\u2032\u2016.\n\u2013 Firm non-expansiveness of the resolvent: for any (z, z\u2032), \u2016(I + \u03c3A)\u22121(z) \u2212 (I + \u03c3A)\u22121(z\u2032)\u20162 6 (1 + \u03c3\u00b5)\u22121(z \u2212 z\u2032)\u22a4 ( (I + \u03c3A)\u22121(z)\u2212 (I + \u03c3A)\u22121(z\u2032) ) .\nMoreover, given our strong-monotonicity assumption, A+B has a unique zero z\u2217 \u2208 E. Finally in order to characterize the running-times, we will consider the complexity Tfw(B) of computing the operator B and the complexity Tbw(A) to compute the resolvent of A. For saddle-point problems, these correspond to T (B) and Tprox(M) from the main paper."}, {"heading": "B Proof for Deterministic Algorithms", "text": "All proofs in this section will follow the same principle, by showing that at every step of our algorithms, a certain function (a \u201cLyapunov\u201d function) is contracted by a factor strictly less than one. For the forward-backward algorithm, this will be the distance to optimum \u2016zt \u2212 z\u2217\u20162; while for the accelerated version, it will be different.\nB.1 Forward-backward algorithm\nWe consider the iteration zt = (I + \u03c3A) \u22121(zt\u22121 \u2212 \u03c3B(zt\u22121)), with B being monotone L-Lipschitzcontinuous and A being \u00b5-strongly monotone. The optimum z\u2217 (i.e., the zero of A+B) is invariant by this iteration. Note that this is the analysis of [20] and that we could improve by putting some of the strong-monotonicity in the operator B rather than in A.\nWe have:\n\u2016zt \u2212 z\u2217\u20162\n6 1\n(1 + \u03c3\u00b5)2 \u2016zt\u22121 \u2212 z\u2217 \u2212 \u03c3(B(zt\u22121)\u2212B(z\u2217))\u20162 by contractivity of the resolvent,\n= 1\n(1 + \u03c3\u00b5)2\n[ \u2016zt\u22121 \u2212 z\u2217\u20162 \u2212 2\u03c3(zt\u22121 \u2212 z\u2217)\u22a4(B(zt\u22121)\u2212B(z\u2217)) + \u03c32\u2016B(zt\u22121)\u2212B(z\u2217)\u20162 ]\n6 1\n(1 + \u03c3\u00b5)2 (1 + \u03c32L2)\u2016zt\u22121 \u2212 z\u2217\u20162 by monotonicity of and Lipschitz-continuity of B,\n6\n( 1 + \u03c32L2\n(1 + \u03c3\u00b5)2\n)t\n\u2016z0 \u2212 z\u2217\u20162, by applying the recursion t times.\nThus we get linear (i.e., geometric) convergence as soon as 1 + \u03c32L2 < (1 + \u03c3\u00b5)2. If we consider \u03b7 = \u03c3\u00b51+\u03c3\u00b5 \u2208 [0, 1), and the rate above becomes equal to:\n1 + \u03c32L2\n(1 + \u03c3\u00b5)2 = (1\u2212 \u03b7)2 + \u03b72L\n2\n\u00b52 = 1\u2212 2\u03b7 + \u03b72(1 + L\n2\n\u00b52 ),\nthus the algorithm converges if \u03b7 < 2 1+L 2\n\u00b52\n, and with \u03b7 = 1 1+L 2\n\u00b52\nwhich corresponds to \u03c3 = 1\u00b5 \u03b7 1\u2212\u03b7 = \u00b5 L2 ,\nwe get a linear convergence rate with constant 1\u2212 \u03b7 = L2\u00b52+L2 .\nThus the complexity to reach the precision \u03b5\u00d7\u2016z0\u2212 z\u2217\u20162 in squared distance to optimum \u2016zt\u2212 z\u2217\u20162 is equal to ( 1 + L 2\n\u00b52 ) [ Tfw(B) + Tbw(A) ] log 1\u03b5 .\nNote that we obtain a slow convergence when applied to convex minimization, because we are not using any co-coercivity of B, which would lead to a rate (1\u2212 \u00b5/L) [7]. Indeed, co-coercivity means that \u2016B(z)\u2212B(z\u2032)\u20162 6 L(B(z)\u2212B(z\u2032))\u22a4(z\u2212z\u2032), and this allows to replace above the term 1+\u03c32L2 by 1 if \u03c3 6 2/L, leading to linear convergence rate with constant (1 + \u00b5/L)\u22122 \u2248 1\u2212 2\u00b5/L.\nB.2 Accelerated forward-backward algorithm\nWe consider the iteration zt = (I+\u03c3A) \u22121(zt\u22121\u2212\u03c3B[zt\u22121+\u03b8(zt\u22121\u2212zt\u22122)]), with B being monotone L-Lipschitz-continuous and linear, and A being \u00b5-strongly monotone. Note that this is an extension of the analysis of [21] to take into account the general monotone operator situation. Again z\u2217 is a fixed-point of the iteration.\nUsing the firm non-expansiveness of the resolvent operator, we get, with \u03b7 = \u03c3\u00b51+\u03c3\u00b5 , and then using the linearity of B:\n\u2016zt \u2212 z\u2217\u20162 6 1 1 + \u03c3\u00b5 (zt \u2212 z\u2217)\u22a4 [ zt\u22121 \u2212 z\u2217 \u2212 \u03c3B[zt\u22121 \u2212 z\u2217 + \u03b8(zt\u22121 \u2212 zt\u22122)] ]\n= (zt \u2212 z\u2217)\u22a4 [ (1 \u2212 \u03b7)(zt\u22121 \u2212 z\u2217)\u2212 \u03b7\n\u00b5 B[zt\u22121 \u2212 z\u2217 + \u03b8(zt\u22121 \u2212 zt\u22122)]\n]\n= \u22121\u2212 \u03b7 2 \u2016zt \u2212 zt\u22121\u20162 + 1\u2212 \u03b7 2 \u2016zt \u2212 z\u2217\u20162 + 1\u2212 \u03b7 2 \u2016zt\u22121 \u2212 z\u2217\u20162\n\u2212 \u03b7 \u00b5 (zt \u2212 z\u2217)\u22a4B[zt\u22121 \u2212 z\u2217 + \u03b8(zt\u22121 \u2212 zt\u22122)]\n= \u22121\u2212 \u03b7 2 \u2016zt \u2212 zt\u22121\u20162 + 1\u2212 \u03b7 2 \u2016zt \u2212 z\u2217\u20162 + 1\u2212 \u03b7 2 \u2016zt\u22121 \u2212 z\u2217\u20162\n\u2212 \u03b7 \u00b5 (zt \u2212 z\u2217)\u22a4B(zt\u22121 \u2212 z\u2217)\u2212 \u03b8 \u03b7 \u00b5 (zt \u2212 z\u2217)\u22a4B(zt\u22121 \u2212 zt\u22122),\nby regrouping terms. By using the Lipschitz-continuity of B, we get:\n\u2016zt \u2212 z\u2217\u20162\n6 \u22121\u2212 \u03b7 2 \u2016zt \u2212 zt\u22121\u20162 + 1\u2212 \u03b7 2 \u2016zt \u2212 z\u2217\u20162 + 1\u2212 \u03b7 2 \u2016zt\u22121 \u2212 z\u2217\u20162 \u2212 \u03b7 \u00b5 (zt \u2212 z\u2217)\u22a4B(zt\u22121 \u2212 zt)\n\u2212\u03b8 \u03b7 \u00b5 (zt\u22121 \u2212 z\u2217)\u22a4B(zt\u22122 \u2212 zt\u22121) + \u03b8 \u03b7 \u00b5 L\u2016zt \u2212 zt\u22121\u2016\u2016zt\u22121 \u2212 zt\u22122\u2016\n6 \u22121\u2212 \u03b7 2 \u2016zt \u2212 zt\u22121\u20162 + 1\u2212 \u03b7 2 \u2016zt \u2212 z\u2217\u20162 + 1\u2212 \u03b7 2 \u2016zt\u22121 \u2212 z\u2217\u20162 \u2212 \u03b7 \u00b5 (zt \u2212 z\u2217)\u22a4B(zt\u22121 \u2212 zt)\n\u2212\u03b8 \u03b7 \u00b5 (zt\u22121 \u2212 z\u2217)\u22a4B(zt\u22122 \u2212 zt\u22121) + \u03b8L 2 \u03b7 \u00b5 [ \u03b1\u22121\u2016zt \u2212 zt\u22121\u20162 + \u03b1\u2016zt\u22121 \u2212 zt\u22122\u20162 ] ,\nwith a constant \u03b1 > 0 to be determined later. This leads to, with \u03b8 = 1\u2212\u03b71+\u03b7 , and by regrouping terms:\n1 + \u03b7\n2 \u2016zt \u2212 z\u2217\u20162 + (1\u2212 \u03b7 2 \u2212 \u03b8\u03b7L 2\u00b5 \u03b1\u22121 ) \u2016zt \u2212 zt\u22121\u20162 \u2212 \u03b7(zt \u2212 z\u2217)\u22a4B(zt\u22121 \u2212 zt)\n6 1\u2212 \u03b7 2 \u2016zt\u22121 \u2212 z\u2217\u20162 + (\u03b1\u03b7\u03b8L 2\u00b5 ) \u2016zt\u22121 \u2212 zt\u22122\u20162 \u2212 \u03b8 \u03b7 \u00b5 (zt\u22121 \u2212 z\u2217)\u22a4B(zt\u22122 \u2212 zt\u22121)\n6 \u03b8\n[\n1 + \u03b7\n2 \u2016zt\u22121 \u2212 z\u2217\u20162 +\n(\u03b7\u03b1L\n2\u00b5\n) \u2016zt\u22121 \u2212 zt\u22122\u20162 \u2212 \u03b7 \u00b5 (zt\u22121 \u2212 z\u2217)\u22a4B(zt\u22122 \u2212 zt\u22121)\n]\n.\nWe get a Lyapunov function L : (z, z\u2032) 7\u2192 1+\u03b72 \u2016z \u2212 z\u2217\u20162 + ( 1\u2212\u03b7 2 \u2212 \u03b8\u03b7L 2\u00b5 \u03b1 \u22121 ) \u2016z \u2212 z\u2032\u20162 \u2212 \u03b7(z \u2212 z\u2217)\u22a4B(z\u2032 \u2212 z), such that L(zt, zt\u22121) converges to zero geometrically, if \u03b1\u03b7L\u00b5 6 1\u2212 \u03b7 \u2212 \u03b7\u03b8L \u00b5 \u03b1 \u22121 and (\n1 + \u03b7 \u2212\u03b7L/\u00b5 \u03b7L/\u00b5 1\u2212 \u03b7 \u2212 \u03b7\u03b8L\u00b5\u22121\u03b1\u22121\n)\n< 0. By setting \u03b7 = 11+2L/\u00b5 , and thus \u03b8 = 1\u2212\u03b7 1+\u03b7 = 1 1+\u00b5/L , \u03c3 =\n1 \u00b5 \u03b7 1\u2212\u03b7 = 1 2L , and \u03b1 = 1, we get the desired first property and the fact that the matrix above is greater\nthan\n(\n1/2 0 0 0\n)\n, which allows us to get a linear rate of convergence for \u2016zt \u2212 z\u2217\u20162 6 2L(zt, zt\u22121)."}, {"heading": "C Proof for Existing Stochastic Algorithms", "text": "We follow [25], but with a specific step-size that leads to a simple result, which also applies to nonuniform sampling from a finite pool. We consider the iteration zt = (I + \u03c3tA)\n\u22121(zt\u22121 \u2212 \u03c3t(Bzt\u22121 + Ctzt\u22121)), with B being monotone L-Lipschitz-continuous and A being \u00b5-strongly monotone, and Ct a random operator (not necessarily monotone) such that ECt(z) = 0 for all z. We assume that all random operators Ct are independent, and we denote by Ft the \u03c3-field generated by C1, . . . , Ct, i.e., the information up to time t.\nWe have with Lip(Ct) the Lipschitz-constant of Ct:\n\u2016zt \u2212 z\u2217\u20162 6 1\n(1 + \u03c3t\u00b5)2 \u2016zt\u22121 \u2212 z\u2217 \u2212 \u03c3t(B(zt\u22121)\u2212B(z\u2217))\u2212 \u03c3tCt(zt\u22121)\u20162\nby contractivity of the resolvent,\n= 1\n(1 + \u03c3t\u00b5)2\n[\n\u2016zt\u22121 \u2212 z\u2217\u20162 \u2212 2\u03c3t(zt\u22121 \u2212 z\u2217)\u22a4(B(zt\u22121)\u2212B(z\u2217))\n+\u03c32t \u2016B(zt\u22121)\u2212B(z\u2217) + Ct(zt\u22121)\u20162 + 2\u03c3t(Ct(zt\u22121))\u22a4(zt\u22121 \u2212 z\u2217) ] .\nBy taking conditional expectations, we get:\nE ( \u2016zt \u2212 z\u2217\u20162 \u2223 \u2223Ft\u22121 ) 6 1\n(1 + \u03c3t\u00b5)2 [ (1 + \u03c32tL 2)\u2016zt\u22121 \u2212 z\u2217\u20162 + \u03c32tE(\u2016Ct(zt\u22121)\u20162|Ft\u22121) ]\nby monotonicity and Lipschitz-continuity of B,\n6 1\n(1 + \u03c3t\u00b5)2 [ (1 + \u03c32tL 2)\u2016zt\u22121 \u2212 z\u2217\u20162 + 2\u03c32tE(\u2016Ct(z\u2217)\u20162|Ft\u22121)\n+2\u03c32t \u2016zt\u22121 \u2212 z\u2217\u20162E( sup \u2016z\u2212z\u2032\u2016=1 \u2016Ct(z)\u2212 Ct(z\u2032)\u20162|Ft\u22121) ]\n= 1\n(1 + \u03c3t\u00b5)2 [ (1 + \u03c32tL 2)\u2016zt\u22121 \u2212 z\u2217\u20162 + 2\u03c32tE(\u2016Ct(z\u2217)\u20162|Ft\u22121)\n+2\u03c32t \u2016zt\u22121 \u2212 z\u2217\u20162E(Lip(Ct)2|Ft\u22121) ]\n= 1\n(1 + \u03c3t\u00b5)2 [ (1 + \u03c32tL 2 + 2\u03c32tE(Lip(Ct) 2|Ft\u22121))\u2016zt\u22121 \u2212 z\u2217\u20162 + 2\u03c32tE(\u2016Ct(z\u2217)\u20162|Ft\u22121) ] .\nBy denoting \u03b7t = \u03c3t\u00b5 1+\u03c3t\u00b5 \u2208 [0, 1), we get\nE\u2016zt \u2212 z\u2217\u20162 6 ( 1\u2212 2\u03b7t + \u03b72t + 2\u03b72t L2\n\u00b52 + 2\u03b72t\n1\n\u00b52 E(Lip(Ct)\n2|Ft\u22121) ) \u2016zt\u22121 \u2212 z\u2217\u20162 + 2 \u03b72t \u00b52 E(\u2016Ctz\u2217\u20162|Ft\u22121) ] .\nBy selecting \u03b7t = 2\n(t+1)+4L 2\n\u00b52 + 4 \u00b52 E(Lip(Ct)2|Ft\u22121)\n= 2t+1+A , with A = 4 L2 \u00b52 + 4 \u00b52E(Lip(Ct) 2|Ft\u22121), we get:\nE\u2016zt \u2212 z\u2217\u20162 6 (1 \u2212 \u03b7t)E\u2016zt\u22121 \u2212 z\u2217\u20162 + 2 \u03b72t \u00b52 E(\u2016Ctz\u2217\u20162) ]\n= t\u2212 1 +A t+ 1 +A E\u2016zt\u22121 \u2212 z\u2217\u20162 + 8 (t+ 1 +A)2 1 \u00b52 E(\u2016Ctz\u2217\u20162)\n6 A(1 +A)\n(t+ 1 +A)(t+A) \u2016z0 \u2212 z\u2217\u20162 +\n8\n\u00b52\nt \u2211\nu=1\n(u+A)(u + 1 +A)\n(t+ 1 +A)(t+A)\n1\n(u + 1 +A)2 E(\u2016Cuz\u2217\u20162)\nby expanding the recursion t times,\n6 A(1 +A)\n(t+ 1 +A)(t+A) \u2016z0 \u2212 z\u2217\u20162 +\n8\n\u00b52\nt \u2211\nu=1\n1\n(t+ 1+ A)(t+A) E(\u2016Cuz\u2217\u20162)\n6 (1 +A)2\n(t+A)2 \u2016z0 \u2212 z\u2217\u20162 +\n8\n\u00b52(t+A) sup u\u2208{1,...,t} E(\u2016Cuz\u2217\u20162).\nThe overall convergence rate is in O(1/t) and the constant depends on the noise in the operator values at the optimum. Note that initial conditions are forgotten at a rate O(1/t2).\nApplication to sampling from a finite family. When sampling from |I| operators Bi, i \u2208 I, and selecting it with probability vector \u03c0, then we have E(Lip(Ct)\n2|Ft\u22121) 6 L\u0304(\u03c0)2 = L\u03042 defined as sup\u2016z\u2212z\u2032\u201661 \u221a \u2211 i\u2208I 1 \u03c0i \u2016Bi(z)\u2212Bi(z\u2032)\u20162. Thus, we can take the step-size 2\nt+1+4L 2+L\u03042\n\u00b52\n, and thus\n\u03c3t = 2/\u00b5\nt+1+4L 2+L\u03042\n\u00b52\n. Moreover, if L is unknown (or hard to compute), we can take L\u0304 instead.\nWe may further bound: E(\u2016Cuz\u2217\u20162) 6 2E(\u2016Cuz0\u20162) + 2E(Lip(Ct)2)\u2016z0 \u2212 z\u2217\u20162, and thus, if we start from an initial point z0 such that Cuz0 = 0, which is always possible for bi-linear problems, we get an overall bound of (taking L = L\u0304 for simplicity)\n( (1 + 8L\u03042/\u00b52)2\n(t+ 8L\u03042/\u00b52)2 +\n16L\u03042/\u00b52\nt+ 8L\u03042/\u00b52\n) \u2016z0 \u2212 z\u2217\u20162 6 1 + 24L\u03042/\u00b52\nt+ 8L\u03042/\u00b52 \u2016z0 \u2212 z\u2217\u20162.\nWe thus get an overall O(1/t) convergence rate."}, {"heading": "D Proof for New Stochastic Algorithms", "text": "We also consider the monotone operator set-up, since this is the only assumption that we use. We follow the proof of the corresponding convex minimization algorithms, with key differences which we highlight below. In particular, (a) we do not use function values, and (b) we use shorter step-sizes to tackle the lack of co-coercivity.\nD.1 SVRG: Stochastic-Variance reduced saddle-point problems (Theorem 1)\nWe only analyze a single epoch starting from the reference estimate z\u0303, and show that the expected squared distance to optimum is shrunk by a factor of 3/4 if the number of iterations per epoch is well-chosen. The epoch is started with z0 = z\u0303.\nWe denote by Ft\u22121 the information up to time t \u2212 1. We consider sampling it1, . . . , itm \u2208 I with replacement at time t. By using the contractivity of the resolvent operator of A, and the fact that z\u2217 = (I + \u03c3A)\u22121(z\u2217 \u2212 \u03c3B(z\u2217)), we get:\n\u2016zt \u2212 z\u2217\u20162 6 1\n(1 + \u03c3\u00b5)2\n\u2225 \u2225 \u2225 zt\u22121 \u2212 z\u2217 \u2212 \u03c3[B(z\u0303)\u2212B(z\u2217) + 1\nm\nm \u2211\nk=1\n1\n\u03c0itk (Bitk (zt\u22121)\u2212Bitk (z\u0303))]\n\u2225 \u2225 \u2225 2\n= 1\n(1 + \u03c3\u00b5)2\n\u2225 \u2225 \u2225 zt\u22121 \u2212 z\u2217\n\u2212\u03c3[B(zt\u22121)\u2212B(z\u2217) + 1\nm\nm \u2211\nk=1\n1\n\u03c0itk (Bitk (zt\u22121)\u2212Bitk(z\u0303))\u2212 (B(zt\u22121)\u2212B(z\u0303))]\n\u2225 \u2225 \u2225 2 .\nExpanding the squared norm, taking conditional expectations with E( 1\u03c0itk Bitk|Ft\u22121) = B, and using the independence of it1, . . . , itm, we get:\nE [ \u2016zt \u2212 z\u2217\u20162|Ft\u22121 ]\n6 1\n(1 + \u03c3\u00b5)2 ( \u2016zt\u22121 \u2212 z\u2217\u20162 \u2212 2\u03c3(zt\u22121 \u2212 z\u2217)\u22a4(B(zt\u22121)\u2212B(z\u2217)) + \u03c32\u2016B(zt\u22121)\u2212B(z\u2217)\u20162 )\n+ 1\nm E\n[ 1\n(1 + \u03c3\u00b5)2\n\u2225 \u2225 \u2225 1\n\u03c0it (Bit(zt\u22121)\u2212Bit(z\u0303))\u2212 (B(zt\u22121)\u2212B(z\u0303))\n\u2225 \u2225 \u2225 2\u2223 \u2223 \u2223 Ft\u22121 ] .\nUsing the monotonicity of B and the Lipschitz-continuity of B (like in Appendix B.1) , we get the bound\n1 + \u03c32L2 (1 + \u03c3\u00b5)2 \u2016zt\u22121 \u2212 z\u2217\u20162 + 1 m E [ 1 (1 + \u03c3\u00b5)2 \u2225 \u2225 1 \u03c0it (Bit(zt\u22121)\u2212Bit(z\u0303))\u2212 (B(zt\u22121)\u2212B(z\u0303)) \u2225 \u2225 2\u2223 \u2223Ft\u22121 ] .\nWe denote by L\u03042 the quantity L\u03042 = supz,z\u2032\u2208E 1 \u2016z\u2212z\u2032\u20162 \u2211 i\u2208I 1 \u03c0i \u2016Bi(z)\u2212Bi(z\u2032)\u20162. We then have (using the fact that a variance is less than the second-order moment):\nE\n[\n\u2225 \u2225\n1\n\u03c0it (Bit(zt\u22121)\u2212Bit(z\u0303))\u2212 (B(zt\u22121)\u2212 B(z\u0303))\n\u2225 \u2225 2\u2223 \u2223Ft\u22121\n]\n6 E\n[\n\u2225 \u2225\n1\n\u03c0it (Bit(zt\u22121)\u2212Bit(z\u0303))\n\u2225 \u2225 2\u2223 \u2223Ft\u22121\n]\n,\nwhich is less than L\u03042\u2016zt\u22121 \u2212 z\u0303\u20162 because we sample i from \u03c0. This leads to\nE [ \u2016zt \u2212 z\u2217\u20162|Ft\u22121 ] 6 1 + \u03c32L2\n(1 + \u03c3\u00b5)2 \u2016zt\u22121 \u2212 z\u2217\u20162 +\n1 (1 + \u03c3\u00b5)2 L\u03042 m \u2016zt\u22121 \u2212 z\u0303\u20162\n6\n( 1\u2212 2\u03b7 + \u03b72 + \u03b72L 2\n\u00b52 +\n(1 + a)\u03b72 \u00b52 L\u03042 m ) \u2016zt\u22121 \u2212 z\u2217\u20162\n+ (1 + a\u22121)\u03b72 \u00b52 L\u03042 m \u2016z\u0303 \u2212 z\u2217\u20162,\nwith \u03b7 = \u03c3\u00b51+\u03c3\u00b5 \u2208 [0, 1) and a > 0 to be determined later. Assuming that \u03b7 ( 1 + L 2 \u00b52 + (1+a) \u00b52 L\u03042 m ) 6 1, and taking full expectations, this leads to:\nE\u2016zt \u2212 z\u2217\u20162 6 (1\u2212 \u03b7)E\u2016zt\u22121 \u2212 z\u2217\u20162 + (1 + a\u22121)\u03b72 \u00b52 L\u03042 m \u2016z\u0303 \u2212 z\u2217\u20162,\nthat is we get a shrinking of the expected distance to optimum with additional noise that depends on the distance to optimum of the reference point z\u0303. The difference with the convex minimization set-up of [27] is that the proof is more direct, and we get a shrinkage directly on the iterates (we\nhave no choice for monotone operators), without the need to do averaging of the iterates. Moreover, we never use any monotonicity of the operators Bi, thus allowing any type of splits (as long as the sum B is monotone).\nThen, using the fact that z0 = z\u0303, and expanding the recursion:\nE\u2016zt \u2212 z\u2217\u20162 6 (1 \u2212 \u03b7)t\u2016z0 \u2212 z\u2217\u20162 + (\nt\u22121 \u2211\nu=0\n(1 \u2212 \u03b7)u ) (1 + a\u22121)\u03b72 \u00b52 L\u03042 m \u2016z\u0303 \u2212 z\u2217\u20162\n6\n( (1 \u2212 \u03b7)t + (1 + a \u22121)\u03b7 \u00b52 L\u03042 m ) \u2016z\u0303 \u2212 z\u2217\u20162.\nIf we take a = 2, \u03b7 = 1\u2223 \u22231+L2+3L\u03042/(m\u00b52) , which corresponds to \u03c3 = 1\u00b5 \u03b7 1\u2212\u03b7 = \u00b5 \u2223\n\u2223L2+ 3 m\nL\u03042 and t =\nlog 4/\u03b7 = log 4 \u00d7 (1 + L2\u00b52 + 3 L\u0304 2 m\u00b52 ), we obtain a bound of 3/4, that is, after t step in an epoch, we obtain E\u2016zt \u2212 z\u2217\u20162 6 34\u2016z\u0303 \u2212 z\u2217\u20162, which is the desired result.\nIn terms of running-time, we therefore need a time proportional to T (B)+ ( 1+L 2 \u00b52 +3 L\u03042 m\u00b52 )( mmaxi T (Bi)+ Tprox(A) ) , times log 1\u03b5 to reach precision \u03b5. Note that if L2 is too expensive to compute (because it is a global constant), we may replace it by L\u03042 and get a worse bound (but still a valid algorithm).\nD.2 SAGA: Online stochastic-variance reduced saddle-point problems (Theorem 2)\nThe proof follows closely the one of SVRG above. Following the same arguments, we get, by contractivity of the resolvent operator:\n\u2016zt \u2212 z\u2217\u20162 6 1\n(1 + \u03c3\u00b5)2\n\u2225 \u2225 \u2225 zt\u22121 \u2212 z\u2217 \u2212 \u03c3[ \u2211\ni\u2208I git\u22121 \u2212B(z\u2217) +\n1\nm\nm \u2211\nk=1\n1\n\u03c0itk (Bitk(zt\u22121)\u2212 gitkt\u22121)]\n\u2225 \u2225 \u2225 2\n= 1\n(1 + \u03c3\u00b5)2\n\u2225 \u2225 \u2225 zt\u22121 \u2212 z\u2217 \u2212 \u03c3[B(zt\u22121)\u2212B(z\u2217)\n+ 1\nm\nm \u2211\nk=1\n1\n\u03c0itk (Bitk(zt\u22121)\u2212 gitkt\u22121)\u2212 (B(zt\u22121)\u2212\n\u2211 i\u2208I git\u22121)]\n\u2225 \u2225 \u2225 2 .\nThen, using independence, monotonicity and Lipschitz-continuity of B, we get (note that we never use any monotonicity of Bi), like in the proof of Theorem 1:\nE [ \u2016zt \u2212 z\u2217\u20162|Ft\u22121 ] 6 1 + \u03c32L2\n(1 + \u03c3\u00b5)2 \u2016zt\u22121 \u2212 z\u2217\u20162\n+ 1\nm E\n[ 1\n(1 + \u03c3\u00b5)2 \u2225 \u2225\n1\n\u03c0it (Bit(zt\u22121)\u2212 gitt\u22121)\u2212 (B(zt\u22121)\u2212\n\u2211 i\u2208I git\u22121) \u2225 \u2225 2\u2223 \u2223Ft\u22121\n]\n6 1 + \u03c32L2\n(1 + \u03c3\u00b5)2 \u2016zt\u22121 \u2212 z\u2217\u20162 +\n1\nm\n1\n(1 + \u03c3\u00b5)2\n(\n\u2211\ni\u2208I\n1\n\u03c0i \u2016Bi(zt\u22121)\u2212 git\u22121\u20162\n)\n6\n( 1\u2212 2\u03b7 + \u03b72 + \u03b72L 2\n\u00b52 +\n(1 + a)\u03b72 \u00b52 L\u03042 m ) \u2016zt\u22121 \u2212 z\u2217\u20162\n+ (1 + a\u22121)\u03b72\n\u00b52m\n(\n\u2211\ni\u2208I\n1\n\u03c0i \u2016Bi(z\u2217)\u2212 git\u22121\u20162\n)\n,\nwith \u03b7 = \u03c3\u00b51+\u03c3\u00b5 . Assuming \u03b7 ( 1 + L 2 \u00b52 + (1+a) \u00b52 L\u03042 m ) 6 1, we get\nE [ \u2016zt \u2212 z\u2217\u20162|Ft\u22121 ] 6 (1\u2212 \u03b7)\u2016zt\u22121 \u2212 z\u2217\u20162 + (1 + a\u22121)\u03b72\n\u00b52m\n(\n\u2211\ni\u2208I\n1 \u03c0i \u2016Bi(z\u2217)\u2212 git\u22121\u20162 ) .\nLike in the SVRG proof above, we get a contraction of the distance to optimum, with now an added noise that depends on the difference between our stored operator values and the operator values at the global optimum. We thus need to control this distance by adding the proper factors to a Lyapunov function. Note that we never use any monotonicity of the operators Bi, thus allowing any type of splits (as long as the sum B is monotone).\nWe assume that we update (at most m because we are sampling with replacement and we may sample the same gradient twice) \u201cgradients\u201d git uniformly at random (when we consider uniform sampling, we can reuse the same gradients as dependence does not impact the bound), by replacing them by git = Bi(zt\u22121). Thus:\nE\n(\n\u2211\ni\u2208I\n1\n\u03c0i \u2016Bi(z\u2217)\u2212 git\u20162\n\u2223 \u2223 \u2223 Ft\u22121 )\n= E ( \u2211\ni selected\n1\n\u03c0i \u2016Bi(z\u2217)\u2212Bi(zt\u22121)\u20162 +\n\u2211\ni non selected\n1\n\u03c0i \u2016Bi(z\u2217)\u2212 git\u22121\u20162\n\u2223 \u2223 \u2223 Ft\u22121 )\n=E ( \u2211\ni selected\n1\n\u03c0i\n( \u2016Bi(z\u2217)\u2212 Bi(zt\u22121)\u20162 \u2212 \u2016Bi(z\u2217)\u2212 git\u22121\u20162 ) + \u2211\ni\u2208I\n1\n\u03c0i \u2016Bi(z\u2217)\u2212 git\u22121\u20162\n\u2223 \u2223 \u2223 Ft\u22121 ) .\nSince we sample uniformly with replacement, the marginal probabilities of selecting an element i is equal to \u03c1 = 1\u2212 (1\u2212 1|I| )m. We thus get\nE\n(\n\u2211\ni\u2208I\n1\n\u03c0i \u2016Bi(z\u2217)\u2212 git\u20162\n\u2223 \u2223 \u2223 Ft\u22121 ) 6 (1\u2212 \u03c1) \u2211\ni\u2208I\n1\n\u03c0i \u2016Bi(z\u2217)\u2212 git\u22121\u20162 + \u03c1\n\u2211\ni\u2208I\n1 \u03c0i \u2016Bi(z\u2217)\u2212Bi(zt\u22121)\u20162\n6 (1\u2212 \u03c1) \u2211\ni\u2208I\n1\n\u03c0i \u2016Bi(z\u2217)\u2212 git\u22121\u20162 + \u03c1L\u03042\u2016zt\u22121 \u2212 z\u2217\u20162.\nTherefore, overall, we have, for a scalar b > 0 to be chosen later:\nE\n(\n\u2016zt \u2212 z\u2217\u20162 + b \u2211\ni\u2208I\n1 \u03c0i \u2016Bi(z\u2217)\u2212 git\u20162\n\u2223 \u2223 \u2223 Ft\u22121 )\n6\n( 1\u2212 2\u03b7 + \u03b72 + \u03b72L 2\n\u00b52 +\n(1 + a)\u03b72 \u00b52 L\u03042 m + b\u03c1L\u03042 ) \u2016zt\u22121 \u2212 z\u2217\u20162\n+b ( 1\u2212 \u03c1+ b\u22121 (1 + a \u22121)\u03b72\nm\u00b52\n)\n\u2211\ni\u2208I\n1\n\u03c0i \u2016Bi(z\u2217)\u2212 git\u22121\u20162.\nIf we take a = 2, \u03b7 = 1 max{ 3|I|\n2m ,1+L\n2\n\u00b52 +3 L\u0304\n2 m\u00b52 } , which corresponds to \u03c3 = 1\u00b5 \u03b7 1\u2212\u03b7 = \u00b5 \u2223 \u2223max{ 3|I| 2m \u22121,L2 \u00b52 +3 L\u0304 2 m\u00b52 } ,\nwith b\u03c1L\u03042 = 3\u03b74 , then we get the bound (using \u03b7 6 1/(L\u0304 2/(3m))):\n(1\u2212 \u03b7 4 )\u2016zt\u22121 \u2212 z\u2217\u20162 + (1\u2212 \u03c1 3 ) \u2211\ni\u2208I\n1\n\u03c0i \u2016Bi(z\u2217)\u2212 git\u22121\u20162,\nwhich shows that the function (z, g) 7\u2192 \u2016z \u2212 z\u2217\u20162 + b \u2211 i\u2208I 1 \u03c0i \u2016Bi(z\u2217) \u2212 gi\u20162 is a good Lyapunov function for the problem that shrinks geometrically in expectation (it resembles the one from convex minimization, but without the need for function values).\nFinally, since we assume that m 6 |I|, we have \u03c1 = 1\u2212 (1 \u2212 1/|I|)m > 1\u2212 exp(\u2212m/|I|) > m/(2|I|). This leads to, after t iterations\nE\u2016zt \u2212 z\u2217\u20162 6 (1\u2212min{ \u03b7 4 , m 6|I|}) t [ \u2016z0 \u2212 z\u2217\u20162 + 3\u03b7 4\u03c1L\u03042 \u2211\ni\u2208I\n1\n\u03c0i \u2016Bi(z\u2217)\u2212Bi(z0)\u20162\n]\n.\nWe have \u03b7 6 2m/(3|I|) and 3\u03b7/(4\u03c1) 6 34 2m3|I| 2|I| m 6 1, leading to\nE\u2016zt \u2212 z\u2217\u20162 6 2(1\u2212 \u03b7\n4 )t\u2016z0 \u2212 z\u2217\u20162,\nwhich is the desired result.\nNote that we get the same overall running-time complexity than for SVRG.\nFactored splits. Note that when applying to saddle-points with factored splits, we need to use a Lyapunov function that considers these splits. The only difference is to treat separately the two parts of the vectors, leading to replacing everywhere |I| by max{|J|, |K|}.\nD.3 Acceleration\nWe also consider in this section a proof based on monotone operators. We first give the algorithm for saddle-point problems.\nAlgorithms for saddle-point problems. At each iteration, we need solve the problem in Eq. (4) of the main paper, with the SVRG algorithm applied to K\u0303(x, y) = K(x, y)\u2212 \u03bb\u03c4x\u22a4x\u0304 + \u03b3\u03c4y\u22a4y\u0304, and M\u0303(x, y) = M(x, y)+ \u03bb\u03c42 \u2016x\u20162\u2212 \u03b3\u03c4 2 \u2016y\u20162. These functions lead to constants \u03bb\u0303 = \u03bb(1+ \u03c4), \u03b3\u0303 = \u03b3(1+ \u03c4) and L\u0303 = L/(1 + \u03c4), \u03c3\u0303 = \u03c3(1 + \u03c4)2. We thus get the iteration, for a single selected operator,\n(x, y) \u2190 prox\u03c3\u0303 M\u0303\n[ (x, y)\u2212 \u03c3\u0303 (1/\u03bb\u0303 0 0 1/\u03b3\u0303 )( B\u0303(x\u0303, y\u0303) + { 1 \u03c0i B\u0303i(x, y)\u2212 1 \u03c0i B\u0303i(x\u0303, y\u0303) })] .\nA short calculation shows that prox\u03c3\u0303 M\u0303 (x, y) = prox \u03c3(1+\u03c4)/(1+\u03c3\u03c4(1+\u03c4)) M ((x, y)/(1+\u03c3\u03c4(1+ \u03c4))), leading to the update (with \u03c3 the step-size from the regular SVRG algorithm in Section 3):\n(x, y) \u2190 prox\u03c3\u0303 M\u0303\n[ (x, y) + \u03c3\u03c4(1 + \u03c4)(x\u0304, y\u0304)\u2212 \u03c3(1 + \u03c4) (1/\u03bb 0 0 1/\u03b3 )( B(x\u0303, y\u0303) + { 1 \u03c0i B\u0303i(x, y)\u2212 1 \u03c0i B\u0303i(x\u0303, y\u0303) })] .\nThis leads to Algorithm 3, where differences with the SVRG algorithm, e.g., Algorithm 1, are highlighted in red. Given the value of \u03c4 , the estimate (x\u0304, y\u0304) is updated every log(1 + \u03c4) epochs of SVRG. While this leads to a provably better convergence rate, in practice, this causes the algorithm to waste time solving with too high precision the modified problem. We have used the simple heuristic of changing (x\u0304, y\u0304) one epoch after the primal-dual gap has been reduced from the previous change of (x\u0304, y\u0304).\nProof of Theorem 3 using monotone operators. We consider \u03c4 > 0, and we consider the following algorithm, which is the transposition of the algorithm presented above. We consider a mini-batch m = 1 for simplicity. We consider a set of SVRG epochs, where z\u0304 remains fixed. These epochs are initialized by z\u0303 = z\u0304.\nFor each SVRG epoch, given z and z\u0303, and starting from z = z\u0303, we run t iterations of:\nz \u2190 (I + \u03c3(\u03c4I +A))\u22121 ( z \u2212 \u03c3[Bz\u0303 + 1 \u03c0i (Biz \u2212Biz\u0303)\u2212 \u03c4 z\u0304] ) ,\nAlgorithm 3 Accelerated Stochastic Variance Reduction for Saddle Points\nInput: Functions (Ki)i, M , probabilities (\u03c0i)i, smoothness L\u0304(\u03c0) and L, iterate (x, y) number of epochs v, number of updates per iteration m, acceleration factor \u03c4\nSet \u03c3 = [ L2 + 3L\u03042/m ]\u22121\nand (x\u0304, y\u0304) = (x, y) for u = 1 to v do If u = 0 mod \u23082 + 2 log(1 + \u03c4)/(log 4/3)\u2309, set (x\u0304, y\u0304) = (x\u0303, y\u0303) Initialize (x\u0303, y\u0303) = (x, y) and compute B(x\u0303, y\u0303) for k = 1 to log 4\u00d7 (L2 + 3L\u03042/m)(1 + \u03c4)2 do Sample i1, . . . , im \u2208 I from probability vector (\u03c0i)i with replacement z \u2190 (x, y)+\u03c3\u03c4(1 + \u03c4)(x\u0304, y\u0304)\u2212 \u03c3(1 + \u03c4)\n(1/\u03bb 0 0 1/\u03b3 )( B(x\u0303, y\u0303) + { 1 \u03c0i B\u0303i(x, y)\u2212 1\u03c0i B\u0303i(x\u0303, y\u0303) })\n(x, y) \u2190 prox\u03c3(1+\u03c4)/(1+\u03c3\u03c4(1+\u03c4))M (z/(1 + \u03c3\u03c4(1 + \u03c4))) end for\nend for Output: Approximate solution (x, y)\nand then update z\u0303 as z at the end of the SVRG epoch. It corresponds exactly to running the SVRG algorithm to find (\u03c4I+A+B)\u22121(\u03c4 z\u0304) approximately, we know from the proof of Theorem 1 that after log 4 ( 1+ L 2\n\u00b52(1+\u03c4)2 + L2 \u00b52(1+\u03c4)2 ) iterations, we have an iterate z such that E\u2016z\u2212(\u03c4I+A+B)\u22121(\u03c4 z\u0304)\u20162 6 3 4E\u2016z\u0303\u2212 (\u03c4I +A+B)\u22121(\u03c4 z\u0304)\u20162. Thus, if we run s epochs where we update z\u0303 (but not z\u0304) at each start of epoch, we get an iterate z such that E\u2016z\u2212(\u03c4I+A+B)\u22121(\u03c4 z\u0304)\u20162 6 (34 )sE\u2016z\u0304\u2212(\u03c4I+A+B)\u22121(\u03c4 z\u0304)\u20162, and thus\nE\u2016z \u2212 (\u03c4I +A+B)\u22121(\u03c4 z\u0304)\u20162 6 (3\n4\n)s\nE\u2016z\u0304 \u2212 (\u03c4I +A+B)\u22121(\u03c4 z\u0304)\u20162\n= (3\n4\n)s\nE\u2016z\u0304 \u2212 z\u2217 \u2212 (\u03c4I +A+B)\u22121(\u03c4 z\u0304) + (\u03c4I +A+B)\u22121(\u03c4z\u2217)\u20162\nusing z\u2217 = (\u03c4I +A+B) \u22121(\u03c4z\u2217),\n= (3\n4\n)s\nE\u2016z\u0304 \u2212 z\u2217 \u2212 (I + \u03c4\u22121(A+B))\u22121(z\u0304) + (I + \u03c4\u22121(A+B))\u22121(z\u2217)\u20162.\nWe may now use the fact that for any multi-valued maximal monotone operator C, I \u2212 (I +C)\u22121 = (I + C\u22121)\u22121, which shows that I \u2212 (I + C)\u22121 is 1-Lipschitz-continuous. Thus\nE\u2016z \u2212 (\u03c4I +A+B)\u22121(\u03c4 z\u0304)\u20162 6 (3\n4\n)s\nE\u2016z\u0304 \u2212 z\u2217\u20162.\nThis implies, by Minkowski\u2019s inequality,\n(E\u2016z \u2212 z\u2217\u20162)1/2 6 (E\u2016z \u2212 (\u03c4I +A+B)\u22121(\u03c4 z\u0304)\u20162)1/2 + (E\u2016(\u03c4I +A+B)\u22121(\u03c4 z\u0304)\u2212 z\u2217\u20162)1/2\n6\n(3\n4\n)s/2\n(E\u2016z\u0304 \u2212 z\u2217\u20162)1/2 + (E\u2016(\u03c4I +A+B)\u22121(\u03c4 z\u0304)\u2212 (\u03c4I +A+B)\u22121(\u03c4z\u2217)\u20162)1/2\n= (3\n4\n)s/2\n(E\u2016z\u0304 \u2212 z\u2217\u20162)1/2 + (E\u2016(I + \u03c4\u22121(A+B))\u22121(z\u0304)\u2212 (I + \u03c4\u22121(A+B))\u22121(z\u2217)\u20162)1/2\n6\n(3\n4\n)s/2\n(E\u2016z\u0304 \u2212 z\u2217\u20162)1/2 + 1\n1 + \u03c4\u22121\u00b5 (E\u2016z\u0304 \u2212 z\u2217\u20162)1/2\n= (3\n4\n)s/2 (E\u2016z\u0304 \u2212 z\u2217\u20162)1/2 + \u03c4\n\u03c4 + \u00b5 (E\u2016z\u0304 \u2212 z\u2217\u20162)1/2,\nusing the fact that the contractivity of resolvents of strongly monotone operators. Thus after s = 2 + 2 log(1+ \u03c4 \u00b5 )\nlog 4 3\n, we get a decrease by (1\u2212 \u00b5\u03c4+\u00b5 ), and thus the desired result.\nD.4 Factored splits and bi-linear models\nIn the table below, we report the running-time complexity for the factored splits which we used in simulations. Note that SAGA and SVRG then have different bounds. Moreover, all these schemes are adapted when n is close to d. For n much different from d, one could imagine to (a) either complete with zeros or (b) to regroup the data in the larger dimension so that we get as many blocks as for the lower dimension."}, {"heading": "E Surrogate to Area Under the ROC Curve", "text": "We consider the following loss function on Rn, given a vector of positive and negative labels, which corresponds to a convex surrogate to the number of misclassified pairs [13, 14]:\n\u2113(u) = 1\n2n+n\u2212\n\u2211\ni+\u2208I+\n\u2211\ni\u2212\u2208I\u2212 (1 \u2212 ui\u2212 + ui+)2\n= 1\n2n+n\u2212\n\u2211\ni+\u2208I+\n\u2211\ni\u2212\u2208I\u2212\n{\n1 + u2i\u2212 + u 2 i+ \u2212 2ui\u2212 + 2ui+ \u2212 2ui\u2212ui+\n}\n= 1\n2 +\n1\nn+\n\u2211\ni+\u2208I+ ui+ \u2212\n1\nn\u2212\n\u2211\ni\u2212\u2208I\u2212 ui\u2212 +\n1\n2n\u2212\n\u2211\ni\u2212\u2208I\u2212 u2i\u2212 +\n1\n2n+\n\u2211\ni+\u2208I+ u2i+ \u2212\n1\nn+n\u2212\n\u2211\ni+\u2208I+\n\u2211\ni\u2212\u2208I\u2212 ui\u2212ui+\n= 1\n2 +\n1\nn+ e\u22a4+u\u2212\n1\nn\u2212 e\u22a4\u2212u+\n1 2 u\u22a4Diag( 1 n+ e+ + 1 n\u2212 e\u2212)u\u2212\n1\n2n+n\u2212 u\u22a4(e+e \u22a4 \u2212 + e\u2212e \u22a4 +)u\n= 1 2 \u2212 a\u22a4u+ 1 2 u\u22a4Au,\nwith e+ \u2208 Rn the indicator vector of I+ and e\u2212 \u2208 Rn the indicator vector of I\u2212. We have A = Diag( 1n+ e+ + 1 n\u2212 e\u2212) \u2212 1n+n\u2212 [ e+e \u22a4 \u2212 + e\u2212e \u22a4 + ]\nand a = e+/n+ \u2212 e\u2212/n\u2212. A short calculation shows that the largest eigenvalue of A is 1M = 1 n+ + 1n\u2212 . We consider the function h(u) = 12u \u22a4Au. It is (1/M)-smooth, its Fenchel conjugate is equal to\n1 2 v\u22a4A\u22121v,\nand our function g will be equal to v 7\u2192 12v\u22a4A\u22121v \u2212 M2 \u2016v\u20162. Given that 1 is a singular vector of A, g(v) is finite only when v\u22a41n = 0.\nWe need to be able to compute g(v), i.e., solve the system A\u22121v, and to compute the the proximal operator\nmin v\n1 2 \u2016v \u2212 v0\u20162 + \u03c3g(v) = min v 1 2 \u2016v \u2212 v0\u20162 + \u03c3 2 v\u22a4(A\u22121 \u2212MI)v,\nwhich leads to to the system: (A\u22121 \u2212 MI + \u03c3\u22121I)v = \u03c3\u22121v0, which is equivalent to: (I \u2212 MA + \u03c3\u22121A)v = \u03c3\u22121Av0 We thus need to compute efficiently Aw, and (I + \u03baA)\u22121w with \u03ba > \u2212M . We have I + \u03baA = Diag((1 + \u03ba/n+)e+ + (1 + \u03ba/n\u2212)e\u2212)\u2212 \u03ba\nn+n\u2212\n[ e+e \u22a4 \u2212 + e\u2212e \u22a4 + ]\n= Diag((1 + \u03ba/n+)e+ + (1 + \u03ba/n\u2212)e\u2212) 1/2\n[ I \u2212 \u03ba n+n\u2212 ([ 1 \u221a 1 + \u03ba/n+ e+ ][ 1 \u221a 1 + \u03ba/n\u2212 e\u2212 ]\u22a4 \u2212 [ 1 \u221a 1 + \u03ba/n\u2212 e\u2212 ][ 1 \u221a 1 + \u03ba/n+ e+ ]\u22a4)] Diag((1 + \u03ba/n+)e+ + (1 + \u03ba/n\u2212)e\u2212) 1/2\n= D1/2(I \u2212 \u03b1u+u\u22a4\u2212 \u2212 \u03b1u\u2212u\u22a4+)D1/2, with u\u22a4+u\u2212 = 0 and u+ = e+\u221a n+ , u\u2212 = e\u2212\u221a n\u2212 of norm 1 and D = Diag((1 + \u03ba/n+)e+ + (1 + \u03ba/n\u2212)e\u2212). We have:\nI \u2212 \u03b1u+u\u22a4\u2212 \u2212 \u03b1u\u2212u\u22a4+ = I \u2212 u+u\u22a4+ \u2212 u\u2212u\u22a4\u2212 + (u+, u\u2212) ( 1 \u2212\u03b1 \u2212\u03b1 1 ) (u+, u\u2212) \u22a4\n(I \u2212 \u03b1u+u\u22a4\u2212 \u2212 \u03b1u\u2212u\u22a4+)\u22121 = I \u2212 u+u\u22a4+ \u2212 u\u2212u\u22a4\u2212 + 1 1\u2212 \u03b12 (u+, u\u2212) ( 1 \u03b1 \u03b1 1 ) (u+, u\u2212) \u22a4\n= I + (1/(1\u2212 \u03b12)\u2212 1)u+u\u22a4+ + (1/(1\u2212 \u03b12)\u2212 1)u\u2212u\u22a4\u2212 + \u03b1 1\u2212 \u03b12 (u+u \u22a4 \u2212 + u\u2212u \u22a4 +) = I + (1/(1\u2212 \u03b12)\u2212 1) 1 n+ e+e \u22a4 + + (1/(1\u2212 \u03b12)\u2212 1) 1 n\u2212 e\u2212e \u22a4 \u2212\n+ \u03b1 1\u2212 \u03b12 1 \u221a n+n\u2212 (e+e \u22a4 \u2212 + e\u2212e \u22a4 +).\nWe have here \u03b1 = \u03ban+n\u2212\n\u221a\nn+ 1+\u03ba/n+\n\u221a\nn\u2212 1+\u03ba/n\u2212 . Thus\n(I + \u03baA)\u22121 = D\u22121/2 [ I \u2212 u+u\u22a4+ \u2212 u\u2212u\u22a4\u2212 + 1 1\u2212 \u03b12 (u+, u\u2212) ( 1 \u03b1 \u03b1 1 ) (u+, u\u2212) \u22a4]D\u22121/2,\nwhich can be done in O(n).\nMoreover, we have\nA = Diag((1/n+)e+ + (1/n\u2212)e\u2212) 1/2\n[ I \u2212 1 n+n\u2212 ([\u221a n+e+ ][\u221a n\u2212e\u2212 ]\u22a4 \u2212 [\u221a n\u2212e\u2212 ][\u221a n+e+ ]\u22a4)] Diag((1/n+)e+ + (1/n\u2212)e\u2212) 1/2\n= D1/2(I \u2212 u+u\u22a4\u2212 \u2212 u\u2212u\u22a4+)D1/2\nwith u\u22a4+u\u2212 = 0 and u+, u\u2212 of norm 1. Thus we have\nI \u2212 u+u\u22a4\u2212 \u2212 u\u2212u\u22a4+ = I \u2212 u+u\u22a4+ \u2212 u\u2212u\u22a4\u2212 + (u+, u\u2212) ( 1 \u22121 \u22121 1 ) (u+, u\u2212) \u22a4\n(I \u2212 u+u\u22a4\u2212 \u2212 u\u2212u\u22a4+)\u22121 = I \u2212 u+u\u22a4+ \u2212 u\u2212u\u22a4\u2212 + 1\n0 (u+, u\u2212) (1 1 1 1 ) (u+, u\u2212) \u22a4.\nThus, if v\u22a41n = 0, we get:\nv\u22a4A\u22121v = v\u22a4 Diag(n+e+ + n\u2212e\u2212)v \u2212 (v\u22a4e+)2 \u2212 (v\u22a4e\u2212)2,\nwhich has running-time complexity O(n).\nOptimization problem. With a regularizer f(x) + \u03bb2 \u2016x\u20162, we obtain the problem:\nmin x\u2208Rd\n\u03bb 2 \u2016x\u20162 + f(x) + 1 2 \u2212 a\u22a4Kx+ 1 2 (Kx)\u22a4A(Kx)\nmin x\u2208Rd max y\u2208Rn\n\u03bb 2 \u2016x\u20162 + f(x) + 1 2 \u2212 a\u22a4Kx+ y\u22a4Kx\u2212 M 2 \u2016y\u20162 \u2212 1 2 y\u22a4(A\u22121 \u2212MI)y,\nwith g(y) = 12y \u22a4(A\u22121 \u2212MI)y."}, {"heading": "F Additional Experimental Results", "text": "We complement the results of the main paper in several ways: (a) by providing all test losses, the distance to optimum \u2126(x\u2212 x\u2217, y\u2212 y\u2217) in log-scale, as well as the primal-dual gaps in log-scale, as a function of the number of passes on the data. We consider the three machine learning settings:\n\u2013 Figure 1: sido dataset, AUC loss and cluster norm (plus squared-norm) regularizer (both non separable).\n\u2013 Figure 2: sido dataset, square loss and \u21131-norm (plus squared-norm) regularizer (both separable).\n\u2013 Figure 3: rcv1 dataset, square loss and \u21131-norm (plus squared-norm) regularizer (both separable).\nWe consider the following methods in all cases (all methods are run with the step-sizes proposed in their respective convergence analysis):\n\u2013 fb-acc: accelerated forward-backward saddle-point method from Section 2.2,\n\u2013 fb-sto: stochastic forward-backward saddle-point method from Section 2.3,\n\u2013 saga: our new algorithm from Section 4, with non-uniform sampling, and sampling of a single row and column per iteration,\n\u2013 saga (unif): our new algorithm from Section 4, with uniform sampling, and sampling of a single row and column per iteration,\n\u2013 svrg: our new algorithm from Section 3, with non-uniform sampling, and sampling of a single row and column per iteration,\n\u2013 svrg-acc: our new accelerated algorithm from Section 3, with non-uniform sampling, and sampling of a single row and column per iteration,\n\u2013 fba-primal: accelerated proximal method [11], which can be applied to the primal version of our problem (which is the sum of a smooth term and a strongly convex term).\nMoreover, for the separable cases, we add:\n\u2013 saga-primal: SAGA with non-uniform sampling [28], which can only be run with separable losses.\nWe can make the following observations:\n\u2013 Non-uniform sampling is key to good performance.\n\u2013 The distance to optimum (left plots) exhibits a clear linear convergence behavior (which is predicted by our analysis), which is not the case for the primal-dual gap, which does converge, but more erratically. It would be interesting to provide bounds for these as well.\n\u2013 When \u03bb decreases (bottom plots, more ill-conditioned problems), the gains of accelerated methods with respect to non-accelerated ones are unsurprisingly larger. Note that for two out of three settings, the final test loss is smaller for the smaller regularization, and non-accelerated methods need more passes on the data to reach good testing losses.\n\u2013 Primal methods which are not using separability (here \u201cfba-primal\u201d) can be run on all instances, but are not competitive. Note that in some situations, they achieve early on good performances (e.g., Figure 2), before getting caught up by stochastic-variance-reduced saddle-point techniques (note also that since these are not primal-dual methods, we compute dual candidates through the gradient of the smooth loss functions, which is potentially disadvantageous).\n\u2013 Primal methods that use separability (here \u201csaga-primal\u201d) cannot be run on non-separable problems, but when they can run, they are still significantly faster than our saddle-point techniques. We believe that this is partly due to adaptivity to strong convexity (the convergence bounds for the two sets of techniques are the same for this problem)."}], "references": [], "referenceMentions": [], "year": 2017, "abstractText": "<lb>We consider convex-concave saddle-point problems where the objective functions may be split<lb>in many components, and extend recent stochastic variance reduction methods (such as SVRG<lb>or SAGA) to provide the first large-scale linearly convergent algorithms for this class of problems<lb>which is common in machine learning. While the algorithmic extension is straightforward, it<lb>comes with challenges and opportunities: (a) the convex minimization analysis does not apply<lb>and we use the notion of monotone operators to prove convergence, showing in particular that<lb>the same algorithm applies to a larger class of problems, such as variational inequalities, (b)<lb>there are two notions of splits, in terms of functions, or in terms of partial derivatives, (c) the<lb>split does need to be done with convex-concave terms, (d) non-uniform sampling is key to an<lb>efficient algorithm, both in theory and practice, and (e) these incremental algorithms can be<lb>easily accelerated using a simple extension of the \u201ccatalyst\u201d framework, leading to an algorithm<lb>which is always superior to accelerated batch algorithms.", "creator": "LaTeX with hyperref package"}}}