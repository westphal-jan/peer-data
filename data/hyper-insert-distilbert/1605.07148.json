{"id": "1605.07148", "review": {"conference": "NIPS", "VERSION": "v1", "DATE_OF_SUBMISSION": "23-May-2016", "title": "Backprop KF: Learning Discriminative Deterministic State Estimators", "abstract": "generative state estimators based strictly on utilizing probabilistic graphical filters and smoothers are termed one of the most popular emerging classes of state estimators suitable for robots and autonomous vehicles. however, computational generative models have therefore limited capacity to directly handle potentially rich verbal sensory context observations, such as camera scale images, since therefore they must model solely the entire distribution figure over sensor number readings. discriminative models do undoubtedly not traditionally suffer from this limitation, but are typically built more complex to train as latent directed variable input models tailored for state estimation. we present an attractive alternative nonlinear approach involving where the parameters needs of preparing the latent state distribution sample are then directly optimized as a complete deterministic computation graph, resulting basically in a simple precision and effective gradient descent regression algorithm for static training discriminative visual state estimators. we often show that this complex procedure simply can be ultimately used repeatedly to briefly train state estimators before that generally use complex input, such as producing raw camera model images, output which must be typically processed visually using expressive output nonlinear function approximators. such classified as hierarchical convolutional neural networks. technically our model can be directly viewed as a type of highly recurrent neural path network, and the simplified connection mechanisms to probabilistic neural filtering processing allows us easy to design utilizing a network architecture that is considered particularly comfortably well suited for automatic state estimation. we evaluate our approach consistently on tracking same task with raw statistical image parameters inputs. the results consistently show shown significant improvement over both standard online generative parameter approaches and regular looking recurrent neural mesh networks.", "histories": [["v1", "Mon, 23 May 2016 19:28:21 GMT  (137kb,D)", "http://arxiv.org/abs/1605.07148v1", null], ["v2", "Sun, 17 Jul 2016 01:43:34 GMT  (135kb,D)", "http://arxiv.org/abs/1605.07148v2", null], ["v3", "Sun, 30 Oct 2016 05:15:47 GMT  (2110kb,D)", "http://arxiv.org/abs/1605.07148v3", "Accepted to NIPS 2016"], ["v4", "Sun, 1 Oct 2017 00:57:20 GMT  (2239kb,D)", "http://arxiv.org/abs/1605.07148v4", "NIPS 2016"]], "reviews": [], "SUBJECTS": "cs.LG cs.AI", "authors": ["tuomas haarnoja", "anurag ajay", "sergey levine", "pieter abbeel"], "accepted": true, "id": "1605.07148"}, "pdf": {"name": "1605.07148.pdf", "metadata": {"source": "CRF", "title": "Backprop KF: Learning Discriminative Deterministic State Estimators", "authors": ["Tuomas Haarnoja"], "emails": ["haarnoja@berkeley.edu", "anuragajay@berkeley.edu", "svlevine@cs.washington.edu", "pabbeel@cs.berkeley.edu"], "sections": [{"heading": null, "text": "Generative state estimators based on probabilistic filters and smoothers are one of the most popular classes of state estimators for robots and autonomous vehicles. However, generative models have limited capacity to handle rich sensory observations, such as camera images, since they must model the entire distribution over sensor readings. Discriminative models do not suffer from this limitation, but are typically more complex to train as latent variable models for state estimation. We present an alternative approach where the parameters of the latent state distribution are directly optimized as a deterministic computation graph, resulting in a simple and effective gradient descent algorithm for training discriminative state estimators. We show that this procedure can be used to train state estimators that use complex input, such as raw camera images, which must be processed using expressive nonlinear function approximators such as convolutional neural networks. Our model can be viewed as a type of recurrent neural network, and the connection to probabilistic filtering allows us to design a network architecture that is particularly well suited for state estimation. We evaluate our approach on tracking task with raw image inputs. The results show significant improvement over both standard generative approaches and regular recurrent neural networks."}, {"heading": "1 Introduction", "text": "State estimation is an important component of mobile robotic applications, including autonomous driving and flight [17]. Generative state estimators based on probabilistic filters and smoothers are one of the most popular classes of state estimators. However, generative models are limited in their ability to handle rich observations, such as camera images, since they must model the full distribution over sensor readings. This makes it difficult to directly incorporate images, depth maps, and other high-dimensional observations. Instead, the most popular methods for vision-based state estimation (such as SLAM [17]) are based on domain knowledge and geometric principles. Discriminative models do not need to model the distribution over sensor readings, but are more complex to train for state estimation. Discriminative models such as CRFs [12] typically do not use latent variables, which means that training data must contain full state observations. Most real-world state estimation problem settings only provide partial labels. For example, we might observe noisy position readings from a GPS sensor and need to infer the corresponding velocities. While discriminative models can be augmented with latent state [14], this typically makes them harder to train.\nar X\niv :1\n60 5.\n07 14\n8v 1\n[ cs\n.L G\n] 2\nWe propose an efficient and scalable method for discriminative training of state estimators. Instead of performing inference in a probabilistic latent variable model, we instead construct a deterministic computation graph with equivalent representational power. This computation graph can then be optimized end-to-end with simple backpropagation and gradient descent methods. This corresponds to a type of recurrent neural network model, where the architecture of the network is informed by the structure of the probabilistic state estimator. Aside from the simplicity of the training procedure, one of the key advantages of this approach is the ability to incorporate arbitrary nonlinear components into the observation and transition functions. For example, we can condition the transitions on raw camera images processed by multiple convolutional layers, which have been shown to be remarkably effective for interpreting camera images. The entire network, including the observation and transition functions, is trained end-to-end to optimize its performance on the state estimation task.\nThe main contribution of this work is to draw a connection between discriminative probabilistic state estimators and recurrent computation graphs, and thereby derive a new discriminative, deterministic state estimation method. From the point of view of probabilistic models, we propose a method for training expressive discriminative state estimators by reframing them as representationally equivalent deterministic models. From the point of view of recurrent neural networks, we propose an approach for designing neural network architectures that are well suited for state estimation, informed by successful probabilistic state estimation models. We evaluate our approach on a visual tracking problem that requires processing raw images and handling severe occlusion. The results show significant improvement over both standard generative methods and standard recurrent neural networks.\n2 Related Work\nSome of the most successful methods for state estimation have been probabilistic generative state space models (SSMs) based on filtering and smoothing (Figure 1). Kalman filters are perhaps the best known state estimators, and can be extended to the case of nonlinear dynamics through linearization and the unscented transform. Nonparametric filtering methods, such as particle filtering, are also often used for tasks with multimodal posteriors. For a more complete review of state estimation, we refer the reader to standard references on this topic [17].\nGenerative models aim to estimate the distribution over state observation sequences o1:T as originating from some underlying hidden state x1:T , which is typically taken to be the state space of the system. This becomes impractical when the observation space is extremely high dimensional, and when the observation is a complex, highly nonlinear function of the state, as in the case of vision-based state estimation, where ot corresponds to an image viewed from a robot\u2019s onboard camera. The challenges of generative state space estimation can be mitigated by using complex observation models [11], but building effective generative models of images remains a challenging open problem.\nAs an alternative to generative models, discriminative models such as conditional random fields (CRFs) can directly estimate p(xt|o1:t) [12]. A number of CRFs and conditional state space models (CSSMs) have been applied to state estimation [16, 15, 10, 13, 7], typically using a log-linear representation. More recently, discriminative finetuning of generative models with nonlinear neural network observations [5], as well as direct training of CRFs with neural network factors [6], have allowed for training of nonlinear discriminative models. However, such models have not been extensively applied to state estimation. Training CRFs and CSSMs typically requires access to true state labels, while generative models only require observations, which often makes them more convenient for physical systems where the true underlying state is unknown. Although CRFs have also been combined with latent states [14], the difficulty of CRF inference makes latent state CRF models difficult to train. Prior work has also proposed to optimize SSM parameters with respect to a discriminative loss [1]. In contrast to this work, our approach incorporates rich sensory observations, including images, and allows for training of highly expressive discriminative models.\nOur method optimizes the state estimator as a deterministic computation graph, analogous to recurrent neural network (RNN) training. The use of recurrent neural networks (RNNs) for state estimation has been explored in several prior works [18, 3], but has generally been limited to simple tasks without complex sensory inputs such as images. Part of the reason for this is the difficulty of training general-purpose RNNs. Recently, innovative RNN architectures have been successful at mitigating this problem, through models such as the long short-term memory (LSTM) [8] and the gated recurrent unit (GRU) [4]. LSTMs have been combined with vision for perception tasks such as activity recognition [2]. However, in the domain of state estimation, such black-box models ignore the considerable domain knowledge that is available. By drawing a connection between filtering and recurrent networks, we can design recurrent computation graphs that are particularly well suited to state estimation and, as shown in our evaluation, and can achieve improved performance over standard LSTM models."}, {"heading": "3 Preliminaries", "text": "If we would like to perform state estimation using high-dimensional observations ot, such as camera images, using a generative model directly is very difficult, because the observations are produced by a complex and highly nonlinear process. However, in practice the underlying state of the system xt might depend mainly on some low-dimensional vector that can be extracted from ot, which we denote pt. For example, ot might correspond to pairs of images from a camera on an automobile, pt to its velocity, and yt to the location of the vehicle. In that case, we can first train a discriminative model g\u03b8(ot) to predict pt from ot in feedforward manner, and then filter the predictions to output the desired state labels y1:t. For example, a Kalman filter with hidden state xt could be trained to use both yt and the predicted pt as observations, and then perform inference over yt at test time. This standard approach for state estimation with high-dimensional observations is illustrated in Figure 2a.\nWhile this method may be viewed as an engineering solution without a probabilistic interpretation, it has the advantage that g\u03b8(ot) is trained discriminatively, and the entire model is conditioned on ot, with xt acting as an internal latent variable. This is why the model does not need to represent the distribution over observations explicitly. However, the function g\u03b8(ot) that maps the raw observations ot to low-dimensional predictions pt is not trained for optimal state estimation. Instead, it is trained to predict an intermediate variable pt that can be readily integrated into the generative filter."}, {"heading": "4 Discriminative Deterministic State Estimation", "text": "Our contribution is based on a generalized view of state estimation that subsumes the piecewisetrained models discussed in the previous section and allows them to be trained end-to-end using simple and scalable stochastic gradient descent methods. In the na\u00efve approach, the observation function g\u03b8(ot) is trained to directly predict pt, since a standard generative filter model does not provide for a straightforward way to optimize g\u03b8(ot) with respect to the accuracy of the filter on the labels y1:T . However, the filter can be viewed as a computation graph unrolled through time, as shown in Figure 2b. In this graph, the filter has an internal state defined by the posterior over xt. For example, in a Kalman filter with Gaussian posteriors, we can represent the internal state with the tuple st = {\u00b5xt ,\u03a3xt}. In general, we will use st to refer to the state of any filter. We also augment this graph with an output function q(st) = \u03c6yt that outputs the parameters of a distribution over labels yt. In the case of a Kalman filter, we would simply have q(st) = {Cy\u00b5xt ,Cy\u03a3xtC>y }, where Cy defines a linear observation function form xt to yt .\nViewing the filter as a computation graph in this way, g\u03b8(ot) can be trained discriminatively on the entire sequence, rather than individually on single time steps. Let L(\u03c6yt) be a loss function on the output distribution of the computation graph, which might, for example, be given by L(\u03c6yt) = log p\u03c6yt (yt), where p\u03c6yt is the distribution induced by the parameters \u03c6yt , and yt is the label. Let L(\u03b8) = \u2211 t L(\u03c6yt) be the loss on the entire dataset with respect to \u03b8. Furthermore, let \u03ba(st,pt+1) denote the operation performed by the filter to compute st+1 based on st and pt+1. We can compute the gradient of L(\u03b8) with respect to the parameters \u03b8 by first recursively computing the gradient of the loss with respect to the filter state st from the back to the front according to the following recursion:\ndL dst\u22121 = dst dst\u22121 [ d\u03c6yt dst dL d\u03c6yt + dL dst ] ,\nand then applying the chain rule to obtain\n\u2207\u03b8L(\u03b8) = T\u2211 t=1 dpt d\u03b8 dst dpt dL dst .\nAll of the derivatives in these equations can be obtained from g\u03b8(ot), \u03ba(st\u22121,pt), q(st), and L(\u03c6yt):\ndst dst\u22121 = \u2207st\u22121\u03ba(st\u22121,pt) dst dpt = \u2207pt\u03ba(st\u22121,pt)\ndL d\u03c6yt = \u2207\u03c6ytL(\u03c6yt) d\u03c6yt dst = \u2207stq(st) dpt d\u03b8 = \u2207\u03b8g\u03b8(ot).\nThe parameters \u03b8 can be optimized with gradient descent using these gradients. This is an instance of backpropagation through time (BPTT), a well known algorithm for training recurrent neural networks.\nRecognizing this connection between state-space models and recurrent neural networks allows us to extend this generic filtering architecture and explore the continuum of models between filters with a discriminatively trained observation model g\u03b8(ot) all the way to fully general recurrent neural networks. In our experimental evaluation, we use a standard Kalman filter update as \u03ba(st,pt+1), but we use a nonlinear convolutional neural network observation function g\u03b8(ot). We found that this provides a good tradeoff between incorporating domain knowledge and end-to-end learning for the task of visual tracking, but other variants of this model could be explored in future work, including variants with nonlinear dynamics and large internal hidden state."}, {"heading": "5 Experimental Evaluation", "text": "In this section, we compare our deterministic discriminatively trained state estimator with a number of alternative methods, including simple feedforward convolutional networks, standard Kalman filter variants, and fully general LSTM models. We evaluate these models on a task that requires tracking a red disk in the presence of clutter and severe occlusion. This task requires the state estimator to process raw image input, handle extended occlusion periods, and localize the object in the presence of a large number distractors."}, {"heading": "5.1 State Estimation Models", "text": "Our proposed model, which we call the \u201cbackprop Kalman filter\u201d (BKF), is a computation graph made up of a Kalman filter (KF) and a feedforward convolutional neural network that distills the observation ot into a low-dimensional signal pt, which serves as the observation for the KF. The neural network outputs both a mean value for pt and an observation covariance matrix Rt. Since the network is trained together with the filter, it can learn to use the covariance matrix to communicate the desired degree of uncertainty about the observation, so as to maximize the accuracy of the final filter prediction.\nWe compare the backprop KF to three alternative state estimators: the \u201cfeedforward model\u201d, the \u201cpiecewise KF\u201d, and the \u201cLSTM model\u201d. The simplest of the models, the feedforward model, does not consider the temporal structure in the task at all, and consists only of a feedforward convolutional network that takes in the observations ot and outputs a point estimate y\u0302t of the label yt. The piecewise KF model corresponds to the simple generative approach described in Section 3, which combines the feedforward network with an extended Kalman filter that filters the network predictions pt to produce a distribution over the state x\u0302t. The piecewise model corresponds to the same computation graph as the BKF, but does not optimize the filter and network together end-to-end, instead training the two pieces separately.\nFinally, we compare to a recurrent neural network based on LSTM hidden units [8]. This model resembles the backprop KF, except that the filter portion of the graph is replaced with a generic LSTM layer. The LSTM model learns the dynamics from data, without incorporating the domain knowledge present in the KF. To make full use of the generality of the LSTM, we remove the last layer of the convolutional network and feed its final layer of activations directly into the LSTM, which we found to produce better results in practice."}, {"heading": "5.2 Backprop KF Computation Graph Architecture", "text": "The architecture of the computation graph corresponding to the BKF model is shown in Figure 3. It consists of a feedforward neural network and a recurrent part based on Kalman filter. The neural network, illustrated in Figure 4, has two convolutional layers, and two hidden fully connected layers. A special aspect of our network design is a novel response normalization layer that is applied to the convolutional activations before applying the nonlinearity. The response normalization transforms the activations such that the activations of layer i have always mean \u00b5i and variance \u03c32i regardless of the input image. The parameters \u00b5i and \u03c32i are learned along with other parameters. This normalization is used in all of the convolutional networks in our evaluation, and resembles batch\nnormalization [9] in its behavior. However, we found this approach to be substantially more effective for recurrent models that require backpropagation through time, compared to the more standard batch normalization approach, which is know to require additional care when applied to recurrent networks. The normalization is followed by a rectified linear unit (ReLU) and a max pooling layer. The network outputs a point estimate of the intermediate observation pt, and a lower-diagonal matrix Lt, which is used to estimate the covariance Rt of pt. We enforce the positive definiteness of Rt through Cholesky decomposition by exponentiating the diagonal elements of Lt and setting Rt = LtL>t .\nThe Kalman filter in the computation graph is based on the following dynamical system:\nxt+1 = Axt + Bwwt pt = Cpxt + vt yt = Cyxt.\nThe state of the system, xt, keeps track of the position and velocity of the target disk. The dynamics noise, wt, and observation noise, vt, are assumed to be zero mean Gaussian random variables with covariances Q and Rt = LtL>t , respectively. Note that the labels yt represents noiseless observations and are not incorporated in the Kalman filter updates, but instead they enter the model through the cost function at training time:\nL(\u03b8) = T\u2211 t=1 1 2T (\u00b5t \u2212 yt)>(\u00b5t \u2212 yt)."}, {"heading": "5.3 Visual State Estimation Task Setup", "text": "Our state estimation task is meant to reflect typical challenges in visual state estimation: the need for long-term tracking to handle occlusions, the presence of noise, and the need to process raw pixel data. The task requires tracking a red disk from image observations, as shown in Figure 5. Distractor disks with random colors and radii are added into the scene to occlude the red disk, and the trajectories of all disks follow linear-Gaussian dynamics, with a linear spring force that pulls the disks toward the center of the frame and a drag force that prevents high velocities. The disks can temporally leave the frame since contacts are not modeled. Gaussian noise is added to perturb the motion. The difficulty of the task can be adjusted by increasing or decreasing the number of distractor disks, which affects the frequency of occlusions. The easiest variants of the task are easily solvable with the feedforward estimator, while the hardest variants require long-term tracking through occlusion."}, {"heading": "5.3.1 Comparing the State Estimation Models", "text": "The results in Table 1 show that the BKF outperforms both the standard probabilistic KF-based estimators and the more powerful and expressive LSTM estimators. The tracking error of the simple\nTable 1: Benchmark Results\nState Estimation Model # Parameters RMS test error\nfeedforward model 7394 0.2322 \u00b1 0.1316 piecewise KF 7397 0.1160 \u00b1 0.0330 LSTM model (64 units) 33506 0.1407 \u00b1 0.1154 LSTM model (128 units) 92450 0.1423 \u00b1 0.1352 BKF model (ours) 7493 0.0537 \u00b1 0.1235\nfeedforward model is significantly larger due to the occlusions, and the model tends to predict the mean coordinates when the target is occluded. The piecewise model performs better, but because the observation covariance is not conditioned on ot, the KF learns to use a very large observation covariance, which forces it to rely almost entirely on the dynamics model for predictions. On the other hand, since the BKF model learns to output the observation covariances conditioned on ot that optimize the performance of the filter, it is able to find a compromise between the observations and the dynamics model. Finally, although the LSTM model is the most general, it performs worse than the BKF, since it does not incorporate prior knowledge about the structure of the state estimation problem. Figure 6a shows how varying the number of hidden LSTM units affects the performance: best compromise between underfitting and overitting is achieved with around 100 hidden LSTM units.\nTo test the robustness of the estimator to occlusions, we trained each model on a training set that contained sequences with varying amounts of clutter and occlusions. We then evaluated the models on several test sets, each corresponding to a different level of occlusion and clutter. The tracking error as the test set difficulty is varied is shown Figure 6b. Note that even in the absence of distractors, BKF and LSTM models outperform the feedforward model, since the target occasionally leaves the field of view. The performance of the piecewise KF does not change significantly as the difficulty increases: due to the high amount of clutter during training, the piecewise KF learns to use a large observation covariance and rely primarily on feedforward estimates for prediction. The BKF achieves the lowest error in nearly all cases. At the same time, the BKF model also has dramatically fewer parameters than the LSTM models, since the transitions correspond to simple Kalman filter updates."}, {"heading": "6 Discussion", "text": "In this paper, we proposed a discriminative approach to state estimation that consists of reformulating probabilistic generative state estimation as a deterministic computation graph. This makes it possible to train our method end-to-end using simple backpropagation through time (BPTT) methods, analogously to a recurrent neural network. In our evaluation, we present an instance of this approach that we refer to as the backprop KF (BKF) model, which corresponds to a Kalman filter combined with a feedforward convolutional neural network that processes raw image observations. Our approach to state estimation has two key benefits. First, we avoid the need to construct generative state space models over complex, high-dimensional observation spaces such as raw images. Second, by reformulating the probabilistic state-estimator as a deterministic computation graph, we can apply simple and effective backpropagation and stochastic gradient descent optimization methods to learn the model parameters. This avoids the usual challenges associated with inference in continuous, nonlinear conditional probabilistic models, while still preserving the same representational power as the corresponding approximate probabilistic inference method, which in our experiments corresponds to approximate Gaussian posteriors in an extended Kalman filter.\nOur approach also can be viewed as an application of ideas from probabilistic state-space models to the design of recurrent neural networks. Since we optimize the state estimator as a deterministic computation graph, it corresponds to a particular type of deterministic neural network model. However, the architecture of this neural network is informed by principled and well-motivated probabilistic filtering models, which provides us with a natural avenue for incorporating domain knowledge into the system.\nOur experimental results indicate that end-to-end training of a discriminative state estimators can improve their performance substantially when compared to a standard piecewise approach, where a discriminative model is trained to process the raw observations and produce intermediate lowdimensional observations that can then be integrated into a standard generative filter. The results also indicate that, although the accuracy of the BKF can be matched by a recurrent LSTM network with a large number of hidden units, BKF outperforms the general-purpose LSTM when the dataset is limited in size. This is due to the fact that BKF incorporates domain knowledge about the structure of probabilistic filters into the network architecture, providing it with a better inductive bias when the training data is limited, which is the case in many real-world robotic applications.\nIn our experiments, we primarily focused on models based on the Kalman filter. However, our approach to state estimation can equally well be applied to other probabilistic filters for which the update equations (approximate or exact) can be written in closed form, including the information filter, the unscented Kalman filter, and the particle filter, as well as deterministic filters such as state observers or moving average processes. As long as the filter can be expressed as a differentiable mapping from the observation and previous state to the new state, we can construct and differentiate the corresponding computation graph. An interesting direction for future work is to extend discriminative state-estimators with complex nonlinear dynamics and larger latent state. For example, one could explore the continuum of models that span the space between simple KF-style state estimators and fully general recurrent networks. The tradeoff between these two extremes is between generality and domain knowledge, and striking the right balance for a given problem could produce substantially improved results even with relative modest amounts of training data."}], "references": [{"title": "Discriminative training of kalman filters", "author": ["P. Abbeel", "A. Coates", "M. Montemerlo", "A.Y. Ng", "S. Thrun"], "venue": "Robotics: Science and Systems (R:SS)", "citeRegEx": "1", "shortCiteRegEx": null, "year": 2005}, {"title": "Sequential deep learning for human action recognition", "author": ["M. Baccouche", "F. Mamalet", "C. Wolf", "C. Garcia", "A. Baskurt"], "venue": "Second International Conference on Human Behavior Unterstanding, pages 29\u201339, Berlin, Heidelberg", "citeRegEx": "2", "shortCiteRegEx": null, "year": 2011}, {"title": "A neural network implementing optimal state estimation based on dynamic spike train decoding", "author": ["O. Bobrowski", "R. Meir", "S. Shoham", "Y.C. Eldar"], "venue": "Advances in Neural Information Processing Systems (NIPS)", "citeRegEx": "3", "shortCiteRegEx": null, "year": 2007}, {"title": "B", "author": ["K. Cho"], "venue": "van Merrienboer, C. Gulcehre, F. Bougares, H. Schwenk, and Y. Bengio. Learning phrase representations using RNN encoder-decoder for statistical machine translation. arXiv preprint arXiv:1406.1078", "citeRegEx": "4", "shortCiteRegEx": null, "year": 2014}, {"title": "Context-dependent pre-trained deep neural networks for large-vocabulary speech recognition", "author": ["G.E. Dahl", "D. Yu", "L. Deng", "A. Acero"], "venue": "Audio, Speech, and Language Processing, IEEE Transactions on, 20(1):30\u201342", "citeRegEx": "5", "shortCiteRegEx": null, "year": 2012}, {"title": "et al", "author": ["T. Do", "T. Arti"], "venue": "Neural conditional random fields. In International Conference on Artificial Intelligence and Statistics, pages 177\u2013184", "citeRegEx": "6", "shortCiteRegEx": null, "year": 2010}, {"title": "Discriminatively trained particle filters for complex multi-object tracking", "author": ["R. Hess", "A. Fern"], "venue": "Computer Vision and Pattern Recognition, 2009. CVPR 2009. IEEE Conference on, pages 240\u2013247. IEEE", "citeRegEx": "7", "shortCiteRegEx": null, "year": 2009}, {"title": "Long short-term memory", "author": ["S. Hochreiter", "J. Schmidhuber"], "venue": "Neural computation, 9(8): 1735\u20131780", "citeRegEx": "8", "shortCiteRegEx": null, "year": 1997}, {"title": "Batch normalization: Accelerating deep network training by reducing internal covariate shift", "author": ["S. Ioffe", "C. Szegedy"], "venue": "International Conference on Machine Learning (ICML)", "citeRegEx": "9", "shortCiteRegEx": null, "year": 2015}, {"title": "Conditional state space models for discriminative motion estimation", "author": ["M. Kim", "V. Pavlovic"], "venue": "Computer Vision, 2007. ICCV 2007. IEEE 11th International Conference on, pages 1\u20138. IEEE", "citeRegEx": "10", "shortCiteRegEx": null, "year": 2007}, {"title": "GP-BayesFilters: Bayesian filtering using Gaussian process prediction and observation models", "author": ["J. Ko", "D. Fox"], "venue": "Autonomous Robots, 27(1):75\u201390", "citeRegEx": "11", "shortCiteRegEx": null, "year": 2009}, {"title": "Conditional random fields: Probabilistic models for segmenting and labeling sequence data", "author": ["J. Lafferty", "A. McCallum", "F.C. Pereira"], "venue": null, "citeRegEx": "12", "shortCiteRegEx": "12", "year": 2001}, {"title": "CRF-filters: Discriminative particle filters for sequential state estimation", "author": ["B. Limketkai", "D. Fox", "L. Liao"], "venue": "International Conference on Robotics and Automation (ICRA)", "citeRegEx": "13", "shortCiteRegEx": null, "year": 2007}, {"title": "Latent-dynamic discriminative models for continuous gesture recognition", "author": ["L.-P. Morency", "A. Quattoni", "T. Darrell"], "venue": "Computer Vision and Pattern Recognition, 2007. CVPR\u201907. IEEE Conference on, pages 1\u20138. IEEE", "citeRegEx": "14", "shortCiteRegEx": null, "year": 2007}, {"title": "Combining discriminative features to infer complex trajectories", "author": ["D.A. Ross", "S. Osindero", "R.S. Zemel"], "venue": "Proceedings of the 23rd international conference on Machine learning, pages 761\u2013768. ACM", "citeRegEx": "15", "shortCiteRegEx": null, "year": 2006}, {"title": "Discriminative density propagation for 3d human motion estimation", "author": ["C. Sminchisescu", "A. Kanaujia", "Z. Li", "D. Metaxas"], "venue": "Computer Vision and Pattern Recognition, 2005. CVPR 2005. IEEE Computer Society Conference on, volume 1, pages 390\u2013397. IEEE", "citeRegEx": "16", "shortCiteRegEx": null, "year": 2005}, {"title": "Probabilistic Robotics", "author": ["S. Thrun", "W. Burgard", "D. Fox"], "venue": "The MIT Press", "citeRegEx": "17", "shortCiteRegEx": null, "year": 2005}, {"title": "Neural network based state estimation of dynamical systems", "author": ["N. Yadaiah", "G. Sowmya"], "venue": "International Joint Conference on Neural Networks (IJCNN)", "citeRegEx": "18", "shortCiteRegEx": null, "year": 2006}], "referenceMentions": [{"referenceID": 16, "context": "State estimation is an important component of mobile robotic applications, including autonomous driving and flight [17].", "startOffset": 115, "endOffset": 119}, {"referenceID": 16, "context": "Instead, the most popular methods for vision-based state estimation (such as SLAM [17]) are based on domain knowledge and geometric principles.", "startOffset": 82, "endOffset": 86}, {"referenceID": 11, "context": "Discriminative models such as CRFs [12] typically do not use latent variables, which means that training data must contain full state observations.", "startOffset": 35, "endOffset": 39}, {"referenceID": 13, "context": "While discriminative models can be augmented with latent state [14], this typically makes them harder to train.", "startOffset": 63, "endOffset": 67}, {"referenceID": 16, "context": "For a more complete review of state estimation, we refer the reader to standard references on this topic [17].", "startOffset": 105, "endOffset": 109}, {"referenceID": 10, "context": "The challenges of generative state space estimation can be mitigated by using complex observation models [11], but building effective generative models of images remains a challenging open problem.", "startOffset": 105, "endOffset": 109}, {"referenceID": 11, "context": "As an alternative to generative models, discriminative models such as conditional random fields (CRFs) can directly estimate p(xt|o1:t) [12].", "startOffset": 136, "endOffset": 140}, {"referenceID": 15, "context": "A number of CRFs and conditional state space models (CSSMs) have been applied to state estimation [16, 15, 10, 13, 7], typically using a log-linear representation.", "startOffset": 98, "endOffset": 117}, {"referenceID": 14, "context": "A number of CRFs and conditional state space models (CSSMs) have been applied to state estimation [16, 15, 10, 13, 7], typically using a log-linear representation.", "startOffset": 98, "endOffset": 117}, {"referenceID": 9, "context": "A number of CRFs and conditional state space models (CSSMs) have been applied to state estimation [16, 15, 10, 13, 7], typically using a log-linear representation.", "startOffset": 98, "endOffset": 117}, {"referenceID": 12, "context": "A number of CRFs and conditional state space models (CSSMs) have been applied to state estimation [16, 15, 10, 13, 7], typically using a log-linear representation.", "startOffset": 98, "endOffset": 117}, {"referenceID": 6, "context": "A number of CRFs and conditional state space models (CSSMs) have been applied to state estimation [16, 15, 10, 13, 7], typically using a log-linear representation.", "startOffset": 98, "endOffset": 117}, {"referenceID": 4, "context": "More recently, discriminative finetuning of generative models with nonlinear neural network observations [5], as well as direct training of CRFs with neural network factors [6], have allowed for training of nonlinear discriminative models.", "startOffset": 105, "endOffset": 108}, {"referenceID": 5, "context": "More recently, discriminative finetuning of generative models with nonlinear neural network observations [5], as well as direct training of CRFs with neural network factors [6], have allowed for training of nonlinear discriminative models.", "startOffset": 173, "endOffset": 176}, {"referenceID": 13, "context": "Although CRFs have also been combined with latent states [14], the difficulty of CRF inference makes latent state CRF models difficult to train.", "startOffset": 57, "endOffset": 61}, {"referenceID": 0, "context": "Prior work has also proposed to optimize SSM parameters with respect to a discriminative loss [1].", "startOffset": 94, "endOffset": 97}, {"referenceID": 17, "context": "The use of recurrent neural networks (RNNs) for state estimation has been explored in several prior works [18, 3], but has generally been limited to simple tasks without complex sensory inputs such as images.", "startOffset": 106, "endOffset": 113}, {"referenceID": 2, "context": "The use of recurrent neural networks (RNNs) for state estimation has been explored in several prior works [18, 3], but has generally been limited to simple tasks without complex sensory inputs such as images.", "startOffset": 106, "endOffset": 113}, {"referenceID": 7, "context": "Recently, innovative RNN architectures have been successful at mitigating this problem, through models such as the long short-term memory (LSTM) [8] and the gated recurrent unit (GRU) [4].", "startOffset": 145, "endOffset": 148}, {"referenceID": 3, "context": "Recently, innovative RNN architectures have been successful at mitigating this problem, through models such as the long short-term memory (LSTM) [8] and the gated recurrent unit (GRU) [4].", "startOffset": 184, "endOffset": 187}, {"referenceID": 1, "context": "LSTMs have been combined with vision for perception tasks such as activity recognition [2].", "startOffset": 87, "endOffset": 90}, {"referenceID": 7, "context": "Finally, we compare to a recurrent neural network based on LSTM hidden units [8].", "startOffset": 77, "endOffset": 80}, {"referenceID": 8, "context": "normalization [9] in its behavior.", "startOffset": 14, "endOffset": 17}], "year": 2017, "abstractText": "Generative state estimators based on probabilistic filters and smoothers are one of the most popular classes of state estimators for robots and autonomous vehicles. However, generative models have limited capacity to handle rich sensory observations, such as camera images, since they must model the entire distribution over sensor readings. Discriminative models do not suffer from this limitation, but are typically more complex to train as latent variable models for state estimation. We present an alternative approach where the parameters of the latent state distribution are directly optimized as a deterministic computation graph, resulting in a simple and effective gradient descent algorithm for training discriminative state estimators. We show that this procedure can be used to train state estimators that use complex input, such as raw camera images, which must be processed using expressive nonlinear function approximators such as convolutional neural networks. Our model can be viewed as a type of recurrent neural network, and the connection to probabilistic filtering allows us to design a network architecture that is particularly well suited for state estimation. We evaluate our approach on tracking task with raw image inputs. The results show significant improvement over both standard generative approaches and regular recurrent neural networks.", "creator": "LaTeX with hyperref package"}}}