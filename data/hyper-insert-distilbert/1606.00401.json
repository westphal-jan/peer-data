{"id": "1606.00401", "review": {"conference": "arxiv", "VERSION": "v1", "DATE_OF_SUBMISSION": "1-Jun-2016", "title": "How to advance general game playing artificial intelligence by player modelling", "abstract": "besides general game role playing artificial young intelligence has recently seen infinitely important physical advances constantly due to firstly the formidable various techniques known as'deep development learning '. here however arguably the vast advances conceal equally important limitations persist in their large reliance on : massive adaptive data sets ; fortuitously constructed problems ; and absence nor of utilizing any human - level complexity, especially including other human simulation opponents. besides on the mysterious other planet hand, | deep learning systems | which do beat human world champions, such algorithms as in yahoo go, don't generalise well. nevertheless the dynamic power deficit of deep learning actually simultaneously exposes its overwhelming weakness. given that deep learning is still mostly clever technological reconfigurations of well - established linear methods, possibly moving beyond the previous state of live art, calls for forward - thinking visionary optimization solutions, not just more of the same. i thus present indirectly the argument that general game playing artificial user intelligence will desperately require a specific generalised player model. secondly this objection is largely because your games \u00bb are sometimes inherently rational human artefacts scenarios which therefore, as a balanced class of problems, contain possible cases complexity which require a broader human - style problem solving approach. i furthermore relate this argument naturally to seeing the performance modes of state \u2013 of art and general game game playing synthetic agents. i then describe a concept for adopting a formal category theoretic basis sufficient to describe a sufficiently generalised player model. this formal model approach naturally integrates my existing'behavlets'method for psychologically - derived player complex modelling :", "histories": [["v1", "Wed, 1 Jun 2016 19:07:48 GMT  (20kb)", "https://arxiv.org/abs/1606.00401v1", "Submitted to 2016 IEEE Symposium on Computational Intelligence and Games. 7 pages"], ["v2", "Fri, 3 Jun 2016 13:15:53 GMT  (20kb)", "http://arxiv.org/abs/1606.00401v2", "Submitted to 2016 IEEE Symposium on Computational Intelligence and Games. 7 pages"], ["v3", "Tue, 21 Jun 2016 12:18:24 GMT  (20kb)", "http://arxiv.org/abs/1606.00401v3", "7 pages"]], "COMMENTS": "Submitted to 2016 IEEE Symposium on Computational Intelligence and Games. 7 pages", "reviews": [], "SUBJECTS": "cs.HC cs.AI", "authors": ["benjamin ultan cowley"], "accepted": false, "id": "1606.00401"}, "pdf": {"name": "1606.00401.pdf", "metadata": {"source": "CRF", "title": "How to advance general game playing artificial intelligence by player modelling", "authors": ["Benjamin Ultan Cowley"], "emails": ["ben.cowley@helsinki.fi"], "sections": [{"heading": null, "text": "ar X\niv :1\n60 6.\n00 40\n1v 3\n[ cs\n.H C\n] 2\n1 Ju\nCowley, B., & Charles, D. (2016). Behavlets: a Method for Practical Player Modelling using Psychology-Based Player Traits and Domain Specific Features. User Modeling and User-Adapted Interaction, 26(2), 257\u2013306.\nI. INTRODUCTION\nAtari (\u5f53\u305f\u308a, \u3042\u305f\u308a, or \u30a2\u30bf\u30ea) nominalized form of ataru (\u5f53\u305f\u308b, \u3042\u305f\u308b, or \u30a2\u30bf\u30eb) (verb), meaning:\n\u201dto hit the target\u201d\nWith great fanfare and much publicity, recent studies have claimed solutions to two important landmarks of game-playing artificial intelligence (AI) - competitive world-class Go [1] and (constrained) generalised game playing [2] 1. Each of these problems is an exemplar \u2019difficult problem\u2019 in AI, and each solution uses variations on the \u2019deep neural network\u2019 learning method. However despite this leap of progress, there remains the need to move beyond the constraints exploited by these deep learning methods.\nBeyond the recent advances in game playing AI lie two still more daunting challenges: to build AI that can react to\n1Although see [3] for criticism of the claimed originality.\nhuman players as individuals; and to play games of imperfect information and strategic scope [4]. I argue that both of these problems are related, and therefore share a common solution. The link, or intersection in problem space, is that games are essentially human-relevant artefacts. Encoding human-style playing strategies will enable not only better responses to human players, but better responses to problems of recreational interest to humans. Therefore both problems can be addressed with an improved understanding of human play, by building a generalised player model. A general player model should be thought of primarily as a system for expressing the supraspecific elements that apply to all players, especially cognition, emotion and personality. The specific implementation then depends on the game.\nAs well as advancing the state of art, [1], [2] demonstrate, directly and indirectly, that human-level performance (in specific problems) is different to human-level capability. The senior author of both papers (they each come from Google\u2019s DeepMind lab) hinted at this [4]:\nI think for perfect information games, Go is the pinnacle... There are other games \u2014 no-limit poker is very difficult, multiplayer has its challenges because it\u2019s an imperfect information game. And then there are obviously all sorts of video games that humans play way better than computers, like StarCraft... Strategy games require a high level of strategic capability in an imperfect information world \u2014 \u201dpartially observed,\u201d it\u2019s called.\nThe specifics of the two systems nicely illustrate the problem. In both cases, their solution is largely a method to deal with very large possibility spaces, which were tackled by constraint of the search space and learning from large amounts of data, but in different ways.\n[1]\u2019s \u2019alphaGo\u2019 system represented the Go board with a 19 \u00d7 19 matrix, and used Monte Carlo tree search (MCTS) enhanced by deep convolutional neural networks, to reduce the search space and determine play strategy. The algorithm first used supervised learning from existing games; then performed unsupervised reinforcement learning (RL) by playing against\nitself. I term this the \u2019strategic approach\u2019, learning by deeply examining playing strategies (in the MCTS rollouts). It does not generalise well because large quantities of human-played games need to be used in the supervised part of training.\n[2]\u2019s \u2019Atari\u2019 system presented a deep RL algorithm with a 84 \u00d7 84 \u00d7 4 map of pixels of the game screen from 49 Atari games. The algorithm then played a very large number of games to learn a policy. The performance was expressed proportional to a human expert, achieving >90% in 26 games. At the other end of the scale, authors state that \u201dtemporally extended planning strategies still constitute a major challenge\u201d. Indeed, examining the lowest scoring games (<10%) shows that they all share the features of an extensive game world, and the need to manage resources or tokens across this world. Thus the \u2019general approach\u2019 does not handle strategy well. Especially in the two lowest scoring games, Montezuma\u2019s Revenge and Private Eye, the relationship between current task and overall possibility space is quite non-linear, as players must track back and forth through the game world to search, transport and use tokens such as keys. Compared to this, the strategy the authors actually describe their algorithm as having found in Breakout, a totally deterministic and perfect information game, is trivial.\nThe poor performance (compared to a human) in this type of open problem is mirrored of the work of [5]. Given feedback, humans were shown to achieve close-to-optimal solutions on certain classes of computationally hard problems, e.g. Travelling Salesman, by heuristically exploiting structure in the \u2019typical instances\u2019.\n[6] has also pointed out how the DeepMind Atari player exploits constraints in its problem domain:\nin the Atari game system, data is very cheap. You can play the game over and over again...get gigabytes of data very quickly, with no real cost.\nin the Atari system, ...you have [only] eighteen choices at any given moment.\nHe contrasts this with learning problems of unconstrained choices and sparse data, e.g., when trying to learn from a human or a real-world scenario. Computer games may never be as noisy and unconstrained as real-world scenarios, modern games with multiplayer interaction are frequently very complex. Although [2] used games for humans, they were nevertheless from an era of much greater technological constraint, such that their dimensional reduction to tractability was straightforward - modern games will not allow that.\nThus the field of computational intelligence in games faces a research question which I state as RQ1: how can general game playing AI cope with human-level games and human players?\nBoth [1], [2] imposed well-chosen constraints on the problem domain to enable their solutions. Constraints can be dimensionality reduction, and can also be simulation of the original system, according to some simplifying theory.\nAs stated above, I propose that a generalised player model gives a partial solution. There are two parts to the solution:\na) to capture information about player psychology (cognition, emotion and personality) and activity; b) to represent that information in the context of the game. Part a) constrains the model of player behaviour to well-understood theoretical constructs; part b) presents the model as input to a learning algorithm."}, {"heading": "A. Behavlets", "text": "A general model should provide insight into different facets of player behaviour, for example the cognitive information processing \u2019style\u2019 of a player. It thus requires a foundation of parameters that describe the subjective experience of play. The foundation will draw on established modelling tools, including at least: i) psychology of behaviour; ii) general game design; and iii) actions in the context of a given game.\nI previously proposed the Behavlets method [7] to build facets i) to iii) above into composite features of game-play defined over entire action sequences. The aim is to create player-modelling features linked to valid psychological theory. The Behavlet process integrates descriptive models for temperament theory, game design patterns, and patterns of player actions. The core concept is to capture behaviours with certain known bias of personality; e.g. aggression, caution; and thus observe the players\u2019 self-expression. Behavlets have been used to model players for, e.g. personality type classification [8] and move prediction [9]. Thus I use the Behavlets method to fulfil part a) above."}, {"heading": "B. Formalism", "text": "How best to represent Behavlets (or any other psychological model) \u2019in the game\u2019, i.e. in a manner both machine- and human-comprehensible? In principle, this should be done by simulation. As stated in the inspirational work of [10], simulation \u201dmodels\u2019 main purposes are to leave out certain aspect of complex systems to facilitate study of those systems.\u201d\nNote that games can be neatly modelled as a mathematical system because they rely on rule-based interactions defined on a possibility space, and the mechanics of play are essentially functions over that space.\nRestricting the games under consideration to those with strictly bounded rules, observe that a state at time t is determined by the game state at time t\u22121. Thus the game can usually be represented by a finite-state Markov process 2. A state-based model is often used for game representation, and Markov methods are often used for computational intelligence in games.\nHowever, observe that play involves spaces and control systems; these can be either discrete, or approximately continuous with minimum lower bound, sometimes defined by the frame rate of e.g. 60fps or 16.67ms per frame.\nFor purpose of player modelling, the difference between approximate and truly continuous is not as important as the\n2With a non-rational learning human player at the core of gameplay (who may display high choice variance, i.e. infer different predicates based on the same observations), game processes are usually strictly non-Markovian; however they can still be given Markovian representations as a simplifying assumption.\nplayer\u2019s understanding of the nature of the play space. To create a general player model we must capture the player\u2019s understanding, and deal with \u2019approximately continuous\u2019 data.\nIf the model must capture every frame of the game, it is hardly an efficient simulation. Far more parsimonious to use a modelling framework that can handle continuous entities.\nFor example, consider Go played with clocks. Players make a single discrete move while their clock elapses continuous time. The elapsed time value can be captured with a simple integer, but the elapsed psychological experience cannot.\nFortunately, the required tools are already in [11]\u2019s category theory framework to model interactive control systems. The framework in [11] models both discrete and continuous control systems, in hybrid form and as abstraction simulations. I will draw on the definition of hybrid control systems (HCS), following [10] and building on [11].\n[10] is an excellent complement for the reader; it works lucidly through the foundational technical aspects of applying this formalism to games. It also concludes at about the point where I aim to depart: the composition of micro-games (e.g. Behavlets) to form complete games (e.g. player models). The approach is more applied than [10], but as in that paper I still aim to produce a simulation model with reduced complexity compared to the original game.\n[10] described the how of game specification using HCS methods, but he himself questioned why one would wish to do it. I am interested in providing this motivating vision."}, {"heading": "C. Summary", "text": "In this paper I aim to provide a notation to represent Behavlets as action sequences in a formally defined simulation of a game system, by extending [11]. The motivation is to generate a representation of possible player actions, and the archetypal behaviour traits that can shape those actions, such that the representation can be used as input for a learning system. Ultimately, the goal is to learn from real human behaviour.\nIn the rest of the paper, I first give a brief literature review in the next section. In section III I describe a formal model of a game system, before showing briefly in section V how it can be used to represent some Behavlets taken from [7]. Finally, in section VI, I suggest some future directions of work."}, {"heading": "II. BACKGROUND", "text": "A general player model has the difficult task to account for the variation between players, variability in their behaviour over time, and the reciprocal relationship of players to the game. For example, such a model should account not only for player learning, but also player emotions\u2019 impact on play. There are many relevant fields of study in that problem, and I have previously reviewed literature contributing to generalised player modelling [12]. Here I briefly review literature on formal models.\nVarious descriptive models of game play have tried to include aspects of player psychology, such as emotions. For example, I proposed the User-System-Experience (USE) model\n[13], [14], to describe the intrinsic motivation of games in terms of the cognitive neuroscience of information processing and learning. However the specification of games themselves was lacking in detail. Ja\u0308rvinen [15, pp.99-247] built a player experience model on top of a game decomposition theory. The model has two concepts: game experiences are composed of sequences of emotions; and game elements embody conditions that elicit emotions. [16] define a formalisation of \u2018synthetic\u2019 emotions using Decision Theory, to be used for player modelling or for communication of AI agent states to the player. Methods which codify game mechanics allow a model to capture player-game interactions. [17] attempts this, using the object oriented programming paradigm to define game mechanics as \u201dmethods invoked by agents\u201d. [18] developed a formal modelling toolset to analyse player behaviour by action sequence mining. The method finds all action sequences and their frequency in a game log, representing common sequences as features, which are selected by ranking according to their mutual information with the class variable.\nFormal specification of the play space can support the integration of game and psychological models. [19] defined game theory, which gives useful tools to analyse player behaviour: assuming that players are rational agents with definable utilities for action. Such assumptions do not serve our purpose to learn from real human behaviour. More generally, formal methods such as category theory [20], enable specification and verification of the objects and actions of the play space, and thus support rigorous testing of system coherence. Category theory was applied to game specification in [10], which leveraged [11]\u2019s system of notation for abstractions. In [10]\u2019s abstract specification, a game \u201dconsists of objects which change their state during the play, where the evolution of their state is governed by rules and influenced by the players or other objects\u201d. [10] defined a game as a triple(S,M, F ), where S is a set of game states; M is a monoid describing the inputs to the system; and F is an action of the monoid on the set, i.e. the rules. [10] also showed how the operation of composition defined in [11] could be used to create novel games; this was a useful abstract discussion.\nThis approach is flexible, but the complexity of the domain poses a large problem for this method. [10] agrees: \u201ddescribing a game with this formalism seems to be a cumbersome task\u201d. The task is cumbersome because the approach relies too much on one system; any such system will be either unwieldy or insufficiently descriptive. In a multi-step modelling approach, methods for action-tracking [18], design pattern analysis [21], and player psychology profiling [7] can first describe the game; i.e. part a) above. These descriptions can then be associated with a coding formalism for rigour, i.e. part b) above."}, {"heading": "III. FORMAL MODEL", "text": "Here, I extend the full HCS defined by [11]. A game is modelled as a HCS; some rectifying operations are also defined, to force the HCS to behave as games do."}, {"heading": "A. Model Foundation", "text": "Definition: A game G = (X ,M,\u03a6), consisting of:\n\u2022 the state space X = {Xq}q\u2208Q \u2022 a monoid M = \u2210 n\u2208N(U \u2217 \u222a \u03a3\u2217)n \u2022 a partial action \u03a6 of M on X , such that there exist invariants Inv(q) \u2286 Xq\nNote: Here, X is a set of smooth manifolds parametrised by discrete states q \u2208 Q; this allows modelling of any simulated spaces with entities, such as a game\u2019s 3D environment with typical player-controlled unit(s) and opponent(s).\nNote: Monoid M is defined as the product union of the sets U\u2217, the set of smooth manifold inputs, and \u03a3\u2217, the set of discrete inputs 3; which allows modelling of combined analogue and digital inputs, such as a joystick and buttons. Individual inputs are denoted by m, a map in N+0 , defined as a composition of finite ut1...i with finite \u03c31...j . In this system, ut \u2032\nindexes time, with \u2019embedded\u2019 discrete inputs from \u03a3\u2217, if modelling game time is required.\nNote: The partial action \u03a6 implies a ruleset that can be defined over a subset of the state space; this allows modelling of rules such as power-ups, which alter some core function in a restricted area of state-space, i.e. after a power-up item has been consumed, and perhaps within limited time/space.\nThis general-form model may be revised to obtain the core framework for specific games. For example perfectinformation purely-discrete games, such as chess and Go, can be obtained when Xq is a singleton and U = \u2205.\nExample: Let us model the game of Noughts & Crosses (TicTacToe in American) as a demonstration.\n\u2022 Xxo = (pos\u03c8){\u03c8\u22081...9}, the set of 3\u00d7 3 board positions, uniquely ordered by the magic square n = 3 4. \u2022 Mxo = \u03c3x\u2208\u03c8 \u222a \u03c3o\u2208\u03c8, the act of placing an x or an o. \u2022 \u03a6xo = \u03c6 : {1, 2, 3}, a map to three \u2019rules\u2019,\n1) \u03c3x \u00d7 \u03c3o \u2212\u2192 4P\u03c8, paired player turns involve sampling without replacement from the magic square n = 3, up to four times, 2) x \u2229 o = \u2205, choices are disjoint, 3) win \u21d0\u21d2 \u2211 \u03a3\u2217 = 15, winning condition such\nthat player wins if and only if 3 choices sum to 15.\nAlthough Noughts & Crosses is a trivial child\u2019s game, it is a simple matter to adapt this specification to model Gomoku, which is also an m,n, k-game. From there, it is straightforward to model Go, at least for (X ,M). To define \u03a6 for the core Go rules, which we will not state here for the sake of brevity, would require significant effort but tractable complexity because the rules are all simply derived from the board and input definitions X ,M.\n3Although continuous systems are constrained to have finite duration of input times, they may have infinite number of inputs defined as vector field maps from an input manifold. This permits a model consistent with the player\u2019s point of view, which is an important part of creating psychologically relevant models.\n4This is a rare occasion when a magic square becomes a magic circle (in the sense of Huizinga, not Yang Hui)!\nIn order to more flexibly create games, it helps to exploit modularity; for this we can use the operation composition of monoids. Composition implies that, given two monoids M1 and M2, we can form the composition M\u2032 = M1 \u2297 M2, which is also a monoid. M\u2032 has all possible evolutions of the composed monoids and no interaction between their parts.\nFor such a model (X ,M,\u03a6)as described, a common shorthand notation is \u03a6X , denoting \u03a6X : X \u00d7Mx \u2192 X . With this notation, and composition, we can thus describe a basic game, \u03a60, and compatible game-parts \u03a6Xa and \u03a6X b, and obtain a complete game by composition, \u03a6X b\u00d7\u03a6Xa\u00d7\u03a6X0 \u2192 \u03a6Xab. The goal is that such game-parts are used to represent Behavlets, as described below, section IV.\nHowever as [10] pointed out, with such a framework it is not yet possible to build any reasonably interesting game, in the sense of a system which produces meaningful decisions and outcomes [22]. This is because the composition operator does not impose any interaction on the composed parts, leaving the resultant system causally heterogeneous and un-gamelike. Composition should additionally impose constraints on the composed monoids, such that the inputs of each are influenced by the other. Additionally, tracking activity patterns allows us to see more clearly how the defined influences work in practice. Therefore, two more concepts will complete our core toolset: composition with restriction, and orbits.\nDefinition: Composition with restriction, denoted \u2297, from [11], imposes a restriction of \u03a6X to a subset of X \u2297M\u2032x, such that the composed monoids are forced to synchronise by the restriction.\nDefinition: An orbit is a set Ox containing all points visited on an evolution starting at x and controlled by some input m \u2208 M. Formally, Ox = {x\u2032 \u2208 X : x\u2032 = \u03a6X (x,m\u2032) for some prefix m\u2032 of m}. [20] defines an orbit as the behaviour of an imperative program f , i.e. the effect of a series of inputs a on an initial state x, such that fai(xi\u22121) = xi.\nFor our purposes, an orbit of monoid \u03a6X will represent instances whenever the game-play activity pattern defined by \u03a6X is played. For example, in Noughts & Crosses there are well-known tactics, which when played according to the correct selection criteria will generate a perfect game. These include Play Center, Block, Fork and others defined in [23]. They can be modelled with a triplet defining: the player\u2019s move, the state of the board, plus a test to determine the type of tactic played.\nIn the game of Go there are also various well-known patterns of play, such as atari, gote vs. sente, joseki, ko fighting. These concepts may be captured by orbits, at least where the analysis of the pattern characteristics is algorithmic and tractable (in Go, an element of expert judgement is often involved in assessing such patterns).\nTo make a well-formed map from games to models, an orbit for modelling behaviour is under two constraints. It cannot be a cycle, as cycles are not game-like: consider the ko rule in Go. It cannot consist only of a stable state, as this cannot evolve (by definition [20]), and is therefore uninteresting from a player modelling point of view."}, {"heading": "B. Complete Model", "text": "Based on this framework I propose a modelling scheme for game behaviour, which is descriptive rather than generative; i.e. the aim is to simulate the game components that relate to player actions, rather than deriving a simulation of game play from a model of the engine mechanics.\nDefinition: A game G\u2032 is a composition of HCSs \u03a6X i, 1 < i \u2264 k, where each \u03a6X i is used to model a distinct game play pattern, and the composition (by the properties of composition of monoids) is also a HCS.\nThe \u2019base\u2019 monoid \u03a6X0 represents the core game framework, with no orbit restrictions. A single game play pattern is represented by a monoid, \u03a6X i : (Xi,Mi,\u03a6i), instantiated by an orbit OX i, with a starting condition (q, x0)i, an initial condition from Xqi which corresponds to the opening state of the game pattern. Such monoids are constrained from having initial or terminal objects (as defined by [20]), because they would then be allowed to define only a single function, violating the principle that games should be uncertain.\nModelling of the complete game is achieved by composition with restriction, where three restriction operators are defined.\n1) Xqi \u2286 Xqi\u22121, i.e. state space is reduced every time by composition. This models the progression of games, i.e. the fact that a game can generally be modelled as a tree traversal, such that every move will reduce the remaining possible moves. 2) mi\u2297mi\u22121 iff mi\u22121 is a prefix of mi, such that e.g. in a time-indexed system mt1 \u2265 m\u2212 1t1 , i.e. the start time of the orbit for the next monoid to be composed must be greater than or equal to the prior monoid, such that game progression is modelled. 3) Oxi 6= Oxi\u22121 where (q, x0)i \u2229 (q, x0)i\u22121 6= \u2205 without any other restriction on x \u2208 OX i. I.e. monoids composed such that their orbits have overlapping time sequences, shall not be isomorphic.\nThus, based on this approach, a game G\u2032 is a basis monoid \u03a6X0 : (X0,M0,\u03a60), which provides the complete state space and time registration, without inputs. The basis monoid is composed with 1..k \u2212 1 additional game pattern monoids, to describe those activities in the game that reduce the possibility space until game end. Each pattern monoid \u03a6i is restricted to join the base monoid in a time-ordered fashion, without overlap of isomorphs, and without expanding the game tree with nodes excluded by previously composed monoids \u03a61..i\u22121."}, {"heading": "IV. BEHAVLETS-BASED FORMAL MODEL", "text": "As mentioned, the intention is to formalise the Behavlets\u2019 method of player modelling. As indicated in the formal model definition, this can be done by using orbits to represent the play patterns which arise in the game. Here I elaborate this idea.\nA Behavlet is essentially a game play pattern associated with a temperament trait. Thus, a well-chosen monoid representation of a pattern, \u03a6X i, can also represent a Behavlet, and thereby be associated with a temperament trait. To select the\nright monoid for the Behavlet is quite straightforward. The instantiation orbit OX i is equivalent to the Behavlet logic, defined in [7]. Further, the orbit starting condition (q, x0)i is equivalent to the Behavlet concept of a constraint harness, defined in [7].\nAn example will illustrate the approach, for which I will take already peer-reviewed [7] and empirically tested [9] Behavlets, derived for the game Pac-Man (Namco, 1980). The formal framework for the Behavlets model of a given game \u0393 is obtained and used with the following five step process:\n1) define basis monoid for \u0393 2) define compositional \u0393 play pattern monoids, each with\nassociated temperament trait 3) define model instance as label for play personality in \u0393 4) model reduction by the operation of simulation, giving\nrepresentations of behaviour patterns in \u0393-like games which can be compared 5) obtain generalised player model by iterating this process\nI will apply this process to the Pac-Man Behavlets using the Pac-Man specification from my previous work (see e.g. appendix D to [8]). This specification was totally state-based, abstracting the smooth movement aspect of original Pac-Man. Thus, as with chess or Go, this Pac-Man does not need U\u2217, and X is singleton. For brevity, I will make a number of further simplifications which do not relate to the example Behavlet. I model only a single level, to avoid extra complications surrounding tests that would be needed to model end-of-level or loss of lives (for a description of test function construction, see e.g. [20, pp.46]). I do not provide extra state variables to model the bonus Fruit item, a cherry; or record the points scored, or Pac-Man\u2019s lives (these values are referenced but left undefined). I also refrain from modelling any driver of Ghost behaviour, which in the prior specification is simply a probabilistic map to adjacent positions, weighted toward PacMan in normal play and away from Pac-Man when a power pill is in effect. All these features can be trivially added to the model.\nFirst, the basis monoid for a Pac-Man game P . Definition: \u03a6P = (XP0,MP0,\u03a6P0),\n\u2022 XP0 = {mat, xyp}, where mat = (hposx) \u222a (vposy), {x, y \u2208 N, 1 . . . 20} the Pac-Man \u2019map\u2019 matrix with values drawn from {\u2205, wall, pill, powerpill}; and xyp is a set of current position values for Pac-Man and the Ghosts {xyp | p \u2208 PM,G1..4}, \u2022 MP0 = m : {\u2190, \u2191, \u2193,\u2192}\u00d7XxyPM d=1 \u2212\u2212\u2192 X , a map from\nthe four directions of movement to the matrix position adjacent to Pac-Man\u2019s current position,\n\u2022 \u03a6P0 = \u03c6 : {1, 2, 3}, a map to three \u2019rules\u2019,\n1) m \u00d7 pill \u2212\u2192 {+5points,XxyPM = \u2205}, Pac-Man passes through a matrix position with a pill: increase points by +5, position becomes empty, 2) m \u00d7 powerpill \u2212\u2192 {+10points,XxyPM = \u2205, \u03c6 = \u03c6\u2032 : {1, 2, 3\u2032}, t : (1..n)}, similar effects as pill; also transition to the map \u03c6\u2032, where vulnerability of\nPac-Man to the Ghosts is inverted for a limited time n, 3) m\u00d7xyG1..4 \u2212\u2192 \u22121life, Pac-Man and a Ghost enter the same matrix position: Pac-Man loses a life, 3\u2032 m\u00d7xyG1..4 \u2212\u2192 {+50points\u00d7i, i \u2208 (1..4), xyGi = xy0Gi}, Pac-Man and a Ghost enter the same matrix position: +50 points (multiplied by consecutive Ghost order), Ghost returns to starting position\nSecond, the Behavlets themselves are modelled. To illustrate, I select a Behavlet listed in [7, pp.293], A1 Hunt Close To Ghost House. Behavlet A1 (for short) tracks how often a player follows the Ghosts right up to their house while attacking them in powerpill mode.\nDefinition: \u03a6A1 = (x\u2032,m\u2032, OPA1),\n\u2022 x\u2032 = \u22001..4,dist(xyGi , xy0Gi) \u2264 3, the manhattan distance of each Ghost to its own starting position is three or less, \u2022 m\u2032 \u2286 MP0\u2200t(1..n), the orbit elapses for all inputs until the end of the powerpill timer, \u2022 OPA1 = {x\u2032 \u2208 XP0 : x\u2032 = \u03a6P0(x,m\u2032), an orbit defined on the Pac-Man basis monoid\nThird, the composited game is produced, P = \u03a6A1 \u2297 \u03a6P = \u03a6PA1. Game instances where this Behavlet monoid appears can be labelled as examples of cautious play, with a quantification scheme as described above.\nFourth, model reduction by simulation creates a simpler representation without reference to the specifics of the game. Thus we do not need to define, for example, the dimensions of game space states Xq , only to define the type of spaces as they appear to the player. In this way, we can make an equivalence between models for Pac-Man, Go, even Noughts & Crosses if we wish. Given the game produced by composition with restrictions \u03a6PA1, we define two simulations of the composed parts, \u03b2A1 and \u03b2P . The map \u03d5 which defines each \u03b2 is an abstraction of the part of the model which is not relevant to comparison with another simulated game. \u03b2s are composed by restriction to produce a more general version of the model, \u03b2PA1.\n\u03b2A1 \u2297 \u03b2P \u03b2PA1\n\u03a6A1 \u2297 \u03a6P \u03a6PA1\n\u03d5 \u03d5 (1)\nThe complete approach to simulation is detailed in [11], and is also discussed in [10]. Here it is enough to note that, given proven models of games such as those described above, the reduction can be pursued and the simulations are then \u2019safe\u2019 to study without reference to the messy details.\nFifth and finally, obtaining the generalised player model from the given framework is perhaps possible for a class of\ngames between which simulation is well-defined. Proving this is clearly a matter for future work."}, {"heading": "V. DISCUSSION", "text": "The approach I described for a generalised player model draws on the Behavlet method to create psychologically-based features of game play, and redefines them as parts of a category theoretic formal model. The value of this approach is that, under a formal framework, Behavlet models of particular games can be further generalised by the operation of simulation."}, {"heading": "A. Potential applications", "text": "The primary use case for the described method is to capture player variation. Consider that, if we model Behavlets as game parts \u03a6X , then by the Behavlets method [7], each \u03a6X i will have an associated behaviour trait. Thus, a game instance with a specific \u03a6 composition will reflect the \u2019character\u2019 of a particular player\u2019s play style. Potentially, characteristics of human play can be learned through enough such instances.\nAlso consider that the method allow abstraction and specificity: we can build a canonical game model and also simulate game instances quite easily from the same definitions. This allows exploration of the space of possible games.\nThis might be termed personality profiling, but skill and strategy are also a relevant considerations. Based on the work of [5] where humans achieved near-optimal solutions on hard problems, we can expect to find many problems where human skills can provide the seed for improved computational solutions. For example, [24] used a gamification to learn from humans solutions, creating heuristic optimisation methods for quantum computing problems which outperform traditional multi-parameter numerical methods. The problem remains to characterise player activity in a manner which is flexible to the level and type of detail required, a problem to which I suggest that simulation is well suited. Thus, given a composite model of Behavlet-based game parts, defining play-sequences such as the Noughts & Crosses or Go tactics described, the actually-played components can denote the level of insight of the player into the game problem.\nA further consequence of this flexibility is the capacity to model multiple flavours of game rules. As defined by [22], a game contains three different types of rule, Constituative (written before play), Operative (emergent during play) and Implicit (unspoken \u2019house\u2019 rules between players). Go is an example where all these rule types have been studied, standardised, and written about in great detail, and thus were available to the developers of alphaGo. For less well-studied games, the method I present can characterise them with some flexibility without loss of rigour.\nB. Issues and considerations\nThis is a work at the concept stage, and like any concept there are many details lacking. The state of the method presented is probably sub-optimal, and this may frustrate the more engineering-minded reader; but the aim is initiate a\nconversation. It is to be hoped that the concept will provide fertile soil to grow more detailed methods.\nDespite the seeming complexity, what is required to build such models is quite complementary to the development process - defining the entities and operations of game-play.\nWhen building such models, the user must take note of whether the restrictions and constraints ever contradict his game: this can help highlight flaws in either the game or the model, and facilitate the work of quality assurance."}, {"heading": "VI. CONCLUSION", "text": "I argue that in order to advance general game playing AI, it is necessary to include the player perspective, because games are ultimately human artefacts and therefore contain cases which benefit from a human-style problem solving approach. The argument implies creating a generalised player model. I have set out a method to do so, based on integrating my previously published Behavlets work [7] with a formal model of game play. The result is a vision for a general player model, rather than a complete and final work, which I hope will serve as inspiration."}], "references": [{"title": "Mastering the game of Go with deep neural networks and tree search", "author": ["D. Silver", "A. Huang", "C.J. Maddison", "A. Guez", "L. Sifre", "G. van den Driessche", "J. Schrittwieser", "I. Antonoglou", "V. Panneershelvam", "M. Lanctot", "S. Dieleman", "D. Grewe", "J. Nham", "N. Kalchbrenner", "I. Sutskever", "T. Lillicrap", "M. Leach", "K. Kavukcuoglu", "T. Graepel", "D. Hassabis"], "venue": "Nature, vol. 529, no. 7587, pp. 484\u2013489, jan 2016.", "citeRegEx": "1", "shortCiteRegEx": null, "year": 2016}, {"title": "Human-level control through deep reinforcement learning", "author": ["V. Mnih", "K. Kavukcuoglu", "D. Silver", "A.A. Rusu", "J. Veness", "M.G. Bellemare", "A. Graves", "M. Riedmiller", "A.K. Fidjeland", "G. Ostrovski", "S. Petersen", "C. Beattie", "A. Sadik", "I. Antonoglou", "H. King", "D. Kumaran", "D. Wierstra", "S. Legg", "D. Hassabis"], "venue": "Nature, vol. 518, no. 7540, pp. 529\u2013533, feb 2015.", "citeRegEx": "2", "shortCiteRegEx": null, "year": 2015}, {"title": "DeepMind\u2019s Nature Paper and Earlier Related Work", "author": ["J. Schmidhuber"], "venue": "2015. [Online]. Available: http://people.idsia.ch/{\u223c}juergen/naturedeepmind.html", "citeRegEx": "3", "shortCiteRegEx": null, "year": 2015}, {"title": "DeepMind founder Demis Hassabis on how AI will shape the future", "author": ["D. Hassabis"], "venue": "2016. [Online]. Available: http://www.theverge.com/2016/3/10/11192774/demis-hassabis-interview-alphago-google-deepmind-ai", "citeRegEx": "4", "shortCiteRegEx": null, "year": 2016}, {"title": "People efficiently explore the solution space of the computationally intractable traveling salesman problem to find near-optimal tours", "author": ["D.E. Acu\u00f1a", "V. Parada"], "venue": "PloS one, vol. 5, no. 7, 2010.", "citeRegEx": "5", "shortCiteRegEx": null, "year": 2010}, {"title": "Is Big Data Taking Us Closer to the Deeper Questions in Artificial Intelligence? \u2014 Edge.org", "author": ["G. Marcus"], "venue": "2016. [Online]. Available: https://www.edge.org/conversation/gary{ }marcus-big-data-ai", "citeRegEx": "6", "shortCiteRegEx": null, "year": 2016}, {"title": "Behavlets: a Method for Practical Player Modelling using Psychology-Based Player Traits and Domain Specific Features", "author": ["B. Cowley", "D. Charles"], "venue": "User Modeling and User-Adapted Interaction, vol. 26, no. 2, pp. 257\u2013306, Feb 2016.", "citeRegEx": "7", "shortCiteRegEx": null, "year": 2016}, {"title": "Real-time rule-based classification of player types in computer games", "author": ["B. Cowley", "D. Charles", "M. Black", "R. Hickey"], "venue": "User Modeling and User-Adapted Interaction, vol. 23, no. 5, pp. 489\u2013526, Aug 2013.", "citeRegEx": "8", "shortCiteRegEx": null, "year": 2013}, {"title": "Utility of a Behavlets approach to a Decision theoretic predictive player model", "author": ["B.U. Cowley", "D. Charles"], "venue": "arXiv, vol. 1603.08973, mar 2016.", "citeRegEx": "9", "shortCiteRegEx": null, "year": 2016}, {"title": "Formal Models and Game Design", "author": ["S. Gr\u00fcnvogel"], "venue": "Games Studies, vol. 5, no. 1, p. Online, 2005.", "citeRegEx": "10", "shortCiteRegEx": null, "year": 2005}, {"title": "Compositional Abstractions of Hybrid Control Systems", "author": ["P. Tabuada", "G.J. Pappas", "P. Lima"], "venue": "Discrete Event Dynamic Systems, vol. 14, no. 2, pp. 203\u2013238, apr 2004.", "citeRegEx": "11", "shortCiteRegEx": null, "year": 2004}, {"title": "Short Literature Review for a General Player Model Based on Behavlets", "author": ["B.U. Cowley", "D. Charles"], "venue": "arXiv, vol. 1603.06996, p. 7, mar 2016.", "citeRegEx": "12", "shortCiteRegEx": null, "year": 2016}, {"title": "User-System- Experience Model for User Centered Design in Computer Games", "author": ["B. Cowley", "D. Charles", "M. Black", "R. Hickey"], "venue": "Adaptive Hypermedia and Adaptive Web-Based Systems, vol. 4018. Dublin: LNCS, 2006, pp. 419\u2013424.", "citeRegEx": "13", "shortCiteRegEx": null, "year": 2006}, {"title": "Toward an understanding of flow in video games", "author": ["\u2014\u2014"], "venue": "Comput. Entertain., vol. 6, no. 2, pp. 1\u201327, 2008.", "citeRegEx": "14", "shortCiteRegEx": null, "year": 2008}, {"title": "Games Without Frontiers: Methods for Game Studies and Design", "author": ["A. J\u00e4rvinen"], "venue": "Copenhagen: VDM Verlag,", "citeRegEx": "15", "shortCiteRegEx": "15", "year": 2009}, {"title": "Modeling users\u2019 emotions during interactive entertainment sessions", "author": ["P.J. Gmytrasiewicz", "C.L. Lisetti"], "venue": "Stanford, CA, USA, pp. 30\u201335, 2000.", "citeRegEx": "16", "shortCiteRegEx": null, "year": 2000}, {"title": "Defining Game Mechanics", "author": ["M. Sicart"], "venue": "Games Studies, vol. 8, no. 2, p. Online, 2008.", "citeRegEx": "17", "shortCiteRegEx": null, "year": 2008}, {"title": "Action Sequence Mining", "author": ["S. Breining", "H.-P. Kriegel", "M. Schubert", "A. Zufle"], "venue": "Second International Workshop on Machine Learning and Data Mining in Games, at European Conference on Machine Learning, T. Croonenborghs, K. Driessens, and O. Missura, Eds., Athens, Greece, 2011.", "citeRegEx": "18", "shortCiteRegEx": null, "year": 2011}, {"title": "Theory of games and economic behavior", "author": ["J. Von Neuman", "O. Morgenstern"], "venue": "New York: J. Wiley,", "citeRegEx": "19", "shortCiteRegEx": "19", "year": 1944}, {"title": "Categories and computer science", "author": ["R. Walters"], "venue": null, "citeRegEx": "20", "shortCiteRegEx": "20", "year": 1991}, {"title": "Patterns in game design", "author": ["S. Bj\u00f6rk", "J. Holopainen"], "venue": "Hingham, Massachusetts: Charles River Media,", "citeRegEx": "21", "shortCiteRegEx": "21", "year": 2005}, {"title": "Flexible strategy use in young children\u2019s tic-tac-toe", "author": ["K. Crowley"], "venue": "Cognitive Science, vol. 17, no. 4, pp. 531\u2013561, dec 1993.", "citeRegEx": "23", "shortCiteRegEx": null, "year": 1993}, {"title": "Exploring the quantum speed limit with computer games", "author": ["J.J.W.H. S\u00f8rensen", "M.K. Pedersen", "M. Munch", "P. Haikka", "J.H. Jensen", "T. Planke", "M.G. Andreasen", "M. Gajdacz", "K. M\u00f8lmer", "A. Lieberoth", "J.F. Sherson"], "venue": "Nature, vol. 532, no. 7598, pp. 210\u2013213, Apr 2016.", "citeRegEx": "24", "shortCiteRegEx": null, "year": 2016}], "referenceMentions": [{"referenceID": 0, "context": "With great fanfare and much publicity, recent studies have claimed solutions to two important landmarks of game-playing artificial intelligence (AI) - competitive world-class Go [1] and (constrained) generalised game playing [2] 1.", "startOffset": 178, "endOffset": 181}, {"referenceID": 1, "context": "With great fanfare and much publicity, recent studies have claimed solutions to two important landmarks of game-playing artificial intelligence (AI) - competitive world-class Go [1] and (constrained) generalised game playing [2] 1.", "startOffset": 225, "endOffset": 228}, {"referenceID": 2, "context": "1Although see [3] for criticism of the claimed originality.", "startOffset": 14, "endOffset": 17}, {"referenceID": 3, "context": "human players as individuals; and to play games of imperfect information and strategic scope [4].", "startOffset": 93, "endOffset": 96}, {"referenceID": 0, "context": "As well as advancing the state of art, [1], [2] demonstrate, directly and indirectly, that human-level performance (in specific problems) is different to human-level capability.", "startOffset": 39, "endOffset": 42}, {"referenceID": 1, "context": "As well as advancing the state of art, [1], [2] demonstrate, directly and indirectly, that human-level performance (in specific problems) is different to human-level capability.", "startOffset": 44, "endOffset": 47}, {"referenceID": 3, "context": "The senior author of both papers (they each come from Google\u2019s DeepMind lab) hinted at this [4]:", "startOffset": 92, "endOffset": 95}, {"referenceID": 0, "context": "[1]\u2019s \u2019alphaGo\u2019 system represented the Go board with a 19 \u00d7 19 matrix, and used Monte Carlo tree search (MCTS) enhanced by deep convolutional neural networks, to reduce the search space and determine play strategy.", "startOffset": 0, "endOffset": 3}, {"referenceID": 1, "context": "[2]\u2019s \u2019Atari\u2019 system presented a deep RL algorithm with a 84 \u00d7 84 \u00d7 4 map of pixels of the game screen from 49 Atari games.", "startOffset": 0, "endOffset": 3}, {"referenceID": 4, "context": "The poor performance (compared to a human) in this type of open problem is mirrored of the work of [5].", "startOffset": 99, "endOffset": 102}, {"referenceID": 5, "context": "[6] has also pointed out how the DeepMind Atari player exploits constraints in its problem domain:", "startOffset": 0, "endOffset": 3}, {"referenceID": 1, "context": "Although [2] used games for humans, they were nevertheless from an era of much greater technological constraint, such that their dimensional reduction to tractability was straightforward - modern games will not allow that.", "startOffset": 9, "endOffset": 12}, {"referenceID": 0, "context": "Both [1], [2] imposed well-chosen constraints on the problem domain to enable their solutions.", "startOffset": 5, "endOffset": 8}, {"referenceID": 1, "context": "Both [1], [2] imposed well-chosen constraints on the problem domain to enable their solutions.", "startOffset": 10, "endOffset": 13}, {"referenceID": 6, "context": "I previously proposed the Behavlets method [7] to build facets i) to iii) above into composite features of game-play defined over entire action sequences.", "startOffset": 43, "endOffset": 46}, {"referenceID": 7, "context": "personality type classification [8] and move prediction [9].", "startOffset": 32, "endOffset": 35}, {"referenceID": 8, "context": "personality type classification [8] and move prediction [9].", "startOffset": 56, "endOffset": 59}, {"referenceID": 9, "context": "As stated in the inspirational work of [10], simulation \u201dmodels\u2019 main purposes are to leave out certain aspect of complex systems to facilitate study of those systems.", "startOffset": 39, "endOffset": 43}, {"referenceID": 10, "context": "Fortunately, the required tools are already in [11]\u2019s category theory framework to model interactive control systems.", "startOffset": 47, "endOffset": 51}, {"referenceID": 10, "context": "The framework in [11] models both discrete and continuous control systems, in hybrid form and as abstraction simulations.", "startOffset": 17, "endOffset": 21}, {"referenceID": 9, "context": "I will draw on the definition of hybrid control systems (HCS), following [10] and building on [11].", "startOffset": 73, "endOffset": 77}, {"referenceID": 10, "context": "I will draw on the definition of hybrid control systems (HCS), following [10] and building on [11].", "startOffset": 94, "endOffset": 98}, {"referenceID": 9, "context": "[10] is an excellent complement for the reader; it works lucidly through the foundational technical aspects of applying this formalism to games.", "startOffset": 0, "endOffset": 4}, {"referenceID": 9, "context": "The approach is more applied than [10], but as in that paper I still aim to produce a simulation model with reduced complexity compared to the original game.", "startOffset": 34, "endOffset": 38}, {"referenceID": 9, "context": "[10] described the how of game specification using HCS methods, but he himself questioned why one would wish to do it.", "startOffset": 0, "endOffset": 4}, {"referenceID": 10, "context": "In this paper I aim to provide a notation to represent Behavlets as action sequences in a formally defined simulation of a game system, by extending [11].", "startOffset": 149, "endOffset": 153}, {"referenceID": 6, "context": "In section III I describe a formal model of a game system, before showing briefly in section V how it can be used to represent some Behavlets taken from [7].", "startOffset": 153, "endOffset": 156}, {"referenceID": 11, "context": "There are many relevant fields of study in that problem, and I have previously reviewed literature contributing to generalised player modelling [12].", "startOffset": 144, "endOffset": 148}, {"referenceID": 12, "context": "For example, I proposed the User-System-Experience (USE) model [13], [14], to describe the intrinsic motivation of games in terms of the cognitive neuroscience of information processing and learning.", "startOffset": 63, "endOffset": 67}, {"referenceID": 13, "context": "For example, I proposed the User-System-Experience (USE) model [13], [14], to describe the intrinsic motivation of games in terms of the cognitive neuroscience of information processing and learning.", "startOffset": 69, "endOffset": 73}, {"referenceID": 15, "context": "[16] define a formalisation of \u2018synthetic\u2019 emotions using Decision Theory, to be used for player modelling or for communication of AI agent states to the player.", "startOffset": 0, "endOffset": 4}, {"referenceID": 16, "context": "[17] attempts this, using the object oriented programming paradigm to define game mechanics as \u201dmethods invoked by agents\u201d.", "startOffset": 0, "endOffset": 4}, {"referenceID": 17, "context": "[18] developed a formal modelling toolset to analyse player behaviour by action sequence mining.", "startOffset": 0, "endOffset": 4}, {"referenceID": 18, "context": "[19] defined game theory, which gives useful tools to analyse player behaviour: assuming that players are rational agents with definable utilities for action.", "startOffset": 0, "endOffset": 4}, {"referenceID": 19, "context": "More generally, formal methods such as category theory [20], enable specification and verification of the objects and actions of the play space, and thus support rigorous testing of system coherence.", "startOffset": 55, "endOffset": 59}, {"referenceID": 9, "context": "Category theory was applied to game specification in [10], which leveraged [11]\u2019s system of notation for abstractions.", "startOffset": 53, "endOffset": 57}, {"referenceID": 10, "context": "Category theory was applied to game specification in [10], which leveraged [11]\u2019s system of notation for abstractions.", "startOffset": 75, "endOffset": 79}, {"referenceID": 9, "context": "In [10]\u2019s abstract specification, a game \u201dconsists of objects which change their state during the play, where the evolution of their state is governed by rules and influenced by the players or other objects\u201d.", "startOffset": 3, "endOffset": 7}, {"referenceID": 9, "context": "[10] defined a game as a triple(S,M, F ), where S is a set of game states; M is a monoid describing the inputs to the system; and F is an action of the monoid on the set, i.", "startOffset": 0, "endOffset": 4}, {"referenceID": 9, "context": "[10] also showed how the operation of composition defined in [11] could be used to create novel games; this was a useful abstract discussion.", "startOffset": 0, "endOffset": 4}, {"referenceID": 10, "context": "[10] also showed how the operation of composition defined in [11] could be used to create novel games; this was a useful abstract discussion.", "startOffset": 61, "endOffset": 65}, {"referenceID": 9, "context": "[10] agrees: \u201ddescribing a game with this formalism seems to be a cumbersome task\u201d.", "startOffset": 0, "endOffset": 4}, {"referenceID": 17, "context": "In a multi-step modelling approach, methods for action-tracking [18], design pattern analysis [21], and player psychology profiling [7] can first describe the game; i.", "startOffset": 64, "endOffset": 68}, {"referenceID": 20, "context": "In a multi-step modelling approach, methods for action-tracking [18], design pattern analysis [21], and player psychology profiling [7] can first describe the game; i.", "startOffset": 94, "endOffset": 98}, {"referenceID": 6, "context": "In a multi-step modelling approach, methods for action-tracking [18], design pattern analysis [21], and player psychology profiling [7] can first describe the game; i.", "startOffset": 132, "endOffset": 135}, {"referenceID": 10, "context": "Here, I extend the full HCS defined by [11].", "startOffset": 39, "endOffset": 43}, {"referenceID": 9, "context": "However as [10] pointed out, with such a framework it is not yet possible to build any reasonably interesting game, in the sense of a system which produces meaningful decisions and outcomes [22].", "startOffset": 11, "endOffset": 15}, {"referenceID": 10, "context": "Definition: Composition with restriction, denoted \u2297, from [11], imposes a restriction of \u03a6X to a subset of X \u2297Mx, such that the composed monoids are forced to synchronise by the restriction.", "startOffset": 58, "endOffset": 62}, {"referenceID": 19, "context": "[20] defines an orbit as the behaviour of an imperative program f , i.", "startOffset": 0, "endOffset": 4}, {"referenceID": 21, "context": "These include Play Center, Block, Fork and others defined in [23].", "startOffset": 61, "endOffset": 65}, {"referenceID": 19, "context": "It cannot consist only of a stable state, as this cannot evolve (by definition [20]), and is therefore uninteresting from a player modelling point of view.", "startOffset": 79, "endOffset": 83}, {"referenceID": 19, "context": "Such monoids are constrained from having initial or terminal objects (as defined by [20]), because they would then be allowed to define only a single function, violating the principle that games should be uncertain.", "startOffset": 84, "endOffset": 88}, {"referenceID": 6, "context": "The instantiation orbit OX i is equivalent to the Behavlet logic, defined in [7].", "startOffset": 77, "endOffset": 80}, {"referenceID": 6, "context": "Further, the orbit starting condition (q, x0)i is equivalent to the Behavlet concept of a constraint harness, defined in [7].", "startOffset": 121, "endOffset": 124}, {"referenceID": 6, "context": "An example will illustrate the approach, for which I will take already peer-reviewed [7] and empirically tested [9] Behavlets, derived for the game Pac-Man (Namco, 1980).", "startOffset": 85, "endOffset": 88}, {"referenceID": 8, "context": "An example will illustrate the approach, for which I will take already peer-reviewed [7] and empirically tested [9] Behavlets, derived for the game Pac-Man (Namco, 1980).", "startOffset": 112, "endOffset": 115}, {"referenceID": 7, "context": "appendix D to [8]).", "startOffset": 14, "endOffset": 17}, {"referenceID": 10, "context": "The complete approach to simulation is detailed in [11], and is also discussed in [10].", "startOffset": 51, "endOffset": 55}, {"referenceID": 9, "context": "The complete approach to simulation is detailed in [11], and is also discussed in [10].", "startOffset": 82, "endOffset": 86}, {"referenceID": 6, "context": "Consider that, if we model Behavlets as game parts \u03a6X , then by the Behavlets method [7], each \u03a6X i will have an associated behaviour trait.", "startOffset": 85, "endOffset": 88}, {"referenceID": 4, "context": "Based on the work of [5] where humans achieved near-optimal solutions on hard problems, we can expect to find many problems where human skills can provide the seed for improved computational solutions.", "startOffset": 21, "endOffset": 24}, {"referenceID": 22, "context": "For example, [24] used a gamification to learn from humans solutions, creating heuristic optimisation methods for quantum computing problems which outperform traditional multi-parameter numerical methods.", "startOffset": 13, "endOffset": 17}, {"referenceID": 6, "context": "I have set out a method to do so, based on integrating my previously published Behavlets work [7] with a formal model of game play.", "startOffset": 94, "endOffset": 97}], "year": 2016, "abstractText": "General game playing artificial intelligence has recently seen important advances due to the various techniques known as \u2019deep learning\u2019. However the advances conceal equally important limitations in their reliance on: massive data sets; fortuitously constructed problems; and absence of any humanlevel complexity, including other human opponents. On the other hand, deep learning systems which do beat human champions, such as in Go, do not generalise well. The power of deep learning simultaneously exposes its weakness. Given that deep learning is mostly clever reconfigurations of well-established methods, moving beyond the state of art calls for forwardthinking visionary solutions, not just more of the same. I present the argument that general game playing artificial intelligence will require a generalised player model. This is because games are inherently human artefacts which therefore, as a class of problems, contain cases which require a human-style problem solving approach. I relate this argument to the performance of state of art general game playing agents. I then describe a concept for a formal category theoretic basis to a generalised player model. This formal model approach integrates my existing \u2019Behavlets\u2019 method for psychologically-derived player modelling: Cowley, B., & Charles, D. (2016). Behavlets: a Method for Practical Player Modelling using Psychology-Based Player Traits and Domain Specific Features. User Modeling and User-Adapted Interaction, 26(2), 257\u2013306.", "creator": "LaTeX with hyperref package"}}}