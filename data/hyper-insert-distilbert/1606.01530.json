{"id": "1606.01530", "review": {"conference": "arxiv", "VERSION": "v1", "DATE_OF_SUBMISSION": "5-Jun-2016", "title": "Adaptive Submodular Ranking", "abstract": "we clearly study suppose a general optimization adaptive ranking quality problem where an algorithm partially needs entropy to perform a sequence of unrelated actions on a uniformly random user, ostensibly drawn from along a generally known priority distribution, so as to \" satisfy \" the selected user as early decisions as possible. the satisfaction ability of inducing each independent user benefit is naturally captured by an individual submodular function, where evidently the user is now said intending to simply be merely satisfied when enforcing the function optimal value goes above overcoming some uncertainty threshold. we obtain a logarithmic factor approximation algorithm for this adaptive ranking problem, which is the best possible. the adaptive information ranking correction problem specifically has served many obvious applications in helping active learning and ranking : it potentially significantly generalizes \" previously - studied problems such as optimal allocation decision trees, equivalence class class determination, decision region determination ) and submodular cover. next we also present some powerful preliminary experimental utility results based just on our inference algorithm.", "histories": [["v1", "Sun, 5 Jun 2016 16:19:58 GMT  (166kb,D)", "http://arxiv.org/abs/1606.01530v1", null]], "reviews": [], "SUBJECTS": "cs.DS cs.LG", "authors": ["fatemeh navidi", "prabhanjan kambadur", "viswanath nagarajan"], "accepted": false, "id": "1606.01530"}, "pdf": {"name": "1606.01530.pdf", "metadata": {"source": "CRF", "title": "Adaptive Submodular Ranking", "authors": ["Fatemeh Navidi", "Prabhanjan Kambadur", "Viswanath Nagarajan"], "emails": [], "sections": [{"heading": "1 Introduction", "text": "Many tasks in machine learning can be represented as sequential decision processes. An algorithm is given an a priori distribution D over inputs, and its goal is to satisfy the realized input i\u2217 \u2208 D. In each step, the algorithm chooses an action which partially satisfies i\u2217 and also provides a feedback depending on i\u2217. This feedback is then used to refine the distribution of i\u2217 for the subsequent steps. So an algorithm in this setting (also called policy) is an adaptive sequence of actions.\nFurthermore, many different criteria to satisfy the realized input i\u2217 can be modeled as covering a submodular function. Submodular functions are a very general class of set-functions that have certain convexity as well as concavity properties [24]. These functions are used to model utilities in game theory, influence maximization in social networks, diversity in search ranking etc.\nIn this paper, we study an adaptive optimization problem in the setting described above which simultaneously generalizes many previously-studied problems such as optimal decision trees [20, 23, 10, 8, 18, 9], equivalence class determination [14, 7], decision region determination [22] and submodular ranking [3, 21]. We obtain an algorithm with the best-possible approximation guarantee. Moreover, our algorithm is very simple to state and implement. We also present some preliminary experimental results which are promising.\nBefore defining the adaptive submodular ranking problem formally, we discuss two special cases with applications in active learning and search ranking.\nOptimal Decision Trees. This is a basic problem in active learning, which is also called entity identification. There are m possible hypotheses with an a priori distribution D on the true hypothesis i\u2217. The distribution D is given by probabilities {pi}mi=1 that sum to one. We can perform tests in order to distinguish between the hypotheses. Each test e costs ce and is positive for a particular subset Te of hypotheses. We assume that i\n\u2217 can be identified by performing all tests.The goal in the optimal decision tree problem is to determine the true hypothesis i\u2217 at the minimum expected cost. Figure 1(a) shows an example with 3 hypotheses, 7 tests and probabilities\n\u2217Department of Industrial and Operations Engineering, University of Michigan \u2020Bloomberg Labs\nar X\niv :1\n60 6.\n01 53\n0v 1\n[ cs\n.D S]\n5 J\nun 2\n01 6\np1 = 0.4, p2 = 0.5, p3 = 0.1; the sets S1, S2, S3 depict the positive tests for each hypothesis; the decision tree corresponds to a feasible adaptive solution with expected cost 1.5.\nAdaptive Multiple Intent Ranking. This is an adaptive version of the search ranking problem studied in [4, 5, 25]. Suppose there are n results to a particular query and m different user-types. Each user-type i is characterized by a subset Si of the results and a threshold Ki \u2264 |Si|, which means that a user of type i will be satisfied after seeing at least Ki results from the subset Si. We are also given a distribution D on the m user-types. The ranking algorithm displays results one by one, and receives feedback on whether each displayed result e is relevant to user-type i\u2217, i.e. whether/not e \u2208 Si\u2217 . The goal is find an ordering of the n results that minimizes the expected number of results before satisfying a random user i\u2217 \u2208 D. Note that the algorithm needs to balance its effort in learning the identity of i\u2217 and satisfying the requirement of i\u2217. Figure 1(b) shows an example with m = 3, n = 7 and probabilities p1 = 0.4, p2 = 0.5, p3 = 0.1; the set system depicts the interest-sets Sis and the thresholds are K1 = K2 = 2, K3 = 4; the decision tree corresponds to a feasible adaptive solution with expected cost 2.7.\nFor some adaptive optimization problems, one can come up with approximately optimal solutions using static (non-adaptive) solutions that are insensitive to the feedback obtained, eg. [11, 6]. However, this is not the case for the adaptive submodular ranking problem that we consider. Even for the special cases above, there are instances where the optimal adaptive value is much less than the optimal non-adaptive value. So it is important to come up with an adaptive algorithm.\nProblem Statement. We start with some basics. A set function f : 2U \u2192 R+ on ground set U is said to be submodular if for all subsets A,B \u2286 U we have f(A) + f(B) \u2265 f(A\u2229B) + f(A\u222aB). See [24] for background. The function f is said to be monotone if f(A) \u2264 f(B) for all A \u2286 B \u2286 U . We assume that set functions are given in the standard value oracle model, i.e. we can evaluate f(S) for any S \u2286 U in polynomial time.\nIn the adaptive submodular ranking problem (ASR) we have a ground set U of n elements with costs {ce}e\u2208U . We also have m scenarios. Each scenario i \u2208 [m] := {1, \u00b7 \u00b7 \u00b7 ,m} is specified by an interest-set Si \u2286 U and a normalized monotone submodular function fi : 2Si \u2192 [0, 1] where fi(\u2205) = 0 and fi(Si) = 1 (every monotone submodular function on Si can be expressed in this form by scaling and truncation). For notational simplicity, we extend each function fi : 2\nSi \u2192 [0, 1] to arbitrary subsets S \u2286 U by setting fi(S) = fi(S \u2229 Si). A scenario i \u2208 [m] is said to be covered/satisfied by any subset S \u2286 U of elements such that fi(S) = 1. We are also given a distribution D on the m scenarios, i.e. probabilities {pi}mi=1 that sum to one: this means that the realized scenario i\u2217 = i with probability pi, for each i \u2208 [m]. The goal in ASR is to find an adaptive ordering of the elements in U that minimizes the expected cost to cover the realized scenario i\u2217 \u2208 D. The key aspect of this problem is that the ranking algorithm receives feedback on whether/not each chosen element e is relevant to user i\u2217 (i.e. whether e \u2208 Si\u2217), and can use this information to choose the next element.\nAn adaptive solution is represented by a binary decision tree T , where nodes are labeled by elements e \u2208 U . Every scenario i \u2208 [m] traces a root-leaf path in the decision tree T which takes the\nyes-branch on any node e \u2208 Si and the no-branch on any node e 6\u2208 Si; let Ti denote the sequence of elements on this path. Every scenario i \u2208 [m] must be satisfied in the decision tree, i.e. fi(Ti) \u2265 1. The cost of scenario i in decision tree T is the cost of the shortest prefix T\u0304i of Ti such that fi(T\u0304i) \u2265 1. The objective in ASR is to minimize the expected cost. We note that multiple scenarios may trace the same path in T .\nAn important parameter in the analysis of our algorithm is the following:\n:= min i\u2208[m], S\u2286U min e\u2208U :fi(S\u222ae)>fi(S)\nfi(S \u222a e)\u2212 f(S). (1)\nThis measures the minimum positive incremental value of any element. This same parameter or its variants appear in all results on the submodular cover problem, eg. [26, 3, 21, 15].\nResults. Our main result is an O(log 1 + logm)-approximation algorithm for adaptive submodular ranking where > 0 is as defined in (1) and m is the number of scenarios. Assuming P 6= NP , this result is the best possible (up to constant factors) as the set cover problem [12] is a special case of ASR even when m = 1. Our algorithm is a simple adaptive greedy-style algorithm. At each step, we assign a score to each remaining element and select the element with maximum score.\nSuch a simple algorithm was previously unknown even in the special case of optimal decision tree (under arbitrary costs/probabilities), despite a large number of papers [20, 23, 10, 1, 8, 16, 18, 13, 9] on this topic. The first O(logm)-approximation algorithm for ODT was obtained in [18], and this result was extended to the equivalence class determination problem in [9]. Previous results, eg. [23, 10, 1, 8, 16], based on a simple greedy \u201csplitting\u201d algorithm, had a logarithmic dependence on either costs or probabilities which (in the worst case) can be exponential in m.\nAs direct applications of our algorithm, we obtain approximation algorithms for the two problems mentioned above: an O(log(maxiKi)+logm)-approximation for the adaptive multiple intent ranking problem and an O(logm)-approximation for optimal decision tree. More applications and details can be seen in Section 3.\nRelated Works. Our work unifies two distinct lines of work in a clean manner. One line of work is on the submodular cover problem and its variants [26, 4, 3, 21]. The other line of work is on the optimal decision tree problem and its variants, eg. [23, 10, 18, 13, 9]. In particular, we combine the time-based analysis for the deterministic submodular ranking problem in [21] with the phase-based analysis for optimal decision tree in [23, 18, 9].\nWe note that [21] also considers a stochastic variant of submodular ranking, but it is different from ASR because [21] assumes an independent distribution whereas we assume a correlated scenariobased distribution. In particular, unlike ASR, the stochastic submodular ranking problem in [21] does not capture the optimal decision tree problem and its variants.\nRecently, [15] also considered a scenario-based submodular cover problem. However, their model requires a single submodular function for all scenarios, whereas ASR allows an individual submodular function for each scenario. In this respect our setting is a generalization of [15], eg. ASR captures the submodular ranking problem [3] whereas [15] does not. On the other hand, [15] allows arbitrary feedback whereas ASR as defined only considers binary (yes/no) feedback. We note that our algorithm can be extended to obtain an O(log 1 + logm)-approximation in the setting with arbitrary feedback as well \u2013 see Section 3.\nThe notion of \u201cadaptive submodularity\u201d [13] has been very useful in obtaining algorithms for some previously-studied special cases [14, 7, 22] of ASR. In particular, among other results [13] obtained an O(log 1/ + log 1/pmin)-approximation algorithm for ASR when fi = f for all scenarios i, the function f is adaptive-submodular (a stronger condition than submodular) and pmin = min m i=1 pi is the minimum probability. Our result is stronger in the following ways (i) we allow non-uniform functions fi for each scenario, (ii) we only require submodularity of these functions, (iii) our performance guarantee O(log 1 + logm) is better. We note that [15] is also an improvement over [13] in points (ii) and (iii) above."}, {"heading": "2 The Algorithm", "text": "Recall that an instance of ASR consists of a ground set U of elements with costs {ce}e\u2208U , and m scenarios with an interest-set Si \u2286 U , submodular function fi : 2Si \u2192 [0, 1] and probability pi associated with each scenario i \u2208 [m]. The goal in ASR is to find an adaptive ordering of the elements in U that minimizes the expected cost to cover the realized scenario i\u2217 \u2208 D.\nThe \u201cstate\u201d of our algorithm (i.e. any node in its decision tree) will be represented by (i) the set E \u2286 U of previously displayed elements, and (ii) the set H \u2286 [m] of scenarios that are compatible with feedback (on E) received so far and are still uncovered. At any state (E,H), our algorithm does the following. For each element e \u2208 U \\ E, we define Le(H) \u2286 H as follows:\nLe(H) = argmin(|{i \u2208 H : e \u2208 Si}|, |{i \u2208 H : e 6\u2208 Si}|) (2)\nThen we select element e \u2208 U \\ E that maximizes:\n1 ce \u00b7  \u2211 j\u2208Le(H) pj + \u2211 i\u2208H pi \u00b7 fi(e \u222a E)\u2212 fi(E) 1\u2212 fi(E)  . (3) Note that H only contains uncovered scenarios. So fi(E) < 1 for all i \u2208 H and the denominator in the sum above is always positive. Next we analyze the performance of this algorithm. Below, for any subset T \u2286 [m] of scenarios, we use Pr(T ) = \u2211i\u2208T pi.\nLet OPT denote an optimal solution to the ASR instance and ALG be the solution found by the above algorithm. Set L := 15(1 + ln 1/ + log2m) and its choice will be clear later. We assume (without loss of generality) by scaling that all costs are positive integers. We refer to the total cost incurred at any point in a solution as the time. For any k = 0, 1, \u00b7 \u00b7 \u00b7 , we define the following quantities:\n\u2022 Ak \u2286 [m] is the set of uncovered scenarios of ALG at time L \u00b7 2k, and ak = Pr(Ak).\n\u2022 xk is the probability of uncovered scenarios of OPT at time 2k\u22121. Claim 1. The expected cost of ALG and OPT can be bounded as follows.\nCALG \u2264 L \u2211 k\u22650 2kak + L and COPT \u2265 1 2 \u2211 k\u22651 2k\u22121xk (4)\nProof. In ALG, for all k \u2265 1, the probability of scenarios for which the cover time is in (2k\u22121L, 2kL] is equal to ak\u22121 \u2212 ak. So we have:\nCovALG \u2264 \u2211 k\u22651 2kL(ak\u22121 \u2212 ak) = \u2211 k\u22651 2kLak\u22121 \u2212 \u2211 k\u22651 2kLak (5)\n= 2 \u2211 k\u22650 2kLak \u2212 ( \u2211 k\u22650 2kLak \u2212 L) = \u2211 k\u22650 2kLak + L (6)\nAbove we use this fact that a0 = 1. On the other hand, in OPT, for all k \u2265 1, the probability of scenarios for which the cover time is in (2k\u22122, 2k\u22121] is equal to xk\u22121 \u2212 xk. So we have:\nCovOPT \u2265 \u2211 k\u22652 2k\u22122(xk\u22121 \u2212 xk) = \u2211 k\u22652 2k\u22122xk\u22121 \u2212 \u2211 k\u22652 2k\u22122xk (7)\n= \u2211 k\u22651 2k\u22121xk \u2212 1 2 ( \u2211 k\u22651 2k\u22121xk \u2212 1) \u2265 1 2 \u2211 k\u22651 2k\u22121xk (8)\nWhere we use this fact that x1 = 1.\nThus, if we could upper bound each ak by some multiple of xk, then it is easy to establish the approximation factor. However, this is not the case here and instead we prove:\nLemma 2.1. For all k \u2265 1 we have ak \u2264 0.2ak\u22121 + 3xk. This lemma implies our main result:\nTheorem 2.2. The algorithm for ASR is an O(log 1/ + logm)-approximation algorithm. Proof. Let Q = \u2211 k\u22650 L \u00b7 2kak + L, which is the bound on CALG from (4). Using Lemma 2.1:\nQ \u2264 L \u00b7 \u2211 k\u22651 2k(0.2ak\u22121 + 3xk) + L(a0 + 1)\n\u2264 0.4L \u00b7 \u2211 k\u22650 2kak + 6L \u00b7 \u2211 k\u22651 2k\u22121xk + L(a0 + 1)\n\u2264 0.4(Q\u2212 L) + 6L \u00b7 \u2211 k\u22651 2k\u22121xk + 2L \u2264 0.4 \u00b7Q+ 12L \u00b7 COPT + 1.6L (9)\nThe first inequality in (9) is by definition of Q and a0 \u2264 1. The second inequality in (9) uses the bound on COPT from (4). Finally, as COPT \u2265 1 (all costs are positive integers), we have Q \u2264 0.4 \u00b7Q + 13.6L \u00b7 COPT . This yields Q \u2264 1366 L \u00b7 COPT . Since L = 15(1 + ln 1/ + logm) and CALG \u2264 Q, we obtain the theorem.\nWe now prove Lemma 2.1 for a fixed k \u2265 1. Consider any time t between L \u00b7 2k\u22121 and L \u00b7 2k. Note that ALG\u2019s decision tree induces a partition of all the uncovered scenarios at time t, where each part H consists of all scenarios that are at a particular node (E,H) at time t. Let R(t) denote the set of parts in this partition. Note that all scenarios in Ak appear in R(t) as these scenarios are uncovered even at time L \u00b7 2k \u2265 t. Similarly, all scenarios in R(t) are also in Ak\u22121.\nFor any part H \u2208 R(t), let (E,H) denote the node in ALG\u2019s decision tree corresponding to H. We note that E consists of all elements that have been completely displayed by time t. The element f selected at this node is not included in E (though f starts at/before time t it is not yet completely displayed). Let TH(k) denote the subtree of OPT that corresponds to paths traced by scenarios in H up to time 2k\u22121. Note that each node (labeled by element e \u2208 E) in TH(k) has two outgoing branches: one corresponding to Le(H) and the other to H \\ Le(H). We define Stemk(H) to be the path in TH(k) that at each node (labeled e) follows the branch corresponding to H \\ Le(H). Below we also use Stemk(H) to denote the set of elements that are completely displayed on this path. As all the scenarios in H are compatible with the feedback from elements E,\nObservation 1. Consider any node (E,H) in ALG. Then for all e \u2208 E we have exactly one of the following: e \u2208 Si for all i \u2208 H, or e /\u2208 Si for all i \u2208 H. Hence, Le(H) = \u2205 for all e \u2208 E.\nDefinition 1. Each node (E,H) in ALG is exactly of one of the following types:\n\u2022 \u201cbad\u201d if the probability of uncovered scenarios at the end of Stemk(H) is at least Pr(H)3 .\n\u2022 \u201cokay\u201d if it is not bad and the probability of \u222ae\u2208Stemk(H) Le(H) is at least Pr(H) 3 .\n\u2022 \u201cgood\u201d if it is neither bad nor okay and the probability of scenarios that get covered by Stemk(H) is at least Pr(H) 3 .\nTo see that this is well defined, note by definition of Stemk(H) that each scenario in H is (i) uncovered at the end of Stemk(H), or (ii) in Le(H) for some e \u2208 Stemk(H), or (iii) covered by some prefix of Stemk(H). So the total probability of the scenarios in one of these 3 categories must be at least Pr(H)3 . Therefore each node (E,H) is at least of one of the three types mentioned.\ntime : L2k\u22121 time : L2ktime : t\ngood\nH1\nH4\nbad\nokay\nH2\nH3\nH5\nH6\nH7\nR(t) = {H1, H2, H3, H4, H5, H6, H7} R(t) is a partition of uncovered scenarios at time t\nFigure 3: Bad, good and okay nodes in ALG\nObservation 2. For any time L2k\u22121 < t \u2264 L2k, we have \u2211H\u2208R(t) H:bad Pr(H) < 3xk.\nProof. Note that Stemk(H) \u2286 TH(k). Recall that TH(k) was the subtree of OPT up to time 2k\u22121 that only contains the scenarios in H. So, the probability of uncovered scenarios at the end of Stemk(H) is at most the probability of scenarios in H that are not covered in OPT by time 2\nk\u22121. This probability is at least equal to P (H)/3 based on the definition of bad nodes. Now, since nodes in R(t) denotes a subpartition of scenarios, we have\n\u2211 H\u2208R(t) H:bad Pr(H)/3 < xk.\nThe following quantity turns out to be useful in our proof of Lemma 2.1.\nG := L2k\u2211\nt>L2k\u22121 \u2211 H\u2208R(t) max e\u2208U\\E 1 ce \u00b7 ( Pr(Le(H)) + \u2211 i\u2208H pi \u00b7 fi(e \u222a E)\u2212 fi(E) 1\u2212 fi(E) ) (10)\nAbove, for any H \u2208 R(t) the set E of elements comes from the node (E,H) in ALG corresponding to H. Note that G corresponds to the total \u201cgain\u201d according to our algorithm\u2019s selection criterion (3) accrued from time L2k\u22121 to L2k. In what follows we obtain a lower and upper bound for G and combine them to prove lemma 2.1.\nLemma 2.3. We have G \u2265 L \u00b7 (ak \u2212 3xk)/3\nProof. Considering only the good/okay nodes in each R(t) in the expression (10) for G,\nG \u2265 L2k\u2211\nt>L2k\u22121 \u2211 H\u2208R(t) H:okay max e\u2208U\\E Pr(Le(H)) ce + L2k\u2211 t>L2k\u22121 \u2211 H\u2208R(t) H:good max e\u2208U\\E 1 ce \u00b7 \u2211 i\u2208H pi \u00b7 fi(e \u222a E)\u2212 fi(E) 1\u2212 fi(E)\nFix any time t. For any node (E,H) with H \u2208 R(t) define W (H) = Stemk(H) \\ E. Recall that the total cost of elements in Stemk(H) is at most 2 k\u22121; so c(W (H)) \u2264 2k\u22121.\nCase 1. (E,H) is an okay node. Since W (H) \u2286 U \\ E we can write:\nmax e\u2208U\\E\nPr(Le(H))\nce \u2265 max e\u2208W (H)\nPr(Le(H))\nce \u2265\n\u2211 e\u2208W (H) Pr(Le(H))\nc(W (H)) \u2265 Pr(\u222ae\u2208W (H)Le(H)) 2k\u22121\n= 1\n2k\u22121 \u00b7 Pr(\u222ae\u2208Stemk(H)Le(H)) \u2265\nPr(H)\n3 \u00b7 2k\u22121 (11)\nThe equality in (11) is by Observation 1, and the last inequality is by definition of an okay node. Case 2. (E,H) is a good node. Below, we use F \u2286 H to denote the set of scenarios that get covered in Stemk(H); by definition of a good node, we have Pr(F ) \u2265 Pr(H)/3. Again using W (H) \u2286 U \\ E, we have:\nmax e\u2208U\\E\n1 ce \u00b7 \u2211 i\u2208H pi \u00b7 fi(e \u222a E)\u2212 fi(E) 1\u2212 fi(E) \u2265 max e\u2208W (H) 1 ce \u00b7 \u2211 i\u2208H pi \u00b7 fi(e \u222a E)\u2212 fi(E) 1\u2212 fi(E)\n\u2265 1 c(W (H)) \u2211 e\u2208W (H) \u2211 i\u2208H pi \u00b7 fi(e \u222a E)\u2212 fi(E) 1\u2212 fi(E) \u2265 1 2k\u22121 \u2211 i\u2208W (H) pi \u00b7 \u2211 e\u2208W (H) fi(e \u222a E)\u2212 fi(E) 1\u2212 fi(E)\n\u2265 1 2k\u22121 \u2211 i\u2208H pi \u00b7 fi(W (H) \u222a E)\u2212 fi(E) 1\u2212 fi(E) =\n1\n2k\u22121 \u2211 i\u2208H pi \u00b7 fi(Stemk(H))\u2212 fi(E) 1\u2212 fi(E) (12)\n\u2265 1 2k\u22121 \u2211 i\u2208F pi \u00b7 1\u2212 fi(E) 1\u2212 fi(E) = Pr(F ) 2k\u22121 \u2265 Pr(H) 3 \u00b7 2k\u22121 (13)\nThe inequality in (12) is by submodularity of the fis, and the equality is by definition of W (H). The first inequality in (13) is by definition of F being the covered scenarios in Stemk(H) and the last inequality is by definition of a good node.\nCombining lower bounds for okay (11) and good (13) nodes,\nG \u2265 L2k\u2211\nt>L2k\u22121 \u2211 H\u2208R(t) H:okay Pr(H) 3 \u00b7 2k\u22121 + L2k\u2211 t>L2k\u22121 \u2211 H\u2208R(t) H:good Pr(H) 3 \u00b7 2k\u22121\n= L2k\u2211 t>L2k\u22121\n1\n3 \u00b7 2k\u22121 Pr(R(t))\u2212 \u2211 H\u2208R(t) H:bad Pr(H)  \u2265 L2 k\u2211 t>L2k\u22121 ak \u2212 3xk 3 \u00b7 2k\u22121 = L \u00b7 (ak \u2212 3xk) 3\nThe first equality uses the fact that the nodes corresponding to H \u2208 R(t) are exactly one of the types bad/okay/good. The last inequality uses Observation 2 and that R(t) contains all scenarios in Ak.\nLemma 2.4. We have G \u2264 ak\u22121 \u00b7 (1 + ln 1/ + logm).\nProof. For any scenario i \u2208 Ak\u22121 (i.e. uncovered in ALG by time L2k\u22121) let \u03c0i be the path traced by i in ALG\u2019s decision tree, starting from time 2k\u22121L and ending at 2kL or when i gets covered. For each element e that appears in \u03c0i, let 1 \u2264 te,i \u2264 ce denote the units of time when e is being displayed during the interval (L2k\u22121 , L2k]. Note that there can be at most two elements e in \u03c0i with ti,e < ce: one that is being displayed at time L2\nk\u22121 and another at L2k. Recall that every scenario in R(t) appears in Ak\u22121. So only scenarios in Ak\u22121 can contribute to\nG and we can rewrite (10) as follows:\nG = \u2211\ni\u2208Ak\u22121 pi \u00b7 \u2211 e\u2208\u03c0i te,i \u00b7 1 ce ( fi(e \u222a E)\u2212 fi(E) 1\u2212 fi(E) + 1[i \u2208 Le(H)] )\n\u2264 \u2211\ni\u2208Ak\u22121 pi \u00b7 (\u2211 e\u2208\u03c0i fi(e \u222a E)\u2212 fi(E) 1\u2212 fi(E) + \u2211 e\u2208\u03c0i 1[i \u2208 Le(H)] )\n(14)\nFix any scenario i \u2208 Ak\u22121. For the first term, we use Claim 2.1 in [3] which relies on the definition of in (1). This implies \u2211 e\u2208\u03c0i fi(e\u222aE)\u2212fi(E) 1\u2212fi(E) \u2264 1 + ln 1 . In order to bound the second term, note that if scenario i \u2208 Le(H) when ALG selects element e then number of possible scenarios decreases by at least a factor of two in path \u03c0i. So such an event can happen at most log2m times along the path \u03c0i. Thus we can write\n\u2211 e\u2208\u03c0i\n1[i \u2208 Le(H)] \u2264 logm. The lemma now follows from (14).\nWe now complete the proof of Lemma 2.1. Using Lemma 2.3 and Lemma 2.4 we can write:\nL \u00b7 (ak \u2212 3xk)/3 \u2264 G \u2264 ak\u22121 \u00b7 (1 + ln 1/ + logm) = ak\u22121 \u00b7 L\n15\nRearranging, we obtain ak \u2264 0.2 \u00b7 ak\u22121 + 3xk as needed."}, {"heading": "3 Extensions", "text": "The ASR problem as defined involves binary feedback from each element. Our algorithm can be easily generalized to handle arbitrary (non-binary) feedback as well. As before, we have elements U with costs {ce}e\u2208U and m scenarios with probabilities {pi}mi=1 (the realized scenario i\u2217 = i with probability pi). Each element e \u2208 U has an initially unknown state \u03b4(e) \u2208 \u0393. When an element e is displayed, it provides its state \u03b4(e) as feedback. Each scenario specifies a state for each element in U , i.e. we are given values {di,e : e \u2208 U, i \u2208 [m]} where di,e is the state of element e under scenario i. In the binary case considered in Section 2, |\u0393| = 2 (corresponding to yes/no) and each scenario i specifies a \u201cyes\u201d state for elements e \u2208 Si and a \u201cno\u201d state for elements e 6\u2208 Si. Each scenario i \u2208 [m] is also associated with a function fi defined over subsets of U \u00d7 \u0393; we again assume that fi is monotone submodular and takes values in [0, 1]. Note that the ground set of these functions is different from the set U of elements. Scenario i \u2208 [m] is said to be covered by a subset S \u2286 U of elements if fi({(e, \u03b4(e))|e \u2208 S}) = 1. The goal is to find an adaptive ordering of the elements so as to minimize the expected cost to cover the realized scenario.\nA slight modification of the algorithm in Section 2 also works here. Recall the definition (2) of Le(H) where H \u2286 [m] is the \u201ccurrent\u201d set of scenarios at any point in the algorithm. We extend this definition as follows. For any element e, let Be(H) denote the set with maximum cardinality amongst {i \u2208 H : di,e = t} for t \u2208 \u0393; then Le(H) = H \\ Be(H). The algorithm again selects elements according to the criterion (3). The analysis of the O(log 1/ + logm) approximation ratio of this algorithm remains unchanged from Section 2."}, {"heading": "4 Applications", "text": "In this section we discuss various applications of ASR. Some problems have been studied previously and our result matches the best approximation ratio known with the added advantage of being a simpler (and more efficient) algorithm. Some other problems are new and our result provides the first approximation ratio for these.\nDeterministic Submodular Ranking In this problem we are given a set of elements [n] and m monotone submodular functions f1, f2, . . . , fm such that fi : 2\n[n] \u2192 R+ and are normalized between 0 and 1. We also have a weight vector w \u2208 Rm+ and our goal is to find a linear ordering of elements that minimizes \u2211n i=1wici, where ci is the first time that the value of function fi reaches one or higher. We can use our algorithm for this problem with the same fis if we define S1 = S2 = ... = Sm = [n] = U , and pi = wi/( \u2211n j=1wj). Theorem 2.2 directly gives an O(logm+ log 1 )-approximation algorithm. Moreover, by observing that in (3) Le = \u2205 always, we obtain an O(log 1 )-approximation, which matches the best result known [3].\nAdaptive Multiple Intent Ranking This problem was defined in the introduction. It can be modeled as ASR using the functions:\nfi(S) = min(|S \u2229 Si|,Ki)\nKi , for all S \u2286 U and i \u2208 [m].\nNote that each fi is bounded between 0 and 1, and is monotone submodular. We also have = 1/maxi\u2208[m]Ki. So Theorem 2.2 yields an O(log max\ni\u2208[m] Ki + logm)-approximation algorithm.\nOptimal Decision Tree This problem was also defined in the introduction. It captures many applications in active learning, medical diagnosis, etc. In order to cast this as an instance of ASR, we need some additional definitions. For each test e \u2208 U and hypothesis i \u2208 [m] we define Te(i) = {j \u2208 [m]|e \u2208 Si \u2295 Sj} where \u2295 is the symmetric difference operator, and set\nfi(S) = | \u222ae\u2208S Te(i)| \u00b7 1\nm\u2212 1 , for all S \u2286 U and i \u2208 [m].\nNote that fis are coverage functions, so they are monotone and submodular; also the scaling by 1 m\u22121 ensures they take values between 0 and 1. By definition of Te(i), we know that \u22c3 e\u2208S Te(i)\nare the hypotheses that differ from i in at least one of the tests S. Hence, having fi(S) = 1 is equivalent to |\u22c3e\u2208S Te(i)| = m\u2212 1, i.e. we have identified i as the true hypothesis. Here we have = 1m\u22121 , so Theorem 2.2 gives an O(logm)-approximation algorithm. This matches the best result known in [18], but their algorithm is more complicated than ours.\nGeneralized Optimal Decision Tree Our algorithm also extends to the setting when we do not have to identify a unique hypothesis. Here we are given a threshold ti for each i \u2208 [m] such that it suffices to output a subset of at most ti\u2217 hypotheses that is guaranteed to contain the true hypothesis i\u2217. This can be handled easily by changing the definition of fis to:\nfi(S) = min { | \u222ae\u2208S Te(i)| \u00b7\n1\nm\u2212 ti , 1\n} , for all S \u2286 U and i \u2208 [m].\nNote that this time we will have fi(S) = 1 if the number of hypotheses that do not match i on tests S is at least m \u2212 ti; so this corresponds to having at most ti possible hypotheses. And Theorem 2.2 implies an O(logm)-approximation algorithm. To the best of our knowledge this is the first approximation algorithm in this setting; previous results only seem applicable when tis are uniform.\nEquivalence Class Determination We are given an unknown hypothesis in a set of m hypotheses and a partition Q of [m]. Let Q(i) be the subset in the partition that contains i. We are allowed to perform a set of tests, and we know that each partition is uniquely identified based on\nthe results of all tests. Our goal is to minimize the expected cost of tests until we recognize the part containing the true hypothesis. We can model this as an ASR instance with\nfi(S) = | \u222ae\u2208S (Te(i) \u2229Q(i)c)|\n|Q(i)c| , for all S \u2286 U and i \u2208 [m].\nWhere Ac denotes the complement of set A. The Te(i) are as defined above for optimal decision tree. Note that fis are monotone submodular with values between 0 and 1. Furthermore, fi(S) = 1 means that Q(i)c \u2286 \u222ae\u2208STe(i), which means that the set of compatible hypotheses based on the tests S is a subset of Q(i). Again, Theorem 2.2 implies an O(logm)-approximation algorithm. This is equal to the best previous result [9], but again our algorithm is much simpler.\nDecision Region Determination As before, we are given an unknown hypothesis in a set of m hypotheses and tests U . We also have a set of decisions: each decision j is a \u201cregion\u201d Dj \u2286 [m] that corresponds to the hypotheses that it is applicable to. The goal is to find a policy for performing tests with minimum expected cost so as to find any decision region containing the true hypothesis.\nFor each hypothesis i \u2208 [m] and decision j such that i \u2208 Dj define fi,j(S) = | \u22c3 e\u2208S(Te(i)\u2229Dj c)|\n|Djc| .\nClearly fi,js are monotone submodular with values between 0 and 1. Also, fi,j(S) = 1 means that Dj c \u2286 \u22c3e\u2208S Te(i), which means that the set of compatible hypotheses based on the tests S is a subset of decision region Dj . However, we may stop when it is determined that the true hypothesis is in any one of the decision regions. This criterion (for hypothesis i) corresponds to at least one fi,j(S) = 1 among {j : i \u2208 Dj} reaches one. In [17] it is shown that the \u201cOR of submodular functions\u201d is submodular. Based on that, we express:\nfi(S) = 1\u2212 \u220f i\u2208Dj (1\u2212 fi,j(S)), for all S \u2286 U and i \u2208 [m].\nSo we obtain an instance of ASR. Note that here the parameter = min i\n\u220f j:i\u2208Dj 1 |Djc| is much\nsmaller due to the OR construction. Still, we have = \u2126(m\u2212r) where r is the maximum number of decision regions that contain a hypothesis. So in this case, Theorem 2.2 implies an O(r logm)approximation algorithm where r is the maximum number of decision regions that contain a hypothesis. [22] obtained an O(min{r, d} \u00b7 ln 1mini pi )-approximation algorithm for this problem, which was improved by [15] to O(min{r, d} \u00b7 logm); here d is the maximum size of a decision region. Our algorithm runs in time polynomial in m and r, unlike [22, 15] which required time exponential in r. As in [22, 15], we can also obtain an O(d logm)-approximation with running time exponential in d."}, {"heading": "5 Experiments", "text": "In this section, we present experimental results for the adaptive multiple intent ranking problem (MIR) and the (generalized) optimal decision tree problem (ODT). We use expected cost (number of elements) as the performance metric to compare different algorithms for the MIR and ODT problems. For example, in the MIR case, if i\u2217 is satisfied after looking at k elements, we say that costi\u2217 = k; the performance metric is then \u2211 i\u2208H pi \u00b7 costi.\nEnvironment: We developed high-quality python modules to evaluate the performance of our algorithms against their well-known counterparts for both ODT and MIR. Our experimental machine has 40 Intel R\u00a9 Xeon R\u00a9 E5-2660 cores running at 2.6 Ghz, with 396 GB of RAM running Linux 2.6.32 kernel. We used the Python 2.7.10 interperter to run our experiments. Datasets: The real-world dataset used in our experiments \u2014 called ML-100 \u2014 is the 100K example from the MovieLens [19] repository, which contains 100,000 ratings on a scale of [1,5] from 943 users\n(scenarios) on 1682 movies (elements) where each user has rated \u2265 20 movies. We binarized this dataset by setting all ratings < 3 to 0, which left us with 82, 520 ratings, where the average user had 87.5 ratings with a standard deviation of 81.2, which suggests a highly-skewed distribution. With this dataset, we use the power-law (Pr[X = x;\u03b1] = \u03b1x\u03b1\u22121) with \u03b1 = 1, 2, 3; note that when \u03b1 = 1, we get a uniform distribution. To get a better understanding of the performance results, we generate multiple permuatations of scenario distributions for the same value of \u03b1. For the ODT problem, we also use a synthetic dataset \u2014 SYN-K \u2014 that is parameterized by k; this is based on a hard instance for the greedy algorithm [23]. Given k, we generate m = 2k + 3 sets, n = k + 2 elements, with 4k + 4 non-zeros as follows: (a) elements i \u2208 [1, k] are contained in scenarios 2i\u2212 1 and 2i, (b) element k + 1 is contained in all odd numbered scenarios, and (c) element k + 2 is contained in all even numbered scenarios and scenario 2k + 3. The probabilities for the scenarios are as follows: Pr[2i \u2212 1] = Pr[2i] = 2\u2212i\u22122 for i \u2208 [1, k], Pr[2k + 1] = Pr[2k + 2] = 2\u2212k\u22122 \u2212 , where 0 < < 2\u2212k\u22122, and Pr[2k + 3] = 2\u22121 + 2 ."}, {"heading": "5.1 Optimal Decision Trees", "text": "Algorithms. The crux of solving the ODT problem is in chosing an element at each step and making updates to the problem state depending on whether e \u2208 Si\u2217 . In our experiments, we compare and contrast the results of 3 algorithms that use different objectives to choose elements: (a) ODT-adsub, which uses the objective described in (3), (b) ODT-greedy, which uses the classic greedy objective [23, 10, 1, 8, 16], and (c) ODT-ml, a \u201cmachine learning\u201d algorithm that operates as follows. ODT-ml, which is parameterized by K uses k-Means [2] to a priori partition U into K clusters. Each cluster cj , j \u2208 [1,K] is initially given a weight wcj = 1. To choose the next element e \u2208 U \\E, a cluster j \u2208 [1,K] is first chosen by sampling non-uniformly according to wcj . Next, an element e \u2208 cj is chosen uniformly at random. If e \u2208 Si\u2217 , the cj is rewarded by setting wcj = 2wcj , else cj is penalized by setting wcj = 0.5wcj .\nResults. Table 1 depicts the results for ODT-adsub, ODT-greedy, and ODT-ml on SYN-K datasets for K = 50, 100, 150, 200, 250. For this highly-skewed distribution, ODT-adsub outperforms ODTgreedy and ODT-ml (with 10 clusters) by a large margin. It is interesting to note that even the simple ODT-ml algorithm outperforms the well-known ODT-greedy algorithm. Table 2 depicts two sets of results using the ML-100 dataset. The left panel shows the expected cost for the generalized ODT problem with a uniform distribution over scenarios and different thresholds, ti, on the ML-100 dataset. The first threshold (ti = 1) is the standard setting. For the other two settings, tis are drawn uniformly at random from the interval indicated in Table. In the left-panel, when the threshold is larger, the expected cost decreases for all three algorithms. Note that although ODT-greedy, which is the best known practical algorithm for ODT, performs the best, ODT-adsub is extremely competitive. Combined with the fact that ODT-greedy performs poorly on worst-case instances (Table 1), we think ODT-adsub is a good alternative in practice. The right panel shows the performance when ti = 1 and the scenarios are drawn from power-law distributions with \u03b1 = 2, 3. For each value of \u03b1, 3 random permutations are used to test the stability of the expected cost of each\nalgorithm. From this panel, we can conclude that the performance of ODT-adsub is comparable to that of ODT-greedy for ML-100 dataset when the scenarios are distributed as power law, with ODT-ml placing a distant third. In practive, we could \u2014 as we have all the data \u2014 fit a custom distribution for the scenarios to get the lowest expected cost."}, {"heading": "5.2 Adaptive Multiple Intent Ranking", "text": "Algorithms. As for ODT, solving the MIR problem involves carefully choosing an element at each step. In our experiments, we compare and contrast the results of 4 algorithms that use different methods to chose elements: (a) MIR-adsub, which is described in (3), (b) MIR-static, which statically ranks the elements using [4] and choses elements in rank order, (c) MIR-adstatic, which improves on MIR-static by using feedback to eliminate elements from the static list if they belong to invalid scenarios, and (d) MIR-ml, a \u201cmachine learning\u201d algorithm that uses the multiplicative scheme described in Section 5.1.\nResults. The results of running MIR-adsub, MIR-static, MIR-adstatic, and MIR-ml on the ML-100 dataset are given in the two tables in Table 3. The table in the left-panel shows the expected cost when the scenarios are drawn from a uniform distribution and the satisfaction thresholds, Kis, are varied, with Ki = |Si| being the classic setting. As expected, when Ki is relaxed, the expected cost decreases for all algorithms. MIR-adsub consistently performs better than all other algorithms in this setting, with MIR-adstatic being a close second. The performance of MIR-static, which is significantly worse than its counterparts demonstrates the importance of adaptive algorithms. The table in right panel shows the performance when Ki = |Si| and the scenarios are drawn from power-law distributions with \u03b1 = 2, 3. For each \u03b1, three random permutations are used to test\nthe stability of the expected cost of each algorithm. The instability of the expected cost across permutations of the user distributions is indicative of the inherent skew in the dataset. Still, MIR-adsub consistently outperforms the other three algorithms.\nAcknowledgement: We thank Lisa Hellerstein for a clarification on [15] regarding the OR construction of submodular functions."}], "references": [{"title": "Approximating optimal binary decision trees", "author": ["M. Adler", "B. Heeringa"], "venue": "Algorithmica, 62(3-4):1112\u20131121", "citeRegEx": "1", "shortCiteRegEx": null, "year": 2012}, {"title": "k-means++: The advantages of careful seeding", "author": ["D. Arthur", "S. Vassilvitskii"], "venue": "SODA, pages 1027\u20131035. Society for Industrial and Applied Mathematics", "citeRegEx": "2", "shortCiteRegEx": null, "year": 2007}, {"title": "Ranking with submodular valuations", "author": ["Y. Azar", "I. Gamzu"], "venue": "SODA, pages 1070\u20131079", "citeRegEx": "3", "shortCiteRegEx": null, "year": 2011}, {"title": "Multiple intents re-ranking", "author": ["Y. Azar", "I. Gamzu", "X. Yin"], "venue": "STOC, pages 669\u2013678", "citeRegEx": "4", "shortCiteRegEx": null, "year": 2009}, {"title": "A constant factor approximation algorithm for generalized min-sum set cover", "author": ["N. Bansal", "A. Gupta", "R. Krishnaswamy"], "venue": "SODA, pages 1539\u20131545", "citeRegEx": "5", "shortCiteRegEx": null, "year": 2010}, {"title": "When LP is the cure for your matching woes: Improved bounds for stochastic matchings", "author": ["N. Bansal", "A. Gupta", "J. Li", "J. Mestre", "V. Nagarajan", "A. Rudra"], "venue": "Algorithmica, 63(4):733\u2013762", "citeRegEx": "6", "shortCiteRegEx": null, "year": 2012}, {"title": "Group-based active query selection for rapid diagnosis in time-critical situations", "author": ["G. Bellala", "S.K. Bhavnani", "C. Scott"], "venue": "IEEE Trans. Information Theory, 58(1):459\u2013478", "citeRegEx": "7", "shortCiteRegEx": null, "year": 2012}, {"title": "Decision trees for entity identification: Approximation algorithms and hardness results", "author": ["V.T. Chakaravarthy", "V. Pandit", "S. Roy", "P. Awasthi", "M.K. Mohania"], "venue": "ACM Transactions on Algorithms, 7(2):15", "citeRegEx": "8", "shortCiteRegEx": null, "year": 2011}, {"title": "Diagnosis determination: decision trees optimizing simultaneously worst and expected testing cost", "author": ["F. Cicalese", "E.S. Laber", "A.M. Saettler"], "venue": "ICML, pages 414\u2013422", "citeRegEx": "9", "shortCiteRegEx": null, "year": 2014}, {"title": "Analysis of a greedy active learning strategy", "author": ["S. Dasgupta"], "venue": "NIPS", "citeRegEx": "10", "shortCiteRegEx": null, "year": 2004}, {"title": "Approximating the stochastic knapsack problem: The benefit of adaptivity", "author": ["B.C. Dean", "M.X. Goemans", "J. Vondr\u00e1k"], "venue": "Math. Oper. Res., 33(4):945\u2013964", "citeRegEx": "11", "shortCiteRegEx": null, "year": 2008}, {"title": "A threshold of ln n for approximating set cover", "author": ["U. Feige"], "venue": "Journal of the ACM, 45(4):634\u2013652", "citeRegEx": "12", "shortCiteRegEx": null, "year": 1998}, {"title": "Adaptive submodularity: Theory and applications in active learning and stochastic optimization", "author": ["D. Golovin", "A. Krause"], "venue": "J. Artif. Intell. Res. (JAIR), 42:427\u2013486", "citeRegEx": "13", "shortCiteRegEx": null, "year": 2011}, {"title": "Near-optimal bayesian active learning with noisy observations", "author": ["D. Golovin", "A. Krause", "D. Ray"], "venue": "NIPS, pages 766\u2013774", "citeRegEx": "14", "shortCiteRegEx": null, "year": 2010}, {"title": "Scenario submodular cover", "author": ["N. Grammel", "L. Hellerstein", "D. Kletenik", "P. Lin"], "venue": "CoRR, abs/1603.03158", "citeRegEx": "15", "shortCiteRegEx": null, "year": 2016}, {"title": "Average-Case Active Learning with Costs", "author": ["A. Guillory", "J. Bilmes"], "venue": "Algorithmic Learning Theory, pages 141\u2013155. Springer Berlin / Heidelberg", "citeRegEx": "16", "shortCiteRegEx": null, "year": 2009}, {"title": "Simultaneous learning and covering with adversarial noise", "author": ["A. Guillory", "J. Bilmes"], "venue": "Proceedings of the 28th International Conference on Machine Learning (ICML-11), pages 369\u2013376", "citeRegEx": "17", "shortCiteRegEx": null, "year": 2011}, {"title": "Approximation algorithms for optimal decision trees and adaptive tsp problems", "author": ["A. Gupta", "V. Nagarajan", "R. Ravi"], "venue": "ICALP (1), pages 690\u2013701", "citeRegEx": "18", "shortCiteRegEx": null, "year": 2010}, {"title": "The movielens datasets: History and context", "author": ["F.M. Harper", "J.A. Konstan"], "venue": "ACM Transactions on Interactive Intelligent Systems (TiiS), 5(4):19", "citeRegEx": "19", "shortCiteRegEx": null, "year": 2015}, {"title": "Constructing optimal binary decision trees is NP -complete", "author": ["L. Hyafil", "R.L. Rivest"], "venue": "Information Processing Lett.,", "citeRegEx": "20", "shortCiteRegEx": "20", "year": 1976}, {"title": "and R", "author": ["S. Im", "V. Nagarajan"], "venue": "van der Zwaan. Minimum latency submodular cover. ICALP, pages 485\u2013497", "citeRegEx": "21", "shortCiteRegEx": null, "year": 2012}, {"title": "Near optimal bayesian active learning for decision making", "author": ["Sh. Javdani", "Y. Chen", "A. Karbasi", "A. Krause", "D. Bagnell", "S.S. Srinivasa"], "venue": "In AISTATS,", "citeRegEx": "22", "shortCiteRegEx": "22", "year": 2014}, {"title": "On an Optimal Split Tree Problem", "author": ["S.R. Kosaraju", "T.M. Przytycka", "R.S. Borgstrom"], "venue": "Proceedings of the 6th International Workshop on Algorithms and Data Structures, pages 157\u2013168", "citeRegEx": "23", "shortCiteRegEx": null, "year": 1999}, {"title": "Combinatorial optimization: polyhedra and efficiency", "author": ["A. Schrijver"], "venue": "Springer-Verlag, Berlin", "citeRegEx": "24", "shortCiteRegEx": null, "year": 2003}, {"title": "A note on the generalized min-sum set cover problem", "author": ["M. Skutella", "D.P. Williamson"], "venue": "Oper. Res. Lett., 39(6):433\u2013436", "citeRegEx": "25", "shortCiteRegEx": null, "year": 2011}, {"title": "An analysis of the greedy algorithm for the submodular set covering problem", "author": ["L.A. Wolsey"], "venue": "Combinatorica, 2(4):385\u2013393", "citeRegEx": "26", "shortCiteRegEx": null, "year": 1982}], "referenceMentions": [{"referenceID": 23, "context": "Submodular functions are a very general class of set-functions that have certain convexity as well as concavity properties [24].", "startOffset": 123, "endOffset": 127}, {"referenceID": 19, "context": "In this paper, we study an adaptive optimization problem in the setting described above which simultaneously generalizes many previously-studied problems such as optimal decision trees [20, 23, 10, 8, 18, 9], equivalence class determination [14, 7], decision region determination [22] and submodular ranking [3, 21].", "startOffset": 185, "endOffset": 207}, {"referenceID": 22, "context": "In this paper, we study an adaptive optimization problem in the setting described above which simultaneously generalizes many previously-studied problems such as optimal decision trees [20, 23, 10, 8, 18, 9], equivalence class determination [14, 7], decision region determination [22] and submodular ranking [3, 21].", "startOffset": 185, "endOffset": 207}, {"referenceID": 9, "context": "In this paper, we study an adaptive optimization problem in the setting described above which simultaneously generalizes many previously-studied problems such as optimal decision trees [20, 23, 10, 8, 18, 9], equivalence class determination [14, 7], decision region determination [22] and submodular ranking [3, 21].", "startOffset": 185, "endOffset": 207}, {"referenceID": 7, "context": "In this paper, we study an adaptive optimization problem in the setting described above which simultaneously generalizes many previously-studied problems such as optimal decision trees [20, 23, 10, 8, 18, 9], equivalence class determination [14, 7], decision region determination [22] and submodular ranking [3, 21].", "startOffset": 185, "endOffset": 207}, {"referenceID": 17, "context": "In this paper, we study an adaptive optimization problem in the setting described above which simultaneously generalizes many previously-studied problems such as optimal decision trees [20, 23, 10, 8, 18, 9], equivalence class determination [14, 7], decision region determination [22] and submodular ranking [3, 21].", "startOffset": 185, "endOffset": 207}, {"referenceID": 8, "context": "In this paper, we study an adaptive optimization problem in the setting described above which simultaneously generalizes many previously-studied problems such as optimal decision trees [20, 23, 10, 8, 18, 9], equivalence class determination [14, 7], decision region determination [22] and submodular ranking [3, 21].", "startOffset": 185, "endOffset": 207}, {"referenceID": 13, "context": "In this paper, we study an adaptive optimization problem in the setting described above which simultaneously generalizes many previously-studied problems such as optimal decision trees [20, 23, 10, 8, 18, 9], equivalence class determination [14, 7], decision region determination [22] and submodular ranking [3, 21].", "startOffset": 241, "endOffset": 248}, {"referenceID": 6, "context": "In this paper, we study an adaptive optimization problem in the setting described above which simultaneously generalizes many previously-studied problems such as optimal decision trees [20, 23, 10, 8, 18, 9], equivalence class determination [14, 7], decision region determination [22] and submodular ranking [3, 21].", "startOffset": 241, "endOffset": 248}, {"referenceID": 21, "context": "In this paper, we study an adaptive optimization problem in the setting described above which simultaneously generalizes many previously-studied problems such as optimal decision trees [20, 23, 10, 8, 18, 9], equivalence class determination [14, 7], decision region determination [22] and submodular ranking [3, 21].", "startOffset": 280, "endOffset": 284}, {"referenceID": 2, "context": "In this paper, we study an adaptive optimization problem in the setting described above which simultaneously generalizes many previously-studied problems such as optimal decision trees [20, 23, 10, 8, 18, 9], equivalence class determination [14, 7], decision region determination [22] and submodular ranking [3, 21].", "startOffset": 308, "endOffset": 315}, {"referenceID": 20, "context": "In this paper, we study an adaptive optimization problem in the setting described above which simultaneously generalizes many previously-studied problems such as optimal decision trees [20, 23, 10, 8, 18, 9], equivalence class determination [14, 7], decision region determination [22] and submodular ranking [3, 21].", "startOffset": 308, "endOffset": 315}, {"referenceID": 3, "context": "This is an adaptive version of the search ranking problem studied in [4, 5, 25].", "startOffset": 69, "endOffset": 79}, {"referenceID": 4, "context": "This is an adaptive version of the search ranking problem studied in [4, 5, 25].", "startOffset": 69, "endOffset": 79}, {"referenceID": 24, "context": "This is an adaptive version of the search ranking problem studied in [4, 5, 25].", "startOffset": 69, "endOffset": 79}, {"referenceID": 10, "context": "[11, 6].", "startOffset": 0, "endOffset": 7}, {"referenceID": 5, "context": "[11, 6].", "startOffset": 0, "endOffset": 7}, {"referenceID": 23, "context": "See [24] for background.", "startOffset": 4, "endOffset": 8}, {"referenceID": 0, "context": "Each scenario i \u2208 [m] := {1, \u00b7 \u00b7 \u00b7 ,m} is specified by an interest-set Si \u2286 U and a normalized monotone submodular function fi : 2Si \u2192 [0, 1] where fi(\u2205) = 0 and fi(Si) = 1 (every monotone submodular function on Si can be expressed in this form by scaling and truncation).", "startOffset": 135, "endOffset": 141}, {"referenceID": 0, "context": "For notational simplicity, we extend each function fi : 2 Si \u2192 [0, 1] to arbitrary subsets S \u2286 U by setting fi(S) = fi(S \u2229 Si).", "startOffset": 63, "endOffset": 69}, {"referenceID": 25, "context": "[26, 3, 21, 15].", "startOffset": 0, "endOffset": 15}, {"referenceID": 2, "context": "[26, 3, 21, 15].", "startOffset": 0, "endOffset": 15}, {"referenceID": 20, "context": "[26, 3, 21, 15].", "startOffset": 0, "endOffset": 15}, {"referenceID": 14, "context": "[26, 3, 21, 15].", "startOffset": 0, "endOffset": 15}, {"referenceID": 11, "context": "Assuming P 6= NP , this result is the best possible (up to constant factors) as the set cover problem [12] is a special case of ASR even when m = 1.", "startOffset": 102, "endOffset": 106}, {"referenceID": 19, "context": "Such a simple algorithm was previously unknown even in the special case of optimal decision tree (under arbitrary costs/probabilities), despite a large number of papers [20, 23, 10, 1, 8, 16, 18, 13, 9] on this topic.", "startOffset": 169, "endOffset": 202}, {"referenceID": 22, "context": "Such a simple algorithm was previously unknown even in the special case of optimal decision tree (under arbitrary costs/probabilities), despite a large number of papers [20, 23, 10, 1, 8, 16, 18, 13, 9] on this topic.", "startOffset": 169, "endOffset": 202}, {"referenceID": 9, "context": "Such a simple algorithm was previously unknown even in the special case of optimal decision tree (under arbitrary costs/probabilities), despite a large number of papers [20, 23, 10, 1, 8, 16, 18, 13, 9] on this topic.", "startOffset": 169, "endOffset": 202}, {"referenceID": 0, "context": "Such a simple algorithm was previously unknown even in the special case of optimal decision tree (under arbitrary costs/probabilities), despite a large number of papers [20, 23, 10, 1, 8, 16, 18, 13, 9] on this topic.", "startOffset": 169, "endOffset": 202}, {"referenceID": 7, "context": "Such a simple algorithm was previously unknown even in the special case of optimal decision tree (under arbitrary costs/probabilities), despite a large number of papers [20, 23, 10, 1, 8, 16, 18, 13, 9] on this topic.", "startOffset": 169, "endOffset": 202}, {"referenceID": 15, "context": "Such a simple algorithm was previously unknown even in the special case of optimal decision tree (under arbitrary costs/probabilities), despite a large number of papers [20, 23, 10, 1, 8, 16, 18, 13, 9] on this topic.", "startOffset": 169, "endOffset": 202}, {"referenceID": 17, "context": "Such a simple algorithm was previously unknown even in the special case of optimal decision tree (under arbitrary costs/probabilities), despite a large number of papers [20, 23, 10, 1, 8, 16, 18, 13, 9] on this topic.", "startOffset": 169, "endOffset": 202}, {"referenceID": 12, "context": "Such a simple algorithm was previously unknown even in the special case of optimal decision tree (under arbitrary costs/probabilities), despite a large number of papers [20, 23, 10, 1, 8, 16, 18, 13, 9] on this topic.", "startOffset": 169, "endOffset": 202}, {"referenceID": 8, "context": "Such a simple algorithm was previously unknown even in the special case of optimal decision tree (under arbitrary costs/probabilities), despite a large number of papers [20, 23, 10, 1, 8, 16, 18, 13, 9] on this topic.", "startOffset": 169, "endOffset": 202}, {"referenceID": 17, "context": "The first O(logm)-approximation algorithm for ODT was obtained in [18], and this result was extended to the equivalence class determination problem in [9].", "startOffset": 66, "endOffset": 70}, {"referenceID": 8, "context": "The first O(logm)-approximation algorithm for ODT was obtained in [18], and this result was extended to the equivalence class determination problem in [9].", "startOffset": 151, "endOffset": 154}, {"referenceID": 22, "context": "[23, 10, 1, 8, 16], based on a simple greedy \u201csplitting\u201d algorithm, had a logarithmic dependence on either costs or probabilities which (in the worst case) can be exponential in m.", "startOffset": 0, "endOffset": 18}, {"referenceID": 9, "context": "[23, 10, 1, 8, 16], based on a simple greedy \u201csplitting\u201d algorithm, had a logarithmic dependence on either costs or probabilities which (in the worst case) can be exponential in m.", "startOffset": 0, "endOffset": 18}, {"referenceID": 0, "context": "[23, 10, 1, 8, 16], based on a simple greedy \u201csplitting\u201d algorithm, had a logarithmic dependence on either costs or probabilities which (in the worst case) can be exponential in m.", "startOffset": 0, "endOffset": 18}, {"referenceID": 7, "context": "[23, 10, 1, 8, 16], based on a simple greedy \u201csplitting\u201d algorithm, had a logarithmic dependence on either costs or probabilities which (in the worst case) can be exponential in m.", "startOffset": 0, "endOffset": 18}, {"referenceID": 15, "context": "[23, 10, 1, 8, 16], based on a simple greedy \u201csplitting\u201d algorithm, had a logarithmic dependence on either costs or probabilities which (in the worst case) can be exponential in m.", "startOffset": 0, "endOffset": 18}, {"referenceID": 25, "context": "One line of work is on the submodular cover problem and its variants [26, 4, 3, 21].", "startOffset": 69, "endOffset": 83}, {"referenceID": 3, "context": "One line of work is on the submodular cover problem and its variants [26, 4, 3, 21].", "startOffset": 69, "endOffset": 83}, {"referenceID": 2, "context": "One line of work is on the submodular cover problem and its variants [26, 4, 3, 21].", "startOffset": 69, "endOffset": 83}, {"referenceID": 20, "context": "One line of work is on the submodular cover problem and its variants [26, 4, 3, 21].", "startOffset": 69, "endOffset": 83}, {"referenceID": 22, "context": "[23, 10, 18, 13, 9].", "startOffset": 0, "endOffset": 19}, {"referenceID": 9, "context": "[23, 10, 18, 13, 9].", "startOffset": 0, "endOffset": 19}, {"referenceID": 17, "context": "[23, 10, 18, 13, 9].", "startOffset": 0, "endOffset": 19}, {"referenceID": 12, "context": "[23, 10, 18, 13, 9].", "startOffset": 0, "endOffset": 19}, {"referenceID": 8, "context": "[23, 10, 18, 13, 9].", "startOffset": 0, "endOffset": 19}, {"referenceID": 20, "context": "In particular, we combine the time-based analysis for the deterministic submodular ranking problem in [21] with the phase-based analysis for optimal decision tree in [23, 18, 9].", "startOffset": 102, "endOffset": 106}, {"referenceID": 22, "context": "In particular, we combine the time-based analysis for the deterministic submodular ranking problem in [21] with the phase-based analysis for optimal decision tree in [23, 18, 9].", "startOffset": 166, "endOffset": 177}, {"referenceID": 17, "context": "In particular, we combine the time-based analysis for the deterministic submodular ranking problem in [21] with the phase-based analysis for optimal decision tree in [23, 18, 9].", "startOffset": 166, "endOffset": 177}, {"referenceID": 8, "context": "In particular, we combine the time-based analysis for the deterministic submodular ranking problem in [21] with the phase-based analysis for optimal decision tree in [23, 18, 9].", "startOffset": 166, "endOffset": 177}, {"referenceID": 20, "context": "We note that [21] also considers a stochastic variant of submodular ranking, but it is different from ASR because [21] assumes an independent distribution whereas we assume a correlated scenariobased distribution.", "startOffset": 13, "endOffset": 17}, {"referenceID": 20, "context": "We note that [21] also considers a stochastic variant of submodular ranking, but it is different from ASR because [21] assumes an independent distribution whereas we assume a correlated scenariobased distribution.", "startOffset": 114, "endOffset": 118}, {"referenceID": 20, "context": "In particular, unlike ASR, the stochastic submodular ranking problem in [21] does not capture the optimal decision tree problem and its variants.", "startOffset": 72, "endOffset": 76}, {"referenceID": 14, "context": "Recently, [15] also considered a scenario-based submodular cover problem.", "startOffset": 10, "endOffset": 14}, {"referenceID": 14, "context": "In this respect our setting is a generalization of [15], eg.", "startOffset": 51, "endOffset": 55}, {"referenceID": 2, "context": "ASR captures the submodular ranking problem [3] whereas [15] does not.", "startOffset": 44, "endOffset": 47}, {"referenceID": 14, "context": "ASR captures the submodular ranking problem [3] whereas [15] does not.", "startOffset": 56, "endOffset": 60}, {"referenceID": 14, "context": "On the other hand, [15] allows arbitrary feedback whereas ASR as defined only considers binary (yes/no) feedback.", "startOffset": 19, "endOffset": 23}, {"referenceID": 12, "context": "The notion of \u201cadaptive submodularity\u201d [13] has been very useful in obtaining algorithms for some previously-studied special cases [14, 7, 22] of ASR.", "startOffset": 39, "endOffset": 43}, {"referenceID": 13, "context": "The notion of \u201cadaptive submodularity\u201d [13] has been very useful in obtaining algorithms for some previously-studied special cases [14, 7, 22] of ASR.", "startOffset": 131, "endOffset": 142}, {"referenceID": 6, "context": "The notion of \u201cadaptive submodularity\u201d [13] has been very useful in obtaining algorithms for some previously-studied special cases [14, 7, 22] of ASR.", "startOffset": 131, "endOffset": 142}, {"referenceID": 21, "context": "The notion of \u201cadaptive submodularity\u201d [13] has been very useful in obtaining algorithms for some previously-studied special cases [14, 7, 22] of ASR.", "startOffset": 131, "endOffset": 142}, {"referenceID": 12, "context": "In particular, among other results [13] obtained an O(log 1/ + log 1/pmin)-approximation algorithm for ASR when fi = f for all scenarios i, the function f is adaptive-submodular (a stronger condition than submodular) and pmin = min m i=1 pi is the minimum probability.", "startOffset": 35, "endOffset": 39}, {"referenceID": 14, "context": "We note that [15] is also an improvement over [13] in points (ii) and (iii) above.", "startOffset": 13, "endOffset": 17}, {"referenceID": 12, "context": "We note that [15] is also an improvement over [13] in points (ii) and (iii) above.", "startOffset": 46, "endOffset": 50}, {"referenceID": 0, "context": "Recall that an instance of ASR consists of a ground set U of elements with costs {ce}e\u2208U , and m scenarios with an interest-set Si \u2286 U , submodular function fi : 2Si \u2192 [0, 1] and probability pi associated with each scenario i \u2208 [m].", "startOffset": 168, "endOffset": 174}, {"referenceID": 2, "context": "1 in [3] which relies on the definition of in (1).", "startOffset": 5, "endOffset": 8}, {"referenceID": 0, "context": "Each scenario i \u2208 [m] is also associated with a function fi defined over subsets of U \u00d7 \u0393; we again assume that fi is monotone submodular and takes values in [0, 1].", "startOffset": 158, "endOffset": 164}, {"referenceID": 2, "context": "Moreover, by observing that in (3) Le = \u2205 always, we obtain an O(log 1 )-approximation, which matches the best result known [3].", "startOffset": 124, "endOffset": 127}, {"referenceID": 17, "context": "This matches the best result known in [18], but their algorithm is more complicated than ours.", "startOffset": 38, "endOffset": 42}, {"referenceID": 8, "context": "This is equal to the best previous result [9], but again our algorithm is much simpler.", "startOffset": 42, "endOffset": 45}, {"referenceID": 16, "context": "In [17] it is shown that the \u201cOR of submodular functions\u201d is submodular.", "startOffset": 3, "endOffset": 7}, {"referenceID": 21, "context": "[22] obtained an O(min{r, d} \u00b7 ln 1 mini pi )-approximation algorithm for this problem, which was improved by [15] to O(min{r, d} \u00b7 logm); here d is the maximum size of a decision region.", "startOffset": 0, "endOffset": 4}, {"referenceID": 14, "context": "[22] obtained an O(min{r, d} \u00b7 ln 1 mini pi )-approximation algorithm for this problem, which was improved by [15] to O(min{r, d} \u00b7 logm); here d is the maximum size of a decision region.", "startOffset": 110, "endOffset": 114}, {"referenceID": 21, "context": "Our algorithm runs in time polynomial in m and r, unlike [22, 15] which required time exponential in r.", "startOffset": 57, "endOffset": 65}, {"referenceID": 14, "context": "Our algorithm runs in time polynomial in m and r, unlike [22, 15] which required time exponential in r.", "startOffset": 57, "endOffset": 65}, {"referenceID": 21, "context": "As in [22, 15], we can also obtain an O(d logm)-approximation with running time exponential in d.", "startOffset": 6, "endOffset": 14}, {"referenceID": 14, "context": "As in [22, 15], we can also obtain an O(d logm)-approximation with running time exponential in d.", "startOffset": 6, "endOffset": 14}, {"referenceID": 18, "context": "Datasets: The real-world dataset used in our experiments \u2014 called ML-100 \u2014 is the 100K example from the MovieLens [19] repository, which contains 100,000 ratings on a scale of [1,5] from 943 users", "startOffset": 114, "endOffset": 118}, {"referenceID": 0, "context": "Datasets: The real-world dataset used in our experiments \u2014 called ML-100 \u2014 is the 100K example from the MovieLens [19] repository, which contains 100,000 ratings on a scale of [1,5] from 943 users", "startOffset": 176, "endOffset": 181}, {"referenceID": 4, "context": "Datasets: The real-world dataset used in our experiments \u2014 called ML-100 \u2014 is the 100K example from the MovieLens [19] repository, which contains 100,000 ratings on a scale of [1,5] from 943 users", "startOffset": 176, "endOffset": 181}, {"referenceID": 22, "context": "For the ODT problem, we also use a synthetic dataset \u2014 SYN-K \u2014 that is parameterized by k; this is based on a hard instance for the greedy algorithm [23].", "startOffset": 149, "endOffset": 153}, {"referenceID": 22, "context": "In our experiments, we compare and contrast the results of 3 algorithms that use different objectives to choose elements: (a) ODT-adsub, which uses the objective described in (3), (b) ODT-greedy, which uses the classic greedy objective [23, 10, 1, 8, 16], and (c) ODT-ml, a \u201cmachine learning\u201d algorithm that operates as follows.", "startOffset": 236, "endOffset": 254}, {"referenceID": 9, "context": "In our experiments, we compare and contrast the results of 3 algorithms that use different objectives to choose elements: (a) ODT-adsub, which uses the objective described in (3), (b) ODT-greedy, which uses the classic greedy objective [23, 10, 1, 8, 16], and (c) ODT-ml, a \u201cmachine learning\u201d algorithm that operates as follows.", "startOffset": 236, "endOffset": 254}, {"referenceID": 0, "context": "In our experiments, we compare and contrast the results of 3 algorithms that use different objectives to choose elements: (a) ODT-adsub, which uses the objective described in (3), (b) ODT-greedy, which uses the classic greedy objective [23, 10, 1, 8, 16], and (c) ODT-ml, a \u201cmachine learning\u201d algorithm that operates as follows.", "startOffset": 236, "endOffset": 254}, {"referenceID": 7, "context": "In our experiments, we compare and contrast the results of 3 algorithms that use different objectives to choose elements: (a) ODT-adsub, which uses the objective described in (3), (b) ODT-greedy, which uses the classic greedy objective [23, 10, 1, 8, 16], and (c) ODT-ml, a \u201cmachine learning\u201d algorithm that operates as follows.", "startOffset": 236, "endOffset": 254}, {"referenceID": 15, "context": "In our experiments, we compare and contrast the results of 3 algorithms that use different objectives to choose elements: (a) ODT-adsub, which uses the objective described in (3), (b) ODT-greedy, which uses the classic greedy objective [23, 10, 1, 8, 16], and (c) ODT-ml, a \u201cmachine learning\u201d algorithm that operates as follows.", "startOffset": 236, "endOffset": 254}, {"referenceID": 1, "context": "ODT-ml, which is parameterized by K uses k-Means [2] to a priori partition U into K clusters.", "startOffset": 49, "endOffset": 52}, {"referenceID": 3, "context": "In our experiments, we compare and contrast the results of 4 algorithms that use different methods to chose elements: (a) MIR-adsub, which is described in (3), (b) MIR-static, which statically ranks the elements using [4] and choses elements in rank order, (c) MIR-adstatic, which improves on MIR-static by using feedback to eliminate elements from the static list if they belong to invalid scenarios, and (d) MIR-ml, a \u201cmachine learning\u201d algorithm that uses the multiplicative scheme described in Section 5.", "startOffset": 218, "endOffset": 221}, {"referenceID": 14, "context": "Acknowledgement: We thank Lisa Hellerstein for a clarification on [15] regarding the OR construction of submodular functions.", "startOffset": 66, "endOffset": 70}], "year": 2016, "abstractText": "We study a general adaptive ranking problem where an algorithm needs to perform a sequence of actions on a random user, drawn from a known distribution, so as to \u201csatisfy\u201d the user as early as possible. The satisfaction of each user is captured by an individual submodular function, where the user is said to be satisfied when the function value goes above some threshold. We obtain a logarithmic factor approximation algorithm for this adaptive ranking problem, which is the best possible. The adaptive ranking problem has many applications in active learning and ranking: it significantly generalizes previously-studied problems such as optimal decision trees, equivalence class determination, decision region determination and submodular cover. We also present some preliminary experimental results based on our algorithm.", "creator": "LaTeX with hyperref package"}}}