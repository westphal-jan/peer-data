{"id": "1606.02820", "review": {"conference": "EMNLP", "VERSION": "v1", "DATE_OF_SUBMISSION": "9-Jun-2016", "title": "Inducing Domain-Specific Sentiment Lexicons from Unlabeled Corpora", "abstract": "organizing a reference word'to s emotional sentiment depends on at the base domain in which it is used. computational social science research thus requires sentiment lexicons that statements are most specific to particular the domains being studied. we further combine numerous domain - like specific functional word morphology embeddings with a proprietary label propagation enhancement framework able to induce politically accurate domain - depth specific sentiment lexicons using varying small sets of seed specific words. naturally we show this that our relational approach itself achieves state - of - the - science art performance on broadly inducing sentiment lexicons from domain - specific corpora data and that our purely corpus - comparison based concept approach outperforms methods that basically rely on applying hand - curated emotional resources ( much e. within g., source wordnet ). collectively using our framework, globally we induce and consequently release historical sentiment lexicons for 150 growing years south of english popularity and community - specific sentiment lexicons for several 250 native online communities including from the social use media trend forum reddit. the google historical preservation lexicons we extensively induce show only that more than 5 % readings of sentiment - bearing ( non - color neutral ) english genre words completely switched polarity during around the decades last or 150 years, and unfortunately the community - specific lexicons themselves highlight how sentiment representation varies very drastically between four different different communities.", "histories": [["v1", "Thu, 9 Jun 2016 04:28:10 GMT  (1007kb,D)", "http://arxiv.org/abs/1606.02820v1", "10 pages, 5 figures"], ["v2", "Sat, 24 Sep 2016 03:12:09 GMT  (1034kb,D)", "http://arxiv.org/abs/1606.02820v2", "11 pages, 5 figures, EMNLP 2016"]], "COMMENTS": "10 pages, 5 figures", "reviews": [], "SUBJECTS": "cs.CL", "authors": ["william l hamilton", "kevin clark", "jure leskovec", "dan jurafsky"], "accepted": true, "id": "1606.02820"}, "pdf": {"name": "1606.02820.pdf", "metadata": {"source": "CRF", "title": "Inducing Domain-Specific Sentiment Lexicons from Unlabeled Corpora", "authors": ["William L. Hamilton", "Kevin Clark", "Jure Leskovec", "Dan Jurafsky"], "emails": ["wleif@stanford.edu", "jure@stanford.edu", "kevclark@stanford.edu", "jurafsky@stanford.edu"], "sections": [{"heading": "1 Introduction", "text": "The sentiment of the word soft varies drastically between an online community dedicated to sports and one dedicated to toy animals (Figure 1). Terrific once had a highly negative connotation; now it is essentially synonomous with good (Figure 2).\nInducing domain-specific sentiment lexicons is crucial to computational social science (CSS) research. Sentiment lexicons allow researchers to an-\nalyze key subjective properties of texts, such as user opinions and emotional attitudes (Taboada et al., 2011). However, without domain-specific lexicons, analyses can be misled by sentiment assignments that are biased towards domain-general contexts and that fail to take into account community-specific vernacular or demographic variations in language use (Hovy, 2015; Yang and Eisenstein, 2015).\nExperts or crowdsourced annotators can be used to construct sentiment lexicons for a specific domain, but these efforts are expensive and timeconsuming (Mohammad and Turney, 2010; Fast et al., 2016). Crowdsourcing is especially problematic when the domain involves very non-standard language (e.g., historical documents or obscure social media forums), since in these cases annotators must understand the sociolinguistic context of the data.\nRecent work has shown that web-scale sentiment lexicons can be automatically induced for large socially-diffuse domains, such as the internet-atlarge (Velikovich et al., 2010) or all of Twitter (Tang\nar X\niv :1\n60 6.\n02 82\n0v 1\n[ cs\n.C L\n] 9\nJ un\n2 01\net al., 2014). However, in cases where researchers want to analyze the sentiment of domain-specific language\u2014such as in financial documents, historical texts, or tight-knit social media forums\u2014it is not enough to simply use generic crowdsourced or webscale lexicons. Generic lexicons will not only be inaccurate in specific domains, they may mislead research by introducing harmful biases (Loughran and McDonald, 2011)1. Researchers need a principled and accurate framework for inducing lexicons that are specific to their domain of study.\nTo meet this need, we introduce SENTPROP, a framework to learn accurate sentiment lexicons from small sets of seed words and domain-specific corpora. Unlike previous approaches, SENTPROP is designed to maintain accurate performance when using modestly-sized domain-specific corpora (\u223c107 tokens), and it provides confidence scores along with the learned lexicons, which allows researchers to quantify uncertainty in a principled manner.\nThe key contributions of this work are:\n1. A state-of-the-art sentiment induction algorithm, combining high-quality word vector embeddings with an intuitive label propagation approach.\n2. A novel bootstrap-sampling framework for inferring confidence scores with the sentiment values.\n3. Two large-scale studies that reveal how sentiment depends on both social and historical context. (a) We induce community-specific sentiment lexicons for the largest 250 \u201csubreddit\u201d communities on the social-media forum Reddit, revealing substantial variation in word sentiment between communities. (b) We induce historical sentiment lexicons for 150 years of English, revealing that >5% of words switched polarity during this time.\nTo the best of our knowledge, this is the first work to systematically analyze the domain-dependency of sentiment at a large-scale, across hundreds of years and hundreds of user-defined online communities.\nAll of the inferred lexicons along with code for SENTPROP and all methods evaluated are made available in the SOCIALSENT package released with this paper.2\n1 http://brandsavant.com/brandsavant/\nthe-hidden-bias-of-social-media-sentiment-analysis 2http://nlp.stanford.edu/projects/socialsent"}, {"heading": "2 Related work", "text": "Our work builds upon a wealth of previous research on inducing sentiment lexicons, along two threads:\nCorpus-based approaches use seed words and patterns in unlabeled corpora to induce domainspecific lexicons. These patterns may rely on syntactic structures (Hatzivassiloglou and McKeown, 1997; Thelen and Riloff, 2002; Widdows and Dorow, 2002; Jijkoun et al., 2010; Rooth et al., 1999), which can be domain-specific and brittle (e.g., in social media lacking usual grammatical structures). Other models rely on general cooccurrence (Turney and Littman, 2003; Riloff and Shepherd, 1997; Igo and Riloff, 2009). Often corpus-based methods exploit distant-supervision signals (e.g., review scores, emoticons) specific to certain domains (Asghar et al., 2015; BlairGoldensohn et al., 2008; Bravo-Marquez et al., 2015; Choi and Cardie, 2009; Severyn and Moschitti, 2015; Speriosu et al., 2011; Tang et al., 2014). An effective corpus-based approach that does not require distant-supervision\u2014which we adapt here\u2014is to construct lexical graphs using word cooccurrences and then to perform some form of label propagation over these graphs (Huang et al., 2014; Velikovich et al., 2010). Recent work has also learned transformations of word-vector representations in order to induce sentiment lexicons (Rothe et al., 2016). Fast et al. (2016) combine word vectors with crowdsourcing to produce domain-general topic lexicons.\nDictionary-based approaches use hand-curated lexical resources\u2014usually WordNet (Fellbaum, 1998)\u2014in order to propagate sentiment from seed labels (Esuli and Sebastiani, 2006; Hu and Liu, 2004; Kamps et al., 2004; Rao and Ravichandran,\n2009; San Vicente et al., 2014; Takamura et al., 2005; Tai and Kao, 2013). There is an implicit consensus that dictionary-based approaches will generate higher-quality lexicons, due to their use of these clean, hand-curated resources; however, they are not applicable in domains lacking such a resource (e.g., most historical texts).\nMost previous work seeks to enrich or enlarge existing lexicons (San Vicente et al., 2014; Velikovich et al., 2010; Qiu et al., 2009), emphasizing recall over precision. This recall-oriented approach is motivated by the need for massive polarity lexicons in tasks like web-advertising (Velikovich et al., 2010). In contrast to these previous efforts, the goal of this work is to induce high-quality lexicons that are accurate to a specific social context.\nAlgorithmically, our approach is inspired by Velikovich et al. (2010). We extend this work by incorporating high-quality word vector embeddings, a new graph construction approach, an alternative label propagation algorithm, and a bootstrapping method to obtain confidences. Together these improvements, especially the high-quality word vectors, allow our corpus-based method to even outperform the state-of-the-art dictionary-based approach."}, {"heading": "3 Framework", "text": "Our framework, SENTPROP, is designed to meet four key desiderata: 1. Resource-light: Accurate performance without\nmassive corpora or hand-curated resources. 2. Interpretable: Uses small seed sets of\n\u201cparadigm\u201d words to maintain interpretability and avoid ambiguity in sentiment values. 3. Robust: Bootstrap-sampled standard deviations provide a measure of confidence. 4. Out-of-the-box: Does not rely on signals that are specific to only certain domains.\nSENTPROP involves two steps: constructing a lexical graph from unlabeled corpora and propagating sentiment labels over this graph."}, {"heading": "3.1 Constructing a lexical graph", "text": "Lexical graphs are constructed from distributional word embeddings learned on unlabeled corpora.\nDistributional word embeddings The first step in our approach is building highquality semantic representations for words using a vector space model (VSM). We embed each word wi \u2208 V as a vector wi that captures information about its co-occurrence statistics with other words (Landauer and Dumais, 1997; Turney and Pantel, 2010). This VSM approach has a long history in NLP and has been highly successful in recent applications (see Levy et al., 2015 for a survey).\nWhen recreating known lexicons, we used a number of publicly available embeddings (Section 4).\nIn the cases where we learned embeddings ourselves, we employed an SVD-based method to construct the word-vectors. First, we construct a matrix MPPMI \u2208 R|V|\u00d7|V| with entries given by\nMPPMIi,j = max\n{ log ( p\u0302(wi, wj)\np\u0302(w)p\u0302(wj)\n) , 0 } , (1)\nwhere p\u0302 denotes smoothed empirical probabilities of word (co-)occurrences within fixed-size sliding windows of text.3 MPPMIi,j is equal to a smoothed variant of the positive pointwise mutual information between words wi and wj (Levy et al., 2015). Next, we compute MPPMI = U\u03a3V>, the truncated singular value decomposition of MPPMI . The vector embedding for word wi is then given by\nwSVDi = (U)i . (2) 3We use contexts of size four on each side and context-\ndistribution smoothing with c = 0.75 (Levy et al., 2015).\nExcluding the singular value weights, \u03a3, has been shown known to dramatically improve embedding qualities (Turney and Pantel, 2010; Bullinaria and Levy, 2012). Following standard practices, we learn embeddings of dimension 300.\nWe found that this SVD method significantly outperformed word2vec (Mikolov et al., 2013) and GloVe (Pennington et al., 2014) on the domainspecific datasets we examined. Our results echo the findings of Levy et al. (2015) that the SVD approach performs best on rare word similarity tasks.\nDefining the graph edges Given a set of word embeddings, a weighted lexical graph is constructed by connecting each word with its nearest k neighbors within the semantic space (according to cosine-similarity). The weights of the edges are set as\nEi,j = arccos\n( \u2212 wi\n>wj \u2016wi\u2016\u2016wj\u2016\n) . (3)"}, {"heading": "3.2 Propagating polarities from a seed set", "text": "Once a weighted lexical graph is constructed, we propagate sentiment labels over this graph using a random walk method (Zhou et al., 2004). A word\u2019s polarity score for a seed set is proportional to the probability of a random walk from the seed set hitting that word.\nLet p \u2208 R|V| be a vector of word-sentiment scores constructed using seed set S (e.g., ten negative words); p is initialized to have 1|V| in all entries. And let E be the matrix of edge weights given by equation (3). First, we construct a symmetric transition matrix from E by computing T = D 1 2 ED 1 2 , where D is a matrix with the column sums of E on the diagonal. Next, using T we iteratively update p until numerical convergence:\np(t+1) = \u03b2Tp(t) + (1\u2212 \u03b2)s, (4)\nwhere s is a vector with values set to 1|S| in the entries corresponding to the seed set S and zeros elsewhere. The \u03b2 term controls the extent to which the algorithm favors local consistency (similar labels for neighbors) vs. global consistency (correct labels on seed words), with lower \u03b2s emphasizing the latter.\nTo obtain a final polarity score for a word wi, we run the walk using both positive and negative\nseed sets, obtaining positive (pP (wi)) and negative (pN (wi)) label scores. We then combine these values into a positive-polarity score as p\u0304P (wi) =\npP (wi) pP (wi)+pN (wi)\nand standardize the final scores to have zero mean and unit variance (within a corpus).\nMany variants of this random walk approach and related label propagation techniques exist in the literature (Zhou et al., 2004; Zhu and Ghahramani, 2002; Zhu et al., 2003; Velikovich et al., 2010; San Vicente et al., 2014). We experimented with a number of these approaches and found little difference between their performance, so we present only this random walk approach here. The SOCIALSENT package contains a full suite of these methods."}, {"heading": "3.3 Bootstrap-sampling for robustness", "text": "Propagated sentiment scores are inevitably influenced by the seed set, and it is important for researchers to know the extent to which polarity values are simply the result of corpus artifacts that are correlated with these seeds words. We address this issue by using a bootstrap-sampling approach to obtain confidence regions over our sentiment scores. We bootstrap by running our propagation over B random equally-sized subsets of the positive and negative seed sets. Computing the standard deviation of the bootstrap-sampled polarity scores provides a measure of confidence and allows the researcher to evaluate the robustness of the assigned polarities. We set B = 50 and used 7 words per random subset (full seed sets are size 10; see Table 1)."}, {"heading": "4 Recreating known lexicons", "text": "We validate our approach by recreating known sentiment lexicons in the three domains: Standard English, Twitter, and Finance. Table 1 lists the seed words used in each domain.\nStandard English: To facilitate comparison with previous work, we focus on the well-known General Inquirer lexicon (Stone et al., 1966). We also use the continuous valence (i.e., polarity) scores collected by Warriner et al. (2013) in order to evaluate the fine-grained performance of our framework. We test our framework\u2019s performance using two different embeddings: off-the-shelf Google news embeddings constructed from 1011 tokens4 and embeddings we\n4https://code.google.com/p/word2vec/\nconstructed from the 2000s decade of the Corpus of Historical American English (COHA), which contains \u223c2 \u00d7 107 words in each decade, from 1850 to 2000 (Davies, 2010). The COHA corpus allows us to test how the algorithms deal with this smaller historical corpus, which is important since we will use the COHA corpus to infer historical sentiment lexicons (Section 6).\nFinance: Previous work found that general purpose sentiment lexicons performed very poorly on financial text (Loughran and McDonald, 2011), so a finance-specific sentiment lexicon (containing binary labels) was hand-constructed for this domain (ibid.). To test against this lexicon, we constructed embeddings using a dataset of\u223c2\u00d7107 tokens from financial 8K documents (Lee et al., 2014).\nTwitter: Numerous works attempt to induce Twitter-specific sentiment lexicons using supervised approaches and features unique to that domain (e.g., follower graphs; Speriosu et al., 2011). Here, we emphasize that we can induce an accurate lexicon using a simple domain-independent and resourcelight approach, with the implication that lexicons can easily be induced for related social media domains without resorting to complex supervised frameworks. We evaluate our approach using the test set from the 2015 SemEval task 10E competition (Rosenthal et al., 2015), and we use the embeddings constructed by Rothe et al. (2016).5"}, {"heading": "4.1 Baselines and state-of-the-art comparisons", "text": "We compared SENTPROP against standard baselines and state-of-the-art approaches. The PMI baseline of Turney and Littman (2003) computes the pointwise mutual information between the seeds and the targets without using propagation. The CountVec baseline, corresponding to the method in Velikovich et al. (2010), is similar to our method but uses an alternative propagation approach and raw cooccurrence vectors instead of learned embeddings. Both these methods require raw corpora, so they function as baselines in cases where we do not use off-the-shelf embeddings. We also compare against DENSIFIER, a state-of-the-art method which learns orthogonal transformations of word vectors instead\n5The official SemEval task 10E involved fully-supervised learning, so we do not use their evaluation setup.\nof propagating labels (Rothe et al., 2016). Lastly, on standard English we compare against a state-of-theart WordNet-based method, which performs label propagation over a WordNet-derived graph (San Vicente et al., 2014). Several variant baselines, all of which SENTPROP outperforms, are omitted for brevity (e.g., using word-vector cosines in place of PMI in Turney and Littman (2003)\u2019s framework). Code for replicating all these variants is available in the SOCIALSENT package."}, {"heading": "4.2 Evaluation setup", "text": "We evaluate the approaches according to (i) their binary classification accuracy (ignoring the neutral class, as is common in previous work), (ii) ternary classification performance (positive vs. neutral vs. negative)6, and (iii) Kendall \u03c4 rank-correlation with continuous human-annotated polarity scores.\nFor all methods in the ternary-classification condition, we use the class-mass normalization method (Zhu et al., 2003) to label words as positive, neutral, or negative. This method assumes knowledge of the label distribution\u2014i.e., how many positive/negative vs. neutral words there are\u2014and simply assigns labels to best match this distribution."}, {"heading": "4.3 Evaluation results", "text": "Tables 2a-2d summarize the performance of our framework along with baselines and other state-ofthe-art approaches. Our framework significantly outperforms the baselines on all tasks, outperforms a state-of-the-art approach that uses WordNet on standard English (Table 2a), and is competitive with Sentiment140 on Twitter (Table 2b), a distantlysupervised approach that uses signals from emoticons (Mohammad and Turney, 2010). DENSIFIER also performs extremely well, outperforming SENTPROP when off-the-shelf embeddings are used (Tables 2a and 2b). However, SENTPROP significantly outperforms all other approaches when using the domain-specific embeddings (Tables 2c and 2d).\nOverall, SENTPROP is competitive with the stateof-the-art across all conditions and, unlike previous approaches, it is able to maintain high accuracy even when modestly-sized domain-specific cor-\n6Only GI contains words explicitly marked neutral, so for ternary evaluations in Twitter and Finance we sample neutral words from GI to match its neutral-vs-not distribution.\npora are used. We found that the baseline method of Velikovich et al. (2010), which our method is closely related to, performed very poorly with these domain-specific corpora. This indicates that using high-quality word-vector embeddings can have a drastic impact on performance. However, it is worth noting that Velikovich et al. (2010)\u2019s method was designed for high recall with massive corpora, so its poor performance in our regime is not surprising."}, {"heading": "5 Inducing community-specific lexicons", "text": "As a first large-scale study, we investigate how sentiment depends on the social context in which a word is used. It is well known that there is substantial sociolinguistic variation between different communities, whether these communities are defined geographically (Trudgill, 1974) or via underlying sociocultural differences (Labov, 2006). However, no previous work has systematically investigated community-specific variation in word sentiment at a large scale. Yang and Eisenstein (2015) exploit social network structures in Twitter to infer a small number (1-10) of communities and analyzed sentiment variation via a supervised framework. Our analysis extends this line of work by analyzing the sentiment across hundreds of user-defined commu-\nnities using only unlabeled corpora and a small set of \u201cparadigm\u201d seed words (the Twitter seed words outlined in Table 1).\nIn our study, we induced sentiment lexicons for the top-250 (by comment-count) subreddits from the social media forum Reddit.7 We used all the 2014 comment data to induce the lexicons, with words lower cased and comments from bots and deleted users removed.8 Sentiment was induced for the top5000 non-stop words in each subreddit (again, by comment-frequency)."}, {"heading": "5.1 Examining the lexicons", "text": "Analysis of the learned lexicons reveals the extent to which sentiment can differ across communities. Figure 3 highlights some words with opposing sentiment in two communities: in r/TwoXChromosomes (r/TwoX), a community dedicated to female perspectives and gender issues, the words crazy and insane have negative polarity, which is not true in the r/sports community, and, vice-versa, words like soft are positive in r/TwoX but negative in r/sports.\nTo get a sense of how much sentiment differs\n7Subreddits are user-created topic-specific forums. 8 https://archive.org/details/2015_reddit_comments_corpus\nacross communities in general, we selected a random subset of 1000 community pairs and examined the correlation in their sentiment values for highly sentiment-bearing words (Figure 4). We see that the distribution is noticeably skewed, with many community pairs having highly uncorrelated sentiment values. The 1000 random pairs were selected such that each member of the pair overlapped in at least half of their top-5000 word vocabulary. We then computed the correlation between the sentiments in these community-pairs. Since sentiment is noisy and relatively uninteresting for neutral words, we compute \u03c425%, the Kendall-\u03c4 correlation over the top25% most sentiment bearing words shared between the two communities.\nAnalysis of individual pairs reveals some interesting insights about sentiment and inter-community dynamics. For example, we found that the sentiment correlation between r/TwoX and r/TheRedPill\n(\u03c425% = 0.58), two communities that hold conflicting views and often attack each other9, was actually higher than the sentiment correlation between r/TwoX and r/sports (\u03c425% = 0.41), two communities that are entirely unrelated. This result suggests that conflicting communities may have more similar sentiment in their language compared to communities that are entirely unrelated."}, {"heading": "6 Inducing diachronic sentiment lexicons", "text": "Sentiment also depends on the historical time-period in which a word is used. To investigate this dependency, we use our framework to analyze how word polarities have shifted over the last 150 years. The phenomena of amelioration (words becoming more positive) and pejoration (words becoming more negative) are well-discussed in the linguistic literature (Traugott and Dasher, 2001); however, no comprehensive polarity lexicons exist for historical data (Cook and Stevenson, 2010). Such lexicons are crucial to the growing body of work on NLP analyses of historical text (Piotrowski, 2012) which are informing diachronic linguistics (Hamilton et al., 2016), the digital humanities (Muralidharan and Hearst, 2012), and history (Hendrickx et al., 2011).\nThe only previous work on automatically inducing historical sentiment lexicons is Cook and Stevenson (2010); they use the PMI method and\n9This conflict is well-known on Reddit; for example, both communities mention each others\u2019 names along with fuck-based profanity in the same comment far more than one would expect by chance (\u03c721 > 6.8, p < 0.01 for both). r/TheRedPill is dedicated to male empowerment.\na full modern sentiment lexicon as their seed set, which problematically assumes that all these words have not changed in sentiment. In contrast, we use a small seed set of words that were manually selected based upon having strong and stable sentiment over the last 150 years (Table 1; confirmed via historical entries in the Oxford English Dictionary)."}, {"heading": "6.1 Examining the lexicons", "text": "We constructed lexicons from COHA, since it was carefully constructed to be genre balanced (e.g., compared to the Google N-Grams; Pechenick et al., 2015). We built lexicons for all adjectives with counts above 100 in a given decade and also for the top-5000 non-stop words within each year. In both these cases we found that>5% of sentiment-bearing (positive/negative) words completely switched polarity during this 150-year time-period and >25% of all words changed their sentiment label (including switches to/from neutral).10 The prevalence of full polarity switches highlights the importance of historical sentiment lexicons for work on diachronic linguistics and cultural change.\nFigure 5a shows an example amelioration detected by this method: the word lean lost its negative connotations associated with \u201cweakness\u201d and instead became positively associated with concepts like \u201cmuscularity\u201d and \u201cfitness\u201d. Figure 5b shows an example pejoration, where pathetic, which used to be more synonymous with passionate, gained stronger negative associations with the concepts of \u201cweakness\u201d and \u201cinadequacy\u201d (Simpson et al., 1989). In both these cases, semantic similarities\n10We defined the thresholds for polar vs. neutral using the class-mass normalization method and compared scores averaged over 1850-1880 to those averaged over 1970-2000.\ncomputed using our learned historical word vectors were used to contextualize the shifts.\nSome other well-known examples of sentiment changes captured by our framework include the semantic bleaching of sorry, which shifted from negative and serious (\u201che was in a sorry state\u201d) to uses as a neutral discourse marker (\u201csorry about that\u201d) and worldly, which used to have negative connotations related to materialism and religious impurity (\u201csinful worldly pursuits\u201d) but now is frequently used to indicate sophistication (\u201ca cultured, worldly woman\u201d) (Simpson et al., 1989). Our hope is that the full lexicons released with this work will spur further examinations of such historical shifts in sentiment, while also facilitating CSS applications that require sentiment ratings for historical text."}, {"heading": "7 Conclusion", "text": "SENTPROP allows researchers to easily induce robust and accurate sentiment lexicons that are relevant to their particular domain of study. Such lexicons are crucial to CSS research, as evidenced by our two studies showing that sentiment depends strongly on both social and historical context.\nThe sentiment lexicons induced by SENTPROP are not perfect, which is reflected in the uncertainty associated with our bootstrap-sampled estimates. However, we believe that these user-constructed, domain-specific lexicons, which quantify uncertainty, provide a more principled foundation for CSS research compared to domain-general sentiment lexicons that contain unknown biases. In the future our method could also be integrated with supervised domain-adaption (e.g.,Yang and Eisenstein, 2015) to further improve these domain-specific results."}, {"heading": "Acknowledgements", "text": "The authors thank P. Liang for his helpful comments. This research has been supported in part by NSF CNS-1010921, IIS-1149837, IIS-1514268 NIH BD2K, ARO MURI, DARPA XDATA, DARPA SIMPLEX, Stanford Data Science Initiative, SAP Stanford Graduate Fellowship, NSERC PGS-D, Boeing, Lightspeed, SAP, and Volkswagen."}], "references": [{"title": "A Unified Framework for Creating Domain Dependent Polarity Lexicons from User Generated Reviews", "author": ["Muhammad Zubair Asghar", "Aurangzeb Khan", "Shakeel Ahmad", "Imran Ali Khan", "Fazal Masud Kundi."], "venue": "PLOS ONE, 10(10):e0140204, October.", "citeRegEx": "Asghar et al\\.,? 2015", "shortCiteRegEx": "Asghar et al\\.", "year": 2015}, {"title": "Building a sentiment summarizer for local service reviews", "author": ["Sasha Blair-Goldensohn", "Kerry Hannan", "Ryan McDonald", "Tyler Neylon", "George A. Reis", "Jeff Reynar."], "venue": "WWW Workshop on NLP in the Information Explosion Era.", "citeRegEx": "Blair.Goldensohn et al\\.,? 2008", "shortCiteRegEx": "Blair.Goldensohn et al\\.", "year": 2008}, {"title": "From Unlabelled Tweets to Twitterspecific Opinion Words", "author": ["Felipe Bravo-Marquez", "Eibe Frank", "Bernhard Pfahringer."], "venue": "SIGIR.", "citeRegEx": "Bravo.Marquez et al\\.,? 2015", "shortCiteRegEx": "Bravo.Marquez et al\\.", "year": 2015}, {"title": "Extracting semantic representations from word co-occurrence statistics: stop-lists, stemming, and SVD", "author": ["John A. Bullinaria", "Joseph P. Levy."], "venue": "Behavior Research Methods, 44(3):890\u2013907, September.", "citeRegEx": "Bullinaria and Levy.,? 2012", "shortCiteRegEx": "Bullinaria and Levy.", "year": 2012}, {"title": "Adapting a polarity lexicon using integer linear programming for domainspecific sentiment classification", "author": ["Yejin Choi", "Claire Cardie."], "venue": "EMNLP.", "citeRegEx": "Choi and Cardie.,? 2009", "shortCiteRegEx": "Choi and Cardie.", "year": 2009}, {"title": "Automatically Identifying Changes in the Semantic Orientation of Words", "author": ["Paul Cook", "Suzanne Stevenson."], "venue": "LREC.", "citeRegEx": "Cook and Stevenson.,? 2010", "shortCiteRegEx": "Cook and Stevenson.", "year": 2010}, {"title": "The Corpus of Historical American English: 400 million words, 1810-2009", "author": ["Mark Davies"], "venue": null, "citeRegEx": "Davies.,? \\Q2010\\E", "shortCiteRegEx": "Davies.", "year": 2010}, {"title": "Sentiwordnet: A publicly available lexical resource for opinion mining", "author": ["Andrea Esuli", "Fabrizio Sebastiani."], "venue": "LREC. Citeseer.", "citeRegEx": "Esuli and Sebastiani.,? 2006", "shortCiteRegEx": "Esuli and Sebastiani.", "year": 2006}, {"title": "Empath: Understanding Topic Signals in LargeScale Text", "author": ["Ethan Fast", "Binbin Chen", "Michael S. Bernstein."], "venue": "CHI.", "citeRegEx": "Fast et al\\.,? 2016", "shortCiteRegEx": "Fast et al\\.", "year": 2016}, {"title": "WordNet", "author": ["Christiane Fellbaum."], "venue": "Wiley Online Library.", "citeRegEx": "Fellbaum.,? 1998", "shortCiteRegEx": "Fellbaum.", "year": 1998}, {"title": "Diachronic Word Embeddings Reveal Statistical Laws of Semantic Change", "author": ["William L. Hamilton", "Jure Leskovec", "Dan Jurafsky."], "venue": "ACL. arXiv:1605.09096.", "citeRegEx": "Hamilton et al\\.,? 2016", "shortCiteRegEx": "Hamilton et al\\.", "year": 2016}, {"title": "Predicting the semantic orientation of adjectives", "author": ["Vasileios Hatzivassiloglou", "Kathleen R. McKeown."], "venue": "EACL.", "citeRegEx": "Hatzivassiloglou and McKeown.,? 1997", "shortCiteRegEx": "Hatzivassiloglou and McKeown.", "year": 1997}, {"title": "Automatic pragmatic text segmentation of historical letters", "author": ["Iris Hendrickx", "Michel Gnreux", "Rita Marquilhas."], "venue": "Language Technology for Cultural Heritage, pages 135\u2013153. Springer.", "citeRegEx": "Hendrickx et al\\.,? 2011", "shortCiteRegEx": "Hendrickx et al\\.", "year": 2011}, {"title": "Demographic factors improve classification performance", "author": ["Dirk Hovy."], "venue": "ACL.", "citeRegEx": "Hovy.,? 2015", "shortCiteRegEx": "Hovy.", "year": 2015}, {"title": "Mining and summarizing customer reviews", "author": ["Minqing Hu", "Bing Liu."], "venue": "KDD. ACM.", "citeRegEx": "Hu and Liu.,? 2004", "shortCiteRegEx": "Hu and Liu.", "year": 2004}, {"title": "Automatic construction of domain-specific sentiment lexicon based on constrained label propagation", "author": ["Sheng Huang", "Zhendong Niu", "Chongyang Shi."], "venue": "Knowledge-Based Systems, 56:191\u2013200, January.", "citeRegEx": "Huang et al\\.,? 2014", "shortCiteRegEx": "Huang et al\\.", "year": 2014}, {"title": "Corpus-based semantic lexicon induction with web-based corroboration", "author": ["Sean P. Igo", "Ellen Riloff."], "venue": "ACL Workshop on Unsupervised and Minimally Supervised Learning of Lexical Semantics.", "citeRegEx": "Igo and Riloff.,? 2009", "shortCiteRegEx": "Igo and Riloff.", "year": 2009}, {"title": "Generating focused topic-specific sentiment lexicons", "author": ["Valentin Jijkoun", "Maarten de Rijke", "Wouter Weerkamp."], "venue": "ACL, pages 585\u2013594.", "citeRegEx": "Jijkoun et al\\.,? 2010", "shortCiteRegEx": "Jijkoun et al\\.", "year": 2010}, {"title": "Using wordnet to measure semantic orientations of adjectives", "author": ["Jaap Kamps", "M.J. Marx", "Robert J. Mokken", "M. de Rijke."], "venue": "LREC.", "citeRegEx": "Kamps et al\\.,? 2004", "shortCiteRegEx": "Kamps et al\\.", "year": 2004}, {"title": "The social stratification of English in New York city", "author": ["William Labov."], "venue": "Cambridge University Press.", "citeRegEx": "Labov.,? 2006", "shortCiteRegEx": "Labov.", "year": 2006}, {"title": "A solution to Plato\u2019s problem: The latent semantic analysis theory of acquisition, induction, and representation of knowledge", "author": ["Thomas K. Landauer", "Susan T. Dumais."], "venue": "Psychol. Rev., 104(2):211.", "citeRegEx": "Landauer and Dumais.,? 1997", "shortCiteRegEx": "Landauer and Dumais.", "year": 1997}, {"title": "On the Importance of Text Analysis for Stock Price Prediction", "author": ["Heeyoung Lee", "Mihai Surdeanu", "Bill MacCartney", "Dan Jurafsky."], "venue": "LREC, pages 1170\u2013 1175.", "citeRegEx": "Lee et al\\.,? 2014", "shortCiteRegEx": "Lee et al\\.", "year": 2014}, {"title": "Improving distributional similarity with lessons learned from word embeddings", "author": ["Omer Levy", "Yoav Goldberg", "Ido Dagan."], "venue": "Trans. Assoc. Comput. Ling.,", "citeRegEx": "Levy et al\\.,? 2015", "shortCiteRegEx": "Levy et al\\.", "year": 2015}, {"title": "When is a liability not a liability? Textual analysis, dictionaries, and 10-Ks", "author": ["Tim Loughran", "Bill McDonald."], "venue": "The Journal of Finance, 66(1):35\u201365.", "citeRegEx": "Loughran and McDonald.,? 2011", "shortCiteRegEx": "Loughran and McDonald.", "year": 2011}, {"title": "Distributed representations of words and phrases and their compositionality", "author": ["Tomas Mikolov", "Ilya Sutskever", "Kai Chen", "Greg S. Corrado", "Jeff Dean."], "venue": "NIPS.", "citeRegEx": "Mikolov et al\\.,? 2013", "shortCiteRegEx": "Mikolov et al\\.", "year": 2013}, {"title": "Emotions evoked by common words and phrases: Using Mechanical Turk to create an emotion lexicon", "author": ["Saif M. Mohammad", "Peter D. Turney."], "venue": "NAACL, pages 26\u201334.", "citeRegEx": "Mohammad and Turney.,? 2010", "shortCiteRegEx": "Mohammad and Turney.", "year": 2010}, {"title": "Supporting exploratory text analysis in literature study", "author": ["Aditi Muralidharan", "Marti A Hearst."], "venue": "Literary and Linguistic Computing.", "citeRegEx": "Muralidharan and Hearst.,? 2012", "shortCiteRegEx": "Muralidharan and Hearst.", "year": 2012}, {"title": "Characterizing the Google Books corpus: Strong limits to inferences", "author": ["Eitan Adam Pechenick", "Christopher M. Danforth", "Peter Sheridan Dodds"], "venue": null, "citeRegEx": "Pechenick et al\\.,? \\Q2015\\E", "shortCiteRegEx": "Pechenick et al\\.", "year": 2015}, {"title": "Glove: Global vectors for word representation", "author": ["Jeffrey Pennington", "Richard Socher", "Christopher D. Manning."], "venue": "EMNLP.", "citeRegEx": "Pennington et al\\.,? 2014", "shortCiteRegEx": "Pennington et al\\.", "year": 2014}, {"title": "Natural language processing for historical texts", "author": ["Michael Piotrowski."], "venue": "Synthesis Lectures on Human Language Technologies, 5(2):1\u2013157.", "citeRegEx": "Piotrowski.,? 2012", "shortCiteRegEx": "Piotrowski.", "year": 2012}, {"title": "Expanding Domain Sentiment Lexicon through Double Propagation", "author": ["Guang Qiu", "Bing Liu", "Jiajun Bu", "Chun Chen."], "venue": "IJCAI, volume 9.", "citeRegEx": "Qiu et al\\.,? 2009", "shortCiteRegEx": "Qiu et al\\.", "year": 2009}, {"title": "Semisupervised polarity lexicon induction", "author": ["Delip Rao", "Deepak Ravichandran."], "venue": "EACL, pages 675\u2013682.", "citeRegEx": "Rao and Ravichandran.,? 2009", "shortCiteRegEx": "Rao and Ravichandran.", "year": 2009}, {"title": "A corpusbased approach for building semantic lexicons", "author": ["Ellen Riloff", "Jessica Shepherd."], "venue": "arXiv preprint cmp-lg/9706013.", "citeRegEx": "Riloff and Shepherd.,? 1997", "shortCiteRegEx": "Riloff and Shepherd.", "year": 1997}, {"title": "Inducing a semantically annotated lexicon via EM-based clustering", "author": ["Mats Rooth", "Stefan Riezler", "Detlef Prescher", "Glenn Carroll", "Franz Beil."], "venue": "ACL, pages 104\u2013111.", "citeRegEx": "Rooth et al\\.,? 1999", "shortCiteRegEx": "Rooth et al\\.", "year": 1999}, {"title": "Semeval-2015 task 10: Sentiment analysis in twitter", "author": ["Sara Rosenthal", "Preslav Nakov", "Svetlana Kiritchenko", "Saif M. Mohammad", "Alan Ritter", "Veselin Stoyanov."], "venue": "SemEval-2015.", "citeRegEx": "Rosenthal et al\\.,? 2015", "shortCiteRegEx": "Rosenthal et al\\.", "year": 2015}, {"title": "Ultradense Word Embeddings by Orthogonal Transformation", "author": ["Sascha Rothe", "Sebastian Ebert", "Hinrich Schtze."], "venue": "arXiv preprint arXiv:1602.07572.", "citeRegEx": "Rothe et al\\.,? 2016", "shortCiteRegEx": "Rothe et al\\.", "year": 2016}, {"title": "Simple, Robust and (almost) Unsupervised Generation of Polarity Lexicons for Multiple Languages", "author": ["Inaki San Vicente", "Rodrigo Agerri", "German Rigau", "Donostia-San Sebastin."], "venue": "EACL, pages 88\u201397.", "citeRegEx": "Vicente et al\\.,? 2014", "shortCiteRegEx": "Vicente et al\\.", "year": 2014}, {"title": "On the automatic learning of sentiment lexicons", "author": ["Aliaksei Severyn", "Alessandro Moschitti."], "venue": "NAACL-HLT.", "citeRegEx": "Severyn and Moschitti.,? 2015", "shortCiteRegEx": "Severyn and Moschitti.", "year": 2015}, {"title": "Twitter polarity classification with label propagation over lexical links and the follower graph", "author": ["Michael Speriosu", "Nikita Sudan", "Sid Upadhyay", "Jason Baldridge."], "venue": "ACL Workshop on Unsupervised Learning in NLP.", "citeRegEx": "Speriosu et al\\.,? 2011", "shortCiteRegEx": "Speriosu et al\\.", "year": 2011}, {"title": "The General Inquirer: A Computer Approach to Content Analysis", "author": ["Philip J Stone", "Dexter C Dunphy", "Marshall S Smith"], "venue": null, "citeRegEx": "Stone et al\\.,? \\Q1966\\E", "shortCiteRegEx": "Stone et al\\.", "year": 1966}, {"title": "Lexicon-based methods for sentiment analysis", "author": ["Maite Taboada", "Julian Brooke", "Milan Tofiloski", "Kimberly Voll", "Manfred Stede."], "venue": "Comput. Ling., 37(2):267\u2013 307.", "citeRegEx": "Taboada et al\\.,? 2011", "shortCiteRegEx": "Taboada et al\\.", "year": 2011}, {"title": "Automatic domain-specific sentiment lexicon generation with label propagation", "author": ["Yen-Jen Tai", "Hung-Yu Kao."], "venue": "Proceedings of International Con-", "citeRegEx": "Tai and Kao.,? 2013", "shortCiteRegEx": "Tai and Kao.", "year": 2013}, {"title": "Extracting semantic orientations of words using spin model", "author": ["Hiroya Takamura", "Takashi Inui", "Manabu Okumura."], "venue": "ACL, pages 133\u2013140.", "citeRegEx": "Takamura et al\\.,? 2005", "shortCiteRegEx": "Takamura et al\\.", "year": 2005}, {"title": "Building Large-Scale Twitter-Specific Sentiment Lexicon: A Representation Learning Approach", "author": ["Duyu Tang", "Furu Wei", "Bing Qin", "Ming Zhou", "Ting Liu."], "venue": "COLING, pages 172\u2013182.", "citeRegEx": "Tang et al\\.,? 2014", "shortCiteRegEx": "Tang et al\\.", "year": 2014}, {"title": "A bootstrapping method for learning semantic lexicons using extraction pattern contexts", "author": ["Michael Thelen", "Ellen Riloff."], "venue": "EMNLP.", "citeRegEx": "Thelen and Riloff.,? 2002", "shortCiteRegEx": "Thelen and Riloff.", "year": 2002}, {"title": "Regularity in Semantic Change", "author": ["Elizabeth Closs Traugott", "Richard B Dasher."], "venue": "Cambridge University Press, Cambridge, UK.", "citeRegEx": "Traugott and Dasher.,? 2001", "shortCiteRegEx": "Traugott and Dasher.", "year": 2001}, {"title": "Linguistic change and diffusion: Description and explanation in sociolinguistic dialect geography", "author": ["Peter Trudgill."], "venue": "Language in Society, 3(2):215\u2013246.", "citeRegEx": "Trudgill.,? 1974", "shortCiteRegEx": "Trudgill.", "year": 1974}, {"title": "Measuring praise and criticism: Inference of semantic orientation from association", "author": ["Peter D. Turney", "Michael L. Littman."], "venue": "ACM Trans. Inf. Sys., 21(4):315\u2013346.", "citeRegEx": "Turney and Littman.,? 2003", "shortCiteRegEx": "Turney and Littman.", "year": 2003}, {"title": "From frequency to meaning: Vector space models of semantics", "author": ["Peter D. Turney", "Patrick Pantel."], "venue": "J. Artif. Intell. Res., 37(1):141\u2013188.", "citeRegEx": "Turney and Pantel.,? 2010", "shortCiteRegEx": "Turney and Pantel.", "year": 2010}, {"title": "The viability of webderived polarity lexicons", "author": ["Leonid Velikovich", "Sasha Blair-Goldensohn", "Kerry Hannan", "Ryan McDonald."], "venue": "NAACL-HLT, pages 777\u2013 785.", "citeRegEx": "Velikovich et al\\.,? 2010", "shortCiteRegEx": "Velikovich et al\\.", "year": 2010}, {"title": "Norms of valence, arousal, and dominance for 13,915 English lemmas", "author": ["Amy Beth Warriner", "Victor Kuperman", "Marc Brysbaert."], "venue": "Behavior research methods, 45(4):1191\u20131207.", "citeRegEx": "Warriner et al\\.,? 2013", "shortCiteRegEx": "Warriner et al\\.", "year": 2013}, {"title": "A graph model for unsupervised lexical acquisition", "author": ["Dominic Widdows", "Beate Dorow."], "venue": "COLING.", "citeRegEx": "Widdows and Dorow.,? 2002", "shortCiteRegEx": "Widdows and Dorow.", "year": 2002}, {"title": "Putting Things in Context: Community-specific Embedding Projections for Sentiment Analysis", "author": ["Yi Yang", "Jacob Eisenstein."], "venue": "arXiv preprint arXiv:1511.06052.", "citeRegEx": "Yang and Eisenstein.,? 2015", "shortCiteRegEx": "Yang and Eisenstein.", "year": 2015}, {"title": "Learning with local and global consistency", "author": ["Dengyong Zhou", "Olivier Bousquet", "Thomas Navin Lal", "Jason Weston", "Bernhard Schlkopf."], "venue": "NIPS, volume 16.", "citeRegEx": "Zhou et al\\.,? 2004", "shortCiteRegEx": "Zhou et al\\.", "year": 2004}, {"title": "Learning from labeled and unlabeled data with label propagation", "author": ["Xiaojin Zhu", "Zoubin Ghahramani."], "venue": "Technical report, Citeseer.", "citeRegEx": "Zhu and Ghahramani.,? 2002", "shortCiteRegEx": "Zhu and Ghahramani.", "year": 2002}], "referenceMentions": [{"referenceID": 40, "context": "alyze key subjective properties of texts, such as user opinions and emotional attitudes (Taboada et al., 2011).", "startOffset": 88, "endOffset": 110}, {"referenceID": 13, "context": "However, without domain-specific lexicons, analyses can be misled by sentiment assignments that are biased towards domain-general contexts and that fail to take into account community-specific vernacular or demographic variations in language use (Hovy, 2015; Yang and Eisenstein, 2015).", "startOffset": 246, "endOffset": 285}, {"referenceID": 52, "context": "However, without domain-specific lexicons, analyses can be misled by sentiment assignments that are biased towards domain-general contexts and that fail to take into account community-specific vernacular or demographic variations in language use (Hovy, 2015; Yang and Eisenstein, 2015).", "startOffset": 246, "endOffset": 285}, {"referenceID": 25, "context": "Experts or crowdsourced annotators can be used to construct sentiment lexicons for a specific domain, but these efforts are expensive and timeconsuming (Mohammad and Turney, 2010; Fast et al., 2016).", "startOffset": 152, "endOffset": 198}, {"referenceID": 8, "context": "Experts or crowdsourced annotators can be used to construct sentiment lexicons for a specific domain, but these efforts are expensive and timeconsuming (Mohammad and Turney, 2010; Fast et al., 2016).", "startOffset": 152, "endOffset": 198}, {"referenceID": 49, "context": "Recent work has shown that web-scale sentiment lexicons can be automatically induced for large socially-diffuse domains, such as the internet-atlarge (Velikovich et al., 2010) or all of Twitter (Tang ar X iv :1 60 6.", "startOffset": 150, "endOffset": 175}, {"referenceID": 23, "context": "Generic lexicons will not only be inaccurate in specific domains, they may mislead research by introducing harmful biases (Loughran and McDonald, 2011)1.", "startOffset": 122, "endOffset": 151}, {"referenceID": 11, "context": "These patterns may rely on syntactic structures (Hatzivassiloglou and McKeown, 1997; Thelen and Riloff, 2002; Widdows and Dorow, 2002; Jijkoun et al., 2010; Rooth et al., 1999), which can be domain-specific and brittle (e.", "startOffset": 48, "endOffset": 176}, {"referenceID": 44, "context": "These patterns may rely on syntactic structures (Hatzivassiloglou and McKeown, 1997; Thelen and Riloff, 2002; Widdows and Dorow, 2002; Jijkoun et al., 2010; Rooth et al., 1999), which can be domain-specific and brittle (e.", "startOffset": 48, "endOffset": 176}, {"referenceID": 51, "context": "These patterns may rely on syntactic structures (Hatzivassiloglou and McKeown, 1997; Thelen and Riloff, 2002; Widdows and Dorow, 2002; Jijkoun et al., 2010; Rooth et al., 1999), which can be domain-specific and brittle (e.", "startOffset": 48, "endOffset": 176}, {"referenceID": 17, "context": "These patterns may rely on syntactic structures (Hatzivassiloglou and McKeown, 1997; Thelen and Riloff, 2002; Widdows and Dorow, 2002; Jijkoun et al., 2010; Rooth et al., 1999), which can be domain-specific and brittle (e.", "startOffset": 48, "endOffset": 176}, {"referenceID": 33, "context": "These patterns may rely on syntactic structures (Hatzivassiloglou and McKeown, 1997; Thelen and Riloff, 2002; Widdows and Dorow, 2002; Jijkoun et al., 2010; Rooth et al., 1999), which can be domain-specific and brittle (e.", "startOffset": 48, "endOffset": 176}, {"referenceID": 47, "context": "Other models rely on general cooccurrence (Turney and Littman, 2003; Riloff and Shepherd, 1997; Igo and Riloff, 2009).", "startOffset": 42, "endOffset": 117}, {"referenceID": 32, "context": "Other models rely on general cooccurrence (Turney and Littman, 2003; Riloff and Shepherd, 1997; Igo and Riloff, 2009).", "startOffset": 42, "endOffset": 117}, {"referenceID": 16, "context": "Other models rely on general cooccurrence (Turney and Littman, 2003; Riloff and Shepherd, 1997; Igo and Riloff, 2009).", "startOffset": 42, "endOffset": 117}, {"referenceID": 0, "context": ", review scores, emoticons) specific to certain domains (Asghar et al., 2015; BlairGoldensohn et al., 2008; Bravo-Marquez et al., 2015; Choi and Cardie, 2009; Severyn and Moschitti, 2015; Speriosu et al., 2011; Tang et al., 2014).", "startOffset": 56, "endOffset": 229}, {"referenceID": 2, "context": ", review scores, emoticons) specific to certain domains (Asghar et al., 2015; BlairGoldensohn et al., 2008; Bravo-Marquez et al., 2015; Choi and Cardie, 2009; Severyn and Moschitti, 2015; Speriosu et al., 2011; Tang et al., 2014).", "startOffset": 56, "endOffset": 229}, {"referenceID": 4, "context": ", review scores, emoticons) specific to certain domains (Asghar et al., 2015; BlairGoldensohn et al., 2008; Bravo-Marquez et al., 2015; Choi and Cardie, 2009; Severyn and Moschitti, 2015; Speriosu et al., 2011; Tang et al., 2014).", "startOffset": 56, "endOffset": 229}, {"referenceID": 37, "context": ", review scores, emoticons) specific to certain domains (Asghar et al., 2015; BlairGoldensohn et al., 2008; Bravo-Marquez et al., 2015; Choi and Cardie, 2009; Severyn and Moschitti, 2015; Speriosu et al., 2011; Tang et al., 2014).", "startOffset": 56, "endOffset": 229}, {"referenceID": 38, "context": ", review scores, emoticons) specific to certain domains (Asghar et al., 2015; BlairGoldensohn et al., 2008; Bravo-Marquez et al., 2015; Choi and Cardie, 2009; Severyn and Moschitti, 2015; Speriosu et al., 2011; Tang et al., 2014).", "startOffset": 56, "endOffset": 229}, {"referenceID": 43, "context": ", review scores, emoticons) specific to certain domains (Asghar et al., 2015; BlairGoldensohn et al., 2008; Bravo-Marquez et al., 2015; Choi and Cardie, 2009; Severyn and Moschitti, 2015; Speriosu et al., 2011; Tang et al., 2014).", "startOffset": 56, "endOffset": 229}, {"referenceID": 15, "context": "An effective corpus-based approach that does not require distant-supervision\u2014which we adapt here\u2014is to construct lexical graphs using word cooccurrences and then to perform some form of label propagation over these graphs (Huang et al., 2014; Velikovich et al., 2010).", "startOffset": 222, "endOffset": 267}, {"referenceID": 49, "context": "An effective corpus-based approach that does not require distant-supervision\u2014which we adapt here\u2014is to construct lexical graphs using word cooccurrences and then to perform some form of label propagation over these graphs (Huang et al., 2014; Velikovich et al., 2010).", "startOffset": 222, "endOffset": 267}, {"referenceID": 35, "context": "Recent work has also learned transformations of word-vector representations in order to induce sentiment lexicons (Rothe et al., 2016).", "startOffset": 114, "endOffset": 134}, {"referenceID": 0, "context": ", review scores, emoticons) specific to certain domains (Asghar et al., 2015; BlairGoldensohn et al., 2008; Bravo-Marquez et al., 2015; Choi and Cardie, 2009; Severyn and Moschitti, 2015; Speriosu et al., 2011; Tang et al., 2014). An effective corpus-based approach that does not require distant-supervision\u2014which we adapt here\u2014is to construct lexical graphs using word cooccurrences and then to perform some form of label propagation over these graphs (Huang et al., 2014; Velikovich et al., 2010). Recent work has also learned transformations of word-vector representations in order to induce sentiment lexicons (Rothe et al., 2016). Fast et al. (2016) combine word vectors with crowdsourcing to produce domain-general topic lexicons.", "startOffset": 57, "endOffset": 655}, {"referenceID": 9, "context": "Dictionary-based approaches use hand-curated lexical resources\u2014usually WordNet (Fellbaum, 1998)\u2014in order to propagate sentiment from seed labels (Esuli and Sebastiani, 2006; Hu and Liu, 2004; Kamps et al.", "startOffset": 79, "endOffset": 95}, {"referenceID": 49, "context": "Most previous work seeks to enrich or enlarge existing lexicons (San Vicente et al., 2014; Velikovich et al., 2010; Qiu et al., 2009), emphasizing recall over precision.", "startOffset": 64, "endOffset": 133}, {"referenceID": 30, "context": "Most previous work seeks to enrich or enlarge existing lexicons (San Vicente et al., 2014; Velikovich et al., 2010; Qiu et al., 2009), emphasizing recall over precision.", "startOffset": 64, "endOffset": 133}, {"referenceID": 49, "context": "This recall-oriented approach is motivated by the need for massive polarity lexicons in tasks like web-advertising (Velikovich et al., 2010).", "startOffset": 115, "endOffset": 140}, {"referenceID": 49, "context": "Algorithmically, our approach is inspired by Velikovich et al. (2010). We extend this work by incorporating high-quality word vector embeddings, a new graph construction approach, an alternative label propagation algorithm, and a bootstrapping method to obtain confidences.", "startOffset": 45, "endOffset": 70}, {"referenceID": 20, "context": "We embed each word wi \u2208 V as a vector wi that captures information about its co-occurrence statistics with other words (Landauer and Dumais, 1997; Turney and Pantel, 2010).", "startOffset": 119, "endOffset": 171}, {"referenceID": 48, "context": "We embed each word wi \u2208 V as a vector wi that captures information about its co-occurrence statistics with other words (Landauer and Dumais, 1997; Turney and Pantel, 2010).", "startOffset": 119, "endOffset": 171}, {"referenceID": 22, "context": "3 MPPMI i,j is equal to a smoothed variant of the positive pointwise mutual information between words wi and wj (Levy et al., 2015).", "startOffset": 112, "endOffset": 131}, {"referenceID": 22, "context": "75 (Levy et al., 2015).", "startOffset": 3, "endOffset": 22}, {"referenceID": 48, "context": "Excluding the singular value weights, \u03a3, has been shown known to dramatically improve embedding qualities (Turney and Pantel, 2010; Bullinaria and Levy, 2012).", "startOffset": 106, "endOffset": 158}, {"referenceID": 3, "context": "Excluding the singular value weights, \u03a3, has been shown known to dramatically improve embedding qualities (Turney and Pantel, 2010; Bullinaria and Levy, 2012).", "startOffset": 106, "endOffset": 158}, {"referenceID": 24, "context": "We found that this SVD method significantly outperformed word2vec (Mikolov et al., 2013) and GloVe (Pennington et al.", "startOffset": 66, "endOffset": 88}, {"referenceID": 28, "context": ", 2013) and GloVe (Pennington et al., 2014) on the domainspecific datasets we examined.", "startOffset": 18, "endOffset": 43}, {"referenceID": 3, "context": "Excluding the singular value weights, \u03a3, has been shown known to dramatically improve embedding qualities (Turney and Pantel, 2010; Bullinaria and Levy, 2012). Following standard practices, we learn embeddings of dimension 300. We found that this SVD method significantly outperformed word2vec (Mikolov et al., 2013) and GloVe (Pennington et al., 2014) on the domainspecific datasets we examined. Our results echo the findings of Levy et al. (2015) that the SVD approach performs best on rare word similarity tasks.", "startOffset": 132, "endOffset": 449}, {"referenceID": 53, "context": "Once a weighted lexical graph is constructed, we propagate sentiment labels over this graph using a random walk method (Zhou et al., 2004).", "startOffset": 119, "endOffset": 138}, {"referenceID": 53, "context": "Many variants of this random walk approach and related label propagation techniques exist in the literature (Zhou et al., 2004; Zhu and Ghahramani, 2002; Zhu et al., 2003; Velikovich et al., 2010; San Vicente et al., 2014).", "startOffset": 108, "endOffset": 222}, {"referenceID": 54, "context": "Many variants of this random walk approach and related label propagation techniques exist in the literature (Zhou et al., 2004; Zhu and Ghahramani, 2002; Zhu et al., 2003; Velikovich et al., 2010; San Vicente et al., 2014).", "startOffset": 108, "endOffset": 222}, {"referenceID": 49, "context": "Many variants of this random walk approach and related label propagation techniques exist in the literature (Zhou et al., 2004; Zhu and Ghahramani, 2002; Zhu et al., 2003; Velikovich et al., 2010; San Vicente et al., 2014).", "startOffset": 108, "endOffset": 222}, {"referenceID": 39, "context": "Standard English: To facilitate comparison with previous work, we focus on the well-known General Inquirer lexicon (Stone et al., 1966).", "startOffset": 115, "endOffset": 135}, {"referenceID": 39, "context": "Standard English: To facilitate comparison with previous work, we focus on the well-known General Inquirer lexicon (Stone et al., 1966). We also use the continuous valence (i.e., polarity) scores collected by Warriner et al. (2013) in order to evaluate the fine-grained performance of our framework.", "startOffset": 116, "endOffset": 232}, {"referenceID": 6, "context": "constructed from the 2000s decade of the Corpus of Historical American English (COHA), which contains \u223c2 \u00d7 107 words in each decade, from 1850 to 2000 (Davies, 2010).", "startOffset": 151, "endOffset": 165}, {"referenceID": 23, "context": "Finance: Previous work found that general purpose sentiment lexicons performed very poorly on financial text (Loughran and McDonald, 2011), so a finance-specific sentiment lexicon (containing binary labels) was hand-constructed for this domain (ibid.", "startOffset": 109, "endOffset": 138}, {"referenceID": 21, "context": "To test against this lexicon, we constructed embeddings using a dataset of\u223c2\u00d7107 tokens from financial 8K documents (Lee et al., 2014).", "startOffset": 116, "endOffset": 134}, {"referenceID": 38, "context": "Twitter: Numerous works attempt to induce Twitter-specific sentiment lexicons using supervised approaches and features unique to that domain (e.g., follower graphs; Speriosu et al., 2011).", "startOffset": 141, "endOffset": 187}, {"referenceID": 34, "context": "We evaluate our approach using the test set from the 2015 SemEval task 10E competition (Rosenthal et al., 2015), and we use the embeddings constructed by Rothe et al.", "startOffset": 87, "endOffset": 111}, {"referenceID": 34, "context": "We evaluate our approach using the test set from the 2015 SemEval task 10E competition (Rosenthal et al., 2015), and we use the embeddings constructed by Rothe et al. (2016).5", "startOffset": 88, "endOffset": 174}, {"referenceID": 47, "context": "The PMI baseline of Turney and Littman (2003) computes the pointwise mutual information between the seeds and the targets without using propagation.", "startOffset": 20, "endOffset": 46}, {"referenceID": 47, "context": "The PMI baseline of Turney and Littman (2003) computes the pointwise mutual information between the seeds and the targets without using propagation. The CountVec baseline, corresponding to the method in Velikovich et al. (2010), is similar to our method but uses an alternative propagation approach and raw cooccurrence vectors instead of learned embeddings.", "startOffset": 20, "endOffset": 228}, {"referenceID": 35, "context": "of propagating labels (Rothe et al., 2016).", "startOffset": 22, "endOffset": 42}, {"referenceID": 35, "context": "of propagating labels (Rothe et al., 2016). Lastly, on standard English we compare against a state-of-theart WordNet-based method, which performs label propagation over a WordNet-derived graph (San Vicente et al., 2014). Several variant baselines, all of which SENTPROP outperforms, are omitted for brevity (e.g., using word-vector cosines in place of PMI in Turney and Littman (2003)\u2019s framework).", "startOffset": 23, "endOffset": 385}, {"referenceID": 25, "context": "Our framework significantly outperforms the baselines on all tasks, outperforms a state-of-the-art approach that uses WordNet on standard English (Table 2a), and is competitive with Sentiment140 on Twitter (Table 2b), a distantlysupervised approach that uses signals from emoticons (Mohammad and Turney, 2010).", "startOffset": 282, "endOffset": 309}, {"referenceID": 49, "context": "We found that the baseline method of Velikovich et al. (2010), which our method is closely related to, performed very poorly with these domain-specific corpora.", "startOffset": 37, "endOffset": 62}, {"referenceID": 49, "context": "We found that the baseline method of Velikovich et al. (2010), which our method is closely related to, performed very poorly with these domain-specific corpora. This indicates that using high-quality word-vector embeddings can have a drastic impact on performance. However, it is worth noting that Velikovich et al. (2010)\u2019s method was designed for high recall with massive corpora, so its poor performance in our regime is not surprising.", "startOffset": 37, "endOffset": 323}, {"referenceID": 46, "context": "It is well known that there is substantial sociolinguistic variation between different communities, whether these communities are defined geographically (Trudgill, 1974) or via underlying sociocultural differences (Labov, 2006).", "startOffset": 153, "endOffset": 169}, {"referenceID": 19, "context": "It is well known that there is substantial sociolinguistic variation between different communities, whether these communities are defined geographically (Trudgill, 1974) or via underlying sociocultural differences (Labov, 2006).", "startOffset": 214, "endOffset": 227}, {"referenceID": 19, "context": "It is well known that there is substantial sociolinguistic variation between different communities, whether these communities are defined geographically (Trudgill, 1974) or via underlying sociocultural differences (Labov, 2006). However, no previous work has systematically investigated community-specific variation in word sentiment at a large scale. Yang and Eisenstein (2015) exploit social network structures in Twitter to infer a small number (1-10) of communities and analyzed sentiment variation via a supervised framework.", "startOffset": 215, "endOffset": 379}, {"referenceID": 45, "context": "The phenomena of amelioration (words becoming more positive) and pejoration (words becoming more negative) are well-discussed in the linguistic literature (Traugott and Dasher, 2001); however, no comprehensive polarity lexicons exist for historical data (Cook and Stevenson, 2010).", "startOffset": 155, "endOffset": 182}, {"referenceID": 5, "context": "The phenomena of amelioration (words becoming more positive) and pejoration (words becoming more negative) are well-discussed in the linguistic literature (Traugott and Dasher, 2001); however, no comprehensive polarity lexicons exist for historical data (Cook and Stevenson, 2010).", "startOffset": 254, "endOffset": 280}, {"referenceID": 29, "context": "Such lexicons are crucial to the growing body of work on NLP analyses of historical text (Piotrowski, 2012) which are informing diachronic linguistics (Hamilton et al.", "startOffset": 89, "endOffset": 107}, {"referenceID": 10, "context": "Such lexicons are crucial to the growing body of work on NLP analyses of historical text (Piotrowski, 2012) which are informing diachronic linguistics (Hamilton et al., 2016), the digital humanities (Muralidharan and Hearst, 2012), and history (Hendrickx et al.", "startOffset": 151, "endOffset": 174}, {"referenceID": 26, "context": ", 2016), the digital humanities (Muralidharan and Hearst, 2012), and history (Hendrickx et al.", "startOffset": 32, "endOffset": 63}, {"referenceID": 12, "context": ", 2016), the digital humanities (Muralidharan and Hearst, 2012), and history (Hendrickx et al., 2011).", "startOffset": 77, "endOffset": 101}, {"referenceID": 5, "context": "The phenomena of amelioration (words becoming more positive) and pejoration (words becoming more negative) are well-discussed in the linguistic literature (Traugott and Dasher, 2001); however, no comprehensive polarity lexicons exist for historical data (Cook and Stevenson, 2010). Such lexicons are crucial to the growing body of work on NLP analyses of historical text (Piotrowski, 2012) which are informing diachronic linguistics (Hamilton et al., 2016), the digital humanities (Muralidharan and Hearst, 2012), and history (Hendrickx et al., 2011). The only previous work on automatically inducing historical sentiment lexicons is Cook and Stevenson (2010); they use the PMI method and", "startOffset": 255, "endOffset": 660}, {"referenceID": 27, "context": "We constructed lexicons from COHA, since it was carefully constructed to be genre balanced (e.g., compared to the Google N-Grams; Pechenick et al., 2015).", "startOffset": 91, "endOffset": 153}], "year": 2016, "abstractText": "A word\u2019s sentiment depends on the domain in which it is used. Computational social science research thus requires sentiment lexicons that are specific to the domains being studied. We combine domain-specific word embeddings with a label propagation framework to induce accurate domain-specific sentiment lexicons using small sets of seed words. We show that our approach achieves state-of-the-art performance on inducing sentiment lexicons from domain-specific corpora and that our purely corpus-based approach outperforms methods that rely on hand-curated resources (e.g., WordNet). Using our framework, we induce and release historical sentiment lexicons for 150 years of English and community-specific sentiment lexicons for 250 online communities from the social media forum Reddit. The historical lexicons we induce show that more than 5% of sentiment-bearing (nonneutral) English words completely switched polarity during the last 150 years, and the community-specific lexicons highlight how sentiment varies drastically between different communities.", "creator": "TeX"}}}