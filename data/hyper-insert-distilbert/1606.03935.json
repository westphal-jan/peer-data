{"id": "1606.03935", "review": {"conference": "arxiv", "VERSION": "v1", "DATE_OF_SUBMISSION": "13-Jun-2016", "title": "A framework for redescription set construction", "abstract": "practical redescription force mining programming is within a wide field of business knowledge discovery that ultimately aims at finding different descriptions of similar specific subsets outcomes of ambiguous instances in the binary data. these hybrid instances largely are characterized, with increasingly descriptive attributes from mere one or the more disjoint sets sizes of attributes uniformly called common views. indeed by alternately exploring different characterizations it almost is possible to find relative non : trivial and interesting systematic connections between different sized subsets combinations of attributes. clearly in this work, questions we explore, the process efficiency of creating possibly large and particularly heterogeneous redescription style set in instances which differing redescriptions elements are iteratively improved by considering a second conjunctive criterion refinement method procedure largely aimed at increasing numerical redescription accuracy. this set is used by our superior redescription finite set construction manufacturing procedure to successfully create multiple redescription sets of certain user constructed defined size. set construction is itself based on generalized redescription selection by basically using different multi - task objective algorithm optimization methods incorporating our user defined importance levels applying towards one possible or more important redescription quality assignment criteria. these properties distinguish our approach from current state'of the art approaches that create one, mostly smaller set typically that effectively contains sufficient redescriptions perfectly satisfying a custom pre - defined set capable of implicit constraints. we introduce a new redescription quality measure criterion that assesses on the individual variability of redescription accuracy when missing particular values are present present in mining the data. finally, after we compare together the performance of our framework with three state, of the art redescription constraint mining algorithms.", "histories": [["v1", "Mon, 13 Jun 2016 13:15:41 GMT  (971kb,D)", "https://arxiv.org/abs/1606.03935v1", null], ["v2", "Mon, 19 Dec 2016 16:41:06 GMT  (1063kb,D)", "http://arxiv.org/abs/1606.03935v2", null]], "reviews": [], "SUBJECTS": "cs.AI cs.DB", "authors": ["matej mihel\\v{c}i\\'c", "sa\\v{s}o d\\v{z}eroski", "nada lavra\\v{c}", "tomislav \\v{s}muc"], "accepted": false, "id": "1606.03935"}, "pdf": {"name": "1606.03935.pdf", "metadata": {"source": "CRF", "title": "A framework for redescription set construction", "authors": ["Matej Mihel\u010di\u0107a", "Sa\u0161o D\u017eeroskib", "Nada Lavra\u010db", "Tomislav \u0160muca"], "emails": ["matej.mihelcic@irb.hr", "saso.dzeroski@ijs.si", "nada.lavrac@ijs.si", "tomislav.smuc@irb.hr"], "sections": [{"heading": null, "text": "Redescription mining is a field of knowledge discovery that aims at finding different descriptions of similar subsets of instances in the data. These descriptions are represented as rules inferred from one or more disjoint sets of attributes, called views. As such, they support knowledge discovery process and help domain experts in formulating new hypotheses or constructing new knowledge bases and decision support systems. In contrast to previous approaches that typically create one smaller set of redescriptions satisfying a pre-defined set of constraints, we introduce a framework that creates large and heterogeneous redescription set from which user/expert can extract compact sets of differing properties, according to its own preferences. Construction of large and heterogeneous redescription set relies on CLUS-RM algorithm and a novel, conjunctive refinement procedure that facilitates generation of larger and more accurate redescription sets. The work also introduces the variability of redescription accuracy when missing values are present in the data, which significantly extends applicability of the method. Crucial part of the framework is the redescription set extraction based on heuristic multi-objective optimization procedure that allows user to define importance levels towards one or more redescription quality criteria. We provide both theoretical and empirical comparison of the novel framework against current state of the art redescription mining algorithms and show that it represents more efficient and versatile approach for mining redescriptions from data.\nKeywords: knowledge discovery, redescription mining, predictive clustering trees, redescription set construction, scalarization, conjunctive refinement, redescription variability"}, {"heading": "1. Introduction", "text": "In many scientific fields, there is a growing need to understand measured or observed data, to find different regularities or anomalies, groups of instances (patterns) for which they occur and their descriptions in order to get an insight into the underlying phenomena.\nThis is addressed by redescription mining (Ramakrishnan et al., 2004), a type of knowledge discovery that aims to find different descriptions of similar sets of instances by using one, or more disjoint sets of descriptive attributes, called views. It is applicable in a variety of scientific fields like biology, economy, pharmacy, ecology, social science and other, where it is important to understand connections between different descriptors and to find regularities that are valid for different subsets of instances. Redescriptions are tuples of logical formulas which are called queries. Redescription Rex = (q1, q2) contains two queries: q1 : (\u22121.8 \u2264 t\u03037 \u2264 4.4 \u2227 12.1 \u2264 p\u03036 \u2264 21.2) q2 : Polarbear\n\u2217Corresponding author. Tel. +385 (1) 456 1080 Email addresses: matej.mihelcic@irb.hr (Matej Mihel\u010di\u0107 ),\nsaso.dzeroski@ijs.si (Sa\u0161o D\u017eeroski), nada.lavrac@ijs.si (Nada Lavra\u010d), tomislav.smuc@irb.hr (Tomislav \u0160muc)\nThe first query (q\u20321) describes a set of instances (geospatial locations) by using a set of attributes related to temperature (t) and precipitation (p) in a given month as first view (in the example average temperature in July and average precipitation in June). The second query (q\u20322) describes very similar set of locations by using a set of attributes specifying animal species inhabiting these locations as a second view (in this instance polar bear). Queries contain only conjunction logical operator, though the approach supports conjunction, negation and disjunction operators.\nWe first describe the fields of data mining and knowledge discovery closely related to redescription mining. Next, we describe recent research in redescription mining, relevant to the approach we propose. We then outline our approach positioned in the context of related work."}, {"heading": "1.1. Fields related to redescription mining", "text": "Redescription mining is related to association rule mining (Agrawal et al., 1996; Hipp et al., 2000; Zhang & He, 2010), two-view data association discovery (van Leeuwen & Galbrun, 2015), clustering (Cox, 1957; Fisher, 1958; Ward, 1963; Jain et al., 1999; Xu & Tian, 2015) and it\u2019s special form conceptual clustering (Michalski, 1980; Fisher, 1987), subgroup discovery (Kl\u00f6sgen, 1996; Wrobel, 1997; Novak et al., 2009; Herrera et al., 2010), emerging\nhttp://dx.doi.org/10.1016/j.eswa.2016.10.012\nar X\niv :1\n60 6.\n03 93\n5v 2\n[ cs\n.A I]\n1 9\nD ec\n2 01\n6\npatterns (Dong & Li, 1999; Novak et al., 2009), contrast set mining (Bay & Pazzani, 2001; Novak et al., 2009) and exceptional model mining (Leman et al., 2008). Most important relations can be seen in Figure 1.\nAssociation rule mining (Agrawal et al., 1996) is related to redescription mining in the aim to find queries describing similar sets of instances which reveal associations between attributes used in these queries. The main difference is that association rules produce one directional associations while redescription mining produces bi directional associations. Two-view data association discovery (van Leeuwen & Galbrun, 2015) aims at finding a small, non - redundant set of associations that provide insight in how two views are related. Produced associations are both uni and bi directional as opposed to redescription mining that only produces bi directional connections providing interesting descriptions of instances.\nThe main goal of clustering is to find groups of similar instances with respect to a set of attributes. However, it does not provide understandable and concise descriptions of these groups which are often complex and hard to find. This is resolved in conceptual clustering Michalski (1980); Fisher (1987) that finds clusters and concepts that describe them. Redescription mining shares this aim but requires each discovered cluster to be described by at least two concepts. Clustering is extended by multi-view (Bickel & Scheffer, 2004; Wang et al., 2013) and multi-layer clustering (Gamberger et al., 2014) to find groups of instances that are strongly connected across multiple views.\nSubgroup discovery (Kl\u00f6sgen, 1996; Wrobel, 1997) differs from redescription mining in its goals. It finds queries describing groups of instances having unusual and interesting statistical properties on their target variable which are often unavailable in purely descriptive tasks. Exceptional model mining (Leman et al., 2008) extends subgroup discovery to more complex target concepts searching for subgroups such that a model trained on this subgroup is exceptional based on some property.\nEmerging Patterns (Dong & Li, 1999) aim at finding itemsets that are statistically dependent on a specific target class while Contrast Set Mining (Bay & Pazzani, 2001) identifies monotone conjunctive queries that best discriminate between instances containing one target class from all other instances."}, {"heading": "1.2. Related work in redescription mining", "text": "The field of redescription mining was introduced by Ramakrishnan et al. (2004), who present an algorithm to mine redescriptions based on decision trees, called CARTwheels. The algorithm works by building two decision trees (one for each view) that are joined in the leaves. Redescriptions are found by examining the paths from the root node of the first tree to the root node of the second. The algorithm uses multi class classification to guide the search between the two views. Other approaches to mine redescriptions include the one proposed by Zaki & Ramakrishnan (2005), which uses a lattice of closed descrip-\ntor sets to find redescriptions; the algorithm for mining exact and approximate redescriptions by Parida & Ramakrishnan (2005) that uses relaxation lattice, and the greedy and the MID algorithm based on frequent itemset mining by Gallo et al. (2008). All these approaches work only on Boolean data.\nGalbrun & Miettinen (2012b) extend the greedy approach by Gallo et al. (2008) to work on numerical data. Redescription mining was extended by Galbrun & Kimmig (2013) to a relational and by Galbrun & Miettinen (2012a) to an interactive setting. Recently, two tree-based algorithms have been proposed by Zinchenko (2014), which explore the use of decision trees in a non-Boolean setting and present different methods of layer-by-layer tree construction, which make informed splits at each level of the tree. Mihel\u010di\u0107 et al. (2015a,b) proposed a redescription mining algorithm based on multi-target predictive clustering trees (PCTs) (Blockeel & De Raedt, 1998; Kocev et al., 2013). This algorithm typically creates a large number of redescriptions by executing PCTs iteratively: it uses rules created for one view of attributes in one iteration, as target attributes for generating rules for the other view of attributes in the next iteration. A redescription set of a given size is improved over the iterations by introducing more suitable redescriptions which replace the ones that are inferior according to predefined quality criteria.\nIn this work, we introduce a redescription mining framework that allows creating multiple redescription sets of user defined size, based on user defined importance levels of one or more redescription quality criteria. The underlying redescription mining algorithm uses multi-target predictive clustering trees (Kocev et al., 2013) and allows the main steps of rule creation and redescription construction explained in (Mihel\u010di\u0107 et al., 2015b). This is in contrast to current state of the art approaches that return all constructed redescriptions that satisfy accuracy and support constraints (Ramakrishnan et al., 2004; Zaki & Ramakrishnan, 2005; Parida & Ramakrishnan, 2005), a smaller number of accurate and significant redescriptions that satisfy support constraints (Galbrun & Miettinen, 2012b; Zinchenko, 2014; Gallo et al., 2008) or optimize one redescription set of user defined size (Mihel\u010di\u0107 et al., 2015b). This algorithm supports a broader process which involves the creation and effective utilization of a possibly large redescription set.\nFrom the expert systems perspective, the framework allows creating large and heterogeneous knowledge basis for use by the domain experts. It also allows fully automated construction of specific subsets of obtained knowledge based on predefined user-criteria. The system is modular and allows using the redescription set construction procedure as an independent querying system on the database created by merging multiple redescription sets produced by many different redescription mining approaches. Obtained knowledge can be used, for example, as a basis or complement in decision support systems.\nThe framework provides means to explore and compare\nSupervised tasks\nUnsupervised tasks\nmultiple redescription sets, without the need to expensively experiment with tuning the parameters of the underlying redescription mining algorithm. This is achieved with (i) an efficient redescription mining algorithm with a new conjunctive refinement procedure, that produces large, heterogeneous and accurate redescription sets and (ii) redescription set construction procedure that produces one or more reduced redescription sets tailored to specific user preferences in a multi-objective optimization manner.\nAfter introducing the necessary notation in Section 2, we present the framework for redescription set construction in Section 3. First, we shortly describe the CLUS-RM algorithm, then we introduce the conjunctive refinement procedure and explain the generalized redescription set construction process. Next, we introduce the variability index: which supports a refined treatment of redescription accuracy in presence of missing values. We describe the datasets and an application involving redescription sets produced by the framework in Section 4 and perform theoretical and empirical evaluation of the framework\u2019s performance in Section 5. Empirical evaluation includes quality analysis of representative sets and comparison to the set containing all discovered redescriptions, evaluation of the conjunctive refinement procedure, and quality comparison of redescriptions produced by our framework to those produced by several state of the art redescription mining algorithms, on three datasets with different properties. We conclude the paper in Section 6."}, {"heading": "2. Notation and definitions", "text": "The input dataset D = (V1, V2, E,W1,W2) is a quintuple of the two attribute (variable) sets (V1, V2), an element (instance) set E, and the two views corresponding to these\nattribute sets. Views (W1 and W2) are |E| \u00d7 |Vd| data matrices such that Wdi,j = ck if an element ei has a value ck for attribute vj \u2208 Vd.\nA query q is a logical formula F that can contain the conjunction, disjunction and negation logical operators. These operators describe logical relations between different attributes, from attribute sets V1 and V2, that constitute a query. The set of all valid queries Q is called a query language. The set of elements described by a query q, denoted supp(q), is called its support. A redescription R = (q1, q2) is defined as a pair of queries, where q1 and q2 contain variables from V1 and V2 respectively. The support of a redescription is the set of elements supported by both queries that constitute this redescription supp(R) = supp(q1)\u2229 supp(q2). We use attr(R) to denote the multi-set of all occurrences of attributes in the queries of a redescription R. The corresponding set of attributes is denoted attrs(R). The set containing all produced redescriptions is denoted R. User-defined constraints C are typically limits on various redescription quality measures.\nGiven a dataset D, a query language Q over a set of attributes V , and a set of constraints C, the task of redescription mining (Galbrun, 2013) is to find all redescriptions satisfying constraints in C."}, {"heading": "2.1. Individual redescription quality measures", "text": "The accuracy of a redescription R = (q1, q2) is measured with the Jaccard similarity coefficient (Jaccard index).\nJ(R) = |supp(q1) \u2229 supp(q2))| |supp(q1) \u222a supp(q2)|\nThe problem with this measure is that redescriptions describing large subsets of instances often have a large intersection which results in high value of Jaccard index. As a\nresult, the obtained knowledge is quite general and often not very useful to the domain expert. It is thus preferred to have redescriptions that reveal more specific knowledge about the studied problem and are harder to obtain by random sampling from the underlying data distribution.\nThis is why we compute the statistical significance (pvalue) of each obtained redescription. We denote the marginal probability of a query q1 and q2 with p1 = |supp(q1)| |E| and p2 = |supp(q2)| |E| , respectively and the set of elements described by both as o = supp(q1) \u2229 supp(q2). The corresponding p-value (Galbrun, 2013) is defined as\npV (R) = |E|\u2211 n=|o| ( |E| n ) (p1 \u00b7 p2)n \u00b7 (1\u2212 p1 \u00b7 p2)|E|\u2212n\nThe p-value represents a probability that a subset of elements of observed size or larger is obtained by joining two random queries with marginal probabilities equal to the fractions of covered elements. It is an optimistic criterion, since the assumption that all elements can be sampled with equal probability need not hold for all datasets.\nSince it is important to provide understandable and short descriptions, it is interesting to measure the number of attributes occurring in redescription queries attr(R).\nBelow, we provide an example of a redescription, together with its associated quality measures obtained on the Bio dataset (Mitchell-Jones, 1999; Hijmans et al., 2005; Galbrun, 2013): Redescription R\u2032ex = (q\u20321, q\u20322) with its queries defined as: q\u20321 : (\u22121.8 \u2264 t\u03037 \u2264 4.4 \u2227 12.1 \u2264 p\u03036 \u2264 21.2) \u2228 (\u22121.6 \u2264 t\u03036 \u2264 1.5 \u2227 21.6 \u2264 p\u03036 \u2264 30.1) q\u20322 : Polarbear describes 34 locations which are inhabited by the polar bear. The q\u20321 query describes the average temperature (t\u0303) and the average precipitation (p\u0303) conditions of these locations in June and July. The redescription has a Jaccard index value of 0.895 and a p-value smaller than 2 \u00b7 10\u221216. The multi-set attr(R\u2032ex) = {t\u03036, t\u03037, p\u03036, p\u03036,Polarbear} and its corresponding set attrs(R\u2032ex) = {t\u03036, t\u03037, p\u03036,Polarbear}. The query size of R\u2032ex, denoted |attr(R\u2032ex)|, equals 5."}, {"heading": "2.2. Redescription quality measures based on redescription set properties", "text": "We use two redescription quality measures based on properties of redescriptions contained in a corresponding redescription set.\nThe measure providing information about the redundancy of elements contained in the redescription support is called the average redescription element Jaccard index and is defined as:\nAEJ(Ri) = 1 |R| \u2212 1 \u00b7 |R|\u2211 j=1 J(supp(Ri), supp(Rj)), i 6= j\nAnalogously, the measure providing information about the redundancy of attributes contained in redescription\nqueries, called the average redescription attribute Jaccard index, is defined as:\nAAJ(Ri) = 1 |R| \u2212 1 \u00b7 |R|\u2211 j=1 J(attrs(Ri), attrs(Rj)), i 6= j\nWe illustrate the average attribute Jaccard index on the redescription example from the previous subsection. If we assume that our redescription set contains only two redescriptions R = {Rex, R\u2032ex} where Rex equals: q1 : (\u22121.8 \u2264 t\u03037 \u2264 4.4 \u2227 12.1 \u2264 p\u03036 \u2264 21.2) q2 : Polarbear The corresponding average attribute Jaccard index of the redescription Rex equals 34 = 0.75 showing a high level of redundancy in the used attributes between redescription Rex and the only other redescription available in the set R\u2032ex. On the other hand, in the redescription set R = {R\u2032ex, R\u2032\u2032ex}, where R\u2032\u2032ex contains queries: q\u2032\u20321 : (7.2 \u2264 t+9 \u2264 17.2 \u2227 13.5 \u2264 t + 7 \u2264 22.7) q\u2032\u20322 : MountainHare the average attribute Jaccard index of the redescription R\u2032ex equals 0 7 = 0 showing no redundancy in the used attributes."}, {"heading": "3. Redescription mining framework", "text": "In this section, we present a redescription mining framework. It first creates a large set of redescriptions and then uses it to create one or more smaller sets that are presented to the user. This is done by taking into account the relative user preferences regarding importance of different redescription quality criteria."}, {"heading": "3.1. The CLUS-RM algorihtm", "text": "The framework generates redescriptions with the CLUSRM algorithm Mihel\u010di\u0107 et al. (2015b), presented in Algorithm 1. It uses multi-target Predictive Clustering Trees (PCT) (Kocev et al., 2013) to construct conjunctive queries which are used as building blocks of redescriptions. Queries containing disjunctions and negations are obtained by combining and transforming queries containing only conjunction operator.\nAlgorithm 1 The CLUS-RM algorithm\nRequire: First view data (W1), Second view data (W2), Constraints C Ensure: A set of redescriptions R 1: procedure CLUS-RM 2: [PW1init, PW2init]\u2190 createInitialPCTs(W1, W2) 3: [rW1, rW2]\u2190 extrRulesFromPCT(PW1init, PW2init) 4: while RunInd<maxIter do 5: [DW1, DW2]\u2190 constructTargets(rW1,rW2) 6: [PW1, PW2]\u2190 createPCTs(DW1, DW2) 7: extractRulesFromPCT(PW1, PW2, rW1, rW2) 8: R \u2190 R\u222a createRedescriptons(rW1 , rW2 , C) 9: return R\nThe algorithm is able to produce a large number of highly accurate redescriptions from which many contain only conjunction operator in the queries. This is in part the consequence of using PCTs in multi-target setting, which is known to outperform single class classification or regression trees due to the property of inductive transfer (Piccart, 2012). This distinguishes the CLUS-RM redescription mining algorithm from other state of the art solutions that in general create a smaller number of redescriptions with majority of redescription queries containing the disjunction operator."}, {"heading": "3.1.1. Rule construction and redescription creation", "text": "The initial task in the algorithm is to create one PCT per view of the original data, constructed for performing unsupervised tasks, to obtain different subsets of instances (referred to as initial clusters) and the corresponding queries that describe them. To create initial clusters (line 2 in Algorithm 1), the algorithm transforms an unsupervised problem to a supervised problem by constructing an artificial instance for each original instance in the dataset. These instances are obtained by shuffling attribute values among original instances thus braking any existing correlations between the attributes. Each artificial instance is assigned a target label 0.0 while each original instance is assigned a target label 1.0. One such dataset is created for each view considered in the redescription mining process. A PCT is constructed on each dataset, with the goal of distinguishing between the original and the artificial instances, and transformed to a set of rules. This transformation is achieved by traversing the tree, joining all attributes used in splits into a rule and computing its support. Each node in a tree forms one query containing the conjunction and possibly negation operators (line 3 and 7 in Algorithm 1).\nAfter the initial queries are created, the algorithm connects different views by assigning target labels to instances based on their coverage by queries constructed from the opposing view (line 5 in Algorithm 1). To construct queries containing attributes from W2, each instance is assigned a target label 1.0 if it is described by a query containing the attributes from W1, otherwise it is assigned a value 0.0. The process is iteratively repeated a predefined number of steps (line 4 in Algorithm 1).\nRedescriptions are created as a Cartesian product of a set of queries formed on W1 and a set of queries formed on W2 (line 8 in Algorithm 1). All redescriptions that satisfy user defined constraints (C): the minimal Jaccard index, the maximal p-value, the minimal and the maximal support are added to the redescription set. The algorithm can produce redescriptions containing conjunction, negation and disjunction operators.\nThe initialization, rule construction and various types of redescription creation are thoroughly described in (Mihel\u010di\u0107 et al., 2015b)."}, {"heading": "3.1.2. Conjunctive refinement", "text": "In this subsection, we present an algorithmic improvement to the redescription mining process presented in Algorithm 1. The aim of this method is to improve the overall accuracy of redescriptions in the redescription set by combining newly created redescriptions with redescriptions already present in redescription set R.\nCombining existing redescription queries with an attribute by using conjunction operator has been used in greedy based redescription mining algorithms (Gallo et al., 2008; Galbrun & Miettinen, 2012b) to construct redescriptions. The idea is to expand each redescription query in turn by using a selected attribute and the selected logical operator. Such procedure, if used with the conjunction operator, leads to increase of Jaccard index but also mostly reduces the support size of a redescription. Zaki & Ramakrishnan (2005) combine closed descriptor sets by using conjunction operator to construct a closed lattice of descriptor sets which are used to construct redescriptions. They conclude that combining descriptor set D1 and D2 describing element sets G1 and G2 respectively, such that G1 \u2286 G2, can be done by constructing a descriptor set D1 \u222a D2. They conclude that the newly created descriptor set, describes the same set of elements G1 as the set D1. This procedure works only with attributes containing Boolean values and does not use the notion of views.\nInstead of extending redescription queries with attributes connected using conjunction operator (which is usually constrained by the number of expansions), the conjunctive refinement procedure compares support of each redescription R = (q1, q2) in the redescription set with the selected redescription Rref = (q\u20321, q\u20322). It merges the queries of these two redescriptions with the {\u2227} operator to obtain a new redescription Rnew = (q1 \u2227 q\u20321, q2 \u2227 q\u20322) if and only if supp(R) \u2286 supp(Rref ). We extend and prove the property described in Zaki & Ramakrishnan (2005) in a more general setting, combining redescriptions with arbitrary type of attributes and a finite amount of different views. We demonstrate how to use it efficiently with numerical attributes and show that this procedure does not decrease the accuracy of a redescription. In fact, if \u2203e \u2208 E, e \u2208 supp(q1) \u2228 \u2203e\u2032 \u2208 E, e\u2032 \u2208 supp(q2) such that e /\u2208 supp(q\u20321) \u2228 e\u2032 /\u2208 supp(q\u20322), than J(Rnew) > J(R).\nIf the attributes contain numerical values, we can transform the redescription Rref , given an arbitrary redescription R \u2208 R such that supp(R) \u2286 supp(Rref ), to redescription R\u2032ref = (q \u2032\u2032 1 , q \u2032\u2032 2 ) such that R\u2032ref has tighter numerical bounds on all attributes contained in the queries, supp(R) \u2286 supp(R\u2032ref ) and that J(supp(R), supp(R\u2032ref )) \u2265 J(supp(R), supp(Rref )). By doing this, we increase the probability of finding the element e or e\u2032 as described above, which leads to improving the accuracy of redescription Rnew. The construction procedure of such redescription is explained in Section S1.1 (Online Resource 1). The redescription R\u2032ref is used as a refinement redescription when numerical attributes are\npresent in the data.\nWe can now state and prove the following lemma:\nLemma 3.1. For every redescription R \u2208 R, for every redescription Rref = (q\u20321, q\u20322), where q\u20321 = qa1 \u2227 qa2 \u2227 . . . \u2227 qan , ai \u2208 attrs(Rref ), \u2200i \u2208 {1, . . . , n} and n \u2208 N, q\u20322 = qb1 \u2227 qb2 \u2227 . . . \u2227 qbm , bj \u2208 attrs(Rref ), \u2200j \u2208 {1, . . . ,m} and m \u2208 N. If supp(R) \u2286 supp(Rref ) then for a redescription Rnew = (q1 \u2227 q\u20321, q2 \u2227 q\u20322) it holds that J(Rnew) \u2265 J(R) and supp(Rnew) = supp(R).\nThe proof of Lemma 3.1 for redescription mining problems containing two views can be seen in Section S1.1 (Online Resource 1). General formulation with n arbitrary views is proven by mathematical induction. It is easily seen from the proof that if \u2203e \u2208 E, e \u2208 supp(q1) \u2228 \u2203e\u2032 \u2208 E, e\u2032 \u2208 supp(q2) such that e /\u2208 supp(q\u20321) \u2228 e\u2032 /\u2208 supp(q\u20322) then supp(q1 \u2227 q\u20321) \u222a supp(q2 \u2227 q\u20322) \u2282 supp(q1) \u222a supp(q2) thus ultimately J(Rnew) > J(R). The conjunctive refinement is demonstrated in Figure 2.\nLine 8 from Algorithm 1 is replaced with the procedure R \u2190createAndRefineRedescriptions(rw1, rw2,R, C) which is presented in Algorithm 2. The procedure described in Algorithm 2 and demonstrated in Figure S1 applies conjunctive refinement by using redescriptions that satisfy the user defined constraints C and redescriptions that satisfy looser constraints on the Jaccard index (R.J \u2265 C.minRefJ , C.minRefJ \u2264 C.minJ). These constraints determine the amount and variability of redescriptions used to improve the redescription set.\nThe refinement procedure, in combination with redescription query minimization explained in Mihel\u010di\u0107 et al. (2015b), provides grounds for mining more accurate yet compact redescriptions.\nAlgorithm 2 The redescription set refinement procedure\nRequire: Rules created on W1 (rw1), Rules created on W2 (rw2), Redescription set R, Constraints C Ensure: A set of redescriptions R 1: procedure ConstructAndRefine 2: for Rnew \u2208 rw1 \u00d7 rw2 do 3: if Rnew.J \u2265 C.minJref then 4: for R \u2208 R do 5: R.Refine(Rnew) 6: Rnew.Refine(R)\n7: if Rnew.J \u2265 C.minJ then 8: R \u2190 R\u222aRnew 9: return R"}, {"heading": "3.2. Generalized redescription set construction", "text": "The redescription set obtained by Algorithm 1 contains redescriptions satisfying hard constraints described in the previous subsections. It is often very large and hard to explore. For this reason, we extract one or more smaller sets of redescriptions that satisfy additional preferential properties on objective redescription evaluation measures, set up by the user, and present them for exploration. This process is demonstrated in Figure 3.\nProducing summaries and compressed rule set representations is important in many fields of knowledge discovery. In the field of frequent itemset mining such dense representations include closed itemsets (Pasquier et al., 1999) and free sets (Boulicaut & Bykowski, 2000). The approaches using set pattern mining construct a set by enforcing constraints on different pattern properties, such as support, overlap or coverage (Guns et al., 2011). Methods developed in information theory consider sets that provide the best compression of a larger set of patterns. These techniques use properties like the Information Bottleneck (Tishby et al., 1999) or the Minimum description length\n(Gr\u00fcnwald, 2007). The work on statistical selection of association rules developed by Bouker et al. (2012) presented techniques to eliminate irrelevant rules based on dominance, which is computed on several possibly conflicting criteria. If some rule is not strictly dominated by any other rule already in the set, the minimal similarity with some representative rule is used to determine if it should be added to the set.\nRedescriptions are highly overlapping with respect to described instances and attributes used in the queries. It is often very hard to find fully dominated redescriptions, and the number of dominated redescriptions that can be safely discarded is relatively small compared to a set of all created redescriptions. Our approach, to create a set of user defined (small) size, does not use a representative rule to compute the similarity. Instead, it adds redescriptions to the final redescription set by using the scalarization technique (Caramia & Dell\u2019Olmo, 2008) developed in multiobjective optimization to find the optimal solution when faced with many conflicting criteria. If the corresponding optimization function is minimized, given positive weights, the solution is a strict pareto optimum, otherwise it is a weak pareto optimum (Caramia & Dell\u2019Olmo, 2008) of a multi objective optimization problem. Similar aggregation technique is used in multi attribute utility theory - MAUT (Winterfeldt & Fischer, 1975) to rank the alternatives in decision making problems.\nEach redescription is evaluated with a set of criteria known from the literature or defined by the user. The final quality score is obtained by aggregating these criteria with user-defined importance weights to produce a final numerical score. Based on this score, the method selects one non-dominated redescription, based on utilised quality criteria, at each step of redescription set construction.\nThe procedure generalizes the current redescription set construction approaches in two ways: 1) it allows defining importance weights to different redescription quality criteria and adding new ones to enable constructing redescription sets with different properties which provides different insight into the data, 2) it allows creating multiple redescription sets by using different weight vectors, support levels, Jaccard index thresholds or redescription set sizes. Thus, it in many cases eliminates the need to make multiple runs of a redescription mining algorithm.\nOne extremely useful property of the procedure is that it can be used by any existing redescription mining algorithm, or a combination thereof. In general, larger number of diverse, high quality redescriptions allows higher quality reduced sets construction.\nAre there any elements in the data that share many common properties? Can we find a subset of elements that allows multiple different redescriptions? Can we find very diverse but accurate redescriptions? What is the effect of reducing redescription query size to the overall accuracy on the observed data? What are the effects of missing values to the redescription accuracy? What is our confidence that these redescriptions will remain accurate if missing values\nare added to our set? This is only a subset of questions that can be addressed by observing redescription sets produced by the proposed procedure. The goal is not to make redescription mining subjective in the sense of interestingness (Tuzhilin, 1995) or unexpectedness (Padmanabhan & Tuzhilin, 1998), but to enable exploration of mined patterns in a more versatile manner.\nThe input to the procedure is a set of redescriptions produced by Algorithm 1 and an importance weight matrix defined by the user. The rows of the importance weight matrix define the users\u2019 importance for various redescription quality criteria. The procedure creates one output redescription set for each row in the importance weight matrix (line 3 in Algorithm 3). The procedure works in two parts: first it computes element and attribute occurrence in redescriptions from the original redescription set (line 2 in Algorithm 3). This information is used to find the redescription that satisfies the user defined criteria and describes elements by using attributes that are found in a small number of redescriptions from the redescription set. When found (line 4 in Algorithm 3), it is placed in the redescription set being constructed (line 5 in Algorithm 3). Next, the procedure iteratively adds non-dominated redescriptions (lines 7-9 in Algorithm 3) until the maximum allowed number of redescriptions is placed in the newly constructed set (line 6 in Algorithm 3).\nAlgorithm 3 Generalized redescription set construction Require: Redescription set R, Importance weight matrix W, Size of reduced set n Ensure: A set of reduced redescription sets Rred 1: procedure ReduceSet 2: [Eocur, Aocur]\u2190 computeCoocurence(R) 3: for wi \u2208 W do 4: Rfirst \u2190 findSpecificRed(R, Ecooc, Acooc, wi) 5: Rwi \u2190 Rwi \u222aRfirst 6: while |Rwi | < n do 7: Rbest \u2190 findBest(R,Rwi , wi) 8: Rwi \u2190 Rwi \u222aRbest 9: Rred \u2190 Rred \u222a {Rwi} 10: return Rred\nIn the current implementation, we use 6 redescription quality criteria, however more can be added. Five of these criteria are general redescription quality criteria, the last one is used when the underlying data contains missing values and will be described in the following section.\nThe procedure findSpecificRed uses the information about the redescription Jaccard index, p-value, query size and the occurrence of elements described by the redescription and attributes found in redescriptions queries in redescriptions from the redescription set. The p-value quality score of a redescription R is computed as:\nscorepval(R) =\n{ log10(pV (R))\n17 + 1 , pV (R) \u2265 10 \u221217\n0 , pV (R) < 10\u221217\nThe logarithm is applied to linearise the p-values and the normalization 17 is used because 10\u221217 is the smallest possible p-value that we can compute.\nThe element occurrence score of a redescription is computed as: scoreocurEl(R) = \u2211 ek\u2208supp(R)\nEocur[k]\u2211|E| j=1 Eocur[j] . The at-\ntribute occurrence score is computed in the same way as: scoreocurAt(R) = \u2211 ak\u2208attrs(R)\nAocur[k]\u2211|V1|+|V2| j=1 Aocur[j] . We also compute\nthe score measuring query size in redescriptions:\nscoresize =\n{ |attr(R)| k , |attr(R)| < k\n1 , k \u2264 |attr(R)|\nThe user-defined constant k denotes redescription complexity normalization factor. In this work we use k = 20, because redescriptions containing more than 20 variables in the queries are highly complex and hard to understand.\nThe first redescription is chosen by computing: Rfirst = argminR (w0 \u00b7 (1.0 \u2212 J(R)) + w1 \u00b7 scorepval(R) +w2 \u00b7 scoreocurEl(R) +w3 \u00b7 scoreocurAt(R) + w4 \u00b7 scoresize(R)). Each following redescription is evaluated with a score function that computes redescription similarity to each redescription contained in the redescription set. The similarity is based on described elements and attributes used in redescription queries. This score thus allows controlling the level of redundancy in the redescription set. For a redescription Ri \u2208 R\\Rred we compute: scoreelemSim(Ri) = maxj J(supp(Ri), supp(Rj)), j = 1, . . . , |Rred| and scoreattrSim(R) = maxj J(attrs(Ri), attrs(Rj)), j = 1, . . . , |Rred|.\nSeveral different approaches to reducing redundancy among redescriptions have been used before, however no exact measure was used to select redescriptions or to assess the overall level of redundancy in the redescription set. Zaki & Ramakrishnan (2005) developed an approach for non-redundant redescription generation based on a lattice of closed descriptor sets, Ramakrishnan et al. (2004) used the parameter defining the number of times one class or descriptor is allowed to participate in a redescription. This is used to make a trade-off between exploration and redundancy. Parida & Ramakrishnan (2005) computed nonredundant representations of sets of redescriptions containing some selected descriptor (set of Boolean attributes). Galbrun & Miettinen (2012b) defined a minimal contribution parameter each literal must satisfy to be incorporated in a redescription query. This enforces control over redundancy on the redescription level. Redundancy between different redescriptions is tackled in the Siren tool Galbrun & Miettinen (2012c) as a post processing (filtering) step. Mihel\u010di\u0107 et al. (2015b) use weighting of attributes occurring in redescription queries and element occurrence in redescription supports based on work in subgroup discovery (Gamberger & Lavrac, 2002; Lavra\u010d et al., 2004).\nWe combine the redescription p-value score with its support to first add highly accurate, significant redescriptions with smaller support, and then incrementally add\naccurate redescriptions with larger support size. Candidate redescriptions are found by computing: Rbest = argminR (w0 \u00b7 (1.0\u2212 J(R)) +w1 \u00b7 ( kn \u00b7 scorepval(R) + (1\u2212 k n ) \u00b7 supp(R) |E| )+w2 \u00b7scoreelemSim(R)+w3 \u00b7scoreattrSim(R)+ w4\u00b7scoresize(R)), where k denotes the number of redescriptions contained in the set under construction at this step."}, {"heading": "3.3. Missing values", "text": "There are more possible ways of computing the redescription Jaccard index when the data contains missing values. The approach that assumes that all elements from redescription support containing missing values are distributed in a way to increase the redescription Jaccard index is called optimistic (Jopt). Similarly, the approach that assumes that all elements from redescription support containing missing values are distributed in a way to decrease the redescription Jaccard index is called pessimistic (Jpess). The rejective Jaccard index evaluates redescriptions only by observing elements that do not contain missing values for attributes contained in redescription queries. These measures are discussed in (Galbrun & Miettinen, 2012b). The Query non-missing Jaccard index (Jqnm), introduced in (Mihel\u010di\u0107 et al., 2015b), is an approach that gives a more conservative estimate than the optimistic Jaccard index but more optimistic estimate than the pessimistic Jaccard index. The main evaluation criteria for this index is that a query (containing only the conjunction operator) can not describe an element that contains missing values for attributes in that query. This index is by its value closer to the optimistic than the pessimistic Jaccard index. However, as opposed to the optimistic approach, redescriptions evaluated by this index contain in their support only elements that have defined values for all attributes in redescription queries and that satisfy query constraints. The index does not penalize the elements containing missing values for attributes in both queries which are penalized in the pessimistic Jaccard index.\nIn this paper, we introduce a natural extension to the presented measures: the redescription variability index. This index measures the maximum possible variability in redescription accuracy due to missing values. This allows finding redescriptions that have only slight variation in accuracy regardless the actual value of the missing values. It also allows reducing very strict constraints imposed by the pessimistic Jaccard index that might lead to the elimination of some useful redescriptions.\nThe redescription variability index is defined as: variability(R) = Jopt(R)\u2212 Jpes(R). Formal definitions of pessimistic and optimistic Jaccard index can be seen in Section S1.2 (Online resource 1).\nThe scores used to find the first and the best redescription in generalized redescription set construction (Section 3.2) are extended to include the variability score. Our framework optimizes query non-missing Jaccard but reports all Jaccard index measures when mining redescrip-\ntions on the data containing missing values. In principle with the generalized redescription set construction, we can return reduced sets containing accurate redescriptions found with respect to each Jaccard index. Also, with the use of variability index, the framework allows finding redescriptions with accuracy affected to a very small degree by the missing values which is not possible by other redescription mining algorithms in the literature. The only approach working with missing values ReReMi requires preforming multiple runs of the algorithm to make any comparisons between redescriptions mined by using different version of Jaccard index."}, {"heading": "4. Data description and applications", "text": "We describe three datasets used to evaluate CRM-GRS and demonstrate its application on a Country dataset."}, {"heading": "4.1. Data description", "text": "The evaluation and comparisons are performed on three datasets with different characteristics: the Country dataset (UNCTAD, 2014; WorldBank, 2014; Gamberger et al., 2014), the Bio dataset (Mitchell-Jones, 1999; Hijmans et al., 2005; Galbrun, 2013) and the DBLP dataset (DBLP, 2010; Galbrun, 2013). Detailed description of each dataset can be seen in Section S2 (Online resource 1).\nDescriptions of all attributes used in the datasets are provided in the document (Online Resource 2)."}, {"heading": "4.2. Application on the Country dataset", "text": "The aim of this study is to discover regularities and interesting descriptions of world countries with respect to their trading properties and general country information (such as various demographic, banking and health related descriptors). We will focus on redescriptions describing four European countries: Germany, Czech Republic, Austria and Italy, discovered as a relevant cluster in a study\nperformed by Gamberger et al. (2014). This study investigated country and trade properties of EU countries with potential implications to a free trade agreement with China. This or similar use-case may be a potential topic of investigation for economic experts but the results of such analysis could also be of interest to the policymakers and people involved in export or import business.\nFirst step in the exploration process involves specifying various constraints on produced redescriptions. Determining parameters such as minimal Jaccard index or minimal support usually requires extensive experimentation. These experiments can be performed with CRM-GRS with only one run of redescription mining algorithm by using minimal Jaccard index of 0.1, minimal support of 5 countries (if smaller subsets are not desired) and p-value of 0.01. Parameters specifying reduced set construction can now be tuned to explore different redescription set sizes, minimal Jaccard thresholds or minimal and maximal support intervals. Results of such meta analysis (presented in Section S2.2.2 (Online resource 1)) show little influence of setting minimal Jaccard threshold on this dataset, however right choice of minimal support is important. Redescription sets using minimal support threshold of 5 countries show superior properties and may contain useful knowledge.\nWe present three different redescriptions describing specified countries and revealing their similarity to several other countries (demonstrated in Figure 4).\nRedescriptions Rblue, Rgreen and Rred are defined as: qb1 : 13.2 \u2264 POP14 \u2264 15.2 \u2227 3.1 \u2264MORT \u2264 5.0 \u2227 0.0 \u2264 POP_GROWTH \u2264 0.5 qb2 : 13.2 \u2264 E/I_MiScManArt \u2264 15.2 \u2227 28.0 \u2264 E_MedSTehInMan \u2264 40.0. (Jqnm(Rblue) = Jopt(Rblue) = 1.0, Jpess(Rblue) = 0.88, pV (Rblue) = 2.3 \u00b7 10\u221210, |supp(Rblue)| = 7) qg1 : 16.2 \u2264 POP64 \u2264 21.1 \u2227 2.9 \u2264MORT \u2264 4.5 \u2227 16.2 \u2264 RUR_POP \u2264 50.1 \u2227 0.2 \u2264W_REM \u2264 1.4\nqg2 : 0.8 \u2264 E/I_ElMachApp \u2264 1.8 \u2227 93.0 \u2264 E_AlocProd \u2264 99.0 \u2227 1.1 \u2264 E/I_SpecMach \u2264 4.3. (Jqnm(Rgreen) = Jopt(Rgreen) = Jpess(Rgreen) = 1.0, pV (Rgreen) = 1.9 \u00b7 10\u221211, |supp(Rblue)| = 9) qr1 : 3.6 \u2264 MORT \u2264 4.7 \u2227 22.9 \u2264 CRED_COV \u2264 100.0 \u2227 77.3 \u2264 M2 \u2264 238.9 qr2 : 0.1 \u2264 E/I_Cereals \u2264 1.7 \u2227 1.2 \u2264 E/I_BevTob \u2264 3.1 \u2227 0.7 \u2264 E/I_SpecMach \u2264 4.3. (Jqnm(Rred) = Jopt(Rred) = 1.0, Jpess(Rred) = 0.45, pV (Rred) = 6.3 \u00b7 10\u221212, |supp(Rred)| = 10)\nPresented redescriptions (attribute descriptions available in Table 2) confirm several findings reported in (Gamberger et al., 2014). Mainly, high export of medium - skill and technology - intensive manufactures, export of beverages and tobacco, low percentage of young population. Additionally, these redescriptions reveal high percentage of elderly population (age 65 and above), lower (compared to world average of 47.4) but still present mortality rate of children under 5 years of age (per 1000 living) and small to medium percentage of rural population. The credit coverage (percentage of adults registered for having unpaid depths, repayment history etc.) varies between countries but is no less than 20% adult population. The money and quasi money (M2 - sum of currency outside banks etc.) is between substantial 77.3% and very large 239% of total country\u2019s GDP. For additional examples see Section S2.2.3, Figure S11 (Online resource 1).\nOutput of CRM-GRS can be further analysed with visualization and exploration tools such as the Siren (Galbrun & Miettinen, 2012c) (available at http://siren.gforge. inria.fr/main/) or the InterSet (Mihel\u010di\u0107 & \u0160muc, 2016) (available at http://zel.irb.hr/interset/). In particular, the InterSet tool allows exploration of different groups of related redescriptions, discovery of interesting associations, multi-criteria filtering and redescription analysis on the individual level."}, {"heading": "5. Evaluation and comparison", "text": "In this section we present the results of different evaluations. First, we perform a theoretical comparison of our approach with other state of the art solutions which, includes description of advantages and drawbacks of our method. Next, we apply the generalized redescription set construction procedure to these datasets starting from redescriptions created by the CLUS-RM algorithm. We evaluate the conjunctive refinement procedure and perform a thorough comparison of our reduced sets with the redescription sets obtained by several state of the art redescription mining algorithms. The comparisons use measures on individual redescriptions (Section 2.1) as well as measures on redescription sets (Section 2.2). We also use the normalized query size defined in Section 3.2.\nThe execution time analysis, showing significant time reduction when using generalized redescription set construction instead of multiple CLUS-RM runs, is described in Section S2.4 (Online resource 1)."}, {"heading": "5.1. Theoretical algorithm comparison", "text": "We compare the average case time and space complexity of the CRM-GRS with state of the art approaches and present the strengths and weaknesses of our framework. The term z = 2d \u2212 1 in Table 3 denotes the number of nodes in the tree and is constrained by the tree depth d. C denotes the set of produced maximal closed frequent itemsets, l denotes the length of the longest itemset, B a set of produced biclusters, L = \u2211 c\u2208B |c| and R denotes a set of produced redescriptions. We can see from Table 3 that the CRM-GRS has slightly higher computational complexity than other tree - based approaches (which is based on time complexity of algorithm C4.5), caused by complexity of underlying redescription mining algorithm CLUS-RM. Optimizations proposed in (Mihel\u010di\u0107 et al., 2015b) lower average time complexity of basic algorithm to O(z \u00b7 (|V1| + |V2|) \u00b7 |E|2 and algorithm with refinement to O(z \u00b7 (|V1|+ |V2|) \u00b7 |E|2+z2 \u00b7 |E|). Worst-case complexity with the use of refinement is O(z \u00b7 (|V1| + |V2|) \u00b7 |E|2 + z4 \u00b7 |E|). It is the result of a very optimistic estimate that produced redescriptions satisfying user constraints grow quadratically with the number of nodes in the tree (this is only the case if no constraints on redescriptions are enforced). In reality, it has at most linear growth. Furthermore, term z2 \u00b7 |E| is only dominating if z > (|V1|+ |V2|) \u00b7 |E|. Since redescription queries\nbecome very hard to understand if they contain more than 10 attributes, even with 2 attributes in each of two views, this term is dominated when |E| > 255 instances.\nGreedy approaches (Gallo et al., 2008; Galbrun & Miettinen, 2012b) are less affected by the increase in number of instances than the tree-based approaches, but are more sensitive to the increase in number of attributes.\nComplexity of approaches based on closed and frequent itemset mining (Gallo et al., 2008; Zaki & Ramakrishnan, 2005) depends on the number of produced frequent or closed itemsets which in worst case equals 2|V1|+|V2|. Similarly, the complexity of approach proposed by Parida & Ramakrishnan (2005) depends on the number of created biclusters and their size.\nOne property of our generalized redescription set construction procedure (GRSC) is that it can be used to replace multiple runs of expensive redescription mining algorithms. Analysis from Table 3 and in S2.6 (Online resource 1) shows that it has substantially lower time complexity than all state of the art approaches except the MID and the Closed Dset. However, even for this approaches, it might be beneficial to use GRSC instead of multiple runs of these algorithms when |C| \u00b7 2l > |R|.\nSince a trade-off between space and time complexity can be made for each of the analysed algorithms, we write the\nspace complexity as a function of stored itemsets, rules, redescriptions or clusters. To reduce execution time, these structures can be stored in memory together with corresponding instances which increases space complexity to O(Cold \u00b7 |E|) for all approaces.\nOne drawback of our method is increased memory consumption (O(z2) in the worst case). Since we memorize all distinct created redescriptions that satisfy user constraints, it is among more memory expensive approaches. Although, the estimate O(z2) is greatly exaggerated, and is in real applications at most O(z), it is currently the only approach that memorizes and uses all created redescriptions to create diverse and accurate redescription sets for the end users. If memory limit is reached, we use the GRCS procedure (called in line 8 of Algorithm 1) to create reduced redescription sets of predefined properties. Only redescriptions from these sets are retained allowing further execution of the framework.\nGreedy and the MID approaches are very memory efficient since they store only a small number of candidate redescriptions in memory. Other tree-based approaches store two decision trees at each iteration, Closed Dset (Zaki & Ramakrishnan, 2005) approach saves a closed lattice of descriptor sets and the relaxation lattice approach (Parida & Ramakrishnan, 2005) saves produced biclusters.\nThe main advantages of our approach are that it produces a large number of diverse, highly accurate redescriptions which enables our multi-objective optimization procedure to generate multiple, high quality redescription sets of differing properties that are presented to the end user."}, {"heading": "5.2. Experimental procedure", "text": "In this section we explain all parameter settings used to perform evaluations and comparisons with various redescription mining algorithms.\nFor all algorithms, we used the maximal p-value threshold of 0.01 (the strictest significance threshold). The minimal Jaccard index was set to 0.2 for the DBLP dataset based on results presented in Galbrun (2013), Table 6.1, p. 46. The same is set to 0.6 for the Bio dataset based on results in Galbrun (2013) Table 7, p. 301. The threshold 0.5 for the Country dataset was experimentally determined. Minimal support was set to 10 elements for the DBLP, based on Galbrun (2013) p.48, and the same is used for the Bio dataset. Country dataset is significantly smaller thus we set this threshold to 5 elements. Impact of changing minimal Jaccard index and minimal support is data dependant. Increasing these thresholds causes a drop in diversity of produced redescriptions, resulting in high redundancy and in some cases inadequate number of produced redescriptions. However, it also increases minimal and average redescription Jaccard index and support size. Lowering these thresholds has the opposite effect, increasing diversity but potentially reducing overall redescription accuracy or support size. Increasing maximal p-value threshold allows more redescriptions (although less significant) to be considered as candidates\nfor redescription set construction. The effects of changing minimal Jaccard index and minimal support size on the produced redescription set of size 50 by our framework on Country, Bio and DBLP dataset can be seen in Section S2.2.2 (Online resource 1).\nWe compared the CLUS-RM algorithm with the generalized redescription set construction procedure (CRMGRS), to the ReReMi, the Split trees and the Layered trees algorithms implemented in the tool called Siren (Galbrun & Miettinen, 2012c). The specific parameter values used for each redescription mining algorithm can be seen in Section S2 (Online Resource 1)."}, {"heading": "5.3. Analysis of redescription sets produced with CRMGRS", "text": "We analyse a set containing all redescriptions produced by CLUS-RM algorithm (referred to as a large set of redescriptions) and the corresponding sets of substantially smaller size constructed from this set by generalized redescription set construction procedure (referred to as reduced sets of redescriptions) on three different datasets.\nFor the purpose of this analysis, we create redescriptions without using the refinement procedure and disallow multiple redescriptions describing the same set of instances. To explore the influence of using different importance weights on properties of produced redescription sets, we use the different weight combinations given in Table 4.\n\n\nIn the rows 1, 2 and 3 of matrix W , we incrementally increase the importance weight for the Jaccard index and equally decrease the weight for the element and attribute Jaccard index in order to explore the effects of finding highly accurate redescriptions at the expense of diversity. The last row explores the opposite setting that completely disregards accuracy and concentrates on diversity.\nBy using importance weights in each row of matrices W (Table 4) and Wmiss (Table 5), we create redescription sets containing 25, 50, 75, 100, 125, 150, 175 and 200 redescriptions. We plot the change in element/attribute coverage, average redescription Jaccard index, average pvalue, average element/attribute Jaccard index and average query size against the redescription set size. Information about redescriptions in the large set is used as a baseline and compared to the quality of reduced sets."}, {"heading": "5.3.1. The analysis on the Bio dataset", "text": "We start the analysis by examining the properties of the large redescription set presented in Figure 5. In Figure 6, we compare the properties of redescriptions in the large redescription set, against properties of redescriptions in reduced sets based on different preference vectors. The results are presented only for the Bio dataset, however similar analysis for the DBLP and the Country dataset is presented in Section S2.2.3 (Online Resource 1).\nFigure 5 shows distributions of quality measures for redescriptions in the large redescription set constructed with CLUS-RM algorithm. Redescription Jaccard index is mostly in [0.6, 0.7] interval, though a noticeable number is in [0.9, 1.0]. The p-value is at most 0.01 but mainly smaller than 10\u221217. The maximum average element Jaccard index equals 0.13 and the maximum average attribute Jaccard index equals 0.14 which shows a fair level of diversity among produced redescriptions. Over 99% of redescriptions contain less than 15 attributes in both queries, and more than 50% contains less than 10 attributes in both queries which is good for understandability.\nPlots in Figure 6 contain 5 graphs demonstrating a specific property of the reduced redescription set and its change with the increase of reduced redescription set size. The Reduced k graph demonstrates properties of redescriptions contained in redescription set created with the preference weights from the k-th row ofW . The graph labelled Large set demonstrates properties of redescriptions from a redescription set containing all produced redescriptions.\nIncreasing the importance weight for a redescription Jaccard index has the desired effect on redescription accuracy in the reduced sets of various size. Large weight on this criteria leads to sets with many highly accurate but more redundant redescriptions (average element Jaccard > 0.15) with larger support (average support > 10% of the total number of elements in the dataset). Consequence of larger support is increased overall element coverage. The effect is in part the consequence of using the Bio dataset that contains a number of accurate redescriptions with high support (also discussed in (Galbrun, 2013)). This effect is not observed on the Country and the DBLP dataset (Figures S4 and S5), where element and attribute coverage is increased only with increasing diversity weights in the preference vector. The average redescription Jaccard index decreases as the reduced set size increases which is expected since the total number of redescriptions with the highest possible accuracy is mostly smaller than 200.\nUse of weights from the second row of the importance matrixW largely reduces redundancy and moderately lowers redescription accuracy in produced redescription set compared to weights that highly favour redescription accuracy. The equal weight combination provides accurate redescriptions (above large set average) that describe different subsets of elements by using different attributes (both below large set average). The average redescription support is lower as a result, around 5% of data elements. De-\nspite this, the element coverage is between 88% and 100% with the sharp increase to 98% for a set containing 50 redescriptions. The element coverage reaches 100% for sets containing at least 175 redescriptions.\nDepending on the application, it might be interesting to find different, highly accurate descriptions of the same or very similar sets of elements (thus the weights from the third row of W from Table 4 would be applied). Higher redundancy provides different characteristics that define the group. It sometimes also provides more specific information about subsets of elements of a given group.\nWe found several highly accurate redescriptions describing very similar subsets of locations on the Bio dataset by using weights from the third row of the matrix W . These\nlocations are characterized as a co-habitat of the Arctic fox and one of several other animals with some specific climate conditions. We provide two redescriptions describing a co-habitat of the Arctic fox and the Wood mouse. q1 : \u22129.5 \u2264 t\u221211 \u2264 0.9 \u2227 9.7 \u2264 t + 7 \u2264 13.4 q2 : Woodmouse \u2227 ArcticFox \u2227 \u00ac MountainHare This redescription describes 57 locations with Jaccard index 0.83. One very similar redescription describing 58 locations from which 57 are the same as above, with Jaccard index 0.87 is: q1 : \u22125.5 \u2264 t\u03032 \u2264 2.2 \u2227 6.4 \u2264 t+9 \u2264 10.6 q2 : Woodmouse \u2227 ArcticFox \u2227 \u00ac Norwaylemming\nExamples that are even more interesting can be found on the Country data where very similar sets of countries\n50 100 150 200\n0. 85\n0. 90\n0. 95\n1. 00\nReduced redescription set size\nEl em\nen t c\nov er\nag e\nReduced 1 Reduced 2 Reduced 3 Reduced 4 Large set\n50 100 150 200\n0. 2\n0. 4\n0. 6\n0. 8\n1. 0\nReduced redescription set size\nAt tri\nbu te\nc ov\ner ag\ne\nReduced 1 Reduced 2 Reduced 3 Reduced 4 Large set\ncan be described by using different trading and general country properties. The example can be seen in Section S2.1.3, Figure S11 (Online Resource 1)."}, {"heading": "5.3.2. Using the redescription variability index on the Country dataset", "text": "We analyse the impact of missing values to redescription creation and use newly defined redescription variability index (RW ), in the context of generalized set generation, on the Country dataset with a weight matrix shown in Table 5. The variability weight is gradually increased while other weights are equally decreased to keep the sum equal to 1.0 (which is convenient for interpretation).\nThe change in variability index depending on a reduced set size and comparison with the large set can be seen in Figure 7.\nAs expected, increasing the importance weight for redescription variability favours selecting more stable redescriptions to the changes in missing values.\nTo demonstrate the effects of variability index to redescription accuracy, we plot graphs comparing averages of optimistic, query non-missing and pessimistic Jaccard index for every row of the weight matrix for different reduced set sizes. The results for row 1 and row 4 can be\nseen in Figures 8 and 9. Plots for reduced sets obtained with importance weights from the 2., the 3. and the 5. row of Wmiss are available in Figure S12 (Online resource 1).\nIncreasing the weight on the variability index has the desired effect of reducing the difference between values of different Jaccard index measures. However, the average optimistic and query non-missing Jaccard index values in the reduced sets drop as a result. Redescription with Jqnm = Jpess = Jopt = 1.0: q1 : 3.6 \u2264MORT \u2264 4.1 \u2227 25.9 \u2264 RUR_POP \u2264 38.4 \u2227 58.8 \u2264 LABOR_PARTICIP_RATE \u2264 61.1 q2 : 68.0 \u2264 E23 \u2264 79.0 \u2227 0.7 \u2264 E/I104 \u2264 4.4 \u2227 0.9 \u2264 E/I50 \u2264 1.5 is highly accurate and stable redescription constructed by CRM-GRS with the importance weight from the fourth\nrow of a matrix Wmiss. It is statistically significant with the p-value smaller than 10\u221217.\nRedescriptions exist for which Jqnm = Jopt and Jpess < Jopt. In such cases, the drop in accuracy from Jopt to Jpess occurs because a number of elements exist in the dataset for which membership in the support of neither redescription query can be determined, due to missing values. Optimizing pessimistic Jaccard index is very strict and can discard some potentially significant redescriptions such as: q1 : 5.6 \u2264 EMPL_BAD \u2264 18.2 \u2227 2.9 \u2264MORT \u2264 4.5 \u2227 2.0 \u2264 AGR_EMP \u2264 10.5 \u2227 \u22122.4 \u2264 BAL \u2264 10.1 q2 : 1.1 \u2264 E/I85 \u2264 3.1 \u2227 93.0 \u2264 E97 \u2264 98.0. This redescription has Jqnm = Jopt = 1.0 and Jpess = 0.48. With the variability index of 0.52 it describes all elements that can be evaluated by at least one redescription query with the highest possible accuracy.\nThis example motivates optimizing query non-missing Jaccard with positive weight on the variability index. It is especially useful when small number of highly accurate redescriptions can be found and when a large percentage of missing values is present in the data."}, {"heading": "5.4. Evaluating the conjunctive refinement procedure", "text": "The next step is to evaluate the conjunctive refinement procedure and its effects on the overall redescription accuracy. We use the same experimental set-up as in Section 5.3 for both sets with the addition of the minimum refinement Jaccard index parameter, which was set to 0.4 on the Bio dataset and 0.1 on the Country and the DBLP dataset. The algorithm requires the initial clusters to start the mining process as explained in Section 3.1.1 and in (Mihel\u010di\u0107 et al., 2015b). To maintain the initial conditions, we create one set of initial clusters and use them to create redescriptions with and without the conjunctive refinement procedure. Since we use PCTs with the same initial random generator seed in both experiments, the differences between sets are the result of applying the conjunctive refinement procedure. The effects of using conjunctive refinement are examined on sets containing all redescriptions produced by CLUS-RM and on reduced sets created with equal importance weights by the generalized redescription set construction procedure (Row 1 in matrix W ).\nThe effects of using the refinement procedure on redescription accuracy are demonstrated in comparative histogram (Figure 10) showing the distribution of redescription Jaccard index in a set created by CLUS-RM with and without the refinement procedure.\nCLUS-RM produced 7413 redescriptions, satisfying constraints from Section 5.2, without the refinement procedure and 10472 redescriptions with the refinement procedure. The substantial increase in redescriptions satisfying user-defined constraints, when the conjunctive refinement procedure is used, is accompanied by significant improvement in redescription accuracy.\nWe performed the one-sided independent 2-group MannWhitney U test with the null hypothesis that there is\na probability of 0.5 that an arbitrary redescription (Rr) from a set obtained by using conjunctive refinement has the Jaccard index larger than the arbitrary redescription (Rnr) from a set obtained without using the conjunctive refinement procedure (P (J(Rr) > J(Rnr)) = 0.5). The p-value of 2.2 \u00b7 10\u221216 lead us to reject the null hypothesis with the level of significance 0.01 and conclude that P (J(Rr) > J(Rnr)) > 0.5 must be true.\nAnother useful property of the conjunctive refinement procedure is that it preserves the size of redescription support. The comparative distribution of redescription supports between the sets is shown in Figure 11.\nMajority of 3059 redescriptions that entered the redescription set because of the improvements made by the conjunctive refinement have supports in the interval [10, 500] elements. Because of that, the average support size in the redescription set obtained by using the refinement procedure (217.98) is lower than that obtained without the refinement procedure (263.63). The change in distribution is significant, as shown by the one-sided independent 2- group Mann-Whitney U test. The test rejects the hypothesis P (|supp(Rnr)| > |supp(Rr)|) = 0.5 with the level of significance 0.01 (p-value equals 2.4 \u00b7 10\u221214), thus showing that P (|supp(Rnr)| > |supp(Rr)|) > 0.5.\nUsing the conjunctive refinement procedure improves redescription accuracy and adds many new redescriptions to the redescription set. However, since the reduced sets are presented to the user, it is important to see if higher quality reduced sets can be created from the large set by using the conjunctive refinement procedure compared to the set obtained without using the procedure.\nWe plot comparative distributions for all defined redescription measures for reduced sets extracted from the redescription set obtained with (CLRef ) and without (CLNRef ) the conjunctive refinement procedure. The comparison made on the sets containing 200 redescriptions is presented in Figure 12. The boxplots representing distributions of supports show that the redescription construction procedure extracts redescriptions of various support sizes, which was intended to prevent focusing only on large or small redescriptions based on redescription accuracy.\nWe compute the one-sided independent 2-group MannWhitney U test on the reduced sets for the redescription Jaccard index (J) and the normalized redescription query size (RQS) since there seem to be a difference in distributions as observed from Figure 12. For other measures, we compute the two-sided Mann-Whitney U test to assess if there is any notable difference in values between the sets.\nThe null hypothesis that P (J(Rr) > J(Rnr)) = 0.5 is rejected with the p-value smaller than 2.2 \u00b7 10\u221216 < 0.01, thus the alternative hypothesis P (J(Rr) > J(Rnr)) > 0.5 holds. The difference in support between two sets is not statistically significant (p-value equals 0.21, obtained with the two-sided test). Distributions of redescription p-values are identical because all redescriptions have equal p-value: 0.0. The difference in average attribute/element Jaccard index is also not statistically significant (p-values 0.88 and 0.13 respectively obtained with the two-sided test). The pvalue for the null hypothesis P (RQS(Rnr) < RQS(Rr)) = 0.5 equals 5.25\u00b710\u22126 < 0.01 thus the alternative hypothesis P (RQS(Rnr) < RQS(Rr)) > 0.5 holds.\nThe refinement procedure enables constructing reduced sets containing more accurate redescriptions with the average Jaccard index increasing from 0.72, for reduced set obtained without using refinement procedure, to 0.82 for reduced set obtained when refinement procedure is used. This improvement sometimes increases redescription complexity, albeit this is limited on average to having less than 1 additional attribute in redescription queries.\nThe set produced by using the conjunctive refinement procedure has the element coverage of 0.9996 and the attribute coverage of 0.7613 compared to the set where this procedure was not used where the element coverage is 1.0 and the attribute coverage is 0.7243.\nThe conjunctive refinement procedure also significantly increases redescription accuracy on the DBLP and the Country dataset. Equivalent analysis for these datasets is performed in Section S2.3 (Online Resource 1)."}, {"heading": "5.5. Comparisons with other state of the art redescription mining algorithms.", "text": "In this section, we present the comparative results of redescription set quality produced by our framework (CRMGRS) compared to the state of the art algorithms: the ReReMi Galbrun & Miettinen (2012b), the Split trees and the Layered trees Zinchenko (2014). To perform the experiments, we used the implementation of the ReReMi, the Split trees and the Layered trees algorithm within the tool Siren (Galbrun & Miettinen, 2012c).\nThe ReReMi algorithm was already compared in (Galbrun & Miettinen, 2012b) with the CartWheels algorithm (Ramakrishnan et al., 2004) (on a smaller version of a DBLP and the Bio dataset), with the association rule mining approach obtained by the ECLAT frequent itemset miner (Zaki, 2000) and the greedy approach developed by Gallo et al. (2008). The approach from Zaki & Ramakrishnan (2005), which is also related, works only with boolean attributes and have no built in mechanism to differentiate different views. Redescription mining on the DBLP dataset with the original implementation of the algorithm1 returned 49 redescriptions, however they only describe authors by using co-authorship network. Since, our goal is to describe authors by their co-authorship network and provide the information about the conferences they have published in, these redescriptions are not used in our evaluation. To use the approach on the Bio dataset, we first applied the Discretize filter in weka2 to obtain nominal attributes. Then, we applied NominalToBinary filter to obtain binary attributes that can be used in Charm-L. As a result, the number of attributes on the Bio dataset increased to 1679 making the process of constructing a lattice of closed itemsets to demanding with respect to execution time constraints. The Country dataset contains missing values which are not supported by this approach.\nSince there is an inherent difference in the number of created redescriptions, depending on the type of logical operators used to create them, between CLUS-RM and the comparative algorithms, we split the algorithm comparison in two parts. First, we compare redescription properties created by using all logical operators and then redescriptions created by using only the conjunction and the negation operator (Bio and DBLP dataset) or only by using the conjunction operator (Country dataset).\nAfter obtaining redescriptions with the algorithms implemented in the tool Siren (Galbrun & Miettinen, 2012c), with parameters specified in Section 5.2, we used the Filter redundant redescriptions option to remove duplicate and redundant redescriptions. Since SplitTrees and LayeredTrees algorithms always use all logical operators to create redescriptions, we created a redescription set with these approaches and filtered out redescriptions containing the disjunction operator in at least one of its queries.\nFor each obtained redescription set from the ReReMi, the Split trees and the Layered trees algorithm, we extracted a redescription set of the same size with the generalized redescription set procedure with equal weight importance for each redescription criteria. These sets are extracted from a large set created with the CLUS-RM algorithm with the parameters specified in Section 5.2.\nWe plot pairwise comparison boxplots for each redescription measure comparing the performance of our framework with the three chosen approaches.\n1http://www.cs.rpi.edu/~zaki/www-new/pmwiki.php/ Software/Software\n2http://www.cs.waikato.ac.nz/ml/weka/\nFor each comparison we analyse the hypothesis about the distributions by using the one-sided independent 2- group Mann-Whitney U test (see summary in Table 6)."}, {"heading": "5.5.1. Comparison on the Bio dataset", "text": "First, we compare the algorithms on the Bio dataset. Figures 13, 14 and Table 6 show that the set produced by CRM-GRS tend to contain more accurate redescriptions on the Bio dataset when the conjunction and the negation operators are allowed and when the conjunctive refinement procedure is used compared to all other approaches.\nThe results are significant at the significance level of 0.01, except for the case of ReReMi when all logical operators were allowed and refinement procedure was not used in the CLUS-RM algorithm. Redescriptions contained in redescription sets produced by CRM-GRS tend to have smaller p-values compared to redescriptions produced by other tree - based algorithms (statistically significant with the significance level of 0.05). Redescription sets created by CRM-GRS tend to contain redescriptions with smaller\nelement/attribute Jaccard index (redundancy) and smaller query size (the difference is statistically significant with the significance level of 0.01 with the exception of a set created by CRM-GRS, when conjunctive refinement procedure was not used in CLUS-RM, compared to the set created by Layered trees algorithm).\nElement and attribute coverage analysis for all approaches is provided in Section S2.5.1 (Online Resource 1). This analysis suggests that despite smaller average redescription support, our framework has comparable performance with respect to element and attribute coverage.\nAs already discussed in (Galbrun, 2013), the ReReMi algorithm has a drift towards redescriptions with large supports on the Bio dataset. The consequence is a large element redundancy among produced redescriptions. The Split trees and the Layered trees algorithms produce redescriptions in the whole support range, though majority of produced redescriptions still have a very high support resulting in large element redundancy. Our approach returns redescriptions with various support size as can be\nseen from Figures 13 and 14 though majority of produced redescriptions are very close to the minimal allowed support. However, if needed, the minimal support can be adjusted to produce sets containing redescriptions that describe larger sets of elements. It is also possible to produce multiple sets, each being produced with different minimal and maximal support bounds. Also, by adjusting the importance weights to highly favour Jaccard index, the user can produce reduced sets with similar properties as those produced by the ReReMi, the Layered trees and the Split trees. The distribution of support size in the large redescription set produced with the basic variant of CLUSRM algorithm on the Bio dataset can be seen in Figure 5. The increase in accuracy obtainable by using different weights to construct reduced sets can be seen in Figure 6.\nRedescription sets produced with the Layered and the Split trees algorithms do not create enough redescriptions containing only conjunction and negation operator in its queries to make the distribution analysis. The Layered trees algorithm produced only one redescription with Jaccard index 0.62 and the Split trees algorithm created four redescriptions with Jaccard index 0.97, 0.65, 0.7 and 0.78. On the other hand, the CLUS-RM with the conjunctive refinement procedure created over 14000 redescriptions containing only conjunction and negation in the queries with the Jaccard index greater than 0.6 from which 73 redescriptions have Jaccard index 1.0.\nOur framework complements the existing approaches which is visible from redescription examples found by our approach that were not discovered by other algorithms. Section S2.5.1 (Online Resource 1) contains one example of very similar redescription, found by the ReReMi and the CRM-GRS, and several redescriptions discovered by CRM-GRS that were not found by other approaches."}, {"heading": "5.5.2. Comparison on the DBLP dataset", "text": "The DBLP dataset is very sparse and all redescription mining algorithms we tested only returned a very small number of highly accurate redescriptions. Half of the redescription mining runs we performed with different algorithms returned to small number of redescriptions to perform a statistical analysis. On this dataset, we can compare quality measure distributions of redescriptions produced by our framework only with the ReReMi algorithm (Figure 15), and with the Split trees algorithm when all operators are used to construct redescription queries. (Figure 16). CRM-GRS tends to produce redescriptions with smaller query size than the ReReMi and the Split trees algorithms when all the operators are allowed. The redescriptions contained in the reduced set produced by our framework tend to have higher support than those produced by the Split trees algorithm. The distribution analysis on sets created by using only conjunction and negation logical operators can be performed only against the ReReMi algorithm due to small number of redescriptions produced by the other approaches. In this case, CRM-GRS tends to produce more accurate redescriptions (significant at the\nsignificance level of 0.01 when the conjunctive refinement is used and at the significance level of 0.05 when conjunctive refinement is not used). In both cases, our framework produces redescriptions that tend to have larger support (significant with the level of 0.01). There is a more pronounced difference between the Split trees algorithm and CRM-GRS when all the operators are allowed. In this case, the Split trees algorithm has higher median in distribution of redescription accuracy.\nThe Layered trees approach produced 7 redescriptions using all operators, with accuracy 0.85, 0.81, 0.71, 0.73, 0.23, 0.23, 0.2 describing 10 to 48 authors. It produced 3 redescriptions using only conjunction and negation operators. The produced redescriptions had the accuracy 0.23, 0.22, 0.2 and the support 45 to 48 authors. The Split trees algorithm produced only one redescription with accuracy 0.33 and support 13 using only conjunction and negation operators.\nThe most accurate redescriptions produced by each algorithm and a short discussion can be seen in Section S2.5.2\n(Online Resource 1)."}, {"heading": "5.5.3. Comparison on the Country dataset", "text": "Comparisons on the Country dataset are preformed only with the ReReMi algorithm since it is the only algorithm, besides CLUS-RM, that can work on datasets containing missing values. Techniques for value imputation must be used before other approaches can be applied. Using these techniques introduces errors in the descriptions and violates a property of descriptions being valid for each element in redescription support. Because of that, we chose not to pursue this line of research.\nSince our framework optimizes the query non-missing Jaccard index and the ReReMi optimizes pessimistic Jaccard index, we decided to make comparisons using both measures (Figure 17 and Figure 18). We extract two sets with CRM-GRS, for each we use different Jaccard index as one of the quality criteria. Redescriptions produced by the ReReMi remain unchanged but we compute the query non-missing Jaccard for each redescription which causes redescription accuracy to rise. Optimizing pessimistic Jac-\ncard seems like the best option for comparisons since then the query non-missing Jaccard index necessarily increases and the redescription support is preserved.\nResults from Table 6 show that CRM-GRS produces redescription set that tends to contain more accurate redescriptions when conjunction refinement procedure is used. The result is significant at the significance level 0.01. However, it failed to produce such set using all operators when pessimistic Jaccard index is used to evaluate redescription accuracy (redescription set produced by ReReMi has higher median in accuracy). Although, CRMGRS produced a few redescriptions with higher accuracy than those produced by the ReReMi. When query nonmissing Jaccard index is used as accuracy evaluation criteria, CRM-GRS tends to create more accurate redescriptions than the ReReMi (statistically significant at the significance level 0.01). When using only conjunction logical operator, the ReReMi tends to produce redescriptions with\nsmaller support compared to CRM-GRS if conjunctive refinement procedure is not used.\nAnalysis of element and attribute coverage is provided in Section S2.5.3 (Online Resource 1).\nThe ReReMi algorithm found 2 redescriptions with Jpess = 1.0 while CRM-GRS created redescription set containing 4 redescriptions with Jpess = 1.0 when only conjunction operators are allowed and 5 redescriptions when all operators are allowed.\nThe analysis of comparative redescription examples produced by CRM-GRS and the ReReMi algorithm can be seen in Section S2.5.3 (Online Resource 1).\nThe ReReMi produced 14 redescriptions with Jqnm = 1.0 using only conjunction operators while redescription sets constructed by CRM-GRS contain 34 out of 36 redescriptions with Jqnm = 1.0 without using conjunctive refinement and 36 out of 36 redescriptions with Jqnm = 1.0 with the use of conjunctive refinement procedure. When\nall logical operators were used to create redescriptions, the ReReMi creates large number of disjunction based redescriptions, many of which are quite complex.\nThe difference in support size of redescriptions produced by CRM-GRS compared to those produced by the ReReMi algorithm, visible in Figures 17 and 18 when all operators are used is in part the consequence of CRM-GRS using high weight on element diversity but is also connected to different logic in using the disjunction operator. CRMGRS allows improving Jaccard index, by using disjunctions, only for redescriptions satisfying a predefined accuracy threshold. Highly overlapping subsets of instances are thus complemented with subsets that are highly overlapping with one of the already existing subset of instances. Because of this, our framework eliminates descriptions of unrelated subsets of instances that occasionally occur in ReReMi\u2019s descriptions as a result of using disjunction operator (discussed in (Galbrun, 2013))."}, {"heading": "6. Conclusions", "text": "We have presented a redescription mining framework CRM-GRS which integrates the generalized redescription set construction procedure with the CLUS-RM algorithm (Mihel\u010di\u0107 et al., 2015a,b).\nThe main contribution of this work is the generalized redescription set construction procedure that allows creating multiple redescription sets of reduced size with different properties defined by the user. These properties are influenced by the user through importance weights on different redescription criteria. Use of the scalarization technique developed in multi - objective optimization guarantees that, at each step, one non-dominated redescription is added to the redescription set under construction. The generalized redescription set construction procedure has lower worst time complexity than existing redescription mining algorithms so it may be preferred choice over the multiple runs of these algorithms. The procedure allows creating sets of different size with different redescription properties. These features generally lack in current redescription mining approaches, where users are forced to experiment with individual algorithm parameters in order to obtain desirable set of redescriptions. Finally, the procedure allows using ensembles of redescription mining algorithms to create reduced sets with superior properties compared to those produced by individual algorithms.\nThe second contribution is related to increasing overall redescription accuracy. Here, we build upon our previous work on CLUS-RM algorithm and provide new - conjunctive refinement procedure, that significantly enlarges and improves the accuracy of redescriptions in the baseline redescription set by combining candidate redescriptions during the generation process. This procedure can be easily applied in the context of majority of other redescription mining algorithms, thus we consider it as a generally useful contribution to the field of redescription mining.\nFinally, we motivate the use of query non-missing Jaccard index, introduced in (Mihel\u010di\u0107 et al., 2015b), when data contains missing values. We show that using pessimistic Jaccard index eliminates some potentially useful, high quality redescriptions obtainable by using query nonmissing Jaccard index. To further increase the possibilities of redescription mining algorithms, we introduce the redescription variability index that allows extracting stable redescriptions in the context of missing data, by combining the upper and lower bound on estimates of Jaccard index.\nThe evaluation of our framework with 3 different state of the art algorithms on 3 different real-world datasets shows that our framework significantly outperforms other approaches in redescription accuracy in majority of cases. In particular in settings when only conjunction and negation operators are used in redescriptions, which is the preferred setting from the point of understandability. In general, CRM-GRS produces more understandable redescriptions (due to smaller query size and extensive use of conjunction operator), it is more flexible and in majority of comparisons more accurate approach to mine redescriptions from datasets. Moreover, we demonstrated that it complements existing approaches in the discovered redescriptions and solves several problems of existing approaches (mainly the problem of support drift and redescriptions connecting unrelated parts of element space by using disjunctions). The framework is easily extendible with new redescription criteria and allows combining results of different redescription mining algorithms to create reduced sets with superior properties with respect to different redescription quality criteria."}, {"heading": "Acknowledgement", "text": "The authors would like to acknowledge the European Commission\u2019s support through the MAESTRA project (Gr. no. 612944), the MULTIPLEX project (Gr.no. 317532), and support of the Croatian Science Foundation (Pr. no. 9623: Machine Learning Algorithms for Insightful Analysis of Complex Data Structures)."}], "references": [{"title": "Fast discovery of association rules", "author": ["R. Agrawal", "H. Mannila", "R. Srikant", "H. Toivonen", "A.I. Verkamo"], "venue": null, "citeRegEx": "Agrawal et al\\.,? \\Q1996\\E", "shortCiteRegEx": "Agrawal et al\\.", "year": 1996}, {"title": "Detecting group differences: Mining contrast sets", "author": ["S.D. Bay", "M.J. Pazzani"], "venue": "Data Mining and Knowledge Discovery,", "citeRegEx": "Bay and Pazzani,? \\Q2001\\E", "shortCiteRegEx": "Bay and Pazzani", "year": 2001}, {"title": "Multi-view clustering", "author": ["S. Bickel", "T. Scheffer"], "venue": "In Proceedings of the 4th IEEE International Conference on Data Mining (ICDM 2004),", "citeRegEx": "Bickel and Scheffer,? \\Q2004\\E", "shortCiteRegEx": "Bickel and Scheffer", "year": 2004}, {"title": "Top-down induction of firstorder logical decision trees", "author": ["H. Blockeel", "L. De Raedt"], "venue": "Artif. Intell.,", "citeRegEx": "Blockeel and Raedt,? \\Q1998\\E", "shortCiteRegEx": "Blockeel and Raedt", "year": 1998}, {"title": "Ranking and selecting association rules based on dominance relationship", "author": ["S. Bouker", "R. Saidi", "S.B. Yahia", "E.M. Nguifo"], "venue": "In Proceedings of the 24th IEEE International Conference on Tools with Artificial Intelligence,", "citeRegEx": "Bouker et al\\.,? \\Q2012\\E", "shortCiteRegEx": "Bouker et al\\.", "year": 2012}, {"title": "Frequent closures as a concise representation for binary data mining", "author": ["Boulicaut", "J.-F", "A. Bykowski"], "venue": "In Proceedings of the 4th Pacific-Asia Conference on Knowledge Discovery and Data Mining, Current Issues and New Applications (PAKDD", "citeRegEx": "Boulicaut et al\\.,? \\Q2000\\E", "shortCiteRegEx": "Boulicaut et al\\.", "year": 2000}, {"title": "Multi-objective Management in Freight Logistics: Increasing Capacity, Service Level and Safety with Optimization Algorithms", "author": ["M. Caramia", "P. Dell\u2019Olmo"], "venue": null, "citeRegEx": "Caramia and Dell.Olmo,? \\Q2008\\E", "shortCiteRegEx": "Caramia and Dell.Olmo", "year": 2008}, {"title": "Note on grouping", "author": ["D.R. Cox"], "venue": "Journal of the American Statistical Association, 52 , 543\u2013547.", "citeRegEx": "Cox,? 1957", "shortCiteRegEx": "Cox", "year": 1957}, {"title": "DBLP dataset", "author": ["DBLP"], "venue": "URL: http://dblp.uni-trier.de/db accessed March 2010.", "citeRegEx": "DBLP,? 2010", "shortCiteRegEx": "DBLP", "year": 2010}, {"title": "Efficient mining of emerging patterns: Discovering trends and differences", "author": ["G. Dong", "J. Li"], "venue": "In Proceedings of the 5th ACM SIGKDD International Conference on Knowledge Discovery and Data Mining (KDD", "citeRegEx": "Dong and Li,? \\Q1999\\E", "shortCiteRegEx": "Dong and Li", "year": 1999}, {"title": "Knowledge acquisition via incremental conceptual clustering", "author": ["D.H. Fisher"], "venue": "Mach. Learn., 2 , 139\u2013172. doi:10.1023/A: 1022852608280.", "citeRegEx": "Fisher,? 1987", "shortCiteRegEx": "Fisher", "year": 1987}, {"title": "On Grouping for Maximum Homogeneity", "author": ["W.D. Fisher"], "venue": "Journal of the American Statistical Association, 53 . doi:10.2307/ 2281952.", "citeRegEx": "Fisher,? 1958", "shortCiteRegEx": "Fisher", "year": 1958}, {"title": "Methods for Redescription Mining", "author": ["E. Galbrun"], "venue": "Ph.D. thesis University of Helsinki Finland.", "citeRegEx": "Galbrun,? 2013", "shortCiteRegEx": "Galbrun", "year": 2013}, {"title": "Finding relational redescriptions", "author": ["E. Galbrun", "A. Kimmig"], "venue": "Machine Learning,", "citeRegEx": "Galbrun and Kimmig,? \\Q2013\\E", "shortCiteRegEx": "Galbrun and Kimmig", "year": 2013}, {"title": "A case of visual and interactive data analysis: Geospatial redescription mining", "author": ["E. Galbrun", "P. Miettinen"], "venue": "In Instant Interactive Data Mining Workshop", "citeRegEx": "Galbrun and Miettinen,? \\Q2012\\E", "shortCiteRegEx": "Galbrun and Miettinen", "year": 2012}, {"title": "From black and white to full color: extending redescription mining outside the boolean world", "author": ["E. Galbrun", "P. Miettinen"], "venue": "Statistical Analysis and Data Mining,", "citeRegEx": "Galbrun and Miettinen,? \\Q2012\\E", "shortCiteRegEx": "Galbrun and Miettinen", "year": 2012}, {"title": "Siren: An interactive tool for mining and visualizing geospatial redescriptions", "author": ["E. Galbrun", "P. Miettinen"], "venue": "In Proceedings of the 18th ACM SIGKDD International Conference on Knowledge Discovery and Data Mining (KDD", "citeRegEx": "Galbrun and Miettinen,? \\Q2012\\E", "shortCiteRegEx": "Galbrun and Miettinen", "year": 2012}, {"title": "Finding subgroups having several descriptions: Algorithms for redescription mining", "author": ["A. Gallo", "P. Miettinen", "H. Mannila"], "venue": "In Siam Conference on Data Mining (SDM", "citeRegEx": "Gallo et al\\.,? \\Q2008\\E", "shortCiteRegEx": "Gallo et al\\.", "year": 2008}, {"title": "Expert-guided subgroup discovery: Methodology and application", "author": ["D. Gamberger", "N. Lavrac"], "venue": "J. Artif. Intell. Res. (JAIR),", "citeRegEx": "Gamberger and Lavrac,? \\Q2002\\E", "shortCiteRegEx": "Gamberger and Lavrac", "year": 2002}, {"title": "Multilayer clustering: A discovery experiment on country level trading data", "author": ["D. Gamberger", "M. Mihel\u010di\u0107", "N. Lavra\u010d"], "venue": "In Proceedings of the 17th International Conference on Discovery Science (DS", "citeRegEx": "Gamberger et al\\.,? \\Q2014\\E", "shortCiteRegEx": "Gamberger et al\\.", "year": 2014}, {"title": "The Minimum Description Length Principle (Adaptive Computation and Machine Learning)", "author": ["P.D. Gr\u00fcnwald"], "venue": "The MIT Press.", "citeRegEx": "Gr\u00fcnwald,? 2007", "shortCiteRegEx": "Gr\u00fcnwald", "year": 2007}, {"title": "Declarative heuristic search for pattern set mining", "author": ["T. Guns", "S. Nijssen", "A. Zimmermann", "L.D. Raedt"], "venue": "ICDM Workshops (pp. 1104\u20131111)", "citeRegEx": "Guns et al\\.,? \\Q2011\\E", "shortCiteRegEx": "Guns et al\\.", "year": 2011}, {"title": "An overview on subgroup discovery: foundations and applications", "author": ["F. Herrera", "C.J. Carmona", "P. Gonz\u00e1lez", "M.J. Jesus"], "venue": "Knowledge and Information Systems,", "citeRegEx": "Herrera et al\\.,? \\Q2010\\E", "shortCiteRegEx": "Herrera et al\\.", "year": 2010}, {"title": "Very high resolution interpolated climate surfaces for", "author": ["R.J. Hijmans", "S.E. Cameron", "J.L. Parra", "P.G. Jones", "A. Jarvis"], "venue": null, "citeRegEx": "Hijmans et al\\.,? \\Q2005\\E", "shortCiteRegEx": "Hijmans et al\\.", "year": 2005}, {"title": "Algorithms for association rule mining \u2014 a general survey and comparison", "author": ["J. Hipp", "U. G\u00fcntzer", "G. Nakhaeizadeh"], "venue": "SIGKDD Explor. Newsl.,", "citeRegEx": "Hipp et al\\.,? \\Q2000\\E", "shortCiteRegEx": "Hipp et al\\.", "year": 2000}, {"title": "Data clustering: A review", "author": ["A.K. Jain", "M.N. Murty", "P.J. Flynn"], "venue": "ACM Comput. Surv.,", "citeRegEx": "Jain et al\\.,? \\Q1999\\E", "shortCiteRegEx": "Jain et al\\.", "year": 1999}, {"title": "Explora: A multipattern and multistrategy discovery assistant", "author": ["W. Kl\u00f6sgen"], "venue": "U. M. Fayyad, G. Piatetsky-Shapiro, P. Smyth, & R. Uthurusamy (Eds.), Advances in Knowledge Discovery and Data Mining (pp. 249\u2013271). Menlo Park, CA, USA: American Association for Artificial Intelligence.", "citeRegEx": "Kl\u00f6sgen,? 1996", "shortCiteRegEx": "Kl\u00f6sgen", "year": 1996}, {"title": "Tree ensembles for predicting structured outputs", "author": ["D. Kocev", "C. Vens", "J. Struyf", "S. D\u017eeroski"], "venue": "Pattern Recognition,", "citeRegEx": "Kocev et al\\.,? \\Q2013\\E", "shortCiteRegEx": "Kocev et al\\.", "year": 2013}, {"title": "Subgroup discovery with cn2-sd", "author": ["N. Lavra\u010d", "B. Kav\u0161ek", "P. Flach", "L. Todorovski"], "venue": "J. Mach. Learn. Res.,", "citeRegEx": "Lavra\u010d et al\\.,? \\Q2004\\E", "shortCiteRegEx": "Lavra\u010d et al\\.", "year": 2004}, {"title": "Association discovery in two-view data", "author": ["M. van Leeuwen", "E. Galbrun"], "venue": "IEEE Trans. Knowl. Data Eng.,", "citeRegEx": "Leeuwen and Galbrun,? \\Q2015\\E", "shortCiteRegEx": "Leeuwen and Galbrun", "year": 2015}, {"title": "Exceptional model mining. In Proceedings of the European Conference on Machine Learning and Knowledge Discovery in Databases - Part II (ECML-PKDD", "author": ["D. Leman", "A. Feelders", "A. Knobbe"], "venue": null, "citeRegEx": "Leman et al\\.,? \\Q2008\\E", "shortCiteRegEx": "Leman et al\\.", "year": 2008}, {"title": "Knowledge acquisition through conceptual clustering: A theoretical framework and an algorithm for partitioning data into conjunctive concepts", "author": ["R.S. Michalski"], "venue": "Journal of Policy Analysis and Information Systems, 4 , 219\u2013244.", "citeRegEx": "Michalski,? 1980", "shortCiteRegEx": "Michalski", "year": 1980}, {"title": "Redescription mining with multi-label predictive clustering trees", "author": ["M. Mihel\u010di\u0107", "S. D\u017eeroski", "N. Lavra\u010d", "T. \u0160muc"], "venue": "In Proceedings of the 4h workshop on New Frontiers in Mining Complex Patterns (NFMCP", "citeRegEx": "Mihel\u010di\u0107 et al\\.,? \\Q2015\\E", "shortCiteRegEx": "Mihel\u010di\u0107 et al\\.", "year": 2015}, {"title": "Redescription mining with multi-target predictive clustering trees. In New Frontiers in Mining Complex Patterns - 4th International Workshop, NFMCP 2015, Held in Conjunction with ECMLPKDD", "author": ["M. Mihel\u010di\u0107", "S. D\u017eeroski", "N. Lavra\u010d", "T. \u0160muc"], "venue": "Revised Se-", "citeRegEx": "Mihel\u010di\u0107 et al\\.,? \\Q2015\\E", "shortCiteRegEx": "Mihel\u010di\u0107 et al\\.", "year": 2015}, {"title": "Interset: Interactive redescription set exploration", "author": ["M. Mihel\u010di\u0107", "T. \u0160muc"], "venue": "In Proceedings of the 19th International Conference on Discovery Science (DS", "citeRegEx": "Mihel\u010di\u0107 and \u0160muc,? \\Q2016\\E", "shortCiteRegEx": "Mihel\u010di\u0107 and \u0160muc", "year": 2016}, {"title": "The Atlas of European Mammals", "author": ["A. Mitchell-Jones"], "venue": "Poyser natural history. T & AD Poyser. URL: www.european-mammals. org.", "citeRegEx": "Mitchell.Jones,? 1999", "shortCiteRegEx": "Mitchell.Jones", "year": 1999}, {"title": "Supervised descriptive rule discovery: A unifying survey of contrast set, emerging pattern and subgroup mining", "author": ["P.K. Novak", "N. Lavra\u010d", "G.I. Webb"], "venue": "J. Mach. Learn. Res.,", "citeRegEx": "Novak et al\\.,? \\Q2009\\E", "shortCiteRegEx": "Novak et al\\.", "year": 2009}, {"title": "A belief-driven method for discovering unexpected patterns", "author": ["B. Padmanabhan", "A. Tuzhilin"], "venue": "In Proceedings of the 4th International conference on Knowledge Discovery and Data Mining (KDD", "citeRegEx": "Padmanabhan and Tuzhilin,? \\Q1998\\E", "shortCiteRegEx": "Padmanabhan and Tuzhilin", "year": 1998}, {"title": "Redescription mining: Structure theory and algorithms", "author": ["L. Parida", "N. Ramakrishnan"], "venue": "In Proceedings of the 20th National Conference on Artificial Intelligence and the 17th Innovative Applications of Artificial Intelligence Conference, July 9-13,", "citeRegEx": "Parida and Ramakrishnan,? \\Q2005\\E", "shortCiteRegEx": "Parida and Ramakrishnan", "year": 2005}, {"title": "Discovering frequent closed itemsets for association rules", "author": ["N. Pasquier", "Y. Bastide", "R. Taouil", "L. Lakhal"], "venue": "In Proceedings of the 7th International Conference on Database Theory (ICDT", "citeRegEx": "Pasquier et al\\.,? \\Q1999\\E", "shortCiteRegEx": "Pasquier et al\\.", "year": 1999}, {"title": "Algorithms for Multi-Target Learning (Algoritmes voor het leren van multi-target modellen)", "author": ["B. Piccart"], "venue": "Ph.D. thesis Katholieke Universiteit Leuven Belgium.", "citeRegEx": "Piccart,? 2012", "shortCiteRegEx": "Piccart", "year": 2012}, {"title": "Turning CARTwheels: An alternating algorithm for mining redescriptions", "author": ["N. Ramakrishnan", "D. Kumar", "B. Mishra", "M. Potts", "R.F. Helm"], "venue": "In Proceedings of the 10th ACM SIGKDD International Conference on Knowledge Discovery and Data Mining (KDD", "citeRegEx": "Ramakrishnan et al\\.,? \\Q2004\\E", "shortCiteRegEx": "Ramakrishnan et al\\.", "year": 2004}, {"title": "The information bottleneck method", "author": ["N. Tishby", "F. Pereira", "W. Bialek"], "venue": "In Proceedings of the 37th Annual Allerton Conference on Communication, Control and Computing (pp. 368\u2013377)", "citeRegEx": "Tishby et al\\.,? \\Q1999\\E", "shortCiteRegEx": "Tishby et al\\.", "year": 1999}, {"title": "On subjective measures of interestingness in knowledge discovery", "author": ["A. Tuzhilin"], "venue": "Proceedings of the 1st International Conference on Knowledge Discovery and Data Mining, (KDD 1995), Quebec, Canada (pp. 275\u2013281). AAAI Press.", "citeRegEx": "Tuzhilin,? 1995", "shortCiteRegEx": "Tuzhilin", "year": 1995}, {"title": "Unctad database", "author": ["UNCTAD"], "venue": "URL: http://unctad.org/en/ Pages/Statistics.aspx accessed October 2013.", "citeRegEx": "UNCTAD,? 2014", "shortCiteRegEx": "UNCTAD", "year": 2014}, {"title": "Multi-view clustering and feature learning via structured sparsity", "author": ["H. Wang", "F. Nie", "H. Huang"], "venue": "In Proceedings of the 30th International Conference on Machine Learning,", "citeRegEx": "Wang et al\\.,? \\Q2013\\E", "shortCiteRegEx": "Wang et al\\.", "year": 2013}, {"title": "Hierarchical grouping to optimize an objective function", "author": ["J.H. Ward"], "venue": "Journal of the American Statistical Association, 58 , 236\u2013244.", "citeRegEx": "Ward,? 1963", "shortCiteRegEx": "Ward", "year": 1963}, {"title": "Multi-attribute utility theory: Models and assessment procedures", "author": ["D. Winterfeldt", "G.W. Fischer"], "venue": null, "citeRegEx": "Winterfeldt and Fischer,? \\Q1975\\E", "shortCiteRegEx": "Winterfeldt and Fischer", "year": 1975}, {"title": "World bank database", "author": ["WorldBank"], "venue": "URL: http://data. worldbank.org/. accessed October 2013.", "citeRegEx": "WorldBank,? 2014", "shortCiteRegEx": "WorldBank", "year": 2014}, {"title": "An algorithm for multi-relational discovery of subgroups", "author": ["S. Wrobel"], "venue": "J. Komorowski, & J. Zytkow (Eds.), Principles of Data Mining and Knowledge Discovery (pp. 78\u201387). Berlin / Heidelberg: Springer volume 1263 of Lecture Notes in Computer Science. doi:10.1007/3-540-63223-9_108.", "citeRegEx": "Wrobel,? 1997", "shortCiteRegEx": "Wrobel", "year": 1997}, {"title": "A comprehensive survey of clustering algorithms", "author": ["D. Xu", "Y. Tian"], "venue": "Annals of Data Science,", "citeRegEx": "Xu and Tian,? \\Q2015\\E", "shortCiteRegEx": "Xu and Tian", "year": 2015}, {"title": "Scalable algorithms for association mining", "author": ["M.J. Zaki"], "venue": "IEEE Trans. on Knowl. and Data Eng., 12 , 372\u2013390. doi:10.1109/69. 846291.", "citeRegEx": "Zaki,? 2000", "shortCiteRegEx": "Zaki", "year": 2000}, {"title": "Reasoning about sets using redescription mining", "author": ["M.J. Zaki", "N. Ramakrishnan"], "venue": "In Proceedings of the 11th ACM SIGKDD International Conference on Knowledge Discovery in Data Mining (KDD", "citeRegEx": "Zaki and Ramakrishnan,? \\Q2005\\E", "shortCiteRegEx": "Zaki and Ramakrishnan", "year": 2005}, {"title": "Survey on association rules mining algorithms", "author": ["M. Zhang", "C. He"], "venue": null, "citeRegEx": "Zhang and He,? \\Q2010\\E", "shortCiteRegEx": "Zhang and He", "year": 2010}, {"title": "Redescription Mining Over non-Binary Data Sets Using Decision Trees", "author": ["T. Zinchenko"], "venue": "Master\u2019s thesis Universit\u00e4t des Saarlandes Saarbr\u00fccken Germany. 25", "citeRegEx": "Zinchenko,? 2014", "shortCiteRegEx": "Zinchenko", "year": 2014}], "referenceMentions": [{"referenceID": 41, "context": "This is addressed by redescription mining (Ramakrishnan et al., 2004), a type of knowledge discovery that aims to find different descriptions of similar sets of instances by using one, or more disjoint sets of descriptive attributes, called views.", "startOffset": 42, "endOffset": 69}, {"referenceID": 0, "context": "Redescription mining is related to association rule mining (Agrawal et al., 1996; Hipp et al., 2000; Zhang & He, 2010), two-view data association discovery (van Leeuwen & Galbrun, 2015), clustering (Cox, 1957; Fisher, 1958; Ward, 1963; Jain et al.", "startOffset": 59, "endOffset": 118}, {"referenceID": 24, "context": "Redescription mining is related to association rule mining (Agrawal et al., 1996; Hipp et al., 2000; Zhang & He, 2010), two-view data association discovery (van Leeuwen & Galbrun, 2015), clustering (Cox, 1957; Fisher, 1958; Ward, 1963; Jain et al.", "startOffset": 59, "endOffset": 118}, {"referenceID": 7, "context": ", 2000; Zhang & He, 2010), two-view data association discovery (van Leeuwen & Galbrun, 2015), clustering (Cox, 1957; Fisher, 1958; Ward, 1963; Jain et al., 1999; Xu & Tian, 2015) and it\u2019s special form conceptual clustering (Michalski, 1980; Fisher, 1987), subgroup discovery (Kl\u00f6sgen, 1996; Wrobel, 1997; Novak et al.", "startOffset": 105, "endOffset": 178}, {"referenceID": 11, "context": ", 2000; Zhang & He, 2010), two-view data association discovery (van Leeuwen & Galbrun, 2015), clustering (Cox, 1957; Fisher, 1958; Ward, 1963; Jain et al., 1999; Xu & Tian, 2015) and it\u2019s special form conceptual clustering (Michalski, 1980; Fisher, 1987), subgroup discovery (Kl\u00f6sgen, 1996; Wrobel, 1997; Novak et al.", "startOffset": 105, "endOffset": 178}, {"referenceID": 46, "context": ", 2000; Zhang & He, 2010), two-view data association discovery (van Leeuwen & Galbrun, 2015), clustering (Cox, 1957; Fisher, 1958; Ward, 1963; Jain et al., 1999; Xu & Tian, 2015) and it\u2019s special form conceptual clustering (Michalski, 1980; Fisher, 1987), subgroup discovery (Kl\u00f6sgen, 1996; Wrobel, 1997; Novak et al.", "startOffset": 105, "endOffset": 178}, {"referenceID": 25, "context": ", 2000; Zhang & He, 2010), two-view data association discovery (van Leeuwen & Galbrun, 2015), clustering (Cox, 1957; Fisher, 1958; Ward, 1963; Jain et al., 1999; Xu & Tian, 2015) and it\u2019s special form conceptual clustering (Michalski, 1980; Fisher, 1987), subgroup discovery (Kl\u00f6sgen, 1996; Wrobel, 1997; Novak et al.", "startOffset": 105, "endOffset": 178}, {"referenceID": 31, "context": ", 1999; Xu & Tian, 2015) and it\u2019s special form conceptual clustering (Michalski, 1980; Fisher, 1987), subgroup discovery (Kl\u00f6sgen, 1996; Wrobel, 1997; Novak et al.", "startOffset": 69, "endOffset": 100}, {"referenceID": 10, "context": ", 1999; Xu & Tian, 2015) and it\u2019s special form conceptual clustering (Michalski, 1980; Fisher, 1987), subgroup discovery (Kl\u00f6sgen, 1996; Wrobel, 1997; Novak et al.", "startOffset": 69, "endOffset": 100}, {"referenceID": 26, "context": ", 1999; Xu & Tian, 2015) and it\u2019s special form conceptual clustering (Michalski, 1980; Fisher, 1987), subgroup discovery (Kl\u00f6sgen, 1996; Wrobel, 1997; Novak et al., 2009; Herrera et al., 2010), emerging", "startOffset": 121, "endOffset": 192}, {"referenceID": 49, "context": ", 1999; Xu & Tian, 2015) and it\u2019s special form conceptual clustering (Michalski, 1980; Fisher, 1987), subgroup discovery (Kl\u00f6sgen, 1996; Wrobel, 1997; Novak et al., 2009; Herrera et al., 2010), emerging", "startOffset": 121, "endOffset": 192}, {"referenceID": 36, "context": ", 1999; Xu & Tian, 2015) and it\u2019s special form conceptual clustering (Michalski, 1980; Fisher, 1987), subgroup discovery (Kl\u00f6sgen, 1996; Wrobel, 1997; Novak et al., 2009; Herrera et al., 2010), emerging", "startOffset": 121, "endOffset": 192}, {"referenceID": 22, "context": ", 1999; Xu & Tian, 2015) and it\u2019s special form conceptual clustering (Michalski, 1980; Fisher, 1987), subgroup discovery (Kl\u00f6sgen, 1996; Wrobel, 1997; Novak et al., 2009; Herrera et al., 2010), emerging", "startOffset": 121, "endOffset": 192}, {"referenceID": 36, "context": "patterns (Dong & Li, 1999; Novak et al., 2009), contrast set mining (Bay & Pazzani, 2001; Novak et al.", "startOffset": 9, "endOffset": 46}, {"referenceID": 36, "context": ", 2009), contrast set mining (Bay & Pazzani, 2001; Novak et al., 2009) and exceptional model mining (Leman et al.", "startOffset": 29, "endOffset": 70}, {"referenceID": 30, "context": ", 2009) and exceptional model mining (Leman et al., 2008).", "startOffset": 37, "endOffset": 57}, {"referenceID": 0, "context": "Association rule mining (Agrawal et al., 1996) is related to redescription mining in the aim to find queries describing similar sets of instances which reveal associations between attributes used in these queries.", "startOffset": 24, "endOffset": 46}, {"referenceID": 45, "context": "Clustering is extended by multi-view (Bickel & Scheffer, 2004; Wang et al., 2013) and multi-layer clustering (Gamberger et al.", "startOffset": 37, "endOffset": 81}, {"referenceID": 19, "context": ", 2013) and multi-layer clustering (Gamberger et al., 2014) to find groups of instances that are strongly connected across multiple views.", "startOffset": 35, "endOffset": 59}, {"referenceID": 26, "context": "Subgroup discovery (Kl\u00f6sgen, 1996; Wrobel, 1997) differs from redescription mining in its goals.", "startOffset": 19, "endOffset": 48}, {"referenceID": 49, "context": "Subgroup discovery (Kl\u00f6sgen, 1996; Wrobel, 1997) differs from redescription mining in its goals.", "startOffset": 19, "endOffset": 48}, {"referenceID": 30, "context": "Exceptional model mining (Leman et al., 2008) extends subgroup discovery to more complex target concepts searching for subgroups such that a model trained on this subgroup is exceptional based on some property.", "startOffset": 25, "endOffset": 45}, {"referenceID": 0, "context": "Association rule mining (Agrawal et al., 1996) is related to redescription mining in the aim to find queries describing similar sets of instances which reveal associations between attributes used in these queries. The main difference is that association rules produce one directional associations while redescription mining produces bi directional associations. Two-view data association discovery (van Leeuwen & Galbrun, 2015) aims at finding a small, non - redundant set of associations that provide insight in how two views are related. Produced associations are both uni and bi directional as opposed to redescription mining that only produces bi directional connections providing interesting descriptions of instances. The main goal of clustering is to find groups of similar instances with respect to a set of attributes. However, it does not provide understandable and concise descriptions of these groups which are often complex and hard to find. This is resolved in conceptual clustering Michalski (1980); Fisher (1987) that finds clusters and concepts that describe them.", "startOffset": 25, "endOffset": 1014}, {"referenceID": 0, "context": "Association rule mining (Agrawal et al., 1996) is related to redescription mining in the aim to find queries describing similar sets of instances which reveal associations between attributes used in these queries. The main difference is that association rules produce one directional associations while redescription mining produces bi directional associations. Two-view data association discovery (van Leeuwen & Galbrun, 2015) aims at finding a small, non - redundant set of associations that provide insight in how two views are related. Produced associations are both uni and bi directional as opposed to redescription mining that only produces bi directional connections providing interesting descriptions of instances. The main goal of clustering is to find groups of similar instances with respect to a set of attributes. However, it does not provide understandable and concise descriptions of these groups which are often complex and hard to find. This is resolved in conceptual clustering Michalski (1980); Fisher (1987) that finds clusters and concepts that describe them.", "startOffset": 25, "endOffset": 1029}, {"referenceID": 27, "context": "(2015a,b) proposed a redescription mining algorithm based on multi-target predictive clustering trees (PCTs) (Blockeel & De Raedt, 1998; Kocev et al., 2013).", "startOffset": 109, "endOffset": 156}, {"referenceID": 27, "context": "The underlying redescription mining algorithm uses multi-target predictive clustering trees (Kocev et al., 2013) and allows the main steps of rule creation and redescription construction explained in (Mihel\u010di\u0107 et al.", "startOffset": 92, "endOffset": 112}, {"referenceID": 41, "context": "This is in contrast to current state of the art approaches that return all constructed redescriptions that satisfy accuracy and support constraints (Ramakrishnan et al., 2004; Zaki & Ramakrishnan, 2005; Parida & Ramakrishnan, 2005), a smaller number of accurate and significant redescriptions that satisfy support constraints (Galbrun & Miettinen, 2012b; Zinchenko, 2014; Gallo et al.", "startOffset": 148, "endOffset": 231}, {"referenceID": 54, "context": ", 2004; Zaki & Ramakrishnan, 2005; Parida & Ramakrishnan, 2005), a smaller number of accurate and significant redescriptions that satisfy support constraints (Galbrun & Miettinen, 2012b; Zinchenko, 2014; Gallo et al., 2008) or optimize one redescription set of user defined size (Mihel\u010di\u0107 et al.", "startOffset": 158, "endOffset": 223}, {"referenceID": 17, "context": ", 2004; Zaki & Ramakrishnan, 2005; Parida & Ramakrishnan, 2005), a smaller number of accurate and significant redescriptions that satisfy support constraints (Galbrun & Miettinen, 2012b; Zinchenko, 2014; Gallo et al., 2008) or optimize one redescription set of user defined size (Mihel\u010di\u0107 et al.", "startOffset": 158, "endOffset": 223}, {"referenceID": 36, "context": "The field of redescription mining was introduced by Ramakrishnan et al. (2004), who present an algorithm to mine redescriptions based on decision trees, called CARTwheels.", "startOffset": 52, "endOffset": 79}, {"referenceID": 36, "context": "The field of redescription mining was introduced by Ramakrishnan et al. (2004), who present an algorithm to mine redescriptions based on decision trees, called CARTwheels. The algorithm works by building two decision trees (one for each view) that are joined in the leaves. Redescriptions are found by examining the paths from the root node of the first tree to the root node of the second. The algorithm uses multi class classification to guide the search between the two views. Other approaches to mine redescriptions include the one proposed by Zaki & Ramakrishnan (2005), which uses a lattice of closed descriptor sets to find redescriptions; the algorithm for mining exact and approximate redescriptions by Parida & Ramakrishnan (2005) that uses relaxation lattice, and the greedy and the MID algorithm based on frequent itemset mining by Gallo et al.", "startOffset": 52, "endOffset": 575}, {"referenceID": 36, "context": "The field of redescription mining was introduced by Ramakrishnan et al. (2004), who present an algorithm to mine redescriptions based on decision trees, called CARTwheels. The algorithm works by building two decision trees (one for each view) that are joined in the leaves. Redescriptions are found by examining the paths from the root node of the first tree to the root node of the second. The algorithm uses multi class classification to guide the search between the two views. Other approaches to mine redescriptions include the one proposed by Zaki & Ramakrishnan (2005), which uses a lattice of closed descriptor sets to find redescriptions; the algorithm for mining exact and approximate redescriptions by Parida & Ramakrishnan (2005) that uses relaxation lattice, and the greedy and the MID algorithm based on frequent itemset mining by Gallo et al.", "startOffset": 52, "endOffset": 741}, {"referenceID": 16, "context": "Other approaches to mine redescriptions include the one proposed by Zaki & Ramakrishnan (2005), which uses a lattice of closed descriptor sets to find redescriptions; the algorithm for mining exact and approximate redescriptions by Parida & Ramakrishnan (2005) that uses relaxation lattice, and the greedy and the MID algorithm based on frequent itemset mining by Gallo et al. (2008). All these approaches work only on Boolean data.", "startOffset": 364, "endOffset": 384}, {"referenceID": 12, "context": "Galbrun & Miettinen (2012b) extend the greedy approach by Gallo et al.", "startOffset": 0, "endOffset": 28}, {"referenceID": 12, "context": "Galbrun & Miettinen (2012b) extend the greedy approach by Gallo et al. (2008) to work on numerical data.", "startOffset": 0, "endOffset": 78}, {"referenceID": 12, "context": "Galbrun & Miettinen (2012b) extend the greedy approach by Gallo et al. (2008) to work on numerical data. Redescription mining was extended by Galbrun & Kimmig (2013) to a relational and by Galbrun & Miettinen (2012a) to an interactive setting.", "startOffset": 0, "endOffset": 166}, {"referenceID": 12, "context": "Galbrun & Miettinen (2012b) extend the greedy approach by Gallo et al. (2008) to work on numerical data. Redescription mining was extended by Galbrun & Kimmig (2013) to a relational and by Galbrun & Miettinen (2012a) to an interactive setting.", "startOffset": 0, "endOffset": 217}, {"referenceID": 12, "context": "Galbrun & Miettinen (2012b) extend the greedy approach by Gallo et al. (2008) to work on numerical data. Redescription mining was extended by Galbrun & Kimmig (2013) to a relational and by Galbrun & Miettinen (2012a) to an interactive setting. Recently, two tree-based algorithms have been proposed by Zinchenko (2014), which explore the use of decision trees in a non-Boolean setting and present different methods of layer-by-layer tree construction, which make informed splits at each level of the tree.", "startOffset": 0, "endOffset": 319}, {"referenceID": 12, "context": "Given a dataset D, a query language Q over a set of attributes V , and a set of constraints C, the task of redescription mining (Galbrun, 2013) is to find all redescriptions satisfying constraints in C.", "startOffset": 128, "endOffset": 143}, {"referenceID": 12, "context": "The corresponding p-value (Galbrun, 2013) is defined as", "startOffset": 26, "endOffset": 41}, {"referenceID": 35, "context": "Below, we provide an example of a redescription, together with its associated quality measures obtained on the Bio dataset (Mitchell-Jones, 1999; Hijmans et al., 2005; Galbrun, 2013): Redescription R\u2032 ex = (q\u2032 1, q\u2032 2) with its queries defined as: q\u2032 1 : (\u22121.", "startOffset": 123, "endOffset": 182}, {"referenceID": 23, "context": "Below, we provide an example of a redescription, together with its associated quality measures obtained on the Bio dataset (Mitchell-Jones, 1999; Hijmans et al., 2005; Galbrun, 2013): Redescription R\u2032 ex = (q\u2032 1, q\u2032 2) with its queries defined as: q\u2032 1 : (\u22121.", "startOffset": 123, "endOffset": 182}, {"referenceID": 12, "context": "Below, we provide an example of a redescription, together with its associated quality measures obtained on the Bio dataset (Mitchell-Jones, 1999; Hijmans et al., 2005; Galbrun, 2013): Redescription R\u2032 ex = (q\u2032 1, q\u2032 2) with its queries defined as: q\u2032 1 : (\u22121.", "startOffset": 123, "endOffset": 182}, {"referenceID": 27, "context": "It uses multi-target Predictive Clustering Trees (PCT) (Kocev et al., 2013) to construct conjunctive queries which are used as building blocks of redescriptions.", "startOffset": 55, "endOffset": 75}, {"referenceID": 31, "context": "The framework generates redescriptions with the CLUSRM algorithm Mihel\u010di\u0107 et al. (2015b), presented in Algorithm 1.", "startOffset": 65, "endOffset": 89}, {"referenceID": 40, "context": "This is in part the consequence of using PCTs in multi-target setting, which is known to outperform single class classification or regression trees due to the property of inductive transfer (Piccart, 2012).", "startOffset": 190, "endOffset": 205}, {"referenceID": 17, "context": "Combining existing redescription queries with an attribute by using conjunction operator has been used in greedy based redescription mining algorithms (Gallo et al., 2008; Galbrun & Miettinen, 2012b) to construct redescriptions.", "startOffset": 151, "endOffset": 199}, {"referenceID": 12, "context": ", 2008; Galbrun & Miettinen, 2012b) to construct redescriptions. The idea is to expand each redescription query in turn by using a selected attribute and the selected logical operator. Such procedure, if used with the conjunction operator, leads to increase of Jaccard index but also mostly reduces the support size of a redescription. Zaki & Ramakrishnan (2005) combine closed descriptor sets by using conjunction operator to construct a closed lattice of descriptor sets which are used to construct redescriptions.", "startOffset": 8, "endOffset": 363}, {"referenceID": 51, "context": "We extend and prove the property described in Zaki & Ramakrishnan (2005) in a more general setting, combining redescriptions with arbitrary type of attributes and a finite amount of different views.", "startOffset": 46, "endOffset": 73}, {"referenceID": 32, "context": "The refinement procedure, in combination with redescription query minimization explained in Mihel\u010di\u0107 et al. (2015b), provides grounds for mining more accurate yet compact redescriptions.", "startOffset": 92, "endOffset": 116}, {"referenceID": 39, "context": "In the field of frequent itemset mining such dense representations include closed itemsets (Pasquier et al., 1999) and free sets (Boulicaut & Bykowski, 2000).", "startOffset": 91, "endOffset": 114}, {"referenceID": 21, "context": "The approaches using set pattern mining construct a set by enforcing constraints on different pattern properties, such as support, overlap or coverage (Guns et al., 2011).", "startOffset": 151, "endOffset": 170}, {"referenceID": 42, "context": "These techniques use properties like the Information Bottleneck (Tishby et al., 1999) or the Minimum description length", "startOffset": 64, "endOffset": 85}, {"referenceID": 20, "context": "(Gr\u00fcnwald, 2007).", "startOffset": 0, "endOffset": 16}, {"referenceID": 43, "context": "The goal is not to make redescription mining subjective in the sense of interestingness (Tuzhilin, 1995) or unexpectedness (Padmanabhan & Tuzhilin, 1998), but to enable exploration of mined patterns in a more versatile manner.", "startOffset": 88, "endOffset": 104}, {"referenceID": 4, "context": "The work on statistical selection of association rules developed by Bouker et al. (2012) presented techniques to eliminate irrelevant rules based on dominance, which is computed on several possibly conflicting criteria.", "startOffset": 68, "endOffset": 89}, {"referenceID": 28, "context": "(2015b) use weighting of attributes occurring in redescription queries and element occurrence in redescription supports based on work in subgroup discovery (Gamberger & Lavrac, 2002; Lavra\u010d et al., 2004).", "startOffset": 156, "endOffset": 203}, {"referenceID": 46, "context": "Zaki & Ramakrishnan (2005) developed an approach for non-redundant redescription generation based on a lattice of closed descriptor sets, Ramakrishnan et al.", "startOffset": 0, "endOffset": 27}, {"referenceID": 37, "context": "Zaki & Ramakrishnan (2005) developed an approach for non-redundant redescription generation based on a lattice of closed descriptor sets, Ramakrishnan et al. (2004) used the parameter defining the number of times one class or descriptor is allowed to participate in a redescription.", "startOffset": 138, "endOffset": 165}, {"referenceID": 37, "context": "Zaki & Ramakrishnan (2005) developed an approach for non-redundant redescription generation based on a lattice of closed descriptor sets, Ramakrishnan et al. (2004) used the parameter defining the number of times one class or descriptor is allowed to participate in a redescription. This is used to make a trade-off between exploration and redundancy. Parida & Ramakrishnan (2005) computed nonredundant representations of sets of redescriptions containing some selected descriptor (set of Boolean attributes).", "startOffset": 138, "endOffset": 381}, {"referenceID": 12, "context": "Galbrun & Miettinen (2012b) defined a minimal contribution parameter each literal must satisfy to be incorporated in a redescription query.", "startOffset": 0, "endOffset": 28}, {"referenceID": 12, "context": "Galbrun & Miettinen (2012b) defined a minimal contribution parameter each literal must satisfy to be incorporated in a redescription query. This enforces control over redundancy on the redescription level. Redundancy between different redescriptions is tackled in the Siren tool Galbrun & Miettinen (2012c) as a post processing (filtering) step.", "startOffset": 0, "endOffset": 307}, {"referenceID": 12, "context": "Galbrun & Miettinen (2012b) defined a minimal contribution parameter each literal must satisfy to be incorporated in a redescription query. This enforces control over redundancy on the redescription level. Redundancy between different redescriptions is tackled in the Siren tool Galbrun & Miettinen (2012c) as a post processing (filtering) step. Mihel\u010di\u0107 et al. (2015b) use weighting of attributes occurring in redescription queries and element occurrence in redescription supports based on work in subgroup discovery (Gamberger & Lavrac, 2002; Lavra\u010d et al.", "startOffset": 0, "endOffset": 370}, {"referenceID": 44, "context": "The evaluation and comparisons are performed on three datasets with different characteristics: the Country dataset (UNCTAD, 2014; WorldBank, 2014; Gamberger et al., 2014), the Bio dataset (Mitchell-Jones, 1999; Hijmans et al.", "startOffset": 115, "endOffset": 170}, {"referenceID": 48, "context": "The evaluation and comparisons are performed on three datasets with different characteristics: the Country dataset (UNCTAD, 2014; WorldBank, 2014; Gamberger et al., 2014), the Bio dataset (Mitchell-Jones, 1999; Hijmans et al.", "startOffset": 115, "endOffset": 170}, {"referenceID": 19, "context": "The evaluation and comparisons are performed on three datasets with different characteristics: the Country dataset (UNCTAD, 2014; WorldBank, 2014; Gamberger et al., 2014), the Bio dataset (Mitchell-Jones, 1999; Hijmans et al.", "startOffset": 115, "endOffset": 170}, {"referenceID": 35, "context": ", 2014), the Bio dataset (Mitchell-Jones, 1999; Hijmans et al., 2005; Galbrun, 2013) and the DBLP dataset (DBLP, 2010; Galbrun, 2013).", "startOffset": 25, "endOffset": 84}, {"referenceID": 23, "context": ", 2014), the Bio dataset (Mitchell-Jones, 1999; Hijmans et al., 2005; Galbrun, 2013) and the DBLP dataset (DBLP, 2010; Galbrun, 2013).", "startOffset": 25, "endOffset": 84}, {"referenceID": 12, "context": ", 2014), the Bio dataset (Mitchell-Jones, 1999; Hijmans et al., 2005; Galbrun, 2013) and the DBLP dataset (DBLP, 2010; Galbrun, 2013).", "startOffset": 25, "endOffset": 84}, {"referenceID": 8, "context": ", 2005; Galbrun, 2013) and the DBLP dataset (DBLP, 2010; Galbrun, 2013).", "startOffset": 44, "endOffset": 71}, {"referenceID": 12, "context": ", 2005; Galbrun, 2013) and the DBLP dataset (DBLP, 2010; Galbrun, 2013).", "startOffset": 44, "endOffset": 71}, {"referenceID": 19, "context": "We will focus on redescriptions describing four European countries: Germany, Czech Republic, Austria and Italy, discovered as a relevant cluster in a study performed by Gamberger et al. (2014). This study investigated country and trade properties of EU countries with potential implications to a free trade agreement with China.", "startOffset": 169, "endOffset": 193}, {"referenceID": 19, "context": "Presented redescriptions (attribute descriptions available in Table 2) confirm several findings reported in (Gamberger et al., 2014).", "startOffset": 108, "endOffset": 132}, {"referenceID": 17, "context": "Greedy approaches (Gallo et al., 2008; Galbrun & Miettinen, 2012b) are less affected by the increase in number of instances than the tree-based approaches, but are more sensitive to the increase in number of attributes.", "startOffset": 18, "endOffset": 66}, {"referenceID": 17, "context": "Complexity of approaches based on closed and frequent itemset mining (Gallo et al., 2008; Zaki & Ramakrishnan, 2005) depends on the number of produced frequent or closed itemsets which in worst case equals 2|V1|+|V2|.", "startOffset": 69, "endOffset": 116}, {"referenceID": 17, "context": "Complexity of approaches based on closed and frequent itemset mining (Gallo et al., 2008; Zaki & Ramakrishnan, 2005) depends on the number of produced frequent or closed itemsets which in worst case equals 2|V1|+|V2|. Similarly, the complexity of approach proposed by Parida & Ramakrishnan (2005) depends on the number of created biclusters and their size.", "startOffset": 70, "endOffset": 297}, {"referenceID": 8, "context": "2 for the DBLP dataset based on results presented in Galbrun (2013), Table 6.", "startOffset": 10, "endOffset": 68}, {"referenceID": 8, "context": "2 for the DBLP dataset based on results presented in Galbrun (2013), Table 6.1, p. 46. The same is set to 0.6 for the Bio dataset based on results in Galbrun (2013) Table 7, p.", "startOffset": 10, "endOffset": 165}, {"referenceID": 8, "context": "2 for the DBLP dataset based on results presented in Galbrun (2013), Table 6.1, p. 46. The same is set to 0.6 for the Bio dataset based on results in Galbrun (2013) Table 7, p. 301. The threshold 0.5 for the Country dataset was experimentally determined. Minimal support was set to 10 elements for the DBLP, based on Galbrun (2013) p.", "startOffset": 10, "endOffset": 332}, {"referenceID": 12, "context": "The effect is in part the consequence of using the Bio dataset that contains a number of accurate redescriptions with high support (also discussed in (Galbrun, 2013)).", "startOffset": 150, "endOffset": 165}, {"referenceID": 12, "context": "In this section, we present the comparative results of redescription set quality produced by our framework (CRMGRS) compared to the state of the art algorithms: the ReReMi Galbrun & Miettinen (2012b), the Split trees and the Layered trees Zinchenko (2014).", "startOffset": 172, "endOffset": 200}, {"referenceID": 12, "context": "In this section, we present the comparative results of redescription set quality produced by our framework (CRMGRS) compared to the state of the art algorithms: the ReReMi Galbrun & Miettinen (2012b), the Split trees and the Layered trees Zinchenko (2014). To perform the experiments, we used the implementation of the ReReMi, the Split trees and the Layered trees algorithm within the tool Siren (Galbrun & Miettinen, 2012c).", "startOffset": 172, "endOffset": 256}, {"referenceID": 41, "context": "The ReReMi algorithm was already compared in (Galbrun & Miettinen, 2012b) with the CartWheels algorithm (Ramakrishnan et al., 2004) (on a smaller version of a DBLP and the Bio dataset), with the association rule mining approach obtained by the ECLAT frequent itemset miner (Zaki, 2000) and the greedy approach developed by Gallo et al.", "startOffset": 104, "endOffset": 131}, {"referenceID": 51, "context": ", 2004) (on a smaller version of a DBLP and the Bio dataset), with the association rule mining approach obtained by the ECLAT frequent itemset miner (Zaki, 2000) and the greedy approach developed by Gallo et al.", "startOffset": 149, "endOffset": 161}, {"referenceID": 8, "context": ", 2004) (on a smaller version of a DBLP and the Bio dataset), with the association rule mining approach obtained by the ECLAT frequent itemset miner (Zaki, 2000) and the greedy approach developed by Gallo et al. (2008). The approach from Zaki & Ramakrishnan (2005), which is also related, works only with boolean attributes and have no built in mechanism to differentiate different views.", "startOffset": 35, "endOffset": 219}, {"referenceID": 8, "context": ", 2004) (on a smaller version of a DBLP and the Bio dataset), with the association rule mining approach obtained by the ECLAT frequent itemset miner (Zaki, 2000) and the greedy approach developed by Gallo et al. (2008). The approach from Zaki & Ramakrishnan (2005), which is also related, works only with boolean attributes and have no built in mechanism to differentiate different views.", "startOffset": 35, "endOffset": 265}, {"referenceID": 12, "context": "As already discussed in (Galbrun, 2013), the ReReMi algorithm has a drift towards redescriptions with large supports on the Bio dataset.", "startOffset": 24, "endOffset": 39}, {"referenceID": 12, "context": "Because of this, our framework eliminates descriptions of unrelated subsets of instances that occasionally occur in ReReMi\u2019s descriptions as a result of using disjunction operator (discussed in (Galbrun, 2013)).", "startOffset": 194, "endOffset": 209}], "year": 2016, "abstractText": "Redescription mining is a field of knowledge discovery that aims at finding different descriptions of similar subsets of instances in the data. These descriptions are represented as rules inferred from one or more disjoint sets of attributes, called views. As such, they support knowledge discovery process and help domain experts in formulating new hypotheses or constructing new knowledge bases and decision support systems. In contrast to previous approaches that typically create one smaller set of redescriptions satisfying a pre-defined set of constraints, we introduce a framework that creates large and heterogeneous redescription set from which user/expert can extract compact sets of differing properties, according to its own preferences. Construction of large and heterogeneous redescription set relies on CLUS-RM algorithm and a novel, conjunctive refinement procedure that facilitates generation of larger and more accurate redescription sets. The work also introduces the variability of redescription accuracy when missing values are present in the data, which significantly extends applicability of the method. Crucial part of the framework is the redescription set extraction based on heuristic multi-objective optimization procedure that allows user to define importance levels towards one or more redescription quality criteria. We provide both theoretical and empirical comparison of the novel framework against current state of the art redescription mining algorithms and show that it represents more efficient and versatile approach for mining redescriptions from data.", "creator": "LaTeX with hyperref package"}}}