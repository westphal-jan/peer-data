{"id": "1606.05545", "review": {"conference": "arxiv", "VERSION": "v1", "DATE_OF_SUBMISSION": "17-Jun-2016", "title": "Universal, Unsupervised (Rule-Based), Uncovered Sentiment Analysis", "abstract": "\u2026 we present firstly a novel unsupervised syntax approach known for multilingual sentiment analysis theoretically driven substantially by compositional syntax - based rules. whilst on that the general one hand, we inadvertently exploit some cases of why the dual main cognitive advantages involved of unsupervised derivation algorithms : ( 1 ) expanding the mutual interpretability of their output, in contrast occurring with most numerical supervised models, which behave uniformly as a natural black box and ( 2 ) supporting their robustness across roughly different cultural corpora and hierarchical domains.'on generally the other hand, done by specifically introducing the general concept category of compositional operations and exploiting existing syntactic information efficiently in the conditional form independently of universal dependencies, we tackle one of their main drawbacks : their formal rigidity consists on identifying data that too are differently syntax structured but depending not on the language. experiments therefore show an improvement virtually both over existing unsupervised methods, consequently and over naive state - much of - the - art language supervised consistency models when evaluating outside their corpus of origin. though the system is freely available.", "histories": [["v1", "Fri, 17 Jun 2016 14:53:02 GMT  (277kb)", "http://arxiv.org/abs/1606.05545v1", "12 pages, 5 Tables, 5 Figures, Preprint"], ["v2", "Thu, 5 Jan 2017 10:33:11 GMT  (404kb)", "http://arxiv.org/abs/1606.05545v2", "19 pages, 5 Tables, 6 Figures. This is the authors version of a work that was accepted for publication in Knowledge-Based Systems"]], "COMMENTS": "12 pages, 5 Tables, 5 Figures, Preprint", "reviews": [], "SUBJECTS": "cs.CL", "authors": ["david vilares", "carlos g\\'omez-rodr\\'iguez", "miguel a alonso"], "accepted": false, "id": "1606.05545"}, "pdf": {"name": "1606.05545.pdf", "metadata": {"source": "CRF", "title": null, "authors": [], "emails": ["david.vilares@udc.es", "carlos.gomez@udc.es", "miguel.alonso@udc.es"], "sections": [{"heading": null, "text": "ar X\niv :1\n60 6.\n05 54\n5v 1\n[ cs\n.C L\n] 1\n7 Ju\nn 20"}, {"heading": "1 Introduction", "text": "Semantic composition is a natural process for humans when understanding the sentiment of an opinion. In the sentence \u2018He is not very handsome, but he has something that I really like\u2019, humans have the ability to infer that the word \u2018very\u2019 emphasizes \u2018handsome\u2019, \u2018not\u2019 affects the whole expression \u2018very handsome\u2019, and \u2018but\u2019 decreases the relevance of \u2018He is not very handsome\u2019 and increases the one of \u2018he has something that I really like\u2019. Based on this, a human could justify a positive overall sentiment on that sentence.\nOur main contribution is the introduction of the first universal and unsupervised model for compositional sentiment analysis (SA) driven by syntax-\n1http://grupolys.org/software/UUUSA/\nbased rules. We introduce a formalism for compositional operations, allowing the creation of arbitrarily complex rules to tackle relevant phenomena for SA, for any language and syntactic dependency annotation. A set of practical universal operations is evaluated on different corpora and languages. The model outperforms existing unsupervised approaches, and state-of-the-art compositional supervised models (Socher et al., 2013) on domain-transfer settings, and shows that the operations can be shared across languages, as they are defined using part-of-speech (PoS) tags and dependency types under the universal guidelines of (Petrov et al., 2011; McDonald et al., 2013)."}, {"heading": "2 Related work", "text": "A na\u0131\u0308ve approach to emulate the comprehension of the meaning of multiword phrases for SA consists in using n-grams with n > 1 (Pang et al., 2002). The approach is limited by the curse of dimensionality, although crawling data from the target domain can help to reduce that problem (Kiritchenko et al., 2014). Joshi and Penstein-Rose\u0301 (2009) went one step forward and proposed generalized dependency triplets as features for subjectivity detection, capturing non-local relations. Socher et al. (2012) modeled a recursive neural network that learns compositional vector representations for phrases and sentences of arbitrary syntactic type and length. Socher et al. (2013) presented an improved recursive deep model for SA over dependency trees, and trained it on a sentiment treebank tagged using Amazon Mechanical Turk, pushing the state of the art up to 85.4% on the Pang and Lee (2005) dataset. Kalchbrenner et al. (2014) showed how convolutional neural networks (CNN) can be used for semantic modeling of sentences. The model implicitly captures local and non-local relations without the need of a parse\ntree. It can be adapted for any language, as far as enough data is available. Severyn and Moschitti (2015) showed the effectiveness of a CNN in a SemEval SA shared task (Rosenthal et al., 2015), although crawling tens of millions of messages was first required to achieve state-of-the-art results.\nIn spite of being powerful and accurate, supervised approaches also present drawbacks. Firstly, they behave as a black box. Secondly, they do not perform so well on domain transfer applications (Aue and Gamon, 2005; Pang and Lee, 2008). Finally, feature and hyper-parameter engineering can be time and resource costly options.\nWhen these limitations need to be addressed, unsupervised (rule-based) approaches are useful. In this line, Turney (2002) proposed an unsupervised learning algorithm to calculate the semantic orientation (SO) of a word. Taboada et al. (2011) presented a lexical rule-based approach to handle relevant linguistic phenomena such as intensification, negation, \u2018but\u2019 clauses and irrealis. Thelwall et al. (2012) released SentiStrength, a multilingual unsupervised system for micro-text SA that handles negation and intensification, among other web linguistic phenomena. Regarding syntax-based approaches, the few described in the literature are language-dependent. Jia et al. (2009) define a set of syntax-based rules for handling negation in English. Vilares et al. (2015a) propose a syntactic SA method, but limited to Spanish reviews and Ancora trees (Taule\u0301 et al., 2008).\nIn brief, most unsupervised approaches are language-dependent, and those that can manage multilinguality, such as SentiStrength, cannot apply semantic composition."}, {"heading": "3 Unsupervised Compositional SA", "text": ""}, {"heading": "3.1 Dependency graphs", "text": "Let w=w1, ..., wn be a sentence, where each word occurrence wi \u2208 W is assigned a PoS tag ti \u2208 T .\nDefinition 1. A dependency tree for w is an edgelabeled directed tree T = (V,E) where V = {0, 1, 2, . . . , n} is the set of nodes and E = V \u00d7 D \u00d7 V is the set of labeled arcs. Each arc, of the form (i, d, j), corresponds to a syntactic dependency between the words wi and wj; where i is the index of the head or parent word, j is the index of the dependent or child word and d is the dependency type representing the kind of syntactic relation between them. Following standard practice, we use node 0 as a dummy root node that acts\nas the head of the syntactic root(s) of the sentence.\nWe will write i d \u2212\u2192 j as shorthand for (i, d, j) \u2208 E and we will omit the dependency types when they are not relevant. Given a dependency tree T = (V,E), and a node i \u2208 V , we define a set of functions to obtain the context of node i:\n\u2022 ancestorT (i, \u03b4) = {k \u2208 V : there is a path of length \u03b4 from k to i in T}, i.e., the singleton set containing the \u03b4th ancestor of i (or the empty set if there is no such node),\n\u2022 childrenT (i) = {k \u2208 V | i \u2192 k}, i.e., the set of children of node i,\n\u2022 lm-branchT (i, d) = min{k \u2208 V | i d \u2212\u2192 k},\ni.e., the set containing the leftmost among the children of i whose dependencies are labeled d (or the empty set if there is no such node)."}, {"heading": "3.2 Operations for compositional SA", "text": "Our compositional SA system will associate an SO value \u03c3i to each node i in the dependency tree of a sentence, representing the SO of the subtree rooted at i. The system will use a set of compositional operations to propagate changes to the semantic orientations of the nodes in the tree. Once all the relevant operations have been executed, the SO of the sentence will be stored as \u03c30, i.e., the semantic orientation of the root node.\nA compositional operation is triggered when a node in the tree matches a given condition (related to its associated PoS tag, dependency type and/or word form); and it is applied to a scope of one or more nodes calculated from the trigger node by ascending a number of levels in the tree and then applying a scope function. More formally, we define our operations as follows:\nDefinition 2. Given a dependency tree T (V,E), a compositional operation is a tuple o = (\u03c4, C, \u03b4, \u03c0, S) such that:\n\u2022 \u03c4 : R \u2192 R is a transformation function to apply on the SO (\u03c3) of nodes,\n\u2022 C : V \u2192 {true, false} is a predicate that determines whether a node in the tree will trigger the operation,\n\u2022 \u03b4 \u2208 N is a number of levels that we need to ascend in the tree to calculate the scope of o,\n\u2022 \u03c0 is a priority that will be used to break ties when several operations coincide on a given node, and\n\u2022 S is a scope calculation function that will be used to determine the nodes affected by the operation.\nIn practice, our system defines C(i) by means of sets of words, tags and/or dependency types such that the operation will be triggered if wi, ti and/or the head dependency of i are in those sets. Compositional operations where C(i) is defined using universal tags and dependency types only are universal and can be used across languages.\nWe propose two options for the transformation function \u03c4 :\n\u2022 shift\u03b1(x) =\n{\nx\u2212 \u03b1 if x > 0 x+ \u03b1 if x < 0 where \u03b1 is\nthe shifting factor and \u03b1, x \u2208 R.\n\u2022 weighting\u03b2(x) = x\u00d7 (1+ \u03b2) where \u03b2 is the weighting factor and \u03b2, x \u2208 R.\nThe scope calculation function, S, allows us to calculate the nodes of T whose SO is affected by the transformation \u03c4 . For this purpose, if the operation was triggered by a node i, we apply S to ancestorT (i, \u03b4), i.e., the \u03b4th ancestor of i (if it exists), which we call the destination node of the operation. The proposed scopes are as follows (see also Figure 1):\n\u2022 dest (destination node): The transformation \u03c4 is applied directly to the SO of ancestorT (i, \u03b4) (see Figure 1.a).\n\u2022 lm-branchd (branch of d): The affected nodes are lm-branchT (ancestorT (i, \u03b4), d) (see Figure 1.b).\n\u2022 rcn (n right children): \u03c4 affects the SO of the n smallest indexes of {j \u2208 childrenT (ancestorT (i, \u03b4)) | j > i} (see Figure 1.c).\n\u2022 lcn (n left children): The transformation affects the n largest elements of {j \u2208 childrenT (ancestorT (i, \u03b4)) | j < i} (see Figure 1.d).\n\u2022 subjr (first subjective right branch): The affected node is min{j \u2208 childrenT (ancestorT (i, \u03b4)) | j > i \u2227 \u03c3j 6= 0} (see Figure 1.e).\n\u2022 subjl (first subjective left branch): The affected node is max{j \u2208 childrenT (ancestorT (i, \u03b4)) | j < i \u2227 \u03c3j 6= 0} (see Figure 1.f).\nCompositional operations can be defined for any language or dependency annotation criterion. While it is possible to add rules for languagespecific phenomena if needed (see \u00a7 3.3), in this paper we focus on universal rules to obtain a truly multilingual system.2"}, {"heading": "3.3 An algorithm for unsupervised SA", "text": "To execute the operations and calculate the SO of each node in the dependency tree of the sentence, we start by initializing the SO of each word using a subjective lexicon, as traditional unsupervised approaches do (Turney, 2002). Some options to obtain multilingual subjectivity lexica are SentiStrength (subjective data for up to 34 languages) or the Chen and Skiena (2014) approach, which introduced a method for building sentiment lexicons for 136 languages. Our implementation supports the lexicon format of SentiStrength, which can be plugged directly into the system. Additionally, we provide the option to create different dictionary entries depending on PoS tags to avoid conflicts between homonymous words (e.g. \u2018I\u2019m fine\u2019 versus \u2018They gave me a fine\u2019).\nThen, we traverse the parse tree in postorder, applying Algorithm 1 to update semantic orientations when visiting each node i. In this algorithm, O is the set of compositional operations defined in our system, Ai is a priority queue of the compositional operations to be applied at node i (because i is their destination node); and Qi is another priority queue of compositional operations to be queued for upper levels at node i (as i is not yet their destination node). \u2295 defines the operation to merge two priority queues, push inserts o in a priority queue and pop pulls the operation with the highest priority (ties are broken by giving preference to the operation that was queued earlier).\nAt a practical level, the set of compositional operations are specified using a simple XML file:\n\u2022 <forms>: Indicates the tokens to be taken into account for the condition C that triggers the operation. Regular expressions are supported.\n2Apart from universal dependencies and PoS tags, the only extra information used by our rules is a short list of negation words, intensifiers, adversative conjunctions and words introducing conditionals (like the English \u201cif\u201d or \u201cwould\u201d). While this information is language-specific, it is standardly included in multilingual sentiment lexica which are available for many languages (\u00a7 3.3), so it does not prevent our system from working on a wide set of languages without any adaptation.\nAlgorithm 1 Compute SO of a node 1: procedure COMPUTE(i, O ,T ) 2: Ai \u2190 [] 3: Qi \u2190 []\n\u22b2 Enqueue operations triggered by node i: 4: for o = (\u03c4, C, \u03b4, \u03c0, S) in O do 5: if C(i) then 6: if \u03b4 > 0 then 7: push((\u03c4, C, \u03b4, \u03c0, S), Qi) 8: else 9: push((\u03c4, C, \u03b4, \u03c0, S), Ai)\n\u22b2 Enqueue operations coming from child nodes: 10: for c in childrenT (i) do 11: for o = (\u03c4, C, \u03b4, \u03c0, S) in Qc do 12: if \u03b4 \u2212 1 = 0 then 13: push((\u03c4, C, \u03b4 \u2212 1, \u03c0, S), Ai) 14: else 15: push(\u03c4, C, \u03b4 \u2212 1, \u03c0, S), Qi)\n\u22b2 Execute operations that have reached their destination node:\n16: while Ai is not empty do 17: o = (\u03c4, C, \u03b4, \u03c0, S)\u2190 pop(Ai) 18: for j in S(i) do 19: \u03c3j \u2190 \u03c4 (\u03c3j)\n\u22b2 Join the SOs for node i and its children: 20: \u03c3i \u2190 \u03c3i + \u2211 c\u2208childrenT (i) \u03c3c\n\u2022 <dependency>: Indicates the dependency types taken into account for C .\n\u2022 <postags>: Indicates the PoS tags that must match to trigger the rule.\n\u2022 <rule>: Defines the operation to be executed when the rule is triggered.\n\u2022 <levelsup>: Defines the number of levels from i to spread before applying o.\n\u2022 <priority>: Defines the priority of o in case than more than one operation needs to be applied over i (a larger number implies a bigger priority)."}, {"heading": "4 NLP tools for universal unsupervised", "text": "SA\nThe following resources serve us as the starting point to carry out state-of-the-art universal, unsupervised and syntactic sentiment analysis.\nThe system by Gimpel et al. (2011) is used for tokenizing. Although initially intended for English tweets, we have observed that it also performs robustly for many other language families (Romance, Slavic, etc.).\nFor part-of-speech tagging we rely on the free distribution of the Toutanova and Manning (2000) tagger. Dependency parsers are built using MaltParser (Nivre et al., 2007) and MaltOptimizer (Ballesteros and Nivre, 2012). We trained a set of taggers and parsers for different languages using the universal tag and dependency sets (Petrov et al., 2011; McDonald et al., 2013). Table 1 shows their performance under standard metrics. The tagging3 and parsing4 models are also available."}, {"heading": "5 Defining compositional operations", "text": "We presented above a formalism to define arbitrarily complex compositional operations for unsupervised SA over a dependency tree. In this section, we show the definition of the most important rules that we used to evaluate our system. In practical terms, this implies studying how syntactic constructions that modify the sentiment of an ex-\n3http://grupolys.org/software/TAGGERS/universal-tagsets/monolingual/\n4http://www.grupolys.org/software/PARSERS/universaltag-sets/monolingual/\npression are represented in the annotation formalism used for the training of the dependency parser, in this case, Universal Dependencies. We are using examples following those universal guidelines, since they are available for more than 40 languages and, as shown in \u00a7 6, the same rules can be competitive across different languages."}, {"heading": "5.1 Intensification", "text": "Intensification amplifies or diminishes the sentiment of a word or phrase. Simple cases of this phenomenon can be \u2018I have huge problems\u2019 or \u2018This is a bit dissapointing\u2019. Traditional lexiconbased methods handle most of these cases with simple heuristics (e.g. amplifying or diminishing the sentiment of the word following an intensifier). However, ambiguous cases might appear where such lexical heuristics are not sufficient. For example, \u2018huge\u2019 can be a subjective adjective introducing its own SO (e.g. \u2018The house is huge\u2019), but also an amplifier when it modifies a subjective noun or adjective (e.g. \u2018I have huge problems\u2019, where it makes \u2018problems\u2019 more negative).\nUniversal compositional operations overcome this problem without the need of any heuristic. A dependency tree already shows the behavior of a word within a sentence thanks to its dependency type, and it shows the role of a word independently of the language. Figure 2 shows graphically how universal dependencies represent the cases discussed above these lines. Formally, the operation for these forms of intensification is: (weighting\u03b2, w \u2208 intensifiers\u2227 t \u2208 {ADV,ADJ}\u2227 d \u2208 {advmod,amod,nmod}, 1, 3, dest \u222a lm-branchacomp), with the value of \u03b2 depending on the strength of the intensifier as given by the sentiment lexicon."}, {"heading": "5.1.1 \u2018But\u2019 clauses", "text": "Compositional operations can also be defined to manage more challenging cases, such as clauses introduced by \u2018but\u2019, considered as a special case of intensification by authors such as Brooke et al. (2009) or Vilares et al. (2015a). It is assumed that the main clause connected by \u2018but\u2019 becomes less relevant for the reader (e.g. \u2018It is expensive, but I love it\u2019). Figure 3 shows our proposed composition operation for this clause, formally: (weighting\u03b2 , w \u2208 {but} \u2227 t \u2208 {CONJ} \u2227 d \u2208 {cc}, 1, 1, subjl ) with \u03b2 = \u22120.25. Note that the priority of this operation (\u03c0 = 1) is smaller than that of intensification (\u03c0 = 3), since we first need to process intensifiers, which are local phenomena, before resolving adversatives, which have a larger scope."}, {"heading": "5.2 Negation", "text": "Negation is one of the most challenging phenomena to handle in SA, since its semantic scope can be non-local (e.g. \u2018I do not plan to make you suffer\u2019). Existing unsupervised lexical approaches are limited to consider a snippet to guess the scope of negation. Thus, it is likely that they consider as a part of the scope terms that should not be negated from a semantic point of view. Dependency types help us to determine which nodes should act as negation and which should be its scope of influence. For brevity, we only illustrate some relevant negation cases and instructional examples in Figure 4. Formally, the proposed compositional operation to tackle most forms of negation under universal guidelines is: (shift\u03b1, w \u2208 negations \u2227 t \u2208 U \u2227 d \u2208 {neg}, 1, 2, dest \u222a lm-branch attr \u222a lm-branchacomp \u222a subjr), where U represents the universal tag set. The priority of negation (\u03c0 = 2) is between those of intensification and \u2018but\u2019 clauses because its scope can be non-local, but it does not go beyond an adversative conjuction."}, {"heading": "5.3 Irrealis", "text": "Irrealis denotes linguistic phenomena used to refer to non-factual actions, such as conditional, subjunctive or desiderative sentences (e.g. \u2018He would have died if he hadn\u2019t gone to the doctor\u2019). It is a very complex phenomenon to deal with, and systems are usually unable to tackle this issue or they simply define rules to ignore sentences containing a list of irrealis stop-words (Taboada et al., 2011). We do not address this phenomenon in detail in this study, but only propose a rule to deal with \u2018if\u2019 constructions (e.g. \u2018if I die [...]\u2019 or \u2018if you are\nhappy [...]\u2019, considering that the phrase that contains it should be ignored from the final computation. Formally: (weighting\u03b2, w \u2208 {if} \u2227 t \u2208 U \u2227 d \u2208 {mark}, 2, 3, dest \u222a subjr). Its graphical representation would be very similar to intensification (see Figures 1 a) and e))."}, {"heading": "5.4 Discussion", "text": "Figure 5 represents an analysis of our introductory sentence \u2018He is not very handsome, but he has something that I really like\u2019, showing how compositional operations accurately capture semantic composition.\nIt is hard to measure the coverage of our rules and the potential of these universal compositional operations, since it is possible to define arbitrarily complex operations for as many relevant linguistic phenomena as wished. In this line, Poria et al. (2014) define a set of English sentic patterns to determine how sentiment flows from concept to concept in a variety of situations (e.g. relations of complementation, direct nominal objects, relative clauses, . . . ) over a dependency tree following the De Marneffe and Manning (2008) guidelines."}, {"heading": "6 Experimental results", "text": "We compare our algorithm with respect to existing approaches on three languages: English, Spanish and German. The availability of corpora and other unsupervised SA systems for English and Spanish enables us to perform a richer comparison than in the case of German, where we only have an ad-hoc corpus.\nWe compare our algorithm with respect to two of the most popular and widely used unsupervised systems: (1) SO-CAL (Taboada et al., 2011), a language-dependent system available for English and Spanish guided by lexical rules at the morphological level, and (2) SentiStrength, a multilingual system that does not apply any PoS tagging or parsing step in order to be able to do multilingual analysis, relying instead on a set of subjectivity lexica, snippet-based rules and treatment of non-grammatical phenomena (e.g. character replication). Additionally, for the Spanish evaluation, we also took into account the system developed by Vilares et al. (2015a), an unsupervised syntaxbased approach available for Spanish but, in contrast to ours, heavily language-dependent.\nFor comparison against state-of-the-art supervised approaches, we consider the deep recursive\nneural network presented by Socher et al. (2013), trained on a movie sentiment treebank (English). To the best of our knowledge, there are no semantic compositional supervised methods for Spanish and German.\nAccuracy is used as the evaluation metric for two reasons: (1) it is adequate for measuring the performance of classifiers when the chosen corpora are balanced and (2) the selected systems for comparison also report their results using this metric."}, {"heading": "6.1 Resources", "text": "We selected the following standard English corpora for evaluation:\n\u2022 Taboada and Grieve (2004) corpus: A general-domain collection of 400 long reviews (200 positive, 200 negative) about hotels, movies, computers or music among other topics, extracted from epinions.com.\n\u2022 Pang and Lee (2004) corpus: A corpus of 2 000 long movie reviews (1 000 positive, 1 000 negative).\n\u2022 Pang and Lee (2005) corpus: A corpus of short movie reviews (sentences). In particular, we used the test split used by Socher et al. (2013), removing the neutral ones, as they did, for the binary classification task (total: 1 821 subjective sentences).\nTo show the universal capabilities of our system we include an evaluation for Spanish using the corpus presented by Brooke et al. (2009) (200 positive and 200 negative long reviews from ciao.es). For German, we rely on a dataset of 2 000 reviews (1 000 positive and 1 000 negative reviews) extracted from Amazon.\nAs subjectivity lexica, we use the same dictionaries used by SO-CAL for both English and Spanish. For German, we use the German SentiStrength dictionaries (Momtazi, 2012) instead, as Brooke et al. (2009) dictionaries are not available for languages other than Spanish or English."}, {"heading": "6.2 Comparison to unsupervised approaches", "text": "Table 2 compares the performance of our model with respect to SentiStrength5 and SO-CAL on\n5We used the default configuration, which already applies many optimizations. We set the length of the snippet between a negator and its scope to 3, based on empirical evaluation, and applied the configuration to compute sentiment on long reviews.\nthe Taboada and Grieve (2004) corpus. With respect to SO-CAL, results show that our handling of negation and intensification provides better results (outperforming SO-CAL by 3.25 percent points overall). With respect to SentiStrength, our system achieves better performance on long reviews.\nTable 3 compares these three unsupervised systems on the Pang and Lee (2004) corpus, showing the robustness of our approach across different domains. Our system again performs better than SOCAL for negation and intensification (although it does not behave as well when dealing with irrealis, probably due to the need of more complex compositional operations to handle this phenomenon), and also better than SentiStrength on long movie reviews.\nTable 4 compares the performance of our universal approach on a different language (Spanish) with respect to: Spanish SentiStrength (Vilares et al., 2015b), the Spanish SO-CAL (Brooke et al., 2009) and a syntactic language-dependent system inspired on the latter (Vilares et al., 2015a). We used exactly the same set of compositional operations as used for English (only changing the list of word forms for negation, intensification and \u2018but\u2019 clauses, as explained in \u00a73.2). Our universal system again outperforms SentiStrength and SO-CAL in its Spanish version. The system also obtains results very similar to the ones reported by Vilares et al. (2015a), even though their system is languagedependent and the set of rules is fixed and written specifically for Spanish.\nIn order to check the validity of our approach for languages other than English and Spanish, we have considered the case of German. It is worth noting that the authors of this article have no notions of German at all. In spite of this, we have been able to create a state-of-the-art unsupervised SA system by integrating an existing sentiment lexicon into the framework that we propose in this article.\nWe use the German SentiStrength system (Momtazi, 2012) for comparison. The use of the German SentiStrength dictionary allows us to show how our system is robust when using different lexica. Experimental results show an accuracy of 72.75% on the Amazon review dataset when all rules are included, while SentiStrength reports 69.95%. Again, adding first negation (72.05%) and then intensification (72.85%) as compositional operations produced relevant improvements over our baseline (69.85%). The results are comparable to those obtained for other languages, using a dataset of comparable size, reinforcing the robustness of our approach across different domains, languages, and base dictionaries."}, {"heading": "6.3 Comparison to supervised approaches", "text": "Supervised systems are usually unbeatable on the test portion of the corpus with which they have been trained. However, in real applications, a sufficiently large training corpus matching the target texts in terms of genre, style, length, etc. is often not available; and the performance of supervised systems has proven controversial on domain transfer applications (Aue and Gamon, 2005).\nTable 5 compares our universal unsupervised system to Socher et al. (2013) on a number of corpora: (1) the collection used in the evaluation of the Socher et al. system (Pang and Lee, 2005), (2) a corpus of the same domain, i.e., movies (Pang and Lee, 2004), and (3) the Taboada and Grieve (2004) collection. Socher et al.\u2019s system provides sentence-level polarity classification with five possible outputs: very positive, positive, neutral, negative, very negative. Since the Pang and\nLee (2004) and Taboada and Grieve (2004) corpora are collections of long reviews, we needed to collect the global sentiment of the text. We count the number of outputs of each class (very positive and very negative count double, positive and negative count one and neutral counts zero). We take the majority class, and in the case of a tie, it is classified as negative.6\nThe experimental results show that our approach obtains better results on corpora (2) and (3). It is worth mentioning that our unsupervised compositional approach outperformed the supervised model not only on an out-of-domain corpus, but also on another dataset of the same domain (movies) as the one where the neural network was trained and evaluated. This reinforces the usefulness of an unsupervised approach for applications that need to analyze a number of texts coming from different domains, styles or dates, but there is a lack of labeled data to train supervised classifiers for all of them. As expected, Socher et al. (2013) is unbeatable for an unsupervised approach on the test set of the corpus where it was trained. However, our unsupervised algorithm also performs very robustly on this dataset.\n6These criteria were selected empirically. Assigning the positive class in the case of a tie was also tested, as well as not doubling the very positive and very negative output, but these settings produced similar or worse results with the (Socher et al., 2013) system."}, {"heading": "7 Conclusions and future work", "text": "In this article, we have described, implemented and evaluated a novel model for universal and unsupervised sentiment analysis driven by a set of syntactic rules for semantic composition. Existing unsupervised approaches are purely lexical, their rules are heavily dependent on the language concerned or they do not consider any kind of natural language processing step in order to be able to handle different languages, using shallow rules instead.\nTo overcome these limitations, we introduce from a theoretical and practical point of view the concept of compositional operations, to define arbitrarily complex semantic relations between different nodes of a dependency tree. Universal partof-speech tagging and dependency parsing guidelines make it feasible to create multilingual sentiment analysis compositional operations that effectively address semantic composition over natural language sentences. The system is not restricted to any corpus or language, and by simply adapting or defining new operations it can be adapted to any other PoS tag or dependency annotation criteria.\nWe have compared our universal unsupervised model with state-of-the-art unsupervised and supervised approaches. Experimental results show: (1) that our algorithm outperforms two of the most commonly used unsupervised systems, (2) the universality of the model\u2019s compositional operations across different languages and (3) the usefulness of our approach on domain-transfer applications, especially with respect to supervised models.\nAs future work, we plan to design algorithms for the automatic extraction of compositional operations that capture the semantic relations between tree nodes. We would also like to collect corpora to extend our evaluation to more languages, since collections that are directly available on the web are scarcer than expected. Additionally, the concept of compositional operations is not limited to generic SA and could be adapted for other tasks such as universal aspect extraction. Finally, we plan to adapt the Poria et al. (2014) sentic patterns as compositional operations, so they can be handled universally."}, {"heading": "Acknowledgments", "text": "This research is supported by the Ministerio de Econom\u0131\u0301a y Competitividad (FFI2014-51978C2). David Vilares is funded by the Ministerio\nde Educacio\u0301n, Cultura y Deporte (FPU13/01180). Carlos Go\u0301mez-Rodr\u0131\u0301guez is funded by an Oportunius program grant (Xunta de Galicia). We thank Roman Klinger for his help in obtaining the German data."}], "references": [{"title": "Customizing sentiment classifiers to new domains: A case study", "author": ["A. Aue", "M. Gamon."], "venue": "Proceedings of the International Conference on Recent Advances in Natural Language Processing (RANLP).", "citeRegEx": "Aue and Gamon.,? 2005", "shortCiteRegEx": "Aue and Gamon.", "year": 2005}, {"title": "MaltOptimizer: an optimization tool for MaltParser", "author": ["M. Ballesteros", "J. Nivre."], "venue": "Proceedings of the Demonstrations at the 13th Conference of the European Chapter of the Association for Computational Linguistics, pages 58\u201362. Association for", "citeRegEx": "Ballesteros and Nivre.,? 2012", "shortCiteRegEx": "Ballesteros and Nivre.", "year": 2012}, {"title": "CrossLinguistic Sentiment Analysis: From English to Spanish", "author": ["J. Brooke", "M. Tofiloski", "M. Taboada."], "venue": "Proceedings of RANLP 2009, Recent Advances in Natural Language Processing, pages 50\u201354, Bovorets, Bulgaria, September.", "citeRegEx": "Brooke et al\\.,? 2009", "shortCiteRegEx": "Brooke et al\\.", "year": 2009}, {"title": "Building Sentiment Lexicons for All Major Languages", "author": ["Y. Chen", "S. Skiena."], "venue": "The 52nd Annual Meeting of the Association for Computational Linguistics. Proceedings of the Conference. Volume 2: Short Papers. ACL 2014, pages 383\u2013389, Baltimore,", "citeRegEx": "Chen and Skiena.,? 2014", "shortCiteRegEx": "Chen and Skiena.", "year": 2014}, {"title": "The Stanford typed dependencies representation", "author": ["M. De Marneffe", "C.D. Manning."], "venue": "Coling 2008: Proceedings of the workshop on CrossFramework and Cross-Domain Parser Evaluation, pages 1\u20138. Association for Computational Linguis-", "citeRegEx": "Marneffe and Manning.,? 2008", "shortCiteRegEx": "Marneffe and Manning.", "year": 2008}, {"title": "Part-of-speech tagging for twitter: Annotation, features, and experiments", "author": ["K. Gimpel", "N. Schneider", "B. O\u2019Connor", "D. Das", "D. Mills", "J. Eisenstein", "M. Heilman", "D. Yogatama", "J. Flanigan", "N.A. Smith"], "venue": "In Proceedings of the 49th Annual Meet-", "citeRegEx": "Gimpel et al\\.,? \\Q2011\\E", "shortCiteRegEx": "Gimpel et al\\.", "year": 2011}, {"title": "The effect of negation on Sentiment Analysis and Retrieval Effectiveness", "author": ["L. Jia", "C. Yu", "W. Meng."], "venue": "CIKM\u201909 Proceeding of the 18th ACM conference on Information and knowledge management, pages 1827\u20131830, Hong Kong, November. ACM,", "citeRegEx": "Jia et al\\.,? 2009", "shortCiteRegEx": "Jia et al\\.", "year": 2009}, {"title": "Generalizing dependency features for opinion mining", "author": ["M. Joshi", "C. Penstein-Ros\u00e9."], "venue": "Proceedings of the ACL-IJCNLP 2009 Conference Short Papers, ACLShort \u201909, pages 313\u2013316, Stroudsburg, PA, USA. Association for Computational Lin-", "citeRegEx": "Joshi and Penstein.Ros\u00e9.,? 2009", "shortCiteRegEx": "Joshi and Penstein.Ros\u00e9.", "year": 2009}, {"title": "Universal Dependency Annotation", "author": ["J. Lee"], "venue": null, "citeRegEx": "Lee.,? \\Q2013\\E", "shortCiteRegEx": "Lee.", "year": 2013}, {"title": "Fine-grained german sentiment", "author": ["S. Momtazi"], "venue": null, "citeRegEx": "Momtazi.,? \\Q2012\\E", "shortCiteRegEx": "Momtazi.", "year": 2012}, {"title": "A sentimental education", "author": ["B. Pang", "L. Lee"], "venue": null, "citeRegEx": "Pang and Lee.,? \\Q2004\\E", "shortCiteRegEx": "Pang and Lee.", "year": 2004}, {"title": "Seeing stars: Exploiting", "author": ["B. Pang", "L. Lee"], "venue": null, "citeRegEx": "Pang and Lee.,? \\Q2005\\E", "shortCiteRegEx": "Pang and Lee.", "year": 2005}, {"title": "Opinion Mining and Senti", "author": ["B. Pang", "L. Lee"], "venue": null, "citeRegEx": "Pang and Lee.,? \\Q2008\\E", "shortCiteRegEx": "Pang and Lee.", "year": 2008}, {"title": "Semeval2015 task 10: Sentiment analysis in Twitter", "author": ["S. Rosenthal", "P. Nakov", "S. Kiritchenko", "S. M Mohammad", "A. Ritter", "V. Stoyanov."], "venue": "Proceedings of the 9th International Workshop on Semantic Evaluation (SemEval 2015).", "citeRegEx": "Rosenthal et al\\.,? 2015", "shortCiteRegEx": "Rosenthal et al\\.", "year": 2015}, {"title": "UNITN: Training Deep Convolutional Neural Network for Twitter Sentiment Classification", "author": ["A. Severyn", "A. Moschitti."], "venue": "Proceedings of the 9th International Workshop on Semantic Evaluation (SemEval 2015), pages 464\u2013469, Denver, Colorado.", "citeRegEx": "Severyn and Moschitti.,? 2015", "shortCiteRegEx": "Severyn and Moschitti.", "year": 2015}, {"title": "Semantic compositionality through recursive matrix-vector spaces", "author": ["R. Socher", "B. Huval", "C.D. Manning", "A.Y. Ng."], "venue": "Proceedings of the 2012 Joint Conference on Empirical Methods in Natural Language Processing and Computational Natural", "citeRegEx": "Socher et al\\.,? 2012", "shortCiteRegEx": "Socher et al\\.", "year": 2012}, {"title": "Recursive Deep Models for Semantic Compositionality Over a Sentiment Treebank", "author": ["R. Socher", "A. Perelygin", "J. Wu", "J. Chuang", "C.D. Manning", "A. Ng", "C. Potts."], "venue": "EMNLP 2013. 2013 Conference on Empirical Methods in Natural Language", "citeRegEx": "Socher et al\\.,? 2013", "shortCiteRegEx": "Socher et al\\.", "year": 2013}, {"title": "Analyzing appraisal automatically", "author": ["M. Taboada", "J. Grieve."], "venue": "Proceedings of AAAI Spring Symposium on Exploring Attitude and Affect in Text (AAAI Technical Re# port SS# 04# 07), Stanford University, CA, pp. 158q161. AAAI Press.", "citeRegEx": "Taboada and Grieve.,? 2004", "shortCiteRegEx": "Taboada and Grieve.", "year": 2004}, {"title": "Lexicon-based methods for sentiment analysis", "author": ["M. Taboada", "J. Brooke", "M. Tofiloski", "K. Voll", "M. Stede."], "venue": "Computational Linguistics, 37(2):267\u2013307.", "citeRegEx": "Taboada et al\\.,? 2011", "shortCiteRegEx": "Taboada et al\\.", "year": 2011}, {"title": "AnCora: Multilevel Annotated Corpora for Catalan and Spanish", "author": ["M. Taul\u00e9", "M.A. Mart\u0131", "M. Recasens"], "venue": null, "citeRegEx": "Taul\u00e9 et al\\.,? \\Q2008\\E", "shortCiteRegEx": "Taul\u00e9 et al\\.", "year": 2008}, {"title": "Sentiment strength detection for the social web", "author": ["M. Thelwall", "K. Buckley", "G. Paltoglou."], "venue": "J. Am. Soc. Inf. Sci. Technol., 63(1):163\u2013173.", "citeRegEx": "Thelwall et al\\.,? 2012", "shortCiteRegEx": "Thelwall et al\\.", "year": 2012}, {"title": "Enriching the knowledge sources used in a maximum entropy partof-speech tagger", "author": ["K. Toutanova", "C.D. Manning."], "venue": "Proceedings of the 2000 Joint SIGDAT conference on Empirical methods in natural language processing and very large corpora:", "citeRegEx": "Toutanova and Manning.,? 2000", "shortCiteRegEx": "Toutanova and Manning.", "year": 2000}, {"title": "Thumbs up or thumbs down?: semantic orientation applied to unsupervised classification of reviews", "author": ["P.D. Turney."], "venue": "Proceedings of the 40th An-", "citeRegEx": "Turney.,? 2002", "shortCiteRegEx": "Turney.", "year": 2002}, {"title": "G\u00f3mez-Rodr\u0131\u0301guez. 2015a. A syntactic approach for opinion mining on Spanish reviews", "author": ["D. Vilares", "M.A. Alonso"], "venue": "Natural Language Engineering,", "citeRegEx": "Vilares et al\\.,? \\Q2015\\E", "shortCiteRegEx": "Vilares et al\\.", "year": 2015}, {"title": "The megaphone of the people? Spanish SentiStrength for real-time analysis of political tweets", "author": ["D. Vilares", "M. Thelwall", "M.A. Alonso."], "venue": "Journal of Information Science, 41(6):799\u2013813.", "citeRegEx": "Vilares et al\\.,? 2015b", "shortCiteRegEx": "Vilares et al\\.", "year": 2015}], "referenceMentions": [{"referenceID": 16, "context": "The model outperforms existing unsupervised approaches, and state-of-the-art compositional supervised models (Socher et al., 2013) on domain-transfer settings, and shows that the operations can be shared across languages, as they are defined using part-of-speech (PoS) tags and dependency types under the universal guidelines of (Petrov et al.", "startOffset": 109, "endOffset": 130}, {"referenceID": 7, "context": "Joshi and Penstein-Ros\u00e9 (2009) went one step forward and proposed generalized dependency triplets as features for subjectivity detection, capturing non-local relations.", "startOffset": 0, "endOffset": 31}, {"referenceID": 7, "context": "Joshi and Penstein-Ros\u00e9 (2009) went one step forward and proposed generalized dependency triplets as features for subjectivity detection, capturing non-local relations. Socher et al. (2012) modeled a recursive neural network that learns compositional vector representations for phrases and sentences of arbitrary syntactic type and length.", "startOffset": 0, "endOffset": 190}, {"referenceID": 7, "context": "Joshi and Penstein-Ros\u00e9 (2009) went one step forward and proposed generalized dependency triplets as features for subjectivity detection, capturing non-local relations. Socher et al. (2012) modeled a recursive neural network that learns compositional vector representations for phrases and sentences of arbitrary syntactic type and length. Socher et al. (2013) presented an improved recursive deep model for SA over dependency trees, and trained it on a sentiment treebank tagged using Amazon Mechanical Turk, pushing the state of the art up to 85.", "startOffset": 0, "endOffset": 361}, {"referenceID": 7, "context": "Joshi and Penstein-Ros\u00e9 (2009) went one step forward and proposed generalized dependency triplets as features for subjectivity detection, capturing non-local relations. Socher et al. (2012) modeled a recursive neural network that learns compositional vector representations for phrases and sentences of arbitrary syntactic type and length. Socher et al. (2013) presented an improved recursive deep model for SA over dependency trees, and trained it on a sentiment treebank tagged using Amazon Mechanical Turk, pushing the state of the art up to 85.4% on the Pang and Lee (2005) dataset.", "startOffset": 0, "endOffset": 578}, {"referenceID": 7, "context": "Joshi and Penstein-Ros\u00e9 (2009) went one step forward and proposed generalized dependency triplets as features for subjectivity detection, capturing non-local relations. Socher et al. (2012) modeled a recursive neural network that learns compositional vector representations for phrases and sentences of arbitrary syntactic type and length. Socher et al. (2013) presented an improved recursive deep model for SA over dependency trees, and trained it on a sentiment treebank tagged using Amazon Mechanical Turk, pushing the state of the art up to 85.4% on the Pang and Lee (2005) dataset. Kalchbrenner et al. (2014) showed how convolutional neural networks (CNN) can be used for semantic modeling of sentences.", "startOffset": 0, "endOffset": 614}, {"referenceID": 13, "context": "Severyn and Moschitti (2015) showed the effectiveness of a CNN in a SemEval SA shared task (Rosenthal et al., 2015), although crawling tens of millions of messages was first required to achieve state-of-the-art results.", "startOffset": 91, "endOffset": 115}, {"referenceID": 0, "context": "Secondly, they do not perform so well on domain transfer applications (Aue and Gamon, 2005; Pang and Lee, 2008).", "startOffset": 70, "endOffset": 111}, {"referenceID": 12, "context": "Secondly, they do not perform so well on domain transfer applications (Aue and Gamon, 2005; Pang and Lee, 2008).", "startOffset": 70, "endOffset": 111}, {"referenceID": 19, "context": "(2015a) propose a syntactic SA method, but limited to Spanish reviews and Ancora trees (Taul\u00e9 et al., 2008).", "startOffset": 87, "endOffset": 107}, {"referenceID": 7, "context": "Severyn and Moschitti (2015) showed the effectiveness of a CNN in a SemEval SA shared task (Rosenthal et al.", "startOffset": 0, "endOffset": 29}, {"referenceID": 0, "context": "Secondly, they do not perform so well on domain transfer applications (Aue and Gamon, 2005; Pang and Lee, 2008). Finally, feature and hyper-parameter engineering can be time and resource costly options. When these limitations need to be addressed, unsupervised (rule-based) approaches are useful. In this line, Turney (2002) proposed an unsupervised learning algorithm to calculate the semantic orientation (SO) of a word.", "startOffset": 71, "endOffset": 325}, {"referenceID": 0, "context": "Secondly, they do not perform so well on domain transfer applications (Aue and Gamon, 2005; Pang and Lee, 2008). Finally, feature and hyper-parameter engineering can be time and resource costly options. When these limitations need to be addressed, unsupervised (rule-based) approaches are useful. In this line, Turney (2002) proposed an unsupervised learning algorithm to calculate the semantic orientation (SO) of a word. Taboada et al. (2011) presented a lexical rule-based approach to handle relevant linguistic phenomena such as intensification, negation, \u2018but\u2019 clauses and irrealis.", "startOffset": 71, "endOffset": 445}, {"referenceID": 0, "context": "Secondly, they do not perform so well on domain transfer applications (Aue and Gamon, 2005; Pang and Lee, 2008). Finally, feature and hyper-parameter engineering can be time and resource costly options. When these limitations need to be addressed, unsupervised (rule-based) approaches are useful. In this line, Turney (2002) proposed an unsupervised learning algorithm to calculate the semantic orientation (SO) of a word. Taboada et al. (2011) presented a lexical rule-based approach to handle relevant linguistic phenomena such as intensification, negation, \u2018but\u2019 clauses and irrealis. Thelwall et al. (2012) released SentiStrength, a multilingual unsupervised system for micro-text SA that handles negation and intensification, among other web linguistic phenomena.", "startOffset": 71, "endOffset": 611}, {"referenceID": 0, "context": "Secondly, they do not perform so well on domain transfer applications (Aue and Gamon, 2005; Pang and Lee, 2008). Finally, feature and hyper-parameter engineering can be time and resource costly options. When these limitations need to be addressed, unsupervised (rule-based) approaches are useful. In this line, Turney (2002) proposed an unsupervised learning algorithm to calculate the semantic orientation (SO) of a word. Taboada et al. (2011) presented a lexical rule-based approach to handle relevant linguistic phenomena such as intensification, negation, \u2018but\u2019 clauses and irrealis. Thelwall et al. (2012) released SentiStrength, a multilingual unsupervised system for micro-text SA that handles negation and intensification, among other web linguistic phenomena. Regarding syntax-based approaches, the few described in the literature are language-dependent. Jia et al. (2009) define a set of syntax-based rules for handling negation in English.", "startOffset": 71, "endOffset": 882}, {"referenceID": 0, "context": "Secondly, they do not perform so well on domain transfer applications (Aue and Gamon, 2005; Pang and Lee, 2008). Finally, feature and hyper-parameter engineering can be time and resource costly options. When these limitations need to be addressed, unsupervised (rule-based) approaches are useful. In this line, Turney (2002) proposed an unsupervised learning algorithm to calculate the semantic orientation (SO) of a word. Taboada et al. (2011) presented a lexical rule-based approach to handle relevant linguistic phenomena such as intensification, negation, \u2018but\u2019 clauses and irrealis. Thelwall et al. (2012) released SentiStrength, a multilingual unsupervised system for micro-text SA that handles negation and intensification, among other web linguistic phenomena. Regarding syntax-based approaches, the few described in the literature are language-dependent. Jia et al. (2009) define a set of syntax-based rules for handling negation in English. Vilares et al. (2015a) propose a syntactic SA method, but limited to Spanish reviews and Ancora trees (Taul\u00e9 et al.", "startOffset": 71, "endOffset": 974}, {"referenceID": 22, "context": "To execute the operations and calculate the SO of each node in the dependency tree of the sentence, we start by initializing the SO of each word using a subjective lexicon, as traditional unsupervised approaches do (Turney, 2002).", "startOffset": 215, "endOffset": 229}, {"referenceID": 3, "context": "Some options to obtain multilingual subjectivity lexica are SentiStrength (subjective data for up to 34 languages) or the Chen and Skiena (2014) approach, which introduced a method for building sentiment lexicons for 136 languages.", "startOffset": 122, "endOffset": 145}, {"referenceID": 5, "context": "The system by Gimpel et al. (2011) is used for tokenizing.", "startOffset": 14, "endOffset": 35}, {"referenceID": 1, "context": ", 2007) and MaltOptimizer (Ballesteros and Nivre, 2012).", "startOffset": 26, "endOffset": 55}, {"referenceID": 20, "context": "For part-of-speech tagging we rely on the free distribution of the Toutanova and Manning (2000) tagger.", "startOffset": 67, "endOffset": 96}, {"referenceID": 2, "context": "Compositional operations can also be defined to manage more challenging cases, such as clauses introduced by \u2018but\u2019, considered as a special case of intensification by authors such as Brooke et al. (2009) or Vilares et al.", "startOffset": 183, "endOffset": 204}, {"referenceID": 2, "context": "Compositional operations can also be defined to manage more challenging cases, such as clauses introduced by \u2018but\u2019, considered as a special case of intensification by authors such as Brooke et al. (2009) or Vilares et al. (2015a). It is assumed that the main clause connected by \u2018but\u2019 becomes less relevant for the reader (e.", "startOffset": 183, "endOffset": 230}, {"referenceID": 18, "context": "It is a very complex phenomenon to deal with, and systems are usually unable to tackle this issue or they simply define rules to ignore sentences containing a list of irrealis stop-words (Taboada et al., 2011).", "startOffset": 187, "endOffset": 209}, {"referenceID": 4, "context": ") over a dependency tree following the De Marneffe and Manning (2008) guidelines.", "startOffset": 42, "endOffset": 70}, {"referenceID": 18, "context": "We compare our algorithm with respect to two of the most popular and widely used unsupervised systems: (1) SO-CAL (Taboada et al., 2011), a language-dependent system available for English and Spanish guided by lexical rules at the morphological level, and (2) SentiStrength, a multilingual system that does not apply any PoS tagging or parsing step in order to be able to do multilingual analysis, relying instead on a set of subjectivity lexica, snippet-based rules and treatment of non-grammatical phenomena (e.", "startOffset": 114, "endOffset": 136}, {"referenceID": 18, "context": "We compare our algorithm with respect to two of the most popular and widely used unsupervised systems: (1) SO-CAL (Taboada et al., 2011), a language-dependent system available for English and Spanish guided by lexical rules at the morphological level, and (2) SentiStrength, a multilingual system that does not apply any PoS tagging or parsing step in order to be able to do multilingual analysis, relying instead on a set of subjectivity lexica, snippet-based rules and treatment of non-grammatical phenomena (e.g. character replication). Additionally, for the Spanish evaluation, we also took into account the system developed by Vilares et al. (2015a), an unsupervised syntaxbased approach available for Spanish but, in contrast to ours, heavily language-dependent.", "startOffset": 115, "endOffset": 655}, {"referenceID": 18, "context": "Semantic orientation, intensification and negation values are extracted from the dictionaries of Taboada et al. (2011). Phase a) shows how the intensification is computed on the branches rooted at \u2018handsome\u2019 and \u2018like\u2019.", "startOffset": 97, "endOffset": 119}, {"referenceID": 15, "context": "neural network presented by Socher et al. (2013), trained on a movie sentiment treebank (English).", "startOffset": 28, "endOffset": 49}, {"referenceID": 17, "context": "\u2022 Taboada and Grieve (2004) corpus: A general-domain collection of 400 long reviews (200 positive, 200 negative) about hotels, movies, computers or music among other topics, extracted from epinions.", "startOffset": 2, "endOffset": 28}, {"referenceID": 8, "context": "\u2022 Pang and Lee (2004) corpus: A corpus of 2 000 long movie reviews (1 000 positive, 1 000 negative).", "startOffset": 11, "endOffset": 22}, {"referenceID": 8, "context": "\u2022 Pang and Lee (2005) corpus: A corpus of short movie reviews (sentences).", "startOffset": 11, "endOffset": 22}, {"referenceID": 8, "context": "\u2022 Pang and Lee (2005) corpus: A corpus of short movie reviews (sentences). In particular, we used the test split used by Socher et al. (2013), removing the neutral ones, as they did, for the binary classification task (total: 1 821 subjective sentences).", "startOffset": 11, "endOffset": 142}, {"referenceID": 9, "context": "For German, we use the German SentiStrength dictionaries (Momtazi, 2012) instead, as Brooke et al.", "startOffset": 57, "endOffset": 72}, {"referenceID": 2, "context": "To show the universal capabilities of our system we include an evaluation for Spanish using the corpus presented by Brooke et al. (2009) (200 positive and 200 negative long reviews from ciao.", "startOffset": 116, "endOffset": 137}, {"referenceID": 2, "context": "To show the universal capabilities of our system we include an evaluation for Spanish using the corpus presented by Brooke et al. (2009) (200 positive and 200 negative long reviews from ciao.es). For German, we rely on a dataset of 2 000 reviews (1 000 positive and 1 000 negative reviews) extracted from Amazon. As subjectivity lexica, we use the same dictionaries used by SO-CAL for both English and Spanish. For German, we use the German SentiStrength dictionaries (Momtazi, 2012) instead, as Brooke et al. (2009) dictionaries are not available for languages other than Spanish or English.", "startOffset": 116, "endOffset": 517}, {"referenceID": 13, "context": "the Taboada and Grieve (2004) corpus.", "startOffset": 4, "endOffset": 30}, {"referenceID": 8, "context": "Table 3 compares these three unsupervised systems on the Pang and Lee (2004) corpus, showing the robustness of our approach across different domains.", "startOffset": 66, "endOffset": 77}, {"referenceID": 17, "context": "Table 2: Accuracy (%) on the Taboada and Grieve (2004) corpus.", "startOffset": 29, "endOffset": 55}, {"referenceID": 8, "context": "Table 3: Accuracy (%) on Pang and Lee (2004) test set.", "startOffset": 34, "endOffset": 45}, {"referenceID": 24, "context": "Table 4 compares the performance of our universal approach on a different language (Spanish) with respect to: Spanish SentiStrength (Vilares et al., 2015b), the Spanish SO-CAL (Brooke et al.", "startOffset": 132, "endOffset": 155}, {"referenceID": 2, "context": ", 2015b), the Spanish SO-CAL (Brooke et al., 2009) and a syntactic language-dependent system inspired on the latter (Vilares et al.", "startOffset": 29, "endOffset": 50}, {"referenceID": 2, "context": ", 2015b), the Spanish SO-CAL (Brooke et al., 2009) and a syntactic language-dependent system inspired on the latter (Vilares et al., 2015a). We used exactly the same set of compositional operations as used for English (only changing the list of word forms for negation, intensification and \u2018but\u2019 clauses, as explained in \u00a73.2). Our universal system again outperforms SentiStrength and SO-CAL in its Spanish version. The system also obtains results very similar to the ones reported by Vilares et al. (2015a), even though their system is languagedependent and the set of rules is fixed and written specifically for Spanish.", "startOffset": 30, "endOffset": 508}, {"referenceID": 23, "context": "Rules SentiStrength SO-CAL Our system Vilares et al. (2015a)", "startOffset": 38, "endOffset": 61}, {"referenceID": 2, "context": "Table 4: Accuracy (%) on the Spanish Brooke et al. (2009) test set.", "startOffset": 37, "endOffset": 58}, {"referenceID": 9, "context": "We use the German SentiStrength system (Momtazi, 2012) for comparison.", "startOffset": 39, "endOffset": 54}, {"referenceID": 0, "context": "is often not available; and the performance of supervised systems has proven controversial on domain transfer applications (Aue and Gamon, 2005).", "startOffset": 123, "endOffset": 144}, {"referenceID": 11, "context": "system (Pang and Lee, 2005), (2) a corpus of the same domain, i.", "startOffset": 7, "endOffset": 27}, {"referenceID": 10, "context": ", movies (Pang and Lee, 2004), and (3) the Taboada and Grieve (2004) collection.", "startOffset": 9, "endOffset": 29}, {"referenceID": 11, "context": "Table 5 compares our universal unsupervised system to Socher et al. (2013) on a number of corpora: (1) the collection used in the evaluation of the Socher et al.", "startOffset": 54, "endOffset": 75}, {"referenceID": 8, "context": "system (Pang and Lee, 2005), (2) a corpus of the same domain, i.e., movies (Pang and Lee, 2004), and (3) the Taboada and Grieve (2004) collection.", "startOffset": 17, "endOffset": 135}, {"referenceID": 8, "context": "system (Pang and Lee, 2005), (2) a corpus of the same domain, i.e., movies (Pang and Lee, 2004), and (3) the Taboada and Grieve (2004) collection. Socher et al.\u2019s system provides sentence-level polarity classification with five possible outputs: very positive, positive, neutral, negative, very negative. Since the Pang and Corpora Socher et al. (2013)Our system Origin corpus of Socher et al.", "startOffset": 17, "endOffset": 353}, {"referenceID": 8, "context": "system (Pang and Lee, 2005), (2) a corpus of the same domain, i.e., movies (Pang and Lee, 2004), and (3) the Taboada and Grieve (2004) collection. Socher et al.\u2019s system provides sentence-level polarity classification with five possible outputs: very positive, positive, neutral, negative, very negative. Since the Pang and Corpora Socher et al. (2013)Our system Origin corpus of Socher et al. (2013) model Pang and Lee (2005) 85.", "startOffset": 17, "endOffset": 401}, {"referenceID": 8, "context": "system (Pang and Lee, 2005), (2) a corpus of the same domain, i.e., movies (Pang and Lee, 2004), and (3) the Taboada and Grieve (2004) collection. Socher et al.\u2019s system provides sentence-level polarity classification with five possible outputs: very positive, positive, neutral, negative, very negative. Since the Pang and Corpora Socher et al. (2013)Our system Origin corpus of Socher et al. (2013) model Pang and Lee (2005) 85.", "startOffset": 17, "endOffset": 427}, {"referenceID": 8, "context": "system (Pang and Lee, 2005), (2) a corpus of the same domain, i.e., movies (Pang and Lee, 2004), and (3) the Taboada and Grieve (2004) collection. Socher et al.\u2019s system provides sentence-level polarity classification with five possible outputs: very positive, positive, neutral, negative, very negative. Since the Pang and Corpora Socher et al. (2013)Our system Origin corpus of Socher et al. (2013) model Pang and Lee (2005) 85.40 75.01 Other corpora Taboada and Grieve (2004) 62.", "startOffset": 17, "endOffset": 479}, {"referenceID": 8, "context": "system (Pang and Lee, 2005), (2) a corpus of the same domain, i.e., movies (Pang and Lee, 2004), and (3) the Taboada and Grieve (2004) collection. Socher et al.\u2019s system provides sentence-level polarity classification with five possible outputs: very positive, positive, neutral, negative, very negative. Since the Pang and Corpora Socher et al. (2013)Our system Origin corpus of Socher et al. (2013) model Pang and Lee (2005) 85.40 75.01 Other corpora Taboada and Grieve (2004) 62.00 73.75 Pang and Lee (2004) 63.", "startOffset": 17, "endOffset": 511}, {"referenceID": 11, "context": "On the Pang and Lee 2005 (Pang and Lee, 2005) collection, our detailed results taking into account different compositional operations were: 73.", "startOffset": 25, "endOffset": 45}, {"referenceID": 11, "context": "Table 5: Accuracy (%) on different corpora for Socher et al. (2013) and our system.", "startOffset": 47, "endOffset": 68}, {"referenceID": 15, "context": "As expected, Socher et al. (2013) is unbeatable for an unsupervised approach on the test set of the corpus where it was trained.", "startOffset": 13, "endOffset": 34}, {"referenceID": 16, "context": "Assigning the positive class in the case of a tie was also tested, as well as not doubling the very positive and very negative output, but these settings produced similar or worse results with the (Socher et al., 2013) system.", "startOffset": 197, "endOffset": 218}], "year": 2017, "abstractText": "We present a novel unsupervised approach for multilingual sentiment analysis driven by compositional syntax-based rules. On the one hand, we exploit some of the main advantages of unsupervised algorithms: (1) the interpretability of their output, in contrast with most supervised models, which behave as a black box and (2) their robustness across different corpora and domains. On the other hand, by introducing the concept of compositional operations and exploiting syntactic information in the form of universal dependencies, we tackle one of their main drawbacks: their rigidity on data that are differently structured depending on the language. Experiments show an improvement both over existing unsupervised methods, and over state-of-the-art supervised models when evaluating outside their corpus of origin. The system is freely available1 .", "creator": "dvips(k) 5.991 Copyright 2011 Radical Eye Software"}}}