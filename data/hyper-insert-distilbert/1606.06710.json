{"id": "1606.06710", "review": {"conference": "arxiv", "VERSION": "v1", "DATE_OF_SUBMISSION": "21-Jun-2016", "title": "Correlation-based Intrinsic Evaluation of Word Vector Representations", "abstract": "we likewise introduce qvec - linked cca - - proposing an intrinsic evaluation metric for word vector representations chosen based loosely on memory correlations typically of learned vectors accompanied with features extracted from functional linguistic identification resources. thus we show well that qvec - cca combined scores are probably an ideally effective reasoning proxy for viewing a range of arbitrary extrinsic semantic and formal syntactic tasks. we also show that extending the proposed evaluation obtains higher cognitive and more easily consistent residual correlations with downstream tasks, compared to existing retrieval approaches to intrinsic comparison evaluation performances of those word vectors that are defined based on word morphological similarity.", "histories": [["v1", "Tue, 21 Jun 2016 19:12:01 GMT  (22kb)", "http://arxiv.org/abs/1606.06710v1", "RepEval 2016, 5 pages"]], "COMMENTS": "RepEval 2016, 5 pages", "reviews": [], "SUBJECTS": "cs.CL", "authors": ["yulia tsvetkov", "manaal faruqui", "chris dyer"], "accepted": false, "id": "1606.06710"}, "pdf": {"name": "1606.06710.pdf", "metadata": {"source": "CRF", "title": "Correlation-based Intrinsic Evaluation of Word Vector Representations", "authors": ["Yulia Tsvetkov", "Manaal Faruqui", "Chris Dyer"], "emails": ["ytsvetko@cs.cmu.edu", "mfaruqui@cs.cmu.edu", "cdyer@cs.cmu.edu"], "sections": [{"heading": null, "text": "ar X\niv :1\n60 6.\n06 71\n0v 1\n[ cs\n.C L\n] 2\n1 Ju\nn 20\n16"}, {"heading": "1 Introduction", "text": "Being linguistically opaque, vector-space representations of words\u2014word embeddings\u2014have limited practical value as standalone items. They are effective, however, in representing meaning\u2014through individual dimensions and combinations of thereof\u2014when used as features in downstream applications (Turian et al., 2010; Lazaridou et al., 2013; Socher et al., 2013; Bansal et al., 2014; Guo et al., 2014, inter alia). Thus, unless it is coupled with an extrinsic task, intrinsic evaluation of word vectors has little value in itself. The main purpose of an intrinsic evaluation is to serve as a proxy for the downstream task the embeddings are tailored for. This paper advocates a novel approach to constructing such a proxy.\nWhat are the desired properties of an intrinsic evaluation measure of word embeddings? First, retraining models that use word embeddings as features is often expensive. A computationally efficient intrinsic evaluation that correlates with extrinsic scores is useful for faster prototyping. Second, an intrinsic evaluation that enables interpre-\ntation and analysis of properties encoded by vector dimensions is an auxiliary mechanism for analyzing how these properties affect the target downstream task. It thus facilitates refinement of word vector models and, consequently, improvement of the target task. Finally, an intrinsic evaluation that approximates a range of related downstream tasks (e.g., semantic text-classification tasks) allows to assess generality (or specificity) of a word vector model, without actually implementing all the tasks.\nTsvetkov et al. (2015) proposed an evaluation measure\u2014QVEC\u2014that was shown to correlate well with downstream semantic tasks. Additionally, it helps shed new light on how vector spaces encode meaning thus facilitating the interpretation of word vectors. The crux of the method is to correlate distributional word vectors with linguistic word vectors constructed from rich linguistic resources, annotated by domain experts. QVEC can easily be adjusted to specific downstream tasks (e.g., part-of-speech tagging) by selecting taskspecific linguistic resources (e.g., part-of-speech annotations). However, QVEC suffers from two weaknesses. First, it is not invariant to linear transformations of the embeddings\u2019 basis, whereas the bases in word embeddings are generally arbitrary (Szegedy et al., 2014). Second, it produces an unnormalized score: the more dimensions in the embedding matrix the higher the score. This precludes comparison of models of different dimensionality. In this paper, we introduce QVECCCA, which simultaneously addresses both problems, while preserving major strengths of QVEC.1"}, {"heading": "2 QVEC and QVEC-CCA", "text": "We introduce QVEC-CCA\u2014an intrinsic evaluation measure of the quality of word embeddings. Our\n1https://github.com/ytsvetko/qvec\nmethod is a modification of QVEC\u2014an evaluation based on alignment of embeddings to a matrix of features extracted from a linguistic resource (Tsvetkov et al., 2015). We review QVEC, and then describe QVEC-CCA.\nQVEC. The main idea behind QVEC is to quantify the linguistic content of word embeddings by maximizing the correlation with a manuallyannotated linguistic resource. Let the number of common words in the vocabulary of the word embeddings and the linguistic resource be N . To quantify the semantic content of embeddings, a semantic/syntactic linguistic matrix S \u2208 RP\u00d7N is constructed from a semantic/syntactic database, with a column vector for each word. Each word vector is a distribution of the word over P linguistic properties, based on annotations of the word in the database. Let X \u2208 RD\u00d7N be embedding matrix with every row as a dimension vector x \u2208 R1\u00d7N . D denotes the dimensionality of word embeddings. Then, S and X are aligned to maximize the cumulative correlation between the aligned dimensions of the two matrices. Specifically, let A \u2208 {0, 1}D\u00d7P be a matrix of alignments such that aij = 1 iff xi is aligned to sj , otherwise aij = 0. If r(xi, sj) is the Pearson\u2019s correlation between vectors xi and sj , then QVEC is defined as:\nQVEC = max A:\n\u2211 j aij\u22641\nX\u2211\ni=1\nS\u2211\nj=1\nr(xi, sj)\u00d7 aij\nThe constraint \u2211\nj aij \u2264 1, warrants that one distributional dimension is aligned to at most one linguistic dimension.\nQVEC-CCA. To measure correlation between the embedding matrix X and the linguistic matrix S, instead of cumulative dimension-wise correlation we employ canonical correlation analysis (Hardoon et al., 2004, CCA). CCA finds two sets of basis vectors, one for X\u22a4 and the other for S\u22a4, such that the correlations between the projections of the matrices onto these basis vectors are maximized. Formally, CCA finds a pair of basis vectors v and w such that\nQVEC-CCA = CCA(X\u22a4,S\u22a4)\n= max v,w\nr(X\u22a4v,S\u22a4w)\nThus, QVEC-CCA ensures invariance to the matrices\u2019 bases\u2019 rotation, and since it is a single correlation, it produces a score in [\u22121, 1]."}, {"heading": "3 Linguistic Dimension Word Vectors", "text": "Both QVEC and QVEC-CCA rely on a matrix of linguistic properties constructed from a manually crafted linguistic resource. Linguistic resources are invaluable as they capture generalizations made by domain experts. However, resource construction is expensive, therefore it is not always possible to find an existing resource that captures exactly the set of optimal lexical properties for a downstream task. Resources that capture more coarse-grained, general properties can be used instead, for example, WordNet for semantic evaluation (Fellbaum, 1998), or Penn Treebank (Marcus et al., 1993, PTB) for syntactic evaluation. Since these properties are not an exact match to the task, the intrinsic evaluation tests for a necessary (but possibly not sufficient) set of generalizations.\nSemantic vectors. To evaluate the semantic content of word vectors, Tsvetkov et al. (2015) exploit supersense annotations in a WordNetannotated corpus\u2014SemCor (Miller et al., 1993). The resulting supersense-dimension matrix has 4,199 rows (supersense-annotated nouns and verbs that occur in SemCor at least 5 times2), and 41 columns: 26 for nouns and 15 for verbs. Example vectors are shown in table 1.\nSyntactic vectors. Similar to semantic vectors, we construct syntactic vectors for all words with 5 or more occurrences in the training part of the PTB. Vector dimensions are probabilities of the part-of-speech (POS) annotations in the corpus. This results in 10,865 word vectors with 45 interpretable columns, each column corresponds to a POS tag from the PTB; a snapshot is shown in table 2."}, {"heading": "4 Experiments", "text": "Experimental setup. We replicate the experimental setup of Tsvetkov et al. (2015):\n2We exclude sparser word types to avoid skewed probability estimates of senses of polysemous words.\n\u2022 We first train 21 word vector models: variants of CBOW and Skip-Gram models (Mikolov et al., 2013); their modifications CWindow, Structured Skip-Gram, and CBOW with Attention (Ling et al., 2015b; Ling et al., 2015a); GloVe vectors (Pennington et al., 2014); Latent Semantic Analysis (LSA) based vectors (Church and Hanks, 1990); and retrofitted GloVe and LSA vectors (Faruqui et al., 2015).\n\u2022 We then evaluate these word vector models using existing intrinsic evaluation methods: QVEC and the proposed QVEC-CCA, and also word similarity tasks using the WordSim353 dataset (Finkelstein et al., 2001, WS353), MEN dataset (Bruni et al., 2012), and SimLex-999 dataset (Hill et al., 2014, SimLex).3\n\u2022 In addition, the same vectors are evaluated using extrinsic text classification tasks. Our semantic benchmarks are four binary categorization tasks from the 20 Newsgroups (20NG); sentiment analysis task (Socher et al., 2013, Senti); and the metaphor detection (Tsvetkov et al., 2014, Metaphor).\n\u2022 Finally, we compute the Pearson\u2019s correlation coefficient r to quantify the linear relationship between the intrinsic and extrinsic scorings. The higher the correlation, the better suited the intrinsic evaluation to be used as a proxy to the extrinsic task.\nWe extend the setup of Tsvetkov et al. (2015) with two syntactic benchmarks, and evaluate QVEC-CCA with the syntactic matrix. The first task is POS tagging; we use the LSTM-CRF model (Lample et al., 2016), and the second is dependency parsing (Parse), using the stack-LSTM model of Dyer et al. (2015).\nResults. To test the efficiency of QVEC-CCA in capturing the semantic content of word vectors, we evaluate how well the scores correspond to the\n3We employ an implementation of a suite of word similarity tasks at wordvectors.org (Faruqui and Dyer, 2014).\nscores of word vector models on semantic benchmarks. QVEC and QVEC-CCA employ the semantic supersense-dimension vectors described in \u00a73. In table 3, we show correlations between intrinsic scores (word similarity/QVEC/QVEC-CCA) and extrinsic scores across semantic benchmarks for 300-dimensional vectors. QVEC-CCA obtains high positive correlation with all the semantic tasks, and outperforms QVEC on two tasks.\nIn table 4, we evaluate QVEC and QVEC-CCA on syntactic benchmarks. We first use linguistic vectors with dimensions corresponding to part-ofspeech tags (denoted as PTB). Then, we use linguistic vectors which are a concatenation of the semantic and syntactic matrices described in \u00a73 for words that occur in both matrices; this setup is denoted as PTB+SST.\nAlthough some word similarity tasks obtain high correlations with syntactic applications, these results are inconsistent, and vary from a high negative to a high positive correlation. Conversely, QVEC and QVEC-CCA consistently obtain moderate-to-high positive correlations with the downstream tasks.\nComparing performance of QVEC-CCA in PTB and PTB+SST setups sheds light on the importance of linguistic signals captured by the linguistic matrices. Appending supersense-annotated columns\nto the linguistic matrix which already contains POS-annotated columns does not affect correlations of QVEC-CCA with the POS tagging task, since the additional linguistic information is not relevant for approximating how well dimensions of word embeddings encode POS-related properties. In the case of dependency parsing\u2014the task which encodes not only syntactic, but also semantic information (e.g., captured by subjectverb-object relations)\u2014supersenses introduce relevant linguistic signals that are not present in POSannotated columns. Thus, appending supersenseannotated columns to the linguistic matrix improves correlation of QVEC-CCA with the dependency parsing task."}, {"heading": "5 Conclusion", "text": "We introduced QVEC-CCA\u2014an approach to intrinsic evaluation of word embeddings. We also showed that both QVEC and QVEC-CCA are not limited to semantic evaluation, but are general approaches, that can evaluate word vector content with respect to desired linguistic properties. Semantic and syntactic linguistic features that we use to construct linguistic dimension matrices are rather coarse, thus the proposed evaluation can approximate a range of downstream tasks, but may not be sufficient to evaluate finergrained features. In the future work we propose to exploit existing semantic, syntactic, morphological, and typological resources (e.g., universal dependencies treebank (Agic\u0301 et al., 2015) and WALS (Dryer and Haspelmath, 2013)), and also multilingual resources (e.g., Danish supersenses (Mart\u00ednez Alonso et al., 2015)) to construct better linguistic matrices, suited for evaluating vectors used in additional NLP tasks."}, {"heading": "Acknowledgments", "text": "This work was supported by the National Science Foundation through award IIS-1526745. We thank Benjamin Wilson for helpful comments."}], "references": [{"title": "Universal dependencies 1.1. LINDAT/CLARIN digital library", "author": ["Prokopis Prokopidis", "Sampo Pyysalo", "Wolfgang Seeker", "Mojgan Seraji", "Natalia Silveira", "Maria Simi", "Kiril Simov", "Aaron Smith", "Reut Tsarfaty", "Veronika Vincze", "Daniel Zeman"], "venue": null, "citeRegEx": "Prokopidis et al\\.,? \\Q2015\\E", "shortCiteRegEx": "Prokopidis et al\\.", "year": 2015}, {"title": "Tailoring continuous word representations for dependency parsing", "author": ["Bansal et al.2014] Mohit Bansal", "Kevin Gimpel", "Karen Livescu"], "venue": "In Proc. of ACL", "citeRegEx": "Bansal et al\\.,? \\Q2014\\E", "shortCiteRegEx": "Bansal et al\\.", "year": 2014}, {"title": "Distributional semantics in technicolor", "author": ["Bruni et al.2012] Elia Bruni", "Gemma Boleda", "Marco Baroni", "Nam-Khanh Tran"], "venue": "In Proc. of ACL", "citeRegEx": "Bruni et al\\.,? \\Q2012\\E", "shortCiteRegEx": "Bruni et al\\.", "year": 2012}, {"title": "Word association norms, mutual information, and lexicography", "author": ["Church", "Hanks1990] Kenneth Ward Church", "Patrick Hanks"], "venue": "Computational Linguistics,", "citeRegEx": "Church et al\\.,? \\Q1990\\E", "shortCiteRegEx": "Church et al\\.", "year": 1990}, {"title": "Transition-based dependency parsing with stack long short-term memory", "author": ["Dyer et al.2015] Chris Dyer", "Miguel Ballesteros", "Wang Ling", "Austin Matthews", "Noah A. Smith"], "venue": "In Proc. of ACL", "citeRegEx": "Dyer et al\\.,? \\Q2015\\E", "shortCiteRegEx": "Dyer et al\\.", "year": 2015}, {"title": "Community evaluation and exchange of word vectors at wordvectors.org", "author": ["Faruqui", "Dyer2014] Manaal Faruqui", "Chris Dyer"], "venue": "In Proc. of ACL (Demonstrations)", "citeRegEx": "Faruqui et al\\.,? \\Q2014\\E", "shortCiteRegEx": "Faruqui et al\\.", "year": 2014}, {"title": "Retrofitting word vectors to semantic lexicons", "author": ["Jesse Dodge", "Sujay Kumar Jauhar", "Chris Dyer", "Noah A. Smith", "Eduard Hovy"], "venue": "In Proc. of NAACL", "citeRegEx": "Faruqui et al\\.,? \\Q2015\\E", "shortCiteRegEx": "Faruqui et al\\.", "year": 2015}, {"title": "Placing search in context: the concept revisited", "author": ["Evgeniy Gabrilovich", "Yossi Matias", "Ehud Rivlin", "Zach Solan", "Gadi Wolfman", "Eytan Ruppin"], "venue": "In Proc. of WWW", "citeRegEx": "Finkelstein et al\\.,? \\Q2001\\E", "shortCiteRegEx": "Finkelstein et al\\.", "year": 2001}, {"title": "Revisiting embedding features for simple semi-supervised learning", "author": ["Jiang Guo", "Wanxiang Che", "Haifeng Wang", "Ting Liu"], "venue": "In Proc. of EMNLP", "citeRegEx": "Guo et al\\.,? \\Q2014\\E", "shortCiteRegEx": "Guo et al\\.", "year": 2014}, {"title": "Canonical correlation analysis: An overview with application to learning methods", "author": ["Sandor Szedmak", "John Shawe-Taylor"], "venue": "Neural Computation,", "citeRegEx": "Hardoon et al\\.,? \\Q2004\\E", "shortCiteRegEx": "Hardoon et al\\.", "year": 2004}, {"title": "SimLex-999: Evaluating semantic models with (genuine) similarity estimation", "author": ["Hill et al.2014] Felix Hill", "Roi Reichart", "Anna Korhonen"], "venue": null, "citeRegEx": "Hill et al\\.,? \\Q2014\\E", "shortCiteRegEx": "Hill et al\\.", "year": 2014}, {"title": "Neural architectures for named entity recognition", "author": ["Miguel Ballesteros", "Sandeep Subramanian", "Kazuya Kawakami", "Chris Dyer"], "venue": "In Proc. of NAACL", "citeRegEx": "Lample et al\\.,? \\Q2016\\E", "shortCiteRegEx": "Lample et al\\.", "year": 2016}, {"title": "Fish transporters and miracle homes: How compositional distributional semantics can help NP parsing", "author": ["Eva Maria Vecchi", "Marco Baroni"], "venue": "In Proc. of EMNLP", "citeRegEx": "Lazaridou et al\\.,? \\Q2013\\E", "shortCiteRegEx": "Lazaridou et al\\.", "year": 2013}, {"title": "2015a. Not all contexts are created equal: Better word representations with variable attention", "author": ["Ling et al.2015a] Wang Ling", "Lin Chu-Cheng", "Yulia Tsvetkov", "Silvio Amir", "Ramon Fermandez", "Chris Dyer", "Alan W Black", "Isabel Trancoso"], "venue": null, "citeRegEx": "Ling et al\\.,? \\Q2015\\E", "shortCiteRegEx": "Ling et al\\.", "year": 2015}, {"title": "2015b. Two/too simple adaptations of word2vec for syntax problems", "author": ["Ling et al.2015b] Wang Ling", "Chris Dyer", "Alan Black", "Isabel Trancoso"], "venue": "In Proc. of NAACL", "citeRegEx": "Ling et al\\.,? \\Q2015\\E", "shortCiteRegEx": "Ling et al\\.", "year": 2015}, {"title": "Building a large annotated corpus of English: The penn treebank", "author": ["Mary Ann Marcinkiewicz", "Beatrice Santorini"], "venue": null, "citeRegEx": "Marcus et al\\.,? \\Q1993\\E", "shortCiteRegEx": "Marcus et al\\.", "year": 1993}, {"title": "Supersense tagging for Danish", "author": ["Anders Johannsen", "Sussi Olsen", "Sanni Nimb", "Nicolai Hartvig S\u00f8rensen", "Anna Braasch", "Anders S\u00f8gaard", "Bolette Sandford Pedersen"], "venue": "In Proc. of NODALIDA,", "citeRegEx": "Alonso et al\\.,? \\Q2015\\E", "shortCiteRegEx": "Alonso et al\\.", "year": 2015}, {"title": "Efficient estimation of word representations in vector space", "author": ["Kai Chen", "Greg Corrado", "Jeffrey Dean"], "venue": "In Proc. of ICLR", "citeRegEx": "Mikolov et al\\.,? \\Q2013\\E", "shortCiteRegEx": "Mikolov et al\\.", "year": 2013}, {"title": "A semantic concordance", "author": ["Claudia Leacock", "Randee Tengi", "Ross T. Bunker"], "venue": "In Proc. of HLT,", "citeRegEx": "Miller et al\\.,? \\Q1993\\E", "shortCiteRegEx": "Miller et al\\.", "year": 1993}, {"title": "GloVe: Global vectors for word representation", "author": ["Richard Socher", "Christopher D. Manning"], "venue": "In Proc. of EMNLP", "citeRegEx": "Pennington et al\\.,? \\Q2014\\E", "shortCiteRegEx": "Pennington et al\\.", "year": 2014}, {"title": "Recursive deep models for semantic compositionality over a sentiment treebank", "author": ["Alex Perelygin", "Jean Wu", "Jason Chuang", "Christopher D. Manning", "Andrew Y. Ng", "Christopher Potts"], "venue": "In Proc. of EMNLP", "citeRegEx": "Socher et al\\.,? \\Q2013\\E", "shortCiteRegEx": "Socher et al\\.", "year": 2013}, {"title": "Intriguing properties of neural networks", "author": ["Wojciech Zaremba", "Ilya Sutskever", "Joan Bruna", "Dumitru Erhan", "Ian Goodfellow", "Rob Fergus"], "venue": "In Proc. of ICLR", "citeRegEx": "Szegedy et al\\.,? \\Q2014\\E", "shortCiteRegEx": "Szegedy et al\\.", "year": 2014}, {"title": "Metaphor detection with cross-lingual model transfer", "author": ["Leonid Boytsov", "Anatole Gershman", "Eric Nyberg", "Chris Dyer"], "venue": "In Proc. of ACL,", "citeRegEx": "Tsvetkov et al\\.,? \\Q2014\\E", "shortCiteRegEx": "Tsvetkov et al\\.", "year": 2014}, {"title": "Evaluation of word vector representations by subspace alignment", "author": ["Manaal Faruqui", "Wang Ling", "Guillaume Lample", "Chris Dyer"], "venue": "In Proc. of EMNLP,", "citeRegEx": "Tsvetkov et al\\.,? \\Q2015\\E", "shortCiteRegEx": "Tsvetkov et al\\.", "year": 2015}, {"title": "Word representations: a simple and general method for semi-supervised learning", "author": ["Turian et al.2010] Joseph Turian", "Lev Ratinov", "Yoshua Bengio"], "venue": "In Proc. of ACL", "citeRegEx": "Turian et al\\.,? \\Q2010\\E", "shortCiteRegEx": "Turian et al\\.", "year": 2010}], "referenceMentions": [{"referenceID": 21, "context": "trary (Szegedy et al., 2014).", "startOffset": 6, "endOffset": 28}, {"referenceID": 23, "context": "method is a modification of QVEC\u2014an evaluation based on alignment of embeddings to a matrix of features extracted from a linguistic resource (Tsvetkov et al., 2015).", "startOffset": 141, "endOffset": 164}, {"referenceID": 18, "context": "(2015) exploit supersense annotations in a WordNetannotated corpus\u2014SemCor (Miller et al., 1993).", "startOffset": 74, "endOffset": 95}, {"referenceID": 21, "context": "To evaluate the semantic content of word vectors, Tsvetkov et al. (2015) exploit supersense annotations in a WordNetannotated corpus\u2014SemCor (Miller et al.", "startOffset": 50, "endOffset": 73}, {"referenceID": 22, "context": "We replicate the experimental setup of Tsvetkov et al. (2015):", "startOffset": 39, "endOffset": 62}, {"referenceID": 17, "context": "\u2022 We first train 21 word vector models: variants of CBOW and Skip-Gram models (Mikolov et al., 2013); their modifications CWindow, Structured Skip-Gram, and CBOW with Attention (Ling et al.", "startOffset": 78, "endOffset": 100}, {"referenceID": 19, "context": ", 2015a); GloVe vectors (Pennington et al., 2014); Latent Semantic Analysis (LSA) based vectors (Church and Hanks, 1990); and retrofitted GloVe and LSA vectors (Faruqui et al.", "startOffset": 24, "endOffset": 49}, {"referenceID": 6, "context": ", 2014); Latent Semantic Analysis (LSA) based vectors (Church and Hanks, 1990); and retrofitted GloVe and LSA vectors (Faruqui et al., 2015).", "startOffset": 118, "endOffset": 140}, {"referenceID": 2, "context": ", 2001, WS353), MEN dataset (Bruni et al., 2012), and SimLex-999 dataset (Hill et al.", "startOffset": 28, "endOffset": 48}, {"referenceID": 22, "context": "We extend the setup of Tsvetkov et al. (2015) with two syntactic benchmarks, and evaluate QVEC-CCA with the syntactic matrix.", "startOffset": 23, "endOffset": 46}, {"referenceID": 11, "context": "task is POS tagging; we use the LSTM-CRF model (Lample et al., 2016), and the second is dependency parsing (Parse), using the stack-LSTM model of Dyer et al.", "startOffset": 47, "endOffset": 68}, {"referenceID": 4, "context": ", 2016), and the second is dependency parsing (Parse), using the stack-LSTM model of Dyer et al. (2015).", "startOffset": 85, "endOffset": 104}], "year": 2016, "abstractText": "We introduce QVEC-CCA\u2014an intrinsic evaluation metric for word vector representations based on correlations of learned vectors with features extracted from linguistic resources. We show that QVECCCA scores are an effective proxy for a range of extrinsic semantic and syntactic tasks. We also show that the proposed evaluation obtains higher and more consistent correlations with downstream tasks, compared to existing approaches to intrinsic evaluation of word vectors that are based on word similarity.", "creator": "LaTeX with hyperref package"}}}