{"id": "1609.00292", "review": {"conference": "arxiv", "VERSION": "v1", "DATE_OF_SUBMISSION": "1-Sep-2016", "title": "Crowdsourcing with Unsure Option", "abstract": "one of the fundamental organizational problems in managed crowdsourcing is the trade - off between number of selected workers needed for high - end accuracy aggregation and the budget to obtain pay. for mass saving budget, assume it is important to ensure high quality of the crowd - sourced bid labels, when hence the total estimation cost on lowest label premium collection objectives will continually be critically reduced. nonetheless since meeting the potential self - confidence of workers extremely often has close relationship relation with their abilities, one a possible way for quality criterion control compliance is to request workers effort to work actively on some problems only provided when expressing they feel critically confident, presented by psychological means merely of individuals providing unsure option to them. on picking the true other hand, allowing workers to best choose what unsure answer option also leads to the potential danger of budget waste. in this way work, we propose the central analysis towards understanding when using providing unsure option indeed potentially leads lead to increasingly significant cost reduction, as well as how the organizational confidence regarding threshold variance is somehow set. we also propose an online mechanism, which is alternative for simple threshold configuration selection when managing the estimation of the crowd matching ability distribution is considerably difficult.", "histories": [["v1", "Thu, 1 Sep 2016 15:53:52 GMT  (90kb)", "http://arxiv.org/abs/1609.00292v1", "25 pages, 1 figures"], ["v2", "Sat, 12 Aug 2017 12:03:32 GMT  (49kb)", "http://arxiv.org/abs/1609.00292v2", "25 pages, 1 figures"]], "COMMENTS": "25 pages, 1 figures", "reviews": [], "SUBJECTS": "cs.AI cs.HC", "authors": ["yao-xiang ding", "zhi-hua zhou"], "accepted": false, "id": "1609.00292"}, "pdf": {"name": "1609.00292.pdf", "metadata": {"source": "CRF", "title": null, "authors": ["Zhi-Hua Zhou"], "emails": ["zhouzh@lamda.nju.edu.cn"], "sections": [{"heading": null, "text": "ar X\niv :1\n60 9.\n00 29\n2v 1\n[ cs\n.A I]\n1 S\nep 2\nOne of the fundamental problems in crowdsourcing is the trade-off between number of workers needed for high-accuracy aggregation and the budget to pay. For saving budget, it is important to ensure high quality of the crowd-sourced labels, hence the total cost on label collection will be reduced. Since the self-confidence of workers often has close relationship with their abilities, a possible way for quality control is to request workers to work on problems only when they feel confident, by means of providing unsure option to them. On the other hand, allowing workers to choose unsure option also leads to the potential danger of budget waste. In this work, we propose the analysis towards understanding when providing unsure option indeed leads to significant cost reduction, as well as how the confidence threshold is set. We also propose an online mechanism, which is alternative for threshold selection when the estimation of the crowd ability distribution is difficult.\nKeywords: crowdsourcing, unsure option"}, {"heading": "1. Introduction", "text": "Labeled data play a crucial role in machine learning. In recent years, crowdsourcing has been a popular cost-saving way for label collection. The power of crowdsourcing relies on two conditions. One is the possibility to obtain highly accurate estimation of true labels by aggregating the noisy labels returned by workers. The other one is that the cost for label collection to achieve desired accuracy is not large, hence is much more economical than to recruit domain experts. Particularly, in practice the budget to pay is\n\u2217Corresponding author. Email: zhouzh@lamda.nju.edu.cn\nPreprint submitted to Artificial Intelligence Journal September 2, 2016\nusually limited. So it is important to study approaches for balancing between cost reduction meanwhile achieving desired estimation performance.\nUnfortunately, there is a trade-off between aggregation accuracy and cost. As more labels are collected, typically, the aggregated accuracy increases, while the cost also increases. To balance between the both sides, one way is to design better label aggregation methods, without controlling over the data collection process (Raykar et al., 2010; Dalvi et al., 2013; Zhang et al., 2014). Another more active way is to design more effective task assignment mechanisms, aiming at saving budget meanwhile maintaining the quality of aggregation (Karger et al., 2011; Ho et al., 2013). However, all these methods do not consider to utilize the subjective behavior of workers. Though seldom studied previously, it is interesting to consider an alternative kind of mechanisms which utilize the subjective uncertainty of the crowd, by allowing workers to choose unsure option instead of actually labeling the data. Since the self-confidence of workers often has close relationship with their potential ability, the quality of returned labels is expected to be guaranteed. In Zhong et al. (2015), the setting of providing unsure option is studied under the active learning with crowd scenario, which empirically justifies the effect of label quality improvement. On the other hand, for ensuring honesty of one worker, choosing unsure option should also be paid, otherwise one would prefer just to guess on the task. As a result, providing unsure option also leads to the potential danger of budget waste, since under the same budget, the number of labels gathered is reduced. It is interesting to theoretically study the condition under which providing unsure option can lead to significant cost reduction.\nIn this work, we take the first step towards the analysis of the cost-saving effect of the crowdsourcing with unsure option setting. We show that simple statistics, i.e. mean and variance of the crowd ability, are key quantities to consider in the analysis. We show that: (1) They are sufficient statistics to provide the sufficient condition on whether some unsure mechanism can indeed lead to significant cost reduction. (2) Based on them, the proper confidence threshold can be calculated. (3) When they can not easily be estimated due to the lack of enough tasks with known labels, an online bandit based algorithm can be applied to set the confidence threshold.\nThe rest of this paper is organized as follows. Section 2 introduces related work. In section 3, we describe the basic formulations and assumptions. Section 4 and section 5 give theoretical analysis on quality ensured and unsure mechanisms, which are main results and contributions of this paper. Section\n6 discusses possible extensions of payment schemes. Section 7 introduces the online algorithm. Section 8 shows experimental results. Section 9 concludes this paper."}, {"heading": "2. Related Work", "text": "Crowdsourcing, typically crowd-sourced data labeling, has been a fruitful topic in machine learning research. One of the central tasks is to maintain learning performance using noisy labels returned by the crowd. This can be done by learning good classifiers using noisy labels directly (Dekel and Shamir, 2009a,b; Urner et al., 2012). Meanwhile, a majority of works focus on the accurate estimation of underlying true labels (Raykar et al., 2010; Zhou et al., 2012; Dalvi et al., 2013; Li and Yu, 2014; Zhang et al., 2014; Zhou et al., 2015). The target of these works is improving learning performance, without direct consideration on the cost of label collection. Wang and Zhou (2016) further points out that it is important to consider the cost-saving effect in crowdsourcing. Another mainstream of researches is on task assignment and budget allocation, which try to balance between aggregation accuracy and data collection cost. Wang and Zhou (2015) theoretically shows that in proper conditions, it is indeed possible to achieve desired accuracy with reasonable cost in crowdsourcing. To achieve this target, both non-adaptive task assignment mechanisms (Karger et al., 2011; Tran-Thanh et al., 2013), which assign tasks off-line before worker comes, and the adaptive mechanisms which assign tasks in online fashion (Ho et al., 2013; Chen et al., 2013; Abbasi-Yadkori et al., 2015), have been studied thoroughly with strong theoretical guarantees. The trade-off between aggregation accuracy and data collection cost is also the major problem discussed in this paper. The difference is that task assignment and budget allocation mechanisms focus on improving the behavior of the task requester, while in designing unsure mechanism, the target is to improve the behavior of workers, by utilizing their own uncertainty about the tasks. There have been several works for employing bandit setting in crowdsourcing. In Abraham et al. (2013), a special crowdsourcing problem called the bandit survey problem is considered. In Jain et al. (2014), the bandit setting is employed to deal with the task assignment problem. In Zhou et al. (2014), the bandit arm identification problem is employed for worker selection. All these works have different settings to our work.\nThere are not many works studying the possibility to employ unsure setting in crowdsourcing. In Zhong et al. (2015), unsure option is provided un-\nder the active learning from crowd scenario. When querying labels from the crowd, the workers are allowed to choose unsure option when their confidence is low. The purpose of allowing unsure option is to improve worker reliability, which is similar to the purpose of employing unsure mechanism in our work. The difference is that instead of considering active learning scenario, we consider general crowdsouring tasks. Our work focuses on the analysis of cost-saving effect for the crowdsourcing with unsure option setting, while in Zhong et al. (2015) they empirically justify that providing unsure option to the crowd improves labeling quality. In Shah and Zhou (2015), a double or nothing incentive compatible mechanism is proposed to ensure workers to behave honestly based on their self-confidence. The proposed mechanism is provable to avoid spammers from the crowd, under the assumption that every worker wants to maximize the expected payment. In their setting, unsure option is provided for ensuring high quality of returned labels. In our work, we directly analyse how allowing unsure option affects the accuracycost trade-off, other than considering incentive compatible mechanisms."}, {"heading": "3. Problem Formulation", "text": "We consider the tasks of collecting binary labels, and adopt the wellknown Dawid-Skene model (Dawid and Skene, 1979; Zhou et al., 2012; Zhang et al., 2014; Karger et al., 2011; Zhou et al., 2015; Li and Yu, 2014) under the binary classification case. Under the D-S model, the tasks are assumed to be homogeneous, which means that the potential cost for different tasks are the same. As a result, in rest of the paper, we focus on dealing with the cost for one single task.\nWe adopt the anonymous worker assumption introduced in Karger et al. (2011) for modeling the crowd. Denoting \u03b8i as the ability of the ith worker, i.e. the probability that the returned label is correct, the process of choosing a number of anonymous workers is modeled as independent random draws \u03b81, \u03b82, \u03b83 \u00b7 \u00b7 \u00b7 \u2208 [0, 1] over the crowd ability distribution \u03b8i \u223c A. After one worker is drawn, she/he is asked to return the label or choose unsure option based on the crowdsourcing mechanism applied, such as the quality ensured mechanism or unsure mechanism which are introduced below, or return the label directly if no mechanism is applied. The accuracy of the returned label is decided by the ability of the worker. We assume that after label collection, labels are aggregated by majority voting, i.e., the label chosen by majority of workers is the estimated label.\nWe introduce three assumptions on the crowd ability distribution A:\n\u00b5 > 1/2,\nFor any t > 0, Pr ( \u03b8 > 1\n2 + t\n) > Pr ( \u03b8 < 1\n2 \u2212 t\n)\n,\n\u03c32 \u2265 2(2\u00b5\u2212 1)2,\n(1)\nwhere \u00b5 and \u03c32 are mean and variance of A. The first assumption states that the mean ability of the crowd is strictly above 1/2. We do not consider the case \u00b5 \u2264 1/2 since it is well known for majority voting, the result converges only when \u00b5 > 1/2. The second assumption states that at any level t, the upper tail probability is always larger than the lower tail probability. This assumption is not strict in practice since typically we always have more highability workers in the crowd. The third assumption is a constraint on the magnitude of variance. It is also known for majority voting, when the mean accuracy of returned labels, i.e. \u00b5 is already high, the number of labels needed for aggregation is rather small so employing unsure mechanism is not necessary. As a result, in this paper we mainly consider those hard tasks, on which the mean ability of the crowd is close to 1/2. So this constraint on the magnitude of variance is weak.\nWe define the confidence of one worker to be the subjective accuracy one believes to have, which is denoted by c1, c2, c3 \u00b7 \u00b7 \u00b7 \u2208 [1/2, 1]. The minimum value is 1/2 since the worst choice for one worker is to make random guess. If ci is close to 1/2, it is reasonable to assume that \u03b8i is also close to 1/2, since when one worker subjectively makes random guess, the resulting accuracy follows. If ci is close to one, one possibility is that \u03b8i is also close to one. The other possibility is that \u03b8i is close to zero. It means that the worker always returns incorrect labels, which indicates that the worker has high selfconfidence of labeling, meanwhile the ability is low. Under this situation, the ability and confidence may have a large gap.\nTo model the relationship between confidence and ability, a straightforward way is first to assume that they are equivalent, that is to assume \u03b8i = ci for every worker, then further to consider relaxations for making the setting closer to practice. But assuming equivalence of confidence and ability immediately leads to an impractical assumption such that \u03b8i \u2265 1/2, so it is not possible to model those workers who have \u03b8i < 1/2. Note that by providing unsure option, the target is to ensure the quality of returned labels. At first, we can consider the mechanism, which simply filters out low quality labels\nbased on ability without using the information of confidence. Based on this subroutine, we further consider the setting which provides unsure option, by introducing practical assumptions on the relationship between self-confidence and ability.\nAs a consequence, we define a quality ensured mechanism as following process: given threshold T , when one worker is drawn for labeling, the label is accepted only when this worker\u2019s ability is above T . This mechanism is ideal since it assumes that once a worker is drawn, the ability can be also obtained.\nAn unsure mechanism is a surrogate for this idealized mechanism. When unsure mechanism is employed, a confidence threshold T is adopted. Worker i is asked to do labeling only when ci \u2265 T , otherwise he/she is asked to use unsure option, for example to return label \u201c0\u201d which represents unsureness.\nThe budget is defined as the total cost for label collection of one single task. For simplification of analysis, we assume that returning one label and choosing unsure option one time are both paid for 1, i.e. the total cost equals to the total number of workers involved in the task. We assume that there are no malicious workers from the crowd, which means that the accuracy of the returned label is totally decided by one\u2019s ability on the task. As discussed in section 6, it is not hard to generalize the results for broader types of payment methods.\nThe goal of our analysis is to study on which kinds of crowd ability distribution, the quality ensured mechanism or unsure mechanism is provable to be effective:\nDefinition 1. Denote m\u2032, m as the provable cost needed with/without the quality ensured mechanism or unsure mechanism, for label aggregation being correct with probability at least 1\u2212\u03b4, an quality ensured mechanism or unsure mechanism is provable to be effective if\nm\u2032 \u226a m.\nNote that this is just a qualitative definition, and will be further quantified in Definition 2. The effectiveness is defined so that the total cost needed is significantly reduced.\nFinally, the following two inequalities are important for showing our results:\nLemma 1 (Hoeffding\u2019s inequality, Shalev-Shwartz and Ben-David (2014) lemma B.6). For independent random variables X1, X2, . . . , Xm bounded in [a, b] with E [ Xi ]\n= \u00b5i, i = {1, 2, . . . , m}, the following inequality holds:\nPr (\nm \u2211\ni=1\n\u00b5i \u2212 1\nm\nm \u2211\ni=1\nXi > \u01eb ) < exp(\u22122m\u01eb2/(b\u2212 a)2). (2)\nLemma 2 (Bernstein\u2019s inequality, Shalev-Shwartz and Ben-David (2014) lemma B.9). For independent random variables X1, X2, . . . , Xm bounded in [\u2212M,M ] with E [ Xi ]\n= 0, i = {1, 2, . . . , m} and variance \u03c321, \u03c3 2 2, . . . , \u03c3 2 m, the following inequality holds:\nPr (\nm \u2211\ni=1\nXi > \u01eb ) < exp(\u2212 \u01eb 2/2\nm \u2211\ni=1\n\u03c32i +M\u01eb/3 ). (3)"}, {"heading": "4. Analysis on Quality Ensured Mechanisms", "text": "In this section, we focus on studying quality ensured mechanisms, which ensure that labels are accepted only when the ability is above the threshold T . We propose the analysis on the properties that the crowd ability distribution should satisfy for a quality ensured mechanism to be effective. The analysis is based on simple statistics of the crowd ability distribution, such as mean and variance, which can be estimated when sufficient labeled golden standard examples are available. The property of quality ensuring, which states that labels are returned when the ability is indeed above the threshold T , is not satisfied by the unsure mechanism, since this potentially assumes that the self-confidence and ability of one worker are equivalent. In this section, the target is to show the main framework of the analysis, which forms the foundation of analysing the unsure mechanism discussed in Section 5.\nTo show that a quality ensured mechanism is effective, it is necessary to compare between sample complexity bounds derived for both situations with and without the mechanism. The first result is on the cost needed for correct estimation for simple aggregation without any mechanisms:\nLemma 3. Let \u00b5 denote the mean of crowd ability distribution A, for simple majority voting aggregation under the settings introduced in Section 3, the\naggregated label is correct with probability at least 1\u2212\u03b4 if the total cost satisfies\nm \u2265 2[1 + 2 3 (2\u00b5\u2212 1)] log 1 \u03b4\n(2\u00b5\u2212 1)2 . (4)\nProof. Given labels a1, a2, . . . , am, ai \u2208 {\u22121, 1} from workers, the majority voting rule is:\ny\u0302 = 1 \u2194 m \u2211\ni=1\nai >= 0,\ny\u0302 = \u22121 \u2194 m \u2211\ni=1\nai < 0.\nThe target is to bound Pr ( yy\u0302 < 0 ) = Pr ( y m \u2211\ni=1\nai < 0 ) . Note that for\n\u2200i, E [ yai ] = Pr ( yai = 1 ) \u2212 Pr ( yai = \u22121 ) = 2\u03b8i \u2212 1. Then E [\nm \u2211\ni=1\nyai ] =\nm \u2211\ni=1\n(2\u03b8i \u2212 1). By assumption, E [\nm \u2211\ni=1\n\u03b8i ] = m\u00b5, then\nPr ( y\nm \u2211\ni=1\nai < 0 )\n= Pr ( E [ y m \u2211\ni=1\nai ] \u2212 y m \u2211\ni=1\nai > E [ y m \u2211\ni=1\nai ])\n= Pr (\nm \u2211\ni=1\n(2\u03b8i \u2212 1)\u2212 y m \u2211\ni=1\nai >\nm \u2211\ni=1\n(2\u03b8i \u2212 1) )\n= Pr ( m(2\u00b5\u2212 1)\u2212 m \u2211\ni=1\n(2\u03b8i \u2212 1) + m \u2211\ni=1\n(2\u03b8i \u2212 1)\u2212 y m \u2211\ni=1\nai > m(2\u00b5\u2212 1) )\n= Pr ( E [\nm \u2211\ni=1\n(2\u03b8i \u2212 1) + y m \u2211\ni=1\nai ] \u2212 ( m \u2211\ni=1\n(2\u03b8i \u2212 1) + y m \u2211\ni=1\nai) > m(2\u00b5\u2212 1) )\n= Pr (\nm \u2211\ni=1\n(2\u00b5\u2212 1\u2212 yai) > m(2\u00b5\u2212 1) ) .\n2\u00b5\u22121\u2212yai is a zero mean random variable bounded in [\u22122, 2], with variance\nE [ (2\u00b5\u2212 1\u2212 yai)2 ] = E [ (2\u00b5\u2212 1)2 \u2212 2(2\u00b5\u2212 1)yai + (yai)2 ]\n= (2\u00b5\u2212 1)2 + E [ (yai) 2 ] \u2212 2(2\u00b5\u2212 1)E [ yai ] = (2\u00b5\u2212 1)2 + 1\u2212 2(2\u00b5\u2212 1)\u03b8i).\n1 m\nm \u2211\ni=1\n[(2\u00b5\u22121)2+1\u22122(2\u00b5\u22121)\u03b8i)] \u2192 (2\u00b5\u22121)2+1\u22122(2\u00b5\u22121)\u00b5 as m \u2192 \u221e,\nand lim \u00b5\u2192 1\n2\n1\u22122(2\u00b5\u22121)\u00b5 2\u00b5\u22121 = \u221e. We use a lemma to bound the variance:\nLemma 4 (Boucheron et al. (2013), Corollary 3.2). If \u2211m\ni=1Xi has the bounded difference property with constant c, then\nVar( m \u2211\ni=1\nXi) 2 \u2264 1\n4\nm \u2211\ni=1\nc2.\nFrom this we obtain that Var( m \u2211\ni=1 (2\u00b5\u2212 1 + yai)) \u2264 m since the bounded difference property with constant 2 holds. By equation 3,\nPr ( yy\u0302 < 0 ) < exp(\u2212 m 2(2\u00b5\u2212 1)2/2\nm \u2211\ni=1\nVar(2\u00b5\u2212 1 + yai) + 2m(2\u00b5\u2212 1)/3 )\n= exp(\u2212 m 2(2\u00b5\u2212 1)2/2\nVar( m \u2211\ni=1\n(2\u00b5\u2212 1 + yai)) + 2m(2\u00b5\u2212 1)/3 )\n\u2264 exp(\u2212 m(2\u00b5\u2212 1) 2/2\n1 + 2(2\u00b5\u2212 1)/3).\nLet \u03b4 = exp(\u2212 m(2\u00b5\u22121)2/2 1+2(2\u00b5\u22121)/3 ), solving for m gives the desired result.\nThe main order term in equation 3 is 1 (2\u00b5\u22121)2 . Then we show another lemma, which gives bound on cost when the mechanism is available. Recall that when the mechanism is allowed, a label is accepted only when the worker\u2019s ability is above the threshold T .\nLemma 5. Let T be the threshold, \u03b7 = Pr ( \u03b8 \u2265 T )\nbe the upper tail probability of crowd ability distribution A. When quality ensured mechanism is\nemployed, for majority voting aggregation under the settings introduced in section 3, then the aggregated label is correct with probability at least 1\u2212 \u03b4 if the total cost satisfies\nm\u2032 \u2265 2(1\u2212 \u03b7) log 2 \u03b4\n\u03b7 +\n2 log 2 \u03b4\n(2T \u2212 1)2\u03b7 + 2 3\u03b7 . (5)\nProof. The first step: for those workers whose confidence is larger than T , we show bound on the number of workers so that the aggregated estimation is incorrect with probability at most \u03b4/2.\nThe target is to bound Pr ( yy\u0302 < 0 ) = Pr ( y m \u2211\ni=1\nai < 0 ) . Note that for\n\u2200i, E [ yai ] = Pr ( yai = 1 ) \u2212 Pr ( yai = \u22121 ) = 2\u03b8i \u2212 1 \u2265 2T \u2212 1. Then E [ m \u2211\ni=1\nai ] \u2265 m(2T \u2212 1). Then\nPr ( y\nm \u2211\ni=1\nai < 0 ) = Pr ( E [ y\nm \u2211\ni=1\nai ] \u2212 y m \u2211\ni=1\nai > E [ y\nm \u2211\ni=1\nai ])\n\u2264 Pr ( E [ y\nm \u2211\ni=1\nai ] \u2212 y m \u2211\ni=1\nai > m(2T \u2212 1) ) .\nyai is independent random variable bounded in [-1,1], by equation 2,\nPr ( yy\u0302 < 0 ) < exp(\u2212m(2T \u2212 1)2/2). Let \u03b4/2 = exp(\u2212m(2T \u2212 1)2/2), solving for m gives\nm = 2 log(2/\u03b4)\n(2T \u2212 1)2 . (6)\nThe second step: we show bound on sufficient number of workers have confidence larger than T .\nConsider random variable I(\u03b8 > T ), The target is to bound Pr (\nm\u2032 \u2211\ni=1\nI(\u03b8 >\nT ) < m ) . We have\nPr (\nm\u2032 \u2211\ni=1\nI(\u03b8 > T ) < m )\n= Pr ( E [\nm\u2032 \u2211\ni=1\nI(\u03b8 > T ) ] \u2212 m\u2032 \u2211\ni=1\nI(\u03b8 > T ) > E [\nm\u2032 \u2211\ni=1\nI(\u03b8 > T ) ] \u2212m ) .\nSince E [ I(\u03b8 > T ) ] = Pr ( \u03b8 > T ) = \u03b7,E [ I(\u03b8 > T )\u2212E [ I(\u03b8 > T ) ]]2 = \u03b7(1\u2212\u03b7), by equation 3,\nPr (\nm\u2032 \u2211\ni=1\nI(\u03b8 > T ) < m ) < exp(\u2212 (m \u2032\u03b7 \u2212m)2/2\nm\u2032\u03b7(1\u2212 \u03b7) + (m\u2032\u03b7 \u2212m)/3).\nLet exp(\u2212 (m\u2032\u03b7\u2212m)2/2 m\u2032\u03b7(1\u2212\u03b7)+(m\u2032\u03b7\u2212m)/3 ) = \u03b4/2, we have\n1 2 \u03b72m\u20322 \u2212 [(1\u2212 \u03b7) log 2 \u03b4 +m+ 1 3 ]\u03b7m\u2032 + 1 2 m2 + 1 3 m log 2 \u03b4 = 0,\nthen\nm\u2032 = (1\u2212 \u03b7) log 2 \u03b4 +m+ 1\n3 + \u221a [(1\u2212 \u03b7) log 2 \u03b4 +m+ 1 3 ]2 \u2212m2 \u2212 2 3 m log 2 \u03b4\n\u03b7 .\nIt is easy to see that m\u2032 = 2((1\u2212\u03b7) log 2 \u03b4 +m+ 1 3 )\n\u03b7 satisfies the condition. To-\ngether with equation 6, the desired result can be shown by union bound.\nLemma 5 shows that the main order term for cost of employing quality ensured mechanism is 1\n(2T\u22121)2\u03b7 . Given above results in hand, we propose more concrete definition on effectiveness, based on how much improvement on cost reduction in order of the cost:\nDefinition 2. We say a quality ensured mechanism, or unsure mechanism with ability or confidence threshold T is at least \u03b1-effective if it is provable that for the aggregated label being correct with probability at least 1\u2212 \u03b4,\n1 (2T \u2212 1)2\u03b7 \u2264 1 (2\u00b5\u2212 1)\u03b1 . (7)\nWhen the above condition is satisfied, by Lemma 3 and Lemma 5, the bound on costs improves in order of 1\n2\u00b5\u22121 , from 2 to \u03b1. \u03b1 is a measure of significance, as \u03b1 decreases, the improvement on sample complexity becomes more significant.\nNow we are ready to give the main result of this section, which shows a general condition for some quality ensured mechanism to be at least \u03b1effective.\nTheorem 1. For crowd ability distribution with mean \u00b5 and variance \u03c32, assume the condition in Equation (1) and confidence threshold T > 1\n2 . As-\nsume that T is set with a lower bounding variable 2\u00b5\u2212 1 < M < 1 such that T \u2265 1\u2212 \u00b5+M/2. When\n( \u221a 1 + \u221a 3\u03c32 + \u221a 1\u2212 4\u03c32)M2\n4 \u221a 3\u03c34[M \u2212 (2\u00b5\u2212 1)]2\n\u2264 1 (2\u00b5\u2212 1)\u03b1 , (8)\nthen the quality ensured mechanism with confidence threshold\nT = 1\u2212 \u00b5+ 1 2\n\u221a 1 + \u221a 1\u2212 4\u03c32 (9)\nis \u03b1-effective.\nProof. First we show a lemma which gives a general lower bound on the tail probability for random variable bounded in [0, 1].\nLemma 6. For random variable x \u223c A such that Pr ( 0 \u2264 x \u2264 1 )\n= 1, and the mean and variance of A are \u00b5 and \u03c32,under the assumption that for any t > 0, Pr (\n\u03b8 > 1 2 + t\n) > Pr ( \u03b8 < 1 2 \u2212 t ) . Then for 0 < r < \u03c3,\nPr ( |x\u2212 \u00b5| \u2265 r ) \u2265 2 \u221a 3(\u03c32 \u2212 r2) 1\u2212 4r2 .\nProof. Suppose that we have a concerntration bound Pr ( |x \u2212 \u00b5| < r )\n> A for some A > 0, then\nPr ( |x\u2212 \u00b5| \u2265 r ) \u2264 1\u2212 A. (10)\nWe then have a upper bound of variance, denote Y = |x\u2212 \u00b5|, then\n\u03c32 = E [ (x\u2212 \u00b5)2 ] =\n\u222b 1\n2\n0\ny2dP (Y \u2264 y) = \u222b 1 2\n0\n2yPr ( Y > y ) dy\n=\n\u222b r\n0\n2yPr ( Y > y ) dy +\n\u222b 1\n2\nr\n2y Pr ( Y > y ) dy\n\u2264 \u222b r\n0\n2ydy +\n\u221a\n\u222b 1\n2\nr\n4y2dy\n\u222b 1\n2\nr\n(Pr ( Y > y ) )2dy\n\u2264 \u222b r\n0\n2ydy +\n\u221a\n\u222b 1\n2\nr\n4y2dy\n\u222b 1\n2\nr\n(1\u2212 A)2dy\n\u2264 r2 + \u221a [ 1\n6 \u2212 4 3 r3]( 1 2 \u2212 r)(1\u2212 A)2,\nwhere the first inequality is due to Cauchy-Schwarz inequality, and the second inequality is due to equation 10. Then we have\n1\u2212 A \u2265 \u03c3 2 \u2212 r2 \u221a\n[1 6 \u2212 4 3 r3](1 2 \u2212 r)\n. (11)\nAs equation 11 holds without the specific choice of A, we obtain\nPr ( |x\u2212 \u00b5| \u2265 r ) \u2265 \u03c3 2 \u2212 r2 \u221a\n[1 6 \u2212 4 3 r3](1 2 \u2212 r)\n= 2 \u221a 3(\u03c32 \u2212 r2) \u221a\n[1\u2212 8r3](1\u2212 2r) .\nObserve that\n(1\u22128r3)(1\u22122r) = 1\u2212 ((2r)3+2r)+(2r)4 \u2264 1\u22122(2r)2+(2r)4 = (1\u2212 (2r)2)2.\nThen we have\nPr ( |x\u2212 \u00b5| \u2265 r ) \u2265 2 \u221a 3(\u03c32 \u2212 r2) 1\u2212 (2r)2 .\nNote that to bound \u03b7, i.e. Pr ( \u03b8 \u2265 T ) , we make use of following calcula-\ntions, by \u00b5 > 1 2 ,\nPr ( |\u03b8 \u2212 \u00b5| \u2265 r ) = Pr ( \u03b8 > \u00b5+ r ) + Pr ( \u03b8 < \u00b5\u2212 r )\n= Pr ( \u03b8 > 1 2 + (\u00b5\u2212 1 2 + r) ) + Pr ( \u03b8 < 1 2 \u2212 (\u2212\u00b5+ 1 2 + r) )\n\u2264 Pr ( \u03b8 > 1 2 + (\u2212\u00b5+ 1 2 + r) ) + Pr ( \u03b8 < 1 2 \u2212 (\u2212\u00b5+ 1 2 + r) )\n\u2264 2 Pr ( \u03b8 > 1\n2 + (\n1 2 \u2212 \u00b5+ r) ) = 2Pr ( \u03b8 > 1\u2212 \u00b5+ r ) ,\n(12) then we have\nPr ( \u03b8 > 1\u2212 \u00b5+ r ) \u2265 \u221a 3(\u03c32 \u2212 r2) 1\u2212 (2r)2 .\nNow we turn to the task of finding the minimum of 1 (2T\u22121)2\u03b7 , which is equivalent to maximizing (2T \u2212 1)2\u03b7. Relaxation can be made to make use of the lower bound given by equation 12. Let T = 1 \u2212 \u00b5 + r, t = 2r. Note that T > \u00b5 and r < \u03c3, so 2(2\u00b5\u2212 1) < t < 2\u03c3. Then we turn to the maximization of\n( \u221a 3)(\u03c32 \u2212 1\n4 t2)\n1\u2212 t2 (1\u2212 2\u00b5+ t) 2.\nSecondly, we have assumed that there exists 2\u00b5 \u2212 1 < M < 1 such that T \u2265 1 \u2212 \u00b5 +M/2, then we have (M\u2212(2\u00b5\u22121)\nM )t \u2264 t + 1 \u2212 2\u00b5. We turn to the\nmaximization of \u221a 3(M \u2212 (2\u00b5\u2212 1))2\n4M2 (4\u03c32 \u2212 t2) 1\u2212 t2 t 2.\nLet s = t2, then we consider\nmax 4(2\u00b5\u22121)2<s<4\u03c32 f(s) = 4\u03c32s\u2212 s2 1\u2212 s .\nWe then have\nf \u2032(s) = (4\u03c32 \u2212 2s)(1\u2212 s) + (4\u03c32s\u2212 s2) (1\u2212 s)2 = s2 \u2212 2s+ 4\u03c32 (1\u2212 s)2 .\nWithout consideration of constraints on s, the optimal is attained when s = 1\u2212 \u221a 1\u2212 4B\u03c32. To see that the solution satisfies the constraints, on one hand calculate s/4\u03c32 = 1\u2212 \u221a 1\u22124\u03c32 4\u03c32 . As 1 \u2212 4\u03c32 \u2264 \u221a 1\u2212 4\u03c32, so s/4\u03c32 \u2264 1. On the other hand, since \u03c32 \u2265 2(2\u00b5\u22121)2, we have \u03c32+4(2\u00b5\u22121)4 \u2265 2(2\u00b5\u22121)2 \u21d0\u21d2\n1\u22128(2\u00b5\u22121)2+162(2\u00b5\u22121)4 \u2265 1\u22124\u03c32 \u21d0\u21d2 [1\u22124(2\u00b5\u22121)2]2 \u2265 1\u22124\u03c32 \u21d0\u21d2 1\u2212 \u221a 1\u2212 4\u03c32 \u2265 4(2\u00b5\u2212 1)2. f(s) = (1\u2212 \u221a 1\u2212 4\u03c32)2. Put it altogether,\nT = 1\u2212 \u00b5+ 1 2\n\u221a 1 + \u221a 1\u2212 4\u03c32\nand\nm\u2032 = (1 +\n\u221a 1\u2212 4\u03c32)M2\n4 \u221a 3\u03c34[M \u2212 (2\u00b5\u2212 1)]2 .\nFrom the theorem, it can be seen that as \u03c32 increases, the left hand side of Equation (8) decreases such that lower \u03b1 can be achieved. In Equation (9), T increases as variance gets larger. The intuition behind is that when more workers are of high quality, the variance of crowd ability distribution increases, and we can safely make higher demand on the quality of returned labels."}, {"heading": "5. Analysis on Unsure Mechanisms", "text": "In this section, we start to consider unsure mechanisms. In the previous analysis, quality ensured mechanisms guarantee that the accuracy of returned labels is above T . However due to the mismatch between self-confidence and ability, an unsure mechanism does not guarantee this property. In special, when one is confident about his/her work, it is indeed possible for this confidence to be misleading such that the actual ability is under 1/2. As a result, relaxations should be made when considering unsure mechanisms. We make following relaxations on the relationship between one\u2019s confidence and ability:\nci \u2265 max{\u03b8i, 1\u2212 \u03b8i}. (13)\nThis is a pessimistic assumption of the crowd, since one worker is assumed to be always over-confident about his/her work, ci \u2265 \u03b8i. Recall that under quality ensured mechanism, the main order term on cost bound is\n1\n(2T\u22121)2 Pr ( \u03b8\u2265T ) . Under unsure mechanism, only the confidence c of one worker is available. If T is used as confidence threshold, since ci \u2265 \u03b8i, the effective ability threshold is \u2265 T . As a result we will always over-estimate the cost using confidence information. From this, we can see that the above assumption is indeed strict, thus makes our analysis general.\nFor further analysis, the first issue to consider is how to properly identify the underlying ability of workers. It is difficult to distinguish between actual labeling accuracy solely based on the confidence information. However we can use a few golden standard examples with known labels to test each worker. The target of this test is not to exactly estimate the ability of each worker, but to guarantee the overall quality of returned labels. We introduce the following worker testing mechanism:\n1. Keep a small pool of golden standard examples with known labels.\n2. For each worker in the crowd, k golden samples are drawn for testing ability.\n3. We only send tasks to workers who have ability > 1/2 on golden standard examples.\nNote that we assume that no rewards are paid on test examples.\nLemma 7. Assume that ci \u2265 max{\u03b8i, 1\u2212 \u03b8i}. When the unsure mechanism and the worker testing mechanism are employed, let T0 \u2265 \u221a 2 2\nbe the confidence threshold, and \u03b70 = Pr ( \u03b8 \u2265 T0 )\nbe the upper tail probability of crowd ability distribution A with mean \u00b5. For majority voting aggregation under the settings introduced in Section 3, then when k = 1, the aggregated label is correct with probability at least 1\u2212 \u03b4, if the cost satisfies\nm\u2032 \u2265 2(1\u2212 \u03b7) log 2 \u03b4\n\u03b7 +\n8 log 2 \u03b4\n(2T \u2212 1)2\u03b7 + 2 3\u03b7 , (14)\nwith\n\u03b7 = T0\u03b70 \u00b5 , T = T 20 . (15)\nProof. Denote the event that a worker passes the test as passed. There are two key quantities to consider, one is the tail probability \u03b7 = Pr (\nc \u2265 T0|passed )\n, which is the probability to have a worker with confidence above T0, another is the mean ability of workers that have confidence c \u2265 T0. We denote the tail probability under the original worker ability distribution as \u03b70 = Pr ( a \u2265 T0 ) and \u03b71 = Pr ( a \u2265 1\u2212 T0 ) . By assumption, we have\nPr ( c \u2265 T0|passed ) \u2265 Pr ( a \u2265 T0|passed ) + Pr ( a \u2264 1\u2212 T0|passed ) ,\nin which a denotes the accuracy of a worker. To calculate Pr ( a \u2265 T0|passed )\n, we have\nPr ( a \u2265 T0|passed ) = Pr\n( a \u2265 T0 ) Pr ( passed|a \u2265 T0 )\nPr ( passed ) .\nEasy to see that Pr ( a \u2265 T0 ) = \u03b70, Pr ( passed|a \u2265 T0 ) \u2265 T0, and\nPr ( passed ) = E [ passed|a ] = E [ a ]\n= \u00b50,\nin which \u00b50 is the mean of the original worker ability distribution. So we have Pr ( a \u2265 T0|passed )\n\u2265 T0\u03b70 \u00b50 , and by similar argument we also have\nPr ( a \u2264 1\u2212 T0|passed ) \u2264 (1\u2212T0)\u03b71 \u00b50 . Then\n\u03b7 = Pr ( c \u2265 T0|passed ) \u2265 Pr ( a \u2265 T0|passed ) \u2265 T0\u03b70 \u00b50 .\nThe remaining task is to bound mean ability of workers that have confidence c \u2265 T0. We have\nE [ a|c \u2265 T0, passed ] \u2265 T0 Pr ( a \u2265 T0|c \u2265 T0, passed )\nand\nPr ( a \u2265 T0|c \u2265 T0, passed ) = Pr\n( a \u2265 T0|passed ) Pr ( c \u2265 T0|a \u2265 T0, passed )\nPr ( c \u2265 T0|passed )\n= Pr\n( a \u2265 T0|passed )\nPr ( a \u2265 T0|passed ) + Pr ( a \u2264 1\u2212 T0|passed )\n\u2265 T0\u03b70 T0\u03b70 + (1\u2212 T0)\u03b71 \u2265 T0,\nwhere the last inequality is from the assumption \u03b70 \u2265 \u03b71. So E [ a|c \u2265 T0, passed ]\n\u2265 T 20 holds. The remaining part of the proof is similar to lemma 5.\nThe main order term of cost needed under an unsure mechanism is 1 (2T0\u22121)2\u03b7 .\nFollowing the similar process of proving theorem 1, We can show the condition when an unsure mechanism can be \u03b1-effective.\nTheorem 2. For crowd ability distribution with mean \u00b5 and variance \u03c32, under the assumption stated in Equation (1) and ci \u2265 max{\u03b8i, 1\u2212\u03b8i}, employ the unsure mechanism and the worker testing mechanism with k = 1. Let T0 > \u221a 2/2 be the confidence threshold. Assume that there exists 2\u00b5 \u2212 1 < M < 1 such that T \u2265 1\u2212 \u00b5+M/2, let s = \u03c32 + 3 4 \u2212 \u221a (\u03c32 + 3 4 )2 \u2212 4\u03c32, if\nM4\n4 \u221a 3[(1\u2212 \u00b5+M/2)\u2212 1]4 1\u2212 s2 (\u03c32 \u2212 1\n4 s2)s4\n\u2264 1 (2\u00b5\u2212 1)\u03b1 , (16)\nthen the unsure mechanism with confidence threshold\nT0 = 1\u2212 \u00b5+ 1\n2\n\u221a s (17)\nis \u03b1-effective.\nProof. Following the proof of theorem 1, let t = 2r, the target is to maximize\n( \u221a 3)(\u03c32 \u2212 1\n4 t2)\n1\u2212 t2 [2( t 2 + 1\u2212 \u00b5)2 \u2212 1)]2.\nThen we have\n[2( t\n2 + 1\u2212 \u00b5)2 \u2212 1]2\n={[ \u221a 2( t\n2 + 1\u2212 \u00b5) + 1][\n\u221a 2( t\n2 + 1\u2212 \u00b5)\u2212 1]}2\n\u2265[ \u221a 2( t\n2 + 1\u2212 \u00b5)\u2212 1]4.\nSo we turn to maximize ( \u221a 3)(\u03c32\u2212 1 4 t2) 1\u2212t2 [ \u221a 2( t 2 + 1 \u2212 \u00b5)\u2212 1]4. We have assumed that there exists 2\u00b5\u2212 1 < M < 1 such that T \u2265 1\u2212 \u00b5+M/2, then we have [ \u221a 2(1\u2212\u00b5+M/2)\u22121]\nM t \u2264\n\u221a 2(1\u2212 \u00b5+ t\n2 )\u2212 1. We turn to maximize\n\u221a 3[ \u221a 2(1\u2212 \u00b5+M/2)\u2212 1]4\nM4 (\u03c32 \u2212 1 4 t2) 1\u2212 t2 t 4.\nLet s = t2, then we consider\nmax 4(2\u00b5\u22121)2<s<4\u03c32\nf(s) = 4\u03c32s2 \u2212 s3\n1\u2212 s .\nWe then have\nf \u2032(s) = (8\u03c32s\u2212 3s2)(1\u2212 s) + (4\u03c32s2 \u2212 s3) (1\u2212 s)2 = s(2s2 \u2212 (4\u03c32 + 3)s+ 8\u03c32) (1\u2212 s)2 .\nThe maximum is attained when s = \u03c32 + 3 4 \u2212\n\u221a\n(\u03c32 + 3 4 )2 \u2212 4\u03c32. \u03c32 + 3 4 \u2212\n\u221a\n(\u03c32 + 3 4 )2 \u2212 4\u03c32 < 4\u03c32 \u21d0\u21d2 \u03c32 + 3 4 \u2212 4\u03c32 <\n\u221a\n(\u03c32 + 3 4 )2 \u2212 4\u03c32 \u21d0\u21d2\n\u03c32 < 1/4, which is held since \u03c32 < 1/4. And 4(2\u00b5 \u2212 1)2 \u2264 \u03c32 + 3 4 \u2212 \u221a\n(\u03c32 + 3 4 )2 \u2212 4\u03c32 \u21d0\u21d2 2(\u03c32 + 3 4 ) \u2264 \u03c32 + 4(2\u00b5 \u2212 1)2, which is held since\n2(2\u00b5\u2212 1)2 \u2264 \u03c32 is assumed. Put it altogether,\nT = 1\u2212 \u00b5+ 1 2\n\u221a s\nand\nm = M4\n4 \u221a 3[(1\u2212 \u00b5+M/2)\u2212 1]4 (1\u2212 s2 (\u03c32 \u2212 1\n4 s2)s4\n.\nIt can be seen that the confidence threshold increases as variance becomes larger, which also matches with the intuition that as the proportion of good workers gets larger, the demand on labeling quality can be safely raised."}, {"heading": "6. Discussion on Payment Strategy", "text": "The above analysis assumes that returning labels and choosing unsure option are equally paid. In many crowdsourcing applications, this payment strategy may have the potential danger for causing workers to always choose the unsure option without returning any labels, which violates the assumption that the workers are honest. For avoiding this problem, it is helpful to design alternative incentive compatible payment method (Shah and Zhou, 2015). As an example, the following payment method can be employed: We assume that choosing unsure option is paid for \u03b3, \u03b3 \u2208 [0, 1). Among returned labels, the ones that accord with the aggregated label are paid for 1, otherwise are paid for \u2212\u00b5/(1\u2212\u00b5) \u2264 \u03b2 < \u03b3. This payment method incentivizes the workers to behave honestly, under the assumption that the workers aim to choose more paid option when their confidence is high, meanwhile avoiding the risk caused by random guessing. It is not hard to generalize the analysis\nto this method since there is only constant scaling of cost on different feedback. One major difference in the analysis is that we need to identify the proportion of returned labels which accord with the aggregated label. This problem is also not hard to solve. Since the aggregated label is correct with high probability, it is also easy to estimate this proportion as the proportion of workers that return correct label is just the mean of the crowd ability. Overall, it is interesting to combine the design of optimal incentive compatible payment method with the design of the unsure mechanism, which is left as future work."}, {"heading": "7. Online Algorithm with Unsure Option", "text": "For practice of unsure setting, a major issue is to determine the confidence threshold T . According to previous analysis, setting T can be transfered to the problem of estimating some simple statistics of the crowd ability distribution, such as mean and variance. If a set of golden standard examples with known labels are available, we can do the estimation before actually releasing the crowdsourcing tasks. However, collecting golden standard examples is an expensive task. If no sufficient examples are available at first, it is hard to do statistical estimations with satisfying accuracy. For solving this problem, we propose an online algorithm based on the bandit setting. We assume that golden standard examples are used only for worker testing mechanism, as described in Section 5.\nThe task is to properly choose confidence threshold T , which can be treated as bandit arms. We can model the crowdsourcing process as following bandit game: when a new task comes, a random worker is drawn from the crowd, and a confidence threshold T is provided. T is updated online by some bandit algorithm. We consider only discrete candidate set of tj , j \u2208 {1, 2, . . . , K}, which segments the interval [0.5, 1] into finite number of parts. Motivated by previous analysis, in special Lemma 5, we define the reward as\nri = (2Ti \u2212 1)2I(ci \u2265 Ti), (18)\nin which i denotes the ith round, Ti is the chosen confidence threshold, and I(ci \u2265 T ) is the indicator function of the event that the worker does not choose the unsure option. Under this definition, for each arm tk, let Nk denote the number of times the arm is chosen. The average reward r\u0302k = 1 Nk \u2211Nk n=1(2tk \u2212 1)2I(ci \u2265 tk) is the empirical estimation of (2tk \u2212 1)2 Pr ( ci \u2265\ntk )\n, i.e., the inverse of main order term of number of workers for accurate estimation for the case \u03b3 = 1, which should be maximized. ri are i.i.d. random variables bounded in [0, 1]. The above problem can be solved by various kinds of bandit algorithms. In this paper, we propose the online algorithm with unsure option based on the UCB-1 algorithm (Auer et al., 2002), which is illustrated in algorithm 1. Note that we do not employ Lemma 7 for designing the reward, since in Lemma 7, T0 > \u221a 2/2, for small\nT0 \u2264 \u221a 2/2 the bound is invalid, and is not capable to be used as reward.\nAlgorithm 1 OLU (OnLine algorithm with Unsure option)\nInput: crowd A, number of rounds N , confidence thresholds tk, k \u2208 {1, 2, . . . , K}. Random initialize T1 \u2208 {t1, t2, . . . , tK}; Initialize Nj = 0, j \u2208 {1, 2, . . . , K}; for i = 1 to N do Draw one worker and provide unsure option with Ti; ri = (2Ti \u2212 1)2I(ci \u2265 Ti); for k = 1 to K do if tk == Ti then Nk = Nk + 1; r\u0302k =\n1 Nk\n( (Nk \u2212 1)r\u0302k + ri )\n; end if\nend for n = argmaxk\u2208{1,2,...,K}(r\u0302k + \u221a 2 ln i Nk );\nTi+1 = tn; end for"}, {"heading": "8. Experiments", "text": "We use synthetic data to test the theoretical results and the online bandit algorithm. In the experiments, a set of binary labeling tasks are generated, and the ground-truth labels are uniformly sampled from {\u22121, 1}. The ability of workers are sampled from Beta distributions, with choices of parameters {\u03b1, \u03b2} to be {0.55, 0.5}, {1.1, 1} and {2.2, 2}. The corresponding mean is 0.52 and variances are 0.1217, 0.0805 and 0.0480. The target is to simulate the polarised, uniform and uni-modal cases of crowd ability distributions with mean close to 1/2. Once the ability \u03b8i of one worker i is sampled, the\nreturned label is sampled from a Bernoulli random draw with parameter \u03b8i. The unsure mechanism is adopted as described in Section 5, with k = 1, that is to use one labeled instance for test. To simulate the self-confidence of workers, in the experiments, the unsure option is used when the sampled ability is above 1 \u2212 T or below T . For examining theory, the mean and variance of crowd ability distribution are assumed to be known, and the confidence threshold is set according to Equation (17). To implement the online algorithm, we employ the candidate threshold sets as [0.55, 0.60, . . . , 1]. For each task, we collect the same number of returned labels for majority voting aggregation. The choices of parameters and results are illustrated in Figure 1.\nFrom the result, in all kinds of crowd ability distributions, employing unsure mechanism significantly outperforms simple aggregation. As the variance gets larger, the number of workers needed for high accuracy aggregation is significantly reduced. It is also interesting to see that when the number\nof tasks gets larger, the performance gap between setting the threshold with Equation (17) and the online algorithm gets smaller. This indicates that the online algorithm is capable to be employed when the number of tasks to be done is large."}, {"heading": "9. Conclusions", "text": "In this work, we propose the analysis on conditions employing the unsure crowdsourcing mechanism can lead to significant reduction on the number of workers needed for high accuracy label aggregation. We show that simple statistics of the distribution, i.e., mean and variance, are enough to examine the effectiveness of an unsure mechanism. Motivated by theoretical analysis, we also propose an online algorithm for setting the confidence threshold. The future work is to consider more complete modeling of tasks and crowds, then more sophisticated crowdsourcing scenarios can be dealt with. We also hope our work to be a motivation for further studies on how crowd-sourced learning can be helped by utilizing subjective uncertainty of workers."}], "references": [{"title": "Large-scale markov decision problems with kl control cost and its application to crowdsourcing", "author": ["Y. Abbasi-Yadkori", "P.L. Bartlett", "C. Xi", "A. Malek"], "venue": "Proceedings of the 32th International Conference on Machine Learning", "citeRegEx": "Abbasi.Yadkori et al\\.,? \\Q2015\\E", "shortCiteRegEx": "Abbasi.Yadkori et al\\.", "year": 2015}, {"title": "Adaptive crowdsourcing algorithms for the bandit survey problem", "author": ["I. Abraham", "O. Alonso", "V. Kandylas", "A. Slivkins"], "venue": "Proceedings of the 26th Conference on Learning Theory", "citeRegEx": "Abraham et al\\.,? \\Q2013\\E", "shortCiteRegEx": "Abraham et al\\.", "year": 2013}, {"title": "Finite-time analysis of the multiarmed bandit problem", "author": ["P. Auer", "N. Cesa-Bianchi", "P. Fischer"], "venue": "Machine Learning", "citeRegEx": "Auer et al\\.,? \\Q2002\\E", "shortCiteRegEx": "Auer et al\\.", "year": 2002}, {"title": "Concentration inequalities: A nonasymptotic theory of independence", "author": ["S. Boucheron", "G. Lugosi", "P. Massart"], "venue": null, "citeRegEx": "Boucheron et al\\.,? \\Q2013\\E", "shortCiteRegEx": "Boucheron et al\\.", "year": 2013}, {"title": "Optimistic knowledge gradient policy for optimal budget allocation in crowdsourcing", "author": ["X. Chen", "Q. Lin", "D. Zhou"], "venue": "Proceedings of the 30th International Conference on Machine Learning", "citeRegEx": "Chen et al\\.,? \\Q2013\\E", "shortCiteRegEx": "Chen et al\\.", "year": 2013}, {"title": "Maximum likelihood estimation of observer", "author": ["A.P. Dawid", "A.M. Skene"], "venue": "ence on World Wide Web", "citeRegEx": "Dawid and Skene,? \\Q1979\\E", "shortCiteRegEx": "Dawid and Skene", "year": 1979}, {"title": "Vox Populi: collecting high-quality labels", "author": ["O. 233\u2013240. Dekel", "O. Shamir"], "venue": null, "citeRegEx": "Dekel and Shamir,? \\Q2009\\E", "shortCiteRegEx": "Dekel and Shamir", "year": 2009}, {"title": "Adaptive task assignment", "author": ["Theory. Ho", "C.-J", "S. Jabbari", "J.W. Vaughan"], "venue": null, "citeRegEx": "Ho et al\\.,? \\Q2013\\E", "shortCiteRegEx": "Ho et al\\.", "year": 2013}, {"title": "Iterative learning for reliable", "author": ["S. Oh", "D. Shah"], "venue": null, "citeRegEx": "Karger et al\\.,? \\Q2011\\E", "shortCiteRegEx": "Karger et al\\.", "year": 2011}, {"title": "Error rate bounds and iterative weighted majority voting", "author": ["H. pp. 1953\u20131961. Li", "B. Yu"], "venue": null, "citeRegEx": "24", "shortCiteRegEx": "24", "year": 2014}, {"title": "Learning from crowds", "author": ["L. Moy"], "venue": "Journal of Machine Learning", "citeRegEx": "L. and Moy,? \\Q2010\\E", "shortCiteRegEx": "L. and Moy", "year": 2010}, {"title": "Understanding machine learning", "author": ["S. Shalev-Shwartz", "S. Ben-David"], "venue": "cessing Systems", "citeRegEx": "Shalev.Shwartz and Ben.David,? \\Q2014\\E", "shortCiteRegEx": "Shalev.Shwartz and Ben.David", "year": 2014}, {"title": "Efficient budget allocation with accuracy guarantees for crowdsourcing classification tasks", "author": ["L. Tran-Thanh", "M. Venanzi", "A. Rogers", "N.R. Jennings"], "venue": "Proceedings of the 2013 International Conference on Autonomous Agents and Multi-agent Systems", "citeRegEx": "Tran.Thanh et al\\.,? \\Q2013\\E", "shortCiteRegEx": "Tran.Thanh et al\\.", "year": 2013}, {"title": "Learning from weak teachers", "author": ["R. Urner", "S. Ben-David", "O. Shamir"], "venue": "Proceedings of 15th International Conference on Artificial Intelligence and Statistics", "citeRegEx": "Urner et al\\.,? \\Q2012\\E", "shortCiteRegEx": "Urner et al\\.", "year": 2012}, {"title": "Cost-saving effect of crowdsourcing learning", "author": ["L. Wang", "Zhou", "Z.-H"], "venue": "Proceedings of the 25th International Joint Conference on Artificial Intelligence", "citeRegEx": "Wang et al\\.,? \\Q2016\\E", "shortCiteRegEx": "Wang et al\\.", "year": 2016}, {"title": "Crowdsourcing label quality: a theoretical analysis", "author": ["W. Wang", "Zhou", "Z.-H"], "venue": "Science China Information Sciences", "citeRegEx": "Wang et al\\.,? \\Q2015\\E", "shortCiteRegEx": "Wang et al\\.", "year": 2015}, {"title": "Spectral methods meet EM: a provably optimal algorithm for crowdsourcing", "author": ["Y. Zhang", "X. Chen", "D. Zhou", "M.I. Jordan"], "venue": "Advances in Neural Information Processing Systems", "citeRegEx": "Zhang et al\\.,? \\Q2014\\E", "shortCiteRegEx": "Zhang et al\\.", "year": 2014}, {"title": "Active learning from crowds with unsure option", "author": ["J. Zhong", "K. Tang", "Zhou", "Z.-H"], "venue": "Proceedings of the 24th International Joint Conference on Artificial Intelligence", "citeRegEx": "Zhong et al\\.,? \\Q2015\\E", "shortCiteRegEx": "Zhong et al\\.", "year": 2015}, {"title": "Learning from the wisdom of crowds by minimax entropy", "author": ["D. Zhou", "S. Basu", "Y. Mao", "J.C. Platt"], "venue": "Advances in Neural Information Processing Systems", "citeRegEx": "Zhou et al\\.,? \\Q2012\\E", "shortCiteRegEx": "Zhou et al\\.", "year": 2012}, {"title": "Regularized minimax conditional entropy for crowdsourcing", "author": ["D. Zhou", "Q. Liu", "J.C. Platt", "C. Meek", "N.B. Shah"], "venue": "arXiv preprint arXiv:1503.07240", "citeRegEx": "Zhou et al\\.,? \\Q2015\\E", "shortCiteRegEx": "Zhou et al\\.", "year": 2015}, {"title": "Optimal pac multiple arm identification with applications to crowdsourcing", "author": ["Y. Zhou", "X. Chen", "J. Li"], "venue": "Proceedings of the 31st International Conference on Machine Learning", "citeRegEx": "Zhou et al\\.,? \\Q2014\\E", "shortCiteRegEx": "Zhou et al\\.", "year": 2014}], "referenceMentions": [{"referenceID": 16, "context": "To balance between the both sides, one way is to design better label aggregation methods, without controlling over the data collection process (Raykar et al., 2010; Dalvi et al., 2013; Zhang et al., 2014).", "startOffset": 143, "endOffset": 204}, {"referenceID": 8, "context": "Another more active way is to design more effective task assignment mechanisms, aiming at saving budget meanwhile maintaining the quality of aggregation (Karger et al., 2011; Ho et al., 2013).", "startOffset": 153, "endOffset": 191}, {"referenceID": 7, "context": "Another more active way is to design more effective task assignment mechanisms, aiming at saving budget meanwhile maintaining the quality of aggregation (Karger et al., 2011; Ho et al., 2013).", "startOffset": 153, "endOffset": 191}, {"referenceID": 7, "context": ", 2011; Ho et al., 2013). However, all these methods do not consider to utilize the subjective behavior of workers. Though seldom studied previously, it is interesting to consider an alternative kind of mechanisms which utilize the subjective uncertainty of the crowd, by allowing workers to choose unsure option instead of actually labeling the data. Since the self-confidence of workers often has close relationship with their potential ability, the quality of returned labels is expected to be guaranteed. In Zhong et al. (2015), the setting of providing unsure option is studied under the active learning with crowd scenario, which empirically justifies the effect of label quality improvement.", "startOffset": 8, "endOffset": 532}, {"referenceID": 13, "context": "This can be done by learning good classifiers using noisy labels directly (Dekel and Shamir, 2009a,b; Urner et al., 2012).", "startOffset": 74, "endOffset": 121}, {"referenceID": 18, "context": "Meanwhile, a majority of works focus on the accurate estimation of underlying true labels (Raykar et al., 2010; Zhou et al., 2012; Dalvi et al., 2013; Li and Yu, 2014; Zhang et al., 2014; Zhou et al., 2015).", "startOffset": 90, "endOffset": 206}, {"referenceID": 16, "context": "Meanwhile, a majority of works focus on the accurate estimation of underlying true labels (Raykar et al., 2010; Zhou et al., 2012; Dalvi et al., 2013; Li and Yu, 2014; Zhang et al., 2014; Zhou et al., 2015).", "startOffset": 90, "endOffset": 206}, {"referenceID": 19, "context": "Meanwhile, a majority of works focus on the accurate estimation of underlying true labels (Raykar et al., 2010; Zhou et al., 2012; Dalvi et al., 2013; Li and Yu, 2014; Zhang et al., 2014; Zhou et al., 2015).", "startOffset": 90, "endOffset": 206}, {"referenceID": 8, "context": "To achieve this target, both non-adaptive task assignment mechanisms (Karger et al., 2011; Tran-Thanh et al., 2013), which assign tasks off-line before worker comes, and the adaptive mechanisms which assign tasks in online fashion (Ho et al.", "startOffset": 69, "endOffset": 115}, {"referenceID": 12, "context": "To achieve this target, both non-adaptive task assignment mechanisms (Karger et al., 2011; Tran-Thanh et al., 2013), which assign tasks off-line before worker comes, and the adaptive mechanisms which assign tasks in online fashion (Ho et al.", "startOffset": 69, "endOffset": 115}, {"referenceID": 7, "context": ", 2013), which assign tasks off-line before worker comes, and the adaptive mechanisms which assign tasks in online fashion (Ho et al., 2013; Chen et al., 2013; Abbasi-Yadkori et al., 2015), have been studied thoroughly with strong theoretical guarantees.", "startOffset": 123, "endOffset": 188}, {"referenceID": 4, "context": ", 2013), which assign tasks off-line before worker comes, and the adaptive mechanisms which assign tasks in online fashion (Ho et al., 2013; Chen et al., 2013; Abbasi-Yadkori et al., 2015), have been studied thoroughly with strong theoretical guarantees.", "startOffset": 123, "endOffset": 188}, {"referenceID": 0, "context": ", 2013), which assign tasks off-line before worker comes, and the adaptive mechanisms which assign tasks in online fashion (Ho et al., 2013; Chen et al., 2013; Abbasi-Yadkori et al., 2015), have been studied thoroughly with strong theoretical guarantees.", "startOffset": 123, "endOffset": 188}, {"referenceID": 3, "context": "This can be done by learning good classifiers using noisy labels directly (Dekel and Shamir, 2009a,b; Urner et al., 2012). Meanwhile, a majority of works focus on the accurate estimation of underlying true labels (Raykar et al., 2010; Zhou et al., 2012; Dalvi et al., 2013; Li and Yu, 2014; Zhang et al., 2014; Zhou et al., 2015). The target of these works is improving learning performance, without direct consideration on the cost of label collection. Wang and Zhou (2016) further points out that it is important to consider the cost-saving effect in crowdsourcing.", "startOffset": 75, "endOffset": 475}, {"referenceID": 3, "context": "This can be done by learning good classifiers using noisy labels directly (Dekel and Shamir, 2009a,b; Urner et al., 2012). Meanwhile, a majority of works focus on the accurate estimation of underlying true labels (Raykar et al., 2010; Zhou et al., 2012; Dalvi et al., 2013; Li and Yu, 2014; Zhang et al., 2014; Zhou et al., 2015). The target of these works is improving learning performance, without direct consideration on the cost of label collection. Wang and Zhou (2016) further points out that it is important to consider the cost-saving effect in crowdsourcing. Another mainstream of researches is on task assignment and budget allocation, which try to balance between aggregation accuracy and data collection cost. Wang and Zhou (2015) theoretically shows that in proper conditions, it is indeed possible to achieve desired accuracy with reasonable cost in crowdsourcing.", "startOffset": 75, "endOffset": 743}, {"referenceID": 0, "context": ", 2013; Abbasi-Yadkori et al., 2015), have been studied thoroughly with strong theoretical guarantees. The trade-off between aggregation accuracy and data collection cost is also the major problem discussed in this paper. The difference is that task assignment and budget allocation mechanisms focus on improving the behavior of the task requester, while in designing unsure mechanism, the target is to improve the behavior of workers, by utilizing their own uncertainty about the tasks. There have been several works for employing bandit setting in crowdsourcing. In Abraham et al. (2013), a special crowdsourcing problem called the bandit survey problem is considered.", "startOffset": 8, "endOffset": 590}, {"referenceID": 0, "context": ", 2013; Abbasi-Yadkori et al., 2015), have been studied thoroughly with strong theoretical guarantees. The trade-off between aggregation accuracy and data collection cost is also the major problem discussed in this paper. The difference is that task assignment and budget allocation mechanisms focus on improving the behavior of the task requester, while in designing unsure mechanism, the target is to improve the behavior of workers, by utilizing their own uncertainty about the tasks. There have been several works for employing bandit setting in crowdsourcing. In Abraham et al. (2013), a special crowdsourcing problem called the bandit survey problem is considered. In Jain et al. (2014), the bandit setting is employed to deal with the task assignment problem.", "startOffset": 8, "endOffset": 693}, {"referenceID": 0, "context": ", 2013; Abbasi-Yadkori et al., 2015), have been studied thoroughly with strong theoretical guarantees. The trade-off between aggregation accuracy and data collection cost is also the major problem discussed in this paper. The difference is that task assignment and budget allocation mechanisms focus on improving the behavior of the task requester, while in designing unsure mechanism, the target is to improve the behavior of workers, by utilizing their own uncertainty about the tasks. There have been several works for employing bandit setting in crowdsourcing. In Abraham et al. (2013), a special crowdsourcing problem called the bandit survey problem is considered. In Jain et al. (2014), the bandit setting is employed to deal with the task assignment problem. In Zhou et al. (2014), the bandit arm identification problem is employed for worker selection.", "startOffset": 8, "endOffset": 789}, {"referenceID": 0, "context": ", 2013; Abbasi-Yadkori et al., 2015), have been studied thoroughly with strong theoretical guarantees. The trade-off between aggregation accuracy and data collection cost is also the major problem discussed in this paper. The difference is that task assignment and budget allocation mechanisms focus on improving the behavior of the task requester, while in designing unsure mechanism, the target is to improve the behavior of workers, by utilizing their own uncertainty about the tasks. There have been several works for employing bandit setting in crowdsourcing. In Abraham et al. (2013), a special crowdsourcing problem called the bandit survey problem is considered. In Jain et al. (2014), the bandit setting is employed to deal with the task assignment problem. In Zhou et al. (2014), the bandit arm identification problem is employed for worker selection. All these works have different settings to our work. There are not many works studying the possibility to employ unsure setting in crowdsourcing. In Zhong et al. (2015), unsure option is provided un3", "startOffset": 8, "endOffset": 1031}, {"referenceID": 5, "context": "Problem Formulation We consider the tasks of collecting binary labels, and adopt the wellknown Dawid-Skene model (Dawid and Skene, 1979; Zhou et al., 2012; Zhang et al., 2014; Karger et al., 2011; Zhou et al., 2015; Li and Yu, 2014) under the binary classification case.", "startOffset": 113, "endOffset": 232}, {"referenceID": 18, "context": "Problem Formulation We consider the tasks of collecting binary labels, and adopt the wellknown Dawid-Skene model (Dawid and Skene, 1979; Zhou et al., 2012; Zhang et al., 2014; Karger et al., 2011; Zhou et al., 2015; Li and Yu, 2014) under the binary classification case.", "startOffset": 113, "endOffset": 232}, {"referenceID": 16, "context": "Problem Formulation We consider the tasks of collecting binary labels, and adopt the wellknown Dawid-Skene model (Dawid and Skene, 1979; Zhou et al., 2012; Zhang et al., 2014; Karger et al., 2011; Zhou et al., 2015; Li and Yu, 2014) under the binary classification case.", "startOffset": 113, "endOffset": 232}, {"referenceID": 8, "context": "Problem Formulation We consider the tasks of collecting binary labels, and adopt the wellknown Dawid-Skene model (Dawid and Skene, 1979; Zhou et al., 2012; Zhang et al., 2014; Karger et al., 2011; Zhou et al., 2015; Li and Yu, 2014) under the binary classification case.", "startOffset": 113, "endOffset": 232}, {"referenceID": 19, "context": "Problem Formulation We consider the tasks of collecting binary labels, and adopt the wellknown Dawid-Skene model (Dawid and Skene, 1979; Zhou et al., 2012; Zhang et al., 2014; Karger et al., 2011; Zhou et al., 2015; Li and Yu, 2014) under the binary classification case.", "startOffset": 113, "endOffset": 232}, {"referenceID": 14, "context": "Our work focuses on the analysis of cost-saving effect for the crowdsourcing with unsure option setting, while in Zhong et al. (2015) they empirically justify that providing unsure option to the crowd improves labeling quality.", "startOffset": 114, "endOffset": 134}, {"referenceID": 14, "context": "Our work focuses on the analysis of cost-saving effect for the crowdsourcing with unsure option setting, while in Zhong et al. (2015) they empirically justify that providing unsure option to the crowd improves labeling quality. In Shah and Zhou (2015), a double or nothing incentive compatible mechanism is proposed to ensure workers to behave honestly based on their self-confidence.", "startOffset": 114, "endOffset": 252}, {"referenceID": 5, "context": "Problem Formulation We consider the tasks of collecting binary labels, and adopt the wellknown Dawid-Skene model (Dawid and Skene, 1979; Zhou et al., 2012; Zhang et al., 2014; Karger et al., 2011; Zhou et al., 2015; Li and Yu, 2014) under the binary classification case. Under the D-S model, the tasks are assumed to be homogeneous, which means that the potential cost for different tasks are the same. As a result, in rest of the paper, we focus on dealing with the cost for one single task. We adopt the anonymous worker assumption introduced in Karger et al. (2011) for modeling the crowd.", "startOffset": 114, "endOffset": 569}, {"referenceID": 11, "context": "Lemma 1 (Hoeffding\u2019s inequality, Shalev-Shwartz and Ben-David (2014) lemma B.", "startOffset": 33, "endOffset": 69}, {"referenceID": 11, "context": "(2) Lemma 2 (Bernstein\u2019s inequality, Shalev-Shwartz and Ben-David (2014) lemma B.", "startOffset": 37, "endOffset": 73}, {"referenceID": 3, "context": "We use a lemma to bound the variance: Lemma 4 (Boucheron et al. (2013), Corollary 3.", "startOffset": 47, "endOffset": 71}, {"referenceID": 2, "context": "In this paper, we propose the online algorithm with unsure option based on the UCB-1 algorithm (Auer et al., 2002), which is illustrated in algorithm 1.", "startOffset": 95, "endOffset": 114}], "year": 2016, "abstractText": "One of the fundamental problems in crowdsourcing is the trade-off between number of workers needed for high-accuracy aggregation and the budget to pay. For saving budget, it is important to ensure high quality of the crowd-sourced labels, hence the total cost on label collection will be reduced. Since the self-confidence of workers often has close relationship with their abilities, a possible way for quality control is to request workers to work on problems only when they feel confident, by means of providing unsure option to them. On the other hand, allowing workers to choose unsure option also leads to the potential danger of budget waste. In this work, we propose the analysis towards understanding when providing unsure option indeed leads to significant cost reduction, as well as how the confidence threshold is set. We also propose an online mechanism, which is alternative for threshold selection when the estimation of the crowd ability distribution is difficult.", "creator": "LaTeX with hyperref package"}}}