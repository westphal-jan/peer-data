{"id": "1609.01594", "review": {"conference": "arxiv", "VERSION": "v1", "DATE_OF_SUBMISSION": "6-Sep-2016", "title": "An Information Extraction Approach to Prescreen Heart Failure Patients for Clinical Trials", "abstract": "to reduce unfortunately the surprisingly large amount of invasive time spent screening, tightly identifying, and immediately recruiting patients first into clinical trials, generally we need prescreening targeting systems that are able nowadays to automate the data extraction and implement decision - making tasks that are typically relegated immediately to clinical research study coordinators. however, a potentially major internal obstacle argument is the vast large amount and of patient numerical data structure available as unstructured free - form text in electronic health records. emerging here we propose then an information automated extraction - constraint based preparation approach that first naturally automatically converts unstructured read text into a randomly structured printed form. originally the previously structured pharmaceutical data packages are then compared against atop a list of recommended eligibility criteria calculated using alternatively a mandatory rule - analysis based search system to determine which patients qualify individually for enrollment assignment in a renal heart failure clinical acceptance trial. nevertheless we show that essentially we can achieve historically highly accurate screening results, with recall and precision values below of mach 0. 95 99 and 0. / 86, respectively. our system model allowed us to also significantly somewhat reduce the time goals needed obtained for prescreening patients progressively from a casual few weeks to a few minutes. our own open - source information extraction guidance modules still are instantly available for researchers and how could be successfully tested, and uniquely validated in other cardiovascular trials. an approach such as retaining the same one we demonstrate here may decrease costs upon and expedite clinical trials, and significantly could enhance the reproducibility ratios of candidate trials across institutions and populations.", "histories": [["v1", "Tue, 6 Sep 2016 15:05:25 GMT  (370kb)", "http://arxiv.org/abs/1609.01594v1", null]], "reviews": [], "SUBJECTS": "cs.CL cs.CY", "authors": ["abhishek kalyan adupa", "ravi prakash garg", "jessica corona-cox", "sanjiv j shah", "siddhartha r jonnalagadda"], "accepted": false, "id": "1609.01594"}, "pdf": {"name": "1609.01594.pdf", "metadata": {"source": "CRF", "title": "AN INFORMATION EXTRACTION APPROACH TO PRESCREEN HEART FAILURE PATIENTS FOR CLINICAL TRIALS", "authors": ["ABHISHEK KALYAN ADUPA", "RAVI PRAKASH GARG", "JESSICA CORONA-COX", "SANJIV J. SHAH", "SIDDHARTHA JONNALAGADDA"], "emails": ["sid@northwestern.edu"], "sections": [{"heading": null, "text": "1 \u00a0  \u00a0\nAN INFORMATION EXTRACTION APPROACH TO PRESCREEN HEART FAILURE PATIENTS FOR CLINICAL TRIALS\nABHISHEK KALYAN ADUPA1, RAVI PRAKASH GARG1, JESSICA CORONA-COX2, SANJIV J. SHAH2, SIDDHARTHA JONNALAGADDA1\n1Division of Health and Biomedical Informatics, Department of Preventive Medicine, Northwestern University Feinberg School of Medicine, Chicago, IL 60611, USA\nEmail: sid@northwestern.edu\n2Division of Cardiology, Department of Medicine, Northwestern University Feinberg School of Medicine, Chicago, IL 60611, USA\nTo reduce the large amount of time spent screening, identifying, and recruiting patients into clinical trials, we need prescreening systems that are able to automate the data extraction and decision-making tasks that are typically relegated to clinical research study coordinators. However, a major obstacle is the vast amount of patient data available as unstructured free-form text in electronic health records. Here we propose an information extraction-based approach that first automatically converts unstructured text into a structured form. The structured data are then compared against a list of eligibility criteria using a rule-based system to determine which patients qualify for enrollment in a heart failure clinical trial. We show that we can achieve highly accurate results, with recall and precision values of 0.95 and 0.86, respectively. Our system allowed us to significantly reduce the time needed for prescreening patients from a few weeks to a few minutes. Our open-source information extraction modules are available for researchers and could be tested and validated in other cardiovascular trials. An approach such as the one we demonstrate here may decrease costs and expedite clinical trials, and could enhance the reproducibility of trials across institutions and populations."}, {"heading": "1. Introduction", "text": "The creation and acceptance of electronic health records (EHRs) has ignited widespread interest in the use of clinical data for secondary purposes and research [1]. One such application that can greatly benefit from an EHR-based approach is clinical trial screening and recruitment. Clinical trial screening is a process that helps medical practitioners and researchers determine whether a particular patient is suitable for trial based on certain eligibility criteria. The eligibility criteria are generally divided into two parts: inclusion criteria and exclusion criteria. Inclusion criteria are characteristics that the prospective subjects must have if they are to be included in the study, while exclusion criteria are those characteristics that disqualify prospective subjects from inclusion in the study.\nIn general, screening for clinical trial recruitment is done manually. Clinicians and study coordinators go through each of the eligibility criteria, determine data elements relevant to the clinical trial, extract the data elements from structured and unstructured EHR of each patient, and match the data elements with the eligibility criteria to decide whether the patient qualifies for the trial. Not only this process is slow, it is also prone to errors. It typically takes approximately 15 to 20 minutes for a study coordinator to examine each patient\u2019s data. Because of the subjectivity involved in human decision-making, domain knowledge, which patients are considered for initial search and other factors [2], there is always a possibility of type-1 and type-2 errors in the\n2 \u00a0  \u00a0\nprescreening process and biases in the overall recruitment. Furthermore, clinicians and study coordinators typically rely on patients identified in their own specialty clinics or in certain defined patient care settings, thereby missing out on the advantage of screening an entire healthcare system.\nWe hypothesize that an automated process for prescreening would be quicker and serve as an independent judge of inclusion/exclusion criteria free of human bias. If the prescreening algorithm also has a high recall (sensitivity), it would potentially reduce recruitment bias because it would be possible to consider patients from a larger pool. Thus, an algorithm that can prescreen eligible patients efficiently could provide a proficient and robust approach to clinical trial recruitment. Therefore, we sought to develop a high recall (sensitivity) prescreening algorithm for recruiting patients into a multicenter, randomized, double-blind, parallel group, active-controlled study to evaluate the efficacy and safety of LCZ696 compared to valsartan, on morbidity and mortality in heart failure patients with preserved ejection fraction (PARAGON). Our approach involves development of information extraction modules that can be reused not only for other EHRs but also for other trials using similar data elements."}, {"heading": "2. Background", "text": "Heart failure (HF) occurs when the heart muscle is no longer able to meet the demands of the body either due to reduced cardiac output or increased ventricular filling pressures. It is one of the most common reasons for hospital admissions among those aged 65 years and older. In 2010 alone, HF affected 6.6 million Americans at a cost of $34.4 billion [3, 4]. Many clinical trials have been undertaken to find efficient solutions to the condition. However, it has been found that 86% of all clinical trials are delayed in patient recruitment from 1 to 6 months, and 13% are delayed by longer than 6 months [2]. A major cause of delay in HF clinical trials is the inability to efficiently screen for and identify eligible patients. An automated system is therefore needed to accelerate the process of prescreening patients for clinical trials.\nThe surge of the use of EHRs in the United States has created abundant opportunities for clinical and translational research. As Friedman et al noted, the extensive use of clinical data provides great potential to transform our healthcare system into a \u201cSelf-learning Health System\u201d [5, 6]. In addition to its primary purpose of providing improved clinical practice, the use of EHRs offers means for the identification of participants who satisfy predefined criteria. This can be used for a variety of applications, including clinical trial recruitment, outcome prediction, survival analysis, and other retrospective studies [7-10].\nEHRs contain patient data in both structured and unstructured formats. The structured data generally encompass a patient\u2019s demographic data, physical characteristics (e.g., body mass index [BMI], blood pressure), laboratory data, and diagnoses. Structured data are not only the best representation of knowledge but also easier to process. However, there is a vast amount of medical knowledge that is locked in the unstructured format. The unstructured data are typically text clinical narratives present in progress notes, imaging reports (e.g., echocardiographic reports), and discharge summaries, for example. Thus, a module that can automatically and efficiently extract information from unstructured clinical text and convert it into a structured form is needed.\n3 \u00a0  \u00a0\nThe syndromic nature of HF presents unique challenges for the identification of patients from EHR data for research [11]. HF with preserved ejection fraction, in which the global pumping function of the heart is normal, is particularly challenging to identify during prescreening activities. The presence of large amounts of unstructured data in patient medical reports aggravates the challenges. Previous studies have shown that clinicians often prefer free text entry to coded options, in order to fully explain the health conditions of each patients [12- 14]. It has also been noted that unstructured data are essential because of the information they contain [15]; therefore, unstructured data are likely to persist in the future. There is an immediate need for an automated data extraction system to transform unstructured clinical reports into a structured form, which is much easier to process and handle [16-18].\nThere has been considerable research in identifying patient cohorts from EHRs [19]. These approaches can be categorized into three general types: (1) rule-based approaches [20-24], (2) machine learning\u2013based approaches [25-28], and (3) information retrieval\u2013based approaches [29-32]. All these approaches use either pattern matching (regular expressions) or language modeling\u2013based methods [33-36] to extract features for their system to work on. Rule-based systems are stringent and binary (either yes or no) in nature. On the other hand, machine learning\u2013 and information retrieval\u2013based methods provide output as probability or a score. Machine learning techniques, however, require a large amount of training data to give accurate results.\nOur proposed system is different from these approaches in various ways. A majority of the reported systems aim to identify whether a patient shows a certain phenotype. Therefore, the number of criteria required is less than that which are necessary for clinical trial screening. For example, a majority of the systems only use a variation of disease names, medications used, or treatments taken as their eligibility criteria [21, 23]. Ours is a more diverse application. Our goal is to check whether a particular patient qualifies for a certain clinical trial. Clinical trials usually have a large number of eligibility criteria that need to be checked. Therefore, a large amount of information related to the eligibility criteria needs to be extracted.\nOur study goal is similar to that of the plethora of approaches proposed in computer-based clinical trial recruitment systems [37]. However, a majority of these approaches either lack EHRs as data source or are not equipped to handle unstructured data. We, on the other hand, obtain patient data from EHRs and handle unstructured data through information extraction methods, as opposed to the \u201cbag of terms\u201d or \u201cbag of concepts\u201d suggested in other methods\n4 \u00a0  \u00a0\n[38]. The main contributions of our study are to (1) show that automated recruitment systems can only serve as prescreening tools and to (2) develop and validate a clinical trial screening system based on information extracted from EHRs. Here, we demonstrate how our system processes a set of eligibility criteria, extracts information from patient records automatically into a structured format, and finally prescreens the patients who could qualify for the trial by matching the structured patient document with the eligibility criteria.\nSection 3 describes the data and the algorithm used to convert the data into a structured form. We present our results in Section 4, discuss our experience and the challenges faced in Section 5, and then conclude in Section 6."}, {"heading": "3. Methods", "text": ""}, {"heading": "3.1. Patient Records and Eligibility Criteria \u2013 Data Description", "text": "The patient records used in this study come from the EPIC EHR used by Northwestern Memorial Group. The initial cohort of patients we have considered for our experiments was very broad to ensure we were not missing any patients that could be included \u2013 patients that currently have been documented to have HF with the ICD-9-CM Diagnosis Code 428.0 or had an echocardiogram within the past year. We selected 198 of these patients for development and 3002 patients for validation.\nEach patient\u2019s data consists of five types of reports: encounters, problem list, echocardiography reports, lab reports, and current medication list. Encounters contain two types of files: encounter diagnosis name and encounter progress notes. The characteristics of the patient records for both datasets are summarized in Table 1. We have 40 eligibility criteria \u2013 7 for inclusion and 33 for exclusion \u2013 for the PARAGON clinical trial [39]. However, we currently evaluate our approach based on a subset of these criteria (Figure 3).\nPatient \u00a0Before \u00a0\nDemographics, \u00a0Lab \u00a0 Values, \u00a0etc. \u00a0 (Structured \u00a0Data) \u00a0\nPathology \u00a0Reports, \u00a0 Echo \u00a0Report, \u00a0 Encounter \u00a0Notes, \u00a0 Discharge \u00a0 Summaries, \u00a0etc. \u00a0 (Unstructured \u00a0Data) \u00a0\nInformation \u00a0 Extraction \u00a0 Modules \u00a0\nDemographics \u00a0\n \u00a0 \u00a0 \u00a0 \u00a0Patient \u00a0After \u00a0\nLab \u00a0Values \u00a0\nPathology \u00a0Report \u00a0 Information \u00a0\nEcho \u00a0Report \u00a0 Information \u00a0\nEncounter \u00a0Notes \u00a0 Information \u00a0\n(All \u00a0Structured \u00a0 Form) \u00a0\nEligibility \u00a0 Criteria \u00a0 OUTPUT \u00a0\nFigure 2. Overview of our clinical trial recruitment system architecture. \u00a0We have analyzed different HFrelated patient medical reports and derived pattern-based Information extraction modules that provide output of structured data to compare against eligibility criteria for clinical trial recruitment\n5 \u00a0  \u00a0\nTable 1. Characteristics of the development and validation patient datasets. \u00a0\n6 \u00a0  \u00a0"}, {"heading": "3.2 Algorithm", "text": "The information from the patient data is extracted as part of separate modules. These modules are designed to extract the data elements relevant to PARAGON but are reusable individually for other clinical trials. After extraction, a rule-based system matches the eligibility criteria and discards patients who do not satisfy any of the inclusion criteria or satisfies one of the exclusion criteria. Figure 3 describes the system\u2019s architecture in finer detail. We broadly categorize the modules as: (1) structured data normalizer, (2) unstructured data extractor, and (3) unstructured data classifier.\nStructured data normalizer is used for the extraction of data elements whose values are already present in the structured form. This module is further divided into two submodules. In submodule 1, we extract the values for age, BMI, hemoglobin, GFR and blood pressure from structured fields. In submodule 2, we extract the number of medications a patient belong to different drug classes. The reports are in structured form with mapping of the medication to the patient. This submodule requires external information resources, which we provide as databases to our system. Table 2 and Table 3 list the drug classes that we incorporated for the PARAGON clinical trial.\nUnstructured data extractor is used for the extraction of values of data elements present in unstructured text. This module also accepts input and provides output just as the previous module but uses a complex set of regular expressions to extract the exact value. For example, we currently extract the left ventricular ejection fraction (LVEF) value for our clinical trial. For this, we first use a set of regular expressions to extract sentences where the LVEF value may be present and then another set of regular expressions to extract the definite values as shown in Table 4. Regular expressions 1 through 4 extract the sentences that can contain LVEF values. Then, the sentences are parsed through regular expressions 5 and 6. Regular expression 5 extracts the values present in\nrange format: for example, \u201c40% to/- 45%.\u201d Regular expression 6 extracts the freely available values: for example, \u201c40%.\u201d\nUnstructured data classifier is used for classifying whether certain data elements are present or absent in relation to the context of the patient. Currently in this module, we extract all the instances of a given data element (diagnosis, medication, treatment, or tests) and its synonyms in the input report(s). For this, the module first checks for synonyms of the input term using UMLS Metathesaurus [40], builds automatically a set of regular expressions, and then applies them to the input report text to extract all the instances. For example, to extract HF-related terms the module compiles a list of synonyms: \u201cheart failure,\u201d \u201cHF,\u201d \u201cdiastolic dysfunction,\u201d and \u201ccardiomyopathy.\u201d Next, a set of regular expressions are automatically generated (Table 5) and used to extract all the instances of HF-related terms. For PARAGON, the other data elements processed in this category are \u201cangioedema\u201d, \u201cpancreatitis\u201d, \u201cvalvular heart disease,\u201d etc. We adapt existing rule-based systems to make sure the data elements are not in their negated form using a rule-based negation detection algorithm, the data elements refer to the current status (as opposed to historical condition or a hypothesis for conducting a test) and the data elements correspond to the patient (as opposed to a family member or relative) [41, 42].\n8 \u00a0  \u00a0\n[^\\w]+HF[^\\w]+ \u00a0"}, {"heading": "4. Evaluation and Results", "text": "We first evaluated our methods iteratively using the development set of 198 patient reports. A study coordinator read each patient record, extracted data elements of relevance to PARAGON, and matched against the eligibility criteria. For the 198 patient reports, our experienced research coordinator took two weeks (80 hours) to generate the gold standard data. Finally, we had 40 of the 198 patients (20%) prescreened for further analysis according to the eligibility criteria. After consulting a cardiologist, the number of patients finally found eligible was 12. The sheer size of the data that the clinical investigator or research coordinator has to read through is time consuming as well as tedious (Table 1).\nThe number of patients finally qualifying for any clinical trial is always small. This is mostly due to the large number of stringent eligibility criteria. Therefore, it becomes important for an automated system to give more importance to retrieving nearly all the qualifying patients; in other words, the recall of the system should be close to 100%. We tuned our system in order to achieve a high recall (i.e., high sensitivity) so as not to have too many false negatives (which would result in missing potentially eligible patients). On the experiments run on the development dataset, we achieved close to 95% recall with a precision of 86% (F-score of 90%). Table 6 presents further details.\nOn the validation dataset, we prescreened 113 (3.7%) patients for the PARAGON clinical trial. Our clinical trial study coordinator went through these records and found that 21 of the patients fully qualify for the clinical trial. Twenty-five of the patients require consultation with a cardiologist. However, 67 of the patients do not qualify for the trial. In most cases, this is not because of errors in the prescreening system but due to certain other criteria that have either been not included in the algorithm (for example, certain specific allergies to medication, pregnancy, patient not present in the country, etc.) or are beyond the scope of any system to check due to lack of data (for example, type of cancer or cancer is malignant or benign when the details are not present). We detail some these issues in the Discussion section.\n9 \u00a0  \u00a0\nTable 7 lists the number of patients we discard based on each criteria for both the development and validation dataset. It can be seen that each information extraction module played a major role in screening out large proportions of patients without human involvement. For example, module 2, which extracts LVEF values, discarded 90 patients from the 198-patient development dataset and 672 patients from the 3002-patient validation dataset. This would not have been captured by any methods that aim to prioritize patients using information retrieval approaches without first extracting the values of the relevant data elements from unstructured reports.\nThe time taken by our system to successfully parse and extract the required information from different data reports is just 2 minutes (for the whole 198-patient dataset). For 3002 patients, we are able to do so in approximately 20 minutes. Our clinical trial coordinator took almost two weeks to go through each of 198 patients\u2019 reports. Thus, the time required for her to go through 3002 patients would have been several months. Instead, she only had to examine the 113 prescreened patients from our system, which only took one week. This demonstrates the usefulness of our system in practical application. However, from these results and observations, we also understand that the system can only be used for prescreening, and further validation by the clinical trial study coordinator or clinical investigator is still required."}, {"heading": "5. Discussion", "text": "We achieved high recall with reasonable precision on our development dataset and were able to replicate the performance on a larger dataset. As with any automated system, there are certain limitations to our proposed architecture, which can be broadly categorized into (1) data processing and (2) data-handling issues. We briefly describe some of these issues. The precision of the system suffers from the complexity of text data. In some cases current unstructured data extractor module is unable to extract terms correctly. For example, the module fails to identify certain HF or ICD related terms. This is due to large number of synonyms and spelling mistakes for the relevant data elements.\nAs mentioned earlier, there are some cases where a patient has certain allergies or may show a certain adverse reaction to a medication, both of which are difficult to extract from unstructured\n10 \u00a0  \u00a0\nnotes because they are not always reported in a standard format within the EHR. There are also cases where the patient has moved out of the hospital\u2019s geographic area and therefore cannot provide consent for the clinical trial. These are details that are too patient-specific for automated extraction and can only be checked manually.\nIn some cases, the LVEF value (which is an important factor for inclusion in HF clinical trials) is present in the form of a range or qualitative description. This created a problem while checking for eligibility according to the criterion given. For example, in our clinical trial, we have set the lower limit of LVEF at 45% based on the inclusion criteria. This creates a problem when the value is contained within the range extracted (40% to 45% or 30% to 50%, for example). Our initial approach was to take the average value and compare it with the threshold. However, after consultation with the cardiologist, our approach was deemed inappropriate. Therefore, we subsequently modified our algorithm to include these patients but with a warning regarding their LVEF value. This then served as an indication to the study coordinators to recheck the echocardiogram report (and review the echocardiographic images with the clinical investigator) in order to make further decisions about the patient\u2019s eligibility for the clinical trial.\nThere are also some cases where the clinicians are just screening the patient for a particular diagnosis but the patient may not actually have the disease, such as a \u201cmalignancy of organ system\u201d check of exclusion criteria. To handle this, we do not discard those patients if we find the \u201cscreening\u201d term in the sentences extracted for eligibility check. In similar cases, we also see the term \u201ccancer\u201d instead of \u201cmalignancy.\u201d However, we cannot discard all patients with the \u201ccancer\u201d term present since some can have a benign diagnosis and not be malignant, and it is impossible for our system to decide if the cancer is malignant or relatively benign. To mitigate these issues, we currently just display a warning in these cases, as we did for LVEF. The coordinator can then perform further checks and decide the classification. In other exclusion criterion where we have to check the B-type natriuretic peptide and glomerular filtration rate values, we face the issues of non-availability and potential outliers in the data. For such cases too, we currently report them as a warning to coordinators for further checking.\nWe also had to deal with data-handling issues in some cases. For example, in criteria where we have to perform a check for recent hemoglobin values, we found that the value may also be present in reports other than just blood reports. To mitigate this issue, we check for hemoglobin values in all reports and then extract the most recent one. Similarly, there were also cases where \u201cend-date\u201d of medication and \u201cdepartment-name\u201d for encounter reports were missing or misplaced. We handled such cases following discussions with the data warehouse coordinator. To summarize, we can deduce that the patient data records are noisy due to various reasons and a preprocessing module is required to handle these issues."}, {"heading": "6. Conclusions and Future Work", "text": "We have presented here a new method for automated clinical trial recruitment system. We have shown, through our results and discussion, that any automated recruitment system suffices as a prescreening process that significantly reduces the workload in recruiting patients, even if it cannot completely replace manual intervention. Our system works on the hypothesis that the performance can be greatly enhanced by converting unstructured free clinical text into a structured\n11 \u00a0  \u00a0\nform. To validate our hypothesis, we built modules that extract key data elements from the unstructured text on the basis of given eligibility criteria. We evaluated our system on two datasets: one of 198 patients and one of 3002 patients. Our experiments show highly favorable results and affirm our hypothesis. For future research, we aim to evaluate the reproducibility of our system for PARAGON trial at other institutions. We also intend to build further modules to use the framework for other clinical trials."}, {"heading": "Acknowledgments", "text": "This work was made possible by funding from the National Library of Medicine: R00LM011389 and R01LM011416 and Novartis. Dr. Sanjiv Shah is supported by grants from the National Institutes of Health (R01 HL107577 and R01 HL127028). The authors acknowledge Prasanth Nannapaneni for his valuable ideas on extracting information from EHR.\nDisclosures: Dr. Shah reports receiving consulting fees from Novartis, Bayer, AstraZeneca, and Alnylam.\nReferences 1. \u00a0 Jensen, \u00a0P.B., \u00a0L.J. \u00a0Jensen, \u00a0and \u00a0S. \u00a0Brunak, \u00a0Mining \u00a0electronic \u00a0health \u00a0records: \u00a0towards \u00a0better \u00a0research \u00a0 applications \u00a0and \u00a0clinical \u00a0care. \u00a0Nat \u00a0Rev \u00a0Genet, \u00a02012. \u00a013(6): \u00a0p. \u00a0395-\u2010405. \u00a0 2. \u00a0 Sullivan, \u00a0 J. \u00a0 Subject \u00a0 Recruitment \u00a0 and \u00a0 Retention: \u00a0 Barrier \u00a0 to \u00a0 Success. \u00a0 2004 \u00a0  \u00a0 [cited \u00a0 2015 \u00a0 27 \u00a0 July]; \u00a0\nAvailable \u00a0 from: \u00a0 http://www.appliedclinicaltrialsonline.com/subject-\u2010recruitment-\u2010and-\u2010retention-\u2010 barriers-\u2010success. \u00a0\n3. \u00a0 Heidenreich, \u00a0P.A., \u00a0et \u00a0al., \u00a0Forecasting \u00a0 the \u00a0 future \u00a0of \u00a0cardiovascular \u00a0disease \u00a0 in \u00a0 the \u00a0United \u00a0States: \u00a0a \u00a0 policy \u00a0statement \u00a0from \u00a0the \u00a0American \u00a0Heart \u00a0Association. \u00a0Circulation, \u00a02011. \u00a0123(8): \u00a0p. \u00a0933-\u201044. \u00a0 4. \u00a0 Mozaffarian, \u00a0 D., \u00a0 et \u00a0 al., \u00a0 Heart \u00a0 disease \u00a0 and \u00a0 stroke \u00a0 statistics-\u2010-\u20102015 \u00a0 update: \u00a0 a \u00a0 report \u00a0 from \u00a0 the \u00a0 American \u00a0Heart \u00a0Association. \u00a0Circulation, \u00a02015. \u00a0131(4): \u00a0p. \u00a0e29-\u2010322. \u00a0 5. \u00a0 Friedman, \u00a0C.P., \u00a0A.K. \u00a0Wong, \u00a0and \u00a0D. \u00a0Blumenthal, \u00a0Achieving \u00a0a \u00a0Nationwide \u00a0Learning \u00a0Health \u00a0System. \u00a0 Science \u00a0Translational \u00a0Medicine, \u00a02010. \u00a02(57): \u00a0p. \u00a057cm29-\u201057cm29. \u00a0 6. \u00a0 Friedman, \u00a0 C. \u00a0 and \u00a0M. \u00a0 Rigby, \u00a0Conceptualising \u00a0 and \u00a0 creating \u00a0 a \u00a0 global \u00a0 learning \u00a0 health \u00a0 system. \u00a0 Int \u00a0 J \u00a0 Med \u00a0Inform, \u00a02013. \u00a082(4): \u00a0p. \u00a0e63-\u201071. \u00a0 7. \u00a0 Ma, \u00a0 X.-\u2010J., \u00a0 et \u00a0 al., \u00a0A \u00a0 two-\u2010gene \u00a0expression \u00a0 ratio \u00a0predicts \u00a0 clinical \u00a0 outcome \u00a0 in \u00a0breast \u00a0 cancer \u00a0 patients \u00a0 treated \u00a0with \u00a0tamoxifen. \u00a0Cancer \u00a0Cell, \u00a02004. \u00a05(6): \u00a0p. \u00a0607-\u2010616. \u00a0 8. \u00a0 Strom, \u00a0B.L., \u00a0et \u00a0al., \u00a0Detecting \u00a0pregnancy \u00a0use \u00a0of \u00a0non-\u2010hormonal \u00a0category \u00a0X \u00a0medications \u00a0in \u00a0electronic \u00a0 medical \u00a0records. \u00a0Vol. \u00a018. \u00a02011. \u00a0i81-\u2010i86. \u00a0 9. \u00a0 Mathias, \u00a0J.S., \u00a0D. \u00a0Gossett, \u00a0and \u00a0D.W. \u00a0Baker, \u00a0Use \u00a0of \u00a0electronic \u00a0health \u00a0record \u00a0data \u00a0to \u00a0evaluate \u00a0overuse \u00a0 of \u00a0cervical \u00a0cancer \u00a0screening. \u00a0Vol. \u00a019. \u00a02012. \u00a0e96-\u2010e101. \u00a0 10. \u00a0 De \u00a0Pauw, \u00a0R., \u00a0et \u00a0al., \u00a0Identifying \u00a0prognostic \u00a0factors \u00a0predicting \u00a0outcome \u00a0in \u00a0patients \u00a0with \u00a0chronic \u00a0neck \u00a0 pain \u00a0after \u00a0multimodal \u00a0treatment: \u00a0A \u00a0retrospective \u00a0study. \u00a0Man \u00a0Ther, \u00a02015. \u00a020(4): \u00a0p. \u00a0592-\u20107. \u00a0 11. \u00a0 Onofrei, \u00a0 M., \u00a0 et \u00a0 al., \u00a0 A \u00a0 first \u00a0 step \u00a0 towards \u00a0 translating \u00a0 evidence \u00a0 into \u00a0 practice: \u00a0 heart \u00a0 failure \u00a0 in \u00a0 a \u00a0 community \u00a0practice-\u2010based \u00a0research \u00a0network. \u00a0Inform \u00a0Prim \u00a0Care, \u00a02004. \u00a012(3): \u00a0p. \u00a0139-\u201045. \u00a0 12. \u00a0 Johnson, \u00a0 S.B., \u00a0 et \u00a0 al., \u00a0An \u00a0 Electronic \u00a0Health \u00a0 Record \u00a0 Based \u00a0 on \u00a0 Structured \u00a0Narrative. \u00a0 Journal \u00a0 of \u00a0 the \u00a0 American \u00a0Medical \u00a0Informatics \u00a0Association \u00a0: \u00a0JAMIA, \u00a02008. \u00a015(1): \u00a0p. \u00a054-\u201064. \u00a0 13. \u00a0 Zhou, \u00a0L., \u00a0et \u00a0al., \u00a0How \u00a0many \u00a0medication \u00a0orders \u00a0are \u00a0entered \u00a0through \u00a0free-\u2010text \u00a0 in \u00a0EHRs?-\u2010-\u2010a \u00a0study \u00a0on \u00a0 hypoglycemic \u00a0agents. \u00a0AMIA \u00a0Annu \u00a0Symp \u00a0Proc, \u00a02012. \u00a02012: \u00a0p. \u00a01079-\u201088. \u00a0 14. \u00a0 Zheng, \u00a0K., \u00a0et \u00a0al., \u00a0Handling \u00a0anticipated \u00a0exceptions \u00a0in \u00a0clinical \u00a0care: \u00a0investigating \u00a0clinician \u00a0use \u00a0of \u00a0\u2018exit \u00a0 strategies\u2019 \u00a0in \u00a0an \u00a0electronic \u00a0health \u00a0records \u00a0system. \u00a0Vol. \u00a018. \u00a02011. \u00a0883-\u2010889. \u00a0\n12 \u00a0  \u00a0\n15. \u00a0 Raghavan, \u00a0P., \u00a0et \u00a0al., \u00a0How \u00a0essential \u00a0are \u00a0unstructured \u00a0clinical \u00a0narratives \u00a0and \u00a0 information \u00a0fusion \u00a0to \u00a0 clinical \u00a0 trial \u00a0 recruitment? \u00a0 AMIA \u00a0 Summits \u00a0 on \u00a0 Translational \u00a0 Science \u00a0 Proceedings, \u00a0 2014. \u00a0 2014: \u00a0 p. \u00a0 218-\u2010223. \u00a0 16. \u00a0 Stanfill, \u00a0M.H., \u00a0et \u00a0al., \u00a0A \u00a0systematic \u00a0literature \u00a0review \u00a0of \u00a0automated \u00a0clinical \u00a0coding \u00a0and \u00a0classification \u00a0 systems. \u00a0Vol. \u00a017. \u00a02010. \u00a0646-\u2010651. \u00a0 17. \u00a0 Jha, \u00a0A.K., \u00a0The \u00a0promise \u00a0of \u00a0 electronic \u00a0 records: \u00a0 around \u00a0 the \u00a0 corner \u00a0 or \u00a0 down \u00a0 the \u00a0 road? \u00a0 JAMA, \u00a02011. \u00a0 306(8): \u00a0p. \u00a0880-\u20101. \u00a0 18. \u00a0 Friedman, \u00a0 C., \u00a0 T.C. \u00a0 Rindflesch, \u00a0 and \u00a0M. \u00a0 Corn, \u00a0Natural \u00a0 language \u00a0 processing: \u00a0 State \u00a0 of \u00a0 the \u00a0 art \u00a0 and \u00a0 prospects \u00a0 for \u00a0 significant \u00a0 progress, \u00a0 a \u00a0 workshop \u00a0 sponsored \u00a0 by \u00a0 the \u00a0 National \u00a0 Library \u00a0 of \u00a0 Medicine. \u00a0 Journal \u00a0of \u00a0Biomedical \u00a0Informatics, \u00a02013. \u00a046(5): \u00a0p. \u00a0765-\u2010773. \u00a0 19. \u00a0 Shivade, \u00a0 C., \u00a0 et \u00a0 al., \u00a0 A \u00a0 review \u00a0 of \u00a0 approaches \u00a0 to \u00a0 identifying \u00a0 patient \u00a0 phenotype \u00a0 cohorts \u00a0 using \u00a0 electronic \u00a0health \u00a0records. \u00a0Vol. \u00a021. \u00a02014. \u00a0221-\u2010230. \u00a0 20. \u00a0 Nguyen, \u00a0 A.N., \u00a0 et \u00a0 al., \u00a0 Symbolic \u00a0 rule-\u2010based \u00a0 classification \u00a0 of \u00a0 lung \u00a0 cancer \u00a0 stages \u00a0 from \u00a0 free-\u2010text \u00a0 pathology \u00a0reports. \u00a0Vol. \u00a017. \u00a02010. \u00a0440-\u2010445. \u00a0 21. \u00a0 Mia \u00a0Schmiedeskamp, \u00a0 P.P., \u00a0 et \u00a0 al., \u00a0Use \u00a0 of \u00a0 International \u00a0 Classification \u00a0 of \u00a0 Diseases, \u00a0 Ninth \u00a0 Revision, \u00a0 Clinical \u00a0Modification \u00a0Codes \u00a0and \u00a0Medication \u00a0Use \u00a0Data \u00a0 to \u00a0 Identify \u00a0Nosocomial \u00a0Clostridium \u00a0difficile \u00a0 Infection \u00a0\u2022 \u00a0 Infection \u00a0Control \u00a0and \u00a0Hospital \u00a0Epidemiology, \u00a02009. \u00a030(11): \u00a0p. \u00a01070-\u20101076. \u00a0 22. \u00a0 Penberthy, \u00a0 L., \u00a0 et \u00a0 al., \u00a0 Automated \u00a0 matching \u00a0 software \u00a0 for \u00a0 clinical \u00a0 trials \u00a0 eligibility: \u00a0 Measuring \u00a0 efficiency \u00a0and \u00a0flexibility. \u00a0Contemporary \u00a0Clinical \u00a0Trials, \u00a02010. \u00a031(3): \u00a0p. \u00a0207-\u2010217. \u00a0 23. \u00a0 Kho, \u00a0A.N., \u00a0et \u00a0al., \u00a0Use \u00a0of \u00a0diverse \u00a0electronic \u00a0medical \u00a0record \u00a0systems \u00a0to \u00a0identify \u00a0genetic \u00a0risk \u00a0for \u00a0type \u00a02 \u00a0 diabetes \u00a0within \u00a0a \u00a0genome-\u2010wide \u00a0association \u00a0study. \u00a0J \u00a0Am \u00a0Med \u00a0Inform \u00a0Assoc, \u00a02012. \u00a019(2): \u00a0p. \u00a0212-\u20108. \u00a0 24. \u00a0 Klompas, \u00a0M., \u00a0et \u00a0al., \u00a0Automated \u00a0identification \u00a0of \u00a0acute \u00a0hepatitis \u00a0B \u00a0using \u00a0electronic \u00a0medical \u00a0record \u00a0 data \u00a0to \u00a0facilitate \u00a0public \u00a0health \u00a0surveillance. \u00a0PLoS \u00a0One, \u00a02008. \u00a03(7): \u00a0p. \u00a0e2626. \u00a0 25. \u00a0 Mani, \u00a0S., \u00a0et \u00a0al., \u00a0Early \u00a0prediction \u00a0of \u00a0 the \u00a0 response \u00a0of \u00a0breast \u00a0 tumors \u00a0 to \u00a0neoadjuvant \u00a0chemotherapy \u00a0 using \u00a0quantitative \u00a0MRI \u00a0and \u00a0machine \u00a0learning. \u00a0AMIA \u00a0Annu \u00a0Symp \u00a0Proc, \u00a02011. \u00a02011: \u00a0p. \u00a0868-\u201077. \u00a0 26. \u00a0 Van \u00a0 den \u00a0 Bulcke, \u00a0 T., \u00a0 et \u00a0 al., \u00a0 Data \u00a0 mining \u00a0 methods \u00a0 for \u00a0 classification \u00a0 of \u00a0 Medium-\u2010Chain \u00a0 Acyl-\u2010CoA \u00a0 dehydrogenase \u00a0deficiency \u00a0(MCADD) \u00a0using \u00a0non-\u2010derivatized \u00a0tandem \u00a0MS \u00a0neonatal \u00a0screening \u00a0data. \u00a0J \u00a0 Biomed \u00a0Inform, \u00a02011. \u00a044(2): \u00a0p. \u00a0319-\u201025. \u00a0 27. \u00a0 Zhao, \u00a0 D. \u00a0 and \u00a0 C. \u00a0 Weng, \u00a0 Combining \u00a0 PubMed \u00a0 knowledge \u00a0 and \u00a0 EHR \u00a0 data \u00a0 to \u00a0 develop \u00a0 a \u00a0 weighted \u00a0 bayesian \u00a0network \u00a0for \u00a0pancreatic \u00a0cancer \u00a0prediction. \u00a0J \u00a0Biomed \u00a0Inform, \u00a02011. \u00a044(5): \u00a0p. \u00a0859-\u201068. \u00a0 28. \u00a0 Kawaler, \u00a0 E., \u00a0 et \u00a0 al., \u00a0 Learning \u00a0 to \u00a0 predict \u00a0 post-\u2010hospitalization \u00a0VTE \u00a0 risk \u00a0 from \u00a0EHR \u00a0 data. \u00a0 AMIA \u00a0Annu \u00a0 Symp \u00a0Proc, \u00a02012. \u00a02012: \u00a0p. \u00a0436-\u201045. \u00a0 29. \u00a0 Lowe, \u00a0 H.J., \u00a0 et \u00a0 al., \u00a0 STRIDE-\u2010-\u2010An \u00a0 integrated \u00a0 standards-\u2010based \u00a0 translational \u00a0 research \u00a0 informatics \u00a0 platform. \u00a0AMIA \u00a0... \u00a0Annual \u00a0Symposium \u00a0proceedings \u00a0/ \u00a0AMIA \u00a0Symposium. \u00a0AMIA \u00a0Symposium, \u00a02009. \u00a0 2009: \u00a0p. \u00a0391-\u2010395. \u00a0 30. \u00a0 Gregg, \u00a0W., \u00a0 et \u00a0 al., \u00a0StarTracker: \u00a0 an \u00a0 integrated, \u00a0web-\u2010based \u00a0 clinical \u00a0 search \u00a0 engine. \u00a0 AMIA \u00a0 ... \u00a0 Annual \u00a0 Symposium \u00a0proceedings \u00a0/ \u00a0AMIA \u00a0Symposium. \u00a0AMIA \u00a0Symposium, \u00a02003: \u00a0p. \u00a0855. \u00a0 31. \u00a0 Hanauer, \u00a0D.A., \u00a0et \u00a0al., \u00a0Supporting \u00a0information \u00a0retrieval \u00a0from \u00a0electronic \u00a0health \u00a0records: \u00a0A \u00a0report \u00a0of \u00a0 University \u00a0 of \u00a0 Michigan\u2019s \u00a0 nine-\u2010year \u00a0 experience \u00a0 in \u00a0 developing \u00a0 and \u00a0 using \u00a0 the \u00a0 Electronic \u00a0 Medical \u00a0 Record \u00a0Search \u00a0Engine \u00a0(EMERSE). \u00a0Journal \u00a0of \u00a0Biomedical \u00a0Informatics, \u00a02015. \u00a055: \u00a0p. \u00a0290-\u2010300. \u00a0 32. \u00a0 Zalis, \u00a0M. \u00a0and \u00a0M. \u00a0Harris, \u00a0Advanced \u00a0Search \u00a0of \u00a0the \u00a0Electronic \u00a0Medical \u00a0Record: \u00a0Augmenting \u00a0Safety \u00a0and \u00a0 Efficiency \u00a0in \u00a0Radiology. \u00a0Journal \u00a0of \u00a0the \u00a0American \u00a0College \u00a0of \u00a0Radiology, \u00a02010. \u00a07(8): \u00a0p. \u00a0625-\u2010633. \u00a0 33. \u00a0 Lehman, \u00a0 L.W., \u00a0 et \u00a0 al., \u00a0 Risk \u00a0 stratification \u00a0 of \u00a0 ICU \u00a0 patients \u00a0 using \u00a0 topic \u00a0 models \u00a0 inferred \u00a0 from \u00a0 unstructured \u00a0progress \u00a0notes. \u00a0AMIA \u00a0Annu \u00a0Symp \u00a0Proc, \u00a02012. \u00a02012: \u00a0p. \u00a0505-\u201011. \u00a0 34. \u00a0 Carroll, \u00a0R.J., \u00a0A.E. \u00a0Eyler, \u00a0and \u00a0J.C. \u00a0Denny, \u00a0Naive \u00a0Electronic \u00a0Health \u00a0Record \u00a0phenotype \u00a0identification \u00a0for \u00a0 Rheumatoid \u00a0arthritis. \u00a0AMIA \u00a0Annu \u00a0Symp \u00a0Proc, \u00a02011. \u00a02011: \u00a0p. \u00a0189-\u201096. \u00a0 35. \u00a0 Liao, \u00a0K.P., \u00a0et \u00a0al., \u00a0Electronic \u00a0medical \u00a0records \u00a0for \u00a0discovery \u00a0research \u00a0in \u00a0rheumatoid \u00a0arthritis. \u00a0Arthritis \u00a0 Care \u00a0& \u00a0Research, \u00a02010. \u00a062(8): \u00a0p. \u00a01120-\u20101127. \u00a0 36. \u00a0 Bejan, \u00a0C.A., \u00a0et \u00a0al., \u00a0Pneumonia \u00a0identification \u00a0using \u00a0statistical \u00a0feature \u00a0selection. \u00a0Vol. \u00a019. \u00a02012. \u00a0817-\u2010 823. \u00a0 37. \u00a0 Kopcke, \u00a0 F. \u00a0 and \u00a0 H.U. \u00a0 Prokosch, \u00a0 Employing \u00a0 computers \u00a0 for \u00a0 the \u00a0 recruitment \u00a0 into \u00a0 clinical \u00a0 trials: \u00a0 a \u00a0 comprehensive \u00a0systematic \u00a0review. \u00a0J \u00a0Med \u00a0Internet \u00a0Res, \u00a02014. \u00a016(7): \u00a0p. \u00a0e161. \u00a0\n13 \u00a0  \u00a0\n38. \u00a0 Ni, \u00a0 Y., \u00a0 et \u00a0 al., \u00a0Automated \u00a0 clinical \u00a0 trial \u00a0 eligibility \u00a0 prescreening: \u00a0 increasing \u00a0 the \u00a0 efficiency \u00a0 of \u00a0 patient \u00a0 identification \u00a0for \u00a0clinical \u00a0trials \u00a0in \u00a0the \u00a0emergency \u00a0department. \u00a0J \u00a0Am \u00a0Med \u00a0Inform \u00a0Assoc, \u00a02015. \u00a022(1): \u00a0 p. \u00a0166-\u201078. \u00a0 39. \u00a0 PARAGON \u00a0 Inclusion/Exclusion \u00a0 Criteria. \u00a0 2015 \u00a0  \u00a0 [cited \u00a0 2015 \u00a0 10th \u00a0 August]; \u00a0 Available \u00a0 from: \u00a0 https://sjonnalagadda.files.wordpress.com/2015/08/paragon_ie-\u2010criteria_10-\u201001-\u20102014.pdf. \u00a0 40. \u00a0 Bodenreider, \u00a0 O., \u00a0 The \u00a0 Unified \u00a0 Medical \u00a0 Language \u00a0 System \u00a0 (UMLS): \u00a0 integrating \u00a0 biomedical \u00a0 terminology. \u00a0Nucleic \u00a0Acids \u00a0Res, \u00a02004. \u00a032(Database \u00a0issue): \u00a0p. \u00a0D267-\u201070. \u00a0 41. \u00a0 Harkema, \u00a0H., \u00a0 et \u00a0al., \u00a0ConText: \u00a0an \u00a0algorithm \u00a0 for \u00a0determining \u00a0negation, \u00a0 experiencer, \u00a0and \u00a0 temporal \u00a0 status \u00a0from \u00a0clinical \u00a0reports. \u00a0J \u00a0Biomed \u00a0Inform, \u00a02009. \u00a042(5): \u00a0p. \u00a0839-\u201051. \u00a0 42. \u00a0 Mitchell, \u00a0 K.J., \u00a0 et \u00a0 al., \u00a0 Implementation \u00a0 and \u00a0 evaluation \u00a0 of \u00a0 a \u00a0 negation \u00a0 tagger \u00a0 in \u00a0 a \u00a0 pipeline-\u2010based \u00a0 system \u00a0for \u00a0information \u00a0extract \u00a0from \u00a0pathology \u00a0reports. \u00a0Stud \u00a0Health \u00a0Technol \u00a0Inform, \u00a02004. \u00a0107(Pt \u00a0 1): \u00a0p. \u00a0663-\u20107."}], "references": [{"title": "Mining electronic health records: towards better research applications and clinical care", "author": ["P.B. Jensen", "L.J. Jensen", "S. Brunak"], "venue": "Nat Rev Genet,", "citeRegEx": "1", "shortCiteRegEx": "1", "year": 2012}, {"title": "Subject Recruitment and Retention: Barrier to Success", "author": ["J. Sullivan"], "venue": null, "citeRegEx": "2", "shortCiteRegEx": "2", "year": 2004}, {"title": "Forecasting the future of cardiovascular disease in the United States: a policy statement from the American Heart Association", "author": ["Heidenreich", "P.A"], "venue": "Circulation,", "citeRegEx": "3", "shortCiteRegEx": "3", "year": 2011}, {"title": "Heart disease and stroke statistics-\u00ad\u2010-\u00ad\u20102015 update: a report from the American Heart Association", "author": ["D Mozaffarian"], "venue": "Circulation,", "citeRegEx": "4", "shortCiteRegEx": "4", "year": 2015}, {"title": "Achieving a Nationwide Learning Health System", "author": ["C.P. Friedman", "A.K. Wong", "D. Blumenthal"], "venue": "Science Translational Medicine,", "citeRegEx": "5", "shortCiteRegEx": "5", "year": 2010}, {"title": "Conceptualising and creating a global learning health system", "author": ["C. Friedman", "M. Rigby"], "venue": "Int J Med Inform,", "citeRegEx": "6", "shortCiteRegEx": "6", "year": 2013}, {"title": "A two-\u00ad\u2010gene expression ratio predicts clinical outcome in breast cancer patients treated with tamoxifen", "author": ["Ma", "X.-\u00ad\u2010J"], "venue": "Cancer Cell,", "citeRegEx": "7", "shortCiteRegEx": "7", "year": 2004}, {"title": "Detecting pregnancy use of non-\u00ad\u2010hormonal category X medications", "author": ["Strom", "B.L"], "venue": "in electronic medical records. Vol", "citeRegEx": "8", "shortCiteRegEx": "8", "year": 2011}, {"title": "Use of electronic health record data to evaluate overuse of cervical cancer", "author": ["J.S. Mathias", "D. Gossett", "D.W. Baker"], "venue": "screening. Vol", "citeRegEx": "9", "shortCiteRegEx": "9", "year": 2012}, {"title": "Identifying prognostic factors predicting outcome in patients with chronic neck pain after multimodal treatment: A retrospective study", "author": ["R De Pauw"], "venue": "Man Ther,", "citeRegEx": "10", "shortCiteRegEx": "10", "year": 2015}, {"title": "A first step towards translating evidence into practice: heart failure in a community practice-\u00ad\u2010based research", "author": ["M Onofrei"], "venue": null, "citeRegEx": "11", "shortCiteRegEx": "11", "year": 2004}, {"title": "An Electronic Health Record Based on Structured Narrative", "author": ["Johnson", "S.B"], "venue": "Journal of the American Medical Informatics Association : JAMIA,", "citeRegEx": "12", "shortCiteRegEx": "12", "year": 2008}, {"title": "How many medication orders are entered through free-\u00ad\u2010text in EHRs?-\u00ad\u2010-\u00ad\u2010a study on hypoglycemic agents", "author": ["L Zhou"], "venue": "AMIA Annu Symp Proc,", "citeRegEx": "13", "shortCiteRegEx": "13", "year": 2012}, {"title": "Handling anticipated exceptions in clinical care: investigating clinician use of \u2018exit strategies", "author": ["K Zheng"], "venue": "in an electronic health records system. Vol", "citeRegEx": "14", "shortCiteRegEx": "14", "year": 2011}, {"title": "How essential are unstructured clinical narratives and information fusion to clinical trial recruitment", "author": ["P Raghavan"], "venue": "AMIA Summits on Translational Science Proceedings,", "citeRegEx": "15", "shortCiteRegEx": "15", "year": 2014}, {"title": "A systematic literature review of automated clinical coding and classification systems", "author": ["Stanfill", "M.H"], "venue": "Vol. 17", "citeRegEx": "16", "shortCiteRegEx": "16", "year": 2010}, {"title": "The promise of electronic records: around the corner or down the road", "author": ["A.K. Jha"], "venue": "JAMA,", "citeRegEx": "17", "shortCiteRegEx": "17", "year": 2011}, {"title": "Natural language processing: State of the art and prospects for significant progress, a workshop sponsored by the National Library of Medicine", "author": ["C. Friedman", "T.C. Rindflesch", "M. Corn"], "venue": "Journal of Biomedical Informatics,", "citeRegEx": "18", "shortCiteRegEx": "18", "year": 2013}, {"title": "A review of approaches to identifying patient phenotype cohorts using electronic health", "author": ["C Shivade"], "venue": "records. Vol", "citeRegEx": "19", "shortCiteRegEx": "19", "year": 2014}, {"title": "Symbolic rule-\u00ad\u2010based classification of lung cancer stages from free-\u00ad\u2010text pathology", "author": ["Nguyen", "A.N"], "venue": "reports. Vol", "citeRegEx": "20", "shortCiteRegEx": "20", "year": 2010}, {"title": "Use of International Classification of Diseases, Ninth Revision, Clinical Modification Codes and Medication Use Data to Identify Nosocomial Clostridium difficile Infection \u2022 Infection", "author": ["Mia Schmiedeskamp", "P.P"], "venue": "Control and Hospital Epidemiology,", "citeRegEx": "21", "shortCiteRegEx": "21", "year": 2009}, {"title": "Automated matching software for clinical trials eligibility: Measuring efficiency and flexibility", "author": ["L Penberthy"], "venue": "Contemporary Clinical Trials,", "citeRegEx": "22", "shortCiteRegEx": "22", "year": 2010}, {"title": "Use of diverse electronic medical record systems to identify genetic risk for type 2 diabetes within a genome-\u00ad\u2010wide association study", "author": ["Kho", "A.N"], "venue": "J Am Med Inform Assoc,", "citeRegEx": "23", "shortCiteRegEx": "23", "year": 2012}, {"title": "Automated identification of acute hepatitis B using electronic medical record data to facilitate public health surveillance", "author": ["M Klompas"], "venue": "PLoS One,", "citeRegEx": "24", "shortCiteRegEx": "24", "year": 2008}, {"title": "Early prediction of the response of breast tumors to neoadjuvant chemotherapy using quantitative MRI and machine learning", "author": ["S Mani"], "venue": "AMIA Annu Symp Proc,", "citeRegEx": "25", "shortCiteRegEx": "25", "year": 2011}, {"title": "Data mining methods for classification of Medium-\u00ad\u2010Chain Acyl-\u00ad\u2010CoA dehydrogenase deficiency (MCADD) using non-\u00ad\u2010derivatized tandem MS neonatal screening data", "author": ["T Van den Bulcke"], "venue": "J Biomed Inform,", "citeRegEx": "26", "shortCiteRegEx": "26", "year": 2011}, {"title": "Combining PubMed knowledge and EHR data to develop a weighted bayesian network for pancreatic cancer prediction", "author": ["D. Zhao", "C. Weng"], "venue": "J Biomed Inform,", "citeRegEx": "27", "shortCiteRegEx": "27", "year": 2011}, {"title": "Learning to predict post-\u00ad\u2010hospitalization VTE risk from EHR data", "author": ["E Kawaler"], "venue": "AMIA Annu Symp Proc,", "citeRegEx": "28", "shortCiteRegEx": "28", "year": 2012}, {"title": "STRIDE-\u00ad\u2010-\u00ad\u2010An integrated standards-\u00ad\u2010based translational research informatics platform", "author": ["Lowe", "H.J"], "venue": "AMIA ... Annual Symposium proceedings / AMIA Symposium. AMIA Symposium,", "citeRegEx": "29", "shortCiteRegEx": "29", "year": 2009}, {"title": "StarTracker: an integrated, web-\u00ad\u2010based clinical search engine", "author": ["W Gregg"], "venue": "AMIA ... Annual Symposium proceedings / AMIA Symposium. AMIA Symposium,", "citeRegEx": "30", "shortCiteRegEx": "30", "year": 2003}, {"title": "Supporting information retrieval from electronic health records: A report of University of Michigan\u2019s nine-\u00ad\u2010year experience in developing and using the Electronic Medical Record Search Engine (EMERSE)", "author": ["Hanauer", "D.A"], "venue": "Journal of Biomedical Informatics,", "citeRegEx": "31", "shortCiteRegEx": "31", "year": 2015}, {"title": "Advanced Search of the Electronic Medical Record: Augmenting Safety and Efficiency in Radiology", "author": ["M. Zalis", "M. Harris"], "venue": "Journal of the American College of Radiology,", "citeRegEx": "32", "shortCiteRegEx": "32", "year": 2010}, {"title": "Risk stratification of ICU patients using topic models inferred from unstructured progress notes", "author": ["Lehman", "L.W"], "venue": "AMIA Annu Symp Proc,", "citeRegEx": "33", "shortCiteRegEx": "33", "year": 2012}, {"title": "Naive Electronic Health Record phenotype identification for Rheumatoid arthritis", "author": ["R.J. Carroll", "A.E. Eyler", "J.C. Denny"], "venue": "AMIA Annu Symp Proc,", "citeRegEx": "34", "shortCiteRegEx": "34", "year": 2011}, {"title": "Electronic medical records for discovery research in rheumatoid arthritis", "author": ["Liao", "K.P"], "venue": "Arthritis Care & Research,", "citeRegEx": "35", "shortCiteRegEx": "35", "year": 2010}, {"title": "Pneumonia identification using statistical feature selection", "author": ["Bejan", "C.A"], "venue": "Vol. 19", "citeRegEx": "36", "shortCiteRegEx": "36", "year": 2012}, {"title": "Employing computers for the recruitment into clinical trials: a comprehensive systematic review", "author": ["F. Kopcke", "H.U. Prokosch"], "venue": "J Med Internet Res,", "citeRegEx": "37", "shortCiteRegEx": "37", "year": 2014}, {"title": "Automated clinical trial eligibility prescreening: increasing the efficiency of patient identification for clinical trials in the emergency department", "author": ["Y Ni"], "venue": "J Am Med Inform Assoc,", "citeRegEx": "38", "shortCiteRegEx": "38", "year": 2015}, {"title": "The Unified Medical Language System (UMLS): integrating biomedical terminology", "author": ["O. Bodenreider"], "venue": "Nucleic Acids Res,", "citeRegEx": "40", "shortCiteRegEx": "40", "year": 2004}, {"title": "ConText: an algorithm for determining negation, experiencer, and temporal status from clinical reports", "author": ["H Harkema"], "venue": "J Biomed Inform,", "citeRegEx": "41", "shortCiteRegEx": "41", "year": 2009}, {"title": "Implementation and evaluation of a negation tagger in a pipeline-\u00ad\u2010based system for information extract from pathology reports", "author": ["Mitchell", "K.J"], "venue": "Stud Health Technol Inform,", "citeRegEx": "42", "shortCiteRegEx": "42", "year": 2004}], "referenceMentions": [{"referenceID": 0, "context": "The creation and acceptance of electronic health records (EHRs) has ignited widespread interest in the use of clinical data for secondary purposes and research [1].", "startOffset": 160, "endOffset": 163}, {"referenceID": 1, "context": "Because of the subjectivity involved in human decision-making, domain knowledge, which patients are considered for initial search and other factors [2], there is always a possibility of type-1 and type-2 errors in the", "startOffset": 148, "endOffset": 151}, {"referenceID": 2, "context": "4 billion [3, 4].", "startOffset": 10, "endOffset": 16}, {"referenceID": 3, "context": "4 billion [3, 4].", "startOffset": 10, "endOffset": 16}, {"referenceID": 1, "context": "However, it has been found that 86% of all clinical trials are delayed in patient recruitment from 1 to 6 months, and 13% are delayed by longer than 6 months [2].", "startOffset": 158, "endOffset": 161}, {"referenceID": 4, "context": "As Friedman et al noted, the extensive use of clinical data provides great potential to transform our healthcare system into a \u201cSelf-learning Health System\u201d [5, 6].", "startOffset": 157, "endOffset": 163}, {"referenceID": 5, "context": "As Friedman et al noted, the extensive use of clinical data provides great potential to transform our healthcare system into a \u201cSelf-learning Health System\u201d [5, 6].", "startOffset": 157, "endOffset": 163}, {"referenceID": 6, "context": "This can be used for a variety of applications, including clinical trial recruitment, outcome prediction, survival analysis, and other retrospective studies [7-10].", "startOffset": 157, "endOffset": 163}, {"referenceID": 7, "context": "This can be used for a variety of applications, including clinical trial recruitment, outcome prediction, survival analysis, and other retrospective studies [7-10].", "startOffset": 157, "endOffset": 163}, {"referenceID": 8, "context": "This can be used for a variety of applications, including clinical trial recruitment, outcome prediction, survival analysis, and other retrospective studies [7-10].", "startOffset": 157, "endOffset": 163}, {"referenceID": 9, "context": "This can be used for a variety of applications, including clinical trial recruitment, outcome prediction, survival analysis, and other retrospective studies [7-10].", "startOffset": 157, "endOffset": 163}, {"referenceID": 10, "context": "3 The syndromic nature of HF presents unique challenges for the identification of patients from EHR data for research [11].", "startOffset": 118, "endOffset": 122}, {"referenceID": 14, "context": "It has also been noted that unstructured data are essential because of the information they contain [15]; therefore, unstructured data are likely to persist in the future.", "startOffset": 100, "endOffset": 104}, {"referenceID": 15, "context": "There is an immediate need for an automated data extraction system to transform unstructured clinical reports into a structured form, which is much easier to process and handle [16-18].", "startOffset": 177, "endOffset": 184}, {"referenceID": 16, "context": "There is an immediate need for an automated data extraction system to transform unstructured clinical reports into a structured form, which is much easier to process and handle [16-18].", "startOffset": 177, "endOffset": 184}, {"referenceID": 17, "context": "There is an immediate need for an automated data extraction system to transform unstructured clinical reports into a structured form, which is much easier to process and handle [16-18].", "startOffset": 177, "endOffset": 184}, {"referenceID": 18, "context": "There has been considerable research in identifying patient cohorts from EHRs [19].", "startOffset": 78, "endOffset": 82}, {"referenceID": 19, "context": "These approaches can be categorized into three general types: (1) rule-based approaches [20-24], (2) machine learning\u2013based approaches [25-28], and (3) information retrieval\u2013based approaches [29-32].", "startOffset": 88, "endOffset": 95}, {"referenceID": 20, "context": "These approaches can be categorized into three general types: (1) rule-based approaches [20-24], (2) machine learning\u2013based approaches [25-28], and (3) information retrieval\u2013based approaches [29-32].", "startOffset": 88, "endOffset": 95}, {"referenceID": 21, "context": "These approaches can be categorized into three general types: (1) rule-based approaches [20-24], (2) machine learning\u2013based approaches [25-28], and (3) information retrieval\u2013based approaches [29-32].", "startOffset": 88, "endOffset": 95}, {"referenceID": 22, "context": "These approaches can be categorized into three general types: (1) rule-based approaches [20-24], (2) machine learning\u2013based approaches [25-28], and (3) information retrieval\u2013based approaches [29-32].", "startOffset": 88, "endOffset": 95}, {"referenceID": 23, "context": "These approaches can be categorized into three general types: (1) rule-based approaches [20-24], (2) machine learning\u2013based approaches [25-28], and (3) information retrieval\u2013based approaches [29-32].", "startOffset": 88, "endOffset": 95}, {"referenceID": 24, "context": "These approaches can be categorized into three general types: (1) rule-based approaches [20-24], (2) machine learning\u2013based approaches [25-28], and (3) information retrieval\u2013based approaches [29-32].", "startOffset": 135, "endOffset": 142}, {"referenceID": 25, "context": "These approaches can be categorized into three general types: (1) rule-based approaches [20-24], (2) machine learning\u2013based approaches [25-28], and (3) information retrieval\u2013based approaches [29-32].", "startOffset": 135, "endOffset": 142}, {"referenceID": 26, "context": "These approaches can be categorized into three general types: (1) rule-based approaches [20-24], (2) machine learning\u2013based approaches [25-28], and (3) information retrieval\u2013based approaches [29-32].", "startOffset": 135, "endOffset": 142}, {"referenceID": 27, "context": "These approaches can be categorized into three general types: (1) rule-based approaches [20-24], (2) machine learning\u2013based approaches [25-28], and (3) information retrieval\u2013based approaches [29-32].", "startOffset": 135, "endOffset": 142}, {"referenceID": 28, "context": "These approaches can be categorized into three general types: (1) rule-based approaches [20-24], (2) machine learning\u2013based approaches [25-28], and (3) information retrieval\u2013based approaches [29-32].", "startOffset": 191, "endOffset": 198}, {"referenceID": 29, "context": "These approaches can be categorized into three general types: (1) rule-based approaches [20-24], (2) machine learning\u2013based approaches [25-28], and (3) information retrieval\u2013based approaches [29-32].", "startOffset": 191, "endOffset": 198}, {"referenceID": 30, "context": "These approaches can be categorized into three general types: (1) rule-based approaches [20-24], (2) machine learning\u2013based approaches [25-28], and (3) information retrieval\u2013based approaches [29-32].", "startOffset": 191, "endOffset": 198}, {"referenceID": 31, "context": "These approaches can be categorized into three general types: (1) rule-based approaches [20-24], (2) machine learning\u2013based approaches [25-28], and (3) information retrieval\u2013based approaches [29-32].", "startOffset": 191, "endOffset": 198}, {"referenceID": 32, "context": "All these approaches use either pattern matching (regular expressions) or language modeling\u2013based methods [33-36] to extract features for their system to work on.", "startOffset": 106, "endOffset": 113}, {"referenceID": 33, "context": "All these approaches use either pattern matching (regular expressions) or language modeling\u2013based methods [33-36] to extract features for their system to work on.", "startOffset": 106, "endOffset": 113}, {"referenceID": 34, "context": "All these approaches use either pattern matching (regular expressions) or language modeling\u2013based methods [33-36] to extract features for their system to work on.", "startOffset": 106, "endOffset": 113}, {"referenceID": 35, "context": "All these approaches use either pattern matching (regular expressions) or language modeling\u2013based methods [33-36] to extract features for their system to work on.", "startOffset": 106, "endOffset": 113}, {"referenceID": 20, "context": "For example, a majority of the systems only use a variation of disease names, medications used, or treatments taken as their eligibility criteria [21, 23].", "startOffset": 146, "endOffset": 154}, {"referenceID": 22, "context": "For example, a majority of the systems only use a variation of disease names, medications used, or treatments taken as their eligibility criteria [21, 23].", "startOffset": 146, "endOffset": 154}, {"referenceID": 36, "context": "Our study goal is similar to that of the plethora of approaches proposed in computer-based clinical trial recruitment systems [37].", "startOffset": 126, "endOffset": 130}, {"referenceID": 37, "context": "4 [38].", "startOffset": 2, "endOffset": 6}, {"referenceID": 38, "context": "For this, the module first checks for synonyms of the input term using UMLS Metathesaurus [40], builds automatically a set of regular expressions, and then applies them to the input report text to extract all the instances.", "startOffset": 90, "endOffset": 94}, {"referenceID": 39, "context": "We adapt existing rule-based systems to make sure the data elements are not in their negated form using a rule-based negation detection algorithm, the data elements refer to the current status (as opposed to historical condition or a hypothesis for conducting a test) and the data elements correspond to the patient (as opposed to a family member or relative) [41, 42].", "startOffset": 360, "endOffset": 368}, {"referenceID": 40, "context": "We adapt existing rule-based systems to make sure the data elements are not in their negated form using a rule-based negation detection algorithm, the data elements refer to the current status (as opposed to historical condition or a hypothesis for conducting a test) and the data elements correspond to the patient (as opposed to a family member or relative) [41, 42].", "startOffset": 360, "endOffset": 368}], "year": 2016, "abstractText": "To reduce the large amount of time spent screening, identifying, and recruiting patients into clinical trials, we need prescreening systems that are able to automate the data extraction and decision-making tasks that are typically relegated to clinical research study coordinators. However, a major obstacle is the vast amount of patient data available as unstructured free-form text in electronic health records. Here we propose an information extraction-based approach that first automatically converts unstructured text into a structured form. The structured data are then compared against a list of eligibility criteria using a rule-based system to determine which patients qualify for enrollment in a heart failure clinical trial. We show that we can achieve highly accurate results, with recall and precision values of 0.95 and 0.86, respectively. Our system allowed us to significantly reduce the time needed for prescreening patients from a few weeks to a few minutes. Our open-source information extraction modules are available for researchers and could be tested and validated in other cardiovascular trials. An approach such as the one we demonstrate here may decrease costs and expedite clinical trials, and could enhance the reproducibility of trials across institutions and populations.", "creator": "Word"}}}