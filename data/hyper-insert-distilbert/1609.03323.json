{"id": "1609.03323", "review": {"conference": "arxiv", "VERSION": "v1", "DATE_OF_SUBMISSION": "12-Sep-2016", "title": "Sensor-based Gait Parameter Extraction with Deep Convolutional Neural Networks", "abstract": "measurement of stride - related, biomechanical parameters is the common rationale for objective gait impairment scoring. state - of - how the - art weighted double integration approaches able to better extract these identifying parameters from other inertial sensor data databases are, however, limited in reaching their clinical applicability implications due to the underlying measurement assumptions. instead to generally overcome this, we typically present a statistical method to truly translate accurately the abstract measured information provided by wearable sensors to identify context - driven related expert features based on deep mesh convolutional neural image networks. regarding using mobile baseline gait analysis, from this methods enables integration - free dynamics and data - base driven entity extraction of a set parameters of dimension 8 interactive spatio - controlled temporal exercises stride adjustment parameters. hopefully to this end, two modelling computational approaches are commercially compared : a detailed combined network estimating encompasses all potential parameters incapable of expressed interest and an ensemble approach that det spawns less extremely complex networks appropriate for each parameter outlined individually. while the synthetic ensemble configuration approach is completely outperforming the combined simulation modelling features in for the current calculation application. focus on a clinically - relevant technical and possibly publicly available benchmark dataset, therefore we cannot estimate stride muscular length, width decrease and rapid medio - lateral change in extended foot strap angle approximately up ahead to $ { - 2 0. 15 \\ pm6. 09 } $ cm, $ { - \\ 0. 09 \\ pm4. 3 22 } $ 100 cm upwards and $ { 0. 13 \\ delta pm 3. 8 78 ^ \\ circ } $ respectively. stride, swing and pendulum stance engagement time ratios as well characterized as heel tilt and left toe contact scale times are estimated up above to $ { \\ pm \u2022 0. 67 07 } $, $ { \\ pm0. 05 } $, $ { \\ pm _ 0. 07 } $, $ { \\ * pm0. 07 } $ 26 and $ { \\ pm0. 17 12 } $ s respectively. nevertheless this insight is still comparable both to and available in substantial parts partially outperforming cadence or defining any state - of - the - kind art. our update results further indicate that the proposed conceptual change in methodology could substitute various assumption - driven double - integration integration methods and partially enable mobile assessment recognition of spatio - temporal exercise stride aspect parameters in clinically linked critical situations known as e. g. in the case of high spastic gait sensor impairments.", "histories": [["v1", "Mon, 12 Sep 2016 09:33:57 GMT  (2035kb,D)", "https://arxiv.org/abs/1609.03323v1", null], ["v2", "Tue, 11 Oct 2016 10:56:32 GMT  (2035kb,D)", "http://arxiv.org/abs/1609.03323v2", null], ["v3", "Fri, 13 Jan 2017 12:30:39 GMT  (2076kb,D)", "http://arxiv.org/abs/1609.03323v3", "in IEEE Journal of Biomedical and Health Informatics (2016)"]], "reviews": [], "SUBJECTS": "cs.LG", "authors": ["julius hannink", "thomas kautz", "cristian f pasluosta", "karl-g\\\"unter ga{\\ss}mann", "jochen klucken", "bjoern m eskofier"], "accepted": false, "id": "1609.03323"}, "pdf": {"name": "1609.03323.pdf", "metadata": {"source": "CRF", "title": "Sensor-based Gait Parameter Extraction with Deep Convolutional Neural Networks", "authors": ["J. Hannink", "T. Kautz", "C. F. Pasluosta", "K.-G. Ga\u00dfmann", "J. Klucken", "B. M. Eskofier"], "emails": ["julius.hannink@fau.de"], "sections": [{"heading": null, "text": "To overcome this, we present a method to translate the abstract information provided by wearable sensors to context-related expert features based on deep convolutional neural networks. Regarding mobile gait analysis, this enables integration-free and data-driven extraction of a set of eight spatio-temporal stride parameters. To this end, two modelling approaches are compared: A combined network estimating all parameters of interest and an ensemble approach that spawns less complex networks for each parameter individually.\nThe ensemble approach is outperforming the combined modelling in the current application. On a clinically relevant and publicly available benchmark dataset, we estimate stride length, width and medio-lateral change in foot angle up to \u22120.15 \u00b1 6.09 cm, \u22120.09\u00b14.22 cm and 0.13\u00b13.78\u25e6 respectively. Stride, swing and stance time as well as heel and toe contact times are estimated up to \u00b10.07, \u00b10.05, \u00b10.07, \u00b10.07 and \u00b10.12 s respectively. This is comparable to and in parts outperforming or defining stateof-the-art.\nOur results further indicate that the proposed change in methodology could substitute assumption-driven doubleintegration methods and enable mobile assessment of spatiotemporal stride parameters in clinically critical situations as e.g. in the case of spastic gait impairments.\nIndex Terms\u2014deep learning, convolutional neural networks, regression, mobile gait analysis, spatio-temporal gait parameters\nI. Introduction\nA variety of neurological and musculoskeletal diseases affect human gait quality and manifest in specific stride characteristics. Parkinson\u2019s disease (PD), for example, is associated with a reduced stride length, shuffling steps or impaired gait initiation. As reduced gait quality can lead to severe reductions in patient mobility and quality of life [1], it is important to quantify, detect and treat gait impairments as early as possible.\nObjective quantification of gait impairment is based on stride-specific characteristics such as stride length or stride time. These parameters are commonly extracted with the help of several electronic measurement systems including computerised pressure mats ([2], [3]), optical motion-capture systems [4] or mobile, sensor-based solutions ([5]\u2013[11]). While the\nJ. Hannink, T. Kautz, C. F. Pasluosta and B. M. Eskofier: Digital Sports Group, Pattern Recognition Lab, Department of Computer Science, University of Erlangen-N\u00fcrnberg (FAU), Germany\nK.-G. Ga\u00dfmann: Geriatrics Centre Erlangen, Waldkrankenhaus St. Marien, Erlangen, Germany\nJ. Klucken: Department of Molecular Neurology, University Hospital Erlangen, University of Erlangen-N\u00fcrnberg (FAU), Germany\nCorresponding author: J. Hannink, julius.hannink@fau.de\nfirst two require a laboratory environment and are limited in availability, the latter is mobile and inexpensive. This renders mobile, sensor-based solutions the primary choice for unobtrusive gait analysis systems.\nChoosing this modality though introduces a conflict between the abstract variables of measurement and the readout parameters requested by the users and is as such entangled with the physical constraints in wearable sensing: For instrumented medical healthcare applications, one might be able to measure accelerations and angular rates at a patient\u2019s foot using stateof-the-art inertial sensors. However, the treating physician is not interested in interpreting acceleration signatures for a given stride but rather wants to monitor variables directly related to the situation as for example stride length or heel-strike angle. The efficient translation of abstract data to context-related knowledge thus is the underlying challenge in all applications of wearable sensors and mobile healthcare technologies.\nIn the extraction of stride parameters, this challenge is addressed from several perspectives. The majority of methods are based on physical and geometric reasoning to extract spatial gait parameters using double-integration of inertial sensor signals ([6]\u2013[9], [12]). The main limitation regarding this type of approach is the dependency on a zero-velocity phase within each stride that is needed to re-initialize the integration process. In clinical practice, however, this assumption is easily violated [13]. Other approaches aim at driving bio-mechanical models of the lower extremity with sensor data ([10], [11]) or apply machine learning approaches in order to extract the parameters of interest [13].\nThe underlying problem of efficient data to knowledge translation is recently being addressed very successfully in the field of image understanding. Here, data from images is identified to belong to a certain object class [14], translated to captions that describe the image content [15] or used to identify persons based on face recognition [16]. All these applications represent ground-breaking advances in their respective field in terms of recognition rates. The common underlying methodology that allows these achievements is a branch of machine learning called deep learning.\nDue to its success in other domains, deep learning is starting to appear in the context of wearable sensing and computing to extract meaningful information from sensor data ([13], [17]\u2013 [20]). This particular branch of machine learning is said to have large potential in mobile sensing and computing regarding inference accuracy, robustness or class-scaling which are partly missing from state-of-the-art [21]. Applications of deep learning in wearable sensing and computing are, however, largely focussing on activity recognition ([17]\u2013[20]). To the authors\u2019 best knowledge, this and their prior work [13] are\nar X\niv :1\n60 9.\n03 32\n3v 3\n[ cs\n.L G\n] 1\n3 Ja\nn 20\n17\n2 the first applications regarding other topics in the field. In this work, we present a framework based on deep convolutional neural networks and aim at translating the abstract information provided by wearable sensors to context-related expert features requested by the users. The system is trained on a regression task between sensor data and a set of reference output parameters. Thereby, it extends the authors\u2019 prior work [13] that only addresses a single output parameter. A prerequisite for this is a knowledge base, i.e. a collection of wearable sensor data captured in a controlled environment and annotated with the help of a reference system that can directly measure the expert features of interest.\nWe apply the proposed framework in the context of mobile gait analysis as illustrated in Fig. 1. In doing so, we focus specifically on the extraction of biomechanical stride parameters with convolutional neural network regression while potential benefits from deep learning approaches to other parts of the pipeline (e.g. segmentation) might be addressed in future work. A total of eight exemplary and stride-specific characteristics are extracted that are clinically relevant as they define gait quality. To this end, two different modelling approaches are compared: A combined model that uses one network architecture to estimate all expert features of interest and an ensemble approach where one neural network is spawned for each output parameter individually. Both models are trained and evaluated on a publicly available and clinically relevant benchmark dataset.\nIn summary, our main contributions are: (1) A generalisable method for data-driven and integration-free extraction of spatio-temporal gait characteristics, and (2) Technical validation of the proposed method on a clinically relevant and publicly available dataset.\nII. Methods"}, {"heading": "A. Data Collection and Setup", "text": "We use a benchmark dataset collected by Rampp et al. [7] that is publicly available at https://www5.cs.fau. de/activitynet/benchmark-datasets/digital-biobank/ and briefly described here.\nThe inertial sensor platform Shimmer2R [22] consisting of a 3d-accelerometer (range \u00b16 g) and a 3d-gyroscope (range \u00b1500 \u25e6/s) was used for data collection. It was attached laterally below each ankle joint (Fig. 2). In order to avoid gait changes due to different shoe characteristics [23], the same shoe model (adidas Duramo 3) was used by all subjects. Data was captured at 102.4 Hz at a resolution of 12 bit. Simultaneously, validation data was acquired with the well established pressure mat GAITRite with a spatial resolution of \u00b11.27 cm [3].\nIn total, 116 geriatric inpatients were assessed at the Geriatrics Centre Erlangen (Waldkrankenhaus St. Marien, Erlangen, Germany). Written informed consent was obtained prior to the gait assessment in accordance with the ethical committee of the medical faculty at Friedrich-Alexander University Erlangen-N\u00fcrnberg (Re.-No. 4208).\nFor our study, the annotation on the dataset was extended with additional parameters compared to the annotation reported on by Rampp et al. [7]. This was based on positions and timings of the patients\u2019 heel and toe as measured by the GAITRite reference system. The spatial parameter set was enlarged to cover not only stride length, but also stride width and change in medio-lateral foot angle. Additionally, heel and toe contact times were added to the list of temporal parameters stride, stance and swing time. Fig. 3 gives an overview on the definitions of temporal and spatial parameters. Stride width was defined as shown in Fig. 3 b) and positive values were measured towards the lateral side of the shoe.\nPatients performed an extensive geriatric assessment, described by Rampp et al. [7] in detail. For the scope of this paper, we focused on the free walking test over the GAITRite mat at comfortable walking speed instrumented with the inertial sensors. After excluding datasets from eight patients due to medical reasons (i.e. patients could not complete the measurement protocol), two due to inertial sensor\n3\nmalfunction and additional seven due to measurement errors with the GAITRite system, 99 patients were left for training and evaluation of the proposed method. Compared to Rampp et al. [7], reference values for heel and toe contact times could not be computed for two patients.\nGait disorders or fall proneness were diagnosed in 54% of the study population. The other top three diagnoses were heart rhythm disorder (70%), arterial hypertension (69%) and coronary artery disease (41%), which are also associated with gait and balance disorders [24]. In summary, this dataset constitutes a clinically relevant study population both in terms of the number of patients and the presence of unpredictable gait alterations.\nTABLE I gives an overview on the extended set of reference parameters on the dataset and their mean value, standard deviation, as well as their minimal/maximal values."}, {"heading": "B. Preprocessing", "text": "Before the inertial sensor data is fed to the convolutional neural network, we perform a series of preprocessing steps. The segmentation step mentioned in the overview Fig. 1 is already provided by the dataset in our case. Preprocessing therefore includes extraction of annotated strides from the continuous recordings, calibration from raw sensor readings to physical units, coordinate system transformations to align sensor axes on left and right feet, normalisation w.r.t. sensor ranges and padding to fixed length of 256 samples per stride to ensure fixed size input to the network.\nThe system is trained on data segments from heel-strike to heel-strike (HS). This choice of stride definition is beneficial since it does not assume a zero-velocity phase that stateof-the-art double-integration approaches need to re-initialize the integration process. In clinical practice, this assumption is\neasily violated as e.g. in the case of spastic gait impairments. However, initial ground contact can still be detected for e.g. spastic gait patterns and provides a valid segmentation of the signal into strides. This is the type of scenario that we intend to address with stride segments defined from HS\u2192HS.\nIn order to provide this kind of input data, we need to detect HS and toe-off (TO) events in the stride segmentation provided by the dataset and adjust the stride borders accordingly. Detection of HS and TO events within the sensor data is done according to Rampp et al. [7]. An exemplary input signal for one stride defined from HS\u2192HS is shown in Fig. 4.\nFurthermore, we can directly compute three expert-features from the list in TABLE I based on the HS and TO events in the datastream. Stride time is defined as the HS\u2192HS distance and given a TO event, we can subdivide each stride into its two phases and compute stance and swing time (see Fig. 3 a) or Rampp et al. [7]). This leaves a set of five output parameters to be estimated by the deep convolutional neural networks."}, {"heading": "C. Network Architectures", "text": "The network architectures used here are based on three elementary building blocks: Convolutional, max-pooling and densely connected layers.\nA convolutional connection between layers is defined by a set of Ni kernels \u03c81 . . . \u03c8Ni of length Li and biases b1 . . . bNi . The index i thereby represents a label for the layer at hand. Given a multi-channeled input vector x j with j = 1...Ni\u22121, the activation or output of the convolutional connection is\n4\ncomputed as\nak = ReLU \u2211 j \u03c8k, j \u2217 x j + bk  (1) with k = 1 . . .Ni. We used a rectifying linear unit (ReLU) as the activation function for this type of connection as this nonlinearity is said to model biological neurons better compared to tangent or sigmoid functions [25].\nConvolutional layers are often followed by max-pooling layers to increase robustness of the extracted features [26]. This type of connection downsamples the feature maps obtained by the convolutional connection by taking the maximum in temporal windows of length r. The downsampling factor is thus 1/r.\nThe third type of connection used here is the densely connected layer. This type of connection is defined by a set of weight vectors W1 . . .WNi and biases b1 . . . bNi . Given a singlechannel input vector x, the activation of the densely connected layer is computed by matrix-multiplication as\na j = ReLU \u2211 i Wi, j xi + b j  (2) with j = 1 . . .Ni. In case the output of the previous layer is a multi-channelled vector, the single-channel input vector x is constructed by concatenation of the individual channels i.e. flattening. Again, we use a rectifying linear unit for activation.\nFinally, a readout layer compresses the last dense layer to the number of output variables for the task at hand. The\nreadout layer is identical to a densely connected layer with the identity instead of the ReLU as an activation function. The number of output variables is then encoded in the number of weight vectors for this layer.\nBased on these elementary blocks, two models are built: \u2022 Model A: Estimating the complete set of output variables\nwith a combined model (Fig. 5, left). \u2022 Model B: Estimating each output variable individually\nwith an ensemble of networks (Fig. 5, right). Consequently, the individual network architectures in model B can be less complex compared to model A in order to achieve comparable model complexities.\nRegarding the application of data to knowledge translation in the context of mobile gait analysis, we decide for a network architecture built from three convolutional layers with maxpooling followed by three densely connected layers and a readout layer for model A. In the convolutional layers we train N1 = 32, N2 = 64 and N3 = 128 kernels of size 30, 15 and 7 samples respectively as well as the corresponding number of bias terms. Max-pooling is done in non-overlapping, temporal windows of size r = 2 samples. Given the sampling frequency, the kernel size corresponds to approximately 0.29 s on all three layers. The three densely connected layers are trained with N4 = 2048, N5 = 1024 and N6 = 512 weight vectors and bias terms respectively. The readout layer has Noutput = 5 nodes for model A.\nFor model B, the individual network architectures are built from two convolutional layers with N1 = 16 and N2 = 32\n5 filters of size 30 and 15 samples respectively and one densely connected layer with N3 = 1024 nodes. The max-pooling layers are identical to model A with a downsampling factor of 1/2. The readout layer, however, has only Noutput = 1 node as each individual architecture is responsible for one of the output parameters. Fig. 5 gives an overview on the network architectures used in both models.\nThe theoretical motivation for this choice is to address the most crucial question in network design of global vs. individual modelling with two representative cases. In model A, we only distinguish between different kinds of output parameters at the last level of the network. The features extracted in this architecture therefore have to be general enough to capture information about all of the output parameters. In model B, however, each output parameter has its own feature extraction path that can be optimized to the parameter at hand."}, {"heading": "D. Training", "text": "Training of neural networks is viewed as an optimization problem regarding an error function (implicitly) depending on the network parameters. This error defines a discrepancy measure between predicted output and a ground truth reference on the training dataset or subsets thereof. Weights and biases on all layers are then changed using back-propagation and with the aim to minimize the error. In practice, however, only random subsets of the training dataset (mini-batches), are shown to the optimizer in one iteration of the training loop to speed up the learning phase (stochastic learning) [27].\nBecause of the different numeric ranges and physical units in the output parameters (see TABLE I), the network is trained to estimate normalized and dimensionless output variables y\u0302i. Therefore, each reference yi,ref is scaled to the range [0, 1] using the minimum/maximum value attained on the entire training set Strain:\ny\u0302i,ref = yi,ref \u2212minStrain yi,ref\nmaxStrain yi,ref \u2212minStrain yi,ref (3)\nPredictions on the test set are later rescaled to their physical dimensions using the scaling parameters from the training set.\nGiven predictions y\u0302i on a mini-batch of size Nbatch for each output variable i = 1 . . .Noutput, we define the error as the sum of the individual root-mean-square errors on the mini-batch:\nE = \u2211\ni\nrmsq ( y\u0302i \u2212 y\u0302i,ref ) (4)\nFor optimization, we use Adam [28], a state-of-the-art optimization method for stochastic learning. On benchmark datasets, it shows faster convergence than other stochastic optimization routines and we use default settings of \u03b1 = 1e\u22123, \u03b21 = 0.9, \u03b22 = 0.999 and = 1e\u22128 (for details see [28]). All weights are initialized by sampling a truncated normal distribution with standard deviation 0.01 and biases are initially set to 0.01. We train for a fixed number of 4000 iterations with a mini-batch size of Nbatch = 100 strides.\nTo prevent over-fitting, dropout is used on the densely connected layers. This technique effectively samples a large\nnumber of thinned architectures on the hidden layers by randomly dropping nodes during training. With this, overfitting could be significantly reduced in many use-cases and was superior to weight-regularisation methods [29]. We use fixed dropout probabilities of p(4) = 0.75, p(5) = 0.5 and p(6) = 0.0 for model A. For the individual architectures in model B, a dropout probability of p(3) = 0.5 is used. Every connection thus has a 50% chance of being inactive. During testing, however, the full architectures are used and no connections are dropped.\nThe networks are implemented and trained using google\u2019s TensorFlow library [30]."}, {"heading": "E. Evaluation Scheme", "text": "Evaluation of the two modelling approaches is based on a 10-fold cross validation scheme. The stride-specific sensor data from 99 patients on the dataset are sorted into training and test partitions depending on the patient identifier to ensure distinct splits of the dataset. For each of the two models, we iterate over the complete dataset in this fashion and estimate the output variables on the test set in each fold. The estimates from individual folds are then pooled to arrive at average statistics for each output variable and model. As an evaluation statistic, we use average accuracy \u00b1 precision which correspond to the mean and standard deviation of the signed error distribution. The two models are compared based on this statistic and a Levene test of equal variances between the respective distributions to check whether precisions differ significantly. Because the error distributions for the parameter heel contact time are slightly non-gaussian (checked by visual inspection of q-q plots), a Levene test is preferred over e.g. a Bartlett test that is less robust against non-normality.\nIn order to assess the learning speed and performance of model A and B, we compute the training error for each of the models over the training iterations for an exemplary and patient-wise 90/10% train/test split of the dataset.\nIII. Results"}, {"heading": "A. Training", "text": "Fig. 6 shows the error evaluated on the entire training set over the iterations for an exemplary 90/10% train/test split of the dataset. The error is evaluated for model A and for each of the submodels that constitute model B. In all cases, the fixed number of 4000 iterations is sufficient to reach a stable regime of the error on the entire training dataset and hence we stop the training. Furthermore, the adaptation of the two models to the training data is comparable w.r.t. the selected error function as E1...5 \u2248 0.02 in model B corresponds to a total/summed error of E \u2248 0.1 for model A (Fig 6)."}, {"heading": "B. Stride Parameter Estimation on Unseen Data", "text": "TABLE II lists average accuracy and precision on the unseen test data achieved by the two models w.r.t. the pooled estimates from each cross-validation fold. The ensemble approach B that spawns one convolutional neural network for each output variable reaches significantly better precision regarding stride\n6 TABLE II Comparison of model A and B regarding average accuracy and precision reached on unseen test data. To compare average precisions, a Levene-test was\nperformed on the respective error distributions at the 0.01 significance level.\nStride length Stride width Foot angle Heel contact time Toe contact time\nModel A \u22120.34 \u00b1 8.10 cm 0.41 \u00b1 7.79 cm \u22120.05 \u00b1 3.59 \u25e6 \u22120.00 \u00b1 0.08 s \u22120.00 \u00b1 0.12 s Model B \u22120.15 \u00b1 6.09 cm \u22120.09 \u00b1 4.22 cm 0.13 \u00b1 3.78 \u25e6 0.00 \u00b1 0.07 s 0.00 \u00b1 0.12 s Levene-test sign. sign. n.s. n.s. n.s.\n0.0\n0.2\n0.4\n0.6\n0.8\n1.0\nE rr\nor E\nModel A: All combined\n0 500 1000 1500 2000 2500 3000 3500 4000\nTraining iterations\n0.00 0.02 0.04 0.06 0.08 0.10 0.12 0.14 E rr or E\nModel B: Stride length Model B: Stride width Model B: Foot angle Model B: Heel contact time Model B: Toe contact time\nFig. 6. Error E evaluated on the entire training set as a function of the training iterations for model A, all submodels that constitute model B and an exemplary 90/10% split of the dataset.\nlength and width while the corresponding mean accuracies also exceed those achieved by model A. On the remaining three parameters foot angle, heel and toe contact time, both models perform similarly. Therefore, we consider the ensemble approach B to be superior in this context.\nDetailed results for all output parameters on the dataset and the superior model B can be found in Fig. 7 and TABLE III.\nFig. 7 includes Bland-Altman plots for each of the output variables as estimated by model B as well as the achieved mean accuracy and precision. TABLE III lists the error statistics for each output parameter as well as state-of-the-art results.\nIV. Discussion\nWe present a method for data to knowledge translation in the context of sensor-based gait analysis to extract a total of 8 spatio-temporal stride characteristics. Within the proposed framework, we compare two different approaches in the case of vectorial knowledge: A) A combined modelling approach estimating the complete set of output parameters and B) An ensemble approach where individual, less complex models are spawned for each output parameter. The resulting model complexities are thereby designed to be of similar magnitude. With the superior ensemble approach B, the spatial parameters stride length, stride width and foot angle are estimated with mean accuracy and precision of \u22120.15\u00b16.09 cm, \u22120.09\u00b14.22 cm and 0.13 \u00b1 3.78\u25e6 respectively. The temporal stride characteristics stride, swing and stance time are predicted with average precision of \u00b10.07, \u00b10.05 and \u00b10.07 s respectively. Additionally, the heel and toe contact times are determined up to \u00b10.07 and \u00b10.12 s respectively. Thereby, we provide\ntechnical validation on a clinically relevant dataset containing 1185 individual strides from 99 geriatric patients. The estimation of stride length is outperforming the doubleintegration result by Rampp et al. [7] by 2.3 cm (27%, statistically significant) in precision. Compared to the deep learning approach presented by Hannink et al. [13] which estimates this parameter up to \u22120.27 \u00b1 5.43 cm based on\n7\nHS\u2192HS strides, our results are slightly worse. This might be due to reduced network complexity in the model presented here (Hannink et al. [13] use twice as much kernels and biases on each of the two convolutional layers) or the fact that the underlying datasets are not completely identical (101 vs. 99 patients here due to technical reasons). Regarding results on other datasets, Ferrari et al. [8] report a measurement error of \u22120.16 \u00b1 7.02 cm for the parameter stride length based on double-integration and a dataset of 1314 strides captured from ten elderly PD patients. Trojaniello et al. even reach an average accuracy and precision of 0.1 \u00b1 1.9 cm and thereby almost resolve their reference precision of \u00b11.3 cm [9]. However, this result is only evaluated on a small dataset of 532 strides from 10 elderly PD patients and points out the limits of this comparison: The results achieved have to be seen as a function of the variability across subjects captured in the evaluation dataset. A different evaluation dataset does not necessarily ensure a fair comparison of methods. And it shows the need for a unified evaluation of stride length estimation methods presented here and in the literature ([7]\u2013[9], [13]) on the same, large cohort study as e.g. the publicly available dataset described by Rampp et al. [7].\nRegarding stride width, there is little related work. Horak et al. [31] even consider it \"difficult to obtain with body-worn sensors\". Nevertheless, Rebula et al. [12] report an intraclass correlation coefficient (ICC) of 0.88 between a motion-capture reference and a sensor-based estimation of stride width. Our result corresponds to an ICC of 0.95 and is thus outperforming state-of-the-art double-integration methods w.r.t. stride width.\nMariani et al. [6] determine the foot or turning angle up to 0.12 \u00b1 3.59\u25e6 on data from 10 elderly subjects and a study protocol that included a 180\u25e6 turn as opposed to our straight walking data. In this respect, our results are comparable.\nFor the parameters stride, stance and swing time, our results are identical to Rampp et al. [7] due to identical methods. Estimation of heel and toe contact times has not been reported in literature to the best of the authors\u2019 knowledge. Sabatini et al. [32] propose detection of heel-off and toe-on/foot-flat events by thresholding the angular velocity in the sagittal plane. However, this approach is rather heuristic and the precision regarding these events was not evaluated. Thus, our\nresult constitutes the state-of-the-art regarding sensor-based estimation of heel and toe contact times.\nBased on these contact times and HS/TO events that are detectable with state-of-the-art methods, the current work enables detection of heel-off and toe-on events (Fig. 3) that don\u2019t manifest that clearly in the sensor signals. Thereby, each gait cycle can be further sub-divided into loading response, mid-stance phase, terminal stance and pre-swing as defined by Perry et al. [33] and their dependency on disease state or speed could be evaluated in future work. The latter would extend the work by Hebenstreit et al. [34] that was based on motion capture data to a mobile setting.\nThe entire processing pipeline presented in the current work is based on stride segments defined from heel-strike to heel-strike and therefore independent of the zero-velocity assumption. In everyday clinical practice and the presence of impaired gait, this assumption is easily violated and limits applicability of state-of-the-art double-integration approaches [13]. However, there are no theoretical considerations that prohibit application of the proposed method to populations experiencing severe gait disturbances as in the case of spasticity. Thereby, the proposed system is a suitable substitute for the assumption-governed double-integration techniques and could enable mobile gait analysis in these clinically critical cases.\nThe main limitation of the proposed method is that the resulting data to knowledge translation is as good as the knowledge base. This is because the knowledge base is used to learn the non-linear relationship between the input sensor data and the output parameters and this mapping implicitly depends on the samples collected in the knowledge base. We thus strongly stress the importance of sharing benchmark datasets within the community and create larger, communitymaintained knowledge bases.\nThe implementation of the framework is generalisable and flexible. Information from other wearable sensing modalities (e.g. barometric pressure) can be introduced by adding additional channels to the input signal. Application to other data to knowledge translation problems in this field can be done by exchanging the knowledge base. TensorFlow [30] generically supports model quantisation and lower level arithmetics that are needed for inference with deep convolutional neural net-\n8 works on mobile devices. Although this is not a necessity in mobile gait analysis, where the emphasis lies on the mobility of the sensing technology, it might be needed in future work.\nFuture work includes the application of the proposed framework to other data to knowledge translation problems and thereby the establishment of a generally applicable system. In this respect, especially the end of training needs to be addressed in a data-adaptive manner. As this work did not include a rigorous exploration of the parameter space (number and dimensionality of kernels, etc.), this part is left for future work. In the context of mobile gait analysis, individualisation or domain adaptations aspects as well as sequential modelling approaches that account for across-stride context will be investigated. Additionally, the aforementioned benchmark-evaluation of several biomechanical parameter estimation methods for a fair comparison of methods will be covered in future work.\nV. Acknowledgements\nThis work was supported by the FAU Emerging Fields Initiative (EFIMoves). The authors would like to thank Samuel Sch\u00fclein and Jens Barth for their effort in compiling the benchmark dataset as well as all participants of the study for their contributions.\nReferences\n[1] T. Ellis, J. T. Cavanaugh, G. M. Earhart, M. P. Ford, K. B. Foreman et al., \u201cWhich measures of physical function and motor impairment best predict quality of life in Parkinson\u2019s disease?\u201d Parkinsonism and Related Disorders, vol. 17, no. 9, pp. 693\u2013697, 2011. [2] U. Givon, G. Zeilig, and A. Achiron, \u201cGait analysis in multiple sclerosis: characterization of temporal-spatial parameters using GAITRite functional ambulation system.\u201d Gait & Posture, vol. 29, no. 1, pp. 138\u2013 42, 2009. [3] K. E. Webster, J. E. Wittwer, and J. a. Feller, \u201cValidity of the GAITRite R\u00a9 walkway system for the measurement of averaged and individual step parameters of gait,\u201d Gait & Posture, vol. 22, no. 4, pp. 317\u2013321, 2005. [4] R. W. Kressig, R. J. Gregor, A. Oliver, D. Waddell, W. Smith et al., \u201cTemporal and spatial features of gait in older adults transitioning to frailty.\u201d Gait & Posture, vol. 20, no. 1, pp. 30\u20135, Aug. 2004. [5] J. Klucken, J. Barth, P. Kugler, J. Schlachetzki, T. Henze et al., \u201cUnbiased and Mobile Gait Analysis Detects Motor Impairment in Parkinson\u2019s Disease,\u201d PLoS ONE, vol. 8, no. 2, 2013. [6] B. Mariani, M. C. Jim\u00e9nez, F. J. G. Vingerhoets, and K. Aminian, \u201cOnshoe wearable sensors for gait and turning assessment of patients with parkinson\u2019s disease,\u201d IEEE Transactions on Biomedical Engineering, vol. 60, no. 1, pp. 155\u2013158, 2013. [7] A. Rampp, J. Barth, S. Sch\u00fclein, K.-G. Ga\u00dfmann, J. Klucken et al., \u201cInertial Sensor Based Stride Parameter Calculation from Gait Sequences in Geriatric Patients.\u201d IEEE Transactions on Biomedical Engineering, vol. 62, no. 4, pp. 1089\u20131097, 2014. [8] A. Ferrari, P. Ginis, M. Hardegger, F. Casamassima, L. Rocchi et al., \u201cA Mobile Kalman-Filter Based Solution for the Real-Time Estimation of Spatio-Temporal Gait Parameters,\u201d IEEE Transactions on Neural Systems and Rehabilitation Engineering, no. 99, 2015. [9] D. Trojaniello, A. Cereatti, E. Pelosin, L. Avanzino, A. Mirelman et al., \u201cEstimation of step-by-step spatio-temporal parameters of normal and impaired gait using shank-mounted magneto-inertial sensors: application to elderly, hemiparetic, parkinsonian and choreic gait,\u201d Journal of Neuroengineering and Rehabilitation, vol. 11, no. 1, p. 152, 2014. [10] K. Aminian, B. Najafi, C. B\u00fcla, P. F. Leyvraz, and P. Robert, \u201cSpatiotemporal parameters of gait measured by an ambulatory system using miniature gyroscopes,\u201d Journal of Biomechanics, vol. 35, no. 5, pp. 689\u2013 699, 2002. [11] A. Salarian, P. R. Burkhard, B. M. Jolles, and K. Aminian, \u201cA Novel Approach to Reducing Number of Sensing Units for Wearable Gait Analysis Systems,\u201d IEEE Transactions on Biomedical Engineering, vol. 60, no. 1, pp. 72\u201377, 2013.\n[12] J. R. Rebula, L. V. Ojeda, P. G. Adamczyk, and A. D. Kuo, \u201cMeasurement of foot placement and its variability with inertial sensors.\u201d Gait & Posture, vol. 38, no. 4, pp. 974\u201380, Sep. 2013. [13] J. Hannink, T. Kautz, C. F. Pasluosta, J. Barth, S. Sch\u00fclein et al., \u201cStride Length Estimation with Deep Learning,\u201d IEEE Transactions on Neural Systems and Rehabilitation, 2016, submitted. [14] K. He, X. Zhang, S. Ren, and J. Sun, \u201cDeep Residual Learning for Image Recognition,\u201d arXiv preprint, 2015, https://arxiv.org/abs/1512.03385. [15] O. Vinyals, A. Toshev, S. Bengio, and D. Erhan, \u201cShow and Tell: A Neural Image Caption Generator,\u201d in The IEEE Conference on Computer Vision and Pattern Recognition (CVPR), 2015. [16] Y. Taigman;, M. Yang;, M. Ranzato, and L. Wolf, \u201cDeepFace: Closing the Gap to Human-Level Performance in Face Verification,\u201d in The IEEE Conference on Computer Vision and Pattern Recognition (CVPR), 2014. [17] N. Y. Hammerla, J. M. Fisher, P. Andras, L. Rochester, R. Walker et al., \u201cPD Disease State Assessment in Naturalistic Environments using Deep Learning,\u201d in Conference on Innovative Applications of Artificial Intelligence, 2015. [18] N. Y. Hammerla, S. Halloran, and T. Ploetz, \u201cDeep, Convolutional, and Recurrent Models for Human Activity Recognition using Wearables,\u201d arXiv, 2016, http://arxiv.org/abs/1604.08880. [19] F. J. Ord\u00f3\u00f1ez and D. Roggen, \u201cDeep convolutional and LSTM recurrent neural networks for multimodal wearable activity recognition,\u201d Sensors, vol. 16, no. 1, 2016. [20] Y. Zheng, Q. Liu, E. Chen, Y. Ge, and J. L. Zhao, \u201cTime series classification using multi-channels deep convolutional neural networks,\u201d in Lecture Notes in Computer Science, vol. 8485, 2014, pp. 298\u2013310. [21] N. D. Lane and P. Georgiev, \u201cCan Deep Learning Revolutionize Mobile Sensing?\u201d Proceedings of the 16th International Workshop on Mobile Computing Systems and Applications - HotMobile \u201915, pp. 117\u2013122, 2015. [22] A. Burns, B. R. Greene, M. J. McGrath, T. J. O\u2019Shea, B. Kuris et al., \u201cSHIMMERTM \u2013 A wireless sensor platform for noninvasive biomedical research,\u201d Sensors, vol. 10, no. 9, pp. 1527\u20131534, 2010. [23] J. C. Menant, J. R. Steele, H. B. Menz, B. J. Munro, and S. R. Lord, \u201cEffects of walking surfaces and footwear on temporo-spatial gait parameters in young and older people.\u201d Gait & Posture, vol. 29, no. 3, pp. 392\u20137, Apr. 2009. [24] B. Salzman, \u201cGait and Balance Disorders in Older Adults,\u201d American Family Physician, vol. 82, no. 1, pp. 61\u201368, 2010. [25] X. Glorot, A. Bordes, and Y. Bengio, \u201cDeep Sparse Rectifier Neural Networks,\u201d AISTATS, vol. 15, pp. 315\u2013323, 2011. [26] Y. Boureau, J. Ponce, and Y. LeCun, \u201cA theoretical analysis of feature pooling in visual recognition,\u201d in Proc. of the 27th International Conference on Machine Learning (ICML-10), 2010, pp. 111\u2013118. [27] I. Goodfellow, Y. Bengio, and A. Courville, \u201cDeep learning,\u201d 2016, book in preparation for MIT Press, available at http://www.deeplearningbook. org. [28] D. P. Kingma and J. L. Ba, \u201cAdam: a Method for Stochastic Optimization,\u201d International Conference on Learning Representations, pp. 1\u201313, 2015. [29] N. Srivastava, G. Hinton, A. Krizhevsky, I. Sutskever, and R. Salakhutdinov, \u201cDropout : A Simple Way to Prevent Neural Networks from Overfitting,\u201d Journal of Machine Learning Research, vol. 15, pp. 1929\u2013 1958, 2014. [30] M. Abadi, A. Agarwal, P. Barham, E. Brevdo, Z. Chen et al., \u201cTensorFlow: Large-scale machine learning on heterogeneous systems,\u201d 2015, software available at https://tensorflow.org. [31] F. B. Horak and M. Mancini, \u201cObjective biomarkers of balance and gait for Parkinson\u2019s disease using body-worn sensors,\u201d Movement Disorders, vol. 28, no. 11, pp. 1544\u20131551, 2013. [32] A. M. Sabatini, \u201cQuaternion-based strap-down integration method for applications of inertial sensing to gait analysis,\u201d Medical and Biological Engineering and Computing, vol. 43, no. 1, pp. 94\u2013101, 2005. [33] J. Perry, J. M. Burnfield, and L. M. Cabico, Gait Analysis: Normal and Pathological Function. Slack Thorofare, NJ, 1992, vol. 12. [34] F. Hebenstreit, A. Leibold, S. Krinner, G. Welsch, M. Lochmann et al., \u201cEffect of walking speed on gait sub phase durations,\u201d Human Movement Science, vol. 43, pp. 118\u2013124, 2015."}], "references": [{"title": "Gait analysis in multiple sclerosis: characterization of temporal-spatial parameters using GAITRite functional ambulation system.", "author": ["U. Givon", "G. Zeilig", "A. Achiron"], "venue": "Gait & Posture,", "citeRegEx": "2", "shortCiteRegEx": "2", "year": 2009}, {"title": "Validity of the GAITRite R  \u00a9 walkway system for the measurement of averaged and individual step parameters of gait", "author": ["K.E. Webster", "J.E. Wittwer", "J. a. Feller"], "venue": "Gait & Posture, vol. 22, no. 4, pp. 317\u2013321, 2005.", "citeRegEx": "3", "shortCiteRegEx": null, "year": 2005}, {"title": "Temporal and spatial features of gait in older adults transitioning to frailty.", "author": ["R.W. Kressig", "R.J. Gregor", "A. Oliver", "D. Waddell", "W. Smith"], "venue": "Gait & Posture,", "citeRegEx": "4", "shortCiteRegEx": "4", "year": 2004}, {"title": "Unbiased and Mobile Gait Analysis Detects Motor Impairment in Parkinson\u2019s Disease", "author": ["J. Klucken", "J. Barth", "P. Kugler", "J. Schlachetzki", "T. Henze"], "venue": "PLoS ONE, vol. 8, no. 2, 2013.", "citeRegEx": "5", "shortCiteRegEx": null, "year": 2013}, {"title": "Onshoe wearable sensors for gait and turning assessment of patients with parkinson\u2019s disease", "author": ["B. Mariani", "M.C. Jim\u00e9nez", "F.J.G. Vingerhoets", "K. Aminian"], "venue": "IEEE Transactions on Biomedical Engineering, vol. 60, no. 1, pp. 155\u2013158, 2013.", "citeRegEx": "6", "shortCiteRegEx": null, "year": 2013}, {"title": "Inertial Sensor Based Stride Parameter Calculation from Gait Sequences in Geriatric Patients.", "author": ["A. Rampp", "J. Barth", "S. Sch\u00fclein", "K.-G. Ga\u00dfmann", "J. Klucken"], "venue": "IEEE Transactions on Biomedical Engineering,", "citeRegEx": "7", "shortCiteRegEx": "7", "year": 2014}, {"title": "A Mobile Kalman-Filter Based Solution for the Real-Time Estimation of Spatio-Temporal Gait Parameters", "author": ["A. Ferrari", "P. Ginis", "M. Hardegger", "F. Casamassima", "L. Rocchi"], "venue": "IEEE Transactions on Neural Systems and Rehabilitation Engineering, no. 99, 2015.", "citeRegEx": "8", "shortCiteRegEx": null, "year": 2015}, {"title": "Estimation of step-by-step spatio-temporal parameters of normal and impaired gait using shank-mounted magneto-inertial sensors: application to elderly, hemiparetic, parkinsonian and choreic gait", "author": ["D. Trojaniello", "A. Cereatti", "E. Pelosin", "L. Avanzino", "A. Mirelman"], "venue": "Journal of Neuroengineering and Rehabilitation, vol. 11, no. 1, p. 152, 2014.", "citeRegEx": "9", "shortCiteRegEx": null, "year": 2014}, {"title": "Spatiotemporal parameters of gait measured by an ambulatory system using miniature gyroscopes", "author": ["K. Aminian", "B. Najafi", "C. B\u00fcla", "P.F. Leyvraz", "P. Robert"], "venue": "Journal of Biomechanics, vol. 35, no. 5, pp. 689\u2013 699, 2002.", "citeRegEx": "10", "shortCiteRegEx": null, "year": 2002}, {"title": "A Novel Approach to Reducing Number of Sensing Units for Wearable Gait Analysis Systems", "author": ["A. Salarian", "P.R. Burkhard", "B.M. Jolles", "K. Aminian"], "venue": "IEEE Transactions on Biomedical Engineering, vol. 60, no. 1, pp. 72\u201377, 2013.", "citeRegEx": "11", "shortCiteRegEx": null, "year": 2013}, {"title": "Measurement of foot placement and its variability with inertial sensors.", "author": ["J.R. Rebula", "L.V. Ojeda", "P.G. Adamczyk", "A.D. Kuo"], "venue": "Gait & Posture,", "citeRegEx": "12", "shortCiteRegEx": "12", "year": 2013}, {"title": "Stride Length Estimation with Deep Learning", "author": ["J. Hannink", "T. Kautz", "C.F. Pasluosta", "J. Barth", "S. Sch\u00fclein"], "venue": "IEEE Transactions on Neural Systems and Rehabilitation, 2016, submitted.", "citeRegEx": "13", "shortCiteRegEx": null, "year": 2016}, {"title": "Deep Residual Learning for Image Recognition", "author": ["K. He", "X. Zhang", "S. Ren", "J. Sun"], "venue": "arXiv preprint, 2015, https://arxiv.org/abs/1512.03385.", "citeRegEx": "14", "shortCiteRegEx": null, "year": 2015}, {"title": "Show and Tell: A Neural Image Caption Generator", "author": ["O. Vinyals", "A. Toshev", "S. Bengio", "D. Erhan"], "venue": "The IEEE Conference on Computer Vision and Pattern Recognition (CVPR), 2015.", "citeRegEx": "15", "shortCiteRegEx": null, "year": 2015}, {"title": "DeepFace: Closing the Gap to Human-Level Performance in Face Verification", "author": ["Y. Taigman", "M. Yang", "M. Ranzato,", "L. Wolf"], "venue": "The IEEE Conference on Computer Vision and Pattern Recognition (CVPR), 2014.", "citeRegEx": "16", "shortCiteRegEx": null, "year": 2014}, {"title": "PD Disease State Assessment in Naturalistic Environments using Deep Learning", "author": ["N.Y. Hammerla", "J.M. Fisher", "P. Andras", "L. Rochester", "R. Walker"], "venue": "Conference on Innovative Applications of Artificial Intelligence, 2015.", "citeRegEx": "17", "shortCiteRegEx": null, "year": 2015}, {"title": "Deep, Convolutional, and Recurrent Models for Human Activity Recognition using Wearables", "author": ["N.Y. Hammerla", "S. Halloran", "T. Ploetz"], "venue": "arXiv, 2016, http://arxiv.org/abs/1604.08880.", "citeRegEx": "18", "shortCiteRegEx": null, "year": 2016}, {"title": "Deep convolutional and LSTM recurrent neural networks for multimodal wearable activity recognition", "author": ["F.J. Ord\u00f3\u00f1ez", "D. Roggen"], "venue": "Sensors, vol. 16, no. 1, 2016.", "citeRegEx": "19", "shortCiteRegEx": null, "year": 2016}, {"title": "Time series classification using multi-channels deep convolutional neural networks", "author": ["Y. Zheng", "Q. Liu", "E. Chen", "Y. Ge", "J.L. Zhao"], "venue": "Lecture Notes in Computer Science, vol. 8485, 2014, pp. 298\u2013310.", "citeRegEx": "20", "shortCiteRegEx": null, "year": 2014}, {"title": "Can Deep Learning Revolutionize Mobile Sensing?", "author": ["N.D. Lane", "P. Georgiev"], "venue": "Proceedings of the 16th International Workshop on Mobile Computing Systems and Applications - HotMobile", "citeRegEx": "21", "shortCiteRegEx": "21", "year": 2015}, {"title": "SHIMMERTM \u2013 A wireless sensor platform for noninvasive biomedical research", "author": ["A. Burns", "B.R. Greene", "M.J. McGrath", "T.J. O\u2019Shea", "B. Kuris"], "venue": "Sensors, vol. 10, no. 9, pp. 1527\u20131534, 2010.", "citeRegEx": "22", "shortCiteRegEx": null, "year": 2010}, {"title": "Effects of walking surfaces and footwear on temporo-spatial gait parameters in young and older people.", "author": ["J.C. Menant", "J.R. Steele", "H.B. Menz", "B.J. Munro", "S.R. Lord"], "venue": "Gait & Posture,", "citeRegEx": "23", "shortCiteRegEx": "23", "year": 2009}, {"title": "Gait and Balance Disorders in Older Adults", "author": ["B. Salzman"], "venue": "American Family Physician, vol. 82, no. 1, pp. 61\u201368, 2010.", "citeRegEx": "24", "shortCiteRegEx": null, "year": 2010}, {"title": "Deep Sparse Rectifier Neural Networks", "author": ["X. Glorot", "A. Bordes", "Y. Bengio"], "venue": "AISTATS, vol. 15, pp. 315\u2013323, 2011.", "citeRegEx": "25", "shortCiteRegEx": null, "year": 2011}, {"title": "A theoretical analysis of feature pooling in visual recognition", "author": ["Y. Boureau", "J. Ponce", "Y. LeCun"], "venue": "Proc. of the 27th International Conference on Machine Learning (ICML-10), 2010, pp. 111\u2013118.", "citeRegEx": "26", "shortCiteRegEx": null, "year": 2010}, {"title": "Deep learning", "author": ["I. Goodfellow", "Y. Bengio", "A. Courville"], "venue": "2016, book in preparation for MIT Press, available at http://www.deeplearningbook. org.", "citeRegEx": "27", "shortCiteRegEx": null, "year": 2016}, {"title": "Adam: a Method for Stochastic Optimization", "author": ["D.P. Kingma", "J.L. Ba"], "venue": "International Conference on Learning Representations, pp. 1\u201313, 2015.", "citeRegEx": "28", "shortCiteRegEx": null, "year": 2015}, {"title": "Dropout : A Simple Way to Prevent Neural Networks from Overfitting", "author": ["N. Srivastava", "G. Hinton", "A. Krizhevsky", "I. Sutskever", "R. Salakhutdinov"], "venue": "Journal of Machine Learning Research, vol. 15, pp. 1929\u2013 1958, 2014.", "citeRegEx": "29", "shortCiteRegEx": null, "year": 1929}, {"title": "Tensor- Flow: Large-scale machine learning on heterogeneous systems", "author": ["M. Abadi", "A. Agarwal", "P. Barham", "E. Brevdo", "Z. Chen"], "venue": "2015, software available at https://tensorflow.org.", "citeRegEx": "30", "shortCiteRegEx": null, "year": 2015}, {"title": "Objective biomarkers of balance and gait for Parkinson\u2019s disease using body-worn sensors", "author": ["F.B. Horak", "M. Mancini"], "venue": "Movement Disorders, vol. 28, no. 11, pp. 1544\u20131551, 2013.", "citeRegEx": "31", "shortCiteRegEx": null, "year": 2013}, {"title": "Quaternion-based strap-down integration method for applications of inertial sensing to gait analysis", "author": ["A.M. Sabatini"], "venue": "Medical and Biological Engineering and Computing, vol. 43, no. 1, pp. 94\u2013101, 2005.", "citeRegEx": "32", "shortCiteRegEx": null, "year": 2005}, {"title": "Cabico, Gait Analysis: Normal and Pathological Function", "author": ["J. Perry", "J.M. Burnfield", "L. M"], "venue": "Slack Thorofare, NJ,", "citeRegEx": "33", "shortCiteRegEx": "33", "year": 1992}, {"title": "Effect of walking speed on gait sub phase durations", "author": ["F. Hebenstreit", "A. Leibold", "S. Krinner", "G. Welsch", "M. Lochmann"], "venue": "Human Movement Science, vol. 43, pp. 118\u2013124, 2015.", "citeRegEx": "34", "shortCiteRegEx": null, "year": 2015}], "referenceMentions": [{"referenceID": 0, "context": "These parameters are commonly extracted with the help of several electronic measurement systems including computerised pressure mats ([2], [3]), optical motion-capture systems [4] or mobile, sensor-based solutions ([5]\u2013[11]).", "startOffset": 134, "endOffset": 137}, {"referenceID": 1, "context": "These parameters are commonly extracted with the help of several electronic measurement systems including computerised pressure mats ([2], [3]), optical motion-capture systems [4] or mobile, sensor-based solutions ([5]\u2013[11]).", "startOffset": 139, "endOffset": 142}, {"referenceID": 2, "context": "These parameters are commonly extracted with the help of several electronic measurement systems including computerised pressure mats ([2], [3]), optical motion-capture systems [4] or mobile, sensor-based solutions ([5]\u2013[11]).", "startOffset": 176, "endOffset": 179}, {"referenceID": 3, "context": "These parameters are commonly extracted with the help of several electronic measurement systems including computerised pressure mats ([2], [3]), optical motion-capture systems [4] or mobile, sensor-based solutions ([5]\u2013[11]).", "startOffset": 215, "endOffset": 218}, {"referenceID": 9, "context": "These parameters are commonly extracted with the help of several electronic measurement systems including computerised pressure mats ([2], [3]), optical motion-capture systems [4] or mobile, sensor-based solutions ([5]\u2013[11]).", "startOffset": 219, "endOffset": 223}, {"referenceID": 4, "context": "The majority of methods are based on physical and geometric reasoning to extract spatial gait parameters using double-integration of inertial sensor signals ([6]\u2013[9], [12]).", "startOffset": 158, "endOffset": 161}, {"referenceID": 7, "context": "The majority of methods are based on physical and geometric reasoning to extract spatial gait parameters using double-integration of inertial sensor signals ([6]\u2013[9], [12]).", "startOffset": 162, "endOffset": 165}, {"referenceID": 10, "context": "The majority of methods are based on physical and geometric reasoning to extract spatial gait parameters using double-integration of inertial sensor signals ([6]\u2013[9], [12]).", "startOffset": 167, "endOffset": 171}, {"referenceID": 11, "context": "In clinical practice, however, this assumption is easily violated [13].", "startOffset": 66, "endOffset": 70}, {"referenceID": 8, "context": "Other approaches aim at driving bio-mechanical models of the lower extremity with sensor data ([10], [11]) or apply machine learning approaches in order to extract the parameters of interest [13].", "startOffset": 95, "endOffset": 99}, {"referenceID": 9, "context": "Other approaches aim at driving bio-mechanical models of the lower extremity with sensor data ([10], [11]) or apply machine learning approaches in order to extract the parameters of interest [13].", "startOffset": 101, "endOffset": 105}, {"referenceID": 11, "context": "Other approaches aim at driving bio-mechanical models of the lower extremity with sensor data ([10], [11]) or apply machine learning approaches in order to extract the parameters of interest [13].", "startOffset": 191, "endOffset": 195}, {"referenceID": 12, "context": "to belong to a certain object class [14], translated to captions that describe the image content [15] or used to identify persons based on face recognition [16].", "startOffset": 36, "endOffset": 40}, {"referenceID": 13, "context": "to belong to a certain object class [14], translated to captions that describe the image content [15] or used to identify persons based on face recognition [16].", "startOffset": 97, "endOffset": 101}, {"referenceID": 14, "context": "to belong to a certain object class [14], translated to captions that describe the image content [15] or used to identify persons based on face recognition [16].", "startOffset": 156, "endOffset": 160}, {"referenceID": 11, "context": "Due to its success in other domains, deep learning is starting to appear in the context of wearable sensing and computing to extract meaningful information from sensor data ([13], [17]\u2013 [20]).", "startOffset": 174, "endOffset": 178}, {"referenceID": 15, "context": "Due to its success in other domains, deep learning is starting to appear in the context of wearable sensing and computing to extract meaningful information from sensor data ([13], [17]\u2013 [20]).", "startOffset": 180, "endOffset": 184}, {"referenceID": 18, "context": "Due to its success in other domains, deep learning is starting to appear in the context of wearable sensing and computing to extract meaningful information from sensor data ([13], [17]\u2013 [20]).", "startOffset": 186, "endOffset": 190}, {"referenceID": 19, "context": "have large potential in mobile sensing and computing regarding inference accuracy, robustness or class-scaling which are partly missing from state-of-the-art [21].", "startOffset": 158, "endOffset": 162}, {"referenceID": 15, "context": "Applications of deep learning in wearable sensing and computing are, however, largely focussing on activity recognition ([17]\u2013[20]).", "startOffset": 121, "endOffset": 125}, {"referenceID": 18, "context": "Applications of deep learning in wearable sensing and computing are, however, largely focussing on activity recognition ([17]\u2013[20]).", "startOffset": 126, "endOffset": 130}, {"referenceID": 11, "context": "To the authors\u2019 best knowledge, this and their prior work [13] are ar X iv :1 60 9.", "startOffset": 58, "endOffset": 62}, {"referenceID": 11, "context": "Thereby, it extends the authors\u2019 prior work [13] that only addresses a single output parameter.", "startOffset": 44, "endOffset": 48}, {"referenceID": 5, "context": "[7] that is publicly available at https://www5.", "startOffset": 0, "endOffset": 3}, {"referenceID": 20, "context": "The inertial sensor platform Shimmer2R [22] consisting of a 3d-accelerometer (range \u00b16 g) and a 3d-gyroscope (range \u00b1500 \u25e6/s) was used for data collection.", "startOffset": 39, "endOffset": 43}, {"referenceID": 21, "context": "In order to avoid gait changes due to different shoe characteristics [23], the same shoe model (adidas Duramo 3) was used by all subjects.", "startOffset": 69, "endOffset": 73}, {"referenceID": 1, "context": "27 cm [3].", "startOffset": 6, "endOffset": 9}, {"referenceID": 5, "context": "[7].", "startOffset": 0, "endOffset": 3}, {"referenceID": 5, "context": "[7] in detail.", "startOffset": 0, "endOffset": 3}, {"referenceID": 5, "context": "[7], reference values for heel and toe contact times could not be computed for two patients.", "startOffset": 0, "endOffset": 3}, {"referenceID": 22, "context": "The other top three diagnoses were heart rhythm disorder (70%), arterial hypertension (69%) and coronary artery disease (41%), which are also associated with gait and balance disorders [24].", "startOffset": 185, "endOffset": 189}, {"referenceID": 5, "context": "[7].", "startOffset": 0, "endOffset": 3}, {"referenceID": 5, "context": "[7]).", "startOffset": 0, "endOffset": 3}, {"referenceID": 23, "context": "We used a rectifying linear unit (ReLU) as the activation function for this type of connection as this nonlinearity is said to model biological neurons better compared to tangent or sigmoid functions [25].", "startOffset": 200, "endOffset": 204}, {"referenceID": 24, "context": "Convolutional layers are often followed by max-pooling layers to increase robustness of the extracted features [26].", "startOffset": 111, "endOffset": 115}, {"referenceID": 25, "context": "In practice, however, only random subsets of the training dataset (mini-batches), are shown to the optimizer in one iteration of the training loop to speed up the learning phase (stochastic learning) [27].", "startOffset": 200, "endOffset": 204}, {"referenceID": 26, "context": "For optimization, we use Adam [28], a state-of-the-art optimization method for stochastic learning.", "startOffset": 30, "endOffset": 34}, {"referenceID": 26, "context": "999 and = 1e\u22128 (for details see [28]).", "startOffset": 32, "endOffset": 36}, {"referenceID": 27, "context": "With this, overfitting could be significantly reduced in many use-cases and was superior to weight-regularisation methods [29].", "startOffset": 122, "endOffset": 126}, {"referenceID": 28, "context": "The networks are implemented and trained using google\u2019s TensorFlow library [30].", "startOffset": 75, "endOffset": 79}, {"referenceID": 5, "context": "[7] by 2.", "startOffset": 0, "endOffset": 3}, {"referenceID": 11, "context": "[13] which estimates this parameter up to \u22120.", "startOffset": 0, "endOffset": 4}, {"referenceID": 5, "context": "37 [7] -0.", "startOffset": 3, "endOffset": 6}, {"referenceID": 6, "context": "02 [8],\u2217 0.", "startOffset": 3, "endOffset": 6}, {"referenceID": 7, "context": "90 [9],\u2217 Stride width cm \u22121.", "startOffset": 3, "endOffset": 6}, {"referenceID": 4, "context": "59 [6],\u2217", "startOffset": 3, "endOffset": 6}, {"referenceID": 5, "context": "07[7]", "startOffset": 2, "endOffset": 5}, {"referenceID": 5, "context": "05[7]", "startOffset": 2, "endOffset": 5}, {"referenceID": 5, "context": "07[7] Model B: n = 99 geriatric patients and 1185 individual strides; \u2217 different evaluation dataset", "startOffset": 2, "endOffset": 5}, {"referenceID": 11, "context": "[13] use twice as much kernels and biases on each of the two convolutional layers) or the fact that the underlying datasets are not completely identical (101 vs.", "startOffset": 0, "endOffset": 4}, {"referenceID": 6, "context": "[8] report a measurement error of \u22120.", "startOffset": 0, "endOffset": 3}, {"referenceID": 7, "context": "3 cm [9].", "startOffset": 5, "endOffset": 8}, {"referenceID": 5, "context": "And it shows the need for a unified evaluation of stride length estimation methods presented here and in the literature ([7]\u2013[9], [13]) on the same, large cohort study as e.", "startOffset": 121, "endOffset": 124}, {"referenceID": 7, "context": "And it shows the need for a unified evaluation of stride length estimation methods presented here and in the literature ([7]\u2013[9], [13]) on the same, large cohort study as e.", "startOffset": 125, "endOffset": 128}, {"referenceID": 11, "context": "And it shows the need for a unified evaluation of stride length estimation methods presented here and in the literature ([7]\u2013[9], [13]) on the same, large cohort study as e.", "startOffset": 130, "endOffset": 134}, {"referenceID": 5, "context": "[7].", "startOffset": 0, "endOffset": 3}, {"referenceID": 29, "context": "[31] even consider it \"difficult to obtain with body-worn sensors\".", "startOffset": 0, "endOffset": 4}, {"referenceID": 10, "context": "[12] report an intraclass correlation coefficient (ICC) of 0.", "startOffset": 0, "endOffset": 4}, {"referenceID": 4, "context": "[6] determine the foot or turning angle up to 0.", "startOffset": 0, "endOffset": 3}, {"referenceID": 5, "context": "[7] due to identical methods.", "startOffset": 0, "endOffset": 3}, {"referenceID": 30, "context": "[32] propose detection of heel-off and toe-on/foot-flat events by thresholding the angular velocity in the sagittal plane.", "startOffset": 0, "endOffset": 4}, {"referenceID": 31, "context": "[33] and their dependency on disease state or speed could be evaluated in future work.", "startOffset": 0, "endOffset": 4}, {"referenceID": 32, "context": "[34] that was based on motion capture data to a mobile setting.", "startOffset": 0, "endOffset": 4}, {"referenceID": 11, "context": "In everyday clinical practice and the presence of impaired gait, this assumption is easily violated and limits applicability of state-of-the-art double-integration approaches [13].", "startOffset": 175, "endOffset": 179}, {"referenceID": 28, "context": "TensorFlow [30] generically supports model quantisation and lower level arithmetics that are needed for inference with deep convolutional neural net-", "startOffset": 11, "endOffset": 15}], "year": 2017, "abstractText": "Measurement of stride-related, biomechanical parameters is the common rationale for objective gait impairment scoring. State-of-the-art double integration approaches to extract these parameters from inertial sensor data are, however, limited in their clinical applicability due to the underlying assumptions. To overcome this, we present a method to translate the abstract information provided by wearable sensors to context-related expert features based on deep convolutional neural networks. Regarding mobile gait analysis, this enables integration-free and data-driven extraction of a set of eight spatio-temporal stride parameters. To this end, two modelling approaches are compared: A combined network estimating all parameters of interest and an ensemble approach that spawns less complex networks for each parameter individually. The ensemble approach is outperforming the combined modelling in the current application. On a clinically relevant and publicly available benchmark dataset, we estimate stride length, width and medio-lateral change in foot angle up to \u22120.15 \u00b1 6.09 cm, \u22120.09\u00b14.22 cm and 0.13\u00b13.78\u25e6 respectively. Stride, swing and stance time as well as heel and toe contact times are estimated up to \u00b10.07, \u00b10.05, \u00b10.07, \u00b10.07 and \u00b10.12 s respectively. This is comparable to and in parts outperforming or defining stateof-the-art. Our results further indicate that the proposed change in methodology could substitute assumption-driven doubleintegration methods and enable mobile assessment of spatiotemporal stride parameters in clinically critical situations as e.g. in the case of spastic gait impairments.", "creator": "LaTeX with hyperref package"}}}