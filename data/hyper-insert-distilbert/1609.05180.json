{"id": "1609.05180", "review": {"conference": "arxiv", "VERSION": "v1", "DATE_OF_SUBMISSION": "16-Sep-2016", "title": "Grammatical Templates: Improving Text Difficulty Evaluation for Language Learners", "abstract": "language quality students are most engaged while simultaneously reading functional texts at some an appropriate difficulty level. however, besides existing methods of independently evaluating minimum text difficulty focus mainly on functional vocabulary training and do especially not prioritize grammatical features, hence they \u2019 don't work well for language learners with seemingly limited knowledge support of relevant grammar. success in defending this paper, notably we introduce complementary grammatical reference templates, while the expert - specifically identified synthetic units of grammar markers that students learn from class, perceived as an extra important feature of text difficulty evaluation. experimental developmental classification results show that grammatical template features sufficiently significantly improve text : difficulty prediction accuracy further over baseline readability features by 7. 54 4 %. \u00bb moreover, annually we build a simple and human - understandable text difficulty evaluation process approach with minimum 87. 95 7 % measurement accuracy, using this only ~ 5 natural grammatical template indicator features.", "histories": [["v1", "Fri, 16 Sep 2016 19:12:30 GMT  (234kb,D)", "http://arxiv.org/abs/1609.05180v1", null], ["v2", "Wed, 15 Feb 2017 22:04:47 GMT  (206kb,D)", "http://arxiv.org/abs/1609.05180v2", null]], "reviews": [], "SUBJECTS": "cs.CL cs.AI", "authors": ["shuhan wang", "erik", "ersen"], "accepted": false, "id": "1609.05180"}, "pdf": {"name": "1609.05180.pdf", "metadata": {"source": "CRF", "title": "Grammatical Templates: Improving Text Difficulty Evaluation for Language Learners", "authors": ["Shuhan Wang"], "emails": ["forsona@cs.cornell.edu", "eland@cs.cornell.edu"], "sections": [{"heading": null, "text": "Keywords text difficulty evaluation, grammatical templates, language learners"}, {"heading": "1 Introduction", "text": "Evaluating text difficulty, or text readability, is an important topic in natural language processing and applied linguistics (Zamanian and Heydari, 2012; Pitler and Nenkova, 2008; Fulcher, 1997). A key challenge of text difficulty evaluation is that linguistic difficulty arises from both vocabulary and grammar (Richards and Schmidt, 2013). However, most existing tools either do not sufficiently take the impact of grammatical difficulty into account (Smith III et al., 2014; Renaissance Learning, 2016; Sheehan et al., 2014), or use traditional syntactic features, which differ from what language students actually learn, to estimate grammatical complexity (Schwarm and Ostendorf, 2005; Heilman et al., 2008). In fact, language courses introduce grammar constructs together with vocabulary, and grammar constructs vary in frequency and difficulty just like vocabulary (Blyth, 1997; Manzanares and Lo\u0301pez, 2008; Waara, 2004). Ideally, we would like to have better ways of estimating the grammatical complexity of a sentence.\nTo make progress in this direction, we introduce grammatical templates as an important feature in text difficulty evaluation. These templates are what language teachers and linguists have identified as the most important units of grammatical understanding at different levels. We present results from Japanese language placement tests and textbooks showing that adding grammatical template features into existing readability features significantly improves difficulty level classification accuracy by 7.4%. We also propose a multilevel linear classification algorithm using only 5 grammatical features. We demonstrate that this simple and human-understandable algorithm effectively predicts the difficulty level of Japanese texts with 87.7% accuracy.\nThis paper is under review at EMNLP\u201916. We will withdraw other submissions if this paper is accepted by COLING\u201916.\nar X\niv :1\n60 9.\n05 18\n0v 1\n[ cs\n.C L\n] 1\n6 Se\np 20\n16"}, {"heading": "2 Related Work", "text": "Text difficulty evaluation has been widely studied over the past few decades (Nelson et al., 2012; Sinha et al., 2012; Hancke et al., 2012; Jameel et al., 2012; Gonzalez-Dios et al., 2014; Sinha et al., 2014). Researchers have developed over 200 metrics of text difficulty (Collins-Thompson and Callan, 2004). For example, Lexile measures text complexity and readability with word frequency and sentence length (Smith III et al., 2014). ATOS includes two formulas for texts and books, both of which take into account three variables to predict text difficulty: word length, word grade level and sentence length (Renaissance Learning, 2016). TextEvaluator is a comprehensive text analysis system desinged to help teachers and test developers evaluate the complexity characteristics of reading materials (Sheehan et al., 2014). It incorporates more vocabulary features, such as meaning and word type, as well as some sentence and paragraph-level features.\nNevertheless, most of these methods provide limited consideration of grammatical difficulty, which is a major challenge for foreign language learners (Callan and Eskenazi, 2007). In fact, text readability not only depends on sentence lengths or word counts, but \u2018the grammatical complexity of the language used\u2019 as well (Richards and Schmidt, 2013). Based on this fact, recent readability evaluation systems improved performance by incorporating syntactic features like parse tree depth (Schwarm and Ostendorf, 2005) and subtree patterns (Heilman et al., 2008) to measure grammatical complexity. However, these syntactic features differ from the grammatical knowledge that students actually learn in language lessons (Blyth, 1997; Manzanares and Lo\u0301pez, 2008; Waara, 2004). Instead, we extract grammatical features from grammatical templates, the knowledge units that expert language instructors identified and highlighted in textbooks.\nAdditionally, researchers have developed an unified framework of text readability evaluation, which combines lexical, syntactic and discourse features, and predicts readability with outstanding accuracy (Pitler and Nenkova, 2008). The relationship between text readability and reading devices was also studied in the past two years (Kim et al., 2014). However, both of these approaches are intended for native speakers and use texts from daily news or economic journals, which are too hard to read for beginning and intermediate language learners. Language education researchers attempted to utilize these native-speaker-oriented techniques, which measure text difficulty based on traditional vocabulary and syntactic features, to predict text difficulty levels for Portuguese language learners (Curto et al., 2015). Unfortunately, the result of 75% accuracy in 5-level classification with 52 features is not satisfactory. We propose a novel technique that has a simpler and human-interpretable structure, uses only 5 grammatical template features, and predicts text difficulty with 87.7% accuracy in 5-level classification."}, {"heading": "3 Grammatical Template Analysis", "text": "A key challenge in modeling text difficulty is to specify all prerequisite knowledge required for understanding a certain sentence. Traditional methods measure text difficulty mostly by evaluating the complexity of vocabulary (word count, word frequency, word type, etc.). This is effective for native speakers, who typically understand the grammar of their language but vary in mastery of vocabulary. However, these vocabulary-based methods underperform for language learners who have limited knowledge of grammar (Callan and Eskenazi, 2007; Curto et al., 2015).\nTo resolve this, we focus our research on grammatical difficulty. We introduce the idea of grammatical templates, units of grammar that expert language instructors and linguists have identified as the most important grammatical knowledge, and are typically emphasized as key points in every textbook lesson (Banno et al., 2011; People\u2019s Education Press, 2013). Since these grammatical templates are taught explicitly in language lessons and learned directly by language students, we believe they reflect the conceptual units of grammar more closely than parse trees.\nGrammatical templates play an important role in language understanding because:\n\u2022 Many grammatical templates suggest sentence structure. For example, \u201chardly ... when ...\u201d in English, \u201cnicht nur ..., sondern auch ...\u201d (not only ... but also ...) in German, and \u201c\u5fc5\u305a\u3057\u3082 ... \u3068 \u306f\u3044\u3048\u306a\u3044\u201d (it is not necessarily the case that ...) in Japanese;\n\u2022 For languages like Chinese and Japanese, lacking knowledge of some grammatical templates will cause difficulties in segmentation. For example, consider the Japanese template \u201c...\u3064...\u3064\u201d (two opposite behaviors occuring alternately) in the phrase \u201c\u884c\u304d\u3064\u623b\u308a\u3064\u201d (to walk back and forth), and the Chinese template \u201c\u8d8a...\u8d8a\u597d\u201d (the more ... the better) in \u201c\u8d8a\u65e9\u8d8a\u597d\u201d(the earlier the better);\n\u2022 Some grammatical templates may refer to special meanings that cannot be understood as the combination of individual words. For example, \u201cin terms of\u201d, \u201csuch that\u201d in English, \u201cmit etwas zu tun haben\u201d (have something to do with ...) in German, and \u201c... \u3053\u3068\u306f\u306a\u3044\u201d (no need to ...) in Japanese.\nWe show some simple examples of grammatical templates for Japanese in Table 11. Line 2 shows the pronunciation of the templates, and the uppercase letters in line 3 are provided for notation. We also provide examples of how the grammar of a sentence can be described as combinations of these grammatical templates in Table 2."}, {"heading": "3.1 Difficulty Evaluation Standard", "text": "To evaluate the difficulty of texts and grammatical templates, we follow the standard of the JapaneseLanguage Proficiency Test (JLPT). The JLPT is the most widely used test for measuring proficiency of non-native speakers, with approximately 610,000 examinees in 62 countries and areas worldwide in 20112. It has five different levels, ranging from from N5 (beginner) to N1 (advanced). A summary of the levels can be found at JLPT website 3."}, {"heading": "3.2 Grammatical Template Library", "text": "Due to their significance in Japanese education, grammatical templates are well-studied by Japanese teachers and researches. Grammatical templates are summarized and collected for both Japanese learners (common templates) and native speakers (templates used in very formal Japanese or old Japanese). We referenced 3 books about grammatical templates for Japanese learners (Sasaki and Kiko, 2010; Xu and Reika, 2015; Liu and Ebihara, 2012), all of which divide their templates into N1-N5 levels, for generating our template library at each corresponding level.\nAlthough not common, books may have different opinions on the difficulty of the same template. For example, an N1 template in book A may be recognized as an N2 template in book B. In order to conduct\n1A long list of Japanese grammatical templates with English translations can be accessed at (JGram, 2016). There is also a nice and comprehensive book of Japanese grammatical templates, written by Japanese linguists, with English, Korean and Chinese translations: (Tomomatsu Etsuko and Masako, 2010).\n2http://www.jlpt.jp/e/about/message.html 3http://www.jlpt.jp/e/about/levelsummary.html\nAlgorithm 1 Grammatical Progression Extraction Require: A dependency-based parse tree of the sentence Ensure: T(node0) = set of identified grammatical templates in (sub)parse tree rooted at note0.\n1: if node0 is leaf node then 2: return T(node0) = {} 3: end if 4: node1, node2, \u00b7 \u00b7 \u00b7 \u2190 children of node0 5: Calculate: T(node1),T(node1), \u00b7 \u00b7 \u00b7 // templates identified in subtrees rooted at node0\u2019s children 6: T1(node0)\u2190 T(node1) \u222aT(node2) \u222a \u00b7 \u00b7 \u00b7 7: T2(node0)\u2190 identified templates in phrase [node1, node2, \u00b7 \u00b7 \u00b7 ] 8: return T(node0) = T1(node0) \u222aT2(node0)\nour experiments on a reliable template library, we only pick the templates recognized as the same level by at least two of the three books. For example, if both book A and C recognized template t as an N3 template, we can incorporate template t into our N3 template library. Ultimately, we collected 147 N1 templates, 122 N2 templates, 74 N3 templates, 95 N4 templates and 128 N5 templates in our library. All selected grammatical templates are stored in the format of regular expressions for easy matching in parse trees."}, {"heading": "3.3 Grammatical Template Extraction", "text": "The framework of grammatical template extraction is shown in Algorithm 1. The program requires the dependency-based parse tree of a sentence as input, runs from bottom to top and returns a set of all identified grammatical templates T(node0). Line 7 extracts the templates in the children of node0 (and ignores the descendants of the children), by matching the phrase associated with the child nodes [node1, node2, \u00b7 \u00b7 \u00b7 ] to all templates stored in terms of regular expressions in our library. The matching is based on both the structure of the phrases and the properties of the words. Line 8 shows T(node0) covers all templates identified in subtrees rooted at node0\u2019s children and the templates extracted in the phrase associated with the child nodes [node1, node2, \u00b7 \u00b7 \u00b7 ].\nThe third row of Table 2 shows the sample results (set of grammatical templates) of Algorithm 1. We use Cabocha (Kudo and Matsumoto, 2002) for parsing Japanese sentences. This tool generates the hierarchical structure of the sentence as well as some properties (e.g. base form, pronunciation, part of speech, etc.) of each word. We execute Algorithm 1 on the parse tree to extract all identified templates of a Japanese sentence."}, {"heading": "4 Statistics of Grammatical Templates", "text": ""}, {"heading": "4.1 Corpus", "text": "We build our corpus from two sources: past JLPT exams and textbooks. The reading texts from JLPT exams are ideal for difficulty evaluation experiments since all of them are tagged authoritatively with\ndifficulty levels, and JLPT problem sets before 2010 are publicly released4. We also collected reading texts from two popular series of Japanese textbooks: Standard Japanese (People\u2019s Education Press, 2013) and Genki (Banno et al., 2011). Standard Japanese I and Genki I are designed for the N5 level (the first semester) and Standard Japanese II and Genki II are designed for the N4 level (the second semester). Ultimately, our corpus consists of 220 texts (150 from past JLPT exams and 70 from textbooks), totaling 167,292 words after segmentation."}, {"heading": "4.2 Results", "text": "For texts with different difficulties, we calculate the distribution of N1-N5 grammatical templates, which are shown in Table 3. We can see that N1 texts have higher portion of N1 and N2 templates than N2 texts, implying that the difficulty boosts from N2 to N1 are derived from increasing usage of advanced grammar. It is also clear that even in the texts of advanced levels, the majority of the sentences are organized by elementary grammatical templates, and the advanced ones are only used occasionally for formality or preciseness.\nWe also calculate the per-100-sentence number of templates at each level, which are shown in Table 4. When comparing any two adjacent levels (e.g. N2 and N3), the templates at those levels or above seem to be the most significant. For instance, N1/N2 texts differ in numbers of N1 and N2 templates while they have similar numbers of N3-N5 templates, and the numbers of N1, N2 and N3 templates differentiate the N2/N3 texts while the numbers of N4 and N5 templates seem relatively similar. This phenomenon inspires us to build a simple and effective approach to differentiate the texts of two adjacent levels.\n4For example, the second exam in 2009 is published in (Japan Educational Exchanges et al., 2010)."}, {"heading": "5 Difficulty Level Prediction", "text": ""}, {"heading": "5.1 Multilevel Linear Classification", "text": "We differentiate two adjacent levels by looking at the knowledge \u2018on the boundary\u2019 and \u2018outside the boundary\u2019. Concretely, when judging whether a text is harder than level Ni, we consider a grammatical template as:\n\u2022 within the boundary, if the template is easier than Ni (Ni+1 to N5);\n\u2022 on the boundary, if the template is exactly at Ni level;\n\u2022 outside the boundary, if the template is harder than Ni (N1 to Ni\u22121).\nWe found that texts of adjacent levels are nearly linear-separable with two features: templates \u2018on the boundary\u2019 and templates \u2018outside the boundary\u2019. For example, Figure 1 shows how N1 and N2 texts are linearly separated based on the numbers of N1 and N2 templates: we can easily obtain a two-dimensional linear classifier separating N1 and N2 texts with 83.4% accuracy. This phenomenon is even more obvious at lower levels. Figure 2 shows N4 and N5 texts are almost perfectly linearly separated with two features: \u2018number of N5 templates per 100 sentences\u2019 (on the boundary) and \u2018number of N1-N4 templates per 100 sentences\u2019 (outside the boundary).\nTaking advantage of this phenomenon, we build 4 linear classifiers for 4 pairs of adjacent levels. For example, the N4 classifier judges whether a text is harder than N4 (N1-N3). Our Multilevel Linear Classification (MLC) algorithm combines all 4 linear classifiers: A text is judged by the N5 classifier first. If it is no harder than N5, it will be labeled as an N5 text; otherwise, it will be passed to the N4 classifier in order to decide if it is harder than N4. The process continues similarly, until if it is judged to be harder than N2, it will be labeled as an N1 text. Figure 3 shows how the algorithm works."}, {"heading": "5.2 Features", "text": "We conduct our experiments on the following 4 feature sets:\nFirst, our grammatical template feature set has only 5 features:\n\u2022 Average number of N1-N5 grammatical templates per sentence\nWe compare our work with recent readability evaluation studies (Kim et al., 2014; Pitler and Nenkova, 2008). In our experiments, the baseline readability feature set consists of the following 12 features:\n\u2022 Number of words in a text \u2022 Number of sentences in a text \u2022 Average number of words per sentence \u2022 Average parse tree depths per sentence \u2022 Average number of noun phrases per sentence \u2022 Average number of verb phrases per sentence \u2022 Average number of pronouns per sentence \u2022 Average number of clauses per sentence \u2022 Average cosine similarity between adjacent sentences \u2022 Average word overlap between adjacent sentences \u2022 Average word overlap over noun and pronoun only \u2022 Article likelihood estimated by language model\nMoreover, we combine these 12 traditional readability features with our 5 grammatical template features, forming a \u2018hybrid\u2019 feature set, since we would like to see if grammatical template features are really able to improve text difficulty evaluation.\nSince the text difficulty level prediction can be regarded as a special text classification problem, we also extract TF-IDF features (Sparck Jones, 1972) (Nelson et al., 2012) as an extra baseline, in order to see how general text classification techniques work on text difficulty evaluation."}, {"heading": "5.3 Result", "text": "We test k-Nearest Neighbor and Support Vector Machines (Joachims, 1998) for each feature set. The implementations of these two popular classification algorithms are provided by the WEKA toolkit (Hall et al., 2009) and LibSVM (Chang and Lin, 2011). The SVMs use RBF kernels (Chang et al., 2010). We also test our Multilevel Linear Classification (MLC) algorithm on the grammatical template feature set. We use 5-fold cross validation to avoid overfitting. Table 5 shows the results.\nComparing the results of kNN and SVM across the four different feature sets in Table 5, it is clear that TF-IDF features have the largest feature set yet lowest accuracy, indicating the general word-based text classification techniques do not work well on text difficulty level prediction. Compared with baseline readability features, our grammatical template features have smaller number of features but higher accuracy (slightly higher with SVM but significantly higher with kNN). Moreover, the hybrid features, which combine baseline readability features with grammatical template features, decisively outperform baseline readability features, confirming our expectation that adding grammatical template features to existing readability techniques improves text difficulty evaluation for language learners.\nAdditionally, our Multilevel Linear Classification algorithm achieves excellent accuracy with only 5 grammatical template features. An accuracy of 87.7% , although slightly lower than hybrid features + SVM (more features, more complexity), still significantly outperforms baseline readability techniques. In conclusion, the Multlevel Linear Classification algorithm has high accuracy, a small number of features, and a simple, human-understandable structure."}, {"heading": "6 Conclusion", "text": "We proposed a new way of evaluating text difficulty which focuses on grammar and utilizes expertidentified grammatical templates, and significantly improved the accuracy of text difficulty evaluation for Japanese language learning. We also introduced a simple, human-understandable and effective text difficulty evaluation approach using only five grammatical template features.\nIn future work, we are interested in extending our work to other languages like English, and adapting grammatical templates for native speakers of various languages. We also plan to develop a machine learning system that could discover discriminative grammatical templates from proficiency-rated text. Finally, we hope to use our approach to recommend reading texts to individual learners at an appropriate difficulty level."}, {"heading": "Acknowledgements", "text": ""}], "references": [{"title": "GENKI: An Integrated Course in Elementary Japanese", "author": ["Banno et al.2011] Eri Banno", "Yoko Ikeda", "Yutaka Ohno"], "venue": "Japan Times and Tsai Fong Books", "citeRegEx": "Banno et al\\.,? \\Q2011\\E", "shortCiteRegEx": "Banno et al\\.", "year": 2011}, {"title": "A constructivist approach to grammar: Teaching teachers to teach aspect", "author": ["Carl Blyth"], "venue": "The Modern Language Journal,", "citeRegEx": "Blyth.,? \\Q1997\\E", "shortCiteRegEx": "Blyth.", "year": 1997}, {"title": "Combining lexical and grammatical features to improve readability measures for first and second language texts", "author": ["Callan", "Eskenazi2007] Jamie Callan", "Maxine Eskenazi"], "venue": "In Proceedings of NAACL HLT,", "citeRegEx": "Callan et al\\.,? \\Q2007\\E", "shortCiteRegEx": "Callan et al\\.", "year": 2007}, {"title": "Libsvm: a library for support vector machines", "author": ["Chang", "Lin2011] Chih-Chung Chang", "Chih-Jen Lin"], "venue": "ACM Transactions on Intelligent Systems and Technology (TIST),", "citeRegEx": "Chang et al\\.,? \\Q2011\\E", "shortCiteRegEx": "Chang et al\\.", "year": 2011}, {"title": "Training and testing low-degree polynomial data mappings via linear svm", "author": ["Chang et al.2010] Yin-Wen Chang", "Cho-Jui Hsieh", "Kai-Wei Chang", "Michael Ringgaard", "Chih-Jen Lin"], "venue": "The Journal of Machine Learning Research,", "citeRegEx": "Chang et al\\.,? \\Q2010\\E", "shortCiteRegEx": "Chang et al\\.", "year": 2010}, {"title": "A language modeling approach to predicting reading difficulty", "author": ["Collins-Thompson", "James P Callan"], "venue": "In HLT-NAACL,", "citeRegEx": "Collins.Thompson et al\\.,? \\Q2004\\E", "shortCiteRegEx": "Collins.Thompson et al\\.", "year": 2004}, {"title": "Assisting european portuguese teaching: Linguistic features extraction and automatic readability classifier", "author": ["Curto et al.2015] Pedro Curto", "Nuno Mamede", "Jorge Baptista"], "venue": "In Computer Supported Education,", "citeRegEx": "Curto et al\\.,? \\Q2015\\E", "shortCiteRegEx": "Curto et al\\.", "year": 2015}, {"title": "Text difficulty and accessibility: Reading formulae and expert judgement", "author": ["Glenn Fulcher"], "venue": null, "citeRegEx": "Fulcher.,? \\Q1997\\E", "shortCiteRegEx": "Fulcher.", "year": 1997}, {"title": "Simple or complex? assessing the readability of basque texts", "author": ["Mar\u0131\u0301a Jes\u00fas Aranzabe", "Arantza D\u0131\u0301az de Ilarraza", "Haritz Salaberri"], "venue": "In Proceedings of COLING 2014, the 25th International Conference on Computational Linguistics: Technical Papers,", "citeRegEx": "Gonzalez.Dios et al\\.,? \\Q2014\\E", "shortCiteRegEx": "Gonzalez.Dios et al\\.", "year": 2014}, {"title": "The weka data mining software: an update", "author": ["Hall et al.2009] Mark Hall", "Eibe Frank", "Geoffrey Holmes", "Bernhard Pfahringer", "Peter Reutemann", "Ian H Witten"], "venue": "ACM SIGKDD explorations newsletter,", "citeRegEx": "Hall et al\\.,? \\Q2009\\E", "shortCiteRegEx": "Hall et al\\.", "year": 2009}, {"title": "Readability classification for German using lexical, syntactic, and morphological features", "author": ["Hancke et al.2012] Julia Hancke", "Sowmya Vajjala", "Detmar Meurers"], "venue": "In Proceedings of COLING", "citeRegEx": "Hancke et al\\.,? \\Q2012\\E", "shortCiteRegEx": "Hancke et al\\.", "year": 2012}, {"title": "An analysis of statistical models and features for reading difficulty prediction", "author": ["Kevyn Collins-Thompson", "Maxine Eskenazi"], "venue": "In Proceedings of the Third Workshop on Innovative Use of NLP for Building Educational Applications,", "citeRegEx": "Heilman et al\\.,? \\Q2008\\E", "shortCiteRegEx": "Heilman et al\\.", "year": 2008}, {"title": "N -gram fragment sequence based unsupervised domain-specific document readability", "author": ["Jameel et al.2012] Shoaib Jameel", "Xiaojun Qian", "Wai Lam"], "venue": "In Proceedings of COLING", "citeRegEx": "Jameel et al\\.,? \\Q2012\\E", "shortCiteRegEx": "Jameel et al\\.", "year": 2012}, {"title": "Text categorization with support vector machines: Learning with many relevant", "author": ["Thorsten Joachims"], "venue": null, "citeRegEx": "Joachims.,? \\Q1998\\E", "shortCiteRegEx": "Joachims.", "year": 1998}, {"title": "Device-dependent readability for improved text understanding", "author": ["Kim et al.2014] A-Yeong Kim", "Hyun-Je Song", "Seong-Bae Park", "Sang-Jo Lee"], "venue": "In EMNLP,", "citeRegEx": "Kim et al\\.,? \\Q2014\\E", "shortCiteRegEx": "Kim et al\\.", "year": 2014}, {"title": "Japanese dependency analysis using cascaded chunking", "author": ["Kudo", "Matsumoto2002] Taku Kudo", "Yuji Matsumoto"], "venue": "In proceedings of the 6th conference on Natural language learning-Volume", "citeRegEx": "Kudo et al\\.,? \\Q2002\\E", "shortCiteRegEx": "Kudo et al\\.", "year": 2002}, {"title": "What can language learners tell us about constructions? APPLICATIONS OF COGNITIVE LINGUISTICS, 9:197", "author": ["Manzanares", "Ana Mar\u0131\u0301a Rojo L\u00f3pez"], "venue": null, "citeRegEx": "Manzanares et al\\.,? \\Q2008\\E", "shortCiteRegEx": "Manzanares et al\\.", "year": 2008}, {"title": "Measures of text difficulty: Testing their predictive value for grade levels and student performance", "author": ["Charles Perfetti", "David Liben", "Meredith Liben"], "venue": "Council of Chief State School Officers,", "citeRegEx": "Nelson et al\\.,? \\Q2012\\E", "shortCiteRegEx": "Nelson et al\\.", "year": 2012}, {"title": "Revisiting readability: A unified framework for predicting text quality", "author": ["Pitler", "Nenkova2008] Emily Pitler", "Ani Nenkova"], "venue": "In Proceedings of the conference on empirical methods in natural language processing,", "citeRegEx": "Pitler et al\\.,? \\Q2008\\E", "shortCiteRegEx": "Pitler et al\\.", "year": 2008}, {"title": "Longman dictionary of language teaching and applied linguistics", "author": ["Richards", "Schmidt2013] Jack C Richards", "Richard W Schmidt"], "venue": null, "citeRegEx": "Richards et al\\.,? \\Q2013\\E", "shortCiteRegEx": "Richards et al\\.", "year": 2013}, {"title": "Japanese Language Proficiency Test N1 GRAMMAR Summary", "author": ["Sasaki", "Kiko2010] Hitoko Sasaki", "Matsumoto Kiko"], "venue": null, "citeRegEx": "Sasaki et al\\.,? \\Q2010\\E", "shortCiteRegEx": "Sasaki et al\\.", "year": 2010}, {"title": "Reading level assessment using support vector machines and statistical language models", "author": ["Schwarm", "Ostendorf2005] Sarah E Schwarm", "Mari Ostendorf"], "venue": "In Proceedings of the 43rd Annual Meeting on Association for Computational Linguistics,", "citeRegEx": "Schwarm et al\\.,? \\Q2005\\E", "shortCiteRegEx": "Schwarm et al\\.", "year": 2005}, {"title": "The textevaluator tool: Helping teachers and test developers select texts for use in instruction and assessment", "author": ["Irene Kostin", "Diane Napolitano", "Michael Flor"], "venue": null, "citeRegEx": "Sheehan et al\\.,? \\Q2014\\E", "shortCiteRegEx": "Sheehan et al\\.", "year": 2014}, {"title": "New readability measures for Bangla and Hindi texts", "author": ["Sinha et al.2012] Manjira Sinha", "Sakshi Sharma", "Tirthankar Dasgupta", "Anupam Basu"], "venue": "In Proceedings of COLING 2012: Posters,", "citeRegEx": "Sinha et al\\.,? \\Q2012\\E", "shortCiteRegEx": "Sinha et al\\.", "year": 2012}, {"title": "Influence of target reader background and text features on text readability in bangla: A computational approach", "author": ["Sinha et al.2014] Manjira Sinha", "Tirthankar Dasgupta", "Anupam Basu"], "venue": "In Proceedings of COLING 2014, the 25th International Conference on Computational Linguistics: Technical Papers,", "citeRegEx": "Sinha et al\\.,? \\Q2014\\E", "shortCiteRegEx": "Sinha et al\\.", "year": 2014}, {"title": "Beyond the classroom", "author": ["Anne Schiano", "Elizabeth Lattanzio"], "venue": "Knowledge Quest,", "citeRegEx": "III et al\\.,? \\Q2014\\E", "shortCiteRegEx": "III et al\\.", "year": 2014}, {"title": "A statistical interpretation of term specificity and its application in retrieval", "author": [], "venue": "Journal of documentation,", "citeRegEx": "Jones.,? \\Q1972\\E", "shortCiteRegEx": "Jones.", "year": 1972}, {"title": "Essential Japanese Expression Dictionary: A Guide to Correct Usage of Key Sentence Patterns (New Edition)", "author": ["Tomomatsu Etsuko", "Waguri Masako"], "venue": null, "citeRegEx": "Etsuko et al\\.,? \\Q2010\\E", "shortCiteRegEx": "Etsuko et al\\.", "year": 2010}, {"title": "Readability of texts:: State of the art", "author": ["Zamanian", "Heydari2012] Mostafa Zamanian", "Pooneh Heydari"], "venue": "Theory and Practice in Language Studies,", "citeRegEx": "Zamanian et al\\.,? \\Q2012\\E", "shortCiteRegEx": "Zamanian et al\\.", "year": 2012}], "referenceMentions": [{"referenceID": 7, "context": "Evaluating text difficulty, or text readability, is an important topic in natural language processing and applied linguistics (Zamanian and Heydari, 2012; Pitler and Nenkova, 2008; Fulcher, 1997).", "startOffset": 126, "endOffset": 195}, {"referenceID": 22, "context": "However, most existing tools either do not sufficiently take the impact of grammatical difficulty into account (Smith III et al., 2014; Renaissance Learning, 2016; Sheehan et al., 2014), or use traditional syntactic features, which differ from what language students actually learn, to estimate grammatical complexity (Schwarm and Ostendorf, 2005; Heilman et al.", "startOffset": 111, "endOffset": 185}, {"referenceID": 11, "context": ", 2014), or use traditional syntactic features, which differ from what language students actually learn, to estimate grammatical complexity (Schwarm and Ostendorf, 2005; Heilman et al., 2008).", "startOffset": 140, "endOffset": 191}, {"referenceID": 1, "context": "In fact, language courses introduce grammar constructs together with vocabulary, and grammar constructs vary in frequency and difficulty just like vocabulary (Blyth, 1997; Manzanares and L\u00f3pez, 2008; Waara, 2004).", "startOffset": 158, "endOffset": 212}, {"referenceID": 17, "context": "Text difficulty evaluation has been widely studied over the past few decades (Nelson et al., 2012; Sinha et al., 2012; Hancke et al., 2012; Jameel et al., 2012; Gonzalez-Dios et al., 2014; Sinha et al., 2014).", "startOffset": 77, "endOffset": 208}, {"referenceID": 23, "context": "Text difficulty evaluation has been widely studied over the past few decades (Nelson et al., 2012; Sinha et al., 2012; Hancke et al., 2012; Jameel et al., 2012; Gonzalez-Dios et al., 2014; Sinha et al., 2014).", "startOffset": 77, "endOffset": 208}, {"referenceID": 10, "context": "Text difficulty evaluation has been widely studied over the past few decades (Nelson et al., 2012; Sinha et al., 2012; Hancke et al., 2012; Jameel et al., 2012; Gonzalez-Dios et al., 2014; Sinha et al., 2014).", "startOffset": 77, "endOffset": 208}, {"referenceID": 12, "context": "Text difficulty evaluation has been widely studied over the past few decades (Nelson et al., 2012; Sinha et al., 2012; Hancke et al., 2012; Jameel et al., 2012; Gonzalez-Dios et al., 2014; Sinha et al., 2014).", "startOffset": 77, "endOffset": 208}, {"referenceID": 8, "context": "Text difficulty evaluation has been widely studied over the past few decades (Nelson et al., 2012; Sinha et al., 2012; Hancke et al., 2012; Jameel et al., 2012; Gonzalez-Dios et al., 2014; Sinha et al., 2014).", "startOffset": 77, "endOffset": 208}, {"referenceID": 24, "context": "Text difficulty evaluation has been widely studied over the past few decades (Nelson et al., 2012; Sinha et al., 2012; Hancke et al., 2012; Jameel et al., 2012; Gonzalez-Dios et al., 2014; Sinha et al., 2014).", "startOffset": 77, "endOffset": 208}, {"referenceID": 22, "context": "TextEvaluator is a comprehensive text analysis system desinged to help teachers and test developers evaluate the complexity characteristics of reading materials (Sheehan et al., 2014).", "startOffset": 161, "endOffset": 183}, {"referenceID": 11, "context": "Based on this fact, recent readability evaluation systems improved performance by incorporating syntactic features like parse tree depth (Schwarm and Ostendorf, 2005) and subtree patterns (Heilman et al., 2008) to measure grammatical complexity.", "startOffset": 188, "endOffset": 210}, {"referenceID": 1, "context": "However, these syntactic features differ from the grammatical knowledge that students actually learn in language lessons (Blyth, 1997; Manzanares and L\u00f3pez, 2008; Waara, 2004).", "startOffset": 121, "endOffset": 175}, {"referenceID": 14, "context": "The relationship between text readability and reading devices was also studied in the past two years (Kim et al., 2014).", "startOffset": 101, "endOffset": 119}, {"referenceID": 6, "context": "Language education researchers attempted to utilize these native-speaker-oriented techniques, which measure text difficulty based on traditional vocabulary and syntactic features, to predict text difficulty levels for Portuguese language learners (Curto et al., 2015).", "startOffset": 247, "endOffset": 267}, {"referenceID": 6, "context": "However, these vocabulary-based methods underperform for language learners who have limited knowledge of grammar (Callan and Eskenazi, 2007; Curto et al., 2015).", "startOffset": 113, "endOffset": 160}, {"referenceID": 0, "context": "We introduce the idea of grammatical templates, units of grammar that expert language instructors and linguists have identified as the most important grammatical knowledge, and are typically emphasized as key points in every textbook lesson (Banno et al., 2011; People\u2019s Education Press, 2013).", "startOffset": 241, "endOffset": 293}, {"referenceID": 0, "context": "We also collected reading texts from two popular series of Japanese textbooks: Standard Japanese (People\u2019s Education Press, 2013) and Genki (Banno et al., 2011).", "startOffset": 140, "endOffset": 160}, {"referenceID": 14, "context": "We compare our work with recent readability evaluation studies (Kim et al., 2014; Pitler and Nenkova, 2008).", "startOffset": 63, "endOffset": 107}, {"referenceID": 17, "context": "Since the text difficulty level prediction can be regarded as a special text classification problem, we also extract TF-IDF features (Sparck Jones, 1972) (Nelson et al., 2012) as an extra baseline, in order to see how general text classification techniques work on text difficulty evaluation.", "startOffset": 154, "endOffset": 175}, {"referenceID": 13, "context": "3 Result We test k-Nearest Neighbor and Support Vector Machines (Joachims, 1998) for each feature set.", "startOffset": 64, "endOffset": 80}, {"referenceID": 9, "context": "The implementations of these two popular classification algorithms are provided by the WEKA toolkit (Hall et al., 2009) and LibSVM (Chang and Lin, 2011).", "startOffset": 100, "endOffset": 119}, {"referenceID": 4, "context": "The SVMs use RBF kernels (Chang et al., 2010).", "startOffset": 25, "endOffset": 45}], "year": 2017, "abstractText": "Language students are most engaged while reading texts at an appropriate difficulty level. However, existing methods of evaluating text difficulty focus mainly on vocabulary and do not prioritize grammatical features, hence they do not work well for language learners with limited knowledge of grammar. In this paper, we introduce grammatical templates, the expert-identified units of grammar that students learn from class, as an important feature of text difficulty evaluation. Experimental classification results show that grammatical template features significantly improve text difficulty prediction accuracy over baseline readability features by 7.4%. Moreover, we build a simple and human-understandable text difficulty evaluation approach with 87.7% accuracy, using only 5 grammatical template features.", "creator": "LaTeX with hyperref package"}}}