{"id": "1609.06686", "review": {"conference": "arxiv", "VERSION": "v1", "DATE_OF_SUBMISSION": "21-Sep-2016", "title": "Character-level and Multi-channel Convolutional Neural Networks for Large-scale Authorship Attribution", "abstract": "convolutional virtual neural networks ( cc cnns ) have apparently demonstrated superior capability for simply extracting information from raw signals in automatic computer expressive vision. recently, character - level processors and multi - face channel cnns have proven exhibited excellent evaluation performance for sentence dependent classification tasks. we systematically apply overall cnns sensitivity to a large - scale authorship for attribution, however which aims to progressively determine how an alternative unknown web text's author placement among many weak candidate search authors, motivated by using their ability designed to favorably process selected character - centered level signals and seeking to differentiate between potentially a large number composed of classes, significantly while making fast predictions in html comparison best to mainstream state - of -'the - adi art approaches. we extensively evaluate cnn - block based recognition approaches however that leverage existing word lengths and character channels and heavily compare them against state - of - the - art methods for a large range of effective author numbers, greatly shedding new light on previous traditional language approaches. nowadays we furthermore show that character - level cnns successfully outperform the state - of - the - act art on chromosome four out of forty five datasets generated in different domains. additionally, musically we should present the first first application description of authorship attribution to reddit.", "histories": [["v1", "Wed, 21 Sep 2016 19:08:15 GMT  (335kb,D)", "http://arxiv.org/abs/1609.06686v1", "9 pages, 5 figures, 3 tables"]], "COMMENTS": "9 pages, 5 figures, 3 tables", "reviews": [], "SUBJECTS": "cs.CL cs.LG", "authors": ["sebastian ruder", "parsa ghaffari", "john g breslin"], "accepted": false, "id": "1609.06686"}, "pdf": {"name": "1609.06686.pdf", "metadata": {"source": "CRF", "title": "Character-level and Multi-channel Convolutional Neural Networks for Large-scale Authorship Attribution", "authors": ["Sebastian Ruder", "Parsa Ghaffari", "John G. Breslin"], "emails": ["sebastian.ruder@insight-centre.org", "john.breslin@insight-centre.org", "sebastian@aylien.com", "parsa@aylien.com"], "sections": [{"heading": "1 Introduction", "text": "State-of-the-art methods in authorship attribution, which aims to determine an unknown text\u2019s author among a set of candidate authors, rely on low-level information such as character n-grams (Frantzeskou and Stamatatos, 2007). Recent approaches (Koppel et al., 2011) focus on largescale authorship attribution for thousands of authors, but are expensive during prediction, which is a deficit in on-line scenarios for purposes of tar-\ngeted marketing, copyright enforcement, writing support, and search relevance, among others (Potthast et al., 2016). Furthermore, besides stylistic information, word-level topical information has been shown to be relevant for authorship attribution (Seroussi et al., 2011).\nSimultaneously, convolutional neural networks (CNNs) have achieved remarkable successes in computer vision (Krizhevsky et al., 2012) and speech recognition (Abdel-Hamid et al., 2012) and have been found particularly suitable for extracting information from just such low-level signals. They have also been shown to be effective for various NLP tasks (Collobert et al., 2011) and have achieved state-of-the-art in several sentence classification tasks (Kim, 2014). Most neural networks and CNNs in NLP perform convolutions on the word level using pre-trained word embeddings (Mikolov et al., 2013). Recent approaches employ convolutions over characters (Zhang et al., 2015).\nWe apply CNNs to the task of authorship attribution for four reasons: a) They have been shown to be excellent at leveraging character-level signals, which have been found to be indicative of authorial style (Stamatatos, 2009); b) they have excelled at differentiating between a large number of classes (Krizhevsky et al., 2012), which is key for large-scale authorship attribution; c) prediction is fast; and d) a combination of word and character input channels enables them to take topical information into account.\nOur main contributions are the following:\n\u2022 We present state-of-the-art results for largescale authorship attribution for four out of five datasets in different domains using character-level convolutional neural networks.\n\u2022 We evaluate combinations of different CNN input channels and propose a novel model\nar X\niv :1\n60 9.\n06 68\n6v 1\n[ cs\n.C L\n] 2\n1 Se\np 20\n16\nthat combines character and word channels.\n\u2022 We compare CNN approaches against traditional approaches for a large range of author numbers and discuss merits and improvements.\n\u2022 We present the first application of authorship attribution to reddit comments and introduce two new Twitter and reddit datasets that we make available for further research."}, {"heading": "2 Related work", "text": "Our work is inspired by two neural network architectures: multi-channel CNNs and character-level CNNs.\nMulti-channel CNNs are pervasive in domains where the input can naturally be separated into different channels, e.g. color channels in computer vision, wave lengths in speech recognition (Hoshen et al., 2014). Natural language input is typically single-channel in the form of tokens or characters. Kim (2014) observe that a static word channel is able to encode general semantic similarities, while a non-static channel can be fine-tuned to the task at hand and improves performance on some datasets.\nCharacter-level CNNs have been shown to outperform traditional classification methods on large-scale datasets (Zhang et al., 2015). Their CNNs, however, require tens of thousands of perclass examples and thousands of training epochs, while our datasets only contain a few hundred examples per class.\nThe use of most other character-level CNNs is motivated by the desire to leverage sub-word information (e.g. morphemes) to which word-level CNNs are blind: Kim et al. (2016) feed the output of a character-level CNN to a recurrent neural language model and improve performance particularly for morphologically rich languages.\nSantos and Zadrozny (2014) use a CNN that associates a character embedding produced by a CNN for each word with its word representation to improve POS tagging performance for English and Portuguese, while Santos and Guimara\u0303es (2015) use the same network to boost results for named entity recognition. In contrast to their approach, we do not aim to detect morphological information because inter-word features such as punctuation and white space are very relevant to authorship. Rather, we treat characters as a distinct input\nchannel as our goal is to learn to identify discrete word and character patterns and to associate them with each other.\nAuthorship attribution is the task of identifying an unknown text\u2019s author among a set of candidate authors with applications ranging from plagiarism detection to Forensic Linguistics. The key notion behind statistical authorship attribution is that measuring textual features enables distinction between texts written by different authors (Stamatatos, 2009). These features range from indicators of content divergence between authors such as bag-of-words to stylometric features that reflect an author\u2019s unique writing patterns, e.g. use of punctuation marks, emoticons, whitespace, etc. (Sapkota et al., 2015), and character and word n-grams (Schwartz et al., 2013).\nDeep learning research has largely neglected authorship attribution; related work has instead focused on modeling an author\u2019s style: Kiros et al. (2014) condition word embeddings on attributes such as style and predict an author\u2019s age, gender, and industry. Zhu et al. (2015) transform image captions into book sentences by subtracting the \u2019style\u2019. State-of-the-art authorship attribution algorithms have to handle possibly thousands of candidate authors and a limited number of examples per author in real-world applications but require CPU-days for prediction as they calculate pairwise distances between feature subsets (Koppel et al., 2011). Simultaneously, character ngrams have proven to be the single most successful feature (Frantzeskou and Stamatatos, 2007). Finally, Potthast et al. (2016) compare traditional approaches on small datasets, while we evaluate state-of-the-art as well as CNN-based methods for thousands of authors, thereby moving a step closer to the goal of authorship attribution at web-scale."}, {"heading": "3 Model", "text": "The model architecture we use is an extension of the CNN structure used by Collobert et al. (2011). Its variant with two word embedding channels used by Kim (2014) is depicted in Figure 1.\nThe model takes as input a text, which is padded to length n. For the character embedding channel, we represent the text as a concatenation of its character embeddings z1:m where zi \u2208 Rk is the k-dimensional vector of the i-th character in the text andm is the character length of the text, while for the word embedding channel, we represent the\ntext as a concatentation of its word embeddings x1:n where xi \u2208 Rk is the k-dimensional vector of the i-th word in the text. The convolutional layer slides filters of different window sizes over each input channel. Each filter with weights w \u2208 Rhk generates a new feature ci for a window of h characters or words according to the following operation:\nci = f(w \u00b7 xi:i+h\u22121 + b) (1)\nNote that b \u2208 R is a bias term and f is a nonlinear function, ReLU (Nair and Hinton, 2010) in our case. The application of the filter over each possible window of h words or characters in the sentence produces the following feature map:\nc = [c1, c2, ..., cn\u2212h+1] (2)\nMax-over-time pooling (Collobert et al., 2011) in turn condenses this feature vector to its most important feature by taking its maximum value and naturally deals with variable input lengths. A final softmax layer takes the concatenation of the maximum values of the feature maps produced by all filters and outputs a probability distribution over all candidate authors.\nFor the standard single-channel character-level CNN, we represent characters as one-hot vectors.1\nIn the multi-channel architecture, we apply each filter to both channels and sum the results2 to calculate ci in equation 1. Note that in order to com-\n1Using low-dimensional character embeddings as in Kim et al. (2016) decreased performance.\n2We have also experimented with concatenation, which produces slightly worse results.\nbine a word and character channel, both spaces must have the same dimensionality. We thus embed characters in a space with the same number of dimensions as the word embedding space and pad the word sequence to have the same length as the character sequence.3"}, {"heading": "4 Datasets", "text": "We benchmark our models on the following datasets that cover a large spectrum of styles and domains:\nThe Enron email dataset contains about 0.5M emails from mostly senior managers at Enron4 organized in different folders. We extract emails from the SENT and SENT ITEMS folders as these include outgoing traffic. We remove all but the email body, discarding emails that contain less than 10 tokens. This leaves us with 80,852 emails from 144 authors.\nThe IMDb62 dataset contains 62,000 movie reviews by 62 prolific users of the Internet Movie database. The dataset is made available by Seroussi et al. (2011) on request.\nThe Blog authorship dataset contains 681,288 blog posts of 19,320 bloggers gathered by Schler et al. (2005) from blogger.com in August 20045.\nWe create the Twitter influencer dataset in order to establish and share benchmark train and test splits for authorship attribution on a dedicated\n3We found that truncating the character sequence yielded worse performance.\n4https://www.cs.cmu.edu/\u02dc./enron/ 5http://u.cs.biu.ac.il/\u02dckoppel/\nBlogCorpus.htm\nTwitter corpus6. We created the dataset by gathering a list of 4,391 celebrity and power-user influencers in 68 domains ranging from politics and tech to arts and writing and collected just over 1M tweets for these users in October and November 2015 using the AYLIEN API7.\nThe reddit gaming dataset is a subset of the massive dataset of around 1.7 billion reddit comments from 2007 to 2015 collected via reddit\u2019s API8. We control for topic by selecting comments only from the /r/Gaming subreddit and download 2 million comments of the subreddit\u2019s most prolific users from January 2014 to May 2015 using Google BigQuery9. We show statistics for the datasets in table 1."}, {"heading": "5 Experimental setup", "text": ""}, {"heading": "5.1 Model variations", "text": "We test variations of our model that use different combinations of input channels together with a one-layer CNN.10\n\u2022 CNN-word: a CNN with a non-static word embedding channel where the vectors are modified during training using backpropagation. This is the classic word embedding CNN used e.g. by Collobert et al. (2011).\n\u2022 CNN-char: a CNN with a non-static character channel. A variant with more than one convolutional layer is used by Zhang et al. (2015).\n\u2022 CNN-word-word: a CNN with a static and a non-static word embedding channel. This is the multi-channel CNN proposed by Kim (2014).\n\u2022 CNN-word-char: a hybrid-channel CNN with a non-static word and a non-static character channel.\n\u2022 CNN-word-word-char: a hybrid-channel CNN with a static word, a non-static word and a non-static character channel.\n6The dataset collected by Layton et al. (2010) is no longer available.\n7http://aylien.com/ 8https://www.reddit.com/dev/api 9https://cloud.google.com/bigquery/\n10We have compared against character- and word-level recurrent neural networks, but do not include them in the evaluation as their performance was not competitive.\nAll word embedding channels are initialized with 300-dimensional GloVe vectors (Pennington et al., 2014) trained on 840B tokens of the Common Crawl corpus11. Character embedding channels and words not present in the set of pre-trained words are initialized randomly."}, {"heading": "5.2 Comparison methods", "text": "We compare against four state-of-the-art authorship attribution methods:\n\u2022 SVM+Stems: an SVM classifier, which distinguishes authors based on word stems rather than bag-of-words (Allison and Guthrie, 2008). Features are additionally weighted with tf-idf and scaled to have unit variance.\n\u2022 SCAP: the Source Code Author Profile (SCAP) method (Frantzeskou and Stamatatos, 2007) determines authorship based on the intersection of the most frequent character n-grams of an unknown text and an author\u2019s profile, i.e. the concatentation of an author\u2019s known texts.\n\u2022 Imposters: the Imposters Method (Koppel et al., 2011) is based on the intuition that the profile of an unknown text\u2019s author is likely to be most similar to the unknown text most often as the feature set varies. For each iteration, it calculates the cosine similarity of a random fraction of a feature set of spacefree character n-grams between an unknown text and an author\u2019s profile. It then chooses the author who exhibited the maximum cosine similarity most frequently.\n11For the Twitter dataset 200-dimensional GloVe vectors trained on 27B tokens of Twitter data are used.\n\u2022 LDAH-S: LDA Hellinger Single-Document, the top-performing method of Seroussi et al. (2011) uses Hellinger distance between the LDA topic distributions for an unknown text and an author\u2019s profile as a measure for authorship.\nResults for SVM+Stems have been reported on the Email dataset (Allison and Guthrie, 2008) and results for Imposters and LDAH-S have been reported on the IMDb62 and Blog dataset (Seroussi et al., 2011). However, as there are no predefined train-test splits for these datasets, we reimplement the above algorithms to guarantee identical conditions and objective comparison."}, {"heading": "5.3 Hyperparameters and training", "text": "As authorship attribution algorithms must be able to deal with a large number of authors, we conduct experiments for a large range of author numbers. For each number of authors n, we select the subset of texts belonging to the n most authors with the most documents in the dataset. Note that as we scale the number of authors, the number of documents per author diminishes and identifying prominent authors transforms into the scenario of detecting authors with only few samples. We do not equalize the number of training documents to maintain the imbalanced distribution common in real-world applications.\nAs the per-fold run time of most of the state-ofthe-art authorship attribution methods renders 10- fold cross-validation prohibitively expensive, we randomly split off 10% as a stratified test set. We keep the test set constant and use a seed to reduce randomness in the comparison. We furthermore use 10% of each training set as a stratified development set. We optimize hyperparameters for all comparison algorithms for each dataset on the development set of its 10-author subset using random search and keep them constant each dataset. For SVM+Stems, we use a linear kernel, unigram\nstems, and a vocabulary size of 10,000. The parameters for the other algorithms can be seen in Table 2.\nCNN parameters. We optimize hyperparameters for our CNN configurations on the development set of the 10-authors emails subset without any task-specific fine-tuning. These are: vocabulary size of 10,000 words, 98 characters12, maximum sequence length of 500 for word-based CNNs and of 3000 for CNN-char and hybridchannel CNNs, l2 constraint of 0, dropout rate of 0.5, filter windows of 6, 7, 8 with 100 feature maps each, and mini-batch size of 50. We train for 15 epochs using mini-batch stochastic gradient descent and early stopping. We use the Adadelta update rule (Zeiler, 2012) as it allows us to pay special attention to infrequent features that can be, however, highly indicative of certain authors."}, {"heading": "6 Results and discussion", "text": "We evaluate all algorithms on all 62 authors for the IMDb dataset and on 10 and 50 authors respectively for all other datasets. Results of our CNN models against the comparison methods are listed in Table 3. Additionally, we evaluate the best CNNs against the best comparison method in Table 3, SCAP on larger numbers of authors. We show results up to all 144 authors for the Emails dataset in Figure 2 and results up to 1,000 authors for the Blogs, Twitter, and reddit datasets in Figures 3, 4, and 5 respectively."}, {"heading": "6.1 Domain", "text": "The corpus domain has a big impact on a model\u2019s performance and often requires domain-specific feature engineering (Stamatatos, 2009). Wordbased methods such as SVM+Stems, LDAH-S,\n12We use the same vocabulary as Zhang et al. (2015), but distinguish between lower-case and upper-case characters and convolve all numbers into one as both measures increase performance.\nCNN-word, CNN-word-word perform well in domains in which topical information is discriminatory, such as emails, movie reviews, and blogs. They, however, achieve comparatively worse performance for short-message domains such as Twitter and reddit. On these, character-enhanced methods provide a considerable performance boost. Past studies (Stamatatos, 2009; Schwartz et al., 2013) highlighted challenges for short text authorship attribution, such as the number of authors, the training set size, and the size of the test document.\nTwitter. The generally impressive scores in the Twitter domain reveal a bias that is two-fold: a) As we have not pre-processed the data (other than lower-casing) to reflect real-world use cases, models are able to leverage mentions and hashtags to achieve high F1 scores; replacing these lowers scores for all models as observed by Layton (2010); b) celebrities and power-users that are the subject of this dataset use language differently in comparison to regular users, with the goal of enhancing their brand by frequently tweeting similar key messages. This behavior, however, makes it easier for models to pick up on their individual style or preferred content. We intend to investigate the stylistic differences between regular users and celebrities and their impact on authorship attribution in future work.\nReddit. Most models perform poorly on the reddit domain. We suspect that authorship attribution on reddit is challenging for two reasons: a) Comments are either very long (tirades / explanations) or very short (short replies / puns); b) in contrast to Twitter, reddit is less about broadcasting\noneself to the world and more about interacting with the community; posts thus often reflect the character of the thread rather than the character of the user and often contain stylistically conspicuous features such as irony (Wallace et al., 2015). Further research may thus reveal how users shift their style and if this behavior differs across different subreddits."}, {"heading": "6.2 CNNs", "text": "All of our CNN variants consistently outperform most traditional authorship attribution methods. Even CNN-word that only uses word embeddings performs significantly better than most comparison methods. Moreover, CNNs show aptitude to handle the class imbalance problem (Stamatatos, 2007) inherent in real-world applications by significantly outperforming the comparison methods on all datasets with imbalanced numbers of documents per author (see Table 1) in line with findings by Potthast et al. (2016).\nIn the emails domain, CNNs outperform the comparison methods by more than 6 %. for 10 authors and SCAP by more than 16 %. for 144 authors. We suppose that these large performance differences lie in the fact that CNNs are able to pay special attention to structural measures such as greetings, farewells, and signatures (de Vel et al., 2001). Differences for the IMDb domain are less pronounced, as authors would generally review similar movies, rendering specific words or character sequences discriminatory. Fine-tuned word embeddings that are sensitive to topical divergence between authors boost CNN performance in the\nblogs domain. They are, however, less helpful in the Twitter and reddit domains, where hashtags or emoticons are the most characteristic features.\nCharacter-level CNNs outperform traditional methods and CNN variants on 4 out of 5 datasets in Table 3, on most of them quite significantly. They outperform comparison methods in domains such as Reddit where certain character sequences such as smileys and emoticons are discriminatory by more than 12 %. for 10 authors. They perform well even with fewer per-class examples scaling better than all other methods (except for SCAP on Twitter in Figure 4) to large numbers of authors.\nThe reason for the success of character-level CNNs clearly is their superior ability to capture stylistic information encoded on the characterlevel. In contrast to traditional approaches such as SCAP and Imposters, character-level CNNs are able to model more complex interactions between different stylistic features by leveraging non-linearities.\nGiven the availability of a GPU, they only take a few hours to train \u2013 even for large-scale authorship attribution scenarios as the author number only affects the number of parameters in the final softmax layer, which scales linearly. More importantly, they are able to form a prediction instantaneously compared to the CPU-hours or CPUdays required by SCAP or the Imposters method respectively. For this reason, they are particularly suited for conducting a large or recurring number of predictions in on-line scenarios such as attributing messages to known terrorists (Abbasi and Chen, 2005).\nHybrid-channel CNNs outperform CNNs that rely solely on word embeddings, as character-level\ninformation is important for the task of authorship attribution. In the blogs domain, where topical information is a distinguishing feature, they outperform character-level CNNs in Table 3. Using a static and a non-static word channel together with the character channel had similar effects as using a multi-channel architecture over a regular word-based CNN, i.e. it increased scores on some datasets."}, {"heading": "6.3 Traditional methods", "text": "Similarly to Frantzeskou and Stamatatos (2007), we find that increasing the profile size of an author\u2019s concatenated known texts consistently increases performance for n-gram based similarity methods, i.e. SCAP and Imposters. The optimal profile size for our datasets, 14,000, however, is considerably higher than past values reported for this hyperparameter (Layton et al., 2010) (Layton et al., 2012), suggesting that larger ranges should be considered in future research.\nWe have found that restricting the vocabulary size by selecting only the 30,000 most frequent space-free character n-grams for the Imposters method generally increased performance as frequency is the most important criterion for selecting features in authorship attribution (Stamatatos, 2009).13 Even though we improve performance for Imposters on the IMDb dataset in comparison to Seroussi et al. (2011) by selecting appropriate hyperparameters, we are unable to achieve competitive scores using the more recently proposed authorship attribution methods, Imposters\n13Koppel et al. (2011) use more than 250,000 unique character n-grams.\nand LDAH-S.14 In contrast, the SCAP method proves to be easy and fast to train and outperforms CNNs on the IMDb dataset in Table 3.\nImpressively, SCAP scales better than CNNs on Twitter in Figure 4. Recall that for Twitter influencers, certain n-grams such as user mentions or hashtags are highly indicative. We suspect that as SCAP stores discrete n-grams for each author, it is better able to assign them to the correct author, while the continuous function used by CNNs might blur the boundaries in the case of many authors. To mitigate this deficit, CNNs can a) be made more expressive by adding more layers (Zhang et al., 2015); or b) can be interpolated with n-grams that capture clear n-gram-author correspondences as in the Twitter domain."}, {"heading": "7 Conclusion", "text": "In this work, we have applied character-level CNNs to large-scale authorship attribution. We have extensively evaluated combinations of different CNN input channels and introduced a novel model that combines character and word channels to leverage both stylistic and topical information. We have compared CNNs against state-of-the-art methods for a large range of author numbers, shedding new light on traditional approaches. We have presented state-of-the-art results for four out of five datasets in different domains and have introduced two new Twitter and reddit datasets that we make available for further research.\n14We apply them to larger numbers of authors and obtain similar results. Note that we evaluate \u2013 in contrast to Koppel et al. (2011) and Seroussi et al. (2011) \u2013 using F1, which penalizes low recall."}, {"heading": "Acknowledgments", "text": "This publication has emanated from research supported by Grant Number EBPPG/2014/30 from the Irish Research Council with Aylien Ltd. as Enterprise Partner and by Grant Number SFI/12/RC/2289 from Science Foundation Ireland (SFI)."}], "references": [{"title": "Applying Authorship Analysis to Extremist-Group Web Forum Messages", "author": ["Ahmed Abbasi", "Hsinchun Chen."], "venue": "Intelligent Systems, IEEE, 20(5):67\u2013", "citeRegEx": "Abbasi and Chen.,? 2005", "shortCiteRegEx": "Abbasi and Chen.", "year": 2005}, {"title": "Applying convolutional neural networks concepts to hybrid NN-HMM model for speech recognition", "author": ["Ossama Abdel-Hamid", "Abdel Rahman Mohamed", "Hui Jiang", "Gerald Penn."], "venue": "IEEE International Conference on Acoustics, Speech and Signal Pro-", "citeRegEx": "Abdel.Hamid et al\\.,? 2012", "shortCiteRegEx": "Abdel.Hamid et al\\.", "year": 2012}, {"title": "Authorship Attribution of E-Mail: Comparing Classifiers over a New Corpus for Evaluation", "author": ["B Allison", "L Guthrie."], "venue": "LREC.", "citeRegEx": "Allison and Guthrie.,? 2008", "shortCiteRegEx": "Allison and Guthrie.", "year": 2008}, {"title": "Natural Language Processing (almost) from Scratch", "author": ["Ronan Collobert", "Jason Weston", "Leon Bottou", "Michael Karlen", "Koray Kavukcuoglu", "Pavel Kuksa."], "venue": "Journal of Machine Learning Research, 12(Aug):2493\u20132537.", "citeRegEx": "Collobert et al\\.,? 2011", "shortCiteRegEx": "Collobert et al\\.", "year": 2011}, {"title": "Mining e-mail content for author identification forensics", "author": ["O. de Vel", "a. Anderson", "M. Corney", "G. Mohay"], "venue": "ACM SIGMOD Record,", "citeRegEx": "Vel et al\\.,? \\Q2001\\E", "shortCiteRegEx": "Vel et al\\.", "year": 2001}, {"title": "Identifying authorship by byte-level n-grams: The source code author profile (scap) method", "author": ["G Frantzeskou", "E Stamatatos."], "venue": "International Journal of Digital Evidence, 6(1):1\u201318.", "citeRegEx": "Frantzeskou and Stamatatos.,? 2007", "shortCiteRegEx": "Frantzeskou and Stamatatos.", "year": 2007}, {"title": "Speech Acoustic Modeling From Raw Multichannel Waveforms", "author": ["Yedid Hoshen", "Ron J Weiss", "Kevin W Wilson."], "venue": "pages 2\u20136.", "citeRegEx": "Hoshen et al\\.,? 2014", "shortCiteRegEx": "Hoshen et al\\.", "year": 2014}, {"title": "Character-Aware Neural Language Models", "author": ["Yoon Kim", "Yacine Jernite", "David Sontag", "Alexander M. Rush."], "venue": "AAAI.", "citeRegEx": "Kim et al\\.,? 2016", "shortCiteRegEx": "Kim et al\\.", "year": 2016}, {"title": "Convolutional Neural Networks for Sentence Classification", "author": ["Yoon Kim."], "venue": "Proceedings of the Conference on Empirical Methods in Natural Language Processing, pages 1746\u20131751.", "citeRegEx": "Kim.,? 2014", "shortCiteRegEx": "Kim.", "year": 2014}, {"title": "A Multiplicative Model for Learning Distributed Text-Based Attribute Representations", "author": ["Ryan Kiros", "Rs Zemel", "Ruslan Salakhutdinov."], "venue": "NIPS.", "citeRegEx": "Kiros et al\\.,? 2014", "shortCiteRegEx": "Kiros et al\\.", "year": 2014}, {"title": "Authorship attribution in the wild", "author": ["Moshe Koppel", "Jonathan Schler", "Shlomo Argamon."], "venue": "Language Resources and Evaluation, 45(1):83\u201394.", "citeRegEx": "Koppel et al\\.,? 2011", "shortCiteRegEx": "Koppel et al\\.", "year": 2011}, {"title": "ImageNet Classification with Deep Convolutional Neural Networks", "author": ["Alex Krizhevsky", "Ilya Sutskever", "Geoffrey E Hinton."], "venue": "Advances In Neural Information Processing Systems, pages 1\u20139.", "citeRegEx": "Krizhevsky et al\\.,? 2012", "shortCiteRegEx": "Krizhevsky et al\\.", "year": 2012}, {"title": "Authorship attribution for twitter in 140 characters or less", "author": ["Robert Layton", "Paul Watters", "Richard Dazeley."], "venue": "Cybercrime and Trustworthy Computing Workshop (CTC), IEEE, pages 1\u20138.", "citeRegEx": "Layton et al\\.,? 2010", "shortCiteRegEx": "Layton et al\\.", "year": 2010}, {"title": "Unsupervised authorship analysis of phishing webpages", "author": ["Robert Layton", "Paul Watters", "Richard Dazeley."], "venue": "2012 International Symposium on Communications and Information Technologies, ISCIT 2012, (October):1104\u20131109.", "citeRegEx": "Layton et al\\.,? 2012", "shortCiteRegEx": "Layton et al\\.", "year": 2012}, {"title": "Distributed Representations of Words and Phrases and their Compositionality", "author": ["Tomas Mikolov", "Kai Chen", "Greg Corrado", "Jeffrey Dean."], "venue": "NIPS, pages 1\u20139.", "citeRegEx": "Mikolov et al\\.,? 2013", "shortCiteRegEx": "Mikolov et al\\.", "year": 2013}, {"title": "Rectified Linear Units Improve Restricted Boltzmann Machines", "author": ["Vinod Nair", "Geoffrey E Hinton."], "venue": "Proceedings of the 27th International Conference on Machine Learning, (3):807\u2013814.", "citeRegEx": "Nair and Hinton.,? 2010", "shortCiteRegEx": "Nair and Hinton.", "year": 2010}, {"title": "Glove: Global Vectors for Word Representation", "author": ["Jeffrey Pennington", "Richard Socher", "Christopher D. Manning."], "venue": "Proceedings of the 2014 Conference on Empirical Methods in Natural Language Processing, pages 1532\u20131543.", "citeRegEx": "Pennington et al\\.,? 2014", "shortCiteRegEx": "Pennington et al\\.", "year": 2014}, {"title": "Who wrote the Web? Revisiting influential author identification research applicable to information retrieval", "author": ["Timo Sommer", "Michael Tr\u00e4ger", "Sebastian Wilhelm", "Benno Stein", "Efstathios Stamatatos", "Matthias Hagen"], "venue": null, "citeRegEx": "Sommer et al\\.,? \\Q2016\\E", "shortCiteRegEx": "Sommer et al\\.", "year": 2016}, {"title": "Boosting Named Entity Recognition with Neural Character Embeddings", "author": ["Cicero Nogueira Dos Santos", "Victor Guimar\u00e3es."], "venue": "Proceedings of NEWS 2015 The Fifth Named Entities Workshop.", "citeRegEx": "Santos and Guimar\u00e3es.,? 2015", "shortCiteRegEx": "Santos and Guimar\u00e3es.", "year": 2015}, {"title": "Learning Character-level Representations for Part-ofSpeech Tagging", "author": ["CD Santos", "B Zadrozny."], "venue": "Proceedings of the 31st International Conference on Machine Learning, ICML14(2011):1818\u20131826.", "citeRegEx": "Santos and Zadrozny.,? 2014", "shortCiteRegEx": "Santos and Zadrozny.", "year": 2014}, {"title": "Not All Character N -grams Are Created Equal: A Study in Authorship Attribution", "author": ["Upendra Sapkota", "Steven Bethard", "Thamar Solorio."], "venue": "Human Language Technologies: The 2015 Annual Conference of the North American Chapter of the", "citeRegEx": "Sapkota et al\\.,? 2015", "shortCiteRegEx": "Sapkota et al\\.", "year": 2015}, {"title": "Effects of Age and Gender on Blogging", "author": ["Jonathan Schler", "Moshe Koppel", "Shlomo Argamon", "James Pennebaker."], "venue": "AAAI Spring Symposium: Computational Approaches to Analyzing Weblogs, pages 199\u2013205.", "citeRegEx": "Schler et al\\.,? 2005", "shortCiteRegEx": "Schler et al\\.", "year": 2005}, {"title": "Authorship Attribution of MicroMessages", "author": ["Roy Schwartz", "Oren Tsur", "Ari Rappoport", "Moshe Koppel."], "venue": "Empirical Methods in Natural Language Processing, pages 1880\u20131891.", "citeRegEx": "Schwartz et al\\.,? 2013", "shortCiteRegEx": "Schwartz et al\\.", "year": 2013}, {"title": "Authorship Attribution with Latent Dirichlet Allocation", "author": ["Yanir Seroussi", "Ingrid Zukerman", "Fabian Bohnert."], "venue": "Proceedings of the Fifteenth Conference on Computational Natural Language Learning, (June):181\u2013189.", "citeRegEx": "Seroussi et al\\.,? 2011", "shortCiteRegEx": "Seroussi et al\\.", "year": 2011}, {"title": "Author identification using imbalanced and limited training texts", "author": ["Efstathios Stamatatos."], "venue": "Proceedings - International Workshop on Database and Expert Systems Applications, DEXA, pages 237\u2013241.", "citeRegEx": "Stamatatos.,? 2007", "shortCiteRegEx": "Stamatatos.", "year": 2007}, {"title": "A Survey of Modern Authorship Attribution Methods", "author": ["Efstathios Stamatatos."], "venue": "Journal of the American Society for Information Science and Technology, 60(3):538\u2013556.", "citeRegEx": "Stamatatos.,? 2009", "shortCiteRegEx": "Stamatatos.", "year": 2009}, {"title": "Sparse, Contextually Informed Models for Irony Detection: Exploiting User Communities, Entities and Sentiment", "author": ["Byron C. Wallace", "Do Kook Choe", "Eugene Charniak."], "venue": "Proceedings of the 53rd Annual Meeting of the Association for Computational", "citeRegEx": "Wallace et al\\.,? 2015", "shortCiteRegEx": "Wallace et al\\.", "year": 2015}, {"title": "ADADELTA: An Adaptive Learning Rate Method", "author": ["Matthew D. Zeiler."], "venue": "arXiv preprint arXiv:1212.5701.", "citeRegEx": "Zeiler.,? 2012", "shortCiteRegEx": "Zeiler.", "year": 2012}, {"title": "Character-level Convolutional Networks for Text Classification", "author": ["Xiang Zhang", "Junbo Zhao", "Yann LeCun."], "venue": "Advances in Neural Information Processing Systems, pages 649\u2013657.", "citeRegEx": "Zhang et al\\.,? 2015", "shortCiteRegEx": "Zhang et al\\.", "year": 2015}, {"title": "Aligning Books and Movies: Towards Story-like Visual Explanations by Watching Movies and Reading Books", "author": ["Yukun Zhu", "Ryan Kiros", "Richard Zemel", "Ruslan Salakhutdinov", "Raquel Urtasun", "Antonio Torralba", "Sanja Fidler."], "venue": "Proceedings", "citeRegEx": "Zhu et al\\.,? 2015", "shortCiteRegEx": "Zhu et al\\.", "year": 2015}], "referenceMentions": [{"referenceID": 5, "context": "State-of-the-art methods in authorship attribution, which aims to determine an unknown text\u2019s author among a set of candidate authors, rely on low-level information such as character n-grams (Frantzeskou and Stamatatos, 2007).", "startOffset": 191, "endOffset": 225}, {"referenceID": 10, "context": "Recent approaches (Koppel et al., 2011) focus on largescale authorship attribution for thousands of authors, but are expensive during prediction, which is a deficit in on-line scenarios for purposes of targeted marketing, copyright enforcement, writing support, and search relevance, among others (Potthast et al.", "startOffset": 18, "endOffset": 39}, {"referenceID": 23, "context": "Furthermore, besides stylistic information, word-level topical information has been shown to be relevant for authorship attribution (Seroussi et al., 2011).", "startOffset": 132, "endOffset": 155}, {"referenceID": 11, "context": "Simultaneously, convolutional neural networks (CNNs) have achieved remarkable successes in computer vision (Krizhevsky et al., 2012) and speech recognition (Abdel-Hamid et al.", "startOffset": 107, "endOffset": 132}, {"referenceID": 1, "context": ", 2012) and speech recognition (Abdel-Hamid et al., 2012) and have been found particularly suitable for extract-", "startOffset": 31, "endOffset": 57}, {"referenceID": 3, "context": "They have also been shown to be effective for various NLP tasks (Collobert et al., 2011) and have achieved state-of-the-art in several sentence classification tasks (Kim, 2014).", "startOffset": 64, "endOffset": 88}, {"referenceID": 8, "context": ", 2011) and have achieved state-of-the-art in several sentence classification tasks (Kim, 2014).", "startOffset": 84, "endOffset": 95}, {"referenceID": 14, "context": "works and CNNs in NLP perform convolutions on the word level using pre-trained word embeddings (Mikolov et al., 2013).", "startOffset": 95, "endOffset": 117}, {"referenceID": 28, "context": "Recent approaches employ convolutions over characters (Zhang et al., 2015).", "startOffset": 54, "endOffset": 74}, {"referenceID": 25, "context": "We apply CNNs to the task of authorship attribution for four reasons: a) They have been shown to be excellent at leveraging character-level signals, which have been found to be indicative of authorial style (Stamatatos, 2009); b) they have excelled at differentiating between a large number of classes (Krizhevsky et al.", "startOffset": 207, "endOffset": 225}, {"referenceID": 11, "context": "We apply CNNs to the task of authorship attribution for four reasons: a) They have been shown to be excellent at leveraging character-level signals, which have been found to be indicative of authorial style (Stamatatos, 2009); b) they have excelled at differentiating between a large number of classes (Krizhevsky et al., 2012), which is key for large-scale authorship attribution; c) prediction is fast; and d) a combination of word and character input channels enables them to take topical information into account.", "startOffset": 302, "endOffset": 327}, {"referenceID": 6, "context": "puter vision, wave lengths in speech recognition (Hoshen et al., 2014).", "startOffset": 49, "endOffset": 70}, {"referenceID": 6, "context": "puter vision, wave lengths in speech recognition (Hoshen et al., 2014). Natural language input is typically single-channel in the form of tokens or characters. Kim (2014) observe that a static word channel is able to encode general semantic similar-", "startOffset": 50, "endOffset": 171}, {"referenceID": 28, "context": "outperform traditional classification methods on large-scale datasets (Zhang et al., 2015).", "startOffset": 70, "endOffset": 90}, {"referenceID": 7, "context": "morphemes) to which word-level CNNs are blind: Kim et al. (2016) feed the output of a character-level CNN to a recurrent neural language model and improve performance particularly for morphologically rich languages.", "startOffset": 47, "endOffset": 65}, {"referenceID": 18, "context": "Santos and Zadrozny (2014) use a CNN that associates a character embedding produced by a CNN for each word with its word representation to improve POS tagging performance for English and Portuguese, while Santos and Guimar\u00e3es (2015) use the same network to boost results for named entity recognition.", "startOffset": 205, "endOffset": 233}, {"referenceID": 25, "context": "The key notion behind statistical authorship attribution is that measuring textual features enables distinction between texts written by different authors (Stamatatos, 2009).", "startOffset": 155, "endOffset": 173}, {"referenceID": 20, "context": "(Sapkota et al., 2015), and character and word n-grams (Schwartz et al.", "startOffset": 0, "endOffset": 22}, {"referenceID": 22, "context": ", 2015), and character and word n-grams (Schwartz et al., 2013).", "startOffset": 40, "endOffset": 63}, {"referenceID": 9, "context": "cused on modeling an author\u2019s style: Kiros et al. (2014) condition word embeddings on attributes such as style and predict an author\u2019s age, gender, and industry.", "startOffset": 37, "endOffset": 57}, {"referenceID": 9, "context": "cused on modeling an author\u2019s style: Kiros et al. (2014) condition word embeddings on attributes such as style and predict an author\u2019s age, gender, and industry. Zhu et al. (2015) transform image captions into book sentences by subtract-", "startOffset": 37, "endOffset": 180}, {"referenceID": 10, "context": "culate pairwise distances between feature subsets (Koppel et al., 2011).", "startOffset": 50, "endOffset": 71}, {"referenceID": 5, "context": "Simultaneously, character ngrams have proven to be the single most successful feature (Frantzeskou and Stamatatos, 2007).", "startOffset": 86, "endOffset": 120}, {"referenceID": 5, "context": "Simultaneously, character ngrams have proven to be the single most successful feature (Frantzeskou and Stamatatos, 2007). Finally, Potthast et al. (2016) compare traditional approaches on small datasets, while we evaluate state-of-the-art as well as CNN-based methods for thousands of authors, thereby moving a step closer to the goal of authorship attribution at web-scale.", "startOffset": 87, "endOffset": 154}, {"referenceID": 3, "context": "The model architecture we use is an extension of the CNN structure used by Collobert et al. (2011). Its variant with two word embedding channels used by Kim (2014) is depicted in Figure 1.", "startOffset": 75, "endOffset": 99}, {"referenceID": 3, "context": "The model architecture we use is an extension of the CNN structure used by Collobert et al. (2011). Its variant with two word embedding channels used by Kim (2014) is depicted in Figure 1.", "startOffset": 75, "endOffset": 164}, {"referenceID": 7, "context": "Figure 1: Multi-channel CNN with two word channels from Kim et al. (2014)", "startOffset": 56, "endOffset": 74}, {"referenceID": 15, "context": "Note that b \u2208 R is a bias term and f is a nonlinear function, ReLU (Nair and Hinton, 2010) in our case.", "startOffset": 67, "endOffset": 90}, {"referenceID": 3, "context": "Max-over-time pooling (Collobert et al., 2011) in turn condenses this feature vector to its most important feature by taking its maximum value and naturally deals with variable input lengths.", "startOffset": 22, "endOffset": 46}, {"referenceID": 7, "context": "Using low-dimensional character embeddings as in Kim et al. (2016) decreased performance.", "startOffset": 49, "endOffset": 67}, {"referenceID": 23, "context": "The dataset is made available by Seroussi et al. (2011) on request.", "startOffset": 33, "endOffset": 56}, {"referenceID": 21, "context": "The Blog authorship dataset contains 681,288 blog posts of 19,320 bloggers gathered by Schler et al. (2005) from blogger.", "startOffset": 87, "endOffset": 108}, {"referenceID": 3, "context": "by Collobert et al. (2011).", "startOffset": 3, "endOffset": 27}, {"referenceID": 8, "context": "This is the multi-channel CNN proposed by Kim (2014).", "startOffset": 42, "endOffset": 53}, {"referenceID": 12, "context": "The dataset collected by Layton et al. (2010) is no longer available.", "startOffset": 25, "endOffset": 46}, {"referenceID": 16, "context": "with 300-dimensional GloVe vectors (Pennington et al., 2014) trained on 840B tokens of the Common Crawl corpus11.", "startOffset": 35, "endOffset": 60}, {"referenceID": 2, "context": "\u2022 SVM+Stems: an SVM classifier, which distinguishes authors based on word stems rather than bag-of-words (Allison and Guthrie, 2008).", "startOffset": 105, "endOffset": 132}, {"referenceID": 5, "context": "file (SCAP) method (Frantzeskou and Stamatatos, 2007) determines authorship based on the intersection of the most frequent character n-grams of an unknown text and an author\u2019s profile, i.", "startOffset": 19, "endOffset": 53}, {"referenceID": 10, "context": "\u2022 Imposters: the Imposters Method (Koppel et al., 2011) is based on the intuition that the profile of an unknown text\u2019s author is likely to be most similar to the unknown text most often as the feature set varies.", "startOffset": 34, "endOffset": 55}, {"referenceID": 23, "context": "\u2022 LDAH-S: LDA Hellinger Single-Document, the top-performing method of Seroussi et al. (2011) uses Hellinger distance between the LDA topic distributions for an unknown text and an author\u2019s profile as a measure for authorship.", "startOffset": 70, "endOffset": 93}, {"referenceID": 2, "context": "Results for SVM+Stems have been reported on the Email dataset (Allison and Guthrie, 2008) and results for Imposters and LDAH-S have been reported on the IMDb62 and Blog dataset (Seroussi", "startOffset": 62, "endOffset": 89}, {"referenceID": 27, "context": "update rule (Zeiler, 2012) as it allows us to pay special attention to infrequent features that can be, however, highly indicative of certain authors.", "startOffset": 12, "endOffset": 26}, {"referenceID": 25, "context": "The corpus domain has a big impact on a model\u2019s performance and often requires domain-specific feature engineering (Stamatatos, 2009).", "startOffset": 115, "endOffset": 133}, {"referenceID": 28, "context": "We use the same vocabulary as Zhang et al. (2015), but distinguish between lower-case and upper-case characters and convolve all numbers into one as both measures increase performance.", "startOffset": 30, "endOffset": 50}, {"referenceID": 25, "context": "Past studies (Stamatatos, 2009; Schwartz et al., 2013) highlighted challenges for short text authorship attribution, such as the number of authors, the training set size, and the size of the test document.", "startOffset": 13, "endOffset": 54}, {"referenceID": 22, "context": "Past studies (Stamatatos, 2009; Schwartz et al., 2013) highlighted challenges for short text authorship attribution, such as the number of authors, the training set size, and the size of the test document.", "startOffset": 13, "endOffset": 54}, {"referenceID": 26, "context": "with the community; posts thus often reflect the character of the thread rather than the character of the user and often contain stylistically conspicuous features such as irony (Wallace et al., 2015).", "startOffset": 178, "endOffset": 200}, {"referenceID": 24, "context": "Moreover, CNNs show aptitude to handle the class imbalance problem (Stamatatos, 2007) inherent in real-world applications by significantly outperforming the comparison methods on all datasets with imbalanced numbers of documents per author (see Table 1) in line with findings by Potthast et al.", "startOffset": 67, "endOffset": 85}, {"referenceID": 24, "context": "Moreover, CNNs show aptitude to handle the class imbalance problem (Stamatatos, 2007) inherent in real-world applications by significantly outperforming the comparison methods on all datasets with imbalanced numbers of documents per author (see Table 1) in line with findings by Potthast et al. (2016).", "startOffset": 68, "endOffset": 302}, {"referenceID": 0, "context": "For this reason, they are particularly suited for conducting a large or recurring number of predictions in on-line scenarios such as attributing messages to known terrorists (Abbasi and Chen, 2005).", "startOffset": 174, "endOffset": 197}, {"referenceID": 5, "context": "Similarly to Frantzeskou and Stamatatos (2007), we find that increasing the profile size of an author\u2019s concatenated known texts consistently increases performance for n-gram based similarity", "startOffset": 13, "endOffset": 47}, {"referenceID": 12, "context": "The optimal profile size for our datasets, 14,000, however, is considerably higher than past values reported for this hyperparameter (Layton et al., 2010) (Layton et al.", "startOffset": 133, "endOffset": 154}, {"referenceID": 13, "context": ", 2010) (Layton et al., 2012), suggesting that larger ranges should be considered in future research.", "startOffset": 8, "endOffset": 29}, {"referenceID": 25, "context": "We have found that restricting the vocabulary size by selecting only the 30,000 most frequent space-free character n-grams for the Imposters method generally increased performance as frequency is the most important criterion for selecting features in authorship attribution (Stamatatos, 2009).", "startOffset": 274, "endOffset": 292}, {"referenceID": 23, "context": "13 Even though we improve performance for Imposters on the IMDb dataset in comparison to Seroussi et al. (2011) by selecting appropriate hyperparameters, we are unable to achieve competitive scores using the more recently proposed authorship attribution methods, Imposters", "startOffset": 89, "endOffset": 112}, {"referenceID": 28, "context": "To mitigate this deficit, CNNs can a) be made more expressive by adding more layers (Zhang et al., 2015); or b) can be interpolated with n-grams that capture clear n-gram-author corre-", "startOffset": 84, "endOffset": 104}, {"referenceID": 10, "context": "Note that we evaluate \u2013 in contrast to Koppel et al. (2011) and Seroussi et al.", "startOffset": 39, "endOffset": 60}, {"referenceID": 10, "context": "Note that we evaluate \u2013 in contrast to Koppel et al. (2011) and Seroussi et al. (2011) \u2013 using F1, which penalizes low recall.", "startOffset": 39, "endOffset": 87}], "year": 2016, "abstractText": "Convolutional neural networks (CNNs) have demonstrated superior capability for extracting information from raw signals in computer vision. Recently, characterlevel and multi-channel CNNs have exhibited excellent performance for sentence classification tasks. We apply CNNs to large-scale authorship attribution, which aims to determine an unknown text\u2019s author among many candidate authors, motivated by their ability to process characterlevel signals and to differentiate between a large number of classes, while making fast predictions in comparison to state-ofthe-art approaches. We extensively evaluate CNN-based approaches that leverage word and character channels and compare them against state-of-the-art methods for a large range of author numbers, shedding new light on traditional approaches. We show that character-level CNNs outperform the state-of-the-art on four out of five datasets in different domains. Additionally, we present the first application of authorship attribution to reddit. Finally, we release our new reddit and Twitter datasets for further research.", "creator": "LaTeX with hyperref package"}}}