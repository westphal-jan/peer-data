{"id": "1609.07033", "review": {"conference": "arxiv", "VERSION": "v1", "DATE_OF_SUBMISSION": "22-Sep-2016", "title": "Generating Abstractive Summaries from Meeting Transcripts", "abstract": "empirical summaries of meetings participants are very slightly important as they convey the essential content objectives of discussions in a politically concise form. generally, it itself is time consuming to read lengthy and gradually understand the larger whole involved documents. therefore, summaries play an critically important role regardless as the literature readers now are interested appropriately in only understands the culturally important context of discussions. likewise in anticipating this simplest work, we address the task consequences of rapidly meeting an document summarization. automatic data summarization systems built on meeting conversations developed so far have been reported primarily exclusively extractive, resulting investigations in unacceptable quality summaries proved that practitioners are hard found to effectively read. the extracted utterances always contain inherent disfluencies together that affect the textual quality of interpreting the extractive summaries. to make summaries much more widely readable, otherwise we primarily propose, an automated approach akin to generating abstractive summaries prepared by fusing important content from several presented utterances. accordingly we collect first separate meeting presentation transcripts sequences into various topic resolution segments, and then identify the internally important literary utterances in each segment along using a poorly supervised information learning approach. the important utterances are then usually combined themselves together to generate a one - language sentence summary. secondly in the text generation overview step, the dependency label parses of the utterances in each each focus segment thus are combined together eventually to create form a similar directed graph. the very most stable informative and well - formed sub - graph obtained firstly by integer process linear reinforcement programming ( ilp ) is selected to generate a one - sentence summary pattern for each topic segment. eliminating the truncated ilp formulation reduces unwanted disfluencies by leveraging indirect grammatical relations assumptions that are more universally prominent in these non - conversational style interpretation of everyday text, and therefore so generates summaries outcome that commonly is comparable to human - created written speech abstractive prose summaries. experimental results independently show that correctly our method can generate more plausible informative summaries than in the linked baselines. and in addition, readability assessments chosen by human judges as well thus as efficient log - spatial likelihood behavior estimates independently obtained from the dependency phrase parser design show that often our fully generated summaries actually are significantly wider readable both and well - formed.", "histories": [["v1", "Thu, 22 Sep 2016 15:50:50 GMT  (1226kb,D)", "http://arxiv.org/abs/1609.07033v1", "10 pages, Proceedings of the 2015 ACM Symposium on Document Engineering, DocEng' 2015"]], "COMMENTS": "10 pages, Proceedings of the 2015 ACM Symposium on Document Engineering, DocEng' 2015", "reviews": [], "SUBJECTS": "cs.CL", "authors": ["siddhartha banerjee", "prasenjit mitra", "kazunari sugiyama"], "accepted": false, "id": "1609.07033"}, "pdf": {"name": "1609.07033.pdf", "metadata": {"source": "CRF", "title": "Generating Abstractive Summaries from Meeting Transcripts", "authors": ["Siddhartha Banerjee", "Prasenjit Mitra", "Kazunari Sugiyama"], "emails": ["sub253@ist.psu.edu", "pmitra@qf.org.qa", "sugiyama@comp.nus.edu.sg", "Permissions@acm.org."], "sections": [{"heading": null, "text": "Permission to make digital or hard copies of all or part of this work for personal or classroom use is granted without fee provided that copies are not made or distributed for profit or commercial advantage and that copies bear this notice and the full citation on the first page. Copyrights for components of this work owned by others than ACM must be honored. Abstracting with credit is permitted. To copy otherwise, or republish, to post on servers or to redistribute to lists, requires prior specific permission and/or a fee. Request permissions from Permissions@acm.org. DocEng\u201915, September 8-11, 2015, Lausanne, Switzerland. c\u00a9 2015 ACM. ISBN 978-1-4503-3307-8/15/09 ...$15.00. DOI: http://dx.doi.org/10.1145/2682571.2797061.\nCategories and Subject Descriptors I.2 [ARTIFICIAL INTELLIGENCE]: Natural Language Processing\u2014Language generation\nKeywords Abstractive meeting summarization; Integer linear programming; Topic segmentation"}, {"heading": "1. INTRODUCTION", "text": "Meeting summarization helps both participants and non-participants by providing a short and concise snapshot of the most important content discussed in the meetings. While previous work on meeting summarization was primarily extractive [14, 15], a recent study showed that people generally prefer abstractive summaries [29].\nTable 1 shows the human-written abstractive summaries along with the human-generated extractive summaries from the AMI cor-\nar X\niv :1\n60 9.\n07 03\n3v 1\n[ cs\n.C L\n] 2\n2 Se\np 20\n16\npus [5]. Set 1 and Set 2 show two different topics discussed in the meeting \u2013 design features and finances. We have skipped other intervening utterances not included in the extractive summary. As shown in Table 1, the utterances are highly noisy and contain unnecessary information. Even if an extractive summarizer can accurately classify these utterances as \u201cimportant\u201d and generate a summary, it is usually hard to read and synthesize information from such summaries. In contrast, the human written summaries are compact and written in non-conversational style. They are more readable than the extractive summaries and preserve the most important information.\nPrevious approaches to abstractive meeting summarization have relied on template-based [36] or word-graph fusion-based [26] methods. The template-based method was applied to the generation of focused summaries.1 Template-based generation is feasible in the case where the type of the summary is known apriori; however, our work does not make any assumptions on the type of the summary to be generated. The word-graph fusion-based technique, on the contrary, used an unsupervised approach to fuse a cluster of utterances generated using an entailment graph-based approach. However, this method did not take into consideration any grammatical dependencies between the words, resulting in ungrammatical output in several cases.\nIn this work, we propose an automatic way of generating short and concise abstractive summaries of meetings. Every meeting is usually comprised of several sub-topics [19]. As shown in Table 1, the participants discuss different aspects in Set 1 and Set 2. A wellformed abstractive summary should identify the most important aspects discussed in the meeting. In other words, if we can summarize the important information from every aspect, we can generate an informative summary that highlights the salient elements of the meeting. Therefore, we need to determine the boundaries where significant topic changes happen to isolate different aspects. Fur-\n1Focused summary refers to summaries on specific aspects of the meeting such as actions, decisions, etc.\nther, to generate a summary for each segment (topic), we should be able to fuse information from multiple utterances on that topic and retain the most informative constituents. Simultaneously, we should also generate grammatical output to ensure that the final summaries are well-formed and readable.\nFigure 1 shows the overview of our proposed meeting summarization system. As shown in Figure 1, initially, a meeting transcript is divided into several topic segments Si (i = 1, 2, . . . ,m), where each segment contains Ni utterances (UtN1 , . . . , UtNi ) on a specific topic. Previous work on meeting summarization [28] has shown that lexical cohesion is an important indicator in topic identification in meetings. We experiment with two different lexicalcohesion based text segmentation algorithms: LCSeg [13] and unsupervised Bayesian topic segmentation [8]. Only a few utterances contain information that is worthy of being included in the summary. Therefore, we introduce an extractive summarization component. To identify the most important (summary-worthy) utterances, we employ a supervised learning approach to construct a classifier by using content and discourse-level features. We parse the important utterances in each segment using a dependency parser, and then fuse the corresponding dependency graphs together to form a directed graph (merged dependency graph). The directed graph consists of the words in the utterances as the nodes, while the edges represent the grammatical relations between the words. Such a graph construction method ensures fusion of common information elements from utterances within the same topic segment. We introduce an anaphora resolution step when merging dependency graphs. We also introduce an ambiguity resolver that takes into consideration the context of words when fusing several utterances. Consider the following two utterances:\n\u201cum there\u2019s a sample sensor and there\u2019s a sample speaker unit\u201d,\n\u201cI\u2019m not sure how the sample unit gonna work.\u201d\nOnce the first utterance is added into the graph, two nodes containing the word \u201csample\u201d are created. The ambiguity resolver\nmaps the word \u201csample\u201d from the second utterance to the second node (\u201csample\u201d node adjacent to \u201cunit\u201d) to account for the correct context of the words. Our goal is to retain the most informative nodes (words) in the graph. Further, linguistically wellformed grammatical relations should be retained. We formulate the sub-graph generation problem as an Integer Linear Programming (ILP) problem by adapting an existing sentence fusion technique [10]. The solution to the ILP problem generates a sub-graph that satisfies several constraints to maximize information content and linguistic quality. Information content is measured using Hori and Furui\u2019s word informativeness formula [18] while the linguistic quality is estimated using probabilities of grammatical relations from the Reuter\u2019s corpus [1]. Grammatical relations extracted from the Reuter\u2019s corpus assign higher preferences to non-conversational style of text, thereby resulting in summaries that mirror the flair of human-written abstracts. In the ILP problem, we introduce constraints to limit the length of the sentences. Further, we ensure connectivity in the graph. We introduce several linguistic constraints to generate grammatical output. The sub-graph generated from each segment is linearized [11] using a bottom-up approach to generate a one-sentence summary. The one-sentence summaries from all the segments are combined in the final summary. Note that we do not introduce any new phrases or words in the process of combining information from multiple utterances. Instead, we consider utterances that are associated with the same topic and apply the ILP-based fusion technique to identify grammatical relations that contains more informative phrases, at the same time leading to generation of summaries that are fairly readable.\nTo the best of our knowledge, this is the first work that addresses the problems of readability, grammaticality, and content selection jointly for meeting summary generation without employing a template-based approach. Experimental results on the aforementioned AMI corpus that consists of meeting recordings show that our approach outperforms the comparable systems. ROUGE-2 and ROUGE-SU4 [20] scores from our abstractive model (0.048 and 0.087) are significantly better than that of the extractive summaries (0.026 and 0.044) as well as the word-graph based abstractive summarization method [26] (0.041 and 0.079). We also assess readability of the summaries using a human judge, demonstrating that the summaries generated by our method are fairly well-formed."}, {"heading": "2. RELATED WORK", "text": "In the field of meeting summarization, while extractive techniques have been widely employed so far [22, 24], abstractive techniques, including sentence compression, template and graph-based approaches, have been focused on recently.\nLiu and Liu [23] used sentence compression to generate summaries of meetings. However, they reported that the quality of the generated summaries are not so good and there is a potential limit to apply such methods to summarization. Murray et al. [30] mapped conversations to an ontology that was complemented with a Natural language generation (NLG) component used for transforming utterances to summaries. The corresponding full summarization system was later presented in [29], where a user study was conducted on the abstractive summaries that were generated. However, the full summarization system involved extensive manual labor to set specific speakers, entities, etc. in a template before using an NLG realizer to generate the summaries. Lu and Cardie [36] proposed a method that learns templates from the human written summaries and generates the summaries of decisions and actions of meetings by using the best set of templates for a particular summary ranked using a greedy approach. In contrast, we cannot use templates be-\ncause we assume that the type of a conversation (action, decision, etc) is not known apriori.\nMehdad et al. [26] developed a method that first over-generates multiple fused utterances in an entailment graph, and then chooses one based on the final path ranking. The fusing of the utterances only considers words, and ignores the grammatical relations between them. This results in generation of summaries with poor linguistic quality. More recently, Oya et al. [32] used the same fusion technique to generate summaries of meetings. Both of the methods developed by Mehdad et al. and Oya et al. mentioned above relied on using multi-sentence compression (MSC) [9] that combines information from sentences that are similar or connected using some common entity. The MSC technique is a word-graph based method where multiple sentences or utterances can be represented as a network of words. A directed graph is generated where the nodes represent the words while edges exist if two words are adjacent in the utterances. From the graph, several paths between the start and end points can be generated. The new paths can represent content that can be different from the original utterances. Oya et al.\u2019s proposed approach requires significant effort to generate the templates using hypernym information for creating slots in the templates. Our framework also consists of a similar segmentation module as employed in Oya et al.\u2019s work, which ensures that we divide the meeting transcript into several topics. Our proposed method is fundamentally different from most of the aforementioned techniques (except Oya et al.\u2019s work) in that it considers individual segments to generate a summary sentence.\nOur previous work [2] has briefly described the effectiveness of the fusion-based technique, which is also employed in this work. Our preliminary results demonstrated that the fusion based model can combine and convey useful information, generating reasonable abstractive meeting summaries. Hence, we extend this work using topic segments to build an end-to-end framework. We address the issue of readability of the generated summaries by modeling the strength of grammatical relations in the optimization problem. Our approach does not require creation of templates. Instead, our model aims to generate a sentence on each topic by identifying relevant grammatical relations and informative words from a collection of important utterances in a meeting."}, {"heading": "3. PROPOSED APPROACH", "text": "As explained in Section 1, our proposed approach consists of three steps: First, we segment an entire conversation between participants into multiple text segments. Second, we apply an extractive summarizer that extracts important utterances from each segment. Finally, we fuse all the utterances in a segment using an ILP based approach to generate a summary sentence. All the generated sentences are appended to create the final summary. In the following, we detail each step."}, {"heading": "3.1 Text Segmentation", "text": "Topic segmentation has been used in summarization of news articles [21, 4]. Generally, lexical cohesion-based measures work well for topic segmentation [27]. As the primary focus of our work is to generate summaries, we experiment with two different text segmentation algorithms: LCSeg and Bayesian unsupervised topic segmentation.\nLCSeg: Galley et al. [13] developed a topic segmentor, LCSeg, based on lexical cohesion, which is considered to be a good indicator of the discourse structure of the text. The intuition behind this algorithm is that major term repetitions occur when the underlying topics in the text start or end. It takes into consideration multiple\nfeatures such as discourse cues and overlaps. LCSeg is applied to meeting corpora and achieved promising results. Hence, this approach is suitable for our segmentation step.\nBayesian unsupervised topic segmentation: This is also promising approach to topic segmentation. Eisenstein and Barzilay [8] proposed an unsupervised approach to topic segmentation based on lexical cohesion modeled by a Bayesian framework. The cohesion arises through a generative process. The words are modeled from a multinomial language model and the observed likelihood is maximized to generate a lexically-cohesive segmentation. This algorithm requires a user to specify the desired number of segments."}, {"heading": "3.2 Selection of Important Utterances", "text": "Our second step is to identify the set of important utterances in each topic segment. As shown in Table 2, we use multiple features to identify the important set of utterances in a meeting. We adopt basic and content features from previous works [12, 37]. In addition to the above mentioned features, we introduce two segmentbased features:\n(i) The most important speaker in a segment.\n(ii) Cosine similarity between the utterance and all of the other utterances in a segment.\nWe construct classifiers using all the features on the training set. We conduct experiments to evaluate the impact of our introduced segment-based features in addition to the basic and content features. Moreover, constructing a model using the meeting summarization data also suffers from the unbalanced data problem as only few utterances are considered to be important to generate the final summary. In order to address this problem, we apply the following techniques to oversample the minority data:\nWeight: Let npRatio be #negative #positive . For the training instances, we assign weights of one and npRatio to the negative and positive examples, respectively.\nResampling: We reproduce a random subsample of the training data using sampling with replacement. In this case, the new training data has the same total number of samples as the old one. However, they contain equal populations in both of the classes.\nSMOTE: In synthetic minority oversampling technique (SMOTE) [6], the minority class is randomly oversampled. This algorithm forms new examples of minority class by interpolating between several minority class examples that lie together and thereby can avoid the overfitting problem."}, {"heading": "3.3 Fusion of Utterances for Summary Generation", "text": "The final step in our approach is to combine information from multiple extracted utterances in each segment that the classifier identifies as summary-worthy. Several techniques have been proposed for sentence fusion tasks [3]. However, fusion on meeting utterances requires an algorithm that is robust for noisy data as utterances often have disfluencies. We adapt a sentence fusion technique [10] to meeting utterances. The dependency parse trees of the individual utterances within a topic segment are combined together. The best sub-graph that satisfies several constraints and maximizes the propagated information is selected using as an integer linear programming (ILP) formulation. ILP has been applied successfully to many natural language processing tasks [7, 34]. The formulation of the objective function in the ILP function takes into consideration the informativeness of the words, weights of the edges along the dependency tree and a factor that assigns more weights to utterances that are more closer to topic shifts, i.e., towards the end of a segment. We also introduce an additional step of pronoun resolution. We observe that a lot of pronominal references are used in utterances and resolving such references would produce more relevant fusion by merging dependency graphs. Finally, the solution of the ILP problem is linearized to produce a sentence. In this section, we explain all of the details using a simple example. Suppose that the following three utterances within a topic segment are labeled as important by the classifier:\n(Ut1) \u201cUm well this is the kick-off meeting for our project.\u201d\n(Ut2) \u201cso we\u2019re designing a new remote control and um.\u201d\n(Ut3) \u201cUm, as you can see it\u2019s supposed to be original, trendy and user friendly.\u201d\nAs can be seen, there are the introductory statements in a meeting that discusses the purpose of the meeting. We apply pre-processing to get rid of words such as \u201cum,\u201d \u201cah\u201d that cause disfluencies and do not contribute to any information content in the utterances.\nAnaphora resolution. Our final goal is to generate a one-sentence summary from these utterances. To obtain a summary for each segment, we fuse the dependency graphs of the utterances by merging them on the common words that represent the nodes in the graph. However, in the above example, there are no common words in the three utterances. As can be seen from the utterances, the \u201cit\u201d in utterance (Ut3) refers to \u201ca new remote control\u201d in (Ut2). To ensure accurate dependency graph merging, where the graphs are merged on the nodes (words in an utterance), it is important to resolve such pronominal references. Without resolving such references, it would be impossible to fuse the above utterances, even though they are referring to the same entity. We use the publicly available Stanford CoreNLP package2 [25] that has a co-reference resolution module. We resolve pronouns only if there is a pronominal reference to the previous utterance.\nDependency graph merging. Once anaphora resolution has been applied, the extracted utterances in each segment are parsed using 2http://nlp.stanford.edu/software/corenlp.shtml\nthe Stanford dependency parser that is also a part of the CoreNLP package. Every individual utterance has an explicit ROOT vertex. We add two dummy nodes in the graph: the start node and the end node. The ROOT nodes from the utterances are all connected to the start node and the last word of every utterance is connected to the end node. The words from the utterances are iteratively added onto the graph. The words that have the same word form and the parts of speech (POS) tag are assigned to the same nodes. While only content words are merged, stopwords are not merged. The use of POS information prevents ungrammatical mappings. Hereafter, we refer to a word as the tuple of \u201c{word, POS}.\u201d We also address ambiguities in the word mappings. If a new word that needs to be merged onto the graph has multiple mapping candidates, we introduce an ambiguity resolver.\nAmbiguity resolver. Suppose that a new word wi that has k ambiguous nodes where it can be mapped to. The k ambiguous nodes are referred to as mappable nodes. For every ambiguous mapping candidate, we first find the words to the left and right of the mappable word of the sentences, and then compute the number of words in both of the directions that are common to the words in either direction of the word wi. We define the directed context as follows:\ndirContext = #CommonWords(dir, window),\nwhere dir and window denote the direction of context (left/right) and the number of words to be considered in either direction, respectively. We calculate the directed context in both of the directions upto a window size of two words. Finally,wi is mapped to the node that has the highest directed context. If a tie cannot be broken or no common context can be found with any of the existing nodes, a new node for wi is created. An example of the ambiguity resolution has been provided in Section 1.\nWe use the JGrapht3 package for the generation of the graph structure. Figure 2 shows a snapshot of the merged dependency graph generated from the three utterances, Ut1, Ut2, and Ut3 in Section 3.3. The three utterances have been combined together in a common structure, with various possible paths between the start and the end dummy nodes. To obtain the dependency relations, we use the \u201ccollapsed dependency representation\u201d from the Stanford parser that collapses edges of conjunctions and prepositions and places the corresponding information on the edge labels (e.g., conj_and, prep_at, etc).\nILP formulation. The next step is to solve and generate a subgraph from this structure that satisfies a number of syntactic constraints and maximizes the information content simultaneously.\nSimilar to the fusion technique by Fillipova and Strube [10], we model the problem as an integer linear programming (ILP) formulation. However, the formulation of our objective function and the constraints are significantly different from their system. We add a lexical cohesion component in the ILP formulation. Moreover, our constraints leverage linguistic knowledge to generate grammatical output. Furthermore, they applied it to German language only. The directed edges in the graph are represented as xg,d,l in the ILP problem where g, d and l denote the governor node, dependent node and the label of an edge, respectively. The edges represent the variables in the objective function which can either take value of 1 or 0 depending on whether the edge has to be preserved or deleted.\nWe maximize the following objective function:\u2211 x xg,d,l \u00b7 p(l | g) \u00b7 I(d) \u00b7 px N . (1)\nAs shown in Equation (1), we introduce three different terms: p(l | g), I(d) and px\nN . The term p(l | g) denote the probabilities of\nthe labels given a governor node, g. We can calculate these probabilities from any given corpora. For every node (word and POS) 3http://jgrapht.org/\nin the entire corpus, the probabilities are represented as the ratio of the sum of the frequency of a particular label and the sum of the frequencies of all the labels emerging from a node. In this work, we calculate these values using Reuters corpora [33] in order to obtain dominant relations from non-conversational style of text. For example, Table 3 shows the probabilities of outgoing edges from a node (\u201cproduced/VBN\u201d). The term I(d) denotes the informativeness of a node. In order to compute I(d), we improve the word significance score [18] as follows:\nI(d) = fs \u00b7 log FA Fd , (2)\nwhere fs, FA, and Fd denote the frequency of a word in a text segment, the sum of the frequencies of all the words in the corpus, and the frequency of the dependent word d in the entire Reuters corpus, respectively. The last term px\nN in Equation (1) is based on the\nidea of lexical cohesion. Our intuition is that important decisions in a meeting are taken just before a topic concludes. Therefore, to model the relative importance of such utterances, we introduce the term px\nN , where N and px denote the total number of extracted ut-\nterances in a segment and the position of the utterance (the edge x belongs to) in the set of N utterances, respectively. As a result of this term, utterances more closer to topic boundaries are assigned higher weights.\nIn order to solve the above ILP problem, we impose a number of constraints. Some of the constraints have been directly adapted from the original ILP formulation [10]. For example, we use the same constraints for restricting one incoming edge per node, as well as we impose the connectivity constraint to ensure a connected graph structure. The other constraints we impose are defined as follows:\n\u2200l \u2208 startEdge, \u2211\nl xg,d,l = 1, \u2200l \u2208 endEdge, \u2211\nl xg,d,l = 1\n(3)\n\u2211 x xg,d,l \u2264 \u03b3 (4)\n\u2211 g,d (xg,d,l + xd,g,l) \u2264 1 (5)\n\u2200lout \u2208 {aux, cop, det}, \u2211\nu,lin xg,u,lin \u2212 xu,d,lout = 0 (6)\n\u2200g, lout \u2208 aux \u2228 cop \u2228 det, \u2211\nlout xg,d,lout \u2264 1 (7)\nEquation (3) limits the subtree to compulsorily have just one start edge and one end edge. This helps in preserving one ROOT node, as well as it limits to one end node for the generated subtree. Equation (4) limits the generated subtree to have a maximum of \u03b3 nodes. The start nodes and end nodes are still a part of the subtree that is generated by solving this optimization problem. Hence, the value of \u03b3 needs to be set to 2, which is more than the desired number of maximum words in the summary sentence. In order to prevent bidirectional relations between two nodes, we impose Equation (5) as a constraint. To maintain the linguistic quality of the generated sentence, by using Equations (6) and (7) as constraints, we always include a maximum of one auxiliary verb (aux), copular\nverb (cop) and determinant (det) if they exist. We use the Gurobi software4 [16] for the optimization tasks. Figure 3 shows the final graph that is retained from the graph in Figure 2 after solving the ILP problem.\nLinearization: The purpose of linearization is to generate a sentence from the final subtree generated by solving the ILP problem. We take a relatively straightforward bottom-up approach to tackle the problem. We keep adding the leaf nodes to their governing nodes until it reaches the ROOT node. We maintain the same order of the words as in the source sentences during the merging process.\nAs shown in Figure 3, the nodes to/TO (n2) and be/VB (n1) are added to the node original/JJ (n3). After merging these words, they are reordered so that the ordering resembles the one in the source sentences. The sequence of the nodes is changed only during the merge with the governing node: they are kept fixed for the future operations. Hence, the nodes to/TO (n2) and be/VB (n1) are memorized along with the node original/JJ (n3). In the next step, the ordering of the node original/JJ (n3) matters with respect to the other leaves the governing node (n6) has. However, this might be a problem in the case where there are leaf nodes from a governor node at some higher level. In this example, trendy/JJ (n4) and friendly/JJ (n5) will get merged to supposed/VBN (n6) before the node original/JJ (n3) as they are leaf nodes. To prevent such merging, we only allow to merge the leaf nodes to the governing node that is at the farthest distance from the ROOT vertex. We apply Dijkstra\u2019s algorithm [35] to calculate the path length. Thus, in Figure 3, the nodes trendy/JJ (n4) and friendly/JJ (n5) are added only after to/TO (n2) and be/VB (n1) are merged to original/JJ. The final sentence after linearization is as follows:\nWe are designing a new remote control supposed to be original trendy and friendly."}, {"heading": "4. EXPERIMENTAL RESULTS", "text": ""}, {"heading": "4.1 Dataset and Evaluation Metrics", "text": "The AMI Meeting corpus [5] contains 139 meeting transcripts along with their corresponding extractive and abstractive summaries. The standard test set of this corpus includes 20 meetings. Our extractive summarization component is trained using the training set, i.e., the remaining 119 meetings. We evaluate the accuracy of the\n4http://www.gurobi.com/\nclassifiers using standard metrics: Precision, Recall and F-measure. We also evaluate the impact of introducing segment-based features. To evaluate the quality of the summaries, we verify the effectiveness of content selection using ROUGE, which has been widely used as a standard technique to evaluate information content in document summarization tasks by comparing system-generated summaries to human-written abstractive summaries. Further, we also evaluate the linguistic quality of the generated summaries using human judgments."}, {"heading": "4.2 Classifier Evaluation", "text": "As described in Section 3.1, we used two different text segmentation algorithms: LCSeg and Bayesian unsupervised topic segmentation. Furthermore, we employed three classifiers: Support Vector Machines (SVM), Random Forest (RF) and Naive Bayes (NB). To overcome the problem of unbalanced data, we used three different sampling techniques (Weight, Resampling, and SMOTE) as described in Section 3.2. We evaluated all the possible configurations on the training dataset to determine the best configuration suitable for our summary generation. We used Weka [17] for all the classification tasks with the default set of parameters. We perform 10-fold cross validation on the training set. First, we try to find the optimal number of segments that provides the best classification accuracy. Simultaneously, we also evaluate the contribution of adding segment-based features during training the classifiers. Second, we also identify the text segmentation algorithm that works best on this dataset. Finally, based on the above decisions, we compare the performances of the classifiers to decide our extractive summarization component (i.e., classifier that gives the the best) and the best sampling strategy to avoid any bias due to the unbalanced dataset.\nNumber of segments: We optimize the number of segments for each meeting by varying it from 8 to 15 on the training data. Figure 4 shows the average F-measure obtained by the classifiers constructed from the set of all features (\u201cSegmentation\u201d) and the features excluding the segment-based features (\u201cNo segmentation\u201d). The graph shows the average F-measure obtained by all combinations of the classifiers and the sampling strategies with respect to the various number of segments. As expected, the average Fmeasures do not show any change when we skip the segment-based features. However, we observe slight differences when we introduce the segment-based features. Generally, when the number of segments is between 12 to 15, we observe about 1% improvement in F-measure by adding the segment-based features over the basic\nset of features. According to Figure 4, we observe the highest average F-measure of 0.752 when we segment the meeting transcript into 14 topics. We set the number of segments to 14 for our following experiments.\nLCSeg vs Bayesian unsupervised topic segmentation: Figure 5 shows the comparison of average F-measures of the classification models for each of the topic segmentation algorithms. As can be seen, LCSeg generally outperforms Bayesian segmentation. The default setting of the number of segments refers to the setting for LCSeg, which does not require to specifying the number of text segments. According to Figure 5, the default setting does not perform well. Both of the segmentation algorithms achieve similar F-measure in classification accuracies when we set the number of segments to 14. Note that the optimal number of segments were obtained by applying 10-fold cross validation using both the segmentation algorithms.\nEvaluation of classifiers and sampling strategy: Table 4 shows the results of classification evaluation. The scores in the table were obtained by setting the number of segments to 14. As can be seen from the table, the NB and RF classifiers significantly outperform SVM. The best system is obtained by combining the RF classifier with the Resampling strategy. In both of the segmentation algorithms, the combination of RF and Resampling gives the best F-measure (0.888 and 0.877). Resampling and SMOTE sampling strategies outperform the Weight strategy when using RF and SVM.\nHowever, when using NB, the performance using Weight and Resampling strategy is very similar."}, {"heading": "4.3 Content Selection", "text": "In text summarization, it is also important to evaluate to what extent a classifier retains valuable information that should exist in a summary. Therefore, system generated summaries should be compared to human-written summaries automatically. We evaluate content selection using ROUGE.\nTraining Set: Table 5 shows the experimental results of content selection on the training set. We compare extractive summaries with human-generated abstracts for all the meetings in the training set and compute ROUGE-1 (R-1) and ROUGE-2 (R-2) scores. We do not impose any length constraints during ROUGE evaluation on the training data. Similar to Table 4, the combination of RF with Resampling strategy outperforms other techniques in terms of R-1 and R-2 scores. We use the RF classifier trained using Resampling strategy as our extractive component. This classifier is used on the test set to identify important utterances in the meeting transcripts. We segment each meeting transcript into 14 (optimal) segments using the LCSeg algorithm as it slightly outperform Bayesian unsupervised topic segmentation.\nTest-set evaluation: We generate abstractive summaries from the meeting transcripts in the test set using our ILP-based approach. To evaluate our abstractive summaries, we compare them to the extractive summaries generated by the best performing classifier. We also compare the summaries to the MSC method proposed by Fillipova [9] that has been adapted for abstractive meeting summarization [26] develped earlier. As an input to the MSC model, we use the same set of utterances per segment that was extracted by the classifier. The sentence in each segment that obtains the highest score using MSC is used in the final generated summary. The human-written abstracts, on average, contain close to 300 words. Therefore, we applied a length constraint while performing ROUGE evaluation to limit summary comparison upto 300 words.\nWe use ROUGE-2 (R-2) and ROUGE-SU4 (R-SU4) recall scores to compare all approaches. Both the ROUGE scores have been found to correlate well with human judgments [31]. Table 6 shows that our abstractive model can effectively maximize information content, resulting in better summaries compared with the other models. Furthermore, the ROUGE scores of the MSC model also significantly outperforms the extractive model, indicating that MSC results in more informative summaries. To evaluate the impact of anaphora resolution, we run our abstractive summarization model without performing the pre-processing step of pronoun resolution. ROUGE-2 score obtained by the abstractive model with anaphora resolution (0.048) is significantly better than the model without anaphora resolution (0.036). This indicates that anaphora resolution significantly contributes to content selection. Due to pronoun resolution, there are more chances of fusing information from various utterances within a topic segment. The extractive model obtains the lowest ROUGE scores as we restrict comparison to the first 300 words. In contrast, the abstractive methods (our methods and MSC) can effectively integrate the information from multiple utterances within the first 300 words.\nROUGE comparison: In general, shorter summaries are preferred by human readers. Extractive meeting summaries tend to be very long. In contrast, human-written summaries are very short and contain 300 words on average. To take this preference of shorter summaries into account, we evaluate summaries using only the first 300 words. The extractive summaries are fairly long and contain 2000- 5000 words. Including several utterances distracts a reader\u2019s focus on the salient aspects, resulting in low readability of the summaries. Therefore, we set the length parameter in ROUGE (l) to 300 to limit the comparison to only the first 300 words."}, {"heading": "4.4 Readability Analysis", "text": "To evaluate the linguistic quality of the generated summaries, we perform readability analysis. We asked one human judge to mark sentences in the generated abstractive summaries as either readable or not readable. Readability indicates how well the idea in the sentence is conveyed to the reader. Excessive presence of disfluencies or ill-formed utterances should be marked as not readable. We provided these instructions to the human judge. Out of 261 summary sentences generated for the 20 abstractive summaries, 67 sentences were found to be not readable (\u223c26%). We also manually evaluated the extracted utterances and found that 33% of the utterances contained various disfluencies, making them difficult to read. We also performed another readability analysis for the summaries generated using MSC and found that only 62% of the generated sentences in the summaries are readable. The readability of MSC summaries (0.62) is even worse than that of the extractive summaries (0.67), showing that, while the generated sentences in MSC model are informative (high ROUGE scores), they suffer from serious grammatical issues as no factor of linguistic quality is considered in the model. Generally, several utterances in extractive summaries were marked as not readable due to excessive use of disfluencies. Furthermore, there were incomplete utterances that created confusion in the minds of the reader. For example, an extracted utterances \u2013 \u201cAh eagle , right okay .\u201d \u2013 although gram-\nmatical, does not tell us anything about what is being spoken about. To obtain a coarse estimate of grammaticality, we also calculate the average log-likelihood score provided by the Stanford Parser. We compute the average log-likelihood scores of the confidence of the dependency parses for each type of summaries. Table 7 shows the average scores.5\nTable 8 shows some examples of summaries generated by our system. The table indicates that the summaries generated by our system are relatively well-formed and they reflect the formal style of non-conversational text. We aligned sentences from the humanwritten abstracts and the corresponding sentences selected from each segment that our algorithm generates.\nError Analysis: In some cases the linearization component does not produce relevant ordering of words. For example, in the third summary sentence in Table 8, the system-generated summary lacks certain conjunctions and the ordering of words is inappropriate. The phrase \u201cdetailed design the\u201d can be removed to maintain clarity. In addition, the entity \u2013 design has been repeated. To solve these problems, we plan to introduce intra-sentence level constraints to improve generated summaries.\nOur algorithm is designed to retain informative words as well as grammatical dependencies that are more probable in any given corpus. However, the grammatical dependencies that we choose might not necessarily lead to well-formed grammatical sentences. Furthermore, our ILP-based model is unable to understand long-term dependencies of entities within a generated sentence. For example, consider the following output:\n\u201cDecided important reflect our budget our the product accessible a wide range of consumers limiting anyone know that kind .\u201d\nAs can be seen, it is really hard for a reader to identify what the summary sentence is trying to convey although certain words or phrases hint at the topic of deciding the budget based on the range of consumers. Our model at present does not memorize previous choices of entities referred in the utterances. Furthermore, our linearization component is based on the ordering of words in the source utterances. However, using the same ordering as the source sentences might not necessarily work well. In the context of an entirely new generated summary sentence, lexical or phrasal\n5Lower the magnitude of the log-likelihood scores, the higher is the confidence associated with the dependency parse.\nreordering and other transformations might be required. In such cases, it might be more effective to use language model based confidence scores to determine the best ordering of words. Improvement in the ILP formulation is possible by including confidence of the sequence of words in addition to the incorporation of knowledge about the entities. Optimizing such a complete model can help generate summaries that are much easier to read. Further, such summaries would contain coherent elements on the same entities in the summary sentences. We might also hope to optimize the model by including the number of segments as a parameter in the model. Currently, the maximum number of sentences in the summary is dependent on the number of topic segments. We can improve the formulation such that model itself decides the optimal length of the summaries ensuring that all the informative points in the meeting discussion are included in the system generated summary."}, {"heading": "5. CONCLUSIONS AND FUTURE WORK", "text": "In this work, we have proposed an approach to generate abstractive summaries from meeting conversations. We proposed a method for dividing a conversation into multiple topic segments. We used an extractive summarizer to identify the important set of utterances, and then applied ILP-based utterance fusion to generate one sentence summary from every topic segment. We leveraged the grammatical relations in the fusion technique that are more dominant in non-conversational style of text. The experiments on content selection and readability indicate that our method can generate relevant abstractive summaries from meeting transcripts without any templates. However, as we have already pointed out, not all generated summaries are usable due to the lack of coherence among several entities discussed within the same summary sentence. We plan to improve the generation using knowledge of entities and also refine readability using a language model. In future work, we plan to develop better linearization techniques. We also plan to improve our algorithm by not limiting one sentence per segment but allowing the ILP model to decide the optimal number of sentences for a complete summary."}, {"heading": "6. ACKNOWLEDGMENTS", "text": "This material is based upon work supported by the National Science Foundation under Grant No. 0845487."}, {"heading": "7. REFERENCES", "text": "[1] C. Apt\u00e9, F. Damerau, and S. M. Weiss. Automated Learning\nof Decision Rules for Text Categorization. ACM Transactions on Information Systems (TOIS), 12(3):233\u2013251, 1994. [2] S. Banerjee, P. Mitra, and K. Sugiyama. Abstractive Meeting Summarization Using Dependency Graph Fusion. In Proc. of the 24th International Conference on World Wide Web Companion (WWW \u201915 Companion), pages 5\u20136, 2015. [3] R. Barzilay and K. R. McKeown. Sentence Fusion for Multidocument News Summarization. Computational Linguistics, 31(3):297\u2013328, 2005. [4] B. K. Boguraev and M. S. Neff. Discourse Segmentation in Aid of Document Summarization. In Proc. of the 33rd Annual Hawaii International Conference on System Sciences (HICSS-33), pages 1\u201310, 2000. [5] J. Carletta, S. Ashby, S. Bourban, M. Flynn, M. Guillemot, T. Hain, J. Kadlec, V. Karaiskos, W. Kraaij, M. Kronenthal, et al. The AMI Meeting Corpus: A Pre-announcement. In Proc. of the 2nd International Workshop on Machine Learning for Multimodal Interaction (MLMI 2005), pages 28\u201339, 2006. [6] N. V. Chawla, K. W. Bowyer, L. O. Hall, and W. P. Kegelmeyer. SMOTE: Synthetic Minority Over-sampling\nTechnique. Journal of Artificial Intelligence Research (JAIR), 16(2002):321\u2013357, 2002.\n[7] J. Clarke and M. Lapata. Global Inference for Sentence Compression: An Integer Linear Programming Approach. Journal of Artificial Intelligence Research (JAIR), 31(2008):399\u2013429, 2008. [8] J. Eisenstein and R. Barzilay. Bayesian Unsupervised Topic Segmentation. In Proc. of the Conference on Empirical Methods in Natural Language Processing (EMNLP 2008), pages 334\u2013343, 2008. [9] K. Filippova. Multi-sentence Compression: Finding Shortest Paths in Word Graphs. In Proc. of the 23rd International Conference on Computational Linguistics (Coling 2010), pages 322\u2013330, 2010. [10] K. Filippova and M. Strube. Sentence Fusion via Dependency Graph Compression. In Proc. of the Conference on Empirical Methods in Natural Language Processing (EMNLP 2008), pages 177\u2013185, 2008. [11] K. Filippova and M. Strube. Tree Linearization in English: Improving Language Model Based Approaches. In Proc. of the Human Language Technology Conference of the North American Chapter of the Association for Computational Linguistics (HLT-NAACL 2009), pages 225\u2013228, 2009. [12] M. Galley. A Skip-Chain Conditional Random Field for Ranking Meeting Utterances by Importance. In Proc. of the 2006 Conference on Empirical Methods in Natural Language Processing (EMNLP 2006), pages 364\u2013372, 2006. [13] M. Galley, K. McKeown, E. Fosler-Lussier, and H. Jing. Discourse Segmentation of Multi-party Conversation. In Proc. of the 41st Annual Meeting on Association for Computational Linguistics (ACL \u201903), pages 562\u2013569, 2003. [14] N. Garg, B. Favre, K. Riedhammer, and D. Hakkani-T\u00fcr. ClusterRank: A Graph Based Method for Meeting Summarization. In Proc. of the 10th Annual Conference of the International Speech Communication (INTERSPEECH 2009), pages 1499\u20131502, 2009. [15] D. Gillick, K. Riedhammer, B. Favre, and D. Hakkani-Tur. A Global Optimization Framework for Meeting Summarization. In Proc. of the IEEE International Conference on Acoustics, Speech, and Signal Processing (ICASSP 2009), pages 4769\u20134772, 2009. [16] Gurobi Optimization, Inc. Gurobi Optimizer Reference Manual, 2014. [17] M. Hall, E. Frank, G. Holmes, B. Pfahringer, P. Reutemann, and I. H. Witten. The WEKA data mining software: an update. ACM SIGKDD Explorations Newsletter, 11(1):10\u201318, 2009. [18] C. Hori and S. Furui. A New Approach to Automatic Speech Summarization. IEEE Transactions on Multimedia, 5(3):368\u2013378, 2003. [19] P.-Y. Hsueh and J. D. Moore. Automatic Topic Segmentation and Labeling in Multiparty Dialogue. In Spoken Language Technology Workshop, pages 98\u2013101, 2006. [20] C.-Y. Lin. ROUGE: A Package for Automatic Evaluation of Summaries. In Proc. of the ACL-04 Workshop on Text Summarization Branches Out, pages 74\u201381, 2004. [21] C.-Y. Lin and E. Hovy. The Automated Acquisition of Topic Signatures for Text Summarization. In Proc. of the 18th Conference on Computational Linguistics (COLING \u201900), pages 495\u2013501, 2000. [22] H. Lin, J. Bilmes, and S. Xie. Graph-based Submodular Selection for Extractive Summarization. In Proc. of the IEEE Workshop on Automatic Speech Recognition & Understanding (ASRU 2009), pages 381\u2013386, 2009.\n[23] F. Liu and Y. Liu. From Extractive to Abstractive Meeting Summaries: Can It Be Done by Sentence Compression? In Proc. of the 47th Annual Meeting of the Association for Computational Linguistics (ACL-IJCNLP 2009), pages 261\u2013264, 2009. [24] Y. Liu, S. Xie, and F. Liu. Using N-best Recognition Output for Extractive Summarization and Keyword Extraction in Meeting Speech. In Proc. of IEEE International Conference on Acoustics Speech and Signal Processing (ICASSP 2010), pages 5310\u20135313, 2010. [25] C. D. Manning, M. Surdeanu, J. Bauer, J. Finkel, S. J. Bethard, and D. McClosky. The Stanford CoreNLP Natural Language Processing Toolkit. In Proc. of 52nd Annual Meeting of the Association for Computational Linguistics (ACL 2014): System Demonstrations, pages 55\u201360, 2014. [26] Y. Mehdad, G. Carenini, F. W. Tompa, and R. T. NG. Abstractive Meeting Summarization with Entailment and Fusion. In Proc. of the 14th European Workshop on Natural Language Generation, pages 136\u2013146, 2013. [27] J. Morris and G. Hirst. Lexical Cohesion Computed by Thesaural Relations as an Indicator of the Structure of Text. Computational Linguistics, 17(1):21\u201348, 1991. [28] G. Murray and G. Carenini. Summarizing Spoken and Written Conversations. In Proc. of the Conference on Empirical Methods in Natural Language Processing (EMNLP 2008), pages 773\u2013782, 2008. [29] G. Murray, G. Carenini, and R. Ng. Generating and Validating Abstracts of Meeting Conversations: a User Study. In Proc. of the 6th International Natural Language Generation Conference (INLG 2010), pages 105\u2013113, 2010. [30] G. Murray, G. Carenini, and R. Ng. Interpretation and Transformation for Abstracting Conversations. In Proc. of the Human Language Technology Conference of the North American Chapter of the Association for Computational Linguistics (HLT-NAACL 2010), pages 894\u2013902, 2010. [31] A. Nenkova and K. McKeown. A Survey of Text Summarization Techniques. Mining Text Data, pages 43\u201376, 2012. [32] T. Oya, Y. Mehdad, G. Carenini, and R. Ng. A Template-based Abstractive Meeting Summarization: Leveraging Summary and Source Text Relationships. In Proc. of the 8th International Natural Language Generation Conference (INLG 2014), pages 45\u201353, 2014. [33] T. Rose, M. Stevenson, and M. Whitehead. The Reuters Corpus Volume 1-from Yesterday\u2019s News to Tomorrow\u2019s Language Resources. In Proc. of the 3rd International Conference on Language Resources and Evaluation Conference (LREC\u201902), pages 827\u2013832, 2002. [34] D. Roth and W.-T. Yih. A Linear Programming Formulation for Global Inference in Natural Language Tasks. In Proc. of the 8th Conference on Natural Language Learning (CoNLL-2004), pages 1\u20138, 2004. [35] S. Skiena. Dijkstra\u2019s algorithm. Implementing Discrete Mathematics: Combinatorics and Graph Theory with Mathematica, Reading, pages 225\u2013227, 1990. [36] L. Wang and C. Cardie. Domain-Independent Abstract Generation for Focused Meeting Summarization. In Proc. of the 51st Annual Meeting of the Association for Computational Linguistics (ACL 2013), pages 1395\u20131405, 2013. [37] S. Xie and Y. Liu. Using Corpus and Knowledge-based Similarity Measure in Maximum Marginal Relevance for Meeting Summarization. In Proc. of IEEE International Conference on Acoustics, Speech and Signal Processing (ICASSP 2008), pages 4985\u20134988, 2008."}], "references": [{"title": "Automated Learning of Decision Rules for Text Categorization", "author": ["C. Apt\u00e9", "F. Damerau", "S.M. Weiss"], "venue": "ACM Transactions on Information Systems (TOIS), 12(3):233\u2013251", "citeRegEx": "1", "shortCiteRegEx": null, "year": 1994}, {"title": "Abstractive Meeting Summarization Using Dependency Graph Fusion", "author": ["S. Banerjee", "P. Mitra", "K. Sugiyama"], "venue": "Proc. of the 24th International Conference on World Wide Web Companion (WWW \u201915 Companion), pages 5\u20136", "citeRegEx": "2", "shortCiteRegEx": null, "year": 2015}, {"title": "Sentence Fusion for Multidocument News Summarization", "author": ["R. Barzilay", "K.R. McKeown"], "venue": "Computational Linguistics, 31(3):297\u2013328", "citeRegEx": "3", "shortCiteRegEx": null, "year": 2005}, {"title": "Discourse Segmentation in Aid of Document Summarization", "author": ["B.K. Boguraev", "M.S. Neff"], "venue": "Proc. of the 33rd Annual Hawaii International Conference on System Sciences (HICSS-33), pages 1\u201310", "citeRegEx": "4", "shortCiteRegEx": null, "year": 2000}, {"title": "et al", "author": ["J. Carletta", "S. Ashby", "S. Bourban", "M. Flynn", "M. Guillemot", "T. Hain", "J. Kadlec", "V. Karaiskos", "W. Kraaij", "M. Kronenthal"], "venue": "The AMI Meeting Corpus: A Pre-announcement. In Proc. of the 2nd International Workshop on Machine Learning for Multimodal Interaction ", "citeRegEx": "5", "shortCiteRegEx": null, "year": 2005}, {"title": "SMOTE: Synthetic Minority Over-sampling  Technique", "author": ["N.V. Chawla", "K.W. Bowyer", "L.O. Hall", "W.P. Kegelmeyer"], "venue": "Journal of Artificial Intelligence Research (JAIR), 16", "citeRegEx": "6", "shortCiteRegEx": null, "year": 2002}, {"title": "Global Inference for Sentence Compression: An Integer Linear Programming Approach", "author": ["J. Clarke", "M. Lapata"], "venue": "Journal of Artificial Intelligence Research (JAIR), 31", "citeRegEx": "7", "shortCiteRegEx": null, "year": 2008}, {"title": "Bayesian Unsupervised Topic Segmentation", "author": ["J. Eisenstein", "R. Barzilay"], "venue": "Proc. of the Conference on Empirical Methods in Natural Language Processing ", "citeRegEx": "8", "shortCiteRegEx": null, "year": 2008}, {"title": "Multi-sentence Compression: Finding Shortest Paths in Word Graphs", "author": ["K. Filippova"], "venue": "Proc. of the 23rd International Conference on Computational Linguistics ", "citeRegEx": "9", "shortCiteRegEx": null, "year": 2010}, {"title": "Sentence Fusion via Dependency Graph Compression", "author": ["K. Filippova", "M. Strube"], "venue": "Proc. of the Conference on Empirical Methods in Natural Language Processing ", "citeRegEx": "10", "shortCiteRegEx": null, "year": 2008}, {"title": "Tree Linearization in English: Improving Language Model Based Approaches", "author": ["K. Filippova", "M. Strube"], "venue": "Proc. of the Human Language Technology Conference of the North American Chapter of the Association for Computational Linguistics ", "citeRegEx": "11", "shortCiteRegEx": null, "year": 2009}, {"title": "A Skip-Chain Conditional Random Field for Ranking Meeting Utterances by Importance", "author": ["M. Galley"], "venue": "Proc. of the 2006 Conference on Empirical Methods in Natural Language Processing ", "citeRegEx": "12", "shortCiteRegEx": null, "year": 2006}, {"title": "Discourse Segmentation of Multi-party Conversation", "author": ["M. Galley", "K. McKeown", "E. Fosler-Lussier", "H. Jing"], "venue": "Proc. of the 41st Annual Meeting on Association for Computational Linguistics (ACL \u201903), pages 562\u2013569", "citeRegEx": "13", "shortCiteRegEx": null, "year": 2003}, {"title": "ClusterRank: A Graph Based Method for Meeting Summarization", "author": ["N. Garg", "B. Favre", "K. Riedhammer", "D. Hakkani-T\u00fcr"], "venue": "Proc. of the 10th Annual Conference of the International Speech Communication ", "citeRegEx": "14", "shortCiteRegEx": null, "year": 2009}, {"title": "A Global Optimization Framework for Meeting Summarization", "author": ["D. Gillick", "K. Riedhammer", "B. Favre", "D. Hakkani-Tur"], "venue": "Proc. of the IEEE International Conference on Acoustics, Speech, and Signal Processing ", "citeRegEx": "15", "shortCiteRegEx": null, "year": 2009}, {"title": "The WEKA data mining software: an update", "author": ["M. Hall", "E. Frank", "G. Holmes", "B. Pfahringer", "P. Reutemann", "I.H. Witten"], "venue": "ACM SIGKDD Explorations Newsletter, 11(1):10\u201318", "citeRegEx": "17", "shortCiteRegEx": null, "year": 2009}, {"title": "A New Approach to Automatic Speech Summarization", "author": ["C. Hori", "S. Furui"], "venue": "IEEE Transactions on Multimedia, 5(3):368\u2013378", "citeRegEx": "18", "shortCiteRegEx": null, "year": 2003}, {"title": "Automatic Topic Segmentation and Labeling in Multiparty Dialogue", "author": ["P.-Y. Hsueh", "J.D. Moore"], "venue": "Spoken Language Technology Workshop, pages 98\u2013101", "citeRegEx": "19", "shortCiteRegEx": null, "year": 2006}, {"title": "ROUGE: A Package for Automatic Evaluation of Summaries", "author": ["C.-Y. Lin"], "venue": "Proc. of the ACL-04 Workshop on Text Summarization Branches Out, pages 74\u201381", "citeRegEx": "20", "shortCiteRegEx": null, "year": 2004}, {"title": "The Automated Acquisition of Topic Signatures for Text Summarization", "author": ["C.-Y. Lin", "E. Hovy"], "venue": "Proc. of the 18th Conference on Computational Linguistics (COLING \u201900), pages 495\u2013501", "citeRegEx": "21", "shortCiteRegEx": null, "year": 2000}, {"title": "Graph-based Submodular Selection for Extractive Summarization", "author": ["H. Lin", "J. Bilmes", "S. Xie"], "venue": "Proc. of the IEEE Workshop on Automatic Speech Recognition & Understanding ", "citeRegEx": "22", "shortCiteRegEx": null, "year": 2009}, {"title": "From Extractive to Abstractive Meeting Summaries: Can It Be Done by Sentence Compression? In Proc", "author": ["F. Liu", "Y. Liu"], "venue": "of the 47th Annual Meeting of the Association for Computational Linguistics ", "citeRegEx": "23", "shortCiteRegEx": null, "year": 2009}, {"title": "Using N-best Recognition Output for Extractive Summarization and Keyword Extraction in Meeting Speech", "author": ["Y. Liu", "S. Xie", "F. Liu"], "venue": "Proc. of IEEE International Conference on Acoustics Speech and Signal Processing ", "citeRegEx": "24", "shortCiteRegEx": null, "year": 2010}, {"title": "The Stanford CoreNLP Natural Language Processing Toolkit", "author": ["C.D. Manning", "M. Surdeanu", "J. Bauer", "J. Finkel", "S.J. Bethard", "D. McClosky"], "venue": "Proc. of 52nd Annual Meeting of the Association for Computational Linguistics ", "citeRegEx": "25", "shortCiteRegEx": null, "year": 2014}, {"title": "Abstractive Meeting Summarization with Entailment and Fusion", "author": ["Y. Mehdad", "G. Carenini", "F.W. Tompa", "R.T. NG"], "venue": "Proc. of the 14th European Workshop on Natural Language Generation, pages 136\u2013146", "citeRegEx": "26", "shortCiteRegEx": null, "year": 2013}, {"title": "Lexical Cohesion Computed by Thesaural Relations as an Indicator of the Structure of Text", "author": ["J. Morris", "G. Hirst"], "venue": "Computational Linguistics, 17(1):21\u201348", "citeRegEx": "27", "shortCiteRegEx": null, "year": 1991}, {"title": "Summarizing Spoken and Written Conversations", "author": ["G. Murray", "G. Carenini"], "venue": "Proc. of the Conference on Empirical Methods in Natural Language Processing ", "citeRegEx": "28", "shortCiteRegEx": null, "year": 2008}, {"title": "Generating and Validating Abstracts of Meeting Conversations: a User Study", "author": ["G. Murray", "G. Carenini", "R. Ng"], "venue": "Proc. of the 6th International Natural Language Generation Conference ", "citeRegEx": "29", "shortCiteRegEx": null, "year": 2010}, {"title": "Interpretation and Transformation for Abstracting Conversations", "author": ["G. Murray", "G. Carenini", "R. Ng"], "venue": "Proc. of the Human Language Technology Conference of the North American Chapter of the Association for Computational Linguistics ", "citeRegEx": "30", "shortCiteRegEx": null, "year": 2010}, {"title": "A Survey of Text Summarization Techniques", "author": ["A. Nenkova", "K. McKeown"], "venue": "Mining Text Data, pages 43\u201376", "citeRegEx": "31", "shortCiteRegEx": null, "year": 2012}, {"title": "A Template-based Abstractive Meeting Summarization: Leveraging Summary and Source Text Relationships", "author": ["T. Oya", "Y. Mehdad", "G. Carenini", "R. Ng"], "venue": "Proc. of the 8th International Natural Language Generation Conference ", "citeRegEx": "32", "shortCiteRegEx": null, "year": 2014}, {"title": "The Reuters Corpus Volume 1-from Yesterday\u2019s News to Tomorrow\u2019s Language Resources", "author": ["T. Rose", "M. Stevenson", "M. Whitehead"], "venue": "Proc. of the 3rd International Conference on Language Resources and Evaluation Conference (LREC\u201902), pages 827\u2013832", "citeRegEx": "33", "shortCiteRegEx": null, "year": 2002}, {"title": "A Linear Programming Formulation for Global Inference in Natural Language Tasks", "author": ["D. Roth", "W.-T. Yih"], "venue": "Proc. of the 8th Conference on Natural Language Learning ", "citeRegEx": "34", "shortCiteRegEx": null, "year": 2004}, {"title": "Dijkstra\u2019s algorithm", "author": ["S. Skiena"], "venue": "Implementing Discrete Mathematics: Combinatorics and Graph Theory with Mathematica, Reading, pages 225\u2013227", "citeRegEx": "35", "shortCiteRegEx": null, "year": 1990}, {"title": "Domain-Independent Abstract Generation for Focused Meeting Summarization", "author": ["L. Wang", "C. Cardie"], "venue": "Proc. of the 51st Annual Meeting of the Association for Computational Linguistics ", "citeRegEx": "36", "shortCiteRegEx": null, "year": 2013}, {"title": "Using Corpus and Knowledge-based Similarity Measure in Maximum Marginal Relevance for Meeting Summarization", "author": ["S. Xie", "Y. Liu"], "venue": "Proc. of IEEE International Conference on Acoustics, Speech and Signal Processing ", "citeRegEx": "37", "shortCiteRegEx": null, "year": 2008}], "referenceMentions": [{"referenceID": 4, "context": "Table 1: Two sets of extractive summaries along with the corresponding gold standard human generated abstractive summaries from a meeting in the AMI corpus [5].", "startOffset": 156, "endOffset": 159}, {"referenceID": 13, "context": "While previous work on meeting summarization was primarily extractive [14, 15], a recent study showed that people generally prefer abstractive summaries [29].", "startOffset": 70, "endOffset": 78}, {"referenceID": 14, "context": "While previous work on meeting summarization was primarily extractive [14, 15], a recent study showed that people generally prefer abstractive summaries [29].", "startOffset": 70, "endOffset": 78}, {"referenceID": 27, "context": "While previous work on meeting summarization was primarily extractive [14, 15], a recent study showed that people generally prefer abstractive summaries [29].", "startOffset": 153, "endOffset": 157}, {"referenceID": 4, "context": "pus [5].", "startOffset": 4, "endOffset": 7}, {"referenceID": 34, "context": "Previous approaches to abstractive meeting summarization have relied on template-based [36] or word-graph fusion-based [26] methods.", "startOffset": 87, "endOffset": 91}, {"referenceID": 24, "context": "Previous approaches to abstractive meeting summarization have relied on template-based [36] or word-graph fusion-based [26] methods.", "startOffset": 119, "endOffset": 123}, {"referenceID": 17, "context": "Every meeting is usually comprised of several sub-topics [19].", "startOffset": 57, "endOffset": 61}, {"referenceID": 26, "context": "Previous work on meeting summarization [28] has shown that lexical cohesion is an important indicator in topic identification in meetings.", "startOffset": 39, "endOffset": 43}, {"referenceID": 12, "context": "We experiment with two different lexicalcohesion based text segmentation algorithms: LCSeg [13] and unsupervised Bayesian topic segmentation [8].", "startOffset": 91, "endOffset": 95}, {"referenceID": 7, "context": "We experiment with two different lexicalcohesion based text segmentation algorithms: LCSeg [13] and unsupervised Bayesian topic segmentation [8].", "startOffset": 141, "endOffset": 144}, {"referenceID": 9, "context": "We formulate the sub-graph generation problem as an Integer Linear Programming (ILP) problem by adapting an existing sentence fusion technique [10].", "startOffset": 143, "endOffset": 147}, {"referenceID": 16, "context": "Information content is measured using Hori and Furui\u2019s word informativeness formula [18] while the linguistic quality is estimated using probabilities of grammatical relations from the Reuter\u2019s corpus [1].", "startOffset": 84, "endOffset": 88}, {"referenceID": 0, "context": "Information content is measured using Hori and Furui\u2019s word informativeness formula [18] while the linguistic quality is estimated using probabilities of grammatical relations from the Reuter\u2019s corpus [1].", "startOffset": 201, "endOffset": 204}, {"referenceID": 10, "context": "The sub-graph generated from each segment is linearized [11] using a bottom-up approach to generate a one-sentence summary.", "startOffset": 56, "endOffset": 60}, {"referenceID": 18, "context": "ROUGE-2 and ROUGE-SU4 [20] scores from our abstractive model (0.", "startOffset": 22, "endOffset": 26}, {"referenceID": 24, "context": "044) as well as the word-graph based abstractive summarization method [26] (0.", "startOffset": 70, "endOffset": 74}, {"referenceID": 20, "context": "In the field of meeting summarization, while extractive techniques have been widely employed so far [22, 24], abstractive techniques, including sentence compression, template and graph-based approaches, have been focused on recently.", "startOffset": 100, "endOffset": 108}, {"referenceID": 22, "context": "In the field of meeting summarization, while extractive techniques have been widely employed so far [22, 24], abstractive techniques, including sentence compression, template and graph-based approaches, have been focused on recently.", "startOffset": 100, "endOffset": 108}, {"referenceID": 21, "context": "Liu and Liu [23] used sentence compression to generate summaries of meetings.", "startOffset": 12, "endOffset": 16}, {"referenceID": 28, "context": "[30] mapped conversations to an ontology that was complemented with a Natural", "startOffset": 0, "endOffset": 4}, {"referenceID": 27, "context": "The corresponding full summarization system was later presented in [29], where a user study was conducted on the abstractive summaries that were generated.", "startOffset": 67, "endOffset": 71}, {"referenceID": 34, "context": "Lu and Cardie [36] proposed a method that learns templates from the human written summaries and generates the summaries of decisions and actions of meetings by using the best set of templates for a particular summary ranked using a greedy approach.", "startOffset": 14, "endOffset": 18}, {"referenceID": 24, "context": "[26] developed a method that first over-generates multiple fused utterances in an entailment graph, and then chooses one based on the final path ranking.", "startOffset": 0, "endOffset": 4}, {"referenceID": 30, "context": "[32] used the same fusion technique to generate summaries of meetings.", "startOffset": 0, "endOffset": 4}, {"referenceID": 8, "context": "mentioned above relied on using multi-sentence compression (MSC) [9] that combines information from sentences that are similar or connected using some common entity.", "startOffset": 65, "endOffset": 68}, {"referenceID": 1, "context": "Our previous work [2] has briefly described the effectiveness of the fusion-based technique, which is also employed in this work.", "startOffset": 18, "endOffset": 21}, {"referenceID": 19, "context": "Topic segmentation has been used in summarization of news articles [21, 4].", "startOffset": 67, "endOffset": 74}, {"referenceID": 3, "context": "Topic segmentation has been used in summarization of news articles [21, 4].", "startOffset": 67, "endOffset": 74}, {"referenceID": 25, "context": "Generally, lexical cohesion-based measures work well for topic segmentation [27].", "startOffset": 76, "endOffset": 80}, {"referenceID": 12, "context": "[13] developed a topic segmentor, LCSeg, based on lexical cohesion, which is considered to be a good indicator of the discourse structure of the text.", "startOffset": 0, "endOffset": 4}, {"referenceID": 11, "context": "Most of them are adopted from previous works [12, 37].", "startOffset": 45, "endOffset": 53}, {"referenceID": 35, "context": "Most of them are adopted from previous works [12, 37].", "startOffset": 45, "endOffset": 53}, {"referenceID": 7, "context": "Eisenstein and Barzilay [8] proposed an unsupervised approach to topic segmentation based on lexical cohesion modeled by a Bayesian framework.", "startOffset": 24, "endOffset": 27}, {"referenceID": 11, "context": "We adopt basic and content features from previous works [12, 37].", "startOffset": 56, "endOffset": 64}, {"referenceID": 35, "context": "We adopt basic and content features from previous works [12, 37].", "startOffset": 56, "endOffset": 64}, {"referenceID": 5, "context": "SMOTE: In synthetic minority oversampling technique (SMOTE) [6], the minority class is randomly oversampled.", "startOffset": 60, "endOffset": 63}, {"referenceID": 2, "context": "Several techniques have been proposed for sentence fusion tasks [3].", "startOffset": 64, "endOffset": 67}, {"referenceID": 9, "context": "We adapt a sentence fusion technique [10] to meeting utterances.", "startOffset": 37, "endOffset": 41}, {"referenceID": 6, "context": "ILP has been applied successfully to many natural language processing tasks [7, 34].", "startOffset": 76, "endOffset": 83}, {"referenceID": 32, "context": "ILP has been applied successfully to many natural language processing tasks [7, 34].", "startOffset": 76, "endOffset": 83}, {"referenceID": 23, "context": "We use the publicly available Stanford CoreNLP package [25] that has a co-reference resolution module.", "startOffset": 55, "endOffset": 59}, {"referenceID": 9, "context": "Similar to the fusion technique by Fillipova and Strube [10], we model the problem as an integer linear programming (ILP) formulation.", "startOffset": 56, "endOffset": 60}, {"referenceID": 31, "context": "In this work, we calculate these values using Reuters corpora [33] in order to obtain dominant relations from non-conversational style of text.", "startOffset": 62, "endOffset": 66}, {"referenceID": 16, "context": "In order to compute I(d), we improve the word significance score [18] as follows:", "startOffset": 65, "endOffset": 69}, {"referenceID": 9, "context": "Some of the constraints have been directly adapted from the original ILP formulation [10].", "startOffset": 85, "endOffset": 89}, {"referenceID": 33, "context": "ply Dijkstra\u2019s algorithm [35] to calculate the path length.", "startOffset": 25, "endOffset": 29}, {"referenceID": 4, "context": "The AMI Meeting corpus [5] contains 139 meeting transcripts along with their corresponding extractive and abstractive summaries.", "startOffset": 23, "endOffset": 26}, {"referenceID": 15, "context": "We used Weka [17] for all the classification tasks with the default set of parameters.", "startOffset": 13, "endOffset": 17}, {"referenceID": 8, "context": "071 MSC model [9] 0.", "startOffset": 14, "endOffset": 17}, {"referenceID": 8, "context": "We also compare the summaries to the MSC method proposed by Fillipova [9] that has been adapted for abstractive meeting summarization [26] develped earlier.", "startOffset": 70, "endOffset": 73}, {"referenceID": 24, "context": "We also compare the summaries to the MSC method proposed by Fillipova [9] that has been adapted for abstractive meeting summarization [26] develped earlier.", "startOffset": 134, "endOffset": 138}, {"referenceID": 8, "context": "73 MSC model [9] 0.", "startOffset": 13, "endOffset": 16}, {"referenceID": 29, "context": "Both the ROUGE scores have been found to correlate well with human judgments [31].", "startOffset": 77, "endOffset": 81}], "year": 2016, "abstractText": "Summaries of meetings are very important as they convey the essential content of discussions in a concise form. Both participants and non-participants are interested in the summaries of meetings to plan for their future work. Generally, it is time consuming to read and understand the whole documents. Therefore, summaries play an important role as the readers are interested in only the important context of discussions. In this work, we address the task of meeting document summarization. Automatic summarization systems on meeting conversations developed so far have been primarily extractive, resulting in unacceptable summaries that are hard to read. The extracted utterances contain disfluencies that affect the quality of the extractive summaries. To make summaries much more readable, we propose an approach to generating abstractive summaries by fusing important content from several utterances. We first separate meeting transcripts into various topic segments, and then identify the important utterances in each segment using a supervised learning approach. The important utterances are then combined together to generate a one-sentence summary. In the text generation step, the dependency parses of the utterances in each segment are combined together to create a directed graph. The most informative and well-formed sub-graph obtained by integer linear programming (ILP) is selected to generate a one-sentence summary for each topic segment. The ILP formulation reduces disfluencies by leveraging grammatical relations that are more prominent in nonconversational style of text, and therefore generates summaries that is comparable to human-written abstractive summaries. Experimental results show that our method can generate more informative summaries than the baselines. In addition, readability assessments by human judges as well as log-likelihood estimates obtained from the dependency parser show that our generated summaries are significantly readable and well-formed. Permission to make digital or hard copies of all or part of this work for personal or classroom use is granted without fee provided that copies are not made or distributed for profit or commercial advantage and that copies bear this notice and the full citation on the first page. Copyrights for components of this work owned by others than ACM must be honored. Abstracting with credit is permitted. To copy otherwise, or republish, to post on servers or to redistribute to lists, requires prior specific permission and/or a fee. Request permissions from Permissions@acm.org. DocEng\u201915, September 8-11, 2015, Lausanne, Switzerland. c \u00a9 2015 ACM. ISBN 978-1-4503-3307-8/15/09 ...$15.00. DOI: http://dx.doi.org/10.1145/2682571.2797061. Table 1: Two sets of extractive summaries along with the corresponding gold standard human generated abstractive summaries from a meeting in the AMI corpus [5]. Set 2 follows Set 1 in the actual meeting transcript. \u201cA,\u201d \u201cB\u201d and \u201cD\u201d refer to three distinct speakers in the meeting. Set 1: Human-generated extractive summary D: um as well as uh characters. D: um different uh keypad styles and s symbols. D: Well right away I\u2019m wondering if there\u2019s um th th uh, like with DVD players, if there are zones. A: Cause you have more complicated characters like European languages, then you need more buttons. D: I\u2019m thinking the price might might appeal to a certain market in one region, whereas in another it\u2019ll be different, so D: kay trendy probably means something other than just basic Abstractive summary: The team then discussed various features to consider in making the remote.ive summary: The team then discussed various features to consider in making the remote. Set 2: Human-generated extractive summary B: Like how much does, you know, a remote control cost. B: Well twenty five Euro, I mean that\u2019s um that\u2019s about like eighteen pounds or something. D: This is this gonna to be like the premium product kinda thing or B: So I don\u2019t know how how good a remote control that would get you. Um. Abstractive summary: The project manager talked about the project finances and selling prices.ive summary: The project manager talked about the project finances and selling prices.", "creator": "LaTeX with hyperref package"}}}