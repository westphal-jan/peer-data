{"id": "1609.08412", "review": {"conference": "arxiv", "VERSION": "v1", "DATE_OF_SUBMISSION": "27-Sep-2016", "title": "OC16-CE80: A Chinese-English Mixlingual Database and A Speech Recognition Baseline", "abstract": "meanwhile we present the latest oc16 - taiwanese ce80 chinese - english mixlingual enhanced speech database program which is was subsequently released as this a main resource for expert training, basic development services and test criteria for conducting the chinese - english phonetic mixlingual speech semantic recognition ( seo mixasr - chen ) challenge on o - cocosda until 2016. compiling this database consists collection of 80 hours estimates of speech recognition signals currently recorded from to more than less 1, 5 400 dialect speakers, where the utterances above are in characteristic chinese speakers but for each involves one greek or several english words. based both on the ms database and another via two free online data resources ( thchs30 and essentially the cmu dictionary ), a true speech recognition ( td asr ) baseline was solely constructed with adapting the canonical deep neural network - hidden markov model ( gs dnn - hmm ) language hybrid reporting system. we then report the baseline results clearly following the mixasr - pr chen evaluation rules and demonstrate that oc16 - chen ce80 criteria is having a reasonable data resource good for enhanced mixlingual linguist research.", "histories": [["v1", "Tue, 27 Sep 2016 13:25:51 GMT  (92kb)", "http://arxiv.org/abs/1609.08412v1", "O-COCOSDA 2016"]], "COMMENTS": "O-COCOSDA 2016", "reviews": [], "SUBJECTS": "cs.CL", "authors": ["dong wang", "zhiyuan tang", "difei tang", "qing chen"], "accepted": false, "id": "1609.08412"}, "pdf": {"name": "1609.08412.pdf", "metadata": {"source": "CRF", "title": "OC16-CE80: A Chinese-English Mixlingual Database and A Speech Recognition Baseline", "authors": ["Dong Wang", "Zhiyuan Tang", "Difei Tang", "Qing Chen"], "emails": ["wangdong99@mails.tsinghua.edu.cn", "tangzy@cslt.riit.tsinghua.edu.cn", "chenqing}@speechocean.com"], "sections": [{"heading": null, "text": "ar X\niv :1\n60 9.\n08 41\n2v 1\n[ cs\n.C L\n] 2\n7 Se\nIndex Terms\u2014code-switching, mixlingual database, speech recognition\nI. INTRODUCTION\nLanguage is a fundamental capability of human beings. In history, language in a particular area was fairly stable at most of the time, which means that the evolution of language was noticeable but rather slow. This steady evolution in history can be largely attributed to the limited inter-area or inter-nation cultural and business interaction.\nThis situation has been fundamentally changed since last century. The international business developed so rapidly that bilateral trading quickly evolved into global trading, and national markets have become inseparable parts of the global market. Especially in the latest twenty years, the development of the Internet has led to much more efficient information exchange and glued the entire earth together. This brings about quick and remarkable change in our daily life, particularly the trend of internationalism, globalization and interculturalism [1].\nAn interesting consequence of this change in human language is the bilingual or multilingual phenomenon. During the international interaction, different languages meet and influence each other, leading to interesting acoustic and linguistic phenomena. It can be simply the popularity of some foreign words, but be more as profound as the adoption of a\nforeign language as an official one [2], [3], [4]. The mutual influence among languages is universal in modern society, e.g., the influence of Mandarin to other minor languages in China, and the influence of English to other languages in the world. The complex acoustic and linguistic patterns of languages in multilingual conditions have attracted much interest in a multitude of research areas, including comparative phonetics, evolutionary linguistics, language development and sociolinguistics.\nPerhaps the most commonly encountered multilingual phenomenon is mixlingual embedding, i.e., the phenomenon that one or several words from other language (called the secondary language or embedding language) were embedded in the sentences of a main language (called the primary language or matrix language). This mixlingual problem is also called \u2018code-switching\u2019, as it involves the change from one language to another. This may take place at various levels including sentence, phrase, or word [5], [6], [7], [8]. For example, the following sentence involves a sentence-level code-switching, where an English word \u201cGoogle\u201d is seated in the main Chinese character sequence: \u201c \u4f60\u53ef\u4ee5Google\u8fd9\u7bc7\u8bba\u6587 \u201d. Speech recognition against code-switching has ignited interest in both robust acoustic modeling [9], [10], [11], [12], [13], [14] and language modeling [15], [16], [17].\nTo promote research on mixlingual speech processing, the center for speech and language technologies (CSLT) at Tsinghua University and SpeechOcean (Beijing Haitian Ruisheng Science Technology Ltd.) together organize a Chinese-English mixlingual speech recognition (MixASR-CHEN) challenge on O-COCOSDA 2016. This event calls for a competition on a speech recognition task on mixlingual utterances where one or several English words are embedded in Chinese utterances. To support this event, SpeechOcean released a mixlingual speech database named \u2018OC16-CE80\u2019 which consists of 80 hours of speech signals. This database is free for the participants of the challenge, and can be used together with another two free data resources (THCHS30 Chinese speech database and CMU English dictionary) to build a full-fledged mixlingual\nspeech recognition system. This paper presents the data profile of the database, the evaluation rules of the challenge, and a mixlingual ASR baseline system that the participants can refer to.\nNote that there are several other mixlingual databases for different code-switching, e.g. Cantonese-English, EnglishMandarin, Mandarin-Taiwanese and Mandarin-English [18], [10], [19], [20], [21]. The OC16-CE80 database is similar to the SEAME database [22] as both are Mandarin-English code-switching, but the speakers of SEAME are from Singaporean and Malaysian, whereas the speakers of OC16CE80 are totally from the China mainland. Due to the less popularity of spoken English in China compared to Singapore and Malaysia, the code-switching in OC16-CE80 might be less fluent. Finally, OC16-CE80 consists of 80 hours of speech signals from nearly 1, 500 speakers, which is larger than SEAME (157 speakers, 63 hours of signals)."}, {"heading": "II. DATABASE PROFILE", "text": "The OC16-CE80 database was originally created by SpeechOcean, targeting for various mixlingual speech processing tasks (mainly ASR). The entire database involves about 80 hours of speech signals, which were recorded by mobile phones in reading style, with a sampling rate of 16 kHz and a sample size of 16 bits. The text of the utterances was selected from a large text corpus, following a greedy search strategy that chose the sentence that can improve the phone coverage mostly one by one. The entire database was separated into a training set, a development set and a test set. More details of the OC16-CE80 database are presented in Table I.\nBesides the speech signals, the OC16-CE80 database also provides the human-labeled transcriptions for all the recordings of the training set and the development set. A simple lexicon is also provided to cover most of the commonly used Chinese characters and the English words appearing in the training and development utterances. The number of Chinese characters involved in the lexicon is about 4, 653, with the pronunciations labelled in tonal Pinyin, e.g., \u2018shang4\u2019. The number of English words involved in the lexicon is about 6, 879, with the pronunciations excerpted from the CMU dictionary1.\n1 http://svn.code.sf.net/p/cmusphinx/code/trunk/cmudict\nThe OC16-CE80 database is freely available for all the participants of the MixASR-CHEN challenge and the OCOCOSDA 2016 special session on Mixlingual Speech Processing. It is also available for other academic and industrial institutes or individual users, subject to a slightly different licence from SpeechOcean.2"}, {"heading": "III. OC16-MIXASR-CHEN CHALLENGE", "text": "Based on the OC16-CE80 database, we call a ChineseEnglish mixlingual speech recognition (MixASR-CHEN) challenge.3 The task of the challenge is to train a mixlingual ASR system using the given resources, and then transcribe the test speech to text using the system within limited time (48 hours). The performance is measured by word error rate (WER). The evaluation details are described as follows."}, {"heading": "A. Development resources", "text": "Three data resources are allowed to utilize in the MixASRCHEN challenge for system development, as shown below:\n\u2022 OC16-CE80, as described in the previous section. This database contributes the main speech data for acoustic model training. The transcriptions of the training data are also a good resource for language model training. These transcriptions are not only domain-specific, but also faced with the phenomenon of code-switching. \u2022 THCHS30 [23], a pure Chinese speech database provided by CSLT at Tsinghua University, free and online downloable4. This database involves a full set of resources that can be used to develop a full-fledged Chinese ASR system, including speech signals, transcriptions, a large lexicon and an associated language model. All the resources of THCHS30 can be used in the challenge, but perhaps the most important ones are the lexicon and the language model. \u2022 CMU English dictionary v0.7b5, a free downloadable resource that can be used to enrich English words in the lexicon.\nAccording to the challenge rule, the above three data resources are the only materials that can be used to develop the recognition system. Any additional resources are not allowed, including speech, text, lexicon, and supervision from other systems. However, participants can use their own phone set, in particular for Chinese words. This is because Chinese pronunciations can be described by either Initial-Finals (IF) or phones, and neither is more standard than the other one. The Chinese lexicon provided by THCHS30 is based on IFs, but participants can freely translate them to phones."}, {"heading": "B. Test plan", "text": "The MixASR-CHEN challenge chooses WER as the principle evaluation metric. Note that for Chinese, we regard each single Chinese character as a word, which means that the\n2 http://speechocean.com 3 http://cslt.riit.tsinghua.edu.cn/mediawiki/index.php/ASR-events-OC16-details 4 http://www.openslr.org/18 5 http://svn.code.sf.net/p/cmusphinx/code/trunk/cmudict/cmudict-0.7b\nWER on the Chinese part is essentially the character error rate (CER). Using WER makes the presentation more clear when the transcriptions involve both Chinese and English words.\nThe WER is computed as follows:\nWER = S +D + I\nN ,\nwhere N is the total number of words in the ground-truth transcription, and S, D, I denote the number of substitutions, deletions and insertions errors, respectively. These errors are computed from the forced alignment between the hypothesized transcriptions and the ground truth.\nNote that different participants may treat English words in different ways. For a fair evaluation, some normalization is performed before the submitted hypothesis is evaluated. We first merge scattered letters to a single word, e.g., \u2018I B M\u2019 to \u2018IBM\u2019, and then convert all English words to the upper case.\nThe challenge reports individual WERs on the Chinese part and English part of the hypothesis respectively, and the WER on the entire hypothesis. Although the main metric is the entire WER, the WER on the English part is also or more important."}, {"heading": "IV. BASELINE", "text": "We present a baseline MixASR system based on the deep neural network-hidden Markov model (DNN-HMM) hybrid architecture. The experiments were conducted with the Kaldi toolkit [24]. The purpose of these experiments is not to present a competitive submission, but to demonstrate that the OC16-CE80 database is a reasonable data resource to conduct mixlingual speech recognition research."}, {"heading": "A. Experimental setup", "text": "The speech data used to train the acoustic model was from the OC16-CE80 database and it contained both training set and development set. We refrained from using THCHS30 because our focus was to test quality of the new OC16-CE80 database, and involving additional data may lead to a biased evaluation. The lexicon used for the baseline system involved two parts: the Chinese part from the THCHS30 database, and the English part from the CMU English dictionary v0.7b. The phones of Chinese words and English words were collected, forming a mixlingual phone set. As it is a baseline system, we did not try to merge phones of different languages.\nThe acoustic model (AM) of the ASR system was built largely following the Kaldi WSJ s5 nnet3 recipe. The training started from building an initial Gaussian mixture model-hidden Markov model (GMM-HMM) system, using Mel frequency cepstral coefficients (MFCCs) as the feature. The initial system involved 4, 483 HMM states and 3, 500 Gaussian Mixture components (pdfs). This system was employed to produce forced alignment for the training data, which was used to train the DNN-HMM model.\nThe DNN model we used was the time-delay neural network (TDNN) [25]. It contained 6 hidden layers, and the activation function was p-norm [26]. The input dimension of the pnorm function was 2, 000 and the output dimension was 250. The natural stochastic gradient descent (NSGD) algorithm was\nemployed to train the TDNN [27]. The input feature involved 40-dimensional Fbanks, with a symmetric 4-frame window to splice neighboring frames. The output layer consisted of 3, 500 units, equal to the total number of Gaussian mixtures in the GMM system that was trained to bootstrap the TDNN model.\nAs for the language model (LM), we used the conventional 3-grams. To deal with the mixlingual difficulty, four LM configurations were investigated. The first one (THLM) was the LM offered by the THCHS30 database. This LM well matched the lexicon of the baseline system, as the Chinese words in the lexicon were just from THCHS30. The problem of this LM was that it involved no English words so it could not handle English at all. The second LM (OCLM) was trained from the transcriptions of the training and development data of OC16-CE80. This LM matched the test domain and involved English words, however it might suffer from data sparsity. The third LM (MIX) was a mixture of the above two LMs by a linear interpolation, where the validation set used to optimize the interpolation factor was 2, 000 sentences selected from the transcriptions of the OC16-CE80 database. In our experiment, we found the interpolation factor for the THLM was nearly 0.0, suggesting that THLM does not fit the domain of the OC16-CE80 database. The fourth LM (JOIN) was trained with all the transcriptions of THCHS30 and OC16-CE80. Note that the baseline lexicon was used when training the OCLM and the JOIN LM, which meant that all the words in the lexicon were consisted in these LMs, although the words absent from the training text data obtained only a small probability, depending on the KN smooth we used in the experiment."}, {"heading": "B. Performance results", "text": "Table II presents the baseline results on the test set, where \u2018THLM\u2019, \u2018OCLM\u2019, \u2018MIX\u2019 and \u2018JOIN\u2019 represent the four LM configurations presented in the previous section. From the results, we observe that the MIX, which is a mixture of THLM and OCLM and has a high bias on OCLM, works the best on both Chinese and English words. The THCHS30 LM is not much suitable for the OC16-CE80 test: it leads to a high WER on Chinese words, and 100% WER on English. Besides, the results of OCLM are not far from those of MIX. From the above, we know that merging THCHS30 can offer a bit benefit on the LM level. And the results with the domain-matched LM (OCLM) confirm that a reasonable multilingual ASR system can be established with the OC16CE80 database, using the standard modeling approach. The only problem is that the WER on English words is still high, which is more clear when compared to the performance on Chinese words. Nevertheless, the baseline results demonstrate that the OC16-CE80 database is a reasonable resource for research on mixlingual speech recognition. Several methods can be simply employed to promote English words, e.g., crosslingual phone/word sharing in the AM and LM. The aim of the baseline system is to offer a basic reference for the participants and so we do not consider these advanced tricks.\nIn order to gain more insight into the difficulties with mixlingual data, we look into the three different types of errors\nwith the system using the MIX LM. The results are showed in Table III. Firstly it can be seen that substitution errors take the largest proportion, as expected. Secondly we observe that both the substitution and deletion errors are much more significant for English than for Chinese. To have a better understanding, we tune the LM weight and word insertion penalty to balance the insertion and deletion errors, and find that when the performance on Chinese words improves, the performance on English words decreases, and vice versa. Further analysis on the resultant transcriptions show that most of the substitution errors overall on English words occur because some of them are recognized as Chinese words with similar pronunciations.\nThese observations suggest that the high WER on English words can be attributed to the competition between the two languages. Firstly, the English phones in the AM are generally weak, which may result in substitution of English phones by either the silence phone or the Chinese phones. The former leads to deletions, and the later leads to substitutions. Secondly, the probabilities of English words in the LM are much weaker than those of Chinese words, in particular the transition probabilities between English words and Chinese words. This encourages the decoding to remain in pure Chinese word sequence, and whenever an English word is encountered, it tends to be skipped over or substituted by a Chinese word, therefore leading to deletion and substitution errors, respectively. This suggests that a key challenge in mixlingual ASR is how to deal with the competition among languages, with respect to both phone posteriors and LM paths."}, {"heading": "V. CONCLUSION", "text": "We presented the data profile of the OC16-CE80 ChineseEnglish mixlingual speech database that was released to support the MixASR-CHEN challenge on O-COCOSDA 2016. The evaluation rules of the challenge were described, and a baseline system was presented. We showed that the OC16CE80 database is a suitable data resource for mixlingual speech recognition research."}, {"heading": "ACKNOWLEDGMENT", "text": "This work was supported by the National Natural Science Foundation of China under Grant No.61271389 and NO.61371136 and the National Basic Research Program (973 Program) of China under Grant No.2013CB329302."}], "references": [{"title": "Foundations of bilingual education and bilingualism", "author": ["C. Baker"], "venue": "Multilingual Matters,", "citeRegEx": "1", "shortCiteRegEx": "1", "year": 2011}, {"title": "Language contact", "author": ["Y. Matras"], "venue": null, "citeRegEx": "2", "shortCiteRegEx": "2", "year": 2009}, {"title": "The handbook of language contact", "author": ["R. Hickey"], "venue": null, "citeRegEx": "3", "shortCiteRegEx": "3", "year": 2010}, {"title": "Matras, Contact languages: A comprehensive guide", "author": ["Y.P. Bakker"], "venue": "Walter de Gruyter, 2013,", "citeRegEx": "4", "shortCiteRegEx": "4", "year": 2013}, {"title": "Bilingual language mixing: Why do bilinguals code-switch?", "author": ["R.R. Heredia", "J. Altarriba"], "venue": "Current Directions in Psychological Science,", "citeRegEx": "5", "shortCiteRegEx": "5", "year": 2001}, {"title": "Code-switching (linguistic)", "author": ["S. Poplack"], "venue": "International Encyclopedia of the Social and Behavioral sciences, pp. 2062\u20132065, 2001.", "citeRegEx": "6", "shortCiteRegEx": null, "year": 2001}, {"title": "The Cambridge handbook of linguistic code-switching", "author": ["A.J. Toribio", "B.E. Bullock"], "venue": null, "citeRegEx": "7", "shortCiteRegEx": "7", "year": 2012}, {"title": "Code-switching in conversation: Language, interaction and identity", "author": ["P. Auer"], "venue": null, "citeRegEx": "8", "shortCiteRegEx": "8", "year": 2013}, {"title": "Acoustic modeling of foreign words in a German speech recognition system.", "author": ["G. Stemmer", "E. N\u00f6th", "H. Niemann"], "venue": "Proceedings of the Annual Conference of International Speech Communication Association (INTERSPEECH),", "citeRegEx": "9", "shortCiteRegEx": "9", "year": 2001}, {"title": "Speech recognition on code-switching among the chinese dialects", "author": ["D.-C. Lyu", "R.-Y. Lyu", "Y.-c. Chiang", "C.-N. Hsu"], "venue": "Proceedings of IEEE International Conference on Acoustics, Speech and Signal Processing (ICASSP), vol. 1. IEEE, 2006.", "citeRegEx": "10", "shortCiteRegEx": null, "year": 2006}, {"title": "A first speech recognition system for mandarin-english code-switch conversational speech", "author": ["N.T. Vu", "D.-C. Lyu", "J. Weiner", "D. Telaar", "T. Schlippe", "F. Blaicher", "E.-S. Chng", "T. Schultz", "H. Li"], "venue": "Proceedings of IEEE International Conference on Acoustics, Speech and Signal Processing (ICASSP). IEEE, 2012, pp. 4889\u20134892.", "citeRegEx": "11", "shortCiteRegEx": null, "year": 2012}, {"title": "Implications of Sepedi/English code switching for asr systems", "author": ["T.I. Modipa", "M.H. Davel", "F. de Wet"], "venue": "Proceedings of Annual Symposium of the Pattern Recognition Association of South Africa (PRASA), 2013, pp. 64\u201369.", "citeRegEx": "12", "shortCiteRegEx": null, "year": 2013}, {"title": "Code-switching speech recognition for closely related languages", "author": ["T. Lyudovyk", "V. Pylypenko"], "venue": "Proceedings of International Workshop on Spoken Language Technologies for Under-resourced Languages (SLTU), pp. 188\u2013193, 2014.", "citeRegEx": "13", "shortCiteRegEx": null, "year": 2014}, {"title": "Investigating bilingual deep neural networks for automatic recognition of codeswitching frisian speech", "author": ["E. Y\u0131lmaz", "H. van den Heuvel", "D. van Leeuwen"], "venue": "Procedia Computer Science, vol. 81, pp. 159\u2013 166, 2016.", "citeRegEx": "14", "shortCiteRegEx": null, "year": 2016}, {"title": "Code-switch language model with inversion constraints for mixed language speech recognition.", "author": ["Y. Li", "P. Fung"], "venue": "Proceedings of International Conference on Computational Linguistics (COLING),", "citeRegEx": "15", "shortCiteRegEx": "15", "year": 2012}, {"title": "Recurrent neural network language modeling for code switching conversational speech", "author": ["H. Adel", "N.T. Vu", "F. Kraus", "T. Schlippe", "H. Li", "T. Schultz"], "venue": "Proceedings of IEEE International Conference on Acoustics, Speech and Signal Processing (ICASSP). IEEE, 2013, pp. 8411\u20138415.", "citeRegEx": "16", "shortCiteRegEx": null, "year": 2013}, {"title": "Features for factored language models for code-switching speech", "author": ["H. Adel", "K. Kirchhoff", "D. Telaar", "N.T. Vu", "T. Schlippe", "T. Schultz"], "venue": "Proceedings of International Workshop on Spoken Language Technologies for Under-resourced Languages (SLTU), pp. 32\u201338, 2014.", "citeRegEx": "17", "shortCiteRegEx": null, "year": 2014}, {"title": "Development of a cantonese-english code-mixing speech corpus", "author": ["J.Y. Chan", "P. Ching", "T. Lee"], "venue": "Proceedings of European Conference on Speech Communication and Technology (EUROSPEECH), 2005.", "citeRegEx": "18", "shortCiteRegEx": null, "year": 2005}, {"title": "Automatic segmentation and identification of mixed-language speech using delta-bic and lsa-based gmms", "author": ["C.-H. Wu", "Y.-H. Chiu", "C.-J. Shia", "C.-Y. Lin"], "venue": "IEEE Transactions on audio, speech, and language processing, vol. 14, no. 1, pp. 266\u2013276, 2006.", "citeRegEx": "19", "shortCiteRegEx": null, "year": 2006}, {"title": "Language identification on code-switching utterances using multiple cues.", "author": ["D.-C. Lyu", "R.-Y. Lyu"], "venue": "Proceedings of the Annual Conference of International Speech Communication Association (INTERSPEECH),", "citeRegEx": "20", "shortCiteRegEx": "20", "year": 2008}, {"title": "An analysis of a Mandarin English code-switching speech corpus: Seame", "author": ["D.-C. Lyu", "T.-P. Tan", "E.-S. Chng", "H. Li"], "venue": "Age, vol. 21, pp. 25\u20138, 2010.", "citeRegEx": "21", "shortCiteRegEx": null, "year": 2010}, {"title": "Mandarin-English codeswitching speech corpus in south-east asia: Seame", "author": ["D.C. Lyu", "T.P. Tan", "E.S. Chng", "H. Li"], "venue": "Language Resources and Evaluation, vol. 49, no. 3, pp. 581\u2013600, 2015.", "citeRegEx": "22", "shortCiteRegEx": null, "year": 2015}, {"title": "THCHS-30: A free chinese speech corpus", "author": ["D. Wang", "X. Zhang"], "venue": "arXiv preprint arXiv:1512.01882, 2015.", "citeRegEx": "23", "shortCiteRegEx": null, "year": 1882}, {"title": "The kaldi speech recognition toolkit", "author": ["D. Povey", "A. Ghoshal", "G. Boulianne", "L. Burget", "O. Glembek", "N. Goel", "M. Hannemann", "P. Motlicek", "Y. Qian", "P. Schwarz"], "venue": "Proceedings of IEEE workshop on automatic speech recognition and understanding. IEEE Signal Processing Society, 2011.", "citeRegEx": "24", "shortCiteRegEx": null, "year": 2011}, {"title": "A time delay neural network architecture for efficient modeling of long temporal contexts", "author": ["V. Peddinti", "D. Povey", "S. Khudanpur"], "venue": "Proceedings of the Annual Conference of International Speech Communication Association (INTERSPEECH). ISCA, 2015, pp. 2440\u20132444.", "citeRegEx": "25", "shortCiteRegEx": null, "year": 2015}, {"title": "Improving deep neural network acoustic models using generalized maxout networks", "author": ["X. Zhang", "J. Trmal", "D. Povey", "S. Khudanpur"], "venue": "Proceedings of IEEE International Conference on Acoustics, Speech and Signal Processing (ICASSP). IEEE, 2014, pp. 215\u2013219.", "citeRegEx": "26", "shortCiteRegEx": null, "year": 2014}, {"title": "Parallel training of deep neural networks with natural gradient and parameter averaging", "author": ["D. Povey", "X. Zhang", "S. Khudanpur"], "venue": "arXiv preprint arXiv:1410.7455, 2014.", "citeRegEx": "27", "shortCiteRegEx": null, "year": 2014}], "referenceMentions": [{"referenceID": 0, "context": "This brings about quick and remarkable change in our daily life, particularly the trend of internationalism, globalization and interculturalism [1].", "startOffset": 144, "endOffset": 147}, {"referenceID": 1, "context": "It can be simply the popularity of some foreign words, but be more as profound as the adoption of a foreign language as an official one [2], [3], [4].", "startOffset": 136, "endOffset": 139}, {"referenceID": 2, "context": "It can be simply the popularity of some foreign words, but be more as profound as the adoption of a foreign language as an official one [2], [3], [4].", "startOffset": 141, "endOffset": 144}, {"referenceID": 3, "context": "It can be simply the popularity of some foreign words, but be more as profound as the adoption of a foreign language as an official one [2], [3], [4].", "startOffset": 146, "endOffset": 149}, {"referenceID": 4, "context": "This may take place at various levels including sentence, phrase, or word [5], [6], [7], [8].", "startOffset": 74, "endOffset": 77}, {"referenceID": 5, "context": "This may take place at various levels including sentence, phrase, or word [5], [6], [7], [8].", "startOffset": 79, "endOffset": 82}, {"referenceID": 6, "context": "This may take place at various levels including sentence, phrase, or word [5], [6], [7], [8].", "startOffset": 84, "endOffset": 87}, {"referenceID": 7, "context": "This may take place at various levels including sentence, phrase, or word [5], [6], [7], [8].", "startOffset": 89, "endOffset": 92}, {"referenceID": 8, "context": "Speech recognition against code-switching has ignited interest in both robust acoustic modeling [9], [10], [11], [12], [13], [14] and language modeling [15], [16], [17].", "startOffset": 96, "endOffset": 99}, {"referenceID": 9, "context": "Speech recognition against code-switching has ignited interest in both robust acoustic modeling [9], [10], [11], [12], [13], [14] and language modeling [15], [16], [17].", "startOffset": 101, "endOffset": 105}, {"referenceID": 10, "context": "Speech recognition against code-switching has ignited interest in both robust acoustic modeling [9], [10], [11], [12], [13], [14] and language modeling [15], [16], [17].", "startOffset": 107, "endOffset": 111}, {"referenceID": 11, "context": "Speech recognition against code-switching has ignited interest in both robust acoustic modeling [9], [10], [11], [12], [13], [14] and language modeling [15], [16], [17].", "startOffset": 113, "endOffset": 117}, {"referenceID": 12, "context": "Speech recognition against code-switching has ignited interest in both robust acoustic modeling [9], [10], [11], [12], [13], [14] and language modeling [15], [16], [17].", "startOffset": 119, "endOffset": 123}, {"referenceID": 13, "context": "Speech recognition against code-switching has ignited interest in both robust acoustic modeling [9], [10], [11], [12], [13], [14] and language modeling [15], [16], [17].", "startOffset": 125, "endOffset": 129}, {"referenceID": 14, "context": "Speech recognition against code-switching has ignited interest in both robust acoustic modeling [9], [10], [11], [12], [13], [14] and language modeling [15], [16], [17].", "startOffset": 152, "endOffset": 156}, {"referenceID": 15, "context": "Speech recognition against code-switching has ignited interest in both robust acoustic modeling [9], [10], [11], [12], [13], [14] and language modeling [15], [16], [17].", "startOffset": 158, "endOffset": 162}, {"referenceID": 16, "context": "Speech recognition against code-switching has ignited interest in both robust acoustic modeling [9], [10], [11], [12], [13], [14] and language modeling [15], [16], [17].", "startOffset": 164, "endOffset": 168}, {"referenceID": 17, "context": "Cantonese-English, EnglishMandarin, Mandarin-Taiwanese and Mandarin-English [18], [10], [19], [20], [21].", "startOffset": 76, "endOffset": 80}, {"referenceID": 9, "context": "Cantonese-English, EnglishMandarin, Mandarin-Taiwanese and Mandarin-English [18], [10], [19], [20], [21].", "startOffset": 82, "endOffset": 86}, {"referenceID": 18, "context": "Cantonese-English, EnglishMandarin, Mandarin-Taiwanese and Mandarin-English [18], [10], [19], [20], [21].", "startOffset": 88, "endOffset": 92}, {"referenceID": 19, "context": "Cantonese-English, EnglishMandarin, Mandarin-Taiwanese and Mandarin-English [18], [10], [19], [20], [21].", "startOffset": 94, "endOffset": 98}, {"referenceID": 20, "context": "Cantonese-English, EnglishMandarin, Mandarin-Taiwanese and Mandarin-English [18], [10], [19], [20], [21].", "startOffset": 100, "endOffset": 104}, {"referenceID": 21, "context": "The OC16-CE80 database is similar to the SEAME database [22] as both are Mandarin-English code-switching, but the speakers of SEAME are from Singaporean and Malaysian, whereas the speakers of OC16CE80 are totally from the China mainland.", "startOffset": 56, "endOffset": 60}, {"referenceID": 22, "context": "\u2022 THCHS30 [23], a pure Chinese speech database provided by CSLT at Tsinghua University, free and online downloable4.", "startOffset": 10, "endOffset": 14}, {"referenceID": 23, "context": "The experiments were conducted with the Kaldi toolkit [24].", "startOffset": 54, "endOffset": 58}, {"referenceID": 24, "context": "The DNN model we used was the time-delay neural network (TDNN) [25].", "startOffset": 63, "endOffset": 67}, {"referenceID": 25, "context": "It contained 6 hidden layers, and the activation function was p-norm [26].", "startOffset": 69, "endOffset": 73}, {"referenceID": 26, "context": "The natural stochastic gradient descent (NSGD) algorithm was employed to train the TDNN [27].", "startOffset": 88, "endOffset": 92}], "year": 2016, "abstractText": "We present the OC16-CE80 Chinese-English mixlingual speech database which was released as a main resource for training, development and test for the Chinese-English mixlingual speech recognition (MixASR-CHEN) challenge on O-COCOSDA 2016. This database consists of 80 hours of speech signals recorded from more than 1,400 speakers, where the utterances are in Chinese but each involves one or several English words. Based on the database and another two free data resources (THCHS30 and the CMU dictionary), a speech recognition (ASR) baseline was constructed with the deep neural network-hidden Markov model (DNN-HMM) hybrid system. We then report the baseline results following the MixASR-CHEN evaluation rules and demonstrate that OC16-CE80 is a reasonable data resource for mixlingual research.", "creator": "LaTeX with hyperref package"}}}