{"id": "1610.00602", "review": {"conference": "arxiv", "VERSION": "v1", "DATE_OF_SUBMISSION": "3-Oct-2016", "title": "Multimodal Semantic Simulations of Linguistically Underspecified Motion Events", "abstract": "in producing this paper, we basically describe a database system for generating transparent three - dimensional conceptual visual simulations of natural language motion expressions. nowadays we use developing a conceptual rich formal model of events database and ensure their participants interface to generate simulations documents that satisfy the minimal constraints entailed often by excluding the previously associated utterance, collectively relying intently on semantic knowledge of physical process objects and global motion events. this latest paper outlines technical considerations and discusses implementing the mutually aforementioned semantic value models directly into such a system.", "histories": [["v1", "Mon, 3 Oct 2016 15:40:08 GMT  (818kb,D)", "http://arxiv.org/abs/1610.00602v1", null]], "reviews": [], "SUBJECTS": "cs.CL", "authors": ["nikhil krishnaswamy", "james pustejovsky"], "accepted": false, "id": "1610.00602"}, "pdf": {"name": "1610.00602.pdf", "metadata": {"source": "META", "title": "Multimodal Semantic Simulations of Linguistically Underspecified Motion Events", "authors": ["Nikhil Krishnaswamy", "James Pustejovsky"], "emails": ["nkrishna@brandeis.edu", "jamesp@brandeis.edu"], "sections": [{"heading": null, "text": "Keywords: spatial cognition; spatial reasoning; spatial language; event semantics; simulation semantics; spatial information representation; spatial information processing; underspecification"}, {"heading": "1 Introduction", "text": "Existing work in visualization from natural language has largely focused on object placement in static scenes [3, 5, 31]. By focusing on motion verbs, in this paper we outline an approach to integrating dynamic semantics into visualization, resulting in simulations of the associated actions. In philosophy, \u201cmental simulation\u201d theory attempts to model everyday human psychological competence [19], providing a process driven theory of mind [13]. In cognitive linguistics, \u201csimulation\u201d has come to mean a mental instantiation of a linguistic utterance, playing a functional role in language understanding [7, 1], based on the notion of an agent\u2019s embodiment [23]. Finally, both QSR and gaming-style AI approaches have been used to develop scenario-based simulators, such as for trainers driven by interactive narratives [8, 6].\nIn a dynamic semantics approach, verbs are treated as programs or processes [17] and so although the computational linguistics and cognitive linguistics communities do not often reference each other, in our opinion there is fertile ground for cross-pollination, starting with the approach of Pustejovsky and Moszkowicz [29], and to implement language-based reasoning in a QSR framework.\nWe previously presented a method for visualizing natural language expressions in a 3D environment built on the Unity game engine [27]. This was followed by the development of VoxML [28], a modeling language which encodes object and event semantic information into voxemes or \u201cvisual object concepts,\u201d and\nar X\niv :1\n61 0.\n00 60\n2v 1\n[ cs\n.C L\n] 3\nO ct\n2 01\n6\na voxicon (the \u201clexicon\u201d of voxemes). This approach enables procedural simulation generation from semantic knowledge of an event and its participants. Our system, given an utterance and scene containing all referenced nominals as 3D objects, enacts the verbal program over them. The remainder of this paper describes in brief the workflow of this system, the Voxicon simulator."}, {"heading": "2 Architecture", "text": "The software uses the Unity game engine [14] for graphics and I/O processing. Input is a simple natural language sentence, which is part-of-speech tagged and dependency-parsed. These NLP tasks are currently handled by external processors (such as the ClearNLP parser [4]) networked to the simulator. 3D assets and VoxML-modeled nominal objects and events (created with other Unity-based tools) are loaded externally, either locally or from a web server."}, {"heading": "3 Linguistic and Semantic Analysis", "text": "From tagged and parsed input text, all noun phrases are cross-referenced to objects in the scene. A reference to ball causes the simulator to attempt to locate a \u201cball\u201d voxeme instance in the scene while table prompts an attempt to locate a \u201ctable\u201d voxeme instance. Attributive adjectives impose a sortal scale on their heads, so small table and big table link to two separate tables if they exist in the scene, and the VoxML-encoded semantics of \u201csmall\u201d and \u201cbig\u201d discriminates the tables based on their relative size [28].\nWe use a basic set of primitive programs to represent verbs, from which we build more complex programs. There have been many previous attempts to group verbs into distinct clusters, based on syntactic behavior [16], or to associate verbs with specific spatial semantic primitives [22]. Frameworks from the computer vision and AI communities include work on representing traffic occurrences [11] and in human-robot communication [32]. VoxML follows a similar model-theoretic approach, and while VoxML and voxeme primitive programs have an underlying semantics of a hybrid dynamic logic [29], their content is largely based on implementation considerations, and focus on decomposing the verbal and relational semantics while leaving object category labels intact, similar to approaches that seek to overcome descriptive constraints limited by robotic perception [21].\nAll 3D motion can be decomposed into translations and rotations, making those obvious verbal primitives in our system. Others include commonlyrepeating subevents of other motions, such as \u201cgrasp,\u201d a fine-grained motion that is difficult to decompose but appears as a subevent of nearly any human-object interaction. We can then assemble complex events out of primitive motions, as in \u201cput\u201d in Fig. 2 below, and then macro-complex events, such as \u201cstack\u201d as a sequence of \u201cput\u201d events."}, {"heading": "3.1 Habitats and Affordances", "text": "We assume that every voxeme exists within an intrinsic \u201chabitat\u201d [25, 20], an encoding of the environment in which the object must exist simply to avoid violating any physical constraints, such as gravity, and conditions under which an object typically exists in the world. For instance, a pencil must be laying flat and not resting on its tip. A table can be situated in almost any orientation, but has an intrinsic \u201ctop\u201d (its surface). This is typically oriented along the world\u2019s upward vector, so we denote this in VoxML with top = top(+Y ).\nA voxeme\u2019s semantic structure also provides \u201cGibsonian\u201d and \u201ctelic\u201d affordances [12, 24, 26], or attached behaviors, which the object either facilitates by its geometry, or purposes for which it is intended to be used. For example, a Gibsonian affordance for a cup may be \u201cgrasp,\u201d while a telic affordance may be \u201cdrink from.\u201d"}, {"heading": "3.2 Predicate-Argument Interaction", "text": "VoxML treats objects (NPs) and events (predicates) in terms of a dynamic event semantics, Dynamic Interval Temporal Logic (DITL) [29]. The verbal semantics follow a type system that encodes how a given formula \u03c6 and proposition \u03c0 are executed/tested during the execution of a verbal program; programs can be a state, process, transition, assignment, or test, all of which are translated into DITL and operationalized differently.\nAdopting a dynamic interpretation of events allows us to map linguistic expressions directly into simulations through an operational semantics. Further, predicates are interpreted relative to their arguments\u2019 semantic encoding.\nIn Fig. 2, \u201cput\u201d is given arguments agent, obj1, and on(obj2). The typing of both \u201cput\u201d and \u201con\u201d encode the calculation of such parameters as object trajectory and destination location (e.g. the position denoted by on(block) vs on(plate) or on(wall)). As seen in body, object A2 is moved to location A3, calculated by operationalizing on over obj2. The results, depending on the arguments, may be configurations such as those shown in Figs. 3-5.\nArgument-sensitive distinctions in the operationalization of predicates themselves exploit the head of the argument\u2019s type structure\u2014a selected surface wholly or partially coterminous with the entire object.\nFor example, on(wall) selects for a vertical face of the object while in all other examples, on selects for the object\u2019s top. The location of \u201ctop\u201d is computed based on the object\u2019s VoxML type structure. The top of a plate, a slightly concave object when situated in its default habitat, is located slightly lower on the Y-axis than the plate\u2019s highest point. in(cup) selects the interior surface of the cup, an object with a telic affordance of containment, while in(wall) explicitly interpenetrates the wall, as \u201cwall\u201d lacks the containment telic role. The system attempts to maximally satisfy the constraints placed upon it by the NL expression. For instance, placing the knife object on(cup) lays the knife across the rim of the upright cup. In the same (horizontal) orientation, the knife cannot be placed at the location computed by in(cup), so the system must transform the knife so that the RCC representation of in(cup), PO(knife, cup), can be satisfied without violating any of the physical or structural constraints of the cup or knife objects.\nGiven any object pair, the system can pinpoint the set of RCC relations applying to them in the current state. RCC8 relations in 3D may leave the dimensionality of the relation unspecified, so VoxML picks up here.1 For example, in VoxML a \u201ccup\u201d is a concave object with reflectional symmetry across the XY and YZ planes, and with rotational symmetry around the Y axis. The symmetry information entails that the concavity must open along the Y axis while the habitat information entails that it opens toward the top of the cup in default orientation. The cup\u2019s affordance structure includes containment, so any object to be placed \u201cin\u201d the cup must be tested to see if it fits inside when aligned to the cup\u2019s Y axis along its longest dimension."}, {"heading": "4 Discussion and Future Work", "text": "We have presented here a method for incorporating motion and dynamic spatial semantics into a visualization framework. Generating a visualization at runtime necessitates some constraints left unspecified in a minimal model be made explicit in the simulation. These include direction in a bare manner-of-motion verb (e.g. \u201cthe ball rolled\u201d). We are developing a Monte-Carlo method to determine prototypical values for these constraints, as well as evaluation methods for the results of these experiments. In instances where a program\u2019s DITL formula says nothing about the nature of a given parameter (e.g. states that bn+1 is farther from b0 than bn is but does not state in which direction), this Monte-Carlo method should allow us to either compute a \u201cprototypical value\u201d for that parameter, or to state that none seems evident. We are exploring three evaluation\n1 The currently-implemented reasoning approach relies on RCC8 [30, 9, 10], but can easily be extended to other QSR approaches, including the situation calculus [2], and the Intersection Calculus [18, 15].\nmethods to determine which variable values occur in the simulation(s) judged the best for a given description label:\n1. Given a visualization and a set of potential descriptions, use Amazon Mechanical Turk to gather the best description. 2. Given a description and a set of possible simulations, gather the best simulation. 3. Using operationalizations of corpus-derived verb satisfaction conditions, automatically compute vector distance from a simulation\u2019s final state to the satisfaction condition.\nFinally, we are also developing methods for automatically composing complex behaviors from primitives, based on Dynamic Interval Temporal Logic [29] as well as building a corpus of linked simulations and event-annotated video in order to train algorithms to discriminate events based on their participants\u2019 motions."}, {"heading": "Acknowledgements", "text": "This work is supported by a contract with the US Defense Advanced Research Projects Agency (DARPA), Contract W911NF-15-C-0238. Approved for Public Release, Distribution Unlimited. The views expressed are those of the authors and do not reflect the official policy or position of the Department of Defense or the U.S. Government. All errors and mistakes are, of course, the responsibilities of the authors."}], "references": [{"title": "Louder than words: The new science of how the mind makes meaning", "author": ["B.K. Bergen"], "venue": "Basic Books", "citeRegEx": "1", "shortCiteRegEx": null, "year": 2012}, {"title": "Modelling dynamic spatial systems in the situation calculus", "author": ["M. Bhatt", "S. Loke"], "venue": "Spatial Cognition and Computation", "citeRegEx": "2", "shortCiteRegEx": null, "year": 2008}, {"title": "Text to 3d scene generation with rich lexical grounding", "author": ["A. Chang", "W. Monroe", "M. Savva", "C. Potts", "C.D. Manning"], "venue": "arXiv preprint arXiv:1505.06289", "citeRegEx": "3", "shortCiteRegEx": null, "year": 2015}, {"title": "Transition-based dependency parsing with selectional branching", "author": ["J.D. Choi", "A. McCallum"], "venue": "ACL (1). pp. 1052\u20131062", "citeRegEx": "4", "shortCiteRegEx": null, "year": 2013}, {"title": "Wordseye: an automatic text-to-scene conversion system", "author": ["B. Coyne", "R. Sproat"], "venue": "Proceedings of the 28th annual conference on Computer graphics and interactive techniques. pp. 487\u2013496. ACM", "citeRegEx": "5", "shortCiteRegEx": null, "year": 2001}, {"title": "From molecule to metaphor: A neural theory of language", "author": ["J. Feldman"], "venue": "MIT press", "citeRegEx": "7", "shortCiteRegEx": null, "year": 2006}, {"title": "How qualitative spatial reasoning can improve strategy game ais", "author": ["K.D. Forbus", "J.V. Mahoney", "K. Dill"], "venue": "IEEE Intelligent Systems 17(4), 25\u201330", "citeRegEx": "8", "shortCiteRegEx": null, "year": 2002}, {"title": "Towards an integrated logic of space, time, and motion", "author": ["A. Galton"], "venue": "Bajcsy, R. (ed.) Proceedings of the Thirteenth International Joint Conference on Artificial Intelligence (IJCAI\u201993). pp. 1550\u20135. Morgan Kaufmann, San Mateo, CA", "citeRegEx": "9", "shortCiteRegEx": null, "year": 1993}, {"title": "Qualitative Spatial Change", "author": ["A. Galton"], "venue": "Oxford University Press, Oxford", "citeRegEx": "10", "shortCiteRegEx": null, "year": 2000}, {"title": "Representation of occurrences for road vehicle traffic", "author": ["R. Gerber", "H.H. Nagel"], "venue": "Artificial Intelligence 172(4), 351\u2013391", "citeRegEx": "11", "shortCiteRegEx": null, "year": 2008}, {"title": "Reasons for realism: Selected essays of James J", "author": ["J.J. Gibson", "E.S. Reed", "R. Jones"], "venue": "Gibson. Lawrence Erlbaum Associates", "citeRegEx": "12", "shortCiteRegEx": null, "year": 1982}, {"title": "Simulating minds: The philosophy, psychology, and neuroscience of mindreading", "author": ["A.I. Goldman"], "venue": "Oxford University Press", "citeRegEx": "13", "shortCiteRegEx": null, "year": 2006}, {"title": "Unity Game Development Essentials", "author": ["W. Goldstone"], "venue": "Packt Publishing Ltd", "citeRegEx": "14", "shortCiteRegEx": null, "year": 2009}, {"title": "The 9+ intersection for topological relations between a directed line segment and a region", "author": ["Y. Kurata", "M. Egenhofer"], "venue": "Gottfried, B. (ed.) Workshop on Behaviour and Monitoring Interpretation. pp. 62\u201376. Germany", "citeRegEx": "15", "shortCiteRegEx": null, "year": 2007}, {"title": "English verb class and alternations: a preliminary investigation", "author": ["B. Levin"], "venue": "University of Chicago Press", "citeRegEx": "16", "shortCiteRegEx": null, "year": 1993}, {"title": "Interpreting Motion: Grounded Representations for Spatial Language", "author": ["I. Mani", "J. Pustejovsky"], "venue": "Oxford University Press", "citeRegEx": "17", "shortCiteRegEx": null, "year": 2012}, {"title": "Topology of prototypical spatial relations between lines and regions in english and spanish", "author": ["D. Mark", "M. Egenhofer"], "venue": "Proceedings of the Twelfth International Symposium on Computer- Assisted Cartography. vol. 4, pp. 245\u2013254", "citeRegEx": "18", "shortCiteRegEx": null, "year": 1995}, {"title": "Handbook of imagination and mental simulation", "author": ["K.D. Markman", "W.M. Klein", "J.A. Suhr"], "venue": "Psychology", "citeRegEx": "19", "shortCiteRegEx": null, "year": 2012}, {"title": "On the representation of inferences and their lexicalization", "author": ["D. McDonald", "J. Pustejovsky"], "venue": "Advances in Cognitive Systems. vol. 3", "citeRegEx": "20", "shortCiteRegEx": null, "year": 2014}, {"title": "Cognitive modeling of spatial reference for human-robot interaction", "author": ["R. Moratz", "K. Fischer", "T. Tenbrink"], "venue": "International Journal on Artificial Intelligence Tools 10(04), 589\u2013611", "citeRegEx": "21", "shortCiteRegEx": null, "year": 2001}, {"title": "A qualitative theory of motion based on spatio-temporal primitives", "author": ["P. Muller"], "venue": "Cohn, A.G., Schubert, L., Shapiro, S.C. (eds.) KR\u201998: Principles of Knowledge Representation and Reasoning, pp. 131\u2013141. Morgan Kaufmann, San Francisco, California", "citeRegEx": "22", "shortCiteRegEx": null, "year": 1998}, {"title": "KARMA: Knowledge-based active representations for metaphor and aspect", "author": ["S.S. Narayanan"], "venue": "University of California, Berkeley", "citeRegEx": "23", "shortCiteRegEx": null, "year": 1997}, {"title": "The Generative Lexicon", "author": ["J. Pustejovsky"], "venue": "Bradford Book, Mit Press", "citeRegEx": "24", "shortCiteRegEx": null, "year": 1995}, {"title": "Dynamic event structure and habitat theory", "author": ["J. Pustejovsky"], "venue": "Proceedings of the 6th International Conference on Generative Approaches to the Lexicon (GL2013). pp. 1\u201310. ACL", "citeRegEx": "25", "shortCiteRegEx": null, "year": 2013}, {"title": "Affordances and the functional characterization of space", "author": ["J. Pustejovsky"], "venue": "Cognitive Processing. vol. 16, pp. S43\u2013S43. Springer Heidelberg", "citeRegEx": "26", "shortCiteRegEx": null, "year": 2015}, {"title": "Generating simulations of motion events from verbal descriptions", "author": ["J. Pustejovsky", "N. Krishnaswamy"], "venue": "Lexical and Computational Semantics (* SEM 2014) p. 99", "citeRegEx": "27", "shortCiteRegEx": null, "year": 2014}, {"title": "Voxml: A visual object modeling language", "author": ["J. Pustejovsky", "N. Krishnaswamy"], "venue": "Proceedings of LREC", "citeRegEx": "28", "shortCiteRegEx": null, "year": 2016}, {"title": "The qualitative spatial dynamics of motion", "author": ["J. Pustejovsky", "J. Moszkowicz"], "venue": "The Journal of Spatial Cognition and Computation", "citeRegEx": "29", "shortCiteRegEx": null, "year": 2011}, {"title": "A spatial logic based on regions and connections", "author": ["D. Randell", "Z. Cui", "A. Cohn"], "venue": "Kaufmann, M. (ed.) Proceedings of the 3rd Internation Conference on Knowledge Representation and REasoning. pp. 165\u2013176. San Mateo", "citeRegEx": "30", "shortCiteRegEx": null, "year": 1992}, {"title": "Grounding the lexical semantics of verbs in visual perception using force dynamics and event logic", "author": ["J.M. Siskind"], "venue": "J. Artif. Intell. Res.(JAIR) 15, 31\u201390", "citeRegEx": "31", "shortCiteRegEx": null, "year": 2001}, {"title": "Spatial language for human-robot dialogs", "author": ["M. Skubic", "D. Perzanowski", "S. Blisard", "A. Schultz", "W. Adams", "M. Bugajska", "D. Brock"], "venue": "Systems, Man, and Cybernetics, Part C: Applications and Reviews, IEEE Transactions on 34(2), 154\u2013167", "citeRegEx": "32", "shortCiteRegEx": null, "year": 2004}], "referenceMentions": [{"referenceID": 2, "context": "Existing work in visualization from natural language has largely focused on object placement in static scenes [3, 5, 31].", "startOffset": 110, "endOffset": 120}, {"referenceID": 4, "context": "Existing work in visualization from natural language has largely focused on object placement in static scenes [3, 5, 31].", "startOffset": 110, "endOffset": 120}, {"referenceID": 29, "context": "Existing work in visualization from natural language has largely focused on object placement in static scenes [3, 5, 31].", "startOffset": 110, "endOffset": 120}, {"referenceID": 17, "context": "In philosophy, \u201cmental simulation\u201d theory attempts to model everyday human psychological competence [19], providing a process driven theory of mind [13].", "startOffset": 100, "endOffset": 104}, {"referenceID": 11, "context": "In philosophy, \u201cmental simulation\u201d theory attempts to model everyday human psychological competence [19], providing a process driven theory of mind [13].", "startOffset": 148, "endOffset": 152}, {"referenceID": 5, "context": "In cognitive linguistics, \u201csimulation\u201d has come to mean a mental instantiation of a linguistic utterance, playing a functional role in language understanding [7, 1], based on the notion of an agent\u2019s embodiment [23].", "startOffset": 158, "endOffset": 164}, {"referenceID": 0, "context": "In cognitive linguistics, \u201csimulation\u201d has come to mean a mental instantiation of a linguistic utterance, playing a functional role in language understanding [7, 1], based on the notion of an agent\u2019s embodiment [23].", "startOffset": 158, "endOffset": 164}, {"referenceID": 21, "context": "In cognitive linguistics, \u201csimulation\u201d has come to mean a mental instantiation of a linguistic utterance, playing a functional role in language understanding [7, 1], based on the notion of an agent\u2019s embodiment [23].", "startOffset": 211, "endOffset": 215}, {"referenceID": 6, "context": "Finally, both QSR and gaming-style AI approaches have been used to develop scenario-based simulators, such as for trainers driven by interactive narratives [8, 6].", "startOffset": 156, "endOffset": 162}, {"referenceID": 15, "context": "In a dynamic semantics approach, verbs are treated as programs or processes [17] and so although the computational linguistics and cognitive linguistics communities do not often reference each other, in our opinion there is fertile ground for cross-pollination, starting with the approach of Pustejovsky and Moszkowicz [29], and to implement language-based reasoning in a QSR framework.", "startOffset": 76, "endOffset": 80}, {"referenceID": 27, "context": "In a dynamic semantics approach, verbs are treated as programs or processes [17] and so although the computational linguistics and cognitive linguistics communities do not often reference each other, in our opinion there is fertile ground for cross-pollination, starting with the approach of Pustejovsky and Moszkowicz [29], and to implement language-based reasoning in a QSR framework.", "startOffset": 319, "endOffset": 323}, {"referenceID": 25, "context": "We previously presented a method for visualizing natural language expressions in a 3D environment built on the Unity game engine [27].", "startOffset": 129, "endOffset": 133}, {"referenceID": 26, "context": "This was followed by the development of VoxML [28], a modeling language which encodes object and event semantic information into voxemes or \u201cvisual object concepts,\u201d and ar X iv :1 61 0.", "startOffset": 46, "endOffset": 50}, {"referenceID": 12, "context": "The software uses the Unity game engine [14] for graphics and I/O processing.", "startOffset": 40, "endOffset": 44}, {"referenceID": 3, "context": "These NLP tasks are currently handled by external processors (such as the ClearNLP parser [4]) networked to the simulator.", "startOffset": 90, "endOffset": 93}, {"referenceID": 26, "context": "Attributive adjectives impose a sortal scale on their heads, so small table and big table link to two separate tables if they exist in the scene, and the VoxML-encoded semantics of \u201csmall\u201d and \u201cbig\u201d discriminates the tables based on their relative size [28].", "startOffset": 253, "endOffset": 257}, {"referenceID": 14, "context": "There have been many previous attempts to group verbs into distinct clusters, based on syntactic behavior [16], or to associate verbs with specific spatial semantic primitives [22].", "startOffset": 106, "endOffset": 110}, {"referenceID": 20, "context": "There have been many previous attempts to group verbs into distinct clusters, based on syntactic behavior [16], or to associate verbs with specific spatial semantic primitives [22].", "startOffset": 176, "endOffset": 180}, {"referenceID": 9, "context": "Frameworks from the computer vision and AI communities include work on representing traffic occurrences [11] and in human-robot communication [32].", "startOffset": 104, "endOffset": 108}, {"referenceID": 30, "context": "Frameworks from the computer vision and AI communities include work on representing traffic occurrences [11] and in human-robot communication [32].", "startOffset": 142, "endOffset": 146}, {"referenceID": 27, "context": "VoxML follows a similar model-theoretic approach, and while VoxML and voxeme primitive programs have an underlying semantics of a hybrid dynamic logic [29], their content is largely based on implementation considerations, and focus on decomposing the verbal and relational semantics while leaving object category labels intact, similar to approaches that seek to overcome descriptive constraints limited by robotic perception [21].", "startOffset": 151, "endOffset": 155}, {"referenceID": 19, "context": "VoxML follows a similar model-theoretic approach, and while VoxML and voxeme primitive programs have an underlying semantics of a hybrid dynamic logic [29], their content is largely based on implementation considerations, and focus on decomposing the verbal and relational semantics while leaving object category labels intact, similar to approaches that seek to overcome descriptive constraints limited by robotic perception [21].", "startOffset": 426, "endOffset": 430}, {"referenceID": 23, "context": "We assume that every voxeme exists within an intrinsic \u201chabitat\u201d [25, 20], an encoding of the environment in which the object must exist simply to avoid violating any physical constraints, such as gravity, and conditions under which an object typically exists in the world.", "startOffset": 65, "endOffset": 73}, {"referenceID": 18, "context": "We assume that every voxeme exists within an intrinsic \u201chabitat\u201d [25, 20], an encoding of the environment in which the object must exist simply to avoid violating any physical constraints, such as gravity, and conditions under which an object typically exists in the world.", "startOffset": 65, "endOffset": 73}, {"referenceID": 10, "context": "A voxeme\u2019s semantic structure also provides \u201cGibsonian\u201d and \u201ctelic\u201d affordances [12, 24, 26], or attached behaviors, which the object either facilitates by its geometry, or purposes for which it is intended to be used.", "startOffset": 80, "endOffset": 92}, {"referenceID": 22, "context": "A voxeme\u2019s semantic structure also provides \u201cGibsonian\u201d and \u201ctelic\u201d affordances [12, 24, 26], or attached behaviors, which the object either facilitates by its geometry, or purposes for which it is intended to be used.", "startOffset": 80, "endOffset": 92}, {"referenceID": 24, "context": "A voxeme\u2019s semantic structure also provides \u201cGibsonian\u201d and \u201ctelic\u201d affordances [12, 24, 26], or attached behaviors, which the object either facilitates by its geometry, or purposes for which it is intended to be used.", "startOffset": 80, "endOffset": 92}, {"referenceID": 27, "context": "VoxML treats objects (NPs) and events (predicates) in terms of a dynamic event semantics, Dynamic Interval Temporal Logic (DITL) [29].", "startOffset": 129, "endOffset": 133}, {"referenceID": 28, "context": "1 The currently-implemented reasoning approach relies on RCC8 [30, 9, 10], but can easily be extended to other QSR approaches, including the situation calculus [2], and the Intersection Calculus [18, 15].", "startOffset": 62, "endOffset": 73}, {"referenceID": 7, "context": "1 The currently-implemented reasoning approach relies on RCC8 [30, 9, 10], but can easily be extended to other QSR approaches, including the situation calculus [2], and the Intersection Calculus [18, 15].", "startOffset": 62, "endOffset": 73}, {"referenceID": 8, "context": "1 The currently-implemented reasoning approach relies on RCC8 [30, 9, 10], but can easily be extended to other QSR approaches, including the situation calculus [2], and the Intersection Calculus [18, 15].", "startOffset": 62, "endOffset": 73}, {"referenceID": 1, "context": "1 The currently-implemented reasoning approach relies on RCC8 [30, 9, 10], but can easily be extended to other QSR approaches, including the situation calculus [2], and the Intersection Calculus [18, 15].", "startOffset": 160, "endOffset": 163}, {"referenceID": 16, "context": "1 The currently-implemented reasoning approach relies on RCC8 [30, 9, 10], but can easily be extended to other QSR approaches, including the situation calculus [2], and the Intersection Calculus [18, 15].", "startOffset": 195, "endOffset": 203}, {"referenceID": 13, "context": "1 The currently-implemented reasoning approach relies on RCC8 [30, 9, 10], but can easily be extended to other QSR approaches, including the situation calculus [2], and the Intersection Calculus [18, 15].", "startOffset": 195, "endOffset": 203}, {"referenceID": 27, "context": "Finally, we are also developing methods for automatically composing complex behaviors from primitives, based on Dynamic Interval Temporal Logic [29] as well as building a corpus of linked simulations and event-annotated video in order to train algorithms to discriminate events based on their participants\u2019 motions.", "startOffset": 144, "endOffset": 148}], "year": 2016, "abstractText": "In this paper, we describe a system for generating threedimensional visual simulations of natural language motion expressions. We use a rich formal model of events and their participants to generate simulations that satisfy the minimal constraints entailed by the associated utterance, relying on semantic knowledge of physical objects and motion events. This paper outlines technical considerations and discusses implementing the aforementioned semantic models into such a system.", "creator": "LaTeX with hyperref package"}}}