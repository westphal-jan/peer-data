{"id": "1611.00549", "review": {"conference": "arxiv", "VERSION": "v1", "DATE_OF_SUBMISSION": "2-Nov-2016", "title": "Inferring Coupling of Distributed Dynamical Systems via Transfer Entropy", "abstract": "in this work, we are interested in structure learning for testing a set framework of spatially distributed systemic dynamical systems, notably where some individual subsystems initially are coupled progressively via latent variables instead and simultaneously observed through a filter. normally we ideally represent this model as a directed acyclic ladder graph ( hierarchical dag ) representation that also characterises the systematic unidirectional coupling between subsystems. three standard approaches to investigate structure learning are just not applicable here in this framework obviously due to the hidden variables, however we could can exploit clearly the coupling properties learned of certain dynamical linear systems to formulate exact sum methods based on state stream space reconstruction. we approach the problem originally by using mathematical reconstruction theorems used to analytically derive accurately a tractable expression for the continuous kl - bp divergence of a candidate causal dag from the observed sample dataset. whereby we show ourselves this measure estimation can be adequately decomposed as a reward function combinations of the two information - gap theoretic sum measures, transfer direct entropy and stochastic matrix interaction. ultimately we then present from two mathematically robust scoring functions based on temporal transfer induced entropy determination and statistical state independence correlation tests. these results support even the previously privately held newell conjecture that transfer entropy constraints can essentially be efficiently used simply to infer further effective connectivity in otherwise complex networks.", "histories": [["v1", "Wed, 2 Nov 2016 11:23:54 GMT  (52kb,D)", "http://arxiv.org/abs/1611.00549v1", null]], "reviews": [], "SUBJECTS": "cs.AI", "authors": ["oliver m cliff", "mikhail prokopenko", "robert fitch"], "accepted": false, "id": "1611.00549"}, "pdf": {"name": "1611.00549.pdf", "metadata": {"source": "CRF", "title": "Inferring Coupling of Distributed Dynamical Systems via Transfer Entropy", "authors": ["Oliver M. Cliff", "Mikhail Prokopenko", "Robert Fitch"], "emails": ["o.cliff@acfr.usyd.edu.au", "mikhail.prokopenko@sydney.edu.au", "robert.fitch@uts.edu.au"], "sections": [{"heading": "1 Introduction", "text": "Complex networks are capable of modelling a wide array of important phenomena in both natural and artificial environments [1]. This work focuses on a particular complex network which comprises spatially distributed dynamical systems. We represent this network as a type of probabilistic graphical model termed a synchronous graph dynamical system (GDS) [2, 3]. We are interested in structure learning for synchronous GDSs whose structure is given by a directed acyclic graph (DAG), that is, the problem of inferring directed relationships between hidden variables from an observed dataset. We propose a solution based on the concept of transfer entropy, which is a measure that detects the directed information-theoretic dependency between random processes [4]. Specifically, we prove, under certain technical assumptions of the system, that the maximum transfer entropy graph is the optimal information-theoretic model. We then employ this result in developing a number of mathematically robust scoring functions for the structure learning problem.\nThis structure learning problem has applications in a wide variety of areas due to its usefulness for performing efficient inference in discrete-time dynamical systems, in addition to understanding the system\u2019s complex structure. Dynamical systems are characterised by a map that describes their evolution over time and a read-out function through which we observe the latent state. These systems are ubiquitous in the literature due to their ability to model many real-world phenomena. Our\nar X\niv :1\n61 1.\n00 54\n9v 1\n[ cs\n.A I]\nresearch focuses on the more general case of a multivariate system, where a set of these subsystems are spatially distributed and unidirectionally coupled to one another. The problem of inferring this coupling is an important multidisciplinary study in fields such as multi-agent systems [5, 6], ecology [7], neuroscience [8, 9], and various others studying artificial and biological systems [1].\nA main challenge in structure learning for DAGs is the case where variables are unobserved. Exact methods are known for fully observable systems [10], however, these are not applicable because the state variables in dynamical systems are latent. Our goal in this paper is to exploit results from differential topology in inferring hidden coupling. Specifically, the main focus of this paper is to analytically derive a measure for comparing a candidate graph to the underlying graph that generated a measured dataset. Such a measure can then be used to solve the two subproblems that comprise structure learning, evaluation and identification [11], and hence find the optimal model that explains the data.\nOur approach in deriving a measure that can be used to solve the evaluation problem can be described in terms of model selection. It is desirable to select the simplest model that incorporates all statistical knowledge. This concept is commonly expressed via information theory, where an established technique is to evaluate the encoding length of the data, given the model [12, 13, 14]. The simplest model should aim to minimise code length [15], and therefore we can simplify our problem to that of minimising KL divergence for the synchronous GDS. Using this measure, we find a factorised distribution (given by the graph structure) that is closest to the joint distribution. We first analytically derive an expression for this divergence, and build on this result to present principled methods for evaluating candidate graphs based on a dataset.\nThe main result of this paper is a tractable expression of the KL divergence for synchronous GDSs. We show that this measure can be decomposed as the difference between two well-known informationtheoretic measures, stochastic interaction [16] and collective transfer entropy [17]. We establish this result by first representing discrete-time multivariate dynamical systems as dynamic Bayesian networks (DBNs) [18]. In this form, both the joint and factorised distributions cannot be directly computed due to the hidden system state. Thus, we draw on methods from differential topology for state space reconstruction to reformulate the KL divergence in terms of computable distributions. Using this expression, we develop two scoring functions based on transfer entropy and independence tests.\nThe significance of this result is that it provides a rigorous foundation for model selection in synchronous GDSs. As we will show, maximising transfer entropy minimises the KL divergence in these systems. Interestingly, transfer entropy has already been used in practice for inferring effective networks [19] with encouraging empirical results. Our work lends mathematical justification to this approach under the given circumstances, and contributes to new potential applications of structure learning in robotics, complex systems analysis, and other areas."}, {"heading": "2 Related Work", "text": "A complex network is a graph with non-trivial topological features that gives rise to emergent behaviour not typically seen in more traditional fields of graph theory [1]. This concept was popularised by the seminal work of Watts and Strogatz [20] on small-world networks and Baraba\u0301si and Albert [21] on scale-free networks. Since then, most of the complex network literature focuses on characterising the structure and dynamics of known biological, physical, and artificial networks [1]. We instead focus on the structure learning problem, a general paradigm in machine learning where the goal is to infer relationships between the variables within a system [22]. In particular, we are interested in systems whereby the subsystems are unidirectionally coupled to one another. Besides complex networks, these types of systems have been introduced under a variety of more specific terms, such as spatially distributed dynamical systems [23, 9] and master-slave configurations [24]. The defining feature of these networks is that the dynamics of each subsystem are given by a set of either discrete-time maps or first-order ordinary differential equations (ODEs). In this paper we use the discrete-time formulation, where a map is obtained numerically by integrating ODEs or recording observations at discrete-time intervals [23].\nAn important precursor to network reconstruction is inferring causality and coupling strength between complex nonlinear systems. In this work, we restrict our attention to methods that determine conditional independence (coupling) rather than causality; algorithms of this kind are applicable\nwhen the experimenter can not intervene with the dataset [25]. In early work, Kolmogorov [26] introduced the concept of classification of dynamical systems by information rates, leading to a generalisation of entropy of an information source [27]. Following this, Granger [28] proposed Granger causality for quantifying the predictability of one variable from another. Although this measure has been used numerous times in identifying coupling, a limiting assumption of Granger causality is the key requirement of linearity, implying subsystems can be understood as individual parts [7]. Schreiber [4] extended the ideas of Granger and introduced transfer entropy using the concept of finite-order Markov processes to quantify the information transfer between coupled nonlinear systems (although this idea was expressed earlier by Marko [29] as an information-theoretic interpretation of predictability). Interestingly, it was recently shown that the two approaches are linked in linearly-coupled Gaussian systems (e.g., Kalman models [18]), where transfer entropy and Granger causality are equivalent [30]. However, there are clear distinctions between the concepts of information transfer and causal effect (see, e.g., the analysis in Lizier and Prokopenko [31] ).\nRecently, a number of measures have been proposed to infer coupling between distributed dynamical systems based on state space reconstruction theorems [7, 9, 3]. Sugihara et al. [7] assumed Granger\u2019s definition of causality as a quantification of predictability and proposed a method labelled convergent cross-mapping (CCM). CCM involves collecting a history of observed data from one subsystem and uses this to predict the outcome of another subsystem. This history is the delay reconstruction map described by Takens\u2019 Delay Embedding Theorem [32]. Similarly, Schumacher et al. [9] used the Bundle Delay Embedding Theorem [33] infer causality and perform inference via Gaussian processes. Although the algorithms presented in these papers can infer driving subsystems in a spatially distributed dynamical system, the results obtained differ from ours as inference is not considered for an entire network structure, nor is a formal derivation presented. Finally, we recently presented similar work on deriving an information criterion for learning the structure of distributed dynamical systems [3]. However, the criterion we proposed was both only asymptotically optimal and required parametric modelling of the probability distributions. In this paper we extend this framework by proposing two scoring functions: one that is comparable to the information criterion presented in [3] in that it is applicable for discrete and linearly-coupled Gaussian variables; and another that allows for non-parametric density estimation techniques and thus make no assumptions about the underlying distributions.\nA major contribution of this paper is a formal proof that maximising collective transfer entropy in a network reveals the information-theoretically optimal structure. A related line of inquiry is recovering effective networks: networks that reveal the \u201ceffective structure\u201d of an observed system [34, 35]. Using transfer entropy to infer effective networks has become a popular transdisciplinary analysis technique, e.g., in computational neuroscience [8, 19]; multi-agent systems [36, 5]; financial markets [37]; supply-chain networks [38]; and gene regulatory networks [39]. However, there is a dearth of work that provide formal derivations for the use of this measure in inferring effective structure. Most of the results build on Schreiber\u2019s work [4] and assume the system to be composed of finite-order Markov chains; we extend this notion by showing that transfer entropy can also reveal the effective structure of distributed dynamical systems. In prior work [3], we have connected the log-likelihood ratio of a distributed dynamical system and transfer entropy. However, in this paper we arrive at this result directly by considering the minimal code length of the graph structure and present scores based on this result.\nIn order to evaluate the quality of a network structure, we adopt the framework of DBNs [18]. In Bayesian network (BN) structure learning literature, there is an already mature research topic called the evaluation problem, which is aimed at deriving a measure that can be used to score candidate graphs, given a dataset [11]. A number of mathematically sound techniques exist for the evaluation problem in a fully observed BN [40, 41, 42, 43], most of which can be readily extended to the DBN case [44]. With hidden variables, however, these guarantees do not hold and authors will often rely on heuristics. Russell et al. [45] and Binder et al. [46] use gradient descent to find parameters with possible hidden variables, and then extended their work to continuous nodes and DBNs. Kwoh and Gillies [47] use an ad hoc method to invent hidden nodes for unexplained data. Bishop et al. [48] focused on solutions for cases specific to a sigmoid network with mixtures. Although most methods for structure learning are aimed at finding a local maxima, Chickering et al. [49] propose using the decomposability of the functions for efficient Monte Carlo methods that avoid this caveat. In general, the above measures are derived for general BNs without any assumptions on the structure, and give only heuristic solutions. Our approach is derived specifically for multivariate dynamical systems,\nand we are thus afforded simplifying assumptions that allow us to develop a mathematically rigorous solution. Interestingly, the analogous concept of maximising mutual information has been previously derived as a measure to recover fully observed BNs [15, 40, 50] and DBNs [51]."}, {"heading": "3 Background", "text": ""}, {"heading": "3.1 Notation", "text": "In this work we consider a collection of stationary stochastic temporal processes Z. Each process Zi comprises a sequence of random variables (Zi1, Z i 2, . . . , Z i N ) with realisation (z i 1, z i 2, . . . , z i N ) for countable time indices n \u2208 N. Given these processes, we can compute probability distributions of each variable by counting relative frequencies or by density estimation techniques [52, 53, 54].1 We use bold to denote the set of all variables, e.g., zn = \u3008z1n, z2n, . . . , zMn \u3009 is the collection of M realisations at index n. Further, unless otherwise stated, Xin is a latent (hidden) variable, Y i n is an observed variable, and Zin is an arbitrary variable; thus, Zn = {Xn,Y n} is the set of all hidden and observed variables at temporal index n. Given a graphical model G, the pi parents of variable Zin+1 is given by the parent set \u03a0G(Zin+1) = \u3008Zijn \u3009j = \u3008Zi1n , Zi2n , . . . , Zip i\nn \u3009. Finally, let the superscript z i,(k) n = \u3008zin, zin\u22121, . . . , zin\u2212k+1\u3009 denote the vector of k previous values taken by variable Zin."}, {"heading": "3.2 Learning Nonlinear Dynamical Networks", "text": "We are interested in modelling discrete-time multivariate dynamical systems, where the state is a vector of real numbers given by a point xn lying on a compact d-dimensional manifoldM. A map f :M\u2192M describes the temporal evolution of the state at any given time, such that the state at the next time index xn+1 = f(xn). Furthermore, in many practical scenarios, we do not have access to xn directly, and can instead observe it through a measurement function \u03c8 :M\u2192 RM that yields a scalar representation yn = \u03c8(xn) of the latent state [33, 23]. We assume the multivariate system can be factorised and modelled as a DAG with spatially distributed dynamical subsystems, termed a synchronous GDS. This definition is restated from [3] as follows.\nDefinition 1 (Synchronous graph dynamical system (GDS)). A synchronous GDS is a tuple (G,xn,yn, {f i}, {\u03c8i}) that consists of:\n\u2022 a finite, directed graph G = (V, E) with edge-set E = {Ei} and M vertices comprising the vertex set V = {V i};\n\u2022 a multivariate state xn = \u3008xin\u3009, composed of states for each vertex V i confined to a di-dimensional manifold xin \u2208Mi;\n\u2022 an M -variate observation yn = \u3008yin\u3009, composed of scalar observations for each vertex yin \u2208 R;\n\u2022 a set of local maps {f i} of the form f i : M \u2192 Mi, which update synchronously and induce a global map f :M\u2192M; and\n\u2022 a set of local observation functions {\u03c81, \u03c82, . . . , \u03c8M} of the form \u03c8i :Mi \u2192 R.\nThe global dynamics and observations can therefore be described by the set of local functions [3]:\nxin+1 = f i(xin, \u3008xijn \u3009j) + \u03c5fi , (1)\nyin+1 = \u03c8 i(xin+1) + \u03c5\u03c8i , (2)\nwhere \u03c5fi and \u03c5\u03c8i are additive noise terms. The subsystem dynamics (1) are a function of the subsystem state xin and the subsystem parents\u2019 state \u3008xijn \u3009j at the previous time index, i.e., f i : (Mi \u00d7jMij)\u2192Mi. However, the observation yin+1 is a function of the subsystem state alone, i.e., \u03c8i :Mi \u2192 R. We assume the maps {f i} and {\u03c8i}, as well as the graph G, are time-invariant.\n1To simplify notation, the variables in this work appear as discrete random variables. There is no restriction on these being continuous variables; we can simply replace all sums with an integral. Obviously, this would require different density estimators as referenced here.\nThe discrete-time mapping for the dynamics (1) and measurement function (2) can be modelled as a DBN in order to facilitate structure learning of the graph [3]. DBNs are a probabilistic graphical model that represent probability distributions over trajectories of random variables (Z1,Z2, . . .) by a prior BN and a two-time-slice BN (2TBN) [44]. To model the maps, however, we need only to consider the 2TBN B = (G,\u0398), which models a first-order Markov process pB(zn+1 | zn) graphically and consists of: a DAG G and a set of conditional probability distribution (CPD) parameters \u0398. [44]. Given a set of stochastic processes (Z1,Z2, . . . ,ZN ), the realisation of which constitutes a dataset D = (z1, z2, . . . ,zN ), the 2TBN distribution is given by pB(zn+1 | zn) =\u220f i pB(z i n+1 | \u03c0G(Zin+1)), where \u03c0G(Zin+1) denotes the (index-ordered) set of realisations {zjo : Zjo \u2208 \u03a0G(Zin+1)}.\nTo model the synchronous GDS as a DBN, we associate each subsystem vertex V i with a state variable Xin and an observation variable Y i n; the parents of subsystem V\ni are denoted \u03a0G(V i) [3]. From the dynamics (1), variables in the set \u03a0G(Xin+1) come strictly from the preceding time slice, and additionally, from the measurement function (2), \u03a0G(Y in+1) = X i n+1. Thus, we can build the edge set E in the GDS by means of the DBN [3], i.e., given an edge Xin \u2192 X j n+1 of the DBN, the equivalent edge V i \u2192 V j exists for the GDS. The distributions for the dynamics (1) and observation (2) maps of M arbitrary subsystems can therefore be factorised according to the DBN structure such that [3]\npB(zn+1 | zn) = M\u220f i=1 pD(x i n+1 | xin, \u3008xijn \u3009j) \u00b7 pD(yin+1 | xin+1). (3)\nThe goal of learning nonlinear dynamical networks thus becomes that of inferring the parent set \u03a0G(X i n) for each latent variable X i n."}, {"heading": "4 Network Scoring Functions", "text": "A number of exact and approximate DBN structure learning algorithms exist that are based on Bayesian statistics and information theory. We have shown in prior work how to compute the loglikelihood function for synchronous GDSs. In this section, we will review the literature on structure learning for DBNs, focusing on the factorised distribution in Eq. (3). Then, we present our proposed approach to structure learning based on conditional KL divergence.\nWe focus on the methods for learning the synchronous GDS structure using the score and search paradigm [22], which can be stated as: given a dataset D = (y1,y2, . . . ,yN ) of multivariate observations, find a DAG G\u2217 such that\nG\u2217 = arg max G\u2208G g(B : D), (4)\nwhere g(B : D) is a scoring function measuring the degree of fitness of a candidate DAG G to the data set D, and G is the set of all DAGs. Finding the optimal graph G\u2217 in (4) requires solutions to the two subproblems that comprise structure learning: the evaluation problem and the identification problem [11]. The main problem we focus on in this paper is the evaluation problem, i.e., determining a score that quantifies the quality of a graph, given data. Later we will address the identification problem by discussing the attributes of this scoring function in efficiently finding the optimal graph structure."}, {"heading": "4.1 Prior work", "text": "A common approach to developing a score is to consider the posterior probability of the network structure G, given data D. Using Bayes\u2019 rule, we can express this distribution as p(G | D) \u221d p(D | G)p(G), where p(G) encodes any prior assumptions we want to make about the network G. Thus, the problem becomes that of computing the likelihood of the data, given the model, p(D | G). The likelihood can be written in terms of distributions over network parameters [44] p(D | G) =\u222b p(D | G,\u0398)p(\u0398 | G)d\u0398. Taking this approach, denote `(\u0398\u0302G : D) = log p(D | G, \u0398\u0302G) as the log-likelihood function for a choice of parameters \u0398\u0302G that maximise p(D | G,\u0398), given a graph G. A number of asymptotically optimal information criterion can then be computed as a function of the\nlog-likelihood `(\u0398\u0302G : D), the model dimension (number of parameters) C(G), and the dataset size f(N), given by the general form [3]\ngIC(B : D) = `(\u0398\u0302G : D)\u2212 f(N) \u00b7 C(G). (5) When f(N) = 1, we have the Akaike information criterion (AIC) score [55], f(N) = log(N)/2 is the Bayesian information criterion (BIC) score [13], and f(N) = 0 gives the maximum likelihood score.\nWe have recently shown that state space reconstruction (see Appendix A) can be used to compute the log-likelihood of (3) as a difference of conditional entropy terms [3]:\n`(\u0398\u0302G : D) = N \u00b7H(Xn | \u3008Y i,(\u03ba i) n \u3009)\u2212N \u00b7 M\u2211 i=1 H(Y in+1 | Y i,(\u03ba i) n , \u3008Y ij,(\u03ba ij) n \u3009j), (6)\nwhere H(Z |W ) is the entropy of variable Z conditioned on W [56], H(Z |W )\u2212 \u2211 z,w p(z, w) log2 p(z | w). (7)\nIn order to calculate the model complexity C(G) for this information criterion (5), a parametric model is required for density estimation. Thus we can not rely on non-parametric density estimators and instead must discretise the dataset to some resolution or derive a parametric model from, e.g., the physics of the phenomenon being studied."}, {"heading": "4.2 Proposed approach", "text": "To overcome the issue of parameterising the distributions, in this work we consider the different problem of finding an optimal DBN structure as searching for a parsimonious factorised distribution that best represents the joint distribution. De Campos [50] proposes using the KL divergence as a natural information-theoretic approach to quantifying the similarity of these distributions for a BN. We extend this approach to the DBN structure learning problem by considering the conditional KL divergence, i.e., we compare the joint and factorised distributions of time slices, given the entire history,2\nDKL (pD \u2016 pB) = DKL ( pD(zn+1 | z(n)n ) \u2016 pB(zn+1 | z(n)n ) ) =\n\u2211 zn+1,z (n) n pD(zn+1, z (n) n ) log2 pD(zn+1 | z(n)n ) pB(zn+1 | zn) . (8)\nAlthough (8) is not yet a scoring function, in Sec. 6 we present a number of scores based on this measure. First, however, we must derive a tractable form of KL divergence. Substituting the synchronous GDS model (3) into (8), we get DKL (pD \u2016 pB) = \u2211\nzn+1,z (n) n\npD(zn+1, z (n) n ) log2 pD(zn+1 | z(n)n )\u220fM i=1 pD(x i n+1 | xin, \u3008x ij n \u3009j) \u00b7 pD(yin+1 | xin+1) .\n(9) Unfortunately, (9) comprises maximum likelihood distributions with unobserved (latent) state components xn; to compute these distribution, we resort to state space reconstruction."}, {"heading": "5 Computing the conditional KL divergence", "text": "In this section we use state space reconstruction theorems based on Takens\u2019 seminal work [32] to obtain a tractable form of the conditional KL divergence (9). Following this, we reformulate this expression as a sum of two information-theoretic terms for use in our scoring functions (described later).\n2Vinh et al. [51] applied the MIT algorithm [50] to DBN structure learning with complete data, however did not derive the results explicitly from conditional KL divergence. We show a full derivation here for the case with latent variables."}, {"heading": "5.1 A tractable expression via state space reconstruction", "text": "In order to compute the distributions in (9), we use the Bundle Delay Embedding Theorem [33] to reformulate the factorised distribution (denominator), and the Delay Embedding Theorem for Multivariate Observation Functions [57] for the joint distribution (numerator). We describe these theorems in detail in Appendix A, along with the technical assumptions required for (f, \u03c8). The first step is to reproduce our prior result for computing the factorised distribution (denominator) in Eq. (9). Lemma 1 (Cliff et al. [3]). Given an observed dataset D = (y1,y2, . . . ,yN ), where yn \u2208 RM , generated by a directed and acyclic synchronous GDS (G,xn,yn, {f i}, {\u03c8i}), the 2TBN distribution can be written as\nM\u220f i=1 pD(x i n+1 | xin, \u3008xijn \u3009j) \u00b7 pD(yin+1 | xin+1) = \u220fM i=1 pD(y i n+1 | y i,(\u03bai) n , \u3008yij,(\u03ba ij) n \u3009j) pD(xn | \u3008yi,(\u03ba i) n \u3009) . (10)\nNext, we present a method for computing the joint distribution (numerator) in Lemma 3. For convenience, Lemma 2 restates part of the delay embedding theorem in [57] in terms of subsystems of a synchronous GDS and establishes existence of a map G for predicting future observations from a history of observations. Lemma 2. Consider a diffeomorphism f :M\u2192M on a d-dimensional manifoldM, where the multivariate state xn consists of M subsystem states \u3008x1n, x2n, . . . , xMn \u3009. Each subsystem state xin is confined to a submanifoldMi \u2286 M of dimension di \u2264 d, where \u2211 i d i = d. The multivariate observation can be estimated, for some map G, by yn+1 = G(\u3008y i,(\u03bai) n \u3009).\nProof. We can reformulate the proof of Deyle et al. [57] in terms of subsystems. Given M inhomogeneous observation functions \u3008\u03c81, \u03c82, . . . , \u03c8M \u3009, the following map\n\u03a6f,\u03c8(x) = \u3008\u03a6f1,\u03c81(x),\u03a6f2,\u03c82(x), . . . ,\u03a6fM ,\u03c8M (x)\u3009 (11)\nis an embedding where each subsystem (local) map \u03a6fi,\u03c8i :M\u2192 R\u03ba i , smoothly (at least C2), and, at time index n is described by\n\u03a6fi,\u03c8i(xn) = y i,(\u03bai) n = \u3008\u03c8i (xn) , \u03c8i(xn\u2212\u03c4 ), \u03c8i(xn\u22122\u03c4 ), . . . , \u03c8i(xn\u2212(k\u22121)\u03c4 )\u3009\n= \u3008yin, yin\u2212\u03c4 i , y i n\u22122\u03c4 i , . . . , y i n\u2212(\u03bai\u22121)\u03c4 i\u3009, (12) where \u03c4 i is the lag, \u03bai is the embedding dimension of the ith subsystem, and \u2211 i \u03ba\ni = 2d+ 1 [57].3 Note that, from (11) and (12), we have the global map\n\u03a6f,\u03c8(xn) = \u3008yi,(\u03ba i) n \u3009 = \u3008y1,(\u03ba 1) n , y 2,(\u03ba2) n , . . . , y m,(\u03baM ) n \u3009.\nNow, since \u03a6f,\u03c8 is an embedding, it follows that the map F = \u03a6f,\u03c8 \u25e6 f \u25e6\u03a6\u22121f,\u03c8 is well defined and a diffeomorphism between two observation sequences F : R2d+1 \u2192 R2d+1, i.e.,\n\u3008yi,(\u03ba i)\nn+1 \u3009 = \u03a6f,\u03c8 (xn+1) = \u03a6f,\u03c8 (f (xn))\n= \u03a6f,\u03c8 ( f ( \u03a6\u22121f,\u03c8 ( \u3008yi,(\u03ba i) n \u3009 ))) = F(\u3008yi,(\u03ba i) n \u3009).\nThe last 2d+ 1 components of F are trivial, i.e., the set \u3008yi,(\u03ba i)\nn \u3009 is observed a priori; denote the first M components by G : \u03a6f,\u03c8 \u2192 RM , then we have that yn+1 = G(\u3008y i,(\u03bai) n \u3009).\nWe now use the result of Lemma 2 to obtain a computable form of the joint distribution. Lemma 3. Given an observed dataset D = (y1,y2, . . . ,yN ), where yn \u2208 RM , generated by a discrete-time multivariate dynamical system with generic (f, \u03c8), the joint distribution can be written as\npD(zn+1 | z(n)n ) = pD(yn+1 | \u3008y\ni,(\u03bai) n \u3009)\npD(xn | \u3008yi,(\u03ba i) n \u3009) . (13)\n3The original proof uses positive lags for notational simplicity, however the authors note that the use of negative lags also applies, and will be used in our derivation to account for endomorphisms.\nProof. Firstly, by the chain rule\npD(zn+1 | z(n)n ) = pD(xn+1 | z(n)n ) \u00b7 pD(yn+1 | xn+1, z(n)n ) (14)\nAssuming we had realisations of (xn,xn+1), the probability distribution of (14) would then be given by the product\npD(zn+1 | z(n)n ) = pD(Xn+1 = f(xn) | xn) \u00b7 pD(Y n+1 = \u03c8(xn+1) | xn+1). (15)\nFrom Lemma 2, we have the set of equations xn+1 = f(xn) + \u03c5f = f ( \u03a6\u22121f,\u03c8 ( \u3008yi,(\u03ba i) n \u3009 )) + \u03c5f , (16)\nyn+1 = \u03c8(xn+1) + \u03c5\u03c8 = G(\u3008yi,(\u03ba i) n \u3009) + \u03c5\u03c8. (17)\nGiven the assumption of i.i.d noise on the function f , from (16), we express the probability of observing xn+1 given by the embedding as\npD(xn+1 | \u3008yi,(\u03ba i) n \u3009) = pD(Xn+1 = f ( \u03a6\u22121f,\u03c8 ( \u3008yi,(\u03ba i) n \u3009 )) | \u3008yi,(\u03ba i) n \u3009)\n= pD ( Xn = \u03a6 \u22121 f,\u03c8 ( \u3008yi,(\u03ba i) n \u3009 ) | \u3008yi,(\u03ba i) n \u3009 ) \u00b7 pD (Xn+1 = f(xn) | xn) ,\n(18)\nFrom our assumption that the observation noise is i.i.d or dependent only on the state xn+1, the probability of observing yn+1, from (17) is\npD(yn+1 | \u3008yi,(\u03ba i) n \u3009) = pD(Y n+1 = G(\u3008yi,(\u03ba i) n \u3009) | \u3008yi,(\u03ba i) n \u3009) = pD(Xn+1 = f ( \u03a6\u22121f,\u03c8 ( \u3008yi,(\u03ba i) n \u3009 )) | \u3008yi,(\u03ba i) n \u3009) \u00b7 pD (Y n+1 = \u03c8(xn+1) | xn+1) .\n(19)\nSubstituting Eq. (18) into (19), we have that\npD(xn+1 | xn) \u00b7 pD(yn+1 | xn+1) = pD(yn+1 | \u3008y\ni,(\u03bai) n \u3009)\npD(xn | \u3008yi,(\u03ba i) n \u3009) (20)\nFinally, substituting Eq. (20) into Eq. (15) gives Eq. (13).\nUsing Lemma 1, we can substitute (10) into (9)\nDKL(pD \u2016 pB) = \u2211\nzn+1,z (n) n\npD(zn+1, z (n) n ) log2\npD(zn+1 | z(n)n ) \u00b7 pD(xn | \u3008yi,(\u03ba i) n \u3009)\u220fM i=1 pD(y i n+1 | y i,(\u03bai) n , \u3008yij,(\u03ba ij) n \u3009j) . (21)\nThen, from Lemma 3, we can substitute (13) into (21), giving\nDKL(pD \u2016 pB) = \u2211\nyn+1,\u3008y i,(\u03bai) n \u3009\npD(yn+1, \u3008yi,(\u03ba i) n \u3009) log2 pD(yn+1 | \u3008y i,(\u03bai) n \u3009)\u220fM\ni=1 pD(y i n+1 | y i,(\u03bai) n , \u3008yij,(\u03ba ij) n \u3009j)\n(22)\nGiven all variables in (22) are observed, it is straightforward to compute KL divergence; however, as we will see, it is more convenient to express (22) as a function of information-theoretic measures."}, {"heading": "5.2 Information-theoretic interpretation", "text": "Before presenting the main theorem of the paper, we first introduce the concepts of collective transfer entropy and stochastic interaction. Transfer entropy detects the directed exchange of information between random processes by marginalising out common history and static correlations between variables; it is thus considered a measure of information transfer within a system [4]. The collective transfer entropy computes the information transfer between a set of M source processes and a single destination process [17]. Consider the set Y = {Y i} of source processes. We can compute\nthe collective transfer entropy from Y to the destination process X as a function of conditional entropy (7) terms\nTY\u2192X = H ( Xn+1 | X(\u03ba i) n ) \u2212H ( Xn+1 | X(\u03ba i) n , \u3008Y i,(\u03ba i) n \u3009 ) (23)\nStochastic interaction measures the complexity of dynamical systems by quantifying the excess of information processed, in time, by the system beyond the information processed by each of the nodes [16, 58, 59]. Using the same notation, stochastic interaction of the collection of processes Y is\nSY = \u2212H ( Y n+1 | \u3008Y i,(\u03ba i) n \u3009 ) + M\u2211 i=1 H ( Y in+1 | Y i,(\u03ba i) n ) . (24)\nNote that the original definition assumed a first-order Markov process [16], and here we have extended stochastic interaction to arbitrary \u03ba-order Markov chains. Given these definitions, we have the following result. Theorem 4. Consider a discrete-time multivariate dynamical system with generic (f, \u03c8) represented as a directed and acyclic synchronous GDS (G,xn,yn, {f i}, {\u03c8i}) with M subsystems. The KL divergence DKL(pD \u2016 pB) of a candidate graph G from the observed dataset D = (y1,y2, . . . ,yN ) is given by the difference between stochastic interaction and collective transfer entropy, i.e.,\nDKL(pD \u2016 pB) = SY \u2212 m\u2211 i=1 T{Y ij}j\u2192Y i . (25)\nProof. We can reformulate (22) as DKL(pD \u2016 pB) = \u2211\nyn+1,\u3008y i,(\u03bai) n \u3009\npD(yn+1, \u3008yi,(\u03ba i) n \u3009) log2 pD(yn+1 | \u3008yi,(\u03ba i) n \u3009)\n\u2212 \u2211\nyn+1,\u3008y i,(\u03bai) n \u3009\npD(yn+1, \u3008yi,(\u03ba i) n \u3009) log2 M\u220f i=1 pD(y i n+1 | yi,(\u03ba i) n , \u3008yij,(\u03ba ij) n \u3009j).\n(26)\nSplitting the latter term in (26) into subsystems without a parent set \u03a0G(V i) = \u2205 and subsystems with a parent set \u03a0G(V i) 6= \u2205, we get a function of conditional entropy (7) terms\nDKL(pD \u2016 pB) =\u2212H(Y n+1 | \u3008Y (\u03ba i) n \u3009)\n+ M\u2211 i=1,\n\u03a0G(V i)=\u2205\nH(Y in+1 | Y i,(\u03ba i) n ) + M\u2211 i=1,\n\u03a0G(V i)6=\u2205\nH(Y in+1 | Y i,(\u03ba i) n , \u3008Y ij,(\u03ba ij) n \u3009j)\n(27) Then, by adding \u2211M\ni=1,\u03a0G(V i)6=\u2205H(Y\ni n+1 | Y i,(\u03bai) n ) to the second term and subtracting it from the\nlast, we can rewrite KL divergence (27) in terms of collective transfer entropy (23) and stochastic interaction (24)\nDKL(pD \u2016 pB) = \u2212H(Y n+1 | \u3008Y (\u03ba i) n \u3009) + M\u2211 i=1 H(Y in+1 | Y i,(\u03ba i) n )\n\u2212 M\u2211 i=1,\n\u03a0G(V i) 6=\u2205\n[ H(Y in+1 | Y i,(\u03ba i) n )\u2212H(Y in+1 | Y i,(\u03ba i) n , \u3008Y ij,(\u03ba ij) n \u3009j) ]\n= SY \u2212 M\u2211 i=1,\n\u03a0G(V i)6=\u2205\nT{Y ij}j\u2192Y i . (28)\nNote that, in (28), we can remove the specification that the transfer entropy sum is over non-empty parent sets \u03a0G(V i) 6= \u2205 since transfer entropy is a measure, and therefore, for any Y i, T\u2205\u2192Y i = 0, so \u2211M\ni=1,\u03a0G(V i)6=\u2205 T{Y ij}j\u2192Y i = \u2211M i=1 T{Y ij}j\u2192Y i , giving (25)."}, {"heading": "6 Scoring functions based on transfer entropy", "text": "There are a number of ways to score a candidate graph based on Theorem 4. Here we present a corollary of this theorem from which we derive two scores: (1) transfer entropy with analytic independence tests (TEA), and (2) transfer entropy with empirical independence tests (TEE). First, we will show that a maximum likelihood-based approach is insufficient for structure learning."}, {"heading": "6.1 The maximum likelihood approach", "text": "A common method to derive a score is to minimise the KL divergence between graph and empirical distributions [15, 60]. This score follows naturally from Theorem 4. The following corollary shows that in practice it suffices to maximise the collective transfer entropy alone in order to minimise KL divergence for a synchronous GDS. Corollary 4.1. The minimum KL divergence of a candidate graph G from the empirical dataset D is equivalent to the maximum transfer entropy graph, i.e.,\narg min G\u2208G DKL(pD \u2016 pB) = arg max G\u2208G m\u2211 i=1 T{Y ij}j\u2192Y i . (29)\nProof. The stochastic interaction term SY in (25) is defined in terms of persistent variables, i.e., each variable Y in+1 is conditioned only on its own past Y i,(\u03bai) n . Stochastic interaction is therefore constant, given a constant vertex set V , time delay \u03c4 and embedding dimension \u03ba and is thus unaffected by the parent set \u03a0G(V i) of a variable. This is evident in (28), where only the latter sum depends on the parent set \u03a0G(V i). As a result, stochastic interaction SY does not depend on the graph G being considered, and, therefore\nmin G\u2208G DKL(pD \u2016 pB) = min G\u2208G\n( SY \u2212\nm\u2211 i=1 T{Y ij}j\u2192Y i\n) = SY \u2212max\nG\u2208G ( m\u2211 i=1 T{Y ij}j\u2192Y i ) . (30)\nTaking instead the arguments of the optima in (30) gives (29).\nFrom Corollary 4.1, a naive score can be defined as\ngTE(B : D) = m\u2211 i=1 T\u3008Y ij\u3009j\u2192Y i . (31)\nHowever, this score is insufficient. Maximising collective transfer entropy will always yield a complete graph. For example, let Y = {Y 1, Y 2, . . . , YM}, then, for any Y i, Y k \u2208 Y and Y j \u2208 Y \\ {Y i, Y k},\nH(Y in+1 | Y jn \u222a Y kn ) \u2264 H(Y in+1 | Y jn ) \u2234 TY j\u222aY k\u2192Y i \u2265 TY j\u2192Y i .\nThe sum of transfer entropy in (31) is therefore strictly non-decreasing when including more variables in a parent set. Further, since observations are taken from a finite number of samples N , a non-zero bias of conditional entropy is likely to result even in the absence of dependence, particularly under noisy observations."}, {"heading": "6.2 Penalising transfer entropy by independence tests", "text": "Building on the maximum likelihood score (31), we propose to use independence tests to define two scores of practical value. Here, we draw on the result of de Campos [50], who derived a scoring function for BN structure learning based on conditional mutual information and statistical significance tests, called MIT (mutual information tests). The central idea is to use collective transfer entropy T\u3008Y ij\u3009j\u2192Y i to measure the degree of interaction between each subsystem V\ni and its parent subsystems \u03a0G(V i), but also to penalise this term with a value based on significance testing. As with the MIT score, this gives a principled way to re-scale the transfer entropy when including more edges in the graph.\nTo develop our scores, we form a null hypothesis H0 that there is no interaction T\u3008Y ij\u3009j\u2192Y i , and then compute a test statistic to penalise the measured transfer entropy. To compute the test statistic, it is necessary to consider the measurement distribution in the case where the hypothesis is true. Fortunately, in the case of discrete and linear-Gaussian systems, the distribution 2NT\u3008Y ij\u3009j\u2192Y i is known to asymptotically approach the \u03c72-distribution [62]. Since this distribution is a function of the parents of Y i, we let it be described by the function \u03c72({lij}j). Now, given this distribution, we can fix some confidence level \u03b1 and determine the value \u03c7\u03b1,{lij}j such that p(\u03c7\n2({lij}j) \u2264 \u03c7\u03b1,{lij}j ). This represents a conditional independence test: if 2NT\u3008Y ij\u3009j\u2192Y i \u2264 \u03c7\u03b1,{lij}j , then we accept the hypothesis of conditional independence between Y i and \u3008Y ij\u3009j ; otherwise, we reject it. We express this idea as the TEA score:\ngTEA(B : D) = M\u2211 i=1 ( 2NT{Y ij}j\u2192Y i \u2212 \u03c7\u03b1,{lij}j ) . (32)\nWe can derive a more general form of the TEA score (32) via surrogate measurements T\u3008Y ij\u3009sj\u2192Y i under the assumption of H0 [61]. This same technique has been used by Lizier and Rubinov [19] to derive a greedy structure learning algorithm for effective network analysis. Here, \u3008Y ij\u3009sj are surrogate sets of variables for \u3008Y ij\u3009j , which have the same statistical properties as \u3008Y ij\u3009j , but the correlation between \u3008Y ij\u3009sj and Y i is removed. Let the distribution of these surrogate measurements be represented by some general function T (si), and note that for the systems described for the TEA score (32), we could compute T (si) analytically as an independent set of \u03c72-distributions \u03c72({lij}j). Where no analytic distribution is known, we use a resampling method (i.e., permutation or bootstrapping), creating a large number of surrogate time-series pairs {\u3008Y ij\u3009sj , Y i} by shuffling (for permutations, or redrawing for bootstrapping) the samples of Y i and computing a population of T\u3008Y ij\u3009sj\u2192Y i . As with the TEA score, we fix some confidence level \u03b1 and determine the value T\u03b1,si , such that p(T (si) \u2264 T\u03b1,si) = \u03b1. This results in the TEE scoring function as\ngTEE(B : D) = M\u2211 i=1 ( T{Y ij}j\u2192Y i \u2212 T\u03b1,si ) . (33)\nWe can obtain the value T\u03b1,si by (1) drawing Ns samples T\u3008Y ij\u3009sj\u2192Y i from the distribution T (s i) (by permutation or bootstrapping), (2) fixing \u03b1 \u2208 {0, 1/Ns, 2/Ns, . . . , 1}, then (3) taking T\u03b1,si such\nthat \u03b1 = 1\nNs \u2211 T{Y ij}j\u2192Y i 1T{Y ij}s j \u2192Y i\u2264T\u03b1,si .\nWe can alternatively limit the number of surrogates Ns to d\u03b1/(1 \u2212 \u03b1)e and take the maximum as T\u03b1,si [23], however taking a larger number of surrogate Ns will improve the validity of the distribution T (si)."}, {"heading": "6.3 Analysis of the scores", "text": "Given the TEA and TEA scoring functions, the optimal graph G\u2217 can be found using any search procedure over DAGs. Exhaustive search, where DAGs are enumerated and scored, is intractable because the search space is super-exponential in the number of variables (about 2O(M\n2)). It is therefore common to employ local search methods such as greedy hill climbing, basin flooding and tabu search [22]. In this section, we discuss two properties of the scoring functions that facilitate these search procedures: decomposability and score-equivalence.\nA decomposable score is a sum of local scores that depend only on a variable and its parents, i.e.,\ng(B : D) = M\u2211 i=1 g(V i,\u03a0G(V i) : D),\ng(V i,\u03a0G(V i) : D) = g(V i,\u03a0G(V i) : NDV i,\u03a0G(V i)),\nwhere NDV i,\u03a0G(V i) are sufficient statistics for the set of variables V i \u222a\u03a0G(V i) in D [50]. Given the independent sums in (32) and (33), the TEA and TEE scoring functions are decomposable. Further, the TEA score (32) can be decomposed as a sum of conditional mutual information tests, i.e.,\ngTEA(B : D) = M\u2211 i=1\n2NT{Y ij}j\u2192Y i \u2212 p i\u2211\nj=1\n\u03c7\u03b1,lij  , where pi is the number of parents of subsystem V i. This approach is more efficient as it allows for caching the results of \u03c7\u03b1,{lij}j incrementally [50]. Note that although any decomposition of collective transfer entropy yields the same value, the ordering of conditioning on the variables Y ij in the penalty term affects the score. This issue can be resolved by penalising the score conservatively by using the maximum permutation of the \u03c7\u03b1,{lij}j value; an in-depth explanation of this approach can be found in de Campos\u2019 [50] discussion of the maximum penalty permutation (Theorem 2) and Shur-concavity (Theorem 3) of the penalty term.\nScore-equivalence in BN structure learning simplifies the evaluation and identification problems by constraining the search space to a set of essential graphs, which is a set of equivalence classes over DAGs [11]. Because TEA and TEE are specific cases of the MIT score [50], they are not scoreequivalent. However, they do satisfy the less demanding property of equivalence in the space of restricted partially directed acyclic graphs (RPDAGs) [63]. Thus, these scoring functions assign the same value to all DAGs that are represented by the same RPDAGs. With a decomposable scoring function, searching in the space of RPDAGs is more efficient than searching through essential graphs, and has been shown to yield better local optima than other local search techniques in practice [63]."}, {"heading": "7 Discussion and future work", "text": "We have presented a principled method to learn the structure of a synchronous GDS based on collective transfer entropy and independence tests. We derived this method analytically by reformulating the KL divergence of factorised from joint distributions of a network, which Theorem 4 shows can be computed in terms of stochastic interaction and transfer entropy. We arrived at this result by first reconsidering the GDS as a DBN, and then employed generalised versions of Takens\u2019 embedding theorem to compute densities comprising hidden and observed variables.\nThe decomposition of KL divergence in Theorem 4 captures an interesting parallel between fully observable systems and partially observable systems. De Campos [50] showed previously that the KL\ndivergence in a fully observable system is given by the difference between multi-information [64] and mutual information.4 Specifically, a condition for generalised Takens\u2019 theorems to hold is that the observation functions {\u03c8i} are injective [57, 33]. We conjecture that if the functions are also surjective (i.e., there is a one-to-one mapping between state and observation), the embedding dimension would reduce to unity and we would arrive at the MIT scoring function.\nIn Corollary 4.1, we have shown that, under certain circumstances, maximising collective transfer entropy minimises the KL divergence of a model from the true distribution. KL divergence is related to model encoding, which is a fundamental measure used in complex systems analysis. Our result, therefore, has potential implications to other areas of complex systems research. For example, the notion of equivalence classes in BN structure learning should lend some insight into the area of effective network analysis [34, 35]. We believe the concepts of effective networks referred to in complex systems literature can be unified with essential graphs and RPDAGs. This would allow for a more rigorous definition of effective networks and a benchmark for analysing the efficacy of an algorithm to reconstruct these networks.\nWe have presented the TEA (32) and TEE (33) scores above based on the MIT scoring function [50]. These scoring functions, however, could be considered to be a generalisation of MIT. There are numerous approaches to recover the time delay \u03c4 and embedding dimension \u03ba for use in transfer entropy [65, 66]. Given a system of fully observed variables, these criteria should optimally select no embedding dimension or time delay, and thus as a special case of our scores we obtain the MIT algorithm with time-lagged mutual information."}, {"heading": "Acknowledgements", "text": "This work was supported in part by the Australian Centre for Field Robotics; the New South Wales Government; and the Faculty of Engineering & Information Technologies, The University of Sydney, under the Faculty Research Cluster Program. Special thanks to Joseph Lizier, Ju\u0308rgen Jost, and Wolfram Martens for their incite in regards to dynamical systems."}, {"heading": "Appendix A. Embedding theory", "text": "We refer here to embedding theory as the study of inferring the (hidden) state xn \u2208M of a dynamical system from a sequence of observations yn \u2208 R. This section will cover reconstruction theorems that define the conditions under which we can use delay embeddings for recovering the original dynamics f from this observed time series.\nIn differential topology, an embedding refers to a smooth map \u03a6 : M \u2192 N between manifolds M and N if it mapsM diffeomorphically onto its image. In Takens seminal work on turbulent flow [32], he proposed a map \u03a6f,\u03c8 :M\u2192 R\u03ba, that is composed of delayed observations, can be used to reconstruct the dynamics for typical (f, \u03c8). That is, fix some \u03ba (the embedding dimension) and \u03c4 (the time delay), the delay embedding map, given by\n\u03a6f,\u03c8(xn) = y (\u03ba) n = \u3008yn, yn+\u03c4 , yn+2\u03c4 , . . . , yn+(\u03ba\u22121)\u03c4 \u3009, (34)\nis an embedding. More formally, denote \u03a6f,\u03c8 , Dr(M,M) as the space of Cr-diffeomorphisms on M and Cr(M,R) as the space of Cr-functions onM, then the theorem can be expressed as follows. Theorem 5 (Delay Embedding Theorem for Diffeomorphisms [32]). LetM be a compact manifold of dimension d \u2265 1. If \u03ba \u2265 2d + 1 and r \u2265 1, then there exists an open and dense set (f, \u03c8) \u2208 Dr(M,M)\u00d7 Cr(M,R) for which the map \u03a6f,\u03c8 is an embedding ofM into R\u03ba.\nThe implication of Theorem 5 is that, for typical (f, \u03c8), the image \u03a6f,\u03c8(M) ofM under the delay embedding map \u03a6f,\u03c8 is completely equivalent toM itself, apart from the smooth invertible change of coordinates given by the mapping \u03a6f,\u03c8. An important consequence of this result is that we can define a map F = \u03a6f,\u03c8 \u25e6 f \u25e6 \u03a6\u22121f,\u03c8 on \u03a6f,\u03c8, such that y (\u03ba) n+1 = F(y (\u03ba) n ) [33]. The bound for the open and dense set referred to in Theorem 5 is given by a number of technical assumptions. Denote (Df)x as the derivative of function f at a point x in the domain of f . The set of periodic points A of\n4Although it is not derived in [50], it is trivial to show the first two terms constitute multi-information.\nf with period less than \u03c4 has finitely many points. In addition, the eigenvalues of (Df)x at each x in a compact neighbourhood A are distinct and not equal to 1.\nImportantly, Theorem 5 was established for diffeomorphisms Dr; by definition the dynamics are thus invertible in time. So the time delay \u03c4 in (34) can be either positive (delay lags) or negative (delay leads). Takens later proved a similar result for endomorphisms, i.e., non-invertible maps that restricts the time delay to a negative integer. Denote by E(M,M) the set of the space of Cr-endomorphisms onM, then the reconstruction theorem for endomorphisms can be expressed as the following. Theorem 6 (Delay Embedding Theorem for Endomorphisms [67]). Let M be a compact m dimensional manifold. If \u03ba \u2265 2d + 1 and r \u2265 1, then there exists an open and dense set (f, \u03c8) \u2208 Dr(M,M) \u00d7 Cr(M,R) for which there is a map \u03c0\u03ba : X\u03ba \u2192M with \u03c0\u03ba\u03a6f,\u03c8 = f\u03ba\u22121. Moreover, the map \u03c0\u03ba has bounded expansion or is Lipschitz continuous.\nAs a result of Theorem 6, a sequence of \u03ba successive measurements from a system determines the system state at the end of the sequence of measurements [67]. That is, there exists an endomorphism F = \u03a6f,\u03c8 \u25e6 f \u25e6 \u03a6\u22121f,\u03c8 to predict the next observation if one takes a negative time (lead) delay \u03c4 in (34).\nIn this work, we consider two important generalisations of the Delay Embedding Theorem 5. Both of these theorems follow similar proofs to the original and have thus been derived for diffeomorphisms, not endomorphisms. However, encouraging empirical results in [9] support the conjecture that they can both be generalised to the case of endomorphisms by taking a negative time delay, as is done in Theorem 6 above.\nThe first generalisation is by Stark et al. [33] and deals with a skew-product system. That is, f is now forced by some second, independent system g : N \u2192 N . The dynamical system onM\u00d7N is thus given by the set of equations\nxn+1 = f(xn, \u03c9n), \u03c9n+1 = g(\u03c9n). (35)\nIn this case, the delay map is written as\n\u03a6f,g,\u03c8(x, \u03c9) = \u3008yn, yn+\u03c4 , yn+2\u03c4 , . . . , yn+(\u03ba\u22121)\u03c4 \u3009, (36)\nand the theorem can be expressed as follows. Theorem 7 (Bundle Delay Embedding Theorem [33]). Let M and N be compact manifolds of dimension d \u2265 1 and e respectively. Suppose that \u03ba \u2265 2(d+ e) + 1 and the periodic orbits of period \u2264 d of g \u2208 Dr(N ) are isolated and have distinct eigenvalues. Then, for r \u2265 1, there exists an open and dense set of (f, \u03c8) \u2282 Dr(M\u00d7N ,M)\u00d7 Cr(M,R) for which the map \u03a6f,g,\u03c8 is an embedding ofM\u00d7N into R\u03ba.\nFinally, all theorems up until now have assumed a single read-out function for the system in question. Recently, Sugihara and Deyle [7] showed that multivariate mappings also form an embedding, with minor changes to the technical assumptions underlying Takens\u2019 original theorem. That is, given M \u2264 2d+ 1 different observation functions, the delay map can be written as\n\u03a6f,\u3008\u03c8i\u3009(x) = \u3008\u03a6f,\u03c81(x),\u03a6f,\u03c82(x), . . . ,\u03a6f,\u03c8M (x)\u3009, (37)\nwhere each delay map \u03a6f,\u03c8i is as per (34) for individual embedding dimension \u03bai \u2264 \u03ba. The theorem can then be stated as follows. Theorem 8 (Delay Embedding Theorem for Multivariate Observation Functions [57]). LetM be a compact manifold of dimension d \u2265 1. Consider a diffeomorphism f \u2208 Dr(M,M) and a set of at most 2d+ 1 observation functions \u3008\u03c8i\u3009 where each \u03c8i \u2208 Cr(M,R) and r \u2265 2. If \u2211 i \u03ba\ni \u2265 2d+ 1, then, for generic (f, \u3008\u03c8i\u3009), the map \u03a6f,\u3008\u03c8i\u3009 is an embedding."}], "references": [{"title": "Complex networks: Structure and dynamics", "author": ["S. Boccaletti", "V. Latora", "Y. Moreno", "M. Chavez", "D.-U. Hwang"], "venue": "Phys. Rep., vol. 424, no. 4, pp. 175\u2013308, 2006.", "citeRegEx": "1", "shortCiteRegEx": null, "year": 2006}, {"title": "An Introduction to Sequential Dynamical Systems", "author": ["H. Mortveit", "C. Reidys"], "venue": "Springer Science & Business Media,", "citeRegEx": "2", "shortCiteRegEx": "2", "year": 2007}, {"title": "An information criterion for inferring coupling in distributed dynamical systems", "author": ["O.M. Cliff", "M. Prokopenko", "R. Fitch"], "venue": "Front. Robot. AI, 2016.", "citeRegEx": "3", "shortCiteRegEx": null, "year": 2016}, {"title": "Measuring information transfer", "author": ["T. Schreiber"], "venue": "Phys. Rev. Lett., vol. 85, no. 2, pp. 461\u2013464, 2000.", "citeRegEx": "4", "shortCiteRegEx": null, "year": 2000}, {"title": "Delayed spatiotemporal interactions and coherent structure in multi-agent team dynamics", "author": ["O.M. Cliff", "J.T. Lizier", "P. Wang", "X.R. Wang", "O. Obst", "M. Prokopenko"], "venue": "Art. Life, vol. 23, no. 1, 2016.", "citeRegEx": "5", "shortCiteRegEx": null, "year": 2016}, {"title": "Scalable identification of stable positive systems", "author": ["J. Umenberger", "I.R. Manchester"], "venue": "Proc. of IEEE CDC, 2016.", "citeRegEx": "6", "shortCiteRegEx": null, "year": 2016}, {"title": "Detecting causality in complex ecosystems", "author": ["G. Sugihara", "R. May", "H. Ye", "C.-h. Hsieh", "E. Deyle", "M. Fogarty", "S. Munch"], "venue": "Science, vol. 338, no. 6106, pp. 496\u2013500, 2012.", "citeRegEx": "7", "shortCiteRegEx": null, "year": 2012}, {"title": "Transfer entropy \u2013 a model-free measure of effective connectivity for the neurosciences", "author": ["R. Vicente", "M. Wibral", "M. Lindner", "G. Pipa"], "venue": "J. Comp. Neurosci., vol. 30, no. 1, pp. 45\u201367, 2011.", "citeRegEx": "8", "shortCiteRegEx": null, "year": 2011}, {"title": "A statistical framework to infer delay and direction of information flow from measurements of complex systems", "author": ["J. Schumacher", "T. Wunderle", "P. Fries", "F. J\u00e4kel", "G. Pipa"], "venue": "Neural Computation, vol. 27, no. 8, pp. 1555\u20131608, 2015.", "citeRegEx": "9", "shortCiteRegEx": null, "year": 2015}, {"title": "Learning Bayesian networks: Approaches and issues", "author": ["R. Daly", "Q. Shen", "J.S. Aitken"], "venue": "Knowl. Eng. Rev., vol. 26, no. 2, pp. 99\u2013157, 2011.", "citeRegEx": "10", "shortCiteRegEx": null, "year": 2011}, {"title": "Learning equivalence classes of Bayesian-network structures", "author": ["D.M. Chickering"], "venue": "J. Mach. Learn. Res., vol. 2, pp. 445\u2013498, 2002.", "citeRegEx": "11", "shortCiteRegEx": null, "year": 2002}, {"title": "Information theory and an extension of the maximum likelihood principle", "author": ["H. Akaike"], "venue": "Proc. of IEEE ISIT, pp. 267\u2013281, 1973.", "citeRegEx": "12", "shortCiteRegEx": null, "year": 1973}, {"title": "Estimating the dimension of a model", "author": ["G. Schwarz"], "venue": "Ann. Statist., vol. 6, no. 2, pp. 461\u2013464, 1978.", "citeRegEx": "13", "shortCiteRegEx": null, "year": 1978}, {"title": "Modeling by shortest data description", "author": ["J. Rissanen"], "venue": "Automatica, vol. 14, no. 5, pp. 465\u2013471, 1978.", "citeRegEx": "14", "shortCiteRegEx": null, "year": 1978}, {"title": "Learning Bayesian belief networks: An approach based on the MDL principle", "author": ["W. Lam", "F. Bacchus"], "venue": "Comp. Intell., vol. 10, no. 3, pp. 269\u2013293, 1994.", "citeRegEx": "15", "shortCiteRegEx": null, "year": 1994}, {"title": "Temporal infomax leads to almost deterministic dynamical systems", "author": ["N. Ay", "T. Wennekers"], "venue": "Neurocomputing, vol. 52, pp. 461\u2013466, 2003.", "citeRegEx": "16", "shortCiteRegEx": null, "year": 2003}, {"title": "Information modification and particle collisions in distributed computation", "author": ["J.T. Lizier", "M. Prokopenko", "A.Y. Zomaya"], "venue": "Chaos, vol. 20, no. 3, pp. 037109\u201313, 2010.", "citeRegEx": "17", "shortCiteRegEx": null, "year": 2010}, {"title": "Dynamic Bayesian Networks: Representation, Inference and Learning", "author": ["K. Murphy"], "venue": "PhD thesis, UC Berkeley,", "citeRegEx": "18", "shortCiteRegEx": "18", "year": 2002}, {"title": "Multivariate construction of effective computational networks from observational data.", "author": ["J.T. Lizier", "M. Rubinov"], "venue": "ArXiV Preprint,", "citeRegEx": "19", "shortCiteRegEx": "19", "year": 2012}, {"title": "Collective dynamics of \u2019small-world\u2019 networks", "author": ["D.J. Watts", "S.H. Strogatz"], "venue": "Nature, vol. 393, no. 6684, pp. 409\u201310, 1998.", "citeRegEx": "20", "shortCiteRegEx": null, "year": 1998}, {"title": "Emergence of scaling in random networks", "author": ["A.-L. Barab\u00e1si", "R. Albert"], "venue": "Science, vol. 286, no. 5439, pp. 509\u2013512, 1999.", "citeRegEx": "21", "shortCiteRegEx": null, "year": 1999}, {"title": "Probabilistic graphical models: Principles and techniques", "author": ["D. Koller", "N. Friedman"], "venue": "MIT press,", "citeRegEx": "22", "shortCiteRegEx": "22", "year": 2009}, {"title": "Nonlinear time series analysis", "author": ["H. Kantz", "T. Schreiber"], "venue": "Cambridge university press,", "citeRegEx": "23", "shortCiteRegEx": "23", "year": 2004}, {"title": "Generalized synchronization, predictability, and equivalence of unidirectionally coupled dynamical systems", "author": ["L. Kocarev", "U. Parlitz"], "venue": "Physical Review Letters, vol. 76, no. 11, p. 1816, 1996.", "citeRegEx": "24", "shortCiteRegEx": null, "year": 1816}, {"title": "Probabilistic Reasoning in Intelligent Systems: Networks of Plausible Inference", "author": ["J. Pearl"], "venue": null, "citeRegEx": "25", "shortCiteRegEx": "25", "year": 2014}, {"title": "Entropy per unit time as a metric invariant of automorphisms", "author": ["A.N. Kolmogorov"], "venue": "Dokl. Akad. Nauk SSSR, vol. 124, pp. 754\u2013755, 1959. 15", "citeRegEx": "26", "shortCiteRegEx": null, "year": 1959}, {"title": "On the notion of entropy of a dynamical system", "author": ["Y.G. Sinai"], "venue": "Dokl. Akad. Nauk SSSR, vol. 124, pp. 768\u2013771, 1959.", "citeRegEx": "27", "shortCiteRegEx": null, "year": 1959}, {"title": "Investigating causal relations by econometric models and cross-spectral methods", "author": ["C.W. Granger"], "venue": "Econometrica, pp. 424\u2013438, 1969.", "citeRegEx": "28", "shortCiteRegEx": null, "year": 1969}, {"title": "The bidirectional communication theory \u2013 a generalization of information theory", "author": ["H. Marko"], "venue": "IEEE Trans. Commun., vol. 21, no. 12, pp. 1345\u20131351, 1973.", "citeRegEx": "29", "shortCiteRegEx": null, "year": 1973}, {"title": "Granger causality and transfer entropy are equivalent for Gaussian variables", "author": ["L. Barnett", "A.B. Barrett", "A.K. Seth"], "venue": "Phys. Rev. Lett., vol. 103, p. e238701, 2009.", "citeRegEx": "30", "shortCiteRegEx": null, "year": 2009}, {"title": "Differentiating information transfer and causal effect", "author": ["J.T. Lizier", "M. Prokopenko"], "venue": "Eur. Phys. J B., vol. 73, no. 4, pp. 605\u2013615, 2010.", "citeRegEx": "31", "shortCiteRegEx": null, "year": 2010}, {"title": "Detecting strange attractors in turbulence", "author": ["F. Takens"], "venue": "Dynamical Systems and Turbulence, vol. 898 of Lecture Notes in Math., pp. 366\u2013381, 1981.", "citeRegEx": "32", "shortCiteRegEx": null, "year": 1981}, {"title": "Takens embedding theorems for forced and stochastic systems", "author": ["J. Stark", "D.S. Broomhead", "M.E. Davies", "J. Huke"], "venue": "Nonlinear Anal. Theory Methods Appl., vol. 30, no. 9, pp. 5303\u20135314, 1997.", "citeRegEx": "33", "shortCiteRegEx": null, "year": 1997}, {"title": "Organization, development and function of complex brain networks", "author": ["O. Sporns", "D.R. Chialvo", "M. Kaiser", "C.C. Hilgetag"], "venue": "Trends Cogn. Sci., vol. 8, no. 9, pp. 418\u2013425, 2004.", "citeRegEx": "34", "shortCiteRegEx": null, "year": 2004}, {"title": "Structural and functional brain networks: from connections to cognition", "author": ["H.-J. Park", "K. Friston"], "venue": "Science, vol. 342, no. 6158, p. 1238411, 2013.", "citeRegEx": "35", "shortCiteRegEx": null, "year": 2013}, {"title": "Towards quantifying interaction networks in a football match", "author": ["O.M. Cliff", "J.T. Lizier", "X.R. Wang", "P. Wang", "O. Obst", "M. Prokopenko"], "venue": "RoboCup 2013: Robot World Cup XVII, pp. 1\u201313, Springer, 2013.", "citeRegEx": "36", "shortCiteRegEx": null, "year": 2013}, {"title": "Structure of a global network of financial companies based on transfer entropy", "author": ["L. Sandoval"], "venue": "Entropy, vol. 16, no. 8, pp. 4443\u20134482, 2014.", "citeRegEx": "37", "shortCiteRegEx": null, "year": 2014}, {"title": "Using information-theoretic principles to analyze and evaluate complex adaptive supply network architectures", "author": ["J. Rodewald", "J. Colombi", "K. Oyama", "A. Johnson"], "venue": "Procedia Computer Sci., vol. 61, pp. 147\u2013152, 2015.", "citeRegEx": "38", "shortCiteRegEx": null, "year": 2015}, {"title": "Model identification using correlation-based inference and transfer entropy estimation", "author": ["C. Damiani", "P. Lecca"], "venue": "Proc. of IEEE EMS, pp. 129\u2013134, 2011.", "citeRegEx": "39", "shortCiteRegEx": null, "year": 2011}, {"title": "Properties of Bayesian belief network learning algorithms", "author": ["R.R. Bouckaert"], "venue": "Proc. of AUAI UAI, pp. 102\u2013109, 1994.", "citeRegEx": "40", "shortCiteRegEx": null, "year": 1994}, {"title": "A tutorial on learning Bayesian networks", "author": ["D. Heckerman"], "venue": "Innovations in Bayesian Net., vol. 156 of Studies in Comp. Intell., pp. 33\u201382, Springer, 1995.", "citeRegEx": "41", "shortCiteRegEx": null, "year": 1995}, {"title": "Learning Bayesian networks: the combination of knowledge and statistical data", "author": ["D. Heckerman", "D. Geiger", "D.M. Chickering"], "venue": "Mach. Learn., vol. 20, no. 3, pp. 20\u2013197, 1995.", "citeRegEx": "42", "shortCiteRegEx": null, "year": 1995}, {"title": "Theory refinement on Bayesian networks", "author": ["W. Buntine"], "venue": "Proc. of AUAI UAI, pp. 52\u201360, 1991.", "citeRegEx": "43", "shortCiteRegEx": null, "year": 1991}, {"title": "Learning the structure of dynamic probabilistic networks", "author": ["N. Friedman", "K. Murphy", "S. Russell"], "venue": "Proc. of AUAI UAI, pp. 139\u2013147, 1998.", "citeRegEx": "44", "shortCiteRegEx": null, "year": 1998}, {"title": "Local learning in probabilistic networks with hidden variables", "author": ["S. Russell", "J. Binder", "D. Koller", "K. Kanazawa"], "venue": "Proc. of AAAI IJCAI, vol. 95, pp. 1146\u20131152, 1995.", "citeRegEx": "45", "shortCiteRegEx": null, "year": 1995}, {"title": "Adaptive probabilistic networks with hidden variables", "author": ["J. Binder", "D. Koller", "S. Russell", "K. Kanazawa"], "venue": "Mach. Learn., vol. 29, no. 2-3, pp. 213\u2013244, 1997.", "citeRegEx": "46", "shortCiteRegEx": null, "year": 1997}, {"title": "Using hidden nodes in Bayesian networks", "author": ["C.-K. Kwoh", "D.F. Gillies"], "venue": "Artif. Intell., vol. 88, no. 1, pp. 1\u201338, 1996.", "citeRegEx": "47", "shortCiteRegEx": null, "year": 1996}, {"title": "Approximating posterior distributions in belief networks using mixtures", "author": ["C.M. Bishop", "N. Lawrence", "T. Jaakkola", "M. Jordan"], "venue": "Proc. of NIPS, p. 416, 1998.", "citeRegEx": "48", "shortCiteRegEx": null, "year": 1998}, {"title": "A Bayesian approach to learning Bayesian networks with local structure", "author": ["D.M. Chickering", "D. Heckerman", "C. Meek"], "venue": "Proc. of AUAI UAI, pp. 80\u201389, 1997.", "citeRegEx": "49", "shortCiteRegEx": null, "year": 1997}, {"title": "A scoring function for learning Bayesian networks based on mutual information and conditional independence tests", "author": ["L.M. de Campos"], "venue": "J. Mach. Learn. Res., vol. 7, pp. 2149\u20132187, Dec. 2006. 16", "citeRegEx": "50", "shortCiteRegEx": null, "year": 2006}, {"title": "GlobalMIT: learning globally optimal dynamic Bayesian network with the mutual information test criterion", "author": ["N.X. Vinh", "M. Chetty", "R. Coppel", "P.P. Wangikar"], "venue": "Bioinformatics, vol. 27, no. 19, pp. 2765\u20132766, 2011.", "citeRegEx": "51", "shortCiteRegEx": null, "year": 2011}, {"title": "Sample estimate of the entropy of a random vector", "author": ["L. Kozachenko", "N.N. Leonenko"], "venue": "Probl. Peredachi Inf., vol. 23, no. 2, pp. 9\u201316, 1987.", "citeRegEx": "52", "shortCiteRegEx": null, "year": 1987}, {"title": "Estimating mutual information", "author": ["A. Kraskov", "H. St\u00f6gbauer", "P. Grassberger"], "venue": "Phys. Rev. E, vol. 69, no. 6, p. 066138, 2004.", "citeRegEx": "53", "shortCiteRegEx": null, "year": 2004}, {"title": "Binless strategies for estimation of information from neural data", "author": ["J.D. Victor"], "venue": "Phys. Rev. E, vol. 66, no. 5, p. 051903, 2002.", "citeRegEx": "54", "shortCiteRegEx": null, "year": 1903}, {"title": "A new look at the statistical model identification", "author": ["H. Akaike"], "venue": "IEEE Trans. Autom. Control, vol. 19, no. 6, pp. 716\u2013723, 1974.", "citeRegEx": "55", "shortCiteRegEx": null, "year": 1974}, {"title": "Information Theory, Inference and Learning Algorithms", "author": ["D.J.C. MacKay"], "venue": "Cambridge university press,", "citeRegEx": "56", "shortCiteRegEx": "56", "year": 2003}, {"title": "Generalized theorems for nonlinear state space reconstruction", "author": ["E.R. Deyle", "G. Sugihara"], "venue": "PLOS ONE, vol. 6, no. 3, p. e18295, 2011.", "citeRegEx": "57", "shortCiteRegEx": null, "year": 1829}, {"title": "Dynamical properties of strongly interacting Markov chains", "author": ["N. Ay", "T. Wennekers"], "venue": "Neural Net., vol. 16, no. 10, pp. 1483\u20131497, 2003.", "citeRegEx": "58", "shortCiteRegEx": null, "year": 2003}, {"title": "Integrated information increases with fitness in the evolution of animats", "author": ["J.A. Edlund", "N. Chaumont", "A. Hintze", "C. Koch", "G. Tononi", "C. Adami"], "venue": "PLOS Comp. Bio., vol. 7, no. 10, p. e1002236, 2011.", "citeRegEx": "59", "shortCiteRegEx": null, "year": 2011}, {"title": "Discretizing continuous attributes while learning Bayesian networks", "author": ["N. Friedman", "M. Goldszmidt"], "venue": "Proc. of ICML, pp. 157\u2013165, 1996.", "citeRegEx": "60", "shortCiteRegEx": null, "year": 1996}, {"title": "JIDT: an information-theoretic toolkit for studying the dynamics of complex systems", "author": ["J.T. Lizier"], "venue": "Front. Robot. AI, vol. 1, no. 11, 2014.", "citeRegEx": "61", "shortCiteRegEx": null, "year": 2014}, {"title": "Transfer entropy as a log-likelihood ratio", "author": ["L. Barnett", "T. Bossomaier"], "venue": "Physical review letters, vol. 109, no. 13, p. 138105, 2012.", "citeRegEx": "62", "shortCiteRegEx": null, "year": 2012}, {"title": "Searching for Bayesian network structures in the space of restricted acyclic partially directed graphs", "author": ["S. Acid", "L.M. de Campos"], "venue": "J. Artif. Intell. Res., pp. 445\u2013490, 2003.", "citeRegEx": "63", "shortCiteRegEx": null, "year": 2003}, {"title": "The multiinformation function as a tool for measuring stochastic dependence", "author": ["M. Studen\u1ef3", "J. Vejnarov\u00e1"], "venue": "Learning in graphical models, pp. 261\u2013297, Springer, 1998.", "citeRegEx": "64", "shortCiteRegEx": null, "year": 1998}, {"title": "Markov models from data by simple nonlinear time series predictors in delay embedding spaces", "author": ["M. Ragwitz", "H. Kantz"], "venue": "Phys. Rev. E, vol. 65, no. 5, p. 056201, 2002.", "citeRegEx": "65", "shortCiteRegEx": null, "year": 2002}, {"title": "Optimal embedding parameters: a modelling paradigm", "author": ["M. Small", "C.K. Tse"], "venue": "Physica D, vol. 194, no. 3, pp. 283\u2013296, 2004.", "citeRegEx": "66", "shortCiteRegEx": null, "year": 2004}, {"title": "The reconstruction theorem for endomorphisms", "author": ["F. Takens"], "venue": "Bull. Braz. Math. Soc., vol. 33, no. 2, pp. 231\u2013262, 2002. 17", "citeRegEx": "67", "shortCiteRegEx": null, "year": 2002}], "referenceMentions": [{"referenceID": 0, "context": "Complex networks are capable of modelling a wide array of important phenomena in both natural and artificial environments [1].", "startOffset": 122, "endOffset": 125}, {"referenceID": 1, "context": "We represent this network as a type of probabilistic graphical model termed a synchronous graph dynamical system (GDS) [2, 3].", "startOffset": 119, "endOffset": 125}, {"referenceID": 2, "context": "We represent this network as a type of probabilistic graphical model termed a synchronous graph dynamical system (GDS) [2, 3].", "startOffset": 119, "endOffset": 125}, {"referenceID": 3, "context": "We propose a solution based on the concept of transfer entropy, which is a measure that detects the directed information-theoretic dependency between random processes [4].", "startOffset": 167, "endOffset": 170}, {"referenceID": 4, "context": "The problem of inferring this coupling is an important multidisciplinary study in fields such as multi-agent systems [5, 6], ecology [7], neuroscience [8, 9], and various others studying artificial and biological systems [1].", "startOffset": 117, "endOffset": 123}, {"referenceID": 5, "context": "The problem of inferring this coupling is an important multidisciplinary study in fields such as multi-agent systems [5, 6], ecology [7], neuroscience [8, 9], and various others studying artificial and biological systems [1].", "startOffset": 117, "endOffset": 123}, {"referenceID": 6, "context": "The problem of inferring this coupling is an important multidisciplinary study in fields such as multi-agent systems [5, 6], ecology [7], neuroscience [8, 9], and various others studying artificial and biological systems [1].", "startOffset": 133, "endOffset": 136}, {"referenceID": 7, "context": "The problem of inferring this coupling is an important multidisciplinary study in fields such as multi-agent systems [5, 6], ecology [7], neuroscience [8, 9], and various others studying artificial and biological systems [1].", "startOffset": 151, "endOffset": 157}, {"referenceID": 8, "context": "The problem of inferring this coupling is an important multidisciplinary study in fields such as multi-agent systems [5, 6], ecology [7], neuroscience [8, 9], and various others studying artificial and biological systems [1].", "startOffset": 151, "endOffset": 157}, {"referenceID": 0, "context": "The problem of inferring this coupling is an important multidisciplinary study in fields such as multi-agent systems [5, 6], ecology [7], neuroscience [8, 9], and various others studying artificial and biological systems [1].", "startOffset": 221, "endOffset": 224}, {"referenceID": 9, "context": "Exact methods are known for fully observable systems [10], however, these are not applicable because the state variables in dynamical systems are latent.", "startOffset": 53, "endOffset": 57}, {"referenceID": 10, "context": "Such a measure can then be used to solve the two subproblems that comprise structure learning, evaluation and identification [11], and hence find the optimal model that explains the data.", "startOffset": 125, "endOffset": 129}, {"referenceID": 11, "context": "This concept is commonly expressed via information theory, where an established technique is to evaluate the encoding length of the data, given the model [12, 13, 14].", "startOffset": 154, "endOffset": 166}, {"referenceID": 12, "context": "This concept is commonly expressed via information theory, where an established technique is to evaluate the encoding length of the data, given the model [12, 13, 14].", "startOffset": 154, "endOffset": 166}, {"referenceID": 13, "context": "This concept is commonly expressed via information theory, where an established technique is to evaluate the encoding length of the data, given the model [12, 13, 14].", "startOffset": 154, "endOffset": 166}, {"referenceID": 14, "context": "The simplest model should aim to minimise code length [15], and therefore we can simplify our problem to that of minimising KL divergence for the synchronous GDS.", "startOffset": 54, "endOffset": 58}, {"referenceID": 15, "context": "We show that this measure can be decomposed as the difference between two well-known informationtheoretic measures, stochastic interaction [16] and collective transfer entropy [17].", "startOffset": 139, "endOffset": 143}, {"referenceID": 16, "context": "We show that this measure can be decomposed as the difference between two well-known informationtheoretic measures, stochastic interaction [16] and collective transfer entropy [17].", "startOffset": 176, "endOffset": 180}, {"referenceID": 17, "context": "We establish this result by first representing discrete-time multivariate dynamical systems as dynamic Bayesian networks (DBNs) [18].", "startOffset": 128, "endOffset": 132}, {"referenceID": 18, "context": "Interestingly, transfer entropy has already been used in practice for inferring effective networks [19] with encouraging empirical results.", "startOffset": 99, "endOffset": 103}, {"referenceID": 0, "context": "A complex network is a graph with non-trivial topological features that gives rise to emergent behaviour not typically seen in more traditional fields of graph theory [1].", "startOffset": 167, "endOffset": 170}, {"referenceID": 19, "context": "This concept was popularised by the seminal work of Watts and Strogatz [20] on small-world networks and Barab\u00e1si and Albert [21] on scale-free networks.", "startOffset": 71, "endOffset": 75}, {"referenceID": 20, "context": "This concept was popularised by the seminal work of Watts and Strogatz [20] on small-world networks and Barab\u00e1si and Albert [21] on scale-free networks.", "startOffset": 124, "endOffset": 128}, {"referenceID": 0, "context": "Since then, most of the complex network literature focuses on characterising the structure and dynamics of known biological, physical, and artificial networks [1].", "startOffset": 159, "endOffset": 162}, {"referenceID": 21, "context": "We instead focus on the structure learning problem, a general paradigm in machine learning where the goal is to infer relationships between the variables within a system [22].", "startOffset": 170, "endOffset": 174}, {"referenceID": 22, "context": "Besides complex networks, these types of systems have been introduced under a variety of more specific terms, such as spatially distributed dynamical systems [23, 9] and master-slave configurations [24].", "startOffset": 158, "endOffset": 165}, {"referenceID": 8, "context": "Besides complex networks, these types of systems have been introduced under a variety of more specific terms, such as spatially distributed dynamical systems [23, 9] and master-slave configurations [24].", "startOffset": 158, "endOffset": 165}, {"referenceID": 23, "context": "Besides complex networks, these types of systems have been introduced under a variety of more specific terms, such as spatially distributed dynamical systems [23, 9] and master-slave configurations [24].", "startOffset": 198, "endOffset": 202}, {"referenceID": 22, "context": "In this paper we use the discrete-time formulation, where a map is obtained numerically by integrating ODEs or recording observations at discrete-time intervals [23].", "startOffset": 161, "endOffset": 165}, {"referenceID": 24, "context": "when the experimenter can not intervene with the dataset [25].", "startOffset": 57, "endOffset": 61}, {"referenceID": 25, "context": "In early work, Kolmogorov [26] introduced the concept of classification of dynamical systems by information rates, leading to a generalisation of entropy of an information source [27].", "startOffset": 26, "endOffset": 30}, {"referenceID": 26, "context": "In early work, Kolmogorov [26] introduced the concept of classification of dynamical systems by information rates, leading to a generalisation of entropy of an information source [27].", "startOffset": 179, "endOffset": 183}, {"referenceID": 27, "context": "Following this, Granger [28] proposed Granger causality for quantifying the predictability of one variable from another.", "startOffset": 24, "endOffset": 28}, {"referenceID": 6, "context": "Although this measure has been used numerous times in identifying coupling, a limiting assumption of Granger causality is the key requirement of linearity, implying subsystems can be understood as individual parts [7].", "startOffset": 214, "endOffset": 217}, {"referenceID": 3, "context": "Schreiber [4] extended the ideas of Granger and introduced transfer entropy using the concept of finite-order Markov processes to quantify the information transfer between coupled nonlinear systems (although this idea was expressed earlier by Marko [29] as an information-theoretic interpretation of predictability).", "startOffset": 10, "endOffset": 13}, {"referenceID": 28, "context": "Schreiber [4] extended the ideas of Granger and introduced transfer entropy using the concept of finite-order Markov processes to quantify the information transfer between coupled nonlinear systems (although this idea was expressed earlier by Marko [29] as an information-theoretic interpretation of predictability).", "startOffset": 249, "endOffset": 253}, {"referenceID": 17, "context": ", Kalman models [18]), where transfer entropy and Granger causality are equivalent [30].", "startOffset": 16, "endOffset": 20}, {"referenceID": 29, "context": ", Kalman models [18]), where transfer entropy and Granger causality are equivalent [30].", "startOffset": 83, "endOffset": 87}, {"referenceID": 30, "context": ", the analysis in Lizier and Prokopenko [31] ).", "startOffset": 40, "endOffset": 44}, {"referenceID": 6, "context": "Recently, a number of measures have been proposed to infer coupling between distributed dynamical systems based on state space reconstruction theorems [7, 9, 3].", "startOffset": 151, "endOffset": 160}, {"referenceID": 8, "context": "Recently, a number of measures have been proposed to infer coupling between distributed dynamical systems based on state space reconstruction theorems [7, 9, 3].", "startOffset": 151, "endOffset": 160}, {"referenceID": 2, "context": "Recently, a number of measures have been proposed to infer coupling between distributed dynamical systems based on state space reconstruction theorems [7, 9, 3].", "startOffset": 151, "endOffset": 160}, {"referenceID": 6, "context": "[7] assumed Granger\u2019s definition of causality as a quantification of predictability and proposed a method labelled convergent cross-mapping (CCM).", "startOffset": 0, "endOffset": 3}, {"referenceID": 31, "context": "This history is the delay reconstruction map described by Takens\u2019 Delay Embedding Theorem [32].", "startOffset": 90, "endOffset": 94}, {"referenceID": 8, "context": "[9] used the Bundle Delay Embedding Theorem [33] infer causality and perform inference via Gaussian processes.", "startOffset": 0, "endOffset": 3}, {"referenceID": 32, "context": "[9] used the Bundle Delay Embedding Theorem [33] infer causality and perform inference via Gaussian processes.", "startOffset": 44, "endOffset": 48}, {"referenceID": 2, "context": "Finally, we recently presented similar work on deriving an information criterion for learning the structure of distributed dynamical systems [3].", "startOffset": 141, "endOffset": 144}, {"referenceID": 2, "context": "In this paper we extend this framework by proposing two scoring functions: one that is comparable to the information criterion presented in [3] in that it is applicable for discrete and linearly-coupled Gaussian variables; and another that allows for non-parametric density estimation techniques and thus make no assumptions about the underlying distributions.", "startOffset": 140, "endOffset": 143}, {"referenceID": 33, "context": "A related line of inquiry is recovering effective networks: networks that reveal the \u201ceffective structure\u201d of an observed system [34, 35].", "startOffset": 129, "endOffset": 137}, {"referenceID": 34, "context": "A related line of inquiry is recovering effective networks: networks that reveal the \u201ceffective structure\u201d of an observed system [34, 35].", "startOffset": 129, "endOffset": 137}, {"referenceID": 7, "context": ", in computational neuroscience [8, 19]; multi-agent systems [36, 5]; financial markets [37]; supply-chain networks [38]; and gene regulatory networks [39].", "startOffset": 32, "endOffset": 39}, {"referenceID": 18, "context": ", in computational neuroscience [8, 19]; multi-agent systems [36, 5]; financial markets [37]; supply-chain networks [38]; and gene regulatory networks [39].", "startOffset": 32, "endOffset": 39}, {"referenceID": 35, "context": ", in computational neuroscience [8, 19]; multi-agent systems [36, 5]; financial markets [37]; supply-chain networks [38]; and gene regulatory networks [39].", "startOffset": 61, "endOffset": 68}, {"referenceID": 4, "context": ", in computational neuroscience [8, 19]; multi-agent systems [36, 5]; financial markets [37]; supply-chain networks [38]; and gene regulatory networks [39].", "startOffset": 61, "endOffset": 68}, {"referenceID": 36, "context": ", in computational neuroscience [8, 19]; multi-agent systems [36, 5]; financial markets [37]; supply-chain networks [38]; and gene regulatory networks [39].", "startOffset": 88, "endOffset": 92}, {"referenceID": 37, "context": ", in computational neuroscience [8, 19]; multi-agent systems [36, 5]; financial markets [37]; supply-chain networks [38]; and gene regulatory networks [39].", "startOffset": 116, "endOffset": 120}, {"referenceID": 38, "context": ", in computational neuroscience [8, 19]; multi-agent systems [36, 5]; financial markets [37]; supply-chain networks [38]; and gene regulatory networks [39].", "startOffset": 151, "endOffset": 155}, {"referenceID": 3, "context": "Most of the results build on Schreiber\u2019s work [4] and assume the system to be composed of finite-order Markov chains; we extend this notion by showing that transfer entropy can also reveal the effective structure of distributed dynamical systems.", "startOffset": 46, "endOffset": 49}, {"referenceID": 2, "context": "In prior work [3], we have connected the log-likelihood ratio of a distributed dynamical system and transfer entropy.", "startOffset": 14, "endOffset": 17}, {"referenceID": 17, "context": "In order to evaluate the quality of a network structure, we adopt the framework of DBNs [18].", "startOffset": 88, "endOffset": 92}, {"referenceID": 10, "context": "In Bayesian network (BN) structure learning literature, there is an already mature research topic called the evaluation problem, which is aimed at deriving a measure that can be used to score candidate graphs, given a dataset [11].", "startOffset": 226, "endOffset": 230}, {"referenceID": 39, "context": "A number of mathematically sound techniques exist for the evaluation problem in a fully observed BN [40, 41, 42, 43], most of which can be readily extended to the DBN case [44].", "startOffset": 100, "endOffset": 116}, {"referenceID": 40, "context": "A number of mathematically sound techniques exist for the evaluation problem in a fully observed BN [40, 41, 42, 43], most of which can be readily extended to the DBN case [44].", "startOffset": 100, "endOffset": 116}, {"referenceID": 41, "context": "A number of mathematically sound techniques exist for the evaluation problem in a fully observed BN [40, 41, 42, 43], most of which can be readily extended to the DBN case [44].", "startOffset": 100, "endOffset": 116}, {"referenceID": 42, "context": "A number of mathematically sound techniques exist for the evaluation problem in a fully observed BN [40, 41, 42, 43], most of which can be readily extended to the DBN case [44].", "startOffset": 100, "endOffset": 116}, {"referenceID": 43, "context": "A number of mathematically sound techniques exist for the evaluation problem in a fully observed BN [40, 41, 42, 43], most of which can be readily extended to the DBN case [44].", "startOffset": 172, "endOffset": 176}, {"referenceID": 44, "context": "[45] and Binder et al.", "startOffset": 0, "endOffset": 4}, {"referenceID": 45, "context": "[46] use gradient descent to find parameters with possible hidden variables, and then extended their work to continuous nodes and DBNs.", "startOffset": 0, "endOffset": 4}, {"referenceID": 46, "context": "Kwoh and Gillies [47] use an ad hoc method to invent hidden nodes for unexplained data.", "startOffset": 17, "endOffset": 21}, {"referenceID": 47, "context": "[48] focused on solutions for cases specific to a sigmoid network with mixtures.", "startOffset": 0, "endOffset": 4}, {"referenceID": 48, "context": "[49] propose using the decomposability of the functions for efficient Monte Carlo methods that avoid this caveat.", "startOffset": 0, "endOffset": 4}, {"referenceID": 14, "context": "Interestingly, the analogous concept of maximising mutual information has been previously derived as a measure to recover fully observed BNs [15, 40, 50] and DBNs [51].", "startOffset": 141, "endOffset": 153}, {"referenceID": 39, "context": "Interestingly, the analogous concept of maximising mutual information has been previously derived as a measure to recover fully observed BNs [15, 40, 50] and DBNs [51].", "startOffset": 141, "endOffset": 153}, {"referenceID": 49, "context": "Interestingly, the analogous concept of maximising mutual information has been previously derived as a measure to recover fully observed BNs [15, 40, 50] and DBNs [51].", "startOffset": 141, "endOffset": 153}, {"referenceID": 50, "context": "Interestingly, the analogous concept of maximising mutual information has been previously derived as a measure to recover fully observed BNs [15, 40, 50] and DBNs [51].", "startOffset": 163, "endOffset": 167}, {"referenceID": 51, "context": "Given these processes, we can compute probability distributions of each variable by counting relative frequencies or by density estimation techniques [52, 53, 54].", "startOffset": 150, "endOffset": 162}, {"referenceID": 52, "context": "Given these processes, we can compute probability distributions of each variable by counting relative frequencies or by density estimation techniques [52, 53, 54].", "startOffset": 150, "endOffset": 162}, {"referenceID": 53, "context": "Given these processes, we can compute probability distributions of each variable by counting relative frequencies or by density estimation techniques [52, 53, 54].", "startOffset": 150, "endOffset": 162}, {"referenceID": 32, "context": "Furthermore, in many practical scenarios, we do not have access to xn directly, and can instead observe it through a measurement function \u03c8 :M\u2192 R that yields a scalar representation yn = \u03c8(xn) of the latent state [33, 23].", "startOffset": 213, "endOffset": 221}, {"referenceID": 22, "context": "Furthermore, in many practical scenarios, we do not have access to xn directly, and can instead observe it through a measurement function \u03c8 :M\u2192 R that yields a scalar representation yn = \u03c8(xn) of the latent state [33, 23].", "startOffset": 213, "endOffset": 221}, {"referenceID": 2, "context": "This definition is restated from [3] as follows.", "startOffset": 33, "endOffset": 36}, {"referenceID": 2, "context": "The global dynamics and observations can therefore be described by the set of local functions [3]:", "startOffset": 94, "endOffset": 97}, {"referenceID": 2, "context": "The discrete-time mapping for the dynamics (1) and measurement function (2) can be modelled as a DBN in order to facilitate structure learning of the graph [3].", "startOffset": 156, "endOffset": 159}, {"referenceID": 43, "context": ") by a prior BN and a two-time-slice BN (2TBN) [44].", "startOffset": 47, "endOffset": 51}, {"referenceID": 43, "context": "[44].", "startOffset": 0, "endOffset": 4}, {"referenceID": 2, "context": "To model the synchronous GDS as a DBN, we associate each subsystem vertex V i with a state variable X n and an observation variable Y i n; the parents of subsystem V i are denoted \u03a0G(V ) [3].", "startOffset": 187, "endOffset": 190}, {"referenceID": 2, "context": "Thus, we can build the edge set E in the GDS by means of the DBN [3], i.", "startOffset": 65, "endOffset": 68}, {"referenceID": 2, "context": "The distributions for the dynamics (1) and observation (2) maps of M arbitrary subsystems can therefore be factorised according to the DBN structure such that [3]", "startOffset": 159, "endOffset": 162}, {"referenceID": 21, "context": "We focus on the methods for learning the synchronous GDS structure using the score and search paradigm [22], which can be stated as: given a dataset D = (y1,y2, .", "startOffset": 103, "endOffset": 107}, {"referenceID": 10, "context": "Finding the optimal graph G\u2217 in (4) requires solutions to the two subproblems that comprise structure learning: the evaluation problem and the identification problem [11].", "startOffset": 166, "endOffset": 170}, {"referenceID": 43, "context": "The likelihood can be written in terms of distributions over network parameters [44] p(D | G) = \u222b p(D | G,\u0398)p(\u0398 | G)d\u0398.", "startOffset": 80, "endOffset": 84}, {"referenceID": 2, "context": "log-likelihood `(\u0398\u0302G : D), the model dimension (number of parameters) C(G), and the dataset size f(N), given by the general form [3]", "startOffset": 129, "endOffset": 132}, {"referenceID": 54, "context": "When f(N) = 1, we have the Akaike information criterion (AIC) score [55], f(N) = log(N)/2 is the Bayesian information criterion (BIC) score [13], and f(N) = 0 gives the maximum likelihood score.", "startOffset": 68, "endOffset": 72}, {"referenceID": 12, "context": "When f(N) = 1, we have the Akaike information criterion (AIC) score [55], f(N) = log(N)/2 is the Bayesian information criterion (BIC) score [13], and f(N) = 0 gives the maximum likelihood score.", "startOffset": 140, "endOffset": 144}, {"referenceID": 2, "context": "We have recently shown that state space reconstruction (see Appendix A) can be used to compute the log-likelihood of (3) as a difference of conditional entropy terms [3]:", "startOffset": 166, "endOffset": 169}, {"referenceID": 55, "context": "where H(Z |W ) is the entropy of variable Z conditioned on W [56],", "startOffset": 61, "endOffset": 65}, {"referenceID": 49, "context": "De Campos [50] proposes using the KL divergence as a natural information-theoretic approach to quantifying the similarity of these distributions for a BN.", "startOffset": 10, "endOffset": 14}, {"referenceID": 31, "context": "In this section we use state space reconstruction theorems based on Takens\u2019 seminal work [32] to obtain a tractable form of the conditional KL divergence (9).", "startOffset": 89, "endOffset": 93}, {"referenceID": 50, "context": "[51] applied the MIT algorithm [50] to DBN structure learning with complete data, however did not derive the results explicitly from conditional KL divergence.", "startOffset": 0, "endOffset": 4}, {"referenceID": 49, "context": "[51] applied the MIT algorithm [50] to DBN structure learning with complete data, however did not derive the results explicitly from conditional KL divergence.", "startOffset": 31, "endOffset": 35}, {"referenceID": 32, "context": "In order to compute the distributions in (9), we use the Bundle Delay Embedding Theorem [33] to reformulate the factorised distribution (denominator), and the Delay Embedding Theorem for Multivariate Observation Functions [57] for the joint distribution (numerator).", "startOffset": 88, "endOffset": 92}, {"referenceID": 56, "context": "In order to compute the distributions in (9), we use the Bundle Delay Embedding Theorem [33] to reformulate the factorised distribution (denominator), and the Delay Embedding Theorem for Multivariate Observation Functions [57] for the joint distribution (numerator).", "startOffset": 222, "endOffset": 226}, {"referenceID": 2, "context": "[3]).", "startOffset": 0, "endOffset": 3}, {"referenceID": 56, "context": "For convenience, Lemma 2 restates part of the delay embedding theorem in [57] in terms of subsystems of a synchronous GDS and establishes existence of a map G for predicting future observations from a history of observations.", "startOffset": 73, "endOffset": 77}, {"referenceID": 56, "context": "[57] in terms of subsystems.", "startOffset": 0, "endOffset": 4}, {"referenceID": 56, "context": "where \u03c4 i is the lag, \u03ba is the embedding dimension of the ith subsystem, and \u2211 i \u03ba i = 2d+ 1 [57].", "startOffset": 93, "endOffset": 97}, {"referenceID": 3, "context": "Transfer entropy detects the directed exchange of information between random processes by marginalising out common history and static correlations between variables; it is thus considered a measure of information transfer within a system [4].", "startOffset": 238, "endOffset": 241}, {"referenceID": 16, "context": "The collective transfer entropy computes the information transfer between a set of M source processes and a single destination process [17].", "startOffset": 135, "endOffset": 139}, {"referenceID": 15, "context": "Stochastic interaction measures the complexity of dynamical systems by quantifying the excess of information processed, in time, by the system beyond the information processed by each of the nodes [16, 58, 59].", "startOffset": 197, "endOffset": 209}, {"referenceID": 57, "context": "Stochastic interaction measures the complexity of dynamical systems by quantifying the excess of information processed, in time, by the system beyond the information processed by each of the nodes [16, 58, 59].", "startOffset": 197, "endOffset": 209}, {"referenceID": 58, "context": "Stochastic interaction measures the complexity of dynamical systems by quantifying the excess of information processed, in time, by the system beyond the information processed by each of the nodes [16, 58, 59].", "startOffset": 197, "endOffset": 209}, {"referenceID": 15, "context": "Note that the original definition assumed a first-order Markov process [16], and here we have extended stochastic interaction to arbitrary \u03ba-order Markov chains.", "startOffset": 71, "endOffset": 75}, {"referenceID": 14, "context": "A common method to derive a score is to minimise the KL divergence between graph and empirical distributions [15, 60].", "startOffset": 109, "endOffset": 117}, {"referenceID": 59, "context": "A common method to derive a score is to minimise the KL divergence between graph and empirical distributions [15, 60].", "startOffset": 109, "endOffset": 117}, {"referenceID": 49, "context": "Here, we draw on the result of de Campos [50], who derived a scoring function for BN structure learning based on conditional mutual information and statistical significance tests, called MIT (mutual information tests).", "startOffset": 41, "endOffset": 45}, {"referenceID": 60, "context": "1b was computed via a kernal box method (computed by the JIDT, see [61] for details).", "startOffset": 67, "endOffset": 71}, {"referenceID": 61, "context": "Fortunately, in the case of discrete and linear-Gaussian systems, the distribution 2NT\u3008Y \u3009j\u2192Y i is known to asymptotically approach the \u03c7-distribution [62].", "startOffset": 151, "endOffset": 155}, {"referenceID": 60, "context": "We can derive a more general form of the TEA score (32) via surrogate measurements T\u3008Y \u3009j\u2192Y i under the assumption of H0 [61].", "startOffset": 121, "endOffset": 125}, {"referenceID": 18, "context": "This same technique has been used by Lizier and Rubinov [19] to derive a greedy structure learning algorithm for effective network analysis.", "startOffset": 56, "endOffset": 60}, {"referenceID": 22, "context": "We can alternatively limit the number of surrogates Ns to d\u03b1/(1 \u2212 \u03b1)e and take the maximum as T\u03b1,si [23], however taking a larger number of surrogate Ns will improve the validity of the distribution T (s).", "startOffset": 100, "endOffset": 104}, {"referenceID": 21, "context": "It is therefore common to employ local search methods such as greedy hill climbing, basin flooding and tabu search [22].", "startOffset": 115, "endOffset": 119}, {"referenceID": 49, "context": "g(V ,\u03a0G(V ) : D) = g(V ,\u03a0G(V ) : N V ,\u03a0G(V i)), where N V ,\u03a0G(V i) are sufficient statistics for the set of variables V i \u222a\u03a0G(V ) in D [50].", "startOffset": 135, "endOffset": 139}, {"referenceID": 49, "context": "This approach is more efficient as it allows for caching the results of \u03c7\u03b1,{lij}j incrementally [50].", "startOffset": 96, "endOffset": 100}, {"referenceID": 49, "context": "This issue can be resolved by penalising the score conservatively by using the maximum permutation of the \u03c7\u03b1,{lij}j value; an in-depth explanation of this approach can be found in de Campos\u2019 [50] discussion of the maximum penalty permutation (Theorem 2) and Shur-concavity (Theorem 3) of the penalty term.", "startOffset": 191, "endOffset": 195}, {"referenceID": 10, "context": "Score-equivalence in BN structure learning simplifies the evaluation and identification problems by constraining the search space to a set of essential graphs, which is a set of equivalence classes over DAGs [11].", "startOffset": 208, "endOffset": 212}, {"referenceID": 49, "context": "Because TEA and TEE are specific cases of the MIT score [50], they are not scoreequivalent.", "startOffset": 56, "endOffset": 60}, {"referenceID": 62, "context": "However, they do satisfy the less demanding property of equivalence in the space of restricted partially directed acyclic graphs (RPDAGs) [63].", "startOffset": 138, "endOffset": 142}, {"referenceID": 62, "context": "With a decomposable scoring function, searching in the space of RPDAGs is more efficient than searching through essential graphs, and has been shown to yield better local optima than other local search techniques in practice [63].", "startOffset": 225, "endOffset": 229}, {"referenceID": 49, "context": "De Campos [50] showed previously that the KL", "startOffset": 10, "endOffset": 14}, {"referenceID": 63, "context": "divergence in a fully observable system is given by the difference between multi-information [64] and mutual information.", "startOffset": 93, "endOffset": 97}, {"referenceID": 56, "context": "4 Specifically, a condition for generalised Takens\u2019 theorems to hold is that the observation functions {\u03c8} are injective [57, 33].", "startOffset": 121, "endOffset": 129}, {"referenceID": 32, "context": "4 Specifically, a condition for generalised Takens\u2019 theorems to hold is that the observation functions {\u03c8} are injective [57, 33].", "startOffset": 121, "endOffset": 129}, {"referenceID": 33, "context": "For example, the notion of equivalence classes in BN structure learning should lend some insight into the area of effective network analysis [34, 35].", "startOffset": 141, "endOffset": 149}, {"referenceID": 34, "context": "For example, the notion of equivalence classes in BN structure learning should lend some insight into the area of effective network analysis [34, 35].", "startOffset": 141, "endOffset": 149}, {"referenceID": 49, "context": "We have presented the TEA (32) and TEE (33) scores above based on the MIT scoring function [50].", "startOffset": 91, "endOffset": 95}, {"referenceID": 64, "context": "There are numerous approaches to recover the time delay \u03c4 and embedding dimension \u03ba for use in transfer entropy [65, 66].", "startOffset": 112, "endOffset": 120}, {"referenceID": 65, "context": "There are numerous approaches to recover the time delay \u03c4 and embedding dimension \u03ba for use in transfer entropy [65, 66].", "startOffset": 112, "endOffset": 120}, {"referenceID": 31, "context": "In Takens seminal work on turbulent flow [32], he proposed a map \u03a6f,\u03c8 :M\u2192 R, that is composed of delayed observations, can be used to reconstruct the dynamics for typical (f, \u03c8).", "startOffset": 41, "endOffset": 45}, {"referenceID": 31, "context": "Theorem 5 (Delay Embedding Theorem for Diffeomorphisms [32]).", "startOffset": 55, "endOffset": 59}, {"referenceID": 32, "context": "An important consequence of this result is that we can define a map F = \u03a6f,\u03c8 \u25e6 f \u25e6 \u03a6\u22121 f,\u03c8 on \u03a6f,\u03c8, such that y (\u03ba) n+1 = F(y (\u03ba) n ) [33].", "startOffset": 134, "endOffset": 138}, {"referenceID": 49, "context": "The set of periodic points A of Although it is not derived in [50], it is trivial to show the first two terms constitute multi-information.", "startOffset": 62, "endOffset": 66}, {"referenceID": 66, "context": "Theorem 6 (Delay Embedding Theorem for Endomorphisms [67]).", "startOffset": 53, "endOffset": 57}, {"referenceID": 66, "context": "As a result of Theorem 6, a sequence of \u03ba successive measurements from a system determines the system state at the end of the sequence of measurements [67].", "startOffset": 151, "endOffset": 155}, {"referenceID": 8, "context": "However, encouraging empirical results in [9] support the conjecture that they can both be generalised to the case of endomorphisms by taking a negative time delay, as is done in Theorem 6 above.", "startOffset": 42, "endOffset": 45}, {"referenceID": 32, "context": "[33] and deals with a skew-product system.", "startOffset": 0, "endOffset": 4}, {"referenceID": 32, "context": "Theorem 7 (Bundle Delay Embedding Theorem [33]).", "startOffset": 42, "endOffset": 46}, {"referenceID": 6, "context": "Recently, Sugihara and Deyle [7] showed that multivariate mappings also form an embedding, with minor changes to the technical assumptions underlying Takens\u2019 original theorem.", "startOffset": 29, "endOffset": 32}, {"referenceID": 56, "context": "Theorem 8 (Delay Embedding Theorem for Multivariate Observation Functions [57]).", "startOffset": 74, "endOffset": 78}], "year": 2016, "abstractText": "In this work, we are interested in structure learning for a set of spatially distributed dynamical systems, where individual subsystems are coupled via latent variables and observed through a filter. We represent this model as a directed acyclic graph (DAG) that characterises the unidirectional coupling between subsystems. Standard approaches to structure learning are not applicable in this framework due to the hidden variables, however we can exploit the properties of certain dynamical systems to formulate exact methods based on state space reconstruction. We approach the problem by using reconstruction theorems to analytically derive a tractable expression for the KL-divergence of a candidate DAG from the observed dataset. We show this measure can be decomposed as a function of two informationtheoretic measures, transfer entropy and stochastic interaction. We then present two mathematically robust scoring functions based on transfer entropy and statistical independence tests. These results support the previously held conjecture that transfer entropy can be used to infer effective connectivity in complex networks.", "creator": "LaTeX with hyperref package"}}}