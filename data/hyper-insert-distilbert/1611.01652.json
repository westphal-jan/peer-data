{"id": "1611.01652", "review": {"conference": "arxiv", "VERSION": "v1", "DATE_OF_SUBMISSION": "5-Nov-2016", "title": "A Differentiable Physics Engine for Deep Learning in Robotics", "abstract": "currently one of them the most important fields in robotics is indeed the efficient optimization discipline of controllers. if currently, robots are treated as nearly a black box in this optimization elimination process, \u2013 which is the reason why derivative - autonomous free optimization solving methods such as evolutionary algorithms and or generic reinforcement learning protocols are now omnipresent. we propose presently an implementation of a modern physics engine, which has the innate ability to differentiate variable control parameters. this has been continuously implemented on basically both cpu and robot gpu. historically we usually show how nearly this speeds start up changing the optimization process, significantly even for quite small problems, and subsequently why it will someday scale better to bigger common problems. we explain furthermore why this is an alternative hybrid approach to deep circular q - space learning, for more using deep data learning in robotics. lastly, still we argue furthermore that this algorithm is precisely a big step for applied deep learning in neural robotics, known as it opens up new possibilities or to optimize autonomous robots, both in hardware and the software.", "histories": [["v1", "Sat, 5 Nov 2016 13:34:58 GMT  (2591kb,D)", "http://arxiv.org/abs/1611.01652v1", "International Conference on Learning Representations 2017"]], "COMMENTS": "International Conference on Learning Representations 2017", "reviews": [], "SUBJECTS": "cs.NE cs.AI cs.RO", "authors": ["jonas degrave", "michiel hermans", "joni dambre", "francis wyffels"], "accepted": false, "id": "1611.01652"}, "pdf": {"name": "1611.01652.pdf", "metadata": {"source": "CRF", "title": null, "authors": ["Jonas Degrave", "Michiel Hermans", "Joni Dambre"], "emails": ["Jonas.Degrave@UGent.be", "Joni.Dambre@UGent.be", "Francis.wyffels@UGent.be"], "sections": [{"heading": null, "text": "One of the most important fields in robotics is the optimization of controllers. Currently, robots are treated as a black box in this optimization process, which is the reason why derivative-free optimization methods such as evolutionary algorithms or reinforcement learning are omnipresent. We propose an implementation of a modern physics engine, which has the ability to differentiate control parameters. This has been implemented on both CPU and GPU. We show how this speeds up the optimization process, even for small problems, and why it will scale to bigger problems. We explain why this is an alternative approach to deep Q-learning, for using deep learning in robotics. Lastly, we argue that this is a big step for deep learning in robotics, as it opens up new possibilities to optimize robots, both in hardware and software."}, {"heading": "1 INTRODUCTION", "text": "In order to solve tasks efficiently, robots require an optimization of their control system. This optimization process can be done in automated testbeds, but typically these controllers are optimized in simulation. Common methods to optimize these controllers include particle swarms, reinforcement learning, genetic algorithms and evolutionary strategies. These are all derivative-free methods.\nHowever, deep learning has taught us that optimizing with a gradient is often faster and more efficient. This is especially true when there are a lot of parameters, as is common in deep learning. However, in these optimization processes the robot is almost exclusively treated as a non differentiable black box. The reason for this, is that the robot in hardware is not differentiable, nor are current physics engines able to provide the gradient of the robot models. The resulting need for derivativefree optimization approaches limits both the optimization speed and the number of parameters in the controllers.\nA recently popular approach is to use deep Q-learning, a reinforcement learning algorithm. This method requires a lot of evaluations in order to work and to learn the many parameters (Levine et al., 2016). Here, we suggest an alternative approach, by introducing a differentiable physics engine. This idea is not novel. It has been done before with spring-damper models in 2D and 3D (Hermans et al., 2014). This approach is also similar to adjoint optimisation, a method widely used in various applications such as thermodynamics (Jarny et al., 1991) and fluid dynamics (Iollo et al., 2001). However, modern engines to model robotics are based on different algorithms. The most commonly used ones are 3D rigid body engines, which rely on impulse-based velocity stepping methods (Erez et al., 2015). In this paper, we test whether these engines are also differentiable, and whether this gradient is computationally tractable.\n\u2217Former member, currently unaffiliated\nar X\niv :1\n61 1.\n01 65\n2v 1\n[ cs\n.N E\n] 5\nN ov\n2 01\n6"}, {"heading": "2 A 3D RIGID BODY ENGINE", "text": "The goal is to implement a modern 3D Rigid body engine, in which parameters can be differentiated with respect to the fitness a robot achieves in a simulation, such that these parameters can be optimized with methods based on gradient descent.\nThe most frequently used simulation tools for model-based robotics, such as PhysX, Bullet, Havok and ODE, go back to MathEngine (Erez et al., 2015). These tools are all 3D rigid body engines, where bodies have 6 degrees of freedom, and the relations between them are defined as constraints. These bodies exert impulses on each other, but their positions are constrainted, e.g. to prevent the bodies from penetrating each other. The velocities, positions and constraints of the rigid bodies define a linear complementarity problem (LCP) (Chappuis, 2013), which is then solved using a Gauss-Seidel projection (GSP) method (Jourdan et al., 1998). The solution of this problem are the new velocities of the bodies, which are then integrated by semi-implicit Euler integration to get the new positions (Stewart and Trinkle, 2000). This system is not always numerically stable, therefore the constraints are usually softened (Catto, 2009).\nWe implemented such an engine as a mathematical expression in Theano (Al-Rfou et al., 2016), a software library which does automatic evaluation and differentiation of expressions with a focus on deep learning. This library has allowed for efficient differentiation of remarkably complex functions before (Degrave et al., 2016). The resulting computational graph to evaluate this expression, is then compiled for both CPU and GPU. In order to be able to compile for GPU however, we had to limit our implementation to a restricted set of elementary operations. This has some drawbacks, such as a limited support for conditionals. This severely caps the range of implementable functions. However, since the gradient is determined automatically, the complexity of implementing the differentiation correctly is removed entirely.\nOne of these limitations, is that we need to implement our physics engine without branching, as this is not yet available in Theano for GPU. Therefore some sacrifices have to be made. For instance, our system only allows for contact constraints between different spheres or between spheres and the ground plane. Collision detection algorithms for cubes typically have a lot of branching (Mirtich, 1998). However, this sphere based approach can in principle be extended to any other shape (Hubbard, 1996). On the other hand, we did implement a rather accurate model of servo motors, with a gain, maximal torque and maximal velocity parameters.\nAnother design choice was to use rotation matrices rather than the more common quaternions for representing rotations. This means that the state of the object is bigger, but the operations required are matrix multiplications. This reduced the complexity of the graph. However, cumulative operations on a rotation matrix might move the matrix away from orthogonality. To correct for this, we renormalize our matrix with the update equation (Premerlani and Bizard, 2009):\nA\u2032 = 3A\u2212A \u25e6 (A \u00b7A)\n2 (1)\nThese design decisions are the most important aspects of difference with the frequently used simulation tools. In the following section, we will evaluate our physics simulator on a number of different problems. We take a look at the speed of computation, and the number of evaluations required before the parameters of are optimized."}, {"heading": "3 RESULTS", "text": ""}, {"heading": "3.1 THROWING A BALL", "text": "To test our engine, we implemented the model of a giant soccer ball in the physics engine, as shown in Fig. 1a. The ball has a 1m diameter, a friction of \u00b5 = 1.0 and restitution e = 0.5. The ball starts off at position (0, 0). After 5 s it should be at position (10, 0) with zero velocity v and zero angular velocity \u03c9. We optimized the initial velocity v0 and angular velocity \u03c90 at time t = 0 s until the errors at t = 5 s are less than 0.01m and 0.01m/s, respectively.\nSince the quantity we optimize is only know at the end of the simulation, but we need to optimize the parameters in the beginning of the simulation, we need to backpropagate our error through time\n(BPTT) (Sutskever, 2013). This is similar to the backpropagation through time method used for optimizing recurrent neural networks (RNN). In our case, every time step in the simulation can be seen as one pass through a neural network, which transforms the inputs from this timestep to inputs for the next time step. For finding the gradient, this RNN is unfolded completely, and the gradient can be found by differentiation this unfolded structure. This differentiation is done automatically by the Theano library.\nOptimizing the 6 parameters in v0 and \u03c90 took only 88 iterations with gradient descent and backpropagation through time. Optimizing this problem with CMA-ES (Hansen, 2006), a state of the art derivative-free optimization method, took 2422 iterations. Even when taking the time to compute the gradient into account, the optimization with gradient descent takes 16.3 s, compared to 59.9 s with CMA-ES. This shows that gradient based optimization of kinematic systems can in some cases already outperform general purpose optimization algorithms from as little as six parameters."}, {"heading": "3.2 QUADRUPEDAL ROBOT", "text": "To verify the speed of our engine, we also implemented a small quadrupedal robot model, as illustrated in Fig. 1b. This model has a total of 81 sensors, e.g. encoders and an inertial measurement unit (IMU). The servo motors are controlled in closed loop by a small neural network with a varying number of parameters, as shown in Fig. 1c. The gradient is the Jacobian of the total travelled distance of the robot in 10 s, differentiated with respect to all the parameters of the controller. This Jacobian is found by using BPTT and propagating all 10 s back. The time it takes to compute this travelled distance and the accompanying Jacobian is shown in Table 1. We include both the computation time with and without the gradient, i.e. both the forward and backward pass and the forwards pass alone. This way, the numbers can be compared to other physics engines, as they only calculate without gradient. Our implementation and our model can probably be made more efficient, and evaluating the gradient can probably be made faster a similar factor.\nWhen only a single controller is optimized, our engine runs more slowly on GPU than on CPU. In order to tackle this issue, we implemented batch gradient descent, which is commonly used in\ncomplex optimization problems. In this case, by batching our robot models, we achieve considerable acceleration on GPU. Although backpropagating the gradient through time slows down the computations by roughly a factor 10, this factor only barely increases with the number of parameters in our controller. Combining this with our previous observation that fewer iterations are needed when using gradient descent, our approach can enable the use of gradient descent through physics for highly complex deep learning controllers with millions of parameters. Also note that by using a batch method, a single GPU can simulate 864 000 model seconds per day. This should be plenty for deep learning. It also means that a single simulation step of a single robot, which includes collision detection, solving the LCP problem, integrating the velocities and backpropagating the gradient through it all, takes about 1ms on average. Without the backpropagation, this is only about seven times faster."}, {"heading": "3.3 4 DEGREE OF FREEDOM ROBOT ARM", "text": "As a first test of optimizing robot controllers, we implemented a four degree of freedom robotic arm, as depicted in Fig. 1c. The bottom of the robot has a 2 degrees of freedom actuated universal joint, the elbow has a 2 degree of freedom actuated joint as well. The arm is 1m long, and has a total mass of 32 kg. The servos have a gain of 30 s\u22121, a torque of 30Nm and a velocity of 45\u25e6 s\u22121.\nFor this robot arm, we train controllers for a task with a decreasing amount of difficulty. In order to be able to train our parameters, we have to use a couple of tricks often used in the training of recurrent neural networks.\n\u2022 We choose an objective which is evaluated at every time step and then averaged, rather than at specific points of the simulation. This vastly increases the amount of samples over which the gradient is averaged, which in turn makes the gradient direction more reliable (Sjo\u0308berg et al., 1995).\n\u2022 The value of the gradient is decreased by a factor \u03b1 < 1 at every time step. This has the effect of a prior: namely events further in the past are less important for influencing current events, because intermediate events might diminish their influence completely. This also improves robustness against exploding gradients (Hermans et al., 2014).\n\u2022 We initialize the controller intelligently. We do not want the controller to shake the actuators violently and explore outside the accurate domain of our simulation model, therefore controllers are initialized such that they only output zeros at the start of the simulation.\n\u2022 We constraint the size of the gradient to an L2-norm of 1. This makes sure that gradients close to discontinuities in the fitness landscape do not push the parameter values too far away, such that everything which was learnt is forgotten (Sutskever, 2013)."}, {"heading": "3.3.1 REACHING A FIXED POINT", "text": "A first simple task, is to have a small neural net controller learn to move the controller to a certain fixed point in space, at coordinates (0.5m; 0.5m; 0.5m). The objective we minimize for this task, is the distance between the end effector and the target point, averaged over the 8 seconds we simulate our model.\nWe provide the controller with a single sensor input, namely the current distance between the end effector and the target point. Input is not required for this task, as there are solutions for which the motor signals are constant in time. However, this would not necessarily be the optimal approach for minimizing the average distance over time, it only solves the distance at the end of the simulation, but does not minimize the distance during the trajectory to get at the final position.\nAs a controller, we use a dense neural network with 1 input, 2 hidden layers of 128 units with a rectifier activation function, and 4 outputs with an identity activation function. This controller has 17 284 parameters in total.\nWe use gradient descent with a batch size of 1 robot for optimization, as the problem is not stochastic in nature. The parameters are optimized with Adam\u2019s rule (Kingma and Ba, 2014) with a learning rate of 0.001. Every update step with this method takes about 5 seconds on CPU. We find that the controller comes within 4 cm of the target in 100 update steps, and within 1 cm in 150 update steps, which is quite small compared to the 1m arm of the robot. Moreover, the controller does find a more optimal trajectory which takes into account the sensor information. Solving problems like these, in less iteration steps than the number of parameters, is completely unfeasible with derivative free methods (Sjo\u0308berg et al., 1995).\nDespite that, we did try to optimize the same problem with CMA-ES. Note that the target volume is 500 000 times smaller than the reachable volume of the robot, therefore from a rough estimation about 1 in 500 000 random controllers should function. After 15 000 iterations, CMA-ES did not manage to lower the average error below the the error of randomly sampled controllers."}, {"heading": "3.3.2 REACHING A RANDOM POINT", "text": "As a second task, we sample a random target point in space, inside the cuboid between (1m; 1m; 1m) and (\u22121m;\u22121m; 0m), parallel to the axes. We give this point as input to the controller, and the task is to again minimize the average distance between the end effector and the target point.\nAs a controller, we use the same dense neural network as in the previous section, but this time with 3 inputs. This controller has 17 540 parameters in total. To train for this task, we use a batch size of 64 robots, such that every update step takes 52 s on GPU. Each simulation takes 8 s with a simulation step of 0.01 s, therefore the gradient on the parameters of the controllers are averaged over 51 200 timesteps at every update step.\nWe find that it takes 5 000 update steps before the 17 540 parameters are optimized, such that the robot has on average 10 cm accuracy. About half of the reachable space can be reached within 5 cm accuracy."}, {"heading": "3.4 OPTIMIZING A CONTROLLER FOR THE QUADRUPEDAL ROBOT \u2013 REVISITED", "text": "Optimizing a gait for a quadrupedal robot is a problem of a different order, something the authors have extensive experience with (Sproewitz et al., 2013; Degrave et al., 2013; 2015). The problem is way more difficult, and allows for a wide range of possible solutions. In nature, we find a wide range of gaits, from hopping over trotting, walking and galopping. With hand tuning, we were able to obtain a trotting gait on this robot model, with an average forward speed of 0.7m/s. We found it tricky to find a gait where the robot did not end up as an upside down turtle, as 75% of the mass of the robot is located in its spine.\nAs a controller for our quadrupedal robot, we use a neural network with 2 input signals, namely a sine and a cosine signal with a frequency of 1.5Hz. On top of this we added 2 hidden layers of 128 units and a rectifier activation function. As output layer, we have a dense layer with 8 units and a linear activation function, which has as input both the input layer and the top layer of the hidden\nlayers. In total, this controller has 17 952 parameters. Since the problem is not stochastic in nature, we use a batch size of 1 robot. We initialize the output layer with zero weights, so the robot starts the optimization in a stand still position.\nWe optimize these parameters to maximize the average velocity of the spine over the course of 10 s of time in simulation. This way, the gradient used in the update step is effectively an average of 1000 time steps after unrolling the recurrent connections. This objective does not take into account energy use, or other metrics normally used in robotic problems.\nIn only 500 iterations, or about 1 hour of optimizing on CPU, the optimization through BPTT comes up with a solution with a speed of 1.17m/s. This solution is a hopping gait, with a summersault every 3 steps, despite limiting the torque of the servos to 4Nm on this 28.7 kg robot. For more life-like gaits, energy use could be use as a regularization method. This is however outside of the scope of this paper."}, {"heading": "4 DISCUSSION", "text": "Our results show the first prototype of a differentiable physics engine based on similar algorithms as those that are commonly used in current robotics simulators. When originally addressing the problem, we had no idea whether finding the gradient would be computationally tractable, let alone whether evaluating it would be fast enough to be beneficial for optimization. We have now demonstrated that evaluating the gradient is expensive, but on a very manageable level. The speed of evaluating the gradient mainly depends on the complexity of the physics model and only slightly on the number of parameters to optimize. Our results therefore suggest that this cost can be dominated by the gain that can be achieved by the combination of using batch gradient descent and GPU acceleration. This is especially true when optimizing controllers with very high numbers of parameters, where we suspect this approach is asymptotically of a lower order in the number of parameters, as each gradient step also contains information proportional to the number of parameters.\nOptimizing the controller of a robot model with gradient based optimization is equivalent to optimizing a RNN. After all, the gradient passes through each parameter at every time step. The parameter space is therefore very noisy. Consequently, training the parameters of this controller is a highly non-trivial problem, as it corresponds to training the parameters of a RNN. On top of that, exploding and vanishing signals and gradients cause far more difficult problems compared to feed forward networks.\nIn section 3.3, we already discussed some of the tricks used for optimizing RNNs. Earlier research shows that these methods can be extended to even more difficult tasks than the ones discussed here (Hermans et al., 2014; Sutskever, 2013). We therefore believe that this approach towards learning controllers for robotics is applicable to far more complex problems than the simple examples tackled in this paper."}, {"heading": "5 FUTURE WORK", "text": "All of the results in this paper will of course largely depend on showing how these controllers will work on the physical counterparts of our models. Nonetheless, we would like to conjecture that to a certain extent, this gradient of a model is close to the gradient of the physical system. The gradient of the model is even more susceptible to high-frequency noise introduced by modeling the system, than the imaginary gradient of the system itself. Nonetheless, it contains information which might be indicative, even if it is not perfect. We would theorize that using this noisy gradient is still better than optimizing in the blind, and that the transferability to real robots can be improved by evaluating the gradients on batches of (slightly) different robots in (slightly) different situations and averaging the results. This technique was already applied in (Hermans et al., 2014) as a regularization technique to avoid bifurcations during online learning. If the previous proves to be correct, our approach can offer an alternative to deep Q-learning for deep learning controllers in robotics.\nWe can see the use of this extended approach for a wide range of applications in robotics:\n\u2022 By introducing recurrent connections in the neural network controller, it is possible to introduce memory in the controller as well. We reckon that advanced recurrent connections\nwith a memory made out of LSTM cells (Hochreiter and Schmidhuber, 1997) can allow for more powerful controllers than the controllers described in this paper. \u2022 Although we did not address this in this paper, there is no reason why only control param-\neters could be differentiated. Hardware parameters of the robot have been optimized the same way before (Jarny et al., 1991; Iollo et al., 2001; Hermans et al., 2014). \u2022 There is no reason why a camera model would not be differentiable either. We think that\ncurrently the only thing in the way to effectively learn deep robot controllers from camera information, is someone implementing a differentiable camera model. \u2022 Where adversarial networks are already showing their use in generating image models, we\nbelieve adversarial robotics training (ART) will create some imaginative ways to design and control robots. Like in generative adversarial nets (GAN) (Goodfellow et al., 2014), where the gradient is pulled through two competing neural networks, the gradient could be pulled through multiple competing robots as well."}, {"heading": "6 CONCLUSION", "text": "In this paper, we show it is possible to build a differentiable physics engine. We implemented a modern engine which can run a 3D rigid body model, using the same algorithm as other engines commonly used to simulate robots, but we can additionally differentiate control parameters with BPTT. Our implementation also runs on GPU, and we show that using GPUs to simulate the physics can speed up the process for large batches of robots.\nWe find that these gradients can be computed surprisingly fast. We also show that using gradient descent with BPTT speeds up optimization processes often found in robotics, even for rather small problems, due to the reduced number of model evaluations required. This improvement in speed will scale to problems with a lot of parameters. This method should therefore allow for a new way to apply deep learning methods in robotics."}, {"heading": "ACKNOWLEDGMENTS", "text": "Special thanks to Iryna Korshunova for valuable discussions and proofreading the paper. The research leading to these results has received funding from the Agency for Innovation by Science and Technology in Flanders (IWT). The GTX 1080 used for this research was donated by the NVIDIA Corporation."}], "references": [{"title": "Theano: A python framework for fast computation of mathematical expressions. arXiv preprint arXiv:1605.02688", "author": ["R. Al-Rfou", "G. Alain", "A. Almahairi", "C. Angermueller", "D. Bahdanau", "N. Ballas", "F. Bastien", "J. Bayer", "A Belikov"], "venue": null, "citeRegEx": "Al.Rfou et al\\.,? \\Q2016\\E", "shortCiteRegEx": "Al.Rfou et al\\.", "year": 2016}, {"title": "Modeling and solving constraints", "author": ["E. Catto"], "venue": "In Game Developers Conference", "citeRegEx": "Catto,? \\Q2009\\E", "shortCiteRegEx": "Catto", "year": 2009}, {"title": "Constraints derivation for rigid body simulation in 3D", "author": ["D. Chappuis"], "venue": null, "citeRegEx": "Chappuis,? \\Q2013\\E", "shortCiteRegEx": "Chappuis", "year": 2013}, {"title": "Transfer learning of gaits on a quadrupedal robot", "author": ["J. Degrave", "M. Burm", "Kindermans", "P.-J", "J Dambre"], "venue": "Adaptive Behavior,", "citeRegEx": "Degrave et al\\.,? \\Q2015\\E", "shortCiteRegEx": "Degrave et al\\.", "year": 2015}, {"title": "Comparing trotting and turning strategies on the quadrupedal oncilla robot", "author": ["J. Degrave", "M. Burm", "T. Waegeman", "F. Wyffels", "B. Schrauwen"], "venue": "In Robotics and Biomimetics (ROBIO),", "citeRegEx": "Degrave et al\\.,? \\Q2013\\E", "shortCiteRegEx": "Degrave et al\\.", "year": 2013}, {"title": "Spatial chirp-Z transformer networks", "author": ["J. Degrave", "S. Dieleman", "J Dambre"], "venue": "In European Symposium on Artificial Neural Networks (ESANN)", "citeRegEx": "Degrave et al\\.,? \\Q2016\\E", "shortCiteRegEx": "Degrave et al\\.", "year": 2016}, {"title": "Simulation tools for model-based robotics: Comparison of bullet, havok, mujoco, ode and physx", "author": ["T. Erez", "Y. Tassa", "E. Todorov"], "venue": "In International Conference on Robotics and Automation (ICRA),", "citeRegEx": "Erez et al\\.,? \\Q2015\\E", "shortCiteRegEx": "Erez et al\\.", "year": 2015}, {"title": "Generative adversarial nets", "author": ["I. Goodfellow", "J. Pouget-Abadie", "M. Mirza", "B. Xu", "D. Warde-Farley", "S. Ozair", "A. Courville", "Y. Bengio"], "venue": "In Advances in Neural Information Processing Systems,", "citeRegEx": "Goodfellow et al\\.,? \\Q2014\\E", "shortCiteRegEx": "Goodfellow et al\\.", "year": 2014}, {"title": "The cma evolution strategy: a comparing review", "author": ["N. Hansen"], "venue": null, "citeRegEx": "Hansen,? \\Q2006\\E", "shortCiteRegEx": "Hansen", "year": 2006}, {"title": "Automated design of complex dynamic systems", "author": ["M. Hermans", "B. Schrauwen", "P. Bienstman", "J. Dambre"], "venue": "PloS one,", "citeRegEx": "Hermans et al\\.,? \\Q2014\\E", "shortCiteRegEx": "Hermans et al\\.", "year": 2014}, {"title": "Long short-term memory", "author": ["S. Hochreiter", "J. Schmidhuber"], "venue": "Neural computation,", "citeRegEx": "Hochreiter and Schmidhuber,? \\Q1997\\E", "shortCiteRegEx": "Hochreiter and Schmidhuber", "year": 1997}, {"title": "Approximating polyhedra with spheres for time-critical collision detection", "author": ["P.M. Hubbard"], "venue": "ACM Transactions on Graphics (TOG),", "citeRegEx": "Hubbard,? \\Q1996\\E", "shortCiteRegEx": "Hubbard", "year": 1996}, {"title": "An aerodynamic optimization method based on the inverse problem adjoint equations", "author": ["A. Iollo", "M. Ferlauto", "L. Zannetti"], "venue": "Journal of Computational Physics,", "citeRegEx": "Iollo et al\\.,? \\Q2001\\E", "shortCiteRegEx": "Iollo et al\\.", "year": 2001}, {"title": "A general optimization method using adjoint equation for solving multidimensional inverse heat conduction", "author": ["Y. Jarny", "M. Ozisik", "J. Bardon"], "venue": "International journal of heat and mass transfer,", "citeRegEx": "Jarny et al\\.,? \\Q1991\\E", "shortCiteRegEx": "Jarny et al\\.", "year": 1991}, {"title": "A gauss-seidel like algorithm to solve frictional contact problems. Computer methods in applied mechanics and engineering, 155(1):31\u201347", "author": ["F. Jourdan", "P. Alart", "M. Jean"], "venue": null, "citeRegEx": "Jourdan et al\\.,? \\Q1998\\E", "shortCiteRegEx": "Jourdan et al\\.", "year": 1998}, {"title": "Adam: A method for stochastic optimization", "author": ["D.P. Kingma", "J. Ba"], "venue": "Proceedings of the 3rd International Conference on Learning Representations (ICLR)", "citeRegEx": "Kingma and Ba,? \\Q2014\\E", "shortCiteRegEx": "Kingma and Ba", "year": 2014}, {"title": "Learning hand-eye coordination for robotic grasping with deep learning and large-scale data collection", "author": ["S. Levine", "P. Pastor", "A. Krizhevsky", "D. Quillen"], "venue": "arXiv preprint arXiv:1603.02199", "citeRegEx": "Levine et al\\.,? \\Q2016\\E", "shortCiteRegEx": "Levine et al\\.", "year": 2016}, {"title": "V-clip: Fast and robust polyhedral collision detection", "author": ["B. Mirtich"], "venue": "ACM Transactions On Graphics (TOG),", "citeRegEx": "Mirtich,? \\Q1998\\E", "shortCiteRegEx": "Mirtich", "year": 1998}, {"title": "Direction cosine matrix IMU: Theory", "author": ["W. Premerlani", "P. Bizard"], "venue": "DIY DRONE: USA,", "citeRegEx": "Premerlani and Bizard,? \\Q2009\\E", "shortCiteRegEx": "Premerlani and Bizard", "year": 2009}, {"title": "Nonlinear black-box modeling in system identification: a unified overview", "author": ["J. Sj\u00f6berg", "Q. Zhang", "L. Ljung", "A. Benveniste", "B. Delyon", "Glorennec", "P.-Y", "H. Hjalmarsson", "A. Juditsky"], "venue": null, "citeRegEx": "Sj\u00f6berg et al\\.,? \\Q1995\\E", "shortCiteRegEx": "Sj\u00f6berg et al\\.", "year": 1995}, {"title": "Towards dynamically running quadruped robots: performance, scaling, and comparison", "author": ["A. Sproewitz", "A. Tuleu", "M. D\u2019Haene", "R. M\u00f6ckel", "J. Degrave", "M. Vespignani", "S. Gay", "M. Ajallooeian", "B. Schrauwen", "A.J. Ijspeert"], "venue": "In Adaptive Motion of Animals and Machines,", "citeRegEx": "Sproewitz et al\\.,? \\Q2013\\E", "shortCiteRegEx": "Sproewitz et al\\.", "year": 2013}, {"title": "An implicit time-stepping scheme for rigid body dynamics with coulomb friction", "author": ["D. Stewart", "J.C. Trinkle"], "venue": "In International Conference on Robotics and Automation (ICRA),", "citeRegEx": "Stewart and Trinkle,? \\Q2000\\E", "shortCiteRegEx": "Stewart and Trinkle", "year": 2000}, {"title": "Training recurrent neural networks", "author": ["I. Sutskever"], "venue": "PhD thesis,", "citeRegEx": "Sutskever,? \\Q2013\\E", "shortCiteRegEx": "Sutskever", "year": 2013}], "referenceMentions": [{"referenceID": 16, "context": "This method requires a lot of evaluations in order to work and to learn the many parameters (Levine et al., 2016).", "startOffset": 92, "endOffset": 113}, {"referenceID": 9, "context": "It has been done before with spring-damper models in 2D and 3D (Hermans et al., 2014).", "startOffset": 63, "endOffset": 85}, {"referenceID": 13, "context": "This approach is also similar to adjoint optimisation, a method widely used in various applications such as thermodynamics (Jarny et al., 1991) and fluid dynamics (Iollo et al.", "startOffset": 123, "endOffset": 143}, {"referenceID": 12, "context": ", 1991) and fluid dynamics (Iollo et al., 2001).", "startOffset": 27, "endOffset": 47}, {"referenceID": 6, "context": "The most commonly used ones are 3D rigid body engines, which rely on impulse-based velocity stepping methods (Erez et al., 2015).", "startOffset": 109, "endOffset": 128}, {"referenceID": 6, "context": "The most frequently used simulation tools for model-based robotics, such as PhysX, Bullet, Havok and ODE, go back to MathEngine (Erez et al., 2015).", "startOffset": 128, "endOffset": 147}, {"referenceID": 2, "context": "The velocities, positions and constraints of the rigid bodies define a linear complementarity problem (LCP) (Chappuis, 2013), which is then solved using a Gauss-Seidel projection (GSP) method (Jourdan et al.", "startOffset": 108, "endOffset": 124}, {"referenceID": 14, "context": "The velocities, positions and constraints of the rigid bodies define a linear complementarity problem (LCP) (Chappuis, 2013), which is then solved using a Gauss-Seidel projection (GSP) method (Jourdan et al., 1998).", "startOffset": 192, "endOffset": 214}, {"referenceID": 21, "context": "The solution of this problem are the new velocities of the bodies, which are then integrated by semi-implicit Euler integration to get the new positions (Stewart and Trinkle, 2000).", "startOffset": 153, "endOffset": 180}, {"referenceID": 1, "context": "This system is not always numerically stable, therefore the constraints are usually softened (Catto, 2009).", "startOffset": 93, "endOffset": 106}, {"referenceID": 0, "context": "We implemented such an engine as a mathematical expression in Theano (Al-Rfou et al., 2016), a software library which does automatic evaluation and differentiation of expressions with a focus on deep learning.", "startOffset": 69, "endOffset": 91}, {"referenceID": 5, "context": "This library has allowed for efficient differentiation of remarkably complex functions before (Degrave et al., 2016).", "startOffset": 94, "endOffset": 116}, {"referenceID": 17, "context": "Collision detection algorithms for cubes typically have a lot of branching (Mirtich, 1998).", "startOffset": 75, "endOffset": 90}, {"referenceID": 11, "context": "However, this sphere based approach can in principle be extended to any other shape (Hubbard, 1996).", "startOffset": 84, "endOffset": 99}, {"referenceID": 18, "context": "To correct for this, we renormalize our matrix with the update equation (Premerlani and Bizard, 2009):", "startOffset": 72, "endOffset": 101}, {"referenceID": 22, "context": "(BPTT) (Sutskever, 2013).", "startOffset": 7, "endOffset": 24}, {"referenceID": 8, "context": "Optimizing this problem with CMA-ES (Hansen, 2006), a state of the art derivative-free optimization method, took 2422 iterations.", "startOffset": 36, "endOffset": 50}, {"referenceID": 19, "context": "This vastly increases the amount of samples over which the gradient is averaged, which in turn makes the gradient direction more reliable (Sj\u00f6berg et al., 1995).", "startOffset": 138, "endOffset": 160}, {"referenceID": 9, "context": "This also improves robustness against exploding gradients (Hermans et al., 2014).", "startOffset": 58, "endOffset": 80}, {"referenceID": 22, "context": "This makes sure that gradients close to discontinuities in the fitness landscape do not push the parameter values too far away, such that everything which was learnt is forgotten (Sutskever, 2013).", "startOffset": 179, "endOffset": 196}, {"referenceID": 15, "context": "The parameters are optimized with Adam\u2019s rule (Kingma and Ba, 2014) with a learning rate of 0.", "startOffset": 46, "endOffset": 67}, {"referenceID": 19, "context": "Solving problems like these, in less iteration steps than the number of parameters, is completely unfeasible with derivative free methods (Sj\u00f6berg et al., 1995).", "startOffset": 138, "endOffset": 160}, {"referenceID": 20, "context": "Optimizing a gait for a quadrupedal robot is a problem of a different order, something the authors have extensive experience with (Sproewitz et al., 2013; Degrave et al., 2013; 2015).", "startOffset": 130, "endOffset": 182}, {"referenceID": 4, "context": "Optimizing a gait for a quadrupedal robot is a problem of a different order, something the authors have extensive experience with (Sproewitz et al., 2013; Degrave et al., 2013; 2015).", "startOffset": 130, "endOffset": 182}, {"referenceID": 9, "context": "Earlier research shows that these methods can be extended to even more difficult tasks than the ones discussed here (Hermans et al., 2014; Sutskever, 2013).", "startOffset": 116, "endOffset": 155}, {"referenceID": 22, "context": "Earlier research shows that these methods can be extended to even more difficult tasks than the ones discussed here (Hermans et al., 2014; Sutskever, 2013).", "startOffset": 116, "endOffset": 155}, {"referenceID": 9, "context": "This technique was already applied in (Hermans et al., 2014) as a regularization technique to avoid bifurcations during online learning.", "startOffset": 38, "endOffset": 60}, {"referenceID": 10, "context": "with a memory made out of LSTM cells (Hochreiter and Schmidhuber, 1997) can allow for more powerful controllers than the controllers described in this paper.", "startOffset": 37, "endOffset": 71}, {"referenceID": 13, "context": "Hardware parameters of the robot have been optimized the same way before (Jarny et al., 1991; Iollo et al., 2001; Hermans et al., 2014).", "startOffset": 73, "endOffset": 135}, {"referenceID": 12, "context": "Hardware parameters of the robot have been optimized the same way before (Jarny et al., 1991; Iollo et al., 2001; Hermans et al., 2014).", "startOffset": 73, "endOffset": 135}, {"referenceID": 9, "context": "Hardware parameters of the robot have been optimized the same way before (Jarny et al., 1991; Iollo et al., 2001; Hermans et al., 2014).", "startOffset": 73, "endOffset": 135}, {"referenceID": 7, "context": "Like in generative adversarial nets (GAN) (Goodfellow et al., 2014), where the gradient is pulled through two competing neural networks, the gradient could be pulled through multiple competing robots as well.", "startOffset": 42, "endOffset": 67}], "year": 2016, "abstractText": "One of the most important fields in robotics is the optimization of controllers. Currently, robots are treated as a black box in this optimization process, which is the reason why derivative-free optimization methods such as evolutionary algorithms or reinforcement learning are omnipresent. We propose an implementation of a modern physics engine, which has the ability to differentiate control parameters. This has been implemented on both CPU and GPU. We show how this speeds up the optimization process, even for small problems, and why it will scale to bigger problems. We explain why this is an alternative approach to deep Q-learning, for using deep learning in robotics. Lastly, we argue that this is a big step for deep learning in robotics, as it opens up new possibilities to optimize robots, both in hardware and software.", "creator": "LaTeX with hyperref package"}}}