{"id": "1611.02027", "review": {"conference": "arxiv", "VERSION": "v1", "DATE_OF_SUBMISSION": "7-Nov-2016", "title": ":telephone::person::sailboat::whale::okhand:; or \"Call me Ishmael\" - How do you translate emoji?", "abstract": "we report on an elementary exploratory analysis of language emoji usage dick, investigating a broader project that leverages numerical crowdsourcing to translate frederick melville's textbook moby dick into consonant emoji. this distinctive use factor of emoji removes weak textual context, and leads them to a varying vowel translation quality. also in this paper, we use our statistical word alignment mapping and part - of - speech tagging to explore how elderly people use emoji. [ despite of these simple compression methods, we initially observed consonant differences significantly in token intervals and part - time of - whisper speech distributions. another experiments obtained also partially suggest that semantics quo are preserved in defining the translation, confirmation and spoken repetition consistency is more easily common in translated emoji.", "histories": [["v1", "Mon, 7 Nov 2016 12:51:22 GMT  (254kb,D)", "http://arxiv.org/abs/1611.02027v1", null]], "reviews": [], "SUBJECTS": "cs.CL", "authors": ["will radford", "andrew chisholm", "ben hachey", "bo han"], "accepted": false, "id": "1611.02027"}, "pdf": {"name": "1611.02027.pdf", "metadata": {"source": "CRF", "title": "; or \u201cCall me Ishmael\u201d \u2013 How do you translate emoji?", "authors": ["Will Radford", "Andrew Chisholm", "Ben Hachey", "Bo Han"], "emails": ["(wradford@hugo.ai", "achisholm@hugo.ai", "bhachey@hugo.ai", "bhan)@hugo.ai"], "sections": [{"heading": "1 Introduction", "text": "Emoji are pictographic characters commonly used in informal written communication, originally in SMS messages, but increasingly in all social media. Emoji represents a range of faces, animals, weather, emotions and activities, compensating for a lack of verbal and non-verbal cues in faceto-face communication (Davis and Edberg, 2016; Dresner and Herring, 2010). Widespread support for emoji input on desktops and mobile devices has led to a rapid adoption of emoji as a communication tool and a part of popular culture, spawning a Word of the Year in 2015 (Oxford Dictionaries, 2015) and, somewhat dubiously, a feature film slated for a 2017 release (IMDb, 2016). Davis and Edberg (2016) also suggest that the limited coverage and a lack of formal grammar in emoji lead to multiple ambiguous messages, and point out the playful aspect of composing and decoding emoji. At its tersest, this can result in a film plot encoded into a single tweet (MacLachlan, 2016): \u201c . . . . . . #dune\u201d. Despite heavy constraints of its form, emoji are used in some surprising linguistic contexts that merit further study.\nMost analysis of emoji considers its usual context amongst regular text, focusing on geographic preferences (Swiftkey, 2015; Ljubes\u030cic\u0301 and Fis\u030cer, 2016), single-word translations (Dimson, 2015) and sentiment (Kralj Novak et al., 2015). Other work has focused on emoticons (e.g. \u201c:)\u201d), uncovering stylistic variation (Schnoebelen, 2012) and demographic factors associated with usage (Hovy et al., 2015). Different types of ambiguity have also been identified: subjective interpretations of symbols, as well as different renderings of what should be the same symbol (Miller et al., 2016). Mitchell et al. (2015) observe that emoji are less likely to occur in the language of schizophrenics, possibly related to a \u201cflat affect\u201d symptom of the mental disorder.\nThis paper analyses a specific instance where emoji have been used in a context usually reserved for fully-fledged languages. Emoji Dick (Benenson, 2010) is a fascinating project that used Amazon Mechanical Turk to translate the novel \u201cMoby-Dick; or, The Whale\u201d (Melville, 1851) into emoji (e.g. Figure 1). Three turkers were paid $0.05 to translate each sentence, and a second round of turkers paid $0.02 to vote for the best translation. Funded entirely by donations through the crowdsourcing platform Kickstarter, soft- and hard-bound copies are available for sale. The idiosyncratic nature of the task raises several key questions: how does one translate a work from the English literary canon into emojis? And, what can statistical analysis techniques from natural language processing tell us about it? ar X iv :1\n61 1.\n02 02\n7v 1\n[ cs\n.C L\n] 7\nN ov\n2 01\n6"}, {"heading": "2 Corpus Analysis", "text": "The dataset contains 9,971 pairs of text and emoji translations. We tokenise the text using the default tokeniser from NLTK (Bird et al., 2009). Digits and stopwords are removed and all tokens are lowercased.\nThe descriptive statistics of the two corpora, TEXT and EMOJI, show a few differences. TEXT has a larger and sparser vocabulary than EMOJI when constructing sentences. There are 207,194 text tokens (16,454 types) and 93,342 emoji tokens (470 types). Furthermore, emoji sentences are roughly half the length of textual sentences with respective means of 9.4 to 20.8. Figure 2 plots the log-counts of two corpora token or emoji frequencies against their ranks. As is common in Zipfian distributions, the TEXT frequencies quickly reduce with rank, but EMOJI has a heavier tail and no approach to low frequencies.\nTable 1 shows the 20 most common tokens and emoji. Unsurprisingly, \u201cwhale\u201d is the most common non-stopword token, while other thematic tokens (e.g. \u201cman\u201d, \u201cship\u201d, \u201csea\u201d, \u201cboat\u201d) and character names (e.g. \u201cahab\u201d, \u201ccaptain\u201d\u2019) are also common. The three most common emoji reference characters: people (e.g. ), and, of course, . Less obvious emoji include references to objects (e.g. ) and places (e.g. ), though not or as found in the common tokens. Symbols (e.g. ) are also present, as are other nonfacial body parts (e.g. )."}, {"heading": "3 Aligning emoji to tokens", "text": "The analysis above makes no attempt to characterise how TEXT was translated to EMOJI. To explore this, we learn an IBM translation model one\n(Brown et al., 1993) using NLTK\u2019s implementation with default parameters. We prepare the parallel text by removing English stopwords and punctuation and filtering pairs missing input or output, leaving 9,734 pairs. We opt for the simplest model with the fewest assumptions about the \u201clanguage pair\u201d, but with the caveat that it does not account well for token phrases aligning to a single emoji, as a phrase-based translation model might allow. We did explore some of the more advanced IBM models and sequence-to-sequence neural models (Sutskever et al., 2014), but these did not seem to yield readily-interpretable results. Recall that despite turkers vote for the best translations, the translations are expected to be extremely noisy, due to the high subjectivity of human emoji comprehension, and the scarcity of native speakers.\nHaving trained the model over 100 iterations, we examine the translation table and find the most probable alignment from token to emoji. Table 2 shows the top-20 emoji ranked by their strongest individual alignment with the tokens that they align to. The most commonly-aligned emoji, aligns to \u201cwhale\u201d, \u201csperm\u201d and \u201cwhales\u201d, as does\n. Rather less satisfying is the strong alignments of \u201cwhale\u201d to , and where a token aligned to\nnothing, showing the extent of the noise and the tendency of the model to align away tokens. Plural forms align well, as do synonyms (e.g. \u201cboat\u201d, \u201cship\u201d and \u201cboats\u201d align to ). Other alignments cover formal elements such as chapter headings ( ) and characters ( ), natural phenomena ( ), actions ( ) and sentiments ( ). Overall, most high-probability alignments seem reasonable, suggesting some consistency between translations."}, {"heading": "4 Emoji parts-of-speech", "text": "We apply the BookNLP pipeline (Bamman et al., 2014) to the original text, which predicts part-ofspeech (POS) tags, character clusters and many other linguistic metadata. Again, we expect this to be noisy, as the models are not adapted to 19th century literature. Nonetheless, we are able to create a distribution of noisy POS tags1 for each token, then induce a distribution of POS for each emoji, by applying the chain rule and alignment probabilities above. Most emoji are NN, with the highest probability . Only 5 emoji have a different majority POS prefix \u2013 VB \u2013 including (i.e. \u201csee\u201d or \u201cseen\u201d from Table 2). Although the low probabilities and compounded noise of the model mean the results are hardly compelling, it is interesting that some emoji seem to align more strongly to verbs, suggesting their consistent use as actions. This preponderence of NN and VB alignments supports the observation made elsewhere that emoji have features in common with pidgin languages (Rosefield, 2014; Stockton, 2015).\nAccumulating the POS probabilities for ac1We attempt to reduce noise by considering the only the\nfirst two characters of the POS tag. NNP and NNS as NN.\ntual occurrence of tokens or emojis, we are able to characterise the whole distribution. Figure 3 shows that emoji concentrate mass into fewer categories: NN, JJ, RB and VB."}, {"heading": "5 Modelling repeats in emoji", "text": "As emoji are often used to convey extra layers of emotion or context, we examine how emoji are repeated. Counting common bigrams of emoji, the most frequently emoji repeat-bigrams are followed by , and . The probability of repeat-bigrams is much higher in emoji at 3.2% as opposed to 0.4% in text, indicating that there is a\nsystematic difference in usage, although it is not clear whether they are used as intensifiers (\u201cvery strong\u201d) or counting mechanisms (\u201cmany boys\u201d)."}, {"heading": "6 Discussion", "text": "As intriguing as the dataset is, there are substantial challenges to working with it and drawing strong conclusions. Firstly, the setting is idiosyncratic and unlike standard current emoji usage, as it lacks the textual context in which emoji are usually found. Thus, findings in these contexts may not necessarily hold when applied to emoji found in informal discourse on the web. Indeed, a promising direction seems to be to learn embedding models that allow an elegant fusion of textual and emoji content (Barbieri et al., 2016; Eisner et al., 2016). The constraints of the limited vocabulary foster a creativity that, combined with the desire of the translator to produce a witty translation, only serves to increase the subjectivity of the dataset. This is exacerbated by the small size of the dataset, and while there are ordinal constraints in emoji (Schnoebelen, 2012), whether they hold for longer sequences is not clear.\nThe next issue to examine in future work is the failure of phrase-based translation models in this context, as this might uncover more interesting translations, as well as shed light on strange alignments (e.g. \u201cwhale\u201d to ). Data collection is also important, as lack of data could prohibit more sophisticated models. Moreover, collecting a dataset in a more natural context, such as chat or social message data, might lead to more immediatelyapplicable conclusions. Exploring whether there is strong evidence for a consistent interpretation of emoji repeats using analysis of the textual corpus would be interesting. Multi-lingual differences in emoji usage are compelling \u2013 do certain languages exhibit features that correlate with different emoji usage? Moreover, emoji may be a productive pivot upon which to align web-scale bitext, which may drive other semantic resources such as paraphrase databases (Ganitkevitch et al., 2013). The overarching direction of this work are to characterise broader temporal trends about how people use emoji, how a community of users settles on specific interpretations of emoji and, perhaps, uncover more evidence for or against the hypothesis that emoji is a pidgin."}, {"heading": "7 Conclusion", "text": "This paper presents a pilot study on how emoji are used in an unusual setting \u2013 verbatim translation. We use NLP techniques to compare the statistical properties of the two corpora (EMOJI and TEXT), showing that emoji operate in a far smaller space. Statistical alignment models from machine translation allow us to explore how translators mapped emoji onto tokens, including plural and synonymous forms. We also considered a noisily-induced POS distribution, showing that most emoji are nouns, with a few operating most frequently as verbs, and that the emoji POS distribution places weights on nouns and verbs, a phenomenon that bears some similarity to pidgins. Finally, we briefly explore how emoji are repeated, finding a much higher rate of repetition in emoji than text. Emoji offer a rare opportunity to study a rapidly evolving and increasingly important mode of communication that is complementary to text and speech and has parallels to human languages like pidgins."}, {"heading": "Acknowledgments", "text": "Many thanks to Fred Benenson and Chris Mulligan for having the wit to create the project and share the data . Thanks also to the reviewers and readers at Hugo.ai for their insightful comments ."}], "references": [{"title": "A bayesian mixed effects model of literary character", "author": ["Bamman et al.2014] David Bamman", "Ted Underwood", "Noah A. Smith"], "venue": "In Proceedings of the 52nd Annual Meeting of the Assoc. for Computational Linguistics", "citeRegEx": "Bamman et al\\.,? \\Q2014\\E", "shortCiteRegEx": "Bamman et al\\.", "year": 2014}, {"title": "What does this emoji mean? a vector space skip-gram model for twitter emojis", "author": ["Francesco Ronzano", "Horacio Saggion"], "venue": "In Language Resources and Evaluation conference,", "citeRegEx": "Barbieri et al\\.,? \\Q2016\\E", "shortCiteRegEx": "Barbieri et al\\.", "year": 2016}, {"title": "The mathematics of statistical machine", "author": ["Brown et al.1993] Peter F. Brown", "Vincent J. Della Pietra", "Stephen A. Della Pietra", "Robert L. Mercer"], "venue": null, "citeRegEx": "Brown et al\\.,? \\Q1993\\E", "shortCiteRegEx": "Brown et al\\.", "year": 1993}, {"title": "Unicode technical report 51 - unicode emoji", "author": ["Davis", "Edberg2016] Mark Davis", "Peter Edberg"], "venue": null, "citeRegEx": "Davis et al\\.,? \\Q2016\\E", "shortCiteRegEx": "Davis et al\\.", "year": 2016}, {"title": "Functions of the non-verbal in cmc: Emoticons and illocutionary force", "author": ["Dresner", "Herring2010] Eli Dresner", "Susan C. Herring"], "venue": "Communication Theory,", "citeRegEx": "Dresner et al\\.,? \\Q2010\\E", "shortCiteRegEx": "Dresner et al\\.", "year": 2010}, {"title": "emoji2vec: Learning emoji representations from their description", "author": ["Eisner et al.2016] Ben Eisner", "Tim Rockt\u00e4schel", "Isabelle Augenstein", "Matko Bosnjak", "Sebastian Riedel"], "venue": "In Proceedings of The Fourth International Workshop on Natural", "citeRegEx": "Eisner et al\\.,? \\Q2016\\E", "shortCiteRegEx": "Eisner et al\\.", "year": 2016}, {"title": "PPDB: The paraphrase database", "author": ["Benjamin Van Durme", "Chris Callison-Burch"], "venue": "In Proceedings of NAACL-HLT,", "citeRegEx": "Ganitkevitch et al\\.,? \\Q2013\\E", "shortCiteRegEx": "Ganitkevitch et al\\.", "year": 2013}, {"title": "User review sites as a resource for large-scale sociolinguistic studies", "author": ["Hovy et al.2015] Dirk Hovy", "Anders Johannsen", "Anders S\u00f8gaard"], "venue": "In Proceedings of the 24th International Conference on World Wide Web, WWW", "citeRegEx": "Hovy et al\\.,? \\Q2015\\E", "shortCiteRegEx": "Hovy et al\\.", "year": 2015}, {"title": "Sentiment of emojis", "author": ["Jasmina Smailovi\u0107", "Borut Sluban", "Igor Mozeti\u010d"], "venue": "PLoS ONE,", "citeRegEx": "Novak et al\\.,? \\Q2015\\E", "shortCiteRegEx": "Novak et al\\.", "year": 2015}, {"title": "Tweet in response to \u201c@kyle maclachlan can you explain dune to me please", "author": ["Kyle MacLachlan"], "venue": "by lifeofkeira. https://twitter.com/Kyle_MacLachlan/", "citeRegEx": "MacLachlan.,? \\Q2016\\E", "shortCiteRegEx": "MacLachlan.", "year": 2016}, {"title": "blissfully happy\u201d or \u201cready to fight\u201d: Varying interpretations of emoji", "author": ["Jacob Thebault-Spieker", "Shuo Chang", "Isaac L. Johnson", "Loren G. Terveen", "Brent Hecht"], "venue": "In Proceedings of the Tenth International", "citeRegEx": "Miller et al\\.,? \\Q2016\\E", "shortCiteRegEx": "Miller et al\\.", "year": 2016}, {"title": "Quantifying the language of schizophrenia in social media", "author": ["Kristy Hollingshead", "Glen Coppersmith"], "venue": "In Proceedings of the 2nd Workshop on Computational Linguistics and Clinical Psychology:", "citeRegEx": "Mitchell et al\\.,? \\Q2015\\E", "shortCiteRegEx": "Mitchell et al\\.", "year": 2015}, {"title": "Do you smile with your nose? stylistic variation in twitter emoticons", "author": ["Tyler Schnoebelen"], "venue": "University of Pennsylvania Working Papers in Linguistics,", "citeRegEx": "Schnoebelen.,? \\Q2012\\E", "shortCiteRegEx": "Schnoebelen.", "year": 2012}, {"title": "Emoji\u2014trendy slang or a whole new language? https", "author": ["Nick Stockton"], "venue": null, "citeRegEx": "Stockton.,? \\Q2015\\E", "shortCiteRegEx": "Stockton.", "year": 2015}, {"title": "Sequence to sequence learning with neural networks", "author": ["Oriol Vinyals", "Quoc V. Le"], "venue": null, "citeRegEx": "Sutskever et al\\.,? \\Q2014\\E", "shortCiteRegEx": "Sutskever et al\\.", "year": 2014}], "referenceMentions": [{"referenceID": 9, "context": "At its tersest, this can result in a film plot encoded into a single tweet (MacLachlan, 2016): \u201c .", "startOffset": 75, "endOffset": 93}, {"referenceID": 12, "context": "\u201c:)\u201d), uncovering stylistic variation (Schnoebelen, 2012) and", "startOffset": 38, "endOffset": 57}, {"referenceID": 7, "context": "demographic factors associated with usage (Hovy et al., 2015).", "startOffset": 42, "endOffset": 61}, {"referenceID": 10, "context": "Different types of ambiguity have also been identified: subjective interpretations of symbols, as well as different renderings of what should be the same symbol (Miller et al., 2016).", "startOffset": 161, "endOffset": 182}, {"referenceID": 2, "context": "(Brown et al., 1993) using NLTK\u2019s implementation with default parameters.", "startOffset": 0, "endOffset": 20}, {"referenceID": 14, "context": "We did explore some of the more advanced IBM models and sequence-to-sequence neural models (Sutskever et al., 2014), but these did not seem to yield readily-interpretable results.", "startOffset": 91, "endOffset": 115}, {"referenceID": 0, "context": "We apply the BookNLP pipeline (Bamman et al., 2014) to the original text, which predicts part-ofspeech (POS) tags, character clusters and many", "startOffset": 30, "endOffset": 51}, {"referenceID": 13, "context": "ports the observation made elsewhere that emoji have features in common with pidgin languages (Rosefield, 2014; Stockton, 2015).", "startOffset": 94, "endOffset": 127}, {"referenceID": 1, "context": "Indeed, a promising direction seems to be to learn embedding models that allow an elegant fusion of textual and emoji content (Barbieri et al., 2016; Eisner et al., 2016).", "startOffset": 126, "endOffset": 170}, {"referenceID": 5, "context": "Indeed, a promising direction seems to be to learn embedding models that allow an elegant fusion of textual and emoji content (Barbieri et al., 2016; Eisner et al., 2016).", "startOffset": 126, "endOffset": 170}, {"referenceID": 12, "context": "This is exacerbated by the small size of the dataset, and while there are ordinal constraints in emoji (Schnoebelen, 2012), whether they hold for longer sequences is not clear.", "startOffset": 103, "endOffset": 122}, {"referenceID": 6, "context": "Multi-lingual differences in emoji usage are compelling \u2013 do certain languages exhibit features that correlate with different emoji usage? Moreover, emoji may be a productive pivot upon which to align web-scale bitext, which may drive other semantic resources such as paraphrase databases (Ganitkevitch et al., 2013).", "startOffset": 289, "endOffset": 316}], "year": 2016, "abstractText": "We report on an exploratory analysis of Emoji Dick, a project that leverages crowdsourcing to translate Melville\u2019s Moby Dick into emoji. This distinctive use of emoji removes textual context, and leads to a varying translation quality. In this paper, we use statistical word alignment and part-of-speech tagging to explore how people use emoji. Despite these simple methods, we observed differences in token and part-of-speech distributions. Experiments also suggest that semantics are preserved in the translation, and repetition is more common in emoji.", "creator": "LaTeX with hyperref package"}}}