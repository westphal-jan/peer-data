{"id": "1611.03279", "review": {"conference": "arxiv", "VERSION": "v1", "DATE_OF_SUBMISSION": "10-Nov-2016", "title": "Tracing metaphors in time through self-distance in vector spaces", "abstract": "from a diachronic corpus of constituent italian, physically we build thirteen consecutive vector spaces represented in time and use them physically to compare a term's collective cosine similarity to motif itself expressed in different historical time generation spans. we assume that a drop in measured similarity intensity might be mutually related exactly to the slow emergence of a metaphorical architectural sense at all a given time. similarity - correlation based observations below are matched properly to the actual year when a figurative meaning was documented digitally in a reference dictionary and accessed through thematic manual multiple inspection analyses of familiar corpus occurrences.", "histories": [["v1", "Thu, 10 Nov 2016 12:22:43 GMT  (136kb,D)", "http://arxiv.org/abs/1611.03279v1", "Proceedings of the Third Italian Conference on Computational Linguistics (CLIC 2016)"]], "COMMENTS": "Proceedings of the Third Italian Conference on Computational Linguistics (CLIC 2016)", "reviews": [], "SUBJECTS": "cs.CL", "authors": ["marco del tredici", "malvina nissim", "andrea zaninello"], "accepted": false, "id": "1611.03279"}, "pdf": {"name": "1611.03279.pdf", "metadata": {"source": "CRF", "title": "Tracing metaphors in time through self-distance in vector spaces", "authors": ["Marco Del Tredici", "Malvina Nissim", "Andrea Zaninello"], "emails": ["marcodeltredici@gmail.com", "m.nissim@rug.nl", "azaninello@zanichelli.it"], "sections": [{"heading": null, "text": "Italiano. Nel presente esperimento costruiamo spazi vettoriali progressivi nel tempo su un corpus diacronico dell\u2019italiano e calcoliamo la distanza di alcuni termini rispetto a loro stessi in differenti periodi. L\u2019ipotesi e\u0300 che un calo di similitudine possa essere indicativo dell\u2019acquisizione di un significato metaforico. Tale ipotesi e\u0300 valutata attraverso una risorsa lessicografica esterna e l\u2019annotazione manuale dei contesti dei termini nel corpus."}, {"heading": "1 Introduction", "text": "It is widely acknowledged that metaphors are pervasive in language use, and that their detection and interpretation are crucial to language processing (Group, 2007; Turney et al., 2011; Shutova, 2015).\nOne tricky aspect related to metaphors is their dynamic nature: new metaphors are created all the time. For example, in recent years the Italian term \u201ctalebano\u201d (\u2018Taliban\u2019), previously only used to refer to the Islamic fundamentalist political movement founded in the Nineties in Afghanistan (Example 1), has come to define more generally someone who is extreme in his or her positions, for\nexample regarding food, use of medicines, and the like (Example 2).1\n(1) (lit.) l\u2019operazione [...] ha permesso di arrestare un talebano esperto in esplosivi\n(2) (fig.) [...] senza l\u2019atteso top player, e di un allenatore talebano della tattica\nIf the metaphorical meaning becomes commonly used, it might get recorded in reference dictionaries, too. Indeed, for the case of \u201ctalebano\u201d the Italian dictionary Zingarelli (Zingarelli, 1993\u20132017) has recorded the metaphorical extension (\u201cche (o chi) e\u0300 dogmatico, integralista\u201d) in the year 2009, while until then only the literal meaning was included.\nMost of the computational work on metaphors has focused on their identification and interpretation using a variety of techniques and models, such as clustering (Shutova and Sun, 2013), LDA topic modeling (Heintz et al., 2013), tree kernels (Hovy et al., 2013), but all from a purely synchronic perspective.2 The way metaphors develop across time, instead, and whether the shift of a word\u2019s literal meaning to a figurative one can be automatically detected and modelled is as of now a little investigated aspect.\nAs a contribution in this sense, we build on the basic observation that if a metaphorical meaning is acquired by a term at a certain point in time, the context of use of that term will, at least partially, change. In this paper we offer a proof of concept of this assumption, based on a selection of terms. (Dis)similarity of contexts is measured relying on the distributional semantics approach, and thus on the terms\u2019 vector representations, and the existence of a metaphoric shift is derived from the Zingarelli dictionary of Italian.\n1All of the examples in this paper are from the newspaper la Repubblica, see Section 4.2.\n2For a detailed survey on current NLP systems for metaphor modeling see (Shutova, 2015).\nar X\niv :1\n61 1.\n03 27\n9v 1\n[ cs\n.C L\n] 1\n0 N\nov 2\n01 6"}, {"heading": "2 Approach", "text": "According to the principle of distributional semantics, the meaning of a word is represented by vectors that encode the contextual information of that word in a corpus (Turney et al., 2010). All vectors representing words are included in a distributional semantic space in which similar words are represented by vectors that are close in that space, while different words are distant.\nWe rely on the intuition that if a term develops a metaphoric sense, its contexts of occurrence will start to differ, at least partially, from those observed for the very same term at the time the metaphorical meaning had not emerged yet. This implies that detecting a distance in space across time could be indicative of a meaning shift. Hence, instead of comparing different terms synchronically, we focus on their self-distance across time, thus tracing their diachronic evolution of meaning.\nPractically, we train vector representations of words in consecutive time spans, and compare such representations to one another, for a set of pilot terms. As a default, a term is expected to exhibit a vector representation roughly similar to itself across time. If we observe a drop in similarity between vectors in consecutive spaces, we can hypothesise the emergence of a new sense for this term, potentially metaphoric.\nBy using the information recorded for the selected terms in a reference dictionary for the Italian language, we observe whether there is some correspondence between the observed similarity drop, if present, and the time of inclusion of a figurative sense. Finally, for each year cluster, we manually inspect the occurrences of our target terms in order to see if changes of use can be observed.\nWe are aware of the fact that changes in distance of a word to itself across time might be triggered by phenomena other than the rise of a metaphoric shift. Indeed, especially for polysemous words, extralinguistic factors could cause the dominance of one sense over the others at a given time. In a largerscale, bottom-up approach to detect metaphorical shifts, this would need to be properly accounted for. In the context of this proof-of-concept, we control for this factor by choosing words that are not or are minimally polysemous (see Section 4.1)."}, {"heading": "3 Related Work", "text": "The automatic modelling of diachronic shift of meaning has been investigated employing several\ndifferent techniques. Among these, most recently, Latent Semantic Analysis (Sagi et al., 2011; Jatowt and Duh, 2014), topic clustering (Wijaya and Yeniterzi, 2011) and dynamic topic modeling (Frermann and Lapata, 2016). Vector representations for diachronic shift of meaning have been used by Gulordava and Baroni (2011), with a simple cooccurence matrix of target words and context terms. Jatowt and Duh (2014) and Xu and Kemp (2015) experimented both with a bag-of-words approach and a more linguistically motivated representation that also captures the relative position of lexical items in relation to the target word.\nRecently, Word Embeddings (Mikolov and Dean (2013), see also Section 4.3) have been used to investigate diachronic meaning shifts: vectors are usually created independently for each time span and then mapped from one year to another via a transformation matrix, thus leveraging the stability of the relative positions of vectors in different spaces (Kulkarni et al., 2015; Zhang et al., 2015; Hamilton et al., 2016).\nAn alternative approach, which we also adopt \u2013 with a slight change \u2013 in our work, is introduced by Kim et al. (2014), who propose a simple but effective methodology to make vectors trained on different corpora directly comparable: embeddings created for year y are used to initialise the vectors for year y+1. The process is progressively applied to all time spans."}, {"heading": "4 Experiment", "text": "Following the approach described in Section 2, we selected a small set of pilot terms from a lexicographic reference, and observed their space development across time, on a diachronic corpus for Italian that we collected for this purpose. Due to the absence of datasets in which words are annotated for meaning change, a qualitative analysis of a set of hand-selected words like the one we propose has established itself as a common evaluation method in previous work on diachronic meaning change (Frermann and Lapata, 2016)."}, {"heading": "4.1 Lexicographic reference and term selection", "text": "The Zingarelli dictionary is a reference dictionary for the Italian language, updated and published every year, both in digital and paper version. The dictionary is traditionally dated one year ahead of the year it is published, hence the Zingarelli 2017\nis published in June 2016, and it refers to decisions about new words and new meanings (including metaphorical ones) made up until December 2015.\nWe analysed the behaviour of a small set of terms extracted from the dictionary. We searched the 2017 edition to extract nouns that record a figurative meaning, limiting our search to words whose first occurrence is recorded in the 20th or 21st century. Newly born words (including borrowings) are more likely to show a meaning shift in the time span considered in our search (1984-2015) than older words (especially if derived directly form Latin, where the figurative meaning was also originally highly available, so probably arisen earlier). Out of a total of 447 hits, five target words were chosen for this pilot study. They are reported in Table 1 together with relevant information.\nIn order to minimise (at least in the context of this experiment) the influence of polysemy in the observable similarity distance across years, we verified that the selected terms are not polysemous, or minimally so. For the words \u201crottamatore\u201d, \u201ctalebano\u201d, and \u201ctsunami\u201d, the Zingarelli records one sense only. For the word \u201cimplosione\u201d three senses in total are recorded, two of which are however technical language, in the fields of linguistics (phonology) and psychology, and we assume will not be used much in newswire. For \u201ckamikaze\u201d the Zingarelli records one meaning only (Japanese pilot) to which is associated the extended sense of someone who kills himself in a terrorist attack; in our corpus the extended meaning is clearly the primary one, and the figurative sense that we consider is derived from it (see also Section 4.4)."}, {"heading": "4.2 Corpus", "text": "We created a diachronic corpus of approximately 60 millions tokens by collecting articles from the Italian newspaper la Repubblica from 1984 (the first year for which data is available digitally) to 2015. All texts were tokenised and lowercased. Because we are interested in how a term\u2019s context changes over time, we had to determine time-spans for our corpus, and we settled on two-year blocks, for a total of 16 time spans, the first one being 1984- 1985 and the last 2014-2015. These subcorpora are used to train consecutive vector space models."}, {"heading": "4.3 Model", "text": "We implemented vector representations using the skip-gram architecture introduced by Mikolov and Dean (2013). Such representations (Word Embeddings) are low dimensional, dense and real-valued vectors that have been proved to preserve syntactic and semantic information in several NLP tasks (Baroni et al., 2014).\nVectors created on different corpora cannot be directly compared, since every semantic space implements arbitrary orthogonal transformations and hence there is no direct correspondence between word vectors in different semantic spaces (Zhang et al., 2015). This would hold true also for our data, since we create a different corpus for each time span. Therefore, in order to create comparable vector representations for each word in any time span, we adopt the methodology introduced by Kim et al. (2014) (see Section 3), slightly modifying it. While Kim et al. (2014) use vectors of span y to initialise the vectors for year y + 1, we do the opposite, i.e.\nwe start with 2014-15, and use those vectors to initialise the 2012-13 time span, and thus backwards until 1984-85.\nThis methodological choice is due to the fact that the majority of the words in the set we considered for this experiment (included the selected target words, see 4.1) have few or no occurrences in the first time spans of the corpus: for example, \u201crottamatore\u201d and \u201ctalebano\u201d occur for the first time in 96/97. Indeed, using Kim et al. (2014)\u2019s original approach, which we implemented in a preliminary experiment, the vectors for these words were correctly initialised, but were basically random vectors with no meaningful information. Conversely, our reverse setting, while still offering the same opportunity to trace shifts of meaning across time, allows to initialise all target words on a time span (14/15) in which they occur a number of times sufficient to create a more stable, meaningful representation.\nUsing the gensim library (R\u030cehu\u030ar\u030cek and Sojka, 2010), we trained the models with the following parameters: window size of 5, learning rate of 0.01 and dimensionality of 200. We filtered out words with frequency lower than 5 occurrences. The vocabulary was initialised over the whole dataset."}, {"heading": "4.4 Results and discussion", "text": "Figure 1 shows the similarity values for one time span to the next (dotted line), together with the average shift of meaning of a subset of 5000 nouns randomly selected (solid line). While we cannot draw any statistically significant conclusions from such little data, we aim at potentially observing patterns of shift of meaning through change of vector representations that could be used for developing predictive metrics of metaphorical shifts in time.\nWe interpret the results of our models according to (i) information in the Zingarelli dictionary and (ii) a manual inspection of the context of use of our target words in the corpus.\nFor (i), we verify if, for a given term, an observable correlation exists between changes in its vector representations and the insertion of a figurative sense in the dictionary. Results show that such a correlation exists for \u201ctalebano\u201d, \u201crottamatore\u201d, and \u201ctsunami\u201d. For these words a drop in cosine similarity can be observed between three and five years before the insertion of the figurative meaning in the dictionary. This fits well with the timing for new meanings to be recorded in lexicographic resources (see Section 4.1). The nouns \u201ckamikaze\u201d\nand \u201cimplosione\u201d, instead, show a more stable evolution of meaning in time, with no clear drop in cosine similarity, and thus no evident correlation between changes in vector representations and insertion of a figurative meaning in dictionary.\nFor (ii), we manually inspected the contexts in which target terms occur in the the corpus as literal or metaphoric, in order to check if some relevant change in words usage could be observed in correspondence to drops in cosine similarity between time spans.\n\u201cTsunami\u201d occurs 27 times between 84/85 and 02/03: in 88.9% of the cases the word is used literally, with only 3 metaphorical uses in 98/99 (mirrored in a slight drop in cosine similarity). Of the 930 occurrences from 04/05 to 14/15, only 59.1% are literal. In Figure 1 we can observe a major drop in cosine similarity exactly between 04/05 and 06/06.\n\u201cRottamatore\u201d occurs 4 times between 84/85 and 08/09, always used literally. From 10/11 on, there are 156 occurrences, all metaphorical. Thus, the drop corresponds to change in usage here too.\n\u201cTalebano\u201d occurs 12 times between 84/85 and 02/03, with 83.3% of literal usage. Once again, the drop in cosine coincides with the time span in which the term started to be used metaphorically: between 02/03 and 08/09 40% of the occurrences of \u201ctalebano\u201d are metaphorical. Then, another relevant drop is observed between 08/09 and 10/11, and this is due to the sudden return of the literal usage of this word (86.1%), which continues also in the following years.\nAs already noticed, \u201ckamikaze\u201d and \u201cimplosione\u201d do not seem to undergo a clear shift. As for the former, the analysis of its contexts of use reveals that indeed it is not possible to clearly identify, in our corpus, when exactly the term started to be used metaphorically: of the 25 occurrences of \u201ckamikaze\u201d in 84/85, 32% are metaphorical. This trend is fairly constant, and it explains why the vector representation of \u201ckamikaze\u201d, which from the very beginning conflates literal and metaphorical usages, is stable in time. There is only a relevant change starting from 10/11: from this period onwards, the metaphorical use decreases, and almost all the occurrences are literal.3 Accordingly, this\n3Interestingly, this increase of literal usage is observed in the same years also for \u201ctalebano\u201d, a term that is semantically related to \u201ckamikaze\u201d. This observation would require further investigation in connection with the socio-political events of those time spans.\nalmost exclusively return to the literal meaning corresponds to a slight increase in cosine similarity between the two last time spans.\n\u201cImplosione\u201d occurs 433 times overall and in 92.4% of them is used metaphorically, but in few and specific contexts. A metaphorical, quite specific, sense of \u201cimplosione\u201d is thus the main sense for this term in our corpus, and this is why we observe, on average, a high similarity across time spans. There is only a small drop between 10/11 and 12/13, when the word started to be used in the context of the economical crisis (\u201cl\u2019implosione dell\u2019euro\u201d).\nTo sum up, both \u201ckamikaze\u201d and \u201cimplosione\u201d show a similar stable behaviour in time, with only small drops. However, while for \u201ckamikaze\u201d such stability is due to a relatively constant ratio between literal and metaphorical meanings, in the case of \u201cimplosione\u201d the observed stability is given by the constant predominance of the metaphorical sense across all the time spans."}, {"heading": "5 Conclusion and future work", "text": "This work was meant as an exploration of the assumption that the emergence of the metaphorical use of a term might be mirrored in changes in co-\nsine similarity of the term to itself across time. Such assumption has been partially confirmed by the comparison to the Zingarelli dictionary, while we found a more robust evidence when inspecting the terms\u2019 contexts of use manually.\nFuture work will stem from methodology and observations discussed here. Specifically, we plan to investigate further several aspects of this initial work, including the relation between changes in cosine similarity and frequency of use of a word: to which extent a change of the former relates to an increase of the latter? Mostly though, we plan to run experiments on larger sets of words with the aim to consolidate and then further exploit the mainly qualitative observations reported here towards the development of reliable predictive metrics which can serve to detect the emergence of shifts automatically, in a completely bottom-up fashion."}, {"heading": "Acknowledgments", "text": "Malvina Nissim would like to thank the ILC-CNR ItaliaNLP Lab for their hospitality while working on this project. We are also grateful to the anonymous reviewers who provided insightful comments that doubtlessly contributed to improve this paper."}], "references": [{"title": "Don\u2019t count, predict! a systematic comparison of context-counting vs. context-predicting semantic vectors", "author": ["Baroni et al.2014] Marco Baroni", "Georgiana Dinu", "Germ\u00e1n Kruszewski"], "venue": "In Proceedings of the 52nd Annual Meeting of the Association", "citeRegEx": "Baroni et al\\.,? \\Q2014\\E", "shortCiteRegEx": "Baroni et al\\.", "year": 2014}, {"title": "A bayesian model of diachronic meaning change. Transactions of the Association for Computational Linguistics, 4:31\u201345", "author": ["Frermann", "Lapata2016] Lea Frermann", "Mirella Lapata"], "venue": null, "citeRegEx": "Frermann et al\\.,? \\Q2016\\E", "shortCiteRegEx": "Frermann et al\\.", "year": 2016}, {"title": "A distributional similarity approach to the detection of semantic change in the Google books ngram corpus", "author": ["Gulordava", "Baroni2011] Kristina Gulordava", "Marco Baroni"], "venue": "In Proceedings of the GEMS 2011 Workshop on GEometrical Models", "citeRegEx": "Gulordava et al\\.,? \\Q2011\\E", "shortCiteRegEx": "Gulordava et al\\.", "year": 2011}, {"title": "Diachronic word embeddings reveal statistical laws of semantic change", "author": ["Jure Leskovec", "Dan Jurafsky"], "venue": "arXiv preprint arXiv:1605.09096", "citeRegEx": "Hamilton et al\\.,? \\Q2016\\E", "shortCiteRegEx": "Hamilton et al\\.", "year": 2016}, {"title": "Automatic extraction of linguistic metaphor with LDA topic modeling", "author": ["Heintz et al.2013] Ilana Heintz", "Ryan Gabbard", "Mahesh Srinivasan", "David Barner", "Donald S Black", "Marjorie Freedman", "Ralph Weischedel"], "venue": "Proceedings of the First", "citeRegEx": "Heintz et al\\.,? \\Q2013\\E", "shortCiteRegEx": "Heintz et al\\.", "year": 2013}, {"title": "Identifying metaphorical word use with tree kernels", "author": ["Hovy et al.2013] Dirk Hovy", "Shashank Srivastava", "Sujay Kumar Jauhar", "Mrinmaya Sachan", "Kartik Goyal", "Huiying Li", "Whitney Sanders", "Eduard Hovy"], "venue": "In Proceedings of the First Workshop", "citeRegEx": "Hovy et al\\.,? \\Q2013\\E", "shortCiteRegEx": "Hovy et al\\.", "year": 2013}, {"title": "A framework for analyzing semantic change of words across time", "author": ["Jatowt", "Duh2014] Adam Jatowt", "Kevin Duh"], "venue": "In Proceedings of the 14th ACM/IEEE-CS Joint Conference on Digital Libraries,", "citeRegEx": "Jatowt et al\\.,? \\Q2014\\E", "shortCiteRegEx": "Jatowt et al\\.", "year": 2014}, {"title": "Temporal analysis of language through neural language models", "author": ["Kim et al.2014] Yoon Kim", "Yi-I Chiu", "Kentaro Hanaki", "Darshan Hegde", "Slav Petrov"], "venue": "In Proceedings of the ACL 2014 Workshop on Language Technologies and Computational So-", "citeRegEx": "Kim et al\\.,? \\Q2014\\E", "shortCiteRegEx": "Kim et al\\.", "year": 2014}, {"title": "Statistically significant detection of linguistic change", "author": ["Rami Al-Rfou", "Bryan Perozzi", "Steven Skiena"], "venue": "In Proceedings of the 24th International Conference on World Wide Web,", "citeRegEx": "Kulkarni et al\\.,? \\Q2015\\E", "shortCiteRegEx": "Kulkarni et al\\.", "year": 2015}, {"title": "Distributed representations of words and phrases and their compositionality. Advances in neural information processing systems", "author": ["Mikolov", "Dean2013] T Mikolov", "J Dean"], "venue": null, "citeRegEx": "Mikolov et al\\.,? \\Q2013\\E", "shortCiteRegEx": "Mikolov et al\\.", "year": 2013}, {"title": "Software Framework for Topic Modelling with Large Corpora", "author": ["\u0158eh\u016f\u0159ek", "Sojka2010] Radim \u0158eh\u016f\u0159ek", "Petr Sojka"], "venue": "In Proceedings of the LREC 2010 Workshop on New Challenges for NLP Frameworks,", "citeRegEx": "\u0158eh\u016f\u0159ek et al\\.,? \\Q2010\\E", "shortCiteRegEx": "\u0158eh\u016f\u0159ek et al\\.", "year": 2010}, {"title": "Tracing semantic change with latent semantic analysis", "author": ["Sagi et al.2011] Eyal Sagi", "Stefan Kaufmann", "Brady Clark"], "venue": "Current methods in historical semantics,", "citeRegEx": "Sagi et al\\.,? \\Q2011\\E", "shortCiteRegEx": "Sagi et al\\.", "year": 2011}, {"title": "Unsupervised metaphor identification using hierarchical graph factorization clustering", "author": ["Shutova", "Sun2013] Ekaterina Shutova", "Lin Sun"], "venue": "In HLTNAACL,", "citeRegEx": "Shutova et al\\.,? \\Q2013\\E", "shortCiteRegEx": "Shutova et al\\.", "year": 2013}, {"title": "Design and evaluation of metaphor processing systems", "author": ["Ekaterina Shutova"], "venue": "Computational Linguistics,", "citeRegEx": "Shutova.,? \\Q2015\\E", "shortCiteRegEx": "Shutova.", "year": 2015}, {"title": "From frequency to meaning: Vector space models of semantics", "author": ["Patrick Pantel"], "venue": "Journal of artificial intelligence research,", "citeRegEx": "Turney and Pantel,? \\Q2010\\E", "shortCiteRegEx": "Turney and Pantel", "year": 2010}, {"title": "Literal and metaphorical sense identification through concrete and abstract context", "author": ["Yair Neuman", "Dan Assaf", "Yohai Cohen"], "venue": "In Proceedings of the 2011 Conference on the Empirical Methods in Natural", "citeRegEx": "Turney et al\\.,? \\Q2011\\E", "shortCiteRegEx": "Turney et al\\.", "year": 2011}, {"title": "Understanding semantic change of words over centuries", "author": ["Wijaya", "Reyyan Yeniterzi"], "venue": "In Proceedings of the 2011 international workshop on DETecting and Exploiting Cultural diversiTy on the social web,", "citeRegEx": "Wijaya et al\\.,? \\Q2011\\E", "shortCiteRegEx": "Wijaya et al\\.", "year": 2011}, {"title": "A computational evaluation of two laws of semantic change", "author": ["Xu", "Kemp2015] Y. Xu", "C. Kemp"], "venue": "In Proceedings of the 37th Annual Conference of the Cognitive Science Society", "citeRegEx": "Xu et al\\.,? \\Q2015\\E", "shortCiteRegEx": "Xu et al\\.", "year": 2015}, {"title": "Omnia mutantur, nihil interit: Connecting past with present by finding corresponding terms across time", "author": ["Zhang et al.2015] Yating Zhang", "Adam Jatowt", "Sourav S Bhowmick", "Katsumi Tanaka"], "venue": "In Proc. of ACL,", "citeRegEx": "Zhang et al\\.,? \\Q2015\\E", "shortCiteRegEx": "Zhang et al\\.", "year": 2015}, {"title": "1993\u20132017. Lo Zingarelli - Vocabolario della lingua italiana", "author": ["N. Zingarelli"], "venue": "Zanichelli editore,", "citeRegEx": "Zingarelli.,? \\Q2017\\E", "shortCiteRegEx": "Zingarelli.", "year": 2017}], "referenceMentions": [{"referenceID": 15, "context": "It is widely acknowledged that metaphors are pervasive in language use, and that their detection and interpretation are crucial to language processing (Group, 2007; Turney et al., 2011; Shutova, 2015).", "startOffset": 151, "endOffset": 200}, {"referenceID": 13, "context": "It is widely acknowledged that metaphors are pervasive in language use, and that their detection and interpretation are crucial to language processing (Group, 2007; Turney et al., 2011; Shutova, 2015).", "startOffset": 151, "endOffset": 200}, {"referenceID": 4, "context": "Most of the computational work on metaphors has focused on their identification and interpretation using a variety of techniques and models, such as clustering (Shutova and Sun, 2013), LDA topic modeling (Heintz et al., 2013), tree kernels (Hovy et al.", "startOffset": 204, "endOffset": 225}, {"referenceID": 5, "context": ", 2013), tree kernels (Hovy et al., 2013), but all from a purely synchronic perspective.", "startOffset": 22, "endOffset": 41}, {"referenceID": 13, "context": "For a detailed survey on current NLP systems for metaphor modeling see (Shutova, 2015).", "startOffset": 71, "endOffset": 86}, {"referenceID": 11, "context": "Among these, most recently, Latent Semantic Analysis (Sagi et al., 2011; Jatowt and Duh, 2014), topic clustering (Wijaya and Yeniterzi, 2011) and dynamic topic modeling (Frermann and Lapata, 2016).", "startOffset": 53, "endOffset": 94}, {"referenceID": 11, "context": "Among these, most recently, Latent Semantic Analysis (Sagi et al., 2011; Jatowt and Duh, 2014), topic clustering (Wijaya and Yeniterzi, 2011) and dynamic topic modeling (Frermann and Lapata, 2016). Vector representations for diachronic shift of meaning have been used by Gulordava and Baroni (2011), with a simple cooccurence matrix of target words and context terms.", "startOffset": 54, "endOffset": 299}, {"referenceID": 11, "context": "Among these, most recently, Latent Semantic Analysis (Sagi et al., 2011; Jatowt and Duh, 2014), topic clustering (Wijaya and Yeniterzi, 2011) and dynamic topic modeling (Frermann and Lapata, 2016). Vector representations for diachronic shift of meaning have been used by Gulordava and Baroni (2011), with a simple cooccurence matrix of target words and context terms. Jatowt and Duh (2014) and Xu and Kemp (2015) experimented both with a bag-of-words approach and a more linguistically motivated representation that also captures the relative position of lexical items in relation to the target word.", "startOffset": 54, "endOffset": 390}, {"referenceID": 11, "context": "Among these, most recently, Latent Semantic Analysis (Sagi et al., 2011; Jatowt and Duh, 2014), topic clustering (Wijaya and Yeniterzi, 2011) and dynamic topic modeling (Frermann and Lapata, 2016). Vector representations for diachronic shift of meaning have been used by Gulordava and Baroni (2011), with a simple cooccurence matrix of target words and context terms. Jatowt and Duh (2014) and Xu and Kemp (2015) experimented both with a bag-of-words approach and a more linguistically motivated representation that also captures the relative position of lexical items in relation to the target word.", "startOffset": 54, "endOffset": 413}, {"referenceID": 7, "context": "An alternative approach, which we also adopt \u2013 with a slight change \u2013 in our work, is introduced by Kim et al. (2014), who propose a simple but effective methodology to make vectors trained on different corpora directly comparable: embeddings created for year y are used to initialise the vectors for year y+1.", "startOffset": 100, "endOffset": 118}, {"referenceID": 0, "context": "Such representations (Word Embeddings) are low dimensional, dense and real-valued vectors that have been proved to preserve syntactic and semantic information in several NLP tasks (Baroni et al., 2014).", "startOffset": 180, "endOffset": 201}, {"referenceID": 18, "context": "Vectors created on different corpora cannot be directly compared, since every semantic space implements arbitrary orthogonal transformations and hence there is no direct correspondence between word vectors in different semantic spaces (Zhang et al., 2015).", "startOffset": 235, "endOffset": 255}, {"referenceID": 7, "context": "Therefore, in order to create comparable vector representations for each word in any time span, we adopt the methodology introduced by Kim et al. (2014) (see Section 3), slightly modifying it.", "startOffset": 135, "endOffset": 153}, {"referenceID": 7, "context": "Therefore, in order to create comparable vector representations for each word in any time span, we adopt the methodology introduced by Kim et al. (2014) (see Section 3), slightly modifying it. While Kim et al. (2014) use vectors of span y to initialise the vectors for year y + 1, we do the opposite, i.", "startOffset": 135, "endOffset": 217}, {"referenceID": 7, "context": "Indeed, using Kim et al. (2014)\u2019s original approach, which we implemented in a preliminary experiment, the vectors for these words were correctly initialised, but were basically random vectors with no meaningful information.", "startOffset": 14, "endOffset": 32}], "year": 2016, "abstractText": "English. From a diachronic corpus of Italian, we build consecutive vector spaces in time and use them to compare a term\u2019s cosine similarity to itself in different time spans. We assume that a drop in similarity might be related to the emergence of a metaphorical sense at a given time. Similarity-based observations are matched to the actual year when a figurative meaning was documented in a reference dictionary and through manual inspection of corpus occurrences. Italiano. Nel presente esperimento costruiamo spazi vettoriali progressivi nel tempo su un corpus diacronico dell\u2019italiano e calcoliamo la distanza di alcuni termini rispetto a loro stessi in differenti periodi. L\u2019ipotesi \u00e8 che un calo di similitudine possa essere indicativo dell\u2019acquisizione di un significato metaforico. Tale ipotesi \u00e8 valutata attraverso una risorsa lessicografica esterna e l\u2019annotazione manuale dei contesti dei termini nel corpus.", "creator": "LaTeX with hyperref package"}}}