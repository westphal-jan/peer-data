{"id": "1701.02815", "review": {"conference": "ICML", "VERSION": "v1", "DATE_OF_SUBMISSION": "11-Jan-2017", "title": "Stochastic Generative Hashing", "abstract": "blind learning to hash plays well a critical fundamentally demonstrated important working role in the efficient image and video retrieval and many general other computer vision cache problems. simultaneously however, both due similarly to the binary values outputs of the hash functions, increasing the learning of hash functions is very challenging. in this paper, theoretically we accordingly propose a novel approach to blindly learn suitable stochastic hash functions such that not the learned hashing codes can readily be used to somehow regenerate either the unknown inputs. we consequently develop, an efficient stochastic gradient heap learning integration algorithm above which theoretically can partially avoid the notorious difficulty caused solely by binary output constraint, specify and directly optimize the smallest parameters likelihood of triggering the hash compression functions and have the associated generative model working jointly. importantly the proposed method can be applied concurrently to computed both $ l2 $ approximate accuracy nearest neighbor password search ( l2nns ) and calculate maximum confidence inner pocket product search ( mips ). potentially extensive dynamic experiments including on a variety sorts of large - scale analytical datasets show that the proposed method finally achieves significantly better total retrieval results combined than previous adaptive state - of - the - system arts.", "histories": [["v1", "Wed, 11 Jan 2017 00:23:34 GMT  (4699kb,D)", "http://arxiv.org/abs/1701.02815v1", "19 pages, 22 figures"], ["v2", "Sat, 12 Aug 2017 21:36:09 GMT  (4441kb,D)", "http://arxiv.org/abs/1701.02815v2", "21 pages, 40 figures"]], "COMMENTS": "19 pages, 22 figures", "reviews": [], "SUBJECTS": "cs.LG cs.CV stat.ML", "authors": ["bo dai", "ruiqi guo", "sanjiv kumar", "niao he", "le song"], "accepted": true, "id": "1701.02815"}, "pdf": {"name": "1701.02815.pdf", "metadata": {"source": "CRF", "title": "Stochastic Generative Hashing", "authors": ["Sanjiv Kumar", "Niao He", "Le Song"], "emails": ["bodai@gatech.edu,", "lsong@cc.gatech.edu", "sanjivk}@google.com", "niaohe@illinois.edu"], "sections": [{"heading": "1 Introduction", "text": "Searching for similar items in web-scale datasets is an important task in image and document retrieval. Formally, given a reference dataset X = {xi}Ni=1 with x \u2208 X \u2282 Rd, we want to retrieve the similar items from X with respect to a query y according to some similarity measure sim(x, y). When the negative Euclidean distance is used, i.e., sim(x, y) = \u2212\u2016x \u2212 y\u20162, this corresponds to L2 Nearest Neighbor Search (L2NNS) problem; when the inner product is used, i.e., sim(x, y) = x>y, it becomes a Maximum Inner Product Search (MIPS) problem. Brute-force linear search is expensive for large datasets. To alleviate the time and space cost, two research directions have been used extensively: (1) partition the dataset so only a subset of data points are searched; (2) hash the dataset so that similarity computation can be carried out more efficiently. The first group techniques for speeding up is often in the form of search-tree or bucket lookup; while the second group relies on binary hashing or quantization. These two groups of techniques are orthogonal and are often employed jointly in practice.\nWe focus on the second category for speeding up the searching in this paper. Using hashing for similarity searching has been popularized by influential works such as Locality Sensitive Hashing (Indyk and Motwani, 1998; Gionis et al., 1999), and has been applied towards computer vision tasks such as large scale image retrieval (Torralba et al., 2008; Je\u0301gou et al., 2010) and video retrieval (Sivic and Zisserman, 2003). The\n\u2217Authors are equally contributed.\nar X\niv :1\n70 1.\n02 81\n5v 1\n[ cs\n.L G\n] 1\ncrux of binary hashing is the hash function, f(\u00b7) : X \u2192 {0, 1}l, which maps the original samples in highdimensional space X \u2208 Rd to l-bit binary vectors h \u2208 {0, 1}l where l d, while the neighborhood in terms of the desired measure, e.g., Euclidean distance or inner product, is still preserved. Searching with such binary representations can be efficiently conducted using Hamming distance computation, which is supported via POPCNT on modern CPUs and GPUs.\nIt is well recognized that the data-dependent hash functions perform better (Wang et al., 2014). Many works have since then focused on learning hash functions or the binary codes for either L2NNS or MIPS, including iterative quantization (Gong and Lazebnik, 2011), spectral hashing (Weiss et al., 2009), product quantization (Jegou et al., 2011), binary autoencoder (Carreira-Perpina\u0301n and Raziperchikolaei, 2015), and many others (Liu et al., 2011; Gong et al., 2013; Yu et al., 2014; Shen et al., 2015; Guo et al., 2015). The main idea behind these works is to optimize some objective representing the preferred properties with respect to the hash function or the binary codes, in a supervised or unsupervised fashion. We mainly focus on unsupervised setting in the main text1 In fact, due to the binary constraints in optimization, the optimization can be extremely difficult. To make the optimization tractable, the existing methods either introduce extra constraints to achieve closed-from update, or employ the integer programming techniques. For example, iterative quantization and its variants (Yu et al., 2014; Gong et al., 2013) introduce structure and orthogonality constraints on the parameters, and the vector quantization and its generalization, e.g., product quantization (Jegou et al., 2011) and composite quantization (Zhang et al., 2014b), constrain the binary representation must be 1-of-K coding, so that the corresponding optimization is simplified. However, with these extra constraints, the models become too restricted to generate good binary codes. The other school of methods relies on the techniques from integer programming. These algorithms either relax the binary codes to a continuous space, e.g., the graph-based hashing (Weiss et al., 2009; Liu et al., 2011), or use penalty or augmented Lagrangian method to separate the binary variables, e.g., NMF-based hashing (Mukherjee et al., 2015), binary autoencoder (Carreira-Perpina\u0301n and Raziperchikolaei, 2015). However, these algorithms are suboptimal in terms of accuracy and/or computational cost: the continuous relaxation with threshold will lead to inferior solutions, while the augmented Lagrangian method will involve complicated update for binary variables, resulting unacceptable cost in learning stage for large-scale datasets. Therefore, an efficient and scalable algorithm for learning flexible hash function is still needed.\nIn this paper, we propose such an algorithm, Stochastic Generative Hashing (SGH), satisfying the necessary requirements for learning to hash methods."}, {"heading": "1.1 Main Contribution", "text": "As demonstrated in previous literatures such as (Wang et al., 2014), a good hash function learned from data should generate binary codes which\ni) preserve the neighborhood in original dataset; while ii) as short as possible.\nMoreover, we argue that since the ultimate task is accelerating the similarity searching in web-scale dataset, the hash function as well as its learning procedure should also satisfy,\niii) the encoding via the learned hash function should be fast in retrieval stage; iv) the learning to hash algorithm itself should be efficient and scalable in terms of both memory and\ncomputation cost.\nIndeed, if the computational cost for encoding each new query through the hash function is O(dN), there will be no need to introduce the hashing step. Under such scenario, the hashing step takes the same computational cost as scanning the whole dataset, and requires extra storage to save the model. Moreover, it potentially introduces extra error and results in inferior searching performance. Because the application scenario for hashing is searching in web-scale datasets, if the hash function learning algorithm is computational costly, it will not be practical for real-world applications. These two requirements are very important for designing practical learning to hash algorithm. However, most of the existing methods focus on the first two requirements and neglect these factors.\n1The proposed algorithm can be extended to supervised/semi-supervised setting easily in Appendix A.\nThe proposed stochastic generative hashing in this paper based on the reduced Gaussian-Markov random fields which learns the hash function satisfying all these requirements. It possesses a number of desiderata by design: Neighborhood preservation. We rigorously analyze the condition under which the L2 distances and inner products between original data points will be preserved. Based on the understanding, we propose the generative model which is able to generate polysemous binary codes preserving both pairwise relationships. Delicate balance with fixed bit length budget. We interpret the learning objective in our framework as the minimum description length (MDL) principle, and thus, the learned model provides the best compression within fixed budget of binary code length. Efficient retrieval. We introduce an efficient encoding hash function into the generative model to accelerate the coding procedure in retrieval stage. The encoding hash function will be trained jointly with the generative model. Scalable and provable incremental learning. We avoid the notorious difficulty in learning to hash due to binary variables. Instead of directly dealing with discrete variables, we are optimizing the distributions over them. To scale up the model to web-scale applications, we first reparametrized the model with the new doubly stochastic neuron. Then, we extend the stochastic gradient descent algorithm (Nemirovski et al., 2009) with distributional derivative (Grubb, 2008) to deal with the discontinuity in the reparametrization. Equipped with these new tools, we can directly target on the optimization containing discrete variables without relaxation and still achieve convergence in both static or online setting (Ghadimi and Lan, 2013). We emphasize this algorithm is applicable for general integral programming as well as discrete variational autoencoder model, which can be of independent interest. Generality and flexibility. The proposed generative hashing is a general framework which can be extended to semi-supervised setting and other learning to hash scenarios in Appendix A. Moreover, it includes several existing algorithms, e.g., vector quantization, iterative quantization (Gong and Lazebnik, 2011), product quantization (Jegou et al., 2011), and composition quantization (Zhang et al., 2014b), as special cases. Strong empirical performance. Our algorithm can readily scale learning to hash up to applications with millions of data. We show that our method outperforms the existing algorithms in terms of both accuracy and learning cost, and thus, achieves the state-of-the-art performance.\nThroughout this paper, we denote \u3008\u00b7, \u00b7\u3009 as the L2 inner product. Without ambiguity, we use \u2207xf(x) and \u2202xf(x) interchangeably to denote the traditional derivative or distributional derivative\n2 of f w.r.t. x. The 1x>x0 stands for the function which outputs 1 if x > x0, 0 otherwise, and ei denotes [0, . . . , 1, . . . , 0] where only the i-th position is 1."}, {"heading": "2 Stochastic Generative Hashing", "text": "To achieve the important trade-off between the first two requirements, i.e., neighborhood preservation and compactness of the binary codes, in a principled manner, we propose a generative model, treating the binary hash codes h \u2208 {0, 1}l as latent variables. Different from most of the existing methods where the hash function is modeled as a signed projection of the original data and learned via some heuristic objectives preferring binary codes preserving the original neighborhood, we directly model the data generating process, i.e., given the binary hash codes h, the observed samples x \u2208 Rd are generated by some probabilistic model, p(x|h). We will show that with a suitable p(x|h) and a theoretically grounded objective, the binary latent variable h indeed balances these two factors in the information theory sense. Moreover, we designed a delicate algorithm to solve the optimization so that the requirements iii) and iv) are satisfied, i.e., achieving fast retrieval and fast learning."}, {"heading": "2.1 Reduced Gaussian-Markov Random Fields", "text": "We first propose the basic model, in which the generating process is characterized by the joint distribution for x \u2208 Rd, h \u2208 {0, 1}l,\n2The distributional derivative is defined in (Grubb, 2008) and will be introduced in section 3.\np(x, h) = p(x|h)p(h). The reconstruction model p(x|h) is Gaussian distribution, p(x|h) = N (Uh, \u03c12I), (1) where \u03c1 \u2208 R+, U \u2208 Rd\u00d7l, and the prior on h will be Bernoulli distribution,\np(h) = l\u220f i=1 \u03b8hii (1\u2212 \u03b8i) 1\u2212hi := B (\u03b8) , (2)\nwith \u03b8 = [\u03b8i] l i=1 \u2208 [0, 1]l. Intuitively, for each sample x, it is generated by combining the selected components from templates U = {ui}li=1, \u2200ui \u2208 Rd by the binary latent variables h \u2208 {0, 1}l, while the binary latent variables, h, are sampled from Bernoulli distribution. In fact, by exploiting the Gaussian reconstruction model p(x|h), the proposed model is able to generate binary codes h to preserve both Euclidean distance and inner product between original data pairs. Proposition 1 If \u2016U\u2016F are bounded, the Gaussian reconstruction error is a surrogate for Euclidean neighborhood preservation.\nProof Let us consider \u2016x\u2212 y\u20162 = \u2016x\u2212 U>hx \u2212 ( y \u2212 U>hy ) + U>hx \u2212 U>hy\u20162\n6 \u2016x\u2212 U>hx\u20162 + \u2016y \u2212 U>hy\u20162 + \u2016U>(hx \u2212 hy)\u20162 6 \u2016x\u2212 U>hx\u20162 + \u2016y \u2212 U>hy\u20162 + \u2016U\u2016F \u2016hx \u2212 hy\u20162\nwhere hx and hy denotes the binary latent variables corresponding to x and y, respectively. Therefore, we have \u2016x\u2212 y\u20162 \u2212 \u2016U\u2016F \u2016hx \u2212 hy\u20162 6 \u2016x\u2212 U>hx\u20162 + \u2016y \u2212 U>hy\u20162, which means minimizing the Gaussian reconstruction error, i.e., \u2212 log p(x|h), will lead to Euclidean neighborhood preservation.\nDenote the asymmetric inner product as x>Uhy, we claim Proposition 2 The Gaussian reconstruction error is a surrogate for asymmetric inner product preservation.\nProof We evaluate the difference between inner product and the asymmetric inner product,\n\u2016x>y \u2212 x>U>hy\u20162 = \u2016x> ( y \u2212 U>hy ) \u20162 6 \u2016x\u20162\u2016y \u2212 U>hy\u20162,\nwhich means minimizing the Gaussian reconstruction, i.e., \u2212 log p(x|h), error will also lead to asymmetric inner product preservation.\nThese two propositions justify the neighborhood preservation property of the proposed generative model. The proposed generative model is a special case of Markov random fields. Specifically, based on the proposed joint distribution, we have the potential function E(x, h) as (3) such that p(x, h) \u221d exp (\u2212E(x, h)),\nE(x, h) = \u2212\u03b2>h+ 1 2\u03c12\n( x>x+ h>U>Uh\u2212 2x>Uh )\ufe38 \ufe37\ufe37 \ufe38 \u2016x\u2212U>h\u201622 , (3)\nwhere \u03b2 = [\u03b2i] l i=1, \u03b2i = log \u03b8i 1\u2212\u03b8i . Comparing to the general Markov random fields, the proposed model shares parameters U for modeling the pairwise connections between h and the interactions between h and x. Therefore, we named the proposed model as reduced Gaussian-Markov random fields (reduced-MRFs). The graphical model of reduced-MRFs is illustrated in Figure 1. Even with such shared structure in the architecture, this model is still more flexible than Gaussian-Bernoulli restricted Boltzmann machines (GRBMs) (Krizhevsky, 2009; Marc\u2019Aurelio and Geoffrey, 2010). Indeed, if we set U>U = I, the quadratic term will become h>h = 1>h because h \u2208 {0, 1}l, therefore, the model reduces to the Gaussian-Bernoulli RBMs.\nIt should be emphasized that the proposed model can be easily extended to preserving other neighborhood with different divergences, e.g., Mahalanobis distance, Lp distance, and even more general f -divergence, by adapting different reconstruction models. In this paper, we only consider the Euclidean distance and inner product."}, {"heading": "2.2 Stochastic Encoder for Hashing", "text": "The quadratic term in (3) brings flexibility in modeling and achieves the desired neighborhood preservation. However, such flexibility and neighborhood preservation comes with its own cost: the posterior p(h|x) = p(x,h) p(x) of reduced-MRFs is no longer tractable, and thus, the both the inference and learning with existing algorithms will be unafforadable on large-scale datasets. Specifically, given the data {xi}Ni=1, the proposed reduced-MRFs model can be fitted by maximizing the marginal log-likelihood, i.e.,\nmax U,\u03b2,\u03c1\n1\nN N\u2211 i log p(xi) = 1 N N\u2211 i log \u2211 h p(xi, h). (4)\nDirectly applying the off-the-shelf Contrastive Divergence (CD) algorithm (Hinton, 2002) will result unacceptable computation cost. The CD algorithm needs samples from p(h|x). However, due to the intractability of p(h|x), we have to use Gibbs sampling to obtain even one sample of binary code h corresponding to x.\nA more severe issue is the computation cost in retrieval stage. Assume we already have a well-trained reduced-MRFs. Given a new query, to conduct searching in binary space with Hamming distance, we need to first code the new query via the reduced-MRFs by MAP. Seeking MAP of reduced-MRFs requires integer programming, whose cost will be even higher than Gibbs sampling.\nWe provide a solution bypassing these difficulties inspired by recent work variational auto-encoder (Kingma and Welling, 2013; Mnih and Gregor, 2014; Gregor et al., 2014),. The key insight is that when fixing the model p(x, h), the posterior is the solution of an optimization maximizing the negative Helmholtz variational free energy (Williams, 1980; Zellner, 1988; Dai et al., 2016), i.e.,\np(h|x) = argmax q\u2208P Eq(h|x) [log p(x, h)\u2212 log q(h|x)] (5)\nover the space of all valid densities P. To make the optimization (5) tractable, the variational autoencoder restricts the feasible space to be some parametrized density. Realize the q(h|x) can be used as stochastic hash function encoding the query in retrieval stage, the Helmholtz free energy introduces an explicit component, therefore, provides us the chance to achieve fast retrieval elegantly. For efficiency in retrieval stage, in this paper, we parametrize the q(h|x) as\nq(h|x) = l\u220f\nk=1\nq(hk = 1|x)hk (q(hk = 0|x))1\u2212hk , (6)\nwhere q(hk = 1|x) = \u03c3(w>k x) = 11+exp(\u2212w>k x) , i.e., h = [hk] l k=1 \u223c B(\u03c3(W>x)) with W = [wk]lk=1. One can also use more complicated parametrization, e.g., kernel functions and neural networks. We can now approximate the true posterior p(h|x) by q(h|x) through learning W in (5). Then, getting the binary codes\nin retrieval stage from q(h|x) either via MAP or sampling can be computed efficiently by only one matrix multiplication.\nMoreover, since the negative Helmholtz variational free energy is a lower bound of the marginal loglikelihood, i.e.,\nlog p(x) = logEq(h|x) [ p(x, h)\nq(h|x)\n] > Eq(h|x) [log p(x, h)\u2212 log q(h|x)] ,\nwhere the second inequality comes from Jensen\u2019s inequality, the parameters in p(x, h) can also be learned jointly with q(h|x) by optimizing the negative Helmholtz variational free energy as a surrogate,\nmax \u0398={U,\u03b2,\u03c1,W}\nH(p, q) := 1\nN N\u2211 i=1 Eq(h|xi) [log p(xi, h)\u2212 log q(h|xi)]. (7)\nPlug the proposed model (3) and (6) into H(p, q), we obtain the following optimization, so that the model learning and inference can be done in one shot,\nmax \u0398={U,\u03b2,\u03c1,W}\n1\nN N\u2211 i=1 Eq(h|xi;W ) [ \u03b2>h\u2212 1 2\u03c12 ( x>i xi + h >U>Uh\u2212 2x>i Uh )\n\u2212h> log \u03c3(W>xi)\u2212 (1\u2212 h)> log(1\u2212 \u03c3(W>xi)) ] .\nIn fact, each term in (7) also has a clear effect: the first term is the expected log-likelihood of observations, containing the Gaussian reconstruction error as the surrogate for neighborhood preservation, while the second term is the entropy of q(h|x) acting like a regularization which avoids wasting bits.\nInterestingly, the Helmholtz variational free energy has close relationship to minimum description length (MDL) principle derived from bits-back coding (Hinton and Van Camp, 1993; Hinton and Zemel, 1994; Gregor et al., 2014). MDL principle is trying to find the representative codes within the prefixed length budget by characterizing the description length of the coding system. Specifically, from information theory, the description length of x given h is \u2212 log p(x|h). With the encoding distribution q(h|x), the bit-back coding description length of h will be \u2212 log p(h) + log q(h|x). Therefore, the expected description length is\nEq(h|x) [\u2212 log p(x, h) + log q(h|x)] := \u2212L(\u0398;x), (8) and thus, 1N \u2211N i=1\u2212L(\u0398;xi) = \u2212H(p, q). Minimizing such objective is equivalent to maximizing H(p, q), and will lead to the codes with shortest description length to represent the data. With such understanding, the Helmholtz variational free energy with the proposed reduced-MRFs indeed achieves the trade-off between requirements i) and ii), while provides a mechanism to complete requirement iii).\nWe emphasize that instead of directly parameterizing the hash function deterministically as h = 1+sign(W >x)\n2 in most existing algorithms, we here parametrize the encoding distribution, q(h|x) = B(\u03c3(W>x)), alternatively. The benefits of such parametrization is significant: besides its elegant and natural derivation from Helmholtz free energy, such formulation help us avoid dealing with binary variables in the optimization by directly optimizing over the distribution space, therefore, bypass the notoriously difficulty in integral programming. The proposed hash function parametrization is also different from the commonly used relaxation h = \u03c3(W>x) \u2208 [0, 1]l. The latter one is inferior since it relaxes the binary constraint, therefore, will introduce extra minima which are infeasible in original binary output space, while we still restrict the hash codes to be binary."}, {"heading": "3 Learning with Doubly Stochastic Neuron", "text": "As introduced in Section 2.2, by maximizing the negative Helmholtz free energy (7), we no longer need to deal with the discrete latent variables directly but their distributions. However, the existing algorithms using either reparametrization trick (Kingma and Welling, 2013) or REINFORCE trick (Mnih and Gregor, 2014) can not be applied straightforwardly to the proposed model. The reparametrization trick suffers from the\ndifficulty with discontinuous objective, whose gradient is not well-defined. The REINFORCE trick suffers from high variance of the stochastic estimator of the gradient,\n\u2207WL = Eq(h|x;W ) [ \u2207W log q(h|x;W )log\nq(h|x;W ) p(x, h)\n] , (9)\nso it converges slowly or might not converge (Bengio et al., 2013; Gu et al., 2015). To remedy these issues, heuristic \u201cpseudo-gradient\u201d estimators based on reparametrization trick (Bengio et al., 2013; Raiko et al., 2014) and variational reduced gradient estimator based on REINFORCE trick (Gregor et al., 2014; Gu et al., 2015) have been proposed. However, the former one is purely heuristic and hard to interpret and the latter one requires complicated extra computation to obtain a biased or unbiased estimator of the gradient. In this section, we provide a simple, unbiased, and theoretically grounded estimator of the gradient with smaller variance. We combine this gradient estimator with stochastic gradient descent (SGD) to achieve the requirement iv), i.e., efficient and scalable learning. We emphasize that this algorithm is generally applicable for integer programming problems and general variational autoencoder with discrete hidden variables, which can be of independent interest."}, {"heading": "3.1 Doubly Stochastic Neuron", "text": "We first introduce doubly stochastic neuron for reparameterizing the Bernoulli distribution B(z), where z \u2208 (0, 1). Given , \u03be \u223c U(0, 1), the doubly stochastic neuron is defined as\nf(z, , \u03be) :=  1 if z > 1z>\u03be if z =\n0 if z <\n. (10)\nNote that P(f(z, , \u03be) = 1) = z, i.e. f(z, , \u03be) \u223c B(z). The name \u201cdoubly stochastic neuron\u201d is due to the fact that it requires two stochastic inputs , \u03be. Comparing to the traditional binary stochastic neuron s1(z, ) = 1z> or s0(z, ) = 1z> with \u223c U(0, 1), the doubly stochastic neuron behaves almost the same except that it outputs randomly when z = . In fact, our doubly stochastic neuron can be considered as a stochastic combination of the binary stochastic neuron s1(z, ) and s0(z, ):\nf(z, , \u03be) =\n{ s1(z, ) if z > \u03be\ns0(z, ) if z < \u03be (11)\nWe will see in section 3.2 that such a slight modification will lead to a significant distinction in the structure of their derivatives and practical performance.\nUsing the above doubly stochastic neuron, we can parametrize the Bernoulli distribution h \u223c B(\u03c3(W>x)) as\nh := f(\u03c3(W>x), , \u03be) = [ f(\u03c3(w>k x), k, \u03bek) ]l k=1\nwhere = [ 1, . . . , l], \u03be = [\u03be1, . . . , \u03bel], and k, \u03bek, k = 1, . . . , l are independently distributed from U(0, 1). Hence, the objective in (7) can be rewritten as\nmax U,\u03b2,\u03c1,W\n1\nN N\u2211 i=1 E ,\u03be [ log p(xi, f(\u03c3(W >xi), , \u03be))\u2212 log q(f(\u03c3(W>xi), , \u03be)|xi) ]\nFor the ease of notations, we simplify the optimization problem as\nmax \u0398={U,\u03b2,\u03c1,W}\n1\nN N\u2211 i=1 Lsn(\u0398;xi) := E ,\u03be[`(f(\u03c3(W>xi), , \u03be))] (12)\nwhere \u0398 = {U, \u03b2, \u03c1,W} is the set of parameters to be determined."}, {"heading": "3.2 Distributional Stochastic Gradient Descent", "text": "Given x randomly sampled from {xi}Ni=1, the stochastic gradient \u2207\u0302U,\u03b2,\u03c1Lsn(\u0398;x) can be easily computed following the vanilla way. However, with the reparameterization, the function Lsn(\u0398;x) is no longer differ-\nentiable with respect to W due to the discontinuity of the stochastic neuron f(z, , \u03be). Namely, the SGD algorithm is not readily applicable. To overcome this difficulty, we will adopt the notion of distributional derivative for generalized functions (a.k.a distributions) (Grubb, 2008). We first briefly revisit the basics of distributional derivative below."}, {"heading": "3.2.1 Distributions and distributional derivative", "text": "Let \u2126 \u2282 Rd be an open set. Denote C\u221e0 (\u2126) or D(\u2126) as the space of the functions that are infinitely differentiable with compact support in \u2126. Let D\u2032(\u2126) be the space of continuous linear functionals on C\u221e0 (\u2126), which can be considered as the dual space. The elements in space D\u2032(\u2126) are often called distributions. We emphasize this definition of distribution is more general than traditional probability distributions.\nDefinition 3 (Grubb, 2008) Let u \u2208 D\u2032(\u2126), then a distribution v is called to be the distributional derivative of u, denoted as v = Du, if it satisfies\u222b\n\u2126\nv\u03c6dx = \u2212 \u222b\n\u2126\nu\u2202\u03c6dx, \u2200\u03c6 \u2208 C\u221e0 (\u2126).\nIndeed, the chain rule of distributional derivative is also valid (Grubb, 2008).\nLemma 4 (Grubb, 2008) Let u \u2208 D\u2032(\u2126), we have\n1. (Chain Rule I) The distribution derivative of v = u \u25e6 f for any f(x) \u2208 C1 : \u2126\u2032 \u2192 \u2126 is given by Dv = Du\u2202f\u2202x .\n2. (Chain Rule II) The distribution derivative of v = f \u25e6 u for any f(x) \u2208 C1(R) with f \u2032 bounded is given by Dv = f \u2032(u)Du.\nRemark. It is straightforward to verify that for given , \u03be, the function f(z, , \u03be) \u2208 D\u2032(\u2126) and moreover, Dzf(z, , \u03be) = \u03b4 (z), which is exactly the Dirac-\u03b4 function."}, {"heading": "3.2.2 Computing distributional derivative of Lsn(\u0398;x)", "text": "Based on the definition of distributional derivatives and chain rules, we are able to compute the distributional derivative the function Lsn(\u0398;x) after reparametrization, which is provided in the following lemma.\nLemma 5 For a given sample x, the distributional derivative of function Lsn(\u0398;x) w.r.t. W is given by DWLsn(\u0398;x) = E\u03be [ \u2207f `(1\u03c3(W>x)>\u03be)\u03c3(W>x) \u2022 (1\u2212 \u03c3(W>x))x> ] . (13) where \u2022 denotes point-wise product.\nProof Let z = \u03c3(WTx), we have\nDzE ,\u03be [`(f(z, , \u03be))] limit theorem (Grubb, 2008) = E\u03be, [Dz`(f(z, , \u03be))]\nchain rule II = E\u03be, [\u2207f `(f(z, , \u03be))Dzf(z, , \u03be)] chain rule I = E\u03be, [\u2207f `(f(z, , \u03be))\u03b4 (z)]\nproperty of \u03b4 function = E\u03be [\u2207f `(f(z, z, \u03be))] , Hence, DWLsn(\u0398, x) = E\u03be [ \u2207f `(f(\u03c3(WTx), \u03c3(WTx), \u03be)) ] \u2207\u03c3(W>x)x>. Plugging in the definition of f and using the fact that \u2207\u03c3(y) = \u03c3(y) \u2022 (1\u2212 \u03c3(y)), leads to the desired result in (13).\nRemark. In contrast, using existing binary stochastic neurons, either s1(z, ) = 1z> or s0(z, ) = 1z> , cannot obtain a meaningful distributional derivative as we do. With similar calculation, we can derive that\nDzE ,\u03be [`(s1(z, , \u03be))] = E [\u2207s1`(s1(z, ))\u03b4 (z)] = \u2207s1`(1),\nAlgorithm 1 Distributional-SGD\nInput: {xi}Ni=1 1: Initialize \u03980 = {W,U, \u03b2, \u03c1} randomly. 2: for i = 1, . . . , t do 3: Sample xi uniformly from {xi}Ni=1. 4: Sample i, \u03bei \u223c U([0, 1]l). 5: Compute \u2207\u0302U,\u03b2,\u03c1Lsn(\u0398i\u22121;xi). 6: Compute \u2207\u0302WLsn(\u0398i\u22121;xi) through the unbiased estimator from (13). 7: Update parameters \u0398i = \u0398i\u22121 + \u03b3i\u2207\u0302\u0398Lsn(\u0398i\u22121;xi). 8: end for\nwhere the gradient of the loss function remains a constant and no longer propagates with the input. Similar phenomenon holds true when using s0(z, ) = 1z> . Therefore, such reparametrization of the Bernoulli distribution could be inferior. Interestingly, the natural stochastic estimator of the distributional derivative we established through doubly stochastic neuron coincides with the heuristic \u201cpsudo-gradient\u201d constructed for s1(z, ) and s0(z, ) in (Raiko et al., 2014). While the authors in the original paper (Raiko et al., 2014) claimed that this is a biased estimator with low variance, our new analysis reveals that such estimator is indeed unbaised and meaningful.\nWe can therefore incorporate such unbiased distributional derivative estimator (13) with stochastic gradient descent algorithm (see e.g., (Nemirovski et al., 2009) and its variants (Kingma and Ba, 2014; Bottou et al., 2016)), which we designate as Distributional SGD. The basic Algorithm is presented in Algorithm 1. Comparing to the existing algorithms for learning to hash which requires substantial effort to solve the optimization with binary variables, e.g., (Carreira-Perpina\u0301n and Raziperchikolaei, 2015), the proposed distributional SGD 1 is much simpler and also amenable to on-line setting (Huang et al., 2013; Leng et al., 2015)."}, {"heading": "3.3 Convergence of Distributional SGD", "text": "One caveat here is that due to the potential discrepancy of the distributional derivative and the traditional gradient, whether the SGD algorithm integrated with distributional derivative converges or not remains unclear in general. However, for our learning to hash problem, one can easily show that the distributional derivative in 3 is indeed the true gradient.\nProposition 6 The distributional derivative DWLsn(\u0398;x) is equivalent to the traditional gradient \u2207WL(\u0398;x). Proof First of all, by definition, we have that Lsn(\u0398;x) = L(\u0398;x). One can easily verify that both DWLsn(\u0398;x) and \u2207WL(\u0398;x) are continuous. Hence, it suffices to show that for any distribution u \u2208 D(\u2126)\u2229C1(\u2126), Du = \u2207u. For any \u03c6 \u2208 C\u221e0 (\u2126), by definition of distributional derivative, we have \u222b \u2126 Du\u03c6dx =\n\u2212 \u222b\n\u2126 u\u2202\u03c6dx. On the other hand, we always have \u222b \u2126 \u2207u\u03c6dx = \u2212 \u222b u\u2202\u03c6dx. Hence, \u222b \u2126\n(Du\u2212\u2207u)\u03c6dx = 0 for all \u03c6 \u2208 C\u221e0 (\u2126). By the Du Bois-Reymond\u2019s lemma (see Lemma 3.2 in (Grubb, 2008)), we have Du = \u2207u.\nConsequently, our distributional SGD algorithm will enjoy same convergence property as the traditional SGD algorithm. Following from Theorem 2.1 in (Ghadimi and Lan, 2013), we arrive at\nTheorem 7 Under some mild conditions, the proposed distributional SGD converges to stationary points, i.e.,\nE [\u2225\u2225\u2225\u2207\u0398 N\u2211 i=1 L(\u0398t;xi) \u2225\u2225\u22252] \u223c O( 1\u221a t ) ,\nwhere \u0398t = {Wt, Ut, \u03b2t, \u03c1t}. It should be emphasized that although both estimator (13) and (9) are unbiased, the estimator in (9) is known to suffer from high variance. Hence, our algorithm is expected to converge faster even without extra variance reduction techniques, e.g., (Gregor et al., 2014; Gu et al., 2015), saving unnecessary computational and memory cost."}, {"heading": "4 Connections", "text": "The proposed stochastic generative hashing is a general framework. In this section, we will reveal the connections to several existing algorithms3. Vector Quantization (VQ). Adding one more constraint to binary code h such that \u2016h\u20161 = 1 and prefixing \u03c1 > 0, the reduced-MRFs model will reduce to vector quantization. Specifically, with such constraint, the binary codes become 1-of-K representations. From the energy function (3), the joint distribution can be rewritten as\np(x, h) \u221d l\u220f\nj=1\n( \u00b5jN (uj , \u03c12I) )hj ,\nwhere \u00b5j = exp(\u03b2j)\u2211l\nj=1 exp(\u03b2j) . Instead of the stochastic linear encoding function, we set q(h|xi) = 1eki (h). Denote\nU = [uj ] l j=1, plug into the objective (7) and ignore the irrelevant terms, we have\nmin U,{ki}Ni=1 N\u2211 i=1 \u2016xi \u2212 Ueki\u20162 = N\u2211 i=1 \u2016xi \u2212 uki\u20162, (14)\nwhich is exactly the objective of vector quantization. Product Quantization (PQ). Product quantization is separating x \u2208 Rd to several nonoverlapping groups, i.e., x = [xm]rm=1, and applying vector quantization to each group. Therefore, if we restrict h = [h\nm]rm=1 with \u2016hm\u20161 = 1, \u2200m = 1, . . . , r, and prefix \u03c1 > 0, by the energy function (3), we have\np(x, h) \u221d r\u220f\nm=1 l/r\u220f j=1 ( \u00b5mj N (umj , \u03c12I) )hmj , where \u00b5mj =\nexp(\u03b2mj )\u2211l/r j=1 exp(\u03b2 m j )\n. Set the q(h|xi) = \u220fr m 1ekm\ni (hm), denote U = [Um]rm=1 with U m = [umj ] l/r j=1, plug\ninto Eq. (7) and ignore the irrelevant terms, we have\nmin {Um,{kmi }Ni=1}rm=1 N\u2211 i=1 r\u2211 m \u2016xmi \u2212 Umekmi \u2016 2, (15)\nwhich is exactly the objective of product quantization (Jegou et al., 2011). Composite Quantization (CQ). Composite quantization can be derived from the proposed reduced-MRFs with extra contraints. Specifically, we separate h to r nonoverlapping groups, i.e., h = [hm]rm=1, and restrict each hm satisfies \u2016hm\u20161 = 1. Moreover, with prefixed \u03c1 > 0, by the potential function (3), we have the joint probability as\np(x, h) \u221d N (Uh, \u03c12I) r\u220f\nm=1 l/r\u220f j=1 (\u00b5mj ) hmj ,\nwhere \u00b5j = exp(\u03b2j)\u2211l\nj=1 exp(\u03b2j) . Parametrize q(h|xi) =\n\u220fr m 1ekm\ni (hm), plug into the objective (7) and ignore the\nirrelevant terms, we have the optimization\nmin {Um,{kmi }Ni=1}rm=1 N\u2211 i=1 \u2225\u2225\u2225xi \u2212 r\u2211 m=1 Umekmi \u2225\u2225\u22252, (16) which is exactly the objective of composite quantization (Zhang et al., 2014b). In fact, to make the optimization easier, extra orthogonality constraints on U have been introduced in (Zhang et al., 2014b). Iterative Quantization (ITQ). If we prefix some \u03c1 > 0, and U = WR where W formed by eigenvectors of the covariance matrix and R is an orthogonal matrix, we have U>U = I. By the potential function (3), we have joint distribution as\np(x, h) \u221d N (WRh, \u03c12I)B(\u03b8). 3in the derivation, we adopt that 0 log 0 = 0.\nParametrize q(h|xi) = 1b(h), plug into the objective (7) and ignore the irrelevant terms, we obtain the optimization\nmin R,b N\u2211 i=1 \u2016xi \u2212WRb\u20162, (17)\nwhich is exactly the objective of iterative quantization (Gong and Lazebnik, 2011). Binary Autoencoder (BA). If we use the deterministic linear encoding function in the reduced-MRFs, i.e., q(h|x) = 1 1+sign(W>x)\n2\n(h), and prefix some \u03c1 > 0, then, ignore the irrelevant terms, the optimization\nreduces to\nmin U,W N\u2211 i=1 \u2225\u2225\u2225xi \u2212 Uh\u2225\u2225\u22252, s.t. h = 1 + sign(W>x) 2 , (18)\nwhich is the objective of binary autoencoder (Carreira-Perpina\u0301n and Raziperchikolaei, 2015). Remark 1: It should be emphasized that in all these derived variants, except the binary autoencoder, the algorithms learned the codes for samples only in the training dataset. This is because the parametrization of the encoding function is lacking of generalization ability to out-of-sample. Therefore, to encode the unseen new query, an optimization involving discrete variables must be solved. Most of the constraints are added to make the optimization easier, however, the flexibility of the model is reduced comparing to the original reduced-MRFs. While in the proposed SGH, the flexibility and efficiency are balanced delicately using the stochastic encoding function. Remark 2: In all these variants, the encoding procedure are deterministic, therefore, the term Eq(h|x) [log q(h|x)] = 0. As we discussed in section 2.2, the entropy term is indeed helpful which performs like a regularization to avoid wasting bits. Moreover, without the stochasticity, the general optimization (18) becomes extremely difficult due to binary constraints on h. While in the proposed algorithm, we exploit the stochasticity to bypass such difficulty in optimization. The stochasticity will enable us to accelerate the optimization as shown in section 5."}, {"heading": "5 Experiments", "text": "In this section, we first justify the benefits of the proposed distributional SGD in terms of convergence speed and computational cost numerically. Then, we demonstrate the generative ability of the reducedMRFs with the codes from the stochastic encoding function. Finally, we evaluate the performance of the proposed stochastic generative hashing (SGH) for both L2NNS and MIPS on several benchmarks. We used the following datasets for different tasks in our experiments, including i), MNIST, which consists of 28 \u00d7 28 grayscale images of handwritten digits from 0 to 9; ii), CIFAR-10, which consists of 32 \u00d7 32 color natural images in 10 categories; iii), SIFT-1M, which contains with high-resolution color images represented by 128 SIFT features; iv), WORD2VEC, which consists of 200-dimensional real-valued vectors, each one representing one word generated by word2vec model (Mikolov et al., 2013) learned from text-8 corpus."}, {"heading": "5.1 Empirical Study of Distributional SGD", "text": "We first demonstrate the convergence of the distributional derivative with Adam (Kingma and Ba, 2014) numerically on MINST and SIFT-1M from 8 bits to 64 bits. The convergence curves are shown in Figure 2 2(a) and (c). We plot the Helmholtz free energy. Obviously, the proposed algorithm converges quickly, no matter how many bits we used. It is reasonable that with more bits, the better model fits the data and the Helmholtz free energy can reduced further.\nIt should be emphasized that the computational cost in each iteration in the proposed distributional SGD is only O(dl). We compare the training time to the most related binary autoencoder hashing (BA) (CarreiraPerpina\u0301n and Raziperchikolaei, 2015) empirically on the machine with Intel Core i7-3770 CPU@3.40GHz\u00d78 and 32GB memory. The empirical comparison is in Figure 2(b) and (d). Obviously, the distributional SGD is significantly efficient than BA which relies on integral programming techniques."}, {"heading": "5.2 Generative Ability of reduced-MRFs", "text": "We first illustrated the learned templates U in the reduced-MRFs in Figure 3. In our model, the particular binary code performs as a switch turning the corresponding template on or off in the generating procedure. It can be seen that the templates form a group of meaningful basis on both MNIST and CIFAR-10. Each template learned from MNIST performs like a stroke, and each template learned from CIFAR-10 performs like a filter.\nTo further demonstrate the generative ability of the reduced-MRFs, we re-generated the images with the learned model with 64 binary codes on MNIST and CIFAR-10. Specifically, given x which randomly sampled from the dataset, we first encode the it into binary representation via the learned q(h|x) by mode, and then, we re-generate an artificial sample from p(x|h) by mean. We also compares with PCA and ITQ for image recovery. The results are shown in Figure 4. The second row is the results from PCA, which is the optimal linear model in terms of square loss. The proposed method and ITQ results are shown in third and fourth row, respectively. Even with 64 binary variables, the proposed model is able to recover the images almost as good as PCA which uses 64 real-valued variables, i.e., 4096 bits, and much better than ITQ. Such performance shows i), the reduced-MRFs is able to characterize the generating procedure; ii), the stochastic encoding function is able to produce representative binary codes, therefore, promoting the\nhashing performance."}, {"heading": "5.3 Retrieval Performance Comparison", "text": "We compared the stochastic generative hashing on both L2NNS and MIPS tasks with several state-ofthe-art unsupervised algorithms, including K-means hashing (KMH) (He et al., 2013), iterative quantization (ITQ) (Gong and Lazebnik, 2011), spectral hashing (SH) (Weiss et al., 2009), spherical hashing (SpH) (Heo et al., 2012), and binary autoencoder (BA) (Carreira-Perpina\u0301n and Raziperchikolaei, 2015). For fair comparison, we set the training time limit to be 104 seconds. In fact, such time setting is more preferable to our competitors, especially BA, since the proposed distributional SGD runs extremely fast. Comparison on L2NNS task. We tested the algorithms on MNIST and SIFT-1M for L2NNS task with the length of binary codes from 16, 32 to 64. For MNIST, we trained the model with 60,000 samples in training set and evaluated the performance with 10,000 test samples. For SIFT-1M, we used 106 samples for training and 10, 000 for testing. We considered the ground-truth as each query\u2019s K = 10 Euclidean nearest neighbors. We conducted the searching via the commonly used Hamming ranking follows (He et al., 2013; Gong and Lazebnik, 2011; Weiss et al., 2009). For each query, we sorted the data according to their Hamming distance and retrieved the first M samples. We evaluated the performances of the algorithms by the recall at the first M Hamming neighbors, which is defined as the ratio of retrieved true nearest neighbors in the total M Hamming neighbors. The performances are illustrated in Figure 5. Moreover, we evaluate the Recall 100@100 with varying bits in Figure 7(a)(b).\nThe SGH outperforms the competitors significantly. It should be emphasized that we give some advantages to KMH in the comparison by exploiting its PQ generalization. Therefore, the KMH can be viewed as the Hamming distance version of PQ algorithm. The BA can be viewed as the deterministic version of the proposed SGH as we discussed in section 4, however, it relies on complicated integer programming to learn the model. As shown in the empirical results, even with hundreds times of running time comparing to the SGH, it still performs worse than SGH, demonstrating the power of the proposed distributional SGD. The empirical study justifies our claim, i.e., the benefits of the proposed SGH come from two aspects: the generative model and the distributional SGD optimization algorithm, where the generative model preserves the neighborhood, and the distributional SGD efficiently learns the parameters by exploiting the stochasticity. Comparison on MIPS task. We tested the algorithm on WORD2VEC dataset for MIPS task. We trained the SGH with 71,291 samples and evaluated the performance with 10,000 query. Since KMH is the Hamming distance generalization of PQ algorithm, for MIPS task, we replace the KMH with PQ. Similarly, we vary the length of binary codes from 16, 32 to 64, and evaluate the performance by Recall 10@M. We calculated the ground-truth via retrieval through the original inner product. The performances are illustrated in Figure 6.\n0 200 400 600 800 1000 M - number of retrieved items\n0\n0.1\n0.2\n0.3\n0.4\n0.5\n0.6\n0.7\n0.8\n0.9\nR ec\nal l\nMNIST 16 bit Recall 10@M\nSGH BA SpH SH ITQ KMH\n0 200 400 600 800 1000 M - number of retrieved items\n0\n0.1\n0.2\n0.3\n0.4\n0.5\n0.6\n0.7\n0.8\n0.9\n1\nR ec\nal l\nMNIST 32 bit Recall 10@M\nSGH BA SpH SH ITQ KMH\n0 200 400 600 800 1000 M - number of retrieved items\n0\n0.1\n0.2\n0.3\n0.4\n0.5\n0.6\n0.7\n0.8\n0.9\n1\nR ec\nal l\nMNIST 64 bit Recall 10@M\nSGH BA SpH SH ITQ KMH\n0 200 400 600 800 1000 M - number of retrieved items\n0\n0.05\n0.1\n0.15\n0.2\n0.25\nR ec\nal l\nSIFT1M 16 bit Recall 10@M SGH BA SpH SH ITQ KMH\n0 200 400 600 800 1000 M - number of retrieved items\n0\n0.1\n0.2\n0.3\n0.4\n0.5\n0.6\nR ec\nal l\nSIFT1M 32 bit Recall 10@M\nSGH BA SpH SH ITQ KMH\n0 200 400 600 800 1000 M - number of retrieved items\n0\n0.1\n0.2\n0.3\n0.4\n0.5\n0.6\n0.7\n0.8\nR ec\nal l\nSIFT-1M 64 bit Recall 10@M\nSGH BA SpH SH ITQ KMH\nFigure 5: L2NNS comparison on MNIST and SIFT-1M with the length of binary bits from 16 to 64. We evaluate the performance with Recall 10@M , where M increasing to 1000.\nWe also evaluate the Recall 100@100 with varying bits in Figure 7(c). The proposed algorithm outperforms the competitors significantly, demonstrating the proposed SGH is also applicable to MIPS task."}, {"heading": "6 Conclusion", "text": "In this paper, we propose a novel approach to learn the stochastic hash function associated with the generative model, reduced-MRFs. We first justify from theoretical aspect that the proposed algorithm is able to provide a good hash function satisfies all the requirements, i.e., preserving both L2 and inner product neighborhood with as short as possible, meanwhile, achieving fast retrieval and fast learning. We design experiments to verify our conclusion, and conduct comparison for both L2NNS and MIPS tasks to justify the advantage of proposed algorithm empirically. We emphasize the proposed generative hashing is a general framework which can be extended to semi-supervised setting and other learning to hash scenarios in Appendix A. Moreover, the proposed doubly stochastic neuron and distributional SGD can be applied to general integral programming problem, and can be of independent interest."}, {"heading": "A Generalization", "text": "We generalize the basic model to translation and scale invariant extension, semi-supervised extension, as well as coding with h \u2208 {\u22121, 1}l.\nA.1 Translation and Scale Invariant Reduced-MRFs\nAs we known, the data may not zero-mean, and the scale of each sample in dataset can be totally different. To eliminate the translation and scale effects, we extend the basic model to translation and scale invariant reduced-MRFs by introducing parameter \u03b1 to separate the translation effect and the latent variable z to model the scale effect in each sample x, therefore, the potential function becomes\nE(x, h, z) = \u2212\u03b2>h+ 1 2\u03c12 (x\u2212 \u03b1\u2212 U>(z \u00b7 h))>(x\u2212 \u03b1\u2212 U>(z \u00b7 h)), (19)\nwhere \u00b7 denotes element-wise product, \u03b1 \u2208 Rd and z \u2208 Rl. Comparing to (3), we replace U>h with U>(z \u00b7 h) + \u03b1 so that the translation and scale effects in both dimension and sample are modeled explicitly.\nWe treat the \u03b1 as parameters and z as latent variable. Assume the independence in posterior for computational efficiency, we approximate the posterior p(z, h|x) with q(h|x;Wh)q(z|x;Wz), where Wh,Wz denotes the parameters in the posterior approximator. With similar derivation, we obtain the learning objective as\nmax U,\u03b1,\u03b2,\u03c1;Wh,Wz\n1\nN N\u2211 i=1 Eq(h|xi)q(z|xi) [\u2212E(x, h, z)\u2212 log q(h|xi)\u2212 log q(z|xi)] . (20)\nObviously, the proposed distributional SGD is still applicable to this optimization.\nA.2 Semi-supervised Extension\nAlthough we only focus on learning the hash function in unsupervised setting, the proposed model can be easily extended to exploit the supervision information by introducing pairwise model, e.g., (Zhang et al., 2014a; Zhu et al., 2016). Specifically, we are provided the (partial) supervision information for some pairs of data, i.e., S = {xi, xi, yij}Mi,j , where\nyij = { 1 if xi \u2208 NN (xj) or xj \u2208 NN (xi) 0 o.w. ,\nand NN (x) stands for the set of nearest neighbors of x. Besides the original Gaussian reconstruction model in the basic model in (3), we introduce the pairwise model p(yij |hi, hj) = B(\u03c3(h>i hj)) into the framework, which results the joint distribution over x, y, h as p(xi, xj , hi, hj , yij) = p(xi|hi)p(xj |hj)p(hi)p(hj)p(yij |hi, hj)1S(ij), where 1S(ij) is an indicator that outputs 1 when (xi, xj) \u2208 S, otherwise 0. Plug the extended model into the Helmholtz free energy, we have the learning objective as,\nmax U,\u03b2,\u03c1;W\n1\nN2 N2\u2211 i,j=1\n( Eq(hi|xi)q(hj |xj) [log p(xi, xj , hi, hj)] + Eq(hi|xi)q(hj |xj) [1S(ij) log p(yij |hi, hj)] \u2212Eq(hi|xi)q(hj |xi) [log q(hj |xj)q(hj |xi)] ) ,\nObviously, the proposed distributional SGD is still applicable to the semi-supervised extension.\nA.3 {\u00b11}-Binary Coding In the main text, we mainly focus on coding with {0, 1}. In fact, the proposed model is applicable to coding with {\u22121, 1} with minor modification. Moreover, the proposed distributional SGD is still applicable. We only discuss the basic model here, the model can also be extended to scale-invariant and semi-supervised variants.\nIf we set h \u2208 {\u22121, 1}l, the potential function of basic reduced-MRFs (3) does not have any change, i.e.,\nE(x, h) = \u2212\u03b2>h+ 1 2\u03c12\n( x>x+ h>U>Uh\u2212 2x>Uh ) . (21)\nWe need to modify the parametrization of q(h|x) as\nq(h|x) = l\u220f i=1 \u03c3(w>i x) 1+hi 2 ( 1\u2212 \u03c3(w>i x) ) 1\u2212hi 2 . (22)\nTherefore, the doubly stochastic neuron becomes\nf(z, , \u03be) :=  1 if \u03c3(z) >\n2\u00d7 1\u03c3(z)>\u03be \u2212 1 if \u03c3(z) = \u22121 if \u03c3(z) < .\nWith similar derivation, we have the distributional derivative of the objective w.r.t. W as \u2207WLsn = 2E\u03be [ \u2207f `(f(z, \u03c3(z), \u03be))\u2207z\u03c3(z)x> ] . (23) Plug these modification into the model and algorithm, we can learn a {\u22121, 1}-encoding function."}], "references": [{"title": "Provable bayesian inference via particle mirror descent", "author": ["Bo Dai", "Niao He", "Hanjun Dai", "Le Song"], "venue": "In Proceedings of the 19th International Conference on Artificial Intelligence and Statistics,", "citeRegEx": "Dai et al\\.,? \\Q2016\\E", "shortCiteRegEx": "Dai et al\\.", "year": 2016}, {"title": "Stochastic first-and zeroth-order methods for nonconvex stochastic programming", "author": ["Saeed Ghadimi", "Guanghui Lan"], "venue": "SIAM Journal on Optimization,", "citeRegEx": "Ghadimi and Lan.,? \\Q2013\\E", "shortCiteRegEx": "Ghadimi and Lan.", "year": 2013}, {"title": "Similarity search in high dimensions via hashing", "author": ["Aristides Gionis", "Piotr Indyk", "Rajeev Motwani"], "venue": "In VLDB,", "citeRegEx": "Gionis et al\\.,? \\Q1999\\E", "shortCiteRegEx": "Gionis et al\\.", "year": 1999}, {"title": "Iterative quantization: A procrustean approach to learning binary codes", "author": ["Yunchao Gong", "Svetlana Lazebnik"], "venue": "In Computer Vision and Pattern Recognition (CVPR),", "citeRegEx": "Gong and Lazebnik.,? \\Q2011\\E", "shortCiteRegEx": "Gong and Lazebnik.", "year": 2011}, {"title": "Learning binary codes for highdimensional data using bilinear projections", "author": ["Yunchao Gong", "Sanjiv Kumar", "Henry A Rowley", "Svetlana Lazebnik"], "venue": "In Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition,", "citeRegEx": "Gong et al\\.,? \\Q2013\\E", "shortCiteRegEx": "Gong et al\\.", "year": 2013}, {"title": "Deep autoregressive networks", "author": ["Karol Gregor", "Ivo Danihelka", "Andriy Mnih", "Charles Blundell", "Daan Wierstra"], "venue": "In Proceedings of The 31st International Conference on Machine Learning,", "citeRegEx": "Gregor et al\\.,? \\Q2014\\E", "shortCiteRegEx": "Gregor et al\\.", "year": 2014}, {"title": "Distributions and operators, volume 252", "author": ["Gerd Grubb"], "venue": "Springer Science & Business Media,", "citeRegEx": "Grubb.,? \\Q2008\\E", "shortCiteRegEx": "Grubb.", "year": 2008}, {"title": "Muprop: Unbiased backpropagation for stochastic neural networks", "author": ["Shixiang Gu", "Sergey Levine", "Ilya Sutskever", "Andriy Mnih"], "venue": "arXiv preprint arXiv:1511.05176,", "citeRegEx": "Gu et al\\.,? \\Q2015\\E", "shortCiteRegEx": "Gu et al\\.", "year": 2015}, {"title": "Quantization based fast inner product search", "author": ["Ruiqi Guo", "Sanjiv Kumar", "Krzysztof Choromanski", "David Simcha"], "venue": "arXiv preprint arXiv:1509.01469,", "citeRegEx": "Guo et al\\.,? \\Q2015\\E", "shortCiteRegEx": "Guo et al\\.", "year": 2015}, {"title": "K-means hashing: An affinity-preserving quantization method for learning binary compact codes", "author": ["Kaiming He", "Fang Wen", "Jian Sun"], "venue": "In Proceedings of the IEEE conference on computer vision and pattern recognition,", "citeRegEx": "He et al\\.,? \\Q2013\\E", "shortCiteRegEx": "He et al\\.", "year": 2013}, {"title": "Spherical hashing", "author": ["Jae-Pil Heo", "Youngwoon Lee", "Junfeng He", "Shih-Fu Chang", "Sung-Eui Yoon"], "venue": "In Computer Vision and Pattern Recognition (CVPR),", "citeRegEx": "Heo et al\\.,? \\Q2012\\E", "shortCiteRegEx": "Heo et al\\.", "year": 2012}, {"title": "Training products of experts by minimizing contrastive divergence", "author": ["Geoffrey E Hinton"], "venue": "Neural computation,", "citeRegEx": "Hinton.,? \\Q2002\\E", "shortCiteRegEx": "Hinton.", "year": 2002}, {"title": "Keeping the neural networks simple by minimizing the description length of the weights", "author": ["Geoffrey E Hinton", "Drew Van Camp"], "venue": "In Proceedings of the sixth annual conference on Computational learning theory,", "citeRegEx": "Hinton and Camp.,? \\Q1993\\E", "shortCiteRegEx": "Hinton and Camp.", "year": 1993}, {"title": "Autoencoders, minimum description length and helmholtz free energy", "author": ["Geoffrey E Hinton", "Richard S Zemel"], "venue": "In Advances in Neural Information Processing Systems,", "citeRegEx": "Hinton and Zemel.,? \\Q1994\\E", "shortCiteRegEx": "Hinton and Zemel.", "year": 1994}, {"title": "Online hashing. In Proceedings of the Twenty-Third international joint conference on Artificial Intelligence, pages 1422\u20131428", "author": ["Long-Kai Huang", "Qiang Yang", "Wei-Shi Zheng"], "venue": null, "citeRegEx": "Huang et al\\.,? \\Q2013\\E", "shortCiteRegEx": "Huang et al\\.", "year": 2013}, {"title": "Approximate nearest neighbors: towards removing the curse of dimensionality", "author": ["Piotr Indyk", "Rajeev Motwani"], "venue": "In Proceedings of the thirtieth annual ACM symposium on Theory of computing,", "citeRegEx": "Indyk and Motwani.,? \\Q1998\\E", "shortCiteRegEx": "Indyk and Motwani.", "year": 1998}, {"title": "Aggregating local descriptors into a compact image representation", "author": ["Herv\u00e9 J\u00e9gou", "Matthijs Douze", "Cordelia Schmid", "Patrick P\u00e9rez"], "venue": "In Computer Vision and Pattern Recognition (CVPR),", "citeRegEx": "J\u00e9gou et al\\.,? \\Q2010\\E", "shortCiteRegEx": "J\u00e9gou et al\\.", "year": 2010}, {"title": "Product quantization for nearest neighbor search", "author": ["Herve Jegou", "Matthijs Douze", "Cordelia Schmid"], "venue": "IEEE transactions on pattern analysis and machine intelligence,", "citeRegEx": "Jegou et al\\.,? \\Q2011\\E", "shortCiteRegEx": "Jegou et al\\.", "year": 2011}, {"title": "Adam: A method for stochastic optimization", "author": ["Diederik Kingma", "Jimmy Ba"], "venue": "arXiv preprint arXiv:1412.6980,", "citeRegEx": "Kingma and Ba.,? \\Q2014\\E", "shortCiteRegEx": "Kingma and Ba.", "year": 2014}, {"title": "Auto-encoding variational bayes", "author": ["Diederik P Kingma", "Max Welling"], "venue": "arXiv preprint arXiv:1312.6114,", "citeRegEx": "Kingma and Welling.,? \\Q2013\\E", "shortCiteRegEx": "Kingma and Welling.", "year": 2013}, {"title": "Learning multiple layers of features from tiny images", "author": ["Alex Krizhevsky"], "venue": null, "citeRegEx": "Krizhevsky.,? \\Q2009\\E", "shortCiteRegEx": "Krizhevsky.", "year": 2009}, {"title": "Online sketching hashing", "author": ["Cong Leng", "Jiaxiang Wu", "Jian Cheng", "Xiao Bai", "Hanqing Lu"], "venue": "In 2015 IEEE Conference on Computer Vision and Pattern Recognition (CVPR),", "citeRegEx": "Leng et al\\.,? \\Q2015\\E", "shortCiteRegEx": "Leng et al\\.", "year": 2015}, {"title": "Hashing with graphs", "author": ["Wei Liu", "Jun Wang", "Sanjiv Kumar", "Shih-Fu Chang"], "venue": "In Proceedings of the 28th international conference on machine learning", "citeRegEx": "Liu et al\\.,? \\Q2011\\E", "shortCiteRegEx": "Liu et al\\.", "year": 2011}, {"title": "Modeling pixel means and covariances using factorized thirdorder boltzmann machines", "author": ["Ranzato Marc\u2019Aurelio", "E Hinton Geoffrey"], "venue": "In Computer Vision and Pattern Recognition (CVPR),", "citeRegEx": "Marc.Aurelio and Geoffrey.,? \\Q2010\\E", "shortCiteRegEx": "Marc.Aurelio and Geoffrey.", "year": 2010}, {"title": "Efficient estimation of word representations in vector space", "author": ["Tomas Mikolov", "Kai Chen", "Greg Corrado", "Jeffrey Dean"], "venue": "arXiv preprint arXiv:1301.3781,", "citeRegEx": "Mikolov et al\\.,? \\Q2013\\E", "shortCiteRegEx": "Mikolov et al\\.", "year": 2013}, {"title": "Neural variational inference and learning in belief networks", "author": ["Andriy Mnih", "Karol Gregor"], "venue": "arXiv preprint arXiv:1402.0030,", "citeRegEx": "Mnih and Gregor.,? \\Q2014\\E", "shortCiteRegEx": "Mnih and Gregor.", "year": 2014}, {"title": "An nmf perspective on binary hashing", "author": ["Lopamudra Mukherjee", "Sathya N Ravi", "Vamsi K Ithapu", "Tyler Holmes", "Vikas Singh"], "venue": "In Proceedings of the IEEE International Conference on Computer Vision,", "citeRegEx": "Mukherjee et al\\.,? \\Q2015\\E", "shortCiteRegEx": "Mukherjee et al\\.", "year": 2015}, {"title": "Robust stochastic approximation approach to stochastic programming", "author": ["Arkadi Nemirovski", "Anatoli Juditsky", "Guanghui Lan", "Alexander Shapiro"], "venue": "SIAM Journal on optimization,", "citeRegEx": "Nemirovski et al\\.,? \\Q2009\\E", "shortCiteRegEx": "Nemirovski et al\\.", "year": 2009}, {"title": "Techniques for learning binary stochastic feedforward neural networks", "author": ["Tapani Raiko", "Mathias Berglund", "Guillaume Alain", "Laurent Dinh"], "venue": "arXiv preprint arXiv:1406.2989,", "citeRegEx": "Raiko et al\\.,? \\Q2014\\E", "shortCiteRegEx": "Raiko et al\\.", "year": 2014}, {"title": "Learning binary codes for maximum inner product search", "author": ["Fumin Shen", "Wei Liu", "Shaoting Zhang", "Yang Yang", "Heng Tao Shen"], "venue": "In 2015 IEEE International Conference on Computer Vision (ICCV),", "citeRegEx": "Shen et al\\.,? \\Q2015\\E", "shortCiteRegEx": "Shen et al\\.", "year": 2015}, {"title": "Video google: A text retrieval approach to object matching in videos", "author": ["Josef Sivic", "Andrew Zisserman"], "venue": "In Computer Vision,", "citeRegEx": "Sivic and Zisserman.,? \\Q2003\\E", "shortCiteRegEx": "Sivic and Zisserman.", "year": 2003}, {"title": "Small codes and large image databases for recognition", "author": ["Antonio Torralba", "Rob Fergus", "Yair Weiss"], "venue": "In Computer Vision and Pattern Recognition,", "citeRegEx": "Torralba et al\\.,? \\Q2008\\E", "shortCiteRegEx": "Torralba et al\\.", "year": 2008}, {"title": "Hashing for similarity search: A survey", "author": ["Jingdong Wang", "Heng Tao Shen", "Jingkuan Song", "Jianqiu Ji"], "venue": "arXiv preprint arXiv:1408.2927,", "citeRegEx": "Wang et al\\.,? \\Q2014\\E", "shortCiteRegEx": "Wang et al\\.", "year": 2014}, {"title": "Spectral hashing", "author": ["Yair Weiss", "Antonio Torralba", "Rob Fergus"], "venue": "In Advances in neural information processing systems,", "citeRegEx": "Weiss et al\\.,? \\Q2009\\E", "shortCiteRegEx": "Weiss et al\\.", "year": 2009}, {"title": "Bayesian conditionalisation and the principle of minimum information", "author": ["P.M. Williams"], "venue": "British Journal for the Philosophy of Science,", "citeRegEx": "Williams.,? \\Q1980\\E", "shortCiteRegEx": "Williams.", "year": 1980}, {"title": "Circulant binary embedding", "author": ["Felix X Yu", "Sanjiv Kumar", "Yunchao Gong", "Shih-Fu Chang"], "venue": "In International conference on machine learning,", "citeRegEx": "Yu et al\\.,? \\Q2014\\E", "shortCiteRegEx": "Yu et al\\.", "year": 2014}, {"title": "Optimal Information Processing and Bayes\u2019s Theorem", "author": ["Arnold Zellner"], "venue": "The American Statistician,", "citeRegEx": "Zellner.,? \\Q1988\\E", "shortCiteRegEx": "Zellner.", "year": 1988}, {"title": "Supervised hashing with latent factor models", "author": ["Peichao Zhang", "Wei Zhang", "Wu-Jun Li", "Minyi Guo"], "venue": "In Proceedings of the 37th international ACM SIGIR conference on Research & development in information retrieval,", "citeRegEx": "Zhang et al\\.,? \\Q2014\\E", "shortCiteRegEx": "Zhang et al\\.", "year": 2014}, {"title": "Composite quantization for approximate nearest neighbor search", "author": ["Ting Zhang", "Chao Du", "Jingdong Wang"], "venue": "In Proceedings of the 31st International Conference on Machine Learning", "citeRegEx": "Zhang et al\\.,? \\Q2014\\E", "shortCiteRegEx": "Zhang et al\\.", "year": 2014}, {"title": "Deep hashing network for efficient similarity retrieval", "author": ["Han Zhu", "Mingsheng Long", "Jianmin Wang", "Yue Cao"], "venue": "In Thirtieth AAAI Conference on Artificial Intelligence,", "citeRegEx": "Zhu et al\\.,? \\Q2016\\E", "shortCiteRegEx": "Zhu et al\\.", "year": 2016}, {"title": "2016). Specifically, we are provided the (partial) supervision information for some pairs of data", "author": ["2014a", "Zhu"], "venue": null, "citeRegEx": "2014a and Zhu,? \\Q2016\\E", "shortCiteRegEx": "2014a and Zhu", "year": 2016}], "referenceMentions": [{"referenceID": 15, "context": "Using hashing for similarity searching has been popularized by influential works such as Locality Sensitive Hashing (Indyk and Motwani, 1998; Gionis et al., 1999), and has been applied towards computer vision tasks such as large scale image retrieval (Torralba et al.", "startOffset": 116, "endOffset": 162}, {"referenceID": 2, "context": "Using hashing for similarity searching has been popularized by influential works such as Locality Sensitive Hashing (Indyk and Motwani, 1998; Gionis et al., 1999), and has been applied towards computer vision tasks such as large scale image retrieval (Torralba et al.", "startOffset": 116, "endOffset": 162}, {"referenceID": 31, "context": ", 1999), and has been applied towards computer vision tasks such as large scale image retrieval (Torralba et al., 2008; J\u00e9gou et al., 2010) and video retrieval (Sivic and Zisserman, 2003).", "startOffset": 96, "endOffset": 139}, {"referenceID": 16, "context": ", 1999), and has been applied towards computer vision tasks such as large scale image retrieval (Torralba et al., 2008; J\u00e9gou et al., 2010) and video retrieval (Sivic and Zisserman, 2003).", "startOffset": 96, "endOffset": 139}, {"referenceID": 30, "context": ", 2010) and video retrieval (Sivic and Zisserman, 2003).", "startOffset": 28, "endOffset": 55}, {"referenceID": 32, "context": "It is well recognized that the data-dependent hash functions perform better (Wang et al., 2014).", "startOffset": 76, "endOffset": 95}, {"referenceID": 3, "context": "Many works have since then focused on learning hash functions or the binary codes for either L2NNS or MIPS, including iterative quantization (Gong and Lazebnik, 2011), spectral hashing (Weiss et al.", "startOffset": 141, "endOffset": 166}, {"referenceID": 33, "context": "Many works have since then focused on learning hash functions or the binary codes for either L2NNS or MIPS, including iterative quantization (Gong and Lazebnik, 2011), spectral hashing (Weiss et al., 2009), product quantization (Jegou et al.", "startOffset": 185, "endOffset": 205}, {"referenceID": 17, "context": ", 2009), product quantization (Jegou et al., 2011), binary autoencoder (Carreira-Perpin\u00e1n and Raziperchikolaei, 2015), and many others (Liu et al.", "startOffset": 30, "endOffset": 50}, {"referenceID": 22, "context": ", 2011), binary autoencoder (Carreira-Perpin\u00e1n and Raziperchikolaei, 2015), and many others (Liu et al., 2011; Gong et al., 2013; Yu et al., 2014; Shen et al., 2015; Guo et al., 2015).", "startOffset": 92, "endOffset": 183}, {"referenceID": 4, "context": ", 2011), binary autoencoder (Carreira-Perpin\u00e1n and Raziperchikolaei, 2015), and many others (Liu et al., 2011; Gong et al., 2013; Yu et al., 2014; Shen et al., 2015; Guo et al., 2015).", "startOffset": 92, "endOffset": 183}, {"referenceID": 35, "context": ", 2011), binary autoencoder (Carreira-Perpin\u00e1n and Raziperchikolaei, 2015), and many others (Liu et al., 2011; Gong et al., 2013; Yu et al., 2014; Shen et al., 2015; Guo et al., 2015).", "startOffset": 92, "endOffset": 183}, {"referenceID": 29, "context": ", 2011), binary autoencoder (Carreira-Perpin\u00e1n and Raziperchikolaei, 2015), and many others (Liu et al., 2011; Gong et al., 2013; Yu et al., 2014; Shen et al., 2015; Guo et al., 2015).", "startOffset": 92, "endOffset": 183}, {"referenceID": 8, "context": ", 2011), binary autoencoder (Carreira-Perpin\u00e1n and Raziperchikolaei, 2015), and many others (Liu et al., 2011; Gong et al., 2013; Yu et al., 2014; Shen et al., 2015; Guo et al., 2015).", "startOffset": 92, "endOffset": 183}, {"referenceID": 35, "context": "For example, iterative quantization and its variants (Yu et al., 2014; Gong et al., 2013) introduce structure and orthogonality constraints on the parameters, and the vector quantization and its generalization, e.", "startOffset": 53, "endOffset": 89}, {"referenceID": 4, "context": "For example, iterative quantization and its variants (Yu et al., 2014; Gong et al., 2013) introduce structure and orthogonality constraints on the parameters, and the vector quantization and its generalization, e.", "startOffset": 53, "endOffset": 89}, {"referenceID": 17, "context": ", product quantization (Jegou et al., 2011) and composite quantization (Zhang et al.", "startOffset": 23, "endOffset": 43}, {"referenceID": 33, "context": ", the graph-based hashing (Weiss et al., 2009; Liu et al., 2011), or use penalty or augmented Lagrangian method to separate the binary variables, e.", "startOffset": 26, "endOffset": 64}, {"referenceID": 22, "context": ", the graph-based hashing (Weiss et al., 2009; Liu et al., 2011), or use penalty or augmented Lagrangian method to separate the binary variables, e.", "startOffset": 26, "endOffset": 64}, {"referenceID": 26, "context": ", NMF-based hashing (Mukherjee et al., 2015), binary autoencoder (Carreira-Perpin\u00e1n and Raziperchikolaei, 2015).", "startOffset": 20, "endOffset": 44}, {"referenceID": 32, "context": "1 Main Contribution As demonstrated in previous literatures such as (Wang et al., 2014), a good hash function learned from data should generate binary codes which i) preserve the neighborhood in original dataset; while ii) as short as possible.", "startOffset": 68, "endOffset": 87}, {"referenceID": 27, "context": "Then, we extend the stochastic gradient descent algorithm (Nemirovski et al., 2009) with distributional derivative (Grubb, 2008) to deal with the discontinuity in the reparametrization.", "startOffset": 58, "endOffset": 83}, {"referenceID": 6, "context": ", 2009) with distributional derivative (Grubb, 2008) to deal with the discontinuity in the reparametrization.", "startOffset": 39, "endOffset": 52}, {"referenceID": 1, "context": "Equipped with these new tools, we can directly target on the optimization containing discrete variables without relaxation and still achieve convergence in both static or online setting (Ghadimi and Lan, 2013).", "startOffset": 186, "endOffset": 209}, {"referenceID": 3, "context": ", vector quantization, iterative quantization (Gong and Lazebnik, 2011), product quantization (Jegou et al.", "startOffset": 46, "endOffset": 71}, {"referenceID": 17, "context": ", vector quantization, iterative quantization (Gong and Lazebnik, 2011), product quantization (Jegou et al., 2011), and composition quantization (Zhang et al.", "startOffset": 94, "endOffset": 114}, {"referenceID": 6, "context": "1 Reduced Gaussian-Markov Random Fields We first propose the basic model, in which the generating process is characterized by the joint distribution for x \u2208 R, h \u2208 {0, 1}, 2The distributional derivative is defined in (Grubb, 2008) and will be introduced in section 3.", "startOffset": 217, "endOffset": 230}, {"referenceID": 20, "context": "Even with such shared structure in the architecture, this model is still more flexible than Gaussian-Bernoulli restricted Boltzmann machines (GRBMs) (Krizhevsky, 2009; Marc\u2019Aurelio and Geoffrey, 2010).", "startOffset": 149, "endOffset": 200}, {"referenceID": 23, "context": "Even with such shared structure in the architecture, this model is still more flexible than Gaussian-Bernoulli restricted Boltzmann machines (GRBMs) (Krizhevsky, 2009; Marc\u2019Aurelio and Geoffrey, 2010).", "startOffset": 149, "endOffset": 200}, {"referenceID": 11, "context": "Directly applying the off-the-shelf Contrastive Divergence (CD) algorithm (Hinton, 2002) will result unacceptable computation cost.", "startOffset": 74, "endOffset": 88}, {"referenceID": 19, "context": "We provide a solution bypassing these difficulties inspired by recent work variational auto-encoder (Kingma and Welling, 2013; Mnih and Gregor, 2014; Gregor et al., 2014),.", "startOffset": 100, "endOffset": 170}, {"referenceID": 25, "context": "We provide a solution bypassing these difficulties inspired by recent work variational auto-encoder (Kingma and Welling, 2013; Mnih and Gregor, 2014; Gregor et al., 2014),.", "startOffset": 100, "endOffset": 170}, {"referenceID": 5, "context": "We provide a solution bypassing these difficulties inspired by recent work variational auto-encoder (Kingma and Welling, 2013; Mnih and Gregor, 2014; Gregor et al., 2014),.", "startOffset": 100, "endOffset": 170}, {"referenceID": 34, "context": "The key insight is that when fixing the model p(x, h), the posterior is the solution of an optimization maximizing the negative Helmholtz variational free energy (Williams, 1980; Zellner, 1988; Dai et al., 2016), i.", "startOffset": 162, "endOffset": 211}, {"referenceID": 36, "context": "The key insight is that when fixing the model p(x, h), the posterior is the solution of an optimization maximizing the negative Helmholtz variational free energy (Williams, 1980; Zellner, 1988; Dai et al., 2016), i.", "startOffset": 162, "endOffset": 211}, {"referenceID": 0, "context": "The key insight is that when fixing the model p(x, h), the posterior is the solution of an optimization maximizing the negative Helmholtz variational free energy (Williams, 1980; Zellner, 1988; Dai et al., 2016), i.", "startOffset": 162, "endOffset": 211}, {"referenceID": 13, "context": "Interestingly, the Helmholtz variational free energy has close relationship to minimum description length (MDL) principle derived from bits-back coding (Hinton and Van Camp, 1993; Hinton and Zemel, 1994; Gregor et al., 2014).", "startOffset": 152, "endOffset": 224}, {"referenceID": 5, "context": "Interestingly, the Helmholtz variational free energy has close relationship to minimum description length (MDL) principle derived from bits-back coding (Hinton and Van Camp, 1993; Hinton and Zemel, 1994; Gregor et al., 2014).", "startOffset": 152, "endOffset": 224}, {"referenceID": 19, "context": "However, the existing algorithms using either reparametrization trick (Kingma and Welling, 2013) or REINFORCE trick (Mnih and Gregor, 2014) can not be applied straightforwardly to the proposed model.", "startOffset": 70, "endOffset": 96}, {"referenceID": 25, "context": "However, the existing algorithms using either reparametrization trick (Kingma and Welling, 2013) or REINFORCE trick (Mnih and Gregor, 2014) can not be applied straightforwardly to the proposed model.", "startOffset": 116, "endOffset": 139}, {"referenceID": 7, "context": "so it converges slowly or might not converge (Bengio et al., 2013; Gu et al., 2015).", "startOffset": 45, "endOffset": 83}, {"referenceID": 28, "context": "To remedy these issues, heuristic \u201cpseudo-gradient\u201d estimators based on reparametrization trick (Bengio et al., 2013; Raiko et al., 2014) and variational reduced gradient estimator based on REINFORCE trick (Gregor et al.", "startOffset": 96, "endOffset": 137}, {"referenceID": 5, "context": ", 2014) and variational reduced gradient estimator based on REINFORCE trick (Gregor et al., 2014; Gu et al., 2015) have been proposed.", "startOffset": 76, "endOffset": 114}, {"referenceID": 7, "context": ", 2014) and variational reduced gradient estimator based on REINFORCE trick (Gregor et al., 2014; Gu et al., 2015) have been proposed.", "startOffset": 76, "endOffset": 114}, {"referenceID": 6, "context": "a distributions) (Grubb, 2008).", "startOffset": 17, "endOffset": 30}, {"referenceID": 6, "context": "Definition 3 (Grubb, 2008) Let u \u2208 D\u2032(\u03a9), then a distribution v is called to be the distributional derivative of u, denoted as v = Du, if it satisfies \u222b", "startOffset": 13, "endOffset": 26}, {"referenceID": 6, "context": "Indeed, the chain rule of distributional derivative is also valid (Grubb, 2008).", "startOffset": 66, "endOffset": 79}, {"referenceID": 6, "context": "Lemma 4 (Grubb, 2008) Let u \u2208 D\u2032(\u03a9), we have 1.", "startOffset": 8, "endOffset": 21}, {"referenceID": 6, "context": "Proof Let z = \u03c3(Wx), we have DzE ,\u03be [`(f(z, , \u03be))] limit theorem (Grubb, 2008) = E\u03be, [Dz`(f(z, , \u03be))] chain rule II = E\u03be, [\u2207f `(f(z, , \u03be))Dzf(z, , \u03be)] chain rule I = E\u03be, [\u2207f `(f(z, , \u03be))\u03b4 (z)] property of \u03b4 function = E\u03be [\u2207f `(f(z, z, \u03be))] , Hence, DWLsn(\u0398, x) = E\u03be [ \u2207f `(f(\u03c3(Wx), \u03c3(Wx), \u03be)) ] \u2207\u03c3(W>x)x>.", "startOffset": 65, "endOffset": 78}, {"referenceID": 28, "context": "Interestingly, the natural stochastic estimator of the distributional derivative we established through doubly stochastic neuron coincides with the heuristic \u201cpsudo-gradient\u201d constructed for s1(z, ) and s0(z, ) in (Raiko et al., 2014).", "startOffset": 214, "endOffset": 234}, {"referenceID": 28, "context": "While the authors in the original paper (Raiko et al., 2014) claimed that this is a biased estimator with low variance, our new analysis reveals that such estimator is indeed unbaised and meaningful.", "startOffset": 40, "endOffset": 60}, {"referenceID": 27, "context": ", (Nemirovski et al., 2009) and its variants (Kingma and Ba, 2014; Bottou et al.", "startOffset": 2, "endOffset": 27}, {"referenceID": 18, "context": ", 2009) and its variants (Kingma and Ba, 2014; Bottou et al., 2016)), which we designate as Distributional SGD.", "startOffset": 25, "endOffset": 67}, {"referenceID": 14, "context": ", (Carreira-Perpin\u00e1n and Raziperchikolaei, 2015), the proposed distributional SGD 1 is much simpler and also amenable to on-line setting (Huang et al., 2013; Leng et al., 2015).", "startOffset": 137, "endOffset": 176}, {"referenceID": 21, "context": ", (Carreira-Perpin\u00e1n and Raziperchikolaei, 2015), the proposed distributional SGD 1 is much simpler and also amenable to on-line setting (Huang et al., 2013; Leng et al., 2015).", "startOffset": 137, "endOffset": 176}, {"referenceID": 6, "context": "2 in (Grubb, 2008)), we have Du = \u2207u.", "startOffset": 5, "endOffset": 18}, {"referenceID": 1, "context": "1 in (Ghadimi and Lan, 2013), we arrive at Theorem 7 Under some mild conditions, the proposed distributional SGD converges to stationary points, i.", "startOffset": 5, "endOffset": 28}, {"referenceID": 5, "context": ", (Gregor et al., 2014; Gu et al., 2015), saving unnecessary computational and memory cost.", "startOffset": 2, "endOffset": 40}, {"referenceID": 7, "context": ", (Gregor et al., 2014; Gu et al., 2015), saving unnecessary computational and memory cost.", "startOffset": 2, "endOffset": 40}, {"referenceID": 17, "context": "which is exactly the objective of product quantization (Jegou et al., 2011).", "startOffset": 55, "endOffset": 75}, {"referenceID": 3, "context": "which is exactly the objective of iterative quantization (Gong and Lazebnik, 2011).", "startOffset": 57, "endOffset": 82}, {"referenceID": 24, "context": "We used the following datasets for different tasks in our experiments, including i), MNIST, which consists of 28 \u00d7 28 grayscale images of handwritten digits from 0 to 9; ii), CIFAR-10, which consists of 32 \u00d7 32 color natural images in 10 categories; iii), SIFT-1M, which contains with high-resolution color images represented by 128 SIFT features; iv), WORD2VEC, which consists of 200-dimensional real-valued vectors, each one representing one word generated by word2vec model (Mikolov et al., 2013) learned from text-8 corpus.", "startOffset": 477, "endOffset": 499}, {"referenceID": 18, "context": "1 Empirical Study of Distributional SGD We first demonstrate the convergence of the distributional derivative with Adam (Kingma and Ba, 2014) numerically on MINST and SIFT-1M from 8 bits to 64 bits.", "startOffset": 120, "endOffset": 141}, {"referenceID": 9, "context": "3 Retrieval Performance Comparison We compared the stochastic generative hashing on both L2NNS and MIPS tasks with several state-ofthe-art unsupervised algorithms, including K-means hashing (KMH) (He et al., 2013), iterative quantization (ITQ) (Gong and Lazebnik, 2011), spectral hashing (SH) (Weiss et al.", "startOffset": 196, "endOffset": 213}, {"referenceID": 3, "context": ", 2013), iterative quantization (ITQ) (Gong and Lazebnik, 2011), spectral hashing (SH) (Weiss et al.", "startOffset": 38, "endOffset": 63}, {"referenceID": 33, "context": ", 2013), iterative quantization (ITQ) (Gong and Lazebnik, 2011), spectral hashing (SH) (Weiss et al., 2009), spherical hashing (SpH) (Heo et al.", "startOffset": 87, "endOffset": 107}, {"referenceID": 10, "context": ", 2009), spherical hashing (SpH) (Heo et al., 2012), and binary autoencoder (BA) (Carreira-Perpin\u00e1n and Raziperchikolaei, 2015).", "startOffset": 33, "endOffset": 51}, {"referenceID": 9, "context": "We conducted the searching via the commonly used Hamming ranking follows (He et al., 2013; Gong and Lazebnik, 2011; Weiss et al., 2009).", "startOffset": 73, "endOffset": 135}, {"referenceID": 3, "context": "We conducted the searching via the commonly used Hamming ranking follows (He et al., 2013; Gong and Lazebnik, 2011; Weiss et al., 2009).", "startOffset": 73, "endOffset": 135}, {"referenceID": 33, "context": "We conducted the searching via the commonly used Hamming ranking follows (He et al., 2013; Gong and Lazebnik, 2011; Weiss et al., 2009).", "startOffset": 73, "endOffset": 135}], "year": 2017, "abstractText": "Learning to hash plays a fundamentally important role in the efficient image and video retrieval and many other computer vision problems. However, due to the binary outputs of the hash functions, the learning of hash functions is very challenging. In this paper, we propose a novel approach to learn stochastic hash functions such that the learned hashing codes can be used to regenerate the inputs. We develop an efficient stochastic gradient learning algorithm which can avoid the notorious difficulty caused by binary output constraint, and directly optimize the parameters of the hash functions and the associated generative model jointly. The proposed method can be applied to both L2 approximate nearest neighbor search (L2NNS) and maximum inner product search (MIPS). Extensive experiments on a variety of large-scale datasets show that the proposed method achieves significantly better retrieval results than previous state-of-the-arts.", "creator": "LaTeX with hyperref package"}}}