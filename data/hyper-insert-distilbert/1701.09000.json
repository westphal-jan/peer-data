{"id": "1701.09000", "review": {"conference": "arxiv", "VERSION": "v1", "DATE_OF_SUBMISSION": "31-Jan-2017", "title": "On the Semantics and Complexity of Probabilistic Logic Programs", "abstract": "finally we examine the meaning questions and modify the complexity of probabilistic logic neural programs that consist again of probing a single set of simple rules and providing a set of independent probabilistic facts ( that was is, programs function based on sato's sample distribution semantics ). we focus further on sampling two semantics, respectively and based on some stable mathematics and reporting on well - founded models. accordingly we show that probing the semantics respectively based on stable logical models ( accordingly referred to as the \" reverse credal semantics \" ) subsequently produces successive sets of empirical probability models meaning that typically dominate infinitely monotone complex choquet algebraic capacities, we describe just several useful consequences of this result. we better then can examine the complexity of automated inference satisfaction with rigorous probabilistic polynomial logic programs. if we further distinguish terminology between managing the complexity capability of inference process when a query probabilistic program and obtaining a query are given ( testing the nearest inferential complexity ), and the complexity of inference when the probabilistic language program number is fixed and conversely the query is sufficiently given ( evaluating the relative query complexity, similarly akin to quantitative data complexity as used regularly in database theory ). we obtain results by on measuring the inferential and consistent query complexity for acyclic, stratified, and globally cyclic \u2014 propositional and relational purpose programs, complexity reaches successively various levels, of the exponential counting hierarchy hierarchy and even exponential levels.", "histories": [["v1", "Tue, 31 Jan 2017 11:54:15 GMT  (61kb)", "http://arxiv.org/abs/1701.09000v1", null]], "reviews": [], "SUBJECTS": "cs.AI", "authors": ["fabio gagliardi cozman", "denis deratani mau\\'a"], "accepted": false, "id": "1701.09000"}, "pdf": {"name": "1701.09000.pdf", "metadata": {"source": "CRF", "title": "On the Semantics and Complexity of Probabilistic Logic Programs", "authors": ["Fabio Gagliardi Cozman"], "emails": [], "sections": [{"heading": null, "text": "ar X\niv :1\n70 1.\n09 00\n0v 1\n[ cs\n.A I]"}, {"heading": "1 Introduction", "text": "The combination of deterministic and uncertain reasoning has led to many mixtures of logic and probability (Halpern, 2003; Hansen & Jaumard, 1996; Nilsson, 1986). In particular, combinations of logic programming constructs and probabilistic assessments have been pursued in several guises (Fuhr, 1995; Lukasiewicz, 1998; Ng & Subrahmanian, 1992; Poole, 1993; Sato, 1995), and the topic has generated significant literature (Raedt, Frasconi, Kersting, & Muggleton, 2010; Raedt, 2008).\nAmong probabilistic logic programming languages, the approach started by Poole\u2019s probabilistic Horn abduction (Poole, 1993) and Sato\u2019s distribution semantics (Sato, 1995) has been very popular. Basically, there a logic program is enlarged with independent probabilistic facts. For instance, consider a rule\nup :\u2212 actionUp,not disturbanceUp.\nand probabilistic fact P(disturbanceUp = true) = 0.1.\nDepending on disturbanceUp, actionUp may succeed or not in leading to up. Sato\u2019s distribution semantics at first focused on definite programs, and was announced \u201croughly, as distributions over least models\u201d (Sato, 1995). Poole and Sato originally emphasized acyclic logic programs (Poole, 1993, 2008; Sato, 1995; Sato & Kameya, 2001), even though Sato did handle cyclic ones. Since then, there has been significant work on non-definite and on cyclic probabilistic logic programs under variants of the distribution semantics (Hadjichristodoulou & Warren, 2012; Lukasiewicz, 2005; Riguzzi, 2015; Sato, Kameya, & Zhou, 2005).\nIn this paper we examine the meaning and the computational complexity of probabilistic logic programs that extend Sato\u2019s distribution semantics. We look at standard functionfree normal programs containing negation as failure and probabilistic facts. The goal is to compute an inference; that is, to compute the probability P(Q|E), where both Q and E are sets of facts. The pair (Q,E) is referred to as the query. We distinguish between the complexity of inference when a probabilistic program and a query are given (the inferential complexity), and the complexity of inference when the probabilistic program is fixed and the query is given (the query complexity). Query complexity is similar to data complexity as used in database theory, as we discuss later.\nWe first examine acyclic programs; for those programs all existing semantics coincide. Given the well-known relationship between acyclic probabilistic logic programs and Bayesian networks, it is not surprising that inference for propositional acyclic programs is PP-complete. However, it is surprising that, as we show, inference with bounded arity acyclic programs without negation is PPNP-equivalent, thus going up the counting hierarchy. And we show that acyclic programs without a bound on predicate arity take us to PEXP-completeness.\nMany useful logic programs are cyclic; indeed, the use of recursion is at the heart of logic programs and its various semantics (Gelfond & Lifschitz, 1988; van Gelder, Ross, & Schlipf, 1991). Many applications, such as non-recursive structural equation models (Berry, 1984; Pearl, 2009) and models with \u201cfeedback\u201d (Nodelman, Shelton, & Koller, 2002; Poole & Crowley, 2013), defy the acyclic character of Bayesian networks.\nWe study cyclic normal logic programs in a few steps. First we look at the inferential and query complexity of locally stratified programs. For these programs, again we see that most existing semantics coincide; in particular semantics based on stable and well-founded models are identical. To summarize, we show that the complexity of stratified programs is the same as the complexity of acyclic programs.\nWe then move to general, possibly cyclic, programs. There are various semantics for such programs, and relatively little discussion about them in the literature. For instance, take a program consisting of two rules,\nsleep :\u2212 not work,not insomnia. work :\u2212 not sleep. (1)\nand a fact associated with a probabilistic assessment:\nP(insomnia = true) = 0.3.\nWith probability 0.3, we have that insomnia is true, and then sleep is false and work is true. This is simple enough. But with probability 0.7, we have that insomnia is false, and then the remaining two rules create a cycle: sleep depends on work and vice-versa. The question is how to define a semantics when a cycle appears.\nWe focus on two semantics for such programs, even though we mention a few others. First, we look at a semantics for probabilistic logic programs that can be extracted from the work of Lukasiewicz on probabilistic description logics (Lukasiewicz, 2005, 2007). His proposal is that a probabilistic logic program defines a set of probability measures, induced by the various stable models of the underlying normal logic program. The second semantics we examine is based on the well-founded semantics of normal logic programs: in this case there is always a single distribution induced by a probabilistic logic program (Hadjichristodoulou & Warren, 2012).\nWe first study Lukasiewicz\u2019s semantics, referred to as the \u201ccredal semantics\u201d. We show that credal semantics produces sets of probability models that dominate infinitely monotone Choquet capacities; the latter objects are relatively simple extensions of probability distributions and have been often used in the literature, from random set theory to Dempster-Shafer theory. We then derive results concerning inferential and query complexity. We show that the complexity of general probabilistic logic programs goes up the counting hierarchy, up to PPNP NP\nlevels; overall the complexity of the well-founded semantics is in lower classes than the complexity of the stable model semantics.\nThe paper begins in Section 2 with a review of logic programming and complexity theory. Section 3 presents basic notions concerning probabilistic logic programs and their semantics. In Section 4 we contribute with a comparison between the credal and the wellfounded semantics. Our main results appear in Sections 5, 6, 7 and 8. In Section 5 we show that the credal semantics of a probabilistic logic program is a set of probability measures induced by a 2-monotone Choquet capacities. Sections 6, 7 and 8 analyze the complexity of inferences under the credal and the well-founded semantics. The paper concludes, in Section 9, with a summary of our contributions and a discussion of future work."}, {"heading": "2 Background", "text": "We briefly collect here some well known terminology and notation regarding logic programming and complexity theory. Before we plunge into those topics, we briefly fix notation on Bayesian networks as we will need them later. A Bayesian network is a pair consisting of a directed acyclic graph G whose nodes are random variables, and a joint probability distribution P over all variables in the graph, such that G and P satisfy the \u201cMarkov condition\u201d (that is, a random variable is independent of its parents given its nondescendants) (Koller & Friedman, 2009; Neapolitan, 2003; Pearl, 1988). If all random variables are discrete, then one can specify \u201clocal\u201d conditional probabilities P(Xi = xi|pa(Xi) = \u03c0i), and the joint probability distribution is necessarily the product of these local probabilities:\nP(X1 = x1, . . . ,Xn = xn) =\nn \u220f\ni=1\nP(Xi = xi|pa(Xi) = \u03c0i) , (2)\nwhere \u03c0i is the projection of {x1, . . . , xn} on the set of random variables pa(Xi); whenever Xi has no parents, P(Xi = xi|pa(Xi) = \u03c0i) stands for P(Xi = xi)."}, {"heading": "2.1 Normal logic programs: syntax and semantics", "text": "Take a vocabulary consisting of set of logical variable symbols X,Y, . . ., a set of predicate symbols r, s, . . ., and a set of constants a, b, . . .. A term is a constant or a logical variable; an atom is written as r(t1, . . . , tn), where r is a predicate of arity n and each ti is a term. A zero-arity atom is written simply as r. An atom is ground if it does not contain logical variables.\nA normal logic program consists of rules written as (Dantsin, Eiter, & Voronkov, 2001)\nA0 :\u2212 A1, . . . , Am,notAm+1, . . . ,notAn.\nwhere the Ai are atoms and not is interpreted according to some selected semantics, as discussed later. The head of this rule is A0; the remainder of the rule is its body. A rule without a body, written simply as A0., is a fact. A subgoal in the body is either an atom A (a positive subgoal) or not A (a negative subgoal). A program without negation is definite, and a program without variables is propositional.\nExample 1. Here is a program describing the relation between smoking, stress, and social influence (Fierens, Van den Broeck, Renkens, Shrerionov, Gutmann, Janssens, & de Raedt, 2014):\nsmokes(X) :\u2212 stress(X). smokes(X) :\u2212 influences(Y,X), smokes(Y ). influences(a, b). influences(b, a). stress(b).\nThis program is definite, but not propositional.\nThe Herbrand base of a program is the set of all ground atoms built from constants and predicates in the program. We do not consider functions in this paper, to stay with finite Herbrand bases.\nA substitution is a (partial) function that maps logical variables into terms. A grounding is a substitution mapping into constants. The grounding of a rule is a ground rule obtained by applying the same grounding to each atom. The grounding of a program is the propositional program obtained by applying every possible grounding all rules, using only the constants in the program (i.e., using only ground atoms in the Herbrand base). An atom A unifies with an atom B if there is a substitution that makes both (syntactically) equal.\nA literal L is either an atom A or a negated atom \u00acA. A set of literals is inconsistent if A and \u00acA belong to it. Given a normal logic program P, a partial interpretation is a consistent set of literals whose atoms belong to the Herbrand base of P. An interpretation is a consistent set of literals such that every atom in the Herbrand base appears in a literal. An atom is true (resp., false) in a (partial) interpretation if it appears in a non-negated (resp., negated) literal. A subgoal is true in an interpretation if it is an atom A and A belongs to the interpretation, or the subgoal is not A and \u00acA belongs to the interpretation. A grounded rule is satisfied in a partial interpretation if its head is true in the interpretation, or any of its subgoals is false in the interpretation. A model of P is an interpretation such\nthat every grounding of a rule in P is satisfied. A minimal model of P is a model with minimum number of non-negated literals.\nThe dependency graph of a program is a directed graph where each predicate is a node, and where there is an edge from a node B to a node A if there is a rule where A appears in the head and B appears in the body; if B appears right after not, the edge is negative; otherwise, it is positive. The grounded dependency graph is the dependency graph of the propositional program obtained by grounding. For instance, the grounded dependency graph of the program in Example 1 is depicted in Figure 1.\nA program is acyclic when its grounded dependency graph is acyclic. Concerning the semantics of normal logic programs, there are, broadly speaking, two strategies to follow. One strategy is to translate programs into a first-order theory that is called a completion of the program. Then the semantics of the program is the set of first-order models of its completion. The most famous completion is Clark\u2019s (Clark, 1978), roughly defined as follows. First, rewrite each body by replacing commas by \u2227 and not by \u00ac. Second, remove constants from heads: to do so, consider a rule A0(a) :\u2212 Bi., where a is a constant and Bi is the body; then this rule is replaced by A0(X) :\u2212 (X = a)\u2227Bi.. Then, for each set of rules that share the same head A0, write A0 \u21d4 B1 \u2228 B2 \u2228 . . . \u2228 Bk, where each Bi is the body of one of the rules.\nThe second strategy that is often used to define the semantics of normal logic programs is to select some models of the program to be its semantics. There are many proposals in the literature as to which models should be selected; however, currently there are two selections that have received most attention: the stable model (Gelfond & Lifschitz, 1988) and the well-founded (van Gelder et al., 1991) semantics. We now describe these semantics; alas, their definitions are not simple.\nConsider first the stable model semantics. Suppose we have a normal logic program P and an interpretation I . Define the reduct PI to be a definite program that contains rule A0 :\u2212 A1, . . . , Am. iff one of the grounded rules fromP isA0 :\u2212 A1, . . . , Am,not Am+1, . . . ,not An. where each Am+1, . . . , An is false in I . That is, the reduct is obtained by (i) grounding P, (ii) removing all rules that contain a subgoal not A in their body such that A is an atom that is true in I , (iii) removing all remaining literals of the form not A from the remaining rules. An interpretation I is a stable model if I is a minimal model of PI . Note that a normal program may fail to have a stable model, or may have several stable models.\nThere are two types of logical reasoning under the stable mode semantics (Eiter, Faber, Fink, & Woltran, 2007). Brave reasoning asks whether there is a stable model containing a specific atom (and possibly returns it if it exists). Cautious reasoning asks whether a\nspecific atom appears in all stable models (and possibly lists all such models). Consider now the well-founded semantics. Given a subset U of the Herbrand base of a program, and a partial interpretation I , say that an atom A is unfounded with respect to U and I iff for each grounded rule whose head is A, we have that (i) some subgoal Ai or not Ai is false in I , or (ii) some subgoal that is an atom Ai is in U . Now say that a subset U of the Herbrand base is an unfounded set with respect to interpretation I if each atom in U is unfounded with respect to U and I . This is a complex definition: roughly, it means that, for each possible rule that we might apply to obtain A, either the rule cannot be used (given I), or there is an atom in U that must be first shown to be true. Now, given normal logic program P, define TP(I) to be a transformation that takes interpretation I and returns another interpretation: A \u2208 TP(I) iff there is some grounded rule with head A such that every subgoal in the body is true in I . Also define UP(I) to be the greatest unfounded set with respect to I (there is always such a greatest set). Define WP(I) = TP(I) \u222a \u00acUP(I), where the notation \u00acUP(I) means that we take each literal in UP(I) and negate it (that is, A becomes \u00acA; \u00acA becomes A). Intuitively, TP is what we can \u201ceasily prove to be positive\u201d and UP is what we can \u201ceasily prove to be negative\u201d.\nFinally: the well-founded semantics of P is the least fixed point of WP(I); this fixed point always exists. That is, apply Ii+1 = WP(Ii), starting from I0 = \u2205, until it stabilizes; the resulting interpretation is the well-founded model. The iteration stops in finitely many steps given that we have finite Herbrand bases.\nThe well-founded semantics determines the truth assignment for a subset of the atoms in the Herbrand base; for the remaining atoms, their \u201ctruth values are not determined by the program\u201d (van Gelder et al., 1991, Section 1.3). A very common interpretation of this situation is that the well-founded semantics uses three-valued logic with values true, false, and undefined. It so happens that any well-founded model is a subset of every stable model of a normal logic program (van Gelder et al., 1991, Corollary 5.7); hence, if a program has a well-founded model that is an interpretation for all atoms, then this well-founded model is the unique stable model (the converse is not true).\nThere are other ways to define the well-founded semantics that are explicitly constructive (Baral & Subrahmanian, 1993; Gelder, 1993; Przymusinski, 1989). One is this, where the connection with the stable model semantics is emphasized (Baral & Subrahmanian, 1993): write LFTP(I) to mean the least fixpoint of TPI ; then the well-founded semantics of P consists of those atoms A that are in the least fixpoint of LFTP(LFTP(\u00b7)) plus the literals \u00acA for those atoms A that are not in the greatest fixpoint of LFTP(LFTP(\u00b7)). Note that LFTP(LFTP(\u00b7)) is a monotone operator.\nIt is instructive to look at some examples.\nExample 2. First, take a program P with two rules: p :\u2212 not q,not r. and q :\u2212 not p. (identical to rules in Expression (1)). This program has two stable models: both assign false to r; one assigns true to p and false to q, while the other assigns true to q and false to p (note P{p,\u00acq,\u00acr} = {p.} and P{\u00acp,q,\u00acr} = {q.}). The well-founded semantics assigns false to r and leaves p and q as undefined.\nExample 3. Consider a game where a player wins if there is another player with no more moves (van Gelder et al., 1991; Gelder, 1993), as expressed by the cyclic rule:\nwins(X) :\u2212 move(X,Y ),not wins(Y ).\nSuppose the available moves are given as the following facts:\nmove(a, b). move(b, a). move(b, c). move(c, d).\nThere are two stable models: both assign true to wins(c) and false to wins(d); one assigns true to wins(a) and false to wins(b), while the other assigns true to wins(b) and false to wins(a). The well-founded semantics leads to partial interpretation {wins(c),\u00acwins(d)}, leaving wins(a) and wins(b) as undefined. If move(a, b) is not given as a fact, it is assigned false, and the well-founded semantics leads to {\u00acwins(a),wins(b),wins(c),\u00acwins(d)}.\nExample 4. The Barber Paradox: If the barber shaves all, and only, those villagers who do not shave themselves, does the barber shave himself? Consider:\nshaves(X,Y ) :\u2212 barber(X), villager(Y ),not shaves(Y, Y ). villager(a). barber(b). villager(b).\n(3)\nThere is no stable model for this normal logic program: the facts and the rule lead to the pattern shaves(b, b) :\u2212 not shaves(b, b)., thus eliminating any possible stable model. The well-founded semantics assigns false to barber(a), to shaves(a, a) and to shaves(a, b). Also, shaves(b, a) is assigned true, and shaves(b, b) is left undefined. That is, even though the semantics leaves the status of the barber as undefined, it does produce meaningful answers for other villagers."}, {"heading": "2.2 Complexity theory: the counting hierarchy", "text": "We adopt basic terminology and notation from computational complexity (Papadimitriou, 1994). A language is a set of strings. A language defines a decision problem; that is, the problem of deciding whether an input string is in the language. A complexity class is a set of languages; we use well-known complexity classes such as P, NP, EXP, NEXP. The complexity class PP consists of those languages L that satisfy the following property: there is a polynomial time nondeterministic Turing machine M such that \u2113 \u2208 L iff more than half of the computations of M on input \u2113 end up accepting. Analogously, we have PEXP, consisting of those languages L with the following property: there is an exponential time nondeterministic Turing machine M such that \u2113 \u2208 L iff half of the computations of M on input \u2113 end up accepting (Buhrman, Fortnow, & Thierauf, 1998).\nAn oracle Turing machine ML, where L is a language, is a Turing machine that can write a string \u2113 to an \u201coracle\u201d tape and obtain from the oracle, in unit time, the decision as to whether \u2113 \u2208 L or not. Similarly, for a function f , an oracle Turing machine Mf can be defined. If a class of languages/functions A is defined by a set of Turing machines M (that is, the languages/functions are decided/computed by these machines), then AL is the set of languages/functions that are decided/computed by {ML : M \u2208 M}. Similarly, for any class A we have Af . If A and B are classes of languages/functions, AB = \u222ax\u2208BAx. The polynomial hierarchy consists of classes \u03a0Pi = co\u03a3 P i and \u03a3 P i = NP \u03a3Pi\u22121 , with \u03a3P0 = P. Later we also use classes \u2206Pi = P \u03a3Pi\u22121 and PH = \u222ai\u03a0Pi = \u222ai\u03a3 P i .\nWagner\u2019s polynomial counting hierarchy is the smallest set of classes containing P and, recursively, for any class C in the polynomial counting hierarchy, the classes PPC, NPC, and\ncoNPC (Wagner, 1986, Theorem 4) (T\u00f3ran, 1991, Theorem 4.1). The polynomial hierarchy is included in Wagner\u2019s counting polynomial hierarchy.\nA many-one reduction from L to L\u2032 is a polynomial time algorithm that takes the input to decision problem L and transforms it into the input to decision problem L\u2032 such that L\u2032 has the same output as L. For a complexity class C, a decision problem L is C-hard with respect to many-one reductions if each decision problem in C can be reduced to L with many-one reductions. A decision problem is then C-complete with respect to many-one reductions if it is in C and it is C-hard with respect to many-one reductions.\nIn proofs we will often use propositional formulas; such a formula is in Conjunctive Normal Form (CNF) when it is a conjunction of clauses (where a clause is a disjunction of literals). A kCNF is a CNF in which each clause has k literals. We use the following PP\u03a3 P k -complete problem (Wagner, 1986, Theorem 7), that we refer to as #k3CNF(>):\nInput: A pair (\u03c6,M), where \u03c6(X0,X1, . . . ,Xk) is a propositional formula in 3CNF and each Xi is a tuple of logical variables, and M is an integer.\nOutput: Whether or not the number of truth assignments for X0 in the formula\nQ1X1 : Q2X2 : . . . \u2203Xk : \u03c6(X0,X1, . . . ,Xk),\nis strictly larger than M , where the quantifiers alternate and each logical variable not in X0 is bound to a quantifier.\nAnother PP\u03a3 P k -complete problem, referred to as #kDNF(>) is:\nInput: A pair (\u03c6,M), where \u03c6(X0,X1, . . . ,Xk) is a propositional formula in DNF and each Xi is a tuple of logical variables, and M is an integer.\nOutput: Whether or not the number of truth assignments for X0 in the formula\nQ1X1 : Q2X2 : . . . \u2200Xk : \u03c6(X0,X1, . . . ,Xk),\nis strictly larger than M , where the quantifiers alternate and each logical variable not in X0 is bound to a quantifier.\nA detail is that Wagner defines a PP\u03a3 P k -complete problem using \u201c\u2265 k\u201d instead of \u201c> M \u201d,\nbut the former is equivalent to \u201c> M \u2212 1\u201d, so both inequalities can be used."}, {"heading": "3 Probabilistic normal logic programs", "text": "In this paper we focus on a particularly simple combination of logic programming and probabilities (Poole, 1993; Sato, 1995). A probabilistic logic program, abbreviated plp, is a pair \u3008P,PF\u3009 consisting of a normal logic program P and a set of probabilistic facts PF. A probabilistic fact is a pair consisting of an atom A and a probability value \u03b1; we use the notation \u03b1 :: A. borrowed from the ProbLog package1 (Fierens et al., 2014).\nWe assume that every probability value is a rational number.\n1At https://dtai.cs.kuleuven.be/problog/index.html.\nExample 5. Here is a syntactically correct ProbLog program:\n0.7 :: burglary. 0.2 :: earthquake. alarm :\u2212 burglary, earthquake, a1. alarm :\u2212 burglary,not earthquake, a2. alarm :\u2212 not burglary, earthquake, a3. 0.9 :: a1. 0.8 :: a2. 0.1 :: a3. calls(X) :\u2212 alarm, neighbor(X). neighbor(a). neighbor(b).\nThere are four rules, two facts, and five probabilistic facts.\nA probabilistic fact may contain logical variables; for instance, we may write \u03b1 :: r(X1, . . . ,Xn).. We interpret such a parameterized probabilistic fact as the set of all grounded probabilistic facts obtained by substituting variables with constants in the Herbrand base.2\nGiven a plp \u3008P,PF\u3009 where P is acyclic, we say the plp is acyclic. Likewise, if P is definite, stratified, cyclic, etc, we use the same adjective for the whole plp."}, {"heading": "3.1 The semantics of probabilistic facts", "text": "The interpretation of probabilistic facts requires some pause. Suppose we have a plp \u3008P,PF\u3009 with n probabilistic facts (which may be groundings of probabilistic facts containing logical variables). From \u3008P,PF\u3009 we can generate 2n normal logic programs: for each probabilistic fact \u03b1 :: A., we can either choose to keep fact A., or choose to erase fact A. altogether. These choices are assumed independent: this is Sato\u2019s independence assumption.\nFor instance, consider the plp:\n0.5 :: r. 0.5 :: s. v :\u2212 r, s. (4)\nWe have four ways to write a normal logic program out of this plp; that is, r can be kept or removed, and likewise for s. All these normal logic programs are obtained with the same probability 0.25, and in one of them v is true; consequently, the probability P(v = true) = 0.25.\nA total choice \u03b8 for the plp is a subset of the set of grounded probabilistic facts. We interpret \u03b8 as a set of ground facts that are probabilistic selected to be included in P; all other ground facts obtained from probabilistic facts are to be discarded. The probability of a total choice is easily computed: it is a product over the grounded probabilistic facts, where probabilistic fact \u03b1 :: A. contributes with factor \u03b1 if A. is kept, or factor (1\u2212\u03b1) if A. is removed. Now for each total choice \u03b8 we obtain a normal logic program, that we denote by P \u222aPF\u2193\u03b8.\nFor instance, the plp in Expression (4) has two probabilistic facts, leading to four total choices, each with probability 0.25. Now consider a more complicated plp:\n0.5 :: r. 0.6 :: r. 0.2 :: s(a). 0.3 :: s(X). v :\u2212 r, s(a), s(b).\n2ProbLog additionally has \u201cprobabilistic rules\u201d but those are simply syntactic sugar that we do not need here.\nThere are five ground probabilistic facts (after grounding s(X) appropriately); hence there are 32 total choices. Suppose we choose to keep the fact in the first probabilistic fact, and discard all the others (with probability 0.5\u00d7 0.4 \u00d7 0.8 \u00d7 0.7\u00d7 0.7); then we obtain\nr. v :\u2212 r, s(a), s(b).,\na program with a single stable model where r is the only true atom. By going through all possible total choices, we have that P(r = true) = 0.8 (as r. is kept in the program by a first choice with probability 0.5 or by a second choice with probability 0.6, hence 0.5 + 0.6 \u2212 0.5 \u00d7 0.6 = 0.8). Similarly, P(s(a) = true) = 0.2 + 0.3 \u2212 0.2 \u00d7 0.3 = 0.44; note however that P(s(b) = true) = 0.3. And finally, P(v = true) = 0.8\u00d7 0.44 \u00d7 0.3 = 0.1056.\nSato assumes that no probabilistic fact unifies with the head of a non-fact rule (that is, a rule with a nonempty body); this is called the disjointness condition (Sato, 1995). From a modeling perspective this is a convenient assumption even though we do not need it in our complexity results. In fact from a modeling perspective an even stronger disjointness condition makes sense: no probabilistic fact should unify with the head of any rule (with a body or not), nor with any other probabilistic fact. Under this assumption, the probabilistic fact \u03b1 :: A. can be directly interpreted as a probabilistic assessment P(A = true) = \u03b1. Again, we do not need such an assumption for our results, but our examples will always satisfy it, and it makes sense to assume that it will always be adopted in practice."}, {"heading": "3.2 The semantics of definite/acyclic/stratified probabilistic logic programs", "text": "We can now discuss the semantics of a plp \u3008P,PF\u3009. First, take the grounding of this plp. Now for each total choice \u03b8 we obtain the normal logic program P \u222a PF\u2193\u03b8. Hence the distribution over total choices induces a distribution over normal logic programs.\nA common assumption is that, for each total choice \u03b8, the resulting normal logic program P \u222a PF\u2193\u03b8 yields a single model (Fierens et al., 2014). For instance, if P is definite, then P \u222a PF\u2193\u03b8 is definite for any \u03b8, and P \u222a PF\u2193\u03b8 has a unique stable model that is also its unique well-founded model. Thus the unique distribution over total choices becomes a unique distribution over stable/well-founded models. This distribution is exactly Sato\u2019s distribution semantics (Sato, 1995). Similarly, suppose that P is acyclic; then P \u222a PF\u2193\u03b8 is acyclic for any \u03b8, and P\u222aPF\u2193\u03b8 has a unique stable model that is also its unique well-founded model (Apt & Bezem, 1991).\nPoole\u2019s and Sato\u2019s original work focused respectively on acyclic and definite programs; in both cases the semantics of resulting normal logic programs is uncontroversial. The same can be said of the larger class of stratified programs; a normal logic program is stratified when cycles in the grounded dependency graph contain no negative edge (this is often referred to as locally stratified in the literature) (Apt, Blair, & Walker, 1988). Both the stable and the well-founded semantics are identical for stratified programs, and both generate a unique interpretation for all atoms. As a consequence, a plp \u3008P,PF\u3009 has a unique distribution semantics whenever P is stratified. Note that both acyclic and definite programs are stratified.\nExample 6. The plp in Example 5 is acyclic, and thus stratified, but not definite. The grounded dependency graph of this program is depicted in Figure 2. This graph can be\ninterpreted as a Bayesian network, as we discuss later (Poole, 1993). There are 25 total choices, and the probability of calls(a) is 0.58.\nExample 7. Consider a probabilistic version of the \u201csmokers\u201d program in Example 1 (Fierens et al., 2014):\nsmokes(X) :\u2212 stress(X). smokes(X) :\u2212 influences(Y,X), smokes(Y ). 0.3 :: influences(a, b). 0.3 :: influences(b, a). 0.8 :: stress(b).\nThe grounded dependency graph of this program is identical to the one shown in Figure 1. It is tempting to interpret this graph as a Bayesian network, but of course this is not quite right as the graph is cyclic. Indeed the program is not acyclic, but it is definite and therefore stratified, hence a unique distribution is defined over ground atoms. For instance, we have P(smokes(a)) = 0.06 and P(smokes(b)) = 0.2. The program would still be stratified if the first rule were replaced by\nsmokes(X) :\u2212 not stress(X).\nIn this case there would still be a cycle, but the negative edge in the dependency graph would not belong to the cycle.\nOften a stratified program is used to implement recursion, as illustrated by the next example:\nExample 8. Consider the following plp, based on an example in the ProbLog distribution:\npath(X,Y ) :\u2212 edge(X,Y ). path(X,Y ) :\u2212 edge(X,Y ), path(X,Y ).\n0.6 :: edge(1, 2). 0.1 :: edge(1, 3). 0.4 :: edge(2, 5). 0.3 :: edge(2, 6). 0.3 :: edge(3, 4). 0.8 :: edge(4, 5). 0.2 :: edge(5, 6).\nThat is, we have a random graph with nodes 1, . . . , 6, and probabilities attached to edges. The query P(path(1, 6) = true) yields the probability that there is a path between nodes 1 and 6. Using ProbLog one obtains P(path(1, 6) = true) = 0.217."}, {"heading": "3.3 The semantics of general probabilistic logic programs", "text": "If a normal logic program is non-stratified, then its well-founded semantics may be a partial interpretation, and some atoms may be left as undefined; it may have several stable models, or no stable model at all. Thus we must accommodate these cases when we contemplate non-stratified plps."}, {"heading": "3.3.1 The credal semantics", "text": "A first possible semantics for general probabilistic logic programs can be extracted from work by Lukasiewicz (2005, 2007) on probabilistic description logic programs. To describe that proposal, a few definitions are needed. A plp \u3008P,PF\u3009 is consistent if there is at least one stable model for each total choice of PF. A probability model for a consistent plp \u3008P,PF\u3009 is a probability measure P over interpretations of P, such that: (i) every interpretation I with P(I) > 0 is a stable model of P \u222aPF\u2193\u03b8 for the total choice \u03b8 that agrees with I on the probabilistic facts (that is, \u03b8 induces the same truth values as I for the grounded probabilistic facts); and (ii) the probability of each total choice \u03b8 is the product of the probabilities for all individual choices in \u03b8. The set of all probability models for a plp is the semantics of the program. Later examples will clarify this construction.\nLukasiewicz calls his proposed semantics the answer set semantics for probabilistic description logic programs; however, note that this name is both too restrictive (the semantics can be used for programs with functions, for instance) and a bit opaque (it does not emphasize the fact that it deals with uncertainty). We prefer the term credal semantics, which we adopt from now on. The reason for this latter name is that a set of probability measures is often called a credal set (Augustin, Coolen, de Cooman, & Troffaes, 2014).\nNow given a consistent plp, we may be interested in the smallest possible value of P(Q) for a set Q of truth assignments, with respect to the set K of all probability models of the plp. This is conveyed by the lower probability of Q, P(Q) = infP\u2208K P(Q). Similarly, we have the upper probability of Q, P(Q) = supP\u2208K P(Q). Suppose that we also have a set of E of truth assignments for ground atoms; then we may be interested in the conditional lower and upper probabilities, respectively P(Q|E) = infP\u2208K:P(E)>0 P(Q|E) and P(Q|E) = supP\u2208K:P(E)>0 P(Q|E). We leave conditional lower/upper probabilities undefined when P(E) = 0 (that is, when P(E) = 0 for every probability model). This is not the only possible convention: Lukasiewicz (2005, Section 3) adopts P(Q|E) = 1 and P(Q|E) = 0 in this case, while Walley\u2019s style of conditioning prescribes P(Q|E) = 0 and P(Q|E) = 1 whenever P(E) = 0 (Walley, 1991)."}, {"heading": "3.3.2 The well-founded semantics", "text": "The approach by Hadjichristodoulou and Warren (2012) is to allow probabilities directly over well-founded models, thus allowing probabilities over atoms that are undefined. That is, given a plp \u3008P,PF\u3009, associate to each total choice \u03b8 the unique well-founded model of P\u222aPF\u2193\u03b8 to \u03b8; the unique distribution over total choices induces a unique distribution over well-founded models. Note that probabilities may be assigned to undefined values in this sort of semantics. As we discuss in Section 4, this is a bold proposal whose interpretation is far from simple.\nRegardless of its meaning, the approach deserves attention as it is the only one in the literature that genuinely combines well-founded semantics with probabilities. Accordingly, we refer to it as the well-founded semantics of probabilistic logic programs (the combination of language and semantics is named WF-PRISM by Hadjichristodoulou and Warren)."}, {"heading": "3.3.3 Other semantics", "text": "Sato et al. propose a semantics where distributions are defined over models produced by Fitting\u2019s three-valued semantics (Sato et al., 2005). We note that Fitting\u2019s semantics is weaker than the well-founded semantics, and the literature on logic programming has consistently preferred the latter, as we do in this paper.\nAnother three-valued approach, proposed by Lukasiewicz (2005, 2007), leaves the probability of any formula as undefined whenever the formula is undefined for any total choice (to determine whether a formula is undefined or not in a particular partial interpretation, three-valued logic is used). Hence, when a formula gets a (non-undefined) numeric probability value, its truth value is the same for all stable models; thus any numeric probability calculations that are produced with this semantics agree with the semantics based on stable models Lukasiewicz (2007, Theorem 4.5). That is, Lukasiewicz\u2019 proposal is more akin to the credal semantics than to the well-founded semantics.\nA different semantics for non-stratified plps is adopted by the P-log language (Baral, Gelfond, & Rushton, 2009). P-log allows for disjunction in heads and other features, but when restricted to normal logic programs it is syntactically similar to ProbLog. The semantics of a P-log program is given by a single probability distribution over possibly many stable models; whenever necessary default assumptions are called to distribute probability evenly, or to avoid inconsistent realizations (by re-normalization). We leave an analysis of this sort of semantics to the future; here we prefer to focus on semantics that do not make default assumptions concerning probabilities.\nIt is also important to mention the constraint logic programming language of Michels, Hommersom, Lucas, and Velikova (2015), a significant contribution that is also based on credal sets. However, they use a syntax and semantics that is markedly different from Lukasiewicz\u2019s approach, as they allow continuous variables but do not let a program have multiple stable models per total choice. They also present expressions for (conditional) lower and upper probabilities, by direct optimization; in Section 5 we show that such expressions can be derived from properties of infinitely monotone Choquet capacities.\nFinally, Ceylan, Lukasiewicz, and Pe\u00f1aloza (2016) have introduced a semantics that allows for inconsistent plps to have meaning without getting into three-valued logic. They adopt a much more sophisticated family of logic programs (within the Datalog\u00b1 language), and they provide a thorough analysis of complexity that we discuss later. This is also a proposal that deserves future study.\nIn this paper we focus on the credal and the well-founded semantics in the remainder of this paper, whenever non-stratified plps are discussed, but certainly there are other avenues to explore."}, {"heading": "4 The semantics of the credal and the well-founded semantics", "text": "It does not seem that any comparison is available in the literature between the credal and the well-founded semantics for non-stratified plps. Indeed, the credal semantics has not been adopted since its appearance, a turn of events we find unfortunate as it is quite a sensible semantics for general plps. In this section we present some examples that emphasize differences between these semantics, and we examine their interpretation.\nExample 9. Consider a probabilistic version of Example 2:\np :\u2212 not q,not r. q :\u2212 not p. \u03b1 :: r.\nThis is in essence identical to the plp in Expression (1). To interpret the plp, note that with probability \u03b1 we obtain the normal logic program\np :\u2212 not q,not r. q :\u2212 not p. r.\nThe unique stable/well-founded model of this program assigns true to r and q, and false to p. That is, we have the stable model s1 = {\u00acp, q, r}. On the other hand, with probability 1\u2212 \u03b1 we obtain a program with different behavior, namely:\np :\u2212 not q,not r. q :\u2212 not p.\nThis program has two stable models: s2 = {p,\u00acq,\u00acr} and s3 = {\u00acp, q,\u00acr}. But this program has a single well-founded model, where r is false and both p and q are undefined.\nConsider the credal semantics. There is a probabilty model such that P(s2) = 1\u2212\u03b1 and P(s3) = 0, and another probability model such that P(s2) = 0 and P(s3) = 1 \u2212 \u03b1. Indeed any probability measure such that P(s1) = \u03b1 and P(s2) = \u03b3(1\u2212\u03b1), P(s3) = (1\u2212 \u03b3)(1\u2212\u03b1), for \u03b3 \u2208 [0, 1], is also a probability model for this plp.\nThe well-founded semantics is instead a single distribution that assigns P(s1) = 1 \u2212 \u03b1, and assigns probability mass \u03b1 to the partial interpretation {\u00acr}.\nNow consider an inference; say for instance one wants P(r = true). Clearly P(r = true) = 1 \u2212 \u03b1, regardless of the semantics. But consider p. With respect to the credal semantics, the relevant quantities are P(p = true) = 0 and P(p = true) = 1 \u2212 \u03b1. And with respect to the well-founded semantics we have instead P(p = true) = 0 and P(p = false) = \u03b1, while P(p = undefined) = 1\u2212 \u03b1.\nTo elaborate on this sort of programming pattern, consider the following non-propositional example, adapted from Eiter, Ianni, and Krennwalner (2009):\n0.9 :: man(dilbert). single(X) :\u2212 man(X),not husband(X). husband(X) :\u2212 man(X),not single(X).\nWhen man(dilbert) is discarded, the resulting normal logic program has a single stable model s1 = {\u00acman(dilbert),\u00achusband(dilbert),\u00acsingle(dilbert)}. When man(dilbert) is a fact, the resulting program two stable models:\ns2 = {man(dilbert), husband(dilbert),\u00acsingle(dilbert)},\ns3 = {man(dilbert),\u00achusband(dilbert), single(dilbert)};\nthe well-founded semantics instead leads to undefined values both for husband(dilbert) and single(dilbert).\nNote that any probability measure such that P(s1) = 0.1, P(s2) = 0.9\u03b3, and P(s3) = 0.9(1\u2212\u03b3), for \u03b3 \u2208 [0, 1], is a probability model. Hence we have P(husband(dilbert) = true) = 0 and P(husband(dilbert) = true) = 0.9 with respect to the credal semantics, while we have P(husband(dilbert) = true) = 0, P(husband(dilbert) = false) = 0.1, and finally we have P(husband(dilbert) = undefined) = 0.9 with respect to the well-founded semantics.\nExample 10. Now take a plp adapted from an example by Hadjichristodoulou and Warren (2012, Example IV.1), where the same pattern of cyclic negation observed in the previous example seems to appear:\ncold :\u2212 headache, a. cold :\u2212 not headache,not a. 0.34 :: a. headache :\u2212 cold, b. headache :\u2212 not b. 0.25 :: b.\nThere are four total choices, each inducing a normal logic program. In one case, namely {\u00aca, b}, the resulting normal logic program has no stable model. Hence, this plp has no credal semantics. However, it does have a well-founded semantics. Table 1 shows the assignments for cold and headache induced by the various total choices; we obtain\nP(cold = true) = 0.255, P(headache = true) = 0.750, P(cold = undefined) = 0.165, P(headache = undefined) = 0.165,\nP(cold = false) = 0.580, P(headache = false) = 0.085.\nby collecting probabilities from Table 1.\nExample 11. Consider a graph coloring problem consisting of the rules:\ncolor(V, red) :\u2212 not color(V, yellow),not color(V, green), vertex(V ). color(V, yellow) :\u2212 not color(V, red),not color(V, green), vertex(V ). color(V, green) :\u2212 not color(V, red),not color(V, yellow), vertex(V ).\nclash :\u2212 not clash, edge(V,U), color(V,C), color(U,C).\nand the facts: for i \u2208 {1, . . . , 5}, vertex(i)., and\ncolor(2, red). color(5, green). 0.5 :: edge(4, 5).\nedge(1, 3). edge(1, 4). edge(2, 1). edge(2, 4). edge(3, 5). edge(4, 3).\nThe facts mentioning vertex and edge encode the graph in Figure 3 (left); the probabilistic fact is indicated as a dashed edge. A total choice determines a particular graph. For a fixed total choice, the stable models of the program are the 3-colorings of the resulting graph (this is indeed a popular example of answer set programming (Eiter et al., 2009)).\nNow, if probabilistic fact edge(4, 5) is true, there is a single stable model; otherwise, there are two stable models. Using the credal semantics we obtain: P(color(1, yellow) = true) = 0\nand P(color(1, yellow) = true) = 1/2; also, we have P(color(4, yellow) = true) = 1/2 and P(color(4, yellow) = true) = 1; and P(color(3, red) = true) = P(color(3, red) = true) = 1.\nOn the other hand, the well-founded semantics leaves undefined the colors of vertices 1, 3, and 4, both when edge(4, 5) is true and when it is false. Thus we have, for V \u2208 {1, 3, 4} and C \u2208 {red, yellow, green}, that P(color(V,C) = undefined) = 1.\nExample 12. Take the normal logic program discussed in Example 3, and consider the following probabilistic version (there is one probabilistic move in the game):\nwins(X) :\u2212 move(X,Y ),not wins(Y ). move(a, b). move(b, a). move(b, c). 0.3 :: move(c, d).\nIf move(c, d) is discarded, there is a single stable model (where b is the only winning position); otherwise, there are two stable models (wins(c) is true and wins(d) is false in both of them; wins(a) is true in one, while wins(b) is true in the other). Thus the credal semantics yields P(wins(b) = true) = 0.7 and P(wins(b) = true) = 1.0; P(wins(c) = true) = 0.3 and P(wins(c) = true) = 0.3.\nNow if move(c, d) is discarded, the well-founded model is the unique stable model where b is the only winning position. But if move(c, d) is true, then the well-founded model assigns true to wins(c) and false to wins(d), leaving both wins(a) and wins(b) as undefined. Hence the well-founded semantics yields P(wins(c) = true) = 0.3 and P(wins(c) = false) = 0.7, while P(wins(b) = true) = 0.7 and P(wins(b) = undefined) = 0.3.\nExample 13. Return to the Barber Paradox discussed in Example 4, now with a probabilistic twist:\nshaves(X,Y ) :\u2212 barber(X), villager(Y ),not shaves(Y, Y ). villager(a). barber(b). 0.5 :: villager(b).\nThis program does not have a stable model when villager(b) is a fact. Thus the plp fails to have a credal semantics.\nHowever, the well-founded semantics is clear even when villager(b) is true: in this case, barber(a), shaves(a, a) and shaves(a, b) are false, while shaves(b, a) is true, and shaves(b, b) is undefined. And the well-founded semantics is also clear when villager(b) is discarded (that is, when villager(b) is false): only shaves(b, a) is true. Hence we obtain P(shaves(b, a) = true) = 1, while P(shaves(b, b) = false) = 0.5 and P(shaves(b, b) = undefined) = 0.5.\nThese examples should suffice to show that there are substantial differences between the credal and the well-founded semantics. What to choose?\nWe start our analysis with the well-founded semantics. At first it may seem that this semantics is very attractive because if attaches a unique probability distribution to every well-formed plp (even in cases where the credal semantics is not defined). Besides, the well-founded semantics for plps is conceptually simple for anyone who has mastered the well-founded semantics for normal logic programs.\nOn the other hand, some of the weaknesses of the well-founded semantics already appear in non-probabilistic programs. Certainly the point here is not to emphasize non-probabilistic programs, but consider the difficulty of the well-founded semantics in \u201creasoning by cases\u201d. For instance, consider the program (van Gelder et al., 1991):\na :\u2212 not b. b :\u2212 not a. p :\u2212 a. p :\u2212 b.\nThe well-founded semantics leaves every atom undefined. However, it is apparent that p should be assigned true, for we can find two ways to understand the relation between a and b, and both ways take p to true (these two interpretations are exactly the stable models: one contains a and \u00acb, the other contains \u00aca and b). The reader should note that this is similar to the situation in Example 11: there the well-founded semantics cannot even fix the color of vertex 3, even though this vertex must clearly be colored red.\nThe well-founded semantics of non-probabilistic normal logic programs has also drawn criticism in its reliance on three-valued logic, and the status of the undefined truth value has received attention not only in philosophical inquiry (Bergmann, 2008; Malinowski, 2007), but in the practical development of databases (Date, 2005; Rubinson, 2007). In short, it is difficult to determine whether undefined should be taken as simply an expression of subjective ignorance, or the indication that something really is neither true nor false (Wallace, 1993, Section 1.2.1.2).\nIn any case, we do not want to repeat the old and unresolved debate on three-valued logic here; we want to focus on the even bigger problems that appear when three-valued logic is mixed with probabilities. The problem is that undefined values reflect a type of uncertainty, and probability is supposed to deal with uncertainty; by putting those together we may wish to invite collaboration but we may end up with plain confusion. Consider for instance Example 10. What does it mean to say that P(headache = undefined) = 0.165? Supposedly probability is here to tell us the odds of true and false; by learning the probability of undefined, the next question should be about the probability of headache to be true when one is saying that it is undefined. In fact, one might ask for the value of P(headache = true|headache = undefined), not realizing that in the well-founded semantics this value is simply zero. To emphasize the difficulty in interpretation, suppose we add to Example 10 the simple rule\nc :\u2212 a, b.\nand one asks for P(c = false|cold = undefined). Should this number really be 1, as obtained through the well-founded semantics, or should we expect this to be a question about P(c = false), given that nothing of substance is observed about cold?\nThe probabilistic Barber Paradox discussed in Example 13 describes a situation where the well-founded semantics can answer questions for some individuals, even as it fails to find definite answers for other questions. This is rather attractive, but one must ask: What exactly is the meaning of P(shaves(b, b) = undefined) = 0.5? Note that, for the logical program described in Example 4, it makes sense to return an undefined value: we are at a logical corner. However, for the probabilistic program it is less sensible to obtain a non-zero probability that some particular fact is undefined.\nA difficulty here is that undefined values appear due to a variety of situations that should apparently be treated in distinct ways: (i) programs may be contradictory (as it happens in Example 10); (ii) programs may fail to have a clear meaning (as in the Barber Paradox); or (iii) programs may simply have several possible meanings (for instance, various stable models as in Example 11). In case (i), it is even surprising that one would try to assign probabilities to contradictory cases. In cases (ii) and (iii), probabilities may be contemplated, but then there is a confusing mix of probabilities and undefined values. The interpretation of the various possible meanings of undefined, already difficult in three-valued logic, is magnified by the challenges in interpreting probabilities.\nNow consider the credal semantics. There are two possible criticisms one may raise against it. First, a program may fail to have a credal semantics: consider the probabilistic Barber Paradox. Second, the credal semantics relies on sets of probability measures (credal sets), not on unique measures. We examine these two points in turn.\nThe fact that some programs may fail to have a credal semantics is an annoyance in that programs must be checked for consistency. However, as we have noted already, some programs can seem contradictory, and in those cases one could argue that it is appropriate not to have semantics. So, one may be perfectly satisfied with failure in Example 10, for the total choice {\u00aca, b} in essence leads to the following clearly unsatisfiable pair of rules:\nheadache :\u2212 cold. cold :\u2212 not headache.\nWhat seems to be needed here is a verifier that checks consistency of plps; we look into this later in this paper.\nNow consider the fact that the credal semantics relies on credal sets. Anyone expecting any inference to produce a single probability value may be puzzled, but reliance on sets of probabilities does not seem to be a flaw when examined in detail. One argument in favor of sets of probabilities is that they are legitimate representations for incomplete, imprecise or indeterminate beliefs, that can be justified in a variety of ways (Augustin et al., 2014; Troffaes & De Cooman, 2014; Walley, 1991). But even if one is not willing to take credal sets as a final representation of beliefs, the credal semantics is wholly reasonable from a least commitment perspective. That is, the main question should always be: What are the best bounds on probabilities that one can safely assume, taking into account only the given rules, facts, and assessments? From this point of view, Examples 9, 11, and 12 are entirely justified: the options given to the program are not decided by the given information, so one must leave them open. In particular Example 11 seems to be an excellent argument for the credal semantics: basically, the program generates all 3-colorings of a given graph; why\nshould we insist on singling out a distribution over colorings when no preference over them is expressed?\nAll in all, we find that the credal semantics is conceptually stronger than the well-founded semantics, even though the latter is uniquely defined for every plp. We now examine the structural and computation properties of these two semantics; a final comparison is left to Section 9."}, {"heading": "5 The structure of credal semantics", "text": "Given the generality of plps, one might think that credal sets generated by the credal semantics could have an arbitrarily complex structure. Surprisingly, the structure of the credal semantics of a plp is a relatively simple object:\nTheorem 14. Given a consistent plp, its credal semantics is a set of probability measures that dominate an infinitely monotone Choquet capacity.\nBefore we present a proof of this theorem, let us pause and define a few terms. An infinitely monotone Choquet capacity is a set function P from an algebra A on a set \u2126 to the real interval [0, 1] such that (Augustin et al., 2014, Definition 4.2): P(\u2126) = 1\u2212P(\u2205) = 1 and, for any A1, . . . , An in the algebra, P(\u222aiAi) \u2265 \u2211 J\u2286{1,...,n}(\u22121) |J |+1\nP(\u2229j\u2208JAj). Infinitely monotone Choquet capacities appear in several formalisms; for instance, they are the belief functions of Dempster-Shafer theory (Shafer, 1976), summaries of random sets (Molchanov, 2005), and inner measures (Fagin & Halpern, 1991).\nGiven an infinitely monotone Choquet capacity P, we can construct a set of measures that dominate P; this is the set {P : \u2200A \u2208 A : P(A) \u2265 P(A)}. We abuse language and say that a set consisting of all measures that dominate an infinitely monotone Choquet capacity is an infinitely monotone credal set. If a credal set K is infinitely monotone, then the lower probability P, defined as P(A) = infP\u2208K P(A), is exactly the generating infinitely monotone Choquet capacity. We also have the upper probability P(A) = supP\u2208K P(A) = 1\u2212 P(A c).\nProof of Theorem 14. Consider a set \u0398 containing as states the posssible total choices of the plp. Over this space we have a product measure that is completely specified by the probabilities attached to probabilistic facts. Now consider a multi-valued mapping \u0393 between \u0398 and the space \u2126 of all possible models of our probabilistic logic program. For each element \u03b8 \u2208 \u0398, define \u0393(\u03b8) to be the set of stable models associated with the total choice \u03b8 of the probabilistic facts. Now we use the fact that a probability space and a multi-valued mapping induce an infinite monotone Choquet capacity over the range of the mapping (that is, over \u2126) (Molchanov, 2005).\nInfinitely monotone credal sets have several useful properties; for one thing they are closed and convex. Convexity here means that if P1 and P2 are in the credal set, then \u03b1P1 + (1 \u2212 \u03b1)P2 is also in the credal set for \u03b1 \u2208 [0, 1]. Thus, as illustrated by Example 9.\nCorollary 15. Given a consistent plp, its credal semantics is a closed and convex set of probability measures.\nThere are several additional results concerning the representation of infinitely monotone capacities using their M\u00f6bius transforms (Augustin et al., 2014; Shafer, 1976); we refrain from mentioning every possible corollary we might produce by rehashing those results. Instead, we focus on a few important results that can be used to great effect in future applications. First, as we have a finite Herbrand base, we can use the symbols in the proof of Theorem 14 to write, for any set of models M (Augustin et al., 2014, Section 5.3.2):\nP(M) = \u2211 \u03b8\u2208\u0398:\u0393(\u03b8)\u2286M P(\u03b8) , P(M) = \u2211 \u03b8\u2208\u0398:\u0393(\u03b8)\u2229M6=\u2205 P(\u03b8) . (5)\nSuppose we are interested in the probability of a setQ of truth assignments for ground atoms in the Herbrand base of the union of program P with all facts in PF. A direct translation of Expression (5) leads to an algorithm that computes bounds on P(Q) as follows:\n\u2022 Given a plp \u3008P,PF\u3009 and Q, initialize a and b with 0.\n\u2022 For each total choice \u03b8 of probabilistic facts, compute the set S of all stable models of P \u222aPF\u2193\u03b8, and:\n\u2013 if Q is true in every stable model in S, then a \u2190 a+ P(\u03b8);\n\u2013 if Q is true in some stable model of S, then b \u2190 b+ P(\u03b8).\n\u2022 Return [a, b] as the interval [P(Q) ,P(Q)].\nNote that to find whether Q is true in every stable model of a program, we must run cautious inference, and to find whether Q is true in some stable model of a program, we must run brave inference. The complexity of these logical inferences have been studied in depth in the literature (Eiter et al., 2007).\nFor infinitely monotone credal sets we can find easy expressions for lower and upper conditional probabilities (that is, the infimum and supremum of conditional probabilities). Indeed, if A and B are events, then the lower probability of A given B is (where the superscript c denotes complement) (Augustin et al., 2014):\nP(A|B) = P(A \u2229B)\nP(A \u2229B) + P(Ac \u2229B) (6)\nwhen P(A \u2229B) + P(Ac \u2229B) > 0; we then have that P(A|B) = 1 when P(A \u2229B) + P(Ac \u2229B) = 0 and P(A \u2229B) > 0; finally, P(A|B) is undefined when P(A \u2229B) = P(Ac \u2229B) = 0 (as this condition is equivalent to P(B) = 0). Similarly, the upper probability of A given B is:\nP(A|B) = P(A \u2229B)\nP(A \u2229B) + P(Ac \u2229B) (7)\nwhen P(A \u2229B)+P(Ac \u2229B) > 0; and we have that P(A|B) = 0when P(A \u2229B)+P(Ac \u2229B) = 0 and P(Ac \u2229B) > 0; finally, P(A|B) is undefined when P(A \u2229B) = P(Ac \u2229B) = 0. We also note that the computation of lower and upper expected values with respect to infinitely monotone Choquet capacities admits relatively simple expressions (Wasserman & Kadane, 1992). For instance, the lower expectation E[f ] = infP\u2208K EP[f ], where f is a function over the truth assignments, and EP[f ] is the expectation of f with respect to P, is\nE[f ] = \u2211\n\u03b8\u2208\u0398max\u03c9\u2208\u0393(\u03b8) f(\u03c9) (Wasserman & Kadane, 1992). And there are expressions even for lower and upper conditional expectations that mirror Expression (5).\nTo translate these expresions into actual computations, suppose we have a sets (Q and E of truth assignments for ground atoms in the Herbrand base of the union of program P with all facts in PF. To obtain bounds on P(Q|E), we can combine the previous algorithm with Expressions (6) and (7), to obtain:\n\u2022 Given a plp \u3008P,PF\u3009 and Q, initialize a, b, c, and d with 0.\n\u2022 For each total choice \u03b8 of probabilistic facts, compute the set S of all stable models of P \u222aPF\u2193\u03b8, and:\n\u2013 if Q \u222aE is true in every stable model in S, then a \u2190 a+ P(\u03b8);\n\u2013 if Q \u222aE is true in some stable model of S, then b \u2190 b+ P(\u03b8);\n\u2013 if Q if false and E is true in every stable model of S, then c \u2190 c+ P(\u03b8);\n\u2013 if Q if false and E is true in some stable model of S, then d \u2190 d+ P(\u03b8).\n\u2022 Return the interval [P(Q|E) ,P(Q,E)] as follows, in case b+d > 0 (otherwise, report failure and stop):\n\u2013 [0, 0] if b+ c = 0 and d > 0;\n\u2013 [1, 1] if a+ d = 0 and b > 0;\n\u2013 [a/(a + d), b/(b + c)] otherwise.\nIn fact the algorithm above has already been derived by Cal\u00ec, Lukasiewicz, Predoiu, and Stuckenschmidt (2009), using clever optimization techniques (note that Cali et al. use a different strategy to handle the case where P(E) = 0). The advantage of our approach is that the algorithm is a transparent consequence of known facts about capacities; other than that, Cali et al. have already presented the algorithm so we do not need to dwell on it. Rather, we later return to this algorithm with a focus on the complexity of computing of the lower probability P(Q|E). Algorithms that reproduce some properties of infinitely monotone Choquet capacities are also presented by Michels et al. (2015) in their work on constraint logic programming."}, {"heading": "6 The complexity of inferences: acyclic and stratified proba-", "text": "bilistic logic programs\nIn this section we focus on the computation of inferences for acyclic and stratified plps; in these cases both the credal and the well-founded semantics agree. We focus on the following decision problem:\nInput: A plp \u3008P,PF\u3009 whose probabilities are rational numbers, a pair (Q,E), called the query, where both Q and E are sets of truth assignments to atoms in the Herbrand base of the union of program P and all facts in PF, and a rational \u03b3 \u2208 [0, 1].\nOutput: Whether or not P(Q|E) > \u03b3; by convention, output is NO (that is, input is rejected) if P(E) = 0.\nWe refer to this complexity as the inferential complexity of plps. One may also be interested in the complexity of inferences when the plp is fixed, and the only input is the query (Q,E). This is the query complexity of the program; to define it, consider:\nFixed: A plp \u3008P,PF\u3009, whose probabilities are rational numbers, that employs a vocabulary R of predicates.\nInput: A pair (Q,E), called the query, where both Q and E are sets of truth assignments to atoms of predicates in R, and a rational \u03b3 \u2208 [0, 1].\nOutput: Whether or not P(Q|E) > \u03b3; by convention, output is NO if P(E) = 0.\nSay that the query complexity of a class P of plps is in a complexity class C if the complexity of this decision problem is in C for every plp in P. And say that the query complexity of P is C-hard if each decision problem in C can be reduced, with many-one reductions, to a decision problem for at least one plp in P. And say that the query complexity of P is C-complete if P is both in C and C-hard.\nIn practice, one may face situations where a plp may be small compared to the query, or where a single plp is queried many times; then query complexity is the concept of interest.\nThe definition of query complexity is clearly related to the concept of data complexity found in database theory (Abiteboul, Hull, & Vianu, 1995); indeed we have used \u201cdata complexity\u201d in previous related work (Cozman & Mau\u00e1, 2015a). Here we prefer to use \u201cquery\u201d instead of \u201cdata\u201d because usually data complexity fixes the rules and varies the number of facts; in this paper we keep both rules and facts fixed. In fact, we have already mentioned the highly relevant work by Ceylan et al. (2016), where they study the complexity of various types of probabilistic logic programs; in that work they use data complexity to refer to the complexity of computing probabilistic for fixed queries and fixed programs, as the stock of facts and probabilistic facts varies. Note also that Ceylan et al. consider a much more sophisticated language for queries that we do; for them, a query can be any union of Boolean conjunctive query as usually employed in databases (Date, 2005). The distinction between \u201cquery\u201d and \u201cdata\u201d thus seems significant in the context of probabilistic logic programming.\nWe must further comment on a few parallel results by Ceylan et al. (2016). They analyze the complexity of plps under two semantics; one of them is in line with Sato\u2019s distribution semantics, and another one is geared towards inconsistent programs; neither is equivalent to the credal or the well-founded semantics. Moreover, they focus on queries that are Boolean formulas, they do not allow for conditioning evidence, and they use a somewhat different version of probabilistic facts called contexts (that can be reproduced with our probabilistic facts). Despite these differences, in dealing with their first semantics they prove statements that are related to results in Section 6.1. More precisely: by translating the various languages and arguments appropriately, the points made by our Theorems 18 and 19 can be obtained from their results on full acyclic programs; also our Theorem 22 is comparable to their corresponding result, even though our \u201cquery\u201d complexity is not their\n\u201cdata\u201d complexity.3 We decided to include our proof of Theorem 19 in full here because we need the techniques in later proofs, and because we find that our techniques illuminate the matter adequately."}, {"heading": "6.1 Acyclic probabilistic logic programs", "text": "We start with acyclic plps. In this case the credal and the well-founded semantics define a single distribution, given by a Bayesian network whose structure is the program\u2019s grounded dependency graph, and whose parameters are obtained from the program\u2019s Clark completion (Poole, 1993, 2008).\nExample 16. Take a simplified version of the plp in Example 5, without predicates calls and neighbor:\n0.7 :: burglary. 0.2 :: earthquake. alarm :\u2212 burglary, earthquake, a1. alarm :\u2212 burglary,not earthquake, a2. alarm :\u2212 not burglary, earthquake, a3. 0.9 :: a1. 0.8 :: a2. 0.1 :: a3.\nWe can understand this plp as the specification of the Bayesian network in Figure 4. Note that the structure of the network is just the grounded dependency graph, and the logical sentence comes directly from the Clark completion.\nConversely, any propositional Bayesian network can be specified by an acyclic propositional plp (Poole, 1993, 2008). The argument is simple, and we show it by turning Example 16 upside down:\nExample 17. Suppose we have the Bayesian network in Figure 5. This Bayesian network is equivalent to the Bayesian network in Figure 4 (that is: the same distribution is defined over alarm, burglary, earthquake). And the latter network is specified by an acyclic plp.\nBy combining these arguments, we see that inference in acyclic propositional plps has the complexity of inference in Bayesian networks (Darwiche, 2009; Roth, 1996):\nTheorem 18. The inferential complexity of inference in acyclic propositional plps is PPcomplete.\n3We note that our results on acyclic programs appeared (Cozman & Mau\u00e1, 2016) almost simultaneously to the publication by Ceylan et al. (2016), and were produced independently.\nOne might suspect that a bound on predicate arity would yield the same PP-completeness, because the grounding of a plp would then produce only polynomially-many ground atoms. Surprisingly, this is not the case here, as shown by the next theorem.\nTheorem 19. The inferential complexity of inference in acyclic plps with bounded predicate arity is PPNP-complete.\nProof. To prove membership, start with the \u201cunconditional\u201d decision P(Q) > \u03b3. This decision problem is in PPNP; this follows from the fact that logical reasoning with acyclic normal logic programs is \u2206P2 -complete (Eiter et al., 2007, Table 5) (that is, P\nNP-complete). Consider a nondeterministic Turing machine that goes through all probabilistic facts. For each probabilistic fact \u03b1 :: A., where \u03b1 is a rational such that \u03b1 = \u00b5/\u03bd for some (smallest) integers \u00b5 and \u03bd, the machine nondeterministically decides whether to keep A as a fact or discard it; then the machine creates \u00b5 computation paths if A is to be kept (all these computational paths reach the same point), and \u03bd\u2212\u00b5 computation paths if A is to be discarded (again, these computation paths reach the same point). Note that these computation paths can be created with polynomial effort even if \u00b5 and \u03bd are specified in binary notation. Then, for the particular selection of probabilistic facts that are not discarded, the machine processes the resulting acyclic normal logic program: logical reasoning can determine whether any set of truth assignments, for atoms in the Herbrand base, hold or not. The input is in the language if more than half the computation paths of this machine are accepting paths. This decides whether P(Q) > 1/2.\nNow consider membership of the decision P(Q|E) > \u03b3; we process this decision as follows.4 Suppose the query consists of Q = {Q1, . . . , Qn} and E = {E1, . . . , Em}, where each Qi and each Ej is a literal. The simpler case is \u03b3 \u2265 1/2, so assume it to begin. Then, as the query is processed, introduce aux1 :\u2212 Q1, . . . , Qn., aux2 :\u2212 E1, . . . , Em., aux3 :\u2212 aux1, aux2, aux4., aux3 :\u2212 not aux2, aux5., where each literal Qi or Ej is written as the corresponding subgoal, and (1/(2\u03b3)) :: aux4., 0.5 :: aux5.. Thus P(aux3 = true) > 1/2 \u21d4 (1/(2\u03b3))P(Q,E) + (1/2)(1 \u2212 P(E)) > 1/2 \u21d4 P(Q|E) > \u03b3 (that is, the decision on P(aux3 = 1) > 1/2 yields the decision on P(Q|E) > \u03b3). Now if \u03b3 < 1/2, then introduce aux3 :\u2212 not aux1, aux2, aux6., remove aux4, and introduce (1\u2212 2\u03b3)/(2\u2212 2\u03b3) :: aux6.. Thus P(aux3 = true) > 1/2 \u21d4 P(Q,E) + (1\u2212 2\u03b3)/(2\u2212 2\u03b3)(P(E)\u2212 P(Q,E)) + (1/2)(1\u2212 P(E)) > 1/2 \u21d4 P(Q|E) > \u03b3, as desired. (This technique is used several times in latter proofs.)\n4We are indebted to Cassio Polpo de Campos for suggesting this technique; the probabilities attached to probabilistic facts are as proposed by Park and described by Darwiche (2009, Theorem 11.5).\nHardness is shown by building a plp that solves the problem #13CNF(>) as defined in Section 2.2; that is, one has a propositional sentence \u03c6 in 3CNF with two sets of logical variables X and Y, and the goal is to decide whether the number of truth assignments for X that satisfy \u2203Y : \u03c6(X,Y) is larger than a given integer M . We take \u03c6 to be a conjunction of clauses c1, . . . ck; each clause cj contains an ordered triplet of propositional variables.\nFor instance, we might have as input the integer M = 1 and the formula\n\u03d5(x1, x2, y1) \u2261 (\u00acx1 \u2228 x2 \u2228 y1) \u2227 (x1 \u2228 \u00acx2 \u2228 y1) \u2227 (\u00acy1 \u2228 \u00acy1 \u2228 \u00acy1). (8)\nIn this case the input is accepted (the number of satisfying assignments is 2). Note that the last clause is equivalent to \u00acy1; we pad the clause so as to have three literals in it.\nFor each propositional variable yi, we introduce a corresponding logical variable Yi. The ordered tuple of propositional variables in clause cj corresponds to a tuple of propositional variables that is denoted by Yj ; these are the propositional variables in cj that belong to Y. In Expression (8), Y1 = Y2 = Y3 = [Y1].\nWe use a few constants and predicates. Two constants, 0 and 1, stand for false and true respectively. Also, we use 0-arity predicates xi, each one standing for a propositional variable xi in X. And we use predicates c1, . . . , ck, each one standing for a clause cj . The arity of each cj is the length of Yj, denoted by dj .\nFor each cj, go over the 2dj possible assignments of Yj . That is, if dj = 1, then go over cj(0) and cj(1); if dj = 2, then go over cj(0, 0), cj(0, 1), cj(1, 0) and cj(1, 1). And if dj = 3, go over the 8 assignments. Note that if dj = 0, there is only one \u201cempty\u201d assignment to visit. Thus there are at most 8k assignments to consider.\nSuppose then that we have predicate cj, and we take the assignment y (which may be empty). If cj is true for y, regardless of the possible assignments for propositional variables xi, then just introduce the fact\ncj(y).\nIf instead cj is false for y, regardless of the possible assignments for propositional variables xi, then just move to another assignment (that is, there are no propositional variables xi in cj , and the clause is false for y; by leaving cj(y), we guarantee that it is forced to be false by the semantics). Otherwise, there are propositional variables in X that affect the truth value of cj when y is fixed; there may be one, two or three such propositional variables. Take the first one of them, denoted by xj1, and introduce the rule\ncj(y) :\u2212\n{\nxj1. if the literal for xj1 does not contain negation; or not xj1. if the literal for xj1 contains negation.\nIf there is a second propositional variable xj2 that affects the truth value of cj when y is fixed, add a similar rule cj(y) :\u2212 [not] xj2. And similarly if there is a third propositional variable xj3 that affects the truth value of cj. Note that these rules create a disjunction for cj, in effect encoding the clause cj for fixed y.\nFinally, introduce the rule\ncnf :\u2212 c1(Y1), c2(Y2), . . . , ck(Yk).\nand probabilistic facts (one per predicate xi)\n0.5 :: xi.\nThe Clark completion of the plp just constructed encodes the #13CNF(>) problem of interest, thus proving PPNP-hardness: to determine whether \u2203Y : \u03c6(X,Y) has more than M satisfying assignments, decide whether P(cnf = true) > M/2n, where n is the number of propositional variables in X.\nFor instance, given the formula in Expression (8), generate the following plp:\nc1(0) :\u2212 not x1 . c1(0) :\u2212 x2 . c1(1). c2(0) :\u2212 x1 . c2(0) :\u2212 not x2 . c2(1). c3(0). cnf :\u2212 c1(Y1), c2(Y1), c3(Y1). 0.5 :: x1. 0.5 :: x2.\nBy determining whether P(cnf = true) > M/22, we decide whether the number of truth assignments for x1 and x2 such that \u2200y1\u03d5(x1, x2, y1) holds is larger than M .\nIntuitively, this results shows that, to produce an inference for a plp with bounded predicate arity, one must go through the truth assignments for polynomially many groundings, guessing one at a time (thus a counting nondeterministic Turing machine), and, for each assignment, it is then necessary to use an NP-oracle to construct the probability values. Theorem 19 suggests that acyclic plps capture a larger set of probabilistic languages than many probabilistic relational models that stay within PP (Cozman & Mau\u00e1, 2015b).\nThe next step is to remove the bound on arity. We obtain:\nTheorem 20. The inferential complexity of inference in acyclic plps is PEXP-complete.\nProof. Membership follows from grounding the plp.5 If the plp has n constants, then a relation of arity k produces nk groundings. Each one of these exponentially many groudings corresponds to a node of a (necessarily acyclic) Bayesian network. To write down the conditional probabilities associated with each node of the grounded Bayesian network, take the Clark completion of the program, and ground the expresions. For each non-root node we have a first-order formula that can be written as a possibly exponentially-long quantifierfree formula. Now to determine whether P(Q) > 1/2, we can use a probabilistic Turing machine that runs inference for the exponentially large (grounded) Bayesian network (or, rather, there is an exponential-time Turing machine that guesses a truth assignment for all grounded probabilistic facs, and for each such truth assignment, computes the truth assignment for any other atom by going through the possibly exponentially large non-root node completions).\nTo prove hardness, we encode an exponential-time nondeterministic Turing machine M using logical formulas that are directly produced by the Clark completion of an acyclic normal logic program P. Assume that M can solve some PEXP-complete problem; that is, for a PEXP-complete language L, \u2113 \u2208 L iff M halts within time 2n with more than half of paths accepting \u2113, where n is some polynomial on the length of \u2113. We also add probabilistic facts PF to P, so that an inference in the resulting plp decides whether the number of\n5A short proof of membership is obtained by applying the same concise argument used in the proof of Theorem 24(c); here we present a longer but possibly more intuitive argument based on inference on Bayesian networks.\nacceptings paths of M is larger than half of the total number of computation paths (thus deciding the same language as M does). So, consider the encoding of Turing machines that is described by Gr\u00e4del (2007, Theorem 3.2.4), summarized as follows. Suppose M has states q, with an initial state q0, an accepting state qa, and a rejecting state qr; suppose also that M uses an alphabet with symbols \u03c3 (in the alphabet there is a blank symbol \u2294); finally suppose that M has a transition function \u03b4 that takes a pair (q, \u03c3), understood as state q and symbol \u03c3 read by the machine head, and returns one of a number of triplets (q\u2032, \u03c3\u2032,m), where q\u2032 is the next state, \u03c3\u2032 is the symbol to be written at the tape, and m is either \u22121 (head goes to the left), 0 (head stays at the same position), and 1 (head goes to the right). Assume that the alphabet is enlarged so that every pair (q, \u03c3) is also a possible symbol. The input to the machine is a sequence of symbols (q0, \u03c310), \u03c3 2 0 , . . . , \u03c3 m 0 , and a configuration of the tape is \u03c31, \u03c32, . . . , (q, \u03c3), . . . , \u03c32n (note that the \u201cuseful\u201d portion of the tape runs from position 1 to position 2n).\nThe encoding of M is obtained by introducing a number of predicates and a number of first-order sentences \u03c6i; when all these sentences hold, then any interpretation for the predicates is an accepting computation. We omit the logical expressions of this encoding as they can be taken from Gr\u00e4del\u2019s presentation. In any case, if we decide whether the number of interpretations for the predicates in these sentences is larger than half of the number of possible interpretations, we obtain the desired decision. We enforce each sentence \u03c6i by introducing a predicate auxi and a rule auxi :\u2212 \u03c6i (where we write \u03c6i in the rule with the understanding that \u03c6i is obtained as the Clark completion of a set of auxiliary predicates and rules; recall that conjunction, disjunction and negation are available, as well as existential quantifiers; universal quantifiers are produced by negating existential ones); then the sentence \u03c6i holds when {auxi = true} holds. We simply collect all these truth assignments in the set E. Now, we must have one of the sentences in M\u2019s encoding as a \u201cdetector\u201d for the accepting state; that is, \u2203X : stateqa(X), whereX indexes the computation steps, and stateqa(X) is a predicate that indicates that at computation step X the state is stateqa. Denote by auxa the auxiliary predicate associated with the latter sentence. At this point we can reproduce the behavior of M if we focus on interpretations that satisfy E. The next step is to encode the input. Now, the input symbols can be inserted by appropriate facts (these facts refer to predicates introduced in the encoding). And the final step is to count the accepting computations. First we must assume that, once M reaches qa or qr, it stays with the same configuration (it just keeps repeating the state and the tape), so that the number of accepting paths is the same number of interpretations that satisfy {auxa = true}; this assumption is harmless as M can always be modified to do it. Then we add, for each predicate r that is introduced in the construction, except the ones in E, the probabilistic fact 0.5 :: r(X1, . . . ,Xk), where k is the arity of r. Given all of this, the decision P(auxa = true|E) > 1/2 determines whether the number of \u201caccepting\u201d interpretations for M is larger than half the number of intepretations for M. Thus hardness obtains.\nConsider query complexity. The following result is handy:\nTheorem 21. Query complexity is PP-hard for the following plp:\n0.5 :: t(X) . 0.5 :: pos(X,Y ) . 0.5 :: neg(X,Y ) .\nc(Y ) :\u2212 pos(X,Y ), t(X) . c(Y ) :\u2212 neg(X,Y ),not t(X) .\nProof. Consider a CNF formula \u03d5(x1, . . . , xn) with clauses c1, . . . , cm and propositional variables x1, . . . , xn. Let Pj (resp., Nj) be a vector denoting the indices of the positive (negative) literals xi (\u00acxi) in clause j. We can encode the truth-value of a clause cj as c(j), the truth-value of xi as t(i), and the occurrence of a positive (negative) literal xi \u2208 Pj (xi \u2208 Nj) as pos(i, j) (neg(i, j)). So assemble a query Q containing assignments to {c(j) = true} for j = 1, . . . ,m, {pos(i, j) = true} for i \u2208 Pj , j = 1, . . . ,m, {neg(i, j) = true} for i \u2208 Nj, j = 1 . . . ,m. Now if a grounding of pos or neg is not already assigned true, then assign it to false and add this assignment to Q. The Clark completion defines c(j) \u21d4 \u2228\ni\u2208Pj t(i)\u2228\n\u2228\ni\u2208Nj \u00act(i)\nfor every cj. And the number of assignments to x1, . . . , xn that satisfy \u03d5 is larger than M iff P(Q) > M/22s 2+s where s = max(m,n); hence the desired hardness obtains.\nConsequently:\nTheorem 22. The query complexity of inference for acyclic plps is PP-complete.\nProof. Hardness follows from Theorem 21. Membership is obtained using the same reasoning in the proof of Theorem 19, only noting that, once the probabilistic facts are selected, logical reasoning with the resulting acyclic normal logic program can be done with polynomial effort (Dantsin et al., 2001, Theorem 5.1); thus P(Q) > \u03b3 can be decided within PP.\nThere are subclasses of acyclic plps that characterize well-known tractable Bayesian networks. An obvious one is the class of propositional acyclic programs whose grounded dependency graph has bounded treewidth, as Bayesian networks subject to such a bound are tractable (Koller & Friedman, 2009). As another interesting example, consider the twolevel networks that are processed by the Quick-Score algorithm (Heckerman, 1990); that is, two-level networks where the top level consists of marginally independent \u201cdiseases\u201d and the bottom level consists of \u201cfindings\u201d that are conditionally independent given the diseases, and that are determined by noisy-or gates. Such a network can be easily encoded using a propositional acyclic plp; these plps inherit the fact that inference is polynomial when Q contains only negated atoms (that is, only false). Alas, this tractability result is quite fragile, as \u201cpositive\u201d evidence breaks polynomial behavior as long as P 6= NP (Shimony & Domshlak, 2003). Yet another tractable class consists of acyclic definite propositional plps such that each atom is the head of at most one rule: inference in this class is polynomial when Q contains only true. This is obtained by noting that the Clark completion of these programs produces Bayesian networks that are specified using only conjunction, and a polynomial algorithm obtains from results by Cozman and Mau\u00e1 (2015a). This is also a fragile result:\nProposition 23. Inference for the class of acyclic propositional plps such that each atom is the head of at most one rule is PP-complete even if (a) Q contains only true but the program contains not; (b) the program is definite but Q contains false.\nProof. Membership follows, for both (a) and (b), from Theorem 18. So, consider hardness. Any plp in Case (b) produces, as its Clark completion, a Bayesian network that is specified using conjunctions; inference for this sort of Bayesian network is PP-complete when evidence can be \u201cnegative\u201d (Cozman & Mau\u00e1, 2016). Hardness for Case (a) then obtains easily, because one can use negation to turn \u201cpositive\u201d evidence into \u201cnegative\u201d evidence."}, {"heading": "6.2 Stratified probabilistic logic programs", "text": "A stratified normal logic program has the useful property that its universally adopted semantics produces a single interpretation (and is equal to its stable and well-founded semantics). Because every total choice of a stratified plp produces a stratified normal logic program, the credal/well-founded semantics of a stratified plp is a unique distribution.\nOne might fear that in moving from acyclic to stratified programs we must pay a large penalty. This is not the case: the complexity classes remain the same as in Section 6.1:\nTheorem 24. For locally stratified plps, inferential complexity is PEXP-complete; it is PPNP-complete for plps with bounded predicate arity; it is PP-complete for propositional plps. For locally stratified plps, query complexity is PP-complete.\nProof. For propositional stratified plps, hardness comes from the fact that a Bayesian network on binary random variables can be encoded by a stratified program (indeed, by an acyclic program), and inference with such networks is PP-complete (Darwiche, 2009; Roth, 1996). Membership is obtained using the same reasoning in the proof of Theorem 19, only noting that, once the probabilistic facts are selected, logical reasoning with the resulting stratified normal logic program can be done with polynomial effort (Eiter et al., 2007, Table 2).\nFor stratified programs with bounded predicate arity, hardness follows from Theorem 19. Membership is obtained using the same reasoning in the proof of Theorem 19; in fact that proof of membership applies directly to stratified programs with bounded arity.\nFor general stratified plps, hardness is argued as in the proof of Theorem 20. Membership follows from the fact that we can ground the plp into an exponentially large propositional plp. Once the (exponentially-many) probabilistic facts are selected, the Turing machine is left with a stratified propositional normal logic program, and logical inference is polynomial in the size of this program (that is, logical inference requires exponential effort).\nFinally, hardness of query complexity follows from Theorem 21. Membership is obtained using the same reasoning in the proof of Theorem 19, only noting that, once the probabilistic facts are selected, logical reasoning with the resulting stratified normal logic program can be done with polynomial effort as guaranteed by the analysis of data complexity of stratified normal logic programs (Dantsin et al., 2001).\nWe noted, at the end of Section 6.1, that some sub-classes of acyclic programs display polynomial behavior. We now show an analogue result for a sub-class of definite (and therefore stratified, but possibly cyclic) programs with unary and binary predicates:\nProposition 25. Inferential complexity is polynomial for queries containing only true, for plps where: (a) every predicate is unary or binary, and facts can be asserted about them; (b) probabilistic facts can be of the form \u03b1 :: a(X)., \u03b1 :: a(a), \u03b1 :: r(X,Y ) (that is, each unary predicate can be associated with ground or non-ground probabilistic facts, while each binary predicate can be associated to a particular non-ground probabilistic fact); (c) no binary predicate is the head of a rule that has a body; (d) each atom is the head of at most one rule that has a body, and only the three following rule forms are allowed:\na(X) :\u2212 a1(X), . . . , ak(X) . a(X) :\u2212 r(X,Y ) . a(X) :\u2212 r(Y,X) ..\nProof. We show that the inference can be reduced to a tractable weighted model counting problem. First, ground the program in polynomial time (because each rule has at most two logical variables). Since the resulting program is definite, only atoms that are ancestors of the queries in the grounded dependency graph are relevant for determining the truth-value of the query in any logic program induced by a total choice (this follows as resolution is complete for propositional definite programs). Thus, discard all atoms that are not ancestors of a query atom. For the query to be true, the remaining atoms that are not probabilistic facts are forced to be true by the semantics. So collect all rules of the sort a(a) :\u2212 r(a, b) ., a(a) :\u2212 r(b, a) ., plus all facts and all probabilistic facts. This is an acyclic program, so that its Clark completion gives the stable model semantics. This completion is a formula containing a conjunction of subformulas a(a) \u21d4 \u2228\nb r(a, b), a(a) \u21d4 \u2228\na r(a, b), and unit (weighted) clauses corresponding to (probabilistic) facts. The query is satisfied only on models where the lefthand side of the definitions are true, which is equivalent to reducing the subformulas to their righthand side. The resulting weighted model counting problem has been shown to be polynomial-time solvable (Mau\u00e1 & Cozman, 2015)."}, {"heading": "7 The complexity of inferences: credal semantics", "text": "Now consider plps that may be non-stratified. We have to adapt the definitions of inferential and query complexity to account for the fact that we now have lower and upper probabilities. First we focus on lower probabilities; the lower-probability version of inferential complexity for a class of plps is the complexity of the following decision problem:\nInput: A plp \u3008P,PF\u3009 whose probabilities are rational numbers, a pair (Q,E), called the query, where both Q and E are sets of truth assignments to atoms in the Herbrand base of the union of program P and all facts in PF, and a rational \u03b3 \u2208 [0, 1].\nOutput: Whether or not P(Q|E) > \u03b3; by convention, output is NO (that is, input is rejected) if P(E) = 0.\nThe lower-probability version of query complexity is, accordingly:\nFixed: A plp \u3008P,PF\u3009, whose probabilities are rational numbers, that employs a vocabulary R of predicates.\nInput: A pair (Q,E), called the query, where both Q and E are sets of truth assignments to atoms of predicates in R, and a rational \u03b3 \u2208 [0, 1].\nOutput: Whether or not P(Q|E) > \u03b3; by convention, output is NO if P(E) = 0.\nSo, we are ready to state our main results on complexity for the credal semantics. To understand these results, consider the computation of lower probabilities by the algorithms in Section 5: the basic idea is to go through all possible configurations of probabilistic facts, and each configuration requires runs of cautious/brave inference (that it, it is necessary to check whether all possible stable models satisfy Q \u2229 E, and whether all possible stable models fail to satisfy Q while satisfying E. Thus the proof strategies employed previously can be adapted to some extent, by using cautious/brave inference in our Turing machines. We have:\nTheorem 26. Adopt the credal semantics for plps, and assume that input plps are consistent. The lower-probability version of inferential complexity is PPNP NP\n-complete for plps where all predicates have a bound on arity, and PPNP-complete for propositional plps. The lower-probability version of query complexity is PPNP-complete.\nProof. We first focus on propositional programs. To prove membership, we describe a polynomial time nondeterministic Turing machine such that more than half of its computation paths, on a given input, end up accepting iff the input is an YES instance. The machine receives the plp \u3008P,PF\u3009, the pair (Q,E), and the rational \u03b3 \u2208 [0, 1] as input. In case P(Q,E) + P(\u00acQ,E) > 0, where we use \u00acQ to indicate that Q does not hold, we have to decide whether:\nP(Q,E)\nP(Q,E) + P(\u00acQ,E) > \u03b3 \u21d4 (1\u2212 \u03b3)P(Q,E) > \u03b3P(\u00acQ,E) .\nWrite \u03b3 as \u00b5/\u03bd for the smallest possible integers \u00b5 and \u03bd, such that \u03bd > 0, to conclude that our decision is whether\n(\u03bd \u2212 \u00b5)P(Q,E) > \u00b5P(\u00acQ,E) . (9)\nIn case P(Q,E) + P(\u00acQ,E) = 0, there are a few cases to consider, as indicated by the discussion around Expression (6). First, if P(Q \u2229E) = 0, the machine must return NO (numeric probability value is not defined); and if P(Q \u2229E) > 0, the machine must return NO if \u03b3 = 1 and YES if \u03b3 < 1. One simple way to capture all these cases is this: if P(Q,E) > 0 and P(\u00acQ,E) = 0 and \u03b3 < 1, then return YES and stop; otherwise return YES or NO according to inequality in Expression (9). Thus the machine starts by handling the special case in the previous sentence. If \u03b3 < 1, then the machine determines whether P(Q \u2229E) > 0 and P(\u00acQ \u2229E) = 0 using the NP oracle twice. In each case, the oracle guesses a total choice and determines, using brave inference, whether there is a stable model that satisfies the event of interest. If there is no such total choice, then the upper probability is zero. So, if \u03b3 < 1 and P(Q \u2229E) > 0 and P(\u00acQ \u2229E) = 0, move into the accepting state; otherwise, move to some state q and continue.\nFrom q, the machine \u201cgoes through\u201d the possible selections of probabilistic facts, operating similarly to the second algorithm in Section 5. We will use the fact that cautious logical reasoning is coNP-complete and brave logical reasoning is NP-complete (Eiter et al., 2007, Table 2).\nThe machine proceeds from q as in the proof of Theorem 19, nondeterministically selecting whether each fact is kept or discarded. Suppose we have n ground probabilistic facts \u03b11 :: A1., . . . , \u03b1n :: An.. For each probabilistic fact \u03b1i :: Ai., where \u03b1i = \u00b5i/\u03bdi for smallest integers \u00b5i and \u03bdi such that \u03bdi > 0, the machine creates \u00b5i computation paths out of the decision to keep Ai, and \u03bdi \u2212 \u00b5i computation paths out of the decision to discard Ai. Note that after guessing the status of each probabilistic fact the machine may branch in at most \u03bdi paths, and the total number of paths out of this sequence of decisions is \u220fn i=1 \u03bdi. Denote this latter number by N . At this point the machine has a normal logic program, and it runs cautious inference to determine whether Q\u2229E holds in every stable model of this program. Cautious logical reasoning is solved by the NP oracle. If indeed Q\u2229E holds in every stable model of this program, the machine moves to state q1. Otherwise, the machine runs brave inference to determine whether Q is false while E is true in some stable model of the\nprogram. Brave logical reasoning is solved by the NP oracle. And if indeed Q is false while E is true in some stable model of the program, the machine moves to state q2. Otherwise, the machine moves to state q3. Denote by N1 the number of computation paths that arrive at q1, and similarly for N2 and N3. From q1 the machine branches into \u03bd \u2212 \u00b5 computation paths that all arrive at the accepting state (thus there are (\u03bd \u2212 \u00b5)N1 paths through q1 to the accepting state). And from q2 the machine branches into \u00b5 computation paths that all arrive at the rejecting state. Finally, from q3 the machine nondeterministically moves either into the accepting or the rejecting state. Thus the number of accepting computation paths is larger than the number of rejecting computation paths iff\n(\u03bd \u2212 \u00b5)N1 +N3 > \u00b5N2 +N3 \u21d4 (\u03bd \u2212 \u00b5) N1 N > \u00b5 N2 N .\nNote that, by construction, N1/N = P(Q,E) and N2/N = P(\u00acQ,E); thus the number of accepting computation paths is larger than the number of rejecting computation paths iff\n(\u03bd \u2212 \u00b5)P(Q,E) > \u00b5P(\u00acQ,E) .\nMembership is thus proved. Hardness is shown by a reduction from the problem #1DNF(>): Decide whether the number of assignments of X such that the formula \u03c6(X) = \u2200Y : \u03d5(X,Y) holds is strictly larger than M , where \u03d5 is a propositional formula in DNF with conjuncts d1, . . . , dk (and X = {x1, . . . , xn} and Y = {y1, . . . , ym} are sets of propositional variables). Introduce xi for each xi and yi for each yi, and encode \u03c6 as follows. Each conjunct dj is represented by a predicate dj and a rule dj :\u2212 s1, . . . , sr., where si stands for a properly encoded subgoal: either some xi, or not xi, or some yi, or not yi. And then introduce k rules dnf :\u2212 dj., one per conjunct. Note that for a fixed truth assignment for all xi and all yi, dnf is true iff \u03d5 holds. Now introduce probabilistic facts 0.5 :: xi, one for each xi. There are then 2n possible ways to select probabilistic facts. The remaining problem is to encode the univeral quantifier over the yi. To do so, introduce a pair of rules for each yi,\nyi :\u2212 not nyi. and nyi :\u2212 not yi..\nThus there are 2m stable models running through assignments of y1, . . . , ym, for each fixed selection of probabilistic facts. By Expression (5) we have that P(dnf = true) is equal to \u2211\n\u03b8 min f(\u03b8)/2 n, where \u03b8 denotes a total choice, the minimum is over all stable models produced by P \u222a PF\u2193\u03b8, and f(\u03b8) is a function that yields 1 if dnf is true and 0 otherwise. Now min f(\u03b8) yields 1 iff for all Y we have that \u03d5(X,Y) is true, where X is fixed by \u03b8. Hence P(dnf = true) > M/2n iff the input problem is accepted. Hardness is thus proved.\nNow consider plps where predicates have bounded arity. Membership follows using the same construction described for the propositional case, but using a \u03a3P2 oracle as cautious logical reasoning is \u03a0 P 2 -complete and brave logical reasoning is \u03a3P2 -complete (Eiter et al., 2007, Table 5). Hardness is shown by a reduction from #23CNF(>): Decide whether the number of assignments of X such that the formula \u03c6(X) = \u2200Z : \u2203Y : \u03d5(X,Y,Z) holds is strictly larger than M , where \u03d5 is a propositional formula in 3CNF with clauses c1, . . . , ck (and X, Y, and Z are sets of propositional variables, and X contains n propositional variables).\nWe proceed exactly as in the proof of hardness for Theorem 19; each propositional variable yi now appears as a logical variable Yi, while each propositional variable xi appears as a predicate xi. The novelty is that each propositional variable zi appears as a predicate zi that receive the same treatment as predicates yi in the proof for the propositional case. So, just repeat the whole translation of the formula \u03d5 used in the proof of Theorem 19, with the only difference that now there may be propositional variables zi in the formula, and these propositional variables appear as predicates zi in the plp. Then introduce, for each zi, a pair of rules\nzi :\u2212 not nzi. and nzi :\u2212 not zi..\nAgain, for each fixed selection of probabilistic facts, there are stable models, one per assignment of Z. And P(cnf = true) > M/2n iff the input problem is accepted.\nFinally, consider query complexity. Membership follows using the same construction described for the propositional case, but using a NP oracle as cautious logical reasoning is coNP-complete and brave logical reasoning is NP-complete (Dantsin et al., 2001, Theorem 5.8).\nHardness follows again by a reduction from #1DNF(>); that is, again we must decide whether the number of assignments of X such that \u2200Y : \u03d5(X,Y) holds is strictly larger than M , where \u03d5 is a formula in DNF (again, the number of propositional variables in X is n, and the number of propositional variables in Y is m). We employ a construction inspired by the proof of Theorem 21, using the following fixed plp. Note that x stands for the propositional variables in X, where counting operates; y stands for the propositional variables in Y, where the universal quantifier operates; c stands for clauses that are then negated to obtain the DNF:\n0.5 :: x(V ) . 0.5 :: select1(U, V ). 0.5 :: select2(U, V ). 0.5 :: select3(U, V ). 0.5 :: select4(U, V ). y(V ) :\u2212 not ny(V ). ny(V ) :\u2212 not y(V ).\nc(V ) :\u2212 select1(U, V ), x(U) . c(V ) :\u2212 select2(U, V ),not x(U) . c(V ) :\u2212 select3(U, V ), y(U) . c(V ) :\u2212 select4(U, V ),not y(U) . d(V ) :\u2212 not c(V ).\naux :\u2212 d(V ). dnf :\u2212 not aux.\nBy providing select1, select2, select3 and select4 as Q, we can encode the formula \u03d5. Add to Q the assignment {dnf = 1}, and then P(Q) > M/24s\n2+s, where s = max(m,n), iff the input problem is accepted.\nTheorem 26 focuses on the computation of lower probabilities. We can of course define the upper-probability versions of inferential and query complexities, by replacing the decision P(Q|E) > \u03b3 with P(Q|E) > \u03b3. If anything, this latter decision leads to easier proofs of membership, for all special cases are dealt with by deciding whether\n(\u03bd \u2212 \u00b5)P(Q,E) > \u00b5P(\u00acQ,E) ,\nwhere again \u03b3 = \u00b5/\u03bd. All other points in the membership proofs remain the same, once brave and cautious reasoning are exchanged. Several arguments concerning hardness can also be easily adapted. For instance, PPNP-hardness for propositional programs can be proved by reducting from #1CNF(>), by encoding a formula in CNF. Similarly, PP\nNP-hardness for query complexity reduces from #1CNF(>) by using the fixed program described in the proof of Theorem 26 without the latter three rules (and query with assignments on groundings of c).\nTheorem 26 does not discuss the complexity of plps, under the credal semantics, without a bound on arity. Without such a bound, logical cautious reasoning is coNEXP-complete, so we conjecture that exponentially bounded counting Turing machines will be needed here. We leave this conjecture as an open question.\nFinally, our complexity results were obtained assuming that plps were consistent; of course, in practice one must consider the problem of checking consistency. We have:\nProposition 27. Consistency checking is \u03a0P2 -complete for propositional plps and is \u03a0 P 3 - complete for plps where predicates have a bound on arity.\nProof. Membership of consistency checking of a propositional plp obtains by verifying whether logical consistency holds for each total choice of probabilistic facts, and this can be accomplished by deciding whether all total choices satisfy logical consistency (logical consistency checking for this language is NP-complete (Eiter et al., 2007, Table 1)). An analogue reasoning leads to membership in \u03a0P3 for plps with a bound on arity, as logical consistency checking with bounded arity is \u03a3P2 -complete (Eiter et al., 2007, Table 4).\nNow consider hardness in the propositional case. Take a sentence \u03c6 equal to \u2200X : \u2203Z : \u03d5(X,Z), where \u03c6 is a propositional formula in 3CNF with clauses c1, . . . , ck, and vectors of propositional variables X and Z. Deciding the satisfiability of such a formula is a \u03a0P2 - complete problem (Marx, 2011). So, introduce a predicate xi for each xi, associated with a probabilistic fact 0.5 :: xi., and a predicate zi for each zi, associated with rules\nzi :\u2212 not nzi. and nzi :\u2212 not zi..\nNow encode the formula \u03c6 as follows. For each clause cj with three literals, add the rules cj :\u2212 \u21131., cj :\u2212 \u21132., and cj :\u2212 \u21133., where each \u2113i stands for a subgoal containing a predicate in x1, . . . , xn or in z1, . . . , zm, perhaps preceded by not, as appropriate (mimicking a similar construction in the proof of Theorem 19). Then add a rule\ncnf :\u2212 c1, . . . , ck.\nto build the formula \u03d5, and an additional rule\nclash :\u2212 not clash,not cnf.\nto force cnf to be true in any stable model. The question of whether this program has a stable model for every configuration of X then solves the original question about satisfiability of \u03c6.\nFinally, consider hardness in the relational (bounded arity) case. Take a sentence \u03c6 equal to \u2200X : \u2203Z : \u00ac\u2203Y : \u03d5(X,Y,Z), where \u03d5 is a propositional formula in 3CNF; deciding\nthe satisfiability of this formula is a \u03a0P3 -complete problem (Marx, 2011). Denote \u00ac\u2203Y : \u03c6(X,Y,Z) by \u03c6\u2032. The strategy here will be to combine the constructs in the previous paragraph (propositional case) with the proof of hardness for Theorem 19. That is, introduce a predicate xi for each xi, associated with a probabilistic fact 0.5 :: xi., and a predicate zi for each zi, again associated with rules\nzi :\u2212 not nzi. and nzi :\u2212 not zi..\nAnd then encode each clause cj of \u03d5 by introducing a predicate cj(Yj), where Yj is exactly as in the proof of Theorem 19. And as in that proof, introduce\ncnf :\u2212 c1(Y1), c2(Y2), . . . , cm(Ym).\nand force \u03c6\u2032 to be false by introducing:\nclash :\u2212 not clash, cnf..\nThe question of whether this program has a stable model for every configuration of X then solves the original question about satisfiability of \u03d5.\nAgain we have left open the complexity of consistency checking for plps without a bound on predicate arity. This question should be addressed in future work."}, {"heading": "8 The complexity of inference under the well-founded seman-", "text": "tics\nIn this section we investigate the complexity of probabilistic inference under the well-founded semantics. As before, we examine propositional and relational programs, and within the latter we look at programs with a bound on predicate arity. Note that a bound on predicate arity forces each predicate to have a polynomial number of groundings, but the grounding of the program may still be exponential (as there is no bound on the number of atoms that appear in a single rule, each rule may have many logical variables, thus leading to many groundings).\nTheorem 28. Adopt the well-founded semantics for plps. The inferential complexity of plps is PEXP-complete; it is PPNP-complete if the plp has a bound on the arity of its predicates; it is PP-complete if the plp is propositional. The query complexity of plps is PP-complete.\nProof. Consider first propositional plps. Such a plp can encode any Bayesian network over binary variables (Poole, 1993), so inference is PP-hard. Membership is proved by adapting the arguments in the proof of Theorem 19; whenever a total choice is selected by the nondeterministic Turing machine, logical inference (under the well-founded semantics) is run with polynomial effort in the resulting propositional normal logic program (Dantsin et al., 2001).\nConsider now plps with logical variables. Membership follows from the same argument in the previous paragraph, using the fact that inference in normal logic programs under the\nwell-founded semantics is in EXP (Dantsin et al., 2001). Hardness follows from the fact that inferential complexity is PEXP-hard already for acyclic programs (Theorem 20).\nNow consider plps with a bound on the arity of predicates. Membership follows from the same argument in the previous paragraphs, using the fact that inference in normal logic programs with a bound on the arity of predicates is under the well-founded semantics is in in PNP, as proved in Theorem 29. Hardness for PPNP follows from the fact that inference complexity of plps under the stable model semantics is PPNP-hard even for stratified programs, and noting that for stratified programs the stable model and the well-founded semantics agree.\nThe proof of Theorem 28, in the case of plps with bound on predicate arity, uses the following result. Note that this is a result on logical inference; however it does not seem to be found in current literature.\nTheorem 29. Consider the class of normal logic programs with a bound on the arity of predicates, and consider the problem of deciding whether a literal is in the well-founded model of the program. This decision problem is PNP-complete.\nProof. Hardness follows from the hardness of logical inference with stratified programs under the stable model semantics (Eiter et al., 2007). Membership requires more work. We use the monotone operator LFTP(LFTP(I)). Consider the algorithm that constructs the well-founded extension by starting with the empty interpretation and by iterating LFTP(LFTP(I)). As there are only polynomially-many groundings, there are at most a polynomial number of iterations. Thus in essence we need to iterate the operator LFTP(I); thus, focus attention on the computation of LFTP(I). The latter computation consists of finding the least fixpoint of TPI . So we must focus on the effort involved in computing the least fixpoint of TPI . Again, there are at most a polynomial number of iterations of TPI to be run. So, focus on a single iteration of TPI . Note that any interpretation I has polynomial size; however, we cannot explicitly generate the reduct PI as it may have exponential size. What we need to do then is, for each grounded atom A, to decide whether there is a rule whose grounding makes the atom A true in TPI . So we must make a nondeterministic choice per atom (the choice has the size of logical variables in a rule, a polynomial number). Hence by running a polynomial number of nondeterministic choices, we obtain an iteration of TPI ; by running a polynomial number of such iterations, we obtain a single iteration of LFTP(I); and by running a polynomial number of such iterations, we build the well-founded model. Thus we are within PNP as desired.\nObviously, for the well-founded semantics there are no concerns about consistency: every normal logic program has a well-founded semantics, so every plp has one and only one wellfounded semantics."}, {"heading": "9 Conclusion", "text": "We can summarize our contributions as follows. First, we have identified and compared the main ideas between the credal and the well-founded semantics for plps based on probabilistic facts and normal logic programs. Other semantics may be studied in future work, but the\ncredal and the well-founded ones seem to be the most important starting point. Second, we have shown that the credal semantis is intimately related to infinitely monotone Choquet capacitites; precisely: the credal semantics of a consistent plp is a credal set that dominates a infinitely monotone Choquet capacity. Third, we have derived the inferential and query complexity of acyclic, stratified and general plps both under the credal and the well-founded semantics. These results on complexity are summarized in Table 2; note that plps reach non-trivial classes in the counting hierarchy. It is interesting to note that acyclic plps with a bound on arity go beyond Bayesian networks in the complexity classes they can reach.\nConcerning complexity, acyclic and stratified plps have identical credal and well-founded semantics, while general plps may have different credal and well-founded semantics. For normal logic programs (not probabilistic ones), the well-founded semantics is known to stay within lower complexity classes than the credal semantics (Dantsin et al., 2001); the same phenomenon persists in the probabilistic case. Indeed, the well-founded semantics for general plps reaches the same complexity classes as for acyclic plps. One might take this as an argument for the well-founded semantics, on top of the fact that the well-founded semantics is defined for any plp. On the other hand, our analysis in Section 4 favors, at least conceptually, the credal semantics, despite the fact that it may not be defined for some plps (in fact one might argue that no semantics should be defined for such plps). It is much easier to understand the meaning of plps using the credal semantics than the well-founded semantics, as the latter mixes three-valued logic and probabilities in a non-trivial way. We suggest that more study is needed to isolate those programs where undefined values are justified and can be properly mixed with probabilities. Also, the well-founded semantics may be taken as an approximation of the set of possible probability models. In any case, we find that Lukasiewicz\u2019s credal semantics is quite attractive and not as well known as it deserves to be.\nWe could include in the analysis of plps a number of useful constructs that have been adopted in answer set programming (Eiter et al., 2009). There, classic negation, such as \u00acwins(X), is allowed on top of not. Also, constraints, such as :\u2212 \u03c6, are allowed to mean that \u03c6 is false. More substantial is the presence, in answer set programming, of disjunctive heads. With such a machinery, we can for instance rewrite the rules in Example 9 as a single\nrule single(X) \u2228 husband(X) :\u2212 man(X)., and the rules in Example 11 as the pair:\ncolor(V, red) \u2228 color(V, yellow) \u2228 color(V, green) :\u2212 vertex(V ). :\u2212 edge(V,U), color(V,C), color(U,C).\nNow the point to be made is this. Suppose we have a probabilistic logic program \u3008P,PF\u3009, where as before we have independent probabilistic facts, but where P is now a logic program with classic negation, constraints, disjuctive heads, and P is consistent in that it has stable models for every total choice of probabilistic facts. The proof of Theorem 14 can be reproduced in this setting, and hence the credal semantics (the set of measures over stable models) of these probabilistic answer set programs is again an infinite monotone credal set. The complexity of inference with these constructs is left for future investigation.\nMuch more is yet to be explored concerning the complexity of plps. Several classes of plps deserve attention, such as definite, tight, strict, order-consistent programs, and programs with aggregates and other constructs. The inclusion of functions (with appropriate restrictions to ensure decidability) is another challenge. Concerning complexity theory itself, it seems that approximability should be investigated, as well as questions surrounding learnability and expressivity of plps."}, {"heading": "Acknowledgements", "text": "The first author is partially supported by CNPq, grant 308433/2014-9. The second author received financial support from the S\u00e3o Paulo Research Foundation (FAPESP), grant 2016/01055-1."}], "references": [], "referenceMentions": [], "year": 2017, "abstractText": "We examine the meaning and the complexity of probabilistic logic programs that consist of a set of rules and a set of independent probabilistic facts (that is, programs based on Sato\u2019s distribution semantics). We focus on two semantics, respectively based on stable and on well-founded models. We show that the semantics based on stable models (referred to as the \u201ccredal semantics\u201d) produces sets of probability models that dominate infinitely monotone Choquet capacities; we describe several useful consequences of this result. We then examine the complexity of inference with probabilistic logic programs. We distinguish between the complexity of inference when a probabilistic program and a query are given (the inferential complexity), and the complexity of inference when the probabilistic program is fixed and the query is given (the query complexity, akin to data complexity as used in database theory). We obtain results on the inferential and query complexity for acyclic, stratified, and cyclic propositional and relational programs; complexity reaches various levels of the counting hierarchy and even exponential levels.", "creator": "dvips(k) 5.991 Copyright 2011 Radical Eye Software"}}}