{"id": "1702.01948", "review": {"conference": "arxiv", "VERSION": "v1", "DATE_OF_SUBMISSION": "7-Feb-2017", "title": "Continuous-Time User Modeling in the Presence of Badges: A Probabilistic Approach", "abstract": "typical user modeling routinely plays up an important sociological role in explicitly delivering integrated customized web connectivity services to the users and toward improving their engagement.. however, sometimes most ubiquitous user models in the education literature do but not explicitly consider the predominant temporal behavior implications of users. starting more recently, typically continuous - time embodied user modeling has gained recently considerable considerable attention nationally and includes many user resource behavior models research have generally been proposed based on temporal point generation processes. however, particularly typical two point transformation process based models often considered the impact of peer influence and content on the user participation and neglected other factors. gamification elements, are widespread among those organizational factors that are ultimately neglected, while they have indeed a distinct strong biological impact and on user participation roles in online user services. in illustrating this paper, we propose interdependent multi - dimensional global temporal point processes designs that capture the impact negatively of vo badges on user participation besides processing the peer influence matrix and evaluating content content factors. we thoroughly extend the proposed simulation processes to model user actions advantages over access the community based through question messaging and answering websites, review and propose an inference validation algorithm based on variational - em that can efficiently comfortably learn the model parameters. performing extensive experiments on both synthetic instances and real usage data gathered especially from stack overflow show confidence that our inference algorithm learns the parameters efficiently significantly and the proposed evolution method can better predict the user behavior compared successfully to developing the interactive alternatives.", "histories": [["v1", "Tue, 7 Feb 2017 10:32:42 GMT  (819kb,D)", "http://arxiv.org/abs/1702.01948v1", "27 pages, 7 figures"]], "COMMENTS": "27 pages, 7 figures", "reviews": [], "SUBJECTS": "cs.SI cs.LG", "authors": ["ali khodadadi", "seyed abbas hosseini", "erfan tavakoli", "hamid r rabiee"], "accepted": false, "id": "1702.01948"}, "pdf": {"name": "1702.01948.pdf", "metadata": {"source": "CRF", "title": "Continuous-Time User Modeling In the Presence of Badges: A Probabilistic Approach", "authors": ["Ali Khodadadi", "Seyed Abbas Hosseini", "Erfan Tavakoli", "Hamid R. Rabiee"], "emails": ["khodadadi@ce.sharif.edu", "hosseini@ce.sharif.edu", "etavakoli@ce.sharif.edu", "rabiee@sharif.edu"], "sections": [{"heading": null, "text": "Ali Khodadadi AICT Innovation Center, Department of Computer Engineering Sharif University of Technology, Tehran, Iran E-mail: khodadadi@ce.sharif.edu\nSeyed Abbas Hosseini AICT Innovation Center, Department of Computer Engineering Sharif University of Technology, Tehran, Iran E-mail: a hosseini@ce.sharif.edu\nErfan Tavakoli AICT Innovation Center, Department of Computer Engineering Sharif University of Technology, Tehran, Iran E-mail: etavakoli@ce.sharif.edu\nHamid R. Rabiee AICT Innovation Center, Department of Computer Engineering Sharif University of Technology, Tehran, Iran E-mail: rabiee@sharif.edu\nar X\niv :1\n70 2.\n01 94\n8v 1\n[ cs\n.S I]\n7 F\neb 2\n01 7\nbased question and answering websites, and propose an inference algorithm based on Variational-EM that can efficiently learn the model parameters. Extensive experiments on both synthetic and real data gathered from Stack Overflow show that our inference algorithm learns the parameters efficiently and the proposed method can better predict the user behavior compared to the alternatives."}, {"heading": "1 Introduction", "text": "In recent years, online social media have become more and more popular. Social media systems such as Facebook, Twitter, Stack Overflow, and Wikipedia have millions of users engaged in various activities. In these systems, the value is created from voluntary user contributions and they need to engage users as much as possible. Hence, it is of key importance for these systems to provide customized services to satisfy their users and preventing user churns. Therefore, these systems need to maintain and analyze user profiles that contain a summary of important personal information. As much as the systems can create more detailed user profiles, they can provide more customized services to the users. Traditionally, the services create profiles based on the user provided information, that has two main drawbacks. First, many of the users do not create profiles and second, user activities over websites are dynamic over time. Therefore, having automated user profiling systems that consider the temporal dynamics of user activities will results in more realistic and applicable profiles.\nThe unprecedented traces of user activities over social computing services provides rich information about what is done by which entities, corresponding to their location and time. These information create new opportunities for learning user interests and modeling users behavior over these systems, which can be used for creating automated user profiles. The temporal dynamics of user behavior carry a great deal of information and can help the service providers in many aspects, such as designing efficient marketing strategies, providing customized services, and preventing users\u2019 churn. For example, in an on-line shopping service it is important to predict when a user will use an item, or in a community based question and answering (CQA) site, predicting when a question will be answered is of great importance. Furthermore, in an e-commerce service, analyzing the dynamics of service usage by the users will also help in finding potential churning users and providing them with more incentives to avoid the churn. Hence, it is important having behavior models that not only predict the type of user actions, but also model the time of user activities and their temporal dynamics. The availability of such data over time enable us to learn the key dynamic characteristics of users such as their interests, their loyalty to the provided services, and their satisfaction over time.\nThere exists a rich literature on modeling user activity that only considers the type of activities but does not pay attention to their timing. Indeed, these models have only concentrated on what is done on the social media, and do not consider when it is done [2]. However, a large and growing interest has been emerged on modeling user behavior over time. Most of these methods do not model the time of user actions and only consider time as a covariate and hence are unable to predict the time of users future actions [5,54]. Moreover, most of the existing temporal user modeling methods approach the problem in a discrete time manner. These models\nsuffer from two main drawbacks. First, they assume the process of generating data proceeds by unit time-steps, and hence are unable to capture the heterogeneity of the time to predict the timing of the next event. Second, these models need to choose the length of time-steps to discretize the time, which is a challenging task. Actually, the precise time interval or the exact distance between two actions carries a great deal of information about the dynamics of the underlying systems and hence the emerging continuous-time models that consider the exact timing of events are more applicable to real world scenarios [53,58,56,51,33,22,23,31].\nDifferent factors affect the user participation in a social computing service over time, and considering them in a continuous time user behavior model will results in more realistic models. These factors include:\n\u2022 Peer Influence: The user engagement may be affected by other users activities in the social media, known as peer influence. For example, in social networks such as Twitter and Foursquare, the user engagement in the service heavily depends on his friends activities. \u2022 Content: One of the main factors that affect user participation in online ser-\nvices, is the content being shared over these media. As much as the content is related to the user interests, the user will be more engaged. For example, in knowledge sharing services such as Stack Overflow, the amount of user engagement depends on the content being generated over this media. \u2022 Incentives: To engage users in more contributions and steer user behaviors,\nmany social computing services incorporate some techniques known as Gamification. Gamification is defined as using game elements in non-game systems to increase user engagement [20]. One of the most widely used gamification elements are Badges. Badges are some medals which are awarded to users based on some predefined levels of engagement. Recently, many social media sites are using badges to encourage users for more contributions. For example, Stack Overflow, which is a well-known questions answering service, uses badges to encourage users for more contributions. Foursquare, which is a location-based social network awards badges for user check-ins. Tripadvisor awards badges for writing reviews about different places. Recent studies have shown that these gamification elements act as incentive mechanisms and have a significant effect on user participation behavior over social media websites [6].\nContinues-Time modeling of user activities over social media has gained considerable attention in recent years. Some preliminary works tried to model the user behavior and predict the future user actions using the time of users\u2019 actions and the impact of activity of friends on each other [53,58].More recently, some works tried to jointly model the content and time of actions [33,22,23]. The main drawback of the aforementioned methods is that they only consider the impact of friends actions on user activity and ignore other factors such as gamification elements, while considering the ways in which the gamification elements impact user activities and participation in the site, is very important in user modeling.\nIn this paper, we propose novel multi-dimensional temporal point processes to jointly model the time and content of user actions by considering gamification elements, specially badges. We customize the method for modeling user actions over CQA sites. To this end, we propose intertwined point processes to jointly model two main type of user actions over these sites: Asking questions, Answering to the questions. Considering all the aforementioned factors in user model, the\nproposed method is able to infer user interests and predict the time and content of future actions. In summary, the major contributions of the proposed method are as follows:\n\u2022 We propose a continuous-time user behavior model, that models the user activities in presence of gamification elements, especially badges. The method Learns the impact of badges on each user which allows us to differentiate between users. \u2022 We customized the method for modeling the time and content of user activities\nover CQA sites. We consider two main activities over these sites: asking questions, and answering questions. To do that, we define two interdependent point processes for each user. One for asking questions, and the other for answering the questions. \u2022 We consider the temporal dynamics of user actions in the proposed model. In\nour model, the time of current user actions depends on the content of previous actions and also the content of current user actions depends on the time of user actions. \u2022 We model the dependency of the processes for asking and answering questions,\nusing interdependent processes. Using this novel framework, beside modeling the dependency between content and time, we also model the dependency between the two different multi-dimensional processes for asking and answering questions. \u2022 We propose an inference algorithm based on variational expectation maximiza-\ntion. The proposed inference algorithm, efficiently learns the parameters of the model.\nWe evaluate the proposed method over synthetic and real datasets. The real dataset is gathered from Stack Overflow which is a popular question answering website. The results show the efficiency of proposed method in both estimating the time and content of user actions.\nThe remainder of this paper is organized as follows. In section 2 we briefly review the relevant related works in continuous-time modeling of user activities and impact of gamification on user behavior. Details of the proposed method is discussed in section 3. To demonstrate the effectiveness of the proposed model, extensive experimental results are reported and analyzed in section 4. Finally, section 5 concludes this paper and discusses the paths for future research."}, {"heading": "2 Continuous-Time User Modeling", "text": "The abundant available data over social media creates new opportunities for learning models of user behavior. These models can be used to predict future activity, and identify temporal information. There exists a rich literature that use user models over social media ranging from recommender systems [4,39], to diffusion network analysis [49,58], and content analysis [3] [2]. Most of the primary works on user modeling have not paid attention to the time of activities. Some have focussed on describing aggregate behavior of many people [38,34,14] while others have focussed on individual behavior models [52,32]. In this direction, the works have mainly concentrated on the impact of social network [44] and topics of interests on user activities [3,52,17]. However, a large and growing literature have\nbeen emerged on modeling user behavior over time. Most of these methods do not model the time of user actions and only consider time as a covariate, and hence are unable to predict the time of users future actions [5,54]. Moreover, most of existing temporal user modeling methods approach the problem in a discrete time manner, and the classic varying-order Markov models [9,46] have been used by most of those methods [41,47,27]. These models suffer from two main drawbacks. First, they assume the process of generating data proceeds by unit time-steps, and hence are unable to capture the heterogeneity of the time to predict the timing of the next events. Second, these models need to choose the length of time-steps to discretize the time which is a challenging task. Furthermore, in the varying-order Markov models when the number of states is large, due to the exponential growth of the state-space, they can not capture the long dependency on the history of events.\nActually, the precise time interval or the exact distance between two actions carries significant information about the dynamics of the underlying systems, and hence it is of great importance to have continuous-time models that consider the exact timing of events. Temporal point processes are a general mathematical framework for modeling continuous-time events [37,48]. Recently, they have attracted considerable attention for modeling user activity over social media. Several models have been proposed in the literature that use temporal point processes to model the information diffusion over networks [53,58]. The first studies considered the impact of peer influence on user diffusion behavior and used a special point process, called Hawkes [58,53,49,24], to model the user activities. In this direction, other extensions were considered, that removed the independence assumption between different cascades [56,51]. Some other works tried to consider the content in the diffusion behavior [33,22,23,31]. More recently, there have been some studies that tried to use temporal point processes in other domains. The authors in [25, 28] incorporated temporal point processes in recommender systems. Linderman et al. [40] used point processes to infer latent network structure in financial economic interactions and reciprocity in gang violence. Farajtabar et. al. [26] tried to use temporal point processes to jointly model the network evolution and diffusion together, and Zarezade et. al.[55] tried to model user check-in behavior in location based social networks using temporal point processes. Our proposed model is different from the previous literature in different aspects; First, the continuous-time models in the literature mainly consider the impact of social network on the user participation and less attention is paid to the content, and more importantly, no attention is paid to the gamification elements and their impact on user participation. We extend the previous works by considering the impact of gamification elements on user participation. Second, the previous works mainly concentrate on modeling information diffusion and pay little attention to other applications. We extended the application of temporal point processes to modeling user activity over CQA sites which is substantially different from information diffusion.\nSince we consider the impact of gamification elements on user actions in the proposed model, in the remainder of this section we briefly review the works on user modeling that is related to gamification. The study of gamification and impact of gamification elements on user participation in online media has gained a considerable attention in recent years [21]. Most of the works done in this domain are empirical studies of user participation in social computing systems. Antin and Churchill [8] discuss the various functions and motivations of badges in terms of\ntheir psychological incentives. Halavais et al. [29] study the impact of social influence on individual badge earnings on Stack Overflow, and conclude that the influence of friends on badge selection is weak but has some effect. Zhang et al. [57] study an existing badge system in Foursquare and unlike Halavais, they found that users who are friends are more likely to obtain common badges. The authors in [35] analyze how much gamification techniques influence the member response tendencies. The authors in [50] study the impact of reputation on user activities and clustered users based on the reputation trends. Analyses of Stack Exchange reputation schema and its influence on user behavior has been performed by Bosu et al. [13] and Movshovitz-Attias et al. [43]. The authors in [15], study the impact of a hierarchical badge system on user participation and engagement at Stack Overflow. Their initial results present strong empirical evidence that confirms the value of the badges and their effectiveness on stimulating voluntary participation.\nBesides the aforementioned works on empirical analysis of user traces of activities, some works have tried to actively study the impact of gamification on real systems. Anderson et al. [7] studied a large-scale deployment of badges as incentives for engagement in a massive open online course (MOOC) system. They found that making badges more salient, increases the forum engagement. Hamari [30] actively studied the impact of gamification elements (badges) on an international peer-to-peer trading service. His results show that users in the gamified condition were significantly more likely to use the service in a more active way. While there are many studies about empirical analysis of impact of gamification on user participation, there are little works on modeling user activities in presence of badges. The main work in this domain is the seminal work of Anderson et al. [6]. They analyzed the impact of badges on user behavior on Stack Overflow. They observed that as users approach the badges boundaries they steer their efforts towards achieving the badges. Using these observations they proposed a theoretical discrete-time user behavior model and evaluated it through different experiments. Marder [42] also proposed a discrete-time model of user actions and performed a regression analysis of user activities over Stack Overflow which conforms with previous empirical observations. In summary, many works have been done on empirical analysis of gamification impact on user behaviors, and little attention is paid to modeling user behavior in presence of gamification elements. Moreover, the existing user activities models, approach the problem in a discrete-time manner and do not pay any attention to the content. Our work is the first to offer a continuous-time user model which considers the impact of gamification elements on user activities, besides the content and social influence factors."}, {"heading": "3 Proposed Method", "text": "In this section, we introduce the proposed method for continuous-time user modeling in presence of badges. Our model considers all the aforementioned factors in user modeling with more emphasis on badges. The CQA websites, which have gained a considerable attention during recent years, incorporate different elements to increase user engagement. For example, Stack Overflow which is the most popular CQA website on programming questions, uses badges in an effective manner to increase user participation. Moreover, user engagement over this site depends on other users participation and the content being shared. These facts makes CQA\nwebsites a good candidate for continuous-time user modeling in presence of badges. Hence, we customize our model for user actions over Stack Overflow.\nAsking questions and answering to others questions are the two main type of user actions over CQA sites that guarantees the survival of these sites. Therefore, it is of great importance that the proposed method be able to model and predict users\u2019 actions in these two areas. In this section, we propose two interdependent multi-dimensional temporal point processes to model the asking questions and answering behaviors over a CQA site in presence of badges. In order to model the dependency of these two types of activities, we interrelate the processes to each other. In order to model the impact of badges in user participation, we develop a rich set of flexible temporal kernels that accumulate the impact of badges on the intensity function of user activity over time. Moreover, we consider the temporal dynamics in the content of user actions. Finally, we propose an efficient inference algorithm to infer the parameters of the proposed model.\nSince our model is based on stochastic temporal point processes, to make the presentation self-sufficient, some theoretical background on these processes is provided in Section 3.1. The proposed generative model is described in Section 3.2, followed by the details of the inference algorithm in Section 3.3.\n3.1 Background\nA temporal point process is a powerful mathematical tool for modeling random events over time. More formally, a temporal point process is a stochastic process whose realizations consists of a list of time-stamped events {t1, t2, . . . , tn} with ti \u2208 R+. Different types of activities over a CQA site, such as asking a question, and answering the questions can be considered as events generated by a point process.\nThe length of the time interval between successive events is referred to as the inter-event duration. A temporal point process can be completely specified by distribution of its inter-event durations [18]. Let Ht denote the history of events up to time t, then by applying the chain rule we have:\nf(t1, . . . , tn) = n\u220f i=1 f(ti|t1, . . . , ti\u22121) = n\u220f i=1 f(ti|Hti) (1)\nTherefore, to specify a point process, it suffices to define f\u2217(t) = f(t|Ht), which is the conditional density function of an event occurring at time t given the history of events.\nA temporal point process can also be defined in terms of counting process N(t) which denotes the number of events up to time t. The increment of the process, dN(t), in an infinitesimal window [t, t + dt), is parametrized by the conditional intensity function \u03bb\u2217(t). The function \u03bb\u2217(t) is formally defined as the expected rate of events occurring at time t given the history of events, that is: \u03bb\u2217(t)dt = E[dN(t)|Ht] (2) There is a bijection between the conditional intensity function (intensity for short) and the conditional density function:\n\u03bb\u2217(t) = f\u2217(t)\n1\u2212 F \u2217(t) (3)\nwhere F \u2217(t) is the Cumulative Distribution Function (CDF) of f\u2217(t). Using the definition of \u03bb\u2217(t) in eq.3, the likelihood of a list of events (t1, . . . , tn) which is observed during a time window [0, T ), can be defined as:\nL = n\u220f i=1 \u03bb\u2217(ti) exp ( \u2212 \u222b T 0 \u03bb\u2217(s)ds ) (4)\nwhere n is the number of observed events and T is the duration of observation. Intuitively, \u03bb\u2217(t) is the probability of an event occurring in time interval [t, t+ dt) given the history of events up to t, and it is a more intuitive way to characterize a temporal point process [1]. For example, a temporal Poisson process can be characterized as a special case of a temporal point process with a history-independent intensity function which is constant over time, i.e. \u03bb\u2217(t) = \u03bb [37]. Users\u2019 actions usually exhibit complex longitudinal dependencies such as self-excitation, where a user tends to repeat what he has done recently. Such behavioral patterns can not be characterized by using homogeneous a Poisson process, and hence more advanced temporal point processes are needed. Hawkes process is a temporal point process with a particular intensity function which is able to capture the self-excitation property. The intensity function of a Hawkes process is given by:\n\u03bb\u2217(t) = \u00b5+ \u03b1g\u03c9(t) ? dN(t) = \u00b5+ \u03b1 \u2211 ti<t g\u03c9(t\u2212 ti) (5)\nwhere \u00b5 is a constant base intensity, \u03b1 is a weighting parameter which controls the impact of previous events on the current intensity, and g\u03c9(t) is a kernel which defines the temporal impact of events on the future intensity. In the case that g\u03c9(t) is a decreasing function, Hawkes process produces clustered point patterns over time and hence is able to model the self-excitation property of users events. The right hand side of eq.5 comes from the fact that the number of events occurred in a small window [t, t+ dt) is dN(t) = \u2211 ti\u2208Ht \u03b4(t\u2212 ti), where \u03b4(t) is a Dirac delta function. In many situations, we need to model the events generated by a set of dependent sources. Multi-dimensional point processes are a set of powerful tools for modeling such events. In a multi-dimensional point process, the intensity of a dimension depends on the event history of all dimensions. For example, as it was mentioned before, the users\u2019 actions over social media depends on each other and hence can\u2019t be modeled independently. In order to model these action, we can use a multidimentional temporal point process in which each user corresponds to a dimension and the events of each user impacts the intensity function of other users. For example, the intensity of a multi-dimensional Hawkes process is given by:\n\u03bbu(t) = \u00b5u + \u2211 v\u2208U \u03b1vug\u03c9(t) ? dNv(t) (6)\nwhere \u03bbu shows the intensity of user u to do an action, and \u00b5u is the base intensity of user u, and \u03b1vu shows the influence of user v on user u. As it is evident in eq.6, the intensity of user u depends on history of all users through the second term. Hawkes process models the dependency among different dimensions through the convolution with a temporal kernel which is a linear operator. However, the event\nin different dimensions may exhibit more complicated dependencies and hence we need more complex methods for modeling such phenomena. For example, in order to model the effect of badges on user activities, we propose a nonlinear multidimensional temporal point process in section 3.2.\nEach event can also be associated with some auxiliary information known as the mark of an event. For example, the tags of the questions in a CQA website can be considered as the marks of events. A marked temporal point process is a point process for modeling such events. If k denotes the mark of the events, then the intensity of the marked temporal point process is given by:\n\u03bb\u2217(t, k) = \u03bb\u2217(t)f\u2217(k|t) (7)\nwhere \u03bb\u2217(t) denotes the temporal intensity function, and f\u2217(k|t) is the conditional probability density function of observing an event with mark k at time t. Therefore, in order to determine a temporal point process, we need a temporal intensity which shows the rate of occurring event given the history and a conditional probability density function over marks. We propose a nonlinear multi-dimensional marked point process to model user activities in presence of badges, in the next section.\n3.2 Proposed Generative Model\nIn this section, we propose multi-dimensional marked point processes to model the user activities over a CQA website in the presence of badges. We consider two main type of activities over such websites, i.e. asking questions and answering them. In order to model such actions using temporal point processes, we consider each of these actions as marked events and propose two intertwine point processes to model these two set of dependent events. In the following, we first detail our notations and assumptions and then introduce the proposed generative model for user actions over CQA sites.\nLet Dq(t) = {eqi } Nq(t) i=1 and D a(t) = {eai } Na(t) i=1 denote the set of asking questions and answering events observed until time t, respectively. We denote the number of asking questions and answering events up to time t by Nq(t) and Na(t), respectively. The event eqi is a triple (ti, ui, zi) which indicates that at time ti, user ui asks a question with tag zi. The event e a i is also a triple (ti, ui, pi) which indicates that at time ti, user ui answers a question with id pi. In the following, we propose two dependent multi-dimensional marked temporal point process to model these two dependent set of marked events.\nWe can consider different intents behind user actions over a CQA site. User activities may be due to drivers external to the website which we call exogenous activities or the influences he receives from the media, such as others actions or website incentives like badges which we call endogenous activities. Paying attention to these drivers will result in more realistic user models. Hence, we assume that the user intensities for asking questions and answering questions are as follows:\n\u03bbqu(t) = \u00b5 q u\ufe38\ufe37\ufe37\ufe38\nExogenous Intensity\n+ \u03c1qu \u2211 b\u2208Bq\ngqw(hb(D q u(t)), \u03c4b)\ufe38 \ufe37\ufe37 \ufe38\nEndogenous Intensity\n(8)\n\u03bbau(t) = \u00b5 a u\ufe38\ufe37\ufe37\ufe38\nExogenous Intensity\n+ \u03c1au \u2211 b\u2208Ba gaw(hb(D a u(t)), \u03c4b) + \u2211 ei\u2208Dq. (t)\n\u03b7uzifw(t, ti)\ufe38 \ufe37\ufe37 \ufe38 Endogenous Intensity (9)\nWe consider the gamification elements (more specifically; badges) as the main drivers of endogenous activities. Badges are awarded to the users based on predefined levels of engagement. Recent analysis has shown that the badges increase user participation over CQA sites. It have also been noticed that the amount of increase depends on how much the user is close to the badge; i.e. the impact of badge on users participation increases as they are close to achieving it [27].\nThe selected kernels in user intensity should be able to reflect the two aforementioned facts. They should be also able to handle the heterogeneity in the criteria for wining badges. For example, some badges are awarded based on the mount of activities of a given type (we call it a badge b1), while others are awarded based on number of days the user performed a given type of activity (we call it b2). To do that, we define the parameter \u03c4b that captures the criteria for winning the badge b. For our examples, \u03c4b1 is the total amount of actions which is required to win a badge, while \u03c4b2 is the amount of active days required to win a badge. We also define per badge functions hb that extracts the required information from the history of user actions related to a specified badge. Again for our example badges, hb1(Du(t)) = Nu(t) , which is the count of total actions of user u until time t, while hb2(t) is the total number of active days of user u, until time t. Finally, the temporal kernels gqw(x, y) and g a w(x, y), represent the impact of badges on user intensity. To capture the two aforementioned facts, they should have the following features:\n\u2013 Non-negativity: To capture the positive impact of badges on user participation, the kernels should never become negative. Here, we consider only a positive impact for badges on user participation. The negative impact of missdesigned badges on user participation, can be a good direction for the future research. \u2013 Exponential Increase: To capture the observed feature of badges for which the impact of badge on users participation increases as they are close to achieving it, the kernels should be able to capture these phenomenon.\nDifferent kernels can be utilized that have the required features. Gaussian RBF and Exponential kernels are among the most popular choices. We used the Gaussian RBF kernel ggauss defined as:\nggauss\u03c9 (x, y) = e \u2212( y\u2212x 2\u03c9 )2 (10)\nAnd, exponential kernel gexp as:\ngexp\u03c9 (x, y) = e \u2212\u03c9(y\u2212x) I[y \u2265 x] (11)\nFig. 1 shows the two selected kernels and their features. The second term in user intensities (eqs. 9, 8), reflects the cumulative impact of badges on users activities. To capture the heterogeneity of users, motivated by badges, we have also incorporated personal parameters \u03c1au and \u03c1 q u. As mentioned before, asking questions and answering questions activities, are interwoven. Since, in a CQA site the\nasking question activity is mainly derived by exogenous factors, we did not consider any impact from the previous answering activities. However, we considered a positive impact of questioning activities on answering behaviors. This impact is captured through the third part of the user intensity for answering questions in eq. 9. It captures the impact of other users previous questions on the user answering intensity.\nAnother important factor which impacts the user activities is the content. The users usually have interest in some fields and also have some expertise in other fields. Therefore, they will ask questions and answer to questions in some limited number of fields. Hence, we considered the temporal effect of content on the intensity of users for answering questions. We modeled the content of user activities as the mark of events in the proposed temporal point processes. The mark for a question is the tag associated to it, and for an answer is the question it belongs to. The proposed mark probabilities for questions and answers are as follows:\nP(zi = k|ti, ui) = \u03b1uik\u2211K s=1 \u03b1uis\n(12)\nP(pj = i|tj , uj) = \u03b7ujzif a \u03c9(ti, tj)\u2211\ner\u2208Dq. (tj) \u03b7ujzrf a \u03c9(tr, tj)\n(13)\nLet \u03b1u be a vector of user interest over tags, and let K be the total number of tags, then \u03b1u is a K dimensional vector, where \u03b1uk represents the interest of user u in asking questions of domain k. Also, the parameter \u03b7u is a K dimensional vector showing the expertise of u in different domains. Another important factor which has a great impact on the content of user actions is time. We also consider the negative impact of time on user answering, to capture the fact that users have less interest to answer older questions. The exponentially decaying function faw(ti, tj) captures the negative effect of time, and for simplicity we consider the widely usaed exponential function faw(ti, tj) = e\n\u2212w(tj\u2212ti). In summary, the proposed process can capture the following desirable proper-\nties:\n\u2013 Capturing heterogeneous impact of badges: The proposed intensity functions for both asking questions and answering questions, captures heterogeneous impact of badges on user participation through the functions hb(.), and the decaying kernels gqw(.) and g a w(.).\nAlgorithm 1 Variational Expectation Maximization UMUB\n1: for each user u \u2208 U do 2: initialize \u03c1au, \u03c1 q u, \u00b5 a u, \u00b5 q u, \u03b7u randomly 3: while \u2206 logL > \u03b4 do . check for model convergence 4: E Step: 5: for each user u \u2208 U do 6: for each event eqi \u2208 D q u do 7: update \u03c6qi using Eq. 28 8: for each event eai \u2208 Dau do 9: update \u03c6ai using Eq. 29\n10: update \u03b6ai using Eq. 30 11: M Step: 12: for each user u \u2208 U do 13: update \u00b5qu using Eq. 31 14: update \u00b5au using Eq. 33 15: update \u03c1qu using Eq. 32 16: update \u03c1au using Eq. 34 17: update \u03b1u using Eq. 35 18: update \u03b7u using Eq. 36\n\u2013 Interdependency and Mutual Excitation: The events of users have an impact on the others events. For example, The existence of more questions will results in more answers (the third part of user answering intensity in eq.9). \u2013 Impact of time on content and impact of content on time: The proposed model captures the impact of time on content through the proposed mark probability function in eq. 13. We also consider the impact of content on timing of user answers, utilizing the impact of user interests \u03b7uk on intensity function in third part of eq.9. \u2013 Temporal decays: Both, the impact of previous content on the time of events and the processes on each other exponentially decays as a function of time differefnce, through the decaying functions faw(.) in eqs.13, and 9. This means the model pays more attention to recent actions.\n3.3 Inference\nIn this section, we discuss the details and practical challenges of estimating the model parameters by using the users activity data, and present a variational expectation maximization algorithm as a scalable solution.\nGiven the users\u2019 activities in a time window [0, T ], and the data D = Dq \u222aDa, we would like to infer the model parameters \u0398 = {\u00b5qu, \u00b5au, \u03c1qu, \u03c1au, \u03b7u, \u03b1u}u\u2208U . Based on the proposed generative model, the log-likelihood of observed data log p(D|\u0398) is given by:\nlog p(D|\u0398) = \u2211 u\u2208U log p(Du|\u03b8u) (14)\nwhere \u03b8u is the parameter set for user u, i.e. {\u00b5qu, \u00b5au, \u03c1qu, \u03c1au, \u03b7u, \u03b1u}. Using the chain rule, we can further split the likelihood for each user as:\nlog p(Du|\u03b8u) = log p(Dqu|\u03b8u) + log p(Dau|Dqu, \u03b8u) (15)\nwhere, the first term is the log-likelihood of user u\u2019s asking question activities, and the second term is the log-likelihood of answering activities of user u. Using the theory of point processes, i.e. eq. 4 and eq. 7, we have:\nlog p(D|\u0398) = \u2211 ei\u2208Dq log(\u03bbqui(ti)) + \u2211 ei\u2208Dq log(fqui(zi|ti))\u2212 \u2211 u \u222b T 0 \u03bbqu(\u03c4)d\u03c4 (16)\n+ \u2211 ej\u2208Da log(\u03bbauj (tj)) + \u2211 ej\u2208Da log(fauj (pj |tj))\u2212 \u2211 u \u222b T 0 \u03bbau(\u03c4)d\u03c4\nWe would like to find the parameter set \u0398 that maximizes this log likelihood function. However, maximizing this log likelihood function turns out to be a complex problem. The difficulty arises from the summation over different components of the intensity functions that appears inside the logarithm in eq. 16:\nlog(\u03bbqui(ti)) = log ( \u00b5qui + \u03c1 q ui \u2211 b\u2208Bq gqw(hb(D q ui(ti)), \u03c4b) ) (17)\nlog(\u03bbauj (tj)) = log \u00b5auj + \u03c1au \u2211 b\u2208Ba gaw(hb(D a uj (tj)), \u03c4b) + \u2211 ei\u2208Dq. (t) \u03b7uzif a w(tj , ti)  Therefore, if we set the derivatives of the log likelihood to zero, we would not obtain a closed form solution. In order to resolve this issue, we first give an alternative formulation of the model in which we add an additional layer of latent variables. These auxiliary variables facilitate the inference algorithm without changing the model [28]. As we mentioned in section 3.2, there are different factors that trigger the users\u2019 actions. Hence, for each activity ei of user u, we introduce a latent variable si which denotes the latent factor that trigger the action ei. For questions in Dq, si is a binary random variable which denotes if the badges are the driving factor of action ei or the driving factor is exogenous:\n\u03bbqu(ti, si) =\n{ \u00b5qu si = 1\n\u03c1qu \u2211 b\u2208Bq g q w(hb(D q u(ti)), \u03c4b) si = 0\n(18)\nFor each answering activity ej in D a, let sj \u2208 {\u22121, 0} \u222a {1, 2, . . . , |Dq(tj)|} be the latent factor, where sj = 0 indicates that the badge incentives drove the user to answer the questions, sj = r > 0 indicates that the correspondence between the topic of question r with user u\u2019s expertise triggered him to answer the question, and sj = \u22121 shows that an external factor triggered the answer event. By using the latent variable sj , the conditional intensity of user u for answering questions can be written as:\n\u03bbau(tj , sj) =  \u00b5au sj = \u22121 \u03c1au \u2211 b\u2208Ba g a w(ha(D a u(tj)), \u03c4b) sj = 0\n\u03b7uzsj f a w(tj \u2212 tsj ) sj \u2208 {1, 2, . . . , |Dq(tj)|}\n(19)\nIt is known that the sum of Poisson processes is itself a Poisson process with rate equal to the sum of all individual rates. Thus, these new latent variables preserve\nthe marginal distribution of the observation. Combining eq. 18 and 19 with eq. 16, the log likelihood of observations D and auxiliary latent variables S is given by:\nlog p(D,S|\u0398) = \u2211 ei\u2208Dq log(\u03bbqui(ti, si)) + \u2211 ei\u2208Dq log(fqui(zi|ti))\u2212 \u2211 u \u222b T 0 \u03bbqu(\u03c4)d\u03c4\n(20) + \u2211 ej\u2208Da log(\u03bbauj (tj , sj)) + \u2211 ej\u2208Da log(fauj (pj |tj))\u2212 \u2211 u \u222b T 0 \u03bbau(\u03c4)d\u03c4\nwhich can be written as:\u2211 ei\u2208Dq log(\u03bbqui(ti, si)) = \u2211 u\u2208U Cqu1 log\u00b5 q u + C q u0 log \u03c1\nq u (21)\u2211\nej\u2208Da log(\u03bbauj (tj , sj)) = \u2211 u\u2208U Cau,\u22121 log\u00b5 a u + C a u0 log \u03c1 a u + \u2211 u\u2208U \u2211 z\u2208Z Cauz log \u03b7uz\nwhere Cqu1 and C a u,\u22121 denote the number of times that user u ask question or answer a question based on an external factor, respectively. Cqu0 and C a u0 also denote the weighted number of times that the user actions are triggered by the badge incentives. Cauz also denotes the weighted number of times that user u\u2019s answers triggered by questions in topic z:\nCqu1 = \u2211 ei\u2208Dqu I[si = 1] (22)\nCqu0 = \u2211 ei\u2208Dqu I[si = 0]\u00d7 \u03c1qu \u2211 b\u2208Bq gqw(hb(D q u(ti)), \u03c4b)\nCau,\u22121 = \u2211 ej\u2208Dau I[sj = \u22121]\nCau0 = \u2211 ej\u2208Dau I[sj = 0]\u00d7 \u03c1au \u2211 b\u2208Ba gaw(hb(D a u(tj)), \u03c4b)\nCauz = \u2211 ej\u2208Dau \u2211 ei\u2208Dqu(tj) I[zi = z]I[sj = i]\u00d7 \u03b7uzfaw(tj \u2212 ti)\nAs it is mentioned before, the direct optimization of log p(D|\u0398) is difficult, but the optimization of complete-data log-likelihood log p(D,S|\u0398) is significantly easier. For any distribution q(S) over the auxiliary latent variables, the following decomposition holds [10]:\nlog p(D|\u0398) = L(q(S), \u0398) + KL (q(S)||p(S|D, \u0398)) (23)\nwhere the functions L(q(S), \u0398) and KL (q(S)||p(S|D)) are defined as follows: L(q(S), \u03b8) = Eq [ p(D,S|\u0398) q(S) ] (24)\nKL (q(S)||p(S|D, \u0398)) = \u2212Eq [ p(S|D, \u0398) q(S) ] (25)\nKL (q(S)||p(S|D, \u0398)) is the Kullback-Leibler divergence between q(S) and the posterior distribution p(S|D, \u0398), and satisfies KL \u2265 0 with equality, if and only if, q(S) = p(S|D, \u0398). Therefore, L(q, \u03b8) is a lower bound on the log-likelihood function. In order to find the value of \u0398 that maximizes the log-likelihood function, we use the Variational Expectation Maximization (Variational-EM) algorithm. Variational-EM is an iterative optimization algorithm which has two main steps in each iteration. In the E-step, the lower bound L(q(S), \u0398) is maximized with respect to q(S) while holding \u0398 fixed. In the subsequent M-step, the distribution q(S) is held fixed, and the lower bound L(q(S), \u0398) is maximized with respect to \u0398. In the E-step, we should find the posterior of the latent variables S in order to maximize the L(q(S), \u0398). However, since finding the joint posterior of all latent variables is not computationally tractable, we use the mean-filed approximation assumption over q:\nq(S) = \u220f\nei\u2208Dq q(si|\u03c6qi ) \u220f ej\u2208Da q(sj |\u03c6aj ) (26)\nIn other words, we find the best factorized q(S) distribution that is most similar to the posterior p(S|D, \u0398) in the KL-divergence sense. In the M-Step, we optimize the L(q(S), \u0398) with respect to \u03b8.\nAlthough introducing the auxiliary latent variables simplify the inference algorithm, we have another challenge in inferring the answer parameters. While computing the log faui(pi|ti), the log {\u2211\ner\u2208Dq. (tj) \u03b7uzrf\na w(tj \u2212 tr) } that exists in\nthe denominator of faui(pi|ti) makes the inference of user expertise challenging. Using the approach used in [11,12], we define a new variational parameters \u03b6j for each answer event:\nlog  \u2211 er\u2208Dq. (tj) \u03b7uzrf a w(tj \u2212 tr)  \u2264 \u03b6j  \u2211 er\u2208Dq. (tj) \u03b7uzrf a w(tj \u2212 tr) \u2212 1\u2212 log(\u03b6j) (27)\nIn summary, we should tighten the lower bound L(q(S), \u0398) with respect to q(S) and \u03b6 in the E-step, and maximize it with respect to \u0398 in the M-Step."}, {"heading": "3.3.1 E-Step:", "text": "Substituting eqs. 27, 22 and 21 in eq. 22, and considering a multinomial distribution for each q(si) with parameter \u03c6i, given the current state of all parameters, we find q(si) that maximizes the lower bound in the E-step, which is equivalent to updating the \u03c6i parameters. Using some straightforward calculations, the update equations for the question latent variables, is given by:\n\u03c6qik = q(si = k) =  \u03c1qu \u2211 b\u2208Bq g q w(hb(D q u(ti)),\u03c4b) \u00b5qu+\u03c1 q u \u2211 b\u2208Bq g q w(hb(D q u(ti)),\u03c4b) k = 0 \u00b5qu\n\u00b5qu+\u03c1 q u \u2211 b\u2208Bq g q w(hb(D q u(ti)),\u03c4b) k = 1 (28)\nand, the update equations for the answer latent variables is given by:\n\u03c6ajk = q(sj = k) (29)\n=  \u00b5au \u00b5au+\u03c1 a u \u2211 b\u2208Bq g a w(hb(D a u(ti)),\u03c4b)+ \u2211 ei\u2208Dq. (tj ) \u03b7uzif a w(tj\u2212ti) k = \u22121 \u03c1au \u2211 b\u2208Bq g a w(hb(D a u(ti)),\u03c4b) \u00b5au+\u03c1 a u \u2211 b\u2208Bq g a w(hb(D a u(ti)),\u03c4b)+ \u2211 ei\u2208Dq. (tj ) \u03b7uzif a w(tj\u2212ti) k = 0 \u03b7uzkf a w(tj\u2212tk)\n\u00b5au+\u03c1 a u \u2211 b\u2208Bq g a w(hb(D a u(ti)),\u03c4b)+ \u2211 ei\u2208Dq. (tj ) \u03b7uzif a w(tj\u2212ti) k \u2208 {1, 2, . . . , |Dq(tj)|}\nfinally, the update equations for variational parameters \u03b6j is given by:\n\u03b6j = 1\u2211\ner\u2208Dq. (tj) \u03b7uzrf\na w(tj \u2212 tr)\n(30)"}, {"heading": "3.3.2 M-Step:", "text": "In the subsequent M-step, the distribution q(S) is held fixed and the lower bound L(q(S), \u0398) is maximized with respect to \u0398, where \u0398 = {\u00b5qu, \u00b5au, \u03c1qu, \u03c1au, \u03b7u, \u03b1u}u\u2208U . To find the point estimations for different parameters, we should maximize the lower bound with respect to different parameters. Maximizing the lower bound with respect to \u00b5qu and \u03c1 q u will result in the following closed form solutions:\n\u00b5\u0302qu =\n\u2211 ei\u2208Dqu \u03c6 q i0\nT (31)\n\u03c1\u0302qu =\n\u2211 ei\u2208Dqu \u03c6 q i1\u2211\nb\u2208Bq G q(u, b, T )\n(32)\nwhere Gq(u, b, T ) = \u222b T 0 gqw(hb(D q u(s)), \u03c4b)ds, and maximizing the lower bound with respect to \u00b5au and \u03c1 a u will result in:\n\u00b5\u0302au =\n\u2211 ej\u2208Dau \u03c6aj,\u22121\nT (33)\n\u03c1\u0302au =\n\u2211 ej\u2208Dau\n\u03c6aj,0\u2211 b\u2208Ba G a(u, b, T ) (34)\nMaximizing the lower bound with respect to \u03b1u will result in the following simple closed form solution:\n\u03b1\u0302uk =\n\u2211 ei\u2208Dqu I[zi = k]\n|Dqu| (35)\nFinally, to find \u03b7u we should maximize the lower bound with respect to \u03b7u. Unfortunately, there is no closed form solution for \u03b7u, and we should solve the following optimization to estimate the vector \u03b7u:\n\u03b7\u0302u = arg max \u03b7u\nlog \u03b7Tu Fu \u2212 \u03b7TuHu\ns.t. K\u2211 k=1 \u03b7uk = 1 (36)\nwhere, Fu and Hu are K dimensional vectors defined over different tags, and for each tag k we have:\nFu(k) = \u2211 ej\u2208Dau I(zpj = k) + \u2211 ei\u2208Dq. (tj),zi=k \u03c6aji  (37) Hu(k) =\n\u2211 ei\u2208Dq. ,zi=k 1 \u03b2 [ 1\u2212 e\u2212\u03b2(T\u2212ti) ] (38)\n+ \u2211 ej\u2208Dau \u03b6j  \u2211 er\u2208Dq. (tj),zr=k faw(tj \u2212 tr)  (39) Since, eq. 36 is convex in \u03b7u, we can find the optimal solution by using different convex optimization tools such as CVX. The overall steps of inference algorithm is depicted in algorithm 1.\n4 Experiments\n4.1 Dataset Description\nIn this section, we evaluate the proposed inference algorithm, and the effectiveness of the proposed method by performing several experiments on synthetic and real datasets. To validate the proposed inference algorithm, we generate a set of events by using the proposed method, and validate the estimated parameters by using different criteria. Moreover, to evaluate the performance of our model, we use a real dataset which has been collected by crawling the Stack Overflow. The datasets are explained in more details in the following paragraphs.\n1 A question is well-received if it is open and has a score greater than 0. http://meta. stackexchange.com/questions/234259/asking-days-badges\ntype of activities, we considered 80% of their actions as train data, and the remaining 20% as the test data.\n4.2 Synthetic Results\nWe evaluated the performance of proposed inference algorithm by using the synthetic data. Indeed we are seeking to answer the following questions; 1) What is the predictive performance of proposed algorithm?, and, 2) Can the proposed inference algorithm accurately infer the model parameters?"}, {"heading": "4.2.1 What is the predictive performance of proposed algorithm?", "text": "To evaluate the predictive performance of proposed method, we plotted the Average log-likelihood per event for the test data vs different train data sizes. Fig. 3a shows the results. We should note that the results are averaged over different kernel types and different users. As it can be seen, with the increase of training events, the performance of proposed method in predicting the future events increases. To evaluate the correctness of the variational EM algorithm, we also plotted average log-likelihood per event after the E-step vs the iteration number in Fig. 3b. In the variational EM, log-likelihood after the E-step should never decreases [10], and our results conform with this expectation. It was also noticed that only after 4 steps the log-likelihood converged which is an indicator of fast convergence of the proposed inference algorithm."}, {"heading": "4.2.2 Can the proposed inference algorithm accurately infer the model parameters?", "text": "To evaluate whether the proposed inference algorithm is able to accurately estimate the model parameters, we plotted the average MRE and Rank for the tem-\nporal and content parameters. The MRE metric, measures the relative error between the true and estimated parameters. i.e. 1n \u2211n i=1 |\u03b8i\u2212\u03b8\u0302i| \u03b8i\n. We also evaluated how much the order of parameter values is preserved. To this end, we used the Kendall rank coefficient [36]. We averaged the metrics over all temporal parameters \u0398t = {\u00b5qu, \u00b5au, \u03c1qu, \u03c1au} |U| u=1 and content parameters {\u03b1u, \u03b7u} |U| u=1. The average results over temporal and content parameters are depicted in Fig. 4. We should note that the results are averaged over event sets of different kernel types and different users. The first row (Fig. 4a, 4b) shows the average recovering error of temporal parameters for different train sizes, and the second row, (Fig. 4c, 4d) shows the average errors for content parameters. The results show that the performance of the proposed method in both metrics for both temporal and content parameters improves as the amount of train data increases. The MRE decreases as the number of train data increases, and the Rank Correlation increases as the number of train data increases. These results confirms the superior performance of the proposed method.\n4.3 Real Data Results\nWe also evaluated the performance of proposed method on real data gathered from Stack Overflow. We used the following criteria to evaluate the predictive performance of methods for time and mark predictions.\n\u2013 Average Test Log-Likelihood: We calculated the average temporal log likelihood for test events of each user, and reported the average results over all users. The higher log likelihood means better performance. \u2013 Time Prediction: For each user we predicted when the test events will occur using the density of next event times (f(t) = \u03bb(t) exp\u2212 \u222b T 0 \u03bb(s)ds). To achieve\nthis, we computed the expected time of next event by sampling the future events. We reported the Mean Absolute Error (MAE) and Mean Relative Error (MRE) between the predicted time and the true time. \u2013 Mark Prediction: We also evaluated the predictive performance of the proposed method for predicting the marks of events. As we mentioned before, the mark of a question is its tag, and the mark of an answer is the question it belongs to. For each test event, given the time of event, we evaluated the probability of its mark (tag/parent). We rank all the tags/parents in the descending order of their probability, and create a recommendation list. We reported average Precision@k and NDCG@k [16] for different test events over all users. Precision@k is the percent of predictions that the true value is among the top k predicted ones.\nWe also used two types of baselines for temporal and content evaluations. For temporal evaluations, measuring the effect of badges would help to obgtain predictions. We used the following baselines.\n\u2013 Hawkes Process: To see whether there is a self-excitation among the events. We fitted a simple Hawkes process for the events of each user with intensity\n\u03bb q/a u (t) = \u00b5 a/q u + \u03b2 a/q u \u2211 ei\u2208D a/q u\n\u03ba(t, ti), where \u03ba(t, ti) = exp(\u2212(t\u2212 ti)). \u2013 Homogeneous Poisson Process: We also fitted a Poisson Process with\na constant intensity function for each user and type (question & answer). \u03bb a/q u (t) = \u03bb a/q u .\nFor mark evaluations, we used the following baselines.\n\u2013 Most Popular: At each time step, regardless of the time we predicted the most popular marker. Usually, predicting the most popular is a strong heuristic [25]. Using this prediction, we can evaluate the impact of utilizing customization and time in our model. \u2013 Most Recent: At each time step, we predict the most recent markers. Using this prediction, we can evaluate impact of utilizing the customization and preferences in our model."}, {"heading": "4.3.1 Temporal Results:", "text": "In Fig. 5, we have plotted the performance of different methods in predicting the time of next events for both question and answer events. For the log-likelihood metric, (Figs. 5d,5a), the proposed method outperforms the Hawkes and Poisson precesses. As it can be seen, the performance of proposed method degrades from\nanswers to questions, because asking more questions is a hard task, and the impact of badges on asking more questions is less than their impact on answering. Therefore, the performance of proposed method degrades from answering to asking questions. For the other two metrics, the proposed method also outperforms the competitors. Only for the MRE metric, the results of Hawkes are better. This is because the Hawkes method predicted times are usually smaller than the true times, which result in smaller MREs. It is interesting to note that the results of Hawkes and Poisson processes are similar for asking questions. This is because asking questions is usually driven by external factors rather than the history of events. Therefore, their performances will be closer for asking questions. According to the time-change theorem [19], given all ti and ti+1 subsequent event times of a particular point process, the set of intensity integrals \u222b ti+1 ti\n\u03bb(t)dt should conform to the unit-rate exponential distribution, if the samples are truly sampled from the process \u03bb(t). Hence, we compare the theoretical quantiles from the exponential\ndistribution with the ones from different models to the real sequence of events. The closer the slope is to one, the better a model matches the event patterns. Figs. 5g, 5h show the results for different models for answers and questions, respectively. The results show that our UMUB model can better explain the observed data compared to the other models."}, {"heading": "4.3.2 Mark Prediction Results", "text": "We plotted the results of different methods in predicting the mark of test events in Fig. 6. Fig. 6a and Fig. 6c, show the precision@k and NDCG@k for different methods in predicting the parent of answers versus different k. In the same way, Fig. 6b and 6d show the precision@k and NDCG@k for different methods in predicting the tag of questions versus k. As it can be seen, by increasing k, the performance of all methods improves. The proposed method outperforms the competitors in predicting both the parents and tags. For predicting the tag of questions, the most recent method performs close to the proposed method (Figs. 6b, 6d). This is because the asking questions is a sequential task, and usually a user asks questions in a domain, sequencially. In addition, by the fact that users usually ask questions in a limited number of topics ( Fig. 2b), the recency is a strong predictor for the\ntags of questions. The high difference between the proposed method and the competitors for predicting the parent of answers (Figs. 6a, 6c) is because, although the popularity and recency heuristics are strong predictors, but for predicting the questions that the user will answer they can not work well. This is due to the huge amount of questions that arrive in every moment and the user must select one of them. Therefore, paying attention only to time or popularity will result in poor performance. The proposed method, considers both the personal preferences and the temporal impacts in predictions, and hence it can better predict the question that user will answer."}, {"heading": "4.3.3 Impact of Kernels and Intertwining the Processes", "text": "We also studied the impact of different configurations on the performance of the proposed method. First, we studied the impact of different kernels on the performance. Fig. 7a shows the impact of Gaussian and Exponential kernels, which previously we depicted in Fig. 1, on the Log-likelihood of test events. The results shows that the Gaussian kernel works better than exponential for both type of actions. This means that for both questioning and answering actions, the impact of badges on user actions do not drop suddenly after obtaining the badge. In addition, the badges have an impact on user activities even after obtaining them.\nWe also studied the impact of intertwining the processes on the performance of the proposed method. We compared the two versions of proposed method with considering the impact of questions on answers and without considering the effect. Fig. 7b shows the performance of the two versions based on the Log-Likelihood of test events. As it can be seen, the intertwined version performs better than the version without the impact of questions. This, shows that the questioning process have an impact, though little, on the answering process."}, {"heading": "5 Conclusion", "text": "In this paper, we proposed new continuous-time user models by using a powerful mathematical framework; Temporal Point Processes. Unlike, previous works on continuous-time user modeling which mainly focus on the impact of peer influence on user actions, the proposed method also consideres the impact of content and gamification elements, especially badges, on user actions. We extended the proposed method for modeling user questioning and answering activities over CQA cites and proposed an inference algorithm based on Variational EM which can efficiently learn the model parameters. The learnt parameters can help in categorizing users and understanding their preferences. These information will help the social media owners in creating implicit user profiles and delivering customized services. The empirical evaluations on both synthetic and real datasets, demonstrate the superior predictive performance of the proposed method.\nThere are many interesting lines for future works. In this work, we only considered the single activity threshold badges, incorporating other hybrid badges and also other gamification elements like reputation systems is a new line of research. On the content side, we used simple models, considering more complex models such as Bayesian non-parametric ones will help to improve the model. Modeling the quality of user actions and considering the impact of badges on the quality, is another interesting line of future investigation."}], "references": [{"title": "Survival and event history analysis: a process point of view", "author": ["O. Aalen", "O. Borgan", "H. Gjessing"], "venue": "Springer Science & Business Media", "citeRegEx": "1", "shortCiteRegEx": "1", "year": 2008}, {"title": "A survey of user modelling in social media websites", "author": ["A. Abdel-Hafez", "Y. Xu"], "venue": "Computer and Information Science 6(4),", "citeRegEx": "2", "shortCiteRegEx": "2", "year": 2013}, {"title": "Modeling content and users: Structured probabilistic representation and scalable inference algorithms", "author": ["A. Ahmed"], "venue": "Proceedings of the 18th ACM SIGKDD international conference on Knowledge discovery and data mining,", "citeRegEx": "3", "shortCiteRegEx": "3", "year": 2012}, {"title": "Scalable distributed inference of dynamic user interests for behavioral targeting", "author": ["A. Ahmed", "Y. Low", "M. Aly", "V. Josifovski", "A.J. Smola"], "venue": "Proceedings of the 17th ACM SIGKDD international conference on Knowledge discovery and data mining,", "citeRegEx": "4", "shortCiteRegEx": "4", "year": 2011}, {"title": "Scalable dynamic nonparametric bayesian models of content and users", "author": ["A. Ahmed", "E.P. Xing"], "venue": "In: Twenty-Third International Joint Conference on Artificial Intelligence", "citeRegEx": "5", "shortCiteRegEx": "5", "year": 2013}, {"title": "Steering user behavior with badges", "author": ["A. Anderson", "D. Huttenlocher", "J. Kleinberg", "J. Leskovec"], "venue": "Proceedings of the 22Nd International Conference on World Wide Web,", "citeRegEx": "6", "shortCiteRegEx": "6", "year": 2013}, {"title": "Engaging with massive online courses", "author": ["A. Anderson", "D. Huttenlocher", "J. Kleinberg", "J. Leskovec"], "venue": "Proceedings of the 23rd International Conference on the World Wide Web", "citeRegEx": "7", "shortCiteRegEx": "7", "year": 2014}, {"title": "Badges in social media: A social psychological perspective", "author": ["J. Antin", "E.F. Churchill"], "venue": "In: CHI 2011 Gamification Workshop Proceedings (Vancouver, BC,", "citeRegEx": "8", "shortCiteRegEx": "8", "year": 2011}, {"title": "On prediction using variable order markov models", "author": ["R. Begleiter", "R. El-Yaniv", "G. Yona"], "venue": "Journal of Artificial Intelligence Research 22,", "citeRegEx": "9", "shortCiteRegEx": "9", "year": 2004}, {"title": "Pattern Recognition and Machine Learning (Information Science and Statistics)", "author": ["C.M. Bishop"], "venue": null, "citeRegEx": "10", "shortCiteRegEx": "10", "year": 2006}, {"title": "Dynamic topic models", "author": ["D.M. Blei", "J.D. Lafferty"], "venue": "Proceedings of the 23rd international conference on Machine learning,", "citeRegEx": "11", "shortCiteRegEx": "11", "year": 2006}, {"title": "A correlated topic model of science", "author": ["D.M. Blei", "J.D. Lafferty"], "venue": "The Annals of Applied Statistics pp", "citeRegEx": "12", "shortCiteRegEx": "12", "year": 2007}, {"title": "Building reputation in stackoverflow: an empirical investigation", "author": ["A. Bosu", "C.S. Corley", "D. Heaton", "D. Chatterji", "J.C. Carver", "N.A. Kraft"], "venue": "Proceedings of the 10th Working Conference on Mining Software Repositories,", "citeRegEx": "13", "shortCiteRegEx": "13", "year": 2013}, {"title": "Statistical physics of social dynamics", "author": ["C. Castellano", "S. Fortunato", "V. Loreto"], "venue": "Reviews of modern physics 81(2),", "citeRegEx": "14", "shortCiteRegEx": "14", "year": 2009}, {"title": "Can gamification motivate voluntary contributions?: The case of stackoverflow q&a community", "author": ["H. Cavusoglu", "Z. Li", "K.W. Huang"], "venue": "Proceedings of the 18th ACM Conference Companion on Computer Supported Cooperative Work & Social Computing,", "citeRegEx": "15", "shortCiteRegEx": "15", "year": 2015}, {"title": "Dynamic poisson factorization", "author": ["L. Charlin", "R. Ranganath", "J. McInerney", "D.M. Blei"], "venue": "Proceedings of the 9th ACM Conference on Recommender Systems,", "citeRegEx": "16", "shortCiteRegEx": "16", "year": 2015}, {"title": "Generative models for item adoptions using social correlation", "author": ["F.C.T. Chua", "H.W. Lauw", "E.P. Lim"], "venue": "IEEE Transactions on Knowledge and Data Engineering", "citeRegEx": "17", "shortCiteRegEx": "17", "year": 2013}, {"title": "An Introduction to the Theory of Point Processes - Vol. I", "author": ["D. Daley", "D. Vere-Jones"], "venue": null, "citeRegEx": "18", "shortCiteRegEx": "18", "year": 2002}, {"title": "An introduction to the theory of point processes. Vol. II, second edn. Probability and its Applications (New York)", "author": ["D.J. Daley", "D. Vere-Jones"], "venue": null, "citeRegEx": "19", "shortCiteRegEx": "19", "year": 2008}, {"title": "From game design elements to gamefulness: defining gamification", "author": ["S. Deterding", "D. Dixon", "R. Khaled", "L. Nacke"], "venue": "Proceedings of the 15th international academic MindTrek conference: Envisioning future media environments,", "citeRegEx": "20", "shortCiteRegEx": "20", "year": 2011}, {"title": "Gamification. using gamedesign elements in non-gaming contexts", "author": ["S. Deterding", "M. Sicart", "L. Nacke", "K. O\u2019Hara", "D. Dixon"], "venue": "Extended Abstracts on Human Factors in Computing Systems, CHI EA", "citeRegEx": "21", "shortCiteRegEx": "21", "year": 2011}, {"title": "Dirichlet-hawkes processes with applications to clustering continuous-time document streams", "author": ["N. Du", "M. Farajtabar", "A. Ahmed", "A.J. Smola", "L. Song"], "venue": "Proceedings of the 21th ACM SIGKDD International Conference on Knowledge Discovery and Data Mining,", "citeRegEx": "22", "shortCiteRegEx": "22", "year": 2015}, {"title": "Uncover topic-sensitive information diffusion networks", "author": ["N. Du", "L. Song", "H. Woo", "H. Zha"], "venue": "Proceedings of the sixteenth international conference on artificial intelligence and statistics,", "citeRegEx": "23", "shortCiteRegEx": "23", "year": 2013}, {"title": "Learning networks of heterogeneous influence", "author": ["N. Du", "L. Song", "M. Yuan", "A.J. Smola"], "venue": "Advances in Neural Information Processing Systems,", "citeRegEx": "24", "shortCiteRegEx": "24", "year": 2012}, {"title": "Time-sensitive recommendation from recurrent user activities", "author": ["N. Du", "Y. Wang", "N. He", "J. Sun", "L. Song"], "venue": "Advances in Neural Information Processing Systems,", "citeRegEx": "25", "shortCiteRegEx": "25", "year": 2015}, {"title": "Coevolve: A joint point process model for information diffusion and network co-evolution", "author": ["M. Farajtabar", "Y. Wang", "M.G. Rodriguez", "S. Li", "H. Zha", "L. Song"], "venue": "Advances in Neural Information Processing Systems,", "citeRegEx": "26", "shortCiteRegEx": "26", "year": 2015}, {"title": "K.J.R.: Understanding Sequential User Behavior in Social Computing: To Answer or to Vote", "author": ["Y. Gao", "Y. Chen", "Liu"], "venue": "IEEE Transactions on Network Science and Engineering", "citeRegEx": "27", "shortCiteRegEx": "27", "year": 2015}, {"title": "Scalable recommendation with hierarchical poisson factorization", "author": ["P. Gopalan", "J.M. Hofman", "D.M. Blei"], "venue": "UAI, pp", "citeRegEx": "28", "shortCiteRegEx": "28", "year": 2015}, {"title": "Badges of friendship: social influence and badge acquisition on stack overflow", "author": ["A. Halavais", "K.H. Kwon", "S. Havener", "J. Striker"], "venue": "47th Hawaii International Conference on System Sciences,", "citeRegEx": "29", "shortCiteRegEx": "29", "year": 2014}, {"title": "Do badges increase user activity? a field experiment on the effects of gamification", "author": ["J. Hamari"], "venue": "Computers in human behavior", "citeRegEx": "30", "shortCiteRegEx": "30", "year": 2015}, {"title": "Hawkestopic: A joint model for network inference and topic modeling from text-based cascades", "author": ["X. He", "T. Rekatsinas", "J.R. Foulds", "L. Getoor", "Y. Liu"], "venue": null, "citeRegEx": "31", "shortCiteRegEx": "31", "year": 2015}, {"title": "Stochastic models predict user behavior in social media", "author": ["T. Hogg", "K. Lerman", "L.M. Smith"], "venue": "arXiv preprint arXiv:1308.2705", "citeRegEx": "32", "shortCiteRegEx": "32", "year": 2013}, {"title": "Hnp3: A hierarchical nonparametric point process for modeling content diffusion over social media", "author": ["S.A. Hosseini", "A. Khodadadi", "S. Arabzade", "H.R. Rabiee"], "venue": "Data Mining (ICDM),", "citeRegEx": "33", "shortCiteRegEx": "33", "year": 2016}, {"title": "Impact of human activity patterns on the dynamics of information diffusion", "author": ["J.L. Iribarren", "E. Moro"], "venue": "Physical review letters 103(3),", "citeRegEx": "34", "shortCiteRegEx": "34", "year": 2009}, {"title": "Quick trigger on stack overflow: A study of gamification-influenced member tendencies", "author": ["Y. Jin", "X. Yang", "R.G. Kula", "E. Choi", "K. Inoue", "H. Iida"], "venue": "IEEE/ACM 12th Working Conference on Mining Software Repositories,", "citeRegEx": "35", "shortCiteRegEx": "35", "year": 2015}, {"title": "A new measure of rank correlation", "author": ["M.G. KENDALL"], "venue": "Biometrika 30(1-2),", "citeRegEx": "36", "shortCiteRegEx": "36", "year": 1938}, {"title": "Using stochastic models to describe and predict social dynamics of web users", "author": ["K. Lerman", "T. Hogg"], "venue": "ACM Transactions on Intelligent Systems and Technology (TIST) 3(4),", "citeRegEx": "38", "shortCiteRegEx": "38", "year": 2012}, {"title": "Modeling user exposure in recommendation", "author": ["D. Liang", "L. Charlin", "J. McInerney", "D.M. Blei"], "venue": "Proceedings of the 25th International Conference on World Wide Web, pp. 951\u2013961. International World Wide Web Conferences Steering Committee", "citeRegEx": "39", "shortCiteRegEx": "39", "year": 2016}, {"title": "Discovering latent network structure in point process data", "author": ["S.W. Linderman", "R.P. Adams"], "venue": "In: ICML, pp", "citeRegEx": "40", "shortCiteRegEx": "40", "year": 2014}, {"title": "Probabilistic user behavior models", "author": ["E. Manavoglu", "D. Pavlov", "C. Giles"], "venue": "Third IEEE International Conference on Data Mining,", "citeRegEx": "41", "shortCiteRegEx": "41", "year": 2003}, {"title": "Stack overflow badges and user behavior: an econometric approach", "author": ["A. Marder"], "venue": "Proceedings of the 12th Working Conference on Mining Software Repositories,", "citeRegEx": "42", "shortCiteRegEx": "42", "year": 2015}, {"title": "Analysis of the reputation system and user contributions on a question answering website: Stackoverflow", "author": ["D. Movshovitz-Attias", "Y. Movshovitz-Attias", "P. Steenkiste", "C. Faloutsos"], "venue": "Advances in Social Networks Analysis and Mining (ASONAM),", "citeRegEx": "43", "shortCiteRegEx": "43", "year": 2013}, {"title": "Information diffusion and external influence in networks", "author": ["S.A. Myers", "C. Zhu", "J. Leskovec"], "venue": "Proceedings of the 18th ACM SIGKDD international conference on Knowledge discovery and data mining,", "citeRegEx": "44", "shortCiteRegEx": "44", "year": 2012}, {"title": "On lewis\u2019 simulation method for point processes", "author": ["Y. Ogata"], "venue": "IEEE Transactions on Information Theory 27(1),", "citeRegEx": "45", "shortCiteRegEx": "45", "year": 1981}, {"title": "A tutorial on hidden markov models and selected applications in speech recognition", "author": ["L.R. Rabiner"], "venue": "Proceedings of the IEEE 77(2),", "citeRegEx": "46", "shortCiteRegEx": "46", "year": 1989}, {"title": "Modeling temporal activity patterns in dynamic social networks", "author": ["V. Raghavan", "G.V. Steeg", "A. Galstyan", "A.G. Tartakovsky"], "venue": "IEEE Transactions on Computational Social Systems", "citeRegEx": "47", "shortCiteRegEx": "47", "year": 2014}, {"title": "Temporal point processes the conditional intensity function", "author": ["J.G. Rasmussen"], "venue": null, "citeRegEx": "48", "shortCiteRegEx": "48", "year": 2011}, {"title": "Uncovering the temporal dynamics of diffusion networks", "author": ["M.G. Rodriguez", "D. Balduzzi", "B. Sch\u00f6lkopf"], "venue": "arXiv preprint arXiv:1105.0697", "citeRegEx": "49", "shortCiteRegEx": "49", "year": 2011}, {"title": "Modeling similarity in incentivized interaction: A longitudinal case study of stackoverflow", "author": ["T. Sinha", "W. Wei", "K. Carley"], "venue": "NIPS 2015 Workshop on Social and Information Networks, 29th Annual International Conference on Neural Information and Processing Systems", "citeRegEx": "50", "shortCiteRegEx": "50", "year": 2015}, {"title": "Modeling adoption and usage of competing products", "author": ["I. Valera", "M. Gomez-Rodriguez"], "venue": "Data Mining (ICDM),", "citeRegEx": "51", "shortCiteRegEx": "51", "year": 2015}, {"title": "Modeling user activity preference by leveraging user spatial temporal characteristics in lbsns", "author": ["D. Yang", "D. Zhang", "V.W. Zheng", "Z. Yu"], "venue": "IEEE Transactions on Systems, Man, and Cybernetics: Systems", "citeRegEx": "52", "shortCiteRegEx": "52", "year": 2015}, {"title": "Mixture of mutually exciting processes for viral diffusion", "author": ["S.H. Yang", "H. Zha"], "venue": null, "citeRegEx": "53", "shortCiteRegEx": "53", "year": 2013}, {"title": "Dynamic User Modeling in Social Media Systems", "author": ["H. Yin", "B. Cui", "L. Chen", "Z. Hu", "X. Zhou"], "venue": "ACM Transactions on Information Systems 33(3),", "citeRegEx": "54", "shortCiteRegEx": "54", "year": 2015}, {"title": "Spatio-temporal modeling of check-ins in location-based social networks", "author": ["A. Zarezade", "S. Jafarzadeh", "H.R. Rabiee"], "venue": null, "citeRegEx": "55", "shortCiteRegEx": "55", "year": 2016}, {"title": "Correlated cascades: Compete or cooperate", "author": ["A. Zarezade", "A. Khodadadi", "M. Farajtabar", "H.R. Rabiee", "H. Zha"], "venue": "arXiv preprint arXiv:1510.00936", "citeRegEx": "56", "shortCiteRegEx": "56", "year": 2015}, {"title": "Social badge system analysis", "author": ["J. Zhang", "X. Kong", "S.Y. Philip"], "venue": "Advances in Social Networks Analysis and Mining (ASONAM),", "citeRegEx": "57", "shortCiteRegEx": "57", "year": 2016}, {"title": "Learning social infectivity in sparse low-rank networks using multi-dimensional hawkes processes", "author": ["K. Zhou", "H. Zha", "L. Song"], "venue": "In: AISTATS,", "citeRegEx": "58", "shortCiteRegEx": "58", "year": 2013}], "referenceMentions": [{"referenceID": 1, "context": "Indeed, these models have only concentrated on what is done on the social media, and do not consider when it is done [2].", "startOffset": 117, "endOffset": 120}, {"referenceID": 4, "context": "Most of these methods do not model the time of user actions and only consider time as a covariate and hence are unable to predict the time of users future actions [5,54].", "startOffset": 163, "endOffset": 169}, {"referenceID": 52, "context": "Most of these methods do not model the time of user actions and only consider time as a covariate and hence are unable to predict the time of users future actions [5,54].", "startOffset": 163, "endOffset": 169}, {"referenceID": 51, "context": "Actually, the precise time interval or the exact distance between two actions carries a great deal of information about the dynamics of the underlying systems and hence the emerging continuous-time models that consider the exact timing of events are more applicable to real world scenarios [53,58,56,51,33,22,23,31].", "startOffset": 290, "endOffset": 315}, {"referenceID": 56, "context": "Actually, the precise time interval or the exact distance between two actions carries a great deal of information about the dynamics of the underlying systems and hence the emerging continuous-time models that consider the exact timing of events are more applicable to real world scenarios [53,58,56,51,33,22,23,31].", "startOffset": 290, "endOffset": 315}, {"referenceID": 54, "context": "Actually, the precise time interval or the exact distance between two actions carries a great deal of information about the dynamics of the underlying systems and hence the emerging continuous-time models that consider the exact timing of events are more applicable to real world scenarios [53,58,56,51,33,22,23,31].", "startOffset": 290, "endOffset": 315}, {"referenceID": 49, "context": "Actually, the precise time interval or the exact distance between two actions carries a great deal of information about the dynamics of the underlying systems and hence the emerging continuous-time models that consider the exact timing of events are more applicable to real world scenarios [53,58,56,51,33,22,23,31].", "startOffset": 290, "endOffset": 315}, {"referenceID": 32, "context": "Actually, the precise time interval or the exact distance between two actions carries a great deal of information about the dynamics of the underlying systems and hence the emerging continuous-time models that consider the exact timing of events are more applicable to real world scenarios [53,58,56,51,33,22,23,31].", "startOffset": 290, "endOffset": 315}, {"referenceID": 21, "context": "Actually, the precise time interval or the exact distance between two actions carries a great deal of information about the dynamics of the underlying systems and hence the emerging continuous-time models that consider the exact timing of events are more applicable to real world scenarios [53,58,56,51,33,22,23,31].", "startOffset": 290, "endOffset": 315}, {"referenceID": 22, "context": "Actually, the precise time interval or the exact distance between two actions carries a great deal of information about the dynamics of the underlying systems and hence the emerging continuous-time models that consider the exact timing of events are more applicable to real world scenarios [53,58,56,51,33,22,23,31].", "startOffset": 290, "endOffset": 315}, {"referenceID": 30, "context": "Actually, the precise time interval or the exact distance between two actions carries a great deal of information about the dynamics of the underlying systems and hence the emerging continuous-time models that consider the exact timing of events are more applicable to real world scenarios [53,58,56,51,33,22,23,31].", "startOffset": 290, "endOffset": 315}, {"referenceID": 19, "context": "Gamification is defined as using game elements in non-game systems to increase user engagement [20].", "startOffset": 95, "endOffset": 99}, {"referenceID": 5, "context": "Recent studies have shown that these gamification elements act as incentive mechanisms and have a significant effect on user participation behavior over social media websites [6].", "startOffset": 175, "endOffset": 178}, {"referenceID": 51, "context": "Some preliminary works tried to model the user behavior and predict the future user actions using the time of users\u2019 actions and the impact of activity of friends on each other [53,58].", "startOffset": 177, "endOffset": 184}, {"referenceID": 56, "context": "Some preliminary works tried to model the user behavior and predict the future user actions using the time of users\u2019 actions and the impact of activity of friends on each other [53,58].", "startOffset": 177, "endOffset": 184}, {"referenceID": 32, "context": "More recently, some works tried to jointly model the content and time of actions [33,22,23].", "startOffset": 81, "endOffset": 91}, {"referenceID": 21, "context": "More recently, some works tried to jointly model the content and time of actions [33,22,23].", "startOffset": 81, "endOffset": 91}, {"referenceID": 22, "context": "More recently, some works tried to jointly model the content and time of actions [33,22,23].", "startOffset": 81, "endOffset": 91}, {"referenceID": 3, "context": "There exists a rich literature that use user models over social media ranging from recommender systems [4,39], to diffusion network analysis [49,58], and content analysis [3] [2].", "startOffset": 103, "endOffset": 109}, {"referenceID": 37, "context": "There exists a rich literature that use user models over social media ranging from recommender systems [4,39], to diffusion network analysis [49,58], and content analysis [3] [2].", "startOffset": 103, "endOffset": 109}, {"referenceID": 47, "context": "There exists a rich literature that use user models over social media ranging from recommender systems [4,39], to diffusion network analysis [49,58], and content analysis [3] [2].", "startOffset": 141, "endOffset": 148}, {"referenceID": 56, "context": "There exists a rich literature that use user models over social media ranging from recommender systems [4,39], to diffusion network analysis [49,58], and content analysis [3] [2].", "startOffset": 141, "endOffset": 148}, {"referenceID": 2, "context": "There exists a rich literature that use user models over social media ranging from recommender systems [4,39], to diffusion network analysis [49,58], and content analysis [3] [2].", "startOffset": 171, "endOffset": 174}, {"referenceID": 1, "context": "There exists a rich literature that use user models over social media ranging from recommender systems [4,39], to diffusion network analysis [49,58], and content analysis [3] [2].", "startOffset": 175, "endOffset": 178}, {"referenceID": 36, "context": "Some have focussed on describing aggregate behavior of many people [38,34,14] while others have focussed on individual behavior models [52,32].", "startOffset": 67, "endOffset": 77}, {"referenceID": 33, "context": "Some have focussed on describing aggregate behavior of many people [38,34,14] while others have focussed on individual behavior models [52,32].", "startOffset": 67, "endOffset": 77}, {"referenceID": 13, "context": "Some have focussed on describing aggregate behavior of many people [38,34,14] while others have focussed on individual behavior models [52,32].", "startOffset": 67, "endOffset": 77}, {"referenceID": 50, "context": "Some have focussed on describing aggregate behavior of many people [38,34,14] while others have focussed on individual behavior models [52,32].", "startOffset": 135, "endOffset": 142}, {"referenceID": 31, "context": "Some have focussed on describing aggregate behavior of many people [38,34,14] while others have focussed on individual behavior models [52,32].", "startOffset": 135, "endOffset": 142}, {"referenceID": 42, "context": "In this direction, the works have mainly concentrated on the impact of social network [44] and topics of interests on user activities [3,52,17].", "startOffset": 86, "endOffset": 90}, {"referenceID": 2, "context": "In this direction, the works have mainly concentrated on the impact of social network [44] and topics of interests on user activities [3,52,17].", "startOffset": 134, "endOffset": 143}, {"referenceID": 50, "context": "In this direction, the works have mainly concentrated on the impact of social network [44] and topics of interests on user activities [3,52,17].", "startOffset": 134, "endOffset": 143}, {"referenceID": 16, "context": "In this direction, the works have mainly concentrated on the impact of social network [44] and topics of interests on user activities [3,52,17].", "startOffset": 134, "endOffset": 143}, {"referenceID": 4, "context": "Most of these methods do not model the time of user actions and only consider time as a covariate, and hence are unable to predict the time of users future actions [5,54].", "startOffset": 164, "endOffset": 170}, {"referenceID": 52, "context": "Most of these methods do not model the time of user actions and only consider time as a covariate, and hence are unable to predict the time of users future actions [5,54].", "startOffset": 164, "endOffset": 170}, {"referenceID": 8, "context": "Moreover, most of existing temporal user modeling methods approach the problem in a discrete time manner, and the classic varying-order Markov models [9,46] have been used by most of those methods [41,47,27].", "startOffset": 150, "endOffset": 156}, {"referenceID": 44, "context": "Moreover, most of existing temporal user modeling methods approach the problem in a discrete time manner, and the classic varying-order Markov models [9,46] have been used by most of those methods [41,47,27].", "startOffset": 150, "endOffset": 156}, {"referenceID": 39, "context": "Moreover, most of existing temporal user modeling methods approach the problem in a discrete time manner, and the classic varying-order Markov models [9,46] have been used by most of those methods [41,47,27].", "startOffset": 197, "endOffset": 207}, {"referenceID": 45, "context": "Moreover, most of existing temporal user modeling methods approach the problem in a discrete time manner, and the classic varying-order Markov models [9,46] have been used by most of those methods [41,47,27].", "startOffset": 197, "endOffset": 207}, {"referenceID": 26, "context": "Moreover, most of existing temporal user modeling methods approach the problem in a discrete time manner, and the classic varying-order Markov models [9,46] have been used by most of those methods [41,47,27].", "startOffset": 197, "endOffset": 207}, {"referenceID": 46, "context": "Temporal point processes are a general mathematical framework for modeling continuous-time events [37,48].", "startOffset": 98, "endOffset": 105}, {"referenceID": 51, "context": "Several models have been proposed in the literature that use temporal point processes to model the information diffusion over networks [53,58].", "startOffset": 135, "endOffset": 142}, {"referenceID": 56, "context": "Several models have been proposed in the literature that use temporal point processes to model the information diffusion over networks [53,58].", "startOffset": 135, "endOffset": 142}, {"referenceID": 56, "context": "The first studies considered the impact of peer influence on user diffusion behavior and used a special point process, called Hawkes [58,53,49,24], to model the user activities.", "startOffset": 133, "endOffset": 146}, {"referenceID": 51, "context": "The first studies considered the impact of peer influence on user diffusion behavior and used a special point process, called Hawkes [58,53,49,24], to model the user activities.", "startOffset": 133, "endOffset": 146}, {"referenceID": 47, "context": "The first studies considered the impact of peer influence on user diffusion behavior and used a special point process, called Hawkes [58,53,49,24], to model the user activities.", "startOffset": 133, "endOffset": 146}, {"referenceID": 23, "context": "The first studies considered the impact of peer influence on user diffusion behavior and used a special point process, called Hawkes [58,53,49,24], to model the user activities.", "startOffset": 133, "endOffset": 146}, {"referenceID": 54, "context": "In this direction, other extensions were considered, that removed the independence assumption between different cascades [56,51].", "startOffset": 121, "endOffset": 128}, {"referenceID": 49, "context": "In this direction, other extensions were considered, that removed the independence assumption between different cascades [56,51].", "startOffset": 121, "endOffset": 128}, {"referenceID": 32, "context": "Some other works tried to consider the content in the diffusion behavior [33,22,23,31].", "startOffset": 73, "endOffset": 86}, {"referenceID": 21, "context": "Some other works tried to consider the content in the diffusion behavior [33,22,23,31].", "startOffset": 73, "endOffset": 86}, {"referenceID": 22, "context": "Some other works tried to consider the content in the diffusion behavior [33,22,23,31].", "startOffset": 73, "endOffset": 86}, {"referenceID": 30, "context": "Some other works tried to consider the content in the diffusion behavior [33,22,23,31].", "startOffset": 73, "endOffset": 86}, {"referenceID": 24, "context": "The authors in [25, 28] incorporated temporal point processes in recommender systems.", "startOffset": 15, "endOffset": 23}, {"referenceID": 27, "context": "The authors in [25, 28] incorporated temporal point processes in recommender systems.", "startOffset": 15, "endOffset": 23}, {"referenceID": 38, "context": "[40] used point processes to infer latent network structure in financial economic interactions and reciprocity in gang violence.", "startOffset": 0, "endOffset": 4}, {"referenceID": 25, "context": "[26] tried to use temporal point processes to jointly model the network evolution and diffusion together, and Zarezade et.", "startOffset": 0, "endOffset": 4}, {"referenceID": 53, "context": "[55] tried to model user check-in behavior in location based social networks using temporal point processes.", "startOffset": 0, "endOffset": 4}, {"referenceID": 20, "context": "The study of gamification and impact of gamification elements on user participation in online media has gained a considerable attention in recent years [21].", "startOffset": 152, "endOffset": 156}, {"referenceID": 7, "context": "Antin and Churchill [8] discuss the various functions and motivations of badges in terms of", "startOffset": 20, "endOffset": 23}, {"referenceID": 28, "context": "[29] study the impact of social influence on individual badge earnings on Stack Overflow, and conclude that the influence of friends on badge selection is weak but has some effect.", "startOffset": 0, "endOffset": 4}, {"referenceID": 55, "context": "[57] study an existing badge system in Foursquare and unlike Halavais, they found that users who are friends are more likely to obtain common badges.", "startOffset": 0, "endOffset": 4}, {"referenceID": 34, "context": "The authors in [35] analyze how much gamification techniques influence the member response tendencies.", "startOffset": 15, "endOffset": 19}, {"referenceID": 48, "context": "The authors in [50] study the impact of reputation on user activities and clustered users based on the reputation trends.", "startOffset": 15, "endOffset": 19}, {"referenceID": 12, "context": "[13] and Movshovitz-Attias et al.", "startOffset": 0, "endOffset": 4}, {"referenceID": 41, "context": "[43].", "startOffset": 0, "endOffset": 4}, {"referenceID": 14, "context": "The authors in [15], study the impact of a hierarchical badge system on user participation and engagement at Stack Overflow.", "startOffset": 15, "endOffset": 19}, {"referenceID": 6, "context": "[7] studied a large-scale deployment of badges as incentives for engagement in a massive open online course (MOOC) system.", "startOffset": 0, "endOffset": 3}, {"referenceID": 29, "context": "Hamari [30] actively studied the impact of gamification elements (badges) on an international peer-to-peer trading service.", "startOffset": 7, "endOffset": 11}, {"referenceID": 5, "context": "[6].", "startOffset": 0, "endOffset": 3}, {"referenceID": 40, "context": "Marder [42] also proposed a discrete-time model of user actions and performed a regression analysis of user activities over Stack Overflow which conforms with previous empirical observations.", "startOffset": 7, "endOffset": 11}, {"referenceID": 17, "context": "A temporal point process can be completely specified by distribution of its inter-event durations [18].", "startOffset": 98, "endOffset": 102}, {"referenceID": 0, "context": "Intuitively, \u03bb\u2217(t) is the probability of an event occurring in time interval [t, t+ dt) given the history of events up to t, and it is a more intuitive way to characterize a temporal point process [1].", "startOffset": 197, "endOffset": 200}, {"referenceID": 26, "context": "the impact of badge on users participation increases as they are close to achieving it [27].", "startOffset": 87, "endOffset": 91}, {"referenceID": 27, "context": "These auxiliary variables facilitate the inference algorithm without changing the model [28].", "startOffset": 88, "endOffset": 92}, {"referenceID": 9, "context": "For any distribution q(S) over the auxiliary latent variables, the following decomposition holds [10]:", "startOffset": 97, "endOffset": 101}, {"referenceID": 10, "context": "Using the approach used in [11,12], we define a new variational parameters \u03b6j for each answer event:", "startOffset": 27, "endOffset": 34}, {"referenceID": 11, "context": "Using the approach used in [11,12], we define a new variational parameters \u03b6j for each answer event:", "startOffset": 27, "endOffset": 34}, {"referenceID": 43, "context": "Then by using the Ogata\u2019s thinning method [45], we generated the events of our model.", "startOffset": 42, "endOffset": 46}, {"referenceID": 9, "context": "In the variational EM, log-likelihood after the E-step should never decreases [10], and our results conform with this expectation.", "startOffset": 78, "endOffset": 82}, {"referenceID": 35, "context": "To this end, we used the Kendall rank coefficient [36].", "startOffset": 50, "endOffset": 54}, {"referenceID": 15, "context": "We reported average Precision@k and NDCG@k [16] for different test events over all users.", "startOffset": 43, "endOffset": 47}, {"referenceID": 24, "context": "Usually, predicting the most popular is a strong heuristic [25].", "startOffset": 59, "endOffset": 63}, {"referenceID": 18, "context": "According to the time-change theorem [19], given all ti and ti+1 subsequent event times of a particular point process, the set of intensity integrals \u222b ti+1 ti \u03bb(t)dt should conform to the unit-rate exponential distribution, if the samples are truly sampled from the process \u03bb(t).", "startOffset": 37, "endOffset": 41}], "year": 2017, "abstractText": "User modeling plays an important role in delivering customized web services to the users and improving their engagement. However, most user models in the literature do not explicitly consider the temporal behavior of users. More recently, continuous-time user modeling has gained considerable attention and many user behavior models have been proposed based on temporal point processes. However, typical point process based models often considered the impact of peer influence and content on the user participation and neglected other factors. Gamification elements, are among those factors that are neglected, while they have a strong impact on user participation in online services. In this paper, we propose interdependent multi-dimensional temporal point processes that capture the impact of badges on user participation besides the peer influence and content factors. We extend the proposed processes to model user actions over the community Ali Khodadadi AICT Innovation Center, Department of Computer Engineering Sharif University of Technology, Tehran, Iran E-mail: khodadadi@ce.sharif.edu Seyed Abbas Hosseini AICT Innovation Center, Department of Computer Engineering Sharif University of Technology, Tehran, Iran E-mail: a hosseini@ce.sharif.edu Erfan Tavakoli AICT Innovation Center, Department of Computer Engineering Sharif University of Technology, Tehran, Iran E-mail: etavakoli@ce.sharif.edu Hamid R. Rabiee AICT Innovation Center, Department of Computer Engineering Sharif University of Technology, Tehran, Iran E-mail: rabiee@sharif.edu ar X iv :1 70 2. 01 94 8v 1 [ cs .S I] 7 F eb 2 01 7 2 Ali Khodadadi, Seyed Abbas Hosseini, Erfan Tavakoli, Hamid R. Rabiee based question and answering websites, and propose an inference algorithm based on Variational-EM that can efficiently learn the model parameters. Extensive experiments on both synthetic and real data gathered from Stack Overflow show that our inference algorithm learns the parameters efficiently and the proposed method can better predict the user behavior compared to the alternatives.", "creator": "LaTeX with hyperref package"}}}