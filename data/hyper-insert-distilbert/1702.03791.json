{"id": "1702.03791", "review": {"conference": "arxiv", "VERSION": "v1", "DATE_OF_SUBMISSION": "13-Feb-2017", "title": "DNN Filter Bank Cepstral Coefficients for Spoofing Detection", "abstract": "experiments with especially the development of speech synthesis techniques, automatic speaker verification experimental systems continuously face confronted the serious challenge of isolated spoofing attack. in order to and improve improved the reliability of speaker verification systems, we develop a new finite filter bank memory based cepstral feature, modeled deep spectrum neural block network filter tissue bank with cepstral coefficients ( dnn - fbcc ), essential to efficiently distinguish between unexpected natural noise and emotionally spoofed speech. learns the deep neural band network filter flow bank matrices is automatically continuously generated professionally by remotely training a filter bank neural network ( fbnn ) database using natural and synthetic speech. by adding restrictions on understanding the empirical training transmission rules, the experimental learned detector weight validation matrix of the fbnn is band - frequency limited and sorted systematically by spatial frequency, being similar to the normal filter product bank. unlike learning the manually designed filter sample bank, the learned filter function bank matrix has captured different spectral filter chain shapes in different performance channels, which can better capture the differences occurring between natural and synthetic speech more fairly effectively. indeed the experimental results announced on the russian asvspoof { sep 2015 } analytical database archives show that the gaussian mixture inversion model applies maximum - likelihood ( gmm - ml ) error classifier independently trained by the new feedback feature performs better than the true state - of - the - art : linear frequency cepstral fourier coefficients ( now lfcc ), based classifier, especially on then detecting unknown listener attacks.", "histories": [["v1", "Mon, 13 Feb 2017 14:44:17 GMT  (2659kb,D)", "http://arxiv.org/abs/1702.03791v1", null]], "reviews": [], "SUBJECTS": "cs.SD cs.CR cs.LG", "authors": ["hong yu", "zheng-hua tan", "zhanyu ma", "jun guo"], "accepted": false, "id": "1702.03791"}, "pdf": {"name": "1702.03791.pdf", "metadata": {"source": "CRF", "title": "DNN Filter Bank Cepstral Coefficients for Spoofing Detection", "authors": ["Hong Yu", "Zheng-Hua Tan", "Zhanyu Ma", "Jun Guo"], "emails": [], "sections": [{"heading": null, "text": "Index Terms\nspeaker verification, spoofing detection, DNN filter bank cepstral coefficients, filter bank neural network.\nI. INTRODUCTION\nAS a low-cost and flexible biometric solution to person authentication, automatic speaker verification (ASV) has been usedin many telephone or network access control systems, such as telephone banking [1]. Recently, with the improvement of automatic speech generation methods, speech produced by voice conversion (VC) [2][3] and speech synthesis (SS) [4][5] techniques has been used to attack ASV systems. Over the past few years, much research has been devoted to protect ASV systems against spoofing attack [6][7][8].\nThere are two general strategies to protect ASV systems. One is to develop a more robust ASV system which can resist the spoofing attack. Unfortunately, research has shown that all the existing ASV systems are vulnerable to spoofing attacks [9][10][11]. Verification and anti-spoofing tasks can not be done well in only one system at the same time.\nThe other more popular strategy is to build a separated spoofing detection system which only focuses on distinguishing between natural and synthetic speech [12]. Because of the advantage of being easily incorporated into existing ASV systems, spoofing detection has become an important research topic in anti-spoofing [6][10][13][14].\nMany different acoustic features have been proposed to improve the performance of Gaussian mixture model maximumlikelihood (GMM-ML) based spoofing detection systems. In [15], relative phase shift (RPS) and Mel-frequency cepstral coefficients (MFCC) were used to detect SS attacks. A fusion system combining MFCC and group delay cepstral coefficients (GDCC) was applied to resist VC spoofing in [1]. Paper [16] compared the spoofing detection performance of 11 different features on the ASVspoof 2015 database [17]. Among others, dynamic linear frequency cepstral coefficients (LFCC) feature performed best on the evaluation set and the average equal error rate was lower than 1%.\nDifferent from the aforementioned systems, some more general systems using machine learning methods were developed to model the difference between natural and synthetic speech more effectively. In [18][19][20], spoofing detection systems based on deep neural networks (DNNs) were proposed and tested, where a DNN was used as a classifier or feature extractor. Unfortunately, experimental results showed that, compared with the acoustic feature based GMM-ML systems, these DNN systems performed slightly better on detecting the trained/known spoofing methods, but much worse on detecting unknown attacks.\nIn the previous studies, when a DNN was used as a feature extractor, the output of the middle hidden layer was used as DNN features to directly train some other types of models, e.g., Gaussian mixture model (GMM) or support vector machine (SVM) [19][21][22].\nIf we use the short-term power spectrum as the input of a DNN and set the activation function of first hidden layer as \u201clinear\u201d, the learned weight matrix between the input layer and the first hidden layer can be considered as a special type of learned filter bank. The number of this hidden layer nodes corresponds to the number of filter bank channels and each column of the weigh matrix can be treated as the frequency response of each filter. Unlike the conventional manually designed filter\nH. Yu, Z. Ma, and J. Guo are with Pattern Recognition and Intelligent System Lab., Beijing University of Posts and Telecommunications, Beijing, China. Z.-H. Tan is with the Department of Electronic Systems, Aalborg University, Aalborg, Denmark This work was conducted during H. Yu\u2019s visit to Z.-H. Tan at the Aalborg University. The corresponding author is Z. Ma. Email mazhanyu@bupt.edu.cn\nar X\niv :1\n70 2.\n03 79\n1v 1\n[ cs\n.S D\n] 1\n3 Fe\nb 20\n17\n2 Frame/ Windowing Speech signal\nFFT Filter bank\nLogDCTCep Features Filter bank features\n2 )( X\u03c9je\nN C\nM\nFig. 1. The processing flow of computing cepstral features, where N , C, and M stand for the FFT points, the number of filter bank channels, and the number of cepstral coefficients, respectively.\nbanks, the filters of the learned filter bank have different shapes in different channels, which can capture the discriminative characteristic between natural and synthetic speech more effectively. The DNN feature generated from the first hidden layer can be treated as a kind of filter bank feature.\nSome filter bank learning methods such as LDA (Linear discriminant analysis) filter learning [23] and log Mel-scale filters learning [24] have been introduced in the literatures. These methods did not restrict the shapes of learned filters and the learned filter bank features were used on the speech recognition task.\nIn this paper, we introduce a new filter bank neural network (FBNN) by introducing some restriction on the training rules, the learned filters are non-negative, band-limited, ordered by frequencies and have restricted shapes. The DNN feature generated by the first hidden layer of FBNN has the similar physical meaning of the conventional filter bank feature and after cepstral analysis we obtain a new type of feature, namely, deep neural network filter bank cepstral coefficients (DNN-FBCC). Experimental results show that the GMM-ML classifier based on DNN-FBCC feature outperforms the LFCC feature and DNN feature on the ASVspoof 2015 data base [17]."}, {"heading": "II. FILTER BANK NEURAL NETWORKS", "text": "As a hot research area, deep neural networks have been successfully used in many speech processing tasks such as speech recognition [25][26], speaker verification [27][28] and speech enhancement [29][30].\nA trained DNN can be used for regression analysis, classification, or feature extraction. When a DNN is used as a feature extractor, due to lack of knowledge about the specific physical interpretation of the DNN feature, the learned feature can only be used to train some other models, directly. Further processing, such as cepstral analysis, can not be applied.\nAs one of the most classical features for speech processing, cepstral (Cep) features , e.g., MFCC and LFCC, have been widely used in most speech processing tasks.\nCep features can be created with the following procedure shown in Fig.1. Firstly, the speech signal is segmented into short time frames with overlapped windows. Secondly, the power spectrum \u2223\u2223X (ejw)\u2223\u22232 are generated by frame-wise N points fast Fourier transform (FFT). Thirdly, the power spectrum is integrated using overlapping band-limited filter bank with C channels, generating the filter bank features. Finally, after logarithmic compression and discrete cosine transform (DCT) on the filter bank feature, M coefficients are selected as the Cep feature.\nAs shown in Fig.2.(a), a representative of commonly filters bank used in Cep feature extraction are non-negative, band limited, sorted by frequency and have similar shapes in different channels. The similar shapes for all the channels are not suitable for the spoofing detection task because different frequency bands may play different roles in spoofing attacks. This motivates us to use a DNN model to train a more flexible and effective filter bank.\nAs show in Fig. 3 we build a FBNN which includes a linear hidden layer H1, a sigmoid hidden layer H2 and a softmax output layer. The number of nodes in the output layer is Nout, where the first node stands for the human voice and the other nodes represent different spoofing attack methods. The same as computing Cep features, we also use the power spectrum as the input. Because the neural activation function of H1 is a linear function, the output of the first hidden layer can be defined as:\nH1 = FWfb, (1)\nwhere F is the input power spectrum feature with D dimension, D = 0.5N + 1. The weight matrix between the input layer and the first hidden layer is defined as a filter bank weight matrix Wfb with dimensions D\u00d7C. C is the number of nodes of the first hidden layer and also means the number of channels in the learned filter bank. Each column of Wfb can be treated as a learned filter channel.\nIf we do not add any restrictions in the training processing, the learned filters will have the shapes as shown in Fig. 2.(b). Each channel can learn a different filter shape but the characteristics of a normal filter bank, such as non-negative, band-limit and ordered by frequency, can not be satisfied.\nIn order to tackle this problem, we apply some restrictive conditions on Wfb as\n3 80 0 1\nFrequency(kHZ)\nAm pl\nit ud\ne\n(a)\n7520\n0\n5\n-3\nAm pl\nit ud\ne\nFFT bin\n(b)\n1 2 3 4 5\n257 0\n0.2 0.4 0.6\n0.8 11\nChannel\nFF T\nbi n\n(c)\n7520 0\n1\nFFT bin\nAm pl\nit ud\ne\n(d)\nFig. 2. (a) A linear frequency triangular filter bank, (b) Learned filter bank without restriction, (c) Band-limiting mask matrix sampling from (a), (d) Learned filter bank with restriction.\nhuman different spoof methods\nInput layer\nHidden layer1\nHidden layer2 Sigmod\nOutput layer Softmax\n2 ) ( X\u03c9je\nLabel\nLearned Filter bank\n\uff08Linear\uff09\nFig. 3. The structure of filter bank neural networks.\nWfb = NR(W) Mbl, (2)\nwhere W \u2208 RD\u00d7C , Mbl \u2208 RD\u00d7C\u22650 and means element wise multiplication. NR(\u00b7) is a non-negative restriction function which can make elements of Wfb non-negative. Any monotone increasing function with non-negative output can be used. We select the sigmoid function:\nNR(x) = 1/(1 + exp(\u2212x)). (3)\nMbl is a non-negative band-limiting shape restriction mask matrix which can restrict the filters of the learned filter bank to have limited band, regulation shape and ordered by frequency. Mbl can be generated from any band-limited filter bank by frequency-domain sampling. Fig. 2.(c) shows a Mbl sampling from a linear frequency triangular filter bank with five channels (Fig. 2.(a)).\n4 Wdc, elements of W, can be learned through stochastic gradient descent using equations (4) - (7):\nWdc = Wdc \u2212 \u03b7gnew, (4)\ngnew = (1\u2212m)\u00d7 g +m\u00d7 gold, (5)\ng = \u2202L\n\u2202H1 c \u2202H1 c \u2202Wdc = \u2202L \u2202H1 c FdMbldc \u2202NR(Wdc) \u2202Wdc , (6)\n\u2202NR(Wdc)\n\u2202Wdc = NR(Wdc)[1\u2212NR(Wdc)], (7)\nwhere d \u2286 [1, D], c \u2286 [1, C], \u03b7 is the learning rate, m is the momentum, g is the gradient computed in backward pass, gold is the gradient value in the previous mini-batch, and gnew is the new gradient for the current min-batch. L is the cost function and \u2202L\u2202H1c can be computed by the standard back propagation equations for neural networks [31]. The learned filters with restrictions are illustrated in Fig. 2.(d), which are band limited, ordered by frequency and have different filter shapes in different channels.\nFollowing the cepstral analysis steps we can generate a new kind of Cep features using the filter bank generated from FBNN, which is defined as deep neural networks filter bank cepstral coefficients (DNN-FBCC). The new feature can integrate the advantages of Cep feature and the discrimination ability of DNN model, which are specially suitable for the task of spoofing detection."}, {"heading": "III. EXPERIMENTAL RESULTS AND DISCUSSIONS", "text": ""}, {"heading": "A. Database and Data Preparation", "text": "The performance of spoofing detection using the DNN-FBCC feature is evaluated on the ASVspoof 2015 database [17]. As shown in TABLE I, the database includes three sub datasets without target speaker overlap: the training set, the development set and the evaluation set. We used the training set for FBNN and human/spoof classifier training. The development set and evaluation set were used for testing.\nTraining set and development set are attacked by the same five spoofing methods, where S1, S2 and S5 belong to VC method and S3, S4 belong to SS method. Regarding the evaluation set, besides the five known spoofing methods, there are another five unknown methods, where S6-S9 are VC methods and S10 is an SS method.\nThe speech signals were segmented into frames with 20ms length and 10ms step size. Pre-emphasis and a hamming window were applied on the frames before the spectrum computation. Paper [16] showed that all the frames of speech are useful for spoofing detection, so we did not apply any voice activity detection method."}, {"heading": "B. FBNN Training", "text": "The FBNN described in Section II was built and trained with computational network toolkit (CNTK) [32]. The output layer has five nodes, the first one is for human speech and the other four are for five known spoofing methods (S3 and S4 use the same label). The number of nodes in hidden layer H2 is set as 100, the cross entropy function was selected as the cost function L and the training epoch was chosen as 30. The mini-batch size was set as 128. W was initialized with uniform random numbers. \u03b7 and m are set as 0.1 and 0 in the first epoch, 1 and 0.9 in the other epochs.\nSome experimental results published in paper [33] and [16], show that the high frequency spectrum of speech is more effective for synthetic detection. In order to investigate the affect of different band-limiting and shape restrictions to the learned filter banks, we use four different manually designed filter banks to generate Mbl: the linear frequency triangular filter bank (TFB) with 20 channels, the linear frequency rectangular filter bank (RFB) with 20 channels, the equivalent rectangular bandwidth (ERB) space Gammatone filter bank (GFB) with 128 channels, and the inverted ERB space Gammatone filter bank (IGFB) with 128 channels, according to the recommended in paper [34] [16].\nCorrespondingly, the number of nodes in the first hidden layer were set as 20, 20, 128, 128 for TFB, RFB, GFB and IGFB, respectively. When using TFB and RFB, the dimension of the input power spectrum is 257. The feature dimension is 513 when using GFB and IGFB.\n5 1 257 1 0 Am pl it ud e FFT bin\n(a)\n1 257 0\n1\nFFT bin\nAm pl\nit ud\ne\n(b)\n1 257 0\n1\nFFT bin\nAm pl it ud e\n(c)\n1 257\n1\n0 FFT bin\nAm pl it ud e\n(d)\n1 513 0\n1\nFFT bin\nAm pl\nit ud\ne\n(e)\n1 513 0\n1\nFFT bin\nAm pl it\nud e\n(f)\n1 513 0\n1\nFFT bin\nAm pl it ud e\n(g)\n1 513 0\n1\nFFT bin\nAm pl it ud e\n(h)\nFig. 4. Filter banks used for generated Mbl and corresponding learned filter banks, (a) TFB, (b) DNN-TFB, (c) RFB, (d) DNN-RFB, (e) GFB, (f) DNN-GFB, (g) IGFB and (h) DNN-IGFB.\nTFB and RFB equally distribute on the whole frequency region (Fig.4(b) and Fig.4(d)). GFB which has been successfully used in audio recognition [34][35], has denser spacing in the low-frequency region (Fig.4(e)) and IGFB gives higher emphasis to the higher frequency region(Fig.4(f)).\nAs shown in Fig.4, after training we can get the DNN-triangle filter bank (DNN-TFB), the DNN-rectangle filter bank (DNNRFB), the DNN-Gammatone filter bank (DNN-GFB) and the DNN-inverted Gammatone filter bank(DNN-IGFB). The learned filters have flexible shapes in different frequency bands which can capture the difference between human and spoofed speech more effectively."}, {"heading": "C. Classifier", "text": "In designing the classifier, we train two separated GMMs with 512 mixtures to model natural and spoofed speech, respectively. Log likelihood ratio is used as criterion of assessment, which is defined as:\nML (X) = 1\nT T\u2211 i=1 {logP(Xi|\u03bbhuman)\u2212 logP(Xi|\u03bbspoof)} , (8)\nwhere X denotes feature vectors with T frames, \u03bbhuman and \u03bbspoof are the GMM parameters of human and spoof model, respectively."}, {"heading": "D. Results and Discussions", "text": "We compare the spoofing detection performance between four manually designed Cep features and four DNN-FBCC features.\n6\nAs shown in Table II, manually designed Cep features: LFCC, RFCC (linear frequency rectangle filter bank cepstral coefficients), GFCC (ERB space Gammatone filter bank cepstral coefficients) and IGFCC (inverted ERB space Gammatone filter bank cepstral coefficients) are generated by manually designed filter bank TFB, RFB, GFB and IGFB described in Section III-B. Four DNN-FBCC features, DNN-LFCC, DNN-RFCC, DNN-GFCC and DNN-IGFCC are generated by learned filter banks DNN-TFB, DNN-RFB, DNN-GFB and DNN-IGFB, respectively. The number of coefficients M of all the eight features are set as 20 (including the 0\u2019th coefficient).\nInspired by the work in [16], we use \u2206 and \u22062 (first- and second-order frame-to-frame difference) coefficients to train the GMM-ML classifier. Equal error rate (EER) is used for measuring spoofing detection performance. The average EERs of different spoofing methods on development and evaluation set are shown in TABLE III.\nWe first conduct experiments on four manually designed Cep features, among which, IGFCC(\u2206\u22062) performs best on detecting both known and unknown attacks and GFCC(\u2206\u22062) works worst. It can be inferred that the filter banks, which give higher emphasis to the higher frequency region, are more suitable for the spoofing detection task. This is inline with the finding in paper [33].\nThen we investigate the performance of four DNN-FBCC features. DNN-RFCC(\u2206\u22062) performs best on detecting known attacks, but works worse on unknown spoofing attacks. This phenomena shows that the shape restrictions applied on FBNN affect the performance of spoofing detection. When a rectangle filter is selected (RFB, Fig.4(d)), there are no special shape restrictions on the learned filters, and this make the learned DNN-RFCC(\u2206\u22062) over-fits the trained/known attacks. When a Gammatone filter is chosen (IGFB, Fig.4(f)), the shape restriction can make the performance of DNN-IGFCC(\u2206\u22062) better than the corresponding IGFCC(\u2206\u22062) on both known and unknown attacks.\nIn general, among the eight investigated Cep features, DNN-IGFCC(\u2206\u22062), generated by the learned filter bank which has denser spacing in the high frequency region and has the Gammatone shape restriction, performs best on ASVspoof 2015 data base and gets the best average accuracy, overall.\nWe also compare the DNN-FBCC feature with other three data driven features which have been successfully used in speaker verification and speech recognition task: LDA filter bank feature (LDA-FB) [23], log-normalized learned Mel-scale filter bank feature (l-LMFB) [24] and DNN bottle neck feature (DNN-BN) [21].\nLDA-FB is generated by a 20 channels LDA filter bank which is learned by power spectrum feature with 257 dimension. DNN-BN is produced by the middle hidden layer of a five hidden layers DNN, and the nodes number of hidden layers are set as 2048, 2048, 60, 2048 and 2048, respectively. The DNN is trained by a block of 11 frames of 60 MFCC(static+\u2206\u22062) features.\nl-LMFB is generated by a neural network introduced by [24] which uses a 20 channel mel-scale rectangle filter bank to generate Mbl and chooses exponential function ex as a non-negative restriction function.\nFrom the results shown in TABLE III we observe that the simple data driven filter bank feature LDA-FB is not suitable for the spoofing detection task. Static DNN-BN, DNN-BN(\u2206\u22062), static l-LMFB and l-LMFB(\u2206\u22062) are all perform worse than the DNN-IGFCC(\u2206\u22062) feature.\nTo sum up the learned filter banks produced by FBNN using suitable band limiting and shape restrictions can improve the spoofing detection accuracy over the existing manually designed filter banks by learning flexible and effective filters. DNN-FBCC, especially DNN-IGFCC(\u2206\u22062), can largely increase the detection accuracy on unknown spoofing attacks."}, {"heading": "IV. CONCLUSIONS", "text": "In this paper, we introduced a filter bank neural network with two hidden layers for spoofing detection. During training, a non-negative restriction function and a band-limiting mask matrix were applied on the weight matrix between the input layer\n7 and the first hidden layer. These restrictions made the learned weight matrix non-negative, band-limited, shape restriction and ordered by frequency. The weight matrix can be used as a filter bank for cepstral analysis. Experimental results show that cepstral coefficients (Cep) features produced by the learned filter banks were able to distinguish the natural and synthetic speech more precisely and robustly than the manually designed Cep features and general DNN features."}], "references": [{"title": "Synthetic speech detection using temporal modulation feature", "author": ["Z. Wu", "X. Xiao", "E.S. Chng", "H. Li"], "venue": "Processing of IEEE International Conference on Acoustics, Speech and Signal (ICASSP), pp. 7234\u20137238, 2013.", "citeRegEx": "1", "shortCiteRegEx": null, "year": 2013}, {"title": "Conditional restricted boltzmann machine for voice conversion", "author": ["Z. Wu", "E.S. Chng", "H. Li"], "venue": "Processing of IEEE China Summit & International Conference on Signal and Information Processing (ChinaSIP), pp. 104\u2013108, 2013.", "citeRegEx": "2", "shortCiteRegEx": null, "year": 2013}, {"title": "Voice conversion using dynamic kernel partial least squares regression", "author": ["E. Helander", "H. Sil\u00e9n", "T. Virtanen", "M. Gabbouj"], "venue": "IEEE Transactions on Audio, Speech, and Language Processing, vol. 20, no. 3, pp. 806\u2013817, 2012.", "citeRegEx": "3", "shortCiteRegEx": null, "year": 2012}, {"title": "Unit selection in a concatenative speech synthesis system using a large speech database", "author": ["A.J. Hunt", "A.W. Black"], "venue": "Processing of IEEE International Conference on Acoustics, Speech, and Signal Processing (ICASSP), vol. 1, pp. 373\u2013376, 1996.", "citeRegEx": "4", "shortCiteRegEx": null, "year": 1996}, {"title": "Statistical parametric speech synthesis using deep neural networks", "author": ["H. Ze", "A. Senior", "M. Schuster"], "venue": "Processing of IEEE International Conference on Acoustics, Speech and Signal Processing (ICASSP), pp. 7962\u20137966, 2013.", "citeRegEx": "5", "shortCiteRegEx": null, "year": 2013}, {"title": "Joint speaker verification and antispoofing in the-vector space", "author": ["A. Sizov", "E. Khoury", "T. Kinnunen", "Z. Wu", "S. Marcel"], "venue": "IEEE Transactions on Information Forensics and Security, vol. 10, no. 4, pp. 821\u2013832, 2015.", "citeRegEx": "6", "shortCiteRegEx": null, "year": 2015}, {"title": "Spoofing detection from a feature representation perspective", "author": ["X. Tian", "Z. Wu", "X. Xiao", "E.S. Chng", "H. Li"], "venue": "Processing of IEEE International Conference on Acoustics, Speech, and Signal Processing (ICASSP), 2016.", "citeRegEx": "7", "shortCiteRegEx": null, "year": 2016}, {"title": "Toward a universal synthetic speech spoofing detection using phase information", "author": ["J. Sanchez", "I. Saratxaga", "I. Hernaez", "E. Navas", "D. Erro", "T. Raitio"], "venue": "IEEE Transactions on Information Forensics and Security, vol. 10, no. 4, pp. 810\u2013820, 2015.", "citeRegEx": "8", "shortCiteRegEx": null, "year": 2015}, {"title": "Vulnerability of speaker verification systems against voice conversion spoofing attacks: The case of telephone speech", "author": ["T. Kinnunen", "Z.-Z. Wu", "K.A. Lee", "F. Sedlak", "E.S. Chng", "H. Li"], "venue": "Processing of IEEE International Conference on Acoustics, Speech and Signal Processing (ICASSP), pp. 4401\u2013 4404, 2012.", "citeRegEx": "9", "shortCiteRegEx": null, "year": 2012}, {"title": "Evaluation of speaker verification security and detection of hmm-based synthetic speech", "author": ["P.L. De Leon", "M. Pucher", "J. Yamagishi", "I. Hernaez", "I. Saratxaga"], "venue": "IEEE Transactions on Audio, Speech, and Language Processing, vol. 20, no. 8, pp. 2280\u20132290, 2012.", "citeRegEx": "10", "shortCiteRegEx": null, "year": 2012}, {"title": "Vulnerability in speaker verification-a study of technical impostor techniques", "author": ["J. Lindberg", "M. Blomberg"], "venue": "Eurospeech, vol. 99, pp. 1211\u20131214, 1999.", "citeRegEx": "11", "shortCiteRegEx": null, "year": 1999}, {"title": "Integrated spoofing countermeasures and automatic speaker verification: an evaluation on asvspoof 2015", "author": ["M. Sahidullah", "H. Delgado", "M. Todisco", "H. Yu", "T. Kinnunen", "N. Evans", "Z.-H. Tan"], "venue": "INTERSPEECH, 2016.", "citeRegEx": "12", "shortCiteRegEx": null, "year": 2016}, {"title": "Detecting converted speech and natural speech for anti-spoofing attack in speaker recognition", "author": ["Z. Wu", "C.E. Siong", "H. Li"], "venue": "INTERSPEECH, pp. 1700\u20131703, 2012.", "citeRegEx": "13", "shortCiteRegEx": null, "year": 2012}, {"title": "Toward a universal synthetic speech spoofing detection using phase information", "author": ["J. Sanchez", "I. Saratxaga", "I. Hernaez", "E. Navas", "D. Erro", "T. Raitio"], "venue": "IEEE Transactions on Information Forensics and Security, vol. 10, no. 4, pp. 810\u2013820, 2015.", "citeRegEx": "14", "shortCiteRegEx": null, "year": 2015}, {"title": "Toward a universal synthetic speech spoofing detection using phase information", "author": ["J. Sanchez", "I. Saratxaga", "I. Hernez", "E. Navas", "D. Erro", "T. Raitio"], "venue": "IEEE Transactions on Information Forensics and Security, vol. 10, pp. 810\u2013820, April 2015.", "citeRegEx": "15", "shortCiteRegEx": null, "year": 2015}, {"title": "A comparison of features for synthetic speech detection", "author": ["M. Sahidullah", "T. Kinnunen", "C. Hanil\u00e7i"], "venue": "Sixteenth Annual Conference of the International Speech Communication Association, 2015.", "citeRegEx": "16", "shortCiteRegEx": null, "year": 2015}, {"title": "Asvspoof 2015: the first automatic speaker verification spoofing and countermeasures challenge", "author": ["Z. Wu", "T. Kinnunen", "N. Evans", "J. Yamagishi", "C. Hanil\u00e7i", "M. Sahidullah", "A. Sizov"], "venue": "Training, vol. 10, no. 15, p. 3750, 2015.", "citeRegEx": "17", "shortCiteRegEx": null, "year": 2015}, {"title": "Spoofing speech detection using high dimensional magnitude and phase features: The ntu approach for asvspoof 2015 challenge", "author": ["X. Xiao", "X. Tian", "S. Du", "H. Xu", "E.S. Chng", "H. Li"], "venue": "Sixteenth Annual Conference of the International Speech Communication Association, 2015.", "citeRegEx": "18", "shortCiteRegEx": null, "year": 2015}, {"title": "Spoofing detection with dnn and one-class svm for the asvspoof 2015 challenge", "author": ["J. Villalba", "A. Miguel", "A. Ortega", "E. Lleida"], "venue": "Sixteenth Annual Conference of the International Speech Communication Association, 2015.", "citeRegEx": "19", "shortCiteRegEx": null, "year": 2015}, {"title": "Robust deep feature for spoofing detection-the sjtu system for asvspoof 2015 challenge", "author": ["N. Chen", "Y. Qian", "H. Dinkel", "B. Chen", "K. Yu"], "venue": "Sixteenth Annual Conference of the International Speech Communication Association, 2015.", "citeRegEx": "20", "shortCiteRegEx": null, "year": 2015}, {"title": "Improved bottleneck features using pretrained deep neural networks", "author": ["D. Yu", "M.L. Seltzer"], "venue": "Processing of IEEE International Conference on INTERSPEECH, vol. 237, p. 240, 2011.", "citeRegEx": "21", "shortCiteRegEx": null, "year": 2011}, {"title": "Auto-encoder bottleneck features using deep belief networks", "author": ["T.N. Sainath", "B. Kingsbury", "B. Ramabhadran"], "venue": "Processing of IEEE International Conference on Acoustics, Speech and Signal Processing (ICASSP), pp. 4153\u20134156, 2012.", "citeRegEx": "22", "shortCiteRegEx": null, "year": 2012}, {"title": "Data driven design of filter bank for speech recognition", "author": ["L. Burget", "H. He\u0159mansk\u1ef3"], "venue": "International Conference on Text, Speech and Dialogue, pp. 299\u2013304, Springer, 2001.", "citeRegEx": "23", "shortCiteRegEx": null, "year": 2001}, {"title": "Learning filter banks within a deep neural network framework", "author": ["T.N. Sainath", "B. Kingsbury", "A.-r. Mohamed", "B. Ramabhadran"], "venue": "Automatic Speech Recognition and Understanding (ASRU), 2013 IEEE Workshop on, pp. 297\u2013302, IEEE, 2013.", "citeRegEx": "24", "shortCiteRegEx": null, "year": 2013}, {"title": "Deep neural networks for acoustic modeling in speech recognition: The shared views of four research groups", "author": ["G. Hinton", "L. Deng", "D. Yu", "G.E. Dahl", "A.-r. Mohamed", "N. Jaitly", "A. Senior", "V. Vanhoucke", "P. Nguyen", "T.N. Sainath"], "venue": "IEEE Transactions on Signal Processing Magazine, vol. 29, no. 6, pp. 82\u201397, 2012.", "citeRegEx": "25", "shortCiteRegEx": null, "year": 2012}, {"title": "Context-dependent pre-trained deep neural networks for large-vocabulary speech recognition", "author": ["G.E. Dahl", "D. Yu", "L. Deng", "A. Acero"], "venue": "IEEE Transactions on Audio, Speech, and Language Processing, vol. 20, no. 1, pp. 30\u201342, 2012.", "citeRegEx": "26", "shortCiteRegEx": null, "year": 2012}, {"title": "Deep neural networks for small footprint text-dependent speaker verification", "author": ["E. Variani", "X. Lei", "E. McDermott", "I. Lopez Moreno", "J. Gonzalez-Dominguez"], "venue": "Processing of IEEE International Conference on Acoustics, Speech and Signal Processing (ICASSP), pp. 4052\u20134056, 2014.", "citeRegEx": "27", "shortCiteRegEx": null, "year": 2014}, {"title": "Unsupervised feature learning for audio classification using convolutional deep belief networks", "author": ["H. Lee", "P. Pham", "Y. Largman", "A.Y. Ng"], "venue": "Advances in neural information processing systems, pp. 1096\u20131104, 2009.", "citeRegEx": "28", "shortCiteRegEx": null, "year": 2009}, {"title": "An experimental study on speech enhancement based on deep neural networks", "author": ["Y. Xu", "J. Du", "L.-R. Dai", "C.-H. Lee"], "venue": "IEEE Transactions on Signal Processing Letters, vol. 21, no. 1, pp. 65\u201368, 2014.", "citeRegEx": "29", "shortCiteRegEx": null, "year": 2014}, {"title": "Neural network-based adaptive noise cancellation for enhancement of speech auditory brainstem responses", "author": ["S. Gholami-Boroujeny", "A. Fallatah", "B.P. Heffernan", "H.R. Dajani"], "venue": "Signal, Image and Video Processing, vol. 10, no. 2, pp. 389\u2013395, 2016.", "citeRegEx": "30", "shortCiteRegEx": null, "year": 2016}, {"title": "Learning representations by back-propagating errors", "author": ["D.E. Rumelhart", "G.E. Hinton", "R.J. Williams"], "venue": "Cognitive modeling, vol. 5, no. 3, p. 1, 1988.", "citeRegEx": "31", "shortCiteRegEx": null, "year": 1988}, {"title": "An introduction to computational networks and the computational network toolkit", "author": ["D. Yu", "A. Eversole", "M. Seltzer", "K. Yao", "Z. Huang", "B. Guenter", "O. Kuchaiev", "Y. Zhang", "F. Seide", "H. Wang"], "venue": "tech. rep., Tech. Rep. MSR, Microsoft Research, 2014, http://codebox/cntk, 2014.", "citeRegEx": "32", "shortCiteRegEx": null, "year": 2014}, {"title": "Effect of multi-condition training and speech enhancement methods on spoofing detection", "author": ["H. Yu", "A. Sarkar", "D.A.L. Thomsen", "Z.-H. Tan", "Z. Ma", "J. Guo"], "venue": "2016 First International Workshop on Sensing, Processing and Learning for Intelligent Machines (SPLINE), pp. 1\u20135, IEEE, 2016. 8", "citeRegEx": "33", "shortCiteRegEx": null, "year": 2016}, {"title": "Gammatone wavelet cepstral coefficients for robust speech recognition", "author": ["A. Adiga", "M. Magimai", "C.S. Seelamantula"], "venue": "TENCON 2013-2013 IEEE Region 10 Conference (31194), pp. 1\u20134, 2013.", "citeRegEx": "34", "shortCiteRegEx": null, "year": 2013}, {"title": "Gammatone cepstral coefficients: biologically inspired features for non-speech audio classification", "author": ["X. Valero", "F. Alias"], "venue": "IEEE Transactions on Multimedia, vol. 14, no. 6, pp. 1684\u20131689, 2012.", "citeRegEx": "35", "shortCiteRegEx": null, "year": 2012}], "referenceMentions": [{"referenceID": 0, "context": "INTRODUCTION AS a low-cost and flexible biometric solution to person authentication, automatic speaker verification (ASV) has been used in many telephone or network access control systems, such as telephone banking [1].", "startOffset": 215, "endOffset": 218}, {"referenceID": 1, "context": "Recently, with the improvement of automatic speech generation methods, speech produced by voice conversion (VC) [2][3] and speech synthesis (SS) [4][5] techniques has been used to attack ASV systems.", "startOffset": 112, "endOffset": 115}, {"referenceID": 2, "context": "Recently, with the improvement of automatic speech generation methods, speech produced by voice conversion (VC) [2][3] and speech synthesis (SS) [4][5] techniques has been used to attack ASV systems.", "startOffset": 115, "endOffset": 118}, {"referenceID": 3, "context": "Recently, with the improvement of automatic speech generation methods, speech produced by voice conversion (VC) [2][3] and speech synthesis (SS) [4][5] techniques has been used to attack ASV systems.", "startOffset": 145, "endOffset": 148}, {"referenceID": 4, "context": "Recently, with the improvement of automatic speech generation methods, speech produced by voice conversion (VC) [2][3] and speech synthesis (SS) [4][5] techniques has been used to attack ASV systems.", "startOffset": 148, "endOffset": 151}, {"referenceID": 5, "context": "Over the past few years, much research has been devoted to protect ASV systems against spoofing attack [6][7][8].", "startOffset": 103, "endOffset": 106}, {"referenceID": 6, "context": "Over the past few years, much research has been devoted to protect ASV systems against spoofing attack [6][7][8].", "startOffset": 106, "endOffset": 109}, {"referenceID": 7, "context": "Over the past few years, much research has been devoted to protect ASV systems against spoofing attack [6][7][8].", "startOffset": 109, "endOffset": 112}, {"referenceID": 8, "context": "Unfortunately, research has shown that all the existing ASV systems are vulnerable to spoofing attacks [9][10][11].", "startOffset": 103, "endOffset": 106}, {"referenceID": 9, "context": "Unfortunately, research has shown that all the existing ASV systems are vulnerable to spoofing attacks [9][10][11].", "startOffset": 106, "endOffset": 110}, {"referenceID": 10, "context": "Unfortunately, research has shown that all the existing ASV systems are vulnerable to spoofing attacks [9][10][11].", "startOffset": 110, "endOffset": 114}, {"referenceID": 11, "context": "The other more popular strategy is to build a separated spoofing detection system which only focuses on distinguishing between natural and synthetic speech [12].", "startOffset": 156, "endOffset": 160}, {"referenceID": 5, "context": "Because of the advantage of being easily incorporated into existing ASV systems, spoofing detection has become an important research topic in anti-spoofing [6][10][13][14].", "startOffset": 156, "endOffset": 159}, {"referenceID": 9, "context": "Because of the advantage of being easily incorporated into existing ASV systems, spoofing detection has become an important research topic in anti-spoofing [6][10][13][14].", "startOffset": 159, "endOffset": 163}, {"referenceID": 12, "context": "Because of the advantage of being easily incorporated into existing ASV systems, spoofing detection has become an important research topic in anti-spoofing [6][10][13][14].", "startOffset": 163, "endOffset": 167}, {"referenceID": 13, "context": "Because of the advantage of being easily incorporated into existing ASV systems, spoofing detection has become an important research topic in anti-spoofing [6][10][13][14].", "startOffset": 167, "endOffset": 171}, {"referenceID": 14, "context": "In [15], relative phase shift (RPS) and Mel-frequency cepstral coefficients (MFCC) were used to detect SS attacks.", "startOffset": 3, "endOffset": 7}, {"referenceID": 0, "context": "A fusion system combining MFCC and group delay cepstral coefficients (GDCC) was applied to resist VC spoofing in [1].", "startOffset": 113, "endOffset": 116}, {"referenceID": 15, "context": "Paper [16] compared the spoofing detection performance of 11 different features on the ASVspoof 2015 database [17].", "startOffset": 6, "endOffset": 10}, {"referenceID": 16, "context": "Paper [16] compared the spoofing detection performance of 11 different features on the ASVspoof 2015 database [17].", "startOffset": 110, "endOffset": 114}, {"referenceID": 17, "context": "In [18][19][20], spoofing detection systems based on deep neural networks (DNNs) were proposed and tested, where a DNN was used as a classifier or feature extractor.", "startOffset": 3, "endOffset": 7}, {"referenceID": 18, "context": "In [18][19][20], spoofing detection systems based on deep neural networks (DNNs) were proposed and tested, where a DNN was used as a classifier or feature extractor.", "startOffset": 7, "endOffset": 11}, {"referenceID": 19, "context": "In [18][19][20], spoofing detection systems based on deep neural networks (DNNs) were proposed and tested, where a DNN was used as a classifier or feature extractor.", "startOffset": 11, "endOffset": 15}, {"referenceID": 18, "context": ", Gaussian mixture model (GMM) or support vector machine (SVM) [19][21][22].", "startOffset": 63, "endOffset": 67}, {"referenceID": 20, "context": ", Gaussian mixture model (GMM) or support vector machine (SVM) [19][21][22].", "startOffset": 67, "endOffset": 71}, {"referenceID": 21, "context": ", Gaussian mixture model (GMM) or support vector machine (SVM) [19][21][22].", "startOffset": 71, "endOffset": 75}, {"referenceID": 22, "context": "Some filter bank learning methods such as LDA (Linear discriminant analysis) filter learning [23] and log Mel-scale filters learning [24] have been introduced in the literatures.", "startOffset": 93, "endOffset": 97}, {"referenceID": 23, "context": "Some filter bank learning methods such as LDA (Linear discriminant analysis) filter learning [23] and log Mel-scale filters learning [24] have been introduced in the literatures.", "startOffset": 133, "endOffset": 137}, {"referenceID": 16, "context": "Experimental results show that the GMM-ML classifier based on DNN-FBCC feature outperforms the LFCC feature and DNN feature on the ASVspoof 2015 data base [17].", "startOffset": 155, "endOffset": 159}, {"referenceID": 24, "context": "FILTER BANK NEURAL NETWORKS As a hot research area, deep neural networks have been successfully used in many speech processing tasks such as speech recognition [25][26], speaker verification [27][28] and speech enhancement [29][30].", "startOffset": 160, "endOffset": 164}, {"referenceID": 25, "context": "FILTER BANK NEURAL NETWORKS As a hot research area, deep neural networks have been successfully used in many speech processing tasks such as speech recognition [25][26], speaker verification [27][28] and speech enhancement [29][30].", "startOffset": 164, "endOffset": 168}, {"referenceID": 26, "context": "FILTER BANK NEURAL NETWORKS As a hot research area, deep neural networks have been successfully used in many speech processing tasks such as speech recognition [25][26], speaker verification [27][28] and speech enhancement [29][30].", "startOffset": 191, "endOffset": 195}, {"referenceID": 27, "context": "FILTER BANK NEURAL NETWORKS As a hot research area, deep neural networks have been successfully used in many speech processing tasks such as speech recognition [25][26], speaker verification [27][28] and speech enhancement [29][30].", "startOffset": 195, "endOffset": 199}, {"referenceID": 28, "context": "FILTER BANK NEURAL NETWORKS As a hot research area, deep neural networks have been successfully used in many speech processing tasks such as speech recognition [25][26], speaker verification [27][28] and speech enhancement [29][30].", "startOffset": 223, "endOffset": 227}, {"referenceID": 29, "context": "FILTER BANK NEURAL NETWORKS As a hot research area, deep neural networks have been successfully used in many speech processing tasks such as speech recognition [25][26], speaker verification [27][28] and speech enhancement [29][30].", "startOffset": 227, "endOffset": 231}, {"referenceID": 30, "context": "L is the cost function and \u2202L \u2202H1c can be computed by the standard back propagation equations for neural networks [31].", "startOffset": 114, "endOffset": 118}, {"referenceID": 16, "context": "Database and Data Preparation The performance of spoofing detection using the DNN-FBCC feature is evaluated on the ASVspoof 2015 database [17].", "startOffset": 138, "endOffset": 142}, {"referenceID": 15, "context": "Paper [16] showed that all the frames of speech are useful for spoofing detection, so we did not apply any voice activity detection method.", "startOffset": 6, "endOffset": 10}, {"referenceID": 31, "context": "FBNN Training The FBNN described in Section II was built and trained with computational network toolkit (CNTK) [32].", "startOffset": 111, "endOffset": 115}, {"referenceID": 32, "context": "Some experimental results published in paper [33] and [16], show that the high frequency spectrum of speech is more effective for synthetic detection.", "startOffset": 45, "endOffset": 49}, {"referenceID": 15, "context": "Some experimental results published in paper [33] and [16], show that the high frequency spectrum of speech is more effective for synthetic detection.", "startOffset": 54, "endOffset": 58}, {"referenceID": 33, "context": "In order to investigate the affect of different band-limiting and shape restrictions to the learned filter banks, we use four different manually designed filter banks to generate Mbl: the linear frequency triangular filter bank (TFB) with 20 channels, the linear frequency rectangular filter bank (RFB) with 20 channels, the equivalent rectangular bandwidth (ERB) space Gammatone filter bank (GFB) with 128 channels, and the inverted ERB space Gammatone filter bank (IGFB) with 128 channels, according to the recommended in paper [34] [16].", "startOffset": 530, "endOffset": 534}, {"referenceID": 15, "context": "In order to investigate the affect of different band-limiting and shape restrictions to the learned filter banks, we use four different manually designed filter banks to generate Mbl: the linear frequency triangular filter bank (TFB) with 20 channels, the linear frequency rectangular filter bank (RFB) with 20 channels, the equivalent rectangular bandwidth (ERB) space Gammatone filter bank (GFB) with 128 channels, and the inverted ERB space Gammatone filter bank (IGFB) with 128 channels, according to the recommended in paper [34] [16].", "startOffset": 535, "endOffset": 539}, {"referenceID": 33, "context": "GFB which has been successfully used in audio recognition [34][35], has denser spacing in the low-frequency region (Fig.", "startOffset": 58, "endOffset": 62}, {"referenceID": 34, "context": "GFB which has been successfully used in audio recognition [34][35], has denser spacing in the low-frequency region (Fig.", "startOffset": 62, "endOffset": 66}, {"referenceID": 15, "context": "Inspired by the work in [16], we use \u2206 and \u2206 (first- and second-order frame-to-frame difference) coefficients to train the GMM-ML classifier.", "startOffset": 24, "endOffset": 28}, {"referenceID": 32, "context": "This is inline with the finding in paper [33].", "startOffset": 41, "endOffset": 45}, {"referenceID": 22, "context": "We also compare the DNN-FBCC feature with other three data driven features which have been successfully used in speaker verification and speech recognition task: LDA filter bank feature (LDA-FB) [23], log-normalized learned Mel-scale filter bank feature (l-LMFB) [24] and DNN bottle neck feature (DNN-BN) [21].", "startOffset": 195, "endOffset": 199}, {"referenceID": 23, "context": "We also compare the DNN-FBCC feature with other three data driven features which have been successfully used in speaker verification and speech recognition task: LDA filter bank feature (LDA-FB) [23], log-normalized learned Mel-scale filter bank feature (l-LMFB) [24] and DNN bottle neck feature (DNN-BN) [21].", "startOffset": 263, "endOffset": 267}, {"referenceID": 20, "context": "We also compare the DNN-FBCC feature with other three data driven features which have been successfully used in speaker verification and speech recognition task: LDA filter bank feature (LDA-FB) [23], log-normalized learned Mel-scale filter bank feature (l-LMFB) [24] and DNN bottle neck feature (DNN-BN) [21].", "startOffset": 305, "endOffset": 309}, {"referenceID": 23, "context": "l-LMFB is generated by a neural network introduced by [24] which uses a 20 channel mel-scale rectangle filter bank to generate Mbl and chooses exponential function e as a non-negative restriction function.", "startOffset": 54, "endOffset": 58}], "year": 2017, "abstractText": "With the development of speech synthesis techniques, automatic speaker verification systems face the serious challenge of spoofing attack. In order to improve the reliability of speaker verification systems, we develop a new filter bank based cepstral feature, deep neural network filter bank cepstral coefficients (DNN-FBCC), to distinguish between natural and spoofed speech. The deep neural network filter bank is automatically generated by training a filter bank neural network (FBNN) using natural and synthetic speech. By adding restrictions on the training rules, the learned weight matrix of FBNN is band-limited and sorted by frequency, similar to the normal filter bank. Unlike the manually designed filter bank, the learned filter bank has different filter shapes in different channels, which can capture the differences between natural and synthetic speech more effectively. The experimental results on the ASVspoof 2015 database show that the Gaussian mixture model maximum-likelihood (GMM-ML) classifier trained by the new feature performs better than the state-of-the-art linear frequency cepstral coefficients (LFCC) based classifier, especially on detecting unknown attacks. Index Terms speaker verification, spoofing detection, DNN filter bank cepstral coefficients, filter bank neural network.", "creator": "LaTeX with hyperref package"}}}