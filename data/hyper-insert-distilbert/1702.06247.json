{"id": "1702.06247", "review": {"conference": "arxiv", "VERSION": "v1", "DATE_OF_SUBMISSION": "21-Feb-2017", "title": "SAR: Semantic Analysis for Recommendation", "abstract": "recommendation system reporting is a typical common emotion demand vector in daily life and matrix decision completion is a widely adopted technique for this task. however, with most quantitative matrix completion review methods nearly lack semantic interpretation programs and usually analyses result both in simply weak - motivated semantic recommendations. to this end, this paper proposes combining a { \\ bf s } default emantic { \\ au bf a } nalysis approach for { \\ bf r } ecommendation training systems \\ ff textbf { ( sar ) }, upon which applies a two - level hierarchical neural generative process, that assigns semantic properties requirements and categories for user and program item. sar modules learns semantic representations of both users / agent items could merely learn from user interface ratings conditional on available items, which offers a new path relevant to analyzing recommendation obtained by semantic grammar matching approaches with the highly learned sensory representations. extensive experiments demonstrate sar functionality outperforms whatever other simple state - conditions of - necessity the - net art baselines substantially.", "histories": [["v1", "Tue, 21 Feb 2017 03:09:10 GMT  (738kb,D)", "http://arxiv.org/abs/1702.06247v1", null], ["v2", "Tue, 13 Jun 2017 02:20:47 GMT  (731kb,D)", "http://arxiv.org/abs/1702.06247v2", null]], "reviews": [], "SUBJECTS": "cs.IR cs.LG", "authors": ["han xiao", "minlie huang", "xiaoyan zhu"], "accepted": false, "id": "1702.06247"}, "pdf": {"name": "1702.06247.pdf", "metadata": {"source": "CRF", "title": "SAR: A Semantic Analysis Approach for Recommendation", "authors": ["Han Xiao", "Minlie Huang", "Xiaoyan Zhu"], "emails": ["bookman@vip.163.com;", "aihuang@tsinghua.edu.cn", "zxy-dcs@tsinghua.edu.cn"], "sections": [{"heading": "1 Introduction", "text": "Recommendation systems are a common need in daily life and can be seen in many applications such as information retrieval, question answering, sentiment analysis, and more. Rating matrix is a simple, common mathematical formulation for recommendation systems, whose entry Mu,i indicates the rating of item i made by user u. However, there are many unknown entries in this matrix and the goal of recommendation is to predict the missing values with various techniques. To this end, much efforts have been attempted, such as low-rank based methods [Lee et al., 2016], latent space models [Song and Zhu, 2015], collaborative filtering [Rao et al., 2015], norm constrained methods [Cai and Zhou, 2013], deep learning [Zhang and Chang, 2006], social integration [Liu et al., 2016], etc.\nAmong these models, matrix completion methods, namely matrix factorization, is one of the most popular branches. Specifically, this branch treats the rating matrix with various assumptions such as low-rank. Under some specific assumption, an optimization problem is formulated to complete the rating matrix by supplementing missing values in it. However, due to the lack of underlying semantics, the accuracy of this branch is unsatisfactory in real-world applications. To incorporate more external resources, social information such as relationship between users can be integrated into matrix\ncompletion [Liu et al., 2016]. However, social information is also noisy and only contributes limited improvement on the performance of recommendation.\nIn this paper, we address a novel problem in recommendation: will recommendation be improved by representing users and items with richer latent semantics? Latent semantics is referred to the properties or attributes for a user or an item, which are not directly observable. For instance, a user can be semantically described as (Age:Middle, Gender:Male, Occupation:Engineer, Action Film Fan:No...), while an item can also be represented in the same way, namely (Age Rage:Adult, Favored by Male:Yes, Welcomed by Engineer:Yes, Action Film:Yes, ...). Under this assumption, semantic matching between a user and an item would be more effective than traditional matrix completion algorithms.\nIn comparison to purely real-valued vectorial representations, this semantic representation indicates the property of a user/item in a semantic form, where recommendation can be more easily approached as a semantic matching issue. In other words, if we can simultaneously represent user and item in the same semantic space, the rating inference is simply to compute similarity between the corresponding properties of a user and those of an item. As shown in Figure 1, the semantic properties of the user Gentleman are consistent with those of the movie King Kong, which makes a \u201cto recommend\u201d rating.\nTherefore, we propose a two-level hierarchical generative model SAR to discover and leverage the property semantics merely from the rating matrix. At the first level of our model, we generate some properties such as Action Film, Gender, etc. At the second level of our model, we assign a corresponding category to each property for users and items. Taking the example of movie \u201cQuick and the Dead\u201d, we assign Yes in the Action Film property, Youth in the Loved by Youth or Elder property and so on. In this manner, users/items are semantically organized in a multi-view clustering form as shown in Figure 1, which is a novel unsupervised paradigm. It is worth noting that, the semantics are learned in a latent form, the observable words of which are addressed as future work.\nContributions. This paper proposes a semantic analysis method for recommendation systems (SAR), which applies a two-level hierarchical generative process that globally allocates semantic properties and then locally assign categories in each property for users and items. Experimental results on real-world datasets show that our model consistently outper-\nar X\niv :1\n70 2.\n06 24\n7v 1\n[ cs\n.I R\n] 2\n1 Fe\nb 20\n17\nforms the state-of-the-art baselines."}, {"heading": "2 Related Work", "text": "Existing recommendation methods can be roughly classified into four categories: matrix factorization, neighborhood based method, regression based method and social information integration method. Notably, the first three methods are all based on matrix completion.\nMatrix Factorization is a conventional paradigm for recommendation. This methodology firstly applies a factorization form on the rating matrix M \u2248 UV to get the factorization matrices U ,V and then multiplies UV \u2248 M\u0302 to estimate the missing ratings, where M\u0302 is the estimated rating matrix and U /V is the user/item-related latent factor matrix respectively. Since this branch addresses different assumptions on U and V , there methods fall into four primary subcategories according to the applied assumptions. (1.) Basic matrix factorization generally emphasizes latent factors as being non-negative, such as NMF [Wang and Zhang, 2013], SVP [Meka et al., 2009], MMMF [Rennie and Srebro, 2005], PMF [Mnih and Salakhutdinov, 2012]. (2.) Combination of matrix factorization with neighborhood-based modeling, such as CISMF [Guo et al., 2015]. (3.) Matrix factorization with complex rank assumptions explores the rank properties and generalization ability to enhance the factorization, such as LLORMA [Lee et al., 2016][Ko et al., 2015], R1MP [Wang et al., 2014b], SoftImpute [Rahul Mazumder, 2010], [Ganti et al., 2015], [Zhang et al., 2013], [Kirly et al., 2012]. (4.) Matrix factorization with discrete assumptions treats the\noutput of the rating matrix as discrete values to avoid noise and obtain more interpretations, such as ODMC [Huo et al., 2016].\nNeighborhood Based Method is one of the most classical approaches, assuming that the similar items/users hold similar rating preference. There are three main variants including item-based, user-based and global similarity, surveyed in [Guo et al., 2015] and [Ricci et al., 2011].\nRegression Based Method is formulated as a regression problem, such as regression for graph GRALS [Cai et al., 2011], blind regression [Song, 2016], Riemannian manifold based regression [Vandereycken, 2013], and others [Davenport et al., 2014].\nSocial Information Integration leverages social information to enhance recommendation such as relationship between users, personalized profiles or movies\u2019 attributes. There list some latest researches: SR [Ma, 2013], PRMF [Liu et al., 2016], geo-specific personalization [Liu et al., 2014], social network based [Deng et al., 2014] and other social context integration methods [Wang et al., 2014a]."}, {"heading": "3 Methodology", "text": ""}, {"heading": "3.1 Model Description", "text": "We apply a two-level hierarchical generative process to discover and leverage the property semantics as shown in Figure 2. All the parameters of P(z|u, f),P(y|t, f),P(p\u0302|z, y, f) are learned by the training procedure. Notably, P(f),P(u),P(t) are uniformly\ndistributed, indicating that they can be safely omitted with simple mathematical manipulation.\nGlobally, we generate the rating r for each user-item pair (u, t) from a softmax distribution (Gibbs distribution) where \u03c9u, \u03c9t are user/item-relevant parameters. We denote the sense of each entry in the softmax distribution as preference p whose range is the same as that of all possible ratings, that is, {1, ..., |R|}.\nRegarding the first-level, we generate a property randomly from the uniform distribution P(fn|u, t), because we suppose each property is equally important. For example, we can hardly distinguish which one is more important between Gender and Occupation.\nRegarding the second-level, we generate a user/itemspecific category and a preference strength for each property. Obviously, the meaning of category depends on property, since different categories are semantically differentiated under different properties. For instance, the first category (z = 1) under the property of Gender is Male or Female, while that under the property of Occupation is Student or Teacher. Intuitively, the preference strength p\u0302 depends on the user/item-specific category and the property, because the property semantics make an effect on the ratings.\nBesides, the properties of user and item occurring in the same rating entry should be semantically close. Briefly speaking, the category distribution P(zn|u, fn) and P(yn|t, fn) are supposed to be consistent as required by the semantic matching demand. Taking Figure 1 as example, the Lady favors \u201cTitanic\u201d, which indicates she loves the classic movies while the \u201cTitanic\u201d is a classic one. Therefore, a Laplace prior is applied in P(p\u0302|zn, yn, fn) to formulate this observation as below:\nP(p\u0302|zn, yn, fn, u, t) = \u03c4p\u0302|zn,yn,fne \u2212 |P(zn|u,fn)\u2212P(yn|t,fn)|\u03c3 (1)\nwhere \u03c4p\u0302|zn,yn,fn is tabular model parameters which can be tuned in the learning process and \u03c3 is the hyper-parameter.\nFigure 3 presents the probabilistic graph form of SAR, with which we can compute the joint probability as (2) \u223c (4),\nwhere |F | and |C| is the number of properties and categories, respectively. It is noteworthy that, P(fi|u, t) are uniformly distributed.\nFigure 3 presents two inference tasks of SAR: rating prediction and user/item-specific category distribution computation. As to the rating prediction, it is estimated as the expectation of softmax distribution, as formulated in (5).\nr|u,t . = Er|u,t(r) = \u2211|R| p=1 p\u00d7 ep\u0302\u03c9u\u03c9t\u2211|R|\np=1 e p\u0302\u03c9u\u03c9t\n(5)\nwhere p\u0302 is the corresponding preference strength. As to the category distribution, it is calculated respectively as (6) and (7), which are the direct results of (2) by applying the sum rule. Notice that all the P(fi), P(u) and P(t) are uniform distributions.\nP(zn|u) = \u2211\nt,fn,yn,p\u0302\nP(p\u0302, zn, yn, fn|u, t) (6)\nP(yn|t) = \u2211\nu,fn,zn,p\u0302\nP(p\u0302, zn, yn, fn|u, t) (7)"}, {"heading": "3.2 Objective & Training", "text": "We formulate the objective function as the mean square error between the predicted and golden ratings. Furthermore, we also apply the regularization term in the objective function.\nL = \u2211\n(u,r,t)\u2208Dtrain\n(r|u,t \u2212 r)2 + (8)\n\u03bb  |F |\u2211 n=1 ||P(zn|u, fn)||22 + |F |\u2211 n=1 ||P(yn|t, fn)||22  where Dtrain is the training dataset and r|u,t is the predicted rating using (4). || ||22 is the l2 norm.\nThe model parameters are as follows: P(zn|u, fn),P(yn|t, fn), \u03c4p\u0302|zn,yn,fn , \u03c9u, \u03c9t, all of which are learned by minimizing the objective function L. For\nP(p\u0302, zn, yn, fn|u, t) = P(zn|u, fn)P(yn|t, fn)P(p\u0302|zn, yn, fn, u, t) (2)\nP(p\u0302|u, t) = First\u2212LevelMixture\ufe37 \ufe38\ufe38 \ufe37 |F |\u2211 n=1 P(fn|u, t) Second\u2212LevelMixture\ufe37 \ufe38\ufe38 \ufe37 |C|\u2211 i,j=1 P(zn = i|u, fn)P(yn = j|t, fn)P(p\u0302|zn = i, yn = j, fn, u, t) (3)\n= |F |\u2211 n=1 P(fn|u, t) |C|\u2211 i,j=1 P(zn = i|u, fn)P(yn = j|t, fn)\u03c4p\u0302|zn,yn,fne \u2212 |P(zn=i|u,fn)\u2212P(yn=j|t,fn)|\u03c3 (4)\na more efficient and facilitating solution, a moment-based gradient method AdaDelta [Zeiler, 2012] is adopted with hyper-parameters: moment factor \u03b7 and RMSE factor .\nRegarding the efficiency, theoretically, the time complex of SAR is O(|F | \u00b7 |C|2), while practically the running time is present in Table 3, which illustrates our method is indeed efficient."}, {"heading": "3.3 Analysis from the Clustering Perspective", "text": "Regarding the mixture form of Equation (3) where the underline terms are the mixture factors, in the both first- and second-level generation, SAR adopts the idea of hierarchical mixture models, which can be further analyzed from the clustering perspective. On one hand, the second-level generative process clusters the users/items according to the corresponding property semantics. These semantic properties originate from the first-level process, according to all the probabilistic terms involved with fn. On the other hand, the first-level generative process adaptively adjusts different property semantics with the information from the secondlevel. Mathematically, the feed-back information indicates P(z1..n, y1..n, f |u, r, t).\nIn essence, users/items are semantically differentiated in a multi-view clustering form. Hence, by characterizing the multi-view clustering nature, SAR can promote recommendation by semantic matching.\nLet\u2019s revisit this process in Figure 1. There is a pool of users/items as input. The single-view clustering process (similar to K-MEANS) is ambiguous, because there are always many clustering angles, such as clustering by Gender, or by Loving Classic, etc. However, once the first-level process generates different semantic properties such as Gender and Occupation, clustering of users/items at the second-level could be addressed according to one exact property semantics. For the example depicted in Figure 1, Boy within the Gender property clustering angle belongs to the Male cluster rather than Female, while that in the Loving Classic or Not property belongs to the No cluster rather than Yes. Finally, summarizing each semantic property, SAR discovers the property semantics of the users/items, namely Boy = (Gender:Male, Loving Classic:No, ...). The property semantics is a \u201clatent\u201d semantic information to empower recommendation systems."}, {"heading": "3.4 Analysis from the Semantic Perspective", "text": "Once SAR discovered the property semantics as shown in Figure 1, the recommendation can be strengthened in the manner of semantic matching. It means it is sufficient to compare the semantic properties between users and items to infer the ratings. For example, when predicting whether the boy would like \u201cTitanic\u201d, we just compare the corresponding properties of the user with those of the item and then no matching is found, so it is reasonable to predict a \u201cnot to recommend\u201d rating. Conversely, when the girl rates \u201cLaLa Land\u201d, semantic matching would reasonably derive a \u201cto recommend\u201d rating. Mathematically, semantic matching is modeled by the Laplace prior of Equation (1)."}, {"heading": "4 Experiment", "text": ""}, {"heading": "4.1 Datasets.", "text": "We conduct our experiments on two public benchmark datasets: MovieLens 100K (ML100K for short) and MovieLens 1M (ML1M). ML100K consists of 100,000 ratings given by 943 users to 1,682 movies, while 93.69% of entries in the rating matrix is empty, while ML1M contains 1,000,209 ratings given by 6,040 users to 3,706 movies, and 95.53% of entries are missing."}, {"heading": "4.2 Performance Evaluation", "text": "The rating prediction is a traditional benchmark task, which concerns the predictive ability for matrix completion. This task directly benefits many recommendation applications, such as item-based recommendation [Zhang et al., 2013].\nProtocol. & Metric. We evaluate how SAR works on the datasets of different sizes and sparsity . Hence, we vary the ratio of training set to test data \u03c1 to evaluate our algorithm and compare with baselines. For example if \u03c1 = 80%, 80% of the observed ratings are randomly sampled for training, and the remaining 20% observed ratings are used for test. Two widely used measures are employed for prediction evaluation, namely Root Mean Square Error (RMSE) and Mean Absolute Error (MAE).\nMAE =\n\u2211 ri\u2208Dtest |ri \u2212 r\u0302i|\nNtest (9)\nRMSE =\n\u221a\u2211 ri\u2208Dtest(ri \u2212 r\u0302i) 2\nNtest (10)\nAbove, Dtest indicates the test set, where each ri means an original rating and r\u0302i is the predicted rating. Ntest is the number of ratings in the test dataset.\nBaselines & Implementation. We compare SAR with 14 state-of-the-art baselines, almost including all the major approaches introduced in Related Work. Specially, SR is a method encodes the social information into matrix completion, and NMF constrained all the factored matrix positive. For a fair comparison with previously proposed methods, we directly reprint the results under the same setting from the literature. On both datasets, the optimal configuration of SAR are as follows: property number |F | = 10, category number |C| = 10, Laplace prior hyper-parameter \u03c3 = 1.0, regularization factor \u03bb = 0.05, moment factor \u03b7 = 0.6 and = 1\u00d7 10\u22126.\nPrediction Accuracy. Evaluation results are shown in Table 1 and Table 2. We can make the following statements.\n1. SAR outperforms all the baselines , justifying the effec-\nTime Complexity. Computation efficiency is evaluated as shown in Table 3, from which we can observe that SAR is as efficient as NMF. As to the trade-off between efficiency and effectiveness, we propose the metric of RMSE improvement over NMF per second: \u2212RMSE(algorithm)\u2212RMSE(NMF )Time(algorithm)\u2212Time(NMF ) (the bigger, the better). In terms of this measurement, the result of PMF is 6.00\u00d7 10\u22123 and that of SAR is 1.60\u00d7 10\u22122 on ML100K, while 2.74\u00d7 10\u22124, 1.50\u00d7 10\u22123 on ML1M for PMF and SAR, respectively. The comparison illustrates that SAR is a better time-performance trade-off method, which is more practical for real-world applications.\nSparsity. We change the \u03c1 to verify the effect of sparsity and the results are shown in Figure 5. We find that all the methods improve as the training set size increases while SAR consistently outperforms the other baselines. For the case of blind regression, where \u03c1 varies from 90% to 30%, the RMSE degrades 0.050, while for SAR, the result is 0.032. This comparison demonstrates that SAR is less sensitive to data sparsity than blind regression which is a strong baseline from this aspect.\nHyper-Parameters. As illustrated in Figure 6, under the normal settings, SAR is insensitive to hyper-parameters. Concretely, when the category number |C| varies between 6 and 12, the performance (RMSE) changes within a magnitude of 0.015, and when the property number |F | changes between 6 and 12, the performance (RMSE) also varies within a small magnitude of 0.1. This comparison justifies the robustness of SAR."}, {"heading": "4.3 Semantic Evaluation", "text": "In this subsection, we conduct an experiment to testify our clarification about property semantics. GroupLens is chosen since it provides the user/item profiles (e.g. gender, occupation, film type) for ML100K, which can facilitate the semantic analysis of our model.\nExperimental Setting. The empirical results are shown in Figure 4, which is proceeded with the following steps. First, we calculate each distribution according to (6) and (7) for each user/item and then represent a user/item with the corresponding distribution (namely P(zi|u) or P(yj |t)) as a point in high-dimensional space R|C|. Second, PCA is conducted to project |C|-dimensional points to a 2D plane. At last, the\ncorresponding attributes from the profile data are manually analyzed to color the points. For clarity, a line is painted artificially to illustrate the boundary.\nResults. We can easily see that SAR discovers and leverages the property semantics appropriately, as shown in Figure 4.\nConcretely, regarding the left figures, user-specific semantics are identified as a combination of gender and age attributes. In fact, only one single user attribute can hardly distinguish a preference (i.e., a rating), but a combination of user attributes is capable to semantically identify the preference. For example in the most left sub-figure, the blue points indicate the teenager boys and the green points denote the housewives or senior business women. Since the properties in terms of recommendation are different, the two point groups are discriminated to a large extent.\nAdditionally, we found the item-relevant semantics are visualized as a transition between attributes components in SAR. In the sub-figure of Children - Drama Film, the proxim-\nity of the boundary lays some Children Drama films, such as \u201cLittle Prince(1995)\u201d and \u201cSecret Garden(1993)\u201d. But conversely in the rightest sub-figure, there are almost no films in the transition area, because in the ML100K dataset, there is not a nominated horror film at all. This phenomenon illustrates the semantic effectiveness of SAR, which can benefit the recommendation by semantic matching."}, {"heading": "5 Conclusion", "text": "In order to discover and utilize latent property semantics, we propose a semantic analysis approach for recommendation, (SAR). The model applies a two-level hierarchical generative process that assigns semantic properties and categories for user and item. Experimental results on benchmark datasets demonstrate the effectiveness of our proposed methods ."}], "references": [{"title": "A max-norm constrained minimization approach to 1-bit matrix completion", "author": ["Tony Cai", "Wen Xin Zhou"], "venue": "Journal of Machine Learning Research, 14(10):3619\u20133647,", "citeRegEx": "Cai and Zhou. 2013", "shortCiteRegEx": null, "year": 2013}, {"title": "Pattern Analysis and Machine Intelligence IEEE Transactions on", "author": ["Deng Cai", "Xiaofei He", "Jiawei Han", "Thomas S. Huang. Graph regularized nonnegative matrix factorization for data representation"], "venue": "33(8):1548\u2013 1560,", "citeRegEx": "Cai et al.. 2011", "shortCiteRegEx": null, "year": 2011}, {"title": "1-bit matrix completion", "author": ["Mark A. Davenport", "Yaniv Plan", "Ewout Van Den Berg", "Mary Wootters"], "venue": "Statistics, 3(3),", "citeRegEx": "Davenport et al.. 2014", "shortCiteRegEx": null, "year": 2014}, {"title": "Expert Systems with Applications", "author": ["Shuiguang Deng", "Longtao Huang", "Guandong Xu. Social network-based service recommendation with trust enhancement"], "venue": "41(18):8075\u20138084,", "citeRegEx": "Deng et al.. 2014", "shortCiteRegEx": null, "year": 2014}, {"title": "and Rebecca Willett", "author": ["Ravi Ganti", "Laura Balzano"], "venue": "Matrix completion under monotonic single index models.", "citeRegEx": "Ganti et al.. 2015", "shortCiteRegEx": null, "year": 2015}, {"title": "Annals of Data Science", "author": ["Meng Jiao Guo", "Jin Guang Sun", "Xiang Fu Meng. A neighborhood-based matrix factorization technique for recommendation"], "venue": "2(3):1\u201316,", "citeRegEx": "Guo et al.. 2015", "shortCiteRegEx": null, "year": 2015}, {"title": "and Heng Huang", "author": ["Zhouyuan Huo", "Ji Liu"], "venue": "Optimal discrete matrix completion.", "citeRegEx": "Huo et al.. 2016", "shortCiteRegEx": null, "year": 2016}, {"title": "Journal of Machine Learning Research", "author": ["Franz J. Kirly", "Louis Theran", "Ryota Tomioka. The algebraic combinatorial approach for lowrank matrix completion"], "venue": "62(2):299\u2013321,", "citeRegEx": "Kirly et al.. 2012", "shortCiteRegEx": null, "year": 2012}, {"title": "In The International Conference on World Wide Web", "author": ["Han Gyu Ko", "Joo Sik Son", "In Young Ko. Multi-aspect collaborative filtering based on linked data for personalized recommendation"], "venue": "pages 49\u201350,", "citeRegEx": "Ko et al.. 2015", "shortCiteRegEx": null, "year": 2015}, {"title": "and S", "author": ["J. Lee", "S. Kim", "G. Lebanon", "Y. Singer"], "venue": "Bengio. Llorma: Local low-rank matrix approximation.", "citeRegEx": "Lee et al.. 2016", "shortCiteRegEx": null, "year": 2016}, {"title": "IEEE Transactions on Multimedia", "author": ["Jing Liu", "Zechao Li", "Jinhui Tang", "Yu Jiang. Personalized geo-specific tag recommendation for photos on social websites"], "venue": "16(3):588\u2013600,", "citeRegEx": "Liu et al.. 2014", "shortCiteRegEx": null, "year": 2014}, {"title": "and Xiao Li Li", "author": ["Yong Liu", "Peilin Zhao", "Xin Liu", "Min Wu"], "venue": "Learning optimal social dependency for recommendation.", "citeRegEx": "Liu et al.. 2016", "shortCiteRegEx": null, "year": 2016}, {"title": "In International ACM SIGIR Conference on Research and Development in Information Retrieval", "author": ["Hao Ma. An experimental study on implicit social recommendation"], "venue": "pages 73\u201382,", "citeRegEx": "Ma. 2013", "shortCiteRegEx": null, "year": 2013}, {"title": "Nips", "author": ["Raghu Meka", "Prateek Jain", "Inderjit S. Dhillon. Guaranteed rank minimization via singular value projection"], "venue": "pages 937\u2013945,", "citeRegEx": "Meka et al.. 2009", "shortCiteRegEx": null, "year": 2009}, {"title": "Probabilistic matrix factorization", "author": ["A. Mnih", "R. Salakhutdinov"], "venue": "International Conference on Machine Learning, pages 880\u2013887", "citeRegEx": "Mnih and Salakhutdinov. 2012", "shortCiteRegEx": null, "year": 2012}, {"title": "Spectral regularization algorithms for learning large incomplete matrices", "author": ["Tibshirani Rahul Mazumder", "Trevor Hastie"], "venue": "Journal of Machine Learning Research,", "citeRegEx": "Mazumder and Hastie.,? \\Q2010\\E", "shortCiteRegEx": "Mazumder and Hastie.", "year": 2010}, {"title": "Dhillon", "author": ["Nikhil Rao", "Hsiang Fu Yu", "Pradeep K. Ravikumar", "Inderjit S"], "venue": "Collaborative filtering with graph information: Consistency and scalable methods.", "citeRegEx": "Rao et al.. 2015", "shortCiteRegEx": null, "year": 2015}, {"title": "In International Conference", "author": ["Jasson D. M Rennie", "Nathan Srebro. Fast maximum margin matrix factorization for collaborative prediction"], "venue": "pages 713\u2013719,", "citeRegEx": "Rennie and Srebro. 2005", "shortCiteRegEx": null, "year": 2005}, {"title": "Recommender systems handbook ", "author": ["Francesco Ricci", "Lior Rokach", "Bracha Shapira", "Paul B Kantor"], "venue": "Springer,,", "citeRegEx": "Ricci et al.. 2011", "shortCiteRegEx": null, "year": 2011}, {"title": "Computer Science", "author": ["Yang Song", "Jun Zhu. Bayesian matrix completion via adaptive relaxed spectral regularization"], "venue": "61(22):5689\u20135703,", "citeRegEx": "Song and Zhu. 2015", "shortCiteRegEx": null, "year": 2015}, {"title": "Siam Journal on Optimization", "author": ["Bart Vandereycken. Low-rank matrix completion by riemannian optimization"], "venue": "23(23):10.1137/110845768,", "citeRegEx": "Vandereycken. 2013", "shortCiteRegEx": null, "year": 2013}, {"title": "Nonnegative matrix factorization: A comprehensive review", "author": ["Yu Xiong Wang", "Yu Jin Zhang"], "venue": "IEEE Transactions on Knowledge and Data Engineering, 25(6):1336\u20131353,", "citeRegEx": "Wang and Zhang. 2013", "shortCiteRegEx": null, "year": 2013}, {"title": "IEEE Transactions on Knowledge and Data Engineering", "author": ["Fei Wang", "Meng Jiang", "Wenwu Zhu", "Shiqiang Yang", "Peng Cui. Recommendation with social contextual information"], "venue": "26(11):2789\u20132802,", "citeRegEx": "Wang et al.. 2014a", "shortCiteRegEx": null, "year": 2014}, {"title": "Rank-one matrix pursuit for matrix completion", "author": ["Z. Wang", "M.J. Lai", "Z. Lu", "W. Fan", "H. Davulcu", "J. Ye"], "venue": "pages 91\u201399", "citeRegEx": "Wang et al.. 2014b", "shortCiteRegEx": null, "year": 2014}, {"title": "Adadelta: An adaptive learning rate method", "author": ["Matthew D. Zeiler"], "venue": "Computer Science,", "citeRegEx": "Zeiler. 2012", "shortCiteRegEx": null, "year": 2012}, {"title": "Journal of Computer Research and Development", "author": ["Feng Zhang", "Huiyou Chang. Employing bp neural networks to alleviate the sparsity issue in collaborative filtering recommendation algorithms"], "venue": "43(4):667\u2013672,", "citeRegEx": "Zhang and Chang. 2006", "shortCiteRegEx": null, "year": 2006}, {"title": "and Shi Feng", "author": ["Yongfeng Zhang", "Min Zhang", "Yiqun Liu", "Shaoping Ma"], "venue": "Localized matrix factorization for recommendation based on matrix block diagonal forms.", "citeRegEx": "Zhang et al.. 2013", "shortCiteRegEx": null, "year": 2013}], "referenceMentions": [{"referenceID": 9, "context": "To this end, much efforts have been attempted, such as low-rank based methods [Lee et al., 2016], latent space models [Song and Zhu, 2015], collaborative filtering [Rao et al.", "startOffset": 78, "endOffset": 96}, {"referenceID": 19, "context": ", 2016], latent space models [Song and Zhu, 2015], collaborative filtering [Rao et al.", "startOffset": 29, "endOffset": 49}, {"referenceID": 16, "context": ", 2016], latent space models [Song and Zhu, 2015], collaborative filtering [Rao et al., 2015], norm constrained methods [Cai and Zhou, 2013], deep learning [Zhang and Chang, 2006], social integration [Liu et al.", "startOffset": 75, "endOffset": 93}, {"referenceID": 0, "context": ", 2015], norm constrained methods [Cai and Zhou, 2013], deep learning [Zhang and Chang, 2006], social integration [Liu et al.", "startOffset": 34, "endOffset": 54}, {"referenceID": 25, "context": ", 2015], norm constrained methods [Cai and Zhou, 2013], deep learning [Zhang and Chang, 2006], social integration [Liu et al.", "startOffset": 70, "endOffset": 93}, {"referenceID": 11, "context": ", 2015], norm constrained methods [Cai and Zhou, 2013], deep learning [Zhang and Chang, 2006], social integration [Liu et al., 2016], etc.", "startOffset": 114, "endOffset": 132}, {"referenceID": 11, "context": "To incorporate more external resources, social information such as relationship between users can be integrated into matrix completion [Liu et al., 2016].", "startOffset": 135, "endOffset": 153}, {"referenceID": 21, "context": ") Basic matrix factorization generally emphasizes latent factors as being non-negative, such as NMF [Wang and Zhang, 2013], SVP [Meka et al.", "startOffset": 100, "endOffset": 122}, {"referenceID": 13, "context": ") Basic matrix factorization generally emphasizes latent factors as being non-negative, such as NMF [Wang and Zhang, 2013], SVP [Meka et al., 2009], MMMF [Rennie and Srebro, 2005], PMF [Mnih and Salakhutdinov, 2012].", "startOffset": 128, "endOffset": 147}, {"referenceID": 17, "context": ", 2009], MMMF [Rennie and Srebro, 2005], PMF [Mnih and Salakhutdinov, 2012].", "startOffset": 14, "endOffset": 39}, {"referenceID": 14, "context": ", 2009], MMMF [Rennie and Srebro, 2005], PMF [Mnih and Salakhutdinov, 2012].", "startOffset": 45, "endOffset": 75}, {"referenceID": 5, "context": ") Combination of matrix factorization with neighborhood-based modeling, such as CISMF [Guo et al., 2015].", "startOffset": 86, "endOffset": 104}, {"referenceID": 9, "context": ") Matrix factorization with complex rank assumptions explores the rank properties and generalization ability to enhance the factorization, such as LLORMA [Lee et al., 2016][Ko et al.", "startOffset": 154, "endOffset": 172}, {"referenceID": 8, "context": ", 2016][Ko et al., 2015], R1MP [Wang et al.", "startOffset": 7, "endOffset": 24}, {"referenceID": 23, "context": ", 2015], R1MP [Wang et al., 2014b], SoftImpute [Rahul Mazumder, 2010], [Ganti et al.", "startOffset": 14, "endOffset": 34}, {"referenceID": 4, "context": ", 2014b], SoftImpute [Rahul Mazumder, 2010], [Ganti et al., 2015], [Zhang et al.", "startOffset": 45, "endOffset": 65}, {"referenceID": 26, "context": ", 2015], [Zhang et al., 2013], [Kirly et al.", "startOffset": 9, "endOffset": 29}, {"referenceID": 7, "context": ", 2013], [Kirly et al., 2012].", "startOffset": 9, "endOffset": 29}, {"referenceID": 6, "context": ") Matrix factorization with discrete assumptions treats the output of the rating matrix as discrete values to avoid noise and obtain more interpretations, such as ODMC [Huo et al., 2016].", "startOffset": 168, "endOffset": 186}, {"referenceID": 5, "context": "There are three main variants including item-based, user-based and global similarity, surveyed in [Guo et al., 2015] and [Ricci et al.", "startOffset": 98, "endOffset": 116}, {"referenceID": 18, "context": ", 2015] and [Ricci et al., 2011].", "startOffset": 12, "endOffset": 32}, {"referenceID": 1, "context": "Regression Based Method is formulated as a regression problem, such as regression for graph GRALS [Cai et al., 2011], blind regression [Song, 2016], Riemannian manifold based regression [Vandereycken, 2013], and others [Davenport et al.", "startOffset": 98, "endOffset": 116}, {"referenceID": 20, "context": ", 2011], blind regression [Song, 2016], Riemannian manifold based regression [Vandereycken, 2013], and others [Davenport et al.", "startOffset": 77, "endOffset": 97}, {"referenceID": 2, "context": ", 2011], blind regression [Song, 2016], Riemannian manifold based regression [Vandereycken, 2013], and others [Davenport et al., 2014].", "startOffset": 110, "endOffset": 134}, {"referenceID": 12, "context": "There list some latest researches: SR [Ma, 2013], PRMF [Liu et al.", "startOffset": 38, "endOffset": 48}, {"referenceID": 11, "context": "There list some latest researches: SR [Ma, 2013], PRMF [Liu et al., 2016], geo-specific personalization [Liu et al.", "startOffset": 55, "endOffset": 73}, {"referenceID": 10, "context": ", 2016], geo-specific personalization [Liu et al., 2014], social network based [Deng et al.", "startOffset": 38, "endOffset": 56}, {"referenceID": 3, "context": ", 2014], social network based [Deng et al., 2014] and other social context integration methods [Wang et al.", "startOffset": 30, "endOffset": 49}, {"referenceID": 22, "context": ", 2014] and other social context integration methods [Wang et al., 2014a].", "startOffset": 53, "endOffset": 73}, {"referenceID": 24, "context": "a more efficient and facilitating solution, a moment-based gradient method AdaDelta [Zeiler, 2012] is adopted with hyper-parameters: moment factor \u03b7 and RMSE factor .", "startOffset": 84, "endOffset": 98}, {"referenceID": 26, "context": "This task directly benefits many recommendation applications, such as item-based recommendation [Zhang et al., 2013].", "startOffset": 96, "endOffset": 116}], "year": 2017, "abstractText": "Recommendation system is a common demand in daily life and matrix completion is a widely adopted technique for this task. However, most matrix completion methods lack semantic interpretation and usually result in weak-semantic recommendations. To this end, this paper proposes a Semantic Analysis approach for Recommendation systems (SAR), which applies a two-level hierarchical generative process that assigns semantic properties and categories for user and item. SAR learns semantic representations of users/items merely from user ratings on items, which offers a new path to recommendation by semantic matching with the learned representations. Extensive experiments demonstrate SAR outperforms other state-of-the-art baselines substantially.", "creator": "LaTeX with hyperref package"}}}