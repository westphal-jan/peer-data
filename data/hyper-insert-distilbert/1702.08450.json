{"id": "1702.08450", "review": {"conference": "arxiv", "VERSION": "v1", "DATE_OF_SUBMISSION": "27-Feb-2017", "title": "A Knowledge-Based Approach to Word Sense Disambiguation by distributional selection and semantic features", "abstract": "enhancing word sense disambiguation improves dramatically many natural knowledge language input processing ( nlp ) intelligence applications such as data information retrieval, digital information extraction, machine translation, or experimental lexical frequency simplification. especially roughly speaking, learning the aim is able to continuously choose for each appropriate word in asking a text its third best mathematical sense. considering one of the second most popular processing method estimates local weighted semantic ordering similarity relatedness between two distinct word senses and proceeds then extends it to all words from text. the most direct application method used computes a rather rough score computed for every repeated pair one of word senses and correctly chooses the lexical temporal chain information that has the best score ( we can imagine constructing the exponential numerical complexity that merely returns this comparatively comprehensive approach ). in drafting this paper, next we propose to begin use imagine a combinatorial temporal optimization optimization metaheuristic paradigm for choosing the nearest neighbors obtained solely by strict distributional rule selection centered around directing the word to virtually disambiguate. the test and supervised the evaluation of our improved method concern resolving a corpus poem written in french by means spoken of acquiring the semantic network product babelnet. the obtained accuracy rate is 78 % on applying all names and + verbs chosen for the evaluation.", "histories": [["v1", "Mon, 27 Feb 2017 13:37:15 GMT  (870kb)", "http://arxiv.org/abs/1702.08450v1", "in French"]], "COMMENTS": "in French", "reviews": [], "SUBJECTS": "cs.CL", "authors": ["mokhtar billami"], "accepted": false, "id": "1702.08450"}, "pdf": {"name": "1702.08450.pdf", "metadata": {"source": "META", "title": "De\u0301sambigui\u0308sation lexicale a\u0300 base de connaissances par se\u0301lection distributionnelle et traits se\u0301mantiques", "authors": ["Mokhtar Boumedyen Billami"], "emails": ["mokhtar.billami@lif.univ-mrs.fr"], "sections": [{"heading": null, "text": "Retrieval, Information Extraction, Machine Translation, or Lexical Simplification. Roughly speaking, the aim is to choose for each word in a text its best sense. One of the most popular method estimates local semantic similarity relatedness between two word senses and then extends it to all words from text. The most direct method computes a rough score for every pair of word senses and chooses the lexical chain that has the best score (we can imagine the exponential complexity that returns this comprehensive approach). In this paper, we propose to use a combinatorial optimization metaheuristic for choosing the nearest neighbors obtained by distributional selection around the word to disambiguate. The test and the evaluation of our method concern a corpus written in French by means of the semantic network BabelNet. The obtained accuracy rate is 78 % on all names and verbs chosen for the evaluation.\nMots-cl\u00e9s : d\u00e9sambigu\u00efsation lexicale non supervis\u00e9e, mesure de similarit\u00e9 distributionnelle, mesures de similarit\u00e9 s\u00e9mantique. Keywords: unsupervised word sense disambiguation, distributional similarity measure, semantic similarity measures."}, {"heading": "1 Introduction", "text": "La d\u00e9sambigu\u00efsation des sens de mots est une \u00ab t\u00e2che interm\u00e9diaire \u00bb (Wilks, Stevenson, 1996), qui ne constitue pas une fin en soi, mais est plut\u00f4t n\u00e9cessaire \u00e0 un niveau ou \u00e0 un autre pour accomplir la plupart des t\u00e2ches de traitement des langues. Ainsi, la d\u00e9sambigu\u00efsation lexicale suscite de l\u2019int\u00e9r\u00eat depuis les premiers jours du traitement informatique de la langue (Ide, V\u00e9ronis, 1998). Elle est n\u00e9cessaire pour plusieurs applications telles que la recherche d'information, l'extraction d'information, la traduction automatique, l'analyse du contenu, la fouille de textes, la lexicographie et le web s\u00e9mantique. La plupart des syst\u00e8mes de d\u00e9sambigu\u00efsation lexicale existants s'appuient sur deux grandes \u00e9tapes (Navigli, 2009) : (1) repr\u00e9sentation de l'ensemble des sens d'un mot ; et (2) choix du sens le plus proche du mot par rapport \u00e0 son contexte. La premi\u00e8re \u00e9tape repose sur l'utilisation de ressources lexicales telles que les dictionnaires ou les r\u00e9seaux s\u00e9mantiques. Ide et V\u00e9ronis (1998) ont montr\u00e9 que la meilleure possibilit\u00e9 d'identifier le sens d'un mot ambigu est de se r\u00e9f\u00e9rer \u00e0 son contexte.\nL\u2019une des approches les plus classiques pour d\u00e9terminer le sens le plus probable d\u2019un mot polys\u00e9mique est d\u2019estimer la proximit\u00e9 s\u00e9mantique entre chaque sens candidat par rapport \u00e0 chaque sens de chaque mot appartenant au contexte du"}, {"heading": "MOKHTAR BOUMEDYEN BILLAMI", "text": "mot \u00e0 d\u00e9sambigu\u00efser1. En d\u2019autres termes, il s\u2019agit de donner des scores locaux et de les propager au niveau global. Une application de cette m\u00e9thode est propos\u00e9e dans (Pederson et al., 2005). On imagine la complexit\u00e9 exponentielle que retourne cette approche exhaustive. On se retrouve facilement avec un temps de calcul tr\u00e8s long alors que le contexte qu\u2019il est possible d\u2019utiliser est petit. Par exemple, pour une phrase de 10 mots avec 10 sens en moyenne, il y aurait 1010 combinaisons possibles. Le calcul exhaustif est donc tr\u00e8s compliqu\u00e9 \u00e0 r\u00e9aliser et, surtout, rend impossible l\u2019utilisation d\u2019un contexte plus important. Pour diminuer le temps de calcul on peut utiliser une fen\u00eatre autour du mot afin de r\u00e9duire le temps d\u2019ex\u00e9cution d\u2019une combinaison mais le choix d\u2019une fen\u00eatre de taille quelconque peut mener \u00e0 une perte de coh\u00e9rence globale de la d\u00e9sambigu\u00efsation.\nLe contexte du mot \u00e0 d\u00e9sambigu\u00efser est d\u00e9limit\u00e9 par une fen\u00eatre textuelle qui se situe \u00e0 gauche ou \u00e0 droite ou des deux c\u00f4t\u00e9s et dont la taille peut varier. Les fen\u00eatres peuvent \u00eatre d\u00e9limit\u00e9es soit \u00e0 l'aide de s\u00e9parateurs de phrases ou de paragraphes, soit \u00e0 l'aide de \u00ab n-grammes \u00bb qui permettent d'observer un certain nombre (n-1) de mots entourant le mot polys\u00e9mique dans le texte. La d\u00e9finition de la taille de la fen\u00eatre textuelle est li\u00e9e \u00e0 celle de la distance optimale entre les mots ambigus et les indices contextuels pouvant servir \u00e0 leur d\u00e9sambigu\u00efsation (Audibert, 2007). Selon Yarowsky (1993), une grande fen\u00eatre est n\u00e9cessaire pour lever l\u2019ambigu\u00eft\u00e9 des noms alors que seulement une petite fen\u00eatre suffit pour le cas des verbes ou des adjectifs. Dans un cadre d\u2019analyse distributionnelle de donn\u00e9es, plusieurs recherches sont faites sur la construction automatique de th\u00e9saurus \u00e0 partir de cooccurrences de mots provenant d\u2019un corpus de grande taille. Pour chaque mot cible en entr\u00e9e, une liste ordonn\u00e9e de voisins les plus proches (nearest neighbours) lui est attribu\u00e9e. Les voisins sont ordonn\u00e9s en termes de la similarit\u00e9 distributionnelle qu\u2019ils ont avec le mot cible. Lin (1998) a propos\u00e9 une m\u00e9thode pour mesurer la similarit\u00e9 distributionnelle entre deux mots (un mot cible et son voisin). Dans cet article, nous nous int\u00e9ressons \u00e0 cette approche d\u2019analyse distributionnelle et nous l\u2019utilisons dans la t\u00e2che de la d\u00e9sambigu\u00efsation lexicale.\nDans un premier temps, nous pr\u00e9sentons un \u00e9tat de l\u2019art sur les m\u00e9thodes de d\u00e9sambigu\u00efsation lexicale (section 2), notre m\u00e9thodologie de d\u00e9sambigu\u00efsation \u00e0 base de traits s\u00e9mantiques est pr\u00e9sent\u00e9e dans la section 3. Elle d\u00e9crit le corpus de travail et d\u2019\u00e9valuation, le r\u00e9seau s\u00e9mantique BabelNet que nous utilisons pour le choix des sens de mots, la mesure de similarit\u00e9 distributionnelle pour le choix des voisins les plus proches ainsi que les algorithmes permettant de retourner le sens le plus probable d\u2019un mot selon le contexte dans lequel il apparait. Nous pr\u00e9sentons par la suite les donn\u00e9es des exp\u00e9riences men\u00e9es (section 4) ainsi que les r\u00e9sultats de l\u2019\u00e9valuation des diff\u00e9rents algorithmes (section 5). Nous terminons par une conclusion et quelques perspectives (section 6).\n2 \u00c9tat de l\u2019art\nNous pouvons distinguer deux grandes cat\u00e9gories de m\u00e9thodes de d\u00e9sambigu\u00efsation : (1) dirig\u00e9es par les donn\u00e9es, o\u00f9 l\u2019on trouve les m\u00e9thodes supervis\u00e9es et non supervis\u00e9es. Les m\u00e9thodes supervis\u00e9es s'appuient sur un corpus d'apprentissage r\u00e9unissant des exemples d'instances d\u00e9sambigu\u00efs\u00e9es de mots. Les m\u00e9thodes non supervis\u00e9es exploitent les r\u00e9sultats de m\u00e9thodes automatiques d'acquisition de sens ; (2) bas\u00e9es sur les connaissances, n\u00e9cessitant une mod\u00e9lisation \u00e9tendue aux informations lexico-s\u00e9mantiques ou encyclop\u00e9diques. Ces m\u00e9thodes peuvent \u00eatre combin\u00e9es avec les m\u00e9thodes non supervis\u00e9es. La d\u00e9sambigu\u00efsation peut \u00eatre de deux types : (a) d\u00e9sambigu\u00efsation cibl\u00e9, seulement sur un mot particulier dans un texte ; (b) d\u00e9sambigu\u00efsation compl\u00e8te pour tous les mots pleins2 d'un texte. Il y a deux crit\u00e8res importants pour choisir l'algorithme \u00e0 utiliser. Le premier crit\u00e8re est une mesure de similarit\u00e9 qui d\u00e9pend des contraintes de la base de connaissances et du contexte applicatif. Le deuxi\u00e8me crit\u00e8re est le temps d'ex\u00e9cution de l'algorithme. Le lecteur pourra consulter (Ide, V\u00e9ronis, 1998) pour les travaux ant\u00e9rieurs \u00e0 1998 et (Navigli, 2009) pour un \u00e9tat de l\u2019art complet.\nUne annotation de mots d'un corpus avec des sens d\u00e9sambigu\u00efs\u00e9s provenant d'un inventaire de sens (ex. WordNet) est extr\u00eamement co\u00fbteuse. \u00c0 l'heure actuelle tr\u00e8s peu de corpus annot\u00e9s s\u00e9mantiquement sont disponibles pour l'anglais ; \u00e0 notre connaissance, rien n\u2019existe pour le fran\u00e7ais. Le consortium de donn\u00e9es linguistiques (Linguistic Data Consortium3) a distribu\u00e9 un corpus contenant approximativement 200 000 phrases en anglais issues du corpus Brown et Wall Street Journal dont toutes les occurrences de 191 lemmes ont \u00e9t\u00e9 annot\u00e9es avec WordNet (Ng, Lee, 1996). Le corpus SemCor (Miller et al., 1993) est le plus grand corpus annot\u00e9 s\u00e9mantiquement. Il contient 352 textes annot\u00e9s avec pr\u00e8s de 234 000 sens au total. Cependant, ces corpus contiennent peu de donn\u00e9es pour \u00eatre utilis\u00e9s avec des m\u00e9thodes statistiques. Ng (1997) estime que, pour obtenir un syst\u00e8me de d\u00e9sambigu\u00efsation \u00e0 large couverture et de haute pr\u00e9cision, nous avons probablement besoin d'un corpus d'environ 3,2 millions de mots de sens \u00e9tiquet\u00e9s. L'effort humain pour construire un tel\n1 Il peut s\u2019agir d\u2019une phrase, d\u2019un paragraphe ou d\u2019un texte brut.\n2 Mots pleins : noms, verbes, adjectifs et adverbes.\n3 Linguistic Data Consortium (LDC). https://www.ldc.upenn.edu\n22\u00e8me Traitement Automatique des Langues Naturelles, Caen, 2015\ncorpus d'apprentissage peut \u00eatre estim\u00e9 \u00e0 27 ann\u00e9es pour une annotation d'un mot par minute par personne (Edmonds, 2000). Il est clair qu'avec une telle ressource \u00e0 port\u00e9e de main, les syst\u00e8mes supervis\u00e9s seraient beaucoup plus performants mais \u00e7a ne reste qu'une hypoth\u00e8se.\nDes efforts ont \u00e9t\u00e9 fournis pour annoter s\u00e9mantiquement des corpus en utilisant des m\u00e9thodes de boostrapping. Hearst (1991) a propos\u00e9 un algorithme (CatchWord) pour une classification des noms qui comprend une phase d'apprentissage au cours de laquelle plusieurs occurrences de chaque nom sont manuellement annot\u00e9es. Les informations statistiques extraites du contexte de ces occurrences sont ensuite utilis\u00e9es pour lever l'ambigu\u00eft\u00e9 d'autres occurrences. Si une autre occurrence peut \u00eatre d\u00e9sambigu\u00efs\u00e9e avec certitude, le syst\u00e8me acquiert automatiquement des informations statistiques de ces nouvelles occurrences d\u00e9sambigu\u00efs\u00e9es, am\u00e9liorant ainsi ses connaissances progressivement. Hearst indique qu'une premi\u00e8re s\u00e9rie d'au moins 10 occurrences est n\u00e9cessaire pour la proc\u00e9dure, et que 20 ou 30 occurrences sont n\u00e9cessaires pour une haute pr\u00e9cision.\nEnfin, les m\u00e9thodes de d\u00e9sambigu\u00efsation lexicale \u00e0 base de connaissances se composent d\u2019une part de mesures de similarit\u00e9 s\u00e9mantique locales qui donnent une valeur de proximit\u00e9 entre deux sens de mots et, d\u2019autre part, d\u2019algorithmes globaux qui utilisent ces mesures pour trouver les sens selon le contexte \u00e0 l\u2019\u00e9chelle de la phrase ou du texte. Plusieurs solutions, autres que l\u2019algorithme exhaustif, ont \u00e9t\u00e9 propos\u00e9es. Par exemple, des approches \u00e0 base de corpus pour diminuer le nombre de combinaisons \u00e0 examiner comme la recherche des cha\u00eenes lexicales compatibles (Vasilescu et al., 2004) ou encore des approches issues de l\u2019intelligence artificielle comme le recuit simul\u00e94 (Cowie et al., 1992) ou les algorithmes g\u00e9n\u00e9tiques (Gelbukh et al., 2003). Pour plus de d\u00e9tails, le lecteur pourra consulter (Tchechmedjiev, 2012).\n3 M\u00e9thodologie\nD\u00e9sambigu\u00efser tous les mots pleins d\u2019un corpus dont le contexte repr\u00e9sente un paragraphe est une t\u00e2che qui demande beaucoup de temps si on se base sur un algorithme exhaustif simple. La cl\u00e9 de notre approche de d\u00e9sambigu\u00efsation est l\u2019observation des voisins de chaque mot polys\u00e9mique dans le texte : au lieu de comparer chaque sens d\u2019un mot \u00e0 d\u00e9sambigu\u00efser avec tous les sens de tous les mots qui se trouvent dans le texte, nous faisons une comparaison uniquement avec les sens des voisins s\u00e9lectionn\u00e9s au moyen d\u2019une similarit\u00e9 distributionnelle. D\u2019une part, ces voisins fournissent souvent des indices sur le sens le plus probable d\u2019un mot dans un texte. D\u2019autre part, cela nous permet de diminuer le temps d\u2019ex\u00e9cution de l\u2019algorithme et de ne pas perdre une coh\u00e9rence au niveau de la d\u00e9sambigu\u00efsation de tous les mots du texte. Il s\u2019agit de garder l\u2019homog\u00e9n\u00e9it\u00e9 des mots afin de retourner le sens le plus sp\u00e9cifique \u00e0 chaque mot au lieu de retourner le sens le plus g\u00e9n\u00e9ral."}, {"heading": "3.1 Corpus de donn\u00e9es", "text": ""}, {"heading": "3.1.1 Corpus de travail", "text": "Nous avons \u00e0 disposition un ensemble de trois corpus de diff\u00e9rents genres. Le premier corpus est une collection de l\u2019agence fran\u00e7aise de presse (French press agency5). Le deuxi\u00e8me corpus est une collection d\u2019articles d\u2019un journal local fran\u00e7ais (l\u2019EST R\u00e9publicain6). Le troisi\u00e8me corpus est une collection d\u2019articles issue de la ressource encyclop\u00e9dique libre, Wikip\u00e9dia7. L\u2019ensemble des donn\u00e9es de ces trois corpus est d\u00e9crit dans le tableau 1. Ces diff\u00e9rents corpus ont \u00e9t\u00e9 analys\u00e9s automatiquement par la cha\u00eene de traitement Macaon8 (Nasr et al., 2011). Nous avons obtenu 2 754 686 triplets9 diff\u00e9rents de d\u00e9pendances syntaxiques correspondant \u00e0 31 774 noms uniques et 5 421 verbes uniques. Ces triplets sont stock\u00e9s et index\u00e9s apr\u00e8s extraction de 12 785 450 cooccurrences.\n4 M\u00e9thode d\u2019optimisation stochastique classique fond\u00e9e sur les principes physiques du refroidissement des m\u00e9taux qui a \u00e9t\u00e9\nappliqu\u00e9e \u00e0 la d\u00e9sambigu\u00efsation lexicale.\n5 French press agency (AFP). http://www.afp.com/fr\n6 L\u2019EST R\u00e9publicain. http://www.estrepublicain.fr/\n7 Wikip\u00e9dia, encyclop\u00e9die libre sur le web. https://fr.wikipedia.org\n8 Macaon, cha\u00eene de traitement permettant d\u2019effectuer des t\u00e2ches standard du TAL. http://macaon.lif.univ-mrs.fr\n9 Un triplet de d\u00e9pendance syntaxique se compose d\u2019une t\u00eate, d\u2019un type de d\u00e9pendance et d\u2019un modificateur. Par exemple,\n(recouvrer, suj, regard) est un triplet extrait de la phrase \u00ab leurs regards recouvraient les eaux du fleuve \u00bb."}, {"heading": "MOKHTAR BOUMEDYEN BILLAMI", "text": "Corpus Phrases Tokens\nAFP 2 041 146 59 914 238\nEST REP 2 998 261 53 913 288\nWIKI 1 592 035 33 821 460\nTotal 6 631 442 147 648 986\nTableau 1 : Donn\u00e9es du corpus de travail\n3.1.2 Corpus d\u2019\u00e9valuation\nNous travaillons sur deux corpus diff\u00e9rents, corpus IREST10 contenant 10 textes et un corpus brut11 contenant 20 textes pour un total de 30 textes. Nous avons 6 235 occurrences de mots (4 139 occurrences de mots pleins) et une moyenne de 208 occurrences (138 occurrences de mots pleins) par texte (cf. section 4, tableau 2). Les textes sont lemmatis\u00e9s et annot\u00e9s en parties du discours par Macaon. Le travail de d\u00e9sambigu\u00efsation que nous menons porte sur des unit\u00e9s monolexicales (les expressions polylexicales n\u2019ont pas \u00e9t\u00e9 prises en compte)."}, {"heading": "3.2 Ressource lexicale BabelNet", "text": "BabelNet12 (Navigli, Ponzetto, 2012) est un r\u00e9seau s\u00e9mantique multilingue permettant de fournir des sens et des entit\u00e9s nomm\u00e9es13. BabelNet a \u00e9t\u00e9 cr\u00e9\u00e9 en int\u00e9grant automatiquement la plus grande encyclop\u00e9die multilingue - c\u2019est-\u00e0-dire Wikip\u00e9dia \u2013 avec WordNet (Fellbaum, 1998). La construction de cette ressource s\u2019est faite en deux grandes \u00e9tapes : (1) mapping entre Wikip\u00e9dia et WordNet ; (2) un syst\u00e8me de traduction automatique, bas\u00e9 sur l'application de traduction en ligne de Google, pour recueillir une grande quantit\u00e9 de concepts multilingues et de compl\u00e9ter par les traductions manuellement \u00e9dit\u00e9es dans Wikip\u00e9dia. La construction de BabelNet a permis de couvrir les sens manquants dans WordNet. Le r\u00e9sultat est une ressource multilingue qui fournit des entr\u00e9es lexicalis\u00e9es multilingues, reli\u00e9es entre elles avec une grande quantit\u00e9 de relations s\u00e9mantiques. De la m\u00eame fa\u00e7on que WordNet, BabelNet regroupe les mots en diff\u00e9rentes langues par groupes de synonymes appel\u00e9s Babel synsets. Pour chaque Babel synset, BabelNet fournit des d\u00e9finitions textuelles (appel\u00e9es gloses) en plusieurs langues, obtenues \u00e0 partir de WordNet et Wikip\u00e9dia. A partir de la version 2.0 de BabelNet (octobre, 2013) cette ressource int\u00e8gre non seulement Wikip\u00e9dia mais aussi Wiktionary, Wikidata, OmegaWiki et Open Multilingual WordNet, une collection de WordNets disponibles dans diff\u00e9rentes langues. A la diff\u00e9rence de WordNet qui offre une seule d\u00e9finition par sens, BabelNet permet d\u2019offrir plusieurs d\u00e9finitions pour plusieurs langues.\nLa version 2.0 de BabelNet couvrait 50 langues, y compris toutes les langues europ\u00e9ennes. Actuellement, la version 3.0 couvre 271 langues et contient plus de 13 millions de synsets. Chaque Babel synset contient en moyenne 5,5 synonymes. Le r\u00e9seau s\u00e9mantique comprend toutes les relations lexico-s\u00e9mantiques de WordNet (hyperonymie et hyponymie, m\u00e9ronymie et holonymie, antonymie et synonymie, etc.). Pour la langue fran\u00e7aise, BabelNet contient actuellement 4 120 733 synsets et 174 591 mots polys\u00e9miques. Nous avons choisi d\u2019utiliser BabelNet parce qu\u2019il offre un tr\u00e8s grand nombre de synsets et couvre plusieurs mots polys\u00e9miques par rapport \u00e0 d\u2019autres ressources lexicales pour le fran\u00e7ais comme Wolf14 (Hanoka, Sagot, 2012) qui offre dans sa version b\u00eata 1.0 un ensemble de 59 091 synsets d\u00e9crits avec des synonymes et des d\u00e9finitions.\n10 Textes standards pour des tests de vitesse de lecture. http://vision-research.eu\n11 Textes de lecture pour enfants en \u00e9cole primaire.\n12 BabelNet, ressource lexicale. http://babelnet.org\n13 Nous nous int\u00e9ressons \u00e0 la d\u00e9sambigu\u00efsation des sens sans tenir compte de la pr\u00e9sence des entit\u00e9s nomm\u00e9es. Nous\nconsid\u00e9rons un sens comme \u00e9tant un concept dans le r\u00e9seau s\u00e9mantique.\n14 Wolf est inspir\u00e9 de WordNet et pr\u00e9sente un r\u00e9seau s\u00e9mantique libre pour le fran\u00e7ais. http://alpage.inria.fr/~sagot/wolf.html\n22\u00e8me Traitement Automatique des Langues Naturelles, Caen, 2015\nBabelNet dans sa version 2.5.1 a \u00e9t\u00e9 utilis\u00e9 pour la r\u00e9alisation d\u2019un syst\u00e8me de d\u00e9sambigu\u00efsation et de d\u00e9tection d\u2019entit\u00e9s nomm\u00e9es, Babelfy15 (Moro et al., 2014). Babelfy obtient de bonnes performances gr\u00e2ce \u00e0 la structure de BabelNet qui permet l\u2019int\u00e9gration des sens lexicographiques et d\u2019entit\u00e9s encyclop\u00e9diques en un seul r\u00e9seau s\u00e9mantique. Nous utilisons la version 2.5.1 pour l\u2019\u00e9valuation de nos exp\u00e9riences afin de comparer nos r\u00e9sultats avec ceux retourn\u00e9s par Babelfy."}, {"heading": "3.3 Similarit\u00e9 distributionnelle", "text": "La similarit\u00e9 distributionnelle est une mesure indiquant le degr\u00e9 de cooccurrence entre un mot cible et son voisin apparaissant dans des contextes similaires. Par exemple, dans un premier texte les voisins de fleuve peuvent \u00eatre rivi\u00e8re, eau, affluent. Le sens le plus probable pour fleuve est d\u00e9crit dans BabelNet par trois d\u00e9finitions.\nSens 1\n(1) Cours d'eau naturel ; (2) En hydrographie, une rivi\u00e8re est un cours d'eau qui s'\u00e9coule sous l'effet de la gravit\u00e9 et qui se jette dans une\nautre rivi\u00e8re ou dans un fleuve, contrairement au fleuve qui se jette, lui, selon cette terminologie, dans la mer ou dans l'oc\u00e9an ; (3) Courant d'eau qui coule d'une altitude \u00e9lev\u00e9e \u00e0 une altitude basse pour arriver dans un lac ou une mer, sauf dans les aires d\u00e9sertiques ou il peut arriver sur rien.\nDans un deuxi\u00e8me texte, les voisins de fleuve peuvent \u00eatre mer, eau, oc\u00e9an. Le sens le plus probable pour fleuve est d\u00e9crit dans BabelNet par deux d\u00e9finitions.\nSens 2\n(1) Cours d'eau se jetant dans une mer ; (2) En hydrographie francophone, un fleuve est un cours d'eau qui se jette dans une mer, dans l'oc\u00e9an, Il se\ndistingue d'une rivi\u00e8re, qui se jette dans un autre cours d'eau.\nPlus la similarit\u00e9 distributionnelle entre les voisins est forte plus la probabilit\u00e9 d\u2019avoir le sens le plus probable est grande. Nous utilisons la m\u00e9thode propos\u00e9e par Lin (1998) pour l\u2019analyse distributionnelle de donn\u00e9es sur notre corpus de travail. Nous avons \u00e0 disposition un ensemble de relations grammaticales extraites \u00e0 partir d\u2019une analyse automatique sur les donn\u00e9es du corpus de travail. Cette extraction est limit\u00e9e \u00e0 un certain nombre de relations de d\u00e9pendances syntaxiques et nous a permis d\u2019avoir un ensemble de cooccurrences entre les noms et les verbes. Pour chaque nom, nous avons des relations de cooccurrences, par exemple la relation objet-de et sujet-de ; pour les verbes, la relation a-pour-objet, etc. Ainsi, nous avons un ensemble de triplets de cooccurrences < \ud835\udc64, \ud835\udc5f, \ud835\udc65 > associ\u00e9s avec leur fr\u00e9quence d\u2019apparition o\u00f9 r est une relation grammaticale et x est une cooccurrence associ\u00e9e avec w selon la relation r. Par exemple, les triplets de d\u00e9pendances syntaxiques dans la phrase \u00ab leurs regards recouvraient les eaux du fleuve \u00bb retourn\u00e9s par la cha\u00eene de traitement Macaon sont : (regard det leur), (recouvrer suj regard), (recouvrer obj eau), (eau det le), (eau dep de) et (de obj fleuve)16. Nous pouvons voir les triplets comme des traits syntaxiques : pour le triplet (recouvrer, suj, regard), regard a pour trait syntaxique suj (recouvrer). La similarit\u00e9 distributionnelle entre deux mots \ud835\udc641 et \ud835\udc642 est d\u00e9finie par la fonction suivante :\n\ud835\udc60\ud835\udc56\ud835\udc5a(\ud835\udc641, \ud835\udc642) = 2\ud835\udc65 \ud835\udc3c(\ud835\udc39(\ud835\udc641) \u2229 \ud835\udc39(\ud835\udc642))\n\ud835\udc3c(\ud835\udc39(\ud835\udc641)) + \ud835\udc3c(\ud835\udc39(\ud835\udc642))\n\ud835\udc39(\ud835\udc641) \ud835\udc52\ud835\udc61 \ud835\udc39(\ud835\udc642) repr\u00e9sentent l\u2019ensemble des traits syntaxiques poss\u00e9d\u00e9s respectivement par \ud835\udc641 et \ud835\udc642. \ud835\udc39(\ud835\udc641) \u2229 \ud835\udc39(\ud835\udc642) repr\u00e9sente l\u2019ensemble des traits syntaxiques communs de \ud835\udc641 et \ud835\udc642. Si \ud835\udc3c(\ud835\udc46) est la quantit\u00e9 d\u2019information contenue dans l\u2019ensemble des traits de \ud835\udc46 alors \ud835\udc3c(\ud835\udc46) = \u2212 \u2211 log \ud835\udc43(\ud835\udc53)f \u2208S o\u00f9 \ud835\udc43(\ud835\udc53) est la probabilit\u00e9 d\u2019avoir le trait syntaxique \ud835\udc53. Cette similarit\u00e9 est born\u00e9e entre 0 et 1. Elle retourne 1 si \ud835\udc641 et \ud835\udc642 partagent les m\u00eames traits et retourne 0 si les deux mots n\u2019ont aucun trait en commun. La probabilit\u00e9 \ud835\udc43(\ud835\udc53) est estim\u00e9e par le pourcentage des mots qui poss\u00e8dent le trait syntaxique \ud835\udc53 parmi l\u2019ensemble des mots poss\u00e9dant la m\u00eame partie de discours du mot analys\u00e9. Sur un ensemble de 30% s\u00e9lectionn\u00e9 al\u00e9atoirement depuis la base de triplets et pour lequel nous avons obtenu 22 168 noms diff\u00e9rents, la probabilit\u00e9 d\u2019avoir le\n15 Babelfy, un syst\u00e8me de d\u00e9sambigu\u00efsation et de d\u00e9tection d\u2019entit\u00e9s nomm\u00e9es. http://babelfy.org\n16 La relation det est sp\u00e9cifique \u00e0 un nom et son d\u00e9terminant ; suj est la relation entre un verbe et son sujet ; obj est la relation\nentre un verbe et son objet ou autres ; la derni\u00e8re relation est dep pour pr\u00e9senter une relation g\u00e9n\u00e9rique par d\u00e9faut."}, {"heading": "MOKHTAR BOUMEDYEN BILLAMI", "text": "trait syntaxique suj (border) est de 38\n22 168 parce que seulement 38 noms uniques sont utilis\u00e9s comme sujet pour le verbe\nborder. La quantit\u00e9 d\u2019information pour ce trait est 6.37. Si on prend l\u2019exemple pr\u00e9c\u00e9dant du nom fleuve, ce nom poss\u00e8de le trait suj (border) comme il poss\u00e8de le trait obj (conna\u00eetre). La probabilit\u00e9 d\u2019avoir obj (conna\u00eetre) est de 582\n22 168 . La\nquantit\u00e9 d\u2019information retourn\u00e9e est 3.64. Dans ce cas, le trait suj (border) est plus informatif que le trait obj (conna\u00eetre)."}, {"heading": "3.4 Similarit\u00e9s s\u00e9mantiques", "text": "Pour mesurer la similarit\u00e9 s\u00e9mantique, nous utilisons l\u2019algorithme de Lesk (1986) et ses variantes propos\u00e9es il y a pr\u00e8s de 30 ans. Cet algorithme est tr\u00e8s simple, il consid\u00e8re la similarit\u00e9 entre deux sens comme le nombre de mots, simplement les suites de caract\u00e8res s\u00e9par\u00e9es par des espaces, en commun dans leurs d\u00e9finitions. La partie 3.4.1 pr\u00e9sente l\u2019algorithme de base de Lesk, la partie 3.4.2 pr\u00e9sente une variante de Lesk que nous utilisons comme baseline et la partie 3.4.3 pr\u00e9sente l\u2019algorithme de Lesk \u00e9tendu."}, {"heading": "3.4.1 Algorithme de base de Lesk", "text": "Cet algorithme n\u00e9cessite un dictionnaire (BabelNet pour notre cas) et aucun apprentissage. Il consiste \u00e0 donner un score \u00e0 une paire de sens de deux mots diff\u00e9rents sans tenir compte ni de l\u2019ordre des mots dans les d\u00e9finitions de ces sens ni d\u2019informations morphologiques ou syntaxiques. Nous faisons une comparaison \u00e0 partir des traits s\u00e9mantiques (mots pleins) de chaque d\u00e9finition de sens. Nous utilisons TreeTagger17 pour obtenir ces trais s\u00e9mantiques dans notre programme. Comme d\u00e9crit ci-dessus, BabelNet permet d\u2019offrir plusieurs d\u00e9finitions \u00e0 un sens pour une langue donn\u00e9e (fran\u00e7ais pour nos exp\u00e9riences), nous prenons en compte toutes les d\u00e9finitions possibles. Dans le cas o\u00f9 aucune d\u00e9finition n\u2019est propos\u00e9e pour un sens, nous prenons en consid\u00e9ration les synonymes li\u00e9s avec le mot \u00e0 comparer. La fonction\nutilis\u00e9e pour mesurer la similarit\u00e9 s\u00e9mantique se pr\u00e9sente par : \ud835\udc46\ud835\udc56\ud835\udc5a\ud835\udc3f\ud835\udc52\ud835\udc60\ud835\udc58 (\ud835\udc461 , \ud835\udc462) = \u2502\ud835\udc37(\ud835\udc461 ) \u2229 \ud835\udc37(\ud835\udc462)\u2502."}, {"heading": "3.4.2 Variante de Lesk", "text": "Cette variante consiste \u00e0 retourner le nombre de mots communs entre les unit\u00e9s lexicales (mots pleins) du contexte du mot \u00e0 d\u00e9sambigu\u00efser et les traits s\u00e9mantiques des d\u00e9finitions de chaque sens candidat. Navigli (2009) d\u00e9crit cette variante. Dans nos exp\u00e9riences, le contexte repr\u00e9sente le paragraphe. La fonction utilis\u00e9e pour mesurer la similarit\u00e9 s\u00e9mantique se\npr\u00e9sente par : \ud835\udc3f\ud835\udc52\ud835\udc60\ud835\udc58\ud835\udc49\ud835\udc4e\ud835\udc5f\ud835\udc56\ud835\udc4e\ud835\udc5b\ud835\udc61\ud835\udc52 = \u2502\ud835\udc50\ud835\udc5c\ud835\udc5b\ud835\udc61\ud835\udc52\ud835\udc65\ud835\udc61\ud835\udc52(\ud835\udc64) \u2229 \ud835\udc37(\ud835\udc46\ud835\udc56 (w))\u2502o\u00f9 \ud835\udc64 est le mot \u00e0 d\u00e9sambigu\u00efser et \ud835\udc46\ud835\udc56 est l\u2019II\u00e8me sens du mot \ud835\udc64. Un probl\u00e8me important dans la mesure de Lesk est qu\u2019elle est tr\u00e8s sensible aux mots pr\u00e9sents dans les d\u00e9finitions. Une absence des mots importants dans les d\u00e9finitions retourne des r\u00e9sultats qui ne sont pas de tr\u00e8s bonne qualit\u00e9. L\u2019une des am\u00e9liorations propos\u00e9es pour ce probl\u00e8me est l\u2019algorithme de Lesk \u00e9tendu."}, {"heading": "3.4.3 Algorithme de Lesk \u00e9tendu", "text": "Banerjee et Pedersen (2002) proposent la mesure de Lesk \u00e9tendu. Cette mesure consiste \u00e0 calculer le recouvrement entre les mots des d\u00e9finitions des deux sens \u00e0 comparer mais aussi les mots des d\u00e9finitions issues de diff\u00e9rentes relations : hypernyms, hyponyms, meronyms, holonyms et attribute, similar-to, also-see18. Cette mesure est sym\u00e9trique : une paire de relation (\ud835\udc451 , \ud835\udc452 ) est conserv\u00e9e si et seulement si la paire inverse (\ud835\udc452 , \ud835\udc451 ) est pr\u00e9sente. Un ensemble de relations possibles est obtenu. Si une relation retourne plusieurs sens, toutes les d\u00e9finitions de ces sens sont conserv\u00e9es. Le recouvrement se calcule par la somme des carr\u00e9s des longueurs de toutes les s\u00e9quences de mots de la d\u00e9finition A dans la d\u00e9finition B. La fonction utilis\u00e9e pour mesurer la similarit\u00e9 se pr\u00e9sente par :\n\ud835\udc46\ud835\udc56\ud835\udc5a\ud835\udc3f\ud835\udc52\ud835\udc60\ud835\udc58\ud835\udc38\ud835\udc61\ud835\udc52\ud835\udc5b\ud835\udc51\ud835\udc62 (\ud835\udc461 , \ud835\udc462) = \u2211 \u2502\ud835\udc37(\ud835\udc451 (\ud835\udc461 )) \u2229 \ud835\udc37(\ud835\udc452 (\ud835\udc462 ))\u2502\n\u2200 (\ud835\udc45 1 ,\ud835\udc45 2\n) \u2208\ud835\udc45\ud835\udc52\ud835\udc59\ud835\udc4e\ud835\udc61\ud835\udc56\ud835\udc5c\ud835\udc5b\ud835\udc602"}, {"heading": "3.5 Notre approche", "text": "Afin de trouver le sens d\u2019un mot dans un paragraphe, nous utilisons d\u2019abord la mesure de similarit\u00e9 distributionnelle de Lin (1998) pour d\u00e9terminer un score entre le mot cible (mot \u00e0 d\u00e9sambigu\u00efser) et l\u2019ensemble des mots du paragraphe qui\n17 TreeTagger, outil d\u2019annotation morphosyntaxique. http://www.cis.uni-muenchen.de/~schmid/tools/TreeTagger\n18 Toutes ces relations sont couvertes dans BabelNet.\n22\u00e8me Traitement Automatique des Langues Naturelles, Caen, 2015\nappartiennent \u00e0 la m\u00eame cat\u00e9gorie grammaticale du mot cible. Cela a pour but de retourner les k meilleurs voisins qui ont le plus grand score. Ce calcul repose sur les cooccurrences extraites \u00e0 partir du corpus de travail. Par la suite nous adaptons une m\u00e9thode structurelle fond\u00e9e sur une distance s\u00e9mantique entre les sens selon une formule propos\u00e9e par Navigli (2009) :\n\ud835\udc7a\u2217 = \ud835\udc4e\ud835\udc5f\ud835\udc54\ud835\udc5a\ud835\udc4e\ud835\udc65\ud835\udc46 \u2208Sens(w) \u2211 \ud835\udc8e\ud835\udc82\ud835\udc99 Score (S, S \u2032)\n\ud835\udc41\ud835\udc56 \u2208\ud835\udc41\ud835\udc64: \ud835\udc41\ud835\udc56 \u2260w\n\ud835\udc46\u2032 \u2208 Sens( \ud835\udc41\ud835\udc56) \ud835\udc4e\ud835\udc63\ud835\udc52\ud835\udc50 \ud835\udc56 = 1 \u2026 \ud835\udc58 et \ud835\udc41\ud835\udc64 = {\ud835\udc411, \ud835\udc412, \u2026 , \ud835\udc41\ud835\udc58} est l\u2019ensemble ordonn\u00e9 des \ud835\udc58 voisins les plus proches du mot cible \ud835\udc64. Sens( \ud835\udc41\ud835\udc56) est l\u2019ensemble des sens du voisin \ud835\udc41\ud835\udc56 et Sens(w) est l\u2019ensemble des sens du mot cible \ud835\udc64. Score (S, S\u2032) est la fonction utilis\u00e9e pour mesurer la similarit\u00e9 entre deux sens S et S\u2032. Nous utilisons les deux algorithmes pr\u00e9sent\u00e9s ci-dessus (algorithme de base de Lesk et algorithme de Lesk \u00e9tendu) et nous comparons notre approche par rapport \u00e0 la variante de Lesk et Babelfy.\nAu niveau de la comparaison des d\u00e9finitions de sens de mots, on peut facilement se retrouver avec des d\u00e9finitions trop concises et il est difficile d\u2019obtenir des distinctions de similarit\u00e9 fines. Pour les trois algorithmes utilis\u00e9s, nous nous servons de l\u2019heuristique suivante une fois on obtient le score final de chaque sens candidat : \u00ab dans le cas o\u00f9 deux sens ou plus poss\u00e8dent le score de similarit\u00e9 le plus grand, le sens retourn\u00e9 est celui qui a le plus grand nombre de connexions s\u00e9mantiques avec les autres sens du r\u00e9seau \u00bb. Nous obtenons cette information directement dans BabelNet gr\u00e2ce \u00e0 sa repr\u00e9sentation graphique. Il est mentionn\u00e9 que le sens d\u2019un mot qui a le plus de connexions s\u00e9mantiques est le plus important. Par exemple, si on prend un extrait d\u2019un texte :\n\u00ab ... Leurs regards recouvraient les eaux du fleuve. Je ne bougeais plus. Ils m'indiquaient l'\u00e9toile du bonheur, quand mon ciel se couvrait de cumulo-nimbus. Je me suis install\u00e9 derri\u00e8re eux, confortablement, et j'ai regard\u00e9 moi aussi couler le fleuve du silence \u2026 \u00bb.\nLe sens de fleuve dans ce texte est \u00ab un cours d\u2019eau naturel recevant des affluents et qui se jette dans une rivi\u00e8re ou dans un autre fleuve \u00bb. Il ne s\u2019agit pas d\u2019un cours d\u2019eau qui se jette dans un oc\u00e9an ou dans une mer. Le bon sens par cet exemple poss\u00e8de 2 026 connexions s\u00e9mantiques et l\u2019autre sens poss\u00e8de 107 connexions s\u00e9mantiques. L\u2019algorithme de Lesk de base et Lesk \u00e9tendu retournent le bon sens, en revanche la variante de Lesk (LeskVariante) se trompe."}, {"heading": "4 Donn\u00e9es des exp\u00e9riences men\u00e9es", "text": "Le tableau 2 ci-dessous r\u00e9sume d\u2019une part le nombre de mots reconnus ou non dans BabelNet par cat\u00e9gorie (mot plein) d\u2019unit\u00e9 lexicale pour les types (mots diff\u00e9rents) et les tokens (ensemble total de mots). D\u2019autre part, les taux de couverture obtenus. La couverture globale pr\u00e9sente le rapport entre les mots reconnus dans BabelNet et l\u2019ensemble des mots du corpus d\u2019\u00e9valuation. La couverture des mots polys\u00e9miques pr\u00e9sente le rapport entre les mots polys\u00e9miques reconnus dans BabelNet et l\u2019ensemble des mots couverts par BabelNet (l\u2019ensemble des mots monos\u00e9miques et polys\u00e9miques).\nPOS\nMots\npolys\u00e9miques\nMots\nmonos\u00e9miques\nMots non reconnus Nombre total\n% couverture\nglobale\n% couverture\nmots\npolys\u00e9miques\nTokens Types Tokens Types Tokens Types Tokens Types Tokens Types Tokens Types\nNoms 1 660 590 130 39 51 28 1 841 657 97,23 95,74 92,74 93,8\nVerbes 1 135 327 31 30 99 47 1 265 404 92,17 88,37 97,34 91,6\nAdjectifs 353 164 28 19 165 48 546 231 69,78 79,22 92,65 89,62\nAdverbes 375 68 79 6 33 14 487 88 93,22 84,09 82,6 91,89\nTotal 3 523 1 149 268 94 348 137 4 139 1 380 91,59 90,07 92,93 92,44\nTableau 2 : Taux de couverture du corpus d\u2019\u00e9valuation par la ressource lexicale BabelNet"}, {"heading": "MOKHTAR BOUMEDYEN BILLAMI", "text": "Nous avons la meilleure couverture globale pour les noms sur les tokens et les types. Nous atteignons 97,23% en tokens contre 92,17% pour les verbes et 95,74% en types contre 88,37% pour les verbes. La couverture en tokens des verbes polys\u00e9miques est forte19 par rapport \u00e0 la couverture des noms polys\u00e9miques (97,34% contre 92,74%). Parmi les cas de non reconnaissance restants, les erreurs d\u2019\u00e9tiquetage morphosyntaxique repr\u00e9sentent la quasi-totalit\u00e9 des cas (seulement 69,78% en tokens reconnus pour les adjectifs). Les mots pleins qui ne sont pas reconnus sont tr\u00e8s peu fr\u00e9quents."}, {"heading": "4.1 Jeu de test", "text": "Nous avons choisi les donn\u00e9es de notre jeu de test selon leur niveau d\u2019ambigu\u00eft\u00e9. Nous avons \u00e0 disposition un corpus d\u2019\u00e9valuation pour lequel il est difficile de faire le choix des mots polys\u00e9miques selon leur fr\u00e9quence d\u2019apparition (peu fr\u00e9quent, fr\u00e9quent et tr\u00e8s fr\u00e9quent). De ce fait, notre choix porte sur le niveau d\u2019ambigu\u00eft\u00e9 (peu ambigu, ambigu et tr\u00e8s ambigu). Nous prenons deux mots polys\u00e9miques pour chaque niveau d\u2019ambig\u00fcit\u00e9 et cela pour les noms et les verbes. Le tableau 3 ci-dessous r\u00e9sume les informations quantitatives utilis\u00e9es pour la s\u00e9lection des mots polys\u00e9miques du jeu de test. Nous consid\u00e9rons les mots qui ont moins de 4 sens comme peu ambigus (cf. tableau 3), les mots qui ont entre 4 et 6 sens comme ambigus et les mots qui ont plus de 6 sens comme tr\u00e8s ambigus.\nPOS Candidat Fr\u00e9quence Nombre de synsets Niveau d\u2019ambig\u00fcit\u00e9\nNoms\nfleuve 3 3\npeu ambigu\nf\u00e9e 8 3\np\u00eacheur 4 4\nambigu\nplante 15 5\ncastor 4 9\ntr\u00e8s ambigu\nsouris 10 9\nVerbes\nplanter 2 3\npeu ambigu\nna\u00eetre 7 3\nobliger 2 5\nambigu\ntaire 9 5\ntroubler 2 7\ntr\u00e8s ambigu\nparler 6 10\nTableau 3 : Mots polys\u00e9miques du jeu de test avec leur fr\u00e9quence d\u2019apparition et niveau d\u2019ambig\u00fcit\u00e9\n5 \u00c9valuation\nPour mesurer les performances des diff\u00e9rentes m\u00e9thodes de d\u00e9sambigu\u00efsation, nous utilisons le taux d\u2019exactitude (accuracy). L\u2019\u00e9valuation de nos m\u00e9thodes est effectu\u00e9e sur des donn\u00e9es dont la couverture des sens par BabelNet est de 100%. Ce taux d\u2019exactitude est calcul\u00e9 pour chaque mot du jeu de test et pour chaque m\u00e9thode de d\u00e9sambigu\u00efsation test\u00e9e. Il pr\u00e9sente le rapport entre le nombre d\u2019occurrences correctement d\u00e9sambigu\u00efs\u00e9es et le nombre total d\u2019occurrences d\u2019un mot. L\u2019ensemble des taux d\u2019exactitude obtenus est r\u00e9sum\u00e9 dans le tableau 4. Notre jeu de test contient 44 occurrences pour 6 noms et 28 occurrences pour 6 verbes (un total de 72 occurrences sur 12 mots diff\u00e9rents). Nous avons affect\u00e9 manuellement \u00e0 chaque occurrence le bon sens propos\u00e9 dans BabelNet. Notre \u00e9valuation porte d\u2019une part sur le niveau d\u2019ambigu\u00eft\u00e9 des mots polys\u00e9miques, d\u2019autre part, sur la mesure distributionnelle utilis\u00e9e pour choisir les k-plus proches\n19 Nous avons une occurrence par verbe monos\u00e9mique (30/31) et une couverture de 327 verbes polys\u00e9miques contre 30 verbes\nmonos\u00e9miques.\n22\u00e8me Traitement Automatique des Langues Naturelles, Caen, 2015\nvoisins (k-PPV). Notre choix s\u2019est port\u00e9 sur trois valeurs diff\u00e9rentes, \ud835\udc58 \u2208 {3, 5, 7}. Nous avons choisi aussi de prendre en compte diff\u00e9rentes versions du corpus de travail afin de mesurer le degr\u00e9 de confiance de notre approche en s\u00e9lectionnant al\u00e9atoirement une partie de l\u2019ensemble des triplets de d\u00e9pendances syntaxiques (30%V1 pour une premi\u00e8re version, 30%V2, 50%V1 et 50%V2) ou la totalit\u00e9 des triplets de d\u00e9pendances. Le tableau 4 pr\u00e9sente les r\u00e9sultats obtenus en tenant compte d\u2019une premi\u00e8re s\u00e9lection de 30% sur l\u2019ensemble des triplets."}, {"heading": "Jeu de test LeskBase Lesk\u00c9tendu LeskVariante Babelfy", "text": "fleuve 100 100 0 100\nf\u00e9e 0 100 100 87,5\np\u00eacheur 0 0 0 0\nplante 86,67 100 80 100\ncastor 100 100 100 100\nsouris 30 100 0 30\nplanter 100 100 100 100\nna\u00eetre 0 85,71 85,71 100\nobliger 50 100 50 100\ntaire erreur POS erreur POS erreur POS -\ntroubler 0 0 0 0\nparler 16,67 100 16,67 50\nTableau 4 : Taux d\u2019exactitude obtenus par m\u00e9thode de Lesk de base, Lesk \u00e9tendu et par s\u00e9lection al\u00e9atoire de 30% (V1)\nsur l\u2019ensemble des triplets pour les 5 plus proches voisins et comparaison avec la m\u00e9thode de Lesk variante et Babelfy\nsur les donn\u00e9es du jeu de test\nLes r\u00e9sultats retourn\u00e9s par l\u2019algorithme de Lesk \u00e9tendu sont int\u00e9ressants en comparaison avec les autres algorithmes ou ce que Babelfy retourne sur l\u2019ensemble des noms \u00e9tudi\u00e9s. Lesk \u00e9tendu retourne le bon sens pour les noms peu ambigus, Babelfy retourne un sens diff\u00e9rent sur une occurrence de f\u00e9e o\u00f9 il a d\u00e9tect\u00e9 une expression polylexicale \u00ab f\u00e9e carabosse \u00bb. Pour les noms ambigus, Lesk \u00e9tendu retourne le bon sens sur toutes les occurrences de plante par contre il se trompe sur toutes les occurrences de p\u00eacheur. Cela en raison qu\u2019il existe deux sens pour lesquels le score retourn\u00e9 par nos m\u00e9thodes est le m\u00eame : (sens 1) \u00ab la p\u00eache est l\u2019activit\u00e9 consistant \u00e0 capturer des animaux aquatiques dans leur milieu naturel \u00bb ; (sens 2) \u00ab personne dont la profession est d'attraper des poissons \u00bb. Sur un extrait de texte : \u00ab \u2026 il fut recueilli par un vieux p\u00e9cheur de saumons \u2026 \u00bb, le bon sens de p\u00eacheur est le deuxi\u00e8me mais le premier est retourn\u00e9 par nos m\u00e9thodes vu qu\u2019il poss\u00e8de plus de connexions s\u00e9mantiques (1 576 contre 355). Pour les noms tr\u00e8s ambigus, Lesk \u00e9tendu ne se trompe pas contrairement \u00e0 Babelfy. Sur quelques textes d\u00e9crivant la souris comme \u00ab genre d\u2019animaux \u00bb, Babelfy retourne une entit\u00e9 nomm\u00e9e \u00ab MouseHunt \u00bb d\u00e9crivant un long m\u00e9trage de Gore Verbinski.\nPour les verbes, il est difficile de juger la sensibilit\u00e9 du taux d\u2019exactitude au niveau d\u2019ambigu\u00eft\u00e9. D\u2019une part, nous avons des erreurs d\u2019\u00e9tiquetage (exp. taire ne se trouve sur aucun des textes utilis\u00e9s), d\u2019autre part, le manque des d\u00e9finitions en fran\u00e7ais dans BabelNet, ce qui permet de retourner dans la plupart des cas le sens le plus fort du verbe \u00e9tudi\u00e9 dans le r\u00e9seau malgr\u00e9 l\u2019utilisation des synonymes. Nous remarquons que l\u2019algorithme de Lesk \u00e9tendu est beaucoup plus r\u00e9gulier par rapport \u00e0 l\u2019algorithme de base de Lesk ou \u00e0 la baseline (Lesk variante). Le meilleur taux d\u2019exactitude que nous obtenons sur l\u2019ensemble des mots \u00e9tudi\u00e9s est celui retourn\u00e9 par l\u2019algorithme de Lesk \u00e9tendu (90,91% pour les noms et 57,14% pour les verbes). Lesk \u00e9tendu est meilleur par rapport \u00e0 Babelfy et Lesk variante pour la d\u00e9sambigu\u00efsation des noms (taux d\u2019exactitude de 72,73% par Babelfy et 54,55% par Lesk variante) ainsi que pour la d\u00e9sambigu\u00efsation des verbes (taux d\u2019exactitude de 50% par Babelfy et 35,71% par Lesk variante). Dans le tableau 5, nous pr\u00e9sentons les r\u00e9sultats obtenus par variation du nombre des voisins les plus proches et par s\u00e9lection al\u00e9atoire ou non (100%) d\u2019un ensemble de d\u00e9pendances syntaxiques.\nMOKHTAR BOUMEDYEN BILLAMI\nAlgorithme de\nLesk \u00e9tendu\nNoms Verbes\nk=3 k=5 k=7 Moyenne \u00c9cart\ntypeP\nk=3 k=5 k=7 Moyenne \u00c9cart\ntypeP\nDepends30%V1 90,91 90,91 84,09 88,64 3,21 50 57,14 60,71 55,95 4,45\nDepends30%V2 84,09 84,09 81,82 83,33 1,07 42,86 39,29 60,71 47,62 9,37\nDepends50%V1 75 90,91 75 80,3 7,5 25 28,57 28,57 27,38 1,68\nDepends50%V2 75 75 84,09 78,03 4,29 35,71 32,14 60,71 42,85 12,71\nDepends100% 84,09 77,27 77,27 79,54 3,21 32,14 60,71 60,71 51,19 13,47\nMoyenne 81,82 83,64 80,45 81,97 1,3 37,14 43,57 54,28 45 7,07\n\u00c9cart typeP 6,1 6,65 3,69 3,76 - 8,63 13,05 12,86 9,80 -\nTableau 5 : Taux d\u2019exactitude obtenus par algorithme de Lesk \u00e9tendu par ensemble de triplets pour k-PPV\nNous remarquons que la variation de l\u2019ensemble des triplets de d\u00e9pendances syntaxiques apporte des r\u00e9sultats diff\u00e9rents pour la d\u00e9sambigu\u00efsation lexicale (diff\u00e9rence l\u00e9g\u00e8re pour les noms mais forte pour les verbes suite au manque des d\u00e9finitions en fran\u00e7ais malgr\u00e9 l\u2019utilisation des synonymes). Les voisins d\u2019un mot \u00e9tudi\u00e9 changent \u00e0 chaque fois o\u00f9 on utilise un ensemble de triplets diff\u00e9rent. Pour l\u2019exemple de plante, nous avons sur un texte les voisins (bande, feuille, oiseau) par s\u00e9lection de 30%V1 sur l\u2019ensemble des triplets alors que nous obtenons un autre ensemble de voisins (animal, insecte, oiseau) par s\u00e9lection de 30%V2. Pour les noms et sur la variation des k voisins les plus proches, nous obtenons le meilleur taux d\u2019exactitude (90,91%) pour \ud835\udc58 \u2208 {3, 5} par rapport au cas o\u00f9 k=7. Cela signifie qu\u2019un petit nombre de voisins est n\u00e9cessaire pour retourner le bon sens pour les noms, ce qui est tout le contraire pour les verbes o\u00f9 le meilleur taux d\u2019exactitude retourn\u00e9 est atteint lorsque \ud835\udc58 = 7. Les r\u00e9sultats montrent qu\u2019on obtient un bon degr\u00e9 de confiance pour les noms (\u00e9cart type de 3,76) par contre un degr\u00e9 de confiance faible pour les verbes (\u00e9cart type de 9,80). Les figures 1 et 2 pr\u00e9sentent les r\u00e9sultats obtenus par utilisation de l\u2019algorithme de Lesk \u00e9tendu respectivement sur les noms et les verbes. Les figures 3 et 4 pr\u00e9sentent les r\u00e9sultats obtenus pour les diff\u00e9rents algorithmes utilis\u00e9s et Babelfy sur un ensemble pr\u00e9cis de d\u00e9pendances syntaxiques.\nL\u2019algorithme Lesk \u00e9tendu retourne le meilleur r\u00e9sultat par rapport \u00e0 la baseline et Babelfy pour les noms et cela sur toutes les variations utilis\u00e9es pour obtenir un ensemble des triplets de d\u00e9pendances syntaxiques. Pour les verbes, quelques s\u00e9lections al\u00e9atoires des triplets de d\u00e9pendances apportent \u00e0 notre approche des r\u00e9sultats faibles par rapport \u00e0 la baseline et Babelfy. L\u2019utilisation d\u2019une autre mesure de similarit\u00e9 qui ne repose pas sur des traits s\u00e9mantiques peut corriger ce probl\u00e8me.\n22\u00e8me Traitement Automatique des Langues Naturelles, Caen, 2015"}, {"heading": "6 Conclusion et perspectives", "text": "Cet article se situe dans le champ de la d\u00e9sambigu\u00efsation lexicale. La m\u00e9thode que nous avons test\u00e9e et \u00e9valu\u00e9e s\u2019appuie sur une s\u00e9lection distributionnelle des voisins les plus proches selon le contexte du mot \u00e0 d\u00e9sambigu\u00efser. Nous avons adapt\u00e9 l\u2019application d\u2019une approche exhaustive pour se comparer avec k-PPV. Cette approche adapt\u00e9e repose sur l\u2019utilisation de mesures de similarit\u00e9 \u00e0 base de traits s\u00e9mantiques. Le contexte utilis\u00e9 dans cette exp\u00e9rience correspond \u00e0 un paragraphe et le corpus d\u2019\u00e9valuation appartient \u00e0 un domaine g\u00e9n\u00e9ral et non pas \u00e0 un domaine de sp\u00e9cialit\u00e9. Le meilleur taux d\u2019exactitude retourn\u00e9 pour les noms est de 90,91% contre 60,71% pour les verbes. La meilleure combinaison retourne 77,78% (k=5 et 30%V1 de l\u2019ensemble des triplets de d\u00e9pendances syntaxiques).\nSur le plan des perspectives de ce travail, nous envisageons d\u2019utiliser d\u2019autres algorithmes locaux pour mesurer la similarit\u00e9 s\u00e9mantique. Par exemple, des algorithmes \u00e0 base de distance taxonomique qui consistent \u00e0 compter le nombre d\u2019arcs qui s\u00e9parent deux sens dans une taxonomie (Wu, Palmer, 1994 ; Hirst, St-Onge, 1998) ou des algorithmes \u00e0 base de contenu informationnel (Resnik, 1995 ; Seco et al., 2004). Nous envisageons aussi de comparer nos r\u00e9sultats avec d\u2019autres algorithmes globaux comme la recherche des cha\u00eenes lexicales (Vasilescu et al., 2004) ou les algorithmes g\u00e9n\u00e9tiques (Gelbukh et al., 2003)."}, {"heading": "Remerciements", "text": "Nous tenons \u00e0 remercier Alexis Nasr qui nous a fourni les donn\u00e9es du corpus de travail, ainsi que N\u00faria Gala pour sa relecture et son encadrement.\nR\u00e9f\u00e9rences\nAudibert, L. (2007). D\u00e9sambigu\u00efsation lexicale automatique : s\u00e9lection automatique d'indices. Traitement Automatique des Langues Naturelles (TALN), Juin 2007, Toulouse, France. IRIT Press, 13-22.\nBanerjee, S., Pedersen, T. (2002). An adapted lesk algorithm for word sense disambiguation using wordnet. In CICLing \u201902, London, UK, 136\u2013145.\nCowie, J., Guthrie, J., Guthrie, L. (1992). Lexical disambiguation using simulated annealing. In COLING 92, Stroudsburg, PA, USA. ACL, 359\u2013365.\nEdmonds, P. (2000). Designing a task for SENSEVAL-2. Tech. note. University of Brighton, Brighton. U.K. Fellbaum, C. Ed. (1998). WordNet: An Electronic Database. MIT Press, Cambridge, MA.\nGelbukh, A., Sidorov, G., Han, S. Y. (2003). Evolutionary approach to natural language word sense disambiguation through global coherence optimization. WSEAS Transactions on Communications, 1(2):11\u201319."}, {"heading": "MOKHTAR BOUMEDYEN BILLAMI", "text": "Hanoka, V., Sagot, B. (2012). Wordnet creation and extension made simple: A multilingual lexicon-based approach using wiki resources. In Proceedings of LREC 2012, Istanbul, Turquie.\nHearst, M. A. (1991). Noun homograph disambiguation using local context in large corpora. Proceedings of the 7th Annual Conf. of the University of Waterloo Centre for the New OED and Text Research, Oxford, United Kingdom, 1-19. Hirst, G., St-Onge, D. D. (1998). Lexical chains as representations of context for the detection and correction of malapropisms. WordNet : An electronic Lexical Database. C. Fellbaum. Ed. MIT Press, 305\u2013332.\nIde, N., V\u00e9ronis, J. (1998). Word sense disambiguation: The state of the art. Computat. Ling. 24, 1, 1\u201340. Lesk, M. (1986). Automatic sense disambiguation using machine readable dictionaries : how to tell a pine cone from an ice cream cone. In Proceedings of the 5th annual international conference on Systems documentation, SIGDOC '86, New York, NY, USA : ACM, 24\u201326.\nLin, D. (1998). An information-theoretic definition of similarity. In Proceedings of the 15th International Conference on Machine Learning (ICML, Madison, WI), 296\u2013304.\nMiller, G. A., Leacock, C., Tengi, R., Bunker, R. T. (1993). A semantic concordance. In Proceedings of the ARPA Workshop on Human Language Technology. 303\u2013308.\nMoro, A., Raganato, A., Navigli, R. (2014). Entity Linking meets Word Sense Disambiguation: a Unified Approach. Transactions of the Association for Computational Linguistics (TACL), 2, 231-244.\nNasr, A., B\u00e9chet, F., Rey, J. F., Favre, B., Le Roux, J. (2011). MACAON: A linguistic tool suite for processing word lattices. The 49th Annual Meeting of the Association for Computational Linguistics. ACTI, 86-91.\nNavigli, R., Ponzetto, S. P. (2012). BabelNet: The Automatic Construction, Evaluation and Application of a WideCoverage Multilingual Semantic Network. Artificial Intelligence, 193, Elsevier, 217-250.\nNavigli, R. (2009). Word Sense Disambiguation : a Survey. ACM Computing Surveys 41(2), ACM Press, 1-69. Ng, T. H. (1997). Getting serious about word sense disambiguation. In Proceedings of the ACL SIGLEX Workshop on Tagging Text with Lexical Semantics: Why, What, and How ? (Washington D.C.), 1\u20137. Ng, H. T., Lee, H. B. (1996). Integrating multiple knowledge sources to disambiguate word sense: An examplar-based approach. Proceedings of the 34th Annual Meeting of the Association for Computational Linguistics, University of California, Santa Cruz, California, 40-47.\nPedersen, T., Banerjee, S., Patwardhan, S. (2005). Maximizing Semantic Relatedness to Perform Word Sense Disambiguation. Research Report UMSI 2005/25, University of Minnesota Supercomputing Institute.\nResnik, P. (1995). Using information content to evaluate semantic similarity in a taxonomy. In IJCAI\u201995, San Francisco, CA, USA, 448\u2013453.\nSeco, N., Veale, T., Hayes, J. (2004). An intrinsic information content metric for semantic similarity in wordnet. In Proceedings of ECAI\u20192004, Valencia, Spain, 1089\u20131090.\nTchechmedjiev, A. (2012). \u00c9tat de l\u2019art : mesures de similarit\u00e9 s\u00e9mantique locales et algorithmes globaux pour la d\u00e9sambigu\u00efsation lexicale \u00e0 base de connaissances. In Proceedings of the Joint Conference JEP-TALN-RECITAL 2012, volume 3: RECITAL,ATALA/AFCP. June 2012, Grenoble, France, 295\u2013308.\nVasilescu, F., Langlais, P., Lapalme, G. (2004). Evaluating variants of the lesk approach for disambiguating words. In Proceedings of LREC 2004, the 4th International Conference On Language Resources And Evaluation, Lisbon, Portugal, 633\u2013636.\nWilks, Y., Stevenson, M. (1996). The grammar of sense: Is word sense tagging much more than part-of-speech tagging ? Technical Report CS-96-05, University of Sheffield, Sheffield, United Kingdom.\nWu, Z., Palmer, M. (1994). Verbs semantics and lexical selection. In Proceedings of the 32nd annual meeting on ACL, volume 2 de ACL \u201994, Stroudsburg, PA, USA. Association for Computational Linguistics, 133\u2013138.\nYarowsky, D (1993). One sense per collocation. In Proceedings of the ARPA Workshop on Human Language Technology (Princeton, NJ), 266\u2013271."}], "references": [], "referenceMentions": [], "year": 2015, "abstractText": "A Knowledge-Based Approach to Word Sense Disambiguation by distributional selection and semantic features. Word sense disambiguation improves many Natural Language Processing (NLP) applications such as Information Retrieval, Information Extraction, Machine Translation, or Lexical Simplification. Roughly speaking, the aim is to choose for each word in a text its best sense. One of the most popular method estimates local semantic similarity relatedness between two word senses and then extends it to all words from text. The most direct method computes a rough score for every pair of word senses and chooses the lexical chain that has the best score (we can imagine the exponential complexity that returns this comprehensive approach). In this paper, we propose to use a combinatorial optimization metaheuristic for choosing the nearest neighbors obtained by distributional selection around the word to disambiguate. The test and the evaluation of our method concern a corpus written in French by means of the semantic network BabelNet. The obtained accuracy rate is 78 % on all names and verbs chosen for the evaluation. Mots-cl\u00e9s : d\u00e9sambigu\u00efsation lexicale non supervis\u00e9e, mesure de similarit\u00e9 distributionnelle, mesures de similarit\u00e9 s\u00e9mantique.", "creator": "Florian Boudin pour TALN Archives"}}}