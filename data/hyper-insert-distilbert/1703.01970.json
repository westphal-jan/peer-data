{"id": "1703.01970", "review": {"conference": "arxiv", "VERSION": "v1", "DATE_OF_SUBMISSION": "6-Mar-2017", "title": "Concentration Bounds for High Sensitivity Functions Through Differential Privacy", "abstract": "a new plain line presentation of related work [ dwork smith et al. | stoc sep 2015 ], [ patrick hardt and felix ullman feb focs dec 2014 ], [ steinke and klaus ullman colt 2015 ], [ bassily et c al. edited stoc 2016 ] specifically demonstrates how limiting differential temporal privacy [ dwork et al. 2006 tcc. 2006 ] can generally be simply used as a simple mathematical tool for guaranteeing polynomial generalization in uniformly adaptive data analysis. specifically, or if a differentially private gamma analysis function is safely applied on all a constrained sample s of measured i. i. \u03b5 d. in examples to informally select a pure low - sensitivity nonlinear function \u03c3 f, then w. k h. p. observes f ( s ) observation is close to its expectation, although else f is necessarily being chosen based on the data.", "histories": [["v1", "Mon, 6 Mar 2017 16:53:32 GMT  (23kb,D)", "http://arxiv.org/abs/1703.01970v1", null]], "reviews": [], "SUBJECTS": "cs.LG", "authors": ["kobbi nissim", "uri stemmer"], "accepted": false, "id": "1703.01970"}, "pdf": {"name": "1703.01970.pdf", "metadata": {"source": "CRF", "title": "Concentration Bounds for High Sensitivity Functions Through Differential Privacy*", "authors": ["Kobbi Nissim", "Uri Stemmer"], "emails": ["kobbi.nissim@georgetown.edu.", "stemmer@cs.bgu.ac.il."], "sections": [{"heading": null, "text": "Very recently, Steinke and Ullman [16] observed that these generalization guarantees can be used for proving concentration bounds in the non-adaptive setting, where the low-sensitivity function is fixed beforehand. In particular, they obtain alternative proofs for classical concentration bounds for low-sensitivity functions, such as the Chernoff bound and McDiarmid\u2019s Inequality.\nIn this work, we set out to examine the situation for functions with high-sensitivity, for which differential privacy does not imply generalization guarantees under adaptive analysis. We show that differential privacy can be used to prove concentration bounds for such functions in the non-adaptive setting.\nKeywords: Differential privacy, concentration bounds, high sensitivity functions\n*Research by K.N. and U.S. is supported by NSF grant No. 1565387. \u2020Dept. of Computer Science, Georgetown University and Center for Research on Computation and Society (CRCS),\nHarvard University. kobbi.nissim@georgetown.edu. \u2021Center for Research on Computation and Society (CRCS), Harvard University. stemmer@cs.bgu.ac.il.\nar X\niv :1\n70 3.\n01 97\n0v 1\n[ cs\n.L G\n] 6\nM ar\n1 Introduction\nA new line of work [6, 9, 15, 2] demonstrates how differential privacy [8] can be used as a mathematical tool for guaranteeing statistical validity in data analysis. Specifically, if a differentially private analysis is applied on a sample S of i.i.d. examples to select a low-sensitivity function f , then w.h.p. f (S) is close to its expectation, even when f is being chosen based on the data. Dwork et al. [6] showed how to utilize this connection for the task of answering adaptively chosen queries w.r.t. an unknown distribution using i.i.d. samples from it.\nTo make the setting concrete, consider a data analyst interested in learning properties of an unknown distribution D. The analyst interacts with the distribution D via a data curator A holding a database S containing n i.i.d. samples from D. The interaction is adaptive, where at every round the analyst specifies a query q : Xn\u2192R and receives an answer aq(S) that (hopefully) approximates q(Dn) , ES \u2032\u223cDn[q(S \u2032)]. As the analyst chooses its queries based on previous interactions with the data, we run the risk of overfitting if A simply answers every query with its empirical value on the sample S. However, if A is a differentially private algorithm then the interaction would not lead to overfitting:\nTheorem 1.1 ([6, 2], informal). A function f : Xn \u2192 R has sensitivity \u03bb if |f (S) \u2212 f (S \u2032)| \u2264 \u03bb for every pair S,S \u2032 \u2208 Xn differing in only one entry. Define f (Dn) , E\nS \u2032\u223cDn [f (S \u2032)]. Let A : Xn \u2192 F\u03bb be\n(\u03b5,\u03b4)-differentially private where F\u03bb is the class of \u03bb-sensitive functions, and n \u2265 1\u03b52 log( 4\u03b5 \u03b4 ). Then for every distribution D on X,\nPr S\u223cDn f\u2190A(S)\n[|f (S)\u2212 f (Dn)| \u2265 18\u03b5\u03bbn] < \u03b4 \u03b5 .\nIn words, if A is a differentially private algorithm operating on a database containing n i.i.d. samples from the distribution D, then A cannot (with significant probability) identify a lowsensitivity function that behaves differently on the sample S and on Dn.\nVery recently, Steinke and Ullman [16] observed that Theorem 1.1 gives alternative proofs for classical concentration bounds for low-sensitivity functions, such as the Chernoff bound and McDiarmid\u2019s Inequality: Fix a function f : Xn \u2192 R with sensitivity \u03bb and consider the trivial mechanismAf that ignores its input and always outputs f . Such a mechanism is (\u03b5,\u03b4)-differentially private for any choice of \u03b5,\u03b4 \u2265 0 and hence Theorem 1.1 yields (up to constants) McDiarmid\u2019s Inequality:\nPr S\u223cDn [|f (S)\u2212 f (Dn)| \u2265 18\u03b5\u03bbn] < \u03b4 \u03b5 = 2\u2212\u2126(\u03b5 2\u00b7n), (1)\nwhere the last equality follows by setting n = 1\u03b52 log( 4\u03b5 \u03b4 ).\nIn light of this result it is natural to ask if similar techniques yield concentration bounds for more general families of queries, and in particular queries that are not low-sensitivity functions. In this work we derive conditions under which this is the case.\n1.1 Differential Privacy, Max-Information, and Typical Stability\nLet D be a fixed distribution over a domain X, and consider a family of functions mapping databases in Xn to the reals, such that for every function f in the family we have that |f (S)\u2212 f (Dn)| is small w.h.p. over S \u223c Dn. Specifically,\nF\u03b1,\u03b2(D) = { f : Xn\u2192R : Pr\nS\u223cDn [|f (S)\u2212 f (Dn)| > \u03b1] \u2264 \u03b2\n} .\nThat is, for every function f \u2208 F\u03b1,\u03b2(D) we have that its empirical value over a sample S \u223c Dn is \u03b1-close to its expected value w.p. 1\u2212 \u03b2. Now consider a differentially private algorithm A : Xn\u2192 F\u03b1,\u03b2(D) that takes a database and returns a function from F\u03b1,\u03b2(D). What can we say about the difference |f (S)\u2212 f (Dn)| when f is chosen by A(S) based on the sample S itself?\nUsing the notion of max-information, Dwork et al. [5] showed that if \u03b2 is small enough, then w.h.p. the difference remains small. Informally, they showed that if A is differentially private, then\nPr S\u223cDn f\u2190A(S)\n[|f (S)\u2212 f (Dn)| > \u03b1] \u2264 \u03b2 \u00b7 e\u03b5 2\u00b7n.\nSo, if A is a differentially private algorithm that ranges over functions which are very concentrated around their expected value (i.e., \u03b2 < e\u2212\u03b5\n2n), then |f (S)\u2212 f (Dn)| remains small (w.h.p.) even when f is chosen by A(S) based on the sample S. When \u03b2 > e\u2212\u03b52n it is easy to construct examples where a differentially private algorithm identifies a function f \u2208 F\u03b1,\u03b2(D) such that |f (S)\u2212f (Dn)| is arbitrarily large with high probability. So, in general, differential privacy does not guarantee generalization for adaptively chosen functions of this sort. However, a stronger notion than differential privacy \u2013 typical stability \u2013 presented by Bassily and Freund [1] does guarantee generalization in this setting. Informally, they showed that if a typically stable algorithm B outputs a function f \u2208 F\u03b1,\u03b2(D), then |f (S)\u2212 f (Dn)| remains small.1\nThe results of this article provide another piece of this puzzle, as we show that (a variant of) differential privacy can in some cases be used to prove that a function f is in F\u03b1,\u03b2(D).\n1.2 Our Results\nNotation. Throughout this article we use the convention that f (Dn) is the expected value of the function f over a sample containing n i.i.d. elements drawn according to the distribution D. That is, f (Dn) , E\nS\u223cDn [f (S)].\nFix a function f : Xn\u2192R, let D be a distribution over X, and let S \u223c Dn. Our goal is to bound the probability that |f (S)\u2212 f (Dn)| is large by some (hopefully) easy-to-analyze quantity. To intuit our result, consider for example what we get by a simple application of Markov\u2019s Inequality:\nPr S\u223cDn [|f (S)\u2212 f (Dn)| > \u03bb] \u2264 1 \u03bb \u00b7 E S\u223cDn\n[ 1|f (S)\u2212f (Dn)|>\u03bb \u00b7 |f (S)\u2212 f (Dn)| ] . (2)\nWe show that using differential privacy we can replace the term |f (S)\u2212f (Dn)| in the expectation with |f (S \u222a {x})\u2212 f (S \u222a {y})|, which can sometimes be easier to analyze. Specifically, we show the following.\nTheorem 1.2 (part 1). Let D be a distribution over a domain X, let f : Xn\u2192R , and let \u2206,\u03bb \u2208R\u22650 be s.t. for every 1 \u2264 i \u2264 n it holds that\nE S\u223cDn z\u223cD\n[ 1|f (S)\u2212f (S(i\u2190z))|>\u03bb \u00b7 \u2223\u2223\u2223\u2223f (S)\u2212 f (S(i\u2190z))\u2223\u2223\u2223\u2223] \u2264 \u2206, (3) where S(i\u2190z) is the same as S except that the ith element is replaced with z. Then for every \u03b5 > 0 we have that\nPr S\u223cDn [|f (S)\u2212 f (Dn)| \u2265 18\u03b5\u03bbn] < 14\u2206 \u03b5\u03bb ,\nprovided that n \u2265O (\n1 \u03b5\u00b7min{1,\u03b5} log( \u03bb\u00b7min{1,\u03b5} \u2206 )\n) .\n1A similar notion \u2013 perfect generalization \u2013 was presented in [4].\nObserve that for a \u03bb-sensitive function f , we have that the expectation in Equation (3) is zero, so the statement holds for every choice of \u03b2 > 0 and n \u2265 O ( 1 \u03b52 log( 1 \u03b2 ) ) , resulting in McDiarmid\u2019s Inequality (Equation (1)). Intuitively, Theorem 1.2 states that in order to obtain a high probability\nbound on |f (S)\u2212 f (Dn)| is suffices to analyze the \u201cexpectation of the tail\u201d of \u2223\u2223\u2223\u2223f (S)\u2212 f (S(i\u2190z))\u2223\u2223\u2223\u2223, as a function of the starting point \u03bb. We also show that the above bound can be improved whenever the \u201cexpectation of the head\u201d of\u2223\u2223\u2223\u2223f (S)\u2212 f (S(i\u2190z))\u2223\u2223\u2223\u2223 is smaller than \u03bb. Specifically,\nTheorem 1.2 (part 2). If, in addition to (3), \u2203\u03c4 \u2264 \u03bb s.t. for every S \u2208 Xn and every 1 \u2264 i \u2264 n we have\nE y,z\u223cD\n[ 1|f (S(i\u2190y))\u2212f (S(i\u2190z))|\u2264\u03bb \u00b7 \u2223\u2223\u2223\u2223f (S(i\u2190y))\u2212 f (S(i\u2190z))\u2223\u2223\u2223\u2223] \u2264 \u03c4, (4) Then for every \u03b5 > 0 we have that\nPr S\u223cDn [|f (S)\u2212 f (Dn)| \u2265 18\u03b5\u03c4n] < 14\u2206 \u03b5\u03c4 ,\nprovided that n \u2265O (\n\u03bb \u03b5\u00b7min{1,\u03b5}\u03c4 log( \u03c4 \u00b7min{1,\u03b5} \u2206 ) ) Observe that while the expectation in (3) is over the entire sample S (as well as the replacement point), in requirement (4) the sample S is fixed. We do not know if this \u201cworst-case\u201d restriction is necessary.\nIn Section 4 we demonstrate how Theorem 1.2 can be used in proving a variety of concentration bounds, such as a high probability bound on |f (S)\u2212 f (Dn)| for Lipschitz functions. In addition we show that Theorem 1.2 can be used to bound the probability that the number of triangles in a random graph significantly exceeds the expectation.\n2 Preliminaries\n2.1 Differential Privacy\nOur results rely on a number of basic facts about differential privacy. An algorithm operating on databases is said to preserve differential privacy if a change of a single record of the database does not significantly change the output distribution of the algorithm. Formally:\nDefinition 2.1. Databases S \u2208 Xn and S \u2032 \u2208 Xn over a domain X are called neighboring if they differ in exactly one entry.\nDefinition 2.2 (Differential Privacy [8, 7]). A randomized algorithmA : Xn\u2192 Y is ( ,\u03b4)-differentially private if for all neighboring databases S,S \u2032 \u2208 Xn, and for every set of outputs T \u2286 Y , we have\nPr[A(S) \u2208 T ] \u2264 e\u03b5 \u00b7Pr[A(S \u2032) \u2208 T ] + \u03b4.\nThe probability is taken over the random coins of A.\n2.2 The Exponential Mechanism\nWe next describe the exponential mechanism of McSherry and Talwar [14].\nDefinition 2.3 (Sensitivity). The sensitivity (or global sensitivity) of a function f : Xn\u2192 R is the smallest \u03bb such that for every neighboring S,S \u2032 \u2208 Xn, we have |f (S)\u2212 f (S \u2032)| \u2264 \u03bb. We use the term \u201c\u03bb-sensitive function\u201d to mean a function of sensitivity \u2264 \u03bb.\nLetX be a domain andH a set of solutions. Given a database S \u2208 X\u2217, the exponential mechanism privately chooses a \u201cgood\u201d solution h out of the possible set of solutions H . This \u201cgoodness\u201d is quantified using a quality function that matches solutions to scores.\nDefinition 2.4 (Quality function). A quality function is a function q : X\u2217 \u00d7H \u2192 R that maps a database S \u2208 X\u2217 and a solution h \u2208H to a real number, identified as the score of the solution h w.r.t. the database S.\nGiven a quality function q and a database S, the goal is to chooses a solution h approximately maximizing q(S,h). The exponential mechanism chooses a solution probabilistically, where the probability mass that is assigned to each solution h increases exponentially with its quality q(S,h):\nThe Exponential Mechanism Input: privacy parameter \u03b5 > 0, finite solution set H , database S \u2208 Xn, and a \u03bb-sensitive quality function q.\n1. Randomly choose h \u2208H with probability exp( \u03b5 2\u03bb \u00b7q(S,h))\u2211 h\u2032\u2208H exp( \u03b52\u03bb \u00b7q(S,h\u2032)) .\n2. Output h.\nTheorem 2.5 (Properties of the exponential mechanism). (i) The exponential mechanism is (\u03b5,0)differentially private. (ii) Let Opt(S) ,maxf \u2208H {q(S,f )} and \u2206 > 0. The exponential mechanism outputs a solution h such that q(S,h) \u2264 (Opt(S)\u2212\u2206) with probability at most |H | \u00b7 exp ( \u2212 \u03b5\u22062\u03bb ) .\n2.3 Concentration Bounds\nLet X1, . . . ,Xn be independent random variables where Pr[Xi = 1] = p and Pr[Xi = 0] = 1 \u2212 p for some 0 < p < 1. Clearly, E[ \u2211n i=1Xi] = pn. Chernoff and Hoeffding bounds show that the sum is concentrated around this expected value:\nPr  n\u2211 i=1 Xi > (1 + \u03b4)pn  \u2264 exp(\u2212pn\u03b42/3) for 0 < \u03b4 \u2264 1, Pr\n n\u2211 i=1 Xi < (1\u2212 \u03b4)pn  \u2264 exp(\u2212pn\u03b42/2) for 0 < \u03b4 < 1, Pr\n \u2223\u2223\u2223\u2223\u2223\u2223\u2223 n\u2211 i=1 Xi \u2212 pn \u2223\u2223\u2223\u2223\u2223\u2223\u2223 > \u03b4  \u2264 2exp(\u22122\u03b42/n) for \u03b4 \u2265 0.\nThe first two inequalities are known as the multiplicative Chernoff bounds [3], and the last inequality is known as the Hoeffding bound [10]. The next theorem states that the Chernoff bound above is tight up to constant factors in the exponent.\nTheorem 2.6 (Tightness of Chernoff bound [12]). Let 0 < p,\u03b4 \u2264 12 , and let n \u2265 3 \u03b42p . Let X1, . . . ,Xn be independent random variables where Pr[Xi = 1] = p and Pr[Xi = 0] = 1\u2212 p. Then,\nPr  n\u2211 i=1 Xi \u2264 (1\u2212 \u03b4)pn  \u2265 exp(\u22129\u03b42pn), Pr\n n\u2211 i=1 Xi \u2265 (1 + \u03b4)pn  \u2265 exp(\u22129\u03b42pn). 3 Concentration Bounds via Differential Privacy\nIn this section we show how the concept of differential privacy can be used to derive conditions under which a function f and a distributionD satisfy that |f (S)\u2212f (Dn)| is small w.h.p. when S \u223c Dn. Our proof technique builds on the proof of Bassily et al. [2] for the generalization properties of a differentially private algorithm that outputs a low-sensitivity function. The proof consists of two steps:\n1. Let S1, . . . ,ST be T independent samples from Dn (each containing n i.i.d. samples from D). Let A be selection procedure that, given S1, . . . ,ST , chooses an index t \u2208 [T ] with the goal of maximizing |f (St)\u2212 f (Dn)|. We show that if A satisfies (a variant of) differential privacy then, under some conditions on the function f and the distribution D, the expectation of |f (St)\u2212 f (Dn)| is bounded. That is, if A is differentially private, then its ability to identify a \u201cbad\u201d index t with large |f (St)\u2212 f (Dn)| is limited.\n2. We show that if |f (S)\u2212 f (Dn)| is large w.h.p. over S \u223c Dn, then it is possible to construct an algorithm A satisfying (a variant of) differential privacy that contradicts our expectation bound.\nWe begin with a few definitions.\n3.1 Definitions\nNotations. We use ~S \u2208 (Xn)T to denote a multi-database consisting of T databases of size n over X. Given a distribution D over a domain X we write ~S \u223c DnT to denote a multi-database sampled i.i.d. from D.\nDefinition 3.1. Fix a function f : Xn \u2192 R mapping databases of size n over a domain X to the reals. We say that two multi-databases ~S = (S1, . . . ,ST ) \u2208 (Xn)T and ~S \u2032 = (S \u20321, . . . ,S \u2032 T ) \u2208 (X\nn)T are (f ,\u03bb)-neighboring if for all 1 \u2264 i \u2264 T we have that\n|f (Si)\u2212 f (S \u2032i )| \u2264 \u03bb.\nDefinition 3.2 ((\u03b5, (f ,\u03bb))-differential privacy). Let M : (Xn)T \u2192 Y be a randomized algorithm that operates on T databases of size n from X. For a function f : Xn \u2192 R and parameters \u03b5,\u03bb \u2265 0, we say that M is (\u03b5, (f ,\u03bb))-differentially private if for every set of outputs F \u2208 Y and for every (f ,\u03bb)-neighboring ~S, ~S \u2032 \u2208 (Xn)T it holds that\nPr[M(~S) \u2208 F] \u2264 e\u03b5 \u00b7Pr[M(~S \u2032) \u2208 F].\nClaim 3.3. Fix a function f : Xn\u2192R and parameters \u03b5 \u2264 1 and \u03bb \u2265 0. If M : (Xn)T \u2192 Y is (\u03b5, (f ,\u03bb))differentially private then for every (f ,\u03bb)-neighboring databases ~S, ~S \u2032 \u2208 (Xn)T and every function h : Y \u2192R we have that\nE y\u2190M(~S) [h(y)] \u2264 E y\u2190M(~S \u2032) [h(y)] + 4\u03b5 \u00b7 E y\u2190M(~S \u2032) [|h(y)|] .\nClaim 3.3 follows from basic arguments in differential privacy. The proof appears in the appendix for completeness.\n3.2 Multi Sample Expectation Bound\nThe proof of Theorem 1.2 contains somewhat unwieldy notation. For readability, we present here a restricted version of the theorem, tailored to the case where the function f computes the sample sum, which highlights most of the ideas in the proof. The full proof of Theorem 1.2 is included in the appendix. Notation. Given a sample S \u2208 Xn, we use f\u0304 (S) to denote the sample sum, i.e., f\u0304 (S) = \u2211 x\u2208S x.\nLemma 3.4 (Simplified Expectation Bound). Let D be a distribution over a domain X such that E x\u223cD [x] = 0 and E x\u223cD [ 1{|x|>1} \u00b7 |x| ] \u2264 \u2206. Fix 0 < \u03b5 \u2264 1, and letA : (Xn)T \u2192 [T ] be an (\u03b5, (f\u0304 ,1))-differentially private algorithm that operates on T databases of size n from X, and outputs an index 1 \u2264 t \u2264 T . Then\u2223\u2223\u2223\u2223\u2223\u2223\u2223\u2223\u2223\u2223 E~S\u223cDnTt\u2190A(~S) [ f\u0304 (St)\n]\u2223\u2223\u2223\u2223\u2223\u2223\u2223\u2223\u2223\u2223 \u2264 4\u03b5n+ 2nT\u2206. Proof. We denote ~S = (S1, . . . ,ST ), where every St is itself a vector St = (xt,1, . . . ,xt,n). We have:\nE ~S\u223cDnT t\u2190A(~S)\n[ f\u0304 (St) ] = \u2211 i\u2208[n] E ~S\u223cDnT E t\u2190A(~S) [ xt,i ]\n= \u2211 i\u2208[n] E ~S\u223cDnT 1{max m\u2208[t] |xm,i | \u2264 1 } \u00b7 E t\u2190A(~S) [ xt,i ] +1 { max m\u2208[t] |xm,i | > 1 } \u00b7 E t\u2190A(~S) [ xt,i ] . (5) In the case where maxm\u2208[t] |xm,i | > 1 we replace the expectation over t\u2190A(~S) with the deterministic choice for the maximal t (this makes the expression larger). When maxm\u2208[t] |xm,i | \u2264 1 we can use the privacy guarantees of algorithm A. Given a multi-sample ~S \u2208 (Xn)T we use ~S\u2212i to denote a multi-sample identical to ~S, except that the ith element of every sub-sample is replaced with 0. Using Claim 3.3 we get\n(5) \u2264 \u2211 i\u2208[n] E ~S\u223cDnT 1{max m\u2208[t] |xm,i | \u2264 1 } \u00b7  E t\u2190A(~S\u2212i ) [ xt,i ] + 4\u03b5 E t\u2190A(~S\u2212i ) [ |xt,i | ]+1{max m\u2208[t] |xm,i | > 1 } \u00b7 max m\u2208[T ] |xm,i | \n\u2264 4\u03b5n + \u2211 i\u2208[n] E ~S\u223cDnT 1{max m\u2208[t] |xm,i | \u2264 1 } \u00b7 E t\u2190A(~S\u2212i ) [ xt,i ] +1 { max m\u2208[t] |xm,i | > 1 } \u00b7 max m\u2208[T ] |xm,i |  (6)\nWe next want to remove the first indicator function. This is useful as without it, the expectation of a fresh example from D is zero. To that end we add and subtract the expression 1 { maxm\u2208[t] |xm,i | > 1 } \u00b7 E t\u2190A(~S\u2212i ) [ xt,i ] to get (after replacing again Et with maxt)\n(6) \u2264 4\u03b5n + \u2211 i\u2208[n] E ~S\u223cDnT  E t\u2190A(~S\u2212i ) [ xt,i ] + 2 \u00b71 { max m\u2208[t] |xm,i | > 1 } \u00b7 max m\u2208[T ] |xm,i | \n\u2264 4\u03b5n + 2 \u2211 i\u2208[n] \u2211 m\u2208[T ] E ~S\u223cDnT [ 1 { |xm,i | > 1 } \u00b7 |xm,i | ] \u2264 4\u03b5n + 2nT\u2206.\n3.3 Multi Sample Amplification\nTheorem 3.5 (Simplified High Probability Bound). Let D be a distribution over a domain X such that E x\u223cD [x] = 0. Let \u2206 \u2265 0 be such that E x\u223cD [ 1{|x|>1} \u00b7 |x| ] \u2264 \u2206. Fix 1 \u2265 \u03b5 \u2265 \u221a 1 n ln(2/\u2206). We have that\nPr S\u223cDn\n[ |f\u0304 (S)| \u2265 30\u03b5n ] < \u2206\n\u03b5 .\nWe present the proof idea of the theorem. Any informalities made hereafter are removed in Section A.\nProof sketch. We only analyze the probability that f\u0304 (S) is large. The analysis is symmetric for when f\u0304 (S) is small. Assume towards contradiction that with probability at least \u22062\u03b5 we have that f\u0304 (S) \u2265 30\u03b5n. We now construct the following algorithm B that contradicts our expectation bound.\nAlgorithm 1 B\nInput: T databases of size n each: ~S = (S1, . . . ,ST ), where T , b2\u03b5/\u2206c.\n1. For i \u2208 [T ], define q(~S, i) = f\u0304 (Si). 2. Sample t\u2217 \u2208 [T ] with probability proportional to exp ( \u03b5 2q(~S, t) ) .\nOutput: t.\nThe fact that algorithm B is (\u03b5, (f\u0304 ,1))-differentially private follows from the standard analysis of the Exponential Mechanism of McSherry and Talwar [14]. The analysis appears in the full version of this proof (Section A) for completeness.\nNow consider applying B on databases ~S = (S1, . . . ,ST ) containing i.i.d. samples from D. By our assumption on D, for every t we have that f\u0304 (St) \u2265 30\u03b5n with probability at least \u22062\u03b5 . By our choice of T = b2\u03b5/\u2206c, we therefore get\nPr ~S\u223cDnT [ max t\u2208[T ] { f\u0304 (St) } \u2265 30\u03b5n ] \u2265 1\u2212 ( 1\u2212 \u2206 2\u03b5 )T \u2265 1 2 .\nThe probability is taken over the random choice of the examples in ~S according to D. Had it been the case that the random variable maxt\u2208[T ] { f\u0304 (St) } is non-negative, we could have used Markov\u2019s\ninequality to get\nE ~S\u223cDnT [ max t\u2208[T ] { q(~S, t) }] = E ~S\u223cDnT [ max t\u2208[T ] { f\u0304 (St) }] \u2265 15\u03b5n. (7)\nEven though it is not the case that maxt\u2208[T ] { f\u0304 (St) } is non-negative, we now proceed as if Equation (7) holds. As described in the full version of this proof (Section A), this technical issue has an easy fix. So, in expectation, maxt\u2208[T ] ( q(~S, t) ) is large. In order to contradict the expectation bound of Theorem A.2, we need to show that this is also the case for the index t\u2217 that is sampled on Step 2. To that end, we now use the following technical claim, stating that the expected quality of a solution sampled as in Step 2 is high.\nClaim 3.6 (e.g., [2]). Let H be a finite set, h :H \u2192R a function, and \u03b7 > 0. Define a random variable Y on H by Pr[Y = y] = exp(\u03b7h(y))/C, where C = \u2211 y\u2208H exp(\u03b7h(y)). Then E [h(Y )] \u2265 maxy\u2208H h(y) \u2212 1 \u03b7 ln |H |.\nFor every fixture of ~S, we can apply Claim 3.6 with h(t) = q(~S, t) and \u03b7 = \u03b52 to get\nE t\u2217\u2208R[T ] [q(~S, t\u2217)] = E t\u2217\u2208R[T ]\n[ f\u0304 (St\u2217) ] \u2265max t\u2208[T ] { f\u0304 (St) } \u2212 2 \u03b5 ln(T ).\nTaking the expectation also over ~S \u223c DnT we get that\nE ~S\u223cDnT t\u2217\u2190B ( ~S ) [ f\u0304 (St\u2217) ] \u2265 E ~S\u223cDnT [ max t\u2208[T ] { f\u0304 (St) }] \u2212 2 \u03b5 ln(T )\n\u2265 15\u03b5n\u2212 2 \u03b5 ln(T ).\nThis contradicts Theorem A.2 whenever \u03b5 > \u221a\n1 n ln(T ) = \u221a 1 n ln(2\u03b5/\u2206).\n4 Applications\nIn this section we demonstrate how Theorem 1.2 can be used in proving a variety of concentration bounds.\n4.1 Example: Subgaussian Diameter and Beyond\nRecall that for a low-sensitivity function f , one could use McDiarmid\u2019s Inequality to obtain a high probability bound on the difference |f (S)\u2212 f (Dn)|, and this bound is distribution-independent. That is, the bound does not depend onD. Over the last few years, there has been some work on providing distribution-dependent refinements to McDiarmid\u2019s Inequality, that hold even for functions with high worst-case sensitivity, but with low \u201caverage-case\u201d sensitivity, where \u201caverage\u201d is with respect to the underlying distribution D. The following is one such refinement, by Kontorovich [13].\nDefinition 4.1 ([13]). Let D be a distribution over a domain X, and let \u03c1 : X2 \u2192 R\u22650. The symmetrized distance of (X,\u03c1,D) is the random variable \u039e = \u03be \u00b7\u03c1(x,x\u2032) where x,x\u2032 \u223c D are independent and \u03be is uniform on {\u00b11} independent of x,x\u2032. The subgaussian diameter of (X,\u03c1,D), denoted \u2206SG(X,\u03c1,D), is the smallest \u03c3 \u2208R\u22650 such that\nE [ e\u03bb\u039e ] \u2264 e\u03c3 2\u03bb2/2, \u2200\u03bb \u2208R.\nIn [13], Kontorovich showed the following theorem:\nTheorem 4.2 ([13], informal). Let f : Xn\u2192R be a function mapping databases of size n over a domain X to the reals. Assume that there exists a function \u03c1 : X2\u2192R\u22650 s.t. for every i \u2208 [n], every S \u2208 Xn, and every y,z \u2208 X we have that \u2223\u2223\u2223\u2223f (S(i\u2190y))\u2212 f (S(i\u2190z))\u2223\u2223\u2223\u2223 \u2264 \u03c1(y,z), where S(i\u2190x) is the same as S except that the ith element is replaced with x. Then,\nPr S\u223cDn [|f (S)\u2212 f (Dn)| \u2265 t] \u2264 2exp \u2212 t22n \u00b7\u22062SG(X,\u03c1,D)  . Informally, using the above theorem it is possible to obtain concentration bounds for functions with unbounded sensitivity (in worst case), provided that the sensitivity (as a random variable) is subgaussian. In this section we show that our result implies a similar version of this theorem. While the bound we obtain is weaker then Theorem 4.2, our techniques can be extended to obtain concentration bounds even in cases where the sensitivity is not subgaussian (that is, in cases where the subgaussian diameter is unbounded, and hence, Theorem 4.2 could not be applied).\nLet us denote \u03c3 = \u2206SG(X,\u03c1,D). Now for t \u2265 0,\nPr x,y\u223cD [\u03c1(x,y) \u2265 t] \u2264 2 Pr x,y\u2208D \u03be\u2208{\u00b11}\n[\u03be \u00b7 \u03c1(x,y) \u2265 t] = 2Pr[\u039e \u2265 t] = 2Pr[e t \u03c32 \u00b7\u039e \u2265 e t \u03c32 \u00b7t]\n\u2264 2e\u2212 t2 \u03c32 \u00b7E [ e t \u03c32 \u00b7\u039e ] \u2264 2e\u2212 t2 \u03c32 \u00b7 e \u03c32 2 \u00b7 t2 \u03c34 = 2exp ( \u2212 t 2\n2\u03c32\n) . (8)\nSo,\nE S\u223cDn x\u2032\u223cD\n[ 1 {\u2223\u2223\u2223\u2223f (S)\u2212 f (S(i\u2190x\u2032))\u2223\u2223\u2223\u2223 > \u03bb} \u00b7 \u2223\u2223\u2223\u2223f (S)\u2212 f (S(i\u2190x\u2032))\u2223\u2223\u2223\u2223] \u2264 E x,y\u223cD [1 { \u03c1(x,y) > \u03bb } \u00b7 \u03c1(x,y)]\n= \u222b \u03bb\n0 Pr x,y\u223cD [1\n{ \u03c1(x,y) > \u03bb } \u00b7 \u03c1(x,y) \u2265 t]dt + \u222b \u221e \u03bb Pr x,y\u223cD [1 { \u03c1(x,y) > \u03bb } \u00b7 \u03c1(x,y) \u2265 t]dt\n= \u222b \u03bb\n0 Pr x,y\u223cD [\u03c1(x,y) \u2265 \u03bb]dt + \u222b \u221e \u03bb Pr x,y\u223cD [\u03c1(x,y) \u2265 t]dt\n= \u03bb \u00b7 Pr x,y\u223cD [\u03c1(x,y) \u2265 \u03bb] + \u222b \u221e \u03bb Pr x,y\u223cD [\u03c1(x,y) \u2265 t]dt\n\u2264 \u03bb \u00b7 2exp ( \u2212 \u03bb 2\n2\u03c32\n) + \u222b \u221e \u03bb 2exp ( \u2212 t 2 2\u03c32 ) dt\n= \u03bb \u00b7 2exp ( \u2212 \u03bb 2\n2\u03c32\n) + \u221a 2\u03c0\u03c3 \u00b7 erfc ( \u03bb \u221a\n2\u03c3 ) \u2264 \u03bb \u00b7 2exp ( \u2212 \u03bb 2\n2\u03c32\n) + \u221a 2\u03c0\u03c3 \u00b7 exp ( \u2212 \u03bb 2\n2\u03c32\n) \u2264 3(\u03bb+ \u03c3 ) \u00b7 exp ( \u2212 \u03bb 2\n2\u03c32\n) , \u2206.\nIn order to apply Theorem 1.2 we need to ensure that n \u2265 O (\n1 \u03b5\u00b7min{1,\u03b5} ln\n( \u03bb\u00b7min{1,\u03b5}\n\u2206\n)) . For our\nchoice of \u2206, it suffices to set \u03b50 = \u0398 ( \u03bb\u221a n\u03c3 ) , assuming that \u03bb\u221a n\u03c3 \u2264 1. Otherwise, if \u03bb\u221a n\u03c3 > 1, we will\nchoose \u03b51 = \u0398 ( \u03bb2\nn\u03c32\n) . Plugging (\u03b50,\u2206) or (\u03b51,\u2206) into Theorem 1.2, and simplifying, we get\nPr S\u223cD\n[|f (S)\u2212 f (Dn)| \u2265 t] \u2264  e \u2212\u2126 ( t\u221a n\u03c3 ) , t \u2264 \u03c3 \u00b7n1.5\ne \u2212\u2126\n( t2/3\n\u03c32/3 ) , t > \u03c3 \u00b7n1.5\n(9)\nClearly, the bound of Theorem 4.2 is stronger. Note, however, that the only assumption we used here is that \u222b\u221e \u03bb\nPrx,y\u223cD[\u03c1(x,y) \u2265 t]dt is small. Hence, as the following section shows, this argument could be extended to obtain concentration bounds even when \u2206SG(X,\u03c1,D) is unbounded. We remark that Inequality 9 can be slightly improved by using part 2 of Theorem 1.2. This will be illustrated in the following section.\n4.2 Example: Concentration Under Infinite Variance\nLet f : Xn\u2192R be a function mapping databases of size n over a domain X to the reals. Assume that there exists a function \u03c1 : X2\u2192 R\u22650 s.t. for every i \u2208 [n], every S \u2208 Xn, and every y,z \u2208 X we have that \u2223\u2223\u2223\u2223f (S(i\u2190y))\u2212 f (S(i\u2190z))\u2223\u2223\u2223\u2223 \u2264 \u03c1(y,z), where S(i\u2190x) is the same as S except that the ith element is replaced with x.\nAs stated in the previous section, the results of [13] can be used to obtain a high probability bound on |f (S)\u2212 f (Dn) | whenever Prx,y\u223cD[\u03c1(x,y) \u2265 t] \u2264 exp ( \u2212t2/\u03c32 ) for some \u03c3 > 0. In contrast,\nour bound can be used whenever \u222b\u221e \u03bb\nPrx,y\u223cD[\u03c1(x,y) \u2265 t]dt is finite. In particular, we now use it to obtain a concentration bound for a case where the probability distribution of \u03c1(x,y) is heavy tailed, and in fact, has infinite variance. Specifically, assume that all we know on \u03c1(x,y) is that Pr[\u03c1(x,y) \u2265 t] \u2264 1/t2 for every t \u2265 1 (this is a special case of the Pareto distribution, with infinite variance). Let \u03bb \u2265 1. We calculate:\nE S\u223cDn x\u2032\u223cD\n[ 1 {\u2223\u2223\u2223\u2223f (S)\u2212 f (S(i\u2190x\u2032))\u2223\u2223\u2223\u2223 > \u03bb} \u00b7 \u2223\u2223\u2223\u2223f (S)\u2212 f (S(i\u2190x\u2032))\u2223\u2223\u2223\u2223] \u2264 E x,y\u223cD [1 { \u03c1(x,y) > \u03bb } \u00b7 \u03c1(x,y)]\n= \u222b \u03bb\n0 Pr x,y\u223cD [1\n{ \u03c1(x,y) > \u03bb } \u00b7 \u03c1(x,y) \u2265 t]dt + \u222b \u221e \u03bb Pr x,y\u223cD [1 { \u03c1(x,y) > \u03bb } \u00b7 \u03c1(x,y) \u2265 t]dt\n= \u222b \u03bb\n0 Pr x,y\u223cD [\u03c1(x,y) \u2265 \u03bb]dt + \u222b \u221e \u03bb Pr x,y\u223cD [\u03c1(x,y) \u2265 t]dt\n= \u03bb \u00b7 Pr x,y\u223cD [\u03c1(x,y) \u2265 \u03bb] + \u222b \u221e \u03bb Pr x,y\u223cD [\u03c1(x,y) \u2265 t]dt \u2264 \u03bb 1 \u03bb2 + \u222b \u221e \u03bb 1 t2 dt = 2 \u03bb , \u2206.\nIn order to apply Theorem 1.2 we need to ensure that n \u2265O (\n1 \u03b5\u00b7min{1,\u03b5} ln\n( \u03bb\u00b7min{1,\u03b5} \u2206 + 1 )) . Assum-\ning that n \u2265 ln(\u03bb), with our choice of \u2206 it suffices to set \u03b5 = \u0398 (\u221a\n1 n ln(\u03bb)\n) . Plugging \u03b5 and \u2206 into\nTheorem 1.2, and simplifying, we get\nPr S\u223cD\n[|f (S)\u2212 f (Dn)| \u2265 t] \u2264 O\u0303 ( n3/2\nt2\n) . (10)\nObserve that the above bound decays as 1/t2. This should be contrasted with Markov\u2019s Inequality, which would decay as 1/t. Recall the assumption that the variance of \u03c1(x,y) is unbounded. Hence, the variance of f (S) can also be unbounded, and Chebyshev\u2019s inequality could not be applied.\nAs we now explain, Inequality 10 can be improved using part 2 of Theorem 1.2. To that end, for a fixed database S \u2208 Xn, we calculate:\nE y,z\u223cD\n[ 1 {\u2223\u2223\u2223\u2223f (S(i\u2190y))\u2212 f (S(i\u2190z))\u2223\u2223\u2223\u2223 \u2264 \u03bb} \u00b7 \u2223\u2223\u2223\u2223f (S(i\u2190y))\u2212 f (S(i\u2190z))\u2223\u2223\u2223\u2223] \u2264 E y,z\u223cD [\u03c1(y,z)] \u2264 \u222b 1 0 1dt + \u222b \u221e 1 1 t2 dt = 2 , \u03c4.\nIn order to apply part 2 of Theorem 1.2 we need to ensure that n \u2265O (\n\u03bb \u03b5\u00b7min{1,\u03b5}\u03c4 ln ( \u03b5\u03c4 \u2206 )) . For our\nchoice of \u2206 and \u03c4 , if n \u2265 \u03bb ln(\u03bb) then it suffices to set \u03b50 = \u0398 (\u221a \u03bb n ln(\u03bb) ) . Otherwise, if n < \u03bb ln(\u03bb)\nthen it suffices to set \u03b51 = \u0398 ( \u03bb n ln(\u03bb) ) . Plugging (\u03b50,\u2206) or (\u03b51,\u2206) into Theorem 1.2, and simplifying, we get\nPr S\u223cD\n[|f (S)\u2212 f (Dn)| \u2265 t] \u2264  O\u0303 ( n2 t3 ) , t \u2264 n\nO\u0303 ( n t2 ) , t > n\n4.3 Example: Triangles in Random Graphs\nA random graph G(N,p) on N vertices 1,2, . . . ,N is defined by drawing an edge between each pair 1 \u2264 i < j \u2264 N independently with probability p. There are n = (N 2 )\ni.i.d. random variables x{i,j} representing the choices: x{i,j} = x{j,i} = 1 if the edge {i, j} is drawn, and 0 otherwise. We will useD to denote the probability Prx\u223cD[x = 1] = p and Prx\u223cD[x = 0] = 1\u2212p, and let S = ( x{1,2}, . . . ,x{n\u22121,n} ) \u223c Dn.\nWe say that three vertices i, j, ` form a triangle if there is an edge between any pair of them. Denote fK3(S) the number of triangles in the graph defined by S. For a small constant \u03b1, we would like to have an exponential bound on the following probability\nPr [ fK3(S) \u2265 (1 +\u03b1) \u00b7 fK3(D n) ] .\nSpecifically, we are interested in small values of p = o(1) such that fK3(D n) = (N 3 ) p3 = \u0398 ( N3p3 ) = o(N ). The difficulty with this choice of p is that (in worst-case) adding a single edge to the graph can increase the number of triangles by (N \u2212 2), which is much larger then the expected number of triangles. Indeed, until the breakthrough work of Vu [17] in 2002, no general exponential bounds were known. Following the work of [17], in 2004 Kim and Vu [11] presented the following sharp bound:\nTheorem 4.3 ([11], informal). Let \u03b1 be a small constant. It holds that exp ( \u2212\u0398 ( p2N2 log(1/p) )) \u2264 Pr S\u223cDn [ fK3(S) \u2265 (1 +\u03b1) \u00b7 fK3(D n) ] \u2264 exp ( \u2212\u0398 ( p2N2 )) .\nIn this section we show that our result can be used to analyze this problem. While the bound we obtain is much weaker than Theorem 4.3, we find it interesting that the same technique from the last sections can also be applied here. To make things more concrete, we fix\np =N\u22123/4.\nIn order to use our concentration bound, we start by analyzing the expected difference incurred to fK3 by resampling a single edge. We will denote Ni,j(S) as the number of triangles that are created (or deleted) by adding (or removing) the edge {i, j}. That is,\nNi,j(S) = \u2223\u2223\u2223\u2223{` , i, j : x{i,`} = 1 and x{`,j} = 1}\u2223\u2223\u2223\u2223 .\nObserve that Ni,j(S) does not depend on x{i,j}. Moreover, observe that for every fixture of i < j we have that Ni,j(S) is the sum of (N \u2212 2) i.i.d. indicators, each equals to 1 with probability p2.\nFix S = ( x{1,2}, . . . ,x{n\u22121,n} ) \u2208 {0,1}n and x\u2032 \u2208 {0,1}. We have that\u2223\u2223\u2223\u2223fK3(S)\u2212 fK3 (S({i,j}\u2190x\u2032))\u2223\u2223\u2223\u2223 = { 0 , x{i,j} = x\u2032Ni,j(S) , x{i,j} , x\u2032\nwhere S({i,j}\u2190x \u2032) is the same as S except with x{i,j} replaced with x\u2032. Fix i < j. We can now calculate\nE S\u223cDn x\u2032\u223cD\n[ 1 {\u2223\u2223\u2223\u2223fK3(S)\u2212 fK3 (S({i,j}\u2190x\u2032))\u2223\u2223\u2223\u2223 > \u03bb} \u00b7 \u2223\u2223\u2223\u2223fK3(S)\u2212 fK3 (S({i,j}\u2190x\u2032))\u2223\u2223\u2223\u2223] = E S\u223cDn x\u2032\u223cD [ 1 { x{i,j},x\u2032 } \u00b71 { Ni,j(S) > \u03bb } \u00b7Ni,j(S)\n] = Pr x{i,j},x\u2032\u223cD [ x{i,j} , x \u2032 ] \u00b7 E S\u223cDn [ 1 { Ni,j(S) > \u03bb } \u00b7Ni,j(S)\n] = 2p(1\u2212 p) \u00b7 ( \u03bb \u00b7 Pr\nS\u223cDn [Ni,j(S) \u2265 \u03bb] + \u222b N \u03bb Pr S\u223cDn [Ni,j(S) \u2265 t]dt )\n\u2264 2pN \u00b7 Pr S\u223cDn [Ni,j(S) \u2265 \u03bb]. (11)\nRecall that Ni,j(S) is the sum of (N \u2212 2) i.i.d. indicators, each equals to 1 with probability p2. We can upper bound the probability that Ni,j(S) \u2265 \u03bb with the probability that a sum of N such random variables is at least \u03bb. We will use the following variant of the Chernoff bound, known as the Chernoff-Hoeffding theorem:\nTheorem 4.4 ([10]). Let X1, . . . ,Xn be independent random variables where Pr[Xi = 1] = p and Pr[Xi = 0] = 1\u2212 p for some 0 < p < 1. Let k be s.t. p < kn < 1. Then,\nP r  n\u2211 i=1 Xi \u2265 k  \u2265 exp(\u2212n \u00b7D ( kn \u2225\u2225\u2225\u2225\u2225p)) ,\nwhere D(a\u2016b) is the relative entropy between an a-coin and a p-coin (i.e. between the Bernoulli(a) and Bernoulli(p) distribution):\nD(a\u2016p) = a \u00b7 log ( a p ) + (1\u2212 a) \u00b7 log ( 1\u2212 a 1\u2212 p ) .\nUsing the Chernoff-Hoeffding theorem, for p2N < \u03bb < N , we have\n(11) \u2264 2pN \u00b7 exp ( \u2212N \u00b7D ( \u03bb N \u2225\u2225\u2225\u2225\u2225p2)) . (12) Recall that we fixed p =N\u22123/4. Choosing \u03bb =N1/13, we get:\n(12) = 2pN \u00b7 exp ( \u2212N \u00b7D ( N\u221212/13 \u2225\u2225\u2225N\u22126/4)) . (13) We will use the following claim to bound D ( N\u221212/13\n\u2225\u2225\u2225N\u22126/4): Claim 4.5. Fix constants c > b > 0. For N \u2265max{21/b,28/(c\u2212b)} we have that D ( N\u2212b\n\u2225\u2225\u2225N\u2212c) \u2265 c\u2212b2 \u00b7N\u2212b \u00b7 log(N ).\nUsing Claim 4.5, for large enough N , we have that\n(13) \u2264 2pN \u00b7 exp ( \u2212N1/13 ) . (14)\nSo, denoting \u2206 = 2pN \u00b7 exp ( \u2212N1/13 ) , we get that\nE S\u223cDn x\u2032\u223cD\n[ 1 {\u2223\u2223\u2223\u2223fK3(S)\u2212 fK3 (S({i,j}\u2190x\u2032))\u2223\u2223\u2223\u2223 > \u03bb} \u00b7 \u2223\u2223\u2223\u2223fK3(S)\u2212 fK3 (S({i,j}\u2190x\u2032))\u2223\u2223\u2223\u2223] \u2264 \u2206. In order to obtain a meaningful bound, we will need to use part 2 of Theorem 1.2. To that end,\nfor every fixture of S \u2208 Xn and i < j we can compute\nE y,z\u223cD\n[ 1 {\u2223\u2223\u2223\u2223fK3(S({i,j}\u2190y))\u2212 fK3 (S({i,j}\u2190z))\u2223\u2223\u2223\u2223 \u2264 \u03bb} \u00b7 \u2223\u2223\u2223\u2223fK3(S({i,j}\u2190y))\u2212 fK3 (S({i,j}\u2190z))\u2223\u2223\u2223\u2223] \u2264 Ey,z\u223cD [1 {y , z} \u00b7\u03bb] = 2p(1\u2212 p)\u03bb \u2264 2p\u03bb , \u03c4.\nFinally, in order to apply Theorem 1.2, we need to ensure that n \u2265 O (\n\u03bb \u03b5min{1,\u03b5}\u03c4 ln\n( min{1,\u03b5}\u03c4\n\u2206\n)) .\nWith our choices for \u2206 and \u03c4 , it suffices to set \u03b5 = \u0398 (\u221a\n\u03bb np\n) . Plugging \u03b5, \u2206 and \u03c4 into Theorem 1.2,\nand simplifying, we get that\nPr S\u223cDn\n[ |fK3(S)\u2212 fK3(D n)| \u2265 o ( fK3(D n) )] < exp ( \u2212N1/13 ) .\nIt remains to prove Claim 4.5: Claim 4.5. Fix constants c > b > 0. For N \u2265max{21/b,28/(c\u2212b)} we have that D ( N\u2212b \u2225\u2225\u2225N\u2212c) \u2265 c\u2212b2 \u00b7N\u2212b \u00b7 log(N ).\nProof of Claim 4.5.\nD ( N\u2212b \u2225\u2225\u2225N\u2212c) =N\u2212b \u00b7 log(N c\u2212b)+ (1\u2212N\u2212b) \u00b7 log(1\u2212N\u2212b 1\u2212N\u2212c ) =N\u2212b \u00b7 log ( N c\u2212b ) + ( 1\u2212N\u2212b ) \u00b7 log ( N c \u2212N c\u2212b\nN c \u2212 1 ) =N\u2212b \u00b7 log ( N c\u2212b ) + ( 1\u2212N\u2212b ) \u00b7 log ( 1\u2212 N\nc\u2212b \u2212 1 N c \u2212 1\n) (15)\nUsing the fact that log(1\u2212 x) \u2265 \u22122x for every 0 \u2264 x \u2264 12 , and assuming that N \u2265 2 1/b, we have\nthat\n(15) \u2265N\u2212b \u00b7 log ( N c\u2212b ) \u2212 2 ( 1\u2212N\u2212b ) \u00b7 N\nc\u2212b \u2212 1 N c \u2212 1\n=N\u2212b \u00b7 log ( N c\u2212b ) \u2212 2 \u00b7 N\nc\u2212b \u2212 1 N c \u2212 1 + 2N\u2212b \u00b7 N c\u2212b \u2212 1 N c \u2212 1\n\u2265N\u2212b \u00b7 log ( N c\u2212b ) \u2212 2 \u00b7 N\nc\u2212b \u2212 1 N c \u2212 1\n\u2265N\u2212b \u00b7 log ( N c\u2212b ) \u2212 2 \u00b7 N c\u2212b\n1 2N c \u2265N\u2212b \u00b7 log ( N c\u2212b ) \u2212 4N\u2212b (16)\nAssuming that N \u2265 28/(c\u2212b) we get\n(16) \u2265 1 2 \u00b7N\u2212b \u00b7 log\n( N c\u2212b ) \u2265 c \u2212 b\n2 \u00b7N\u2212b \u00b7 log(N ) .\n5 Privately Identifying a High-Sensitivity Function\nLet S be a sample of n i.i.d. elements from some distribution D. Recall that if a low-sensitivity function f is identified by a differentially private algorithm operating on S, then w.h.p. f (S) \u2248 f (Dn) , E\nS \u2032\u223cDn [f (S \u2032)]. In this section we present a simple example showing that, in general, this\nis not the case for high-sensitivity functions. Specifically, we show that a differentially private algorithm operating on S can identify a high-sensitivity function f s.t. |f (S)\u2212 f (Dn)| is arbitrarily large, even though |f (S \u2032)\u2212 f (Dn)| is small for a fresh sample S \u2032 \u223c Dn.\nTheorem 5.1. Fix \u03b2,\u03b5,B > 0, let U be the uniform distribution over X = {\u00b11}d where d = poly(1/\u03b2), and let n \u2265 O( 1\u03b52 ln(1/\u03b2)). There exists an (\u03b5,0)-differentially private algorithm A that operates on a database S \u2208 ({\u00b11}d)n and returns a function mapping ({\u00b11}d)n to R, s.t. the following hold.\n1. For every f in the range of A it holds that PrS \u2032\u223cUn[f (S \u2032) , f (Un)] \u2264 \u03b2.\n2. Pr S\u223cUn f\u2190A(S)\n[|f (S)\u2212 f (Un)| \u2265 B] \u2265 1/2.\nProof. For t \u2208 [d], define ft : ({\u00b11}d)n\u2192R as\nft(x1, . . . ,xn) =  0 , \u2223\u2223\u2223\u2211i\u2208[n] xi,t\u2223\u2223\u2223 \u2264\u221a2n ln(2/\u03b2) B , \u2211 i\u2208[n] xi,t > \u221a 2n ln(2/\u03b2) \u2212B , \u2211 i\u2208[n] xi,t < \u2212 \u221a 2n ln(2/\u03b2)\nThat is, given a database S of n rows from {\u00b11}d , we define ft(S) as 0 if the sum of column t (in absolute value) is less than some threshold, and otherwise set ft(S) to be \u00b1B (depending on the\nsign of the sum). Observe that the global sensitivity of ft is B, and that ft(Un) , E S \u2032\u223cUn [ft(S \u2032)] = 0. Also, by the Hoeffding bound, we have that\nPr S\u223cUn [ft(S) , 0] \u2264 \u03b2.\nSo, for every fixed t, with high probability over sampling S \u223c Un we have that ft(S) = 0 = ft(Un). Nevertheless, as we now explain, if d is large enough, then an (\u03b5,0)-differentially private algorithm can easily identify a \u201cbad\u201d index t\u2217 such that |ft\u2217(S)| = B.\nConsider the algorithm that on input S = (x1,x2, . . . ,xn) samples an index t \u2208 [d] with probability proportional to exp ( \u03b5 4 \u2223\u2223\u2223\u2211i\u2208[n] xi,t\u2223\u2223\u2223). We will call it algorithm BadIndex. By the properties of the exponential mechanism, algorithm BadIndex is (\u03b5,0)-differentially private. Moreover, with probability at least 3/4, the output t\u2217 satisfies\u2223\u2223\u2223\u2223\u2223\u2223\u2223\u2223 \u2211 i\u2208[n] xi,t\u2217 \u2223\u2223\u2223\u2223\u2223\u2223\u2223\u2223 \u2265 maxt\u2208[d]  \u2223\u2223\u2223\u2223\u2223\u2223\u2223\u2223 \u2211 i\u2208[n] xi,t \u2223\u2223\u2223\u2223\u2223\u2223\u2223\u2223  \u2212 4\u03b5 ln(4d) . (17)\nIn addition, by Theorem 2.6 (tightness of Chernoff bound), for every fixed t it holds that\nPr \u2211 i\u2208[n] xi,t \u2265 1.11 \u00b7 \u221a 2n ln(2/\u03b2)  \u2265 (\u03b22 )45 . As the columns are independent, taking d = 2 ( 2 \u03b2 )45 , we get that\nPr maxt\u2208[d]  \u2211 i\u2208[n] xi,t  \u2265 1.11 \u00b7\u221a2n ln(2/\u03b2)  \u2265 3/4. (18)\nCombining (17) and (18) we get that with probability at least 1/2 algorithm BadIndex identifies an index t\u2217 such that \u2223\u2223\u2223\u2223\u2223\u2223\u2223\u2223 \u2211 i\u2208[n] xi,t\u2217 \u2223\u2223\u2223\u2223\u2223\u2223\u2223\u2223 \u2265 1.11 \u00b7 \u221a 2n ln(2/\u03b2) \u2212 4 \u03b5 ln(4d) .\nAssuming that n \u2265 O( 1\u03b52 ln(1/\u03b2)) we get that with probability at least 1/2 algorithm BadIndex outputs an index t\u2217 s.t. ft\u2217(S) = B.\n5.1 Max-Information\nIn this section we show that algorithm BadIndex has relatively high max-information: Given two (correlated) random variables Y , Z, we use Y \u2297Z denote the random variable obtained by drawing independent copies of Y and Z from their respective marginal distributions.\nDefinition 5.2 (Max-Information [5]). Let Y and Z be jointly distributed random variables over the domain (Y ,Z). The \u03b2-approximate max-information between Y and Z is defined as\nI \u03b2 \u221e(Y ;Z) = log sup\nO\u2286(Y\u00d7Z), Pr[(Y ,Z)\u2208O]>\u03b2\nPr[(Y ,Z) \u2208 O]\u2212 \u03b2 Pr[Y \u2297Z \u2208 O] .\nAn algorithm A : Xn \u2192 F has \u03b2-approximate max-information of k over product distributions, written I\u03b2\u221e,P (A,n) \u2264 k, if for every distribution D over X, we have I \u03b2 \u221e(S;A(S)) \u2264 k when S \u223c Dn.\nIt follows immediately from the definition that approximate max-information controls the probability of \u201cbad events\u201d that can happen as a result of the dependence of A(S) on S: for every event O, we have Pr[(S,A(S)) \u2208 O] \u2264 2k Pr[S \u2297A(S) \u2208 O] + \u03b2.\nConsider again algorithm BadIndex : ({\u00b11})n \u2192 F that operates on database S of size n = O( 1\u03b52 ln(1/\u03b2)) and identifies, with probability 1/2, a function f s.t. f (S) , 0, even though f (S\n\u2032) = 0 w.p. 1\u2212 \u03b2 for a fresh sample S \u2032. Let us define O as the set of all pairs (S,f ), where S is a database and f is a function in the range of algorithm BadIndex such that f (S) , 0. That is,\nO = {(S,f ) \u2208 ({\u00b11})n \u00d7F : f (S) , 0} .\nIf we assume that I1/4\u221e,P (BadIndex,n) \u2264 k, then by Definition 5.2 we have:\n1 2 \u2264 Pr\nS\u223cUn f\u2190BadIndex(S) [(S,f ) \u2208 O] \u2264 ek \u00b7 Pr S\u223cUn T\u223cUn\nf\u2190BadIndex(T )\n[(S,f ) \u2208 O] + 1 4 \u2264 ek \u00b7 \u03b2 + 1 4 .\nSo k \u2265 ln( 14\u03b2 ) = \u2126(\u03b5 2n).\nReferences\n[1] Raef Bassily and Yoav Freund. Typicality-based stability and privacy. CoRR, abs/1604.03336, 2016.\n[2] Raef Bassily, Kobbi Nissim, Adam D. Smith, Thomas Steinke, Uri Stemmer, and Jonathan Ullman. Algorithmic stability for adaptive data analysis. In Proceedings of the 48th Annual ACM SIGACT Symposium on Theory of Computing, STOC 2016, Cambridge, MA, USA, June 18-21, 2016, pages 1046\u20131059, 2016.\n[3] Herman Chernoff. A measure of asymptotic efficiency for tests of a hypothesis based on the sum of observations. Ann. Math. Statist., 23:493\u2013507, 1952.\n[4] Rachel Cummings, Katrina Ligett, Kobbi Nissim, Aaron Roth, and Zhiwei Steven Wu. Adaptive learning with robust generalization guarantees. In Proceedings of the 29th Conference on Learning Theory, COLT 2016, New York, USA, June 23-26, 2016, pages 772\u2013814, 2016.\n[5] Cynthia Dwork, Vitaly Feldman, Moritz Hardt, Toniann Pitassi, Omer Reingold, and Aaron Roth. Generalization in adaptive data analysis and holdout reuse. In Advances in Neural Information Processing Systems (NIPS), Montreal, December 2015.\n[6] Cynthia Dwork, Vitaly Feldman, Moritz Hardt, Toniann Pitassi, Omer Reingold, and Aaron Roth. Preserving statistical validity in adaptive data analysis. In ACM Symposium on the Theory of Computing (STOC). ACM, June 2015.\n[7] Cynthia Dwork, Krishnaram Kenthapadi, Frank McSherry, Ilya Mironov, and Moni Naor. Our data, ourselves: Privacy via distributed noise generation. In Serge Vaudenay, editor, EUROCRYPT, volume 4004 of Lecture Notes in Computer Science, pages 486\u2013503. Springer, 2006.\n[8] Cynthia Dwork, Frank McSherry, Kobbi Nissim, and Adam Smith. Calibrating noise to sensitivity in private data analysis. In TCC, volume 3876 of Lecture Notes in Computer Science, pages 265\u2013284. Springer, 2006.\n[9] Moritz Hardt and Jonathan Ullman. Preventing false discovery in interactive data analysis is hard. In FOCS, pages 454\u2013463, 2014.\n[10] Wassily Hoeffding. Probability inequalities for sums of bounded random variables. Journal of the American Statistical Association, 58(301):13\u201330, 1963.\n[11] J. H. Kim and V. H. Vu. Divide and conquer martingales and the number of triangles in a random graph. Random Structures and Algorithms, 24(2):166\u2013174, 2004.\n[12] Philip N. Klein and Neal E. Young. On the number of iterations for dantzig-wolfe optimization and packing-covering approximation algorithms. SIAM J. Comput., 44(4):1154\u20131172, 2015.\n[13] Aryeh Kontorovich. Concentration in unbounded metric spaces and algorithmic stability. In Proceedings of the 31th International Conference on Machine Learning, ICML 2014, Beijing, China, 21-26 June 2014, pages 28\u201336, 2014.\n[14] Frank McSherry and Kunal Talwar. Mechanism design via differential privacy. In FOCS, pages 94\u2013103. IEEE, Oct 20\u201323 2007.\n[15] Thomas Steinke and Jonathan Ullman. Interactive fingerprinting codes and the hardness of preventing false discovery. In COLT, pages 1588\u20131628, 2015.\n[16] Thomas Steinke and Jonathan Ullman. Subgaussian tail bounds via stability arguments. ArXiv.org, (arXiv:1701.03493 [cs.DM]), 2017.\n[17] Van H. Vu. Concentration of non-lipschitz functions and applications. Random Structures and Algorithms, 20(3):262\u2013316, 2002.\nA Concentration Bounds Through Differential Privacy \u2013 Missing Details\nClaim 3.3. Fix a function f : Xn \u2192 R and parameters \u03b5,\u03bb \u2265 0. If M : (Xn)T \u2192 Y is (\u03b5, (f ,\u03bb))differentially private then for every (f ,\u03bb)-neighboring databases ~S, ~S \u2032 \u2208 (Xn)T and every function h : Y \u2192R we have that\nE y\u2190M(~S) [h(y)] \u2264 e\u2212\u03b5 \u00b7 E y\u2190M(~S \u2032) [h(y)] + (e\u03b5 \u2212 e\u2212\u03b5) \u00b7 E y\u2190M(~S \u2032) [|h(y)|] .\nProof.\nE y\u2190M(~S)\n[h(y)] = \u222b \u221e\n0 Pr y\u2190M(~S) [h(y) \u2265 z]dz \u2212 \u222b 0 \u2212\u221e Pr y\u2190M(~S) [h(y) \u2264 z]dz\n\u2264 e\u03b5 \u00b7 \u222b \u221e\n0 Pr y\u2190M(~S \u2032) [h(y) \u2265 z]dz \u2212 e\u2212\u03b5 \u00b7 \u222b 0 \u2212\u221e Pr y\u2190M(~S \u2032) [h(y) \u2264 z]dz\n= e\u2212\u03b5 \u222b \u221e\n0 Pr y\u2190M(~S \u2032) [h(y) \u2265 z]dz \u2212 \u222b 0 \u2212\u221e Pr y\u2190M(~S \u2032) [h(y) \u2264 z]dz \n+ (e\u03b5 \u2212 e\u2212\u03b5) \u00b7 \u222b \u221e\n0 Pr y\u2190M(~S \u2032) [h(y) \u2265 z]dz\n= e\u2212\u03b5 \u00b7 E y\u2190M(~S \u2032)\n[h(y)] + (e\u03b5 \u2212 e\u2212\u03b5) \u00b7 \u222b \u221e\n0 Pr y\u2190M(~S \u2032) [h(y) \u2265 z]dz\n\u2264 e\u2212\u03b5 \u00b7 E y\u2190M(~S \u2032)\n[h(y)] + (e\u03b5 \u2212 e\u2212\u03b5) \u00b7 \u222b \u221e\n0 Pr y\u2190M(~S \u2032) [|h(y)| \u2265 z]dz\n= e\u2212\u03b5 \u00b7 E y\u2190M(~S \u2032) [h(y)] + (e\u03b5 \u2212 e\u2212\u03b5) \u00b7 E y\u2190M(~S \u2032) [|h(y)|]\nA.1 Multi Sample Expectation Bound\nLemma A.1 (Expectation Bound). Let D be a distribution over a domain X, let f : Xn\u2192R , and let \u2206,\u03bb be s.t. for every 1 \u2264 i \u2264 n it holds that\nE S\u223cDn z\u223cD\n[ 1 {\u2223\u2223\u2223\u2223f (S)\u2212 f (S(i\u2190z))\u2223\u2223\u2223\u2223 > \u03bb} \u00b7 \u2223\u2223\u2223\u2223f (S)\u2212 f (S(i\u2190z))\u2223\u2223\u2223\u2223] \u2264 \u2206, (19) where S(i\u2190z) is the same as S except that the ith element is replaced with z. Let A : (Xn)T \u2192 ([T ]\u222a\u22a5) be an (\u03b5, (f ,\u03bb))-differentially private algorithm that operates on T databases of size n from X, and outputs an index 1 \u2264 t \u2264 T or \u22a5. Then\u2223\u2223\u2223\u2223\u2223\u2223\u2223\u2223\u2223\u2223 E~S\u223cDnTt\u2190A(~S) [1{t ,\u22a5} \u00b7 (f (D n)\u2212 f (St))] \u2223\u2223\u2223\u2223\u2223\u2223\u2223\u2223\u2223\u2223 \u2264 (e \u03b5 \u2212 e\u2212\u03b5) \u00b7\u03bbn+ 6\u2206nT .\nIf, in addition to (19), there exists a number 0 \u2264 \u03c4 \u2264 \u03bb s.t. for every 1 \u2264 i \u2264 n and every fixture of S \u2208 Xn we have that\nE y,z\u223cD\n[ 1 {\u2223\u2223\u2223\u2223f (S(i\u2190y))\u2212 f (S(i\u2190z))\u2223\u2223\u2223\u2223 \u2264 \u03bb} \u00b7 \u2223\u2223\u2223\u2223f (S(i\u2190y))\u2212 f (S(i\u2190z))\u2223\u2223\u2223\u2223] \u2264 \u03c4, (20) Then, \u2223\u2223\u2223\u2223\u2223\u2223\u2223\u2223\u2223\u2223 E~S\u223cDnTt\u2190A(~S) [1{t ,\u22a5} \u00b7 (f (D n)\u2212 f (St))] \u2223\u2223\u2223\u2223\u2223\u2223\u2223\u2223\u2223\u2223 \u2264 (e \u03b5 \u2212 e\u2212\u03b5) \u00b7 \u03c4n+ 6\u2206nT .\nWe now present the proof assuming that (20) holds for some 0 \u2264 \u03c4 \u2264 \u03bb. This is without loss of generality, as trivially it holds for \u03c4 = \u03bb.\nProof of Lemma A.1. Let ~S \u2032 = (S \u20321, . . . ,S \u2032 T ) \u223c D nT be independent of ~S. Recall that each element St of ~S is itself a vector (xt,1, . . . ,xt,n), and the same is true for each element S \u2032t of ~S\n\u2032 . We will sometimes refer to the vectors S1, . . . ,ST as the subsamples of ~S.\nWe define a sequence of intermediate samples that allow us to interpolate between ~S and ~S \u2032. Formally, for ` \u2208 {0,1, . . . ,n} define ~S` = (S`1, . . . ,S ` T ) \u2208 (X n)T where S`t = (x ` t,1, . . . ,x ` t,n) and\nx`t,i = { xt,i , i > ` x\u2032t,i , i \u2264 `\nThat is, every subsample S`t of ~S ` is identical to S \u2032t on the first ` elements, and identical to St thereafter. By construction we have ~S0 = ~S and ~Sn = ~S \u2032. Moreover, for every t we have that S`t and S`\u22121t differ in exactly one element. In terms of these intermediate samples we can write:\u2223\u2223\u2223\u2223\u2223\u2223 E~S\u223cDnT Et\u2190A(~S) [1{t ,\u22a5} \u00b7 (f (Dn)\u2212 f (St))]\n\u2223\u2223\u2223\u2223\u2223\u2223 =\n\u2223\u2223\u2223\u2223\u2223\u2223 E~S\u223cDnT Et\u2190A(~S) [ 1{t ,\u22a5} \u00b7 ( E ~S \u2032\u223cDnT [ f (S \u2032t) ] \u2212 f (St) )]\u2223\u2223\u2223\u2223\u2223\u2223 =\n\u2223\u2223\u2223\u2223\u2223\u2223 E~S\u223cDnT Et\u2190A(~S) E~S \u2032\u223cDnT [1{t ,\u22a5} \u00b7 (f (S \u2032t)\u2212 f (St))] \u2223\u2223\u2223\u2223\u2223\u2223\n= \u2223\u2223\u2223\u2223\u2223\u2223\u2223\u2223 \u2211 `\u2208[n] E ~S,~S \u2032\u223cDnT E t\u2190A(~S) [ 1{t ,\u22a5} \u00b7 ( f (S`t )\u2212 f (S`\u22121t ) )]\u2223\u2223\u2223\u2223\u2223\u2223\u2223\u2223 \u2264\n\u2211 `\u2208[n] \u2223\u2223\u2223\u2223\u2223\u2223 E~S,~S \u2032\u223cDnT Et\u2190A(~S) [1{t ,\u22a5} \u00b7 (f (S`t )\u2212 f (S`\u22121t ))] \u2223\u2223\u2223\u2223\u2223\u2223\n= \u2211 `\u2208[n] \u2223\u2223\u2223\u2223\u2223\u2223 E~S,~S \u2032\u223cDnT EZ\u223cDT Et\u2190A(~S) [1{t ,\u22a5} \u00b7 (f (S`t )\u2212 f (S`\u22121t ))] \u2223\u2223\u2223\u2223\u2223\u2223 (21)\nGiven a multisample ~S = (S1, . . . ,ST ) \u2208 (Xn)T , a vector Z = (z1 . . . , zT ) \u2208 XT , and an index 1 \u2264 k \u2264 n, we define ~S(k\u2190Z) to be the same as ~S except that the kth element of every subsample Si is replaced with zi . Observe that by construction, for every `,Z we have ~S`,(`\u2190Z) = ~S`\u22121,(`\u2190Z). Thus, (21) = \u2211 `\u2208[n] \u2223\u2223\u2223\u2223\u2223\u2223 E~S,~S \u2032\u223cDnT EZ\u223cDT Et\u2190A(~S) 1{t ,\u22a5} \u00b7 f (S`t )\u2212 f (S`,(`\u2190Z)t )\u22121{t ,\u22a5} \u00b7 f (S`\u22121t )\u2212 f (S`\u22121,(`\u2190Z)t )\u2223\u2223\u2223\u2223\u2223\u2223 .\n(22) Observer that the pairs (~S, ~S`) and ( ~S, ~S`,(`\u2190Z) ) are identically distributed. Namely, both ~S` and\n~S`,(`\u2190Z) agree with ~S on the last (n \u2212 `) entries of every subsample, and otherwise contain i.i.d. samples from D. Hence, the expectation of ( f (S`t )\u2212 f ( S `,(`\u2190Z) t )) is zero, and we get\n(22) = \u2211 `\u2208[n] \u2223\u2223\u2223\u2223\u2223\u2223 E~S,~S \u2032\u223cDnT EZ\u223cDT Et\u2190A(~S) 1{t ,\u22a5} \u00b7 f (S`\u22121,(`\u2190Z)t )\u2212 f (S`\u22121t )\u2223\u2223\u2223\u2223\u2223\u2223 . (23)\nObserver that the pair (~S`\u22121, ~S) has the same distribution as (~S, ~S`\u22121). Specifically, the first component is nT independent samples from D and the second component is equal to the first component with a subset of the entries replaced by fresh independent samples from D. Thus,\n(23) = \u2211 `\u2208[n] \u2223\u2223\u2223\u2223\u2223\u2223 E~S,~S \u2032\u223cDnT EZ\u223cDT Et\u2190A(~S`\u22121) 1{t ,\u22a5} \u00b7 f (S(`\u2190Z)t )\u2212 f (St)\u2223\u2223\u2223\u2223\u2223\u2223\n\u2264 \u2211 `\u2208[n] \u2223\u2223\u2223\u2223\u2223\u2223\u2223\u2223\u2223\u2223\u2223\u2223 E ~S,~S \u2032\u223cDnT E Z\u223cDT 1  maxm\u2208[T ] |f (S`\u22121m )\u2212 f (S`m)| \u2264 \u03bb and maxm\u2208[T ] |f ( S (`\u2190Z) m ) \u2212 f (Sm)| \u2264 \u03bb  \u00b7 Et\u2190A(~S`\u22121) 1{t ,\u22a5} \u00b7 f (S(`\u2190Z)t )\u2212 f (St)  \u2223\u2223\u2223\u2223\u2223\u2223\u2223\u2223\u2223\u2223\u2223\u2223\n+ \u2211 `\u2208[n] \u2223\u2223\u2223\u2223\u2223\u2223\u2223\u2223\u2223\u2223\u2223\u2223 E ~S,~S \u2032\u223cDnT E Z\u223cDT 1  maxm\u2208[T ] |f (S`\u22121m )\u2212 f (S`m)| > \u03bb or maxm\u2208[T ] |f ( S (`\u2190Z) m ) \u2212 f (Sm)| > \u03bb  \u00b7 maxm\u2208[T ] \u2223\u2223\u2223\u2223\u2223f (S(`\u2190Z)m )\u2212 f (Sm)\u2223\u2223\u2223\u2223\u2223  \u2223\u2223\u2223\u2223\u2223\u2223\u2223\u2223\u2223\u2223\u2223\u2223\n(24)\nWhen maxm\u2208[T ] |f (S`\u22121m )\u2212 f (S`m)| \u2264 \u03bb we now use the properties of algorithm A to argue that A(~S`\u22121) \u2248 A(~S`). Be Claim 3.3 we get that\n(24)\n\u2264 \u2211 `\u2208[n] \u2223\u2223\u2223\u2223\u2223\u2223\u2223\u2223\u2223\u2223\u2223\u2223 E ~S,~S \u2032\u223cDnT E Z\u223cDT 1  maxm\u2208[T ] |f (S`\u22121m )\u2212 f (S`m)| \u2264 \u03bb and maxm\u2208[T ] |f ( S (`\u2190Z) m ) \u2212 f (Sm)| \u2264 \u03bb  \u00b7 Et\u2190A(~S`) 1{t ,\u22a5} \u00b7 f (S(`\u2190Z)t )\u2212 f (St)  \u2223\u2223\u2223\u2223\u2223\u2223\u2223\u2223\u2223\u2223\u2223\u2223\n+ (e\u03b5 \u2212 e\u2212\u03b5) \u00b7 \u2211 `\u2208[n] \u2223\u2223\u2223\u2223\u2223\u2223\u2223\u2223\u2223\u2223\u2223\u2223 E ~S,~S \u2032\u223cDnT E Z\u223cDT 1  maxm\u2208[T ] |f (S`\u22121m )\u2212 f (S`m)| \u2264 \u03bb and maxm\u2208[T ] |f ( S (`\u2190Z) m ) \u2212 f (Sm)| \u2264 \u03bb  \u00b7 Et\u2190A(~S`) [ 1{t ,\u22a5} \u00b7 \u2223\u2223\u2223\u2223\u2223f (S(`\u2190Z)t )\u2212 f (St)\u2223\u2223\u2223\u2223\u2223]  \u2223\u2223\u2223\u2223\u2223\u2223\u2223\u2223\u2223\u2223\u2223\u2223\n+ \u2211 `\u2208[n] \u2223\u2223\u2223\u2223\u2223\u2223\u2223\u2223\u2223\u2223\u2223\u2223 E ~S,~S \u2032\u223cDnT E Z\u223cDT 1  maxm\u2208[T ] |f (S`\u22121m )\u2212 f (S`m)| > \u03bb or maxm\u2208[T ] |f ( S (`\u2190Z) m ) \u2212 f (Sm)| > \u03bb  \u00b7 maxm\u2208[T ] \u2223\u2223\u2223\u2223\u2223f (S(`\u2190Z)m )\u2212 f (Sm)\u2223\u2223\u2223\u2223\u2223  \u2223\u2223\u2223\u2223\u2223\u2223\u2223\u2223\u2223\u2223\u2223\u2223\n(25)\nWe can remove one of the two requirements in the indicator function in the middle row (this makes the expression bigger), to get:\n(25)\n\u2264 \u2211 `\u2208[n] \u2223\u2223\u2223\u2223\u2223\u2223\u2223\u2223\u2223\u2223\u2223\u2223 E ~S,~S \u2032\u223cDnT E Z\u223cDT 1  maxm\u2208[T ] |f (S`\u22121m )\u2212 f (S`m)| \u2264 \u03bb and maxm\u2208[T ] |f ( S (`\u2190Z) m ) \u2212 f (Sm)| \u2264 \u03bb  \u00b7 Et\u2190A(~S`) 1{t ,\u22a5} \u00b7 f (S(`\u2190Z)t )\u2212 f (St)  \u2223\u2223\u2223\u2223\u2223\u2223\u2223\u2223\u2223\u2223\u2223\u2223 + (e\u03b5 \u2212 e\u2212\u03b5) \u00b7 \u2211 `\u2208[n] \u2223\u2223\u2223\u2223\u2223\u2223 E~S,~S \u2032\u223cDnT EZ\u223cDT Et\u2190A(~S`) [ 1 { max m\u2208[T ] |f ( S (`\u2190Z) m ) \u2212 f (Sm)| \u2264 \u03bb } \u00b71{t ,\u22a5} \u00b7 \u2223\u2223\u2223\u2223\u2223f (S(`\u2190Z)t )\u2212 f (St)\u2223\u2223\u2223\u2223\u2223] \u2223\u2223\u2223\u2223\u2223\u2223\n+ \u2211 `\u2208[n] \u2223\u2223\u2223\u2223\u2223\u2223\u2223\u2223\u2223\u2223\u2223\u2223 E ~S,~S \u2032\u223cDnT E Z\u223cDT 1  maxm\u2208[T ] |f (S`\u22121m )\u2212 f (S`m)| > \u03bb or maxm\u2208[T ] |f ( S (`\u2190Z) m ) \u2212 f (Sm)| > \u03bb  \u00b7 maxm\u2208[T ] \u2223\u2223\u2223\u2223\u2223f (S(`\u2190Z)m )\u2212 f (Sm)\u2223\u2223\u2223\u2223\u2223  \u2223\u2223\u2223\u2223\u2223\u2223\u2223\u2223\u2223\u2223\u2223\u2223\n(26)\nFurthermore, we can replace 1 { maxm\u2208[T ] |f ( S (`\u2190Z) m ) \u2212 f (Sm)| \u2264 \u03bb } in the middle row with the\nweaker requirement \u2013 just for the specific t that was selected by algorithm A. This yields:\n(26)\n\u2264 \u2211 `\u2208[n] \u2223\u2223\u2223\u2223\u2223\u2223\u2223\u2223\u2223\u2223\u2223\u2223 E ~S,~S \u2032\u223cDnT E Z\u223cDT 1  maxm\u2208[T ] |f (S`\u22121m )\u2212 f (S`m)| \u2264 \u03bb and maxm\u2208[T ] |f ( S (`\u2190Z) m ) \u2212 f (Sm)| \u2264 \u03bb  \u00b7 Et\u2190A(~S`) 1{t ,\u22a5} \u00b7 f (S(`\u2190Z)t )\u2212 f (St)  \u2223\u2223\u2223\u2223\u2223\u2223\u2223\u2223\u2223\u2223\u2223\u2223 + (e\u03b5 \u2212 e\u2212\u03b5) \u00b7 \u2211 `\u2208[n] \u2223\u2223\u2223\u2223\u2223\u2223 E~S,~S \u2032\u223cDnT EZ\u223cDT Et\u2190A(~S`) [ 1 { |f ( S (`\u2190Z) t ) \u2212 f (St)| \u2264 \u03bb } \u00b71{t ,\u22a5} \u00b7 \u2223\u2223\u2223\u2223\u2223f (S(`\u2190Z)t )\u2212 f (St)\u2223\u2223\u2223\u2223\u2223] \u2223\u2223\u2223\u2223\u2223\u2223\n+ \u2211 `\u2208[n] \u2223\u2223\u2223\u2223\u2223\u2223\u2223\u2223\u2223\u2223\u2223\u2223 E ~S,~S \u2032\u223cDnT E Z\u223cDT 1  maxm\u2208[T ] |f (S`\u22121m )\u2212 f (S`m)| > \u03bb or maxm\u2208[T ] |f ( S (`\u2190Z) m ) \u2212 f (Sm)| > \u03bb  \u00b7 maxm\u2208[T ] \u2223\u2223\u2223\u2223\u2223f (S(`\u2190Z)m )\u2212 f (Sm)\u2223\u2223\u2223\u2223\u2223  \u2223\u2223\u2223\u2223\u2223\u2223\u2223\u2223\u2223\u2223\u2223\u2223\n(27)\nUsing the fact that the pairs (~S, ~S`) and (~S`, ~S) are identically distributed, we can switch them in the middle row, to get\n(27)\n\u2264 \u2211 `\u2208[n] \u2223\u2223\u2223\u2223\u2223\u2223\u2223\u2223\u2223\u2223\u2223\u2223 E ~S,~S \u2032\u223cDnT E Z\u223cDT 1  maxm\u2208[T ] |f (S`\u22121m )\u2212 f (S`m)| \u2264 \u03bb and maxm\u2208[T ] |f ( S (`\u2190Z) m ) \u2212 f (Sm)| \u2264 \u03bb  \u00b7 Et\u2190A(~S`) 1{t ,\u22a5} \u00b7 f (S(`\u2190Z)t )\u2212 f (St)  \u2223\u2223\u2223\u2223\u2223\u2223\u2223\u2223\u2223\u2223\u2223\u2223\n+ (e\u03b5 \u2212 e\u2212\u03b5) \u00b7 \u2211 `\u2208[n] \u2223\u2223\u2223\u2223\u2223\u2223\u2223\u2223\u2223 E~S\u223cDnT Et\u2190A(~S) E~S \u2032\u223cDnT Z\u223cDT [ 1 { |f ( S `,(`\u2190Z) t ) \u2212 f (S`t )| \u2264 \u03bb } \u00b71{t ,\u22a5} \u00b7 \u2223\u2223\u2223\u2223\u2223f (S`,(`\u2190Z)t )\u2212 f (S`t )\u2223\u2223\u2223\u2223\u2223] \u2223\u2223\u2223\u2223\u2223\u2223\u2223\u2223\u2223\n+ \u2211 `\u2208[n] \u2223\u2223\u2223\u2223\u2223\u2223\u2223\u2223\u2223\u2223\u2223\u2223 E ~S,~S \u2032\u223cDnT E Z\u223cDT 1  maxm\u2208[T ] |f (S`\u22121m )\u2212 f (S`m)| > \u03bb or maxm\u2208[T ] |f ( S (`\u2190Z) m ) \u2212 f (Sm)| > \u03bb  \u00b7 maxm\u2208[T ] \u2223\u2223\u2223\u2223\u2223f (S(`\u2190Z)m )\u2212 f (Sm)\u2223\u2223\u2223\u2223\u2223  \u2223\u2223\u2223\u2223\u2223\u2223\u2223\u2223\u2223\u2223\u2223\u2223\n(28)\nUsing our assumptions on the function f and the distribution D (for the middle row), brings us to:\n(28)\n\u2264 \u2211 `\u2208[n] \u2223\u2223\u2223\u2223\u2223\u2223\u2223\u2223\u2223\u2223\u2223\u2223 E ~S,~S \u2032\u223cDnT E Z\u223cDT 1  maxm\u2208[T ] |f (S`\u22121m )\u2212 f (S`m)| \u2264 \u03bb and maxm\u2208[T ] |f ( S (`\u2190Z) m ) \u2212 f (Sm)| \u2264 \u03bb  \u00b7 Et\u2190A(~S`) 1{t ,\u22a5} \u00b7 f (S(`\u2190Z)t )\u2212 f (St)  \u2223\u2223\u2223\u2223\u2223\u2223\u2223\u2223\u2223\u2223\u2223\u2223\n+ (e\u03b5 \u2212 e\u2212\u03b5)n\u03c4\n+ \u2211 `\u2208[n] \u2223\u2223\u2223\u2223\u2223\u2223\u2223\u2223\u2223\u2223\u2223\u2223 E ~S,~S \u2032\u223cDnT E Z\u223cDT 1  maxm\u2208[T ] |f (S`\u22121m )\u2212 f (S`m)| > \u03bb or maxm\u2208[T ] |f ( S (`\u2190Z) m ) \u2212 f (Sm)| > \u03bb  \u00b7 maxm\u2208[T ] \u2223\u2223\u2223\u2223\u2223f (S(`\u2190Z)m )\u2212 f (Sm)\u2223\u2223\u2223\u2223\u2223  \u2223\u2223\u2223\u2223\u2223\u2223\u2223\u2223\u2223\u2223\u2223\u2223\n(29)\nOur next task is to remove the indicator function in the first row. This is useful as the pairs( ~S`, ~S(`\u2190Z) ) and (~S`, ~S) are identically distributed, and hence, if we were to remove the indicator function, the first row would be equal to zero. To that end we add and subtract the first row with the complementary indicator function (this amounts to multiplying the third row by 2). We get\n(29) \u2264 \u2211 `\u2208[n] \u2223\u2223\u2223\u2223\u2223\u2223 E~S,~S \u2032\u223cDnT EZ\u223cDT  E t\u2190A(~S`) 1{t ,\u22a5} \u00b7 f (S(`\u2190Z)t )\u2212 f (St)\u2223\u2223\u2223\u2223\u2223\u2223 + (e\u03b5 \u2212 e\u2212\u03b5)n\u03c4\n+ 2 \u00b7 \u2211 `\u2208[n] \u2223\u2223\u2223\u2223\u2223\u2223\u2223\u2223\u2223\u2223\u2223\u2223 E ~S,~S \u2032\u223cDnT E Z\u223cDT 1  maxm\u2208[T ] |f (S`\u22121m )\u2212 f (S`m)| > \u03bb or maxm\u2208[T ] |f ( S (`\u2190Z) m ) \u2212 f (Sm)| > \u03bb  \u00b7 maxm\u2208[T ] \u2223\u2223\u2223\u2223\u2223f (S(`\u2190Z)m )\u2212 f (Sm)\u2223\u2223\u2223\u2223\u2223  \u2223\u2223\u2223\u2223\u2223\u2223\u2223\u2223\u2223\u2223\u2223\u2223\n(30)\nNow the first row is 0, so\n(30) = (e\u03b5 \u2212 e\u2212\u03b5)n\u03c4\n+ 2 \u00b7 \u2211 `\u2208[n] \u2223\u2223\u2223\u2223\u2223\u2223\u2223\u2223\u2223\u2223\u2223\u2223 E ~S,~S \u2032\u223cDnT E Z\u223cDT 1  maxm\u2208[T ] |f (S`\u22121m )\u2212 f (S`m)| > \u03bb or maxm\u2208[T ] |f ( S (`\u2190Z) m ) \u2212 f (Sm)| > \u03bb  \u00b7 maxm\u2208[T ] \u2223\u2223\u2223\u2223\u2223f (S(`\u2190Z)m )\u2212 f (Sm)\u2223\u2223\u2223\u2223\u2223  \u2223\u2223\u2223\u2223\u2223\u2223\u2223\u2223\u2223\u2223\u2223\u2223\n(31)\nWe can replace the or condition in the indicator function with the sum of the two conditions:\n(31) \u2264 (e\u03b5 \u2212 e\u2212\u03b5)n\u03c4\n+ 2 \u00b7 \u2211 `\u2208[n] \u2223\u2223\u2223\u2223\u2223\u2223 E~S,~S \u2032\u223cDnT EZ\u223cDT [ 1 { max m\u2208[T ] |f (S`\u22121m )\u2212 f (S`m)| > \u03bb } \u00b7 max m\u2208[T ] \u2223\u2223\u2223\u2223\u2223f (S(`\u2190Z)m )\u2212 f (Sm)\u2223\u2223\u2223\u2223\u2223] \u2223\u2223\u2223\u2223\u2223\u2223\n+ 2 \u00b7 \u2211 `\u2208[n] \u2223\u2223\u2223\u2223\u2223\u2223 E~S,~S \u2032\u223cDnT EZ\u223cDT [ 1 { max m\u2208[T ] |f ( S (`\u2190Z) m ) \u2212 f (Sm)| > \u03bb } \u00b7 max m\u2208[T ] \u2223\u2223\u2223\u2223\u2223f (S(`\u2190Z)m )\u2212 f (Sm)\u2223\u2223\u2223\u2223\u2223] \u2223\u2223\u2223\u2223\u2223\u2223 (32)\nIn the third row, we can replace maxm\u2208[T ] with \u2211 m\u2208[T ], to get\n(32) \u2264 (e\u03b5 \u2212 e\u2212\u03b5)n\u03c4\n+ 2 \u00b7 \u2211 `\u2208[n] \u2223\u2223\u2223\u2223\u2223\u2223 E~S,~S \u2032\u223cDnT EZ\u223cDT [ 1 { max m\u2208[T ] |f (S`\u22121m )\u2212 f (S`m)| > \u03bb } \u00b7 max m\u2208[T ] \u2223\u2223\u2223\u2223\u2223f (S(`\u2190Z)m )\u2212 f (Sm)\u2223\u2223\u2223\u2223\u2223] \u2223\u2223\u2223\u2223\u2223\u2223\n+ 2 \u00b7 \u2211 `\u2208[n] \u2211 m\u2208[T ] \u2223\u2223\u2223\u2223\u2223\u2223 E~S,~S \u2032\u223cDnT EZ\u223cDT [ 1 { |f ( S (`\u2190Z) m ) \u2212 f (Sm)| > \u03bb } \u00b7 \u2223\u2223\u2223\u2223\u2223f (S(`\u2190Z)m )\u2212 f (Sm)\u2223\u2223\u2223\u2223\u2223] \u2223\u2223\u2223\u2223\u2223\u2223 (33) Applying our assumptions on f and D to the third row brings us to\n(33) \u2264 (e\u03b5 \u2212 e\u2212\u03b5)n\u03c4 + 2nT\u2206\n+ 2 \u00b7 \u2211 `\u2208[n] \u2223\u2223\u2223\u2223\u2223\u2223 E~S,~S \u2032\u223cDnT EZ\u223cDT [ 1 { max m\u2208[T ] |f (S`\u22121m )\u2212 f (S`m)| > \u03bb } \u00b7 max m\u2208[T ] \u2223\u2223\u2223\u2223\u2223f (S(`\u2190Z)m )\u2212 f (Sm)\u2223\u2223\u2223\u2223\u2223] \u2223\u2223\u2223\u2223\u2223\u2223\n(34)\nThe issue now is that the expression inside the indicator function is different from the expression outside of it. To that end, we split the indicator function as follows:\n(34) \u2264 (e\u03b5 \u2212 e\u2212\u03b5)n\u03c4 + 2nT\u2206\n+ 2 \u00b7 \u2211 `\u2208[n] \u2223\u2223\u2223\u2223\u2223\u2223\u2223\u2223\u2223\u2223\u2223\u2223 E ~S,~S \u2032\u223cDnT E Z\u223cDT 1  maxm\u2208[T ] |f (S`\u22121m )\u2212 f (S`m)| > \u03bb and maxm\u2208[T ] \u2223\u2223\u2223\u2223\u2223f (S(`\u2190Z)m )\u2212 f (Sm)\u2223\u2223\u2223\u2223\u2223 > \u03bb  \u00b7 maxm\u2208[T ] \u2223\u2223\u2223\u2223\u2223f (S(`\u2190Z)m )\u2212 f (Sm)\u2223\u2223\u2223\u2223\u2223  \u2223\u2223\u2223\u2223\u2223\u2223\u2223\u2223\u2223\u2223\u2223\u2223\n+ 2 \u00b7 \u2211 `\u2208[n] \u2223\u2223\u2223\u2223\u2223\u2223\u2223\u2223\u2223\u2223\u2223\u2223 E ~S,~S \u2032\u223cDnT E Z\u223cDT 1  maxm\u2208[T ] |f (S`\u22121m )\u2212 f (S`m)| > \u03bb and maxm\u2208[T ] \u2223\u2223\u2223\u2223\u2223f (S(`\u2190Z)m )\u2212 f (Sm)\u2223\u2223\u2223\u2223\u2223 \u2264 \u03bb  \u00b7 maxm\u2208[T ] \u2223\u2223\u2223\u2223\u2223f (S(`\u2190Z)m )\u2212 f (Sm)\u2223\u2223\u2223\u2223\u2223  \u2223\u2223\u2223\u2223\u2223\u2223\u2223\u2223\u2223\u2223\u2223\u2223\n\u2264 (e\u03b5 \u2212 e\u2212\u03b5)n\u03c4 + 2nT\u2206\n+ 2 \u00b7 \u2211 `\u2208[n] \u2223\u2223\u2223\u2223\u2223\u2223 E~S,~S \u2032\u223cDnT EZ\u223cDT [ 1 { max m\u2208[T ] \u2223\u2223\u2223\u2223\u2223f (S(`\u2190Z)m )\u2212 f (Sm)\u2223\u2223\u2223\u2223\u2223 > \u03bb} \u00b7 maxm\u2208[T ] \u2223\u2223\u2223\u2223\u2223f (S(`\u2190Z)m )\u2212 f (Sm)\u2223\u2223\u2223\u2223\u2223] \u2223\u2223\u2223\u2223\u2223\u2223 + 2 \u00b7\n\u2211 `\u2208[n] \u2223\u2223\u2223\u2223\u2223\u2223 E~S,~S \u2032\u223cDnT EZ\u223cDT [ 1 { max m\u2208[T ] |f (S`\u22121m )\u2212 f (S`m)| > \u03bb } \u00b7 max m\u2208[T ] |f (S`\u22121m )\u2212 f (S`m)| ]\u2223\u2223\u2223\u2223\u2223\u2223\n\u2264 (e\u03b5 \u2212 e\u2212\u03b5)n\u03c4 + 6nT\u2206.\nA.2 Multi Sample Amplification\nTheorem A.2 (High Probability Bound). Let D be a distribution over a domain X, let f : Xn\u2192 R , and let \u2206,\u03bb,\u03c4 be s.t. for every 1 \u2264 i \u2264 n it holds that\nE S\u223cDn z\u223cD\n[ 1 {\u2223\u2223\u2223\u2223f (S)\u2212 f (S(i\u2190z))\u2223\u2223\u2223\u2223 > \u03bb} \u00b7 \u2223\u2223\u2223\u2223f (S)\u2212 f (S(i\u2190z))\u2223\u2223\u2223\u2223] \u2264 \u2206, and, furthermore, \u2200S \u2208 Xn and \u22001 \u2264 i \u2264 n we have\nE y,z\u223cD\n[ 1 {\u2223\u2223\u2223\u2223f (S(i\u2190y))\u2212 f (S(i\u2190z))\u2223\u2223\u2223\u2223 \u2264 \u03bb} \u00b7 \u2223\u2223\u2223\u2223f (S(i\u2190y))\u2212 f (S(i\u2190z))\u2223\u2223\u2223\u2223] \u2264 \u03c4, where S(i\u2190z) is the same as S except that the ith element is replaced with z. Then for every \u03b5 > 0 we have that\nPr S\u223cDn [|f (S)\u2212 f (Dn)| \u2265 6(e\u03b5 \u2212 e\u2212\u03b5)\u03c4n] < 14\u2206 (e\u03b5 \u2212 e\u2212\u03b5)\u03c4 ,\nprovided that n \u2265O (\n\u03bb \u03b5(e\u03b5\u2212e\u2212\u03b5)\u03c4 log ( (e\u03b5\u2212e\u2212\u03b5)\u03c4 \u2206 ))\nProof. We only analyze the probability that (f (S)\u2212 f (Dn)) is large. The analysis for (f (Dn)\u2212 f (S)) is symmetric. Assume towards contradiction that with probability at least 7\u2206(e\u03b5\u2212e\u2212\u03b5)\u03c4 we have that f (S) \u2212 f (Dn) \u2265 6(e\u03b5 \u2212 e\u2212\u03b5)\u03c4n. We now construct the following algorithm B that contradicts our expectation bound.\nAlgorithm 2 B Input: T databases of size n each: ~S = (S1, . . . ,ST ), where T , \u230a (e\u03b5\u2212e\u2212\u03b5)\u03c4\n7\u2206\n\u230b .\n1. Set H = {\u22a5,1,2, . . . ,T }.\n2. For i = 1, ...,T , define q(~S, i) = f (Si)\u2212 f (Dn). Also set q(~S,\u22a5) = 0. 3. Sample t\u2217 \u2208H with probability proportional to exp ( \u03b5 2\u03bbq(~S, t) ) .\nOutput: t.\nThe fact that algorithm B is (\u03b5, (f ,\u03bb))-differentially private follows from the standard analysis of the Exponential Mechanism of McSherry and Talwar [14]. The proof appears in Claim A.4 for completeness.\nNow consider applying B on databases ~S = (S1, . . . ,ST ) containing i.i.d. samples from D. By our assumption on D and f , for every t we have that f (St)\u2212 f (Dn) \u2265 6(e\u03b5 \u2212 e\u2212\u03b5)\u03c4n with probability at least 7\u2206(e\u03b5\u2212e\u2212\u03b5)\u03c4 . By our choice of T = \u230a (e\u03b5\u2212e\u2212\u03b5)\u03c4 7\u2206 \u230b , we therefore get\nPr ~S\u223cDnT [ max t\u2208[T ] {f (St)\u2212 f (Dn)} \u2265 6(e\u03b5 \u2212 e\u2212\u03b5)\u03c4n ] \u2265 1\u2212 ( 1\u2212 7\u2206 (e\u03b5 \u2212 e\u2212\u03b5)\u03c4 )T \u2265 1 2 .\nThe probability is taken over the random choice of the examples in ~S according to D. Thus, by Markov\u2019s inequality,\nE ~S\u223cDnT [ max t\u2208H { q(~S, t) }] = E ~S\u223cDnT [ max { 0 , max t\u2208[T ] (f (St)\u2212 f (D)) }] \u2265 3(e\u03b5 \u2212 e\u2212\u03b5)\u03c4n. (35)\nSo, in expectation, maxt\u2208H ( q(~S, t) ) is large. In order to contradict the expectation bound of Theorem A.2, we need to show that this is also the case for the index t\u2217 that is sampled on Step 3. To that end, we now use the following technical claim, stating that the expected quality of a solution sampled as in Step 3 is high.\nClaim A.3 (e.g., [2]). Let H be a finite set, h :H \u2192R a function, and \u03b7 > 0. Define a random variable Y on H by Pr[Y = y] = exp(\u03b7h(y))/C, where C = \u2211 y\u2208H exp(\u03b7h(y)). Then E [h(Y )] \u2265 maxy\u2208H h(y) \u2212 1 \u03b7 ln |H |.\nFor every fixture of ~S, we can apply Claim A.3 with h(t) = q(~S, t) and \u03b7 = \u03b52\u03bb to get\nE t\u2217\u2208RH [q(~S, t\u2217)] = E t\u2217\u2208RH\n[ 1{t\u2217 ,\u22a5} \u00b7 (f (St\u2217)\u2212 f (Dn))} ] \u2265max{0 , max\nt\u2208[T ] (f (St)\u2212 f (Dn))} \u2212 2\u03bb \u03b5 ln(T + 1).\nTaking the expectation also over ~S \u223c DnT we get that\nE ~S\u223cDnT t\u2217\u2190B ( ~S ) [ 1{t\u2217 ,\u22a5} \u00b7 (f (St\u2217)\u2212 f (Dn))} ] \u2265 E ~S\u223cDnT [ max { 0 , max t\u2208[T ] (f (St)\u2212 f (Dn)) }] \u2212 2\u03bb \u03b5 ln(T + 1)\n\u2265 3(e\u03b5 \u2212 e\u2212\u03b5)\u03c4n\u2212 2\u03bb \u03b5 ln(T + 1).\nThis contradicts Theorem A.2 whenever n > 2\u03bb\u03b5(e\u03b5\u2212e\u2212\u03b5)\u03c4 ln(T + 1) = 2\u03bb \u03b5(e\u03b5\u2212e\u2212\u03b5)\u03c4 ln( (e\u03b5\u2212e\u2212\u03b5)\u03c4 7\u2206 + 1).\nClaim A.4. Algorithm B is (\u03b5, (f ,\u03bb))-differentially private.\nProof. Fix two (f ,\u03bb)-neighboring databases ~S and ~S \u2032, and let b \u2208 {\u22a5,1,2, . . . ,T } be a possible output. We have that\nPr[B(~S) = b] = exp( \u03b52\u03bb \u00b7 q(~S,b))\u2211 a\u2208H exp( \u03b5 2\u03bb \u00b7 q(~S,a))\n(36)\nUsing the fact that ~S and ~S \u2032 are (f ,\u03bb)-neighboring, for every a \u2208 H we get that q(~S \u2032 , a) \u2212 \u03bb \u2264 q(~S,a) \u2264 q(~S \u2032 , a) +\u03bb. Hence,\n(36) \u2264 exp( \u03b52\u03bb \u00b7 [q(~S \u2032 ,b) +\u03bb])\u2211 a\u2208H exp( \u03b5 2\u03bb \u00b7 [q(~S \u2032 , a)\u2212\u03bb])\n= e\u03b5/2 \u00b7 exp( \u03b52\u03bb \u00b7 q(~S \u2032 ,b)) e\u2212\u03b5/2 \u2211 a\u2208H exp( \u03b5 2\u03bb \u00b7 q(~S \u2032 , a)) = e\u03b5 \u00b7Pr[B(~S \u2032) = b].\nFor any possible set of outputs B \u2286 {\u22a5,1,2, . . . ,T } we now have that\nPr[B(~S) \u2208 B] = \u2211 b\u2208B Pr[B(~S) = b] \u2264 \u2211 b\u2208B e\u03b5 \u00b7Pr[B(~S \u2032) = b] = Pr[B(~S \u2032) \u2208 B]."}], "references": [{"title": "Typicality-based stability and privacy", "author": ["Raef Bassily", "Yoav Freund"], "venue": "CoRR, abs/1604.03336,", "citeRegEx": "1", "shortCiteRegEx": "1", "year": 2016}, {"title": "Algorithmic stability for adaptive data analysis", "author": ["Raef Bassily", "Kobbi Nissim", "Adam D. Smith", "Thomas Steinke", "Uri Stemmer", "Jonathan Ullman"], "venue": "In Proceedings of the 48th Annual ACM SIGACT Symposium on Theory of Computing,", "citeRegEx": "2", "shortCiteRegEx": "2", "year": 2016}, {"title": "A measure of asymptotic efficiency for tests of a hypothesis based on the sum of observations", "author": ["Herman Chernoff"], "venue": "Ann. Math. Statist.,", "citeRegEx": "3", "shortCiteRegEx": "3", "year": 1952}, {"title": "Adaptive learning with robust generalization guarantees", "author": ["Rachel Cummings", "Katrina Ligett", "Kobbi Nissim", "Aaron Roth", "Zhiwei Steven Wu"], "venue": "In Proceedings of the 29th Conference on Learning Theory, COLT 2016,", "citeRegEx": "4", "shortCiteRegEx": "4", "year": 2016}, {"title": "Generalization in adaptive data analysis and holdout reuse", "author": ["Cynthia Dwork", "Vitaly Feldman", "Moritz Hardt", "Toniann Pitassi", "Omer Reingold", "Aaron Roth"], "venue": "In Advances in Neural Information Processing Systems (NIPS),", "citeRegEx": "5", "shortCiteRegEx": "5", "year": 2015}, {"title": "Preserving statistical validity in adaptive data analysis", "author": ["Cynthia Dwork", "Vitaly Feldman", "Moritz Hardt", "Toniann Pitassi", "Omer Reingold", "Aaron Roth"], "venue": "In ACM Symposium on the Theory of Computing (STOC)", "citeRegEx": "6", "shortCiteRegEx": "6", "year": 2015}, {"title": "Our data, ourselves: Privacy via distributed noise generation", "author": ["Cynthia Dwork", "Krishnaram Kenthapadi", "Frank McSherry", "Ilya Mironov", "Moni Naor"], "venue": "In Serge Vaudenay, editor, EUROCRYPT,", "citeRegEx": "7", "shortCiteRegEx": "7", "year": 2006}, {"title": "Calibrating noise to sensitivity in private data analysis", "author": ["Cynthia Dwork", "Frank McSherry", "Kobbi Nissim", "Adam Smith"], "venue": "In TCC,", "citeRegEx": "8", "shortCiteRegEx": "8", "year": 2006}, {"title": "Preventing false discovery in interactive data analysis is hard", "author": ["Moritz Hardt", "Jonathan Ullman"], "venue": "In FOCS,", "citeRegEx": "9", "shortCiteRegEx": "9", "year": 2014}, {"title": "Probability inequalities for sums of bounded random variables", "author": ["Wassily Hoeffding"], "venue": "Journal of the American Statistical Association,", "citeRegEx": "10", "shortCiteRegEx": "10", "year": 1963}, {"title": "Divide and conquer martingales and the number of triangles in a random graph", "author": ["J.H. Kim", "V.H. Vu"], "venue": "Random Structures and Algorithms,", "citeRegEx": "11", "shortCiteRegEx": "11", "year": 2004}, {"title": "On the number of iterations for dantzig-wolfe optimization and packing-covering approximation algorithms", "author": ["Philip N. Klein", "Neal E. Young"], "venue": "SIAM J. Comput.,", "citeRegEx": "12", "shortCiteRegEx": "12", "year": 2015}, {"title": "Concentration in unbounded metric spaces and algorithmic stability", "author": ["Aryeh Kontorovich"], "venue": "In Proceedings of the 31th International Conference on Machine Learning,", "citeRegEx": "13", "shortCiteRegEx": "13", "year": 2014}, {"title": "Mechanism design via differential privacy", "author": ["Frank McSherry", "Kunal Talwar"], "venue": "In FOCS,", "citeRegEx": "14", "shortCiteRegEx": "14", "year": 2007}, {"title": "Interactive fingerprinting codes and the hardness of preventing false discovery", "author": ["Thomas Steinke", "Jonathan Ullman"], "venue": "In COLT, pages 1588\u20131628,", "citeRegEx": "15", "shortCiteRegEx": "15", "year": 2015}, {"title": "Subgaussian tail bounds via stability arguments. ArXiv.org, (arXiv:1701.03493 [cs.DM]), 2017", "author": ["Thomas Steinke", "Jonathan Ullman"], "venue": null, "citeRegEx": "16", "shortCiteRegEx": "16", "year": 2017}], "referenceMentions": [{"referenceID": 5, "context": "Abstract A new line of work [6, 9, 15, 2] demonstrates how differential privacy [8] can be used as a mathematical tool for guaranteeing generalization in adaptive data analysis.", "startOffset": 28, "endOffset": 41}, {"referenceID": 8, "context": "Abstract A new line of work [6, 9, 15, 2] demonstrates how differential privacy [8] can be used as a mathematical tool for guaranteeing generalization in adaptive data analysis.", "startOffset": 28, "endOffset": 41}, {"referenceID": 14, "context": "Abstract A new line of work [6, 9, 15, 2] demonstrates how differential privacy [8] can be used as a mathematical tool for guaranteeing generalization in adaptive data analysis.", "startOffset": 28, "endOffset": 41}, {"referenceID": 1, "context": "Abstract A new line of work [6, 9, 15, 2] demonstrates how differential privacy [8] can be used as a mathematical tool for guaranteeing generalization in adaptive data analysis.", "startOffset": 28, "endOffset": 41}, {"referenceID": 7, "context": "Abstract A new line of work [6, 9, 15, 2] demonstrates how differential privacy [8] can be used as a mathematical tool for guaranteeing generalization in adaptive data analysis.", "startOffset": 80, "endOffset": 83}, {"referenceID": 15, "context": "Very recently, Steinke and Ullman [16] observed that these generalization guarantees can be used for proving concentration bounds in the non-adaptive setting, where the low-sensitivity function is fixed beforehand.", "startOffset": 34, "endOffset": 38}, {"referenceID": 5, "context": "1 Introduction A new line of work [6, 9, 15, 2] demonstrates how differential privacy [8] can be used as a mathematical tool for guaranteeing statistical validity in data analysis.", "startOffset": 34, "endOffset": 47}, {"referenceID": 8, "context": "1 Introduction A new line of work [6, 9, 15, 2] demonstrates how differential privacy [8] can be used as a mathematical tool for guaranteeing statistical validity in data analysis.", "startOffset": 34, "endOffset": 47}, {"referenceID": 14, "context": "1 Introduction A new line of work [6, 9, 15, 2] demonstrates how differential privacy [8] can be used as a mathematical tool for guaranteeing statistical validity in data analysis.", "startOffset": 34, "endOffset": 47}, {"referenceID": 1, "context": "1 Introduction A new line of work [6, 9, 15, 2] demonstrates how differential privacy [8] can be used as a mathematical tool for guaranteeing statistical validity in data analysis.", "startOffset": 34, "endOffset": 47}, {"referenceID": 7, "context": "1 Introduction A new line of work [6, 9, 15, 2] demonstrates how differential privacy [8] can be used as a mathematical tool for guaranteeing statistical validity in data analysis.", "startOffset": 86, "endOffset": 89}, {"referenceID": 5, "context": "[6] showed how to utilize this connection for the task of answering adaptively chosen queries w.", "startOffset": 0, "endOffset": 3}, {"referenceID": 5, "context": "1 ([6, 2], informal).", "startOffset": 3, "endOffset": 9}, {"referenceID": 1, "context": "1 ([6, 2], informal).", "startOffset": 3, "endOffset": 9}, {"referenceID": 15, "context": "Very recently, Steinke and Ullman [16] observed that Theorem 1.", "startOffset": 34, "endOffset": 38}, {"referenceID": 4, "context": "[5] showed that if \u03b2 is small enough, then w.", "startOffset": 0, "endOffset": 3}, {"referenceID": 0, "context": "However, a stronger notion than differential privacy \u2013 typical stability \u2013 presented by Bassily and Freund [1] does guarantee generalization in this setting.", "startOffset": 107, "endOffset": 110}, {"referenceID": 3, "context": "1A similar notion \u2013 perfect generalization \u2013 was presented in [4].", "startOffset": 62, "endOffset": 65}, {"referenceID": 7, "context": "2 (Differential Privacy [8, 7]).", "startOffset": 24, "endOffset": 30}, {"referenceID": 6, "context": "2 (Differential Privacy [8, 7]).", "startOffset": 24, "endOffset": 30}, {"referenceID": 13, "context": "2 The Exponential Mechanism We next describe the exponential mechanism of McSherry and Talwar [14].", "startOffset": 94, "endOffset": 98}, {"referenceID": 2, "context": "The first two inequalities are known as the multiplicative Chernoff bounds [3], and the last inequality is known as the Hoeffding bound [10].", "startOffset": 75, "endOffset": 78}, {"referenceID": 9, "context": "The first two inequalities are known as the multiplicative Chernoff bounds [3], and the last inequality is known as the Hoeffding bound [10].", "startOffset": 136, "endOffset": 140}, {"referenceID": 11, "context": "6 (Tightness of Chernoff bound [12]).", "startOffset": 31, "endOffset": 35}, {"referenceID": 1, "context": "[2] for the generalization properties of a differentially private algorithm that outputs a low-sensitivity function.", "startOffset": 0, "endOffset": 3}, {"referenceID": 13, "context": "The fact that algorithm B is (\u03b5, (f\u0304 ,1))-differentially private follows from the standard analysis of the Exponential Mechanism of McSherry and Talwar [14].", "startOffset": 152, "endOffset": 156}, {"referenceID": 1, "context": ", [2]).", "startOffset": 2, "endOffset": 5}, {"referenceID": 12, "context": "The following is one such refinement, by Kontorovich [13].", "startOffset": 53, "endOffset": 57}, {"referenceID": 12, "context": "1 ([13]).", "startOffset": 3, "endOffset": 7}, {"referenceID": 12, "context": "In [13], Kontorovich showed the following theorem: Theorem 4.", "startOffset": 3, "endOffset": 7}, {"referenceID": 12, "context": "2 ([13], informal).", "startOffset": 3, "endOffset": 7}, {"referenceID": 12, "context": "As stated in the previous section, the results of [13] can be used to obtain a high probability bound on |f (S)\u2212 f (Dn) | whenever Prx,y\u223cD[\u03c1(x,y) \u2265 t] \u2264 exp ( \u2212t2/\u03c32 ) for some \u03c3 > 0.", "startOffset": 50, "endOffset": 54}, {"referenceID": 10, "context": "Following the work of [17], in 2004 Kim and Vu [11] presented the following sharp bound:", "startOffset": 47, "endOffset": 51}, {"referenceID": 10, "context": "3 ([11], informal).", "startOffset": 3, "endOffset": 7}, {"referenceID": 9, "context": "4 ([10]).", "startOffset": 3, "endOffset": 7}, {"referenceID": 4, "context": "2 (Max-Information [5]).", "startOffset": 19, "endOffset": 22}], "year": 2017, "abstractText": "A new line of work [6, 9, 15, 2] demonstrates how differential privacy [8] can be used as a mathematical tool for guaranteeing generalization in adaptive data analysis. Specifically, if a differentially private analysis is applied on a sample S of i.i.d. examples to select a lowsensitivity function f , then w.h.p. f (S) is close to its expectation, although f is being chosen based on the data. Very recently, Steinke and Ullman [16] observed that these generalization guarantees can be used for proving concentration bounds in the non-adaptive setting, where the low-sensitivity function is fixed beforehand. In particular, they obtain alternative proofs for classical concentration bounds for low-sensitivity functions, such as the Chernoff bound and McDiarmid\u2019s Inequality. In this work, we set out to examine the situation for functions with high-sensitivity, for which differential privacy does not imply generalization guarantees under adaptive analysis. We show that differential privacy can be used to prove concentration bounds for such functions in the non-adaptive setting.", "creator": "LaTeX with hyperref package"}}}