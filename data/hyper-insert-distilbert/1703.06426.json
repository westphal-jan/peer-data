{"id": "1703.06426", "review": {"conference": "arxiv", "VERSION": "v1", "DATE_OF_SUBMISSION": "19-Mar-2017", "title": "Semi-Supervised Learning with Competitive Infection Models", "abstract": "there the goal of applying semi supervised learning methods is to effectively combine labeled and unlabeled labeled data extracted to and arrive at hopefully a better model. many such knowledge methods nevertheless rely on embedded graph - based cognitive approaches, where continuous labels are propagated naturally through selecting a parallel graph composed on even the largest input cluster points. here we argue in that it is more effective to confidently consider infection processes on these graphs, often whereby malaria at any discrete point sufficiently in time nodes can infect other nodes adjacent with their labels. since controlling the dynamics analyzed of these disease processes alone is stochastic, we develop elementary algorithms for efficiently estimating eventually the expected labels decay over time. we show caution that such our approach addresses many of for the limitations here of graph based learning, evaluation and evaluation is probably also empirically effective.", "histories": [["v1", "Sun, 19 Mar 2017 12:49:51 GMT  (49kb)", "https://arxiv.org/abs/1703.06426v1", null], ["v2", "Sun, 21 May 2017 07:17:41 GMT  (1289kb)", "http://arxiv.org/abs/1703.06426v2", null], ["v3", "Mon, 16 Oct 2017 21:26:17 GMT  (1313kb)", "http://arxiv.org/abs/1703.06426v3", null]], "reviews": [], "SUBJECTS": "cs.LG", "authors": ["nir rosenfeld", "amir globerson"], "accepted": false, "id": "1703.06426"}, "pdf": {"name": "1703.06426.pdf", "metadata": {"source": "CRF", "title": "Semi-Supervised Learning with Competitive Infection Models", "authors": ["Nir Rosenfeld", "Amir Globerson"], "emails": [], "sections": [{"heading": null, "text": "ar X\niv :1\n70 3.\n06 42\n6v 3\n[ cs\n.L G\n] 1\n6 O\nct 2\n01 7\nThe goal of semi-supervised learning methods is to effectively combine labeled and unlabeled data to arrive at a better model. Many methods rely on graph-based approaches, where labels are propagated through a graph over the input examples. In most current methods, the propagation mechanism underlying the learning objective is based on random walks. While theoretically elegant, random walks suffer from several drawbacks which can hurt predictive performance.\nIn this work, we explore dynamic infection processes as an alternative propagation mechanism. In these, unlabeled nodes can be \u201cinfected\u201d with the label of their already infected neighbors. We provide an efficient, scalable, and parallelizable algorithm for estimating the expected infection outcomes. We also describe an optimization view of the method, relating it to Laplacian approaches. Finally, experiments demonstrate that the method is highly competitive across multiple benchmarks and for various learning settings."}, {"heading": "1 Introduction", "text": "The supervised learning framework underlies much of the empirical success of machine learning systems. Nonetheless, results in unsupervised learning have demonstrated that there is much to be gained from unlabeled data as well. This has prompted considerable interest in the semi-supervised learning [11] setting, where the data includes both labeled and unlabeled examples. Methods for semi-supervised learning (SSL) are especially useful for applications in which unlabeled examples are ample, but labeled examples are scarce or expensive.\nOne of the most wide-spread approaches to SSL, and our focus in this paper, is the class of graph-based methods. In these, part of the problem input is a graph that specifies which input points should be considered close. Graph-based methods assume that proximity in the graph implies similarity in labels. There are many variations on this idea [5, 7, 36, 40], each using smoothness and graph distance differently. However, they all share the intuition that the classification function should be smooth with respect to the graph.\nOne way for encouraging smoothness in predictions is by optimizing an objective based on the graph Laplacian. This approach is prevalent in both classic SSL methods such as Label Propagation (LabelProp) [46] and its variants [45, 4, 41], as well as in recent deepembedding methods [44, 35]. Optimizing the quadratic learning objective in these methods can often be done by iterative local averaging of labels. This can be thought of as propagating labels under a certain averaging dynamic process, whose steady state corresponds to the optimum. Equivalently, the optimum can also be expressed as the probability that a random walk terminates at a certain state. Due to their elegance, computational properties, and empirical performance, random walks and local averaging have become the standard go-to mechanisms for propagating information in many applications. Nonetheless, they also have several shortcomings, which we address here.\nFirst, many of the guarantees of such methods hold only for undirected graphs. For directed graphs, the Laplacian is not necessarily PSD, meaning that the objective is no longer convex, and that the quadratic smoothness interpretation breaks down. Optimization in directed graph Laplacians is much harder and far less understood [42], and sampling is computationally prohibitive, slow to converge, and unstable [28, 29].\nSecond, such methods were originally designed for graphs that approximate the density of the data in feature space. As such, they can fail when applied to real graphs, especially large networks with a community structure. This is because random walks are prone to get stuck in local neighborhoods [9], because visiting all nodes can require an expected O(n3) steps [2],\nand since the limit distribution can be uninformative for large graphs [43] or when labels are rare [32].\nThird, extending such methods beyond the vanilla multiclass setting has proven to be quite challenging. For instance, outputting confidence in predictions is possible, but leads to extremely low values [41]. Label priors can be utilized, but only in determining the classification rule, rather than being incorporated into the model [46]. Most methods for an active semisupervised setting are either heuristic [22] or based on pessimistic worst-case objectives [23]. Finally, supporting structured labels is far from straightforward and can be computationally demanding [3].\nDue to the above, in this work we advocate for considering alternative mechanisms for propagating labels over a graph, and propose an approach which addresses most of the above issues. Our method, called Infection Propagation (InfProp), views the process of labeling the graph as a dynamic infection process. Initially, only the labeled nodes are \u201cinfected\u201d with their known labels. As time unfolds, unlabeled nodes can, with some probability, be infected by their neighbors. When this happens, they inherit the label of their infector. The labeled nodes therefore compete over infecting the unlabeled nodes with their labels. Since the infection process is stochastic we can calculate the probability that a given node was infected by a given label, and label the node according to this probability.\nExact calculation of the above infection probabilities is #P hard. However, we provide a fully polynomial-time randomized approximation scheme (FPRAS), which exploits an equivalence between the infection process and shortest paths in random graphs. The resulting algorithm is easy to parallelize, making the method highly scalable. It also extends to various learning settings, such as multilabel prediction and active SSL.\nInfProp is motivated by the idea that different graph types may require different dynamics for efficient propagation of information. It is inspired by propagation dynamics found in the natural and social worlds, and draws on the successful application of infection models in different contexts [25, 19, 13]. InfProp is especially efficient for graphs with highly intra-connected but lightly inter-connected components, a characteristic of many real-world networks. Fig. 1 illustrates this for a small synthetic random network with three clusters (see supplementary material for details). As can be seen, InfProp propagates information correctly, even when the seed set is very small. In comparison, LabelProp provides uninformative and almost uniform predictions which are prone to error, and shortest paths over the weighted graph err due to cross-cluster links.\nSince InfProp is a graph based method, it is intriguing to understand its relation to label propagation and random walk based methods. Our analysis in Sec. 5 provides some surprising connections. Specifically, we show that InfProp can be viewed as optimizing a quadratic objective, in which weights are related in an intricate manner to the undelying diffusion process. We conclude with an extensive set of experiments which demonstrate the effectiveness of our approach."}, {"heading": "2 Propagating Labels with Infections", "text": "In this section we present our infection-based method for semi-supervised learning. We are given as input a directed weighted graph G = (V,E,W ), as well as a subset of labeled nodes S \u2286 V referred to as the seed set. Each seed node s \u2208 S also comes with a true label ys \u2208 Y. We denote the unlabeled nodes by U = V \\S, and set n = |V |, m = |E|, L = |Y|, and k = |S|. In some settings additional node features are available.\nWe focus on the transductive setting, where the goal is to predict the labels of all non-seed nodes u \u2208 U .\nThe core idea of our method is to propagate labels from labeled to unlabeled nodes using infection dynamics. The process is initialized with all seed nodes in an infected state and all unlabeled nodes in a null state \u2205. Then, a stochastic model of infection dynamics is used to determine how the infectious state of nodes in the graph changes over time, typically as a function of the states of neighboring nodes. To allow for multiple label classes, we consider competitive infection models. In these, seed nodes s \u2208 S are initialized with their true labels ys, and compete in infecting unlabeled nodes.\nThe models we consider are stochastic and converge to a steady state. This means that, after some time point, the labels of all nodes will not change anymore (we refer to this as process termination, or steady state). Since the process itself is stochastic each instantiation will result in a different value for the labels at termination. For a given infection model, let Yv\u2113 be the binary random variable indicating whether node v is infected by label \u2113 at steady state.1 Since our goal is to reason about the labels of the nodes, it will be natural to utilize the infection dynamics to generate probabilistic predictions. For each node v, our method outputs a distribution over labels fv. Each entry fv\u2113 corresponds to the probability that v had value \u2113 at steady state, as a function of the seed set S and its labels. Formally:\nfv\u2113(S, y) = P [Yv\u2113 = 1] = E [Yv\u2113] (1)\nNote that \u2113 can take values in 1, . . . , L but also \u2113 = 0 for \u2205. The entry fv0 therefore describes the (possibly non-negative) probability that v remained uninfected.\nAs we show in Sec. 2.2, even for simple infection models, computing f exactly is #P-hard. Like many other infection-based methods [25, 16, 15], we resort to a Monte-Carlo approach and estimate f by averaging over infection outcomes Y . Our final predictor f\u0302 is:\nf\u0302v\u2113(S, y) = 1\nN \u2211N i=1 Y (i) v\u2113 (2)\nwhere Y (i) v\u2113 is an indicator for the i th random instance.\nIn principle, outcomes Y can be evaluated by simulating the infection dynamics. This however is not straightforward for several of the models we consider, such as those with continuous time. In the next section we describe some infection models, and show how f\u0302 can be efficiently computed for them using an alternative graphical representation of the infection process.\nWe conclude by stating an approximation bound for f . As we can calculate f\u0302 efficiently (see next section) this\n1For multilabel tasks, Y is the set of seed node identities, and f becomes a weighted sum of their labels.\nimplies that our method yields an efficient approximation scheme for the true infections probabilities.\nProposition 1. For every \u01eb, \u03b4 \u2208 [0, 1], if N \u2265 1\n2\u01eb2 log 2n(L+1) \u03b4 , then with probability of at least 1\u2212 \u03b4, Algorithm 2 returns f\u0302 such that \u2016f\u0302 \u2212 f\u2016\u221e \u2264 \u01eb.\nProof. Note that each Yv\u2113 is a random variable in {0, 1}. Furthermore, f\u0302 is an average of Y , and f is the corresponding expectation. The result is obtained by applying the Hoeffding and union bounds."}, {"heading": "2.1 Competitive Infection Models for Graph Labeling", "text": "As mentioned above, our SSL method relies on an infection process which infects nodes of the graph with labels. There are of course many variants of infection processes, and we described some relevant ones below."}, {"heading": "2.1.1 The Independent Cascade model", "text": "Since its introduction in [18], the simple but powerful Independent Cascade (IC) model has been used extensively. The original IC model, briefly reviewed below, is a discrete-time, network-dependent interpretation of the classic Susceptible-Infected-Recovered (SIR) epidemiological model [26]. At time t = 0, seed nodes are initialized to an infected state, and all other nodes to a susceptible state. If node u is infected at time step t, then at time t + 1 it attempts to infect each of its non-infected out-neighbors v \u2208 Nei(u), and succeeds with probability puv. If successful, we refer to the edge (u, v) as active or activated, mark the infection time of v as \u03c4v = t+1, and set v\u2019s infector to be u, which we denote by \u03c1(v) = u. The model is therefore parametrized by the set of all edge infection probabilities {puv | (u, v) \u2208 E} (given as input via Wuv = puv). Once a node becomes infected, it remains in this state. As infections are probabilistic, not all nodes are necessarily infected. The process terminates either when all nodes are infected, or (more commonly) when all infection attempts at some time step are unsuccessful.\nThe IC model describes the propagation of a single infectious content. Hence, it can tell us only when and how a node is infected, but not by what. This motivated a class of competitive infection models which support multiple content types. Several competitive IC variants have been proposed [8, 10, 12, 24]. The common theme in these is that nodes inherit the label of their earliest infector (with tie-breaking when needed). All of these are supported by our method. In the supplementary material we show how our approach can also be applied to threshold models [25].\nAlgorithm 1 BasicInfProp(G,S, y, p,N)\n1: for i = 1, . . . , N do 2: Initialize Y (i) u\u2113 \u2190 0 for all u \u2208 U, \u2113 \u2208 Y \u222a\u2205 3: for (u, v) \u2208 E do 4: Wuv \u2190 1 with probability puv, and \u221e o.w. 5: for s \u2208 S do 6: dist[s][ \u00b7 ] \u2190 Dijkstra(G,W, s) 7: for u \u2208 U do 8: Y\n(i) u,\u03b1(u) \u2190 1 where \u03b1(u) \u2208 argmins dist[s][u]\n9: Return f\u0302 = 1 N \u2211N i=1 Y (i)"}, {"heading": "2.1.2 Continuous Time Dynamics", "text": "While simple and elegant, the IC dynamics are somewhat limited in their expressive power. One important generalization is the Continuous-Time IC model (CTIC) [19]. This model is well suited for SSL as it is flexible, does not require tie-breaking, and allows for incorporating node priors. In this model, a successful infection attempt entails an \u201cincubation period\u201d, after which the node becomes infected. Hence, if u succeeds in infecting v at time \u03c4u \u2208 R\n+, it draws an incubation time \u03b4uv \u223c D(\u03b8uv), and v can become infected at time \u03c4uv = \u03c4u+\u03b4uv. As in the IC model, v inherits the label of its earliest infector \u03c1(v) = argminu \u03c4uv. The competitive CTIC model generalizes the competitive IC model for an appropriate choice of D, where \u03b4e is set to 1 with probability pe, and\u221e with probability 1\u2212pe. We will therefore consider a general mixture distribution of activations and incubation times D(p, \u03b8). Since infections are determined by the earliest successful attempt, the shortest-paths interpretation and algorithm (Sec. 2.2.1) hold for the random graph G\u03b4 = (V,E, \u03b4)."}, {"heading": "2.2 Computing Infections Efficiently", "text": "For infection models as in Sec. 2.1, we would like to calculate predictions f\u0302 as in Eq. (2). A naive approach would be to do this via simulating the infection process N times and averaging. This, however, is inefficient for discrete-time IC, requires continuous time simulation for CTIC, and does not apply to general models. We hence provide an equivalent efficient alternative below."}, {"heading": "2.2.1 Infections as Shortest Paths", "text": "We now present an alternative view of the sampling process, which facilitates efficient implementation and extensions. Consider first the discrete time IC process. For a single instantiation of the process, recall that if u succeeded in infecting v, the edge (u, v) is considered active. We use the set of active edges A \u2286 E (sam-\npled throughout the instantiation until termination) to construct the active graph GA = (V,E,WA) with weights WAe = 1 for e \u2208 A and W A e = \u221e for e \u2208 E \\A. An important observation is that node v is infected at termination iff there exists a path in GA from some seed node s \u2208 S to v with finite weight. We refer to this as an active path. Since v\u2019s actual infection time \u03c4v is set by the earliest successful infection, it is also the length of the shortest active path from some s \u2208 S.\nThe above formulation allows us to replace time with graph distances. Let dA(u, v) be the distance from u to v in GA. Due the recursive nature of label assignment, it follows that a node v inherits its label from the seed node s \u2208 S whose distance to v is shortest. We refer to s as v\u2019s ancestor, denoted by \u03b1(v) and set \u03b1(v) = \u2205 when there are no paths from S to v. We can now express the infection outcomes Yv\u2113 using distances:\nYv\u2113 = 1{\u2113 = y\u03b1(v)}, \u03b1(v) = argmin s\u2208S dA(s, v) (3)\nRecall that our motivation here was to compute Y without simulating the dynamics. Since distances dA depend on edge activations, it is not yet clear why Eq. (3) is useful. An important result by [25] shows ancestors can be computed over a simpler random graph model. Specifically, let A\u0303 \u2286 E be a random edge set, where each edge (u, v) \u2208 E is sampled independently to be in A\u0303 with probability puv. Then, for an appropriately defined GA\u0303 and dA\u0303, we have:\n\u03b1(v) = argmin s\u2208S dA\u0303(s, v) (4)\nThus, to compute each Y (i) v\u2113 (and hence f\u0302), it suffices to sample edges independently, and compute shortest paths on GA\u0303, bypassing the need for simulation. Under this view, f can be thought of as an ensemble of shortest-path predictors, whose weights are set by the dynamics. Algorithm 1 provides a simple implementation of this idea for the discrete time IC model. After sampling edges, the algorithm computes shortest paths (using Dikjstra) from each s \u2208 S to all u \u2208 U . Then, each node u is assigned the label of its ancestor \u03b1(u). This approach applies to a large class of infection models that admit to a similar graphical form [25]."}, {"heading": "2.2.2 Improved Efficiency via Modified Dijkstra", "text": "Recall that for a single infection instance, a node inherits its label from the closest seed node. Based on this, Algorithm 1 offers a direct approach for computing f , where shortest paths are computed from each of the k seed nodes to every unlabeled node v \u2208 U using k calls to Dijkstra. While correct, this method suffers an unnecessary factor of k on its runtime. To reduce\nthis overhead, we change Dijkstra\u2019s initialization and updates, so that only a single call would suffice. Algorithm 2 implements this idea for the more general CTIC model and allows for node priors (Sec. 2). The correctness of the algorithm is stated below, and a proof is provided in the supplementary material.\nProposition 2. Algorithm 2 correctly computes the average infection probabilities f\u0302 in Eq. (1).\nThe worst-case complexity of Dijkstra, and hence of each iteration in Algorithm 2, is O(m+n logn). Other implementations of Dijkstra which support further parallelization or GPUs [30] can also be modified for our setting. Nonetheless, the practical run time of Algorithm 2 can be, and typically is, much better, for two reasons. First, note that only the subset of active edges are traversed (and sampled on the fly), and only nodes which are reachable from S are processed. The infection parameters p therefore induce a tradeoff between the influence diameter of S and the run time (empirical demonstration in Fig. 3 (left)). Second, many settings require \u201chard\u201d predictions y\u0302 \u2208 Y, typically set by y\u0302v = argmax\u2113 f\u0302u\u2113. Hence, for y\u0302v to be correct, it suffices that f\u0302u,yu \u2265 f\u0302u\u2113 for all \u2113 \u2208 Y, which does not require the full convergence stated in Proposition 1 (empirical demonstration in Fig. 3 (right)).\nIn this section we showed how infection outcomes can be computed efficiently. It is therefore only natural to ask - what is it that infections compute? In the next section we show that f is in fact the solution to a quadratic optimization objective, whose weights depend on the infection dynamics."}, {"heading": "3 What do infections optimize?", "text": "Many SSL methods propose an optimization objective which encodes some notion of smoothness. For instance, the classic LabelProp algorithm [46] encourages adjacent nodes to agree on their predicted labels by minimizing a quadratic penalty term:\nflp = argmin f \u2032\n\u2211\n\u2113\n\u2211\nu,v\nWuv(f \u2032 u\u2113 \u2212 f \u2032 v\u2113) 2 (5)\nfor predictions f \u2032 and symmetric and normalized weightsW , subject to f \u2032s = ys for all s \u2208 S. In this section we show that InfProp has a related interpretation. Specifically, we show that the InfProp predictions f minimize the quadratic objective in Eq. (13).\nWhile similar in structure, the fundamental difference between Eqs. (5) and (13) lies in how the weights are determined. In LabelProp (and variants), edge weights are given as input, and are typically set according to some feature-based similarity measure. In this sense, each Wuv is a local function of the features of u and\nAlgorithm 2 InfProp (G,S, y,D, q,N)\n1: for i = 1, . . . , N do 2: Initialize Y (i) u\u2113 \u2190 0 for all u \u2208 U, \u2113 \u2208 Y \u222a\u2205 3: for v \u2208 U do 4: dist[v] \u2190 \u221e, y[v] \u2190 \u2205 5: for s \u2208 S do 6: dist[s] \u2190 0, y[s] \u2190 ys 7: push s into min-queue Q 8: while Q is not empty do 9: pop v from Q \u22b2 break ties randomly 10: for u \u2208 Nei(v) do 11: sample \u03b4vu \u223c D(\u03b8, p) \u22b2 incubation time 12: if \u03b4vu = \u221e then continue 13: alt \u2190 dist[v] + wAvu + qu(y[v]) \u22b2 penalize 14: if alt < dist[u] then 15: dist[u] = alt 16: y[u] \u2190 y[v] \u22b2 u inherits label from parent v 17: update u in Q with dist[u] 18: Y (i) u,y[v] \u2190 1 for all u \u2208 U 19: Return f\u0302 = 1 N \u2211N i=1 Y (i)\nv. In contrast, weights in Eq. (13) are set in a global manner. As we show next, each weight is a function of the infection dynamics, of the specific seed set S, and, if available, of the features of all nodes. To demonstrate this, and to see why Eq. (13) holds, it will be helpful to analyze InfProp from a spectral perspective."}, {"heading": "3.1 A Laplacian Interpretation for InfProp", "text": "An interesting property of LabelProp is that its objective can be expressed via the graph Laplacian. For a directed weighted graph, the standard Laplacian is:\nLlp = D \u2212W (6)\nwhere D is a diagonal matrix with Duu = \u2211\nv Wuv (and W is symmetric). The output of LabelProp can be computed by solving the system Llpf\n\u2032 = 0 for the unlabeled nodes. We now show that the infectionbased predictions of InfProp also correspond to the solution of a certain Laplacian system which is determined by the seed set and the infection dynamics.\nConsider a single infection instance, and denote by Tuv(S) the random variable indicating whether u was infected by v for seed S, namely Tuv(S) = 1{u=\u03c1(v)}. We refer to the matrix T as the infector matrix. Further denote by T the expected infector matrix T (S) = E [T (S)]. We use this to define the following Laplacian:\nL(S) = I \u2212 T (S) (7)\nNote that L is defined over the same graphG, but need not be symmetric. We now show that L is indeed a Laplacian matrix, and that it can be used to infer f .\nLemma 1. The infection-based predictions f in Eq. (2) are also the solution to the Laplacian system:\nL(S)f = b(S) (8)\nwhere:\nbu\u2113(S) = \u2211\nv\nb (S) vu\u2113, b (S) vu\u2113 = cov [Tvu(S), Yu\u2113]\nFor conciseness, we defer the full proof to the supplementary material, and show here a useful special case.\nLemma 2. If T and Y are uncorrelated, then the infection-based predictions f in Eq. (2) are also the solution to the homogeneous Laplacian system:\nL(S)f = 0 (9)\nProof. We first show that L is a graph Laplacian, namely that the sum of each row in T equals the corresponding diagonal element in I, which is 1. Since rows in T have only one non-zero entry of value one, each row in T is positive and sums to one. Note that T u\u00b7 provides a distribution over the infectors of u.\nWe now prove Eq. (9). By definition, the label of each node at steady state is set to be that of its infector, namely Yv\u2113 = Y\u03c1(v),\u2113 for all v and \u2113, or simply Y = TY . Using Eq. (2) and applying expectation, we have:\nf(S) = E [Y ] = E [T (S)Y ] (10)\nWhen T, Y are uncorrelated, E [TY ] = E [T ]E [Y ], hence f = T f. Rearranging concludes our proof."}, {"heading": "3.2 InfProp as Optimization", "text": "We next use the Laplacian insight above to provide an objective minimized by the InfProp solution. Begin by noting that for LabelProp, Eq. (6) can be restated as:2\nflp = argmin f \u2032\n\u2016Llpf \u2032\u201622\n= argmin f \u2032\n\u2211\n\u2113\n\u2211\nu\n( f \u2032u \u2212 \u2211\nv\nWuvf \u2032 v\n)2 (11)\nwhere minimization is only over the unlabeled nodes. This gives an alternative quadratic objective, which lower-bounds Eq. (5),3 and directly expresses the steady-state of LabelProp\u2019s averaging dynamics. In a similar fashion, we can restate Eq. (8) as:\nf(S) = argmin f \u2032\n\u2016L(S)f \u2032 \u2212 b(S)\u201622 (12)\n2Using the symmetry and normalization of W 3Using Jensen\u2019s inequality\nExpanding and denoting w (S) uv = T uv(S) provides the general objective of our method:\nmin f \u2032\n\u2211\n\u2113\n\u2211\nu\n( f \u2032u\u2113 \u2212 \u2211\nv\n( w(S)uv f \u2032 v\u2113 + b (S) uv\u2113 ))2 (13)\nNote that Eq. (13) and Eq. (11) are structurally equivalent up to the bias terms, which disappear when the conditions of Lemma 2 hold. The critical difference is that the weights in Eq. (13) are intricate functions of the dynamics, rather than just scalars. Through their dependence on T and Y , the weights and bias terms in Eq. (13) are in fact functions of the dynamics. In this sense, w (S) uv quantifies how well v relays information from S to u, which depends on the entire graph. Similarly, the term b (S) uv\u2113 quantifies consistency between the identity of u\u2019s infector (v) and the inherited label (\u2113). This means that frequent yet indecisive infectors are penalized, while reliable nodes remain unbiased.\nFinally, note that the optimization interpretation above does not offer a better optimization scheme, since calculating the weights w(S) and b(S) would require sampling, and hence our InfProp sampling algorithms from Sec. 2.2 would be a simpler approach."}, {"heading": "4 Other Learning Settings", "text": "In this section we briefly describe how our method extends to other learning settings used in our experiments. For more details please see the supp. material.\nIncorporating features and priors: Many network based datasets include additional node features or priors. Our method incorporates priors directly into the CTIC dynamics by penalizing incubation times. Denote by \u03c1v\u2113 the prior for labeling v with \u2113, and let q : [0, 1] \u2192 R be a penalty function. If u succeeds in infecting v with \u2113, the incubation time \u03b4uv is penalized by an additional q(\u03c1v\u2113). For a decreasing q , high priors induce low penalties, and vice versa. Although penalties are deployed locally, they delay the global propagation of the penalized label across the graph.\nConfidence and active learning: Recall that v remains uninfected with probability fv0. Hence, \u03c3v(S) = 1\u2212 fv0 serves as a natural measure of confidence. We use this as a selection criteria for an active setting where the goal is to choose a seed set of size k. The objective we consider coincides with the well-studied notion of influence [25], which is monotone and submodular and admits to an efficient greedy approximation scheme. Our method offers a tractable alternative to existing active SSL methods [23, 17, 21]."}, {"heading": "5 Related Work", "text": "As in unsupervised learning, methods for semisupervised learning are often based on assumptions regarding the structure of the unlabeled data. One such assumption is that of smoothness, which states that examples that are close are likely to have similar labels. In the classic Label Propagation algorithm [46], adjacent nodes in the graph are encouraged to agree on their labels via a quadratic penalty. Some variants add regularization terms [4], allow for label uncertainty [41], or include normalization and unanchored seeds [45]. An interesting property of this approach is that, for undirected graphs, the objective can be interpreted as the solution to a Laplacian system, as the outcome of a random walk process, and as the fixed point of a dynamic process of label propagation.\nThe above methods were originally designed for graphs that approximate the data density by encoding similarity in feature space. In many cases, these graphs need to be constructed from the sample set. Since many modern datasets originate from real-world networks, several SSL methods have been recently introduced that utilize the graph as an additional source of information. Motivated by the success of deep embedding techniques [31], these methods embed the nodes of a graph into a low-dimensional vector space, which can then be used in various ways. When the data includes only the graph, the embeddings can be used as input for an off-the-shelf predictor [35]. When the data includes additional node features, the embedding can act as a regularizer for a standard loss over the labeled nodes [44, 27]. In contrast to classic methods, these methods propagate features rather than labels.\nAn alternative but related method for utilizing graphs is to consider shortest paths as a measure of closeness between nodes. The authors of [1] show that Laplacians and shortest paths are in some sense special cases of resistance distances, and propose (but do not evaluate) a new regularizer. Other methods construct adhoc graphs whose shortest paths approximate density-\nbased distances [34, 6]. Our method, which can be viewed as an ensemble of shortest paths, can be applied to any graph. A recent work [14] proposes a method for SSL in directed graphs based on distance diffusion. As they consider distances from unlabeled to labeled nodes, each instance of their model is computationally intensive, and requires an approximation scheme. In contrast, we consider distances from labeled to unlabeled nodes, which can be computed efficiently. While for a specific setting (symmetric weights and a certain link function) both models overlap, in this paper we consider a more general setup.\nAs mentioned, our method draws on the rich literature of infection models and diffusion processes over networks. Infection models have been used for describing the propagation of information, innovation, behavioral norms, influence, and others. Such models were popularized in a seminal work on choosing a seed set which maximizes influence [25]. In our work we leverage this concept for choosing nodes in an active semi-supervised learning setting. Other methods have utilized infection models for network inference [19], influence maximization [25] estimation [16, 15] and prediction [37], and personalized marketing [13]."}, {"heading": "6 Experiments", "text": "We evaluated our method on various learning tasks over three benchmark dataset collections, which include network based data for multiclass learning with\n[39] and without features [38], and multilabel learning [33]. The datasets include diverse networks such as social networks, citation and co-authorship graphs, product and item networks, and hyperlink graphs. Dataset statistics can be found in the supplementary material.\nOur experimental setup follows the standard graphbased semi-supervised learning evaluation approach. Specifically, in each instance we draw a seed set of size k uniformly at random, acquire its labels, and then use the graph and labeled seed set to generate labels for all nodes. We repeat this procedure for 10 random seed set selections and for various values of k (where k is set to be a fixed proportion of the number of nodes in the graph) and report average results.\nWe compared our method to current state-of-the-art baselines, which include spectral methods as well as deep embedding methods. For tasks which do not include features, these included LabelProp [46], Adsorption [4], MAD [41], and the feature-agnostic deep method DeepWalk [35]. For tasks which do include features, we compared to the prior-supporting spectral method LLGC [45], the recent feature-based deep method Planetoid [44], LabelProp as a graph-only baseline, logistic regression (LogReg) as a features-only baseline, and a baseline where labels are set by shortest paths in G (ShortPaths). For the active setting (Fig. 2), we compared our approach (Greedy) to METIS [22]), to choosing high-degree nodes (HiDeg), and to random seeds (Rand).\nFor our method (InfProp) we used exponential incubation times \u03b4 \u223c Exp(\u03b8). As in many works (e.g., [25, 14]), we used \u03b8uv = 1/du for all node pairs (u, v) \u2208 E, where du is the out-degree of u. We set the number of random instances to N = 1, 000. Fig. 3 (right) demonstrates accuracy and convergence as a function of N . We show results for two variants: InfProp, where we set activation probabilities to p = 1 for all edges, and InfProp0.5, where p = 0.5. In addition to providing a confidence measure, InfProp0.5 is much faster, while on average achieving 0.99% of the performance of InfProp. Fig. 3 (left) demonstrates the tradeoff in accuracy and runtime when varying p.\nMost methods we consider naturally output probabilistic \u201csoft\u201d labels as predictions. We therefore evaluate\nperformance using both probabilistic or order-based performance measures, as well as performance measures for \u201chard\u201d labels. For all methods, hard labels were generated by choosing the label with the highest value. Tables 1 and 2 include results for all datasets for k = 0.1% of the data. Fig. 2 shows results for various values of k on the CoRA dataset, since it appears in all learning tasks. As can be seen, InfProp consistently performs well across all settings."}, {"heading": "7 Conclusions", "text": "In this work we presented an SSL method where labels propagate over the graph using dynamic infection models. These models have a strong connection to short-path ensembles and to graph Laplacians, allow for efficient computation, and show empirical potential. Our work was motivated by the idea that different graph types may require different dynamics, which led us to consider alternatives to random walks and averaging dynamics. We used a competitive CTIC variant, but other infection models (and other dynamics in general) can be considered. The choice of dynamics can serve as a means for expressing prior knowledge and for encoding structure and dependencies.\nThe models we use have very few tunable parameters. Nonetheless, one can consider highly parametrized models. Such parameters can be used to control infection probabilities, be node or label specific, relate to features, and even adjust the dynamics themselves. The stochastic nature of the models and the nonlinearity of the dynamics makes learning these parameters a challenging task, which we leave for future work.\n4Our results differ from those in [44] since their evaluation is based on a specific seed of fixed size, chosen by a different procedure, evaluated only on 1000 test samples, and early-stopped using test data."}, {"heading": "1 Proof of Proposition 2 in Main Text", "text": "In this section we prove the correctness of our algorithm. The proof considers the more general CTIC infection dynamics and allows for node features or priors (via a penalty function).\nIn the infection dynamics presented in the paper, once a node\u2019s label is set, it remains fixed. In contrast, during the course of the algorithm a node\u2019s label may change with each distance update. It therefore remains to show that the algorithm outputs the desired labels. For basing our claim it will be easier to assume that instead of initially inserting all seed nodes into Q, we add a dummy root node r to V , with edges of length wrs = 0 to all s \u2208 S, and initialize Q to include only r. It is easy to see that after extracting r from Q, we return to our original algorithm.\nRecall that the standard single-source Dijkstra algorithm offers three important guarantees: (1) the estimated distance of an extracted node is correct (and remains unchanged), (2) nodes are extracted in increasing order of their true distance, and (3) the distance estimates always upper-bound the true distances. Now, let v \u2208 U be a node that has just been extracted, and assume by induction that the labels of all previously extracted nodes (which include all seed nodes) are correct.5 The above guarantees tell us that the distance from r to v is correct, and all nodes on the shortest path from r to v have already been extracted. This is true even when a penalty is incurred, as it can only increase the distance estimate. As these nodes are assumed to be correctly labeled, v inherits the correct label as well, as by construction its shortest path from r goes through exactly one seed node. The correctness of the seed node labels gives the induction basis, which concludes the proof.\n5Correct in the sense of the algorithm, not in the sense of their true labels."}, {"heading": "2 Extensions", "text": "In this section we describe in more depth several useful extensions of our method. These include applying out method to the Linear Threshold model, incorporating node features and priors into the infection dynamics, and a framework for using our method in an active SSL setting."}, {"heading": "2.1 The Linear Threshold model", "text": "In this section we show how InfProp can be applied with the Linear Threshold (LT) dynamics, rather than the IC or CTIC dynamics discussed in the text. This includes adapting the algorithm for computing expected labels to the LT model, as well as supporting node features and priors.\nThe input to the LT model is a weighted graph G = (V,E,W ) and an initial set of infected seed nodes S. We assume that weights are positive, and that for each v \u2208 V , the sum of incoming weights \u2211 v Wuv is at most 1 (thought can be strictly less than 1). Before the process begins, each node u is assigned a threshold \u03b7u sampled uniformly at random from the interval [0, 1]. The dynamics then progress in discrete time steps, where at time t, a susceptible node v becomes infected if the weighted sum of its infected neighbors exceeds its threshold. Denoting by Iu(t) an indicator of whether u is infected at time t, v is infected at time t if: \u2211\nu\nWuvIv(t\u2212 1) \u2265 \u03b7u (14)\nNote that the randomness in this model comes from the threshold \u03b7; given \u03b7, the dynamics are deterministic.\nIntriguingly, the authors of [25] show that the LT model can also be equivalently expressed using a graphical perspective using active edge sets. Here, however, edges are no longer sampled independently. Instead, for each node v, only at most one incoming edge will become active in each instance. Specifically, for each node v, an edge (u, v) \u2208 E is going to be se-\nlected to be the active incoming edge with probability puv = Wuv, where no incoming edges are active with probability W\u2212u = 1 \u2212 \u2211 v Wuv . Then, for a given instance, v is infected if and only if there is an active path to v from some seed node in S.\nAn interesting interpretation of the above is that the chosen active edge (u, v) can be thought of as corresponding to the node u whose infection triggered the infection of v by crossing the threshold. Under this view, a type-dependent specification of the above model is one where v inherits its label from its triggering neighbor v, which we refer to as his infector. This model readily applies to the competitive setting which we consider. In terms of implementation, the only necessary modification to the algorithm is the way in which active edges are sampled.\nThe competitive LT model can also incorporate node priors using penalty terms. Specifically, the nodelabel prior \u03c1v\u2113 will induce a multiplicative penalty qv(\u2113) \u2208 [0, 1] on the original weights Wuv when u tries to infect v with label \u2113. Thus, given that u has label \u2113, the penalty reduces the probability that it will be the infector of v. To implement this, when u is expanded, the edge (u, v) is sampled to be active with the penalized probability, and all other incoming weights (including the complementing W\u2212u) are re-normalized."}, {"heading": "2.2 Incorporating node features and priors", "text": "In addition to the graph, many network based datasets include node or edge features. These can be used to generate node-specific class priors. In this section we describe a novel generalization of the competitive infection models introduced above which incorporates class priors into the dynamics. In this setting, our approach is to first train a probabilistic classifier (e.g., logistic regression) on the labeled seed set, and then use its predictions on the unlabeled nodes as a prior for our model.\nOur method utilizes node priors by transforming them into penalties on incubation times. Consider a single instance of an infection process. Assume node u has just been infected with label \u2113 \u2208 Y, and succeeded in its attempt to infect node v with an incubation time of \u03b4uv. If \u03b4uv is small, then it is very likely that v will get infected with \u2113 as well. On the other hand, if \u03b4uv is large, then other nodes might have a chance to infect v with other labels. This motivates the idea of further penalizing the infection time of a node according to its prior. We do this by adding a label-dependent penalty qv(\u2113) to \u03b4uv, as a function of the prior \u03c1v\u2113. We use the link function qv(\u2113) = \u2212 log(\u03c1v\u2113), which maps low priors into large penalties, and high priors into low penalties, where \u03c1v\u2113 = 1 entails no penalty. Hence,\nsetting \u03c1v\u2113 = 1 for all v, \u2113 recovers the original model.\nNote that while the priors are deployed locally, their effect is in fact global, as penalizing a node\u2019s infection time delays the potential propagation of its acquired label throughout the graph. This increases the significance of nodes which are central to the infection process, and reduces the significance of those which play a small role in it, a property captured by our notion of confidence (Sec. 2.3). The strength of the above formulation lies in its ability to introduce non-linear label dependencies to the actual infection dynamics. To see this, we can write the original predictions as:\nf = E\u03b4\u223cD [ A\u03b4S ] = E\u03b4\u223cD [ A\u03b4 ] S (15)\nwhere A\u03b4vs = 1{s=\u03b1(v)} indicates ancestors in G \u03b4, and Ss\u2113 = 1{ys=\u2113} indicates the seed nodes\u2019 true labels. This shows that predictions are non-linear in the propagation of the seed nodes, but linear in the labels. In the prior-dependent model, the above no longer holds, as activation times are now label-dependent. In the supplementary material we show how to efficiently compute predictions for this model as well."}, {"heading": "2.3 Confidence and Active Learning", "text": "Recall that a node v has a probability fv0 of not being infected by any label. This suggests a very natural measure of confidence in our prediction, namely:\n\u03c3v(S) = 1\u2212fv0 =\nL\u2211\n\u2113=1\nfv\u2113, \u03c3(S) = \u2211\nv\n\u03c3v(S) (16)\nThe function \u03c3 quantifies the confidence in the labeling. This is conceptually different from confidence in a label. Our model supports both concepts distinctly. The former is controlled by the activations p, as they determine reachability in the active graph and are agnostic to labels. The latter is controlled by \u03b8, as it affects the speed of propagation of the labels.\nThe notion of confidence allows us to apply our method to an active learning setting. Instead of assuming the seed is given as input, in this setting we are allowed to choose the seed set, often under a cardinality budget constraint. The goal is then to choose the seed set which leads to a good labeling. Various graph-based notions have been suggested as objectives for active seed selection, such as those based on graph cuts [23], graph signals [17], and generalization error [21]. Such methods however either optimize an adversarial objective, or simply offer a heuristic solution. In contrast, using \u03c3 as a seed-selection criterion offers an optimistic alternative, as summing over all classes makes it indifferent to the actual (latent) labels. In Sec. 6 we show that this also leads to good predictions.\nThe confidence term \u03c3 coincides with the well-studied notion of influence, defined as the expected number of nodes a seed will infect. In [25] it is shown that for various settings, influence is submodular, and therefore admits to a greedy (1\u22121/\u01eb)-approximation scheme. Any algorithm for maximizing influence efficiently (e.g., [15, 20]), can therefore be adopted for out setting."}, {"heading": "3 Non-Homogeneous Laplacian", "text": "Here we prove that:\nL(S)f = b(S)\nwhere:\nbu\u2113(S) = \u2211\nv\nb (S) vu\u2113, b (S) vu\u2113 = cov [Tvu(S), Yu\u2113]\nFor clarity we drop the notational dependence on S. We begin by expanding fu\u2113 using Y and T :\nfu\u2113 = E [Yu\u2113] = E [Tu\u00b7Y\u00b7\u2113]\n= E\n[ \u2211\nv\nTuvYv\u2113\n]\n= \u2211\nv\nE [TuvYv\u2113]\n= \u2211\nv\n(E [Tuv]E [Yv\u2113] + cov [TuvYv\u2113])\n= \u2211\nv\n(T uvfv\u2113 + buv\u2113)\nwhere the final step is true for the product of general random variables. Rewriting in matrix form gives: f = T f + b. Rearranging we get: (I \u2212 T )f = Lf = b, as required.\nThe objective function can then be expressed as: \u2016Lf \u2032 \u2212 b\u201622 = \u2211\nu\n\u2211\n\u2113\n(Lu\u00b7f\u00b7\u2113 \u2212 bu\u2113) 2\n= \u2211\nu\n\u2211\n\u2113\n( \u2211\nv\nLuvfv\u2113 \u2212 buv\u2113\n)2\n= \u2211\nu\n\u2211\n\u2113\n( \u2211\nv\n(1{u=v} \u2212 T uv)fv\u2113 \u2212 buv\u2113\n)2\n= \u2211\nu\n\u2211\n\u2113\n( fu\u2113 \u2212 \u2211\nv\n(wuvfv\u2113 + buv\u2113)\n)2\nwhere wuv = T uv."}, {"heading": "4 Details for the Illustrative Synthetic Experiment", "text": "Our hypothesis in this work is that infection dynamics are a good candidate for propagating label information over real networks. To illustrate this, we designed\na synthetic experimental setup in which our goal was to capture the structure of real world networks. One well-known property of such networks is that they often have a community-like structure, with many intracommunity edges, but few inter-community edges. In many cases, only a few specific nodes within a community are also connected to other communities. Hence, we randomly created small networks with the above properties.\nSpecifically, each network was set to have 3 communities, each with 64 nodes. Edges were randomly added between these nodes with probability 0.1. For community A, 8 nodes were assigned to community B, and an additional 8 to community C (and similarly for the other communities). These edges were also added with probability 0.1. To account for some noise, all other edges were added with probability 0.05. The seed set included one randomly chosen node from each community, giving |S| = 3. The figure in the main text displays a random instance of the above setting, providing both the instance specific accuracies, as well as the average accuracy over 1,000 random instances.\nRecall that InfProp can be interpreted both as the expected result of a dynamic infection process, and as a stochastic ensemble of shortest paths. We therefore compared our method to two baselines. To compare the dynamics, we used Label Propagation (LabelProp) which is based on the more standard random-walk dynamics. As we argue in the text, these dynamics are prone to getting stuck in dense clusters. As can be seen, while InfProp provides almost exact predictions, the predictive values of LabelProp are almost uniform and hence extremely error-prone. This demonstrates the inability of label information to propagate efficiently over the network.\nTo demonstrate the power of using a stochastic ensemble of paths, we compared to simply setting labels according to the deterministic shortest paths given by the original graph. While correctly classifying most labels, shortest paths can be very sensitive to crosscommunity or noisy edges. In contrast, InfProp mitigates this noise by considering a distribution over shortest-paths."}, {"heading": "5 Datasets", "text": "We evaluated our method on various learning tasks over three collections of benchmark datasets, which include network based datasets for multi-class learning with features6 [39], multi-class learning without\n6 http://linqs.umiacs.umd.edu/projects//projects/lbc/\nfeatures7 [38], and multi-label learning8 [33]. The following table provides some statistics.\nDataset Nodes Edges Classes Features Avg. |y|\nM u lt ic la ss\n7\nCoRA 2,708 5,278 7 - 1 DBLP 5,329 21,880 6 - 1 Flickr 7,971 478,980 7 - 1 IMDb 2,411 12,255 22 - 1 Industry 2,189 11,666 12 - 1\nF e a tu\nre s6 CiteSeer 3,132 4,713 6 3,703 1\nCoRA 2,708 5,278 7 1,433 1 PubMed 19,717 44,324 3 500 1\nM u lt il a b e l8\nAmazon 83,742 190,097 30 - 1.546 CoRA 24,519 92,207 10 - 1.004 IMDb 19,359 362,079 21 - 2.300 PubMed 19,717 44,324 3 - 1 Wikipedia 35,633 49,538 16 - 1.312 YouTube 22,693 96,361 47 - 1.707\n7 http://cs.gmu.edu/ tsaha/Homepage/Projects.html 8 http://github.com/sharadnandanwar/snbc"}], "references": [], "referenceMentions": [], "year": 2017, "abstractText": "The goal of semi-supervised learning methods is to effectively combine labeled and unlabeled data to arrive at a better model. Many methods rely on graph-based approaches, where labels are propagated through a graph over the input examples. In most current methods, the propagation mechanism underlying the learning objective is based on random walks. While theoretically elegant, random walks suffer from several drawbacks which can hurt predictive performance. In this work, we explore dynamic infection processes as an alternative propagation mechanism. In these, unlabeled nodes can be \u201cinfected\u201d with the label of their already infected neighbors. We provide an efficient, scalable, and parallelizable algorithm for estimating the expected infection outcomes. We also describe an optimization view of the method, relating it to Laplacian approaches. Finally, experiments demonstrate that the method is highly competitive across multiple benchmarks and for various learning settings.", "creator": "dvips(k) 5.996 Copyright 2016 Radical Eye Software"}}}