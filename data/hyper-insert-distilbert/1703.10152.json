{"id": "1703.10152", "review": {"conference": "arxiv", "VERSION": "v1", "DATE_OF_SUBMISSION": "29-Mar-2017", "title": "Automatic Argumentative-Zoning Using Word2vec", "abstract": "in comparison with another document summarization on the articles from social commons media and newswire, argumentative programming zoning ( lev az ) is an as important evaluation task in scientific paper analysis. what traditional development methodology to carry back on this collaborative task extensively relies on analyzing feature engineering procedures from different levels. in this paper, ultimately three models of automatically generating sentence vectors tools for controlling the task of sentence classification were explored quickly and compared. the proposed approach builds sentence representations simply using learned embeddings based on neural network. the learned the word embeddings further formed a mathematical feature control space, tied to which section the examined scripted sentence is loosely mapped to. both those sensory features are all input into half the specified classifiers for supervised classification. using 10 - parameters cross - layered validation filtering scheme, evaluation was conducted on the latest argumentative - directional zoning ( vt az ) annotated multimedia articles. the compiled results combined showed that simply averaging roughly the median word vectors squared in a structured sentence works together better data than the paragraph to vector algorithm calculation and code by integrating extremely specific cuewords into thinking the unit loss function of the neural compute network can systematically improve the classification performance. in his comparison with the hand - crafted editing features, the manual word2vec taxonomy method once won for identifying most of individually the categories. however, the hand - crafted optimization features showed how their sheer strength on classifying some of themselves the key categories.", "histories": [["v1", "Wed, 29 Mar 2017 17:33:27 GMT  (21kb)", "http://arxiv.org/abs/1703.10152v1", "13 pages; 5 tables"]], "COMMENTS": "13 pages; 5 tables", "reviews": [], "SUBJECTS": "cs.CL", "authors": ["haixia liu"], "accepted": false, "id": "1703.10152"}, "pdf": {"name": "1703.10152.pdf", "metadata": {"source": "CRF", "title": "Automatic Argumentative-Zoning Using Word2vec", "authors": ["Haixia Liu"], "emails": ["khyx3lhi@nottingham.edu.my"], "sections": [{"heading": null, "text": "ar X\niv :1\n70 3.\n10 15\n2v 1\n[ cs\n.C L\n] 2\n9 M"}, {"heading": "1 Introduction", "text": "One of the crucial tasks for researchers to carry out scientific investigations is to detect existing ideas that are related to their research topics. Research ideas are usually documented in scientific publications. Normally, there is one main idea stated in the abstract, explicitly presenting the aim of the paper. There are also other sub-ideas distributed across the entire paper. As the growth rate of scientific publication has been rising dramatically, researchers are overwhelmed by the explosive information. It is almost impossible to digest the ideas contained in the documents emerged everyday. Therefore, computer assisted technologies such as document summarization are expected to play a role in condensing information and providing readers with more relevant short texts. Unlike document summarization from news circles, where the task is to identify centroid sentences [1] or to extract the first few sentences of the\nparagraphs [2], summarization of scientific articles involves extra text processing stage [3]. After highest ranked texts are extracted, rhetorical status analysis will be conducted on the selected sentences. Rhetorical sentence classification, also known as argumentative zoning (AZ) [4], is a process of assigning rhetorical status to the extracted sentences. The results of AZ provide readers with general discourse context from which the scientific ideas could be better linked, compared and analyzed. For example, given a specific task, which sentences should be shown to the reader is related to the features of the sentences. For the task of identifying a paper\u2019s unique contribution, sentences expressing research purpose should be retrieved with higher priority. For comparing ideas, statements of comparison with other works would be more useful. Teufel et. al. [3] introduced their rhetorical annotation scheme which takes into account of the aspects of argumentation, metadiscourse and relatedness to other works. Their scheme resulted seven categories of rhetorical status and the categories are assigned to full sentences. Examples 1 of human annotated sentences with their rhetorical status are shown in Table. 1. The seven categories are aim, contrast, own, background, other, basis and textual.\nAnalyzing the rhetorical status of sentences manually requires huge amount of efforts, especially for structuring information from multiple documents. Fortunately, computer algorithms have been introduced to solve this problem. With the development of artificial intelligence, machine learning and computational linguistics, Natural Language Processing (NLP) has become a popular research area [5, 6]. NLP covers the applications from document retrieval, text categorization [7], document summarization [8] to sentiment analysis [9, 10]. Those applications are targeting different types of text resources, such as articles from social media [11] and scientific publications [3]. There are several approaches to tackle these tasks. From machine learning prospective, text can be analysed via supervised [3], semi-supervised [12] and unsupervised [13] algorithms.\nDocument summarization from social media and news circles has received much attention for the past decades. Those problems have been addressed from many angles, one of which is feature extraction and representation. At the early stage of document summarization, features are usually engineered manually. Although the hand-crafted features have shown the ability for document summarization and sentiment analysis [14, 10], there are not enough efficient features to capture the semantic relations between words, phrases and sentences. Moreover, building a sufficient pool of features manually is difficult, because it requires expert knowledge and it is time-consuming. Teufel et. al. [3] have built feature pool of sixteen types of features to classify sentences, such as the position of sentence, sentence length and tense. Widyantoro et. al. used content features, qualifying adjectives and meta-discourse features [15] to explore AZ task. It took efforts to engineer these features and it is also time consuming to optimize the combination of the entire features. With the advent of neural networks [16], it is possible for computers to learn feature representations automatically. Recently, word embedding technique [17] has been widely used in the NLP community. There are plenty of cases where word embedding and sentence representations have been applied to short text classification [18] and paraphrase detection [19]. However, the effectiveness of this technique on AZ needs further study. The research question is, is it possible to extract word embeddings as features to classify sentences into the seven categories mentioned above using supervised machine learning approach?"}, {"heading": "2 Related Work", "text": "The tool of word2vec proposed by Mikolov et al. [17] has gained a lot attention recently. With word2vec tool, word embeddings can be learnt from big amount of text corpus and the semantic relationships between words can be measured by the cosine distances between the vectors. The idea behind word embeddings is to use distributed representation [20] to map each word into k-dimension vector. How these vectors are generated using word2vec tool? The common method to derive the vectors is using neural probabilistic language model [21]. The underlying word representations for each word are obtained while training the language model. Similar to the mechanism in language model, Mikolov et al. [17] introduced two architectures: Skip-gram model and continuous bag of words (CBOW) model. Each of the model has two different training strategies, such as hierarchical softmax and negative sampling. Both these two models have three layers: input, projection and output layer. The word vectors are obtained once the models are optimized. Usually, this optimizing process is done using stochastic gradient descent method. It doesn\u2019t need labels when training the models, which makes word2vec algorithm more valuable compared with traditional supervised machine learning methods that require a big amount of annotated data. Given enough text corpus, the word2vec can generate meaningful representations.\nWord2vec has been applied to sentiment analysis [22, 23, 24] and text classification [25]. Sadeghian and Sharafat [26] explored averaging of the word vectors in a sentiment review statement. Their results indicated that word2vec models significantly outperform the vanilla bag-of-words model. Amongst the word2vec based models, softmax provides the best form of classification. Tang et al. [22] used the concatenation of vectors derived from different convolutional layers to analyze the sentiment statements. They also trained sentiment-specific word embeddings to improve the twitter sentiment classification results. This work is aiming at learning word embeddings for the task of AZ. The results were compared from three aspects: the impact of the training corpus, the effectiveness of specific word embeddings and different ways of constructing sentence representations based on the learned word vectors.\nLe and Mikolov [27] introduced the concept of word vector representation in a formal way:\nGiven a sequence of training words w =< w1, x2, ..., wn >, the objective of the word2vec model is to maximize the average log probability:\n1 T \u2211T\u2212k t=k log p(wt|wt\u2212k, ..., wt+k) (1)\nUsing softmax technique, the prediction can be formalized as:\np(wt|wt\u2212k, ..., wt+k) = eywt\u2211 e ywy (2)\nEach of yi is un-normalized log probability for each output word i:\ny = b+ Uh(wt\u2212k, ..., wt+k ;W ) (3)"}, {"heading": "3 Methodology", "text": ""}, {"heading": "3.1 Models", "text": "In this study, sentence embeddings were learned from large text corpus as features to classify sentences into seven categories in the task of AZ. Three models were explored to obtain the sentence vectors: averaging the vectors of the words in one sentence, paragraph vectors and specific word vectors.\nThe first model, averaging word vectors (AV GWV EC), is to average the vectors in word sequence w =< w1, x2, ...wn >. The main process in this model is to learn the word embedding matrix Ww:\nVavgwvec(w) = 1 n \u2211 W xiw (4)\nwhere Ww is the word embedding for word xi, which is learned by the classical word2vec algorithm [17].\nThe second model, PARAV EC, is aiming at training paragraph vectors. It is also called distributed memory model of paragraph vectors (PV-DM) [27], which is an extension of word2vec. In comparison with the word2vec framework, the only change in PV-DM is in the equation (3), where h is constructed from W and D, where matrix W is the word vector and D holds the paragraph vectors in such a way that every paragraph is mapped to a unique vector represented by a column in matrix D.\nThe third model is constructed for the purpose of improving classification results for a certain category. In this study specifically, the optimization task was focused on identifying the category BAS 2. In this\n2This is a general case to show how to improve the classification result by integrating cuewords to the embeddings.\nstudy, BAS specific word embeddings were trained (BSWE) inspired by Tang et al. [22]\u2019s model: Sentiment-Specific Word Embedding (unified model: SSWEu). After obtaining the word vectors via BSWE, the same scheme was used to average the vectors in one sentence as in the model AV GWV EC."}, {"heading": "3.2 Classification and evaluation", "text": "The learned word embeddings are input into a classifier as features under a supervised machine learning framework. Similar to sentiment classification using word embeddings [22], where they try to predict each tweet to be either positive or negative, in the task of AZ, the embeddings are used to classify each sentence into one of the seven categories.\nTo evaluate the classification performance, precision, recall and Fmeasure were computed."}, {"heading": "4 Experimental Evaluation", "text": ""}, {"heading": "4.1 Training Dataset", "text": "ACL collection. ACL Anthology Reference Corpus 3 contains the canonical 10,921 computational linguistics papers, from which 622,144 sentences were generated after filtering out sentences with lower quality.\nMixedAbs collection contains 6,778 sentences, extracted from the titles and abstracts of publications provided by WEB OF SCIENCE 4."}, {"heading": "4.2 Test Dataset", "text": "Argumentative Zoning Corpus (AZ corpus) consists of 80 AZ\u2212annotated conference articles in computational linguistics, originally drawn from the Cmplg arXiv. 5. After Concatenating sub-sentences, 7,347 labeled sentences were obtained."}, {"heading": "4.3 Training strategy", "text": "To compare the three models effectiveness on the AZ task, the three models on a same ACL dataset (introduced int he dataset section) were trained. The word2vec were also trained using different parameters, such\n3http : //acl-arc.comp.nus.edu.sg/ 4webofknowledge.com 5http : //www.cl.cam.ac.uk/\u02dcsht25/AZ corpus.html\nas different dimension of features. To evaluate the impact from different domains, the first model was trained on different corpus.\nThe characteristics of word embeddings based on different model and dataset are listed in Table. 2."}, {"heading": "4.4 Parameters", "text": "Inspired by the work from Sadeghian and Sharafat [26] 6, the word to vector features were set up as follows: the Minimum word count is 40; The number of threads to run in parallel is 4 and the context window is 10."}, {"heading": "4.5 Strategy of dealing with unbalanced data", "text": "In imbalanced data sets, some classes are significantly outnumbered by other classes [28], which affects the classification results. In this experiment, the test dataset is an imbalanced data set. Table. 3 shows the distribution of rhetorical categories from the AZ test dataset. The categories OWN and OTH are significantly outnumbering other categories.\nTo deal with the problem of classification on unbalanced data, synthetic Minority Over-sampling TEchnique (SMOTE) [29] were performed on the original dataset. 10-cross validation scheme was adopted and the results were averaged from 10 iterations."}, {"heading": "4.6 Results of classification for per category", "text": "Table. 4 and 5 show the classification performance of different methods. 7\nThe results were examined from the following aspects: When the feature dimension is set to 100 and the training corpus is ACL, the results generated by different models were compared (AVGWVEC,\n7Note that it is not completely compatible with Teufel 2002 results, since the dataset is different due to the sentence concatenation in this paper. But Teufel\u2019s reports could be a reference.\nPARAVEC and AVGWVEC+BSWE for BAS category only). Looking at the F-measure, AVGWVEC performs better than PARAVEC, but PARAVEC gave a better precision results on several categories, such as AIM, CTR, TXT and OWN. The results showed that PARAVEC model is not robust, for example, it performs badly for the category of BAS. For specific category classification, take the BAS category for example, the BSWE model outperforms others in terms of F-measure.\nWhen the model is fixed to AVGWVEC and the training corpus is ACL, the feature size impact (300 and 100 dimensions) was investigated. From the F-measure, it can be seen that for some categories, 300-dimension features perform better than the 100-dimension ones, for example, CTR and BKG, but they are not as good as 100-dimension features for some categories, such as BAS.\nWhen the model is set to AVGWVEC and the feature dimension is 100, the results computed from different training corpus were compared (ACL+AZ, MixedAbs and Brown corpus). ACL+AZ outperforms others and brown corpus is better than MixedAbs for most of the categories, but brown corpus is not as good as MixedAbs for the category of OWN.\nFinally, the results were compared between word embeddings and the methods of cuewords, Teufel 2002 and baseline. To evaluate word embeddings on AZ, the model AVGWVEC trained on ACL+AZ was used for the comparison. It can be seen from the table. 4, the model of word embeddings is better than the method using cuewords matching. It also outperforms Teufel 2002 for most of the cases, except AIM, BAS and OWN. It won baseline for most of the categories, except OWN."}, {"heading": "5 Discussion", "text": "The classification results showed that the type of word embeddings and the training corpus affect the AZ performance. As the simple model, AV GWV EC performs better than others, which indicate averaging the word vectors in a sentence can capture the semantic property of statements. By training specific argumentation word embeddings, the performance can be improved, which can be seen from the case of detecting BAS status using BSWE model.\nFeature dimension doesn\u2019t dominate the results. There is no significant difference between the resutls generated by 300-dimension of features and 100 dimensions.\nTraining corpus affects the results. ACL+AZ outperforming others indicates that the topics of the training corpus are important factors in\nargumentative zoning. Although Brown corpus has more vocabularies, it doesn\u2019t win ACL+AZ.\nIn general, the classification performance of word embeddings is competitive in terms of F-measure for most of the categories. But for classifying the categories AIM, BAS and OWN, the manually crafted features proposed by Teufel et al. [3] gave better results."}, {"heading": "6 Conclusion", "text": "In this paper, different word embedding models on the task of argumentative zoning were compared . The results showed that word embeddings are effective on sentence classification from scientific papers. Word embeddings trained on a relevant corpus can capture the semantic features of statements and they are easier to be obtained than hand engineered features.\nTo improve the sentence classification for a specific category, integrating word specific embedding strategy helps. The size of the feature pool doesn\u2019t matter too much on the results, nor does the vocabulary size. In comparison, the domain of the training corpus affects the classification performance."}], "references": [{"title": "Centroid-based summarization of multiple documents: sentence extraction, utility-based evaluation, and user studies", "author": ["D.R. Radev", "H. Jing", "M. Budzikowska"], "venue": "Proceedings of the 2000 NAACL- ANLP Workshop on Automatic summarization. Association for Computational Linguistics, 2000, pp. 21\u201330.", "citeRegEx": "1", "shortCiteRegEx": null, "year": 2000}, {"title": "Identifying topics by position", "author": ["C.-Y. Lin", "E. Hovy"], "venue": "Proceedings of the fifth conference on Applied natural language processing. Association for Computational Linguistics, 1997, pp. 283\u2013290.", "citeRegEx": "2", "shortCiteRegEx": null, "year": 1997}, {"title": "Summarizing scientific articles: experiments with relevance and rhetorical status", "author": ["S. Teufel", "M. Moens"], "venue": "Computational linguistics, vol. 28, no. 4, pp. 409\u2013445, 2002.", "citeRegEx": "3", "shortCiteRegEx": null, "year": 2002}, {"title": "Argumentative zoning: Information extraction from scientific text", "author": ["S. Teufel"], "venue": "Ph.D. dissertation, Citeseer, 2000.", "citeRegEx": "4", "shortCiteRegEx": null, "year": 2000}, {"title": "Advances in natural language processing", "author": ["J. Hirschberg", "C.D. Manning"], "venue": "Science, vol. 349, no. 6245, pp. 261\u2013266, 2015.", "citeRegEx": "6", "shortCiteRegEx": null, "year": 2015}, {"title": "Natural language processing for online applications: Text retrieval, extraction and categorization", "author": ["P. Jackson", "I. Moulinier"], "venue": "John Benjamins Publishing,", "citeRegEx": "7", "shortCiteRegEx": "7", "year": 2007}, {"title": "Ranking with recursive neural networks and its application to multi-document summarization", "author": ["Z. Cao", "F. Wei", "L. Dong", "S. Li", "M. Zhou"], "venue": "Twenty-Ninth AAAI Conference on Artificial Intelligence, 2015.", "citeRegEx": "8", "shortCiteRegEx": null, "year": 2015}, {"title": "Sentiment analysis: Capturing favorability using natural language processing", "author": ["T. Nasukawa", "J. Yi"], "venue": "Proceedings of the 2nd international conference on Knowledge capture. ACM, 2003, pp. 70\u201377.", "citeRegEx": "9", "shortCiteRegEx": null, "year": 2003}, {"title": "Opinion mining and sentiment analysis", "author": ["B. Pang", "L. Lee"], "venue": "Foundations and trends in information retrieval, vol. 2, no. 1-2, pp. 1\u2013135, 2008.", "citeRegEx": "10", "shortCiteRegEx": null, "year": 2008}, {"title": "Predicting the future with social media", "author": ["S. Asur", "B. Huberman"], "venue": "Web Intelligence and Intelligent Agent Technology (WI- IAT), 2010 IEEE/WIC/ACM International Conference on, vol. 1. IEEE, 2010, pp. 492\u2013499.", "citeRegEx": "11", "shortCiteRegEx": null, "year": 2010}, {"title": "Document-word co-regularization for semi-supervised sentiment analysis", "author": ["V. Sindhwani", "P. Melville"], "venue": "Data Mining, 2008.  ICDM\u201908. Eighth IEEE International Conference on. IEEE, 2008, pp. 1025\u20131030.", "citeRegEx": "12", "shortCiteRegEx": null, "year": 2008}, {"title": "Unsupervised learning by probabilistic latent semantic analysis", "author": ["T. Hofmann"], "venue": "Machine learning, vol. 42, no. 1-2, pp. 177\u2013196, 2001.", "citeRegEx": "13", "shortCiteRegEx": null, "year": 2001}, {"title": "A survey on automatic text summarization", "author": ["D. Das", "A.F. Martins"], "venue": "Literature Survey for the Language and Statistics II course at CMU, vol. 4, pp. 192\u2013195, 2007.", "citeRegEx": "14", "shortCiteRegEx": null, "year": 2007}, {"title": "A multiclass-based classification strategy for rhetorical sentence categorization from scientific papers", "author": ["D.H. Widyantoro", "M.L. Khodra", "B. Riyanto", "A. Aziz"], "venue": "FormaMente: Rivista internazionale di ricerca sul futuro digitale, no. 3-2014, p. 223, 2015.", "citeRegEx": "15", "shortCiteRegEx": null, "year": 2014}, {"title": "A fast learning algorithm for deep belief nets", "author": ["G.E. Hinton", "S. Osindero", "Y.-W. Teh"], "venue": "Neural computation, vol. 18, no. 7, pp. 1527\u2013 1554, 2006.", "citeRegEx": "16", "shortCiteRegEx": null, "year": 2006}, {"title": "Efficient estimation of word representations in vector space", "author": ["T. Mikolov", "K. Chen", "G. Corrado", "J. Dean"], "venue": "arXiv preprint arXiv:1301.3781, 2013.", "citeRegEx": "17", "shortCiteRegEx": null, "year": 2013}, {"title": "Semantic expansion using word embedding clustering and convolutional neural network for improving short text classification", "author": ["P. Wang", "B. Xu", "J. Xu", "G. Tian", "C.-L. Liu", "H. Hao"], "venue": "Neurocomputing, 2015.", "citeRegEx": "18", "shortCiteRegEx": null, "year": 2015}, {"title": "Dynamic pooling and unfolding recursive autoencoders for paraphrase detection", "author": ["R. Socher", "E.H. Huang", "J. Pennin", "C.D. Manning", "A.Y. Ng"], "venue": "Advances in Neural Information Processing Systems, 2011, pp. 801\u2013809.", "citeRegEx": "19", "shortCiteRegEx": null, "year": 2011}, {"title": "Distributed representations", "author": ["M.J. Hinton", "Geoffrey", "D. Rumelhart"], "venue": "1986.", "citeRegEx": "20", "shortCiteRegEx": null, "year": 1986}, {"title": "A neural probabilistic language model", "author": ["Y. Bengio", "R. Ducharme", "P. Vincent", "C. Janvin"], "venue": "The Journal of Machine Learning Research, vol. 3, pp. 1137\u20131155, 2003.", "citeRegEx": "21", "shortCiteRegEx": null, "year": 2003}, {"title": "Learning sentiment-specific word embedding for twitter sentiment classification", "author": ["D. Tang", "F. Wei", "N. Yang", "M. Zhou", "T. Liu", "B. Qin"], "venue": "Proceedings of the 52nd Annual Meeting of the Association for Computational Linguistics, vol. 1, 2014, pp. 1555\u20131565.", "citeRegEx": "22", "shortCiteRegEx": null, "year": 2014}, {"title": "A study on sentiment computing and classification of sina weibo with word2vec", "author": ["B. Xue", "C. Fu", "Z. Shaobin"], "venue": "Big Data (BigData Congress), 2014 IEEE International Congress on. IEEE, 2014, pp. 358\u2013363.", "citeRegEx": "23", "shortCiteRegEx": null, "year": 2014}, {"title": "Chinese comments sentiment classification based on word2vec and svm perf", "author": ["D. Zhang", "H. Xu", "Z. Su", "Y. Xu"], "venue": "Expert Systems with Applications, vol. 42, no. 4, pp. 1857\u20131863, 2015.", "citeRegEx": "24", "shortCiteRegEx": null, "year": 1857}, {"title": "Support vector machines and word2vec for text classification with semantic features", "author": ["J. Lilleberg", "Y. Zhu", "Y. Zhang"], "venue": "Cognitive Informatics & Cognitive Computing (ICCI* CC), 2015 IEEE 14th International Conference on. IEEE, 2015, pp. 136\u2013140.", "citeRegEx": "25", "shortCiteRegEx": null, "year": 2015}, {"title": "Distributed representations of sentences and documents", "author": ["Q.V. Le", "T. Mikolov"], "venue": "arXiv preprint arXiv:1405.4053, 2014.", "citeRegEx": "27", "shortCiteRegEx": null, "year": 2014}, {"title": "Borderline oversampling for imbalanced data classification", "author": ["H.M. Nguyen", "E.W. Cooper", "K. Kamei"], "venue": "International Journal of Knowledge Engineering and Soft Data Paradigms, vol. 3, no. 1, pp. 4\u201321, 2011.", "citeRegEx": "28", "shortCiteRegEx": null, "year": 2011}, {"title": "Smote: synthetic minority over-sampling technique", "author": ["N.V. Chawla", "K.W. Bowyer", "L.O. Hall", "W.P. Kegelmeyer"], "venue": "Journal of artificial intelligence research, pp. 321\u2013357, 2002.", "citeRegEx": "29", "shortCiteRegEx": null, "year": 2002}], "referenceMentions": [{"referenceID": 0, "context": "Unlike document summarization from news circles, where the task is to identify centroid sentences [1] or to extract the first few sentences of the", "startOffset": 98, "endOffset": 101}, {"referenceID": 1, "context": "paragraphs [2], summarization of scientific articles involves extra text processing stage [3].", "startOffset": 11, "endOffset": 14}, {"referenceID": 2, "context": "paragraphs [2], summarization of scientific articles involves extra text processing stage [3].", "startOffset": 90, "endOffset": 93}, {"referenceID": 3, "context": "Rhetorical sentence classification, also known as argumentative zoning (AZ) [4], is a process of assigning rhetorical status to the extracted sentences.", "startOffset": 76, "endOffset": 79}, {"referenceID": 2, "context": "[3] introduced their rhetorical annotation scheme which takes into account of the aspects of argumentation, metadiscourse and relatedness to other works.", "startOffset": 0, "endOffset": 3}, {"referenceID": 4, "context": "With the development of artificial intelligence, machine learning and computational linguistics, Natural Language Processing (NLP) has become a popular research area [5, 6].", "startOffset": 166, "endOffset": 172}, {"referenceID": 5, "context": "NLP covers the applications from document retrieval, text categorization [7], document summarization [8] to sentiment analysis [9, 10].", "startOffset": 73, "endOffset": 76}, {"referenceID": 6, "context": "NLP covers the applications from document retrieval, text categorization [7], document summarization [8] to sentiment analysis [9, 10].", "startOffset": 101, "endOffset": 104}, {"referenceID": 7, "context": "NLP covers the applications from document retrieval, text categorization [7], document summarization [8] to sentiment analysis [9, 10].", "startOffset": 127, "endOffset": 134}, {"referenceID": 8, "context": "NLP covers the applications from document retrieval, text categorization [7], document summarization [8] to sentiment analysis [9, 10].", "startOffset": 127, "endOffset": 134}, {"referenceID": 9, "context": "Those applications are targeting different types of text resources, such as articles from social media [11] and scientific publications [3].", "startOffset": 103, "endOffset": 107}, {"referenceID": 2, "context": "Those applications are targeting different types of text resources, such as articles from social media [11] and scientific publications [3].", "startOffset": 136, "endOffset": 139}, {"referenceID": 2, "context": "From machine learning prospective, text can be analysed via supervised [3], semi-supervised [12] and unsupervised [13] algorithms.", "startOffset": 71, "endOffset": 74}, {"referenceID": 10, "context": "From machine learning prospective, text can be analysed via supervised [3], semi-supervised [12] and unsupervised [13] algorithms.", "startOffset": 92, "endOffset": 96}, {"referenceID": 11, "context": "From machine learning prospective, text can be analysed via supervised [3], semi-supervised [12] and unsupervised [13] algorithms.", "startOffset": 114, "endOffset": 118}, {"referenceID": 12, "context": "Although the hand-crafted features have shown the ability for document summarization and sentiment analysis [14, 10], there are not enough efficient features to capture the semantic relations between words, phrases and sentences.", "startOffset": 108, "endOffset": 116}, {"referenceID": 8, "context": "Although the hand-crafted features have shown the ability for document summarization and sentiment analysis [14, 10], there are not enough efficient features to capture the semantic relations between words, phrases and sentences.", "startOffset": 108, "endOffset": 116}, {"referenceID": 2, "context": "[3] have built feature pool of sixteen types of features to classify sentences, such as the position of sentence, sentence length and tense.", "startOffset": 0, "endOffset": 3}, {"referenceID": 13, "context": "features, qualifying adjectives and meta-discourse features [15] to explore AZ task.", "startOffset": 60, "endOffset": 64}, {"referenceID": 14, "context": "With the advent of neural networks [16], it is possible for computers to learn feature representations automatically.", "startOffset": 35, "endOffset": 39}, {"referenceID": 15, "context": "Recently, word embedding technique [17] has been widely used in the NLP community.", "startOffset": 35, "endOffset": 39}, {"referenceID": 16, "context": "There are plenty of cases where word embedding and sentence representations have been applied to short text classification [18] and paraphrase detection [19].", "startOffset": 123, "endOffset": 127}, {"referenceID": 17, "context": "There are plenty of cases where word embedding and sentence representations have been applied to short text classification [18] and paraphrase detection [19].", "startOffset": 153, "endOffset": 157}, {"referenceID": 15, "context": "[17] has gained a lot attention recently.", "startOffset": 0, "endOffset": 4}, {"referenceID": 18, "context": "The idea behind word embeddings is to use distributed representation [20] to map each word into k-dimension vector.", "startOffset": 69, "endOffset": 73}, {"referenceID": 19, "context": "How these vectors are generated using word2vec tool? The common method to derive the vectors is using neural probabilistic language model [21].", "startOffset": 138, "endOffset": 142}, {"referenceID": 15, "context": "[17] introduced two architectures: Skip-gram model and continuous bag of words (CBOW) model.", "startOffset": 0, "endOffset": 4}, {"referenceID": 20, "context": "Word2vec has been applied to sentiment analysis [22, 23, 24] and text classification [25].", "startOffset": 48, "endOffset": 60}, {"referenceID": 21, "context": "Word2vec has been applied to sentiment analysis [22, 23, 24] and text classification [25].", "startOffset": 48, "endOffset": 60}, {"referenceID": 22, "context": "Word2vec has been applied to sentiment analysis [22, 23, 24] and text classification [25].", "startOffset": 48, "endOffset": 60}, {"referenceID": 23, "context": "Word2vec has been applied to sentiment analysis [22, 23, 24] and text classification [25].", "startOffset": 85, "endOffset": 89}, {"referenceID": 20, "context": "[22] used the concatenation of vectors derived from different convolutional layers to analyze the sentiment statements.", "startOffset": 0, "endOffset": 4}, {"referenceID": 24, "context": "Le and Mikolov [27] introduced the concept of word vector representation in a formal way:", "startOffset": 15, "endOffset": 19}, {"referenceID": 15, "context": "where Ww is the word embedding for word xi, which is learned by the classical word2vec algorithm [17].", "startOffset": 97, "endOffset": 101}, {"referenceID": 24, "context": "(PV-DM) [27], which is an extension of word2vec.", "startOffset": 8, "endOffset": 12}, {"referenceID": 20, "context": "[22]\u2019s model: Sentiment-Specific Word Embedding (unified model: SSWEu).", "startOffset": 0, "endOffset": 4}, {"referenceID": 20, "context": "Similar to sentiment classification using word embeddings [22], where they try to predict each tweet to be either positive or negative, in the task of AZ, the embeddings are used to classify each sentence into one of the seven categories.", "startOffset": 58, "endOffset": 62}, {"referenceID": 25, "context": "In imbalanced data sets, some classes are significantly outnumbered by other classes [28], which affects the classification results.", "startOffset": 85, "endOffset": 89}, {"referenceID": 26, "context": "To deal with the problem of classification on unbalanced data, synthetic Minority Over-sampling TEchnique (SMOTE) [29] were performed on the original dataset.", "startOffset": 114, "endOffset": 118}, {"referenceID": 2, "context": "[3] gave better results.", "startOffset": 0, "endOffset": 3}], "year": 2017, "abstractText": "In comparison with document summarization on the articles from social media and newswire, argumentative zoning (AZ) is an important task in scientific paper analysis. Traditional methodology to carry on this task relies on feature engineering from different levels. In this paper, three models of generating sentence vectors for the task of sentence classification were explored and compared. The proposed approach builds sentence representations using learned embeddings based on neural network. The learned word embeddings formed a feature space, to which the examined sentence is mapped to. Those features are input into the classifiers for supervised classification. Using 10-cross-validation scheme, evaluation was conducted on the Argumentative-Zoning (AZ) annotated articles. The results showed that simply averaging the word vectors in a sentence works better than the paragraph to vector algorithm and by integrating specific cuewords into the loss function of the neural network can improve the classification performance. In comparison with the hand-crafted features, the word2vec method won for most of the categories. However, the hand-crafted features showed their strength on classifying some of the categories.", "creator": "LaTeX with hyperref package"}}}