{"id": "1703.10476", "review": {"conference": "arxiv", "VERSION": "v1", "DATE_OF_SUBMISSION": "30-Mar-2017", "title": "Speaking the Same Language: Matching Machine to Human Captions by Adversarial Training", "abstract": "hence while certainly strong progress evolution has obviously been made in cooperative image captioning schemes over nearly the last years, concurrent machine and human captions processing are now still quite distinct. a closer look reveals that this is limited due to the progressive deficiencies in the generated word distribution, vocabulary size, difficulty and relatively strong repetition bias in the verbal generators towards those frequent captions. ironically furthermore, frustrated humans - - probably rightfully so - - generate multiple, typically diverse captions, due therefore to the distinct inherent morphological ambiguity posed in the captioning task which virtually is not much considered in today'most s systems.", "histories": [["v1", "Thu, 30 Mar 2017 13:54:51 GMT  (9553kb,D)", "http://arxiv.org/abs/1703.10476v1", "16 pages"]], "COMMENTS": "16 pages", "reviews": [], "SUBJECTS": "cs.CV cs.AI cs.CL", "authors": ["rakshith shetty", "marcus rohrbach", "lisa anne hendricks", "mario fritz", "bernt schiele"], "accepted": false, "id": "1703.10476"}, "pdf": {"name": "1703.10476.pdf", "metadata": {"source": "CRF", "title": "Speaking the Same Language: Matching Machine to Human Captions by Adversarial Training", "authors": ["Rakshith Shetty", "Marcus Rohrbach", "Lisa Anne Hendricks", "Mario Fritz", "Bernt Schiele"], "emails": [], "sections": null, "references": [], "referenceMentions": [], "year": 2017, "abstractText": "While strong progress has been made in image caption-<lb>ing over the last years, machine and human captions are<lb>still quite distinct. A closer look reveals that this is due to<lb>the deficiencies in the generated word distribution, vocabu-<lb>lary size, and strong bias in the generators towards frequent<lb>captions. Furthermore, humans \u2013 rightfully so \u2013 generate<lb>multiple, diverse captions, due to the inherent ambiguity in<lb>the captioning task which is not considered in today\u2019s sys-<lb>tems. To address these challenges, we change the training ob-<lb>jective of the caption generator from reproducing ground-<lb>truth captions to generating a set of captions that is indis-<lb>tinguishable from human generated captions. Instead of<lb>handcrafting such a learning target, we employ adversar-<lb>ial training in combination with an approximate Gumbel<lb>sampler to implicitly match the generated distribution to the<lb>human one. While our method achieves comparable perfor-<lb>mance to the state-of-the-art in terms of the correctness of<lb>the captions, we generate a set of diverse captions, that are<lb>significantly less biased and match the word statistics better<lb>in several aspects.", "creator": "LaTeX with hyperref package"}}}