{"id": "1704.01074", "review": {"conference": "arxiv", "VERSION": "v1", "DATE_OF_SUBMISSION": "4-Apr-2017", "title": "Emotional Chatting Machine: Emotional Conversation Generation with Internal and External Memory", "abstract": "working emotional intelligence is one of the eight key factors to the success of modern dialogue social systems simulations or conversational agents. in this paper, we propose emotional chatting machine ( ecm ) cognition which generates natural responses that truly are appropriate mainly not only at specifically the logical content evaluation level ( hence relevant and grammatical ) but also consistent at the emotion construct level ( consistent to emotional expression ). to the relatively best of our historical knowledge, this is the major first work that presently addresses facilitating the emotion analytic factor system in large - scale conversation style generation. ecm addresses improving the factor assessment in examining three ways : modeling high - level facial abstraction consisting of artificial emotion expression abilities by embedding abstract emotion emotional categories, changing of externally implicit internal emotion states, compiling and using explicit emotion expressions with an external emotion vocabulary. field experiments show that properly our model can generate responses appropriate internally not only simultaneously in written content but then also adequately in physical emotion.", "histories": [["v1", "Tue, 4 Apr 2017 15:44:48 GMT  (335kb,D)", "http://arxiv.org/abs/1704.01074v1", null], ["v2", "Wed, 19 Apr 2017 10:17:53 GMT  (337kb,D)", "http://arxiv.org/abs/1704.01074v2", null], ["v3", "Thu, 14 Sep 2017 10:29:06 GMT  (1357kb,D)", "http://arxiv.org/abs/1704.01074v3", null]], "reviews": [], "SUBJECTS": "cs.CL", "authors": ["hao zhou", "minlie huang", "tianyang zhang", "xiaoyan zhu", "bing liu"], "accepted": false, "id": "1704.01074"}, "pdf": {"name": "1704.01074.pdf", "metadata": {"source": "CRF", "title": "Emotional Chatting Machine: Emotional Conversation Generation with Internal and External Memory", "authors": ["Hao Zhou", "Minlie Huang", "Tianyang Zhang", "Xiaoyan Zhu", "Bing Liu"], "emails": ["tuxchow@gmail.com", "aihuang@tsinghua.edu.cn", "keavilzhangzty@gmail.com,", "zxy-dcs@tsinghua.edu.cn,", "liub@cs.uic.edu"], "sections": [{"heading": null, "text": "Emotional intelligence is one of the key factors to the success of dialogue systems or conversational agents. In this paper, we propose Emotional Chatting Machine (ECM) which generates responses that are appropriate not only at the content level (relevant and grammatical) but also at the emotion level (consistent emotional expression). To the best of our knowledge, this is the first work that addresses the emotion factor in large-scale conversation generation. ECM addresses the factor in three ways: modeling high-level abstraction of emotion expression by embedding emotion categories, changing of implicit internal emotion states, and using explicit emotion expressions with an external emotion vocabulary. Experiments show that our model can generate responses appropriate not only in content but also in emotion."}, {"heading": "1 Introduction", "text": "In recent years, there has been a rising tendency in AI research to enhance Human-Computer Interaction by humanizing machines (Treur, 2007). However, to create a robot capable of acting and talking with a user at the human level requires the robot to understand human cognitive behaviors, while one of the most important human behaviors is expressing and understanding emotions and affects (Salovey and Mayer, 1990; Picard and Picard, 1997). As a vital part of human intelligence, emotional intelligence is defined as the ability to perceive, integrate, understand, and regulate emotions (Mayer and Salovey, 1997; Mayer et al., 2008). To create a machine capable to communicate with a user at\nthe human level, it is necessary to equip the machine with emotional intelligence.\nThere have been prior works on endowing dialogue systems or conversational agents with emotional intelligence, through text, facial expression, and other modalities (Andre et al., 2004; Ptaszynski et al., 2009; Skowron, 2010; Skowron et al., 2011). These studies showed that addressing the issue of emotional intelligence can enhance users performance (Partala and Surakka, 2004) and users satisfaction (Prendinger et al., 2005), and lead to less breakdowns in dialogues (Martinovski and Traum, 2003). Additionally, dialogue behaviors can be adjusted to the users emotional state (Polzin and Waibel, 2000), and systems can respond to users\u2019 utterances both at the contentand affect-related levels (Skowron, 2010).\nHowever, these studies, mostly inspired by psychology findings, are either rule-based or limited to small-scale data, and not easily extensible to large-scale data. Recently, thanks to the advance of deep learning, large-scale conversation generation approaches have been investigated (Ritter et al., 2011; Vinyals and Le, 2015; Shang et al., 2015; Serban et al., 2016). Training on large scale data collected from social media or movie subtitles, most of these works aim to improve the content quality issues of conversation generation systems (Gu et al., 2016; Li et al., 2015; Xing et al., 2016; Mou et al., 2016; Li et al., 2016a). However, to the best of our knowledge, the emotion factor has not been addressed in current large-scale conversation generation models. Table 1 shows some dialogue examples with/without emotions. We can see that our ECM model can be more emotionally empathic.\nIn this paper, we address the problem of generating emotional responses in conversational chatbots. We propose a model in the encoder-decoder framework of large-scale sequence-to-sequence\nar X\niv :1\n70 4.\n01 07\n4v 1\n[ cs\n.C L\n] 4\nA pr\n2 01\n7\ngeneration that can respond to users emotionally. The central idea is to model emotion expressions in conversation generation with the following additional new mechanisms: a high-level abstraction of emotion expressions is considered through embedding emotion categories and feeding into the decoder; an internal memory module is used to implicitly model the change of the internal emotion state of the decoder; and the expression of an emotion is explicitly modeled by choosing a generic (non-emotion) or emotion word during decoding.\nTo the best of our knowledge, this is the first work addressing the emotion factor in large-scale conversation generation. To summarize, our contributions are as follows:\n\u2022 We propose an end-to-end framework to incorporate emotion influence in large-scale sequence-to-sequence conversation generation. Three novel mechanisms are proposed: emotion category embedding, an internal emotion memory, and an external memory.\n\u2022 We show that ECM can generate responses with higher naturalness and emotion intelligence than the traditional seq2seq model. We believe that future work such as empathetic computer agent and emotion interaction model can be carried out based on ECM."}, {"heading": "2 Related Work", "text": ""}, {"heading": "2.1 Emotional Intelligence", "text": "Several attempts have been made to endow dialogue systems or conversational agents with emotional intelligence (Andre et al., 2004; Ptaszynski et al., 2009; Skowron, 2010; Skowron et al., 2011). In interactions between humans and artificial agents, the capability to detect signs of human emotions and to suitably react to them can\nenrich communication. For example, display of empathic emotional expressions enhanced users performance (Partala and Surakka, 2004), led to an increase in users satisfaction (Prendinger et al., 2005). Experiments in (Prendinger and Ishizuka, 2005) showed that an empathetic computer agent can contribute to a more positive perception of the interaction. In (Martinovski and Traum, 2003), the authors showed that many breakdowns could be avoided if the machine was able to recognize the emotional state of the user and responded to it sensitively. The work in (Polzin and Waibel, 2000) presented how dialogue behaviors can be adjusted to the users emotional state. Skowron (2010) proposed conversational systems, called affect listeners, that can respond to users\u2019 utterances both at the content- and affect-related level.\nThese works, mainly inspired by psychological findings, are either rule-based, or limited to small data, making them difficult to apply to large-scale dialogue or conversation generation."}, {"heading": "2.2 Large-scale Sequence-to-sequence Based Conversation Generation", "text": "Thanks to the recent advances of deep learning, data-driven approaches are applied to opendomain conversation systems (Ritter et al., 2011; Shang et al., 2015; Serban et al., 2015). In (Ritter et al., 2011), statistical machine translation (SMT) was used to generate conversational responses from social media data. Due to the success of sequence-to-sequence generation models in machine translation (Sutskever et al., 2014; Bahdanau et al., 2014), these models were soon applied to conversation generation (Vinyals and Le, 2015), including the neural responding machine (Shang et al., 2015), the hierarchical recurrent encoderdecoder neural network (Serban et al., 2015), and many others (Sordoni et al., 2015).\nTo avoid generating meaningless and universal responses such as \u201cI dont know\u201d, Li et al. (2015) proposed the maximum mutual information (MMI) principle as an alternative to maximum likelihood estimation. Beam search was also extensively used to generate meaningful and diversified responses (Li et al., 2015, 2016b; Shao et al., 2017). Other attempts to improve content quality include incorporating into the decoder additional topic words (Xing et al., 2016; Mou et al., 2016), topic categories (Xiong et al., 2016), persona information (Li et al., 2016a), or other retrieved\nresponses (Song et al., 2016). Another path to avoid meaningless response is to apply deep reinforcement learning which can model the long-term delayed reward in chatbot\u2019s dialogues (Li et al., 2016c; Ranzato et al., 2015). Dealing with unknown words can improve the generation quality too. Duplicating low-frequency words from post to response was proposed in (Gu et al., 2016).\nThese works have been done to improve the content quality generation, however, no work has addressed the emotion factor. Our work aims to generate responses both relevant in content and coherent in emotion."}, {"heading": "2.3 Memory-based Networks", "text": "Memory Network (Weston et al., 2014) and Neural Turing Machine (NTM) (Graves et al., 2014) augment traditional RNNs with memory structures to improve the ability of modeling long-range sequences. Inspired by these models, many other memory networks have been proposed for tasks such as machine translation (Meng et al., 2015), question answering (Miller et al., 2016) and dialogue state tracking (Perez and Liu, 2016). Our model adopts a dynamic memory to model the change of an internal emotion state, and a static memory to store a dictionary of emotion words."}, {"heading": "3 Background: Sequence-to-sequence Generation", "text": "Before presenting the proposed model, we first introduce a general encoder-decoder framework based on sequence-to-sequence (seq2seq) learning (Sutskever et al., 2014), which will be adopted for our work. The encoder and decoder of the seq2seq model (Sutskever et al., 2014) are implemented with GRU (Cho et al., 2014; Chung et al., 2014).\nThe encoder converts the post sequence X = (x1, x2, \u00b7 \u00b7 \u00b7 , xn) to hidden representations h = (h1, h2, \u00b7 \u00b7 \u00b7 , hn), which is briefly defined as:\nht = GRU(ht\u22121, xt) (1)\nDetails of GRU can be found in (Cho et al., 2014). The decoder takes a context vector ct and the embedding of a previously decoded word e(yt\u22121), and updates its state st using another GRU:\nst = GRU(st\u22121, [ct; e(yt\u22121)]) (2)\nwhere [ct; e(yt\u22121)] is concatenation of the two vectors, serving as input to the GRU network. The\ncontext vector ct is designed to dynamically attend on key information of the input post during decoding (Bahdanau et al., 2014). Formally, ct depends on the previous state of the decoder st\u22121:\nct = n\u2211\nk=1\n\u03b1tkhk (3)\n\u03b1tk = exp(etk)\u2211n j=1 exp(etj)\n(4)\netk = v > a tanh(Wast\u22121 + Uahk) (5)\nwhere \u03b1tk can be viewed as the similarity score between each hidden state hk of the post and the decoder\u2019s state st\u22121.\nOnce the state vector st is obtained, the decoder generates a token by sampling from the output probability distribution ot computed from the decoder\u2019s state st, as follows:\nyt \u223c ot = P (yt | y1, y2, \u00b7 \u00b7 \u00b7 , yt\u22121, ct) (6) = softmax(Wost) (7)"}, {"heading": "4 Emotional Chatting Machine", "text": ""}, {"heading": "4.1 Task Definition and Overview", "text": "The problem we deal with in this paper is formulated as follows: Given a post X = (x1, x2, \u00b7 \u00b7 \u00b7 , xn), and a user-specified emotion category e of the response to be generated, the goal is to generate a response Y = (y1, y2, \u00b7 \u00b7 \u00b7 , ym) that is coherent with the emotion category e. Essentially, the model estimates the probability: P (Y |X, e) = \u220fm t=1 P (yt|y<t,X, e). The emotion categories are {Anger, Disgust, Happiness, Like, Sadness, Other}, adopted from a Chinese emotion classification challenge task.1 In order to train our model, X/Y will be automatically annotated with emotion categories by an emotion classifier.\nBuilt upon the sequence-to-sequence (seq2seq) generation framework discussed in the previous section. Emotional Chatting Machine (ECM) generates an emotion expression using three mechanisms: First, since the emotion category is a highlevel abstraction of an emotion expression, ECM embeds the emotion category and takes the emotion category embedding as input to the decoder; Second, we assume that during decoding, there is an internal emotion state, and in order to model\n1The taxonomy comes from http://tcci.ccf.org.cn/confere -nce/2014/dldoc/evatask1.pdf\nthe implicit change of the state, ECM adopts an internal memory module; Last, explicit expression of an emotion is modeled through explicit selection of a common or emotion word by an external memory module.\nAn overview of ECM is given in Figure 1. The decoder has several inputs: the context vector c, and, the emotion embedding vector and the internal memory both indexed by the emotion category. After combined with an external memory module, the decoder obtains a probability distribution o (see Eq. 17) for response generation."}, {"heading": "4.2 Emotion Category Embedding", "text": "Since an emotion category provides a high-level abstraction of an expression of the emotion, the most intuitive approach to model emotion in response generation is to take as additional input the emotion category of a response to be generated. Each emotion category is represented by a realvalued, low dimensional vector. For each emotion category e, we randomly initialize the vector of the emotion category ve, and then learn the emotion category representations through training. The emotion category embedding ve, along with word embedding e(yt\u22121), and the context vector ct, are fed into the decoder to update the decoder\u2019s state st:\nst = GRU(st\u22121, [ct; e(yt\u22121); ve]) (8)\nBased on st, the decoding probability distribution can be updated accordingly as Eq. 7 to generate the next token yt."}, {"heading": "4.3 Internal Memory", "text": "The method presented in the preceding section is rather static: the emotion category embedding will not change during the token generation process. We assume that there is an internal emotion state during the decoding process, and the state changes as the decoding process proceeds. Hence, we design an internal memory module to approach the emotion dynamics during decoding. We simulate the process as follows: there is an internal emotion state for each category before the decoding process starts; at each step of the decoding pro-\ncess, the emotion state decays by a certain amount; once the decoding process stops, the emotion state should decay to zero.\nThe detailed process of the internal memory module is illustrated in Figure 2. At each step t, the read gate grt takes as input the word embedding of the previously decoded word e(yt\u22121), the previous state of the decoder st\u22121, and the current context vector ct. The write gate gwt computes a write vector from the decoder\u2019s state vector st. The read and write vector are then used to read from and write into the internal memory. Hence, the emotion state is erased by a certain amount (by gwt ) at each step. At the last step, the internal emotion state will decay to zero. This process is formally described as below:\ngrt = \u03c3(W r g [e(yt\u22121); st\u22121; ct]) (9)\ngwt = \u03c3(W w g st) (10) M Ir,t = g r t M Ie,t (11) M Ie,t+1 = g w t M Ie,t (12)\nwhere r/w denotes read/write respectively, and I means Internal. With the input of the previous target word e(yt\u22121), the previous state of the decoder st\u22121, the context vector ct, and the emotion state update M Ir,t, GRU outputs the current state st,\nst = GRU(st\u22121, [ct; e(yt\u22121);M I r,t]) (13)\nWith the state, the word generation distribution ot can be obtained with Eq. 7, and the next word yt can be sampled. After generating the next word, M Ie,t+1 is written back to the internal memory.\nIt is noteworthy that the write vector works as a DELETE operation to model the expression of an emotion in generation of a response, which is quite different from the ADD and DELETE operation used in previous memory networks (Meng et al., 2015; Miller et al., 2016; Perez and Liu, 2016)."}, {"heading": "4.4 External Memory", "text": "In the internal memory module, the correlation between the change of the internal emotion state and choosing of a word is implicit and not directly observable. As most emotional responses contain emotion words such as lovely and awesome which indicate strong emotions compared to generic (non-emotion) words such as person and day, we propose an external memory model to model emotion expressions explicitly by assigning different generation probabilities to emotion\nwords and generic words. Thus the model can choose to generate words from a generic vocabulary or an emotion vocabulary (Xu et al., 2008).\nThe decoder with an external memory is illustrated in Figure 3. Given the current state of the decoder st, the emotion softmax Pe(yt = we) and the generic softmax Pg(yt = wg) are computed over the emotion vocabulary which is read from the external memory and generic vocabulary, respectively. The output gate got controls the weights of generating an emotion or a generic word. Finally, the next word yt is sampled from the next word probability, and the concatenation of the two weighted probabilities. The process can be formulated as follows:\ngot = \u03c3(v > u st) (14)\nPg(yt = wg) = softmax(W o g st) (15) Pe(yt = we) = softmax(W o e st) (16)\not = P (yt) =\n[ (1\u2212 got )Pg(yt = wg)\ngotPe(yt = we)\n] (17)\nwhere got \u2208 [0, 1] is a scalar to balance the choice between an emotion word we and a generic word wg, Pg/Pe is the distribution over generic/emotion words respectively, and P (yt) is the final word decoding distribution. Note that the two vocabularies have no intersection, and the final distribution P (yt) is a concatenation of two distributions."}, {"heading": "4.5 Loss Function", "text": "The loss function is the cross entropy error between the predicted token distribution ot and the gold distribution pt in the training corpus. Additionally, we apply two regularization terms: one\non the internal memory, enforcing that the internal emotion state should decay to zero at the end of decoding, and the other on the external memory, constraining the selection of an emotional or generic word. The loss on one sample < X,Y > (X = x1, x2, ..., xn, Y = y1, y2, ..., ym) is defined as: L(\u03b8) = \u2212 m\u2211 t=1 ptlog(ot)\u2212 m\u2211 t=1 qtlog(g o t )+ \u2016M Ie,m \u2016 (18) whereM Ie,m is the internal emotion state at the last step m, got is the probability of choosing an emotion word or a generic word, and qt \u2208 {0, 1} is the true choice of an emotion word or a generic word in Y . The second term is used to supervise the probability of selecting an emotion or generic word. And the third term is used to ensure that the internal emotion state has been expressed completely once the generation is completed."}, {"heading": "5 Datasets and Preparation", "text": ""}, {"heading": "5.1 Data Collection", "text": "We collected several Weibo datasets:\n\u2022 The STC dataset: a conversation dataset from (Shang et al., 2015), where each post has multiple responses. It has 219,905 posts and 4,308,211 responses. The ratio of post to response is about 1:20. This dataset will be automatically annotated by an emotion classifier and then used to train our model. We also collected 9,698,728 one-to-one postresponse pairs from Weibo for pretraining.\n\u2022 The NLPCC dataset: the Emotion Analysis Dataset of NLPCC 20132&20143, a benchmark dataset for emotion classification, consisting of 23,105 sentences collected from Weibo. The dataset is manually annotated with the emotion categories Anger, Disgust, Fear, Happiness, Like, Sadness and Surprise, and is used to train the emotion classifier."}, {"heading": "5.2 Emotion Classifier", "text": "To annotate the large-scale STC Dataset with emotion categories, we compare several models for emotion classification, including a dictionary based classifier (denoted by Dict in Table 2), RNN (Mikolov et al., 2010), LSTM (Hochreiter\n2http://tcci.ccf.org.cn/conference/2013/ 3http://tcci.ccf.org.cn/conference/2014/\nand Schmidhuber, 1997), and Bidirectional LSTM (Bi-LSTM) (Graves et al., 2005). After removing the infrequent classes including Fear and Surprise of which the proportion are 1.5% and 4.4% respectively, we partition the NLPCC dataset into the training, validation, and test set with the ratio of 8:1:1. Finally, the accuracy of 6-class (Anger, Disgust, Happiness, Like, Sadness and Other) classification is shown in Table 2.\nResults show that all neural classifiers outperform the dictionary-based classifier, and the BiLSTM classifier obtains the best performance of 0.623. Although this accuracy may introduce errors in the classification of emotion categories, we found that it is sufficient for our models to generate good emotional responses in practice. As future work, we will consider how the classification errors influence response generation."}, {"heading": "5.3 Weibo Emotion Dataset", "text": "We apply the Bi-LSTM emotion classifier to annotate the STC Dataset with emotion categories. To build the validation and test sets, we randomly sample 1000 posts respectively, and these samples don\u2019t contain low frequency words and have more than 20 responses.\nAfter automated annotation, we call this dataset the Weibo Emotion Dataset which is used to train our ECM models. The statistics of the Weibo Emotion Dataset are shown in Table 3."}, {"heading": "6 Experiments", "text": ""}, {"heading": "6.1 Implementation Details", "text": "We use Tensorflow(Abadi et al., 2016) to implement the proposed model. The encoder and decoder have 2-layer GRU structures with 256 hidden cells for each layer and use different sets of parameters respectively. The word embedding size is set to 100. The vocabulary size is limited to 40,000. The embedding size of emotion category is set to 100. The internal memory is a trainable matrix of size 6 \u00d7 256 and the external memory is a list of 40,000 words containing generic words and emotion words (but emotion words have different markers). Parameters are initialized by sampling from the uniform distribution (\u2212sqrt(3/n), sqrt(3/n)), where n represents the dimension of parameters. To generate diverse responses, we adopt beam search in the decoding process of which the beam size is set to 20. And then rerank responses by the generation probability after removing those containing UNKs, unknown words.\nWe use the stochastic gradient descent (SGD) algorithm with mini-batch. Batch size and learning rate are set to 128 and 0.5, respectively. To accelerate the training process, we train a seq2seq model on the Weibo pretraining dataset with pretrained word embeddings. And we then train our model on the Weibo Emotion Dataset with parameters initialized by the parameters of the pretrained seq2seq model. We run 20 epoches, and the training stage of each model took about a week on a Titan X GPU machine."}, {"heading": "6.2 Quantitative Evaluation", "text": "As argued in (Liu et al., 2016), BLEU is not suitable for measuring conversation generation. Instead, we adopt perplexity to evaluate the model at the content level (whether the content is relevant and grammatical). To evaluate the model at the emotion level, we adopt the coherence between the expected emotion category (as input to the model)\nand the predicted emotion category of a generated response by the emotion classifier as mentioned in Section 5.2.\nWe compare the seq2seq model (Sutskever et al., 2014) as the baseline with our ECM models. The three options including emotion category embedding (Emb), internal memory (IMem), and external memory (EMem) are incrementally added to the basic model. In other words, EMem in the tables means all three options have been included. We choose the model with the best perplexity on the validation set to evaluate the two metrics of perplexity and coherence in the test set. To evaluate the performance of ECM models at the emotion level, we generate emotional responses using beam search and evaluate the emotion coherence of the top 5 responses for each model on the 1,000 test set.\nThe results are shown in Table 4. As it can be seen, the perplexity of our models is much lower than that of the seq2seq model; the emotion coherence is much higher correspondingly. Note that emotion coherence measures the agreement between the pre-specified emotion category and the predicted category by the emotion classifier, which may be influenced by the errors of the classifier. However, as shown in the table, better coherence is observed when more model options are incrementally added.\nAlthough the EMem model obtains the best performance in emotion coherence, the perplexity of this model is worse than the other two settings after incorporating the external memory. This may be due to the fact that the loss function of the EMem model is not only supervised on perplexity, but also on the selection of generic or emotion words (see Eq.18)."}, {"heading": "6.3 Human Evaluation", "text": "In order to better understand the quality of generated responses from the content and emotion perspectives, we recruit 5 judges for human eval-\nuation experiments. Given the post and an emotion category, the seq2seq model and ECM models are used to generate one response, and the top response generated by beam search for each model was presented to human judges. Judges were asked to score each response in terms of naturalness and emotion (rating scale is 1,2,3), and also to state a preference between any two of the four systems. The naturalness is defined as whether the response could plausibly have been produced by a human and the emotion is defined as whether the emotion expression of a response is coherent and appropriate to the given emotion category. We test the same 500 posts extracted from the test set, for each setting of our models, we generate 2533 emotional responses, and additional 500 responses for the seq2seq model, which amounts to 8099 responses in total.\nThe results of human evaluation for the quality of response are shown in Table 5. As can be seen, EMem outperforms the other methods in both metrics. Besides, ECM models are much more preferred than the seq2seq model and EMem is most preferred by judges compared to other methods as shown in Table 6."}, {"heading": "6.4 Analysis of Emotion Interaction", "text": "We present some sample responses in Figure 4. We can see that ECM can generate responses that are appropriate both in content and in emotion if the pre-specified emotion category and the emotion of the post belong to one of frequent emotion interaction patterns. Emotion interaction pattern (EIP) is defined as < ep, er >, the pair of emotion categories of a post and its response. The value of an EIP is the conditional probability P (er|ep) = P (er, ep)/P (ep). For low-valued EIPs such as < Happiness,Disgust > and < Happiness,Anger > as shown in last two lines of Figure 4, responses are less coherent to the emotion category due to the lack of training data and/or the errors caused by the emotion classifier./Users/tuxchow/Downloads/ZhouHaoACL2017 (arxiv)/acl2017.bib\nFigure 5 visualizes the emotion interaction patterns between post and response in the training\ndata whose label is made by our emotion classifier. The color darkness indicates the strength of an EIP. Each cell indicates an EIP, for instance, the cell of row 6 and column 2 indicates < Happiness,Like >. Frequent EIPs show that there exists a major responding emotion given the post emotion category. For instance, when a post expresses Happiness, the emotion of responses is typically Like. The diagonal patterns indicate emotional empathy which is a common type of emotion interaction. Note that class other has much more data than other classes (see Table 3), and thus EIP is biased to this class (the first column of Figure 5), which may be biased by the data and the errors of the classifier. Also, note that the analysis highly depends on the results of an automated classifier but not manually labeled data."}, {"heading": "7 Conclusion", "text": "In this paper, we proposed the emotional chatting machine (ECM) to model the emotion influence in large-scale conversation generation. Three mechanisms have been proposed to model the emotion factor, including emotion category embedding, internal emotion memory, and external memory. Automatic and manual evaluation shows that ECM can generate responses appropriate not only in content but also in emotion. Preference tests show that our proposals are more preferred than the seq2seq model. As future work, we will explore the emotion interaction patterns based on ECM."}], "references": [{"title": "Tensorflow: Large-scale machine learning on heterogeneous distributed systems", "author": ["Mart\u0131\u0301n Abadi", "Ashish Agarwal", "Paul Barham", "Eugene Brevdo", "Zhifeng Chen", "Craig Citro", "Greg S Corrado", "Andy Davis", "Jeffrey Dean", "Matthieu Devin"], "venue": null, "citeRegEx": "Abadi et al\\.,? \\Q2016\\E", "shortCiteRegEx": "Abadi et al\\.", "year": 2016}, {"title": "Endowing spoken language dialogue systems with emotional intelligence", "author": ["Elisabeth Andre", "Matthias Rehm", "Wolfgang Minker", "Dirk B\u00fchler."], "venue": "Tutorial and Research Workshop on Affective Dialogue Systems. Springer, pages 178\u2013187.", "citeRegEx": "Andre et al\\.,? 2004", "shortCiteRegEx": "Andre et al\\.", "year": 2004}, {"title": "Neural machine translation by jointly learning to align and translate", "author": ["Dzmitry Bahdanau", "Kyunghyun Cho", "Yoshua Bengio."], "venue": "arXiv preprint arXiv:1409.0473 .", "citeRegEx": "Bahdanau et al\\.,? 2014", "shortCiteRegEx": "Bahdanau et al\\.", "year": 2014}, {"title": "Empirical evaluation of gated recurrent neural networks on sequence modeling", "author": ["Junyoung Chung", "Caglar Gulcehre", "KyungHyun Cho", "Yoshua Bengio."], "venue": "arXiv preprint arXiv:1412.3555 .", "citeRegEx": "Chung et al\\.,? 2014", "shortCiteRegEx": "Chung et al\\.", "year": 2014}, {"title": "Bidirectional lstm networks for improved phoneme classification and recognition", "author": ["Alex Graves", "Santiago Fern\u00e1ndez", "J\u00fcrgen Schmidhuber."], "venue": "International Conference on Artificial Neural Networks. Springer, pages 799\u2013804.", "citeRegEx": "Graves et al\\.,? 2005", "shortCiteRegEx": "Graves et al\\.", "year": 2005}, {"title": "Neural turing machines", "author": ["Alex Graves", "Greg Wayne", "Ivo Danihelka."], "venue": "arXiv preprint arXiv:1410.5401 .", "citeRegEx": "Graves et al\\.,? 2014", "shortCiteRegEx": "Graves et al\\.", "year": 2014}, {"title": "Incorporating copying mechanism in sequence-to-sequence learning", "author": ["Jiatao Gu", "Zhengdong Lu", "Hang Li", "Victor OK Li."], "venue": "Proceedings of the 54th Annual Meeting of the Association for Computational Linguistics.", "citeRegEx": "Gu et al\\.,? 2016", "shortCiteRegEx": "Gu et al\\.", "year": 2016}, {"title": "Long short-term memory", "author": ["Sepp Hochreiter", "J\u00fcrgen Schmidhuber."], "venue": "Neural computation 9(8):1735\u20131780.", "citeRegEx": "Hochreiter and Schmidhuber.,? 1997", "shortCiteRegEx": "Hochreiter and Schmidhuber.", "year": 1997}, {"title": "A diversity-promoting objective function for neural conversation models", "author": ["Jiwei Li", "Michel Galley", "Chris Brockett", "Jianfeng Gao", "Bill Dolan."], "venue": "arXiv preprint arXiv:1510.03055 .", "citeRegEx": "Li et al\\.,? 2015", "shortCiteRegEx": "Li et al\\.", "year": 2015}, {"title": "A persona-based neural conversation model", "author": ["Jiwei Li", "Michel Galley", "Chris Brockett", "Jianfeng Gao", "Bill Dolan."], "venue": "arXiv preprint arXiv:1603.06155 .", "citeRegEx": "Li et al\\.,? 2016a", "shortCiteRegEx": "Li et al\\.", "year": 2016}, {"title": "A simple, fast diverse decoding algorithm for neural generation", "author": ["Jiwei Li", "Will Monroe", "Dan Jurafsky."], "venue": "CoRR abs/1611.08562.", "citeRegEx": "Li et al\\.,? 2016b", "shortCiteRegEx": "Li et al\\.", "year": 2016}, {"title": "Deep reinforcement learning for dialogue generation", "author": ["Jiwei Li", "Will Monroe", "Alan Ritter", "Dan Jurafsky."], "venue": "arXiv preprint arXiv:1606.01541 .", "citeRegEx": "Li et al\\.,? 2016c", "shortCiteRegEx": "Li et al\\.", "year": 2016}, {"title": "How NOT to evaluate your dialogue system: An empirical study of unsupervised evaluation metrics for dialogue response generation", "author": ["Chia-Wei Liu", "Ryan Lowe", "Iulian Serban", "Michael Noseworthy", "Laurent Charlin", "Joelle Pineau."], "venue": "In", "citeRegEx": "Liu et al\\.,? 2016", "shortCiteRegEx": "Liu et al\\.", "year": 2016}, {"title": "Breakdown in human-machine interaction: the error is the clue", "author": ["Bilyana Martinovski", "David Traum."], "venue": "Proceedings of the ISCA tutorial and research workshop on Error handling in dialogue systems. pages 11\u201316.", "citeRegEx": "Martinovski and Traum.,? 2003", "shortCiteRegEx": "Martinovski and Traum.", "year": 2003}, {"title": "Human abilities: Emotional intelligence", "author": ["John D Mayer", "Richard D Roberts", "Sigal G Barsade."], "venue": "Annu. Rev. Psychol. 59:507\u2013536.", "citeRegEx": "Mayer et al\\.,? 2008", "shortCiteRegEx": "Mayer et al\\.", "year": 2008}, {"title": "What is emotional intelligence? Emotional Development and Emo- tional Intelligence pages 3\u201331", "author": ["John D Mayer", "Peter Salovey"], "venue": null, "citeRegEx": "Mayer and Salovey.,? \\Q1997\\E", "shortCiteRegEx": "Mayer and Salovey.", "year": 1997}, {"title": "A deep memory-based architecture for sequence-to-sequence learning", "author": ["Fandong Meng", "Zhengdong Lu", "Zhaopeng Tu", "Hang Li", "Qun Liu."], "venue": "arXiv preprint arXiv:1506.06442 .", "citeRegEx": "Meng et al\\.,? 2015", "shortCiteRegEx": "Meng et al\\.", "year": 2015}, {"title": "Recurrent neural network based language model", "author": ["Tomas Mikolov", "Martin Karafi\u00e1t", "Lukas Burget", "Jan Cernock\u1ef3", "Sanjeev Khudanpur."], "venue": "Interspeech. volume 2, page 3.", "citeRegEx": "Mikolov et al\\.,? 2010", "shortCiteRegEx": "Mikolov et al\\.", "year": 2010}, {"title": "Key-value memory networks for directly reading documents", "author": ["Alexander Miller", "Adam Fisch", "Jesse Dodge", "AmirHossein Karimi", "Antoine Bordes", "Jason Weston."], "venue": "arXiv preprint arXiv:1606.03126 .", "citeRegEx": "Miller et al\\.,? 2016", "shortCiteRegEx": "Miller et al\\.", "year": 2016}, {"title": "Sequence to backward and forward sequences: A content-introducing approach to generative short-text conversation", "author": ["Lili Mou", "Yiping Song", "Rui Yan", "Ge Li", "Lu Zhang", "Zhi Jin."], "venue": "26th International Conference on Computational Linguistics,", "citeRegEx": "Mou et al\\.,? 2016", "shortCiteRegEx": "Mou et al\\.", "year": 2016}, {"title": "The effects of affective interventions in human\u2013computer interaction", "author": ["Timo Partala", "Veikko Surakka."], "venue": "Interacting with computers 16(2):295\u2013309.", "citeRegEx": "Partala and Surakka.,? 2004", "shortCiteRegEx": "Partala and Surakka.", "year": 2004}, {"title": "Dialog state tracking, a machine reading approach using memory network", "author": ["Julien Perez", "Fei Liu."], "venue": "arXiv preprint arXiv:1606.04052 .", "citeRegEx": "Perez and Liu.,? 2016", "shortCiteRegEx": "Perez and Liu.", "year": 2016}, {"title": "Affective computing, volume 252", "author": ["Rosalind W Picard", "Roalind Picard."], "venue": "MIT press Cambridge.", "citeRegEx": "Picard and Picard.,? 1997", "shortCiteRegEx": "Picard and Picard.", "year": 1997}, {"title": "Emotion-sensitive human-computer interfaces", "author": ["Thomas S Polzin", "Alexander Waibel."], "venue": "ISCA Tutorial and Research Workshop (ITRW) on Speech and Emotion.", "citeRegEx": "Polzin and Waibel.,? 2000", "shortCiteRegEx": "Polzin and Waibel.", "year": 2000}, {"title": "The empathic companion: A character-based interface that addresses users\u2019affective states", "author": ["Helmut Prendinger", "Mitsuru Ishizuka."], "venue": "Applied Artificial Intelligence 19(3-4):267\u2013285.", "citeRegEx": "Prendinger and Ishizuka.,? 2005", "shortCiteRegEx": "Prendinger and Ishizuka.", "year": 2005}, {"title": "Using human physiology to evaluate subtle expressivity of a virtual quizmaster in a mathematical game", "author": ["Helmut Prendinger", "Junichiro Mori", "Mitsuru Ishizuka."], "venue": "International journal of human-computer studies 62(2):231\u2013245.", "citeRegEx": "Prendinger et al\\.,? 2005", "shortCiteRegEx": "Prendinger et al\\.", "year": 2005}, {"title": "Towards context aware emotional intelligence in machines: Computing contextual appropriateness of affective states", "author": ["Michal Ptaszynski", "Pawel Dybala", "Wenhan Shi", "Rafal Rzepka", "Kenji Araki."], "venue": "IJCAI 2009, Proceedings of the 21st Interna-", "citeRegEx": "Ptaszynski et al\\.,? 2009", "shortCiteRegEx": "Ptaszynski et al\\.", "year": 2009}, {"title": "Sequence level training with recurrent neural networks. CoRR abs/1511.06732", "author": ["Marc\u2019Aurelio Ranzato", "Sumit Chopra", "Michael Auli", "Wojciech Zaremba"], "venue": null, "citeRegEx": "Ranzato et al\\.,? \\Q2015\\E", "shortCiteRegEx": "Ranzato et al\\.", "year": 2015}, {"title": "Data-driven response generation in social media", "author": ["Alan Ritter", "Colin Cherry", "William B. Dolan."], "venue": "Conference on Empirical Methods in Natural Language Processing, EMNLP 2011, 27-31 July 2011, John Mcintyre Conference Centre, Edinburgh, Uk,", "citeRegEx": "Ritter et al\\.,? 2011", "shortCiteRegEx": "Ritter et al\\.", "year": 2011}, {"title": "Emotional intelligence", "author": ["Peter Salovey", "John D Mayer."], "venue": "Imagination, cognition and personality 9(3):185\u2013211.", "citeRegEx": "Salovey and Mayer.,? 1990", "shortCiteRegEx": "Salovey and Mayer.", "year": 1990}, {"title": "Hierarchical neural network generative models for movie dialogues", "author": ["Iulian V Serban", "Alessandro Sordoni", "Yoshua Bengio", "Aaron Courville", "Joelle Pineau."], "venue": "arXiv preprint arXiv:1507.04808 .", "citeRegEx": "Serban et al\\.,? 2015", "shortCiteRegEx": "Serban et al\\.", "year": 2015}, {"title": "Building end-to-end dialogue systems using generative hierarchical neural network models", "author": ["Iulian V. Serban", "Alessandro Sordoni", "Yoshua Bengio", "Aaron Courville", "Joelle Pineau."], "venue": "Computer Science .", "citeRegEx": "Serban et al\\.,? 2016", "shortCiteRegEx": "Serban et al\\.", "year": 2016}, {"title": "Neural responding machine for short-text conversation", "author": ["Lifeng Shang", "Zhengdong Lu", "Hang Li."], "venue": "Computer Science .", "citeRegEx": "Shang et al\\.,? 2015", "shortCiteRegEx": "Shang et al\\.", "year": 2015}, {"title": "Generating long and diverse responses with neural conversation models", "author": ["Louis Shao", "Stephan Gouws", "Denny Britz", "Anna Goldie", "Brian Strope", "Ray Kurzweil."], "venue": "CoRR abs/1701.03185.", "citeRegEx": "Shao et al\\.,? 2017", "shortCiteRegEx": "Shao et al\\.", "year": 2017}, {"title": "Affect listeners: Acquisition of affective states by means of conversational systems", "author": ["Marcin Skowron."], "venue": "Development of Multimodal Interfaces: Active Listening and Synchrony, Springer, pages 169\u2013 181.", "citeRegEx": "Skowron.,? 2010", "shortCiteRegEx": "Skowron.", "year": 2010}, {"title": "The good, the bad and the neutral: affective profile in dialog system-user communication", "author": ["Marcin Skowron", "Stefan Rank", "Mathias Theunis", "Julian Sienkiewicz."], "venue": "International Conference on Affective Computing and Intelligent Interaction. Springer,", "citeRegEx": "Skowron et al\\.,? 2011", "shortCiteRegEx": "Skowron et al\\.", "year": 2011}, {"title": "Two are better than one: An ensemble of retrieval-and generation-based dialog systems", "author": ["Yiping Song", "Rui Yan", "Xiang Li", "Dongyan Zhao", "Ming Zhang."], "venue": "arXiv preprint arXiv:1610.07149 .", "citeRegEx": "Song et al\\.,? 2016", "shortCiteRegEx": "Song et al\\.", "year": 2016}, {"title": "A neural network approach to context-sensitive generation of conversational responses", "author": ["Alessandro Sordoni", "Michel Galley", "Michael Auli", "Chris Brockett", "Yangfeng Ji", "Margaret Mitchell", "Jian-Yun Nie", "Jianfeng Gao", "Bill Dolan."], "venue": "NAACL HLT", "citeRegEx": "Sordoni et al\\.,? 2015", "shortCiteRegEx": "Sordoni et al\\.", "year": 2015}, {"title": "Sequence to sequence learning with neural networks", "author": ["Ilya Sutskever", "Oriol Vinyals", "Quoc V Le."], "venue": "Advances in neural information processing systems. pages 3104\u20133112.", "citeRegEx": "Sutskever et al\\.,? 2014", "shortCiteRegEx": "Sutskever et al\\.", "year": 2014}, {"title": "On human aspects in ambient intelligence", "author": ["Jan Treur."], "venue": "European Conference on Ambient Intelligence. Springer, pages 262\u2013267.", "citeRegEx": "Treur.,? 2007", "shortCiteRegEx": "Treur.", "year": 2007}, {"title": "A neural conversational model", "author": ["Oriol Vinyals", "Quoc Le."], "venue": "Computer Science .", "citeRegEx": "Vinyals and Le.,? 2015", "shortCiteRegEx": "Vinyals and Le.", "year": 2015}, {"title": "Memory networks", "author": ["Jason Weston", "Sumit Chopra", "Antoine Bordes."], "venue": "arXiv preprint arXiv:1410.3916 .", "citeRegEx": "Weston et al\\.,? 2014", "shortCiteRegEx": "Weston et al\\.", "year": 2014}, {"title": "Topic aware neural response generation", "author": ["Chen Xing", "Wei Wu", "Yu Wu", "Jie Liu", "Yalou Huang", "Ming Zhou", "Wei-Ying Ma."], "venue": "arXiv preprint arXiv:1606.08340 .", "citeRegEx": "Xing et al\\.,? 2016", "shortCiteRegEx": "Xing et al\\.", "year": 2016}, {"title": "Neural contextual conversation learning with labeled question-answering pairs", "author": ["Kun Xiong", "Anqi Cui", "Zefeng Zhang", "Ming Li."], "venue": "CoRR abs/1607.05809.", "citeRegEx": "Xiong et al\\.,? 2016", "shortCiteRegEx": "Xiong et al\\.", "year": 2016}, {"title": "Affective lexicon ontology", "author": ["Linhong Xu", "Hongfei Lin", "Yu Pan", "Hui Ren", "Jianmei Chen."], "venue": "Journal of information 27(2):180\u2013185.", "citeRegEx": "Xu et al\\.,? 2008", "shortCiteRegEx": "Xu et al\\.", "year": 2008}], "referenceMentions": [{"referenceID": 39, "context": "In recent years, there has been a rising tendency in AI research to enhance Human-Computer Interaction by humanizing machines (Treur, 2007).", "startOffset": 126, "endOffset": 139}, {"referenceID": 29, "context": "However, to create a robot capable of acting and talking with a user at the human level requires the robot to understand human cognitive behaviors, while one of the most important human behaviors is expressing and understanding emotions and affects (Salovey and Mayer, 1990; Picard and Picard, 1997).", "startOffset": 249, "endOffset": 299}, {"referenceID": 22, "context": "However, to create a robot capable of acting and talking with a user at the human level requires the robot to understand human cognitive behaviors, while one of the most important human behaviors is expressing and understanding emotions and affects (Salovey and Mayer, 1990; Picard and Picard, 1997).", "startOffset": 249, "endOffset": 299}, {"referenceID": 15, "context": "As a vital part of human intelligence, emotional intelligence is defined as the ability to perceive, integrate, understand, and regulate emotions (Mayer and Salovey, 1997; Mayer et al., 2008).", "startOffset": 146, "endOffset": 191}, {"referenceID": 14, "context": "As a vital part of human intelligence, emotional intelligence is defined as the ability to perceive, integrate, understand, and regulate emotions (Mayer and Salovey, 1997; Mayer et al., 2008).", "startOffset": 146, "endOffset": 191}, {"referenceID": 1, "context": "There have been prior works on endowing dialogue systems or conversational agents with emotional intelligence, through text, facial expression, and other modalities (Andre et al., 2004; Ptaszynski et al., 2009; Skowron, 2010; Skowron et al., 2011).", "startOffset": 165, "endOffset": 247}, {"referenceID": 26, "context": "There have been prior works on endowing dialogue systems or conversational agents with emotional intelligence, through text, facial expression, and other modalities (Andre et al., 2004; Ptaszynski et al., 2009; Skowron, 2010; Skowron et al., 2011).", "startOffset": 165, "endOffset": 247}, {"referenceID": 34, "context": "There have been prior works on endowing dialogue systems or conversational agents with emotional intelligence, through text, facial expression, and other modalities (Andre et al., 2004; Ptaszynski et al., 2009; Skowron, 2010; Skowron et al., 2011).", "startOffset": 165, "endOffset": 247}, {"referenceID": 35, "context": "There have been prior works on endowing dialogue systems or conversational agents with emotional intelligence, through text, facial expression, and other modalities (Andre et al., 2004; Ptaszynski et al., 2009; Skowron, 2010; Skowron et al., 2011).", "startOffset": 165, "endOffset": 247}, {"referenceID": 20, "context": "These studies showed that addressing the issue of emotional intelligence can enhance users performance (Partala and Surakka, 2004) and users satisfaction (Prendinger et al.", "startOffset": 103, "endOffset": 130}, {"referenceID": 25, "context": "These studies showed that addressing the issue of emotional intelligence can enhance users performance (Partala and Surakka, 2004) and users satisfaction (Prendinger et al., 2005), and lead to less breakdowns in dialogues (Martinovski and Traum, 2003).", "startOffset": 154, "endOffset": 179}, {"referenceID": 13, "context": ", 2005), and lead to less breakdowns in dialogues (Martinovski and Traum, 2003).", "startOffset": 50, "endOffset": 79}, {"referenceID": 23, "context": "Additionally, dialogue behaviors can be adjusted to the users emotional state (Polzin and Waibel, 2000), and systems can respond to users\u2019 utterances both at the contentand affect-related levels (Skowron, 2010).", "startOffset": 78, "endOffset": 103}, {"referenceID": 34, "context": "Additionally, dialogue behaviors can be adjusted to the users emotional state (Polzin and Waibel, 2000), and systems can respond to users\u2019 utterances both at the contentand affect-related levels (Skowron, 2010).", "startOffset": 195, "endOffset": 210}, {"referenceID": 28, "context": "Recently, thanks to the advance of deep learning, large-scale conversation generation approaches have been investigated (Ritter et al., 2011; Vinyals and Le, 2015; Shang et al., 2015; Serban et al., 2016).", "startOffset": 120, "endOffset": 204}, {"referenceID": 40, "context": "Recently, thanks to the advance of deep learning, large-scale conversation generation approaches have been investigated (Ritter et al., 2011; Vinyals and Le, 2015; Shang et al., 2015; Serban et al., 2016).", "startOffset": 120, "endOffset": 204}, {"referenceID": 32, "context": "Recently, thanks to the advance of deep learning, large-scale conversation generation approaches have been investigated (Ritter et al., 2011; Vinyals and Le, 2015; Shang et al., 2015; Serban et al., 2016).", "startOffset": 120, "endOffset": 204}, {"referenceID": 31, "context": "Recently, thanks to the advance of deep learning, large-scale conversation generation approaches have been investigated (Ritter et al., 2011; Vinyals and Le, 2015; Shang et al., 2015; Serban et al., 2016).", "startOffset": 120, "endOffset": 204}, {"referenceID": 6, "context": "Training on large scale data collected from social media or movie subtitles, most of these works aim to improve the content quality issues of conversation generation systems (Gu et al., 2016; Li et al., 2015; Xing et al., 2016; Mou et al., 2016; Li et al., 2016a).", "startOffset": 174, "endOffset": 263}, {"referenceID": 8, "context": "Training on large scale data collected from social media or movie subtitles, most of these works aim to improve the content quality issues of conversation generation systems (Gu et al., 2016; Li et al., 2015; Xing et al., 2016; Mou et al., 2016; Li et al., 2016a).", "startOffset": 174, "endOffset": 263}, {"referenceID": 42, "context": "Training on large scale data collected from social media or movie subtitles, most of these works aim to improve the content quality issues of conversation generation systems (Gu et al., 2016; Li et al., 2015; Xing et al., 2016; Mou et al., 2016; Li et al., 2016a).", "startOffset": 174, "endOffset": 263}, {"referenceID": 19, "context": "Training on large scale data collected from social media or movie subtitles, most of these works aim to improve the content quality issues of conversation generation systems (Gu et al., 2016; Li et al., 2015; Xing et al., 2016; Mou et al., 2016; Li et al., 2016a).", "startOffset": 174, "endOffset": 263}, {"referenceID": 9, "context": "Training on large scale data collected from social media or movie subtitles, most of these works aim to improve the content quality issues of conversation generation systems (Gu et al., 2016; Li et al., 2015; Xing et al., 2016; Mou et al., 2016; Li et al., 2016a).", "startOffset": 174, "endOffset": 263}, {"referenceID": 1, "context": "Several attempts have been made to endow dialogue systems or conversational agents with emotional intelligence (Andre et al., 2004; Ptaszynski et al., 2009; Skowron, 2010; Skowron et al., 2011).", "startOffset": 111, "endOffset": 193}, {"referenceID": 26, "context": "Several attempts have been made to endow dialogue systems or conversational agents with emotional intelligence (Andre et al., 2004; Ptaszynski et al., 2009; Skowron, 2010; Skowron et al., 2011).", "startOffset": 111, "endOffset": 193}, {"referenceID": 34, "context": "Several attempts have been made to endow dialogue systems or conversational agents with emotional intelligence (Andre et al., 2004; Ptaszynski et al., 2009; Skowron, 2010; Skowron et al., 2011).", "startOffset": 111, "endOffset": 193}, {"referenceID": 35, "context": "Several attempts have been made to endow dialogue systems or conversational agents with emotional intelligence (Andre et al., 2004; Ptaszynski et al., 2009; Skowron, 2010; Skowron et al., 2011).", "startOffset": 111, "endOffset": 193}, {"referenceID": 20, "context": "For example, display of empathic emotional expressions enhanced users performance (Partala and Surakka, 2004), led to an increase in users satisfaction (Prendinger et al.", "startOffset": 82, "endOffset": 109}, {"referenceID": 25, "context": "For example, display of empathic emotional expressions enhanced users performance (Partala and Surakka, 2004), led to an increase in users satisfaction (Prendinger et al., 2005).", "startOffset": 152, "endOffset": 177}, {"referenceID": 24, "context": "Experiments in (Prendinger and Ishizuka, 2005) showed that an empathetic computer agent can contribute to a more positive perception of the interaction.", "startOffset": 15, "endOffset": 46}, {"referenceID": 13, "context": "In (Martinovski and Traum, 2003), the authors showed that many breakdowns could be avoided if the machine was able to recognize the emotional state of the user and responded to it sensitively.", "startOffset": 3, "endOffset": 32}, {"referenceID": 23, "context": "The work in (Polzin and Waibel, 2000) presented how dialogue behaviors can be adjusted to the users emotional state.", "startOffset": 12, "endOffset": 37}, {"referenceID": 1, "context": "Several attempts have been made to endow dialogue systems or conversational agents with emotional intelligence (Andre et al., 2004; Ptaszynski et al., 2009; Skowron, 2010; Skowron et al., 2011). In interactions between humans and artificial agents, the capability to detect signs of human emotions and to suitably react to them can enrich communication. For example, display of empathic emotional expressions enhanced users performance (Partala and Surakka, 2004), led to an increase in users satisfaction (Prendinger et al., 2005). Experiments in (Prendinger and Ishizuka, 2005) showed that an empathetic computer agent can contribute to a more positive perception of the interaction. In (Martinovski and Traum, 2003), the authors showed that many breakdowns could be avoided if the machine was able to recognize the emotional state of the user and responded to it sensitively. The work in (Polzin and Waibel, 2000) presented how dialogue behaviors can be adjusted to the users emotional state. Skowron (2010) proposed conversational systems, called affect listeners, that can respond to users\u2019 utterances both at the content- and affect-related level.", "startOffset": 112, "endOffset": 1011}, {"referenceID": 28, "context": "Thanks to the recent advances of deep learning, data-driven approaches are applied to opendomain conversation systems (Ritter et al., 2011; Shang et al., 2015; Serban et al., 2015).", "startOffset": 118, "endOffset": 180}, {"referenceID": 32, "context": "Thanks to the recent advances of deep learning, data-driven approaches are applied to opendomain conversation systems (Ritter et al., 2011; Shang et al., 2015; Serban et al., 2015).", "startOffset": 118, "endOffset": 180}, {"referenceID": 30, "context": "Thanks to the recent advances of deep learning, data-driven approaches are applied to opendomain conversation systems (Ritter et al., 2011; Shang et al., 2015; Serban et al., 2015).", "startOffset": 118, "endOffset": 180}, {"referenceID": 28, "context": "In (Ritter et al., 2011), statistical machine translation (SMT) was used to generate conversational responses from social media data.", "startOffset": 3, "endOffset": 24}, {"referenceID": 38, "context": "Due to the success of sequence-to-sequence generation models in machine translation (Sutskever et al., 2014; Bahdanau et al., 2014), these models were soon applied to conversation generation (Vinyals and Le, 2015), including the neural responding machine (Shang et al.", "startOffset": 84, "endOffset": 131}, {"referenceID": 2, "context": "Due to the success of sequence-to-sequence generation models in machine translation (Sutskever et al., 2014; Bahdanau et al., 2014), these models were soon applied to conversation generation (Vinyals and Le, 2015), including the neural responding machine (Shang et al.", "startOffset": 84, "endOffset": 131}, {"referenceID": 40, "context": ", 2014), these models were soon applied to conversation generation (Vinyals and Le, 2015), including the neural responding machine (Shang et al.", "startOffset": 67, "endOffset": 89}, {"referenceID": 32, "context": ", 2014), these models were soon applied to conversation generation (Vinyals and Le, 2015), including the neural responding machine (Shang et al., 2015), the hierarchical recurrent encoderdecoder neural network (Serban et al.", "startOffset": 131, "endOffset": 151}, {"referenceID": 30, "context": ", 2015), the hierarchical recurrent encoderdecoder neural network (Serban et al., 2015), and many others (Sordoni et al.", "startOffset": 66, "endOffset": 87}, {"referenceID": 37, "context": ", 2015), and many others (Sordoni et al., 2015).", "startOffset": 25, "endOffset": 47}, {"referenceID": 33, "context": "Beam search was also extensively used to generate meaningful and diversified responses (Li et al., 2015, 2016b; Shao et al., 2017).", "startOffset": 87, "endOffset": 130}, {"referenceID": 42, "context": "Other attempts to improve content quality include incorporating into the decoder additional topic words (Xing et al., 2016; Mou et al., 2016), topic categories (Xiong et al.", "startOffset": 104, "endOffset": 141}, {"referenceID": 19, "context": "Other attempts to improve content quality include incorporating into the decoder additional topic words (Xing et al., 2016; Mou et al., 2016), topic categories (Xiong et al.", "startOffset": 104, "endOffset": 141}, {"referenceID": 43, "context": ", 2016), topic categories (Xiong et al., 2016), persona information (Li et al.", "startOffset": 26, "endOffset": 46}, {"referenceID": 9, "context": ", 2016), persona information (Li et al., 2016a), or other retrieved", "startOffset": 29, "endOffset": 47}, {"referenceID": 8, "context": "To avoid generating meaningless and universal responses such as \u201cI dont know\u201d, Li et al. (2015) proposed the maximum mutual information (MMI) principle as an alternative to maximum likelihood estimation.", "startOffset": 79, "endOffset": 96}, {"referenceID": 36, "context": "responses (Song et al., 2016).", "startOffset": 10, "endOffset": 29}, {"referenceID": 11, "context": "Another path to avoid meaningless response is to apply deep reinforcement learning which can model the long-term delayed reward in chatbot\u2019s dialogues (Li et al., 2016c; Ranzato et al., 2015).", "startOffset": 151, "endOffset": 191}, {"referenceID": 27, "context": "Another path to avoid meaningless response is to apply deep reinforcement learning which can model the long-term delayed reward in chatbot\u2019s dialogues (Li et al., 2016c; Ranzato et al., 2015).", "startOffset": 151, "endOffset": 191}, {"referenceID": 6, "context": "Duplicating low-frequency words from post to response was proposed in (Gu et al., 2016).", "startOffset": 70, "endOffset": 87}, {"referenceID": 41, "context": "Memory Network (Weston et al., 2014) and Neural Turing Machine (NTM) (Graves et al.", "startOffset": 15, "endOffset": 36}, {"referenceID": 5, "context": ", 2014) and Neural Turing Machine (NTM) (Graves et al., 2014) augment traditional RNNs with memory structures to improve the ability of modeling long-range sequences.", "startOffset": 40, "endOffset": 61}, {"referenceID": 16, "context": "Inspired by these models, many other memory networks have been proposed for tasks such as machine translation (Meng et al., 2015), question answering (Miller et al.", "startOffset": 110, "endOffset": 129}, {"referenceID": 18, "context": ", 2015), question answering (Miller et al., 2016) and dialogue state tracking (Perez and Liu, 2016).", "startOffset": 28, "endOffset": 49}, {"referenceID": 21, "context": ", 2016) and dialogue state tracking (Perez and Liu, 2016).", "startOffset": 36, "endOffset": 57}, {"referenceID": 38, "context": "Before presenting the proposed model, we first introduce a general encoder-decoder framework based on sequence-to-sequence (seq2seq) learning (Sutskever et al., 2014), which will be adopted for our work.", "startOffset": 142, "endOffset": 166}, {"referenceID": 38, "context": "The encoder and decoder of the seq2seq model (Sutskever et al., 2014) are implemented with GRU (Cho et al.", "startOffset": 45, "endOffset": 69}, {"referenceID": 3, "context": ", 2014) are implemented with GRU (Cho et al., 2014; Chung et al., 2014).", "startOffset": 33, "endOffset": 71}, {"referenceID": 2, "context": "The context vector ct is designed to dynamically attend on key information of the input post during decoding (Bahdanau et al., 2014).", "startOffset": 109, "endOffset": 132}, {"referenceID": 16, "context": "It is noteworthy that the write vector works as a DELETE operation to model the expression of an emotion in generation of a response, which is quite different from the ADD and DELETE operation used in previous memory networks (Meng et al., 2015; Miller et al., 2016; Perez and Liu, 2016).", "startOffset": 226, "endOffset": 287}, {"referenceID": 18, "context": "It is noteworthy that the write vector works as a DELETE operation to model the expression of an emotion in generation of a response, which is quite different from the ADD and DELETE operation used in previous memory networks (Meng et al., 2015; Miller et al., 2016; Perez and Liu, 2016).", "startOffset": 226, "endOffset": 287}, {"referenceID": 21, "context": "It is noteworthy that the write vector works as a DELETE operation to model the expression of an emotion in generation of a response, which is quite different from the ADD and DELETE operation used in previous memory networks (Meng et al., 2015; Miller et al., 2016; Perez and Liu, 2016).", "startOffset": 226, "endOffset": 287}, {"referenceID": 44, "context": "Thus the model can choose to generate words from a generic vocabulary or an emotion vocabulary (Xu et al., 2008).", "startOffset": 95, "endOffset": 112}, {"referenceID": 32, "context": "\u2022 The STC dataset: a conversation dataset from (Shang et al., 2015), where each post has multiple responses.", "startOffset": 47, "endOffset": 67}, {"referenceID": 17, "context": "To annotate the large-scale STC Dataset with emotion categories, we compare several models for emotion classification, including a dictionary based classifier (denoted by Dict in Table 2), RNN (Mikolov et al., 2010), LSTM (Hochreiter", "startOffset": 193, "endOffset": 215}, {"referenceID": 4, "context": "and Schmidhuber, 1997), and Bidirectional LSTM (Bi-LSTM) (Graves et al., 2005).", "startOffset": 57, "endOffset": 78}, {"referenceID": 0, "context": "We use Tensorflow(Abadi et al., 2016) to implement the proposed model.", "startOffset": 17, "endOffset": 37}, {"referenceID": 12, "context": "As argued in (Liu et al., 2016), BLEU is not suitable for measuring conversation generation.", "startOffset": 13, "endOffset": 31}, {"referenceID": 38, "context": "We compare the seq2seq model (Sutskever et al., 2014) as the baseline with our ECM models.", "startOffset": 29, "endOffset": 53}], "year": 2017, "abstractText": "Emotional intelligence is one of the key factors to the success of dialogue systems or conversational agents. In this paper, we propose Emotional Chatting Machine (ECM) which generates responses that are appropriate not only at the content level (relevant and grammatical) but also at the emotion level (consistent emotional expression). To the best of our knowledge, this is the first work that addresses the emotion factor in large-scale conversation generation. ECM addresses the factor in three ways: modeling high-level abstraction of emotion expression by embedding emotion categories, changing of implicit internal emotion states, and using explicit emotion expressions with an external emotion vocabulary. Experiments show that our model can generate responses appropriate not only in content but also in emotion.", "creator": "LaTeX with hyperref package"}}}