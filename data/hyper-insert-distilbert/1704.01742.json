{"id": "1704.01742", "review": {"conference": "arxiv", "VERSION": "v1", "DATE_OF_SUBMISSION": "6-Apr-2017", "title": "Transferrable Plausibility Model - A Probabilistic Interpretation of Mathematical Theory of Evidence", "abstract": "this 2001 paper suggests introducing a new interpretation of either the dempster - shafer evolution theory manifested in another terms of probabilistic interpretation of innate plausibility. a sweeping new rule of combination of independent morphological evidence classifications is simultaneously shown separately and its preservation of interpretation is continuously demonstrated.", "histories": [["v1", "Thu, 6 Apr 2017 08:08:38 GMT  (14kb)", "http://arxiv.org/abs/1704.01742v1", "Pre-publication version of: M.A. K{\\l}opotek: Transferable Plausibility Model - A Probabilistic Interpretation of Mathematical Theory of Evidence O.Hryniewicz, J. Kacprzyk, J.Koronacki, S.Wierzcho\\'{n}: Issues in Intelligent Systems Paradigms Akademicka Oficyna Wydawnicza EXIT, Warszawa 2005 ISBN 83-87674-90-7, pp.107--118"]], "COMMENTS": "Pre-publication version of: M.A. K{\\l}opotek: Transferable Plausibility Model - A Probabilistic Interpretation of Mathematical Theory of Evidence O.Hryniewicz, J. Kacprzyk, J.Koronacki, S.Wierzcho\\'{n}: Issues in Intelligent Systems Paradigms Akademicka Oficyna Wydawnicza EXIT, Warszawa 2005 ISBN 83-87674-90-7, pp.107--118", "reviews": [], "SUBJECTS": "cs.AI", "authors": ["mieczys{\\l}aw k{\\l}opotek"], "accepted": false, "id": "1704.01742"}, "pdf": {"name": "1704.01742.pdf", "metadata": {"source": "CRF", "title": null, "authors": [], "emails": ["klopotek@ipipan.waw.pl"], "sections": [{"heading": null, "text": "ar X\niv :1\n70 4.\n01 74\n2v 1\n[ cs\n.A I]\n6 A\npr 2"}, {"heading": "1 Introduction", "text": "Dempster Rule of Independent Evidence Combination has been criticized for its failure to conform to probabilistic interpretation ascribed to belief and plausibility function. Among those verifying DST (Dempster-Shafer-Theory, [2,12]) critically were Kyburg [7], Fagin [3], Halpern [6], Pearl [9], Provan [10], Cano [1], just to mention a few.\nAs a way out of those difficulties, we proposed in a recent book co-authored by S.T.Wierzchon [18] three proposals for an empirical model of DST:\n\u2013 \u201dthe marginally correct approximation\u201d. \u2013 \u201dthe qualitative model\u201d \u2013 \u201dthe quantitative model\u201d\nThe marginally correct approximation assumes that the belief function shall constitute lower bounds for frequencies, though only for the marginals, and not for the joint distribution. Then, the reasoning process is expressed in terms of the so-called Cano et al. conditionals - a special class of conditional belief functions that are positive. This approach implies modification of the reasoning mechanism, because the correctness is maintained only by reasoning forward. Depending on the reasoning direction we need different \u201dMarkov trees\u201d for the reasoning engine.\nNote that lower/upper bound interpretations have a long tradition for DST [2,7] and have been heavily criticized [6]. The one that we presented in our\n1 This is a preliminary version of the paper: M.A. Kopotek: Transferable Plausibility Model - A Probabilistic Interpretation of Mathematical Theory of Evidence O.Hryniewicz, J. Kacprzyk, J.Koronacki, S.Wierzcho: Issues in Intelligent Systems Paradigms Akademicka Oficyna Wydawnicza EXIT, Warszawa 2005 ISBN 83-87674-90-7, pp.107\u2013118\nbook differs from the known ones significantly as we insist on different reasoning schemes (hypertrees) depending on which are our target variables, whose values are to be inferred. This assures overcoming of the basic difficulties with lower/upper bound interpretations.\nOur qualitative approach is based on the earlier rough set interpretations of DST, but makes a small and still significant distinction. All computations are carried out in a strictly \u201drelational\u201d way, that is, indistinguishable objects in a database are merged (no object identities). The behavior under reasoning fits strictly the DST reasoning model. Factors of well established hypergraph representation (due to Shafer and Shenoy [14]) can be expressed by relational tables. Conditional independence is well defined. However, there is no interpretation for conditional belief functions in this model.\nRough set interpretations [15] were primarily developed for interpreting the belief function in terms of decision tables. However, the Dempster-rule of evidence combination was valid there only for the \u201dextended decision tables\u201d, not easily derived from the original ones. In our interpretation, both the original tables and the resultant tables dealt with when simulating Dempster-rule are conventional decision tables and the process of combining of decision tables is a natural one (relational join operator).\nOur rough set based interpretation may be directly applied in the domain of multiple decision tables: independence of decision variables or Shenoy\u2019s conditional independence in the sense of DST may serve as an indication of possibility of decomposition of the decision table into smaller but equivalent tables.\nFurthermore, it may be applied in the area of Cooperative Query Answering [11]. The problem there is that a query posed to a local relational database system may contain an unknown attribute. But, possibly, other co-operating database systems know it and may explain it to the queried system in terms of known attributes, shared by the various systems. The uncertainties studied in the decision tables arise here in a natural way and our interpretation may be used to measure these uncertainties in terms of DST (as a diversity of support). Furthermore, if several co-operating systems respond, then the queried system may calculate the overall uncertainty measure using DST combination of measures of individual responses.\nThe quantitative model assumed that the objects possess multivalued properties which are then lost in some physical properties and these physical processes are described by DST belief functions (see e.g. [8])..\nThe quantitative model assumes that during the reasoning process one attaches labels to objects hiding some of their properties. There is a full agreement with the reasoning mechanism of DST. Conditional independence and conditional belief functions are well defined. We have also elaborated processes that can give rise to well-controlled graphoidally structured belief functions. Thus, sample generation for DST is possible. We elaborated also learning procedures for discovery of graphoidal structures from data.\nThe quantitative model seems to be the best fitting model for belief functions created so far.\nThis frequency model differs from what was previously considered [16,17] in that it assumes that reasoning in DST is connected with updating of variables for individual cases. This is different from e.g. reasoning in probability where reasoning means only selection of cases. In this way, failures of previous approaches could be overcome.\nMany authors [13,16] question the need for an empirical model for DST and point rather to theoretical properties of DST considered within an axiomatic framework seeking parallels with the probability theory. Though it is true that the probability theory may be applied within the framework of Kolmogorov axioms and quite useful results are derived in this way, one shall still point out that the applicability of probability theory is significantly connected with frequencies. Both frequencies considered as \u201dnaive probabilities\u201d, ore ones being probabilities \u201din the limit\u201d. Statistics is clearly an important part of the probabilistic world.\nAll three interpretations share a common drawback they are not sensu stricto probabilistic. In the current paper we make an attempt of a purely probabilistic vision of plausibility function."}, {"heading": "2 Basics of the Dempster-Shafer Theory", "text": "We understand DST measures in a standard way (see [12]). Let \u039e be a finite set of elements called elementary events. Any subset of \u039e is a composite event, or hypothesis. \u039e be called also the frame of discernment.\nDefinition 1. [12] Let \u2126 be a finite set of elements called elementary events. The set \u2126 is called frame of discernment. Any subset of \u2126 be a composite event. A basic probability assignment (bpa) function is any function m:2\u2126 \u2192 [0, 1] such that \u2211\nA\u22082\u2126\nm(A) = ONE m(\u2205) = 0, \u2200A\u22082\u2126 0 \u2264 \u2211\nA\u2286B\nm(B)\nWe say that a bpa is vacuous iff m(\u2126) = ONE and m(A) = 0 for every A 6= \u2126.\nIf ONE is equal 1, then we say that the belief function is normalized, otherwise not (but ONE must be positive).\nDefinition 2. [12] Let a belief function be defined as Bel:2\u2126 \u2192 [0, 1] so that Bel(A) = \u2211 B\u2286A m(B). Let a plausibility function be Pl:2 \u2126 \u2192 [0, 1] with \u2200A\u22082\u2126 Pl(A) = ONE \u2212 Bel(\u2126 \u2212 A), a commonality function be Q:2\u2126 \u2212 {\u2205} \u2192 [0, 1] with \u2200A\u22082\u2126\u2212{\u2205} Q(A) = \u2211 A\u2286B m(B).\nDefinition 3. [12] The Rule of Combination of two Independent Belief Functions BelE1 , BelE2 Over the Same Frame of Discernment (the so-called DempsterRule), denoted\nBelE1,E2 = BelE1 \u2295BelE2\nis defined as follows: :\nmE1,E2(A) = c \u00b7 \u2211\nB,C;A=B\u2229C\nmE1(B) \u00b7mE2(C)\n(c - constant normalizing the sum of m to 1).\nUnder multivariate settings \u039e is a set of vectors in n-dimensional space spanned by the set of variables X={ X1, X2, . . .Xn}. If A \u2286 \u039e, then by projection A\u2193Y of the set A onto a subspace spanned by the set of variables Y \u2286 X we understand the set B of vectors from A projected onto Y. Then marginalization operator of DST is defined as follows: m\u2193Y(B) = \u2211 A;B=A\u2193X m(A).\nDefinition 4. (See [?]) Let B be a subset of \u039e, called evidence, mB be a basic probability assignment such that mB(B) = 1 and mB(A) = 0 for any A different from B. Then the conditional belief function Bel(.||B) representing the belief function Bel conditioned on evidence B is defined as: Bel(.||B) = Bel \u2295BelB."}, {"heading": "3 New Rule of Evidence Combination", "text": "Let us suggest now a totally new approach to understanding belief functions.\nWe assume the following interpretation of the plausibility function: Pl\u03be(A) is the maximum probability that an element from the set of events A occurs, given the evidence \u03be, where we assume the apriorical probability of all elementary events is equal. Let \u03be1 and \u03be2 be two independent bodies of evidence, which are represented numerically by plausibility functions Pl\u03be1 and Pl\u03be2 over some frame of discourse \u2126. We would like to obtain such an evidence updating rule \u2295Pl that Pl3 = Pl\u03be1 \u2295Pl Pl\u03be2 would have the semantics that under that interpretation Pl3(A) is the maximum probability that an element from the set of events A occurs, given the evidence Pl1, Pl2 under the least conflicting evidence.\nLet us study in detail this assumption. First of all we have to tell what we mean by independent evidence. Let \u03c9 be an elementary event from the frame of discernment \u2126. The body of evidence \u03be1 is independent of the body \u03be2 if, for each \u03c9 \u2208 \u2126, the probability of occurrence of evidence \u03be1 is independent of the occurrence of evidence \u03be2. So we say that Pr(\u03be1 \u2227 \u03be2|\u03c9) = Pr(\u03be1|\u03c9) \u00b7 Pr(\u03be2|\u03c9).\nHow shall we understand the evidence, however. For any A \u2286 \u2126) should hold Pl\u03be(A) \u2265 Pr(A|\u03be). Consequently, by the way, Pl\u03be(A) + Pl\u03be(\u2126/A) \u2265 1.\nNow observe that Pr(\u03c91 \u2228 \u03c92|\u03be) = Pr(\u03c91|\u03be) + Pr(\u03c92|\u03be). As a consequence, we have always that Pl\u03be({\u03c91}) + Pl\u03be({\u03c92}) \u2265 Pl\u03be({\u03c91, \u03c92}).\nLet us now turn to combining independent evidence.\nPr(\u03c9|\u03be1 \u2227 \u03be2) = Pr(\u03be1 \u2227 \u03be2|\u03c9) \u00b7 Pr(\u03c9)\nPr(\u03be1 \u2227 \u03be2) Pr(\u03be1|\u03c9) \u00b7 Pr(\u03be2|\u03c9) \u00b7\nPr(\u03c9)\nPr(\u03be1 \u2227 \u03be2)\nPr(\u03c9|\u03be1) \u00b7 Pr(\u03c9|\u03be2) \u00b7 Pr(\u03be1) \u00b7 Pr(\u03be2)\nPr(\u03be1 \u2227 \u03be2) \u00b7 Pr(\u03c9)\nSo we can conclude that Pl\u03be1\u2227\u03be2(\u03c9) = Pl\u03be1(\u03c9)\u00b7Pl\u03be2(\u03c9)\u00b7c where c is a normalizing factor (which needs to be chosen carefully).\nBut what about Pr(\u03c91 \u2228 \u03c92|\u03be1 \u2227 \u03be2) ? We know that Pr(\u03c91 \u2228 \u03c92|\u03be1 \u2227 \u03be2) = Pr(\u03c91|\u03be1 \u2227 \u03be2) + Pr(\u03c92|\u03be1 \u2227 \u03be2) hence\nPr(\u03c91 \u2228 \u03c92|\u03be1 \u2227 \u03be2)\nPr(\u03c91|\u03be1)\u00b7Pr(\u03c91|\u03be2)\u00b7 Pr(\u03be1) \u00b7 Pr(\u03be2)\nPr(\u03be1 \u2227 \u03be2) \u00b7 Pr(\u03c91) +Pr(\u03c92|\u03be1)\u00b7Pr(\u03c92|\u03be2)\u00b7\nPr(\u03be1) \u00b7 Pr(\u03be2)\nPr(\u03be1 \u2227 \u03be2) \u00b7 Pr(\u03c92)\nAs Pr(\u03c9) is the same for all the \u03c9s, we get\nPr(\u03c91 \u2228 \u03c92|\u03be1 \u2227 \u03be2)\n(Pr(\u03c91|\u03be1) \u00b7 Pr(\u03c91|\u03be2) + Pr(\u03c92|\u03be1) \u00b7 Pr(\u03c92|\u03be2)) \u00b7 Pr(\u03be1) \u00b7 Pr(\u03be2)\nPr(\u03be1 \u2227 \u03be2) \u00b7 Pr(\u03c9)\nWe can easily check that this translates to:\nPl\u03be1\u2227\u03be2({\u03c91, \u03c92}) =\nmax(Pl\u03be1(\u03c91) \u00b7Pl\u03be2(\u03c91)+(Pl\u03be1({\u03c91, \u03c92}\u2212Pl\u03be1(\u03c91)) \u00b7(Pl\u03be2({\u03c91, \u03c92}\u2212Pl\u03be2(\u03c91))\n, P l\u03be1(\u03c91) \u00b7 (Pl\u03be2({\u03c91, \u03c92} \u2212 Pl\u03be2(\u03c92)) + (Pl\u03be1({\u03c91, \u03c92} \u2212 Pl\u03be1(\u03c91)) \u00b7 Pl\u03be2(\u03c92)\n, P l\u03be1(\u03c92) \u00b7 (Pl\u03be2({\u03c91, \u03c92} \u2212 Pl\u03be2(\u03c91)) + (Pl\u03be1({\u03c91, \u03c92} \u2212 Pl\u03be1(\u03c92)) \u00b7 Pl\u03be2(\u03c91)\n, P l\u03be1(\u03c92) \u00b7Pl\u03be2(\u03c92)+ (Pl\u03be1({\u03c91, \u03c92}\u2212Pl\u03be1(\u03c92)) \u00b7 (Pl\u03be2({\u03c91, \u03c92}\u2212Pl\u03be2(\u03c92))) \u00b7 c\nwhere c is the normalizing factor mentioned earlier. These formulas easily generalize for subsets of \u2126 with higher cardinality. The normalizing factor should be chosen in such a way that Pl\u03be1\u2227\u03be2(\u2126) = 1. The generalization of \u2295Pl for frames of discourse with cardinality higher than 3 runs along the following lines. To combine Pl1 with Pl2 we calculate:\n\u2013 for each subset X of \u2126 Plresult(X) = PL \u2193\u2217X 1 \u2297V Pl2\u2193 \u2217X;\nThe operator \u2193 \u2217X does only a change of the domain of the Pl function keeping the values of Pl for each subset of X and presuming that the discourse frame consists only of X . In this way we get unnormalized Pls here, which are not normalized during this operation.\nThe operator \u2297V , returning a numerical value, attempts identify such combinations of mass assignments ma and mb to singleton sets that will not violate the constraints imposed by plausibility functions Pl1 and Pl2 resp. and such that the sum \u2211 X;Xasingleton ma(X) \u00b7mb(X) is maximal.\nThis is done by the operation of so-called pushing down the plausibilities to singleton sets. Independently for Pl1 and Pl2 candidate ma and mb are obtaining via \u201dpushing-down\u201d recursively a singleton \u03c9 of \u2126. A candidate ma is obtained if all singletons are pushed down. Different candidates are obtained by different sequences of pushing down. It is easy to imagine that the process is time-consuming and its complexity grows exponentially with the number of elements of a set. Nonetheless for small domains the operation is feasible.\nThe idea of the push-down operator \u2193 + is as follows: Let Pl be a plausibility function. If A does not contain \u03c9, Pl\u2193+\u03c9(A) = min(Pl(A), P l(A \u222a {\u03c9}) \u2212 Pl({\u03c9})), and otherwise Pl\u2193+\u03c9(A) = Pl(A).\nUnder these conditions it is obvious that we do not seek actually the maximum product over the whole domain, but rather in some \u201dcorner points\u201d. We will give a formal proof elsewhere that this check is in fact sufficient to establish the maximum. Here we only want to draw attention to the analogy with linear programming, where we seek the maximum subject to linear constraints. Whenever we fix \u201dpushdown\u201d of one of the plausibility distributions, we in fact have a linear optimization case with the other. If found, we can do the same with the other.\nThe \u2295Pl operator is characterized by commutativity and associativity. The commutativity is easily seen because all the operations are in fact symmetrical with respect to left and right hand of the operators. The associativity is more difficult to grasp, and a formal proof will be subject of another publication. Nonetheless we can give here brief common-sense guidelines how it can be established. We can essentially concentrate on the associative properties of the maximum operator. Starting with the expression of combination of all the three plausibility functions, we can show that we can equivalently denote the same optimization task when drawing behind braces the first or the third operand.\nIn the next section we show some properties of the new operator compared with Dempster rule of combination for some illustrative examples."}, {"heading": "4 Examples", "text": "Let us consider the bodies of evidence in the tables 1, 2, 3.\ncompare tables 4 and 6\nWith this and other experiments we see clearly the tendency of Dempster rule to move mass downwards to singleton sets, whereas the new rule is much more cautious here and in fact does not introduce the feeling of certainty where it is not justified."}, {"heading": "5 Conclusions", "text": "We have introduced in this paper a new DST operator for combining independent evidence providing a clear probabilistic definition of the plausibility function, which is preserved under this rule of combination.\nWe have also provided several toy examples to give an impression what results are returned by the new operator.\nThough the strict theoretical proof of properties like cummutativeness, associativeness is still to be provided, the computations for test examples show that the properties really hold. It is also obvious from the examples that the new rule differs from the Dempster rule of evidence combination. An interested reader is invited to visit the Web page http://www.ipipan.waw.pl/\u02dcklopotek/DSTnew/DSTdemo.html to try out himself."}], "references": [{"title": "An axiomatic framework for propagating uncertainty in directed acyclic networks", "author": ["J. Cano", "M. Delgado", "S. Moral"], "venue": "Int. J. of Approximate Reasoning", "citeRegEx": "1", "shortCiteRegEx": "1", "year": 1993}, {"title": "Halpern: Uncertainty, belief, and probability", "author": ["J.Y.R. Fagin"], "venue": "Comput. Intell", "citeRegEx": "5", "shortCiteRegEx": "5", "year": 1991}, {"title": "Two views of belief: belief as generalized probability and belief as evidence.Artificial Intelligence", "author": ["J.Y. Halpern", "R. Fagin"], "venue": null, "citeRegEx": "6", "shortCiteRegEx": "6", "year": 1992}, {"title": "Query processing in distributed information systems, Fundamenta Informaticae Journal, Special Issue on Logics for Artificial Intelligence, IOS Press, Vol", "author": ["Z.W. Ras"], "venue": "XV, No", "citeRegEx": "11", "shortCiteRegEx": "11", "year": 1991}, {"title": "Ph.Smets, R.Kennes: The tranferable belief model", "author": ["Smets", "Kenne"], "venue": "Artificial Intelligence", "citeRegEx": "17", "shortCiteRegEx": "17", "year": 1994}], "referenceMentions": [{"referenceID": 2, "context": "Among those verifying DST (Dempster-Shafer-Theory, [2,12]) critically were Kyburg [7], Fagin [3], Halpern [6], Pearl [9], Provan [10], Cano [1], just to mention a few.", "startOffset": 106, "endOffset": 109}, {"referenceID": 0, "context": "Among those verifying DST (Dempster-Shafer-Theory, [2,12]) critically were Kyburg [7], Fagin [3], Halpern [6], Pearl [9], Provan [10], Cano [1], just to mention a few.", "startOffset": 140, "endOffset": 143}, {"referenceID": 2, "context": "Note that lower/upper bound interpretations have a long tradition for DST [2,7] and have been heavily criticized [6].", "startOffset": 113, "endOffset": 116}, {"referenceID": 3, "context": "Furthermore, it may be applied in the area of Cooperative Query Answering [11].", "startOffset": 74, "endOffset": 78}, {"referenceID": 4, "context": "This frequency model differs from what was previously considered [16,17] in that it assumes that reasoning in DST is connected with updating of variables for individual cases.", "startOffset": 65, "endOffset": 72}, {"referenceID": 0, "context": "A basic probability assignment (bpa) function is any function m:2 \u2192 [0, 1] such that \u2211", "startOffset": 68, "endOffset": 74}, {"referenceID": 0, "context": "[12] Let a belief function be defined as Bel:2 \u2192 [0, 1] so that Bel(A) = \u2211 B\u2286A m(B).", "startOffset": 49, "endOffset": 55}, {"referenceID": 0, "context": "Let a plausibility function be Pl:2 \u03a9 \u2192 [0, 1] with \u2200A\u22082\u03a9 Pl(A) = ONE \u2212 Bel(\u03a9 \u2212 A), a commonality function be Q:2 \u2212 {\u2205} \u2192 [0, 1] with \u2200A\u22082\u03a9\u2212{\u2205} Q(A) = \u2211 A\u2286B m(B).", "startOffset": 40, "endOffset": 46}, {"referenceID": 0, "context": "Let a plausibility function be Pl:2 \u03a9 \u2192 [0, 1] with \u2200A\u22082\u03a9 Pl(A) = ONE \u2212 Bel(\u03a9 \u2212 A), a commonality function be Q:2 \u2212 {\u2205} \u2192 [0, 1] with \u2200A\u22082\u03a9\u2212{\u2205} Q(A) = \u2211 A\u2286B m(B).", "startOffset": 122, "endOffset": 128}], "year": 2017, "abstractText": "This paper suggests a new interpretation of the DempsterShafer theory in terms of probabilistic interpretation of plausibility. A new rule of combination of independent evidence is shown and its preservation of interpretation is demonstrated. 1", "creator": "LaTeX with hyperref package"}}}