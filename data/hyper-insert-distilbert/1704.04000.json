{"id": "1704.04000", "review": {"conference": "arxiv", "VERSION": "v1", "DATE_OF_SUBMISSION": "13-Apr-2017", "title": "Dempster-Shafer Belief Function - A New Interpretation", "abstract": "we develop our simple interpretation of whether the joint belief distribution and of evidential updating assumptions that matches achieve the following of basic testing requirements :", "histories": [["v1", "Thu, 13 Apr 2017 06:00:00 GMT  (35kb)", "http://arxiv.org/abs/1704.04000v1", "70 pages, an internat intermediate research report, dating back to 1993"]], "COMMENTS": "70 pages, an internat intermediate research report, dating back to 1993", "reviews": [], "SUBJECTS": "cs.AI", "authors": ["mieczys{\\l}aw k{\\l}opotek"], "accepted": false, "id": "1704.04000"}, "pdf": {"name": "1704.04000.pdf", "metadata": {"source": "CRF", "title": "Dempster-Shafer Belief Function - A New Interpretation", "authors": ["Mieczyslaw A. Klopotek"], "emails": ["klopotek@ipipan.waw.pl"], "sections": [{"heading": null, "text": "ar X\niv :1\n70 4.\n04 00\n0v 1\n[ cs\n.A I]\n1 3\nA pr\n2 01\n7\nDempster-Shafer Belief\nFunction - A New\nInterpretation\nMieczyslaw A. Klopotek\nInstitute of Computer Science, Polish Academy of Sciences\nPL 01-237 Warsaw, 21 Ordona St., e-mail: klopotek@ipipan.waw.pl"}, {"heading": "1 Introduction", "text": "Dempster-Shafer theory of evidence has been found by many researchers very attractive as a way of modeling reasoning behaviour under uncertainty stemming from ignorance. It provides a framework for representation of certainty of a logical formula without necessity of expressing commitment to any of its consequences. E.g. we can express our 100 % belief in fact that Tweedy\u2019s wife is either Mary or Jane and at the same time express our total ignorance to the fact who of them is actually his wife (zero belief attached to the statement \u201dMary is Tweedy\u2019s wife\u201d and zero belief in \u201dJane is Tweedy\u2019s\nwife\u201d).\nIf a theory is to become of practical importance in expert systems application - as foundation for knowledge representation and reasoning, ar least the following conditions must be fulfilled:\n\u2022 there must exist an efficient method for reasoning within this framework\n\u2022 there must exist a clear correspondence between the contents of the\nknowledge base and the real world\n\u2022 there must be a clear correspondence between the reasoning method\nand some real world process\n\u2022 there must exist a clear correspondence between the results of the rea-\nsoning process and the results of the real world process corresponding to the reasoning process.\nOnly under such circumstances we can say that the expert system is helpful as it allows us either to predict or to follow retrospectively real world processes.\nDempster initiated the theory of evidence in his paper [4] and other works, and Shafer developed this theory in his book [21] and other publications. Though it became obvious that the DST (Dempster-Shafer Theory) captures many intuitions behind the human dealing with uncertainty (e.g. as mentioned above), it did not become a foundation for implementation of expert systems with uncertainty due to claimed high computational complexity [9].\nIn the recent years, however, a number of efficient methods for dealing with DS reasoning have been developed - see e.g. [23] and citations therein. So the first of the above mentioned conditions is met. Meeting of other conditions proved to be more complicated.\nSmets [26] and also initially Shafer [21] insisted on Bels (measures of uncertainty in the DST) not being connected to any empirical measure (frequency, probability etc.) considering the domain of DST applications as the one where \u201dwe are ignorant of the existence of probabilities\u201d, and warn that the DST is \u201dnot a model for poorly known probabilities\u201d ([26], p.324). The question may be raised, however, what practically useful can be obtained from a computer reasoning on the basis of such a DST. It would have to be demonstrated that humans indeed reason as DST. Then the computer, if fed with our knowledge, would be capable to predict our conclusions on a given subject. However, to my knowledge, no experiment confirming that humans actually use internally DST for reasoning under uncertainty has been carried out. Under these circumstances the computer reasoning with DST would tell us what we have to think and not what we think. Hence, from the point of view of computer implementation the position of Smets and Shafer is not acceptable.\nThe other category of DST interpretations, described by Smets as approaches assuming existence of an underlying probability distribution, which is only approximated by the Bels (called by him PXMY models), is represented by early works of Dempster [4], papers of Kyburg [12], Fagin [7],\n[8],, Halpern [10], Skowron [24], Grzyma la-Busse [9] and others. Both Smets [26] and Shafer [22] consider such approaches as inadequate as most of them give rise to contradictions and counter intuitiveness. As Smets states, \u201dFar too often, authors concentrate on the static component (how beliefs are allocated?) and discover many relations between TBM (transferable belief model of Smets) and ULP (upper lower probability) models, inner and outer measures (Fagin and Halpern [6]), random sets (Nguyen [16]), probabilities of provability (Pearl [17]), probabilities of necessity (Ruspini [19]) etc. But these authors usually do not explain or justify the dynamic component (how are beliefs updated?), that is, how updating (conditioning) is to be handled (except in some cases by defining conditioning as a special case of combination). So I (that is Smets) feel that these partial comparisons are incomplete, especially as all these interpretations lead to different updating rules.\u201d ([26], pp. 324-325). Smets attributes this failure to the very nature of attempts of assigning a probabilistic interpretation. We disagree with Smets and will show in this paper that creation of a probabilistic interpretation of the DST incorporating the Dempster rule of combination is actually possible. However, this new interpretation indicates the need for a drastic change in viewing the Dempster rule: it does not accommodate evidence, but prejudices. How this statement is to be understood, will be visible later. Nonetheless our interpretation allows for assignment of an experimentally verifiable numerical meaning to a DS knowledge base, assigns a numerical meaning to the reasoning process (the DS rule of combination) and yields agreement between\nnumerical empirical interpretation of the results of DS reasoning and results of a real world process. This means that we have an interpretation fitting formal interpretation of the DS theory to the largest extent ever achieved.\nSmets ([26],p.327) subdivided the DST into two categories: a closed world category (as if excluding the possibility of contradictions in the \u201devidence\u201d) and an open world category of DST (as if allowing for this). Let us assume that two independent experts elicited their beliefs concerning the event A: both assigned beliefs of 0.7 to the event A, and beliefs of 0.3 to the event \u00acA. The open world DST will lead us to a combined belief in A of 0.5 and in \u00acA of 0.1. The closed world assumption on the other hand will assign a combined belief in A of 0.7 and in \u00acA of 0.3. I find it a dismaying property of a theory if collecting agreeing information from independent expert shall decline my belief in the opinions of both experts. Hence only closed world theories are subject of this paper.\nWe first recall the formal definition of the DS-Theory, then introduce some notation used throughout the rest of the paper. Subsequently we develop our interpretation of the joint belief distribution and of evidential updating. We conclude with a brief comparison of our interpretation with other attempts."}, {"heading": "2 Formal Definition of the Dempster-Shafer", "text": "Theory of Evidence\nLet us make the remark that if an object is described by a set of discrete attributes X1, X2, ..., Xn taking values from their respective domains \u039e1,\u039e2, ...,\u039en then we can think of it as being described by a complex attribute X having vector values, that is the domain \u039e of X is equal:\n\u039e = {(x1, x2, ..., xn)|xi \u2208 \u039ei, i = 1, ..., n}\n.\nSo unless specified otherwise let us assume that we are talking of objects described by a single attribute X taking its values from the domain \u039e. We say that \u039e, the domain of X is our space of discourse spanned by the attribute X. We shall also briefly say that X is our space of discourse instead.\nFor the purpose of this paper we define the Bel-function as follows (com-\npare also [10], [26], [22]):\nDefinition 1 The Belief Function in the sense of the DS-Theory is defined as Bel:2\u039e \u2192 [0, 1] with \u039e = \u039e1 \u00d7 Xi2 \u00d7 ... \u00d7 \u039en being the space spanned by the attribute X = X1 \u00d7X2 \u00d7 . . .\u00d7Xn with\n\u2200A;A\u2286\u039e Bel(A) = \u2211\nB\u2286A\nm(B)\nwhere m(A) is a Mass Function in the sense of the DS-Theory (see Def.2 below).\nThe function m is defined as\nDefinition 2 The Mass Function in the sense of the DS-Theory is defined as m:2\u039e \u2192 [0, 1] with\nm(\u2205) = 0\n\u2211\nA\u22082\u039e\nm(A) = 1\n\u2200A\u22082\u039e m(A) \u2265 0\n.\nDefinition 3 Whenever m(A) > 0, we say that A is the focal point of the Bel-Function.\nLet us also introduce the Pl-Function (Plausibility) as:\nDefinition 4 The Plausibility Function in the sense of the DS-Theory is defined as\n\u2200A;A\u2286\u039e P l(A) = 1\u2212 Bel(\u039e\u2212A)\nBeside the above definition a characteristic feature of the DS-Theory is\nthe so-called DS-rule of combination of independent evidence:\nDefinition 5 Let BelE1 and BelE2 represent independent information over the same space of discourse. Then:\nBelE1,E2 = BelE1 \u2295 BelE2\ndefined as:\nmE1,E2(A) = c \u00b7 \u2211\nB,C;A=B\u2229C\nmE1(B) \u00b7mE2(C)\n(c - normalizing constant) represents the Combined Belief-Function of Two Independent Beliefs"}, {"heading": "3 Denotation", "text": "F. Bacchus in his paper [2] on axiomatization of probability theory and first order logic shows that probability should be considered as a quantifier binding free variables in first order logic expressions just like universal and existential quantifiers do. So if e.g. \u03b1(x) is an open expression with a free variable x then [\u03b1(x)]x means the probability of truth of the expression \u03b1(x). (The quantifier []x binds the free variable x and yields a numerical value ranging from 0 to 1 and meeting all the Kolmogoroff axioms). Within the expression [\u03b1(x)]x the variable x is bound. See [2] on justification why other types of integration of probability theory and first order logic or propositional logic fail. Also for justification of rejection of the traditional view of probability as a function over sets. While sharing Bacchus\u2019 view, we find his notation a bit cumbersome so we change it to be similar to the universal and existential quantifiers throughout this paper. Furthermore, Morgan [14] insisted that the probabilities be always considered in close connection with the population they refer to. Bacchus\u2019 expression [\u03b1(x)]x we rewrite as: Prob P (x)\nx \u03b1(x) - the probability of \u03b1(x)] being true within the population\nP. The P (population) is a unary predicate with P(x)=TRUE indicating that the object x(\u2208 \u2126, that is element of a universe of objects) belongs to the population under considerations. If P and P\u2019 are populations such that \u2200xP \u2032(x) \u2192 P (x) (that is membership in P\u2019 implies membership in P, or in other words: P\u2019 is a subpopulation of P), then we distinguish two cases: case 1: (Prob P (x)\nx P \u2032(x)) = 0 (that is probability of membership in P\u2019 with\nrespect to P is equal 0) - then (according to [14] for any expression \u03b1(x) in free variable x the following holds for the population P\u2019: (Prob P \u2032(x)\nx \u03b1(x)) = 1\ncase 2: (Prob P (x)\nx P \u2032(x)) > 0then (according to [14] for any expression \u03b1(x)\nin free variable x the following holds for the population P\u2019:\n( ProbP \u2032(x)\nx\n\u03b1(x)) = Prob\nP (x)\nx (\u03b1(x) \u2227 P \u2032(x))\nProb P (x)\nx P \u2032(x)\nWe also use the following (now traditional) mathematical symbols: \u2200x\u03b1(x) - always \u03b1(x) (universal quantifier) \u2203x\u03b1(x) - there exists an x such that \u03b1(x) (existential quantifier)\n\u03b1 \u2227 \u03b2 - logical AND of expressions \u2227\nB \u03b1(B) - logical AND over all instantiations of\nthe expression \u03b1(B) in free variable B\n\u03b1 \u2228 \u03b2 - logical OR of expressions \u2228\nB \u03b1(B) - logical OR over all instantiations of\nthe expression \u03b1(B) in free variable B\n\u00ac - logical negation P \u2229Q - intersection of two sets P \u222aQ - union of two sets"}, {"heading": "4 A New Interpretation of Belief Functions", "text": "The empirical meaning of a new interpretation of the DS Belief function will be explained by means of the following example:\nExample 1 Let us consider a daily-life example. Buying a bottle of hair shampoo is not a trivial task from both the side of the consumer and the manufacturer. If the consumer arrives at the consciousness that the shampoos may fall into one of the four categories: high quality products (excellent for maintaining cleanness and health of the consumer) (H), moderate quality products (keeping just all Polish industry standards) (M), suspicious products (violating some industry standards) (S) and products dangerous for health and life (containing bacteria or fungi or other microbes causing infectious or invasive diseases, containing cancerogenous or poisonous substances\netc.) (D), he has a hard time upon leaving his house for shopping. Clearly, precise chemical, biochemical and medical tests exist which may precisely place the product into one of those obviously exclusive categories. But the Citizen1 Coot2 usually neither has a private chemical laboratory nor enough money to make use of required services. Hence Citizen Coot coins a personal set of \u201dquality\u201d tests M1 mapping the pair (bottle of shampoo, quality) into the set {TRUE, FALSE} (the letter O - object - stands for bottle of shampoo, H, M, S, D indicate quality classes: high, moderate, suspicious, dangerous):\n1. If the shampoo is heavily advertised on TV then it is of high quality\n(M1(O, {H}) = TRUE) and otherwise not (M1(O, {H}) = FALSE).\n2. If the name of the shampoo was never heard on TV, but the bottle looks\nfine (pretty colours, aesthetic shape of the bottle), then the shampoo must be of moderate quality (M1(O, {M}) = TRUE) and otherwise not (M1(O, {M}) = FALSE).\n3. If the packaging is not fine or the date of production is not readable\non the bottle or the product is out of date, but the shampoo smells acceptably otherwise then it is suspicious (M1(O, {S}) = TRUE) and otherwise not (M1(O, {S}) = FALSE).\n1The term \u201dCitizen\u201d was a fine socialist time descriptor allowing to avoid the cumber-\nsome usage of words like \u201dMr.\u201d, \u201dMrs.\u201d and \u201dMiss\u201d\n2This family name was coined as abbreviation for \u201dCitizen Of Our Town\u201d\n4. If either the packaging is not fine or the date of production is not\nreadable on the bottle or the product is out of date, and at the same time the shampoo smells awfully, then it is dangerous (M1(O, {D}) = TRUE and otherwise not (M1(O, {D}) = FALSE).\nNotice that the criteria are partially rational: a not fine looking bottle may in fact indicate some decaying processing of the shampoo or at least that the product remains for a longer time on the shelf already. Bad smell is usually caused by development of some bacteria dangerous for human health.Notice also that test for high and moderate quality are enthusiastic, while the other two are more cautious.\nNotice that the two latter tests are more difficult to carry out in a shop than the leading two (the shop assistant would hardly allow to open a bottle before buying). Also, there may be no time to check whether the shampoo was actually advertised on TV or not (as the son who carefully watches all the running advertisements stayed home and does his lessons). Hence some simplified tests may be quite helpful:\n\u2022 M1(O, {S,D}): If the packaging is not fine or the product is out of\ndate or the production date is not readable then the product is either suspicious or dangerous (M1(O, {S,D}) = TRUE and otherwise not (M1(O, {D,S}) = FALSE). .\n\u2022 M1(O, {H,M}): If the packaging looks fine, then the product is either\nof high or moderate quality (M1(O, {M,H}) = TRUE and otherwise\nnot (M1(O, {M,H}) = FALSE)..\nClearly these tests are far from being precise ones, but for the Citizen Coot no better tests will be ever available. What is more, they are not exclusive: if one visits a dubious shop at a later hour, one may buy a product meeting both M1(O, {H}) and M1(O, {D}) as defined above !\nLet us assume we have two types of shops in our town: good ones (G) and bad ones (B). (Let M2 : \u2126 \u00d7 2{G,B} \u2192 {TRUE, FALSE} indicate for each shampoo in which shop type it was available. Further, let M3 : \u2126 \u00d7 2{H,M,S,D}\u00d7{G,B} \u2192 {TRUE, FALSE} indicate for each shampoo both its quality and the type of shop it was available from. Let clearly M1(O,Quality) \u2227M2(O, Shop) = M3(O,Quality \u00d7 Shop). The good shops are those with new furniture, well-clothed shop assistants. Bad ones are those with always dirty floor or old furniture, or badly clothed shop assistants. Clearly, again, both shop categories may be considered (nearly) exclusive as seldom well clothed shop assistants do not care of floors. Let us assume we have obtained the statistics of shampoo sales in our town presented in Table 1:\nRows and columns are marked with those singleton tests which were passed (e.g. in the left upper corner there are 20 shampoo bottles sold in an undoubtedly bad shop and having exclusively high quality, that is for all those bottles (O) M1(O, {H}) = TRUE, M1(O, {M}) = FALSE, M1(O, {S}) = FALSE,M1(O, {D}) = FALSE, andM2(O, {B}) = TRUE,M2(O, {G}) =\nFALSE.) The measurement ofM1(O, {H})would yield TRUE for 190+39+13 =242 bottles and FALSE for the remaining 581 bottles, the measurement of M1(O, {D}) would yield TRUE for 14+13+32=59 bottles, and FALSE for the remaining 664 bottles. The measurement M1(O, {S,D}) will turn true in 70+14+ 39+75+ 13+12 =343 cases and FALSE in the remaining 480 cases.\u2738\nIn general let us assume that we know that objects of a population can be described by an intrinsic attribute X taking exclusively one of the n discrete values from its domain \u039e = {v1, v2, ..., vn} . Let us assume furthermore that to obtain knowledge of the actual value taken by an object we must apply a measurement method (a system of tests) M\nDefinition 6 X be a set-valued attribute taking as its values non-empty subsets of a finite domain \u039e. By a measurement method of value of the attribute X we understand a function:\nM : \u2126\u00d7 2\u039e \u2192 {TRUE, FALSE}\n. where \u2126 is the set of objects, (or population of objects) such that\n\u2022 \u2200\u03c9;\u03c9\u2208\u2126 M(\u03c9,\u039e) = TRUE (X takes at least one of values from \u039e)\n\u2022 \u2200\u03c9;\u03c9\u2208\u2126 M(\u03c9, \u2205) = FALSE\n\u2022 whenever M(\u03c9,A) = TRUE for \u03c9 \u2208 \u2126, A \u2286 \u039e then for any B such\nthat A \u2282 B M(\u03c9,B) = TRUE holds,\n\u2022 whenever M(\u03c9,A) = TRUE for \u03c9 \u2208 \u2126, A \u2286 \u039e and if card(A) > 1\nthen there exists B, B \u2282 A such that M(\u03c9,B) = TRUE holds.\n\u2022 for every \u03c9 and every A either M(\u03c9,A) = TRUE or M(\u03c9,A) =\nFALSE (but never both).\nM(\u03c9,A) tells us whether or not any of the elements of the set A belong to the actual value of the attribute X for the object \u03c9.\nThe measuring function M(O,A), if it takes the value TRUE, states for an object O and a set A of values from the domain of X that the X takes for this object (at least) one of the values in A.\nIt makes sense to talk of such measuring function assigning truth values to sets of values of an attribute if it is possibly cheaper to measure M(O,A) than to measure M(O,B) whenever B \u2282 A and we are interested in avoiding measuring M(O,B) whenever possible, that is whenever measuring M(O,A) suffices. For example, measuring pH-value with a pH-meter may turn out to be more expensive than one with litmus paper, at the advantage of a higher precision.\nThe above definition assumes that this measurement method is superset-\nand subset-consistent that is: Whenever M(object, A) = TRUE then\n\u2200B;A\u2282B M(object, B) = TRUE\nholds, and if card(A) > 1 then\n\u2203B;B\u2282A M(object, B) = TRUE\nholds. The superset consistency means that if a test for larger set of values indicates FALSE then it is not necessary to test its subsets as they will not contribute to our knowledge of the value of X (cost savings). The subset consistency means that if the M-test for a given value set gives true than in end effect at least of its singleton subsets would yield TRUE for the respective M-test. It is clearly the matter of convention: we assume that we can always provide the answer YES or NO, and whenever we are in doubt we still answer YES.\nSuch a convention is not an unusual one: in various legal systems \u201danything, that is not forbidden by law, is permitted\u201d; in the default logics if a default statement cannot be proven wrong, it is assumed correct.\nIn any case, this means that from the universe of all possible objects, a concrete measurement method selects a population for which its assumptions are satisfied. E.g. if we have a measurement method for measuring pH-values, we surely consider an aqueous sodium solution as a member of our universal population, but never a car as such (because then pH-value has no meaning at all)..\nFurthermore us consider this measurement method a stable one that is whenever the same object is presented, the results are the same. However, let us assume that the measurement method is not completely reliable: it measures only quantities related to the quantity X and not X itself. So it is conceivable that e.g. M(object, {v1}) = TRUE and at the same time M(object, {v2}) = TRUE though both values of X are deemed to be exclu-\nsive. For practical reasons however it may not bother us at all as either the true value of X may not be accessible at all (e.g. the true event of killing or not killing a person by the suspect belongs to the past and can never be recalled as such), may be too expensive to access (e.g. if the most reliable method of checking whether a match can inflame or not it to inflame it, but thereafter it would be useless, so we check only for its color, dryness etc.) or it may be prohibitive to access it for other reasons, e.g. social (sex may be treated with extremely high precision as an exclusive attribute taking values male,female, but we would reluctantly check the primary features before deciding to call someone Mr, Miss or Mrs). Beside this it may prove too expensive to check all the elementary hypotheses (e.g. in the medical diagnosis) so that after stating M(object, {v1}) = TRUE we do not bother of other alternatives, that is of the degree of imprecision of the relationship between the measured quantities and the real values of X. We assume that the approximations of X achieved by the measurement method are in most cases sufficient for our decision making (whatever its nature), so we do not insist on closer knowledge of X itself.\nSo though we wish X to take singleton values only, we actually live with\nthe fact that for our practical purposes X is possibly set-valued.\nLet us make at this point some remarks on practical relevance.\nExample 2 If we are making statistical tests on equality or non-equality of two quantities (means, variances, distributions), we can purely logically say\nthat the quantities are either equal or not equal but never both. However, the available indirect measurement method (by sampling) may lead to a statement that there is neither evidence to reject equality nor to reject nonequality. So we say that in those cases both equity and inequity holds. We still enjoy statistical inference because in sufficiently many other cases statistics provides us with more precise results.\u2738\nExample 3 Similarly if we consider components of a chemical substance, the measurement methods for absence and presence of a component may be different from one another depending whether or not we should be more sensitive to its presence or absence and hence in some cases applying both may lead to apparently contradicting results. \u2738\nLet us furthermore assume that with each application of the measurement procedure some costs are connected, increasing roughly with the decreasing size of the tested set A so that we are ready to accept results of previous measurements in the form of pre-labeling of the population. So\nDefinition 7 A label L of an object \u03c9 \u2208 \u2126 is a subset of the domain \u039e of the attribute X. A labeling under the measurement method M is a function l : \u2126 \u2192 2\u039e such that for any object \u03c9 \u2208 \u2126 either l(\u03c9) = \u2205 or M(\u03c9, l(\u03c9)) = TRUE. Each labelled object (under the labeling l) consists of a pair (Oj, Lj), Oj - the jth object, Lj = l(Oj) - its label. By a population under the labeling l we understand the predicate P : \u2126 \u2192\n{TRUE, FALSE} of the form P (\u03c9) = TRUE iff l(\u03c9) 6= \u2205 (or alternatively, the set of objects for which this predicate is true) If for every object of the population the label is equal to \u039e then we talk of an unlabeled population (under the labeling l), otherwise of a pre-labelled one.\nLet us assume that in practice we apply a modified measurement method\nMl being a function:\nDefinition 8 Let l be a labeling under the measurement method M . Let us consider the population under this labeling. The modified measurement method\nMl : \u2126\u00d7 2 \u039e \u2192 {TRUE, FALSE}\nwhere \u2126 is the set of objects, is is defined as\nMl(\u03c9,A) = M(\u03c9,A \u2229 l(\u03c9))\n(Notice that Ml(\u03c9,A) = FALSE whenever A \u2229 l(\u03c9) = \u2205.)\nFor a labeled object (Oj, Lj) (Oj - proper object, Lj - its label) and a set A of values from the domain of X, the modified measurement method tells us that X takes one of the values in A if and only if it takes in fact a value from intersection of A and Lj . Expressed differently, we discard a priori any attribute not in the label.\nPlease pay attention also to the fact, that given a population P for which the measurement method M is defined, the labeling l (according to its definition) selects a subset of this population, possibly a proper subset, namely\nthe population P\u2019 under this labeling. P \u2032(\u03c9) = P (\u03c9) \u2227 M(\u03c9, l(\u03c9)). Hence also Ml is defined possibly for the \u201dsmaller\u201d population P\u2019 than M is.\nExample 4 In practice, we frequently have to do with pre-labelled population. The statistics of illnesses based on poly-clinical data are based on a population pre-labelled by financial status (whether or not they are ready to visit a physician with less serious disease due to economical background), educational background (whether or not they estimate properly the seriousness of the disease, whether or not they care of symptoms) etc. Similarly in chemical analysis knowledge of substrates pre-labels the tests on composition of the product (not relevant measurements are a priori discarded) etc. \u2738\nExample 5 To continue Citizen Coot example, we may believe that in good shops only moderate and high quality products are available, that is we assign to every shampoo \u03c9 the label l(\u03c9) = \u2205 (we discard it from our register) if \u03c9 denies our belief that there are no suspicious nor dangerous products in a good shop, and l(\u03c9) = {H,M} if it is moderate or high quality product in a good shop and l(\u03c9) = \u039e to all the other products. After this rejection of shampoos not fitting our beliefs we have to do with (a bit smaller) soldshampoos-population from Table 5 :\nPlease notice the following changes: Suspicious and dangerous products encountered in good shops were totally dropped from the statistics (their\nexistence was not revealed to the public). Suspicious and dangerous products from shops with unclear classification (good/bad shops) were declared to come from bad shops. Products from good shops which obtained both the label high quality and dangerous were simply moved into the category high quality products (the bad smelt was just concealed) etc. This is frequently the sense in which our beliefs have impact on our attitude towards real facts and we will see below that the Dempster-Shafer Theory reflects such a view of beliefs. \u2738\nLet us now define the following function:\nDefinition 9\nBelMP (A) = ProbP (O)\nO\n(\u00acM(O,\u039e\u2212 A))\nwhich is the probability that the test M, while being true for A, rejects every hypothesis of the form X=vi for every vi not in A for the population P. We shall call this function \u201dthe belief exactly in the the result of measurement\u201d.\nLet us define also the function:\nDefinition 10\nP lMP (A) = ProbP (O)\nO\n(M(O,A))\nwhich is the probability of the test M holding for A for the population P. Let us refer to this function as the \u201dPlausibility of taking any value from the set A\u201d.\nLast not least be defined the function:\nDefinition 11\nmMP (A) = ProbP (O)\nO\n( \u2227\nB;B={vi}\u2286A\nM(O,B) \u2227 \u2227\nB;B={vi}\u2286\u039e\u2212A\n\u00acM(O,B))\nwhich is the probability that all the tests for the singleton subsets of A are true and those outside of A are false for the population P.\nLet us illustrate the above concepts with Citizen Coot example:\nExample 6 For the belief function for sold-bottles-population and the measurement function M3, if we identify probability with relative frequency, we have the focal points given in the Table 4:\u2738\nIt is easily seen that:\nTHEOREM 1 mMP is the mass Function in the sense of DS-Theory.\nPROOF: We shall recall the definition and construction of the DNF (Dis-\njunctive Normal Form). If, given an object O of a population P under the measurement method M, we look at the expression\nexpr(A) = \u2227\nB;B={vi}\u2286A\nM(O,B) \u2227 \u2227\nB;B={vi}\u2286\u039e\u2212A\n\u00acM(O,B)\nfor two different sets A1, A2 \u2286 \u039e then clearly expr(A1) \u2227 expr(A2) is never true - the truth of the one excludes the truth of the other.\nThey represent mutually exclusive events in the sense of the probability theory. On the other hand:\n\u2228\nA;A\u2286\u039e\nexpr(A) = TRUE\nhence:\n( ProbP (O)\nO\n( \u2228\nA;A\u2286\u039e\nexpr(A))) = ( ProbP (O)\nO\nTRUE) = 1\nand due to mutual exclusiveness:\n\u2211\nA;A\u2286\u039e\n( ProbP (O)\nO\nexpr(A)) = 1\nwhich means:\n\u2211\nA;A\u2286\u039e\nmMP (A) = 1\nHence the first condition of Def.2 is satisfied.Due to the second condition of Def.6 we have\n( ProbP (O)\nO\nexpr(\u2205)) = 1\u2212 ( ProbP (O)\nO\n(M(O,\u039e))) =\n= 1\u2212 ( ProbP (O)\nO\nTRUE) = 1\u2212 1 = 0\nHence\nmMP (\u2205) = 0\n.The last condition is satisfied due to the very nature of probability: Probability is never negative. So we can state that mMP is really a Mass Function in the sense of the DS-Theory. Q.e.d.\u2737\nTHEOREM 2 BelMP is a Belief Function in the sense of DS-Theory corresponding to the mMP .\nPROOF: Let A be a non-empty set. By definition\nM(O,\u039e\u2212A) = \u2228\nC={vi}\u2286\u039e\u2212A\nM(O,C)\nhence by de-Morgan-law:\n\u00acM(O,\u039e\u2212A) = \u2227\nC={vi}\u2286\u039e\u2212A\n\u00acM(O,C)\nOn the other hand, \u00acM(O,\u039e\u2212A) implies M(O,A). But :\nM(O,A) = \u2228\nB\u2286A\n \n\u2227\nC;C={vi}\u2286B\nM(O,C) \u2227 \u2227\nC;C={vi}\u2286A\u2212B\n\u00acM(O,C)\n \nSo .\n\u00acM(O,\u039e\u2212 A) = \u00acM(O,\u039e\u2212A) \u2227M(O,A) =\n= \u2227\nC;C={vi}\u2286\u039e\u2212A\n\u00acM(O,C) \u2227M(O,A) =\n= \u2227\nC;C={vi}\u2286\u039e\u2212A\n\u00acM(O,C) \u2227\n  \u2228\nB\u2286A\n \n\u2227\nC;C={vi}\u2286B\nM(O,C)\u2227\n\u2227 \u2227\nC;C={vi}\u2286A\u2212B\n\u00acM(O,C)\n  \n =\n= \u2228\nB\u2286A\n \n\u2227\nC;C={vi}\u2286B\nM(O,C) \u2227 \u2227\nC;C={vi}\u2286\u039e\u2212A\n\u00acM(O,C)\u2227\n\u2227 \u2227\nC;C={vi}\u2286A\u2212B\n\u00acM(O,C)\n  =\n= \u2228\nB\u2286A\n \n\u2227\nC;C={vi}\u2286B\nM(O,C) \u2227 \u2227\nC;C={vi}\u2286\u039e\u2212B\n\u00acM(O,C)\n \nHence\n\u00acM(O,\u039e\u2212 A) = \u2228\nB\u2286A\nexpr(B)\nand therefore:\n( ProbP (O)\nO\n\u00acM(O,\u039e\u2212 A)) = ( ProbP (O)\nO\n\u2228\nB\u2286A\nexpr(B))\nexpr(A) being defined as in the previous proof. As we have shown in the proof of the previous theorem, expressions under the probabilities of the right hand side are exclusive events, and therefore:\n( ProbP (O)\nO\n\u00acM(O,\u039e\u2212A)) = \u2211\nB\u2286A\n( ProbP (O)\nO\nexpr(B))\nthat is:\nBelMP (A \u2208 2 \u039e) =\n\u2211\nB\u2286A\nmMP (B)\nAs the previous theorem shows thatmMP is a DS Theory Mass Function, it suffices to show the above. Q.e.d.\u2737\nTHEOREM 3 P lMP is a Plausibility Function in the sense of DS-Theory and it is the Plausibility Function corresponding to the BelMP .\nPROOF: By definition:\nP lMP (A) = ProbM(O)\nO\n(O,A)\nhence\nP lMP (A) = 1\u2212 ( ProbP (O)\nO\n\u00acM(O,A))\nBut by definition:\n( ProbP (O)\nO\n\u00acM(O,A)) = ( ProbP (O)\nO\n\u00acM(O,\u039e\u2212(\u039e\u2212A))) = BelMP (\u039e\u2212A)\nhence\nP lMP (A) = 1\u2212 Bel M P (\u039e\u2212 A)\nQ.e.d.\u2737\nTwo important remarks must be made concerning this particular inter-\npretation:\n\u2022 Bel and Pl are both defined, contrary to many traditional approaches,\nas THE probabilities and NOT as lower or upper bounds to any probability.\n\u2022 It is Pl(A) (and not Bel(A) as assumed traditionally) that expresses\nthe probability of A, and Bel(A) refers to the probability of the complementary set AC .\nOf course, a complementary measurement function is conceivable to revert the latter effect, but the intuition behind such a measurement needs some elaboration. We shall not discuss this issue in this paper.\nLet us also define the following functions referred to as labelled Belief, labelled Plausibility and labelled Mass Functions respectively for the labeled population P:\nDefinition 12 Let P be a population and l its labeling. Then\nBel Ml P (A) =\nProbP (\u03c9)\n\u03c9\n\u00acMl(\u03c9,\u039e\u2212A)\nP l Ml P (A) =\nProbP (\u03c9)\n\u03c9\nMl(\u03c9,A)\nm Ml P (A) =\nProbP (\u03c9)\n\u03c9\n( \u2227\nB;B={vi}\u2286A\nMl(\u03c9,B) \u2227 \u2227\nB;B={vi}\u2286\u039e\u2212A\n\u00acMl(\u03c9,B))\nLet us illustrate the above concepts with Citizen Coot example:\nExample 7 For the belief function for sold-bottles-population P and the measurement function M3, let us assume the following labeling: l(\u03c9) ={(H,G),(H,B),(M,G),(M,B),(S,B),(D,B)} for every \u03c9 \u2208 \u2126, which means that we are convinced that only high and moderate quality products are sold in good shops.For the population P\u2019 under\nthis labeling, if we identify probability with relative frequency, we have the focal points given in the Table 4:\u2738\nIt is easily seen that:\nTHEOREM 4 m Ml P is the mass Function in the sense of DS-Theory.\nPROOF: To show this is suffices to show that the modified measurement\nmethod Ml possesses the same properties as the measurement method M . Let us consider a labeling l and a population P under this labeling. Let O be an object and L its label under labeling l (L = l(O)). Always Ml(O,\u039e) = TRUE because by definition Ml(O,\u039e) = M(O,\u039e \u2229 L) = M(O,L) and by definition of a labeled population for the object\u2019s O label L M(O,L) = TRUE. Second, the superset consistency is satisfied, because if A \u2282 B then if Ml(O,A) = TRUE then also Ml(O,A) = M(O,A \u2229 L) = TRUE, but because A \u2229 L \u2286 B \u2229 L then also M(O,B \u2229 L) = TRUE, but by definition M(O,B \u2229 L) = Ml(O,B) = TRUE and thus it was shown that Ml(O,A) = TRUE implies Ml(O,B) = TRUE for any superset B of the set A. Finally, also the subset consistency holds, because if M(O,L \u2229 A) = TRUE then there exists a proper subset B of L\u2229A such thatM(O,B) = TRUE. But in this case B = L\u2229B so we can formally write: M(O,L\u2229\nB) = TRUE. Hence we see that Ml(O,A) = TRUE implies the existence of a proper subset B of the set A such that Ml(O,B) = TRUE. Hence considering analogies between definitions of mMP and mP M l as well as between the respective Theorems we see immediately that this Theorem is valid. Q.e.d.\u2737\nTHEOREM 5 Bel Ml P is a Belief Function in the sense of DS-Theory corresponding to the mMlP .\nPROOF: AsMl is shown to be a DS Theory Mass Function and considering\nanalogies between definitions of BelMP and BelP M l as well as between the respective Theorems we see immediately that this Theorem is valid. Q.e.d.\u2737\nTHEOREM 6 P l Ml P is a Plausibility Function in the sense of DS-Theory and it is the Plausibility Function corresponding to the BelMlP .\nPROOF: AsMl is shown to be a DS Theory Mass Function and considering\nanalogies between definitions of P lMP and P lP M l as well as between the respective Theorems we see immediately that this Theorem is valid. Q.e.d.\u2737\nThis does not complete the interpretation. Let us now assume we run a \u201d(re-)labelling process\u201d on the (pre-labelled\nor unlabeled) population P.\nDefinition 13 Let M be a measurement method, l be a labeling under this measurement method, and P be a population under this labeling (Note that the population may also be unlabeled). The (simple) labelling process on the population P is defined as a functional LP : 2\u039e \u00d7 \u0393 \u2192 \u0393, where \u0393 is the set of all possible labelings under M , such that for the given labeling l and a given nonempty set of attribute values L (L \u2286 \u039e), it delivers a new labeling l\u2032 (l\u2032 = LP (L, l)) such that for every object \u03c9 \u2208 \u2126:\n1. if Ml(\u03c9, L) = FALSE then l \u2032(\u03c9) = \u2205\n(that is l\u2019 discards a labeled object (\u03c9, l(\u03c9)) if Ml(\u03c9, L) = FALSE\n2. otherwise l\u2032(\u03c9) = l(\u03c9) \u2229 L (that is l\u2019 labels the object with l(\u03c9) \u2229 L\notherwise.\nRemark: It is immediately obvious, that the population obtained as the\nsample fulfills the requirements of the definition of a labeled population.\nThe labeling process clearly induces from P another population P\u2019 (a population under the labeling l\u2032) being a subset of P (hence perhaps \u201dsmaller\u201d than P) labelled a bit differently. Clearly if we retain the primary measurement method M then a new modified measurement method Ml\u2032 is induced by the new labeling. The (re-)labelling process may be imagined as the diagnosis process made by a physician. A patient \u201dlabelled\u201d with symptoms observed by himself (many symptoms remain hidden for the physician, like the body temperature curve over last few days) is relabeled by the physician when being ill (labelled with the diseases suspected) or rejected (declared\nhealthy due to symptoms not matching physician\u2019s diagnostic procedure).\nLet us define the following\nDefinition 14 \u201dlabelling process function\u201d mLP ;L : 2\u039e \u2192 [0, 1]: is defined as:\nmLP ;L(L) = 1\n\u2200B;B\u22082\u039e ,B 6=Lm LP ;L(B) = 0\nIt is immediately obvious that:\nTHEOREM 7 mLP ;L is a Mass Function in sense of DS-Theory.\nLet BelLP,L be the belief and P lLP,L be the Plausibility corresponding to mLP,L. Now let us pose the question: what is the relationship between Bel M l\u2032\nP \u2032 , Bel Ml P , and Bel LP,L. It is easy to show that\nTHEOREM 8 Let M be a measurement function, l a labeling, P a population under this labeling. Let L be a subset of \u039e. Let LP be a labeling process and let l\u2032 = LP (L, l). Let P\u2019 be a population under the labeling l\u2032. Then Bel M l\u2032\nP \u2032 is a combination via DS Combination rule of Bel Ml , and BelLP ;L.,\nthat is:\nBel M l\u2032 P \u2032 = Bel Ml P \u2295 Bel LP ;L\n.\nPROOF: Let us consider a labeled object (Oj, Lj) from the population P\n(before re-labeling, that is Lj = l(Oj)) which passed the relabeling and\nbecame (Oj, Lj \u2229 L), that is Lj \u2229 L = l \u2032(Oj).. Let us define exprB (before relabeling) and exprA (after labeling) as:\nexprB((Oj, Lj), A) = \u2227\nB;B={vi}\u2286A\nMl(O,B)\u2227\n\u2227 \u2227\nB;B={vi}\u2286\u039e\u2212A\n\u00acMl(O,B)\nand\nexprA((Oj, Lj), A) = \u2227\nB;B={vi}\u2286A\nMl\u2032(O,B)\u2227\n\u2227 \u2227\nB;B={vi}\u2286\u039e\u2212A\n\u00acMl\u2032(O,B)\nLet exprB((Oj, Lj), C) = TRUE and exprA((Oj, Lj), D) = TRUE for some C and some D. Obviously then for no other C and no other D the respective expressions are valid. It holds also that:\nexprB((Oj, Lj), C) = \u2227\nB;B={vi}\u2286C\nM(Oj , Lj \u2229 B)\u2227\n\u2227 \u2227\nB;B={vi}\u2286\u039e\u2212D\n\u00acM((Oj , Lj \u2229B)\nand\nexprA((Oj, Lj), D) = \u2227\nB;B={vi}\u2286D\nM(Oj , Lj \u2229 L \u2229B)\u2227\n\u2227 \u2227\nB;B={vi}\u2286\u039e\u2212D\n\u00acM(Oj , Lj \u2229 L \u2229 B)\nIn order to get truth on the first expression, C must be a subset of Lj , and for the second we need D to be a subset of Lj \u2229 L. Furthermore, for a singleton F \u2286 \u039e either M(Oj , Lj \u2229 F ) = TRUE,M(Oj , Lj \u2229 L \u2229 F ) = TRUE, and then it belongs to C, L and D, orM(Oj , Lj \u2229 F ) =\nTRUE,M(Oj , Lj \u2229 L \u2229 F ) = FALSE, and then it belongs to C, but not to L and hence not to D, orM(Oj, Lj \u2229 F ) = FALSE, so due to superset consistency also M(Oj, Lj \u2229 L \u2229 F ) = FALSE, and then it belongs neither to C nor to D (though membership in L does not need to be excluded). So we can state that D = C \u2229 L,\nSo the absolute expected frequency of objects for which exprA(D) holds, is given by:\n\u2211\nC;D=C\u2229L\nsamplecardinality \u00b7mMlP (C)\nthat is:\n\u2211\nC;D=C\u2229L\nsamplecardinality \u00b7mMlP (C) \u00b7m LP ;L(L)\nwhich can be easily re-expressed as:\n\u2211\nC,G;D=C\u2229G\nsamplecardinality \u00b7mMlP (C) \u00b7m LP ;L(G)\nSo generally:\nm M l\u2032 P \u2032 (D) = c \u00b7 \u2211\nC,G;D=C\u2229G\nm Ml P (C) \u00b7m LP ;L(G)\nwith c - normalizing constant. Q.e.d.\u2737\nExample 8 To continue Citizen Coot example let us recall the function BelMP from Example 6 which is one of an unlabeled population. Let us\ndefine the label\nL = {(H,G), (H,B), (M,G), (M,B), (S,B), (D,B)}\nas in Example 7. Let us define the labeling process function as\nmLP ;L(L) = 1\n\u2200B;B\u22082\u039e,B 6=Lm LP ;L(B) = 0\n. Let us consider the function BelMlP \u2032 from Example 7. It is easily seen that:\nBel Ml P \u2032 = Bel M P \u2295Bel LP ;L\n\u2738\nLet us try another experiment, with a more general (re-)labeling process. Instead of a single set of attribute values let us take a set of sets of attribute values L1, L2, ..., Lk (not necessarily disjoint) and assign to each one a probability mLP,L 1,L2,...,Lk(Ai) of selection.\nDefinition 15 Let M be a measurement method, l be a labeling under this measurement method, and P be a population under this labeling (Note that the population may also be unlabeled). Let us take a set of (not necessarily disjoint) nonempty sets of attribute values {L1, L2, ..., Lk} and let us define the probability of selection as a function mLP,L 1,L2,...,Lk : 2\u039e \u2192 [0, 1] such that\n\u2211\nA;A\u2286\u039e\nmLP,L 1,L2,...,Lk(A) = 1\n\u2200A;A\u2208{L1,L2,...,Lk}m LP,L1,L2,...,Lk(A) > 0\n\u2200A;A 6\u2208{L1,L2,...,Lk}m LP,L1,L2,...,Lk(A) = 0\nThe (general) labelling process on the population P is defined as a (randomized) functional LP : 22 \u039e \u00d7 \u2206 \u00d7 \u0393 \u2192 \u0393, where \u0393 is the set of all possible labelings under M , and \u2206 is a set of all possible probability of selection functions, such that for the given labeling l and a given set of (not necessarily disjoint) nonempty sets of attribute values {L1, L2, ..., Lk} and a given probability of selection mLP,L 1,L2,...,Lk it delivers a new labeling l\u201d such that for every object \u03c9 \u2208 \u2126:\n1. a label L, element of the set {L1, L2, ..., Lk} is sampled randomly according to the probability distribution mLP,L 1,L2,...,Lk; This sampling is done independently for each individual object,\n2. if Ml(\u03c9, L) = FALSE then l\u201d(\u03c9) = \u2205\n(that is l\u201d discards an object (\u03c9, l(\u03c9)) if Ml(\u03c9, L) = FALSE\n3. otherwise l\u201d(\u03c9) = l(\u03c9) \u2229 L (that is l\u201d labels the object with l(\u03c9) \u2229 L\notherwise.)\nAgain we obtain another (\u201dsmaller\u201d) population P\u201d under the labeling l\u201d labelled a bit differently. Also a new modified measurement method Ml\u201d is induced by the \u201dre-labelled\u201d population. Please notice, that l\u201d is not derived deterministicly. Another run of the general (re-)labeling process LP may result in a different final labeling of the population and hence a different subpopulation under this new labeling.\nExample 9 The (re-)labelling process may be imagined as the diagnosis process made by a team of physicians in a poly-clinic. A patient \u201dlabelled\u201d with symptoms observed by himself is (a bit randomly) directed by the ward administration to one of the available internists each of them having a bit different educational background and/or a different experience in his profession, hence taking into consideration a bit different set of working hypotheses. The patient is relabeled by the given physician being ill (labelled with the diseases suspected) or rejected (declared healthy) according to the knowledge of this particular physician. The final ward statistics of illnesses does not take into account the fact that a physician may have had no knowledge of a particular disease unit and hence qualified the patient either healthy or ill of another, related disease unit. And it reflects the combined processes: of random allocations of patients to physicians and of belief worlds of the physicians rather then what the patients were actually suffering from. (We are actually satisfied with the fact that both views of ward statistics usually converge).\u2738\nClearly:\nTHEOREM 9 mLP,L 1,...,Lk is a Mass Function in sense of DS-Theory.\nLet BelLP ;L 1,...,Lk be the belief and P lLP,L 1,...,Lk be the Plausibility corresponding to mLP,L 1,...,Lk. Now let us pose the question: what is the relationship between BelMl\u201dP\u201d , Bel Ml P , and Bel LP,L1,...,Lk. It is easy to show that\nTHEOREM 10 Let M be a measurement function, l a labeling, P a population under this labeling. Let LP be a generalized labeling process and let l\u201d be the result of application of the LP for the set of labels from the set {L1, L2, ..., Lk} sampled randomly according to the probability distribution mLP,L 1,L2,...,Lk;. Let P\u201d be a population under the labeling l\u201d. Then The expected value over the set of all possible resultant labelings l\u201d (and hence populations P\u201d) (or, more precisely, value vector) of BelMl\u201dP\u201d is a combination via DS Combination rule of BelMlP , and Bel LP,L1,...,Lk., that is:\nE(Bel M \u2032 l\nP\u201d ) = Bel Ml P \u2295 Bel\nLP,L1,...,Lk\n.\nPROOF: By the same reasoning as in the proof of Theorem 8 we come to\nthe conclusion that for the given label Li and the labeling l\u201d (instead of l\u2032 the absolute expected frequency of objects for which exprA(D) holds, is given by:\n\u2211\nC;D=C\u2229Li\nsamplecardinality \u00b7mMlP (C) \u00b7m LP ;L1,...,Lk(Li)\nas the process of sampling the population runs independently of the sampling the set of labels of the labeling process. But exprA(D) may hold for any L i such that C \u2286 Li, hence in all the exprA(D) holds for as many objects as:\n\u2211\ni;i=1,...,k\n\u2211\nC;D=C\u2229Li\nsamplecardinality \u00b7mMlP (C) \u00b7m LP ;L1,...,Lk(Li)\nwhich can be easily re-expressed as:\n\u2211\nC,G;D=C\u2229G\nsamplecardinality \u00b7mMlP (C) \u00b7m LP ;L1,...,Lk(G)\nSo generally:\nE(mMl\u201dP\u201d (D)) = c \u00b7 \u2211\nC;D=C\u2229G\nm Ml P (C) \u00b7m LP ;L1,...,Lk(G)\nwith c - normalizing constant.Hence the claimed relationship really holds. Q.e.d.\u2737\nExample 10 The generalized labeling process and its consequences may be realized in our Citizen Coot example by randomly assigning the sold bottles for evaluation to two \u201dexperts\u201d, one of them - considering about 30 % of the bottles - is running the full M test procedure, and the other - having to consider the remaining 70 % of checked bottles - makes it easier for himself by making use of his belief in the labeling l of Example 7. \u2738"}, {"heading": "4.1 Summary of the New Interpretation", "text": "The following results have been established in this Section:\n\u2022 concepts of measurement and modified measurement methods have\nbeen introduced\n\u2022 a concept of labelled population has been developed\n\u2022 it has been shown that a labelled population with the modified measure-\nment method can be considered in terms of a Joint Belief Distribution in the sense of DS-Theory,\n\u2022 the process of \u201drelabeling\u201d of a labelled population has been defined\nand shown to be describable as a Belief Distribution.\n\u2022 it has been shown that the relationship between the Belief Distribu-\ntions of the resulting relabeled population, the basic population and the relabeling process can be expressed in terms of the Dempster-Ruleof-Independent-Evidence-Combination.\nThis last result can be considered as of particular practical importance. The interpretation schemata of DS Theory made by other authors suffered from one basic shortcoming: if we interpreted population data as well as evidence in terms of their DS schemes, and then combine the evidence with population data (understood as a Dempster type of conditioning) then the resulting belief function cannot be interpreted in terms of the population data scheme, with subsequent updating of evidence making thinks worse till even the weakest relation between the belief function and the (selected sub)population is lost.\nIn this paper we achieve a break-through: data have the same interpretation scheme after any number of evidential updating and hence the belief function can be verified against the data at any moment of DS evidential reasoning.\nThe above definition and properties of the generalized labeling process should be considered from a philosophical point of view. If we take one by one the objects of our domain, possibly labelled previously by an expert in the past, and assign a label independently of the actual value of the attribute of the object, then we cannot claim in any way that such a process may be attributed to the opinion of the expert. Opinions of two experts may be independent of one another, but they cannot be independent of the subject under consideration. This is the point of view with which most people would agree, and should the opinions of the experts not depend on the subject, then at least one of them may be considered as not expert.\nThis is exactly what we want to point at with our interpretation: the precise pinpointing at what kind of independence is assumed within the Dempster-Shafer theory is essential for its usability. Under our interpretation, the independence relies in trying to select a label for fitting to an object independently of whatever properties this object has (including its previous labeling). The distribution of labels for fitting is exactly identical from object to object. The point, where the dependence of object\u2019s labeling on its properties comes to appearance, is when the measurement method states that the label does not fit. Then the object is discarded. From philosophical point of view it means exactly that we try to impose our philosophy of life onto the facts: cumbersome facts are neglected and ignored. We suspect that this is exactly the justification of the name \u201dbelief function\u201d. It expresses not what we see but what we would like to see.\nOur suspicion is strongly supported by the quite recent statement of Smets that \u201dauthors (of multiple interpretations in terms of upper lower probability models, inner and outer measures, random sets, probabilities of provability, probabilities of necessity etc.) usually do not explain or justify the dynamic component, that is, how updating (conditioning) is to be handled (except in some cases by defining conditioning as a special case of combination. So I (that is Smets) feel that these partial comparisons are incomplete, especially as all these interpretations lead to different updating rules. \u201d Our interpretation explains both the static and dynamic component of the DST, and does not lead to any other but to the Dempster Rule of Combination, hence may be acceptable from the rigorous point of view of Smets. As in the light of Smets\u2019 paper [26] we have presented the only correct probabilistic interpretation of the DS theory so far, we feel to be authorized to claim that our philosophical assessment of the DST is the correct one.\nWe have seen from the proofs of the theorems of this paper, that our interpretation may be called a true one. The paper of Smets [26] permits us to claim that we have found the true interpretation."}, {"heading": "5 Belief from Data", "text": "As the DS-belief function introduced in this paper is defined in terms of frequentist measures, there exists a direct possibility of calculating the belief\nfunction from data.\nIt has to be assumed that we have a data set for which the measurements of type Ml have been carried out for each singleton subset of the space of discourse \u039e. The results of these measurements may be available for example as a set-valued attribute associated with each object in such a way that the values actually appearing are those for which the singleton set tests were positive (i.e. TRUE). In this case if for an object the attribute X has the value X = A with A \u2286 \u039e then this object increases the count for the DS-Mass Function m(A) (and for no other m).\nWhenever any statistical quantity is estimated from data, there exists some risk (uncertainty) about unseen examples. If we assume some significance levels, we can complete the estimation by taking the lower bounds as actual estimates of m\u2019s and shifting the remaining burden (summing up to 1) onto the m(\u039e) just taking for granted that doubtful cases may be considered as matching all the measurements."}, {"heading": "6 Discussion", "text": "In the past, various interpretations have been sought for the Dempster-Shafer Bel-Functions. Two main steams of research were distinguished by Smets [26]: probability related approaches and probability discarding approaches\n(the former disguised, the latter welcome by Smets). Let us make some comparisons with our interpretation and its underlying philosophy."}, {"heading": "6.1 Shafer and Smets", "text": "Shafer [22] and Smets [26] have made some strong statements in defense of the Dempster-Shafer theory against sharp criticism of this theory by its opponents as well as unfortunate users of the DST who wanted to attach it to the dirty reality (that is objectively given databases). Smets [26] and also initially Shafer [21] insisted on Bels not being connected to any empirical measure (frequency, probability etc.) considering the domain of DST applications as the one where \u201dwe are ignorant of the existence of probabilities\u201d, and not one with \u201dpoorly known probabilities\u201d ([26], p.324). The basic property of probability, which should be dropped in the DST axiomatization, should be the additivity of belief measures. Surely, it is easily possible to imagine situations where in the real life additivity is not granted: imagine we have had a cage with 3 pigs, we put into it 3 hungry lions two hours ago, how many animals are there now ? (3+ 3 < 6). Or ten years ago we left one young man and one young woman on an island in the middle of the atlantic ocean with food and weapons sufficing for 20 years. How many human beings are there now ? (1 + 1 > 2). The trouble is, however, that the objects stored in databases of a computer behave usually (under normal operation) in an additive manner. Hence the DST is simply disqualified for any reasoning within human collected data on\nreal world, if we accept the philosophy of Smets and Shafer.\nThe question may be raised at this point, what else practically useful can be obtained from a computer reasoning on the basis of such a DST. If the DST models, as Smets and Shafer claim, human behaviour during evidential reasoning, then it would have to be demonstrated that humans indeed reason as DST. We take e.g. 1000 people who never heard of Dempster-Shafer theory, briefly explain the static component, provide them with two opinions of independent experts and expect of them to answers what are their final beliefs. Should their answers correspond to results of the DST (at least converge toward them), then the computer, if fed with our knowledge, would be capable to predict our conclusions on a given subject. However, to my knowledge, no experiment like this has ever been carried out. Under these circumstances the computer reasoning with DST would tell us what we have to think and not what we think. But I don\u2019t suspect that anybody would be happy about a computer like this.\nHence, from the point of view of computer implementation the philosophy of Smets and Shafer is not acceptable.Compare also Discussion in [10] on the subject.\nBoth of them felt a bit uneasy about a total loss of reference to any scientific experiment checking practical applicability of the DST and suggested some probabilistic background for decision making (e.g. the pigeonistic probabilities of Smets), but I am afraid that by these interpretations they fall precisely into the same pitfalls they claimed to avoid by their highly abstract\nphilosophy.\nAs statistical properties of Shafer\u2019s [21] notion of evidence are concerned, sufficient criticism has been expressed by Halpern and Fagin ([10] in sections 4-5). Essentially it is pointed there at the fact that \u201dthe belief that represents the joint observation is equal to the combination is in general not equal to the combination of the belief functions representing the individual (independent) observations\u201d (p.297). The other point raised there that though it is possible to capture properly in belief functions evidence in terms of probability of observations update functions (section 4 of [10]), it is not possible to do the same if we would like to capture evidence in terms of beliefs of observations update functions (section 5 of [10]).\nAs Smets probabilistic interpretations are concerned, let us \u201dcontinue\u201d the killer example of [26] on pages 330-331. \u201dThere are three potential killers, A, B, C. Each can use a gun or a knife. I shall select one of them, but you will not know how I select the killer. The killer selects his weapon by a random process with p(gun)=0.2 and p(knife)=0.8. Each of A, B, C has his own personal random device, the random devices are unrelated. ...... Suppose you are a Bayesian and you must express your \u201dbelief\u201d that the killer will use a gun. The BF (belief function) solution gives Bel(gun) = 0.2 \u00d7 0.2 \u00d7 0.2 = 0.008. ..... Would you defend 0.2 ? But this applies only if I select a killer with a random device ...... But I never said I would use a random device; I might be a very hostile player and cheat whenever I can. ... . So you could interpret bel(x) as the probability that you are sure to win whatever Mother Nature\n(however hostile) will do.\u201d Yes, I will try to continue the hostile Mother Nature game here. For completeness I understand that Bel(knife) = 0.83 = 0.512 and Bel({gun, knife}) = 1. But suppose there is another I, the chief of gangster science fiction physicians, making decisions independly of the chief I of the killers. The chief I of physicians knows of the planned murder and has three physicians X,Y,Z. Each can either rescue a killed man or let him die. I shall select one of them, but you will not know how I select the physician. The physician, in case of killing with a gun, selects his attritude by a random process with p(rescue|gun) = 0.2 and p(let die|gun) = 0.8 and he lets the person die otherwise. Each of X, Y, Z has his own personal random device, the random devices are unrelated. ...... Suppose you are a Bayesian and you must express your \u201dbelief\u201d that the physician will rescue if the killer will use a gun. The BF (belief function) solution gives Bel1(rescue|gun) = 0.2 3 = 0.008. Bel1(let die|gun) = 0.8 3 = 0.512, Bel1({recue, let die}|gun) = 1. Also Bel2(let die|knife) = 1. As the scenarios for Bel1 and Bel2 are independent, let us combine them by the Dempster rule: Bel12 = Bel1 \u2295 Bel2. We make use of the Smets\u2019 claim that \u201dthe de re and de dicto interpretations lead to the same results\u201d ([26], p. 333), that is Bel(A|B) = Bel(\u00acB \u2228 A). Hence\nm12({(gun, let die), (knife, let die), (knife, rescue)}) = 0.480\nm12({(gun, rescue), (knife, rescue)}) = 0.008\nm12({(knife, rescue), (gun, let die)}) = 0.512\nNow let us combine Bel12 with the original Bel. We obtain:\nm\u2295m12((gun, let die) = 0.008 \u00b7 0.480 + 0.008 \u00b7 0.512 = 0.008 \u00b7 0.992\nBut these two unfriendly chiefs of gangster organizations can be extremely unfriendly and in fact your chance of winning a bet may be as bad as 0.008 \u00b7 0.512 for the event (gun, let die). Hence the \u201dmodel\u201d proposed by Smets for understanding beliefs functions as \u201dunfriendly Mother Nature\u201d is simply wrong. If the Reader finds the combination of Bel2 with the other Bels a little tricky, then for justification He should refer to the paper of Smets and have a closer look at all the other examples.\nNow returning to the philosophy of \u201dsubjectivity\u201d of Bel measures: Even if a human being may possess his private view on a subject, it is only after we formalize the feeling of subjectiveness and hence ground it in the data that we can rely on any computer\u2019s \u201dopinion\u201d. We hope we have found one such formalization in this paper. The notion of labeling developed here substitutes one aspect of subjective human behaviour - if one has found one plausible explanation, one is too lazy to look for another one. So the process of labeling may express our personal attitudes, prejudices, sympathies etc. The interpretation drops deliberately the strive for maximal objectiveness aimed at by traditional statistical analysis. Hence we think this may be a promising path for further research going beyond the DS-Theory formalism.\nSmets [26] views the probability theory as a formal mathematical apparatus and hence puts it on the same footing as his view of the DST. However, in our opinion, he ignores totally one important thing: The abstract concept of probability has its real world counterpart of relative frequency which tends to behave approximately like the theoretical probability in sufficiently many experimental settings as to make the abstract concept of probability useful for practical life. And a man-in-the-street will expect of the DST to possess also such a counterpart or otherwise the DST will be considered as another version of the theory of counting devils on a pin-head.\nLet us also have a look at interpretations disguised by Shafer and Smets\n(i.e. all the mentioned below):"}, {"heading": "6.2 DST and Random Sets", "text": "The canonic random set interpretation [16] is one with a statistical process over set instantiations. The rule of combination assumes then that two such statistically independent processes are run and we are interested in their intersections. This approach is not sound as empty intersection is excluded and this will render any two processes statistically dependent. We overcome this difficulty assuming in a straight forward manner that we are \u201dwalking\u201d from population to population applying the Rule of Combination. Classical DS theory in fact assumes such a walk implicitly or it drops in fact the\nassumption that Bel() of the empty set is equal 0. In this sense the random set approaches may be considered as sound as ours.\nHowever, in many cases the applications of the model are insane. For example, to imitate the logical inference it is frequently assumed that we have a Bel-function describing the actual observed value of a predicate P(x), and a Bel-Function describing the implication \u201dIf P(x) then Q(x)\u201d [13]. It is assumed further that the evidence on the validity of both Bel\u2019s has been collected independently and one applies the DS-rule of combination to calculate the Bel of the predicate Q(x). One has then to assume that there is a focal m of the following expression: m({(P (x), Q(x)), (\u00acP (x), Q(x)), (\u00acP (x),\u00acQ(x))}) which actually means that with non-zero probability at the same time P (x) and \u00acP (x) hold for the same object as we will see in the following example: Let Bel1 represent our belief in the implication, with focal points:\nm1(P (x) \u2192 Q(x)) = 0.5, m1(\u00ac(P (x) \u2192 Q(x))) = 0.5,\nLet further the independent opinion Bel2 on P(x) be available in the form of focal points:\nm2(P (x)) = 0.5, m2(\u00acP (x)) = 0.5\nLet Bel12 = Bel1 \u2295 Bel2 represent the combined opinions of both experts. The focal points of Bel12 are:\nm12({(P (x), Q(x))}) = 0.33, m12({(P (x),\u00acQ(x))}) = 0.33,\nm12({(\u00acP (x), Q(x)), (\u00acP (x),\u00acQ(x))}) = 0.33\nm12({(P (x), Q(x))}) = 0.33 makes us believe that there exist objects for which both P(x) and Q(x) holds. However, a sober (statistical) look at expert opinions suggests that all situations for which the implication P (x) \u2192 Q(x) holds, must result from falsity of P (x), hence whenever Q(x) holds then \u00acP (x) holds. These two facts combined mean that P(x) and its negation have to hold simultaneously. This is actually absurdity overseen deliberately. The source of this misunderstanding is obvious: the lack of proper definition of what is and what is not independent. Our interpretation allows for sanitation of this situation. We are not telling that the predicate and its negation hold simultaneously. Instead we say that for one object we modify the measurement procedure (set a label) in such a way that it, applied for calculation of P (x), yields true and at the same time for another object, with the same original properties we make another modification of measurement procedure (attach a label to it) so that measurement of \u00acP (x) yields also true, because possibly two different persons were enforcing their different beliefs onto different subsets of data.\nOur approach is also superior to canonical random set approach in the following sense: The canonical approach requires knowledge of the complete random set realizations of two processes on an object to determine the combination of both processes. We, however, postpone the acquisition of knowledge of the precise instantiation of properties of the object by interleaving the concept of measurement and the concept of labeling process. This has a\nclose resemblance to practical processing whenever diagnosis for a patient is made. If a physician finds a set of hypotheses explaining the symptoms of a patient, he will usually not try to carry out other testing procedures than those related to the plausible hypotheses. He runs clearly at risk that there exists a different set of hypotheses also explaining the patients\u2019s symptoms, and so a disease unit possibly present may not be detected on time, but usually the risk is sufficiently low to proceed in this way, and the cost savings may prove enormous."}, {"heading": "6.3 Upper and Lower Probabilities", "text": "Still another approach was to handle Bel and Pl as lower and upper probabilities [4]. This approach is of limited use as not every set of lower and upper probabilities leads to Bel/Pl functions [12], hence establishing a unidirectional relationship between probability theory and the DS-theory. Under our interpretation, the Bel/Pl function pair may be considered as a kind of interval approximations to some \u201dintrinsic\u201d probability distributions which, however, cannot be accessed by feasible measurements and are only of interest as a kind of qualitative explanation to the physical quantities really measured.\nTherefore another approach was to handle them as lower/upper envelops to some probability density function realization [12], [8]. However, the DS\nrule of combination of independent evidence failed."}, {"heading": "6.4 Inner and Outer Measures", "text": "Still another approach was to handle Bels/Pl in probabilistic structures rather than in probabilistic spaces [7]. Here, DS-rule could be justified as one of the possible outcomes of independent combinations, but no stronger properties were available. This is due to the previously mentioned fact that exclusion of empty intersections renders actually most of conceivable processes dependent. Please notice that under our interpretation no such ambiguity occurs. This is because we not only drop empty intersecting objects but also relabel the remaining ones so that any probability calculated afterwards does not refer to the original population.\nSo it was tried to drop the DS-rule altogether in the probabilistic structures, but then it was not possible to find a meaningful rule for multistage reasoning [10]. This is a very important negative outcome. As the DempsterShafer-Theory is sound in this respect and possesses many useful properties (as mentioned in the Introduction), it should be sought for an interpretation meeting the axiomatic system of DS Theory rather then tried to violate its fundamentals. Hence we consider our interpretation as a promising one for which decomposition of the joint distribution paralleling the results for probability distributions may be found based on the data."}, {"heading": "6.5 Rough Set Approach", "text": "An interesting alternative interpretation of the Dempster-Shafer Theory was found within the framework of the rough set theory [24], [9]. Essentially the rough set theory searches for approximation of the value of a decision attribute by some other (explaining) attributes. It usually happens that those attributes are capable only of providing a lower and upper approximation to the value of the decision attribute (that is the set of vectors of explaining attributes supporting only this value of the decision variable, and the set of vectors of explaining attributes supporting also this value of the decision variable resp.- for details see texts of Skowron [24] and Grzyma la-Busse [9]). The Dempster Rule of combination is interpreted by Skowron [25] as combination of opinions of independent experts, who possibly look at different sets of explanation attributes and hence may propose different explanations.\nThe difference between our approach and the one based on rough sets lies first of all in the ideological background: We assume that the \u201ddecision attribute\u201d is set-valued whereas the rough-set approach assumes it to be single-valued. This could have been overcome by some tricks which will not be explained in detail here.But the combination step is here essential: If we assume that the data sets for forming knowledge of these two experts are exhaustive, then it can never occur that these opinions are contradictory. But the DST rule of combination uses the normalization factor for dealing with cases like this. Also the opinions of experts may have only the form of a simple (that is deterministic) support function. Hence, rough-set in-\nterpretation implies axioms not actually present in the DST. Hence rough set interpretation is on the one hand restrictive, and on the other hand not fully conforming to the general DST. From our point of view the DST would change the values of decision variables rather then recover them from expert opinions.\nHere, we come again at the problem of viewing the independence of experts. The DST assumes some strange kind of independence within the data: the proportionality of the distribution of masses of sets of values among intersecting subsets weight by their masses in the other expert opinion. Particularly unhappy is the fact for the rough set theory, that given a value of the decision variable, the respective indicating vectors of explaining variables values must be proportionally distributed among the experts not only for this decision attribute value, but also for all the other decision attribute values that ever belong to the same focal point. Hence applicability of the rough set approach is hard to justify by a simple(, \u201dusual\u201d as Shafer wants) statistical test. On the other hand, statistical independence required for Dempster rule application within our approach is easily checked.\nTo demonstrate the problem of rough set theory with re combination of opinions of independent experts let us consider an examle of two experts having the combined explanatory attributes E1 (for expert 1) and E2 (for expert 2) both trying to guess the decision attribute D. Let us assume that D takes one of two values: d1, d2, E1 takes one of three values e11, e12, e13, E2 takes one of three values e21, e22, e23. Furthermore let us assume that the\nrough set analysis of an exhaustive set of possible cases shows that the value e11 of the attribute E1 indicates the value d1 of the decision attribute D, e12 indicates d2, e13 indicates the set {d1, d2}, Also let us assume that the rough set analysis of an exhaustive set of possible cases shows that the value e21 of the attribute E2 indicates the value d1 of the decision attribute D, e22 indicates d2, e32 indicates the set {d1, d2}, From the point of view of bayesian analysis four cases of causal influence may be distinguished (arrows indicate the direction of dependence).\nE1 \u2192 D \u2192 E2\nE1 \u2190 D \u2190 E2\nE1 \u2190 D \u2192 E2\nE1 \u2192 D \u2190 E2\nFrom the point of view of bayesian analysis, in the last case attributes E1 and E2 have to be unconditionally independent, in the remaining cases: E1 and E2 have to be independent conditioned on D. Let us consider first unconditional independence of E1 and E2. Then we have tthat:\n( ProbP (\u03c9)\n\u03c9\nE1(\u03c9) = e11 \u2227 E2(\u03c9) = e22) =\n= ( ProbP (\u03c9)\n\u03c9\nE1(\u03c9) = e11) \u00b7 ( ProbP (\u03c9)\n\u03c9\nE2(\u03c9) = e22) > 0\nHowever, it is impossible that (Prob P (\u03c9)\n\u03c9 E1(\u03c9) = e11 \u2227 E2(\u03c9) = e22) > 0\nbecause we have to do with experts who may provide us possibly with information not specific enough, but will never provide us with contradictory\ninformation. We conclude that unconditional independence of experts is impossible. Let us turn to independence of E1 and E2 if conditioned on D. We introduce the following denotation:\np1 = ProbP (\u03c9)\n\u03c9\nD(\u03c9) = d1\np2 = ProbP (\u03c9)\n\u03c9\nD(\u03c9) = d2\ne\u20321 = Prob(D(\u03c9)=d1)\u2227P (\u03c9)\n\u03c9\nE1(\u03c9) = e11\ne\u20323 = Prob(D(\u03c9)=d1)\u2227P (\u03c9)\n\u03c9\nE1(\u03c9) = e13\nf \u20321 = Prob(D(\u03c9)=d1)\u2227P (\u03c9)\n\u03c9\nE2(\u03c9) = e21\nf \u20323 = Prob(D(\u03c9)=d1)\u2227P (\u03c9)\n\u03c9\nE2(\u03c9) = e23\ne2\u201d = Prob(D(\u03c9)=d2)\u2227P (\u03c9)\n\u03c9\nE1(\u03c9) = e12\ne3\u201d = Prob(D(\u03c9)=d2)\u2227P (\u03c9)\n\u03c9\nE1(\u03c9) = e13\nf2\u201d = Prob(D(\u03c9)=d2)\u2227P (\u03c9)\n\u03c9\nE2(\u03c9) = e22\nf3\u201d = Prob(D(\u03c9)=d2)\u2227P (\u03c9)\n\u03c9\nE2(\u03c9) = e23\nLet Bel1 and m1 be the belief function and the mass function representing the knowledge of the first expert, let Bel2 and m2 be the belief function and the mass function representing the knowledge of the second expert. Let\nBel12 and m12 be the belief function and the mass function representing the knowledge contained in the combined usage of attributes E1, E2 if used for prediction of D - on the grounds of the rough set theory. It can be easily checked that:\nm1({d1}) = e \u2032 1 \u00b7 p1, m1({d2}) = e2\u201d \u00b7 p2, m1({d1, d2}) = e \u2032 3 \u00b7 p1,+e3\u201d \u2032 \u00b7 p2\nm2({d1}) = f \u2032 1 \u00b7 p1, m2({d2}) = f2\u201d \u00b7 p2, m2({d1, d2}) = f \u2032 3 \u00b7 p1,+f3\u201d \u2032 \u00b7 p2\nand if we assume the conditional independence of E1 and E2 conditioned on D, then we obtain:\nm12({d1}) = e \u2032 1 \u00b7 f \u2032 1 \u00b7 p1 + e \u2032 1 \u00b7 f \u2032 3 \u00b7 p1 + e \u2032 3 \u00b7 f \u2032 1 \u00b7 p1\nm12({d2}) = e2\u201d \u00b7 f2\u201d \u00b7 p2 + e2\u201d \u00b7 f3\u201d \u00b7 p2 + e3\u201d \u00b7 f2\u201d \u00b7 p2\nm12({d1, d2}) = e \u2032 3 \u00b7 f \u2032 3 \u00b7 p1 + e3\u201d \u00b7 f3\u201d \u00b7 p2\nHowever, the Dempster rule of combination would result in (c - normalization constant):\nm1\u2295m2({d1}) = c\u00b7(e \u2032 1 \u00b7f \u2032 1 \u00b7p 2 1+e \u2032 1 \u00b7f \u2032 3 \u00b7p 2 1+e \u2032 1 \u00b7f3\u201d\u00b7p1 \u00b7p2+e \u2032 3 \u00b7f \u2032 1 \u00b7p 2 1+e3\u201d\u00b7f \u2032 1 \u00b7p1 \u00b7p2)\nm1\u2295m2({d2}) = c\u00b7(e2\u201d\u00b7f2\u201d\u00b7p 2 2+e2\u201d\u00b7f \u2032 3\u00b7p1\u00b7p2+e2\u201d\u00b7f3\u201d\u00b7p 2 2+e \u2032 3\u00b7f2\u201d\u00b7p1\u00b7p2+e3\u201d\u00b7f2\u201d\u00b7p 2 2)\nm1\u2295m2({d1, d2}) = c \u00b7e \u2032 3 \u00b7f \u2032 3 \u00b7p 2 1+e3\u201d \u00b7f3\u201d \u00b7p 2 2+e \u2032 3 \u00b7f3\u201d \u00b7p1 \u00b7p2+e3\u201d \u00b7f \u2032 3 \u00b7p1 \u00b7p2)\nObviously, Bel12 and Bel1 \u2295 Bel2 are not identical in general. We conclude that conditional independence of experts is also impossible. Hence no usual\nstaatistical indeperndence assumption is valid for the rough set interpretation of the DST. This fact points at where the difference between rough set interpretation and our interpretation lies in: in our interpretation, traditional statistical independence is incorporated into the Dempster\u2019s scheme of combination (labelling process).\nBy the way, lack of correspondence between statistical independence and Dempster rule of combination is characteristic not only of the rough set interpretation, but also of most of the other ones. The Reader should read carefully clumsy statements of Shafer about DST and statistical independence in [22]."}, {"heading": "6.6 General Remarks", "text": "The Dempster-Shafer Theory exists already over two decades. Though it was claimed to reflect various aspects of human reasoning, it has not been widely used in expert systems until recently due to the high computational complexity. Three years ago, however, an important paper of Shenoy and Shafer [23] has been published, along papers of other authors similar in spirit, which meant a break-through for application of both bayesian and Dempster-Shafer theories in reasoning systems, because it demonstrated that if joint (bayesian or DS) belief distribution can be decomposed in form of a belief network than it can be both represented in a compact manner and marginalized efficiently by local computations.\nThis fact makes them suitable as alternative fundamentals for represen-\ntation of (uncertain) knowledge in expert system knowledge bases [11].\nReasoning in bayesian belief networks has been subject of intense research work also earlier [20], [23], [15], [17]. There exist methods of imposing various logical constraints on the probability density function and of calculating marginals not only of single variables but of complicated logical expressions over elementary statements of the type X =x (x belonging to the domain of the variable X ) [17]. There exist also methods determining the decomposition of a joint probability distribution given by a sample into a bayesian belief network [3], [18], [1], [27].\nIt is also known that formally probability distributions can be treated as special cases of Dempster-Shafer belief distributions (with sinngleton focal points) [10].\nHowever, for application of DS Belief-Functions for representation of uncertainty in expert system knowledge bases there exist several severe obstacles. The main one is the missing frequentist interpretation of the DS-Belief function and hence neither a comparison of the deduction results with experimental data nor any quantitative nor even qualitative conclusions can be drawn from results of deduction in Dempster-Shafer-theory based expert systems [13].\nNumerous attempts to find a frequentist interpretation have been reported (e.g. [7], [8], [9], [10], [12], [22], [24]). But, as Smets [26] states, they failed either trying to incorporate Dempster rule or when explaining the nature of probability interval approximation. The Dempster-Shafer The-\nory experienced therefore sharp criticism from several authors in the past [17], [10]. It is suggested in those critical papers that the claim of DST to represent uncertainty stemming from ignorance is not valid. Hence alternative rules of combination of evidence have been proposed. However, these rules fail to fulfill Shenoy/Shafer axioms of local computation [23] and hence are not tractable in practice. These failures of those authors meant to us that one shall nonetheless try to find a meaningful frequentist interpretation of DST compatible with Dempster rule of combination.\nWe have carefully studied several of these approaches and are convinced that the key for many of those failures (beside those mentioned by Halpern in [10]) was: (1) treating the Bel-Pl pair as an interval approximation and (2) viewing combination of evidence as a process of approaching a point estimation. In this paper we claim that the most reasonable treatment of Bel\u2019s Pl\u2019s is to consider them to be POINT ESTIMATES of probability distribution over set-valued attributes (rather then Interval estimates of probability distribution over single valued attributes). Of course, we claim also that Bel-Pl estimates by an interval some probability density function but in our interpretation that \u201dintrinsic\u201d probability density function is of little interest for the user. The combination of evidence represents in our interpretation manipulation of data by imposing on them our prejudices (rather then striving for extraction of true values).\nUnder these assumptions a frequentionistically meaningful interpretation to the Bel\u2019s can be constructed, which remains consistent under combination\nof joint distribution with \u201devidence\u201d, giving concrete quantitative meaning to results of expert system reasoning. Within this interpretation we were able to prove the correctness of Dempster-Shafer rule. This means that this frequentist interpretation is consistent with the DS-Theory to the largest extent ever achieved."}, {"heading": "7 Conclusions", "text": "\u2022 According to Smets [26] there has existed no proper frequentist inter-\npretation of the Dempster-Shafer theory of evidence so far.\n\u2022 In this paper a novel frequentist interpretation of the Dempster-Shafer-\nTheory has been found allowing for close correspondence between Belief and Plausibility functions and the real data.\n\u2022 This interpretation fits completely into the framework of Bel/Pl defi-\nnitions and into the Dempster rule of combination of independent evidence relating for the first time in DST history this rule to plain statistical independence just overcoming difficulties of many alternative interpretations of the Dempster-Shafer-Theory. Hence this interpretation dismisses the claim of Smets [26] that such an interpretation cannot exist.\n\u2022 It is distinguished by the fact of postponing the moment of measur-\ning object properties behind combination of evidence leading even to\ndropping some costly measurements altogether.\n\u2022 The interpretation allows for subjective treatment of Bel\u2019s and Pl\u2019s as\nsome approximations to unknown probability distribution of an intrinsic, but not accessible, attribute.\n\u2022 The introduced concept of labeled population may to some extent rep-\nresent subjectivity in viewing probabilities.\n\u2022 This interpretation questions the common usage of the DST as a mean\nto represent and to reason with uncertainty stemming from ignorance. This view has been already shaken by works of Pearl [17] and Halpern and Fagin [10]. What our interpretation states clearly is that the DST should be viewed as a way to express unwillingness to accept objective facts rather than as a mean to express ignorance about them. Hence it should be called a theory of prejudices rather than a theory of evidence.\nFinally, I feel obliged to apologize and to say that all critical remarks towards interpretations of DST elaborated by other authors result from deviations of those interpretations from the formalism of the DST. I do not consider, however, a deviation from DST as a crime, because modifications of DST may and possibly have a greater practical importance than the original theory. The purpose of this paper was to shed a bit more light onto the intrinsic nature of pure DST and not to call for orthodox attitudes towards DST."}, {"heading": "Acknowledgements", "text": "I am indebted to anonymous referees who greatly contributed to enhancement of the quality of presentation of this paper."}], "references": [{"title": "Learning with CASTLE, Symbolic and Quantitative Approaches", "author": ["S. Acid", "L.M. deCampos", "A. Gonzales", "B. Molina", "N. Perez de la Blanca"], "venue": "Lecture Notes In Computer Science", "citeRegEx": "1", "shortCiteRegEx": "1", "year": 1991}, {"title": "L.p., a logic for representing and reasoning with statistical knowledge", "author": ["F. Bacchus"], "venue": "Computer Intelligence", "citeRegEx": "2", "shortCiteRegEx": "2", "year": 1990}, {"title": "Approximating discrete probability distributions with dependence trees", "author": ["C.K. Chow", "C.N. Liu"], "venue": "IEEE Transactions on Information Theory , Vol. IT-14,", "citeRegEx": "3", "shortCiteRegEx": "3", "year": 1968}, {"title": "Upper and lower probabilities induced by a multi-valued mapping", "author": ["A.P. Dempster"], "venue": "Ann. Math. Stat", "citeRegEx": "4", "shortCiteRegEx": "4", "year": 1967}, {"title": "A generalization of Bayesian inference", "author": ["A.P. Dempster"], "venue": "J. R. Stat. Soc. Ser.B", "citeRegEx": "5", "shortCiteRegEx": "5", "year": 1968}, {"title": "Halpern: Uncertainty, belief, and probability", "author": ["J.Y.R. Fagin"], "venue": "Proc. Int. Joint Conf. AI, IJCAI89, Detroit,", "citeRegEx": "6", "shortCiteRegEx": "6", "year": 1989}, {"title": "Halpern: Uncertainty, belief, and probability", "author": ["J.Y.R. Fagin"], "venue": "Comput. Intell", "citeRegEx": "7", "shortCiteRegEx": "7", "year": 1991}, {"title": "Halpern: A new approach to updating beliefs", "author": ["J.Y.R. Fagin"], "venue": "Uncertainty in Artificial Intelligence", "citeRegEx": "8", "shortCiteRegEx": "8", "year": 1991}, {"title": "Two views of belief: belief as generalized probability and belief as evidence,Artificial", "author": ["J.Y. Halpern", "R. Fagin"], "venue": null, "citeRegEx": "10", "shortCiteRegEx": "10", "year": 1992}, {"title": "An introduction to algorithm for inference in belief nets, in: Henrion M., Shachter R.D.,Kanal L.N", "author": ["M. Henrion"], "venue": "Lemmer J.F.: Uncertainty in Artificial Intelligence", "citeRegEx": "11", "shortCiteRegEx": "11", "year": 1990}, {"title": "Bayesian and non-Bayesian evidential updating", "author": ["H.E. Kyburg Jr."], "venue": "Artificial Intelligence", "citeRegEx": "12", "shortCiteRegEx": "12", "year": 1987}, {"title": "Induction of uncertain rules and the sociopathicity property in Dempster-Shafer theory, in Symbolic and Quantitative Approaches", "author": ["Y. Ma", "D.C. Wilkins"], "venue": "Lecture Notes In Computer Science", "citeRegEx": "13", "shortCiteRegEx": "13", "year": 1991}, {"title": "On random sets and belief functions", "author": ["H.T. Nguyen"], "venue": "J. Math. Anal. Appl", "citeRegEx": "16", "shortCiteRegEx": "16", "year": 1978}, {"title": "Probabilistic Reasoning in Intelligent Systems: Networks of Plausible Influence", "author": ["J. Pearl"], "venue": null, "citeRegEx": "17", "shortCiteRegEx": "17", "year": 1988}, {"title": "Pearl: The recovery of causal poly-trees from statistical data, in Uncertainty in Artificial Intelligence", "author": ["J.G. Rebane"], "venue": null, "citeRegEx": "18", "shortCiteRegEx": "18", "year": 1989}, {"title": "The logical foundation of evidential reasoning, Tech", "author": ["E.H. Ruspini"], "venue": "Note 408,", "citeRegEx": "19", "shortCiteRegEx": "19", "year": 1986}, {"title": "Evidence absorption and propagation through evidence reversals", "author": ["R.D. Shachter"], "venue": "Uncertainty in Artificial Intelligence", "citeRegEx": "20", "shortCiteRegEx": "20", "year": 1990}, {"title": "A Mathematical Theory of Evidence", "author": ["G. Shafer"], "venue": null, "citeRegEx": "21", "shortCiteRegEx": "21", "year": 1976}, {"title": "Axioms for probability and belief-function propagation", "author": ["P.P. Shenoy", "G. Shafer"], "venue": "Uncertainty in Artificial Intelligence", "citeRegEx": "23", "shortCiteRegEx": "23", "year": 1990}, {"title": "Boolean reasoning for decision rules generation, in: J. Komorowski, Z.W.Ra\u015b (Eds): Methodologies for Intelligent Systems, Lecture Notes in Artificial Intelligence 689", "author": ["A. Skowron"], "venue": null, "citeRegEx": "24", "shortCiteRegEx": "24", "year": 1993}, {"title": "Boolean reasoning for decision rules generation, a talk at the Intelligent Information Systems Workshop, August\u00f3w", "author": ["A. Skowron"], "venue": null, "citeRegEx": "25", "shortCiteRegEx": "25", "year": 1993}, {"title": "Resolving misunderstandings about belief functions, International Journal of Approximate Reasoning 1992:6:321-344", "author": ["Ph. Smets"], "venue": null, "citeRegEx": "26", "shortCiteRegEx": "26", "year": 1992}, {"title": "Automated construction of sparse Bayesian networks from unstructured probabilistic models and domain information Henrion M., Shachter R.D.,Kanal L.N", "author": ["S. Srinivas", "S. Russel", "A. Agogino"], "venue": "Lemmer J.F.: Uncertainty in Artificial Intelligence", "citeRegEx": "27", "shortCiteRegEx": "27", "year": 1990}], "referenceMentions": [{"referenceID": 3, "context": "Dempster initiated the theory of evidence in his paper [4] and other works, and Shafer developed this theory in his book [21] and other publications.", "startOffset": 55, "endOffset": 58}, {"referenceID": 17, "context": "Dempster initiated the theory of evidence in his paper [4] and other works, and Shafer developed this theory in his book [21] and other publications.", "startOffset": 121, "endOffset": 125}, {"referenceID": 18, "context": "[23] and citations therein.", "startOffset": 0, "endOffset": 4}, {"referenceID": 21, "context": "Smets [26] and also initially Shafer [21] insisted on Bels (measures of uncertainty in the DST) not being connected to any empirical measure (frequency, probability etc.", "startOffset": 6, "endOffset": 10}, {"referenceID": 17, "context": "Smets [26] and also initially Shafer [21] insisted on Bels (measures of uncertainty in the DST) not being connected to any empirical measure (frequency, probability etc.", "startOffset": 37, "endOffset": 41}, {"referenceID": 21, "context": ") considering the domain of DST applications as the one where \u201dwe are ignorant of the existence of probabilities\u201d, and warn that the DST is \u201dnot a model for poorly known probabilities\u201d ([26], p.", "startOffset": 186, "endOffset": 190}, {"referenceID": 3, "context": "The other category of DST interpretations, described by Smets as approaches assuming existence of an underlying probability distribution, which is only approximated by the Bels (called by him PXMY models), is represented by early works of Dempster [4], papers of Kyburg [12], Fagin [7],", "startOffset": 248, "endOffset": 251}, {"referenceID": 10, "context": "The other category of DST interpretations, described by Smets as approaches assuming existence of an underlying probability distribution, which is only approximated by the Bels (called by him PXMY models), is represented by early works of Dempster [4], papers of Kyburg [12], Fagin [7],", "startOffset": 270, "endOffset": 274}, {"referenceID": 6, "context": "The other category of DST interpretations, described by Smets as approaches assuming existence of an underlying probability distribution, which is only approximated by the Bels (called by him PXMY models), is represented by early works of Dempster [4], papers of Kyburg [12], Fagin [7],", "startOffset": 282, "endOffset": 285}, {"referenceID": 7, "context": "[8],, Halpern [10], Skowron [24], Grzyma la-Busse [9] and others.", "startOffset": 0, "endOffset": 3}, {"referenceID": 8, "context": "[8],, Halpern [10], Skowron [24], Grzyma la-Busse [9] and others.", "startOffset": 14, "endOffset": 18}, {"referenceID": 19, "context": "[8],, Halpern [10], Skowron [24], Grzyma la-Busse [9] and others.", "startOffset": 28, "endOffset": 32}, {"referenceID": 21, "context": "Both Smets [26] and Shafer [22] consider such approaches as inadequate as most of them give rise to contradictions and counter intuitiveness.", "startOffset": 11, "endOffset": 15}, {"referenceID": 5, "context": "As Smets states, \u201dFar too often, authors concentrate on the static component (how beliefs are allocated?) and discover many relations between TBM (transferable belief model of Smets) and ULP (upper lower probability) models, inner and outer measures (Fagin and Halpern [6]), random sets (Nguyen [16]), probabilities of provability (Pearl [17]), probabilities of necessity (Ruspini [19]) etc.", "startOffset": 269, "endOffset": 272}, {"referenceID": 12, "context": "As Smets states, \u201dFar too often, authors concentrate on the static component (how beliefs are allocated?) and discover many relations between TBM (transferable belief model of Smets) and ULP (upper lower probability) models, inner and outer measures (Fagin and Halpern [6]), random sets (Nguyen [16]), probabilities of provability (Pearl [17]), probabilities of necessity (Ruspini [19]) etc.", "startOffset": 295, "endOffset": 299}, {"referenceID": 13, "context": "As Smets states, \u201dFar too often, authors concentrate on the static component (how beliefs are allocated?) and discover many relations between TBM (transferable belief model of Smets) and ULP (upper lower probability) models, inner and outer measures (Fagin and Halpern [6]), random sets (Nguyen [16]), probabilities of provability (Pearl [17]), probabilities of necessity (Ruspini [19]) etc.", "startOffset": 338, "endOffset": 342}, {"referenceID": 15, "context": "As Smets states, \u201dFar too often, authors concentrate on the static component (how beliefs are allocated?) and discover many relations between TBM (transferable belief model of Smets) and ULP (upper lower probability) models, inner and outer measures (Fagin and Halpern [6]), random sets (Nguyen [16]), probabilities of provability (Pearl [17]), probabilities of necessity (Ruspini [19]) etc.", "startOffset": 381, "endOffset": 385}, {"referenceID": 21, "context": "\u201d ([26], pp.", "startOffset": 3, "endOffset": 7}, {"referenceID": 21, "context": "Smets ([26],p.", "startOffset": 7, "endOffset": 11}, {"referenceID": 8, "context": "For the purpose of this paper we define the Bel-function as follows (compare also [10], [26], [22]):", "startOffset": 82, "endOffset": 86}, {"referenceID": 21, "context": "For the purpose of this paper we define the Bel-function as follows (compare also [10], [26], [22]):", "startOffset": 88, "endOffset": 92}, {"referenceID": 0, "context": "Definition 1 The Belief Function in the sense of the DS-Theory is defined as Bel:2 \u2192 [0, 1] with \u039e = \u039e1 \u00d7 Xi2 \u00d7 .", "startOffset": 85, "endOffset": 91}, {"referenceID": 0, "context": "Definition 2 The Mass Function in the sense of the DS-Theory is defined as m:2 \u2192 [0, 1] with m(\u2205) = 0", "startOffset": 81, "endOffset": 87}, {"referenceID": 1, "context": "Bacchus in his paper [2] on axiomatization of probability theory and first order logic shows that probability should be considered as a quantifier binding free variables in first order logic expressions just like universal and existential quantifiers do.", "startOffset": 21, "endOffset": 24}, {"referenceID": 1, "context": "See [2] on justification why other types of integration of probability theory and first order logic or propositional logic fail.", "startOffset": 4, "endOffset": 7}, {"referenceID": 0, "context": "Let us define the following Definition 14 \u201dlabelling process function\u201d m ;L : 2 \u2192 [0, 1]: is defined as: m (L) = 1 \u2200B;B\u22082\u039e ,B 6=Lm LP (B) = 0", "startOffset": 82, "endOffset": 88}, {"referenceID": 0, "context": ",Lk : 2 \u2192 [0, 1] such that", "startOffset": 10, "endOffset": 16}, {"referenceID": 21, "context": "As in the light of Smets\u2019 paper [26] we have presented the only correct probabilistic interpretation of the DS theory so far, we feel to be authorized to claim that our philosophical assessment of the DST is the correct one.", "startOffset": 32, "endOffset": 36}, {"referenceID": 21, "context": "The paper of Smets [26] permits us to claim that we have found the true interpretation.", "startOffset": 19, "endOffset": 23}, {"referenceID": 21, "context": "Two main steams of research were distinguished by Smets [26]: probability related approaches and probability discarding approaches", "startOffset": 56, "endOffset": 60}, {"referenceID": 21, "context": "1 Shafer and Smets Shafer [22] and Smets [26] have made some strong statements in defense of the Dempster-Shafer theory against sharp criticism of this theory by its opponents as well as unfortunate users of the DST who wanted to attach it to the dirty reality (that is objectively given databases).", "startOffset": 41, "endOffset": 45}, {"referenceID": 21, "context": "Smets [26] and also initially Shafer [21] insisted on Bels not being connected to any empirical measure (frequency, probability etc.", "startOffset": 6, "endOffset": 10}, {"referenceID": 17, "context": "Smets [26] and also initially Shafer [21] insisted on Bels not being connected to any empirical measure (frequency, probability etc.", "startOffset": 37, "endOffset": 41}, {"referenceID": 21, "context": ") considering the domain of DST applications as the one where \u201dwe are ignorant of the existence of probabilities\u201d, and not one with \u201dpoorly known probabilities\u201d ([26], p.", "startOffset": 162, "endOffset": 166}, {"referenceID": 8, "context": "Compare also Discussion in [10] on the subject.", "startOffset": 27, "endOffset": 31}, {"referenceID": 17, "context": "As statistical properties of Shafer\u2019s [21] notion of evidence are concerned, sufficient criticism has been expressed by Halpern and Fagin ([10] in sections 4-5).", "startOffset": 38, "endOffset": 42}, {"referenceID": 8, "context": "As statistical properties of Shafer\u2019s [21] notion of evidence are concerned, sufficient criticism has been expressed by Halpern and Fagin ([10] in sections 4-5).", "startOffset": 139, "endOffset": 143}, {"referenceID": 8, "context": "The other point raised there that though it is possible to capture properly in belief functions evidence in terms of probability of observations update functions (section 4 of [10]), it is not possible to do the same if we would like to capture evidence in terms of beliefs of observations update functions (section 5 of [10]).", "startOffset": 176, "endOffset": 180}, {"referenceID": 8, "context": "The other point raised there that though it is possible to capture properly in belief functions evidence in terms of probability of observations update functions (section 4 of [10]), it is not possible to do the same if we would like to capture evidence in terms of beliefs of observations update functions (section 5 of [10]).", "startOffset": 321, "endOffset": 325}, {"referenceID": 21, "context": "As Smets probabilistic interpretations are concerned, let us \u201dcontinue\u201d the killer example of [26] on pages 330-331.", "startOffset": 94, "endOffset": 98}, {"referenceID": 21, "context": "We make use of the Smets\u2019 claim that \u201dthe de re and de dicto interpretations lead to the same results\u201d ([26], p.", "startOffset": 104, "endOffset": 108}, {"referenceID": 21, "context": "Smets [26] views the probability theory as a formal mathematical apparatus and hence puts it on the same footing as his view of the DST.", "startOffset": 6, "endOffset": 10}, {"referenceID": 12, "context": "2 DST and Random Sets The canonic random set interpretation [16] is one with a statistical process over set instantiations.", "startOffset": 60, "endOffset": 64}, {"referenceID": 11, "context": "For example, to imitate the logical inference it is frequently assumed that we have a Bel-function describing the actual observed value of a predicate P(x), and a Bel-Function describing the implication \u201dIf P(x) then Q(x)\u201d [13].", "startOffset": 223, "endOffset": 227}, {"referenceID": 3, "context": "3 Upper and Lower Probabilities Still another approach was to handle Bel and Pl as lower and upper probabilities [4].", "startOffset": 113, "endOffset": 116}, {"referenceID": 10, "context": "This approach is of limited use as not every set of lower and upper probabilities leads to Bel/Pl functions [12], hence establishing a unidirectional relationship between probability theory and the DS-theory.", "startOffset": 108, "endOffset": 112}, {"referenceID": 10, "context": "Therefore another approach was to handle them as lower/upper envelops to some probability density function realization [12], [8].", "startOffset": 119, "endOffset": 123}, {"referenceID": 7, "context": "Therefore another approach was to handle them as lower/upper envelops to some probability density function realization [12], [8].", "startOffset": 125, "endOffset": 128}, {"referenceID": 6, "context": "4 Inner and Outer Measures Still another approach was to handle Bels/Pl in probabilistic structures rather than in probabilistic spaces [7].", "startOffset": 136, "endOffset": 139}, {"referenceID": 8, "context": "So it was tried to drop the DS-rule altogether in the probabilistic structures, but then it was not possible to find a meaningful rule for multistage reasoning [10].", "startOffset": 160, "endOffset": 164}, {"referenceID": 19, "context": "An interesting alternative interpretation of the Dempster-Shafer Theory was found within the framework of the rough set theory [24], [9].", "startOffset": 127, "endOffset": 131}, {"referenceID": 19, "context": "- for details see texts of Skowron [24] and Grzyma la-Busse [9]).", "startOffset": 35, "endOffset": 39}, {"referenceID": 20, "context": "The Dempster Rule of combination is interpreted by Skowron [25] as combination of opinions of independent experts, who possibly look at different sets of explanation attributes and hence may propose different explanations.", "startOffset": 59, "endOffset": 63}, {"referenceID": 18, "context": "Three years ago, however, an important paper of Shenoy and Shafer [23] has been published, along papers of other authors similar in spirit, which meant a break-through for application of both bayesian and Dempster-Shafer theories in reasoning systems, because it demonstrated that if joint (bayesian or DS) belief distribution can be decomposed in form of a belief network than it can be both represented in a compact manner and marginalized efficiently by local computations.", "startOffset": 66, "endOffset": 70}, {"referenceID": 9, "context": "tation of (uncertain) knowledge in expert system knowledge bases [11].", "startOffset": 65, "endOffset": 69}, {"referenceID": 16, "context": "Reasoning in bayesian belief networks has been subject of intense research work also earlier [20], [23], [15], [17].", "startOffset": 93, "endOffset": 97}, {"referenceID": 18, "context": "Reasoning in bayesian belief networks has been subject of intense research work also earlier [20], [23], [15], [17].", "startOffset": 99, "endOffset": 103}, {"referenceID": 13, "context": "Reasoning in bayesian belief networks has been subject of intense research work also earlier [20], [23], [15], [17].", "startOffset": 111, "endOffset": 115}, {"referenceID": 13, "context": "There exist methods of imposing various logical constraints on the probability density function and of calculating marginals not only of single variables but of complicated logical expressions over elementary statements of the type X =x (x belonging to the domain of the variable X ) [17].", "startOffset": 284, "endOffset": 288}, {"referenceID": 2, "context": "There exist also methods determining the decomposition of a joint probability distribution given by a sample into a bayesian belief network [3], [18], [1], [27].", "startOffset": 140, "endOffset": 143}, {"referenceID": 14, "context": "There exist also methods determining the decomposition of a joint probability distribution given by a sample into a bayesian belief network [3], [18], [1], [27].", "startOffset": 145, "endOffset": 149}, {"referenceID": 0, "context": "There exist also methods determining the decomposition of a joint probability distribution given by a sample into a bayesian belief network [3], [18], [1], [27].", "startOffset": 151, "endOffset": 154}, {"referenceID": 22, "context": "There exist also methods determining the decomposition of a joint probability distribution given by a sample into a bayesian belief network [3], [18], [1], [27].", "startOffset": 156, "endOffset": 160}, {"referenceID": 8, "context": "It is also known that formally probability distributions can be treated as special cases of Dempster-Shafer belief distributions (with sinngleton focal points) [10].", "startOffset": 160, "endOffset": 164}, {"referenceID": 11, "context": "The main one is the missing frequentist interpretation of the DS-Belief function and hence neither a comparison of the deduction results with experimental data nor any quantitative nor even qualitative conclusions can be drawn from results of deduction in Dempster-Shafer-theory based expert systems [13].", "startOffset": 300, "endOffset": 304}, {"referenceID": 6, "context": "[7], [8], [9], [10], [12], [22], [24]).", "startOffset": 0, "endOffset": 3}, {"referenceID": 7, "context": "[7], [8], [9], [10], [12], [22], [24]).", "startOffset": 5, "endOffset": 8}, {"referenceID": 8, "context": "[7], [8], [9], [10], [12], [22], [24]).", "startOffset": 15, "endOffset": 19}, {"referenceID": 10, "context": "[7], [8], [9], [10], [12], [22], [24]).", "startOffset": 21, "endOffset": 25}, {"referenceID": 19, "context": "[7], [8], [9], [10], [12], [22], [24]).", "startOffset": 33, "endOffset": 37}, {"referenceID": 21, "context": "But, as Smets [26] states, they failed either trying to incorporate Dempster rule or when explaining the nature of probability interval approximation.", "startOffset": 14, "endOffset": 18}, {"referenceID": 13, "context": "ory experienced therefore sharp criticism from several authors in the past [17], [10].", "startOffset": 75, "endOffset": 79}, {"referenceID": 8, "context": "ory experienced therefore sharp criticism from several authors in the past [17], [10].", "startOffset": 81, "endOffset": 85}, {"referenceID": 18, "context": "However, these rules fail to fulfill Shenoy/Shafer axioms of local computation [23] and hence are not tractable in practice.", "startOffset": 79, "endOffset": 83}, {"referenceID": 8, "context": "We have carefully studied several of these approaches and are convinced that the key for many of those failures (beside those mentioned by Halpern in [10]) was: (1) treating the Bel-Pl pair as an interval approximation and (2) viewing combination of evidence as a process of approaching a point estimation.", "startOffset": 150, "endOffset": 154}, {"referenceID": 21, "context": "\u2022 According to Smets [26] there has existed no proper frequentist interpretation of the Dempster-Shafer theory of evidence so far.", "startOffset": 21, "endOffset": 25}, {"referenceID": 21, "context": "Hence this interpretation dismisses the claim of Smets [26] that such an interpretation cannot exist.", "startOffset": 55, "endOffset": 59}, {"referenceID": 13, "context": "This view has been already shaken by works of Pearl [17] and Halpern and Fagin [10].", "startOffset": 52, "endOffset": 56}, {"referenceID": 8, "context": "This view has been already shaken by works of Pearl [17] and Halpern and Fagin [10].", "startOffset": 79, "endOffset": 83}], "year": 2017, "abstractText": null, "creator": "dvips(k) 5.996 Copyright 2016 Radical Eye Software"}}}