{"id": "1704.04408", "review": {"conference": "arxiv", "VERSION": "v1", "DATE_OF_SUBMISSION": "14-Apr-2017", "title": "Incremental learning of high-level concepts by imitation", "abstract": "beginning nowadays, practical robots rarely become a companion in everyday life. choosing to be well - alike accepted superior by natural humans, robots should efficiently understand meanings of calling their partners'motions verbs and target body language, and respond accordingly. learning concepts developed by self imitation actually brings them this ability engaging in a truly user - friendly way.", "histories": [["v1", "Fri, 14 Apr 2017 12:28:19 GMT  (546kb,D)", "http://arxiv.org/abs/1704.04408v1", "6 pages, 5 figures, 2 tables, supplementary material, conference"]], "COMMENTS": "6 pages, 5 figures, 2 tables, supplementary material, conference", "reviews": [], "SUBJECTS": "cs.AI cs.RO", "authors": ["mina alibeigi", "majid nili ahmadabadi", "babak nadjar araabi"], "accepted": false, "id": "1704.04408"}, "pdf": {"name": "1704.04408.pdf", "metadata": {"source": "CRF", "title": "Incremental learning of high-level concepts by imitation", "authors": ["Mina Alibeigi", "Majid Nili Ahmadabadi", "Babak Nadjar Araabi"], "emails": ["minaalibeigi@gmail.com;", "m.alibeigi@ut.ac.ir", "araabi}@ut.ac.ir"], "sections": [{"heading": null, "text": "This paper presents a fast and robust model for Incremental Learning of Concepts by Imitation (ILoCI). In ILoCI, observed multimodal spatio-temporal demonstrations are incrementally abstracted and generalized based on both their perceptual and functional similarities during the imitation. In this method, perceptually similar demonstrations are abstracted by a dynamic model of mirror neuron system. An incremental method is proposed to learn their functional similarities through a limited number of interactions with the teacher. Learning all concepts together by the proposed memory rehearsal enables robot to utilize the common structural relations among concepts which not only expedites the learning process especially at the initial stages, but also improves the generalization ability and the robustness against discrepancies between observed demonstrations.\nPerformance of ILoCI is assessed using standard LASA handwriting benchmark data set. The results show efficiency of ILoCI in concept acquisition, recognition and generation in addition to its robustness against variability in demonstrations.\nIndex Terms\u2014 Concepts, imitation learning, humanoid robots, social human-robot interaction\nI. INTRODUCTION\nNowadays, along with the advances in sensing and learning techniques, applications of robots have been extended from controlled to unstructured and complex environments [2], [3]. Company of robots in humans\u2019 daily life have caused lots of difficulties in designing and programming them, since they should operate in complex environments with unpredictable or time-varying dynamics and interact with humans [2], [3], [4]. Moreover, ordinary users generally do not have enough expertise to program robots for new tasks [2], [3]. In addition, to gain acceptance as an intelligent companion in our everyday life, robots should be sociable. They should understand the meanings of their partners\u2019 motions and body language, and respond accordingly. These requirements and limitations specify the necessity of developing socially interactive learning methods for robots to enable them to\n1Mina Alibeigi is with Cognitive Systems Lab., School of Electrical and Computer Engineering, College of Engineering, University of Tehran, Tehran, Iran minaalibeigi@gmail.com; m.alibeigi@ut.ac.ir\n2Majid Nili Ahmadabadi and Babak Nadjar Araabi are with Cognitive Systems Lab., Control and Intelligent Processing Center of Excellence, School of Electrical and Computer Engineering, College of Engineering, University of Tehran, Tehran, Iran. They are also with School of Cognitive Sciences, Institute for Research in Fundamental Sciences (IPM), Tehran, Iran {mnili, araabi}@ut.ac.ir\n\u2217The elaborate version of this paper is available at [1].\neffectively cope with new environments and tasks instead of being manually pre-programmed [2], [3], [4].\nInspiring by the efficient social learning methods in animals and humans (e.g. mimicry, emulation and goal emulation), researchers proposed natural and user-friendly ways to teach robots, which is called robot programming by demonstration or imitation learning [2], [3], [4]. Although all the social learning methods from the high-level knowledge transfer to the low-level exact regeneration of observed demonstrations are mistakenly known as imitation, but there are stark differences between them [3], [4], [5]. In the highlevel methods, in contrast to the low-level ones, understanding the teacher\u2019s intentions along with regenerating actions are required [3], [4], [5]. In this level, also called \u201dtrue imitation\u201d, skills are abstracted in a generalized symbolic representation. Abstraction, conceptualization and symbolization are bases of true imitation. They bring decreased state-space as one of the requirements of real applications in addition to expediting the knowledge transfer from one agent or situation to another [3], [6], [5], [7], [8].\nIn recent years, abstraction and symbolization have received a great deal of attention by researchers in the field of imitation learning [6], [7], [8], [9], [10], [11]. A considerable portion of the proposed methods inspired by the presumed role of mirror neurons in imitative behaviors of animals and humans [6], [7], [9], [10]. Tani et al. [9], [10], [12] proposed an offline bio-inspired method called recurrent neural networks with parametric biases (RNNPB), as a model of mirror neuron system. In this model, the observed spatio-temporal demonstrations are learned and abstracted by the network based on their perceptual properties. Moreover, Inamura et al. [7] proposed another bio-inspired imitation learning method inspiring the mirror neurons and mimesis theory [13]. In this model, hidden markov models (HMMs) are used for abstracting and symbolizing the observed human motions as well as for recognizing and generating them. Demonstrations of different motion patterns are manually grouped and encoded into distinct HMMs in an offline manner. The number of HMMs representing different behaviors should be known a priori; which is not suitable for real applications. Moreover, the method is not incremental, meaning that it does not give robot the ability to learn concepts gradually and autonomously in cooperation with the partners in order to keep itself socially competent.\nConsidering these shortcomings into account, some methods were proposed for incremental learning of human motions [8], [11]. One of the prominent representative algorithms is proposed by Kadone and Nakamura [8]. This model affords autonomous segmentation, abstraction, mem-\nar X\niv :1\n70 4.\n04 40\n8v 1\n[ cs\n.A I]\n1 4\nA pr\n2 01\n7\norization and recognition of demonstrated motions using associative neural networks. Kulic et al. [11] proposed another well-known incremental and autonomous imitation learning method for acquisition, symbolization, recognition and hierarchical organization of whole body motion patterns using Factorial HMMs.\nAlthough, in all the mentioned studies [7], [8], [9], [10], [11], [12], only the perceptual similarity among observed demonstrations are addressed for abstraction and symbolization, but there are some perceptually different concepts that have the same functional effects or semantic meanings, called relational concepts [6], [14], [15], [16]. These concepts cannot be specified merely based on their perceptual properties and an extra information is needed to acquire them [6], [14], [15], [16]. They are highly prevalence in humans\u2019 social interactions and their everyday life; for instance, disparate gestures to convey the meaning of \u201dHello\u201d in different cultures. Therefore, functional categorization of observed demonstrations is also indispensable for robots coexisting with humans. However, despite the prevalence of relational concepts, not enough researches carried out in this field.\nTo the best of our knowledge, only a limited number of researches has been proposed for learning and abstracting concepts based on both their perceptual and functional properties [6], [14], [16], [17]. One of the basic models is proposed by Mobahi et al. [16]. The model is just applicable for learning concepts from single observations, and is not directly extendible to continuous sequences of observations. In contrast, the proposed methods by Hajmirsadeghi et al. [6], [17] are applicable for learning concepts from spatiotemporal motion sequences using both perceptual and functional properties. In these models, each relational concept is represented by a group of distinct HMM prototypes that each symbolize a different perceptual variant of that concept. Separated modeling of prototypes in these models [6], [17], leads to neglecting their common structural relations and consequently each prototype should relearn the common knowledge again. Therefore, the learning speed decreases and more observations are needed for generalization. This is in contradiction to the main idea of the imitation learning that supports expediting the autonomous training of robots using the minimum number of demonstrations.\nConsidering the mentioned requirements and limitations, this paper presents a gradual and incremental learning algorithm to abstract and generalize the observed multimodal spatio-temporal demonstrations based on both their perceptual and functional characteristics during the imitation. The proposed method comprises low-level and high-level modules. The low-level module abstracts the observed spatiotemporal demonstrations based on their perceptual properties using an RNNPB network [9], [10], [12]. The high-level module acquires relational concepts based on the formed perceptual prototypes and the perceived teacher\u2019s feedbacks. The proposed memory rehearsal procedure enables the robot to gradually extract and utilize the common structural relations among concepts. Therefore, the learning process is expedited especially at the initial stages and the generaliza-\ntion capability is improved as well as the robustness against noise and variations among observed demonstrations.\nII. ILOCI: THE PROPOSED METHOD FOR INCREMENTAL LEARNING OF CONCEPTS BY IMITATION\nIn a nutshell, ILoCI has a low-level and a high-level module. The low-level module of ILoCI is a dynamic model of mirror neuron systems, called RNNPB, which abstracts the observed multimodal spatio-temporal demonstrations as perceptual concepts. For more details on RNNPB refer to [9], [10], [12]. It automatically assigns a PB vector to each acquired perceptual prototype. The acquired PB vectors can be exemplars or prototypes based on their associated information in the high-level module. An exemplar PB vector stands for only one demonstration and a prototype PB vector is the medoid of demonstrations with sufficient perceptual similarity. All the exemplar and prototype PB vectors along with their associated information are stored in a memory in the high-level module, called \u201dMem\u201d (see Table I). A relational concept is defined as a set of perceptually variant exemplars and prototypes in the memory that have same functional properties. The high-level module learns the relational concepts by employing the low-level module and the acquired teacher\u2019s feedbacks through interactions. Fig. 1 illustrates the relations among exemplars, prototypes and concepts. In the sequel, ILoCI is explained in more details."}, {"heading": "A. Learning Phase", "text": "The main procedure of ILoCI is an iterative cycle triggered by the advent of a new teacher\u2019s demonstration. After perceiving a new demonstration, the smoothing, scaling and fitting post-processes are activated consecutively. Then, the processed demonstration is fed into the inverse kinematics function to compute its corresponding motor data. Afterwards, the obtained sensory and motor data are input into the low-level module to recognize the corresponding concept.\nAfter recognizing the concept, the robot performs an action in response to the teacher and receives a reinforcement signal accordingly. Receiving a reward, the robot uses the observed demonstration to update or develop its memory. In contrast, in the case of punishment, robot tries other available concepts until receiving a reward. If none of the former concepts in the robot\u2019s memory are proper for the new demonstration, a new concept will be generated and consolidated in memory. In this way, the robot gradually and incrementally learns and develops the relational concepts in imitation of the teacher to increase its lifetime rewards. In following, steps are described in more details.\n1) Perceiving new demonstration: At first an observation from the teacher goes through pre-processing. Details are described in Section III. After preparing the observed motion sequence, the robot tries to find its associated concept. To do so, the observed motion sequence in terms of sensory and motor data, is fed into Mem.TrajectoryNet and the value of PBobs is computed for it by back propagating and minimizing the error between the target and the predicted values of sensory and motor data. Afterwards, in order to find the most similar consolidated PBs rec in memory, the computed value of PBobs is compared with the untried associated PBs rec values of the consolidated concepts in memory.\nThe concept of the most similar consolidated exemplar or prototype is selected as the guessed concept of the novel observed demonstration (CLobs) and is added to the set of the currently tried concepts (Qtried). Then, in response to the teacher, the robot executes the action with the lowest generation error among the actions with CLobs concept in its memory. After performing the selected action, robot receives a feedback (reward or punishment) from the teacher, which helps it to adjust its concepts. According to the received reinforcement signal, robot faces three situations:\nReceiving positive reinforcement signal with high similarity between the compared PB vectors: A positive feedback shows that the robot has found the concept of the newly observed demonstration correctly. Moreover, it is an evidence of a highly similar exemplar or prototype for the that demonstration in the robot\u2019s memory and fulfills the need of relearning. Therefore, the most similar consolidated demonstration in the robot\u2019s memory is strengthened as a potential candidate for the new observed demonstration.\nReceiving positive reinforcement signal with low similarity between the compared PB vectors: In this case, CLobs has been found correctly but there is no enough perceptually similar exemplar or prototype for that demonstration in the memory. Therefore, the robot should learn a new prototype\nfor that relational concept in its memory and consolidate it through memory rehearsal. After a while, memory may be overpopulated with perceptually similar exemplars and prototypes. Therefore, these demonstrations should be abstracted and clustered in order to select the best representatives of their counterpart clusters. Thus, a complete link hierarchical agglomerative clustering is called when a new exemplar of a concept is added to the memory while the number of samples of both prototypes and exemplars of that concept exceeds Numthreshold . Afterwards, final valid clusters are selected based on two criteria. First, the number of demonstrations should exceed a predefined threshold with at least one exemplar in the cluster. Second, the mean of the pairwise Euclidean distances among PB vectors within the cluster should be less than Dcuto f f (1). This threshold is computed based on the mean (\u00b5) and the standard deviation (\u03c3 ) of the pairwise Euclidean distances across all vectors in the clusters of the desired concept.\nDcuto f f = \u00b5 \u2212Kcuto f f \u2217 \u03c3 (1)\nIn (1), Kcuto f f is a predefined parameter that controls the granularity level of the algorithm. Higher values of Kcuto f f lead to more number of specific prototypes; while lower values bring more general prototypes. However, all variant perceptual prototypes of a concept will be generalized as one relational concept in the high-level module. In our experiments, this parameter is set to an equitable value selected based on some prior knowledge and trial and errors. However, it could be set to a desired value to satisfy the requirements of the application. Fig. 2 illustrates the clustering process when a new demonstration of triangle concept is added to the memory.\nReceiving negative reinforcement signal: In the case of receiving a negative signal, the robot uses its next most similar untried concept (i.e the one not in Qtried), until it receives a positive feedback. If the robot uses all its learned concepts without receiving a positive feedback, then the new observed demonstration will be learned as a novel exemplar of a new concept using memory rehearsal.\n2) No other untried concept exists in the robot\u2019s memory: This situation means that none of the former tried concepts in the robot\u2019s memory were proper for the novel demonstration; therefore, a new concept is generated and the new demonstration is consolidated in the robot\u2019s memory as an exemplar of that concept through memory rehearsal.\n3) Memory rehearsal: Memory rehearsal is performed to learn a novel demonstration of a new concept, or to form a novel prototype for an earlier learned concept. Learning new demonstrations faces memory interference which damages previously learned patterns in the memory. This is due to the distributed representation of all patterns in a single network (various patterns share the same synaptic weights in the network). Despite its numerous advantages, memory interference is one of the challenges of employing distributed representation scheme to abstract patterns. To overcome this difficulty, rehearsing and consolidation according to a biological hypothesis is employed [18].\nIn the memory rehearsal, previous consolidated prototypes and exemplars in Mem are first regenerated using Mem.TrajectoryNet as a long-term memory. To do this, the values of PB neurons and initial input neurons in the network\u2019s input layer are set to the associated values of the consolidated prototypes or exemplars in Mem. Then, the corresponding patterns are regenerated. The regenerated patterns are temporarily stored in a temporal storage called temporal memory. New demonstration is also added to the temporal memory. Next, Mem.TrajectoryNet is trained with all the patterns in the temporal memory, starting from the previous network in order to speed up the network\u2019s training process. After that, Mem is updated based on the new trained Mem.TrajectoryNet and the prior associated information of patterns in temporal memory (e.g. nPrototypes, numSamples, numSteps, initalInfo and conceptLables). Finally, the temporal memory is released.\nLike infants in their early years of life, a na\u0131\u0308ve robot should spend considerable time for learning a sufficient number of patterns through rehearsing and consolidation. In this step, more interactions with teacher are needed to learn concepts during imitation. However, as time passes, the robot has a variety of previously learned concepts in its memory and consequently it responds to the teacher more appropriately with less interactions. But, it is clear that by observing a new concept, the robot should spend time to rehearse and consolidate it. This is similar to the costs and practices that humans experience to learn a new skill.\nB. Inference Phase\nIn an incremental method, the learning process never stops. However, to assess the performance of ILoCI, an inference phase is designed. In this phase, no further feedbacks are provided by the teacher. When observing a new demonstration, the robot uses its current acquired knowledge during the learning phase to recognize the concept of the new demonstration. PBobs is computed and its value is compared with the values of consolidated PBs rec vectors in the memory. The concept of the most similar vector is\nconsidered as the concept of the demonstration and a proper action is responded to the teacher."}, {"heading": "III. RESULTS AND DISCUSSION", "text": "To assess the generalization ability of ILoCI in facing large number of concepts and to make it directly comparable with other competing algorithms, its performance is evaluated on a standard benchmark data set, called LASA [19], [20]. LASA consists of 26 various handwriting motions, collected from pen input using a tablet PC [19], [20] (supplementary data). All motion shapes constitute 22 distinct relational concepts together in total. It is worthy to note that the shapes are incrementally and gradually demonstrated to the robot to learn their relational concepts while imitating and interacting with the teacher.\nTo recognize and generate the observed demonstrations in future, the robot needs to learn the motor data along with the associated observed sensory information. Thereby, the observed teacher\u2019s handwriting motion is scaled and fitted in a selected y-z plane in the robot\u2019s workspace. The selected workspace, depicted as a supplementary figure, assures the feasibility of executing the action by robot considering its physical limitations and valid workspace [21]. Our test platform is the Aldebaran Roboticsr Nao humanoid robot version V3.2 [22]. After scaling and fitting processes, the joint angles of Nao\u2019s right arm will be obtained by applying the built-in inverse kinematics module (IK) on the processed demonstration. To make the results invariant to the possible translational and rotational transformations, the relative displacement values of sensory and motor data are used instead of their absolute values as the inputs to the learning algorithm.\nFive-fold cross-validation is used to examine the performance of the proposed algorithm. Each fold consists of different combinations of demonstrations for training and testing. Variant perceptual representations of each shape are randomly divided to five partitions and each of the partitions is used once as training and four times as testing data set. The ideal situation for the robot is to learn the concepts fast while observing only a few numbers of demonstrations and acquiring more comprehensive prototypes. Thus, only 20% of the demonstrations are used for training and the remaining 80% are used for testing in each fold. In the experiment, Mem.TrajectoryNet has 6 input/output nodes, 4 PB neurons, 25 context and 60 hidden neurons. Moreover, Kcuto f f , Numthreshold and Similaritythreshold are set to 0.5, 3 and 0.1 values, respectively.\nThe average correct classification rate over all five folds is 91.346 \u00b1 3.511 during the inference phase. Table II presents the sparse representation of the average normalized confusion and confidence matrices. The full representation of these matrices are available as supplementary data. True positive values in Table II show that the robot can correctly recognize demonstrations of each relational concept with high confidence values. Although, some motion shapes in LASA data set have considerable degree of similarity with each other, but the algorithm can discriminate them properly.\nThese similarities also explain the false negative values for some shapes like Line and Saeghe as well as Angle, NShape and Worm. However, the low confidence values for the false negatives indicate that the algorithm is unsure about these results. This ability to properly judge its outcomes brings the metacognition property to the robot.\nMoreover, to assess the learning speed and the interaction quality of the proposed algorithm, the reinforcement signals given by the teacher during the learning phase is investigated. Fig. 3 shows the average reinforcement signals (over five folds) given by the teacher. Because of the discrete nature of the reinforcement signals (+1 for reward and -1 for punishment), the results in Fig. 3 has been smoothed with a backward moving average with window length of seven to reflect the expected behavior clearly. Results show that robot is capable of learning the relational concepts of the observed demonstrations very fast especially at the initial stages of learning. According to Fig. 3, in 85% (in average) of the experiments, the robot has correctly recognized the relational concepts in the first interaction after merely learning 45 demonstrations (25% of the data). Two specific reasons can be cited for this notable property. First, when a new demonstration with a novel relational concept is observed, it will be consolidated and probably updated later in the memory as a representative of the perceived relational concept. Consequently, the robot has at least one representation for each relational concept in the memory due to the functional abstraction. Therefore, it can recognize new demonstrations quickly using prototypes in its memory without relearning\nthem from scratch. Second, all consolidated exemplars and prototypes are stored in one memory (distributed representation) through memory rehearsal which brings about the utilization of their common structural relations in order to expedite and enhance the learning process.\nFurthermore, ILoCI unites all different perceptual prototypes of each relational concept in the high-level module based on the teachers\u2019 feedbacks. Fig. 4 shows the symbol space (PB space) of the acquired perceptual prototypes in the fifth fold using non-metric multidimensional scaling (MDS). The figure shows the 2D visualization of the acquired 4D PB vectors. In Fig. 4, all PB vectors associating with different perceptual prototypes of one relational concept are represented with same markers, which shows their unity as one relational concept (e.g. both acquired perceptual prototypes of BendedLine are shown with blue square markers). The results also show that ILoCI almost finds the same number of perceptual prototypes for each relational concept as the number of their real perceptual variants. However, two different perceptual prototypes are acquired here for LShape which has only one distinct perceptual representation since the teachers can draw shapes freely. So, the observed demonstrations might vary and consequently two different perceptual prototypes are formed for LShape. However, it is notable that all variant perceptual prototypes of each relational concept are unified in the high-level module through the functional abstraction.\nIn addition, the proposed algorithm generates smooth and comprehensive prototypes for each relational concept, despite the discrepancies in the observed demonstrations, without any smoothing post-processing. Fig. 5 shows one regenerated example for each acquired relational concept by the robot. The smoothness of the generated prototypes supports the generalization ability of the algorithm. The supplementary videos show the execution of some presented motions by Nao humanoid robot."}, {"heading": "IV. CONCLUSIONS", "text": "This paper introduced an incremental and gradual model for learning concepts by imitation as one of the manifesta-\ntions of true imitation learning. The presented algorithm autonomously and incrementally learns concepts from observed multimodal spatio-temporal demonstrations, based on both their perceptual and functional properties during imitation. It abstracts demonstrations both at the trajectory and the symbolic levels, which is a significant challenge in integrating the symbolic AI and the continuous control of robots [3]. In this method, all perceptual concepts are incrementally learned in a single recurrent neural network through the proposed memory rehearsal. Functional similarities between concepts are also acquired through a limited number of interactions with the teacher. Incremental learning of acquired concepts together through memory rehearsal enables robot to utilize the common structural relations among demonstrations. Consequently the learning process is expedited especially at the initial stages and the generalization ability of the algorithm is also increased.\nThe performance of the proposed method was assessed using standard LASA benchmark data set [19], [20]. Results show that due to abstraction and generalization in both perceptual and functional spaces, robot acquires comprehensive prototypes and therefore it can truly recognize concepts of observed demonstrations during the imitation. The mentioned properties make the proposed method a good choice for real-world applications in which robots should comprehend intentions of their partners while interacting with them."}, {"heading": "V. SUPPLEMENTARY MATERIAL", "text": "The supplementary material is available at https:// goo.gl/ojowSx."}], "references": [{"title": "A fast, robust, and incremental model for learning high-level concepts from human motions by imitation", "author": ["M. Alibeigi", "M.N. Ahmadabadi", "B.N. Araabi"], "venue": "IEEE Transactions on Robotics, vol. 33, no. 1, pp. 153\u2013168, 2017.", "citeRegEx": "1", "shortCiteRegEx": null, "year": 2017}, {"title": "Challenges for robot manipulation in human environments", "author": ["C.C. Kemp", "A. Edsinger", "E. Torres-Jara"], "venue": "IEEE Robotics and Automation Magazine, vol. 14, no. 1, p. 20, 2007.", "citeRegEx": "2", "shortCiteRegEx": null, "year": 2007}, {"title": "Handbook of robotics chapter 59: Robot programming by demonstration", "author": ["A. Billard", "S. Calinon", "R. Dillmann", "S. Schaal"], "venue": "Handbook of Robotics. Springer, 2008.", "citeRegEx": "3", "shortCiteRegEx": null, "year": 2008}, {"title": "Abstraction levels for robotic imitation: Overview and computational approaches", "author": ["M. Lopes", "F. Melo", "L. Montesano", "J. Santos-Victor"], "venue": "From Motor Learning to Interaction Learning in Robots, pp. 313\u2013 355, Springer, 2010.", "citeRegEx": "4", "shortCiteRegEx": null, "year": 2010}, {"title": "Three sources of information in social learning", "author": ["J. Call", "M. Carpenter"], "venue": "Imitation in animals and artifacts, pp. 211\u2013228, 2002.", "citeRegEx": "5", "shortCiteRegEx": null, "year": 2002}, {"title": "Conceptual imitation learning based on perceptual and functional characteristics of action", "author": ["H. Hajimirsadeghi", "M.N. Ahmadabadi", "B.N. Araabi"], "venue": "IEEE Transactions on Autonomous Mental Development, vol. 5, no. 4, pp. 311\u2013325, 2013.", "citeRegEx": "6", "shortCiteRegEx": null, "year": 2013}, {"title": "Embodied symbol emergence based on mimesis theory", "author": ["T. Inamura", "I. Toshima", "H. Tanie", "Y. Nakamura"], "venue": "The International Journal of Robotics Research, vol. 23, no. 4-5, pp. 363\u2013377, 2004.", "citeRegEx": "7", "shortCiteRegEx": null, "year": 2004}, {"title": "Segmentation, memorization, recognition and abstraction of humanoid motions based on correlations and associative memory", "author": ["H. Kadone", "Y. Nakamura"], "venue": "2006 6th IEEE-RAS International Conference on Humanoid Robots, pp. 1\u20136, IEEE, 2006.", "citeRegEx": "8", "shortCiteRegEx": null, "year": 2006}, {"title": "Self-organization of distributedly represented multiple behavior schemata in a mirror system: reviews of robot experiments using rnnpb", "author": ["J. Tani", "M. Ito", "Y. Sugita"], "venue": "Neural Networks, vol. 17, no. 8, pp. 1273\u20131289, 2004.", "citeRegEx": "9", "shortCiteRegEx": null, "year": 2004}, {"title": "On-line imitative interaction with a humanoid robot using a dynamic neural network model of a mirror system", "author": ["M. Ito", "J. Tani"], "venue": "Adaptive Behavior, vol. 12, no. 2, pp. 93\u2013115, 2004.", "citeRegEx": "10", "shortCiteRegEx": null, "year": 2004}, {"title": "Incremental learning, clustering and hierarchy formation of whole body motion patterns using adaptive hidden markov chains", "author": ["D. Kuli\u0107", "W. Takano", "Y. Nakamura"], "venue": "The International Journal of Robotics Research, vol. 27, no. 7, pp. 761\u2013784, 2008.", "citeRegEx": "11", "shortCiteRegEx": null, "year": 2008}, {"title": "Interacting with neurocognitive robots: A dynamical system view", "author": ["J. Tani", "M. Ito"], "venue": "Proc. 2nd int. workshop on man-machine symbiotic systems, kyoto, japan, pp. 123\u2013134, 2005.", "citeRegEx": "12", "shortCiteRegEx": null, "year": 2005}, {"title": "Origins of the modern mind: Three stages in the evolution of culture and cognition", "author": ["M. Donald"], "venue": null, "citeRegEx": "13", "shortCiteRegEx": "13", "year": 1991}, {"title": "Hierarchical concept learning based on functional similarity of actions", "author": ["M. Mahmoodian", "H. Moradi", "M.N. Ahmadabadi", "B.N. Araabi"], "venue": "Robotics and Mechatronics (ICRoM), 2013 First RSI/ISM International Conference on, pp. 1\u20136, IEEE, 2013.", "citeRegEx": "14", "shortCiteRegEx": null, "year": 2013}, {"title": "Categorization, concept learning, and behavior analysis: An introduction", "author": ["T.R. Zentall", "M. Galizio", "T.S. Critchfield"], "venue": "Journal of the experimental analysis of behavior, vol. 78, no. 3, pp. 237\u2013248, 2002.", "citeRegEx": "15", "shortCiteRegEx": null, "year": 2002}, {"title": "A biologically inspired method for conceptual imitation using reinforcement learning", "author": ["H. Mobahi", "M.N. Ahmadabadi", "B. Nadjar Araabi"], "venue": "Applied Artificial Intelligence, vol. 21, no. 3, pp. 155\u2013183, 2007.", "citeRegEx": "16", "shortCiteRegEx": null, "year": 2007}, {"title": "Conceptual imitation learning based on functional effects of action", "author": ["H. Hajimirsadeghi"], "venue": "EUROCON-International Conference on Computer as a Tool (EUROCON), 2011 IEEE, pp. 1\u20136, IEEE, 2011.", "citeRegEx": "17", "shortCiteRegEx": null, "year": 2011}, {"title": "The medial temporal region and memory consolidation: A new hypothesis", "author": ["L.R. Squire", "N.J. Cohen", "L. Nadel"], "venue": "Memory consolidation: Psychobiology of cognition, pp. 185\u2013210, 1984.", "citeRegEx": "18", "shortCiteRegEx": null, "year": 1984}, {"title": "Learning stable nonlinear dynamical systems with gaussian mixture models", "author": ["S.M. Khansari-Zadeh", "A. Billard"], "venue": "IEEE Transactions on Robotics, vol. 27, no. 5, pp. 943\u2013957, 2011.", "citeRegEx": "19", "shortCiteRegEx": null, "year": 2011}, {"title": "Open-source benchmarking for learned reaching motion generation in robotics", "author": ["A. Lemme", "Y. Meirovitch", "M. Khansari-Zadeh", "T. Flash", "A. Billard", "J.J. Steil"], "venue": "Paladyn, Journal of Behavioral Robotics, vol. 6, no. 1, 2015.", "citeRegEx": "20", "shortCiteRegEx": null, "year": 2015}, {"title": "Inverse kinematics based human mimicking system using skeletal tracking technology", "author": ["M. Alibeigi", "S. Rabiee", "M.N. Ahmadabadi"], "venue": "Journal of Intelligent & Robotic Systems, pp. 1\u201319, 2016.", "citeRegEx": "21", "shortCiteRegEx": null, "year": 2016}], "referenceMentions": [{"referenceID": 1, "context": "Nowadays, along with the advances in sensing and learning techniques, applications of robots have been extended from controlled to unstructured and complex environments [2], [3].", "startOffset": 169, "endOffset": 172}, {"referenceID": 2, "context": "Nowadays, along with the advances in sensing and learning techniques, applications of robots have been extended from controlled to unstructured and complex environments [2], [3].", "startOffset": 174, "endOffset": 177}, {"referenceID": 1, "context": "Company of robots in humans\u2019 daily life have caused lots of difficulties in designing and programming them, since they should operate in complex environments with unpredictable or time-varying dynamics and interact with humans [2], [3], [4].", "startOffset": 227, "endOffset": 230}, {"referenceID": 2, "context": "Company of robots in humans\u2019 daily life have caused lots of difficulties in designing and programming them, since they should operate in complex environments with unpredictable or time-varying dynamics and interact with humans [2], [3], [4].", "startOffset": 232, "endOffset": 235}, {"referenceID": 3, "context": "Company of robots in humans\u2019 daily life have caused lots of difficulties in designing and programming them, since they should operate in complex environments with unpredictable or time-varying dynamics and interact with humans [2], [3], [4].", "startOffset": 237, "endOffset": 240}, {"referenceID": 1, "context": "Moreover, ordinary users generally do not have enough expertise to program robots for new tasks [2], [3].", "startOffset": 96, "endOffset": 99}, {"referenceID": 2, "context": "Moreover, ordinary users generally do not have enough expertise to program robots for new tasks [2], [3].", "startOffset": 101, "endOffset": 104}, {"referenceID": 0, "context": "ir \u2217The elaborate version of this paper is available at [1].", "startOffset": 56, "endOffset": 59}, {"referenceID": 1, "context": "effectively cope with new environments and tasks instead of being manually pre-programmed [2], [3], [4].", "startOffset": 90, "endOffset": 93}, {"referenceID": 2, "context": "effectively cope with new environments and tasks instead of being manually pre-programmed [2], [3], [4].", "startOffset": 95, "endOffset": 98}, {"referenceID": 3, "context": "effectively cope with new environments and tasks instead of being manually pre-programmed [2], [3], [4].", "startOffset": 100, "endOffset": 103}, {"referenceID": 1, "context": "mimicry, emulation and goal emulation), researchers proposed natural and user-friendly ways to teach robots, which is called robot programming by demonstration or imitation learning [2], [3], [4].", "startOffset": 182, "endOffset": 185}, {"referenceID": 2, "context": "mimicry, emulation and goal emulation), researchers proposed natural and user-friendly ways to teach robots, which is called robot programming by demonstration or imitation learning [2], [3], [4].", "startOffset": 187, "endOffset": 190}, {"referenceID": 3, "context": "mimicry, emulation and goal emulation), researchers proposed natural and user-friendly ways to teach robots, which is called robot programming by demonstration or imitation learning [2], [3], [4].", "startOffset": 192, "endOffset": 195}, {"referenceID": 2, "context": "Although all the social learning methods from the high-level knowledge transfer to the low-level exact regeneration of observed demonstrations are mistakenly known as imitation, but there are stark differences between them [3], [4], [5].", "startOffset": 223, "endOffset": 226}, {"referenceID": 3, "context": "Although all the social learning methods from the high-level knowledge transfer to the low-level exact regeneration of observed demonstrations are mistakenly known as imitation, but there are stark differences between them [3], [4], [5].", "startOffset": 228, "endOffset": 231}, {"referenceID": 4, "context": "Although all the social learning methods from the high-level knowledge transfer to the low-level exact regeneration of observed demonstrations are mistakenly known as imitation, but there are stark differences between them [3], [4], [5].", "startOffset": 233, "endOffset": 236}, {"referenceID": 2, "context": "In the highlevel methods, in contrast to the low-level ones, understanding the teacher\u2019s intentions along with regenerating actions are required [3], [4], [5].", "startOffset": 145, "endOffset": 148}, {"referenceID": 3, "context": "In the highlevel methods, in contrast to the low-level ones, understanding the teacher\u2019s intentions along with regenerating actions are required [3], [4], [5].", "startOffset": 150, "endOffset": 153}, {"referenceID": 4, "context": "In the highlevel methods, in contrast to the low-level ones, understanding the teacher\u2019s intentions along with regenerating actions are required [3], [4], [5].", "startOffset": 155, "endOffset": 158}, {"referenceID": 2, "context": "They bring decreased state-space as one of the requirements of real applications in addition to expediting the knowledge transfer from one agent or situation to another [3], [6], [5], [7], [8].", "startOffset": 169, "endOffset": 172}, {"referenceID": 5, "context": "They bring decreased state-space as one of the requirements of real applications in addition to expediting the knowledge transfer from one agent or situation to another [3], [6], [5], [7], [8].", "startOffset": 174, "endOffset": 177}, {"referenceID": 4, "context": "They bring decreased state-space as one of the requirements of real applications in addition to expediting the knowledge transfer from one agent or situation to another [3], [6], [5], [7], [8].", "startOffset": 179, "endOffset": 182}, {"referenceID": 6, "context": "They bring decreased state-space as one of the requirements of real applications in addition to expediting the knowledge transfer from one agent or situation to another [3], [6], [5], [7], [8].", "startOffset": 184, "endOffset": 187}, {"referenceID": 7, "context": "They bring decreased state-space as one of the requirements of real applications in addition to expediting the knowledge transfer from one agent or situation to another [3], [6], [5], [7], [8].", "startOffset": 189, "endOffset": 192}, {"referenceID": 5, "context": "In recent years, abstraction and symbolization have received a great deal of attention by researchers in the field of imitation learning [6], [7], [8], [9], [10], [11].", "startOffset": 137, "endOffset": 140}, {"referenceID": 6, "context": "In recent years, abstraction and symbolization have received a great deal of attention by researchers in the field of imitation learning [6], [7], [8], [9], [10], [11].", "startOffset": 142, "endOffset": 145}, {"referenceID": 7, "context": "In recent years, abstraction and symbolization have received a great deal of attention by researchers in the field of imitation learning [6], [7], [8], [9], [10], [11].", "startOffset": 147, "endOffset": 150}, {"referenceID": 8, "context": "In recent years, abstraction and symbolization have received a great deal of attention by researchers in the field of imitation learning [6], [7], [8], [9], [10], [11].", "startOffset": 152, "endOffset": 155}, {"referenceID": 9, "context": "In recent years, abstraction and symbolization have received a great deal of attention by researchers in the field of imitation learning [6], [7], [8], [9], [10], [11].", "startOffset": 157, "endOffset": 161}, {"referenceID": 10, "context": "In recent years, abstraction and symbolization have received a great deal of attention by researchers in the field of imitation learning [6], [7], [8], [9], [10], [11].", "startOffset": 163, "endOffset": 167}, {"referenceID": 5, "context": "A considerable portion of the proposed methods inspired by the presumed role of mirror neurons in imitative behaviors of animals and humans [6], [7], [9], [10].", "startOffset": 140, "endOffset": 143}, {"referenceID": 6, "context": "A considerable portion of the proposed methods inspired by the presumed role of mirror neurons in imitative behaviors of animals and humans [6], [7], [9], [10].", "startOffset": 145, "endOffset": 148}, {"referenceID": 8, "context": "A considerable portion of the proposed methods inspired by the presumed role of mirror neurons in imitative behaviors of animals and humans [6], [7], [9], [10].", "startOffset": 150, "endOffset": 153}, {"referenceID": 9, "context": "A considerable portion of the proposed methods inspired by the presumed role of mirror neurons in imitative behaviors of animals and humans [6], [7], [9], [10].", "startOffset": 155, "endOffset": 159}, {"referenceID": 8, "context": "[9], [10], [12] proposed an offline bio-inspired method called recurrent neural networks with parametric biases (RNNPB), as a model of mirror neuron system.", "startOffset": 0, "endOffset": 3}, {"referenceID": 9, "context": "[9], [10], [12] proposed an offline bio-inspired method called recurrent neural networks with parametric biases (RNNPB), as a model of mirror neuron system.", "startOffset": 5, "endOffset": 9}, {"referenceID": 11, "context": "[9], [10], [12] proposed an offline bio-inspired method called recurrent neural networks with parametric biases (RNNPB), as a model of mirror neuron system.", "startOffset": 11, "endOffset": 15}, {"referenceID": 6, "context": "[7] proposed another bio-inspired imitation learning method inspiring the mirror neurons and mimesis theory [13].", "startOffset": 0, "endOffset": 3}, {"referenceID": 12, "context": "[7] proposed another bio-inspired imitation learning method inspiring the mirror neurons and mimesis theory [13].", "startOffset": 108, "endOffset": 112}, {"referenceID": 7, "context": "Considering these shortcomings into account, some methods were proposed for incremental learning of human motions [8], [11].", "startOffset": 114, "endOffset": 117}, {"referenceID": 10, "context": "Considering these shortcomings into account, some methods were proposed for incremental learning of human motions [8], [11].", "startOffset": 119, "endOffset": 123}, {"referenceID": 7, "context": "One of the prominent representative algorithms is proposed by Kadone and Nakamura [8].", "startOffset": 82, "endOffset": 85}, {"referenceID": 10, "context": "[11] proposed another well-known incremental and autonomous imitation learning method for acquisition, symbolization, recognition and hierarchical organization of whole body motion patterns using Factorial HMMs.", "startOffset": 0, "endOffset": 4}, {"referenceID": 6, "context": "Although, in all the mentioned studies [7], [8], [9], [10],", "startOffset": 39, "endOffset": 42}, {"referenceID": 7, "context": "Although, in all the mentioned studies [7], [8], [9], [10],", "startOffset": 44, "endOffset": 47}, {"referenceID": 8, "context": "Although, in all the mentioned studies [7], [8], [9], [10],", "startOffset": 49, "endOffset": 52}, {"referenceID": 9, "context": "Although, in all the mentioned studies [7], [8], [9], [10],", "startOffset": 54, "endOffset": 58}, {"referenceID": 10, "context": "[11], [12], only the perceptual similarity among observed demonstrations are addressed for abstraction and symbolization, but there are some perceptually different concepts that have the same functional effects or semantic meanings, called relational concepts [6], [14], [15], [16].", "startOffset": 0, "endOffset": 4}, {"referenceID": 11, "context": "[11], [12], only the perceptual similarity among observed demonstrations are addressed for abstraction and symbolization, but there are some perceptually different concepts that have the same functional effects or semantic meanings, called relational concepts [6], [14], [15], [16].", "startOffset": 6, "endOffset": 10}, {"referenceID": 5, "context": "[11], [12], only the perceptual similarity among observed demonstrations are addressed for abstraction and symbolization, but there are some perceptually different concepts that have the same functional effects or semantic meanings, called relational concepts [6], [14], [15], [16].", "startOffset": 260, "endOffset": 263}, {"referenceID": 13, "context": "[11], [12], only the perceptual similarity among observed demonstrations are addressed for abstraction and symbolization, but there are some perceptually different concepts that have the same functional effects or semantic meanings, called relational concepts [6], [14], [15], [16].", "startOffset": 265, "endOffset": 269}, {"referenceID": 14, "context": "[11], [12], only the perceptual similarity among observed demonstrations are addressed for abstraction and symbolization, but there are some perceptually different concepts that have the same functional effects or semantic meanings, called relational concepts [6], [14], [15], [16].", "startOffset": 271, "endOffset": 275}, {"referenceID": 15, "context": "[11], [12], only the perceptual similarity among observed demonstrations are addressed for abstraction and symbolization, but there are some perceptually different concepts that have the same functional effects or semantic meanings, called relational concepts [6], [14], [15], [16].", "startOffset": 277, "endOffset": 281}, {"referenceID": 5, "context": "These concepts cannot be specified merely based on their perceptual properties and an extra information is needed to acquire them [6], [14], [15], [16].", "startOffset": 130, "endOffset": 133}, {"referenceID": 13, "context": "These concepts cannot be specified merely based on their perceptual properties and an extra information is needed to acquire them [6], [14], [15], [16].", "startOffset": 135, "endOffset": 139}, {"referenceID": 14, "context": "These concepts cannot be specified merely based on their perceptual properties and an extra information is needed to acquire them [6], [14], [15], [16].", "startOffset": 141, "endOffset": 145}, {"referenceID": 15, "context": "These concepts cannot be specified merely based on their perceptual properties and an extra information is needed to acquire them [6], [14], [15], [16].", "startOffset": 147, "endOffset": 151}, {"referenceID": 5, "context": "To the best of our knowledge, only a limited number of researches has been proposed for learning and abstracting concepts based on both their perceptual and functional properties [6], [14], [16], [17].", "startOffset": 179, "endOffset": 182}, {"referenceID": 13, "context": "To the best of our knowledge, only a limited number of researches has been proposed for learning and abstracting concepts based on both their perceptual and functional properties [6], [14], [16], [17].", "startOffset": 184, "endOffset": 188}, {"referenceID": 15, "context": "To the best of our knowledge, only a limited number of researches has been proposed for learning and abstracting concepts based on both their perceptual and functional properties [6], [14], [16], [17].", "startOffset": 190, "endOffset": 194}, {"referenceID": 16, "context": "To the best of our knowledge, only a limited number of researches has been proposed for learning and abstracting concepts based on both their perceptual and functional properties [6], [14], [16], [17].", "startOffset": 196, "endOffset": 200}, {"referenceID": 15, "context": "[16].", "startOffset": 0, "endOffset": 4}, {"referenceID": 5, "context": "[6], [17] are applicable for learning concepts from spatiotemporal motion sequences using both perceptual and functional properties.", "startOffset": 0, "endOffset": 3}, {"referenceID": 16, "context": "[6], [17] are applicable for learning concepts from spatiotemporal motion sequences using both perceptual and functional properties.", "startOffset": 5, "endOffset": 9}, {"referenceID": 5, "context": "Separated modeling of prototypes in these models [6], [17], leads to neglecting their common structural relations and consequently each prototype should relearn the common knowledge again.", "startOffset": 49, "endOffset": 52}, {"referenceID": 16, "context": "Separated modeling of prototypes in these models [6], [17], leads to neglecting their common structural relations and consequently each prototype should relearn the common knowledge again.", "startOffset": 54, "endOffset": 58}, {"referenceID": 8, "context": "The low-level module abstracts the observed spatiotemporal demonstrations based on their perceptual properties using an RNNPB network [9], [10], [12].", "startOffset": 134, "endOffset": 137}, {"referenceID": 9, "context": "The low-level module abstracts the observed spatiotemporal demonstrations based on their perceptual properties using an RNNPB network [9], [10], [12].", "startOffset": 139, "endOffset": 143}, {"referenceID": 11, "context": "The low-level module abstracts the observed spatiotemporal demonstrations based on their perceptual properties using an RNNPB network [9], [10], [12].", "startOffset": 145, "endOffset": 149}, {"referenceID": 8, "context": "For more details on RNNPB refer to [9], [10], [12].", "startOffset": 35, "endOffset": 38}, {"referenceID": 9, "context": "For more details on RNNPB refer to [9], [10], [12].", "startOffset": 40, "endOffset": 44}, {"referenceID": 11, "context": "For more details on RNNPB refer to [9], [10], [12].", "startOffset": 46, "endOffset": 50}, {"referenceID": 17, "context": "To overcome this difficulty, rehearsing and consolidation according to a biological hypothesis is employed [18].", "startOffset": 107, "endOffset": 111}, {"referenceID": 18, "context": "number of concepts and to make it directly comparable with other competing algorithms, its performance is evaluated on a standard benchmark data set, called LASA [19], [20].", "startOffset": 162, "endOffset": 166}, {"referenceID": 19, "context": "number of concepts and to make it directly comparable with other competing algorithms, its performance is evaluated on a standard benchmark data set, called LASA [19], [20].", "startOffset": 168, "endOffset": 172}, {"referenceID": 18, "context": "LASA consists of 26 various handwriting motions, collected from pen input using a tablet PC [19], [20] (supplementary data).", "startOffset": 92, "endOffset": 96}, {"referenceID": 19, "context": "LASA consists of 26 various handwriting motions, collected from pen input using a tablet PC [19], [20] (supplementary data).", "startOffset": 98, "endOffset": 102}, {"referenceID": 20, "context": "The selected workspace, depicted as a supplementary figure, assures the feasibility of executing the action by robot considering its physical limitations and valid workspace [21].", "startOffset": 174, "endOffset": 178}, {"referenceID": 2, "context": "It abstracts demonstrations both at the trajectory and the symbolic levels, which is a significant challenge in integrating the symbolic AI and the continuous control of robots [3].", "startOffset": 177, "endOffset": 180}, {"referenceID": 18, "context": "using standard LASA benchmark data set [19], [20].", "startOffset": 39, "endOffset": 43}, {"referenceID": 19, "context": "using standard LASA benchmark data set [19], [20].", "startOffset": 45, "endOffset": 49}], "year": 2017, "abstractText": "Nowadays, robots become a companion in everyday life. To be well-accepted by humans, robots should efficiently understand meanings of their partners\u2019 motions and body language, and respond accordingly. Learning concepts by imitation brings them this ability in a user-friendly way. This paper presents a fast and robust model for Incremental Learning of Concepts by Imitation (ILoCI). In ILoCI, observed multimodal spatio-temporal demonstrations are incrementally abstracted and generalized based on both their perceptual and functional similarities during the imitation. In this method, perceptually similar demonstrations are abstracted by a dynamic model of mirror neuron system. An incremental method is proposed to learn their functional similarities through a limited number of interactions with the teacher. Learning all concepts together by the proposed memory rehearsal enables robot to utilize the common structural relations among concepts which not only expedites the learning process especially at the initial stages, but also improves the generalization ability and the robustness against discrepancies between observed demonstrations. Performance of ILoCI is assessed using standard LASA handwriting benchmark data set. The results show efficiency of ILoCI in concept acquisition, recognition and generation in addition to its robustness against variability in demonstrations.", "creator": "LaTeX with hyperref package"}}}