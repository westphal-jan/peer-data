{"id": "1705.00534", "review": {"conference": "arxiv", "VERSION": "v1", "DATE_OF_SUBMISSION": "27-Apr-2017", "title": "Single image depth estimation by dilated deep residual convolutional neural network and soft-weight-sum inference", "abstract": "now this preliminary paper proposes a single new residual convolutional partial neural network ( fresh cnn ) architecture for allowing single image depth bracket estimation. compared with existing underlying deep cnn based methods, lowering our mapping method obviously achieves much the better results with fewer training using examples provided and model parameters. the further advantages of strengthening our method come from detecting the usage issues of residual dilated convolution, reduced skip connection architecture technique and soft - weight - sum inference. analyzing experimental evaluation procedures on the nyu depth based v2 proxy dataset however shows that our method accurately outperforms fairly other state - of - standard the - art random methods calculated by a margin.", "histories": [["v1", "Thu, 27 Apr 2017 06:07:05 GMT  (1068kb,D)", "http://arxiv.org/abs/1705.00534v1", null]], "reviews": [], "SUBJECTS": "cs.CV cs.LG", "authors": ["bo li", "yuchao dai", "huahui chen", "mingyi he"], "accepted": false, "id": "1705.00534"}, "pdf": {"name": "1705.00534.pdf", "metadata": {"source": "CRF", "title": "SINGLE IMAGE DEPTH ESTIMATION BY DILATED DEEP RESIDUAL CONVOLUTIONAL NEURAL NETWORK AND SOFT-WEIGHT-SUM INFERENCE", "authors": ["Bo Li", "Yuchao Dai", "Huahui Chen", "Mingyi He"], "emails": ["libo.npu@gmail.com"], "sections": [{"heading": "1. INTRODUCTION", "text": "Single image depth estimation aims at predicting pixel-wise depth for a single color image, which has drawn increasing attentions in computer vision, virtual reality and robotic. It is a very challenging problem due to its ill-posedness nature. Recently, there have been considerable efforts in applying deep convolutional neural network (CNN) to this problem and excellent performances have been achieved [1\u20135].\nLi et al. [1] predicted the depth and surface normals from a color image by regression on deep CNN features in a patchbased framework. Liu et al. [2] proposed a CRF-CNN combined learning framework. Wang et al. [3] proposed a CNN architecture for joint semantic labeling and depth prediction. Recent works have shown that the depth estimation problem could benefit from a better CNN architecture design. Eigen et al. [4] proposed a multi-scale architecture that first predicts a coarse global output and then refines it using finer-scale local networks. Very recently, Cao et al. [5] demonstrated that formulating depth estimation as a classification task is better than direct regression. These works demonstrate that, network architecture design plays a central role in improving the performance.\nTo this end, a simple yet effective dilated deep residual CNN architecture is proposed, which could converge with much fewer training examples and model parametres. Furthermore, we analyze the statistic property of our network\n\u2217 libo.npu@gmail.com\noutput, and propose soft-weight-sum inference instead of the traditional hard-threshold method. At last, we conduct evaluations on widly used NYU Depth V2 dataset [6], and outperforms other state-of-the-art methods by a margin."}, {"heading": "2. NETWORK ARCHITECTURE", "text": "Our CNN architecture is illustrated in Fig. 1, in which the weights are initialized from a pre-trained 152 layers residual CNN [7]. The original network [7] was specially designed for image classification problem. In this work, we transform it to be suitable to our depth estimation task.\nFirstly, we remove all the fully connect layers. In this way, we greatly reduce the number of model parameters as more than 80% of the parameters are in the fully connect layers [4, 5]. Although, both [4] and [5] preserved the fully connect layers for long range context information, our experiments show that it is unnecessary in our network for the usage of dilated convolution. Secondly, we take advantage of the dilated convolution, which could expand the receptive field of the neuron without increasing the parameters. Thirdly, with dilated convolution, we could keep the spatial resolution of feature maps. Then, we concatenate intermediate feature maps with the final feature map directly. This skip connection design benefits the multi-scale feature fusion and boundary preserving.\n(1) Dilated Convolution: Recently, dilated convolution is successfully utilized in the CNN design by Yu et al. [8]. Specially:\nLetF : Z2 \u2192 R be a discrete function. Let \u2126r = [r, r]2\u2229 Z2 and let k : \u2126r \u2192 R be a discrete filter of size (2r + 1)2. The discrete convolution filter \u2217 can be expressed as\n(F \u2217 k)(p) = \u2211\ns+t=p\nF (s)k(t). (1)\nWe now generalize this operator. Let l be a dilation factor and let \u2217l be defined as\n(F \u2217l k)(p) = \u2211\ns+lt=p\nF (s)k(t). (2)\nar X\niv :1\n70 5.\n00 53\n4v 1\n[ cs\n.C V\n] 2\n7 A\npr 2\n01 7\nWe refer to \u2217l as a dilated convolution or an l-dilated convolution. The conventional discrete convolution \u2217 is simply the 1-dilated convolution.\n(2) Skip Connection: As the CNN is of hierarchical structure, which means high level neurons have larger receptive field and more abstract features, while the low level neurons have smaller receptive field and more boundary information. We propose to concatenate the high-level feature map and the inter-mediate feature map. The skip connection structure benefits both the multi-scale fusion and boundary preserving."}, {"heading": "3. SOFT-WEIGHT-SUM INFERENCE", "text": "We reformulate depth estimation as classification task by equally discretizing the depth value in log space as [5]. Specially, we train our network with the multinomial logistic loss E = \u2212 1N \u2211N n=1 log(p n k ) followed by softmax\npi = exp xi\u2211m\ni \u2032 =1 exp x i \u2032 . Here, N is the number of training sam-\nples, k the correspondent label of sample n, m is the number of bins.\nA typical predicted score distribution is given in Fig. 2a, where the non-zero score is centralized. Fig. 2b is the confusion matrix on the test set, which present a kind of diagonal dominant structure. In Table 1, we give the pixel-wise accuracy and Relative error (Rel) with respect to different number of discretization bins.\nThese statistic results show that: Even though the model can\u2019t distinguish the detailed depth well, it still learns the correct concept of depth as the non-zero predicted score is centralized and around the right label. These statistic results also explain why increasing the number of bins could not improve the performance further, mainly due to the decrease of the pixel-wise accuracy.\nInspired by these statistic results, we propose the softweight-sum inference. It is worth noting that, this method transforms the predicted score to the continuous depth value in a nature way. Specially:\ndi = exp {wTpi}, (3)\nwhere w is the weight vector of depth bins. pi is the output score for sample i. In our experiments, we set the number of bins to 200."}, {"heading": "4. EXPERIMENTS", "text": "We test our method on the widely used NYU V2 dataset [6]. The raw dataset consists of 464 scenes, captured with a Microsoft Kinect, The official split consists of 249 training and 215 test scenes. We equally sample frames out of each training sequence, resulting in approximately 12k unique images. After off-line augmentations, our dataset comprises approximately 48k RGB-D image pairs.\nImplementation details: Our implementation is based on the CNN toolbox: caffe [9] with an NVIDIA Titian X GPU. The proposed network is trained by using stochastic gradient decent with batch size of 3 (This size is too small, thus we average the gradient of 5 iterations for one back-propagation), momentum of 0.9, and weight decay of 0.0004. Weights are\ninitialized by the pre-trained model from [7]. The network is trained with iterations of 50k by a fixed learning rate 0.001 in the first 30k iterations, then divided by 10 every 10k iterations.\nFor quantitative evaluation, we report errors obtained with the following error metrics, which have been extensively used. Denote d as the ground truth depth, d\u0302 as the estimated depth, and T denotes the set of all points in the images. \u2022 Threshold: % of di s.t. max ( d\u0302i di , di d\u0302i ) = \u03b4 < thr;\n\u2022 Mean relative error (rel): 1|T | \u2211\nd\u2208T |d\u0302\u2212 d|/d; \u2022 Mean log10 error (log10):\n1 |T | \u2211\nd\u2208T |log10 d\u0302\u2212 log10 d|; \u2022 Root mean squared error (rms):\u221a\n1 |T | \u2211 d\u2208T \u2016d\u0302\u2212 d\u2016 2 .\nHere d is the ground truth depth, d\u0302 is the estimated depth, and T denotes the set of all points in the images.\nQuantitative and qualitative evaluation of our method is presented in Table 2 and Fig. 3 respectively. Our method outperforms other state-of-the-art depth estimation methods by a large margin with much fewer training examples and model scale. It is worth noting that, without any post processing, our result is of high visual quality.\nTo further evaluate our method, we conduct experiments to analyze the contribution of each component and the results are illustrated in Table 3. From Table 3 we can see that dilated convolution, skip connection, and soft-weight-sum inference all contribute to final depth estimation. From Fig. 3, we could also observe that the soft-weight-sum inference is beneficial to smooth the depth map while keeping the boundary sharp."}, {"heading": "5. CONCLUSION", "text": "An adapted deep convolutional neural network architecture is proposed for single image depth estimation. We also propose\nthe soft-weight-sum inference instead of the hard-threshold method. Experimental results demonstrate that our proposed method achieves better performance than other state-of-theart methods on NYU Depth V2 dataset."}, {"heading": "6. REFERENCES", "text": "[1] Bo Li, Chunhua Shen, Yuchao Dai, A. van den Hengel, and Mingyi He, \u201cDepth and surface normal estimation from monocular images using regression on deep features and hierarchical crfs,\u201d in CVPR, jun 2015, pp. 1119\u2013 1127.\n[2] Fayao Liu, Chunhua Shen, Guosheng Lin, and Ian Reid, \u201cLearning depth from single monocular images using deep convolutional neural fields,\u201d TPAMI, vol. 38, no. 10, pp. 2024\u20132039, 2016.\n[3] Peng Wang, Xiaohui Shen, Zhe Lin, Scott Cohen, Brian Price, and Alan L Yuille, \u201cTowards unified depth and semantic prediction from a single image,\u201d in CVPR, 2015, pp. 2800\u20132809.\n[4] David Eigen and Rob Fergus, \u201cPredicting depth, surface normals and semantic labels with a common multi-scale convolutional architecture,\u201d in ICCV, 2015, pp. 2650\u2013 2658.\n[5] Yuanzhouhan Cao, Zifeng Wu, and Chunhua Shen, \u201cEstimating depth from monocular images as classification using deep fully convolutional residual networks,\u201d [Online]. Avaliable: https://arxiv.org/abs/1605.02305, 2016.\n[6] Nathan Silberman, Derek Hoiem, Pushmeet Kohli, and Rob Fergus, \u201cIndoor segmentation and support inference from rgbd images,\u201d in ECCV, 2012, pp. 746\u2013760.\n[7] Kaiming He, Xiangyu Zhang, Shaoqing Ren, and Jian Sun, \u201cDeep residual learning for image recognition,\u201d in CVPR, 2016, pp. 770\u2013778.\n[8] Fisher Yu and Vladlen Koltun, \u201cMulti-scale context aggregation by dilated convolutions,\u201d in ICLR, 2016, pp. 1\u201310.\n[9] Yangqing Jia, Evan Shelhamer, Jeff Donahue, Sergey Karayev, Jonathan Long, Ross Girshick, Sergio Guadarrama, and Trevor Darrell, \u201cCaffe: Convolutional architecture for fast feature embedding,\u201d in Proc. ACM Int. Conf. Multimedia, 2014, pp. 675\u2013678."}], "references": [{"title": "Depth and surface normal estimation from monocular images using regression on deep features and hierarchical crfs", "author": ["Bo Li", "Chunhua Shen", "Yuchao Dai", "A. van den Hengel", "Mingyi He"], "venue": "CVPR, jun 2015, pp. 1119\u2013 1127.", "citeRegEx": "1", "shortCiteRegEx": null, "year": 2015}, {"title": "Learning depth from single monocular images using deep convolutional neural fields", "author": ["Fayao Liu", "Chunhua Shen", "Guosheng Lin", "Ian Reid"], "venue": "TPAMI, vol. 38, no. 10, pp. 2024\u20132039, 2016.", "citeRegEx": "2", "shortCiteRegEx": null, "year": 2024}, {"title": "Towards unified depth and semantic prediction from a single image", "author": ["Peng Wang", "Xiaohui Shen", "Zhe Lin", "Scott Cohen", "Brian Price", "Alan L Yuille"], "venue": "CVPR, 2015, pp. 2800\u20132809.", "citeRegEx": "3", "shortCiteRegEx": null, "year": 2015}, {"title": "Predicting depth, surface normals and semantic labels with a common multi-scale convolutional architecture", "author": ["David Eigen", "Rob Fergus"], "venue": "ICCV, 2015, pp. 2650\u2013 2658.", "citeRegEx": "4", "shortCiteRegEx": null, "year": 2015}, {"title": "Estimating depth from monocular images as classification using deep fully convolutional residual networks", "author": ["Yuanzhouhan Cao", "Zifeng Wu", "Chunhua Shen"], "venue": "[Online]. Avaliable: https://arxiv.org/abs/1605.02305, 2016.", "citeRegEx": "5", "shortCiteRegEx": null, "year": 2016}, {"title": "Indoor segmentation and support inference from rgbd images", "author": ["Nathan Silberman", "Derek Hoiem", "Pushmeet Kohli", "Rob Fergus"], "venue": "ECCV, 2012, pp. 746\u2013760.", "citeRegEx": "6", "shortCiteRegEx": null, "year": 2012}, {"title": "Deep residual learning for image recognition", "author": ["Kaiming He", "Xiangyu Zhang", "Shaoqing Ren", "Jian Sun"], "venue": "CVPR, 2016, pp. 770\u2013778.", "citeRegEx": "7", "shortCiteRegEx": null, "year": 2016}, {"title": "Multi-scale context aggregation by dilated convolutions", "author": ["Fisher Yu", "Vladlen Koltun"], "venue": "ICLR, 2016, pp. 1\u201310.", "citeRegEx": "8", "shortCiteRegEx": null, "year": 2016}, {"title": "Caffe: Convolutional architecture for fast feature embedding", "author": ["Yangqing Jia", "Evan Shelhamer", "Jeff Donahue", "Sergey Karayev", "Jonathan Long", "Ross Girshick", "Sergio Guadarrama", "Trevor Darrell"], "venue": "Proc. ACM Int. Conf. Multimedia, 2014, pp. 675\u2013678.", "citeRegEx": "9", "shortCiteRegEx": null, "year": 2014}], "referenceMentions": [{"referenceID": 0, "context": "Recently, there have been considerable efforts in applying deep convolutional neural network (CNN) to this problem and excellent performances have been achieved [1\u20135].", "startOffset": 161, "endOffset": 166}, {"referenceID": 1, "context": "Recently, there have been considerable efforts in applying deep convolutional neural network (CNN) to this problem and excellent performances have been achieved [1\u20135].", "startOffset": 161, "endOffset": 166}, {"referenceID": 2, "context": "Recently, there have been considerable efforts in applying deep convolutional neural network (CNN) to this problem and excellent performances have been achieved [1\u20135].", "startOffset": 161, "endOffset": 166}, {"referenceID": 3, "context": "Recently, there have been considerable efforts in applying deep convolutional neural network (CNN) to this problem and excellent performances have been achieved [1\u20135].", "startOffset": 161, "endOffset": 166}, {"referenceID": 4, "context": "Recently, there have been considerable efforts in applying deep convolutional neural network (CNN) to this problem and excellent performances have been achieved [1\u20135].", "startOffset": 161, "endOffset": 166}, {"referenceID": 0, "context": "[1] predicted the depth and surface normals from a color image by regression on deep CNN features in a patchbased framework.", "startOffset": 0, "endOffset": 3}, {"referenceID": 1, "context": "[2] proposed a CRF-CNN combined learning framework.", "startOffset": 0, "endOffset": 3}, {"referenceID": 2, "context": "[3] proposed a CNN architecture for joint semantic labeling and depth prediction.", "startOffset": 0, "endOffset": 3}, {"referenceID": 3, "context": "[4] proposed a multi-scale architecture that first predicts a coarse global output and then refines it using finer-scale local networks.", "startOffset": 0, "endOffset": 3}, {"referenceID": 4, "context": "[5] demonstrated that formulating depth estimation as a classification task is better than direct regression.", "startOffset": 0, "endOffset": 3}, {"referenceID": 5, "context": "At last, we conduct evaluations on widly used NYU Depth V2 dataset [6], and outperforms other state-of-the-art methods by a margin.", "startOffset": 67, "endOffset": 70}, {"referenceID": 6, "context": "1, in which the weights are initialized from a pre-trained 152 layers residual CNN [7].", "startOffset": 83, "endOffset": 86}, {"referenceID": 6, "context": "The original network [7] was specially designed for image classification problem.", "startOffset": 21, "endOffset": 24}, {"referenceID": 3, "context": "In this way, we greatly reduce the number of model parameters as more than 80% of the parameters are in the fully connect layers [4, 5].", "startOffset": 129, "endOffset": 135}, {"referenceID": 4, "context": "In this way, we greatly reduce the number of model parameters as more than 80% of the parameters are in the fully connect layers [4, 5].", "startOffset": 129, "endOffset": 135}, {"referenceID": 3, "context": "Although, both [4] and [5] preserved the fully connect layers for long range context information, our experiments show that it is unnecessary in our network for the usage of dilated convolution.", "startOffset": 15, "endOffset": 18}, {"referenceID": 4, "context": "Although, both [4] and [5] preserved the fully connect layers for long range context information, our experiments show that it is unnecessary in our network for the usage of dilated convolution.", "startOffset": 23, "endOffset": 26}, {"referenceID": 7, "context": "[8].", "startOffset": 0, "endOffset": 3}, {"referenceID": 6, "context": "The detail of the basic residual block could be refer to [7].", "startOffset": 57, "endOffset": 60}, {"referenceID": 4, "context": "We reformulate depth estimation as classification task by equally discretizing the depth value in log space as [5].", "startOffset": 111, "endOffset": 114}, {"referenceID": 5, "context": "We test our method on the widely used NYU V2 dataset [6].", "startOffset": 53, "endOffset": 56}, {"referenceID": 8, "context": "Implementation details: Our implementation is based on the CNN toolbox: caffe [9] with an NVIDIA Titian X GPU.", "startOffset": 78, "endOffset": 81}, {"referenceID": 6, "context": "initialized by the pre-trained model from [7].", "startOffset": 42, "endOffset": 45}, {"referenceID": 0, "context": "[1] 795 60M 62.", "startOffset": 0, "endOffset": 3}, {"referenceID": 1, "context": "[2] 795 130M 65.", "startOffset": 0, "endOffset": 3}, {"referenceID": 2, "context": "[3] 795 - 60.", "startOffset": 0, "endOffset": 3}, {"referenceID": 3, "context": "[4] 240k 200M 76.", "startOffset": 0, "endOffset": 3}, {"referenceID": 4, "context": "[5] 240k 350M 80.", "startOffset": 0, "endOffset": 3}, {"referenceID": 0, "context": "[1]", "startOffset": 0, "endOffset": 3}, {"referenceID": 3, "context": "[4] Ours hard Ours soft", "startOffset": 0, "endOffset": 3}], "year": 2017, "abstractText": "This paper proposes a new residual convolutional neural network (CNN) architecture for single image depth estimation. Compared with existing deep CNN based methods, our method achieves much better results with fewer training examples and model parameters. The advantages of our method come from the usage of dilated convolution, skip connection architecture and soft-weight-sum inference. Experimental evaluation on the NYU Depth V2 dataset shows that our method outperforms other state-of-the-art methods by a margin.", "creator": "LaTeX with hyperref package"}}}