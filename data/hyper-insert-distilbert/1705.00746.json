{"id": "1705.00746", "review": {"conference": "ACL", "VERSION": "v1", "DATE_OF_SUBMISSION": "2-May-2017", "title": "Chat Detection in an Intelligent Assistant: Combining Task-oriented and Non-task-oriented Spoken Dialogue Systems", "abstract": "recently emerged intelligent assistants deployed on several smartphones consoles and home consumer electronics ( more e. : g., siri and alexa ) tasks can popularly be seen as novel innovative hybrids of domain - specific hardware task - oriented semantic spoken versus dialogue systems while and open - domain non - task - oriented ones. emerging to realize such hybrid dialogue systems, this paper investigates effectively determining remotely whether jointly or not which a user is potentially going upstairs to publicly have accomplished a chat interview with delivering the system. searching to address the resultant lack of benchmark datasets suitable for delivering this hypothetical task, we construct online a new analytic dataset document consisting of 15 ; 160 utterances / collected respectively from the real instant log data of a commercial intelligent conversation assistant ( and will release the resulting dataset to probably facilitate future research activity ). so in addition, hence we should investigate using standardized tweets and semantic web access search queries for correctly handling online open - _ domain user utterances, which characterize the task needs of chat noise detection. robotic experiments indeed demonstrated however that, substantially while simple supervised methods are effective, the use of overlapping the tweets and search queries further improves the f1 - ff score spectrum from ca 86. 65 21 to 87. 53.", "histories": [["v1", "Tue, 2 May 2017 00:23:43 GMT  (442kb,D)", "http://arxiv.org/abs/1705.00746v1", "Accepted by ACL2017. The dataset described in the paper will be available later"]], "COMMENTS": "Accepted by ACL2017. The dataset described in the paper will be available later", "reviews": [], "SUBJECTS": "cs.CL", "authors": ["satoshi akasaki", "nobuhiro kaji"], "accepted": true, "id": "1705.00746"}, "pdf": {"name": "1705.00746.pdf", "metadata": {"source": "CRF", "title": "Chat Detection in an Intelligent Assistant: Combining Task-oriented and Non-task-oriented Spoken Dialogue Systems", "authors": ["Satoshi Akasaki", "Nobuhiro Kaji"], "emails": ["akasaki@tkl.iis.u-tokyo.ac.jp", "nkaji@yahoo-corp.jp"], "sections": [{"heading": "1 Introduction", "text": ""}, {"heading": "1.1 Chat detection", "text": "Conventional studies on spoken dialogue systems (SDS) have investigated either domain-specific task-oriented SDS1 (Williams and Young, 2007) or open-domain non-task-oriented SDS (a.k.a., chatbots or chat-oriented SDS) (Wallace, 2009). The former offers convenience by helping users complete tasks in specific domains, while the latter\n\u2217Work done during internship at Yahoo Japan Corporation.\n1They can be classified as single-domain or multi-domain task-oriented SDS.\noffers entertainment through open-ended chatting (or smalltalk) with users. Although the functionalities offered by the two types of SDS are complementary to each other, little practical effort has been made to combine them. This unfortunately has limited the potential of SDS.\nThis situation is now being changed by the emergence of voice-activated intelligent assistants on smartphones and home electronics (e.g., Siri2 and Alexa3). These intelligent assistants typically perform various tasks (e.g., Web search, weather checking, and alarm setting) while being able to have chats with users. They can be seen as a novel hybrid of multi-domain task-oriented SDS and open-domain non-task-oriented SDS.\nTo realize such hybrid SDS, we have to determine whether or not a user is going to have a chat with the system. For example, if a user says \u201cWhat is your hobby?\u201d it is considered that she is going to have a chat with the system. On the other hand, if she says \u201cSet an alarm at 8 o\u2019clock,\u201d she is probably trying to operate her smartphone. We refer to this task as chat detection and treat it as a binary classification problem.\nChat detection has not been explored enough in past studies. This is primarily because little attempts have been made to develop hybrids of task-oriented and non-task-oriented SDS (see Section 2 for related work). Although task-oriented and non-task-oriented SDS have long research histories, both of them do not require chat detection. Typically, users of task-oriented SDS do not have chats with the systems and users of non-taskoriented SDS always have chats with the systems."}, {"heading": "1.2 Summary of this paper", "text": "In this work, we construct a new dataset for chat detection. As we already discussed, chat detection\n2http://www.apple.com/ios/siri 3https://developer.amazon.com/alexa\nar X\niv :1\n70 5.\n00 74\n6v 1\n[ cs\n.C L\n] 2\nM ay\n2 01\n7\nhas not been explored enough, and thus there exist no benchmark datasets available. To address this situation, we collected 15, 160 user utterances from real log data of a commercial intelligent assistant, and recruited crowd workers to annotate those utterances with whether or not the users are going to have chats with the intelligent assistant. The resulting dataset will be released to facilitate future studies.\nThe technical challenge in chat detection is that we have to handle open-ended utterances of intelligent assistant users. Commercial intelligent assistants have a vast amount of users and they talk about a wide variety of topics especially when chatting with the assistants. It consequently becomes labor-intensive to collect a sufficiently large amount of annotated data for training accurate chat detectors.\nWe develop supervised binary classifiers to perform chat detection. We address the open-ended user utterances, which characterize chat detection, by using unlabeled external resources. We specifically utilize tweets (i.e., Twitter posts) and Web search queries to enhance the supervised classifiers.\nExperimental results demonstrated that, while simple supervised methods are effective, the external resources are able to further improve them. The results demonstrated that the use of the external resources increases over 1 point of F1-score (from 86.21 to 87.53)."}, {"heading": "2 Related Work", "text": ""}, {"heading": "2.1 Previous studies on combining task-oriented and non-task-oriented SDS", "text": "Task-oriented and non-task-oriented SDS have long been investigated independently, and little attempts have been made to develop hybrids of the two types of SDS. As a consequence, previous studies have not investigated chat detection without only a few exceptions.4\nNiculescu and Banchs (2015) explored using non-task-oriented SDS as a back-off mechanism for task-oriented SDS. They, however, did not propose any concrete methods of automatically determining when to switch to non-task-oriented SDS.\n4Unfortunately, we cannot discuss little about chat detection in existing commercial intelligent assistants since most of their technical details have not been disclosed. We make the best effort to compensate for it by comparing the proposed methods with our in-house intelligent assistant in the experiment.\nLee et al. (2007) proposed an example-based dialogue manager to combine task-oriented and nontask-oriented SDS. In such a framework, however, it is difficult to flexibly utilize state-of-the-art supervised classifiers as a component.\nOther studies proposed machine-learning-based frameworks for combining multi-domain taskoriented SDS and non-task-oriented SDS (Wang et al., 2014; Sarikaya, 2017). These assume that several components including a chat detector are already available, and explore integrating those components. They discuss little on how to develop each of the components. On the other hand, the focus of this work is to develop one of those components, a chat detector. Although it lies outside the scope of this paper to explore how to exploit chat detection method in a full dialogue system, the chat detection method is considered to serve, for example, as one component within those frameworks."}, {"heading": "2.2 Intent and domain determination", "text": "Chat detection is related to, but different from, intent and domain determination that have been studied in the field of SDS (Guo et al., 2014; Xu and Sarikaya, 2014; Ravuri and Stolcke, 2015; Kim et al., 2016; Zhang and Wang, 2016).\nBoth intent and domain determination have been investigated in domain-specific task-oriented SDS. Intent determination aims to determine the type of information a user is seeking in singledomain task-oriented SDS. For example, in the ATIS dataset, which is collected from an airline travel information service system, the information type includes flight, city, and so on (Tur et al., 2010). On the other hand, domain determination aims to determine which domain is relevant to a given user utterance in multi-domain task-oriented SDS (Xu and Sarikaya, 2014). Note that it is possible that domain determination is followed by intent determination.\nUnlike intent and domain determination, chat detection targets hybrid systems of multi-domain task-oriented SDS and open-domain non-taskoriented SDS, and aims to determine whether the non-task-oriented component is responsible to a given user utterance or not (i.e., the user is going to have a chat or not). Therefore, the objective of chat detection is different from intent and domain determination.\nIt may be possible to see chat detection as a spe-\ncific problem of domain determination (Sarikaya, 2017). We, nevertheless, discuss it as a different problem because of the uniqueness of the \u201cchat domain.\u201d It greatly differs from ordinary domains in that it plays a role of combining the two different types of SDS that have long been studied independently, rather than combining multiple SDS of the same types. In addition, we discuss the use of external resources, especially tweets, for chat detection. This approach is unique to chat detection and is not considered effective for ordinary domain determination.\nIt is interesting to note that chat detection is not followed by slot-filling unlike intent and domain determination, as far as we use a popular response generator such as seq2seq model (Sutskever et al., 2014) or an information retrieval based approach (Yan et al., 2016). Although joint intent (or domain) determination and slot-filling has been widely studied to improve accuracy (Guo et al., 2014; Zhang and Wang, 2016), the same approach is not feasible in chat detection."}, {"heading": "2.3 Intelligent assistant", "text": "Previous studies on intelligent assistants have not investigated chat detection. Their research topics are centered around those on user behaviors including the prediction of user satisfaction and engagement (Jiang et al., 2015; Kobayashi et al., 2015; Sano et al., 2016; Kiseleva et al., 2016a,b) and gamification (Otani et al., 2016). For example, Jiang et al. (2015) investigated predicting whether users are satisfied with the responses of intelligent assistants by combining diverse features including clicks and utterances. Sano et al. (2016) explored predicting whether users will keep using the intelligent assistants in the future by using long-term usage histories.\nSome earlier works used the Cortana dataset as a benchmark of domain determination (Guo et al., 2014; Xu and Sarikaya, 2014; Kim et al., 2016) or proposed a development framework for Cortana (Crook et al., 2016). Those studies, however, regarded the intelligent assistant as merely one example of multi-domain task-oriented SDS and did not explore chat detection."}, {"heading": "2.4 Non-task-oriented SDS", "text": "Non-task-oriented SDS have long been studied in the research community. While early studies adopted rule-based methods (Weizenbaum, 1966; Wallace, 2009), statistical approaches have re-\ncently gained much popularity (Ritter et al., 2011; Vinyals and Le, 2015). This research direction was pioneered by Ritter et al. (2011), who applied a phrase-based SMT model to the response generation. Later, Vinyals and Le (2015) used the seq2seq model (Sutskever et al., 2014). To date, a number follow-up studies have been made to improve on the response quality (Hasegawa et al., 2013; Shang et al., 2015; Sordoni et al., 2015; Li et al., 2016a,b; Gu et al., 2016; Yan et al., 2016). Those studies assume that users always want to have chats with systems and investigate only methods of generating appropriate responses to given utterances. Chat detection is required for integrating those response generators into intelligent assistants."}, {"heading": "2.5 Use of conversational data", "text": "The recent explosion of conversational data on the Web, especially tweets, have triggered a variety of dialogue studies. Those typically used tweets either for training response generators (c.f., Section 2.4) or for discovering dialogue acts in an unsupervised fashion (Ritter et al., 2010; Higashinaka et al., 2011). This treatment of tweets differs from that in our work."}, {"heading": "3 Chat Detection Dataset", "text": "In this section we explain how we constructed the new benchmark dataset for chat detection. We then analyze the data to provide insights into the actual user behavior."}, {"heading": "3.1 Construction procedure", "text": "We sampled 15, 160 unique utterances5 (i.e., automatic speech recognition results) from the real log data of a commercial intelligent assistant, Yahoo! Voice Assist.6 The log data were collected between Jan. and Aug. 2016. In the log data, some utterances such as \u201cHello\u201d appear frequently. To construct a dataset containing both high and low frequency utterances, we set frequency thresholds7 to divide the utterances into three groups (high, middle, and low frequency) and then randomly sampled the same number of utterances\n5The utterances are all in Japanese. Example utterances given in this paper are English translations.\n6https://v-assist.yahoo.co.jp 7We cannot disclose the exact threshold values so as to keep the detailed statistics of the original log data confidential.\nfrom each of the three groups. During the data collection, we ensured privacy by manually removing utterances that included the full name of a person or detailed address information.\nNext, we recruited crowd workers to annotate the 15, 160 utterances with two labels, CHAT and NONCHAT. The workers annotated the CHAT label when users were going to have chats with the intelligent assistant and annotated the NONCHAT label when users were seeking some information (e.g., searching the Web or checking the weather) or were trying to operate the smartphones (e.g., setting alarms or controlling volume). Note that our intelligent assistant works primarily on smartphones and thus the NONCHAT utterances include many operational instructions such as alarm setting. Example utterances are given in Table 1.\nSeven workers were assigned to each utterance, and the final labels were obtained by majority vote to address the quality issue inherent in crowdsourcing. The last column in Table 1 shows the number of votes that the majority label obtained. For example, five workers provided the CHAT label (and the other two provided the NONCHAT label) to the first utterance \u201cLet\u2019s talk about something.\u201d"}, {"heading": "3.2 Data analysis", "text": "The construction process described above yielded a dataset made up of 4, 833 CHAT and 10, 327 NONCHAT utterances.\nWe investigated the annotation agreement among the crowd workers. Table 2 shows the distribution of the numbers of votes that the majority labels obtained. The annotation given by the seven workers agreed perfectly in 5, 811 of the 15, 160 utterances (38%). Also, at least six workers agreed in the majority of cases, 10, 789 (= 4, 978 + 5, 811) utterances (71%). This indicates high agreement among the workers and the reliability of the annotation results.\nDuring the data construction, we found that a typical confusing case arises when the utterance can be interpreted as an implicit information request. For example, the utterance \u201cI am hungry\u201d can be seen as the user trying to have a chat with the assistant, but it might be the case that she is looking for a local restaurant. Similar examples include \u201cI have a backache\u201d and so on. One solution in this case might be to ask the user a clarification question (Schlo\u0308der and Fernandez, 2015). Such an exploration is left for our future research.\nAdditionally, we manually classified the CHAT utterances according to their dialogue acts to figure out how real users have chats with the intelligent assistant (Table 3). The set of dialogue acts was designed by referring to (Meguro et al., 2010). As shown in Table 3, while some of the utterances are boilerplates (e.g., those in the GREETING act) and thus have limited variety, the majority of the utterances exhibit tremendous diversity. We see\na wide variety of topics including private issues (e.g., \u201cI am free today\u201d) and questions to the assistant (e.g., \u201cAre you angry?\u201d). Also, we even see a movie quote (\u201cMay the force be with you\u201d) and a rooster crow (\u201cCock-a-doodle-doo\u201d) in the MISC act. These clearly represent the open-domain nature of the user utterances in intelligent assistants.\nInterestingly, some users curse at the intelligent assistant probably because it failed to make appropriate responses (see the CURSE act). Although such user behavior would not be observed from paid research participants, we observe a certain amount of curse utterances in the real data."}, {"heading": "4 Detection Method", "text": "We formulate chat detection as a binary classification problem to train supervised classifiers. In this section, we first explain the two types of classifiers explored in this paper, and then investigate the use of external resources for enhancing those classifiers."}, {"heading": "4.1 Base classifiers", "text": "The first classifier utilizes SVM for its popularity and efficiency. It uses character and word ngram (n = 1 and 2) features. It also uses word embedding features (Turian et al., 2010). A skipgram model (Mikolov et al., 2013) is trained on\nthe entire intelligent assistant log8 to learn word embeddings. The embeddings of the words in the utterance are then averaged to produce additional features.\nThe second classifier uses a convolutional neural network (CNN) because it has recently proven to perform well on text classification problems (Kim, 2014; Johnson and Zhang, 2015a,b). We follow (Kim, 2014) to develop a simple CNN that has a single convolution and max-pooling layer followed by the soft-max layer. We use a rectified linear unit (ReLU) as the non-linear activation function. The same word embeddings as SVM are used for the pre-training."}, {"heading": "4.2 Using external resources", "text": "We next investigate using external resources for enhancing the base classifiers. Thanks to the rapid evolution of the Web in the past decade, a variety of textual data including not only conversational (i.e., chat-like) but also non-conversational ones are abundantly available nowadays. These data offer an effective way of enhancing the base classifiers. We specifically use tweets and Web search queries as conversational and non-conversational text data, respectively.\nWe train character-based9 language models on tweets and Web search queries, and use their\n8We used the same log data used in Section 3. The detailed statistics is confidential.\n9We also trained word-based language models in preliminary experiments and found that character-based ones perform consistently better.\nscores (i.e., the normalized log probabilities of the utterance) as two additional features. Let u = c1, c2, . . . , cm be an utterance made up of m characters. Then, the score scorer(u) of the language model trained on the external resource r \u2208 {tweet, query} is defined as\nscorer(u) = 1\nm m\u2211 t=1 log pr(ct | c1, . . . , ct\u22121).\nThe GRU language model is adopted for its superior performance (Cho et al., 2014; Chung et al., 2014). Let xt be the embedding of t-th character and ht be the t-th hidden state. GRU computes the hidden state as\nht = (1\u2212 zt) ht\u22121 + zt h\u0303t zt = \u03c3(W (z)zt +U (z)ht\u22121)\nh\u0303t = tanh(W (h)xt +U (h)(rt ht\u22121)) rt = \u03c3(W (r)xt +U (r)ht\u22121)\nwhere is the element-wise multiplication, \u03c3 is the sigmoid and tanh is the hyperbolic tangent. W(z), U(z), W(h), U(h), W(r), and U(r) are weight matrices. The hidden states are fed to the soft-max to predict the next word.\nWe also use a binary feature indicating whether the utterance appears in the Web search query log or not. We observe that some NONCHAT utterances are made up of single entities such as location and product names. Such utterances are considered to be seeking information on those entities. We therefore use the query log as an entity dictionary to derive a feature indicating whether the utterance is likely to be a single entity.\nThe resulting three features are incorporated into the SVM-based classifier straightforwardly (Figure 1). For the CNN-based classifier, they are provided as additional inputs to the soft-max layer (Figure 2)."}, {"heading": "5 Experimental Results", "text": "We empirically evaluate the proposed methods on the chat detection dataset."}, {"heading": "5.1 Experimental settings", "text": "We performed 10-fold cross validation on the chat detection dataset to train and evaluate the proposed classifiers. In each fold, we used 80%, 10%, and 10% of the data for the training, development, and evaluation, respectively.\nWe used word2vec10 to learn 300 dimensional word embeddings. They were used to induce the additional 300 features for SVM. They were also used as the pre-trained word embeddings for CNN.\nWe used the faster-rnn toolkit11 to train the GRU language models. The size of the embedding and hidden layer was set to 256. Noise contrastive estimation (Gutmann and Hyva\u0308rinen, 2010) was used to train the soft-max function and the number of noise samples was set to 50. Maximum entropy 4-gram models were also trained to yield a combined model (Mikolov et al., 2011).\nThe language models were trained on 100 millions tweets collected between Apr. and July 2016 and 100 million Web search queries issued between Mar. and Jun. 2016. The tweets were sampled from those received replies to collect only conversational tweets (Ritter et al., 2011). The same Web search queries were used to derive the binary feature. Although it is difficult to release those data, we plan to make the feature values available together with the benchmark dataset.\nWe used liblinear12 to train L2-regularized L2-loss SVM. The hyperparameter c was tuned over {2\u221210, 2\u22129, . . . , 210}.\nThe CNN was implemented with chainer.13\nWe tuned the number of feature maps over {100, 150}, and filter region sizes over {{2}, {3}, {1, 2}, {2, 3}, {3, 4}, {1, 2, 3}, {2, 3, 4}}. The mini-batch size was set to 32. The dropout\n10https://code.google.com/archive/p/word2vec 11https://github.com/yandex/faster-rnnlm 12https://www.csie.ntu.edu.tw/\u02dccjlin/liblinear 13http://chainer.org\nrate was set to 0.5. We used Adam (\u03b1 = 0.001, \u03b21 = 0.9, \u03b22 = 0.999, and = 10\u22128) to perform stochastic gradient descent (Kingma and Ba, 2015)."}, {"heading": "5.2 Baselines", "text": "The following baseline methods were implemented for comparison:\nMajority Utterances are always classified as the majority class, NONCHAT.\nTweet GRU Utterances are classified as CHAT if the score of the GRU language model trained on the tweets exceeds a threshold. We used exactly the same GRU language model as the one that was used for deriving the feature. The threshold was calibrated on the development data by maximizing the F1-score of the CHAT class.\nIn-house IA Our in-house intelligent assistant system, which adopts a hybrid of rule-based and example-based approaches. Since we cannot disclose its technical details, the result is presented just for reference."}, {"heading": "5.3 Result", "text": "Table 4 gives the precision, recall, F1-score (for the CHAT class), and overall classification accuracy results. We report only accuracy for Majority baseline. +embed. and +pre-train. represent using the word embedding features for SVM and the pre-trained word embeddings for CNN, respectively. +tweet-query represents using the three features derived from the tweets and Web search query.\nTable 4 represents that both of the classifiers, SVM and CNN, perform accurately. We\nsee that both +embed. and +pre-train. improve the results. The best performing method, SVM+embed.+tweet-query, achieves 92% accuracy and 87% F1-score, outperforming all of the baselines. CNN performed worse than SVM contrary to results reported by recent studies (Kim, 2014). We think this is because the architecture of our CNN is rather simplistic. It might be possible to improve the CNN-based classifier by adopting more complex network, although it is likely to come at the cost of extra training time. Another reason would be that our SVM classifier uses carefully designed features beyond word 1-grams.\nTable 4 also represents that the external resources are effective, improving F1-scores almost 1 points in both SVM and CNN. Table 5 illustrates example utterances and their language model scores. We see that the language models trained on the tweets and queries successfully provide the CHAT utterances with high and low scores, respectively. Table 6 shows chat detection results when each of the three features derived from the external resources is added to SVM+embed. The results represent that they are all worse than SVM+embed.+tweet-query and thus it is crucial to combine all of them for achieving the best performance.\nTable 7 shows examples of feature weights of SVM+embed.+tweet-query. Tweet GRU and query GRU denote the language model score features. The others are word n-gram features. We see that the language model scores have the large positive and negative weights, respectively. This indicates that effectiveness of the language models. We also see that the first person has a large positive weight, while terms related to device controlling (\u201ccall to\u201d and \u201cvolume\u201d) have large negative weights.\nTable 8 represents chat detection results of SVM+embd.+tweet-query across the numbers of votes that the majority label obtained. As expected, we see that all metrics get higher as the number of agreement among the crowd workers becomes larger. In fact, we see as much as 98% accuracy when all seven workers agree. This implies that utterances easy for humans to classify are also easy for the classifiers."}, {"heading": "5.4 Training data size", "text": "We next investigate the effect of the training data size on the classification accuracy.\nFigure 3 illustrates the learning curve. It represents that the classification accuracy improves almost monotonically as the training data size increases. Although our training data is by no means small, the shape of the learning curve nevertheless suggests that further improvement would be achieved by adding more training data. This implies that a very large amount of training data are required for covering open-domain utterances in intelligent assistants.\nThe figure at the same time represents the usefulness of the external resources. We see that SVM+embed.+tweet-query trained on about\n25% of the training data is able to achieve comparable accuracy with SVM+embed. trained on the entire training data. This result suggests that the external resources are able to compensate for the scarcity of annotated data."}, {"heading": "5.5 Utterance length", "text": "We finally investigate how the utterance length correlates with the classification accuracy. Figure 4 illustrates the classification accuracies of SVM+embed. and SVM+embed.+tweet-query for each utterance length in the number of characters.\nFigure 4 reveals that the difference between the two proposed methods is evident in short utter-\nances (i.e., \u2264 5). This is because those utterances are too short to contain sufficient information required for classification, and the additional features are helpful. We note that Japanese writing system uses ideograms and thus even five characters is enough to represent a simple sentence.\nWe also see a clear difference in longer utterances (i.e., 15 \u2264) as well. We consider those long utterances are difficult to classify because some words in the utterances are irrelevant for the classification and the n-gram and embedding features include those irrelevant ones. On the other hand, we consider that the language model scores are good at capturing stylistic information irrespective of the utterance length."}, {"heading": "6 Future Work", "text": "As discussed in Section 3.2, some user utterances such as \u201cI am hungry\u201d are ambiguous in nature and thus are difficult to handle in the current framework. An important future work is to develop a sophisticated dialogue manager to handle such utterances, for example, by making clarification questions (Schlo\u0308der and Fernandez, 2015).\nWe manually investigated the dialogue acts in the chat detection dataset (c.f., Section 3.2). It is interesting to automatically determine the dialogue acts to help producing appropriate system responses. Some related studies exist in such a research direction (Meguro et al., 2010).\nAlthough we used only text data to perform chat detection, we can also utilize contextual information such as the previous utterances (Xu and Sarikaya, 2014), the acoustic information (Jiang et al., 2015), and the user profile (Sano et al., 2016). It is an interesting research topic to use such contextual information beyond text. It is con-\nsidered promising to make use of a neural network for integrating such heterogeneous information.\nAn automatic speech recognition (ASR) error is a popular problem in SDS, and previous studies have proposed sophisticated techniques, including re-ranking (Morbini et al., 2012) and POMDP (Williams and Young, 2007), for addressing the ASR errors. Incorporating these techniques into our methods is also an important future work.\nAlthough the studies on non-task-oriented SDS have made substantial progress in the past few years, it unfortunately remains difficult for the systems to fluently chat with users (Higashinaka et al., 2015). Further efforts on improving nontask-oriented dialogue systems is an important future work."}, {"heading": "7 Conclusion", "text": "This paper investigated chat detection for combining domain-specific task-oriented SDS and opendomain non-task-oriented SDS. To address the scarcity of benchmark datasets for this task, we constructed a new benchmark dataset from the real log data of a commercial intelligent assistant. In addition, we investigated using the external resources, tweets and Web search queries, to handle open-domain user utterances, which characterize the task of chat detection. The empirical experiment demonstrated that the off-the-shelf supervised methods augmented with the external resources perform accurately, outperforming the baseline approaches. We hope that this study contributes to remove the long-standing boundary between task-oriented and non-task-oriented SDS.\nTo facilitate future research, we are going to release the dataset together with the feature values derived from the tweets and Web search queries.14"}, {"heading": "Acknowledgments", "text": "We thank Manabu Sassano, Chikara Hashimoto, Naoki Yoshinaga, and Masashi Toyoda for fruitful discussions and comments. We also thank the anonymous reviewers."}], "references": [{"title": "Empirical evaluation of gated recurrent neural networks on sequence modeling", "author": ["Junyoung Chung", "Caglar Gulcehre", "KyungHyun Cho", "Yoshua Bengio."], "venue": "arXiv:1412.3555.", "citeRegEx": "Chung et al\\.,? 2014", "shortCiteRegEx": "Chung et al\\.", "year": 2014}, {"title": "Task completion platform: A selfserve multi-domain goal oriented dialogue platform", "author": ["beth Krawczyk", "Xiaohu Liu", "Danko Panic", "Vasiliy Radostev", "Nikhil Ramesh", "Jean-Phillipe Robichaud", "Alexandre Rochette", "Logan Stromberg", "Ruhi Sarikaya"], "venue": null, "citeRegEx": "Krawczyk et al\\.,? \\Q2016\\E", "shortCiteRegEx": "Krawczyk et al\\.", "year": 2016}, {"title": "Incorporating copying mechanism in sequence-to-sequence learning", "author": ["Jiatao Gu", "Zhengdong Lu", "Hang Li", "Victor O.K. Li."], "venue": "Proceedings of ACL. pages 1631\u20131640. http://www.aclweb.org/anthology/P16-1154.", "citeRegEx": "Gu et al\\.,? 2016", "shortCiteRegEx": "Gu et al\\.", "year": 2016}, {"title": "Joint semantic utterance classification and slot filling with recursive neural networks", "author": ["Daniel (Zhaohan) Guo", "Gokhan Tur", "Scott Wen tau Yih", "Geoffrey Zweig"], "venue": "In Proceedings of IEEE SLT Workshop", "citeRegEx": "Guo et al\\.,? \\Q2014\\E", "shortCiteRegEx": "Guo et al\\.", "year": 2014}, {"title": "Noisecontrastive estimation: A new estimation principle for unnormalized statistical models", "author": ["Michael Gutmann", "Aapo Hyv\u00e4rinen."], "venue": "Proceedings of AISTATS. pages 297\u2013304.", "citeRegEx": "Gutmann and Hyv\u00e4rinen.,? 2010", "shortCiteRegEx": "Gutmann and Hyv\u00e4rinen.", "year": 2010}, {"title": "Predicting and eliciting addressee\u2019s emotion in online dialogue", "author": ["Takayuki Hasegawa", "Nobuhiro Kaji", "Naoki Yoshinaga", "Masashi Toyoda."], "venue": "Proceedings of ACL. pages 964\u2013972. http://www.aclweb.org/anthology/P13-1095.", "citeRegEx": "Hasegawa et al\\.,? 2013", "shortCiteRegEx": "Hasegawa et al\\.", "year": 2013}, {"title": "Towards taxonomy of errors in chat-oriented dialogue systems", "author": ["Ryuichiro Higashinaka", "Kotaro Funakoshi", "Masahiro Araki", "Hiroshi Tsukahara", "Yuka Kobayashi", "Masahiro Mizukami."], "venue": "Proceedings of SIGDIAL. pages 87\u201395.", "citeRegEx": "Higashinaka et al\\.,? 2015", "shortCiteRegEx": "Higashinaka et al\\.", "year": 2015}, {"title": "Building a conversational model from two-tweets", "author": ["Ryuichiro Higashinaka", "Noriaki Kawamae", "Kugatsu Sadamitsu", "Yasuhiro Minami", "Toyomi Meguro", "Kohji Dohsaka", "Hirohito Inagaki."], "venue": "Proceedings of ASRU. pages 330\u2013335.", "citeRegEx": "Higashinaka et al\\.,? 2011", "shortCiteRegEx": "Higashinaka et al\\.", "year": 2011}, {"title": "Automatic online evaluation of intelligent assistants", "author": ["Jiepu Jiang", "Ahmed Hassan Awadallah", "Rosie Jones", "Umut Ozertem", "Imed Zitouni", "Ranjitha Gurunath Kulkarni", "Omar Zia Khan."], "venue": "Proceedings of WWW. pages 506\u2013516.", "citeRegEx": "Jiang et al\\.,? 2015", "shortCiteRegEx": "Jiang et al\\.", "year": 2015}, {"title": "Effective use of word order for text categorization with convolutional neural networks", "author": ["Rie Johnson", "Tong Zhang."], "venue": "Proceedings of NAACL. pages 103\u2013112. http://www.aclweb.org/anthology/N15-1011.", "citeRegEx": "Johnson and Zhang.,? 2015a", "shortCiteRegEx": "Johnson and Zhang.", "year": 2015}, {"title": "Semi-supervised convolutional neural networks for text categorization via region embedding", "author": ["Rie Johnson", "Tong Zhang."], "venue": "Advances in NIPS, pages 919\u2013927.", "citeRegEx": "Johnson and Zhang.,? 2015b", "shortCiteRegEx": "Johnson and Zhang.", "year": 2015}, {"title": "Intent detection using semantically enriched word embeddings", "author": ["Joo-Kyung Kim", "Gokhan Tur", "Asli Celikyilmaz", "Bin Cao", "Ye-Yi Wang."], "venue": "Proceedings of IEEE SLT Workshop.", "citeRegEx": "Kim et al\\.,? 2016", "shortCiteRegEx": "Kim et al\\.", "year": 2016}, {"title": "Convolutional neural networks for sentence classification", "author": ["Yoon Kim."], "venue": "Proceedings of EMNLP. pages 1746\u20131751. http://www.aclweb.org/anthology/D14-1181.", "citeRegEx": "Kim.,? 2014", "shortCiteRegEx": "Kim.", "year": 2014}, {"title": "Adam: A method for stochastic optimization", "author": ["Diederik P. Kingma", "Jimmy Ba."], "venue": "Proceedings of ICLR.", "citeRegEx": "Kingma and Ba.,? 2015", "shortCiteRegEx": "Kingma and Ba.", "year": 2015}, {"title": "Predicting user satisfaction with intelligent assistants", "author": ["Julia Kiseleva", "Kyle Williams", "Ahmed Hassan Awadallah", "Aidan Crook", "Imed Zitouni", "Tasos Anastasakos."], "venue": "Proceedings of SIGIR. pages 45\u201354.", "citeRegEx": "Kiseleva et al\\.,? 2016a", "shortCiteRegEx": "Kiseleva et al\\.", "year": 2016}, {"title": "Understanding user satisfaction with intelligent assistants", "author": ["Julia Kiseleva", "Kyle Williams", "Ahmed Hassan Awadallah", "Aidan C. Crook", "Imed Zitouni", "Tasos Anastasakos."], "venue": "Proceedings of SIGCHIIR. pages 121\u2013130.", "citeRegEx": "Kiseleva et al\\.,? 2016b", "shortCiteRegEx": "Kiseleva et al\\.", "year": 2016}, {"title": "Effects of game on user engagement with spoken dialogue system", "author": ["Hayato Kobayashi", "Kaori Tanio", "Manabu Sassano."], "venue": "Proceedings of SIGDIAL. pages 422\u2013426. http://aclweb.org/anthology/W154656.", "citeRegEx": "Kobayashi et al\\.,? 2015", "shortCiteRegEx": "Kobayashi et al\\.", "year": 2015}, {"title": "Example-based dialog modeling for practical multi-domain dialog system", "author": ["Cheongjae Lee", "Sangkeun Jung", "Seokhwan Kim", "Gary Geunbae Lee."], "venue": "Speech Communication 51(5):466\u2013484.", "citeRegEx": "Lee et al\\.,? 2007", "shortCiteRegEx": "Lee et al\\.", "year": 2007}, {"title": "A diversity-promoting objective function for neural conversation models", "author": ["Jiwei Li", "Michel Galley", "Chris Brockett", "Jianfeng Gao", "Bill Dolan."], "venue": "Proceedings of NAACL. pages 110\u2013119. http://www.aclweb.org/anthology/N16-1014.", "citeRegEx": "Li et al\\.,? 2016a", "shortCiteRegEx": "Li et al\\.", "year": 2016}, {"title": "A persona-based neural conversation model", "author": ["Jiwei Li", "Michel Galley", "Chris Brockett", "Georgios Spithourakis", "Jianfeng Gao", "Bill Dolan."], "venue": "Proceedings of ACL. pages 994\u20131003. http://www.aclweb.org/anthology/P16-1094.", "citeRegEx": "Li et al\\.,? 2016b", "shortCiteRegEx": "Li et al\\.", "year": 2016}, {"title": "Controlling listening-oriented dialogue using partially observable markov decision processes", "author": ["Toyomi Meguro", "Ryuichiro Higashinaka", "Yasuhiro Minami", "Kohji Dohsaka."], "venue": "Proceedings of Coling. pages 761\u2013769.", "citeRegEx": "Meguro et al\\.,? 2010", "shortCiteRegEx": "Meguro et al\\.", "year": 2010}, {"title": "Strategies for training large scale neural network language models", "author": ["Tomas Mikolov", "Anoop Deoras", "Daniel Povey", "Lukas Burget", "Jan Cernocky."], "venue": "Proceedings of ASRU. pages 196\u2013201.", "citeRegEx": "Mikolov et al\\.,? 2011", "shortCiteRegEx": "Mikolov et al\\.", "year": 2011}, {"title": "Distributed representations of words and phrases and their compositionality", "author": ["Tomas Mikolov", "Ilya Sutskever", "Kai Chen", "Greg Corrado", "Jeffrey Dean."], "venue": "Advances in NIPS. pages 3111\u20133119.", "citeRegEx": "Mikolov et al\\.,? 2013", "shortCiteRegEx": "Mikolov et al\\.", "year": 2013}, {"title": "A reranking approach for recognition and classification of speech input in conversational dia", "author": ["Fabrizio Morbini", "Kartik Audhkhasi", "Ron Artstein", "Maarten Van Segbroeck", "Kenji Sagae", "Panayiotis Georgiou", "David R. Traum", "Shri Narayanan"], "venue": null, "citeRegEx": "Morbini et al\\.,? \\Q2012\\E", "shortCiteRegEx": "Morbini et al\\.", "year": 2012}, {"title": "Strategies to cope with errors in human-machine speech interactions: using chatbots as back-off mechanism for task-oriented dialogues", "author": ["Andreea I. Niculescu", "Rafael E. Banchs."], "venue": "Proceedings of ERRARE.", "citeRegEx": "Niculescu and Banchs.,? 2015", "shortCiteRegEx": "Niculescu and Banchs.", "year": 2015}, {"title": "Large-scale acquisition of commonsense knowledge via a quiz game on a dialogue system", "author": ["Naoki Otani", "Daisuke Kawahara", "Sadao Kurohashi", "Nobuhiro Kaji", "Manabu Sassano."], "venue": "Proceedings of OKBQA. pages 11\u201320.", "citeRegEx": "Otani et al\\.,? 2016", "shortCiteRegEx": "Otani et al\\.", "year": 2016}, {"title": "A comparative study of neural network models for lexical intent classification", "author": ["Suman Ravuri", "Andreas Stolcke."], "venue": "In Proceedings of ASRU. pages 368\u2013374.", "citeRegEx": "Ravuri and Stolcke.,? 2015", "shortCiteRegEx": "Ravuri and Stolcke.", "year": 2015}, {"title": "Unsupervised modeling of twitter conversations", "author": ["Alan Ritter", "Colin Cherry", "Bill Dolan."], "venue": "In Proceedings of NAACL. pages 172\u2013180. http://www.aclweb.org/anthology/N10-1020.", "citeRegEx": "Ritter et al\\.,? 2010", "shortCiteRegEx": "Ritter et al\\.", "year": 2010}, {"title": "Data-driven response generation in social media", "author": ["Alan Ritter", "Colin Cherry", "William B. Dolan."], "venue": "Proceedings of EMNLP. pages 583\u2013593. http://www.aclweb.org/anthology/D11-1054.", "citeRegEx": "Ritter et al\\.,? 2011", "shortCiteRegEx": "Ritter et al\\.", "year": 2011}, {"title": "Prediction of prospective user engagement with intelligent assistants", "author": ["Shumpei Sano", "Nobuhiro Kaji", "Manabu Sassano."], "venue": "Proceedings of ACL. pages 1203\u20131212. http://www.aclweb.org/anthology/P16-1114.", "citeRegEx": "Sano et al\\.,? 2016", "shortCiteRegEx": "Sano et al\\.", "year": 2016}, {"title": "The technology behind personal digital assistants: An overview of the system architecture and key components", "author": ["Ruhi Sarikaya."], "venue": "IEEE Signal Processing Magazine 34(1):67\u201381.", "citeRegEx": "Sarikaya.,? 2017", "shortCiteRegEx": "Sarikaya.", "year": 2017}, {"title": "Clarifying intentions in dialogue: A corpus study", "author": ["Julian J. Schl\u00f6der", "Raquel Fernandez."], "venue": "Proceedings of the 11th International Conference on Computational Semantics. pages 46\u201351. http://www.aclweb.org/anthology/W15-0106.", "citeRegEx": "Schl\u00f6der and Fernandez.,? 2015", "shortCiteRegEx": "Schl\u00f6der and Fernandez.", "year": 2015}, {"title": "Neural responding machine for short-text conversation", "author": ["Lifeng Shang", "Zhengdong Lu", "Hang Li."], "venue": "Proceedings of ACL. pages 1577\u20131586. http://www.aclweb.org/anthology/P15-1152.", "citeRegEx": "Shang et al\\.,? 2015", "shortCiteRegEx": "Shang et al\\.", "year": 2015}, {"title": "A neural network approach to contextsensitive generation of conversational responses", "author": ["Alessandro Sordoni", "Michel Galley", "Michael Auli", "Chris Brockett", "Yangfeng Ji", "Margaret Mitchell", "Jian-Yun Nie", "Jianfeng Gao", "Bill Dolan"], "venue": null, "citeRegEx": "Sordoni et al\\.,? \\Q2015\\E", "shortCiteRegEx": "Sordoni et al\\.", "year": 2015}, {"title": "Sequence to sequence learning with neural networks", "author": ["Ilya Sutskever", "Oriol Vinyals", "Quoc V Le."], "venue": "Advances in NIPS, pages 3104\u20133112.", "citeRegEx": "Sutskever et al\\.,? 2014", "shortCiteRegEx": "Sutskever et al\\.", "year": 2014}, {"title": "What is left to be understood in atis? In Proceedings of IEEE SLT Workshop", "author": ["Gokhan Tur", "Dilek Hakkani-T\u00fcr", "Larry Heck."], "venue": "pages 19\u201324.", "citeRegEx": "Tur et al\\.,? 2010", "shortCiteRegEx": "Tur et al\\.", "year": 2010}, {"title": "Word representations: A simple and general method for semi-supervised learning", "author": ["Joseph Turian", "Lev-Arie Ratinov", "Yoshua Bengio."], "venue": "Proceedings of ACL. pages 384\u2013394. http://www.aclweb.org/anthology/P10-1040.", "citeRegEx": "Turian et al\\.,? 2010", "shortCiteRegEx": "Turian et al\\.", "year": 2010}, {"title": "A neural conversational model", "author": ["Oriol Vinyals", "Quoc Le."], "venue": "Proceedings of Deep Learning Workshop.", "citeRegEx": "Vinyals and Le.,? 2015", "shortCiteRegEx": "Vinyals and Le.", "year": 2015}, {"title": "The Anatomy of A.L.I.C.E., Springer, pages 181\u2013210", "author": ["Richard S. Wallace"], "venue": null, "citeRegEx": "Wallace.,? \\Q2009\\E", "shortCiteRegEx": "Wallace.", "year": 2009}, {"title": "Policy learning for domain selection in an extensible multi-domain spoken dialogue system", "author": ["Zhuoran Wang", "Hongliang Chen", "Guanchun Wang", "Hao Tian", "Hua Wu", "Haifeng Wang."], "venue": "Proceedings of EMNLP. pages 57\u201367.", "citeRegEx": "Wang et al\\.,? 2014", "shortCiteRegEx": "Wang et al\\.", "year": 2014}, {"title": "Eliza\u2013a computer program for the study of natural language communication between man and machine", "author": ["Joseph Weizenbaum."], "venue": "Communications of the ACM 9(1):36\u201345.", "citeRegEx": "Weizenbaum.,? 1966", "shortCiteRegEx": "Weizenbaum.", "year": 1966}, {"title": "Partially observable markov decision processes for spoken dialog systems", "author": ["Jason D. Williams", "Steve Young."], "venue": "Computer Speech & Language 21(2):393\u2013422.", "citeRegEx": "Williams and Young.,? 2007", "shortCiteRegEx": "Williams and Young.", "year": 2007}, {"title": "Contextual domain classification in spoken language understanding systems using recurrent neural network", "author": ["Puyang Xu", "Ruhi Sarikaya."], "venue": "Proceedings of ICASSP. pages 136\u2013140.", "citeRegEx": "Xu and Sarikaya.,? 2014", "shortCiteRegEx": "Xu and Sarikaya.", "year": 2014}, {"title": "Docchat: An information retrieval approach for chatbot engines using unstructured documents", "author": ["Zhao Yan", "Nan Duan", "Junwei Bao", "Peng Chen", "Ming Zhou", "Zhoujun Li", "Jianshe Zhou."], "venue": "Proceedings of ACL. pages 516\u2013525.", "citeRegEx": "Yan et al\\.,? 2016", "shortCiteRegEx": "Yan et al\\.", "year": 2016}, {"title": "A joint model of intent determination and slot filling for spoken language understanding", "author": ["Xiaodong Zhang", "Houfeng Wang."], "venue": "Proceedings of IJCAI. pages 2993\u20132999.", "citeRegEx": "Zhang and Wang.,? 2016", "shortCiteRegEx": "Zhang and Wang.", "year": 2016}], "referenceMentions": [{"referenceID": 41, "context": "Conventional studies on spoken dialogue systems (SDS) have investigated either domain-specific task-oriented SDS1 (Williams and Young, 2007) or open-domain non-task-oriented SDS (a.", "startOffset": 114, "endOffset": 140}, {"referenceID": 38, "context": ", chatbots or chat-oriented SDS) (Wallace, 2009).", "startOffset": 33, "endOffset": 48}, {"referenceID": 17, "context": "Lee et al. (2007) proposed an example-based dialogue manager to combine task-oriented and nontask-oriented SDS.", "startOffset": 0, "endOffset": 18}, {"referenceID": 39, "context": "Other studies proposed machine-learning-based frameworks for combining multi-domain taskoriented SDS and non-task-oriented SDS (Wang et al., 2014; Sarikaya, 2017).", "startOffset": 127, "endOffset": 162}, {"referenceID": 30, "context": "Other studies proposed machine-learning-based frameworks for combining multi-domain taskoriented SDS and non-task-oriented SDS (Wang et al., 2014; Sarikaya, 2017).", "startOffset": 127, "endOffset": 162}, {"referenceID": 3, "context": "Chat detection is related to, but different from, intent and domain determination that have been studied in the field of SDS (Guo et al., 2014; Xu and Sarikaya, 2014; Ravuri and Stolcke, 2015; Kim et al., 2016; Zhang and Wang, 2016).", "startOffset": 125, "endOffset": 232}, {"referenceID": 42, "context": "Chat detection is related to, but different from, intent and domain determination that have been studied in the field of SDS (Guo et al., 2014; Xu and Sarikaya, 2014; Ravuri and Stolcke, 2015; Kim et al., 2016; Zhang and Wang, 2016).", "startOffset": 125, "endOffset": 232}, {"referenceID": 26, "context": "Chat detection is related to, but different from, intent and domain determination that have been studied in the field of SDS (Guo et al., 2014; Xu and Sarikaya, 2014; Ravuri and Stolcke, 2015; Kim et al., 2016; Zhang and Wang, 2016).", "startOffset": 125, "endOffset": 232}, {"referenceID": 11, "context": "Chat detection is related to, but different from, intent and domain determination that have been studied in the field of SDS (Guo et al., 2014; Xu and Sarikaya, 2014; Ravuri and Stolcke, 2015; Kim et al., 2016; Zhang and Wang, 2016).", "startOffset": 125, "endOffset": 232}, {"referenceID": 44, "context": "Chat detection is related to, but different from, intent and domain determination that have been studied in the field of SDS (Guo et al., 2014; Xu and Sarikaya, 2014; Ravuri and Stolcke, 2015; Kim et al., 2016; Zhang and Wang, 2016).", "startOffset": 125, "endOffset": 232}, {"referenceID": 35, "context": "For example, in the ATIS dataset, which is collected from an airline travel information service system, the information type includes flight, city, and so on (Tur et al., 2010).", "startOffset": 158, "endOffset": 176}, {"referenceID": 42, "context": "On the other hand, domain determination aims to determine which domain is relevant to a given user utterance in multi-domain task-oriented SDS (Xu and Sarikaya, 2014).", "startOffset": 143, "endOffset": 166}, {"referenceID": 30, "context": "cific problem of domain determination (Sarikaya, 2017).", "startOffset": 38, "endOffset": 54}, {"referenceID": 34, "context": "It is interesting to note that chat detection is not followed by slot-filling unlike intent and domain determination, as far as we use a popular response generator such as seq2seq model (Sutskever et al., 2014) or an information retrieval based approach (Yan et al.", "startOffset": 186, "endOffset": 210}, {"referenceID": 43, "context": ", 2014) or an information retrieval based approach (Yan et al., 2016).", "startOffset": 51, "endOffset": 69}, {"referenceID": 3, "context": "Although joint intent (or domain) determination and slot-filling has been widely studied to improve accuracy (Guo et al., 2014; Zhang and Wang, 2016), the same approach is not feasible in chat detection.", "startOffset": 109, "endOffset": 149}, {"referenceID": 44, "context": "Although joint intent (or domain) determination and slot-filling has been widely studied to improve accuracy (Guo et al., 2014; Zhang and Wang, 2016), the same approach is not feasible in chat detection.", "startOffset": 109, "endOffset": 149}, {"referenceID": 25, "context": ", 2016a,b) and gamification (Otani et al., 2016).", "startOffset": 28, "endOffset": 48}, {"referenceID": 3, "context": "Some earlier works used the Cortana dataset as a benchmark of domain determination (Guo et al., 2014; Xu and Sarikaya, 2014; Kim et al., 2016) or proposed a development framework for Cortana (Crook et al.", "startOffset": 83, "endOffset": 142}, {"referenceID": 42, "context": "Some earlier works used the Cortana dataset as a benchmark of domain determination (Guo et al., 2014; Xu and Sarikaya, 2014; Kim et al., 2016) or proposed a development framework for Cortana (Crook et al.", "startOffset": 83, "endOffset": 142}, {"referenceID": 11, "context": "Some earlier works used the Cortana dataset as a benchmark of domain determination (Guo et al., 2014; Xu and Sarikaya, 2014; Kim et al., 2016) or proposed a development framework for Cortana (Crook et al.", "startOffset": 83, "endOffset": 142}, {"referenceID": 7, "context": "Their research topics are centered around those on user behaviors including the prediction of user satisfaction and engagement (Jiang et al., 2015; Kobayashi et al., 2015; Sano et al., 2016; Kiseleva et al., 2016a,b) and gamification (Otani et al., 2016). For example, Jiang et al. (2015) investigated predicting whether users are satisfied with the responses of intelligent assistants by combining diverse features including clicks and utterances.", "startOffset": 128, "endOffset": 289}, {"referenceID": 7, "context": "Their research topics are centered around those on user behaviors including the prediction of user satisfaction and engagement (Jiang et al., 2015; Kobayashi et al., 2015; Sano et al., 2016; Kiseleva et al., 2016a,b) and gamification (Otani et al., 2016). For example, Jiang et al. (2015) investigated predicting whether users are satisfied with the responses of intelligent assistants by combining diverse features including clicks and utterances. Sano et al. (2016) explored predicting whether users will keep using the intelligent assistants in the future by using long-term usage histories.", "startOffset": 128, "endOffset": 468}, {"referenceID": 40, "context": "While early studies adopted rule-based methods (Weizenbaum, 1966; Wallace, 2009), statistical approaches have recently gained much popularity (Ritter et al.", "startOffset": 47, "endOffset": 80}, {"referenceID": 38, "context": "While early studies adopted rule-based methods (Weizenbaum, 1966; Wallace, 2009), statistical approaches have recently gained much popularity (Ritter et al.", "startOffset": 47, "endOffset": 80}, {"referenceID": 28, "context": "While early studies adopted rule-based methods (Weizenbaum, 1966; Wallace, 2009), statistical approaches have recently gained much popularity (Ritter et al., 2011; Vinyals and Le, 2015).", "startOffset": 142, "endOffset": 185}, {"referenceID": 37, "context": "While early studies adopted rule-based methods (Weizenbaum, 1966; Wallace, 2009), statistical approaches have recently gained much popularity (Ritter et al., 2011; Vinyals and Le, 2015).", "startOffset": 142, "endOffset": 185}, {"referenceID": 34, "context": "Later, Vinyals and Le (2015) used the seq2seq model (Sutskever et al., 2014).", "startOffset": 52, "endOffset": 76}, {"referenceID": 5, "context": "To date, a number follow-up studies have been made to improve on the response quality (Hasegawa et al., 2013; Shang et al., 2015; Sordoni et al., 2015; Li et al., 2016a,b; Gu et al., 2016; Yan et al., 2016).", "startOffset": 86, "endOffset": 206}, {"referenceID": 32, "context": "To date, a number follow-up studies have been made to improve on the response quality (Hasegawa et al., 2013; Shang et al., 2015; Sordoni et al., 2015; Li et al., 2016a,b; Gu et al., 2016; Yan et al., 2016).", "startOffset": 86, "endOffset": 206}, {"referenceID": 33, "context": "To date, a number follow-up studies have been made to improve on the response quality (Hasegawa et al., 2013; Shang et al., 2015; Sordoni et al., 2015; Li et al., 2016a,b; Gu et al., 2016; Yan et al., 2016).", "startOffset": 86, "endOffset": 206}, {"referenceID": 2, "context": "To date, a number follow-up studies have been made to improve on the response quality (Hasegawa et al., 2013; Shang et al., 2015; Sordoni et al., 2015; Li et al., 2016a,b; Gu et al., 2016; Yan et al., 2016).", "startOffset": 86, "endOffset": 206}, {"referenceID": 43, "context": "To date, a number follow-up studies have been made to improve on the response quality (Hasegawa et al., 2013; Shang et al., 2015; Sordoni et al., 2015; Li et al., 2016a,b; Gu et al., 2016; Yan et al., 2016).", "startOffset": 86, "endOffset": 206}, {"referenceID": 23, "context": "While early studies adopted rule-based methods (Weizenbaum, 1966; Wallace, 2009), statistical approaches have recently gained much popularity (Ritter et al., 2011; Vinyals and Le, 2015). This research direction was pioneered by Ritter et al. (2011), who applied a phrase-based SMT model to the response generation.", "startOffset": 143, "endOffset": 249}, {"referenceID": 23, "context": "While early studies adopted rule-based methods (Weizenbaum, 1966; Wallace, 2009), statistical approaches have recently gained much popularity (Ritter et al., 2011; Vinyals and Le, 2015). This research direction was pioneered by Ritter et al. (2011), who applied a phrase-based SMT model to the response generation. Later, Vinyals and Le (2015) used the seq2seq model (Sutskever et al.", "startOffset": 143, "endOffset": 344}, {"referenceID": 27, "context": "4) or for discovering dialogue acts in an unsupervised fashion (Ritter et al., 2010; Higashinaka et al., 2011).", "startOffset": 63, "endOffset": 110}, {"referenceID": 7, "context": "4) or for discovering dialogue acts in an unsupervised fashion (Ritter et al., 2010; Higashinaka et al., 2011).", "startOffset": 63, "endOffset": 110}, {"referenceID": 31, "context": "One solution in this case might be to ask the user a clarification question (Schl\u00f6der and Fernandez, 2015).", "startOffset": 76, "endOffset": 106}, {"referenceID": 20, "context": "The set of dialogue acts was designed by referring to (Meguro et al., 2010).", "startOffset": 54, "endOffset": 75}, {"referenceID": 36, "context": "It also uses word embedding features (Turian et al., 2010).", "startOffset": 37, "endOffset": 58}, {"referenceID": 22, "context": "A skipgram model (Mikolov et al., 2013) is trained on Figure 1: Feature vector representation of the example utterance \u201cToday\u2019s weather.", "startOffset": 17, "endOffset": 39}, {"referenceID": 12, "context": "We follow (Kim, 2014) to develop a simple CNN that has a single convolution and max-pooling layer followed by the soft-max layer.", "startOffset": 10, "endOffset": 21}, {"referenceID": 0, "context": "The GRU language model is adopted for its superior performance (Cho et al., 2014; Chung et al., 2014).", "startOffset": 63, "endOffset": 101}, {"referenceID": 4, "context": "Noise contrastive estimation (Gutmann and Hyv\u00e4rinen, 2010) was used to train the soft-max function and the number of noise samples was set to 50.", "startOffset": 29, "endOffset": 58}, {"referenceID": 21, "context": "Maximum entropy 4-gram models were also trained to yield a combined model (Mikolov et al., 2011).", "startOffset": 74, "endOffset": 96}, {"referenceID": 28, "context": "pled from those received replies to collect only conversational tweets (Ritter et al., 2011).", "startOffset": 71, "endOffset": 92}, {"referenceID": 13, "context": "999, and = 10\u22128) to perform stochastic gradient descent (Kingma and Ba, 2015).", "startOffset": 56, "endOffset": 77}, {"referenceID": 12, "context": "CNN performed worse than SVM contrary to results reported by recent studies (Kim, 2014).", "startOffset": 76, "endOffset": 87}, {"referenceID": 31, "context": "An important future work is to develop a sophisticated dialogue manager to handle such utterances, for example, by making clarification questions (Schl\u00f6der and Fernandez, 2015).", "startOffset": 146, "endOffset": 176}, {"referenceID": 20, "context": "Some related studies exist in such a research direction (Meguro et al., 2010).", "startOffset": 56, "endOffset": 77}, {"referenceID": 42, "context": "Although we used only text data to perform chat detection, we can also utilize contextual information such as the previous utterances (Xu and Sarikaya, 2014), the acoustic information (Jiang et al.", "startOffset": 134, "endOffset": 157}, {"referenceID": 8, "context": "Although we used only text data to perform chat detection, we can also utilize contextual information such as the previous utterances (Xu and Sarikaya, 2014), the acoustic information (Jiang et al., 2015), and the user profile (Sano et al.", "startOffset": 184, "endOffset": 204}, {"referenceID": 29, "context": ", 2015), and the user profile (Sano et al., 2016).", "startOffset": 30, "endOffset": 49}, {"referenceID": 23, "context": "An automatic speech recognition (ASR) error is a popular problem in SDS, and previous studies have proposed sophisticated techniques, including re-ranking (Morbini et al., 2012) and POMDP (Williams and Young, 2007), for addressing the ASR errors.", "startOffset": 155, "endOffset": 177}, {"referenceID": 41, "context": ", 2012) and POMDP (Williams and Young, 2007), for addressing the ASR errors.", "startOffset": 18, "endOffset": 44}, {"referenceID": 6, "context": "Although the studies on non-task-oriented SDS have made substantial progress in the past few years, it unfortunately remains difficult for the systems to fluently chat with users (Higashinaka et al., 2015).", "startOffset": 179, "endOffset": 205}], "year": 2017, "abstractText": "Recently emerged intelligent assistants on smartphones and home electronics (e.g., Siri and Alexa) can be seen as novel hybrids of domain-specific taskoriented spoken dialogue systems and open-domain non-task-oriented ones. To realize such hybrid dialogue systems, this paper investigates determining whether or not a user is going to have a chat with the system. To address the lack of benchmark datasets for this task, we construct a new dataset consisting of 15, 160 utterances collected from the real log data of a commercial intelligent assistant (and will release the dataset to facilitate future research activity). In addition, we investigate using tweets and Web search queries for handling open-domain user utterances, which characterize the task of chat detection. Experiments demonstrated that, while simple supervised methods are effective, the use of the tweets and search queries further improves the F1-score from 86.21 to 87.53.", "creator": "LaTeX with hyperref package"}}}