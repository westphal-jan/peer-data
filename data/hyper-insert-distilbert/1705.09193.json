{"id": "1705.09193", "review": {"conference": "arxiv", "VERSION": "v1", "DATE_OF_SUBMISSION": "25-May-2017", "title": "Classification of Quantitative Light-Induced Fluorescence Images Using Convolutional Neural Network", "abstract": "images are an other important data source for standardized diagnosis and treatment of human oral procedure diseases. learning the manual forensic classification of pediatric images automatically may lead to misdiagnosis detection or mistreatment due to subjective errors. in making this experimental paper an image classification model based data on convolutional neural network is applied usually to determine quantitative light - induced fluorescence screening images. additionally the deep fiber neural network outperforms rivals other state drugs of the art on shallow classification classification models in automatically predicting hygiene labels derived derived from creating three different comprehensive dental plaque assessment panel scores. the model directly allows benefits from having multi - prism channel filtered representation of the images compared resulting in improved performance indicators when, so besides the red colour white channel, additional green and blue colour highlight channels are used.", "histories": [["v1", "Thu, 25 May 2017 14:21:40 GMT  (434kb)", "http://arxiv.org/abs/1705.09193v1", "Full version of ICANN 2017 submission"]], "COMMENTS": "Full version of ICANN 2017 submission", "reviews": [], "SUBJECTS": "cs.CV cs.LG", "authors": ["sultan imangaliyev", "monique h van der veen", "catherine m c volgenant", "bruno g loos", "bart j f keijser", "wim crielaard", "evgeni levin"], "accepted": false, "id": "1705.09193"}, "pdf": {"name": "1705.09193.pdf", "metadata": {"source": "CRF", "title": "Classification of Quantitative Light-Induced Fluorescence Images Using Convolutional Neural Network", "authors": ["Sultan Imangaliyev", "Monique H. van der Veen", "Catherine M. C. Volgenant", "Bruno G. Loos", "Bart J. F. Keijser", "Wim Crielaard", "Evgeni Levin"], "emails": ["s.imangaliyev@vumc.nl"], "sections": [{"heading": null, "text": "ar X\niv :1\n70 5.\n09 19\n3v 1\n[ cs\n.C V\n] 2\nKeywords: Deep Learning, Convolutional Neural Networks, Bioinformatics, Quantitative Light-Induced Fluorescence"}, {"heading": "1 Introduction", "text": "Diagnosis and therapy in many areas of medicine, including dentistry, nowadays extensively rely on technological advances in biomedical imaging. One of the challenges in the diagnosis of dental patients during daily practice is assessment of their dental plaque level. A novel way to look at this plaque is the use of a Quantitative Light-induced Fluorescence (QLF) camera. When the QLF-camera is used some dental plaque fluoresces red, which is suggested to be an indication for the pathogenicity of the dental plaque [18].\nIn this paper we apply deep artificial neural network on QLF-images to make a predictive classification model, where class separation is based on the amount\n\u22c6 Corresponding author.\nof red fluorescent dental plaque disclosed in such images. Although both intraexaminer and inter-examiner reliability of manual assessment of QLF-images are shown to be high [19], this may become expensive and laborious if the number of images is large. Therefore, there is a need to automate this procedure by implementing a computer-based system for assessment of QLF-images. Existing computer programs developed for this goal have several drawbacks which limit efficiency of QLF-images assessment. They require that the images must have been captured under the fixed circumstances such as camera geometry, focal distance and ambient light conditions [9], which is hard to achieve under clinical settings.\nThe problem mentioned above could be solved by the use of Deep Learning models, because descriptive features can be learnt directly from raw data representations [10] being insensitive to ambient conditions and natural image variability. Since images have a special two-dimensional structure, a group of Deep Learning methods called Convolutional Neural Network (CNN) explicitly uses the advantages of such a representation [7,12]. Applications of CNN may include both non-biological [2] and biological images [3].\nThe aim of this paper is to describe the novel application of CNN to QLFimages obtained during clinical intervention study [18]. Furthermore, we compare the performances of the CNN and several state of the art classification models. We tested all of these models on three existing plaque assessment scoring systems. We also checked the influence of adding various colour channels on the model performance. Possible differences were explained based on the biological nature of the problem and based on the properties of these models. Previous studies on this topic either focused on only a single plaque scoring system without providing detailed analysis of results [6] or used small dataset of different images and different network architecture [8]."}, {"heading": "2 Materials and Methods", "text": ""}, {"heading": "2.1 Convolutional Neural Networks", "text": "Many of the modern deep learning models utilize very deep architectures to achieve superhuman performance in solving object recognition problems [15,17]. One of such architectures is a novel ultra-deep residual learning network (ResNet) [4]. This architecture can be implemented by adding so called \u2019shortcut connections\u2019 [5] which skip one or more layers. They perform a mapping so that their outputs are added to the outputs of the stacked layes. The whole network can be trained and implemented by using common libraries without modifying the solvers, hence adding neither extra parameters nor computational complexity. ResNet and many other architectures [7,12] use convolutional operator in extracting useful feature mappings in image classification task. Generally, given the filter K \u2208 R(2h1+1)\u00d7(2h2+1), the discrete convolution of the image I with\nfilter K is given by\n(I \u2217K)r,s :=\nh1\u2211\nu=\u2212h1\nh2\u2211\nv=\u2212h2\nKu,vIr+u,s+v. (1)\nLet layer l \u2208 Z be a convolutional layer. The ith feature map in layer l,\ndenoted Y (l) i , is computed as\nY (l) i = B (l) i +\nm (l\u22121) 1\u2211\nj=1\nK (l) i,j \u2217 Y (l\u22121) j , (2)\nwhere B (l) i is a bias matrix and K (l) i,j is the filter of size (2h (l) 1 + 1)\u00d7 (2h (l) 2 + 1) connecting the jth feature map in layer (l\u2212 1) with the ith feature map in layer l [12]."}, {"heading": "2.2 Dataset", "text": "The analyzed 427 QLF-images were taken during a clinical intervention study [18] which was conducted at the Academic Centre for Dentistry Amsterdam. Those images were translated into a combined dataset of three colour channels with 216\u00d7 324 raw pixel intensity values in each of them. In total, three different experiments were performed on labels derived from plaque scoring systems such as Red Fluorescent Plaque Percentage (RF-PP) [18], Red Fluorescent modified Quigley-Hein index (RF-mQH) [19] and modified Sillness-Loe Plaque index (mSLP) [20]."}, {"heading": "2.3 Experimental Setup", "text": "The CNN model was implemented on an NVIDIA GeForce GTX Titan X Graphics Processing Unit (GPU) using the Theano package [1]. To compare the influence of different colour channels three dataset compositions were tested which are only Red, Red with Green, or full RGB representations. To compare the CNN performance with the performance of the other models, experiments were performed using various shallow classification models implemented in the Scikitlearn package [14] such as Logistic Regression (LR), Support Vector Machines Classifier with Gaussian Kernel (SVMC-K), Support Vector Machines Classifier with Linear Kernel (SVMC-L), Gaussian Nave Bayes Classifier (GNB), Gradient Boosting Classifier (GBC), K-Neighbors Classifier (KNC), and Random Forest Classifier (RFC).\nHyperparameters of those models were selected via an exhaustive grid search with stratified shuffled cross-validation procedure so that 80% of the dataset was used as a training set, 10% as a validation set, and the rest 10% as a test set. All binary models were adapted to a multiclass setting by using a one-versus-all approach. The predictive performance of the models was assessed by calculating the F1-score [16]. The reported final F1-score was obtained by averaging the results of ten random shuffles with fixed test-train splits across all models."}, {"heading": "3 Results and Discussion", "text": ""}, {"heading": "3.1 Model Performance Evaluation", "text": "Results of experiments for RF-PP, RF-mQH and mSLP labels are provided in Figure 1, Figure 2, and Figure 3 respectively. As it is seen from Figure 1, in the experiment with the RF-PP label, most of the models have a perfect classification performance on the training dataset, but a poor performance on the test dataset. Moreover, the results indicate that using only the Red channel results in a relatively good and comparable performance between both SVM models and Logistic Regression. Adding the Green and especially Blue channels improves the performance of CNN compared to the other models. As a result, the best model (CNN) provided a 0.76 \u00b1 0.05 F1-score on the test set and a 0.89 \u00b1 0.11 F1-score on the training set.\nSimilar to the experiment with RF-PP labels, results depicted in Figure 2, and Figure 3 clearly demonstrate the advantage of CNN over the other models, especially after adding the Green channel. As a result, the best model (CNN) provided a 0.54 \u00b1 0.07 F1-score on the test set for RF-mQH labels and a 0.40 \u00b1 0.08 F1-score on the test set for mSLP labels. However, unlike in the RF-PP case, adding the Blue channel did not improve and even decreased the performance for most of the models. Also, there is a clear difference between the performance of models applied on RF-PP and the other labels overall. Namely, even the best model\u2019s F1-scores are in the interval [0.4, 0.55] in the experiments with RF-mQH and mSLP labels, which are much less than the 0.76 achieved in experiments with the RF-PP label."}, {"heading": "3.2 Advantages of the Deep Learning Model", "text": "The results of the models\u2019 predictive performance evaluation clearly demonstrated advantage of the CNN model over the other models. In general, the predictive performance of the model on previously unseen data, i.e., its generalization can be improved if certain a priori information about the problem is added into the choice of the model architecture [11]. In case of images, domain information about the problem can be utilized by a model if such a model is able to learn spatial information between the pixels of an image. This property is explicitly embedded into the CNN model via a discrete convolution operation [10]. In the case of the QLF-images the model may learn, for example, the intensity of red colour associated with plaque, or the sharpness of edges between gingiva and teeth as well as between teeth. Classification results shown in Figures 1, 2, 3 indicate the robustness of CNN to overfitting despite image variability. Other models used in this study do not directly embed spatial information unique for image pixel representation, thus these models have poorer generalization properties and result in a lower classification performance on previously unseen data.\nThe QLF-images are a good example of images where learning invariant representation is crucial for good predictive performance. Typical examples of QLF-images for each of the three RF-PP classes are provided in Figure 4. As\nseen from this figure, these images were taken under various conditions such as slightly different focal distances, rotations, angles and not all images are perfectly centered or focussed to get better resolution. Besides ambient conditions during taking the pictures, the definition of every person is unique. Thus, there is a risk that standard models would overfit and learn variations in angles and distances which are not important for the plaque assessment."}, {"heading": "3.3 Influence of Multi-channel Representation", "text": "For the experiments on the RF-PP plaque labels, the CNN model results in superior performance over the other classification models if all three colour channels\nwere used. In the experiments on the RF-mQH and mSLP labels, an improvement was achieved when only the Green channel was added. Moreover, the standard deviation of the training performance tends to be narrower compared to when the model is applied on the Red channel only. This is especially true for GBC, LR and both of the SVMC models.\nThe Red over Green ratio of pixel values is generally used to identify red fluorescent plaque. Therefore, previous work performed on QLF-images [13,9] used the Red over Green pixel intensities\u2019 ratio instead of using the Red channel\u2019s pixel intensity values only. The Green channel helps to distinguish plaque from gingiva, since they have slightly different pixel values in Green channel of RGB representation. As for adding the Blue channel, due to technical implementation of the QLF-camera, the blue backscattered light is expected to produce sharper defined edges in images with little red fluorescent plaque, in comparison to images with a thicker plaque. The CNN model incorporates usage of all three colour channels without calculating ratios, thus numerically it is more stable and preferable. Based on these results we conclude that the CNN model benefits from multi-channel representation of the images. Precisely speaking, the CNN model efficiently and explicitly uses the fact that each colour channel contains important information relevant to the classification task."}, {"heading": "4 Conclusion", "text": "In this study, we applied the CNN model for the automatic classification of red fluorescent dental plaque images. A comparison with several other state of the art shallow classification methods clearly showed the advantage of the CNN model in achieving a higher prediction performance. Such a result was possible because the CNN model directly learns invariant feature representations from raw pixel intensity values without engineering of hand-crafted features. We expect that Deep Learning of red fluorescent dental plaque images can help dental practitioners to perform efficient fluorescent plaque assessments and thus contribute to the improvement of patients\u2019 oral health."}], "references": [{"title": "Theano: Deep learning on GPUs with Python", "author": ["J. Bergstra", "F. Bastien", "O. Breuleux", "P. Lamblin", "R. Pascanu", "O. Delalleau", "G. Desjardins", "D. Warde-Farley", "I. Goodfellow", "A Bergeron"], "venue": "NIPS 2011, BigLearning Workshop, Granada, Spain", "citeRegEx": "1", "shortCiteRegEx": null, "year": 2011}, {"title": "DeepPainter: Painter classification using deep convolutional autoencoders", "author": ["O.E. David", "N.S. Netanyahu"], "venue": "International Conference on Artificial Neural Networks. pp. 20\u201328. Springer", "citeRegEx": "2", "shortCiteRegEx": null, "year": 2016}, {"title": "Dermatologist-level classification of skin cancer with deep neural networks", "author": ["A. Esteva", "B. Kuprel", "R.A. Novoa", "J. Ko", "S.M. Swetter", "H.M. Blau", "S. Thrun"], "venue": "Nature 542(7639), 115\u2013118", "citeRegEx": "3", "shortCiteRegEx": null, "year": 2017}, {"title": "Deep residual learning for image recognition", "author": ["K. He", "X. Zhang", "S. Ren", "J. Sun"], "venue": "Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition. pp. 770\u2013778", "citeRegEx": "4", "shortCiteRegEx": null, "year": 2016}, {"title": "Identity mappings in deep residual networks", "author": ["K. He", "X. Zhang", "S. Ren", "J. Sun"], "venue": "European Conference on Computer Vision. pp. 630\u2013645. Springer", "citeRegEx": "5", "shortCiteRegEx": null, "year": 2016}, {"title": "Deep learning for classification of dental plaque images", "author": ["S. Imangaliyev", "M.H. van der Veen", "C.M. Volgenant", "B.J. Keijser", "W. Crielaard", "E. Levin"], "venue": "International Workshop on Machine Learning, Optimization and Big Data. pp. 407\u2013410. Springer", "citeRegEx": "6", "shortCiteRegEx": null, "year": 2016}, {"title": "What is the best multistage architecture for object recognition? In: Computer Vision, 2009 IEEE 12th International Conference on", "author": ["K. Jarrett", "K. Kavukcuoglu", "M. Ranzato", "Y. LeCun"], "venue": "pp. 2146\u20132153. IEEE", "citeRegEx": "7", "shortCiteRegEx": null, "year": 2009}, {"title": "Dental plaque quantification using cellular neural network-based image segmentation", "author": ["J. Kang", "X. Li", "Q. Luan", "J. Liu", "L. Min"], "venue": "Intelligent computing in signal processing and pattern recognition, pp. 797\u2013802. Springer", "citeRegEx": "8", "shortCiteRegEx": null, "year": 2006}, {"title": "Monitoring the maturation process of a dental microcosm biofilm using the Quantitative Light-induced Fluorescencedigital (QLF-D)", "author": ["Y.S. Kim", "E.S. Lee", "H.K. Kwon", "B.I. Kim"], "venue": "Journal of dentistry 42(6), 691\u2013696", "citeRegEx": "9", "shortCiteRegEx": null, "year": 2014}, {"title": "Deep learning", "author": ["Y. LeCun", "Y. Bengio", "G. Hinton"], "venue": "Nature 521(7553), 436\u2013444", "citeRegEx": "10", "shortCiteRegEx": null, "year": 2015}, {"title": "Backpropagation applied to handwritten zip code recognition", "author": ["Y. LeCun", "B. Boser", "J.S. Denker", "D. Henderson", "R.E. Howard", "W. Hubbard", "L.D. Jackel"], "venue": "Neural computation 1(4), 541\u2013551", "citeRegEx": "11", "shortCiteRegEx": null, "year": 1989}, {"title": "Convolutional networks and applications in vision", "author": ["Y. LeCun", "K. Kavukcuoglu", "C Farabet"], "venue": "ISCAS. pp. 253\u2013256", "citeRegEx": "12", "shortCiteRegEx": null, "year": 2010}, {"title": "Association between the cariogenicity of a dental microcosm biofilm and its red fluorescence detected by Quantitative Light-induced Fluorescence-Digital (QLF-D)", "author": ["E.S. Lee", "S.M. Kang", "H.Y. Ko", "H.K. Kwon", "B.I. Kim"], "venue": "Journal of dentistry 41(12), 1264\u20131270", "citeRegEx": "13", "shortCiteRegEx": null, "year": 2013}, {"title": "Scikit-learn: Machine learning in Python", "author": ["F. Pedregosa", "G. Varoquaux", "A. Gramfort", "V. Michel", "B. Thirion", "O. Grisel", "M. Blondel", "P. Prettenhofer", "R. Weiss", "V Dubourg"], "venue": "Journal of Machine Learning Research 12, 2825\u20132830", "citeRegEx": "14", "shortCiteRegEx": null, "year": 2011}, {"title": "Very deep convolutional networks for large-scale image recognition", "author": ["K. Simonyan", "A. Zisserman"], "venue": "arXiv preprint arXiv:1409.1556", "citeRegEx": "15", "shortCiteRegEx": null, "year": 2014}, {"title": "A systematic analysis of performance measures for classification tasks", "author": ["M. Sokolova", "G. Lapalme"], "venue": "Information Processing & Management 45(4), 427\u2013437", "citeRegEx": "16", "shortCiteRegEx": null, "year": 2009}, {"title": "Going deeper with convolutions", "author": ["C. Szegedy", "W. Liu", "Y. Jia", "P. Sermanet", "S. Reed", "D. Anguelov", "D. Erhan", "V. Vanhoucke", "A. Rabinovich"], "venue": "Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition. pp. 1\u20139", "citeRegEx": "17", "shortCiteRegEx": null, "year": 2015}, {"title": "Dynamics of red fluorescent dental plaque during experimental gingivitis - a cohort study", "author": ["M.H. van der Veen", "C.M. Volgenant", "B.J. Keijser", "J.B. ten Cate", "W. Crielaard"], "venue": "Journal of dentistry 48, 71\u201376", "citeRegEx": "18", "shortCiteRegEx": null, "year": 2016}, {"title": "Comparison of red autofluorescing plaque and disclosed plaque - a cross-sectional study", "author": ["C.M. Volgenant", "M.F. y Mostajo", "N.A. Rosema", "F.A. van der Weijden", "J.B. ten Cate", "M.H. van der Veen"], "venue": "Clinical oral investigations 20(9), 2551\u20132558", "citeRegEx": "19", "shortCiteRegEx": null, "year": 2016}, {"title": "A comparative study of electric toothbrushes for the effectiveness of plaque removal in relation to toothbrushing duration", "author": ["G. Weijden", "M. Timmerman", "A. Nijboer", "M. Lie", "U. Velden"], "venue": "Journal of clinical periodontology 20(7), 476\u2013481", "citeRegEx": "20", "shortCiteRegEx": null, "year": 1993}], "referenceMentions": [{"referenceID": 17, "context": "When the QLF-camera is used some dental plaque fluoresces red, which is suggested to be an indication for the pathogenicity of the dental plaque [18].", "startOffset": 145, "endOffset": 149}, {"referenceID": 18, "context": "Although both intraexaminer and inter-examiner reliability of manual assessment of QLF-images are shown to be high [19], this may become expensive and laborious if the number of images is large.", "startOffset": 115, "endOffset": 119}, {"referenceID": 8, "context": "They require that the images must have been captured under the fixed circumstances such as camera geometry, focal distance and ambient light conditions [9], which is hard to achieve under clinical settings.", "startOffset": 152, "endOffset": 155}, {"referenceID": 9, "context": "The problem mentioned above could be solved by the use of Deep Learning models, because descriptive features can be learnt directly from raw data representations [10] being insensitive to ambient conditions and natural image variability.", "startOffset": 162, "endOffset": 166}, {"referenceID": 6, "context": "Since images have a special two-dimensional structure, a group of Deep Learning methods called Convolutional Neural Network (CNN) explicitly uses the advantages of such a representation [7,12].", "startOffset": 186, "endOffset": 192}, {"referenceID": 11, "context": "Since images have a special two-dimensional structure, a group of Deep Learning methods called Convolutional Neural Network (CNN) explicitly uses the advantages of such a representation [7,12].", "startOffset": 186, "endOffset": 192}, {"referenceID": 1, "context": "Applications of CNN may include both non-biological [2] and biological images [3].", "startOffset": 52, "endOffset": 55}, {"referenceID": 2, "context": "Applications of CNN may include both non-biological [2] and biological images [3].", "startOffset": 78, "endOffset": 81}, {"referenceID": 17, "context": "The aim of this paper is to describe the novel application of CNN to QLFimages obtained during clinical intervention study [18].", "startOffset": 123, "endOffset": 127}, {"referenceID": 5, "context": "Previous studies on this topic either focused on only a single plaque scoring system without providing detailed analysis of results [6] or used small dataset of different images and different network architecture [8].", "startOffset": 132, "endOffset": 135}, {"referenceID": 7, "context": "Previous studies on this topic either focused on only a single plaque scoring system without providing detailed analysis of results [6] or used small dataset of different images and different network architecture [8].", "startOffset": 213, "endOffset": 216}, {"referenceID": 14, "context": "Many of the modern deep learning models utilize very deep architectures to achieve superhuman performance in solving object recognition problems [15,17].", "startOffset": 145, "endOffset": 152}, {"referenceID": 16, "context": "Many of the modern deep learning models utilize very deep architectures to achieve superhuman performance in solving object recognition problems [15,17].", "startOffset": 145, "endOffset": 152}, {"referenceID": 3, "context": "One of such architectures is a novel ultra-deep residual learning network (ResNet) [4].", "startOffset": 83, "endOffset": 86}, {"referenceID": 4, "context": "This architecture can be implemented by adding so called \u2019shortcut connections\u2019 [5] which skip one or more layers.", "startOffset": 80, "endOffset": 83}, {"referenceID": 6, "context": "ResNet and many other architectures [7,12] use convolutional operator in extracting useful feature mappings in image classification task.", "startOffset": 36, "endOffset": 42}, {"referenceID": 11, "context": "ResNet and many other architectures [7,12] use convolutional operator in extracting useful feature mappings in image classification task.", "startOffset": 36, "endOffset": 42}, {"referenceID": 11, "context": "where B (l) i is a bias matrix and K (l) i,j is the filter of size (2h (l) 1 + 1)\u00d7 (2h (l) 2 + 1) connecting the j feature map in layer (l\u2212 1) with the i feature map in layer l [12].", "startOffset": 177, "endOffset": 181}, {"referenceID": 17, "context": "The analyzed 427 QLF-images were taken during a clinical intervention study [18] which was conducted at the Academic Centre for Dentistry Amsterdam.", "startOffset": 76, "endOffset": 80}, {"referenceID": 17, "context": "In total, three different experiments were performed on labels derived from plaque scoring systems such as Red Fluorescent Plaque Percentage (RF-PP) [18], Red Fluorescent modified Quigley-Hein index (RF-mQH) [19] and modified Sillness-Loe Plaque index (mSLP) [20].", "startOffset": 149, "endOffset": 153}, {"referenceID": 18, "context": "In total, three different experiments were performed on labels derived from plaque scoring systems such as Red Fluorescent Plaque Percentage (RF-PP) [18], Red Fluorescent modified Quigley-Hein index (RF-mQH) [19] and modified Sillness-Loe Plaque index (mSLP) [20].", "startOffset": 208, "endOffset": 212}, {"referenceID": 19, "context": "In total, three different experiments were performed on labels derived from plaque scoring systems such as Red Fluorescent Plaque Percentage (RF-PP) [18], Red Fluorescent modified Quigley-Hein index (RF-mQH) [19] and modified Sillness-Loe Plaque index (mSLP) [20].", "startOffset": 259, "endOffset": 263}, {"referenceID": 0, "context": "The CNN model was implemented on an NVIDIA GeForce GTX Titan X Graphics Processing Unit (GPU) using the Theano package [1].", "startOffset": 119, "endOffset": 122}, {"referenceID": 13, "context": "To compare the CNN performance with the performance of the other models, experiments were performed using various shallow classification models implemented in the Scikitlearn package [14] such as Logistic Regression (LR), Support Vector Machines Classifier with Gaussian Kernel (SVMC-K), Support Vector Machines Classifier with Linear Kernel (SVMC-L), Gaussian Nave Bayes Classifier (GNB), Gradient Boosting Classifier (GBC), K-Neighbors Classifier (KNC), and Random Forest Classifier (RFC).", "startOffset": 183, "endOffset": 187}, {"referenceID": 15, "context": "The predictive performance of the models was assessed by calculating the F1-score [16].", "startOffset": 82, "endOffset": 86}, {"referenceID": 10, "context": ", its generalization can be improved if certain a priori information about the problem is added into the choice of the model architecture [11].", "startOffset": 138, "endOffset": 142}, {"referenceID": 9, "context": "This property is explicitly embedded into the CNN model via a discrete convolution operation [10].", "startOffset": 93, "endOffset": 97}, {"referenceID": 12, "context": "Therefore, previous work performed on QLF-images [13,9] used the Red over Green pixel intensities\u2019 ratio instead of using the Red channel\u2019s pixel intensity values only.", "startOffset": 49, "endOffset": 55}, {"referenceID": 8, "context": "Therefore, previous work performed on QLF-images [13,9] used the Red over Green pixel intensities\u2019 ratio instead of using the Red channel\u2019s pixel intensity values only.", "startOffset": 49, "endOffset": 55}], "year": 2017, "abstractText": "Images are an important data source for diagnosis and treatment of oral diseases. The manual classification of images may lead to misdiagnosis or mistreatment due to subjective errors. In this paper an image classification model based on Convolutional Neural Network is applied to Quantitative Light-induced Fluorescence images. The deep neural network outperforms other state of the art shallow classification models in predicting labels derived from three different dental plaque assessment scores. The model directly benefits from multi-channel representation of the images resulting in improved performance when, besides the Red colour channel, additional Green and Blue colour channels are used.", "creator": "LaTeX with hyperref package"}}}