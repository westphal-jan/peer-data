{"id": "1705.10308", "review": {"conference": "arxiv", "VERSION": "v1", "DATE_OF_SUBMISSION": "29-May-2017", "title": "Learning Belief Network Structure From Data under Causal Insufficiency", "abstract": "though independently a belief path network ( a logical representation of the joint probability squared distribution, see ['3 ] ) hypothesis and a causal network ( a unitary representation relation of causal fact relationships [ \u2265 14 ] ) are intended simultaneously to mean different things, they are inevitably closely related. now both assume an additive underlying dag ( simple directed acyclic bucket graph ) behavior structure graph of moral relations unique among multiple variables and if probability markov condition and state faithfulness condition [ 15 ] are exactly met, then a causal network is in particular fact a good belief network. simply the difference comes to mutual appearance when we recover belief trust network and explain causal event network structure from data.", "histories": [["v1", "Mon, 29 May 2017 17:58:13 GMT  (17kb)", "http://arxiv.org/abs/1705.10308v1", "A short version of this paper appeared in [Klopotek:94m] M.A. K{\\l}opotek: Learning Belief Network Structure From Data under Causal Insufficiency. [in:] F. Bergadano, L.DeRaed Eds.: Machine Learning ECML-94 , Proc. 13th European Conference on Machine Learning, Catania, Italy, 6-8 April 1994, Lecture Notes in Artificial Intelligence 784, Springer-Verlag, 1994, pp. 379-382"]], "COMMENTS": "A short version of this paper appeared in [Klopotek:94m] M.A. K{\\l}opotek: Learning Belief Network Structure From Data under Causal Insufficiency. [in:] F. Bergadano, L.DeRaed Eds.: Machine Learning ECML-94 , Proc. 13th European Conference on Machine Learning, Catania, Italy, 6-8 April 1994, Lecture Notes in Artificial Intelligence 784, Springer-Verlag, 1994, pp. 379-382", "reviews": [], "SUBJECTS": "cs.AI", "authors": ["mieczys{\\l}aw k{\\l}opotek"], "accepted": false, "id": "1705.10308"}, "pdf": {"name": "1705.10308.pdf", "metadata": {"source": "CRF", "title": null, "authors": [], "emails": ["klopotek@ipipan.waw.pl"], "sections": [{"heading": null, "text": "ar X\niv :1\n70 5.\n10 30\n8v 1\n[ cs\n.A I]\n2 9\nM ay\n2 01\n7"}, {"heading": "Learning Belief Network Structure", "text": ""}, {"heading": "From Data under Causal Insufficiency", "text": ""}, {"heading": "Mieczys law A. K lopotek", "text": ""}, {"heading": "Institute of Computer Science, Polish Academy of Sciences", "text": "e-mail: klopotek@ipipan.waw.pl"}, {"heading": "1 Introduction", "text": "Various expert systems, dealing with uncertain data and knowledge, possess knowledge representation in terms of a belief network (e.g. knowledge base of the MUNIM system [1] , ALARM network [2] etc.). A number of efficient algorithms for propagation of uncertainty within belief networks and their derivatives have been developed, compare e.g. [9], [11], [12].\nBelief networks, causal networks, or influence diagrams, or (in Polish) cause-effect networks are terms frequently used interchangeably. They are quite popular for expressing causal relations under multiple variable setting both for deterministic and non-deterministic (e.g. stochastic) relationships in various domains: statistics, philosophy, artificial intelligence [3], [14]. Though a belief network (a representation of the joint probability distribution, see [3]) and a causal network (a representation of causal relationships [14]) are intended to mean different things, they are closely related. Both assume an underlying dag (directed acyclic graph) structure of relations among variables and if Markov condition and faithfulness condition [15] are met, then a causal network is in fact a belief network. The difference comes to appearance when we recover belief network and causal network structure from data. A dag of a belief network is satisfactory if the generated probability distribution fits the data, may be some sort of minimality is required. A causal network structure may be impossible to recover completely from data as not all directions of causal links may be uniquely determined [15]. Fortunately, if we deal with causally sufficient sets of variables (that is whenever\nsignificant influence variables are not omitted from observation), then there exists the possibility to identify the family of belief networks a causal network belongs to [16].\nRegrettably, to our knowledge, a similar result is not directly known for causally insufficient sets of variables (that is when significant influence variables are hidden) - \u201dStatistical indistinguishability is less well understood when graphs can contain variables representing unmeasured common causes\u201d ([15], p. 88). Latent (hidden) variable identification has been investigated intensely both for belief networks (e.g. [8], [6], [7], [2]) and causal networks ([10], [14], [15], [4], [5]), as well as in traditional statistics (see [13] for a comparative study of LISREL and EQS techniques). The algorithm of [2] recovers the most probable location of a hidden variable. Whereas the CI algorithm of [15] recovers exact locations of common causes, but clearly not all of them. In fact, the CI algorithm does not provide a dag, but rather a graph with edges fully (unidirected or bidirected) or partially oriented, or totally non-oriented with additional constraints for edge directions at other edges. Partially or non-oriented edges may prove to be either directed or bidirected edges. The big open question is whether or not the bidirectional edges (that is indications of a common cause) are the only ones necessary to develop a belief\nnetwork out of the product of CI, or must there be some other hidden variables added (e.g. by guessing).\nThis paper is devoted to settling this question."}, {"heading": "2 Causal Inference Algorithm", "text": "Below we remind the Causal Inference (CI) algorithm of Spirtes, Glymour and Scheines [15] together with some basic notation used therein.\nEssentially, the CI algorithm recovers partially the structure of an including path graph. Given a directed acyclic graph G with the set of hidden nodes Vh and visible nodes Vs representing a causal network CN, an including path between nodes A and B belonging to Vs is a path in the graph G such that the only visible nodes (except for A and B) on the path are those where edges of the path meet head-to-head and there exists a directed path in G from such a node to either A or B. An including path graph for G is such a graph over Vs in which if nodes A and B are connected by an including path in G ingoing into A and B, then A and B are connected by a bidirectional edge A < \u2212 > B. Otherwise if they are connected by an including path in G outgoing from A and ingoing into B then A and B are connected by an unidirectional edge A\u2212 > B.\nA partially oriented including path graph contains the following types of edges unidirectional: A\u2212 > B, bidirectional A < \u2212 > B, partially oriented Ao\u2212 > B and non-oriented Ao \u2212 oB, as well as some local constraint information A \u2217 \u2212\u2217B\u2217 \u2212 \u2217Cmeaning that edges between A and B and between B and C cannot meet head to head at B. (Subsequently an asterisk (*) means any orientation of an edge end: e.g. A\u2217\u2212 > B means either A\u2212 > B or Ao\u2212 > B or A < \u2212 > B).\nIn a partially oriented including graph \u03c0:\n(i) A is a parent of B if and only if A\u2212 > B in \u03c0.\n(ii) B is a collider along the path < A,B,C > if and only if A \u2217 \u2212 > B < \u2212 \u2217 C in \u03c0.\n(iii) An edge between B and A is into A iff A < \u2212 \u2217B in \u03c0\n(iv) An edge between B and A is out of A iff A\u2212 > B in \u03c0.\n(v) A is d-separated from B given set S iff A and B are conditionally independent given S.\n(vi) A and B are d-connected given C iff there exists no such S containing C such that A and B are\nconditionally independent given S.\n(vii) In a partially oriented including path graph \u03c0\u2032, U is a definite discriminating path for B if and only if\nU is an undirected path between X and Y containing B, B 6= X,B 6= Y , every vertex on U except for B and the endpoints is a collider or a definite non-collider on U and: (a) if V and V\u201d are adjacent on U, and V\u201d is between V and B on U, then V \u2217 \u2212 > V \u201d on U, (b) if V is between X and B on U and V is a collider on U, then V\u2212 > Y in \u03c0, else V < \u2212 \u2217 Y on \u03c0 (c) if V is between Y and B on U and V is a collider on U, then V\u2212 > X in \u03c0, else V < \u2212 \u2217X on \u03c0 (d) X and Y are not adjacent in \u03c0.\nviii) Directed path U: from X to Y: if V is adjacent to X on U then X\u2212 > V in \u03c0, if V is adjacent to Y on\nV, then V\u2212 > Y , if V and V\u201d are adjacent on U and V is between X and V\u201d on U, then V\u2212 > V \u201d in \u03c0."}, {"heading": "The Causal Inference (CI) Algorithm:", "text": "Input: Empirical joint probability distribution\nOutput: partial including path graph \u03c0.\nA) Form the complete undirected graph Q on the vertex set V.\nB) if A and B are d-separated given any subset S of V, remove the edge between A and B, and record S\nin Sepset(A,B) and Sepset(B,A).\nC) Let F be the graph resulting from step B). Orient each edge o-o. For each triple of vertices A,B,C\nsuch that the pair A,B and the pair B,C are each adjacent in F, but the pair A,C are not adjacent in F, orient (C) A*-*B*-*C as A \u2217 \u2212 > B < \u2212 \u2217 C if and only if B is not in Sepset(A,C), and orient A*-*B*-*C as A \u2217 \u2212\u2217B\u2217 \u2212 \u2217C if and only if B is in Sepset(A,C).\nD) Repeat\nif there is a directed path from A to B, and an edge A*-*B, orient (Dp) A*-*B as A \u2217 \u2212 > B,\nelse if B is a collider along < A,B,C > in \u03c0, B is adjacent to D, and A and C are not d-connected given\nD, then orient (Ds) B \u2217 \u2212 \u2217D as B < \u2212 \u2217D ,\nelse if U is a definite discriminating path between A and B for M in \u03c0 and P and R are adjacent to M\non U, and P-M-R is a triangle, then if M is in Sepset(A,B) then M is marked as non-collider on subpath P \u2217 \u2212\u2217M\u2217 \u2212R else P \u2217 \u2212 \u2217AM \u2217 \u2212 \u2217R is oriented (Dd) as P \u2217 \u2212 > M < \u2212 \u2217R,\nelse if P \u2217 \u2212> M\u2217 \u2212 \u2217R then orient (Dc) as P \u2217 \u2212 > M\u2212 > R.\nuntil no more edges can be oriented.\nEnd of CI"}, {"heading": "3 From CI Output to Belief Network", "text": "Let us imagine that we have obtained a partial including path graph from CI, and we want to find a Belief Network representing the joint probability distribution out of it. Let us consider the following algorithm:"}, {"heading": "CI-to-BN Algorithm", "text": "Input: Result of the CI algorithm (a partial including path graph) Output: A belief network\nA) Accept unidirectional and bidirectional edges obtained from CI.\nB) Orient every edge Ao\u2212 > B as A\u2212 > B.\nC) Orient edges of type Ao \u2212 oB either as A < \u2212B or A\u2212 > B so as not to violate P \u2217 \u2212\u2217M\u2217 \u2212 \u2217R\nconstraints.\nEnd of CI-to-BN\nWe claim that:\nTHEOREM 1 (i) By the CI-to-BN algorithm, a belief network can always be obtained. (ii) The obtained belief network keeps all the dependencies and independencies of the original underlying including path graph.\nThe rest of this section provides a sketchy proof of the above theorem. First, we shall notice, that hiding variables - while keeping the connections of original variables - introduces into an including path graph two kinds of new edges: (1) those stemming from a direct connection: unidirectional, keeping the acyclicity of the graph, (ii) common cause connections, introducing bidirectionality, Let us notice, that the dag of the original network (the intrinsic one) introduced a partial ordering of the (observed and unobserved) nodes. If a new (uni)directed edge is introduced by variable hiding, then only if there existed a directed path between the nodes. Therefore, the original partial order is not violated by them. On the other hand, a newly introduced bidirectional edge indicates that there exists a hidden node such that there exist a directed path from this node to each of the now connected nodes in the original graph. So it is justified to replace the introduced bidirectional edge by a parentless common cause and in this way also the partial ordering of the original graph is not violated. Hence the obtained including path graph is in fact a dag. Also, all the dependencies and independences represented by this graph would be really those which are present in the original graph under the assumption of variable hiding. There remains only one cosmetic question to be settled: What happens if a new bidirectional edge is introduced between nodes which were already connected within the original dag. Should we keep the information that there was an edge between the nodes in the original graph between them or can we drop it without affecting the\ndependence/independence information ? It happens that we can drop it because the procedure introduces necessary additional edges around this connection (vital for incoming directed edges) in order to keep all the paths considered by d-separation intact. Hence it is legitimate to draw a dag (called below the full hiding dag) consisting only of observable nodes with uni- and bi-directional edges the latter ones indicating that the nodes are not connected but have a hidden common cause.\nNow let us consider the following question: Let us consider a mixed graph (MG) having all the unoriented edges of the original including path graph (here called FHD - Full Hiding Dag) and the CI partially oriented including path graph (here called CIG - CI graph). Let all the unidirected edges of FHD be unidirected the same way in MG, let all the edges bidirected by CI he bidirected in MG. Let all partially directed edges of CI be unidirected in MG. Last not least, let all bidirectional FHD edges not oriented at all by Ci be left unoriented in MG. Now if there were no cycles in MG, then also the claim (i) of the above theorem would be valid. The proof of acyclicity of MG is not difficult, but laborious. An overview can be made in terms of Figures, from Fig.2 to Fig.11. In this series of Figures it is demonstrated that no three edges of MG can form a cycle. Within the CI algorithm, only orientation steps denoted asDp, Ds and C can give rise to a partial orientation of a FHD-bidirectional edge within CIG. (Step Dd immediately creates a bidirectional edge in CIG out of it). The Figures summarize the proof as follows: e.g. in Fig.4 (a) overviews the general situation in the FHD when one edge (BA) is bidirectional and AC and CB are unidirectional and the edge DA caused in step (C) of CI orientation of BA and DA towards A. (b) and (c) follow the case when the edges DA and AC are not bridged: as a result the edge BA is made biorriented in CIG. On the other hand, (d) and (f) deal with the case when DA and AC are bridged: then also BA grows bidirectional in CIG. So. Fig.3-4 show that in case of one FHD-bidirectional and two FHD-unidirectional edges no cycle in MG is possible. Fig.5-9 demonstrate the same for two FHD-bi- and one FHDunidirectional edges, demonstrating, that both bidirectional edges will be made bidirectional in MG if there were any risk of cyclicity during the CI-algorithm. Fig.10-11 are concened with potential cycles consisting of three FHD-bidirectional edges Within a longer trail of edges it is immediately visible, that there must exist at least one pair of neighboring edges (one of them bidirectional in FHD) which are \u201dbridged\u201d that is their ends not neighboring on the path are neighbors in the graph. Hence we have here a triangle which - due to facts proven earlier - cannot form a cycle in MG and at least two edges and at least one FHD-bidirectional are oriented correctly (that is as in FHD), hence cannot participate also in a larger cycle. (This is clear if the \u201dthird\u201d edge has also been\noriented by C, Ds or Dp step. But we can easily check, that if it has been oriented by the Dd step, then the other edges will be oriented prohibiting a long-run cycle.) This completes the proof of claim (i).\nAs claim (ii) is concerned, we shall first notice that a situation like that of Fig.12 cannot happen in an including path graph, that is it is never possible, that along a path AB1...BnC with head to head meetings at Bi one edge outgoing from each Bi points at A and there is some j such that an edge BjC is outgoing from Bj . Now, when orienting edges according to CI-to-BN algorithm, we can make two types of errors:(a) introduce a path which is not active (in terminology of [3]) in BN, but is actually active in FHD, and (b) introduce a path which is active (in terminology of [3]) in BN, but is actually not active (blocked) in FHD. In case (a), we may have the structure of such a path as ..., D,Bn, ..., B1, A, C1, ..., Cm, E, ... in Fig. 13, with node A set in BN erroneously active (to the left) or passive (to the right). Let us assume that this is the shortest active path between the nodes of interest that is no subset of nodes on the erroneously active path can form also an active path. Then in Fig.13.a) and .b) there exists no unioriented edge D\u2212 > Bi nor E\u2212 > Cj , nor bidirectional edge Bi < \u2212 > Cj nor D < \u2212 > Bj nor E < \u2212 > Cj nor D < \u2212 > A nor E < \u2212 > A,for any i,j. And additionally in Fig.13.a) there exists no edge D\u2212 > A nor E\u2212 > A. In Fig.13.b) there exists no edge D < \u2212A nor E < \u2212A. But it can then be demonstrated, that the CI orients correctly nodes from D to B1 and from E to C1, and then a definite discriminating path for A emerges, and the edges at A are oriented correctly, hence it is denied that an error may occur at A.\nAs error (b) is concerned, we can proceed in an analogous way, also assuming that we have to do with\nthe shortest erroneously passive path.\nThis would then complete the proof of the Theorem."}, {"heading": "4 Summary and Outlook", "text": "Within this paper an algorithm of recovery of belief network structure from data has been presented and its correctness demonstrated. It relies essentially on exploitation of the result of the known CI algorithm of Spirtes, Glymour and Scheines [15]. The edges of partial including path graph, not oriented by CI, are oriented to form a directed acyclic graph. The contribution of this paper is to show that such an orientation of edges always exists without necessity of adding auxiliary hidden variables, and that this dag captures all dependencies and independencies of the intrinsic underlying including path graph.\nThe CI-to-BN algorithm will suffer from the very same shortcomings as the CI algorithm, that is it is tractable only for a small number of edges. It will be interesting task to examine the possibility of such an adaptation of the Fast CI algorithm [15]. It may not be trivial as the product of CI differs from that of FCI [15]. Another path of research would be to elaborate of version of CI-to-BN assuming only with a restricted number of variables participating in a d-separation, which would also bind the exponential explosion of numerical complexity.\n(a) \u2709 A\n\u2709 B1\n\u2709 B2\n\u2709 Bn\u22121\n\u2709 Bn\n\u2709 C1\n\u2709 C2\n\u2709 Cm\u22121\n\u2709 Cm\n\u2709 D\n\u2709 E\n\u2709 F\n(b) \u2709 A\n\u2709 B1\n\u2709 B2\n\u2709 Bn\u22121\n\u2709 Bn\n\u2709 C1\n\u2709 C2\n\u2709 Cm\u22121\n\u2709 Cm\n\u2709 D\n\u2709 E\n\u2709 F"}], "references": [{"title": "MUNIN - a causal probabilistic network for interpretation of electromyographic findings", "author": ["S. Andreassen", "M. Woldbye", "B. Falck", "S.K. Andersen"], "venue": "Proc. of the Tenth International Joint Conference on AI,", "citeRegEx": "1", "shortCiteRegEx": "1", "year": 1987}, {"title": "A Bayesian method for the induction of probabilistic networks from data, Machine Learning", "author": ["G.F. Cooper", "E. Herskovits"], "venue": null, "citeRegEx": "2", "shortCiteRegEx": "2", "year": 1992}, {"title": "d-Separation: From theorems to algorithms, M.Henrion, R.D.Shachter, L.N.Kamal, J.F.Lemmer (Eds): Uncertainty in Artificial Intelligence", "author": ["D. Geiger", "T Verma", "J. Pearl"], "venue": "Elsevier Science Publishers B.V. (North-Holland),", "citeRegEx": "3", "shortCiteRegEx": "3", "year": 1990}, {"title": "Discovering causal structure, New York", "author": ["C. Glymour", "R. Scheines", "P. Spirtes", "K. Kelley"], "venue": null, "citeRegEx": "4", "shortCiteRegEx": "4", "year": 1987}, {"title": "Latent variables, causal models and overidentifying constraints", "author": ["C. Glymour", "P. Spirtes"], "venue": "Journal of Econometrics,", "citeRegEx": "5", "shortCiteRegEx": "5", "year": 1988}, {"title": "Learning probabilities in causal trees from incomplete databases", "author": ["J.L. Golmard", "A. Mallet"], "venue": "Proc. of the IJCAI Workshop on Knowledge Discovery in Databases (Detroit M.I.),", "citeRegEx": "6", "shortCiteRegEx": "6", "year": 1989}, {"title": "Minimum error tree decomposition", "author": ["L. Liu", "D.C. Wilkins", "X. Ying", "Z. Bian"], "venue": "Proc. of the Conference on Uncertainty in Artificial Intelligence,", "citeRegEx": "7", "shortCiteRegEx": "7", "year": 1990}, {"title": "Fusion, propagation and structuring in belief networks", "author": ["J. Pearl"], "venue": "Artificial Intelligence,", "citeRegEx": "8", "shortCiteRegEx": "8", "year": 1986}, {"title": "Probabilistic Reasoning in Intelligent Systems:Networks of Plausible Inference", "author": ["J. Pearl"], "venue": null, "citeRegEx": "9", "shortCiteRegEx": "9", "year": 1988}, {"title": "A theory of inferred causation,, [in:] Principles of Knowledge Representation and Reasoning", "author": ["J. Pearl", "T. Verma"], "venue": "Proc. of the Second International Conference,", "citeRegEx": "10", "shortCiteRegEx": "10", "year": 1991}, {"title": "Evidence absorption and propagation through evidence reversals", "author": ["R.D. Shachter"], "venue": "Uncertainty in Artificial Intelligence", "citeRegEx": "11", "shortCiteRegEx": "11", "year": 1990}, {"title": "Axioms for probability and belief-function propagation", "author": ["P.P. Shenoy", "G. Shafer"], "venue": "eds: Uncertainty in Artificial Intelligence 4, (Elsevier Science Publishers B.V. (North Holland),", "citeRegEx": "12", "shortCiteRegEx": "12", "year": 1990}, {"title": "Simulation studies of the reliability of computer-aided model specification using TETRAD II, EQS and LISREL programs", "author": ["P. Spirtes", "C. Glymour", "R. Scheines"], "venue": "Sociological Methods and Research,", "citeRegEx": "13", "shortCiteRegEx": "13", "year": 1990}, {"title": "Causality from probability, in: G.McKee ed.: Evolving knowledge in natural and artificial intelligence (London", "author": ["P. Spirtes", "C. Glymour", "R. Scheines"], "venue": null, "citeRegEx": "14", "shortCiteRegEx": "14", "year": 1990}, {"title": "Causation, Prediction and Search", "author": ["P. Spirtes", "C. Glymour", "R. Scheines"], "venue": "Lecture Notes in Statistics", "citeRegEx": "15", "shortCiteRegEx": "15", "year": 1993}, {"title": "Equivalence and synthesis of causal models", "author": ["T. Verma", "J. Pearl"], "venue": "Proc. 6th Conference on Uncertainty in AI,", "citeRegEx": "16", "shortCiteRegEx": "16", "year": 1990}], "referenceMentions": [{"referenceID": 0, "context": "knowledge base of the MUNIM system [1] , ALARM network [2] etc.", "startOffset": 35, "endOffset": 38}, {"referenceID": 1, "context": "knowledge base of the MUNIM system [1] , ALARM network [2] etc.", "startOffset": 55, "endOffset": 58}, {"referenceID": 8, "context": "[9], [11], [12].", "startOffset": 0, "endOffset": 3}, {"referenceID": 10, "context": "[9], [11], [12].", "startOffset": 5, "endOffset": 9}, {"referenceID": 11, "context": "[9], [11], [12].", "startOffset": 11, "endOffset": 15}, {"referenceID": 2, "context": "stochastic) relationships in various domains: statistics, philosophy, artificial intelligence [3], [14].", "startOffset": 94, "endOffset": 97}, {"referenceID": 13, "context": "stochastic) relationships in various domains: statistics, philosophy, artificial intelligence [3], [14].", "startOffset": 99, "endOffset": 103}, {"referenceID": 2, "context": "Though a belief network (a representation of the joint probability distribution, see [3]) and a causal network (a representation of causal relationships [14]) are intended to mean different things, they are closely related.", "startOffset": 85, "endOffset": 88}, {"referenceID": 13, "context": "Though a belief network (a representation of the joint probability distribution, see [3]) and a causal network (a representation of causal relationships [14]) are intended to mean different things, they are closely related.", "startOffset": 153, "endOffset": 157}, {"referenceID": 14, "context": "Both assume an underlying dag (directed acyclic graph) structure of relations among variables and if Markov condition and faithfulness condition [15] are met, then a causal network is in fact a belief network.", "startOffset": 145, "endOffset": 149}, {"referenceID": 14, "context": "A causal network structure may be impossible to recover completely from data as not all directions of causal links may be uniquely determined [15].", "startOffset": 142, "endOffset": 146}, {"referenceID": 15, "context": "K lOPOTEK significant influence variables are not omitted from observation), then there exists the possibility to identify the family of belief networks a causal network belongs to [16].", "startOffset": 181, "endOffset": 185}, {"referenceID": 14, "context": "Regrettably, to our knowledge, a similar result is not directly known for causally insufficient sets of variables (that is when significant influence variables are hidden) - \u201dStatistical indistinguishability is less well understood when graphs can contain variables representing unmeasured common causes\u201d ([15], p.", "startOffset": 306, "endOffset": 310}, {"referenceID": 7, "context": "[8], [6], [7], [2]) and causal networks ([10], [14], [15], [4], [5]), as well as in traditional statistics (see [13] for a comparative study of LISREL and EQS techniques).", "startOffset": 0, "endOffset": 3}, {"referenceID": 5, "context": "[8], [6], [7], [2]) and causal networks ([10], [14], [15], [4], [5]), as well as in traditional statistics (see [13] for a comparative study of LISREL and EQS techniques).", "startOffset": 5, "endOffset": 8}, {"referenceID": 6, "context": "[8], [6], [7], [2]) and causal networks ([10], [14], [15], [4], [5]), as well as in traditional statistics (see [13] for a comparative study of LISREL and EQS techniques).", "startOffset": 10, "endOffset": 13}, {"referenceID": 1, "context": "[8], [6], [7], [2]) and causal networks ([10], [14], [15], [4], [5]), as well as in traditional statistics (see [13] for a comparative study of LISREL and EQS techniques).", "startOffset": 15, "endOffset": 18}, {"referenceID": 9, "context": "[8], [6], [7], [2]) and causal networks ([10], [14], [15], [4], [5]), as well as in traditional statistics (see [13] for a comparative study of LISREL and EQS techniques).", "startOffset": 41, "endOffset": 45}, {"referenceID": 13, "context": "[8], [6], [7], [2]) and causal networks ([10], [14], [15], [4], [5]), as well as in traditional statistics (see [13] for a comparative study of LISREL and EQS techniques).", "startOffset": 47, "endOffset": 51}, {"referenceID": 14, "context": "[8], [6], [7], [2]) and causal networks ([10], [14], [15], [4], [5]), as well as in traditional statistics (see [13] for a comparative study of LISREL and EQS techniques).", "startOffset": 53, "endOffset": 57}, {"referenceID": 3, "context": "[8], [6], [7], [2]) and causal networks ([10], [14], [15], [4], [5]), as well as in traditional statistics (see [13] for a comparative study of LISREL and EQS techniques).", "startOffset": 59, "endOffset": 62}, {"referenceID": 4, "context": "[8], [6], [7], [2]) and causal networks ([10], [14], [15], [4], [5]), as well as in traditional statistics (see [13] for a comparative study of LISREL and EQS techniques).", "startOffset": 64, "endOffset": 67}, {"referenceID": 12, "context": "[8], [6], [7], [2]) and causal networks ([10], [14], [15], [4], [5]), as well as in traditional statistics (see [13] for a comparative study of LISREL and EQS techniques).", "startOffset": 112, "endOffset": 116}, {"referenceID": 1, "context": "The algorithm of [2] recovers the most probable location of a hidden variable.", "startOffset": 17, "endOffset": 20}, {"referenceID": 14, "context": "Whereas the CI algorithm of [15] recovers exact locations of common causes, but clearly not all of them.", "startOffset": 28, "endOffset": 32}, {"referenceID": 14, "context": "2 Causal Inference Algorithm Below we remind the Causal Inference (CI) algorithm of Spirtes, Glymour and Scheines [15] together with some basic notation used therein.", "startOffset": 114, "endOffset": 118}, {"referenceID": 2, "context": "Now, when orienting edges according to CI-to-BN algorithm, we can make two types of errors:(a) introduce a path which is not active (in terminology of [3]) in BN, but is actually active in FHD, and (b) introduce a path which is active (in terminology of [3]) in BN, but is actually not active (blocked) in FHD.", "startOffset": 151, "endOffset": 154}, {"referenceID": 2, "context": "Now, when orienting edges according to CI-to-BN algorithm, we can make two types of errors:(a) introduce a path which is not active (in terminology of [3]) in BN, but is actually active in FHD, and (b) introduce a path which is active (in terminology of [3]) in BN, but is actually not active (blocked) in FHD.", "startOffset": 254, "endOffset": 257}, {"referenceID": 14, "context": "It relies essentially on exploitation of the result of the known CI algorithm of Spirtes, Glymour and Scheines [15].", "startOffset": 111, "endOffset": 115}, {"referenceID": 14, "context": "It will be interesting task to examine the possibility of such an adaptation of the Fast CI algorithm [15].", "startOffset": 102, "endOffset": 106}, {"referenceID": 14, "context": "It may not be trivial as the product of CI differs from that of FCI [15].", "startOffset": 68, "endOffset": 72}], "year": 2017, "abstractText": null, "creator": "dvips(k) 5.996 Copyright 2016 Radical Eye Software"}}}