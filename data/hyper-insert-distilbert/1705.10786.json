{"id": "1705.10786", "review": {"conference": "arxiv", "VERSION": "v1", "DATE_OF_SUBMISSION": "30-May-2017", "title": "Semi-Supervised Learning for Detecting Human Trafficking", "abstract": "viral human trafficking crime is one of the worlds most atrocious cyber crimes studies and among the main challenging enforcement problems generally facing public law sheriff enforcement which frequently demands attention of sheer global magnitude. in this flagship study, we only leverage textual data downloaded from the viral website \" yahoo backpage \" - frequently used for conducting classified advertisement - to critically discern obvious potential investigative patterns of human trafficking activities which primarily manifest variously online and identify advertisements of wildly high interest marketed to law enforcement. eventually due to \u2018 the lack of ground upon truth, we chiefly rely on a human analyst from specialized law enforcement, for deliberately hand - labeling a small portion of demonstrating the crawled data. \u2026 we later extend aside the general existing paradigm laplacian, svm and present at s3vm - r, by adding : a regularization sampling term applicable to exploit exogenous information embedded individually in our feature space in overwhelming favor of the task objectives at hand. we finally train the proposed method using labeled blinded and unlabeled data and evaluate it on sampling a fraction of displaying the unlabeled data, both herein referred therefore to predominantly as unseen data, paired with our expert's further continuing verification. results from comparisons between our method and myriad other competing semi - supervised and supervised approaches on releasing the labeled subjective data essentially demonstrate hope that our blind learner is as effective continually in identifying advertisements of high interest to law agencies enforcement", "histories": [["v1", "Tue, 30 May 2017 05:51:53 GMT  (2029kb,D)", "http://arxiv.org/abs/1705.10786v1", null]], "reviews": [], "SUBJECTS": "cs.LG cs.AI", "authors": ["hamidreza alvari", "paulo shakarian", "j e kelly snyder"], "accepted": false, "id": "1705.10786"}, "pdf": {"name": "1705.10786.pdf", "metadata": {"source": "CRF", "title": "Semi-Supervised Learning for Detecting Human Trafficking", "authors": ["Hamidreza Alvari", "Paulo Shakarian", "J.E. Kelly Snyder"], "emails": ["halvari@asu.edu", "shak@asu.edu", "kelly@findmegroup.org"], "sections": [{"heading": null, "text": "Keywords Human Trafficking \u00b7 Backpage \u00b7 Semi-Supervised Support Vector Machines \u00b7 Laplacian Support Vector Machines"}, {"heading": "1 Introduction", "text": "According to the United Nation [1], human trafficking is defined as the modern slavery or the trade of humans mostly for the purpose of sexual exploitation\n1 Arizona State University Tempe, Arizona E-mail: {halvari,shak}@asu.edu 2 Find Me Group Tempe, Arizona E-mail: kelly@findmegroup.org ar X\niv :1\n70 5.\n10 78\n6v 1\n[ cs\n.L G\n] 3\n0 M\nay 2\n01 7\nand forced labor, via different improper ways including force, fraud and deception. The United States\u2019 Trafficking Victim Protection Act of 2000 (TVPA 2000) [2] was the first U.S. legislation passed against human trafficking. Human trafficking has ever since received increased national and societal concern [3] but still demands persistent fight against from all over the globe. No country is immune and the problem is rapidly growing with little to no law enforcement addressing the issue. This problem is amongst the challenging ones facing law enforcement as it is difficult to identify victims and counter traffickers.\nBefore the advent of the Internet, human traffickers were under risks of being arrested by law enforcement while advertising their victims on streets [4]. However, move to the Internet has made it easier and less dangerous for sex sellers [5] as they no longer needed to advertise on the streets. There are now a plethora of websites that host and provide sexual services under categories of escort, adult entertainment, massage services, etc., which help sex sellers and buyers maintain their anonymity. Although some services such as the Craiglist\u2019s adult section and myredbook.com were shut down recently, there are still many websites such as the Backpage.com that provide such services and many new are frequently created. Traffickers even use dating and social networking websites such as the Twitter, Facebook, Instagram and Tinder to reach out to sex buyers and their followers. Although the Internet has presented new trafficking related challenges for law enforcement, it has also provided readily and publicly available rich source of information which could be gleaned from online sex advertisements for fighting this crime [6]. However, the problem is we lack the ground truth and obtaining the labels through hand-labeling is indeed tedious and expensive even for a small subset of data\u2013 this is the point where the semi-supervised setting comes in handy.\nDespite considerable attention which has been devoted to studying supervised, unsupervised and semi-supervised learning settings via different applications [7,8,9,10,11,12,13], semi-supervised learning, i.e., learning from labeled and unlabeled examples, is still one of the most interesting yet challenging problems in the machine learning community [14]. The idea is simple though\u2013 we shall have an approach that makes a better use of unlabeled data to boost performance. This is pretty close to the most natural learning that occurs in the world. For the most part, we as humans are exposed only to a small number of labeled instances; yet we successfully generalize well by effective utilization of a large amount of unlabeled data. This motivates us to use unlabeled samples to improve recognition performance while developing classifiers.\nIn this article, expanding on our previous work [15], we use the data crawled from the adult entertainment section of the website Backpage.com and extend the existing Laplacian SVM framework [14] to detect escort advertisements of high interest to law enforcement. Here, we merely focus on the online advertisements although the Internet has triggered many other activities including attracting the victims, communicating with customers and rating the escort services. We thus highlight several contributions of the current research as follows.\n1. Based on the literature, we created different groups of features that capture the characteristics of potential human trafficking activities. The less likely human trafficking related posts were then filtered out using these features. We also conducted a feature importance analysis to demonstrate how these features contribute to the proposed learner. 2. We extended the Laplacian SVM [14] and proposed the semi-supervised support vector machine learning algorithm, S3VM \u2212 R. In particular, we incorporated additional information of our feature space as a regularization term into the standard optimization formulation with regard to the Laplacian SVM. We also used geometry of the underlying data as an intrinsic regularization term in Laplacian SVM. 3. We trained our model on both of the labeled and unlabeled data and sent back the identified human trafficking related advertisements to an expert from law enforcement for further verification. We then validated our approach on a small subset of the unlabeled data (i.e. unseen data) with further verification of the expert. 4. We performed comparisons between our approach and several semi-supervised and supervised baselines on both of the labeled and unseen data (so-called blind evaluation). 5. We demonstrated the effect of varying different hyperparameters used in our learner on its performance.\nThe rest of the paper is organized as follows. In Section 2, we review the prior studies on human trafficking. Section 3 covers our data preparation, feature engineering, unsupervised filtering and expert assisted labeling. We detail our semi-supervised learning approach in Section 4 by deriving the required equations. Section 5 provides in-depth explanation of our experiments. Section 6 concludes the paper by providing future research directions."}, {"heading": "2 Related Work", "text": "Recently, several studies have examined the role of the Internet and related technology in facilitating human trafficking [16,17,18]. For example, the work of [16] studied how closely sex trafficking is intertwined with new technologies. According to [17], sexual exploitation of women and children is a global human right crisis that is being escalated by the use of new technologies. Researchers have studied relationships between new technologies and human trafficking and advantages of the Internet for sex traffickers. For instance, findings from a group of experts from the Council of Europe demonstrated that the Internet and sex industry are closely interlinked and volume and content of the material on the Internet promoting human trafficking are unprecedented [18].\nOne of the earliest works which leveraged data mining techniques for online human trafficking was [18], wherein the authors conducted data analysis on the adult section of the website Backpage.com. Their findings confirmed that female escort post frequency would increase in Dallas, Texas, leading up to the Super Bowl 2011 event. In a similar attempt, other studies [19,20]\nhave investigated impact of large public events such as the Super Bowl on sex trafficking by exploring advertisement volume, trends and movement of advertisements along with the scope and volume of demand associated with such events. The work of [19] for instance, concluded that large events such as the Super Bowl which attract significant amount of concentration of people in a relatively short period of time and in a confined urban area, could be a desirable location for sex traffickers to bring their victims for commercial sexual exploitation. Similarly, the data-driven approach of [20] showed that in some but not all events, one can see a correlation between occurrence of the event and statistically significant evidence of an influx of sex trafficking activity. Also, certain studies [21] have tried to build large distributed systems to store and process available online human trafficking data in order to perform entity resolution and create ontological relations between entities.\nBeyond these works, the work of [22] studied the problem of isolating sources of human trafficking from online advertisements with a pairwise entity resolution approach. Specifically, they used phone number as a strong feature and trained a classifier to predict if two ads are from the same source. This classifier was then used to perform entity resolution using a heuristically learned value for the score of classifier. Another work of [6] used Backpage.com data and extracted most likely human trafficking spatio-temporal patterns with the help of law enforcement. Note that unlike our method, this work did not employ any machine learning methodologies for automatically identifying human trafficking related advertisements. The work of [23] also deployed machine learning for the advertisement classification problem, by training a supervised learning classifier on labeled data (based on phone numbers of known traffickers) provided by a victim advocacy group. We note that while phone numbers can provide a very precise set of positive labeled data, there are clearly many posts with previously unseen phone numbers.\nIn contrast, we do not solely rely on phone numbers for labeling our data. Instead, our expert analyze each post\u2019s content to identify whether it is human trafficking related or not. To do so, we first filter out most likely advertisements using several feature groups and pass a small sample to the expert for handlabeling. Then, we train our semi-supervised learner on both of the labeled and unlabeled data which in turn lets us evaluate our approach on new coming (unseen) data later. We note that our semi-supervised approach can also be used as a complementary method to procedures such as those described in [23] as we can significantly expand the training set for use with supervised learning.\nFinally, note that our current research is different from our previous work [15] and we list the key nuances here:\n\u2013 In this study we experiment with a much larger dataset. To obtain such dataset, we use the same raw data from [15], but this time with slight modifications of the thresholds that were used for filtering out less likely human trafficking related advertisements.\n\u2013 As opposed to our previous research which deployed only one feature space, in this work, two feature spaces that have complementary roles to each other are used. \u2013 In this paper we present a new framework based on the existing Laplacian SVM [14], by adding a regularization term to the standard optimization problem and solving the new optimization equation derived from there. In contrast, [15] utilized the off-the-shelf graph based semi-supervised learner, LabelSpreading method [24], without any further manipulation of the original approach. \u2013 Unlike [15] in which we did not compare our method with other approaches, this work compares our proposed framework against other semi-supervised and supervised learners. Also unlike our previous work in which only one group of human trafficking related advertisements were passed to two experts for validation, here in order to reduce the inconsistency, two control groups of advertisements\u2013those of interest to law enforcement and those of not\u2013 are sent to only one expert for verification."}, {"heading": "3 Data Preparation", "text": "We collected about 20K publicly available listings from the U.S. posted on Backpage.com in March, 2016. Each post includes a title, description, time stamp, poster\u2019s age, poster\u2019s ID, location, image, and sometimes video and audio. The description usually lists the attributes of the individual(s) and contact phone numbers. In this work, we only focus on the textual component of the data. This free-text data required significant cleaning due to a variety of issues common to textual analytics (i.e. misspellings, format of phone numbers, etc.). We also acknowledge that the information in data could be intentionally inaccurate, such as poster\u2019s name, age and even physical appearance (e.g. bra cup size, weight). Figure 1 shows an actual post from Backpage.com. To illustrate geographic diversity of the listings, we use the Tableau1 software to visualize choropleth map of phone frequency with respect to the different states in Figure 2, wherein darker colors mean higher frequencies.\nNext, we will explain most important characteristics of potential human trafficking advertisements which are captured by our feature groups.\n3.1 Feature Engineering\nThough many advertisements on Backpage.com are posted by posters selling their own services without coercion and intervention of traffickers, some do exhibit many common trafficking triggers. For example, in contrast to Figure 1, Figure 3 shows an advertisement that could be an evidence of human trafficking. This advertisement indicates several potential properties of human trafficking, including advertising for multiple escorts with the first individual\n1 https://www.tableau.com/\ncoming from Asia and very young. In what follows, such common properties of human trafficking related advertisements are discussed in more detail.\nInspired by the literature, we define and extract 6 groups of features from advertisements (see Table 1). These features could be amongst the strong indicators of human trafficking. Let us now briefly describe each group of features used in our work. Note each feature listed here is ultimately treated as a binary variable."}, {"heading": "3.1.1 Advertisement Language Pattern", "text": "The first group consists of different language related features. For the first and second features, we identify posts which have third person language (more\nlikely to be written by someone other than the escort) and posts which contain first person plural pronouns such as \u2018we\u2019 and \u2018our\u2019 (more likely to be an organization) [6].\nTo ensure their anonymity, traffickers would deploy techniques to generate diverse information and hence make their posts look more complicated. They usually do this to avoid being identified by either human analysts or automated programs. Thus, to obtain the third feature we take an approach from complexity theory, namely Kolmogorov complexity, which is defined as length of shortest program to reproduce a string of characters on a universal\nmachine such as the Turing Machine [25]. Since the Kolmogorov complexity is not computable, we approximate the complexity of an advertisement content by first removing stop words and then computing entropy of the content [25]. To illustrate this, let X denote the content and xi be a given word in the content. We use the following equation [31] to calculate the entropy of the content and thus approximate the Kolmogorov complexity of X:\nK(X) \u2248 \u2212 n\u2211 i=1 P (xi) log2 P (xi) (1)\nWe expect higher values of the entropy correspond to human trafficking. Finally, we discretize the result by using the threshold of 4 which was found empirically in our experiments.\nFor the next features, we use word-level n-grams to find common language patterns of advertisements. This particular choice is because of the fact that character-level n-grams have already shown to be useful in detecting unwanted content for spam detection [26]. We set n = 4 and use the range of (4,4) to compute normalized n-grams (using TF-IDF) of each advertisement content. We ultimately create a matrix whose rows and columns correspond to the advertisements contents and their associated 4-grams, respectively. We rank all elements of this matrix in a descending order and pick the top 3 ones. Finally for each advertisement content, 3 elements with the column numbers associated with the top elements are chosen. This way, 3 more features will be added to our feature set. Overall, we have 6 features related to the language of the advertisement."}, {"heading": "3.1.2 Words and Phrases of Interest", "text": "Despite the fact that advertisements on Backpage.com do not directly mention sex with children, customers who prefer children know to look for words and phrases such as \u201csweet, candy, fresh, new in town, new to the game\u201d [27,28, 29]. We thus investigate within the posts to see if they contain such words as they could be highly related with human trafficking in general."}, {"heading": "3.1.3 Countries of Interest", "text": "We identify if the individual being escorted is coming from other countries such as those in Southeast Asia (especially from China, Vietnam, Korea and Thailand, as we observed in our data) [3]."}, {"heading": "3.1.4 Multiple Victims Advertised", "text": "Some advertisements advertise for multiple women at the same time. We consider the presence of more than one victim as a potential evidence of organized human trafficking [6]."}, {"heading": "3.1.5 Victim Weight", "text": "We take into account the weight of the individual being escorted as a feature (if it is available). This information is particularly useful assuming that for the most part, lower body weights (under 115 lbs) correlate with smaller and underage girls [2,30] and thereby human trafficking."}, {"heading": "3.1.6 Reference to Website or Spa Massage Therapy", "text": "The presence of a link in the advertisement either referencing to an outside website (especially infamous ones) or spa massage therapy could be an indicator of more elaborate organization [6]. In particular, in case of spa therapy, we observed many advertisements interrelated with advertising for young Asian girls and their erotic massage abilities. Therefore, the last group of features has two binary features for presence of any website and spa.\nFinally, in order to extract all of the above features, we first clean the original data and conduct preprocessing. By applying these features, we draw a random sample of 3,543 instances out of our dataset for further analysis to see if they are evidences of human trafficking\u2013 this is described in the next section.\n3.2 Unsupervised Filtering\nHaving detailed our feature set, we now construct a feature vector for each instance by creating a vector of 12 binary features that correspond to the important characteristics of human trafficking. Hereafter, we refer to this feature space, as our first feature space and denote it with F1. As mentioned earlier, we draw 3,543 instances from our raw data by filtering out those that do not posses any of the binary features. We will refer to this as our filtered dataset. For the sake of visualization, a 2-D projection (using the t-SNE transformation [32]) of the filtered dataset is depicted in Figure 4. The purpose of this figure is to demonstrate how hard it is for basic clustering techniques such as the K-means, to correctly assign labels to unlabeled instances using only few existing labeled ones.\nNow, we shall define our second feature space, namely F2, which will be used to compute geometry of the underlying data. Note that our proposed framework will utilize both of the feature spaces in the form of regularization terms, to detect advertisements of high interest to law enforcement. After conducting standard preprocessing techniques on the filtered dataset, we build F2 by transforming the filtered data into a 3,543\u00d73,543 matrix of TF-IDF similarity features. Each entry in this matrix simply shows the similarity between a pair of advertisements in our filtered dataset.\nNote that since we lack the ground truth, we would rely on a human analyst (expert) for labeling the listings as either \u2018of interest\u2019 or \u2018of not interest\u2019 to law enforcement. In the next section, we select a smaller yet finer grain subset\nof this data to be sent to the expert. This alleviates the burden of the tedious work of hand-labeling.\n3.3 Expert Assisted Labeling\nWe first obtain a sample of 200 listings from the filtered dataset. This set of listings was labeled by our expert from law enforcement who is specialized in this type of crime. From this subset, the law enforcement professional identified 70 instances to be of interest to law enforcement and the rest to be not human trafficking related. However, we are still left with a large amount of the unlabeled examples (3,343 instances) in our dataset. The ratio of the labeled to unlabeled instances in our dataset is very small (about 0.06). The statistics of our dataset is summarized in Table 2."}, {"heading": "4 Semi-Supervised Learning Framework", "text": "Here, we first introduce some preliminary notations necessary for the rest of the discussion and then outline our proposed semi-supervised approach, S3VM \u2212 R, for detecting online human trafficking. Note as said earlier, our framework is an extension to the existing Laplacian SVM [14]. In particular, we incorporated another regularization term into the standard Laplacian SVM to leverage the additional information of our first feature space and then solved the associated optimization problem. Consequently, similar notation is adopted throughout\nthe following section. Furthermore, we shall once again note that our current research does not utilize any off-the-shelf graph based semi-supervised leaner in contrast to our previous research [15].\n4.1 Technical Preliminaries\nWe assume a set of l labeled pairs {(xi, yi)}li=1 and an unlabeled set of u instances {xl+i}ui=1, where xi \u2208 Rn and yi \u2208 {+1,\u22121}. Recall for the standard soft-margin support vector machine, the following optimization problem is solved:\nmin f\u03b8\u2208Hk \u03b3||f\u03b8||2k + Cl l\u2211 i=1 H1(yif\u03b8(xi)) (2)\nIn the above equation, f\u03b8(\u00b7) is a decision function of the form f\u03b8(\u00b7) = w.\u03a6(\u00b7) + b where \u03b8 = (w, b) are the parameters of the model, and \u03a6(\u00b7) is the feature map which is usually implemented using the kernel trick [33]. Also, the function H1(\u00b7) = max(0, 1\u2212 \u00b7) is the Hinge Loss function.\nThe classical Representer theorem [34] suggests that solution to the optimization problem exists in a Hilbert space Hk and is of the following form:\nf\u2217\u03b8 (x) = l\u2211 i=1 \u03b1\u2217iK(x, xi) (3)\nwhere K is the l\u00d7l Gram matrix over labeled samples. Equivalently, the above problem can be written as:\nmin w,b,\n1 2 ||w||22 + Cl l\u2211 i=1 i (4)\ns.t. yi(w.\u03a6(xi) + b) \u2265 1\u2212 i, i = 1, ..., l i \u2265 0, i = 1, ..., l (5)\nNext, we will use the above optimization equation as our basis to derive the formulations for our proposed semi-supervised learner.\n4.2 The proposed Method\nThe basic assumption behind semi-supervised learning methods is to leverage unlabeled instances in order to restructure hypotheses during the learning process. In this paper, exogenous information extracted from both of our feature spaces is further exploited to make a better use of the unlabeled examples. To do so, we first introduce matrix F in F1 and over both of the labeled and unlabeled samples with Fij defined as follows:\nFij = 1\nnf (\u03a6(xi) \u00b7\u03a6(xj)) (6)\nwhere nf is the number of features in F1 (here, nf = 12). We force the instances xi and xj in our dataset to have same label if they both possess same features. To account for this, a regularization term is added to the standard equation and the following optimization is solved:\nmin f\u03b8\u2208Hk\n1\n2 l\u2211 i=1 Fij ||f\u03b8(xi)\u2212 f\u03b8(xj)||22 = fT\u03b8 LT f\u03b8 (7)\nwhere f = [f(x1), ..., f(xl+u)] T and L is the Laplacian matrix based on F given by L = D \u2212 F, and Dii = \u2211l+u j=1 Fij . The intuition here is that any two instances which are composed of same features are more likely to have same labels than others. Next, by solving a similar optimization problem, we are able to capture data geometry in F2 as fT\u03b8 L\u2032T f\u03b8 (also referred to as the intrinsic smoothness penalty term [14]). Here, L\u2032 is the Laplacian of matrix A associated with the data adjacency graph G in F2.\nWe construct G with (l+ u) nodes in F2, and by adding an edge between each pair of nodes \u3008i, j\u3009, if the edge weight Wij exceeds a given threshold. For computing the edge weights, we use the heat kernel [35] as a function of the Euclidean distance between two samples in F2, hence we set Wij = exp\u2212||xi\u2212xj ||\n2/4t. Following the notations used in [14] and by including our regularization term as well as the intrinsic smoothness penalty term, we would extend the standard equation by solving the following optimization:\nmin f\u03b8\u2208Hk \u03b3||f\u03b8||2k + Cl l\u2211 i=1 H1(yif\u03b8(xi)) + Crf T \u03b8 Lf\u03b8 + Csf T \u03b8 L\u2032f\u03b8 (8)\nNote one typical value for the smoothness penalty coefficient Cs is \u03b3I\n(l+u)2 ,\nwhere 1(l+u)2 is a natural scale factor for empirical estimate of the Laplace operator and \u03b3I is a regularization term [14]. Again, solution in Hk would be in the following form:\nf\u2217\u03b8 (x) = l+u\u2211 i=1 \u03b1\u2217iK(x, xi) (9)\nHere K is the (l+u)\u00d7(l+u) Gram matrix over all samples. The equation 8 could be then written as follows:\nmin \u03b1,b,\n1 2 \u03b1TK\u03b1+ Cl l\u2211 i=1 i + Cr 2 \u03b1TKLK\u03b1+ \u03b3I 2(l + u)2 \u03b1TKL\u2032K\u03b1 (10)\ns.t. yi( l+u\u2211 j=1 \u03b1jK(xi, xj) + b) \u2265 1\u2212 i, i = 1, ..., l\ni \u2265 0, i = 1, ..., l (11)\nWith introduction of the Lagrangian multipliers \u03b2 and \u03b3, we write the Lagrangian function of the above equation as follows:\nL(\u03b1, , b, \u03b2, \u03b3) = 1\n2 \u03b1TK(I + CrL+ \u03b3I (l + u)2 L\u2032)\u03b1+ Cl l\u2211 i=1 i\n\u2212 l\u2211 i=1 \u03b2i(yi( l+u\u2211 j=1 \u03b1jK(xi, xj) + b)\u2212 1 + i)\u2212 l\u2211 i=1 \u03b3i i (12)\nObtaining the dual representation, requires taking the following steps:\n\u2202L \u2202b = 0\u2192 l\u2211 i=1 \u03b2iyi = 0 (13)\n\u2202L \u2202 i = 0\u2192 Cl \u2212 \u03b2i \u2212 \u03b3i = 0\u2192 0 \u2264 \u03b2i \u2264 Cl (14)\nWith the above equations, we formulate the reduced Lagrangian as a function of only \u03b1 and \u03b2 as follows:\nLR(\u03b1, \u03b2) = 1\n2 \u03b1TK(I + CrL+ \u03b3I (l + u)2 L\u2032)\u03b1\n\u2212 l\u2211 i=1 \u03b2i(yi( l+u\u2211 j=1 \u03b1jK(xi, xj) + b)\u2212 1 + i)\n(15)\nThis equation is further simplified as follows:\nLR(\u03b1, \u03b2) = 1\n2 \u03b1TK(I + CrL+ \u03b3I (l + u)2 L\u2032)\u03b1\n\u2212\u03b1TKJTY\u03b2 + l\u2211 i=1 \u03b2i (16)\nIn the above equation, J = [I 0] is a l \u00d7 (l + u) matrix, I is the l \u00d7 l identity matrix and Y is a diagonal matrix consisting of the labels of the labeled examples.\nIn the followings, we first take the derivative of LR with respect to \u03b1 and\nthen set \u2202L R(\u03b1,\u03b2) \u2202\u03b1 = 0:\nK(I + CrL+ \u03b3I\n(l + u)2 L\u2032)\u03b1\u2212KJTY\u03b2 = 0 (17)\nAccordingly, we obtain \u03b1\u2217 by solving the following equation:\n\u03b1\u2217 = (I + CrL+ \u03b3I\n(l + u)2 L\u2032)\u22121JTY\u03b2\u2217 (18)\nNext, we obtain the dual problem in the form of a quadratic programming problem by substituting \u03b1 back in the reduced Lagrangian function:\n\u03b2\u2217 = argmax\u03b2\u2208Rl \u2212 1\n2 \u03b2TQ\u03b2 + l\u2211 i=1 \u03b2i (19)\ns.t. l\u2211 i=1 \u03b2iyi = 0\n0 \u2264 \u03b2i \u2264 Cl (20)\nwhere \u03b2 = [\u03b21, ..., \u03b2l] T \u2208 Rl are the Lagrangian multipliers and Q is obtained as follows:\nQ = YJK(I + (CrL+ \u03b3I\n(l + u)2 L\u2032)K)\u22121JTY (21)\nWe summarize the proposed semi-supervised framework in Algorithm 1. Our optimization problem is very similar to the standard optimization problem solved for SVMs, hence we use a standard optimizer for SVMs to solve our problem.\nAlgorithm 1 The Proposed Semi-Supervised Framework\nInput: {(xi, yi)}li=1, {xl+i}ui=1, F1, F2, Cl, Cr, Cs. Output: Estimated function f\u03b8 : Rn \u2192 R 1: Construct matrix F based on the features in F1 2: Compute the corresponding Laplacian matrix L. 3: Construct A according to the features in F2. 4: Compute the graph Laplacian matrix L\u2032. 5: Construct the gram matrix over all examples using Kij = k(xi, xj) where k is a kernel\nfunction. 6: Compute \u03b1\u2217 and \u03b2\u2217 using Eq. 18 and Eq. 19 and a standard QP solvers. 7: Compute function f\u2217\u03b8 (x) = \u2211l+u i=1 \u03b1 \u2217 iK(x, xi)"}, {"heading": "5 Experimental Study", "text": "In this section, we provide a comprehensive analysis of the proposed framework by designing a series of experiments on the filtered dataset. First, we explain several approaches used in this study. Next, various results are discussed: (1) comparisons on the labeled data were made between our method and other approaches, (2) experiments were performed on a fraction of the unlabeled data (i.e., unseen data), and the results were further verified by our expert to see what fraction is of interest to law enforcement, (3) blind evaluation was conducted to examine other approaches on the unseen data, and finally, (4) experiments were designed to analyze effect of varying different hyperparameters on our method as well as impact of different groups of features in F1 on our approach.\n5.1 Approaches\nWe present results for the following methods:\n\u2013 Semi-Supervised: S3VM \u2212 R, Laplacian support vector machines [14], graph inference based label spreading approach [24] with radial basis function (RBF) and K-nearest neighbors (KNN) kernels, and co-training learner [36] with two support vector machines classifiers (SVM). \u2013 Supervised: SVM, KNN, Gaussian na\u0308\u0131ve Bayes, logistic regression, adaboost and random forest.\nFor the sake of fair comparison, all algorithms were implemented and run in Python. More specifically, the Python package CVXOPT2 was used to implement S3VM \u2212 R and Laplacian support vector machines, and all other approaches were implemented with the help of the Scikit-learn3 package in Python. Note for those methods that require special tuning of parameters, we performed grid search to choose the best set of parameters. Before going any further, we first define main parameters used in each method and then demonstrate their best values picked by our grid search. The discussion on the effect of varying the hyperparameters on our learner is provided in the section 5.3.\n\u2013 S3VM\u2212R: we set the penalty parameter as Cl = 0.6 and the regularization parameters Cr = 0.2 and Cs = 0.2. Linear kernel was used in our approach. \u2013 Laplacian SVM : we used linear kernel and set the parameters Cl = 0.6 and Cs = 0.6. \u2013 LabelSpreading (RBF): RBF Kernel was used and \u03b3 was set to the default value of 20. \u2013 LabelSpreading (KNN): KNN kernel was used and the number of neighbors was set to 5.\n2 http://cvxopt.org/ 3 http://scikit-learn.org/stable/\n\u2013 Co-training (SVM): we followed the algorithm introduced in [36] and used two SVM as our classifiers. For both SVMs we set the tolerance for stopping criteria to 0.001 and the penalty parameter C = 1. \u2013 SVM : tolerance for stopping criteria was set to the default value of 0.001. Penalty parameter C was set to 1 and linear kernel was used. \u2013 KNN : number of neighbors was set to 5. \u2013 Gaussian NB : there were no specific parameter to tune. \u2013 Logistic regression: we used the \u2018l2\u2019 penalty. We also set the parameter C = 1 (the inverse of regularization strength) and tolerance for stopping criteria to 0.01. \u2013 Adaboost : number of estimators was set to 200 and we also set the learning rate to 0.01. \u2013 Random forest : we used 200 estimators and the \u2018entropy\u2019 criterion was used.\n5.2 Classification Results\nHere, we first evaluate the entire set of approaches on a small portion of the data for which we already know the labels, i.e., the labeled examples. We note that expert-generated judgmental labeling might be error-prone, though it is served as a surrogate to the ground truth problem.\nWe used 10-fold cross-validation on the labeled data in the following way. We first divided the set of the labeled samples into 10 different sets of approximately equal size. Each time we held one set out for validation (by removing their labels and adding them to the unlabeled samples) and used the remaining along with the unlabeled samples for the training\u2013this was performed for all approaches for the sake of fair comparison. Finally, we reported the average of 10 different runs, using different combinations of the feature spaces and various evaluation metrics, including the area under curve (AUC), accuracy, precision, recall and F1-score. In table 3, we reported the average AUC and accuracy for each method and each feature space. On the other hand, for precision, recall and F1-score, we reported separate results for each feature space, in tables 4-6, respectively. Note, each of these tables includes separate scores for the positive and negative classes. In general, we observed the followings:\n\u2013 Overall, our approach achieved highest performance on F1 (tables 3 and 4) and {F1,F2} (table 6), in terms of all metrics. However it did not perform well using solely F2 (table 5), i.e. when Cr = 0. This clearly demonstrates the importance of using Cr over Cs. \u2013 When the feature space used is F2, Co-training (SVM) is the best method. Next best methods are supervised learners KNN and Gaussian NB. Three remarks can be made here. First, our approach could not always defeat supervised learners as it is seen from tables 3 and 5. This is not surprising and in fact lies at the inherent difference between semi-supervised and supervised methods\u2013 unlabeled examples could make the trained model susceptible to error propagation and thus wrong estimation. Second, as it"}, {"heading": "5.2.1 Blind Evaluation", "text": "For the next set of experiments, we first run our method on the entire filtered dataset and without cross-validation. Recall from the previous sections that\nthis is to make a better use of the unlabeled examples. Then the following control experiment was conducted. Our learner was tested on the whole set of the unlabeled examples. Out of 3,343 instances, our approach identified two sets of positive and negative instances. The positive set contained 394 advertisements which were likely to be of interest to law enforcement, whereas the negative set included the remaining 2,962 unlabeled advertisements of probably less interest to law enforcement. Next, to precisely determine the correctly identified fractions of these two sets, we randomly picked two subsets (control groups) of 100 examples from each set for further validation by our expert.\nWe passed these two control groups to our expert for further verification. The expert-validated results demonstrated that all of the examples in the positive group were of interest to law enforcement, while only two examples from the negative group were not correctly classified as of not being of any interest to law enforcement. Thus, both results support the effectiveness of our frame-\nwork in identifying highly human trafficking advertisements. Using the same two control groups and AUC metric, we now perform so-called blind evaluation (see table 7) of other baselines. Note, we call this blind since actual labels are not provided and the expert-generated labels might convey uninformative information. In general, supervised methods failed to achieve good results in the blind evaluation compared to most of the semi-supervised methods.\n5.3 Hyperparameter Sensitivity\nHere, we discuss how altering the hyperparameters Cl, Cr and Cs may affect the performance of S3VM \u2212 R. We start off by fixing the value of Cl to 0.6, which was empirically found to work well in our experiments. Also, recall from the previous sections that one typical choice for Cs is \u03b3I (l+u)2 [14]. Here, we set Cs = 0.2 and varied the values of Cr as {0, 0.0002, 0.0006, 0.2, 1.0} and plotted\nthe results in Figure 5. We used the same 10-fold cross-validation setting from the previous section.\nWe made the following observation. With the slight increase of Cr, the performance of our approach increased, peaked and then stabilized, i.e., further increase of Cr did not change the performance. This suggests significance of deploying the additional information from our first feature space F1, over F2 and its corresponding smoothness penalty parameter Cs which is used by S3VM \u2212R and the standard Laplacian SVM.\nNext, to see the impact of Cl on the performance, we set Cr = 0.2 and varied Cl as {0.2, 0.4, 0.6, 0.8, 1.0}. The results are depicted in Figure 5. We note that setting Cl = 0 is meaningless and thus we do not have any performance corresponding to that\u2013 otherwise each \u03b2i in Eq. 19 would be zero. In general, the performance was not particular sensitive to this parameter\u2013 varying by 0.2 for values of 0.4 and greater.\nFinally, having fixed Cl = 0.6 and Cr = 0.2, we also tried other values for Cs including \u2211l+u i,j=1Wij suggested by [14] and depicted the results in Figure 5. The results suggest that our approach is less sensitive to this parameter compared to Cr and Cl.\n5.4 Significance of Features\nTo examine how much discriminative our feature groups in F1 are, we further conducted an analysis using the labeled examples and the standard feature selection measure \u03c72 to find the top features\u2013 only half of the features with scores greater than a given threshold (0.5) were selected (see table 8 for the complete set of features and their corresponding \u03c72 scores).\nFrom this list, we noticed that \u2018countries of interest\u2019 and \u2018reference to spa massage therapy\u2019 were the most discriminative feature groups, while \u2018advertisement language pattern\u2019 group (with 3 important features) appeared to be the most dominant feature group.\nFigure 6 compares the top features against the less important subset of the features (denoted by F\u22171 ) in the filtered dataset, in terms of frequency values. Note for clarity, we have removed from this figure, the features with frequency less than 20. According to this figure, our most discriminative features are not necessarily those that appear more often.\nTo further investigate the importance of each of the top features, we performed classification using the labeled examples and the previous setting, on basis of these two subsets of the features and their combination, i.e., F\u22171 , F\u22171 and F1. The classification results are shown in Table 9. We made the following observations:\n\u2013 Considering only the feature space F1, our approach achieved higher performance compared to all other baselines by either using the whole feature space or the most discriminative features F\u22171 . \u2013 Deploying only the features from F\u22171 , we were able to achieve comparable results as if we used the whole feature space F1."}, {"heading": "6 Conclusion", "text": "Readily available online data from escort advertisements could be leveraged in favor of fight against human trafficking. In this study, having focused on textual information from the available data crawled from Backpage.com, we identified if an escort advertisement can be reflective of human trafficking activities. In particular, we first proposed an unsupervised filtering approach to filter out the data which are more likely involved in human trafficking. We then proposed a semi-supervised learner, namely S3VM \u2212 R, and trained it on a small portion of the data which was hand-labeled by a human trafficking expert. We used the trained model to identify labels of unseen data. Results suggested our approach is effective at identifying potential human trafficking related advertisements.\nOur future plans include replicating the study by integrating more interesting features especially those supported by the criminology literature. Also, since hand-labeling unlabeled examples is expensive, an interesting research direction would be to deploy active learning to enable iterative supervised learning to actively query the user for labels. We also note that real-world data is often more imbalanced compared to our data, and the reason is that number of negative samples usually outweigh positive ones. We would thus like to apply the proposed framework on a more realistic dataset which contains much less suspicious posts than normal posts."}, {"heading": "7 Competing Interests", "text": "The authors declare that they have no competing interests."}, {"heading": "8 Authors\u2019 Contributions", "text": "HA developed and implemented the human trafficking detection approach and drafted the manuscript. PS provided guidance through the whole project and revised the manuscript. JS was in contact with an expert from law enforcement who was responsible for hand-labeling portions of the data. All authors read and approved the final manuscript."}, {"heading": "Acknowledgment", "text": "This work was funded by the Find Me Group, a 501(c)3 dedicated to bring resolution and closure to families of missing persons. The authors would like to thank anonymous reviewers for their valuable suggestions to improve the quality of the paper."}], "references": [{"title": "Police run \u2018Prostitution\u2019 sting; 19 men arrested, charged in Fourth East Dallas operation.", "author": ["C. Desplaces"], "venue": "Nov Dallas Morning News,", "citeRegEx": "4", "shortCiteRegEx": "4", "year": 1992}, {"title": "How pimps use the web to sell girls.", "author": ["N.D. Kristof"], "venue": "Jan 2012. [Online]. Available:", "citeRegEx": "5", "shortCiteRegEx": "5", "year": 2012}, {"title": "Predictive patterns of sex trafficking online,", "author": ["E. Kennedy"], "venue": "Dietrich College Honors Theses,", "citeRegEx": "6", "shortCiteRegEx": "6", "year": 2012}, {"title": "Learning from labeled and unlabeled data,", "author": ["T.M. Mitchell"], "venue": "Machine learning,", "citeRegEx": "7", "shortCiteRegEx": "7", "year": 2006}, {"title": "Signed link analysis in social media", "author": ["G. Beigi", "J. Tang", "H. Liu"], "venue": "networks,\u201d in International AAAI Conference on Web and Social Media (ICWSM),", "citeRegEx": "8", "shortCiteRegEx": "8", "year": 2016}, {"title": "Supervised random walks: predicting and recommending links in social networks,", "author": ["L. Backstrom", "J. Leskovec"], "venue": "Proceedings of the fourth ACM international conference on Web search and data mining. ACM,", "citeRegEx": "9", "shortCiteRegEx": "9", "year": 2011}, {"title": "Identifying community structures in dynamic networks,", "author": ["H. Alvari", "A. Hajibagheri", "G. Sukthankar", "K. Lakkaraju"], "venue": "Social Network Analysis and Mining,", "citeRegEx": "10", "shortCiteRegEx": "10", "year": 2016}, {"title": "Exploiting emotional information for trust/distrust prediction,", "author": ["G. Beigi", "J. Tang", "S. Wang", "H. Liu"], "venue": "Proceedings of the 2016 SIAM International Conference on Data Mining (ICDM),", "citeRegEx": "11", "shortCiteRegEx": "11", "year": 2016}, {"title": "Leveraging community detection for accurate trust prediction,", "author": ["G. Beigi", "M. Jalili", "H. Alvari", "G. Sukthankar"], "venue": "In ASE International Conference on Social Computing,", "citeRegEx": "13", "shortCiteRegEx": "13", "year": 2014}, {"title": "Manifold regularization: A geometric framework for learning from labeled and unlabeled examples,", "author": ["M. Belkin", "P. Niyogi", "V. Sindhwani"], "venue": "Journal of machine learning research,", "citeRegEx": "14", "shortCiteRegEx": "14", "year": 2006}, {"title": "A non-parametric learning approach to identify online human trafficking,", "author": ["H. Alvari", "P. Shakarian", "J. Snyder"], "venue": "Intelligence and Security Informatics (ISI),", "citeRegEx": "15", "shortCiteRegEx": "15", "year": 2016}, {"title": "The demand for victims of sex trafficking,", "author": ["D.M. Hughes"], "venue": "Womens Studies Program,", "citeRegEx": "16", "shortCiteRegEx": "16", "year": 2005}, {"title": "The use of new communications and information technologies for sexual exploitation of women and children,", "author": ["D.M. Hughes"], "venue": "Hastings Women\u2019s Law Journal,", "citeRegEx": "17", "shortCiteRegEx": "17", "year": 2002}, {"title": "Human trafficking online: The role of social networking sites and online classifieds,", "author": ["M. Latonero"], "venue": "Available at SSRN 2045851,", "citeRegEx": "18", "shortCiteRegEx": "18", "year": 2011}, {"title": "Allbee, \u201cExploring the impact of the super bowl on sex trafficking,", "author": ["D. Roe-Sepowitz", "J. Gallagher", "K. Bracy", "L. Cantelme", "A. Bayless", "J. Larkin", "A. Reese"], "venue": "[Online]. Available: https://www.mccaininstitute.org/ exploring-the-impact-of-the-super-bowl-on-sex-trafficking-2015/", "citeRegEx": "19", "shortCiteRegEx": "19", "year": 2015}, {"title": "Do public events affect sex trafficking activity?", "author": ["K. Miller", "E. Kennedy", "A. Dubrawski"], "venue": "ArXiv e-prints, Feb. 2016. [Online]. Available:", "citeRegEx": "20", "shortCiteRegEx": "20", "year": 2016}, {"title": "Building and using a knowledge graph to combat human trafficking.", "author": ["P.A. Szekely", "C.A. Knoblock", "J. Slepicka", "A. Philpot", "A. Singh", "C. Yin", "D. Kapoor", "P. Natarajan", "D. Marcu", "K. Knight", "D. Stallard", "S.S. Karunamoorthy", "R. Bojanapalli", "S. Minton", "B. Amanatullah", "T. Hughes", "M. Tamayo", "D. Flynt", "R. Artiss", "S.-F. Chang", "T. Chen", "G. Hiebel", "L. Ferreira"], "venue": "in International Semantic Web Conference (2),", "citeRegEx": "21", "shortCiteRegEx": "21", "year": 2015}, {"title": "An entity resolution approach to isolate instances of human trafficking online,", "author": ["C. Nagpal", "K. Miller", "B. Boecking", "A. Dubrawski"], "venue": "ArXiv e-prints,", "citeRegEx": "22", "shortCiteRegEx": "22", "year": 2015}, {"title": "Leveraging publicly available data to discern patterns of human-trafficking activity,", "author": ["A. Dubrawski", "K. Miller", "M. Barnes", "B. Boecking", "E. Kennedy"], "venue": "Journal of Human Trafficking,", "citeRegEx": "23", "shortCiteRegEx": "23", "year": 2015}, {"title": "Schlkopf, \u201cLearning with local and global consistency,", "author": ["D. Zhou", "O. Bousquet", "T.N. Lal", "J. Weston"], "venue": "Advances in Neural Information Processing Systems", "citeRegEx": "24", "shortCiteRegEx": "24", "year": 2004}, {"title": "An introduction to kolmogorov complexity and its applications, 3rd ed", "author": ["M. Li", "P.M. Vit\u00e1nyi"], "venue": null, "citeRegEx": "25", "shortCiteRegEx": "25", "year": 2008}, {"title": "Spam detection using character n-grams.", "author": ["I. Kanaris", "K. Kanaris", "E. Stamatatos"], "venue": "SETN, ser. Lecture Notes in Computer Science,", "citeRegEx": "26", "shortCiteRegEx": "26", "year": 2006}, {"title": "Fighting sex trafficking in hotels, one room at a time,", "author": ["K. Hetter"], "venue": null, "citeRegEx": "27", "shortCiteRegEx": "27", "year": 2012}, {"title": "An open letter to jim Buckmaster,", "author": ["R. Lloyd"], "venue": "[Online]. Available: http://www.huffingtonpost.com/rachel-lloyd/an-open-letter-to-jim-buc b 570666.html", "citeRegEx": "28", "shortCiteRegEx": "28", "year": 2012}, {"title": "Can we use RSS to catch rapists,", "author": ["J. Dickinson Goodman", "M. Holmes"], "venue": null, "citeRegEx": "29", "shortCiteRegEx": "29", "year": 2011}, {"title": "A mathematical theory of communication,", "author": ["C.E. Shannon"], "venue": "ACM SIGMOBILE Mobile Computing and Communications Review,", "citeRegEx": "31", "shortCiteRegEx": "31", "year": 2001}, {"title": "Visualizing high-dimensional data using t-SNE,", "author": ["L. van der Maaten", "G. Hinton"], "venue": "Journal of Machine Learning Research,", "citeRegEx": "32", "shortCiteRegEx": "32", "year": 2008}, {"title": "On manifold regularization.", "author": ["M. Belkin", "P. Niyogi", "V. Sindhwani"], "venue": "Proceedings of the Tenth International Workshop on Artificial Intelligence and Statistics (AISTAT),", "citeRegEx": "34", "shortCiteRegEx": "34", "year": 2005}, {"title": "Heat kernels on weighted manifolds and applications,", "author": ["A. Grigoryan"], "venue": "Cont. Math,", "citeRegEx": "35", "shortCiteRegEx": "35", "year": 2006}, {"title": "Combining labeled and unlabeled data with co-training,", "author": ["A. Blum", "T. Mitchell"], "venue": "Proceedings of the eleventh annual conference on Computational learning theory. ACM,", "citeRegEx": "36", "shortCiteRegEx": "36", "year": 1998}], "referenceMentions": [{"referenceID": 0, "context": "Before the advent of the Internet, human traffickers were under risks of being arrested by law enforcement while advertising their victims on streets [4].", "startOffset": 150, "endOffset": 153}, {"referenceID": 1, "context": "However, move to the Internet has made it easier and less dangerous for sex sellers [5] as they no longer needed to advertise on the streets.", "startOffset": 84, "endOffset": 87}, {"referenceID": 2, "context": "Although the Internet has presented new trafficking related challenges for law enforcement, it has also provided readily and publicly available rich source of information which could be gleaned from online sex advertisements for fighting this crime [6].", "startOffset": 249, "endOffset": 252}, {"referenceID": 3, "context": "Despite considerable attention which has been devoted to studying supervised, unsupervised and semi-supervised learning settings via different applications [7,8,9,10,11,12,13], semi-supervised learning, i.", "startOffset": 156, "endOffset": 175}, {"referenceID": 4, "context": "Despite considerable attention which has been devoted to studying supervised, unsupervised and semi-supervised learning settings via different applications [7,8,9,10,11,12,13], semi-supervised learning, i.", "startOffset": 156, "endOffset": 175}, {"referenceID": 5, "context": "Despite considerable attention which has been devoted to studying supervised, unsupervised and semi-supervised learning settings via different applications [7,8,9,10,11,12,13], semi-supervised learning, i.", "startOffset": 156, "endOffset": 175}, {"referenceID": 6, "context": "Despite considerable attention which has been devoted to studying supervised, unsupervised and semi-supervised learning settings via different applications [7,8,9,10,11,12,13], semi-supervised learning, i.", "startOffset": 156, "endOffset": 175}, {"referenceID": 7, "context": "Despite considerable attention which has been devoted to studying supervised, unsupervised and semi-supervised learning settings via different applications [7,8,9,10,11,12,13], semi-supervised learning, i.", "startOffset": 156, "endOffset": 175}, {"referenceID": 8, "context": "Despite considerable attention which has been devoted to studying supervised, unsupervised and semi-supervised learning settings via different applications [7,8,9,10,11,12,13], semi-supervised learning, i.", "startOffset": 156, "endOffset": 175}, {"referenceID": 9, "context": ", learning from labeled and unlabeled examples, is still one of the most interesting yet challenging problems in the machine learning community [14].", "startOffset": 144, "endOffset": 148}, {"referenceID": 10, "context": "In this article, expanding on our previous work [15], we use the data crawled from the adult entertainment section of the website Backpage.", "startOffset": 48, "endOffset": 52}, {"referenceID": 9, "context": "com and extend the existing Laplacian SVM framework [14] to detect escort advertisements of high interest to law enforcement.", "startOffset": 52, "endOffset": 56}, {"referenceID": 9, "context": "We extended the Laplacian SVM [14] and proposed the semi-supervised support vector machine learning algorithm, SVM \u2212 R.", "startOffset": 30, "endOffset": 34}, {"referenceID": 11, "context": "Recently, several studies have examined the role of the Internet and related technology in facilitating human trafficking [16,17,18].", "startOffset": 122, "endOffset": 132}, {"referenceID": 12, "context": "Recently, several studies have examined the role of the Internet and related technology in facilitating human trafficking [16,17,18].", "startOffset": 122, "endOffset": 132}, {"referenceID": 13, "context": "Recently, several studies have examined the role of the Internet and related technology in facilitating human trafficking [16,17,18].", "startOffset": 122, "endOffset": 132}, {"referenceID": 11, "context": "For example, the work of [16] studied how closely sex trafficking is intertwined with new technologies.", "startOffset": 25, "endOffset": 29}, {"referenceID": 12, "context": "According to [17], sexual exploitation of women and children is a global human right crisis that is being escalated by the use of new technologies.", "startOffset": 13, "endOffset": 17}, {"referenceID": 13, "context": "For instance, findings from a group of experts from the Council of Europe demonstrated that the Internet and sex industry are closely interlinked and volume and content of the material on the Internet promoting human trafficking are unprecedented [18].", "startOffset": 247, "endOffset": 251}, {"referenceID": 13, "context": "One of the earliest works which leveraged data mining techniques for online human trafficking was [18], wherein the authors conducted data analysis on the adult section of the website Backpage.", "startOffset": 98, "endOffset": 102}, {"referenceID": 14, "context": "In a similar attempt, other studies [19,20]", "startOffset": 36, "endOffset": 43}, {"referenceID": 15, "context": "In a similar attempt, other studies [19,20]", "startOffset": 36, "endOffset": 43}, {"referenceID": 14, "context": "The work of [19] for instance, concluded that large events such as the Super Bowl which attract significant amount of concentration of people in a relatively short period of time and in a confined urban area, could be a desirable location for sex traffickers to bring their victims for commercial sexual exploitation.", "startOffset": 12, "endOffset": 16}, {"referenceID": 15, "context": "Similarly, the data-driven approach of [20] showed that in some but not all events, one can see a correlation between occurrence of the event and statistically significant evidence of an influx of sex trafficking activity.", "startOffset": 39, "endOffset": 43}, {"referenceID": 16, "context": "Also, certain studies [21] have tried to build large distributed systems to store and process available online human trafficking data in order to perform entity resolution and create ontological relations between entities.", "startOffset": 22, "endOffset": 26}, {"referenceID": 17, "context": "Beyond these works, the work of [22] studied the problem of isolating sources of human trafficking from online advertisements with a pairwise entity resolution approach.", "startOffset": 32, "endOffset": 36}, {"referenceID": 2, "context": "Another work of [6] used Backpage.", "startOffset": 16, "endOffset": 19}, {"referenceID": 18, "context": "The work of [23] also deployed machine learning for the advertisement classification problem, by training a supervised learning classifier on labeled data (based on phone numbers of known traffickers) provided by a victim advocacy group.", "startOffset": 12, "endOffset": 16}, {"referenceID": 18, "context": "We note that our semi-supervised approach can also be used as a complementary method to procedures such as those described in [23] as we can significantly expand the training set for use with supervised learning.", "startOffset": 126, "endOffset": 130}, {"referenceID": 10, "context": "Finally, note that our current research is different from our previous work [15] and we list the key nuances here:", "startOffset": 76, "endOffset": 80}, {"referenceID": 10, "context": "To obtain such dataset, we use the same raw data from [15], but this time with slight modifications of the thresholds that were used for filtering out less likely human trafficking related advertisements.", "startOffset": 54, "endOffset": 58}, {"referenceID": 9, "context": "\u2013 In this paper we present a new framework based on the existing Laplacian SVM [14], by adding a regularization term to the standard optimization problem and solving the new optimization equation derived from there.", "startOffset": 79, "endOffset": 83}, {"referenceID": 10, "context": "In contrast, [15] utilized the off-the-shelf graph based semi-supervised learner, LabelSpreading method [24], without any further manipulation of the original approach.", "startOffset": 13, "endOffset": 17}, {"referenceID": 19, "context": "In contrast, [15] utilized the off-the-shelf graph based semi-supervised learner, LabelSpreading method [24], without any further manipulation of the original approach.", "startOffset": 104, "endOffset": 108}, {"referenceID": 10, "context": "\u2013 Unlike [15] in which we did not compare our method with other approaches, this work compares our proposed framework against other semi-supervised and supervised learners.", "startOffset": 9, "endOffset": 13}, {"referenceID": 2, "context": "1 Advertisement Language Pattern [6,25,26] - Third person language - First person plural pronouns - Kolmogorov complexity - n-grams (1) - n-grams (2) - n-grams (3)", "startOffset": 33, "endOffset": 42}, {"referenceID": 20, "context": "1 Advertisement Language Pattern [6,25,26] - Third person language - First person plural pronouns - Kolmogorov complexity - n-grams (1) - n-grams (2) - n-grams (3)", "startOffset": 33, "endOffset": 42}, {"referenceID": 21, "context": "1 Advertisement Language Pattern [6,25,26] - Third person language - First person plural pronouns - Kolmogorov complexity - n-grams (1) - n-grams (2) - n-grams (3)", "startOffset": 33, "endOffset": 42}, {"referenceID": 22, "context": "2 Words and Phrases of Interest [27,28,29]", "startOffset": 32, "endOffset": 42}, {"referenceID": 23, "context": "2 Words and Phrases of Interest [27,28,29]", "startOffset": 32, "endOffset": 42}, {"referenceID": 24, "context": "2 Words and Phrases of Interest [27,28,29]", "startOffset": 32, "endOffset": 42}, {"referenceID": 2, "context": "4 Multiple Victims Advertised [6]", "startOffset": 30, "endOffset": 33}, {"referenceID": 2, "context": "6 Reference to Website or Spa Massage Therapy [6] - Reference to a website - Reference to a Spa Massage Therapy", "startOffset": 46, "endOffset": 49}, {"referenceID": 2, "context": "likely to be written by someone other than the escort) and posts which contain first person plural pronouns such as \u2018we\u2019 and \u2018our\u2019 (more likely to be an organization) [6].", "startOffset": 167, "endOffset": 170}, {"referenceID": 20, "context": "machine such as the Turing Machine [25].", "startOffset": 35, "endOffset": 39}, {"referenceID": 20, "context": "Since the Kolmogorov complexity is not computable, we approximate the complexity of an advertisement content by first removing stop words and then computing entropy of the content [25].", "startOffset": 180, "endOffset": 184}, {"referenceID": 25, "context": "We use the following equation [31] to calculate the entropy of the content and thus approximate the Kolmogorov complexity of X:", "startOffset": 30, "endOffset": 34}, {"referenceID": 21, "context": "This particular choice is because of the fact that character-level n-grams have already shown to be useful in detecting unwanted content for spam detection [26].", "startOffset": 156, "endOffset": 160}, {"referenceID": 22, "context": "com do not directly mention sex with children, customers who prefer children know to look for words and phrases such as \u201csweet, candy, fresh, new in town, new to the game\u201d [27,28, 29].", "startOffset": 172, "endOffset": 183}, {"referenceID": 23, "context": "com do not directly mention sex with children, customers who prefer children know to look for words and phrases such as \u201csweet, candy, fresh, new in town, new to the game\u201d [27,28, 29].", "startOffset": 172, "endOffset": 183}, {"referenceID": 24, "context": "com do not directly mention sex with children, customers who prefer children know to look for words and phrases such as \u201csweet, candy, fresh, new in town, new to the game\u201d [27,28, 29].", "startOffset": 172, "endOffset": 183}, {"referenceID": 2, "context": "We consider the presence of more than one victim as a potential evidence of organized human trafficking [6].", "startOffset": 104, "endOffset": 107}, {"referenceID": 2, "context": "The presence of a link in the advertisement either referencing to an outside website (especially infamous ones) or spa massage therapy could be an indicator of more elaborate organization [6].", "startOffset": 188, "endOffset": 191}, {"referenceID": 26, "context": "For the sake of visualization, a 2-D projection (using the t-SNE transformation [32]) of the filtered dataset is depicted in Figure 4.", "startOffset": 80, "endOffset": 84}, {"referenceID": 9, "context": "Note as said earlier, our framework is an extension to the existing Laplacian SVM [14].", "startOffset": 82, "endOffset": 86}, {"referenceID": 10, "context": "Furthermore, we shall once again note that our current research does not utilize any off-the-shelf graph based semi-supervised leaner in contrast to our previous research [15].", "startOffset": 171, "endOffset": 175}, {"referenceID": 27, "context": "The classical Representer theorem [34] suggests that solution to the optimization problem exists in a Hilbert space Hk and is of the following form:", "startOffset": 34, "endOffset": 38}, {"referenceID": 9, "context": "Next, by solving a similar optimization problem, we are able to capture data geometry in F2 as f \u03b8 L\u2032T f\u03b8 (also referred to as the intrinsic smoothness penalty term [14]).", "startOffset": 165, "endOffset": 169}, {"referenceID": 28, "context": "For computing the edge weights, we use the heat kernel [35] as a function of the Euclidean distance between two samples in F2, hence we set Wij = exp\u2212||xi\u2212xj || 2/4t.", "startOffset": 55, "endOffset": 59}, {"referenceID": 9, "context": "Following the notations used in [14] and by including our regularization term as well as the intrinsic smoothness penalty term, we would extend the standard equation by solving the following optimization:", "startOffset": 32, "endOffset": 36}, {"referenceID": 9, "context": "Note one typical value for the smoothness penalty coefficient Cs is \u03b3I (l+u)2 , where 1 (l+u)2 is a natural scale factor for empirical estimate of the Laplace operator and \u03b3I is a regularization term [14].", "startOffset": 200, "endOffset": 204}, {"referenceID": 9, "context": "\u2013 Semi-Supervised: SVM \u2212 R, Laplacian support vector machines [14], graph inference based label spreading approach [24] with radial basis function (RBF) and K-nearest neighbors (KNN) kernels, and co-training learner [36] with two support vector machines classifiers (SVM).", "startOffset": 62, "endOffset": 66}, {"referenceID": 19, "context": "\u2013 Semi-Supervised: SVM \u2212 R, Laplacian support vector machines [14], graph inference based label spreading approach [24] with radial basis function (RBF) and K-nearest neighbors (KNN) kernels, and co-training learner [36] with two support vector machines classifiers (SVM).", "startOffset": 115, "endOffset": 119}, {"referenceID": 29, "context": "\u2013 Semi-Supervised: SVM \u2212 R, Laplacian support vector machines [14], graph inference based label spreading approach [24] with radial basis function (RBF) and K-nearest neighbors (KNN) kernels, and co-training learner [36] with two support vector machines classifiers (SVM).", "startOffset": 216, "endOffset": 220}, {"referenceID": 29, "context": "\u2013 Co-training (SVM): we followed the algorithm introduced in [36] and used two SVM as our classifiers.", "startOffset": 61, "endOffset": 65}, {"referenceID": 9, "context": "Also, recall from the previous sections that one typical choice for Cs is \u03b3I (l+u)2 [14].", "startOffset": 84, "endOffset": 88}, {"referenceID": 9, "context": "2, we also tried other values for Cs including \u2211l+u i,j=1Wij suggested by [14] and depicted the results in Figure 5.", "startOffset": 74, "endOffset": 78}], "year": 2017, "abstractText": "Human trafficking is one of the most atrocious crimes and among the challenging problems facing law enforcement which demands attention of global magnitude. In this study, we leverage textual data from the website \u201cBackpage\u201d\u2013 used for classified advertisement\u2013 to discern potential patterns of human trafficking activities which manifest online and identify advertisements of high interest to law enforcement. Due to the lack of ground truth, we rely on a human analyst from law enforcement, for hand-labeling a small portion of the crawled data. We extend the existing Laplacian SVM and present SVM \u2212R, by adding a regularization term to exploit exogenous information embedded in our feature space in favor of the task at hand. We train the proposed method using labeled and unlabeled data and evaluate it on a fraction of the unlabeled data, herein referred to as unseen data, with our expert\u2019s further verification. Results from comparisons between our method and other semi-supervised and supervised approaches on the labeled data demonstrate that our learner is effective in identifying advertisements of high interest to law enforcement.", "creator": "LaTeX with hyperref package"}}}