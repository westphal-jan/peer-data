{"id": "1706.00587", "review": {"conference": "arxiv", "VERSION": "v1", "DATE_OF_SUBMISSION": "2-Jun-2017", "title": "Learning-based Surgical Workflow Detection from Intra-Operative Signals", "abstract": "a simple modern operating room ( sa or ) provides employees a plethora of different advanced medical devices. sometimes in order to enable better facilitate the information offered physicians by consulting them, they just need to automatically react to the prevalent intra - operative context. to prevent this satisfactory end, evaluating the progress of the required surgical hospital workflow investigation must be detected and neatly interpreted, so that the critical current therapeutic status can be summarized given in finite machine - like readable sequential form. in this work, random forests ( covert rf ) numerical and quantum hidden markov models ( hmm ) computed are compared and combined manually to clearly detect the current surgical clinical workflow phase of a controlled laparoscopic cholecystectomy. various combinations systems of data analytics were tested, progressing from systems using compressed only raw radio sensor data to simple filtered digital and augmented datasets. for achieved accuracies achieved ranged from 64 %, to $ 72 % for the preferred rf approach, filtered and from 80 % directly to half 82 % for the combination of objective rf and hmm.", "histories": [["v1", "Fri, 2 Jun 2017 08:33:24 GMT  (354kb)", "http://arxiv.org/abs/1706.00587v1", "7 pages, 4 figures"]], "COMMENTS": "7 pages, 4 figures", "reviews": [], "SUBJECTS": "cs.LG", "authors": ["ralf stauder", "erg\\\"un kayis", "nassir navab"], "accepted": false, "id": "1706.00587"}, "pdf": {"name": "1706.00587.pdf", "metadata": {"source": "CRF", "title": "Learning-based Surgical Workflow Detection from Intra- Operative Signals", "authors": ["Ralf Stauder", "Erg\u00fcn Kayis", "Nassir Navab"], "emails": [], "sections": [{"heading": null, "text": "medical devices. In order to better facilitate the information offered by them, they need to automatically react to the intra-operative context. To this end, the progress of the surgical workflow must be detected and interpreted, so that the current status can be given in machine-readable form. In this work, Random Forests (RF) and Hidden Markov Models (HMM) are compared and combined to detect the surgical workflow phase of a laparoscopic cholecystectomy. Various combinations of data were tested, from using only raw sensor data to filtered and augmented datasets. Achieved accuracies ranged from 64% to 72% for the RF approach, and from 80% to 82% for the combination of RF and HMM.\nKeywords: Surgical Data Science, Random Forest, Hidden Markov Model"}, {"heading": "1 Introduction", "text": "Automatic detection and recognition of the ongoing surgical process is a vital step on the way to a more context-sensitive and collaborative operating room of the future [1]. While it is generally a positive development, that an increasing number of medical and imaging devices are available during surgery, this unfortunately also increases the cognitive workload of the surgeon and the organizational complexity for the OR team. In order to provide the available information only when it is actually necessary for the procedure, devices must recognize the surgical context and workflow.\nDifferent approaches exist in the field of surgical workflow recognition [2], which is also an aspect of the recently defined area of surgical data science. Some methods try to extract a structured model from recorded surgeries [3], while others directly try to recognize the surgical phases or activities through instrument and sensor data [4\u2013 6], laparoscopic video [7\u20139], kinematics information [10], or a mixture thereof [11]. In this work we will apply both Random Forests (RF) [12] and Hidden Markov Models (HMM) [13], separately and combined, to recognize the surgical phase from instrument and sensor data."}, {"heading": "2 Methods", "text": "RF are a collection of randomized decision trees [12]. The individual trees are trained on a randomized subset of all available training data each, and in every node only a randomly selected subset of all available features is available for splitting. This way, all trees of the forest should have a different structure. After training, every tree evaluates each sample and casts a vote, while the majority of votes designates the final classification result. The parameters for the random forest in this experiment were optimized through an exhaustive parameter sweep: The forest consisted of 80 trees with a maximal tree depth of 9 nodes. During training, each node was presented with a random subset with 8 of the 17 available features.\nHMMs can be used to estimate and model the internal state of a system based on the trained network structure and recorded observations [13]. A common approach in surgical process modeling is to use left-to-right HMMs to model the surgical workflow, as the internal states usually can be mapped directly to the surgical phases or activities, while the unidirectional structure ensures medically reasonable state transitions. In these experiments the HMM was set up to contain 7 states, corresponding to the surgical phases, which should be detected.\nThe RF classifier by itself does not take temporal relationships between samples into account, so the classification results can be rather noisy with ambiguous data. Left-to-right HMMs on the other hand are always at risk of switching states too early, or being stuck in wrong phases if no transition event is detected. In an attempt to alleviate these issues, we combined both approaches (see Fig. 1). The examined samples are first being classified by the RF. This classification result is then passed to the HMM as observation, and the phase corresponding to the estimated HMM state is given as overall classification result. In this setup, the HMM effectively acts as filter to even out the RF results. The training of this combined setup was done in two steps: First, the RF was trained regularly, using a part of the overall training data. Then the second part of the training data was classified by the trained RF, and the confusion matrix for this classification was generated. This calculated confusion matrix was used directly as emission matrix for the HMM, while the transition matrix was initialized with numbers taken from the ground truth, and later refined through the BaumWelch-algorithm [14]."}, {"heading": "3 Data and Experiments", "text": "Two separate, yet related datasets were used in this work. Both were recorded during laparoscopic cholecystectomies, which is the minimally invasive removal of the gallbladder, on real patients in the same hospital, after obtaining appropriate ethics approval. The first dataset, herein called \u201cA\u201d, consists of 5 surgeries, of which the laparoscopic video stream, as well as instrument usage and other sensor data were collected. This dataset includes the four recordings used in [6], with one additional surgery added afterwards in the same manner. The second dataset, denoted \u201cB\u201d, contains a total of 18 surgeries, although only sensor data, but no video information was stored in these cases. The sensor data includes 12 binary signals, mainly instrument usage [15] and device activation states, 4 analog signals, such as irrigation weight or intra-abdominal pressure, and the time passed (in seconds) since the start of the surgery. The same 7 surgical phase definitions were used in both cases: Trocar placement, Preparation, Clipping, Detaching gallbladder, Retrieving gallbladder, Hemostasis, and Closing. Unless otherwise noted, all of the following experiments were performed on both datasets separately, each time in leave-one-surgery-out fashion, in order to do cross validation.\nFor the first experiments, we applied both the RF and HMM to the raw sensor data of each dataset directly. The RF classifier reached an overall accuracy of 69.9% on dataset A, and 70.1% on dataset B, with average Jaccard indices of 60.0% and 57.1% respectively, successfully recreating the setup and results of the work presented in [6]. The HMM achieved an accuracy of 41.8% on the first dataset, and 48.1% on the second, larger dataset, while the average Jaccard indices attained 32.8% and 30.3% each.\nAs mentioned above, classification of individual frames can be susceptible to signal noise, so in order to improve the signal quality, the data was filtered and augmented for the next experiment. A sliding window median filter over 120 frames was applied to the analog sensor data for smoothing, and the difference of the original and the filtered signals was kept in the dataset as additional noise signal (Fig. 2). After processing the first dataset in such a way, the RF achieved an accuracy of 72.0%, and an average Jaccard index of 62.8%. Since median filters do not provide a reasonable filtering on binary signals, these were additionally augmented with two separate, time-dependent features each (Fig. 3). The cumulative sum over the binary signal since beginning of the recording is the first additional feature. This feature exhibits a continuous increase in value during usage, flat areas during inactivity, and shallow, unstable increases during noisy periods. The second feature is the sum of rising signal edges since surgery start. This feature has a mainly flat progress during both continuous use and inactivity, but grows rapidly with noisy segments. Training the RF on the datasets with augmentations for analog and digital signals produced mixed results. The overall accuracy dropped for dataset A to 64.0%, but slightly increased to 71.5% on dataset B, while the average Jaccard index improved on both datasets to 65.3% and 60.3% each. The classifications in this case were generally clearer, yet the short phase \u201cClipping\u201d was completely skipped for some datasets during testing.\nFinally, the two methods of RF and HMM have been combined as described in section 2. Due to the increased requirement for training data, this experiment could not be performed on the first dataset, so all results reported here were achieved on dataset B only. As expected, the output of the combined classifier was more consistent than the pure RF output, yet the phase transitions were more reliable than from the HMM alone (Fig. 4). An accuracy of 80.8% was reached on the raw sensor data, and 82.4% after applying the noise-filtering step. The average Jaccard in this case reached 71.1%."}, {"heading": "4 Discussion", "text": "We collected simple, 1-dimensional signals for multiple surgeries, with the goal to detect the surgical workflow only from these signals. We compared the classification quality of Random Forests and Hidden Markov Models, as well as the effect of data\naugmentation in this limited case. Finally, we connected both classifiers, and were able to notably improve the detection result with this novel, combined approach. The recognition of surgical phases with HMM based only on such simple signals did not yield reliable results. This can likely be attributed to the fact that the HMM cannot handle the severe signal noise well, and is unable to recover from misclassifications due to the strict left-to-right structure. Also processing the data in order to separate the noise from the expected signal, or providing auxiliary, derived signals only had a minor impact on the classification result. One conceivable explanation for this result is that these derived values were already implicitly represented in the internal decision structure of many random trees. Offering them as separate signal therefore only increased the probability of these values to influence each tree\u2019s decision, without actually providing new information. The combination of RF and HMM succeeded in enhancing the detection result. While the RF has the main influence on the overall classification and phase detection, the HMM positively could filter out erroneous phase changes due to the strict modelling structure. While video data has also been recorded for some surgeries, it was not yet utilized in this work. Preliminary results suggest that the inclusion of feature data extracted from the video stream can further enhance detection results. Comparing such a system to a more complex, yet possibly slower deep neural network has to be done in future works.\nReferences\n1. Cleary K, Kinsella A, Mun SK (2005) OR 2020 workshop report: Operating\nroom of the future. Int Congr Ser 1281:832\u2013838. doi: 10.1016/j.ics.2005.03.279\n2. Lalys F, Jannin P (2014) Surgical process modelling: a review. Int J Comput\nAssist Radiol Surg 9:495\u2013511. doi: 10.1007/s11548-013-0940-5\n3. Franke S, Meixensberger J, Neumuth T (2015) Multi-perspective workflow\nmodeling for online surgical situation models. J Biomed Inform 54:158\u2013166. doi: 10.1016/j.jbi.2015.02.005\n4. Malpani A, Lea C, Chen CCG, Hager GD (2016) System events: readily\naccessible features for surgical phase detection. Int J Comput Assist Radiol Surg 11:1201\u20131209. doi: 10.1007/s11548-016-1409-0\n5. Forestier G, Riffaud L, Jannin P (2015) Automatic phase prediction from low-\nlevel surgical activities. Int J Comput Assist Radiol Surg 10:833\u201341. doi: 10.1007/s11548-015-1195-0\n6. Stauder R, Okur A, Peter L, Schneider A, Kranzfelder M, Feu\u00dfner H, Navab\nN (2014) Random Forests for Phase Detection in Surgical Workflow Analysis. 5th Int. Conf. Inf. Process. Comput. Interv.\n7. Twinanda AP, Shehata S, Mutter D, Marescaux J, de Mathelin M, Padoy N\n(2016) EndoNet: A Deep Architecture for Recognition Tasks on Laparoscopic Videos.\n8. Haro BB, Zappella L, Vidal R (2012) Surgical Gesture Classification from\nVideo Data. In: MICCAI. pp 1\u20138\n9. Blum T, Feu\u00dfner H, Navab N (2010) Modeling and segmentation of surgical\nworkflow from laparoscopic video. Med Image Comput Comput Assist Interv 13:400\u20137.\n10. Zia A, Zhang C, Xiong X, Jarc AM (2017) Temporal clustering of surgical\nactivities in robot-assisted surgery. Int J Comput Assist Radiol Surg 1\u201312. doi: 10.1007/s11548-017-1600-y\n11. Dergachyova O, Bouget D, Huaulm\u00e9 A, Morandi X, Jannin P (2016)\nAutomatic data-driven real-time segmentation and recognition of surgical workflow. Int J Comput Assist Radiol Surg 11:1081\u20131089. doi: 10.1007/s11548-016-1371-x\n12. Criminisi A (2011) Decision Forests: A Unified Framework for\nClassification, Regression, Density Estimation, Manifold Learning and SemiSupervised Learning. Found Trends\u00ae Comput Graph Vis 7:81\u2013227. doi: 10.1561/0600000035\n13. Rabiner LR (1989) A tutorial on hidden Markov models and selected\napplications in speech recognition. Proc IEEE 77:257\u2013286. doi: 10.1109/5.18626\n14. Yamato J, Ohya J, Ishii K (1992) Recognizing human action in time-\nsequential images using hidden Markov model. In: Proc. 1992 IEEE Comput. Soc. Conf. Comput. Vis. Pattern Recognit. IEEE Comput. Soc. Press, pp 379\u2013 385\n15. Kranzfelder M, Schneider A, Fiolka A, Schwan E, Gillen S, Wilhelm D,\nSchirren R, Reiser S, Jensen B, Feu\u00dfner H (2013) Real-time instrument detection in minimally invasive surgery using radiofrequency identification technology. J Surg Res 1\u20137. doi: 10.1016/j.jss.2013.06.022"}], "references": [{"title": "Surgical process modelling: a review", "author": ["F Lalys", "P Jannin"], "venue": "Int J Comput Assist Radiol Surg 9:495\u2013511", "citeRegEx": "2", "shortCiteRegEx": "2", "year": 2014}, {"title": "Multi-perspective workflow modeling for online surgical situation models", "author": ["S Franke", "J Meixensberger", "T Neumuth"], "venue": "J Biomed Inform 54:158\u2013166", "citeRegEx": "3", "shortCiteRegEx": "3", "year": 2015}, {"title": "System events: readily accessible features for surgical phase detection", "author": ["A Malpani", "C Lea", "CCG Chen", "GD Hager"], "venue": "Int J Comput Assist Radiol Surg 11:1201\u20131209", "citeRegEx": "4", "shortCiteRegEx": "4", "year": 2016}, {"title": "Automatic phase prediction from lowlevel surgical activities", "author": ["G Forestier", "L Riffaud", "P Jannin"], "venue": "Int J Comput Assist Radiol Surg 10:833\u201341", "citeRegEx": "5", "shortCiteRegEx": "5", "year": 2015}, {"title": "Random Forests for Phase Detection in Surgical Workflow Analysis", "author": ["R Stauder", "A Okur", "L Peter", "A Schneider", "M Kranzfelder", "H Feu\u00dfner", "N Navab"], "venue": null, "citeRegEx": "6", "shortCiteRegEx": "6", "year": 2014}, {"title": "EndoNet: A Deep Architecture for Recognition Tasks on Laparoscopic Videos", "author": ["AP Twinanda", "S Shehata", "D Mutter", "J Marescaux", "M de Mathelin", "N Padoy"], "venue": null, "citeRegEx": "7", "shortCiteRegEx": "7", "year": 2016}, {"title": "Surgical Gesture Classification from Video Data. In: MICCAI", "author": ["BB Haro", "L Zappella", "R Vidal"], "venue": null, "citeRegEx": "8", "shortCiteRegEx": "8", "year": 2012}, {"title": "Modeling and segmentation of surgical workflow from laparoscopic video", "author": ["T Blum", "H Feu\u00dfner", "N Navab"], "venue": "Med Image Comput Comput Assist Interv 13:400\u20137", "citeRegEx": "9", "shortCiteRegEx": "9", "year": 2010}, {"title": "Temporal clustering of surgical activities in robot-assisted surgery", "author": ["A Zia", "C Zhang", "X Xiong", "AM Jarc"], "venue": "Int J Comput Assist Radiol Surg 1\u201312. doi: 10.1007/s11548-017-1600-y", "citeRegEx": "10", "shortCiteRegEx": "10", "year": 2017}, {"title": "Automatic data-driven real-time segmentation and recognition of surgical workflow", "author": ["O Dergachyova", "D Bouget", "A Huaulm\u00e9", "X Morandi", "P Jannin"], "venue": "Int J Comput Assist Radiol Surg 11:1081\u20131089", "citeRegEx": "11", "shortCiteRegEx": "11", "year": 2016}, {"title": "Decision Forests: A Unified Framework for Classification, Regression, Density Estimation, Manifold Learning and SemiSupervised Learning", "author": ["A Criminisi"], "venue": "Found Trends\u00ae Comput Graph Vis 7:81\u2013227", "citeRegEx": "12", "shortCiteRegEx": "12", "year": 2011}, {"title": "A tutorial on hidden Markov models and selected applications in speech recognition", "author": ["LR Rabiner"], "venue": "Proc IEEE 77:257\u2013286", "citeRegEx": "13", "shortCiteRegEx": "13", "year": 1989}, {"title": "Recognizing human action in timesequential images using hidden Markov model", "author": ["J Yamato", "J Ohya", "K Ishii"], "venue": "IEEE Comput. Soc. Conf. Comput. Vis. Pattern Recognit. IEEE Comput. Soc. Press,", "citeRegEx": "14", "shortCiteRegEx": "14", "year": 1992}, {"title": "Real-time instrument detection in minimally invasive surgery using radiofrequency identification technology", "author": ["M Kranzfelder", "A Schneider", "A Fiolka", "E Schwan", "S Gillen", "D Wilhelm", "R Schirren", "S Reiser", "B Jensen", "H Feu\u00dfner"], "venue": "J Surg Res 1\u20137. doi: 10.1016/j.jss.2013.06.022", "citeRegEx": "15", "shortCiteRegEx": "15", "year": 2013}], "referenceMentions": [{"referenceID": 0, "context": "Different approaches exist in the field of surgical workflow recognition [2], which is also an aspect of the recently defined area of surgical data science.", "startOffset": 73, "endOffset": 76}, {"referenceID": 1, "context": "Some methods try to extract a structured model from recorded surgeries [3], while others directly try to recognize the surgical phases or activities through instrument and sensor data [4\u2013 6], laparoscopic video [7\u20139], kinematics information [10], or a mixture thereof [11].", "startOffset": 71, "endOffset": 74}, {"referenceID": 4, "context": "Some methods try to extract a structured model from recorded surgeries [3], while others directly try to recognize the surgical phases or activities through instrument and sensor data [4\u2013 6], laparoscopic video [7\u20139], kinematics information [10], or a mixture thereof [11].", "startOffset": 184, "endOffset": 190}, {"referenceID": 5, "context": "Some methods try to extract a structured model from recorded surgeries [3], while others directly try to recognize the surgical phases or activities through instrument and sensor data [4\u2013 6], laparoscopic video [7\u20139], kinematics information [10], or a mixture thereof [11].", "startOffset": 211, "endOffset": 216}, {"referenceID": 6, "context": "Some methods try to extract a structured model from recorded surgeries [3], while others directly try to recognize the surgical phases or activities through instrument and sensor data [4\u2013 6], laparoscopic video [7\u20139], kinematics information [10], or a mixture thereof [11].", "startOffset": 211, "endOffset": 216}, {"referenceID": 7, "context": "Some methods try to extract a structured model from recorded surgeries [3], while others directly try to recognize the surgical phases or activities through instrument and sensor data [4\u2013 6], laparoscopic video [7\u20139], kinematics information [10], or a mixture thereof [11].", "startOffset": 211, "endOffset": 216}, {"referenceID": 8, "context": "Some methods try to extract a structured model from recorded surgeries [3], while others directly try to recognize the surgical phases or activities through instrument and sensor data [4\u2013 6], laparoscopic video [7\u20139], kinematics information [10], or a mixture thereof [11].", "startOffset": 241, "endOffset": 245}, {"referenceID": 9, "context": "Some methods try to extract a structured model from recorded surgeries [3], while others directly try to recognize the surgical phases or activities through instrument and sensor data [4\u2013 6], laparoscopic video [7\u20139], kinematics information [10], or a mixture thereof [11].", "startOffset": 268, "endOffset": 272}, {"referenceID": 10, "context": "In this work we will apply both Random Forests (RF) [12] and Hidden Markov Models (HMM) [13], separately and combined, to recognize the surgical phase from instrument and sensor data.", "startOffset": 52, "endOffset": 56}, {"referenceID": 11, "context": "In this work we will apply both Random Forests (RF) [12] and Hidden Markov Models (HMM) [13], separately and combined, to recognize the surgical phase from instrument and sensor data.", "startOffset": 88, "endOffset": 92}, {"referenceID": 10, "context": "RF are a collection of randomized decision trees [12].", "startOffset": 49, "endOffset": 53}, {"referenceID": 11, "context": "HMMs can be used to estimate and model the internal state of a system based on the trained network structure and recorded observations [13].", "startOffset": 135, "endOffset": 139}, {"referenceID": 12, "context": "This calculated confusion matrix was used directly as emission matrix for the HMM, while the transition matrix was initialized with numbers taken from the ground truth, and later refined through the BaumWelch-algorithm [14].", "startOffset": 219, "endOffset": 223}, {"referenceID": 4, "context": "This dataset includes the four recordings used in [6], with one additional", "startOffset": 50, "endOffset": 53}, {"referenceID": 13, "context": "The sensor data includes 12 binary signals, mainly instrument usage [15] and device activation states, 4 analog signals, such as irrigation weight or intra-abdominal pressure, and the time passed (in seconds) since the start of the surgery.", "startOffset": 68, "endOffset": 72}, {"referenceID": 4, "context": "1% respectively, successfully recreating the setup and results of the work presented in [6].", "startOffset": 88, "endOffset": 91}], "year": 2017, "abstractText": "A modern operating room (OR) provides a plethora of advanced medical devices. In order to better facilitate the information offered by them, they need to automatically react to the intra-operative context. To this end, the progress of the surgical workflow must be detected and interpreted, so that the current status can be given in machine-readable form. In this work, Random Forests (RF) and Hidden Markov Models (HMM) are compared and combined to detect the surgical workflow phase of a laparoscopic cholecystectomy. Various combinations of data were tested, from using only raw sensor data to filtered and augmented datasets. Achieved accuracies ranged from 64% to 72% for the RF approach, and from 80% to 82% for the combina-", "creator": "Microsoft\u00ae Word 2016"}}}