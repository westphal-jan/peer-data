{"id": "1706.01875", "review": {"conference": "arxiv", "VERSION": "v1", "DATE_OF_SUBMISSION": "6-Jun-2017", "title": "Measuring Offensive Speech in Online Political Discourse", "abstract": "traditionally the internet and online dialogue forums including such as reddit sites have become an nevertheless increasingly surprisingly popular medium for citizens to engage in frequent political hack conversations. increasingly however, the overall online disinhibition effect resulting from avoiding the ability to use pseudonymous authoritative identities may however manifest today in the form indicative of \" offensive provocative speech, consequently making political discussions more aggressive and historically polarizing than parties they historically already typically are. such environments repeatedly may result in massive harassment attacks and self - censorship from its targets. secondly in executing this draft paper, shall we present preliminary results from a large - scale temporal measurement aimed not at quantifying offensiveness as in using online political discussions.", "histories": [["v1", "Tue, 6 Jun 2017 21:29:23 GMT  (902kb,D)", "http://arxiv.org/abs/1706.01875v1", null], ["v2", "Wed, 19 Jul 2017 17:24:51 GMT  (808kb,D)", "http://arxiv.org/abs/1706.01875v2", null]], "reviews": [], "SUBJECTS": "cs.CL cs.CY cs.SI", "authors": ["rishab nithyanand", "brian schaffner", "phillipa gill"], "accepted": false, "id": "1706.01875"}, "pdf": {"name": "1706.01875.pdf", "metadata": {"source": "CRF", "title": "Measuring Offensive Speech in Online Political Discourse", "authors": ["Rishab Nithyanand", "Brian Schaffner"], "emails": [], "sections": [{"heading": null, "text": "To enable our measurements, we develop and evaluate an offensive speech classifier. We then use this classifier to quantify and compare offensiveness in the political and general contexts. We perform our study using a database of over 168M Reddit comments made by over 7M pseudonyms between January 2015 and January 2017 \u2013 a period covering several divisive political events including the 2016 US presidential elections."}, {"heading": "1 Introduction", "text": "The apparent rise in political incivility has attracted substantial attention from scholars in recent years. These studies have largely focused on the extent to which politicians and elected officials are increasingly employing rhetoric that appears to violate norms of civility [4, 12]. The 2016 US presidential election was an especially noteworthy case in this regard, particularly in terms of Donald Trump\u2019s campaign which frequently violated norms of civility both in how he spoke about broad groups in the public (such as Muslims, Mexicans, and African Americans) and the attacks he leveled at his opponents [2]. The consequences of incivility are thought to be crucial to the functioning of democracy since \u201cpublic civility and interpersonal politeness sustain social har-\nmony and allow people who disagree with one another to maintain ongoing relationships\u201d [16].\nWhile political incivility appears to be on the rise among elites, it is less clear whether this is true among the mass public as well. Is political discourse particularly lacking in civility compared to discourse more generally? Does the incivility of mass political discourse respond to the dynamics of political campaigns? Addressing these questions has been difficult for political scientists because traditional tools for studying mass behavior, such as public opinion surveys, are ill-equipped to measure how citizens discuss politics with one another. Survey data does reveal that the public tends to perceive politics as becoming increasingly less civil during the course of a political campaign [17]. Yet, it is not clear whether these perceptions match the reality, particularly in terms of the types of discussions that citizens have with each other.\nAn additional question is how incivility is received by others. On one hand, violations of norms regarding offensive discourse may be policed by members of a community, rendering such speech ineffectual. On the other hand, offensive speech may be effective as a means for drawing attention to a particular argument. Indeed, there is evidence that increasing incivility in political speech results in higher levels of attention from the public [12]. During the 2016 campaign, the use of swearing in comments posted on Donald Trump\u2019s YouTube channel tended to result in additional responses that mimicked such swearing [8]. Thus, offensive speech in online fora may attract more attention from the community and lead to the spread of even more offensive speech in subsequent posts.\nTo address these questions regarding political incivility, we examine the use of offensive speech in political discussions housed on Reddit. Scholars tend to define uncivil discourse as \u201ccommunication that violates the norms of politeness\u201d [12] a definition that clearly includes offensive remarks. Reddit fora represent a \u201cmost likely\u201d case for the study of offensive political speech\nar X\niv :1\n70 6.\n01 87\n5v 1\n[ cs\n.C L\n] 6\nJ un\n2 01\ndue to the ability of participants to use pseudonymous identities. That is, if political incivility in the public did increase during the 2016 campaign, this should be especially evident on fora such as Reddit. Tracking Reddit discussions throughout all of 2015 and 2016, we find that online political discussions became increasingly more offensive as the general election campaign intensified. By comparison, discussions on non-political subreddits did not become increasingly offensive during this period. Notably, the presence of offensive comments did not subside after the election, suggesting that 2016 may have set a new baseline for political incivility, at least for the near future."}, {"heading": "2 Datasets", "text": "Our study makes use of multiple datasets in order to identify and characterize trends in offensive speech.\nThe CrowdFlower hate speech dataset. The CrowdFlower hate speech dataset [1] contains 14.5K tweets, each receiving labels from at least three contributors. Contributors were allowed to classify each tweet into one of three classes: Not Offensive (NO), Offensive but not hateful (O), and Offensive and hateful (OH). Of the 14.5K tweets, only 37.6% had a decisive class \u2013 i.e., the same class was assigned by all contributors. For indecisive cases, the majority class was selected and a class confidence score (fraction of contributors that selected the majority class) was made available. Using this approach, 50.4%, 33.1%, and 16.5% of the tweets were categorized as NO, O, and OH, respectively. Since our goal is to identify any offensive speech (not just hate speech), we consolidate assigned classes into Offensive and Not Offensive by relabeling OH tweets as Offensive. We use this modified dataset to train, validate, and test our offensive speech classifier.\nOffensive word lists. We also use two offensive word lists as auxiliary input to our classifier: (1) The Hatebase hate speech vocabulary [3] consisting of 1122 hateful words and (2) 422 offensive words banned from Google\u2019s What Do You Love project [7].\nReddit comments dataset. Finally, after building our offensive speech classifier using the above datasets, we use it to classify comments made on Reddit. While the complete Reddit dataset contains 2B comments made between the period of January 2015 and January 2017, we only analyze only 168M. We select comments to be analyzed using the following process: (1) we exclude comments shorter than 10 characters in length, (2) we exclude comments made by [deleted] authors, and (3) we randomly sample and include 10% of all remaining comments. We categorize comments made in any of 21 popular political subreddits as political and the remain-\nder as apolitical. Our final dataset contains 129M apolitical and 39M political comments. Figure 1 shows the number of comments in our dataset that were made during each week included in our study. We see an increasing number of political comments per week starting in February 2016 \u2013 the start of the 2016 US presidential primaries."}, {"heading": "3 Offensive Speech Classification", "text": "In order to identify offensive speech, we propose a fully automated technique that classifies comments into two classes: Offensive and Not Offensive."}, {"heading": "3.1 Classification approach", "text": "At a high-level, our approach works as follows:\n\u2022 Build a word embedding. We construct a 100- dimensional word embedding using all comments from our complete Reddit dataset (2B comments).\n\u2022 Construct a hate vector. We construct a list of offensive and hateful words identified from external data and map them into a single vector within the high-dimensional word embedding.\n\u2022 Text transformation and classification. Finally, we transform text to be classified into scalars representing their distance from the constructed hate vector and use these as input to a Random Forest classifier.\nBuilding a word embedding. At a high-level, a word embedding maps words into a high-dimensional continuous vector space in such a way that semantic similarities between words are maintained. This mapping is achieved by exploiting the distributional properties of words and their occurrences in the input corpus.\nRather than using an off-the-shelf word embedding (e.g., the GloVe embeddings [13] trained using public domain data sources such as Wikipedia and news articles), we construct a 100-dimensional embedding using the complete Reddit dataset (2B comments) as the input corpus. The constructed embedding consists of over 400M unique words (words occurring less than 25 times in the entire corpus are excluded) using the Word2Vec [10] implementation provided by the Gensim library [14]. Prior to constructing the embedding, we perform stop-word removal and lemmatize each word in the input corpus using the SpaCy NLP framework [5]. The main reason for building a custom embedding is to ensure that our embeddings capture semantics specific to the data being measured (Reddit) \u2013 e.g., while the word \u201ckarma\u201d in the non-Reddit context may be associated with spirituality, it is associated with points (comment and submission scores) on Reddit.\nConstructing a hate vector. We use two lists of words associated with hate [3] and offensive [7] speech to construct a hate vector in our word embedding. This is done by mapping each word in the list into the 100- dimensional embedding and computing the mean vector. This vector represents the average of all known offensive words. The main idea behind creating a hate vector is to capture the point (in our embedding) to which the most offensive observed comments are likely to be near. Although clustering our offensive word lists into similar groups and constructing multiple hate vectors \u2013 one for each cluster \u2013 results in marginally better accuracy for our classifier, we use this approach due to the fact that our classification cost grows linearly with the number of hate vectors \u2013 i.e., we need to perform O(|S|) distance computations per hate vector to classify string S.\nTransforming and classifying text. We first remove stop-words and perform lemmatization of each word in the text to be classified. We then obtain the vector representing each word in the text and compute its similarity\nto the constructed hate vector using the cosine similarity metric. A 0-vector is used to represent words in the text that are not present in the embedding. Finally, the maximum cosine similarity score is used to represent the comment. Equation 1 shows the transformation function on a string S = {s1, . . . ,sn} where si is the vector representing the ith lemmatized non-stop-word, cos is the cosine-similarity function, and H is the hate vector.\nT (S) = max 1\u2264i\u2264n [cos(si,H)] (1)\nIn words, the numerical value assigned to a text is the cosine similarity between the hate vector and the vector representing the word (in the text) closest to the hate vector. This approach allows us to transform a string of text into a single numerical value that captures its semantic similarity to the most offensive comment. We use these scalars as input to a random forest classifier to perform classification into Offensive and Not Offensive classes. Figure 2 shows the proximity of Offensive and Non Offensive comments to our constructed hate vector after using t-distributed Stochastic Neighbor Embedding (t-SNE) [9] to reduce our 100-dimension vector space into 2 dimensions."}, {"heading": "3.2 Classifier evaluation", "text": "We now present results to (1) validate our choice of classifier and (2) demonstrate the impact of training/validation sample count on our classifiers performance.\nClassifier selection methodology. To identify the most suitable classifier for classifying the scalars associated with each text, we perform evaluations using the stochastic gradient descent, naive bayes, decision tree, and random forest classifiers. For each classifier, we split the CrowdFlower hate speech dataset into a training/validation set (75%), and a holdout set (25%). We perform 10-fold cross-validation on the training/validation set to identify the best classifier model and parameters (using a grid search). Based on the results of this evaluation, we select a 100-estimator entropy-based\nsplitting random forest model as our classifier. Table 1 shows the mean accuracy and F1-score for each evaluated classifier during the 10-fold cross-validation. Real-world classifier performance. To evaluate realworld performance of our selected classifier (i.e., performance in the absence of model and parameter bias), we perform classification of the holdout set. On this set, our classifier had an accuracy and F1-score of 89.6% and 89.2%, respectively. These results show that in addition to superior accuracy during training and validation, our chosen classifier is also robust against over-fitting. Impact of dataset quality and size. To understand how the performance of our chosen classifier model and parameters are impacted by: (1) the quality and consistency of manually assigned classes in the CrowdFlower dataset and (2) the size of the dataset, we re-evaluate the classifier while only considering tweets having a minimum confidence score and varying the size of the holdout set. Specifically, our experiments considered confidence thresholds of 0 (all tweets considered), .35 (only tweets where at least 35% of contributors agreed on a class were\nconsidered), and .70 (only tweets where at least 70% of the contributors agreed on a class were considered) and varied the holdout set sizes between 5% and 95% of all tweets meeting the confidence threshold set for the experiment.\nThe results illustrated in Figure 3 show the performance of the classifier while evaluating the corresponding holdout set. We make several conclusions from these results:\n\u2022 Beyond a (fairly low) threshold, the size of the training and validation set has little impact on classifier performance. We see that the accuracy, precision, and recall have, at best, marginal improvements with holdout set sizes smaller than 60%. This implies that the CrowdFlower dataset is sufficient for building an offensive speech classifier.\n\u2022 Quality of manual labeling has a significant impact on the accuracy and precision of the classifier. Using only tweets which had at least 70% of contributors agreeing on a class resulted in between 5-7% higher accuracy and up to 5% higher precision.\n\u2022 Our classifier achieves precision of over 95% and recall of over 85% when considering only high confidence samples. This implies that the classifier is more likely to underestimate the presence of offensive speech \u2013 i.e., our results likely provide a lowerbound on the quantity of observed offensive speech."}, {"heading": "4 Measurements", "text": "In this section we quantify and characterize offensiveness in the political and general contexts using our offensive speech classifier and the Reddit comments dataset which considers a random sample of comments made between January 2015 and January 2017.\nOffensiveness over time. We find that on average 8.4% of all political comments are offensive compared to 7.8% of all apolitical comments. Figure 4 illustrates the fraction of offensive political and apolitical comments made during each week in our study. We see that while the fraction of apolitical offensive comments has stayed steady, there has been an increase in the fraction of offensive political comments starting in July 2016. Notably, this increase is observed after the conclusion of the US presidential primaries and during the period of the Democratic and Republican National Conventions and does not reduce even after the conclusion of the US presidential elections held on November 8. Participants in political subreddits were 2.6% more likely to observe offensive comments prior to July 2016 but 14.9% more likely to observe offensive comments from July 2016 onwards.\nReactions to offensive comments. We use the comment score, roughly the difference between up-votes and down-votes received, as a proxy for understanding how users reacted to offensive comments. We find that comments that were offensive: (1) on average, had a higher score than non-offensive comments (average scores: 8.9 vs. 6.7) and (2) were better received when they were posted in the general context than in the political context (average scores: 8.6 vs. 9.0). To understand how peoples reactions to offensive comments evolved over time, Figure 5 shows the average scores received by offensive comments over time. Again, we observe an increasing trend in average scores received by offensive and political comments after July 2016.\nCharacteristics of offensive authors. We now focus on understanding characteristics of authors of offensive comments. Specifically, we are interested in identifying the use of throwaway and troll accounts. We find that 26% of all authors with at least one offensive comment have over 75% of all their comments identified as offensive. Further, 93.7% of these authors appear to use throwaway accounts (identified as accounts with less than 5 total comments), while only 1.3% appear to use troll accounts (identified as accounts with more than 15 total comments). Complete results are illustrated in Figure 6.\nCharacteristics of offensive communities. We break-\ndown subreddits by their category (default, political, and other) and identify the most and least offensive communities in each. Figure 7 shows the distribution of the fraction of offensive comments in each category and Table 2 shows the most and least offensive subreddits in the political and default categories (we exclude the \u201cother\u201d category due to the inappropriateness of their names). We find that less than 19% of all subreddits (that account for over 23% of all comments) have over 10% offensive comments. Further, several default and political subreddits fall in this category, including r/the donald \u2013 the most offensive political subreddit and the subreddit dedicated to the US President.\nFlow of offensive authors. Finally, we uncover patterns in the movement of offensive authors between communities. In Figure 8 we show the communities in which large number of authors of offensive content on the r/politics subreddut had previously made offensive comments (we refer to these communities as sources). Unsurprisingly, the most popular sources belonged to the default subreddits (e.g., r/worldnews,\nr/wtf, r/videos, r/askreddit, and r/news). We find that several other political subreddits also serve as large sources of offensive authors. In fact, the subreddits dedicated to the three most popular US presidential candidates \u2013 r/the donald, r/sandersforpresident, and r/hillaryclinton rank in the top three. Finally, outside of the default and political subreddits, we find that r/nfl, r/conspiracy, r/dota2, r/reactiongifs, r/blackpeopletwitter, and r/imgoingtohellforthis were the largest sources of offensive political authors."}, {"heading": "5 Conclusions and Future Work", "text": "We develop and validate an offensive speech classifier to quantify the presence of offensive online comments from January 2015 through January 2017. We find that political discussions on Reddit became increasingly less civil \u2013 as measured by the incidence of offensive comments \u2013\nduring the 2016 general election campaign. In fact, during the height of the campaign, nearly one of every 10 comments posted on a political subreddit were classified as offensive. Offensive comments also received more positive feedback from the community, even though over three-fourths of the authors of such comments appear to come from throwaway accounts. While offensive posts were increasingly common on political subreddits as the campaign wore on, there was no such increase in nonpolitical fora. This contrast provides additional evidence that the increasing use of offensive speech was directly related to the ramping up of the general election campaign for president.\nOur findings provide a unique and important mapping of the increasing incivility of online political discourse during the 2016 campaign. Such an investigation is important because scholars have outlined many consequences for incivility in political discourse. Incivility tends to \u201cturn off\u201d political moderates, leading to increasing polarization among those who are actively engaged in politics [17]. More importantly, a lack of civility in political discussions generally reduces the degree to which people view opponents as holding legitimate viewpoints. This dynamic makes it difficult for people to find common ground with those who disagree with them [11] and it may ultimately lead citizens to view electoral victories by opponents as lacking legitimacy [12]. Thus, from a normative standpoint, the fact that the 2016 campaign sparked a marked increase in the offensiveness of political comments posted to Reddit is of concern in its own right; that the incidence of offensive political comments has remained high even after the election is all the more troubling.\nIn future work, we will extend our analysis of Reddit back to 2007 with the aim of formulating a more complete understanding of the dynamics of political incivility. For example, we seek to understand whether the high incidence of offensive speech we find in 2016 is unique to this particular campaign or if previous presidential campaigns witnessed similar spikes in incivility. We will also examine whether there is a more general long-term trend toward offensive online political speech, which would be consistent with what scholars have found when studying political elites [6, 15]."}], "references": [{"title": "Hate speech identification", "author": ["CrowdFlower Blog"], "venue": "URL: https://www.crowdflower.com/data/h ate-speech-identification/ (Accessed May", "citeRegEx": "1", "shortCiteRegEx": "1", "year": 2017}, {"title": "Twitter taunts and tirades: Negative campaigning in the age 6  of trump", "author": ["Justin H Gross", "Kaylee T Johnson"], "venue": "PS: Political Science  Politics,", "citeRegEx": "2", "shortCiteRegEx": "2", "year": 2016}, {"title": "Rude democracy: Civility and incivility in American politics", "author": ["Susan Herbst"], "venue": null, "citeRegEx": "4", "shortCiteRegEx": "4", "year": 2010}, {"title": "An Improved Non-monotonic Transition System for Dependency Parsing", "author": ["Matthew Honnibal", "Mark Johnson"], "venue": "In Proceedings of the 2015 Conference on Empirical Methods in Natural Language Processing,", "citeRegEx": "5", "shortCiteRegEx": "5", "year": 2015}, {"title": "Continuity and change in civility in the house", "author": ["Kathleen Hall Jamieson", "Erika Falk"], "venue": null, "citeRegEx": "6", "shortCiteRegEx": "6", "year": 2000}, {"title": "Is aggression contagious online? a case of swearing on donald trump\u2019s campaign videos on youtube", "author": ["K Hazel Kwon", "Anatoliy Gruzd"], "venue": "In Proceedings of the 50th Hawaii International Conference on System Sciences,", "citeRegEx": "8", "shortCiteRegEx": "8", "year": 2017}, {"title": "Visualizing Data Using t-SNE", "author": ["Laurens van der Maaten", "Geoffrey Hinton"], "venue": "Journal of Machine Learning Research,", "citeRegEx": "9", "shortCiteRegEx": "9", "year": 2008}, {"title": "Distributed Representations of Words and Phrases and their Compositionality", "author": ["Tomas Mikolov", "Ilya Sutskever", "Kai Chen", "Greg S Corrado", "Jeff Dean"], "venue": "In Advances in neural information processing systems,", "citeRegEx": "10", "shortCiteRegEx": "10", "year": 2013}, {"title": "Hearing the other side: Deliberative versus participatory democracy", "author": ["Diana C Mutz"], "venue": null, "citeRegEx": "11", "shortCiteRegEx": "11", "year": 2006}, {"title": "In-your-face politics: The consequences of uncivil media", "author": ["Diana C Mutz"], "venue": null, "citeRegEx": "12", "shortCiteRegEx": "12", "year": 2015}, {"title": "GloVe: Global Vectors for Word Representation", "author": ["Jeffrey Pennington", "Richard Socher", "Christopher D. Manning"], "venue": "In Empirical Methods in Natural Language Processing (EMNLP),", "citeRegEx": "13", "shortCiteRegEx": "13", "year": 2014}, {"title": "Software Framework for Topic Modelling with Large Corpora", "author": ["Radim \u0158eh\u016f\u0159ek", "Petr Sojka"], "venue": "In Proceedings of the LREC 2010 Workshop on New Challenges for NLP Frameworks,", "citeRegEx": "14", "shortCiteRegEx": "14", "year": 2010}, {"title": "The rise and fall of nasty politics in america", "author": ["Daniel M Shea", "Alex Sproveri"], "venue": "PS: Political Science  Politics,", "citeRegEx": "15", "shortCiteRegEx": "15", "year": 2012}, {"title": "Incivility and standing firm: A second layer of partisan division", "author": ["Michael R Wolf", "J Cherie Strachan", "Daniel M Shea"], "venue": "PS: Political Science  Politics,", "citeRegEx": "17", "shortCiteRegEx": "17", "year": 2012}], "referenceMentions": [{"referenceID": 2, "context": "These studies have largely focused on the extent to which politicians and elected officials are increasingly employing rhetoric that appears to violate norms of civility [4, 12].", "startOffset": 170, "endOffset": 177}, {"referenceID": 9, "context": "These studies have largely focused on the extent to which politicians and elected officials are increasingly employing rhetoric that appears to violate norms of civility [4, 12].", "startOffset": 170, "endOffset": 177}, {"referenceID": 1, "context": "The 2016 US presidential election was an especially noteworthy case in this regard, particularly in terms of Donald Trump\u2019s campaign which frequently violated norms of civility both in how he spoke about broad groups in the public (such as Muslims, Mexicans, and African Americans) and the attacks he leveled at his opponents [2].", "startOffset": 326, "endOffset": 329}, {"referenceID": 13, "context": "Survey data does reveal that the public tends to perceive politics as becoming increasingly less civil during the course of a political campaign [17].", "startOffset": 145, "endOffset": 149}, {"referenceID": 9, "context": "Indeed, there is evidence that increasing incivility in political speech results in higher levels of attention from the public [12].", "startOffset": 127, "endOffset": 131}, {"referenceID": 5, "context": "During the 2016 campaign, the use of swearing in comments posted on Donald Trump\u2019s YouTube channel tended to result in additional responses that mimicked such swearing [8].", "startOffset": 168, "endOffset": 171}, {"referenceID": 9, "context": "Scholars tend to define uncivil discourse as \u201ccommunication that violates the norms of politeness\u201d [12] a definition that clearly includes offensive remarks.", "startOffset": 99, "endOffset": 103}, {"referenceID": 0, "context": "The CrowdFlower hate speech dataset [1] contains 14.", "startOffset": 36, "endOffset": 39}, {"referenceID": 10, "context": ", the GloVe embeddings [13] trained using public domain data sources such as Wikipedia and news articles), we construct a 100-dimensional embedding using the complete Reddit dataset (2B comments) as the input corpus.", "startOffset": 23, "endOffset": 27}, {"referenceID": 7, "context": "The constructed embedding consists of over 400M unique words (words occurring less than 25 times in the entire corpus are excluded) using the Word2Vec [10] implementation provided by the Gensim library [14].", "startOffset": 151, "endOffset": 155}, {"referenceID": 11, "context": "The constructed embedding consists of over 400M unique words (words occurring less than 25 times in the entire corpus are excluded) using the Word2Vec [10] implementation provided by the Gensim library [14].", "startOffset": 202, "endOffset": 206}, {"referenceID": 3, "context": "Prior to constructing the embedding, we perform stop-word removal and lemmatize each word in the input corpus using the SpaCy NLP framework [5].", "startOffset": 140, "endOffset": 143}, {"referenceID": 6, "context": "Figure 2 shows the proximity of Offensive and Non Offensive comments to our constructed hate vector after using t-distributed Stochastic Neighbor Embedding (t-SNE) [9] to reduce our 100-dimension vector space into 2 dimensions.", "startOffset": 164, "endOffset": 167}, {"referenceID": 13, "context": "Incivility tends to \u201cturn off\u201d political moderates, leading to increasing polarization among those who are actively engaged in politics [17].", "startOffset": 136, "endOffset": 140}, {"referenceID": 8, "context": "This dynamic makes it difficult for people to find common ground with those who disagree with them [11] and it may ultimately lead citizens to view electoral victories by opponents as lacking legitimacy [12].", "startOffset": 99, "endOffset": 103}, {"referenceID": 9, "context": "This dynamic makes it difficult for people to find common ground with those who disagree with them [11] and it may ultimately lead citizens to view electoral victories by opponents as lacking legitimacy [12].", "startOffset": 203, "endOffset": 207}, {"referenceID": 4, "context": "We will also examine whether there is a more general long-term trend toward offensive online political speech, which would be consistent with what scholars have found when studying political elites [6, 15].", "startOffset": 198, "endOffset": 205}, {"referenceID": 12, "context": "We will also examine whether there is a more general long-term trend toward offensive online political speech, which would be consistent with what scholars have found when studying political elites [6, 15].", "startOffset": 198, "endOffset": 205}], "year": 2017, "abstractText": "The Internet and online forums such as Reddit have become an increasingly popular medium for citizens to engage in political conversations. However, the online disinhibition effect resulting from the ability to use pseudonymous identities may manifest in the form of offensive speech, consequently making political discussions more aggressive and polarizing than they already are. Such environments may result in harassment and self-censorship from its targets. In this paper, we present preliminary results from a large-scale temporal measurement aimed at quantifying offensiveness in online political discussions. To enable our measurements, we develop and evaluate an offensive speech classifier. We then use this classifier to quantify and compare offensiveness in the political and general contexts. We perform our study using a database of over 168M Reddit comments made by over 7M pseudonyms between January 2015 and January 2017 \u2013 a period covering several divisive political events including the 2016 US presidential elections.", "creator": "TeX"}}}