{"id": "1706.04473", "review": {"conference": "arxiv", "VERSION": "v1", "DATE_OF_SUBMISSION": "14-Jun-2017", "title": "Idea density for predicting Alzheimer's disease from transcribed speech", "abstract": "idea quantity density ( lowest id ) using measures decreases the rate regardless at most which ideas or elementary semantic predications are explicitly expressed typically in scarcely an obvious utterance or in generating a hypothetical text. lower id is found to theoretically be typically associated with an obviously increased screening risk of developing alzheimer'early s inherited disease ( ad ) ( snowdon green et al., 1996 ; ron engelman et al., 2010 ). id has nevertheless been used in two technically different versions : information propositional idea density ( pid ) exclusively counts the expressed ideas and can be applied negatively to any text while descriptive semantic memory idea value density ( extended sid ) counts pre - defined information content and units and method is naturally more applicable as to regular normative domains, amongst such times as picture description research tasks. in this paper, we develop experimental depid, pioneering a novel dependency - model based control method unsuitable for computing null pid, and its particular version depid - r that enables to exclude further repeating ideas - - - plus a feature characteristic according to ad _ speech. theoretically we conduct the standard first comparison pattern of automatically extracted pid entries and paired sid in simultaneously the diagnostic info classification task on applying two theoretically different ad datasets covering both closed - topic and parallel free - recall domains. for while sequential sid estimation performs weakly better on the normative type dataset, adding these pid leads authors to forming a relatively small marginal but significant improvement ( + ratio 1. 8 7 from f - score ). on the dual free - topic indicator dataset, pid performs well better than subsequent sid combined as expected ( averaged 77. 24 6 vs 72. 3 places in current f - score ) lists but adding the features derived simultaneously from the word embedding dot clustering underlying the normally automatic generated sid chart increases the results considerably, leading to an even f - score of only 84. 8.", "histories": [["v1", "Wed, 14 Jun 2017 13:18:08 GMT  (31kb)", "http://arxiv.org/abs/1706.04473v1", "CoNLL 2017"]], "COMMENTS": "CoNLL 2017", "reviews": [], "SUBJECTS": "cs.CL", "authors": ["kairit sirts", "olivier piguet", "mark johnson"], "accepted": false, "id": "1706.04473"}, "pdf": {"name": "1706.04473.pdf", "metadata": {"source": "CRF", "title": "Idea density for predicting Alzheimer\u2019s disease from transcribed speech", "authors": ["Kairit Sirts", "Olivier Piguet", "Mark Johnson"], "emails": ["kairit.sirts@ut.ee,", "olivier.piguet@sydney.edu.au", "mark.johnson@mq.edu.au"], "sections": [{"heading": null, "text": "ar X\niv :1\n70 6.\n04 47\n3v 1\n[ cs\n.C L\n] 1\n4 Ju\nn 20\n17\nwhich ideas or elementary predications are expressed in an utterance or in a text. Lower ID is found to be associated with an increased risk of developing Alzheimer\u2019s disease (AD) (Snowdon et al., 1996; Engelman et al., 2010). ID has been used in two different versions: propositional idea density (PID) counts the expressed ideas and can be applied to any text while semantic idea density (SID) counts pre-defined information content units and is naturally more applicable to normative domains, such as picture description tasks. In this paper, we develop DEPID, a novel dependency-based method for computing PID, and its version DEPID-R that enables to exclude repeating ideas\u2014a feature characteristic to AD speech. We conduct the first comparison of automatically extracted PID and SID in the diagnostic classification task on two different AD datasets covering both closed-topic and free-recall domains. While SID performs better on the normative dataset, adding PID leads to a small but significant improvement (+1.7 Fscore). On the free-topic dataset, PID performs better than SID as expected (77.6 vs 72.3 in F-score) but adding the features derived from the word embedding clustering underlying the automatic SID increases the results considerably, leading to an Fscore of 84.8."}, {"heading": "1 Introduction", "text": "Idea density (ID) measures the rate of propositions or ideas expressed per word in a text and it is\nconnected to some very interesting results from neuroscience related to Alzheimer\u2019s disease (AD). In particular, two longitudinal studies\u2014the Nun Study (Snowdon et al., 1996) and the Precursors Study (Engelman et al., 2010)\u2014suggest that lower ID, as measured from the essays written in young age, is associated with the higher probability of developing AD in later life.\nTwo alternative definitions of idea density have been used in relation to AD. Propositional idea density (PID) counts the number of any ideas expressed in the text, setting no restriction to the topic (Turner and Greene, 1977; Chand et al., 2010). An example sentence with its ideas or propositions is given in Table 1. Based on each proposition a question can be formulated with a yes or no answer. Removing a proposition from a sentence changes the semantic meaning of that sentence. For instance, removing the proposition (GRAY, MARE) from the example makes the overall meaning of the sentence more general. The PID is then computed by normalising the proposition count with the token count and thus the PID of the\nexample given in Table 1 is 6/9 \u2248 0.667.\nThe existing tool for automatic PID computation, CPIDR (Brown et al., 2008), is based on counting POS tags. However, we noticed that the propositional structure of a sentence is very similar to its dependency structure, see the first column in Table 1. This motivated us to come up with DEPID, a method for computing PID from dependency structures. In addition, DEPID more easily enables to consider idea repetition which has been shown to be a characteristic feature in Alzheimer\u2019s speech (Bayles et al., 1985; Tomoeda et al., 1996; Bayles et al., 2004), resulting in a modified PID version DEPID-R which excludes the repeated ideas.\nSemantic idea density (SID) (Ahmed et al., 2013a,b) relies on a set of pre-defined information content units (ICU). ICU is an object or action that can be seen on the picture or is told in the story and is expected to be mentioned in the narrative. For instance, assuming that the words in capital letters and square brackets in the example sentence shown in Table 1 belong to the set of pre-defined ICUs the SID is computed by normalising the ICU count with the token count: 2/9 \u2248 0.222. Recently, Yancheva and Rudzicz (2016), proposed a method for computing SID based on word embedding clusters. We use their method for computing SID as it does not rely on any pre-defined ICU inventory and thus is applicable also on free-topic datasets.\nPID and SID are complementary definitions of idea density with SID being naturally applicable in standardised picture description or story re-telling tasks while PID is more suitable on datasets of spontaneous speech on free topics.\nIn this paper we study the predictiveness of both PID and SID features in the diagnostic classification task for predicting AD. To that end, we conduct experiments on two very different datasets: DementiaBank, which consists of transcriptions of a normative picture description task, and AMI, which contains autobiographical memory interviews describing life events freely chosen by the subjects.\nWe show that on the DementiaBank data the POS-based PID scores are actually higher for AD patients than they are for normal controls, contrary to the expectations from the AD literature (Engelman et al., 2010; Chand et al., 2012; Kemper et al., 2001). By studying the character-\nistics of the DementiaBank we are able to adapt DEPID such that its PID values become significantly different between the patient and control groups in the expected direction. Thus, we believe that our proposed DEPID is a better tool for measuring PID as described by neurolinguists on spontaneous speech transcripts than the POSbased CPIDR.\nSecondly, we show that the SID performs better than PID on the constrained-domain DementiaBank corpus but adding the PID feature leads to a small but significant improvement.\nThirdly, we show that on the free-topic AMI dataset the PID performs better than the automatically extracted SID, but adding the features derived from the word embedding clustering underlying the SID, modeling the broad discussion topics, increases the results considerably\u2014an effect which is less visible on the constrained topic DementiaBank.\nThe contributions of this paper are the follow-\ning:\n1. Development of DEPID, the new\ndependency-based method for automatically computing PID and its version DEPID-R which enables to detect and exclude idea repetitions; 2. Analysis of the characteristic features of the\nDementiaBank dataset and the proposal for modifying DEPID to make it applicable to this and other similar closed-topic datasets. 3. Results of extensive diagnostic classification\nexperiments using PID, SID and several related baselines on two very different AD datasets."}, {"heading": "2 Idea density and Alzheimer\u2019s disease", "text": "ID was first associated with AD in the Nun Study (Snowdon et al., 1996), based on a cohort of elderly nuns participating in a longitudinal study of aging and Alzheimer\u2019s disease. In this work, they studied the autobiographical essays the nuns had written decades ago in their youth. The nuns were divided into three groups based on their ID score computed from the essays, so that each group covered 33.3% percentile of the whole range of ID values. The lowest group was labeled as having low ID and the medium and highest group as having high ID. These groups were established from a sample of 93 nuns. The association between AD and ID was studied on a sample of 25 nuns who\nhad died by the time of the study, for 10 of whom the cause of death had been marked as AD. The study found that most subjects with AD belonged to the low ID group while most of those, who did not develop AD, belonged to the group with high ID, thus suggesting that the low ID in youth might be associated with the development of the AD in later life.\nSimilar work was conducted on a group of medical students for whom essays from the time of their admission to the medical school several decades earlier were available (Engelman et al., 2010). The results of this study also showed a significantly lower ID on the AD group as compared to the healthy controls, suggesting that ID could be an important discriminative feature for predicting AD."}, {"heading": "2.1 Propositional and semantic idea density", "text": "Two different versions of ID have been developed over time, both derived from the propositional base structure developed by Kintsch and Keenan (1973) to describe the semantic complexity of texts in reading experiments.\nPropositional idea density (PID), which was used both in the Nun Study and the medical students study, is based on counting the semantic propositions as defined by Turner and Greene (1977) and later refined by Chand et al. (2012). Three main types of propositions where described: 1) predications that are based on verb frames; 2) modifications that include all sorts of modifiers, e.g. adjectival, adverbial, quantifying, qualifying etc.; and 3) connections that join simple propositions into complex ones. For each proposition, a question can be formed with a yes or no answer. For instance, based on the example in Table 1, we could form the following questions:\n1. Is the mare old? 2. Is the mare gray? 3. Has the mare a nose? 4. Is the nose large? 5. Is the nose very large?\nEach of those questions inquires about a different aspect of the whole sentence and is a basis of an idea or proposition.\nSemantic idea density (SID) has retained its relation to the propositional base of some text. It relies on a set of information content units (ICUs) that have been pre-defined for a closed-topic task, such as picture description or story re-telling. For instance, different inventories of 7-25 ICUs have\nbeen described for the Cookie Theft picture task (Goodglass and Kaplan, 1983), listing objects visible on the picture such as \u201cboy\u201d, \u201cgirl\u201d, \u201ccookie\u201d or \u201ckitchen\u201d or actions performed on the scene such as \u201cboy stealing cookies\u201d or \u201cwoman drying dishes\u201d. SID is computed by counting the number of ICUs mentioned in the text and then normalising by the total number of word tokens."}, {"heading": "2.2 Related work on AD using ID", "text": "PID, computed with CPIDR, has been used in few previous works for predicting AD. Jarrold et al. (2010) used PID as one among many features and reported it as significant. They obtained a classification accuracy of 73% on their dataset, which contained short structured clinical interviews, with their best model and feature set that also included the PID feature. PID was also used by Roark et al. (2011) to detect mild cognitive impairment on a story re-telling dataset. However, they found no significant difference between groups in terms of PID and thus, their feature selection procedure most probably filtered it out.\nIn terms of SID, most previous work has relied on manually defined ICUs (Ahmed et al., 2013b,a). Fraser et al. (2015) extracted binary and frequency-based ICU features. They searched for words related to the ICU objects and looked at the nsubj-relations in the dependency parses to detect the ICUs referring to actions. The binary feature was set when any word related to an ICU was mentioned in the text, while frequency-based features counted the total number of times any word referring to an ICU was mentioned.\nRecently, Yancheva and Rudzicz (2016) proposed a method for automatically extracting ICUs and computing SID without relying on a manually defined ICU inventory. This work will be reviewed in more detail in section 4. They found that the automatically extracted ICUs and SID performed as well in a diagnostic AD classification task as the human-defined ICUs."}, {"heading": "3 Computation of PID", "text": "Automating the computation of PID is difficult because it is essentially a semantic measure. The instructions given by Turner and Greene (1977) for counting the propositions assume the comprehension of the semantic meaning of the text, while the raw text lacks the necessary semantic annotations. However, it has been noticed that the propositions\naexcept a, an and the bexcept it and this\nroughly correspond to certain POS tags. In particular, Snowdon et al. (1996) mention that elementary propositions are expressed using verbs, adjectives, adverbs and prepositions. This observation is the basis of the CPIDR program (Brown et al., 2008), a tool for automatically computing PID scores from text. CPIDR first processes the text with a POS-tagger, then counts all verbs, adjectives, adverbs, prepositions and coordinating conjunctions as propositions, and then applies a set of 37 rules to adjust the final proposition count."}, {"heading": "3.1 DEPID\u2014dependency-based PID", "text": "We propose that the dependency structure is better suited for PID computation than the POS tag counting approach adopted by the existing CPIDR program (Brown et al., 2008) because the dependency structure resembles more closely the semantic propositional structure, see Table 1. We treat each dependency type as a separate feature and manually set the feature weights to either one or zero depending on whether this dependency relation encodes a proposition or not. We make these decisions based on the dependency type descriptions in the Stanford dependency manual (de Marneffe and Manning, 2008). The dependency types with non-zero weights are listed in Table 2. The PID is then computed by summing the\ncounts of those dependency relations and normalising by the number of word tokens. We call our dependency-based PID computation method DEPID.\nWe computed the Spearman correlations be-\ntween CPIDR, DEPID and manual proposition counts on the 69 example sentences given in chapter 2 in (Turner and Greene, 1977)1 and the 177 example sentences given in (Chand et al., 2010), making up the total of 276 sentences. These correlations are given in Table 3. We observe that by just counting the dependency relations given in Table 2, we obtain proposition counts that correlate better with the manual counts than the POS-based CPIDR counts."}, {"heading": "3.2 DEPID-R", "text": "It is known that the Alzheimer\u2019s language is generally fluent and grammatical but in order to maintain the fluency the deficiencies in semantic or episodic memory are compensated with empty speech (Nicholas et al., 1985), such as repetitions, both on the word level but also on the idea, sentence or narrative level. DEPID easily enables to track repeated ideas in the narrative. We consider a proposition as repetition of a previous idea when the deprel(DEPENDENT LEMMA, HEAD LEMMA) tuples of the two propositions match. For instance, a sentence \u201cI had a happy life.\u201d contains three propositions: nsubj(I, HAVE), dobj(LIFE, HAVE) and amod(HAPPY, LIFE). Another sentence \u201cI\u2019ve had a very happy life.\u201d later in the same narrative only adds a single proposition to the total count\u2014 advmod(VERY, HAPPY)\u2014as this is the only new piece of information that was added.\nWe modify DEPID to exclude the repetitive ideas of a narrative by only counting the proposition types expressed with the lexicalised de-\n1Similar to Brown et al. (2008), we exclude the example 17, but for examples 18, 54, 55, 56, we include all paraphrases.\nprel(DEPENDENT LEMMA, HEAD LEMMA) dependency arcs. We call this modified version of dependency-based PID computation method DEPID-R. The relation between DEPID-R and DEPID is that DEPID counts the tokens of the same propositions."}, {"heading": "4 Computation of SID", "text": "Recently, Yancheva and Rudzicz (2016) proposed a method for automatically computing SID without the use of manually defined ICUs. Their method relies on clustering word embeddings of the nouns and verbs found in the transcriptions, assuming that the embeddings of the words related to the same semantic unit are clustered together.\nThey first perform K-means clustering on the word embeddings. Then, for each cluster they compute the mean distance \u00b5cl and its standard deviation \u03c3cl. The mean distance is the average Euclidean distance of all vectors assigned to a cluster from the centroid of that cluster. Finally, for each word they compute the scaled distance as a z-score of the Euclidean distance dE between the word embedding and its closest cluster centroid:\ndscaled = dE \u2212 \u00b5cl\n\u03c3cl\nThe words with dscaled < 3 are counted as automatic ICUs. SID is then computed by dividing the number of ICUs with the total number of word tokens in the transcription.\nIn addition to SID, Yancheva and Rudzicz (2016) experiment with distance-based features also derived from the same clustering. The distance feature for each cluster is computed as the average of the scaled distances of the words (nouns or verbs) in the transcript assigned to that cluster. These cluster features are not directly related to the concept of SID but they could be viewed as an automatic approximation of features derived from the human annotated ICUs."}, {"heading": "5 Experiments", "text": ""}, {"heading": "5.1 Data", "text": "We conduct experiments on two very different AD datasets. The first dataset is derived from the DementiaBank (Becker et al., 1994), which is part of a publicly available Talkbank corpus.2 It contains descriptions of the Cookie Theft picture\n2 https://talkbank.org/DementiaBank/\n(Goodglass and Kaplan, 1983) produced by subjects diagnosed with dementia as well as of healthy control cases. The data is manually transcribed and annotated in the CHAT format (MacWhinney, 2000), containing a range of annotations denoting various speech events. This is the same dataset used by Yancheva and Rudzicz (2016) and similar to them, we use the interviews of all control subjects and subjects whose diagnose is either AD or probable AD.\nThe second dataset, collected at NeuRA3, contains autobiographical memory interviews (AMI) of both AD patients and healthy control subjects. Each interview consists of four stories, each story describing events from a particular period of the subject\u2019s life: teenage years, early adulthood, middle adulthood and last year. Each story has three logical parts: free recall, general probe and specific probe. In the free recall part the subject is asked to talk freely about events he remembers from the given life period. In the general recall part the interviewer helps to narrow down to a particular specific event. In the specific probe part the interviewer asks a number of predefined questions about this specific event. We use all four stories of an interview as a single sample but extract only the free recall part of each story as this is the most spontaneous part of the interview.\nWe preprocess both data sets similarly, following the procedure described in (Fraser et al., 2015) as closely as possible. We first extract only the patient\u2019s dialogue turns. Then we remove any tokens that are not words (e.g. laughs). In DementiaBank corpus, such tokens can be detected by various CHAT annotations. We also remove filled pauses such as um, uh, er, ah. The statistics of\n3Neuroscience Research Australia\nboth datasets are given in Table 4."}, {"heading": "5.2 Analysis of the idea density", "text": "First, we perform a statistical analysis of the different ID measures in Table 5 on both datasets using the indepedent samples Wilcoxon rank-sum test to test the difference between group means.\nThe DEPID computed PID values are systematically lower than the CPIDR values on both datasets, suggesting that either CPIDR overestimates or the DEPID underestimates the number of propositions. In order to check that we manually annotated the propositions of 20 interviews from DementiaBank according to the guidelines given by Chand et al. (2012). We found that both CPIDR and DEPID overestimate the PID values although CPIDR does it to much greater extent. CPIDR both overestimates the number of propositions and underestimates the number of tokens in certain cases leading to higher PID scores. For example, CPIDR does not count contracted forms, such as \u201c\u2019s\u201d in \u201cit\u2019s\u201d or \u201cn\u2019t\u201d in \u201cdon\u2019t\u201d as distinct tokens. Because there are many such forms in DementiaBank transcriptions, this behaviour considerably lowers CPIDR token counts. Also, CPIDR counts each auxiliary verb in present participle constructions as a separate proposition although these auxiliaries only mark syntax, thus leading to an artificially high proposition count. For instance, the clauses \u201cshe is reaching\u201d and\n\u201che is taking\u201d both contain two propositions ac-\ncording to CPIDR, whereas they both really contain only one semantic idea.\nBoth CPIDR and DEPID PID values differ significantly between AD and control groups on DementiaBank but the mean values are opposite to what was expected\u2014AD patients have significantly higher PID than controls. When the repeated ideas are not counted (DEPID-R), the difference between groups becomes non-significant. However, we were curious about why the association between the lower PID values and the AD diagnosis cannot be observed on DementiaBank. Thus, we investigated this issue and found that the DementiaBank interviews have certain additional characteristics that contribute to the automatic proposition count being too high.\nConjunctive propositions First, we noticed that most and-conjunctions are used as lexical fillers in DementiaBank, whereas both CPIDR and DEPID count all conjunctions as propositions. In order to address this problem we excluded the cc dependency type from the set of propositions.\nSentences with pronominal subjects Secondly, we noticed that the sentences with subject either I or you most probably do not say anything about the picture but rather belong to the meta conversation. Two examples of such sentences are for instance \u201cwhat else can I tell you about the picture?\u201d or \u201cI\u2019d say that\u2019s about all.\u201d. To solve this problem we did not count propositions from sentences, where the subject was either I or you.\nVague sentences Finally, we observed that the AD patients seem to utter more vague sentences that do not contain any concrete ideas, such as for instance \u201cthe upper one is there\u201d or \u201cthey\u2019re doing more things on the outside.\u201d. Both CPIDR and DEPID extract propositions from syntactic structures and thus they count pseudo-ideas from those sentences as well. To detect such vague sentences we evaluated the specificity of all sentences using SpeciTeller (Li and Nenkova, 2015). SpeciTeller predicts a specificity score between 0 and 1 for each sentence using features extracted from the sentence surface-level, specific dictionaries and distributional word embeddings. We did not count propositions from sentences whose specificity score was lower than 0.01.\nAfter incorporating all those three measures to DEPID we finally obtain PID values on Demen-\ntiaBank that are significantly different for patients and controls in the expected direction\u2014the AD patients have significantly lower PID values than control subjects. Note that those measures only affect the proposition count and not the number of tokens. Also note that although these measures were motivated by the observations made on one particular (DementiaBank) dataset, they can be expected to be applicable to other similar closedtopic datasets, containing picture descriptions or story re-tellings.4\nOn AMI data, the difference between group\nmeans is non-significant for both CPIDR and DEPID values. However, when the repeated ideas are excluded (DEPID-R), the mean PID for AD patients is significantly lower than for controls, as expected. It should be noted that the first two problems observed on DementiaBank\u2014conjunctions and pronominal subjects\u2014are not actual on the free-recall AMI data. In autobiographical memory interviews many sentences are expected to have I as subject. Also, the and-conjunctions are more likely to convey real ideas there rather than carry the role of lexical fillers. However, AD patients can utter more sentences with very vague meaning in AMI data as well and thus, in the last row of the Table 5 we show the DEPID PID values with vague sentences excluded for AMI dataset as well. We see that the PID values decrease for both patients and controls and the difference between groups remains statistically significant.\nSID values differ significantly between the AD and control groups on both datasets with AD patients having significantly lower SID values as expected. The clustering underlying the automatically computed SID is trained on the whole dataset for both DementiaBank and AMI data."}, {"heading": "5.3 Classification setup", "text": "We test both PID and SID in the diagnostic binary classification task on both DementiaBank and AMI datasets. When computing PID, the repeated ideas are excluded (DEPID-R). In addition, for DementiaBank, we also use the additional measures described in Section 5.2 (DEPID-R-ADD) as, according to Table 5, just DEPID-R cannot be expected to be predictive on that type of dataset. We compute the SID as described in Section 4. In following (Yancheva and Rudzicz, 2016), we clus-\n4Unfortunately, aside from DementiaBank there are no other publicly available AD datasets and thus we could not test whether our expectations hold true."}, {"heading": "DB CPIDR 59.8 (0.7) 59.1 (0.5) 58.8 (0.5)", "text": ""}, {"heading": "DB PID 61.1 (0.7) 60.3 (0.6) 60.0 (0.5)", "text": "ter the 50-dimensional Glove embeddings5 of all nouns and verbs found in the transcripts with kmeans. Similar to them, we set the number of clusters to 10 on both datasets.\nFor single feature models (SID or PID) we use a simple logistic regression classifier. For models with multiple features we use the elastic net logistic regression with an elastic net hyperparameter \u03b1 = 0.5. We train and test with 10-fold cross-validation on subjects and repeat each experiment 100 times. We report the mean and standard deviation of the 100 macro-averaged crossvalidated runs. For each experiment we report class-weighted precision, recall and F-score.6"}, {"heading": "5.4 Classification results", "text": "The classification results using various ID measures are shown in Table 6. On both datasets, PID and SID are better from the CPIDR baseline although the difference is considerably larger on the free-recall AMI dataset. On DementiaBank, SID performs better than PID and combining SID and PID also gives a small consistent cumulative effect, improving the F-score by 1.7%. On AMI data, the SID performs surprisingly well, considering that the automatic ICUs were extracted from only 10 clusters and the number of clusters was not tuned to that dataset at all. However, PID performs ca 5% better than SID in terms of all measures. Combining PID and SID gives some improvements in precision at the cost the decrease in recall and gives no cumulative gains in F-score. These results are fully in line with our expectations that the syntax-based DEPID performs better on the free-topic dataset, while the SID is better on closed-domain dataset.\n5 http://nlp.stanford.edu/projects/glove/\n6Classification accuracy is omitted because it is equivalent to the class-weighted recall.\nFor better comparison with Yancheva and Rudzicz (2016) we also experimented with the distance-based cluster features, which are derived from the clusters underlying the automatic SID (see section 4). We also show additional semantic baselines using LIWC features (Tausczik and Pennebaker, 2010) and bag-of-word (BOW) features extracting the counts of nouns and verbs normalised by the number of tokens. These results are shown in Table 7. On DementiaBank dataset, cluster features alone do not perform too well and using cluster features together with PID and SID gives only minor improvements. On the other hand, both the LIWC and BOW baselines perform very well on DementiaBank with BOW features giving the total highest precision of 80.6%, recall of 79.1% and F-score of 79.3%. In fact, these results are very close to the state-of-the-art on this dataset: a recall of 81.9% (Fraser et al., 2015) and an F-score\nof 80.0% (Yancheva and Rudzicz, 2016). Note however that the BOW features are conceptually much simpler than the acoustic and lexicosyntactic features extracted by Yancheva and Rudzicz (2016) and Fraser et al. (2015).\nOn the free-recall AMI data, the cluster features perform surprisingly well while the results of the LIWC and BOW baselines are lower. Adding cluster features to ID behaves inconsistently\u2014in case of SID the F-score improves while adding cluster features to PID lowers the F-score. It is also worth noticing that results on AMI data including cluster features vary quite a bit, in some cases having standard deviation even as high as 7.7%.\nFinally, we experimented with a scenario where the word embedding clusters are pre-trained on the whole dataset, in which case the clustering and thus also the SID feature reflect the structure of both training and test folds. This scenario assumes re-training the clustering and the classification model for each new test item/set. Although the classification model is then informed by the test set, we do not see it as test set leakage as the clustering is unsupervised. These results, given in Table 8, show that all results on both datasets improve, whereas the improvements are considerably larger on AMI dataset, which is expected because the model trained on the free-topic AMI data is likely to gain more on knowing the topics discussed in the test item/set. This scenario gives the highest F-score of 84.8% on this dataset when adding cluster features to SID.\nNote, that the cluster features F-score trained on the full dataset is slightly lower than the 68% reported by Yancheva and Rudzicz (2016). This difference is probably due to the differences in hyperparameters and experimental setup: we use an elastic-net regularised logistic regression classifier while they used a random forest, we perform 10- fold cross-validation while they divided the DementiaBank into 60-20-20 train-dev-test partitions. However, the classification performance of cluster features together with SID are in the same range as their reported 74%."}, {"heading": "6 Discussion", "text": "This is the first work we are aware of that compares the same methods for predicting AD on two different datasets. Moreover, most previous work has been conducted either on constrained-topic datasets, contain-\ning picture descriptions (Orimaye et al., 2014; Fraser et al., 2015; Yancheva and Rudzicz, 2016; Rentoumi et al., 2014), or semi-constrained structured interviews about some particular topic (Thomas et al., 2005; Jarrold et al., 2010, 2014), while our AMI dataset contains free recall samples and thus is probably more spontaneous than the previously used datasets.\nWe expected PID to perform well on the freerecall AMI dataset, which proved to be the case. However, we were surprised that the small number of automatically extracted clusters perform so well on that dataset too. This raises the natural question what topics those clusters represent. To shed light on this question, we studied the clustering trained on the whole AMI dataset. There were three clusters for which values differed significantly7 between AD and control subjects: C0 (p < 0.001), C6 (p < 0.001) and C9 (p = 0.0044). C0, which could be denoted as a cluster describing experiences, contained a diverse mix of words, which close to the cluster center denoted specific aspects of something or connoted emotions such as \u201crudeness\u201d, \u201cflirting\u201d and \u201cusher\u201d, while the farther words contained a range of aspects relevant to people\u2019s lives such as \u201cbilliards\u201d, \u201cbronchitis\u201d and \u201cdepression\u201d. C6 contained close to the cluster center simple work-related words, e.g. \u201cworking\u201d, \u201cemployed\u201d and \u201cstudent\u201d, while farther from the center there were more words referring to family members and even further away became the words referring to specific professions such as\n\u201cpsychologists\u201d, \u201cbarrister\u201d and \u201cchemist\u201d. The\nvalues of C6 feature for AD patients were significantly lower than for controls. Finally, the cluster C9 contained simple business-related words close to the cluster center, such as \u201cmanage\u201d, \u201cproduct\u201d and \u201caccount\u201d, while the words got more specific farther away from the centroid, e.g. \u201clicensed\u201d,\n\u201creorganisation\u201d and \u201ctextile\u201d.\nAlso, we checked how many words were considered as ICUs (words with dscaled < 3.0 to their closest cluster center) on AMI data and found that most words were counted. This suggests that the automatically computed SID is in fact very close to the simple proportion of nouns and verbs in the transcripts. In order to check this, we extracted the normalised counts of nouns and verbs from all transcripts in both datasets and used it to train single feature logistic regression classi-\n7We used the Wilcoxon signed rank test.\nfiers. We obtained the precision 67.6, recall 66.8 and F-score 66.6 on DementiaBank and precision 77.1, recall 76.0 and F-score 74.3 on AMI dataset. Also, we found that on DementiaBank the simple bag-of-words baseline obtained the results very close to the current state-of-the-art that uses much more complex feature sets, including both acoustic and lexicosyntactic features (Fraser et al., 2015). These two observations suggest that there is still room for studying simple feature sets for predicting AD."}, {"heading": "7 Conclusion", "text": "We experimented with two different definitions of idea density\u2014propositional idea density and semantic idea density\u2014in the classification task for predicting Alzheimer\u2019s disease. In the AD and psycholinguistic literature, PID has been automatically calculated using CPIDR (Engelman et al., 2010; Ferguson et al., 2014; Bryant et al., 2013; Moe et al., 2016). We show that CPIDR has a number of flaws when applied to AD speech, and we propose a new PID computation method DEPID which is more highly correlated with manual estimates of PID. We recommend that AD researchers use our automatic measure, DEPID-R, which also excludes repeating ideas from the total idea count, in place of CPIDR.\nThis is the first comparison between PID and SID and also the first computational study that evaluates the predictive models for Alzheimer\u2019s disease on two very different datasets. While on the closed-topic picture description dataset SID performs better, including PID also adds a small improvement to the classification results. On the open-domain dataset we found that the PID was more predictive than SID as expected. However, the small number of automatically extracted cluster features underlying the SID, modeling the broad discussion topics, led to even better results.\nIn future we plan to study the usefulness and applicability of both PID and SID also in other clinical tasks, such as in clinical diagnostic tasks for depression or schizophrenia. Another possible avenue for future work would include combining dependency-base PID and embedding-based SID into a unified idea density measure that would take into account both the propositional structure as well as the semantic content of words."}, {"heading": "Acknowledgements", "text": "This research was supported by a Google award through the Natural Language Understanding Focused Program, and under the Australian Research Council\u2019s Discovery Projects funding scheme (project number DP160102156), and in part by funding to ForeFront, a collaborative research group dedicated to the study of frontotemporal dementia and motor neuron disease, from the National Health and Medical Research Council (NHMRC) (APP1037746), and the Australian Research Council (ARC) Centre of Excellence in Cognition and its Disorders Memory Program (CE11000102). OP is supported by an NHMRC Senior Research Fellowship (APP1103258)."}], "references": [{"title": "Semantic processing in connected speech at a uniformly early stage of autopsy-confirmed Alzheimer\u2019s disease", "author": ["Samrah Ahmed", "Celeste A. de Jager", "Anne-Marie Haigh", "Peter Garrard."], "venue": "Neuropsychology 27(1):79\u201385.", "citeRegEx": "Ahmed et al\\.,? 2013a", "shortCiteRegEx": "Ahmed et al\\.", "year": 2013}, {"title": "Connected speech as a marker of disease progression in autopsyproven Alzheimer\u2019s disease", "author": ["Samrah Ahmed", "Anne-Marie F. Haigh", "Celeste A. de Jager", "Peter Garrard."], "venue": "Brain 136(12):3727\u2013 3737.", "citeRegEx": "Ahmed et al\\.,? 2013b", "shortCiteRegEx": "Ahmed et al\\.", "year": 2013}, {"title": "Verbal perseveration of dementia patients", "author": ["Kathryn A. Bayles", "Cheryl K. Tomoeda", "Alfred W. Kaszniak", "Lawrence Z. Stern", "Karen K. Eagans."], "venue": "Brain and Language 25(1):102\u2013116.", "citeRegEx": "Bayles et al\\.,? 1985", "shortCiteRegEx": "Bayles et al\\.", "year": 1985}, {"title": "Verbal perseveration in individuals with Alzheimer\u2019s disease", "author": ["Kathryn A. Bayles", "Cheryl K. Tomoeda", "Patrick E. McKnight", "Nancy Helm-Estabrooks", "Josh N. Hawley."], "venue": "Seminars in Speech and Language 25(4):335\u2013347.", "citeRegEx": "Bayles et al\\.,? 2004", "shortCiteRegEx": "Bayles et al\\.", "year": 2004}, {"title": "The natural history of Alzheimer\u2019s disease", "author": ["James T. Becker", "Francois Boller", "Oscar L. Lopez", "Judith Saxton", "Karen L. McGonigle."], "venue": "Description of study cohort and accuracy of diagnosis. Archives of Neurology 51(6):585\u2013594.", "citeRegEx": "Becker et al\\.,? 1994", "shortCiteRegEx": "Becker et al\\.", "year": 1994}, {"title": "Automatic measurement of propositional idea density from part-of-speech tagging", "author": ["Cati Brown", "Tony Snodgrass", "Susan J. Kemper", "Ruth Herman", "Michael A. Covington."], "venue": "Behavior research methods 40(2):540\u2013545.", "citeRegEx": "Brown et al\\.,? 2008", "shortCiteRegEx": "Brown et al\\.", "year": 2008}, {"title": "Propositional Idea Density in aphasic discourse", "author": ["Lucy Bryant", "Elizabeth Spencer", "Alison Ferguson", "Hugh Craig", "Kim Colyvas", "Linda Worrall."], "venue": "Aphasiology 27(8):992\u20131009.", "citeRegEx": "Bryant et al\\.,? 2013", "shortCiteRegEx": "Bryant et al\\.", "year": 2013}, {"title": "A rubric for extracting idea density from oral language samples", "author": ["Vineeta Chand", "Kathleen Baynes", "Lisa M. Bonnici", "Sarah Tomaszewski Farias."], "venue": "Current Protocols in Neuroscience 1.", "citeRegEx": "Chand et al\\.,? 2012", "shortCiteRegEx": "Chand et al\\.", "year": 2012}, {"title": "Stanford Dependencies manual", "author": ["Marie-Catherine de Marneffe", "Christopher D. Manning."], "venue": "Technical report, Stanford University.", "citeRegEx": "Marneffe and Manning.,? 2008", "shortCiteRegEx": "Marneffe and Manning.", "year": 2008}, {"title": "Propositional density and cognitive function in later life: findings from the Precursors Study", "author": ["Michal Engelman", "Emily M. Agree", "Lucy A. Meoni", "Michael J. Klag."], "venue": "Journals of Gerontology - Series B Psychological Sciences and Social Sciences", "citeRegEx": "Engelman et al\\.,? 2010", "shortCiteRegEx": "Engelman et al\\.", "year": 2010}, {"title": "Propositional idea density in women\u2019s written language over the lifespan: computerized analysis", "author": ["Alison Ferguson", "Elizabeth Spencer", "Hugh Craig", "Kim Colyvas."], "venue": "Cortex 55:107\u2013121.", "citeRegEx": "Ferguson et al\\.,? 2014", "shortCiteRegEx": "Ferguson et al\\.", "year": 2014}, {"title": "Linguistic Features Identify Alzheimer\u2019s Disease in Narrative Speech", "author": ["Kathleen C. Fraser", "Jed A. Meltzer", "Frank Rudzicz."], "venue": "Journal of Alzheimer\u2019s disease 49(2):407\u2013422.", "citeRegEx": "Fraser et al\\.,? 2015", "shortCiteRegEx": "Fraser et al\\.", "year": 2015}, {"title": "The Assessment of Aphasia and Related Disorders", "author": ["Harold Goodglass", "Edith Kaplan."], "venue": "Lea & Febiger.", "citeRegEx": "Goodglass and Kaplan.,? 1983", "shortCiteRegEx": "Goodglass and Kaplan.", "year": 1983}, {"title": "Aided diagnosis of dementia type through computer-based analysis of spontaneous speech", "author": ["William Jarrold", "Bart Peintner", "David Wilkins", "Dimitra Vergryi", "Colleen Richey", "Maria Luisa GornoTempini", "Jennifer Ogar."], "venue": "Proceedings of the Work-", "citeRegEx": "Jarrold et al\\.,? 2014", "shortCiteRegEx": "Jarrold et al\\.", "year": 2014}, {"title": "Language analytics for assessing brain health: Cognitive impairment, depression and pre-symptomatic alzheimer\u2019s disease", "author": ["William L. Jarrold", "Bart Peintner", "Eric Yeh", "Ruth Krasnow", "Harold S. Javitz", "Gary E. Swan."], "venue": "Proceedings of the 2010 In-", "citeRegEx": "Jarrold et al\\.,? 2010", "shortCiteRegEx": "Jarrold et al\\.", "year": 2010}, {"title": "Longitudinal change in language production: effects of aging and dementia on grammatical complexity and propositional content", "author": ["Susan Kemper", "Janet Marquis", "Marilyn Thompson."], "venue": "Psychology and Aging 16(4):600\u2013614.", "citeRegEx": "Kemper et al\\.,? 2001", "shortCiteRegEx": "Kemper et al\\.", "year": 2001}, {"title": "Reading rate and retention as a function of the number of propositions in the base structure of sentences", "author": ["Walter Kintsch", "Janice Keenan."], "venue": "Cognitive Psychology 5(3):257\u2013274.", "citeRegEx": "Kintsch and Keenan.,? 1973", "shortCiteRegEx": "Kintsch and Keenan.", "year": 1973}, {"title": "Fast and accurate prediction of sentence specificity", "author": ["Junyi Jessy Li", "Ani Nenkova."], "venue": "Proceedings of the Twenty-Ninth AAAI Conference on Artificial Intelligence. pages 2281\u20132287.", "citeRegEx": "Li and Nenkova.,? 2015", "shortCiteRegEx": "Li and Nenkova.", "year": 2015}, {"title": "The CHILDES Project: Tools for analyzing talk, 3rd edition", "author": ["Brian MacWhinney"], "venue": null, "citeRegEx": "MacWhinney.,? \\Q2000\\E", "shortCiteRegEx": "MacWhinney.", "year": 2000}, {"title": "Idea density in the lifestories of people with schizophrenia: Associations with narrative qualities and psychiatric symptoms", "author": ["Aubrey M. Moe", "Nicholas J.K. Breitborde", "Mohammed K. Shakeel", "Colin J. Gallagher", "Nancy M. Docherty"], "venue": null, "citeRegEx": "Moe et al\\.,? \\Q2016\\E", "shortCiteRegEx": "Moe et al\\.", "year": 2016}, {"title": "Empty Speech in Alzheimer\u2019s Disease and Fluent Aphasia", "author": ["Marjorie Nicholas", "Loraine K. Obler", "Martin L. Albert", "Nancy Helm-Estabrooks."], "venue": "Journal of Speech and Hearing Research 28(3):405\u2013410.", "citeRegEx": "Nicholas et al\\.,? 1985", "shortCiteRegEx": "Nicholas et al\\.", "year": 1985}, {"title": "Learning Predictive Linguistic Features for Alzheimer\u2019s Disease and related Dementias using Verbal Utterances", "author": ["Sylvester O. Orimaye", "Jojo Sze-Meng Wong", "Karen J. Golden."], "venue": "Proceedings of the Workshop on Computational Linguistics and", "citeRegEx": "Orimaye et al\\.,? 2014", "shortCiteRegEx": "Orimaye et al\\.", "year": 2014}, {"title": "Features and machine learning classification of connected speech samples from patients with autopsy proven Alzheimer\u2019s disease", "author": ["Vassiliki Rentoumi", "Ladan Raoufian", "Samrah Ahmed", "Celeste A. de Jager", "Peter Garrard"], "venue": null, "citeRegEx": "Rentoumi et al\\.,? \\Q2014\\E", "shortCiteRegEx": "Rentoumi et al\\.", "year": 2014}, {"title": "Spoken Language Derived Measures for Detecting Mild Cognitive Impairment", "author": ["Brian Roark", "Margaret Mitchell", "John-Paul Hosom", "Kristy Hollingshead", "Jeffrey Kaye."], "venue": "IEEE transactions on audio, speech, and language processing 19(7):2081\u20132090.", "citeRegEx": "Roark et al\\.,? 2011", "shortCiteRegEx": "Roark et al\\.", "year": 2011}, {"title": "Linguistic ability in early life and cognitive function and Alzheimer\u2019s disease in late life", "author": ["David A. Snowdon", "Susan J. Kemper", "James A. Mortimer", "Lydia H. Greiner", "David R. Wekstein", "William R. Markesbery."], "venue": "Findings from the Nun Study. JAMA", "citeRegEx": "Snowdon et al\\.,? 1996", "shortCiteRegEx": "Snowdon et al\\.", "year": 1996}, {"title": "The Psychological Meaning of Words: LIWC and Computerized Text Analysis Methods", "author": ["Yla R. Tausczik", "James W. Pennebaker."], "venue": "Journal of Language and Social Psychology 29(1):24\u201354.", "citeRegEx": "Tausczik and Pennebaker.,? 2010", "shortCiteRegEx": "Tausczik and Pennebaker.", "year": 2010}, {"title": "Automatic detection and rating of dementia of Alzheimer type through lexical analysis of spontaneous speech", "author": ["Calvin Thomas", "Vlado Keselj", "Nick Cercone", "Kenneth Rockwood", "Elissa Asp."], "venue": "IEEE International Conference Mechatronics and", "citeRegEx": "Thomas et al\\.,? 2005", "shortCiteRegEx": "Thomas et al\\.", "year": 2005}, {"title": "Cross-sectional analysis of Alzheimer disease effects on oral discourse in a picture description task", "author": ["Cheryl K. Tomoeda", "Kathryn A. Bayles", "Michael W. Trosset", "Tamiko Azuma", "Anna McGeagh."], "venue": "Alzheimer Disease and Associated Disorders", "citeRegEx": "Tomoeda et al\\.,? 1996", "shortCiteRegEx": "Tomoeda et al\\.", "year": 1996}, {"title": "The construction and use of a propositional text base", "author": ["Althea Turner", "Edith Greene."], "venue": "Technical report, University of Colorado.", "citeRegEx": "Turner and Greene.,? 1977", "shortCiteRegEx": "Turner and Greene.", "year": 1977}, {"title": "Vectorspace topic models for detecting Alzheimer\u2019s disease", "author": ["Maria Yancheva", "Frank Rudzicz."], "venue": "Proceedings of the 54th Annual Meeting of the Association for Computational Linguistics. pages 2337\u20132346.", "citeRegEx": "Yancheva and Rudzicz.,? 2016", "shortCiteRegEx": "Yancheva and Rudzicz.", "year": 2016}], "referenceMentions": [{"referenceID": 24, "context": "Lower ID is found to be associated with an increased risk of developing Alzheimer\u2019s disease (AD) (Snowdon et al., 1996; Engelman et al., 2010).", "startOffset": 97, "endOffset": 142}, {"referenceID": 9, "context": "Lower ID is found to be associated with an increased risk of developing Alzheimer\u2019s disease (AD) (Snowdon et al., 1996; Engelman et al., 2010).", "startOffset": 97, "endOffset": 142}, {"referenceID": 5, "context": "The example sentence is due to Brown et al. (2008). The predicative proposition (HAS, MARE, NOSE) is represented by two dependency arcs.", "startOffset": 31, "endOffset": 51}, {"referenceID": 24, "context": "In particular, two longitudinal studies\u2014the Nun Study (Snowdon et al., 1996) and the Precursors Study (Engelman et al.", "startOffset": 54, "endOffset": 76}, {"referenceID": 9, "context": ", 1996) and the Precursors Study (Engelman et al., 2010)\u2014suggest that lower ID, as measured from the essays written in young age, is associated with the higher probability of de-", "startOffset": 33, "endOffset": 56}, {"referenceID": 28, "context": "Propositional idea density (PID) counts the number of any ideas expressed in the text, setting no restriction to the topic (Turner and Greene, 1977; Chand et al., 2010).", "startOffset": 123, "endOffset": 168}, {"referenceID": 5, "context": "The existing tool for automatic PID computation, CPIDR (Brown et al., 2008), is based on counting POS tags.", "startOffset": 55, "endOffset": 75}, {"referenceID": 2, "context": "In addition, DEPID more easily enables to consider idea repetition which has been shown to be a characteristic feature in Alzheimer\u2019s speech (Bayles et al., 1985; Tomoeda et al., 1996; Bayles et al., 2004), resulting in a modified PID version DEPID-R which excludes the repeated ideas.", "startOffset": 141, "endOffset": 205}, {"referenceID": 27, "context": "In addition, DEPID more easily enables to consider idea repetition which has been shown to be a characteristic feature in Alzheimer\u2019s speech (Bayles et al., 1985; Tomoeda et al., 1996; Bayles et al., 2004), resulting in a modified PID version DEPID-R which excludes the repeated ideas.", "startOffset": 141, "endOffset": 205}, {"referenceID": 3, "context": "In addition, DEPID more easily enables to consider idea repetition which has been shown to be a characteristic feature in Alzheimer\u2019s speech (Bayles et al., 1985; Tomoeda et al., 1996; Bayles et al., 2004), resulting in a modified PID version DEPID-R which excludes the repeated ideas.", "startOffset": 141, "endOffset": 205}, {"referenceID": 0, "context": "Semantic idea density (SID) (Ahmed et al., 2013a,b) relies on a set of pre-defined information content units (ICU). ICU is an object or action that can be seen on the picture or is told in the story and is expected to be mentioned in the narrative. For instance, assuming that the words in capital letters and square brackets in the example sentence shown in Table 1 belong to the set of pre-defined ICUs the SID is computed by normalising the ICU count with the token count: 2/9 \u2248 0.222. Recently, Yancheva and Rudzicz (2016), proposed a method for computing SID based on word embedding clusters.", "startOffset": 29, "endOffset": 527}, {"referenceID": 9, "context": "AD patients than they are for normal controls, contrary to the expectations from the AD literature (Engelman et al., 2010; Chand et al., 2012; Kemper et al., 2001).", "startOffset": 99, "endOffset": 163}, {"referenceID": 7, "context": "AD patients than they are for normal controls, contrary to the expectations from the AD literature (Engelman et al., 2010; Chand et al., 2012; Kemper et al., 2001).", "startOffset": 99, "endOffset": 163}, {"referenceID": 15, "context": "AD patients than they are for normal controls, contrary to the expectations from the AD literature (Engelman et al., 2010; Chand et al., 2012; Kemper et al., 2001).", "startOffset": 99, "endOffset": 163}, {"referenceID": 24, "context": "ID was first associated with AD in the Nun Study (Snowdon et al., 1996), based on a cohort of elderly nuns participating in a longitudinal study of aging and Alzheimer\u2019s disease.", "startOffset": 49, "endOffset": 71}, {"referenceID": 9, "context": "Similar work was conducted on a group of medical students for whom essays from the time of their admission to the medical school several decades earlier were available (Engelman et al., 2010).", "startOffset": 168, "endOffset": 191}, {"referenceID": 15, "context": "Two different versions of ID have been developed over time, both derived from the propositional base structure developed by Kintsch and Keenan (1973) to describe the semantic complexity of texts in reading experiments.", "startOffset": 124, "endOffset": 150}, {"referenceID": 15, "context": "Two different versions of ID have been developed over time, both derived from the propositional base structure developed by Kintsch and Keenan (1973) to describe the semantic complexity of texts in reading experiments. Propositional idea density (PID), which was used both in the Nun Study and the medical students study, is based on counting the semantic propositions as defined by Turner and Greene (1977) and later refined by Chand et al.", "startOffset": 124, "endOffset": 408}, {"referenceID": 7, "context": "Propositional idea density (PID), which was used both in the Nun Study and the medical students study, is based on counting the semantic propositions as defined by Turner and Greene (1977) and later refined by Chand et al. (2012). Three main types of propositions where described: 1) predications that are based on verb frames; 2) modifications that include all sorts of modifiers, e.", "startOffset": 210, "endOffset": 230}, {"referenceID": 12, "context": "For instance, different inventories of 7-25 ICUs have been described for the Cookie Theft picture task (Goodglass and Kaplan, 1983), listing objects visible on the picture such as \u201cboy\u201d, \u201cgirl\u201d, \u201ccookie\u201d or \u201ckitchen\u201d or actions performed on the scene such as \u201cboy stealing cookies\u201d or \u201cwoman drying dishes\u201d.", "startOffset": 103, "endOffset": 131}, {"referenceID": 13, "context": "Jarrold et al. (2010) used PID as one among many features and reported it as significant.", "startOffset": 0, "endOffset": 22}, {"referenceID": 13, "context": "Jarrold et al. (2010) used PID as one among many features and reported it as significant. They obtained a classification accuracy of 73% on their dataset, which contained short structured clinical interviews, with their best model and feature set that also included the PID feature. PID was also used by Roark et al. (2011) to detect mild cognitive impairment on a story re-telling dataset.", "startOffset": 0, "endOffset": 324}, {"referenceID": 0, "context": "In terms of SID, most previous work has relied on manually defined ICUs (Ahmed et al., 2013b,a). Fraser et al. (2015) extracted binary and frequency-based ICU features.", "startOffset": 73, "endOffset": 118}, {"referenceID": 29, "context": "Recently, Yancheva and Rudzicz (2016) proposed a method for automatically extracting ICUs and computing SID without relying on a manually defined ICU inventory.", "startOffset": 10, "endOffset": 38}, {"referenceID": 28, "context": "The instructions given by Turner and Greene (1977) for counting the propositions assume the comprehension of the semantic meaning of the text, while the raw text lacks the necessary semantic annotations.", "startOffset": 26, "endOffset": 51}, {"referenceID": 5, "context": "This observation is the basis of the CPIDR program (Brown et al., 2008), a tool for automatically computing PID scores from text.", "startOffset": 51, "endOffset": 71}, {"referenceID": 23, "context": "In particular, Snowdon et al. (1996) mention that elementary propositions are expressed using verbs, adjectives, adverbs and prepositions.", "startOffset": 15, "endOffset": 37}, {"referenceID": 5, "context": "We propose that the dependency structure is better suited for PID computation than the POS tag counting approach adopted by the existing CPIDR program (Brown et al., 2008) because the dependency structure resembles more closely the semantic propositional structure, see Table 1.", "startOffset": 151, "endOffset": 171}, {"referenceID": 27, "context": "Table 3: Spearman correlations between CPIDR, DEPID and manual proposition counts on the examples given in Turner and Greene (1977) and Chand et al.", "startOffset": 107, "endOffset": 132}, {"referenceID": 7, "context": "Table 3: Spearman correlations between CPIDR, DEPID and manual proposition counts on the examples given in Turner and Greene (1977) and Chand et al. (2010).", "startOffset": 136, "endOffset": 156}, {"referenceID": 28, "context": "We computed the Spearman correlations between CPIDR, DEPID and manual proposition counts on the 69 example sentences given in chapter 2 in (Turner and Greene, 1977) and the 177 example sentences given in (Chand et al.", "startOffset": 139, "endOffset": 164}, {"referenceID": 20, "context": "It is known that the Alzheimer\u2019s language is generally fluent and grammatical but in order to maintain the fluency the deficiencies in semantic or episodic memory are compensated with empty speech (Nicholas et al., 1985), such as repetitions, both on the word level but also on the idea, sen-", "startOffset": 197, "endOffset": 220}, {"referenceID": 5, "context": "Similar to Brown et al. (2008), we exclude the example 17, but for examples 18, 54, 55, 56, we include all paraphrases.", "startOffset": 11, "endOffset": 31}, {"referenceID": 29, "context": "Recently, Yancheva and Rudzicz (2016) proposed a method for automatically computing SID without the use of manually defined ICUs.", "startOffset": 10, "endOffset": 38}, {"referenceID": 29, "context": "In addition to SID, Yancheva and Rudzicz (2016) experiment with distance-based features also derived from the same clustering.", "startOffset": 20, "endOffset": 48}, {"referenceID": 4, "context": "The first dataset is derived from the DementiaBank (Becker et al., 1994), which is part of a publicly available Talkbank corpus.", "startOffset": 51, "endOffset": 72}, {"referenceID": 12, "context": "(Goodglass and Kaplan, 1983) produced by subjects diagnosed with dementia as well as of healthy control cases.", "startOffset": 0, "endOffset": 28}, {"referenceID": 18, "context": "The data is manually transcribed and annotated in the CHAT format (MacWhinney, 2000), containing a range of annotations denoting various speech events.", "startOffset": 66, "endOffset": 84}, {"referenceID": 12, "context": "(Goodglass and Kaplan, 1983) produced by subjects diagnosed with dementia as well as of healthy control cases. The data is manually transcribed and annotated in the CHAT format (MacWhinney, 2000), containing a range of annotations denoting various speech events. This is the same dataset used by Yancheva and Rudzicz (2016) and similar to them, we use the interviews of all control subjects and subjects whose diagnose is either AD or probable AD.", "startOffset": 1, "endOffset": 324}, {"referenceID": 11, "context": "We preprocess both data sets similarly, following the procedure described in (Fraser et al., 2015) as closely as possible.", "startOffset": 77, "endOffset": 98}, {"referenceID": 7, "context": "ually annotated the propositions of 20 interviews from DementiaBank according to the guidelines given by Chand et al. (2012). We found that both CPIDR and DEPID overestimate the PID values although CPIDR does it to much greater extent.", "startOffset": 105, "endOffset": 125}, {"referenceID": 17, "context": "sentences we evaluated the specificity of all sentences using SpeciTeller (Li and Nenkova, 2015).", "startOffset": 74, "endOffset": 96}, {"referenceID": 29, "context": "In following (Yancheva and Rudzicz, 2016), we clus-", "startOffset": 13, "endOffset": 41}, {"referenceID": 29, "context": "For better comparison with Yancheva and Rudzicz (2016) we also experi-", "startOffset": 27, "endOffset": 55}, {"referenceID": 25, "context": "We also show additional semantic baselines using LIWC features (Tausczik and Pennebaker, 2010) and bag-of-word (BOW) features extracting the counts", "startOffset": 63, "endOffset": 94}, {"referenceID": 11, "context": "9% (Fraser et al., 2015) and an F-score of 80.", "startOffset": 3, "endOffset": 24}, {"referenceID": 29, "context": "0% (Yancheva and Rudzicz, 2016).", "startOffset": 3, "endOffset": 31}, {"referenceID": 11, "context": "9% (Fraser et al., 2015) and an F-score of 80.0% (Yancheva and Rudzicz, 2016). Note however that the BOW features are conceptually much simpler than the acoustic and lexicosyntactic features extracted by Yancheva and Rudzicz (2016) and Fraser et al.", "startOffset": 4, "endOffset": 232}, {"referenceID": 11, "context": "9% (Fraser et al., 2015) and an F-score of 80.0% (Yancheva and Rudzicz, 2016). Note however that the BOW features are conceptually much simpler than the acoustic and lexicosyntactic features extracted by Yancheva and Rudzicz (2016) and Fraser et al. (2015).", "startOffset": 4, "endOffset": 257}, {"referenceID": 29, "context": "Note, that the cluster features F-score trained on the full dataset is slightly lower than the 68% reported by Yancheva and Rudzicz (2016). This difference is probably due to the differences in hy-", "startOffset": 111, "endOffset": 139}, {"referenceID": 21, "context": "ing picture descriptions (Orimaye et al., 2014; Fraser et al., 2015; Yancheva and Rudzicz, 2016; Rentoumi et al., 2014), or semi-constrained structured interviews about some particular topic (Thomas et al.", "startOffset": 25, "endOffset": 119}, {"referenceID": 11, "context": "ing picture descriptions (Orimaye et al., 2014; Fraser et al., 2015; Yancheva and Rudzicz, 2016; Rentoumi et al., 2014), or semi-constrained structured interviews about some particular topic (Thomas et al.", "startOffset": 25, "endOffset": 119}, {"referenceID": 29, "context": "ing picture descriptions (Orimaye et al., 2014; Fraser et al., 2015; Yancheva and Rudzicz, 2016; Rentoumi et al., 2014), or semi-constrained structured interviews about some particular topic (Thomas et al.", "startOffset": 25, "endOffset": 119}, {"referenceID": 22, "context": "ing picture descriptions (Orimaye et al., 2014; Fraser et al., 2015; Yancheva and Rudzicz, 2016; Rentoumi et al., 2014), or semi-constrained structured interviews about some particular topic (Thomas et al.", "startOffset": 25, "endOffset": 119}, {"referenceID": 26, "context": ", 2014), or semi-constrained structured interviews about some particular topic (Thomas et al., 2005; Jarrold et al., 2010, 2014), while our AMI dataset contains free recall samples and thus is probably more spontaneous than the previously used datasets.", "startOffset": 79, "endOffset": 128}, {"referenceID": 11, "context": "Also, we found that on DementiaBank the simple bag-of-words baseline obtained the results very close to the current state-of-the-art that uses much more complex feature sets, including both acoustic and lexicosyntactic features (Fraser et al., 2015).", "startOffset": 228, "endOffset": 249}, {"referenceID": 9, "context": "In the AD and psycholinguistic literature, PID has been automatically calculated using CPIDR (Engelman et al., 2010; Ferguson et al., 2014; Bryant et al., 2013; Moe et al., 2016).", "startOffset": 93, "endOffset": 178}, {"referenceID": 10, "context": "In the AD and psycholinguistic literature, PID has been automatically calculated using CPIDR (Engelman et al., 2010; Ferguson et al., 2014; Bryant et al., 2013; Moe et al., 2016).", "startOffset": 93, "endOffset": 178}, {"referenceID": 6, "context": "In the AD and psycholinguistic literature, PID has been automatically calculated using CPIDR (Engelman et al., 2010; Ferguson et al., 2014; Bryant et al., 2013; Moe et al., 2016).", "startOffset": 93, "endOffset": 178}, {"referenceID": 19, "context": "In the AD and psycholinguistic literature, PID has been automatically calculated using CPIDR (Engelman et al., 2010; Ferguson et al., 2014; Bryant et al., 2013; Moe et al., 2016).", "startOffset": 93, "endOffset": 178}], "year": 2017, "abstractText": "Idea Density (ID) measures the rate at which ideas or elementary predications are expressed in an utterance or in a text. Lower ID is found to be associated with an increased risk of developing Alzheimer\u2019s disease (AD) (Snowdon et al., 1996; Engelman et al., 2010). ID has been used in two different versions: propositional idea density (PID) counts the expressed ideas and can be applied to any text while semantic idea density (SID) counts pre-defined information content units and is naturally more applicable to normative domains, such as picture description tasks. In this paper, we develop DEPID, a novel dependency-based method for computing PID, and its version DEPID-R that enables to exclude repeating ideas\u2014a feature characteristic to AD speech. We conduct the first comparison of automatically extracted PID and SID in the diagnostic classification task on two different AD datasets covering both closed-topic and free-recall domains. While SID performs better on the normative dataset, adding PID leads to a small but significant improvement (+1.7 Fscore). On the free-topic dataset, PID performs better than SID as expected (77.6 vs 72.3 in F-score) but adding the features derived from the word embedding clustering underlying the automatic SID increases the results considerably, leading to an Fscore of 84.8.", "creator": "LaTeX with hyperref package"}}}