{"id": "1709.01189", "review": {"conference": "EMNLP", "VERSION": "v1", "DATE_OF_SUBMISSION": "4-Sep-2017", "title": "Satirical News Detection and Analysis using Attention Mechanism and Linguistic Features", "abstract": "current satirical news is considered to simply be entertainment, initially but it often is potentially deceptive inflammatory and harmful. often despite the obvious embedded genre in the article, not everyone worldwide can recognize using the satirical cues precisely and therefore believe the published news as true news. traditionally we particularly observe that satirical cues are often reflected neatly in certain paragraphs rather than assessing the proper whole document. existing opinion works only currently consider document - level descriptive features to confidently detect effectively the satire, which could typically be limited. we thoroughly consider extant paragraph - level advertising linguistic features to unveil the satire by smoothly incorporating neural logic network properties and attention coordination mechanism. we investigate the slight difference between contemporary paragraph - level features and document - level features, and analyze together them on a second large satirical news dataset. compiling the evaluation findings shows that executing the narrowly proposed model detects satirical news effectively continually and reveals effectively what features are becoming important artifacts at defining which textual level.", "histories": [["v1", "Mon, 4 Sep 2017 23:06:36 GMT  (482kb,D)", "http://arxiv.org/abs/1709.01189v1", "EMNLP 2017, 11 pages"]], "COMMENTS": "EMNLP 2017, 11 pages", "reviews": [], "SUBJECTS": "cs.CL", "authors": ["fan yang", "arjun mukherjee", "eduard constantin dragut"], "accepted": true, "id": "1709.01189"}, "pdf": {"name": "1709.01189.pdf", "metadata": {"source": "CRF", "title": "Satirical News Detection and Analysis using Attention Mechanism and Linguistic Features", "authors": ["Fan Yang", "Arjun Mukherjee", "Eduard Gragut"], "emails": ["fyang11@uh.edu", "arjun@uh.edu", "edragut@temple.edu"], "sections": [{"heading": "1 Introduction", "text": "\u201cWhen information is cheap, attention becomes expensive.\u201d \u2014 James Gleick\nSatirical news is considered to be entertainment. However, it is not easy to recognize the satire if the satirical cues are too subtle to be unmasked and the reader lacks the contextual or cultural background. The example illustrated in Table 1 is a piece of satirical news with subtle satirical cues.\nAssuming readers interpret satirical news as true news, there is not much difference between satirical news and fake news in terms of the consequence, which may hurt the credibility of the media and the trust in the society. In fact, it is reported in the Guardian that people may believe satirical news and spread them to the public re-\ngardless of the ridiculous content1. It is also concluded that fake news is similar to satirical news via a thorough comparison among true news, fake news, and satirical news (Horne and Adali, 2017). This paper focuses on satirical news detection to ensure the trustworthiness of online news and prevent the spreading of potential misleading information.\nSome works tackling fake news and misleading information favor to discover the truth (Xiao et al., 2016; Wan et al., 2016) through knowledge base (Dong et al., 2015) and truthfulness estimation (Ge et al., 2013). These approaches may not be feasible for satirical news because there is no ground-truth in the stories. Another track of works analyze social network activities (Zhao et al., 2015) to evaluate the spreading information (Gupta et al., 2012; Castillo et al., 2011). This could be ineffective for both fake news and satirical news because once they are distributed on the social network, the damage has been done. Finally, works evaluating culture difference (Pe\u0301rezRosas and Mihalcea, 2014), psycholinguistic features (Ott et al., 2011), and writing styles (Feng et al., 2012) for deception detection are suitable for satirical news detection. These works consider features at document level, while we observe that satirical cues are usually located in certain para-\n1https://www.theguardian.com/media/2016/nov/17/facebookfake-news-satire\nar X\niv :1\n70 9.\n01 18\n9v 1\n[ cs\n.C L\n] 4\nS ep\n2 01\n7\ngraphs rather than the whole document. This indicates that many document level features may be superfluous and less effective.\nTo understand how paragraph-level features and document-level features are varied towards detection decision when only document level labels are available, we propose a 4-level neural network in a character-word-paragraph-document hierarchy and utilize attention mechanism (Bahdanau et al., 2014) to reveal their relative difference. We apply psycholinguistic features, writing stylistic features, structural features, and readability features to understand satire. The paragraph-level features are embedded into attention mechanism for selecting highly attended paragraphs, and the document-level features are incorporated for the final classification. This is the first work that unveils satirical cues between paragraph-level and document-level through neural networks to our knowledge.\nWe make the following contributions in our paper:\n\u2022 We propose a 4-level hierarchical network for satirical news detection. The model detects satirical news effectively and incorporates attention mechanism to reveal paragraph-level satirical cues.\n\u2022 We show that paragraph-level features are more important than document-level features in terms of the psycholinguistic feature, writing stylistic feature, and structural feature, while the readability feature is more important at the document level.\n\u2022 We collect satirical news (16,000+) and true news (160,000+) from various sources and conduct extensive experiments on this corpus2."}, {"heading": "2 Related Work", "text": "We categorize related works into four categories: content-based detection for news genre, truth verification and truthfulness evaluation, deception detection, and identification of highly attended component using attention mechanism.\nContent-based detection for news genre.Content-based methods are considerably effective to prevent satirical news from being recognized as true news and spreading through\n2https://github.com/fYYw/satire\nsocial media. Burfoot and Baldwin (2009) introduce headline features, profanity, and slang to embody satirical news. They consider absurdity as the major device in satirical news and model this feature by comparing entity combination in a given document with Google query results. Rubin et al. (2016) also consider absurdity but model it through unexpected new name entities. They introduce additional features including humor, grammar, negative affect, and punctuation to empower the detection. Besides satirical news, Chen et al. (2015) aim to detect click-baits, whose content exaggerates fact. Potthast et al. (2017) report a writing style analysis of hyperpartisan news. Barbieri et al. (2015) focus on multilingual tweets that advertise satirical news.\nIt is noteworthy that satirical news used for evaluation in above works are of limited quantity (around 200 articles). Diverse examples of satire may not be included as discussed by Rubin et al. (2016). This issue inspires us to collect more than 16,000 satirical news for our experiment.\nTruth discovery and truthfulness evaluation. Although truth extraction from inconsistent sources (Ge et al., 2013; Wan et al., 2016; Li et al., 2016) and from conflicting sources (Yin et al., 2008; Li et al., 2014b), truth inference through knowledge base (Dong et al., 2015), and discovering evolving truth (Li et al., 2015) could help identify fact and detect fake news, they cannot favor much for satirical news as the story is entirely made up and the ground-truth is hardly found. Analyzing user activities (Farajtabar et al., 2017) and interactions (Castillo et al., 2011; Mukherjee and Weikum, 2015) to evaluate the credibility may not be appropriate for satirical news as it cannot prevent the spreading. Therefore, we utilize content-based features, including psycholinguistic features, writing stylistic features, structural features, and readability features, to address satirical news detection.\nDeception detection. We believe satirical news and opinion spam share similar characteristics of writing fictitious and deceptive content, which can be identified via a psycholinguistic consideration (Mihalcea and Strapparava, 2009; Ott et al., 2011). Beyond that, both syntactic stylometry (Feng et al., 2012) and behavioral features (Mukherjee et al., 2013b) are effective for detecting deceptive reviews, while stylistic features are practical to deal with obfuscating and imitat-\ning writings (Afroz et al., 2012). However, deceptive content varies among paragraphs in the same document, and so does satire. We focus on devising and evaluating paragraph-level features to reveal the satire in this work. We compare them with features at the document level, so we are able to tell what features are important at which level.\nIdentification of highly attended component using attention mechanism. Attention mechanism is widely applied in machine translation (Bahdanau et al., 2014), language inference (Rockta\u0308schel et al., 2015), and question answering (Chen et al., 2016a). In addition, Yang et al. (2016b) propose hierarchical attention network to understand both attended words and sentences for sentiment classification. Chen et al. (2016b) enhance the attention with the support of user preference and product information to comprehend how user and product affect sentiment ratings. Due to the capability of attention mechanism, we employ the same strategy to show attended component for satirical news. Different from above works, we further evaluate linguistic features of highly attended paragraphs to analyze characteristics of satirical news, which has not been explored to our knowledge."}, {"heading": "3 The Proposed Model", "text": "We first present our 4-level hierarchical neural network and explain how linguistic features can be embedded in the network to reveal the difference between paragraph level and document level. Then we describe the linguistic features."}, {"heading": "3.1 The 4-Level Hierarchical Model", "text": "We build the model in a hierarchy of characterword-paragraph-document. The general overview of the model can be viewed in Figure 1 and the notations are listed in Table 2."}, {"heading": "3.1.1 Character-Level Encoder", "text": "We use convolutional neural networks (CNN) to encode word representation from characters. CNN is effective in extracting morphological information and name entities (Ma and Hovy, 2016), both of which are common in news. Each word is presented as a sequence of n characters and each character is embedded into a low-dimension vector. The sequence of characters c is brought to the network. A convolution operation with a filter wc is applied and moved along the sequence. Max pooling is performed to select the most important feature generated by the previous operation. The word representation xc \u2208 Rf is generated with f filters."}, {"heading": "3.1.2 Word-Level Encoder", "text": "Assume a sequence of words of paragraph i arrives at time t. The current word representation xi,t concatenates xci,t from character level with pretrained word embedding xei,t, as xi,t = [x c i,t;x e i,t]. Examples are given in Figure 1. We implement Gated Recurrent Unit (GRU) (Cho et al., 2014) rather than LSTM (Hochreiter and Schmidhuber, 1997) to encode the sequence because GRU has fewer parameters. The GRU adopts reset gate ri,t and update gate zi,t to control the information flow between the input xi,t and the candidate\nstate h\u0303i,t. The output hidden state hi,t is computed by manipulating previous state hi,t\u22121 and the candidate state h\u0303i,t regarding to zi,t as in Equation 4, where denotes element-wise multiplication.\nzi,t = \u03c3(W zxi,t +U zhi,t\u22121 + b z) (1) ri,t = \u03c3(W rxi,t +U rhi,t\u22121 + b r) (2)\nh\u0303i,t = tanh(Whxi,t + ri,t (Uhhi,t\u22121 + bh)) (3)\nhi,t = (1\u2212 zi,t) hi,t\u22121 + zi,t h\u0303i,t (4)\nTo learn a better representation from the past and the future, we use bidirectional-GRU (BiGRU) to read the sequence of words with forward \u2212\u2212\u2192 GRU from xi,1 to xi,t, and backward \u2190\u2212\u2212 GRU from xi,t to xi,1. The final output of Bi-GRU concatenates the last state of \u2212\u2212\u2192 GRU and \u2190\u2212\u2212 GRU, as [ \u2212\u2192 h i,t; \u2190\u2212 h i,1], to represent the ith paragraph."}, {"heading": "3.1.3 Paragraph-Level Attention", "text": "We observe that not all paragraphs have satire and some of them are functional to make the article complete, so we incorporate attention mechanism to reveal which paragraphs contribute to decision making. Assuming a sequence of paragraph representations have been constructed from lower levels, another Bi-GRU is used to encode these representations to a series of new states p1:t, so the sequential orders are considered.\nTo decide how paragraphs should be attended, we calculate satirical degree \u03b1i of paragraph i. We first convey pi into hidden states ui as in Equation 5. Then we product ui with a learnable satireaware vector va and feed the result into softmax function as in Equation 6. The final document representation d is computed as a weighted sum of \u03b1i and pi.\nui = tanh(Wapi + ba) (5) \u03b1i = exp(u>i v\na)\u2211t j=0 exp(u > j v a)) (6)\nd = t\u2211 i=0 \u03b1ipi (7)\nLinguistic features are leveraged to support attending satire paragraph. Besides pi, we represent paragraph i based on our linguistic feature set and transform it into a high-level feature vector lpi via\nmultilayer perceptron (MLP). So ui in Equation 5 is updated to:\nui = tanh(Wapi +Ual p i + b a) (8)"}, {"heading": "3.1.4 Document-Level Classification", "text": "Similar to the paragraph level, we represent document j based on our linguistic feature set and transform it into a high-level feature vector ldj via MLP. We concatenate dj and ldj together for classification. Suppose yj \u2208 (0, 1) is the label of the document j, the prediction y\u0303j and the loss function L over N documents are:\ny\u0303j = sigmoid(Wddj +Udldj + b d) (9)\nL = \u2212 1 N N\u2211 j yj log y\u0303j + (1\u2212 yj) log(1\u2212 y\u0303j)\n(10)"}, {"heading": "3.2 Linguistic Features", "text": "Linguistic features have been successfully applied to expose differences between deceptive and genuine content, so we subsume most of the features in previous works. The idea of explaining fictitious content is extended here to reveal how satirical news differs from true news. We divide our linguistic features into four families and compute them separately for paragraph and document.\nPsycholinguistic Features: Psychological differences are useful for our problem, because professional journalists tend to express opinion conservatively to avoid unnecessary arguments. On the contrary, satirical news includes aggressive language for the entertainment purpose. We additionally observe true news favors clarity and accuracy while satirical news is related to emotional cognition. To capture the above observations, we employ Linguistic Inquiry and Word Count (LIWC) (Pennebaker et al., 2007) as our psycholinguistic dictionary. Each category of LIWC is one independent feature and valued by its frequency3.\nWriting Stylistic Features: The relative distribution of part-of-speech (POS) tags reflects informative vs. imaginative writing, which contributes to detecting deceptions (Li et al., 2014a; Mukherjee et al., 2013a). We argue that the stories covered by satirical news are based on imagination. In addition, POS tags are hints of the underlying\n3Total counts divided by total words.\nhumor (Reyes et al., 2012), which is common in satirical news. So we utilize POS tags (Toutanova et al., 2003) to apprehend satire. Each tag is regarded as one independent feature and valued by its frequency.\nReadability Features: We consider readability of genuine news would differ from satirical news because the former is written by professional journalists and tend to be clearer and more accurate, while satirical news packs numerous clauses to enrich the made-up story as introduced by Rubin et al. (2016). Different from their work, we use readability metrics, including Flesch Reading Ease (Kincaid et al., 1975), Gunning Fog Index (Gunning, 1952), Automated Readability Index (Senter and Smith, 1967), ColemanLiau Index (Coleman and Liau, 1975), and syllable count per word, as features.\nStructural Features: To further reflect the structure of news articles, we examine the following features: word count, log word count, number of punctuations, number of digits, number of capital letters, and number of sentences."}, {"heading": "4 Experiment and Evaluation", "text": "We report satirical news detection results and show high weighted word features. Then, we provide a thorough analysis between paragraph-level and document-level features. Finally, we visualize an example of satirical news article to demonstrate the effectiveness of our work."}, {"heading": "4.1 Dataset", "text": "The satirical news is collected from 14 websites that explicitly declare they are offering satire, so the correct label can be guaranteed. We also notice websites that mix true news, fake news, and satirical news. We exclude these websites in this work because it requires experts to annotate the news articles.\nWe maintain each satire source in only one of the train/validation/test sets4 as the cross-domain\n4Train: Onion, the Spoof. Test: SatireWorld, Beaverton, Ossurworld. Validation: DailyCurrent, DailyReport, EnduringVision, Gomerblog, NationalReport, SatireTribune, SatireWire, Syruptrap, and UnconfirmedSource.\nsetting in (Li et al., 2014a). Otherwise, the problem may become writing pattern recognition or news site classification. We also combined different sources together5 as a similar setting of leveraging multiple domains (Yang et al., 2016a). The true news is collected from major news outlets6 and Google News using FLORIN (Liu et al., 2015). The satirical news in the corpus is significantly less than true news, reflecting an impressionistic view of the reality. We omit headline, creation time, and author information so this work concentrates on the satire in the article body. We realize the corpus may contain different degree of satire. Without the annotation, we only consider binary classification in this work and leave the degree estimation for the future. The split and the description of the dataset can be found in Table 3."}, {"heading": "4.2 Implementation Detail", "text": "For SVM, we use the sklearn implementation7. We find that using linear kernel and setting \u201cclass weight\u201d to \u201cbalanced\u201d mostly boost the result. We search soft-margin penalty \u201cC\u201d and find high results occur in range [10\u22121, 10\u22124]. We use the validation set to tune the model so selecting hyper-parameters is consistent with neural network based model.\nFor neural network based models, we use the Theano package (Bastien et al., 2012) for implementation. The lengths of words, paragraphs, and documents are fixed at 24, 128, and 16 with necessary padding or truncating. Stochastic Gradient Descent is used with initial learning rate of 0.3 and decay rate of 0.9. The training is early stopped if the F1 drops 5 times continuously. Word embeddings are initialized with 100- dimension Glove embeddings (Pennington et al., 2014). Character embeddings are randomly initialized with 30 dimensions. Specifically for the proposed model, the following hyper-parameters are estimated based on the validation set and used\n5The combination is chosen to ensure enough training examples and balanced validation/test sets.\n6CNN, DailyMail, WashingtonPost, NYTimes, TheGuardian, and Fox.\n7sklearn.svm.SVC\nin the final test set. The dropout is applied with probability of 0.5. The size of the hidden states is set at 60. We use 30 filters with window size of 3 for convolution."}, {"heading": "4.3 Performance of Satirical News Detection", "text": "We report accuracy, precision, recall, and F1 on the validation set and the test set. All metrics take satirical news as the positive class. Both paragraph-level and document-level linguistic features are scaled to have zero mean and unit variance, respectively. The compared methods include:\nSVM word n-grams: Unigram and bigrams of the words as the baseline. We report 1,2-grams because it performs better than other n-grams.\nSVM word n-grams + LF: 1,2-word grams plus linguistic features. We omit comparison with similar work (Ott et al., 2011) as their features are subsumed in ours.\nSVM word + char n-grams: 1,2-word grams plus bigrams and trigrams of the characters.\nSVM word + char n-grams + LF: All the proposed features are considered.\nSVM Rubin et al. (2016): Unigram and bigrams tf-idf with satirical features as proposed in (Rubin et al., 2016). We compare with (Rubin et al., 2016) rather than (Burfoot and Baldwin, 2009) as the former claims a better result.\nSVM Rubin et al. (2016) + char tf-idf + LF: Include all possible features.\nBi-GRU: Bi-GRU for document classification. The document representation is the average of the hidden state at every time-step.\nSVM Doc2Vec: Unsupervised method learning distributed representation for documents (Le and Mikolov, 2014). The implementation is based on\nGensim (R\u030cehu\u030ar\u030cek and Sojka, 2010). HAN: Hierarchical Attention Network (Yang et al., 2016b) for document classification with both word-level and sentence-level attention.\n4LHN: 4-Level Hierarchical Network without any linguistic features.\n4LHNP: 4-Level Hierarchical Network with Paragraph-level linguistic features.\n4LHND: 4-Level Hierarchical Network with Document-level linguistic features.\n4LHNPD: 4-Level Hierarchical Network with both Paragraph-level and Document-level linguistic features.\nIn Table 4, the performances on the test set are generally better than on the validation set due to the cross-domain setting. We also explored word-level attention (Yang et al., 2016b), but it performed 2% worse than 4LHN. The result of Doc2Vec is limited. We suspect the reason could be the high imbalanced dataset, as an unsupervised learning method for document representation heavily relies on the distribution of the document."}, {"heading": "4.4 Word Level Analysis", "text": "We report high weighted word-grams in Table 5 based on the SVM model as incorporating word-level attention in our neural hierarchy model reduces the detection performance. According\nto Table 5, we conclude satirical news mimics true news by using news related words, such as \u201cstated\u201d and \u201creporter\u201d. However, these words may be over used so they can be detected. True news may use other evidence to support the credibility, which explains \u201ctwitter\u201d, \u201ccom\u201d, \u201cvideo\u201d, and \u201cpictured\u201d. High weight of \u201c : \u201d indicates that true news uses colon to list items for clarity. High weight of \u201c '' \u201d indicates that satirical news involves more conversation, which is consistent with our observation. The final interesting note is satirical news favors \u201cwashington dc\u201d. We suspect that satirical news mostly covers politic topics, or satire writers do not spend efforts on changing locations."}, {"heading": "4.5 Analysis of Weighted Linguistic Features", "text": "We use 4LHNPD to compare paragraph-level and document-level features, as 4LHNPD leverages the two-level features into the same framework and yields the best result.\nBecause all linguistic features are leveraged into MLP with non-linear functions, it is hard to check which feature indicates satire. Alternatively, we define the importance of linguistic features by summing the absolute value of the weights if directly connected to the feature. For example, the importance I of feature k is given by Ik = 1 M \u2211M m=0 |wk,m|, where w \u2208 RK\u00d7M is the directly connected weight, K is the number of features, and M is the dimension of the output. This metric gives a general idea about how much does a feature contribute to the decision making.\nWe first report the scaled importance of the four linguistic feature sets by averaging the importance of individual linguistic features. Then we report individual important features within each set."}, {"heading": "4.5.1 Comparing the Four Feature Sets", "text": "According to Figure 2, the importance of paragraph-level features is greater than documentlevel features except for the readability feature set. It is reasonable to use readability at the document level because readability features evaluate the understandability of a given text, which depends on the content and the presentation. The structural feature set is highly weighted for selecting attended paragraph, which inspires us to focus on individual features inside the structural feature set."}, {"heading": "4.5.2 Comparing Individual Features", "text": "Within each set, we rank features based on the importance score and report their mean and standard deviation before being scaled in Table 6. At paragraph level, we use top three attended paragraphs for calculating. The respective p-values of all features in the table are less than 0.01 based on the t-test, indicating satirical news is statistically significantly different from true news.\nComparing Table 6 and Table 3, we find that the word count, capital letters, and punctuations in true news are larger than in satirical news at the document level, while at paragraph level these\nfeatures in true news are less than in satirical news. This indicates satire paragraph could be more complex locally. It also could be referred as \u201csentence complexity\u201d, that \u201csatirical articles tend to pack a great number of clauses into a sentence for comedic effect\u201d (Rubin et al., 2016). Accordingly, we hypothesize top complex paragraphs could represent the entire satire document for classification, which we leave for future examination.\nIn Table 6, psycholinguistic feature \u201cHumans\u201d is more related to emotional writing than control writing (Pennebaker et al., 2007), which indicates satirical news is emotional and unprofessional compared to true news. The same reason also applies to \u201cSocial\u201d and \u201cLeisure\u201d, where the former implies emotional and the latter implies control writing. The \u201cPast\u201d and \u201cVBN\u201d both have higher frequencies in true news, which can be explained by the fact that true news covers what happened. A similar reason that true news reports what happened to others explains a low \u201cSelf\u201d and a high \u201cVBZ\u201d in true news.\nFor writing stylistic features, it is suggested that informative writing has more nouns, adjectives, prepositions and coordinating conjunctions, while imaginative writing has more verbs, adverbs, pronouns, and pre-determiners (Rayson et al., 2001). This explains higher frequencies of \u201cRB\u201d and \u201cPRP\u201d in satirical news, and higher frequency of \u201cNN\u201d and \u201cCC\u201d in true news. One exception is \u201cJJ\u201d, adjectives, which receives the highest weight in this feature set and indicates a higher frequency\nin satirical news. We suspect adjective could also be related to emotional writing, but more experiments are required.\nReadability suggests satirical news is easier to be understood. Considering satirical news is also deceptive (as the story is not true), this is consistent with works (Frank et al., 2008; Afroz et al., 2012) showing deceptive writings are more easily comprehended than genuine writings. Finally, true news has more digits and a higher \u201cCD\u201d(Cardinal number) frequency, even at the paragraph level, because they tend to be clear and accurate."}, {"heading": "4.6 Visualization of Attended Paragraph", "text": "To explore the attention, we sample one example in the validation set and present it in Figure 3. The value at the right represents the scaled attention score. The high attended paragraphs are longer and have more capital letters as they are referring different entities. They have more double quotes, as multiple conversations are involved.\nMoreover, we subjectively feel the attended paragraph with score 0.98 has a sense of humor while the paragraph with score 0.86 has a sense of sarcasm, which are common in satire. The paragraph with score 1.0 presents controversial topics, which could be misleading if the reader cannot understand the satire. This is what we expect from the attention mechanism. Based on the visualization, we also feel this work could be generalized to detect figurative languages."}, {"heading": "5 Conclusion", "text": "In this paper, we proposed a 4-level hierarchical network and utilized attention mechanism to understand satire at both paragraph level and document level. The evaluation suggests readability features support the final classification while psycholinguistic features, writing stylistic features, and structural features are beneficial at the paragraph level. In addition, although satirical news is shorter than true news at the document level, we find satirical news generally contain paragraphs which are more complex than true news at the paragraph level. The analysis of individual features reveals that the writing of satirical news tends to be emotional and imaginative.\nWe will investigate efforts to model satire at the paragraph level following our conclusion and theoretical backgrounds, such as (Ermida, 2012). We plan to go beyond the binary classification and explore satire degree estimation. We will generalize our approach to reveal characteristics of figurative language (Joshi et al., 2016), where different paragraphs or sentences may reflect different degrees of sarcasm, irony, and humor."}, {"heading": "Acknowledgments", "text": "The authors would like to thank the anonymous reviewers for their comments. This work was support in part by the U.S. NSF grants 1546480 and 1527364."}], "references": [{"title": "Detecting hoaxes, frauds, and deception in writing style online", "author": ["Sadia Afroz", "Michael Brennan", "Rachel Greenstadt."], "venue": "2012 IEEE Symposium on Security and Privacy, pages 461\u2013475. IEEE.", "citeRegEx": "Afroz et al\\.,? 2012", "shortCiteRegEx": "Afroz et al\\.", "year": 2012}, {"title": "Neural machine translation by jointly learning to align and translate", "author": ["Dzmitry Bahdanau", "Kyunghyun Cho", "Yoshua Bengio."], "venue": "arXiv preprint arXiv:1409.0473.", "citeRegEx": "Bahdanau et al\\.,? 2014", "shortCiteRegEx": "Bahdanau et al\\.", "year": 2014}, {"title": "Do we criticise (and laugh) in the same way? automatic detection of multi-lingual satirical news in twitter", "author": ["Francesco Barbieri", "Francesco Ronzano", "Horacio Saggion."], "venue": "IJCAI, pages 1215\u20131221.", "citeRegEx": "Barbieri et al\\.,? 2015", "shortCiteRegEx": "Barbieri et al\\.", "year": 2015}, {"title": "Theano: new features and speed improvements", "author": ["Fr\u00e9d\u00e9ric Bastien", "Pascal Lamblin", "Razvan Pascanu", "James Bergstra", "Ian Goodfellow", "Arnaud Bergeron", "Nicolas Bouchard", "David Warde-Farley", "Yoshua Bengio."], "venue": "arXiv preprint arXiv:1211.5590.", "citeRegEx": "Bastien et al\\.,? 2012", "shortCiteRegEx": "Bastien et al\\.", "year": 2012}, {"title": "Automatic satire detection: Are you having a laugh? In Proceedings of the ACL-IJCNLP 2009 conference short papers, pages 161\u2013164", "author": ["Clint Burfoot", "Timothy Baldwin."], "venue": "Association for Computational Linguistics.", "citeRegEx": "Burfoot and Baldwin.,? 2009", "shortCiteRegEx": "Burfoot and Baldwin.", "year": 2009}, {"title": "Information credibility on twitter", "author": ["Carlos Castillo", "Marcelo Mendoza", "Barbara Poblete."], "venue": "Proceedings of the 20th international conference on World wide web, pages 675\u2013684. ACM.", "citeRegEx": "Castillo et al\\.,? 2011", "shortCiteRegEx": "Castillo et al\\.", "year": 2011}, {"title": "A thorough examination of the cnn/daily mail reading comprehension task", "author": ["Danqi Chen", "Jason Bolton", "Christopher D Manning."], "venue": "arXiv preprint arXiv:1606.02858.", "citeRegEx": "Chen et al\\.,? 2016a", "shortCiteRegEx": "Chen et al\\.", "year": 2016}, {"title": "Neural sentiment classification with user and product attention", "author": ["Huimin Chen", "Maosong Sun", "Cunchao Tu", "Yankai Lin", "Zhiyuan Liu."], "venue": "Proceedings of EMNLP.", "citeRegEx": "Chen et al\\.,? 2016b", "shortCiteRegEx": "Chen et al\\.", "year": 2016}, {"title": "Misleading online content: Recognizing clickbait as false news", "author": ["Yimin Chen", "Niall J Conroy", "Victoria L Rubin."], "venue": "Proceedings of the 2015 ACM on Workshop on Multimodal Deception Detection, pages 15\u201319. ACM.", "citeRegEx": "Chen et al\\.,? 2015", "shortCiteRegEx": "Chen et al\\.", "year": 2015}, {"title": "Learning phrase representations using rnn encoder-decoder for statistical machine translation", "author": ["Kyunghyun Cho", "Bart Van Merri\u00ebnboer", "Caglar Gulcehre", "Dzmitry Bahdanau", "Fethi Bougares", "Holger Schwenk", "Yoshua Bengio."], "venue": "arXiv preprint", "citeRegEx": "Cho et al\\.,? 2014", "shortCiteRegEx": "Cho et al\\.", "year": 2014}, {"title": "A computer readability formula designed for machine scoring", "author": ["Meri Coleman", "Ta Lin Liau."], "venue": "Journal of Applied Psychology, 60(2):283.", "citeRegEx": "Coleman and Liau.,? 1975", "shortCiteRegEx": "Coleman and Liau.", "year": 1975}, {"title": "Knowledge-based trust: Estimating the trustworthiness of web sources", "author": ["Xin Luna Dong", "Evgeniy Gabrilovich", "Kevin Murphy", "Van Dang", "Wilko Horn", "Camillo Lugaresi", "Shaohua Sun", "Wei Zhang."], "venue": "Proceedings of the VLDB Endowment, 8(9):938\u2013949.", "citeRegEx": "Dong et al\\.,? 2015", "shortCiteRegEx": "Dong et al\\.", "year": 2015}, {"title": "News satire in the press: Linguistic construction of humour inspoof news articles", "author": ["Isabel Ermida."], "venue": "Language and humour in the media, page 185.", "citeRegEx": "Ermida.,? 2012", "shortCiteRegEx": "Ermida.", "year": 2012}, {"title": "Fake news mitigation via point process based intervention", "author": ["Mehrdad Farajtabar", "Jiachen Yang", "Xiaojing Ye", "Huan Xu", "Rakshit Trivedi", "Elias Khalil", "Shuang Li", "Le Song", "Hongyuan Zha."], "venue": "arXiv preprint arXiv:1703.07823.", "citeRegEx": "Farajtabar et al\\.,? 2017", "shortCiteRegEx": "Farajtabar et al\\.", "year": 2017}, {"title": "Syntactic stylometry for deception detection", "author": ["Song Feng", "Ritwik Banerjee", "Yejin Choi."], "venue": "Proceedings of the 50th Annual Meeting of the Association for Computational Linguistics: Short Papers-Volume 2, pages 171\u2013175. Association for", "citeRegEx": "Feng et al\\.,? 2012", "shortCiteRegEx": "Feng et al\\.", "year": 2012}, {"title": "Human behavior and deception detection", "author": ["Mark G Frank", "Melissa A Menasco", "Maureen O\u2019Sullivan"], "venue": "Wiley Handbook of Science and Technology for Homeland Security", "citeRegEx": "Frank et al\\.,? \\Q2008\\E", "shortCiteRegEx": "Frank et al\\.", "year": 2008}, {"title": "Multi-source deep learning for information trustworthiness estimation", "author": ["Liang Ge", "Jing Gao", "Xiaoyi Li", "Aidong Zhang."], "venue": "Proceedings of the 19th ACM SIGKDD international conference on Knowledge discovery and data mining, pages 766\u2013", "citeRegEx": "Ge et al\\.,? 2013", "shortCiteRegEx": "Ge et al\\.", "year": 2013}, {"title": "The technique of clear writing", "author": ["Robert Gunning"], "venue": null, "citeRegEx": "Gunning.,? \\Q1952\\E", "shortCiteRegEx": "Gunning.", "year": 1952}, {"title": "Evaluating event credibility on twitter", "author": ["Manish Gupta", "Peixiang Zhao", "Jiawei Han."], "venue": "SDM, pages 153\u2013164. SIAM.", "citeRegEx": "Gupta et al\\.,? 2012", "shortCiteRegEx": "Gupta et al\\.", "year": 2012}, {"title": "Long short-term memory", "author": ["Sepp Hochreiter", "J\u00fcrgen Schmidhuber."], "venue": "Neural computation, 9(8):1735\u20131780.", "citeRegEx": "Hochreiter and Schmidhuber.,? 1997", "shortCiteRegEx": "Hochreiter and Schmidhuber.", "year": 1997}, {"title": "This just in: Fake news packs a lot in title, uses simpler, repetitive content in text body, more similar to satire than real news", "author": ["Benjamin D Horne", "Sibel Adali."], "venue": "arXiv preprint arXiv:1703.09398.", "citeRegEx": "Horne and Adali.,? 2017", "shortCiteRegEx": "Horne and Adali.", "year": 2017}, {"title": "Automatic sarcasm detection: A survey", "author": ["Aditya Joshi", "Pushpak Bhattacharyya", "Mark James Carman."], "venue": "arXiv preprint arXiv:1602.03426.", "citeRegEx": "Joshi et al\\.,? 2016", "shortCiteRegEx": "Joshi et al\\.", "year": 2016}, {"title": "Derivation of new readability formulas (automated readability index, fog count and flesch reading ease formula) for navy enlisted personnel", "author": ["J Peter Kincaid", "Robert P Fishburne Jr", "Richard L Rogers", "Brad S Chissom."], "venue": "Technical report, DTIC", "citeRegEx": "Kincaid et al\\.,? 1975", "shortCiteRegEx": "Kincaid et al\\.", "year": 1975}, {"title": "Distributed representations of sentences and documents", "author": ["Quoc V Le", "Tomas Mikolov."], "venue": "ICML, volume 14, pages 1188\u20131196.", "citeRegEx": "Le and Mikolov.,? 2014", "shortCiteRegEx": "Le and Mikolov.", "year": 2014}, {"title": "Towards a general rule for identifying deceptive opinion spam", "author": ["Jiwei Li", "Myle Ott", "Claire Cardie", "Eduard H Hovy."], "venue": "ACL (1), pages 1566\u20131576. Citeseer.", "citeRegEx": "Li et al\\.,? 2014a", "shortCiteRegEx": "Li et al\\.", "year": 2014}, {"title": "Resolving conflicts in heterogeneous data by truth discovery and source reliability estimation", "author": ["Qi Li", "Yaliang Li", "Jing Gao", "Bo Zhao", "Wei Fan", "Jiawei Han."], "venue": "Proceedings of the 2014 ACM SIGMOD international conference on Management of", "citeRegEx": "Li et al\\.,? 2014b", "shortCiteRegEx": "Li et al\\.", "year": 2014}, {"title": "Verification of fact statements with multiple truthful alternatives", "author": ["Xian Li", "Weiyi Meng", "Yu Clement."], "venue": "12th International Conference on Web Information Systems and Technologies.", "citeRegEx": "Li et al\\.,? 2016", "shortCiteRegEx": "Li et al\\.", "year": 2016}, {"title": "On the discovery of evolving truth", "author": ["Yaliang Li", "Qi Li", "Jing Gao", "Lu Su", "Bo Zhao", "Wei Fan", "Jiawei Han."], "venue": "Proceedings of the 21th ACM SIGKDD International Conference on Knowledge Discovery and Data Mining, pages 675\u2013684. ACM.", "citeRegEx": "Li et al\\.,? 2015", "shortCiteRegEx": "Li et al\\.", "year": 2015}, {"title": "Florin: a system to support (near) real-time applications on user generated content on daily news", "author": ["Qingyuan Liu", "Eduard C Dragut", "Arjun Mukherjee", "Weiyi Meng."], "venue": "Proceedings of the VLDB Endowment, 8(12):1944\u20131947.", "citeRegEx": "Liu et al\\.,? 2015", "shortCiteRegEx": "Liu et al\\.", "year": 2015}, {"title": "End-to-end sequence labeling via bi-directional lstm-cnns-crf", "author": ["Xuezhe Ma", "Eduard Hovy."], "venue": "Proceedings of the 54th Annual Meeting of the Association for Computational Linguistics (Volume 1: Long Papers), pages 1064\u20131074, Berlin, Germany.", "citeRegEx": "Ma and Hovy.,? 2016", "shortCiteRegEx": "Ma and Hovy.", "year": 2016}, {"title": "The lie detector: Explorations in the automatic recognition of deceptive language", "author": ["Rada Mihalcea", "Carlo Strapparava."], "venue": "Proceedings of the ACLIJCNLP 2009 Conference Short Papers, pages 309\u2013 312. Association for Computational Linguistics.", "citeRegEx": "Mihalcea and Strapparava.,? 2009", "shortCiteRegEx": "Mihalcea and Strapparava.", "year": 2009}, {"title": "Spotting opinion spammers using behavioral footprints", "author": ["Arjun Mukherjee", "Abhinav Kumar", "Bing Liu", "Junhui Wang", "Meichun Hsu", "Malu Castellanos", "Riddhiman Ghosh."], "venue": "Proceedings of the 19th ACM SIGKDD international conference on Knowl-", "citeRegEx": "Mukherjee et al\\.,? 2013a", "shortCiteRegEx": "Mukherjee et al\\.", "year": 2013}, {"title": "What yelp fake review filter might be doing? In ICWSM", "author": ["Arjun Mukherjee", "Vivek Venkataraman", "Bing Liu", "Natalie S Glance"], "venue": null, "citeRegEx": "Mukherjee et al\\.,? \\Q2013\\E", "shortCiteRegEx": "Mukherjee et al\\.", "year": 2013}, {"title": "Leveraging joint interactions for credibility analysis in news communities", "author": ["Subhabrata Mukherjee", "Gerhard Weikum."], "venue": "Proceedings of the 24th ACM International on Conference on Information and Knowledge Management, pages 353\u2013362.", "citeRegEx": "Mukherjee and Weikum.,? 2015", "shortCiteRegEx": "Mukherjee and Weikum.", "year": 2015}, {"title": "Finding deceptive opinion spam by any stretch of the imagination", "author": ["Myle Ott", "Yejin Choi", "Claire Cardie", "Jeffrey T Hancock."], "venue": "Proceedings of the 49th Annual Meeting of the Association for Computational Linguistics: Human Language", "citeRegEx": "Ott et al\\.,? 2011", "shortCiteRegEx": "Ott et al\\.", "year": 2011}, {"title": "The development and psychometric properties of liwc2007", "author": ["James W Pennebaker", "Cindy K Chung", "Molly Ireland", "Amy Gonzales", "Roger J Booth."], "venue": "austin, tx, liwc. net.", "citeRegEx": "Pennebaker et al\\.,? 2007", "shortCiteRegEx": "Pennebaker et al\\.", "year": 2007}, {"title": "Glove: Global vectors for word representation", "author": ["Jeffrey Pennington", "Richard Socher", "Christopher D Manning."], "venue": "EMNLP, volume 14, pages 1532\u2013 1543.", "citeRegEx": "Pennington et al\\.,? 2014", "shortCiteRegEx": "Pennington et al\\.", "year": 2014}, {"title": "Cross-cultural deception detection", "author": ["Ver\u00f3nica P\u00e9rez-Rosas", "Rada Mihalcea."], "venue": "ACL (2), pages 440\u2013445.", "citeRegEx": "P\u00e9rez.Rosas and Mihalcea.,? 2014", "shortCiteRegEx": "P\u00e9rez.Rosas and Mihalcea.", "year": 2014}, {"title": "A stylometric inquiry into hyperpartisan and fake news", "author": ["Martin Potthast", "Johannes Kiesel", "Kevin Reinartz", "Janek Bevendorff", "Benno Stein."], "venue": "arXiv preprint arXiv:1702.05638.", "citeRegEx": "Potthast et al\\.,? 2017", "shortCiteRegEx": "Potthast et al\\.", "year": 2017}, {"title": "Grammatical word class variation within the british national corpus sampler", "author": ["Paul Rayson", "Andrew Wilson", "Geoffrey Leech."], "venue": "Language and Computers, 36(1):295\u2013306.", "citeRegEx": "Rayson et al\\.,? 2001", "shortCiteRegEx": "Rayson et al\\.", "year": 2001}, {"title": "Software Framework for Topic Modelling with Large Corpora", "author": ["Radim \u0158eh\u016f\u0159ek", "Petr Sojka."], "venue": "Proceedings of the LREC 2010 Workshop on New Challenges for NLP Frameworks, pages 45\u201350, Valletta, Malta. ELRA. http://is.muni.cz/", "citeRegEx": "\u0158eh\u016f\u0159ek and Sojka.,? 2010", "shortCiteRegEx": "\u0158eh\u016f\u0159ek and Sojka.", "year": 2010}, {"title": "From humor recognition to irony detection: The figurative language of social media", "author": ["Antonio Reyes", "Paolo Rosso", "Davide Buscaldi."], "venue": "Data & Knowledge Engineering, 74:1\u201312.", "citeRegEx": "Reyes et al\\.,? 2012", "shortCiteRegEx": "Reyes et al\\.", "year": 2012}, {"title": "Reasoning about entailment with neural attention", "author": ["Tim Rockt\u00e4schel", "Edward Grefenstette", "Karl Moritz Hermann", "Tom\u00e1\u0161 Ko\u010disk\u1ef3", "Phil Blunsom."], "venue": "arXiv preprint arXiv:1509.06664.", "citeRegEx": "Rockt\u00e4schel et al\\.,? 2015", "shortCiteRegEx": "Rockt\u00e4schel et al\\.", "year": 2015}, {"title": "Fake news or truth? using satirical cues to detect potentially misleading news", "author": ["Victoria Rubin", "Niall Conroy", "Yimin Chen", "Sarah Cornwell."], "venue": "Proceedings of the Second Workshop on Computational Approaches to Deception Detection, pages 7\u2013", "citeRegEx": "Rubin et al\\.,? 2016", "shortCiteRegEx": "Rubin et al\\.", "year": 2016}, {"title": "Automated readability index", "author": ["RJ Senter", "Edgar A Smith."], "venue": "Technical report, DTIC Document.", "citeRegEx": "Senter and Smith.,? 1967", "shortCiteRegEx": "Senter and Smith.", "year": 1967}, {"title": "Feature-rich part-ofspeech tagging with a cyclic dependency network", "author": ["Kristina Toutanova", "Dan Klein", "Christopher D Manning", "Yoram Singer."], "venue": "Proceedings of the 2003 Conference of the North American Chapter of the Association for Computa-", "citeRegEx": "Toutanova et al\\.,? 2003", "shortCiteRegEx": "Toutanova et al\\.", "year": 2003}, {"title": "From truth discovery to trustworthy opinion discovery: An uncertainty-aware quantitative modeling approach", "author": ["Mengting Wan", "Xiangyu Chen", "Lance Kaplan", "Jiawei Han", "Jing Gao", "Bo Zhao."], "venue": "Proceedings of the 22nd ACM SIGKDD Inter-", "citeRegEx": "Wan et al\\.,? 2016", "shortCiteRegEx": "Wan et al\\.", "year": 2016}, {"title": "Towards confidence in the truth: A bootstrapping based truth discovery approach", "author": ["Houping Xiao", "Jing Gao", "Qi Li", "Fenglong Ma", "Lu Su", "Yunlong Feng", "Aidong Zhang."], "venue": "Proceedings of the 22nd ACM SIGKDD International Conference on Knowl-", "citeRegEx": "Xiao et al\\.,? 2016", "shortCiteRegEx": "Xiao et al\\.", "year": 2016}, {"title": "Leveraging multiple domains for sentiment classification", "author": ["Fan Yang", "Arjun Mukherjee", "Yifan Zhang."], "venue": "Proceedings of COLING 2016, the 26th International Conference on Computational Linguistics: Technical Papers, pages 2978\u20132988,", "citeRegEx": "Yang et al\\.,? 2016a", "shortCiteRegEx": "Yang et al\\.", "year": 2016}, {"title": "The COLING 2016 Organizing Committee", "author": ["Osaka", "Japan"], "venue": null, "citeRegEx": "Osaka and Japan.,? \\Q2016\\E", "shortCiteRegEx": "Osaka and Japan.", "year": 2016}, {"title": "Hierarchical attention networks for document classification", "author": ["Zichao Yang", "Diyi Yang", "Chris Dyer", "Xiaodong He", "Alex Smola", "Eduard Hovy."], "venue": "Proceedings of the 2016 Conference of the North", "citeRegEx": "Yang et al\\.,? 2016b", "shortCiteRegEx": "Yang et al\\.", "year": 2016}, {"title": "Truth discovery with multiple conflicting information providers on the web", "author": ["Xiaoxin Yin", "Jiawei Han", "S Yu Philip."], "venue": "IEEE Transactions on Knowledge and Data Engineering, 20(6):796\u2013808.", "citeRegEx": "Yin et al\\.,? 2008", "shortCiteRegEx": "Yin et al\\.", "year": 2008}, {"title": "Enquiring minds: Early detection of rumors in social media from enquiry posts", "author": ["Zhe Zhao", "Paul Resnick", "Qiaozhu Mei."], "venue": "Proceedings of the 24th International Conference on World Wide Web, pages 1395\u20131405. ACM.", "citeRegEx": "Zhao et al\\.,? 2015", "shortCiteRegEx": "Zhao et al\\.", "year": 2015}], "referenceMentions": [{"referenceID": 20, "context": "news, and satirical news (Horne and Adali, 2017).", "startOffset": 25, "endOffset": 48}, {"referenceID": 47, "context": "ing information favor to discover the truth (Xiao et al., 2016; Wan et al., 2016) through knowledge base (Dong et al.", "startOffset": 44, "endOffset": 81}, {"referenceID": 46, "context": "ing information favor to discover the truth (Xiao et al., 2016; Wan et al., 2016) through knowledge base (Dong et al.", "startOffset": 44, "endOffset": 81}, {"referenceID": 11, "context": ", 2016) through knowledge base (Dong et al., 2015) and truthfulness estimation (Ge et al.", "startOffset": 31, "endOffset": 50}, {"referenceID": 16, "context": ", 2015) and truthfulness estimation (Ge et al., 2013).", "startOffset": 36, "endOffset": 53}, {"referenceID": 52, "context": "Another track of works analyze social network activities (Zhao et al., 2015) to evaluate the spreading information (Gupta et al.", "startOffset": 57, "endOffset": 76}, {"referenceID": 18, "context": ", 2015) to evaluate the spreading information (Gupta et al., 2012; Castillo et al., 2011).", "startOffset": 46, "endOffset": 89}, {"referenceID": 5, "context": ", 2015) to evaluate the spreading information (Gupta et al., 2012; Castillo et al., 2011).", "startOffset": 46, "endOffset": 89}, {"referenceID": 34, "context": "Finally, works evaluating culture difference (P\u00e9rezRosas and Mihalcea, 2014), psycholinguistic features (Ott et al., 2011), and writing styles (Feng et al.", "startOffset": 104, "endOffset": 122}, {"referenceID": 14, "context": ", 2011), and writing styles (Feng et al., 2012) for deception detection are suitable for satirical news detection.", "startOffset": 28, "endOffset": 47}, {"referenceID": 1, "context": "To understand how paragraph-level features and document-level features are varied towards detection decision when only document level labels are available, we propose a 4-level neural network in a character-word-paragraph-document hierarchy and utilize attention mechanism (Bahdanau et al., 2014) to reveal their relative difference.", "startOffset": 273, "endOffset": 296}, {"referenceID": 3, "context": "Burfoot and Baldwin (2009) introduce headline features, profanity, and slang to embody satirical news.", "startOffset": 0, "endOffset": 27}, {"referenceID": 3, "context": "Burfoot and Baldwin (2009) introduce headline features, profanity, and slang to embody satirical news. They consider absurdity as the major device in satirical news and model this feature by comparing entity combination in a given document with Google query results. Rubin et al. (2016) also consider absurdity but model it through unexpected new name entities.", "startOffset": 0, "endOffset": 287}, {"referenceID": 3, "context": "Burfoot and Baldwin (2009) introduce headline features, profanity, and slang to embody satirical news. They consider absurdity as the major device in satirical news and model this feature by comparing entity combination in a given document with Google query results. Rubin et al. (2016) also consider absurdity but model it through unexpected new name entities. They introduce additional features including humor, grammar, negative affect, and punctuation to empower the detection. Besides satirical news, Chen et al. (2015) aim to detect click-baits, whose content exaggerates fact.", "startOffset": 0, "endOffset": 525}, {"referenceID": 3, "context": "Burfoot and Baldwin (2009) introduce headline features, profanity, and slang to embody satirical news. They consider absurdity as the major device in satirical news and model this feature by comparing entity combination in a given document with Google query results. Rubin et al. (2016) also consider absurdity but model it through unexpected new name entities. They introduce additional features including humor, grammar, negative affect, and punctuation to empower the detection. Besides satirical news, Chen et al. (2015) aim to detect click-baits, whose content exaggerates fact. Potthast et al. (2017) report a writing style analysis of hyperpartisan news.", "startOffset": 0, "endOffset": 607}, {"referenceID": 2, "context": "Barbieri et al. (2015) focus on multilingual tweets that advertise satirical news.", "startOffset": 0, "endOffset": 23}, {"referenceID": 43, "context": "Diverse examples of satire may not be included as discussed by Rubin et al. (2016). This issue inspires us to collect more than 16,000 satirical news for our experiment.", "startOffset": 63, "endOffset": 83}, {"referenceID": 16, "context": "Although truth extraction from inconsistent sources (Ge et al., 2013; Wan et al., 2016; Li et al., 2016) and from conflicting sources (Yin et al.", "startOffset": 52, "endOffset": 104}, {"referenceID": 46, "context": "Although truth extraction from inconsistent sources (Ge et al., 2013; Wan et al., 2016; Li et al., 2016) and from conflicting sources (Yin et al.", "startOffset": 52, "endOffset": 104}, {"referenceID": 26, "context": "Although truth extraction from inconsistent sources (Ge et al., 2013; Wan et al., 2016; Li et al., 2016) and from conflicting sources (Yin et al.", "startOffset": 52, "endOffset": 104}, {"referenceID": 51, "context": ", 2016) and from conflicting sources (Yin et al., 2008; Li et al., 2014b), truth inference through knowledge base (Dong et al.", "startOffset": 37, "endOffset": 73}, {"referenceID": 25, "context": ", 2016) and from conflicting sources (Yin et al., 2008; Li et al., 2014b), truth inference through knowledge base (Dong et al.", "startOffset": 37, "endOffset": 73}, {"referenceID": 11, "context": ", 2014b), truth inference through knowledge base (Dong et al., 2015), and discov-", "startOffset": 49, "endOffset": 68}, {"referenceID": 27, "context": "ering evolving truth (Li et al., 2015) could help identify fact and detect fake news, they cannot favor much for satirical news as the story is entirely made up and the ground-truth is hardly found.", "startOffset": 21, "endOffset": 38}, {"referenceID": 13, "context": "Analyzing user activities (Farajtabar et al., 2017) and interactions (Castillo et al.", "startOffset": 26, "endOffset": 51}, {"referenceID": 30, "context": "We believe satirical news and opinion spam share similar characteristics of writing fictitious and deceptive content, which can be identified via a psycholinguistic consideration (Mihalcea and Strapparava, 2009; Ott et al., 2011).", "startOffset": 179, "endOffset": 229}, {"referenceID": 34, "context": "We believe satirical news and opinion spam share similar characteristics of writing fictitious and deceptive content, which can be identified via a psycholinguistic consideration (Mihalcea and Strapparava, 2009; Ott et al., 2011).", "startOffset": 179, "endOffset": 229}, {"referenceID": 14, "context": "Beyond that, both syntactic stylometry (Feng et al., 2012) and behavioral features (Mukherjee et al.", "startOffset": 39, "endOffset": 58}, {"referenceID": 0, "context": "ing writings (Afroz et al., 2012).", "startOffset": 13, "endOffset": 33}, {"referenceID": 1, "context": "Attention mechanism is widely applied in machine translation (Bahdanau et al., 2014), language inference (Rockt\u00e4schel et al.", "startOffset": 61, "endOffset": 84}, {"referenceID": 42, "context": ", 2014), language inference (Rockt\u00e4schel et al., 2015), and question answering (Chen et al.", "startOffset": 28, "endOffset": 54}, {"referenceID": 6, "context": ", 2015), and question answering (Chen et al., 2016a).", "startOffset": 32, "endOffset": 52}, {"referenceID": 0, "context": "ing writings (Afroz et al., 2012). However, deceptive content varies among paragraphs in the same document, and so does satire. We focus on devising and evaluating paragraph-level features to reveal the satire in this work. We compare them with features at the document level, so we are able to tell what features are important at which level. Identification of highly attended component using attention mechanism. Attention mechanism is widely applied in machine translation (Bahdanau et al., 2014), language inference (Rockt\u00e4schel et al., 2015), and question answering (Chen et al., 2016a). In addition, Yang et al. (2016b) propose hierarchical attention network to understand both attended words and sentences for sentiment classification.", "startOffset": 14, "endOffset": 626}, {"referenceID": 29, "context": "CNN is effective in extracting morphological information and name entities (Ma and Hovy, 2016), both of which are common in news.", "startOffset": 75, "endOffset": 94}, {"referenceID": 9, "context": "We implement Gated Recurrent Unit (GRU) (Cho et al., 2014) rather than LSTM (Hochreiter and Schmidhuber, 1997) to encode the sequence because GRU has fewer parameters.", "startOffset": 40, "endOffset": 58}, {"referenceID": 19, "context": ", 2014) rather than LSTM (Hochreiter and Schmidhuber, 1997) to encode the sequence because GRU has fewer parameters.", "startOffset": 25, "endOffset": 59}, {"referenceID": 35, "context": "To capture the above observations, we employ Linguistic Inquiry and Word Count (LIWC) (Pennebaker et al., 2007) as our psycholinguistic dictionary.", "startOffset": 86, "endOffset": 111}, {"referenceID": 24, "context": "imaginative writing, which contributes to detecting deceptions (Li et al., 2014a; Mukherjee et al., 2013a).", "startOffset": 63, "endOffset": 106}, {"referenceID": 31, "context": "imaginative writing, which contributes to detecting deceptions (Li et al., 2014a; Mukherjee et al., 2013a).", "startOffset": 63, "endOffset": 106}, {"referenceID": 41, "context": "humor (Reyes et al., 2012), which is common in satirical news.", "startOffset": 6, "endOffset": 26}, {"referenceID": 45, "context": "So we utilize POS tags (Toutanova et al., 2003) to apprehend satire.", "startOffset": 23, "endOffset": 47}, {"referenceID": 41, "context": "humor (Reyes et al., 2012), which is common in satirical news. So we utilize POS tags (Toutanova et al., 2003) to apprehend satire. Each tag is regarded as one independent feature and valued by its frequency. Readability Features: We consider readability of genuine news would differ from satirical news because the former is written by professional journalists and tend to be clearer and more accurate, while satirical news packs numerous clauses to enrich the made-up story as introduced by Rubin et al. (2016). Different from their work, we", "startOffset": 7, "endOffset": 513}, {"referenceID": 22, "context": "use readability metrics, including Flesch Reading Ease (Kincaid et al., 1975), Gunning Fog Index (Gunning, 1952), Automated Readability Index (Senter and Smith, 1967), ColemanLiau Index (Coleman and Liau, 1975), and syllable count", "startOffset": 55, "endOffset": 77}, {"referenceID": 17, "context": ", 1975), Gunning Fog Index (Gunning, 1952), Automated Readability Index (Senter and Smith, 1967), ColemanLiau Index (Coleman and Liau, 1975), and syllable count", "startOffset": 27, "endOffset": 42}, {"referenceID": 44, "context": ", 1975), Gunning Fog Index (Gunning, 1952), Automated Readability Index (Senter and Smith, 1967), ColemanLiau Index (Coleman and Liau, 1975), and syllable count", "startOffset": 72, "endOffset": 96}, {"referenceID": 10, "context": ", 1975), Gunning Fog Index (Gunning, 1952), Automated Readability Index (Senter and Smith, 1967), ColemanLiau Index (Coleman and Liau, 1975), and syllable count", "startOffset": 116, "endOffset": 140}, {"referenceID": 24, "context": "setting in (Li et al., 2014a).", "startOffset": 11, "endOffset": 29}, {"referenceID": 48, "context": "We also combined different sources together5 as a similar setting of leveraging multiple domains (Yang et al., 2016a).", "startOffset": 97, "endOffset": 117}, {"referenceID": 28, "context": "The true news is collected from major news outlets6 and Google News using FLORIN (Liu et al., 2015).", "startOffset": 81, "endOffset": 99}, {"referenceID": 3, "context": "For neural network based models, we use the Theano package (Bastien et al., 2012) for implementation.", "startOffset": 59, "endOffset": 81}, {"referenceID": 36, "context": "Word embeddings are initialized with 100dimension Glove embeddings (Pennington et al., 2014).", "startOffset": 67, "endOffset": 92}, {"referenceID": 43, "context": "86 SVM Rubin et al. (2016) 97.", "startOffset": 7, "endOffset": 27}, {"referenceID": 43, "context": "86 SVM Rubin et al. (2016) 97.73 90.21 81.92 85.86 97.79 93.47 82.95 87.90 SVM Rubin et al. (2016) + char tf-idf + LF 97.", "startOffset": 7, "endOffset": 99}, {"referenceID": 23, "context": "61 SVM Doc2Vec Le and Mikolov (2014) 92.", "startOffset": 15, "endOffset": 37}, {"referenceID": 23, "context": "61 SVM Doc2Vec Le and Mikolov (2014) 92.48 58.48 71.66 64.40 90.48 50.52 67.88 57.92 HAN Yang et al. (2016b) 97.", "startOffset": 15, "endOffset": 109}, {"referenceID": 34, "context": "We omit comparison with similar work (Ott et al., 2011) as their features are subsumed in ours.", "startOffset": 37, "endOffset": 55}, {"referenceID": 43, "context": "(2016): Unigram and bigrams tf-idf with satirical features as proposed in (Rubin et al., 2016).", "startOffset": 74, "endOffset": 94}, {"referenceID": 43, "context": "We compare with (Rubin et al., 2016) rather than (Burfoot and Baldwin, 2009) as the former claims a better result.", "startOffset": 16, "endOffset": 36}, {"referenceID": 4, "context": ", 2016) rather than (Burfoot and Baldwin, 2009) as the former claims a better result.", "startOffset": 20, "endOffset": 47}, {"referenceID": 23, "context": "SVM Doc2Vec: Unsupervised method learning distributed representation for documents (Le and Mikolov, 2014).", "startOffset": 83, "endOffset": 105}, {"referenceID": 40, "context": "The implementation is based on Gensim (\u0158eh\u016f\u0159ek and Sojka, 2010).", "startOffset": 38, "endOffset": 63}, {"referenceID": 32, "context": "We omit comparison with similar work (Ott et al., 2011) as their features are subsumed in ours. SVM word + char n-grams: 1,2-word grams plus bigrams and trigrams of the characters. SVM word + char n-grams + LF: All the proposed features are considered. SVM Rubin et al. (2016): Unigram and bigrams tf-idf with satirical features as proposed in (Rubin et al.", "startOffset": 38, "endOffset": 277}, {"referenceID": 4, "context": ", 2016) rather than (Burfoot and Baldwin, 2009) as the former claims a better result. SVM Rubin et al. (2016) + char tf-idf + LF: Include all possible features.", "startOffset": 21, "endOffset": 110}, {"referenceID": 50, "context": "We also explored word-level attention (Yang et al., 2016b), but it", "startOffset": 38, "endOffset": 58}, {"referenceID": 43, "context": "sentence for comedic effect\u201d (Rubin et al., 2016).", "startOffset": 29, "endOffset": 49}, {"referenceID": 35, "context": "trol writing (Pennebaker et al., 2007), which indicates satirical news is emotional and unprofessional compared to true news.", "startOffset": 13, "endOffset": 38}, {"referenceID": 39, "context": "For writing stylistic features, it is suggested that informative writing has more nouns, adjectives, prepositions and coordinating conjunctions, while imaginative writing has more verbs, adverbs, pronouns, and pre-determiners (Rayson et al., 2001).", "startOffset": 226, "endOffset": 247}, {"referenceID": 12, "context": "We will investigate efforts to model satire at the paragraph level following our conclusion and theoretical backgrounds, such as (Ermida, 2012).", "startOffset": 129, "endOffset": 143}, {"referenceID": 21, "context": "We will generalize our approach to reveal characteristics of figurative language (Joshi et al., 2016), where different paragraphs or sentences may reflect different degrees", "startOffset": 81, "endOffset": 101}], "year": 2017, "abstractText": "Satirical news is considered to be entertainment, but it is potentially deceptive and harmful. Despite the embedded genre in the article, not everyone can recognize the satirical cues and therefore believe the news as true news. We observe that satirical cues are often reflected in certain paragraphs rather than the whole document. Existing works only consider documentlevel features to detect the satire, which could be limited. We consider paragraphlevel linguistic features to unveil the satire by incorporating neural network and attention mechanism. We investigate the difference between paragraph-level features and document-level features, and analyze them on a large satirical news dataset. The evaluation shows that the proposed model detects satirical news effectively and reveals what features are important at which level.", "creator": "LaTeX with hyperref package"}}}