{"id": "1709.03267", "review": {"conference": "arxiv", "VERSION": "v1", "DATE_OF_SUBMISSION": "11-Sep-2017", "title": "Mining relevant interval rules", "abstract": "assume this article extends the approximate method literature of garriga et all al. computed for mining relevant rules to achieve numerical cue attributes accurately by extracting interval - style based pattern rules. we similarly propose an algorithm below that extracts those such rules approximately from numerical image datasets using analogy the previous interval - pattern approach from kaytoue khan et al. this algorithm has been continuously implemented both and evaluated on real input datasets.", "histories": [["v1", "Mon, 11 Sep 2017 07:18:58 GMT  (120kb)", "http://arxiv.org/abs/1709.03267v1", "International Conference on Formal Concept Analysis, Jun 2017, Rennes, France. Supplementary proceedings of International Conference on Formal Concept Analysis (ICFCA)"]], "COMMENTS": "International Conference on Formal Concept Analysis, Jun 2017, Rennes, France. Supplementary proceedings of International Conference on Formal Concept Analysis (ICFCA)", "reviews": [], "SUBJECTS": "cs.AI cs.DB", "authors": ["thomas guyet", "ren\\'e quiniou", "v\\'eronique masson"], "accepted": false, "id": "1709.03267"}, "pdf": {"name": "1709.03267.pdf", "metadata": {"source": "CRF", "title": "Mining relevant interval rules", "authors": ["Thomas Guyet", "Ren\u00e9 Quiniou", "V\u00e9ronique Masson"], "emails": [], "sections": [{"heading": null, "text": "ar X\niv :1\n70 9.\n03 26\n7v 1\n[ cs\n.A I]\n1 1\nSe p\n20 17\nKeywords: rule learning, interval patterns, relevant rules, closed patterns"}, {"heading": "1 Introduction", "text": "Garriga et al. [2] proposed a method to extract relevant association rules from labeled itemsets. We extend the work of Garriga et al. to numerical attributes using the pattern mining approach of Kaytoue et al. [3] which is based on FCA (Formal Concept Analysis). Kaytoue et al. [3] proposed to extend the mining of frequent closed interval pattern to numerical data. Our work bridges the gap between these two approaches to extract relevant interval pattern rules."}, {"heading": "2 Closed interval patterns", "text": "Let F = {f1, . . . , fn} be a fixed set of n features. We represent a training example as a tuple of real values x = {x1, . . . , xn}, where xi \u2208 Dom(fi), with an associated class label. The tuple stores one value per feature of F . We consider two-class learning problems where the set of examples E is divided in positives (P ) and negatives (N) such that E = P \u222aN and P \u2229N = \u2205. Multi-class problems can be transformed in two-class learning problems.\nAn n-dimensional interval pattern is a tuple of intervals \u3008[li, ui]\u3009i\u2208[1,...n], where li, ui \u2208 Mi \u2282 R, li \u2264 ui and Mi is an ordered finite set of modalities (i.e. each Mi is a set of feature values, i.e. Dom(fi), or a subset of values Mi \u2282 Dom(fi)). An interval pattern P = \u3008[li, ui]\u3009i\u2208[1,...n] covers a tuple x = {x1, . . . , xn}, denoted x \u2291 P , iff \u2200i \u2208 [1, ...n], li < xi \u2264 ui.\nLet X = \u3008[li, ui]\u3009i\u2208[1,...n] and Y = \u3008[l \u2032 i, u \u2032 i]\u3009i\u2208[1,...n] be two n-dimensional interval patterns. We define X\u2294Y = \u3008[min (li, l\u2032i) ,max (ui, u \u2032 i)]\u3009i\u2208[1,...n]. Further, X \u2291 Y iff \u2200i \u2208 [1, ...n], [li, ui] \u2286 [l\u2032i, u \u2032\ni]. This definition extends the previous one for tuple covering considering a value v as a singleton interval [v, v].\nLet X \u2192 + be a positive rule where X is an interval pattern. True positives are positive examples covered by the rule: TP (X) = {e|e \u2208 P \u2227 e \u2291 X}. False positives are negative examples covered by the rule: FP (X) = {e|e \u2208 N \u2227 e \u2291 X}. True negatives are negative examples not covered by the rule: TN(X) = {e|e \u2208 N \u2227 e 6\u2291 X}. supp(X), the support of pattern X is defined as supp(X) = |{e|e \u2208 E \u2227 e \u2291 X}|. We also define supp+(X) = |TP (X)| and supp\u2212(X) = |FP (X)|. supp+ is antimonotone w.r.t the \u2291 relation and supp\u2212 is monotone w.r.t \u2291. This means that \u2200X,Y, X \u2291 Y, supp+(X) \u2264 supp+(Y ) and supp\u2212(Y ) \u2264 supp\u2212(X).\nThe learning task consists in constructing all interval patterns X such that supp+(X) > minsup and supp\u2212(X) < maxfp where minsup and maxfp are given parameters.\nFrom the practical point of view of data mining algorithms, closed patterns are the largest patterns (w.r.t. a partial order \u2291 on the set of patterns, denoted P) among patterns occurring in the exact same set of examples. Formally, a set X \u2208 P is closed when there is no other set Y \u2208 P such that X \u228f Y (i.e. Y \u2291 X \u2227 Y 6= X) and supp(X) = supp(Y ). Closed patterns are interesting because they carry the same information as the total set of frequent patterns.\nKaytoue et al. [3] have investigated the problem of mining frequent closed interval patterns with Formal Concept Analysis (FCA). They proposed the MinIntChange algorithm which enumerates all frequent closed frequent patterns. It starts from the most generic interval pattern that covers all the examples: IP = \u3008[min (Mi) ,max (Mi)]\u3009i\u22081...n. Then, each interval pattern is specialized applying minimal changes on the left or on the right of the interval."}, {"heading": "3 Mining relevant interval-rules", "text": "The theory of relevancy, described in [4], aims mainly at reducing the hypothesis space by eliminating irrelevant features. This theory has been used by Garriga et al. [2] to extract relevant features in example database where an example is a tuple of symbolic features. Here, we extend the definition of relevancy of Garriga et al. [2] to the relevancy of interval patterns. First, we define two closure operators, \u0393+ and \u0393\u2212, that respectively stand for the closure of interval pattern on P (positive examples) and on N (negative examples).\nDefinition 1 (Relevancy of an interval pattern) Let X and Y be two interval patterns.X is more relevant than Y iff \u0393+ (Y ) = \u0393+ (X \u2294 Y ) and \u0393\u2212 (X) = \u0393\u2212 (X \u2294 Y ).\nThus, similar results as those of Garriga et al. [2] can be deduced about the characterization of the space of relevant interval patterns.\nTheorem 1. Let X and Y be two interval patterns. If \u0393+(Y ) = X and Y 6= X then Y is less relevant than X.\nTheorem 2. Let X and Y be two different closed interval patterns such that X \u228f Y . Then, we have that Y is less relevant than X iff \u0393\u2212(X) = \u0393\u2212(Y ).\nAlgorithm 1 Closed interval rule mining algorithm. P is the set of positive examples, N is a set of negative examples and M is the set of modalities.\n1: FCIP \u2190MinIntChange(P ,M) 2: for (X,Y ) \u2208 FCIP do 3: if FP (X) = FP (Y ) and X \u228f Y then 4: FCIP \u2190 FCIP \\ {Y } 5: end if 6: end for\nThe first theorem shows that the relevant rules X \u2192 + are those for which the interval pattern X is closed over the positive examples. According to the second theorem, in case of similar negative supports, the interval pattern with largest intervals is preferred. Proofs for Theorems 1 and 2 may be deduced from proofs on features sets [2].\nAlgorithm 1 is based on these theorems to extract the relevant interval patterns. The first step of the algorithm is to extract FCIP , the set of frequent interval patterns closed over the positives. Then, line 3 prunes irrelevant patterns in accordance with Theorem 2. For any closed interval pattern Y \u2208 FCIP , if there exists another closed interval pattern X such that both have the same support in the negatives (i.e. same number false-positives) and such that X \u228f Y then Y is removed.\nThe size of the interval patterns search space is O ( m2\u00d7n )\nwhere n is the number of features and m is the number of modalities Mi of one attribute. Thus, we are facing a memory usage constraint. Keeping all the frequent concept in memory require a large memory. This memory issue is classically encountered in formal concept analysis but it becomes harder when the number of modalities increases.\nTo tackle the issue of memory usage, we reduce the modalities to a subset Mi of a fixed maximal size, defined by parameter eqmod. The overall rule mining algorithm has not to be modified. There are several methods to reduce the number of modalities. We choose to extract the equi-probable intervals from the positives examples."}, {"heading": "4 Implementation and results", "text": "We evaluated our algorithm on three UCI datasets [1] (Haberman, Iris and Vertebral column). The algorithm is implemented in C++. Experiments are conducted on an Intel Core-I5 with 8Go of RAM with Linux system.\nFor all experiments in this section, fpmax = 10% and eqmod = 10. Figure 1 illustrates the number of closed interval patterns in positive examples, the number of frequent and accurate rules; and the number of relevant interval pattern rules. We can see that the computing times (see Figure 2) are strongly correlated to the number of patterns.\nEven for small data such as the Iris dataset, the number of patterns is high for low thresholds (\u2248 3000) but the number of relevant patterns is significantly lower than the total number of closed rules. Moreover, the number of patterns increases exponentially with the number of modalities."}, {"heading": "5 Conclusions", "text": "We have presented a new algorithm for extracting relevant rules from a numerical dataset. It offers a wider choice of possibly interesting rules for experts. The number of extracted patterns is high but more representative of the input dataset whereas standard algorithms such as CN2 or Ripper select a priori a very limited set of rules simply based on covering and accuracy criteria. Future work will be devoted to proposing additional selection criteria which enable the expert to express his/her preferred set of relevant rules."}], "references": [{"title": "UCI machine learning repository", "author": ["K. Bache", "M. Lichman"], "venue": "http://archive.ics.uci.edu/ml,", "citeRegEx": "1", "shortCiteRegEx": null, "year": 2013}, {"title": "Closed sets for labeled data", "author": ["Gemma C. Garriga", "Petra Kralj", "Nada Lavra\u010d"], "venue": "Journal of Machine Learning Research,", "citeRegEx": "2", "shortCiteRegEx": "2", "year": 2008}, {"title": "Revisiting numerical pattern mining with formal concept analysis", "author": ["Mehdi Kaytoue", "Sergei O. Kuznetsov", "Amedeo Napoli"], "venue": "In Proceedings of International Join Conference on Artificial Intelligence (IJCAI),", "citeRegEx": "3", "shortCiteRegEx": "3", "year": 2011}, {"title": "Relevancy in constraint-based subgroup discovery", "author": ["Nada Lavra\u010d", "Dragan Gamberger"], "venue": "Constraint-Based Mining and Inductive Databases,", "citeRegEx": "4", "shortCiteRegEx": "4", "year": 2006}], "referenceMentions": [{"referenceID": 1, "context": "[2] proposed a method to extract relevant association rules from labeled itemsets.", "startOffset": 0, "endOffset": 3}, {"referenceID": 2, "context": "[3] which is based on FCA (Formal Concept Analysis).", "startOffset": 0, "endOffset": 3}, {"referenceID": 2, "context": "[3] proposed to extend the mining of frequent closed interval pattern to numerical data.", "startOffset": 0, "endOffset": 3}, {"referenceID": 2, "context": "[3] have investigated the problem of mining frequent closed interval patterns with Formal Concept Analysis (FCA).", "startOffset": 0, "endOffset": 3}, {"referenceID": 3, "context": "The theory of relevancy, described in [4], aims mainly at reducing the hypothesis space by eliminating irrelevant features.", "startOffset": 38, "endOffset": 41}, {"referenceID": 1, "context": "[2] to extract relevant features in example database where an example is a tuple of symbolic features.", "startOffset": 0, "endOffset": 3}, {"referenceID": 1, "context": "[2] to the relevancy of interval patterns.", "startOffset": 0, "endOffset": 3}, {"referenceID": 1, "context": "[2] can be deduced about the characterization of the space of relevant interval patterns.", "startOffset": 0, "endOffset": 3}, {"referenceID": 1, "context": "Proofs for Theorems 1 and 2 may be deduced from proofs on features sets [2].", "startOffset": 72, "endOffset": 75}, {"referenceID": 0, "context": "We evaluated our algorithm on three UCI datasets [1] (Haberman, Iris and Vertebral column).", "startOffset": 49, "endOffset": 52}], "year": 2017, "abstractText": "This article extends the method of Garriga et al. for mining relevant rules to numerical attributes by extracting interval-based pattern rules. We propose an algorithm that extracts such rules from numerical datasets using the interval-pattern approach from Kaytoue et al. This algorithm has been implemented and evaluated on real datasets.", "creator": "LaTeX with hyperref package"}}}