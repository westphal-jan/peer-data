{"id": "1003.0659", "review": {"conference": "arxiv", "VERSION": "v1", "DATE_OF_SUBMISSION": "2-Mar-2010", "title": "Particle Filtering on the Audio Localization Manifold", "abstract": "secondly present a stationary particle filtering algorithm calculating their underlying moving stream source using a microphone array. if there are n microphones spanning the array, the track compute $ n \\ choose 2 $ delays with a single detector filter matching time. since it is known physical communication of high dimensions seems rife with difficulties, next instead integrate into our final filter search model of corresponding low pitched object presenting these delays apply together. that process model is based off of complexity within modeling low sized manifolds into random projection trees [ 1 ]. in modeling, we also introduce comprehensive meta modelling scheme to geometric dot filtering algorithm based on recent advancements in online coding. we applied effectively our corresponding tdoa computational algorithm that replaces a visual model explicitly can outperform global particle filters on this geometric tracking task.", "histories": [["v1", "Tue, 2 Mar 2010 19:50:38 GMT  (187kb,S)", "https://arxiv.org/abs/1003.0659v1", null], ["v2", "Tue, 2 Mar 2010 21:40:35 GMT  (187kb)", "http://arxiv.org/abs/1003.0659v2", null]], "reviews": [], "SUBJECTS": "cs.AI cs.SD", "authors": ["evan ettinger", "yoav freund"], "accepted": false, "id": "1003.0659"}, "pdf": {"name": "1003.0659.pdf", "metadata": {"source": "CRF", "title": "Particle Filtering on the Audio Localization Manifold", "authors": ["Evan Ettinger"], "emails": ["yfreund}@cs.ucsd.edu"], "sections": [{"heading": null, "text": "ar X\niv :1\n00 3.\n06 59\nv2 [\ncs .A\nI] 2\nM ar\nWe present a novel particle filtering algorithm for tracking a moving sound source using a microphone array. If there are N microphones in the array, we track all (\nN 2\n)\ndelays with a single particle filter over time. Since it is known that tracking in high dimensions is rife with difficulties, we instead integrate into our particle filter a model of the low dimensional manifold that these delays lie on. Our manifold model is based off of work on modeling low dimensional manifolds via random projection trees [5]. In addition, we also introduce a new weighting scheme to our particle filtering algorithm based on recent advancements in online learning. We show that our novel TDOA tracking algorithm that integrates a manifold model can greatly outperform standard particle filters on this audio tracking task."}, {"heading": "1 Introduction", "text": "There is an increasing interest in locating audio sources with a microphone array as a means to direct the pointing of a camera. Camera pointing applications include video conferencing, surveillance, game playing and interactive displays. In addition, speech enhancement with microphone arrays rely critically on knowing the correct source location.\nOne popular method for locating an audio source is based on measuring the delays observed between spatially separated pairs of microphones known as the time delay of arrival (TDOA). For locating a source a two stage process can be employed: First TDOAs for all pairs of microphones are estimated, and then a source location is derived from this delay information. If microphone positions are given, the second step becomes approximately solving a set of non-linear phys-\nical equations such as in [6]. However, localizing an audio source accurately in a large room requires that the microphones are far apart from each other. As a result of placing the microphones far apart, it becomes difficult to estimate their positions within a coordinate system accurately. If the positions are not known, then a regressor can be learned that maps TDOAs to camera pointing directives as in [7, 4].\nIn this work we focus on accurately estimating and tracking TDOAs for a microphone array in a large room. There is an extensive literature on using particle filters for tracking audio sources when the microphone positions are known [13, 11]. Since positional information is known, the state space for the particles is typically only two or three spatial dimensions for the location of the sound source. When the microphone positions are not known and we attempt to track in the native TDOA space we become victim to the slew of problems that come with tracking in high dimensions. With N microphones in the array each pair has a TDOA that needs to be tracked making the state space be of dimension D = (\nN 2\n)\n. D can be quite large for a microphone array in a large room.\nTo alleviate the problem of high dimensionality we propose an addition to the particle filter that includes a restriction on the state space of particles to that of a low dimensional manifold. Underlying the D dimensions of a TDOA measurement are only three degrees of spatial freedom for the sound source to move in. Each 3-d spatial location creates a unique TDOA vector which varies smoothly with smooth variations in the spatial location. We model this low dimensional manifold using a tree-based spatial partitioning data structure combined with principal components analysis. Our tree structure is based on work on random projection trees, which have been shown to adapt to low dimensional intrinsic structure when the data itself lies in a high dimensional space [5].\nWe also investigate in this work a new particle filter based on work from the online learning body of liter-\nature. In particular we focus on work from combining expert advice via the normal hedge algorithm [2]. For particle filters, each expert is itself a particle that predicts a state at each time step. The normal hedge particle filter gives both a new particle weighting scheme and a natural resampling scheme for particles based on the fact that the algorithm explicitly gives zero weight to poorly performing particles. Using normal hedge in the particle filtering framework has been initially explored in [3]. This is the first time this algorithm has been applied to the TDOA tracking problem, and to the best of our knowledge, any practical problem to date.\nThe rest of the paper is organized as follows. Section 2 briefly discusses how we estimate TDOAs for a given pair of microphones via the phase transform. Section 3 discusses random projection trees and how they adapt to low dimensional intrinsic structure. Section 4 discusses our particle filter implementation that includes the model of the manifold. Finally in section 5 we discuss some experiments on tracking TDOA vectors with real-world data collected from an interactive display."}, {"heading": "2 Time Delay of Arrival", "text": "One very popular method for estimating a TDOA given frames of audio from a pair of microphones is to use a generalized correlation technique such as the phase transform otherwise known as PHAT [13]. PHAT is a normalized cross correlation technique that removes the magnitudes of the amplitude information from the audio signals putting the emphasize on aligning the phase components. Define Rp(\u03c4) as the PHAT correlation between microphone pair p at time delay \u03c4 , then the TDOA is often estimated by\n\u2206\u0302p = argmax \u03c4 Rp(\u03c4) (1)\nHowever, in a reverberant environment there are often spurious peaks in Rp from either line noise or multipath reflections. In these cases the true TDOA may not be the largest peak in the PHAT correlation. By using particle filters we are able to leverage this secondary peak information when formulating a likelihood function that incorporates the entirety of the observation Rp. This gives the particle filtering method a robustness over traditional approaches that depend on the accuracy of Equation (1) over all pairs p."}, {"heading": "3 Modeling the Manifold", "text": "A TDOA vector has only three underlying spatial degrees of freedom. If the microphone positions were known, then the physics equation for the TDOA be-\ntween microphone pair p = (i, j) is\n\u2206p = \u2016mi \u2212 s\u20162 \u2212 \u2016mj \u2212 s\u20162\nc (2)\nwhere mi is the position of microphone i, s is the source location and c is the speed of sound in air. In this work we assume no such knowledge of mi, but nevertheless the same physical principals apply. As s varies smoothly, so does \u2206p. So even though the vector containing the TDOAs for all microphone pairs has D components, the real underlying dimensionality is only three. We call this lower dimensional smooth structure the TDOA manifold.\nModeling the TDOA manifold for a particular array configuration is an integral part of the particle filtering algorithm we present in Section 4. Our model is based off of the random projection tree spatial partitioning algorithm whose details can be found in [5]. A random projection tree (RP-tree) is a binary tree that recursively splits a dataset into two subsets. It is constructed in nearly the same way as a KD-tree but instead of recursively splitting the dataset along a single coordinate axis, the data is first projected onto a random direction and then split near the median of these projections. RP-trees have been effectively used as a means for vector quantization and for regression problems when the data has much lower intrinsic dimensionality than it\u2019s ambient dimension[10, 8].\nThe intrinsic dimensionality of a dataset can be measured in a variety of ways including Assouad dimension or fraction of variance explained by a PCA at the appropriate neighborhood size. RP-trees guarantee that if the data falling in a given node n of the tree has intrinsic dimensionality d, then all cells O(d) levels below n have at most half the data diameter. This guarantee depends only on the intrinsic dimensionality of the data d and not the ambient dimensionality D. Therefore, we can expect a rapid convergence to the manifold structure from such a partitioning tree.\nTo model the TDOA manifold we first collect a training set of TDOA vectors sampled from the room containing our fixed microphone array. This can be done by using a white noise source and moving it throughout the room. Since white noise is random, the TDOAs measured via PHAT using Equation 1 are very reliable training data after some simple outlier removal. Another way to collect such a training set is from interactions by people with an interactive display as in [4].\nThe tree we build in this work is similar to an RP-tree but uses principal components analysis instead of random projections. We call this tree a PD-tree and it has been shown empirically that these trees adapt to intrinsic dimensionality well in practice [12]. A PD-tree recursively partitions the training set by projecting the data onto its top principal direction and then choosing the median of these projections to be the splitting point. A depiction of a PD-tree of height 1 on a toy dataset is given in Figure 1. We find that in practice using the top principal direction lends to quicker convergence to the underlying manifold compared to using random directions.\nAt each node of the PD-tree we store the mean and top k principal directions of the data that belongs to the node. We use this tree as a means of denoising TDOAs. For a given TDOA vector, find the corresponding leaf node it belongs to and then project it onto the affine space spanned by the top k eigenvectors stored in that leaf node. This is effectively a projection onto the manifold where the manifold is modeled piecewise by PCAs of local neighborhoods."}, {"heading": "4 Particle Filters & Normal Hedge", "text": "In this section we briefly describe a standard particle filtering algorithm as it relates to the TDOA tracking problem. We then introduce a new particle filtering algorithm with a new weighting and particle resampling scheme based on results from online learning."}, {"heading": "4.1 Particle Filtering Framework", "text": "Particle filtering is an approximation technique used to solve the Bayesian filtering problem for state space tracking first proposed in [9]. For TDOA tracking, the state space Xt is composed of each of the D time delays. A weighting overm particles is chosen to approximate the posterior density at time t over this state space. A good tutorial discussing particle filtering and its many variants can be found in [1].\nOne popular variant is the sampling importance resampling (SIR) particle filter. We examine this filter for our purposes since it has been shown to work well for audio tracking when a coordinate system is known\nAlgorithm 1 SIR Particle Filter for TDOA Tracking\nInitial Assumptions: At time t-1, we have the following:\n1. Set of m particles X it\u22121 for i \u2208 {1, . . . ,m}.\n2. A collection of PHAT correlation observations at time t Rt(\u03c4) for each pair of microphones.\n3. Each particle\u2019s weight wit\u22121, a discrete representation of the posterior Pr(Xt\u22121|R1:t\u22121).\n4. A likelihood function L(Rt, Xt) \u221d Pr(Rt|Xt).\n5. A resampling variance parameter \u03a3r\n1: Resampling: Resample m new particles and add independent Gaussian noise\nX it = X\u0303 i t + ni\nwhere X\u0303 it is drawn according to {wt\u22121} from the set of particles at t\u2212 1 and ni \u223c N(0,\u03a3r). 2: Weight Update: Assign each particle a likelihood weight according to\nwit = L(R p t , X i t)\nNormalize weights so that they sum to 1. 3: Prediction: Predict state according to the\nweighted average\nm \u2211\ni=1\nwitX i t\nand can be used for the state representation [13, 11]. A single iteration of such a SIR particle filtering algorithm for the TDOA tracking problem is given in Algorithm 1. At each time step the algorithm goes through a resampling, a prediction and an update stage. The key decisions for optimizing the performance of this TDOA tracking algorithm are:\n1. The choice of L(Rt, Xt), the likelihood function of the observation given the state. For a given state Xt the likelihood function measures how likely it is to have observed the PHAT correlation Rt. This function should be chosen so that the likelihood function is largest when the coordinates of state Xt is nearby many of the peaks in each of the corresponding Rt. However, modeling the true likelihood of the PHAT observation given the state is problematic since it is affected by issues such as line noise and multipath reflections. This makes accurately modeling this likelihood rather challenging, and instead a pseudo-\nlikelihood is employed.\n2. The total number of particles m. The larger m is the more computational load the system must undertake. Minimizing m while not sacrificing performance is of paramount importance for real time implementations.\n3. The covariance of the resampling noise, \u03a3r. We assume a very simple model for the state space in what follows, namely that sound sources do not move too quickly. We should choose the size of \u03a3r to match how quickly we expect sound sources to be moving. More expressive state spaces that take into account the velocity or higher order moments of each TDOA coordinate are not explored in this work.\nWe integrate the manifold modeling discussed in the previous section at the resampling stage. That is, after resampling a new particle it can be denoised by projecting it through the trained tree model. This will disallow particles to drift off into regions where TDOAs can not be created by true sound sources."}, {"heading": "4.2 Normal Hedge Particle Filtering", "text": "To discuss the differences between the SIR particle filter and the normal hedge version we must first introduce some terminology from the online learning body of literature. Normal hedge is an online learning algorithm that attempts to learn how to combine predictions from experts at each time step so as to compete with the predictions of the best set of experts in the collection.\nThe algorithm maintains a distribution over the experts wit. At each time step each expert suffers a bounded loss \u2113it which is a function of the observation and the experts prediction at time t, typically squared, absolute or log-loss. Finally, the algorithm suffers the loss \u2211\ni w i t\u2113 i t. The cumulative loss at time\nt for expert i is then Lit = \u2211t i=1 \u2113 i t (cumulative loss for the algorithm, LAt is similar). Often the goal of an online learning algorithm is to maintain a distribution such that LAt is small relative to that of the best expert in the set, mini L i t. Instead of competing with the best expert in hindsight, normal hedge attempts to compete with the top \u01eb-quantile of Lit. This setting is useful when the number of experts is very large and it is expected that many of the experts will perform very similarly.\nA key concept in online learning is the regret at time t of the algorithm RAt = L A t \u2212 L i t to a particular expert i. The theoretical guarantee of normal hedge is that the algorithm\u2019s regret at time t to the \u230a\u01ebN\u230b-best expert is small. This is not as strong as the regret to the\nAlgorithm 2 NH Particle Filter for TDOA Tracking\nInitial Assumptions: At time t-1, we have the following:\n1. Set of m particles X it\u22121 for i \u2208 {1, . . . ,m}.\n2. A collection of PHAT correlation observations at time t Rt(\u03c4) for each pair of microphones.\n3. Each particle\u2019s weight wit\u22121.\n4. A scoring function L for how well Xt matches the observation Rt.\n5. A resampling variance parameter \u03a3r\n1: Weight Update: Update the discounted cumulative regret of each particle and each particle\u2019s weight using (3)\u2013(6). Normalize weights so that they sum to 1. 2: Prediction: Predict the state according to the weighted average.\nm \u2211\ni=1\nwitX i t\n3: Resampling: For each particle with zero weight, resample a new particle\nX it = X\u0303 i t + ni\nwhere X\u0303 it is drawn according to {wt\u22121} from the set of particles at t \u2212 1 and ni \u223c N(0,\u03a3r). Also, reassign the cumulative regret to be the same as that of X\u0303 it .\nbest expert in hindsight being small, but is very applicable when an \u01eb fraction of experts in fact predict well. We will exploit this fact in our tracking problem. In addition, unlike many other online learning algorithms which have a learning rate parameter that controls how aggressive the wit updates are made, normal hedge has no such parameter to tune. A detailed explanation of normal hedge in the online setting can be found in [2].\nNormal hedge is easily adapted to the problem of tracking with particle filters. Here the experts predict a state at each time step, exactly the same as what a particle does in SIR particle filtering. At each time step the experts suffer a loss which is based on the same likelihood function L(Rt, Xt) as discussed for particle filters. Instead of calculating the cumulative loss of each expert, we maintain the discounted cumulative regret.\nGit = (1 \u2212 \u03b1)G i t\u22121 + (L(Rt, X i t\u22121)\u2212 g A t ) (3)\ngAt =\nm \u2211\ni=1\nwit\u22121L(Rt, X i t\u22121) (4)\nWhere L is the likelihood scoring function used in the generic particle filtering algorithm, gAt is the weighted likelihood of all the particles, and \u03b1 is the discounting factor. The second term in (3) is the instantaneous regret between the algorithm and the ith expert. The choice of \u03b1 determines how long the memory is for the discounted cumulative regret, which determines how far back a particle must suffer for mistakes in the past. Given Git for each particle, we use the normal hedge weighting update to determine each particle\u2019s weight.\nwit = [Git]+ ct exp ([Git]+) 2 2ct (5)\n[A]+ denotes max(A, 0) and ct is the solution to\n1\nm\nm \u2211\ni=1\nexp ([Git]+) 2\n2ct = e (6)\nwhere e is Euler\u2019s number. Note that the weighting is very aggressive since it is doubly exponential in Git. A more in depth discussion of the normal hedge particle filter can be found in [3]. An instantiation of such an algorithm for the TDOA tracking problem is given in Algorithm 2.\nThere are a few things to note about this algorithm. First, the resampling scheme for particles is built into the normal hedge framework since particles get assigned zero weight when they have a non-positive discounted cumulative regret. Therefore, when an iteration occurs where a particle is found to have weight zero, a resampling step is undertaken that replaces it near a particle that currently is performing better than the algorithm\u2019s cumulative regret. This leads to a very natural resampling scheme that undergoes much less sampling per iteration than the SIR particle filter which resamples every particle every iteration.\nThe second thing to note is that there are no probabilistic assumptions about L. The only requirement is that the user provide a scoring function, denoted L by which the particles are judged by, but unlike SIR particle filters it need not be an accurate representation of the true likelihood. The introduction of a scoring function to which performance can be guaranteed makes for a strong match with practical considerations."}, {"heading": "4.3 Choice of Scoring Function", "text": "What remains to be discussed is how we define our likelihood (scoring) function L. It is difficult to accurately define the likelihood of an observation of a\ngroup of PHAT correlations given a particular state. Instead, we define a pseudo-likelihood, L. We\u2019d like L to be large when the state is near large peaks in the PHAT correlations series. Moreover, we would like to encourage the particles to track these peaks over time, so they should be attracted in the direction of these peaks as well.\nTo identify the peaks in a particular PHAT function we take a simple z-scoring method. For each PHAT correlation Rpt let it undergo a z-scoring transform as follows:\nZ p t (\u03c4) =\n[ R p t (\u03c4) \u2212 \u00b5 p t\n\u03c3 p t\n\u2212 C\n]\n+\n(7)\nwhere \u00b5pt , \u03c3 p t are the mean and standard deviation of R p t over a fixed bounded range of \u03c4 , and C is a constant requiring that peaks be at least C standard deviations above the mean. This performs well to find a fixed small number, Kpt of peaks in each R p t since PHAT sequences typically have a small number of very large peaks relative to the rest of the series. Now we define a pseudo-likelihood function as follows:\nL(Zt, Xt) = Z0 + D \u2211\np=1\nK p\nt \u2211\nl=1\nZ p t (\u03c4 p l )N (\u03c4 p l ;X p t , \u03c3 2 z) (8)\nwhere Xpt is the TDOA for pair p for this state, N (x;\u00b5, \u03c32) is the density under a normal distribution evaluated at x with mean \u00b5 and variance \u03c32, and Zpt has Kpt non-zero entries each of which are at \u03c4 p l . The parameter Z0 is the background likelihood that determines how much likelihood is given to any state. The variance parameter \u03c32z controls how much weighting is given relative to how far each state is from the peaks in the corresponding PHAT series. A similar pseudolikelihood function is given in [13]."}, {"heading": "4.4 Integrating the Manifold Model", "text": "The manifold modeling from Section 3 is integrated into both particle filtering algorithms very easily after the resampling stage. A final step is added after resampling a particle to denoise it so that it lies on the model of the manifold. The leaf node in the PD-tree that corresponds to the state of the particle is found. To denoise it, the particle is then projected onto the affine space spanned by the top k PCA components stored in this leaf.\nIn the experiments that follow we explore several manifold models:\n1. No manifold modeling: no projection is performed after the resampling step.\n2. Fixed depth manifold modeling: We grow\neach PD-tree to a fixed depth and use the leaf nodes at this depth as the manifold model.\n3. Randomized manifold modeling: We grow the tree to a fixed depth and we examine the path from root to leaf node the particle takes in the PD-tree. We then choose one of the nodes along this path uniformly at random to be the node which we use for the projection. We hope this randomized model has the ability to adapt over time to which levels of the tree are currently best at modeling the position of the sound source being tracked."}, {"heading": "5 Experiments", "text": ""}, {"heading": "5.1 Experimental Setup", "text": "Recordings were made at 16 kHz on a 7 microphone array that is part of an interactive display placed in a large public lobby. The room is approximately 10m x 13m x 5m in size. Four of the microphones are placed at the corners of the display which is mounted on one of the walls in the room, and the three remaining microphones are placed on the ceiling of the room. For more details of the microphone setup and the room see [4, 7].\nTo build a PD-tree we first collected a training set of TDOA vectors from our microphone array. We accomplished this by moving a white noise producing sound source around the room near typical locations that sitting or standing people would be interacting with the display. This resulted in approximately 20000 training TDOA vectors to which we built a PD-tree of depth 2. In each node of the PD-tree we store the mean of the training data and the top k=3 principal directions.\nHere are the parameter settings we use for the experiments that follow. We use m=50 particles for each type of particle filter examined. Our frame size is 500 ms with an overlap of 25 ms. We set \u03a3r = 4\nr ID, where\nr is the sampling rate. The discounting factor for NH is set to \u03b1 = 0.05, and the parameters of Equation (8) are \u03c32z = 10 and Z0 = 1.\nWe made several real audio recordings of a person walking throughout the room facing the array and talking. We describe each experiment in detail in what follows."}, {"heading": "5.2 Usage of Manifold Modeling", "text": "This first experiment has a person walking and counting aloud while facing the array. The person\u2019s path goes through the center of the room far from each microphone. Since TDOAs evolve more slowly when the sound source is far from each microphone we\u2019d expect this to be well modeled by the root PCA of our PDtree. Here we compare using the root PCA of our PD-tree versus no projection step at all for both SIR particle filters (PF) and the normal hedge particle filters (NH).\nFigure 2 depicts such a comparison. Here we show tracking results from two microphone pairs that are typical of the remaining pairs. In green is shown Zpt where its magnitude is represented by the size of the circle marker. The sound source moved in a continuous and slowly moving path so we\u2019d expect each TDOA coordinate to follow a continuous and slowly changing path as well. The trackers with the PCA projection step are able to follow the sound source, while the versions without the projection lose the source quickly.\nRemember that there are only 50 particles to track a\nstate that is 21 dimensional. There are no dynamics involved in our particle filters, so the resampling stage alone has to include enough randomness for the source to be tracked as it moves. When the manifold model is not used the amount of randomness needed is to large for 50 particles to be able to track on all D dimensions. However, when a model of the manifold is used effective tracking results can be had. Moreover, it should be noted that the normal hedge version uses less randomness since it only resamples when the weight of a particle becomes zero. Despite this, the normal hedge versions are able to have a competitive performance with SIR particle filters with much less randomness being used."}, {"heading": "5.3 Testing Different Manifold Models", "text": "The setup of this experiment is exactly the same as the last except the path the speaker took traveled much closer to some pairs of microphones at certain points in time. When a sound source is moving close to some set of microphones, the TDOAs involved with those microphones will change much more rapidly and in a much more non-linear way. With this path we hope to examine the usefulness of deeper nodes in the PD-tree. Since the performance of PF and NH are comparable when using the global PCA projection we only examine NH in this experiment.\nFigure 3 is a similar figure to that discussed in the previous section. The particle filtering variants examined here use projections at fixed depth zero (NH-0), one (NH-1), and two (NH-2). The random strategy discussed in Section 4.4 is also examined (NH-rand). It is clear that somewhere between 50-70s. the location of the sound source is modeled poorly by the global PCA at the root and is better modeled by the PCA\nat level 2. However, it is only for this short duration where this modeling transition takes place. Depth\u2019s 0 and 1 performed particularly poorly in this region, while depth 2 seems to have a significant advantage.\nHowever, the best performing tracker was one that utilized the entire tree structure in a random fashion. By allowing particles to die and birth randomly, there was a clear pressure to transition from a depth-0 model to a depth-2 model rather quickly by NH-rand. This can be seen in Figure 4. Here we depict what proportion of the 50 particles at time t were last sampled from which depth by a stacked bar graph. There is a clear preference for transitioning towards depth-2 at this particular time period. Nearly all the particles during this time period that were sampled from depth-2 are staying alive during this period.\nThis is a rather intuitive result since a particular node\u2019s PCA model may only be good for tracking in a small region of the entire 21 dimensional space that its PD-tree node represents. When the sound source exits this region, some other depth in the tree may become a better model. Using the randomness over time by NH-rand naturally captures such transitions.\nFigure 5 shows a sound source moving at constant speed a back-and-forth sweeping path. Each sweep starts beyond one side of the display and continues across and past the opposite end of the display. This is repeated at various distances away from the display. The TDOA vectors predicted by NH-rand are projected on the top 2 principal components of the root PCA. Colors indicate time, dark blue being the earliest part of the path that started approximately 1m from the display and red is the last segment of the path approximately 12m away. The change in TDOAs is greatest when near the microphones on the display\nwhich results in a wide spacing of points. The markers indicate which of the 3 depths the majority of the NH-rand particles were last sampled from. In the center of the room its clear that the root-PCA performs best, whereas near the display on the right side depth 2 dominates, and far from the display depth 1 is best."}, {"heading": "6 Conclusion", "text": "In this work we examine particle filtering methods for tracking the TDOA vectors for moving sound sources. This is an essential problem to solve for audio localization and sound enhancement applications. We present a model of the manifold based on space partitioning trees that alleviates the problem of high dimensional tracking with particle filters. We also present a new version of a particle filter based on results from online learning that is competitive with traditional particle filters on this task and has properties that are attractive to many real world problems."}], "references": [{"title": "A tutorial on particle filters for online nonlinear/non-Gaussian Bayesian tracking", "author": ["M. Arulampalam", "S. Maskell", "N. Gordon", "T. Clapp"], "venue": "IEEE Transactions on signal processing,", "citeRegEx": "1", "shortCiteRegEx": "1", "year": 2002}, {"title": "A parameterfree hedging algorithm", "author": ["K. Chaudhuri", "Y. Freund", "D. Hsu"], "venue": "In Advances in Neural Information Processing Systems", "citeRegEx": "2", "shortCiteRegEx": "2", "year": 2009}, {"title": "Tracking using explanation-based modeling", "author": ["K. Chaudhuri", "Y. Freund", "D. Hsu"], "venue": "Technical report, UC San Diego,", "citeRegEx": "3", "shortCiteRegEx": "3", "year": 2009}, {"title": "Detecting, tracking and interacting", "author": ["S. Cheamanunkul", "E. Ettinger", "M. Jacobsen", "P. Lai", "Y. Freund"], "venue": "Proceedings of the 2009 international conference on Multimodal interfaces,", "citeRegEx": "4", "shortCiteRegEx": "4", "year": 2009}, {"title": "Random projection trees for vector quantization", "author": ["S. Dasgupta", "Y. Freund"], "venue": "Information Theory, IEEE Transactions on,", "citeRegEx": "5", "shortCiteRegEx": "5", "year": 2009}, {"title": "Robust localization in reverberant rooms. In Microphone arrays: signal processing techniques and applications, page", "author": ["J. DiBiase", "H. Silverman", "M. Brandstein"], "venue": null, "citeRegEx": "6", "shortCiteRegEx": "6", "year": 2001}, {"title": "Coordinate-free calibration of an acoustically driven camera pointing system", "author": ["E. Ettinger", "Y. Freund"], "venue": "In Distributed Smart Cameras,", "citeRegEx": "7", "shortCiteRegEx": "7", "year": 2008}, {"title": "Learning the structure of manifolds using random projections", "author": ["Y. Freund", "S. Dasgupta", "M. Kabra", "N. Verma"], "venue": "In Advances in Neural Information Processing Systems", "citeRegEx": "8", "shortCiteRegEx": "8", "year": 2007}, {"title": "Novel approach to nonlinear/non-Gaussian Bayesian state estimation", "author": ["N. Gordon", "D. Salmond", "A. Smith"], "venue": "IEE proceedings. Part F. Radar and signal processing,", "citeRegEx": "9", "shortCiteRegEx": "9", "year": 1993}, {"title": "Escaping the curse of dimensionality with a tree-based regressor", "author": ["S. Kpotufe"], "venue": "In COLT \u201909: Proceedings of the 22nd annual workshop on computational learning theory,", "citeRegEx": "10", "shortCiteRegEx": "10", "year": 2009}, {"title": "Particle filter with integrated voice activity detection for acoustic source tracking", "author": ["E. Lehmann", "A. Johansson"], "venue": "EURASIP J. Appl. Signal Process.,", "citeRegEx": "11", "shortCiteRegEx": "11", "year": 2007}, {"title": "Which spatial partition trees are adaptive to intrinsic dimension", "author": ["N. Verma", "S. Kpotufe", "S. Dasgupta"], "venue": "In The 25th Conference on Uncertainty in Artificial Intelligence", "citeRegEx": "12", "shortCiteRegEx": "12", "year": 2009}, {"title": "Particle filtering algorithms for tracking an acoustic source in a reverberant environment", "author": ["D. Ward", "E. Lehmann", "R. Williamson"], "venue": "IEEE Transactions on Speech and Audio Processing,", "citeRegEx": "13", "shortCiteRegEx": "13", "year": 2003}], "referenceMentions": [{"referenceID": 4, "context": "Our manifold model is based off of work on modeling low dimensional manifolds via random projection trees [5].", "startOffset": 106, "endOffset": 109}, {"referenceID": 5, "context": "If microphone positions are given, the second step becomes approximately solving a set of non-linear physical equations such as in [6].", "startOffset": 131, "endOffset": 134}, {"referenceID": 6, "context": "If the positions are not known, then a regressor can be learned that maps TDOAs to camera pointing directives as in [7, 4].", "startOffset": 116, "endOffset": 122}, {"referenceID": 3, "context": "If the positions are not known, then a regressor can be learned that maps TDOAs to camera pointing directives as in [7, 4].", "startOffset": 116, "endOffset": 122}, {"referenceID": 12, "context": "There is an extensive literature on using particle filters for tracking audio sources when the microphone positions are known [13, 11].", "startOffset": 126, "endOffset": 134}, {"referenceID": 10, "context": "There is an extensive literature on using particle filters for tracking audio sources when the microphone positions are known [13, 11].", "startOffset": 126, "endOffset": 134}, {"referenceID": 4, "context": "Our tree structure is based on work on random projection trees, which have been shown to adapt to low dimensional intrinsic structure when the data itself lies in a high dimensional space [5].", "startOffset": 188, "endOffset": 191}, {"referenceID": 1, "context": "In particular we focus on work from combining expert advice via the normal hedge algorithm [2].", "startOffset": 91, "endOffset": 94}, {"referenceID": 2, "context": "Using normal hedge in the particle filtering framework has been initially explored in [3].", "startOffset": 86, "endOffset": 89}, {"referenceID": 12, "context": "One very popular method for estimating a TDOA given frames of audio from a pair of microphones is to use a generalized correlation technique such as the phase transform otherwise known as PHAT [13].", "startOffset": 193, "endOffset": 197}, {"referenceID": 4, "context": "Our model is based off of the random projection tree spatial partitioning algorithm whose details can be found in [5].", "startOffset": 114, "endOffset": 117}, {"referenceID": 9, "context": "RP-trees have been effectively used as a means for vector quantization and for regression problems when the data has much lower intrinsic dimensionality than it\u2019s ambient dimension[10, 8].", "startOffset": 180, "endOffset": 187}, {"referenceID": 7, "context": "RP-trees have been effectively used as a means for vector quantization and for regression problems when the data has much lower intrinsic dimensionality than it\u2019s ambient dimension[10, 8].", "startOffset": 180, "endOffset": 187}, {"referenceID": 3, "context": "Another way to collect such a training set is from interactions by people with an interactive display as in [4].", "startOffset": 108, "endOffset": 111}, {"referenceID": 11, "context": "We call this tree a PD-tree and it has been shown empirically that these trees adapt to intrinsic dimensionality well in practice [12].", "startOffset": 130, "endOffset": 134}, {"referenceID": 8, "context": "Particle filtering is an approximation technique used to solve the Bayesian filtering problem for state space tracking first proposed in [9].", "startOffset": 137, "endOffset": 140}, {"referenceID": 0, "context": "A good tutorial discussing particle filtering and its many variants can be found in [1].", "startOffset": 84, "endOffset": 87}, {"referenceID": 12, "context": "and can be used for the state representation [13, 11].", "startOffset": 45, "endOffset": 53}, {"referenceID": 10, "context": "and can be used for the state representation [13, 11].", "startOffset": 45, "endOffset": 53}, {"referenceID": 1, "context": "A detailed explanation of normal hedge in the online setting can be found in [2].", "startOffset": 77, "endOffset": 80}, {"referenceID": 2, "context": "A more in depth discussion of the normal hedge particle filter can be found in [3].", "startOffset": 79, "endOffset": 82}, {"referenceID": 12, "context": "A similar pseudolikelihood function is given in [13].", "startOffset": 48, "endOffset": 52}, {"referenceID": 3, "context": "For more details of the microphone setup and the room see [4, 7].", "startOffset": 58, "endOffset": 64}, {"referenceID": 6, "context": "For more details of the microphone setup and the room see [4, 7].", "startOffset": 58, "endOffset": 64}], "year": 2013, "abstractText": "We present a novel particle filtering algorithm for tracking a moving sound source using a microphone array. If there are N microphones in the array, we track all ( N", "creator": "LaTeX with hyperref package"}}}