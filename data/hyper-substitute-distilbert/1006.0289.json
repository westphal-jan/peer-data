{"id": "1006.0289", "review": {"conference": "arxiv", "VERSION": "v1", "DATE_OF_SUBMISSION": "2-Jun-2010", "title": "M\\'{e}todos para la Selecci\\'{o}n y el Ajuste de Caracter\\'{i}sticas en el Problema de la Detecci\\'{o}n de Spam", "abstract": "it seems suspected daily receives millions more clicks to communicate against the marketplace : is a mission - critical concern for infected businesses. over the last decade, sophisticated fake email filters become overwhelmingly major problem for email users. an overwhelming concern is spam is flowing into users'mailboxes daily. in 2004, a estimated 25 % among all attack was attributed to spam. not just recognizes spam used? most anonymous employees, it strains the trusted infrastructure beyond organizations and retains another billions monthly dollars in lost productivity. in recent 2000s, encryption has evolved from an item posing a persistent content threat, and ranks potentially a dominant medium with phishing of sensitive information, as ever the deliberately spread malicious software. therefore we propose this algorithm better approaches a competitor as one of its weaknesses. our proposal does not include website development given a classifier specifically, instead deliberately proposing it plans an adjustment in the vulnerability training set aside in order to limit their performance.", "histories": [["v1", "Wed, 2 Jun 2010 03:48:49 GMT  (198kb)", "http://arxiv.org/abs/1006.0289v1", "5 pages, 1 figure, Workshop de Investigadores en Ciencias de la Computaci\\'{o}n, WICC 2010, pp 48-52"], ["v2", "Thu, 14 Oct 2010 15:43:13 GMT  (74kb)", "http://arxiv.org/abs/1006.0289v2", "5 pages, 1 figure, Workshop de Investigadores en Ciencias de la Computaci\\'{o}n, WICC 2010, pp 48-52"]], "COMMENTS": "5 pages, 1 figure, Workshop de Investigadores en Ciencias de la Computaci\\'{o}n, WICC 2010, pp 48-52", "reviews": [], "SUBJECTS": "cs.IR cs.AI", "authors": ["carlos m lorenzetti", "roc\\'io l cecchini", "ana g maguitman", "andr\\'as a bencz\\'ur"], "accepted": false, "id": "1006.0289"}, "pdf": {"name": "1006.0289.pdf", "metadata": {"source": "CRF", "title": "Me\u0301todos para la Seleccio\u0301n y el Ajuste de Caracter\u0131\u0301sticas en el Problema de la Deteccio\u0301n de Spam", "authors": ["Carlos M. Lorenzetti", "Roc\u0131\u0301o L. Cecchini", "Ana G. Maguitman", "Andr\u00e1s A. Bencz\u00far"], "emails": ["cml@cs.uns.edu.ar", "rlc@cs.uns.edu.ar", "agm@cs.uns.edu.ar", "benczur@ilab.sztaki.hu"], "sections": [{"heading": null, "text": "Me\u0301todos para la Seleccio\u0301n y el Ajuste de Caracter\u0131\u0301sticas en el Problema de la Deteccio\u0301n de Spam\nCarlos M. Lorenzetti\u2020\u00a7 Roc\u0131\u0301o L. Cecchini\u2020\u2217 Ana G. Maguitman\u2020\u00a7 Andra\u0301s A. Benczu\u0301r\u2021 \u00a7Laboratorio de Inv. y Des. en Inteligencia Artificial \u2217Laboratorio de Inv. y Des. en Computacio\u0301n Cient\u0131\u0301fica\n\u2020Departamento de Cs. e Ing. de la Computacio\u0301n \u2013 Universidad Nacional del Sur {cml,rlc,agm}@cs.uns.edu.ar\n\u2021Data Mining and Web search Research Group \u2013 Informatics Laboratory Computer and Automation Research Institute \u2013 Hungarian Academy of Sciences\nbenczur@ilab.sztaki.hu\n1. INTRODUCCIO\u0301N\nEl correo electro\u0301nico es quiza\u0301s la aplicacio\u0301n que ma\u0301s tra\u0301fico genera en la Internet. Es utilizado por millones de personas para comunicarse alrededor del mundo y es una aplicacio\u0301n de misio\u0301n cr\u0131\u0301tica para muchos negocios. En la u\u0301ltima de\u0301cada la avalancha de correo no deseado (Spam) ha sido el mayor problema para los usuarios del correo electro\u0301nico, ya que diariamente una cantidad arrolladora de spam entra en las bandejas de los usuarios. En 2004, se estimo\u0301 que el 62 % de todos los correos que se generaron fueron spam [2]. El spam no solo es frustrante para muchos usuarios, sino que tambie\u0301n compromete a la infraestructura tecnolo\u0301gica de las empresas, costando dinero a causa de la pe\u0301rdida de productividad. En los u\u0301ltimos an\u0303os, el spam ha evolucionado desde ser una molestia a ser un serio riesgo en la seguridad, llegando a ser el principal medio para el robo de informacio\u0301n personal, as\u0131\u0301 como tambie\u0301n para la proliferacio\u0301n de software malicioso.\nMuchas alternativas se han propuesto para solucionar el problema, desde protocolos de autenticacio\u0301n del remitente a, incluso, cobrarles dinero a los remitentes [10]. Otra alternativa prometedora es el uso de filtros basados en contenido capaces de discriminar automa\u0301ticamente entre mensajes spam y mensajes leg\u0131\u0301timos. Los me\u0301todos de Aprendizaje Automatizado son atractivos para realizar esta tarea ya que son capaces de adaptarse a las caracter\u0131\u0301sticas evolutivas del spam, conta\u0301ndose adema\u0301s con dis-\nponibilidad de datos para entrenar tales modelos. Sin embargo, uno de los aspectos ma\u0301s frustrantes del spam es que cambia continuamente para adaptarse a las nuevas te\u0301cnicas que intentan detenerlo. Cada vez que se lo ataca de alguna manera, los generadores de spam encuentran una manera de eludir este ataque. Esta carrera ha llevado a una coevolucio\u0301n continua y a un aumento del nivel de sofisticacio\u0301n de ambas partes [10]. Otra diferencia con respecto a muchas tareas en la clasificacio\u0301n de texto consiste en que el costo de un error en la clasificacio\u0301n esta\u0301 fuertemente sesgado: etiquetar un correo leg\u0131\u0301timo como spam, usualmente llamado falso positivo, trae peores consecuencias que el caso inverso.\nLa deteccio\u0301n de spam web puede verse como un problema de clasificacio\u0301n. Para detectar pa\u0301ginas web spam, construimos un clasificador para etiquetar una dada pa\u0301gina como spam o como no spam. Centra\u0301ndonos en el ana\u0301lisis del contenido sema\u0301ntico de los correos y de las pa\u0301ginas, se han estudiado varias te\u0301cnicas de clasificacio\u0301n de texto basadas en me\u0301todos de Aprendizaje Automatizado y Reconocimiento de Patrones, debido principalmente a su mayor capacidad de generalizacio\u0301n. Las te\u0301cnicas de clasificacio\u0301n de texto (ver [25], para una revisio\u0301n detallada) se aplican ba\u0301sicamente a documentos de texto representados en formato ASCII no estructurado, en formatos estructurados como HTML y tambie\u0301n se aplican a mensajes de correo electro\u0301nico.\nEl proceso de clasificacio\u0301n comienza en la\n48WICC 2010 - XII Workshop de Investigadores en Ciencias de la Computaci\u00f3n\nfase de entrenamiento y necesita representar el texto plano que contienen los documentos, por esto el primer paso transforma los documentos a alguna representacio\u0301n interna. Luego se construye un vocabulario con todos los te\u0301rminos que se encontraron en los documentos, para luego pasar a una fase de extraccio\u0301n de caracter\u0131\u0301sticas en donde, por lo general, se reduce la cardinalidad de las mismas. Esto se lleva a cabo mediante la eliminacio\u0301n de signos de puntuacio\u0301n y de palabras muy frecuentes, y por el stemming (reduccio\u0301n de las palabras a su palabra ra\u0131\u0301z o stem), con el propo\u0301sito de descartar te\u0301rminos no discriminantes y de reducir el taman\u0303o del vocabulario (y por lo tanto, de la complejidad computacional). Finalmente se representa el documento como un vector de longitud fija de caracter\u0131\u0301sticas, en el cual cada componente (usualmente un nu\u0301mero real) esta\u0301 asociado a un te\u0301rmino del vocabulario. Los te\u0301rminos usualmente corresponden a palabras individuales, o a frases que se encuentran en los documentos de entrenamiento. Las te\u0301cnicas de extraccio\u0301n de caracter\u0131\u0301sticas ma\u0301s simples esta\u0301n basadas en un me\u0301todo de bolsa de palabras, en donde solo se tienen en cuenta la ocurrencia de los te\u0301rminos y se descarta la informacio\u0301n de su posicio\u0301n dentro del documento. Las caracter\u0131\u0301sticas ma\u0301s comunes son la ocurrencia de la palabra (valor booleano), el nu\u0301mero de ocurrencias (valor entero), o su frecuencia relativa a la longitud del documentos (valor real). Una caracter\u0131\u0301stica llamada TFIDF tiene en cuenta el nu\u0301mero de apariciones en el documento y en todos los documentos de entrenamiento.\nLos clasificadores estad\u0131\u0301sticos pueden aplicarse a la representacio\u0301n vectorial de caracter\u0131\u0301sticas. Las principales te\u0301cnicas analizadas hasta hoy en este contexto para el filtrado de spam esta\u0301n basadas en el clasificador de texto Bayes Na\u0131\u0308ve [20] y en los llamados \u201cfiltros Bayesianos\u201d [24, 11]. Dado su rendimiento en tareas de clasificacio\u0301n de texto, tambie\u0301n se ha investigado el uso de clasificadores Ma\u0301quina de Vectores de Soporte (SVM, Support Vector Machine [7, 28]).\n2. LI\u0301NEA DE INVESTIGACIO\u0301N"}, {"heading": "PROPUESTA", "text": "Como se dijo en la seccio\u0301n previa, la identificacio\u0301n de spam puede verse como un problema de clasificacio\u0301n. Por lo tanto proponemos un algoritmo que utiliza un clasificador como uno de sus componentes. Nuestra propuesta no incluye el desarrollo de un clasificador en s\u0131\u0301 mismo, sino que plantea un ajuste en los datos de entrada del conjunto de entrenamiento del clasificador con el objetivo de mejorar su rendimiento. El esquema general del sistema se muestra en la figura 1 y se describe a continuacio\u0301n."}, {"heading": "2.1. Clustering", "text": "Dada la heterogeneidad que posee el spam, no puede asumirse que todo spam se asocia a un u\u0301nico to\u0301pico. Es por esto que proponemos, como primera etapa, la utilizacio\u0301n de un algoritmo de clustering que dividira\u0301 a los documentos en subto\u0301picos ma\u0301s pequen\u0303os esperando con esto una mejora en el rendimiento global del algoritmo. Una lista detallada de los algoritmos disponibles para este propo\u0301sito puede encontrarse en [4]."}, {"heading": "2.2. Descriptores y Discriminadores", "text": "Una vez que los datos de entrada se encuentran agrupados en subto\u0301picos ma\u0301s espec\u0131\u0301ficos, tomamos cada uno de ellos y calculamos los pesos de los te\u0301rminos en ellos como descriptores y discriminadores de estos subto\u0301picos. En [19] proponemos estudiar el poder descriptivo y discriminante de un te\u0301rmino en base a su distribucio\u0301n a trave\u0301s de los to\u0301picos de las pa\u0301ginas recuperadas por un motor de bu\u0301squeda.\nPara distinguir entre descriptores y discriminadores de to\u0301picos argumentamos que buenos descriptores de to\u0301picos pueden encontrarse buscando aquellos te\u0301rminos que aparecen con frecuencia en documentos relacionados con el to\u0301pico deseado. Por otro lado, buenos discriminadores de to\u0301picos pueden hallarse buscando te\u0301rminos que aparecen solo en documentos relacionados con el to\u0301pico deseado. Ambos tipos\n49WICC 2010 - XII Workshop de Investigadores en Ciencias de la Computaci\u00f3n\naaaaaaa aaaaaaa aaaaaaa aaaaaaa aaaaaaa aaaaaaa\naaaa aaaa aaaa aaaa aaaa aaaa\naaaa aaaa aaaa\nFigura 1: Diagrama esquema\u0301tico de la propuesta\nde te\u0301rminos son importantes a la hora de generar consultas. Utilizar te\u0301rminos descriptores del to\u0301pico mejora el problema de los resultados falso negativo porque aparecen frecuentemente en pa\u0301ginas relevantes. De la misma manera, los buenos discriminadores de to\u0301picos ayudan a reducir el problema de los falsos positivos, ya que aparecen principalmente en pa\u0301ginas relevantes.\nEsta etapa da como resultado listas de te\u0301rminos con informacio\u0301n asociada a la importancia de los mismos como descriptores y discriminadores. Dicha informacio\u0301n se utilizara\u0301 para ajustar la matriz de datos de entrenamiento para reflejar de forma ma\u0301s fidedigna los pesos de los te\u0301rminos en los documentos."}, {"heading": "2.3. Clasificador", "text": "Los clasificadores son implementados a partir de un conjunto de instancias o ejemplos previamente etiquetados, en donde cada ejemplo tiene un vector de atributos o caracter\u0131\u0301sticas. En general, en los conjuntos de datos que utilizaremos en nuestras evaluaciones (descriptos en la seccio\u0301n 3) las etiquetas fueron determinadas por personas.\nLa clasificacio\u0301n involucra la creacio\u0301n de un\nmodelo durante la etapa de entrenamiento que predecira\u0301 la etiqueta de cada instancia del conjunto de testeo usando los valores del vector de caracter\u0131\u0301sticas. Para construir el clasificador, primero lo entrenamos sobre un nu\u0301mero de ejemplos del conjunto etiquetado de entrenamiento y determinamos los para\u0301metros de nuestro clasificador. Durante la etapa de testeo, el clasificador examina el vector de caracter\u0131\u0301sticas de forma conjunta para determinar si una pa\u0301gina pertenece a una dada categor\u0131\u0301a o no. La evaluacio\u0301n del clasificador se realiza en la etapa de testeo comparando, para cada instancia, la etiqueta calculada por el clasificador con la asignada a esa instancia.\nUna lista detallada de los algoritmos disponibles para este propo\u0301sito puede encontrarse en [16, 23]. Se preve\u0301 utilizar el entorno Weka [13] en esta etapa.\n3. EVALUACIO\u0301N\nPara la evaluacio\u0301n de nuestra propuesta utilizaremos distintos conjuntos de datos disponibles, como por ejemplo el conjunto de datos UK-2007 del workshop internacional AirWeb [8], el conjunto de datos de la conferen-\n50WICC 2010 - XII Workshop de Investigadores en Ciencias de la Computaci\u00f3n\ncia internacional ECML PKDD [15], el conjunto de datos del track de Spam de la conferencia TREC [5] y el corpus de correos electro\u0301nicos SpamAssassin [26]. Para analizar la eficacia del me\u0301todo propuesto evaluaremos el rendimiento del clasificador. Para ello utilizaremos las me\u0301tricas esta\u0301ndares de evaluacio\u0301n, como precisio\u0301n, cobertura, F-score, Media Geome\u0301trica, a\u0301rea bajo la curva ROC, a\u0301rea bajo la curva Precisio\u0301n-Cobertura y estad\u0131\u0301sticas de KolmogorovSmirnov."}, {"heading": "4. CONCLUSIONES", "text": "La te\u0301cnica propuesta en este trabajo ataca uno de los problemas ma\u0301s grandes a los que se deben enfrentar los usuarios de los sistemas de informacio\u0301n actuales. Mejorar la representacio\u0301n de los documentos mediante el uso de vocabularios ma\u0301s representativos, as\u0131\u0301 como el ajuste de los datos realizado a trave\u0301s de la deteccio\u0301n de buenos descriptores y discriminadores ha mostrado ser efectivo en otras a\u0301reas de recuperacio\u0301n de informacio\u0301n [18, 17]. Anticipamos que aplicar estos me\u0301todos sera\u0301 ventajoso para abordar diversos problemas de clasificacio\u0301n, en particular en el a\u0301mbito de la deteccio\u0301n de spam.\nNuestro trabajo esta\u0301 relacionado con muchos estudios previos sobre clasificacio\u0301n de pa\u0301ginas web spam basados en caracter\u0131\u0301sticas. Desde los comienzos de la World Wide Web ha existido una necesidad de calificar a las pa\u0301ginas de acuerdo a su relevancia con una dada consulta. Sin embargo se ha puesto un nuevo e\u0301nfasis al problema dadas las grandes ganancias que genera la publicidad a trave\u0301s de Internet. La clasificacio\u0301n de spam web es uno de los desaf\u0131\u0301os ma\u0301s importantes de los motores de bu\u0301squeda [14], en particular debido a la degradacio\u0301n de la calidad de sus resultados. Un me\u0301todo prometedor para la identificacio\u0301n del spam web es la utilizacio\u0301n de la informacio\u0301n de los enlaces web que contienen las pa\u0301ginas [6, 1, 3, 12, 27]. Por otro lado recientemente se ha estudiado la clasificacio\u0301n de spam web basa\u0301ndose en el contenido de la pa\u0301gina [22, 9]. La deteccio\u0301n de spam en blogs se estudio\u0301 en [21].\nTodos estos ejemplos son solo los primeros pasos en el combate contra el spam: la naturaleza necesariamente adversaria de la tarea conlleva a un problema que evoluciona ra\u0301pidamente, y esta caracter\u0131\u0301stica (de tener que buscar te\u0301cnicas que sean exitosas a la luz de la adaptacio\u0301n del enemigo) es algo nuevo en la comunidad de Aprendizaje Automatizado y trae consigo numerosos desaf\u0131\u0301os y oportunidades de investigacio\u0301n."}, {"heading": "REFERENCIAS", "text": "[1] E. Amitay, D. Carmel, A. Darlow, R. Lempel, and A. Soffer. The connectivity sonar: detecting site functionality by structural patterns. In HYPERTEXT \u201903: Proceedings of the fourteenth ACM conference on Hypertext and hypermedia, pages 38\u201347, New York, NY, USA, 2003. ACM. [2] I. Androutsopoulos, J. Koutsias, K. Chandrinos, G. Paliouras, and C. D. Spyropoulos. An evaluation of Naive Bayesian anti-spam filtering. In G. Potamias, V. Moustakis, and M. van Someren, editors, Proceedings of the Workshop on Machine Learning in the New Information Age, 11th European Conference on Machine Learning (ECML 2000), pages 9\u201317, Barcelona, Spain, 2000. [3] L. Becchetti, C. Castillo, D. Donato, S. Leonardi, and R. Baeza-Yates. Using rank propagation and probabilistic counting for linkbased spam detection. In Proceedings of the Workshop on Web Mining and Web Usage Analysis (WebKDD), Pennsylvania, USA, August 2006. ACM Press. [4] P. Berkhin. A survey of clustering data mining techniques. In Grouping Multidimensional Data, pages 25\u201371. Springer Berlin Heidelberg, 2006. [5] G. V. Cormack. TREC 2007 Spam Track Overview. In TREC, 2007. [6] B. D. Davison. Recognizing nepotistic links on the Web. In Artificial Intelligence for Web Search, pages 23\u201328, Austin, Texas, USA, July 2000. AAAI Press. [7] H. Drucker, D. Wu, and V. Vapnik. Support vector machines for spam categorization. IEEE Transactions on Neural Networks,\n51WICC 2010 - XII Workshop de Investigadores en Ciencias de la Computaci\u00f3n\n10(5):1048\u20131054, 1999. [8] D. Fetterly and Z. Gyo\u0308ngyi, editors. AIR-\nWeb \u201909: Proceedings of the 5th International Workshop on Adversarial Information Retrieval on the Web, New York, NY, USA, 2009. ACM. [9] D. Fetterly, M. Manasse, and M. Najork. Spam, damn spam, and statistics: using statistical analysis to locate spam web pages. In WebDB \u201904: Proceedings of the 7th International Workshop on the Web and Databases, pages 1\u20136, New York, NY, USA, 2004. ACM. [10] J. Goodman, D. Heckerman, and R. Rounthwaite. Stopping spam. Scientific American, 292(4):42\u201349, April 2005. [11] P. Graham. A Plan for Spam, August 2002. [12] Z. Gyo\u0308ngyi and H. Garcia-Molina. Link spam\nalliances. In K. Bo\u0308hm, C. S. Jensen, L. M. Haas, M. L. Kersten, P.-A\u030a. Larson, and B. C. Ooi, editors, Proceedings of the 31st International Conference on Very Large Data Bases (VLDB), pages 517\u2013528. ACM, 2005.\n[13] M. Hall, E. Frank, G. Holmes, B. Pfahringer, P. Reutemann, and I. H. Witten. The weka data mining software: an update. ACM SIGKDD Explorations Newsletter, 11(1):10\u201318, 2009. [14] M. R. Henzinger, R. Motwani, and C. Silverstein. Challenges in web search engines. In IJCAI\u201903: Proceedings of the 18th International Joint Conference on Artificial Intelligence, pages 1573\u20131579, San Francisco, CA, USA, 2003. Morgan Kaufmann Publishers Inc. [15] A. Hotho, D. Benz, R. Ja\u0308schke, and B. Krause, editors. ECML PKDD Discovery Challenge 2008 (RSDC\u201908). Workshop at 18th European Conference on Machine Learning (ECML\u201908) / 11th European Conference on Principles and Practice of Knowledge Discovery in Databases (PKDD\u201908), 2008. [16] A. K. Jain, M. N. Murty, and P. J. Flynn. Data clustering: a review. ACM Computing Surveys, 31(3):264\u2013323, 1999. [17] C. M. Lorenzetti and A. G. Maguitman. Tuning Topical Queries through Context Vocabulary Enrichment: A Corpus-based approach. In R. Meersman, Z. Tari, and P. Herrero, editors, On the Move to Meaningful Internet Systems: OTM 2008 Workshops, volume 5333 of LNCS, pages 646\u2013655. Springer, 2008. [18] C. M. Lorenzetti and A. G. Maguitman. A semi-supervised incremental algorithm to au-\ntomatically formulate topical queries. Information Sciences, 179(12):1881\u20131892, 2009. Including Special Issue on Web Search.\n[19] A. Maguitman, D. Leake, T. Reichherzer, and F. Menczer. Dynamic Extraction of Topic Descriptors and Discriminators: Towards automatic context-based topic search. In Proceedings of the Thirteenth Conference on Information and Knowledge Management (CIKM), pages 463\u2013472, Washington, DC, November 2004. ACM Press. [20] A. McCallum and K. Nigam. A Comparison of Event Models for Naive Bayes Text Classification. In Learning for Text Categorization: Papers from the 1998 AAAI Workshop, volume 752, pages 41\u201348, 1998. [21] G. Mishne, D. Carmel, and R. Lempel. Blocking Blog Spam with Language Model Disagreement. In Proceedings of the First International Workshop on Adversarial Information Retrieval on the Web (AIRWeb), Chiba, Japan, May 2005. [22] A. Ntoulas, M. Najork, M. Manasse, and D. Fetterly. Detecting spam web pages through content analysis. In WWW \u201906: Proceedings of the 15th International Conference on World Wide Web, pages 83\u201392, New York, NY, USA, 2006. ACM. [23] X. Qi and B. D. Davison. Web page classification: Features and algorithms. ACM Computing Surveys (CSUR), 41(2):1\u201331, 2009. [24] M. Sahami, S. Dumais, D. Heckerman, and E. Horvitz. A bayesian approach to filtering junk E-mail. In Learning for Text Categorization: Papers from the 1998 Workshop, Madison, Wisconsin, 1998. AAAI Technical Report WS-98-05. [25] F. Sebastiani. Machine learning in automated text categorization. ACM Computing Surveys, 34(1):1\u201347, 2002. [26] SpamAssassin. SpamAssassin public corpus, http://spamassassin.apache.org/publiccorpus/. [27] B. Wu and B. D. Davison. Identifying link farm spam pages. In WWW \u201905: Special interest tracks and posters of the 14th International Conference on World Wide Web, pages 820\u2013 829, New York, NY, USA, 2005. ACM Press. [28] L. Zhang, J. Zhu, and T. Yao. An evaluation of statistical spam filtering techniques. ACM Transactions on Asian Language Information Processing (TALIP), 3(4):243\u2013269, 2004.\n52WICC 2010 - XII Workshop de Investigadores en Ciencias de la Computaci\u00f3n"}], "references": [{"title": "The connectivity sonar: detecting site functionality by structural patterns", "author": ["E. Amitay", "D. Carmel", "A. Darlow", "R. Lempel", "A. Soffer"], "venue": "HYPERTEXT \u201903: Proceedings of the fourteenth ACM conference on Hypertext and hypermedia, pages 38\u201347, New York, NY, USA", "citeRegEx": "1", "shortCiteRegEx": null, "year": 2003}, {"title": "An evaluation of Naive Bayesian anti-spam filtering", "author": ["I. Androutsopoulos", "J. Koutsias", "K. Chandrinos", "G. Paliouras", "C.D. Spyropoulos"], "venue": "G. Potamias, V. Moustakis, and M. van Someren, editors, Proceedings of the Workshop on Machine Learning in the New Information Age, 11th European Conference on Machine Learning ", "citeRegEx": "2", "shortCiteRegEx": null, "year": 2000}, {"title": "Using rank propagation and probabilistic counting for linkbased spam detection", "author": ["L. Becchetti", "C. Castillo", "D. Donato", "S. Leonardi", "R. Baeza-Yates"], "venue": "In Proceedings of the Workshop on Web Mining and Web Usage Analysis (WebKDD), Pennsylvania,", "citeRegEx": "3", "shortCiteRegEx": "3", "year": 2006}, {"title": "A survey of clustering data mining techniques", "author": ["P. Berkhin"], "venue": "Grouping Multidimensional Data, pages 25\u201371. Springer Berlin Heidelberg", "citeRegEx": "4", "shortCiteRegEx": null, "year": 2006}, {"title": "TREC 2007 Spam Track Overview", "author": ["G.V. Cormack"], "venue": "TREC", "citeRegEx": "5", "shortCiteRegEx": null, "year": 2007}, {"title": "Recognizing nepotistic links on the Web", "author": ["B.D. Davison"], "venue": "In Artificial Intelligence for Web Search,", "citeRegEx": "6", "shortCiteRegEx": "6", "year": 2000}, {"title": "Support vector machines for spam categorization", "author": ["H. Drucker", "D. Wu", "V. Vapnik"], "venue": "IEEE Transactions on Neural Networks, 51  WICC 2010 - XII Workshop de Investigadores en Ciencias de la Computaci\u00f3n  10(5):1048\u20131054", "citeRegEx": "7", "shortCiteRegEx": null, "year": 1999}, {"title": "editors", "author": ["D. Fetterly", "Z. Gy\u00f6ngyi"], "venue": "AIR- Web \u201909: Proceedings of the 5th International Workshop on Adversarial Information Retrieval on the Web, New York, NY, USA", "citeRegEx": "8", "shortCiteRegEx": null, "year": 2009}, {"title": "Spam", "author": ["D. Fetterly", "M. Manasse", "M. Najork"], "venue": "damn spam, and statistics: using statistical analysis to locate spam web pages. In WebDB \u201904: Proceedings of the 7th International Workshop on the Web and Databases, pages 1\u20136, New York, NY, USA", "citeRegEx": "9", "shortCiteRegEx": null, "year": 2004}, {"title": "A Plan for Spam", "author": ["P. Graham"], "venue": null, "citeRegEx": "11", "shortCiteRegEx": "11", "year": 2002}, {"title": "Link spam alliances", "author": ["Z. Gy\u00f6ngyi", "H. Garcia-Molina"], "venue": "K. B\u00f6hm, C. S. Jensen, L. M. Haas, M. L. Kersten, P.-\u00c5. Larson, and B. C. Ooi, editors, Proceedings of the 31st International Conference on Very Large Data Bases (VLDB), pages 517\u2013528. ACM", "citeRegEx": "12", "shortCiteRegEx": null, "year": 2005}, {"title": "The weka data mining software: an update", "author": ["M. Hall", "E. Frank", "G. Holmes", "B. Pfahringer", "P. Reutemann", "I.H. Witten"], "venue": "ACM SIGKDD Explorations Newsletter, 11(1):10\u201318", "citeRegEx": "13", "shortCiteRegEx": null, "year": 2009}, {"title": "Challenges in web search engines", "author": ["M.R. Henzinger", "R. Motwani", "C. Silverstein"], "venue": "IJCAI\u201903: Proceedings of the 18th International Joint Conference on Artificial Intelligence, pages 1573\u20131579, San Francisco, CA, USA", "citeRegEx": "14", "shortCiteRegEx": null, "year": 2003}, {"title": "editors", "author": ["A. Hotho", "D. Benz", "R. J\u00e4schke", "B. Krause"], "venue": "ECML PKDD Discovery Challenge 2008 (RSDC\u201908). Workshop at 18th European Conference on Machine Learning (ECML\u201908) / 11th European Conference on Principles and Practice of Knowledge Discovery in Databases (PKDD\u201908)", "citeRegEx": "15", "shortCiteRegEx": null, "year": 2008}, {"title": "Data clustering: a review", "author": ["A.K. Jain", "M.N. Murty", "P.J. Flynn"], "venue": "ACM Computing Surveys, 31(3):264\u2013323", "citeRegEx": "16", "shortCiteRegEx": null, "year": 1999}, {"title": "Tuning Topical Queries through Context Vocabulary Enrichment: A Corpus-based approach", "author": ["C.M. Lorenzetti", "A.G. Maguitman"], "venue": "R. Meersman, Z. Tari, and P. Herrero, editors, On the Move to Meaningful Internet Systems: OTM 2008 Workshops, volume 5333 of LNCS, pages 646\u2013655. Springer", "citeRegEx": "17", "shortCiteRegEx": null, "year": 2008}, {"title": "A semi-supervised incremental algorithm to au-  tomatically formulate topical queries", "author": ["C.M. Lorenzetti", "A.G. Maguitman"], "venue": "Information Sciences, 179(12):1881\u20131892", "citeRegEx": "18", "shortCiteRegEx": null, "year": 2009}, {"title": "Dynamic Extraction of Topic Descriptors and Discriminators: Towards automatic context-based topic search", "author": ["A. Maguitman", "D. Leake", "T. Reichherzer", "F. Menczer"], "venue": "In Proceedings of the Thirteenth Conference on Information and Knowledge Management (CIKM),", "citeRegEx": "19", "shortCiteRegEx": "19", "year": 2004}, {"title": "A Comparison of Event Models for Naive Bayes Text Classification", "author": ["A. McCallum", "K. Nigam"], "venue": "Learning for Text Categorization: Papers from the 1998 AAAI Workshop, volume 752, pages 41\u201348", "citeRegEx": "20", "shortCiteRegEx": null, "year": 1998}, {"title": "Blocking Blog Spam with Language Model Disagreement", "author": ["G. Mishne", "D. Carmel", "R. Lempel"], "venue": "In Proceedings of the First International Workshop on Adversarial Information Retrieval on the Web (AIRWeb),", "citeRegEx": "21", "shortCiteRegEx": "21", "year": 2005}, {"title": "Detecting spam web pages through content analysis", "author": ["A. Ntoulas", "M. Najork", "M. Manasse", "D. Fetterly"], "venue": "WWW \u201906: Proceedings of the 15th International Conference on World Wide Web, pages 83\u201392, New York, NY, USA", "citeRegEx": "22", "shortCiteRegEx": null, "year": 2006}, {"title": "Web page classification: Features and algorithms", "author": ["X. Qi", "B.D. Davison"], "venue": "ACM Computing Surveys (CSUR), 41(2):1\u201331", "citeRegEx": "23", "shortCiteRegEx": null, "year": 2009}, {"title": "A bayesian approach to filtering junk E-mail", "author": ["M. Sahami", "S. Dumais", "D. Heckerman", "E. Horvitz"], "venue": "Learning for Text Categorization: Papers from the 1998 Workshop, Madison, Wisconsin", "citeRegEx": "24", "shortCiteRegEx": null, "year": 1998}, {"title": "Machine learning in automated text categorization", "author": ["F. Sebastiani"], "venue": "ACM Computing Surveys, 34(1):1\u201347", "citeRegEx": "25", "shortCiteRegEx": null, "year": 2002}, {"title": "Identifying link farm spam pages", "author": ["B. Wu", "B.D. Davison"], "venue": "WWW \u201905: Special interest tracks and posters of the 14th International Conference on World Wide Web, pages 820\u2013 829, New York, NY, USA", "citeRegEx": "27", "shortCiteRegEx": null, "year": 2005}, {"title": "An evaluation of statistical spam filtering techniques", "author": ["L. Zhang", "J. Zhu", "T. Yao"], "venue": "ACM Transactions on Asian Language Information Processing (TALIP), 3(4):243\u2013269", "citeRegEx": "28", "shortCiteRegEx": null, "year": 2004}], "referenceMentions": [{"referenceID": 1, "context": "En 2004, se estim\u00f3 que el 62 % de todos los correos que se generaron fueron spam [2].", "startOffset": 81, "endOffset": 84}, {"referenceID": 23, "context": "Las t\u00e9cnicas de clasificaci\u00f3n de texto (ver [25], para una revisi\u00f3n detallada) se aplican b\u00e1sicamente a documentos de texto representados en formato ASCII no estructurado, en formatos estructurados como HTML y tambi\u00e9n se aplican a mensajes de correo electr\u00f3nico.", "startOffset": 44, "endOffset": 48}, {"referenceID": 18, "context": "Las principales t\u00e9cnicas analizadas hasta hoy en este contexto para el filtrado de spam est\u00e1n basadas en el clasificador de texto Bayes Na\u0131\u0308ve [20] y en los llamados \u201cfiltros Bayesianos\u201d [24, 11].", "startOffset": 143, "endOffset": 147}, {"referenceID": 22, "context": "Las principales t\u00e9cnicas analizadas hasta hoy en este contexto para el filtrado de spam est\u00e1n basadas en el clasificador de texto Bayes Na\u0131\u0308ve [20] y en los llamados \u201cfiltros Bayesianos\u201d [24, 11].", "startOffset": 187, "endOffset": 195}, {"referenceID": 9, "context": "Las principales t\u00e9cnicas analizadas hasta hoy en este contexto para el filtrado de spam est\u00e1n basadas en el clasificador de texto Bayes Na\u0131\u0308ve [20] y en los llamados \u201cfiltros Bayesianos\u201d [24, 11].", "startOffset": 187, "endOffset": 195}, {"referenceID": 6, "context": "Dado su rendimiento en tareas de clasificaci\u00f3n de texto, tambi\u00e9n se ha investigado el uso de clasificadores M\u00e1quina de Vectores de Soporte (SVM, Support Vector Machine [7, 28]).", "startOffset": 168, "endOffset": 175}, {"referenceID": 25, "context": "Dado su rendimiento en tareas de clasificaci\u00f3n de texto, tambi\u00e9n se ha investigado el uso de clasificadores M\u00e1quina de Vectores de Soporte (SVM, Support Vector Machine [7, 28]).", "startOffset": 168, "endOffset": 175}, {"referenceID": 3, "context": "Una lista detallada de los algoritmos disponibles para este prop\u00f3sito puede encontrarse en [4].", "startOffset": 91, "endOffset": 94}, {"referenceID": 17, "context": "En [19] proponemos estudiar el poder descriptivo y discriminante de un t\u00e9rmino en base a su distribuci\u00f3n a trav\u00e9s de los t\u00f3picos de las p\u00e1ginas recuperadas por un motor de b\u00fasqueda.", "startOffset": 3, "endOffset": 7}, {"referenceID": 14, "context": "Una lista detallada de los algoritmos disponibles para este prop\u00f3sito puede encontrarse en [16, 23].", "startOffset": 91, "endOffset": 99}, {"referenceID": 21, "context": "Una lista detallada de los algoritmos disponibles para este prop\u00f3sito puede encontrarse en [16, 23].", "startOffset": 91, "endOffset": 99}, {"referenceID": 11, "context": "Se prev\u00e9 utilizar el entorno Weka [13] en esta etapa.", "startOffset": 34, "endOffset": 38}, {"referenceID": 7, "context": "Para la evaluaci\u00f3n de nuestra propuesta utilizaremos distintos conjuntos de datos disponibles, como por ejemplo el conjunto de datos UK-2007 del workshop internacional AirWeb [8], el conjunto de datos de la conferen-", "startOffset": 175, "endOffset": 178}, {"referenceID": 13, "context": "cia internacional ECML PKDD [15], el conjunto de datos del track de Spam de la conferencia TREC [5] y el corpus de correos electr\u00f3nicos SpamAssassin [26].", "startOffset": 28, "endOffset": 32}, {"referenceID": 4, "context": "cia internacional ECML PKDD [15], el conjunto de datos del track de Spam de la conferencia TREC [5] y el corpus de correos electr\u00f3nicos SpamAssassin [26].", "startOffset": 96, "endOffset": 99}, {"referenceID": 16, "context": "Mejorar la representaci\u00f3n de los documentos mediante el uso de vocabularios m\u00e1s representativos, as\u0131\u0301 como el ajuste de los datos realizado a trav\u00e9s de la detecci\u00f3n de buenos descriptores y discriminadores ha mostrado ser efectivo en otras \u00e1reas de recuperaci\u00f3n de informaci\u00f3n [18, 17].", "startOffset": 277, "endOffset": 285}, {"referenceID": 15, "context": "Mejorar la representaci\u00f3n de los documentos mediante el uso de vocabularios m\u00e1s representativos, as\u0131\u0301 como el ajuste de los datos realizado a trav\u00e9s de la detecci\u00f3n de buenos descriptores y discriminadores ha mostrado ser efectivo en otras \u00e1reas de recuperaci\u00f3n de informaci\u00f3n [18, 17].", "startOffset": 277, "endOffset": 285}, {"referenceID": 12, "context": "La clasificaci\u00f3n de spam web es uno de los desaf\u0131\u0301os m\u00e1s importantes de los motores de b\u00fasqueda [14], en particular debido a la degradaci\u00f3n de la calidad de sus resultados.", "startOffset": 96, "endOffset": 100}, {"referenceID": 5, "context": "Un m\u00e9todo prometedor para la identificaci\u00f3n del spam web es la utilizaci\u00f3n de la informaci\u00f3n de los enlaces web que contienen las p\u00e1ginas [6, 1, 3, 12, 27].", "startOffset": 138, "endOffset": 155}, {"referenceID": 0, "context": "Un m\u00e9todo prometedor para la identificaci\u00f3n del spam web es la utilizaci\u00f3n de la informaci\u00f3n de los enlaces web que contienen las p\u00e1ginas [6, 1, 3, 12, 27].", "startOffset": 138, "endOffset": 155}, {"referenceID": 2, "context": "Un m\u00e9todo prometedor para la identificaci\u00f3n del spam web es la utilizaci\u00f3n de la informaci\u00f3n de los enlaces web que contienen las p\u00e1ginas [6, 1, 3, 12, 27].", "startOffset": 138, "endOffset": 155}, {"referenceID": 10, "context": "Un m\u00e9todo prometedor para la identificaci\u00f3n del spam web es la utilizaci\u00f3n de la informaci\u00f3n de los enlaces web que contienen las p\u00e1ginas [6, 1, 3, 12, 27].", "startOffset": 138, "endOffset": 155}, {"referenceID": 24, "context": "Un m\u00e9todo prometedor para la identificaci\u00f3n del spam web es la utilizaci\u00f3n de la informaci\u00f3n de los enlaces web que contienen las p\u00e1ginas [6, 1, 3, 12, 27].", "startOffset": 138, "endOffset": 155}, {"referenceID": 20, "context": "Por otro lado recientemente se ha estudiado la clasificaci\u00f3n de spam web bas\u00e1ndose en el contenido de la p\u00e1gina [22, 9].", "startOffset": 112, "endOffset": 119}, {"referenceID": 8, "context": "Por otro lado recientemente se ha estudiado la clasificaci\u00f3n de spam web bas\u00e1ndose en el contenido de la p\u00e1gina [22, 9].", "startOffset": 112, "endOffset": 119}, {"referenceID": 19, "context": "La detecci\u00f3n de spam en blogs se estudi\u00f3 en [21].", "startOffset": 44, "endOffset": 48}, {"referenceID": 0, "context": "[1] E.", "startOffset": 0, "endOffset": 3}, {"referenceID": 1, "context": "[2] I.", "startOffset": 0, "endOffset": 3}, {"referenceID": 2, "context": "[3] L.", "startOffset": 0, "endOffset": 3}, {"referenceID": 3, "context": "[4] P.", "startOffset": 0, "endOffset": 3}, {"referenceID": 4, "context": "[5] G.", "startOffset": 0, "endOffset": 3}, {"referenceID": 5, "context": "[6] B.", "startOffset": 0, "endOffset": 3}, {"referenceID": 6, "context": "[7] H.", "startOffset": 0, "endOffset": 3}, {"referenceID": 7, "context": "[8] D.", "startOffset": 0, "endOffset": 3}, {"referenceID": 8, "context": "[9] D.", "startOffset": 0, "endOffset": 3}, {"referenceID": 9, "context": "[11] P.", "startOffset": 0, "endOffset": 4}, {"referenceID": 10, "context": "[12] Z.", "startOffset": 0, "endOffset": 4}, {"referenceID": 11, "context": "[13] M.", "startOffset": 0, "endOffset": 4}, {"referenceID": 12, "context": "[14] M.", "startOffset": 0, "endOffset": 4}, {"referenceID": 13, "context": "[15] A.", "startOffset": 0, "endOffset": 4}, {"referenceID": 14, "context": "[16] A.", "startOffset": 0, "endOffset": 4}, {"referenceID": 15, "context": "[17] C.", "startOffset": 0, "endOffset": 4}, {"referenceID": 16, "context": "[18] C.", "startOffset": 0, "endOffset": 4}, {"referenceID": 17, "context": "[19] A.", "startOffset": 0, "endOffset": 4}, {"referenceID": 18, "context": "[20] A.", "startOffset": 0, "endOffset": 4}, {"referenceID": 19, "context": "[21] G.", "startOffset": 0, "endOffset": 4}, {"referenceID": 20, "context": "[22] A.", "startOffset": 0, "endOffset": 4}, {"referenceID": 21, "context": "[23] X.", "startOffset": 0, "endOffset": 4}, {"referenceID": 22, "context": "[24] M.", "startOffset": 0, "endOffset": 4}, {"referenceID": 23, "context": "[25] F.", "startOffset": 0, "endOffset": 4}, {"referenceID": 24, "context": "[27] B.", "startOffset": 0, "endOffset": 4}, {"referenceID": 25, "context": "[28] L.", "startOffset": 0, "endOffset": 4}], "year": 2010, "abstractText": "Carlos M. Lorenzetti\u2020\u00a7 Roc\u0131\u0301o L. Cecchini\u2020\u2217 Ana G. Maguitman\u2020\u00a7 Andr\u00e1s A. Bencz\u00far\u2021 \u00a7Laboratorio de Inv. y Des. en Inteligencia Artificial \u2217Laboratorio de Inv. y Des. en Computaci\u00f3n Cient\u0131\u0301fica \u2020Departamento de Cs. e Ing. de la Computaci\u00f3n \u2013 Universidad Nacional del Sur {cml,rlc,agm}@cs.uns.edu.ar \u2021Data Mining and Web search Research Group \u2013 Informatics Laboratory Computer and Automation Research Institute \u2013 Hungarian Academy of Sciences", "creator": null}}}