{"id": "1006.1537", "review": {"conference": "arxiv", "VERSION": "v1", "DATE_OF_SUBMISSION": "8-Jun-2010", "title": "New worst upper bound for #SAT", "abstract": "the recent theoretical techniques of functions for # sat have been proposed in numerical literature. as previously observe, previous algorithms for managing # sat without been analyzed first regarding the probability of variables under the parameter. presently, the exponential complexity for solving # sat has runs once only in the likelihood associated variables, but primarily on the magnitude of clauses. normally, patience is tempting to exploit the narrowing window from the greedy point of view, i. e. the number index labels. in this paper, more present algorithms for solving # 2 - ut \u2013 # 0 - it comprising continuous complexity sequences relating the sum of clauses and the criterion. by competing regression algorithms, we obtain the new worst - evaluated upper bounds o ( 1. 5 ) for # 2 - must and cs ( 31. 4142m ) for # 3 - sat, where m is some number of citations.", "histories": [["v1", "Tue, 8 Jun 2010 11:48:12 GMT  (152kb)", "http://arxiv.org/abs/1006.1537v1", "6 pages; proceedings of AAAI 2010"]], "COMMENTS": "6 pages; proceedings of AAAI 2010", "reviews": [], "SUBJECTS": "cs.AI cs.CC", "authors": ["junping zhou", "minghao yin", "chunguang zhou"], "accepted": false, "id": "1006.1537"}, "pdf": {"name": "1006.1537.pdf", "metadata": {"source": "CRF", "title": "New Worst-Case Upper Bound for #2-SAT and #3-SAT with the Number of Clauses as the Parameter", "authors": ["Junping Zhou", "Minghao Yin", "Chunguang Zhou"], "emails": ["zhoujp08@mails.jlu.edu.cn,", "mhyin@nenu.edu.cn,", "cgzhou@jlu.edu.cn", "mhyin@nenu.edu.cn)"], "sections": [{"heading": null, "text": "Introduction Propositional model counting or #SAT is the problem of computing the number of models for a given propositional formula, i.e., the number of distinct truth assignments to variables for which the formula evaluates to true. Nowadays, efficient model counting algorithms have opened up a range of applications. For example, various probabilistic inference problems can be translated into model counting problems (cf. Park 2002; Sang et al. 2005). #SAT problem can be viewed as a generalization of the well-known canonical NP-complete problem of Propositional Satisfiability (SAT), which has been well studied. Actually, model counting has been proved to be #P-complete, harder than standard SAT problems (Bacchus et al. 2003). Therefore, improvements in exponential time bounds are crucial in determining the size of model counting problem that can be solved. Even a slight *Please correspond the author (Dr. Minghao Yin, mhyin@nenu.edu.cn) for any theoretical problems of this paper. Copyright \u00a9 2010, Association for the Advancement of Artificial Intelligence (www.aaai.org). All rights reserved.\nimprovement from O(ck) to O((c-\u03b5)k) may significantly increase the size of the problem being tractable.\nRecently, tremendous efforts have been made on efficient #SAT algorithms with complexity analyses. By introducing independent clauses and combining formulas, Dubois (1991) presented a #SAT algorithm which ran in O(1.6180n) for #2-SAT and O(1.8393n) for #3-SAT, where n is the number of variables of a formula. Based on a more elaborate analysis of the relationship among the variables, Dahllof et al. (2002) presented algorithms running in O(1.3247n) for #2-SAT and O(1.6894n) for #3-SAT. Furer et al. (2007) presented an algorithm performing in O(1.246n) for #2-SAT by using a standard reduction. Further improved algorithms in (Kutzkov 2007) presented a new upper time bound for the #3-SAT (O(1.6423n)), which is the best upper bound so far.\nDifferent from complexity analyses regarding the number of variables as the parameter, Hirsch (2000) introduced a SAT algorithm with a time bound O(1.239m), where m is the number of clauses of a formula. An improved algorithm for SAT with an upper bound O(1.234m) was proposed in (Masaki 2005). Skjernaa (2004) presented an algorithm for Exact Satisfiability with a time bound O(2m). Bolette (2006) addressed an algorithm for Exact Satisfiability with a time bound O(m!).\nSimilar to the SAT problem, the time complexity of #SAT problem is calculated based on the size of the #SAT instances, which depends not only on the number of variables, but also on the number of clauses. Therefore, it is significant to exploit the time complexity from the other point of view, i.e. the number of clauses. However, so far all algorithms for solving #SAT have been analyzed based on the number of variables. And to our best knowledge, it is still an open problem that analyzes the #SAT algorithm with the number of clauses as the parameter.\nThe aim of this paper is to exploit new upper bounds for #2-SAT and #3-SAT using the number of clauses as the parameter. We provide algorithms for solving #2-SAT and #3-SAT respectively. The algorithm for #2-SAT employs a new principle, i.e. the five-vertex principle, to simplify formulae. This allows us to eliminate variables whose\ndegree is 3, and therefore improves the efficiency of the algorithm. In addition, by transforming a formula into a constraint graph, we propose some detailed analyses between the adjacent variables in the constraint graph, which provides us theoretical foundations for choosing better variables to branch. By analyzing the algorithm, we obtain the worst-case upper bound O(1.1892m) for #2-SAT. For the algorithm solving #3-SAT, we adopt a different strategy, first simplifying the 3-clause formulae into 2- clause formulae, then solving these 2-clasue formulae by the algorithm for #2-SAT. To demonstrate that this strategy is efficient, we give a deep analysis and obtain the worst-case upper bound O(1.4142m) for #3-SAT."}, {"heading": "Problem Definitions", "text": "We now describe the definitions that will be used in this paper. A literal is either a Boolean variable x or its negation x. If a literal is l, the negation of the literal is\u00ac \u00ac l. A clause is a disjunction of literals which doesn\u2019t contain a complementary pair x and x simultaneously. A 2-clause is the clause that contains exactly two literals. A 3-clause is the corresponding clause. The length of a clause C is the number of literals in it. A clause C is a unit clause if the length of the clause is 1. We call the literal in the unit clause is the unit literal. A k-SAT formula F in Conjunction Normal Form (CNF) is a conjunction of clauses, each of which contains exactly k literals. Any Boolean variable xi in F can take a value true or false. A truth assignment for F is a map that assigns each variable a value. The satisfying assignment, called model, is the truth assignment that makes F evaluated to true. The propositional model counting or #SAT problem is to determine the number of satisfying assignments for a formula. #2-SAT is the problem of computing the number of satisfying assignments of a 2-SAT formula and #3-SAT is the corresponding problem for a 3-SAT formula. \u00ac\nA formula F in CNF can be expressed as an undirected graph called constraint graph. In the constraint graph G, the vertexes are the variables of F and the edges between two vertexes if the corresponding variables appear together in some clause of F. The degree of a vertex is the number of edges incident to the vertex. The degree of a Boolean variable x, represented by \u03d5 (x), is the degree of the corresponding vertex. The degree of a formula F, denoted by \u03d5 (F), is the maximum degree of variables in F. We say a formula is a cycle or a path whenever the constraint graph forms a cycle or a path. We define M(F) as the number of models of the formula F, m as the number of clauses in F, and n as the number of variables F contains.\nAfter specifying the definitions, we present some basic rules for solving #SAT problem. Suppose constraint graph G can be partitioned into disjoint components G1 and G2 where there is no edge connecting a vertex in G1 to a vertex in G2, i.e. the variables corresponding to vertexes in G1 and G2 are mutually disjoint. Let F1 and F2 be the subformulae of F corresponding to the two components G1 and G2. Then,\nM(F)=M(F1) \u00d7 M(F2) (1)\nGiven a formula F, the basic strategy of Davis-PutnamLogemann-Loveland (DPLL) computing the models of F is to arbitrarily choose a variable x that appears in F. Then,\nM(F)=M(F \u2227 x)+M(F \u2227 x) \u00ac (2)\nIn order to determine the number of models of F \u2227 l, we adopt the unit literal rule which assigns the unit literal true. The result of the unit literal rule, denoted by lF , can be obtained by (1) removing all clauses containing the literal l from F, and (2) deleting all occurrences of \u00ac l from the other clauses. However, when we apply the unit literal rule to the two sub-formulae F x and F \u2227 x, variables that appear in F may not appear in the simplified version \u2227 \u00ac xF and xF \u00ac , which may make M(F x) and M(F\u2227 \u2227 \u00ac x) wrong. For example, let F=x y z and we choose x to branch, then \u2228 \u2228\nWhen the sub-formula F x is simplified by the unit literal rule, variable y and z are eliminated. Thus, M( \u2227\nxF )=1. When the same rule is applied to F and F \u2227 \u00ac x, we obtain M(F)=7 and M( xF \u00ac )=3. It is obvious that M(F) \u2260 M(F \u2227 x)+M(F \u2227 \u00ac x). Therefore, we introduce a variable set R to record the eliminated variables, which we will give a detailed description in the next section."}, {"heading": "The Complexity Measure", "text": "In this subsection, we explain how we compute the complexity of our algorithms. At first, we give a notion called branching tree. The branching tree (Hirsch 2000) is a hierarchical tree structure with a set of nodes, each of which is labeled with a formula. Suppose a node is labeled with a formula F, then its sons are labeled with the subformulae F1, F2, \u2026 , Fj, each of which is obtained by assigning a value to one of variables in F. From the definition we can see that the process of constructing a branching tree is the same as the process of executing DPLL-style algorithms, therefore, we use the branching tree to estimate the time complexity. In the branching tree, every node has a branching vector. Let us consider a node labeled with F0 and its children nodes labeled with F1, F2, \u2026, Fk. The branching vector of the node labeled with F0 is (r1, r2,\u2026, rk), where ri=f(F0)f(Fi) ( f(F0) is the number of clauses of F0). The value of the branching vector of a node, called branching number ( \u03bb (r1, r2,\u2026, rk)), is obtained from the positive root of the following equation.\n1\ni\nk r\ni x\u2212 = \u2211 =1 (4)\nWe define the maximum branching number of nodes in the branching tree as the branching number of the branching tree, expressed by max \u03bb (r1, r2,\u2026, rk). The branching number of a branching tree has an important relationship\nM(F)=M(F \u2227 x)+M(F x) \u2227 \u00ac (3)\nwith the running time (T(m)) of DPLL-style algorithms. At first, we assume that the running time of DPLL-style algorithms performing on each node is in polynomial time. Then we obtain the following inequality.\nT(m) \u2264 (max \u03bb (r1, r2,\u2026, rk)) m poly(F) \u00d7\n= (max T(m-ri))m \u00d7 poly(F) 1\nk\ni= \u2211\n(5)\nwhere m is the number of clauses in the formula F, ploy(F) is the polynomial time executing on the node F, and\n\u03bb (r1, r2,\u2026, rk)= T(m-ri) 1\nk\ni= \u2211 (6)\nIn addition, if a #SAT problem recursively solved by the DPLL-style algorithms, the time required doesn\u2019t increase, for\n1\nk\ni= \u2211 T(mi) \u2264 T(m) where m = mi 1\nk\ni= \u2211 (7)\nwhere m is the number of clauses, mi is the number of clauses in the sub-formula Fi (1\u2264i\u2264k) of the formula F. Note that when analyzing the running time of our algorithms, we ignore the polynomial factor so that we assume that all polynomial time computations take O(1) time in this paper."}, {"heading": "Algorithm for #2-SAT", "text": "In this section, we present the algorithm MC2 for #2-SAT and prove an upper bound O(1.1892m). Firstly we address some preliminaries used in this part."}, {"heading": "Preliminaries", "text": "We begin the subsection by specifying some notions similar to that proposed in (Dahll\u00f6f et al.2002). {x1, x2} represents a formula which is composed of the variables x1 and x2. Given a formula F expressed as a constraint graph G and a vertex x, LF(x) is the number of vertexes which are not only adjacent to x but also adjacent to other vertexes not in the neighborhood of x, i.e.,\nLF(x)= { ( , ) ( ) ( ) { }}G Gu u v G u N x v N x x\u2208 \u2227 \u2208 \u2227 \u2209 U (8)\nwhere u and v are vertexes, (u, v) is an edge, and NG(x) is the neighborhood of x in the constraint graph G. When LF(x)=1, the unique variable corresponding to the vertex is denoted by U(x), just as Figure1 describes."}, {"heading": "Helpful Function and Principle", "text": "The subsection discusses some functions and principles used for simplifying the formulae. The first function unit(F, l) in Figure 2 is to record the variables which appear in the unit clauses after assigning the literal l true. var(l) denotes the variable forming the literal l. The second function \u03a9 (F, R, l) in Figure 3 recursively executes the unit literal rule. The function takes as input the formula F, a variable set R recording the eliminated variables, and a literal l being assigned true. The detailed process of the function is presented as follows. (1) Remove all clauses containing literal l from F; (2) Delete all occurrences of the negation of literal l from the other clauses; (3) Perform the process as far as possible. Finally, the function returns a simplified formula and a new set R.\nFigure1: A constraint graph where LF(x)=1; the solid lines indicate the end point variables of each solid line appear together in some clause of F; the dashed lines indicate the end points variables of each dashed line may appear together in some clause of F.\nNow we concentrate on the introduction of the fivevertex principle whose applicable condition is described in Figure 4. Supposing in a 2-SAT formula F, one of the maximum degree variables is x and the neighborhood of x in the constraint graph G is y, z, w, \u2026, where \u03d5 (y) \u2265 \u03d5 (z) \u2265 \u03d5 (w) \u2026 \u2265\nfive-vertex principle. If (1) \u03d5 (F)=3 and LF(x)=2, and (2)\u03d5 (y)+\u03d5 (z)\uff0b\u03d5 (w)=5, then\nM(F)= M(F1 \u2227 x) \u00d7 M( F2 x)\uff0b M(F1 \u2227 \u2227 \u00ac x) \u00d7 M(F2 x) \u2227 \u00ac\n(9)\nwhere F1={x, w} and F2= F/F1.\nThe aim of the principle is to remove F1 such that F doesn\u2019t contain the variables whose degree is 3. And since\nLF(x)=2 and\nF1 only contains two variables, it can be solved in polynomial time by exhaustive search. In fact, if \u03d5 (x)=3 and LF(x)=2, then \u03d5 (y) +\u03d5 (z) \uff0b\u03d5 (w) \u2265 5. This is because if LF(x)=2, then \u03d5 (y) 2 and\u2265 \u03d5 (z) 2. And if\u2265 \u03d5 (x)=3 and \u03d5 (y) \u2265 \u03d5 (z) \u2265 \u03d5 (w), then \u03d5 (w)=1. Therefore, when \u03d5 (x)=3 and LF(x)=2, \u03d5 (y)+\u03d5 (z)\uff0b\u03d5 (w) \u2265 5."}, {"heading": "Algorithm MC2 for Solving #2-SAT", "text": "The algorithm MC2 for #2-SAT is based on the DPLL algorithm for satisfiablility modified to count all the satisfying assignments. The basic idea of the algorithm is to choose a variable and recursively count the number of satisfying assignments where the variable is true and the variable is false. We propose the framework of our algorithm MC2 for #2-SAT in Figure 5. The algorithm employs a new principle to simplify formulae, i.e. the fivevertex principle. This allows us to eliminate variables whose degree is 3 in a formula, and therefore improve the efficiency of the algorithm. In addition, by transforming a formula into a constraint graph, we analyze the relationship between the adjacent variables in the constraint graph, which can choose better variables to branch. Note that in the algorithm MC(F) is a function that solves the #2-SAT by exhaustive search. As we all know, if a #2-SAT is solved by exhaustive search, it will spend a lot of time. However, when the number of variables that the formula F contains is so few, it may run in polynomial time. Therefore, we use the function MC(F) only when the number of variables isn\u2019t above 4, which can guarantee the exhaustive search runs in polynomial time. In addition, since the operation on each node is the function \u03a9 (F, R, l) running in polynomial time, we analyze the algorithm in Theorem 1 using the complexity measure described above.\nTheorem 1. Algorithm MC2 runs in O(1.1892m), where m is the number of clauses.\nProof. Let us analyze the algorithm case by case. Case 1, 2, and 3: These cases run in O(1). Case 4: This case doesn\u2019t increase the time needed. Case 5.1: When x is fixed a value, it splits F into two paths and the clauses containing x or x are removed. The worst case is only two clauses containing x or \u00ac \u00acx. Since any two connected variables may form four clauses, we have T(m) 4T( -2), i.e. T(m)\u2208 O( )=O(m2). \u2264 / 2m\u23a1\u23a2 \u23a4\u23a5 4 2logm\nCase 5.2: When any variable is fixed a value, it can split F into a path which case 5.1 is met. Therefore, we also have T(m)\u2208 O(m2).\nCase 6.1: Since LF(x)=1, \u03d5 (U(x)) 2. When U(x)=true, every clause containing U(x) is removed and \u2265 \u00acU(x) is removed from clauses. Then every clause containing \u00acU(x) can be also removed by function . Therefore, the current formula contains at least two clauses less than F. In addition, when U(x) is fixed a value, x forms a component containing three variables which meets the case 3. So we have T(m)=2T(m-4) because the same situation is encountered when U(x)=false. This case takes O(1.1892m) time. \u03a9\nCase 6.2: Figure 4 describes this case. Since F1={x, w}, the number of satisfying assignments of F1 can be counted in O(1) by using MC (F). In fact, the same process is carried out until \u03d5 (F) \u2264 2, i.e. case 5 is met. Therefore, we have T(m)\u2208 O(m2).\nCase 6.3: In this case, LF(x) 2 and \u2265 \u03d5 (y)+\u03d5 (z)\uff0b\u03d5 (w) 6. The neighborhood of variable x is y, z, and w. Since\nLF(x) 2, at least two of them are not just related to \u2265 \u2265\n\u03d5 (y)+\u03d5 (z)\uff0b\u03d5 (w)=5\nvariable x. If we give a fix value to x, at least three clauses are removed. And simultaneously the clauses containing y or z or w may be removed by function . Let S=Unit(F, x) { y, z, w } and S\u2019=Unit(F, \u00acx) { y, z, w }. Then we have T(m) = T(m-3\u03a9 I I\nS )+ T(m-3- 'S ). Since \u03d5 (y)+ \u03d5 (z) \uff0b\u03d5 (w) 6, \u2265 S + 'S \u2265 3. Therefore, the worst case is when T(m)=T(m-3)+T(m-6) with solution O(1.1740m).\nCase 7: Since \u03d5 (x)=4, at least four clauses can be removed if x is fixed a value. Therefore, we have T(m)=2T(m-4) with solution O(1.1892m).\nIn total, MC2 runs in O(1.1892m) time."}, {"heading": "Algorithm for #3-SAT", "text": "In this section, we present our algorithm MC3 for solving #3-SAT and provide an upper bound O(1.4142m)."}, {"heading": "Algorithm MC3 for Solving #3-SAT", "text": "Algorithm MC3 for #3-SAT is also based on the DPLL algorithm for satisfiablility modified to count all the satisfying assignments. We firstly present a notion used in this part. The frequency of a variable xi in a formula F is the number of clauses in F that xi appears in. Then we propose the framework of the algorithm MC3 in Figure 6. The main idea of the algorithm is to choose the maximum frequency variable in all the 3-clauses to branch so that the input 3-clause formula is simplified into 2-clause formulae. Then we recursively count the number of satisfying assignments of these simplified 2-clauses by the algorithm MC2. In the algorithm MC3, there is a helpful function (F, R, l) which has been described in the algorithm MC2. \u03a9\nIn fact, the algorithm MC3 splits the search space into two parts. At first, it explores partial search tree until the 3- clause formula is transformed into 2-clause formulae. Then the algorithm MC2 explores the complete search tree for the 2-clause formulae. Thus, the size of the search space of the MC3 is equal to the DPLL-style algorithm which explores the complete search tree for an n-variable formula. Therefore, the algorithm MC3 also can be solved in polynomial space. In addition, from the discussions above, we know that the algorithm MC2 can be solved rapidly.\nAnd the process of the transformation from 3-clause formula into 2-clause formulae is not difficult. As a result, the algorithm MC3 improves the efficiency of solving the #3-SAT problem in a sense. In the next subsection, we will address the detailed complexity analysis about the algorithm MC3."}, {"heading": "Complexity Analysis", "text": "In this subsection, we explain how to compute the complexity of the algorithm MC3. As we have already described, we also use the branching tree to estimate the time complexity. However, the difference between the complexity analysis of the algorithm MC3 and the others is that we only employ the branching tree to estimate time using in the process of the transformation from 3-clause formula into 2-clause formulae. When we acquire the time complexity of the simplified 3-clause formula, the time complexity of the algorithm MC3 is easy to obtain by making use of the time complexity of the algorithm MC2. The detailed proof will be presented in Theorem 2.\nTheorem 2. Algorithm MC3 runs in O(1.4142m) , where m is the number of clauses.\nProof. Let us analyze the algorithm in detail. Case 1 and 2 can solve the problems completely. These cases run in O(1). Case 3 doesn\u2019t increase the time needed. In Case 4, the maximum frequency of variables in 3- clauses is at least 2. Because if the maximum frequency of variables in 3-clauses is 1, it means that the frequencies of all the variables in 3-clauses are 1. Then the formula F is mutually disjoint which case 3 is met. Thus, when x is fixed a value, every clause containing x(or \u00acx) is either removed or simplified as 2-clauses. Since the maximal frequency of variables is at least 2, at least two clauses are removed when we give a fix value to x. Therefore, we have T(m) = 2T(m-2) with solution O(1.4142m).\nIn Case 5, the formula only contains 2-clauses. We know that the algorithm MC2 runs in O(1.1892m).\nIn total, the upper bound for the algorithm MC3 is O(1.4142m)."}, {"heading": "Conclusion", "text": "This paper addresses the worst-case upper bound for #2- SAT and #3-SAT problems with the number of clauses as the parameter. The algorithms presented are both DPLLstyle algorithms. In order to improve the algorithms, we put forward a new five-vertex principle to simplify the formulae. After a skillful analysis of these algorithms, we obtain the worst-case upper bound O(1.1892m) for #2-SAT and O(1.4142m) for #3-SAT."}, {"heading": "Acknowledgement", "text": "This work was fully supported by the National Natural Science Foundation of China (Grant No. 60673099, 60803102, 60773097, and 60873146)."}], "references": [{"title": "Algorithms and complexity results for #SAT and Bayesian inference", "author": ["F. Bacchus", "Dalmao S.", "Pitassi T.."], "venue": "FOCS\u201903, 340\u2212351. Bolette Ammitzboll Madsen. 2006. An algorithm for exact satisfiability analysed with the number of clauses as", "citeRegEx": "Bacchus et al\\.,? 2003", "shortCiteRegEx": "Bacchus et al\\.", "year": 2003}, {"title": "Counting satisfying assignments in 2-SAT and 3-SAT", "author": ["V. Dahll\u00f6f", "P. Jonsson", "M.. Wahlstr\u00f6m"], "venue": "In 8th COCOON,", "citeRegEx": "Dahll\u00f6f et al\\.,? \\Q2002\\E", "shortCiteRegEx": "Dahll\u00f6f et al\\.", "year": 2002}, {"title": "New upper bound for the #3SAT problem", "author": ["Hirsch E. A"], "venue": "Theoretical Comput. Sci", "citeRegEx": "A..,? \\Q2007\\E", "shortCiteRegEx": "A..", "year": 2007}, {"title": "An improved O(1.234)-time deterministic algorithm for SAT", "author": ["Masaki Yamamoto"], "venue": "SAT. J. Auto. Reasoning", "citeRegEx": "Yamamoto.,? \\Q2005\\E", "shortCiteRegEx": "Yamamoto.", "year": 2005}, {"title": "Algorithms for counting 2-SAT solutions and colorings with applications", "author": ["F\u00fcrer M", "Prasad Kasiviswanathan S"], "venue": "In 3rd AAIM,", "citeRegEx": "M. and S..,? \\Q2007\\E", "shortCiteRegEx": "M. and S..", "year": 2007}], "referenceMentions": [{"referenceID": 0, "context": "Actually, model counting has been proved to be #P-complete, harder than standard SAT problems (Bacchus et al. 2003).", "startOffset": 94, "endOffset": 115}, {"referenceID": 2, "context": "All rights reserved. improvement from O(c) to O((c-\u03b5)) may significantly increase the size of the problem being tractable. Recently, tremendous efforts have been made on efficient #SAT algorithms with complexity analyses. By introducing independent clauses and combining formulas, Dubois (1991) presented a #SAT algorithm which ran in O(1.", "startOffset": 0, "endOffset": 295}, {"referenceID": 2, "context": "All rights reserved. improvement from O(c) to O((c-\u03b5)) may significantly increase the size of the problem being tractable. Recently, tremendous efforts have been made on efficient #SAT algorithms with complexity analyses. By introducing independent clauses and combining formulas, Dubois (1991) presented a #SAT algorithm which ran in O(1.6180) for #2-SAT and O(1.8393) for #3-SAT, where n is the number of variables of a formula. Based on a more elaborate analysis of the relationship among the variables, Dahllof et al. (2002) presented algorithms running in O(1.", "startOffset": 0, "endOffset": 529}, {"referenceID": 2, "context": "All rights reserved. improvement from O(c) to O((c-\u03b5)) may significantly increase the size of the problem being tractable. Recently, tremendous efforts have been made on efficient #SAT algorithms with complexity analyses. By introducing independent clauses and combining formulas, Dubois (1991) presented a #SAT algorithm which ran in O(1.6180) for #2-SAT and O(1.8393) for #3-SAT, where n is the number of variables of a formula. Based on a more elaborate analysis of the relationship among the variables, Dahllof et al. (2002) presented algorithms running in O(1.3247) for #2-SAT and O(1.6894) for #3-SAT. Furer et al. (2007) presented an algorithm performing in O(1.", "startOffset": 0, "endOffset": 628}, {"referenceID": 2, "context": "All rights reserved. improvement from O(c) to O((c-\u03b5)) may significantly increase the size of the problem being tractable. Recently, tremendous efforts have been made on efficient #SAT algorithms with complexity analyses. By introducing independent clauses and combining formulas, Dubois (1991) presented a #SAT algorithm which ran in O(1.6180) for #2-SAT and O(1.8393) for #3-SAT, where n is the number of variables of a formula. Based on a more elaborate analysis of the relationship among the variables, Dahllof et al. (2002) presented algorithms running in O(1.3247) for #2-SAT and O(1.6894) for #3-SAT. Furer et al. (2007) presented an algorithm performing in O(1.246) for #2-SAT by using a standard reduction. Further improved algorithms in (Kutzkov 2007) presented a new upper time bound for the #3-SAT (O(1.6423)), which is the best upper bound so far. Different from complexity analyses regarding the number of variables as the parameter, Hirsch (2000) introduced a SAT algorithm with a time bound O(1.", "startOffset": 0, "endOffset": 962}, {"referenceID": 2, "context": "All rights reserved. improvement from O(c) to O((c-\u03b5)) may significantly increase the size of the problem being tractable. Recently, tremendous efforts have been made on efficient #SAT algorithms with complexity analyses. By introducing independent clauses and combining formulas, Dubois (1991) presented a #SAT algorithm which ran in O(1.6180) for #2-SAT and O(1.8393) for #3-SAT, where n is the number of variables of a formula. Based on a more elaborate analysis of the relationship among the variables, Dahllof et al. (2002) presented algorithms running in O(1.3247) for #2-SAT and O(1.6894) for #3-SAT. Furer et al. (2007) presented an algorithm performing in O(1.246) for #2-SAT by using a standard reduction. Further improved algorithms in (Kutzkov 2007) presented a new upper time bound for the #3-SAT (O(1.6423)), which is the best upper bound so far. Different from complexity analyses regarding the number of variables as the parameter, Hirsch (2000) introduced a SAT algorithm with a time bound O(1.239), where m is the number of clauses of a formula. An improved algorithm for SAT with an upper bound O(1.234) was proposed in (Masaki 2005). Skjernaa (2004) presented an algorithm for Exact Satisfiability with a time bound O(2).", "startOffset": 0, "endOffset": 1170}, {"referenceID": 2, "context": "All rights reserved. improvement from O(c) to O((c-\u03b5)) may significantly increase the size of the problem being tractable. Recently, tremendous efforts have been made on efficient #SAT algorithms with complexity analyses. By introducing independent clauses and combining formulas, Dubois (1991) presented a #SAT algorithm which ran in O(1.6180) for #2-SAT and O(1.8393) for #3-SAT, where n is the number of variables of a formula. Based on a more elaborate analysis of the relationship among the variables, Dahllof et al. (2002) presented algorithms running in O(1.3247) for #2-SAT and O(1.6894) for #3-SAT. Furer et al. (2007) presented an algorithm performing in O(1.246) for #2-SAT by using a standard reduction. Further improved algorithms in (Kutzkov 2007) presented a new upper time bound for the #3-SAT (O(1.6423)), which is the best upper bound so far. Different from complexity analyses regarding the number of variables as the parameter, Hirsch (2000) introduced a SAT algorithm with a time bound O(1.239), where m is the number of clauses of a formula. An improved algorithm for SAT with an upper bound O(1.234) was proposed in (Masaki 2005). Skjernaa (2004) presented an algorithm for Exact Satisfiability with a time bound O(2). Bolette (2006) addressed an algorithm for Exact Satisfiability with a time bound O(m!).", "startOffset": 0, "endOffset": 1257}], "year": 2010, "abstractText": "The rigorous theoretical analyses of algorithms for #SAT have been proposed in the literature. As we know, previous algorithms for solving #SAT have been analyzed only regarding the number of variables as the parameter. However, the time complexity for solving #SAT instances depends not only on the number of variables, but also on the number of clauses. Therefore, it is significant to exploit the time complexity from the other point of view, i.e. the number of clauses. In this paper, we present algorithms for solving #2-SAT and #3-SAT with rigorous complexity analyses using the number of clauses as the parameter. By analyzing the algorithms, we obtain the new worst-case upper bounds O(1.1892) for #2-SAT and O(1.4142) for #3-SAT, where m is the number of clauses.", "creator": "Acrobat PDFMaker 8.0 for Word"}}}