{"id": "1105.5459", "review": {"conference": "arxiv", "VERSION": "v1", "DATE_OF_SUBMISSION": "27-May-2011", "title": "Solving Highly Constrained Search Problems with Quantum Computers", "abstract": "siam previously developed parameter relaxation problem for solving 1 - node problems in a single step successfully chosen to apply along a range around highly primitive hyper - sat algorithm. some assign a restrictions on the number or actions in satisfiability problems for which the generalized solutions can maximize a solution beyond a constant number of steps as the number of variables ages. this performance contrasts for only small growth in the number to variables required by the best method search, and the exponential number required by classical and quantum methods that ignore the problem completely. in classical cases, specific algorithm solutions also approximate relatively insoluble problems at fact have no solutions, comparing previously proposed quantum filter operators.", "histories": [["v1", "Fri, 27 May 2011 01:52:46 GMT  (88kb)", "http://arxiv.org/abs/1105.5459v1", null]], "reviews": [], "SUBJECTS": "cs.AI", "authors": ["t hogg"], "accepted": false, "id": "1105.5459"}, "pdf": {"name": "1105.5459.pdf", "metadata": {"source": "CRF", "title": null, "authors": ["Tad Hogg"], "emails": ["hogg@parc.xerox.com"], "sections": [{"heading": null, "text": "Journal of Arti cial Intelligence Research 10 (1999) 39-66 Submitted 9/98; published 2/99Solving Highly Constrained Search Problemswith Quantum ComputersTad Hogg hogg@parc.xerox.comXerox Palo Alto Research Center3333 Coyote Hill Road Palo Alto, CA 94304 USAAbstractA previously developed quantum search algorithm for solving 1-SAT problems in asingle step is generalized to apply to a range of highly constrained k-SAT problems. Weidentify a bound on the number of clauses in satis ability problems for which the general-ized algorithm can nd a solution in a constant number of steps as the number of variablesincreases. This performance contrasts with the linear growth in the number of steps re-quired by the best classical algorithms, and the exponential number required by classicaland quantum methods that ignore the problem structure. In some cases, the algorithm canalso guarantee that insoluble problems in fact have no solutions, unlike previously proposedquantum search algorithms.1. IntroductionQuantum computers (Benio , 1982; Bernstein & Vazirani, 1993; Deutsch, 1985, 1989; Di-Vincenzo, 1995; Feynman, 1986; Lloyd, 1993) o er a new approach to combinatorial searchproblems (Garey & Johnson, 1979) with quantum parallelism, i.e., the ability to oper-ate simultaneously on many classical search states, and interference among di erent pathsthrough the search space. A quantum algorithm to rapidly factor integers (Shor, 1994), aproblem thought to be intractable for classical machines, o ers a dramatic example of howthese features of quantum mechanics can be exploited.While several additional algorithms have been developed (Boyer, Brassard, Hoyer, &Tapp, 1996; Cerny, 1993; Grover, 1997b, 1997a; Hogg, 1996, 1998a; Terhal & Smolin, 1997),the extent to which quantum searches can improve on heuristically guided classical searchmethods remains an open question. Quantum algorithms can be based directly on classicalheuristics, achieving a search cost that is the square root of the corresponding classicalmethod (Brassard, Hoyer, & Tapp, 1998; Cerf, Grover, & Williams, 1998). Obtainingfurther improvement requires uniquely quantum mechanical methods. Heuristics exploitthe structure of the search problems to greatly reduce the search cost in many cases. Thesuccess of these heuristics raises the question of whether the structure of search problems canform the basis of even better quantum algorithms. A suggestion that this is possible has beenobserved empirically for highly constrained problems (Hogg, 1998a), but the complexity ofthe algorithm precluded a de nitive theoretical analysis of its behavior.This paper presents a new quantum search algorithm that is extremely e ective forsome highly constrained search problems. These constraints also allow for e ective classicalheuristics, i.e., these problems are relatively easy. However, the new quantum algorithm re-quires even fewer steps than the best classical methods, providing another example of searchproblems for which quantum computers can outperform classical ones. More signi cantly,c 1999 AI Access Foundation and Morgan Kaufmann Publishers. All rights reserved.\nHoggthis algorithm illustrates how knowledge of the structure inherent in search problems canbe used to develop new algorithms. Finally, because of its simplicity, the algorithm's be-havior can be readily characterized analytically in some cases, conclusively demonstratingits asymptotic performance behavior in those cases.Speci cally the following two sections brie y review the ingredients of quantum programsand the satis ability problem. The quantum algorithm for a particularly simple case isdescribed in Section 4 and generalized in Section 5. The new algorithm is then evaluated fora variety of highly constrained problems. Finally some open issues are discussed, includinga variety of ways this approach can be extended.2. Quantum ComputersThe state of a classical computer can be described by a string of bits, each of which is im-plemented by some two-state device. Quantum computers use physical devices whose fullquantum state can be controlled. For example (DiVincenzo, 1995), an atom in its groundstate could represent a bit set to 0, and an excited state for 1. The atom can be switchedbetween these states and also be placed in a uniquely quantum mechanical superposition ofthese values, which can be denoted as a vector 0 1 , with a component (called an ampli-tude) for each of the corresponding classical states for the system. These amplitudes arecomplex numbers. A superposition should not be confused with a probabilistic representa-tion of ignorance about whether a classical bit is really 0 or 1. Nor is a superposition simplyin between a 0 or 1, as could be the case with a 3 volt value for classical bits implementedas 0 and 5 volts. Instead, a superposition has no complete classical analog.In contrast to a classical machine which, at any given step of its program, has a de nitevalue for each bit, a quantum machine with n quantum bits exists in a general superpositionof the 2n classical states for n bits, described by the vector = 0B@ 0... 2n 11CA (1)The amplitudes have a physical interpretation: when the computer's state is measured, thesuperposition randomly changes to one of the classical states with j sj2 being the probabilityto obtain the state s. Thus amplitudes satisfy the normalization condition Ps j sj2 = 1.This measurement operation is used to obtain de nite results from a quantum computation.Using this rich set of states requires operations that can rapidly manipulate the am-plitudes in a superposition. Because quantum mechanics is linear and the normalizationcondition must always be satis ed, these operations are limited to unitary linear opera-tors (Hogg, 1996). That is, a state vector can only change to a new vector 0 related tothe original one by a unitary transformation, i.e., 0 = U where U is a unitary matrix1of dimension 2n 2n. In particular, this requires that the operations be reversible: eachoutput is the result of a single input. In spite of the exponential size of the matrix, in many1. A complex matrix U is unitary when UyU = I, where Uy is the transpose of U with all elements changedto their complex conjugates. Examples include permutations, rotations and multiplication by phases(complex numbers whose magnitude is one). 40\nSolving Highly Constrained Search Problems with Quantum Computerscases the operation can be performed in a time that grows only as a polynomial in n byquantum computers (Boyer et al., 1996; Hoyer, 1997). Importantly, the quantum computerdoes not explicitly form, or store, the matrix U . Rather it performs a series of elementaryoperations whose net e ect is to produce the new state vector 0. On the other hand,the components of the new vector are not directly accessible: rather they determine theprobabilities of obtaining various results when the state is measured.Important examples of such operations are reversible classical programs (Bennett &Landauer, 1985; Feynman, 1996). Let P be such a program. Then for each classical state s,i.e., a string of bit values, it produces an output s0 = P [s], and each output is produced byonly a single input. A simple example is a program operating with two bits that replacesthe rst value with the exclusive-or of both bits and leaves the second value unchanged,i.e., P [00] = 00, P [01] = 11, P [10] = 10 and P [11] = 01. When used with a quantumsuperposition, such classical programs operate independently and simultaneously on eachcomponent to give a new superposition. That is, a program operating with n bits givesP 2640B@ 0... 2n 11CA375! 0B@ 00... 02n 11CA (2)where 0s0 = s with s0 = P [s]. This quantum parallelism allows a machine with n bits tooperate simultaneously with 2n di erent classical states.Unitary operations can also mix the amplitudes in a state vector. An example for n = 1is 1p2 1 11 1 (3)This converts 10 , which could correspond to an atom prepared in its ground state, to1p2 11 , i.e., an equal superposition of the two states. Since amplitudes are complexnumbers, such mixing can combine amplitudes to leave no amplitude in some of the states.This capability for interference (Bernstein & Vazirani, 1993; Feynman, 1985) distinguishesquantum computers from probabilistic classical machines.3. The Satis ability ProblemNP search problems have exponentially many possible states and a procedure that quicklychecks whether a given state is a solution (Garey & Johnson, 1979). Constraint satisfac-tion problems (CSPs) (Mackworth, 1992) are an example. A CSP consists of n variables,V1; : : : ; Vn, and the requirement to assign a value to each variable to satisfy given constraints.An assignment speci es a value for each variable.One important CSP is the satis ability problem (SAT), which consists of a logical propo-sitional formula in n variables and the requirement to nd a value (true or false) for eachvariable that makes the formula true. This problem has N = 2n assignments. For k-SAT,the formula consists of a conjunction of clauses and each clause is a disjunction of k variables,any of which may be negated. For k 3 these problems are NP-complete. An example ofsuch a clause for k = 3, with the third variable negated, is V1 OR V2 OR (NOT V3), which41\nHoggis false for exactly one assignment for these variables: fV1 = false; V2 = false; V3 = trueg. Aclause with k variables is false for exactly one assignment to those variables, and true for theother 2k 1 choices. Since the formula is a conjunction of clauses, a solution must satisfyevery clause. We say an assignment con icts with a particular clause when the values theassignment gives to the variables in the clause make the clause false. For example, in a fourvariable problem, the assignmentfV1 = false; V2 = false; V3 = true; V4 = truegcon icts with the k = 3 clause given above, whilefV1 = false; V2 = false; V3 = false; V4 = truegdoes not. Thus each clause is a constraint that adds one con ict to all assignments thatcon ict with it. The number of distinct clauses m is then the number of constraints in theproblem.The assignments for SAT can also be viewed as bit strings with the correspondence thatthe ith bit is 0 or 1 according to whether Vi is assigned the value false or true, respec-tively. In turn, these bit strings are the binary representation of integers, ranging from 0to 2n 1. For de niteness, we arbitrarily order the bits so that the values of V1 and Vncorrespond, respectively, to the least and most signi cant bits of the integer. For example,the assignment fV1 = false; V2 = false; V3 = true; V4 = falsegcorresponds to the integer whose binary representation is 0100, i.e., the number 4.For bit strings r and s, let jsj be the number of 1-bits in s and r ^ s the bitwise ANDoperation on r and s. Thus jr ^ sj counts the number of 1-bits both assignments have incommon. We also use d(r; s) as the Hamming distance between r and s, i.e., the number ofpositions at which they have di erent values. These quantities are related byd(r; s) = jrj+ jsj 2jr ^ sj (4)An example 1-SAT problem with n = 2 is the propositional formula (NOT V1) AND(NOT V2). This problem has a unique solution: fV1 = false; V2 = falseg, an assignmentwith the bit representation 00. The remaining assignments for this problem have bit repre-sentations 01, 10, and 11.3.1 Highly Constrained SAT ProblemsIn general, SAT problems are di cult to solve. However, in a few simple cases the veryregular structure of the search space allows much more e ective algorithms. One example isgiven by 1-SAT problems. In this case, each clause eliminates one value for a single variableallowing classical algorithms to examine the variables independently, giving an overall searchcost of O(n) in spite of the exponentially large number of assignments. A 1-SAT problemhas a solution if and only if each of the m clauses involves a distinct variable. Otherwise,both values for some variable will be in con ict, i.e., making a clause false, resulting in nosolutions. 42\nSolving Highly Constrained Search Problems with Quantum ComputersThis simple structure allows for rapid search. SAT problems with larger clauses have amore complicated structure. Nevertheless, when the k-SAT problems are highly constrained,their structure is close to that of 1-SAT. To see this, consider a soluble k-SAT problem. Withrespect to a particular solution of that problem, de ne the good value for each variable asthe value (true or false) it is assigned in that solution, while the opposite value is the bad onefor that variable. For k-SAT problems with many constraints, the number of bad values inan assignment can usually be determined rapidly from its number of con icts, even thoughdetermining exactly which variables have incorrect assigned values requires rst nding thesolution. In such cases, using the number of bad values results in a tractable algorithm aslong as a priori knowledge of the solution is not assumed.For example, consider soluble problems with the largest possible number of constraints.For k-SAT, these maximally constrained soluble problems have m = mmax wheremmax = nk!(2k 1) (5)i.e., the single solution precludes any clause that con icts with it.An assignment with j bad values contains n jk sets of k variables all of which have thesame values as the solution. Each of the remaining sets con icts with at least one clause inthe problem. Thus each assignment with j bad values hascmax(j) = nk! n jk ! (6)con icts. This quantity grows strictly monotonically with j for j n k, so in these casesj is directly determined by the number of con icts. Assignments with n k + 1 j nare not distinguishable.Assignments with j = n k + 1 can also be corrrectly determined by including neigh-borhood information. To see this, consider an assignment s with j bad values, and its nneighbors, i.e., assignments at Hamming distance one from s. Of these neighbors, j havej 1 bad values, and the remaining n j have j + 1 bad values. For j n k, s hasj neighbors with fewer con icts and n j with more. Thus for these assignments, exam-ining the number of con icts in the neighbors readily determines the value of j. Whenj = n k + 1, the assignment continues to have j neighbors with fewer con icts, but nowthe remaining k 1 neighbors have the same number of con icts since the additional badvalue does not increase the number of con icts. Finally, the neighbors of assignments withn k + 1 < j n all have the same number of con icts. Thus examining the number ofcon icts in an assignment's neighbors determines the value of j, with the exception thatassignments with n k + 1 < j n are not distinguishable.The value of j is the number of con icts that s would have in the maximally constrained1-SAT problem with the same solution as the given maximally constrained k-SAT problem.Thus for a maximally constrained k-SAT problem letce (s) = ( j if j n k + 1n k + 2 otherwise (7)43\nHoggThe value of ce (s) can be determined rapidly, in much the same way that a classical localsearch method checks the number of con icts among neighbors of its current state to deter-mine which assignment to move to next (Minton, Johnston, Philips, & Laird, 1992; Selman,Levesque, & Mitchell, 1992). Thus ce is a computationally tractable approximation tothe number of con icts each assignment would have in the corresponding 1-SAT problem.Except for a few assignments with many con icts, ce gives the correct value. Speci cally,only assignments with at least n k+3 bad values are given an incorrect value of j by thisapproximation. In particular, the approximation is completely correct for k = 2.While classical searches use the number of con icts in an assignment and its neighbors,another possibility for maximally constrained problems is to use the number of con icts inthe assignment and its complement (i.e., the assignment with opposite values for all thevariables). If the assignment has j bad values, its complement will have n j. As describedabove, the number of con icts in an assignment uniquely determines the corresponding valueof j provided j n k. On the other hand, the number of con icts in the complementassignment uniquely determines j when n j n k, or j k. Thus, as long as n > 2k,at least one of these conditions will be true for all 0 j n and the correct value of j canbe determined.3.2 Random SAT ProblemsTheoretically, search algorithms are often evaluated for the worst possible case. However,in practice, search problems are often found to be considerably easier than suggested bythese worst case analyses (Hogg, Huberman, & Williams, 1996). This observation leads toexamining the typical behavior of search algorithms with respect to a speci ed ensemble ofproblems, i.e., a class of problems and a probability for each to occur. For instance, theensemble of random k-SAT is speci ed by the number of variables n, the size of the clausesk and the number of distinct2 clauses m.The quantum algorithm presented in this paper is e ective for highly constrained solublek-SAT problems. When there are many constraints, soluble problems are very rare amongrandomly generated instances. Thus to study the algorithm's behavior we generate randomproblems with a prespeci ed solution. That is, a random assignment is selected to be asolution and used to restrict the selection of clauses for the problem. In the remainder ofthis section we describe two methods for generating such problems, and how they can berelated to corresponding 1-SAT problems.3.2.1 Prespecified SolutionThe most common use of a prespeci ed solution is to simply avoid selecting any clausesthat con ict with it. Thus, we generate problems by randomly selecting a set of m distinctclauses from among the mmax, given by Eq. (5), available clauses (Nijenhuis & Wilf, 1978).Consider a given soluble k-SAT problem with m clauses, and let the assignment r beone of its solutions. With respect to the solution r, we can de ne the bad value for each2. This ensemble di ers slightly from other studies where the clauses are not required to be distinct.44\nSolving Highly Constrained Search Problems with Quantum Computersvariable. For an assignment with j bad values, the probability it has c con icts isPconf(cjj) = cmax(j)c mmax cmax(j)m c mmaxm (8)where cmax(j), given by Eq. (6), is the largest possible number of con icts for an assignmentwith j bad values. The probability that an assignment has j bad values isPbad(j) = 2 n nj!From these expressions and the de nition of conditional probability, the probability thatan assignment with c con icts has j bad values isPbad(jjc)/ Pconf(cjj)Pbad(j) (9)Hence, for a given assignment s with c con icts, we can estimate the number of bad valuesit has by picking j that maximizes Pbad(jjc). We use this maximum likelihood value for jas ce (s) instead of Eq. (7) for random soluble k-SAT problems. This estimate is readilycomputed from the number of con icts.3.2.2 Balanced ClausesGenerating problems with a prespeci ed solution as described above is commonly used tostudy search problems. However, for each variable there are more allowable clauses wherethe variable is assigned its bad value than its good value. This makes highly constrainedinstances particularly easy since the good value for each variable can often be determinedfrom its assigned value that appears most often in the clauses (Gent, 1998).This bias in clause selection can be removed by a slight change in the generationmethod (Van Gelder & Tsuji, 1993). Speci cally, instead of only avoiding those clausesthat con ict with the prespeci ed solution, i.e., specify zero bad values, we also avoid anyclauses that have an even number of bad values with respect to the prespeci ed solution.This selection method means both values for each variable appear equally often among theclauses. These balanced problems can have at mostmbalmax = nk!2k 1 (10)clauses. Furthermore, an assignment with j bad values can have at mostcbalmax(j) =Xi 0 ji! n jk i! (11)con icts, where the sum is over odd values of i. Using these values in Eq. (8) instead ofmmax and cmax(j) gives the maximum likelihood estimate for j in this \\balanced clause\"ensemble conditioned on the number of con icts in the assignment.45\nHogg4. Solving 1-SATA quantum computer, operating on superpositions of all assignments for any 1-SAT prob-lem, can nd a solution in a single search step (Hogg, 1998b). As a basis for solving highlyconstrained problems with larger clause sizes, we focus on maximally constrained 1-SATwhich, from Eq. (5), has m = n clauses and allows a simple speci cation. Speci cally, we rst motivate and de ne the algorithm for this case and illustrate it with small examples.Then we show that it is guaranteed to nd a solution if one exists, and nally describe howthe algorithm can be e ciently implemented on a quantum computer. The remainder ofthe paper then shows how this algorithm can form the basis for e ectively solving highlyconstrained k-SAT for k > 1.4.1 MotivationSolving a search problem with a quantum computer requires nding a unitary operator Lthat transforms an easily constructed initial state vector to a new state with large am-plitude in those components of the state vector corresponding to solutions. Furthermore,determining this operator and evaluating it with the quantum computer must be tractableoperations. This restriction means that any information used for a particular assignmentmust itself be easily computed, and the algorithm only uses readily computable unitaryoperations.To design a single-step quantum algorithm, we consider superpositions of all assignmentsfor the problem. Since we have no a priori knowledge of the solution, an unbiased initialstate vector is one with equal amplitude in each assignment: s = 2 n=2.We must then incorporate information about the particular problem to be solved intothis state vector. As in previous algorithms (Grover, 1997b; Hogg, 1996, 1998a), we dothis by adjusting the phases in parallel, based on a readily computed property of eachassignment: its number of con icts with the constraints of the problem. This amountsto multiplication by a diagonal matrix R, with the entries on the diagonal having unitmagnitude so that R is unitary. The resulting amplitude for assignment s is then of theform (s)2 n=2 where j (s)j = 1 and (s) depends only on the number of con icts in s. Whilethis operation adds problem speci c information to the state vector, in itself it does notsolve the problem: at this point a measurement would return assignment s with probabilityj (s)j22 n = 2 n, the same as random selection.This operation also illustrates how the unitarity requirement, j (s)j = 1, prevents usfrom using a computationally more desirable selection, i.e., (s) = 0 if s is not a solution,and nonzero otherwise. Such a choice, if possible, would immediately give a state vectorwith all amplitude in the solution. While determining whether a given assignment is asolution can be done rapidly for any NP problem, that information can not be directly usedto set amplitudes of the nonsolutions to zero. Thus, while quantum parallelism allows rapidtesting of all assignments, the restriction to unitary operators severely limits the use thatcan be made of this information.For a single-step search algorithm, the remaining operations must not require any addi-tional evaluation of the problem constraints, i.e., these operations will be the same for allproblems of a given size. One the other hand, this restriction has the advantage of allowingmore general unitary matrices than just phase adjustments. Speci cally, this allows oper-46\nSolving Highly Constrained Search Problems with Quantum Computersations that mix the various components of the state vector. We need to identify a mixingoperator U that makes all contributions to the solution add together in phase, but with Uindependent of the particular problem.The nal result of the algorithm is r = Ps Urs (s)2 n=2. Suppose t is the solution.The maximum possible contribution to t will be when all values in the sum combine in-phase. This will be the case if Uts = (s)2 n=2 where is the complex conjugate of . Inthis case, t = Ps j (s)j22 n which is just equal to 1. However, the mixing matrix itselfis to be independent of any particular problem. Thus the issue is whether it is possible tocreate a U whose values will have the required phases no matter where the solution is. Oneapproach is to note that the mixing should have no bias as to the amount of amplitude thatwill need to be moved from one assignment to another in the state vector. This means thatthe magnitude of each element in U will be the same, i.e., jUrsj = 2 n=2. For the phaseof each element, we can consider using the feature of assignments used in classical localsearches, namely the neighbors of each assignment. This suggests having Urs depend onlyon the Hamming distance between r and s, i.e., Urs = 2 n=2 d(r;s) where j dj = 1.With the elements of U depending only on the Hamming distance, the matrix is inde-pendent of any particular problem's constraints. The question is then whether some feasiblechoices of (s) and d allow 2 nPs d(t;s) (s) = 1 for the solution t. This will be the caseprovided d(t;s) = (s), where (s) = c depends only on the number of con icts c inassignment s. This relation does not hold for all search problems. However, for the maxi-mally constrained 1-SAT considered here, the Hamming distance of assignment s from thesolution, d(t; s), which is the number of bad values in s, is precisely equal to the number ofcon icts in s. Thus, to ensure all amplitude is combined into the solution, we merely needto have d = d.The nal question is what choices for the d values are consistent with U being a unitarymatrix. This requirement restricts the available choices, e.g., having all d = 1 results inthe nonunitary matrix with all elements equal to 2 n=2.To examine the possible choices, consider the smallest possible case, n = 1. One max-imally constrained, but still solvable, problem has the single clause NOT V1 and solutionV1 = false. The two assignments, 0 and 1, have, respectively, 0 and 1 con icts. Since overallphase factors are irrelevant, we can select 0 = 1 leaving a single remaining choice for 1.For the matrix U , we have pairs of assignments with Hamming distance 0 and 1. Requiring d = d then gives U = 1p2 1 1 1 1 The unitarity condition, UyU = I , then requires that 1 be purely imaginary, i.e., 1 = i.We arbitrarily pick 1 = i. Starting from the initial state with equal amplitude in bothassignments we then have the results of applying R followed by U :1p2 11 ! 1p2 1i ! 10 giving all the amplitude in the solution. The overall operation L = UR isL = 12 1 1 i i 47\nHoggIt is important to note that the same operations also work if, instead, the other assign-ment is the solution, i.e., the problem has the clause V1 and solution V1 = true. In thiscase, the assignments 0 and 1 now have, respectively, 1 and 0 con icts so the 1 = i phaseadjustment is now applied to assignment 0. The operation then gives1p2 11 ! 1p2 i1 ! 01 Again, all amplitude is in the single solution, and the overall operation isL = 12 i i1 1 While the overall operation L depends on the location of the solution, for these problemsit can be implemented by composing operators U and R that do not require knowledge ofthe solution. Instead, as described more generally in Section 4.5, R is implemented byusing the classical function for evaluating the number of con icts in a given assignment,but applied to a superposition of all assignments.With these motivating arguments for the form of the operations, examining a few largervalues of n establishes the simple pattern of phases used in the algorithm described in theremainder of this section.4.2 The Algorithm for Maximally Constrained 1-SATBrie y, the algorithm starts with an equal superposition of all the assignments, adjusts thephases of the amplitudes based on the number of con icts in the assignments, and thenmixes the amplitudes from di erent assignments. This algorithm requires only a singletesting of the assignments, corresponding to a single classical search step.Speci cally, the initial state is s = 2 n=2 for each of the 2n assignments s, and the nalstate vector is = UR (12)where the matricesR and U are de ned as follows. The matrixR is diagonal with Rss (s)depending on the number of con icts c in the assignment s, ranging from 0 to n: (s) = c = ic (13)The mixing matrix elements Urs = ud(r;s) depend only on the Hamming distance betweenthe assignments r and s, with ud = 2 n=2( i)d (14)and d ranging from 0 to n.4.3 ExamplesTo illustrate the algorithm, consider the example problem in Section 3. It has n = m = 2.With the assignments ordered according to the corresponding interger value, i.e., 00, 01,10, and 11, U = A(2)=2 where A(2) = 0BB@ 1 i i 1 i 1 1 i i 1 1 i 1 i i 1 1CCA (15)48\nSolving Highly Constrained Search Problems with Quantum ComputersThe resulting behavior is:assignment s 00 01 10 11number of con icts 0 1 1 2 (s) 1 i i 1 1=2 1=2 1=2 1=2R 1=2 i=2 i=2 1=2 = UR 1 0 0 0giving an amplitude of 1 in the solution assignment 00.Another example, with n = m = 3 is the propositional formula (NOT V1) AND (NOTV2) AND V3, with assignments 000; 001; 010; : : : ; 110; 111, represented as bit vectors, andsolution fV1 = false; V2 = false; V3 = trueg, i.e., the bit vector 100. In this case U can beexpressed in terms of A(2) from Eq. (15) in block form:U = 1p8 A(2) iA(2) iA(2) A(2) (16)For this case, the algorithm's behavior is:assignment s 000 001 010 011 100 101 110 111number of con icts 1 2 2 3 0 1 1 2 (s) i 1 1 i 1 i i 1p8 1 1 1 1 1 1 1 1p8R i 1 1 i 1 i i 1 = UR 0 0 0 0 1 0 0 0Again, all the amplitude is in the solution.4.4 Performance of the AlgorithmConsider a maximally constrained soluble 1-SAT problem with n variables. As describedin Section 3, in such a problem each clause involves a separate variable and there is exactlyone solution. To show that the algorithm works for all n, we evaluate Eq. (12).For each assignment s, (R )s = (s)2 n=2 from Eq. (13). Then for each assignment r,(UR )r = 2 n=2Ps Urs (s). Each s in this sum can be characterized by x: the number of con icts s shares with r y: the number of con icts of s that are not con icts of rLet h be the number of con icts in the assignment r, i.e., the number of the n variables towhich r assigns an incorrect value. In terms of these quantities, s has x + y con icts andis at Hamming distance d(r; s) = (h x) + y from r. The number of such assignments is hx n hy , so the sum can be written as(UR )r = 2 n=2Xx hx!Xy n hy !uh x+y x+y (17)49\nHoggSubstituting the values from Eq. (13) and (14), gives(UR )r = 2 nXx hx!Xy n hy !( i)h x+yix+y (18)= 2 n( i)h2n hXx hx!( 1)xThis gives (UR )r = h0 where xy = 1 if x = y and 0 otherwise by use of the identityhXx=0( 1)x hx! = h0 (19)Thus, = UR has all its amplitude in the state with no con icts, i.e., the unique solution.A measurement made on this nal state is guaranteed to produce a solution.4.5 ImplementationConceptually, the operation of Eq. (12) can be performed classically by matrix multipli-cation. However, since the matrices have 2n rows and columns, this is not be a practicalalgorithm. As described in Section 2, quantum computers can rapidly perform many matrixoperations of this size. Here we show how this is possible for the operations used by thisalgorithm.For describing the implementation, it is useful to denote the individual components ina superposition explicitly. Traditionally, this is done using the ket notation introduced byDirac (1958). For instance, the superposition described by the state vector of Eq. (1) isequivalently written asPs sjsi where jsi just represents a unit basis vector correspondingto the assignment s. An example of these alternate, and equivalent, notations is: 0 1 = 0 10 + 1 01 = 0j0i+ 1j1i4.5.1 Forming the Initial SuperpositionThe initialization of can be performed rapidly by applying the matrix of Eq. (3) separatelyto each of the n bits. For instance, when n = 2, starting from both bits set to 0, the statevector is changed as: j00i ! 1p2 (j00i+ j01i)! 12 ((j00i+ j10i) + (j01i+ j11i))Equivalently, in terms of state vectors, this is0BB@ 10001CCA! 1p2 0BB@ 11001CCA! 12 0BB@ 11111CCA50\nSolving Highly Constrained Search Problems with Quantum Computers4.5.2 Adjusting PhasesFor the operation R , note that each value in Eq. (13) has unit magnitude so R is a unitarydiagonal matrix. Furthermore each c only requires using the e cient classical proceduref(s) that counts the number of con icts in an assignment s. We require a reversible versionof this procedure, which can be made with an additional program register. When the phasesto be introduced are just 1, this additional register needs to take on only two values, 0or 1, corresponding to whether the phase should be 1 or 1, respectively. Thus it canbe represented with a single additional quantum bit, beyond those required to representthe assignment. Such phases have been used in previous algorithms (Hogg, 1996; Grover,1997b) and can be implemented through a single evaluation of f(s) by setting the extravariable to be a superposition of its two values (Boyer et al., 1996).In the algorithm presented here, Eq. (13) requires phases that are powers of i, whichcan take on four di erent values: 1, i, 1 and i. The technique used with 1 phases canbe generalized to work with these four values, again with a single evaluation of f(s). Theadditional register must consist of two quantum bits, so it can take on the values 0, 1, 2 or3. For an assignment s and register x, we use the reversible operationF : js; xi ! js; x+ c mod 4iwhere c = f(s) is the number of con icts in assignment s. It then remains to show howthis operation can be used to perform the required phase adjustments. Just as we operatewith a superposition of all possible assignments, to implement the phase adjustment, we setregister x to be a particular superposition of its four values: = 12(j0i ij1i j2i+ ij3i).One way to construct this superposition is to start with both bits of x set to 1, operate onthe most signi cant bit with Eq. (3) and then operate on the other bit with1p2 i 11 i to get j11i ! 1p2 (j01i j11i)! 12 ((j00i ij01i) (j10i ij11i))This is just the superposition when we make the correspondence between the 2-bit vectors00; : : : ; 11 and the integers 0; : : : ; 3, respectively.We start with the equal superposition of amplitudes for the assignments and this super-position for x: 2 n=2Xs jsi = 2 n=2 1Xs 3Xx=0( i)xjs; xiAs illustrated with Eq. (2), the operation F acts on each term in this superposition sepa-rately, to produce 2 n=2 1Xsx ( i)xjs; x+ c mod 4i51\nHoggwhere c is the number of con icts in assignment s. Let y = x+ c mod 4. Then, for a givenassignment s, as x ranges from 0 to 3, y also takes on these values, but not necessarily inthe same order. Thus this resulting superposition can also be written as2 n=2 1Xs 3Xy=0( i)y cjs; yibecause ( i)4 = 1. In this form, the sums separate to give nally2 n=2Xs icjsi 3Xy=0( i)yjyi = 2 n=2Xs icjsi The net result of applying F using the superposition for the additional register is tochange the phase of each assignment s by ic, as required by Eq. (13). Importantly, the nal result reproduces the original factored form in which the superposition of assignmentsis not correlated with the superposition of the register. This factored form means theregister plays no role in the subsequent mixing operation applied by the matrix U to thesuperposition of assignments. Thus this procedure produces the required phase changesusing only one evaluation of f(s), showing how the phases of a superposition of assignmentscan be adjusted without requiring any prior explicit knowledge of the solution.4.5.3 The Mixing MatrixTo implement U speci ed by Eq. (14) we use two simpler matrices, W and de ned asfollows. For assignments r and s, Wrs = 2 n=2( 1)jr^sj (20)is the Walsh transform and is a diagonal matrix whose elements rr (r) depend onlyon the number of 1-bits in each assignment, namely, (r) = h ihe i n=4 (21)where h = jrj, ranging from 0 to n. The overall phase, e i n=4, is not essential for thealgorithm. It merely serves to make the nal amplitude in the solution be one rather thanei n=4. Whether or not this overall phase is used, the probability to nd a solution is one.The matrixW is unitary and can be implemented e ciently (Boyer et al., 1996; Grover,1997b). For n = 1, W is just the matrix of Eq. (3). The phases in the matrix are powersof i and so can be computed rapidly using similar procedures to those described above forthe matrix R. In this case we use a procedure that counts the number of 1-bits in eachassignment rather than the number of con icts.Finally we show that U can be implemented by the product W W . To see this, letU\u0302 W W . Then U\u0302rs = 2 n nXh=0 hSh(r; s) (22)where Sh(r; s) = Xt;jtj=h( 1)jr^tj+js^tj (23)52\nSolving Highly Constrained Search Problems with Quantum Computerswith the sum over all assignments t with h 1-bits. Each 1-bit of t contributes 0, 1 or 2 tojr ^ tj+ js ^ tj when the corresponding positions of r and s are both 0, have exactly a single1-bit, or are both 1, respectively. Thus ( 1)jr^tj+js^tj equals ( 1)z where z is the numberof 1-bits in t that are in exactly one of r and s. There are (jrj jr ^ sj) + (jsj jr ^ sj)positions from which such bits of t can be selected, and by Eq. (4) this is just d(r; s). Thusthe number of assignments t with h 1-bits and z of these bits in exactly one of r and s isgiven by dz n dh z where d = d(r; s). Thus Sh(r; s) = S(n)hd whereS(n)hd =Xz ( 1)z dz! n dh z! (24)so that U\u0302rs = u\u0302d(r;s) with u\u0302d = 2 nPh hS(n)hd . Substituting the value of h from Eq. (21)then gives u\u0302d = 2 ne i n=4Xhz ih( 1)z dz! n dh z!= 2 ne i n=4(1 i)d(1 + i)n dwhich equals ud as de ned in Eq. (14). Thus U = W W , allowing U to be e cientlyimplemented. As a nal note, except for a di erent choice of the h phases, this is the sameimplementation as used for the mixing matrix de ned in an unstructured quantum searchalgorithm (Grover, 1997b).4.5.4 Required Search TimeWhile search algorithm performances are often compared based on the number of searchsteps required, i.e., the number of sequentially examined assignments, it is also important tocompare the number of more elementary computational operations required. At the mostfundamental level, these operations are logic operators on one or two bits at a time (e.g.,the logical not or exclusive-or operations). As described above, the matrix operations andforming the initial state can be done with a series of O(n) bit operations (Boyer et al.,1996).The time required to count the number of con icts in an assignment depends on datastructures used to represent the problem. A single evaluation will be comparable for boththe quantum and classical algorithms. For a SAT problem with m clauses, examining eachclause to see if it con icts with a given assignment uses O(m) tests. Each of these testswill, in turn, require comparing at least part of the clause to the assignment. Because theclauses in k-SAT are of xed size, this gives an overall cost of O(m) to evaluate the numberof con icts.For local classical search, the number of con icts in neighboring assignments will alsobe evaluated to determine which assignment should be examined at the next step of thesearch. Since neighbors di er by the value of only one variable, in fact it is only necessaryto examine clauses that involve that variable to determine the di erence in the number ofcon icts between an assignment and one of its neighbors. This evaluation will thus requireonly O(m=n) tests. Examining each, or a least a good portion, of the n neighbors results in53\nHogga total of O(m) tests to nd the next assignment. Selecting an initial assignment requiresa value for each variable, a cost of O(n).Thus we can expect both algorithms to involve costs of O(n +m) to evaluate a singlesearch step. That is, the cost for a single search step is about the same for the quantumalgorithm and classical searches when neighbors are examined. However, the quantumalgorithm is able to examine the characteristics of all assignments in superposition whilea classical search examines just one state, allowing the quantum algorithm to complete injust one step while the best classical methods for k-SAT require O(n) steps. For the highlyconstrained k-SAT problems with k > 1, discussed below, m n so the dominant cost willbe in the evaluation of the number of con icts.This discussion indicates how a comparison of search steps gives a reasonable compari-son in terms of elementary operations as well. However, a full comparison will also dependon details of actual implementations, such as any additional operations required for con-trolling errors that cannot themselves be performed in parallel with the higher level stepsof the algorithm. These remain signi cant issues in the development of quantum compu-tation (Landauer, 1994; Unruh, 1995; Haroche & Raimond, 1996; Monroe & Wineland,1996), but at this point seem unlikely to be fundamental di culties (Berthiaume, Deutsch,& Jozsa, 1994; Shor, 1995; Knill, La amme, & Zurek, 1998). In particular, because thealgorithm requires only a single step, decoherence is likely to be less of a di culty for itthan search algorithms that require multiple repeated steps to move signi cant amplitudeto solutions (Grover, 1997b; Hogg, 1998a).Finally, search algorithms can be compared based on elapsed execution time. Currenthardware implementations (Barenco, Deutsch, & Ekert, 1995; Bouwmeester et al., 1997;Chuang, Vandersypen, Zhou, Leung, & Lloyd, 1998; Cirac & Zoller, 1995; Cory, Fahmy, &Havel, 1996; Gershenfeld, Chuang, & Lloyd, 1996; Sleator & Weinfurter, 1995) are quitelimited in size, so such a comparison will need to await the construction of quantummachineswith a su cient number of bits to perform interesting searches.5. Applying the Algorithm to k-SATThe algorithm presented above is e ective for 1-SAT by exploiting the simple structure ofsuch problems. As described in Section 3, many highly constrained k-SAT problems havea similar structure. This observation allows the 1-SAT algorithm to be applied to moregeneral problems, although with a reduction in performance. Speci cally, applying Eq. (13)requires knowing the number of con icts the assignments would have in the correspondingmaximally constrained 1-SAT problem whose solution is equal to one of the solutions of theoriginal k-SAT problem. As described in Section 3.1, for the most part this can be computede ciently using the neighborhood relations for the problem. This suggests simply changingthe 1-SAT algorithm to use (s) = ce (s).To see how this approximation changes the performance, consider an assignment s withy bad values with respect to a speci c solution r and let (s) = ce (s) y (25)The vector v(k) = R used with the k-SAT problem is related to the vector from thecorresponding 1-SAT problem v(1) by v(k)s = v(1)s + s. Except for this change, the remaining54\nSolving Highly Constrained Search Problems with Quantum Computerstransformations of the algorithm are the same as in the 1-SAT case. ThusUR = (1) + U where (1) is the result of the corresponding 1-SAT problem, i.e., all amplitude in thesolution, and is a diagonal matrix, with elements given by (s). It is convenient to de nethe average value of (s) over all assignments with y bad values: y = 1 ny Xs 0 (s) (26)where the sum is restricted to just the ny assignments with y bad values.The change in the amplitude in the solution state is determined by (U )r whenr is the solution. This change can be expressed using Eq. (17) by recalling that h = 0 forthe solution and replacing the phases y by the error in the phases, y: = 2 n=2 nXy=0 ny!uy y (27)Since all the y have unit magnitude, j y j 2. If the problem has only one solution, theprobability the algorithm will nd it is Psoln = j1+ j2. If there are multiple solutions, thisis a lower bound on the probability.The following sections use these observations to extend the range of problems to whichthe 1-SAT algorithm can be e ectively applied.6. Solving Maximally Constrained k-SATThe regular structure of maximally constrained soluble k-SAT problems allows them to besolved in O(1) steps. That is, the probability to nd a solution remains O(1) as n increases.Thus a solution is very likely to be found by repeating the algorithm O(1) times, and, asdescribed above, each trial of the algorithm involves only one evaluation of the con icts.To see this, we use ce (s) from Eq. (7). For k > 2, this approximation results in incorrectphase choices for only a few, high-con ict assignments. Because the proportion of incorrectphases is small, we can expect this approximation will introduce only small amplitudesin nonsolution states. However, it will also make the algorithm incomplete: it can nd asolution if one exists but not prove no solutions exist.Speci cally, (s) can be nonzero only for y n k + 3, where y is the number of badvalues in assignment s. Thus using Eq. (27), j y j 2 and Eq. (14),j j 2 n2 nXy=n k+3 ny!When n k + 3 n=2, the sum over binomial coe cients can be bounded (Palmer, 1985)to give j j 2 (n 1) nk 3! n+ 1 (k 3)n + 1 2(k 3) 2 (n 1) nk 3(k 3)! (28)55\nHoggThus the probability to obtain a solution isPsoln = j1 + j2 (1 j j)2 1 2 (n 2) nk 3(k 3)! ! 1 (29)which rapidly approaches 1. Hence, this algorithm is able to nd the solution in O(1) searchsteps as n increases. This behavior is illustrated in Figure 1. 5 10 15 20 25 30 n -7 10 -5 10 -3 10 -1 10 1-P Figure 1: Behavior of 1 Psoln vs. n for maximally constrained soluble k-SAT for k = 3(black) and 4 (gray). For comparison, the bounds (1 j j)2 from Eq. (28) areshown as the dashed lines.Similarly, soluble balanced k-SAT problems with the maximum possible number ofclauses, given by Eq. (10), give good performance as shown in Figure 2. The behaviorin this case is rather irregular and continues for larger values of n, but still gives a highprobability to nd a solution. For odd k, the probability for a solution is exactly one formany values of n. In fact, by including neighborhood information, the errors in the remain-ing cases can also be eliminated, giving a perfect algorithm for these problems. For evenk, the balanced clauses force the problem to have two solutions with opposite values. Eventhough this problem structure di ers signi cantly from that of a 1-SAT problem with asingle solution, the algorithm is able to nd solutions for k = 4 with probability of about1/2, even as n increases.7. Solving Highly Constrained Random k-SATThe discussion of Section 3.2 shows how a maximum likelihood estimate for ce can becomputed for each assignment. This value can then be used to extend the algorithm toarbitrary k-SAT problems. To the extent that the errors introduced by this approximationare small, the quantum algorithm will have a substantial probability to nd a solution in asingle step. 56\nSolving Highly Constrained Search Problems with Quantum Computers 20 30 40 50 n 0.2 0.4 0.6 0.8 1 P\nFigure 2: Behavior of Psoln vs. n for maximally constrained balanced soluble k-SAT fork = 3 (black) and 4 (gray). For comparison, the bounds (1 j j)2 based onEq. (27) are shown as the dashed lines, and is quite small for the k = 4 case.When averaged over the problem ensemble, the error given by Eq. (27) becomesj j B 2 n2 nXy=0 ny!pywhere py is the probability an assignment with y bad values is (incorrectly) determined tohave a di erent number of bad values. In terms of the conditional probabilities of Section 3.2,py = 1 Xc Pconf(cjy) cywhere cy = 1 when the maximum likelihood estimate for a state with c con icts is y (i.e.,ce = y), and 0 otherwise.For simplicity, these maximum likelihood estimates are determined solely from the num-ber of con icts in each state. The ce values could be made a bit more accurate by includingneighborhood information, as was used for maximally constrained random problems in Sec-tion 6.Because highly constrained random SAT problems are relatively easy, they have not beenwell-studied with classical algorithms. Hence, to provide comparison with the quantumsearch results presented below, these problems were also solved with the classical GSATprocedure (Selman et al., 1992), limiting each trial to use no more than 2n steps beforea new random initial state was selected. For both random and balanced ensembles, themedian number of search steps required to nd a solution grows linearly over the rangeof sizes considered here when m = O(n2). In particular, while the balanced ensemble haslarger search costs, it still grows linearly when there is such a large number of clauses.57\nHogg7.1 Random k-SATFor random k-SAT with prespeci ed solution, Stirling's asymptotic expansion in Eq. (8)shows that py = O(1) for y = O(n) when m grows as O(n2), which is much less thatthe maximum mmax = O(nk). In this case, the asymptotic behavior of the bound B isdetermined by the values near the maximum of the binomial coe cient, i.e., near y = n=2.Thus if m = n2, we have B 2pn=2. From Eq. (29), Psoln = O(1) at least when B < 1.This is the case for > crit where crit = ( 27 2=(2 + 18 2) if k = 22(2k 1)3 2=k2 if k > 2 (30)where erf 1(12) 0:477. For instance, crit is 1.01 and 17.3 for k = 2 and 3, respectively.Thus, the algorithm presented here is simple enough to allow an analytic bound on itsbehavior for highly constrained problems, thus demonstrating its asymptotic e ectiveness inthese cases. Other, more complex, structured quantum algorithms have only been evaluatedempirically (Hogg, 1996, 1998a), which is limited to small problems.The algorithm's behavior with fewer constraints, i.e., < crit, is not easily evalutedanalytically since the bound provided by B is no longer useful. Instead, the behavior can beexamined empirically using a classical simulation (Hogg & Yanik, 1998), which is howeverlimited to problems with a relatively small number of variables. These empirical studies mayeventually be extendable to larger problems using approximate evaluation techniques (Cerf& Koonin, 1997).An example is given in Figure 3. This shows good performance for highly constrainedproblems, as expected from the behavior of the lower bound. Performance is also good withfew constraints; not because the algorithm is capturing the problem structure particularlywell but rather because there are many solutions to weakly constrained problems. As withother classical and quantum search methods that use problem structure, the hardest casesare for problems with an intermediate number of constraints (Hogg et al., 1996).From Figure 4 we see that the nonzero asymptotic limit for the probability of a solutionappears to continue for somewhat fewer constraints than expected from the value of crit.Below this value, the probability for nding a solution appears to decrease as a powerof n, indicated by linear scaling on the log-log plot of Figure 4 for m = n2. Similarempirical evaluations of the scaling with an intermediate number of constraints where thehard problems are concentrated, e.g., m = 4n for 3-SAT, shows linear scaling on a log-plot, indicating exponential decrease in the probability to nd a solution. Moreover, theresulting search costs in these cases are larger than those of other structured quantum searchalgorithms (Hogg, 1996, 1998a). Thus the structure of these harder cases di ers enoughfrom the simple 1-SAT problems that this algorithm is not e ective for them.In summary, the algorithm solves highly constrained problems with m = n2 in O(1)steps for > crit, and possibly for somewhat smaller values of as well. As the numberof clauses is further reduced, the required number of steps appears to grow polynomiallywhen > 0 and exponentially when m = O(n).58\nSolving Highly Constrained Search Problems with Quantum Computers 1 5 10 50 100 m/n -410 -3 10 -2 10 -1 10 1 P\nFigure 3: Probability to nd a solution for random 3-SAT for n = 10 (solid) and 20 (dashed)vs. m=n, on a log-log scale. Each point is an average over at least 100 probleminstances, and includes error bars for the standard deviation in this estimate ofthe averge. The error bars are smaller than the size of the plotted points. Thegray lines show the corresponding lower bounds (1 B)2. 5 10 15 20 n -3 10 -2 10 -1 10 1 p Figure 4: Probability to nd a solution for random soluble 3-SAT vs. n with, from top tobottom, m = 18n2, 8n2 and n2, respectively, on a log-log plot. For each valueof n, at least 100 problem instances were used. Error bars showing the expectederror in the estimate are included but are smaller than the size of the plottedpoints.7.2 Balanced ClausesIn a similar way, the behavior of problems with balanced clauses can be evaluated, as shownin Figure 5. In this case the lower bound is much looser than for random soluble problems.59\nHoggThis is because, unlike the previous case, signi cant errors are made in assigning ce for thelarge number of assignments with about n=2 bad values. The bound assumes that any suchmistake gives the maximum possible contribution to Eq. (27), but in fact because of thelimited phase choices in Eq. (13), some such mistakes will nevertheless give the correct valueof the phase. Again, the intermediate problems are the most di cult for this algorithm. 1 2 5 10 20 50 100 200 m/n -510 -4 10 -3 10 -2 10 -1 10 1 P Figure 5: Probability to nd a solution for random balanced 3-SAT for n = 10 (solid)and 20 (dashed) vs. m=n, on a log-log scale. Each point represents 100 probleminstances and includes error bars which, in most cases, are smaller than the size ofthe plotted points. The gray lines show the corresponding lower bounds (1 B)2Because the bound is so poor, its asymptotic behavior does not o er a useful guideto the behavior of the algorithm for highly constrained problems. Instead, the scaling form = O(n2) is illustrated in Figure 6. The behavior is consistent with a polynomial decreasein the probability to nd a solution, but de nitive statements cannot be made from suchsmall problem sizes.8. DiscussionThe algorithm presented in this paper provides an analytic demonstration that quantumma-chines can signi cantly exploit the structure of highly constrained k-SAT problems, therebyextending the range of search problems that de nitely have e ective quantum algorithms.This contrasts with previous work on structured quantum algorithms that could only beevaluated empirically.In addition, for maximally constrained 2-SAT problems and many maximally con-strained balanced k-SAT problems, the algorithm nds a solution with probability one.Thus in these cases, failure to nd a solution de nitely indicates the problem is not soluble,i.e., the search method is complete. As described in Section 3.1, with the slight additionalcost of evaluating the number of con icts in the complement of an assignment as well asthe assignment itself for maximally constrained k-SAT, the correct corresponding 1-SATproblem can be determined. This additional information thus gives a complete search algo-60\nSolving Highly Constrained Search Problems with Quantum Computers 10 15 20 n -5 10 -4 10 -3 10 -2 10 -1 10 p\nFigure 6: Probability to nd a solution for random balanced 3-SAT vs. n with, from topto bottom, m = 8n2 and n2, respectively, on a log-log plot. For each value of n,100 problem instances were used. Error bars showing the expected error in theestimate are included but are smaller than the size of the plotted points.rithm for maximally constrained k-SAT. This contrasts with previously proposed quantumalgorithms that nd solutions with probability less than one and hence cannot guaranteeno solutions exist.One direction for future work is generalizing this algorithm to other types of combinato-rial search. For instance, the algorithm is restricted to CSPs with two values per variable,such as SAT. While other CSPs can be recast as satis ability problems, this mapping mayobscure structure inherent in the original formulation. Thus it would be useful to nd algo-rithms that apply directly to more general CSP formulations. One possible approach wouldbe based on search methods that construct solutions incrementally from smaller parts, i.e.,expanding the set of states to include assignments that give values to only some of the vari-ables in the problem. Such a representation can apply readily to CSPs with any numberof values for the variables (Hogg, 1996, 1998a). Another approach would examine replac-ing Walsh transforms with the approximate Fourier transform (Kitaev, 1995) as has beenproposed to extend an unstructured search method to cases where the size of the searchspace is not a power of two (Boyer et al., 1996). Beyond CSPs, it would be interesting toinvestigate optimization problems.Search problems with an intermediate number of constraints are the most di cult forclassical heuristics as well as structure-based quantum searches (Hogg, 1996, 1998a) based onanalogies with these classical methods. For k-SAT, these hard cases occur when the numberof clauses grows linearly with the number of variables, which is much smaller than theO(n2) used in Section 7. The intermediate number of clauses creates considerable variancein the detailed structure of the search space from one problem instance to another. Thusone cannot rely on precise a priori knowledge of the structure in designing the algorithm.Nevertheless, the average or typical structure of these harder search problems has been61\nHoggcharacterized (Cheeseman, Kanefsky, & Taylor, 1991; Hogg et al., 1996; Hogg & Williams,1994; Kirkpatrick & Selman, 1994; Monasson & Zecchina, 1996; Williams & Hogg, 1994)and may be suitable as a basis for developing appropriate search methods. Instead ofaiming for a single-step algorithm, the large variation in structure is likely to require aseries of smaller changes to the amplitudes, along with repeated tests of the consistencyof all assignments, as with previous proposals (Grover, 1997b; Hogg, 1998a). However,since a quantum algorithm can explore all search paths simultaneously, it can avoid someof the variability encountered in classical methods: namely, that due to random selection ofinitial states or random tie-breaking when evaluating heuristics. Thus a quantum algorithmcan focus on variation due only to di erences in problem instances rather than also to theparticular choices made in exploring a single search path. Ultimately, this observationmay allow quantum algorithms to more usefully exploit improved understanding of typicalproblem structure than is feasible for classical methods.This discussion raises the general issue of optimally using the information that canbe readily extracted from CSP search states, as commonly used in classical heuristics.Such information includes the number of con icts a state has and how it compares withits neighbors. Additional information is available on partial assignments, as used withincremental searches, but at the cost of involving a greatly expanded search space. Theapproach described in Section 5 suggests a useful technique is matching quantum algorithmsto the average structure of search problem ensembles.The most signi cant open question is the extent to which quantum algorithms cansolve problems in polynomial time that require exponential time classically. Factoring pro-vides one example (Shor, 1994), if, as commonly believed, it cannot be done in polynomialtime classically. By contrast, highly constrained searches can be solved in polynomial timeby both classical heuristics and, as shown in this paper, quantum machines. At the otherextreme, searches that ignore problem structure are exponential, requiring O(2n) steps clas-sically, and O(2n=2) steps on quantum computers (Boyer et al., 1996). These observationscan be summarized as: cost scalingtype of problem classical quantumunstructured exponential exponentialfactoring exponential polynomialhighly constrained polynomial polynomialThis comparison suggests some problems, including factoring, have enough structure to al-low quantum machines to operate in polynomial time but not enough for classical machinesto do so. Identifying the class of such problems is an important research direction for quan-tum computation. For example, an interesting open question is whether there is a scalingregime for the number of clauses, m, as a function of n where the probability of nding a so-lution with a quantum machine decreases only polynomially with n while classical searchesrequire an exponential number of steps, even with the best known heuristics. This questionis di cult to treat empirically, pointing to the need for further analytic investigation ofquantum algorithms and the structure of search problems.62\nSolving Highly Constrained Search Problems with Quantum ComputersAcknowledgmentsI have bene ted from discussions with Ian Gent, Carlos Mochon, Wolf Polak and EleanorRie el.ReferencesBarenco, A., Deutsch, D., & Ekert, A. (1995). Conditional quantum dynamics and logicgates. Physical Review Letters, 74, 4083{4086.Benio , P. (1982). Quantum mechanical hamiltonian models of Turing machines. J. Stat.Phys., 29, 515{546.Bennett, C. H., & Landauer, R. (1985). The fundamental physical limits of computation.Scienti c American, July, 48{56.Bernstein, E., & Vazirani, U. (1993). Quantum complexity theory. In Proc. 25th ACMSymp. on Theory of Computation, pp. 11{20.Berthiaume, A., Deutsch, D., & Jozsa, R. (1994). The stabilization of quantum compu-tations. In Proc. of the Workshop on Physics and Computation (PhysComp94), pp.60{62 Los Alamitos, CA. IEEE Press.Bouwmeester, D., et al. (1997). Experimental quantum teleportation. Nature, 390, 575{579.Boyer, M., Brassard, G., Hoyer, P., & Tapp, A. (1996). Tight bounds on quantum search-ing. In To oli, T., et al. (Eds.), Proc. of the Workshop on Physics and Computation(PhysComp96), pp. 36{43 Cambridge, MA. New England Complex Systems Institute.Brassard, G., Hoyer, P., & Tapp, A. (1998). Quantum counting. Los Alamos preprintquant-ph/9805082.Cerf, N. J., & Koonin, S. E. (1997). Monte Carlo simulation of quantum computation.In Proc. of IMACS Conf. on Monte Carlo Methods. Los Alamos preprint quant-ph/9703050.Cerf, N. J., Grover, L. K., & Williams, C. P. (1998). Nested quantum search and NP-complete problems. Los Alamos preprint quant-ph/9806078.Cerny, V. (1993). Quantum computers and intractable (NP-complete) computing problems.Physical Review A, 48, 116{119.Cheeseman, P., Kanefsky, B., & Taylor, W. M. (1991). Where the really hard problemsare. In Mylopoulos, J., & Reiter, R. (Eds.), Proceedings of IJCAI91, pp. 331{337 SanMateo, CA. Morgan Kaufmann.Chuang, I. L., Vandersypen, L. M. K., Zhou, X., Leung, D. W., & Lloyd, S. (1998). Ex-perimental realization of a quantum algorithm. Nature, 393, 143{146. Los Alamospreprint quant-ph/9801037. 63\nHoggCirac, J. I., & Zoller, P. (1995). Quantum computations with cold trapped ions. PhysicalReview Letters, 74, 4091{4094.Cory, D. G., Fahmy, A. F., & Havel, T. F. (1996). Nuclear magnetic resonance spectroscopy:An experimentally accessible paradigm for quantum computing. In To oli, T., et al.(Eds.), Proc. of the Workshop on Physics and Computation (PhysComp96), pp. 87{91Cambridge, MA. New England Complex Systems Institute.Deutsch, D. (1985). Quantum theory, the Church-Turing principle and the universal quan-tum computer. Proc. R. Soc. London A, 400, 97{117.Deutsch, D. (1989). Quantum computational networks. Proc. R. Soc. Lond., A425, 73{90.Dirac, P. A. M. (1958). The Principles of Quantum Mechanics (4th edition). Oxford.DiVincenzo, D. P. (1995). Quantum computation. Science, 270, 255{261.Feynman, R. P. (1986). Quantum mechanical computers. Foundations of Physics, 16,507{531.Feynman, R. P. (1985). QED: The Strange Theory of Light and Matter. Princeton Univ.Press, NJ.Feynman, R. P. (1996). Feynman Lectures on Computation. Addison-Wesley, Reading, MA.Garey, M. R., & Johnson, D. S. (1979). Computers and Intractability: A Guide to theTheory of NP-Completeness. W. H. Freeman, San Francisco.Gent, I. (1998). On the stupid algorithm for satis ability. Tech. rep. APES-03-1998, Strath-clyde University. Available at www.cs.strath.ac.uk/ apes/apereports.html.Gershenfeld, N., Chuang, I., & Lloyd, S. (1996). Bulk quantum computation. In To oli,T., et al. (Eds.), Proc. of the Workshop on Physics and Computation (PhysComp96),p. 134 Cambridge, MA. New England Complex Systems Institute.Grover, L. K. (1997a). Quantum computers can search arbitrarily large databases by asingle query. Los Alamos preprint quant-ph/9706005, Bell Labs.Grover, L. K. (1997b). Quantum mechanics helps in searching for a needle in a haystack.Physical Review Letters, 78, 325{328.Haroche, S., & Raimond, J.-M. (1996). Quantum computing: Dream or nightmare?. PhysicsToday, 49, 51{52.Hogg, T. (1996). Quantum computing and phase transitions in combinatorial search. J.of Arti cial Intelligence Research, 4, 91{128. Available at http://www.jair.org/ab-stracts/hogg96a.html.Hogg, T. (1998a). A framework for structured quantum search. Physica D, 120, 102{116.Los Alamos preprint quant-ph/9701013.64\nSolving Highly Constrained Search Problems with Quantum ComputersHogg, T. (1998b). Highly structured searches with quantum computers. Phys-ical Review Letters, 80, 2473{2476. Preprint at publish.aps.org/eprint/gate-way/eplist/aps1997oct30 002.Hogg, T., Huberman, B. A., & Williams, C. (1996). Phase transitions and the searchproblem. Arti cial Intelligence, 81, 1{15.Hogg, T., & Williams, C. P. (1994). The hardest constraint problems: A double phasetransition. Arti cial Intelligence, 69, 359{377.Hogg, T., & Yanik, M. (1998). Local search methods for quantum computers. Los Alamospreprint quant-ph/9802043, Xerox.Hoyer, P. (1997). E cient quantum transforms. Los Alamos preprint quant-ph/9702028.Kirkpatrick, S., & Selman, B. (1994). Critical behavior in the satis ability of randomboolean expressions. Science, 264, 1297{1301.Kitaev, A. Y. (1995). Quantum measurements and the Abelian stabilizer problem. LosAlamos preprint quant-ph/9511026.Knill, E., La amme, R., & Zurek, W. H. (1998). Resilient quantum computation. Science,279, 342{345.Landauer, R. (1994). Is quantum mechanically coherent computation useful?. In Feng,D. H., & Hu, B.-L. (Eds.), Proc. of the Drexel-4 Symposium on Quantum Nonintegra-bility Boston. International Press.Lloyd, S. (1993). A potentially realizable quantum computer. Science, 261, 1569{1571.Mackworth, A. (1992). Constraint satisfaction. In Shapiro, S. (Ed.), Encyclopedia of Arti- cial Intelligence, pp. 285{293. Wiley, NY.Minton, S., Johnston, M. D., Philips, A. B., & Laird, P. (1992). Minimizing con icts: Aheuristic repair method for constraint satisfaction and scheduling problems. Arti cialIntelligence, 58, 161{205.Monasson, R., & Zecchina, R. (1996). The entropy of the k-satis ability problem. Phys.Rev. Lett., 76, 3881{3885.Monroe, C., & Wineland, D. (1996). Future of quantum computing proves to be debatable.Physics Today, 49, 107{108.Nijenhuis, A., & Wilf, H. S. (1978). Combinatorial Algorithms for Computers and Calcula-tors (2nd edition). Academic Press, New York.Palmer, E. M. (1985). Graphical Evolution: An Introduction to the Theory of RandomGraphs. Wiley Interscience, NY.Selman, B., Levesque, H., & Mitchell, D. (1992). A new method for solving hard satis abilityproblems. In Proc. of the 10th Natl. Conf. on Arti cial Intelligence (AAAI92), pp.440{446 Menlo Park, CA. AAAI Press.65\nHoggShor, P. (1995). Scheme for reducing decoherence in quantum computer memory. PhysicalReview A, 52, 2493{2496.Shor, P. W. (1994). Algorithms for quantum computation: Discrete logarithms and fac-toring. In Goldwasser, S. (Ed.), Proc. of the 35th Symposium on Foundations ofComputer Science, pp. 124{134 Los Alamitos, CA. IEEE Press.Sleator, T., & Weinfurter, H. (1995). Realizable universal quantum logic gates. PhysicalReview Letters, 74, 4087{4090.Terhal, B. M., & Smolin, J. A. (1997). Single quantum querying of a database. Los Alamospreprint quant-ph/9705041 v4, IBM.Unruh, W. G. (1995). Maintaining coherence in quantum computers. Physical Review A,51, 992{997.Van Gelder, A., & Tsuji, Y. K. (1993). Incomplete thoughts about incomplete satis abilityproblems. In Proc. of 2nd DIMACS Challenge.Williams, C. P., & Hogg, T. (1994). Exploiting the deep structure of constraint problems.Arti cial Intelligence, 70, 73{117.\n66"}], "references": [{"title": "Conditional quantum dynamics and logic", "author": ["A. Barenco", "D. Deutsch", "A. Ekert"], "venue": null, "citeRegEx": "Barenco et al\\.,? \\Q1995\\E", "shortCiteRegEx": "Barenco et al\\.", "year": 1995}, {"title": "Quantum mechanical hamiltonian models of Turing machines", "author": ["P. Benio"], "venue": "J. Stat.", "citeRegEx": "Benio,? 1982", "shortCiteRegEx": "Benio", "year": 1982}, {"title": "The fundamental physical limits of computation", "author": ["C.H. Bennett", "R. Landauer"], "venue": null, "citeRegEx": "Bennett and Landauer,? \\Q1985\\E", "shortCiteRegEx": "Bennett and Landauer", "year": 1985}, {"title": "Quantum complexity theory", "author": ["E. Bernstein", "U. Vazirani"], "venue": null, "citeRegEx": "Bernstein and Vazirani,? \\Q1993\\E", "shortCiteRegEx": "Bernstein and Vazirani", "year": 1993}, {"title": "The stabilization of quantum compu", "author": ["A. Berthiaume", "D. Deutsch", "R. Jozsa"], "venue": null, "citeRegEx": "Berthiaume et al\\.,? \\Q1994\\E", "shortCiteRegEx": "Berthiaume et al\\.", "year": 1994}, {"title": "Experimental quantum teleportation", "author": ["D Bouwmeester"], "venue": null, "citeRegEx": "Bouwmeester,? \\Q1997\\E", "shortCiteRegEx": "Bouwmeester", "year": 1997}, {"title": "Tight bounds on quantum search", "author": ["M. Boyer", "G. Brassard", "P. Hoyer", "A. Tapp"], "venue": null, "citeRegEx": "Boyer et al\\.,? \\Q1996\\E", "shortCiteRegEx": "Boyer et al\\.", "year": 1996}, {"title": "Quantum counting", "author": ["G. Brassard", "P. Hoyer", "A. Tapp"], "venue": null, "citeRegEx": "Brassard et al\\.,? \\Q1998\\E", "shortCiteRegEx": "Brassard et al\\.", "year": 1998}, {"title": "Monte Carlo simulation of quantum computation", "author": ["N.J. Cerf", "S.E. Koonin"], "venue": null, "citeRegEx": "Cerf and Koonin,? \\Q1997\\E", "shortCiteRegEx": "Cerf and Koonin", "year": 1997}, {"title": "Nested quantum search and NP", "author": ["N.J. Cerf", "L.K. Grover", "C.P. Williams"], "venue": null, "citeRegEx": "Cerf et al\\.,? \\Q1998\\E", "shortCiteRegEx": "Cerf et al\\.", "year": 1998}, {"title": "Quantum computers and intractable (NP-complete) computing problems", "author": ["V. Cerny"], "venue": null, "citeRegEx": "Cerny,? \\Q1993\\E", "shortCiteRegEx": "Cerny", "year": 1993}, {"title": "Where the really hard problems", "author": ["P. Cheeseman", "B. Kanefsky", "W.M. Taylor"], "venue": null, "citeRegEx": "Cheeseman et al\\.,? \\Q1991\\E", "shortCiteRegEx": "Cheeseman et al\\.", "year": 1991}, {"title": "Quantum computations with cold trapped ions", "author": ["J.I. Cirac", "P. Zoller"], "venue": null, "citeRegEx": "Cirac and Zoller,? \\Q1995\\E", "shortCiteRegEx": "Cirac and Zoller", "year": 1995}, {"title": "Nuclear magnetic resonance spectroscopy", "author": ["D.G. Cory", "A.F. Fahmy", "T.F. Havel"], "venue": null, "citeRegEx": "Cory et al\\.,? \\Q1996\\E", "shortCiteRegEx": "Cory et al\\.", "year": 1996}, {"title": "Quantum theory, the Church-Turing principle and the universal quan", "author": ["D. Deutsch"], "venue": null, "citeRegEx": "Deutsch,? \\Q1985\\E", "shortCiteRegEx": "Deutsch", "year": 1985}, {"title": "Quantum computational networks", "author": ["D. Deutsch"], "venue": "Proc. R. Soc. Lond., A425, 73{90.", "citeRegEx": "Deutsch,? 1989", "shortCiteRegEx": "Deutsch", "year": 1989}, {"title": "The Principles of Quantum Mechanics (4th edition)", "author": ["P.A.M. Dirac"], "venue": "Oxford.", "citeRegEx": "Dirac,? 1958", "shortCiteRegEx": "Dirac", "year": 1958}, {"title": "Quantum computation", "author": ["D.P. DiVincenzo"], "venue": "Science, 270, 255{261.", "citeRegEx": "DiVincenzo,? 1995", "shortCiteRegEx": "DiVincenzo", "year": 1995}, {"title": "Quantum mechanical computers", "author": ["R.P. Feynman"], "venue": "Foundations of Physics, 16,", "citeRegEx": "Feynman,? 1986", "shortCiteRegEx": "Feynman", "year": 1986}, {"title": "QED: The Strange Theory of Light and Matter", "author": ["R.P. Feynman"], "venue": "Princeton Univ.", "citeRegEx": "Feynman,? 1985", "shortCiteRegEx": "Feynman", "year": 1985}, {"title": "Feynman Lectures on Computation", "author": ["R.P. Feynman"], "venue": "Addison-Wesley, Reading, MA.", "citeRegEx": "Feynman,? 1996", "shortCiteRegEx": "Feynman", "year": 1996}, {"title": "Computers and Intractability: A Guide", "author": ["M.R. Garey", "D.S. Johnson"], "venue": null, "citeRegEx": "Garey and Johnson,? \\Q1979\\E", "shortCiteRegEx": "Garey and Johnson", "year": 1979}, {"title": "On the stupid algorithm for satis ability", "author": ["I. Gent"], "venue": "Tech. rep. APES-03-1998, Strath-", "citeRegEx": "Gent,? 1998", "shortCiteRegEx": "Gent", "year": 1998}, {"title": "Bulk quantum computation", "author": ["N. Gershenfeld", "I. Chuang", "S. Lloyd"], "venue": "In To oli,", "citeRegEx": "Gershenfeld et al\\.,? \\Q1996\\E", "shortCiteRegEx": "Gershenfeld et al\\.", "year": 1996}, {"title": "Quantum computers can search arbitrarily large databases", "author": ["L.K. Grover"], "venue": null, "citeRegEx": "Grover,? \\Q1997\\E", "shortCiteRegEx": "Grover", "year": 1997}, {"title": "Quantum mechanics helps in searching for a needle in a haystack", "author": ["L.K. Grover"], "venue": null, "citeRegEx": "Grover,? \\Q1997\\E", "shortCiteRegEx": "Grover", "year": 1997}, {"title": "Quantum computing: Dream or nightmare", "author": ["S. Haroche", "Raimond", "J.-M"], "venue": null, "citeRegEx": "Haroche et al\\.,? \\Q1996\\E", "shortCiteRegEx": "Haroche et al\\.", "year": 1996}, {"title": "Quantum computing and phase transitions in combinatorial search", "author": ["T. Hogg"], "venue": "J.", "citeRegEx": "Hogg,? 1996", "shortCiteRegEx": "Hogg", "year": 1996}, {"title": "A framework for structured quantum search", "author": ["T. Hogg"], "venue": "Physica D, 120, 102{116.", "citeRegEx": "Hogg,? 1998a", "shortCiteRegEx": "Hogg", "year": 1998}, {"title": "Highly structured searches with quantum computers", "author": ["T. Hogg"], "venue": "Phys-", "citeRegEx": "Hogg,? 1998b", "shortCiteRegEx": "Hogg", "year": 1998}, {"title": "Phase transitions and the search", "author": ["T. Hogg", "B.A. Huberman", "C. Williams"], "venue": null, "citeRegEx": "Hogg et al\\.,? \\Q1996\\E", "shortCiteRegEx": "Hogg et al\\.", "year": 1996}, {"title": "The hardest constraint problems: A double phase", "author": ["T. Hogg", "C.P. Williams"], "venue": null, "citeRegEx": "Hogg and Williams,? \\Q1994\\E", "shortCiteRegEx": "Hogg and Williams", "year": 1994}, {"title": "Local search methods for quantum computers", "author": ["T. Hogg", "M. Yanik"], "venue": null, "citeRegEx": "Hogg and Yanik,? \\Q1998\\E", "shortCiteRegEx": "Hogg and Yanik", "year": 1998}, {"title": "E cient quantum transforms", "author": ["P. Hoyer"], "venue": "Los Alamos preprint quant-ph/9702028.", "citeRegEx": "Hoyer,? 1997", "shortCiteRegEx": "Hoyer", "year": 1997}, {"title": "Critical behavior in the satis ability of random", "author": ["S. Kirkpatrick", "B. Selman"], "venue": null, "citeRegEx": "Kirkpatrick and Selman,? \\Q1994\\E", "shortCiteRegEx": "Kirkpatrick and Selman", "year": 1994}, {"title": "Quantum measurements and the Abelian stabilizer problem", "author": ["A.Y. Kitaev"], "venue": "Los", "citeRegEx": "Kitaev,? 1995", "shortCiteRegEx": "Kitaev", "year": 1995}, {"title": "Resilient quantum computation", "author": ["E. Knill", "R. La amme", "W.H. Zurek"], "venue": null, "citeRegEx": "Knill et al\\.,? \\Q1998\\E", "shortCiteRegEx": "Knill et al\\.", "year": 1998}, {"title": "Is quantum mechanically coherent computation useful", "author": ["R. Landauer"], "venue": "Feng,", "citeRegEx": "Landauer,? 1994", "shortCiteRegEx": "Landauer", "year": 1994}, {"title": "A potentially realizable quantum computer", "author": ["S. Lloyd"], "venue": "Science, 261, 1569{1571.", "citeRegEx": "Lloyd,? 1993", "shortCiteRegEx": "Lloyd", "year": 1993}, {"title": "Constraint satisfaction", "author": ["A. Mackworth"], "venue": "Shapiro, S. (Ed.), Encyclopedia of Arti-", "citeRegEx": "Mackworth,? 1992", "shortCiteRegEx": "Mackworth", "year": 1992}, {"title": "Minimizing con icts: A", "author": ["S. Minton", "M.D. Johnston", "A.B. Philips", "P. Laird"], "venue": null, "citeRegEx": "Minton et al\\.,? \\Q1992\\E", "shortCiteRegEx": "Minton et al\\.", "year": 1992}, {"title": "The entropy of the k-satis ability problem", "author": ["R. Monasson", "R. Zecchina"], "venue": null, "citeRegEx": "Monasson and Zecchina,? \\Q1996\\E", "shortCiteRegEx": "Monasson and Zecchina", "year": 1996}, {"title": "Future of quantum computing proves to be debatable", "author": ["C. Monroe", "D. Wineland"], "venue": null, "citeRegEx": "Monroe and Wineland,? \\Q1996\\E", "shortCiteRegEx": "Monroe and Wineland", "year": 1996}, {"title": "Combinatorial Algorithms for Computers and Calcula", "author": ["A. Nijenhuis", "H.S. Wilf"], "venue": null, "citeRegEx": "Nijenhuis and Wilf,? \\Q1978\\E", "shortCiteRegEx": "Nijenhuis and Wilf", "year": 1978}, {"title": "Graphical Evolution: An Introduction to the Theory of Random", "author": ["E.M. Palmer"], "venue": null, "citeRegEx": "Palmer,? \\Q1985\\E", "shortCiteRegEx": "Palmer", "year": 1985}, {"title": "A new method for solving hard satis ability", "author": ["B. Selman", "H. Levesque", "D. Mitchell"], "venue": null, "citeRegEx": "Selman et al\\.,? \\Q1992\\E", "shortCiteRegEx": "Selman et al\\.", "year": 1992}, {"title": "Scheme for reducing decoherence in quantum computer memory", "author": ["P. Shor"], "venue": "Physical", "citeRegEx": "Shor,? 1995", "shortCiteRegEx": "Shor", "year": 1995}, {"title": "Algorithms for quantum computation: Discrete logarithms and fac", "author": ["P.W. Shor"], "venue": null, "citeRegEx": "Shor,? \\Q1994\\E", "shortCiteRegEx": "Shor", "year": 1994}, {"title": "Realizable universal quantum logic gates", "author": ["T. Sleator", "H. Weinfurter"], "venue": null, "citeRegEx": "Sleator and Weinfurter,? \\Q1995\\E", "shortCiteRegEx": "Sleator and Weinfurter", "year": 1995}, {"title": "Single quantum querying of a database", "author": ["B.M. Terhal", "J.A. Smolin"], "venue": null, "citeRegEx": "Terhal and Smolin,? \\Q1997\\E", "shortCiteRegEx": "Terhal and Smolin", "year": 1997}, {"title": "Maintaining coherence in quantum computers", "author": ["W.G. Unruh"], "venue": "Physical Review A,", "citeRegEx": "Unruh,? 1995", "shortCiteRegEx": "Unruh", "year": 1995}, {"title": "Incomplete thoughts about incomplete satis ability", "author": ["A. Van Gelder", "Y.K. Tsuji"], "venue": null, "citeRegEx": "Gelder and Tsuji,? \\Q1993\\E", "shortCiteRegEx": "Gelder and Tsuji", "year": 1993}, {"title": "Exploiting the deep structure of constraint problems", "author": ["C.P. Williams", "T. Hogg"], "venue": null, "citeRegEx": "Williams and Hogg,? \\Q1994\\E", "shortCiteRegEx": "Williams and Hogg", "year": 1994}], "referenceMentions": [{"referenceID": 17, "context": "Introduction Quantum computers (Benio , 1982; Bernstein & Vazirani, 1993; Deutsch, 1985, 1989; DiVincenzo, 1995; Feynman, 1986; Lloyd, 1993) o er a new approach to combinatorial search problems (Garey & Johnson, 1979) with quantum parallelism, i.", "startOffset": 31, "endOffset": 140}, {"referenceID": 18, "context": "Introduction Quantum computers (Benio , 1982; Bernstein & Vazirani, 1993; Deutsch, 1985, 1989; DiVincenzo, 1995; Feynman, 1986; Lloyd, 1993) o er a new approach to combinatorial search problems (Garey & Johnson, 1979) with quantum parallelism, i.", "startOffset": 31, "endOffset": 140}, {"referenceID": 38, "context": "Introduction Quantum computers (Benio , 1982; Bernstein & Vazirani, 1993; Deutsch, 1985, 1989; DiVincenzo, 1995; Feynman, 1986; Lloyd, 1993) o er a new approach to combinatorial search problems (Garey & Johnson, 1979) with quantum parallelism, i.", "startOffset": 31, "endOffset": 140}, {"referenceID": 47, "context": "A quantum algorithm to rapidly factor integers (Shor, 1994), a problem thought to be intractable for classical machines, o ers a dramatic example of how these features of quantum mechanics can be exploited.", "startOffset": 47, "endOffset": 59}, {"referenceID": 10, "context": "While several additional algorithms have been developed (Boyer, Brassard, Hoyer, & Tapp, 1996; Cerny, 1993; Grover, 1997b, 1997a; Hogg, 1996, 1998a; Terhal & Smolin, 1997), the extent to which quantum searches can improve on heuristically guided classical search methods remains an open question.", "startOffset": 56, "endOffset": 171}, {"referenceID": 28, "context": "A suggestion that this is possible has been observed empirically for highly constrained problems (Hogg, 1998a), but the complexity of the algorithm precluded a de nitive theoretical analysis of its behavior.", "startOffset": 97, "endOffset": 110}, {"referenceID": 17, "context": "For example (DiVincenzo, 1995), an atom in its ground state could represent a bit set to 0, and an excited state for 1.", "startOffset": 12, "endOffset": 30}, {"referenceID": 27, "context": "Because quantum mechanics is linear and the normalization condition must always be satis ed, these operations are limited to unitary linear operators (Hogg, 1996).", "startOffset": 150, "endOffset": 162}, {"referenceID": 6, "context": "Solving Highly Constrained Search Problems with Quantum Computers cases the operation can be performed in a time that grows only as a polynomial in n by quantum computers (Boyer et al., 1996; Hoyer, 1997).", "startOffset": 171, "endOffset": 204}, {"referenceID": 33, "context": "Solving Highly Constrained Search Problems with Quantum Computers cases the operation can be performed in a time that grows only as a polynomial in n by quantum computers (Boyer et al., 1996; Hoyer, 1997).", "startOffset": 171, "endOffset": 204}, {"referenceID": 20, "context": "Important examples of such operations are reversible classical programs (Bennett & Landauer, 1985; Feynman, 1996).", "startOffset": 72, "endOffset": 113}, {"referenceID": 19, "context": "This capability for interference (Bernstein & Vazirani, 1993; Feynman, 1985) distinguishes quantum computers from probabilistic classical machines.", "startOffset": 33, "endOffset": 76}, {"referenceID": 39, "context": "Constraint satisfaction problems (CSPs) (Mackworth, 1992) are an example.", "startOffset": 40, "endOffset": 57}, {"referenceID": 22, "context": "This makes highly constrained instances particularly easy since the good value for each variable can often be determined from its assigned value that appears most often in the clauses (Gent, 1998).", "startOffset": 184, "endOffset": 196}, {"referenceID": 29, "context": "Solving 1-SAT A quantum computer, operating on superpositions of all assignments for any 1-SAT problem, can nd a solution in a single search step (Hogg, 1998b).", "startOffset": 146, "endOffset": 159}, {"referenceID": 16, "context": "Traditionally, this is done using the ket notation introduced by Dirac (1958). For instance, the superposition described by the state vector of Eq.", "startOffset": 65, "endOffset": 78}, {"referenceID": 27, "context": "Such phases have been used in previous algorithms (Hogg, 1996; Grover, 1997b) and can be implemented through a single evaluation of f(s) by setting the extra variable to be a superposition of its two values (Boyer et al.", "startOffset": 50, "endOffset": 77}, {"referenceID": 6, "context": "Such phases have been used in previous algorithms (Hogg, 1996; Grover, 1997b) and can be implemented through a single evaluation of f(s) by setting the extra variable to be a superposition of its two values (Boyer et al., 1996).", "startOffset": 207, "endOffset": 227}, {"referenceID": 6, "context": "The matrixW is unitary and can be implemented e ciently (Boyer et al., 1996; Grover, 1997b).", "startOffset": 56, "endOffset": 91}, {"referenceID": 6, "context": "As described above, the matrix operations and forming the initial state can be done with a series of O(n) bit operations (Boyer et al., 1996).", "startOffset": 121, "endOffset": 141}, {"referenceID": 37, "context": "These remain signi cant issues in the development of quantum computation (Landauer, 1994; Unruh, 1995; Haroche & Raimond, 1996; Monroe & Wineland, 1996), but at this point seem unlikely to be fundamental di culties (Berthiaume, Deutsch, & Jozsa, 1994; Shor, 1995; Knill, La amme, & Zurek, 1998).", "startOffset": 73, "endOffset": 152}, {"referenceID": 50, "context": "These remain signi cant issues in the development of quantum computation (Landauer, 1994; Unruh, 1995; Haroche & Raimond, 1996; Monroe & Wineland, 1996), but at this point seem unlikely to be fundamental di culties (Berthiaume, Deutsch, & Jozsa, 1994; Shor, 1995; Knill, La amme, & Zurek, 1998).", "startOffset": 73, "endOffset": 152}, {"referenceID": 46, "context": "These remain signi cant issues in the development of quantum computation (Landauer, 1994; Unruh, 1995; Haroche & Raimond, 1996; Monroe & Wineland, 1996), but at this point seem unlikely to be fundamental di culties (Berthiaume, Deutsch, & Jozsa, 1994; Shor, 1995; Knill, La amme, & Zurek, 1998).", "startOffset": 215, "endOffset": 294}, {"referenceID": 28, "context": "In particular, because the algorithm requires only a single step, decoherence is likely to be less of a di culty for it than search algorithms that require multiple repeated steps to move signi cant amplitude to solutions (Grover, 1997b; Hogg, 1998a).", "startOffset": 222, "endOffset": 250}, {"referenceID": 44, "context": "(14), j j 2 n2 n X y=n k+3 ny! When n k + 3 n=2, the sum over binomial coe cients can be bounded (Palmer, 1985) to give j j 2 (n 1) n k 3! n+ 1 (k 3) n + 1 2(k 3) 2 (n 1) nk 3 (k 3)! (28) 55", "startOffset": 97, "endOffset": 111}, {"referenceID": 45, "context": "Hence, to provide comparison with the quantum search results presented below, these problems were also solved with the classical GSAT procedure (Selman et al., 1992), limiting each trial to use no more than 2n steps before a new random initial state was selected.", "startOffset": 144, "endOffset": 165}, {"referenceID": 30, "context": "As with other classical and quantum search methods that use problem structure, the hardest cases are for problems with an intermediate number of constraints (Hogg et al., 1996).", "startOffset": 157, "endOffset": 176}, {"referenceID": 35, "context": "Another approach would examine replacing Walsh transforms with the approximate Fourier transform (Kitaev, 1995) as has been proposed to extend an unstructured search method to cases where the size of the search space is not a power of two (Boyer et al.", "startOffset": 97, "endOffset": 111}, {"referenceID": 6, "context": "Another approach would examine replacing Walsh transforms with the approximate Fourier transform (Kitaev, 1995) as has been proposed to extend an unstructured search method to cases where the size of the search space is not a power of two (Boyer et al., 1996).", "startOffset": 239, "endOffset": 259}], "year": 2011, "abstractText": null, "creator": "dvipsk 5.58c Copyright 1986, 1994 Radical Eye Software"}}}