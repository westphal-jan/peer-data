{"id": "1111.2664", "review": {"conference": "NIPS", "VERSION": "v1", "DATE_OF_SUBMISSION": "11-Nov-2011", "title": "A Collaborative Mechanism for Crowdsourcing Prediction Problems", "abstract": "other testing competitions such their miss netflix prize have proven reasonably practical regarding a method of \" crowdsourcing \" prediction performance. increasingly unpredictable strategies invite a number of impacts, featuring in instance incentive instability they cause for individual participants. we institute technological new innovation, called a crowdsourced learning mechanism, fundamentally explaining participants simply \" learn \" default hypothesis for a given optimal task. the challenge devi radically from the concept of a prediction market, where traders wait on the likelihood triggering a future event. in our framework, online forecast specification will publish the current hypothesis, and operators can modify this hypothesis beyond rely on an adversary. her critical incentive property assumes that a participant will profit an efficiency throughout scales according versus how much added update exceeds performance on a released test set.", "histories": [["v1", "Fri, 11 Nov 2011 05:09:33 GMT  (21kb)", "http://arxiv.org/abs/1111.2664v1", "Full version of the extended abstract which appeared in NIPS 2011"]], "COMMENTS": "Full version of the extended abstract which appeared in NIPS 2011", "reviews": [], "SUBJECTS": "cs.LG cs.GT", "authors": ["jacob d abernethy", "rafael m frongillo"], "accepted": true, "id": "1111.2664"}, "pdf": {"name": "1111.2664.pdf", "metadata": {"source": "CRF", "title": "A Collaborative Mechanism for Crowdsourcing Prediction Problems", "authors": ["Jacob Abernethy", "Rafael M. Frongillo"], "emails": ["jake@cs.berkeley.edu", "raf@cs.berkeley.edu"], "sections": [{"heading": null, "text": "ar X\niv :1\n11 1.\n26 64\nv1 ["}, {"heading": "1 Introduction", "text": "The last several years has revealed a new trend in Machine Learning: prediction and learning problems rolled into prize-driven competitions. One of the first, and certainly the most wellknown, was the Netflix prize released in the Fall of 2006. Netflix, aiming to improve the algorithm used to predict users\u2019 preferences on its database of films, released a dataset of 100M ratings to the public and asked competing teams to submit a list of predictions on a test set withheld from the public. Netflix offered $1,000,000 to the first team achieving prediction\naccuracy exceeding a given threshold, a goal that was eventually met. This competitive model for solving a prediction task has been used for a range of similar competitions since, and there is even a new company (kaggle.com) that creates and hosts such competitions. Such prediction competitions have proven quite valuable for a couple of important reasons: (a) they leverage the abilities and knowledge of the public at large, commonly known as \u201ccrowdsourcing\u201d, and (b) they provide an incentivized mechanism for an individual or team to apply their own knowledge and techniques which could be particularly beneficial to the problem at hand. This type of prediction competition provides a nice tool for companies and institutions that need help with a given prediction task yet can not afford to hire an expert. The potential leverage can be quite high: the Netflix prize winners apparently spent more than $1,000,000 in effort on their algorithm alone.\nDespite the extent of its popularity, is the Netflix competition model the ideal way to \u201ccrowdsource\u201d a learning problem? We note several weaknesses:\nIt is anti-collaborative. Competitors are strongly incentivized to keep their techniques private. This is in stark contrast to many other projects that rely on crowdsourcing \u2013 Wikipedia being a prime example, where participants must build off the work of others. Indeed, in the case of the Netflix prize, not only do leading participants lack incentives to share, but the work of non-winning competitors is effectively wasted.\nThe incentives are skewed and misaligned. The winner-take-all prize structure means that second place is as good as having not competed at all. This ultimately leads to an equilibrium where only a few teams are actually competing, and where potential new teams never form since catching up seems so unlikely. In addition, the fixed achievement benchmark, set by Netflix as a 10% improvement in prediction RMSE over a baseline, leads to misaligned incentives. Effectively, the prize structure implies that an improvement of %9.9 percent is worth nothing to Netflix, whereas a 20% improvement is still only worth $1,000,000 to Netflix. This is clearly not optimal.\nThe nature of the competition precludes the use of proprietary methods. By requiring that the winner reveal the winning algorithm, potential competitors utilizing nonopen software or proprietary techniques will be unwilling to compete. By participating in the competition, a user must effectively give away his intellectual property.\nIn this paper we describe a new and very general mechanism to crowdsource prediction/learning problems. Our mechanism requires participants to place bets, yet the space they are betting over is the set of hypotheses for the learning task at hand. At any given time the mechanism publishes the current hypothesis w and participants can wager on a modification of w to w\u2032, upon which the modified w\u2032 is posted. Eventually the wagering period finishes, a set of test data is revealed, and each participant receives a payout according to their bets. The critical property is that every trader\u2019s profit scales according to how well their modification improved the solution on the test data.\nThe framework we propose has many qualities similar to that of an information or prediction market, and many of the ideas derive from recent research on the design of automated market makers [7, 8, 3, 4, 1]. Many information markets already exist; at sites like Intrade.com and Betfair.com, individuals can bet on everything ranging from election outcomes to geopolitical events. There has been a burst of interest in such markets in recent years, not least of which is due to their potential for combining large amounts of information from a range of sources. In the words of Hanson et al [9]: \u201cRational expectations theory predicts that, in equilibrium, asset prices will reflect all of the information held by market participants. This theorized information aggregation property of prices has lead economists to become increasingly interested in using securities markets to predict future events.\u201d In practice, prediction markets have proven impressively accurate as a forecasting tool [11, 2, 12].\nThe central contribution of the present paper is to take the framework of a prediction market as a tool for information aggregation and to apply this tool for the purpose of \u201caggregating\u201d a hypothesis (classifier, predictor, etc.) for a given learning problem. The crowd of ML researchers, practitioners, and domain experts represents a highly diverse range of expertise and algorithmic tools. In contrast to the Netflix prize, which pitted teams of participants against each other, the mechanism we propose allows for everyone to contribute whatever knowledge they may have available towards the final solution. In a sense, this approach decentralizes the process of solving the task, as individual experts can potentially apply their expertise to a subset of the problem on which they have an advantage. Whereas a market price can be thought of as representing a consensus estimate of the value of an asset, our goal is to construct a consensus hypothesis reflecting all the knowledge and capabilities about a particular learning problem1.\nLayout: We begin in Section 2.1 by introducing the simple notion of a generalized scoring rule L(\u00b7, \u00b7) representing the \u201closs function\u201d of the learning task at hand. In Section 2.2 we describe our proposed Crowdsourced Learning Mechanism (CLM) in detail, and discuss how to structure a CLM for a particular scoring function L, in order that the traders are given incentives to minimize L. In Section 3 we give an example based on the design of Huffman codes. In Section 4 we discuss previous work on the design of prediction markets using an automated prediction market maker (APMM). We observe that any APMM is just a particular CLM and, moreover, we fully classify what types of problems can be solved with an APMM. In Section 5 we finish by considering two learning settings (e.g. linear regression) and we construct a CLM for each. The proofs have been omitted throughout, but these are available in the full version of the present paper.\nNotation: Given a smooth strictly convex functionR : Rd \u2192 R, and points x,y \u2208 dom(R), we define the Bregman divergence DR(x,y) as the quantity R(x)\u2212R(y)\u2212\u2207R(y) \u00b7 (x\u2212 y). For any convex function R, we let R\u2217 denote the convex conjugate of R, that is R\u2217(y) :=\n1It is worth noting that Barbu and Lay utilized concepts from prediction markets to design algorithms for classifier aggregation [10], although their approach was unrelated to crowdsourcing.\nsup x\u2208dom(R) y \u00b7 x \u2212 R(x). We shall use \u2206(S) to refer to the set of integrable probability distributions over the set S, and \u2206n to refer to the set of probability vectors p \u2208 R n. The function H : \u2206n \u2192 R shall denote the entropy function, that is H(p) := \u2212 \u2211n\ni=1 p(i) logp(i). We use the notation KL(p;q) to describe the relative entropy or Kullback-Leibler divergence between distributions p,q \u2208 \u2206n, that is KL(p;q) := \u2211n i=1 p(i) log p(i) q(i)\n. We will also use ei \u2208 R\nn to denote the ith standard basis vector, having a 1 in the ith coordinate and 0\u2019s elsewhere."}, {"heading": "2 Scoring Rules and Crowdsourced Learning Mecha-", "text": "nisms\nWe shall now provide a full description of our proposed crowdsourced learning mechanism. We begin by discussing the notion of a scoring rule, a well-studied object from statistics for the purpose eliciting \u201cgood\u201d probability forecasts [6]. We propose a weaker notion which we call a generalized scoring rule L(\u00b7, \u00b7) which shall reflect the loss function of the learning problem at hand. We then proceed to describe the CLM framework, and in particular we present the important case when a CLM implements a generalized scoring rule L. We provide a range of properties and results for L-CLMs."}, {"heading": "2.1 Generalized Scoring Rules", "text": "For the remainder of this section, we shall let H denote some set of hypotheses, which we will assume is a convex subset of Rn. We let O be some arbitrary set of outcomes. We use the symbol X to refer to either an element of O, or a random variable taking values in O.\nWe recall the notion of a scoring rule, a concept that arises frequently in economics and statistics [6].\nDefinition 1. Let P \u2286 \u2206(O) be some convex set of distributions on an outcome space O. A scoring rule is a function S : P\u00d7O \u2192 R where, for all P \u2208 P, P \u2208 argmaxQ\u2208P EX\u223cPS(Q,X).\nIn other words, if you are paid S(P,X) upon stating belief P \u2208 P and outcome X occurring, then you maximize your expected utility by stating your true belief. We offer a much weaker notion:\nDefinition 2. Given a convex hypothesis space H \u2282 Rn and an outcome space O, let L : H\u00d7O \u2192 R be a continuous function. Given any P \u2208 \u2206(O), let\nWL(P ) := argmin w\u2208H EX\u223cP [L(w;X)].\nThen we say that L is a Generalized Scoring Rule (GSR) if WL(P ) is a nonempty convex set for every P \u2208 \u2206(O).\nThe generalized scoring rule shall represent the \u201closs function\u201d for the learning problem at hand, and in Section 2.2 we will see how L is utilized in the mechanism. The hypothesis w shall represent the advice we receive from the crowd, X shall represent the test data to be revealed at the close of the mechanism, and L(w;X) shall represent the loss of the advised w on the data X . Notice that we do not define L to be convex in its first argument as this does not hold for many important cases. Instead, we require the weaker condition that EX [L(w;X)] is minimized on a convex set for any distribution on X .\nOur scoring rule differs from traditional scoring rules in an important way. Instead of starting with the desire know about the true value of X , and then designing a scoring rule which incentivizes participants to elicit their belief P \u2208 P, our objective is precisely to minimize our scoring rule. In other words, traditional scoring rules were a means to an end (eliciting P ) but our generalized scoring rule is the end itself. One can recover the traditional scoring rule definition by setting H = P and imposing the constraint that P \u2208 WL(P ).\nA useful class of GSRs L are those based on a Bregman divergence.\nDefinition 3. We say that a GSR L : H \u00d7 O \u2192 R is divergence-based if there exists an alternative hypothesis space H\u2032 \u2282 Rm, for some m, where we can write\nL(w;X) \u2261 DR(\u03c1(X), \u03c8(w)) + f(X) (1)\nfor arbitrary maps \u03c1 : O \u2192 H\u2032, f : O \u2192 R, and \u03c8 : H \u2192 H\u2032, and any closed strictly convex R : H\u2032 \u2192 R whose convex conjugate R\u2217 is finite on all of Rm.\nThis property allows us to think of L(w;X) as a kind of distance between \u03c1(X) and \u03c8(w). Clearly then, the minimum value of L for a given X will be attained when \u03c8(w) = \u03c1(X), given that DR(x,x) = 0 for any Bregman divergence. In fact, as the following proposition shows, we can even think of the expected value E[L(w;X)], as a distance between E[\u03c1(X)] and \u03c8(w).\nProposition 1. Given a divergence-based GSR L(w;X) = DR(\u03c1(X), \u03c8(w)) + f(X) and a belief distribution P on O, we have WL(P ) = \u03c8 \u22121 ( EX\u223cP [\u03c1(X)] ) .\nProof. All expectations in the following are over X \u223c P . Expanding L, we have\nWL(P ) = argmin w\u2208H\n{\nE [ R(\u03c1(X))\u2212 R(\u03c8(w))\u2212\u2207R(\u03c8(w)) \u00b7 (\u03c1(X)\u2212 \u03c8(w)) + f(X)\n]}\n= argmin w\u2208H\n{ E [R(\u03c1(X)) + f(X)]\u2212R(\u03c8(w))\u2212\u2207R(\u03c8(w)) \u00b7 (E[\u03c1(X)]\u2212 \u03c8(w)) }\n= argmin w\u2208H\n{ R(E[\u03c1(X)])\u2212 R(\u03c8(w))\u2212\u2207R(\u03c8(w)) \u00b7 (E[\u03c1(X)]\u2212 \u03c8(w)) }\n= argmin w\u2208H\n{ DR(E[\u03c1(X)], \u03c8(w)) } = \u03c8\u22121 ( E[\u03c1(X)] )\nwhere the last line follows from the strict convexity of R and properties of divergences.\nWe now can see that the divergence-based property greatly simplifies the task of minimizing L; instead of worrying about E[L(\u00b7;X)] one can simply base the hypothesis directly on the expectation E[\u03c1(X)]. As we will see in section 4, this also leads to efficient prediction markets and crowdsourcing mechanisms."}, {"heading": "2.2 The Crowdsourced Learning Mechanism", "text": "We will now define our actual mechanism rigorously.\nDefinition 4. A Crowdsourced Learning Mechanism (CLM) is the procedure in Algorithm 1 as defined by the tuple (H,O, Cost, Payout). The function Cost : H\u00d7H \u2192 R sets the cost charged to a participant that makes a modification to the posted hypothesis. The function Payout : H\u00d7H\u00d7O \u2192 R determines the amount paid to each participant when the outcome is revealed to be X.\nAlgorithm 1 Crowdsourced Learning Mechanism for (H,O, Cost, Payout)\n1: Mechanism sets initial hypothesis to some w0 \u2208 H 2: for rounds t = 0, 1, 2, . . . do 3: Mechanism posts current hypothesis wt \u2208 H 4: Some participant places a bid on the update wt 7\u2192 w \u2032 5: Mechanism charges participant Cost(wt,w \u2032) 6: Mechanisms updates hypothesis wt+1 \u2190 w \u2032 7: end for\n8: Market closes after T rounds and the outcome (test data) X \u2208 O is revealed 9: for each t do 10: Participant responsible for the update wt 7\u2192 wt+1 receives Payout(wt,wt+1;X) 11: end for\nThe above procedure describes the process by which participants can provide advice to the mechanism to select a good w, and the profit they earn by doing so. Of course, this profit will precisely determine the incentives of our mechanism, and hence a key question is: how can we design Cost and Payout so that participants are incentivized to provide good hypotheses? The answer is that we shall structure the incentives around a GSR L(w;X) chosen by the mechanism designer.\nDefinition 5. For a CLM A = (H,O, Cost, Payout), denote the ex-post profit for the bid (w 7\u2192 w\u2032) when the outcome is X \u2208 O by Profit(w,w\u2032;X) := Payout(w,w\u2032;X) \u2212 Cost(w,w\u2032). We say that A implements a GSR L : H\u2032 \u00d7O \u2192 R if there exists a surjective map \u03d5 : H \u2192 H\u2032 such that for all w1,w2 \u2208 H and X \u2208 O,\nProfit(w1,w2;X) = L(\u03d5(w1);X)\u2212 L(\u03d5(w2);X). (2)\nIf additionally H\u2032 = H and \u03d5 = idH, we call A an L-CLM and say that A is L-incentivized.\nWhen a CLM implements a given L, the incentives are structured in order that the participants will work to minimize L(w;X). Of course, the input X is unknown to the participants, yet we can assume that the mechanism has provided a public \u201ctraining set\u201d to use in a learning algorithm. The participants are thus asked not only to propose a \u201cgood\u201d hypothesis wt but to wager on whether the update wt\u22121 7\u2192 wt improves generalization error. It is worth making clear that knowledge of the true distribution on X provides a straightforward optimal strategy.\nProposition 2. Given a GSR L : H \u00d7 O \u2192 R and an L-CLM (Cost, Payout), any participant who knows the true distribution P \u2208 P over X will maximize expected profit by modifying the hypothesis to any w \u2208 WL(P ).\nProof. By equation (2) we can directly compute the expected profit; for any current hypothesis w \u2208 H, we have\nargmax w\u2032\u2208H EX\u2208P\n[ Profit(w,w\u2032;X) ] = argmax\nw\u2032\u2208H\nEX\u2208P\n[ L(w;X)\u2212 L(w\u2032;X) ]\n= argmin w\u2032\u2208H EX\u2208P\n[ L(w\u2032;X) ] = WL(P ),\nwhich completes the proof.\nCost of operating a CLM. It is clear that the agent operating the mechanism must pay the participants at the close of the competition, and is thus at risk of losing money (in fact, it is possible he may gain). How much money is lost depends on the bets (wt 7\u2192 wt+1) made by the participants, and of course the final outcome X . The agent has a clear interest in knowing precisely the potential cost \u2013 fortunately this cost is easy to compute. The loss to the agent is clearly the total ex-post profit earned by the participants, and by construction this sum telescopes:\n\u2211T t=0 Profit(wt,wt+1;X) = L(w0;X)\u2212L(wT ;X). This is a simple yet\nappealing property of the CLM: the agent pays only as much in reward to the participants as it benefits from the improvement of wT over the initial w0. It is worth noting that this value could be negative when wT is actually \u201cworse\u201d than w0; in this case, as we shall see in section 3, the CLM can act as an insurance policy with respect to the mistakes of the participants. A more typical scenario, of course, is where the participants provide an improved hypothesis, in which case the CLM will run at a cost. We can compute the WorstCaseLoss(L-CLM) := maxw\u2208H,X\u2208O (L(w0;X)\u2212 L(w;X)). Given a budget of size $B, the mechanism can always rescale L in order that WorstCaseLoss(L-CLM) = B. This requires, of course, that the WorstCaseLoss is finite.\nComputational efficiency of operating a CLM. We shall say that a CLM has the efficient computation (EC) property if both Cost and Payout are efficiently computable functions. We shall say a CLM has the tractable trading (TT) property if, given a current hypothesis w, a belief P \u2208 \u2206(O) and a budget B, one can efficiently compute an element of the set\nargmax w\u2032\u2208H\n{\nEX\u223cP\n[ Profit(w,w\u2032, X) ] : Cost(w,w\u2032) \u2264 B\n}\n.\nThe EC property ensures that the mechanism operator can run the CLM efficiently. The TT property says that participants can compute the optimal hypothesis to bet on given a belief on the outcome and a budget. This is absolutely essential for the CLM to successfully aggregate the knowledge and expertise of the crowd \u2013 without it, despite their motivation to lower L(; ), the participants would not be able to compute the optimal bet.\nSuitable collateral requirements. We say that a CLM has the escrow (ES) property if the Cost and Payout functions are structured in order that, given any wager (w 7\u2192 w\u2032), we have that Payout(w,w\u2032;X) \u2265 0 for all X \u2208 O. It is clear that, when designing an L-CLM for a particular L, the Payout function is fully specified once Cost is fixed, since we have the relation Payout(w,w\u2032;X) = L(w;X)\u2212L(w\u2032;X)+Cost(w,w\u2032) for every w,w\u2032 \u2208 H and X \u2208 O. A curious reader might ask, why not simply set Cost(w,w\u2032) \u2261 0 and Payout \u2261 Profit? The problem with this approach is that potentially Payout(w,w\u2032;X) < 0 which implies that the participant who wagered on (w 7\u2192 w\u2032) can be indebted to the mechanism and could default on this obligation. Thus the Cost function should be set in order to require every participant to deposit at least enough collateral in escrow to cover any possible losses.\nSubsidizing with a voucher pool. One practical weakness of a wagering-based mechanism is that individuals may be hesitant to participate when it requires depositing actual money into the system. This can be allayed to a reasonable degree by including a voucher pool where each of the first m participants may receive a voucher in the amount of $C. These candidates need not pay to participate, yet have the opportunity to win. Of course, these vouchers must be paid for by the agent running the mechanism, and hence a value of mC is added to the total operational cost."}, {"heading": "3 Warm-up: Compressing an Unfamiliar Data Stream", "text": "Let us now introduce a particular setting motivated by a well-known problem in information theory. Imagine a firm is looking to do compression on an unfamiliar channel, and from this channel the firm will receive a stream of m characters from an n-sized alphabet which we shall index by [n]. The goal is to select a binary encoding of this alpha in such a way that minimizes the total bits required to store the data, as a cost of $1 is required for each bit.\nA first-order approach to encode such a stream is to assign a probability distribution q \u2208 \u2206n to the alphabet, and to select an encoding of character i with a binary word of length log(1/q(i)) (we ignore round-off for simplicity). This can be achieved using Huffman Codes for example, and we refer the reader to Cover and Thomas ([5], Chapter 5) for more details. Thus, given a distribution q, the firm pays L(q; i) = \u2212 logq(i) for each character i. It is easy to see that if the characters are sampled from some \u201ctrue\u201d distribution p, then the expected cost L(q;p) := Ei\u223cp [L(q; i)] = KL(p;q)+H(p), which is minimized at q = p. Not knowing the true distribution p, the firm is thus interested in finding a q with a low expected cost L(q;p).\nAn attractive option available to the firm is to crowdsource the task of lowering this cost L(\u00b7; \u00b7) by setting up an L-CLM. It is reasonably likely that outside individuals have private information about the behavior of the channel and, in particular, may be able to provide a better estimate q of the true distribution of the characters in the channel. As just discussed, the better the estimate the cheaper the compression.\nWe set H = \u2206n and O = [n], where a hypothesis q represents the proposed distribution over the n characters, and X is some character sampled uniformly from the stream after it\nhas been observed. We define Cost and Payout as\nCost(q,q\u2032) := max i\u2208[n] log(q(i)/q\u2032(i)), Payout(q,q\u2032; i) := log(q(i)/q\u2032(i)) + Cost(q,q\u2032),\nwhich is clearly an L-CLM for the loss defined above. It is worth noting that L is a divergencebased GSR if we take R(q) = \u2212H(q), \u03c1(i) = ei, f \u2261 0, \u03c8 \u2261 id\u2206n, using the convention 0 log 0 = 0 (in fact, L is the LMSR). Finally, the firm will initially set q0 to be its best guess of p, which we will assume to be uniform (but need not be).\nWe have devised this payout scheme according to the selection of a single character i, and it is worth noting that because this character is sampled uniformly at random from the stream (with private randomness), the participants cannot know which character will be released. This forces the participants to wager on the empirical distribution p\u0302 of the characters from the stream. A reasonable alternative, and one which lowers the payment variance, is to payout according to the L(q; p\u0302), which is also equal to the average of L(q; i) when i is chosen uniformly from the stream.\nThe obvious question to ask is: how does this CLM benefit the firm that wants to design the encoding? More precisely, if the firm uses the final estimate qT from the mechanism, instead of the initial guess q0, what is the trade-off between the money paid to participants and the money gained by using the crowdsourced hypothesis? At first glance, it appears that this trade-off can be arbitrarily bad: the worst case cost of encoding the stream using the final estimate qT is supi,qT \u2212 log(qT (i)) = \u221e. Amazingly, however, by virtue of the aligned incentives, the firm has a very strong control of its total cost (the CLM cost plus the encoding cost). Suppose the firm scales L by a parameter \u03b1, to separate the scale of the CLM from the scale of the encoding cost (which we assumed to be $1 per bit). Then given any initial estimate q0 and final estimate qT , the expected total cost over p is\nTotal expected cost =\nEncoding cost of using qT given p \ufe37 \ufe38\ufe38 \ufe37\nH(p) + KL(p;qT ) +\nMechanism\u2019s cost of getting advice qT \ufe37 \ufe38\ufe38 \ufe37\n\u03b1(KL(p;q0)\u2212KL(p;qT ))\n= H(p) + (1\u2212 \u03b1)KL(p;qT ) + \u03b1KL(p;q0)\nLet us spend a moment to analyze the above expression. Imagine that the firm set \u03b1 = 1. Then the total cost of the firm would be H(p) + KL(p;q0), which is bounded by logn for q0 uniform. Notice that this expression does not depend on qT \u2013 in fact, this cost precisely corresponds to the scenario where the firm had not set up a CLM and instead used the initial estimate q0 to encode. In other words, for \u03b1 = 1, the firm is entirely neutral to the quality of the estimate qT ; even if the CLM provided an estimate qT which performed worse than q0, the cost increase due to the bad choice of q is recouped from payments of the ill-informed participants.\nThe firm may not want to be neutral to the estimate of the crowd, however, and under the reasonable assumption that the final estimate qT will improve upon q0, the firm should set 0 < \u03b1 < 1 (of course, positivity is needed for nonzero payouts). In this case, the firm will strictly gain by using the CLM when KL(p;qT ) < KL(p;q0), but still has some insurance policy if the estimate qT is poor."}, {"heading": "4 Prediction Markets as a Special Case", "text": "Let us briefly review the literature for the type of prediction markets relevant to the present work. In such a prediction market, we imagine a future event to reveal one of n uncertain outcomes. Hanson [7, 8] proposed a framework in which traders make \u201creports\u201d to the market about their internal belief in the form of a distribution p \u2208 \u2206n. Each trader would receive a reward (or loss) based on a function of their proposed belief and the belief of the previous trader, and the function suggested by Hanson was the Logarithmic Market Scoring Rule (LMSR). It was shown later that the LMSR-based market is equivalent to what is known as a cost function based automated market makers, proposed by Chen and Pennock [3]. More recently a much broader equivalence was established by Chen and Wortman Vaughan [4] between markets based on cost functions and those based on scoring rules.\nThe market framework proposed by Chen and Pennock allows traders to buy and sell Arrow-Debreu securities (equivalently: shares, contracts), where an Arrow-Debreu security corresponding to outcome i pays out $1 if and only if i is realized. All shares are bought and sold through an automated market maker, which is the entity managing the market and setting prices. At any time period, traders can purchase bundles of contracts r \u2208 Rn, where r(i) represents the number of shares purchased on outcome i. The price of a bundle r is set as C(s + r) \u2212 C(s), where C is some differentiable convex cost function and s \u2208 Rn is the \u201cquantity vector\u201d representing the total number of outstanding shares. The LMSR cost function is C(s) := 1\n\u03b7 log ( \u2211n i=1 exp(\u03b7s(i))).\nThis cost function framework was extended by Abernethy et al. [1] to deal with prohibitively large outcome spaces. When the set of potential outcomes O is of exponential size or even infinite, the market designer can offer a restricted number of contracts, say n (\u226a |O|), rather than offer an Arrow-Debreu contract for each member of O. To determine the payout structure, the market designer chooses a function \u03c1 : O \u2192 Rn, where contract i returns a payout of \u03c1i(X) and, thus, a contract bundle r pays \u03c1(X) \u00b7 r. As with the framework of Chen and Pennock, the contract prices are set according to a cost function C, so that a bundle r has a price of C(s+ r)\u2212C(s). The design of the function C is addressed at length in Abernethy et al., to which we refer the reader.\nFor the remainder of this section we shall discuss the prediction market template of Abernethy et al. as it provides the most general model; we shall refer to such a market as an Automated Prediction Market Maker. We now precisely state the ingredients of this framework.\nDefinition 6. An Automated Prediction Market Maker (APMM) is defined by a tuple (S,O,\u03c1, C) where S is the share space of the market, which we will assume to be the linear space Rn; O is the set of outcomes; C : S \u2192 R is a smooth and convex cost function with \u2207C(S) = relint(\u2207C(S)) (here, we use \u2207C(S) := {\u2207C(s) | s \u2208 S} to denote the derivative space of C); and \u03c1 : O \u2192 \u2207C(S) is a payoff function\nFortunately, we need not provide a full description of the procedure of the APMM mechanism: The APMM is precisely a special case of a CLM! Indeed, the APMM framework can\nbe described as a CLM (H,O, Cost, Payout) where\nH = S(= Rn) Cost(s, s\u2032) = C(s\u2032)\u2212 C(s) Payout(s, s\u2032;X) = \u03c1(X) \u00b7 (s\u2032 \u2212 s). (3)\nHence we can think of APMM prediction markets in terms of our learning mechanism. Markets of this form are an important special class of CLMs \u2013 in particular, we can guarantee that they are efficient to work with, as we show in the following proposition.\nProposition 3. An APMM (S,O,\u03c1, C) with a efficiently computable C satisfies the EC and"}, {"heading": "TT properties.", "text": "Proof. Computing Cost and Payout, defined in (3), requires simply evaluating C(\u00b7) at two inputs and evaluating \u03c1(\u00b7) and taking a dot product, all of which are polynomial-in-n operations. Hence an APMM satisfies the EC property. Furthermore, for a participant to make an optimal trade with belief P under a budget constraint B, she must simply compute, for any fixed s\u2032,\nargmax s\u2208Rn:C(s)\u2212C(s\u2032)\u2264B\nEX\u223cP [\u03c1(X)] \u00b7 (s\u2212 s \u2032)\u2212 C(s) + C(s\u2032).\nThe latter objective is a standard convex optimization problem in n parameters which can be solved efficiently.\nWe now ask, what is the learning problem that the participants of an APMM are trying to solve? More precisely, when we think of an APMM as a CLM, does it implement a particular L?\nLemma 1. Let APMM A = (S,O,\u03c1, C) be given. Then A implements the GSR L : \u2207C(S)\u00d7 O \u2192 R defined by\nL(w;X) = DC\u2217(\u03c1(X),w) + f(X), (4)\nwhere C\u2217 is the conjugate dual of the function C and f is arbitrary.\nProof. We analyze the profits for trades in A. Let pt = \u2207C(st) be the instantaneous prices at time t. The ex-post profit of the bet (st 7\u2192 st+1) is then\nProfit(st, st+1;X) = (st+1 \u2212 st) \u00b7 \u03c1(X)\u2212 C(st+1) + C(st)\n= (st+1 \u2212 st) \u00b7 \u03c1(X)\u2212 (pt+1 \u00b7 st+1 \u2212 C \u2217(pt+1)) + (pt \u00b7 st \u2212 C \u2217(pt)) = C\u2217(pt+1) + st+1 \u00b7 (\u03c1(X)\u2212 pt+1)\u2212 C \u2217(pt)\u2212 st \u00b7 (\u03c1(X)\u2212 pt) (5)\nNow note that since C is closed and convex, by duality we can write\nC(s) = sup p\u2208\u2207C(S)\n{s \u00b7 p\u2212 C\u2217(p)}, (6)\nfor all s. Using standard techniques in conjugate duality theory, we can conclude that the sup is achieved for p = \u2207C(s); we briefly sketch this argument here. Since C\u2217 is the conjugate dual of C, we have C\u2217(\u2207C(s)) = sup\ns\u2032\u2208Rn s \u2032 \u00b7 \u2207C(s)\u2212 C(s\u2032). As this objective is\nunconstrained, we see that an optimal choice of s\u2032 is identically s. This gives the following equality,\nC\u2217(\u2207C(s)) = s \u00b7 \u2207C(s)\u2212 C(s). (7)\nOf course, by reconciling equations (6) and (7), we see that one optimal choice of p is \u2207C(s); indeed this is the only choice, although we need not prove this statement.\nContinuing, since this p := \u2207C(s) maximizes the objective in (6), we must have\n0 = v \u00b7 \u2207p (s \u00b7 p\u2212 C \u2217(p)) = v \u00b7 (s\u2212\u2207C\u2217(p)),\nfor any direction v \u2208 \u2207C(S) \u2212 {p}. This is because p \u2208 \u2207C(S) \u2261 relint(\u2207C(S)) by assumption, so if the directional derivative were nonzero the objective would increase in the direction of v or \u2212v. Now since \u03c1(O) \u2286 \u2207C(S) according to Definition 6, we have \u03c1(X)\u2212 p \u2208 \u2207C(S)\u2212 {p} for all p. Thus,\nst+1 \u00b7 (\u03c1(X)\u2212 pt+1) = \u2207C \u2217(pt+1) \u00b7 (\u03c1(X)\u2212 pt+1), and\nst \u00b7 (\u03c1(X)\u2212 pt) = \u2207C \u2217(pt) \u00b7 (\u03c1(X)\u2212 pt).\n(8)\nFinally, applying (8) and adding C\u2217(\u03c1(X))\u2212 C\u2217(\u03c1(X)) to (5) yields\nProfit(st, st+1;X) = DC\u2217(\u03c1(X),pt)\u2212DC\u2217(\u03c1(X),pt+1), (9)\nNote that if we had instead added C\u2217(p\u0304) \u2212 C\u2217(p\u0304), where p\u0304 = EX\u223cP [\u03c1(X)], we would see that the expected ex-post profit under P is DC\u2217(E[\u03c1(X)],pt)\u2212DC\u2217(E[\u03c1(X)],pt+1). We now have\nProfit(st, st+1;X) = L(\u2207C(st);X)\u2212 L(\u2207C(st+1);X),\nsince the f(X) terms cancel; the implementation property thus follows with the surjective map \u03d5 : s 7\u2192 \u2207C(s).\nThere is another more subtle benefit to APMMs \u2013 and, in fact, to most prediction market mechanisms in practice \u2013 which is that participants make bets via purchasing of shares or share bundles. When a trader makes a bet, she purchases a contract bundle r, is charged C(s + r) \u2212 C(s) (when the current quantity vector is s), and shall receive payout \u03c1(X) \u00b7 r if and when X is realized. But at any point before X is observed and trading is open, the trader can sell off this bundle, to the APMM or another trader, and hence neutralize her risk. In this sense bets made in an APMM are stateless, whereas for an arbitrary CLM this may not be the case: the wager defined by (wt 7\u2192 wt+1) can not necessarily be sold back to the mechanism, as the posted hypothesis may no longer remain at wt+1.\nGiven a learning problem defined by the GSR L : H \u00d7 O \u2192 R, it is natural to ask whether we can design a CLM which implements this L and has this \u201cshare-based property\u201d of APMMs. More precisely, under what conditions is it possible to implement L with an APMM?\nTheorem 1. For any divergence-based GSR L(w;X) = DR(\u03c1(X), \u03c8(w)) + f(X), with \u03c8 : H \u2192 H\u2032 one-to-one, H\u2032 = relint(H\u2032), and \u03c1(O) \u2286 \u03c8(H), there exists an APMM which implements L.\nProof. Recall the functions involved from Definition 3: \u03c1 : O \u2192 H\u2032, f : O \u2192 R, \u03c8 : H \u2192 H\u2032, and finally R : H\u2032 \u2192 R is a closed strictly convex function. In order to construct an APMM we set C = R\u2217, the conjugate dual of R, and S = dom(R\u2217). Note that S = Rn by assumption. Using standard results of conjugate duality we have \u2207C(S) = dom(R) = H\u2032, and since R is closed and convex, we also have C\u2217 = (R\u2217)\u2217 = R.\nSince we have \u03c1(O) \u2286 H\u2032 = \u2207C(S), we can construct an APMM A = (S,O,\u03c1, C). By (9) from Lemma 1, we can write the profit of the bet (st 7\u2192 st+1) in A as\nProfit(st, st+1;X) = DR(\u03c1(X),\u2207C(st))\u2212DR(\u03c1(X),\u2207C(st+1)). (10)\nAs \u03c8 is one-to-one by assumption, we can now write\nProfit(st, st+1;X) = L(\u03c8 \u22121(\u2207C(st));X)\u2212 L(\u03c8 \u22121(\u2207C(st+1));X),\nsince the f(X) terms cancel. Finally, since \u2207C : S \u2192 H\u2032 and \u03c8\u22121 : H\u2032 \u2192 H are surjective, we see that A implements L with map \u03d5 \u2261 \u03c8\u22121 \u25e6 \u2207C.\nWe point out that if an APMM implements some arbitrary L, not necessarily the canonical L0 established in Lemma 1, then L is effectively equivalent to L0 and, hence, is divergence based. This fully specifies the class of problems solvable using APMMs.\nTheorem 2. If APMM (S,O,\u03c1, C) implements a GSR L : H\u00d7O \u2192 R, then L is divergencebased.\nProof. Given that (S,O,\u03c1, C) implements L, we know there exists some surjective map \u03d5 : S \u2192 H so that Profit(s, s\u2032;X) = L(\u03d5(s);X)\u2212 L(\u03d5(s\u2032);X) for all s, s\u2032 \u2208 S. Of course, applying Lemma 1 we now have,\nDR(\u03c1(X),\u2207C(s))\u2212DR(\u03c1(X),\u2207C(s \u2032)) = Profit(s, s\u2032;X) = L(\u03d5(s);X)\u2212 L(\u03d5(s\u2032);X),\nwhere R = C\u2217. Focusing on L(\u00b7; \u00b7) as a function of s, and fixing s\u2032 arbitrarily, we see that\nL(\u03d5(s);X) \u2261 DR(\u03c1(X),\u2207C(s)) + ( L(\u03d5(s\u2032);X)\u2212DR(\u03c1(X),\u2207C(s \u2032)) )\n\u2261 DR(\u03c1(X),\u2207C(s)) + f(X)\nfor some f : O \u2192 R, since L(\u03d5(s);X) cannot depend on the unbound variable s\u2032. Furthermore, for any w, s such that w = \u03d5(s), we must have\nL(w;X) = DR(\u03c1(X),\u2207C(s)) + f(X).\nNow since \u03d5 is surjective, there exists a map \u03d5\u0303 with \u03d5 \u25e6 \u03d5\u0303 = idH. Hence,\nL(w;X) \u2261 DR(\u03c1(X), \u03c8(w)) + f(X),\nwhere \u03c8 = \u2207C \u25e6 \u03d5\u0303.\nTheorem 2 establishes a strong connection between prediction markets and a natural class of GSRs. One interpretation of this result is that any GSR based on a Bregman divergence has a \u201cdual\u201d characterization as a share-based market, where participants buy and sell shares rather than directly altering the share prices (the hypothesis). This has many advantages for prediction markets, not least of which is that shares are often easier to think about than the underlying hypothesis space.\nOur notion of a CLM offers another interpretation. In light of Proposition 3, any machine learning problem whose hypotheses can be evaluated in terms of a divergence leads to a tractable crowdsourcing mechanism, as was the case in Section 3. Moreover, this theorem does not preclude efficient yet non-divergence-based loss functions as we see in the next section."}, {"heading": "5 Example CLMs for Typical Machine Learning Tasks", "text": "Regression. We now construct a CLM for a typical regression problem. We let H be the \u21132-norm ball of radius 1 in R\nd, and we shall let an outcome be a batch of a data, that is X := {(x1, y1), . . . , (xn, yn)} where for each i we have xi \u2208 R\nd, yi \u2208 [\u22121, 1], and we assume \u2016xi\u20162 \u2264 1. We construct a GSR according to the mean squared error, L(w; {(xi, yi)} n i=1) =\n\u03b1 2n \u2211n i=1(w \u00b7 xi \u2212 yi)\n2 for some parameter \u03b1 > 0. It is worth noting that L is not divergencebased.\nIn order to satisfy the escrow property (ES), we can set Cost(w,w\u2032) := 2\u03b1\u2016w \u2212 w\u2032\u20162 because the function L(w;X) is 2\u03b1-lipschitz with respect to w for any X . To ensure that the CLM is L-incentivized, we must set Payout(w,w\u2032;X) := Cost(w,w\u2032)+L(w;X)\u2212L(w\u2032;X).\nIf we set the initial hypothesis w0 = 0, it is easy to check that WorstCaseLoss = \u03b1/2. It remains to check whether this CLM is tractable. It\u2019s clear that we can efficiently compute Cost and Payout, hence the EC property holds. Given how Cost is defined, it is clear that the set {w\u2032 : Cost(w,w\u2032) \u2264 B} is just an \u21132-norm ball. Also, since L is convex in w for each X , so is the function EX\u223cP [ Profit(w,w\u2032, X) ] for every P . A budget-constrained profitmaximizing participant must simply solve a convex optimization problem, and hence the TT property holds.\nBetting Directly on the Labels. Let us return our attention to the Netflix Prize model as discussed in the Introduction. For this style of competition a host releases a dataset for a given prediction task. The host then requests participants to provide predictions on a specified set of instances on which it has correct labels. For every submission the agent computes an error measure, say the MSE, and reports this to the participants. Of course, the correct labels are withheld throughout.\nOur CLM framework is general enough to apply to this problem framework as well. Define H = O = Km where K \u2286 R bounded is the set of valid labels, and m is the number of requested test set predictions. For some w \u2208 H and y \u2208 O, w(k) specifies the kth predicted label, and y(k) specifies the true label. A natural scoring function is the total squared loss, L(w;y) :=\n\u2211m k=1(w(k)\u2212 y(k)) 2. Of course, this approach is quite different from the Netflix\nPrize model, in two key respects: (a) the participants have to wager on their predictions and (b) by participating in the mechanism they are required to reveal their modification to all of the other players. Hence while we have structured a competitive process the participants are de facto forced to collaborate on the solution.\nA reasonable critique of this collaborative mechanism approach to a Netflix-style competition is that it does not provide the instant feedback of the \u201cleaderboard\u201d where individuals observe performance improvements in real time. However, we can adjust our mechanism to be online with a very simple modification of the CLM protocol, which we sketch here. Rather than make payouts in a large batch at the end, the competition designer could perform a mini-payout at the end of each of a sequence of time intervals. At each interval, the designer could select a (potentially random) subset S of user/movie pairs in the remaining test set, freeze updates on the predictions w(k) for all k \u2208 S, and perform payouts to the participants on only these labels. What makes this possible, of course, is that the generalized scoring rule we chose decomposes as a sum over the individual labels.\nWith this online approach just discussed, let us end with one final observation. Given that some firm such as Netflix would like to make good predictions on a given data source, the firm could potentially rely entirely on the advice from a CLM. The firm could post batches of data on which it does not have labels and ask the participants to provide predictions via the CLM. The firm could then pay out according to a small sample which are manually labeled or whose labels are received in the mean time. But by not revealing on which subset the labels will arrive, the firm receives potentially good predictions on the full set. This could provide a valuable market between small firms which have machine learning needs and \u201cfreelance\u201d machine learning bounty hunters.\nAcknowledgments. We gratefully acknowledge the support of the NSF under award DMS-0830410, a Google University Research Award, and the National Defense Science and Engineering Graduate (NDSEG) Fellowship, 32 CFR 168a."}], "references": [{"title": "An optimization-based framework for automated market-making", "author": ["J. Abernethy", "Y. Chen", "J. Wortman Vaughan"], "venue": "Proceedings of the 12th ACM Conference on Electronic Commerce", "citeRegEx": "1", "shortCiteRegEx": null, "year": 2011}, {"title": "Results from a dozen years of election futures markets research", "author": ["J.E. Berg", "R. Forsythe", "F.D. Nelson", "T.A. Rietz"], "venue": "Handbook of Experimental Economic Results", "citeRegEx": "2", "shortCiteRegEx": "2", "year": 2001}, {"title": "A utility framework for bounded-loss market makers", "author": ["Y. Chen", "D.M. Pennock"], "venue": "Proceedings of the 23rd Conference on Uncertainty in Artificial Intelligence", "citeRegEx": "3", "shortCiteRegEx": null, "year": 2007}, {"title": "A new understanding of prediction markets via noregret learning", "author": ["Y. Chen", "J. Wortman Vaughan"], "venue": "Proceedings of the 11th ACM Conference on Electronic Commerce", "citeRegEx": "4", "shortCiteRegEx": null, "year": 2010}, {"title": "et al", "author": ["T.M. Cover", "J.A. Thomas", "J. Wiley"], "venue": "Elements of information theory, volume 6. Wiley Online Library", "citeRegEx": "5", "shortCiteRegEx": null, "year": 1991}, {"title": "Strictly proper scoring rules", "author": ["T. Gneiting", "A.E. Raftery"], "venue": "prediction, and estimation. Journal of the American Statistical Association, 102(477):359\u2013378", "citeRegEx": "6", "shortCiteRegEx": null, "year": 2007}, {"title": "Combinatorial information market design", "author": ["R. Hanson"], "venue": "Information Systems Frontiers, 5(1):105\u2013119", "citeRegEx": "7", "shortCiteRegEx": null, "year": 2003}, {"title": "Logarithmic market scoring rules for modular combinatorial information aggregation", "author": ["R. Hanson"], "venue": "Journal of Prediction Markets, 1(1):3\u201315", "citeRegEx": "8", "shortCiteRegEx": null, "year": 2007}, {"title": "Information aggregation and manipulation in an experimental market", "author": ["R. Hanson", "R. Oprea", "D. Porter"], "venue": "Journal of Economic Behavior & Organization, 60(4):449\u2013459", "citeRegEx": "9", "shortCiteRegEx": null, "year": 2006}, {"title": "Supervised aggregation of classifiers using artificial prediction markets", "author": ["Nathan Lay", "Adrian Barbu"], "venue": "In ICML,", "citeRegEx": "10", "shortCiteRegEx": "10", "year": 2010}, {"title": "An experimental test of combinatorial information markets", "author": ["J. Ledyard", "R. Hanson", "T. Ishikida"], "venue": "Journal of Economic Behavior and Organization, 69:182\u2013189", "citeRegEx": "11", "shortCiteRegEx": null, "year": 2009}, {"title": "Prediction markets", "author": ["J. Wolfers", "E. Zitzewitz"], "venue": "Journal of Economic Perspective, 18(2):107\u2013126", "citeRegEx": "12", "shortCiteRegEx": null, "year": 2004}], "referenceMentions": [{"referenceID": 6, "context": "The framework we propose has many qualities similar to that of an information or prediction market, and many of the ideas derive from recent research on the design of automated market makers [7, 8, 3, 4, 1].", "startOffset": 191, "endOffset": 206}, {"referenceID": 7, "context": "The framework we propose has many qualities similar to that of an information or prediction market, and many of the ideas derive from recent research on the design of automated market makers [7, 8, 3, 4, 1].", "startOffset": 191, "endOffset": 206}, {"referenceID": 2, "context": "The framework we propose has many qualities similar to that of an information or prediction market, and many of the ideas derive from recent research on the design of automated market makers [7, 8, 3, 4, 1].", "startOffset": 191, "endOffset": 206}, {"referenceID": 3, "context": "The framework we propose has many qualities similar to that of an information or prediction market, and many of the ideas derive from recent research on the design of automated market makers [7, 8, 3, 4, 1].", "startOffset": 191, "endOffset": 206}, {"referenceID": 0, "context": "The framework we propose has many qualities similar to that of an information or prediction market, and many of the ideas derive from recent research on the design of automated market makers [7, 8, 3, 4, 1].", "startOffset": 191, "endOffset": 206}, {"referenceID": 8, "context": "In the words of Hanson et al [9]: \u201cRational expectations theory predicts that, in equilibrium, asset prices will reflect all of the information held by market participants.", "startOffset": 29, "endOffset": 32}, {"referenceID": 10, "context": "\u201d In practice, prediction markets have proven impressively accurate as a forecasting tool [11, 2, 12].", "startOffset": 90, "endOffset": 101}, {"referenceID": 1, "context": "\u201d In practice, prediction markets have proven impressively accurate as a forecasting tool [11, 2, 12].", "startOffset": 90, "endOffset": 101}, {"referenceID": 11, "context": "\u201d In practice, prediction markets have proven impressively accurate as a forecasting tool [11, 2, 12].", "startOffset": 90, "endOffset": 101}, {"referenceID": 9, "context": "It is worth noting that Barbu and Lay utilized concepts from prediction markets to design algorithms for classifier aggregation [10], although their approach was unrelated to crowdsourcing.", "startOffset": 128, "endOffset": 132}, {"referenceID": 5, "context": "We begin by discussing the notion of a scoring rule, a well-studied object from statistics for the purpose eliciting \u201cgood\u201d probability forecasts [6].", "startOffset": 146, "endOffset": 149}, {"referenceID": 5, "context": "We recall the notion of a scoring rule, a concept that arises frequently in economics and statistics [6].", "startOffset": 101, "endOffset": 104}, {"referenceID": 4, "context": "This can be achieved using Huffman Codes for example, and we refer the reader to Cover and Thomas ([5], Chapter 5) for more details.", "startOffset": 99, "endOffset": 102}, {"referenceID": 6, "context": "Hanson [7, 8] proposed a framework in which traders make \u201creports\u201d to the market about their internal belief in the form of a distribution p \u2208 \u2206n.", "startOffset": 7, "endOffset": 13}, {"referenceID": 7, "context": "Hanson [7, 8] proposed a framework in which traders make \u201creports\u201d to the market about their internal belief in the form of a distribution p \u2208 \u2206n.", "startOffset": 7, "endOffset": 13}, {"referenceID": 2, "context": "It was shown later that the LMSR-based market is equivalent to what is known as a cost function based automated market makers, proposed by Chen and Pennock [3].", "startOffset": 156, "endOffset": 159}, {"referenceID": 3, "context": "More recently a much broader equivalence was established by Chen and Wortman Vaughan [4] between markets based on cost functions and those based on scoring rules.", "startOffset": 85, "endOffset": 88}, {"referenceID": 0, "context": "[1] to deal with prohibitively large outcome spaces.", "startOffset": 0, "endOffset": 3}], "year": 2011, "abstractText": "Machine Learning competitions such as the Netflix Prize have proven reasonably successful as a method of \u201ccrowdsourcing\u201d prediction tasks. But these competitions have a number of weaknesses, particularly in the incentive structure they create for the participants. We propose a new approach, called a Crowdsourced Learning Mechanism, in which participants collaboratively \u201clearn\u201d a hypothesis for a given prediction task. The approach draws heavily from the concept of a prediction market, where traders bet on the likelihood of a future event. In our framework, the mechanism continues to publish the current hypothesis, and participants can modify this hypothesis by wagering on an update. The critical incentive property is that a participant will profit an amount that scales according to how much her update improves performance on a released test set.", "creator": "LaTeX with hyperref package"}}}