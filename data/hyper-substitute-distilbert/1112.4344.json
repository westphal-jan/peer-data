{"id": "1112.4344", "review": {"conference": "arxiv", "VERSION": "v1", "DATE_OF_SUBMISSION": "19-Dec-2011", "title": "A Scalable Multiclass Algorithm for Node Classification", "abstract": "we introduce a scalable algorithm, mechanically, unlike multiclass node identification in scoring graphs. unlike previously proposed methods for the averaging task, mucca works towards time linear filtering the number of nodes. your approach moves based within a game - scoring test though the problem in respect the matching cases are expressed after absolute nash equilibrium of determining certain game. however, any order to achieve that, simulations find graphs matching by a spanning tree of six original vertices. experiments observing real - world data reveal that mucca is much poorer than competitors competitors while proving a similar relative improvement.", "histories": [["v1", "Mon, 19 Dec 2011 14:21:00 GMT  (694kb,D)", "http://arxiv.org/abs/1112.4344v1", null]], "reviews": [], "SUBJECTS": "cs.LG cs.GT", "authors": ["giovanni zappella"], "accepted": false, "id": "1112.4344"}, "pdf": {"name": "1112.4344.pdf", "metadata": {"source": "CRF", "title": "A Scalable Multiclass Algorithm for Node Classification", "authors": ["Giovanni Zappella"], "emails": [], "sections": [{"heading": "1 Introduction", "text": "Classification of networked data is a quite attractive field with applications in computer vision, bioinformatics, spam detection and text categorization. In recent years networked data have become widespread due to the increasing importance of social networks and other web-related applications. This growing interest is pushing researchers to find scalable algorithms for important practical applications of these problems. In this paper we focus our attention on a task called node classification, often studied in the semi-supervised setting Zhu et al. [2003]. Recently, different teams studied the problem from a theoretic point of view with interesting results. For example Cesa-Bianchi et al. [2009, 2010, 2011] developed on-line fast predictors for weighted and unweighted graphs and Herbster et al. developed different versions of the Perceptron algorithm to classify the nodes of a graph (Herbster et al. [2009], Herbster and Pontil [2006]). Erdem and Pelillo [2011] introduced a game-theoretic framework for node classification. We adopt the same approach and, in particular, we obtain a scalable algorithm by finding a Nash Equilibrium on a special instance of their game. The main difference between our algorithm and theirs is the high scalability achieved by our approach. This is really important in practice, since it makes possible to use our algorithm on large scale problems.\nar X\niv :1\n11 2.\n43 44\nv1 [\ncs .L\nG ]\n1 9\nD ec"}, {"heading": "2 Basic Framework", "text": "Given a weighted graph G = (V,E,W ), a labeling of G is an assignment y = (y1, .., yn) \u2208 {0, 1, ..., c}n where n = |V |. We expect our graph to respect a notion of regularity where adjacent nodes often have the same label: this notion of regularity is called homophily. Most machine learning algorithms for node classification (Herbster et al. [2009], Cesa-Bianchi et al. [2010], Zhu et al. [2003], Cesa-Bianchi et al. [2011]) adopt this bias and exploit it to improve their performances. The learner is given the graph G, but just a subset of y, that we call training set. The learner\u2019s goal is to predict the remaining labels minimizing the number of mistakes. Cesa-Bianchi et al. [2010] introduce also an irregularity measure of the graph G, for the labeling y, defined as the ratio between the sum of the weights of the edges between nodes with different labels and the sum of all the weights. Intuitively, we can view the weight of an edge as a similarity measure between two nodes, we expect highly similar nodes to have the same label and edges between nodes with different labels being \u201clight\u201d. Based on this intuition, we may assign labels to non-training nodes so to minimize some function of the induced weighted cut. In the binary classification case, algorithms based on min-cut have been proposed in the past (for example Blum and Chawla [2001]). Generalizing this approach to the multiclass case, naturally takes us to the multi-way cut (or multi-terminal cut \u2014 see Costa et al. [2005]) problem. Given a graph and a list of terminal nodes, find a set of edges such that, once removed, each terminal belongs to a different component. The goal is to minimize the sum of the weights of the removed edges. Unfortunately, the multi-way cut problem is MAX SNP-hard when the number of terminals is bigger than two (Dalhaus et al. [1994]). Furthermore, efficient algorithms to find the multi-way cut on special instances of the problem are known, but, for example, it is not clear if it is possible to reduce a node classification problem on a tree to a multi-way cut on a tree."}, {"heading": "3 Graph Transduction Game", "text": "In this section we describe the game introduced by Erdem and Pelillo [2011] that, in a certain sense, aims at distributing over the nodes the cost of approximating the multi-way cut. This is done by expressing the labels assignment as a Nash Equilibrium. We have to keep in mind that, since this game is non-cooperative, each player maximizes its own payoff disregarding what it can do to maximize the sum of utilities of all the players (the so-called social welfare). The value of the multi-way cut is strongly related to the value of the social welfare of the game, but in the general case a Nash Equilibrium does not give any guarantee about the collective result. In the Graph Transduction Game (later called GTG), the graph topology is\nknown in advance and we consider each node as a player. Each possible label of the nodes is a pure strategy of the players. Since we are working in a batch setting, we will have a train/test split that induces two different kind of players:\n\u2022 Determined players(ID) those are nodes with a known label (train set), so in our game they will be players with a fixed strategy (they do not change their strategy since we can not change the labels given as training set)\n\u2022 Undetermined players(IU ) those that do not have a fixed strategy and can choose whatever strategy they prefer (we have to predict their labels)\nThe game is defined as \u0393 = (I, S, \u03c0), where I = {1, 2, ..., n} is the set of players, S = \u00d7i\u2208ISi is the joint strategy space (the Cartesian product of all strategy sets Si \u2286 {1, 2, ...c}), and \u03c0 : S \u2192 Rn is the combined payoff function which assigns a real valued payoff \u03c0i(s) \u2208 R to each pure strategy profile s \u2208 S and player i \u2208 I. A mixed strategy of player i \u2208 I is a probability distribution x over the set of the pure strategies of i. Each pure strategy k corresponds to a mixed strategy where all the strategies but the k-th one have probability equals to zero. We define the utility function of the player i as\nui(s) = \u2211 s\u2208S x(s)\u03c0i(s)\nwhere x(s) is the probability of s. We assume the payoff associated to each player is additively separable (this will be clear in the following lines). This makes GTG a member of a subclass of the multi-player games called polymatrix games. For a pure strategy profile s = (s1, s2, ...sn) \u2208 S, the payoff function of every player i \u2208 I is:\n\u03c0i(s) = \u2211 j\u223ci wijI{si=sj}\nwhere i \u223c j means that i and j are neighbors, this can be written in matrix form as \u03c0i(s) = \u2211 j\u223ci Aij(si, sj)\nwhere Aij \u2208 Rc\u00d7c is the partial payoff matrix between i and j, defined as Aij = Ic \u00d7 wij , where Ic is the identity matrix of size c and Aij(x, y) represent the element of Aij at row x and column y. The utility function of each player i \u2208 IU can be re-written as follows:\nui(x) = \u2211 i\u223cj x T i Aijxj\n= \u2211 i\u223cj wijx T i xj\n= \u2211 i\u223cj wij \u2211c k=1 xikxjk\nwhere k is an action selected from the player\u2019s set and in case i is a determined node with training label k, x\u2019s components will be always zeros except the k-th corresponding to the pure strategy k. Since the utility function of each player is linear, it is easy to see that players can achieve their maximum payoff using pure strategies. In a non-cooperative game, a vector of strategies SNE is said to be a (pure strategies) Nash Equilibrium, if \u2200i \u2208 I, \u2200s\u2032i \u2208 Si : s\u2032i 6= si \u2208 SNE , we have that\nui(si, S \u2212i NE) \u2265 ui(s \u2032 i, S \u2212i NE)\nwhere ui(si, S \u2212i) is the strategy configuration S except the i-th one, that is replaced by si. In practice, no player i will change its strategy si to an alternative strategy improving its payoff. There are no guarantees that the Nash Equilibrium exists in pure strategies, but any game with a finite set of players and finite set of strategies has a Nash Equilibrium in mixed strategies (Nash [1951], also see Nisan et al. [2008]). In this case each player does not have to choose a strategy but it mixes its choices over its strategies. Instead of maximizing its payoff, it will maximize its expected payoff. Abusing of terminology, in the following sections we may talk about labels or pure strategies with the same meaning."}, {"heading": "3.1 The Evolutionary Stable Strategies approach", "text": "Erdem and Pelillo [2011] propose to find a Nash equilibrium of the GTG using the Evolutionary Stable Strategies. We briefly present their approach in order for the reader to better understand the difference between their algorithm and ours. The evolutionary stable strategies (ESS) approach is well known (Weibull [1995]) in the game-theoretic literature. It considers a game played repeatedly; each repetition of the game is seen as a generation, where an imaginary population evolve through a selection mechanism that, at each step, gives to the best \u201cchoices\u201d a growing portion of the total population. The algorithm (later called GTG-ESS), at each generation, updates the probability associated to every action h of every player i as\nxih(t+ 1) = xih(t) ui(eh)\nui(x(t))\nThe previous formula is just the discrete version of the so-called multi-population replicator dynamic:\nx\u0307ih = xih(ui(eh, x\u2212i)\u2212 ui(x))\nwhere eh is a vector of zeros except the h-th component that is one and xih is the h-th strategy of player i. The fixed points of the previous equations are Nash Equilibria, and the discrete version has the same properties \u2014 for further details see Erdem and Pelillo [2011].\nIn this case, the computational cost of finding the Nash Equilibrium is O(k|V |2) where k is the number of iterations and considering the number of classes as a constant factor. Erdem and Pelillo [2011] experimentally found that the number of iterations grows linearly with the number of nodes, so they consider the running time close to O(|V |3), but they do not seem to have any upper bound on the number of iterations.\n4 The MUCCA algorithm\nUse GTG-ESS for large scale networks can not be considered a viable solution, even if the time complexity of the algorithm were to be demonstrated in the order of \u0398(|V |3). A possible alternative is to apply some known results about regret minimization, such as those described by Cesa-Bianchi and Lugosi [2006], in order to converge to a weaker notion of equilibrium, for example the Correlated Equilibrium (Aumann [1974]). Unfortunately, the results of our experiments with the Correlated Equilibrium were not satisfactory. In this section we present MUCCA: a multiclass Classification Algorithm. Our algorithm consists in finding a Nash Equilibrium of the Graph Transduction Game on a special graph: a tree. We will show that in this way we achieve both good accuracy and scalability. In the remaining part of this section we will assume that the graph G is a tree. Now, we briefly introduce few notions those will be useful later in this section (see Figure 1):\n\u2022 Revealed node: a node whose label is known\n\u2022 Unrevealed node: a node whose label is unknown\n\u2022 Fork: an unrevealed node that is connected to at least 3 revealed nodes by edge-disjoint paths\n\u2022 Hinge node: a revealed node or a fork\n\u2022 Hinge tree: component of the forest created by removing from G all the edges incident to hinge nodes\n\u2022 Native hinge tree: component of the forest created by removing from G all the edges incident to revealed nodes. Its connection nodes are intended to be only labeled nodes.\n\u2022 Hinge line: a path connecting two hinge nodes such that there are no internal nodes those are hinge nodes\n\u2022 Connection Node: an hinge node that is adjacent to a node in an hinge tree\n\u2022 -edge: given Pij , the path between i and j, an -edge is ij \u2208 arg mine\u2208Pij we, where we is the weight of the edge e.\n\u2022 Grafted tree: a tree without hinge nodes that is connected to just one node on an hinge line\nMUCCA works in four phases:\n1. Mark all the paths between revealed nodes and find all the fork nodes\n2. Estimate the label of each fork node\n3. Assign a label to all the nodes on the hinge lines using a min cut technique\n4. Assign a label to all the remaining nodes\nNow we describe what it does in every phase: Phase 1 Starting from each revealed node, it does a breadth-first search until another revealed node or a leaf are found. Then if a revealed node was found, during the backtracking phase, MUCCA marks the edges on the path to the starting node with a special flag that we will call \u201cblack line\u201d. After that, each node with more than 3 edges marked as \u201cblack line\u201d incident to it, is a fork. Phase 2 Given a native hinge tree H that contains the fork F , we can categorize its connection nodes in c categories using their labels. For each path between F and each connection node of H, we have an -edge as defined before. The label assigned to F is the same as the category (of the connection nodes) that has the maximum sum of weights over the distinct -edges on the path between F and the nodes of that category. Phase 3 On every hinge line, we label the nodes using min cut: in case the hinge nodes at the beginning and at the end of the line has the same label, all the nodes on the hinge line will be labeled with that label. Otherwise, all the nodes before\nPhase1\nthe -edge are assigned with the label of the node at the beginning of the line, and the others with the label of the node at the end of the line. In case we have more than one edge with the same weight of the -edge (for example all the edges have the same weight), we use nearest neighbor to choose the labeling on the line. Phase 4 All the remaining nodes are in grafted trees. In this case, we assign the label of the node on the hinge line (connected to the tree) to all the nodes in that particular grafted tree.\nWe now prove that MUCCA finds a Nash Equilibrium for this special case of the GTG.\nTheorem. The labeling found by MUCCA is a Nash Equilibrium of the Graph Transduction Game when the graph is an undirected tree. Proof. As we explained in Section 3, a profile of strategies SNE is a Nash Equilibrium if no one has incentive to deviate from its strategy. This means that \u2200i \u2208 I, ui(si, S\u2212iNE) \u2265 ui(s\u2032i, S \u2212i NE). For the purpose of contradiction suppose that exists a node j such that it can improve its payoff by changing its strategy. j can not be contained in a grafted tree (those labeled in phase 4) since all the nodes contained in those trees have the same labels, so, whatever is the label, each of them gets a payoff of \u2211 i\u223cj wij , the maximum possible payoff. j can not be on an hinge line since they are labeled using min cut, so in the best case the payoff of each node is already the maximum payoff; in the worst case the payoff is the maximum minus the weight of the -edge. Since the -edge, by definition, has the minimum weight, there are no chance to improve the payoff. j can not be a revealed node (for obvious reasons). j can not be a fork. Since we use min cut to label the hinge lines if the -edge of an hinge line is not incident to the fork, the node adjacent to the fork on that hinge line will have the same label of the fork. In this way the fork will get the part of payoff given by the edge between it and the adjacent node. Even if the -edges are incident to the fork, the label prediction can not achieve a payoff better than the one achieved by the majority vote. Since j can not be a revealed node, nor a fork, nor a node on an hinge line, nor a node on a tree with just a connection node, it can not be in G.\nSince we consider the number of forks as a constant factor, MUCCA runs in O(|V |). Note that the labels of the unlabeled nodes of every native hinge tree can be predicted just using information about that singular native hinge tree. In this way, once the tree is splitted in native hinge trees, the predictions for the labels contained in every subtree are independent from the other subtrees. So, they can be computed using different threads, processes or even machines and we just need to get back a list of points (node id, predicted label)."}, {"heading": "5 Experiments", "text": "In this section we present our experimental results. Since binary classification is a (well-studied) special case of our problem, we first compare MUCCA with the state of the art in this particular field. In the second part of this section we test our algorithm versus its competitors on multiclass problems. We have to keep in mind that MUCCA works in linear time and can be used on large-scale graphs, where we can not test its competitors. Our experimental protocol is quite simple: for every size of the training set (and possibly on every class), we did 10 runs for each algorithm. Algorithms working on trees were ran on: Minimum Spanning Trees since previous experimental works showed that predictors get their best results on this kind of tree (Cesa-Bianchi et al. [2011]), and on Random Spanning Trees (RandomSpanningTrees) generated as in Wilson [1996] to test the most scalable solution possible. We tested MUCCA also in a committee version: in the tables numbers before the predictor\u2019s name represent the number of predictors in the committee (for example n*MyPred will represents a committee of n predictors MyPred). Each predictor in the committee predicts its own labels using its own tree and then we aggregate the predictions with a majority vote over the committee. In order to better understand the competitiveness of MUCCA, we will compare it with some well-know algorithms besides GTG-ESS. Label Propagation (abbreviated LABPROP), introduced by Zhu et al. [2003], is a popular algorithm for node classification and one of the most accurate algorithms in the literature. LABPROP computes a real-valued function f : V \u2192 R on G, and then assigns a labeling to G using the values of f . The algorithm minimizes the following quadratic energy function:\nE(f) = 1\n2 \u2211 i\u223cj wij(f(i)\u2212 f(j))2\nwith constrains on the labeled nodes. Its running time is O(|E| \u00d7 |V |). SHAZOO is a quite new algorithm introduced by Cesa-Bianchi et al. [2011] and, at the best of our knowledge, it is the most accurate scalable algorithms between our competitors. SHAZOO has strong theoretical foundations, but the idea behind the algorithm is really different from our one: it is an online algorithm based on nearest neighbor. In Figure 2, you can see a toy example where SHAZOO and MUCCA behave in a different way: MUCCA predicts all the nodes on the left hand side as positive since there are two nodes labeled as positive, connected to a fork that is labeled as positive and the -edge is the one with weight 1. Clearly every player wants to maximize its payoff, so the algorithm produces a labeling with a minimum possible cut. In the second part, for SHAZOO the node in the middle looks closer to the negative example than to the positive ones. In this way also all the nodes contained into the grafted tree will be labeled in a different way. SHAZOO\u2019s running time is O(|V |). Weighted Majority Vote (later called WMV) predicts the label of a node i\nusing a majority vote on the labeled neighbors weighted on the edges connecting them to i. Its running time is \u0398(|E|). Both LABPROP and GTG-ESS can be used for multiclass datasets but it is not clear if it is possible to modify SHAZOO in order to get a multiclass algorithm. In the multiclass section we replace SHAZOO with WMV. We did not include in our comparison WTA (Cesa-Bianchi et al. [2010]) since it was always outperformed by SHAZOO. Graph Perceptron (Herbster et al. [2009]) was omitted since it requires a lot of computational resource and performed poorly in previous comparisons (for example in Cesa-Bianchi et al. [2010])."}, {"heading": "5.1 Binary classification", "text": "In order to create a fair comparison, for the experimental activity we will generate our datasets in the same way of Cesa-Bianchi et al. [2011]."}, {"heading": "5.1.1 Datasets", "text": "We choose two real-world and well-known datasets to generate our graphs: USPS and RCV1. USPS is a set of hand written digits collected by the United States Postal Service, it contains 9298 images of 16 \u00d7 16 pixels (gray scale); the dataset called RCV1 is a subset of 10000 articles in chronological order taken from Reuters Corpus (a huge collection of news released by ). All the articles have been preprocessed using TF-IDF. Both datasets were natively multiclass, so we tested our binary predictors using a standard one-vs-rest schema. We have 10 binary experiments for USPS and 4 binary experiments for RCV1. We generated our graphs with as many nodes as the total number of examples for each dataset, keeping for each node only 10 nearest neighbor (before symmetrization) using the Euclidean distance \u2016xi \u2212 xj\u2016. Edges\u2019 weights have been\ncalculated as wij = e \u2212\u2016xi\u2212xj\u2016/\u03c32\nwhere \u03c3 is the average between the weights of all the edges incident to i or j."}, {"heading": "5.1.2 Experimental results", "text": "The results, shown in Table 1, are not conclusive, but we can observe some interesting trends:\n\u2022 GTG-ESS is the most accurate algorithm, but its computational complexity makes it not particularly suitable for most of the current practical applications.\n\u2022 MUCCA\u2019s accuracy is good and it is always close or better that SHAZOO\u2019s one.\n\u2022 LABPROP approaches the competitors as the training set size grows."}, {"heading": "5.2 Multiclass classification", "text": "In the multiclass comparison we replaced RCV1 with two other datasets, since it is not just multiclass but also multi-label (an element has more than one label). As we explained before, SHAZOO works just on binary problems, so the only scalable competitor in this section is WMV."}, {"heading": "5.2.1 Datasets", "text": "\u2022 USPS is the same graph we used for the binary classification.\n\u2022 CARDIO consists of measurements of fetal heart rate (FHR) and uterine contraction (UC) features on cardiotocograms classified by expert obstetricians. We generated a graph starting from the feature vectors, in the\nsame way we did for USPS and RCV1. The graph is constituted by 2126 nodes and 13696 edges. The nodes are divided in 3 classes (fetal states)1.\n\u2022 GHGRAPH is a graph created from the data released by Github.com for their contest in 2009. Every node represents a repository and an edge means that there is a developer working on both repositories connected by that edge. In case more than one developer works on those repositories, the number of developers is used as a weight for that edge. The label of each repository is the most used programming language to write the code in that repository. We kept only the biggest connected component of the graph that includes 99907 nodes (64885 of them are labeled) and 11044757 edges. Each programming language is a different class and at the end we had 40 classes."}, {"heading": "5.2.2 Experimental results", "text": "The results of our experiments, shown in Table 2, are not conclusive, but we can observe some interesting trends:\n\u2022 It is not really clear which one between GTG-ESS and LABPROP is the most accurate algorithm, but anyway MUCCA is always competitive with them.\n\u2022 MUCCA is always much better than WMV. As expected WMV works better on \u201cnot too sparse\u201d graphs such GHGRAPH, but even in this case it is outperformed by MUCCA.\n\u2022 GTG-ESS and LABPROP\u2019s time complexity did not permit us to run them in a reasonable amount of time with our computational resources."}, {"heading": "6 Conclusions and future work", "text": "We introduced a novel scalable algorithm for multiclass node classification in arbitrary weighted graphs. Our algorithm is motivated within a game theoretic\n1The Cardiotocography dataset was created by de Campos et al. [2000] and now is freely available on the UCI website with a complete description: http://archive.ics.uci.edu/ml/datasets/Cardiotocography\nframework, where test labels are expressed as the Nash equilibrium of a certain game. In practice, MUCCA works well even on binary problems against competitors like Label Propagation and SHAZOO that have been specifically designed for the binary setting. Several questions remain open. For example, committees of MUCCA predictors work well but we do not know whether there are better ways to aggregate their predictions. Also, given their common game-theoretic background, it would be interesting to explore possible connections between committees of MUCCA predictors and GTG-ESS."}, {"heading": "A. Blum and S. Chawla. Learning from labeled and unlabeled data using graph", "text": "mincuts. In Proceedings of the 18th International Conference on Machine Learning. Morgan Kaufmann, 2001.\nN. Cesa-Bianchi and G. Lugosi. Prediction, Learning and Games. Cambidge University Press, 2006."}, {"heading": "N. Cesa-Bianchi, C.Gentile, and F.Vitale. Fast and optimal prediction of a labeled", "text": "tree. In Proceedings of the 22nd Annual Conference on Learning Theory, 2009."}, {"heading": "N. Cesa-Bianchi, C. Gentile, F. Vitale, and G. Zappella. Random spanning trees", "text": "and the prediction of weighted graphs. In Proceedings of the 27th International Conference on Machine Learning, 2010."}, {"heading": "N. Cesa-Bianchi, C. Gentile, F. Vitale, and G. Zappella. See the tree through the lines:", "text": "The shazoo algorithm. In Advances in Neural Information Processing Systems 25, 2011.\nM. Costa, L.Letocart, and F. Roupin. Minimal multicut and maximal integer multiflow: a survey. In European Journal of Operational Research. Elsevier, 2005."}, {"heading": "E. Dalhaus, D.S. Johnson, C.H. Papadimitriou, P.D. Seymour, and M. Yannakakis.", "text": "The complexity of multiway cuts. In SIAM Journal of Computers, 1994."}, {"heading": "D. Ayres de Campos, J. Bernardes, A. Garrido, J. Marques de S, and L. Pereira-Leite.", "text": "Sisporto 2.0 a program for automated analysis of cardiotocograms. In Journal of Matern Fetal Med, 2000.\nA. Erdem and M. Pelillo. Graph transduction as a non-cooperative game. In Graphbase Representation in Pattern Recognition. Lecture Notes in Computer Science, 2011.\nM. Herbster and M. Pontil. Prediction on a graph with a perceptron. In Advances in Neural Information Processing Systems 20. MIT Press, 2006.\nM. Herbster, M. Pontil, and S. Rojas-Galeano. Fast prediction on a tree. In Advances in Neural Information Processing Systems 22. MIT Press, 2009.\nJ. Nash. Non-cooperative games. In The Annals of Mathematics, 1951.\nN. Nisan, T. Roughgarden, E. Tardos, and V.V. Vazirani. Algorithmic Game Theory. Cambidge University Press, 2008.\nA. Weibull. Evolutionary Game Theory. MIT Press, 1995.\nD.B. Wilson. Generating random spanning trees more quickly than the cover time. In Proceedings of the 28th ACM Symposium on the Theory of Computing, pages 296\u2013303. ACM Press, 1996."}, {"heading": "X. Zhu, Z. Ghahramani, and J. Lafferty. Semi-supervised learning using gaussian", "text": "fields and harmonic functions. In Proceedings of the 20th International Conference on Machine Learning, 2003."}], "references": [{"title": "Subjectivity and correlation in randomized strategies", "author": ["R.J. Aumann"], "venue": "In Journal of Mathematical Economics,", "citeRegEx": "Aumann.,? \\Q1974\\E", "shortCiteRegEx": "Aumann.", "year": 1974}, {"title": "Learning from labeled and unlabeled data using graph mincuts", "author": ["A. Blum", "S. Chawla"], "venue": "In Proceedings of the 18th International Conference on Machine Learning", "citeRegEx": "Blum and Chawla.,? \\Q2001\\E", "shortCiteRegEx": "Blum and Chawla.", "year": 2001}, {"title": "Prediction, Learning and Games", "author": ["N. Cesa-Bianchi", "G. Lugosi"], "venue": null, "citeRegEx": "Cesa.Bianchi and Lugosi.,? \\Q2006\\E", "shortCiteRegEx": "Cesa.Bianchi and Lugosi.", "year": 2006}, {"title": "Fast and optimal prediction of a labeled tree", "author": ["N. Cesa-Bianchi", "C.Gentile", "F.Vitale"], "venue": "In Proceedings of the 22nd Annual Conference on Learning Theory,", "citeRegEx": "Cesa.Bianchi et al\\.,? \\Q2009\\E", "shortCiteRegEx": "Cesa.Bianchi et al\\.", "year": 2009}, {"title": "Random spanning trees and the prediction of weighted graphs", "author": ["N. Cesa-Bianchi", "C. Gentile", "F. Vitale", "G. Zappella"], "venue": "In Proceedings of the 27th International Conference on Machine Learning,", "citeRegEx": "Cesa.Bianchi et al\\.,? \\Q2010\\E", "shortCiteRegEx": "Cesa.Bianchi et al\\.", "year": 2010}, {"title": "See the tree through the lines: The shazoo algorithm", "author": ["N. Cesa-Bianchi", "C. Gentile", "F. Vitale", "G. Zappella"], "venue": "In Advances in Neural Information Processing Systems", "citeRegEx": "Cesa.Bianchi et al\\.,? \\Q2011\\E", "shortCiteRegEx": "Cesa.Bianchi et al\\.", "year": 2011}, {"title": "Minimal multicut and maximal integer multiflow: a survey", "author": ["M. Costa", "L.Letocart", "F. Roupin"], "venue": "In European Journal of Operational Research. Elsevier,", "citeRegEx": "Costa et al\\.,? \\Q2005\\E", "shortCiteRegEx": "Costa et al\\.", "year": 2005}, {"title": "The complexity of multiway cuts", "author": ["E. Dalhaus", "D.S. Johnson", "C.H. Papadimitriou", "P.D. Seymour", "M. Yannakakis"], "venue": "In SIAM Journal of Computers,", "citeRegEx": "Dalhaus et al\\.,? \\Q1994\\E", "shortCiteRegEx": "Dalhaus et al\\.", "year": 1994}, {"title": "Sisporto 2.0 a program for automated analysis of cardiotocograms", "author": ["D. Ayres de Campos", "J. Bernardes", "A. Garrido", "J. Marques de S", "L. Pereira-Leite"], "venue": "In Journal of Matern Fetal Med,", "citeRegEx": "Campos et al\\.,? \\Q2000\\E", "shortCiteRegEx": "Campos et al\\.", "year": 2000}, {"title": "Graph transduction as a non-cooperative game. In Graphbase Representation in Pattern Recognition", "author": ["A. Erdem", "M. Pelillo"], "venue": "Lecture Notes in Computer Science,", "citeRegEx": "Erdem and Pelillo.,? \\Q2011\\E", "shortCiteRegEx": "Erdem and Pelillo.", "year": 2011}, {"title": "Prediction on a graph with a perceptron", "author": ["M. Herbster", "M. Pontil"], "venue": "In Advances in Neural Information Processing Systems", "citeRegEx": "Herbster and Pontil.,? \\Q2006\\E", "shortCiteRegEx": "Herbster and Pontil.", "year": 2006}, {"title": "Fast prediction on a tree", "author": ["M. Herbster", "M. Pontil", "S. Rojas-Galeano"], "venue": "In Advances in Neural Information Processing Systems", "citeRegEx": "Herbster et al\\.,? \\Q2009\\E", "shortCiteRegEx": "Herbster et al\\.", "year": 2009}, {"title": "Non-cooperative games", "author": ["J. Nash"], "venue": "In The Annals of Mathematics,", "citeRegEx": "Nash.,? \\Q1951\\E", "shortCiteRegEx": "Nash.", "year": 1951}, {"title": "Evolutionary Game Theory", "author": ["A. Weibull"], "venue": "Cambidge", "citeRegEx": "Weibull.,? \\Q2008\\E", "shortCiteRegEx": "Weibull.", "year": 2008}], "referenceMentions": [{"referenceID": 3, "context": "For example Cesa-Bianchi et al. [2009, 2010, 2011] developed on-line fast predictors for weighted and unweighted graphs and Herbster et al. developed different versions of the Perceptron algorithm to classify the nodes of a graph (Herbster et al. [2009], Herbster and Pontil [2006]).", "startOffset": 12, "endOffset": 254}, {"referenceID": 3, "context": "For example Cesa-Bianchi et al. [2009, 2010, 2011] developed on-line fast predictors for weighted and unweighted graphs and Herbster et al. developed different versions of the Perceptron algorithm to classify the nodes of a graph (Herbster et al. [2009], Herbster and Pontil [2006]).", "startOffset": 12, "endOffset": 282}, {"referenceID": 3, "context": "For example Cesa-Bianchi et al. [2009, 2010, 2011] developed on-line fast predictors for weighted and unweighted graphs and Herbster et al. developed different versions of the Perceptron algorithm to classify the nodes of a graph (Herbster et al. [2009], Herbster and Pontil [2006]). Erdem and Pelillo [2011] introduced a game-theoretic framework for node classification.", "startOffset": 12, "endOffset": 309}, {"referenceID": 5, "context": "Most machine learning algorithms for node classification (Herbster et al. [2009], Cesa-Bianchi et al.", "startOffset": 58, "endOffset": 81}, {"referenceID": 2, "context": "[2009], Cesa-Bianchi et al. [2010], Zhu et al.", "startOffset": 8, "endOffset": 35}, {"referenceID": 2, "context": "[2009], Cesa-Bianchi et al. [2010], Zhu et al. [2003], Cesa-Bianchi et al.", "startOffset": 8, "endOffset": 54}, {"referenceID": 2, "context": "[2009], Cesa-Bianchi et al. [2010], Zhu et al. [2003], Cesa-Bianchi et al. [2011]) adopt this bias and exploit it to improve their performances.", "startOffset": 8, "endOffset": 82}, {"referenceID": 2, "context": "[2009], Cesa-Bianchi et al. [2010], Zhu et al. [2003], Cesa-Bianchi et al. [2011]) adopt this bias and exploit it to improve their performances. The learner is given the graph G, but just a subset of y, that we call training set. The learner\u2019s goal is to predict the remaining labels minimizing the number of mistakes. Cesa-Bianchi et al. [2010] introduce also an irregularity measure of the graph G, for the labeling y, defined as the ratio between the sum of the weights of the edges between nodes with different labels and the sum of all the weights.", "startOffset": 8, "endOffset": 346}, {"referenceID": 1, "context": "In the binary classification case, algorithms based on min-cut have been proposed in the past (for example Blum and Chawla [2001]).", "startOffset": 107, "endOffset": 130}, {"referenceID": 1, "context": "In the binary classification case, algorithms based on min-cut have been proposed in the past (for example Blum and Chawla [2001]). Generalizing this approach to the multiclass case, naturally takes us to the multi-way cut (or multi-terminal cut \u2014 see Costa et al. [2005]) problem.", "startOffset": 107, "endOffset": 272}, {"referenceID": 1, "context": "In the binary classification case, algorithms based on min-cut have been proposed in the past (for example Blum and Chawla [2001]). Generalizing this approach to the multiclass case, naturally takes us to the multi-way cut (or multi-terminal cut \u2014 see Costa et al. [2005]) problem. Given a graph and a list of terminal nodes, find a set of edges such that, once removed, each terminal belongs to a different component. The goal is to minimize the sum of the weights of the removed edges. Unfortunately, the multi-way cut problem is MAX SNP-hard when the number of terminals is bigger than two (Dalhaus et al. [1994]).", "startOffset": 107, "endOffset": 616}, {"referenceID": 9, "context": "In this section we describe the game introduced by Erdem and Pelillo [2011] that, in a certain sense, aims at distributing over the nodes the cost of approximating the multi-way cut.", "startOffset": 51, "endOffset": 76}, {"referenceID": 12, "context": "In a non-cooperative game, a vector of strategies SNE is said to be a (pure strategies) Nash Equilibrium, if \u2200i \u2208 I, \u2200si \u2208 Si : si 6= si \u2208 SNE , we have that ui(si, S \u2212i NE) \u2265 ui(s \u2032 i, S \u2212i NE) where ui(si, S \u2212i) is the strategy configuration S except the i-th one, that is replaced by si. In practice, no player i will change its strategy si to an alternative strategy improving its payoff. There are no guarantees that the Nash Equilibrium exists in pure strategies, but any game with a finite set of players and finite set of strategies has a Nash Equilibrium in mixed strategies (Nash [1951], also see Nisan et al.", "startOffset": 88, "endOffset": 597}, {"referenceID": 12, "context": "In a non-cooperative game, a vector of strategies SNE is said to be a (pure strategies) Nash Equilibrium, if \u2200i \u2208 I, \u2200si \u2208 Si : si 6= si \u2208 SNE , we have that ui(si, S \u2212i NE) \u2265 ui(s \u2032 i, S \u2212i NE) where ui(si, S \u2212i) is the strategy configuration S except the i-th one, that is replaced by si. In practice, no player i will change its strategy si to an alternative strategy improving its payoff. There are no guarantees that the Nash Equilibrium exists in pure strategies, but any game with a finite set of players and finite set of strategies has a Nash Equilibrium in mixed strategies (Nash [1951], also see Nisan et al. [2008]).", "startOffset": 88, "endOffset": 627}, {"referenceID": 9, "context": "The fixed points of the previous equations are Nash Equilibria, and the discrete version has the same properties \u2014 for further details see Erdem and Pelillo [2011].", "startOffset": 139, "endOffset": 164}, {"referenceID": 9, "context": "Erdem and Pelillo [2011] experimentally found that the number of iterations grows linearly with the number of nodes, so they consider the running time close to O(|V |), but they do not seem to have any upper bound on the number of iterations.", "startOffset": 0, "endOffset": 25}, {"referenceID": 1, "context": "A possible alternative is to apply some known results about regret minimization, such as those described by Cesa-Bianchi and Lugosi [2006], in order to converge to a weaker notion of equilibrium, for example the Correlated Equilibrium (Aumann [1974]).", "startOffset": 108, "endOffset": 139}, {"referenceID": 0, "context": "A possible alternative is to apply some known results about regret minimization, such as those described by Cesa-Bianchi and Lugosi [2006], in order to converge to a weaker notion of equilibrium, for example the Correlated Equilibrium (Aumann [1974]).", "startOffset": 236, "endOffset": 250}, {"referenceID": 3, "context": "Algorithms working on trees were ran on: Minimum Spanning Trees since previous experimental works showed that predictors get their best results on this kind of tree (Cesa-Bianchi et al. [2011]), and on Random Spanning Trees (RandomSpanningTrees) generated as in Wilson [1996] to test the most scalable solution possible.", "startOffset": 166, "endOffset": 193}, {"referenceID": 3, "context": "Algorithms working on trees were ran on: Minimum Spanning Trees since previous experimental works showed that predictors get their best results on this kind of tree (Cesa-Bianchi et al. [2011]), and on Random Spanning Trees (RandomSpanningTrees) generated as in Wilson [1996] to test the most scalable solution possible.", "startOffset": 166, "endOffset": 276}, {"referenceID": 3, "context": "Algorithms working on trees were ran on: Minimum Spanning Trees since previous experimental works showed that predictors get their best results on this kind of tree (Cesa-Bianchi et al. [2011]), and on Random Spanning Trees (RandomSpanningTrees) generated as in Wilson [1996] to test the most scalable solution possible. We tested MUCCA also in a committee version: in the tables numbers before the predictor\u2019s name represent the number of predictors in the committee (for example n*MyPred will represents a committee of n predictors MyPred). Each predictor in the committee predicts its own labels using its own tree and then we aggregate the predictions with a majority vote over the committee. In order to better understand the competitiveness of MUCCA, we will compare it with some well-know algorithms besides GTG-ESS. Label Propagation (abbreviated LABPROP), introduced by Zhu et al. [2003], is a popular algorithm for node classification and one of the most accurate algorithms in the literature.", "startOffset": 166, "endOffset": 897}, {"referenceID": 3, "context": "SHAZOO is a quite new algorithm introduced by Cesa-Bianchi et al. [2011] and, at the best of our knowledge, it is the most accurate scalable algorithms between our competitors.", "startOffset": 46, "endOffset": 73}, {"referenceID": 3, "context": "We did not include in our comparison WTA (Cesa-Bianchi et al. [2010]) since it was always outperformed by SHAZOO.", "startOffset": 42, "endOffset": 69}, {"referenceID": 3, "context": "We did not include in our comparison WTA (Cesa-Bianchi et al. [2010]) since it was always outperformed by SHAZOO. Graph Perceptron (Herbster et al. [2009]) was omitted since it requires a lot of computational resource and performed poorly in previous comparisons (for example in Cesa-Bianchi et al.", "startOffset": 42, "endOffset": 155}, {"referenceID": 3, "context": "We did not include in our comparison WTA (Cesa-Bianchi et al. [2010]) since it was always outperformed by SHAZOO. Graph Perceptron (Herbster et al. [2009]) was omitted since it requires a lot of computational resource and performed poorly in previous comparisons (for example in Cesa-Bianchi et al. [2010]).", "startOffset": 42, "endOffset": 306}, {"referenceID": 3, "context": "In order to create a fair comparison, for the experimental activity we will generate our datasets in the same way of Cesa-Bianchi et al. [2011].", "startOffset": 117, "endOffset": 144}, {"referenceID": 8, "context": "Our algorithm is motivated within a game theoretic 1The Cardiotocography dataset was created by de Campos et al. [2000] and now is freely available on the UCI website with a complete description: http://archive.", "startOffset": 99, "endOffset": 120}], "year": 2011, "abstractText": "We introduce a scalable algorithm, MUCCA for multiclass node classification in weighted graphs. Unlike previously proposed methods for the same task, MUCCA works in time linear in the number of nodes. Our approach is based on a game-theoretic formulation of the problem in which the test labels are expressed as a Nash Equilibrium of a certain game. However, in order to achieve scalability, we find the equilibrium on a spanning tree of the original graph. Experiments on real-world data reveal that MUCCA is much faster than its competitors while achieving a similar predictive performance.", "creator": "LaTeX with hyperref package"}}}