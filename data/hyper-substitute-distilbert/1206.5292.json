{"id": "1206.5292", "review": {"conference": "arxiv", "VERSION": "v1", "DATE_OF_SUBMISSION": "20-Jun-2012", "title": "Markov Logic in Infinite Domains", "abstract": "combining first - round logic and associated phenomena again been controversial goal of scientists. markov logic ( richardson & partners ; domingos, 2007 ) accomplishes goals by locating weights preventing first - order computation and viewing them over templates for features of naive data. unfortunately, it does not have the full functionality of first - impression semantics, because infinite is none necessarily representing finite domains. this usage extends markov logic to infinite domains, by casting it in philosophical framework through gibbs measures ( georgii, 1988 ). economists show that a markov logic network ( atp ) without such particular measure as long as infinite interacting atom has a stable bit 0 neighbors. many interesting mechanisms are opposite this hierarchy. we similarly show but either mln admits a unique metric if the properties of no non - unit bits are small enough. will mentally examine the identities inside quantum distributions of consistent ones plus zero half - vanishing case. many important phenomena, including systems with phase transitions, are evaluated at mlns with non - decreasing measures. we view the problem of induction in mixed - come logic explaining the properties of fuzzy structures, others discuss how markov logic relates past previous infinite relations.", "histories": [["v1", "Wed, 20 Jun 2012 15:18:47 GMT  (235kb)", "http://arxiv.org/abs/1206.5292v1", "Appears in Proceedings of the Twenty-Third Conference on Uncertainty in Artificial Intelligence (UAI2007)"]], "COMMENTS": "Appears in Proceedings of the Twenty-Third Conference on Uncertainty in Artificial Intelligence (UAI2007)", "reviews": [], "SUBJECTS": "cs.AI", "authors": ["parag singla", "pedro domingos"], "accepted": false, "id": "1206.5292"}, "pdf": {"name": "1206.5292.pdf", "metadata": {"source": "CRF", "title": "Markov Logic in Infinite Domains", "authors": ["Parag Singla", "Pedro Domingos"], "emails": ["pedrod}@cs.washington.edu"], "sections": [{"heading": null, "text": "Combining first-order logic and probability has long been a goal of AI. Markov logic (Richardson & Domingos, 2006) accomplishes this by attaching weights to first-order formulas and viewing them as templates for features of Markov networks. Unfortunately, it does not have the full power of first-order logic, because it is only defined for finite domains. This paper extends Markov logic to infinite domains, by casting it in the framework of Gibbs measures (Georgii, 1988). We show that a Markov logic network (MLN) admits a Gibbs measure as long as each ground atom has a finite number of neighbors. Many interesting cases fall in this category. We also show that an MLN admits a unique measure if the weights of its non-unit clauses are small enough. We then examine the structure of the set of consistent measures in the non-unique case. Many important phenomena, including systems with phase transitions, are represented by MLNs with non-unique measures. We relate the problem of satisfiability in first-order logic to the properties of MLN measures, and discuss how Markov logic relates to previous infinite models."}, {"heading": "1 Introduction", "text": "Most AI problems are characterized by both uncertainty and complex structure, in the form of multiple interacting objects and relations. Handling both requires combining the capabilities of probabilistic models and firstorder logic. Attempts to achieve this have a long history, and have gathered steam in recent years. Within AI, Nilsson (1986) is an early example. Bacchus (1990), Halpern (1990) and coworkers (e.g., Bacchus et al. (1996)) produced a substantial body of relevant theoretical work. Around the same time, several authors began using logic programs to compactly specify complex Bayesian net-\nworks, an approach known as knowledge-based model construction (Wellman et al., 1992). More recently, many combinations of (subsets of) first-order logic and probability have been proposed in the burgeoning field of statistical relational learning (Getoor & Taskar, 2007), including probabilistic relational models (Friedman et al., 1999), stochastic logic programs (Muggleton, 1996), Bayesian logic programs (Kersting & De Raedt, 2001), and others.\nOne of the most powerful representations to date is Markov logic (Richardson & Domingos, 2006). Markov logic is a simple combination of Markov networks and first-order logic: each first-order formula has an associated weight, and each grounding of a formula becomes a feature in a Markov network, with the corresponding weight. The use of Markov networks instead of Bayesian networks obviates the difficult problem of avoiding cycles in all possible groundings of a relational model (Taskar et al., 2002). The use of first-order logic instead of more limited representations (e.g., description logics, Horn clauses) makes it possible to compactly represent a broader range of dependencies. For example, a dependency between relations like \u201cFriends of friends are (usually) friends\u201d cannot be specified compactly in (say) probabilistic relational models, but in Markov logic it suffices to write down the corresponding formula and weight. Markov logic has been successfully applied in a variety of domains (Domingos et al., 2006), and open source software with implementations of state-ofthe-art inference and learning algorithms for it is available (Kok et al., 2006).\nOne limitation of Markov logic is that it is only defined for finite domains. While this is seldom a problem in practice, considering the infinite limit can simplify the treatment of some problems, and yield new insights. We would also like to elucidate how far it is possible to combine the full power of first-order logic and graphical models. Thus in this paper we extend Markov logic to infinite domains. Our treatment is based on the theory of Gibbs measures (Georgii, 1988). Gibbs measures are infinite-dimensional extensions of Markov networks, and have been studied extensively by statistical physicists and mathematical statisti-\ncians, due to their importance in modeling systems with phase transitions. We begin with some necessary background on first-order logic and Gibbs measures. We then define MLNs over infinite domains, state sufficient conditions for the existence and uniqueness of a probability measure consistent with a given MLN, and examine the important case of MLNs with non-unique measures. Next, we establish a correspondence between the problem of satisfiability in logic and the existence of MLN measures with certain properties. We conclude with a discussion of the relationship between infinite MLNs and previous infinite relational models."}, {"heading": "2 Background", "text": ""}, {"heading": "2.1 First-Order Logic", "text": "A first-order knowledge base is a set of sentences or formulas in first-order logic (Genesereth & Nilsson, 1987). Formulas are constructed using four types of symbols: constants, variables, functions, and predicates. Constant symbols represent objects in the domain of discourse (e.g., people: Anna, Bob, Chris, etc.). Variable symbols range over the objects in the domain (or a subset of it, in which case they are typed). Function symbols (e.g., MotherOf) represent mappings from tuples of objects to objects. Predicate symbols represent relations among objects (e.g., Friends) or attributes of objects (e.g., Smokes). A term is any expression representing an object. It can be a constant, a variable, or a function applied to a tuple of terms. For example, Anna, x, and GreatestCommonDivisor(x, y) are terms. An atomic formula or atom is a predicate symbol applied to a tuple of terms (e.g., Friends(x, MotherOf(Anna))). A ground term is a term containing no variables. A ground atom or ground predicate is an atomic formula all of whose arguments are ground terms. Formulas are recursively constructed from atomic formulas using logical connectives and quantifiers. A positive literal is an atomic formula; a negative literal is a negated atomic formula. A clause is a disjunction of literals. Every first-order formula can be converted into an equivalent formula in prenex conjunctive normal form, Qx1 . . . QxnC(x1, . . . , xn), where each Q is a quantifier, the xi are the quantified variables, and C(. . .) is a conjunction of clauses.\nThe Herbrand universe U(C) of a set of clauses C is the set of all ground terms constructible from the function and constant symbols in C (or, if C contains no constants, some arbitrary constant, e.g., A). If C contains function symbols, U(C) is infinite. (For example, if C contains solely the function f and no constants, U(C) = {f(A), f(f(A)), f(f(f(A))), . . .}.) Some authors define the Herbrand base B(C) of C as the set of all ground atoms constructible from the predicate symbols in C and the terms in U(C). Others define it as the set of all ground clauses constructible from the clauses in C and the terms\nin U(C). For convenience, in this paper we will define it as the union of the two, and talk about the atoms in B(C) and clauses in B(C) as needed.\nAn interpretation is a mapping between the constant, predicate and function symbols in the language and the objects, functions and relations in the domain. In a Herbrand interpretation there is a one-to-one mapping between ground terms and objects (i.e., every object is represented by some ground term, and no two ground terms correspond to the same object). A model or possible world specifies which relations hold true in the domain. Together with an interpretation, it assigns a truth value to every atomic formula, and thus to every formula in the knowledge base."}, {"heading": "2.2 Gibbs Measures", "text": "Gibbs measures are infinite-dimensional generalizations of Gibbs distributions. A Gibbs distribution, also known as a log-linear model or exponential model, and equivalent under mild conditions to a Markov network or Markov random field, assigns to a state x the probability\nP (X=x) = 1\nZ exp (\u2211 i wifi(x) ) (1)\nwhere wi is any real number, fi is an arbitrary function or feature of x, and Z is a normalization constant. In this paper we will be concerned exclusively with Boolean states and functions (i.e., states are binary vectors, corresponding to possible worlds, and functions are logical formulas). Markov logic can be viewed as the use of first-order logic to compactly specify families of these functions (Richardson & Domingos, 2006). Thus, a natural way to generalize it to infinite domains is to use the existing theory of Gibbs measures (Georgii, 1988). Although Gibbs measures were primarily developed to model regular lattices (e.g., ferromagnetic materials, gas/liquid phases, etc.), the theory is quite general, and applies equally well to the richer structures definable using Markov logic.\nOne problem with defining probability distributions over infinite domains is that the probability of most or all worlds will be zero. Measure theory allows us to overcome this problem by instead assigning probabilities to sets of worlds (Billingsley, 1995). Let \u2126 denote the set of all possible worlds, and E denote a set of subsets of \u2126. E must be a \u03c3algebra, i.e., it must be non-empty and closed under complements and countable unions. A function \u00b5 : E \u2192 R is said to be a probability measure over (\u2126, E) if \u00b5(E) \u2265 0 for every E \u2208 E , \u00b5(\u2126) = 1, and \u00b5(\u22c3Ei) = \u2211\u00b5(Ei), where the union is taken over any countable collection of disjoint elements of E . A related difficulty is that in infinite domains the sum in Equation 1 may not exist. However, the distribution of any finite subset of the state variables conditioned on its complement is still well defined. We can thus define the infinite\ndistribution indirectly by means of an infinite collection of finite conditional distributions. This is the basic idea in Gibbs measures.\nLet us introduce some notation which will be used throughout the paper. Consider a countable set of variables S = {X1, X2, . . .}, where each Xi takes values in {0, 1}. Let X be a finite set of variables in S, and SX = S \\ X. A possible world \u03c9 \u2208 \u2126 is an assignment to all the variables in S. Let \u03c9X denote the assignment to the variables in X under \u03c9, and \u03c9Xi the assignment to Xi. Let X denote the set of all finite subsets of S. A basic event X = x is an assignment of values to a finite subset of variables X \u2208 X , and denotes the set of possible worlds \u03c9 \u2208 \u2126 such that wX = x. Let E be the set of all basic events, and let E be the \u03c3-algebra generated by E, i.e., the smallest \u03c3-algebra containing E. An element E of E is called an event, and E is the event space. The following treatment is adapted from Georgii (1988).\nDefinition 1. An interaction potential (or simply a potential) is a family \u03a6 = (\u03a6V)V\u2208X of functions \u03a6V : V \u2192 R such that, for all X \u2208 X and \u03c9 \u2208 \u2126, the summation\nH\u03a6 X (\u03c9) = \u2211 V\u2208X ,V\u2229X6=\u2205 \u03a6V(\u03c9V) (2)\nis finite. H\u03a6 X is called the Hamiltonian in X for \u03a6.\nIntuitively, the Hamiltonian H\u03a6 X includes a contribution from all the potentials \u03a6V which share at least one variable with the set X. Given an interaction potential \u03a6 and a subset of variables X, we define the conditional distribution \u03b3\u03a6\nX (X|SX) as1\n\u03b3\u03a6 X (X = x|SX = y) =\nexp(H\u03a6 X (x,y))\u2211\nx\u2208Dom(X)\nexp(H\u03a6X(x,y)) (3)\nwhere the denominator is called the partition function in X for \u03a6 and denoted by Z\u03a6\nX , and Dom(X) is the domain of\nX. Equation 3 can be easily extended to arbitrary events E \u2208 E by defining \u03b3\u03a6\nX (E|SX) to be non-zero only when\nE is consistent with the assignment in SX. Details are skipped here to keep the discussion simple, and can be found in Georgii (1988). The family of conditional distributions \u03b3\u03a6 = (\u03b3\u03a6\nX )X\u2208X as defined above is called a Gibb-\nsian specification.2\nGiven a measure \u00b5 over (\u2126, E) and conditional probabilities \u03b3\u03a6\nX (E|SX), let the composition \u00b5\u03b3\u03a6X be defined as\n\u00b5\u03b3\u03a6 X (E) = \u222b Dom(SX) \u03b3\u03a6 X (E|SX) \u2202\u00b5 (4)\n1For physical reasons, this equation is usually written with a negative sign in the exponent, i.e., exp[\u2212H\u03a6X(\u03c9)]. Since this is not relevant in Markov logic and does not affect any of the results, we omit it.\n2Georgii (1988) defines Gibbsian specifications in terms of underlying independent specifications. For simplicity, we assume these to be equidistributions and omit them throughout this paper.\n\u00b5\u03b3\u03a6 X (E) is the probability of event E according to the conditional probabilities \u03b3\u03a6 X (E|SX) and the measure \u00b5 on SX. We are now ready to define Gibbs measure.\nDefinition 2. Let \u03b3\u03a6 be a Gibbsian specification. Let \u00b5 be a probability measure over the measurable space (\u2126, E) such that, for every X \u2208 X and E \u2208 E , \u00b5(E) = \u00b5\u03b3\u03a6\nX (E).\nThen the specification \u03b3\u03a6 is said to admit the Gibbs measure \u00b5. Further, G(\u03b3\u03a6) denotes the set of all such measures.\nIn other words, a Gibbs measure is consistent with a Gibbsian specification if its event probabilities agree with those obtained from the specification. Given a Gibbsian specification, we can ask whether there exists a Gibbs measure consistent with it (|G(\u03b3\u03a6)| > 0), and whether it is unique (|G(\u03b3\u03a6)| = 1). In the non-unique case, we can ask what the structure of G(\u03b3\u03a6) is, and what the measures in it represent. We can also ask whether Gibbs measures with specific properties exist. The theory of Gibbs measures addresses these questions. In this paper we apply it to the case of Gibbsian specifications defined by MLNs."}, {"heading": "3 Infinite MLNs", "text": ""}, {"heading": "3.1 Definition", "text": "A Markov logic network (MLN) is a set of weighted firstorder formulas. As we saw in the previous section, these can be converted to equivalent formulas in prenex CNF. We will assume throughout that all existentially quantified variables have finite domains, unless otherwise specified. While this is a significant restriction, it still includes essentially all previous probabilistic relational representations as special cases. Existentially quantified formulas can now be replaced by finite disjunctions. By distributing conjunctions over disjunctions, every prenex CNF can now be converted to a quantifier-free CNF, with all variables implicitly universally quantified.\nThe Herbrand universe U(L) of an MLN L is the set of all ground terms constructible from the constants and function symbols in the MLN. The Herbrand base B(L) of L is the set of all ground atoms and clauses constructible from the predicates in L, the clauses in the CNF form of L, and the terms in U(L), replacing typed variables only by terms of the corresponding type. We assume Herbrand interpretations throughout. We are now ready to formally define MLNs.\nDefinition 3. A Markov logic network (MLN) L is a (finite) set of pairs (Fi, wi), where Fi is a formula in firstorder logic and wi is a real number. L defines a countable set of variables S and interaction potential \u03a6L = (\u03a6L\nX )X\u2208X , X being the set of all finite subsets of S, as\nfollows:\n1. S contains a binary variable for each atom in B(L).\nThe value of this variable is 1 if the atom is true, and 0 otherwise.\n2. \u03a6L X (x) = \u2211 j wjfj(x), where the sum is over the\nclauses Cj in B(L) whose arguments are exactly the elements of X. If Fi(j) is the formula in L from which Cj originated, and Fi(j) gave rise to n clauses in the CNF form of L, then wj = wi/n. fj(x) = 1 if Cj is true in world x, and fj = 0 otherwise.\nFor \u03a6L to correspond to a well-defined Gibbsian specification, the corresponding Hamiltonians (Equation 2) need to be finite. This brings us to the following definition.\nDefinition 4. Let C be a set of first-order clauses. Given a ground atom X \u2208 B(C), let the neighbors N(X) of X be the atoms that appear with it in some ground clause. C is said to be locally finite if each atom in the Herbrand base of C has a finite number of neighbors, i.e., \u2200X \u2208 B(C), |N(X)| < \u221e. An MLN (or knowledge base) is said to be locally finite if the set of its clauses is locally finite."}, {"heading": "It is easy to see that local finiteness is sufficient to ensure a well-defined Gibbsian specification. Given such an MLN", "text": ""}, {"heading": "L, the distribution \u03b3L", "text": "X of a set of variables X \u2208 X condi-\ntioned on its complement SX is given by\n\u03b3L X (X=x|SX=y) =\nexp (\u2211 j wjfj(x,y) )\n\u2211 x\u2032\u2208Dom(X) exp (\u2211 j wjfj(x \u2032,y) )\n(5) where the sum is over the clauses in B(L) that contain at least one element of X, and fj(x,y) = 1 if clause Cj is true under the assignment (x,y) and 0 otherwise. The corresponding Gibbsian specification is denoted by \u03b3L.\nFor an MLN to be locally finite, it suffices that it be \u03c3determinate.\nDefinition 5. A clause is \u03c3-determinate if all the variables with infinite domains it contains appear in all literals.3 A set of clauses is \u03c3-determinate if each clause in the set is \u03c3-determinate. An MLN is \u03c3-determinate if the set of its clauses is \u03c3-determinate.\nNotice that this definition does not require that all literals have the same infinite arguments; for example, the clause Q(x, y) \u21d2 R(f(x), g(x, y)) is \u03c3-determinate. In essence, \u03c3determinacy requires that the neighbors of an atom be defined by functions of its arguments. Because functions can be composed indefinitely, the network can be infinite; because first-order clauses have finite length, \u03c3-determinacy ensures that neighborhoods are still finite.\n3This is related to the notion of a determinate clause in logic programming. In a determinate clause, the grounding of the variables in the head determines the grounding of all the variables in the body. In infinite MLNs, any literal in a clause can be inferred from the others, not just the head from the body, so we require that the (infinite-domain) variables in each literal determine the variables in the others."}, {"heading": "If the MLN contains no function symbols, Definition 3 reduces to the one in Richardson and Domingos (2006), with", "text": "C being the constants appearing in the MLN. This can be easily seen by substituting X = S in Equation 5. Notice it would be equally possible to define features for conjunctions of clauses, and this may be preferable for some applications."}, {"heading": "3.2 Existence", "text": "Let L be a locally finite MLN. The focus of this section is to show that its specification \u03b3L always admits some measure \u00b5. It is useful to first gain some intuition as to why this might not always be the case. Consider an MLN stating that each person is loved by exactly one person: \u2200x \u2203!y Loves(y, x). Let \u03c9k denote the event Loves(Pk, Anna), i.e., Anna is loved by the kth person in the (countably infinite) domain. Then, in the limit of infinite weights, one would expect that \u00b5( \u22c3 \u03c9k) = \u00b5(\u2126) = 1.\nBut in fact \u00b5( \u22c3 \u03c9k) = \u2211 \u00b5(\u03c9k) = 0. The first equality holds because the \u03c9k\u2019s are disjoint, and the second one because each \u03c9k has zero probability of occurring by itself. There is a contradiction, and there exists no measure consistent with the MLN above.4 The reason the MLN fails to have a measure is that the formulas are not local, in the sense that the truth value of an atom depends on the truth values of infinite others. Locality is in fact the key property for the existence of a consistent measure, and local finiteness ensures it.\nDefinition 6. A function f : \u2126 \u2192 R is local if it depends only on a finite subset V \u2208 X . A Gibbsian specification \u03b3 = (\u03b3X)X\u2208X is local if each \u03b3X is local.\nLemma. Let L be a locally finite MLN, and \u03b3L the corresponding specification. Then \u03b3L is local.\nProof. Each Hamiltonian HL X is local, since by local finiteness it depends only on a finite number of potentials \u03c6L\nV . It\nfollows that each \u03b3L X is local, and hence the corresponding specification \u03b3L is also local.\nWe now state the theorem for the existence of a measure admitted by \u03b3L.\nTheorem 1. Let L be a locally finite MLN, and \u03b3L = (\u03b3L\nX )X\u2208X be the corresponding Gibbsian specification. Then there exists a measure \u00b5 over (\u2126, E) admitted by \u03b3L, i.e., |G(\u03b3L)| \u2265 1. Proof. To show the existence of a measure \u00b5, we need to prove the following two conditions:\n1. The net (\u03b3L X (X|SX))X\u2208X has a cluster point with re-\nspect to the weak topology on (\u2126, E).\n2. Each cluster point of (\u03b3L X (X|SX))X\u2208X belongs to\nG(\u03b3L). 4See Example 4.16 in Georgii (1988) for a detailed proof.\nIt is a well known result that, if all the variables Xi have finite domains, then the net in Condition 1 has a cluster point (see Section 4.2 in Georgii (1988)). Thus, since all the variables in the MLN are binary, Condition 1 holds. Further, since \u03b3L is local, every cluster point \u00b5 of the net (\u03b3L\nX (X|SX))X\u2208X belongs to G(\u03b3L) (Comment 4.18 in\nGeorgii (1988)). Therefore, Condition 2 is also satisfied. Hence there exists a measure \u00b5 consistent with the specification \u03b3L, as required."}, {"heading": "3.3 Uniqueness", "text": "This section addresses the question of under what conditions an MLN admits a unique measure. Let us first gain some intuition as to why an MLN might admit more than one measure. The only condition an MLN L imposes on a measure is that it should be consistent with the local conditional distributions \u03b3L\nX . But since these distribu-\ntions are local, they do not determine the behavior of the measure at infinity. Consider, for example, a semi-infinite two-dimensional lattice, where neighboring sites are more likely to have the same truth value than not. This can be represented by formulas of the form \u2200x, y Q(x, y) \u21d4 Q(s(x), y) and \u2200x, y Q(x, y) \u21d4 Q(x, s(y)), with a single constant 0 to define the origin (0, 0), and with s() being the successor function. The higher the weight w of these formulas, the more likely neighbors are to have the same value. This MLN has two extreme states: one where \u2200x S(x), and one where \u2200x \u00acS(x). Let us call these states \u03be and \u03be\u00ac, and let \u03be\u2032 be a local perturbation of \u03be (i.e., \u03be\u2032 differs from \u03be on only a finite number of sites). If we draw a contour around the sites where \u03be\u2032 and \u03be differ, then the log odds of \u03be and \u03be\u2032 increase with wd, where d is the length of the contour. Thus long contours are improbable, and there is a measure \u00b5 \u2192 \u03b4\u03be as w \u2192 \u221e. Since, by the same reasoning, there is a measure \u00b5\u00ac \u2192 \u03b4\u03be\u00ac as w \u2192 \u221e, the MLN admits more than one measure.5\nLet us now turn to the mathematical conditions for the existence of a unique measure for a given MLN L. Clearly, in the limit of all non-unit clause weights going to zero, L defines a unique distribution. Thus, by a continuity argument, one would expect the same to be true for small enough weights. This is indeed the case. To make it precise, let us first define the notion of the oscillation of a function. Given a function f : X \u2192 R, let the oscillation of f , \u03b4(f), be defined as\n\u03b4(f) = max x,x\u2032\u2208Dom(X)\n|f(x)\u2212 f(x\u2032)|\n= max x |f(x)| \u2212min x |f(x)| (6)\n5Notice that this argument fails for a one-dimensional lattice (equivalent to a Markov chain), since in this case an arbitrarily large number of sites can be separated from the rest by a contour of length 2. Non-uniqueness (corresponding to a non-ergodic chain) can then only be obtained by making some weights infinite (corresponding to zero transition probabilities).\nThe oscillation of a function is thus simply the difference between its extreme values. We can now state a sufficient condition for the existence of a unique measure.\nTheorem 2. Let L be a locally finite MLN with interaction potential \u03a6L and Gibbsian specification \u03b3L such that\nsup Xi\u2208S \u2211 Cj\u2208C(Xi) (|Cj | \u2212 1)|wj | < 2 (7)\nwhere C(Xi) is the set of ground clauses in which Xi appears, |Cj | is the number of ground atoms appearing in clause Cj , and wj is its weight. Then \u03b3L admits a unique Gibbs measure.\nProof. Based on Theorem 8.7 and Proposition 8.8 in Georgii (1988), a sufficient condition for uniqueness is\nsup Xi\u2208S \u2211 V\u220bXi (|V| \u2212 1)\u03b4(\u03a6L V ) < 2 (8)\nRewriting this condition in terms of the ground formulas in which a variable Xi appears (see Definition 3) yields the desired result.\nNote that, as alluded to before, the above condition does not depend on the weight of the unit clauses. This is because for a unit clause |Cj | \u2212 1 = 0. If we define the interaction between two variables as the sum of the weights of all the ground clauses in which they appear together, then the above theorem states that the total sum of the interactions of any variable with its neighbors should be less than 2 for the measure to be unique.\nTwo other sufficient conditions are worth mentioning briefly. One is that, if the weights of the unit clauses are sufficiently large compared to the weights of the non-unit ones, the measure is unique. Intuitively, the unit terms \u201cdrown out\u201d the interactions, rendering the variables approximately independent. The other condition is that, if the MLN is a one-dimensional lattice, it suffices that the total interaction between the variables to the left and right of any arc be finite. This corresponds to the ergodicity condition for a Markov chain."}, {"heading": "3.4 Non-unique MLNs", "text": "At first sight, it might appear that non-uniqueness is an undesirable property, and non-unique MLNs are not an interesting object of study. However, the non-unique case is in fact quite important, because many phenomena of interest are represented by MLNs with non-unique measures (for example, very large social networks with strong wordof-mouth effects). The question of what these measures represent, and how they relate to each other, then becomes important. This is the subject of this section.\nThe first observation is that the set of all Gibbs measures G(\u03b3L) is convex. That is, if \u00b5, \u00b5\u2032 \u2208 G(\u03b3L) then \u03bd \u2208 G(\u03b3L), where \u03bd = s\u00b5+(1\u2212s)\u00b5\u2032, s \u2208 (0, 1). This is easily verified\nby substituting \u03bd in Equation 4. Hence, the non-uniqueness of a Gibbs measure implies the existence of infinitely many consistent Gibbs measures. Further, many properties of the set G(\u03b3L) depend on the set of extreme Gibbs measures ex G(\u03b3L), where \u00b5 \u2208 ex G(\u03b3L) if \u00b5 \u2208 G(\u03b3L) cannot be written as a linear combination of two distinct measures in G(\u03b3L). An important notion to understand the properties of extreme Gibbs measures is the notion of a tail event. Consider a subset S\u2032 of S. Let \u03c3(S\u2032) denote the \u03c3-algebra generated by the set of basic events involving only variables in S\u2032. Then we define the tail \u03c3-algebra T as\nT = \u22c2\nX\u2208X \u03c3(SX) (9)\nAny event belonging to T is called a tail event. T is precisely the set of events which do not depend on the value of any finite set of variables, but rather only on the behavior at infinity. For example, in the infinite tosses of a coin, the event that ten consecutive heads come out infinitely many times is a tail event. Similarly, in the lattice example in the previous section, the event that a finite number of variables have the value 1 is a tail event. Events in T can be thought of as representing macroscopic properties of the system being modeled.\nDefinition 7. A measure \u00b5 is trivial on a \u03c3-algebra E if \u00b5(E) = 0 or 1 for all E \u2208 E .\nThe following theorem (adapted from Theorem 7.8 in Georgii (1988)) describes the relationship between the extreme Gibbs measures and the tail \u03c3-algebra.\nTheorem 3. Let L be a locally finite MLN, and \u03b3L denote the corresponding Gibbsian specification. Then the following results hold:\n1. A measure \u00b5 \u2208 ex G(\u03b3L)) iff it is trivial on the tail \u03c3-algebra T .\n2. Each measure \u00b5 is uniquely determined by its behavior on the tail \u03c3-algebra, i.e., if \u00b51 = \u00b52 on T then \u00b51 = \u00b52.\nIt is easy to see that each extreme measure corresponds to some particular value for all the macroscopic properties of the network. In physical systems, extreme measures correspond to phases of the system (e.g., liquid vs. gas, or different directions of magnetization), and non-extreme measures correspond to probability distributions over phases. Uncertainty over phases arises when our knowledge of a system is not sufficient to determine its macroscopic state. Clearly, the study of non-unique MLNs beyond the highly regular ones statistical physicists have focused on promises to be quite interesting. In the next section we take a step in this direction by considering the problem of satisfiability in the context of MLN measures."}, {"heading": "4 Satisfiability and Entailment", "text": "Richardson and Domingos (2006) showed that, in finite domains, first-order logic can be viewed as the limiting case of Markov logic when all weights tend to infinity, in the following sense. If we convert a satisfiable knowledge base"}, {"heading": "K into an MLN LK by assigning the same weight w \u2192 \u221e to all clauses, then LK defines a uniform distribution over the worlds satisfying K. Further, K entails a formula \u03b1 iff", "text": "LK assigns probability 1 to the set of worlds satisfying \u03b1 (Proposition 4.3). In this section we extend this result to infinite domains.\nConsider an MLN L such that each clause in its CNF form has the same weight w. In the limit w \u2192 \u221e, L does not correspond to a valid Gibbsian specification, since the Hamiltonians defined in Equation 2 are no longer finite. Revisiting Equation 5 in the limit of all equal infinite clause weights, the limiting conditional distribution is equidistribution over those configurations X which satisfy the maximum number of clauses given SX = y. It turns out we can still talk about the existence of a measure consistent with these conditional distributions, because they constitute a valid specification (though not Gibbsian) under the same conditions as in the finite weight case. We omit the details and proofs for lack of space; they can be found in Singla and Domingos (2007). Existence of a measure follows as in the case of finite weights because of the locality of conditional distributions. We now define the notion of a satisfying measure, which is central to the results presented in this section.\nDefinition 8. Let L be a locally finite MLN. Given a clause Ci \u2208 B(L), let Vi denote the set of Boolean variables appearing in Ci. A measure \u00b5 \u2208 G(\u03b3L) is said to be a satisfying measure for L if, for every ground clause Ci \u2208 B(L), \u00b5 assigns non-zero probability only to the satisfying assignments of the variables in Ci, i.e., \u00b5(Vi = vi) > 0 implies that Vi = vi is a satisfying assignment for Ci. S(\u03b3L) denotes the set of all satisfying measures for L.\nInformally, a satisfying measure assigns non-zero probability only to those worlds which are consistent with all the formulas in L. Intuitively, existence of a satisfying measure for L should be in some way related to the existence of a satisfying assignment for the corresponding knowledge base. Our next theorem formalizes this intuition.\nTheorem 4. Let K be a locally finite knowledge base, and let L\u221e be the MLN obtained by assigning weight w \u2192 \u221e to all the clauses in K. Then there exists a satisfying measure for L\u221e iff K is satisfiable. Mathematically,\n|S(\u03b3L\u221e)| > 0 \u21d4 Satisfiable(K) (10) Proof. Let us first prove that existence of a satisfying measure implies satisfiability of K. This is equivalent to proving that unsatisfiability of K implies non-existence of a satisfying measure. Let K be unsatisfiable. Equivalently,\nB(K), the Herbrand base of K, is unsatisfiable. By Herbrand\u2019s theorem, there exists a finite set of ground clauses C \u2286 B(K) that is unsatisfiable. Let V denote the set of variables appearing in C. Then every assignment v to the variables in V violates some clause in C. Let \u00b5 denote a measure for L\u221e. Since \u00b5 is a probability measure,\u2211\nv\u2208Dom(V) \u00b5(V = v) = 1. Further, since V is finite, there exists some v \u2208 Dom(V) such that \u00b5(V = v) > 0. Let Ci \u2208 C be some clause violated by the assignment v (every assignment violates some clause). Let Vi denote the set of variables in Ci and vi be the restriction of assignment v to the variables in Vi. Then vi is an unsatisfying assignment for Ci. Further, \u00b5(Vi = vi) \u2265 \u00b5(V = v) > 0. Hence \u00b5 cannot be a satisfying measure for L\u221e. Since the above argument holds for any \u00b5 \u2208 G(\u03b3L\u221e), there does not exist a satisfying measure for L\u221e when K is unsatisfiable.\nNext, we need to prove that satisfiability of K implies existence of a satisfying measure. We will only give a proof sketch here; the full proof can be found in Singla and Domingos (2007). Let K be satisfiable. Now, consider a finite subset X of the variables defined by L\u221e. Given X, let \u2206X denote the set of those probability distributions over X which assign non-zero probability only to the configurations which are partial satisfying assignments of K. We will call \u2206X the set of satisfying distributions over X. \u2206X is a compact set. Let Y denote the set of neighbors of the variables in X. We define FX : \u2206Y \u2192 \u2206X to be the function which maps a satisfying distribution over Y to a satisfying distribution over X given the conditional distribution \u03b3L\u221e\nX (X|SX). The mapping results in a satis-\nfying distribution over X because, in the limit of all equal infinite weights, the conditional distribution over X is nonzero only for the satisfying assignments of X. Since \u2206Y is compact, its image under the continuous function FX is also compact.\nGiven Xi \u2282 Xj and their neighbors, Yi and Yj respectively, we show that if \u03c0Xj \u2208 \u2206Xj is in the image of \u2206Yj under FXj , then \u03c0Xi = \u2211 Xj\u2212Xi \u03c0Xj is in the image of \u2206Xi under FXi . This process can then be repeated for ever-increasing sets Xk \u2283 Xi. This defines a sequence (Tji ) j=\u221e j=i of non-empty subsets of satisfying distributions over Xi. Further, it is easy to show that \u2200k Tk+1i \u2286 Tki . Since each Tki is compact and non-empty, from the theory of compact sets we obtain that the countably infinite intersection Ti = \u22c2j=\u221e j=i T j i is also non-empty.\nLet (X1, X2, . . . , Xk, . . .) be some ordering of the variables defined by L\u221e, and let Xk = {X1, X2, . . .Xk}. We now define a satisfying measure \u00b5 as follows. We define \u00b5(X1) to be some element of T1. Given \u00b5(Xk), we define \u00b5(Xk+1) to be that element of Tk+1 whose marginal is \u00b5(Xk) (such an element always exists, by construction). For an arbitrary set of variables X, let k be the smallest index such that X \u2286 Xk, and define \u00b5(X) = \u2211 Xk\\X \u00b5(Xk). We show that \u00b5 defined in such\na way satisfies the properties of a probability measure (see Section 2.2). Finally, \u00b5 is a satisfying measure because \u2200k \u00b5(Xk) \u2208 Tk and each Tk is a set of satisfying distributions over Xk.\nCorollary. Let K be a locally finite knowledge base. Let \u03b1 be a first-order formula, and L\u03b1\u221e be the MLN obtained by assigning weight w \u2192 \u221e to all clauses in K \u222a {\u00ac\u03b1}. Then K entails \u03b1 iff L\u03b1\u221e has no satisfying measure. Mathematically, K |= \u03b1 \u21d4 |S(\u03b3L\u03b1\u221e)| = 0 (11) Thus, for locally finite knowledge bases with Herbrand interpretations, first-order logic can be viewed as the limiting case of Markov logic when all weights tend to infinity. Whether these conditions can be relaxed is a question for future work."}, {"heading": "5 Related Work", "text": "A number of relational representations capable of handling infinite domains have been proposed in recent years. Generally, they rely on strong restrictions to make this possible. To our knowledge, Markov logic is the most flexible language for modeling infinite relational domains to date. In this section we briefly review the main approaches.\nStochastic logic programs (Muggleton, 1996) are generalizations of probabilistic context-free grammars. PCFGs allow for infinite derivations but as a result do not always represent valid distributions (Booth & Thompson, 1973). In SLPs these issues are avoided by explicitly assigning zero probability to infinite derivations. Similar remarks apply to related languages like independent choice logic (Poole, 1997) and PRISM (Sato & Kameya, 1997).\nMany approaches combine logic programming and Bayesian networks. The most advanced one is arguably Bayesian logic programs (Kersting & De Raedt, 2001). Kersting and De Raedt show that, if all nodes have a finite number of ancestors, a BLP represents a unique distribution. This is a stronger restriction than finite neighborhoods. Richardson and Domingos (2006) showed how BLPs can be converted into Markov logic without loss of representational efficiency.\nJaeger (1998) shows that probabilistic queries are decidable for a very restricted language where a ground atom cannot depend on other groundings of the same predicate. Jaeger shows that if this restriction is removed queries become undecidable.\nRecursive probability models are a combination of Bayesian networks and description logics (Pfeffer & Koller, 2000). Like Markov logic, RPMs require finite neighborhoods, and in fact existence for RPMs can be proved succinctly by converting them to Markov logic and applying Theorem 1. Pfeffer and Koller show that RPMs\ndo not always represent unique distributions, but do not study conditions for uniqueness. Description logics are a restricted subset of first-order logic, and thus MLNs are considerably more flexible than RPMs.\nContingent Bayesian networks (Milch et al., 2005) allow infinite ancestors, but require that, for each variable with infinite ancestors, there exist a set of mutually exclusive and exhaustive contexts (assignments to finite sets of variables) such that in every context only a finite number of ancestors affect the probability of the variable. This is a strong restriction, excluding even simple infinite models like backward Markov chains (Pfeffer & Koller, 2000).\nMulti-entity Bayesian networks are another relational extension of Bayesian networks (Laskey & Costa, 2005). Laskey and Costa claim that MEBNs allow infinite parents and arbitrary first-order formulas, but the definition of MEBN explicitly requires that, for each atom X and increasing sequence of substates S1 \u2282 S2 \u2282 . . ., there exist a finite N such that P (X |Sk) = P (X |SN ) for k > N . This assumption necessarily excludes many dependencies expressible in first-order logic (e.g., \u2200x \u2203!y Loves(y, x)). Further, unlike in Markov logic, first-order formulas in MEBNs must be hard (and consistent). Laskey and Costa do not specify a language for specifying conditional distributions; they simply assume that a terminating algorithm for computing them exists. Thus the question of what infinite distributions can be specified by MEBNs remains open."}, {"heading": "6 Conclusion", "text": "In this paper, we extended the semantics of Markov logic to infinite domains using the theory of Gibbs measures. We gave sufficient conditions for the existence and uniqueness of a measure consistent with the local potentials defined by an MLN. We also described the structure of the set of consistent measures when it is not a singleton, and showed how the problem of satisfiability can be cast in terms of MLN measures. Directions for future work include designing lifted inference and learning algorithms for infinite MLNs, deriving alternative conditions for existence and uniqueness, analyzing the structure of consistent measure sets in more detail, extending the theory to non-Herbrand interpretations and recursive random fields (Lowd & Domingos, 2007), and studying interesting special cases of infinite MLNs."}, {"heading": "Acknowledgements", "text": "We are grateful to Michael Jordan for helpful discussions. This research was partly funded by DARPA contract NBCHD030010/02-000225, DARPA grant FA8750-05-2-0283, NSF grant IIS-0534881, and ONR grant N-00014-05-1-0313. The views and conclusions contained in this document are those of the authors and should not be interpreted as necessarily represent-\ning the official policies, either expressed or implied, of DARPA, NSF, ONR, or the United States Government."}], "references": [{"title": "Representing and reasoning with probabilistic knowledge", "author": ["F. Bacchus"], "venue": "MIT Press.", "citeRegEx": "Bacchus,? 1990", "shortCiteRegEx": "Bacchus", "year": 1990}, {"title": "From statistical knowledge bases to degrees of belief", "author": ["F. Bacchus", "A.J. Grove", "J.Y. Halpern", "D. Koller"], "venue": "Artif. Intel.,", "citeRegEx": "Bacchus et al\\.,? \\Q1996\\E", "shortCiteRegEx": "Bacchus et al\\.", "year": 1996}, {"title": "Probability and measure (3rd Ed.)", "author": ["P. Billingsley"], "venue": null, "citeRegEx": "Billingsley,? \\Q1995\\E", "shortCiteRegEx": "Billingsley", "year": 1995}, {"title": "Applying probability measures to abstract languages", "author": ["T. Booth", "R. Thompson"], "venue": "IEEE Transactions on Computers,", "citeRegEx": "Booth and Thompson,? \\Q1973\\E", "shortCiteRegEx": "Booth and Thompson", "year": 1973}, {"title": "Statistical properties of probabilistic context-free grammars", "author": ["Z. Chi"], "venue": "Computational Linguistics, 25, 131\u2013160.", "citeRegEx": "Chi,? 1999", "shortCiteRegEx": "Chi", "year": 1999}, {"title": "Unifying logical and statistical AI", "author": ["P. Domingos", "S. Kok", "H. Poon", "M. Richardson", "P. Singla"], "venue": "Proc. AAAI-06", "citeRegEx": "Domingos et al\\.,? \\Q2006\\E", "shortCiteRegEx": "Domingos et al\\.", "year": 2006}, {"title": "Learning probabilistic relational models", "author": ["N. Friedman", "L. Getoor", "D. Koller", "A. Pfeffer"], "venue": "Proc. IJCAI-99 (pp", "citeRegEx": "Friedman et al\\.,? \\Q1999\\E", "shortCiteRegEx": "Friedman et al\\.", "year": 1999}, {"title": "Logical foundations of artificial intelligence", "author": ["M.R. Genesereth", "N.J. Nilsson"], "venue": null, "citeRegEx": "Genesereth and Nilsson,? \\Q1987\\E", "shortCiteRegEx": "Genesereth and Nilsson", "year": 1987}, {"title": "Gibbs measures and phase transitions", "author": ["H. Georgii"], "venue": "De Gruyter.", "citeRegEx": "Georgii,? 1988", "shortCiteRegEx": "Georgii", "year": 1988}, {"title": "Introduction to Statistical Relational Learning", "author": ["L. Getoor", "B. Taskar"], "venue": null, "citeRegEx": "Getoor and Taskar,? \\Q2007\\E", "shortCiteRegEx": "Getoor and Taskar", "year": 2007}, {"title": "An analysis of first-order logics of probability", "author": ["J. Halpern"], "venue": "Artif. Intel., 46, 311\u2013350.", "citeRegEx": "Halpern,? 1990", "shortCiteRegEx": "Halpern", "year": 1990}, {"title": "Reasoning about infinite random structures with relational Bayesian networks", "author": ["M. Jaeger"], "venue": "Proc. KR-98.", "citeRegEx": "Jaeger,? 1998", "shortCiteRegEx": "Jaeger", "year": 1998}, {"title": "Towards combining inductive logic programming with Bayesian networks", "author": ["K. Kersting", "L. De Raedt"], "venue": "Proc. ILP-01", "citeRegEx": "Kersting and Raedt,? \\Q2001\\E", "shortCiteRegEx": "Kersting and Raedt", "year": 2001}, {"title": "The Alchemy system for statistical relational AI (Tech. Rept.)", "author": ["S. Kok", "M. Sumner", "M. Richardson", "P. Singla", "H. Poon", "P. Domingos"], "venue": null, "citeRegEx": "Kok et al\\.,? \\Q2006\\E", "shortCiteRegEx": "Kok et al\\.", "year": 2006}, {"title": "Of starships and Klingons: Bayesian logic for 23rd century", "author": ["K. Laskey", "P. Costa"], "venue": "Proc. UAI-05", "citeRegEx": "Laskey and Costa,? \\Q2005\\E", "shortCiteRegEx": "Laskey and Costa", "year": 2005}, {"title": "Recursive random fields", "author": ["D. Lowd", "P. Domingos"], "venue": "Proc. IJCAI-07", "citeRegEx": "Lowd and Domingos,? \\Q2007\\E", "shortCiteRegEx": "Lowd and Domingos", "year": 2007}, {"title": "Approximate inference for infinite contingent Bayesian networks", "author": ["B. Milch", "B. Marthi", "D. Sontag", "S. Russell", "D.L. Ong"], "venue": "Proc. AISTATS-05", "citeRegEx": "Milch et al\\.,? \\Q2005\\E", "shortCiteRegEx": "Milch et al\\.", "year": 2005}, {"title": "Stochastic logic programs", "author": ["S. Muggleton"], "venue": "L. De Raedt (Ed.), Advances in inductive logic programming, 254\u2013264. IOS Press.", "citeRegEx": "Muggleton,? 1996", "shortCiteRegEx": "Muggleton", "year": 1996}, {"title": "Probabilistic logic", "author": ["N. Nilsson"], "venue": "Artif. Intel., 28, 71\u201387.", "citeRegEx": "Nilsson,? 1986", "shortCiteRegEx": "Nilsson", "year": 1986}, {"title": "Semantics and inference for recursive probability models", "author": ["A. Pfeffer", "D. Koller"], "venue": "Proc. AAAI-00", "citeRegEx": "Pfeffer and Koller,? \\Q2000\\E", "shortCiteRegEx": "Pfeffer and Koller", "year": 2000}, {"title": "The independent choice logic for modelling multiple agents under uncertainty", "author": ["D. Poole"], "venue": "Artif. Intel., 94, 7\u201356.", "citeRegEx": "Poole,? 1997", "shortCiteRegEx": "Poole", "year": 1997}, {"title": "PRISM: A symbolic-statistical modeling language", "author": ["T. Sato", "Y. Kameya"], "venue": "Proc. AAAI-97", "citeRegEx": "Sato and Kameya,? \\Q1997\\E", "shortCiteRegEx": "Sato and Kameya", "year": 1997}, {"title": "Markov logic in infinite domains (Tech", "author": ["P. Singla", "P. Domingos"], "venue": "Rept.). Dept. Comp. Sci. & Eng., Univ. Washington", "citeRegEx": "Singla and Domingos,? \\Q2007\\E", "shortCiteRegEx": "Singla and Domingos", "year": 2007}, {"title": "Discriminative probabilistic models for relational data", "author": ["B. Taskar", "P. Abbeel", "D. Koller"], "venue": "Proc. UAI-02", "citeRegEx": "Taskar et al\\.,? \\Q2002\\E", "shortCiteRegEx": "Taskar et al\\.", "year": 2002}, {"title": "From knowledge bases to decision models", "author": ["M. Wellman", "J.S. Breese", "R.P. Goldman"], "venue": "Knowl. Eng. Rev.,", "citeRegEx": "Wellman et al\\.,? \\Q1992\\E", "shortCiteRegEx": "Wellman et al\\.", "year": 1992}], "referenceMentions": [{"referenceID": 8, "context": "This paper extends Markov logic to infinite domains, by casting it in the framework of Gibbs measures (Georgii, 1988).", "startOffset": 102, "endOffset": 117}, {"referenceID": 24, "context": "Around the same time, several authors began using logic programs to compactly specify complex Bayesian networks, an approach known as knowledge-based model construction (Wellman et al., 1992).", "startOffset": 169, "endOffset": 191}, {"referenceID": 6, "context": "More recently, many combinations of (subsets of) first-order logic and probability have been proposed in the burgeoning field of statistical relational learning (Getoor & Taskar, 2007), including probabilistic relational models (Friedman et al., 1999), stochastic logic programs (Muggleton, 1996), Bayesian logic programs (Kersting & De Raedt, 2001), and others.", "startOffset": 228, "endOffset": 251}, {"referenceID": 17, "context": ", 1999), stochastic logic programs (Muggleton, 1996), Bayesian logic programs (Kersting & De Raedt, 2001), and others.", "startOffset": 35, "endOffset": 52}, {"referenceID": 2, "context": "Attempts to achieve this have a long history, and have gathered steam in recent years. Within AI, Nilsson (1986) is an early example.", "startOffset": 13, "endOffset": 113}, {"referenceID": 0, "context": "Bacchus (1990), Halpern (1990) and coworkers (e.", "startOffset": 0, "endOffset": 15}, {"referenceID": 0, "context": "Bacchus (1990), Halpern (1990) and coworkers (e.", "startOffset": 0, "endOffset": 31}, {"referenceID": 0, "context": "Bacchus (1990), Halpern (1990) and coworkers (e.g., Bacchus et al. (1996)) produced a substantial body of relevant theoretical work.", "startOffset": 0, "endOffset": 74}, {"referenceID": 23, "context": "The use of Markov networks instead of Bayesian networks obviates the difficult problem of avoiding cycles in all possible groundings of a relational model (Taskar et al., 2002).", "startOffset": 155, "endOffset": 176}, {"referenceID": 5, "context": "Markov logic has been successfully applied in a variety of domains (Domingos et al., 2006), and open source software with implementations of state-ofthe-art inference and learning algorithms for it is available (Kok et al.", "startOffset": 67, "endOffset": 90}, {"referenceID": 13, "context": ", 2006), and open source software with implementations of state-ofthe-art inference and learning algorithms for it is available (Kok et al., 2006).", "startOffset": 128, "endOffset": 146}, {"referenceID": 8, "context": "Our treatment is based on the theory of Gibbs measures (Georgii, 1988).", "startOffset": 55, "endOffset": 70}, {"referenceID": 8, "context": "Thus, a natural way to generalize it to infinite domains is to use the existing theory of Gibbs measures (Georgii, 1988).", "startOffset": 105, "endOffset": 120}, {"referenceID": 2, "context": "Measure theory allows us to overcome this problem by instead assigning probabilities to sets of worlds (Billingsley, 1995).", "startOffset": 103, "endOffset": 122}, {"referenceID": 8, "context": "The following treatment is adapted from Georgii (1988).", "startOffset": 40, "endOffset": 55}, {"referenceID": 8, "context": "Details are skipped here to keep the discussion simple, and can be found in Georgii (1988). The family of conditional distributions \u03b3 = (\u03b3 X )X\u2208X as defined above is called a Gibbsian specification.", "startOffset": 76, "endOffset": 91}, {"referenceID": 8, "context": "Georgii (1988) defines Gibbsian specifications in terms of underlying independent specifications.", "startOffset": 0, "endOffset": 15}, {"referenceID": 8, "context": "16 in Georgii (1988) for a detailed proof.", "startOffset": 6, "endOffset": 21}, {"referenceID": 8, "context": "2 in Georgii (1988)).", "startOffset": 5, "endOffset": 20}, {"referenceID": 8, "context": "2 in Georgii (1988)). Thus, since all the variables in the MLN are binary, Condition 1 holds. Further, since \u03b3 is local, every cluster point \u03bc of the net (\u03b3 X (X|SX))X\u2208X belongs to G(\u03b3L) (Comment 4.18 in Georgii (1988)).", "startOffset": 5, "endOffset": 219}, {"referenceID": 8, "context": "8 in Georgii (1988), a sufficient condition for uniqueness is", "startOffset": 5, "endOffset": 20}, {"referenceID": 8, "context": "8 in Georgii (1988)) describes the relationship between the extreme Gibbs measures and the tail \u03c3-algebra.", "startOffset": 5, "endOffset": 20}, {"referenceID": 22, "context": "We omit the details and proofs for lack of space; they can be found in Singla and Domingos (2007). Existence of a measure follows as in the case of finite weights because of the locality of conditional distributions.", "startOffset": 71, "endOffset": 98}, {"referenceID": 22, "context": "We will only give a proof sketch here; the full proof can be found in Singla and Domingos (2007). Let K be satisfiable.", "startOffset": 70, "endOffset": 97}, {"referenceID": 17, "context": "Stochastic logic programs (Muggleton, 1996) are generalizations of probabilistic context-free grammars.", "startOffset": 26, "endOffset": 43}, {"referenceID": 20, "context": "Similar remarks apply to related languages like independent choice logic (Poole, 1997) and PRISM (Sato & Kameya, 1997).", "startOffset": 73, "endOffset": 86}, {"referenceID": 16, "context": "Contingent Bayesian networks (Milch et al., 2005) allow infinite ancestors, but require that, for each variable with infinite ancestors, there exist a set of mutually exclusive and exhaustive contexts (assignments to finite sets of variables) such that in every context only a finite number of ancestors affect the probability of the variable.", "startOffset": 29, "endOffset": 49}], "year": 2009, "abstractText": "Combining first-order logic and probability has long been a goal of AI. Markov logic (Richardson & Domingos, 2006) accomplishes this by attaching weights to first-order formulas and viewing them as templates for features of Markov networks. Unfortunately, it does not have the full power of first-order logic, because it is only defined for finite domains. This paper extends Markov logic to infinite domains, by casting it in the framework of Gibbs measures (Georgii, 1988). We show that a Markov logic network (MLN) admits a Gibbs measure as long as each ground atom has a finite number of neighbors. Many interesting cases fall in this category. We also show that an MLN admits a unique measure if the weights of its non-unit clauses are small enough. We then examine the structure of the set of consistent measures in the non-unique case. Many important phenomena, including systems with phase transitions, are represented by MLNs with non-unique measures. We relate the problem of satisfiability in first-order logic to the properties of MLN measures, and discuss how Markov logic relates to previous infinite models.", "creator": "Adobe InDesign CS2 (4.0.4)"}}}