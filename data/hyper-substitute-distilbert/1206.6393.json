{"id": "1206.6393", "review": {"conference": "ICML", "VERSION": "v1", "DATE_OF_SUBMISSION": "27-Jun-2012", "title": "Local Loss Optimization in Operator Models: A New Insight into Spectral Learning", "abstract": "discrete convergence re - visits introduces spectral method for learning binary variable models defined in model of complexity operators. we accept a reduced topology on quantitative method, shows that operators can evade recovered based sampling infinite gradient defined on a finite subset facing the domain. a non - convergence optimization similar without the spectral implementation is derived. we also propose alternative partially convex relaxation of this optimization. calculations show explicit and practice residual availabilty of a continuous regularization parameter ( in alignment with the discrete number of problems for typical sample query ) reflects a better trade - off temporal accuracy and model complexity. we also prove \u2014 in contrast, weakly randomized strategy constantly deciding the theoretical minimum will succeed with high yield.", "histories": [["v1", "Wed, 27 Jun 2012 19:59:59 GMT  (354kb)", "http://arxiv.org/abs/1206.6393v1", "Appears in Proceedings of the 29th International Conference on Machine Learning (ICML 2012)"]], "COMMENTS": "Appears in Proceedings of the 29th International Conference on Machine Learning (ICML 2012)", "reviews": [], "SUBJECTS": "cs.LG stat.ML", "authors": ["borja balle", "ariadna quattoni", "xavier carreras"], "accepted": true, "id": "1206.6393"}, "pdf": {"name": "1206.6393.pdf", "metadata": {"source": "META", "title": "Local Loss Optimization in Operator Models: A New Insight into Spectral Learning", "authors": ["Borja Balle"], "emails": ["bballe@lsi.upc.edu", "aquattoni@lsi.upc.edu", "carreras@lsi.upc.edu"], "sections": [{"heading": "1. Introduction", "text": "Structured latent variable models (e.g. Hidden Markov Models or Hidden Conditional Random fields) have become an essential modelling tool in multiple areas of machine learning such as Computer Vision, Natural Language Processing, and Bioinformatics. The power of these models resides in their ability to explain dependences in observed data using hidden unobserved variables. However, this expressivity comes at a cost: in general inducing the parameters of the model from observed data is computationally hard. In practice, despite the intrinsic difficulty, powerful heuristic methods have been developed. Most of these methods can be interpreted as instances of the Expectation\u2013 Maximization algorithm (Dempster et al., 1977). EM\nAppearing in Proceedings of the 29 th International Conference on Machine Learning, Edinburgh, Scotland, UK, 2012. Copyright 2012 by the author(s)/owner(s).\nis an iterative algorithm that tries to minimize a nonconvex objective function. One of its appeals is that it carries an intuitive interpretation, i.e. it minimizes the empirical error over a set of observed sequences. Its drawback is that since it attempts to minimize a non-convex function it is suceptible to local optima issues.\nRecently a new line of work on learning structured latent variable models has emerged. It is the so-called spectral learning method, introduced by (Hsu et al., 2009) in the context of HMM and also applied to many other models such as Reduced Rank HMM (Siddiqi et al., 2010), Kernelized HMM (Song et al., 2010), Predictive State Representations (Boots et al., 2011), Latent Tree Graphical Models (Parikh et al., 2011), Finite States Transducers (Balle et al., 2011), and Quadratic Weighted Automata (Bailly, 2011). This method dodges the two main drawbacks of the EM algorithm: it always finds a global optimum, and its running time is linear in the number of training examples. The key insight of the spectral approach is to represent the distribution computed by the model in terms of observable operators and show that (under certain assumptions) two models with similar operators compute similar functions (under some metric).\nThe learning method then provides a set of equations, involving statistics computed from data, from which operators can be induced by computing approximate regularized solutions. In particular, all the works cited above share a common ingredient: the use of a Singular Value Decompostion for obtaining operators; hence the name spectral method. One of the appeals of this approach is that in general it can be rigorously studied using sensitivity analysis to bound the effect of perturbations on the equations used to recover operators from data. Altogether, it seems fair to assert that some of the theoretical aspects of the spectral method are now well understood. When contrasted with EM, there is little doubt that the spectral method is a very\nattractive alternative. However, EM seems to have some advantages on the eye of the researchers interested in exploiting latent variable models for a given application. Namely, its generic nature makes it easier to apply to new models and applications.\nWe believe some important aspects that can ease the applicability of spectral methods to real world problems have been overlooked in previous analysis. Some of these issues are addressed in the present paper.\nOur first contribution is to re-visit the problem of learning observable operators from a loss minimization perspective. In particular, we give a formulation of the problem in terms of a regularized local loss minimization. We emphasize the local aspect of this minimization \u2013 which means that, in order to learn a function computed by an operator model, it is enough to observe its behavior on a finite set of elements. This is in contrast to the global loss formulation used in iterative algorithms such as EM.\nTo solve the local loss minimization we derive two optimization algorithms. The first algorithm frames the problem as minimizing a non-convex local loss function. We show that under certain conditions the standard SVD method can be seen as an optimizer for this objective.\nOur second contribution is to propose a regularized convex relaxation of the local loss minimization. A feature of the SVD method is that only one discrete parameter, the number of states, needs to be tuned. In practice, this means that the space of all possible hypothesis can be exhaustively explored in relatively short time. However, in many cases, tuning this coarse-grained parameter is not enough for attaining an optimal trade-off between empirical error and model complexity. In contrast, our convex optimization algorithm takes a continuous regularization parameter that can be tuned in order to achieve an optimal trade-off. In practice, our synthetic experiments show that our method can be more robust to some spectral properties of the target distribution that represent a challenge for the SVD method.\nIn this paper we also address another important practical issue overlooked by previous work. In the general case, the consistency of both the SVD method and our optimization algorithms depend on a rather strong hypothesis. Namely, that the \u201ccorrect\u201d subset of the domain where the operators must be optimized \u2013 in our terms, the local loss function \u2013 is known to the algorithm. Though very convenient in theoretical studies, in practice this assumption does not seem very realistic.\nOur third contribution is to prove that a simple randomized strategy can identify a correct local loss function with high probability. More precisely, we give bounds on the number of examples required by our loss-selection algorithm that depend polynomially on some parameters of the target.\nWe choose to present our results in the setting of Weighted Automata. This framework encompasses several of the models considered in the literature on the spectral method: HMM, reduced-rank HMM, PNFA, QWA and rational stochastic languages. With some modifications, this framework can also deal with inputoutput models like FST and PSR. In general, models defined in terms of a finite state machines over some finite alphabet can be formulated using Weighted Automata."}, {"heading": "2. Weighted Automata and Hankel Matrices", "text": ""}, {"heading": "2.1. Preliminaries and Notation", "text": "Let \u03a3 be a finite alphabet with m symbols. We write \u03a3\u2217 for the set of all strings over \u03a3 and use \u03bb to denote the empty string. The Hankel matrix of a function f : \u03a3\u2217 \u2192 R over strings is a bi-infinite matrix Hf : \u03a3\u2217 \u00d7 \u03a3\u2217 \u2192 R with its entries indexed by prefixes and suffixes: Hf (u, v) = f(uv). The rank of f is defined as rank(f) = rank(Hf ), which may in principle be infinite. Given sets of prefixes and suffixes U ,V \u2282 \u03a3\u2217, we define the Hankel sub-block H : U \u00d7 V \u2192 R of Hf as H(u, v) = f(uv). Note that when |U| = p, |V| = s we have H \u2208 Rp\u00d7s. In general, given U and V one has rank(H) \u2264 rank(Hf ). We say that the pair (U ,V) is a basis for f if rank(H) = rank(Hf ). Note that then it must be the case that p, s \u2265 rank(Hf ). For any symbol a \u2208 \u03a3, we also define the sub-block Ha \u2208 Rp\u00d7s as Ha(u, v) = f(uav).\nA weighted automata (WA) over \u03a3 with n states is a tuple A = \u2329 \u03b1>1 , \u03b1\u221e, {Aa}a\u2208\u03a3 \u232a , where \u03b11, \u03b1\u221e \u2208 Rn, Aa \u2208 Rn\u00d7n. We write |A| for the number of states of A. The function fA : \u03a3 \u2217 \u2192 R defined by A is given by\nfA(x1 \u00b7 \u00b7 \u00b7xt) = \u03b1>1 Ax1 \u00b7 \u00b7 \u00b7Axt\u03b1\u221e = \u03b1>1 Ax\u03b1\u221e . (1)\nIt is obvious from the definition that if M \u2208 Rn\u00d7n is an invertible matrix, the WA B =\u2329 \u03b1>1 M,M \u22121\u03b1\u221e, {M\u22121AaM} \u232a\nsatisfies fB = fA. Sometimes B is denoted by M\u22121AM .\nA probability distribution D over \u03a3\u2217 receives the name of a stochastic languange. We say that D has full support if D(x) > 0 for all x \u2208 \u03a3\u2217. A stochastic language is rational if there exists a WA A such that\nfA(x) = D(x) for all x \u2208 \u03a3\u2217.\nBy default all vectors are assumed to be columns. The Moore\u2013Penrose pseudo-inverse of a matrix M is denoted by M+. A rank factorization of a matrix M \u2208 Rm\u00d7n with rank(M) = r is a pairQ \u2208 Rm\u00d7r, R \u2208 Rr\u00d7n such that M = QR and rank(Q) = rank(R) = r. We denote the ith row of M by M(i, :), and the jth column by M(:, j). For Hankel matrices and Hankel sub-blocks, rows and columns are respectively indexed by prefixes and suffixes. The notation \u2016 \u00b7 \u2016 is used for the `2 norm of vectors and matrices. Similarly, \u2016 \u00b7 \u2016F denotes the Frobenius norm, and \u2016 \u00b7 \u2016\u2217 the nuclear norm."}, {"heading": "2.2. Probability Distributions over Strings", "text": "Throughout the paper it is assumed that some subblocks of the Hankel matrix Hf are known, either exactly or in an approximate form. Obviously, in practice it only makes sense to consider targets for which (approximations of) these sub-blocks can be effectively obtained, say by examples drawn from a probility distribution, say by making queries to some oracle. In general, most spectral methods discussed in Section 1 are used for learning probability distributions defined by some form of finite state machine. In these cases, the entries of H are probabilities and usually a sample drawn from the corresponding distribution is used for obtaining empirical estimates of this probabilities, yielding an approximate Hankel sub-block H\u0302.\nThough we shall not fix any particular probabilistic model, it is worth noting that our results apply seamlessly to most of the settings cosidered so far. In particular, we can deal with the following two settings: when f defines probabilities over finite prefixes (like in the HMM formulations) and words are sampled from these distributions conditioned on an externally (fixed or randomly) given length; and, when f is a rational stochastic language. Furthermore, in the latter case our model encompasses the settings where a sample is used to estimate probabilities of words f(x), prefixes f(x\u03a3\u2217), or substrings f(\u03a3\u2217x\u03a3\u2217), since it is not difficult to see that when f is given by some WA with n states, there exists another WA with n states computing prefix and substring probabilities (Luque et al., 2012)."}, {"heading": "2.3. Duality between WA and Factorizations", "text": "Let f : \u03a3\u2217 \u2192 R be a function over strings with Hankel matrix Hf . We recall the following result (see (Beimel et al., 2000)): rank(f) = r < \u221e if and only if f = fA for some WA A with r states and for any WA A such that fA = f then |A| \u2265 r. If f = fA and |A| = rank(f)\nwe say that A is minimal for f .\nOur ultimate goal is to learn a function f : \u03a3\u2217 \u2192 R of finite rank by observing a sub-block of its Hankel matrix. Since our hypotheses will be functions computed by weighted automata, a natural question to ask is the relation between (minimal) WA for f and sub-blocks of Hf . Our first observation is that any minimal WA for f induces a \u201cnice\u201d factorization of any sub-block H defined on a \u201cgood\u201d set of prefixes and suffixes.\nLet A be a minimal WA for some f of rank r. Then A induces a rank factorization of the Hankel matrix of f of the form Hf = PfSf , where Pf \u2208 R\u221e\u00d7r and Sf \u2208 Rr\u00d7\u221e are defined as: Pf (u, :) = \u03b1>1 Au, and Sf (: , v) = Av\u03b1\u221e. Actually, for any sets of prefixes U and suffixes V, A also induces a factorization H = PS of the associated sub-block with P \u2208 Rp\u00d7r and S \u2208 Rr\u00d7s. Furthermore, we can show that if (U ,V) is a basis of f , then H = PS is a rank factorization. Indeed, the inequalities r = rank(H) \u2264 min{rank(P ), rank(S)} and p, s \u2265 r, imply that rank(P ) = rank(S) = r. Note that from P (u, :) = \u03b11Au and S(:, v) = Av\u03b1\u221e one can also derive the following useful factorization: Ha = PAaS.\nThus, we have seen how a minimal WA for f induces a rank factorization of H provided that U and V form a basis of f . The following lemma shows that this relation can be reversed. Together, these two facts show that minimal WA for f and rank factorizations of H are \u201cdual\u201d whenever (U ,V) is a basis. Lemma 1. Suppose (U ,V) is a basis of f with \u03bb \u2208 U and \u03bb \u2208 U . Let h>r,\u03bb = H(\u03bb, :) and hc,\u03bb = H(: , \u03bb) be the respective row and column of H associated with \u03bb. For any rank factorization H = QR, let A =\u2329 \u03b1>1 , \u03b1\u221e, {Aa} \u232a be the WA given by: \u03b1>1 = h > r,\u03bbR +, \u03b1\u221e = Q +hc,\u03bb, and Aa = Q +HaR +. Then A is a minimal WA for f .\nProof. Let B = \u3008\u03b21, \u03b2\u221e, {Ba}\u3009 be a minimal WA for f inducing a rank factorization H = PS. It suffices to prove that there exists an invertible M such that A = M\u22121BM . Let M = SR+. Since (Q+P )(SR+) = Q+HR+ = I, we see that M is invertible with inverse M\u22121 = Q+P . Now we check that the operators of A correspond to the operators of B under the change of basis M . First, we see that Aa = Q +HaR + = Q+PBaSR\n+ = M\u22121BaM . Now observe that by the definitions of S and P we have \u03b2>1 S = h > r,\u03bb and P\u03b2\u221e = hc,\u03bb. Thus, we see that \u03b1>1 = \u03b2 > 1 M and \u03b1\u221e = M \u22121\u03b2\u221e.\nFrom now on, we assume without loss of generality that any basis (U ,V) contains the empty string \u03bb as a prefix and a suffix.\nThe spectral algorithm of (Hsu et al., 2009) can be easily derived using Lemma 1. Basically, it accounts to taking the rank factorization H = (HV )V >, where H = U\u039bV > is a compact SVD. In next section we will derive another algorithm based on loss minimization that yields similar results."}, {"heading": "3. Learning WA via Loss Minimization", "text": "In spirit, our algorithm is similar to the spectral method in the sense that in order to learn a function f : \u03a3\u2217 \u2192 R of finite rank, the algorithm infers a WA using (approximate) information from a sub-block of Hf . The sub-block used by the algorithm is defined in terms of a set of prefixes U and suffixes V. Throughout this section we assume that f is fixed and has rank r, and that a basis (U ,V) of f is given. How to find these sets of prefixes and suffixes given a sample is discussed in Section 4.\nWe state our algorithm under the hypothesis that subblocks H and {Ha}a\u2208\u03a3 of Hf are known exactly. It is trivial to modify the algorithms to work in the case when only approximations H\u0302 and {H\u0302a}a\u2208\u03a3 of the Hankel sub-blocks are known.\nFor 1 \u2264 n \u2264 s we define the local loss function `n(X,\u03b2\u221e, {Ba}) on variables X \u2208 Rs\u00d7n, \u03b2\u221e \u2208 Rn and Ba \u2208 Rn\u00d7n for a \u2208 \u03a3 as:\n`n = \u2016HX\u03b2\u221e \u2212 hc,\u03bb\u201622 + \u2211 a \u2016HXBa \u2212HaX\u20162F (2)\nThe operator learning algorithm is a constrained minimization of the local loss:\nmin X,\u03b2\u221e,{Ba}\n`n(X,\u03b2\u221e, {Ba}) s.t. X>X = I (SO)\nIntuitively, this optimization tries to jointly solve the optimizations solved by SVD and pseudo-inverse in the spectral method based on Lemma 1. In particular, likewise for the SVD-based method, it can be shown that (SO) is consistent whenever a large enough guess for n is provided.\nTheorem 2. Suppose n \u2265 r. Then, for any optimal solution (X\u2217, \u03b2\u2217\u221e, {B\u2217a}) to problem (SO), the weighted automata B\u2217 = \u2329 h>r,\u03bbX \u2217, \u03b2\u2217\u221e, {B\u2217a} \u232a satisfies f = fB\u2217\nThe proof of this theorem is sketched in Appendix A.1. Though the proof is relatively simple in the case n = r, it turns out that the case n > r is much more delicate \u2013 unlike in the SVD-based method, where the same proof applies to all n \u2265 r.\nOf course, if H and {Ha} are not fully known, but approximations H\u0302 and {H\u0302a} are given to the algorithm,\nwe can still minimize the empirical local loss \u0302\u0300n and build a WA from the solution using the same method of Theorem 2.\nDespite its consistency, in general the optimization (SO) is not algorithmically tractable because its objective function is quadratic non-positive semidefinite and the constraint on X is not convex. Nonetheless, the proof of Theorem 2 shows that when H and {Ha} are known exactly, the SVD method can be used to efficiently compute an optimal solution of (SO). Furthermore, the SVD method can be regarded as an approximate solver for (SO) with an empirical loss function \u0302\u0300n as follows. Find first an X\u0302 satisfying the constraints using the SVD of H\u0302, and then compute \u03b2\u0302\u221e and {B\u0302a} by minimizing the loss (2) with fixed X\u0302 \u2013 note that in this case, the optimization turns out to be convex.\nFrom this perspective, the bounds for the distance between operators recovered with full and approximate data given in several papers about the spectral method, can be restated as a sensitivity analysis of the optimization solved by the spectral algorithm. In fact, a similar analysis can be done for (SO), though we shall not pursue this direction here.\nInstead, we shall present a convex relaxation of (SO) that addresses a practical issue in this optimization algorithm. That is, the fact that the only parameter a user can adjust in (SO) in order to trade accuracy and model complexity is the number of states n. Though the discreteness of this parameter allows for a fast model selection scheme through a full exploration of the parameter space, in some applications one may be willing to invest some time in exploring a larger, more fine-grained space of parameters, with the hope of reaching a better trade-off between accuracy and model complexity. The algorithm presented in next section does this by incorporating a continuous regularization parameter."}, {"heading": "3.1. A Convex Local Loss", "text": "The main idea in order to obtain a convex optimization problem similar to (SO) will be to remove X, since we have already seen that it is the only source of non-convexity in the optimization. However, the new convex objective will need to incorporate a term that enforces the optimization to behave in a similar way as (SO).\nFirst note that the choice of n effectively restricts the maximum rank of the operators Ba. Once this maximal rank is set, X can be interpreted as enforcing a common \u201csemantic space\u201d between the different operators Ba by making sure each of them works on a state\nspace defined by the same projection of H. Furthermore, the constraint onX tightly controls its norm and thus ensures that the operators Ba will also have its norm tightly controlled to be in the order of \u2016Ha\u2016/\u2016H\u2016 \u2013 at least when n = r, see the proof of Theorem 2.\nThus, in order to obtain a convex optimization similar to (SO) we do the following. First, take n = s and fix X = I, thus unrestricting the model class and removing the source of non-convexity. Then penalize the resulting objective with a convex relaxation of the term rank([Ba1 , . . . , Bam ]), which makes sure the operators have low rank individually, and enforces them to work on a common low-dimensional state space.\nMore formally, for any regularization parameter \u03c4 > 0, the relaxed local loss \u02dc\u0300\u03c4 (B\u03a3) on a matrix variable B\u03a3 \u2208 Rs\u00d7ms is defined as:\n\u02dc\u0300 \u03c4 = \u2016B\u03a3\u2016\u2217 + \u03c4\u2016HB\u03a3 \u2212H\u03a3\u20162F , (3)\nwhere we interpret B\u03a3 = [Ba1 , . . . , Bam ] as a concatenation of the operators, and H\u03a3 = [Ha1 , . . . ,Ham ]. Since \u02dc\u0300 is clearly convex on B\u03a3, we can learn a set of operators by solving the convex optimization problem\nmin B\u03a3\n\u02dc\u0300(B\u03a3) . (CO)\nGiven an optimal solution B\u2217\u03a3 of (CO), we define a WA B\u2217 = \u2329 h>r,\u03bb, e\u03bb, B \u2217 \u03a3 \u232a , where e\u03bb \u2208 Rs is the coordinate vector with e\u03bb(\u03bb) = 1.\nSome useful facts about this optimization are collected in the following proposition.\nProposition 3. The following hold: (1) if H has full column rank, then (CO) has a unique solution; (2) for n = s and \u03c4 \u2265 1, the optimum value `\u2217s of (SO) and the optimum value \u02dc\u0300\u2217\u03c4 of (CO) satisfy ` \u2217 s \u2264 \u02dc\u0300\u2217\u03c4 ; (3) suppose rank(H) = rank([H\u03a3, H]) and let [H\u03a3, H] = U\u039b[V >\u03a3 V >] be a compact SVD. Then, B\u03a3 = (V >)+V >\u03a3 is a closed form solution for (CO) when \u03c4 \u2192\u221e\nProof. Fact (1) follows from the observation that when H has full rank the loss \u02dc\u0300\u03c4 is strictly convex. For fact (2), suppose B\u2217\u03a3 achieves the optimal value in (CO) and check that `\u2217s \u2264 `s(I, e\u03bb, B\u2217\u03a3) = \u2016HB\u2217\u03a3 \u2212H\u03a3\u20162F \u2264 \u02dc\u0300\u2217 \u03c4 . Fact (3) follows from Theorem 2.1 in (Liu et al., 2010) and the observation that when \u03c4 \u2192 \u221e optimization (CO) is equivalent to minB\u03a3 \u2016B\u03a3\u2016\u2217 s.t. HB\u03a3 = H\u03a3.\nNote that in general approximations H\u0302 of H computed from samples will have full rank with high probability. Thus, fact (1) tells us that either in this case, or when p = n, optimization (CO) has a unique optimum.\nFurthermore, by fact (2) we see that minimizing the convex loss is also, in a relaxed sense, minimizing the non-convex loss which is known to be consistent. In addition, fact (3) implies that when H has full rank and \u03c4 is very large, we recover the spectral method with n = s. These and other properties of (CO) appear in the experimens described in Section 5.\nOptimization (CO) can be restated in several ways. In particular, by standard techniques, it can be shown that it is equivalent to a Conic Program on the intersection of a semi-definite cone (given by the nuclear norm), and a quadratic cone (given by the Frobenius norm). Similarly, the problem can also be fully expressed as a semi-definite program, though in general this conversion is believed to be inefficient. Altogether, the number of variables in (CO) is ms2. Formulating the conic program yields O(m2s2) varibles, and constraints in a space of size O(mps + ms2). When the fully semi-definite program is considered, the constraint space grows to dimension O(m2p2s2). This shows that finding a small basis, in particular, a basis defined over a small set of prefixes, is important in practice. We note here that the complexity of the SVD method scales similarly."}, {"heading": "4. Choosing the Local Loss", "text": "We have already discussed why, in practice, it is important to have methods for finding a basis. In this section we show a fundamental result about basis. Namely, that simple randomized strategies for choosing a basis succeed with high probability. Furthermore, our result gives bounds on the number of examples required for finding a basis that depend polynomially on some parameters of the target function f : \u03a3\u2217 \u2192 R and the sampling distribution D.\nWe begin with a well-known folklore result about the existence of minimal basis. This implies that in principle all methods for learning WA from sub-blocks of the Hankel matrix can work with a block whose size is only quadratic in the number of states of the target. Proposition 4. For any f : \u03a3\u2217 \u2192 R of rank r there exists a basis (U ,V) of f with |U| = |V| = r.\nA WA A = \u2329 \u03b1>1 , \u03b1\u221e, {Aa} \u232a is called strongly bounded if \u2016Aa\u2016 \u2264 1 for all a \u2208 \u03a3. Note that this implies the boundeness of fA since |fA(x)| = |\u03b1>1 Ax\u03b1\u221e| \u2264 \u2016\u03b11\u2016\u2016\u03b1\u221e\u2016. A function over strings f of finite rank is called strongly bounded if there exists a strongly bounded minimal WA for f . Note that, in particular, all models of probabilistic automata discussed in Section 2.2 are strongly bounded.\nOur result states that, under some simple hypothesis,\nAlgorithm 1 Random Basis\nInput: strings S = (x1, . . . , xN ) Output: basis candidate (U ,V) Initialize U \u2190 \u2205, V \u2190 \u2205 for i = 1 to N do\nChoose 0 \u2264 t \u2264 |xi| uniformly at random Split xi = uivi with |ui| = t and |vi| = |xi| \u2212 t Add ui to U and vi to V\nend for\nwith high probability Algorithm 1 will return a correct basis when enough examples are examined.\nTheorem 5. Let f : \u03a3\u2217 \u2192 R be a strongly bounded function of rank r and D a distribution over \u03a3\u2217 with full support.Suppose that N strings sampled i.i.d. from D are given to Algorithm 1. Then, if N \u2265 C\u03b7 log(1/\u03b4) for some universal constant C and a parameter \u03b7 that depends on f and D, the output (U ,V) is a basis for f with probability at least 1\u2212 \u03b4.\nA proof of this result based on random matrix theory is given in Appendix A."}, {"heading": "5. Experimental Results", "text": "We conducted synthetic and real experiments comparing the SVD and the Convex Optimization methods.\nFor the synthetic experiments, we created random PNFAs with alphabet sizes ranging from 2 to 10 symbols and a random number of states in the same range. For each random target model, we then sampled k training sequences and trained models using SVD and CO. Results are reported in terms of L1 error with respect to the true distribution (all results are averages of 10 sampling rounds). We fixed the set of prefixes and suffixes to be all substrings of length 1, following (Hsu et al., 2009). Table 1 shows learning curves for three target models. Each model was chosen randomly from a set of models that have the smallest singular value of H in the same order of magnitude. For each target and method we show the error of the best model (i.e. optimal n for the SVD method and optimal \u03c4 for the CO method). For the second distribution in Table 1, Figure 1.a shows the L1 error of the CO method as a function of \u03c4 . It also shows the error of the SVD method for different number of states.\nFigure 1.b summarizes all results for the largest size of training set. For each target model, we show the average error of the two learned models as a function of the smallest singular value of the target. We observe that in general target models with smaller singular values are harder to learn, and it is in those cases that the\nCO approach obtains the largest gain in accuracy.\nWe also conducted experiments on natural language data, for the task of language modeling of syntactic part-of-speech tags (i.e. noun, verb, adjective, . . . ). This type of language models are a central building block in Natural Language Processing methods for tagging the words of a sentence with their syntactic function. We used the English Penn Treebank with a tag set of 12 symbols, and used the standard splits for training (39,832 sentences with avg. length of 23) and validation (1,700 sentences).\nFigure 1.c plots curves on the validation set comparing the SVD method, the CO method, the standard EM algorithm, and two simple baselines based on statistics of single symbols (Unigram) and pairs of symbols (Bigram). For each model we plot the word error rate with respect to the nuclear norm of their operators. All hidden state models improve the baselines, while the CO method is able to improve over the SVD method. The EM method obtains the best error rates, though it is much slower to train (a factor of 100 times).\nFinally, Table 2 shows the peformance of the SVD method using random sets of prefixes and suffixes. In this case, we generated substrings of up to 4 symbols, and sampled them according to their frequency on the training data. We used the random substrings to define Hankel sub-blocks of increasing dimensionalities. For each dimensionality, we trained a model using SVD, and chose the number of states that minimized error on validation data. Clearly, expanding the Hankel sub-block results in a benefit in terms of the error. For comparison, the table also reports the performance of EM with respect to the number of states."}, {"heading": "6. Conclusion", "text": "In this paper we have attempted to facilitate the understanding and applicability of spectral approaches for learning weighted automata. In particular, we have made the following contributions: (1) formulate weighted automata learning as a local loss minimization; (2) show that under certain conditions the standard SVD approach is an optimizer of this local loss;\n(3) propose a convex relaxation that permits fine tuning of the complexity\u2013accuracy trade-off; (4) offer a provable correct method for estimating the scope of the local loss function from samples; and (5) show on synthetic experiments that under certain conditions the convex relaxation method is more robust than the SVD approach."}, {"heading": "A. Technical Proofs", "text": ""}, {"heading": "A.1. Proof Sketch for Theorem 2", "text": "The following two lemmas will be used in the proof. Lemma 6. Let A = \u2329 \u03b1>1 , \u03b1\u221e, {Aa} \u232a be a WA with n states. Suppose that (U ,V) is a basis for fA and write H = PS for the factorization induced by A on this Hankel sub-block. For any m and any pair of matrices N \u2208 Rm\u00d7n and M \u2208 Rn\u00d7m such that PMN = P , the WA B = NAM = \u2329 \u03b1>1 M,N\u03b1\u221e, {NAaM} \u232a satistifies fB = fA. Lemma 7. Let f : \u03a3\u2217 \u2192 R be a function of finite rank r and suppose that (U ,V) is a basis for f . Then the matrix H\u03a3 = [Ha1 , . . . ,Ham ] has rank r.\nNow the following three facts can be established. To-\ngether, they imply the result.\nClaim 1: The optimal value of problem (SO) is zero. Let H = U\u039bV > be a full SVD of H and write Vn \u2208 Rs\u00d7n for the n left singular vectors corresponding first n singular values. Then consider the\nWA An = \u2329 h>r,\u03bbVn, (HVn) +hc,\u03bb, {(HVn)+HaVn} \u232a and show that `n(Vn, (HVn) +hc,\u03bb, {(HVn)+HaVn}) = 0.\nClaim 2: For any n \u2265 r, An satisfies fAn = f . Apply Lemma 6 to show that fAn = fAr for n > r, and then Lemma 1 to show fAr = f . Claim 3: For any optimal solution B\u2217 one has fB\u2217 = fAn . Lemma 7 is used to show that HX\n\u2217(X\u2217)> = H. Then, Lemma 6 with N = (X\u2217)>Vn and M = V > n X \u2217 implies the claim."}, {"heading": "A.2. Proof of Theorem 5", "text": "We use the following result from (Vershynin, 2012).\nTheorem 8 (Corollary 5.52 in (Vershynin, 2012)). Consider a probability distribution in Rd with full-rank covariance matrix C and supported in a centered Euclidean ball of radius R. Also, let \u03c31 \u2265 . . . \u2265 \u03c3d > 0 be the singular values of C. Take N i.i.d. examples from the distribution and let C\u0302 denote its sample covariance matrix. Then, if N \u2265 K(\u03c31/\u03c32d)R2 log(1/\u03b4) the matrix C\u0302 has full rank with probability at least 1\u2212\u03b4. Here K is a universal constant.\nConsider the prefixes produced by Algorithm 1 on input an i.i.d. random sample S = (x1, . . . , xN ) drawn from D. We write U = (u1, . . . , uN ) for the tuple of prefixes produced by the algorithm and use U \u2032 to denote the set defined by these prefixes. We define V and V \u2032 similarly. Let p\u2032 = |U \u2032| and s\u2032 = |V \u2032|. Our goal is to show that the random sub-block H \u2032 \u2208 Rp\u2032\u00d7s\u2032 of Hf defined by the output of Algorithm 1 has rank r\nwith high probability w.r.t. the choices of input sample and splitting points. Our strategy will be to show that one always has H \u2032 = P \u2032S\u2032, where P \u2032 \u2208 Rp\u2032\u00d7r and S\u2032 \u2208 Rr\u00d7s\u2032 are such that with high probability rank(P \u2032) = rank(S\u2032) = r. The arguments are identical for P \u2032 and S\u2032. Fix a strongly bounded minimal WA A =\u2329 \u03b1>1 , \u03b1\u221e, {Aa} \u232a for f , and let Hf = PfSf denote the rank factorization induced by A. We write p>u = Pf (u, :) for the uth row of Pf . Note that since A is strongly bounded we have \u2016p>u \u2016 = \u2016\u03b1>1 Au\u2016 \u2264 \u2016\u03b1>1 \u2016. The desired P \u2032 will be the sub-block of Pf correponding to the prefixes in U \u2032. In the following we bound the probability that this matrix is rank deficient.\nThe first step is to characterize the distribution of the elements of U . Since the prefixes ui are all i.i.d., we write Dp to denote the distribution from which these prefixes are drawn, and observe that for any u \u2208 \u03a3\u2217 and any 1 \u2264 i \u2264 N we have Dp(u) = P[ui = u] = P[\u2203 v : xi = uv \u2227 t = |u|], where xi is drawn from D and t is uniform in [0, |xi|]. Thus we see that Dp(u) =\u2211 v\u2208\u03a3\u2217(1 + |uv|)\u22121D(uv).\nNow we overload our notation and let Dp also denote the following distribution over Rr supported on the set of all rows of Pf : Dp(q>) = \u2211 u:p>u =q\n> Dp(u). It follows from this definition that the covariance matrix of Dp satisfies Cp = E[qq>] = \u2211 uDp(u)pup>u . Observe that this expression can be written in matrix form as Cp = P > f DpPf , where Dp is a bi-infinite diagonal matrix with entries Dp(u, u) = Dp(u). We say that the distribution D is pref-adversarial for A if rank(Cp) < r. Note that if D(x) > 0 for all x \u2208 \u03a3\u2217, then Dp has full-rank and consequently rank(Cp) = r. This shows that distributions with full support are never pref-adversarial, and thus we can assume that Cp has full rank.\nNext we use the prefixes in U to build a matrix P \u2208 RN\u00d7r whose ith row corresponds to the uith row of Pf , that is: P (i, :) = p>ui . It is immediate to see that P \u2032 can be obtained from P by possibly removing some repeated rows and reordering the remaining ones. Thus we have rank(P ) = rank(P \u2032). Furthermore, by construction we have that C\u0302p = P >P is the sample covariance matrix of N vectors in Rr drawn i.i.d. from Dp. Therefore, a straightforward application of Theorem 8 shows that if N \u2265 K(\u03ba(Cp)/\u03c3(Cp))\u2016\u03b1>1 \u20162 log(1/\u03b4), then rank(P \u2032) = r with probability at least 1\u2212\u03b4. Here K is a universal constant, \u03ba(Cp) is the condition number of Cp, and \u03c3(Cp) is the smallest singular value of Cp, where these last two terms depend on A and D.\nThe result follows by symmetry from a union\nbound. Furthermore, we can take \u03b7 = \u03b7(f,D) = infA max{(\u03ba(Cp)/\u03c3(Cp))\u2016\u03b1>1 \u20162, (\u03ba(Cs)/\u03c3(Cs))\u2016\u03b1\u221e\u20162}, where the infimum is taken over all minimal strongly bounded WA for f ."}, {"heading": "Acknowledgments", "text": "This work was partially supported by the EU PASCAL2 NoE (FP7-ICT-216886), and by a Google Research Award. B.B. was supported by an FPU fellowship (AP2008-02064) of the Spanish Ministry of Education. A.Q. and X.C. were supported by the Spanish Government (JCI-2009-04240, RYC-2008-02223) and the E.C. (XLike FP7-288342)."}, {"heading": "Balle, B., Quattoni, A., and Carreras, X. A spectral", "text": "learning algorithm for finite state transducers. ECML\u2013 PKDD, 2011."}, {"heading": "Beimel, A., Bergadano, F., Bshouty, N.H., Kushilevitz, E.,", "text": "and Varricchio, S. Learning functions represented as multiplicity automata. JACM, 2000."}, {"heading": "Boots, B., Siddiqi, S., and Gordon, G. Closing the learning", "text": "planning loop with predictive state representations. I. J. Robotic Research, 2011."}, {"heading": "Dempster, A. P., Laird, N. M., and Rubin, D. B. Maximum", "text": "likelihood from incomplete data via the EM algorithm. Journal of the Royal Statistical Society, 1977.\nHsu, D., Kakade, S. M., and Zhang, T. A spectral algorithm for learning hidden markov models. In Proc. of COLT, 2009."}, {"heading": "Liu, G., Sun, J., and Yan, S. Closed-form solutions to a", "text": "category of nuclear norm minimization problems. NIPS Workshop on Low-Rank Methods for Large-Scale Machine Learning, 2010."}, {"heading": "Luque, F.M., Quattoni, A., Balle, B., and Carreras, X.", "text": "Spectral learning in non-deterministic dependency parsing. EACL, 2012.\nParikh, A.P., Song, L., and Xing, E.P. A spectral algorithm for latent tree graphical models. ICML, 2011."}, {"heading": "Siddiqi, S.M., Boots, B., and Gordon, G.J. Reduced-rank", "text": "hidden markov models. AISTATS, 2010."}, {"heading": "Song, L., Boots, B., Siddiqi, S., Gordon, G., and Smola,", "text": "A. Hilbert space embeddings of hidden markov models. ICML, 2010.\nVershynin, R. Introduction to the non-asymptotic analysis of random matrices, volume Compressed Sensing, Theory and Applications, chapter 5. CUP, 2012."}], "references": [{"title": "Quadratic weighted automata: Spectral algorithm and likelihood maximization", "author": ["R. Bailly"], "venue": "Journal of Machine Learning Research,", "citeRegEx": "Bailly,? \\Q2011\\E", "shortCiteRegEx": "Bailly", "year": 2011}, {"title": "A spectral learning algorithm for finite state transducers", "author": ["B. Balle", "A. Quattoni", "X. Carreras"], "venue": "ECML\u2013 PKDD,", "citeRegEx": "Balle et al\\.,? \\Q2011\\E", "shortCiteRegEx": "Balle et al\\.", "year": 2011}, {"title": "Learning functions represented as multiplicity automata", "author": ["A. Beimel", "F. Bergadano", "N.H. Bshouty", "E. Kushilevitz", "S. Varricchio"], "venue": null, "citeRegEx": "Beimel et al\\.,? \\Q2000\\E", "shortCiteRegEx": "Beimel et al\\.", "year": 2000}, {"title": "Closing the learning planning loop with predictive state representations. I", "author": ["B. Boots", "S. Siddiqi", "G. Gordon"], "venue": "J. Robotic Research,", "citeRegEx": "Boots et al\\.,? \\Q2011\\E", "shortCiteRegEx": "Boots et al\\.", "year": 2011}, {"title": "Maximum likelihood from incomplete data via the EM algorithm", "author": ["A.P. Dempster", "N.M. Laird", "D.B. Rubin"], "venue": "Journal of the Royal Statistical Society,", "citeRegEx": "Dempster et al\\.,? \\Q1977\\E", "shortCiteRegEx": "Dempster et al\\.", "year": 1977}, {"title": "A spectral algorithm for learning hidden markov models", "author": ["D. Hsu", "S.M. Kakade", "T. Zhang"], "venue": "In Proc. of COLT,", "citeRegEx": "Hsu et al\\.,? \\Q2009\\E", "shortCiteRegEx": "Hsu et al\\.", "year": 2009}, {"title": "Closed-form solutions to a category of nuclear norm minimization problems", "author": ["G. Liu", "J. Sun", "S. Yan"], "venue": "NIPS Workshop on Low-Rank Methods for Large-Scale Machine Learning,", "citeRegEx": "Liu et al\\.,? \\Q2010\\E", "shortCiteRegEx": "Liu et al\\.", "year": 2010}, {"title": "Spectral learning in non-deterministic dependency parsing", "author": ["F.M. Luque", "A. Quattoni", "B. Balle", "X. Carreras"], "venue": null, "citeRegEx": "Luque et al\\.,? \\Q2012\\E", "shortCiteRegEx": "Luque et al\\.", "year": 2012}, {"title": "A spectral algorithm for latent tree graphical models", "author": ["A.P. Parikh", "L. Song", "E.P. Xing"], "venue": null, "citeRegEx": "Parikh et al\\.,? \\Q2011\\E", "shortCiteRegEx": "Parikh et al\\.", "year": 2011}, {"title": "Reduced-rank hidden markov models", "author": ["S.M. Siddiqi", "B. Boots", "G.J. Gordon"], "venue": "AISTATS,", "citeRegEx": "Siddiqi et al\\.,? \\Q2010\\E", "shortCiteRegEx": "Siddiqi et al\\.", "year": 2010}, {"title": "Hilbert space embeddings of hidden markov models", "author": ["L. Song", "B. Boots", "S. Siddiqi", "G. Gordon", "A. Smola"], "venue": null, "citeRegEx": "Song et al\\.,? \\Q2010\\E", "shortCiteRegEx": "Song et al\\.", "year": 2010}, {"title": "Introduction to the non-asymptotic analysis of random matrices, volume Compressed Sensing, Theory and Applications, chapter", "author": ["R. Vershynin"], "venue": "CUP,", "citeRegEx": "Vershynin,? \\Q2012\\E", "shortCiteRegEx": "Vershynin", "year": 2012}], "referenceMentions": [{"referenceID": 4, "context": "Most of these methods can be interpreted as instances of the Expectation\u2013 Maximization algorithm (Dempster et al., 1977).", "startOffset": 97, "endOffset": 120}, {"referenceID": 5, "context": "It is the so-called spectral learning method, introduced by (Hsu et al., 2009) in the context of HMM and also applied to many other models such as Reduced Rank HMM (Siddiqi et al.", "startOffset": 60, "endOffset": 78}, {"referenceID": 9, "context": ", 2009) in the context of HMM and also applied to many other models such as Reduced Rank HMM (Siddiqi et al., 2010), Kernelized HMM (Song et al.", "startOffset": 93, "endOffset": 115}, {"referenceID": 10, "context": ", 2010), Kernelized HMM (Song et al., 2010), Predictive State Representations (Boots et al.", "startOffset": 24, "endOffset": 43}, {"referenceID": 3, "context": ", 2010), Predictive State Representations (Boots et al., 2011), Latent Tree Graphical Models (Parikh et al.", "startOffset": 42, "endOffset": 62}, {"referenceID": 8, "context": ", 2011), Latent Tree Graphical Models (Parikh et al., 2011), Finite States Transducers (Balle et al.", "startOffset": 38, "endOffset": 59}, {"referenceID": 1, "context": ", 2011), Finite States Transducers (Balle et al., 2011), and Quadratic Weighted Automata (Bailly, 2011).", "startOffset": 35, "endOffset": 55}, {"referenceID": 0, "context": ", 2011), and Quadratic Weighted Automata (Bailly, 2011).", "startOffset": 41, "endOffset": 55}, {"referenceID": 7, "context": "Furthermore, in the latter case our model encompasses the settings where a sample is used to estimate probabilities of words f(x), prefixes f(x\u03a3\u2217), or substrings f(\u03a3\u2217x\u03a3\u2217), since it is not difficult to see that when f is given by some WA with n states, there exists another WA with n states computing prefix and substring probabilities (Luque et al., 2012).", "startOffset": 335, "endOffset": 355}, {"referenceID": 2, "context": "We recall the following result (see (Beimel et al., 2000)): rank(f) = r < \u221e if and only if f = fA for some WA A with r states and for any WA A such that fA = f then |A| \u2265 r.", "startOffset": 36, "endOffset": 57}, {"referenceID": 5, "context": "The spectral algorithm of (Hsu et al., 2009) can be easily derived using Lemma 1.", "startOffset": 26, "endOffset": 44}, {"referenceID": 6, "context": "1 in (Liu et al., 2010) and the observation that when \u03c4 \u2192 \u221e optimization (CO) is equivalent to minB\u03a3 \u2016B\u03a3\u2016\u2217 s.", "startOffset": 5, "endOffset": 23}, {"referenceID": 5, "context": "We fixed the set of prefixes and suffixes to be all substrings of length 1, following (Hsu et al., 2009).", "startOffset": 86, "endOffset": 104}, {"referenceID": 11, "context": "We use the following result from (Vershynin, 2012).", "startOffset": 33, "endOffset": 50}, {"referenceID": 11, "context": "52 in (Vershynin, 2012)).", "startOffset": 6, "endOffset": 23}], "year": 2012, "abstractText": "This paper re-visits the spectral method for learning latent variable models defined in terms of observable operators. We give a new perspective on the method, showing that operators can be recovered by minimizing a loss defined on a finite subset of the domain. This leads to a derivation of a non-convex optimization similar to the spectral method. We also propose a regularized convex relaxation of this optimization. In practice our experiments show that a continuous regularization parameter (in contrast with the discrete number of states in the original method) allows a better trade-off between accuracy and model complexity. We also prove that in general, a randomized strategy for choosing the local loss succeeds with high probability.", "creator": "LaTeX with hyperref package"}}}