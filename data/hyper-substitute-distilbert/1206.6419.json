{"id": "1206.6419", "review": {"conference": "ICML", "VERSION": "v1", "DATE_OF_SUBMISSION": "27-Jun-2012", "title": "Cross-Domain Multitask Learning with Latent Probit Models", "abstract": "measuring optimization tasks across numerous domains is a challenging problem thus the feature mapping may not conserve the one for different tasks. we write the data in multiple tasks are generated uniquely underlying relative common domain via sparse domain transforms and propose a latent aggregation model ( cc ) to jointly learn particular correlated variables, and consequently biased probit solution chooses the common domain. although describe similar domain domains and avoid location - referenced tasks situations, simulations utilize inclusion in the domain name matrices, as such as in the common classifier. we derive theoretical bounds for generalized estimation error for finite classifier in terms of the sparsity covering both transforms. applying r - values framework is derived to learning the lpm. the modeling of the network is demonstrated on combining overlapping datasets.", "histories": [["v1", "Wed, 27 Jun 2012 19:59:59 GMT  (908kb)", "http://arxiv.org/abs/1206.6419v1", "Appears in Proceedings of the 29th International Conference on Machine Learning (ICML 2012)"]], "COMMENTS": "Appears in Proceedings of the 29th International Conference on Machine Learning (ICML 2012)", "reviews": [], "SUBJECTS": "cs.LG stat.ML", "authors": ["shaobo han", "xuejun liao", "lawrence carin"], "accepted": true, "id": "1206.6419"}, "pdf": {"name": "1206.6419.pdf", "metadata": {"source": "META", "title": "Cross-Domain Multitask Learning with Latent Probit Models", "authors": ["Shaobo Han", "Xuejun Liao", "Lawrence Carin"], "emails": ["shaobo.han@duke.edu", "xjliao@duke.edu", "lcarin@duke.edu"], "sections": [{"heading": "1. Introduction", "text": "There are two basic approaches for analysis of data from two or more tasks, single-task learning (STL) and multi-task learning (MTL). Whereas STL solves each task in isolation, with possible relations between the tasks ignored, MTL solves the tasks jointly, exploiting between-task relations to reduce the hypothesis space and improve generalization (Baxter, 2000). The advantage of MTL is known to be manifested when the tasks are truly related and the task relations are appropriately employed. For supervised learning, in particular, MTL can achieve the same level of generalization performance as STL, and yet uses significantly fewer labeled examples per task (Baxter, 2000). The reduced sample complexity in each task is achieved by transferring labeling information from related tasks.\nAppearing in Proceedings of the 29 th International Conference on Machine Learning, Edinburgh, Scotland, UK, 2012. Copyright 2012 by the author(s)/owner(s).\nWhile the MTL literature has primarily assumed that the tasks have the same input and output domains and differ only in data distributions (Baxter, 2000; Bakker & Heskes, 2003; Argyriou et al., 2007; Ben-David & Borbely, 2008), a number of recent publications are beginning to break the limit of this assumption, in an attempt of extending MTL to a wider range of applications (He & Rick, 2011; Maayan & Mannor, 2011; Kulis et al., 2011; Wang & Mahadevan, 2011).\nIn these recent publications, different tasks are permitted to have different feature spaces. In particular, (He & Rick, 2011) simultaneously performs multiview learning in each task and multi-task learning in shared views, assuming each task has its own features but may also share features with other tasks. The method in (Maayan & Mannor, 2011) allows tasks to have different feature representations, learning rotations between the feature representations by matching the tasks\u2019 empirical means and covariance matrices. The work in (Kulis et al., 2011) considers a source task and a target task, assumed to have different feature dimensions, and learns a nonlinear transformation between the source feature domain and the target feature domain using kernel techniques. Finally, (Wang & Mahadevan, 2011) employs a manifold alignment technique to map each task\u2019s input domain to a common latent space, with the task-specific maps achieving the goal of simultaneously clustering examples with the same label, separating examples with different labels, and preserving the topology of each task\u2019s manifold.\nIn this paper, we address the problem of multi-task learning across heterogenous domains, assuming that each task is a binary classification with a task-specific feature representation. The approach we take differs from (Maayan & Mannor, 2011; Kulis et al., 2011; Wang & Mahadevan, 2011) in several important aspects. First, while these previous methods all learn domain transforms and classification in two separate steps, we integrate the two steps by learning domain transforms and classification jointly. Secondly, the domain transforms in our approach are represented by sparse matrices, with the sparsity enforced by a Lapla-\ncian prior on the transform matrices (corresponding to an `1 penalty to the log-likelihood). By contrast, all previous methods do not impose sparsity on domain transforms. The third difference is that the overall model in our approach consists of a factor model for the observed features, which can be used to synthesize new data unseen during training. Finally, our approach is semi-supervised, using labeled as well as unlabeled examples to jointly find the domain transforms and the classification. By contrast, the methods in (Maayan & Mannor, 2011; Kulis et al., 2011) are supervised, and the method in (Wang & Mahadevan, 2011) is semi-supervised in learning domain transforms, but supervised in learning classification. While full supervision can be challenged by the scarcity of labeled examples (typically assumed in MTL), semisupervision is doubly beneficial to a joint learning approach, in which unlabeled examples help to perform classification, while labeled examples help to find the domain transforms.\nThe proposed approach is based on a sparse hierarchical Bayesian model, referred to as the latent probit model (LPM), which jointly represents the sparse domain transforms and a common sparse probit classifier (Albert & Chib, 1993) in the latent feature space, with the sparsity imposed by a hierarchical Laplacian prior (Figueiredo, 2003). We employ expectationmaximization (EM) to find the maximum a posterior (MAP) solution to the domain transforms and probit parameters.\nThe sparsity of domain transforms in LPM plays a pivotal role in defining the between-task relations. Roughly speaking, a greater sparsity in domain transforms indicates closer relations between the tasks. In other words, sparser domain transforms imply that different tasks look more similar to each other in the latent feature space, and thus greater performance gain may be achieved by sharing information among the tasks. We give a quantitative analysis of the performance gain by providing an upper bound to the estimation error of the probit classifier, which is shared among the tasks in the latent space. The bound has an analytic functional dependence on the sparsity level of domain transforms, showing that sparsity contributes directly to the error reduction. In addition, the bound also reveals the error\u2019s dependency on the number of tasks, the number of labeled examples in each task, and the latent dimensionality."}, {"heading": "2. The Latent probit Model", "text": "The latent probit model (LPM) is a generative probabilistic model for M \u2265 2 partially labeled sets of\nfeature vectors (data points), assuming each dataset has a different feature representation. The LPM has a hierarchical Bayesian structure, as graphically shown in Figure 1, and is parameterized by {\u03b7,\u00b5,\u03a3, b,w} and {Fm,dm}Mm=1. The parameters w specify the probit classifier shared by the tasks in the latent feature space, and Fm specifies the domain transform for the m-th dataset up to a translation (which is specified by dm). The parameters w and {Fm}Mm=1 are given hierarchical Laplacian priors (Figueiredo, 2003) to encourage sparsity, with the priors specified by hyperparameters {\u03b3, \u03bb}. The other hollow circles in Figure 1 denote latent variables, which include {\u03c4 ,u, s, z}. The generative process in the LPM is described below, with N (\u00b5,\u03a3) denoting a normal distribution with mean \u00b5 and covariance matrix \u03a3.\nGiven hyper-parameters {\u03b3, \u03bb}, the sparse parameters w and {Fm}Mm=1 are generated as follows.\n1. Draw w = [wj ]F0\u00d71, the sparse parameters of the probit model shared by the tasks in the latent feature space,\nwj \u223c N (0, uj), uj \u223c \u03bb\n2 exp{\u2212\u03bb 2 uj}, uj \u2265 0, j = 1, 2, ..., F0,\nwhere F0 is the latent feature dimensionality.\n2. For m = 1, 2, \u00b7 \u00b7 \u00b7 ,M , draw the sparse domain transform matrix Fm = [fmkj ]Dm\u00d7F0 by\nfmkj \u223c N (0, \u03c4mkj), \u03c4mkj \u223c \u03b32 exp{\u2212 \u03b3 2 \u03c4mkj}, \u03c4mkj \u2265 0,\nk = 1, \u00b7 \u00b7 \u00b7 , Dm and j = 1, ..., F0, with Dm the observed feature dimensionality of the m-th dataset.\nGiven parameters {\u03b7,\u00b5,\u03a3, b,w} \u222a {Fm,dm}Mm=1, the data sets are generated as follows.\nFor i = 1, 2, \u00b7 \u00b7 \u00b7 , Nm and m = 1, 2, \u00b7 \u00b7 \u00b7 ,M ,\n1. Draw a latent feature vector\nsmi \u223c N (\u00b5,\u03a3), (1)\nwhere \u00b5 \u2208 RF0\u00d71 and \u03a3 \u2208 RF0\u00d7F0 are the mean and covariance matrix, respectively.\n2. Draw an observed feature vector\nxmi \u223c N (Fmsmi + dm, \u03b7I), (2)\nwhere dm \u2208 RDm , \u03b7 > 0 and I denotes an identity matrix of appropriate dimensions.\n3. If the feature vector xmi requires a label, draw the label by\nymi = { +1, if zmi \u2265 0, \u22121, otherwise, zmi \u223c N (wT smi + b, 1), b \u2208 R. (3)\nNote that the latent normal distribution in (1) can be extended to a mixtures of normal distributions to account for more complicated data manifolds.\nWith {Fm}Mm=1 drawn from sparse prior distributions, most entries of these matrices will be zero; by (2) this implies that only a few latent features are responsible for generating the observed features. Since this is true for any m, the chance for different datasets to use the same features to generate their observed features is large. However, latent features are identically distributed; thus the shared latent features must have the same statistics across the tasks. Therefore, the datasets (sets of features vectors) generated by the LPM model are encouraged to be closely related.\nWhile the sparsity of {Fm}Mm=1 reflects the relatedness between the sets of features vectors, the sparsity of w encourages the classification to be dependent on a few latent features. This is important, because even when the observed features differ among tasks to entail less sparse {Fm}Mm=1, the tasks may still be able to share information for classification through appropriately selected latent features."}, {"heading": "3. Theoretical Analysis of the LPM", "text": "The goal of our analysis is to quantify the notion that sparse domain transforms encourage the tasks to be related, and that better generalization can be achieved by sharing information among related tasks to learn the common classifier. The analysis is based on an\nupper bound for the estimation error of w, with the bound represented in terms of the number of nonzero elements of the true {Fm}Mm=1.\nSince we are analyzing the general information-sharing mechanism in the LPM, we expect the results to be insensitive to the choice of estimation method. We therefore employ a simple two-step approach to estimate w. The estimation is based on training data generated by the true LPM parameterized by {\u03b7,\u00b5,\u03a3, b,w\u2217} \u222a {Fm,dm}Mm=1, with the simplifications b = 0, \u03a3 = I, \u00b5 = 0, and dm = 0 \u2200m, where 0 is a vector of zeros of appropriate dimensions. Note we have used a superscript \u2217 to emphasize w\u2217 is the vector of unknown parameters to be estimated.\nLet {Xm}Mm=1, with Xm = [xm1,xm2, \u00b7 \u00b7 \u00b7 ,xmLm ], be M sets of feature vectors, each corresponding to a task. By the generative process of the LPM,\nXm = FmSm + [ mij ]Dm\u00d7Nm ,\nwhere { mij} are i.i.d. drawn from a zero-mean normal distribution with variance \u03b7, and the entries of Sm are i.i.d. from the standard normal distribution. Given Xm, the maximum-likelihood solutions to {Sm} are given by\nS\u0302m = (F T mFm) \u22121FTmXm, \u2200m, (4)\nwhich form a global data matrix by pooling data across the tasks,\n\u03a8 = [S\u03021, S\u03022, ..., S\u0302M ] \u2208 RF0\u00d7nt , (5)\nwhere nt = \u2211M m=1 Lm is the total number of training examples across all M tasks.\nTo simplify the analysis, we assume access to the latent responses of w\u2217 to \u03a8, i.e,\nz = \u03a8Tw\u2217 + e (6)\nwhere z = [z1, \u00b7 \u00b7 \u00b7 , zM ]T with zm = [zm1, \u00b7 \u00b7 \u00b7 , zmLm ], and the entries in e are assumed i.i.d. from the standard normal distribution. These assumptions may be avoided at the price of complicating the bound, which is not pursued here. The estimate of w\u2217 is given by\nw\u0302 = arg min w\n( \u2016z\u2212\u03a8Tw\u201622 + r\u2016w\u20161 ) . (7)\nWe derive an upper bound to \u2016w\u0302 \u2212 w\u2217\u20162, following similar arguments as in (Bickel et al., 2009; Lounici et al., 2009) and making use of a key result in (Byrne, 2009) on extreme singular values of Hermitian matrices. Our main results are stated in Theorem 1, the proof of which is in the Appendix.\nTheorem 1. Let w\u2217 have nonzero and zero elements indexed respectively by J and Jc. Denote s = |J | as the cardinality of J . Let \u03b4 = w\u0302 \u2212 w\u2217 with w\u0302 given in (7), and c0 be the minimum nonnegative number such that \u2016\u03b4Jc\u20161 \u2264 c0\u2016\u03b4J\u20161. Let \u03c8j be the transpose of the j-th row of \u03a8 and \u03b5\u03c8 = maxj \u2016\u03c8j\u20162. For any F0 \u2265 2 and a \u2265 \u221a 8, it holds with probability of at least Pe = 1\u2212 F 1\u2212a 2/8 0 that\n\u2016\u03b4\u20162 \u2264 2a\u03b5\u03c8n\n\u22121 t \u221a s(1 + c20s) lnF0\nM\u2211 m=1\n\u03c9min(X T mXm/nt)\nmaxi (\u2211F0 j=1 \u2016fm,:,j\u20160|fij |2 ) , (8)\nwhere fm,:,j denotes the j-th column of Fm and \u2016f\u20160 denotes the number of nonzero elements in vector f .\nThe bound in (8) establishes the functional dependency of \u2016w\u0302 \u2212 w\u2217\u20162 on a number of characteristic parameters of the LPM. Foremost, the term \u2016fm,:,j\u20160 measures the number of nonzero elements in the j-th column of Fm. A sparse Fm has small \u2016fm,:,j\u20160 for its columns, which decreases the term maxj ( \u2016fm,:,j\u20160 \u2211F0 j=1 |fij |2 ) and contributes to the error reduction. Second, s is the number of nonzero elements in w; a sparse w has a small s, which makes the error small.\nThird, recall that nt = \u2211M m=1 Lm, where M is the number of tasks, and Lm is the number of training samples in the m-th task. The nt in the denominator of (8) plays the role of normalization with respect to the training examples across all tasks, leaving the nt in the numerator to influence the error: large nt indicates small error. Note that some tasks may have few examples while other have abundant ones; as long as they add up to a large nt, similar error reduction will be achieved. Lastly, F0 is the dimensionality of latent features shared across the tasks. The error bound decreases as F0 becomes smaller."}, {"heading": "4. Parameter Estimation", "text": "We seek a MAP estimate of the parameters \u0398 = {\u00b5,\u03a3, b,w} \u222a {Fm,dm}Mm=1. Taking into account all data (labeled and unlabeled) and the sparse priors, and integrating out the latent variables {\u03c4 ,u, s, z}, one obtains the logarithmic posterior probability of \u0398,\n`(\u0398) = \u2211M m=1 \u2211 i\u2208Um ln \u222b p(xmi, smi|\u0398)dsmi\n+ M\u2211 m=1 \u2211 i\u2208Lm ln \u222b p(xmi, ymi, zmi, smi|\u0398)dzmidsmi\n+ M\u2211 m=1 \u2211 k \u2211 j ln \u222b p(fmkj |\u03c4mkj)p(\u03c4mkj |\u03b3)d\u03c4mkj ,\n+ \u2211 j ln \u222b p(wj |uj)p(uj |\u03bb)duj\nlabeled and unlabeled feature vectors in the m-th data set, i.e., Lm \u222a Um = {1, 2, \u00b7 \u00b7 \u00b7 , Nm}.\nWe employ an expectation-maximization (EM) algorithm to maximize `(\u0398), with {\u03b7, F0} and hyperparameters {\u03b3, \u03bb} treated as input parameters to the algorithm, determined separately by cross-validation when necessary. The EM algorithm consists of an iteration of E-step and M-step. In the E-step, one computes the conditional moments of latent variables {zmi, smi, \u03c4 ,u} given the data and the most recent parameters \u0398. In the M-step, one calculates the updated model parameters \u0398\u0302 using the latent variables\u2019 moments obtained in E-step. The complete EM algorithm is given in Algorithm 1, with major update equations summarized below. The algorithm requires O(F0 \u2211M m=1Dm(Fm + F 2 0 )) scalar products per iteration.\nUpdate of Latent Features\u2019 Distribution1\n\u00b5\u0302 = 1\nna\n\u2211M m=1 \u2211Nm i=1 \u03c6mi (9a)\n\u03a3\u0302 = 1\nna\n\u2211M m=1 \u2211Nm i=1 ( (\u03c6mi \u2212 \u00b5)(\u03c6mi \u2212 \u00b5)T\n+ Rmw\u03b2miw TRm + Rm ) (9b)\nwhere na = \u2211M m=1Nm.\n\u03c6mi = Rm(\u03a3 \u22121\u00b5+ w(\u03bemi \u2212 b) + \u03b7\u22121FTm(xmi\u2212dm)), Rm = (\u03a3 \u22121 + wwT + \u03b7\u22121FTmFm) \u22121,\n\u03b2mi =  \u03c1mi, if i \u2208 Um, (\u03b62mi+\u03c1mi)gcdf ( \u03b6mi\u221a \u03c1mi )\n+\u03b6mi \u221a \u03c1migpdf (\n\u03b6mi\u221a \u03c1mi\n) , if i \u2208 Lm,\n\u03bemi =  \u03b6mi, if i \u2208 Um, \u03b6migcdf ( \u03b6mi\u221a \u03c1mi )\n+ \u221a \u03c1migpdf (\n\u03b6mi\u221a \u03c1mi\n) , if i \u2208 Lm,\n\u03c1mi = 1 + w TQmw, \u03b6mi = w T\u00b5+ b+ \u03b7\u22121wTQmF T m(xmi \u2212 Fm\u00b5\u2212 dm), Qm = (\u03a3 \u22121 + \u03b7\u22121FTmFm) \u22121.\nUpdate of Domain Transforms\nd\u0302m = 1 Nm \u2211Nm i=1 (xmi \u2212 Fm\u03c6mi) , (10a) f\u0302mk = Vmk(\u03b1IF0 + Vmk\u0393m1Vmk) \u22121Vmk\n\u00d7 \u2211Nm i=1 \u03c6 T mi(xmik \u2212 d\u0302mk), (10b)\n1It can be shown that, under the LPM, the marginal distribution of xmi isN (Fm\u00b5+dm, \u03b7I+Fm\u03a3FTm), with the mean and covariance matrix defined duplicately by (\u00b5,dm) and (Fm,\u03a3), respectively. Similar situations exist for zmi. To void duplicatedness, one may wish to set \u00b5 = 0, \u03a3 = I, and do not update them during learning.\nAlgorithm 1 The EM algorithm for learning the LPM\nInput: {xmi}Nmi=1 \u222a {ymi}i\u2208Lm , m = 1, 2, \u00b7 \u00b7 \u00b7 ,M ; {\u03b3, \u03bb} and {\u03b7, F0}. Initialize \u0398. repeat\nUpdate \u03a3, \u00b5 using {xmi}Nmi=1 \u222a {ymi}i\u2208Lm , m = 1, 2, \u00b7 \u00b7 \u00b7 ,M , according to (9) for m = 1 to M do\nUpdate Fm, dm using {xmi}Nmi=1 \u222a {ymi}i\u2208Lm according to (10) end for Estimate w, b according to (11) using {xmi}i\u2208Lm \u222a {ymi}i\u2208Lm , m = 1, 2, \u00b7 \u00b7 \u00b7 ,M ,\nuntil `(\u0398) Converges\nfor k = 1, 2, \u00b7 \u00b7 \u00b7 , F0 and m = 1, 2, \u00b7 \u00b7 \u00b7 ,M , where \u03b1 = \u03b7 \u221a \u03b3 is a regularization parameter and\n\u0393m1 = Nm\u2211 i=1 (\u03c6mi\u03c6 T mi + Rm + \u03b2miRmww TRm),\nVmk = diag( \u221a |fmk1|, \u221a |fmk2|, \u00b7 \u00b7 \u00b7 , \u221a |fmkF0 |).\nUpdate of Probit Classifier\nw\u0302 =G(\u03d1I+G\u03931G) \u22121G M\u2211 m=1 \u2211 i\u2208Lm \u03c6mi(\u03bemi\u2212b), (11a)\nb\u0302 = 1\u2211M\nm=1Nm M\u2211 m=1 \u2211 i\u2208Lm (\u03bemi \u2212 \u03c6Tmiw\u0302), (11b)\nwhere \u03d1 = \u221a \u03bb is another regularization parameter and\n\u03932 = M\u2211 m=1 \u2211 i\u2208Lm (\u03c6mi\u03c6 T mi + Rm + Rmw\u03b2miw TRm),\nG = diag( \u221a |w1|, \u221a |w2|, \u00b7 \u00b7 \u00b7 , \u221a |wF0 |)."}, {"heading": "5. Experimental Results", "text": ""}, {"heading": "5.1. Cancer Diagnosis", "text": "We first consider the two Wisconsin breast cancer datasets (original and diagnostic) from the UCI machine learning repository2. The objective of both tasks is to identify benign or malignant cells. The feature dimensionality is 9 for the original data and 30 for the diagnostic data. We set F0 to the smallest dimensionality among the tasks to favor error reduction (as suggested by (8)), and \u03b7 = 10\u22123 to enlarge the role of domain transforms in connecting the tasks, with the regularization parameters (\u03b1, \u03d1) determined via cross-validation (the robustness to these parameters is shown below). We perform both multitask learning and transfer learning experiments, and compare\n2UC Irvine Machine Learning Repository: http:// archive.ics.uci.edu/ml/.\nthe LPM to STL and the methods in (Wang & Mahadevan, 2011) (abbreviated as HDAMA), (Maayan & Mannor, 2011), and (Kulis et al., 2011), with all competing methods using standard probit classifiers. The method in (Maayan & Mannor, 2011) cannot perform MTL and is excluded in the comparisons on MTL. The performance is measured in terms of the area under ROC curve (AUC), as a function of the number of labeled examples per task in the MTL case, or the number of labeled examples in the target task in the transfer learning case. The results are averaged over 50 independent runs, each constituting an independent split of the data into training sets and test sets.\nFigure 2(a) shows that, for MTL, the LPM performs comparably as or slightly better than HDAMA and both outperform the other methods, especially when labeled data are scarce. In transfer learning, all data in the source domain are labeled, and we have only a few labeled data in the target domain. We transfer all the labeled data from the source domain to the target domain. Figure 2(b-c) show that the performance of the LPM is slightly better than HDAMA, probably due to the fact that the amount of data (labeled and unlabeled) is balanced between the two tasks.\nThe regularization parameters \u03b1 and \u03d1 control the sparsity of domain transforms and the classifier, respectively. Table 1 summarizes the performance of the LPM relative to STL, under a wide range of settings for these parameters. The importance of sparsity is indicated by the diminishing performance improvements as the regularization parameters approach zero. Over a wide range in the middle, the LPM maintains stable performance improvements over STL, indicating the learning is robust to the settings of regularization parameters. The table also shows that the sparsity of domain transforms plays a more prominent role in influencing the performance than the classifier itself, signaling that the benefit of sharing information among the tasks can outweigh the benefit of feature selection."}, {"heading": "5.2. Mine Detection", "text": "The land-mine detection problem (Xue et al., 2007) is based on airborne synthetic-aperture radar (SAR) data and the underwater mine detection problem (Liu et al., 2009) is based on synthetic-aperture sonar (SAS) data3. Here we solve these two problems together, using the proposed cross-domain multitask learning approach. The feature dimensionality of land-mine data is 9 and that of underwater mine data is 13, and the labels do not have the same exact meaning for the two problem domains. There are a total of 19 land-mine tasks and 8 underwater mine tasks. The number of data points in the underwater mine tasks ranges from 756 to 3562, which is much larger than that for the land-mine tasks (ranging from 445 to 454). This problem can be viewed as a multitask learning across heterogeneous input and output domains (although the labels have known correspondence). We consider 9 land-mine tasks and all 8 underwater tasks, pairing\n3The land-mine data are available at http://www.ee. duke.edu/~lcarin/LandmineData.zip and the underwater mine data are available at http://www.ece.duke.edu/ ~lcarin/UnderwaterMines.zip\nthem up to form 9 \u00d7 8 = 72 MTL problems. The results are reported as an average over the 72 problems, with the setting of F0 and regularization parameters based on the same rule as in Section 5.1.\nThe performance comparisons for multi-task learning are shown in Figure 3(a) in terms of average AUC. Each curve results from an average of 100 independent runs of independently splitting the data into training and test sets and 9 \u00d7 8 combinations of underwater tasks versus land-mine tasks. In the transfer learning case, 50 labeled samples together with all other unlabeled samples are transferred to the target domain. The performance on the target task is shown in Figure 3(b-c). It is seen that the LPM outperforms all other methods by significantly large margins, in both multi-task learning and transfer learning from landmine data to underwater mine data. The competition on transfer learning from underwater mine data to land-mine data is more intense, but the LPM still gives the best overall outperformance.\nWhile the amount of examples is balanced between the two Wisconsin tasks, it is highly unbalanced between\nthe land-mine tasks and the underwater mine tasks (as detailed above). The results indicate that the LPM is more robust to this unbalance than the other methods."}, {"heading": "6. Conclusions", "text": "We have proposed the LPM model for cross-domain multi-task learning, assuming heterogenous feature representations across the tasks. The benefit of MTL in the LPM is based on the tasks\u2019 relatedness in the latent feature space, which is characterized by the sparse domain transforms. By promoting sparseness of domain transforms and the common classifiers, information sharing is encouraged to the advantage of improving performance in each individual task. The importance of sparsity is demonstrated by both theoretical analysis and experimental results."}, {"heading": "Acknowledgement", "text": "The research reported here has been supported by the ONR ATL program.\nAppendix\nProof of Theorem 1\nBy (7), one has\n1\nnt \u2016\u03a8T w\u0302\u2212z\u201622 + r\u2016w\u0302\u20161 \u2264\n1\nnt \u2016\u03a8Tw\u2217\u2212z\u201622 + r\u2016w\u2217\u20161.\nSubstituting z = \u03a8Tw\u2217 + e, one obtains\n1\nnt \u2016\u03a8T (w\u0302\u2212w\u2217)\u2212 e\u201622 \u2264\n1\nnt \u2016e\u201622 + r(\u2016w\u2217\u20161\u2212\u2016w\u0302\u20161),\nwhich, using the notations \u03b4 = w\u0302 \u2212 w\u2217 and re = \u2016\u03a8e\u2016\u221e/nt, is expanded to give\n1 nt \u2016\u03a8T \u03b4\u201622 \u2264 2nt \u03b4 T\u03a8e + r(\u2016w\u2217\u20161 \u2212 \u2016w\u0302\u20161),\n\u2264 2re\u2016\u03b4\u20161 + r(\u2016w\u2217\u20161 \u2212 \u2016w\u0302\u20161), = 2re(\u2016\u03b4J\u20161+\u2016w\u0302Jc\u20161) +r(\u2016w\u2217J\u20161\u2212\u2016w\u0302J\u20161)\u2212 r\u2016w\u0302Jc\u20161, (a) \u2264 \u2016\u03b4J\u20161(2re + r) + \u2016w\u0302Jc\u20161(2re \u2212 r), \u2264 \u221a s\u2016\u03b4J\u20162(2re+r) + \u2016w\u0302Jc\u20161(2re\u2212r), (12)\nwhere inequality (a) arises because \u2016w\u2217\u20161\u2212\u2016w\u0302\u20161 \u2264 \u2016w\u2217\u2212 w\u0302\u20161 = \u2016\u03b4J\u20161. Dividing both sides of (12) by \u2016\u03a8T \u03b4\u20162 gives\n1\nnt \u2016\u03a8T \u03b4\u20162 \u2264 \u221a s\u2016\u03b4J\u20162 \u2016\u03a8T \u03b4\u20162 (2re+r) + \u2016w\u0302Jc\u20161 \u2016\u03a8T \u03b4\u20162 (2re\u2212r),\nwhich is reduced to\n1\nnt \u2016\u03a8T \u03b4\u20162 \u2264 2r \u221a s \u2016\u03b4J\u20162 \u2016\u03a8T \u03b4\u20162 . (13)\nwhen 2re \u2264 r. Clearly the inequality in (13) holds with probability no less than Pe = p(2re \u2264 r). We will come back to find the expression of Pe; until then we assume 2re \u2264 r is true. We follow (Bickel et al., 2009; Lounici et al., 2009) to similarly define \u03bas = min\n\u03b4 6=0 n \u22121/2 t \u2016\u03b4J\u2016 \u22121 2 \u2016\u03a8 T \u03b4\u20162, then\n\u2016\u03b4J\u20162 \u2264 \u03ba\u22121s n \u22121/2 t \u2016\u03a8 T \u03b4\u20162, (14)\nSubstitution of (14) into (13) yields \u2016\u03a8T \u03b4\u20162 \u2264 2r \u221a nts/\u03bas, which is substituted back into (14) to give\n\u2016\u03b4J\u20162 \u2264 2r\u03ba\u22122s \u221a s. (15)\nBy the definition of \u03bas, one has\nnt\u03ba 2 s = min\n\u03c5 6=0 \u2016\u03a8T\u03c5\u201622 \u2016\u03c5J\u201622 \u2265 min \u03c5 6=0 \u2016\u03a8T\u03c5\u201622 \u2016\u03c5\u201622 .\nSubstituting (5), alongside (4), one gets\nnt\u03ba 2 s = min\n\u03c5 6=0 M\u2211 m=1 \u2016XTmFm(FTmFm)\u22121\u03c5\u201622 \u2016\u03c5\u201622 ,\n\u2265 \u2211M m=1 min\u03c5 6=0 \u2016XTmFm(FTmFm)\u22121\u03c5\u201622 \u2016\u03c5\u201622 ,\n(Weyl\u2019s Inequality)\n= M\u2211 m=1 min \u03c5 6=0 \u2016XTmFm(FTmFm)\u22121\u03c5\u201622 \u2016Fm(FTmFm)\u22121\u03c5\u201622 \u03c5T (FTmFm) \u22121\u03c5 \u03c5T\u03c5 ,\n\u2265 M\u2211 m=1 min \u03c5 6=0 \u2016XTmFm(FTmFm)\u22121\u03c5\u201622 \u2016Fm(FTmFm)\u22121\u03c5\u201622\n\u00d7min \u03c5 6=0\n\u03c5T (FTmFm) \u22121\u03c5\n\u03c5T\u03c5 ,\n\u2265 M\u2211 m=1 min \u03c5\u0303 6=0 \u2016Xm\u03c5\u0303\u201622 \u2016\u03c5\u0303\u201622 min \u03c5 6=0 \u03c5T (FTmFm) \u22121\u03c5 \u03c5T\u03c5 ,\n\u2265 M\u2211 m=1 \u03c9min(X T mXm) \u03c9max(FTmFm) , (16)\nwhere \u03c9min(\u00b7) and \u03c9max(\u00b7) respectively represents the maximum and minimum eigenvalue of a Hermitian matrix. Substitution of (16) into (15) gives\n\u2016\u03b4J\u20162 \u2264 2r \u221a s\u2211M\nm=1 \u03c9min(X T mXm/nt)\u03c9 \u22121 max(FTmFm)\n. (17)\nBy the result in (Byrne, 2009),\n\u03c9max(F T mFm) \u2264 maxi (\u2211F0 j=1 \u2016fm,:,j\u20160|fij | 2 ) ,\nm = 1, 2, \u00b7 \u00b7 \u00b7 ,M , which is substituted into (17) to yield (8), using the auxiliary variable defined as a = ntr (lnF0) \u22121/2\u03b5\u22121\u03c8 and \u2016\u03b4Jc\u20162 \u2264 \u2016\u03b4Jc\u20161 \u2264 c0\u2016\u03b4J\u20161 \u2264 c0 \u221a s\u2016\u03b4J\u20162, where \u2016\u03b4Jc\u20161 \u2264 c0\u2016\u03b4J\u20161 by assumption.\nRecall that (13) holds with probability no less than Pe = p(2re \u2264 r). Since (8) is implied by (13), the probability for (8) being true is no less than Pe also.\nTo evaluate Pe, we first plug re = \u2016\u03a8e\u2016\u221e/nt into Pe = p(2re \u2264 r) and expand the result, yielding\nPe = p(2\u2016\u03a8e\u2016\u221e/nt \u2264 r), = 1\u2212 p(2\u2016\u03a8e\u2016\u221e/nt \u2265 r), \u2265 1\u2212 \u2211F0 j=1p ( 2|\u03c8Tj e|/nt \u2265 r ) ,\n= 1\u2212 \u2211F0 j=1p ( |\u03c8Tj e| \u2016\u03c8j\u2016\u221212 \u2265 ntr2 \u22121\u2016\u03c8j\u2016\u221212 ) ,\n\u2265 1\u2212 \u2211F0 j=1p ( |\u03c8Tj e| \u2016\u03c8j\u2016\u221212 \u2265 ntr/(2\u03b5\u03c8) ) ,\nwhere the first inequality results from the union bound. Since the elements of e are i.i.d. from the standard normal distribution, so is \u03c8Tj e/\u2016\u03c8j\u20162. Using the inequality P(|X| > x) \u2264 2 exp (\u2212x 2 2 )/(x \u221a\n2\u03c0), x > 0, for any standard normal-distributed random number X, one obtains\nPe \u2265 1\u2212 4F0 exp (\u2212n\n2 t r 2\n8\u03b52 \u03c8 ) \u221a\n2\u03c0ntr\u03b5 \u22121 \u03c8\n= 1\u2212 4 a \u221a 2\u03c0 lnF0 F 1\u2212a2/8 0 , \u2265 1\u2212 F 1\u2212a 2/8\n0 ,\nwhere the equation is due to a = ntr (lnF0) \u22121/2\u03b5\u22121\u03c8 , and the second inequality arises because F0 \u2265 2 and a \u2265 \u221a\n8 by assumption, which ensure 4\na \u221a 2\u03c0 lnF0 \u2264 1."}], "references": [{"title": "Bayesian analysis of binary and polychotomous response data", "author": ["J.H. Albert", "S. Chib"], "venue": "Journal of the American Statistical Association,", "citeRegEx": "Albert and Chib,? \\Q1993\\E", "shortCiteRegEx": "Albert and Chib", "year": 1993}, {"title": "Multi-task feature learning", "author": ["Argyriou", "Andreas", "Evgeniou", "Theodoros", "Pontil", "Massimiliano"], "venue": "Advances in Neural Information Processing Systems", "citeRegEx": "Argyriou et al\\.,? \\Q2007\\E", "shortCiteRegEx": "Argyriou et al\\.", "year": 2007}, {"title": "Task clustering and gating for Bayesian multitask learning", "author": ["B. Bakker", "T. Heskes"], "venue": "Journal of Machine Learning Research,", "citeRegEx": "Bakker and Heskes,? \\Q2003\\E", "shortCiteRegEx": "Bakker and Heskes", "year": 2003}, {"title": "A model of inductive bias learning", "author": ["J. Baxter"], "venue": "J. Artif. Intell. Res. (JAIR), pp", "citeRegEx": "Baxter,? \\Q2000\\E", "shortCiteRegEx": "Baxter", "year": 2000}, {"title": "A notion of task relatedness yielding provable multiple-task learning guarantees", "author": ["S. Ben-David", "R.S. Borbely"], "venue": "Machine Learning,", "citeRegEx": "Ben.David and Borbely,? \\Q2008\\E", "shortCiteRegEx": "Ben.David and Borbely", "year": 2008}, {"title": "Simultaneous analysis of lasso and dantzig selector", "author": ["P.J. Bickel", "Y. Ritov", "B.T. Tsybakov"], "venue": "The Annals of Statistics,", "citeRegEx": "Bickel et al\\.,? \\Q2009\\E", "shortCiteRegEx": "Bickel et al\\.", "year": 2009}, {"title": "Bounds on the largest singular value of a matrix and the convergence of simultaneous and blockiterative algorithms for sparse linear systems", "author": ["C. Byrne"], "venue": "International Transactions in Operational Research,", "citeRegEx": "Byrne,? \\Q2009\\E", "shortCiteRegEx": "Byrne", "year": 2009}, {"title": "Adaptive sparseness for supervised learning", "author": ["M.A.T. Figueiredo"], "venue": "IEEE Trans. Pattern Anal. Mach. Intell.,", "citeRegEx": "Figueiredo,? \\Q2003\\E", "shortCiteRegEx": "Figueiredo", "year": 2003}, {"title": "A graph-based framework for multi-task multi-view learning", "author": ["J. He", "L. Rick"], "venue": "In Proceedings of the 28th International Conference on Machine Learning, ICML\u2019", "citeRegEx": "He and Rick,? \\Q2011\\E", "shortCiteRegEx": "He and Rick", "year": 2011}, {"title": "What you saw is not what you get: Domain adaptation using asymmetric kernel transforms", "author": ["B. Kulis", "K. Saenko", "T. Darrell"], "venue": "In Computer Vision and Pattern Recognition (CVPR),", "citeRegEx": "Kulis et al\\.,? \\Q2011\\E", "shortCiteRegEx": "Kulis et al\\.", "year": 2011}, {"title": "Semisupervised multitask learning", "author": ["Q. Liu", "X. Liao", "H. Li", "J.R. Stack", "L. Carin"], "venue": "Pattern Analysis and Machine Intelligence, IEEE Transactions on,", "citeRegEx": "Liu et al\\.,? \\Q2009\\E", "shortCiteRegEx": "Liu et al\\.", "year": 2009}, {"title": "Taking advantage of sparsity in multi-task learning", "author": ["K. Lounici", "M. Pontil", "A.B. Tsybakov", "S. van de Geer"], "venue": "In Proceedings of the 22nd Conference on Information Theory,", "citeRegEx": "Lounici et al\\.,? \\Q2009\\E", "shortCiteRegEx": "Lounici et al\\.", "year": 2009}, {"title": "Learning from multiple outlooks", "author": ["H. Maayan", "S. Mannor"], "venue": "In ICML, pp", "citeRegEx": "Maayan and Mannor,? \\Q2011\\E", "shortCiteRegEx": "Maayan and Mannor", "year": 2011}, {"title": "Heterogeneous domain adaptation using manifold alignment", "author": ["C. Wang", "S. Mahadevan"], "venue": "IJCAI/AAAI,", "citeRegEx": "Wang and Mahadevan,? \\Q2011\\E", "shortCiteRegEx": "Wang and Mahadevan", "year": 2011}, {"title": "Multitask learning for classification with dirichlet process priors", "author": ["Y. Xue", "X. Liao", "L. Carin", "B. Krishnapuram"], "venue": "J. Mach. Learn. Res.,", "citeRegEx": "Xue et al\\.,? \\Q2007\\E", "shortCiteRegEx": "Xue et al\\.", "year": 2007}], "referenceMentions": [{"referenceID": 3, "context": "Whereas STL solves each task in isolation, with possible relations between the tasks ignored, MTL solves the tasks jointly, exploiting between-task relations to reduce the hypothesis space and improve generalization (Baxter, 2000).", "startOffset": 216, "endOffset": 230}, {"referenceID": 3, "context": "For supervised learning, in particular, MTL can achieve the same level of generalization performance as STL, and yet uses significantly fewer labeled examples per task (Baxter, 2000).", "startOffset": 168, "endOffset": 182}, {"referenceID": 3, "context": "While the MTL literature has primarily assumed that the tasks have the same input and output domains and differ only in data distributions (Baxter, 2000; Bakker & Heskes, 2003; Argyriou et al., 2007; Ben-David & Borbely, 2008), a number of recent publications are beginning to break the limit of this assumption, in an attempt of extending MTL to a wider range of applications (He & Rick, 2011; Maayan & Mannor, 2011; Kulis et al.", "startOffset": 139, "endOffset": 226}, {"referenceID": 1, "context": "While the MTL literature has primarily assumed that the tasks have the same input and output domains and differ only in data distributions (Baxter, 2000; Bakker & Heskes, 2003; Argyriou et al., 2007; Ben-David & Borbely, 2008), a number of recent publications are beginning to break the limit of this assumption, in an attempt of extending MTL to a wider range of applications (He & Rick, 2011; Maayan & Mannor, 2011; Kulis et al.", "startOffset": 139, "endOffset": 226}, {"referenceID": 9, "context": ", 2007; Ben-David & Borbely, 2008), a number of recent publications are beginning to break the limit of this assumption, in an attempt of extending MTL to a wider range of applications (He & Rick, 2011; Maayan & Mannor, 2011; Kulis et al., 2011; Wang & Mahadevan, 2011).", "startOffset": 185, "endOffset": 269}, {"referenceID": 9, "context": "The work in (Kulis et al., 2011) considers a source task and a target task, assumed to have different feature dimensions, and learns a nonlinear transformation between the source feature domain and the target feature domain using kernel techniques.", "startOffset": 12, "endOffset": 32}, {"referenceID": 9, "context": "The approach we take differs from (Maayan & Mannor, 2011; Kulis et al., 2011; Wang & Mahadevan, 2011) in several important aspects.", "startOffset": 34, "endOffset": 101}, {"referenceID": 9, "context": "By contrast, the methods in (Maayan & Mannor, 2011; Kulis et al., 2011) are supervised, and the method in (Wang & Mahadevan, 2011) is semi-supervised in learning domain transforms, but supervised in learning classification.", "startOffset": 28, "endOffset": 71}, {"referenceID": 7, "context": "The proposed approach is based on a sparse hierarchical Bayesian model, referred to as the latent probit model (LPM), which jointly represents the sparse domain transforms and a common sparse probit classifier (Albert & Chib, 1993) in the latent feature space, with the sparsity imposed by a hierarchical Laplacian prior (Figueiredo, 2003).", "startOffset": 321, "endOffset": 339}, {"referenceID": 7, "context": "The parameters w and {Fm}m=1 are given hierarchical Laplacian priors (Figueiredo, 2003) to encourage sparsity, with the priors specified by hyperparameters {\u03b3, \u03bb}.", "startOffset": 69, "endOffset": 87}, {"referenceID": 5, "context": "We derive an upper bound to \u2016\u0175 \u2212 w\u20162, following similar arguments as in (Bickel et al., 2009; Lounici et al., 2009) and making use of a key result in (Byrne, 2009) on extreme singular values of Hermitian matrices.", "startOffset": 72, "endOffset": 115}, {"referenceID": 11, "context": "We derive an upper bound to \u2016\u0175 \u2212 w\u20162, following similar arguments as in (Bickel et al., 2009; Lounici et al., 2009) and making use of a key result in (Byrne, 2009) on extreme singular values of Hermitian matrices.", "startOffset": 72, "endOffset": 115}, {"referenceID": 6, "context": ", 2009) and making use of a key result in (Byrne, 2009) on extreme singular values of Hermitian matrices.", "startOffset": 42, "endOffset": 55}, {"referenceID": 9, "context": "the LPM to STL and the methods in (Wang & Mahadevan, 2011) (abbreviated as HDAMA), (Maayan & Mannor, 2011), and (Kulis et al., 2011), with all competing methods using standard probit classifiers.", "startOffset": 112, "endOffset": 132}, {"referenceID": 9, "context": "LPM (Proposed Method) STL HDAMA (Wang & Mahadevan,2011) Kulis et al.(2011) 50 100 150 200 0.", "startOffset": 56, "endOffset": 75}, {"referenceID": 9, "context": "LPM (Proposed Method) STL HDAMA (Wang & Mahadevan,2011) Maayan & Mannor (2011) Kulis et al.(2011) 50 100 150 200 0.", "startOffset": 79, "endOffset": 98}, {"referenceID": 9, "context": "LPM (Proposed Method) STL HDAMA (Wang & Mahadevan,2011) Maayan & Mannor (2011) Kulis et al.(2011)", "startOffset": 79, "endOffset": 98}, {"referenceID": 14, "context": "The land-mine detection problem (Xue et al., 2007) is based on airborne synthetic-aperture radar (SAR) data and the underwater mine detection problem (Liu et al.", "startOffset": 32, "endOffset": 50}, {"referenceID": 10, "context": ", 2007) is based on airborne synthetic-aperture radar (SAR) data and the underwater mine detection problem (Liu et al., 2009) is based on synthetic-aperture sonar (SAS) data.", "startOffset": 107, "endOffset": 125}, {"referenceID": 9, "context": "LPM (Proposed Method) STL HDAMA (Wang & Mahadevan,2011) Kulis et al.(2011) 50 100 150 200 250 300 0.", "startOffset": 56, "endOffset": 75}, {"referenceID": 9, "context": "LPM (Proposed Method) STL HDAMA (Wang & Mahadevan,2011) Maayan & Mannor (2011) Kulis et al.(2011) 50 100 150 200 250 300 0.", "startOffset": 79, "endOffset": 98}, {"referenceID": 9, "context": "LPM (Proposed Method) STL HDAMA (Wang & Mahadevan,2011) Maayan & Mannor (2011) Kulis et al.(2011)", "startOffset": 79, "endOffset": 98}, {"referenceID": 5, "context": "We follow (Bickel et al., 2009; Lounici et al., 2009) to similarly define \u03bas = min \u03b4 6=0 n \u22121/2 t \u2016\u03b4J\u2016 \u22121 2 \u2016\u03a8 T \u03b4\u20162, then", "startOffset": 10, "endOffset": 53}, {"referenceID": 11, "context": "We follow (Bickel et al., 2009; Lounici et al., 2009) to similarly define \u03bas = min \u03b4 6=0 n \u22121/2 t \u2016\u03b4J\u2016 \u22121 2 \u2016\u03a8 T \u03b4\u20162, then", "startOffset": 10, "endOffset": 53}, {"referenceID": 6, "context": "By the result in (Byrne, 2009),", "startOffset": 17, "endOffset": 30}], "year": 2012, "abstractText": "Learning multiple tasks across heterogeneous domains is a challenging problem since the feature space may not be the same for different tasks. We assume the data in multiple tasks are generated from a latent common domain via sparse domain transforms and propose a latent probit model (LPM) to jointly learn the domain transforms, and a probit classifier shared in the common domain. To learn meaningful task relatedness and avoid over-fitting in classification, we introduce sparsity in the domain transforms matrices, as well as in the common classifier parameters. We derive theoretical bounds for the estimation error of the classifier parameters in terms of the sparsity of domain transform matrices. An expectation-maximization algorithm is derived for learning the LPM. The effectiveness of the approach is demonstrated on several real datasets.", "creator": "LaTeX with hyperref package"}}}