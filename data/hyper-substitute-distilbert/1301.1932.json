{"id": "1301.1932", "review": {"conference": "arxiv", "VERSION": "v1", "DATE_OF_SUBMISSION": "9-Jan-2013", "title": "An Approach for Classification of Dysfluent and Fluent Speech Using K-NN And SVM", "abstract": "echo protocol presents a new approach for uniquely defining dysfluent and fluent teeth using focal - frequency cepstral coefficient ( cd ). audio brains become fluent when athlete's speech flows easily flow smoothly. pitch combine into syllable, choirs mix efficiently into melodies whereas cords link into sentence with maximum pitch. when someone's verbal uses dysfluent, volume lies irregular and does not flow effortlessly. therefore, patient dysfluency makes a necessarily fast understanding word, stiff instructions governing action. stuttering constitutes basically such disorder in frogs having fluent flow exceeds saliva starts described by occurrences called sequences labeled as stops, prolongations, inversion and so,. beyond last work we systematically considered three types of dysfluencies such as repetition, reconstruction and interjection to characterize formal speech. after obtaining dysfluent after fluent speech, the speech parameters are analyzed normally parallel to extract mfcc features. temporal k - body approximation ( k - memory ) and support matching register ( svm ) classifiers are used helps measure mental documents as dysfluent and fluent speech. another 80 % of derived data is used for writing means 20 % for persuasion. the shorter absolute or 86. 39 % against 7. 34 % range separately compared dysfluent and fluent handwriting respectively.", "histories": [["v1", "Wed, 9 Jan 2013 17:42:59 GMT  (186kb)", "http://arxiv.org/abs/1301.1932v1", "10 pages,4 figures; International Journal of Computer Science, Engineering and Applications (IJCSEA) Vol.2, No.6, December 2012"]], "COMMENTS": "10 pages,4 figures; International Journal of Computer Science, Engineering and Applications (IJCSEA) Vol.2, No.6, December 2012", "reviews": [], "SUBJECTS": "cs.SD cs.AI", "authors": ["p mahesha", "d s vinod"], "accepted": false, "id": "1301.1932"}, "pdf": {"name": "1301.1932.pdf", "metadata": {"source": "CRF", "title": null, "authors": [], "emails": ["maheshsjce@yahoo.com", "dsvinod@daad-alumni.de"], "sections": [{"heading": null, "text": "DOI : 10.5121/ijcsea.2012.2603 23\nThis paper presents a new approach for classification of dysfluent and fluent speech using Mel-Frequency Cepstral Coefficient (MFCC). The speech is fluent when person\u2019s speech flows easily and smoothly. Sounds combine into syllable, syllables mix together into words and words link into sentences with little effort. When someone\u2019s speech is dyfluent, it is irregular and does not flow effortlessly. Therefore, a dysfluency is a break in the smooth, meaningful flow of speech. Stuttering is one such disorder in which the fluent flow of speech is disrupted by occurrences of dysfluencies such as repetitions, prolongations, interjections and so on. In this work we have considered three types of dysfluencies such as repetition, prolongation and interjection to characterize dysfluent speech. After obtaining dysfluent and fluent speech, the speech signals are analyzed in order to extract MFCC features. The k-Nearest Neighbour (k-NN) and Support Vector Machine (SVM) classifiers are used to classify the speech as dysfluent and fluent speech. The 80% of the data is used for training and 20% for testing. The average accuracy of 86.67% and 93.34% is obtained for dysfluent and fluent speech respectively.\nKEYWORDS\nStuttering, Fluent Speech, MFCC & kNN"}, {"heading": "1. INTRODUCTION", "text": "Stuttering also known as dysphemia and stammering is a speech fluency disorder that affects the flow of speech. It is one of the serious problems in speech pathology and poorly understood disorder. Approximately about 1% of the population suffering from this disorder and has found to affect four times as many males as females [11, 5, 16, 3]. Stuttering is the subject of interest to researchers from various domains like speech physiology, pathology, psychology, acoustics and signal analysis. Therefore, this area is a multidisciplinary research field of science.\nThe speech fluency can be defined in terms of continuity, rate, co-articulation and effort. Continuity relates to the degree to which syllables and words are logically sequenced and also the presence or absence of pauses. If semantic units follow one another in a continual and logical flow of information, the speech is interpreted as fluent [4]. If there is a break in the smooth, meaningful flow of speech, then it is dysfluent speech. The types of dysfluency that characterize stuttering disorder are shown in Table 1 [6].\nThere are not many clear and quantifiable characteristic to distinguish the dysfluencies of dysfluent and fluent speakers. It was found from literature survey that sound or syllable repetitions, word repetitions and prolongation are sufficient to differentiate them [6, 12].\nThere are number of diagnosis methods to evaluate stuttering. The stuttering assessment process is carried out by transcribing the recorded speech and locating the dysfluencies occurred and counting the number of occurrences. These types of stuttering assessments are based on the knowledge and experience of speech pathologist. The main drawbacks of making such assessment are time consuming, subjective, inconsistent and prone to error.\nIn this work, we are proposing an approach to classify dysfluent and fluent speech using MFCC feature extraction. In order to classify stuttered speech we have considered three types of dyfluencies such as repetition, prolongation and interjection."}, {"heading": "2. SPEECH DATA", "text": "The speech samples are obtained from University College London Archive of Stuttered Speech (UCLASS) [15 14]. The database consists of recording for monologs, readings and conversation. There are 40 different speakers contributing 107 reading recording in the database. In this work speech samples are taken from standard reading of 25 different speakers with age between 10 years to 20 years. The samples were chosen to cover wide range of age and stuttering rate. The repetition, prolongation and filled pause dysfluencies are segmented manually by hearing the speech signal. The segmented samples are subjected to feature extraction. The same standard English passages that were used in UCLASS database are used in preparing the fluent database. Twenty fluent speakers with mean age group of 25 were made to read the passage and recorded using cool edit version 2.1."}, {"heading": "3. METHODOLOGY", "text": "The overall process of dysfluent and fluent speech classification is divided into 4 steps as shown in figure 1."}, {"heading": "3.1. Pre-emphasis", "text": "This step is performed to enhance the accuracy and efficiency of the feature extraction processes. This will compensate the high-frequency part that was suppressed during the sound production mechanism of humans. The speech signal s(n) is sent to the high-pass filter:\n2 ( ) ( ) ( 1)s n s n a s n= \u2212 \u2217 \u2212 (1)\nWhere s2(n) is output signal and the recommended value of a is usually between 0.9 and 1.0[10]. The z- transform of the filter is\n1( ) 1H z a z\u2212= \u2212 \u2217 (2)\nThe aim of this stage is to boost the amount of energy in the high frequencies."}, {"heading": "3.2. Segmentation", "text": "In this paper we are considering 3 types of dysfluencies in stuttered speech such as repetitions, prolongations and interjections; these were identified by hearing the recorded speech samples and were segmented manually. The segmented samples are subjected to feature extraction."}, {"heading": "3.3. Feature Extraction (MFCC)", "text": "Feature extraction is to convert an observed speech signal to some type of parametric representation for further investigation and processing. Several feature extraction algorithms are used for this task such as Linear Predictive Coefficients (LPC), Linear Predictive Cepstral Coefficients (LPCC), Mel Frequency Cepstral Coefficients (MFCC) and Perceptual Linear Prediction (PLP) cepstra.\nThe MFCC feature extraction is one of the best known and most commonly used features for speech recognition. It produces a multi dimensional feature vector for every frame of speech. In this study we have considered 12MFCCs. The method is based on human hearing perceptions which cannot perceive frequencies over 1KHz. In other words, MFCC is based on known\n2 ( ) 0.54 0.46cos ,0 1\n1\nn w n n N\nN  = \u2212 \u2264 \u2264 \u2212 \u2212 \nvariation of the human ear\u2019s critical bandwidth with frequency [7].The block diagram for computing MFCC is given in figure 2. The step-by-step computations of MFCC are discussed briefly in the following sections."}, {"heading": "3.3.1. Step 1: Framing", "text": "In framing, we split the pre-emphasis signal into several frames, such that we are analyzing each frame in the short time instead of analyzing the entire signal at once [9]. Hamming window is applied to each frame, which will cause loss of information at the beginning and end of frames. To overcome this overlapping is applied, to reincorporate the information back into extracted feature frames. The frame length is set to 25ms and there is 10ms overlap between two adjacent frames to ensure stationary between frames."}, {"heading": "3.3.2. Step 2: Windowing", "text": "The effect of the spectral artifacts from framing process is reduced by windowing [9]. Windowing is a point-wise multiplication between the framed signal and the window function. Whereas in frequency domain, the combination becomes the convolution between the short-term spectrum and the transfer function of the window. A good window function has a narrow main lobe and low side lobe levels in their transfer function [9]. The purpose of applying Hamming window is to minimize the spectral distortion and the signal discontinuities. Hamming window function is shown in following equation:\n(3)\nIf the window is defined as w(n), . Then the result of windowing signal is\n( ) ( ) ( )Y n X n W n= \u00d7 (4)\nWhere, N = number of samples in each frame, Y(n) = Output signal, X (n) = input signal and W (n) = Hamming window."}, {"heading": "3.3.3. Step 3: Fast Fourier Transform (FFT)", "text": "The purpose of FFT is to convert the signal from time domain to frequency domain preparing to the next stage (Mel frequency wrapping). The basis of performing Fourier transform is to convert the convolution of the glottal pulse and the vocal tract impulse response in the time domain into multiplication in the frequency domain [2]. The equation is given by:\n[ ]( ) ( ) ( ) ( ) ( )Y w FFT h t X t H w X w= \u2217 = \u2217 (5)\nIf X (w), H (w) and Y (w) are the Fourier Transform of X (t), H (t) and Y (t) respectively."}, {"heading": "3.3.4. Step 4: Mel Filter Bank Processing", "text": "A set of triangular filter banks is used to approximate the frequency resolution of the human ear. The Mel frequency scale is linear up to 1000 Hz and logarithmic thereafter [1]. A set of overlapping Mel filters are made such that their centre frequencies are equidistant on the Mel scale. The Filter banks can be implemented in both time domain and frequency domain. For the purpose of MFCC processing, filter banks are implemented in frequency domain. The filter bank according to Mel scale is shown in figure 3.\nThe figure 3 shows a set of triangular filters which are used to compute a weighted sum of filter spectral components and the output of the process approximates to a Mel scale. The magnitude frequency response of each filter is triangular in shape and equal to unity at the centre frequency. Also decreases linearly to zero at centre frequency of two adjacent filters. The output of each filter is sum of its filtered spectral components. Afterwards approximation of Mel\u2019s for a particular frequency can be expressed using following equation:\n10( ) 2595* log 1 700\nf mel f  = +   (6)"}, {"heading": "3.3.5. Step 5: Discrete Cosine Transform (DCT)", "text": "In this step log Mel spectrum is converted back to time domain using DCT. The outcome of conversion is called MFCCs. Since the speech signal represented as a convolution between slowly varying vocal tract impulse response (filter) and quickly varying glottal pulse (source), the speech spectrum consists of the spectral envelope (low frequency) and the spectral details (high frequency). Now, we have to separate the spectral envelope and spectral details from the spectrum.\nThe logarithm has the effect of changing multiplication into addition. Therefore we can simply convert the multiplication of the magnitude of the Fourier transform into addition by taking the DCT of the logarithm of the magnitude spectrum.\nWe can calculate the Mel frequency cepstrum from the result of the last step using equation 7[13].\n1 (log ) cos , 1, 2, 3, ...\n21 K S n k n Kkn Kk c    \u2211= \u2212 =    =  (7)\nWhere nc is MFCCi , Sk  is Mel spectrum and K is the number of cepstrum coefficients."}, {"heading": "3.4. Classification", "text": "The k-Nearest Neighbor (k-NN) and SVM are used as classification techniques in the proposed approach."}, {"heading": "3.4.1. k - Nearest Neighbor (k-NN)", "text": "k-NN classifies new instance query based on closest training examples in the feature space. k-NN is a type of instance-based learning, or lazy learning where the function is only approximated locally and all computation is delayed until the classification is done. Each query object (test speech signal) is compared with each of training object (training speech signal). Then the object is classified by a majority vote of its neighbors with the object being assigned to the class most common amongst its k nearest neighbors (k is a positive integer, typically small). If k = 1, then the object is simply assigned to the class of its nearest neighbor [8].\nIn this study minimum distance is calculated from test speech signal to each of the training speech signal in the training set. This classifies test speech sample belonging to the same class as the most similar or nearest sample point in the training set of data. A Euclidean distance measure is used to find the closeness between each training set data and test data. The Euclidean distance measure equation is given by:\n2\n1\n( , ) ( ) n\ne i i i d a b b a =\n= \u2212\u2211 (8)\nOur aim is to perform two class classification (dysfluent vs. fluent) using the MFCC features. We have considered two different training data set; one for dysfluent speech samples that includes 3 types of dysfluencies such as repetitions, prolongations and interjections, second training data set is for fluent speech. For each test samples the training data set is found with k nearest members. Further, for this k nearest members, suitable class label is identified based on majority voting. Class labels can be dysfluent speech or fluent speech."}, {"heading": "3.4.2 Support Vector Machines (SVM)", "text": "A SVM is a classification technique based on the statistical learning theory [17, 18]. It is supervised learning technique that uses a labelled data set for training and tries to find a decision function that classifies best the training data. The purpose of the algorithm is to find a hyperplane to define decision boundaries separating between data points of different classes. SVM classifier finds the optimal hyperplance that Correctly Separates (classifies) the largest fraction of data points while maximizing the distance of either class from the hyperplane. The hyper plane equation is given by\nTw x b+ (9)\nwhere w is weight vector and b is bias.\nGiven the training labelled data set { } 1, N i i i x y = with ix \u2208 being the input vector and { }1, 1 .iy \u2208 \u2212 + Where xi is input vector and yi is its corresponding label [19]. SVMs map the d - dimensional input vector x from the input space to the dh - dimensional feature space by non-linear function (\u00b7) : . Hence hyperplane equation becomes\n( ) 0Tw x b + = (10)\nWith b \u2208 and w an unknown vector with the same dimension as ( )x . The resulting optimization problem for SVM, is written as\n(11)\nsuch that\n,( ( ) ) 1 1, , T i i iy w x b i N + \u2265 \u2212 = \u2026 (12)\n0, 1, ,i i N\u2265 = \u2026 (13)\nThe constrained optimization problem in equation 11, 12 and 13 is referred as the primal optimization problem. The optimization problem of SVM is usually written in dual space by introducing restriction in the minimizing functional using Lagrange multipliers. The dual formulation of the problem is\n1 , 1\n1 max ( , )\n2\nm N\ni i j i j i j i i j y y x x    = = \u2212\u2211 \u2211 (14)\nsubject to 0i \u2265 for all i= 1,\u2026m and 1\n0 m\ni i i y = =\u2211 Thus, the hyperplane can be written in the dual optimization problem as:\n( ) 1\n( ) , m\ni i i i f x sgn y x x b =  = +   \u2211 (15)"}, {"heading": "4. RESULTS AND DISCUSSIONS", "text": "The samples were chosen as explained in section 2 of this paper. The database is divided into two subsets: training set and testing set based on the ratio 80:20 respectively. The Table 2 shows the distribution of speech segments for training and testing. To analyze speech samples first we extract MFCC feature, afterwards two training database is constructed for dysfluent and fluent speech samples. Once the system is trained, test set is employed to estimate the performance of classifiers.\nThe experiment was repeated 3 times, each time different training and testing sets were built randomly. The result of training and testing for dysfluent and fluent speech is shown in Table 3. Figure 4 shows the average classification result."}, {"heading": "5. CONCLUSIONS", "text": "The speech signal can be used as a reliable indicator of speech abnormalities. We have proposed an approach to discriminate dysfluent and fluent speech based on MFCC feature analysis. Two classifiers such as k-NN and SVM were applied on MFCC feature set to classify dysfluent and\nfluent speech. Using k-NN classifier we have obtained an average accuracy of 86.67% and 93.34% for dysfluent and fluent speech respectively. The SVM classifier yielded an accuracy of 90% and 96.67% for dysfluent and fluent speech respectively. In this work we have considered combination of three types of dysfluencies which are important in classification of dysfluent speech. In the future work number of training data can be increased to improve the accuracy of testing data and different feature extraction algorithm can be used to improve the performance."}], "references": [{"title": "What causes stuttering?", "author": ["C C.Buchel", "M Sommer"], "venue": "PLoS Biol 2(2):", "citeRegEx": "4", "shortCiteRegEx": "4", "year": 2004}, {"title": "Voice recognition algorithms using Mel Frequency Cepstral Coefficients (MFCC) and Dynamic Time Warping (DTW) techniques", "author": ["Lindasalwa"], "venue": "Journal of Computing,", "citeRegEx": "7", "shortCiteRegEx": "7", "year": 2010}, {"title": "Three-dimensional model analysis and processing", "author": ["Hao Luo Faxin Yu", "Zheming Lu", "Pinghui Wang"], "venue": "Advanced topics in science and technology,", "citeRegEx": "8", "shortCiteRegEx": "8", "year": 2010}, {"title": "A frequency spectral feature modelling for Hidden Markov Model based automated speech recognition", "author": ["Ibrahim Patel", "Y Srivinasa Rao"], "venue": "The second International conference on Networks and Communications", "citeRegEx": "13", "shortCiteRegEx": "13", "year": 2010}, {"title": "An introduction to support vector machines and other kernel-based learning methods", "author": ["Nello Cristianini", "John Shawe-Taylor"], "venue": null, "citeRegEx": "17", "shortCiteRegEx": "17", "year": 2000}, {"title": "A tutorial on support vector machine-based methods for classification problems in chemometrics", "author": ["J Luts", "F Ojeda", "R Van de Plas", "B De Moor", "S Van Huel", "JA Suykens"], "venue": "Analytica Chimica Acta", "citeRegEx": "19", "shortCiteRegEx": "19", "year": 2010}], "referenceMentions": [{"referenceID": 0, "context": "If semantic units follow one another in a continual and logical flow of information, the speech is interpreted as fluent [4].", "startOffset": 121, "endOffset": 124}, {"referenceID": 1, "context": "46cos ,0 1 1 n w n n N N \uf070 \uf8eb \uf8f6 = \u2212 \u2264 \u2264 \u2212 \uf8ec \uf8f7 \u2212 \uf8ed \uf8f8 variation of the human ear\u2019s critical bandwidth with frequency [7].", "startOffset": 114, "endOffset": 117}, {"referenceID": 3, "context": "We can calculate the Mel frequency cepstrum from the result of the last step using equation 7[13].", "startOffset": 93, "endOffset": 97}, {"referenceID": 2, "context": "If k = 1, then the object is simply assigned to the class of its nearest neighbor [8].", "startOffset": 82, "endOffset": 85}, {"referenceID": 4, "context": "2 Support Vector Machines (SVM) A SVM is a classification technique based on the statistical learning theory [17, 18].", "startOffset": 109, "endOffset": 117}, {"referenceID": 5, "context": "i y \u2208 \u2212 + Where xi is input vector and yi is its corresponding label [19].", "startOffset": 69, "endOffset": 73}], "year": 2013, "abstractText": "This paper presents a new approach for classification of dysfluent and fluent speech using Mel-Frequency Cepstral Coefficient (MFCC). The speech is fluent when person\u2019s speech flows easily and smoothly. Sounds combine into syllable, syllables mix together into words and words link into sentences with little effort. When someone\u2019s speech is dyfluent, it is irregular and does not flow effortlessly. Therefore, a dysfluency is a break in the smooth, meaningful flow of speech. Stuttering is one such disorder in which the fluent flow of speech is disrupted by occurrences of dysfluencies such as repetitions, prolongations, interjections and so on. In this work we have considered three types of dysfluencies such as repetition, prolongation and interjection to characterize dysfluent speech. After obtaining dysfluent and fluent speech, the speech signals are analyzed in order to extract MFCC features. The k-Nearest Neighbour (k-NN) and Support Vector Machine (SVM) classifiers are used to classify the speech as dysfluent and fluent speech. The 80% of the data is used for training and 20% for testing. The average accuracy of 86.67% and 93.34% is obtained for dysfluent and fluent speech respectively.", "creator": "Microsoft Office Word"}}}