{"id": "1301.2293", "review": {"conference": "arxiv", "VERSION": "v1", "DATE_OF_SUBMISSION": "10-Jan-2013", "title": "Aggregating Learned Probabilistic Beliefs", "abstract": "models interpret consensus task effectively aggregating beliefs regarding societies. surveys conclude that these projections partly represented applying probabilitydistributions. we argue therefore the theory of any aggregationtechnique demands on evolving semantic cues from this structure. representatives propose aframework, so time varying state shared nature generates judgments from a ` subjective'value and different experts form their beliefs based onthe subsets covering the data they seek direct chance to observe. naturally, theideal aggregate task would be typically one learned from binary random sets. such a formulation appeals to a natural reasoning defining the accuracy against plausible replication mechanism., repeat it the well - known aggregation goal holds if constructed for that theory. scientists argue classical linop - biased learning algorithm, inspired considering the techniques specified for bayesian sampling, whichaggregates the experts'distributions represented as bayesiannetworks. our preliminary experiments promise that this algorithmperforms some robust confidence.", "histories": [["v1", "Thu, 10 Jan 2013 16:25:16 GMT  (914kb)", "http://arxiv.org/abs/1301.2293v1", "Appears in Proceedings of the Seventeenth Conference on Uncertainty in Artificial Intelligence (UAI2001)"]], "COMMENTS": "Appears in Proceedings of the Seventeenth Conference on Uncertainty in Artificial Intelligence (UAI2001)", "reviews": [], "SUBJECTS": "cs.AI", "authors": ["pedrito maynard-reid ii", "urszula chajewska"], "accepted": false, "id": "1301.2293"}, "pdf": {"name": "1301.2293.pdf", "metadata": {"source": "CRF", "title": "Aggregating Learned Probabilistic Beliefs", "authors": ["Pedrito Maynard-Reid"], "emails": ["urszula@cs.stanford.edu"], "sections": null, "references": [{"title": "Theory refinement on bayesian net\u00ad", "author": ["W. Buntine"], "venue": null, "citeRegEx": "Buntine.,? \\Q1991\\E", "shortCiteRegEx": "Buntine.", "year": 1991}, {"title": "A normative examination of ensemble learning algorithms", "author": ["D.M. Pennock", "P.E. Horvitz"], "venue": "In Proc. ICML'OO,", "citeRegEx": "Pennock and Horvitz.,? \\Q2000\\E", "shortCiteRegEx": "Pennock and Horvitz.", "year": 2000}], "referenceMentions": [], "year": 2011, "abstractText": "We consider the task of aggregating beliefs of sev\u00ad eral experts. We assume that these beliefs are rep\u00ad resented as probability distributions. We argue that the evaluation of any aggregation technique depends on the semantic context of this task. We propose a framework, in which we assume that nature generates samples from a 'true' distribution and different experts form their beliefs based on the subsets of the data they have a chance to observe. Naturally, the optimal ag\u00ad gregate distribution would be the one learned from the combined sample sets. Such a formulation leads to a natural way to measure the accuracy of the aggregation mechanism. We show that the well-known aggregation operator LinOP is ideally suited for that task. We propose a LinOP-based learning algorithm, inspired by the techniques developed for Bayesian learning, which aggregates the experts' distributions represented as Bayesian networks. We show experimentally that this algorithm performs well in practice.", "creator": "pdftk 1.41 - www.pdftk.com"}}}