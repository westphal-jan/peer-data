{"id": "1301.3224", "review": {"conference": "arxiv", "VERSION": "v1", "DATE_OF_SUBMISSION": "15-Jan-2013", "title": "Efficient Learning of Domain-invariant Image Representations", "abstract": "we present an implement that learns representations which explicitly allows maximum unnecessary diversity and often seeks be reasonably realized as linear classifiers. specifically, we form a linear set that maps features from their transition ( learners ) domain to second source ( training ) domain as part of computational decision classifier. we employ both the transformed models define parameters appropriately, lastly introduce an efficient cost function based its misclassification loss. our scheme combines emerging disciplines previously unavailable making a new algorithm : scale - scaled adaptation through selective learning, attempts to map across compact feature spaces, and smoothing against large datasets. collaborators produce experiments relating existing image datasets that show greatest accuracy and computational success compared from two approaches.", "histories": [["v1", "Tue, 15 Jan 2013 04:39:32 GMT  (177kb,D)", "https://arxiv.org/abs/1301.3224v1", null], ["v2", "Thu, 17 Jan 2013 01:36:31 GMT  (179kb,D)", "http://arxiv.org/abs/1301.3224v2", null], ["v3", "Mon, 11 Mar 2013 05:09:12 GMT  (179kb,D)", "http://arxiv.org/abs/1301.3224v3", null], ["v4", "Sun, 17 Mar 2013 19:39:37 GMT  (179kb,D)", "http://arxiv.org/abs/1301.3224v4", null], ["v5", "Tue, 9 Apr 2013 01:10:49 GMT  (179kb,D)", "http://arxiv.org/abs/1301.3224v5", null]], "reviews": [], "SUBJECTS": "cs.LG", "authors": ["judy hoffman", "erik rodner", "jeff donahue", "trevor darrell", "kate saenko"], "accepted": false, "id": "1301.3224"}, "pdf": {"name": "1301.3224.pdf", "metadata": {"source": "CRF", "title": "Efficient Learning of Domain-invariant Image Representations", "authors": ["Judy Hoffman", "Erik Rodner", "Jeff Donahue"], "emails": ["jhoffman@eecs.berkeley.edu", "erik.rodner@gmail.com", "jdonahue@eecs.berkeley.edu", "trevor@eecs.berkeley.edu", "saenko@cs.uml.edu"], "sections": [{"heading": "1 Introduction", "text": "We address the problem of learning domain-invariant image representations for multi-class classifiers. The ideal image representation often depends not just on the task but also on the domain. Recent studies have demonstrated a significant degradation in the performance of state-of-the-art image classifiers when input feature distributions change due to different image sensors and noise conditions [1], pose changes [2], a shift from commercial to consumer video [3, 4], and, more generally, training datasets biased by the way in which they were collected [5]. Learning adaptive representations for linear classifiers is particularly interesting as they are efficient and prevalent in vision applications, with fast linear SVMs forming the core of some of the most popular object detection methods [6, 7].\nPrevious work proposed to adapt linear SVMs [8, 9, 10], learning a perturbation of the source hyperplane by minimizing the classification error on labeled target examples for each binary task. These perturbations can be thought of as new feature representations that correct for the domain change. The recent HFA method [11] learns both the perturbed classifier and a latent domain-invariant feature representation, allowing domains to have heterogeneous features with different dimensionalities. However, existing SVM-based methods are limited to learning a separate representation for each binary problem and cannot transfer a common, class-independent component of the shift (such as global lighting change) to unlabeled categories, as illustrated in Figure 1. Additionally, the HFA algorithm cannot be solved in linear space and therefore scales poorly to large datasets.\nar X\niv :1\n30 1.\n32 24\nv5 [\ncs .L\nRecently proposed feature adaptation methods [1, 2, 12, 13, 14, 15] offer a solution by learning a category-independent feature transform that maps target features into the source, pooling all training labels across categories. This enables multi-class adaptation, i.e. transferring the categoryindependent component of the domain-invariant representation to unlabeled categories. For example, a map learned on the labeled \u201ctriangle\u201d class in Figure 1 can also be used to map the unlabeled \u201cstar\u201d class to the source domain. An additional advantage of the asymmetric transform method ARC-t [12] over metric learning [1] or the recently proposed Geodesic Flow Kernel (GFK) [15], is that, like HFA [11], ARC-t can map between heterogeneous feature spaces. However, ARC-t has two major limitations: First, the feature learning does not optimize the objective function of a strong, discriminative classifier directly; rather, it maximizes some notion of similarity between the transformed target points and points in the source. Second, it does not scale well to domains with large numbers of points due to the high number of constraints, which is proportional to the product of the number of labeled data points in the source and target.\nIn this paper, we present a novel technique that combines the desirable aspects of recent methods in a single algorithm, which we call Max-Margin Domain Transforms, or MMDT for short. MMDT uses an asymmetric (non-square) transform W to map target features x to a new representation Wx maximally aligned with the source, learning the transform jointly on all categories for which target labels are available (Figure 1(d)). MMDT provides a way to adapt max-margin classifiers in a multi-class manner, by learning a shared component of the domain shift as captured by the feature transformation W . Additionally, MMDT can be optimized quickly in linear space, making it a feasible solution for problem settings with a large amount of training data.\nThe key idea behind our approach is to simultaneously learn both the projection of the target features into the source domain and the classifier parameters themselves, using the same classification loss to jointly optimize both.\nThus our method learns a feature representation that combines the strengths of max-margin learning with the flexibility of the feature transform. Because it operates over the input features, it can generalize the learned shift in a way that parameter-based methods cannot. On the other hand, it overcomes the two flaws of the ARC-t method: by optimizing the classification loss directly in the transform learning framework, it can achieve higher accuracy; furthermore, replacing similarity constraints with more efficient hyperplane constraints significantly reduces the training time of the algorithm and learning a transformation directly from target to source allows optimization in linear space.\nThe main contributions of our paper can be summarized as follows (also see Table 1):\n\u2022 Experiments show that MMDT in linear feature space outperforms competing methods in terms of multi-class accuracy even compared to previous kernelized methods.\n\u2022 MMDT learns a representation via an asymmetric category independent transform. Therefore, it can adapt features even when the target domain does not have any labeled examples for some categories and when the target and source features are not equivalent.\n\u2022 The optimization of MMDT is scalable to large datasets because the number of constraints to optimize is linear in the number of training data points and because it can be optimized in linear feature space.\n\u2022 Our final iterative solution can be solved using standard QP packages, making MMDT easy to implement."}, {"heading": "2 Related Work", "text": "Domain adaptation, or covariate shift, is a fundamental problem in machine learning, and has attracted a lot of attention in the machine learning and natural language community, e.g. [16, 17, 18, 19] (see [20] for a comprehensive overview). It is related to multi-task learning but differs from it in the following way: in domain adaptation problems, the distribution over the features p(X) varies across domains while the output labels Y remain the same; in multi-task learning or knowledge transfer, p(X) stays the same (single domain) while the output labels vary (see [20] for more details). In this paper, we perform multi-task learning across domains, i.e. both p(X) and the output labels Y can change between domains.\nDomain adaptation has been gaining considerable attention in the vision community. Several SVMbased approaches have been proposed for image domain adaptation, including: weighted combination of source and target SVMs and transductive SVMs applied to adaptation in [21]; the feature replication method of [17]; Adaptive SVM [8, 9], where the source model parameters are adapted by adding a perturbation function, and its successor PMT-SVM [10]; Domain Transfer SVM [3], which learns a target decision function while reducing the mismatch in the domain distributions; and a related method [4] based on multiple kernel learning. In the linear case, feature replication [17] can be shown to decompose the learned parameter into \u03b8 = \u03b8\u0302 + \u03b8\u2032, where \u03b8\u0302 is shared by all domains [22], in a similar fashion to adaptive SVMs.\nSeveral authors considered learning feature representations for unsupervised and transfer learning [23], and for domain adaptation [18, 24]. For visual domain adaptation, transform-based adaptation methods [1, 12, 13, 2, 14, 11] have recently been proposed. These methods attempt to learn a perturbation over the feature space rather than a class-specific perturbation over the model parameters, typically in the form of a transformation matrix/kernel. The most closely related are the ARC-t method [12], which learns a transformation that maximizes similarity constraints between points in the source and those projected from the target domain, and the recent HFA method [11], which learns a transformation both from the source and target into a common latent space, as well as the classifier parameters. Another related method is the recently proposed GFK [15], which computes a symmetric kernel between source and target points based on geodesic flow along a latent manifold. We will present a detailed comparison to these three methods in the next section."}, {"heading": "3 Max-Margin Domain Transforms", "text": "We propose a novel method for multi-task domain adaptation of linear SVMs by learning a target feature representation. Denote the normal to the affine hyperplane associated with the k\u2019th binary SVM as \u03b8k, k = 1, ...,K, and the offset of that hyperplane from the origin as bk. Intuitively, we would like to learn a new target feature representation that is shared across multiple categories. We propose to do so by estimating a transformation W of the input features, or, equivalently, a transformation WT of the source hyperplane parameters \u03b8k. Let xs1, . . . , x s nS denote the training points in the source domain (DS), with labels ys1, . . . , ysnS . Let x t 1, . . . , x t nT denote the labeled\npoints in the target domain (DT ), with labels yt1, . . . , ytnT . Thus our goal is to jointly learn 1) affine hyperplanes that separate the classes in the common domain consisting of the source domain and target points projected to the source and 2) the new feature representation of the target domain determined by the transformationW mapping points from the target domain into the source domain. The transformation should have the property that it projects the target points onto the correct side of each source hyperplane.\nFor simplicity of presentation, we first show the optimization problem for a binary problem (dropping k) with no slack variables. Our objective is as follows:\nmin W,\u03b8,b\n1 2 ||W ||2F + 1 2 ||\u03b8||22 (1)\ns.t. ysi ([ xsi 1 ]T [ \u03b8 b ]) \u2265 1 \u2200i \u2208 DS (2)\nyti ([ xti 1 ]T WT [ \u03b8 b ]) \u2265 1 \u2200i \u2208 DT (3)\nNote that this can be easily extended to the multi-class case by simply adding a sum over the regularizers on all \u03b8k parameters and pooling the constraints for all categories. The objective function, written as in Equations (1)-(3), is not a convex problem and so is both hard to optimize and is not guaranteed to have a global solution. Therefore, a standard way to solve this problem is to do alternating minimization on the parameters, in our case W and (\u03b8, b). We can effectively do this because when each parameter vector is fixed, the resulting optimization problem is convex.\nWe begin by re-writing Equations (1)-(3) for the more general problem with soft constraints and K categories. Let us denote the hinge loss as: L(y, x, \u03b8) = max{0, 1 \u2212 \u03b4(y, k) \u00b7 xT \u03b8}. We define a cost function\nJ(W, \u03b8k, bk) = 1\n2 ||W ||2F + K\u2211 k=1 [ 1 2 ||\u03b8k||22 (4)\n+CS nS\u2211 i=1 L ( ysi , [ xsi 1 ] , [ \u03b8k bk ]) +CT nT\u2211 i=1 L ( yti ,W \u00b7 [ xti 1 ] , [ \u03b8k bk ])] where the constant CS penalizes the source classification error and CT penalizes the target adapta-\ntion error. Finally, we define our objective function with soft constraints as follows:\nmin W,\u03b8k,bk J(W, \u03b8k, bk) (5)\nTo solve the above optimization problem we perform coordinate descent on W and (\u03b8, b).\n1. Set iteration j = 0, W (j) = 0.\n2. Solve the sub-problem (\u03b8(j+1)k , b (j+1) k ) = argmin\u03b8k,bk J(W (j), \u03b8k, bk) by solving:\nmin \u03b8,b K\u2211 k=1 [ 1 2 ||\u03b8k||22 + CS nS\u2211 i=1 L ( ysi , [ xsi 1 ] , [ \u03b8k; bk ]) +CT nT\u2211 i=1 L ( yti ,W (j) \u00b7 [ xti 1 ] , [ \u03b8k bk ])] Notice, this corresponds to the standard SVM objective function, except that the target points are first projected into the source using W (j). Therefore, we can solve this intermediate problem using a standard SVM solver package.\n3. Solve the subproblem W (j+1) = argminW J(W, \u03b8(j+1), b(j+1)) by solving\nmin W\n1 2 ||W ||2F + CT K\u2211 k=1 nT\u2211 i=1 L ( yti ,W \u00b7 [ xti 1 ] , [ \u03b8 (j+1) k b (j+1) k ]) and increment j. This optimization sub-problem is convex and is in a form that a standard QP optimization package can solve.\n4. Iterate steps 2 & 3 until convergence.\nIt is straightforward to show that both stages (2) and (3) cannot increase the global cost function J(W, \u03b8, b). Therefore, this algorithm is guaranteed to converge to a local optimum. A proof is included in the supplemental material.\nIt is important to note that since both steps of our iterative algorithm can be solved using standard QP solvers, the algorithm can be easily implemented. Additionally, since the constraints in our algorithm grow linearly with the number of training points and it can be solved in linear feature space, the optimization can be solved efficiently even as the number of training points grows.\nRelation to existing work: We now analyze the proposed algorithm in the context of the previous feature transform methods ARC-t [12], HFA [11] and GFK [15]. ARC-t introduced similarity-based constraints to learn a mapping similar to that in step 3 in our algorithm. This approach creates a constraint for each labeled point xsi in the source and labeled point x t i in the target, and then learns a transformation W that satisfies constraints of the form (xsi ) TWxti > u if the labels of x s i and x t i are the same, and (xsi ) TWxti < l if the labels are different, for some constants u, l.\nThe ARC-t formulation has two distinct limitations that our method overcomes. First, it must solve nS \u00b7nT constraints, whereas our formulation only needs to solveK \u00b7nT constraints, for aK category problem. In general, our method scales to much larger source domains than with ARC-t. The second benefit of our max-margin transformation learning approach is that the transformation learned using the max-margin constraints is learned jointly with the classifier, and explicitly seeks to optimize the final SVM classifier objective. While ARC-t\u2019s similarity-based constraints seek to map points of the same category arbitrarily close to one another, followed by a separate classifier learning step, we seek simply to project the target points onto the correct side of the learned hyperplane, leading to better classification performance.\nThe HFA formulation also takes advantage of the max-margin framework to directly optimize the classification objective while learning transformations. HFA learns the classifier and transformations to a common latent feature representation between the source and target. However, HFA is formulated to solve a binary problem so a new feature transformation must be learned for each category. Therefore, unlike MMDT, HFA cannot learn a representation that generalizes to novel target categories. Additionally, due to the difficulty of defining the dimension of the latent feature representation directly, the authors optimize with respect to a larger combined transformation matrix and a relaxed constraint. This transformation matrix becomes too large when the feature dimensions in source and target are large so the HFA must usually be solved in kernel space. This can make the method slow and cause it to scale poorly with the number of training examples. In contrast, our method can be efficiently solved in linear feature space which makes it fast and potentially more scalable.\nFinally, GFK [15] formulates a kernelized representation of the data that is equivalent to computing the dot product in infinitely many subspaces along the geodesic flow between the source and target domain subspaces. The kernel is defined by the authors to be symmetric and so can not handle source and target domains of different initial dimension. Additionally, GFK does not directly optimize a classification objective. In contrast, our method, MMDT, can handle source and target domains of different feature dimensions via an asymmetric W , as well as directly optimizes the classification objective."}, {"heading": "4 Experiments on Image Datasets", "text": "We now present experiments using the Office [1], Caltech256 [25] and Bing [21] datasets to evaluate our algorithm according to the following four criteria. 1) Using a subset of the Office and Caltech256 datasets we evaluate multi-class accuracy performance in a standard supervised domain adaptation setting, where all categories have a small number of labeled examples in the target. 2) Using the full Office dataset we evaluate multi-class accuracy for the supervised domain adaptation setting where the source and target have different feature dimensions. 3) Using the full Office dataset we evaluate multi-class accuracy in the multi-task domain adaptation setting with novel target categories at test time. 4) Using the Bing dataset we assess the ability to scale to larger datasets by analyzing timing performance.\nOffice Dataset The Office dataset is a collection of images that provides three distinct domains: amazon, webcam, and dslr. The dataset has 31 categories consisting of common office objects such as chairs, backpacks and keyboards. The amazon domain contains product images (from amazon.com) containing a single object, centered, and usually on a white background. The webcam and dslr domains contain images taken in\u201cthe wild\u201d using a webcam or a dslr camera, respectively. They are taken in an office setting and so have different lighting variation and background changes (see Figure 1 for some examples.) We use the SURF-BoW image features provided by the authors [1]. More details on how these features were computed can be found in [1]. The available features are vector quantized to 800 dimensions for all domains and additionally for the dslr domain there are 600 dimensional features available (we denote this as dslr-600).\nOffice + Caltech256 Dataset This dataset consists of the 10 common categories shared by the Office and Caltech256 datasets. To better compare to previously reported performance, we use the features provided by [15], which are also SURF-BoW 800 dimensional features.\nBing Dataset To demonstrate the effect that constraint set size has on run-time performance, we use the Bing dataset from [21], which has a larger number of images in each domain than Office. The source domain has images from the Bing search engine and the target domain is from the Caltech256 benchmark. We run experiments using the first 20 categories and set the number of source examples per category to be 50. We use the train/test split from [21] and then vary the number of labeled target examples available from 5 to 25.\nBaselines We use the following baselines as a comparison in the experiments where applicable.1\n\u2022 svms: A support vector machine using source training data. \u2022 svmt: A support vector machine using target training data. \u2022 arc-t: A category general feature transform method proposed by [12]. We implement the\ntransform learning and then apply both a KNN classifier (as originally proposed) and an SVM classifier.\n\u2022 hfa: A max-margin transform approach that learns a latent common space between source and target as well as a classifier that can be applied to points in that common space [11].\n\u2022 gfk: The geodesic flow kernel [15] applied to all source and target data (including test data). Following [15], we use a 1-nearest neighbor classifier with the kernel.\n1We used the LIBSVM package [26] for kernelized methods and Liblinear [27] package for linear methods.\nStandard Domain Adaptation Experiment For our first experiment, we use the Office+Caltech256 domain adaptation benchmark dataset to evaluate multi-class accuracy in the standard domain adaptation setting where a few labeled examples are available for all categories in the target domain. We follow the setup of [1] and [15]: 20 training examples for amazon source (8 for all other domains as source) and 3 labeled examples per category for the target domain. We created 20 random train/test splits and averaged results across them.\nThe multi-class accuracy for each domain pair is shown in Table 2. Our method produced the highest multi-class accuracy for 9 out of 12 of the domain shifts and competitively on the other 3 shifts. This experiment demonstrates that our method achieves a high recognition performance and is able to outperform the most recent domain adaptation algorithms. Our method especially stands out in the settings where the domains are initially very different. The most similar domains in this dataset are webcam and dslr and we see that our algorithm does not perform as well on those two shifts as gfk. This fits with our intuition since gfk is a 1-nearest neighbor approach and so is more suitable when the domains are initially similar.\nAdditionally, an important observation is that our linear method on average outperforms all the baselines, even though they each learn a non-linear transformation. Asymmetric Transform Experiment Next, we analyze the effectiveness of our asymmetric transform learning by experimenting with the source and target having different feature dimensions. We use the same experimental setup as previously, but use the Office dataset and the alternate representation for the dslr domain that is 600-dimensional (denoted as dslr-600). We compare against svmt, arc-t and hfa, the baselines that can handle this scenario. The results are shown in Table 3. Again, we find that our method can effectively learn a feature representation for the target domain that optimizes the final classification objective. Generalizing to Novel Categories Experiment We next consider the setting of practical importance where labeled target examples are not available for all objects. Recall that this is a setting that many category specific adaptation methods cannot generalize to, including hfa [11]. Therefore, we compare our results for this setting to the arc-t [12] method which learns a category independent feature transform and the gfk [15] method which learns a category independent kernel to compare the domains. Following the experimental setup of [12], we use the full Office dataset and allow 20 labeled examples per category in the source for amazon and 10 labeled examples for the first 15 object categories in the target (dslr). For the webcam\u2192dslr shift, we use 8 labeled examples per category in the source for webcam and 4 labeled examples for the first 15 object categories in the target dslr.\nThe experimental results for the domain shift of webcam\u2192dslr are evaluated and shown in Table 4; MMDT outperforms the baselines for the amazon\u2192dslr shift and offers adaptive benefit over svms for the shift from webcam to dslr. As in the first experiment, both arc-t and gfk use nearest neighbor classifiers on a learned kernel are more suitable to the shift between webcam and dslr, which are initially very similar.\nScaling to Larger Datasets Experiment With our last experiment we show that our method not only offers high accuracy performance it also scales well with an increasing dataset size. Specifi-\n5 10 15 2030\n35\n40\n45\n50\n55\nNumber of Labeled Target Examples\nM ul\ntic la\nss a\ncc ur\nac y\ncally, the number of constraints our algorithm optimizes scales linearly with the number of training points. Conversely, the number of constraints that need to be optimized for the arc-t baseline is quadratic in the number of training points.\nTo demonstrate the effect that constraint set size has on run-time performance, we use the Bing [21] dataset, which has a larger number of images in each domain than Office. The source domain has images from the Bing search engine and the target domain is from the Caltech256 benchmark. We run experiments using the first 20 categories and set the number of source examples per category to be 50. We use the train/test split from [21] and then vary the number of labeled target examples available from 5 to 20. The left-hand plot in Figure 2 presents multi-class accuracy for this setup. Additionally, the training time of our method (run to convergence) and that of the baselines is shown on the right-hand plot.\nOur mmdt method provides a considerable improvement over all the baselines in terms of multiclass accuracy. It is also considerably faster than all but the gfk method. An important point to note is that both our method and arc-t scale approximately linearly with the number of target training points which is empirical verification for our claims. Note that hfa and gfk do not vary significantly as the number of target training points increases. However, for hfa the main bottleneck time is consumed by a distance computation between each pair of training points. Therefore, since there are many more source training points than target, adding a few more target points does not significantly increase the overall time spent for this experiment, but would present a problem as the size of the dataset grew in general."}, {"heading": "5 Conclusion", "text": "In this paper, we presented a feature learning technique for domain adaptation that combines the ability of feature transform-based methods to perform multi-task adaptation with the performance benefits of directly adapting classifier parameters.\nWe validated the computational efficiency and effectiveness of our method using two standard benchmarks used for image domain adaptation. Our experiments show that 1) our method is a competitive domain adaptation algorithm able to outperform previous methods, 2) is successfully able to generalize to novel target categories at test time, and 3) can learn asymmetric transformations. In addition, these benefits are offered through a framework that is scalable to larger datasets and achieves higher classification accuracy than previous approaches.\nSo far we have focused on linear transforms because of its speed and scalability; however, our method can also be kernelized to include nonlinear transforms. In future work, we would like to explore the kernelized version of our algorithm and especially experiment with the geodesic flow kernel as input to our algorithm.\nAcknowledgements: This work was supported by NSF grants IIS-1116411 and IIS-1212798, DARPA, and the Toyota Corporation."}], "references": [{"title": "Adapting visual category models to new domains", "author": ["K. Saenko", "B. Kulis", "M. Fritz", "T. Darrell"], "venue": "In Proc. ECCV,", "citeRegEx": "1", "shortCiteRegEx": "1", "year": 2010}, {"title": "Learning to recognize activities from the wrong view point", "author": ["A. Farhadi", "M.K. Tabrizi"], "venue": "In Proc. ECCV,", "citeRegEx": "2", "shortCiteRegEx": "2", "year": 2008}, {"title": "Domain transfer svm for video concept detection", "author": ["L. Duan", "I.W. Tsang", "D. Xu", "S.J. Maybank"], "venue": "In CVPR,", "citeRegEx": "3", "shortCiteRegEx": "3", "year": 2009}, {"title": "Visual event recognition in videos by learning from web data", "author": ["L. Duan", "D. Xu", "I. Tsang", "J. Luo"], "venue": "In Proc. CVPR,", "citeRegEx": "4", "shortCiteRegEx": "4", "year": 2010}, {"title": "Unbiased look at dataset bias", "author": ["A. Torralba", "A. Efros"], "venue": "In Proc. CVPR,", "citeRegEx": "5", "shortCiteRegEx": "5", "year": 2011}, {"title": "Object detection with discriminatively trained part based models", "author": ["D. McAllester P. Felzenszwalb", "R. Girshick", "D. Ramanan"], "venue": "IEEE Transactions on Pattern Analysis and Machine Intelligence,", "citeRegEx": "6", "shortCiteRegEx": "6", "year": 2010}, {"title": "Poselets: Body part detectors trained using 3d human pose annotations", "author": ["Lubomir Bourdev", "Jitendra Malik"], "venue": "In Proc. ICCV,", "citeRegEx": "7", "shortCiteRegEx": "7", "year": 2009}, {"title": "Adapting svm classifiers to data with shifted distributions", "author": ["J. Yang", "R. Yan", "A. Hauptmann"], "venue": "In ICDM Workshops,", "citeRegEx": "8", "shortCiteRegEx": "8", "year": 2007}, {"title": "Regularized adaptation: Theory, algorithms and applications", "author": ["X. Li"], "venue": "In PhD thesis,", "citeRegEx": "9", "shortCiteRegEx": "9", "year": 2007}, {"title": "Tabula rasa: Model transfer for object category detection", "author": ["Y. Aytar", "A. Zisserman"], "venue": "In Proc. ICCV,", "citeRegEx": "10", "shortCiteRegEx": "10", "year": 2011}, {"title": "Learning with augmented features for heterogeneous domain adaptation", "author": ["Lixin Duan", "Dong Xu", "Ivor W. Tsang"], "venue": "In Proc. ICML,", "citeRegEx": "11", "shortCiteRegEx": "11", "year": 2012}, {"title": "What you saw is not what you get: Domain adaptation using asymmetric kernel transforms", "author": ["B. Kulis", "K. Saenko", "T. Darrell"], "venue": "In Proc. CVPR,", "citeRegEx": "12", "shortCiteRegEx": "12", "year": 2011}, {"title": "Domain adaptation for object recognition: An unsupervised approach", "author": ["R. Gopalan", "R. Li", "R. Chellappa"], "venue": "In Proc. ICCV,", "citeRegEx": "13", "shortCiteRegEx": "13", "year": 2011}, {"title": "Translated learning: Transfer learning across different feature spaces", "author": ["W. Dai", "Y. Chen", "G. Xue", "Q. Yang", "Y. Yu"], "venue": "In Proc. NIPS,", "citeRegEx": "14", "shortCiteRegEx": "14", "year": 2008}, {"title": "Geodesic flow kernel for unsupervised domain adaptation", "author": ["B. Gong", "Y. Shi", "F. Sha", "K. Grauman"], "venue": "In Proc. CVPR,", "citeRegEx": "15", "shortCiteRegEx": "15", "year": 2012}, {"title": "Biographies, bollywood, boom-boxes and blenders: Domain adaptation for sentiment classification", "author": ["J. Blitzer", "M. Dredze", "F. Pereira"], "venue": null, "citeRegEx": "16", "shortCiteRegEx": "16", "year": 2007}, {"title": "Frustratingly easy domain adaptation", "author": ["H. Daume III"], "venue": "In Proc. ACL,", "citeRegEx": "17", "shortCiteRegEx": "17", "year": 2007}, {"title": "Analysis of representations for domain adaptation", "author": ["S. Ben-david", "J. Blitzer", "K. Crammer", "O. Pereira"], "venue": null, "citeRegEx": "18", "shortCiteRegEx": "18", "year": 2007}, {"title": "Instance weighting for domain adaptation in nlp", "author": ["J. Jiang", "C.X. Zhai"], "venue": "In Proceedings of the 45th Annual Meeting of the Association of Computational Linguistics,", "citeRegEx": "19", "shortCiteRegEx": "19", "year": 2007}, {"title": "Exploiting weakly-labeled web images to improve object classification: a domain adaptation approach", "author": ["A. Bergamo", "L. Torresani"], "venue": "In Proc. NIPS,", "citeRegEx": "21", "shortCiteRegEx": "21", "year": 2010}, {"title": "Cross-domain learning methods for high-level visual concept classification", "author": ["W. Jiang", "E. Zavesky", "S. Chang", "A. Loui"], "venue": "In ICIP,", "citeRegEx": "22", "shortCiteRegEx": "22", "year": 2008}, {"title": "Deep learning of representations for unsupervised and transfer learning", "author": ["Yoshua Bengio"], "venue": "Journal of Machine Learning Research - Proceedings Track,", "citeRegEx": "23", "shortCiteRegEx": "23", "year": 2012}, {"title": "Domain adaptation with structural correspondence learning", "author": ["John Blitzer", "Ryan McDonald", "Fernando Pereira"], "venue": "In Proceedings of the 2006 Conference on Empirical Methods in Natural Language Processing,", "citeRegEx": "24", "shortCiteRegEx": "24", "year": 2006}, {"title": "Caltech-256 object category dataset", "author": ["G. Griffin", "A. Holub", "P. Perona"], "venue": "Technical Report 7694, California Institute of Technology,", "citeRegEx": "25", "shortCiteRegEx": "25", "year": 2007}, {"title": "LIBSVM: A library for support vector machines", "author": ["Chih-Chung Chang", "Chih-Jen Lin"], "venue": "ACM Transactions on Intelligent Systems and Technology,", "citeRegEx": "26", "shortCiteRegEx": "26", "year": 2011}, {"title": "LIBLINEAR: A library for large linear classification", "author": ["Rong-En Fan", "Kai-Wei Chang", "Cho-Jui Hsieh", "Xiang-Rui Wang", "Chih-Jen Lin"], "venue": "Journal of Machine Learning Research,", "citeRegEx": "27", "shortCiteRegEx": "27", "year": 2008}], "referenceMentions": [{"referenceID": 0, "context": "Recent studies have demonstrated a significant degradation in the performance of state-of-the-art image classifiers when input feature distributions change due to different image sensors and noise conditions [1], pose changes [2], a shift from commercial to consumer video [3, 4], and, more generally, training datasets biased by the way in which they were collected [5].", "startOffset": 208, "endOffset": 211}, {"referenceID": 1, "context": "Recent studies have demonstrated a significant degradation in the performance of state-of-the-art image classifiers when input feature distributions change due to different image sensors and noise conditions [1], pose changes [2], a shift from commercial to consumer video [3, 4], and, more generally, training datasets biased by the way in which they were collected [5].", "startOffset": 226, "endOffset": 229}, {"referenceID": 2, "context": "Recent studies have demonstrated a significant degradation in the performance of state-of-the-art image classifiers when input feature distributions change due to different image sensors and noise conditions [1], pose changes [2], a shift from commercial to consumer video [3, 4], and, more generally, training datasets biased by the way in which they were collected [5].", "startOffset": 273, "endOffset": 279}, {"referenceID": 3, "context": "Recent studies have demonstrated a significant degradation in the performance of state-of-the-art image classifiers when input feature distributions change due to different image sensors and noise conditions [1], pose changes [2], a shift from commercial to consumer video [3, 4], and, more generally, training datasets biased by the way in which they were collected [5].", "startOffset": 273, "endOffset": 279}, {"referenceID": 4, "context": "Recent studies have demonstrated a significant degradation in the performance of state-of-the-art image classifiers when input feature distributions change due to different image sensors and noise conditions [1], pose changes [2], a shift from commercial to consumer video [3, 4], and, more generally, training datasets biased by the way in which they were collected [5].", "startOffset": 367, "endOffset": 370}, {"referenceID": 5, "context": "Learning adaptive representations for linear classifiers is particularly interesting as they are efficient and prevalent in vision applications, with fast linear SVMs forming the core of some of the most popular object detection methods [6, 7].", "startOffset": 237, "endOffset": 243}, {"referenceID": 6, "context": "Learning adaptive representations for linear classifiers is particularly interesting as they are efficient and prevalent in vision applications, with fast linear SVMs forming the core of some of the most popular object detection methods [6, 7].", "startOffset": 237, "endOffset": 243}, {"referenceID": 7, "context": "Previous work proposed to adapt linear SVMs [8, 9, 10], learning a perturbation of the source hyperplane by minimizing the classification error on labeled target examples for each binary task.", "startOffset": 44, "endOffset": 54}, {"referenceID": 8, "context": "Previous work proposed to adapt linear SVMs [8, 9, 10], learning a perturbation of the source hyperplane by minimizing the classification error on labeled target examples for each binary task.", "startOffset": 44, "endOffset": 54}, {"referenceID": 9, "context": "Previous work proposed to adapt linear SVMs [8, 9, 10], learning a perturbation of the source hyperplane by minimizing the classification error on labeled target examples for each binary task.", "startOffset": 44, "endOffset": 54}, {"referenceID": 10, "context": "The recent HFA method [11] learns both the perturbed classifier and a latent domain-invariant feature representation, allowing domains to have heterogeneous features with different dimensionalities.", "startOffset": 22, "endOffset": 26}, {"referenceID": 0, "context": "Recently proposed feature adaptation methods [1, 2, 12, 13, 14, 15] offer a solution by learning a category-independent feature transform that maps target features into the source, pooling all training labels across categories.", "startOffset": 45, "endOffset": 67}, {"referenceID": 1, "context": "Recently proposed feature adaptation methods [1, 2, 12, 13, 14, 15] offer a solution by learning a category-independent feature transform that maps target features into the source, pooling all training labels across categories.", "startOffset": 45, "endOffset": 67}, {"referenceID": 11, "context": "Recently proposed feature adaptation methods [1, 2, 12, 13, 14, 15] offer a solution by learning a category-independent feature transform that maps target features into the source, pooling all training labels across categories.", "startOffset": 45, "endOffset": 67}, {"referenceID": 12, "context": "Recently proposed feature adaptation methods [1, 2, 12, 13, 14, 15] offer a solution by learning a category-independent feature transform that maps target features into the source, pooling all training labels across categories.", "startOffset": 45, "endOffset": 67}, {"referenceID": 13, "context": "Recently proposed feature adaptation methods [1, 2, 12, 13, 14, 15] offer a solution by learning a category-independent feature transform that maps target features into the source, pooling all training labels across categories.", "startOffset": 45, "endOffset": 67}, {"referenceID": 14, "context": "Recently proposed feature adaptation methods [1, 2, 12, 13, 14, 15] offer a solution by learning a category-independent feature transform that maps target features into the source, pooling all training labels across categories.", "startOffset": 45, "endOffset": 67}, {"referenceID": 11, "context": "An additional advantage of the asymmetric transform method ARC-t [12] over metric learning [1] or the recently proposed Geodesic Flow Kernel (GFK) [15], is that, like HFA [11], ARC-t can map between heterogeneous feature spaces.", "startOffset": 65, "endOffset": 69}, {"referenceID": 0, "context": "An additional advantage of the asymmetric transform method ARC-t [12] over metric learning [1] or the recently proposed Geodesic Flow Kernel (GFK) [15], is that, like HFA [11], ARC-t can map between heterogeneous feature spaces.", "startOffset": 91, "endOffset": 94}, {"referenceID": 14, "context": "An additional advantage of the asymmetric transform method ARC-t [12] over metric learning [1] or the recently proposed Geodesic Flow Kernel (GFK) [15], is that, like HFA [11], ARC-t can map between heterogeneous feature spaces.", "startOffset": 147, "endOffset": 151}, {"referenceID": 10, "context": "An additional advantage of the asymmetric transform method ARC-t [12] over metric learning [1] or the recently proposed Geodesic Flow Kernel (GFK) [15], is that, like HFA [11], ARC-t can map between heterogeneous feature spaces.", "startOffset": 171, "endOffset": 175}, {"referenceID": 11, "context": "ARC-t [12] HFA [11] GFK [15] MMDT (ours) multi-class yes no yes yes large datasets no no yes yes heterogeneous features yes yes no yes optimize max-margin objective no yes no yes", "startOffset": 6, "endOffset": 10}, {"referenceID": 10, "context": "ARC-t [12] HFA [11] GFK [15] MMDT (ours) multi-class yes no yes yes large datasets no no yes yes heterogeneous features yes yes no yes optimize max-margin objective no yes no yes", "startOffset": 15, "endOffset": 19}, {"referenceID": 14, "context": "ARC-t [12] HFA [11] GFK [15] MMDT (ours) multi-class yes no yes yes large datasets no no yes yes heterogeneous features yes yes no yes optimize max-margin objective no yes no yes", "startOffset": 24, "endOffset": 28}, {"referenceID": 15, "context": "[16, 17, 18, 19] (see [20] for a comprehensive overview).", "startOffset": 0, "endOffset": 16}, {"referenceID": 16, "context": "[16, 17, 18, 19] (see [20] for a comprehensive overview).", "startOffset": 0, "endOffset": 16}, {"referenceID": 17, "context": "[16, 17, 18, 19] (see [20] for a comprehensive overview).", "startOffset": 0, "endOffset": 16}, {"referenceID": 18, "context": "[16, 17, 18, 19] (see [20] for a comprehensive overview).", "startOffset": 0, "endOffset": 16}, {"referenceID": 19, "context": "Several SVMbased approaches have been proposed for image domain adaptation, including: weighted combination of source and target SVMs and transductive SVMs applied to adaptation in [21]; the feature replication method of [17]; Adaptive SVM [8, 9], where the source model parameters are adapted by adding a perturbation function, and its successor PMT-SVM [10]; Domain Transfer SVM [3], which learns a target decision function while reducing the mismatch in the domain distributions; and a related method [4] based on multiple kernel learning.", "startOffset": 181, "endOffset": 185}, {"referenceID": 16, "context": "Several SVMbased approaches have been proposed for image domain adaptation, including: weighted combination of source and target SVMs and transductive SVMs applied to adaptation in [21]; the feature replication method of [17]; Adaptive SVM [8, 9], where the source model parameters are adapted by adding a perturbation function, and its successor PMT-SVM [10]; Domain Transfer SVM [3], which learns a target decision function while reducing the mismatch in the domain distributions; and a related method [4] based on multiple kernel learning.", "startOffset": 221, "endOffset": 225}, {"referenceID": 7, "context": "Several SVMbased approaches have been proposed for image domain adaptation, including: weighted combination of source and target SVMs and transductive SVMs applied to adaptation in [21]; the feature replication method of [17]; Adaptive SVM [8, 9], where the source model parameters are adapted by adding a perturbation function, and its successor PMT-SVM [10]; Domain Transfer SVM [3], which learns a target decision function while reducing the mismatch in the domain distributions; and a related method [4] based on multiple kernel learning.", "startOffset": 240, "endOffset": 246}, {"referenceID": 8, "context": "Several SVMbased approaches have been proposed for image domain adaptation, including: weighted combination of source and target SVMs and transductive SVMs applied to adaptation in [21]; the feature replication method of [17]; Adaptive SVM [8, 9], where the source model parameters are adapted by adding a perturbation function, and its successor PMT-SVM [10]; Domain Transfer SVM [3], which learns a target decision function while reducing the mismatch in the domain distributions; and a related method [4] based on multiple kernel learning.", "startOffset": 240, "endOffset": 246}, {"referenceID": 9, "context": "Several SVMbased approaches have been proposed for image domain adaptation, including: weighted combination of source and target SVMs and transductive SVMs applied to adaptation in [21]; the feature replication method of [17]; Adaptive SVM [8, 9], where the source model parameters are adapted by adding a perturbation function, and its successor PMT-SVM [10]; Domain Transfer SVM [3], which learns a target decision function while reducing the mismatch in the domain distributions; and a related method [4] based on multiple kernel learning.", "startOffset": 355, "endOffset": 359}, {"referenceID": 2, "context": "Several SVMbased approaches have been proposed for image domain adaptation, including: weighted combination of source and target SVMs and transductive SVMs applied to adaptation in [21]; the feature replication method of [17]; Adaptive SVM [8, 9], where the source model parameters are adapted by adding a perturbation function, and its successor PMT-SVM [10]; Domain Transfer SVM [3], which learns a target decision function while reducing the mismatch in the domain distributions; and a related method [4] based on multiple kernel learning.", "startOffset": 381, "endOffset": 384}, {"referenceID": 3, "context": "Several SVMbased approaches have been proposed for image domain adaptation, including: weighted combination of source and target SVMs and transductive SVMs applied to adaptation in [21]; the feature replication method of [17]; Adaptive SVM [8, 9], where the source model parameters are adapted by adding a perturbation function, and its successor PMT-SVM [10]; Domain Transfer SVM [3], which learns a target decision function while reducing the mismatch in the domain distributions; and a related method [4] based on multiple kernel learning.", "startOffset": 504, "endOffset": 507}, {"referenceID": 16, "context": "In the linear case, feature replication [17] can be shown to decompose the learned parameter into \u03b8 = \u03b8\u0302 + \u03b8\u2032, where \u03b8\u0302 is shared by all domains [22], in a similar fashion to adaptive SVMs.", "startOffset": 40, "endOffset": 44}, {"referenceID": 20, "context": "In the linear case, feature replication [17] can be shown to decompose the learned parameter into \u03b8 = \u03b8\u0302 + \u03b8\u2032, where \u03b8\u0302 is shared by all domains [22], in a similar fashion to adaptive SVMs.", "startOffset": 145, "endOffset": 149}, {"referenceID": 21, "context": "Several authors considered learning feature representations for unsupervised and transfer learning [23], and for domain adaptation [18, 24].", "startOffset": 99, "endOffset": 103}, {"referenceID": 17, "context": "Several authors considered learning feature representations for unsupervised and transfer learning [23], and for domain adaptation [18, 24].", "startOffset": 131, "endOffset": 139}, {"referenceID": 22, "context": "Several authors considered learning feature representations for unsupervised and transfer learning [23], and for domain adaptation [18, 24].", "startOffset": 131, "endOffset": 139}, {"referenceID": 0, "context": "For visual domain adaptation, transform-based adaptation methods [1, 12, 13, 2, 14, 11] have recently been proposed.", "startOffset": 65, "endOffset": 87}, {"referenceID": 11, "context": "For visual domain adaptation, transform-based adaptation methods [1, 12, 13, 2, 14, 11] have recently been proposed.", "startOffset": 65, "endOffset": 87}, {"referenceID": 12, "context": "For visual domain adaptation, transform-based adaptation methods [1, 12, 13, 2, 14, 11] have recently been proposed.", "startOffset": 65, "endOffset": 87}, {"referenceID": 1, "context": "For visual domain adaptation, transform-based adaptation methods [1, 12, 13, 2, 14, 11] have recently been proposed.", "startOffset": 65, "endOffset": 87}, {"referenceID": 13, "context": "For visual domain adaptation, transform-based adaptation methods [1, 12, 13, 2, 14, 11] have recently been proposed.", "startOffset": 65, "endOffset": 87}, {"referenceID": 10, "context": "For visual domain adaptation, transform-based adaptation methods [1, 12, 13, 2, 14, 11] have recently been proposed.", "startOffset": 65, "endOffset": 87}, {"referenceID": 11, "context": "The most closely related are the ARC-t method [12], which learns a transformation that maximizes similarity constraints between points in the source and those projected from the target domain, and the recent HFA method [11], which learns a transformation both from the source and target into a common latent space, as well as the classifier parameters.", "startOffset": 46, "endOffset": 50}, {"referenceID": 10, "context": "The most closely related are the ARC-t method [12], which learns a transformation that maximizes similarity constraints between points in the source and those projected from the target domain, and the recent HFA method [11], which learns a transformation both from the source and target into a common latent space, as well as the classifier parameters.", "startOffset": 219, "endOffset": 223}, {"referenceID": 14, "context": "Another related method is the recently proposed GFK [15], which computes a symmetric kernel between source and target points based on geodesic flow along a latent manifold.", "startOffset": 52, "endOffset": 56}, {"referenceID": 11, "context": "Relation to existing work: We now analyze the proposed algorithm in the context of the previous feature transform methods ARC-t [12], HFA [11] and GFK [15].", "startOffset": 128, "endOffset": 132}, {"referenceID": 10, "context": "Relation to existing work: We now analyze the proposed algorithm in the context of the previous feature transform methods ARC-t [12], HFA [11] and GFK [15].", "startOffset": 138, "endOffset": 142}, {"referenceID": 14, "context": "Relation to existing work: We now analyze the proposed algorithm in the context of the previous feature transform methods ARC-t [12], HFA [11] and GFK [15].", "startOffset": 151, "endOffset": 155}, {"referenceID": 14, "context": "Finally, GFK [15] formulates a kernelized representation of the data that is equivalent to computing the dot product in infinitely many subspaces along the geodesic flow between the source and target domain subspaces.", "startOffset": 13, "endOffset": 17}, {"referenceID": 0, "context": "We now present experiments using the Office [1], Caltech256 [25] and Bing [21] datasets to evaluate our algorithm according to the following four criteria.", "startOffset": 44, "endOffset": 47}, {"referenceID": 23, "context": "We now present experiments using the Office [1], Caltech256 [25] and Bing [21] datasets to evaluate our algorithm according to the following four criteria.", "startOffset": 60, "endOffset": 64}, {"referenceID": 19, "context": "We now present experiments using the Office [1], Caltech256 [25] and Bing [21] datasets to evaluate our algorithm according to the following four criteria.", "startOffset": 74, "endOffset": 78}, {"referenceID": 11, "context": "svms svmt arct [12] hfa [11] gfk[15] mmdt (ours) a\u2192 w 33.", "startOffset": 15, "endOffset": 19}, {"referenceID": 10, "context": "svms svmt arct [12] hfa [11] gfk[15] mmdt (ours) a\u2192 w 33.", "startOffset": 24, "endOffset": 28}, {"referenceID": 14, "context": "svms svmt arct [12] hfa [11] gfk[15] mmdt (ours) a\u2192 w 33.", "startOffset": 32, "endOffset": 36}, {"referenceID": 0, "context": ") We use the SURF-BoW image features provided by the authors [1].", "startOffset": 61, "endOffset": 64}, {"referenceID": 0, "context": "More details on how these features were computed can be found in [1].", "startOffset": 65, "endOffset": 68}, {"referenceID": 14, "context": "To better compare to previously reported performance, we use the features provided by [15], which are also SURF-BoW 800 dimensional features.", "startOffset": 86, "endOffset": 90}, {"referenceID": 19, "context": "Bing Dataset To demonstrate the effect that constraint set size has on run-time performance, we use the Bing dataset from [21], which has a larger number of images in each domain than Office.", "startOffset": 122, "endOffset": 126}, {"referenceID": 19, "context": "We use the train/test split from [21] and then vary the number of labeled target examples available from 5 to 25.", "startOffset": 33, "endOffset": 37}, {"referenceID": 11, "context": "\u2022 arc-t: A category general feature transform method proposed by [12].", "startOffset": 65, "endOffset": 69}, {"referenceID": 10, "context": "\u2022 hfa: A max-margin transform approach that learns a latent common space between source and target as well as a classifier that can be applied to points in that common space [11].", "startOffset": 174, "endOffset": 178}, {"referenceID": 14, "context": "\u2022 gfk: The geodesic flow kernel [15] applied to all source and target data (including test data).", "startOffset": 32, "endOffset": 36}, {"referenceID": 14, "context": "Following [15], we use a 1-nearest neighbor classifier with the kernel.", "startOffset": 10, "endOffset": 14}, {"referenceID": 24, "context": "We used the LIBSVM package [26] for kernelized methods and Liblinear [27] package for linear methods.", "startOffset": 27, "endOffset": 31}, {"referenceID": 25, "context": "We used the LIBSVM package [26] for kernelized methods and Liblinear [27] package for linear methods.", "startOffset": 69, "endOffset": 73}, {"referenceID": 11, "context": "Following the experimental setup of [12].", "startOffset": 36, "endOffset": 40}, {"referenceID": 9, "context": "We compare against pmt-svm [10] and ARC-t [12] using both knn and svm classification.", "startOffset": 27, "endOffset": 31}, {"referenceID": 11, "context": "We compare against pmt-svm [10] and ARC-t [12] using both knn and svm classification.", "startOffset": 42, "endOffset": 46}, {"referenceID": 0, "context": "We follow the setup of [1] and [15]: 20 training examples for amazon source (8 for all other domains as source) and 3 labeled examples per category for the target domain.", "startOffset": 23, "endOffset": 26}, {"referenceID": 14, "context": "We follow the setup of [1] and [15]: 20 training examples for amazon source (8 for all other domains as source) and 3 labeled examples per category for the target domain.", "startOffset": 31, "endOffset": 35}, {"referenceID": 10, "context": "Recall that this is a setting that many category specific adaptation methods cannot generalize to, including hfa [11].", "startOffset": 113, "endOffset": 117}, {"referenceID": 11, "context": "Therefore, we compare our results for this setting to the arc-t [12] method which learns a category independent feature transform and the gfk [15] method which learns a category independent kernel to compare the domains.", "startOffset": 64, "endOffset": 68}, {"referenceID": 14, "context": "Therefore, we compare our results for this setting to the arc-t [12] method which learns a category independent feature transform and the gfk [15] method which learns a category independent kernel to compare the domains.", "startOffset": 142, "endOffset": 146}, {"referenceID": 11, "context": "Following the experimental setup of [12], we use the full Office dataset and allow 20 labeled examples per category in the source for amazon and 10 labeled examples for the first 15 object categories in the target (dslr).", "startOffset": 36, "endOffset": 40}, {"referenceID": 19, "context": "To demonstrate the effect that constraint set size has on run-time performance, we use the Bing [21] dataset, which has a larger number of images in each domain than Office.", "startOffset": 96, "endOffset": 100}, {"referenceID": 19, "context": "We use the train/test split from [21] and then vary the number of labeled target examples available from 5 to 20.", "startOffset": 33, "endOffset": 37}], "year": 2013, "abstractText": "We present an algorithm that learns representations which explicitly compensate for domain mismatch and which can be efficiently realized as linear classifiers. Specifically, we form a linear transformation that maps features from the target (test) domain to the source (training) domain as part of training the classifier. We optimize both the transformation and classifier parameters jointly, and introduce an efficient cost function based on misclassification loss. Our method combines several features previously unavailable in a single algorithm: multi-class adaptation through representation learning, ability to map across heterogeneous feature spaces, and scalability to large datasets. We present experiments on several image datasets that demonstrate improved accuracy and computational advantages compared to previous approaches.", "creator": "LaTeX with hyperref package"}}}