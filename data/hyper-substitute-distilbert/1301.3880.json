{"id": "1301.3880", "review": {"conference": "arxiv", "VERSION": "v1", "DATE_OF_SUBMISSION": "16-Jan-2013", "title": "Using ROBDDs for Inference in Bayesian Networks with Troubleshooting as an Example", "abstract": "when using bayesian networks for modelling the behavior of man - made machinery, it usually happens that specific causal part constructing any model is justified. over large bayesian domains deterministic modelling of the model can change represented as a boolean function, showing a specific cause of belief bias reduces to the task of indicating the dependence of relevant commands in a specified logic. structured analytics lab : explore how results in the calculation on dependency fields can possibly adopted for sanity updating, those particular within the context computer troubleshooting. it present tentative results reflecting considerably substantial speed - up compared to traditional junction channel propagation.", "histories": [["v1", "Wed, 16 Jan 2013 15:51:50 GMT  (379kb)", "http://arxiv.org/abs/1301.3880v1", "Appears in Proceedings of the Sixteenth Conference on Uncertainty in Artificial Intelligence (UAI2000)"]], "COMMENTS": "Appears in Proceedings of the Sixteenth Conference on Uncertainty in Artificial Intelligence (UAI2000)", "reviews": [], "SUBJECTS": "cs.AI", "authors": ["thomas d nielsen", "pierre-henri wuillemin", "finn verner jensen", "uffe kj{\\ae}rulff"], "accepted": false, "id": "1301.3880"}, "pdf": {"name": "1301.3880.pdf", "metadata": {"source": "CRF", "title": "Using ROBDDs for Inference in Bayesian Networks with Troubleshooting as an Example", "authors": ["Thomas D. Nielsen", "Pierre-Henri Wuillemin Finn", "V. Jensen Uffe Kjcerulff"], "emails": [], "sections": [{"heading": null, "text": "When using Bayesian networks for modelling the behavior of man-made machinery, it usu ally happens that a large part of the model is deterministic. For such Bayesian networks the deterministic part of the model can be represented as a Boolean function, and a cen tral part of belief updating reduces to the task of calculating the number of satisfying configurations in a Boolean function. In this paper we explore how advances in the calcu lation of Boolean functions can be adopted for belief updating, in particular within the context of troubleshooting. We present ex perimental results indicating a substantial speed-up compared to traditional junction tree propagation.\n1 INTRODUCTION\nWhen building a Bayesian network model it frequently happens that a large part of the model is determinis tic. This happens particularly when modelling the be havior of man-made machinery. Then the situation is that we have a deterministic kernel with surrounding chance variables, and it seems excessive to use stan dard junction tree algorithms for belief updating. First of all, the calculations in the deterministic kernel are integer calculations and double precision calculations are unnecessary complex. However, there may be room for further improvements. If the deterministic part of the model is represented as a Boolean function, we may exploit contemporary advances in calculation of Boolean functions.\nA major advance in Boolean calculation is Binary Decision Diagrams, particularly Reduced Ordered Bi nary Decision Diagrams, ROBDDs[Bryant, 1986]. An ROBDD is a DAG representation of a Boolean func tion. The representation is tailored for fast calculation\nof values, but the representation can also be used for fast calculation of the number of satisfying configura tions given an instantiation of a subset of the variables.\nTo be more precise: let B(X) be a Boolean function over the Boolean variables X, and let Y \ufffd X with Z = X\\Y. Define Cards (1)) on a configuration iJ of y as the number of configurations z over Z such that B (1j, z) = true( 1). It turns out that given iJ an ROBDD representation of B can be constructed such that Cards can be calculated in time linear in the num ber of nodes in the ROBDD. However, the number of nodes in an ROBDD may be exponential in the num ber of variables in the domain of the Boolean function.\nIn this paper we exploit the ROBDD representation for propagation through a Boolean kernel in a Bayesian network, and we illustrate that a central part of this propagation is to calculate Cards (i)). We use the tech nique on models for troubleshooting. These models are particularly well suited for ROBDD calculation as the size of the ROBDD is quadratic in the size of the domain.\nIn section 2 we illustrate the use of Cards for prob ability updating in Bayesian networks. \u00b7 Section 3 is a brief introduction to ROBDDs and in section 4 we show how to calculate Cards in an ROBDD. Section 5 introduces the troubleshooting task and the type of Bayesian network models used. In section 6 the de terministic kernel of these models is represented as an ROBDD and it is shown that the size of this represen tation is quadratic in the number of Boolean variables. In section 7 we outline the propagation algorithms for various troubleshooting tasks, and in section 8 we re port on empirical results indicating a substantial speed up compared to traditional junction tree propagation.\n2 TWO MOTIVATING EXAMPLES\nTo illustrate the special considerations in connection with Boolean kernels we shall treat a couple of exam-\nUNCERTAINTY IN ARTIFICIAL INTELLIGENCE PROCEEDINGS 2000 427\nples. First consider the situation in Figure 1.\nFigure 1: The Boolean variable A has a parent net work of proper chance variables and a child network representing a Boolean function B.\nFor the situation in Figure 1 we have (U = WUVU{A}):"}, {"heading": "P (U) = Q(W,A)I.tB(V,A),", "text": "where 1-l = 1/ Lvu{A} B(V,A) is a normalization con stant. Assume we have evidence e = ew u ev , where ev is a configuration y of the variables Y \ufffd V, then:\nP(A,e) 1-l L Q(W,ew,A) L B(Z,y,A) w z\n1-l L Q(W, ew, A)CardB (y, A), w\nAs the example illustrates, an efficient procedure for calculating CardB is central for probability updating.\nIf we extend the example s.t. a Boolean variable C E V has a child network R(T, C) of proper chance variables, we get (the normalization constant is omitted) :\nP(U) = Q(W,A)B(V,A)R(T,C)\nAssume we have evidence e = ew u ev u er, where ev is a configuration y of the variables Y \ufffd V. If er is empty then R does not contribute, and the calculations are as for Figure 1. If not, we have:\nP(A,e) = L Q(W,ew,A) \u00b7 w\nL (L B(Z, y, A, C) L R(T, e7, C)) C Z T\n= L Q(W, ew, A)\u00b7 w\n(L B(Z,y,A,C = y ) L R(T,er,C = y ) Z T\n+ L B(Z,y,A,C =n ) L R(T,e7,C =n)) Z T\n= L Q(W,ew,A) \u00b7 w\n( CardB(y,A, C = y) \ufffd R(T, er, C = y) + Card8(Y,A, C = n ) \ufffd R(T, er, C = n))\nAgain, calculation of Card8 is part of belief updating.\n3 BOOLEAN FUNCTIONS AND\nROBDDS\nThis section is a survey of classical logic in the context of binary decision diagrams.\nThe classical calculus for dealing with truth assign ments consists of Boolean variables, the constants true (1) and false (0) and the operators 1\\ (conjunction), V (disjunction), -. (negation), =} (implication) and {:::} ( bi-implication). A combination of these entities form a Boolean function and the set of all Boolean functions is known as propositional logic.\nA truth assignment to a Boolean function B is the same as fixing a set of variables in the domain of B, i.e., if X is a Boolean variable in the domain of B, then X can be assigned either 0 or 1 (denoted [X H 0] and [X H 1], respectively) . A Boolean function is said to be a tautology if it yields true for all truth assignments, and it is satisfiable if it yields true for at least one truth assignment.\nLet X --7 Y 1, Y 2 denote the if-then-else operator. Then X --7 Y1 , Y2 is true if either X and Y, are true or X is false and Y 2 is true; the variable X is said to be the test expression. More formally we have:\nAll operators in propositional logic can be expressed using only this operator and this can be done s.t. tests are only performed on unnegated variables.\nDefinition 1. An If-then-else Normal Form (INF) is a Boolean function built entirely from the if-then-else operator and the constants 0 and 1 s.t. all tests are performed only on variables.\nConsider the Boolean function B and let B [X H 0] denote the Boolean function produced by substituting 0 for X in B. The Shannon expansion of B w.r.t. X is defined as:"}, {"heading": "B =: X -t B [(< H 1], B [X H 0]", "text": "From the Shannon expansion we get that any Boolean function can be expressed in INF by iteratively using the above substitution scheme on B.\nBy applying the Shannon expansion to a Boolean func tion B w.r.t. an ordering of all the variables in the do main of B we get a set of if-then-else expressions which can be represented as a binary decision tree. The de cision tree may contain identical substructures and by \"collapsing\" such substructures we get a binary deci sion diagram (BDD) which is a directed acyclic graph. The ordering of the variables, corresponding to the order in which the Shannon expansion is performed,\n428 UNCERTAINTY IN ARTIFICIAL INTELLIGENCE PROCEEDINGS 2000\nis encoded in the BDD hence, we say that the BDD is an ordered binary decision diagram (OBDD); the variables occur in the same order on all paths from the root. If all redundant tests are removed in an OBDD it is said to be reduced and we have a reduced ordered binary decision diagram (ROBDD).\nDefinition 2. A reduced ordered binary decision di agram {ROBDD) is a rooted, directed acyclic graph with\n\u2022 one or two terminal nodes labeled 0 and 1 respec tively.\n\u2022 a set of non-terminal nodes of out-degree two with one outgoing arc labeled 0 and the other 1.\n\u2022 a variable name attached to each non-terminal node s.t. on all paths from the root to the ter minal nodes the variables respect a given linear ordering.\n\u2022 no two nodes have isomorphic subgraphs.\nWe will use Eo to denote the set of 0-arcs (drawn as dashed arcs) and \u00a31 to denote the set of l-ares (drawn as solid arcs).\nTheorem 1 ([Bryant, 1986]). For any Boolean function f : {0, l}n --7 {0, 1} there is exactly one ROBDD B with variables X, < X2 < \u00b7 \u00b7 \u00b7 < Xn s.t. B[X, H b1 ,X2 H b2, ... ,Xn H bnJ f (b1, b2, ... , bn), \\i (b1, b2, ... , bn) E {0, l}n.\nFrom Theorem 1 we have that in order to calculate the number of satisfying configurations in a Boolean function B we can produce an ROBDD equivalent to B and then count in this structure.\nIn the remainder of this paper we assume that an ROBDD has exactly one terminal node labeled 1, as we are only interested in the number of satisfying configu rations; in this situation we allow non-terminal nodes with out-degree one. Additionally, we will use the term \"nodes\" in the context of ROBDDs and \"variables\" when referring to a Boolean function or a Bayesian network(BN); nodes and variables will be denoted with lower case letters and upper case letters, respectively (the nodes representing a variable Xi will each be de noted Xi if this does not cause any confusion).\n4 CALCULATION OF CARDB\nUSING ROBDDS\nGiven an ROBDD representation of a Boolean func tion B, the number of satisfying configurations can be calculated in time linear in the number of nodes in the\nROBDD. The algorithm basically propagates a num ber (2 n, where n is the number of distinct variables in the corresponding Boolean function) from the root of the ROBDD to the terminal node. The value sent from a node (including the root) to one of its children is the value associated with that node divided by 2. The value associated with a node (except the root) is the sum of the values sent from its parents (see Fig ure 2).\nFigure 2: There are 3 satisfying configurations for the Boolean function \"Exactly one variable among A 1 , A 2, A 3 is true\" represented by this RO BD D.\nDefinition 3. Let B = (U,\u00a3) be an ROBDD. Propa gation in B is the computation of v (u), where u E U and v : U --7 lR is defined as:\n\u2022 v (r) = 2 n, where r is the root in B and n is the number of distinct variables in B. L v(p) \u2022 \\iu E U\\{r}: v (u) = pEnd' , where nu repre-\nsents the set of parents for u in B.\nSo, in order to determine Cards for some Boolean function B(U) we only need one propagation in the corresponding ROBDD since Cards = v (l). In case evidence y has been received on the variables Y \ufffd U we simply modify the algorithm s.t. configurations, in consistent with y, does not contribute to the propaga tion, i.e., given a configuration y the function v (u)y is defined as:\n. _ LvEna v(p )y \\iu E U\\{r}. v (u)y - 2 ,\nwhere nR = {p E nul[p (j. Yl or [y(p) = i and (p, u) E \u00a3i]}; y(p) is the state ofp E Y under y and v (r) = 2n, n being the number of distinct variables in B including those on which evidence has been received. In partic ular we have that Cards (i:i) = v (1 )y. Notice, that the structure of the ROBDD is not changed when evidence is received.\nThe size of the ROBDD has a significant impact on the performance of the algorithm and the problem of\nUNCERTAINTY IN ARTIFICIAL INTELLIGENCE PROCEEDINGS 2000 429\nidentifying a minimal sized ROBDD is NP-complete. Thus, in the remainder of this paper we shall mainly focus on troubleshooting models as it turns out that the structure of such a model ensures that the size of the corresponding ROBDD is at most quadratic in the size of the domain.\n5 TROUBLESHOOTING\nWhen troubleshooting a device which is not working properly we wish to determine the cause of the problem or find an action sequence repairing the device. At any time during the process there may be numerous differ ent operations that can be performed e.g. a component can be repaired/replaced or the status of a component can be investigated. Because such operations can be expensive and may not result in a functioning device, it is expedient to determine a sequence of operations that minimizes the expected cost and (eventually) re pairs the device.\n[Breese and Heckerman, 1996] presents a method to myopicly determine such a sequence. The method as sumes a BN representing the device in question, and the BN is assumed to satisfy the following properties.\n1. There is only one problem defining variable in the BN and this variable represents the functional sta tus of the device.\n2. The device is initially faulty.\n3. Exactly one component is malfunctioning causing the device to be faulty (single fault).\nA central task of troubleshooting, within the frame work of [Breese and Heckerman, 1996], is the calcula tion of Pi = P( C i =faulty! e) which denotes the prob ability that component ci is the cause of the problem given evidence e. So we are looking for a way to exploit the logical structure of the model when calculating the probabilities Pi\u00b7 As such a scheme is strongly depen dent on the structure of the troubleshooting model we give a syntactical definition of this concept. The def inition is based on BNs: a BN consists of a directed acyclic graph G = (U, \u00a3) and a joint probability dis tribution P(U), where U is a set of variables and \u00a3 is a set of edges connecting the variables in U; we use sp(X) to denote the state space for a variable X E U. The joint probability distribution P (U) factorizes over U s.t. :\nP(U) = IJ P(XInx), XEU\nwhere nx is the parents of X in G. The set of con ditional probability distributions factorizing P (U) ac cording to G is denoted P.\nDefinition 4. A troubleshooting model is a con nected BN T5 = ((U =Us U Uc U UA,\u00a3), P), where:\n\u2022 The set Us contains a distinct variable 5 with no successors, and for each 51 E Us \\{5} there exists a directed path from 51 to 5.\n\u2022 For each variable C E Uc there exists an 51 E Us s.t. C Ens, and nc = 0.\n\u2022 For each variable A E UA there does not exist an X E U s.t. A E nx.\n\u2022 sp(X) = {ok, \ufffdok}, VX E Us U Uc.\n\u2022 For each X E Us: P(xly) = 1 or P(xly) = 0, Vx E sp(X) and Vy E sp(nx).\nThe variable 5 is termed the problem defining variable and the variables Us are termed system variables. The variables Uc (termed cause variables) represent the set of components which can be repaired, and the vari ables in UA (termed action variables) represent user performable operations such as observations and sys tem repairing actions; notice that UA is not part of the actual system specification. In the remainder of this paper we shall extend the single fault assump tion to include the system variables also. That is, if a system variable 5i is faulty, then there exists ex actly one variable X E ns, which is faulty also (see [Skaanning et al., 1999] for further discussion of this extension and how the single fault assumption can be enforced using so-called \"constraint variables\" ).\nFigure 3 depicts a troubleshooting model, where A is an action variable and 5 represents the problem defin ing variable. The variables 51 ,5z,53 and 54 repre sent subsystems, which should be read as: the sys tem 5 can be decomposed into two subsystems 51 and 5z, and subsystem 51 can be decomposed into 53 and 54. Component C 1 can cause either 53 or 54 to fail, whereas Cz can cause either 5z or 54 to fail (neither C 1 nor Cz can cause two subsystems to fail simultane ously). Notice that A is not part of the actual system model.\nFigure 3: A troubleshooting model with five system variables, two cause variables and one action variable.\n430 UNCERTAINTY IN ARTIFICIAL INTELLIGENCE PROCEEDINGS 2000\nFrom assumption (2) and (3) we have that:\nP(C1 = y, e) =P(C1 =1J, Cz =n, . . . , Cm =n, e)\nm = P(C1 = y) II P(Ci = n)\ni=2\n.L_ \ufffd-tB(C1 = y, Cz = n, .. . , Cm = n, Us, e) Us\nm = P(C1 = y) II P(Ci = n) \ufffd-tCards(C1 = y, e),\ni=2\nwhere B(Us , Uc) is a Boolean function (specified in the following section) and J.t is a normalization constant. Now, P(C11el = P(C1, e)/P(e) and P(e) is given by:\nm P(e) = .[_ IJ P(Cd!-!B(C1, \u00b7\u00b7\u00b7 , Cm, S, S, . . . , Sn, el\nu i=1\nIn the remainder of this paper we omit the normaliza tion constant.\n6 ROBDDS AS\nTROUBLESHOOTING MODELS\nIn what follows we shall assume single fault and use the truth values 1 and 0 to denote the state of a com ponent/subsystem (1 indicates a fault).\nNow, let nsi be the subsystems which immediately compose Si E Us and let Sc \ufffd Us be the subsys tems that component C E Uc can cause to fail; Sc is the immediate successors of C. The Boolean func tion representing the logical kernel of a troubleshoot ing model TS =((Us UUc UUA, \u00a3), P) is then given by B(U' =Us UUc):\nF(T)\nG(C)\nM\nB(U')\n(T A \u00ae s') v (\ufffdr A 1\\ \ufffds') S'EnT S'EnT\nC=} Q9 T TESc\n(sA \u00ae c) v (\ufffdsA 1\\ \ufffdc) CEUc CEUc ( f\\ F(T)) A ( f\\ G(C)) AM, TEUs CEUc\nwhere \u00ae\ufffd=1 xi denotes an exclusive-or between the variables {X 1 , . . . , Xn}. F (T) specifies that if the sys tem Tis malfunctioning then one (and only) of its sub systems is faulty, and if the system is functioning prop erly then all of its subsystems are functioning properly also. G(C) states that if a cause is present then one\n(and only one) of its subsystems (Sc) is faulty (if a cause is not present we can not say anything about its subsystems). M says that there can be either zero or at most one cause present (consistent with the system state). B(U) is the Boolean function representing the system as a whole. Note that:\n\u2022 The Boolean function is a list of expressions for local constraints and it can therefore be built in an incremental fashion.\n\u2022 The Boolean function can easily be modified to represent any logical relation between the compo nents.\n\u2022 The expression ensures the single fault assump tion based on the structure of the model, i.e., it is not necessary to introduce \"constraint variables\" .\nExample 1. The Boolean function representing the troubleshooting model depicted in Figure 3 is specified by B:\n((SA (S1 l3l Sz)) V (\ufffdS A--,51--,Sz))\nB1 A ((S1 A (S3 l3l S4)) V (\ufffdS1 A \ufffds3\ufffdS4))\nB3 A (Cz:::} (Sz!Zl S4))\n84 A ((SA (C1 IZl Cz)) V (\ufffdSA \ufffdC1 A \ufffdCz))\nGiven the ordering S, S1, Sz, S3, S4, C1, C2, the ROBDD corresponding to B is depicted in Figure 4. Note that all paths from the root S to the terminal node are consistent with the ordering above.1 D\nUNCERTAINTY IN ARTIFICIAL INTELLIGENCE PROCEEDINGS 2000 431\nNow, as indicated in Section 3, the size of the ROBDD is dependent on the ordering of the variables. So we are looking for a general \"rule of ordering\" producing ROBDDs of \"small\" size.\nConsider an ordering of the variables where each sys tem variable occurs before all the variables repre senting its subsystems, and where all the cause vari ables occur last in the ordering. By constructing the ROBDD according to this ordering we get the node representing the problem defining variable as root and the nodes representing the cause variables at the bot tom (see Figure 4). Moreover, we get an upper bound on the size of the ROBDD as stated in the following theorem; note that the action variables are not part of the logical kernel.\nTheorem 2. Let TS= ((U = UAUUsUUc,\u00a3), P) be a troubleshooting model. Then the size of the ROBDD, representing the Boolean function B(Us U Uc), is O(IUsi2+1Ucl2), if the ordering a: UsUUc H IUsUUcl satisfies:\n\u2022 VX E Us: a(X) < a(Y) for each Y E nx. \u2022 VZ E Uc there does not exist an X E Us s.t.\na(Z) < a(X).\nProof. Assume an indexing of the layers in the ROBDD s.t. the layers containing the root node and the terminal node have index 1 and IUs U Ucl + 1, re spectively; a layer is the set of nodes representing a distinct variable.\nNow, consider the layers consisting of system nodes but no cause nodes. The number of nodes in the i'th layer either equals the number of nodes in the i'th - 1 layer or it has exactly one more node than the i'th- 1 layer. This is the same as saying that at most one node in the i'th- 1 layer branches in two; if two differ ent nodes in a layer branched into two we would have two distinct paths from a node at a higher level to these nodes however, this contradicts the single-fault assumption due to the ordering of the nodes. Thus, the number of nodes in the layers containing system nodes is at most L.\ufffdZ::11 i = IUs l{l\ufffds I+ 11.\nFor the cause nodes, there can be at most one distinct path for each of their possible configurations. This means that the number of nodes in the layers contain ing cause nodes is at most IUcl('\ufffdcl) = 1Ucl2. Hence, the size of the ROBDD is O(IUsl2 + IUcl2). D\nIn the ROBDDs, we have an all-false path from the root to the terminal node. Indeed the Boolean function is true when the model has no fault. However, we can force S to be true (faulty) to avoid this path."}, {"heading": "7 PROPAGATION USING ROBDDS", "text": "For our context, we need to compute the number of satisfying configurations for each instantiation of the cause variables (see Section 5). Now, if we order the variables as described in Theorem 2 we get an ROBDD where the nodes representing the cause variables are the nodes closest to the terminal node. This means that after one propagation we can determine all the values needed, i.e., the number of configurations con sistent with ci = 1J and evidence e is given by:\n\" v(c\u00b7 ) CardB(C=y,e)= L 2#\\ie' CtECt\nwhere Ci is the set of nodes Ci with an outgoing 1-arc and # li is the number of arcs on the path li from the Ci in question to the terminal node; the single-fault assumption ensures that there exist exactly one path from each Ci to the terminal node which include the 1-arc emanating from Ci. However, this scheme does not take user performable operations (i.e. UA) into account, and in the follow ing section we extend the algorithm to include such scenarios.\n7.1 Inserting evidence\nAfter an action has been performed we may gain new knowledge about the system. This knowledge is incor porated into the model by instantiating the appropri ate variable. If either a system variable or a cause vari able is instantiated we can use the method described in Section 4. So, let A E UA be a binary variable associ ated with a proper conditional probability distribution P(AISi) and assume that A= y is observed. In order to take the state of A into consideration we get:\nP(C1 =y,A=y) =P(Cl =1J,Cz=n, ... ,Cm=n,A=y)\n= P(C1 = y) IT P(Ci = n) L (P(A = yiSd Us\nB(C1 = y, Cz = n, ... , Cm = n,Us))\nBy expanding the sum in the above equation we get:\nL P(A = yiSi)B(Cl = y, Cz = n, ... , Cm = n,Us) Us\n= P(A = yiSi = y)CardB (C1 = y, Si = y) +P(A=yiSi=n)CardB(Cl =1J,Si=n)\n(1)\nThus, with one piece of evidence we can retrieve the probabilities with two propagations. However, if we have a set of actions u;,._ \ufffd UA with parents u;, \ufffdUs\n432 UNCERTAINTY IN ARTIFICIAL INTELLIGENCE PROCEEDINGS 2000\nwe need to count the number of satisfying configura tions consistent with each configuration of U$. So, by using the above approach, the number of times we need to count is exponential in the number of variables on which evidence has been received.\nIn what follows we will consider a different algorithm, where all values can be found after one propagation. Initially we assume that evidence has been received on exactly one variable, but the algorithm can easily be generalized to any number of variables.\nIn order to prove the soundness of the algorithm we will use the following notation. If B is an ROBDD with root r, then l;_ = {v ir = v1, . . . , V;_ = vis a directed path in B} is termed the i'th layer of B; the layers l1 and ln+ 1 contain the root node and the terminal node, respectively. So, given a Boolean function over the variables U = {X 1 , Xz, . . . , X n} (or dered by index), the corresponding ROBDD can be specified as B =(Us = U\ufffd 1\n1lk, \u00a3 = \u00a31 U \u00a3o); assum ing that the variable X;_ is represented by the layer l;_. Now, let f : sp(W) -t IR be a function where W ={Xi, . . . , Xi} \ufffd U, and assume that the variables are ordered by index. We define the following parti tioning of B =(Us = u\ufffd;;1 1lk, \u00a3) w.r.t. f:\n\u2022 The root part of B w.r.t. f is given by BT = (Uf3,\u00a3f3), where Uf3 = u\ufffd:1 1lk.\n\u2022 The conditioning part of B w.r.t. f is given by Be = (U\ufffd, \u00a3\ufffd), where U\ufffd = ul=i lk.\n\u2022 The terminal part of B w.r.t. f is given by Bt = (U\ufffd, \u00a3\ufffd), where U\ufffd = u\ufffd,:i 1 + 1lk.\nFor ease of exposition, we shall in the remainder of this section assume that no evidence has been received on any variable in Us UU c; the results presented can easily be generalized to this situation also.\nAlgorithm 1. Let B = (U = U\ufffd11li,\u00a3 = \u00a31 U \u00a3o) be an ROBDD corresponding to a Boolean function over the variables U = {X 1 , Xz, . . . , Xn}, and assume that the variables are ordered by index. Let f : sp(W) -t IR be a function with W \ufffd U and let Q = W\\{Xj}, where X i E W is the variable with highest index.\ni) Propagate from the root to the terminal nodes in the root part of B.\nii) Use the values obtained in step (i) to perform a propagation in the conditioning part of B, i. e. , for each q E sp(Q) :\na) Propagate to layer li. b) If there exists an arc ( p, u) E Ci from a node\np E lj to a node u E li +1 add the value c(ii.X;=;i)v(p)q) to the value ofu.\niii) Use the values obtained in step (ii) to propagate in st.\nNote, that the number of variables in the domain off determines the number of iterations performed by the algorithm. In particular, if IWI = 1 we only need one iteration. Theorem 3. Let B = (U = U\ufffd11li, \u00a3 = \u00a31 U\u00a3o) be an ROBDD and let f : sp(W) -t IR be a function where W \ufffd U. If Algorithm 1 is invoked on B, then:\nv(l) = L f(w)Cards(w) wEsp(W)\nProof. Let Q = W\\{Xj}, where X i E W is the variable with highest index. Let q E sp( Q) and let n\ufffdq,i) = {p E nuiP f/. W or (p, u) E \u00a3;_}. Then 'v'u E li+ 1 we have:\nv(u)\n=\n=\nLqEsp(Q) (L.bE{0,1},pEn\ufffd <i.b l v(p)qf(q, bl) 2\nLqEsp(Q) (L.bE{O,l},pEn\ufffd'l.bl v(p)(q,b )f(q, bl) 2\nLwEsp(W) (L.vEn\ufffd v(p)wf(wl) 2 LwEsp{Wl f(w) LvEn\ufffd v(p)w 2\nL f(w)v(u)w wEsp(W)\nLet u E lt, for l > j + 1. Suppose that 'v'p E lt-1 : v(p) = LwEsp(W) f(w)v(Plw \u00b7 Then:\nv (u) = LvEnu v(p) = LvEnu LwEsp(W) f(w)v(p)w 2 2 In particular we have that for l = n + 1:\nv(1) LwEsp(W) f(w) LvEnu v(p)w\n2\nL f(w)Card8(w) wEsp(W)\nThereby completing the proof. D\nBy performing induction in the number of operations the algorithm can easily be extended to handle multi ple functions, assuming that the variables in the do main of the functions do not overlap; the variables in the domain of two functions f and g are said to over lap w.r.t. the ordering a if a(Xd < a(X k) < a(Xj ), where xk is a variable in the domain of g, and xi and Xi are the variables in the domain of f with lowest and highest index, respectively. If the variables of two functions overlap we can multiply these functions and consider the resulting function.\nUNCERTAINTY IN ARTIFICIAL INTELLIGENCE PROCEEDINGS 2000 433\nExample 2. Consider the troubleshooting model de picted in Figure 3, and assume that action A E UA is associated with the conditional probability distribu tion specified in Table 1; nA = {5z, 54}.\nThe ROBDD corresponding to this specification is de picted in Figure 4. In the naive approach, if A = y is observed, we perform three propagations to the termi nal node (one propagation for each configuration of 5z and 54 except for (5z = 1 , 54 = 1 ) due to the single fault assumption). The resulting counts are weighted with the appropriate values and then added (see equa tion 1): 0 \u00b7 0.3 + 4 \u00b7 0.2 + 1 \u00b7 0.4 + 1 \u00b7 0.6 = 1.8.\nWhen using algorithm 1 we start off by propagating to the layer l3 (the nodes representing 5z); after propa gation, each node in l3 is associated with 25. We then perform two propagations to the layer ls (the nodes representing 54); each propagation is conditioned on the state of 5z, i.e., 1 and 0, respectively. After each propagation, the resulting value is multiplied with the appropriate value from the conditional probability ta ble and then added to the value associated with its child. So, the final value can be found with less than two full propagations (see Figure 5); note that we only perform one propagation in W and in Bt. D\nStep (ii) of Algorithm 1 can be optimized by start ing the iteration with the variable with highest in dex, and then iterate in reverse order of their in dex. That is, when iterating over the variables {X 1, Xz, . . . , Xt-1, Xt} we can start off by propagat ing to the layer containing Xt, for some configuration of {X 1, Xz, . . . , Xt-1 }. The values associated with the nodes Xt-1 can then be used when propagating from the nodes Xt, for each instance of Xt. The same ap plies when considering variables of lower index, i.e., we can reuse previous computations. For instance, in Figure 5 we can use the value from the first iteration when computing the value 0.2 \u00b7 22 associated with c1 (consistent with (5z = 0, 54 = 1 )).\n8 RESULTS\nWe have measured the performance of the ROBDD algorithm by comparing it to the Shafer-Shenoy algo rithm [Shafer and Shenoy, 1990] and the Hugin algo rithm [Jensen et al., 1990] w.r.t. the number of opera tions performed during inference; the number of opera-\nB' B'\nC0 (0. '\u2022 ... ,,\n\ufffd& :\u00b7 .. _':_ .. __ 0 'Q_ . ...... ': .... \ufffd.:: . .. ...... 0 .. 0.4. 22 \ufffd 0 4\u2022 22 \ufffd\n0 6\u20222 2 i\n.. ()_ 8 \u00b7\u00b78 .8\" ,.\u00b7\u00b7\u00b7 \u00b7 \u2022.. \u00b7\u00b7 B'\n-- --\ufffdr {a) (bl\nThe tests were performed on 225 randomly generated troubleshooting models (see Definition 4) which dif fered in the number of system variables, cause vari ables and action variables; the total number of vari ables varied from 21 to 322 and for a fixed set of vari ables 15 different troubleshooting models were gener ated. As the single fault assumption is not ensured in the troubleshooting models we augmented these mod els with constraint variables when using the Hugin al gorithm and the Shafer-Shenoy algorithm (the single fault assumption is naturally ensured in the ROBDD architecture). Finally, evidence were inserted on the problem defining variable and on the constraint vari ables.\nFigure 6 show plots of the number of operations per formed as a function of the number of variables in the models. Note that we use a logarithmic scale on the y-axis and that the numbers on the x-axis do not rep resent the actual number of variables in the models. The plots show that, w.r.t. the number of operations, propagation using ROBDDs is considerably more ef ficient than both Shafer-Shenoy and Hugin propaga tion. Moreover, as indicated in Section 6, the tradi tional tradeoff between time and space is less apparent in the ROBDD architecture, as the space complexity is O(IUcl2 + IUsl2).\nIt should be noted that the tests were designed to\n434 UNCERTAINTY IN ARTIFICIAL INTELLIGENCE PROCEEDINGS 2000\ncompare ROBDD propagation with Shafer-Shenoy and Hugin propagation, and they should not be seen as a comparison of Shafer-Shenoy propagation and Hugin propagation. In particular, we have only considered troubleshooting models and not Bayesian networks in general.\nThe efficiency of the ROBDD architecture is partly based on the single fault assumption. However, this assumption can also be exploited in certain trou bleshooting models by compiling the original model TS =((Us UUc UUA,\u00a3), P) into a secondary Bayesian network BN = ((UA U{C}U{S},\u00a3'),P'), where Cis a variable having a state for each cause variable in the original model together with a state representing the situation where no fault is present. S is a problem defining variable having C as parent, and UA is the set of action variables in the original model each having C as parent. We have compared the ROBDD architec ture with this approach using the randomly generated troubleshooting models from the previous tests (see Figure 7).\nBy using this secondary representation the speed-up is less apparent. However, if we allow multiple faults then this representation can not be used. Moreover, a troubleshooting model allowing multiple faults will in general not be simpler than a model with no con straints on the number of faults. In the case of ROB DDs, assume that the single fault assumption still ap plies to the system variables and consider the case where exactly m components can fail simultaneously; m is generally \"small\" . In this situation the number of nodes in the layers containing system nodes does not change but the number of nodes in the layers con taining cause nodes do: there can be a distinct path for each configuration of the cause nodes so the num-\nber of nodes in the layers containing cause nodes is at most IUcl(l\ufffd1). Hence the size of the ROBBD is O(IUsl2 + IUcl(l\ufffd1)); note that in an ROBDD there does not exist two nodes having isomorphic subgraphs so the size of the ROBDD is usually much smaller.\nNow, as the complexity of propagation in an ROBDD is linear in its size, the maximum number of operations performed for m = 2 increases by a factor of n2l ; with m faults the maximum number of operations increases by a factor of n\ufffd\ufffd!= i. This corresponds to adding a constant value to the ROBDD plots in Figure 6 since we use a logarithmic scale on the y-axis.\nFurthermore, if we redefine the m-faults assump tion to cover at most m faults then the number of nodes in the layers containing cause nodes is at most IUcl L\ufffdl euicl). Again, it should be noticed that the actual number of nodes is usually significantly smaller as isomorphic subgraphs are collapsed.\nIn case m-faults is extended to include system vari ables also, it can be shown that the variables can be ordered s.t. the number of nodes in the layers contain ing system nodes is exponential in m but quadratic in the number of system variables if m \ufffd maxsEUs Ins/ (see Figure 8).\nFinally, as the single fault assumption no longer ap plies, the number of configurations consistent with Ct = y and evidence y is given by:\n\ufffd v(c\u00b7 )-Cards(Ct = y, y) = L L 2#\\iy, Ci ECi li E.Ci where Ct is the set of nodes Ct with an outgoing 1-arc, Lt is the set of distinct paths from the Ct in question to the terminal node and # lt is the number of arcs on such a path.\nHaving multiple faults also supports other frame-\nUNCERTAINTY IN ARTIFICIAL INTELLIGENCE PROCEEDINGS 2000 435\nworks like [de Kleer and Williams, 1987] and [Williams and Nayak, 1996]. For instance, in cir cuit diagnosis [de Kleer and Williams, 1987] uses a logical model of the system to be diagnosed and determines the next action based on expected Shan non entropy. To calculate the expected Shannon entropy they require the conditional probability of a set of failed components (termed a candidate in [de Kleer and Williams, 1987]) given some observa tion. As their framework does not yield an easy way to obtain this probability they use an approximation. In our framework the logical circuits can be represented as ROBDDs which makes the necessary probabilities easily available.\nSo far we have not established a practical upper bound on the size of ROBDDs with m faults, but all the examples we have worked with until now have been of a \"small\" size. Moreover, several heuristic methods have been devised for finding a good order ing of the variables (see e.g. [Malik et al., 1988] and (Fujita et al., 1988]).\n9 CONCLUSION\nWhen modelling the behavior of man-made machinery using Bayesian networks it frequently happens that a large part of the model is deterministic. In this pa per we have reduced the task of belief updating in the deterministic part of such models to the task of calculating the number of configurations satisfying a Boolean function. In particular, we have exploited that a Boolean function can be represented by an ROBDD, and in this particular framework the number of satisfying configurations can be calculated in time linear in the size of the ROBDD.\nThe use of ROBDDs for belief updating was exempli fied in the context of troubleshooting, which is partic ular well-suited as it was shown that the variables can\nbe ordered s.t. the size of the ROBDD is quadratic in the size of the domain.\nThe performance of ROBDD propagation was com pared with Shafer-Shenoy and Hugin propagation us ing randomly generated troubleshooting models. The results showed a substantial speed-up and it was argued that the single-fault assumption, underlying troubleshooting models, can be weakened without sig nificantly affecting the performance of the algorithm in case the number of faults is \"small\" .\nReferences\n(Breese and Heckerman, 1996] Breese, J. S. and Beck erman, D. (1996). Decision-theoretic troubleshoot ing: A framework for repair and experiment. In Proc. of twelfth Conf. on Uncertainty in AI, pages 124-132. Morgan Kaufmann Publishers.\n(Bryant, 1986] Bryant, R. E. (1986). Graph-based al gorithms for boolean function manipulation. IEEE transactions on computers, 8(C-35):677-691.\n[de Kleer and Williams, 1987] de Kleer, J. and Williams, B. (1987). Diagnosing multiple faults. Artificial Intelligence, 32 (1) :97-130.\n(Fujita et al., 1988] Fujita, M., Fujisawa, H., and Kawato, N. (1988). Evaluation and improvements of boolean comparison method based on binary de cision diagrams. In International conference on Computer-aided design, pages 2-5. IEEE.\n(Jensen et al., 1990] Jensen, F. V., Lauritzen, S. L., and Olesen, K. G. (1990). Bayesian updating in causal probabilistic networks by local computations. Computational Statistics Quarterly, 4:269-282.\n(Malik et al., 1988] Malik, S., Wang, A. R., Brayton, R. K., and Saugiovanni-Vincentelli, A. (1988). Logic verification using binary decision diagrams in a logic synthesis environment. In International conference on Computer-aided design, pages 6-9. IEEE.\n(Shafer and Shenoy, 1990] Shafer, G. R. and Shenoy, P. P. (1990). Probability Propagation. Annals of Mathematics and Artificial Intelligence, 2:327-352.\n(Skaanning et al., 1999] Skaanning, C., Jensen, F. V., Kjrerulff, U., and Madsen, A. L. (1999). Acquisi tion and transformation of likelihoods to conditional probabilities for Bayesian networks. In AAAI Spring Symposium on AI in Equipment Maintenance Ser vice and Support, pages 34-40.\n(Williams and Nayak, 1996] Williams, B. C. and Nayak, P. P. (1996). A Model-based Approach to Reactive Self-configuring Systems. In Proceedings of AAAI-96, pages 971-978. AAAI."}], "references": [{"title": "Decision-theoretic troubleshoot\u00ad ing: A framework for repair and experiment", "author": ["Breese", "Heckerman", "J.S. 1996] Breese", "D. Beck\u00ad erman"], "venue": "In Proc. of twelfth Conf. on Uncertainty in AI,", "citeRegEx": "Breese et al\\.,? \\Q1996\\E", "shortCiteRegEx": "Breese et al\\.", "year": 1996}, {"title": "Diagnosing multiple faults", "author": ["de Kleer", "Williams", "J. 1987] de Kleer", "B. Williams"], "venue": "Artificial Intelligence,", "citeRegEx": "Kleer et al\\.,? \\Q1987\\E", "shortCiteRegEx": "Kleer et al\\.", "year": 1987}, {"title": "Evaluation and improvements of boolean comparison method based on binary de\u00ad cision diagrams", "author": ["Fujita et al", "M. 1988] Fujita", "H. Fujisawa", "N. Kawato"], "venue": "In International conference on Computer-aided design,", "citeRegEx": "al. et al\\.,? \\Q1988\\E", "shortCiteRegEx": "al. et al\\.", "year": 1988}, {"title": "Bayesian updating in causal probabilistic networks by local computations", "author": ["Jensen et al", "F.V. 1990] Jensen", "S.L. Lauritzen", "K.G. Olesen"], "venue": null, "citeRegEx": "al. et al\\.,? \\Q1990\\E", "shortCiteRegEx": "al. et al\\.", "year": 1990}, {"title": "Logic verification using binary decision diagrams in a logic synthesis environment", "author": ["Malik et al", "S. 1988] Malik", "A.R. Wang", "R.K. Brayton", "A. Saugiovanni-Vincentelli"], "venue": "In International conference on Computer-aided design,", "citeRegEx": "al. et al\\.,? \\Q1988\\E", "shortCiteRegEx": "al. et al\\.", "year": 1988}, {"title": "Probability Propagation", "author": ["Shafer", "Shenoy", "G.R. 1990] Shafer", "P.P. Shenoy"], "venue": "Annals of Mathematics and Artificial Intelligence,", "citeRegEx": "Shafer et al\\.,? \\Q1990\\E", "shortCiteRegEx": "Shafer et al\\.", "year": 1990}, {"title": "Acquisi\u00ad tion and transformation of likelihoods to conditional probabilities for Bayesian networks", "author": ["Skaanning et al", "C. 1999] Skaanning", "F.V. Jensen", "U. Kjrerulff", "A.L. Madsen"], "venue": "In AAAI Spring Symposium on AI in Equipment Maintenance Ser\u00ad", "citeRegEx": "al. et al\\.,? \\Q1999\\E", "shortCiteRegEx": "al. et al\\.", "year": 1999}, {"title": "A Model-based Approach to Reactive Self-configuring Systems", "author": ["Williams", "Nayak", "B.C. 1996] Williams", "P.P. Nayak"], "venue": "In Proceedings of AAAI-96,", "citeRegEx": "Williams et al\\.,? \\Q1996\\E", "shortCiteRegEx": "Williams et al\\.", "year": 1996}], "referenceMentions": [], "year": 2011, "abstractText": "When using Bayesian networks for modelling the behavior of man-made machinery, it usu\u00ad ally happens that a large part of the model is deterministic. For such Bayesian networks the deterministic part of the model can be represented as a Boolean function, and a cen\u00ad tral part of belief updating reduces to the task of calculating the number of satisfying configurations in a Boolean function. In this paper we explore how advances in the calcu\u00ad lation of Boolean functions can be adopted for belief updating, in particular within the context of troubleshooting. We present ex\u00ad perimental results indicating a substantial speed-up compared to traditional junction tree propagation.", "creator": "pdftk 1.41 - www.pdftk.com"}}}