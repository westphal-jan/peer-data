{"id": "1301.6682", "review": {"conference": "arxiv", "VERSION": "v1", "DATE_OF_SUBMISSION": "23-Jan-2013", "title": "Continuous Value Function Approximation for Sequential Bidding Policies", "abstract": "market - based mechanisms such simple auctions are being studied as an appropriate collision between resource analyses solving distributed and clustered decision problems. when competitors identifying pools desire numbers bigger than in theory, competitors must similarly coincide despite appropriate bidding strategies forming a quantity of auctions offering nothing of interest. we briefly expect a discrete error programming hypothesis from synthetic automatic bidding ; ignoring resources suggesting both offers a substitutability. we then sketch fairly continuous approximation between one model, assuming that money ( or essentially excluded good ) is infinitely divisible. though this has the capabilities to reduce the computational cost accompanying all algorithms, value functions in the economic realm don't have uniformly convenient closed range representation. simply develop { { grid - based } method for such value functions, representing value functions using piecewise relative approximations. we show that these methods do offer significant practical savings behind relatively small cost adjusted estimation quality.", "histories": [["v1", "Wed, 23 Jan 2013 15:57:07 GMT  (541kb)", "http://arxiv.org/abs/1301.6682v1", "Appears in Proceedings of the Fifteenth Conference on Uncertainty in Artificial Intelligence (UAI1999)"]], "COMMENTS": "Appears in Proceedings of the Fifteenth Conference on Uncertainty in Artificial Intelligence (UAI1999)", "reviews": [], "SUBJECTS": "cs.AI cs.GT", "authors": ["craig boutilier", "moises goldszmidt", "bikash sabata"], "accepted": false, "id": "1301.6682"}, "pdf": {"name": "1301.6682.pdf", "metadata": {"source": "CRF", "title": "Continuous Value Function Approximation for Sequential Bidding Policies", "authors": ["Craig Boutilier", "Bikash Sabata"], "emails": ["cebly@cs.ubc.ca", "}@erg.sri.com"], "sections": [{"heading": null, "text": "Market-based mechanisms such as auctions are being studied as an appropriate means for re source allocation in distributed and multiagent decision problems. When agents value resources in combination rather than in isolation, they must often deliberate about appropriate bidding strate gies for a sequence of auctions offering resources of interest. We briefly describe a discrete dy namic programming model for constructing ap propriate bidding policies for resources exhibit ing both complementarities and substitutability. We then introduce a continuous approximation of this model, assuming that money (or the nu meraire good) is infinitely divisible. Though this has the potential to reduce the computational cost of computing policies, value functions in the transformed problem do not have a convenient closed form representation. We develop grid based approximations for such value functions, representing value functions using piecewise lin ear approximations. We show that these methods can offer significant computational savings with relatively small cost in solution quality.\n1 Introduction\nA great deal of attention has been paid to the development of appropriate models and protocols for the interaction of agents in distributed and multiagent systems (MASs). Of ten agents need access to specific resources to pursue their objectives, but the needs of one agent may conflict with those of another. A number of market-based approaches have been proposed as a means to deal with resource alloca tion and related problems in MASs [6, 20, 22]. Of particu lar interest are auction mechanisms, where each agent bids for a resource according to some protocol, and the alloca tion and price for the resource are determined by specific rules [14]. Auctions have a number of desirable properties as a means for coordinating activities, including minimiz-\ning the communication between agents and, in some cases, guaranteeing Pareto efficient outcomes [14, 22].\nIn order to effectively make use of market mechanisms, an agent must be aware of the resources it needs, their value, and how best to obtain them. In sequential decision making under uncertainty, an agent will typically consider a number of potential courses of action and settle on one with high est expected utility. However, when different courses of ac tion require different collections of resources to be imple mented, an agent must develop rational bidding strategies in order to obtain the most desirable resource sets. In many cases, these resources will be made available by different sellers at different times and at uncertain prices. As a con sequence, optimal bidding behavior in a sequence of auc tions is of considerable interest. Of course, similar consid erations apply to other forms of market interaction as well: what resources should be purchased, at what prices, at what time, what portion of the budget should be set aside for spe cific resources, and so on.\nIn the setting described above, an agent often requires sev eral resources (a resource bundle) before pursuing a par ticular course of action. Obtaining one resource without another-for example, being allocated trucks without fuel or drivers, or processing time on a machine without skilled labor to operate it--makes that resource worthless. Such re sources are said to exhibit complementarities. Furthermore, resource bundles are generally substitutable: obtaining the bundle needed to pursue one course of action can lower the value of obtaining another, or render it worthless. For in stance, once trucks and drivers are obtained for transporting material in an optimal fashion, helicopters and pilots lose any value they may have had.\nComplementarities and substitutability complicate the pro cess of bidding on resources. A key difficulty that arises in the sequential model is how an agent computes bids for in dividual resources. An agent has a valuation for a particular resource bundle b = { r1, \u00b7 \u00b7 \u00b7 , rk}, but has no independent assignment of value to the individual resources. While auc tion theory can tell us how an agent should bid as a function of its valuation of resource r; for specific auction mecha nisms [ 14], in our setting no such valuation exists. If b is\n82 Boutilier, Goldszmidt, and Sabata\nworth v(b), how is an agent to \"distribute the value\" among the resources r; in order to compute bids?1 In earlier work [3], we described a sequential auction model and a dynamic programming algorithm for constructing op timal bidding policies when agents valued bundles that ex hibited the type of complementarity and substitutability that arises in sequential decision models. Specifically, assum ing resources are auctioned in a known order, we modeled the bidding problem as a Markov decision process (MOP), and described how an agent could construct an optimal bid ding policy for the sequence of auctions based on its val uations of different resource bundles. Agents can choose how much (and whether) to bid for a resource depending on past successes, failures, prices, and so on. Unfortunately, the number of bids available at any point in time is gener ally very large. Given any stated of the agent's endowment (say, measured in dollars), the agent can bid any amount less than d for the good in question. Since endowments can usually be divided quite finely, this induces very large state and action spaces, causing computational difficulty for dis crete dynamic programming. While the complexity of the algorithm grows only linearly in the size of the endowment, large endowments, or endowments that are finely divisible, often cause greater computational difficulty than the num ber of resources under consideration, inducing MOPs with very large state and action spaces.\nIn this paper, we investigate continuous approximations of this model, allowing an agent's endowment and set of pos sible bids to vary continuously. While this clearly expands the state and action spaces, we do this in the hope of us ing continuous function maximization methods to choose optimal bids. Once again, difficulties arise because value functions in this model generally do not have a conve nient closed fonn representation. To deal with this, we in troduce grid-based approximation methods for computing value functions. In particular, we sample the value func tion at specific points in state space (at various endowment levels) and use linear interpolation to detennine the value function at other points in state space. This is similar in spirit to the use of grid-based methods for approximating value functions (w.r.t. belief space) in partially observable Markov decision processes [4, II, 13, 12]. We show that the piecewise linear (PWL) value functions constructed in this fashion approximate the true value functions for the se quential bidding problem quite closely in many instances, while requiring considerably less computational effort.\nThe remainder of the paper is organized as follows. In Sec tion 2 we describe the basic resource allocation problem un der consideration and review the MDP model of this prob lem and the DP algorithm for bidding policy construction of [3]. In Section 3 we describe a continuous approximation of the discrete MDP, where endowment is treated as a contin uous component of state space and the action space (pos-\n1 \ufffdompl\ufffdmenta\ufffdties are often a\ufffddressed l!nder the guise of combmatonal and Simultaneous auctwns; we d1scuss these briefly in Section 6.\nsible bids) is similarly treated continuously. We describe a fixed-grid method for approximating the value functions in the continuous MDP that constructs piecewise linear ap proximations of the value functions, and whose error can be bounded a posteriori. In Section 4 we describe empir ical results using the fixed grid approximation. We show that computing value functions at a small number of sam ple points and interpolating can offer significant computa tional savings in constructing value functions and the in duced policies, yet often provides very good approxima tions to both the optimal value function and optimal policy. We also demonstrate that, as expected, increased grid den sity offers better solution quality at higher computational cost, allowing anytime tradeoffs to be addressed within our model. In Section 5, we briefly describe two variable grid methods for value function approximation that introduce grid points into the approximation in places estimated to provide highest reduction in approximation error. We con clude in Section 6 with a discussion of related work and sug gestions for future research.\n2 The Discrete DP Model\n2.1 Resource Allocation Problems\nWe assume we have a finite collection of agents, all of whom require resources from a pool of n resources R = {r1, \u00b7 \u00b7 \u00b7, rn}. We denote by Rt the subset {r1, \u00b7 \u00b7 \u00b7, rt}, t :::; n, with R0 = 0 by convention. We describe the quantities relevant to a specific agent a, since our focus in the paper is on the computation of policies for a fixed agent. Agent a can use exactly one bundle b; = { rL \u00b7 \u00b7 \u00b7, rtb'l} of resources from a set of k possible bundles: B = { b1, ... , bk}. We de note by U = UB the set of useful resources for our agent. Generally, a need only worry about the properties (e.g., ex pected prices and demand) of resources in this set. 2 For this reason, we take U to be identical to R (possibly by ignoring irrelevant resources in R).\nAgent a bas a positive valuation vW) for each resource bundle b' E B. This may, for instance, reflect the expected value of some course of action which requires the resource in b'. Suppose the holdings of a, h \ufffd R, are those resources it is able to obtain. The value of these holdings is given by v(h) = max{ vW) : b; \ufffd h }; that is, the agent will be able to use the resource bundle from among those it holds in entirety with maximal value, with the others going unused. This is consistent with our interpretation given in Section I where resource bundles correspond to alternative plans for achieving some objective.3 We denote by 1i the set of pos sible holdings (i.e., 1i = 2R).\n2This is not true when demand for elements of U is correlated with that for other resources. We do not address this possibility in this paper (see [3]).\n3 Our model can be extended to deal with bundles that stand in more general subadditiverelations than the complete substitutabil ity described here (though all such relations could be represented in the form described here with simple transformations). We keep this assumption for ease of presentation.\n-;\nThe resources R of interest to a will be auctioned off se quentially in a fixed, known order: without loss of gener ality, we assume that this ordering is r1, r2, \u00b7 \u00b7 \u00b7 , rn We use A; to denote the auction for r;. Agent a is given an initial endowment e of some common numeraire good (we'll use dollars) which it can use to obtain resources. At the end of the round, a has holdings h and d dollars remaining from its endowment.4 We assume that the utility of being in such a state at the end of the round is given by v (h) + f (d), where f is some function attaching utility to the unused portion of the endowment. Other utility functions could be consid ered, but this form is often suitable. There are a wide range of options one could consider when instantiating this framework, with regard to the type of auc tions used, the information provided to agents, and so on (see [3] for more on this). We assume that the individual auctions will be first-price, sealed-bid--each agent will pro vide a single bid and the highest bidder will be awarded the resource for the price bid. We adopt this model because of the ease with which it fits with our sequential model for bid computation; however, we believe our model could be adapted to other auction protocols as well as to other forms of market interaction. We also assume that bids are dis crete (integer-valued): that is, bids are not arbitrarily di visible. Additionally, we assume that agents, once obtain ing a resource, cannot resell that resource to another agent. This, of course, means that an agent may obtain one re source r;, but later be unable to obtain a complementary resource r;+k\u2022 essentially being \"stuck\" with a useless re source r;. We do this primarily for simplicity, though in cer tain settings this assumption may be realistic. We are cur rently exploring more sophisticated models where agents can \"put back\" resources for re-auctioning, or possibly re sell resources directly to other agents. Finally, we assume that agent a believes that the highest bid that will be made for resource r;, excluding any bid a might make, is drawn from some unknown distribution Pr;. Because bids are integer-valued, this unknown distribution is a multinomial over a non-negative, bounded range of integers.5 We make two remarks on this model. First, if the space of possible bids is continuous, a suitable continuous PDF (e.g., Gaussian) could be used to model bid distributions (and uncertainty about the parameters of this PDF, if neces sary). Second, we make an implicit assumption that bids for different resources are uncorrelated. By having indepen dent distributions Pr; rather than a joint distribution over all bids, agent a is reasoning as if the bids for different re sources are independent. When resources exhibit comple mentarities, this is unlikely to be the case. For instance, if someone bids up the price of some resource r; (e.g., trucks),\n4 If speculation or reselling is allowed, there is the possibility that d > e, depending on the interaction protocols we allow. We ignore this possibility here.\n5 We assume that some reasonable bound can be placed on the highest bid. In [3] we represent a's uncertainty over the parame ters of this distribution with a Dirichlet distribution. The expected values of these parameters can be used here without difficulty.\nContinuous Value Function Approximation 83\nthey may subsequently bid up the price of complementary resource ri (e.g., fuel or drivers). If agent a does not ad mit a model that can capture such correlations, it may make poor bids for certain resources. Once again, we make this assumption primarily for ease of exposition. Admitting cor relations does not fundamentally change the nature of the algorithms to follow, though it does raise interesting mod eling and computational issues [3].\n2.2 Computing Bids by Dynamic Programming\nThe difficulty in computing bids for the sequential auctions A; lies in the fact that the agent does not have a specific valuation for any individual good; rather, it has valuations over bundles. This suggests an agent should compute a bidding policy in which bids for specific resources are conditioned on the outcomes of previous auctions. In [3] we model this problem as a fully observable MDP [ 16, 2]. The computa tion of an optimal bidding policy can be implemented using a standard stochastic dynamic programming algorithm such as value iteration. We briefly recap this model below. As we will point out later in this section, optimal policy con struction may be computationally intensive. The main goal of this paper to examine specific approximations to ease this burden. However, this dynamic programming model deals with the complementarities and substitutability inherent in our resource model; no special devices are required. Fur thermore, it automatically deals with issues such as uncer tainty, dynamic valuation, \"sunk costs,\" and so on. Finally, we stress that given stationary, uncorrelated bid distribu tions, the computed policy is optimal. We assume the decision problem is broken into n+ 1 stages, n stages at which bidding decisions must be made, and a terminal stage at the end of the round. We use a time index 0 \ufffd t \ufffd n to refer to stages--time t refers to the point at which auction At+! for rt+1 is about to begin. The state of the decision problem for agent a at time t is given by two variables: h1 C R1, the subset of resources R1 held by agent a; and d1, the dollar amount (unspent endowment) available for future bidding. We write (h, d)1 to denote the state of a's decision problem at timet. The dynamics of the decision process can be characterized by a's estimated transition distributions. Assuming that prices are drawn independently from the stationary distribu tions Pr;, agent a can predict the effect of any action (bid) z available to it. If agent a is in state (h, d)1 at stage t, it can bid for rt+l any amount 0 \ufffd z \ufffd d1\u2022 Letting w denote the highest bid offered by other agents, if a bids z at timet, it will transition to state (h U {r1+1},d- z)\nt+1 with proba bilityPr1+1(w < z) and to(h,d)1+1 withPrt+1(w \ufffd z).6 The final piece of the MDP is a reward function q. We simply associate a reward of zero with all states at stages 0 through n - 1, and assign reward v(h) + f(d) to ev ery terminal state (h, d)\". A bidding policy 1r is a map-\n6For expository purposes, the model assumes ties are won. Several rules can be used for ties; none complicate the analysis.\n84 Boutilier, Goldszmidt, and Sabata\nping from states into actions: for each legal state (h, d)1, 1r( (h, d)1) = z means that a will bid z for resource rt+l\u00b7 The value V\" ( (h, d)1) of policy 1r at any state (h, d)1 is the expected reward E,..(q( (h, d)\") l(h, d)1) obtained by ex ecuting 11\". The expected value of 1r given the agent's initial state (0, e)l is simply V\" ( (0, e)1). An optimal bidding pol icy is any 1r that has maximal expected reward at every state.\nWe compute the optimal policy using value iteration [ 16], defining the value of states at stage t using the value of states at stage t + 1. Specifically, we set\nV((h,d)\") = v(h) + f(d)\nand define, for each t < n:\nPr1+1(w < z) \u00b7 V((h U {rt}, d- z)1+1) +Pr1+1(w? z) \u00b7 V((h, d)1+1) (!) maxQ( (h, d)1, z) (2) z\ufffdd be extended to allow for equilibrium computation. How ever, there are several reasons for using the approach de scribed above rather than a full Bayes-Nash equilibrium model [21]. First, equilibrium computation is often infea sible, especially in a nontrivial sequential, multi-resource setting like ours. Second, the information required on the part of each agent, nan1ely a distribution over the possible types of other agents, is incredibly complex--an agent type in this setting is its valuations for all resource bundles, mak ing the space of types unmanageable in general. 7 Finally, the common knowledge assumptions usually required for equilibrium analysis are unlikely to hold in this setting. Our model is thus more akin to limited rationality models (e.g., fictitious play [5, 9]), in particular, when agents attempt to learn bid distributions over time [3]. A consequence of this approach is that, in early rounds, allocations may not be effi cient. However, learning behavior tends to lead to efficient outcomes after some number of rounds, and often leads to optimal allocations (with respect to social welfare) [3]. V( (h, d)1)\n11\"( (h, d)1) = argmaxQ((h,d)1,z) z\ufffdd\n(3) 3 Continuous Approximations of Bids and Endowments\nWith V defined for all stage t + 1 states, Q ( ( h, d) 1 , z) de notes the value of bidding z at state (h, d)1 and acting op timally thereafter. V ( ( h, d?) denotes the optimal value at state ( h, d) 1, while 1r ( ( h, d) 1) is the optimal bid. Implementing value iteration requires that we enumerate, for each t, all possible stage t states and compute the con sequences of every feasible action at that state. This can re quire substantial computational effort. While linear in the state and action spaces (and in the number of stages n ), the state and action spaces themselves are potentially quite large. The number of possible states at stage t could poten tially consist of any subset of resources R1 together with any monetary component. The action set at a state with monetary component d has size d + 1. Fortunately, we can manage some of the complexity associated with various re source combinations by using certain pruning and general ization strategies; a number of these are described in [3].\nReducing the impact of the number of possible bids is more difficult. We can certainly restrict the state and action space to dollar values no greater than a's initial endowment e. If the PDF is well-behaved (e.g., concave), pruning is pos sible: for instance, once the expected value of a larger bids starts to decrease, search for a maximizing bid can be halted. Another method for dealing with this is to assume that endowment and bids are continuous. We turn our at tention to this strategy in the next section.\nWe point out that the model described above does not al low for strategic reasoning on the part of the bidding agent. The agent takes the expected prices as given and does not attempt to compute any form of equilibrium. The motiva tion for this model is described in more detail in [3]: briefly, we assume there that the price models will be adjusted over time with the aim of converging to some form of equilib rium. We expect that the MDP model described here could\nWhen an agent's initial endowment is large or finely divisible, value iteration can be computationally expensive. For instance, given an endowment of$! 0,000 which can be bid in $1 increments, the state space of the MDP has size 10,000 \u00b7 11il and the action space has size 10,000. An en dowment of $100 with penny increments is just as large. In order to deal with the computational complexity incurred by such endowments, we assume that endowments and bids are continuous-valued. This allows us to use continuous opti mization methods to compute optimal bids as a function of the state and represent our value functions in a continuous fashion. In Section 3.1 we describe the continuous MDP, while in Section 3.2 we present a fixed-grid, approximate representation for value functions, and show how to solve the MDP using this representation.\n3.1 Continuous Version of the MDP\nViewing money as continuous requires that we make the following adjustments to the MDP described in Section 2. At any state where the agent's remaining endowment is d, the agent can consider bids in the interval [0, d); and given a maximum endowment m, state space ranges over any en dowment value in the interval [0, m] . Note that the state spaceS = 1i x [0, m] has both a discrete and continuous component. Since bids are now continuous, we assume the agent models the high bid distributions using a continuous density function. We generally assume that simple paranlet ric distributions or mixtures are used for this purpose (e.g., in Section 4, we use Gaussian bid distributions). Value functions in the discrete MDP presented in the last section are represented as a table of values. With\n7We use type here in the sense used in game theory for games with incomplete information (15].\nContinuous Value Function Approximation 85\nthe hybrid MOP-containing both continuous and discrete ,,...----\ufffd-\ufffd--\ufffd--\ufffd--\ufffd---, components--we represent a value function V1 as a table of continuous functions. For each resource holding h \ufffd R1, we define the one-dimensional, continuous function Vt (d) == V1 ( ( h, d)); that is, Vt describes how V1 varies with remaining endowment for a fixed set of holdings h.\nIn order to implement OP with the continuous dimension in the state space, we require some manageable represen tation for the continuous value function components Vt. At stage n (i.e., with zero stages to go), V,:' (d) is simply equal to q( (h, d)); since the reward function is specified in a suitable form, vhn will have a tractable form for each h \ufffd R. For instance, if our agent has linear utility for remain ing endowment-that is, if q((h, d)) == v(h) +ad-then vhn can be represented with two parameters. Constructing v: -1 requires that we backup values through possible bids (actions) as in Equation (I) and then choose the bid with highest Q-value to determine Vhn-1 as in Equation (2). For any specific state (h, d), the computation of v:-1 (d) is not problematic. Equation (2) requires that we find the bid z that maximizes Q((h, d)n-1, z) . As long as the re ward function is monotonically increasing with remaining endowment and the probability of winning a resource in creases with higher bids (and both are well-behaved), it is easy to see that the Q-function has a unique maximum. Thus the corresponding constrained maximization problem is easy to solve. The difficulty lies in the fact that we can not compute the value function at the infinitely many states (varying with possibly endowment). In general, the value function vhn-l will not have a convenient closed form, nor will vt for any t < n. To circumvent this difficulty, we adopt a grid-based ap proach to approximating the continuous (component) value functions at each stage. This method of approxima tion is fairly common in representing value functions in continuous-state MOPs. Continuous domains are studied quite frequently in reinforcement learning (RL ), and arise in the conversion of POMOPs to belief state MOPs. In fact, the grid-based approach to computing value functions for PO MOPs is a commonly used approximation technique [4, 11, 13, 12]. Unlike belief state MOPs (which have an n - !-dimensional state space, where n is the number of system states) or many multi-dimensional control and RL problems, our domain has only one continuous dimension. As such, we are not affected by the curse of dimensional ity that often plagues grid-based approximation methods in other areas: increasing the density of our grid causes only a linear increase in required computational effort.\n3.2 A Uniform Fixed Grid Approach\nLet us assume that we are given some representation of the continuous value function components Vt for each h \ufffd R1\u2022 Our grid-based approaches to computing an approximation of v\ufffd-1 all work as follows. First, a set of grid points is chosen: these form a small sample of the possible remain-\n\"\nFigure I: Uniform grid approximation: the solid line repre sents the true value function, the dashed line an approxima tion using a coarse grid, and the dotted line an approxima tion using a fine grid.\ning endowments d at stage t - 1. These grid points are cho sen over the interval (0, m] (where m is the maximum initial endowment), and we assume that both 0 and m are among the set. Let there beg such points: 0 == d1 < d2 < \u00b7 \u00b7 \u00b7 < dg == m. At each such point d;, we compute v;-1(d;) us ing \ufffdquation (2): \ufffde \ufffdote again that this is a fairlr \ufffdoutine contmuous maxuruzatwn problem, and that Q1- ts con structed using the given functions V\ufffd. If each V\ufffd is correct, then we have computed the exact value function v;-1 at these grid points. We define v;-1 over the entire endow ment range using linear interpolation. For any endowment d, let di \ufffd d \ufffd di+1\u2022 We set"}, {"heading": "The interpolation process is illustrated in Figure I for two", "text": "different grid granularities. Note that v;-1 (d) is an approx imation to the true value v;-1 (d) in the hybrid MOP. Our uniform, fixed grid approach to value function compu tation assumes that a fixed grid is specified in advance, with\ng grid points uniformly covering the interval (0, m]. This grid is not adjusted during computation, nor does it vary across stages or across different states (with different hold ings h). Specifically, the steps above are repeated at each stage: V\ufffd ( d;) is computed at each grid point d; with re spect to the approximate value functions v\ufffd+1; and v\ufffd is defined at all remaining points by interpolation over the val ues V\ufffd ( d;) at the grid points. The grid-based approach allows one to determine a poste riori bounds in the error in the value function. Suppose that we are given an accurate t+ !-stage value function V1+1 (so that v;+1 (d) is correct for all hand all d). Because we com-\npute V\ufffd ( d;) exactly at each grid point d;, we are assured that the resulting approximate value function v\ufffd is correct at each of these grid points (for all h). Now consider the difference in value of = V\ufffd(di+l)- V\ufffd(d;) between any two consecutive grid points d; and d;+l\u00b7 Since the value function is monotonically increasing with endowment (for any reasonable utility function), this difference is positive. Furthermore, the error in the approximate value function V\ufffd on the interval [ d; , di+ 1] must be bounded by this difference of. To see this, see the extreme value function candidate illustrated in Figure 2 between grid points d1 and d2\u2022 For any h \ufffd R1, define oh = max;<g of, and for any stage t define cf(V1) = maxhcR\u2022 cfh. This maximum value differ ence bounds the error in the estimated value function V1: Proposition 1 Let approximate value function V1 be gen erated (for all h \ufffd R1) with a .fixed grid approach, using the exact valuefunction vt+l. Then IIV1- V1ll < o(V1).\nOf course, we generally construct V1 using an approxima tion vt+l ofvt+l' thus the errors can accumulate; but they do so in an additive fashion.\nProposition 2 If the continuous MDP for sequential auc tions (with n stages) is solved using a fixed grid approxi mation, then\nfor all t :5 n.\nn\nIIVt- Vtll < 2: o(V;) i=t+l\nWe note that these bounds, while tight theoretically, are generally not reached in practice, as we shall see in the next section. Error as large as this can only be reached for value functions that behave very badly. Finally, using standard ar guments regarding how error in value functions manifests\nitself in behavioral error, we note that the difference in value of the (greedy) policy induced by the approximate value function and the optimal policy is bounded by twice the er ror in the value function.\n4 Empirical Evaluation\nWe have implemented the dynamic programming algorithm for sequential auctions in Matlab, and have experimented with the approximation of value functions using sampled, continuous functions. We performed 20 experiments each consisting of four runs. Each experiment comprises the computation of a bidding policy for an agent requiring four bundles of resources drawn from a set of ten potentially use ful resources. The number of resources per bundle was gen erated from a Gaussian distribution with mean 3 and vari ance I. The valuation for the bundles was also generated from a Gaussian with mean 15 and variance 2, while the es timated bid distributions were Gaussians with means in the range of3 to 6 for different resources and variance of 0.5. The utility function used is v(h) + 0.7d (so remaining en dowment is valued at 70 cents to the dollar).8 The four runs in each experiment differ on the number of samples used in the approximation. One of the runs, which we identifyasDiscrete, consists of an initial endowment of $30, with bids that can be incremented discretely in $ 1 units. The dynamic program computing the bidding policy of the agent is based on the algorithm described in section 2.2. Since there are no approximations involved, this run is our \"gold standard\" against which we compare the approx imations produced by the fixed grid methods. The optimal value function at the initial state in the Discrete model (i.e., expected value obtained in the sequence of auctions) tended to lie between 25 and 33 for the 20 different trials. 9 The remaining three runs consist of the fixed grid strategy with continuous bids, using 5, 10, and 15 sample points, and are denoted as G5, GlO, and Gl5, respectively. We use several pruning techniques to reduce the number of states (i.e., different resource combinations considered at different stages). This influences both the computation time and the reporting of the errors. Since in a large number of these states the best policy is to bid zero (e.g., given the current resources it will be impossible to complete a bundle with the resource being auctioned), considering all of these states in error computation conveys misleading average er ror statistics (our approximations would look too good). By eliminating these states, we report on a more meaningful measure of error between the optimal result and our approx imations. In addition, we report relative error results rather than absolute error (scaling relative to the magnitude of the true value at each point). Errors reported are squared differences using ( \u2022 \ufffd \u2022 ) 2, where e is the estimated value using\n8Discounting endowment is simply a convenient way to raise the relative values of all bundles uniformly.\n9This is higher than the expected value of not competing for resources, which has a value of21 (= 0.7 \u00b7 30).\nContinuous Value Function Approximation 87\n\u2022. ...\n] \"' ] 1 \" l\n0.15\n\"\"\n\u00b7-\nTable 1 provides the summary of the number of states ex plored by each method, the mean error in the value func tion, the mean error in the \"optimal\" policy induced by the corresponding value function, and the maximum error in the value function and induced policy. These are computed (av eraged or maximized) over all (unpruned) states in all stages of the dynamic program. The numbers reported are the av erages over the 20 experiments. As can be seen, we have a reduction in error (both in the value function and the induced policy) as we increase the number of sample points in the grid. Also there is an ex pected (linear) increase in computational effort as we in crease the number of sample points. These results strongly suggest that with a fraction of the computational effort ( 5 grid points) we can obtain decent approximations to the value function and the optimal policy. Notice also that the error in induced behavior is generally smaller than the er ror in the approximate value function. This is because the incorrect value function still induces optimal bids at many states. The number of states explored by the approxima tions is a fraction of the the number required by the origi nal, accurate model, but the computation per stage is some times more. To display the average and maximum errors in the value function at different stages of the bidding process, we compute the average error over all (unpruned) states at each stage and over all 20 experiments. Figure 3 shows this stage-by-stage error (mean and maximum) in the val\ufffde function, while Figure 4 shows the stage-by-stage error m\n5 Variable Grid Approaches\nOne difficulty with the fixed grid approach is that compu tational effort is sometimes spent computing values at grid points that do not improve the accuracy of the PWL approx imation of the value function, while candidate grid points that could reduce the error substantially are ignored. In the experiments described above, this was sometimes ob served to be the case. For this reason we consider several variable grid strategies which introduce grid points dynam ically based on some measure of the likely improvement they will make in the value function estimate.\nMethod VG 1: Based on the error analysis above, one way to ensure that the maximum error is reduced as much as pos sible with as few grid points as possible is to introduce grid points in those intervals that have the largest maximum er ror. Variable grid method VGl does just this. We assume that we have a set of grid points d 1, \u00b7 \u00b7 \u00b7 dn whose values V\ufffd ( d;) have been computed. (Initially, we assume that we have grid points at endowment level 0 and endowment level m, the maximum). For each consecutive pair of grid poin\ufffds, the difference in value v\ufffd ( d; +I)-v\ufffd ( d;) computed. A grid point is introduced at the midpoint between that pair of grid points whose value difference is the largest. This contin ues until some maximum number of grid points has been introduced or the maximum value difference between any pair of adjacent grid points falls below some threshold. We know that the error in our approximation v\ufffd is bounded by\n88 Boutilier, Goidszmidt, and Sabata\nthis maximum difference (as described in the previous sec tion). This adaptive grid method improves this error bound the fastest fashion possible.\nFigure 5 illustrates this method of introducing grid po\ufffdnts. Here the grid point d5 is introduced rather than d4 smce Vi(da)- Vi(d2) is larger than Vi(d2)- Vi(dl). Choos ing the maximum value difference can be implemented very quickly using a priority queue: the pair of adjacent grid points with the maximum value difference is popped off the queue, and the two new intervals created by the insertion of a new grid point are added to the queue using the value dif ference as a key.\nMethod VG2: One difficulty with method VGI is that a lot of effort can be expended introducing grid points that have no real effect on the value function estimate. Specifically, if there is a segment of the value function that is actually lin ear, the introduction of a grid point in that region does not improve our estimate.1\u00b0 For instance, adding a new point between d5 and d3 in the example above might improve the guaranteed error bound by the largest amount. But since\n_ it\nlies on a linear segment, it doesn't reduce the actual error m\n10 Because we often adopt a linear utility component for r\ufffdmain ing endowment at the end of the round of aucttons (see Sectton 4), such linear segments arise rather frequently.\nthe value function estimate at all. Introducing a point else where (e.g., at d4, or between d2 and ds) would be a more effective use of computational resources.\nTo capture this intuition, we say that the error reduction of fered by the introduction of grid point ds is the absolute difference between Vi ( ds) (which we computed when that grid point was introduced) and the previous predicted value for d5 before the introduction of the point (that is, it's pre dicted value using the linear segment from d2 to da). If the introduction of d5 caused a small reduction in error, this suggests that introducing points on either side of it may \ufffdot be useful in reducing error. Another method of measunng this is by exanlining the angles between the linear interpo lates. If the angle is close to 180\u00b0, then adding new points will not improve the accuracy significantly. The closer the angle is to goo, the greater the odds of improving the error by introducing new grid points.\nOur second variable grid method, VG2, requires the intro duction of pairs of grid points at each iteration. Suppose we have grid points d1, \u00b7 \u00b7 \u00b7dn whose values Vi(d;) have been computed. Whenever a grid point is introduced, we compute its error reduction factor (ERF): the difference be tween its computed value and the value it was predicted to have just before it was introduced as a grid point. We keep une.xpanded grid points ordered in a priority queue, sorted according to their ERFs. When the grid point d; with the largest ERF is removed from the queue, it is considered expanded. Expanding a grid point d; requires that we in troduce two new grid points: one that bisects the interval [d;_1, d;]; and one that bisects the interval [d;, d;:+-d\u00b7 Th\ufffdse two new grid points are added to our value functiOn \ufffdd m serted into the priority queue for subsequent expansiOn.\nThis second method works extremely well when value functions have large linear segments. In Figure 6, we see that after the introduction of d4 and ds surrounding da, the error reduction factor of d4 is close to zero, since it lies on a linear segment between d3 and dz. The ERF fords is shown by the arrows, and is greater; so we introduce points d6 and d7 surrounding d5, ignoring further splitting of the interv\ufffdls around d4. Notice that we can \"fool\" this method. If we m-\nd5 d7 d8 d2 Endowment\nd4\nFigure 6: Variable Grid Method VG2 dl\ntroduce a grid point d8 between d7 and d2 (in the middle of the \"S-shaped\" portion of the value function), we compute a \ufffdery small ER! for ds; this is misleading since new grid pomts surroundmg d8 would be very useful. While poten tially problematic, such circumstances seem to arise rarely, at least in preliminary experimental evaluation.\nOne could introduce a number of other variable grid gener ation techniques. While the two methods described above are intuitively appealing and easy to implement (and have low computational cost), others may be well-suited to dif ferent types of problems or different utility functions. We have not yet experimented with these techniques in depth. We note that the error bounds derived for the fixed grid method above apply directly to variable grid methods as well. Given a set of variable grid points, the error in the value function approximation can be bounded by the cS; fac tors (the maximum differences in values at consecutive grid points).\n6 Concluding Remarks 6.1 Related Work\nAuctions involving complementary goods have been stud ied widely, though it is unknown whether simple selling mechanisms can lead to efficient outcomes [1, 22]. Two methods for dealing with complementarities have been studied in some depth in the literature: simultaneous auc tions for multiple goods [1, 18); and combinatorial auc tions in which agents submit bids for resource bundles [ 17, 19, 22] .\n. Neither of these models is suitable in the setting\nwe constder, when resources are made available at different points in time or are offered by different sellers.\nEven in settings where the requirements of combinatorial or simultaneous auctions are met---<>r could be enforced--a sequential model has some attractive features. Unlike com binatorial models, it relieves the (computational) burden of d\ufffdte\ufffdn.ing a final a.llocation from the seller, effectively dtstnbutmg computatiOn among the buyers (as in the simul t\ufffdeous case). This can be important, as determining an op timal allocation (maximizing the seller's revenue) is NP hard [ 19]. Our sequential model also has the advantage that\nContinuous Value Function Approximation 89\nbuyers are not required to reveal information about their valuations for specific resource bundles that they do not ob tain. Furthermore, it has greater flexibility in that agents can enter and leave the market without forcing recomputa tion of entire allocations. In contrast to simultaneous mod els, agents in the sequential model lessen their exposure. If an agent does not obtain a certain resource early in the se quence, it need not expose itself by bidding on complemen tary resources occurring later in the sequence. Agents are typically bidding in a state of greater knowledge in the se quential model, at least during later auctions.\nWhile bidding strategies for sequential auctions would seem to be an issue worthy of study, there appears to have been little research focused on this issue. What work ex ists (see, e. g., [8, 10)) tends to focus the seller's point of view-for example, will simultaneous or sequential sales maximize revenue--and does not address the types of com plementarities and substitutability we consider here.\n6.2 Summary and Future Directions\nIn this paper we reviewed a model for computing optimal sequential bidding policies for resources that exhibit com plementarities and substitutability, and described a contin uous approximation of the model. We presented several grid-based approximate representations for value functions, and described a dynamic programming algorithm that uses these PWL representations. While the resulting policies may not be optimal, we provided error bounds on the value functions and policies produced, and showed empirically that the fixed-grid method works quite well: it produces high quality value functions and policies with a small por tion of the computational effort required by an exact algo rithm. We also illustrated the \"contract anytime\" flavor of these algorithms: with denser grids (thus, more computa tional effort) one can produce higher quality policies.\nWe have not yet experimented with the variable grid ap proaches in detail. We expect these algorithms to outper form the fixed grid algorithm, especially in domains where linear utility for remaining endowment is adopted--this is due to the frequent linear segments exhibited by certain parts of the value function. It is also the case the general strategy of adopting PWL approximations is especially ap propriate when these linear utility fragments abound. We hope to explore other approximate representations that are suitable for other \"typical\" utility functions.\nThere are a number of other issues we hope to explore in the near future. One is the appropriate modeling of correlations in prices. As mentioned above, when goods exhibit comple mentarities, it is highly unlikely that prices will be uncorre lated. Modeling this simply requires that the agent maintain a joint distribution reflecting price expectations.11 The dif ficulty lies in strategy computation-when one price is ob se\ufffded, expected prices for future resources may change, re qumng a change in \"planned\" behavior. In other words, the\n11 Clearly, representations that exploit a certain amount of inde pendence can be used as well.\n90 Boutilier, Goldszmidt, and Sabata\ndecision problem is truly partially observable and requires some form of history-dependent policy [3].\nAnother avenue we hope to explore is the integration of the adaptive model explored in [3}--where prices are learned during multiple rounds of auctions-with the continuous approximation strategy used here. Note that to include adaptivity in the continuous model described in Section 3 requires only the update of the bid distributions, which for simple parametric forms and mixture models (e.g., Gaus sians) is a well-known process [7].\nFinally, we want to explore the deeper issues involved with integrating an agent's \"object-level\" sequential reasoning (i.e., the decision making in which the courses of action that consume resources are developed) with the type of mar ket reasoning described here. Specifically, we envision the emergence of very interesting policy patterns; for example, an agent might decide not to bid for resources until it exe cutes part of its plan because the uncertainty associated with that plan's outcome may make obtaining the resource too risky until it is more certain of the plan's outcome. A \"com pound MOP\" modeling all levels of reasoning seems to be an appropriate framework for thinking about such prob lems.\nAcknowledgements\nCraig Boutilier and Moises Goldszmidt acknowledge par tial support from the DARPA Co-ABS program (through Stanford University contract F30602-98C-0214). Bikash Sabata was funded by DARPA through the SPAWARSYSCEN under Contract Number N66001-97-C8525. Craig Boutilier was partially supported by NSERC Research Grant OGP0121843. We would like to thank Bill Walsh for his helpful comments, suggestions and pointers to relevant literature, as well as Yoav Shoham, Tuomas Sand holm and Mike Wellman for their comments and pointers.\nReferences\n[I] S. Bikhchandani and J. W. Marner. Competitive equi libria in and exchange economy with indivisibilities. J. of Economic Theory, 74:385-413, 1997.\n[2] C. Boutilier, T. Dean, and S. Hanks. Decision theo retic planning: Structural assumptions and computa tional leverage. J. Artif. Intel. Research, 1999. To ap pear.\n[3] C. Boutilier, M. Goldszmidt, and B. Sabata. Sequen tial auctions for allocation of resources with comple mentarities. IJCA/-99, Stockholm, 1999. To appear.\n[ 4] R. I. Brafinan. A heuristic variable-grid solution method for POMDPs. AAA/-97, pp.727-733, Provi dence, 1997.\n[5] G. W. Brown. Iterative solution of games by fictitious play. InT. C. Koopmans, ed., Activity Analysis of Pro duction and Allocation. Wiley, New York, 1951.\n[6] S. Clearwater, ed. Market-based Control: A Paradigm for Distributed Resource Allo cation. World Scientific, San Mateo, 1995.\n[7] R. 0. Duda and P. E. Hart. Pattern Classification and Scene Analysis. Wiley, New York, 1973.\n[8] R. Engelbrecht-Wiggans and R. J. Weber. A sequen tial auction involving assymetrically informed bid ders. Inti. J. Game Theory, 12:123-127, 1983.\n[9] D. Fudenberg and D. K. Levine. The Theory of Learn ing in Games. MIT Press, Cambridge, MA, 1998.\n[10] D. B. Hausch. Multi-object auctions: Sequential vs. simultaneous sales. Management Science, 32(12):1599-1610, 1986.\n[ 11] M. Hauskrecht. A heuristic variable-grid solution method for POMDPs. AAA/-97, pp.734-739, Provi dence, 1997.\n[12] C. C. White III and W. T. Scherer. Solutions pro cedures for partially observed Markov decision pro cesses. Operations Research, 37(5):791-797, 1989.\n[13] W. S. Lovejoy. Computationally feasible bounds for partially observed Markov decision processes. Oper ations Research, 39(1):162-175, 1991.\n[14] R. P. McAfee andJ. McMillan. Auctions and bidding. J. Econ. Lit., 25:699-738, 1987.\n[IS] R. B. Myerson. Game Theory: Analysis of Conflict. Harvard University Press, Cambridge, 1991.\n[16] M. L. Puterman. Markov Decision Processes: Dis crete Stochastic Dynamic Programming. Wiley, 1994.\n[17] S. J. Rassenti, V. L. Smith, and R. L. Bulfin. A com binatorial auction mechanism for airport time slot al location. Bel/J. Econ., 13:402-417, 1982.\n[18] M. H. Rothkopf. Bidding in simultaneous auctions with a constraint on exposure. Op. Res., 25:620-629, 1977.\n[19] M. H. Rothkopf, A. Pekec, and R. M. Harstad. Computationally manageable combinatorial auctions. Mgmt. Sci., 1998. To appear.\n[20] T. Sandholm. Limitations of the vickrey auction in computational multiagent systems. ICMAS-96, pp.299-306, Kyoto, 1996.\n[21] W. Vickrey. Counterspeculation, auctions, and com petitive sealed tenders. J. Finance, 16(1):8-37, 1961.\n[22] M. P. Wellman, W. E. Walsh, P. R. Wurman, and I. K. MacKie-Mason. Auction protocols for decentralized scheduling. (manuscript), 1998."}], "references": [{"title": "Competitive equi\u00ad libria in and exchange economy with indivisibilities", "author": ["S. Bikhchandani", "J.W. Marner"], "venue": "J. of Economic Theory,", "citeRegEx": "Bikhchandani and Marner.,? \\Q1997\\E", "shortCiteRegEx": "Bikhchandani and Marner.", "year": 1997}, {"title": "Decision theo\u00ad retic planning: Structural assumptions and computa\u00ad tional leverage", "author": ["C. Boutilier", "T. Dean", "S. Hanks"], "venue": "J. Artif. Intel. Research,", "citeRegEx": "2", "shortCiteRegEx": "2", "year": 1999}, {"title": "Sequen\u00ad tial auctions for allocation of resources with comple\u00ad mentarities", "author": ["C. Boutilier", "M. Goldszmidt", "B. Sabata"], "venue": "IJCA/-99, Stockholm,", "citeRegEx": "3", "shortCiteRegEx": "3", "year": 1999}, {"title": "Brafinan. A heuristic variable-grid solution method for POMDPs. AAA/-97, pp.727-733", "author": ["I. R"], "venue": "Provi\u00ad dence,", "citeRegEx": "R.,? \\Q1997\\E", "shortCiteRegEx": "R.", "year": 1997}, {"title": "Iterative solution of games by fictitious play", "author": ["G.W. Brown"], "venue": "ed., Activity Analysis of Pro\u00ad duction and Allocation", "citeRegEx": "5", "shortCiteRegEx": "5", "year": 1951}, {"title": "Pattern Classification and Scene Analysis", "author": ["R. 0. Duda", "P.E. Hart"], "venue": null, "citeRegEx": "7", "shortCiteRegEx": "7", "year": 1973}, {"title": "A sequen\u00ad tial auction involving assymetrically informed bid\u00ad", "author": ["R. Engelbrecht-Wiggans", "R.J. Weber"], "venue": "ders. Inti. J. Game Theory,", "citeRegEx": "8", "shortCiteRegEx": "8", "year": 1983}, {"title": "The Theory of Learn\u00ad ing in Games", "author": ["D. Fudenberg", "D.K. Levine"], "venue": null, "citeRegEx": "9", "shortCiteRegEx": "9", "year": 1998}, {"title": "Multi-object auctions: Sequential vs. simultaneous sales", "author": ["D.B. Hausch"], "venue": "Management Science,", "citeRegEx": "10", "shortCiteRegEx": "10", "year": 1986}, {"title": "A heuristic variable-grid solution method for POMDPs", "author": ["M. Hauskrecht"], "venue": "Provi\u00ad dence,", "citeRegEx": "Hauskrecht.,? \\Q1997\\E", "shortCiteRegEx": "Hauskrecht.", "year": 1997}, {"title": "Solutions pro\u00ad cedures for partially observed Markov decision pro\u00ad cesses", "author": ["C.C. White III", "W.T. Scherer"], "venue": "Operations Research,", "citeRegEx": "12", "shortCiteRegEx": "12", "year": 1989}, {"title": "Computationally feasible bounds for partially observed Markov decision processes", "author": ["W.S. Lovejoy"], "venue": "Oper\u00ad ations Research,", "citeRegEx": "13", "shortCiteRegEx": "13", "year": 1991}, {"title": "Auctions and bidding", "author": ["R.P. McAfee andJ. McMillan"], "venue": "J. Econ. Lit.,", "citeRegEx": "14", "shortCiteRegEx": "14", "year": 1987}, {"title": "Game Theory: Analysis of Conflict", "author": ["R.B. Myerson"], "venue": null, "citeRegEx": "Myerson.,? \\Q1991\\E", "shortCiteRegEx": "Myerson.", "year": 1991}, {"title": "Markov Decision Processes: Dis\u00ad crete Stochastic Dynamic Programming", "author": ["M.L. Puterman"], "venue": null, "citeRegEx": "16", "shortCiteRegEx": "16", "year": 1994}, {"title": "A com\u00ad binatorial auction mechanism for airport time slot al\u00ad location", "author": ["S.J. Rassenti", "V.L. Smith", "R.L. Bulfin"], "venue": "Bel/J. Econ.,", "citeRegEx": "17", "shortCiteRegEx": "17", "year": 1982}, {"title": "Bidding in simultaneous auctions with a constraint on exposure", "author": ["M.H. Rothkopf"], "venue": "Op. Res.,", "citeRegEx": "18", "shortCiteRegEx": "18", "year": 1977}, {"title": "Computationally manageable combinatorial auctions", "author": ["M.H. Rothkopf", "A. Pekec", "R.M. Harstad"], "venue": "Mgmt. Sci.,", "citeRegEx": "19", "shortCiteRegEx": "19", "year": 1998}, {"title": "Limitations of the vickrey auction in computational multiagent systems", "author": ["T. Sandholm"], "venue": "ICMAS-96, pp.299-306,", "citeRegEx": "20", "shortCiteRegEx": "20", "year": 1996}, {"title": "Counterspeculation, auctions, and com\u00ad petitive sealed tenders", "author": ["W. Vickrey"], "venue": "J. Finance,", "citeRegEx": "21", "shortCiteRegEx": "21", "year": 1961}, {"title": "Auction protocols for decentralized scheduling", "author": ["M.P. Wellman", "W.E. Walsh", "P.R. Wurman", "I.K. MacKie-Mason"], "venue": "(manuscript),", "citeRegEx": "22", "shortCiteRegEx": "22", "year": 1998}], "referenceMentions": [], "year": 2011, "abstractText": "Market-based mechanisms such as auctions are being studied as an appropriate means for re\u00ad source allocation in distributed and multiagent decision problems. When agents value resources in combination rather than in isolation, they must often deliberate about appropriate bidding strate\u00ad gies for a sequence of auctions offering resources of interest. We briefly describe a discrete dy\u00ad namic programming model for constructing ap\u00ad propriate bidding policies for resources exhibit\u00ad ing both complementarities and substitutability. We then introduce a continuous approximation of this model, assuming that money (or the nu\u00ad meraire good) is infinitely divisible. Though this has the potential to reduce the computational cost of computing policies, value functions in the transformed problem do not have a convenient closed form representation. We develop grid\u00ad based approximations for such value functions, representing value functions using piecewise lin\u00ad ear approximations. We show that these methods can offer significant computational savings with relatively small cost in solution quality.", "creator": "pdftk 1.41 - www.pdftk.com"}}}