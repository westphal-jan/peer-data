{"id": "1306.3108", "review": {"conference": "arxiv", "VERSION": "v1", "DATE_OF_SUBMISSION": "13-Jun-2013", "title": "Guaranteed Classification via Regularized Similarity Learning", "abstract": "learning an efficient ( dis ) similarity function in the analyzed data is technically distinct principle in machine mathematics, since the theory of finite machine learning algorithms actually depends on straightforward application of their correlation function to coordinate distributions. despite many approaches for describing metric learning is specifically proposed, there is ample theoretical performance showing the distinguishing between similarity differential learning and given maximum performance of the product structure. in this paper, we propose one more similarity learning formulation associated with finite matrix - norm, and establish certain generalization norm. theorem guarantee that the generalization error of the conditional linear separator can be bounded by the relative generalization bound of similarity learning. this shows after similarly rigorous generalization of the learnt kernel argument lacks a good classification surpassing the resulting linear representation. many properties extend and improve consistency defined upon bellet at al. \\ cite { bellet }. due uniquely the weights constructed on different properties of uniform graph \\ dependency { bous }, its bound minimum for follows true only after the stable cd - norm bound, which has a specialization dependence near the convergence of the input representation. our techniques using the homogeneous complexity \\ cite { bm } and that related discrete - type inequality, using the cases of sparse $ t ^ hyper $ - norm and abundant $ ( 590, 780 ) $ - vector sums, enables us to obtain bounds that match a special dependence following the input graph.", "histories": [["v1", "Thu, 13 Jun 2013 13:47:51 GMT  (16kb)", "http://arxiv.org/abs/1306.3108v1", null], ["v2", "Thu, 29 Aug 2013 15:38:27 GMT  (18kb)", "http://arxiv.org/abs/1306.3108v2", null]], "reviews": [], "SUBJECTS": "cs.LG", "authors": ["zheng-chu guo", "yiming ying"], "accepted": false, "id": "1306.3108"}, "pdf": {"name": "1306.3108.pdf", "metadata": {"source": "CRF", "title": "Guaranteed Classification via Regularized Similarity Learning", "authors": ["Zheng-Chu Guo"], "emails": ["gzhengchu@gmail.com", "mathying@gmail.com"], "sections": [{"heading": null, "text": "ar X\niv :1\n30 6.\n31 08\nv1 [\ncs .L"}, {"heading": "1 Introduction", "text": "The success of many machine learning algorithms heavily depends on how to specify the similarity or distance metric between examples. For instance, the k-nearest neighbor (k-NN) classifier depends on a distance (dissimilarity) function to identify the nearest neighbors for classification. Most information retrieval methods rely on a similarity function to identify the data points that are most similar to a given query. Kernel methods rely on the kernel function to represent the similarity between examples. Hence, how to learn an appropriate (dis)similarity function from the available\ndata is a central problem in machine learning, which we refer to as similarity metric learning throughout the paper.\nRecently, a considerable amount of research efforts are devoted to similarity metric learning and many approaches have been proposed. They can be briefly divided into three main approaches. The first approach is referred to as metric learning [4, 11, 12, 14, 26, 29, 31] which often focuses on learning a Mahalanobis distance metric defined, for any x, x\u2032 \u2208 Rd, by dM (x, x\u2032) = \u221a\n(x\u2212 x\u2032)TM(x\u2212 x\u2032). Here, M is a positive semi-definite (PSD) matrix. The second approach focuses on learning a bilinear similarity function defined, for any x, x\u2032 \u2208 Rd, by sM(x, x\u2032) = xTMx\u2032 with M being a PSD matrix. This approach has been successfully applied to image searching [9] and object recognition [18]. The generalization bounds were recently established for metric and similarity learning [7, 14, 18] under different statistical assumptions on the data. The above methods are mainly motivated by the natural intuition that the similarity score between examples in the same class should be larger than that of examples from distinct classes. The k-NN classification using the similarity metric learnt from the above methods was empirically shown to achieve better accuracy than that using the standard Euclidean distance. However, there are no theoretical guarantees for such empirical success. In other words, it is not clear whether good generalization bounds for metric and similarity learning [14, 7] can lead to a good classification performance of the resultant k-NN classifiers.\nThe third approach for similarity metric learning is concerned with the problem of learning a general non-PSD similarity function (indefinite kernel). Kernel methods such as support vector machine (SVM) require the similarity function (kernel) to be PSD, which ensures the similarity function explicitly implies an embedding of the data into a high-dimensional Hilbert space and leads to an elegant convex optimization problem. However, many potential kernel matrices could be non-positive semi-definite. Such cases are quite common in applications such as hyperbolic tangent kernels [23], and the protein sequence similarity measures derived from SmithWaterman and BLAST score [22]. The problem of learning with an indefinite kernel has recently attracted considerable attention. Some methods [8, 30] learn a PSD kernel matrix from a prescribed indefinite kernel matrix, which are mostly restricted to the transductive settings. Recent methods [27, 28] analyzed regularization networks such as ridge regression and SVM given a prescribed indefinite kernel, instead of aiming to learn an indefinite kernel function from data.\nAlthough many approaches for similarity metric learning have been proposed, there is little theoretical study on the question whether similarity-based learning guarantees a good generalization of the resultant classification. Recently, Bellet et al. [3] proposed a regularized similarity learning approach, which is mainly motivated by the (\u03b5, \u03b3, \u03c4)good similarity functions introduced in [1, 2]. In particular, they showed that the proposed similarity learning can theoretically guarantee a good generalization for classification. However, due to the techniques dependent on the notion of uniform stability [6], the generalization bounds only hold true for the Frobenius matrix-norm regularization which usually has a strong dependence on the dimensionality of the input space.\nIn this paper, we consider a new similarity learning formulation associated with general matrix-norm regularization terms. Its generalization bounds are established for various matrix regularization including the Frobenius norm, sparse L1-norm, and mixed (2, 1)-norm (see definitions below). The learnt similarity matrix is used to design a sparse classification algorithm and we prove the generalization error of its resultant linear separator can be bounded by the derived generalization bound for similarity learning. This implies that the proposed similarity learning with general matrix-norm regularization guarantees a good generalization for classification. Our techniques using the Rademacher complexity [5] and the important Khinchin-type inequality for the Rademacher variables, in the cases of sparse L1-norm, and mixed (2, 1)-norm regularization, enables us to derive bounds that have a mild dependence on the input dimensionality.\nThe remainder of this paper is organized as follows. In Section 2, we propose the similarity learning formulations with general matrix-norm regularization terms and state the main theorems. In particular, the results will be illustrated using various examples. The related work is discussed in Section 3. The generalization bounds for similarity learning are established in Section 4. In Section 5, we develop a theoretical link between the generalization bounds of the proposed similarity learning method and the generalization error of the linear classifier built from the learnt similarity function. Section 6 estimates the Rademacher averages and gives the proof for examples stated in Section 2. Section 7 summarizes this paper and discuss some possible directions for future research."}, {"heading": "2 Regularization Formulation and Main Results", "text": "In this section, we mainly introduce the regularized formulation of similarity learning and state our main results. Before we do that, let us introduce some notations and present some background material.\nDenote, for any n \u2208 N, Nn = {1, 2, . . . , n}. Let z = {zi = (xi, yi) : i \u2208 Nm} be a set of training samples, which is drawn identically and independently from a distribution \u03c1 on Z = X \u00d7 Y. Here, the input space X is a domain in Rd and Y = {\u22121, 1} is called the output space. For any x, x\u2032 \u2208 X , we consider KA(x, x\u2032) = xTAx\u2032 as a bilinear similarity score parameterized by a symmetric matrix A \u2208 Sd\u00d7d. The symmetry of matrix A guarantees the symmetry of the similarity score KA, i.e. KA(x, x\n\u2032) = KA(x \u2032, x).\nThe aim of similarity learning is to learn a matrix A from a given set of training samples z such that the similarity score KA between examples from the same label is larger than that between examples from different labels. A natural approach to achieve the above aim [1, 3] is to minimize the following empirical error\nEz(A) = 1\nm\n\u2211\ni\u2208Nm\n( 1\u2212 1 mr \u2211\nj\u2208Nm\nyiyjKA(xi, xj) )\n+ . (1)\nNote that \u2211\nj\u2208Nm yiyjKA(xi, xj) =\n\u2211\n{j:yj=yi} KA(xi, xj)\u2212\n\u2211\n{j:yj 6=yi} KA(xi, xj).Min-\nimizing the above empirical error encourages, for any i, that the average similarity scores between examples with the same class as yi are relatively larger than those between examples with distinct classes from yi. To avoid overfitting, we add a matrixregularized term to the above empirical error (1) and reach the following regularization formulation\nAz = arg min A\u2208Sd\u00d7d\n[ Ez(A) + \u03bb\u2016A\u2016 ] , (2)\nwhere \u03bb > 0 is the regularization parameter. Here, the notation \u2016A\u2016 denotes a general matrix norm. For instance, it can be the sparse L1-norm \u2016A\u20161 = \u2211\nk\u2208Nd\n\u2211\n\u2113\u2208Nd |Ak\u2113|,\nthe (2, 1)-mixed norm \u2016A\u2016(2,1) := \u2211\nk\u2208Nd\n( \u2211\n\u2113\u2208Nd A2k\u2113\n) 1\n2 , the Frobenius norm \u2016A\u2016F = ( \u2211\nk,\u2113\u2208Nd A2k\u2113\n) 1\n2 or the trace norm \u2016A\u2016tr := \u2211 \u2113\u2208Nd \u03c3\u2113(A), where {\u03c3\u2113(A) : \u2113 \u2208 Nd}\ndenote the singular values of matrix A.\nThe first contribution of this paper is to establish generalization bounds for regularized similarity learning (1) with general matrix-norms. Specifically, define\nE(A) = \u222b\nZ\n(\n1\u2212 1 r\n\u222b\nZ yy\u2032KA(x, x \u2032)d\u03c1(x\u2032, y\u2032)\n)\n+\nd\u03c1(x, y). (3)\nThe target of generalization analysis for similarity learning is to bound E(Az) \u2212 Ez(Az). Its special case with the Frobenius matrix norm was established in [3]. It used the uniform stability techniques [6], which, however, can not deal with non-strongly convex matrix-norms such as the L1-norm, (2, 1)-mixed norm and trace norm. Our new analysis techniques are able to deal with general matrix norms, which depend on the concept of Rademacher averages [5] defined as follows.\nDefinition 1. Let F be a class of uniformly bounded functions. For every integer n, we call\nRn(F ) := EzE\u03c3\n[\nsup f\u2208F\n1\nn\n\u2211\ni\u2208Nn\n\u03c3if(zi)\n]\n,\nthe Rademacher average over F, where {zi : i \u2208 Nn} are independent random variables distributed according to some probability measure and {\u03c3i : i \u2208 Nn} are independent Rademacher random variables, that is, P (\u03c3i = 1) = P (\u03c3i = \u22121) = 12 .\nBefore stating our generalization bounds for similarity learning, we first introduce some notations. For any B,A \u2208 Rn\u00d7d, let \u3008B,A\u3009 = trace(BTA), where trace(\u00b7) denotes the trace of a matrix. For any matrix-norm \u2016 \u00b7 \u2016, its dual norm \u2016 \u00b7 \u2016\u2217 defined, for any B, by \u2016B\u2016\u2217 = sup\u2016A\u2016\u22641 trace(BTA). Denote \u2016X\u2016\u2217 = supx,x\u2032\u2208X \u2016x\u2032xT \u2016\u2217. Let the Rademacher average with respect to the dual matrix norm be defined by\nRm := Ez,\u03c3 [\nsup x\u0303\u2208X\n\u2225 \u2225 \u2225 1\nm\n\u2211\ni\u2208Nm\n\u03c3iyixix\u0303 T \u2225 \u2225 \u2225\n\u2217\n]\n. (4)\nNow we can state the generalization bounds for similarity learning, which is closely related to the Rademacher averages with respect to the dual matrix-norm \u2016 \u00b7 \u2016\u2217.\nTheorem 1. Let Az be the solution to algorithm (2). Then, for any 0 < \u03b4 < 1, with probability at least 1\u2212 \u03b4, there holds\nE(Az)\u2212 Ez(Az) \u2264 6Rm r\u03bb + 2X\u2217 r\u03bb\n\u221a\n2 ln ( 1 \u03b4 )\nm . (5)\nThe proof for Theorem 1 will be given in Section 4.\nThe second contribution of this paper is to investigate the theoretical relationship between similarity learning (2) and the generalization error of the linear classifier built from the learnt metric Az. We show that the generalization bound for the similarity learning gives an upper bound for the generalization error of a linear classifier produced by the linear Support Vector Machine (SVM) [24] defined as follows:\nfz = argmin { 1\nm\n\u2211\ni\u2208Nm\n( 1\u2212 yif(xi) ) + : f \u2208 Fz, \u2126(f) :=\n\u2211\nj\u2208Nm\n|\u03b1j | \u2264 1/r } . (6)\nwhere Fz = { f : f = \u2211\nj\u2208Nm \u03b1jKAz(xj , \u00b7), aj \u2208 R\n}\nis the sample-dependent hypoth-\nesis space. The empirical error of f \u2208 Fz associated with z is defined by\nEz(f) = 1\nm\n\u2211\ni\u2208Nm\n( 1\u2212 yif(xi) )\n+ .\nThe true generalization error is defined as\nE (f) =\n\u222b\nZ\n( 1\u2212 yf(x) )\n+ d\u03c1(x, y).\nNow we are in a position to state the relationship between the generalization error of similarity learning and the generalization error of the liner classifier.\nTheorem 2. Let Az and fz be defined by (2) and (6), respectively. Then, for any 0 < \u03b4 < 1, with confidence at least 1\u2212 \u03b4, there holds\nE (fz) \u2264 Ez(Az) + 4Rm \u03bbr + 2X\u2217 \u03bbr\n\u221a\n2 log 1\u03b4 m . (7)\nThe proof for Theorem 2 will be established in Section 5.\nTheorems 1 and 2 depend critically on two terms: the constantX\u2217 and the Rademacher average Rm. Below, we list the estimation of these two terms associated with different matrix norms. For any vector x = (x1, x2, . . . , xd) \u2208 Rd, denote \u2016x\u2016\u221e = max\u2113\u2208Nd |x\u2113|.\nExample 1. Consider the matrix norm be the sparse L1-norm defined, for any A \u2208 S d\u00d7d, by \u2016A\u2016 = \u2211k,\u2113\u2208Nd |Ak\u2113|. Let Az and fz be defined respectively by (2) and (6). Then, we have the following results.\n(a) X\u2217 \u2264 supx\u2208X \u2016x\u20162\u221e and Rm \u2264 2 supx\u2208X \u2016x\u20162\u221e \u221a e log(d+1) m .\n(b) For any 0 < \u03b4 < 1, with confidence at least 1\u2212 \u03b4, there holds\nE(Az)\u2212Ez(Az) \u2264 12 supx\u2208X \u2016x\u20162\u221e\nr\u03bb\n\u221a\ne log(d+ 1) m + 2 supx\u2208X \u2016x\u20162\u221e r\u03bb\n\u221a\n2 ln ( 1 \u03b4 )\nm . (8)\n(c) For any 0 < \u03b4 < 1, with confidence at least 1\u2212 \u03b4, there holds\nE (fz) \u2264 Ez(Az)+ 4 supx\u2208X \u2016x\u20162\u221e\n\u03bbr\n\u221a\n2e log(d+ 1)\nm + 2 supx\u2208X \u2016x\u20162\u221e \u03bbr\n\u221a\n2 log 1\u03b4 m . (9)\nFor any vector x \u2208 Rd, let \u2016x\u2016F be the standard Euclidean norm. Considering the regularized similarity learning with the Frobenius matrix norm, we have the following result.\nExample 2. Consider the Frobenius matrix norm defined, for any A \u2208 Sd\u00d7d, by \u2016A\u2016 = \u221a \u2211\nk,\u2113\u2208Nd |Ak\u2113|2. Let Az and fz be defined by (2) and (6), respectively. Then,\nwe have the following estimation.\n(a) X\u2217 \u2264 supx\u2208X \u2016x\u20162F and Rm \u2264 2 supx\u2208X \u2016x\u20162F \u221a 1 m .\n(b) For any 0 < \u03b4 < 1, with confidence at least 1\u2212 \u03b4, there holds\nE(Az)\u2212 Ez(Az) \u2264 6 supx\u2208X \u2016x\u20162F\nr\u03bb \u221a m\n+ 2 supx\u2208X \u2016x\u20162F\nr\u03bb\n\u221a\n2 ln ( 1 \u03b4 )\nm . (10)\n(c) For any 0 < \u03b4 < 1, with confidence at least 1\u2212 \u03b4, there holds\nE (fz) \u2264 Ez(Az) + 4 supx\u2208X \u2016x\u20162F\n\u03bbr \u221a m\n+ 2 supx\u2208X \u2016x\u20162F\n\u03bbr\n\u221a\n2 log 1\u03b4 m . (11)\nWe end this section with two remarks. Firstly, the above theorem and examples means that a good similarity (i.e. a small generalization error Ez(Az) for similarity learning) can guarantee a good classification (i.e. a small classification error E (fz)). Secondly, the bounds in Example 2 is consistent with that in [3]. Comparing the results in Examples 1 and 2, the generalization bound of similarity learning using the L1-norm has a milder dependence on the input dimension d than using the Frobenius norm. For instance, if the input space X = [0, 1]d, then we have supx\u2208X \u2016x\u2016\u221e = 1 and supx\u2208X \u2016x\u2016F = \u221a d. Hence, we can observe from inequalities (9) and (11) that the generalization bound with L1-norm only relies on log(1 + d), while the bound for the Frobenius norm heavily depends on d."}, {"heading": "3 Related Work", "text": "In this section, we discuss studies on similarity metric learning which are related to our work.\nMany similarity metric learning methods have been motivated by the intuition that the similarity score between examples in the same class should be larger than that of examples from distinct classes, see e.g. [4, 7, 9, 12, 14, 18, 26, 29]. Jin et al. [14] established generalization bounds for regularized metric learning algorithms via the concept of uniform stability [5], which, however, only works for strongly convex matrix regularization terms. A very recent work [7] established generalization bounds for the metric and similarity learning associated with general matrix norm regularization using techniques of Rademacher averages and U-statistics. However, there was no theoretical links between the similarity metric learning and the generalization performance of classifiers based on the learnt similarity matrix. Here, we focused on the problem how to learn a good linear similarity function KA such that it can guarantee a good classification error of the resultant classifier derived from the learnt similarity function. In addition, our formulation (2) is quite distinct from the available similarity metric learning methods, since most of them are based on pairwise or triplet-wise constraints. For instance, the following pairwise empirical objective function was considered in [9, 7]:\n1\nm(m\u2212 1)\nm \u2211\ni,j=1,i 6=j\n( 1\u2212 yiyj(KA(xi, xj)\u2212 r) )\n+ . (12)\nOur formulation (2) is less restrictive since the empirical objective function is defined over an average of similarity scores and it doesn\u2019t require the positive semi-definiteness of the similarity function K.\nBalcan et al. [2] developed a theory of (\u01eb, \u03b3, \u03c4)-good similarity function defined as follows. It attempts to investigate the theoretical relationship between the properties of a similarity function and its performance in linear classification.\nDefinition 2. A similarity function K is a (\u01eb, \u03b3, \u03c4)-good similarity function in hinge loss for a learning problem P if there exists a random indicator function R(x) defining a probabilistic set of \u201creasonable points\u201d such that the following conditions hold: 1. E(x,y)\u223cP [1\u2212 yg(x)/\u03b3]+ \u2264 \u01eb, where g(x) = E(x\u2032,y\u2032)\u223cP [y\u2032K(x, x\u2032)|R(x\u2032)], 2. Prx\u2032 [R(x \u2032)] \u2265 \u03c4.\nThe first condition can be interpreted as \u201cmost points x are on average 2\u03b3 more similar to random reasonable points of the same class than to random reasonable points of the distinct classes\u201d and the second condition as \u201cat least a \u03c4 proportion of the points should be reasonable.\u201d The following theorem implies that if given an (\u01eb, \u03b3, \u03c4)-good similarity function and enough landmarks, there exists a separator \u03b1 with error arbitrarily close to \u01eb.\nTheorem 3. Let K be an (\u01eb, \u03b3, \u03c4)-good similarity function in hinge loss for a learning problem P. For any \u01eb1 > 0, and 0 < \u03b4 \u2264 \u03b3\u01eb1/4, let S = {x\u20321, \u00b7 \u00b7 \u00b7 , x\u2032dland} be a poten-\ntially unlabeled sample of dland = 2 \u03c4\n( log(2/\u03b4) + 16 log(2/\u03b4) (\u01eb1\u03b3)2 ) landmarks drawn from P.\nConsider the mapping \u03c6Si = K(x, x \u2032 i), i \u2208 {1, \u00b7 \u00b7 \u00b7 , dland}. Then, with probability at least 1\u2212 \u03b4 over the random sample S, the induced distribution \u03c6S(P ) in Rdland has a linear separator \u03b1 of error at most \u01eb+ \u01eb1 at margin \u03b3.\nIt was mentioned in [2] that the linear separator can be estimated by solving the following linear programming if we have du potentially unlabeled sample and dl labeled sample,\nmin \u03b1\n{ dl \u2211\ni=1\n[ 1\u2212 du \u2211\nj=1\n\u03b1jyiK(xi, x \u2032 j) ]\n+ :\ndu \u2211\nj=1\n|\u03b1j | \u2264 1/\u03b3 } . (13)\nThe above algorithm (13) is quite similar to the linear SVM (6) used in our paper. Our work is distinct from Balcan et al. [2] in the following two aspects. Firstly, the similarity function K is predefined in algorithm (13), while we aim to learn a similarity function KAz from a regularized similarity learning formulation (2). Secondly, although the separators are both trained from the linear SVM, the classification algorithm (13) in [2] was designed using two different sets of examples, a set of labeled samples of size dl to train the classification algorithm and another set of unlabeled samples with size du to define the mapping \u03c6\nS . In this paper, we used the same set of training samples for both similarity learning (2) and the classification algorithm (6), which could be more practically feasible.\nRecent work by Bellet et al. [3] is mostly close to ours. Specifically, they considered similarity learning formulation (2) with the Frobenius norm regularization. Generalization bounds for similarity learning were derived via uniform stability arguments [6] which can not deal with, for instance, the L1-norm and (2, 1)-norm regularization terms. In addition, the results about the relationship between the similarity learning and the performance of the learnt matrix in classification were quoted from [2] and hence requires two separate sets of samples to train the classifier.\nJain et al. [13] and Kar et al. [15] introduced an extended framework of [1, 2] in the general setting of supervised learning. The authors proposed a general goodness criterion for similarity functions, which can handle general supervised learning tasks and also subsumes the goodness of condition of [2]. There, efficient algorithms were constructed with provable generalization error bounds. The main distinction between these work and our work is that we aim to learn a similarity function while in their work a similarity function is defined in advance."}, {"heading": "4 Generalization Bounds for Similarity Learning", "text": "In this section, we establish generalization bounds for the similarity learning formulation (2) with general matrix-norm regularization terms. Recall that the true error for similarity learning is defined by\nE(A) = \u222b\nZ\n( 1\u2212 1 r\n\u222b\nZ yy\u2032KA(x, x\n\u2032)d\u03c1(x\u2032, y\u2032) )\n+ d\u03c1(x, y).\nThe target of generalization analysis for similarity learning is to bound the true error E(Az) by the empirical error Ez(Az).\nBy the definition (2) of Az, we know that Ez(Az) + \u03bb\u2016Az\u2016 \u2264 Ez(0) + \u03bb\u20160\u2016 = 1, which implies that \u2016Az\u2016 \u2264 1/\u03bb. Denote\nA = { A \u2208 Sd\u00d7d : \u2016A\u2016 \u2264 1/\u03bb } .\nHence, one can easily see that the solution Az to algorithm (2) belongs to A. Now we are ready to prove generalization bounds for similarity learning which was stated as Theorem 1 in Section 2.\nProof of Theorem 1: Our proof is divided into two steps.\nStep 1: Let Ez denote the expectation with respect to samples z. Observe that E(Az) \u2212 Ez(Az) \u2264 sup A\u2208A [ E(A) \u2212 Ez(A) ] . Also, for any z = (z1, . . . , zk, . . . , zm) and z\u0303 = (z1, . . . , z\u0303k, . . . , zm), 1 \u2264 k \u2264 m, there holds \u2223\n\u2223 \u2223 sup A\u2208A\n[ E(A) \u2212 Ez(A) ]\n\u2212 sup A\u2208A\n[ E(A)\u2212 Ez\u0303(A) ] \u2223 \u2223 \u2223 \u2264 sup\nA\u2208A |Ez(A)\u2212 Ez\u0303(A)|\n\u2264 1 m2r\nsup A\u2208A\n{ m \u2211\ni=1,i 6=k\n|yiykKA(xk, xi)\u2212 yiy\u0303kKA(x\u0303k, xi)|\n+ |\u2211j\u2208Nm(ykyjKA(xk, xj)\u2212 y\u0303kyjKA(x\u0303k, xj))| }\n\u2264 2 m2r\nsup A\u2208A\n\u2211\ni\u2208Nm\n( |yiykKA(xk, xi)|+ |yiy\u0303kKA(x\u0303k, xi)| ) \u2264 4X\u2217 mr\u03bb .\nApplying the McDiarmid\u2019s inequality [19] (see Lemma 1 in the Appendix) to the term\nsup A\u2208A\n[ E(A)\u2212 Ez(A) ] , with probability at least 1\u2212 \u03b4, there holds\nsup A\u2208A\n[ E(A)\u2212 Ez(A) ]\n\u2264 Ez sup A\u2208A\n[ E(A)\u2212 Ez(A) ] + 2X\u2217 r\u03bb\n\u221a\n2 ln ( 1 \u03b4 )\nm . (14)\nNow we are in a position to estimate the first term in the expectation form on the righthand side of the above equation by standard symmetrization techniques.\nStep 2: We divide the term Ez sup A\u2208A\n[ E(A)\u2212 EzA ] into two parts as follows,\nEz sup A\u2208A\n[ E(A)\u2212 Ez(A) ]\n= Ez sup A\u2208A\n{ E(A)\u2212 1 m \u2211\ni\u2208Nm\n[ 1\u2212 1 mr \u2211\nj\u2208Nm\nyiyjKA(xi, xj) ]\n+\n}\n= Ez sup A\u2208A\n{ E(A)\u2212 1 m \u2211\ni\u2208Nm\n[ 1\u2212 1 r E(x\u2032,y\u2032)yiy \u2032KA(xi, x \u2032) ] +\n+ 1m\n\u2211\ni\u2208Nm\n[ 1\u2212 1 r E(x\u2032,y\u2032)yiy \u2032KA(xi, x \u2032) ] + \u2212 1 m \u2211\ni\u2208Nm\n[ 1\u2212 1 mr \u2211\nj\u2208Nm\nyiyjKA(xi, xj) ]\n+\n}\n\u2264 I1 + I2,\nwhere\nI1 := Ez sup A\u2208A\n{ E(A)\u2212 1 m \u2211\ni\u2208Nm\n[ 1\u2212 1 r E(x\u2032,y\u2032)yiy \u2032KA(xi, x \u2032) ] + } ,\nand\nI2 := Ez sup A\u2208A\n{ 1\nm\n\u2211\ni\u2208Nm\n[ 1\u22121 r E(x\u2032,y\u2032)yiy \u2032KA(xi, x \u2032) ] + \u2212 1 m \u2211\ni\u2208Nm\n( 1\u2212 1 mr \u2211\nj\u2208Nm\nyiyjKA(xi, xj) )\n+\n}\n.\nNow let z\u0304 = {z\u03041, z\u03042, . . . , z\u0304m} be an i.i.d. sample which is independent of z. We first estimate I1 using the standard symmetrization techniques, to this end, we rewrite E(A) as Ez\u0304 ( 1 m \u2211\ni\u2208Nm\n[ 1\u2212 1 r E(x\u2032,y\u2032)y\u0304iy \u2032KA(x\u0304i, x \u2032) ] + ) . Then we have\nI1 = Ez sup A\u2208A\n{\nEz\u0304\n( 1\nm\n\u2211\ni\u2208Nm\n[ 1\u2212 1 r E(x\u2032,y\u2032)y\u0304iy \u2032KA(x\u0304i, x \u2032) ] + )\n\u2212 1m \u2211\ni\u2208Nm\n[ 1\u2212 1 r E(x\u2032,y\u2032)yiy \u2032KA(xi, x \u2032) ] + }\n\u2264 Ez,z\u0304 sup A\u2208A\n{ 1\nm\n\u2211\ni\u2208Nm\n[ 1\u2212 1 r E(x\u2032,y\u2032)y\u0304iy \u2032KA(x\u0304i, x \u2032) ] +\n\u2212 1m \u2211\ni\u2208Nm\n[ 1\u2212 1 r E(x\u2032,y\u2032)yiy \u2032KA(xi, x \u2032) ] + } .\nBy the standard Rademacher symmetrization technique and the contraction property of the Rademacher average (see Lemma 2 in the Appendix), we further have\nI1 \u2264 2Ez,\u03c3 sup A\u2208A\n{ 1\nm\n\u2211\ni\u2208Nm\n\u03c3i\n[ 1\u2212 1 r E(x\u2032,y\u2032)yiy \u2032KA(xi, x \u2032) ] + }\n\u2264 4Ez,\u03c3 sup A\u2208A\n\u2223 \u2223 \u2223 \u3008 1 mr \u2211\ni\u2208Nm\n\u03c3iyixi\n\u222b\ny\u2032x\u2032Td\u03c1(x\u2032, y\u2032), A\u3009 \u2223 \u2223\n\u2223\n\u2264 4r\u03bbEz,\u03c3 \u2225 \u2225 \u2225 1 m \u2211\ni\u2208Nm\n\u03c3iyixi\n\u222b\ny\u2032x\u2032Td\u03c1(x\u2032, y\u2032) \u2225 \u2225\n\u2225 \u2217 \u2264 4 r\u03bb Ez,\u03c3 sup\nx\u0303\n\u2225 \u2225 \u2225 1\nm\n\u2211\ni\u2208Nm\n\u03c3iyixix\u0303 T \u2225 \u2225 \u2225\n\u2217 ,\nwhere the last inequality follows from the fact that \u3008A,B\u3009 \u2264 \u2016A\u2016\u2016B\u2016\u2217 \u2264 1r\u2016B\u2016\u2217 for any A \u2208 A and B \u2208 Rd\u00d7d.\nSimilarly, we can estimate I2 as follows.\nI2 = Ez sup A\u2208A\n1\nm\n\u2211\ni\u2208Nm\n([ 1\u2212 1 r E(x\u2032,y\u2032)yiy \u2032KA(xi, x \u2032) ] + \u2212 [ 1\u2212 1 mr \u2211\nj\u2208Nm\nyiyjKA(xi, xj) ]\n+\n)\n\u2264 Ez sup A\u2208A\n1\nm\n\u2211\ni\u2208Nm\n(\u2223\n\u2223 \u2223\n1 r E(x\u2032,y\u2032)yiy \u2032KA(xi, x \u2032)\u2212 1 mr \u2211\nj\u2208Nm\nyiyjKA(xi, xj) \u2223 \u2223 \u2223 )\n= Ez sup A\u2208A\n1\nmr\n\u2211\ni\u2208Nm\n(\u2223\n\u2223 \u2223 \u3008E(x\u2032,y\u2032)yiy\u2032x\u2032xTi \u2212\n1\nm\n\u2211\nj\u2208Nm\nyiyjxjx T i , A\u3009\n\u2223 \u2223 \u2223 )\n\u2264 1r\u03bbEz sup x\u2208X\n\u2225 \u2225 \u2225 E(x\u2032,y\u2032)y \u2032x\u2032xT \u2212 1 m \u2211\nj\u2208Nm\nyjxjx T \u2225 \u2225 \u2225\n\u2217\n= 1r\u03bbEz sup x\u2208X\n\u2225 \u2225 \u2225 Ez\u2032 1\nm\n\u2211\nj\u2208Nm\ny\u2032jx \u2032 jx T \u2212 1 m \u2211\nj\u2208Nm\nyjxjx T \u2225 \u2225 \u2225\n\u2217 .\nIn the above estimation, the first inequality follows from the Lipschitz continuity of the hinge loss function. Following the standard Rademacher symmetrization technique (see e.g. [5]), from the above estimation we can further estimate I2 as follows:\nI2 \u2264 1r\u03bbEz sup x\u2208X\n\u2225 \u2225 \u2225 Ez\u2032 1\nm\n\u2211\nj\u2208Nm\ny\u2032jx \u2032 jx T \u2212 1 m \u2211\nj\u2208Nm\nyjxjx T \u2225 \u2225 \u2225\n\u2217\n\u2264 1r\u03bbEz,z\u2032 sup x\u2208X\n\u2225 \u2225 \u2225 1\nm\n\u2211\nj\u2208Nm\ny\u2032jx \u2032 jx T \u2212 1 m \u2211\nj\u2208Nm\nyjxjx T \u2225 \u2225 \u2225\n\u2217\n\u2264 1r\u03bbEz,z\u2032,\u03c3 sup x\u2208X\n\u2225 \u2225 \u2225 1\nm\n\u2211\nj\u2208Nm\n\u03c3j\n(\ny\u2032jx \u2032 jx T \u2212 yjxjxT )\u2225 \u2225 \u2225 \u2217 \u2264 2 r\u03bb Ez,\u03c3 sup\nx\u2208X\n\u2225 \u2225 \u2225 1\nm\n\u2211\nj\u2208Nm\n\u03c3jyjxjx T \u2225 \u2225 \u2225\n\u2217 .\nThe desired result follows by combining (14) with the above estimation for I1 and I2. This completes the proof for the theorem."}, {"heading": "5 Guaranteed Classification Via Good Similarity", "text": "In this section, we investigate the theoretical relationship between the generalization error for the similarity learning and that of the linear classifier built from the learnt similarity metric KAz . In particular, we will show that the generalization error of the similarity learning gives an upper bound for the generalization error of the linear classifier which was stated as Theorem 2 in Section 2.\nBefore giving the proof of Theorem 2, we first establish the generalization bounds for the linear SVM algorithm (6). Recalling that the linear SVM algorithm (6) was defined by\nfz = argmin { 1\nm\n\u2211\ni\u2208Nm\n( 1\u2212 yif(xi) ) + : f \u2208 Fz, \u2126(f) :=\n\u2211\nj\u2208Nm\n|\u03b1j | \u2264 1/r } ,\nwhere Fz = { f : f = \u2211\nj\u2208Nm\n\u03b1jKAz(xj , \u00b7), aj \u2208 R } .\nThe generalization analysis of the linear SVM algorithm (6) aims to estimate the term E (fz)\u2212 Ez(fz). For any z, one can easily see that the solution to algorithm (6) belongs to the set Fz,r, where\nFz,r = { f = \u2211\nj\u2208Nm\n\u03b1jKAz(xj , \u00b7) : \u2126(f) = \u2211\nj\u2208Nm\n|\u03b1j | \u2264 1/r, aj \u2208 R } .\nTo perform the generalization analysis, we seek a sample-independent set which contains, for any z, the sample-dependent hypothesis space Fz. Specifically, we define a sample independent hypothesis space by\nFm = { f = \u2211\ni\u2208Nm\n\u03b1iKA(ui, \u00b7) : \u2016A\u2016 \u2264 1/\u03bb, uj \u2208 X, aj \u2208 R } .\nRecalling that, for any z, \u2016Az\u2016 \u2264 \u03bb\u22121, one can easily see that Fz is a subset of Fm. It follows that, for any z, the solution to the linear SVM algorithm (6) lies in the set Fm,r, which is given by\nFm,r = { f \u2208 Fm : \u2126(f) \u2264 1/r } .\nThe following theorem states the generalization bounds of the linear SVM for classification.\nTheorem 4. Let fz be the solution to the algorithm (6). For any 0 < \u03b4 < 1, with probability at least 1\u2212 \u03b4, we have\nE (fz)\u2212 Ez(fz) \u2264 4\n\u03bbr Ez,\u03c3 sup\nx\u2208X\n\u2225 \u2225 \u2225 1\nm\n\u2211\ni\u2208Nm\n\u03c3iyixix T \u2225 \u2225 \u2225\n\u2217 + 2X\u2217 \u03bbr\n\u221a\n2 log 1\u03b4 m . (15)\nProof. By McDiarmid\u2019s inequality, for any 0 < \u03b4 < 1, with confidence 1 \u2212 \u03b4, there holds\nE (fz)\u2212 Ez(fz) \u2264 sup f\u2208Fz,r\n( E (f)\u2212 Ez(f) ) \u2264 sup f\u2208Fm,r ( E (f)\u2212 Ez(f) )\n\u2264 Ez sup f\u2208Fm,r\n( E (f)\u2212 Ez(f) ) + 2X\u2217 \u03bbr\n\u221a\n2 log 1\u03b4 m .\nNext, all we need is to estimate the first part of the right hand-side of the above inequality. Let z\u0304 be an independent sample (independent each other and z) and with the same distribution as z.\nEz sup f\u2208Fm,r\n( E (f)\u2212 Ez(f) )\n= Ez sup f\u2208Fm,r\n( Ez\u0304Ez\u0304(f)\u2212 Ez(f) ) \u2264 Ez,z\u0304 sup f\u2208Fm,r ( Ez\u0304(f)\u2212 Ez(f) )\n\u2264 2Ez,\u03c3 [\nsup \u2016A\u2016\u22641/\u03bb sup\u2211 i\u2208Nm |\u03b1i|\u22641/r\n( 1\nm\n\u2211\ni\u2208Nm\n\u03c3i [ 1\u2212 \u2211\nj\u2208Nm\n\u03b1jyiKA(xi, uj)]+\n)]\n\u2264 4Ez,\u03c3 [\nsup \u2016A\u2016\u22641/\u03bb sup\u2211 i\u2208Nm |\u03b1i|\u22641/r\n( 1\nm\n\u2211\ni\u2208Nm\n\u03c3i \u2211\nj\u2208Nm\n\u03b1jyiKA(xi, uj) )]\n\u2264 4rEz,\u03c3 sup A:\u2016A\u2016\u22641/\u03bb sup x\u2208X\n( \u2223\n\u2223 \u2223\n1\nm\n\u2211\ni\u2208Nm\n\u03c3iyi\u3008xixT , A\u3009 \u2223 \u2223 \u2223 ) \u2264 4 \u03bbr Ez,\u03c3 sup x\u2208X \u2225 \u2225 \u2225 1 m \u2211\ni\u2208Nm\n\u03c3iyixix T \u2225 \u2225 \u2225\n\u2217 .\nHere we also use the standard Rademacher Symmetrization technique and the contractor property of the Rademacher average. Then the proof is completed.\nNow we are in a position to give the detailed proof of Theorem 2.\nProof of Theorem 2: If we take \u03b10 = ( y1mr , \u00b7 \u00b7 \u00b7 , ym mr ) T , then f0 z = 1mr \u2211 j\u2208Nm yjKAz(xj, \u00b7). One can easily see that \u2126(f0 z ) = \u2211 j\u2208Nm |\u03b10j | = 1r , that means f0z \u2208 Fz,r. From Theo-\nrem 4 and the definition of fz , we get\nE (fz) \u2264 Ez(fz) + 4\u03bbrEz,\u03c3 sup x\u2208X\n\u2225 \u2225 \u2225 1\nm\n\u2211\ni\u2208Nm\n\u03c3iyixix T \u2225 \u2225 \u2225\n\u2217 + 2X\u2217 \u03bbr\n\u221a\n2 log 1\u03b4 m\n\u2264 Ez(f0z ) + 4\u03bbrEz,\u03c3 sup x\u2208X\n\u2225 \u2225 \u2225 1\nm\n\u2211\ni\u2208Nm\n\u03c3iyixix T \u2225 \u2225 \u2225\n\u2217 + 2X\u2217 \u03bbr\n\u221a\n2 log 1\u03b4 m\n= 1m\n\u2211\ni\u2208Nm\n( 1\u2212 1 mr \u2211\nj\u2208Nm\nyiyjKAz(xi, xj) )\n+ +\n4\n\u03bbr Ez,\u03c3 sup\nx\u2208X\n\u2225 \u2225 \u2225 1\nm\n\u2211\ni\u2208Nm\n\u03c3iyixix T \u2225 \u2225 \u2225\n\u2217\n+2X\u2217\u03bbr\n\u221a\n2 log 1 \u03b4\nm\n= Ez(Az) + 4\u03bbrEz,\u03c3 sup x\u2208X\n\u2225 \u2225 \u2225 1\nm\n\u2211\ni\u2208Nm\n\u03c3iyixix T \u2225 \u2225 \u2225\n\u2217 + 2X\u2217 \u03bbr\n\u221a\n2 log 1\u03b4 m .\nThis completes the proof of the theorem."}, {"heading": "6 Estimating Rademacher Averages", "text": "The main theorems above critically depend on the estimation of the Rademacher average Rm. In this section, we establish its estimation and prove the examples listed in Section 2. For notational simplicity, denote by x\u2113i the \u2113-th variable of the i-th sample xi \u2208 Rd.\nProof of Example 1: The dual norm of L1-norm is the L\u221e-norm. Hence,\nX\u2217 = sup x,x\u2032\u2208X sup \u2113,k\u2208Nd |x\u2113(x\u2032)k| = sup x\u2208X \u2016x\u20162\u221e. (16)\nAlso, the Rademacher average can be rewritten as\nRm = Ez,\u03c3 sup x\u2208X \u2016 1 m \u2211\nj\u2208Nm\n\u03c3jyjxjx T \u2016\u221e \u2264 sup x\u2208X \u2016x\u2016\u221e Ez,\u03c3 max \u2113\u2208Nd\n\u2223 \u2223 \u2223 1\nm\n\u2211\nj\u2208Nm\n\u03c3jyjx \u2113 j\n\u2223 \u2223 \u2223 . (17)\nNow let U\u2113(\u03c3) = 1 m\n\u2211\nj\u2208Nm\n\u03c3jyjx \u2113 j, for any \u2113 \u2208 Nd. By Jensen\u2019s inequality, for any \u03b7 > 0,\nwe have e\u03b7 2(E\u03c3 max\u2113\u2208Nd |U\u2113(\u03c3)|) 2 \u2212 1 \u2264 E\u03c3[e\u03b7 2(max\u2113\u2208Nd |U\u2113(\u03c3)|) 2 \u2212 1]\n= E\u03c3[max \u2113\u2208Nd\ne\u03b7 2|U\u2113(\u03c3)| 2 \u2212 1] \u2264 \u2211\n\u2113\u2208Nd\nE\u03c3[e \u03b72(|U\u2113(\u03c3)|) 2 \u2212 1]. (18)\nFurthermore, for any \u2113 \u2208 Nd, there holds\nE\u03c3[e \u03b72(|U\u2113(\u03c3)|) 2 \u2212 1] = \u2211\nk\u22651\n1 k! \u03b72kE\u03c3|U\u2113|2k\n\u2264 \u2211\nk\u22651\n1 k! \u03b72k(2k \u2212 1)k(E\u03c3|U\u2113|2)k \u2264 \u2211\nk\u22651\n(2e\u03b72E\u03c3|U\u2113|2)k,\nwhere the first inequality follows from the Khinchin-type inequality (see Lemma 3 in the Appendix), and the second inequality holds due to the Stirling\u2019s inequality:e\u2212kkk \u2264 k!. Now set \u03b7 = [2\n\u221a emax \u2113\u2208Nd (E\u03c3|U\u2113|2) 1 2 ]\u22121. The above inequality can be upper bounded\nby\nE[e\u03b7 2(|U\u2113(\u03c3)|) 2 \u2212 1] \u2264 \u2211\nk\u22651\n2\u2212k = 1, \u2200\u2113 \u2208 Nd.\nPutting the above estimation back into (18) implies that\ne\u03b7 2(Emax\u2113\u2208Nd |U\u2113(\u03c3)|) 2 \u2212 1 \u2264 d. That means\nE\u03c3 max \u2113\u2208Nd |U\u2113(\u03c3)| = E\u03c3 max \u2113\u2208Nd\n\u2223 \u2223\n1\nm\n\u2211\nj\u2208Nm\n\u03c3jyjx \u2113 j\n\u2223 \u2223 \u2264 \u221a log(d+ 1)\u03b7\u22122\n= 2 \u221a\ne log(d+ 1)max \u2113\u2208Nd\n(E\u03c3|U\u2113|2) 1 2\n= 2 \u221a\ne log(d+ 1)max \u2113\u2208Nd\n(\nE\u03c3\n\u2223 \u2223 \u2223 1\nm\nn \u2211\nj\u2208Nm\n\u03c3jyjx \u2113 j\n\u2223 \u2223 \u2223\n2) 1 2\n= 2 \u221a\ne log(d+ 1)max \u2113\u2208Nd\n( E\u03c3 1\nm2\n\u2211\nj,k\u2208Nm\n\u03c3j\u03c3kyjykx \u2113 jx \u2113 k\n) 1\n2\n= 2 \u221a\ne log(d+ 1)max \u2113\u2208Nd\n( 1\nm2\n\u2211\nj\u2208Nm\n(x\u2113j) 2 )\n1 2 \u2264 2 sup x\u2208X \u2016x\u2016\u221e \u221a e log(d+ 1) m .\n(19)\nPutting the above estimation back into (17) implies that\nRm \u2264 2 sup x\u2208X \u2016x\u20162\u221e\n\u221a\ne log(d+ 1)\nm .\nThe other desired results in the example follow directly from combining the above estimation with Theorems 1 and 2.\nWe turn our attention to similarity learning formulation (2) with the Frobenius norm regularization.\nProof of Example 2: The dual norm of the Frobenius norm is itself. Consequently, X\u2217 = sup\nx,x\u2032\u2208X \u2016x\u2032xT \u2016F = sup x\u2208X \u2016x\u20162F . The Rademacher average can be rewritten as\nRn = Ez,\u03c3 sup x\u2208X\n\u2225 \u2225 \u2225 1\nm\n\u2211\nj\u2208Nm\n\u03c3jyjxjx T \u2225 \u2225 \u2225\nF .\nBy Cauchy\u2019s Inequality, there holds\nRn \u2264 Ez,\u03c3 sup x\u2208X\n\u2016x\u2016F \u2225 \u2225 \u2225 1\nm\n\u2211\nj\u2208Nm\n\u03c3jyjxj\n\u2225 \u2225 \u2225\nF = Ez,\u03c3 sup x\u2208X \u2016x\u2016F\n( d \u2211\nk=1\n( 1\nm\n\u2211\nj\u2208Nm\n\u03c3jyjx k j\n)2) 1 2\n\u2264 Ez sup x\u2208X\n\u2016x\u2016F (\nd \u2211\nk=1\nE\u03c3\n( 1\nm\n\u2211\nj\u2208Nm\n\u03c3jyjx k j\n)2) 1 2\n= Ez sup x\u2208X\n\u2016x\u2016F (\nd \u2211\nk=1\n1\nm2\n\u2211\nj\u2208Nm\n(xkj ) 2 )\n1 2\n= Ez sup x\u2208X\n\u2016x\u2016F ( 1\nm2\n\u2211\nj\u2208Nm\n\u2016xj\u20162F )\n1 2 \u2264 sup x\u2208X \u2016x\u20162F 1\u221a m .\n.\nThen, the desired results can be derived by combining the above estimation with Theorems 1 and 2.\nThe above generalization bound for similarity learning formulation (2) with the Frobenius norm regularization is consistent with that given in [3], where the result holds true under the assumption that supx\u2208X \u2016x\u2016F \u2264 1. Below, we provide the estimation of Rm respectively for the mixed (2, 1)-norm and the trace norm.\nExample 3. Consider similarity learning formulation (2) with the mixed (2, 1)-norm regularization \u2016A\u2016(2,1) = \u2211 k\u2208Nd ( \u2211 \u2113\u2208Nd |Ak\u2113|2)1/2. Then, we have the following estimation.\n(a) X\u2217 \u2264 [ supx\u2208X \u2016x\u2016F ][ supx\u2208X \u2016x\u2016\u221e ] and\nRm \u2264 2 [\nsup x\u2208X\n\u2016x\u2016F ][\nsup x\u2208X\n\u2016x\u2016\u221e ]\n\u221a\ne log(d+ 1)\nm .\n(b) For any 0 < \u03b4 < 1, with confidence at least 1\u2212 \u03b4, there holds\nE(Az)\u2212 Ez(Az) \u2264 12 [ supx\u2208X \u2016x\u2016F ][ supx\u2208X \u2016x\u2016\u221e ]\nr\u03bb\n\u221a\ne log(d+1) m\n+ 2 [ supx\u2208X \u2016x\u2016F ][ supx\u2208X \u2016x\u2016\u221e ]\nr\u03bb\n\u221a\n2 ln ( 1\n\u03b4\n)\nm .\n(20)\n(c) For any 0 < \u03b4 < 1, with probability at least 1\u2212 \u03b4 there holds\nE (fz) \u2264 Ez(Az) + 4 [ supx\u2208X \u2016x\u2016F ][ supx\u2208X \u2016x\u2016\u221e ]\n\u03bbr\n\u221a\n2e log(d+1) m\n+ 2 [ supx\u2208X \u2016x\u2016F ][ supx\u2208X \u2016x\u2016\u221e ]\n\u03bbr\n\u221a\n2 log 1 \u03b4\nm .\nProof. The dual norm of the (2, 1)-norm is the (2,\u221e)-norm, which implies that X\u2217 = sup\nx,x\u2032\u2208X \u2016x\u2032xT \u2016(2,\u221e) = sup x\u2208X \u2016x\u2016F sup x\u2032\u2208X \u2016x\u2032\u2016\u221e and\nEz,\u03c3 sup x\u2208X\n\u2225 \u2225 \u2225 1\nm\n\u2211\nj\u2208Nm\n\u03c3jyjxjx T \u2225 \u2225 \u2225\n\u2217 \u2264 sup x\u2208X \u2016x\u2016FEz,\u03c3 max \u2113\u2208Nd\n\u2223 \u2223 \u2223 1\nm\n\u2211\nj\u2208Nm\n\u03c3jyjx \u2113 j\n\u2223 \u2223 \u2223\n\u2264 2 sup x\u2208X \u2016x\u2016F sup x\n\u2016x\u2016\u221e \u221a e log(d+ 1)\nm ,\nwhere the last inequality follows from estimation (19). We complete the proof by combining the above estimation with Theorems 1 and 2.\nWe briefly discuss the case of the trace norm regularization, i.e., \u2016A\u2016 = \u2016A\u2016tr. In this case, the dual norm of trace norm is the spectral norm defined, for any B \u2208 Sd\u00d7d, by \u2016B\u2016\u2217 = max\u2113\u2208Nd \u03c3\u2113(B) where {\u03c3\u2113 : \u2113 \u2208 Nd} are the singular values of matrix B.\nObserve, for any u, v \u2208 Rd, that \u2016uvT \u2016\u2217 = \u2016u\u2016F \u2016v\u2016F . Hence, the constant X\u2217 = sup\nx,x\u2032\u2208X \u2016x\u2032xT \u2016\u2217 = sup x\u2208X \u2016x\u20162F . In addition,\nRm = Ez,\u03c3 sup x\u2208X\n\u2225 \u2225 \u2225 1\nm\n\u2211\nj\u2208Nm\n\u03c3jyjxjx T \u2225 \u2225 \u2225\n\u2217 = Ez,\u03c3 sup x\u2208X \u2016x\u2016F\n\u2225 \u2225 \u2225 1\nm\n\u2211\nj\u2208Nm\n\u03c3jyjxj\n\u2225 \u2225 \u2225\nF \u2264 sup x\u2208X \u2016x\u20162F 1\u221a m .\nThese estimations above mean that the estimation for X\u2217 and Rm are the same as those for the Frobenius norm regularization. Hence the generalization bounds for similarity learning and the relationship between similarity learning and the linear SVM are the same as those stated in Example 2. It is a bit disappointing that there is no improvement when using the trace norm. The possible reason is that the spectral norm of B and the Frobenius norm of B are the same when B takes the form B = xyT for any x, y \u2208 Rd."}, {"heading": "7 Conclusion", "text": "In this paper, we considered a regularized similarity learning formulation (2). Its generalization bounds were established for various matrix-norm regularization terms such as the Frobenius norm, sparse L1-norm, and mixed (2, 1)-norm. We proved the generalization error of the linear separator based on the learnt similarity function can be bounded by the derived generalization bound of similarity learning. This guarantees the goodness of the generalization of similarity learning (2) with general matrix-norm regularization and thus the classification generalization of the resulting linear classifier. Our techniques using the Rademacher complexity [5] and the important Khinchin-type inequality for the Rademacher variables allows us to obtain new bounds for similarity learning that have a mild dependence on the input dimensionality.\nThere are several possible directions for future work. Firstly, we may consider similarity algorithms with general loss functions. It is expected that under some convexity conditions on the loss functions, better results could be obtained. Secondly, we usually focus on the excess misclassification error when considering classification problems. Hence, in the future, we would like to consider the theoretical link between the generalization bounds of the similarity learning and the excess misclassification error of the classifier built from the learnt similarity function.\nAcknowledgement:\nThis work is supported by the EPSRC under grant EP/J001384/1. The corresponding author is Yiming Ying."}], "references": [{"title": "A theory of learning with similarity functions", "author": ["M.-F. Balcan", "A. Blum"], "venue": "COLT,", "citeRegEx": "1", "shortCiteRegEx": null, "year": 2006}, {"title": "Improved gaurantees for learning via similarity functions", "author": ["M.-F. Balcan", "A. Blum", "N. Srebro"], "venue": "COLT,", "citeRegEx": "2", "shortCiteRegEx": null, "year": 2008}, {"title": "Similarity learning for provably accurate sparse linear classification", "author": ["A. Bellet", "A. Habrard", "M. Sebban"], "venue": "ICML,", "citeRegEx": "3", "shortCiteRegEx": null, "year": 2012}, {"title": "Rademacher and Gaussian complexities: risk bounds and structural results", "author": ["P.L. Bartlett", "S. Mendelson"], "venue": "J. of Machine Learning Research, 3: 463\u2013482,", "citeRegEx": "5", "shortCiteRegEx": null, "year": 2002}, {"title": "Stability and generalization", "author": ["O. Bousequet", "A. Elisseeff"], "venue": "J. of Machine Learning Research, 2: 499\u2013526,", "citeRegEx": "6", "shortCiteRegEx": null, "year": 2002}, {"title": "Generalization bounds for metric and similarity learning", "author": ["Q. Cao", "Z.-C. Guo", "Y. Ying"], "venue": "Preprint,", "citeRegEx": "7", "shortCiteRegEx": null, "year": 2012}, {"title": "Similaritybased classification: concepts and algorithms", "author": ["Y. Chen", "E.K. Garcia", "M.R. Gupta", "A. Rahimi", "L. Cazzanti"], "venue": "J. of Machine Learning Research, 10:747-776,", "citeRegEx": "8", "shortCiteRegEx": null, "year": 2009}, {"title": "Large scale online learning of image similarity through ranking", "author": ["G. Chechik", "V. Sharma", "U. Shalit", "S. Bengio"], "venue": "J. of Machine Learning Research, 11: 1109-1135,", "citeRegEx": "9", "shortCiteRegEx": null, "year": 2010}, {"title": "Is that you? Metric learning approaches for face identification", "author": ["M. Guillaumin", "J. Verbeek", "C. Schmid"], "venue": "ICCV", "citeRegEx": "10", "shortCiteRegEx": null, "year": 2009}, {"title": "Information-theoretic metric learning", "author": ["J. Davis", "B. Kulis", "P. Jain", "S. Sra", "I. Dhillon"], "venue": "ICML,", "citeRegEx": "11", "shortCiteRegEx": null, "year": 2007}, {"title": "Learning distance metrics with contextual constraints for image retrieval", "author": ["S.C.H. Hoi", "W. Liu", "M.R. Lyu", "W.-Y. Ma"], "venue": "IEEE Computer Society Conference on Computer Vision and Pattern Recognition, pages 2072\u20132078,", "citeRegEx": "12", "shortCiteRegEx": null, "year": 2006}, {"title": "Supervised learning with similarity functions", "author": ["P. Jain", "P. Kar"], "venue": "NIPS,", "citeRegEx": "13", "shortCiteRegEx": null, "year": 2012}, {"title": "Regularized distance metric learning: theory and algorithm", "author": ["R. Jin", "S. Wang", "Y. Zhou"], "venue": null, "citeRegEx": "14", "shortCiteRegEx": "14", "year": 2009}, {"title": "Similarity-based learning via data-driven embeddings", "author": ["P. Kar", "P. Jain"], "venue": "NIPS,", "citeRegEx": "15", "shortCiteRegEx": null, "year": 2011}, {"title": "Empirical margin distributions and bounding the generalization error of combined classifiers", "author": ["V. Koltchinskii", "V. Panchenko"], "venue": "The Annals of Statistics, 30, 1\u20135,", "citeRegEx": "16", "shortCiteRegEx": null, "year": 2002}, {"title": "Probability in Banach Spaces: Isoperimetry and Processes", "author": ["M. Ledoux", "M. Talagrand"], "venue": "Springer Press, New York,", "citeRegEx": "17", "shortCiteRegEx": null, "year": 1991}, {"title": "Learning similarity with operator-valued large-margin classifiers", "author": ["A. Maurer"], "venue": "J. of Machine Learning Research, 9: 1049\u20131082,", "citeRegEx": "18", "shortCiteRegEx": null, "year": 2008}, {"title": "Surveys in Combinatorics, Chapter On the methods of bounded differences, 148\u2013188", "author": ["C. McDiarmid"], "venue": null, "citeRegEx": "19", "shortCiteRegEx": "19", "year": 1989}, {"title": "Learning with non-positive kernels", "author": ["C.S. Ong", "X. Mary", "S. Canu", "A.J. Smola"], "venue": "ICML,", "citeRegEx": "20", "shortCiteRegEx": null, "year": 2004}, {"title": "Decoupling: from Dependence to Independence", "author": ["V.H. De La Pe\u00f1a", "E. Gin\u00e9"], "venue": null, "citeRegEx": "21", "shortCiteRegEx": "21", "year": 1999}, {"title": "Protein homology detection using string alignment kernels", "author": ["H. Saigo", "J.P. Vert", "N. Ueda", "T. Akutsu"], "venue": "Bioinformatics, 20: 1682\u20131689.,", "citeRegEx": "22", "shortCiteRegEx": null, "year": 2004}, {"title": "Regularization with dot-product kernels", "author": ["A.J. Smola", "Z.L. \u00d3v\u0301ari", "R.C. Williamson"], "venue": null, "citeRegEx": "23", "shortCiteRegEx": "23", "year": 2000}, {"title": "Statistical Learning Theory", "author": ["V.N. Vapnik"], "venue": "Wiley, New York,", "citeRegEx": "24", "shortCiteRegEx": null, "year": 1998}, {"title": "On learning with dissimilarity functions", "author": ["L. Wang", "C. Yang", "J. Feng"], "venue": "ICML,", "citeRegEx": "25", "shortCiteRegEx": null, "year": 2007}, {"title": "Distance metric learning for large margin nearest neighbour classification", "author": ["K.Q. Weinberger", "J. Blitzer", "L.K. Saul"], "venue": "NIPS,", "citeRegEx": "26", "shortCiteRegEx": null, "year": 2006}, {"title": "SVM soft margin classifiers: linear programming versus quadratic programming", "author": ["Q. Wu", "D.X. Zhou"], "venue": "Neural computation, 17: 1160\u20131187,", "citeRegEx": "27", "shortCiteRegEx": null, "year": 2005}, {"title": "Regularization networks with indefinite kernels", "author": ["Q. Wu"], "venue": "Journal of Approximation Theory, 166: 1\u201318,", "citeRegEx": "28", "shortCiteRegEx": null, "year": 2013}, {"title": "Distance metric learning with application to clustering with side information", "author": ["E. Xing", "A. Ng", "M. Jordan", "S. Russell"], "venue": "NIPS,", "citeRegEx": "29", "shortCiteRegEx": null, "year": 2002}, {"title": "Analysis of SVM with indefinite kernels", "author": ["Y. Ying", "M. Girolami", "C. Campbell"], "venue": "NIPS,", "citeRegEx": "30", "shortCiteRegEx": null, "year": 2009}, {"title": "Sparse metric learning via smooth optimization", "author": ["Y. Ying", "K. Huang", "C. Campbell"], "venue": "NIPS,", "citeRegEx": "31", "shortCiteRegEx": null, "year": 2009}], "referenceMentions": [{"referenceID": 2, "context": "[3].", "startOffset": 0, "endOffset": 3}, {"referenceID": 4, "context": "Due to the techniques dependent on the notion of uniform stability [6], the bound obtained there holds true only for the Frobenius matrixnorm regularization, which has a strong dependence on the dimensionality of the input space.", "startOffset": 67, "endOffset": 70}, {"referenceID": 3, "context": "Our techniques using the Rademacher complexity [5] and its related Khinchin-type inequality, in the cases of sparse L-norm and mixed (2, 1)-norm regularization, enables us to obtain bounds that have a mild dependence on the input dimensionality.", "startOffset": 47, "endOffset": 50}, {"referenceID": 9, "context": "The first approach is referred to as metric learning [4, 11, 12, 14, 26, 29, 31] which often focuses on learning a Mahalanobis distance metric defined, for any x, x\u2032 \u2208 Rd, by dM (x, x\u2032) = \u221a (x\u2212 x\u2032)TM(x\u2212 x\u2032).", "startOffset": 53, "endOffset": 80}, {"referenceID": 10, "context": "The first approach is referred to as metric learning [4, 11, 12, 14, 26, 29, 31] which often focuses on learning a Mahalanobis distance metric defined, for any x, x\u2032 \u2208 Rd, by dM (x, x\u2032) = \u221a (x\u2212 x\u2032)TM(x\u2212 x\u2032).", "startOffset": 53, "endOffset": 80}, {"referenceID": 12, "context": "The first approach is referred to as metric learning [4, 11, 12, 14, 26, 29, 31] which often focuses on learning a Mahalanobis distance metric defined, for any x, x\u2032 \u2208 Rd, by dM (x, x\u2032) = \u221a (x\u2212 x\u2032)TM(x\u2212 x\u2032).", "startOffset": 53, "endOffset": 80}, {"referenceID": 24, "context": "The first approach is referred to as metric learning [4, 11, 12, 14, 26, 29, 31] which often focuses on learning a Mahalanobis distance metric defined, for any x, x\u2032 \u2208 Rd, by dM (x, x\u2032) = \u221a (x\u2212 x\u2032)TM(x\u2212 x\u2032).", "startOffset": 53, "endOffset": 80}, {"referenceID": 27, "context": "The first approach is referred to as metric learning [4, 11, 12, 14, 26, 29, 31] which often focuses on learning a Mahalanobis distance metric defined, for any x, x\u2032 \u2208 Rd, by dM (x, x\u2032) = \u221a (x\u2212 x\u2032)TM(x\u2212 x\u2032).", "startOffset": 53, "endOffset": 80}, {"referenceID": 29, "context": "The first approach is referred to as metric learning [4, 11, 12, 14, 26, 29, 31] which often focuses on learning a Mahalanobis distance metric defined, for any x, x\u2032 \u2208 Rd, by dM (x, x\u2032) = \u221a (x\u2212 x\u2032)TM(x\u2212 x\u2032).", "startOffset": 53, "endOffset": 80}, {"referenceID": 7, "context": "This approach has been successfully applied to image searching [9] and object recognition [18].", "startOffset": 63, "endOffset": 66}, {"referenceID": 16, "context": "This approach has been successfully applied to image searching [9] and object recognition [18].", "startOffset": 90, "endOffset": 94}, {"referenceID": 5, "context": "The generalization bounds were recently established for metric and similarity learning [7, 14, 18] under different statistical assumptions on the data.", "startOffset": 87, "endOffset": 98}, {"referenceID": 12, "context": "The generalization bounds were recently established for metric and similarity learning [7, 14, 18] under different statistical assumptions on the data.", "startOffset": 87, "endOffset": 98}, {"referenceID": 16, "context": "The generalization bounds were recently established for metric and similarity learning [7, 14, 18] under different statistical assumptions on the data.", "startOffset": 87, "endOffset": 98}, {"referenceID": 12, "context": "In other words, it is not clear whether good generalization bounds for metric and similarity learning [14, 7] can lead to a good classification performance of the resultant k-NN classifiers.", "startOffset": 102, "endOffset": 109}, {"referenceID": 5, "context": "In other words, it is not clear whether good generalization bounds for metric and similarity learning [14, 7] can lead to a good classification performance of the resultant k-NN classifiers.", "startOffset": 102, "endOffset": 109}, {"referenceID": 21, "context": "Such cases are quite common in applications such as hyperbolic tangent kernels [23], and the protein sequence similarity measures derived from SmithWaterman and BLAST score [22].", "startOffset": 79, "endOffset": 83}, {"referenceID": 20, "context": "Such cases are quite common in applications such as hyperbolic tangent kernels [23], and the protein sequence similarity measures derived from SmithWaterman and BLAST score [22].", "startOffset": 173, "endOffset": 177}, {"referenceID": 6, "context": "Some methods [8, 30] learn a PSD kernel matrix from a prescribed indefinite kernel matrix, which are mostly restricted to the transductive settings.", "startOffset": 13, "endOffset": 20}, {"referenceID": 28, "context": "Some methods [8, 30] learn a PSD kernel matrix from a prescribed indefinite kernel matrix, which are mostly restricted to the transductive settings.", "startOffset": 13, "endOffset": 20}, {"referenceID": 25, "context": "Recent methods [27, 28] analyzed regularization networks such as ridge regression and SVM given a prescribed indefinite kernel, instead of aiming to learn an indefinite kernel function from data.", "startOffset": 15, "endOffset": 23}, {"referenceID": 26, "context": "Recent methods [27, 28] analyzed regularization networks such as ridge regression and SVM given a prescribed indefinite kernel, instead of aiming to learn an indefinite kernel function from data.", "startOffset": 15, "endOffset": 23}, {"referenceID": 2, "context": "[3] proposed a regularized similarity learning approach, which is mainly motivated by the (\u03b5, \u03b3, \u03c4)good similarity functions introduced in [1, 2].", "startOffset": 0, "endOffset": 3}, {"referenceID": 0, "context": "[3] proposed a regularized similarity learning approach, which is mainly motivated by the (\u03b5, \u03b3, \u03c4)good similarity functions introduced in [1, 2].", "startOffset": 139, "endOffset": 145}, {"referenceID": 1, "context": "[3] proposed a regularized similarity learning approach, which is mainly motivated by the (\u03b5, \u03b3, \u03c4)good similarity functions introduced in [1, 2].", "startOffset": 139, "endOffset": 145}, {"referenceID": 4, "context": "However, due to the techniques dependent on the notion of uniform stability [6], the generalization bounds only hold true for the Frobenius matrix-norm regularization which usually has a strong dependence on the dimensionality of the input space.", "startOffset": 76, "endOffset": 79}, {"referenceID": 3, "context": "Our techniques using the Rademacher complexity [5] and the important Khinchin-type inequality for the Rademacher variables, in the cases of sparse L1-norm, and mixed (2, 1)-norm regularization, enables us to derive bounds that have a mild dependence on the input dimensionality.", "startOffset": 47, "endOffset": 50}, {"referenceID": 0, "context": "A natural approach to achieve the above aim [1, 3] is to minimize the following empirical error Ez(A) = 1 m \u2211", "startOffset": 44, "endOffset": 50}, {"referenceID": 2, "context": "A natural approach to achieve the above aim [1, 3] is to minimize the following empirical error Ez(A) = 1 m \u2211", "startOffset": 44, "endOffset": 50}, {"referenceID": 2, "context": "Its special case with the Frobenius matrix norm was established in [3].", "startOffset": 67, "endOffset": 70}, {"referenceID": 4, "context": "It used the uniform stability techniques [6], which, however, can not deal with non-strongly convex matrix-norms such as the L1-norm, (2, 1)-mixed norm and trace norm.", "startOffset": 41, "endOffset": 44}, {"referenceID": 3, "context": "Our new analysis techniques are able to deal with general matrix norms, which depend on the concept of Rademacher averages [5] defined as follows.", "startOffset": 123, "endOffset": 126}, {"referenceID": 22, "context": "We show that the generalization bound for the similarity learning gives an upper bound for the generalization error of a linear classifier produced by the linear Support Vector Machine (SVM) [24] defined as follows: fz = argmin { 1 m \u2211", "startOffset": 191, "endOffset": 195}, {"referenceID": 2, "context": "Secondly, the bounds in Example 2 is consistent with that in [3].", "startOffset": 61, "endOffset": 64}, {"referenceID": 0, "context": "For instance, if the input space X = [0, 1]d, then we have supx\u2208X \u2016x\u2016\u221e = 1 and supx\u2208X \u2016x\u2016F = \u221a d.", "startOffset": 37, "endOffset": 43}, {"referenceID": 5, "context": "[4, 7, 9, 12, 14, 18, 26, 29].", "startOffset": 0, "endOffset": 29}, {"referenceID": 7, "context": "[4, 7, 9, 12, 14, 18, 26, 29].", "startOffset": 0, "endOffset": 29}, {"referenceID": 10, "context": "[4, 7, 9, 12, 14, 18, 26, 29].", "startOffset": 0, "endOffset": 29}, {"referenceID": 12, "context": "[4, 7, 9, 12, 14, 18, 26, 29].", "startOffset": 0, "endOffset": 29}, {"referenceID": 16, "context": "[4, 7, 9, 12, 14, 18, 26, 29].", "startOffset": 0, "endOffset": 29}, {"referenceID": 24, "context": "[4, 7, 9, 12, 14, 18, 26, 29].", "startOffset": 0, "endOffset": 29}, {"referenceID": 27, "context": "[4, 7, 9, 12, 14, 18, 26, 29].", "startOffset": 0, "endOffset": 29}, {"referenceID": 12, "context": "[14] established generalization bounds for regularized metric learning algorithms via the concept of uniform stability [5], which, however, only works for strongly convex matrix regularization terms.", "startOffset": 0, "endOffset": 4}, {"referenceID": 3, "context": "[14] established generalization bounds for regularized metric learning algorithms via the concept of uniform stability [5], which, however, only works for strongly convex matrix regularization terms.", "startOffset": 119, "endOffset": 122}, {"referenceID": 5, "context": "A very recent work [7] established generalization bounds for the metric and similarity learning associated with general matrix norm regularization using techniques of Rademacher averages and U-statistics.", "startOffset": 19, "endOffset": 22}, {"referenceID": 7, "context": "For instance, the following pairwise empirical objective function was considered in [9, 7]: 1 m(m\u2212 1) m \u2211", "startOffset": 84, "endOffset": 90}, {"referenceID": 5, "context": "For instance, the following pairwise empirical objective function was considered in [9, 7]: 1 m(m\u2212 1) m \u2211", "startOffset": 84, "endOffset": 90}, {"referenceID": 1, "context": "[2] developed a theory of (\u01eb, \u03b3, \u03c4)-good similarity function defined as follows.", "startOffset": 0, "endOffset": 3}, {"referenceID": 1, "context": "It was mentioned in [2] that the linear separator can be estimated by solving the following linear programming if we have du potentially unlabeled sample and dl labeled sample, min \u03b1 { dl \u2211", "startOffset": 20, "endOffset": 23}, {"referenceID": 1, "context": "[2] in the following two aspects.", "startOffset": 0, "endOffset": 3}, {"referenceID": 1, "context": "Secondly, although the separators are both trained from the linear SVM, the classification algorithm (13) in [2] was designed using two different sets of examples, a set of labeled samples of size dl to train the classification algorithm and another set of unlabeled samples with size du to define the mapping \u03c6 S .", "startOffset": 109, "endOffset": 112}, {"referenceID": 2, "context": "[3] is mostly close to ours.", "startOffset": 0, "endOffset": 3}, {"referenceID": 4, "context": "Generalization bounds for similarity learning were derived via uniform stability arguments [6] which can not deal with, for instance, the L1-norm and (2, 1)-norm regularization terms.", "startOffset": 91, "endOffset": 94}, {"referenceID": 1, "context": "In addition, the results about the relationship between the similarity learning and the performance of the learnt matrix in classification were quoted from [2] and hence requires two separate sets of samples to train the classifier.", "startOffset": 156, "endOffset": 159}, {"referenceID": 11, "context": "[13] and Kar et al.", "startOffset": 0, "endOffset": 4}, {"referenceID": 13, "context": "[15] introduced an extended framework of [1, 2] in the general setting of supervised learning.", "startOffset": 0, "endOffset": 4}, {"referenceID": 0, "context": "[15] introduced an extended framework of [1, 2] in the general setting of supervised learning.", "startOffset": 41, "endOffset": 47}, {"referenceID": 1, "context": "[15] introduced an extended framework of [1, 2] in the general setting of supervised learning.", "startOffset": 41, "endOffset": 47}, {"referenceID": 1, "context": "The authors proposed a general goodness criterion for similarity functions, which can handle general supervised learning tasks and also subsumes the goodness of condition of [2].", "startOffset": 174, "endOffset": 177}, {"referenceID": 17, "context": "Applying the McDiarmid\u2019s inequality [19] (see Lemma 1 in the Appendix) to the term sup A\u2208A [ E(A)\u2212 Ez(A) ] , with probability at least 1\u2212 \u03b4, there holds sup A\u2208A [ E(A)\u2212 Ez(A) ] \u2264 Ez sup A\u2208A [ E(A)\u2212 Ez(A) ]", "startOffset": 36, "endOffset": 40}, {"referenceID": 3, "context": "[5]), from the above estimation we can further estimate I2 as follows: I2 \u2264 1 r\u03bbEz sup x\u2208X \u2225 \u2225 \u2225 Ez\u2032 1 m \u2211", "startOffset": 0, "endOffset": 3}, {"referenceID": 2, "context": "The above generalization bound for similarity learning formulation (2) with the Frobenius norm regularization is consistent with that given in [3], where the result holds true under the assumption that supx\u2208X \u2016x\u2016F \u2264 1.", "startOffset": 143, "endOffset": 146}], "year": 2017, "abstractText": "Learning an appropriate (dis)similarity function from the available data is a central problem in machine learning, since the success of many machine learning algorithms critically depends on the choice of a similarity function to compare examples. Despite many approaches for similarity metric learning have been proposed, there is little theoretical study on the links between similarity metric learning and the classification performance of the result classifier. In this paper, we propose a regularized similarity learning formulation associated with general matrix-norms, and establish their generalization bounds. We show that the generalization error of the resulting linear separator can be bounded by the derived generalization bound of similarity learning. This shows that a good generalization of the learnt similarity function guarantees a good classification of the resulting linear classifier. Our results extend and improve those obtained by Bellet at al. [3]. Due to the techniques dependent on the notion of uniform stability [6], the bound obtained there holds true only for the Frobenius matrixnorm regularization, which has a strong dependence on the dimensionality of the input space. Our techniques using the Rademacher complexity [5] and its related Khinchin-type inequality, in the cases of sparse L-norm and mixed (2, 1)-norm regularization, enables us to obtain bounds that have a mild dependence on the input dimensionality.", "creator": "LaTeX with hyperref package"}}}