{"id": "1306.3203", "review": {"conference": "NIPS", "VERSION": "v1", "DATE_OF_SUBMISSION": "13-Jun-2013", "title": "Bregman Alternating Direction Method of Multipliers", "abstract": "the selective descent algorithm ( mda ) combines functional fraction regression using universal bregman trace - analysis to provide numerical euclidean distance as a proximal function. beyond previous paper, we simi - larly implement simpler approximate direction method reverse reflection ( lcd ) specifically bregman admm ( cm ), which uses bregman divergences rendering all functions converge frames. badmm updates then use unique generalized bregman generators for coordinate variable updates and creates alternating optimization - style jumps, involves alternating additive and elastic multiplicative effects giving adaptive options. badmm handles global unified repertoire for admm and its users, including generalized indices and tensor admm. we are the global gradient subgroup badmm. we present promising optimization theorem results for badmm response to opti - mization over map related matrices.", "histories": [["v1", "Thu, 13 Jun 2013 19:22:16 GMT  (254kb)", "http://arxiv.org/abs/1306.3203v1", null], ["v2", "Tue, 1 Jul 2014 05:57:36 GMT  (325kb)", "http://arxiv.org/abs/1306.3203v2", null], ["v3", "Tue, 8 Jul 2014 03:55:36 GMT  (625kb)", "http://arxiv.org/abs/1306.3203v3", null]], "reviews": [], "SUBJECTS": "math.OC cs.LG stat.ML", "authors": ["huahua wang", "arindam banerjee"], "accepted": true, "id": "1306.3203"}, "pdf": {"name": "1306.3203.pdf", "metadata": {"source": "CRF", "title": "Bregman Alternating Direction Method of Multipliers", "authors": ["Huahua Wang", "Arindam Banerjee"], "emails": ["huwang@cs.umn.edu", "banerjee@cs.umn.edu"], "sections": [{"heading": null, "text": "ar X\niv :1\n30 6.\n32 03\nv1 [\nm at\nh. O\nC ]\n1 3\nJu n"}, {"heading": "1 Introduction", "text": "In recent years, the alternating direction method of multipliers (ADM or ADMM) [4] has been successfully applied in a broad spectrum of applications, ranging from image processing [11, 1, 13] to applied statistics and machine learning [23, 27, 20, 26]. The proof of global convergence of ADMM can be found in [12, 4]. Recently, it has been shown that ADMM converges at a rate of O(1/T ) [26, 16], where T is the number of iterations. For strongly convex functions, the dual objective of an accelerated version of ADMM can converge at a rate of O(1/T 2) [14]. Under suitable assumptions like strongly convex functions or a sufficiently small step size for the dual variable update, ADMM can achieve a linear convergence rate [8, 21]. For further understanding of ADMM, we refer the readers to the comprehensive review by [4] and references therein.\nIn particular, ADMM considers the problem of minimizing composite objective functions subject to an equality constraint:\nmin x\u2208X ,z\u2208Z f(x) + g(z) s.t. Ax+Bz = c , (1)\nwhere f and g are convex functions, A \u2208 Rm\u00d7n1 ,B \u2208 Rm\u00d7n2 , c \u2208 Rm\u00d71, x \u2208 X \u2208 Rn1\u00d71, z \u2208 Z \u2208 Rn2\u00d71, and X and Z are convex sets. f and g can be non-smooth functions, including indicator functions of convex sets. Many machine learning problems can be cast into the framework of\nminimizing a composite objective [22, 10], where f is a loss function such as hinge or logistic loss, and g is a regularizer, e.g., \u21131 norm, \u21132 norm, nuclear norm or total variation. The two functions usually have different structures and constraints because they have different tasks in data mining. Therefore, it is useful and sometimes necessary to split them and solve them separately, which is exactly the forte of ADMM.\nIn each iteration, ADMM updates splitting variables separately and alternatively by solving the augmented Lagrangian of (1), which is defined as follows:\nL\u03c1(x, z,y) = f(x) + g(z) + \u3008y,Ax+Bz\u2212 c\u3009+ \u03c1\n2 \u2016Ax+Bz\u2212 c\u201622, (2)\nwhere y \u2208 Rm is dual variable, \u03c1 > 0 is penalty parameter, and the quadratic penalty term is to penalize the violation of the equality constraint. ADMM consists of the following three updates:\nxt+1 = argmin x\u2208X\nf(x) + \u3008yt,Ax+Bzt \u2212 c\u3009+ \u03c1\n2 \u2016Ax+Bzt \u2212 c\u201622 , (3)\nzt+1 = argmin z\u2208Z\ng(z) + \u3008yt,Axt+1 +Bz\u2212 c\u3009+ \u03c1\n2 \u2016Axt+1 +Bz\u2212 c\u201622 , (4)\nyt+1 = yt + \u03c1(Axt+1 +Bzt+1 \u2212 c) . (5)\nSince the computational complexity of y update (5) is trivial, the computational complexity of ADMM lies in the x and z updates (3)-(4) which amount to solving proximal minimization problems using the quadratic penalty term. Inexact ADMM [4] and generalized ADMM [8] have also been proposed to solve the updates inexactly by linearizing the functions and adding additional quadratic terms. As far as we know, all existing ADMMs use quadratic penalty terms1.\nRecent work shows that replacing the quadratic penalty term by Bregman divergence could effectively exploit the structure of problems [6, 3, 10], particularly in clustering problems and exponential family distributions [2, 25]. Mirror descent algorithm (MDA) and composite objective mirror descent (COMID) [10] use Bregman divergence to replace the quadratic term in gradient descent or proximal gradient [7]. In particular, if the Bregman divergence is Kullback-Leibler (KL) divergence, MDA leads to exponentiated gradient or multiplicative update algorithms which performs better than additive update in gradient descent in some applications [18]. Proximal point method with D-functions (PMD) [6, 5] and Bregman proximal minimization (BPM) [19] generalize proximal point method by using Bregman divegence to replace the quadratic term. However, as pointed out by [4], \u201cThere is currently no proof of convergence known for ADMM with nonquadratic penalty terms.\u201d\nIn this paper, we propose Bregman ADMM (BADMM) where Bregman divergences are used in ADMM updates and establish the global convergence for BADMM. In particular, we show the quadratic penalty term in the x and z updates (3)-(4) can be replaced by a Bregman divergence, which answers the question raised in [4]. Since functions (f and g) and constraints (X and Z) usually have different structures, we may not have efficient algorithms by simply using the same Bregman divergence in the x and z updates. To allow the use of different Bregman divergences in\n1An exception is online ADMM [26], where the x update keeps the quadratic penalty term \u2016Ax +Bz \u2212 c\u20162 2 and has an additional Bregman divergence.\nBADMM, we introduce additional Bregman divergences in the x and z updates. BADMM provides a unified framework for solving (1), which allows one to choose suitable Bregman divergence so that the x and z updates can be solved efficiently. BADMM includes ADMM and its variants as special cases. In particular, BADMM replaces all quadratic terms in generalized ADMM [8] with Bregman divergences. By choosing a proper Bregman divergence, we also show that inexact ADMM can be considered as a special case of BADMM. BADMM generalizes ADMM similar to how MDA generalizes gradient descent and how PMD generalizes proximal methods. In BADMM, the x and z updates can take the form of MDA or PMD. In particular, BADMM updates become alternating additive updates when using quadratic functions and alternating multiplicative updates when using KL divergence. More generally,\nA motivating example to use BADMM is minimization over doubly stochastic matrices. Classical methods like MDA include the full projection onto doubly stochastic matrices in each iteration, which require alternating projections like the Sinkhorn algorithm [24]. By splitting doubly stochastic matrix into row stochastic matrix and column stochastic matrix, we can use BADMM to solve it. When using quadratic penalty terms, the x and z updates require doing Euclidean projections onto the unit simplex [9]. When using KL divergence, BADMM leads to a projectionfree alternating multiplicative updates which amount to elementwise operation and can be done in parallel.\nThe rest of the paper is organized as follows. In Section 2, we propose Bregman ADMM and discuss several special cases of BADMM. In Section 3, we establish the convergence of BADMM. In Sections 4, we consider an illustrative application of minimization over doubly stochastic matrices, and conclude in Section 5."}, {"heading": "2 Bregman Alternating Direction Method of Multipliers", "text": "Let \u03c6 : \u2126 \u2192 R be a continuously differentiable and strictly convex function on the relative interior of a convex set \u2126. Denote \u2207\u03c6(y) as the gradient of \u03c6 at y. We define Bregman divergence2 B\u03c6 : \u2126\u00d7 ri(\u2126) \u2192 R+ induced by \u03c6 as\nB\u03c6(x,y) = \u03c6(x)\u2212 \u03c6(y)\u2212 \u3008\u2207\u03c6(y),x\u2212 y\u3009 .\nSince \u03c6 is convex, B\u03c6(x,y) \u2265 0 where the equality holds if and only if x = y. More details about Bregman divergence can be found in [6, 2]. Two of the most commonly used examples are squared Euclidean distance B\u03c6(x,y) = 12\u2016x\u2212 y\u201622 and KL divergence B\u03c6(x,y) = \u2211n i=1 xi log xi yi\n. Assuming B\u03c6(c \u2212Ax,Bz) is well defined, we replace the quadratic penalty term in the aug-\nmented Lagrangian (2) by a Bregman divergence as follows:\nL\u03c6\u03c1(x, z,y) = f(x) + g(z) + \u3008y,Ax+Bz\u2212 c\u3009+ \u03c1B\u03c6(c\u2212Ax,Bz). (6)\nUnfortunately, we can not derive Bregman ADMM (BADMM) updates by simply solvingL\u03c6\u03c1(x, z,y) alternatingly as ADMM does because Bregman divergence is generally not symmetric. More\n2The definition of Bregman divergence has been generalized to nondifferentiable functions [19, 25].\nspecifically, given yt and zt, xt+1 can be obtained by solving L\u03c6\u03c1(x, zt,yt) as ADMM does. In other words, the quadratic penalty term 1\n2 \u2016Ax+Bzt\u2212c\u201622 in (3) is replaced with B\u03c6(c\u2212Ax,Bzt)\nin the x update of BADMM. However, we cannot get zt+1 by solving L\u03c6\u03c1(xt+1, z,yt), since L\u03c6\u03c1(xt+1, z,yt) contains the term B\u03c6(c\u2212Axt+1,Bz) which is not convex in z. Instead, the z update of BADMM uses B\u03c6(Bz, c\u2212Axt+1) to replace the quadratic penalty term 12\u2016Axt+1 +Bz\u2212 c\u201622 in (3). It is worth noting that the same Bregman divergence B\u03c6 is used in the x and z updates. To allow the use of different Bregman divergences, additional Bregman divergences are introduced in the x and z updates, which give more options for solving them efficiently. Therefore, we formally propose the following updates for BADMM:\nxt+1 = argmin x\u2208X\nf(x) + \u3008yt,Ax+Bzt \u2212 c\u3009+ \u03c1B\u03c6(c\u2212Ax,Bzt) + \u03c1xB\u03d5x(x,xt) , (7)\nzt+1 = argmin z\u2208Z\ng(z) + \u3008yt,Axt+1 +Bz\u2212 c\u3009+ \u03c1B\u03c6(Bz, c\u2212Axt+1) + \u03c1zB\u03d5z(z, zt) , (8)\nyt+1 = yt + \u03c4(Axt+1 +Bzt+1 \u2212 c) . (9)\nwhere \u03c1 > 0, \u03c4 > 0, \u03c1x \u2265 0, \u03c1z \u2265 0. Note that three Bregman divergences are used in BADMM. If all three of them are quadratic functions, Bregman ADMM reduces to generalized ADMM [8]. We allow the use of a different step size \u03c4 in the dual variable update [8, 21]. The global convergence for BADMM will be shown in Section 3.\nWe will discuss some special cases in two scenarios. In scenario 1 where \u03c1x, \u03c1z are zero, BADMM simply replaces the quadratic penalty term in ADMM by a single Bregman divergence. In this scenario, the x and z updates should be solved exactly. In scenario 2 where one or both of \u03c1x, \u03c1z are positive, we can choose different Bregman divergences in the x and z updates so that they can be solved inexactly. Compared to scenario 1, scenario 2 usually takes more iterations to converge but may be less expensive in solving the x and z updates. Since (7) and (8) are symmetric, the discussion below focuses on the x update, and can be applied for the z update. As a gentle reminder, the global convergence for BADMM in Section 3 automatically applies for the special cases considered here."}, {"heading": "2.1 Scenario 1: Exact BADMM Update", "text": "If \u03c1x = \u03c1z = 0, BADMM simply uses a single Bregman divergence to replace the quadratic penalty term in ADMM. This scenario is particularly useful when a single Bregman divergence \u03c6 can yield efficient algorithms for both the x and z updates.\nIn a special case, like consensus optimization [4], when A = \u2212I,B = I, c = 0, (7) becomes\nxt+1 = argmin x\u2208X\nf(x) + \u3008yt,\u2212x+ zt\u3009+ \u03c1B\u03c6(x, zt) . (10)\nThis special case is similar to Case 2 in Scenario 2. Further, if f is a linear function and X is the unit simplex, we have multiplicative update when using KL divergence. If the z update is also a multiplicative update, we have alternating multiplicative updates. In Section 4, we will show the minimization over doubly stochastic matrices can be cast into this scenario."}, {"heading": "2.2 Scenario 2: Inexact BADMM Update", "text": "This scenario is particularly useful when it is expensive to solve the x update exactly in Scenario 1. Instead, we solve the x update inexactly by adding another Bregman divergence B\u03d5x . Since there are two Bregman divergences B\u03c6 and B\u03d5x in the x update (7) and B\u03c6 is also used in the z update, we set B\u03c6 to be a quadratic term in this scenario, which is easy to be linearized and does not need any assumptions on A and B. Bregman divergence B\u03d5x can be be selected so that (7) can be solved efficiently.\nIn the following three special cases, we will show that the x update can be solved efficiently by linearizing some terms, say, \u03c8x. Let B\u03c8x be the Bregman divergence defined on \u03c8x. We denote the sum of \u03b2xB\u03c8x and B\u03d5x as a new Bregman divegence B\u03d5\u2032x , i.e., B\u03d5\u2032x = B\u03d5x +\u03b2xB\u03c8x . Using the linearity of Bregman divergence, \u03d5\u2032x = \u03d5x + \u03b2x\u03c8x. In other words, we assume \u03d5x = \u03d5 \u2032 x \u2212 \u03b2x\u03c8x. The following three cases show such a choice of \u03d5x can solve (7) efficiently. Case 1: Linearization of function f 3 Assume f is continuously differentiable and strictly convex defined on the convex set X . Let \u2207f(xt) be the gradient of f(x) at xt. Bregman divergence Bf 4 induced by f is defined as\nBf(x,xt) = f(x)\u2212 f(xt)\u2212 \u3008\u2207f(xt),x\u2212 xt\u3009 , (11)\nwhich can be considered as high order residuals in Taylor expansion of f at xt. Therefore, the linearization of f(x) at xt can be done by removing Bf(x,xt) from f(x), i.e.,\nf(x)\u2212Bf (x,xt) = f(xt) + \u3008\u2207f(xt),x\u2212 xt\u3009 . (12)\nLet B\u03d5x(x,xt) = B\u03d5\u2032x(x,xt)\u2212 1\u03c1xBf (x,xt). Removing constant terms, (7) becomes\nxt+1 = argmin x\u2208X\n\u3008\u2207f(xt),x\u2212 xt\u3009+ \u3008yt,Ax\u3009+ \u03c1B\u03c6(c\u2212Ax,Bzt) + \u03c1xB\u03d5\u2032 x (x,xt) . (13)\nThis case is particularly useful when the difficulty of solving (3) is caused by f(x), e.g., when f is a logistic loss function.\nExample 1 Consider the following ADMM form sparse logistic regression problem [15, 4]:\nmin x\nl(x) + \u03bb\u2016z\u20161 , s.t. x = z (14)\nwhere l(x) is the logistic function. If we use ADMM to solve (14), the x update is as follows [4]:\nxt+1 = argmin x\nl(x) + \u3008yt,x\u2212 zt\u3009+ \u03c1\n2 \u2016x\u2212 zt\u201622 , (15)\n3If f can be decomposed into a differentiable function and a nonsmooth function, we can simply linearize the differentiable part.\n4In general, f is not necessarily differentiable. Let f be relatively differentiable, xt \u2208 ri(dom(f)) and f \u2032(xt) \u2208 \u2202f(xt). The generalized Bregman divegence is Bf (x,xt) = f(x)\u2212 f(xt)\u2212 \u3008f \u2032(xt),x \u2212 xt\u3009 [25].\nwhich is an \u21132 regularized logistic regression problem and requires a loop algorithm like L-BFGS to solve it. Instead, if we linearize l(x) at xt and set B\u03c6 to be a quadratic function, we have\nxt+1 = argmin x\n\u3008\u2207l(xt),x\u2212 xt\u3009+ \u3008yt,x\u2212 zt\u3009+ \u03c1\n2 \u2016x\u2212 zt\u201622 + \u03c1x 2 \u2016x\u2212 xt\u201622 , (16)\nthe x update has a simple closed-form solution.\nCase 2: Linearization of the quadratic penalty term Set B\u03c6(c \u2212 Ax,Bzt) = 12\u2016Ax + Bzt \u2212 c\u201622, which contains \u2016Ax\u201622. The linearization of the quadratic penalty term can be done by removing \u2016Ax\u201622 as follows:\n\u2016Ax+Bzt \u2212 c\u201622 \u2212 \u2016A(x\u2212 xt)\u201622 = 2\u3008Axt +Bzt \u2212 c,Ax\u3009+ \u2016Bzt \u2212 c\u201622 \u2212 \u2016Axt\u201622 .\nLet B\u03d5x(x,xt) = B\u03d5\u2032x(x,xt)\u2212 \u03c1 2\u03c1x \u2016A(x\u2212 xt)\u201622. Removing constant terms, (7) becomes\nxt+1 = argmin x\u2208X\nf(x) + \u3008yt + \u03c1(Axt +Bzt \u2212 c),Ax\u3009+ \u03c1xB\u03d5\u2032 x (x,xt) . (17)\nCompared to (10) where A = \u2212I,B = I and c = 0 in Scenario 1, (17) is more general. However, (17) requires the linearization of the quadratic penalty term and solving the z update inexactly.\nThis case mainly solves the problem caused by A, e.g., Ax makes x nonseparable. Several problems have been benefited from the linearization of quadratic term [8], e.g., f is \u21131 loss function [15] and projection onto the unit simplex or \u21131 ball [9].\nExample 2 Consider the following x update:\nxt+1 = argmin x\n\u3008b,x\u3009+ \u3008yt,Ax\u2212 zt\u3009+ \u03c1\n2 \u2016Ax\u2212 zt\u201622 , s.t. xi \u2265 0,\nn \u2211\ni=1\nxi = 1 , (18)\nwhere we assume f(x) = \u3008b,x\u3009 is a linear function. (18) amounts to the Euclidean projection onto the unit simplex. If A = I, the projection can be done by an efficient algorithm [9]. In general, we do not have an efficient algorithm to solve (18). However, if we linearize the quadratic term and add KL divergence such that\nxt+1=argmin x\n\u3008b+ATyt+\u03c1AT (Axt\u2212zt),x\u3009+\u03c1xKL(x,xt) , s.t. xi \u2265 0, n \u2211\ni=1\nxi = 1 , (19)\nthe x update has a closed-form solution.\nCase 3: Mirror Descent In this case, we linearize both the function and the quadratic term. Let B\u03d5x(x,xt) = B\u03d5\u2032x(x,xt)\u2212 1\u03c1xBf(x,xt)\u2212 \u03c1 2\u03c1x \u2016A(x\u2212 xt)\u201622. Combining the results in Case 1 and 2, (7) becomes\nxt+1 = argmin x\u2208X\n\u3008F (xt),x\u3009+ \u03c1xB\u03d5\u2032 x (x,xt) , (20)\nwhere F (xt) = \u2207f(xt) +AT{yt + \u03c1(Axt +Bzt \u2212 c)}, which is the gradient of the objective in (3). (20) is a MDA-type update.\nExample 3 Consider the x update(18) for a logistic loss function:\nxt+1 = argmin x\nl(x) + \u3008yt,Ax\u2212 zt\u3009+ \u03c1\n2 \u2016Ax\u2212 zt\u201622 , s.t. xi \u2265 0,\nn \u2211\ni=1\nxi = 1 (21)\nwhere l(x) is the logistic function. We do not have an efficient algorithm for (21) by using the strategy either in Case 1 or Case 2. If we linearize the objective in (21) and add KL divergence, the x update has a closed-form solution.\nIf (8) can also be written in a similar MDA-type update, BADMM behaves like alternating mirror descent. If both Bregman divergences are quadratic function, BADMM leads to alternating additive updates. If both Bregman divergences are KL divergence and X ,Z are unit simplex, BADMM leads to alternating multiplicative updates. If one is quadratic function and the other is KL-divergence, we have alternating additive-multiplicative updates.\nThe three special cases depend on the decomposition B\u03d5x = B\u03d5\u2032x \u2212 \u03b2xB\u03c8x , where \u03c8x is the term to be linearized. The nonnegativeness of B\u03d5x implies that B\u03d5\u2032x \u2265 \u03b2xB\u03c8x . We now show this condition can be satisfied by assuming that \u03d5\u2032x is strongly convex and \u03c8x has Lipschitz continuous gradient, which are generally used in MDA and COMID. Assume \u03c8x is \u03bd-strongly smooth w.r.t. a p-norm, i.e., \u03c8x(u) \u2264 \u03c8x(v) + \u3008\u2207\u03c8x(v),u \u2212 v\u3009 + \u03bd2\u2016u \u2212 v\u20162p. According to the definition of Bregman divergence, B\u03c8x(u,v) \u2264 \u03bd2\u2016u\u2212 v\u20162p. If \u03d5\u2032x is \u03b2x\u03bd-strongly convex w.r.t. the p-norm, we have B\u03d5\u2032\nx (u,v) \u2265 \u03b2x\u03bd 2 \u2016u\u2212 v\u20162p. Therefore, B\u03d5\u2032x \u2265 \u03b2xB\u03c8x holds."}, {"heading": "3 Convergence Analysis of BADMM", "text": "In this section, we first discuss the assumptions required in the convergence analysis of BADMM. Then we establish the global convergence for BADMM. Finally, we show O(1/T ) convergence rate for the objective and residual of equality constraint.\nWe need the following assumption in establishing the convergence of BADMM:\nAssumption 1 (a) f : Rn1 \u2192 R \u222a {+\u221e} and g : Rn2 \u2192 R \u222a {+\u221e} are closed, proper and convex5. (b) An optimal solution exists. (c) The Bregman divergence B\u03c6 is defined on an \u03b1-strongly convex function \u03c6 with respect to a p-norm \u2016 \u00b7 \u20162p, i.e., B\u03c6(u,v) \u2265 \u03b12\u2016u\u2212 v\u20162p, where alpha > 0.\nWe start wth the Lagrangian of (1), which is defined as follows:\nL(x,y, z) = f(x) + g(z) + \u3008y,Ax+Bz\u2212 c\u3009. (22) 5f is assumed to be relatively differentiable [25] when we define a generalied Bregman divegence Bf in Case 1 of\nScenario 2 in Section 2.\nAssume that {x\u2217, z\u2217,y\u2217} satisfies the KKT conditions of (22), i.e.,\n\u2212ATy\u2217 \u2208 \u2202f(x\u2217) , (23) \u2212BTy\u2217 \u2208 \u2202g(z\u2217) , (24)\nAx\u2217 +Bz\u2217 \u2212 c = 0 . (25)\n{x\u2217, z\u2217,y\u2217} is an optimal solution. The optimality conditions of (7) and (8) are\n\u2212AT{yt + \u03c1(\u2212\u2207\u03c6(c\u2212Axt+1) +\u2207\u03c6(Bzt)} \u2212 \u03c1x(\u2207\u03d5x(xt+1)\u2212\u2207\u03d5x(xt)) \u2208 \u2202f(xt+1) , (26) \u2212BT{yt + \u03c1(\u2207\u03c6(Bzt+1)\u2212\u2207\u03c6(c\u2212Axt+1)} \u2212 \u03c1z(\u2207\u03d5z(zt+1)\u2212\u2207\u03d5z(zt)) \u2208 \u2202g(zt+1) . (27)\nIf Axt+1+Bzt+1 = c, then yt+1 = yt. Therefore, (23) is satisfied if Axt+1+Bzt = c ,xt+1 = xt in (26). Similarly, (24) is satisfied if zt+1 = zt in (27). Overall, the KKT conditions (23)-(25) are satisfied if the following optimality conditions are satisfied:\nxt+1 \u2212 xt = 0 , zt+1 \u2212 zt = 0 , Axt+1 +Bzt \u2212 c = 0 , Axt+1 +Bzt+1 \u2212 c = 0 . (28)\nIn Scenario 1, \u03c1x = \u03c1z = 0 in (7) and (8), we have the following optimality conditions:\nAxt+1 +Bzt \u2212 c = 0 , Axt+1 +Bzt+1 \u2212 c = 0 , (29)\nwhich are a subset of conditions of (28). Define the residuals of optimality conditions (28) at (t+1) as:\nR(t+ 1)= \u03c1x \u03c1 B\u03d5x(xt+1,xt)+ \u03c1z \u03c1 B\u03d5z(zt+1,zt)+B\u03c6(c\u2212Axt+1,Bzt)+\u03b3\u2016Axt+1+Bzt+1\u2212c\u201622 , (30)\nwhere \u03b3 > 0. If R(t+1) = 0, the optimality conditions (28) and (29) are satisfied. It is sufficient to show the convergence of BADMM by showing R(t+1) converges to zero. We need the following lemma.\nLemma 1 Let the sequence {xt, zt,yt} be generated by Bregman ADMM (7)-(9). For any x\u2217, z\u2217 satisfying Ax\u2217 +Bz\u2217 = c, we have\nf(xt+1) + g(zt+1)\u2212 (f(x\u2217) + g(z\u2217)) \u2264 \u2212\u3008yt,Axt+1 +Bzt+1 \u2212 c\u3009 \u2212 \u03c1(B\u03c6(c\u2212Axt+1,Bzt) +B\u03c6(Bzt+1, c\u2212Axt+1)) + \u03c1(B\u03c6(Bz\n\u2217,Bzt)\u2212 B\u03c6(Bz\u2217,Bzt+1)) + \u03c1x(B\u03d5x(x\u2217,xt)\u2212 B\u03d5x(x\u2217,xt+1)\u2212B\u03d5x(xt+1,xt)) + \u03c1z(B\u03d5z(z \u2217, zt)\u2212 B\u03d5z(z\u2217, zt+1)\u2212 B\u03d5z(zt+1, zt)) . (31)\nProof: Using the convexity of f and its subgradient given in (26), we have\nf(xt+1)\u2212 f(x) \u2264 \u3008\u2212AT{yt + \u03c1(\u2212\u2207\u03c6(c\u2212Axt+1) +\u2207\u03c6(Bzt)} \u2212 \u03c1x(\u2207\u03d5x(xt+1)\u2212\u2207\u03d5x(xt)),xt+1 \u2212 x\u3009 = \u2212\u3008yt,A(xt+1 \u2212 x)\u3009+ \u03c1\u3008\u2207\u03c6(c\u2212Axt+1)\u2212\u2207\u03c6(Bzt),A(xt+1 \u2212 x)\u3009 \u2212 \u03c1x\u3008\u2207\u03d5x(xt+1)\u2212\u2207\u03d5x(xt),xt+1 \u2212 x\u3009 . (32)\nSetting x = x\u2217 and using Ax\u2217 +Bz\u2217 = c, we have\nf(xt+1)\u2212 f(x\u2217) \u2264 \u2212\u3008yt,Axt+1 +Bz\u2217 \u2212 c\u3009+ \u03c1\u3008\u2207\u03c6(c\u2212Axt+1)\u2212\u2207\u03c6(Bzt),Bz\u2217 \u2212 (c\u2212Axt+1)\u3009 \u2212 \u03c1x\u3008\u2207\u03d5x(xt+1)\u2212\u2207\u03d5x(xt),xt+1 \u2212 x\u3009 = \u2212\u3008yt,Axt+1 +Bz\u2217 \u2212 c\u3009+ \u03c1(B\u03c6(Bz\u2217,Bzt)\u2212 B\u03c6(Bz\u2217, c\u2212Axt+1)\u2212B\u03c6(c\u2212Axt+1,Bzt)) + \u03c1x(B\u03d5x(x \u2217,xt)\u2212 B\u03d5x(x\u2217,xt+1)\u2212B\u03d5x(xt+1,xt)) . (33)\nwhere the last equality uses the three point property of Bregman divergence, i.e.,\n\u3008\u2207\u03c6(u)\u2212\u2207\u03c6(v),w\u2212 u\u3009 = B\u03c6(w,v)\u2212B\u03c6(w,u)\u2212 B\u03c6(u,v) . (34)\nSimilarly, using the convexity of g and its subgradient given in (27), for any z,\ng(zt+1)\u2212 g(z) \u2264 \u3008\u2212BT{yt + \u03c1(\u2207\u03c6(Bzt+1)\u2212\u2207\u03c6(c\u2212Axt+1)} \u2212 \u03c1z(\u2207\u03d5z(zt+1)\u2212\u2207\u03d5z(zt)), zt+1 \u2212 z\u3009 = \u2212\u3008yt,B(zt+1 \u2212 z)\u3009+ \u03c1\u3008\u2207\u03c6(Bzt+1)\u2212\u2207\u03c6(c\u2212Axt+1),Bz\u2212Bzt+1)\u3009 \u2212 \u03c1z\u3008\u2207\u03d5z(zt+1)\u2212\u2207\u03d5z(zt), zt+1 \u2212 z\u3009 = \u2212\u3008yt,B(zt+1 \u2212 z)\u3009+ \u03c1 {B\u03c6(Bz, c\u2212Axt+1)\u2212 B\u03c6(Bz,Bzt+1)\u2212B\u03c6(Bzt+1, c\u2212Axt+1)} + \u03c1z(B\u03d5z(z, zt)\u2212 B\u03d5z(z, zt+1)\u2212 B\u03d5z(zt+1, zt)) . (35)\nwhere the last equality uses the three point property of Bregman divergence (34). Set z = z\u2217 in (35). Adding (33) and (35) completes the proof.\nUnder Assumption 1(c), the following lemma shows that (30) is bounded by a telescoping series of D(w\u2217,wt)\u2212D(w\u2217,wt+1), where D(w\u2217,wt) defines the distance from the current iterate wt = (xt, zt,yt) to a KKT point w\u2217 = (x\u2217, z\u2217,y\u2217) as follows:\nD(w\u2217,wt)= 1\n2\u03c4\u03c1 \u2016y\u2217\u2212yt\u201622+B\u03c6(Bz\u2217,Bzt)+ \u03c1x \u03c1 B\u03d5x(x \u2217,xt)+ \u03c1z \u03c1 B\u03d5z(z \u2217, zt) . (36)\nLemma 2 Let the sequence {xt, zt,yt} be generated by Bregman ADMM (7)-(9) and {x\u2217, z\u2217,y\u2217} satisfying (23)-(25). Let the Assumption 1 hold. R(t + 1) and D(w\u2217,wt) are defined in (30) and (36) respectively. Set \u03c4 \u2264 (\u03b1\u03c3 \u2212 2\u03b3)\u03c1, where \u03c3 = min{1, m 2p\u22121} and 0 < \u03b3 < \u03b1\u03c3 2 . Then\nR(t + 1) \u2264 D(w\u2217,wt)\u2212D(w\u2217,wt+1) . (37)\nProof: Assume {x\u2217,y\u2217} satisfies (23). Since f is convex, then\nf(x\u2217)\u2212 f(xt+1) \u2264 \u2212\u3008ATy\u2217,x\u2217 \u2212 xt+1\u3009 = \u2212\u3008y\u2217,Ax\u2217 \u2212Axt+1\u3009 . (38)\nSimilarly, for convex function g and {z\u2217,y\u2217} satisfying (24), we have\ng(z\u2217)\u2212 g(zt+1) \u2264 \u2212\u3008BTy\u2217, z\u2217 \u2212 zt+1\u3009 = \u2212\u3008y\u2217,Bz\u2217 \u2212Bzt+1\u3009 . (39)\nAdding them together and using the fact that Ax\u2217 +Bz\u2217 = c, we have\nf(x\u2217) + g(z\u2217)\u2212 (f(xt+1) + g(zt+1)) \u2264 \u3008y\u2217,Axt+1 +Bzt+1 \u2212 c\u3009 . (40)\nAdding (40) and (31) together yields\n0 \u2264 \u3008y\u2217 \u2212 yt,Axt+1 +Bzt+1 \u2212 c\u3009 \u2212 \u03c1(B\u03c6(c\u2212Axt+1,Bzt) +B\u03c6(Bzt+1, c\u2212Axt+1)) + \u03c1(B\u03c6(Bz\n\u2217,Bzt)\u2212 B\u03c6(Bz\u2217,Bzt+1)) + \u03c1x(B\u03d5x(x\u2217,xt)\u2212 B\u03d5x(x\u2217,xt+1)\u2212B\u03d5x(xt+1,xt)) + \u03c1z(B\u03d5z(z \u2217, zt)\u2212 B\u03d5z(z\u2217, zt+1)\u2212 B\u03d5z(zt+1, zt)) . (41)\nUsing Axt+1 +Bzt+1 \u2212 c = 1\u03c4 (yt+1 \u2212 yt), the first term can be rewritten as\n\u3008y\u2217 \u2212 yt,Axt+1 +Bzt+1 \u2212 c\u3009 = 1\n\u03c4 \u3008y\u2217 \u2212 yt,yt+1 \u2212 yt\u3009\n= 1\n2\u03c4\n( \u2016y\u2217 \u2212 yt\u201622 \u2212 \u2016y\u2217 \u2212 yt+1\u201622 + \u2016yt+1 \u2212 yt\u201622 )\n= 1\n2\u03c4\n( \u2016y\u2217 \u2212 yt\u201622 \u2212 \u2016y\u2217 \u2212 yt+1\u201622 )\n+ \u03c4\n2 \u2016Axt+1 +Bzt+1 \u2212 c\u201622 . (42)\nPlugging into (41) and rearranging the terms, we have\n1\n2\u03c4\n( \u2016y\u2217 \u2212 yt\u201622 \u2212 \u2016y\u2217 \u2212 yt+1\u201622 ) + \u03c1(B\u03c6(Bz \u2217,Bzt)\u2212 B\u03c6(Bz\u2217,Bzt+1))\n\u03c1x(B\u03d5x(x \u2217,xt)\u2212 B\u03d5x(x\u2217,xt+1)) + \u03c1z(B\u03d5z(z\u2217, zt)\u2212 B\u03d5z(z\u2217, zt+1))\n\u2265 \u03c1xB\u03d5x(xt+1,xt) + \u03c1zB\u03d5z(zt+1, zt) + \u03c1B\u03c6(c\u2212Axt+1,Bzt) + \u03c1B\u03c6(Bzt+1, c\u2212Axt+1)\u2212 \u03c4\n2 \u2016Axt+1 +Bzt+1 \u2212 c\u201622 . (43)\nDividing both sides by \u03c1 and letting R(t + 1) and D(w\u2217,wt) be defined in (30) and (36) respectively, we have\nD(w\u2217,wt)\u2212D(w\u2217,wt+1)\u2265R(t + 1)+B\u03c6(Bzt+1, c\u2212Axt+1)\u2212( \u03c4\n2\u03c1 + \u03b3)\u2016Axt+1 +Bzt+1 \u2212 c\u201622\n\u2265 R(t + 1) + \u03b1 2 \u2016Axt+1 +Bzt+1 \u2212 c\u20162p \u2212 ( \u03c4 2\u03c1 + \u03b3)\u2016Axt+1 +Bzt+1 \u2212 c\u201622 , (44)\nwhere the last inequality uses the Assumption 1(c). If 0 < p \u2264 2, \u2016u\u2016p \u2265 \u2016u\u20162. Set \u03b12 \u2265 \u03c42\u03c1 + \u03b3 in (44), i.e., \u03c4 \u2264 (\u03b1\u2212 2\u03b3)\u03c1. We can always find a \u03b3 < \u03b1 2 , thus (37) follows.\nIf p > 2, \u2016u\u20162 \u2264 m 1 2 \u2212 1 p \u2016u\u2016p for any u \u2208 Rm\u00d71, so \u2016u\u20162p \u2265 m 2 p \u22121\u2016u\u201622. In (44), set \u03b12m 2 p \u22121 \u2265\n\u03c4 2\u03c1 + \u03b3, i.e., \u03c4 \u2264 (\u03b1m 2p\u22121 \u2212 2\u03b3)\u03c1. As long as \u03b3 < \u03b1 2 m 2 p \u22121, we have (37).\nRemark 1 (a) If 0 < p \u2264 2, then \u03c3 = 1 and \u03c4 \u2264 (\u03b1\u22122\u03b3)\u03c1. The case that 0 < p \u2264 2 includes two widely used Bregman divergences, i.e., Euclidean distance and KL divergence. For KL divergence in the unit simplex, we have \u03b1 = 1, p = 1 in the Assumption 1 (c), i.e., KL(u,v) \u2265 1\n2 \u2016u\u2212v\u201621 [3].\n(b) Since we often set B\u03c6 to be a quadratic function (p = 2) in Scenario 2 in Section 2, the three special cases in Scenario 2 could choose step size \u03c4 = (\u03b1\u2212 2\u03b3)\u03c1.\n(c) If p > 2, the proof requires a sufficiently small step size \u03c4 , which may not be needed in practice. It would be interesting to see whether we can use a same \u03c4 = O(\u03c1) for any p > 0 using other proof techniques. In appendix A, under the assumption that yt is bounded, BADMM requires choosing a large step size \u03c4 = O( \u221a T ).\nThe following theorem establishes the global convergence for BADMM.\nTheorem 1 Let the sequence {xt, zt,yt} be generated by Bregman ADMM (7)-(9) and {x\u2217, z\u2217,y\u2217} satisfying (23)-(25). Let the Assumption 1 hold and \u03c4, \u03b3 satisfy the conditions in Lemma 2. Then R(t+ 1) converges to zero and {xt, zt,yt} converges to a KKT point {x\u2217, z\u2217,y\u2217} of (1). Proof: Since R(t + 1) \u2265 0, (37) implies D(w\u2217,wt+1) \u2264 D(w\u2217,wt). Therefore, D(w\u2217,wt) is monotonically nonincreasing and wt converges to a KKT point w\u2217. Summing (37) over t from 0 to \u221e yields\n\u221e \u2211\nt=0\nR(t+ 1) \u2264 D(w\u2217,w0) . (45)\nSince R(t + 1) \u2265 0, R(t+ 1) \u2192 0 as t \u2192 \u221e, which completes the proof.\nRemark 2 Under the assumption that yt is bounded, R(t + 1) converges to zero when choosing \u03c1x = \u03c1z = c1 \u221a T , \u03c4 = c2 \u221a T , \u03c1 = \u221a T for some positive constants c1, c2, which is shown in Theorem 3 on Appendix A.\nThe following theorem establishs a O(1/T ) convergence rate for the objective and residual of constraints in an ergodic sense.\nTheorem 2 Let the sequences {xt, zt,yt} be generated by Bregman ADMM (7),(8),(9). Let x\u0304T = 1 T \u2211T t=1 xt, z\u0304T = 1 T \u2211T t=1 zt. Set \u03c4 \u2264 (\u03b1\u03c3 \u2212 2\u03b3)\u03c1, where \u03c3 = min{1, m 2 p \u22121} and 0 < \u03b3 < \u03b1\u03c3 2 . For any (x\u2217, z\u2217,y\u2217) satisfying KKT conditions (23)-(25), we have\nf(x\u0304T ) + g(z\u0304T )\u2212 (f(x\u2217) + g(z\u2217)) \u2264 D1 T , (46) \u03b3\u2016Ax\u0304T +Bz\u0304T \u2212 c\u201622 \u2264 D(w\u2217,w0)\nT , (47)\nwhere D1 = 12\u03c4 \u2016y0\u201622 + \u03c1B\u03c6(Bz\u2217,Bz0) + \u03c1xB\u03d5x(x\u2217,x0) + \u03c1zB\u03d5z(z\u2217, z0). Proof: Using (9), we have\n\u2212\u3008yt,Axt+1 +Bzt+1 \u2212 c\u3009 = \u2212 1\n\u03c4 \u3008yt,yt+1 \u2212 yt\u3009\n= \u2212 1 2\u03c4 (\u2016yt+1\u201622 \u2212 \u2016yt\u201622 \u2212 \u2016yt+1 \u2212 yt\u201622) = 1\n2\u03c4 (\u2016yt\u201622 \u2212 \u2016yt+1\u201622) +\n\u03c4 2 \u2016Axt+1 +Bzt+1 \u2212 c\u201622 . (48)\nPlugging into (31) and ignoring some negative terms yield\nf(xt+1) + g(zt+1)\u2212 (f(x\u2217) + g(z\u2217))\n\u2264 1 2\u03c4 (\u2016yt\u201622 \u2212 \u2016yt+1\u201622) + \u03c1(B\u03c6(Bz\u2217,Bzt)\u2212 B\u03c6(Bz\u2217,Bzt+1)) + \u03c1x(B\u03d5x(x\u2217,xt)\u2212B\u03d5x(x\u2217,xt+1))\n+\u03c1z(B\u03d5z(z \u2217, zt)\u2212B\u03d5z(z\u2217, zt+1))\u2212\u03c1B\u03c6(Bzt+1, c\u2212Axt+1)+\n\u03c4 2 \u2016Axt+1+Bzt+1\u2212c\u201622 . (49)\nAssume B\u03c6(Bzt+1, c\u2212Axt+1) \u2265 \u03b12\u2016Axt+1 +Bzt+1 \u2212 c\u20162p. If 0 < p \u2264 2, using \u2016u\u2016p \u2264 \u2016u\u20162,\n\u2212\u03c1B\u03c6(Bzt+1, c\u2212Axt+1) + \u03c4\n2 \u2016Axt+1 +Bzt+1 \u2212 c\u201622 \u2264 \u2212 \u03b1\u03c1\u2212 \u03c4 2 \u2016Axt+1 +Bzt+1 \u2212 c\u201622 .\nSetting \u03c4 \u2264 (\u03b1\u2212 2\u03b3)\u03c1, the last two terms on the right hand side of (49) can be removed. If p > 2, \u2016u\u20162 \u2264 m 1 2 \u2212 1 p\u2016u\u2016p for any u \u2208 Rm\u00d71, so \u2016u\u20162p \u2265 m 2 p \u22121\u2016u\u201622. Then\n\u2212\u03c1B\u03c6(Bzt+1, c\u2212Axt+1) + \u03c4\n2 \u2016Axt+1 +Bzt+1 \u2212 c\u201622 \u2264 \u2212\n\u03b1\u03c1m 2 p \u22121 \u2212 \u03c4 2 \u2016Axt+1 +Bzt+1 \u2212 c\u201622 .\nSetting \u03c4 \u2264 (\u03b1m 2p\u22121 \u2212 2\u03b3)\u03c1, the last two terms on the right hand side of (49) can be removed. Summing over t from 0 to T \u2212 1, we have the following telescoping sum\nT\u22121 \u2211\nt=0\n[f(xt+1) + g(zt+1)\u2212 (f(x\u2217) + g(z\u2217))]\n\u2264 1 2\u03c4 \u2016y0\u201622 + \u03c1B\u03c6(Bz\u2217,Bz0) + \u03c1xB\u03d5x(x\u2217,x0) + \u03c1z(B\u03d5z(z\u2217, z0) . (50)\nDividing both sides by T and applying the Jensen\u2019s inequality gives (46). Dividing both sides of (45) by T and applying the Jensen\u2019s inequality yield (47).\nRemark 3 Under the assumption that yt is bounded, the objective converges at a rate of O(1/ \u221a T )\nwhen setting \u03c1x, \u03c1z, \u03c4, \u03c1 = O( \u221a T ), which is established in Theorem 4 in Appendix A."}, {"heading": "4 Application: Doubly Stochastic Matrices", "text": "In this section, as an illustrative example, we consider the problem of minimizing a loss function of a doubly stochastic matrix, which has been studied in spectral clustering [28] and learning permutations [17]. The class of n \u00d7 n doubly stochastic matrices is a convex polytope known as the Birkhoff polytope Bn. In particular, we consider the following problem:\nmin \u3008L,P\u3009 s.t. P \u2208 Bn = {P|P \u2265 0, eTP = e,Pe = e} , (51)\nwhere \u3008L,P\u3009 denotes Tr(LTP), L \u2208 Rn\u00d7n is a loss matrix, Bn denotes the Birkhoff polytope and e is a column vector of ones.\nTo solve this problem, we can use MDA which has the following update:\nPt+1 = argminP\u2208Bn \u3008L,P\u3009+ \u03c1B\u03c6(P,Pt) . (52)\nIn (52), simply choosing a Bregman divergence does not yield efficient projection onto the Birkhoff polytope. Since Bn contains the structure of the unit simplex (P \u2265 0, eTP = e), we use KL divergence in (52) which yields a multiplicative update. As a result, MDA leads to a double-loop algorithm which has the following two steps:\nP t+ 1 2\nij = P t ij exp(\u2212\n1 \u03c1 Lij) , P t+1 = \u03a0Bn(P t+ 1 2 ) . (53)\nwhere \u03a0Bn denotes the projection back onto Birkhoff polytope which can be solved using Sinkhorn algorithm [24, 17].\nThe projection in (53) requires a loop algorithm which normalizes columns and rows to 1 repeatedly and alternatingly until convergence. We now show this iterative step can be avoided using splitting variables. We split Bn into column stochastic matrices Bcn = {Pc|Pc \u2265 0, eTPc = e} and row stochastic matrices Brn = {Pr|Pr \u2265 0,Pre = e}. (51) can be rewritten in the following ADMM form:\nmin \u3008L,Pc\u3009 s.t. Pc \u2208 Bcn,Pr \u2208 Brn,Pc = Pr . (54)\nWe can solve (54) using ADMM which has the following updates:\nPt+1c = argminPc\u2208Bcn\u3008L,Pc\u3009+ \u3008Q t,Pc \u2212Ptr\u3009+\n\u03c1 2 \u2016Pc \u2212Ptr\u201622 , (55)\nPt+1r = argminPr\u2208Brn\u3008Q t,Pt+1c \u2212Pr\u3009+\n\u03c1 2 \u2016Pr \u2212Pt+1c \u201622 , (56)\nQt+1 = Qt + \u03c1(Pt+1c \u2212Pt+1r ) . (57)\nThe Euclidean projection onto the unit simplex in (55) and (56) can be done efficiently [9]. Replacing the quadratic term in (55) and (56) by KL divergence, we have the following BADMM algorithm:\nPt+1c = argminPc\u2208Bcn\u3008L,Pc\u3009+ \u3008Q t,Pc \u2212Ptr\u3009+ \u03c1KL(Pc,Ptr) , (58) Pt+1r = argminPr\u2208Brn\u3008Q t,Pt+1c \u2212Pr\u3009+ \u03c1KL(Pr,Pt+1c ) , (59) Qt+1 = Qt + \u03c1(Pt+1c \u2212Pt+1r ) . (60)\n(58) and (59) yield the following multiplicative updates :\nPt+1c,ij = Ptr,ij exp(\u2212 (L+Qt)ij \u03c1 ) \u2211n\ni=1P t r,ij exp(\u2212 (L+Qt)ij \u03c1\n) , Pt+1r,ij =\nPt+1c,ij exp(\u2212 Qt ij \u03c1 )\n\u2211n i=1P t+1 c,ij exp(\u2212\nQt ij \u03c1 ) , (61)\nBoth updates in (61) can be done in O(n2). Besides the sum operation in (61) which can be done in O(log(n)), the multiplicative updates amount to elementwise operation which can be done in parallel. BADMM yields a single-loop alternating multiplicative updates.\nThe following experiment compares BADMM with ADMM and MDA in minimizing a linear function over doubly stochastic matrix. L \u2208 Rn\u00d7n is randomly generated from uniform distribution. We set \u03c1 = 0.5 in MDA, ADMM and BADMM. All algorithms are run 10 times for n = 100, 500 and the average results are reported. The running time is plotted in Figure 1(a). Since BADMM is projection-free, ADMM has two efficient projections and MDA does one projection, BDAMM is the fastest and MDA is slightly faster than ADMM. The objective value is plotted in Figure 1(b). The three methods have almost the same value. In all methods, the sum of rows of doubly stochastic matrices is always equal to 1. We plot the sum of columns of doubly stochastic matrix for n = 100 in Figure 1(c). The matrices in BADMM and ADMM are row stochastic and thus doubly stochastic. The matrix in MDA is still close to a doubly stochastic matrix but is worse than BADMM and ADMM, which may be because the Sinkhorn algorithm stops early (the maximum iteration is 1000). BDAMM runs much faster than MDA and ADMM while maintaining the same performance as them."}, {"heading": "5 Conclusions", "text": "In this paper, we have generalized the alternating direction method of multipliers(ADMM) to Bregman ADMM, similar to how mirror descent generalizes gradient descent. BADMM defines a unified framework for ADMM, generalized ADMM and inexact ADMM. BADMM behaves like alternating proximal point method with Bregman divergence or alternating mirror descent, including alternating additive updates and alternating multiplicative updates as special cases. We illustrate the potential advantage of BADMM on optimization over doubly stochastic matrices. While classical approaches require doing a projection onto the constraint set, BADMM gives a single-loop projection-free algorithm."}, {"heading": "A Convergence of BADMM with Large Step Size", "text": "Under the assumption that yt is bounded, the following theorem requires a large step size to establish the convergence of BADMM.\nTheorem 3 Let the sequences {xt, zt,yt} be generated by Bregman ADMM (7)-(9) and {x\u2217, z\u2217,y\u2217} satisfying (23)-(25). Let the Assumption 1 hold and \u2016yt\u20162 \u2264 Dy. Setting \u03c1x = \u03c1z = c1 \u221a T , \u03c4 =\nc2 \u221a T and \u03c1 = \u221a T for some positive constant c1, c2, then R(t+ 1) converges to zero.\nProof: Assuming \u2016yt\u20162 \u2264 Dy and using (9), we have\n\u2016Axt+1 +Bzt+1 \u2212 c\u201622 = 1\n\u03c4 2 \u2016yt+1 \u2212 yt\u201622 \u2264\n2\n\u03c4 2 (\u2016yt+1\u201622 + \u2016yt\u201622) \u2264 4D2y \u03c4 2 . (62)\nPlugging into (44) and rearranging the terms yields\nR(t+ 1) \u2264 D(w\u2217,wt)\u2212D(w\u2217,wt+1) + ( \u03c4\n2\u03c1 + \u03b3) 4D2y \u03c4 2 . (63)\nSetting \u03c1x = \u03c1z = c1 \u221a T , \u03c4 = c2 \u221a T and \u03c1 = \u221a T for some positive constant c1, c2, we have\nR(t+ 1) = c1B\u03d5x(xt+1,xt) + c1B\u03d5z(zt+1, zt) +B\u03c6(c\u2212Axt+1,Bzt) + \u03b3\u2016Axt+1 +Bzt+1 \u2212 c\u201622 , (64)\nSumming (63) over t from 0 to T \u2212 1, we have the following telescoping sum T\u22121 \u2211\nt=0\nR(t+ 1) \u2264 D(w\u2217,w0) + T\u22121 \u2211\nt=0\n( \u03c4\n2\u03c1 + \u03b3) 4D2y \u03c4 2 = D(w\u2217,w0) + 4(c2/2 + \u03b3)D 2 y c22 . (65)\nTherefore, R(t+ 1) \u2192 0 as t \u2192 \u221e. The following theorem establishs the convergence rate for the objective and residual of constraints in an ergodic sense.\nTheorem 4 Let the sequences {xt, zt,yt} be generated by Bregman ADMM (7)-(9). Let x\u0304T = 1 T \u2211T t=1 xt, z\u0304T = 1 T \u2211T\nt=1 zt. Let the Assumption 1 hold and \u2016yt\u20162 \u2264 Dy. Set \u03c1x = \u03c1z = c1 \u221a T , \u03c4 = c2 \u221a T , \u03c1 = \u221a T for some positive constants c1, c2. For any (x\u2217, z\u2217,y\u2217) satisfying KKT conditions (23)-(25), we have\nf(x\u0304T ) + g(z\u0304T )\u2212 (f(x\u2217) + g(z\u2217)) \u2264 2D2y\nc2 \u221a T\n+ \u2016y0\u201622\n2c2T \u221a T + D2\u221a T , (66)\n\u03b3\u2016Ax\u0304T +Bz\u0304T \u2212 c\u201622 \u2264 D(w\u2217,w0)\nT +\n4(c2/2 + \u03b3)D 2 y\nc22T , (67)\nwhere D2 = B\u03c6(Bz\u2217,Bz0) + c1(B\u03d5x(x \u2217,x0) +B\u03d5z(z \u2217, z0)).\nProof: Assuming \u2016yt\u20162 \u2264 D2y and using (9), we have\n\u2212\u3008yt,Axt+1 +Bzt+1 \u2212 c\u3009 = \u2212 1\n\u03c4 \u3008yt,yt+1 \u2212 yt\u3009 \u2264\n1 \u03c4 (\u2016yt\u201622 + \u2016yt\u20162 \u2217 \u2016yt+1\u20162) \u2264 2D2y \u03c4 . (68)\nPlugging into (31) and ignoring some negative terms yield\nf(xt+1) + g(zt+1)\u2212 (f(x\u2217) + g(z\u2217))\n\u2264 2D2y \u03c4 + \u03c1(B\u03c6(Bz \u2217,Bzt)\u2212 B\u03c6(Bz\u2217,Bzt+1)) + \u03c1x(B\u03d5x(x\u2217,xt)\u2212 B\u03d5x(x\u2217,xt+1)) + \u03c1z(B\u03d5z(z \u2217, zt)\u2212B\u03d5z(z\u2217, zt+1)) . (69)\nSumming over t from 0 to T \u2212 1, we have the following telescoping sum T\u22121 \u2211\nt=0\n[f(xt+1) + g(zt+1)\u2212 (f(x\u2217) + g(z\u2217))]\n\u2264 T\u22121 \u2211\nt=0\n2D2y \u03c4 + 1 2\u03c4 \u2016y0\u201622 + \u03c1B\u03c6(Bz\u2217,Bz0) + \u03c1xB\u03d5x(x\u2217,x0) + \u03c1zB\u03d5z(z\u2217, z0) .\nSetting \u03c1x = \u03c1z = c1 \u221a T , \u03c4 = c2 \u221a T , \u03c1 = \u221a T , dividing both sides by T and applying the Jensen\u2019s inequality yield (66). Dividing both sides of (65) by T and applying the Jesen\u2019s inequality yield (67)."}], "references": [], "referenceMentions": [], "year": 2017, "abstractText": "<lb>The mirror descent algorithm (MDA) generalizes gradient descent by using a Bregman di-<lb>vergence to replace squared Euclidean distance as a proximal function. In this paper, we simi-<lb>larly generalize the alternating direction method of multipliers (ADMM) to Bregman ADMM<lb>(BADMM), which uses Bregman divergences as proximal functions in updates. BADMM<lb>allows the use of different Bregman divergences for different variable updates and involves<lb>alternating MDA-style updates, including alternating additive and alternating multiplicative<lb>updates as special cases. BADMM provides a unified framework for ADMM and its variants,<lb>including generalized ADMM and inexact ADMM. We establish the global convergence for<lb>BADMM. We present promising preliminary empirical results for BADMM applied to opti-<lb>mization over doubly stochastic matrices.", "creator": "dvips(k) 5.991 Copyright 2011 Radical Eye Software"}}}