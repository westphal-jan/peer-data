{"id": "1306.4653", "review": {"conference": "arxiv", "VERSION": "v1", "DATE_OF_SUBMISSION": "19-Jun-2013", "title": "Multiarmed Bandits With Limited Expert Advice", "abstract": "we solve the colt 2013 reliability problem where apple corp. l. on worst regret in the setting of advice - biased multiarmed bandits with fewer advice. we introduce an algorithm for incorrect setting gives rs < 1 update rules out of whichever you always allowed to query and compute only \u2018'' advices with each round, which has least regret bound below f \\ factor { \\ quad { \\ phi \\ { k, o \\ } n \\ log ( n ) } { m } t } \u2026 t checks.", "histories": [["v1", "Wed, 19 Jun 2013 19:25:51 GMT  (5kb)", "http://arxiv.org/abs/1306.4653v1", null], ["v2", "Thu, 27 Jun 2013 19:48:35 GMT  (8kb)", "http://arxiv.org/abs/1306.4653v2", "Updated with lower bound nearly matching the upper bound"], ["v3", "Fri, 28 Jun 2013 18:35:06 GMT  (8kb)", "http://arxiv.org/abs/1306.4653v3", "Updated with lower bound nearly matching the upper bound, and fixed some typos"], ["v4", "Mon, 8 Jul 2013 19:05:49 GMT  (9kb)", "http://arxiv.org/abs/1306.4653v4", "Updated with tighter upper bound based on PolyINF algorithm, lower bound nearly matching the upper bound, and fixed some typos"]], "reviews": [], "SUBJECTS": "cs.LG", "authors": ["satyen kale"], "accepted": false, "id": "1306.4653"}, "pdf": {"name": "1306.4653.pdf", "metadata": {"source": "CRF", "title": "Multiarmed Bandits With Limited Expert Advice", "authors": ["Satyen Kale"], "emails": ["sckale@us.ibm.com"], "sections": [{"heading": null, "text": "ar X\niv :1\n30 6.\n46 53\nv1 [\ncs .L\nG ]\n1 9\nJu n\n20 13\nin each round, which has a regret bound of 4 \u221a\nmin{K,M}N log(N) M T after T rounds."}, {"heading": "1 Introduction", "text": "Consider the following advice-efficient setting of the multiarmed bandits with expert advice problem, introduced by Seldin et al. [2]. In each round t = 1, 2, . . . , T , we are required to pull one arm At \u2208 {1, 2, . . . ,K} =: K. Simultaneously, an adversary sets losses \u2113t(a) \u2208 [0, 1] for each arm a \u2208 K. Assisting us in this task are N experts in the set N = {1, 2, . . . , N}. Each expert h can provide advice on which arm to pull in the form of a probability distribution \u03beht on the set of arms. This advice gives the expert h an expected loss of \u03beht \u00b7\u2113t in round t. The catch is that we can only observe the advice of at most M experts of our choosing in each round. The goal is to choose subsets of M experts in each round to query the advice of, and using their advice play some arm At \u2208 K (probabilistically, if desired) to minimize the expected regret with respect to the loss of the best expert, where the regret is defined as:\nRegretT := T \u2211\nt=1\n\u2113t(At)\u2212min h\u2208N\nT \u2211\nt=1\n\u03beht \u00b7 \u2113t.\nIn the following sections we give an algorithm whose expected regret is bounded by\n4\n\u221a\nmin{K,M}N log(N) M T\nafter T rounds. This matches the regret of the best known algorithms (up to the O( \u221a logN) factor)\nfor the special cases M = 1 and M = N , and interpolates between them for intermediate values of M . This solves the COLT 2013 open problem proposed by Seldin et al. [2], and in fact gives a\nbetter regret bound than the bound conjectured in [2], which was O\n(\n\u221a\nKN log(N) M T\n)\n."}, {"heading": "2 Preliminaries", "text": "For any event E, let I{E} be the indicator random variable set to 1 if E happens. In any round t of the algorithm, let Prt[\u00b7] and Et[\u00b7] denote probability and expectation respectively conditioned on all the randomness defined up to round t\u2212 1.\nWithout loss of generality, we may assume that each expert suggests exactly one arm to play in any round; i.e. \u03beht (a) = 1 for exactly one arm a \u2208 K and 0 for all other arms. Call such advice vectors \u201cstandard basis vectors\u201d. To see this, for every expert h we can randomly round a general advice vector \u03beht to a standard basis vector by sampling some arm ah \u223c \u03beht and constructing a new advice vector \u03be\u0302ht by setting \u03be\u0302 h t (ah) = 1 and \u03be\u0302 h t (a) = 0 for all a 6= ah. Note that in E[\u03be\u0302ht ] = \u03beht ; thus for any expert h following the randomly rounded advices \u03be\u0302ht for t = 1, 2, . . . , T has the same expected cost as following the advices \u03beht . Since this randomized rounding trick can be applied to the advices (algorithmically for the observed advices, and conceptually for the unobserved advices), in the rest of the paper we assume that all advice vectors are standard basis vectors; this helps us in getting a tighter bound on the regret.\nFor any time period t and any set U \u2286 N , define the \u201cactive set of arms\u201d to be the set of all arms recommended by experts in U , i.e.\nKUt = {a \u2208 K : \u2203h \u2208 U s.t. \u03beht (a) = 1}.\nNote that since we are allowed to query at most M experts in any round, if U is the queried set of experts in round t, then |KUt | \u2264 min{K,M}; this leads to min{K,M} factor in the regret bound. Define K \u2032 := min{K,M}, the effective number of arms."}, {"heading": "3 Algorithm", "text": "Partition the N experts into R = N/M groups of M experts each arbitrarily. Call the groups B1, B2, . . . , BR, and define R := {1, 2, . . . , R}. Run the Multiplicative Weights (MW) algorithm on all the experts, where the loss of expert h at time t is given as\nY ht := \u03be h t \u00b7 \u2113\u0302ht ,\nwhere \u03beht is the probability distribution over the K arms specified by expert h at time t, \u2113\u0302 h t is an estimator for the losses of the arms (we will specify this later; we will ensure that \u2113\u0302ht = 0 for all but M experts so that only M experts need to be queried for their advice). If the distribution over experts generated by the MW algorithm at time t is qt, then the distribution in round t+1 is specified by the following update rule:\nqt+1(h) := qt(h) exp(\u2212\u03b7Y ht )/Zt,\nwhere Zt is the normalization constant required to make qt+1 a distribution, and \u03b7 is a learning rate parameter to specified later.\nDefine the probability distribution rt over group indices R as rt(i) = \u2211\nh\u2208Bi qt(h). Each group\nBi defines a probability distribtion over arms:\npit :=\n\u2211\nh\u2208Bi qt(h)\u03be h t\n\u2211\nh\u2208Bi qt(h)\n=\n\u2211\nh\u2208Bi qt(h)\u03be h t\nrt(i) .\nFor some parameter \u03b3 \u2264 1/2 to be defined later, do the following in round t. With probability \u03b3, sample It uniformly from R and At uniformly from KBIt , and with probability (1 \u2212 \u03b3), sample It from rt, and At from p It t . Play At and observe its loss \u2113t(At). For every group Bi, define the loss estimator given by\n\u2113\u0302it(a) :=\n{\n\u2113it(a) I{It=i,At=a} Prt[i,a] if a \u2208 KBit 0 otherwise, (1)\nwhere for a \u2208 KBit , Pr t [i, a] = (1\u2212 \u03b3)rt(i)pit(a) +\n\u03b3\nR|KBit | is the probability of the event {It = i, At = a}, conditioned on all the randomness up to round t\u2212 1.\nFor all experts h \u2208 Bi, define the loss estimator:\n\u2113\u0302ht := \u2113\u0302 i t.\nNote that except for h \u2208 BIt , all \u2113\u0302ht are zero, and for BIt , the probabilities Prt[It, a] for all arms a can be computed using the only the advices of the experts h \u2208 BIt . Thus Y ht for all experts h can be computed and the algorithm is well-defined."}, {"heading": "4 Analysis", "text": "Theorem 1 Set \u03b7 = \u221a\nM log(N) K \u2032NT and \u03b3 = min\n{\n\u221a\nK \u2032N log(N) MT , 12\n}\n. Then the expected regret of the\nalgorithm is bounded by 4\n\u221a\nK \u2032N log(N) M T .\nProof: For T \u2264 4K \u2032N log(N) M\n, the regret of the algorithm is trivially bounded by T \u2264 4 \u221a\nK \u2032N log(N) M T .\nSo assume T > 4K \u2032N log(N) M so that \u03b3 =\n\u221a\nK \u2032N log(N) MT . The MW algorithm guarantees (see [1]) that\nas long as \u03b7 is chosen so that |\u03b7Y ht | \u2264 1 for all t, h, we have for any expert h\u22c6\nT \u2211\nt=1\n\u2211\nh\nqt(h)Y h t \u2264\n\u2211\nt\nY h \u22c6 t + \u03b7 \u2211\nt\n\u2211\nh\nqt(h)(Y h t )\n2 + logN\n\u03b7 . (2)\nNow, we have for any expert h\u22c6\n\u2211\nt\nE[\u2113t(At)] \u2264 \u2211\nt\nE[ \u2211\nh\nqt(h)Y h t ] + \u03b3T (By Lemma 2)\n\u2264 \u2211\nt\nE[Y h \u22c6 t ] + \u03b7 \u2211\nt\nE[ \u2211\nh\nqt(h)(Y h t )\n2] + logN\n\u03b7 + \u03b3T (By (2))\n\u2264 \u2211\nt\n\u03beh \u22c6 t \u00b7 \u2113t + \u03b7 2K \u2032N\nM T +\nlogN\n\u03b7 + \u03b3T (By Lemmas 1 and 3)\n\u2264 \u2211\nt\n\u03beh \u22c6 t \u00b7 \u2113t + 4 \u221a K \u2032N log(N)\nM T,\nusing \u03b7 =\n\u221a\nM log(N) K \u2032NT =\n\u221a\nlog(N) RK \u2032T and \u03b3 =\n\u221a\nK \u2032N log(N) MT =\n\u221a\nRK \u2032 log(N) T .\nAll that remains is to verify that |\u03b7Y ht | \u2264 1. Let h \u2208 Bi. Note that |\u2113\u0302ht (a)| \u2264 RK \u2032 \u03b3 , since if\na /\u2208 KBit , then \u2113\u0302ht (a) = 0, and if a \u2208 KBit , then Prt[i, a] \u2265 \u03b3 R|K\nBi t\n| \u2265 \u03b3 RK \u2032 . Since Y ht = \u03be h t \u00b7 \u2113\u0302ht and \u03beht\nis a distribution over arms, this implies that |Y ht | \u2264 RK \u2032 \u03b3 . Thus\n|\u03b7Y ht | \u2264 \u221a log(N) RK \u2032T \u00b7 \u221a RK \u2032T log(N) = 1.\n\u2737\nLemma 1 For all rounds t and all experts h, we have\nEt[Y h t ] = \u03be h t \u00b7 \u2113t and E[Y ht ] = \u03beht \u00b7 \u2113t.\nProof: Note that Y ht = \u2211 a\u2208K \u03be h t (a)\u2113\u0302 h t (a). We show that for all rounds t, experts h, and arms a, Et[\u03be h t (a)\u2113\u0302 h t (a)] = \u03be h t (a)\u2113t(a), which implies the required bounds. Let h \u2208 Bi. If \u03beht (a) = 0, then the equality holds trivially. Otherwise, if \u03beht (a) = 1, then a \u2208 KBit , so by the definition of the loss estimator in (1), we have\nEt[\u03be h t (a)\u2113\u0302 h t (a)] = Et\n[\n\u03beht (a)\u2113 h t (a) I{It = i, At = a} Prt[i, a] ] = \u03beht (a)\u2113 h t (a) Prt[i, a] Prt[i, a] = \u03beht (a)\u2113 h t (a).\n\u2737\nLemma 2 For all rounds t we have\nE[\u2113t(At)] \u2264 E[ \u2211\nh\nqt(h)Y h t ] + \u03b3.\nProof:\nEt[\u2113t(At)] = \u2211\ni\u2208R\n\u2211\na\u2208K Bi t\n\u2113t(a) Pr t [i, a]\n= \u2211\ni\u2208R\n\u2211\na\u2208K Bi t\n\u2113t(a) \u00b7 ( (1\u2212 \u03b3)rt(i)pit(a) + \u03b3\nR|KBit |\n)\n\u2264 (1\u2212 \u03b3) [ \u2211\ni\u2208R\nrt(i)(p i t \u00b7 \u2113t)\n]\n+ \u03b3 (\u2235 \u2113t(a) \u2208 [0, 1])\n= (1\u2212 \u03b3)\n\n\n\u2211\ni\u2208R\n\u2211\nh\u2208Bi\nqht \u03be h t \u00b7 \u2113t\n\n+ \u03b3\n= (1\u2212 \u03b3)Et[ \u2211\nh\nqht Y h t ] + \u03b3 (By Lemma 1)\n\u2264 Et[ \u2211\nh\nqht Y h t ] + \u03b3,\nsince Y ht \u2265 0. Taking expectation over all the randomness up to time t\u2212 1, the proof is complete. \u2737\nLemma 3 For all rounds t we have\nE[ \u2211\nh\nqt(h)(Y h t ) 2] \u2264 2RK \u2032.\nProof: Note that in any round, the algorithm only plays arms in KBItt . Fix the values of the random variables It \u2208 R and At \u2208 KBItt . Then \u2211 h qt(h)(Y h t )\n2 is a deterministic quantity, for which we provide an upper bound below.\n\u2211\nh\nqt(h)(Y h t )\n2 = \u2211\nh\u2208BIt\nqt(h)(\u03be h t \u00b7 \u2113\u0302Itt )2\n= \u2211\nh\u2208BIt\nqt(h)\n(\n\u03beh(At) \u00b7 \u2113t(At)\nPrt[It, At]\n)2\n(\u2235 \u2113\u0302Itt (a) = 0 for all a 6= At)\n\u2264 \u2211\nh\u2208BIt\nqt(h)\u03be h(At)\n(\n1\nPrt[It, At]\n)2\n(\u2235 \u03beh(At) \u2208 [0, 1] and \u2113t(At) \u2208 [0, 1])\n= rt(It)p It t (At) \u00b7\n1\nPrt[It, At]2\n(\n\u2235 pItt (At) =\n\u2211\nh\u2208BIt qt(h)\u03be\nh(At)\nrt(It)\n)\n\u2264 2 Prt[It, At] , (3)\nsince Prt[It, At] \u2265 (1\u2212 \u03b3)rt(It)pItt (At) \u2265 12rt(It)p It t (At) because \u03b3 \u2264 1/2. Next, we have\nEt[ \u2211\nh\nqt(h)(Y h t ) 2] = Et[Et[ \u2211\nh\nqt(h)(Y h t ) 2 | It, At \u2208 KBItt ]]\n= \u2211\nIt\u2208R\n\u2211\nAt\u2208K BIt t\nPr t [It, At] \u00b7\n2\nPrt[It, At] (By (3))\n= \u2211\nIt\u2208R\n2|KBItt |\n\u2264 2RK \u2032. Taking expectation over all the randomness up to time t\u2212 1, the proof is complete. \u2737"}, {"heading": "Acknowledgments", "text": "The author thanks Elad Hazan, Dean Foster, Rob Schapire, and Yevgeny Seldin for discussions on this problem."}], "references": [{"title": "The Multiplicative Weights Update Method: a Meta-Algorithm and Applications", "author": ["Sanjeev Arora", "Elad Hazan", "Satyen Kale"], "venue": "Theory of Computing,", "citeRegEx": "1", "shortCiteRegEx": "1", "year": 2012}, {"title": "Open Problem: Advice-Efficient Adversarial Multiarmed Bandits with Expert Advice", "author": ["Yevgeny Seldin", "Koby Crammer", "Peter Bartlett"], "venue": "In COLT,", "citeRegEx": "2", "shortCiteRegEx": "2", "year": 2013}], "referenceMentions": [{"referenceID": 1, "context": "[2] on minimizing regret in the setting of advice-efficient multiarmed bandits with expert advice.", "startOffset": 0, "endOffset": 3}, {"referenceID": 1, "context": "[2].", "startOffset": 0, "endOffset": 3}, {"referenceID": 0, "context": "Simultaneously, an adversary sets losses lt(a) \u2208 [0, 1] for each arm a \u2208 K.", "startOffset": 49, "endOffset": 55}, {"referenceID": 1, "context": "[2], and in fact gives a better regret bound than the bound conjectured in [2], which was O ( \u221a KN log(N) M T )", "startOffset": 0, "endOffset": 3}, {"referenceID": 1, "context": "[2], and in fact gives a better regret bound than the bound conjectured in [2], which was O ( \u221a KN log(N) M T )", "startOffset": 75, "endOffset": 78}, {"referenceID": 0, "context": "The MW algorithm guarantees (see [1]) that as long as \u03b7 is chosen so that |\u03b7Y h t | \u2264 1 for all t, h, we have for any expert h T \u2211", "startOffset": 33, "endOffset": 36}, {"referenceID": 0, "context": "+ \u03b3 (\u2235 lt(a) \u2208 [0, 1]) = (1\u2212 \u03b3) \uf8ee", "startOffset": 15, "endOffset": 21}, {"referenceID": 0, "context": "h\u2208BIt qt(h)\u03be (At) ( 1 Prt[It, At] 2 (\u2235 \u03be(At) \u2208 [0, 1] and lt(At) \u2208 [0, 1]) = rt(It)p It t (At) \u00b7 1 Prt[It, At] (", "startOffset": 47, "endOffset": 53}, {"referenceID": 0, "context": "h\u2208BIt qt(h)\u03be (At) ( 1 Prt[It, At] 2 (\u2235 \u03be(At) \u2208 [0, 1] and lt(At) \u2208 [0, 1]) = rt(It)p It t (At) \u00b7 1 Prt[It, At] (", "startOffset": 67, "endOffset": 73}], "year": 2017, "abstractText": "We solve the COLT 2013 open problem of Seldin et al. [2] on minimizing regret in the setting of advice-efficient multiarmed bandits with expert advice. We give an algorithm for the setting of K arms and N experts out of which we are allowed to query and use only M experts\u2019 advices in each round, which has a regret bound of 4 \u221a min{K,M}N log(N) M T after T rounds.", "creator": "LaTeX with hyperref package"}}}