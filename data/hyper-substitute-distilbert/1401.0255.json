{"id": "1401.0255", "review": {"conference": "arxiv", "VERSION": "v1", "DATE_OF_SUBMISSION": "1-Jan-2014", "title": "Modeling Attractiveness and Multiple Clicks in Sponsored Search Results", "abstract": "this models are an important tool for leveraging user feedback, and easily marketed amidst commercial message engines mainly computing relevant text recommendations. however, purely click models consider lacking in two aspects. first, developers don't control content across search results when listing choices. second,, assume page operators interact with the search results effectively. based on our relationship against the click category, previous comprehensive search graph, competitors observe restrictions that human dependency assumption does not always hold, especially for describing search results. to exploit the least two limitations, we invented relational functional utility model. our improved insight is since analyzing relationships across search results helps in solving important words or key - phrases which can well be used to accurately compute effects of current yahoo result. additionally, customers argue what multiple click probability of detecting picture as well as its attractiveness changes when a user session and depends on the task's past click experience. our model accordingly incorporates the effect of externalities ( quality of other browser statistics displayed in response to a user visit ), user fatigue, as well as pre and high - error manipulation of stored sponsored search result. we propose an efficient one - edge inference formulation and empirically evaluate the performance of business model despite extensive integration highlighting centralized result logs of producing large structured search resource.", "histories": [["v1", "Wed, 1 Jan 2014 06:45:58 GMT  (47kb)", "http://arxiv.org/abs/1401.0255v1", null]], "reviews": [], "SUBJECTS": "cs.IR cs.LG", "authors": ["dinesh govindaraj", "tao wang", "s v n vishwanathan"], "accepted": false, "id": "1401.0255"}, "pdf": {"name": "1401.0255.pdf", "metadata": {"source": "CRF", "title": "Modeling Attractiveness and Multiple Clicks in Sponsored Search Results", "authors": ["Dinesh Govindaraj", "Tao Wang", "S V N Vishwanathan"], "emails": ["digovind@microsoft.com", "taowang@purdue.edu", "vishy@stat.purdue.edu"], "sections": [{"heading": null, "text": "ar X\niv :1\n40 1.\n02 55\nv1 [\ncs .I\nR ]\n1 J\nan 2\n01 4\nCategories and Subject Descriptors H.4 [Information Systems Applications]: Miscellaneous\nGeneral Terms Algorithms\nKeywords Click Models, User behavior, Query log, Click and Browsing data analysis, Sponsored Search, Optimization, Ranking\n\u2217Work done when visiting Microsoft Bing Ads, Bangalore."}, {"heading": "1. INTRODUCTION", "text": "When a user submits a query, search engines return organic search results as a list of ranked URLs. Sometimes URLs linked to landing pages of ads (sponsored search results) are also displayed along with the organic search results. Sponsored search URLs displayed above the organic search results are called mainline ads, while those displayed on the side are called sidebar ads. Search engines generate revenue when users click on ads. In this paper we are interested in modeling how users interact with and click on sponsored search results. In particular, we focus on mainline ads since a majority of user clicks and hence revenue can be attributed to these ads.\nMining click-through logs is an important component of the never ending quest of commercial search engines to surface the most relevant (sponsored) search results in response to an user query. To understand this, consider the following scenario: Suppose documents d and d\u2032 are displayed in response to a query q. If the number of clicks that d receives is disproportionately high compared to d\u2032, one can reasonably conclude that d is more relevant than d\u2032 for q. While this approach of learning from the \u201cwisdom of the crowd\u201d is cheaper than employing a human labeler, it is not without its fair share of difficulties. For instance, it is well known that user clicks display a position bias, that is, documents at higher ranked positions are more likely to be clicked than lower ranked documents. There is a rich body of research which tries to infer an unbiased estimate of the document relevance from click-through logs by explicitly modeling user behavior using click models.\nAlmost all existing click models are designed for organic search, and make the simplifying assumption that users interact with the search results sequentially [12, 13]. In other words, they assume that a user examines an URL at position i + 1 only after examining the URLs at positions 1, . . . , i. Furthermore, since an overwhelming majority of user sessions end after one click, many models focus exclusively on this scenario. However, based on the analysis of the click logs of a commercial search engine, we observed that user interaction with sponsored search results do not confirm to these assumptions. Approximately 10% of the user sessions with clicks contain more than one click. Furthermore, in approximately 30% of multi-click sessions at least one pair of clicks is in reverse order (e.g., a click at position 3 followed by a click at position 1). This situation is depicted graphically in Figure 1.\nWe conjecture that users scan all the sponsored search results before they begin clicking. This is because sponsored search results are shown in a small block at the beginning of the page and usually occupy only 4 to 8 lines. Perhaps, eye tracking studies [9] which are often used to support the linear scan assumption in organic search may not apply to sponsored search1. Therefore, meaningful click models for sponsored search need to model reverse clicks.\nUnlike organic search, where short snippets of the landing page of a search result is displayed, sponsored search results are designed to grab attention. Towards this end, they employ titles that are short, catchy, and some words (which match query terms) are displayed in bold font. An sponsored search result might look very attractive to an user, but after clicking on it she might realize that the landing page does not contain the information that she wants. In other words, not only the attractiveness but also the postclick relevance of a sponsored search result are important factors for user satisfaction in sponsored search.\nSomewhat surprisingly, most existing click models either do not distinguish between attractiveness and post-click relevance or use very simple methods of estimating attractiveness. However, consider the following: the presence of the words \u201cbonded and insured\u201d in the title can make a sponsored search result more attractive for the query \u201cplumber\u201d. If we can share such information across all sponsored search results displayed in response to the query \u201cplumber\u201d, we can accurately estimate attractiveness.\n1Validating our conjecture using carefully designed user studies is an interesting research direction in its own right, but is unfortunately beyond the scope of the current work\nIn this paper, we present a novel statistical click model which models reverse clicks, and incorporates a new method for estimating attractiveness. Like in previous work [15, 16, 5] we also assume a separable model, that is, the user propensity for clicking on a search result is a product of the probability of examining that position and the attractiveness of the document displayed at that position. However, our key insight is that the examination probability of a position as well as the attractiveness of a position changes over time and depends on the user\u2019s past click experience.\nOur contributions can be summarized as follows: We propose a new click model for user interaction with sponsored search results. Our model can handle multiple click sessions as well as user sessions where the order of clicks is reversed. Furthermore, we present a new method for estimating attractiveness which shares information across multiple sponsored search results displayed in response to a user query. Our model is flexible and can easily incorporate user fatigue, pre-click and post-click relevance of an ad, and externalities. We derive an efficient one-pass inference mechanism for estimating parameters. Finally, we show that our model comprehensively outperforms existing click models in large scale empirical evaluation using real-life data from a large commercial search engine."}, {"heading": "2. CLICK MODELS: A BRIEF REVIEW", "text": "In what follows we will use the terms documents, ads, urls, and sponsored search results interchangeably. Almost all click prediction models make the following separability assumptions: (1) A document is clicked if and only if it is examined (or viewed); (2) The probability that a document is clicked is independent of its position given that it was viewed; (3) The probability that a document is viewed is independent of the document given the position, and is independent of the other ads presented.\nExamination Hypothesis. Let Ei (resp. Ci) be a random variable which is equal to 1 if a document di at position i was examined (resp. clicked). Based on the above assumptions one can write:\nP (Ci = 1 | di) = P (Ci = 1 \u2229 Ei = 1 | di)\n= P (Ci = 1 | di, Ei = 1) \ufe38 \ufe37\ufe37 \ufe38\nrelevance\nP (Ei = 1) \ufe38 \ufe37\ufe37 \ufe38 position bias . (1)\nIn other words, the probability of a document being clicked can be factored into the product of the relevance of the document and the position bias. This is the so-called examination hypothesis [15] or separability assumption [1].\nCascade Model and Extensions. The cascade model [6] assumes that users scan the documents from top to bottom without skipping, that is, users examine the ads sequentially:\nP (Ei = 1|Ei\u22121 = 1) = 1 and P (Ei = 1|Ei\u22121 = 0) = 0. (2)\nThe cascade model [6] further assumes that users examine documents until they find an appropriate one, and then abandon the search after the first click:\nP (Ei = 1|Ei\u22121 = 1, Ci\u22121) = 1\u2212Ci\u22121. (3)\nThe basic cascade model can only deal with query sessions with a single click. The dependent click model (DCM) [11] extends this to multi-click sessions, by modifying (3) to\nP (Ei = 1|Ei\u22121 = 1, Ci\u22121) = (\u03bbi\u22121) Ci\u22121 . (4)\nHere \u03bbi is estimated from the empirical probability that a browsing session did not end after a click at position i.\nThe user browsing model (UBM) [7] extends the DCM by assuming that the examination probability depends on the last clicked position in the same query session. In other words\nP (Ei = 1 |C1, . . . , Ci) = \u03b2ri , (5)\nwhere ri denotes the position of the previous click, that is, ri := argmaxj I (Cj = 1). The Bayesian browsing model (BBM) [14] models relevance P (Ci = 1 | di, Ei = 1) as a random variable, and uses a Bayesian approach to estimate its value.\nDynamic Bayesian Network Model. The dynamic Bayesian network (DBN) [4] model differs from the above click models in two important ways. First, it distinguishes between attractiveness (also called perceived relevance or pre-click relevance in literature [16]) and post-click relevance. Second, it incorporates user fatigue. This leads to\nP (Ci\u22121 = 1|di\u22121, Ei\u22121 = 1) = \u03b8di\u22121 (6)\nP (Ei = 1|Ei\u22121 = 1, Ci\u22121) = \u03bbi\u22121 ( 1\u2212 \u03c1di\u22121 )Ci\u22121 . (7)\nHere, \u03c1di\u22121 (resp. \u03b8di\u22121) denotes the post-click satisfaction (resp. attractiveness) of document di\u22121 displayed at position i \u2212 1. For simplicity, one can set \u03bbi\u22121 = \u03bb for all i [4], or like in the DCM estimate \u03bbi\u22121 from empirical probabilities. Similarly, \u03b8di\u22121 is estimated (essentially) by counting the number of times a document was displayed and the number of times it was clicked. As we will see later in the paper, estimating the attractiveness by using a naive-Bayes like model leads to information sharing and hence better estimates for the attractiveness.\nRecently [3] extended the DBN by learning a per-query fatigue parameter and adding a variable to indicate if the user is likely to interact with sponsored search results or directly skip over them. A related model to DBN is the click chain model (CCM) [10].\nTemporal Hidden Click Model. Some recent work [18] has focused on incorporating revisiting behaviors into click models. However, the temporal hidden click model (THCM) proposed by the authors of [18] does not distinguish between attractiveness and post-click relevance. Furthermore, THCM allows for only two kinds of transitions namely\nP (Ei = 1|Ei\u22121 = 1) = \u03b1 (8)\nP (Ei\u22122 = 1|Ei\u22121 = 1) = \u03b3, (9)\nwith \u03b1+\u03b3 \u2264 1. Note that the transition probabilities do not depend on the location i \u2212 1. Furthermore, the probability of examining a position decays exponentially with distance from the current location.\nEffect of Externalities. Externalities [8] refer to the observation that the click on a document also depends on the quality of other documents presented on the same search result page. That is, the examination event will be affected not only by the documents shown above a certain position, but also by the documents below a certain position.\nMuch of the early work on click models considers the displayed documents as being independent of each other. Some recent work has tried to take externalities into account. For instance, [17] proposed a conditional random fields based model to click prediction to consider the externalities., [19] considers externalities but restrict their attention to sessions with just two ads. On the other hand, [16] showed that the relevance of a document at a position is not constant and it is affected by the clicks in other positions. In the context of news recommendation, [2] extended the basic DBN model to take into account a sub-modular information gain score, which affects the relevance of a document. Although a similar extension is also possible in our setting, for the sake of brevity we will omit discussing this for our model."}, {"heading": "3. MODEL DESCRIPTION", "text": ""}, {"heading": "3.1 Notation", "text": "Since we have to deal with reverse clicks, our notation is non-standard. Given a query q, we assume that the user is presented with a ranked list of n documents or sponsored search results D = {d1, . . . , dn}, and she might choose to click on 0 \u2264 n\u0302 \u2264 n documents. We consider this as a query session. Let ci \u2208 {0, 1, . . . , n} be a multinomial random variable; ci for 1 \u2264 i \u2264 n\u0302 denotes the position of the i-th click, and we let both c0 and cn\u0302+1 to be equal to 0. Let c1:i = (c1, c2, \u00b7 \u00b7 \u00b7 , ci), and c be a shorthand for c1:n\u0302+1.\nThe user browsing behavior in sponsored search can be ex-\nplained by Figure 2. After clicking on a document, the user has two choices: she can abandon the session or she can choose to return and click on any other document that has not been clicked so far. Users abandon a session for one of two reasons:\n\u2022 In the abandon with satisfaction case, the user found the information she was looking for in the sponsored search results. We capture this behavior via a Bernoulli random variable si, which takes on a value of 1 when the user is satisfied after clicking the document dci\u22121 at position ci\u22121. This, in turn, depends on the post-click relevance of the clicked document, which we denote as \u03c1dci\u22121 . In other words,\nP (si = 1 | ci\u22121,D) = \u03c1dci\u22121 . (10)\nBy default, we will set P (si = 1 | c0,D) = 0.\n\u2022 In the abandon without satisfaction case, the user may choose to skip ahead to the organic search results or close the browsing session. This behavior is captured via another Bernoulli random variable ti, which depends upon the perseverance of the user. We will let\nP (ti = 1 | si = 0, ci\u22121) = \u03b7i, (11)\nwhere \u03b7i denotes the probability that user will abandon the session after i clicks.\nAs one can expect, the perseverance of the user decreases as the number of clicks increase. This allows our model to capture the effect of externalities in the following natural way: The user fatigue parameter multiplied by the pre-click relevance gives the instantaneous pre-click relevance of a document. If an ad appears alongside other highly relevant ads which have already received clicks, then its instantaneous pre-click relevance reduces. In other words, the number of previous clicks observed is a direct measure of externalities (relevance of other documents). On the other hand, when the user decides to continue, then two factors influence the position of the next click:\n\u2022 She will choose a position based on attractiveness of the documents presented. We denote the attractiveness of the document at position ci by aci , and assume that the attractiveness of the documents at different positions is independent of each other. Furthermore, let a denote the n-dimensional vector of ai and\nP (aci = 1 | D) = \u03b8dci . (12)\n\u2022 The position of the previous click influences the position of the next click, the so-called position bias effect. This is captured using vi a n dimensional random vector, whose distribution is given by \u03b3ci\u22121\nP (vi,j = 1 | c1:i\u22121) = \u03b3ci\u22121,j . (13)\nHere \u03b3ci\u22121,j denotes the probability that the user transitions to position j after the previous click at position ci\u22121. We allow for non-zero \u03b3ci\u22121,j even if j < ci\u22121. This is different from existing click models which assume that users scan the list linearly, that is ci > ci\u22121."}, {"heading": "3.2 Graphical Model", "text": "Following standard practice, we will place a Beta prior on \u03b7i\n\u03b7i \u223c Beta(\u03b1 \u03b7 i , \u03b2 \u03b7 i ) (14)\nand a Dirichlet prior on \u03b3i\n\u03b3i \u223c Dirichlet(\u03b1 \u03b3 i ). (15)\nA Bayesian network specification of our model can be found in Figure 3. We denote all vectors in bold and matrices in\ncapital and bold. If we let s = (s1, . . . , sn), t = (t1, . . . , tn), V = (v1, . . . ,vn), \u03b1 \u03b7 = ((\u03b1\u03b71 , \u03b2 \u03b7 1 ), . . . , (\u03b1 \u03b7 n, \u03b2 \u03b7 n)), and A\n\u03b3 = (\u03b1\u03b31 , . . . ,\u03b1 \u03b3 n), then our click model can be described as follows:\nP (c, s, t,a,V |\u03b1\u03b7,A\u03b3 ,D) = (16) P (a | D)\u00d7 P (s | D)\u00d7 P (\u03b1\u03b7 | D)\u00d7 P (A\u03b3 | D)\u00d7\nn\u0302+1\u220f\ni=1\nP (ci | si, ti,a,vi)\u00d7 P (ti | ci\u22121,\u03b1 \u03b7)\u00d7\nP (vi | ci\u22121,A \u03b3)\u00d7 P (si | ci\u22121,D),\nwhere we define\nP (ci = 0 | si = 1) = 1 (17a)\nP (ci = 0 | ti = 1) = 1 (17b)\nP (ci = j | si, ti = 0, a,vi) = P (aj = 1) \u00b7 P (vi,j = 1) . (17c)\nIf the user has abandoned the session (si = 1 or ti = 1) then subsequent value of ci is set to 0. This is captured in (17a) and (17b) above. On the other hand, if the user decides to continue, then the probability of a click at the j-th position (with j 6= 0) depends on the attractiveness of the document as well as the position bias as can be seen from (17c)."}, {"heading": "3.3 Inference", "text": "Global parameters of our model include \u03b7i, and \u03b3i for i = 1, . . . , n. Furthermore, for each document d we need to infer its attractiveness \u03b8d and post-click relevance \u03c1d. The hyper-parameters \u03b1\u03b7 and A\u03b3 are estimated from historical data, and the other parameters such as \u03b7i, \u03b3i, and \u03c1d can be estimated efficiently by one pass through the click-logs. Details can be found in Appendix A. Next we discuss a novel method for computing \u03b8d."}, {"heading": "3.4 Estimating Attractiveness", "text": "A sponsored search result d displayed in response to a query q contains three components namely a title, description, and a display URL. We use the following naive Bayes like scheme to estimate attractiveness: For each word w, excluding commonly occurring stop words, which appears either in the title, description or the display URL2 we compute Nw the number of occurrences of w in Dq , and N\u0302w the number of occurrences of w in the subset of Dq that received a click. For infrequent queries (search volume less than 50 in a one week window) we let Dq be the entire training corpus, while for frequent queries (which occur with frequency greater than 50) we restrict Dq to the documents displayed in response to q. Let |d| denote the number of words in d and estimate\n\u03b8d = 1\n|d|\n\u2211\n\u2200w\u2208d\nN\u0302w Nw . (18)\nIn other words, for each word w \u2208 d we estimate the fraction of times it occurred in a clicked document for query q, sum the contribution due to each word independently and normalize by the length of d to obtain \u03b8d. The advantage of our method is that we share information across documents in the collection Dq . For instance, if a word w occurs frequently in documents which are clicked in response to a query, then it is very likely to be a relevant word for that query and our method gives it a high weight. Another advantage of our method is that we are able to address the cold start problem; we can estimate the attractiveness of a new sponsored search result based on the words that appear in the ad copy."}, {"heading": "4. EXPERIMENTAL EVALUATION", "text": "We collected three weeks of click logs from a large commercial search engine, and used the first week data for computing priors, the second week data for training, and third week data for testing. We filter the data and only retain sessions where at least one mainline ad was displayed. Our test setup is closer to a real-world deployment scenario, and somewhat different from the commonly used practice of randomly splitting available data into a training and test set. In particular, we retain all queries in the test set, even if they have not been observed in the training set. In this case, our estimation is purely based on priors, which are computed from the first week of data. We set \u03b1\u03b3i + \u03b2 \u03b3 i = 10 and \u03b1 \u03b7 i + \u03b2 \u03b7 i = 10. Table 1 summarizes our training data statistics. Note that for high decile (>1000) queries, there are significantly fewer three and four click sessions than for tail queries."}, {"heading": "4.1 Baselines", "text": "For our experiments we will compare the performance of our algorithm against the following four baselines:\n2For simplicity the display URL is treated as a single word."}, {"heading": "4.2 Evaluation Plan", "text": "In the first part of our experimental evaluation we are mainly interested in understanding how well our algorithm is able to infer post-click relevance. After all, this is the main motivation behind studying click models. Since other models do not distinguish between attractiveness and post-click relevance, we will only compare our algorithm with the dynamic Bayesian network (DBN) model of [4]. Details of this experiment can be found in Section 4.3.\nFor our second set of experiments (Sections 4.4 to 4.8) we focus on verifying that our model is able to predict the sequence of user clicks accurately. Click models are usually evaluated by computing average perplexity, or the closely related log-likelihood on the test set. Recall that the perplexity for a single user session is computed as\np = 2\u2212 1 n \u2211n i=1 Ci log qi+(1\u2212Ci) log(1\u2212qi), (19)\nwhere qi is the probability of observing a click at position i as predicted by the model and Ci indicates if an actual user click was observed at that position.\nHowever, we believe that perplexity alone does not tell the full story. For instance, the perplexity scores of our model (1.1932) and DBN (1.1984) are very similar, but they differ vastly in terms of how well they predict a sequence of user clicks. Similarly, a model which simply predicts qi as the empirical click-through rate, especially for high decile queries, achieves very low perplexity but is unable to explain a sequence of user clicks (also see the results for the AM below). Therefore, we adapt a stronger evaluation criterion which is designed to answer the following natural questions:\n\u2022 How well does the model predict the first click position?\n\u2022 How well does the model predict two, three, and all four click sequences? This is a very stringent evaluation criterion for multiple click models, and the model wins only if it predicts all clicks in the sequence correctly.\n\u2022 Even if the model makes mistakes in predicting the actual click sequence, we want to understand whether the actual click sequence ranks high in terms of loglikelihood.\n\u2022 Does the model predict the top two and three clicks correctly? In other words, the predicted click sequence need not be in the same order as the actual click sequence but the model needs to accurately predict whic h ads were clicked. For instance, if the actual click sequence was {1, 2} and the model predicts {2, 1} then this is considered to be a correct prediction as per this metric. Note that predicting the top four clicks in a four click session will always be 100% accurate.\n\u2022 How does the model fare in terms of predicting and ranking of sessions with reverse clicks?\nIntuitively, predicting well on higher decile queries is easier than lower decile queries. In order to understand the strengths and weaknesses of various model, for all the above cases we report their performance across different query deciles."}, {"heading": "4.3 Predicting Post-Click Relevance", "text": "We have access to approximately 10,000 (query, ad) pairs from the test dataset which have been labeled as relevant or irrelevant by trained human editors. Note that the human editors look into the landing pages to determine the labels. Following [4] we rank these (q, d) pairs using a score which is calculated as \u03b8d \u00d7 \u03c1d (attractiveness times post-click relevance). The documents are ranked based on the computed score, and we measure precision vs recall. The results for our model and DBN are plotted in Figure 4. Clearly our proposed model outperforms DBN consistently across recalls. In particular note that our model has high precision at low recall and is therefore able to rank relevant documents higher on the list as compared to DBN. Our model achieves an AUC of 0.8653 compared to DBN which is only able to achieve 0.7843."}, {"heading": "4.4 Predicting the First Clicked Ad", "text": "This is a multi-class classification problem with imbalanced class probabilities. Therefore PM which predicts that the first click happens at position one and has an accuracy of 72.27% on our test dataset. The AM has an accuracy of 73.5% while the DBN and ICM accuracies are 72.7% and 71.7% respectively. In our model we predict the ad which has the maximum click propensity as the first clicked ad. This results in an accuracy of 79.59%, a gain of over 8.2% as compared to the other models. To further understand the performance of models across different query deciles we plot the accuracy of different models in Figure 5. Note that we consistently outperform all other models across all query deciles, with the gains being more substantial for the lower decile queries which are harder to learn."}, {"heading": "4.5 Predicting the Entire Click Sequence", "text": "We compute click propensity for each click sequence with the same length as the actual click sequence. We say that our model predicted the click sequence only when we predict the entire click sequence correctly. Table 3 summarizes the results. Our model gains 8.6% (resp. 25%) on two-clicksequence prediction and 3.4% (resp. 37%) on three-clicksequence prediction over DBN (resp. PM). The model accuracies are comparable when predicting four click sequences, which are only a very small fraction of the data.\nAlthough AM is very competitive when predicting the first click, it is unable to predict longer click sequences accurately. This is because users do not decide to click on an ad solely based on its attractiveness, position bias and past click experience also plays an important role and needs to be taken into account.\nFigure 6 shows the accuracy of the models for two, three and four click prediction across different query deciles. Note that we consistently outperform other models across all query deciles in two click sequence prediction. In three click sequence prediction, DBN performs slightly better in top deciles than our model. Since number of queries and session in tail deciles are higher than top deciles, we achieve better overall performance than DBN."}, {"heading": "4.6 Ranking of the Actual Click Sequence", "text": "In the previous section we focused on predicting the entire click sequence correctly. Here we focus on how we rank the actual click sequences in terms of log-likelihood. For this, we compute the log likelihood for all permutations of click sequences. We then sort the click sequences based on the computed log likelihood and check the rank of the actual click sequence in this list. Table 4 summarizes our results. As can be seen, our model on the average ranks the actual\nclick sequence among the top 3 or 4 of all the possible permutations of click sequence.\nFigure 7 shows how the ranking of the actual click sequence varies across different query deciles. As can be seen from Table 1, longer click sequences are more frequent in the lower deciles, and hence our model has more data to learn in these deciles. Consequently the average rank of the actual click sequence as predicted by our model for two, three and four clicks is lower for lower decile queries."}, {"heading": "4.7 Predicting Top Clicks", "text": "Here we ignore the order and focus on understanding if our model is able to predict the positions of the clicks in two and three click sessions. Table 5 shows we out perform all other models in predicting top 2 and 3 click positions. Figure 8 shows accuracies across query deciles."}, {"heading": "4.8 Predicting Reverse Click Sequences", "text": "In our final experiment we focus only on the sessions where at least one pair of clicks was observed in reverse order (reverse click sessions). As before, we focus on the accuracy (Table 6), rank of the actual click sequence (Table 7), and accuracy of predicting the location of the top clicks (Table 8). Figure 9 shows the accuracy and rank of the actual click sequence for different deciles, and Figure 10 shows the accuracy of predicting positions of clicks in two and three click sessions.\nAs expected our model prediction accuracy for reverse click sessions is low since the reverse click sessions are only around 30% of the multi-click sessions. Even though our accuracies are lower than the attractiveness model, our model ranks actual reverse click sequences in top 5 of all the possible permutations of click sequence. Our model out performs all other models in most of the experiments and still achieves better ranking of actual click sequence even when clicks have been observed in reverse order."}, {"heading": "5. CONCLUSION AND FUTURE WORK", "text": "We presented a new multiple click model for modeling how users interact with and click on sponsored search results. Our model can handle reverse click sequence and comprehensively outperforms other models across a number of different metrics in extensive empirical evaluation.\nOnline sponsored search auctions are priced using a Generalized Second Price (GSP) auction mechanism. Inherent in this model is the assumption that the clicks on the ads happen independent of each other. We are currently working on developing pricing mechanisms which will take into account the clicking behavior predicted by our model. Our efforts are also directed towards improving the reverse click prediction accuracy of our model by using stronger priors. Finally, we are also working towards making our model robust to noise.\nAPPENDIX"}, {"heading": "A. PARAMETER ESTIMATION", "text": "Our training data consists of m sessions, and we assume that the document set Dk was displayed in the k-th session in response to query qk and we observed a click sequence ck of length n\u0302k. If we assume that the sessions are iid, then\nP ({ ck } | { Dk }) = m\u220f\nk=1\nP ( ck | Dk ) . (20)\nLet cki denote the location of the i-th click in the k-th session, I(\u00b7) denote the indicator variable of an event, D\u2032 denote the set of unique query-document pairs in our session data and D = |D\u2032|. Plugging in (16) into (20), using (10)\u2013(17) shows that P ({ ck } | { Dk })\n\u221d \u220f\nd\u2208D\u2032\n\u03b8 \u03c8d d \u00d7\nn\u220f\nj=1\nn\u220f\nk=1\n\u03b3 \u03b4jk jk p (\u03b3jk)\n\u00d7 n\u220f\nj=0\n(1\u2212 \u03b7j) \u03b2j \u03b7 \u03b2\u2032j j p (\u03b7j)\u00d7\n\u220f\nd\u2208D\u2032\n(1\u2212 \u03c1d) \u03bad \u03c1 \u03ba\u2032d d ,\nwhere we define\n\u03c8d =\nm\u2211\nk=1\nn\u0302k\u2211\ni=1\nI (\ndck i = d\n)\n(21)\n\u03b4i,j =\nm\u2211\nk=1\nn\u0302k\u2211\nt=1\nI ( c k t\u22121 = i ) and I ( c k t = j ) . (22)\n\u03c8d counts the number of times document d occurs in {Dk}, \u03b4i,j counts the number of times we observed a click at position j after having observed a click at position i. Note that when i < j \u03b4i,j counts the in-sequence users clicks, and for all i > j, \u03b4i,j captures out of sequence clicks.\n\u03b2j = m\u2211\nk=1\nI ( n\u0302 k > j ) and \u03b2\u2032j = m\u2211\nk=1\nI ( n\u0302 k = j )\n(23)\n(24)\n\u03b2j counts the number of sessions with greater than j clicks, while \u03b2\u2032j counts the number of sessions with exactly j clicks. It is easy to see that \u03b2j = \u2211 j\u2032>j \u03b2 \u2032 j\u2032 for j 6= 0.\n\u03bad = m\u2211\nk=1\nI (\ndck n\u0302k\n6= d ) and I (\ndck i = d\n)\nfor some i, (25)\nand \u03ba\u2032d =\nm\u2211\nk=1\nI (\ndck n\u0302k\n= d ) . (26)\n\u03ba\u2032d counts the number of sessions which ended after clicking on the document d, while \u03bad is the number of sessions which did not end after a click on document d.\nAs a consequence of using the Beta prior, we can estimate\n\u03b7j = \u03b2\u2032j + \u03b1 \u03b7 j\n\u03b2\u2032j + \u03b1 \u03b7 j + \u03b2j + \u03b2 \u03b7 j\nand \u03c1d = \u03ba\u2032d\n\u03ba\u2032d + \u03bad (27)\nFurthermore, since \u03b3i \u223c Dir(\u03b1 \u03b3 i ), we can estimate:\n\u03b3i,j = \u03b4i,j + \u03b1\n\u03b3 i,j\n\u2211\nj(\u03b4i,j + \u03b1 \u03b3 i,j)\n. (28)\nA.1 Time Complexity In order to perform the updates (27) and (28) we need to compute the quantities defined in (21) \u2013 (26). However, all these quantities involve simple counts, which can be computed by using one-pass through the click logs. Therefore, we can conclude that inference in our model is extremely salable."}, {"heading": "B. REFERENCES", "text": "[1] Gagan Aggarwal, Ashish Goel, and Rajeev Motwani.\nTruthful auctions for pricing search keywords. In Proceedings of the 7th ACM conference on Electronic commerce, pages 1\u20137, 2006.\n[2] Amr Ahmed, A. J. Smola, Choon Hui Teo, and S. V. N. Vishwanathan. Fair and balanced: Learning to present news stories. In Web Science and Data Mining (WSDM), 2012.\n[3] Azin Ashkan and Charles L.A. Clarke. Modeling browsing behavior for click analysis in sponsored search. In Proceedings of the 21st ACM Conference on Information and Knowledge Management, pages 2015\u20132019, 2012.\n[4] Olivier Chapelle and Ya Zhang. A dynamic bayesian network click model for web search ranking. In Proceedings of the 18th International Conference on World Wide Web, WWW \u201909, pages 1\u201310, 2009.\n[5] Ye Chen and Tak W. Yan. Position-normalized click prediction in search advertising. In Proceedings of the 18th ACM SIGKDD international conference on Knowledge discovery and data mining, KDD \u201912, pages 795\u2013803, 2012.\n[6] Nick Craswell, Onno Zoeter, Michael Taylor, and Bill Ramsey. An experimental comparison of click position-bias models. In Proceedings of the international conference on Web search and web data mining, WSDM \u201908, pages 87\u201394, 2008.\n[7] Georges E. Dupret and Benjamin Piwowarski. A user browsing model to predict search engine click data from past observations. In Proceedings of the 31st annual international ACM SIGIR conference on\nResearch and development in information retrieval, SIGIR \u201908, pages 331\u2013338, 2008.\n[8] Arpita Ghosh and Mohammad Mahdian. Externalities in online advertising. In Proceedings of the 17th international conference on World Wide Web, WWW \u201908, pages 161\u2013168, 2008.\n[9] Laura A. Granka, Thorsten Joachims, and Geri Gay. Eye-tracking analysis of user behavior in www search. In Proceedings of the 27th annual international ACM SIGIR conference on Research and development in information retrieval, SIGIR \u201904, pages 478\u2013479, 2004.\n[10] Fan Guo, Chao Liu, Anitha Kannan, Tom Minka, Michael Taylor, Yi-Min Wang, and Christos Faloutsos. Click chain model in web search. In Proceedings of the 18th international conference on World wide web, WWW \u201909, pages 11\u201320, 2009.\n[11] Fan Guo, Chao Liu, and Yi Min Wang. Efficient multiple-click models in web search. In Proceedings of the Second ACM International Conference on Web Search and Data Mining, WSDM \u201909, pages 124\u2013131, 2009.\n[12] T. Joachims. Optimizing search engines using clickthrough data. In Proceedings of the ACM Conference on Knowledge Discovery and Data Mining (KDD). ACM, 2002.\n[13] Thorsten Joachims, Laura Granka, Bing Pan, Helene Hembrooke, and Geri Gay. Accurately interpreting clickthrough data as implicit feedback. In Proceedings of the 28th annual international ACM SIGIR conference on Research and development in information retrieval, SIGIR \u201905, pages 154\u2013161, 2005.\n[14] Chao Liu, Fan Guo, and Christos Faloutsos. BBM: bayesian browsing model from petabyte-scale data. In Conference on Knowledge Discovery and Data Mining, KDD \u201909, pages 537\u2013546, 2009.\n[15] Matthew Richardson, Ewa Dominowska, and Robert Ragno. Predicting clicks: Estimating the click-through rate for new ads. In World Wide Web Conference, 2007.\n[16] Ramakrishnan Srikant, Sugato Basu, Ni Wang, and Daryl Pregibon. User browsing models: relevance versus examination. In Proceedings of the 16th ACM SIGKDD international conference on Knowledge discovery and data mining, KDD \u201910, pages 223\u2013232, 2010.\n[17] Chenyan Xiong, Taifeng Wang, Wenkui Ding, Yidong Shen, and Tie-Yan Liu. Relational click prediction for sponsored search. In Proceedings of the fifth ACM international conference on Web search and data mining, WSDM \u201912, pages 493\u2013502, 2012.\n[18] Danqing Xu, Yiqun Liu, Min Zhang, Shaoping Ma, and Liyun Ru. Incorporating revisiting behaviors into click models. In Proceedings of the fifth ACM international conference on Web search and data mining, WSDM \u201912, pages 303\u2013312, New York, NY, USA, 2012. ACM.\n[19] Wanhong Xu, Eren Manavoglu, and Erick Cantu-Paz. Temporal click model for sponsored search. In Proceedings of the 33rd international ACM SIGIR conference on Research and development in information retrieval, SIGIR \u201910, pages 106\u2013113, 2010."}], "references": [{"title": "Truthful auctions for pricing search keywords", "author": ["Gagan Aggarwal", "Ashish Goel", "Rajeev Motwani"], "venue": "In Proceedings of the 7th ACM conference on Electronic commerce,", "citeRegEx": "1", "shortCiteRegEx": "1", "year": 2006}, {"title": "Fair and balanced: Learning to present news stories", "author": ["Amr Ahmed", "A.J. Smola", "Choon Hui Teo", "S.V.N. Vishwanathan"], "venue": "In Web Science and Data Mining (WSDM),", "citeRegEx": "2", "shortCiteRegEx": "2", "year": 2012}, {"title": "Modeling browsing behavior for click analysis in sponsored search", "author": ["Azin Ashkan", "Charles L.A. Clarke"], "venue": "In Proceedings of the 21st ACM Conference on Information and Knowledge Management,", "citeRegEx": "3", "shortCiteRegEx": "3", "year": 2012}, {"title": "A dynamic bayesian network click model for web search ranking", "author": ["Olivier Chapelle", "Ya Zhang"], "venue": "In Proceedings of the 18th International Conference on World Wide Web, WWW", "citeRegEx": "4", "shortCiteRegEx": "4", "year": 2009}, {"title": "Position-normalized click prediction in search advertising", "author": ["Ye Chen", "Tak W. Yan"], "venue": "In Proceedings of the 18th ACM SIGKDD international conference on Knowledge discovery and data mining,", "citeRegEx": "5", "shortCiteRegEx": "5", "year": 2012}, {"title": "An experimental comparison of click position-bias models", "author": ["Nick Craswell", "Onno Zoeter", "Michael Taylor", "Bill Ramsey"], "venue": "In Proceedings of the international conference on Web search and web data mining,", "citeRegEx": "6", "shortCiteRegEx": "6", "year": 2008}, {"title": "A user browsing model to predict search engine click data from past observations", "author": ["Georges E. Dupret", "Benjamin Piwowarski"], "venue": "In Proceedings of the 31st annual international ACM SIGIR conference on  Research and development in information retrieval,", "citeRegEx": "7", "shortCiteRegEx": "7", "year": 2008}, {"title": "Externalities in online advertising", "author": ["Arpita Ghosh", "Mohammad Mahdian"], "venue": "In Proceedings of the 17th international conference on World Wide Web, WWW", "citeRegEx": "8", "shortCiteRegEx": "8", "year": 2008}, {"title": "Eye-tracking analysis of user behavior in www search", "author": ["Laura A. Granka", "Thorsten Joachims", "Geri Gay"], "venue": "In Proceedings of the 27th annual international ACM SIGIR conference on Research and development in information retrieval,", "citeRegEx": "9", "shortCiteRegEx": "9", "year": 2004}, {"title": "Click chain model in web search", "author": ["Fan Guo", "Chao Liu", "Anitha Kannan", "Tom Minka", "Michael Taylor", "Yi-Min Wang", "Christos Faloutsos"], "venue": "In Proceedings of the 18th international conference on World wide web,", "citeRegEx": "10", "shortCiteRegEx": "10", "year": 2009}, {"title": "Efficient multiple-click models in web search", "author": ["Fan Guo", "Chao Liu", "Yi Min Wang"], "venue": "In Proceedings of the Second ACM International Conference on Web Search and Data Mining,", "citeRegEx": "11", "shortCiteRegEx": "11", "year": 2009}, {"title": "Optimizing search engines using clickthrough data", "author": ["T. Joachims"], "venue": "In Proceedings of the ACM Conference on Knowledge Discovery and Data Mining (KDD). ACM,", "citeRegEx": "12", "shortCiteRegEx": "12", "year": 2002}, {"title": "Accurately interpreting clickthrough data as implicit feedback", "author": ["Thorsten Joachims", "Laura Granka", "Bing Pan", "Helene Hembrooke", "Geri Gay"], "venue": "In Proceedings of the 28th annual international ACM SIGIR conference on Research and development in information retrieval,", "citeRegEx": "13", "shortCiteRegEx": "13", "year": 2005}, {"title": "BBM: bayesian browsing model from petabyte-scale data", "author": ["Chao Liu", "Fan Guo", "Christos Faloutsos"], "venue": "In Conference on Knowledge Discovery and Data Mining, KDD", "citeRegEx": "14", "shortCiteRegEx": "14", "year": 2009}, {"title": "Predicting clicks: Estimating the click-through rate for new ads", "author": ["Matthew Richardson", "Ewa Dominowska", "Robert Ragno"], "venue": "In World Wide Web Conference,", "citeRegEx": "15", "shortCiteRegEx": "15", "year": 2007}, {"title": "User browsing models: relevance versus examination", "author": ["Ramakrishnan Srikant", "Sugato Basu", "Ni Wang", "Daryl Pregibon"], "venue": "In Proceedings of the 16th ACM SIGKDD international conference on Knowledge discovery and data mining,", "citeRegEx": "16", "shortCiteRegEx": "16", "year": 2010}, {"title": "Relational click prediction for sponsored search", "author": ["Chenyan Xiong", "Taifeng Wang", "Wenkui Ding", "Yidong Shen", "Tie-Yan Liu"], "venue": "In Proceedings of the fifth ACM international conference on Web search and data mining,", "citeRegEx": "17", "shortCiteRegEx": "17", "year": 2012}, {"title": "Incorporating revisiting behaviors into click models", "author": ["Danqing Xu", "Yiqun Liu", "Min Zhang", "Shaoping Ma", "Liyun Ru"], "venue": "In Proceedings of the fifth ACM international conference on Web search and data mining,", "citeRegEx": "18", "shortCiteRegEx": "18", "year": 2012}, {"title": "Temporal click model for sponsored search", "author": ["Wanhong Xu", "Eren Manavoglu", "Erick Cantu-Paz"], "venue": "In Proceedings of the 33rd international ACM SIGIR conference on Research and development in information retrieval,", "citeRegEx": "19", "shortCiteRegEx": "19", "year": 2010}], "referenceMentions": [{"referenceID": 11, "context": "Almost all existing click models are designed for organic search, and make the simplifying assumption that users interact with the search results sequentially [12, 13].", "startOffset": 159, "endOffset": 167}, {"referenceID": 12, "context": "Almost all existing click models are designed for organic search, and make the simplifying assumption that users interact with the search results sequentially [12, 13].", "startOffset": 159, "endOffset": 167}, {"referenceID": 8, "context": "Perhaps, eye tracking studies [9] which are often used to support the linear scan assumption in organic search may not apply to sponsored search.", "startOffset": 30, "endOffset": 33}, {"referenceID": 14, "context": "Like in previous work [15, 16, 5] we also assume a separable model, that is, the user propensity for clicking on a search result is a product of the probability of examining that position and the attractiveness of the document displayed at that position.", "startOffset": 22, "endOffset": 33}, {"referenceID": 15, "context": "Like in previous work [15, 16, 5] we also assume a separable model, that is, the user propensity for clicking on a search result is a product of the probability of examining that position and the attractiveness of the document displayed at that position.", "startOffset": 22, "endOffset": 33}, {"referenceID": 4, "context": "Like in previous work [15, 16, 5] we also assume a separable model, that is, the user propensity for clicking on a search result is a product of the probability of examining that position and the attractiveness of the document displayed at that position.", "startOffset": 22, "endOffset": 33}, {"referenceID": 14, "context": "This is the so-called examination hypothesis [15] or separability assumption [1].", "startOffset": 45, "endOffset": 49}, {"referenceID": 0, "context": "This is the so-called examination hypothesis [15] or separability assumption [1].", "startOffset": 77, "endOffset": 80}, {"referenceID": 5, "context": "The cascade model [6] assumes that users scan the documents from top to bottom without skipping, that is, users examine the ads sequentially:", "startOffset": 18, "endOffset": 21}, {"referenceID": 5, "context": "The cascade model [6] further assumes that users examine documents until they find an appropriate one, and then abandon the search after the first click:", "startOffset": 18, "endOffset": 21}, {"referenceID": 10, "context": "The dependent click model (DCM) [11] extends this to multi-click sessions, by modifying (3) to", "startOffset": 32, "endOffset": 36}, {"referenceID": 6, "context": "The user browsing model (UBM) [7] extends the DCM by assuming that the examination probability depends on the last clicked position in the same query session.", "startOffset": 30, "endOffset": 33}, {"referenceID": 13, "context": "The Bayesian browsing model (BBM) [14] models relevance P (Ci = 1 | di, Ei = 1) as a random variable, and uses a Bayesian approach to estimate its value.", "startOffset": 34, "endOffset": 38}, {"referenceID": 3, "context": "The dynamic Bayesian network (DBN) [4] model differs from the above click models in two important ways.", "startOffset": 35, "endOffset": 38}, {"referenceID": 15, "context": "First, it distinguishes between attractiveness (also called perceived relevance or pre-click relevance in literature [16]) and post-click relevance.", "startOffset": 117, "endOffset": 121}, {"referenceID": 3, "context": "For simplicity, one can set \u03bbi\u22121 = \u03bb for all i [4], or like in the DCM estimate \u03bbi\u22121 from empirical probabilities.", "startOffset": 47, "endOffset": 50}, {"referenceID": 2, "context": "Recently [3] extended the DBN by learning a per-query fatigue parameter and adding a variable to indicate if the user is likely to interact with sponsored search results or directly skip over them.", "startOffset": 9, "endOffset": 12}, {"referenceID": 9, "context": "A related model to DBN is the click chain model (CCM) [10].", "startOffset": 54, "endOffset": 58}, {"referenceID": 17, "context": "Some recent work [18] has focused on incorporating revisiting behaviors into click models.", "startOffset": 17, "endOffset": 21}, {"referenceID": 17, "context": "However, the temporal hidden click model (THCM) proposed by the authors of [18] does not distinguish between attractiveness and post-click relevance.", "startOffset": 75, "endOffset": 79}, {"referenceID": 7, "context": "Externalities [8] refer to the observation that the click on a document also depends on the quality of other documents presented on the same search result page.", "startOffset": 14, "endOffset": 17}, {"referenceID": 16, "context": "For instance, [17] proposed a conditional random fields based model to click prediction to consider the externalities.", "startOffset": 14, "endOffset": 18}, {"referenceID": 18, "context": ", [19] considers externalities but restrict their attention to sessions with just two ads.", "startOffset": 2, "endOffset": 6}, {"referenceID": 15, "context": "On the other hand, [16] showed that the relevance of a document at a position is not constant and it is affected by the clicks in other positions.", "startOffset": 19, "endOffset": 23}, {"referenceID": 1, "context": "In the context of news recommendation, [2] extended the basic DBN model to take into account a sub-modular information gain score, which affects the relevance of a document.", "startOffset": 39, "endOffset": 42}, {"referenceID": 3, "context": "This was found via crossvalidation, based on the recommendation of [4].", "startOffset": 67, "endOffset": 70}, {"referenceID": 5, "context": "Independent Click Model (ICM): Since the cascade model [6] can only handle single click sessions, one can extended it by setting the user perseverance parameter \u03bb in (4) to one [11].", "startOffset": 55, "endOffset": 58}, {"referenceID": 10, "context": "Independent Click Model (ICM): Since the cascade model [6] can only handle single click sessions, one can extended it by setting the user perseverance parameter \u03bb in (4) to one [11].", "startOffset": 177, "endOffset": 181}, {"referenceID": 3, "context": "Since other models do not distinguish between attractiveness and post-click relevance, we will only compare our algorithm with the dynamic Bayesian network (DBN) model of [4].", "startOffset": 171, "endOffset": 174}, {"referenceID": 3, "context": "Following [4] we rank these (q, d) pairs using a score which is calculated as \u03b8d \u00d7 \u03c1d (attractiveness times post-click relevance).", "startOffset": 10, "endOffset": 13}], "year": 2014, "abstractText": "Click models are an important tool for leveraging user feedback, and are used by commercial search engines for surfacing relevant search results. However, existing click models are lacking in two aspects. First, they do not share information across search results when computing attractiveness. Second, they assume that users interact with the search results sequentially. Based on our analysis of the click logs of a commercial search engine, we observe that the sequential scan assumption does not always hold, especially for sponsored search results. To overcome the above two limitations, we propose a new click model. Our key insight is that sharing information across search results helps in identifying important words or key-phrases which can then be used to accurately compute attractiveness of a search result. Furthermore, we argue that the click probability of a position as well as its attractiveness changes during a user session and depends on the user\u2019s past click experience. Our model seamlessly incorporates the effect of externalities (quality of other search results displayed in response to a user query), user fatigue, as well as pre and post-click relevance of a sponsored search result. We propose an efficient one-pass inference scheme and empirically evaluate the performance of our model via extensive experiments using the click logs of a large commercial search engine.", "creator": "dvips(k) 5.991 Copyright 2011 Radical Eye Software"}}}