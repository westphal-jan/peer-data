{"id": "1401.1475", "review": {"conference": "arxiv", "VERSION": "v1", "DATE_OF_SUBMISSION": "7-Jan-2014", "title": "Belief Revision in Structured Probabilistic Argumentation", "abstract": "near real - world applications, sensory interfaces consisting of all the definitions at hand for creating broader domain, along containing the current state of affairs, are bound to contain concurrent data coming from different sources, as is global phenomena involving variable degrees of dependency associated. likewise, an important aspect of procedural reasoning associated with creating knowledge bases is refining what properties am no longer useful ; pieces of structure ( collectively fragile intelligence reports ) may be outdated, even overlap whenever sources whose have recently been acknowledged of be of low quality, this strong evidence about just unavailable merely contradicts them. by futures forum, two compare a probabilistic causal argumentation framework that arises because the extension applying rational defeasible logic programming ( cds ) with behavioral models, who argue that this formalism is capable of addressing the basic issues of handling unexpected and uncertain solutions. lastly, \" address the dual task, we conditional on some study supporting non - prioritized belief revision operations - probabilistic predelp programs. should propose a book of reasoning postulates - - based on well - updated textbooks developed for semantic knowledge methods - - that demonstrate how structured collections should replicate, and study a majority of types coping with resulting conclusions with the proposed semantics, including a representation guarantee or consistent converse between this instruction and the class system operators characterized by the compiler.", "histories": [["v1", "Tue, 7 Jan 2014 18:53:24 GMT  (38kb)", "http://arxiv.org/abs/1401.1475v1", null]], "reviews": [], "SUBJECTS": "cs.LO cs.AI", "authors": ["paulo shakarian", "gerardo i simari", "marcelo a falappa"], "accepted": false, "id": "1401.1475"}, "pdf": {"name": "1401.1475.pdf", "metadata": {"source": "CRF", "title": "Belief Revision in Structured Probabilistic Argumentation", "authors": ["Paulo Shakarian", "Gerardo I. Simari", "Marcelo A. Falappa"], "emails": ["paulo@shakarian.net", "gerardo.simari@cs.ox.ac.uk", "mfalappa@cs.uns.edu.ar"], "sections": [{"heading": null, "text": "ar X\niv :1\n40 1.\n14 75\nv1 [\ncs .L\nO ]"}, {"heading": "1 Introduction and Related Work", "text": "Decision-support systems that are part of virtually any kind of real-world application must be part of a framework that is rich enough to deal with several basic problems: (i) handling contradictory information; (ii) answering abductive queries; (iii) managing uncertainty; and (iv) updating beliefs. Presumptions come into play as key components of answers to abductive queries, and must be maintained as elements of the knowledge base; therefore, whenever candidate answers to these queries are evaluated, the (in)consistency of the knowledge base\ntogether with the presumptions being made needs to be addressed via belief revision operations.\nIn this paper, we begin by proposing a framework that addresses items (i)\u2013 (iii) by extending Presumptive DeLP [1] (PreDeLP, for short) with probabilistic models in order to model uncertainty in the application domain; the resulting framework is a general-purpose probabilistic argumentation language that we will refer to as Probabilistic PreDeLP(P-PreDeLP, for short).\nIn the second part of this paper, we address the problem of updating beliefs \u2013 item (iv) above \u2013 in P-PreDeLP knowledge bases, focusing on the study of nonprioritized belief revision operations. We propose a set of rationality postulates characterizing how such operations should behave \u2013 these postulates are based on the well-known postulates proposed in [2] for non-prioritized belief revision in classical knowledge bases. We then study a class of operators and their theoretical relationships with the proposed postulates, concluding with a representation theorem.\nRelated Work. Belief revision studies changes to knowledge bases as a response to epistemic inputs. Traditionally, such knowledge bases can be either belief sets (sets of formulas closed under consequence) [3, 4] or belief bases [5, 2] (which are not closed); since our end goal is to apply the results we obtain to real-world domains, here we focus on belief bases. In particular, as motivated by requirements (i)\u2013(iv) above, our knowledge bases consist of logical formulas over which we apply argumentation-based reasoning and to which we couple a probabilistic model. The connection between belief revision and argumentation was first studied in [6]; since then, the work that is most closely related to our approach is the development of the explanation-based operators of [7].\nThe study of argumentation systems together with probabilistic reasoning has recently received a lot attention, though a significant part has been in the combination between the two has been in the form of probabilistic abstract argumentation [8\u201311]. There have, however, been several approaches that combine structured argumentation with models for reasoning under uncertainty; the first of such approaches to be proposed was [12], and several others followed, such as the possibilistic approach of [13], and the probabilistic logic-based approach of [14]. The main difference between these works and our own is that here we adopt a bipartite knowledge base, where one part models the knowledge that is not inherently probabilistic \u2013 uncertain knowledge is modeled separately, thus allowing a clear separation of interests between the two kinds of models. This approach is based on a similar one developed for ontological languages in the Semantic Web (see [15], and references within).\nFinally, to the best of our knowledge, this is the first paper in which the combination of structured argumentation, probabilistic models, and belief revision has been addressed in conjunction."}, {"heading": "2 Preliminaries", "text": "The Probabilistic PreDeLP (P-PreDeLP, for short) framework is composed of two separate models of the world. The first is called the environmental model (referred to as \u201cEM\u201d), and is used to describe the probabilistic knowledge that we have about the domain. The second one is called the analytical model (referred to as \u201cAM\u201d), and is used to analyze competing hypotheses that can account for a given phenomenon \u2013 what we will generally call queries. The AM is composed of a classical (that is, non-probabilistic) PreDeLP program in order to allow for contradictory information, giving the system the capability to model competing explanations for a given query.\nTwo Kinds of Uncertainty. In general, the EM contains knowledge such as evidence, uncertain facts, or knowledge about agents and systems. The AM, on the other hand, contains ideas that a user may conclude based on the information in the EM. Table 1 gives some examples of the types of information that could appear in each of the two models in a cyber-security application. Note that a knowledge engineer (or automated system) could assign a probability to statements in the EM column, whereas statements in the AM column can be either true or false depending on a certain combination (or several possible combinations) of statements from the EM. There are thus two kinds of uncertainty that need to be modeled: probabilistic uncertainty and uncertainty arising from defeasible knowledge. As we will see, our model allows both kinds of uncertainty to coexist, and also allows for the combination of the two since defeasible rules and presumptions (that is, defeasible facts) can also be annotated with probabilistic events.\nIn the rest of this section, we formally describe these two models, as well as how knowledge in the AM can be annotated with information from the EM \u2013 these annotations specify the conditions under which the various statements in the AM can potentially be true.\nBasic Language. We assume sets of variable and constant symbols, denoted with V and C, respectively. In the rest of this paper, we will use capital letters to represent variables (e.g., X,Y, Z), while lowercase letters represent constants. The next component of the language is a set of n-ary predicate symbols; the EM and AM use separate sets of predicate symbols, denoted with PEM,PAM,\nrespectively \u2013 the two models can, however, share variables and constants. As usual, a term is composed of either a variable or constant. Given terms t1, ..., tn and n-ary predicate symbol p, p(t1, ..., tn) is called an atom; if t1, ..., tn are constants, then the atom is said to be ground. The sets of all ground atoms for EM and AM are denoted with GEM and GAM, respectively.\nGiven set of ground atoms, a world is any subset of atoms \u2013 those that belong to the set are said to be true in the world, while those that do not are false. Therefore, there are 2|GEM| possible worlds in the EM and 2|GAM| worlds in the AM. These sets are denoted with WEM and WAM, respectively. In order to avoid worlds that do not model possible situations given a particular domain, we include integrity constraints of the form oneOf(A\u2032), where A\u2032 is a subset of ground atoms. Intuitively, such a constraint states that any world where more than one of the atoms from set A\u2032 appears is invalid. We use ICEM and ICAM to denote the sets of integrity constraints for the EM and AM, respectively, and the sets of worlds that conform to these constraints is denoted with WEM(ICEM),WAM(ICAM), respectively.\nFinally, logical formulas arise from the combination of atoms using the traditional connectives (\u2227, \u2228, and \u00ac). As usual, we say a world w satisfies formula (f), written w |= f , iff: (i) If f is an atom, then w |= f iff f \u2208 w; (ii) if f = \u00acf \u2032 then w |= f iff w 6|= f \u2032; (iii) if f = f \u2032 \u2227 f \u2032\u2032 then w |= f iff w |= f \u2032 and w |= f \u2032\u2032; and (iv) if f = f \u2032 \u2228 f \u2032\u2032 then w |= f iff w |= f \u2032 or w |= f \u2032\u2032. We use the notation formEM , formAM to denote the set of all possible (ground) formulas in the EM and AM, respectively."}, {"heading": "2.1 Probabilistic Model", "text": "The EM or environmental model is largely based on the probabilistic logic of [16], which we now briefly review.\nDefinition 1. Let f be a formula over PEM, V, and C, p \u2208 [0, 1], and \u01eb \u2208 [0,min(p, 1\u2212 p)]. A probabilistic formula is of the form f : p\u00b1 \u01eb. A set KEM of probabilistic formulas is called a probabilistic knowledge base.\nIn the above definition, the number \u01eb is referred to as an error tolerance. Intuitively, probabilistic formulas are interpreted as \u201cformula f is true with probability between p\u2212 \u01eb and p+ \u01eb\u201d \u2013 note that there are no further constraints over this interval apart from those imposed by other probabilistic formulas in the knowledge base. The uncertainty regarding the probability values stems from the fact that certain assumptions (such as probabilistic independence) may not be suitable in the environment being modeled.\nExample 1. Consider the following set KEM:\nf1 = a : 0.8\u00b1 0.1 f4 = d \u2227 e : 0.7\u00b1 0.2 f7 = k : 1\u00b1 0 f2 = b : 0.2\u00b1 0.1 f5 = f \u2227 g \u2227 h : 0.6\u00b1 0.1 f3 = c : 0.8\u00b1 0.1 f6 = i \u2228 \u00acj : 0.9\u00b1 0.1\nThroughout the paper, we also use K\u2032EM = {f1, f2, f3}\nA set of probabilistic formulas describes a set of possible probability distributions Pr over the set WEM(ICEM). We say that probability distribution Pr satisfies probabilistic formula f : p\u00b1 \u01eb iff: p\u2212 \u01eb \u2264 \u2211\nw\u2208WEM(ICEM) Pr(w) \u2264 p+ \u01eb.\nWe say that a probability distribution over WEM(ICEM) satisfies KEM iff it satisfies all probabilistic formulas in KEM.\nGiven a probabilistic knowledge base and a (non-probabilistic) formula q, the maximum entailment problem seeks to identify real numbers p, \u01eb such that all valid probability distributions Pr that satisfy KEM also satisfy q : p\u00b1 \u01eb, and there does not exist p\u2032, \u01eb\u2032 s.t. [p\u2212 \u01eb, p+ \u01eb] \u2283 [p\u2032\u2212 \u01eb\u2032, p\u2032+ \u01eb\u2032], where all probability distributions Pr that satisfy KEM also satisfy q : p\u2032 \u00b1 \u01eb\u2032. In order to solve this problem we must solve the linear program defined below.\nDefinition 2. Given a knowledge base KEM and a formula q, we have a variable xi for each wi \u2208 WEM(ICEM).\n\u2013 For each fj : pj \u00b1 \u01ebj \u2208 KEM, there is a constraint of the form:\npj \u2212 \u01ebj \u2264 \u2211\nwi\u2208WEM(ICEM) s.t. wi|=fj xi \u2264 pj + \u01ebj .\n\u2013 We also have the constraint: \u2211\nwi\u2208WEM(ICEM) xi = 1.\n\u2013 The objective is to minimize the function: \u2211\nwi\u2208WEM(ICEM) s.t. wi|=q xi.\nWe use the notation EP-LP-MIN(KEM, q) to refer to the value of the objective function in the solution to the EM-LP-MIN constraints.\nThe next step is to solve the linear program a second time, but instead maximizing the objective function (we shall refer to this as EM-LP-MAX) \u2013 let \u2113 and u be the results of these operations, respectively. In [16], it is shown that \u01eb = u\u2212\u21132 and p = \u2113 + \u01eb is the solution to the maximum entailment problem. We note that although the above linear program has an exponential number of variables in the worst case (i.e., no integrity constraints), the presence of constraints has the potential to greatly reduce this space. Further, there are also good heuristics (cf. [17, 18]) that have been shown to provide highly accurate approximations with a reduced-size linear program.\nExample 2. Consider KB K\u2032EM from Example 1 and a set of ground atoms restricted to those that appear in that program; we have the following worlds:\nw1 = {a, b, c} w2 = {a, b} w3 = {a, c} w4 = {b, c} w5 = {b} w6 = {a} w7 = {c} w8 = \u2205\nand suppose we wish to compute the probability for formula q = a\u2228 c. For each formula in KEM we have a constraint, and for each world above we have a variable. An objective function is created based on the worlds that satisfy the query formula (in this case, worldsw1, w2, w3, w4, w6, w7). Solving EP-LP-MAX(K\u2032EM, q) and EP-LP-MIN(K\u2032EM, q), we obtain the solution 0.9\u00b1 0.1."}, {"heading": "3 Argumentation Model", "text": "For the analytical model (AM), we choose a structured argumentation framework [19] due to several characteristics that make such frameworks highly applicable to many domains. Unlike the EM, which describes probabilistic information about the state of the real world, the AM must allow for competing ideas. Therefore, it must be able to represent contradictory information. The algorithmic approach we shall later describe allows for the creation of arguments based on the AM that may \u201ccompete\u201d with each other to answer a given query. In this competition \u2013 known as a dialectical process \u2013 one argument may defeat another based on a comparison criterion that determines the prevailing argument. Resulting from this process, certain arguments are warranted (those that are not defeated by other arguments) thereby providing a suitable explanation for the answer to a given query.\nThe transparency provided by the system can allow knowledge engineers to identify potentially incorrect input information and fine-tune the models or, alternatively, collect more information. In short, argumentation-based reasoning has been studied as a natural way to manage a set of inconsistent information \u2013 it is the way humans settle disputes. As we will see, another desirable characteristic of (structured) argumentation frameworks is that, once a conclusion is reached, we are left with an explanation of how we arrived at it and information about why a given argument is warranted; this is very important information for users to have. In the following, we first recall the basics of the underlying argumentation framework used, and then go on to introduce the analytical model (AM)."}, {"heading": "3.1 Defeasible Logic Programming with Presumptions (PreDeLP)", "text": "Defeasible Logic Programming with Presumptions (PreDeLP) [1] is a formalism combining logic programming with defeasible argumentation; it arises as an extension of classical DeLP [20] with the possibility of having presumptions, as described below \u2013 since this capability is useful in many applications, we adopt this extended version in this paper. In this section, we briefly recall the basics of PreDeLP; we refer the reader to [20, 1] for the complete presentation.\nThe formalism contains several different constructs: facts, presumptions, strict rules, and defeasible rules. Facts are statements about the analysis that can always be considered to be true, while presumptions are statements that may or may not be true. Strict rules specify logical consequences of a set of facts or presumptions (similar to an implication, though not the same) that must always occur, while defeasible rules specify logical consequences that may be assumed to be true when no contradicting information is present. These building blocks are used in the construction of arguments, and are part of a PreDeLP program, which is a set of facts, strict rules, presumptions, and defeasible rules. Formally, we use the notation \u03a0AM = (\u0398,\u2126,\u03a6,\u2206) to denote a PreDeLP program, where \u2126 is the set of strict rules, \u0398 is the set of facts, \u2206 is the set of defeasible rules, and \u03a6 is the set of presumptions. In Figure 1, we provide an example \u03a0AM. We now define these constructs formally.\nFacts (\u0398) are ground literals representing atomic information or its negation, using strong negation \u201c\u00ac\u201d. Note that all of the literals in our framework must be formed with a predicate from the set PAM. Note that information in the form of facts cannot be contradicted. We will use the notation [\u0398] to denote the set of all possible facts.\nStrict Rules (\u2126) represent non-defeasible cause-and-effect information that resembles an implication (though the semantics is different since the contrapositive does not hold) and are of the form L0\u2190 L1, . . . , Ln, where L0 is a ground literal and {Li}i>0 is a set of ground literals. We will use the notation [\u2126] to denote the set of all possible strict rules.\nPresumptions (\u03a6) are ground literals of the same form as facts, except that they are not taken as being true but rather defeasible, which means that they can be contradicted. Presumptions are denoted in the same manner as facts, except that the symbol \u2013\u227a is added.\nDefeasible Rules (\u2206) represent tentative knowledge that can be used if nothing can be posed against it. Just as presumptions are the defeasible counterpart of facts, defeasible rules are the defeasible counterpart of strict rules. They are of the form L0 \u2013\u227a L1, . . . , Ln, where L0 is a ground literal and {Li}i>0 is a set of ground literals. In both strict and defeasible rules, strong negation is allowed in the head of rules, and hence may be used to represent contradictory knowledge.\nEven though the above constructs are ground, we allow for schematic versions with variables that are used to represent sets of ground rules. We denote variables with strings starting with an uppercase letter.\nArguments. Given a query in the form of a ground atom, the goal is to derive arguments for and against it\u2019s validity \u2013 derivation follows the same mechanism of logic programming [21]. Since rule heads can contain strong negation, it is possible to defeasibly derive contradictory literals from a program. For the treatment of contradictory knowledge, PreDeLP incorporates a defeasible argumentation formalism that allows the identification of the pieces of knowledge that are in conflict and, through the previously mentioned dialectical process, decides which information prevails as warranted. This dialectical process involves\nthe construction and evaluation of arguments, building a dialectical tree in the process. Arguments are formally defined next.\nDefinition 3. An argument \u3008A, L\u3009 for a literal L is a pair of the literal and a (possibly empty) set of the EM (A \u2286 \u03a0AM) that provides a minimal proof for L meeting the following requirements: (i) L is defeasibly derived from A; (ii) \u2126 \u222a \u0398 \u222a A is not contradictory; and (iii) A is a minimal subset of \u2206 \u222a \u03a6 satisfying 1 and 2, denoted \u3008A, L\u3009.\nLiteral L is called the conclusion supported by the argument, and A is the support of the argument. An argument \u3008B, L\u3009 is a subargument of \u3008A, L\u2032\u3009 iff B \u2286 A. An argument \u3008A, L\u3009 is presumptive iff A\u2229\u03a6 is not empty. We will also use \u2126(A) = A \u2229\u2126, \u0398(A) = A \u2229\u0398, \u2206(A) = A\u2229\u2206, and \u03a6(A) = A\u2229 \u03a6.\nOur definition differs slightly from that of [22], where DeLP is introduced, as we include strict rules and facts as part of arguments \u2013 the reason for this will become clear in Section 4. Arguments for our scenario are shown next.\nExample 3. Figure 2 shows example arguments based on the knowledge base from Figure 1. Note that \u3008A5, u\u3009 is a sub-argument of \u3008A2, s\u3009 and \u3008A3, s\u3009.\nGiven an argument \u3008A1, L1\u3009, counter-arguments are arguments that contradict it. Argument \u3008A2, L2\u3009 is said to counterargue or attack \u3008A1, L1\u3009 at a literal L\u2032 iff there exists a subargument \u3008A, L\u2032\u2032\u3009 of \u3008A1, L1\u3009 such that the set \u2126(A1) \u222a\u2126(A2) \u222a\u0398(A1) \u222a\u0398(A2) \u222a {L2, L\u2032\u2032} is contradictory.\nExample 4. Consider the arguments from Example 3. The following are some of the attack relationships between them: A1, A2, A3, and A4 all attack A6; A5 attacks A7; and A7 attacks A2.\nA proper defeater of an argument \u3008A,L\u3009 is a counter-argument that \u2013 by some criterion \u2013 is considered to be better than \u3008A,L\u3009; if the two are incomparable according to this criterion, the counterargument is said to be a blocking defeater. An important characteristic of PreDeLP is that the argument comparison criterion is modular, and thus the most appropriate criterion for the domain that is being represented can be selected; the default criterion used in classical defeasible logic programming (from which PreDeLP is derived) is generalized specificity [23], though an extension of this criterion is required for arguments using presumptions [1]. We briefly recall this criterion next \u2013 the first definition is for generalized specificity, which is subsequently used in the definition of presumption-enabled specificity.\nDefinition 4. Let \u03a0AM = (\u0398,\u2126,\u03a6,\u2206) be a PreDeLP program and let F be the set of all literals that have a defeasible derivation from \u03a0AM. An argument \u3008A1, L1\u3009 is preferred to \u3008A2, L2\u3009, denoted with A1 \u227bPS A2 iff:\n(1) For all H \u2286 F , \u2126(A1) \u222a \u2126(A2) \u222a H is non-contradictory: if there is a derivation for L1 from \u2126(A2) \u222a\u2126(A1) \u222a\u2206(A1)\u222aH, and there is no derivation for L1 from \u2126(A1)\u222a\u2126(A2)\u222aH, then there is a derivation for L2 from \u2126(A1)\u222a \u2126(A2) \u222a\u2206(A2) \u222aH; and (2) there is at least one set H \u2032 \u2286 F , \u2126(A1)\u222a\u2126(A2)\u222aH \u2032 is non-contradictory, such that there is a derivation for L2 from \u2126(A1) \u222a\u2126(A2) \u222aH \u2032 \u222a\u2206(A2), there is no derivation for L2 from \u2126(A1)\u222a\u2126(A2)\u222aH \u2032, and there is no derivation for L1 from \u2126(A1) \u222a\u2126(A2) \u222aH \u2032 \u222a\u2206(A1).\nIntuitively, the principle of specificity says that, in the presence of two conflicting lines of argument about a proposition, the one that uses more of the available information is more convincing. A classic example involves a bird, Tweety, and arguments stating that it both flies (because it is a bird) and doesn\u2019t fly (because it is a penguin). The latter argument uses more information about Tweety \u2013 it is more specific \u2013 and is thus the stronger of the two.\nDefinition 5 ([1]). Let \u03a0AM = (\u0398,\u2126,\u03a6,\u2206) be a PreDeLP program. An argument \u3008A1, L1\u3009 is preferred to \u3008A2, L2\u3009, denoted with A1 \u227b A2 iff any of the following conditions hold:\n(1) \u3008A1, L1\u3009 and \u3008A2, L2\u3009 are both factual arguments and \u3008A1, L1\u3009 \u227bPS \u3008A2, L2\u3009.\n(2) \u3008A1, L1\u3009 is a factual argument and \u3008A2, L2\u3009 is a presumptive argument.\n(3) \u3008A1, L1\u3009 and \u3008A2, L2\u3009 are presumptive arguments, and\n(a) \u03a6(A1) ( \u03a6(A2) or,\n(b) \u03a6(A1) = \u03a6(A2) and \u3008A1, L1\u3009 \u227bPS \u3008A2, L2\u3009.\nGenerally, if A,B are arguments with rules X and Y , resp., and X \u2282 Y , then A is stronger than B. This also holds when A and B use presumptions P1 and P2, resp., and P1 \u2282 P2.\nExample 5. The following are some relationships between arguments from Example 3, based on Definitions 4 and 5.\nA1 and A6 are incomparable (blocking defeaters); A6 \u227b A2, and thus A6 defeats A2; A5 and A7 are incomparable (blocking defeaters).\nA sequence of arguments called an argumentation line thus arises from this attack relation, where each argument defeats its predecessor. To avoid undesirable sequences, which may represent circular argumentation lines, in DeLP an argumentation line is acceptable if it satisfies certain constraints (see [20]). A literal L is warranted if there exists a non-defeated argument A supporting L.\nClearly, there can be more than one defeater for a particular argument \u3008A, L\u3009. Therefore, many acceptable argumentation lines could arise from \u3008A, L\u3009, leading to a tree structure. The tree is built from the set of all argumentation lines\nrooted in the initial argument. In a dialectical tree, every node (except the root) represents a defeater of its parent, and leaves correspond to undefeated arguments. Each path from the root to a leaf corresponds to a different acceptable argumentation line. A dialectical tree provides a structure for considering all the possible acceptable argumentation lines that can be generated for deciding whether an argument is defeated. We call this tree dialectical because it represents an exhaustive dialectical4 analysis for the argument in its root. For a given argument \u3008A, L\u3009, we denote the corresponding dialectical tree as T (\u3008A, L\u3009).\nGiven a literal L and an argument \u3008A, L\u3009, in order to decide whether or not a literal L is warranted, every node in the dialectical tree T (\u3008A, L\u3009) is recursively marked as \u201cD\u201d (defeated) or \u201cU\u201d (undefeated), obtaining a marked dialectical tree T \u2217(\u3008A, L\u3009) as follows:\n1. All leaves in T \u2217(\u3008A, L\u3009) are marked as \u201cU\u201ds, and 2. Let \u3008B, q\u3009 be an inner node of T \u2217(\u3008A, L\u3009). Then \u3008B, q\u3009 will be marked as \u201cU\u201d\niff every child of \u3008B, q\u3009 is marked as \u201cD\u201d. The node \u3008B, q\u3009 will be marked as \u201cD\u201d iff it has at least a child marked as \u201cU\u201d.\nGiven an argument \u3008A, L\u3009 obtained from \u03a0AM, if the root of T \u2217(\u3008A, L\u3009) is marked as \u201cU\u201d, then we will say that T \u2217(\u3008A, h\u3009) warrants L and that L is warranted from \u03a0AM. (Warranted arguments correspond to those in the grounded extension of a Dung argumentation system [24].) There is a further requirement when the arguments in the dialectical tree contains presumptions \u2013 the conjunction of all presumptions used in even (respectively, odd) levels of the tree must be consistent. This can give rise to multiple trees for a given literal, as there can potentially be different arguments that make contradictory assumptions.\nWe can then extend the idea of a dialectical tree to a dialectical forest. For a given literal L, a dialectical forest F(L) consists of the set of dialectical trees for all arguments for L. We shall denote a marked dialectical forest, the set of all marked dialectical trees for arguments for L, as F\u2217(L). Hence, for a literal L, we say it is warranted if there is at least one argument for that literal in the dialectical forest F\u2217(L) that is labeled as \u201cU\u201d, not warranted if there is at least one argument for the literal \u00acL in the dialectical forest F\u2217(\u00acL) that is labeled as \u201cU\u201d, and undecided otherwise."}, {"heading": "4 Probabilistic PreDeLP", "text": "Probabilistic PreDeLP arises from the combination of the environmental and analytical models (\u03a0EM and \u03a0AM, respectively). Intuitively, given \u03a0AM, every element of \u2126 \u222a \u0398 \u222a\u2206 \u222a \u03a6 might only hold in certain worlds in the set WEM \u2013 that is, they are subject to probabilistic events. Therefore, we associate elements of \u2126 \u222a\u0398 \u222a\u2206 \u222a \u03a6 with a formula from formEM . For instance, we could associate formula rainy to fact umbrella to state that the latter only holds when the probabilistic event rainy holds; since weather is uncertain in nature, it has been modeled as part of the EM.\n4 In the sense of providing reasons for and against a position.\nWe can then compute the probabilities of subsets of \u2126 \u222a\u0398\u222a\u2206 \u222a \u03a6 using the information contained in \u03a0EM, as we describe shortly. The notion of an annotation function associates elements of \u2126 \u222a\u0398 \u222a\u2206 \u222a \u03a6 with elements of formEM .\nDefinition 6. An annotation function is any function af : \u2126 \u222a \u0398 \u222a \u2206 \u222a \u03a6 \u2192 formEM . We shall use [af ] to denote the set of all annotation functions.\nWe will sometimes denote annotation functions as sets of pairs (f, af(f)) in order to simplify the presentation. Figure 3 shows an example of an annotation function for our running example.\nWe now have all the components to formally define Probabilistic PreDeLP programs (P-PreDeLP for short).\nDefinition 7. Given environmental model \u03a0EM, analytical model \u03a0AM, and annotation function af , a probabilistic PreDeLP program is of the form I = (\u03a0EM, \u03a0AM, af ). We use notation [I] to denote the set of all possible programs.\nGiven this setup, we can consider a world-based approach; that is, the defeat relationship among arguments depends on the current state of the (EM) world.\nDefinition 8. Let I = (\u03a0EM, \u03a0AM, af ) be a P-PreDeLP program, argument \u3008A, L\u3009 is valid w.r.t. world w \u2208 WEM iff \u2200c \u2208 A, w |= af(c).\nWe extend the notion of validity to argumentation lines, dialectical trees, and dialectical forests in the expected way (for instance, an argumentation line is valid w.r.t. w iff all arguments that comprise that line are valid w.r.t. w). We also extend the idea of a dialectical tree w.r.t. worlds; so, for a given world w \u2208 WEM, the dialectical (resp., marked dialectical) tree induced by w is denoted with Tw\u3008A, L\u3009 (resp., T \u2217w \u3008A, L\u3009). We require that all arguments and defeaters in these trees to be valid with respect to w. Likewise, we extend the notion of dialectical forests in the same manner (denoted with Fw(L) and F\u2217w(L), resp.). Based on these concepts we introduce the notion of warranting scenario.\nDefinition 9. Let I = (\u03a0EM, \u03a0AM, af ) be a P-PreDeLP program and L be a literal formed with a ground atom from GAM; a world w \u2208 WEM is said to be a warranting scenario for L (denoted w \u22a2war L) iff there is a dialectical forest F\u2217w(L) in which L is warranted and F \u2217 w(L) is valid w.r.t. w.\nHence, the set of worlds in the EM where a literal L in the AM must be true is exactly the set of warranting scenarios \u2013 these are the \u201cnecessary\u201d worlds: nec(L) = {w \u2208 WEM | (w \u22a2war L)}. Now, the set of worlds in the EM where AM literal L can be true is the following \u2013 these are the \u201cpossible\u201d worlds: poss(L) = {w \u2208 WEM | w 6\u22a2war \u00acL}. The probability distribution Pr defined over the worlds in the EM induces an upper and lower bound on the probability of literal L (denoted PL,Pr ,I) as follows:\n\u2113L,Pr ,I = \u2211\nw\u2208nec(L)\nPr(w), uL,Pr ,I = \u2211\nw\u2208poss(L)\nPr (w)\n\u2113L,Pr ,I \u2264 PL,Pr ,I \u2264 uL,Pr ,I\nSince the EM in general does not define a single probability distribution, the above computations should be done using linear programs EP-LP-MIN and EPLP-MAX, as described above."}, {"heading": "4.1 Sources of Inconsistency", "text": "We use the following notion of (classical) consistency of PreDeLP programs: \u03a0 is said to be consistent if there does not exist ground literal a s.t. \u03a0 \u22a2 a and \u03a0 \u22a2 \u00aca. For P-PreDeLP programs, there are two main kinds of inconsistency that can be present; the first is what we refer to as EM, or Type I, (in)consistency.\nDefinition 10. Environmental model \u03a0EM is Type I consistent iff there exists a probability distribution Pr over the set of worlds WEM that satisfies \u03a0EM.\nWe illustrate this type of consistency in the following example.\nExample 6. The following formula is a simple example of an EM for which there is no satisfying probability distribution:\nrain \u2228 hail : 0.3\u00b1 0;\nrain \u2227 hail : 0.5\u00b1 0.1.\nA P-PreDeLP program using such an EM gives rise to an example of Type I inconsistency, as it arises from the fact that there is no satisfying interpretation for the EM knowledge base.\nAssuming a consistent EM, inconsistencies can still arise through the interaction between the annotation function and facts and strict rules. We will refer to this as combined, or Type II, (in)consistency.\nDefinition 11. A P-PreDeLP program I = (\u03a0EM, \u03a0AM, af ), with \u03a0AM = \u3008\u0398,\u2126,\u03a6,\u2206\u3009, is Type II consistent iff: given any probability distribution Pr that satisfies \u03a0EM, if there exists a world w \u2208 WEM such that \u22c3 x\u2208\u0398\u222a\u2126 |w|=af(x){x} is inconsistent, then we have Pr(w) = 0.\nThus, any EM world in which the set of associated facts and strict rules are inconsistent (we refer to this as \u201cclassical consistency\u201d) must always be assigned a zero probability. The following is an example of this other type of inconsistency.\nExample 7. Consider the EM knowledge base from Example 1, the AM presented in Figure 1 and the annotation function from Figure 3. Suppose the following fact is added to the argumentation model:\n\u03b83 = \u00acp,\nand that the annotation function is expanded as follows:\naf (\u03b83) = \u00ack.\nClearly, fact \u03b83 is in direct conflict with fact \u03b81a \u2013 this does not necessarily mean that there is an inconsistency. For instance, by the annotation function, \u03b81a holds in the world {k} while \u03b83 does not. However, if we consider the world:\nw = {f, h)\nNote that w |= af (\u03b83) and w |= af (\u03b82), which means that, in this world, two contradictory facts can occur. Since the environmental model indicates that this world can be assigned a non-zero probability, we have a Type II inconsist program.\nAnother example (perhaps easier to visualize) in the rain/hail scenario discussed above, is as follows: suppose we have facts f = umbrella and g = \u00acumbrella, and annotation function af (f) = rain \u2228 hail and af (g) = wind. Intuitively, the first fact states that an umbrella should be carried if it either rains or hails, while the second states that an umbrella should not be carried if it is windy. If the EM assigns a non-zero probability to formula (rain \u2228 hail)\u2227wind, then we have Type II inconsistency.\nIn the following, we say that a P-PreDeLP program is consistent if and only if it is both Type I and Type II consistent. However, in this paper, we focus on Type II consistency and assume that the program is Type I consistent."}, {"heading": "4.2 Basic Operations for Restoring Consistency", "text": "Given a P-PreDeLP program that is Type II inconsistent, there are two basic strategies that can be used to restore consistency:\nRevise the EM: the probabilistic model can be changed in order to force the worlds that induce contradicting strict knowledge to have probability zero.\nRevise the annotation function: The annotations involved in the inconsistency can be changed so that the conflicting information in the AM does not become induced under any possible world.\nIt may also appear that a third option would be to adjust the AM \u2013 this is, however, equivalent to modifying the annotation function. Consider the presence\nof two facts in the AM: a,\u00aca. Assuming that this causes an inconsistency (that is, there is at least one world in which they both hold), one way to resolve it would be to remove one of these two literals. Suppose \u00aca is removed; this would be equivalent to setting af(\u00aca) = \u22a5 (where \u22a5 represents a contradiction in the language of the EM). In this paper, we often refer to \u201cremoving elements of \u03a0AM\u201d to refer to changes to the annotation function that cause certain elements of the \u03a0AM to not have their annotations satisfied in certain EM worlds.\nNow, suppose that \u03a0EM is consistent, but that the overall program is Type II inconsistent. Then, there must exist a set of worlds in the EM where there is a probability distribution that assigns each of them a non-zero probability. This gives rise to the following result.\nProposition 1. If there exists a probability distribution Pr that satisfies \u03a0EM s.t. there exists a world w \u2208 WEM where Pr(w) > 0 and \u22c3 x\u2208\u0398\u222a\u2126 |w|=af(x){x} is inconsistent (Type II inconsistency), then any change made in order to resolve this inconsistency by modifying only \u03a0EM yields a new EM \u03a0 \u2032 EM such that ( \u2227\na\u2208w a \u2227 \u2227 a/\u2208w \u00aca ) : 0\u00b1 0 is entailed by \u03a0 \u2032EM.\nProposition 1 seems to imply an easy strategy of adding formulas to \u03a0EM causing certain worlds to have a zero probability. However, this may lead to Type I inconsistencies in the resulting model\u03a0 \u2032EM. If we are applying an EM-only strategy to resolve inconsistencies, this would then lead to further adjustments to \u03a0 \u2032EM in order to restore Type I consistency. However, such changes could potentially lead to Type II inconsistency in the overall P-PreDeLP program (by either removing elements of \u03a0 \u2032EM or loosening probability bounds of the sentences in \u03a0 \u2032EM), which would lead to setting more EM worlds to a probability of zero. It is easy to devise an example of a situation in which the probability mass cannot be accommodated given the constraints imposed by the AM and EM together \u2013 in such cases, it would be impossible to restore consistency by only modifying \u03a0EM. We thus arrive at the following observation:\nObservation 1 Given a Type II inconsistent P-PreDeLP program, consistency cannot always be restored via modifications to \u03a0EM alone.\nTherefore, due to this line of reasoning, in this paper we focus our efforts on modifications to the annotation function only. However, in the future, we intend to explore belief revision operators that consider both the annotation function (which, as we saw, captures changes to the AM) along with changes to the EM, as well as combinations of the two."}, {"heading": "5 Revising Probabilistic PreDeLP Programs", "text": "Given a P-PreDeLP program I = (\u03a0EM, \u03a0AM, af ), with \u03a0AM = \u2126\u222a\u0398\u222a\u2206 \u222a \u03a6, we are interested in solving the problem of incorporating an epistemic input (f, af \u2032) into I, where f is either an atom or a rule and af \u2032 is equivalent to af , except for its expansion to include f . For ease of presentation, we assume\nthat f is to be incorporated as a fact or strict rule, since incorporating defeasible knowledge can never lead to inconsistency. As we are only conducting annotation function revisions, for I = (\u03a0EM, \u03a0AM, af ) and input (f, af\n\u2032) we denote the revision as follows: I \u2022 (f, af \u2032) = (\u03a0EM, \u03a0 \u2032 AM, af\n\u2032\u2032) where \u03a0 \u2032AM = \u03a0AM \u222a {f} and af \u2032\u2032 is the revised annotation function.\nNotation. We use the symbol \u201c\u2022\u201d to denote the revision operator. We also slightly abuse notation for the sake of presentation, as well as introduce notation to convert sets of worlds to/from formulas.\n\u2013 I \u222a (f, af \u2032) to denote I \u2032 = (\u03a0EM, \u03a0AM \u222a {f}, af \u2032).\n\u2013 (f, af \u2032) \u2208 I = (\u03a0AM, \u03a0EM, af ) to denote f \u2208 \u03a0AM and af = af \u2032.\n\u2013 wld(f) = {w | w |= f} \u2013 the set of worlds that satisfy formula f ; and\n\u2013 for(w) = \u2227 a\u2208w a \u2227 \u2227 a/\u2208w \u00aca \u2013 the formula that has w as its only model.\n\u2013 \u03a0IAM(w) = {f \u2208 \u0398 \u222a\u2126 | w |= af(f)}\n\u2013 W0EM(I) = {w \u2208 WEM | \u03a0 I AM(w) is inconsistent}\n\u2013 WIEM(I) = {w \u2208 W 0 EM | \u2203Pr s.t. Pr |= \u03a0EM \u2227 Pr(w) > 0}\nIntuitively, \u03a0IAM(w) is the subset of facts and strict rules in \u03a0AM whose annotations are true in EM world w. The set W0EM(I) contains all the EM worlds for a given program where the corresponding knowledge base in the AM is classically inconsistent and WIEM(I) is a subset of these that can be assigned a non-zero probability \u2013 the latter are the worlds where inconsistency in the AM can arise."}, {"heading": "5.1 Postulates for Revising the Annotation Function", "text": "We now analyze the rationality postulates for non-prioritized revision of belief bases first introduced in [2] and later generalized in [25], in the context of PPreDeLP programs. These postulates are chosen due to the fact that they are well studied in the literature for non-prioritized belief revision.\nInclusion: For I \u2022 (f, af \u2032) = (\u03a0EM, \u03a0AM\u222a{f}, af \u2032\u2032), \u2200g \u2208 \u03a0AM, wld\n( af \u2032\u2032(g) )\n\u2286 wld(af \u2032(g)).\nThis postulate states that, for any element in the AM, the worlds that satisfy its annotation after the revision are a subset of the original set of worlds satisfying the annotation for that element.\nVacuity: If I \u222a (f, af \u2032) is consistent, then I \u2022 (f, af \u2032) = I \u222a (f, af \u2032)\nConsistency Preservation: If I is consistent, then I\u2022(f, af \u2032) is also consistent.\nWeak Success: If I \u222a (f, af \u2032) is consistent, then (f, af \u2032) \u2208 I \u2022 (f, af \u2032).\nWhenever the simple addition of the input doesn\u2019t cause inconsistencies to arise, the result will contain the input.\nCore Retainment: For I \u2022 (f, af \u2032) = (\u03a0EM, \u03a0AM \u222a {f}, af \u2032\u2032), for each w \u2208 WIEM(I \u222a (f, af \u2032)), we have Xw = {h \u2208 \u0398 \u222a \u2126 | w |= af \u2032\u2032(h)}; for each g \u2208\n\u03a0AM(w) \\Xw there exists Yw \u2286 Xw \u222a {f} s.t. Yw is consistent and Yw \u222a {g} is inconsistent.\nFor a given EM world, if a portion of the associated AM knowledge base is removed by the operator, then there exists a subset of the remaining knowledge base that is not consistent with the removed element and f .\nRelevance: For I \u2022 (f, af \u2032) = (\u03a0EM, \u03a0AM \u222a {f}, af \u2032\u2032), for each w \u2208 WIEM(I \u222a (f, af \u2032)), we have Xw = {h \u2208 \u0398 \u222a\u2126 | w |= af \u2032\u2032(h)}; for each g \u2208 \u03a0AM(w) \\Xw there exists Yw \u2287 Xw \u222a {f} s.t. Yw is consistent and Yw \u222a {g} is inconsistent.\nFor a given EM world, if a portion of the associated AM knowledge base is removed by the operator, then there exists a superset of the remaining knowledge base that is not consistent with the removed element and f .\nUniformity 1: Let (f, af \u20321), (g, af \u2032 2) be two inputs where W I EM(I \u222a (f, af \u2032 1)) = WIEM(I \u222a (g, af \u2032 2)); for all w \u2208 W I EM(I \u222a (f, af\n\u2032)) and for all X \u2286 \u03a0AM(w); if {x | x \u2208 X \u222a {f}, w |= af \u20321(x)} is inconsistent iff {x | x \u2208 X \u222a {g}, w |= af \u2032 2(x)} is inconsistent, then for each h \u2208 \u03a0AM, we have that:\n{w \u2208 WIEM(I \u222a (f, af \u2032 1)) | w |= af \u2032 1(h) \u2227 \u00acaf \u2032\u2032 1(h)} =\n{w \u2208 WIEM(I \u222a (g, af \u2032 2)) | w |= af \u2032 2(h) \u2227 \u00acaf \u2032\u2032 2(h)}.\nIf two inputs result in the same set of EM worlds leading to inconsistencies in an AM knowledge base, and the consistency between analogous subsets (when joined with the respective input) are the same, then the models removed from the annotation of a given strict rule or fact are the same for both inputs.\nUniformity 2: Let (f, af \u20321), (g, af \u2032 2) be two inputs where W I EM(I \u222a (f, af \u2032 1)) = WIEM(I \u222a (g, af \u2032 2)); for all w \u2208 W I EM(I \u222a (f, af\n\u2032))and for all X \u2286 \u03a0AM(w); if {x | x \u2208 X \u222a {f}, w |= af \u20321(x)} is inconsistent iff {x | x \u2208 X \u222a {g}, w |= af \u2032 2(x)} is inconsistent, then\n{w \u2208 WIEM(I \u222a (f, af \u2032 1)) | w |= af \u2032 1(h) \u2227 af \u2032\u2032 1(h)} =\n{w \u2208 WIEM(I \u222a (g, af \u2032 2)) | w |= af \u2032 2(h) \u2227 af \u2032\u2032 2 (h)}.\nIf two inputs result in the same set of EM worlds leading to inconsistencies in an AM knowledge base, and the consistency between analogous subsets (when joined with the respective input) are the same, then the models retained in the the annotation of a given strict rule or fact are the same for both inputs.\nRelationships between Postulates. There are a couple of interesting relationships among the postulates. The first is a sufficient condition for Core Retainment to be implied by Relevance.\nProposition 2. Let \u2022 be an operator such that I \u2022 (f, af \u2032) = (\u03a0EM, \u03a0AM \u222a {f}, af \u2032\u2032), where \u2200w \u2208 WIEM(I \u222a (f, af \u2032)), \u03a0 I\u2022(f,af \u2032) AM (w) is a maximal consistent subset of \u03a0 I\u222a(f,af \u2032) AM (w). If \u2022 satisfies Relevance then it also satisfies Core Retainment.\nSimilarly, we can show the equivalence between the two Uniformity postulates under certain conditions.\nProposition 3. Let \u2022 be an operator such that I \u2022 (f, af \u2032) = (\u03a0EM, \u03a0AM \u222a {f}, af \u2032\u2032) and \u2200w, \u03a0 I\u2022(f,af \u2032) AM (w) \u2286 \u03a0 I\u222a(f,af \u2032) AM (w). Operator \u2022 satisfies Uniformity 1 iff it satisfies Uniformity 2.\nGiven the results of Propositions 2 and 3, we will not study Core Retainment and Uniformity 2 with respect to the construction of a belief revision operator in the next section."}, {"heading": "5.2 An Operator for P-PreDeLP Revision", "text": "In this section, we introduce an operator for revising a P-PreDeLP program. As stated earlier, any subset of \u03a0AM associated with a world in WIEM(I \u222a (f, af\n\u2032)) must be modified by the operator in order to remain consistent. So, for such a world w, we introduce a set of candidate replacement programs for \u03a0AM(w) in order to maintain consistency and satisfy the Inclusion postulate.\ncandPgm(w, I) = {\u03a0 \u2032AM | \u03a0 \u2032 AM \u2286 \u03a0AM(w) s.t. \u03a0 \u2032 AM is consistent and\n\u2204\u03a0 \u2032\u2032AM \u2286 \u03a0AM(w) s.t. \u03a0 \u2032\u2032 AM \u2283 \u03a0 \u2032 AM s.t. \u03a0 \u2032\u2032 AM is consistent}\nIntuitively, candPgm(w, I) is the set of maximal consistent subsets of \u03a0AM(w). Coming back to the rain/hail example presented above, we have:\nExample 8. Consider the P-PreDeLP program I presented right after Example 7, and the following EM knowledge base:\nrain \u2228 hail : 0.5\u00b1 0.1;\nrain \u2227 hail : 0.3\u00b1 0.1;\nwind : 0.2\u00b1 0.\nGiven this setup, we have, for instance:\ncandPgm({rain, hail, wind}, I) = { { umbrella } , { \u00acumbrella } } .\nIntuitively, this means that, since the world where rain, hail, and wind are all true can be assigned a non-zero probability by the EM, we must choose either umbrella or \u00acumbrella in order to recover consistency.\nWe now show a series of intermediate results that lead up to the representation theorem (Theorem 1). First, we show how this set plays a role in showing a necessary and sufficient requirement for Inclusion and Consistency Preservation to hold together.\nLemma 1. Given program I and input (f, af \u2032), operator \u2022 satisfies Inclusion and Consistency Preservation iff for I \u2022 (f, af \u2032) = (\u03a0EM, \u03a0AM, af\n\u2032\u2032), for all w \u2208 WIEM(I \u222a (f, af\n\u2032)), there exists an element X \u2208 candPgm(w, I \u222a (f, af \u2032)) s.t. {h \u2208 \u0398 \u222a\u2126 \u222a {f} | w |= af \u2032\u2032(h)} \u2286 X.\nNext, we investigate the role that the set candPgm plays in showing the necessary and sufficient requirement for satisfying Inclusion, Consistency Preservation, and Relevance all at once.\nLemma 2. Given program I and input (f, af \u2032), operator \u2022 satisfies Inclusion, Consistency Preservation, and Relevance iff for I \u2022 (f, af \u2032) = (\u03a0EM, \u03a0AM, af\n\u2032\u2032), for all w \u2208 WIEM(I \u222a (f, af\n\u2032)) we have {h \u2208 \u0398 \u222a \u2126 \u222a {f} | w |= af \u2032\u2032(h)} \u2208 candPgm(w, I \u222a (f, af \u2032)).\nThe last of the intermediate results shows that if there is a consistent program where two inputs cause inconsistencies to arise in the same way, then for each world the set of candidate replacement programs (minus the added AM formula) is the same. This result will be used as a support of the satisfaction of the first Uniformity postulate.\nLemma 3. Let I = (\u03a0EM, \u03a0AM, af ) be a consistent program, (f1, af \u2032 1), (f2, af \u2032 2) be two inputs, and Ii = (\u03a0EM, \u03a0AM \u222a {fi}, af \u2032 i). If W I EM(I1) = W I EM(I2), then for all w \u2208 WIEM(I1) and all X \u2286 \u03a0AM(w) we have that:\n1. If {x | x \u2208 X \u222a {f1}, w |= af \u2032 1(x)} is inconsistent \u21d4 {x | x \u2208 X \u222a {f2}, w |=\naf \u20322(x)} is inconsistent, then {X \\ {f1} | X \u2208 candPgm(w, I1)} = {X \\ {f2} | X \u2208 candPgm(w, I2)}.\n2. If {X \\ {f1} | X \u2208 candPgm(w, I1)} = {X \\ {f2} | X \u2208 candPgm(w, I2)} then {x | x \u2208 X\u222a{f1}, w |= af \u2032 1(x)} is inconsistent \u21d4 {x | x \u2208 X\u222a{f2}, w |=\naf \u20322(x)} is inconsistent.\nWe now have the necessary tools to present the construction of our nonprioritized belief revision operator.\nConstruction. Before introducing the construction, we define some preliminary notation. Let \u03a6 : WEM \u2192 2 [\u0398]\u222a[\u2126]. For each h there is a formula in \u03a0AM \u222a {f}, where f is part of the input. Given these elements, we define:\nnewFor(h, \u03a6, I, (f, af \u2032)) = af \u2032(h) \u2227 \u2227\nw\u2208WI EM (I\u222a(f,af \u2032)) | h/\u2208\u03a6(w)\n\u00acfor(wi)\nThe following definition then characterizes the class of operators called AFO (annotation function-based operators).\nDefinition 12 (AF-based Operators). A belief revision operator \u2022 is an \u201cannotation function-based\u201d (or af-based) operator (\u2022 \u2208 AFO) iff given program I = (\u03a0EM, \u03a0AM, af ) and input (f, af\n\u2032), the revision is defined as I \u2022 (f, af \u2032) = (\u03a0EM, \u03a0AM \u222a {f}, af \u2032\u2032), where:\n\u2200h, af \u2032\u2032(h) = newFor(h, \u03a6, I, (f, af \u2032))\nwhere \u2200w \u2208 WEM, \u03a6(w) \u2208 CandPgmaf(w, I \u222a (f, af \u2032)).\nAs the main result of the paper, we now show that satisfying a key set of postulates is a necessary and sufficient condition for membership in AFO.\nTheorem 1 (Representation Theorem). An operator \u2022 belongs to class AFO iff it satisfies Inclusion, Vacuity, Consistency Preservation, Weak Success, Relevance, and Uniformity 1.\nProof. (Sketch) (If) By the fact that formulas associated with worlds in the set WIEM(I\u222a(f, af\n\u2032)) are considered in the change of the annotation function, Vacuity and Weak Success follow trivially. Further, Lemma 2 shows that Inclusion, Consistency Preservation, and Relevance are satisfied while Lemma 3 shows that Uniformity 1 is satisfied.\n(Only-If) Suppose BWOC that an operator \u2022 satisfies all postulates and \u2022 /\u2208 AFO. Then, one of four conditions must hold: (i) it does not satisfy Lemma 2 or (ii) it does not satisfy Lemma 3. However, by those previous arguments, if it satisfies all postulates, these arguments must be true as well \u2013 hence a contradiction."}, {"heading": "6 Conclusions", "text": "We have proposed an extension of the PreDeLP language that allows sentences to be annotated with probabilistic events; such events are connected to a probabilistic model, allowing a clear separation of interests between certain and uncertain knowledge. After presenting the language, we focused on characterizing belief revision operations over P-PreDeLP KBs. We presented a set of postulates inspired in the ones presented for non-prioritized revision of classical belief bases, and then proceeded to study a construction based on these postulates and prove that the two characterizations are equivalent.\nAs future work, we plan to study other kinds of operators, such as more general ones that allow the modification of the EM, as well as others that operate at different levels of granularity. Finally, we are studying the application of PPreDeLP to real-world problems in cyber security and cyber warfare domains.\nAcknowledgments. The authors are partially supported by UK EPSRC grant EP/J008346/1 (\u201cPrOQAW\u201d), ERC grant 246858 (\u201cDIADEM\u201d), ARO project 2GDATXR042, DARPA project R.0004972.001, Consejo Nacional de Investigaciones Cient\u0301\u0131ficas y Te\u0301cnicas (CONICET) and Universidad Nacional del Sur (Argentina).\nThe opinions in this paper are those of the authors and do not necessarily reflect the opinions of the funders, the U.S. Military Academy, or the U.S. Army."}], "references": [{"title": "On the use of presumptions in structured defeasible reasoning", "author": ["M.V. Martinez", "A.J. Gar\u0107\u0131a", "G.R. Simari"], "venue": "Proc. of COMMA.", "citeRegEx": "1", "shortCiteRegEx": null, "year": 2012}, {"title": "Semi-revision", "author": ["S. Hansson"], "venue": "J. of App. Non-Classical Logics 7(1-2)", "citeRegEx": "2", "shortCiteRegEx": null, "year": 1997}, {"title": "On the logic of theory change: Partial meet contraction and revision functions", "author": ["C.E. Alchourr\u00f3n", "P. G\u00e4rdenfors", "D. Makinson"], "venue": "J. Sym. Log. 50(2)", "citeRegEx": "3", "shortCiteRegEx": null, "year": 1985}, {"title": "Knowledge in flux: modeling the dynamics of epistemic states", "author": ["P. Gardenfors"], "venue": "MIT Press, Cambridge, Mass.", "citeRegEx": "4", "shortCiteRegEx": null, "year": 1988}, {"title": "Kernel contraction", "author": ["S.O. Hansson"], "venue": "J. Symb. Log. 59(3)", "citeRegEx": "5", "shortCiteRegEx": null, "year": 1994}, {"title": "A truth maintenance system", "author": ["J. Doyle"], "venue": "Artif. Intell. 12(3)", "citeRegEx": "6", "shortCiteRegEx": null, "year": 1979}, {"title": "Explanations, belief revision and defeasible reasoning", "author": ["M.A. Falappa", "G. Kern-Isberner", "G.R. Simari"], "venue": "Artif. Intell. 141(1/2)", "citeRegEx": "7", "shortCiteRegEx": null, "year": 2002}, {"title": "Probabilistic argumentation frameworks", "author": ["H. Li", "N. Oren", "T.J. Norman"], "venue": "Proc. of TAFA.", "citeRegEx": "8", "shortCiteRegEx": null, "year": 2011}, {"title": "A probabilistic semantics for abstract argumentation", "author": ["M. Thimm"], "venue": "Proc. of ECAI 2012.", "citeRegEx": "9", "shortCiteRegEx": null, "year": 2012}, {"title": "Some foundations for probabilistic abstract argumentation", "author": ["A. Hunter"], "venue": "Proc. of COMMA 2012.", "citeRegEx": "10", "shortCiteRegEx": null, "year": 2012}, {"title": "On the complexity of probabilistic abstract argumentation", "author": ["B. Fazzinga", "S. Flesca", "F. Parisi"], "venue": "Proc. of IJCAI 2013.", "citeRegEx": "11", "shortCiteRegEx": null, "year": 2013}, {"title": "Probabilistic argumentation systems", "author": ["R. Haenni", "J. Kohlas", "N. Lehmann"], "venue": "Springer", "citeRegEx": "12", "shortCiteRegEx": null, "year": 1999}, {"title": "A logic programming framework for possibilistic argumentation with vague knowledge", "author": ["C.I. Ches\u00f1evar", "G.R. Simari", "T. Alsinet", "L. Godo"], "venue": "Proc. of UAI 2004.", "citeRegEx": "13", "shortCiteRegEx": null, "year": 2004}, {"title": "A probabilistic approach to modelling uncertain logical arguments", "author": ["A. Hunter"], "venue": "Int. J. Approx. Reasoning 54(1)", "citeRegEx": "14", "shortCiteRegEx": null, "year": 2013}, {"title": "Query answering under probabilistic uncertainty in Datalog+/\u2013 ontologies", "author": ["G. Gottlob", "T. Lukasiewicz", "M.V. Martinez", "G.I. Simari"], "venue": "AMAI", "citeRegEx": "15", "shortCiteRegEx": null, "year": 2013}, {"title": "Probabilistic logic", "author": ["N.J. Nilsson"], "venue": "Artif. Intell. 28(1)", "citeRegEx": "16", "shortCiteRegEx": null, "year": 1986}, {"title": "Computing most probable worlds of action probabilistic logic programs: scalable estimation for 1030,000 worlds", "author": ["S. Khuller", "M.V. Martinez", "D.S. Nau", "A. Sliva", "G.I. Simari", "V.S. Subrahmanian"], "venue": "AMAI 51(2-4)", "citeRegEx": "17", "shortCiteRegEx": null, "year": 2007}, {"title": "Focused most probable world computations in probabilistic logic programs", "author": ["G.I. Simari", "M.V. Martinez", "A. Sliva", "V.S. Subrahmanian"], "venue": "AMAI 64(2-3)", "citeRegEx": "18", "shortCiteRegEx": null, "year": 2012}, {"title": "Argumentation in Artificial Intelligence", "author": ["I. Rahwan", "G.R. Simari"], "venue": "Springer", "citeRegEx": "19", "shortCiteRegEx": null, "year": 2009}, {"title": "Defeasible logic programming: An argumentative approach", "author": ["A.J. Gar\u0107\u0131a", "G.R. Simari"], "venue": "TPLP 4(1-2)", "citeRegEx": "20", "shortCiteRegEx": null, "year": 2004}, {"title": "Foundations of Logic Programming, 2nd Edition", "author": ["J.W. Lloyd"], "venue": "Springer", "citeRegEx": "21", "shortCiteRegEx": null, "year": 1987}, {"title": "A mathematical treatment of defeasible reasoning and its implementation", "author": ["G.R. Simari", "R.P. Loui"], "venue": "Artif. Intell. 53(2-3)", "citeRegEx": "22", "shortCiteRegEx": null, "year": 1992}, {"title": "Computing Generalized Specificity", "author": ["F. Stolzenburg", "A. Gar\u0107\u0131a", "C.I. Ches\u00f1evar", "G.R. Simari"], "venue": "Journal of Non-Classical Logics 13(1)", "citeRegEx": "23", "shortCiteRegEx": null, "year": 2003}, {"title": "On the acceptability of arguments and its fundamental role in nonmonotonic reasoning, logic programming and n-person games", "author": ["P.M. Dung"], "venue": "Artif. Intell. 77", "citeRegEx": "24", "shortCiteRegEx": null, "year": 1995}, {"title": "Prioritized and nonprioritized multiple change on belief bases", "author": ["M.A. Falappa", "G. Kern-Isberner", "M. Reis", "G.R. Simari"], "venue": "J. Philosophical Logic 41(1)", "citeRegEx": "25", "shortCiteRegEx": null, "year": 2012}], "referenceMentions": [{"referenceID": 0, "context": "In this paper, we begin by proposing a framework that addresses items (i)\u2013 (iii) by extending Presumptive DeLP [1] (PreDeLP, for short) with probabilistic models in order to model uncertainty in the application domain; the resulting framework is a general-purpose probabilistic argumentation language that we will refer to as Probabilistic PreDeLP(P-PreDeLP, for short).", "startOffset": 111, "endOffset": 114}, {"referenceID": 1, "context": "We propose a set of rationality postulates characterizing how such operations should behave \u2013 these postulates are based on the well-known postulates proposed in [2] for non-prioritized belief revision in classical knowledge bases.", "startOffset": 162, "endOffset": 165}, {"referenceID": 2, "context": "Traditionally, such knowledge bases can be either belief sets (sets of formulas closed under consequence) [3, 4] or belief bases [5, 2] (which are not closed); since our end goal is to apply the results we obtain to real-world domains, here we focus on belief bases.", "startOffset": 106, "endOffset": 112}, {"referenceID": 3, "context": "Traditionally, such knowledge bases can be either belief sets (sets of formulas closed under consequence) [3, 4] or belief bases [5, 2] (which are not closed); since our end goal is to apply the results we obtain to real-world domains, here we focus on belief bases.", "startOffset": 106, "endOffset": 112}, {"referenceID": 4, "context": "Traditionally, such knowledge bases can be either belief sets (sets of formulas closed under consequence) [3, 4] or belief bases [5, 2] (which are not closed); since our end goal is to apply the results we obtain to real-world domains, here we focus on belief bases.", "startOffset": 129, "endOffset": 135}, {"referenceID": 1, "context": "Traditionally, such knowledge bases can be either belief sets (sets of formulas closed under consequence) [3, 4] or belief bases [5, 2] (which are not closed); since our end goal is to apply the results we obtain to real-world domains, here we focus on belief bases.", "startOffset": 129, "endOffset": 135}, {"referenceID": 5, "context": "The connection between belief revision and argumentation was first studied in [6]; since then, the work that is most closely related to our approach is the development of the explanation-based operators of [7].", "startOffset": 78, "endOffset": 81}, {"referenceID": 6, "context": "The connection between belief revision and argumentation was first studied in [6]; since then, the work that is most closely related to our approach is the development of the explanation-based operators of [7].", "startOffset": 206, "endOffset": 209}, {"referenceID": 7, "context": "The study of argumentation systems together with probabilistic reasoning has recently received a lot attention, though a significant part has been in the combination between the two has been in the form of probabilistic abstract argumentation [8\u201311].", "startOffset": 243, "endOffset": 249}, {"referenceID": 8, "context": "The study of argumentation systems together with probabilistic reasoning has recently received a lot attention, though a significant part has been in the combination between the two has been in the form of probabilistic abstract argumentation [8\u201311].", "startOffset": 243, "endOffset": 249}, {"referenceID": 9, "context": "The study of argumentation systems together with probabilistic reasoning has recently received a lot attention, though a significant part has been in the combination between the two has been in the form of probabilistic abstract argumentation [8\u201311].", "startOffset": 243, "endOffset": 249}, {"referenceID": 10, "context": "The study of argumentation systems together with probabilistic reasoning has recently received a lot attention, though a significant part has been in the combination between the two has been in the form of probabilistic abstract argumentation [8\u201311].", "startOffset": 243, "endOffset": 249}, {"referenceID": 11, "context": "There have, however, been several approaches that combine structured argumentation with models for reasoning under uncertainty; the first of such approaches to be proposed was [12], and several others followed, such as the possibilistic approach of [13], and the probabilistic logic-based approach of [14].", "startOffset": 176, "endOffset": 180}, {"referenceID": 12, "context": "There have, however, been several approaches that combine structured argumentation with models for reasoning under uncertainty; the first of such approaches to be proposed was [12], and several others followed, such as the possibilistic approach of [13], and the probabilistic logic-based approach of [14].", "startOffset": 249, "endOffset": 253}, {"referenceID": 13, "context": "There have, however, been several approaches that combine structured argumentation with models for reasoning under uncertainty; the first of such approaches to be proposed was [12], and several others followed, such as the possibilistic approach of [13], and the probabilistic logic-based approach of [14].", "startOffset": 301, "endOffset": 305}, {"referenceID": 14, "context": "This approach is based on a similar one developed for ontological languages in the Semantic Web (see [15], and references within).", "startOffset": 101, "endOffset": 105}, {"referenceID": 15, "context": "The EM or environmental model is largely based on the probabilistic logic of [16], which we now briefly review.", "startOffset": 77, "endOffset": 81}, {"referenceID": 0, "context": "Let f be a formula over PEM, V, and C, p \u2208 [0, 1], and \u01eb \u2208 [0,min(p, 1\u2212 p)].", "startOffset": 43, "endOffset": 49}, {"referenceID": 15, "context": "In [16], it is shown that \u01eb = u\u2212l 2 and p = l + \u01eb is the solution to the maximum entailment problem.", "startOffset": 3, "endOffset": 7}, {"referenceID": 16, "context": "[17, 18]) that have been shown to provide highly accurate approximations with a reduced-size linear program.", "startOffset": 0, "endOffset": 8}, {"referenceID": 17, "context": "[17, 18]) that have been shown to provide highly accurate approximations with a reduced-size linear program.", "startOffset": 0, "endOffset": 8}, {"referenceID": 18, "context": "For the analytical model (AM), we choose a structured argumentation framework [19] due to several characteristics that make such frameworks highly applicable to many domains.", "startOffset": 78, "endOffset": 82}, {"referenceID": 0, "context": "Defeasible Logic Programming with Presumptions (PreDeLP) [1] is a formalism combining logic programming with defeasible argumentation; it arises as an extension of classical DeLP [20] with the possibility of having presumptions, as described below \u2013 since this capability is useful in many applications, we adopt this extended version in this paper.", "startOffset": 57, "endOffset": 60}, {"referenceID": 19, "context": "Defeasible Logic Programming with Presumptions (PreDeLP) [1] is a formalism combining logic programming with defeasible argumentation; it arises as an extension of classical DeLP [20] with the possibility of having presumptions, as described below \u2013 since this capability is useful in many applications, we adopt this extended version in this paper.", "startOffset": 179, "endOffset": 183}, {"referenceID": 19, "context": "In this section, we briefly recall the basics of PreDeLP; we refer the reader to [20, 1] for the complete presentation.", "startOffset": 81, "endOffset": 88}, {"referenceID": 0, "context": "In this section, we briefly recall the basics of PreDeLP; we refer the reader to [20, 1] for the complete presentation.", "startOffset": 81, "endOffset": 88}, {"referenceID": 20, "context": "Given a query in the form of a ground atom, the goal is to derive arguments for and against it\u2019s validity \u2013 derivation follows the same mechanism of logic programming [21].", "startOffset": 167, "endOffset": 171}, {"referenceID": 21, "context": "Our definition differs slightly from that of [22], where DeLP is introduced, as we include strict rules and facts as part of arguments \u2013 the reason for this will become clear in Section 4.", "startOffset": 45, "endOffset": 49}, {"referenceID": 22, "context": "An important characteristic of PreDeLP is that the argument comparison criterion is modular, and thus the most appropriate criterion for the domain that is being represented can be selected; the default criterion used in classical defeasible logic programming (from which PreDeLP is derived) is generalized specificity [23], though an extension of this criterion is required for arguments using presumptions [1].", "startOffset": 319, "endOffset": 323}, {"referenceID": 0, "context": "An important characteristic of PreDeLP is that the argument comparison criterion is modular, and thus the most appropriate criterion for the domain that is being represented can be selected; the default criterion used in classical defeasible logic programming (from which PreDeLP is derived) is generalized specificity [23], though an extension of this criterion is required for arguments using presumptions [1].", "startOffset": 408, "endOffset": 411}, {"referenceID": 0, "context": "Definition 5 ([1]).", "startOffset": 14, "endOffset": 17}, {"referenceID": 19, "context": "To avoid undesirable sequences, which may represent circular argumentation lines, in DeLP an argumentation line is acceptable if it satisfies certain constraints (see [20]).", "startOffset": 167, "endOffset": 171}, {"referenceID": 23, "context": "(Warranted arguments correspond to those in the grounded extension of a Dung argumentation system [24].", "startOffset": 98, "endOffset": 102}, {"referenceID": 1, "context": "We now analyze the rationality postulates for non-prioritized revision of belief bases first introduced in [2] and later generalized in [25], in the context of PPreDeLP programs.", "startOffset": 107, "endOffset": 110}, {"referenceID": 24, "context": "We now analyze the rationality postulates for non-prioritized revision of belief bases first introduced in [2] and later generalized in [25], in the context of PPreDeLP programs.", "startOffset": 136, "endOffset": 140}], "year": 2014, "abstractText": "In real-world applications, knowledge bases consisting of all the information at hand for a specific domain, along with the current state of affairs, are bound to contain contradictory data coming from different sources, as well as data with varying degrees of uncertainty attached. Likewise, an important aspect of the effort associated with maintaining knowledge bases is deciding what information is no longer useful; pieces of information (such as intelligence reports) may be outdated, may come from sources that have recently been discovered to be of low quality, or abundant evidence may be available that contradicts them. In this paper, we propose a probabilistic structured argumentation framework that arises from the extension of Presumptive Defeasible Logic Programming (PreDeLP) with probabilistic models, and argue that this formalism is capable of addressing the basic issues of handling contradictory and uncertain data. Then, to address the last issue, we focus on the study of non-prioritized belief revision operations over probabilistic PreDeLP programs. We propose a set of rationality postulates \u2013 based on well-known ones developed for classical knowledge bases \u2013 that characterize how such operations should behave, and study a class of operators along with theoretical relationships with the proposed postulates, including a representation theorem stating the equivalence between this class and the class of operators characterized by the postulates.", "creator": "dvips(k) 5.991 Copyright 2011 Radical Eye Software"}}}