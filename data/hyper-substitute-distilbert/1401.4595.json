{"id": "1401.4595", "review": {"conference": "arxiv", "VERSION": "v1", "DATE_OF_SUBMISSION": "18-Jan-2014", "title": "Robust Local Search for Solving RCPSP/max with Durational Uncertainty", "abstract": "scheduling problems in enterprises, developing industrial project management have similarly appeared modeled using the framework of globally constrained fast closure problems with minimum anticipated maximum time varying ( s / max ). - because the importance defining these problems, generating advanced solution dynamics for rcpsp / max problems is readily topic from extensive research. therefore, all existing methods for solving ic / max assume that durations of activities are known with regard, an assumption that does not pose in real world administration problems where unexpected policy consequences such as manpower availability, weather changes, etc. lead to confusion or advances implementing critical procedure activities. thus, releasing summary paper, specific focus is on emerging completely scalable method supporting efficiently rcpsp / max problems with great uncertainty. to which end, we introduce the robust local search method consisting involving three functional ideas : ( ; ) introducing and studying the applications of two interval rule servers utilizing both compute length times dependent inputs with 1 percent finite realizations of residual durational uncertainty ; ( b ) proposing successful search for robust guarantees of restricted execution facility using on parallel field approximations ; and ( c ) identifying robust procedural design mechanism to efficiently yield explicit execution procedures that proved correct against observed conditions. firstly, we also extend enhancements to local tools that exploit temporal dependencies based groups. our experimental analyses illustrate producing simple local search methods able to exploits robust execution behavior efficiently.", "histories": [["v1", "Sat, 18 Jan 2014 21:04:55 GMT  (1179kb)", "http://arxiv.org/abs/1401.4595v1", null]], "reviews": [], "SUBJECTS": "cs.AI", "authors": ["na fu", "hoong chuin lau", "pradeep r varakantham", "fei xiao"], "accepted": false, "id": "1401.4595"}, "pdf": {"name": "1401.4595.pdf", "metadata": {"source": "CRF", "title": "Robust Local Search for Solving RCPSP/max with Durational Uncertainty", "authors": ["Na Fu", "Hoong Chuin Lau", "Pradeep Varakantham", "Fei Xiao"], "emails": ["na.fu.2007@phdis.smu.edu.sg", "hclau@smu.edu.sg", "pradeepv@smu.edu.sg", "feixiao@gmail.com"], "sections": [{"heading": "1. Introduction", "text": "Research in scheduling has typically considered problems with deterministic durations. In real-world scheduling problems, unexpected external events such as manpower availability, weather changes, etc. lead to uncertainty about durations of activities. There has been a growing interest to account for such data uncertainty (Herroelen & Leus, 2005; Beck & Wilson, 2007; Rodr\u0301\u0131guez, Vela, Puente, & Herna\u0301ndez-Arauzo, 2009) while providing optimized schedules. This paper also focuses on this important issue of durational uncertainty in scheduling problems. More specifically, we consider scheduling problems where there are complex resource constraints and temporal dependencies between activities.\nc\u00a92012 AI Access Foundation. All rights reserved.\nThere are broadly two approaches for tackling scheduling problems with durational uncertainty. One is to adopt a hybrid of proactive and reactive methods, e.g., the work of Vonder, Demeulemeester, and Herroelen (2007), where an initial baseline schedule is computed offline, which is then modified (if required) during execution reactively based on the occurrence of external events. The second approach, e.g., the paper by Mohring and Stork (2000), is to design schedule policies that provide online decision rules such that at time t, the policy decides which task(s) may start and which resource(s) to assign. In this paper, we adopt the latter approach and focus on the computation of a robust schedule policy.\nFrom the computational perspective, stochasticity adds a great deal of complexity to the underlying deterministic scheduling problem. For example, in the infinite-resource project scheduling problem where processing times have two possible discrete values, the problem of computing the expected makespan (or any point on the cumulative distribution of the optimal makespan), is #P-hard (Hagstrom, 1988; Mo\u0308hring, 2001). It has also been shown that for the scheduling problem 1|stoch pj ; dj = d|E[ \u2211 wjUj ], the problem of computing a policy (i.e., execution strategy) maximizing the probability that some job completes exactly at the deadline is PSPACE-hard (Dean, Goemans, & Vondra\u0301k, 2004). Daniels and Carrillo (1997) consider a one-machine scheduling problem with probabilistic durations, with an objective to capture the likelihood that a schedule yields actual performance no worse than a given target level. This has been shown to be NP-hard even though the underlying deterministic problem can be solved in polynomial time.\nThe concrete problem of interest in this paper is the Resource Constrained Project Scheduling Problem with minimum and maximum time lags (abbrev. RCPSP/max), which is of great importance in manufacturing, logistics and project management. Though these problems have been shown to be NP-Hard (Bartusch, Mohring, & Radermacher, 1988), local search based techniques (Demeulemeester & Herroelen, 2002) have achieved great success in solving these problems. Taking a cue from this and the recent advancements in robust optimization, we propose a robust local search method for solving the RCPSP/max problem under durational uncertainty with a risk management perspective. More precisely, we (a) employ concepts from robust optimization to compute the robust makespan with proven success probability (or risk of failure) for an execution strategy; and (b) then use local search methods for computing an execution strategy that seeks to minimize this robust makespan.\nA recent approach (Beck & Wilson, 2007) provides techniques to compute the robust baseline schedule from a risk management perspective, where durations of activities are modeled as random variables. Given a value 0 < \u03b1 \u2264 1, they were interested to compute a schedule with minimal (probabilistic) makespan where the probability of successful execution is at least 1 \u2212 \u03b1 over all realizations of the durational uncertainty. The main contribution there was to derive a lower bound for the \u03b1-makespan of a given schedule by solving a deterministic problem. They considered the Job-shop Scheduling Problem (JSP) that represents a special case of RCPSP/max (which is the problem of interest in this paper).\nUnlike in JSPs, there are complex resource constraints and activity dependencies in RCPSP/max problems with durational uncertainty. To account for these, we compute an execution strategy (also known commonly as schedule policy) called Partial Order Schedule\n(POS) instead of a schedule. We combine techniques from robust optimization with classical local search to compute a POS that minimizes the robust makespan. The robust makespan is a value for which the probability of realized makespan for any schedule (derived from POS) does not exceed it is greater than (1\u2212 \u03b5), over all realizations of uncertainty. Thus, we compute an upper bound on makespan values as opposed to lower bound computation in the work of Beck and Wilson (2007).\nMore specifically, we make three key contributions in this paper. Firstly, we introduce two decision rule approximations to define expressions for start times of activities based on random variables used to represent the durational uncertainties: (a) Segregated Linear Approximation(SLA) and (b) Generalized Non-Linear Approximation (GNLA). Secondly, we derive expressions for the upper bound on robust makespan by employing the one sided Chebyshev\u2019s inequality on the decision rule approximations above. Finally, we perform local search for an execution strategy using the robust makespan upper bound. We also provide enhancements that consider feedback about robustness of execution strategies to improve the performance of local search.\nIn order to demonstrate the effectiveness of our methods, we evaluate the performance on benchmark problem sets of RCPSP/max and Job-shop Scheduling Problems (JSPs) with durational uncertainty. Furthermore, we make an in house comparison amongst various enhancements developed in this paper. Finally, due to the absence of competing algorithms for solving RCPSP/max problems and to provide an indication of the performance provided by robust local search, we compare against the existing best solver for JSPs with durational uncertainty.\nIn the next section, we present a brief background of the models and solution concepts referred to in this paper. We then present the decision rule approximations in Section 3 and the computation of robust makespan upper bound in Section 4. The detailed description of robust local search and its enhancements are provided in Section 5 and Section 6. Finally, the experimental setup and results are provided in Section 7."}, {"heading": "2. Preliminaries", "text": "In this section, we briefly describe the notations along with the scheduling models and robust optimization concepts of relevance to this paper."}, {"heading": "2.1 Definitions and Notations", "text": "As given by Ben-Tal and Nemirovski (2002), we also classify the variables in a stochastic optimization problem into 2 types: Adjustable and Non-Adjustable variables.\nDefinition 1. Non-Adjustable variables are a priori decisions that must be made before the actual realization of the uncertainty.\nDefinition 2. Adjustable variables (also known as recourse variables) are \u2019wait-and-see\u2019 variables that can adjust themselves when part of the uncertain data become known.\nFor example, in a scheduling problem such as RCPSP with uncertain task durations, the non-adjustable variables will represent the execution policy, e.g., the POS proposed by Policella, Smith, Cesta, and Oddi (2004), that need to be constructed a priori, while the\nadjustable variables are associated with the actual start times of the tasks, which will be set with respect to the execution policy and dynamic realizations of uncertainty.\nA random variable will be denoted by x\u0303 and bold face lower case letters such as x represent vectors."}, {"heading": "2.2 RCPSP/max", "text": "We now describe the deterministic RCPSP/max scheduling problem along with the extension to handle durational uncertainty. We also explain the execution policy for an uncertain duration extension of the RCPSP/max."}, {"heading": "2.2.1 Deterministic RCPSP/max", "text": "The RCPSP/max problem (Bartusch et al., 1988) consists of N activities {a1, a2..., aN}, where each activity aj (j = 1, ...N) is to be executed for a certain amount of time units without preemption. Each activity aj has a fixed duration or processing time dj , which is assumed to be a non-negative real number or non-negative integer number. In addition, dummy activities a0 and aN+1 with d0 = dN+1 = 0 are introduced to represent the beginning and the completion of the project, respectively.\nA start time schedule ss is an assignment of start times to all activities a1, a2..., aN , i.e. a vector ss = (st(a1), st(a2), ...st(aN )) where st(ai) represents the start time of activity ai and st(a0) is assumed to be 0. Let et(ai) be the end time of activity ai. Since durations are deterministic and preemption is not allowed, we then have\nst(ai) + di = et(ai). (1)\nAnd the project makespan which is also the start time of the final dummy activity st(aN+1) equals\nst(aN+1) = maxi=1,...Net(ai). (2)\nSchedules are subject to two kinds of constraints, temporal constraints and resource constraints. Temporal constraints restrict the time lags between activities. A minimum time lag Tminij between the start time of two different activities ai and aj says that\nst(aj)\u2212 st(ai) \u2265 Tminij (3) Specially, Tminij = 0 means that activity aj cannot be started before activity ai begins. A maximum time lag Tmaxij between the start time of two different activities ai and aj says that st(aj)\u2212 st(ai) \u2264 Tmaxij (4) Tmaxij = 0 means that activity aj cannot be started after activity ai begins.\nIn this definition, time lags connect start times of two related activities, known as start-to-start time lags. start-to-end, end-to-end, end-to-start time lags can be easily transformed to the general start-to-start time lags for the deterministic case as given by Bartusch et al. (1988). A schedule ss = (st(a1), st(a2), ...st(aN )) is time feasible, if all the time lag constraints are satisfied at the start times st(ai) (i = 1, ...N).\nA resource unit is reusable and available for another activity once it is no longer used by the current activity. Each type of resource has a limited capacity, Ck (k = 1, 2...,K)\nunits. Each activity ai requires rik units of resource of type k where k = 1, 2...,K. Let A(t) = {i \u2208 {1, 2...N}|st(ai) \u2264 t \u2264 et(ai)} be the set of activities which are being processed at time instant t. A schedule is resource feasible if at each time instant t, the total demand for a resource k does not exceed its capacity Ck, i.e.\n\u2211\ni\u2208A(t) rik \u2264 Ck. (5)\nA schedule ss is called feasible if it is both time and resource feasible. The objective of the deterministic RCPSP/max scheduling problem is to find a feasible schedule so that the project makespan is minimized.\nExample 1. In Figure 1, we show a simple example of a deterministic RCPSP problem which is a special case of RCPSP/max with only precedence constraints (rather than arbitrary time lags) between activities for expository purposes. Each circle indicates an activity with the number inside the circle representing the activity ID. The two numbers on top of each activity represent the duration and the number of units of the resource required by the activity. In this example, there are 9 activities and one type of resource, with the capacity of the resource limited to 10. It should be noted that the activities 0 and 10 are dummy activities introduced to have a source and sink in the dependency graph. Arrows between activities represent temporal dependencies. A feasible schedule with makespan of 13 is represented in Figure 2."}, {"heading": "2.2.2 RCPSP/max with Durational Uncertainty and Robust Makespan", "text": "In this paper, we consider RCPSP/max problems with durational uncertainty. The duration of an activity is specified as a sum of its mean value and its deviation: d\u0303i = d0i + z\u0303i, where d 0 i is the mean of d\u0303i and z\u0303i is the perturbation part with an expected value of 0 and standard deviation \u03c3. It should be noted that irrespective of its distribution type, we can always represent d\u0303i as d\u0303i = d0i + z\u0303i where d 0 i is the mean and z\u0303i is the perturbation part with E(z\u0303i) = 0. In addition, we also assume that these random variables, {z\u0303i}, corresponding to durational uncertainty are independent of each other.\nSimilar to the deterministic RCPSP/max, the start-to-start constraints are still deterministic. However, unlike the deterministic case, other types of constraints (end-to-start etc.) cannot be converted into deterministic start-to-start constraints . Instead the equivalent start-to-start constraint is a stochastic one as shown in the following expressions for an end-to-start constraint. It should be noted that even though the converted constraints are stochastic, our techniques will still be applicable (with minor modifications) to all types of time lag constraints. Our robust local search techniques depend on the computation of maximum and sum of random variables and even with stochastic time lag constraints that remains the case. In this paper, for purposes of exposition, we present our techniques assuming the temporal dependencies are provided as start-to-start constraints.\nst(aj)\u2212 et(ai) \u2264 Tmaxij st(aj)\u2212 (st(ai) + d\u0303i) \u2264 Tmaxij\nst(aj)\u2212 st(ai) \u2264 Tmaxij + d\u0303i In the deterministic setting, start time schedules can be computed and values of makespan\ncan be used to evaluate the performance of the schedule. However, when durational uncertainty is involved, the project makespan becomes a random variable and the schedule is replaced by an execution strategy. In the following sections, we introduce the Partial Order Schedule (POS) (Policella et al., 2004), which serves as an execution strategy of the scheduling project.\nGiven a level of risk 0 < \u03b5 \u2264 1, the goal of our problem is to find such a strategy with a minimum value (across all strategies) of the robust makespan. We define the robust makespan as a makespan value where the probability that any feasible schedule (i.e. an assignment of start times to activities) instantiated from the strategy can be completed before robust makespan is at least 1\u2212 \u03b5."}, {"heading": "2.2.3 Partial Order Schedule", "text": "A Partial Order Schedule (POS) was first proposed by Policella et al. (2004). It is defined as a set of activities, which are partially ordered such that any schedule with total activity order that is consistent with the partial order is resource and time feasible. Mathematically, a POS can be represented by a graph where a node represents an activity and the edges represent the precedence constraints between the activities. Within a POS, each activity retains a set of feasible start times, which provide the flexibility to respond to unexpected disruptions. A POS can be constructed from a given RCPSP instance via a chaining algorithm (where one such algorithm is described below).\nExample 2. Figure 3 provides a POS for the problem instance introduced in Example 1. There are 10 units of the resource and that is shown on the left most side of the figure. Each unit represents a chain. An activity can require multiple resource units and hence is shown on multiple resource units. For instance, activity 6 is shown on resource units 4, 7 and 8. A solid arrow between activities represents a temporal dependency provided in the original problem. Solid arrow between activities 1 and 2 is one such example. A dotted arrow between activities represents a temporal dependency that is introduced since both activities have to be executed on the same resource unit. It is added to remove resource conflict. An example for this is the dependency introduced between activity 2 and activity 6. For explanatory purposes we only consider one resource type in this example, however in the most general case, there exists multiple resource types and a dependency diagram for every resource type."}, {"heading": "2.2.4 Chaining Algorithm", "text": "Chaining is a procedure of dispatching activities to different resource units (henceforth referred to as chains) based on temporal and resource feasibility. During the chaining process, each activity can be allocated to one or more resource chains based on the number of resource requirement of the activity. During the chaining process, once an activity is scheduled to be executed on a resource unit, an additional edge (indicating precedence\nrelationship) is added between the last activity of the selected chain and this activity so as to eliminate all possible resource conflicts.\nIn the following, we describe the basic chaining algorithm proposed by Policella et al. (2004). In this algorithm, a feasible schedule is first obtained using a simple greedy heuristic. Consequently, the POS is constructed through a chaining method as follows: First, the set of activities are sorted according to their start times given in the feasible solution; Then, all activities are allocated to different chains in that order, where each chain corresponds to a unit of a certain type of resource. A chain is called available for an activity if the end time of the last activity allocated on this chain is no greater than the start time of the activity in the feasible schedule. Once an activity is allocated on a chain, a precedence constraint between this activity and the last activity of the chain is posted. For those activities that require more than one unit of one or more types of resources, they will be allocated to a number of chains with the number equal to the overall number of resource units required by the activity.\nExample 3. Take Figure 3 for example. Given the schedule of Figure 2 as an input,activities are first sorted according to their starting time and the sequence of activities can be presented as: (7,1,2,8,3,5,4,6,9). The chaining procedure first picks activity 7 and randomly allocates it to five chains to fulfill its resource requirement. The available chains are those belonging to dummy activity 0.Thus, five chains 1 through 5 are created which posts the precedence relationship from the current last activity 0 to activity 7. Activity 7 then becomes the last activity on those chains. Activity 1 is treated in the same way. The available chains for activity 2 are those belonging to activity 1. Activity 2 is then randomly assigned to chain 8 through 10 and an edge between activity 1 and activity 2 indicating precedence relationship is added. This procedure continues until all activities are dispatched to chains that the number equals its resource requirement, and finally the chained POS 3 is yielded. However, because the randomness of the chaining procedure, activity 6 is allocated to chains that belong to three different activities: activity 2, activity 1 and activity 7. This will tie together the execution of three previously unrelated activities: (activity 2, activity 6),(activity 1, activity 6) and (activity 7, activity 6), which would decrease the flexibility of execution.\nTo reduce inter-dependencies between activities as much as possible during the chaining procedure, Policella, Cesta, Oddi, and Smith (2009) developed two heuristics. One direct advantage of such approaches is that synchronization points of a solution can be reduced:\n\u2022 Activities that require more than one resource units are allocated to the same subset of chains. This is achieved by scanning the list of available chains where the last activity in the chain : (a) requires multiple resource units; and (b) was also previously assigned another resource unit allocated to the current activity.\n\u2022 Activities with a precedence constraint defined in the original problem are allocated to the same set of chains. This is implemented by choosing a chain that has a last activity with precedence constraint with the current activity.\nExample 4. Figure 4 provides the POS computed by using the above mentioned chaining algorithm for the RCPSP problem described in Example 1. When allocating activity 6,\nthe available chains are divided into two sets: {chain 10, chain 9} and {chain 8, chain7, chain6}. The first set contains chains for which the last activity (i.e. activity 5) is already ordered in problem definition with respect to activity 6. A chain (for example, chain 10) is randomly chosen from this set with the last activity on it as activity 5. Then, The remaining available chains for activity 6 is redivided into two sets: {chain 9} and {chain 8, chain7, chain6}. The first set contains the chains with activity 5 (i.e. the last activity of the first picked chain) as the last activity and the second set are the remaining. Activity 6 is first allocated to chains belonging to the first subset to satisfy all remaining resource requirements. In this case, the synchronization points caused by activities 1 and 6, activities 7 and 6 being allocated to different chains has disappeared."}, {"heading": "2.3 Job-shop Scheduling Problem (JSP) with Durational Uncertainty", "text": "The classical JSP consists of a set of n jobs and a set of M machines. Each job Ji (i = 1, ...n) consists of a sequence of ni operations denoted as Oij (j = 1, ...ni) which have to be processed in a given order. For convenience, we enumerate all operations of all jobs by Ok, where k = 1, ...N and N = \u2211n j=1 nj . Each operation Ok has a positive duration denoted as dk and must be executed on a dedicated machine denoted as Mk. Once an operation is started it must be executed for its entire duration. No operations that require the same resource can overlap in their execution. Thus, operations can be partitioned into two sets: job sets and resource sets. Job sets referring to operations corresponding to a job and resource sets referring to all operations that require the same resource.\nA solution s is a total ordering of operations on each resource set, which does not conflict with the job ordering. A path of a solution s is a sequence of operations which follows both the job ordering and the ordering on various resource sets of the solution s. The length of a path is equal to the sum of the durations of the operations in the path. The makespan of a solution s make(s) is the length of the longest path. The minimum makespan of a JSP problem is defined to be the minimum value of makespans over all solutions, i.e. mins make(s). Each operation Ok is associated with a start time of st(Ok) and end time of\net(Ok). A schedule is an assignment of starting times st(Ok) (k = 1, ...N) to all operations on the machines. The objective is to find a schedule which optimizes the total makespan (makespan is the completion time of the last operation): maxNk=1et(Ok), which is also the minimum value of the longest path of all solutions. The job shop scheduling problem is a special case of RCPSP in which resources have unary capacity and each activity (i.e. operation) consumes only one resource.\nWe can propagate the same notations from RCPSP/max with durational uncertainty to the JSP with durational uncertainty, i.e. the processing time of each activity (i.e. operation) d\u0303Ok is now modeled as a sum of an expected value d 0 Ok\nand a random part z\u0303Ok : d\u0303Ok = d0Ok + z\u0303Ok . The objective is to find the robust makespan with a given level of risk."}, {"heading": "2.4 Segregated Random Variables", "text": "A primitive random variable z\u0303k is one which has zero mean. Examples of a primitive random variable include U(\u2212a, a) (uniform distribution between constants \u2212a and a) and N(0, \u03c3) (normal distribution with mean 0 and variance \u03c32). As mentioned earlier, we assume that every uncertain distribution is equal to the sum of its nominal value (mean) and its deviation, represented by one (or possibly more) primitive random variable z\u0303. In a straight forward representation, there is only one primitive random variable z\u0303k associated with an uncertain variable. In the recent work by Chen, Sim, Sun, and Zhang (2008), each primitive random variable z\u0303k is represented by 2 segregated random variables z\u0303+k (read z-plus) and z\u0303 \u2212 k (z-minus):\nz\u0303 = z\u0303+ \u2212 z\u0303\u2212 (6) z\u0303+ = max {z\u0303, 0} (7) z\u0303\u2212 = max {\u2212z\u0303, 0} . (8) In the following Table 1, we give examples of the respective values of mean \u00b5p, \u00b5m and\nvariance \u03c3p2, \u03c3m2 for the segregated variables z\u0303+ and z\u0303\u2212.\nThe underlying assumption with the use of segregated random variables is that the mean and variance of the individual segregated variables is provided for the random variables employed. We are not aware of mean and variance values for segregated variables for distributions other than normal and uniform."}, {"heading": "2.5 Decision Rules for Optimization under Data Uncertainty", "text": "In optimization problems with data uncertainty, a decision rule specifies the dependence of adjustable variables on the uncertainty parameters and the non-adjustable variables. Let z\u0303\nand x denote the set of primitive random variables and non-adjustable variables respectively. An example is the linear decision rule framework proposed by Ben-Tal and Nemirovski (2002), where the setting value of an adjustable decision variable S\u0303(x, z\u0303) is assumed to be affinely dependent on a subset of the N number of primitive random variables:\nS\u0303(x, z\u0303) = c0 + N\u2211\nk=1\nck(x)z\u0303k (9)\nwhere each ck(x) (1 \u2264 k \u2264 N) is a coefficient derived from x. Another example is the segregated linear decision rule framework proposed by Chen et al. (2008), where each adjustable decision variable is assumed to be affinely dependent on a set of some N segregated random variables { z\u0303+1 , z\u0303 \u2212 1 , . . . , z\u0303 + N , z\u0303 \u2212 N } . Hence, a segregated linear decision rule has the following general form:\nS\u0303(x, z\u0303) = c0 + \u2211N\nk=1 { c+k z\u0303 + k + c \u2212 k z\u0303 \u2212 k } . (10)\nAs we will show below, a segregated linear decision rule allows us to easily obtain an upper bound on a subset of random variables (see Eqn 14), which is not possible in the linear decision rule framework proposed by Ben-Tal and Nemirovski (2002).\nGiven the mean and variance for each segregated variable E(z\u0303+k ) = E(z\u0303 \u2212 k ) = \u00b5k ,\nV ar(z\u0303+k ) = \u03c3 2 pk and V ar(z\u0303 \u2212 k ) = \u03c3 2 mk , we can express the expected value and variance of any adjustable variable as:\nE[S\u0303(x, z\u0303)] = c0 + N\u2211\nk=1\n{ c+k \u00b5k + c \u2212 k \u00b5k } (11)\nV ar[S\u0303(x, z\u0303)] = N\u2211\nk=1\n{[ c+k \u03c3pk ]2 + [c\u2212k \u03c3mk ]2 \u2212 2c+k c\u2212k \u00b5k } . (12)"}, {"heading": "3. Decision Rules for RCPSP/max with Durational Uncertainty", "text": "In RCPSP/max with durational uncertainty, a decision rule specifies the dependence of activity start times on the durational uncertainty associated with other activities. To make the comparison with Equation 9, x represents the POS to be generated; each task\u2019s start time is associated with the adjustable variable S\u0303(x, z\u0303), where c0 represents the earliest start time of this task under the POS, and ck(x) encodes how task k is related to this task in the POS.\nIn a scheduling context, the start time of an activity is dependent on the start times of the preceding activities, i.e. Adjustable variables S\u0303(x, z\u0303) are dependent on one another. Any activity will either start after the end of an activity (i.e. in series) or after the end of multiple activities occurring simultaneously (i.e. in parallel). Thus, adjustable variables are functions of other adjustable variables through the addition operator (to model serial activities) and/or the maximum operator (to model parallel activities).\nGiven M number of adjustable variables, we may express its sum as an adjustable variable in the form of a segregated linear decision rule as follows:\n\u2211M i=1 S\u0303i(x, z\u0303)\n= \u2211M\ni=1 c 0 i + \u2211N k=1 {\u2211M i=1 c + i,kz\u0303 + k + \u2211M i=1 c \u2212 i,kz\u0303 \u2212 k } .\n(13)\nSimilarly, given some set C of adjustable variables, we may also express the upper bound on the maximum of these variables as an adjustable variable in the form of a segregated linear decision rule:\nmaxi\u2208C{S\u0303i(x, z\u0303)} \u2264 maxi\u2208C{c0i }+ \u2211N k=1 { maxi\u2208C{c+i,k}z\u0303+k } + \u2211N k=1 { maxi\u2208C{c\u2212i,k}z\u0303\u2212k } .\n(14)\nMore specifically, the output of solving a RCPSP/max involves a POS that is represented as a graph with activities as vertices and precedence constraints between activities as the edges. Given a POS graph, x = (V, E), where V is the set of activities and E is the set of temporal dependencies (an edge (u, v) represents a temporal dependency that states that activity v should occur after activity u). For any activity v \u2208 V , the decision rule for computing its start time is defined recursively as follows:\nS\u0303v(x, z\u0303) = max (u,v)\u2208E\n{d0u + z\u0303u + S\u0303u(x, z\u0303)}. (15)\nEquation 15 is a recursive expression that is defined as a combination of sum and maximum on a set of random variables. It should be noted that combinations of sum and maximum of random variables cannot be computed exactly and hence we present two operational decision rule approximations to evaluate the recursive expression of Equation 15: (a) Segregated Linear Approximation(SLA); and (b) General Non-Linear Approximation(GNLA). It should be noted that the S\u0303v is computable as long as mean and variance of S\u0303u is computable and this is demonstrated with both our approximations."}, {"heading": "3.1 Segregated Linear Approximation (SLA)", "text": "In this decision rule, the duration for each activity is defined based on the segregated random variables introduced in Section 2.4. For an uncertain duration d\u0303 with mean processing time d0, we represent d\u0303 as a sum of three components: its mean d0, lateness z\u0303+ (i.e. max{d\u0303\u2212 d0, 0}), and earliness z\u0303\u2212 (i.e. max{d0 \u2212 d\u0303, 0}),\nd\u0303 = d0 + z\u0303+ \u2212 z\u0303\u2212. (16)\nFor a normally distributed duration, i.e., z\u0303 \u223c N{0, \u03c3}, the respective values of mean and variance for the segregated variables can be summarized as:\nE[z\u0303+] = E[z\u0303\u2212] = \u03c3\u221a 2\u03c0\n(17)\nV ar[z\u0303+] = V ar[z\u0303\u2212] = (\u03c0 \u2212 1)\u03c32\n2\u03c0 . (18)\nNow we describe the computation of S\u0303v(x, z\u0303) by representing durational uncertainty for activities using segregated random variables. Upper bounds on both the sum and maximum of random variables are derived as linear functions of segregated variables as illustrated below:\n\u2022 Sum of random variables : In the case of a project network involving k activities, any two of which have either precedence constraints in between or competing for the same resource units, a solution in the form of POS requires computation of the sum of activity durations. The start time of the activity starting after the k-activity project is expressed as:\nS\u0303k(x, (z\u0303+, z\u0303\u2212)) = \u2211k i=1(d 0 i + z\u0303 + i \u2212 z\u0303\u2212i ). (19)\nThus, the adjustable variable S\u0303k a mean of \u2211k i=1 d 0 i with uncertainty captured by\na random variable, which has a positive segregated component of \u2211k\ni=1 z\u0303 + i and a\nnegative segregated component of \u2211k\ni=1 z\u0303 \u2212 i . Mean and variance of the segregated\nvariables are known and hence the mean and variance of S\u0303k are easy to compute.\n\u2022 Max of random variables: Consider activities that are executed concurrently, the upper bound on the start time of an activity starting after the parallel k-activity project network in SLA is represented by a linear function of the positive segregated components of duration perturbations:\nS\u0303k(x, (z\u0303+, z\u0303\u2212)) \u2264 maxi=1,...k{d0i }+ \u2211k i=1 z\u0303 + i . (20)\nThus, the adjustable variable S\u0303k has an upper bound on the mean of maxi=1,...k{d0i } with uncertainty captured by a random variable with the positive segregated component given by \u2211k i=1 z\u0303 + i and no negative segregated component. Mean and variance of the segregated variables are known and hence the mean and variance of S\u0303k are easy to compute.\nSince, in both cases (sum and max) S\u0303k is expressed linearly on a subset of random segregated variables, the recursive computation is straightforward. Compared with other linear decision rules (Ben-Tal & Nemirovski, 2002), the superiority of SLA (Chen et al., 2008) lies in this ability to linearly express an upper bound on a subset of random variables by dissecting each uncertainty into its positive and negative components. While this approximation increases tractability and scalability, it comes at the expense of losing accuracy."}, {"heading": "3.2 General Non Linear Approximation (GNLA)", "text": "While SLA is efficient, it can typically provide loose upper bounds on robust makespan due to the linear approximation for computing max of random variables. In this section, we describe General Non Linear Approximation (GNLA), which is not restricted to only affine dependencies. For clarity and comparison purposes, we use G\u0303 to denote the start time instead of S\u0303 used in SLA.\nGiven the mean and variance values of duration uncertainty, we describe the approximation involved in computing mean and variance of the sum and max of activities that will\nbe used in Equation 15. It should be recalled that irrespective of the distribution of the uncertain duration d\u0303, we can always represent d\u0303 as d\u0303 = d0 + z\u0303, where d0 is the mean of d\u0303 and z\u0303 is the perturbation part. Thus, E(z\u0303) = 0."}, {"heading": "3.2.1 Sum of Random Variables", "text": "We compute sum of all stochastic durations in a serial k activity project network as follows:\nG\u0303k(x, z\u0303) = k\u2211\ni=1\n(d0i + z\u0303i). (21)\nIn this case, we have a similar representation to SLA. Mean and variance of G\u0303k are computed as follows:\nSince {z\u0303i}i=1,...k are random variables with zero mean, we can then calculate the expected value as:\nE[ k\u2211\ni=1\n(d0i + z\u0303i)] = k\u2211\ni=1\nd0i . (22)\nBecause {z\u0303i} are assumed to be independent of each other, the variance value is computed by the following expression:\nV ar[ k\u2211\ni=1\n(d0i + z\u0303i)] = k\u2211\ni=1\nV ar[z\u0303i], (23)\nand under normal distribution where z\u0303i \u223c N(0, \u03c3i), we have\nV ar[ k\u2211\ni=1\n(d0i + z\u0303i)] = k\u2211\ni=1\n\u03c32i . (24)\nNote that the expressions for expected value and variance in the case of serial activities are identical to the ones used by Wu, Brown, and Beck (2009)."}, {"heading": "3.2.2 Max of Random Variables", "text": "For ease of explanation, we begin by considering two activities to be executed in parallel and then extend the analysis to multiple parallel activities. In GNLA, (unlike in SLA) the max of random variables itself is not approximated but the expected value and variance of the max are approximately calculated. Expected Value and Variance of Max of Two Variables\nThe decision rule to represent the starting time of an activity, which will begin after the completion of two parallel activities is defined as:\nG\u03032(z\u0303) \u2264 max{d01, d02}+ max{z\u03031, z\u03032}. (25)\nNote that we tighten the bound in Eqn 20 by replacing z\u0303+1 + z\u0303 + 2 with max{z\u03031, z\u03032}.\nWe now derive the expressions for expected value and variance of the adjustable variable, i.e., the RHS term of Eqn 25. Firstly, we focus on the expected value:\nE[max{d01, d02}+ max{z\u03031, z\u03032}] = max{d01, d02}+ E[max{z\u03031, z\u03032}]. (26)\nIn the general case, it is difficult to derive an exact expression for E[max{z\u03031, z\u03032}] and hence, we provide an upper bound.\nIn the following Propositions 1 and 2, we compute expected value and variance for the more general case of E(z\u0303) \u2265 0 (note that we assume E(z\u0303) = 0 for all primitive random variables). We calculate for the more general case because it will be required in the computation of expected value and variance for more than two random variables (next subsection).\nProposition 1. The expected value for the maximum of two general distributions, z\u03031 and z\u03032 with nonnegative means is less than 1 2 (E[z\u03031] + E[z\u03032]) + 1 2 \u221a V ar[z\u03031] + V ar[z\u03032] + (E[z\u03031])2 + (E[z\u03032])2.\nProof. We begin by considering the following two equalities:\nmax{z\u03031, z\u03032}+ min{z\u03031, z\u03032} = z\u03031 + z\u03032 max{z\u03031, z\u03032} \u2212min{z\u03031, z\u03032} = |z\u03031 \u2212 z\u03032|.\nWe now sum the above two equalities.\nmax{z\u03031, z\u03032} = 12(z\u03031 + z\u03032 + |z\u03031 \u2212 z\u03032|). (27)\nThus, we can now compute the expected value of the maximum using the following equation:\nE[max{z\u03031, z\u03032}] = 12(E[z\u03031] + E[z\u03032] + E|z\u03031 \u2212 z\u03032|). (28)\nIn addition, by using the definition of variance, we obtain:\nV ar|z\u03031 \u2212 z\u03032| = E(z\u03031 \u2212 z\u03032)2 \u2212 (E|z\u03031 \u2212 z\u03032|)2 \u2265 0.\nTherefore,\nE|z\u03031 \u2212 z\u03032| \u2264 \u221a\nE(z\u03031 \u2212 z\u03032)2 = \u221a E(z\u030321) + E(z\u0303 2 2)\u2212 2E(z\u03031)E(z\u03032)\n\u2264 \u221a\nE(z\u030321) + E(z\u0303 2 2)\n= \u221a V ar[z\u03031] + V ar[z\u03032] + E(z\u03031)2 + E(z\u03032)2.\n(29)\nSubstituting the final expression of Eqn 29 into Eqn 28 yields the bound\nE[max{z\u03031, z\u03032}] \u2264 12(E[z\u03031] + E[z\u03032]) + 12 \u221a V ar[z\u03031] + V ar[z\u03032] + (E[z\u03031])2 + (E[z\u03032])2. (30)\nHence the proof. Note that in this paper, we assume E(z\u0303) = 0, thus, a tighter bound can be obtained\nfrom Eqn 30: E[max{z\u03031, z\u03032}] \u2264 12 \u221a V ar[z\u03031] + V ar[z\u03032]. (31)\nIn the special case where {z\u0303i} (i = 1, ...k) are normally and identically distributed, i.e. z\u0303i \u223c N(0, \u03c3), we know from the work of Clark (1961) that there is a closed form representation for the expected value of the maximum when k = 2:\nE[max{z\u03031, z\u03032}] = \u03c3\u221a \u03c0 .\nNow we focus on deriving expressions for variance of the maximum of two general distributions, i.e., V ar[max(z\u03031, z\u03032)].\nProposition 2. The variance for the maximum of two general distributions, z\u03031 and z\u03032 with nonnegative means is less than V ar(z\u03031) + V ar(z\u03032) + 12(E(z\u03031)) 2 + 12(E(z\u03032)) 2.\nProof. From Eqn 27, we have\nV ar[max(z\u03031, z\u03032)] = 14V ar[z\u03031 + z\u03032 + |z\u03031 \u2212 z\u03032|] = 14(V ar[z\u03031 + z\u03032] + V ar|z\u03031 \u2212 z\u03032|+ 2COV (z\u03031 + z\u03032, |z\u03031 \u2212 z\u03032|)) \u2264 14(V ar[z\u03031 + z\u03032] + V ar|z\u03031 \u2212 z\u03032|+ 2 \u221a V ar[z\u03031 + z\u03032]V ar|z\u03031 \u2212 z\u03032|)\n\u2264 12(V ar[z\u03031 + z\u03032] + V ar|z\u03031 \u2212 z\u03032|). (32)\nFirstly, we consider the following two equations.\nV ar|z\u03031 \u2212 z\u03032| = E(z\u03031 \u2212 z\u03032)2 \u2212 (E|z\u03031 \u2212 z\u03032|)2 (33) V ar(z\u03031 \u2212 z\u03032) = E(z\u03031 \u2212 z\u03032)2 \u2212 (E(z\u03031 \u2212 z\u03032))2\nSubtracting the second from the first yields\nV ar|z\u03031 \u2212 z\u03032| = V ar(z\u03031 \u2212 z\u03032) + (E(z\u03031 \u2212 z\u03032))2 \u2212 (E|z\u03031 \u2212 z\u03032|)2.\nNow, we substitute this expression into the last term of Eqn 32 to obtain:\nV ar[max(z\u03031, z\u03032)] \u2264 V ar(z\u03031) + V ar(z\u03032) + 12(E(z\u03031)\u2212 E(z\u03032))2 \u2212 12(E|z\u03031 \u2212 z\u03032|)2. (34)\nWhen no specific distribution about duration perturbation is known, we can obtain a bound for V ar[max(z\u03031, z\u03032)] as:\nV ar[max(z\u03031, z\u03032)] \u2264 V ar(z\u03031) + V ar(z\u03032) + 12(E(z\u03031))2 + 12(E(z\u03032))2. (35)\nHence the proof. Note that in this paper, we assume E(z\u0303) = 0, thus, a tighter bound can be obtained from Eqn 35: V ar[max(z\u03031, z\u03032)] \u2264 V ar(z\u03031) + V ar(z\u03032). (36)\nIt is interesting to consider the special case when both random variables are normally distributed. We first state the following lemma1.\n1. This can be found in statistics texts, and found online at http://en.wikipedia.org/wiki/Halfnormal distribution.\nLemma 3.1. If X is normally distributed X \u223c N(0, \u03c3), then Y = |X| is half-normally distributed, with\nE(Y ) = \u03c3 \u221a 2 \u03c0 . (37)\nUnder normal distribution z\u0303i \u223c N(0, \u03c3i), since z\u03031 \u2212 z\u03032 is also normally distributed, and z\u03031\u2212 z\u03032 \u223c N(0, \u03c31 + \u03c32), we can conclude from Lemma 3.1 that |z\u03031\u2212 z\u03032| follows half-normal distribution with\nE|z\u03031 \u2212 z\u03032| = (\u03c31 + \u03c32) \u221a\n2 \u03c0 . (38)\nThus, if we substitute this expression into Eqn 34, we can express an upper bound on the variance value for the maximum duration perturbation of two activities, when z\u0303i \u223c N(0, \u03c3i) as :\nV ar[max(z\u03031, z\u03032)] \u2264 (1\u2212 1 \u03c0 )(\u03c321 + \u03c3 2 2)\u2212 2 \u03c0 \u03c31\u03c32. (39)\nExpected Value and Variance of Max of Multiple Variables Extending from two to k (k > 2) parallel activities, the completion time can be upper\nbounded by: G\u0303k(z\u0303) \u2264 max\ni=1,...k {d0i }+ max i=1,...k {z\u0303i}. (40)\nIn the following, we first compute the variance value of the above RHS term and then use a similar procedure to compute the expected value. The basic expression for variance of RHS is:\nV ar[ max i=1,...k {d0i }+ max i=1,...k {z\u0303i}] = V ar[ max i=1,...k {z\u0303i}]. (41)\nTo obtain the value of V ar[ max i=1,...k {z\u0303i}] for general probability distributions, we take advantage of the analysis provided for the two-parallel-activity case above. The following steps outline the overall idea: (a) Firstly, we group the activity set {a1, ..., ak} into a couple set {C1, ..., Cd k 2 e}, where each element Cj(j = 1, ...dk2e) contains two different activities Cj = {aj1, aj2} chosen from the activity set. Note that when k is an odd, the final element in the couple set contains just one activity. (b) For each couple Cj , we apply the maximum operator on duration perturbations of involving activities. Denote c\u0303j = max{z\u0303j1, z\u0303j2}, where z\u0303j1 and z\u0303j2 are duration perturbations of the two activities involved in Cj , then V ar(c\u0303j) can be calculated based on the expression for the two-parallel-activity case. (c) Then we have max\ni=1,...k {z\u0303i} = max j=1,...d k 2 e {c\u0303j}. (Note again just one activity is contained in\nCd k 2 e when k is odd). Then, we can build another couple set from {C1, ..., Cd k 2 e}, and the same method from steps (1) and (2) above is used to compute V ar[ max j=1,...d k 2 e {c\u0303j}] based on Eqn 35 and/or Eqn 36 and/or Eqn 39.\nThere are numerous ways (exponential in k) for generating the couple set {C1, ..., Cd k 2 e} for k activities in parallel. Each of these couple sets can lead to different levels of tightness of derived robust makespan. To compute the grouping which provides the best robust fitness for random variables with generic distributions is an open problem. Instead, we focus on a heuristic that computes the best grouping under normal distribution z\u0303i \u223c N(0, \u03c3i). It is obtained by solving the following optimization problem:\nmax t\n\u2211\nj=1,...b k 2 c \u03c3j1\u03c3j2 (42)\nwhere t denotes the grouping technique and is also the decision variable; {Cj} is the couple set constructed from the activity set under grouping method t; \u03c3j1 and \u03c3j2 are the standard deviations of data perturbation for durations of activities contained in Cj . The intuition for employing this optimization problem is obtained from the Equation 39. It should be noted that computing a tighter bound on variance implies considering the highest possible value of the product of primitive variances. Hence, the reason for employing the optimization problem of Equation 42.\nProposition 3. The solution t\u2217 to the optimization problem of Eqn 42 is obtained by ordering the k activities in a non-increasing order of their variance values and then grouping all two nearest activities according to the order, i.e. Cj = {aj1, aj2}, where j = 1, ...bk2c and the standard deviations are in the following order:\n\u03c311 \u2265 \u03c312 \u2265 \u03c321 \u2265 \u03c322 \u2265, ...\u03c3b k 2 c1 \u2265 \u03c3b k 2 c2. (43)\nProof. Suppose we have another grouping method t\u2032, in which all elements in the couple set are the same as under t\u2217 except two couples 2 where the ordering is different, i.e., Cm = {am1, an2} and Cn = {am2, an1} (m 6= n), where Cm = {am1, am2} and Cn = {an1, an2} under t\u2217. Without loss of generality, assume m > n and from Eqn 43, we have\n\u03c3m1 \u2265 \u03c3m2 \u2265 \u03c3n1 \u2265 \u03c3n2. (44)\nSince t\u2032 is supposed to provide a solution which is no less ( defined in Eqn 42) than t\u2217, i.e. \u03c311\u03c312 + ... + \u03c3m1\u03c3n2 + ... + \u03c3n1\u03c3m2 + ... + \u03c3b k\n2 c1\u03c3b k 2 c2\n\u2265 \u03c311\u03c312 + ... + \u03c3m1\u03c3m2 + ... + \u03c3n1\u03c3n2 + ... + \u03c3b k\n2 c1\u03c3b k 2 c2.\nTherefore, we have\n\u03c3m1\u03c3n2 + \u03c3n1\u03c3m2 \u2265 \u03c3m1\u03c3m2 + \u03c3n1\u03c3n2, which is equivalent to: (\u03c3m1 \u2212 \u03c3n1)(\u03c3n2 \u2212 \u03c3m2) \u2265 0. This contradicts Eqn 44 (except the case where all standard deviations are equal, in which case mixing the order does not affect anything). Thus, there exists no such t\u2032 which is different from t\u2217 by at least two couples and has better objective value. The general case\n2. It should be noted that if there is an ordering change in only one couple, then the method still produces the same solution because within a couple the variance computation does not consider the order.\nthat t\u2032 has multiple (more than two) couples different from t\u2217 can be easily derived from to this case (and is omitted due to space constraints).\nHence the proof. As for analyzing the expected value E[ max\ni=1,...k {z\u0303i}], we apply the same procedure em-\nployed to calculate the variance, i.e., based on the group solution returned by the above optimization problem, we first calculate the expected value for each couple and then, get the final bound following Eqn 30 and/or Eqn 31 and/or Eqn 32.\nAt present, we are unable to show the effectivness of our grouping heuristic (Equation 42) analytically in the most general case. However, we show the intuition behind the grouping heuristic by providing an analytical comparison3 on an example where there are four activities (normally distributed durations) executed in parallel, i.e. z\u0303i \u223c N(0, \u03c3i), and we assume \u03c31 \u2265 \u03c32 \u2265 \u03c33 \u2265 \u03c34 (no loss of generality).\nThe representation of makespan under our grouping heuristic (denoted as Mheu) and random grouping (denoted as Mran) are, respectively:\nMheu = max{d01, d02, d03, d04}+ max{max{z\u03031, z\u03032},max{z\u03033, z\u03034}} Mran = max{d01, d02, d03, d04}+ max{max{z\u03031, z\u03034},max{z\u03032, z\u03033}}.\n(45)\nLet us first examine mean and variance values of Mheu. From Eqn 31, we have\nE(max{z\u03031, z\u03032}) \u2264 12 \u221a \u03c321 + \u03c3 2 2\nE(max{z\u03033, z\u03034}) \u2264 12 \u221a \u03c323 + \u03c3 2 4.\n(46)\nFrom Eqn 39, we have\nV ar[max(z\u03031, z\u03032)] \u2264 (1\u2212 1\u03c0 )(\u03c321 + \u03c322)\u2212 2\u03c0\u03c31\u03c32 V ar[max(z\u03033, z\u03034)] \u2264 (1\u2212 1\u03c0 )(\u03c323 + \u03c324)\u2212 2\u03c0\u03c33\u03c34.\n(47)\nFrom Eqn 30, Eqn 35, Eqn 46 and Eqn 47, we can obtain bounds of mean and variance values of of Mheu are 4:\nE(Mheu) \u2264 const + 14( \u221a \u03c321 + \u03c3 2 2 + \u221a \u03c323 + \u03c3 2 4) + 1 2 \u221a (54 \u2212 1\u03c0 ) \u22114 i=1 \u03c3 2 i \u2212 2\u03c0 (\u03c31\u03c32 + \u03c33\u03c34)\nV ar(Mheu) \u2264 (98 \u2212 1\u03c0 ) \u22114 i=1 \u03c3 2 i \u2212 2\u03c0 (\u03c31\u03c32 + \u03c33\u03c34).\n(48)\nSimilarly, mean and variance values of of Mran can also be calculated,\nE(Mran) \u2264 const + 14( \u221a \u03c321 + \u03c3 2 4 + \u221a \u03c322 + \u03c3 2 3) + 1 2 \u221a (54 \u2212 1\u03c0 ) \u22114 i=1 \u03c3 2 i \u2212 2\u03c0 (\u03c31\u03c34 + \u03c32\u03c33)\nV ar(Mran) \u2264 (98 \u2212 1\u03c0 ) \u22114 i=1 \u03c3 2 i \u2212 2\u03c0 (\u03c31\u03c34 + \u03c32\u03c33).\n(49)\nFrom Eqn 57, bounds of fitness of Mheu (denoted by Fitheu) and Mran (denoted by Fitran) can then be respectively represented as a function of RHS of Eqn 48 and Eqn 49. We then examine the difference value between the two bounds, Fitheu\u2212Fitran. Let us first compare the first term of RHS of mean values in Eqn 48 and Eqn 49, since\n( \u221a\n\u03c321 + \u03c3 2 2 + \u221a \u03c323 + \u03c3 2 4) 2 \u2212 ( \u221a \u03c321 + \u03c3 2 4 + \u221a \u03c322 + \u03c3 2 3) 2\n= 2 \u221a\n\u03c321\u03c3 2 3 + \u03c3 2 2\u03c3 2 4 + \u03c3 2 1\u03c3 2 4 + \u03c3 2 2\u03c3 2 3 \u2212 2 \u221a \u03c321\u03c3 2 3 + \u03c3 2 2\u03c3 2 4 + \u03c3 2 1\u03c3 2 2 + \u03c3 2 3\u03c3 2 4\n(50)\n3. The calculation will use the robust fitness function provided in Definition 57 introduced in Section 4. 4. Note that const in Eqn 48 and Eqn 49 is max{d01, d02, d03, d04}.\nand from Proposition 3, we have\n\u03c31\u03c34 + \u03c32\u03c33 \u2264 \u03c31\u03c32 + \u03c33\u03c34, (51) thus,\n\u03c321\u03c3 2 4 + \u03c3 2 2\u03c3 2 3 \u2212 (\u03c321\u03c322 + \u03c323\u03c324) = (\u03c31\u03c34 + \u03c32\u03c33)2 \u2212 (\u03c31\u03c32 + \u03c33\u03c34)2 \u2264 0. (52)\nFrom Eqn 51, Eqn 52, Eqn 48 and Eqn 49, we have that the bounds of mean and variance values of Mheu are lower than Mran. Given the robust fitness function in Eqn 57, we conclude that\nFitheu \u2212 Fitran \u2264 0 (53) which is independent of \u03b5 and \u03c3. In other words, our grouping heuristic can provide tighter fitness bound than random grouping."}, {"heading": "4. Robust Fitness Function", "text": "The makespan (start time of the dummy \u201csink\u201d activity) for the RCPSP/max with durational uncertainty is a function of non-adjustable variables x and random variables representing durational uncertainty z\u0303 and is represented using S\u0303(x, z\u0303) for SLA and G\u0303(x, z\u0303) for GNLA. Recall that the robust optimization problem is to find the minimum value F \u2217 for which the following probability bound is observed5:\nP (S\u0303(x, z\u0303) \u2264 F \u2217) \u2265 (1\u2212 \u00b2) (54) From the one-sided Chebyshev\u2019s Inequality, we can obtain a bound for the robust objective value F \u2217 as a function of its expected value and variance of the adjustable fitness function, i.e.:\nE[S\u0303(x, z\u0303)] + \u221a\n1\u2212\u00b2 \u00b2\n\u221a V ar[S\u0303(x, z\u0303)] \u2264 F \u2217 \u21d2 P (S\u0303(x, z\u0303) \u2264 F \u2217) \u2265 (1\u2212 \u00b2) (55)\nHence, we can reformulate our robust optimization problem as follows:\nmin F \u2217 s.t. E[S\u0303(x, z\u0303)] + \u221a\n1\u2212\u00b2 \u00b2\n\u221a V ar[S\u0303(x, z\u0303)] \u2264 F \u2217 (56)\nFrom this model, we can now derive the robust fitness function which will be used in our local search framework:\nDefinition 3. Given 0 < \u00b2 \u2264 1 and the adjustable fitness function S\u0303(x, z\u0303) defined above, the robust fitness function, f(x, z\u0303, \u00b2), is defined as\nf(x, z\u0303, \u00b2) = E[S\u0303(x, z\u0303)] +\n\u221a 1\u2212 \u00b2\n\u00b2\n\u221a V ar[S\u0303(x, z\u0303)] (57)\nThe goal of the local search mechanism is to find a local minima of f . In addition, local search typically requires the fitness function to be computed many times and hence it is imperative that the computation of fitness function is efficient.\n5. We show the computation of SLA robust fitness function. By substituting S\u0303 with G\u0303, we obtain the fitness function for GNLA."}, {"heading": "4.1 Schedule Infeasibility of a Given POS", "text": "It should be noted that the fitness function, f assumes that any schedule generated by the POS, x is always executable. However, due to durational uncertainty and the maximum time lags, the schedule is not always executable. A direct way to measure IPr(POS) the probability of infeasibility of the POS (i.e. probability that the POS can lead to an infeasible schedule) lies in the computation of the probability of infeasibility of each activity ai IPr(ai), that there does not exist a feasible start time such that all temporal constraints with respect to ai are satisfied. IPr(POS) can be calculated as the probability that at least one activity is infeasible. However, due to temporal dependencies between activities providing a theoretical expression for the overall probability of infeasibility is an open problem. Therefore, we propose a simulation approach, where we simulate POS execution over multiple trials to compute this probability eciently and approximately. As an illustration, we experimented with the benchmark J10 instances from the PSPLib (Kolisch, Schwindt, & Sprecher, 1998) for RCPSP/max with additional durational uncertainty that follows a normal distribution with mean 0 and variance 1. We generated 1000 sample realizations for the POS obtained from SLA, and check for infeasibility with respect to the original temporal (including the maximum time lag) constraints. Examples of the probability of infeasibility obtained by our simulation for PSP1, PSP4, and PSP13 are 0.18, 0.17 and 0.001. However, for the other problems PSP3, PSP5 etc. the probability of infeasibility was 0, because the maximal time lags were much larger than the variance of durational uncertainty."}, {"heading": "5. Robust Local Search Algorithm", "text": "This section will present how the decision rule approximations introduced by SLA, GNLA are integrated with the robust fitness function and local search mechanisms to provide a solution for the problems represented by RCPSP/max with durational uncertainty. Our proposed algorithm is outlined as follows. Steps 1, 2, 5 and 6 are standard steps in a local search algorithm. Steps 3 and 4 represent our departure from standard local search to deal with uncertainty.\n1. Generate initial solution This is usually obtained using a simple greedy heuristic.\n2. Generate neighborhood of solutions Generate a pool of neighbor solutions from the current solution.\n3. Employ one of the decision rule approximations (SLA and GNLA) for all adjustable variables and check feasibility For each candidate solution x in the solution pool, derive the coefficients Ck(x) for each adjustable variable. Subsequently, for each solution check constraint violation and reject those that are not feasible.\n4. Evaluate robust fitness function f For each feasible solution x, evaluate f to obtain the robust objective values. The solution with the lowest robust objective value is the current best robust solution.\n5. Apply penalty (optional) Some advanced local search strategies may require a penalty to be applied to prevent it from being caught at a local minima. In the case of tabu-search for example, a tabu-list is updated when a tabu move is applied. In the case of iterated local search, a perturbation move will be applied to the current local minima.\n6. Termination criteria If the termination criteria is met, return the solution with the lowest robust fitness function value else repeat the optimization cycle by determining the next move.\nAlgorithm 1 provides the robust local search algorithm guided by decision rule using SLA. By substituting S\u2217now, S\u2217min, S \u2217 with G\u2217now, G\u2217min, G \u2217, we obtain the local search algorithm using GNLA. Given the RCPSP/max with durational uncertainty and the level of risk (0 < \u00b2 \u2264 1), the algorithm returns the POS with the (locally) minimal robust makespan, S\u2217 (or G\u2217 by GNLA). In essence, we perform robust local search on the neighborhood set of activity lists. An activity list (al) is defined as a precedence-constraint feasible sequence that is used by heuristics to generate earliest start time schedules in solving the standard RCPSP problem (Kolisch & Hartmann, 2005).\nDifferent activity lists are explored by local moves. In our context, we only consider the activity list as the sequence of activities which satisfy the non-negative minimal time lag constraint. Due to the existence of maximal time lag constraint in RCPSP/max, scheduling activities to their earliest possible start time based on the order position in the activity list may restrict the schedule so much that it may not even return in a feasible schedule. Thus, when we schedule each activity sequentially based on order position in the activity list, we will assign its starting time by randomly picking a time from its domain of feasible start times.\nAccording to our experiments, this new randomized approach returns more feasible solutions than the earliest start time one. After finding a feasible schedule, a POS will be generated by applying the chaining procedure proposed by Policella et al. (2004). Then, the S\u2217 (or G\u2217 by GNLA) value will be computed according to the POS. Intuitively, using the randomized approach may return a schedule with a large baseline scheduled completion time. However, we can apply the shortest path algorithm on the resulting POS to generate the earliest start time schedule for a smaller makespan.\nAs mentioned above, it may be difficult to find a feasible schedule that satisfies minimal and maximal time lag constraints using the activity list. In fact, we believe that in the set of all activity lists, many may not yield a feasible schedule. We overcome this problem as follows. We define the set of activity lists which result in feasible (or infeasible) schedules as F (or I). We seek to design a local search algorithm with the following characteristics: a) Starting from an activity list in I, the local search should move to an activity list in F within a short time. b) Starting from an activity list in F , the local search should move to the activity list with the minimal S\u2217(or G\u2217 by GNLA)value. c) We also diversify the exploration of activity lists in F by allowing the local search to move from an activity list in F to an activity list in I, since activity lists in the F region may not be reachable from one another by simple local moves. This has the flavor of strategic oscillation proposed in meta-heuristics research.\nAlgorithm 1 Robust Local Search 1: Generate an activity list al randomly 2: Find a start time schedule, ss randomly according to al 3: if al \u2208 F then 4: POS \u2190 chaining(ss) 5: Compute S\u2217now according POS 6: Update S\u2217min as S \u2217 now\n7: else 8: Record the first activity a which cannot be scheduled 9: end if\n10: for i \u2190 1 to Max Iteration do 11: if al \u2208 I then 12: Shift activity a ahead in al randomly as al\u2019 13: else 14: Select two activities b and c in al randomly 15: Swap b and c in al as al\u2019 16: end if 17: Find randomized start time schedule ss\u2032 according to al\u2019 18: if al\u2032 \u2208 F then 19: POS\u2032 \u2190 chaining(ss\u2032) 20: Compute S\u2217 according to POS\u2032 21: if al \u2208 I or S\u2217 \u2264 S\u2217now then 22: S\u2217now \u2190 S\u2217 23: al \u2190 al\u2032 24: if S\u2217 \u2264 S\u2217min then 25: S\u2217min \u2190 S\u2217 26: end if 27: end if 28: else if al \u2208 I then 29: al \u2190 al\u2032 30: else 31: p \u2190 rand(0, 1) 32: if p < 0.01 then 33: al \u2190 al\u2032 34: Record the first activity a which cannot be scheduled 35: end if 36: end if 37: end for\nThe detailed robust local search procedure is given in Algorithm 1. The procedure starts by randomly generating an activity list al, which is a sequence of activities that satisfy the non-negative minimum time lag constraint (Line 1). In Line 2, a schedule ss is produced based on ordering of activities in the activity list al. We first perform domain reduction on the distance graph using the Floyd-Warshall algorithm, so that the feasible range of the start time for each activity based on the temporal constraints can be obtained. We then schedule each activity sequentially based on the order position in the activity list. For each activity, we first pick a start time randomly from the feasible domain and evaluate resource constraints for the duration of the activity (i.e. check if the current resource capacity exceeds the resource amount used by that activity). If yes, we set the start time to that activity, run the shortest path algorithm to reduce domains for the remaining activities, and update current resource capacity due to consumption of that activity. If the resource constraints are not satisfied, we will try to set the start time randomly again for a prescribed maximum numbers of retries. Once the start time of current activity is set, we proceed iteratively to the next activity according to the activity list. In Line 4, chaining() is employed to generate a POS from a baseline schedule (section 2.2.4). Max Iteration refers to the maximum number of iterations in the robust local search. We apply two different types of local moves. To converge quickly to an activity list in F, the first local move is designed to schedule the activity that is causing a temporal or resource conflict to an earlier time. It will randomly shift ahead the first activity which cannot be scheduled in the current activity list (Line 12). When an activity list is in F, the second local move will randomly pick two activities and swap them in the current activity list, while satisfying the nonnegative minimal time lag constraints (Line 14-15). The move will be accepted, if it results in a smaller or equal S\u2217 value (Line 18-29). To explore different activity lists, we include a small probability to accept the move which leads to an infeasible schedule (Line 31-35). The probability to move from an activity list in F to one in I is set at 0.01. The minimal S\u2217 value will be saved as S\u2217min.\nThe worst-case computational complexity analysis is given as follows. For each iteration in local search, there are three major components: randomized schedule generation, POS construction and fitness calculation. In the process of randomized schedule generation, we perform domain reduction and resource checking at each iteration, and thus the complexity is O(N \u00b7 (N3 +H \u00b7K \u00b7w)) where N is the number of activities, H is the maximum planning horizon, K is the number of types of resources, and w is the prescribed maximum number of retries for each activity on setting the randomized start time. The POS construction process works as follows: the set of activities are first sorted according to their start times in the generated deterministic schedule and the sorting part costs O(N \u00b7 logN); then it proceeds to allocate each activity the total units needed for each type of resource. Let maxcap be the maximum capacity among all resources. The cost for computing POS is then O(N \u00b7 logN + N \u00b7 K \u00b7 maxcap). When determining the fitness value of generated POS, we examine edge by edge to check if it is connected in parallel or in serial with respect to its predecessors and it costs O(N + e) where e is the number of edges in POS (e < N2). Thus, the worst-case complexity of our proposed robust local search algorithm is O(TN \u00b7 (N3 + H \u00b7K \u00b7w + K \u00b7maxcap)) where T is the number of iterations in local search."}, {"heading": "6. Enhancing Robust Local Search", "text": "In this section, we describe two enhancements to improve the basic local search method described in Section 5. Firstly, we describe ordering generation, which is a pre-processing step used to identify precedence ordering between activities. This precedence ordering is then used to focus the local search over activity lists. Secondly, we describe a new chaining method to generate POS from a feasible schedule."}, {"heading": "6.1 Ordering Generation", "text": "Ordering Generation is a pre-processing step that identifies precedence relationships between pairs of activities. The key idea is that for certain pairs of activities, it is always better (with respect to robust makespan) to have the same ordering among activities. Our goal is to identify these pairs of activities and employ this ordering to focus the local search over activity lists and in the chaining method used to compute POS from feasible schedule.\nIn deciding an ordering between a pair of activities, a and b, there are two key steps: (i) Sample set generation: Generate two sets of m activity lists. The first set consists of m activity lists where a occurs before b. The second set is generated by swapping activities a and b in every activity list in the first set; (ii) Order determination: In this step, we first compute POS and its robust makespan for all activity lists in the two sets. By comparing the robust makespan values of corresponding activity lists in the two sets, we determine an ordering between activities. We explain these steps in the following subsections.\nFor a problem with n activities, there are C2n pairs of activities. If we are to decide the orders between all pairs, the ordering computation needs to be implemented for C2n times, which is computationally expensive. Based on this observation, we first propose a PairsSelection heuristic to selectively choose a certain number of activities pairs whose ordering can have a significant impact on the robust makespan.\nThe Pairs-Selection heuristic picks an activity pair: (a) If it is not precedence related in the original problem definition; and (b) If there exists at least one type of resource, where the total demand of both activities exceeds the resource capacity. The intuition behind picking such an activity pair is that those two activities cannot be executed in parallel and deciding an ordering relationship is imperative to eliminate the resource conflict. One main advantage of the heuristic is that the number of pairs of activities that need to be ordered is significantly reduced. Now, we describe the two steps of ordering generation below:"}, {"heading": "6.1.1 Sample Set Generation", "text": "We first randomly generate m activity lists as an initial sample set denoted by T . Each element in T is an activity list represented as ali which is a sequence of all activities, where i = 1, ...m, i.e.\nT = {ali|ali = (a1, a2, ...an),\u2200i \u2208 {1, ...m}}. For each pair of activities (ak, al) resulting from the Pairs-Selection heuristic, we define two sample sets represented as T ak\u227aal and T al\u227aak . T ak\u227aal has all the activity lists that are in T , except that if an activity list has al before ak, then those activities are swapped.\nT ak\u227aal = {alak\u227aali |i \u2208 {1, ...m}},\nwhere alak\u227aali = { (a1, a2, ..., ak, ...al, ...an) if ali = (a1, a2, ..., al, ...ak, ...an) ali if ali = (a1, a2, ..., ak, ...al, ...an) .\nSimilarly, T al\u227aak can be constructed by incrementally selecting each activity list from the initial set T with al \u227a ak and reverse the order if ak \u227a al, i.e.\nT al\u227aak = {alal\u227aaki |i \u2208 {1, ...m}},\nwhere alal\u227aaki = { (a1, a2, ..., al, ...ak, ...an) if ali = (a1, a2, ..., ak, ...al, ...an) ali if ali = (a1, a2, ..., al, ...ak, ...an) .\nThus, each activity list in the sample set T ak\u227aal share the same positions of all activities except ak and al with the corresponding activity list in set T al\u227aak , where al precedes ak."}, {"heading": "6.1.2 Order Determination", "text": "We then determine the activity order of each selected pair of activities based on the sample sets obtained from last phase. For a pair (ak, al), we construct a new instance by posting a precedence constraint ak \u227a al or al \u227a ak to the original instance, and based on the new instance, we determine the fitness which are denoted as fak\u227aali and f al\u227aak i for al ak\u227aal i and alal\u227aaki , respectively. Note that alak\u227aali and al al\u227aak i share the same elements and the same positions except the order of ak and al. Thus, the order of ak and al can be considered as a reason why the fitness of alak\u227aali and al al\u227aak i differs. To decide the order of ak and al, we define an index variable denoted as ivak\u227aal that measures the percentage of samples where the one with the order ak proceeds al wins, i.e.\nivak\u227aal = \u2212 \u2211 i min( f ak\u227aal i \u2212fal\u227aak i |fak\u227aal i \u2212fal\u227aak i | ,0) m .\nWe then define an Index Parameter for activities ak and al denoted as IPak\u227aal as a benchmark for the index variable ivak\u227aal in determining the order of ak and al. The parameter IPak\u227aal can be prescribed by users and different values (usually larger than 50%) represent different levels of confidence that the order of ak and al matters in causing fitness variance, and thus also represents different controllability of ivak\u227aal .\nIf the value of index variable ivak\u227aal is larger than the value of IPak\u227aal , we set the order ak \u2192 al since there indicates a higher probability that a \u2192 b can provide better robustness than b \u2192 a; If ivak\u227aal is less than 1\u2212 IPak\u227aal , we set al \u2192 ak; And in other cases, no order between ak and al is settled."}, {"heading": "6.2 Improved Chaining based on Robustness Feedback", "text": "As noted in the \u201cPreliminaries\u201d section, for each activity a, there may exist multiple choices of resource chains to which it can be assigned. In addition, different chaining heuristics will lead to POSes that can have different robust makespan values. In this section, we propose a new chaining heuristic that dispatches activities to resource chains by predicting the improvement in robust makespan of the generated POS.\nAlgorithm 2 Robustness-Feedback Resource Chaining (Activity a, Schedule S, Order G) 1: C \u2190 Find set of available chains, C for activity a based on S 2: P \u2190 Collect chains from C with last activity of chain preceding a in problem 3: O \u2190 Collect chains from C with last activity of chain ordered before a in G 4: if P 6= \u03c6 then 5: k \u2190 Get first available chain in P 6: else if O 6= \u03c6 then 7: k \u2190 Get first available chain in O 8: else 9: k \u2190 Get first available chain in C 10: end if 11: Post constraint between last activity of chain k (denoted as last(k)) and activity a 12: if a requires more than one resource unit then 13: C1 \u2190 chains in C which have last activity as last(k) 14: C2 \u2190 C \\ C1 15: for all resource units required by a do 16: choose the first available chain belonging to C1 17: if chain above is not feasible then 18: choose the first available chain belonging to C2 19: end if 20: end for 21: end if\nIn the latest chaining method which aims to increase flexibility as described in Section 2.2.4, the chains are first randomly picked from a superior subset (i.e., chains where the last activity is already ordered, or chains sharing the same last element). Since our objective is makespan-related and time becomes a concern, we build on the work of Policella et al. (2009) and pick the first available chain wherever available. The updated chaining method is called Robustness-Feedback based Resource Chaining.\nExample 5. Figure 5 provides the POS provided by this chaining heuristic when used on Example 1. As can be seen, compared to the POS in 4, the key difference is the allocation of activity 5 and 6. With our new heuristic, it can be seen that there is more parallelism and hence reduced robust makespan with high probability.\nWhen employing the Ordering Generation algorithm in conjunction with the chaining heuristic, we also consider the information about ordered pairs when allocating resource units to an activity. The motivation is that once activity a and activity b (for example, a \u2192 b) is ordered, there is a high probability that this precedence relationship can result in a better solution. Algorithm 2 provides the pseudo code for the Robustness-Feedback Resource Chaining heuristic with Ordering."}, {"heading": "7. Experimental Evaluation", "text": "In this section, we first evaluate the scalability and quality of the execution strategies provided by robust local search and the various enhancements introduced in this paper.\nSecondly, to establish a benchmark on the performance, we compare against the best known technique for solving JSP problems with durational uncertainty. It should be noted that the robust local search method is developed to solve RCPSP/max problems with durational uncertainty and hence does not exploit the structure present in JSP problems. Furthermore, as described earlier, the optimization metrics of both approaches are different."}, {"heading": "7.1 Experimental Setup", "text": "We have two sets of problems that we consider and those are described in the subsections below. Additionally, we also indicate the algorithms that are compared on each of the data sets in this section."}, {"heading": "7.1.1 RCPSP/max with Durational Uncertainty", "text": "The problems considered for RCPSP/max with durational uncertainty were obtained by extending the three benchmark sets available for RCPSP/max problems, J10, J20 and J30 as specified in the PSPLib (Kolisch et al., 1998). Each set contains 270 problem instances with duration for each activity ranging between 1 and 10. The maximum number of activities for J10, J20 and J30 are 10, 20 and 30, respectively. For each activity ai, we set the expected value d0i of the stochastic duration as the corresponding deterministic duration given by the benchmarks, and assume that duration uncertainty is normally distributed, i.e. z\u0303i \u223c N(0, \u03c3). Henceforth, we refer to J10, J20 and J30 as these RCPSP/max problems with durational uncertainty. We run the algorithms on problems with four different duration variabilities \u03c3 = {0.1, 0.5, 1, 2} and four increasing levels of risk \u03b5 = {0.01, 0.05, 0.1, 0.2}.\nOn RCPSP/max problems with durational uncertainty, we compare the robust local search that is guided using the two decision rule approximations SLA and GNLA. Furthermore, we also compare the different enhancements to robust local search on RCPSP/max problems with durational uncertainty. We compare five different variants of robust local search for each decision rule approximation: (a) (GNLA) refers to basic robust local search guided by GNLA decision rule approximation; (b) (GNLA+RC) is the robust local search with the new Robustness-feedback Chaining heuristic guided by GNLA; (c) (GNLA+) refers to the basic robust local search with additional local search iterations, where the number of local search iterations is determined based on the problem set (as described later); (d) (GNLA+OG) is the Order Generation heuristic on top of GNLA guided robust local search; and finally (e) (GNLA+OG+RC) has both Order Generation and Robustness-feedback Chaining heuristics on GNLA guided robust local search.\nThe number of local search iterations for robust local search was set to 1000. To reduce the stochasticity effects of robust local search, we average over 10 random executions for each problem instance. Our code was implemented in C++ and executed on a Core(TM)2 Duo CPU 2.33GHz processor under FedoraCore 11 (Kernel Linux 2.6.29.4-167.fc11.i586)."}, {"heading": "7.1.2 JSP with Durational Uncertainty", "text": "For JSPs, (GNLA) is compared against the probabilistic makespan results provided by Beck and Wilson (2007). For the benchmark problems, we consider the instances generated using an existing generator in the work of Watson, Barbulescu, Whitley, and Howe (2002) with durations drawn uniformly from the interval [1,99]. Specifically, we focus on three sets of probabilistic JSPs of size {4\u00d74,6\u00d76,10\u00d710} (where a 4\u00d74 problems consists of 4 jobs consisting of 4 activities each) and for each set, three uncertainty levels {0.1,0.5,1} are considered."}, {"heading": "7.2 Comparison between SLA and GNLA", "text": "We first compare the average robust makespan of 270 problem instances obtained by robust local search that is guided by our decision rule approximations proposed in Section 3.1 and Section 3.2. We refer to the robust makespan computed using SLA as S\u2217 and using GNLA as G\u2217. Figure 6 provides these results for all three sets of RCPSP/max problems with durational uncertainty. In these results, we show how the robust makespan is affected by the level of risk \u03b5 and the standard deviation \u03c3 of duration uncertainty. X-axis represents different combinations of risk and standard deviation of durational uncertainty, as shown in the table of Figure 6. All runs on every instance takes a couple of seconds and hence we do not report CPU times here. The key observations and conclusions of interest from Figure 6 are as follows:\n\u2022 Irrespective of the \u03c3, as the level of risk \u03b5 increases, the robust makespan decreases with both SLA and GNLA. Clearly, the lower risk that the planner is willing to take, the higher is the robust value of the generated execution strategy. Our method is capable of quantifying this trade off, which can help the planner to decide on the desired strategies.\n\u2022 Irrespective of \u03b5, as the degree of duration variability \u03c3 increases, the robust makespan increases with both SLA and GNLA, and the value becomes more sensitive to \u03c3 when the level of risk is constrained to a small value (e.g. \u03b5 = 0.01).\n\u2022 For lower values of \u03b5, more specifically for 0.01, S\u2217 provides lower values of robust makespan than G\u2217. On the other hand, for higher values of \u03b5 \u2208 {0.05, 0.1, 0.2}, G\u2217 provides superior performance to S\u2217. We do not yet understand the reason for drop in performance for \u03b5 = 0.01, but this is observed consistently across all the RCPSP/max benchmark problems.\nFor each problem instance, we also observe some monotonicity between the absolute difference of robust makespan S\u2217 and G\u2217 and risk values. When the level of risk \u03b5 takes a value around 0.02, S\u2217 (SLA) has a slightly lower value than G\u2217 (GNLA). However, when risk becomes more than 0.02, the superiority of GNLA increases with higher values of risk. Figure 7 illustrates this on a randomly picked J10 instance with \u03c3 = 1 and \u03c3 = 2. The same pattern is observed across all problem instances of J10, J20 and J30.\nNext, in Figure 8, we compare the quality of the execution strategies obtained by using SLA and GNLA. More precisely, we compare the distributions of the actual makespans of schedules computed using these decision rule approximations. For this purpose, we generate a set of 100 samples of realizations of durational uncertainty and test with all 270 instances of each benchmark set with different levels of risk \u03b5 = 0.2, \u03b5 = 0.1 and \u03b5 = 0.05 to obtain the respective POS, and then compute the actual makespans of schedules derived from the respective POS under the given realization samples. This difference between real makespans obtained from POSs generated by two different decision rule approximations was observed across the board in all examples of the three sets for all values of \u03b5 except 0.01. We randomly select three problem instances from each benchmark set and present the results in Figure 8. Figure 8 also compares the cumulative frequency distributions of the actual makespans. We observe that GNLA provided far better realized makespans than SLA - both in absolute terms, as well as distributionally. For J20, except in 2 cases, rest of the actual makespan\nvalues obtained by SLA were higher than the ones obtained by GNLA. Similar trends were observed for J10 and J30.\nTo illustrate the difference of quality in absolute of the two upper bounds, we provide four lines (computed S\u2217, actual S\u2217, computed G\u2217 and actual G\u2217) indicating the upper bounds computed using the algorithms and in simulation over the 100 samples."}, {"heading": "7.3 Comparing Robust Local Search Enhancements", "text": "Since, we have already shown GNLA performs better than SLA, we will only show the performance of our enhancements over GNLA in this section. It should be noted that enhancements over SLA provided similar results and conclusions with GNLA based enhancements outperforming SLA based enhancements. Since \u201dOrdering Generation\u201d heuristic requires additional rounds of robust makespan computation, we also include a benchmark called (GNLA+) (which is GNLA plus extra iterations of local search) to make a fair comparison. To avoid the complexity of considering all pairs of activities, we only consider those pairs of activities where ordering would improve performance. We proposed the Pairs-Selection heuristic to select these pairs of activities. The number of extra iterations of local search for the (GNLA+) benchmark is \u201dthe number of activity pairs picked by the Pairs-Selection heuristic\u201d times \u201dthe number of samples m used in the Ordering Generation process\u201d. The experimental results shows that the average number of activity pairs of all 270 instances selected under the Pairs-Selection heuristic for J10, J20 and J30 are 5, 14, and 28 respectively. In our work, we set m = 100. Thus, the extra iterations of the (GNLA+) benchmark for J10, J20 and J30 are 500, 1400 and 2800, respectively. The performance of all our enhancements is shown in Figure 9(a), Figure 9(b), Figure 9(c) for J10, J20 and J30 respectively. In all the charts, \u03b5 is represented on the X-axis and robust makespan on the Y-axis. So, lower values are better on the Y-axis.\nGiven below are some key observations and conclusions made from the results:\n\u2022 Irrespective of the durational uncertainty, (GNLA+RC) and (GNLA+OG) provide better robust makespan values than both (GNLA) and (GNLA+) for J10 and J30. This indicates that the new Robustness Feedback Chaining heuristic and the Order Determination are able to provide more robust partial ordered schedules for J10 and J30. This improvement seems to increase further with more number of activities, i.e. the difference is more obvious for instances in J30 than in J10. Furthermore, the difference is consistently observed across all the problems. However, the improvement is not consistent for J20 and there are cases where (GNLA+RC) and (GNLA+OG) did not out perform (GNLA) and (GNLA+). For instance in J20 problems, (GNLA+) provides better performance than (GNLA+RC) and (GNLA+OG) for \u03b5 = 0.01 and \u03c3 = 1.5.\n\u2022 The extra iterations of local search in (GNLA+) do not improve the solution quality much for J10. However, it improves the solution quality for J20 and J30. This could be because the optimal solution is obtained within 1000 iterations for the smaller problems.\n\u2022 In most cases, (GNLA+RC+OG) provides the lowest robust makespan among all the enhancements. Thus, the OG and RC enhancements in combination do not degrade\n(a) Results of J10\n(b) Results of J20\nthe performance improvement obtained individually. In some cases, the difference is significant such as in J10 for \u03c3 = 0.1 and \u03b5 = 0.01. On the other hand, there are cases where (GNLA+RC+OG) does not provide the lowest robust makespan, such as in J20 for \u03c3 = 0.5 and \u03b5 = 0.01."}, {"heading": "7.4 Comparing on JSPs with Durational Uncertainty", "text": "In this section, we compare the performance of our GNLA approach (referred to as G\u2217) with the best known solver for Job Shop Scheduling Problems proposed by Beck and Wilson (2007) (referred to as CB). For a fair comparison of the two approaches, we employ the Mean Normalized Makespan (MNPM) metric defined by Beck and Wilson:\nMNPM(a, L) = 1 |L|\n\u2211\nl\u2208L\nD(a, l) Dlb(l)\n(58)\nwhere L is a set of problem instances, D(a, l) is the probabilistic makespan (i.e., robust makespan in our work) for instance l by algorithm a generated by Monte Carlo simulation, Dlb(l) is a lower bound on the probabilistic makespan.\nWe denote the best MNPM values aross different algorithms reported by Beck and Wilson as CB. We compare them with the MNPM values in our work which are obtained by replacing D(a, l) in Eqn 58 with an upper bound of robust makespan from the POS generated from GNLA-guided local search. All runs on 4\u00d7 4 and 6\u00d7 6 instances took less than a minute, while 10\u00d7 10 instances took about 15 minutes.\nTable 2 provides the results. The performance of our solver is comparable to CB solver across all problem instances. This comparison illustrates that our local search mechanism is generic (different types of scheduling problems) and is also able to provide performance on par with near optimal approaches. While the performance is comparable, CB provides better MNPM values than our approach due to the following key reasons: (a) Our approach does not exploit the structure specific to JSPs (jobs consisting of a sequence of operations). We hope to improve our approach to exploit this in the near future. (b) Our robust local search reasons with upper bounds (due to Chebyshev inequality), which can be loose."}, {"heading": "8. Related Work", "text": "The Resource-Constrained Project Scheduling Problem with minimum and maximum time lags, RCPSP/max, (or known as the Resource-Constrained Project Scheduling Problem with Generalized Precedence Relations, RCPSP-GSR) is a strongly NP-hard combinatorial optimization problem; and even the decision problem of determining whether an\nRCPSP/max instance has a feasible solution or not is NP-complete (Bartusch et al., 1988). A survey of recent developments and new applications for RCPSP/max has been given by Neumann, Schwindt, and Zimmermann (2006).\nHowever, we did not find much study that considers RCPSP/max under uncertainty. One such paper dealing with variable durations on RCPSP/max is done by Lombardi and Milano (2009), where activity durations range between given lower and upper bounds. A precedence constraint posting approach (Policella, Cesta, Oddi, & Smith, 2007) was adopted. Whereas in our work, we consider RCPSP/max with durational uncertainty where each activity duration is modeled as a random variable with known mean and variance values.\nResearch on scheduling under uncertainty has received much attention in both Artificial Intelligence and Operations Research communities. For a complete survey of recent AI papers on robust project scheduling up to 2004, one may refer to the work of Herroelen and Leus (2005) and of production scheduling (Aytug, Lawley, McKay, Mohan, & Uzsoy, 2005). Broadly, one may classify the techniques to tackle scheduling with uncertainty into two categories: Proactive Scheduling is to design a priori schedule or a schedule policy that take into account the possible uncertainty that may occur; Reactive Scheduling modifies or re-optimizes the baseline schedule when an unexpected event occurs. Here our interest is on proactive scheduling and we are concerned with robust scheduling which focuses on obtaining proactive schedules that maintain a high level of performance against uncertainty.\nThe main idea of proactive techniques is to build a global solution which hopefully does not need to be revised at execution time. One can divide the research in this area into three categories, according to how and when the information of uncertainties can be taken into account in generating more robust and stable schedules than they would be without using this information (Bidot, Vidal, Laborie, & Beck, 2009): 1. generating one complete generic schedule which is proved to execute correctly in most scenarios arising during execution; 2. generating a flexible solution in which some decisions are postponed to be made until execution; 3. generating a conditional solution in which mutually exclusive decisions are developed,the one being chosen dependent on some observations during execution, like markov decision processes. In the following, we briefly look at the first two cases since they are related to our work."}, {"heading": "8.1 Generating Generic Schedule", "text": "A first method for making a generic schedule that is insensitive to online perturbations is to produce a complete and robust schedule by taking into account all possible scenarios, i.e. a schedule with strong controllability (Vidal & Fargier, 1999). Rather than dealing with execution with 100% confidence, probabilistic techniques have been proposed that build schedules with a probabilistic guarantee against a threshold value of an optimization metric such as makespan. Another example of such generic schedule generation is fuzzy scheduling (Herroelen & Leus, 2005): instead of stochastic variables and probabilistic distributions, fuzzy set scheduling use fuzzy numbers for modeling uncertainties based on possibility theory; a recent work by Rodr\u0301\u0131guez et al. (2009) modeled uncertain durations as fuzzy numbers and improved local search to solve the Job Shop Scheduling Problem. In the following,\nwe provide further details on the work related to strong controllability and probabilistic techniques."}, {"heading": "8.1.1 Strong Controllable Techniques", "text": "Strong Controllability was introduced by Vidal and Fargier (1999) over Simple Temporal Networks with Uncertainty (STNU) for which controllability is achievable in polynomial time. With the existence of uncontrollable events that are controlled by exogenous factors, often referred to as Nature, an STNU is strongly controllable if there exists at least one universal schedule that suits any situation. Such schedule might be computed off-line beforehand. Strong controllability is the strictest form of STNU. A strongly controllable network means that the schedule can be executed without regard to the contingent events. It is useful in applications where contingent events cannot be observed exactly."}, {"heading": "8.1.2 Probabilistic Techniques", "text": "Instead of generating a global solution suitable for all realizations of uncertainties, probabilistic techniques build a schedule that has a probabilistic guarantee of a deterministic optimization measure with respect to a threshold value, e.g., find the schedule with the highest probability that the project makespan will not exceed a particular value.\nDaniels and Carrillo (1997) defined a \u03b2-robust schedule as one that has maximum probability of achieving a given performance level, e.g., the total flow time is no greater than a given threshold. They presented branch-and-bound and heuristic techniques to find a robust schedule in a one-machine manufacturing context that performs the best within a given confidence level. As for the Job Shop Scheduling Problem, Beck and Wilson (2007) consider activity durations as random variables; given a level of risk 0 \u2264 \u03b1 \u2264 1, they are interested in a solution of minimal (probabilistic) makespan which has a probability of execution of at least 1\u2212 \u03b1."}, {"heading": "8.2 Generating Flexible Schedule", "text": "Another way of producing robust schedule taking into account of uncertainty is to introduce flexibility into the schedule. The idea is that only a subset of decisions are made offline and the rest are postponed to be made online, so that decisions are only made when information becomes more precise and certain (Bidot et al., 2009). In the following, we discuss three subcategories of works that deal with generating flexible schedules."}, {"heading": "8.2.1 Dynamic Controllable Techniques", "text": "An STNU is Dynamic Controllable (Vidal & Fargier, 1999) if there exists a solution that can always be instantiated incrementally based on the outcomes of contingent edges in the past. An execution strategy using dynamic controllability is needed to produce an incremental solution based on the subsequent revelation of contingent events. Morris and Muscettola (2005) proposed a pseudo-polynomial algorithm to handle dynamic controllability of STNUs based on constraint satisfaction. Techniques were proposed by Wah and Xin (2004) to optimize the bounds on durations of contingent edges such that the resulting STNU is dynamic controllable."}, {"heading": "8.2.2 Redundancy-based Techniques", "text": "Redundancy-based scheduling is another proactive technique for scheduling. The idea is to generate a schedule that includes the allocation of extra resources and/or time in the schedule so that these buffers will help absorb the impact of unexpected events without rescheduling during execution. Davenport, Gefflot, and Beck (2001) proposed techniques for generating robust schedules based on the insertion of temporal slacks to critical activities that are allocated on possibly breakable resources. Lambrechts, Demeulemeester, and Herroelen (2010) analytically determined the expected increase in activity duration due to resource breakdown. Based on this information, simulation-based time buffering was used to protect the schedule from disruptions caused by resource availability."}, {"heading": "8.2.3 Partial Order Schedule (POS)", "text": "Even with buffering, baseline schedules may become brittle in face of unpredictable execution dynamics and can quickly get invalidated. Instead of baseline schedule, another line of work is to consider design of good schedule policies. One such example is the notion of Partial Order Schedules (POS) defined by Policella et al. (2004) which seeks to retain temporal flexibility whenever the problem constraints allow it and can often absorb unexpected deviation from predictive assumptions. They considered robustness measures such as fluidity and flexibility. Generating POS is another example of such flexible approaches: a subset of sequencing decisions are made offline and the remaining decisions are made online by using a dispatching rule (Bidot et al., 2009). Different methods of generating POS were compared in terms of the robustness of the resulting schedules in the work of Rasconi, Cesta, and Policella (2010). In our work, we apply the concept of POS as the execution policy. Given an RCPSP/max instance, mean and variance values of the segregated variables of data perturbations and the level of risk, the objective of our work is to determine POS with a locally minimal robust value."}, {"heading": "8.3 Scenario-based Optimization in Scheduling", "text": "Another line of work that deals with scheduling under uncertainty is based on the use of scenarios (scenario-based optimization). For example, Kouvelis, Daniels, and Vairaktarakis (2000) introduced the concept of robustness into scheduling problems. They considered uncertain processing times and proposed methods to generate a robust schedule based on the maximum absolute deviation between the robust solution against all possible scenarios in a given scenario set. A shortcoming of this kind of approach is that all scenarios are assumed to be known in advance, and that the scenario space is usually exponentially large. Noteworthy of mention are the two notions of solution robustness and quality robustness, where solution robustness (or stability) refers to the insensitivity of actual start times, whereas quality robustness refers to the insensitivity of solution quality (i.e. makespan) to different scenarios (Herroelen & Leus, 2005). Another pioneering scenario-based optimization work is by Mulvey, Vanderbei, and Zenios (1995) which handles the tradeoff between solution robustness (if a solution remains close to the optimal for all scenarios) and model robustness (if a solution remains feasible for most scenarios)."}, {"heading": "8.4 Robust Optimization in Scheduling", "text": "A recent development in Operations Research saw the potential of applying the concept of Robust Optimization to deal with uncertainty. Ben-Tal and Nemirovski (2002) and Bertsimas and Sim (2003) proposed robust optimization models where no assumptions of the underlying probability distribution of data are needed. The idea is often to approximate data uncertainty by a tractable (convex) uncertainty set, and optimization is performed on that set. This results in a robust counterpart formulation as a conic (such as second-order cone) optimization problem which can be solved in polynomial time. However, only a few works have been reported in the literature on applying robust optimization to scheduling, due mainly to a high-degree combinational nature of the problem. One such application is the process scheduling problem in chemical engineering, such as the works by Janak, Lin, and Floudas (2007) and Li and Ierapetritou (2008). A notable recent breakthrough in robust optimization on tractable approximation models to solve stochastic optimization problems is found by Chen et al. (2008). This work makes use of linear segregated decision rules that are relevant to solving combinatorial scheduling problems with durational uncertainty and our work exploit this mechanism and incorporate it into local search."}, {"heading": "9. Conclusion", "text": "Given a level of risk 0 < \u03b5 \u2264 1 chosen by the planner, we investigated the problem of finding the minimum (1\u2212 \u03b5)-guaranteed makespan (i.e. Robust Makespan) and proposed methods to find a schedule policy (POS) such that when uncertainty is dynamically realized, the execution policy will result in a solution whose value is as good as robust makespan. We first put forward a new decision rule utilized in scheduling to help specify the start times for all activities with respect to execution policy and dynamic realizations of data uncertainty. Based on the decision rule, new fitness function was then derived to evaluate robustness, which was finally integrated into a local search framework to produce the solution with robust makespan. Experimental results illustrate the improved performance of local search with the new fitness evaluation, which provider tighter bounds on robust makespan and better partial order schedules compared to the existing method.\nFor simplicity we have adopted an upper bound approach where we assume independence among the durational uncertainties. One future work is to treat correlations between durational uncertainties, since a task duration could be correlated with some others in real life. For example, correlations occur when an external event is not peculiar to a single task, but more universal, such as weather conditions, seasonal peaks. In such situations, the durational delays are correlated in the same direction. When this occurs, the decision rules proposed in this paper break down unfortunately, since even if the covariances of pairs of duration variables are given, it is very complex to analytically model the extent to which one duration and any combination (resulting from SUM and MAX operators) of other durations change together. This in turn complicates the analysis on the variance of the makespan variable, and hence the robust makespan. Extending our work to handle covariances is an interesting future direction."}, {"heading": "Acknowledgments", "text": "This paper extends previous research by Lau, Ou, and Xiao (2007) and Fu, Varakantham, and Lau (2010). The authors wish to thank all reviewers for their insightful comments."}], "references": [{"title": "Executing production schedules in the face of uncertainties: A review and some future directions", "author": ["H. Aytug", "M.A. Lawley", "K. McKay", "S. Mohan", "R. Uzsoy"], "venue": "In European Journal of Operational Research,", "citeRegEx": "Aytug et al\\.,? \\Q2005\\E", "shortCiteRegEx": "Aytug et al\\.", "year": 2005}, {"title": "Scheduling project networks with resource constraints and time windows", "author": ["M. Bartusch", "R.H. Mohring", "F.J. Radermacher"], "venue": "Annals of Operations Research,", "citeRegEx": "Bartusch et al\\.,? \\Q1988\\E", "shortCiteRegEx": "Bartusch et al\\.", "year": 1988}, {"title": "Proactive algorithms for job shop scheduling with probabilistic durations", "author": ["J.C. Beck", "N. Wilson"], "venue": "Journal of Artificial Intelligence Research,", "citeRegEx": "Beck and Wilson,? \\Q2007\\E", "shortCiteRegEx": "Beck and Wilson", "year": 2007}, {"title": "Robust optimization - methodology and applications", "author": ["A. Ben-Tal", "A. Nemirovski"], "venue": "Mathematical Programming,", "citeRegEx": "Ben.Tal and Nemirovski,? \\Q2002\\E", "shortCiteRegEx": "Ben.Tal and Nemirovski", "year": 2002}, {"title": "Robust discrete optimization and network flows", "author": ["D. Bertsimas", "M. Sim"], "venue": "Mathematical Programming,", "citeRegEx": "Bertsimas and Sim,? \\Q2003\\E", "shortCiteRegEx": "Bertsimas and Sim", "year": 2003}, {"title": "A theoretic and practical framework for scheduling in a stochastic environment", "author": ["J. Bidot", "T. Vidal", "P. Laborie", "J.C. Beck"], "venue": "Journal of Scheduling,", "citeRegEx": "Bidot et al\\.,? \\Q2009\\E", "shortCiteRegEx": "Bidot et al\\.", "year": 2009}, {"title": "A linear decision-based approximation approach to stochastic programming", "author": ["X. Chen", "M. Sim", "P. Sun", "J. Zhang"], "venue": "Operations Research,", "citeRegEx": "Chen et al\\.,? \\Q2008\\E", "shortCiteRegEx": "Chen et al\\.", "year": 2008}, {"title": "The Greatest of a Finite Set of Random Variables", "author": ["C.E. Clark"], "venue": "Operations Research,", "citeRegEx": "Clark,? \\Q1961\\E", "shortCiteRegEx": "Clark", "year": 1961}, {"title": "Beta-robust scheduling for single-machine systems with uncertain processing times", "author": ["R. Daniels", "J. Carrillo"], "venue": "IIE Transactions,", "citeRegEx": "Daniels and Carrillo,? \\Q1997\\E", "shortCiteRegEx": "Daniels and Carrillo", "year": 1997}, {"title": "Slack-based techniques for robust schedules", "author": ["A.J. Davenport", "C. Gefflot", "J.C. Beck"], "venue": "In Proceedings of the 6th European Conferences on Planning (ECP)", "citeRegEx": "Davenport et al\\.,? \\Q2001\\E", "shortCiteRegEx": "Davenport et al\\.", "year": 2001}, {"title": "Approximating the stochastic knapsack problem: The benefit of adaptivity", "author": ["B.C. Dean", "M.X. Goemans", "J. Vondr\u00e1k"], "venue": "In FOCS,", "citeRegEx": "Dean et al\\.,? \\Q2004\\E", "shortCiteRegEx": "Dean et al\\.", "year": 2004}, {"title": "Project scheduling : a research handbook", "author": ["E.L. Demeulemeester", "W.S. Herroelen"], "venue": null, "citeRegEx": "Demeulemeester and Herroelen,? \\Q2002\\E", "shortCiteRegEx": "Demeulemeester and Herroelen", "year": 2002}, {"title": "Towards finding robust execution strategies for rcpsp/max with durational uncertainty", "author": ["N. Fu", "P. Varakantham", "H.C. Lau"], "venue": "In Proceedings of International Conference on Automated Planning and Scheduling (ICAPS),", "citeRegEx": "Fu et al\\.,? \\Q2010\\E", "shortCiteRegEx": "Fu et al\\.", "year": 2010}, {"title": "Computational complexity of pert problems", "author": ["J.N. Hagstrom"], "venue": "Networks, 18,", "citeRegEx": "Hagstrom,? \\Q1988\\E", "shortCiteRegEx": "Hagstrom", "year": 1988}, {"title": "Project scheduling under uncertainty: Survey and research potentials", "author": ["W. Herroelen", "R. Leus"], "venue": "In European Journal of Operational Research,", "citeRegEx": "Herroelen and Leus,? \\Q2005\\E", "shortCiteRegEx": "Herroelen and Leus", "year": 2005}, {"title": "A new robust optimization approach for scheduling under uncertainty :ii. uncertainty with known probability distribution", "author": ["S. Janak", "X. Lin", "C. Floudas"], "venue": "Computers and Chemical Engineering,", "citeRegEx": "Janak et al\\.,? \\Q2007\\E", "shortCiteRegEx": "Janak et al\\.", "year": 2007}, {"title": "Experimental investigation of heuristics for resourceconstrained project scheduling: An update", "author": ["R. Kolisch", "S. Hartmann"], "venue": "European Journal of Operational Research", "citeRegEx": "Kolisch and Hartmann,? \\Q2005\\E", "shortCiteRegEx": "Kolisch and Hartmann", "year": 2005}, {"title": "Benchmark Instances for Project Scheduling Problems, pp. 197\u2013212", "author": ["R. Kolisch", "C. Schwindt", "A. Sprecher"], "venue": null, "citeRegEx": "Kolisch et al\\.,? \\Q1998\\E", "shortCiteRegEx": "Kolisch et al\\.", "year": 1998}, {"title": "Robust scheduling of a two-machine flow shop with uncertain processing times", "author": ["P. Kouvelis", "R.L. Daniels", "G. Vairaktarakis"], "venue": "IIE Transactions,", "citeRegEx": "Kouvelis et al\\.,? \\Q2000\\E", "shortCiteRegEx": "Kouvelis et al\\.", "year": 2000}, {"title": "Time slack-based techniques for robust project scheduling subject to resource uncertainty. Open access publications from katholieke universiteit leuven urn:hdl:123456789/272147", "author": ["O. Lambrechts", "E. Demeulemeester", "W. Herroelen"], "venue": null, "citeRegEx": "Lambrechts et al\\.,? \\Q2010\\E", "shortCiteRegEx": "Lambrechts et al\\.", "year": 2010}, {"title": "Robust local search and its application to generating robust schedules", "author": ["H.C. Lau", "T. Ou", "F. Xiao"], "venue": "In Proceedings of International Conference on Automated Planning and Scheduling (ICAPS),", "citeRegEx": "Lau et al\\.,? \\Q2007\\E", "shortCiteRegEx": "Lau et al\\.", "year": 2007}, {"title": "Robust optimization for process scheduling under uncertainty", "author": ["Z. Li", "M.G. Ierapetritou"], "venue": "Industrial and Engineering Chemistry Research,", "citeRegEx": "Li and Ierapetritou,? \\Q2008\\E", "shortCiteRegEx": "Li and Ierapetritou", "year": 2008}, {"title": "A precedence constraint posting approach for the rcpsp with time lags and variable durations", "author": ["M. Lombardi", "M. Milano"], "venue": "In Proceedings of the 15th international conference on Principles and practice of constraint programming,", "citeRegEx": "Lombardi and Milano,? \\Q2009\\E", "shortCiteRegEx": "Lombardi and Milano", "year": 2009}, {"title": "Scheduling under uncertainty: Bounding the makespan distribution", "author": ["R.H. M\u00f6hring"], "venue": "In Computational Discrete Mathematics,", "citeRegEx": "M\u00f6hring,? \\Q2001\\E", "shortCiteRegEx": "M\u00f6hring", "year": 2001}, {"title": "Linear preselective policies for stochastic project scheduling", "author": ["R.H. Mohring", "F. Stork"], "venue": "Mathematical Methods of Operations Research,", "citeRegEx": "Mohring and Stork,? \\Q2000\\E", "shortCiteRegEx": "Mohring and Stork", "year": 2000}, {"title": "Temporal dynamic controllability revisited", "author": ["P. Morris", "N. Muscettola"], "venue": "In Proceedings of the 20th National Conference on Artificial Intelligence,", "citeRegEx": "Morris and Muscettola,? \\Q2005\\E", "shortCiteRegEx": "Morris and Muscettola", "year": 2005}, {"title": "Robust optimization of large-scale systems", "author": ["J.M. Mulvey", "R.J. Vanderbei", "S.J. Zenios"], "venue": "Operations Research,", "citeRegEx": "Mulvey et al\\.,? \\Q1995\\E", "shortCiteRegEx": "Mulvey et al\\.", "year": 1995}, {"title": "Resource-constrained project scheduling with time windows", "author": ["K. Neumann", "C. Schwindt", "J. Zimmermann"], "venue": "International Series in Operations Research and Management Science,", "citeRegEx": "Neumann et al\\.,? \\Q2006\\E", "shortCiteRegEx": "Neumann et al\\.", "year": 2006}, {"title": "From precedence constraint posting to partial order schedules: A csp approach to robust scheduling", "author": ["N. Policella", "A. Cesta", "A. Oddi", "S.F. Smith"], "venue": "AI Communications,", "citeRegEx": "Policella et al\\.,? \\Q2007\\E", "shortCiteRegEx": "Policella et al\\.", "year": 2007}, {"title": "Generating robust schedules through temporal flexibility", "author": ["N. Policella", "S.F. Smith", "A. Cesta", "A. Oddi"], "venue": "In Proceedings of International Conference on Automated Planning and Scheduling (ICAPS),", "citeRegEx": "Policella et al\\.,? \\Q2004\\E", "shortCiteRegEx": "Policella et al\\.", "year": 2004}, {"title": "Validating scheduling approaches against executional uncertainty", "author": ["R. Rasconi", "A. Cesta", "N. Policella"], "venue": "Journal of Intelligent Manufacturing,", "citeRegEx": "Rasconi et al\\.,? \\Q2010\\E", "shortCiteRegEx": "Rasconi et al\\.", "year": 2010}, {"title": "Improved local search for job shop scheduling with uncertain durations", "author": ["I.G. Rod\u0155\u0131guez", "C.R. Vela", "J. Puente", "A. Hern\u00e1ndez-Arauzo"], "venue": "In Proceedings of International Conference on Automated Planning and Scheduling (ICAPS)", "citeRegEx": "Rod\u0155\u0131guez et al\\.,? \\Q2009\\E", "shortCiteRegEx": "Rod\u0155\u0131guez et al\\.", "year": 2009}, {"title": "Handling contingency in temporal constraint networks: from consistency to controllabilities", "author": ["T. Vidal", "H. Fargier"], "venue": "Journal of Experimental and Theoretical Artificial Intelligence,", "citeRegEx": "Vidal and Fargier,? \\Q1999\\E", "shortCiteRegEx": "Vidal and Fargier", "year": 1999}, {"title": "A classification of predictivereactive project scheduling procedures", "author": ["S. Vonder", "E. Demeulemeester", "W. Herroelen"], "venue": "Journal of Scheduling,", "citeRegEx": "Vonder et al\\.,? \\Q2007\\E", "shortCiteRegEx": "Vonder et al\\.", "year": 2007}, {"title": "Optimization of bounds in temporal flexible planning with dynamic controllability", "author": ["B.W. Wah", "D. Xin"], "venue": "IEEE International Conference on Tools with Artificial Intelligence,", "citeRegEx": "Wah and Xin,? \\Q2004\\E", "shortCiteRegEx": "Wah and Xin", "year": 2004}, {"title": "Contrasting structured and random permutation flow-shop scheduling problems: Search-space topology and algorithm performance", "author": ["Watson", "J.-P", "L. Barbulescu", "L.D. Whitley", "A.E. Howe"], "venue": "INFORMS Journal on Computing,", "citeRegEx": "Watson et al\\.,? \\Q2002\\E", "shortCiteRegEx": "Watson et al\\.", "year": 2002}, {"title": "Scheduling with uncertain durations: Modeling beta-robust scheduling with constraints", "author": ["C.W. Wu", "K.N. Brown", "J.C. Beck"], "venue": "Computers and Operations Research,", "citeRegEx": "Wu et al\\.,? \\Q2009\\E", "shortCiteRegEx": "Wu et al\\.", "year": 2009}], "referenceMentions": [{"referenceID": 13, "context": "For example, in the infinite-resource project scheduling problem where processing times have two possible discrete values, the problem of computing the expected makespan (or any point on the cumulative distribution of the optimal makespan), is #P-hard (Hagstrom, 1988; M\u00f6hring, 2001).", "startOffset": 252, "endOffset": 283}, {"referenceID": 23, "context": "For example, in the infinite-resource project scheduling problem where processing times have two possible discrete values, the problem of computing the expected makespan (or any point on the cumulative distribution of the optimal makespan), is #P-hard (Hagstrom, 1988; M\u00f6hring, 2001).", "startOffset": 252, "endOffset": 283}, {"referenceID": 21, "context": ", the paper by Mohring and Stork (2000), is to design schedule policies that provide online decision rules such that at time t, the policy decides which task(s) may start and which resource(s) to assign.", "startOffset": 15, "endOffset": 40}, {"referenceID": 8, "context": "Daniels and Carrillo (1997) consider a one-machine scheduling problem with probabilistic durations, with an objective to capture the likelihood that a schedule yields actual performance no worse than a given target level.", "startOffset": 0, "endOffset": 28}, {"referenceID": 2, "context": "Thus, we compute an upper bound on makespan values as opposed to lower bound computation in the work of Beck and Wilson (2007). More specifically, we make three key contributions in this paper.", "startOffset": 104, "endOffset": 127}, {"referenceID": 3, "context": "1 Definitions and Notations As given by Ben-Tal and Nemirovski (2002), we also classify the variables in a stochastic optimization problem into 2 types: Adjustable and Non-Adjustable variables.", "startOffset": 40, "endOffset": 70}, {"referenceID": 1, "context": "The RCPSP/max problem (Bartusch et al., 1988) consists of N activities {a1, a2.", "startOffset": 22, "endOffset": 45}, {"referenceID": 1, "context": "start-to-end, end-to-end, end-to-start time lags can be easily transformed to the general start-to-start time lags for the deterministic case as given by Bartusch et al. (1988). A schedule ss = (st(a1), st(a2), .", "startOffset": 154, "endOffset": 177}, {"referenceID": 29, "context": "In the following sections, we introduce the Partial Order Schedule (POS) (Policella et al., 2004), which serves as an execution strategy of the scheduling project.", "startOffset": 73, "endOffset": 97}, {"referenceID": 28, "context": "A Partial Order Schedule (POS) was first proposed by Policella et al. (2004). It is defined as a set of activities, which are partially ordered such that any schedule with total activity order that is consistent with the partial order is resource and time feasible.", "startOffset": 53, "endOffset": 77}, {"referenceID": 28, "context": "In the following, we describe the basic chaining algorithm proposed by Policella et al. (2004). In this algorithm, a feasible schedule is first obtained using a simple greedy heuristic.", "startOffset": 71, "endOffset": 95}, {"referenceID": 3, "context": "An example is the linear decision rule framework proposed by Ben-Tal and Nemirovski (2002), where the setting value of an adjustable decision variable S\u0303(x, z\u0303) is assumed to be affinely dependent on a subset of the N number of primitive random variables:", "startOffset": 61, "endOffset": 91}, {"referenceID": 6, "context": "Another example is the segregated linear decision rule framework proposed by Chen et al. (2008), where each adjustable decision variable is assumed to be affinely dependent on a set of some N segregated random variables { z\u0303 1 , z\u0303 \u2212 1 , .", "startOffset": 77, "endOffset": 96}, {"referenceID": 3, "context": "As we will show below, a segregated linear decision rule allows us to easily obtain an upper bound on a subset of random variables (see Eqn 14), which is not possible in the linear decision rule framework proposed by Ben-Tal and Nemirovski (2002). Given the mean and variance for each segregated variable E(z\u0303 k ) = E(z\u0303 \u2212 k ) = \u03bck , V ar(z\u0303 k ) = \u03c3 2 pk and V ar(z\u0303 \u2212 k ) = \u03c3 2 mk , we can express the expected value and variance of any adjustable variable as:", "startOffset": 217, "endOffset": 247}, {"referenceID": 6, "context": "Compared with other linear decision rules (Ben-Tal & Nemirovski, 2002), the superiority of SLA (Chen et al., 2008) lies in this ability to linearly express an upper bound on a subset of random variables by dissecting each uncertainty into its positive and negative components.", "startOffset": 95, "endOffset": 114}, {"referenceID": 7, "context": "z\u0303i \u223c N(0, \u03c3), we know from the work of Clark (1961) that there is a closed form representation for the expected value of the maximum when k = 2:", "startOffset": 40, "endOffset": 53}, {"referenceID": 28, "context": "After finding a feasible schedule, a POS will be generated by applying the chaining procedure proposed by Policella et al. (2004). Then, the S\u2217 (or G\u2217 by GNLA) value will be computed according to the POS.", "startOffset": 106, "endOffset": 130}, {"referenceID": 28, "context": "Since our objective is makespan-related and time becomes a concern, we build on the work of Policella et al. (2009) and pick the first available chain wherever available.", "startOffset": 92, "endOffset": 116}, {"referenceID": 17, "context": "The problems considered for RCPSP/max with durational uncertainty were obtained by extending the three benchmark sets available for RCPSP/max problems, J10, J20 and J30 as specified in the PSPLib (Kolisch et al., 1998).", "startOffset": 196, "endOffset": 218}, {"referenceID": 2, "context": "For JSPs, (GNLA) is compared against the probabilistic makespan results provided by Beck and Wilson (2007). For the benchmark problems, we consider the instances generated using an existing generator in the work of Watson, Barbulescu, Whitley, and Howe (2002) with durations drawn uniformly from the interval [1,99].", "startOffset": 84, "endOffset": 107}, {"referenceID": 2, "context": "For JSPs, (GNLA) is compared against the probabilistic makespan results provided by Beck and Wilson (2007). For the benchmark problems, we consider the instances generated using an existing generator in the work of Watson, Barbulescu, Whitley, and Howe (2002) with durations drawn uniformly from the interval [1,99].", "startOffset": 84, "endOffset": 260}, {"referenceID": 2, "context": "4 Comparing on JSPs with Durational Uncertainty In this section, we compare the performance of our GNLA approach (referred to as G\u2217) with the best known solver for Job Shop Scheduling Problems proposed by Beck and Wilson (2007) (referred to as CB).", "startOffset": 205, "endOffset": 228}, {"referenceID": 1, "context": "RCPSP/max instance has a feasible solution or not is NP-complete (Bartusch et al., 1988).", "startOffset": 65, "endOffset": 88}, {"referenceID": 1, "context": "RCPSP/max instance has a feasible solution or not is NP-complete (Bartusch et al., 1988). A survey of recent developments and new applications for RCPSP/max has been given by Neumann, Schwindt, and Zimmermann (2006). However, we did not find much study that considers RCPSP/max under uncertainty.", "startOffset": 66, "endOffset": 216}, {"referenceID": 1, "context": "RCPSP/max instance has a feasible solution or not is NP-complete (Bartusch et al., 1988). A survey of recent developments and new applications for RCPSP/max has been given by Neumann, Schwindt, and Zimmermann (2006). However, we did not find much study that considers RCPSP/max under uncertainty. One such paper dealing with variable durations on RCPSP/max is done by Lombardi and Milano (2009), where activity durations range between given lower and upper bounds.", "startOffset": 66, "endOffset": 395}, {"referenceID": 1, "context": "RCPSP/max instance has a feasible solution or not is NP-complete (Bartusch et al., 1988). A survey of recent developments and new applications for RCPSP/max has been given by Neumann, Schwindt, and Zimmermann (2006). However, we did not find much study that considers RCPSP/max under uncertainty. One such paper dealing with variable durations on RCPSP/max is done by Lombardi and Milano (2009), where activity durations range between given lower and upper bounds. A precedence constraint posting approach (Policella, Cesta, Oddi, & Smith, 2007) was adopted. Whereas in our work, we consider RCPSP/max with durational uncertainty where each activity duration is modeled as a random variable with known mean and variance values. Research on scheduling under uncertainty has received much attention in both Artificial Intelligence and Operations Research communities. For a complete survey of recent AI papers on robust project scheduling up to 2004, one may refer to the work of Herroelen and Leus (2005) and of production scheduling (Aytug, Lawley, McKay, Mohan, & Uzsoy, 2005).", "startOffset": 66, "endOffset": 1004}, {"referenceID": 31, "context": "Another example of such generic schedule generation is fuzzy scheduling (Herroelen & Leus, 2005): instead of stochastic variables and probabilistic distributions, fuzzy set scheduling use fuzzy numbers for modeling uncertainties based on possibility theory; a recent work by Rod\u0155\u0131guez et al. (2009) modeled uncertain durations as fuzzy numbers and improved local search to solve the Job Shop Scheduling Problem.", "startOffset": 275, "endOffset": 299}, {"referenceID": 32, "context": "Strong Controllability was introduced by Vidal and Fargier (1999) over Simple Temporal Networks with Uncertainty (STNU) for which controllability is achievable in polynomial time.", "startOffset": 41, "endOffset": 66}, {"referenceID": 7, "context": "Daniels and Carrillo (1997) defined a \u03b2-robust schedule as one that has maximum probability of achieving a given performance level, e.", "startOffset": 0, "endOffset": 28}, {"referenceID": 2, "context": "As for the Job Shop Scheduling Problem, Beck and Wilson (2007) consider activity durations as random variables; given a level of risk 0 \u2264 \u03b1 \u2264 1, they are interested in a solution of minimal (probabilistic) makespan which has a probability of execution of at least 1\u2212 \u03b1.", "startOffset": 40, "endOffset": 63}, {"referenceID": 5, "context": "The idea is that only a subset of decisions are made offline and the rest are postponed to be made online, so that decisions are only made when information becomes more precise and certain (Bidot et al., 2009).", "startOffset": 189, "endOffset": 209}, {"referenceID": 25, "context": "Morris and Muscettola (2005) proposed a pseudo-polynomial algorithm to handle dynamic controllability of STNUs based on constraint satisfaction.", "startOffset": 0, "endOffset": 29}, {"referenceID": 25, "context": "Morris and Muscettola (2005) proposed a pseudo-polynomial algorithm to handle dynamic controllability of STNUs based on constraint satisfaction. Techniques were proposed by Wah and Xin (2004) to optimize the bounds on durations of contingent edges such that the resulting STNU is dynamic controllable.", "startOffset": 0, "endOffset": 192}, {"referenceID": 5, "context": "Generating POS is another example of such flexible approaches: a subset of sequencing decisions are made offline and the remaining decisions are made online by using a dispatching rule (Bidot et al., 2009).", "startOffset": 185, "endOffset": 205}, {"referenceID": 27, "context": "One such example is the notion of Partial Order Schedules (POS) defined by Policella et al. (2004) which seeks to retain temporal flexibility whenever the problem constraints allow it and can often absorb unexpected deviation from predictive assumptions.", "startOffset": 75, "endOffset": 99}, {"referenceID": 5, "context": "Generating POS is another example of such flexible approaches: a subset of sequencing decisions are made offline and the remaining decisions are made online by using a dispatching rule (Bidot et al., 2009). Different methods of generating POS were compared in terms of the robustness of the resulting schedules in the work of Rasconi, Cesta, and Policella (2010). In our work, we apply the concept of POS as the execution policy.", "startOffset": 186, "endOffset": 363}, {"referenceID": 3, "context": "Ben-Tal and Nemirovski (2002) and Bertsimas and Sim (2003) proposed robust optimization models where no assumptions of the underlying probability distribution of data are needed.", "startOffset": 0, "endOffset": 30}, {"referenceID": 3, "context": "Ben-Tal and Nemirovski (2002) and Bertsimas and Sim (2003) proposed robust optimization models where no assumptions of the underlying probability distribution of data are needed.", "startOffset": 0, "endOffset": 59}, {"referenceID": 3, "context": "Ben-Tal and Nemirovski (2002) and Bertsimas and Sim (2003) proposed robust optimization models where no assumptions of the underlying probability distribution of data are needed. The idea is often to approximate data uncertainty by a tractable (convex) uncertainty set, and optimization is performed on that set. This results in a robust counterpart formulation as a conic (such as second-order cone) optimization problem which can be solved in polynomial time. However, only a few works have been reported in the literature on applying robust optimization to scheduling, due mainly to a high-degree combinational nature of the problem. One such application is the process scheduling problem in chemical engineering, such as the works by Janak, Lin, and Floudas (2007) and Li and Ierapetritou (2008).", "startOffset": 0, "endOffset": 769}, {"referenceID": 3, "context": "Ben-Tal and Nemirovski (2002) and Bertsimas and Sim (2003) proposed robust optimization models where no assumptions of the underlying probability distribution of data are needed. The idea is often to approximate data uncertainty by a tractable (convex) uncertainty set, and optimization is performed on that set. This results in a robust counterpart formulation as a conic (such as second-order cone) optimization problem which can be solved in polynomial time. However, only a few works have been reported in the literature on applying robust optimization to scheduling, due mainly to a high-degree combinational nature of the problem. One such application is the process scheduling problem in chemical engineering, such as the works by Janak, Lin, and Floudas (2007) and Li and Ierapetritou (2008). A notable recent breakthrough in robust optimization on tractable approximation models to solve stochastic optimization problems is found by Chen et al.", "startOffset": 0, "endOffset": 800}, {"referenceID": 3, "context": "Ben-Tal and Nemirovski (2002) and Bertsimas and Sim (2003) proposed robust optimization models where no assumptions of the underlying probability distribution of data are needed. The idea is often to approximate data uncertainty by a tractable (convex) uncertainty set, and optimization is performed on that set. This results in a robust counterpart formulation as a conic (such as second-order cone) optimization problem which can be solved in polynomial time. However, only a few works have been reported in the literature on applying robust optimization to scheduling, due mainly to a high-degree combinational nature of the problem. One such application is the process scheduling problem in chemical engineering, such as the works by Janak, Lin, and Floudas (2007) and Li and Ierapetritou (2008). A notable recent breakthrough in robust optimization on tractable approximation models to solve stochastic optimization problems is found by Chen et al. (2008). This work makes use of linear segregated decision rules that are relevant to solving combinatorial scheduling problems with durational uncertainty and our work exploit this mechanism and incorporate it into local search.", "startOffset": 0, "endOffset": 961}], "year": 2012, "abstractText": "Scheduling problems in manufacturing, logistics and project management have frequently been modeled using the framework of Resource Constrained Project Scheduling Problems with minimum and maximum time lags (RCPSP/max). Due to the importance of these problems, providing scalable solution schedules for RCPSP/max problems is a topic of extensive research. However, all existing methods for solving RCPSP/max assume that durations of activities are known with certainty, an assumption that does not hold in real world scheduling problems where unexpected external events such as manpower availability, weather changes, etc. lead to delays or advances in completion of activities. Thus, in this paper, our focus is on providing a scalable method for solving RCPSP/max problems with durational uncertainty. To that end, we introduce the robust local search method consisting of three key ideas: (a) Introducing and studying the properties of two decision rule approximations used to compute start times of activities with respect to dynamic realizations of the durational uncertainty; (b) Deriving the expression for robust makespan of an execution strategy based on decision rule approximations; and (c) A robust local search mechanism to efficiently compute activity execution strategies that are robust against durational uncertainty. Furthermore, we also provide enhancements to local search that exploit temporal dependencies between activities. Our experimental results illustrate that robust local search is able to provide robust execution strategies efficiently.", "creator": " TeX output 2012.01.03:1019"}}}