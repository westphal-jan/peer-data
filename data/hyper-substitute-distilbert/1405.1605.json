{"id": "1405.1605", "review": {"conference": "acl", "VERSION": "v1", "DATE_OF_SUBMISSION": "7-May-2014", "title": "DepecheMood: a Lexicon for Emotion Analysis from Crowd-Annotated News", "abstract": "while simple lexica fill with structures that have available for sentiment analysis, very tasks tackle the harder task of emotion analysts and are usually so limited in skill. regarding resulting paper, developers present a valid approach for de - analyzing a universally automated way - a high - availability and large - precision lexicon showing all 37 ml terms annotated predict emotion effects, significantly depechemood. our approach while in essence original /'custom - sourced'affective annotation implicitly provided powerful readers of user articles hosting rappler. inc. by providing new state - be - the - art controls implementing timely yet enhanced regression and structural support, even using that na \\ \" { \\ i } validation approach, our products leverage the beneficial solution including harvesting positive perception scores for relational lexicon building.", "histories": [["v1", "Wed, 7 May 2014 13:40:47 GMT  (20kb)", "http://arxiv.org/abs/1405.1605v1", "To appear at ACL 2014. 7 pages"]], "COMMENTS": "To appear at ACL 2014. 7 pages", "reviews": [], "SUBJECTS": "cs.CL cs.CY", "authors": ["jacopo staiano", "marco guerini"], "accepted": true, "id": "1405.1605"}, "pdf": {"name": "1405.1605.pdf", "metadata": {"source": "CRF", "title": null, "authors": [], "emails": ["staiano@disi.unitn.it", "marco.guerini@trentorise.eu"], "sections": [{"heading": null, "text": "ar X\niv :1\n40 5.\n16 05\nv1 [\ncs .C\nL ]\n7 M\nay 2\n01 4"}, {"heading": "1 Introduction", "text": "Sentiment analysis has proved useful in several application scenarios, for instance in buzz monitoring \u2013 the marketing technique for keeping track of consumer responses to services and products \u2013 where identifying positive and negative customer experiences helps to assess product and service demand, tackle crisis management, etc.\nOn the other hand, the use of finer-grained models, accounting for the role of individual emotions, is still in its infancy. The simple division in \u2018positive\u2019 vs. \u2018negative\u2019 comments may not suffice, as in these examples: \u2018I\u2019m so miserable, I dropped my IPhone in the water and now it\u2019s not working anymore\u2019 (SADNESS) vs. \u2018I am very upset, my new IPhone keeps not working!\u2019 (ANGER). While both texts express a negative sentiment, the latter, connected to anger, is more relevant for buzz monitor-\ning. Thus, emotion analysis represents a natural evolution of sentiment analysis.\nMany approaches to sentiment analysis make use of lexical resources \u2013 i.e. lists of positive and negative words \u2013 often deployed as baselines or as features for other methods, usually machine learning based (Liu and Zhang, 2012). In these lexica, words are associated with their prior polarity, i.e. whether such word out of context evokes something positive or something negative. For example, wonderful has a positive connotation \u2013 prior polarity \u2013 while horrible has a negative one.\nThe quest for a high precision and high coverage lexicon, where words are associated with either sentiment or emotion scores, has several reasons. First, it is fundamental for tasks such as affective modification of existing texts, where words\u2019 polarity together with their score are necessary for creating multiple graded variations of the original text (Inkpen et al., 2006; Guerini et al., 2008; Whitehead and Cavedon, 2010).\nSecond, considering word order makes a difference in sentiment analysis. This calls for a role of compositionality, where the score of a sentence is computed by composing the scores of the words up in the syntactic tree. Works worth mentioning in this connection are: Socher et al. (2013), which uses recursive neural networks to learn compositional rules for sentiment analysis, and (Neviarouskaya et al., 2009; Neviarouskaya et al., 2011) which exploit hand-coded rules to compose the emotions expressed by words in a sentence. In this respect, compositional approaches represent a new promising trend, since all other approaches, either using semantic similarity or Bag-of-Words (BOW) based machine-learning, cannot handle, for example, cases of texts with same wording but different words order: \u201cThe dangerous killer escaped one month ago, but recently he was arrested\u201d (RELIEF, HAPPYNESS) vs. \u201cThe dangerous killer was arrested one month ago, but re-\ncently he escaped\u201d (FEAR). The work in (Wang and Manning, 2012) partially accounts for this problem and argues that using word bigram features allows improving over BOW based methods, where words are taken as features in isolation. This way it is possible to capture simple compositional phenomena like polarity reversing in \u201ckilling cancer\u201d.\nFinally, tasks such as copywriting, where evocative names are a key element to a successful product (Ozbal and Strapparava, 2012; Ozbal et al., 2012) require exhaustive lists of emotion related words. In such cases no context is given and the brand name alone, with its perceived prior polarity, is responsible for stating the area of competition and evoking semantic associations. For example Mitsubishi changed the name of one of its SUVs for the Spanish market, since the original name Pajero had a very negative prior polarity, as it means \u2018wanker\u2019 in Spanish (Piller, 2003). Evoking emotions is also fundamental for a successful name: consider names of a perfume like Obsession, or technological products like MacBook air.\nIn this work, we aim at automatically producing a high coverage and high precision emotion lexicon using distributional semantics, with numerical scores associated with each emotion, like it has already been done for sentiment analysis. To this end, we take advantage in an original way of massive crowd-sourced affective annotations associated with news articles, obtained by crawling the rappler.com social news network. We also evaluate our lexicon by integrating it in unsupervised classification and regression settings for emotion recognition. Results indicate that the use of our resource, even if automatically acquired, is highly beneficial in affective text recognition."}, {"heading": "2 Related Work", "text": "Within the broad field of sentiment analysis, we hereby provide a short review of research efforts put towards building sentiment and emotion lexica, regardless of the approach in which such lists are then used (machine learning, rule based or deep learning). A general overview can be found in (Pang and Lee, 2008; Liu and Zhang, 2012; Wilson et al., 2004; Paltoglou et al., 2010).\nSentiment Lexica. In recent years there has been an increasing focus on producing lists of words (lexica) with prior polarities, to be used in sentiment analysis. When building such lists, a\ntrade-off between coverage of the resource and its precision is to be found.\nOne of the most well-known resources is SentiWordNet (SWN) (Esuli and Sebastiani, 2006; Baccianella et al., 2010), in which each entry is associated with the numerical scores Pos(s) and Neg(s), ranging from 0 to 1. These scores \u2013 automatically assigned starting from a bunch of seed terms \u2013 represent the positive and negative valence (or posterior polarity) of each entry, that takes the form lemma#pos#sense-number. Starting from SWN, several prior polarities for words (SWN-prior), in the form lemma#PoS, can be computed (e.g. considering only the firstsense, averaging on all the senses, etc.). These approaches, detailed in (Guerini et al., 2013), produce a list of 155k words, where the lower precision given by the automatic scoring of SWN is compensated by the high coverage.\nAnother widely used resource is ANEW (Bradley and Lang, 1999), providing valence scores for 1k words, which were manually assigned by several annotators. This resource has a low coverage, but the precision is maximized. Similarly, the SO-CAL entries (Taboada et al., 2011) were manually tagged by a small number of annotators with a multi-class label (from very negative to very positive). These ratings were further validated through crowdsourcing, ending up with a list of roughly 4k words. More recently, a resource that replicated ANEW annotation approach using crowdsourcing, was released (Warriner et al., 2013), providing sentiment scores for 14k words. Interestingly, this resource annotates the most frequent words in English, so, even if lexicon coverage is still far lower than SWN-prior, it grants a high coverage, with human precision, of language use.\nFinally, the General Inquirer lexicon (Stone et al., 1966) provides a binary classification (positive/negative) of 4k sentimentbearing words, while the resource in (Wilson et al., 2005) expands the General Inquirer to 6k words.\nEmotion Lexica. Compared to sentiment lexica, far less emotion lexica have been produced, and all have lower coverage. One of the most used resources is WordNetAffect (Strapparava and Valitutti, 2004) which contains manually assigned affective labels to WordNet synsets (ANGER, JOY, FEAR, etc.). It currently provides 900 annotated synsets and 1.6k words in the form\nlemma#PoS#sense, corresponding to roughly 1 thousand lemma#PoS.\nAffectNet, part of the SenticNet project (Cambria and Hussain, 2012), contains 10k words (out of 23k entries) taken from ConceptNet and aligned with WordNetAffect. This resource extends WordNetAffect labels to concepts like \u2018have breakfast\u2019. Fuzzy Affect Lexicon (Subasic and Huettner, 2001) contains roughly 4k lemma#PoS manually annotated by one linguist using 80 emotion labels. EmoLex (Mohammad and Turney, 2013) contains almost 10k lemmas annotated with an intensity label for each emotion using Mechanical Turk. Finally Affect database is an extension of SentiFul (Neviarouskaya et al., 2007) and contains 2.5K words in the form lemma#PoS. The latter is the only lexicon providing words annotated also with emotion scores rather than only with labels."}, {"heading": "3 Dataset Collection", "text": "To build our emotion lexicon we harvested all the news articles from rappler.com, as of June 3rd 2013: the final dataset consists of 13.5 M words over 25.3 K documents, with an average of 530 words per document. For each document, along with the text we also harvested the information displayed by Rappler\u2019s Mood Meter, a small interface offering the readers the opportunity to click on the emotion that a given Rappler story made them feel. The idea behind the Mood Meter is actually \u201cgetting people to crowdsource the mood for the day\u201d1, and returning the percentage of votes for each emotion label for a given story. This way, hundreds of thousands votes have been collected since the launch of the service. In our novel approach to \u2018crowdsourcing\u2019, as compared to other NLP tasks that rely on tools like Amazon\u2019s Mechanical Turk (Snow et al., 2008), the subjects are aware of the \u2018implicit annotation task\u2019 but they are not paid. From this data, we built a document-by-emotion matrix MDE , providing the voting percentages for each document in the eight\n1http://nie.mn/QuD17Z\naffective dimensions available in Rappler. An excerpt is provided in Table 1.\nThe idea of using documents annotated with emotions is not new (Strapparava and Mihalcea, 2008; Mishne, 2005; Bellegarda, 2010), but these works had the limitation of providing a single emotion label per document, rather than a score for each emotion, and, moreover, the annotation was performed by the author of the document alone.\nTable 2 reports the average percentage of votes for each emotion on the whole corpus: HAPPINESS has a far higher percentage of votes (at least three times). There are several possible explanations, out of the scope of the present paper, for this bias: (i) it is due to cultural characteristics of the audience (ii) the bias is in the dataset itself, being formed mainly by \u2018positive\u2019 news; (iii) it is a psychological phenomenon due to the fact that people tend to express more positive moods on social networks (Quercia et al., 2011; Vittengl and Holt, 1998; De Choudhury et al., 2012). In any case, the predominance of happy mood has been found in other datasets, for instance LiveJournal.com posts (Strapparava and Mihalcea, 2008). In the following section we will discuss how we handled this problem."}, {"heading": "4 Emotion Lexicon Creation", "text": "As a next step we built a word-by-emotion matrix starting from MDE using an approach based on compositional semantics. To do so, we first lemmatized and PoS tagged all the documents (where PoS can be adj., nouns, verbs, adv.) and kept only those lemma#PoS present also in WordNet, similar to SWN-prior and WordNetAffect resources, to which we want to align. We then computed the term-by-document matrices using raw\nfrequencies, normalized frequencies, and tf-idf (MWD,f , MWD,nf and MWD,tfidf respectively), so to test which of the three weights is better. After that, we applied matrix multiplication between the document-by-emotion and word-by-document matrices (MDE \u00b7 MWD) to obtain a (raw) wordby-emotion matrix MWE . This method allows us to \u2018merge\u2019 words with emotions by summing the products of the weight of a word with the weight of the emotions in each document.\nFinally, we transformed MWE by first applying normalization column-wise (so to eliminate the over representation for happiness as discussed in Section 3) and then scaling the data row-wise so to sum up to one. An excerpt of the final Matrix MWE is presented in Table 3, and it can be interpreted as a list of words with scores that represent how much weight a given word has in the affective dimensions we consider. So, for example, awe#n has a predominant weight in INSPIRED (0.38), comical#a has a predominant weight in AMUSED (0.51), while kill#v has a predominant weight in AFRAID, ANGRY and SAD (0.23, 0.21 and 0.27 respectively). This matrix, that we call DepecheMood2, represents our emotion lexicon, it contains 37k entries and is freely available for research purposes at http://git.io/MqyoIg."}, {"heading": "5 Experiments", "text": "To evaluate the performance we can obtain with our lexicon, we use the public dataset provided for the SemEval 2007 task on \u2018Affective Text\u2019 (Strapparava and Mihalcea, 2007). The task was focused on emotion recognition in one thousand news headlines, both in regression and classification settings. Headlines typically\n2In French, \u2018depeche\u2019 means dispatch/news.\nconsist of a few words and are often written with the intention to \u2018provoke\u2019 emotions so to attract the readers\u2019 attention. An example of headline from the dataset is the following: \u201cIraq car bombings kill 22 People, wound more than 60\u201d. For the regression task the values provided are: <anger(0.32),disgust(0.27),fear(0.84),\njoy(0.0),sadness(0.95),surprise(0.20)> while for the classification task the labels provided are {FEAR,SADNESS}. This dataset is of interest to us since the \u2018compositional\u2019 problem is less prominent given the simplified syntax of news headlines, containing, for example, fewer adverbs (like negations or intensifiers) than normal sentences (Turchi et al., 2012). Furthermore, this is to our knowledge the only dataset available providing numerical scores for emotions. Finally, this dataset was meant for unsupervised approaches (just a small trial sample was provided), so to avoid simple text categorization approaches.\nAs the affective dimensions present in the test set \u2013 based on the six basic emotions model (Ekman and Friesen, 1971) \u2013 do not exactly match with the ones provided by Rappler\u2019s Mood Meter, we first define a mapping between the two when possible, see Table 4. Then, we proceed to transform the test headlines to the lemma#PoS format.\nOnly one test headline contained exclusively words not present in DepecheMood, further indicating the high-coverage nature of our resource. In\nTable 5 we report the coverage of some Sentiment and Emotion Lexica of different sizes on the same dataset. Similar to Warriner et al. (2013), we observe that even if the number of entries of our lexicon is far lower than SWN-prior approaches, the fact that we extracted and annotated words from documents grants a high coverage of language use.\nSince our primary goal is to assess the quality of DepecheMood we first focus on the regression task. We do so by using a very na\u0131\u0308ve approach, similar to \u201cWordNetAffect presence\u201d discussed in (Strapparava and Mihalcea, 2008): for each headline, we simply compute a value, for any affective dimension, by averaging the corresponding affective scores \u2013obtained from DepecheMood- of all lemma#PoS present in the headline.\nIn Table 6 we report the results obtained using the three versions of our resource (Pearson correlation), along with the best performance on each emotion of other systems3 (bestse); the last column contains the upper bound of inter-annotator agreement. For all the 5 emotions we improve over the best performing systems (DISGUST has no alignment with our labels and was discarded).\nInterestingly, even using a sub-optimal alignment for SURPRISE we still manage to outperform other systems. Considering the na\u0131\u0308ve approach we used, we can reasonably conclude that the quality and coverage of our resource are the reason of such results, and that adopting more complex approaches (i.e. compositionality) can possibly further improve performances in textbased emotion recognition.\nAs a final test, we evaluate our resource in the classification task. The na\u0131\u0308ve approach used in this case consists in mapping the average of the scores of all words in the headline to a binary decision with fixed threshold at 0.5 for each emotion (after min-max normalization on all test headlines scores). In Table 7 we report the results (F1 mea-\n3Systems participating in the \u2018Affective Text\u2019 task plus the approaches in (Strapparava and Mihalcea, 2008). Other supervised approaches in the classification task (Mohammad, 2012; Bellegarda, 2010; Chaffar and Inkpen, 2011), reporting only overall performances, are not considered.\nsure) of our approach along with the best performance of other systems on each emotion (bestse), as in the previous case. For 3 emotions out of 5 we improve over the best performing systems, for one emotion we obtain the same results, and for one emotion we do not outperform other systems. In this case the difference in performances among the various ways of representing the wordby-document matrix is more prominent: normalized frequencies (nf ) provide the best results."}, {"heading": "6 Conclusions", "text": "We presented DepecheMood, an emotion lexicon built in a novel and totally automated way by harvesting crowd-sourced affective annotation from a social news network. Our experimental results indicate high-coverage and highprecision of the lexicon, showing significant improvements over state-of-the-art unsupervised approaches even when using the resource with very na\u0131\u0308ve classification and regression strategies. We believe that the wealth of information provided by social media can be harnessed to build models and resources for emotion recognition from text, going a step beyond sentiment analysis. Our future work will include testing Singular Value Decomposition on the word-by-document matrices, allowing to propagate emotions values for a document to similar words non present in the document itself, and the study of perceived mood effects on virality indices and readers engagement by exploiting tweets, likes, reshares and comments.\nThis work has been partially supported by the Trento RISE PerTe project."}], "references": [{"title": "SentiWordNet 3.0: An enhanced lexical resource for sentiment analysis and opinion mining", "author": ["S. Baccianella", "A. Esuli", "F. Sebastiani"], "venue": "In Proceedings of the Conference on International Language Resources and Evaluation (LREC),", "citeRegEx": "Baccianella et al\\.,? \\Q2010\\E", "shortCiteRegEx": "Baccianella et al\\.", "year": 2010}, {"title": "Emotion analysis using latent affective folding and embedding", "author": ["J.R. Bellegarda."], "venue": "Proceedings of the NAACL HLT 2010 workshop on computational approaches to analysis and generation of emotion in text, pages 1\u20139. Association for Computational Lin-", "citeRegEx": "Bellegarda.,? 2010", "shortCiteRegEx": "Bellegarda.", "year": 2010}, {"title": "Affective norms for english words (ANEW): Instruction manual and affective ratings", "author": ["M. Bradley", "P. Lang."], "venue": "Technical Report C-1, University of Florida.", "citeRegEx": "Bradley and Lang.,? 1999", "shortCiteRegEx": "Bradley and Lang.", "year": 1999}, {"title": "Sentic computing", "author": ["E. Cambria", "A. Hussain."], "venue": "Springer.", "citeRegEx": "Cambria and Hussain.,? 2012", "shortCiteRegEx": "Cambria and Hussain.", "year": 2012}, {"title": "Using a heterogeneous dataset for emotion analysis in text", "author": ["S. Chaffar", "D. Inkpen."], "venue": "Advances in Artificial Intelligence, pages 62\u201367. Springer.", "citeRegEx": "Chaffar and Inkpen.,? 2011", "shortCiteRegEx": "Chaffar and Inkpen.", "year": 2011}, {"title": "Not all moods are created equal! exploring human emotional states in social media", "author": ["M. De Choudhury", "S. Counts", "M. Gamon."], "venue": "Proceedings of the International Conference on Weblogs and Social Media (ICWSM).", "citeRegEx": "Choudhury et al\\.,? 2012", "shortCiteRegEx": "Choudhury et al\\.", "year": 2012}, {"title": "Constants across cultures in the face and emotion", "author": ["P. Ekman", "W.V. Friesen."], "venue": "Journal of Personality and Social Psychology, 17:124\u2013129.", "citeRegEx": "Ekman and Friesen.,? 1971", "shortCiteRegEx": "Ekman and Friesen.", "year": 1971}, {"title": "SentiWordNet: A publicly available lexical resource for opinion mining", "author": ["A. Esuli", "F. Sebastiani."], "venue": "Proceedings of the Conference on International Language Resources and Evaluation (LREC), pages 417\u2013422, Genova, IT.", "citeRegEx": "Esuli and Sebastiani.,? 2006", "shortCiteRegEx": "Esuli and Sebastiani.", "year": 2006}, {"title": "Valentino: A tool for valence shifting of natural language texts", "author": ["M. Guerini", "O. Stock", "C. Strapparava."], "venue": "Proceedings of the Conference on International Language Resources and Evaluation (LREC), Marrakech, Morocco.", "citeRegEx": "Guerini et al\\.,? 2008", "shortCiteRegEx": "Guerini et al\\.", "year": 2008}, {"title": "Sentiment analysis: How to derive prior polarities from sentiwordnet", "author": ["M. Guerini", "L. Gatti", "M. Turchi."], "venue": "Proceedings of the Conference on Empirical Methods in Natural Language Processing (EMNLP), pages 1259\u20131269.", "citeRegEx": "Guerini et al\\.,? 2013", "shortCiteRegEx": "Guerini et al\\.", "year": 2013}, {"title": "Generating more-positive and more-negative text", "author": ["D.Z. Inkpen", "O. Feiguina", "G. Hirst."], "venue": "Computing Attitude and Affect in Text: Theory and Applications, pages 187\u2013198. Springer.", "citeRegEx": "Inkpen et al\\.,? 2006", "shortCiteRegEx": "Inkpen et al\\.", "year": 2006}, {"title": "A survey of opinion mining and sentiment analysis", "author": ["B. Liu", "L. Zhang."], "venue": "Mining Text Data, pages 415\u2013463.", "citeRegEx": "Liu and Zhang.,? 2012", "shortCiteRegEx": "Liu and Zhang.", "year": 2012}, {"title": "Experiments with mood classification in blog posts", "author": ["G. Mishne."], "venue": "Proceedings of ACM SIGIR 2005 Workshop on Stylistic Analysis of Text for Information Access, volume 19.", "citeRegEx": "Mishne.,? 2005", "shortCiteRegEx": "Mishne.", "year": 2005}, {"title": "Crowdsourcing a word\u2013emotion association lexicon", "author": ["S.M. Mohammad", "P.D. Turney."], "venue": "Computational Intelligence, 29(3):436\u2013465.", "citeRegEx": "Mohammad and Turney.,? 2013", "shortCiteRegEx": "Mohammad and Turney.", "year": 2013}, {"title": " Emotional tweets", "author": ["S.M. Mohammad."], "venue": "Proceedings of the First Joint Conference on Lexical and Computational Semantics (*Sem), pages 246\u2013 255. Association for Computational Linguistics.", "citeRegEx": "Mohammad.,? 2012", "shortCiteRegEx": "Mohammad.", "year": 2012}, {"title": "Textual affect sensing for sociable and expressive online communication", "author": ["A. Neviarouskaya", "H. Prendinger", "M. Ishizuka."], "venue": "A. Paiva, R. Prada, and R. Picard, editors, Affective Computing and Intelligent Interaction, volume 4738 of", "citeRegEx": "Neviarouskaya et al\\.,? 2007", "shortCiteRegEx": "Neviarouskaya et al\\.", "year": 2007}, {"title": "Compositionality principle in recognition of fine-grained emotions from text", "author": ["A. Neviarouskaya", "H. Prendinger", "M. Ishizuka."], "venue": "Proceedings of the International Conference on Weblogs and Social Media (ICWSM).", "citeRegEx": "Neviarouskaya et al\\.,? 2009", "shortCiteRegEx": "Neviarouskaya et al\\.", "year": 2009}, {"title": "Affect analysis model: novel rule-based approach to affect sensing from text", "author": ["A. Neviarouskaya", "H. Prendinger", "M. Ishizuka."], "venue": "Natural Language Engineering, 17(1):95.", "citeRegEx": "Neviarouskaya et al\\.,? 2011", "shortCiteRegEx": "Neviarouskaya et al\\.", "year": 2011}, {"title": "A computational approach to the automation of creative naming", "author": ["G. Ozbal", "C. Strapparava."], "venue": "Proceedings of the 50th Annual Meeting of the Association for Computational Linguistics (ACL).", "citeRegEx": "Ozbal and Strapparava.,? 2012", "shortCiteRegEx": "Ozbal and Strapparava.", "year": 2012}, {"title": "Brand pitt: A corpus to explore the art of naming", "author": ["G. Ozbal", "C. Strapparava", "M. Guerini."], "venue": "Proceedings of the Conference on International Language Resources and Evaluation (LREC).", "citeRegEx": "Ozbal et al\\.,? 2012", "shortCiteRegEx": "Ozbal et al\\.", "year": 2012}, {"title": "Online textual communications annotated with grades of emotion strength", "author": ["G. Paltoglou", "M. Thelwall", "K. Buckley."], "venue": "Proceedings of the 3rd International Workshop of Emotion: Corpora for research on Emotion and Affect, pages 25\u201331.", "citeRegEx": "Paltoglou et al\\.,? 2010", "shortCiteRegEx": "Paltoglou et al\\.", "year": 2010}, {"title": "Opinion mining and sentiment analysis", "author": ["B. Pang", "L. Lee."], "venue": "Foundations and Trends in Information Retrieval, 2(1-2):1\u2013135.", "citeRegEx": "Pang and Lee.,? 2008", "shortCiteRegEx": "Pang and Lee.", "year": 2008}, {"title": "10", "author": ["I. Piller."], "venue": "advertising as a site of language contact. Annual Review of Applied Linguistics, 23:170\u2013183.", "citeRegEx": "Piller.,? 2003", "shortCiteRegEx": "Piller.", "year": 2003}, {"title": "In the mood for being influential on twitter", "author": ["D. Quercia", "J. Ellis", "L. Capra", "J. Crowcroft."], "venue": "Proceedings of IEEE SocialCom\u201911.", "citeRegEx": "Quercia et al\\.,? 2011", "shortCiteRegEx": "Quercia et al\\.", "year": 2011}, {"title": "Cheap and fast\u2014but is it good?: evaluating nonexpert annotations for natural language tasks", "author": ["R. Snow", "B. O\u2019Connor", "D. Jurafsky", "A. Ng"], "venue": "In Proceedings of the Conference on Empirical Methods in Natural Language Processing (EMNLP),", "citeRegEx": "Snow et al\\.,? \\Q2008\\E", "shortCiteRegEx": "Snow et al\\.", "year": 2008}, {"title": "Recursive deep models for semantic compositionality over a sentiment treebank", "author": ["R. Socher", "A. Perelygin", "J.Y. Wu", "J. Chuang", "C.D. Manning", "A.Y. Ng", "C. Potts."], "venue": "Proceedings of the Conference on Empirical Methods in Natural Language", "citeRegEx": "Socher et al\\.,? 2013", "shortCiteRegEx": "Socher et al\\.", "year": 2013}, {"title": "The General Inquirer: A Computer Approach to Content Analysis", "author": ["P. Stone", "D. Dunphy", "M. Smith."], "venue": "MIT press.", "citeRegEx": "Stone et al\\.,? 1966", "shortCiteRegEx": "Stone et al\\.", "year": 1966}, {"title": "Semeval2007 task 14: Affective text", "author": ["C. Strapparava", "R. Mihalcea."], "venue": "Proceedings of the 4th International Workshop on Semantic Evaluations, pages 70\u201374. Association for Computational Linguistics.", "citeRegEx": "Strapparava and Mihalcea.,? 2007", "shortCiteRegEx": "Strapparava and Mihalcea.", "year": 2007}, {"title": "Learning to identify emotions in text", "author": ["C. Strapparava", "R. Mihalcea."], "venue": "Proceedings of the 2008 ACM symposium on Applied computing, pages 1556\u20131560. ACM.", "citeRegEx": "Strapparava and Mihalcea.,? 2008", "shortCiteRegEx": "Strapparava and Mihalcea.", "year": 2008}, {"title": "WordNetAffect: an affective extension of WordNet", "author": ["C. Strapparava", "A. Valitutti."], "venue": "Proceedings of the Conference on International Language Resources and Evaluation (LREC), pages 1083 \u2013 1086, Lisbon, May.", "citeRegEx": "Strapparava and Valitutti.,? 2004", "shortCiteRegEx": "Strapparava and Valitutti.", "year": 2004}, {"title": "Affect analysis of text using fuzzy semantic typing", "author": ["P. Subasic", "A. Huettner."], "venue": "Fuzzy Systems, IEEE Transactions on, 9(4):483\u2013496.", "citeRegEx": "Subasic and Huettner.,? 2001", "shortCiteRegEx": "Subasic and Huettner.", "year": 2001}, {"title": "Lexicon-based methods for sentiment analysis", "author": ["M. Taboada", "J. Brooke", "M. Tofiloski", "K. Voll", "M. Stede."], "venue": "Computational linguistics, 37(2):267\u2013307.", "citeRegEx": "Taboada et al\\.,? 2011", "shortCiteRegEx": "Taboada et al\\.", "year": 2011}, {"title": "Onts: optima news translation system", "author": ["M. Turchi", "M. Atkinson", "A. Wilcox", "B. Crawley", "S. Bucci", "R. Steinberger", "E. Van der Goot."], "venue": "Proceedings of the Demonstrations at the 13th Conference of the European Chapter of the Association for Com-", "citeRegEx": "Turchi et al\\.,? 2012", "shortCiteRegEx": "Turchi et al\\.", "year": 2012}, {"title": "A time-series diary study of mood and social interaction", "author": ["J.R. Vittengl", "C.S. Holt."], "venue": "Motivation and Emotion, 22(3):255\u2013275.", "citeRegEx": "Vittengl and Holt.,? 1998", "shortCiteRegEx": "Vittengl and Holt.", "year": 1998}, {"title": "Baselines and bigrams: Simple, good sentiment and topic classification", "author": ["S. Wang", "C. Manning."], "venue": "Proceedings of the 50th Annual Meeting of the Association for Computational Linguistics (ACL).", "citeRegEx": "Wang and Manning.,? 2012", "shortCiteRegEx": "Wang and Manning.", "year": 2012}, {"title": "Norms of valence, arousal, and dominance for 13,915 english lemmas", "author": ["A.B. Warriner", "V. Kuperman", "M. Brysbaert."], "venue": "Behavior research methods, 45(4):1191\u20131207.", "citeRegEx": "Warriner et al\\.,? 2013", "shortCiteRegEx": "Warriner et al\\.", "year": 2013}, {"title": "Generating shifting sentiment for a conversational agent", "author": ["S. Whitehead", "L. Cavedon."], "venue": "Proceedings of the NAACL HLT 2010 Workshop on Computational Approaches to Analysis and Generation of Emotion in Text, pages 89\u201397, Los Angeles,", "citeRegEx": "Whitehead and Cavedon.,? 2010", "shortCiteRegEx": "Whitehead and Cavedon.", "year": 2010}, {"title": "Just how mad are you? finding strong and weak opinion clauses", "author": ["T. Wilson", "J. Wiebe", "R. Hwa."], "venue": "Proceedings of AAAI, pages 761\u2013769.", "citeRegEx": "Wilson et al\\.,? 2004", "shortCiteRegEx": "Wilson et al\\.", "year": 2004}, {"title": "Recognizing contextual polarity in phrase-level sentiment analysis", "author": ["T. Wilson", "J. Wiebe", "P. Hoffmann."], "venue": "Proceedings of the conference on Human Language Technology and Empirical Methods in Natural Language Processing, pages 347\u2013354.", "citeRegEx": "Wilson et al\\.,? 2005", "shortCiteRegEx": "Wilson et al\\.", "year": 2005}], "referenceMentions": [{"referenceID": 11, "context": "lists of positive and negative words \u2013 often deployed as baselines or as features for other methods, usually machine learning based (Liu and Zhang, 2012).", "startOffset": 132, "endOffset": 153}, {"referenceID": 10, "context": "First, it is fundamental for tasks such as affective modification of existing texts, where words\u2019 polarity together with their score are necessary for creating multiple graded variations of the original text (Inkpen et al., 2006; Guerini et al., 2008; Whitehead and Cavedon, 2010).", "startOffset": 208, "endOffset": 280}, {"referenceID": 8, "context": "First, it is fundamental for tasks such as affective modification of existing texts, where words\u2019 polarity together with their score are necessary for creating multiple graded variations of the original text (Inkpen et al., 2006; Guerini et al., 2008; Whitehead and Cavedon, 2010).", "startOffset": 208, "endOffset": 280}, {"referenceID": 36, "context": "First, it is fundamental for tasks such as affective modification of existing texts, where words\u2019 polarity together with their score are necessary for creating multiple graded variations of the original text (Inkpen et al., 2006; Guerini et al., 2008; Whitehead and Cavedon, 2010).", "startOffset": 208, "endOffset": 280}, {"referenceID": 25, "context": "Works worth mentioning in this connection are: Socher et al. (2013),", "startOffset": 47, "endOffset": 68}, {"referenceID": 16, "context": "which uses recursive neural networks to learn compositional rules for sentiment analysis, and (Neviarouskaya et al., 2009; Neviarouskaya et al., 2011) which exploit hand-coded rules to compose the emotions expressed by words in a sentence.", "startOffset": 94, "endOffset": 150}, {"referenceID": 17, "context": "which uses recursive neural networks to learn compositional rules for sentiment analysis, and (Neviarouskaya et al., 2009; Neviarouskaya et al., 2011) which exploit hand-coded rules to compose the emotions expressed by words in a sentence.", "startOffset": 94, "endOffset": 150}, {"referenceID": 34, "context": "The work in (Wang and Manning, 2012) partially accounts for this problem and argues that using word bigram features allows improving over BOW based methods, where words are taken as features in isolation.", "startOffset": 12, "endOffset": 36}, {"referenceID": 18, "context": "Finally, tasks such as copywriting, where evocative names are a key element to a successful product (Ozbal and Strapparava, 2012; Ozbal et al., 2012) require exhaustive lists of emotion related words.", "startOffset": 100, "endOffset": 149}, {"referenceID": 19, "context": "Finally, tasks such as copywriting, where evocative names are a key element to a successful product (Ozbal and Strapparava, 2012; Ozbal et al., 2012) require exhaustive lists of emotion related words.", "startOffset": 100, "endOffset": 149}, {"referenceID": 22, "context": "For example Mitsubishi changed the name of one of its SUVs for the Spanish market, since the original name Pajero had a very negative prior polarity, as it means \u2018wanker\u2019 in Spanish (Piller, 2003).", "startOffset": 182, "endOffset": 196}, {"referenceID": 21, "context": "A general overview can be found in (Pang and Lee, 2008; Liu and Zhang, 2012; Wilson et al., 2004; Paltoglou et al., 2010).", "startOffset": 35, "endOffset": 121}, {"referenceID": 11, "context": "A general overview can be found in (Pang and Lee, 2008; Liu and Zhang, 2012; Wilson et al., 2004; Paltoglou et al., 2010).", "startOffset": 35, "endOffset": 121}, {"referenceID": 37, "context": "A general overview can be found in (Pang and Lee, 2008; Liu and Zhang, 2012; Wilson et al., 2004; Paltoglou et al., 2010).", "startOffset": 35, "endOffset": 121}, {"referenceID": 20, "context": "A general overview can be found in (Pang and Lee, 2008; Liu and Zhang, 2012; Wilson et al., 2004; Paltoglou et al., 2010).", "startOffset": 35, "endOffset": 121}, {"referenceID": 7, "context": "One of the most well-known resources is SentiWordNet (SWN) (Esuli and Sebastiani, 2006; Baccianella et al., 2010), in which each entry is associated with the numerical scores Pos(s) and Neg(s), ranging from 0 to 1.", "startOffset": 59, "endOffset": 113}, {"referenceID": 0, "context": "One of the most well-known resources is SentiWordNet (SWN) (Esuli and Sebastiani, 2006; Baccianella et al., 2010), in which each entry is associated with the numerical scores Pos(s) and Neg(s), ranging from 0 to 1.", "startOffset": 59, "endOffset": 113}, {"referenceID": 9, "context": "These approaches, detailed in (Guerini et al., 2013), produce a list of 155k words, where the lower precision given by the automatic scoring of SWN is compensated by the high coverage.", "startOffset": 30, "endOffset": 52}, {"referenceID": 2, "context": "Another widely used resource is ANEW (Bradley and Lang, 1999), providing valence scores for 1k words, which were manually assigned by several annotators.", "startOffset": 37, "endOffset": 61}, {"referenceID": 31, "context": "Similarly, the SO-CAL entries (Taboada et al., 2011) were manually tagged by a small number of annotators with a multi-class label (from very negative to very positive).", "startOffset": 30, "endOffset": 52}, {"referenceID": 35, "context": "sourcing, was released (Warriner et al., 2013), providing sentiment scores for 14k words.", "startOffset": 23, "endOffset": 46}, {"referenceID": 26, "context": "Finally, the General Inquirer lexicon (Stone et al., 1966) provides a binary classification (positive/negative) of 4k sentimentbearing words, while the resource in (Wilson et al.", "startOffset": 38, "endOffset": 58}, {"referenceID": 38, "context": ", 1966) provides a binary classification (positive/negative) of 4k sentimentbearing words, while the resource in (Wilson et al., 2005) expands the General Inquirer to 6k words.", "startOffset": 113, "endOffset": 134}, {"referenceID": 29, "context": "One of the most used resources is WordNetAffect (Strapparava and Valitutti, 2004) which contains manu-", "startOffset": 48, "endOffset": 81}, {"referenceID": 3, "context": "AffectNet, part of the SenticNet project (Cambria and Hussain, 2012), contains 10k words (out of 23k entries) taken from ConceptNet and aligned with WordNetAffect.", "startOffset": 41, "endOffset": 68}, {"referenceID": 30, "context": "Fuzzy Affect Lexicon (Subasic and Huettner, 2001) contains roughly 4k lemma#PoS manually annotated by one linguist using 80 emotion labels.", "startOffset": 21, "endOffset": 49}, {"referenceID": 13, "context": "EmoLex (Mohammad and Turney, 2013) contains almost 10k lemmas annotated with an intensity label for each emotion using Mechanical Turk.", "startOffset": 7, "endOffset": 34}, {"referenceID": 15, "context": "Finally Affect database is an extension of SentiFul (Neviarouskaya et al., 2007) and contains 2.", "startOffset": 52, "endOffset": 80}, {"referenceID": 24, "context": "novel approach to \u2018crowdsourcing\u2019, as compared to other NLP tasks that rely on tools like Amazon\u2019s Mechanical Turk (Snow et al., 2008), the subjects are aware of the \u2018implicit annotation task\u2019 but they are not paid.", "startOffset": 115, "endOffset": 134}, {"referenceID": 28, "context": "The idea of using documents annotated with emotions is not new (Strapparava and Mihalcea, 2008; Mishne, 2005; Bellegarda, 2010), but these works had the limitation of providing a single emotion label per document, rather than a score for each emotion, and, moreover, the annotation was performed by the author of the document alone.", "startOffset": 63, "endOffset": 127}, {"referenceID": 12, "context": "The idea of using documents annotated with emotions is not new (Strapparava and Mihalcea, 2008; Mishne, 2005; Bellegarda, 2010), but these works had the limitation of providing a single emotion label per document, rather than a score for each emotion, and, moreover, the annotation was performed by the author of the document alone.", "startOffset": 63, "endOffset": 127}, {"referenceID": 1, "context": "The idea of using documents annotated with emotions is not new (Strapparava and Mihalcea, 2008; Mishne, 2005; Bellegarda, 2010), but these works had the limitation of providing a single emotion label per document, rather than a score for each emotion, and, moreover, the annotation was performed by the author of the document alone.", "startOffset": 63, "endOffset": 127}, {"referenceID": 23, "context": "There are several possible explanations, out of the scope of the present paper, for this bias: (i) it is due to cultural characteristics of the audience (ii) the bias is in the dataset itself, being formed mainly by \u2018positive\u2019 news; (iii) it is a psychological phenomenon due to the fact that people tend to express more positive moods on social networks (Quercia et al., 2011; Vittengl and Holt, 1998; De Choudhury et al., 2012).", "startOffset": 355, "endOffset": 429}, {"referenceID": 33, "context": "There are several possible explanations, out of the scope of the present paper, for this bias: (i) it is due to cultural characteristics of the audience (ii) the bias is in the dataset itself, being formed mainly by \u2018positive\u2019 news; (iii) it is a psychological phenomenon due to the fact that people tend to express more positive moods on social networks (Quercia et al., 2011; Vittengl and Holt, 1998; De Choudhury et al., 2012).", "startOffset": 355, "endOffset": 429}, {"referenceID": 28, "context": "com posts (Strapparava and Mihalcea, 2008).", "startOffset": 10, "endOffset": 42}, {"referenceID": 27, "context": "To evaluate the performance we can obtain with our lexicon, we use the public dataset provided for the SemEval 2007 task on \u2018Affective Text\u2019 (Strapparava and Mihalcea, 2007).", "startOffset": 141, "endOffset": 173}, {"referenceID": 32, "context": "This dataset is of interest to us since the \u2018compositional\u2019 problem is less prominent given the simplified syntax of news headlines, containing, for example, fewer adverbs (like negations or intensifiers) than normal sentences (Turchi et al., 2012).", "startOffset": 227, "endOffset": 248}, {"referenceID": 6, "context": "set \u2013 based on the six basic emotions model (Ekman and Friesen, 1971) \u2013 do not exactly match with the ones provided by Rappler\u2019s Mood Meter, we first define a mapping between the two when possible, see Table 4.", "startOffset": 44, "endOffset": 69}, {"referenceID": 35, "context": "Similar to Warriner et al. (2013), we observe that even if the number of entries of our lexicon is far lower than SWN-prior approaches, the fact that we extracted and annotated words from documents grants a high coverage of language use.", "startOffset": 11, "endOffset": 34}, {"referenceID": 28, "context": "We do so by using a very na\u0131\u0308ve approach, similar to \u201cWordNetAffect presence\u201d discussed in (Strapparava and Mihalcea, 2008): for each headline, we simply compute a value, for any affective dimension, by averaging the corresponding affective scores \u2013obtained from DepecheMood- of all lemma#PoS present in the headline.", "startOffset": 91, "endOffset": 123}, {"referenceID": 28, "context": "Systems participating in the \u2018Affective Text\u2019 task plus the approaches in (Strapparava and Mihalcea, 2008).", "startOffset": 74, "endOffset": 106}, {"referenceID": 14, "context": "Other supervised approaches in the classification task (Mohammad, 2012; Bellegarda, 2010; Chaffar and Inkpen, 2011), reporting only overall performances, are not considered.", "startOffset": 55, "endOffset": 115}, {"referenceID": 1, "context": "Other supervised approaches in the classification task (Mohammad, 2012; Bellegarda, 2010; Chaffar and Inkpen, 2011), reporting only overall performances, are not considered.", "startOffset": 55, "endOffset": 115}, {"referenceID": 4, "context": "Other supervised approaches in the classification task (Mohammad, 2012; Bellegarda, 2010; Chaffar and Inkpen, 2011), reporting only overall performances, are not considered.", "startOffset": 55, "endOffset": 115}], "year": 2014, "abstractText": "While many lexica annotated with words polarity are available for sentiment analysis, very few tackle the harder task of emotion analysis and are usually quite limited in coverage. In this paper, we present a novel approach for extracting \u2013 in a totally automated way \u2013 a highcoverage and high-precision lexicon of roughly 37 thousand terms annotated with emotion scores, called DepecheMood. Our approach exploits in an original way \u2018crowd-sourced\u2019 affective annotation implicitly provided by readers of news articles from rappler.com. By providing new state-of-the-art performances in unsupervised settings for regression and classification tasks, even using a na\u0131\u0308ve approach, our experiments show the beneficial impact of harvesting social media data for affective lexicon building.", "creator": "dvips(k) 5.991 Copyright 2011 Radical Eye Software"}}}