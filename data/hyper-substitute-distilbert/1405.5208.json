{"id": "1405.5208", "review": {"conference": "arxiv", "VERSION": "v1", "DATE_OF_SUBMISSION": "23-Jan-2014", "title": "A Tutorial on Dual Decomposition and Lagrangian Relaxation for Inference in Natural Language Processing", "abstract": "dual transformation, and more generally lagrangian relaxation, is a suitable method for combinatorial operations ; variation has as formally applied to examining popular problems in constraint language processing ( nlp ). this tutorial enables quantitative overview of the technique. we try matching algorithms, evaluate formal arrangements for an method, and describe practical issues in implementing new techniques. while our examples come now drawn from the domain literature, sparse material potentially be allocated more relevance into math problems especially machine learning. given central theme covering this tutorial is that mirror relaxation is naturally applied in general but a broad context studying combinatorial algorithms, easing inference in models that restrict overboard per previous work on lagrangian relaxation limiting inference per graphical machinery.", "histories": [["v1", "Thu, 23 Jan 2014 02:50:15 GMT  (490kb)", "http://arxiv.org/abs/1405.5208v1", null]], "reviews": [], "SUBJECTS": "cs.CL cs.AI", "authors": ["alexander m rush", "michael collins"], "accepted": false, "id": "1405.5208"}, "pdf": {"name": "1405.5208.pdf", "metadata": {"source": "CRF", "title": "A Tutorial on Dual Decomposition and Lagrangian Relaxation for Inference in Natural Language Processing", "authors": ["Alexander M. Rush", "Michael Collins"], "emails": ["SRUSH@CSAIL.MIT.EDU", "MCOLLINS@CS.COLUMBIA.EDU"], "sections": [{"heading": null, "text": "binatorial optimization; it has recently been applied to several inference problems in natural language processing (NLP). This tutorial gives an overview of the technique. We describe example algorithms, describe formal guarantees for the method, and describe practical issues in implementing the algorithms. While our examples are predominantly drawn from the NLP literature, the material should be of general relevance to inference problems in machine learning. A central theme of this tutorial is that Lagrangian relaxation is naturally applied in conjunction with a broad class of combinatorial algorithms, allowing inference in models that go significantly beyond previous work on Lagrangian relaxation for inference in graphical models."}, {"heading": "1. Introduction", "text": "In many problems in statistical natural language processing, the task is to map some input x (e.g., a string) to some structured output y (e.g., a parse tree). This mapping is often defined as\ny\u2217 = argmax y\u2208Y h(y) (1)\nwhere Y is a finite set of possible structures for the input x, and h : Y \u2192 R is a function that assigns a score h(y) to each y in Y . For example, in part-of-speech tagging, x would be a sentence, and Y would be the set of all possible tag sequences for x; in parsing, x would be a sentence and Y would be the set of all parse trees for x; in machine translation, x would be a source-language sentence and Y would be the set of all possible translations for x. The problem of finding y\u2217 is referred to as the decoding problem. The size of Y typically grows exponentially with respect to the size of the input x, making exhaustive search for y\u2217 intractable.\nThis paper gives an overview of decoding algorithms for NLP based on dual decomposition, and more generally, Lagrangian relaxation. Dual decomposition leverages the observation that many decoding problems can be decomposed into two or more sub-problems, together with linear constraints that enforce some notion of agreement between solutions to the different problems. The sub-problems are chosen such that they can be solved efficiently using exact combinatorial\nc\u00a92012 AI Access Foundation. All rights reserved.\nalgorithms. The agreement constraints are incorporated using Lagrange multipliers, and an iterative algorithm\u2014for example, a subgradient algorithm\u2014is used to minimize the resulting dual. Dual decomposition algorithms have the following properties:\n\u2022 They are typically simple and efficient. For example, subgradient algorithms involve two steps at each iteration: first, each of the sub-problems is solved using a combinatorial algorithm; second, simple additive updates are made to the Lagrange multipliers.\n\u2022 They have well-understood formal properties, in particular through connections to linear programming (LP) relaxations.\n\u2022 In cases where the underlying LP relaxation is tight, they produce an exact solution to the original decoding problem, with a certificate of optimality.1 In cases where the underlying LP is not tight, heuristic methods can be used to derive a good solution; alternatively, constraints can be added incrementally until the relaxation is tight, at which point an exact solution is recovered.\nDual decomposition, where two or more combinatorial algorithms are used, is a special case of Lagrangian relaxation (LR). It will be useful to also consider LR methods that make use of a single combinatorial algorithm, together with a set of linear constraints that are again incorporated using Lagrange multipliers. The use of a single combinatorial algorithm is qualitatively different from dual decomposition approaches, although the techniques are very closely related.\nLagrangian relaxation has a long history in the combinatorial optimization literature, going back to the seminal work of Held and Karp (1971), who derive a relaxation algorithm for the traveling salesman problem. Initial work on Lagrangian relaxation/dual decomposition for decoding in statistical models focused on the MAP problem in Markov random fields (Komodakis, Paragios, & Tziritas, 2007, 2011). More recently, decoding algorithms have been derived for several models in statistical NLP, including models that combine a weighted context-free grammar (WCFG) with a finite-state tagger (Rush, Sontag, Collins, & Jaakkola, 2010); models that combine a lexicalized WCFG with a discriminative dependency parsing model (Rush et al., 2010); head-automata models for non-projective dependency parsing (Koo, Rush, Collins, Jaakkola, & Sontag, 2010); alignment models for statistical machine translation (DeNero & Macherey, 2011); models for event extraction (Riedel & McCallum, 2011); models for combined CCG parsing and supertagging (Auli & Lopez, 2011); phrase-based models for statistical machine translation (Chang & Collins, 2011); syntaxbased models for statistical machine translation (Rush & Collins, 2011); models for semantic parsing (Das, Martins, & Smith, 2012); models for parsing and tagging that make use of document-level constraints (Rush, Reichart, Collins, & Globerson, 2012); models for the coordination problem in natural language parsing (Hanamoto, Matsuzaki, & Tsujii, 2012); and models based on the intersection of weighted automata (Paul & Eisner, 2012). We will give an overview of several of these algorithms in this paper.\nWhile our focus is on examples from natural language processing, the material in this tutorial should be of general relevance to inference problems in machine learning. There is clear relevance to the problem of inference in graphical models, as described for example by Komodakis et al. (2007, 2011); however one central theme of this tutorial is that Lagrangian relaxation is naturally\n1. A certificate of optimality is information that allows a proof of optimality of the solution to be constructed in polynomial time.\napplied in conjunction with a much broader class of combinatorial algorithms than max-product belief propagation, allowing inference in models that go significantly beyond graphical models.\nThe remainder of this paper is structured as follows. Section 2 describes related work. Section 3 gives a formal introduction to Lagrangian relaxation. Section 4 describes a dual decomposition algorithm (from Rush et al., 2010) for decoding a model that combines a weighted context-free grammar with a finite-state tagger. This algorithm will be used as a running example throughout the paper. Section 5 describes formal properties of dual decomposition algorithms. Section 6 gives further examples of algorithms, and section 7 describes practical issues. Section 8 gives an overview of work on alternative optimization methods to the subgradient methods described in this tutorial. Finally, section 9 describes the relationship to LP relaxations, and describes tightening methods."}, {"heading": "2. Related Work", "text": "This tutorial draws on ideas from the fields of combinatorial optimization, machine learning, and natural language processing. In this section, we give a summary of work from these fields that is relevant to the methods we will describe."}, {"heading": "2.1 Combinatorial Optimization", "text": "Lagrangian relaxation (LR) is a widely used method in combinatorial optimization, going back to the seminal work of Held and Karp (1971) on the traveling salesman problem. See the work of Lemare\u0301chal (2001) and Fisher (1981) for surveys of LR methods, and the textbook of Korte and Vygen (2008) for background on combinatorial optimization. Decomposing linear and integer linear programs is also a fundamental technique in the optimization community (Dantzig & Wolfe, 1960; Everett III, 1963). There is a very direct relationship between LR algorithms and linear programming relaxations of combinatorial optimization problems; again, see the textbook of Korte and Vygen."}, {"heading": "2.2 Belief Propagation, and Linear Programming Relaxations for Inference in MRFs", "text": "There has been a large amount of research on the MAP inference problem in Markov random fields (MRFs). For tree-structured MRFs, max-product belief propagation (max-product BP) (Pearl, 1988) gives exact solutions. (Max-product BP is a form of dynamic programming, which is closely related to the Viterbi algorithm.) For general MRFs where the underlying graph may contain cycles, the MAP problem is NP-hard: this has led researchers to consider a number of approximate inference algorithms. Early work considered loopy variants of max-product BP (see for example Felzenszwalb & Huttenlocher, 2006, for the application of loopy max-product BP to problems in computer vision); however, these methods are heuristic, lacking formal guarantees.\nMore recent work has considered methods based on linear programming (LP) relaxations of the MAP problem. See the work of Yanover, Meltzer, and Weiss (2006), or section 1.6 of the work of Sontag, Globerson, and Jaakkola (2010), for a description. Methods based on LP relaxations have the benefit of stronger guarantees than loopy belief propagation. Inference is cast as an optimization problem, for example the problem of minimizing a dual. Since the dual problem is convex, convergence results from convex optimization and linear programming can be leveraged directly. One particularly appealing feature of these methods is that certificates of optimality can be given when the exact solution to the MAP problem is found.\nKomodakis et al. (2007, 2011) describe a dual decomposition method that provably optimizes the dual of an LP relaxation of the MAP problem, using a subgradient method. This work is a crucial reference for this tutorial. (Note that in addition, Johnson, Malioutov, & Willsky, 2007, also describes LR methods for inference in MRFs.)\nIn this tutorial we focus on subgradient algorithms for optimization of the dual objective. See section 8 for a discussion of alternative optimization approaches that have been developed within the machine learning community."}, {"heading": "2.3 Combinatorial Algorithms in Belief Propagation", "text": "A central idea in the algorithms we describe is the use of combinatorial algorithms other than maxproduct BP. This idea is closely related to earlier work on the use of combinatorial algorithms within belief propagation, either for the MAP inference problem (Duchi, Tarlow, Elidan, & Koller, 2007), or for computing marginals (Smith & Eisner, 2008). These methods generalize loopy BP in a way that allows the use of combinatorial algorithms. Again, we argue that methods based on Lagrangian relaxation are preferable to variants of loopy BP, as they have stronger formal guarantees."}, {"heading": "2.4 Linear Programs for Decoding in Natural Language Processing", "text": "Dual decomposition and Lagrangian relaxation are closely related to integer linear programming (ILP) approaches, and linear programming relaxations of ILP problems. Several authors have used integer linear programming directly for solving challenging problems in NLP. Germann, Jahr, Knight, Marcu, and Yamada (2001) use ILP to test the search error of a greedy phrase-based translation system on short sentences. Roth and Yih (2005) formulate a constrained sequence labeling problem as an ILP and decode using a general-purpose solver. Lacoste-Julien, Taskar, Klein, and Jordan (2006) describe a quadratic assignment problem for bilingual word alignment and then decode using an ILP solver. Both the work of Riedel and Clarke (2006) and Martins, Smith, and Xing (2009) formulates higher-order non-projective dependency parsing as an ILP. Riedel and Clarke decode using an ILP method where constraints are added incrementally. Martins et al. solve an LP relaxation and project to a valid dependency parse. Like many of these works, the method presented in this tutorial begins with an ILP formulation of the decoding problem; however, instead of employing a general-purpose solver we aim to speed up decoding by using combinatorial algorithms that exploit the underlying structure of the problem."}, {"heading": "3. Lagrangian Relaxation and Dual Decomposition", "text": "This section first gives a formal description of Lagrangian relaxation, and then gives a description of dual decomposition, an important special case of Lagrangian relaxation. The descriptions we give are deliberately concise. The material in this section is not essential to the remainder of this paper, and may be safely skipped by the reader, or returned to in a second reading. However the descriptions here may be useful for those who would like to immediately see a formal treatment of Lagrangian relaxation and dual decomposition. All of the algorithms in this paper are special cases of the framework described in this section."}, {"heading": "3.1 Lagrangian Relaxation", "text": "We assume that we have some finite set Y , which is a subset of Rd. The score associated with any vector y \u2208 Y is h(y) = y \u00b7 \u03b8 where \u03b8 is also a vector in Rd. The decoding problem is to find\ny\u2217 = argmax y\u2208Y h(y) = argmax y\u2208Y y \u00b7 \u03b8 (2)\nUnder these definitions, each structure y is represented as a d-dimensional vector, and the score for a structure y is a linear function, namely y \u00b7 \u03b8. In practice, in structured prediction problems y is very often a binary vector (i.e., y \u2208 {0, 1}d) representing the set of parts2 present in the structure y. The vector \u03b8 then assigns a score to each part, and the definition h(y) = y \u00b7 \u03b8 implies that the score for y is a sum of scores for the parts it contains.\nWe will assume that the problem in Eq. 2 is computationally challenging. In some cases, it might be an NP-hard problem. In other cases, it might be solvable in polynomial time, but with an algorithm that is still too slow to be practical.\nThe first key step in Lagrangian relaxation will be to choose a finite set Y \u2032 \u2282 Rd that has the following properties:\n\u2022 Y \u2282 Y \u2032. Hence Y \u2032 contains all vectors found in Y , and in addition contains some vectors that are not in Y .\n\u2022 For any value of \u03b8 \u2208 Rd, we can easily find\nargmax y\u2208Y \u2032\ny \u00b7 \u03b8\n(Note that we have replaced Y in Eq. 2 with the larger set Y \u2032.) By \u201ceasily\u201d we mean that this problem is significantly easier to solve than the problem in Eq. 2. For example, the problem in Eq. 2 might be NP-hard, while the new problem is solvable in polynomial time; or both problems might be solvable in polynomial time, but with the new problem having significantly lower complexity.\n\u2022 Finally, we assume that Y = {y : y \u2208 Y \u2032 and Ay = b} (3)\nfor some A \u2208 Rp\u00d7d and b \u2208 Rp. The condition Ay = b specifies p linear constraints on y. We will assume that the number of constraints, p, is polynomial in the size of the input.\nThe implication here is that the linear constraints Ay = b need to be added to the set Y \u2032, but these constraints considerably complicate the decoding problem. Instead of incorporating them as hard constraints, we will deal with these constraints using Lagrangian relaxation.\n2. For example, in context-free parsing each part might correspond to a tuple \u3008A \u2192 B C, i, k, j\u3009 where A \u2192 B C is a context-free rule, and i, k, j are integers specifying that non-terminal A spans words i . . . j in the input sentence, non-terminal B spans words i . . . k, and non-terminal C spans words (k + 1) . . . j. In finite-state tagging with a bigram tagging model each part might be a tuple \u3008A,B, i\u3009 whereA,B are tags, and i is an integer specifying that tag B is seen at position i in the sentence, and that tag A is seen at position (i \u2212 1). See the work of Rush et al. (2010) for a detailed treatment of both of these examples.\nWe introduce a vector of Lagrange multipliers, u \u2208 Rp. The Lagrangian is\nL(u, y) = y \u00b7 \u03b8 + u \u00b7 (Ay \u2212 b)\nThis function combines the original objective function y \u00b7 \u03b8, with a second term that incorporates the linear constraints and the Lagrange multipliers. The dual objective is\nL(u) = max y\u2208Y \u2032 L(u, y)\nand the dual problem is to find min u\u2208Rp L(u)\nA common approach\u2014which will be used in all algorithms in this paper\u2014is to use a subgradient algorithm to minimize the dual. We set the initial Lagrange multiplier values to be u(0) = 0. For k = 1, 2, . . . we then perform the following steps:\ny(k) = argmax y\u2208Y \u2032 L(u(k\u22121), y) (4)\nfollowed by u(k) = u(k\u22121) \u2212 \u03b4k(Ay(k) \u2212 b) (5)\nwhere \u03b4k > 0 is the step size at the k\u2019th iteration. Thus at each iteration we first find a structure y(k), and then update the Lagrange multipliers, where the updates depend on y(k).\nA crucial point is that y(k) can be found efficiently, because\nargmax y\u2208Y \u2032 L(u(k\u22121), y) = argmax y\u2208Y \u2032\n( y \u00b7 \u03b8 + u(k\u22121) \u00b7 (Ay \u2212 b) ) = argmax\ny\u2208Y \u2032 y \u00b7 \u03b8\u2032\nwhere \u03b8\u2032 = \u03b8 + A>u(k\u22121). Hence the Lagrange multiplier terms are easily incorporated into the objective function.\nWe can now state the following theorem:\nTheorem 1 The following properties hold for Lagrangian relaxation:\na). For any u \u2208 Rp, L(u) \u2265 maxy\u2208Y h(y).\nb). Under a suitable choice of the step sizes \u03b4k (see section 5), limk\u2192\u221e L(u(k)) = minu L(u).\nc). Define yu = argmaxy\u2208Y \u2032 L(u, y). If \u2203u such that Ayu = b, then yu = argmaxy\u2208Y y \u00b7 \u03b8 (i.e., yu is optimal).\nIn particular, in the subgradient algorithm described above, if for any k we have Ay(k) = b, then y(k) = argmaxy\u2208Y y \u00b7 \u03b8.\nd). minu L(u) = max\u00b5\u2208Q \u00b5 \u00b7 \u03b8, where the set Q is defined below.\nThus part (a) of the theorem states that the dual value provides an upper bound on the score for the optimal solution, and part (b) states that the subgradient method successfully minimizes this upper bound. Part (c) states that if we ever reach a solution y(k) that satisfies the linear constraints, then we have solved the original optimization problem.\nPart (d) of the theorem gives a direct connection between the Lagrangian relaxation method and an LP relaxation of the problem in Eq. 2. We now define the set Q. First, define \u2206 to be the set of all distributions over the set Y \u2032:\n\u2206 = {\u03b1 : \u03b1 \u2208 R|Y \u2032|, \u2211 y\u2208Y \u2032 \u03b1y = 1,\u2200y 0 \u2264 \u03b1y \u2264 1}\nThe convex hull of Y \u2032 is then defined as\nConv(Y \u2032) = {\u00b5 \u2208 Rd : \u2203\u03b1 \u2208 \u2206 s.t. \u00b5 = \u2211 y\u2208Y \u2032 \u03b1yy}\nFinally, define the set Q as follows:\nQ = {y : y \u2208 Conv(Y \u2032) and Ay = b}\nNote the similarity to Eq. 3: we have simply replaced Y \u2032 in Eq. 3 by the convex hull of Y \u2032. Y \u2032 is a subset of Conv(Y \u2032), and hence Y is a subset ofQ. A consequence of the Minkowski-Weyl theorem (Korte & Vygen, 2008, Thm. 3.31) is that Conv(Y \u2032) is a polytope (a bounded set that is specified by an intersection of a finite number of half spaces), and Q is therefore also a polytope. The problem\nmax \u00b5\u2208Q\n\u00b5 \u00b7 \u03b8\nis therefore a linear program, and is a relaxation of our original problem, maxy\u2208Y y \u00b7 \u03b8. Part (d) of theorem 1 is a direct consequence of duality in linear programming. It has the following implications:\n\u2022 By minimizing the dual L(u), we will recover the optimal value max\u00b5\u2208Q \u00b5 \u00b7 \u03b8 of the LP relaxation.\n\u2022 If max\u00b5\u2208Q \u00b5 \u00b7 \u03b8 = maxy\u2208Y y \u00b7 \u03b8 then we say that the LP relaxation is tight. In this case the subgradient algorithm is guaranteed3 to find the solution to the original decoding problem,\ny\u2217 = argmax \u00b5\u2208Q \u00b5 \u00b7 \u03b8 = argmax y\u2208Y y \u00b7 \u03b8\n\u2022 In cases where the LP relaxation is not tight, there are methods (e.g., see Nedic\u0301 & Ozdaglar, 2009) that allow us to recover an approximate solution to the linear program, \u00b5\u2217 = argmax\u00b5\u2208Q \u00b5\u00b7 \u03b8. Alternatively, methods can be used to tighten the relaxation until an exact solution is obtained.\n3. Under the assumption that there is unique solution y\u2217 to the problem maxy\u2208Y y \u00b7 \u03b8; if the solution is not unique then subtleties may arise."}, {"heading": "3.2 Dual Decomposition", "text": "We now give a formal description of dual decomposition. As we will see, dual decomposition is a special case of Lagrangian relaxation;4 however, it is important enough for the purposes of this tutorial to warrant its own description. Again, this section is deliberately concise, and may be safely skipped on a first reading.\nWe again assume that we have some finite set Y \u2282 Rd. Each vector y \u2208 Y has an associated score\nf(y) = y \u00b7 \u03b8(1)\nwhere \u03b8(1) is a vector in Rd. In addition, we assume a second finite set Z \u2282 Rd\u2032 , with each vector z \u2208 Z having an associated score\ng(z) = z \u00b7 \u03b8(2)\nThe decoding problem is then to find\nargmax y\u2208Y,z\u2208Z\ny \u00b7 \u03b8(1) + z \u00b7 \u03b8(2)\nsuch that Ay + Cz = b\nwhere A \u2208 Rp\u00d7d, C \u2208 Rp\u00d7d\u2032 , b \u2208 Rp. Thus the decoding problem is to find the optimal pair of structures, under the linear constraints specified by Ay + Cz = b. In practice, the linear constraints often specify agreement constraints between y and z: that is, they specify that the two vectors are in some sense coherent.\nFor convenience, and to make the connection to Lagrangian relaxation clear, we will define the following sets:\nW = {(y, z) : y \u2208 Y, z \u2208 Z, Ay + Cz = b} W \u2032 = {(y, z) : y \u2208 Y, z \u2208 Z}\nIt follows that our decoding problem is to find\nargmax (y,z)\u2208W\n( y \u00b7 \u03b8(1) + z \u00b7 \u03b8(2) ) (6)\nNext, we make the following assumptions:\n4. Strictly speaking, Lagrangian relaxation can also be viewed as a special case of dual decomposition: in the formulation of this section we can set Z = Y , \u03b8(2) = 0, and Ci,j = 0 for all i, j, thus recovering the Lagrangian relaxation problem from the previous section. In this sense Lagrangian relaxation and dual decomposition are equivalent (we can transform any Lagrangian relaxation problem to a dual decomposition problem, and vice versa). However, in our view dual decomposition is more naturally viewed as a special case of Lagrangian relaxation, in particular because the methods described in this tutorial go back to the work of Held and Karp (1971) (see section 6.3), which makes use of a single combinatorial algorithm. In addition, Lagrangian relaxation appears to be a more standard term in the combinatorial optimization literature: for example the textbook of Korte and Vygen (2008) has a description of Lagrangian relaxation but no mention of dual decomposition; there are several tutorials on Lagrangian relaxation in the combinatorial optimization literature (e.g., see Lemare\u0301chal, 2001; Fisher, 1981), but we have found it more difficult to find direct treatments of dual decompositon. Note however that recent work in the machine learning and computer vision communities has often used the term dual decomposition (e.g., Sontag et al., 2010; Komodakis et al., 2007, 2011).\n\u2022 For any value of \u03b8(1) \u2208 Rd, we can easily find argmaxy\u2208Y y \u00b7 \u03b8(1). Furthermore, for any value of \u03b8(2) \u2208 Rd\u2032 , we can easily find argmaxz\u2208Z z \u00b7 \u03b8(2). It follows that for any \u03b8(1) \u2208 Rd, \u03b8(2) \u2208 Rd\u2032 , we can easily find\n(y\u2217, z\u2217) = argmax (y,z)\u2208W \u2032 y \u00b7 \u03b8(1) + z \u00b7 \u03b8(2) (7)\nby setting y\u2217 = argmax\ny\u2208Y y \u00b7 \u03b8(1), z\u2217 = argmax z\u2208Z z \u00b7 \u03b8(2)\nNote that Eq. 7 is closely related to the problem in Eq. 6, but withW replaced byW \u2032 (i.e., the linear constraints Ay + Cz = b have been dropped). By \u201ceasily\u201d we again mean that these optimization problems are significantly easier to solve than our original problem in Eq. 6.\nIt should now be clear that the problem is a special case of the Lagrangian relaxation setting, as described in the previous section. Our goal involves optimization of a linear objective, over the finite setW , as given in Eq. 6; we can efficiently find the optimal value over a setW \u2032 such thatW is a subset ofW \u2032, andW \u2032 has dropped the linear constraints Ay + Cz = b.\nThe dual decomposition algorithm is then derived in a similar way to before. We introduce a vector of Lagrange multipliers, u \u2208 Rp. The Lagrangian is now\nL(u, y, z) = y \u00b7 \u03b8(1) + z \u00b7 \u03b8(2) + u \u00b7 (Ay + Cz \u2212 b)\nand the dual objective is L(u) = max\n(y,z)\u2208W \u2032 L(u, y, z)\nA subgradient algorithm can again be used to find minu\u2208Rp L(u). We initialize the Lagrange multipliers to u(0) = 0. For k = 1, 2, . . . we perform the following steps:\n(y(k), z(k)) = argmax (y,z)\u2208W \u2032 L(u(k\u22121), y, z)\nfollowed by u(k) = u(k\u22121) \u2212 \u03b4k(Ay(k) + Cz(k) \u2212 b)\nwhere each \u03b4k > 0 is a stepsize. Note that the solutions y(k), z(k) at each iteration are found easily, because it is easily verified that\nargmax (y,z)\u2208W \u2032\nL(u(k\u22121), y, z) = ( argmax y\u2208Y y \u00b7 \u03b8\u2032(1), argmax z\u2208Z z \u00b7 \u03b8\u2032(2), )\nwhere \u03b8\u2032(1) = \u03b8(1) + A>u(k\u22121) and \u03b8\u2032(2) = \u03b8(2) + C>u(k\u22121). Thus the dual decomposes into two easily solved maximization problems.\nThe formal properties for dual decomposition are very similar to those stated in theorem 1. In particular, it can be shown that\nmin u\u2208Rp L(u) = max (\u00b5,\u03bd)\u2208Q\n\u00b5 \u00b7 \u03b8(1) + \u03bd \u00b7 \u03b8(2)\nwhere the set Q is defined as\nQ = {(\u00b5, \u03bd) : (\u00b5, \u03bd) \u2208 Conv(W \u2032) and A\u00b5+ C\u03bd = d}\nThe problem\nmax (\u00b5,\u03bd)\u2208Q\n\u00b5 \u00b7 \u03b8(1) + \u03bd \u00b7 \u03b8(2)\nis again a linear programming problem, and L(u) is the dual of this linear program.\nThe descriptions of Lagrangian relaxation and dual decomposition that we have given are at a sufficient level of generality to include a very broad class of algorithms, including all those introduced in this paper. The remainder of this paper describes specific algorithms developed within this framework, describes experimental results and practical issues that arise, and elaborates more on the theory underlying these algorithms.\nNote that in this section we have described the dual-decomposition approach with two components. The generalization to more than two components is relatively straightforward; for example see the work of Komodakis et al. (2007, 2011), see also the work of Martins, Smith, Figueiredo, and Aguiar (2011)."}, {"heading": "4. An Example: Integration of a Parser and a Finite-State Tagger", "text": "We next describe a dual decomposition algorithm for decoding under a model that combines a weighted context-free grammar and a finite-state tagger. The classical approach for this problem is to use a dynamic programming algorithm, based on the construction of Bar-Hillel, Perles, and Shamir (1964) for the intersection of a context-free language and a finite-state language. The dual decomposition algorithm has advantages over exhaustive dynamic programming, in terms of both efficiency and simplicity. We will use this dual decomposition algorithm as a running example throughout this tutorial.\nWe first give a formal definition of the problem, describe motivation for the problem, and describe the classical dynamic programming approach. We then describe the dual decomposition algorithm."}, {"heading": "4.1 Definition of the Problem", "text": "Consider the problem of mapping an input sentence x to a parse tree y. Define Y to be the set of all parse trees for x. The parsing problem is to find\ny\u2217 = argmax y\u2208Y h(y) (8)\nwhere h(y) is the score for any parse tree y \u2208 Y . We consider the case where h(y) is the sum of two model scores: first, the score for y under a weighted context-free grammar; and second, the score for the part-of-speech (POS) sequence in y under a finite-state part-of-speech tagging model. More formally, we define h(y) to be\nh(y) = f(y) + g(l(y)) (9)\nwhere the functions f , g, and l are defined as follows:\n1. f(y) is the score for y under a weighted context-free grammar (WCFG). A WCFG consists of a context-free grammar with a set of rules G, and a scoring function \u03b8 : G\u2192 R that assigns a real-valued score to each rule in G. The score for an entire parse tree is the sum of scores for the rules it contains. As an example, consider the parse tree shown in Figure 1; for this tree,\nf(y) = \u03b8(S\u2192 NP VP) + \u03b8(NP\u2192 N) + \u03b8(N\u2192 United) +\u03b8(VP\u2192 V NP) + . . .\nWe remain agnostic as to how the scores for individual context-free rules are defined. As one example, in a probabilistic context-free grammar, we would define \u03b8(\u03b1 \u2192 \u03b2) = log p(\u03b1 \u2192 \u03b2|\u03b1). As a second example, in a conditional random field (CRF) (Lafferty, McCallum, & Pereira, 2001) we would define \u03b8(\u03b1 \u2192 \u03b2) = w \u00b7 \u03c6(\u03b1 \u2192 \u03b2) where w \u2208 Rq is a parameter vector, and \u03c6(\u03b1\u2192 \u03b2) \u2208 Rq is a feature vector representing the rule \u03b1\u2192 \u03b2.\n2. l(y) is a function that maps a parse tree y to the sequence of part-of-speech tags in y. For the parse tree in Figure 1, l(y) would be the sequence N V D A N.\n3. g(z) is the score for the part-of-speech tag sequence z under anm\u2019th-order finite-state tagging model. Under this model, if zi for i = 1 . . . n is the i\u2019th tag in z, then\ng(z) = n\u2211 i=1 \u03b8(i, zi\u2212m, zi\u2212m+1, . . . , zi)\nwhere \u03b8(i, zi\u2212m, zi\u2212m+1, . . . , zi) is the score for the sub-sequence of tags zi\u2212m, zi\u2212m+1, . . . , zi ending at position i in the sentence.5\nWe again remain agnostic as to how these \u03b8 terms are defined. As one example, g(z) might be the log-probability for z under a hidden Markov model, in which case\n\u03b8(i, zi\u2212m . . . zi) = log p(zi|zi\u2212m . . . zi\u22121) + log p(xi|zi)\n5. We define zi for i \u2264 0 to be a special \u201cstart\u201d POS symbol.\nwhere xi is the i\u2019th word in the input sentence. As another example, under a CRF we would have\n\u03b8(i, zi\u2212m . . . zi) = w \u00b7 \u03c6(x, i, zi\u2212m . . . zi)\nwhere w \u2208 Rq is a parameter vector, and \u03c6(x, i, zi\u2212m . . . zi) is a feature-vector representation of the sub-sequence of tags zi\u2212m . . . zi ending at position i in the sentence x.\nThe motivation for this problem is as follows. The scoring function h(y) = f(y) + g(l(y)) combines information from both the parsing model and the tagging model. The two models capture fundamentally different types of information: in particular, the part-of-speech tagger captures information about adjacent POS tags that will be missing under f(y). This information may improve both parsing and tagging performance, in comparison to using f(y) alone.6\nUnder this definition of h(y), the conventional approach to finding y\u2217 in Eq. 8 is to construct a new context-free grammar that introduces sensitivity to surface bigrams (Bar-Hillel et al., 1964). Roughly speaking, in this approach (assuming a first-order tagging model) rules such as\nVP\u2192 V NP\nare replaced with rules such as VPN,N \u2192 VN,V NPV,N (10)\nwhere each non-terminal (e.g., NP) is replaced with a non-terminal that tracks the preceding and last POS tag relative to that non-terminal. For example, NPV,N represents a NP that dominates a sub-tree whose preceding POS tag was V, and whose last POS tag is N. The weights on the new rules are just context-free weights from f(y). Furthermore, rules such as\nV\u2192 flies\nare replaced with rules such as VN,V \u2192 flies\nThe weights on these rules are the context-free weights from f(y) plus the bigram tag weights from g(z), in this example for the bigram N V. A dynamic programming parsing algorithm\u2014for example the CKY algorithm\u2014can then be used to find the highest scoring structure under the new grammar.\nThis approach is guaranteed to give an exact solution to the problem in Eq. 8; however it is often very inefficient. We have greatly increased the size of the grammar by introducing the refined non-terminals, and this leads to significantly slower parsing performance. As one example, consider the case where the underlying grammar is a CFG in Chomsky-normal form, with G non-terminals, and where we use a 2nd order (trigram) tagging model, with T possible part-of-speech tags. Define n to be the length of the input sentence. Parsing with the grammar alone would take O(G3n3) time, for example using the CKY algorithm. In contrast, the construction of Bar-Hillel et al. (1964)\n6. We have assumed that it is sensible, in a theoretical and/or empirical sense, to take a sum of the scores f(y) and g(l(y)). This might be the case, for example, if f(y) and g(z) are defined through structured prediction models (e.g., conditional random fields), and their parameters are estimated jointly using discriminative methods. If f(y) and g(z) are log probabilities under a PCFG and HMM respectively, then from a strict probabilistic sense it does not make sense to combine their scores in this way: however in practice this may work well; for example, this type of log-linear combination of probabilistic models is widely used in approaches for statistical machine translation.\nresults in an algorithm with a run time of O(G3T 6n3).7 The addition of the tagging model leads to a multiplicative factor of T 6 in the runtime of the parser, which is a very significant decrease in efficiency (it is not uncommon for T to take values of say 5 or 50, giving values for T 6 larger than 15, 000 or 15 million). In contrast, the dual decomposition algorithm which we describe next takes O(k(G3n3 + T 3n)) time for this problem, where k is the number of iterations required for convergence; in experiments, k is often a small number. This is a very significant improvement in runtime over the Bar-Hillel et al. method."}, {"heading": "4.2 The Dual Decomposition Algorithm", "text": "We now introduce an alternative formulation of the problem in Eq. 8, which will lead directly to the dual decomposition algorithm. Define T to be the set of all POS tags. Assume the input sentence has n words. For any parse tree y, for any position i \u2208 {1 . . . n}, for any tag t \u2208 T , we define y(i, t) = 1 if parse tree y has tag t at position i, y(i, t) = 0 otherwise. Similarly, for any tag sequence z, we define z(i, t) = 1 if the tag sequence has tag t at position i, 0 otherwise. As an example, the following parse tree and tag sequence have y(4, A) = 1 and z(4, A) = 1:\nS\nNP\nN\nUnited\nVP\nV\nflies\nNP\nD\nsome\nA\nlarge\nN\njet United1 flies2 some3 large4 jet5\nN V D A N\nIn addition, define Z to be the set of all possible POS tag sequences for the input sentence. We then introduce the following optimization problem:\nOptimization Problem 1 Find argmax y\u2208Y,z\u2208Z f(y) + g(z) (11)\nsuch that for all i \u2208 {1 . . . n}, for all t \u2208 T , y(i, t) = z(i, t).\nThus we now find the best pair of structures y and z such that they share the same POS sequence. We define (y\u2217, z\u2217) to be the pair of structures that achieve the argmax in this problem. The crucial\n7. To be precise, assume we have a finite-state automaton with Q states and a context-free chart with rule productions \u3008A \u2192 B C, i, k, j\u3009 for all A,B,C \u2208 G and 1 \u2264 i < k < j \u2264 n as well as productions \u3008A \u2192 wi, i\u3009 for all A \u2208 G and i \u2208 {1 . . . n}. (Here we use wi to refer to the i\u2019th word in the sentence, and the set G to refer to the set of nonterminals in the grammar. It follows that G = |G|.) Applying the Bar-Hillel intersection gives new rule productions \u3008As1,s3 \u2192 Bs1,s2 Cs2,s3 , i, k, j\u3009 for s1, s2, s3 \u2208 {1 . . . Q} as well as \u3008As,t \u2192 wi, i\u3009 for s, t \u2208 {1 . . . Q} where (s, t) is a valid state transition in the FSA. After intersection, we can count the free variables to see that there are O(G3n3Q3) rule productions, which implies that the CKY algorithm can find the best parse in O(G3n3Q3) time. In the case of tagging, a 2nd-order tagging model can be represented as an FSA with |T |2 states, where each state represents the previous two tags. After intersection, this yields an O(G3n3|T |6) time algorithm.\nclaim, which is easily verified, is that y\u2217 is also the argmax to the problem in Eq. 8. In this sense, solving the new problem immediately leads to a solution to our original problem.\nWe then make the following two assumptions. Whether these assumptions are satisfied will depend on the definitions of Y and f(y) (for assumption 1) and on the definitions of Z and g(z) (for assumption 2). The assumptions hold when f(y) is a WCFG and g(z) is a finite-state tagger, but more generally they may hold for other parsing and tagging models.\nAssumption 1 Assume that we introduce variables u(i, t) \u2208 R for i \u2208 {1 . . . n}, and t \u2208 T . We assume that for any value of these variables, we can find\nargmax y\u2208Y f(y) +\u2211 i,t u(i, t)y(i, t)  efficiently.\nAn example. Consider a WCFG where the grammar is in Chomsky normal form. The scoring function is defined as\nf(y) = \u2211\nX\u2192Y Z c(y,X \u2192 Y Z)\u03b8(X \u2192 Y Z) + \u2211 i,t y(i, t)\u03b8(t\u2192 wi)\nwhere we write c(y,X \u2192 Y Z) to denote the number of times that rule X \u2192 Y Z is seen in the parse tree y, and as before y(i, t) = 1 if word i has POS t, 0 otherwise (note that y(i, t) = 1 implies that the rule t \u2192 wi is used in the parse tree). The highest scoring parse tree under f(y) can be found efficiently, for example using the CKY parsing algorithm. We then have\nargmax y\u2208Y f(y) +\u2211 i,t u(i, t)y(i, t)  = argmax y\u2208Y  \u2211 X\u2192Y Z c(y,X \u2192 Y Z)\u03b8(X \u2192 Y Z) + \u2211 i,t y(i, t)(\u03b8(t\u2192 wi) + u(i, t)) \nThis argmax can again be found easily using the CKY algorithm, where the scores \u03b8(t \u2192 wi) are simply replaced by new scores defined as \u03b8\u2032(t\u2192 wi) = \u03b8(t\u2192 wi) + u(i, t).\nAssumption 2 Assume that we introduce variables u(i, t) \u2208 R for i \u2208 {1 . . . n}, and t \u2208 T . We assume that for any value of these variables, we can find\nargmax z\u2208Z g(z)\u2212\u2211 i,t u(i, t)z(i, t)  efficiently.\nAn example. Consider a 1st-order tagging model,\ng(z) = n\u2211 i=1 \u03b8(i, zi\u22121, zi)\nThen\nargmax z\u2208Z g(z)\u2212\u2211 i,t u(i, t)z(i, t)  = argmax\nz\u2208Z  n\u2211 i=1 \u03b8(i, zi\u22121, zi)\u2212 \u2211 i,t u(i, t)z(i, t)  = argmax\nz\u2208Z n\u2211 i=1 \u03b8\u2032(i, zi\u22121, zi)\nwhere \u03b8\u2032(i, zi\u22121, zi) = \u03b8(i, zi\u22121, zi)\u2212 u(i, zi)\nThis argmax can be found efficiently using the Viterbi algorithm, where we have new \u03b8\u2032 terms that incorporate the u(i, t) values.\nGiven these assumptions, the dual decomposition algorithm is shown in Figure 2. The algorithm manipulates a vector of variables u = {u(i, t) : i \u2208 {1 . . . n}, t \u2208 T }. We will soon see that each variable u(i, t) is a Lagrange multiplier enforcing the constraint y(i, t) = z(i, t) in our optimization problem. At each iteration the algorithm finds hypotheses y(k) and z(k); under assumptions 1 and 2 this step is efficient. If the two structures have the same POS sequence (i.e., y(k)(i, t) = z(k)(i, t) for all (i, t)) then the algorithm returns this solution. Otherwise, simple updates are made to the u(i, t) variables, based on the y(k)(i, t) and z(k)(i, t) values.\nIn a moment we\u2019ll give an example run of the algorithm. First, though, we give an important theorem:\nTheorem 2 If at any iteration of the algorithm in Figure 2 we have y(k)(i, t) = z(k)(i, t) for all (i, t), then (y(k), z(k)) is a solution to optimization problem 1.\nThis theorem is a direct consequence of theorem 5 of this paper. Thus if we do reach agreement between y(k) and z(k), then we are guaranteed to have an optimal solution to the original problem. Later in this tutorial we will give empirical results for various NLP problems showing how often, and how quickly, we reach agreement. We will also describe the theory underlying convergence; theory underlying cases where the algorithm doesn\u2019t converge; and methods that can be used to \u201ctighten\u201d the algorithm with the goal of achieving convergence.\nNext, consider the efficiency of the algorithm. To be concrete, again consider the case where f(y) is defined through a weighted CFG, and g(z) is defined through a finite-state tagger. Each iteration of the algorithm requires decoding under each of these two models. If the number of iterations k is relatively small, the algorithm can be much more efficient than using the construction of Bar-Hillel et al. (1964). As discussed before, assuming a context-free grammar in Chomsky normal form, and a trigram tagger with T tags, the CKY parsing algorithm takes O(G3n3) time, and the Viterbi algorithm for tagging takes O(T 3n) time. Thus the total running time for the dual decomposition algorithm is O(k(G3n3 + T 3n)) where k is the number of iterations required for convergence. In contrast, the construction of Bar-Hillel et al. results in an algorithm with running time ofO(G3T 6n3). The dual decomposition algorithm results in an additive cost for incorporating a tagger (a T 3n term is added into the run time), whereas the construction of Bar-Hillel et al. results in a much more expensive multiplicative cost (a T 6 term is multiplied into the run time). (Smith & Eisner, 2008, makes a similar observation about additive versus multiplicative costs in the context of belief propagation algorithms for dependency parsing.)"}, {"heading": "4.3 Relationship of the Approach to Section 3", "text": "It is easily verified that the approach we have described is an instance of the dual decomposition framework described in section 3.2. The set Y is the set of all parses for the input sentence; the set Z is the set of all POS sequences for the input sentence. Each parse tree y \u2208 Rd is represented as a vector such that f(y) = y \u00b7\u03b8(1) for some \u03b8(1) \u2208 Rd: there are a number of ways of representing parse trees as vectors, see the work of Rush et al. (2010) for one example. Similarly, each tag sequence z \u2208 Rd\u2032 is represented as a vector such that g(z) = z \u00b7 \u03b8(2) for some \u03b8(2) \u2208 Rd\u2032 . The constraints\ny(i, t) = z(i, t)\nfor all (i, t) can be encoded through linear constraints\nAy + Cz = b\nfor suitable choices of A, C, and b, assuming that the vectors y and z include components y(i, t) and z(i, t) respectively."}, {"heading": "4.4 An Example Run of the Algorithm", "text": "We now give an example run of the algorithm. For simplicity, we will assume that the step size \u03b4k is equal to 1 for all iterations k. We take the input sentence to be United flies some large jet. Initially, the algorithm sets u(i, t) = 0 for all (i, t). For our example, decoding with these initial weights leads to the two hypotheses\nS\nNP\nA\nUnited\nN\nflies\nD\nsome\nA\nlarge\nVP\nV\njet United1 flies2 some3 large4 jet5\nN V D A N\nThese two structures have different POS tags at three positions, highlighted in red; thus the two structures do not agree. We then update the u(i, t) variables based on these differences, giving new values as follows:\nu(1, A) = u(2, N) = u(5, V ) = \u22121\nu(1, N) = u(2, V ) = u(5, N) = 1\nAny u(i, t) values not shown still have value 0. We now decode with these new u(i, t) values, giving structures\nS\nNP\nN\nUnited\nVP\nV\nflies\nNP\nD\nsome\nA\nlarge\nN\njet United1 flies2 some3 large4 jet5\nA N D A N\nAgain, differences between the structures are shown in red. We update the u(i, t) values to obtain new values as follows:\nu(5, N) = \u22121\nu(5, V ) = 1\nwith all other u(i, t) values being 0. (Note that the updates reset u(1, A), u(1, N), u(2, N) and u(2, V ) back to zero.)\nWe decode again, with the new u(i, t) values; this time, the two structures are\nS\nNP\nN\nUnited\nVP\nV\nflies\nNP\nD\nsome\nA\nlarge\nN\njet United1 flies2 some3 large4 jet5\nN V D A N\nThese two structures have identical sequences of POS tags, and the algorithm terminates, with the guarantee that the solutions are optimal.\nRush et al. (2010) describe experiments using this algorithm to integrate the probabilistic parser of Collins (1997) with the POS tagger of Toutanova, Klein, Manning, and Singer (2003). (In these experiments the stepsize \u03b4k is not held constant, but is instead set using the strategy described in section 7.2 of this paper.) Figure 3 shows the percentage of cases where exact solutions are returned (we have agreement between y(k) and z(k)) versus the number of iterations of the algorithm. The algorithm produces exact solutions on over 99% of all examples. On over 94% of the examples the algorithm returns an exact solution in 10 iterations or fewer. So with these models at least, while the dual decomposition algorithm is not guaranteed to give an exact solution, in this case it is very successful at achieving this goal."}, {"heading": "5. Formal Properties", "text": "We now give some formal properties of the algorithm described in the previous section. We first describe three important theorems regarding the algorithm, and then describe connections between the algorithm and subgradient optimization methods."}, {"heading": "5.1 Three Theorems", "text": "Recall that the problem we are attempting to solve (optimization problem 1) is\nargmax y\u2208Y,z\u2208Z f(y) + g(z)\nsuch that for all i = 1 . . . n, t \u2208 T , y(i, t) = z(i, t)\nThe first step will be to introduce the Lagrangian for this problem. We introduce a Lagrange multiplier u(i, t) for each equality constraint y(i, t) = z(i, t): we write u = {u(i, t) : i \u2208 {1 . . . n}, t \u2208 T } to denote the vector of Lagrange mulipliers. Each Lagrange multiplier can take any positive or negative value. The Lagrangian is\nL(u, y, z) = f(y) + g(z) + \u2211 i,t u(i, t) (y(i, t)\u2212 z(i, t)) (12)\nNote that by grouping the terms that depend on y and z, we can rewrite the Lagrangian as\nL(u, y, z) = f(y) +\u2211 i,t u(i, t)y(i, t) + g(z)\u2212\u2211 i,t u(i, t)z(i, t)  Having defined the Lagrangian, the dual objective is\nL(u) = max y\u2208Y,z\u2208Z L(u, y, z)\n= max y\u2208Y f(y) +\u2211 i,t u(i, t)y(i, t) + max z\u2208Z g(z)\u2212\u2211 i,t u(i, t)z(i, t)  Under assumptions 1 and 2 described above, the dual valueL(u) for any value of u can be calculated efficiently: we simply compute the two max\u2019s, and sum them. Thus the dual decomposes in a very convenient way into two efficiently solvable sub-problems.\nFinally, the dual problem is to minimize the dual objective, that is, to find\nmin u L(u)\nWe will see shortly that the algorithm in Figure 2 is a subgradient algorithm for minimizing the dual objective.\nDefine (y\u2217, z\u2217) to be the optimal solution to optimization problem 1. The first theorem is as follows:\nTheorem 3 For any value of u, L(u) \u2265 f(y\u2217) + g(z\u2217)\nHence L(u) provides an upper bound on the score of the optimal solution. The proof is simple: Proof:\nL(u) = max y\u2208Y,z\u2208Z L(u, y, z) (13)\n\u2265 max y\u2208Y,z\u2208Z:y=z L(u, y, z) (14)\n= max y\u2208Y,z\u2208Z:y=z f(y) + g(z) (15) = f(y\u2217) + g(z\u2217) (16)\nHere we use the shorthand y = z to state that y(i, t) = z(i, t) for all (i, t). Eq. 14 follows because by adding the constraints y = z, we are optimizing over a smaller set of (y, z) pairs, and hence the max cannot increase. Eq. 15 follows because if y = z, we have\u2211\ni,t\nu(i, t) (y(i, t)\u2212 z(i, t)) = 0\nand hence L(u, y, z) = f(y) + g(z). Finally, Eq. 16 follows through the definition of y\u2217 and z\u2217. The property that L(u) \u2265 f(y\u2217) + g(z\u2217) for any value of u is often referred to as weak duality. The value of infu L(u)\u2212 f(y\u2217)\u2212 g(z\u2217) is often referred to as the duality gap or the optimal duality gap (see for example Boyd & Vandenberghe, 2004).\nNote that obtaining an upper bound on f(y\u2217) + g(z\u2217) (providing that it is relatively tight) can be a useful goal in itself. First, upper bounds of this form can be used as admissible heuristics for search methods such as A* or branch-and-bound algorithms. Second, if we have some method that generates a potential solution (y, z), we immediately obtain an upper bound on how far this solution is from being optimal, because\n(f(y\u2217) + g(z\u2217))\u2212 (f(y) + g(z)) \u2264 L(u)\u2212 (f(y) + g(z))\nHence if L(u)\u2212 (f(y) + g(z)) is small, then (f(y\u2217) + g(z\u2217))\u2212 (f(y) + g(z)) must be small. See section 7 for more discussion.\nOur second theorem states that the algorithm in Figure 2 successfully converges to minu L(u). Hence the algorithm successfully converges to the tightest possible upper bound given by the dual. The theorem is as follows:\nTheorem 4 Consider the algorithm in Figure 2. For any sequence \u03b41, \u03b42, \u03b43, . . . such that \u03b4k > 0 for all k \u2265 1, and\nlim k\u2192\u221e \u03b4k = 0 and \u221e\u2211 k=1 \u03b4k =\u221e,\nwe have lim k\u2192\u221e L(uk) = min u L(u)\nProof: See the work of Shor (1985). See also Appendix A.3. Our algorithm is actually a subgradient method for minimizing L(u): we return to this point in section 5.2. For now though, the important point is that our algorithm successfully minimizes L(u). Our final theorem states that if we ever reach agreement during the algorithm in Figure 2, we are guaranteed to have the optimal solution. We first need the following definitions:\nDefinition 1 For any value of u, define\ny(u) = argmax y\u2208Y f(y) +\u2211 i,t u(i, t)y(i, t)  and\nz(u) = argmax z\u2208Z g(z)\u2212\u2211 i,t u(i, t)z(i, t)  The theorem is then:\nTheorem 5 If \u2203u such that y(u)(i, t) = z(u)(i, t)\nfor all i, t, then f(y(u)) + g(z(u)) = f(y\u2217) + g(z\u2217)\ni.e., (y(u), z(u)) is optimal.\nProof: We have, by the definitions of y(u) and z(u), L(u) = f(y(u)) + g(z(u)) + \u2211 i,t u(i, t)(y(u)(i, t)\u2212 z(u)(i, t))\n= f(y(u)) + g(z(u))\nwhere the second equality follows because y(u)(i, t) = z(u)(i, t) for all (i, t). But L(u) \u2265 f(y\u2217) + g(z\u2217) for all values of u, hence\nf(y(u)) + g(z(u)) \u2265 f(y\u2217) + g(z\u2217) Because y\u2217 and z\u2217 are optimal, we also have\nf(y(u)) + g(z(u)) \u2264 f(y\u2217) + g(z\u2217) hence we must have\nf(y(u)) + g(z(u)) = f(y\u2217) + g(z\u2217)\nTheorems 4 and 5 refer to quite different notions of convergence of the dual decomposition algorithm. For the remainder of this tutorial, to avoid confusion, we will explicitly use the following terms:\n\u2022 d-convergence (short for \u201cdual convergence\u201d) will be used to refer to convergence of the dual decomposition algorithm to the minimum dual value: that is, the property that limk\u2192\u221e L(u(k)) = minu L(u). By theorem 4, assuming appropriate step sizes in the algorithm, we always have d-convergence.\n\u2022 e-convergence (short for \u201cexact convergence\u201d) refers to convergence of the dual decomposition algorithm to a point where y(i, t) = z(i, t) for all (i, t). By theorem 5, if the dual decomposition algorithm e-converges, then it is guaranteed to have provided the optimal solution. However, the algorithm is not guaranteed to e-converge."}, {"heading": "5.2 Subgradients", "text": "The proof of d-convergence, as defined in theorem 4, relies on the fact that the algorithm in Figure 2 is a subgradient algorithm for minimizing the dual objective L(u). Subgradient algorithms are a generalization of gradient-descent methods; they can be used to minimize convex functions that are non-differentiable. This section describes how the algorithm in Figure 2 is derived as a subgradient algorithm.\nRecall that L(u) is defined as follows:\nL(u) = max y\u2208Y,z\u2208Z L(u, y, z)\n= max y\u2208Y f(y) +\u2211 i,t u(i, t)y(i, t) + max z\u2208Z g(z)\u2212\u2211 i,t u(i, t)z(i, t)  and that our goal is to find minu L(u).\nFirst, we note that L(u) has the following properties:\n\u2022 L(u) is a convex function. That is, for any u(1) \u2208 Rd, u(2) \u2208 Rd, \u03bb \u2208 [0, 1],\nL(\u03bbu(1) + (1\u2212 \u03bb)u(2)) \u2264 \u03bbL(u(1)) + (1\u2212 \u03bb)L(u(2))\n(The proof is simple: see Appendix A.1.)\n\u2022 L(u) is not differentiable. In fact, it is easily shown that it is a piecewise linear function.\nThe fact that L(u) is not differentiable means that we cannot use a gradient descent method to minimize it. However, because it is nevertheless a convex function, we can instead use a subgradient algorithm. The definition of a subgradient is as follows:\nDefinition 2 (Subgradient) A subgradient of a convex function L : Rd \u2192 R at u is a vector \u03b3(u) such that for all v \u2208 Rd,\nL(v) \u2265 L(u) + \u03b3(u) \u00b7 (v \u2212 u)\nThe subgradient \u03b3(u) is a tangent at the point u that gives a lower bound to L(u): in this sense it is similar8 to the gradient for a convex but differentiable function.9 The key idea in subgradient methods is to use subgradients in the same way that we would use gradients in gradient descent methods. That is, we use updates of the form\nu\u2032 = u\u2212 \u03b4\u03b3(u)\nwhere u is the current point in the search, \u03b3(u) is a subgradient at this point, \u03b4 > 0 is a step size, and u\u2032 is the new point in the search. Under suitable conditions on the stepsizes \u03b4 (e.g., see theorem 4), these updates will successfully converge to the minimum of L(u).\n8. More precisely, for a function L(u) that is convex and differentiable, then its gradient at any point u is a subgradient at u. 9. It should be noted, however, that for a given point u, there may be more than one subgradient: this will occur, for example, for a piecewise linear function at points where the gradient is not defined.\nSo how do we calculate the subgradient for L(u)? It turns out that it has a very convenient form. As before (see definition 1), define y(u) and z(u) to be the argmax\u2019s for the two maximization problems in L(u). If we define the vector \u03b3(u) as\n\u03b3(u)(i, t) = y(u)(i, t)\u2212 z(u)(i, t)\nfor all (i, t), then it can be shown that \u03b3(u) is a subgradient of L(u) at u. The updates in the algorithm in Figure 2 take the form\nu\u2032(i, t) = u(i, t)\u2212 \u03b4(y(u)(i, t)\u2212 z(u)(i, t))\nand hence correspond directly to subgradient updates. See Appendix A.2 for a proof that the subgradients take this form, and Appendix A.3 for a proof of convergence for the subgradient optimization method."}, {"heading": "6. Other Examples", "text": "In this section we describe other examples of dual decomposition algorithms. Our first example, also from the work of Rush et al. (2010), is a dual decomposition algorithm that combines two parsing models. Our second example, from the work of Komodakis et al. (2007, 2011), is a dual decomposition algorithm for inference in Markov random fields. Finally, we describe the algorithm of Held and Karp (1971) for the traveling salesman problem, and the algorithm of Chang and Collins (2011) for decoding of phrase-based translation models."}, {"heading": "6.1 Combined Constituency and Dependency Parsing", "text": "Rush et al. (2010) describe an algorithm for finding the highest scoring lexicalized context-free parse tree for an input sentence, under a combination of two models: a lexicalized probabilistic context-free grammar, and a discriminative dependency parsing model.\nFigure 4 shows an example of a lexicalized context-free tree. We take Y to be the set of all lexicalized trees for the input sentence, and f(y) to be the score of the tree y under a lexicalized parsing model\u2014specifically, f(y) is the log-probability of y under the model of Collins (1997). Under this model, each lexicalized rule in y receives a score that is a log probability, and the log probability of y is a sum of the log probabilities for the rules that it contains.\nOur second model is a dependency parsing model. An example dependency parse is also shown in Figure 4. The set of all possible dependency parses for the sentence is Z; each parse z receives a score g(z) under the dependency parsing model. We use the discriminative dependency parsing model of Koo, Carreras, and Collins (2008) (see also McDonald, 2006).\nFor any lexicalized parse tree y, there is a mapping to an underlying dependency structure l(y). The decoding problem we consider is to find\nargmax y\u2208Y f(y) + g(l(y)) (17)\nThe motivation for this problem is that it will allow us to inject information from the dependency parsing model g(z) into the lexicalized parsing model of Collins (1997); Rush et al. (2010) show that this gives significant improvements in parsing accuracy.\nThe problem can be again solved exactly using a dynamic programming approach, where a dynamic program is created that is an intersection of the two models (there is a clear analogy to the Bar-Hillel et al. (1964) method for construction of a dynamic program for the intersection of a PCFG and an HMM). However this dynamic program is again relatively inefficient.\nWe develop a dual decomposition algorithm in a very similar way to before. For any dependency (i, j) where i \u2208 {0 . . . n} is the head word (we use 0 to denote the root symbol) and j \u2208 {1 . . . n}, j 6= i, is the modifier, we define y(i, j) = 1 if y contains the dependency (i, j), and y(i, j) = 0 otherwise. We define similar variables z(i, j) for dependency structures. We can then reformulate the problem in Eq. 17 as:\nOptimization Problem 2 Find argmax y\u2208Y,z\u2208Z f(y) + g(z) (18)\nsuch that for all (i, j), y(i, j) = z(i, j).\nA Lagrangian is introduced for this problem, which is very similar to that in Eq. 12, and a subgradient algorithm is used to minimize the resulting dual. We introduce Lagrange multipliers u(i, j) for all dependencies (i, j), whose initial values are u(0)(i, j) = 0 for all i, j. At each iteration of the algorithm we find\ny(k) = argmax y\u2208Y f(y) +\u2211 i,j u(k\u22121)(i, j)y(i, j)  using a dynamic programming algorithm for lexicalized context-free parsing (a trivial modification of the original algorithm for finding argmaxy f(y)). In addition we find\nz(k) = argmax z\u2208Z g(z)\u2212\u2211 i,j u(k\u22121)(i, j)z(i, j)  using a dynamic programming algorithm for dependency parsing (again, this requires a trivial modification to an existing algorithm). If y(k)(i, j) = z(k)(i, j) for all (i, j) then the algorithm has e-converged, and we are guaranteed to have a solution to optimization problem 2. Otherwise, we perform subgradient updates\nu(k)(i, j) = u(k\u22121)(i, j)\u2212 \u03b4k(y(k)(i, j)\u2212 z(k)(i, j))\nfor all (i, j), then go to the next iteration. Rush et al. (2010) describe experiments with this algorithm. The method e-converges on over 99% of examples, with over 90% of examples e-converging in 10 iterations or less. Figure 5 shows a histogram of the number of examples that have e-converged, versus the number of iterations of the algorithm. The method gives significant gains in parsing accuracy over the model of Collins (1997), and significant gains over a baseline method that simply forces the lexicalized CFG parser to have the same dependency structure as the first-best output from the dependency parser.10"}, {"heading": "6.2 The MAP Problem for Pairwise Markov Random Fields", "text": "Markov random fields (MRFs), and more generally graphical models, are widely used in machine learning and statistics. The MAP problem in MRFs\u2014 the problem of finding the most likely setting of the random variables in an MRF\u2014is an inference problem of central importance. In this section we describe the dual decomposition algorithm from the work of Komodakis et al. (2007, 2011) for finding the MAP solution in pairwise, binary, MRFs. Pairwise MRFs are limited to the case where potential functions consider pairs of random variables, as opposed to larger subsets; however, the generalization of the method to non-pairwise MRFs is straightforward.\nA commonly used approach for the MAP problem in MRFs is to use loopy max-product belief propagation. The dual decomposition algorithm has advantages in terms of stronger formal guarantees, as described in section 5.\n10. Note that Klein and Manning (2002) describe a method for combination of a dependency parser with a constituent based parser, where the score for an entire structure is again the sum of scores under two models. In this approach an A* algorithm is developed, where admissible estimates within the A* method can be computed efficiently using separate inference under the two models. There are interesting connections between the A* approach and the dual decomposition algorithm described in this section.\nThe MAP problem is as follows. Assume we have a vector y of variables y1, y2, . . . , yn, where each yi can take two possible values, 0 or 1 (the generalization to more than two possible values for each variable is straightforward). There are 2n possible settings of these n variables. An MRF assumes an underlying undirected graph (V,E), where V = {1 . . . n} is the set of vertices in the graph, and E is a set of edges. The MAP problem is then to find\nargmax y\u2208{0,1}n h(y) (19)\nwhere h(y) = \u2211 {i,j}\u2208E \u03b8i,j(yi, yj)\nHere each \u03b8i,j(yi, yj) is a local potential associated with the edge {i, j} \u2208 E, which returns a real value (positive or negative) for each of the four possible settings of (yi, yj).\nIf the underlying graph E is a tree, the problem in Eq. 19 is easily solved using max-product belief propagation, a form of dynamic programming. In contrast, for general graphs E, which may contain loops, the problem is NP-hard. The key insight behind the dual decomposition algorithm will be to decompose the graph E into m trees T1, T2, . . . , Tm. Inference over each tree can be performed efficiently; we use Lagrange multipliers to enforce agreement between the inference results for each tree. A subgradient algorithm is used, where at each iteration we first perform inference over each of the trees T1, T2, . . . , Tm, and then update the Lagrange multipliers in cases where there are disagreements.\nFor simplicity, we describe the case where m = 2. Assume that the two trees are such that T1 \u2282 E, T2 \u2282 E, and T1 \u222a T2 = E.11 Thus each of the trees contains a subset of the edges in E, but together the trees contain all edges in E. Assume that we define potential functions \u03b8(1)i,j for (i, j) \u2208 T1 and \u03b8(2)i,j for (i, j) \u2208 T2 such that\u2211 {i,j}\u2208E \u03b8i,j(yi, yj) = \u2211 {i,j}\u2208T1 \u03b8 (1) i,j (yi, yj) + \u2211 {i,j}\u2208T2 \u03b8 (2) i,j (yi, yj)\nThis is easy to do: for example, define\n\u03b8mi,j(yi, yj) = \u03b8i,j(yi, yj)\n#(i, j)\nfor m = 1, 2 where #(i, j) is 2 if the edge {i, j} appears in both trees, 1 otherwise. We can then define a new problem that is equivalent to the problem in Eq. 19:\nOptimization Problem 3 Find\nargmax y\u2208{0,1}n,z\u2208{0,1}n \u2211 {i,j}\u2208T1 \u03b8 (1) i,j (yi, yj) + \u2211 {i,j}\u2208T2 \u03b8 (2) i,j (zi, zj)\nsuch that yi = zi for i = 1 . . . n.\n11. It may not always be possible to decompose a graph E into just 2 trees in this way. Komodakis et al. (2007, 2011) describe an algorithm for the general case of more than 2 trees.\nNote the similarity to our previous optimization problems. Our goal is to find a pair of structures, y \u2208 {0, 1}n and z \u2208 {0, 1}n. The objective function can be written as\nf(y) + g(z)\nwhere f(y) = \u2211 {i,j}\u2208T1 \u03b8 (1) i,j (yi, yj)\nand g(z) = \u2211 {i,j}\u2208T2 \u03b8 (2) i,j (zi, zj)\nWe have a set of constraints, yi = zi for i = 1 . . . n, which enforce agreement between y and z. We then proceed as before\u2014we define a Lagrangian with a Lagrange multiplier ui for each constraint:\nL(u, y, z) = \u2211\n{i,j}\u2208T1\n\u03b8 (1) i,j (yi, yj) + \u2211 {i,j}\u2208T2 \u03b8 (2) i,j (zi, zj) + n\u2211 i=1 ui(yi \u2212 zi)\nWe then minimize the dual L(u) = max\ny,z L(u, y, z)\nusing a subgradient algorithm. The algorithm is initialized with u(0)i = 0 for i = 1 . . . n. At each iteration of the algorithm we find\ny(k) = argmax y\u2208{0,1}n  \u2211 {i,j}\u2208T1 \u03b8 (1) i,j (yi, yj) + \u2211 i u (k\u22121) i yi  and\nz(k) = argmax z\u2208{0,1}n  \u2211 {i,j}\u2208T2 \u03b8 (2) i,j (zi, zj)\u2212 \u2211 i u (k\u22121) i zi  These steps can be achieved efficiently, because T1 and T2 are trees, hence max-product belief propagation produces an exact answer. (The Lagrangian terms \u2211 i u (k\u22121) i yi and \u2211 i u (k\u22121) i zi are easily incorporated.) If y(k)i = z (k) i for all i then the algorithm has e-converged, and we are guaranteed to have a solution to optimization problem 3. Otherwise, we perform subgradient updates of the form\nu (k) i = u (k\u22121) i \u2212 \u03b4k(y (k) i \u2212 z (k) i )\nfor i = {1 . . . n}, then go to the next iteration. Intuitively, these updates will bias the two inference problems towards agreement with each other.\nKomodakis et al. (2007, 2011) show good experimental results for the method. The algorithm has some parallels to max-product belief propagation, where the ui values can be interpreted as \u201cmessages\u201d being passed between sub-problems."}, {"heading": "6.3 The Held and Karp Algorithm for TSPs", "text": "Our next example is the approach of Held and Karp (1971) for traveling salesman problems (TSPs), which is notable for being the original paper on Lagrangian relaxation. This algorithm is not an instance of dual decomposition. Instead of leveraging two or more combinatorial algorithms, in combination with agreement constraints, it makes use of a single combinatorial algorithm, together with a set of linear constraints that are again incorporated using Lagrange multipliers. While the use of two or more combinatorial algorithms, as seen in dual decomposition, is a very useful technique, broadening our scope to algorithms that make use of a single combinatorial algorithm will be very useful. For NLP decoding algorithms that leverage a single combinatorial algorithm, see the algorithm of Chang and Collins (2011) for decoding of phrase-based translation models (we describe this algorithm in the next section), and the algorithm of Rush and Collins (2011) for decoding of syntax-based translation models.\nA TSP is defined as follows. We have an undirected graph (V,E) with vertices V = {1, 2, . . . , n}, and edges E. Each edge e \u2208 E has a score \u03b8e \u2208 R. Any subset of the edges E can be represented as a vector y = {ye : e \u2208 E}, where ye = 1 if the edge is in the subset, and ye = 0 otherwise. Thus y is a vector in {0, 1}|E|. A tour of the graph is a subset of the edges that corresponds to a path through the graph that begins and ends at the same vertex, and includes every other vertex exactly once. See Figure 6 for an example of a tour. We use Y \u2282 {0, 1}|E| to denote the set of all possible tours. The traveling salesman problem is to find\nargmax y\u2208Y \u2211 e\u2208E ye\u03b8e\nThis problem is well-known to be NP-hard.12\nA key idea in the work of Held and Karp (1971) is that of a 1-tree, which, like a tour, is a subset of E. Held and Karp define a 1-tree as follows:\nA 1-tree consists of a tree on the vertex set {2, 3, . . . , n}, together with two distinct edges at vertex 1... Thus, a 1-tree has a single cycle, this cycle contains vertex 1, and vertex 1 always has degree two.\n12. In many presentations of the traveling salesman problem the goal is to find a minimum cost tour: for consistency with the rest of this tutorial our presentation considers the maximization problem, which is equivalent.\nFigure 6 shows an example 1-tree. We define Y \u2032 to be the set of all possible 1-trees. It follows that Y is a subset of Y \u2032, because every tour is also a 1-tree.\nCrucially, it is possible to find argmax y\u2208Y \u2032 \u2211 e\u2208E ye\u03b8e\nusing an efficient algorithm. In the first step, we find the maximum scoring spanning tree over the vertices {2, 3, . . . , n}, using a maximum spanning tree algorithm. In the second step, we add the two highest scoring edges that include vertex 1. It is simple to show that the resulting 1-tree is optimal. Thus while search over the set Y is NP-hard, search over the larger set Y \u2032 can be performed easily. The Lagrangian relaxation algorithm will explicitly leverage this observation.\nNext, we note that\nY = {y : y \u2208 Y \u2032, and for all i \u2208 {1, 2, . . . , n}, \u2211e:i\u2208e ye = 2} Each constraint of the form \u2211\ne:i\u2208e ye = 2 (20)\ncorresponds to the property that the i\u2019th vertex should have exactly two incident edges. Thus if we add the constraint that each vertex has exactly two incident edges, we go from the set of 1-trees to the set of tours. Constraints of the form in Eq. 20 are linear in the ye variables, and are therefore easily incorporated into a Lagrangian.\nHeld and Karp introduce the following optimization problem:\nOptimization Problem 4 Find argmax y\u2208Y \u2032 \u2211 e\u2208E ye\u03b8e\nsuch that for all i \u2208 {1, 2, . . . , n}, \u2211e:i\u2208e ye = 2. It is clear that this is equivalent to finding the highest scoring tour in the graph.\nAs before, we deal with the equality constraints using Lagrange multipliers. Define the Lagrange multipliers to be a vector u = {ui : i \u2208 {1 . . . n}}. The Lagrangian is\nL(u, y) = \u2211 e\u2208E ye\u03b8e + n\u2211 i=1 ui (\u2211 e:i\u2208e ye \u2212 2 )\nand the dual objective is L(u) = max\ny\u2208Y \u2032 L(u, y)\nThe subgradient algorithm takes the following form. Initially we set u(0)i = 0 for i = 1 . . . n. At each iteration we find\ny(k) = argmax y\u2208Y \u2032 (\u2211 e\u2208E ye\u03b8e + n\u2211 i=1 u (k\u22121) i (\u2211 e:i\u2208e ye \u2212 2 ))\n(21)\nIf the constraints are satisfied, i.e., if for all i\u2211 e:i\u2208e y(k)e = 2\nthen the algorithm terminates, with a guarantee that the structure y(k) is the solution to optimization problem 4. Otherwise, a subgradient step is used to modify the Lagrange multipliers. It can be shown that the subgradient of L(u) at u is the vector g(u) defined as\ng(u)(i) = \u2211 e:i\u2208e y(u)e \u2212 2\nwhere y(u) = argmaxy\u2208Y \u2032 L(u, y). Thus the subgradient step is for all i \u2208 {1 . . . n},\nu (k) i = u (k\u22121) i \u2212 \u03b4k (\u2211 e:i\u2208e y(k)e \u2212 2 )\n(22)\nNote that the problem in Eq. 21 is easily solved. It is equivalent to finding\ny(k) = argmax y\u2208Y \u2032 \u2211 e\u2208E ye\u03b8 \u2032 e\nwith modified edge weights \u03b8\u2032e: for an edge e = {i, j}, we define\n\u03b8\u2032e = \u03b8e + u (k\u22121) i + u (k\u22121) j\nHence the new edge weights incorporate the Lagrange multipliers for the two vertices in the edge. The subgradient step in Eq. 22 has a clear intuition. For vertices with greater than 2 incident edges in y(k), the value of the Lagrange multiplier ui is decreased, which will have the effect of penalising any edges including vertex i. Conversely, for vertices with fewer than 2 incident edges, ui will increase, and edges including that vertex will be preferred. The algorithm manipulates the ui values in an effort to enforce the constraints that each vertex has exactly two incident edges.\nWe note that there is a qualitative difference between this example and our previous algorithms. Our previous algorithms had employed two sets of structures Y and Z , two optimization problems, and equality constraints enforcing agreement between the two structures. The TSP relaxation instead involves a single set Y . The two approaches are closely related, however, and similar theorems apply to the TSP method (the proofs are trivial modifications of the previous proofs). We have\nL(u) \u2265 \u2211 e\u2208E y\u2217e\u03b8e\nfor all u, where y\u2217 is the optimal tour. Under appropriate step sizes for the subgradient algorithm, we have\nlim k\u2192\u221e L(u(k)) = min u L(u)\nFinally, if we ever find a structure y(k) that satisfies the linear constraints, then the algorithm has e-converged, and we have a guaranteed solution to the traveling salesman problem."}, {"heading": "6.4 Phrase-Based Translation", "text": "We next consider a Lagrangian relaxation algorithm, described in the work of Chang and Collins (2011), for decoding of phrase-based translation models (Koehn, Och, & Marcu, 2003). The input to a phrase-based translation model is a source-language sentence with n words, x = x1 . . . xn. The output is a sentence in the target language. The examples in this section will use German as the source language, and English as the target language. We will use the German sentence\nwir mu\u0308ssen auch diese kritik ernst nehmen\nas a running example. A key component of a phrase-based translation model is a phrase-based lexicon, which pairs sequences of words in the source language with sequences of words in the target language. For example, lexical entries that are relevent to the German sentence shown above include\n(wir mu\u0308ssen, we must) (wir mu\u0308ssen auch, we must also) (ernst, seriously)\nand so on. Each phrase entry has an associated score, which can take any value in the reals. We introduce the following notation. A phrase is a tuple (s, t, e), signifying that the subsequence xs . . . xt in the source language sentence can be translated as the target-language string e, using an entry from the phrase-based lexicon. For example, the phrase (1, 2,we must) would specify that the sub-string x1 . . . x2 can be translated as we must. Each phrase p = (s, t, e) receives a score \u03b8(p) \u2208 R under the model. For a given phrase p, we will use s(p), t(p) and e(p) to refer to its three components. We will use P to refer to the set of all possible phrases for the input sentence x.\nA derivation y is then a finite sequence of phrases, p1, p2, . . . pL. The length L can be any positive integer value. For any derivation y we use e(y) to refer to the underlying translation defined by y, which is derived by concatenating the strings e(p1), e(p2), . . . e(pL). For example, if\ny = (1, 3, we must also), (7, 7, take), (4, 5, this criticism), (6, 6, seriously) (23)\nthen\ne(y) = we must also take this criticism seriously\nThe score for any derivation y is then defined as\nh(y) = g(e(y)) + \u2211 p\u2208y \u03b8(p)\nwhere g(e(y)) is the score (log-probability) for e(y) under an n-gram language model. The set Y of valid derivations is defined as follows. For any derivation y, we define y(i) for i = 1 . . . n to be the number of times that source word i is translated in the derivation. More formally,\ny(i) = \u2211 p\u2208y [[s(p) \u2264 i \u2264 t(p)]]\nwhere [[\u03c0]] is 1 if the statement \u03c0 is true, 0 otherwise. The set of valid derivations is then\nY = {y \u2208 P\u2217 : for i = 1 . . . n, y(i) = 1}\nwhere P\u2217 is the set of finite length sequences of phrases. Thus for a derivation to be valid, each source-language word must be translated exactly once. Under this definition, the derivation in Eq. 23 is valid. The decoding problem is then to find\ny\u2217 = argmax y\u2208Y h(y) (24)\nThis problem is known to be NP-hard. Some useful intuition is as follows. A dynamic programming approach for this problem would need to keep track of a bit-string of length n specifying which of the n source language words have or haven\u2019t been translated at each point in the dynamic program. There are 2n such bit-strings, resulting in the dynamic program having an exponential number of states.\nWe now describe the Lagrangian relaxation algorithm. As before, the key idea will be to define a set Y \u2032 such that Y is a subset of Y \u2032, and such that\nargmax y\u2208Y \u2032 h(y) (25)\ncan be found efficiently. We do this by defining Y \u2032 = {y \u2208 P\u2217 : \u2211ni=1 y(i) = n} Thus derivations in Y \u2032 satisfy the weaker constraint that the total number of source words translated is exactly n: we have dropped the y(i) = 1 constraints. As one example, the following derivation is a member of Y \u2032, but is not a member of Y:\ny = (1, 3, we must also), (1, 2, we must), (3, 3, also), (6, 6, seriously) (26)\nIn this case we have y(1) = y(2) = y(3) = 2, y(4) = y(5) = y(7) = 0, and y(6) = 1. Hence some words are translated more than once, and some words are translated 0 times.\nUnder this definition of Y \u2032, the problem in Eq. 25 can be solved efficiently, using dynamic programming. In contrast to the dynamic program for Eq. 24, which keeps track of a bit-string of length n, the new dynamic program merely needs to keep track of how many source language words have been translated at each point in the search.\nWe proceed as follows. Note that\nY = {y : y \u2208 Y \u2032, and for i = 1 . . . n, y(i) = 1}\nWe introduce a Lagrange multiplier u(i) for each constraint y(i) = 1. The Lagrangian is\nL(u, y) = h(y) + n\u2211 i=1 u(i) (y(i)\u2212 1)\nThe subgradient algorithm is as follows. Initially we set u(0)(i) = 0 for all i. At each iteration we find\ny(k) = argmax y\u2208Y \u2032 L(u(k\u22121), y) (27)\nand perform the subgradient step\nu(k)(i) = u(k\u22121)(i)\u2212 \u03b4k(y(k)(i)\u2212 1) (28)\nIf at any point we have y(k)(i) = 1 for i = 1 . . . n, then we are guaranteed to have the optimal solution to the original decoding problem.\nThe problem in Eq. 27 can be solved efficiently, because\nargmax y\u2208Y \u2032\nL(u(k\u22121), y)\n= argmax y\u2208Y \u2032 g(e(y)) +\u2211 p\u2208y \u03b8(p) + n\u2211 i=1 u(k\u22121)(i) (y(i)\u2212 1) \n= argmax y\u2208Y \u2032 g(e(y)) +\u2211 p\u2208y \u03b8\u2032(p)  where\n\u03b8\u2032(p) = \u03b8(p) + t(p)\u2211 i=s(p) u(k\u22121)(i)\nThus we have new phrase scores, \u03b8\u2032(p), which take into account the Lagrange multiplier values for positions s(p) . . . t(p). The subgradient step in Eq. 28 has a clear intuition. For any source language word i that is translated more than once, the associated Lagrange multiplier u(i) will decrease, causing phrases including word i to be penalised at the next iteration. Conversely, any word translated 0 times will have its Lagrange multiplier increase, causing phrases including that word to be preferred at the next iteration. The subgradient method manipulates the u(i) values in an attempt to force each source-language word to be translated exactly once.\nThe description we have given here is a sketch: Chang and Collins (2011) describe details of the method, including a slightly more involved dynamic program that gives a tighter relaxation than the method we have described here, and a tightening method that incrementally adds constraints when the method does not initially e-converge. The method is successful in recovering exact solutions under a phrase-based translation model, and is far more efficient than alternative approaches based on general-purpose integer linear programming solvers."}, {"heading": "7. Practical Issues", "text": "This section reviews various practical issues that arise with dual decomposition algorithms. We describe diagnostics that can be used to track progress of the algorithm in minimizing the dual, and in providing a primal solution; we describe methods for choosing the step sizes, \u03b4k, in the algorithm; and we describe heuristics that can be used in cases where the algorithm does not provide an exact solution. We will continue to use the algorithm from section 4 as a running example, although our observations are easily generalized to other Lagrangian relaxation algorithms.\nThe first thing to note is that each iteration of the algorithm produces a number of useful terms, in particular:\n\u2022 The solutions y(k) and z(k).\n\u2022 The current dual value L(u(k)) (which is equal to L(u(k), y(k), z(k)).\nIn addition, in cases where we have a function l : Y \u2192 Z that maps each structure y \u2208 Y to a structure l(y) \u2208 Z , we also have\n\u2022 A primal solution y(k), l(y(k)).\n-19\n-18\n-17\n-16\n-15\n-14\n-13\n0 10 20 30 40 50 60\nV al\nue\nRound\nCurrent Primal Current Dual\nFigure 7: Graph showing the dual value L(u(k)) and primal value f(y(k)) + g(l(y(k))), versus iteration number k, for the subgradient algorithm on a translation example from the work of Rush and Collins (2011).\n\u2022 A primal value f(y(k)) + g(l(y(k))).\nBy a \u201cprimal solution\u201d we mean a pair (y, z) that satisfies all constraints in the optimization problem. For example, in optimization problem 1 (the combined HMM and PCFG problem from section 4) a primal solution has the properties that y \u2208 Y , z \u2208 Z , and y(i, t) = z(i, t) for all (i, t).\nAs one example, in the algorithm in Figure 2, at each iteration we produce a parse tree y(k). It is simple to recover the POS sequence l(y(k)) from the parse tree, and to calculate the score f(y(k))+g(l(y(k))) under the combined model. Thus even if y(k) and z(k) disagree, we can still use y(k), l(y(k)) as a potential primal solution. This ability to recover a primal solution from the value y(k) does not always hold\u2014but in cases where it does hold, it is very useful. It will allow us, for example, to recover an approximate solution in cases where the algorithm hasn\u2019t e-converged to an exact solution.\nWe now describe how the various items described above can be used in practical applications of the algorithm."}, {"heading": "7.1 An Example Run of the Algorithm", "text": "Figure 7 shows a run of the subgradient algorithm for the decoding approach for machine translation described in the work of Rush and Collins (2011). The behavior is typical of cases where the algorithm e-converges to an exact solution. We show the dual value L(u(k)) at each iteration, and the value for f(y(k)) + g(l(y(k))). A few important points are as follows:\n\u2022 Because L(u) provides an upper bound on f(y\u2217) + g(z\u2217) for any value of u, we have L(u(k)) \u2265 f(y(k)) + g(l(y(k)))\nat every iteration.\n\u2022 On this example we have e-convergence to an exact solution, at which point we have L(u(k)) = f(y(k)) + g(z(k)))\n-19\n-18\n-17\n-16\n-15\n-14\n-13\n0 10 20 30 40 50 60\nV al\nue\nRound\nBest Primal Best Dual\n0\n0.5\n1\n1.5\n2\n2.5\n3\n3.5\n4\n0 10 20 30 40 50 60\nV al\nue\nRound\nGap\nFigure 8 shows a plot of L\u2217k and p \u2217 k versus the number of iterations k for our previous example, and in addition shows a plot of the gap L\u2217k \u2212 p\u2217k. These graphs are, not surprisingly, much smoother than the graph in Figure 7. In particular we are guaranteed that the values for L\u2217k and p \u2217 k are monotonically decreasing and increasing respectively."}, {"heading": "7.2 Choice of the Step Sizes \u03b4k", "text": "Figure 9 shows convergence of the algorithm for various choices of step size, where we have chosen to keep the stepsize constant at each iteration. We immediately see a potential dilemma arising. With too small a step size (\u03b4 = 0.0005), convergence is smooth\u2014the dual value is monotonically decreasing\u2014but convergence is slow. With too large a step size (\u03b4 = 0.01), convergence is much faster in the initial phases of the algorithm, but the dual then fluctuates quite erratically. In practice it is often very difficult to choose a constant step size that gives good convergence properties in both early and late iterations of the algorithm.\nInstead, we have found that we often find improved convergence properties with a choice of step size \u03b4k that decreases with increasing k. One possibility is to use a definition such as \u03b4k = c/k or \u03b4k = c/ \u221a k where c > 0 is a constant. However these definitions can decrease the step size too rapidly\u2014in particular, they decrease the step size at all iterations, even in cases where progress is being made in decreasing the dual value. In many cases we have found that a more effective definition is\n\u03b4k = c\nt+ 1\nwhere c > 0 is again a constant, and t < k is the number of iterations prior to k where the dual value increases rather than decreases (i.e., the number of cases for k\u2032 \u2264 k where L(u(k\u2032)) > L(u(k\u2032\u22121))). Under this definition the step size decreases only when the dual value moves in the wrong direction."}, {"heading": "7.3 Recovering Approximate Solutions", "text": "Figure 10 shows a run of the algorithm where we fail to get e-convergence to an exact solution. In section 9.4 we will describe one possible strategy, namely tightening the relaxation, which can be used to produce an exact solution in these cases. Another obvious strategy, which is approximate, is to simply choose the best primal solution generated after k iterations of the algorithm, for some fixed k: i.e., to choose y(k \u2032), l(y(k \u2032)) where\nk\u2032 = argmax k\u2032\u2264k f(y(k \u2032)) + g(l(y(k \u2032)))\n-30\n-25\n-20\n-15\n-10\n-5\n0\n0 10 20 30 40 50 60 70\nV al\nue\nRound\nBest Primal\nCurrent Primal Current Dual\nFigure 10: Graph showing the dual value L(u(k)) and primal value f(y(k)) + g(l(y(k))), versus iteration number k, for the subgradient algorithm on a translation example from the work of Rush and Collins (2011), where the method does not e-converge to an exact solution.\n50\n60\n70\n80\n90\n100\n0 200 400 600 800 1000\nP er\nce nt\nag e\nMaximum Number of Dual Decomposition Iterations\n% validation UAS % certificates % match K=5000 50 60\n70\n80\n90\n100\n0 10 20 30 40 50\nP er\nce nt\nag e\nMaximum Number of Dual Decomposition Iterations\nf score % certificates\n% match K=50\nFigure 11: Figures showing effects of early stopping for the non-projective parsing algorithm of Koo et al. (2010) (left graph) and combined constituency and dependency parsing (right graph). In each case we plot three quantities versus the number of iterations, k: 1) the accuracy (UAS or f-score); 2) the percentage of cases where the algorithm e-converges giving an exact solution, with a certificate of optimality; 3) the percentage of cases where the best primal solution up to the k\u2019th iteration is the same as running the algorithm to e-convergence.\nAs described before, we can use L\u2217k \u2212 p\u2217k as an upper bound on the difference between this approximate solution and the optimal solution."}, {"heading": "7.4 Early Stopping", "text": "It is interesting to also consider the strategy of returning the best primal solution early in the algorithm in cases where the algorithm does eventually e-converge to an exact solution. In practice, this strategy can sometimes produce a high quality solution, albeit without a certificate of optimality, faster than running the algorithm to e-convergence. Figure 11 shows graphs for two problems: non-projective dependency parsing (Koo et al., 2010), and combined constituency and dependency\nparsing (Rush et al., 2010). In each case we show how three quantities vary with the number of iterations of the algorithm. The first quantity is the percentage of cases where the algorithm econverges, giving an exact solution, with a certificate of optimality. For combined constituency and dependency parsing it takes roughly 50 iterations for most (over 95%) of cases to e-converge; the second algorithm takes closer to 1000 iterations.\nIn addition, we show graphs indicating the quality of the best primal solution generated up to iteration k of the algorithm, versus the number of iterations, k. An \u201cearly stopping\u201d strategy would be to pick some fixed value for k, and to simply return the best primal solution generated in the first k iterations of the algorithm. We first plot the accuracy (f-score, or dependency accuracy respectively) for the two models under early stopping: we can see that accuracy very quickly asymptotes to its optimal value, suggesting that returning a primal solution before e-convergence can often yield high quality solutions. We also plot the percentage of cases where the primal solution returned is in fact identical to the primal solution returned when the algorithm is run to e-convergence. We again see that this curve asymptotes quickly, showing that in many cases the early stopping strategy does in fact produce the optimal solution, albeit without a certificate of optimality."}, {"heading": "8. Alternatives to Subgradient Optimization", "text": "This tutorial has focused on subgradient methods for optimization of the dual objective. Several alternative optimization algorithms have been proposed in the machine learning literature; in this section we give an overview of these approaches.\nWainwright, Jaakkola, and Willsky (2005) describe an early and important algorithm for Markov random fields (MRFs) based on LP relaxations, tree-reweighted message passing (TRW). Following the work of Kolmogorov (2006), we use TRW-E to refer to the edge-based variant of TRW, and TRW-T to refer to the tree-based algorithm. Kolmogorov (2006) derives a further variant, TRW-S (the \u201cS\u201d refers to the sequential nature of the algorithm). All three algorithms\u2014TRW-E, TRW-T, and TRW-S\u2014are motivated by the LP relaxation for MRFs, but none of them have a guarantee of converging to the optimal value of the LP. TRW-S has the strongest guarantee of the three algorithms, namely that it monotonically improves the dual value, but it may not converge to the optimal dual value.\nYanover et al. (2006) describe experiments comparing TRW-based algorithms to generic LP solvers for MRF problems (specifically, the LP solver they use is CPLEX13). The TRW-based algorithms are considerably more efficient than CPLEX, due to the fact that the TRW-based methods leverage the underlying structure of the MRF problem. The various Lagrangian relaxation algorithms described in the current paper can all be viewed as specialized algorithms for solving LP relaxations, which explicitly leverage combinatorial structure within the underlying problem.\nKomodakis et al. (2007, 2011) give experiments comparing the subgradient method to the TRWS and TRW-T algorithms. In these experiments TRW-S generally performs better than TRW-T. In several cases TRW-S finds the optimal dual solution faster than the subgradient method; in other cases TRW-S appears to get stuck (as expected given its lack of convergence guarantee), while the subgradient method finds the global optimum. Overall, the subgradient method is competitive with TRW-S: it may initially make slower progress on the dual objective, but has the benefit of guaranteed convergence to the global optimum of the LP relaxation.\n13. http://www.ilog.com/products/cplex/\nAnother important class of algorithms for optimizing the dual of the LP are block coordinate descent algorithms: for example the MPLP algorithm of Globerson and Jaakkola (2007). See the work of Sontag et al. (2010) for a discussion of these methods. Like TRW-S, the MPLP algorithm is guaranteed to monotonically improve the dual value, but is not guaranteed to converge to the global optimum of the MRF LP. In several experimental settings, the MPLP algorithm produces better dual values in early iterations than subgradient methods, but can get stuck at a non-optimal solution (Jojic, Gould, & Koller, 2010; Martins, Figueiredo, Aguiar, Smith, & Xing, 2011; Meshi & Globerson, 2011). Another complication of MPLP is that it requires computing max-marginals for the sub-problems at each iteration instead of MAP assignments. Max-marginals may be slower to compute in practice, and for some combinatorial problems computation may be asymptotically slower. (For example, for the directed spanning tree models from Koo et al., 2010, the MAP problem can be solved in O(n2) time where n is the length of the input sentence, but we are not aware of an algorithm that solves the max-marginal problem in better than O(n4) time.)\nIn other work, Jojic et al. (2010) describe an accelerated method for MRF inference, using the method of Nesterov (2005) to smooth the objective in the underlying decomposition. The method has a relatively fast rate of convergence (O(1/ ) time to reach a solution that is -close to optimal). Experiments from the work of Jojic et al. (2010) show a decrease in the number of iterations required compared to subgradient; however in the work of Martins et al. (2011) the accelerated method requires more iterations than the subgradient algorithm. In both sets of experiments, MPLP makes more initial progress than either method. Accelerated subgradient also requires computing subproblem marginals, which has similar disadvantages as MPLP\u2019s requirement of max-marginals.\nRecently, Martins et al. (2011) proposed an augmented Lagrangian method for inference using the alternating direction method of multipliers (ADMM). See the tutorial of Boyd, Parikh, Chu, Peleato, and Eckstein (2011) on ADMM. The augmented Lagrangian method further extends the objective with a quadratic penalty term representing the amount of constraint violation. ADMM is a method for optimizing this augmented problem that is able to maintain similar decomposibility properties as dual decomposition. Like the subgradient method, ADMM is guaranteed to find the optimum of the LP relaxation. Martins et al. (2011) show empirically that ADMM requires a comparable number of iterations to MPLP to find a good primal solution, while still being guaranteed to optimize the LP. A challenge of ADMM is that the extra quadratic term may complicate sub-problem decoding, for example it is not clear how to directly decode the parsing problems presented in this work with a quadratic term in the objective. Several alternative approaches have been proposed: Martins et al. (2011) binarize the combinatorial sub-problems into binary-valued factor graphs; Meshi and Globerson (2011) avoid the problem by instead applying ADMM to the dual of the LP; Martins (2012) and Das et al. (2012) use an iterative active set method that utilizes MAP solutions of the original sub-problems to solve the quadratic version. Martins (2012) also describes recent results on ADMM that give a O(1/ ) bound for relaxed primal convergence."}, {"heading": "9. The Relationship to Linear Programming Relaxations", "text": "This section describes the close relationship between the dual decomposition algorithm and linear programming relaxations. This connection will be very useful in understanding the behavior of the algorithm, and in particular in understanding the cases where the algorithm does not e-converge to an exact solution. In addition, it will suggest strategies for \u201ctightening\u201d the algorithm until an exact solution is found."}, {"heading": "9.1 The Linear Programming Relaxation", "text": "We continue to use the algorithm from section 4 as an example; the generalization to other problems is straightforward. First, define the set\n\u2206y = {\u03b1 : \u03b1 \u2208 R|Y|, \u2211 y \u03b1y = 1,\u2200y 0 \u2264 \u03b1y \u2264 1}\nThus \u2206y is a simplex, corresponding to the set of probability distributions over the finite set Y . Similarly, define\n\u2206z = {\u03b2 : \u03b2 \u2208 R|Z|, \u2211 z \u03b2z = 1, \u2200z 0 \u2264 \u03b2z \u2264 1}\nas the set of distributions over the set Z . We now define a new optimization problem, as follows:\nOptimization Problem 5 Find\nmax \u03b1\u2208\u2206y ,\u03b2\u2208\u2206z \u2211 y \u03b1yf(y) + \u2211 z \u03b2zg(z) (29)\nsuch that for all i, t, \u2211 y \u03b1yy(i, t) = \u2211 z \u03b2zz(i, t) (30)\nThis optimization problem is a linear program: the objective in Eq. 29 is linear in the variables \u03b1 and \u03b2; the constraints in Eq. 30, together with the constraints in the definitions of \u2206y and \u2206z , are also linear in these variables.\nThis optimization problem is very similar to our original problem, optimization problem 1. To see this, define \u2206\u2032y as follows:\n\u2206\u2032y = {\u03b1 : \u03b1 \u2208 R|Y|, \u2211 y \u03b1y = 1,\u2200y \u03b1y \u2208 {0, 1}}\nThus \u2206\u2032y is a subset of \u2206y, where the constraints 0 \u2264 \u03b1y \u2264 1 have been replaced by \u03b1y \u2208 {0, 1}. Define \u2206\u2032z similarly. Consider the following optimization problem, where we replace \u2206y and \u2206z in Eq. 29 by \u2206\u2032y and \u2206 \u2032 z respectively:\nOptimization Problem 6 Find\nmax \u03b1\u2208\u2206\u2032y ,\u03b2\u2208\u2206\u2032z \u2211 y \u03b1yf(y) + \u2211 z \u03b2zg(z) (31)\nsuch that for all i, t, \u2211 y \u03b1yy(i, t) = \u2211 z \u03b2zz(i, t) (32)\nThis new problem is equivalent to our original problem, optimization problem 1: choosing vectors \u03b1 \u2208 \u2206\u2032y and \u03b2 \u2208 \u2206\u2032z is equivalent to choosing a single parse in Y , and a single POS sequence in z. In this sense, optimization problem 5 is a relaxation of our original problem, where constraints of the form \u03b1y \u2208 {0, 1} and \u03b2z \u2208 {0, 1} are replaced with constraints of the form 0 \u2264 \u03b1y \u2264 1 and 0 \u2264 \u03b2z \u2264 1.\nNote that optimization problem 6 is an integer linear program, because the objective is again linear in the \u03b1 and \u03b2 variables, and the constraints on these variables combine linear constraints with integer constraints (that each \u03b1y and \u03b2z must be either 0 or 1). It is also worth noting that \u2206y is actually the convex hull of the finite set \u2206\u2032y. The points in \u2206 \u2032 y form the vertices of the polytope \u2206y. A useful theorem, which is central to the relationship between linear programming and combinatorial optimization problems, is the following:\nTheorem 6 For any finite set Y , and any function f : Y \u2192 R,\nmax y\u2208Y f(y) = max \u03b1\u2208\u2206y \u2211 y\u2208Y \u03b1yf(y)\nwhere \u2206y is as defined above.\nThe proof is simple, and is given in Appendix A.4."}, {"heading": "9.2 The Dual of the New Optimization Problem", "text": "We now describe the dual problem for the linear program in Eqs. 29 and 30. This will again be a function M(u) of a vector of dual variables u = {u(i, t) : i \u2208 {1 . . . n}, t \u2208 T }. A crucial result will be that the two dual functions M(u) and L(u) are identical.\nOur new Lagrangian is\nM(u, \u03b1, \u03b2) = \u2211 y \u03b1yf(y) + \u2211 z \u03b2zg(z) + \u2211 i,t u(i, t) (\u2211 y \u03b1yy(i, t)\u2212 \u2211 z \u03b2zz(i, t) )\n= \u2211 y \u03b1yf(y) + \u2211 i,t u(i, t) \u2211 y \u03b1yy(i, t)  +\n\u2211 z \u03b2zg(z)\u2212 \u2211 i,t u(i, t) \u2211 z \u03b2zz(i, t)  The new dual objective is\nM(u) = max \u03b1\u2208\u2206y ,\u03b2\u2208\u2206z M(u, \u03b1, \u03b2)\nNote that once again we have simply maximized out over the primal (\u03b1 and \u03b2) variables, ignoring the constraints in Eq. 30. The dual problem is to find\nmin u M(u)\nTwo theorems regarding the dual problem are then as follows:\nTheorem 7 Define (\u03b1\u2217, \u03b2\u2217) to be the solution to the optimization problem in Eqs. 29 and 30. Then\nmin u M(u) = \u2211 y \u03b1\u2217yf(y) + \u2211 z \u03b2\u2217zg(z)\nProof. This follows immediately by results from linear programming duality see the textbook of Korte and Vygen (2008) for more details.\nNote that we now have equality in the above, in contrast to our previous result,\nmin u L(u) \u2265 f(y\u2217) + g(z\u2217)\nwhere the dual function only gave an upper bound on the best primal solution. Our second theorem is as follows:\nTheorem 8 For any value of u, M(u) = L(u)\nThus the two dual functions are identical. Given that the subgradient algorithm we have described minimizesL(u), it therefore also minimizes the dual of the linear program in Eqs. 29 and 30.\nProof. We have\nM(u) = max \u03b1\u2208\u2206y \u2211 y \u03b1yf(y) + \u2211 i,t u(i, t) \u2211 y \u03b1yy(i, t) + max \u03b2\u2208\u2206z \u2211 z \u03b2zg(z)\u2212 \u2211 i,t u(i, t) \u2211 z \u03b2zz(i, t)\n = max\ny\u2208Y f(y) +\u2211 i,t u(i, t)y(i, t) + max z\u2208Z g(z)\u2212\u2211 i,t u(i, t)z(i, t)\n = L(u)\nwhere we have used theorem 6 to give\nmax \u03b1\u2208\u2206y \u2211 y \u03b1yf(y) + \u2211 i,t u(i, t) \u2211 y \u03b1yy(i, t)  = max y\u2208Y f(y) +\u2211 i,t u(i, t)y(i, t)  and we have used a similar result to replace the max over \u2206z by the max over Z ."}, {"heading": "9.3 An Example", "text": "We now give an example that illustrates these ideas. Through this example we will also illustrate what happens when the algorithm fails to e-converge.\nWe assume that there are three possible parse trees, Y = {y1, y2, y3}, and three possible tag sequences, Z = {z1, z2, z3}, shown in Figure 12. We will write distributions over these sets as vectors such as \u03b1 = [0, 0, 1] or \u03b2 = [0.5, 0.5, 0].\nNow consider pairs of vectors (\u03b1, \u03b2) that satisfy the constraints in Eq. 30. Figure 13 illustrates two possible solutions. One such pair, which we will denote as (\u03b11, \u03b21), is \u03b11 = [0, 0, 1], \u03b21 = [0, 0, 1]. It is easily verified that under this definition\u2211\ny\u2208Y \u03b11yy(1, c) = \u2211 z\u2208Y \u03b21zz(1, c) = \u2211 y\u2208Y \u03b11yy(2, c) = \u2211 z\u2208Y \u03b21zz(2, c) = 1\nwith all other expected values being equal to 0: hence (\u03b11, \u03b21) satisfies the constraints. This potential solution is integral, in that it puts weight 1 on a single parse tree/POS-tag sequence, with all other structures having weight 0.\nA second pair that satisfies the constraints is \u03b12 = [0.5, 0.5, 0], \u03b22 = [0.5, 0.5, 0]. Under these definitions, \u2211\ny\u2208Y \u03b12yy(1, a) = \u2211 z\u2208Y \u03b22zz(1, a) = \u2211 y\u2208Y \u03b12yy(1, b) = \u2211 z\u2208Y \u03b22zz(1, b) = 0.5\nand \u2211 y\u2208Y \u03b12yy(2, a) = \u2211 z\u2208Y \u03b22zz(2, a) = \u2211 y\u2208Y \u03b12yy(2, b) = \u2211 z\u2208Y \u03b22zz(2, b) = 0.5\nwith all other expected values being equal to 0. The pair (\u03b12, \u03b22) is a fractional solution, in that it puts fractional (0.5) weight on some structures.\nNext, consider different definitions for the functions f(y) and g(z). Consider first the definitions f = [0, 0, 1] and g = [0, 0, 1] (we write f = [0, 0, 1] as shorthand for f(y1) = 0, f(y2) = 0, f(y3) = 1). The solution to the problem in Eqs. 29 and 30 is then the pair (\u03b11, \u03b21).\nAlternatively, consider the definitions f = [1, 1, 2] and g = [1, 1,\u22122]. In this case the following situation arises:\n\u2022 The pair (\u03b11, \u03b21) achieves score 0 under the objective in Eq. 29, whereas the pair (\u03b12, \u03b22) achieves a score of 2. Thus the solution to the problem in Eqs. 29 and 30 is (\u03b12, \u03b22), which is a fractional solution.\n\u2022 By theorem 7, minuM(u) is equal to the value for the optimal primal solution, i.e., minuM(u) = 2. Hence minu L(u) = 2.\n\u2022 In contrast, the solution to the original optimization problem 1 is (y\u2217, z\u2217) = (y3, z3): in fact, (y3, z3) is the only pair of structures that satisfies the constraints y(i, t) = z(i, t) for all (i, t). Thus f(y\u2217) + g(z\u2217) = 0. We have\nmin u L(u) = 2 > f(y\u2217) + g(z\u2217) = 0\nThus there is a clear gap between the minimum dual value, and the score for the optimal primal solution.\nFigure 14 shows a trace of the subgradient method on this problem. After nine iterations the method has reached L(u(9)) = 2.06, which is close to the optimal dual value. In this case, however, the algorithm does not reach agreement between the structures y(k) and z(k). Instead, it reaches a point where it alternates between solutions (y(1), z(1)), and (y(2), z(2)). Thus the dual d-converges to its minimum value, but the primal solutions generated alternate between the structures y1, y2, z1, z2 that have greater than 0 weight in the fractional solution (\u03b12, \u03b22). This behavior is typical of cases where there is a duality gap, i.e., where minu L(u) is strictly greater than f(y\u2217) + g(z\u2217)."}, {"heading": "9.4 Fixing E-Convergence: Tightening Approaches", "text": "We now describe a \u201ctightening\u201d approach that can be used to fix the issue of non-convergence given in the previous example.\nConsider again the problem of integrated CFG parsing and HMM tagging. Assume that the input sentence is of length n. The first approach is as follows. We introduce new variables y(i, t1, t2) for i = 1 . . . (n \u2212 1), t1 \u2208 T , t2 \u2208 T , with y(i, t1, t2) = 1 if y(i, t1) = 1 and y(i + 1, t2) = 1, 0 otherwise. Thus the new variables track tag bigrams. Similarly, we introduce variables z(i, t1, t2) for tag sequences z \u2208 Z . We now define the set of constraints to be\ny(i, t) = z(i, t)\nfor all i \u2208 {1 . . . n}, t \u2208 T (the same constraints as before), and in addition\ny(i, t1, t2) = z(i, t1, t2)\nfor all i \u2208 {1 . . . n\u2212 1}, t1 \u2208 T , t2 \u2208 T . We then proceed as before, using Lagrange multipliers u(i, t) to enforce the first set of constraints, and Lagrange multipliers v(i, t1, t2) to enforce the second set of constraints. The dual\ndecomposition algorithm will require us to find\ny(k) = argmax y\u2208Y f(y) + \u2211 i,t u(k\u22121)(i, t)y(i, t) + \u2211 i,t1,t2 v(k\u22121)(i, t1, t2)y(i, t1, t2) (33)\nand z(k) = argmax\nz\u2208Z g(z)\u2212 \u2211 i,t u(k\u22121)(i, t)z(i, t)\u2212 \u2211 i,t1,t2 v(k\u22121)(i, t1, t2)z(i, t1, t2) (34)\nat each iteration, followed by updates of the form\nu(k)(i, t)\u2190 u(k\u22121)(i, t)\u2212 \u03b4(y(k)(i, t)\u2212 z(k)(i, t))\nand v(k)(i, t1, t2)\u2190 v(k\u22121)(i, t1, t2)\u2212 \u03b4(y(k)(i, t1, t2)\u2212 z(k)(i, t1, t2))\nIt can be shown that if g(z) is defined through a bigram HMM model, the above method is guaranteed to e-converge to an exact solution. In fact, the underlying LP relaxation is now tight, in that only integral solutions are possible.\nThe problem with this approach is that finding the argmax in Eq. 33 is now expensive, due to the v(i, t1, t2)y(i, t1, t2) terms: in fact, it requires the exact dynamic programming algorithm for intersection of a bigram HMM with a PCFG. Thus we end up with an algorithm that is at least as expensive as integration of a bigram HMM with a PCFG using the construction of Bar-Hillel et al. (1964).14\nA second approach, which may be more efficient, is as follows. Rather than introducing all constraints of the form of Eq. 33, we might introduce a few selected constraints. As an example, with the previous non-convergent example we might add the single constraint\ny(1, a, b) = z(1, a, b)\nWe have a single Lagrange multiplier v(1, a, b) for this new constraint, and the dual decomposition algorithm requires the following steps at each iteration:\ny(k) = argmax y\u2208Y f(y) + \u2211 i,t u(k\u22121)(i, t)y(i, t) + v(k\u22121)(1, a, b)y(1, a, b) (35)\nand z(k) = argmax\nz\u2208Z g(z)\u2212 \u2211 i,t u(k\u22121)(i, t)z(i, t)\u2212 v(k\u22121)(1, a, b)z(1, a, b) (36)\nand updates u(k)(i, t)\u2190 u(k\u22121)(i, t)\u2212 \u03b4(y(k)(i, t)\u2212 z(k)(i, t))\nand v(k)(1, a, b)\u2190 v(k\u22121)(1, a, b)\u2212 \u03b4(y(k)(1, a, b)\u2212 z(k)(1, a, b))\nFigure 15 shows a run of the subgradient algorithm with this single constraint added. The fractional solution (\u03b12, \u03b22) is now eliminated, and the method e-converges to the correct solution.\nTwo natural questions arise:\n14. If g(z) is defined through a bigram HMM, then clearly nothing has been gained in efficiency over the Bar-Hillel et al. (1964) method. If g(z) is more complex, for example consisting of a trigram model, the dual decomposition method may still be preferable.\n\u2022 Which constraints should be added? One strategy is to first run the subgradient method with the basic constraints, as shown in Figure 14. Some heuristic is used to determine that the dual is no longer decreasing at a significant rate. At that point, it can be determined that the algorithm is oscillating between solutions (y1, z1) and (y2, z2), and that the additional constraint y(1, a, b) = z(1, a, b) would rule out these solutions; hence this constraint is added.\n\u2022 When is this more efficient than adding all constraints in Eq. 33? Our toy example is too simple to illustrate the benefit of only adding selected constraints. To understand the benefit, consider the case where the sentence length n is reasonably large. In that case, we might add bigram constraints at only a few positions in the sentence: in practice the CKY decoding algorithm will only need to introduce the Bar-Hillel et al. (1964) machinery at these selected points, which can be much more efficient that introducing all constraints.\nFor examples of methods that tighten dual decomposition/Lagrangian relaxation techniques using additional constraints, see the work of Sontag, Meltzer, Globerson, Jaakkola, and Weiss (2008), Rush and Collins (2011), Chang and Collins (2011), and Das et al. (2012). This is related to previous work on non-projective dependency parsing (Riedel & Clarke, 2006) that incrementally adds constraints to an integer linear program solver."}, {"heading": "9.5 Compact Linear Programs", "text": "The LP relaxations that we have described have a very large set of variables: that is, one variable for each member of Y and Z . In most cases of interest, the sets Y and Z will be exponential in size.\nIn this section we describe how to derive equivalent linear programs with far fewer variables. This is a problem of practical interest: for many problems, we have found it beneficial to implement the underlying LP relaxation within a generic LP solver, as a way of debugging dual decomposition\nalgorithms. This is practical with the compact LPs that we describe in this section, but is clearly impractical with the exponential-size linear programs described in the previous section.\nFirst, consider the abstract description of Lagrangian relaxation given in section 3. The LP relaxation was\nargmax \u00b5\u2208Q\n\u00b5 \u00b7 \u03b8\nwhere Q = {y : y \u2208 Conv(Y \u2032) and Ay = b}\nwhere A \u2208 Rp\u00d7d and b \u2208 Rp. Recall that Conv(Y \u2032) is the convex hull of the set Y \u2032. Next, assume that Conv(Y \u2032) can itself be defined through a polynomial number of linear constraints: that is,\nConv(Y \u2032) = {y \u2208 Rd : Cy = e, y \u2265 0} (37)\nfor some C \u2208 Rq\u00d7d and e \u2208 Rq, where the number of constraints, q, is polynomial. In this case we have an explicit characterization of the set Q as"}, {"heading": "Q = {y \u2208 Rd : Cy = e, y \u2265 0 and Ay = b}", "text": "Because d, p, and q are all polynomial in size, the resulting linear program is polynomial in size. In this sense it is \u201ccompact\u201d.\nThe remaining question is whether a characterization of the form of Eq. 37 exists, and if so, how it is defined. Recall that we made the assumption that for any value of \u03b8,\nargmax y\u2208Y \u2032\ny \u00b7 \u03b8 (38)\ncan be found using a combinatorial algorithm. For many combinatorial algorithms, there are LP formulations that are polynomial in size: these formulations lead directly to definitions of C and e.15 For example, Martin, Rardin, and Campbell (1990) give such a construction for dynamic programming algorithms, which includes parsing algorithms for weighted context-free grammars, the Viterbi algorithm, and other dynamic programs used in NLP. Martins et al. (2009) make use of a construction for directed spanning trees (see also Magnanti & Wolsey, 1994), and apply it to nonprojective dependency parsing. Korte and Vygen (2008) describe many other such constructions. In short, given a combinatorial algorithm that solves the problem in Eq. 38, it is often straightforward to find a recipe for constructing a pair (C, e) that completely characterizes Conv(Y \u2032).\nIt is straightforward to extend this idea to the LP for dual decomposition. Consider again our running example, (optimization problem 1),\nargmax y\u2208Y,z\u2208Z f(y) + g(z)\nsuch that for all i = 1 . . . n, t \u2208 T , y(i, t) = z(i, t)\nRush et al. (2010) give a full description of the compact LP for this problem: we give a sketch here.\n15. There is one subtlety here: in some cases additional auxilliary variables may need to be introduced. See for example the spanning tree construction of Magnanti and Wolsey (1994). However the number of auxilliary variables is generally polynomial in number, hence this is benign.\nDefine each y to be a vector in {0, 1}d that specifies which context-free rules y contains. It follows that Y is a subset of {0, 1}d. We then have\nf(y) = y \u00b7 \u03b8\nwhere \u03b8 \u2208 Rd is a vector specifying the weight for each rule. Similarly, define z to be a vector in {0, 1}d\u2032 that specifies the trigrams that z contains (assuming that g(z) is a trigram tagging model). It follows that Z is a subset of {0, 1}d\u2032 . We can then write\ng(z) = z \u00b7 \u03b8\u2032\nfor some \u03b8\u2032 \u2208 Rd\u2032 . The compact LP is then\nargmax \u00b5\u2208Conv(Y),\u03bd\u2208Conv(Z)\n\u00b5 \u00b7 \u03b8 + \u03bd \u00b7 \u03b8\u2032\nsuch that for all i = 1 . . . n, t \u2208 T , \u00b5(i, t) = \u03bd(i, t)\nAgain, the existence of combinatorial algorithms for the problems argmaxy\u2208Y y\u00b7\u03b8 and argmaxz\u2208Z z\u00b7 \u03b8\u2032 implies explicit representations\nConv(Y) = {\u00b5 \u2208 Rd : A\u00b5 = b, \u00b5 \u2265 0}\nand Conv(Z) = {\u03bd \u2208 Rd\u2032 : C\u03bd = e, \u03bd \u2265 0}\nwhere A, b, C and e are polynomial in size. Rush et al. (2010) describe this construction in detail for the case where a weighted CFG is combined with a finite-state tagger."}, {"heading": "9.6 Summary", "text": "To summarize, the key points of this section were as follows:\n\u2022 We introduced a linear programming problem that was a relaxation of our original problem. The function L(u) was shown to be the dual of this linear programming relaxation.\n\u2022 In cases where the optimal solution to the underlying LP is fractional, the subgradient method will still d-converge to minu L(u). However the primal solutions (y(k), z(k)) will alternate between different solutions that do not satisfy the y(i, t) = z(i, t) constraints.\n\u2022 In practice, tightening methods can be used to improve convergence. These methods selectively introduce constraints in an effort to improve convergence of the method, with the cost of increased complexity in finding y(k) and/or z(k). The precise constraints to be added can be chosen by identifying constraints that are frequently violated during the subgradient method.\n\u2022 Finally, we described methods that construct a compact linear program that is equivalent to the original LP relaxation. This linear program is often small enough to be solved by a generic LP solver; this can be useful in debugging dual decomposition or Lagrangian relaxation algorithms."}, {"heading": "10. Conclusions", "text": "A broad class of inference problems in statistical NLP and other areas of machine learning are amenable to Lagrangian relaxation (LR) methods. LR methods make use of combinatorial algorithms in combination with linear constraints that are introduced using Lagrange multipliers: iterative methods are used to minimize the resulting dual objective. LR algorithms are simple and efficient, typically involving repeated applications of the underlying combinatorial algorithm, in conjunction with simple additive updates to the Lagrange multipliers. They have well-understood formal properties: the dual objective is an upper bound on the score for the optimal primal solution; there are close connections to linear programming relaxations; and crucially, they have the potential of producing an exact solution to the original inference problem, with a certificate of optimality. Experiments on several NLP problems have shown the effectiveness of LR algorithms for inference: LR methods are often considerably more efficient than existing exact methods, and have stronger formal guarantees than the approximate search methods that are often used in practice."}, {"heading": "Acknowledgments", "text": "We thank the anonymous reviewers for helpful comments. Tommi Jaakkola and David Sontag introduced us to dual decomposition and Lagrangian relaxation for inference in probabilistic models; this work would not have happened without them. We have benefited from many discussions with Yin-Wen Chang, Terry Koo, and Roi Reichart, who with Tommi and David were collaborators on our work on dual decomposition/Lagrangian relaxation for NLP. We also thank Shay Cohen, Yoav Goldberg, Mark Johnson, Andre Martins, Ryan McDonald, and Slav Petrov for feedback on earlier drafts of this paper. Columbia University gratefully acknowledges the support of the Defense Advanced Research Projects Agency (DARPA) Machine Reading Program under Air Force Research Laboratory (AFRL) prime contract no. FA8750-09-C-0181. Alexander Rush was supported by a National Science Foundation Graduate Research Fellowship."}, {"heading": "Appendix A. Proofs", "text": "In this section we derive various results for the combined parsing and tagging problem. Recall that in this case the Lagrangian is defined as\nL(u, y, z) = f(y) + g(z) + \u2211\ni\u2208{1...n},t\u2208T u(i, t)(y(i, t)\u2212 z(i, t))\nand that the dual objective is L(u) = maxy\u2208Y,z\u2208Z L(u, y, z). Here n is the number of words in the sentence, and T is a finite set of part-of-speech tags.\nWe first prove that L(u) is a convex function; we then derive the expression for subgradients of L(u); we then give a convergence theorem for the algorithm in Figure 2, which is a subgradient algorithm for minimization of L(u).\nFinally, we give a proof of theorem 6.\nA.1 Proof of Convexity of L(u)\nThe theorem is as follows:\nTheorem 9 L(u) is convex. That is, for any u(1) \u2208 Rd, u(2) \u2208 Rd, \u03bb \u2208 [0, 1],\nL(\u03bbu(1) + (1\u2212 \u03bb)u(2)) \u2264 \u03bbL(u(1)) + (1\u2212 \u03bb)L(u(2))\nProof: Define (y\u2217, z\u2217) = arg max\ny\u2208Y,z\u2208Z L(u\u2217, y, z)\nwhere u\u2217 = \u03bbu(1) + (1\u2212 \u03bb)u(2). It follows that\nL(u\u2217) = L(u\u2217, y\u2217, z\u2217)\nIn addition, note that\nL(u(1), y\u2217, z\u2217) \u2264 max y\u2208Y,z\u2208Z L(u(1), y, z) = L(u(1))\nand similarly L(u(2), y\u2217, z\u2217) \u2264 L(u(2))\nfrom which it follows that\n\u03bbL(u(1), y\u2217, z\u2217) + (1\u2212 \u03bb)L(u(2), y\u2217, z\u2217) \u2264 \u03bbL(u(1)) + (1\u2212 \u03bb)L(u(2))\nFinally, it is easy to show that\n\u03bbL(u(1), y\u2217, z\u2217) + (1\u2212 \u03bb)L(u(2), y\u2217, z\u2217) = L(u\u2217, y\u2217, z\u2217) = L(u\u2217)\nhence L(u\u2217) \u2264 \u03bbL(u(1)) + (1\u2212 \u03bb)L(u(2))\nwhich is the desired result.\nA.2 Subgradients of L(u)\nFor any value of u \u2208 Rd, as before define\n(y(u), z(u)) = argmax y\u2208Y,z\u2208Z L(u, y, z)\nor equivalently,\ny(u) = argmax y\u2208Y f(y) +\u2211 i,t u(i, t)y(i, t)  and\nz(u) = argmax z\u2208Z g(z)\u2212\u2211 i,t u(i, t)z(i, t)  Then if we define \u03b3(u) as the vector with components\n\u03b3(u)(i, t) = y(u)(i, t)\u2212 z(u)(i, t)\nfor i \u2208 {1 . . . n}, t \u2208 T , then \u03b3(u) is a subgradient of L(u) at u. This result is a special case of the following theorem:16\nTheorem 10 Define the function L : Rd \u2192 R as\nL(u) = max i\u2208{1...m}\n(ai \u00b7 u+ bi)\nwhere ai \u2208 Rd and bi \u2208 R for i \u2208 {1 . . .m}. Then for any value of u, if\nj = argmax i\u2208{1...m}\n(ai \u00b7 u+ bi)\nthen aj is a subgradient of L(u) at u.\nProof: For aj to be a subgradient at the point u, we need to show that for all v \u2208 Rd,\nL(v) \u2265 L(u) + aj \u00b7 (v \u2212 u)\nEquivalently, we need to show that for all v \u2208 Rd,\nmax i\u2208{1...m} (ai \u00b7 v + bi) \u2265 max i\u2208{1...m} (ai \u00b7 u+ bi) + aj \u00b7 (v \u2212 u) (39)\nTo show this, first note that\naj \u00b7 u+ bj = max i\u2208{1...m} (ai \u00b7 u+ bi)\nhence max\ni\u2208{1...m} (ai \u00b7 u+ bi) + aj \u00b7 (v \u2212 u) = bj + aj \u00b7 v \u2264 max i\u2208{1...m} (ai \u00b7 v + bi)\nthus proving the theorem.\nA.3 Convergence Proof for the Subgradient Method\nConsider a convex function L : Rd \u2192 R, which has a minimizer u\u2217 (i.e., u\u2217 = argmin u\u2208Rd L(u)). The subgradient method is an iterative method which initializes u to some value u(0) \u2208 Rd, then sets u(k+1) = u(k) \u2212 \u03b4kgk for k = 0, 1, 2, . . ., where \u03b4k > 0 is the stepsize at the k\u2019th iteration, and gk is a subgradient at u(k): that is, for all v \u2208 Rd,\nL(v) \u2265 L(u(k)) + gk \u00b7 (v \u2212 u(k)) The following theorem will then be very useful in proving convergence of the method (the\ntheorem and proof is taken from Boyd & Mutapcic, 2007):\n16. To be specific, our definition of L(u) can be written in the form maxi\u2208{1...m} (ai \u00b7 u+ bi) as follows. Define the integerm to be |Y|\u00d7 |Z|. Define (y(i), z(i)) for i \u2208 {1 . . .m} to be a list of all possible pairs (y, z) such that y \u2208 Y and z \u2208 Z . Define bi = f(y(i)) + g(z(i)), and ai to be the vector with components ai(l, t) = y(i)(l, t)\u2212 z(i)(l, t) for l \u2208 {1 . . . n}, t \u2208 T . Then it can be verifed that L(u) = maxi\u2208{1...m} (ai \u00b7 u+ bi).\nTheorem 11 Assume that for all k, ||gk||2 \u2264 G2 where G is some constant. Then for any k \u2265 0,\nmin i\u2208{0...k}\nL(u(i)) \u2264 L(u\u2217) + ||u (0) \u2212 u\u2217||2 +G2\u2211ki=0 \u03b42i\n2 \u2211k i=0 \u03b4i\nProof: First, given the updates u(k+1) = u(k) \u2212 \u03b4kgk, we have for all k \u2265 0, ||u(k+1) \u2212 u\u2217||2 = ||u(k) \u2212 \u03b4kgk \u2212 u\u2217||2\n= ||u(k) \u2212 u\u2217||2 \u2212 2\u03b4kgk \u00b7 (u(k) \u2212 u\u2217) + \u03b42k||gk||2\nBy the subgradient property,\nL(u\u2217) \u2265 L(u(k)) + gk \u00b7 (u\u2217 \u2212 u(k)) hence \u2212gk \u00b7 (u(k) \u2212 u\u2217) \u2264 L(u\u2217)\u2212 L(u(k)) Using this inequality, together with ||gk||2 \u2264 G2, gives\n||u(k+1) \u2212 u\u2217||2 \u2264 ||u(k) \u2212 u\u2217||2 + 2\u03b4k ( L(u\u2217)\u2212 L(u(k)) ) + \u03b42kG 2\nTaking a sum over both sides of i = 0 . . . k gives k\u2211 i=0 ||u(i+1) \u2212 u\u2217||2 \u2264 k\u2211 i=0 ||u(i) \u2212 u\u2217||2 + 2 k\u2211 i=0 \u03b4i ( L(u\u2217)\u2212 L(u(i)) ) + k\u2211 i=0 \u03b42iG 2\nand hence\n||u(k+1) \u2212 u\u2217||2 \u2264 ||u(0) \u2212 u\u2217||2 + 2 k\u2211 i=0 \u03b4i ( L(u\u2217)\u2212 L(u(i)) ) + k\u2211 i=0 \u03b42iG 2\nFinally, using ||u(k+1) \u2212 u\u2217||2 \u2265 0 and k\u2211 i=0 \u03b4i ( L(u\u2217)\u2212 L(u(i)) ) \u2264 ( k\u2211 i=0 \u03b4i )( L(u\u2217)\u2212 min i\u2208{0...k} L(u(i)) ) gives\n0 \u2264 ||u(0) \u2212 u\u2217||2 + 2 (\nk\u2211 i=0 \u03b4i\n)( L(u\u2217)\u2212 min\ni\u2208{0...k} L(u(i))\n) +\nk\u2211 i=0 \u03b42iG 2\nRearranging terms gives the result in the theorem. This theorem has a number of consequences. As one example, for a constant step-size, \u03b4k = h for some h > 0,\nlim k\u2192\u221e\n( ||u(0) \u2212 u\u2217||2 +G2\u2211ki=1 \u03b42i\n2 \u2211k i=1 \u03b4i\n) = Gh\n2\nhence in the limit the value for min\ni\u2208{1...k} L(u(i))\nis within Gh/2 of the optimal solution. A slightly more involved argument shows that under the assumptions that \u03b4k > 0, limk\u2192\u221e \u03b4k = 0, and \u2211\u221e k=0 \u03b4k =\u221e,\nlim k\u2192\u221e\n( ||u(0) \u2212 u\u2217||2 +G2\u2211ki=1 \u03b42i\n2 \u2211k i=1 \u03b4i\n) = 0\nSee Boyd and Mutapcic for the full derivation.\nA.4 Proof of Theorem 6\nRecall that our goal is to prove that\nmax y\u2208Y f(y) = max \u03b1\u2208\u2206y \u2211 y\u2208Y \u03b1yf(y)\nWe will show this by proving: (1) maxy\u2208Y f(y) \u2264 max\u03b1\u2208\u2206y \u2211 y\u2208Y \u03b1yf(y), and (2) maxy\u2208Y f(y) \u2265\nmax\u03b1\u2208\u2206y \u2211 y\u2208Y \u03b1yf(y).\nFirst, consider case (1). Define y\u2217 to be a member of Y such that\nf(y\u2217) = max y\u2208Y f(y)\nNext, define \u03b1y\u2217 = 1, and \u03b1y = 0 for y 6= y\u2217. Then we have\u2211 y\u2208Y \u03b1yf(y) = f(y \u2217)\nHence we have found a setting for the \u03b1 variables such that\u2211 y\u2208Y \u03b1yf(y) = max y\u2208Y f(y)\nfrom which it follows that max \u03b1\u2208\u2206y \u2211 y\u2208Y \u03b1yf(y) \u2265 max y\u2208Y f(y)\nNext, consider case (2). Define \u03b1\u2217 to be a setting of the \u03b1 variables such that\u2211 y \u03b1\u2217yf(y) = max \u03b1\u2208\u2206y \u2211 y\u2208Y \u03b1yf(y)\nNext, define y\u2217 to be a member of Y such that\nf(y\u2217) = max y:\u03b1\u2217y>0 f(y)\nIt is easily verified that f(y\u2217) \u2265 \u2211 y \u03b1\u2217yf(y)\nHence we have found a y\u2217 \u2208 Y such that\nf(y\u2217) \u2265 max \u03b1\u2208\u2206y \u2211 y \u03b1\u2217yf(y)\nfrom which it follows that max y\u2208Y f(y) \u2265 max \u03b1\u2208\u2206y \u2211 y \u03b1\u2217yf(y)"}], "references": [{"title": "A comparison of loopy belief propagation and dual decomposition for integrated ccg supertagging and parsing", "author": ["M. Auli", "A. Lopez"], "venue": "In Proceedings of the 49th Annual Meeting of the Association for Computational Linguistics: Human Language Technologies,", "citeRegEx": "Auli and Lopez,? \\Q2011\\E", "shortCiteRegEx": "Auli and Lopez", "year": 2011}, {"title": "On formal properties of simple phrase structure grammars", "author": ["Y. Bar-Hillel", "M. Perles", "E. Shamir"], "venue": "In Language and Information: Selected Essays on their Theory and Application,", "citeRegEx": "Bar.Hillel et al\\.,? \\Q1964\\E", "shortCiteRegEx": "Bar.Hillel et al\\.", "year": 1964}, {"title": "Distributed optimization and statistical learning via the alternating direction method of multipliers", "author": ["S. Boyd", "N. Parikh", "E. Chu", "B. Peleato", "J. Eckstein"], "venue": null, "citeRegEx": "Boyd et al\\.,? \\Q2011\\E", "shortCiteRegEx": "Boyd et al\\.", "year": 2011}, {"title": "Subgradient Methods. Course Notes for EE364b, Stanford University, Winter 2006-07", "author": ["S. Boyd", "A. Mutapcic"], "venue": null, "citeRegEx": "Boyd and Mutapcic,? \\Q2007\\E", "shortCiteRegEx": "Boyd and Mutapcic", "year": 2007}, {"title": "Exact Decoding of Phrase-based Translation Models through Lagrangian Relaxation", "author": ["Y. Chang", "M. Collins"], "venue": "In To appear proc. of EMNLP", "citeRegEx": "Chang and Collins,? \\Q2011\\E", "shortCiteRegEx": "Chang and Collins", "year": 2011}, {"title": "Three Generative, Lexicalised Models for Statistical Parsing", "author": ["M. Collins"], "venue": "In Proc. ACL,", "citeRegEx": "Collins,? \\Q1997\\E", "shortCiteRegEx": "Collins", "year": 1997}, {"title": "Decomposition principle for linear programs", "author": ["G. Dantzig", "P. Wolfe"], "venue": "In Operations research,", "citeRegEx": "Dantzig and Wolfe,? \\Q1960\\E", "shortCiteRegEx": "Dantzig and Wolfe", "year": 1960}, {"title": "An exact dual decomposition algorithm for shallow semantic parsing with constraints", "author": ["D. Das", "A. Martins", "N. Smith"], "venue": "Proceedings of* SEM.[ii,", "citeRegEx": "Das et al\\.,? \\Q2012\\E", "shortCiteRegEx": "Das et al\\.", "year": 2012}, {"title": "Model-Based Aligner Combination Using Dual Decomposition", "author": ["J. DeNero", "K. Macherey"], "venue": "In Proc. ACL", "citeRegEx": "DeNero and Macherey,? \\Q2011\\E", "shortCiteRegEx": "DeNero and Macherey", "year": 2011}, {"title": "Using combinatorial optimization within maxproduct belief propagation", "author": ["J. Duchi", "D. Tarlow", "G. Elidan", "D. Koller"], "venue": "In Advances in Neural Information Processing Systems (NIPS)", "citeRegEx": "Duchi et al\\.,? \\Q2007\\E", "shortCiteRegEx": "Duchi et al\\.", "year": 2007}, {"title": "Generalized lagrange multiplier method for solving problems of optimum allocation of resources", "author": ["III H. Everett"], "venue": "Operations Research,", "citeRegEx": "Everett,? \\Q1963\\E", "shortCiteRegEx": "Everett", "year": 1963}, {"title": "Efficient belief propagation for early vision", "author": ["P. Felzenszwalb", "D. Huttenlocher"], "venue": "International journal of computer vision,", "citeRegEx": "Felzenszwalb and Huttenlocher,? \\Q2006\\E", "shortCiteRegEx": "Felzenszwalb and Huttenlocher", "year": 2006}, {"title": "The lagrangian relaxation method for solving integer programming problems", "author": ["M.L. Fisher"], "venue": "Management Science,", "citeRegEx": "Fisher,? \\Q1981\\E", "shortCiteRegEx": "Fisher", "year": 1981}, {"title": "Fast decoding and optimal decoding for machine translation", "author": ["U. Germann", "M. Jahr", "K. Knight", "D. Marcu", "K. Yamada"], "venue": "In Proceedings of the 39th Annual Meeting on Association for Computational Linguistics,", "citeRegEx": "Germann et al\\.,? \\Q2001\\E", "shortCiteRegEx": "Germann et al\\.", "year": 2001}, {"title": "Fixing max-product: Convergent message passing algorithms for map lp-relaxations", "author": ["A. Globerson", "T. Jaakkola"], "venue": null, "citeRegEx": "Globerson and Jaakkola,? \\Q2007\\E", "shortCiteRegEx": "Globerson and Jaakkola", "year": 2007}, {"title": "Coordination structure analysis using dual decomposition", "author": ["A. Hanamoto", "T. Matsuzaki", "J. Tsujii"], "venue": "In Proceedings of the 13th Conference of the European Chapter of the Association for Computational Linguistics,", "citeRegEx": "Hanamoto et al\\.,? \\Q2012\\E", "shortCiteRegEx": "Hanamoto et al\\.", "year": 2012}, {"title": "The traveling-salesman problem and minimum spanning trees: Part ii", "author": ["M. Held", "R.M. Karp"], "venue": "Mathematical Programming,", "citeRegEx": "Held and Karp,? \\Q1971\\E", "shortCiteRegEx": "Held and Karp", "year": 1971}, {"title": "Lagrangian relaxation for map estimation in graphical models", "author": ["J. Johnson", "D. Malioutov", "A. Willsky"], "venue": "In 45th Annual Allerton Conference on Communication, Control and Computing", "citeRegEx": "Johnson et al\\.,? \\Q2007\\E", "shortCiteRegEx": "Johnson et al\\.", "year": 2007}, {"title": "Fast and smooth: Accelerated dual decomposition for MAP inference", "author": ["V. Jojic", "S. Gould", "D. Koller"], "venue": "In Proceedings of International Conference on Machine Learning (ICML)", "citeRegEx": "Jojic et al\\.,? \\Q2010\\E", "shortCiteRegEx": "Jojic et al\\.", "year": 2010}, {"title": "Fast exact inference with a factored model for natural language parsing", "author": ["D. Klein", "C. Manning"], "venue": "Advances in neural information processing systems,", "citeRegEx": "Klein and Manning,? \\Q2002\\E", "shortCiteRegEx": "Klein and Manning", "year": 2002}, {"title": "Statistical phrase-based translation", "author": ["P. Koehn", "F.J. Och", "D. Marcu"], "venue": "In Proceedings of the 2003 Conference of the North American Chapter of the Association for Computational Linguistic s on Human Language Technology,", "citeRegEx": "Koehn et al\\.,? \\Q2003\\E", "shortCiteRegEx": "Koehn et al\\.", "year": 2003}, {"title": "Convergent tree-reweighted message passing for energy minimization", "author": ["V. Kolmogorov"], "venue": "Pattern Analysis and Machine Intelligence, IEEE Transactions on,", "citeRegEx": "Kolmogorov,? \\Q2006\\E", "shortCiteRegEx": "Kolmogorov", "year": 2006}, {"title": "MRF Optimization via Dual Decomposition: Message-Passing Revisited", "author": ["N. Komodakis", "N. Paragios", "G. Tziritas"], "venue": "In Proc. ICCV", "citeRegEx": "Komodakis et al\\.,? \\Q2007\\E", "shortCiteRegEx": "Komodakis et al\\.", "year": 2007}, {"title": "Mrf energy minimization and beyond via dual decomposition", "author": ["N. Komodakis", "N. Paragios", "G. Tziritas"], "venue": "Pattern Analysis and Machine Intelligence, IEEE Transactions on,", "citeRegEx": "Komodakis et al\\.,? \\Q2011\\E", "shortCiteRegEx": "Komodakis et al\\.", "year": 2011}, {"title": "Simple semi-supervised dependency parsing", "author": ["T. Koo", "X. Carreras", "M. Collins"], "venue": "In Proc. ACL/HLT", "citeRegEx": "Koo et al\\.,? \\Q2008\\E", "shortCiteRegEx": "Koo et al\\.", "year": 2008}, {"title": "Dual decomposition for parsing with non-projective head", "author": ["T. Koo", "A.M. Rush", "M. Collins", "T. Jaakkola", "D. Sontag"], "venue": null, "citeRegEx": "Koo et al\\.,? \\Q2010\\E", "shortCiteRegEx": "Koo et al\\.", "year": 2010}, {"title": "Combinatorial Optimization: Theory and Algorithms", "author": ["B. Korte", "J. Vygen"], "venue": null, "citeRegEx": "Korte and Vygen,? \\Q2008\\E", "shortCiteRegEx": "Korte and Vygen", "year": 2008}, {"title": "Word alignment via quadratic assignment", "author": ["S. Lacoste-Julien", "B. Taskar", "D. Klein", "M. Jordan"], "venue": "In Proceedings of the main conference on Human Language Technology Conference of the North American Chapter of the Association of Computational Linguistics,", "citeRegEx": "Lacoste.Julien et al\\.,? \\Q2006\\E", "shortCiteRegEx": "Lacoste.Julien et al\\.", "year": 2006}, {"title": "Conditional Random Fields: Probabilistic Models for Segmenting and Labeling Sequence Data", "author": ["J. Lafferty", "A. McCallum", "F. Pereira"], "venue": "In Proc. ICML,", "citeRegEx": "Lafferty et al\\.,? \\Q2001\\E", "shortCiteRegEx": "Lafferty et al\\.", "year": 2001}, {"title": "Lagrangian Relaxation", "author": ["C. Lemar\u00e9chal"], "venue": null, "citeRegEx": "Lemar\u00e9chal,? \\Q2001\\E", "shortCiteRegEx": "Lemar\u00e9chal", "year": 2001}, {"title": "Polyhedral characterization of discrete dynamic programming", "author": ["R. Martin", "R. Rardin", "B. Campbell"], "venue": "Operations research,", "citeRegEx": "Martin et al\\.,? \\Q1990\\E", "shortCiteRegEx": "Martin et al\\.", "year": 1990}, {"title": "The Geometry of Constrained Structured Prediction: Applications to Inference and Learning of Natural Language Syntax", "author": ["A. Martins"], "venue": "Ph.D. thesis", "citeRegEx": "Martins,? \\Q2012\\E", "shortCiteRegEx": "Martins", "year": 2012}, {"title": "An augmented lagrangian approach to constrained map inference", "author": ["A. Martins", "M. Figueiredo", "P. Aguiar", "N. Smith", "E. Xing"], "venue": "In International Conference on Machine Learning", "citeRegEx": "Martins et al\\.,? \\Q2011\\E", "shortCiteRegEx": "Martins et al\\.", "year": 2011}, {"title": "Concise Integer Linear Programming Formulations for Dependency Parsing", "author": ["A. Martins", "N. Smith", "E. Xing"], "venue": "In Proc. ACL,", "citeRegEx": "Martins et al\\.,? \\Q2009\\E", "shortCiteRegEx": "Martins et al\\.", "year": 2009}, {"title": "Dual decomposition with many overlapping components", "author": ["A. Martins", "N. Smith", "M. Figueiredo", "P. Aguiar"], "venue": "In Proceedings of the 2011 Conference on Empirical Methods in Natural Language Processing,", "citeRegEx": "Martins et al\\.,? \\Q2011\\E", "shortCiteRegEx": "Martins et al\\.", "year": 2011}, {"title": "Discriminative Training and Spanning Tree Algorithms for Dependency Parsing", "author": ["R. McDonald"], "venue": "Ph.D. thesis,", "citeRegEx": "McDonald,? \\Q2006\\E", "shortCiteRegEx": "McDonald", "year": 2006}, {"title": "An alternating direction method for dual map lp relaxation", "author": ["O. Meshi", "A. Globerson"], "venue": "Machine Learning and Knowledge Discovery in Databases,", "citeRegEx": "Meshi and Globerson,? \\Q2011\\E", "shortCiteRegEx": "Meshi and Globerson", "year": 2011}, {"title": "Approximate primal solutions and rate analysis for dual subgradient methods", "author": ["A. Nedi\u0107", "A. Ozdaglar"], "venue": "SIAM Journal on Optimization,", "citeRegEx": "Nedi\u0107 and Ozdaglar,? \\Q2009\\E", "shortCiteRegEx": "Nedi\u0107 and Ozdaglar", "year": 2009}, {"title": "Smooth minimization of non-smooth functions", "author": ["Y. Nesterov"], "venue": "Mathematical Programming,", "citeRegEx": "Nesterov,? \\Q2005\\E", "shortCiteRegEx": "Nesterov", "year": 2005}, {"title": "Implicitly intersecting weighted automata using dual decomposition", "author": ["M.J. Paul", "J. Eisner"], "venue": "In Proc. NAACL", "citeRegEx": "Paul and Eisner,? \\Q2012\\E", "shortCiteRegEx": "Paul and Eisner", "year": 2012}, {"title": "Probabilistic Reasoning in Intelligent Systems: Networks of Plausible Inference (2nd edition)", "author": ["J. Pearl"], "venue": null, "citeRegEx": "Pearl,? \\Q1988\\E", "shortCiteRegEx": "Pearl", "year": 1988}, {"title": "Incremental integer linear programming for non-projective dependency parsing", "author": ["S. Riedel", "J. Clarke"], "venue": "In Proceedings of the 2006 Conference on Empirical Methods in Natural Language Processing,", "citeRegEx": "Riedel and Clarke,? \\Q2006\\E", "shortCiteRegEx": "Riedel and Clarke", "year": 2006}, {"title": "Fast and robust joint models for biomedical event extraction", "author": ["S. Riedel", "A. McCallum"], "venue": "In Proceedings of the 2011 Conference on Empirical Methods in Natural Language Processing,", "citeRegEx": "Riedel and McCallum,? \\Q2011\\E", "shortCiteRegEx": "Riedel and McCallum", "year": 2011}, {"title": "Integer linear programming inference for conditional random fields", "author": ["D. Roth", "W. Yih"], "venue": "In Proceedings of the 22nd international conference on Machine learning,", "citeRegEx": "Roth and Yih,? \\Q2005\\E", "shortCiteRegEx": "Roth and Yih", "year": 2005}, {"title": "Improved parsing and pos tagging using inter-sentence consistency constraints", "author": ["A. Rush", "R. Reichart", "M. Collins", "A. Globerson"], "venue": "In Proceedings of the 2012 Joint Conference on Empirical Methods in Natural Language Processing and Computational Natural Language Learning,", "citeRegEx": "Rush et al\\.,? \\Q2012\\E", "shortCiteRegEx": "Rush et al\\.", "year": 2012}, {"title": "Exact Decoding of Syntactic Translation Models through Lagrangian Relaxation", "author": ["A. Rush", "M. Collins"], "venue": "In Proc. ACL", "citeRegEx": "Rush and Collins,? \\Q2011\\E", "shortCiteRegEx": "Rush and Collins", "year": 2011}, {"title": "On Dual Decomposition and Linear Programming Relaxations for Natural Language Processing", "author": ["A. Rush", "D. Sontag", "M. Collins", "T. Jaakkola"], "venue": "In Proc. EMNLP", "citeRegEx": "Rush et al\\.,? \\Q2010\\E", "shortCiteRegEx": "Rush et al\\.", "year": 2010}, {"title": "Minimization Methods for Non-differentiable Functions", "author": ["N.Z. Shor"], "venue": null, "citeRegEx": "Shor,? \\Q1985\\E", "shortCiteRegEx": "Shor", "year": 1985}, {"title": "Dependency parsing by belief propagation", "author": ["D. Smith", "J. Eisner"], "venue": "In Proc. EMNLP,", "citeRegEx": "Smith and Eisner,? \\Q2008\\E", "shortCiteRegEx": "Smith and Eisner", "year": 2008}, {"title": "Introduction to dual decomposition for inference", "author": ["D. Sontag", "A. Globerson", "T. Jaakkola"], "venue": null, "citeRegEx": "Sontag et al\\.,? \\Q2010\\E", "shortCiteRegEx": "Sontag et al\\.", "year": 2010}, {"title": "Tightening LP relaxations for MAP using message passing", "author": ["D. Sontag", "T. Meltzer", "A. Globerson", "T. Jaakkola", "Y. Weiss"], "venue": "In Proc. UAI", "citeRegEx": "Sontag et al\\.,? \\Q2008\\E", "shortCiteRegEx": "Sontag et al\\.", "year": 2008}, {"title": "Feature-rich part-of-speech tagging with a cyclic dependency network", "author": ["K. Toutanova", "D. Klein", "C.D. Manning", "Y. Singer"], "venue": "In HLT-NAACL", "citeRegEx": "Toutanova et al\\.,? \\Q2003\\E", "shortCiteRegEx": "Toutanova et al\\.", "year": 2003}, {"title": "MAP estimation via agreement on trees: message-passing and linear programming", "author": ["M. Wainwright", "T. Jaakkola", "A. Willsky"], "venue": "In IEEE Transactions on Information Theory,", "citeRegEx": "Wainwright et al\\.,? \\Q2005\\E", "shortCiteRegEx": "Wainwright et al\\.", "year": 2005}, {"title": "Linear Programming Relaxations and Belief Propagation\u2013An Empirical Study", "author": ["C. Yanover", "T. Meltzer", "Y. Weiss"], "venue": "In The Journal of Machine Learning Research,", "citeRegEx": "Yanover et al\\.,? \\Q2006\\E", "shortCiteRegEx": "Yanover et al\\.", "year": 2006}], "referenceMentions": [{"referenceID": 46, "context": "More recently, decoding algorithms have been derived for several models in statistical NLP, including models that combine a weighted context-free grammar (WCFG) with a finite-state tagger (Rush, Sontag, Collins, & Jaakkola, 2010); models that combine a lexicalized WCFG with a discriminative dependency parsing model (Rush et al., 2010); head-automata models for non-projective dependency parsing (Koo, Rush, Collins, Jaakkola, & Sontag, 2010); alignment models for statistical machine translation (DeNero & Macherey, 2011); models for event extraction (Riedel & McCallum, 2011); models for combined CCG parsing and supertagging (Auli & Lopez, 2011); phrase-based models for statistical machine translation (Chang & Collins, 2011); syntaxbased models for statistical machine translation (Rush & Collins, 2011); models for semantic parsing (Das, Martins, & Smith, 2012); models for parsing and tagging that make use of document-level constraints (Rush, Reichart, Collins, & Globerson, 2012); models for the coordination problem in natural language parsing (Hanamoto, Matsuzaki, & Tsujii, 2012); and models based on the intersection of weighted automata (Paul & Eisner, 2012).", "startOffset": 317, "endOffset": 336}, {"referenceID": 15, "context": "Lagrangian relaxation has a long history in the combinatorial optimization literature, going back to the seminal work of Held and Karp (1971), who derive a relaxation algorithm for the traveling salesman problem.", "startOffset": 121, "endOffset": 142}, {"referenceID": 14, "context": "1 Combinatorial Optimization Lagrangian relaxation (LR) is a widely used method in combinatorial optimization, going back to the seminal work of Held and Karp (1971) on the traveling salesman problem.", "startOffset": 145, "endOffset": 166}, {"referenceID": 14, "context": "1 Combinatorial Optimization Lagrangian relaxation (LR) is a widely used method in combinatorial optimization, going back to the seminal work of Held and Karp (1971) on the traveling salesman problem. See the work of Lemar\u00e9chal (2001) and Fisher (1981) for surveys of LR methods, and the textbook of Korte and Vygen (2008) for background on combinatorial optimization.", "startOffset": 145, "endOffset": 235}, {"referenceID": 11, "context": "See the work of Lemar\u00e9chal (2001) and Fisher (1981) for surveys of LR methods, and the textbook of Korte and Vygen (2008) for background on combinatorial optimization.", "startOffset": 38, "endOffset": 52}, {"referenceID": 11, "context": "See the work of Lemar\u00e9chal (2001) and Fisher (1981) for surveys of LR methods, and the textbook of Korte and Vygen (2008) for background on combinatorial optimization.", "startOffset": 38, "endOffset": 122}, {"referenceID": 40, "context": "For tree-structured MRFs, max-product belief propagation (max-product BP) (Pearl, 1988) gives exact solutions.", "startOffset": 74, "endOffset": 87}, {"referenceID": 40, "context": "For tree-structured MRFs, max-product belief propagation (max-product BP) (Pearl, 1988) gives exact solutions. (Max-product BP is a form of dynamic programming, which is closely related to the Viterbi algorithm.) For general MRFs where the underlying graph may contain cycles, the MAP problem is NP-hard: this has led researchers to consider a number of approximate inference algorithms. Early work considered loopy variants of max-product BP (see for example Felzenszwalb & Huttenlocher, 2006, for the application of loopy max-product BP to problems in computer vision); however, these methods are heuristic, lacking formal guarantees. More recent work has considered methods based on linear programming (LP) relaxations of the MAP problem. See the work of Yanover, Meltzer, and Weiss (2006), or section 1.", "startOffset": 75, "endOffset": 793}, {"referenceID": 40, "context": "For tree-structured MRFs, max-product belief propagation (max-product BP) (Pearl, 1988) gives exact solutions. (Max-product BP is a form of dynamic programming, which is closely related to the Viterbi algorithm.) For general MRFs where the underlying graph may contain cycles, the MAP problem is NP-hard: this has led researchers to consider a number of approximate inference algorithms. Early work considered loopy variants of max-product BP (see for example Felzenszwalb & Huttenlocher, 2006, for the application of loopy max-product BP to problems in computer vision); however, these methods are heuristic, lacking formal guarantees. More recent work has considered methods based on linear programming (LP) relaxations of the MAP problem. See the work of Yanover, Meltzer, and Weiss (2006), or section 1.6 of the work of Sontag, Globerson, and Jaakkola (2010), for a description.", "startOffset": 75, "endOffset": 863}, {"referenceID": 38, "context": "Roth and Yih (2005) formulate a constrained sequence labeling problem as an ILP and decode using a general-purpose solver.", "startOffset": 0, "endOffset": 20}, {"referenceID": 38, "context": "Roth and Yih (2005) formulate a constrained sequence labeling problem as an ILP and decode using a general-purpose solver. Lacoste-Julien, Taskar, Klein, and Jordan (2006) describe a quadratic assignment problem for bilingual word alignment and then decode using an ILP solver.", "startOffset": 0, "endOffset": 172}, {"referenceID": 37, "context": "Both the work of Riedel and Clarke (2006) and Martins, Smith, and Xing (2009) formulates higher-order non-projective dependency parsing as an ILP.", "startOffset": 17, "endOffset": 42}, {"referenceID": 31, "context": "Both the work of Riedel and Clarke (2006) and Martins, Smith, and Xing (2009) formulates higher-order non-projective dependency parsing as an ILP.", "startOffset": 46, "endOffset": 78}, {"referenceID": 44, "context": "See the work of Rush et al. (2010) for a detailed treatment of both of these examples.", "startOffset": 16, "endOffset": 35}, {"referenceID": 12, "context": "In addition, Lagrangian relaxation appears to be a more standard term in the combinatorial optimization literature: for example the textbook of Korte and Vygen (2008) has a description of Lagrangian relaxation but no mention of dual decomposition; there are several tutorials on Lagrangian relaxation in the combinatorial optimization literature (e.g., see Lemar\u00e9chal, 2001; Fisher, 1981), but we have found it more difficult to find direct treatments of dual decompositon.", "startOffset": 346, "endOffset": 388}, {"referenceID": 15, "context": "However, in our view dual decomposition is more naturally viewed as a special case of Lagrangian relaxation, in particular because the methods described in this tutorial go back to the work of Held and Karp (1971) (see section 6.", "startOffset": 193, "endOffset": 214}, {"referenceID": 15, "context": "However, in our view dual decomposition is more naturally viewed as a special case of Lagrangian relaxation, in particular because the methods described in this tutorial go back to the work of Held and Karp (1971) (see section 6.3), which makes use of a single combinatorial algorithm. In addition, Lagrangian relaxation appears to be a more standard term in the combinatorial optimization literature: for example the textbook of Korte and Vygen (2008) has a description of Lagrangian relaxation but no mention of dual decomposition; there are several tutorials on Lagrangian relaxation in the combinatorial optimization literature (e.", "startOffset": 193, "endOffset": 453}, {"referenceID": 22, "context": "The generalization to more than two components is relatively straightforward; for example see the work of Komodakis et al. (2007, 2011), see also the work of Martins, Smith, Figueiredo, and Aguiar (2011).", "startOffset": 106, "endOffset": 204}, {"referenceID": 1, "context": "8 is to construct a new context-free grammar that introduces sensitivity to surface bigrams (Bar-Hillel et al., 1964).", "startOffset": 92, "endOffset": 117}, {"referenceID": 1, "context": "8 is to construct a new context-free grammar that introduces sensitivity to surface bigrams (Bar-Hillel et al., 1964). Roughly speaking, in this approach (assuming a first-order tagging model) rules such as VP\u2192 V NP are replaced with rules such as VPN,N \u2192 VN,V NPV,N (10) where each non-terminal (e.g., NP) is replaced with a non-terminal that tracks the preceding and last POS tag relative to that non-terminal. For example, NPV,N represents a NP that dominates a sub-tree whose preceding POS tag was V, and whose last POS tag is N. The weights on the new rules are just context-free weights from f(y). Furthermore, rules such as V\u2192 flies are replaced with rules such as VN,V \u2192 flies The weights on these rules are the context-free weights from f(y) plus the bigram tag weights from g(z), in this example for the bigram N V. A dynamic programming parsing algorithm\u2014for example the CKY algorithm\u2014can then be used to find the highest scoring structure under the new grammar. This approach is guaranteed to give an exact solution to the problem in Eq. 8; however it is often very inefficient. We have greatly increased the size of the grammar by introducing the refined non-terminals, and this leads to significantly slower parsing performance. As one example, consider the case where the underlying grammar is a CFG in Chomsky-normal form, with G non-terminals, and where we use a 2nd order (trigram) tagging model, with T possible part-of-speech tags. Define n to be the length of the input sentence. Parsing with the grammar alone would take O(G3n3) time, for example using the CKY algorithm. In contrast, the construction of Bar-Hillel et al. (1964) 6.", "startOffset": 93, "endOffset": 1652}, {"referenceID": 1, "context": "If the number of iterations k is relatively small, the algorithm can be much more efficient than using the construction of Bar-Hillel et al. (1964). As discussed before, assuming a context-free grammar in Chomsky normal form, and a trigram tagger with T tags, the CKY parsing algorithm takes O(G3n3) time, and the Viterbi algorithm for tagging takes O(T 3n) time.", "startOffset": 123, "endOffset": 148}, {"referenceID": 44, "context": "Each parse tree y \u2208 Rd is represented as a vector such that f(y) = y \u00b7\u03b8(1) for some \u03b8(1) \u2208 Rd: there are a number of ways of representing parse trees as vectors, see the work of Rush et al. (2010) for one example.", "startOffset": 178, "endOffset": 197}, {"referenceID": 44, "context": "Figure 3: Convergence results from the work of Rush et al. (2010) for integration of a probabilistic parser and a POS tagger, using dual decomposition.", "startOffset": 47, "endOffset": 66}, {"referenceID": 5, "context": "(2010) describe experiments using this algorithm to integrate the probabilistic parser of Collins (1997) with the POS tagger of Toutanova, Klein, Manning, and Singer (2003).", "startOffset": 90, "endOffset": 105}, {"referenceID": 5, "context": "(2010) describe experiments using this algorithm to integrate the probabilistic parser of Collins (1997) with the POS tagger of Toutanova, Klein, Manning, and Singer (2003). (In these experiments the stepsize \u03b4k is not held constant, but is instead set using the strategy described in section 7.", "startOffset": 90, "endOffset": 173}, {"referenceID": 47, "context": "Proof: See the work of Shor (1985). See also Appendix A.", "startOffset": 23, "endOffset": 35}, {"referenceID": 39, "context": "Our first example, also from the work of Rush et al. (2010), is a dual decomposition algorithm that combines two parsing models.", "startOffset": 41, "endOffset": 60}, {"referenceID": 14, "context": "Finally, we describe the algorithm of Held and Karp (1971) for the traveling salesman problem, and the algorithm of Chang and Collins (2011) for decoding of phrase-based translation models.", "startOffset": 38, "endOffset": 59}, {"referenceID": 4, "context": "Finally, we describe the algorithm of Held and Karp (1971) for the traveling salesman problem, and the algorithm of Chang and Collins (2011) for decoding of phrase-based translation models.", "startOffset": 116, "endOffset": 141}, {"referenceID": 43, "context": "1 Combined Constituency and Dependency Parsing Rush et al. (2010) describe an algorithm for finding the highest scoring lexicalized context-free parse tree for an input sentence, under a combination of two models: a lexicalized probabilistic context-free grammar, and a discriminative dependency parsing model.", "startOffset": 47, "endOffset": 66}, {"referenceID": 5, "context": "We take Y to be the set of all lexicalized trees for the input sentence, and f(y) to be the score of the tree y under a lexicalized parsing model\u2014specifically, f(y) is the log-probability of y under the model of Collins (1997). Under this model, each lexicalized rule in y receives a score that is a log probability, and the log probability of y is a sum of the log probabilities for the rules that it contains.", "startOffset": 212, "endOffset": 227}, {"referenceID": 44, "context": "Figure 5: Convergence results from the work of Rush et al. (2010) for integration of a lexicalized probabilistic context-free grammar, and a discriminative dependency parsing model.", "startOffset": 47, "endOffset": 66}, {"referenceID": 5, "context": "We use the discriminative dependency parsing model of Koo, Carreras, and Collins (2008) (see also McDonald, 2006).", "startOffset": 73, "endOffset": 88}, {"referenceID": 4, "context": "The motivation for this problem is that it will allow us to inject information from the dependency parsing model g(z) into the lexicalized parsing model of Collins (1997); Rush et al.", "startOffset": 156, "endOffset": 171}, {"referenceID": 4, "context": "The motivation for this problem is that it will allow us to inject information from the dependency parsing model g(z) into the lexicalized parsing model of Collins (1997); Rush et al. (2010) show that this gives significant improvements in parsing accuracy.", "startOffset": 156, "endOffset": 191}, {"referenceID": 1, "context": "The problem can be again solved exactly using a dynamic programming approach, where a dynamic program is created that is an intersection of the two models (there is a clear analogy to the Bar-Hillel et al. (1964) method for construction of a dynamic program for the intersection of a PCFG and an HMM).", "startOffset": 188, "endOffset": 213}, {"referenceID": 40, "context": "Rush et al. (2010) describe experiments with this algorithm.", "startOffset": 0, "endOffset": 19}, {"referenceID": 5, "context": "The method gives significant gains in parsing accuracy over the model of Collins (1997), and significant gains over a baseline method that simply forces the lexicalized CFG parser to have the same dependency structure as the first-best output from the dependency parser.", "startOffset": 73, "endOffset": 88}, {"referenceID": 5, "context": "The method gives significant gains in parsing accuracy over the model of Collins (1997), and significant gains over a baseline method that simply forces the lexicalized CFG parser to have the same dependency structure as the first-best output from the dependency parser.10 6.2 The MAP Problem for Pairwise Markov Random Fields Markov random fields (MRFs), and more generally graphical models, are widely used in machine learning and statistics. The MAP problem in MRFs\u2014 the problem of finding the most likely setting of the random variables in an MRF\u2014is an inference problem of central importance. In this section we describe the dual decomposition algorithm from the work of Komodakis et al. (2007, 2011) for finding the MAP solution in pairwise, binary, MRFs. Pairwise MRFs are limited to the case where potential functions consider pairs of random variables, as opposed to larger subsets; however, the generalization of the method to non-pairwise MRFs is straightforward. A commonly used approach for the MAP problem in MRFs is to use loopy max-product belief propagation. The dual decomposition algorithm has advantages in terms of stronger formal guarantees, as described in section 5. 10. Note that Klein and Manning (2002) describe a method for combination of a dependency parser with a constituent based parser, where the score for an entire structure is again the sum of scores under two models.", "startOffset": 73, "endOffset": 1230}, {"referenceID": 16, "context": "Figure 6: An illustration of the approach of Held and Karp (1971). On the left is a tour of the vertices 1 .", "startOffset": 45, "endOffset": 66}, {"referenceID": 14, "context": "3 The Held and Karp Algorithm for TSPs Our next example is the approach of Held and Karp (1971) for traveling salesman problems (TSPs), which is notable for being the original paper on Lagrangian relaxation.", "startOffset": 6, "endOffset": 96}, {"referenceID": 4, "context": "For NLP decoding algorithms that leverage a single combinatorial algorithm, see the algorithm of Chang and Collins (2011) for decoding of phrase-based translation models (we describe this algorithm in the next section), and the algorithm of Rush and Collins (2011) for decoding of syntax-based translation models.", "startOffset": 97, "endOffset": 122}, {"referenceID": 4, "context": "For NLP decoding algorithms that leverage a single combinatorial algorithm, see the algorithm of Chang and Collins (2011) for decoding of phrase-based translation models (we describe this algorithm in the next section), and the algorithm of Rush and Collins (2011) for decoding of syntax-based translation models.", "startOffset": 97, "endOffset": 265}, {"referenceID": 16, "context": "12 A key idea in the work of Held and Karp (1971) is that of a 1-tree, which, like a tour, is a subset of E.", "startOffset": 29, "endOffset": 50}, {"referenceID": 4, "context": "4 Phrase-Based Translation We next consider a Lagrangian relaxation algorithm, described in the work of Chang and Collins (2011), for decoding of phrase-based translation models (Koehn, Och, & Marcu, 2003).", "startOffset": 104, "endOffset": 129}, {"referenceID": 4, "context": "The description we have given here is a sketch: Chang and Collins (2011) describe details of the method, including a slightly more involved dynamic program that gives a tighter relaxation than the method we have described here, and a tightening method that incrementally adds constraints when the method does not initially e-converge.", "startOffset": 48, "endOffset": 73}, {"referenceID": 5, "context": "Figure 7: Graph showing the dual value L(u(k)) and primal value f(y(k)) + g(l(y(k))), versus iteration number k, for the subgradient algorithm on a translation example from the work of Rush and Collins (2011).", "startOffset": 194, "endOffset": 209}, {"referenceID": 5, "context": "1 An Example Run of the Algorithm Figure 7 shows a run of the subgradient algorithm for the decoding approach for machine translation described in the work of Rush and Collins (2011). The behavior is typical of cases where the algorithm e-converges to an exact solution.", "startOffset": 168, "endOffset": 183}, {"referenceID": 5, "context": "Figure 8: The graph on the left shows the best dual value Lk and the best primal value p \u2217 k, versus iteration number k, for the subgradient algorithm on a translation example from the work of Rush and Collins (2011). The graph on the right shows Lk \u2212 pk plotted against k.", "startOffset": 202, "endOffset": 217}, {"referenceID": 5, "context": "Figure 10: Graph showing the dual value L(u(k)) and primal value f(y(k)) + g(l(y(k))), versus iteration number k, for the subgradient algorithm on a translation example from the work of Rush and Collins (2011), where the method does not e-converge to an exact solution.", "startOffset": 195, "endOffset": 210}, {"referenceID": 24, "context": "Figure 11: Figures showing effects of early stopping for the non-projective parsing algorithm of Koo et al. (2010) (left graph) and combined constituency and dependency parsing (right graph).", "startOffset": 97, "endOffset": 115}, {"referenceID": 25, "context": "Figure 11 shows graphs for two problems: non-projective dependency parsing (Koo et al., 2010), and combined constituency and dependency", "startOffset": 75, "endOffset": 93}, {"referenceID": 46, "context": "parsing (Rush et al., 2010).", "startOffset": 8, "endOffset": 27}, {"referenceID": 21, "context": "Following the work of Kolmogorov (2006), we use TRW-E to refer to the edge-based variant of TRW, and TRW-T to refer to the tree-based algorithm.", "startOffset": 22, "endOffset": 40}, {"referenceID": 21, "context": "Following the work of Kolmogorov (2006), we use TRW-E to refer to the edge-based variant of TRW, and TRW-T to refer to the tree-based algorithm. Kolmogorov (2006) derives a further variant, TRW-S (the \u201cS\u201d refers to the sequential nature of the algorithm).", "startOffset": 22, "endOffset": 163}, {"referenceID": 21, "context": "Following the work of Kolmogorov (2006), we use TRW-E to refer to the edge-based variant of TRW, and TRW-T to refer to the tree-based algorithm. Kolmogorov (2006) derives a further variant, TRW-S (the \u201cS\u201d refers to the sequential nature of the algorithm). All three algorithms\u2014TRW-E, TRW-T, and TRW-S\u2014are motivated by the LP relaxation for MRFs, but none of them have a guarantee of converging to the optimal value of the LP. TRW-S has the strongest guarantee of the three algorithms, namely that it monotonically improves the dual value, but it may not converge to the optimal dual value. Yanover et al. (2006) describe experiments comparing TRW-based algorithms to generic LP solvers for MRF problems (specifically, the LP solver they use is CPLEX13).", "startOffset": 22, "endOffset": 612}, {"referenceID": 13, "context": "Another important class of algorithms for optimizing the dual of the LP are block coordinate descent algorithms: for example the MPLP algorithm of Globerson and Jaakkola (2007). See the work of Sontag et al.", "startOffset": 147, "endOffset": 177}, {"referenceID": 13, "context": "Another important class of algorithms for optimizing the dual of the LP are block coordinate descent algorithms: for example the MPLP algorithm of Globerson and Jaakkola (2007). See the work of Sontag et al. (2010) for a discussion of these methods.", "startOffset": 147, "endOffset": 215}, {"referenceID": 13, "context": "Another important class of algorithms for optimizing the dual of the LP are block coordinate descent algorithms: for example the MPLP algorithm of Globerson and Jaakkola (2007). See the work of Sontag et al. (2010) for a discussion of these methods. Like TRW-S, the MPLP algorithm is guaranteed to monotonically improve the dual value, but is not guaranteed to converge to the global optimum of the MRF LP. In several experimental settings, the MPLP algorithm produces better dual values in early iterations than subgradient methods, but can get stuck at a non-optimal solution (Jojic, Gould, & Koller, 2010; Martins, Figueiredo, Aguiar, Smith, & Xing, 2011; Meshi & Globerson, 2011). Another complication of MPLP is that it requires computing max-marginals for the sub-problems at each iteration instead of MAP assignments. Max-marginals may be slower to compute in practice, and for some combinatorial problems computation may be asymptotically slower. (For example, for the directed spanning tree models from Koo et al., 2010, the MAP problem can be solved in O(n2) time where n is the length of the input sentence, but we are not aware of an algorithm that solves the max-marginal problem in better than O(n4) time.) In other work, Jojic et al. (2010) describe an accelerated method for MRF inference, using the method of Nesterov (2005) to smooth the objective in the underlying decomposition.", "startOffset": 147, "endOffset": 1256}, {"referenceID": 13, "context": "Another important class of algorithms for optimizing the dual of the LP are block coordinate descent algorithms: for example the MPLP algorithm of Globerson and Jaakkola (2007). See the work of Sontag et al. (2010) for a discussion of these methods. Like TRW-S, the MPLP algorithm is guaranteed to monotonically improve the dual value, but is not guaranteed to converge to the global optimum of the MRF LP. In several experimental settings, the MPLP algorithm produces better dual values in early iterations than subgradient methods, but can get stuck at a non-optimal solution (Jojic, Gould, & Koller, 2010; Martins, Figueiredo, Aguiar, Smith, & Xing, 2011; Meshi & Globerson, 2011). Another complication of MPLP is that it requires computing max-marginals for the sub-problems at each iteration instead of MAP assignments. Max-marginals may be slower to compute in practice, and for some combinatorial problems computation may be asymptotically slower. (For example, for the directed spanning tree models from Koo et al., 2010, the MAP problem can be solved in O(n2) time where n is the length of the input sentence, but we are not aware of an algorithm that solves the max-marginal problem in better than O(n4) time.) In other work, Jojic et al. (2010) describe an accelerated method for MRF inference, using the method of Nesterov (2005) to smooth the objective in the underlying decomposition.", "startOffset": 147, "endOffset": 1342}, {"referenceID": 13, "context": "Another important class of algorithms for optimizing the dual of the LP are block coordinate descent algorithms: for example the MPLP algorithm of Globerson and Jaakkola (2007). See the work of Sontag et al. (2010) for a discussion of these methods. Like TRW-S, the MPLP algorithm is guaranteed to monotonically improve the dual value, but is not guaranteed to converge to the global optimum of the MRF LP. In several experimental settings, the MPLP algorithm produces better dual values in early iterations than subgradient methods, but can get stuck at a non-optimal solution (Jojic, Gould, & Koller, 2010; Martins, Figueiredo, Aguiar, Smith, & Xing, 2011; Meshi & Globerson, 2011). Another complication of MPLP is that it requires computing max-marginals for the sub-problems at each iteration instead of MAP assignments. Max-marginals may be slower to compute in practice, and for some combinatorial problems computation may be asymptotically slower. (For example, for the directed spanning tree models from Koo et al., 2010, the MAP problem can be solved in O(n2) time where n is the length of the input sentence, but we are not aware of an algorithm that solves the max-marginal problem in better than O(n4) time.) In other work, Jojic et al. (2010) describe an accelerated method for MRF inference, using the method of Nesterov (2005) to smooth the objective in the underlying decomposition. The method has a relatively fast rate of convergence (O(1/ ) time to reach a solution that is -close to optimal). Experiments from the work of Jojic et al. (2010) show a decrease in the number of iterations required compared to subgradient; however in the work of Martins et al.", "startOffset": 147, "endOffset": 1562}, {"referenceID": 13, "context": "Another important class of algorithms for optimizing the dual of the LP are block coordinate descent algorithms: for example the MPLP algorithm of Globerson and Jaakkola (2007). See the work of Sontag et al. (2010) for a discussion of these methods. Like TRW-S, the MPLP algorithm is guaranteed to monotonically improve the dual value, but is not guaranteed to converge to the global optimum of the MRF LP. In several experimental settings, the MPLP algorithm produces better dual values in early iterations than subgradient methods, but can get stuck at a non-optimal solution (Jojic, Gould, & Koller, 2010; Martins, Figueiredo, Aguiar, Smith, & Xing, 2011; Meshi & Globerson, 2011). Another complication of MPLP is that it requires computing max-marginals for the sub-problems at each iteration instead of MAP assignments. Max-marginals may be slower to compute in practice, and for some combinatorial problems computation may be asymptotically slower. (For example, for the directed spanning tree models from Koo et al., 2010, the MAP problem can be solved in O(n2) time where n is the length of the input sentence, but we are not aware of an algorithm that solves the max-marginal problem in better than O(n4) time.) In other work, Jojic et al. (2010) describe an accelerated method for MRF inference, using the method of Nesterov (2005) to smooth the objective in the underlying decomposition. The method has a relatively fast rate of convergence (O(1/ ) time to reach a solution that is -close to optimal). Experiments from the work of Jojic et al. (2010) show a decrease in the number of iterations required compared to subgradient; however in the work of Martins et al. (2011) the accelerated method requires more iterations than the subgradient algorithm.", "startOffset": 147, "endOffset": 1685}, {"referenceID": 13, "context": "Another important class of algorithms for optimizing the dual of the LP are block coordinate descent algorithms: for example the MPLP algorithm of Globerson and Jaakkola (2007). See the work of Sontag et al. (2010) for a discussion of these methods. Like TRW-S, the MPLP algorithm is guaranteed to monotonically improve the dual value, but is not guaranteed to converge to the global optimum of the MRF LP. In several experimental settings, the MPLP algorithm produces better dual values in early iterations than subgradient methods, but can get stuck at a non-optimal solution (Jojic, Gould, & Koller, 2010; Martins, Figueiredo, Aguiar, Smith, & Xing, 2011; Meshi & Globerson, 2011). Another complication of MPLP is that it requires computing max-marginals for the sub-problems at each iteration instead of MAP assignments. Max-marginals may be slower to compute in practice, and for some combinatorial problems computation may be asymptotically slower. (For example, for the directed spanning tree models from Koo et al., 2010, the MAP problem can be solved in O(n2) time where n is the length of the input sentence, but we are not aware of an algorithm that solves the max-marginal problem in better than O(n4) time.) In other work, Jojic et al. (2010) describe an accelerated method for MRF inference, using the method of Nesterov (2005) to smooth the objective in the underlying decomposition. The method has a relatively fast rate of convergence (O(1/ ) time to reach a solution that is -close to optimal). Experiments from the work of Jojic et al. (2010) show a decrease in the number of iterations required compared to subgradient; however in the work of Martins et al. (2011) the accelerated method requires more iterations than the subgradient algorithm. In both sets of experiments, MPLP makes more initial progress than either method. Accelerated subgradient also requires computing subproblem marginals, which has similar disadvantages as MPLP\u2019s requirement of max-marginals. Recently, Martins et al. (2011) proposed an augmented Lagrangian method for inference using the alternating direction method of multipliers (ADMM).", "startOffset": 147, "endOffset": 2021}, {"referenceID": 13, "context": "Another important class of algorithms for optimizing the dual of the LP are block coordinate descent algorithms: for example the MPLP algorithm of Globerson and Jaakkola (2007). See the work of Sontag et al. (2010) for a discussion of these methods. Like TRW-S, the MPLP algorithm is guaranteed to monotonically improve the dual value, but is not guaranteed to converge to the global optimum of the MRF LP. In several experimental settings, the MPLP algorithm produces better dual values in early iterations than subgradient methods, but can get stuck at a non-optimal solution (Jojic, Gould, & Koller, 2010; Martins, Figueiredo, Aguiar, Smith, & Xing, 2011; Meshi & Globerson, 2011). Another complication of MPLP is that it requires computing max-marginals for the sub-problems at each iteration instead of MAP assignments. Max-marginals may be slower to compute in practice, and for some combinatorial problems computation may be asymptotically slower. (For example, for the directed spanning tree models from Koo et al., 2010, the MAP problem can be solved in O(n2) time where n is the length of the input sentence, but we are not aware of an algorithm that solves the max-marginal problem in better than O(n4) time.) In other work, Jojic et al. (2010) describe an accelerated method for MRF inference, using the method of Nesterov (2005) to smooth the objective in the underlying decomposition. The method has a relatively fast rate of convergence (O(1/ ) time to reach a solution that is -close to optimal). Experiments from the work of Jojic et al. (2010) show a decrease in the number of iterations required compared to subgradient; however in the work of Martins et al. (2011) the accelerated method requires more iterations than the subgradient algorithm. In both sets of experiments, MPLP makes more initial progress than either method. Accelerated subgradient also requires computing subproblem marginals, which has similar disadvantages as MPLP\u2019s requirement of max-marginals. Recently, Martins et al. (2011) proposed an augmented Lagrangian method for inference using the alternating direction method of multipliers (ADMM). See the tutorial of Boyd, Parikh, Chu, Peleato, and Eckstein (2011) on ADMM.", "startOffset": 147, "endOffset": 2205}, {"referenceID": 13, "context": "Another important class of algorithms for optimizing the dual of the LP are block coordinate descent algorithms: for example the MPLP algorithm of Globerson and Jaakkola (2007). See the work of Sontag et al. (2010) for a discussion of these methods. Like TRW-S, the MPLP algorithm is guaranteed to monotonically improve the dual value, but is not guaranteed to converge to the global optimum of the MRF LP. In several experimental settings, the MPLP algorithm produces better dual values in early iterations than subgradient methods, but can get stuck at a non-optimal solution (Jojic, Gould, & Koller, 2010; Martins, Figueiredo, Aguiar, Smith, & Xing, 2011; Meshi & Globerson, 2011). Another complication of MPLP is that it requires computing max-marginals for the sub-problems at each iteration instead of MAP assignments. Max-marginals may be slower to compute in practice, and for some combinatorial problems computation may be asymptotically slower. (For example, for the directed spanning tree models from Koo et al., 2010, the MAP problem can be solved in O(n2) time where n is the length of the input sentence, but we are not aware of an algorithm that solves the max-marginal problem in better than O(n4) time.) In other work, Jojic et al. (2010) describe an accelerated method for MRF inference, using the method of Nesterov (2005) to smooth the objective in the underlying decomposition. The method has a relatively fast rate of convergence (O(1/ ) time to reach a solution that is -close to optimal). Experiments from the work of Jojic et al. (2010) show a decrease in the number of iterations required compared to subgradient; however in the work of Martins et al. (2011) the accelerated method requires more iterations than the subgradient algorithm. In both sets of experiments, MPLP makes more initial progress than either method. Accelerated subgradient also requires computing subproblem marginals, which has similar disadvantages as MPLP\u2019s requirement of max-marginals. Recently, Martins et al. (2011) proposed an augmented Lagrangian method for inference using the alternating direction method of multipliers (ADMM). See the tutorial of Boyd, Parikh, Chu, Peleato, and Eckstein (2011) on ADMM. The augmented Lagrangian method further extends the objective with a quadratic penalty term representing the amount of constraint violation. ADMM is a method for optimizing this augmented problem that is able to maintain similar decomposibility properties as dual decomposition. Like the subgradient method, ADMM is guaranteed to find the optimum of the LP relaxation. Martins et al. (2011) show empirically that ADMM requires a comparable number of iterations to MPLP to find a good primal solution, while still being guaranteed to optimize the LP.", "startOffset": 147, "endOffset": 2605}, {"referenceID": 13, "context": "Another important class of algorithms for optimizing the dual of the LP are block coordinate descent algorithms: for example the MPLP algorithm of Globerson and Jaakkola (2007). See the work of Sontag et al. (2010) for a discussion of these methods. Like TRW-S, the MPLP algorithm is guaranteed to monotonically improve the dual value, but is not guaranteed to converge to the global optimum of the MRF LP. In several experimental settings, the MPLP algorithm produces better dual values in early iterations than subgradient methods, but can get stuck at a non-optimal solution (Jojic, Gould, & Koller, 2010; Martins, Figueiredo, Aguiar, Smith, & Xing, 2011; Meshi & Globerson, 2011). Another complication of MPLP is that it requires computing max-marginals for the sub-problems at each iteration instead of MAP assignments. Max-marginals may be slower to compute in practice, and for some combinatorial problems computation may be asymptotically slower. (For example, for the directed spanning tree models from Koo et al., 2010, the MAP problem can be solved in O(n2) time where n is the length of the input sentence, but we are not aware of an algorithm that solves the max-marginal problem in better than O(n4) time.) In other work, Jojic et al. (2010) describe an accelerated method for MRF inference, using the method of Nesterov (2005) to smooth the objective in the underlying decomposition. The method has a relatively fast rate of convergence (O(1/ ) time to reach a solution that is -close to optimal). Experiments from the work of Jojic et al. (2010) show a decrease in the number of iterations required compared to subgradient; however in the work of Martins et al. (2011) the accelerated method requires more iterations than the subgradient algorithm. In both sets of experiments, MPLP makes more initial progress than either method. Accelerated subgradient also requires computing subproblem marginals, which has similar disadvantages as MPLP\u2019s requirement of max-marginals. Recently, Martins et al. (2011) proposed an augmented Lagrangian method for inference using the alternating direction method of multipliers (ADMM). See the tutorial of Boyd, Parikh, Chu, Peleato, and Eckstein (2011) on ADMM. The augmented Lagrangian method further extends the objective with a quadratic penalty term representing the amount of constraint violation. ADMM is a method for optimizing this augmented problem that is able to maintain similar decomposibility properties as dual decomposition. Like the subgradient method, ADMM is guaranteed to find the optimum of the LP relaxation. Martins et al. (2011) show empirically that ADMM requires a comparable number of iterations to MPLP to find a good primal solution, while still being guaranteed to optimize the LP. A challenge of ADMM is that the extra quadratic term may complicate sub-problem decoding, for example it is not clear how to directly decode the parsing problems presented in this work with a quadratic term in the objective. Several alternative approaches have been proposed: Martins et al. (2011) binarize the combinatorial sub-problems into binary-valued factor graphs; Meshi and Globerson (2011) avoid the problem by instead applying ADMM to the dual of the LP; Martins (2012) and Das et al.", "startOffset": 147, "endOffset": 3062}, {"referenceID": 13, "context": "Another important class of algorithms for optimizing the dual of the LP are block coordinate descent algorithms: for example the MPLP algorithm of Globerson and Jaakkola (2007). See the work of Sontag et al. (2010) for a discussion of these methods. Like TRW-S, the MPLP algorithm is guaranteed to monotonically improve the dual value, but is not guaranteed to converge to the global optimum of the MRF LP. In several experimental settings, the MPLP algorithm produces better dual values in early iterations than subgradient methods, but can get stuck at a non-optimal solution (Jojic, Gould, & Koller, 2010; Martins, Figueiredo, Aguiar, Smith, & Xing, 2011; Meshi & Globerson, 2011). Another complication of MPLP is that it requires computing max-marginals for the sub-problems at each iteration instead of MAP assignments. Max-marginals may be slower to compute in practice, and for some combinatorial problems computation may be asymptotically slower. (For example, for the directed spanning tree models from Koo et al., 2010, the MAP problem can be solved in O(n2) time where n is the length of the input sentence, but we are not aware of an algorithm that solves the max-marginal problem in better than O(n4) time.) In other work, Jojic et al. (2010) describe an accelerated method for MRF inference, using the method of Nesterov (2005) to smooth the objective in the underlying decomposition. The method has a relatively fast rate of convergence (O(1/ ) time to reach a solution that is -close to optimal). Experiments from the work of Jojic et al. (2010) show a decrease in the number of iterations required compared to subgradient; however in the work of Martins et al. (2011) the accelerated method requires more iterations than the subgradient algorithm. In both sets of experiments, MPLP makes more initial progress than either method. Accelerated subgradient also requires computing subproblem marginals, which has similar disadvantages as MPLP\u2019s requirement of max-marginals. Recently, Martins et al. (2011) proposed an augmented Lagrangian method for inference using the alternating direction method of multipliers (ADMM). See the tutorial of Boyd, Parikh, Chu, Peleato, and Eckstein (2011) on ADMM. The augmented Lagrangian method further extends the objective with a quadratic penalty term representing the amount of constraint violation. ADMM is a method for optimizing this augmented problem that is able to maintain similar decomposibility properties as dual decomposition. Like the subgradient method, ADMM is guaranteed to find the optimum of the LP relaxation. Martins et al. (2011) show empirically that ADMM requires a comparable number of iterations to MPLP to find a good primal solution, while still being guaranteed to optimize the LP. A challenge of ADMM is that the extra quadratic term may complicate sub-problem decoding, for example it is not clear how to directly decode the parsing problems presented in this work with a quadratic term in the objective. Several alternative approaches have been proposed: Martins et al. (2011) binarize the combinatorial sub-problems into binary-valued factor graphs; Meshi and Globerson (2011) avoid the problem by instead applying ADMM to the dual of the LP; Martins (2012) and Das et al.", "startOffset": 147, "endOffset": 3163}, {"referenceID": 13, "context": "Another important class of algorithms for optimizing the dual of the LP are block coordinate descent algorithms: for example the MPLP algorithm of Globerson and Jaakkola (2007). See the work of Sontag et al. (2010) for a discussion of these methods. Like TRW-S, the MPLP algorithm is guaranteed to monotonically improve the dual value, but is not guaranteed to converge to the global optimum of the MRF LP. In several experimental settings, the MPLP algorithm produces better dual values in early iterations than subgradient methods, but can get stuck at a non-optimal solution (Jojic, Gould, & Koller, 2010; Martins, Figueiredo, Aguiar, Smith, & Xing, 2011; Meshi & Globerson, 2011). Another complication of MPLP is that it requires computing max-marginals for the sub-problems at each iteration instead of MAP assignments. Max-marginals may be slower to compute in practice, and for some combinatorial problems computation may be asymptotically slower. (For example, for the directed spanning tree models from Koo et al., 2010, the MAP problem can be solved in O(n2) time where n is the length of the input sentence, but we are not aware of an algorithm that solves the max-marginal problem in better than O(n4) time.) In other work, Jojic et al. (2010) describe an accelerated method for MRF inference, using the method of Nesterov (2005) to smooth the objective in the underlying decomposition. The method has a relatively fast rate of convergence (O(1/ ) time to reach a solution that is -close to optimal). Experiments from the work of Jojic et al. (2010) show a decrease in the number of iterations required compared to subgradient; however in the work of Martins et al. (2011) the accelerated method requires more iterations than the subgradient algorithm. In both sets of experiments, MPLP makes more initial progress than either method. Accelerated subgradient also requires computing subproblem marginals, which has similar disadvantages as MPLP\u2019s requirement of max-marginals. Recently, Martins et al. (2011) proposed an augmented Lagrangian method for inference using the alternating direction method of multipliers (ADMM). See the tutorial of Boyd, Parikh, Chu, Peleato, and Eckstein (2011) on ADMM. The augmented Lagrangian method further extends the objective with a quadratic penalty term representing the amount of constraint violation. ADMM is a method for optimizing this augmented problem that is able to maintain similar decomposibility properties as dual decomposition. Like the subgradient method, ADMM is guaranteed to find the optimum of the LP relaxation. Martins et al. (2011) show empirically that ADMM requires a comparable number of iterations to MPLP to find a good primal solution, while still being guaranteed to optimize the LP. A challenge of ADMM is that the extra quadratic term may complicate sub-problem decoding, for example it is not clear how to directly decode the parsing problems presented in this work with a quadratic term in the objective. Several alternative approaches have been proposed: Martins et al. (2011) binarize the combinatorial sub-problems into binary-valued factor graphs; Meshi and Globerson (2011) avoid the problem by instead applying ADMM to the dual of the LP; Martins (2012) and Das et al.", "startOffset": 147, "endOffset": 3244}, {"referenceID": 7, "context": "(2011) binarize the combinatorial sub-problems into binary-valued factor graphs; Meshi and Globerson (2011) avoid the problem by instead applying ADMM to the dual of the LP; Martins (2012) and Das et al. (2012) use an iterative active set method that utilizes MAP solutions of the original sub-problems to solve the quadratic version.", "startOffset": 193, "endOffset": 211}, {"referenceID": 7, "context": "(2011) binarize the combinatorial sub-problems into binary-valued factor graphs; Meshi and Globerson (2011) avoid the problem by instead applying ADMM to the dual of the LP; Martins (2012) and Das et al. (2012) use an iterative active set method that utilizes MAP solutions of the original sub-problems to solve the quadratic version. Martins (2012) also describes recent results on ADMM that give a O(1/ ) bound for relaxed primal convergence.", "startOffset": 193, "endOffset": 350}, {"referenceID": 26, "context": "This follows immediately by results from linear programming duality see the textbook of Korte and Vygen (2008) for more details.", "startOffset": 88, "endOffset": 111}, {"referenceID": 1, "context": "Thus we end up with an algorithm that is at least as expensive as integration of a bigram HMM with a PCFG using the construction of Bar-Hillel et al. (1964).14 A second approach, which may be more efficient, is as follows.", "startOffset": 132, "endOffset": 157}, {"referenceID": 1, "context": "If g(z) is defined through a bigram HMM, then clearly nothing has been gained in efficiency over the Bar-Hillel et al. (1964) method.", "startOffset": 101, "endOffset": 126}, {"referenceID": 1, "context": "In that case, we might add bigram constraints at only a few positions in the sentence: in practice the CKY decoding algorithm will only need to introduce the Bar-Hillel et al. (1964) machinery at these selected points, which can be much more efficient that introducing all constraints.", "startOffset": 158, "endOffset": 183}, {"referenceID": 4, "context": "For examples of methods that tighten dual decomposition/Lagrangian relaxation techniques using additional constraints, see the work of Sontag, Meltzer, Globerson, Jaakkola, and Weiss (2008), Rush and Collins (2011), Chang and Collins (2011), and Das et al.", "startOffset": 200, "endOffset": 215}, {"referenceID": 4, "context": "For examples of methods that tighten dual decomposition/Lagrangian relaxation techniques using additional constraints, see the work of Sontag, Meltzer, Globerson, Jaakkola, and Weiss (2008), Rush and Collins (2011), Chang and Collins (2011), and Das et al.", "startOffset": 216, "endOffset": 241}, {"referenceID": 4, "context": "For examples of methods that tighten dual decomposition/Lagrangian relaxation techniques using additional constraints, see the work of Sontag, Meltzer, Globerson, Jaakkola, and Weiss (2008), Rush and Collins (2011), Chang and Collins (2011), and Das et al. (2012). This is related to previous work on non-projective dependency parsing (Riedel & Clarke, 2006) that incrementally adds constraints to an integer linear program solver.", "startOffset": 216, "endOffset": 264}, {"referenceID": 30, "context": "Martins et al. (2009) make use of a construction for directed spanning trees (see also Magnanti & Wolsey, 1994), and apply it to nonprojective dependency parsing.", "startOffset": 0, "endOffset": 22}, {"referenceID": 26, "context": "Korte and Vygen (2008) describe many other such constructions.", "startOffset": 0, "endOffset": 23}, {"referenceID": 44, "context": "n, t \u2208 T , y(i, t) = z(i, t) Rush et al. (2010) give a full description of the compact LP for this problem: we give a sketch here.", "startOffset": 29, "endOffset": 48}, {"referenceID": 44, "context": "n, t \u2208 T , y(i, t) = z(i, t) Rush et al. (2010) give a full description of the compact LP for this problem: we give a sketch here. 15. There is one subtlety here: in some cases additional auxilliary variables may need to be introduced. See for example the spanning tree construction of Magnanti and Wolsey (1994). However the number of auxilliary variables is generally polynomial in number, hence this is benign.", "startOffset": 29, "endOffset": 313}, {"referenceID": 44, "context": "Rush et al. (2010) describe this construction in detail for the case where a weighted CFG is combined with a finite-state tagger.", "startOffset": 0, "endOffset": 19}], "year": 2012, "abstractText": "Dual decomposition, and more generally Lagrangian relaxation, is a classical method for combinatorial optimization; it has recently been applied to several inference problems in natural language processing (NLP). This tutorial gives an overview of the technique. We describe example algorithms, describe formal guarantees for the method, and describe practical issues in implementing the algorithms. While our examples are predominantly drawn from the NLP literature, the material should be of general relevance to inference problems in machine learning. A central theme of this tutorial is that Lagrangian relaxation is naturally applied in conjunction with a broad class of combinatorial algorithms, allowing inference in models that go significantly beyond previous work on Lagrangian relaxation for inference in graphical models.", "creator": "TeX"}}}