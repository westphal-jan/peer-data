{"id": "1407.0754", "review": {"conference": "NIPS", "VERSION": "v1", "DATE_OF_SUBMISSION": "3-Jul-2014", "title": "Structured Learning via Logistic Regression", "abstract": "a preferred approach against structured learning is to write the learning formula : a regression function of linear statements and inference messages, connecting iterate between updates to uncertainty. this article observes that if the adaptive pipeline is \" smoothed \" through internal addition of entropy terms, for any messages, the retrieval intention reduces over a traditional ( non - structured ) logistic regression problem with low weighted parameters. remembering these logistic optimization problems, each specific example has its convex gradient detected by defining current set of analyses. based on reliability insight, determining empirical forecast function by be done integrating optimal factors to any stable type where an \" oracle \" exists to minimize a logistic loss.", "histories": [["v1", "Thu, 3 Jul 2014 00:48:34 GMT  (20206kb)", "http://arxiv.org/abs/1407.0754v1", "Advances in Neural Information Processing Systems 2013"]], "COMMENTS": "Advances in Neural Information Processing Systems 2013", "reviews": [], "SUBJECTS": "cs.LG stat.ML", "authors": ["justin domke"], "accepted": true, "id": "1407.0754"}, "pdf": {"name": "1407.0754.pdf", "metadata": {"source": "CRF", "title": "Structured Learning via Logistic Regression", "authors": ["Justin Domke"], "emails": ["justin.domke@nicta.com.au"], "sections": [{"heading": null, "text": "ar X\niv :1\n40 7.\n07 54\nv1 [\ncs .L\nG ]\n3 J\nul 2\n01 4"}, {"heading": "1 Introduction", "text": "The structured learning problem is to find a function F (x, y) to map from inputs x to outputs as y\u2217 = argmaxy F (x, y). F is chosen to optimize a loss function defined on these outputs. A major challenge is that evaluating the loss for a given function F requires solving the inference optimization to find the highest-scoring output y for each exemplar, which is NP-hard in general. A standard solution to this is to write the loss function using an LP-relaxation of the inference problem, meaning an upper-bound on the true loss. The learning problem can then be phrased as a joint optimization of parameters and inference variables, which can be solved, e.g., by alternating message-passing updates to inference variables with gradient descent updates to parameters [16, 9].\nPrevious work has mostly focused on linear energy functions F (x, y) = wT\u03a6(x, y), where a vector of weights w is adjusted in learning, and \u03a6(x, y) = \u2211\n\u03b1 \u03a6(x, y\u03b1) decomposes over subsets of variables y\u03b1. While linear weights are often useful in practice [23, 16, 9, 3, 17, 12, 5], it is also common to make use of non-linear classifiers. This is typically done by training a classifier (e.g. ensembles of trees [20, 8, 25, 13, 24, 18, 19] or multi-layer perceptrons [10, 21]) to predict each variable independently. Linear edge interaction weights are then learned, with unary classifiers either held fixed [20, 8, 25, 13, 24, 10] or used essentially as \u201cfeatures\u201d with linear weights readjusted [18].\nThis paper allows the more general formF (x, y) = \u2211\n\u03b1 f\u03b1(x, y\u03b1). The learning problem is to select f\u03b1 from some set of functions F\u03b1. Here, following previous work [15], we add entropy smoothing to the LP-relaxation of the inference problem. Again, this leads to phrasing the learning problem as a joint optimization of learning and inference variables, alternating between message-passing updates to inference variables and optimization of the functions f\u03b1. The major result is that minimization of the loss over f\u03b1 \u2208 F\u03b1 can be re-formulated as a logistic regression problem, with a \u201cbias\u201d vector added to each example reflecting the current messages incoming to factor \u03b1. No assumptions are needed on the sets of functionsF\u03b1, beyond assuming that an algorithm exists to optimize the logistic loss on a given dataset over all f\u03b1 \u2208 F\u03b1\nWe experimentally test the results of varying F\u03b1 to be the set of linear functions, multi-layer perceptrons, or boosted decision trees. Results verify the benefits of training flexible function classes in terms of joint prediction accuracy."}, {"heading": "2 Structured Prediction", "text": "The structured prediction problem can be written as seeking a function h that will predict an output y from an input x. Most commonly, it can be written in the form\nh(x;w) = argmax y\nwT\u03a6(x, y), (1)\nwhere \u03a6 is a fixed function of both x and y. The maximum takes place over all configurations of the discrete vector y. It is further assumed that \u03a6 decomposes into a sum of functions evaluated over subsets of variables y\u03b1 as\n\u03a6(x, y) = \u2211\n\u03b1\n\u03a6\u03b1(x, y\u03b1).\nThe learning problem is to adjust set of linear weightsw. This paper considers the structured learning problem in a more general setting, directly handling nonlinear function classes. We generalize the function h to\nh(x;F ) = argmax y F (x, y),\nwhere the energy F again decomposes as\nF (x, y) = \u2211\n\u03b1\nf\u03b1(x, y\u03b1).\nThe learning problem now becomes to select {f\u03b1 \u2208 F\u03b1} for some set of functions F\u03b1. This reduces to the previous case when f\u03b1(x, y\u03b1) = wT\u03a6\u03b1(x, y\u03b1) is a linear function. Here, we do not make any assumption on the class of functions F\u03b1 other than assuming that there exists an algorithm to find the best function f\u03b1 \u2208 F\u03b1 in terms of the logistic regression loss (Section 6)."}, {"heading": "3 Loss Functions", "text": "Given a dataset (x1, y1), ..., (xN , yN ), we wish to select the energyF to minimize the empirical risk\nR(F ) = \u2211\nk\nl(xk, yk;F ), (2)\nfor some loss function l. Absent computational concerns, a standard choice would be the slackrescaled loss [22]\nl0(x k, yk;F ) = max y F (xk, y)\u2212 F (xk, yk) + \u2206(yk, y), (3)\nwhere \u2206(yk, y) is some measure of discrepancy. We assume that \u2206 is a function that decomposes over \u03b1, (i.e. that \u2206(yk, y) = \u2211\n\u03b1 \u2206\u03b1(y k \u03b1, y\u03b1)). Our experiments use the Hamming distance.\nIn Eq. 3, the maximum ranges over all possible discrete labelings y, which is in NP-hard in general. If this inference problem must be solved approximately, there is strong motivation [6] for using relaxations of the maximization in Eq. 1, since this yields an upper-bound on the loss. A common solution [16, 14, 6] is to use a linear relaxation1\nl1(x k, yk;F ) = max \u00b5\u2208M F (xk, \u00b5)\u2212 F (xk, yk) + \u2206(yk, \u00b5), (4)\nwhere the local polytope M is defined as the set of local pseudomarginals that are normalized, and agree when marginalized over other neighboring regions,\nM = {\u00b5|\u00b5\u03b1\u03b2(y\u03b2) = \u00b5\u03b2(y\u03b2)\u2200\u03b2 \u2282 \u03b1, \u2211\ny\u03b1\n\u00b5\u03b1(y\u03b1) = 1 \u2200\u03b1, \u00b5\u03b1(y\u03b1) \u2265 1 \u2200\u03b1, y\u03b1}.\nHere, \u00b5\u03b1\u03b2(y\u03b2) = \u2211\ny\u03b1\\\u03b2 \u00b5\u03b1(y\u03b1) is \u00b5\u03b1 marginalized out over some region \u03b2 contained in \u03b1. It is\neasy to show that l1 \u2265 l0, since the two would be equivalent if \u00b5 were restricted to binary values, and hence the maximization in l1 takes place over a larger set [6]. We also define\n\u03b8kF (y\u03b1) = f\u03b1(x k, y\u03b1) + \u2206\u03b1(y k \u03b1, y\u03b1), (5)\n1Here, F and \u2206 are slightly generalized to allow arguments of pseudomarginals, as F (xk, \u00b5) =\u2211 \u03b1 \u2211 y\u03b1 f(xk, y\u03b1)\u00b5(y\u03b1) and \u2206(yk, \u00b5) = \u2211 \u03b1 \u2211 y\u03b1 \u2206\u03b1(y k \u03b1, y\u03b1)\u00b5(y\u03b1).\nwhich gives the equivalent representation of l1 as l1(xk, yk;F ) = \u2212F (xk, yk) + max\u00b5\u2208M \u03b8kF \u00b7 \u00b5.\nThe maximization in l1 is of a linear objective under linear constraints, and is thus a linear program (LP), solvable in polynomial time using a generic LP solver. In practice, however, it is preferable to use custom solvers based on message-passing that exploit the sparsity of the problem.\nHere, we make a further approximation to the loss, replacing the inference problem of max\u00b5\u2208M \u03b8 \u00b7\u00b5 with the \u201csmoothed\u201d problem max\u00b5\u2208M \u03b8 \u00b7 \u00b5 + \u01eb \u2211\n\u03b1 H(\u00b5\u03b1), where H(\u00b5\u03b1) is the entropy of the marginals \u00b5\u03b1. This approximation has been considered by Meshi et al. [15] who show that local message-passing can have a guaranteed convergence rate, and by Hazan and Urtasun [9] who use it for learning. The relaxed loss is\nl(xk, yk;F ) = \u2212F (xk, yk) + max \u00b5\u2208M\n(\n\u03b8kF \u00b7 \u00b5+ \u01eb \u2211\n\u03b1\nH(\u00b5\u03b1)\n)\n. (6)\nSince the entropy is positive, this is clearly a further upper-bound on the \u201cunsmoothed\u201d loss, i.e. l1 \u2264 l. Moreover, we can bound the looseness of this approximation as in the following theorem, proved in the appendix. A similar result was previously given [15] bounding the difference of the objective obtained by inference with and without entropy smoothing. Theorem 1. l and l1 are bounded by (where |y\u03b1| is the number of configurations of y\u03b1)\nl1(x, y, F ) \u2264 l(x, y, F ) \u2264 l1(x, y, F ) + \u01ebHmax, Hmax = \u2211\n\u03b1\nlog |y\u03b1|."}, {"heading": "4 Overview", "text": "Now, the learning problem is to select the functions f\u03b1 composing F to minimize R as defined in Eq. 2. The major challenge is that evaluating R(F ) requires performing inference. Specifically, if we define\nA(\u03b8) = max \u00b5\u2208M\n\u03b8 \u00b7 \u00b5+ \u01eb \u2211\n\u03b1\nH(\u00b5\u03b1), (7)\nthen we have that\nmin F R(F ) = min F\n\u2211\nk\n( \u2212F (xk, yk) +A(\u03b8kF ) ) .\nSince A(\u03b8) contains a maximization, this is a saddle-point problem. Inspired by previous work [16, 9], our solution (Section 5) is to introduce a vector of \u201cmessages\u201d \u03bb to write A in the dual form\nA(\u03b8) = min \u03bb A(\u03bb, \u03b8),\nwhich leads to phrasing learning as the joint minimization\nmin F min {\u03bbk}\n\u2211\nk\n[ \u2212F (xk, yk) +A(\u03bbk, \u03b8kF ) ] .\nWe propose to solve this through an alternating optimization of F and {\u03bbk}. For fixed F , messagepassing can be used to perform coordinate ascent updates to all the messages \u03bbk (Section 5). These updates are trivially parallelized with respect to k. However, the problem remains, for fixed messages, how to optimize the functions f\u03b1 composing F . Section 7 observes that this problem can be re-formulated into a (non-structured) logistic regression problem, with \u201cbias\u201d terms added to each example that reflect the current messages into factor \u03b1."}, {"heading": "5 Inference", "text": "In order to evaluate the loss, it is necessary to solve the maximization in Eq. 6. For a given \u03b8, consider doing inference over \u00b5, that is, in solving the maximization in Eq. 7. Standard Lagrangian duality theory gives the following dual representation for A(\u03b8) in terms of \u201cmessages\u201d \u03bb\u03b1(x\u03b2) from a region \u03b1 to a subregion \u03b2 \u2282 \u03b1, a variant of the representation of Heskes [11].\nAlgorithm 1 Reducing structured learning to logistic regression.\nFor all k, \u03b1, initialize \u03bbk(y\u03b1) \u2190 0. Repeat until convergence:\n1. For all k, for all \u03b1, set the bias term to\nbk\u03b1(y\u03b1) \u2190 1\n\u01eb\n\n\u2206(yk\u03b1, y\u03b1) + \u2211\n\u03b2\u2282\u03b1\n\u03bbk\u03b1(y\u03b2)\u2212 \u2211\n\u03b3\u2283\u03b1\n\u03bbk\u03b3(y\u03b1)\n\n .\n2. For all \u03b1, solve the logistic regression problem\nf\u03b1 \u2190 arg max f\u03b1\u2208F\u03b1\nK \u2211\nk=1\n[\n(\nf\u03b1(x k, yk\u03b1) + b k \u03b1(y k \u03b1) ) \u2212 log \u2211\ny\u03b1\nexp ( f\u03b1(x k, y\u03b1) + b k \u03b1(y\u03b1) )\n]\n.\n3. For all k, for all \u03b1, form updated parameters as\n\u03b8k(y\u03b1) \u2190 \u01ebf\u03b1(x k, y\u03b1) + \u2206(y k \u03b1, y\u03b1).\n4. For all k, perform a fixed number of message-passing iterations to update \u03bbk using \u03b8k. (Eq. 10)\nTheorem 2. A(\u03b8) can be represented in the dual form A(\u03b8) = min\u03bb A(\u03bb, \u03b8), where\nA(\u03bb, \u03b8) = max \u00b5\u2208N\n\u03b8 \u00b7 \u00b5+ \u01eb \u2211\n\u03b1\nH(\u00b5\u03b1) + \u2211\n\u03b1\n\u2211\n\u03b2\u2282\u03b1\n\u2211\nx\u03b2\n\u03bb\u03b1(x\u03b2) (\u00b5\u03b1\u03b2(y\u03b2)\u2212 \u00b5\u03b2(y\u03b2)) , (8)\nand N = {\u00b5| \u2211\ny\u03b1 \u00b5\u03b1(y\u03b1) = 1, \u00b5\u03b1(y\u03b1) \u2265 0} is the set of locally normalized pseudomarginals.\nMoreover, for a fixed \u03bb, the maximizing \u00b5 is given by\n\u00b5\u03b1(y\u03b1) = 1\nZ\u03b1 exp\n\n\n1\n\u01eb\n\n\u03b8(y\u03b1) + \u2211\n\u03b2\u2282\u03b1\n\u03bb\u03b1(y\u03b2)\u2212 \u2211\n\u03b3\u2283\u03b1\n\u03bb\u03b3(y\u03b1)\n\n\n\n , (9)\nwhere Z\u03b1 is a normalizing constant to ensure that \u2211\ny\u03b1 \u00b5\u03b1(y\u03b1) = 1.\nThus, for any set of messages \u03bb, there is an easily-evaluated upper-boundA(\u03bb, \u03b8) \u2265 A(\u03b8), and when A(\u03bb, \u03b8) is minimized with respect to \u03bb, this bound is tight. The standard approach to performing the minimization over \u03bb is essentially block-coordinate descent. There are variants, depending on the size of the \u201cblock\u201d that is updated. In our experiments, we use blocks consisting of the set of all messages \u03bb\u03b1(y\u03bd) for all regions \u03b1 containing \u03bd. When the graph only contains regions for single variables and pairs, this is a \u201cstar update\u201d of all the messages from pairs that contain a variable i. It can be shown [11, 15] that the update is\n\u03bb\u2032\u03b1(y\u03bd) \u2190 \u03bb\u03b1(y\u03bd) + \u01eb\n1 +N\u03bd (log\u00b5\u03bd(y\u03bd) +\n\u2211\n\u03b1\u2032\u2283\u03bd\nlog\u00b5\u03b1\u2032(y\u03bd)) \u2212 \u01eb log\u00b5\u03b1(y\u03bd), (10)\nfor all \u03b1 \u2283 \u03bd, where N\u03bd = |{\u03b1|\u03b1 \u2283 \u03bd}|. Meshi et al. [15] show that with greedy or randomized selection of blocks to update, O(1\n\u03b4 ) iterations are sufficient to converge within error \u03b4."}, {"heading": "6 Logistic Regression", "text": "Logistic regression is traditionally understood as defining a conditional distribution p(y|x;W ) = exp ((Wx)y) /Z(x) where W is a matrix that maps the input features x to a vector of margins Wx. It is easy to show that the maximum conditional likelihood training problem maxW \u2211 k log p(y k|xk;W ) is equivalent to\nmax W\n\u2211\nk\n[\n(Wxk)yk \u2212 log \u2211\ny\nexp(Wxk)y\n]\n.\nHere, we generalize this in two ways. First, rather than taking the mapping from features x to the margin for label y as the y-th component of Wx, we take it as f(x, y) for some function f in a set of function F . (This reduces to the linear case when f(x, y) = (Wx)y .) Secondly, we assume that there is a pre-determined \u201cbias\u201d vector bk associated with each training example. This yields the learning problem\nmax f\u2208F\n\u2211\nk\n[\n( f(xk, yk) + bk(yk) ) \u2212 log \u2211\ny\nexp ( f(xk, y) + bk(y) )\n]\n, (11)\nAside from linear logistic regression, one can see decision trees, multi-layer perceptrons, and boosted ensembles under an appropriate loss as solving Eq. 11 for different sets of functions F (albeit possibly to a local maximum)."}, {"heading": "7 Training", "text": "Recall that the learning problem is to select the functions f\u03b1 \u2208 F\u03b1 so as to minimize the empirical risk R(F ) = \u2211\nk[\u2212F (x k, yk) + A(\u03b8kF )]. At first blush, this appears challenging, since evaluating\nA(\u03b8) requires solving a message-passing optimization. However, we can use the dual representation of A from Theorem 2 to represent minF R(F ) in the form\nmin F min {\u03bbk}\n\u2211\nk\n[ \u2212F (xk, yk) +A(\u03bbk, \u03b8kF ) ] . (12)\nTo optimize Eq. 12, we alternating between optimization of messages {\u03bbk} and energy functions {f\u03b1}. Optimization with respect to \u03bbk for fixed F decomposes into minimizing A(\u03bbk, \u03b8kF ) independently for each yk, which can be done by running message-passing updates as in Section 5 using the parameter vector \u03b8kF . Thus, the rest of this section is concerned with how to optimize with respect to F for fixed messages. Below, we will use a slight generalization of a standard result [1, p. 93].\nLemma 3. The conjugate of the entropy is the \u201clog-sum-exp\u201d function. Formally,\nmax x:xT 1=1,x\u22650\n\u03b8 \u00b7 x\u2212 \u03c1 \u2211\ni\nxi log xi = \u03c1 log \u2211\ni\nexp \u03b8i \u03c1 .\nTheorem 4. If f\u2217\u03b1 is the minimizer of Eq 12 for fixed messages \u03bb, then\nf\u2217\u03b1 = \u01eb argmax f\u03b1\n\u2211\nk\n[\n(\nf\u03b1(x k, yk\u03b1) + b k \u03b1(y k \u03b1) ) \u2212 log \u2211\ny\u03b1\nexp ( f\u03b1(x k, y\u03b1) + b k \u03b1(y\u03b1) )\n]\n, (13)\nwhere the set of biases are defined as\nbk\u03b1(y\u03b1) = 1\n\u01eb\n\n\u2206(yk\u03b1, y\u03b1) + \u2211\n\u03b2\u2282\u03b1\n\u03bbk\u03b1(y\u03b2)\u2212 \u2211\n\u03b3\u2283\u03b1\n\u03bbk\u03b3(y\u03b1)\n\n . (14)\nProof. Substituting A(\u03bb, \u03b8) from Eq. 8 and \u03b8k from Eq. 5 gives that\nA(\u03bbk, \u03b8kF ) = max \u00b5\u2208N\n\u2211\n\u03b1\n\u2211\ny\u03b1\n(\nf\u03b1(x k, y\u03b1) + \u2206\u03b1(y k \u03b1, y\u03b1)\n) \u00b5(y\u03b1) + \u01eb \u2211\n\u03b1\nH(\u00b5\u03b1)\n+ \u2211\n\u03b1\n\u2211\n\u03b2\u2282\u03b1\n\u2211\nx\u03b2\n\u03bbk\u03b1(x\u03b2) (\u00b5\u03b1\u03b2(y\u03b2)\u2212 \u00b5\u03b2(y\u03b2)) .\nUsing the definition of bk from Eq. 14 above, this simplifies into\nA(\u03bbk, \u03b8kF ) = \u2211\n\u03b1\nmax \u00b5\u03b1\u2208N\u03b1\n(\n\u2211\ny\u03b1\n(f\u03b1(x, y\u03b1) + \u01ebb\u03b1(y\u03b1))\u00b5\u03b1(y\u03b1) + \u01ebH(\u00b5\u03b1)\n)\n,\nwhere N\u03b1 = {\u00b5\u03b1| \u2211\ny\u03b1 \u00b5\u03b1(y\u03b1) = 1, \u00b5\u03b1(y\u03b1) \u2265 0} enforces that \u00b5\u03b1 is a locally normalized set of\nmarginals. Applying Lemma 3 to the inner maximization gives the closed-form expression\nA(\u03bbk, \u03b8kF ) = \u2211\n\u03b1\n\u01eb log \u2211\ny\u03b1\nexp\n(\n1 \u01eb f\u03b1(x, y\u03b1) + b\u03b1(y\u03b1)\n)\n.\nThus, minimizing Eq. 12 with respect to F is equivalent to finding (for all \u03b1)\nargmax f\u03b1\n\u2211\nk\n[\nf\u03b1(x k, yk\u03b1)\u2212 \u01eb log\n\u2211\ny\u03b1\nexp\n(\n1 \u01eb f\u03b1(x, y\u03b1) + b k \u03b1(y\u03b1)\n)\n]\n= argmax f\u03b1\n\u2211\nk\n[\n1 \u01eb f\u03b1(x k, yk\u03b1)\u2212 log \u2211\ny\u03b1\nexp\n(\n1 \u01eb f(xk, y\u03b1) + b k \u03b1(y\u03b1)\n)\n]\nObserving that adding a bias term doesn\u2019t change the maximizing f\u03b1, and using the fact that argmax g(1\n\u01eb \u00b7) = \u01eb argmax g(\u00b7) gives the result.\nThe final learning algorithm is summarized as Alg. 1. Sometimes, the local classifier f\u03b1 will depend on the input x only through some \u201clocal features\u201d \u03c6\u03b1. The above framework accomodates this situation if the set F\u03b1 is considered to select these local features.\nIn practice, one will often wish to constrain that some of the functions f\u03b1 are the same. This is done by taking the sum in Eq. 13 not just over all data k, but also over all factors \u03b1 that should be so constrained. For example, it is common to model image segmentation problems using a 4-connected grid with an energy like F (x, y) = \u2211\ni u(\u03c6i, yi) +\u2211 ij v(\u03c6ij , yi, yj), where \u03c6i/\u03c6ij are univariate/pairwise features determined by x, and u and v are functions mapping local features to local energies. In this case, u would be selected to max-\nimize \u2211\nk\n\u2211\ni\n[\n(\nu(\u03c6ki , y k i ) + b k i (y k i ) ) \u2212 log \u2211 yi exp ( u(\u03c6ki , yi) + b k i (yi) )\n]\n, and analogous expres-\nsion exists for v. This is the framework used in the following experiments."}, {"heading": "8 Experiments", "text": "These experiments consider three different function classes: linear, boosted decision trees, and multi-layer perceptrons. To maximize Eq. 11 under linear functions f(x, y) = (Wx)y , we simply compute the gradient with respect to W and use batch L-BFGS. For a multi-layer perceptron, we fit the function f(x, y) = (W\u03c3(Ux))y using stochastic gradient descent with momentum2 on mini-batches of size 1000, using a step size of .25 for univariate classifiers and .05 for pairwise. Boosted decision trees use stochastic gradient boosting [7]: the gradient of the logistic loss is computed for each exemplar, and a regression tree is induced to fit this (one tree for each class). To control overfitting, each leaf node must contain at least 5% of the data. Then, an optimization adjusts the values of leaf nodes to optimize the logistic loss. Finally, the tree values are multiplied by\n2At each time, the new step is a combination of .1 times the new gradient plus .9 times the old step.\n.25 and added to the ensemble. For reference, we also consider the \u201czero\u201d classifier, and a \u201cconstant\u201d classifier that ignores the input\u2013 equivalent to a linear classifier with a single constant feature.\nAll examples use \u01eb = 0.1. Each learning iteration consists of updating fi, performing 25 iterations of message passing, updating fij , and then performing another 25 iterations of message-passing.\nThe first dataset is a synthetic binary denoising dataset, intended for the purpose of visualization. To create an example, an image is generated with each pixel random in [0, 1]. To generate y, this image is convolved with a Gaussian with standard deviation 10 and rounded to {0, 1}. Next, if yi = 0, \u03c6ki is sampled uniformly from [0, .9], while if yki = 1, \u03c6 k i is sampled from [.1, 1]. Finally, for a pair (i, j), if yki = y k j , then \u03c6 k ij is sampled from [0, .8] while if y k i 6= y k j \u03c6ij is sampled from [.2, 1]. A constant feature is also added to both \u03c6ki and \u03c6 k ij .\nThere are 16 100\u00d7 100 images each training and testing. Test errors for each classifier combination are in Table 1, learning curves are in Fig. 2, and example results in Fig. 3. The nonlinear classifiers result in both lower asymptotic training and testing errors and faster convergence rates. Boosting converges particularly quickly. Finally, because there is only a single input feature for univariate and pairwise terms, the resulting functions are plotted in Fig. 1.\nSecond, as a more realistic example, we use the Weizmann horses dataset. We use 42 univariate features fki consisting of a constant (1) the RBG values of the pixel (3), the vertical and horizontal position (2) and a histogram of gradients [2] (36). There are three edge features, consisting of a constant, the l2 distance of the RBG vectors for the two pixels, and the output of a Sobel edge filter. Results are show in Table 1 and Figures 2 and 3. Again, we see benefits in using nonlinear classifiers, both in convergence rate and asymptotic error."}, {"heading": "9 Discussion", "text": "This paper observes that in the structured learning setting, the optimization with respect to energy can be formulated as a logistic regression problem for each factor, \u201cbiased\u201d by the current messages. Thus, it is possible to use any function class where an \u201coracle\u201d exists to optimize a logistic loss. Besides the possibility of using more general classes of energies, another advantage of the proposed method is the \u201csoftware engineering\u201d benefit of having the algorithm for fitting the energy modularized from the rest of the learning procedure. The ability to easily define new energy functions for individual problems could have practical impact.\nFuture work could consider convergence rates of the overall learning optimization, systematically investigate the choice of \u01eb, or consider more general entropy approximations, such as the Bethe approximation used with loopy belief propagation.\nIn related work, Hazan and Urtasun [9] use a linear energy, and alternate between updating all inference variables and a gradient descent update to parameters, using an entropy-smoothed inference objective. Meshi et al. [16] also use a linear energy, with a stochastic algorithm updating inference variables and taking a stochastic gradient step on parameters for one exemplar at a time, with a pure LP-relaxation of inference. The proposed method iterates between updating all inference variables and performing a full optimization of the energy. This is a \u201cbatch\u201d algorithm in the sense of making repeated passes over the data, and so is expected to be slower than an online method for large datasets. In practice, however, inference is easily parallelized over the data, and the majority of computational time is spent in the logistic regression subproblems. A stochastic solver can easily be used for these, as was done for MLPs above, giving a partially stochastic learning method.\nAnother related work is Gradient Tree Boosting [4] in which to train a CRF, the functional gradient of the conditional likelihood is computed, and a regression tree is induced. This is iterated to produce an ensemble. The main limitation is the assumption that inference can be solved exactly. It appears possible to extend this to inexact inference, where the tree is induced to improve a dual bound, but this has not been done so far. Experimentally, however, simply inducing a tree on the loss gradient leads to much slower learning if the leaf nodes are not modified to optimize the logistic loss. Thus, it is likely that such a strategy would still benefit from using the logistic regression reformulation."}, {"heading": "Appendix for paper: Structured Learning via Logistic Regression", "text": "Theorem 5. The difference of l and l1 is bounded by\nl1(x, y, F ) \u2264 l(x, y, F ) \u2264 l1(x, y, F ) + \u01ebHmax, Hmax = \u2211\n\u03b1\nlog |y\u03b1|.\nProof. Defining \u00b5\u2217 = argmax\u00b5\u2208M \u03b8 \u00b7\u00b5 and \u00b5\u2032 = argmax\u00b5\u2208M \u03b8 \u00b7\u00b5+ \u01eb \u2211 \u03b1 H(\u00b5\u03b1), one can write\nl(x, y;F )\u2212 l1(x, y;F ) = \u2212F (x, y) + max \u00b5\u2208M\n(\n\u03b8 \u00b7 \u00b5+ \u2211\n\u03b1\n\u01ebH(\u00b5\u03b1)\n)\n+ F (x, y)\u2212 max \u00b5\u2208M \u03b8 \u00b7 \u00b5\n= max \u00b5\u2208M\n(\n\u03b8 \u00b7 \u00b5+ \u2211\n\u03b1\n\u01ebH(\u00b5\u03b1)\n)\n\u2212 max \u00b5\u2208M \u03b8 \u00b7 \u00b5\n= \u03b8 \u00b7 \u00b5\u2032 \u2212 \u03b8 \u00b7 \u00b5\u2217 + \u2211\n\u03b1\n\u01ebH(\u00b5\u2032\u03b1)\n\u2264 \u01eb \u2211\n\u03b1\nlog |y\u03b1|.\nThe last line follows from the fact that \u03b8 \u00b7 \u00b5\u2217 \u2265 \u03b8 \u00b7 \u00b5\u2032, and that H(\u00b5\u2032\u03b1) \u2264 log |y\u03b1|.\nZero Const Linear Boosting MLP Fij \\ Fi\nZero Const Linear Boosting MLP Fij \\ Fi\nZero Const Linear Boosting MLP Fij \\ Fi\nZero Const Linear Boosting MLP Fij \\ Fi\nZero Const Linear Boosting MLP Fij \\ Fi\nZero Const Linear Boosting MLP Fij \\ Fi\nZero Const Linear Boosting MLP Fij \\ Fi\nZero Const Linear Boosting MLP Fij \\ Fi\nZero Const Linear Boosting MLP Fij \\ Fi"}], "references": [{"title": "Convex Optimization", "author": ["Stephen Boyd", "Lieven Vandenberghe"], "venue": null, "citeRegEx": "1", "shortCiteRegEx": "1", "year": 2004}, {"title": "Histograms of oriented gradients for human detection", "author": ["N. Dalal", "B. Triggs"], "venue": "In CVPR,", "citeRegEx": "2", "shortCiteRegEx": "2", "year": 2005}, {"title": "Discriminative models for multi-class object layout", "author": ["Chaitanya Desai", "Deva Ramanan", "Charless C. Fowlkes"], "venue": "International Journal of Computer Vision,", "citeRegEx": "3", "shortCiteRegEx": "3", "year": 2011}, {"title": "Training conditional random fields via gradient tree boosting", "author": ["Thomas G. Dietterich", "Adam Ashenfelter", "Yaroslav Bulatov"], "venue": "In ICML,", "citeRegEx": "4", "shortCiteRegEx": "4", "year": 2004}, {"title": "Learning graphical model parameters with approximate marginal inference", "author": ["Justin Domke"], "venue": "PAMI, 35(10):2454\u20132467,", "citeRegEx": "5", "shortCiteRegEx": "5", "year": 2013}, {"title": "Training structural svms when exact inference is intractable", "author": ["Thomas Finley", "Thorsten Joachims"], "venue": "In ICML,", "citeRegEx": "6", "shortCiteRegEx": "6", "year": 2008}, {"title": "Stochastic gradient boosting", "author": ["Jerome H. Friedman"], "venue": "Computational Statistics and Data Analysis,", "citeRegEx": "7", "shortCiteRegEx": "7", "year": 1999}, {"title": "Multi-class segmentation with relative location", "author": ["Stephen Gould", "Jim Rodgers", "David Cohen", "Gal Elidan", "Daphne Koller"], "venue": "prior. IJCV,", "citeRegEx": "8", "shortCiteRegEx": "8", "year": 2008}, {"title": "Efficient learning of structured predictors in general graphical models", "author": ["Tamir Hazan", "Raquel Urtasun"], "venue": "CoRR, abs/1210.2346,", "citeRegEx": "9", "shortCiteRegEx": "9", "year": 2012}, {"title": "Multiscale conditional random fields for image labeling", "author": ["Xuming He", "Richard S. Zemel", "Miguel \u00c1. Carreira-Perpi\u00f1\u00e1n"], "venue": "In CVPR,", "citeRegEx": "10", "shortCiteRegEx": "10", "year": 2004}, {"title": "Convexity arguments for efficient minimization of the bethe and kikuchi free energies", "author": ["Tom Heskes"], "venue": "J. Artif. Intell. Res. (JAIR),", "citeRegEx": "11", "shortCiteRegEx": "11", "year": 2006}, {"title": "Discriminative fields for modeling spatial dependencies in natural images", "author": ["Sanjiv Kumar", "Martial Hebert"], "venue": "In NIPS,", "citeRegEx": "12", "shortCiteRegEx": "12", "year": 2003}, {"title": "Associative hierarchical CRFs for object class image segmentation", "author": ["Lubor Ladicky", "Christopher Russell", "Pushmeet Kohli", "Philip H.S. Torr"], "venue": "In ICCV,", "citeRegEx": "13", "shortCiteRegEx": "13", "year": 2009}, {"title": "Polyhedral outer approximations with application to natural language parsing", "author": ["Andr\u00e9 F.T. Martins", "Noah A. Smith", "Eric P. Xing"], "venue": "In ICML,", "citeRegEx": "14", "shortCiteRegEx": "14", "year": 2009}, {"title": "Convergence rate analysis of MAP coordinate minimization algorithms", "author": ["Ofer Meshi", "Tommi Jaakkola", "Amir Globerson"], "venue": "In NIPS", "citeRegEx": "15", "shortCiteRegEx": "15", "year": 2012}, {"title": "Learning efficiently with approximate inference via dual losses", "author": ["Ofer Meshi", "David Sontag", "Tommi Jaakkola", "Amir Globerson"], "venue": "In ICML,", "citeRegEx": "16", "shortCiteRegEx": "16", "year": 2010}, {"title": "On parameter learning in CRF-based approaches to object class image segmentation", "author": ["Sebastian Nowozin", "Peter V. Gehler", "Christoph H. Lampert"], "venue": "In ECCV,", "citeRegEx": "17", "shortCiteRegEx": "17", "year": 2010}, {"title": "Decision tree fields", "author": ["Sebastian Nowozin", "Carsten Rother", "Shai Bagon", "Toby Sharp", "Bangpeng Yao", "Pushmeet Kohli"], "venue": "In ICCV,", "citeRegEx": "18", "shortCiteRegEx": "18", "year": 2011}, {"title": "Object class segmentation using random forests", "author": ["Florian Schroff", "Antonio Criminisi", "Andrew Zisserman"], "venue": "In BMVC,", "citeRegEx": "19", "shortCiteRegEx": "19", "year": 2008}, {"title": "Textonboost for image understanding: Multi-class object recognition and segmentation by jointly modeling texture", "author": ["Jamie Shotton", "John M. Winn", "Carsten Rother", "Antonio Criminisi"], "venue": "layout, and context. IJCV,", "citeRegEx": "20", "shortCiteRegEx": "20", "year": 2009}, {"title": "Indoor scene segmentation using a structured light sensor", "author": ["Nathan Silberman", "Rob Fergus"], "venue": "In ICCV Workshops,", "citeRegEx": "21", "shortCiteRegEx": "21", "year": 2011}, {"title": "Max-margin markov networks", "author": ["Benjamin Taskar", "Carlos Guestrin", "Daphne Koller"], "venue": "In NIPS,", "citeRegEx": "22", "shortCiteRegEx": "22", "year": 2003}, {"title": "Scene segmentation with crfs learned from partially labeled images", "author": ["Jakob J. Verbeek", "Bill Triggs"], "venue": "In NIPS,", "citeRegEx": "23", "shortCiteRegEx": "23", "year": 2007}, {"title": "The layout consistent random field for recognizing and segmenting partially occluded objects", "author": ["John M. Winn", "Jamie Shotton"], "venue": "In CVPR,", "citeRegEx": "24", "shortCiteRegEx": "24", "year": 2006}], "referenceMentions": [{"referenceID": 15, "context": ", by alternating message-passing updates to inference variables with gradient descent updates to parameters [16, 9].", "startOffset": 108, "endOffset": 115}, {"referenceID": 8, "context": ", by alternating message-passing updates to inference variables with gradient descent updates to parameters [16, 9].", "startOffset": 108, "endOffset": 115}, {"referenceID": 22, "context": "While linear weights are often useful in practice [23, 16, 9, 3, 17, 12, 5], it is also common to make use of non-linear classifiers.", "startOffset": 50, "endOffset": 75}, {"referenceID": 15, "context": "While linear weights are often useful in practice [23, 16, 9, 3, 17, 12, 5], it is also common to make use of non-linear classifiers.", "startOffset": 50, "endOffset": 75}, {"referenceID": 8, "context": "While linear weights are often useful in practice [23, 16, 9, 3, 17, 12, 5], it is also common to make use of non-linear classifiers.", "startOffset": 50, "endOffset": 75}, {"referenceID": 2, "context": "While linear weights are often useful in practice [23, 16, 9, 3, 17, 12, 5], it is also common to make use of non-linear classifiers.", "startOffset": 50, "endOffset": 75}, {"referenceID": 16, "context": "While linear weights are often useful in practice [23, 16, 9, 3, 17, 12, 5], it is also common to make use of non-linear classifiers.", "startOffset": 50, "endOffset": 75}, {"referenceID": 11, "context": "While linear weights are often useful in practice [23, 16, 9, 3, 17, 12, 5], it is also common to make use of non-linear classifiers.", "startOffset": 50, "endOffset": 75}, {"referenceID": 4, "context": "While linear weights are often useful in practice [23, 16, 9, 3, 17, 12, 5], it is also common to make use of non-linear classifiers.", "startOffset": 50, "endOffset": 75}, {"referenceID": 19, "context": "ensembles of trees [20, 8, 25, 13, 24, 18, 19] or multi-layer perceptrons [10, 21]) to predict each variable independently.", "startOffset": 19, "endOffset": 46}, {"referenceID": 7, "context": "ensembles of trees [20, 8, 25, 13, 24, 18, 19] or multi-layer perceptrons [10, 21]) to predict each variable independently.", "startOffset": 19, "endOffset": 46}, {"referenceID": 12, "context": "ensembles of trees [20, 8, 25, 13, 24, 18, 19] or multi-layer perceptrons [10, 21]) to predict each variable independently.", "startOffset": 19, "endOffset": 46}, {"referenceID": 23, "context": "ensembles of trees [20, 8, 25, 13, 24, 18, 19] or multi-layer perceptrons [10, 21]) to predict each variable independently.", "startOffset": 19, "endOffset": 46}, {"referenceID": 17, "context": "ensembles of trees [20, 8, 25, 13, 24, 18, 19] or multi-layer perceptrons [10, 21]) to predict each variable independently.", "startOffset": 19, "endOffset": 46}, {"referenceID": 18, "context": "ensembles of trees [20, 8, 25, 13, 24, 18, 19] or multi-layer perceptrons [10, 21]) to predict each variable independently.", "startOffset": 19, "endOffset": 46}, {"referenceID": 9, "context": "ensembles of trees [20, 8, 25, 13, 24, 18, 19] or multi-layer perceptrons [10, 21]) to predict each variable independently.", "startOffset": 74, "endOffset": 82}, {"referenceID": 20, "context": "ensembles of trees [20, 8, 25, 13, 24, 18, 19] or multi-layer perceptrons [10, 21]) to predict each variable independently.", "startOffset": 74, "endOffset": 82}, {"referenceID": 19, "context": "Linear edge interaction weights are then learned, with unary classifiers either held fixed [20, 8, 25, 13, 24, 10] or used essentially as \u201cfeatures\u201d with linear weights readjusted [18].", "startOffset": 91, "endOffset": 114}, {"referenceID": 7, "context": "Linear edge interaction weights are then learned, with unary classifiers either held fixed [20, 8, 25, 13, 24, 10] or used essentially as \u201cfeatures\u201d with linear weights readjusted [18].", "startOffset": 91, "endOffset": 114}, {"referenceID": 12, "context": "Linear edge interaction weights are then learned, with unary classifiers either held fixed [20, 8, 25, 13, 24, 10] or used essentially as \u201cfeatures\u201d with linear weights readjusted [18].", "startOffset": 91, "endOffset": 114}, {"referenceID": 23, "context": "Linear edge interaction weights are then learned, with unary classifiers either held fixed [20, 8, 25, 13, 24, 10] or used essentially as \u201cfeatures\u201d with linear weights readjusted [18].", "startOffset": 91, "endOffset": 114}, {"referenceID": 9, "context": "Linear edge interaction weights are then learned, with unary classifiers either held fixed [20, 8, 25, 13, 24, 10] or used essentially as \u201cfeatures\u201d with linear weights readjusted [18].", "startOffset": 91, "endOffset": 114}, {"referenceID": 17, "context": "Linear edge interaction weights are then learned, with unary classifiers either held fixed [20, 8, 25, 13, 24, 10] or used essentially as \u201cfeatures\u201d with linear weights readjusted [18].", "startOffset": 180, "endOffset": 184}, {"referenceID": 14, "context": "Here, following previous work [15], we add entropy smoothing to the LP-relaxation of the inference problem.", "startOffset": 30, "endOffset": 34}, {"referenceID": 21, "context": "Absent computational concerns, a standard choice would be the slackrescaled loss [22] l0(x , y;F ) = max y F (x, y)\u2212 F (x, y) + \u2206(y, y), (3) where \u2206(y, y) is some measure of discrepancy.", "startOffset": 81, "endOffset": 85}, {"referenceID": 5, "context": "If this inference problem must be solved approximately, there is strong motivation [6] for using relaxations of the maximization in Eq.", "startOffset": 83, "endOffset": 86}, {"referenceID": 15, "context": "A common solution [16, 14, 6] is to use a linear relaxation1 l1(x , y;F ) = max \u03bc\u2208M F (x, \u03bc)\u2212 F (x, y) + \u2206(y, \u03bc), (4) where the local polytope M is defined as the set of local pseudomarginals that are normalized, and agree when marginalized over other neighboring regions, M = {\u03bc|\u03bc\u03b1\u03b2(y\u03b2) = \u03bc\u03b2(y\u03b2)\u2200\u03b2 \u2282 \u03b1, \u2211", "startOffset": 18, "endOffset": 29}, {"referenceID": 13, "context": "A common solution [16, 14, 6] is to use a linear relaxation1 l1(x , y;F ) = max \u03bc\u2208M F (x, \u03bc)\u2212 F (x, y) + \u2206(y, \u03bc), (4) where the local polytope M is defined as the set of local pseudomarginals that are normalized, and agree when marginalized over other neighboring regions, M = {\u03bc|\u03bc\u03b1\u03b2(y\u03b2) = \u03bc\u03b2(y\u03b2)\u2200\u03b2 \u2282 \u03b1, \u2211", "startOffset": 18, "endOffset": 29}, {"referenceID": 5, "context": "A common solution [16, 14, 6] is to use a linear relaxation1 l1(x , y;F ) = max \u03bc\u2208M F (x, \u03bc)\u2212 F (x, y) + \u2206(y, \u03bc), (4) where the local polytope M is defined as the set of local pseudomarginals that are normalized, and agree when marginalized over other neighboring regions, M = {\u03bc|\u03bc\u03b1\u03b2(y\u03b2) = \u03bc\u03b2(y\u03b2)\u2200\u03b2 \u2282 \u03b1, \u2211", "startOffset": 18, "endOffset": 29}, {"referenceID": 5, "context": "It is easy to show that l1 \u2265 l0, since the two would be equivalent if \u03bc were restricted to binary values, and hence the maximization in l1 takes place over a larger set [6].", "startOffset": 169, "endOffset": 172}, {"referenceID": 14, "context": "[15] who show that local message-passing can have a guaranteed convergence rate, and by Hazan and Urtasun [9] who use it for learning.", "startOffset": 0, "endOffset": 4}, {"referenceID": 8, "context": "[15] who show that local message-passing can have a guaranteed convergence rate, and by Hazan and Urtasun [9] who use it for learning.", "startOffset": 106, "endOffset": 109}, {"referenceID": 14, "context": "A similar result was previously given [15] bounding the difference of the objective obtained by inference with and without entropy smoothing.", "startOffset": 38, "endOffset": 42}, {"referenceID": 15, "context": "Inspired by previous work [16, 9], our solution (Section 5) is to introduce a vector of \u201cmessages\u201d \u03bb to write A in the dual form A(\u03b8) = min \u03bb A(\u03bb, \u03b8), which leads to phrasing learning as the joint minimization min F min {\u03bbk} \u2211", "startOffset": 26, "endOffset": 33}, {"referenceID": 8, "context": "Inspired by previous work [16, 9], our solution (Section 5) is to introduce a vector of \u201cmessages\u201d \u03bb to write A in the dual form A(\u03b8) = min \u03bb A(\u03bb, \u03b8), which leads to phrasing learning as the joint minimization min F min {\u03bbk} \u2211", "startOffset": 26, "endOffset": 33}, {"referenceID": 10, "context": "Standard Lagrangian duality theory gives the following dual representation for A(\u03b8) in terms of \u201cmessages\u201d \u03bb\u03b1(x\u03b2) from a region \u03b1 to a subregion \u03b2 \u2282 \u03b1, a variant of the representation of Heskes [11].", "startOffset": 194, "endOffset": 198}, {"referenceID": 10, "context": "It can be shown [11, 15] that the update is \u03bb\u03b1(y\u03bd) \u2190 \u03bb\u03b1(y\u03bd) + \u01eb 1 +N\u03bd (log\u03bc\u03bd(y\u03bd) + \u2211", "startOffset": 16, "endOffset": 24}, {"referenceID": 14, "context": "It can be shown [11, 15] that the update is \u03bb\u03b1(y\u03bd) \u2190 \u03bb\u03b1(y\u03bd) + \u01eb 1 +N\u03bd (log\u03bc\u03bd(y\u03bd) + \u2211", "startOffset": 16, "endOffset": 24}, {"referenceID": 14, "context": "[15] show that with greedy or randomized selection of blocks to update, O( \u03b4 ) iterations are sufficient to converge within error \u03b4.", "startOffset": 0, "endOffset": 4}, {"referenceID": 6, "context": "Boosted decision trees use stochastic gradient boosting [7]: the gradient of the logistic loss is computed for each exemplar, and a regression tree is induced to fit this (one tree for each class).", "startOffset": 56, "endOffset": 59}], "year": 2014, "abstractText": "A successful approach to structured learning is to write the learning objective as a joint function of linear parameters and inference messages, and iterate between updates to each. This paper observes that if the inference problem is \u201csmoothed\u201d through the addition of entropy terms, for fixed messages, the learning objective reduces to a traditional (non-structured) logistic regression problem with respect to parameters. In these logistic regression problems, each training example has a bias term determined by the current set of messages. Based on this insight, the structured energy function can be extended from linear factors to any function class where an \u201coracle\u201d exists to minimize a logistic loss.", "creator": "LaTeX with hyperref package"}}}