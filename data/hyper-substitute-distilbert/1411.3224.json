{"id": "1411.3224", "review": {"conference": "ICML", "VERSION": "v1", "DATE_OF_SUBMISSION": "12-Nov-2014", "title": "On TD(0) with function approximation: Concentration bounds and a centered variant with exponential convergence", "abstract": "\u2022 provide non - standard bounds for the well - settled expectation error estimates policy td ( 0 ) with linear function feedback. these include size - loss bounds, h exceed bounds linear complexity. similar observation suggests precisely applying step - size inversely scaled sequence the price of rows cannot guarantee extreme avoidance of convergence unless we assume knowledge of the mixing theory for the markov strategy underlying the policy considered. this problem additionally alleviated considerably employing the further - known schneider - ruppert averaging scheme, as unto optimal rate gibbs convergence abandoning any necessity of infinite mixing rate. furthermore, we propose a domain of \u03b8 ( 0 ) with exponential approximators strongly incorporates a centering relation, thus ourselves establish that it exhibits an acceptable rate of convergence in expectation.", "histories": [["v1", "Wed, 12 Nov 2014 16:22:28 GMT  (24kb)", "https://arxiv.org/abs/1411.3224v1", null], ["v2", "Tue, 1 Sep 2015 18:20:52 GMT  (571kb)", "http://arxiv.org/abs/1411.3224v2", null]], "reviews": [], "SUBJECTS": "cs.LG math.OC stat.ML", "authors": ["nathaniel korda", "prashanth l a"], "accepted": true, "id": "1411.3224"}, "pdf": {"name": "1411.3224.pdf", "metadata": {"source": "CRF", "title": "On TD(0) with function approximation: Concentration bounds and a centered variant with exponential convergence", "authors": ["Nathaniel Korda", "Prashanth L.A"], "emails": ["nathaniel.korda@eng.ox.ac.uk", "prashla@isr.umd.edu"], "sections": [{"heading": null, "text": "ar X\niv :1\n41 1.\n32 24\nv2 [\ncs .L\nG ]\n1 S\n1 Introduction\nMany stochastic control problems can be cast within the framework of Markov decision processes (MDP). Reinforcement learning (RL) is a popular approach to solve MDPs, when the underlying transition mechanism is unknown. An important problem in RL is to estimate the value function V \u03c0 for a given stationary policy \u03c0. We focus on discounted reward MDPs with a high-dimensional state space S . In this setting, one can only hope to estimate the value function approximately and this constitutes the policy evaluation step in several approximate policy iteration methods, e.g. actor-critic algorithms [Konda and Tsitsiklis, 2003], [Bhatnagar et al., 2009].\nTemporal difference learning is a well-known policy evaluation algorithm that is both online and works with a single sample path obtained by simulating the underlying MDP. However, the classic TD(0) algorithm uses full-state representations (i.e. it stores an entry for each state s \u2208 S) and hence, suffers from the curse of dimensionality. A standard trick to alleviate this problem is to approximate the value function within a linearly parameterized space of functions, i.e., V \u03c0(s) \u2248 \u03b8T\u03c6(s). Here \u03b8 is a tunable parameter and \u03c6(s) is a column feature vector with dimension d << |S|. This approximation allows for efficient implementation of TD(0) even on large state spaces.\nThe update rule for TD(0) that incorporates linear function approximators is as follows: Starting with an arbitrary \u03b80,\n\u03b8n+1 = \u03b8n + \u03b3n ( r(sn, \u03c0(sn)) + \u03b2\u03b8 T n\u03c6(sn+1)\u2212 \u03b8Tn\u03c6(sn) ) \u03c6(sn). (1)\n\u2217nathaniel.korda@eng.ox.ac.uk \u2020prashla@isr.umd.edu\nIn the above, the quantities \u03b3n are step sizes, chosen in advance ,and satisfying standard stochastic approximation conditions (see assumption (A5)). Further, r(s, a) is the reward recieved in state s on choosing action a, \u03b2 \u2208 (0, 1) is a discount factor, and sn is the state of the MDP at time n.\nAsymptotic convergence of TD(0). In [Tsitsiklis and Van Roy, 1997], the authors establish that \u03b8n governed by (1) converges almost surely to the fixed point, \u03b8\u2217, of the projected Bellman equation given by\n\u03a6\u03b8\u2217 = \u03a0T \u03c0(\u03a6\u03b8\u2217). (2)\nIn the above, T \u03c0 is the Bellman operator, \u03a0 is the orthogonal projection onto the linearly parameterized space within which we approximate the value function, and \u03a6 is the feature matrix with rows \u03c6(s)T,\u2200s \u2208 S denoting the features corresponding to state s \u2208 S (see Section 2 for more details). Let P denote the transition probability matrix with components p(s, \u03c0(s), s\u2032) that denote the probability of transitioning from state s to s\u2032 under the action \u03c0(s). Let r be a vector with components r(s, \u03c0(s)), and \u03a8 be a diagonal matrix whose diagonal forms the stationary distribution (assuming it exists) of the Markov chain for the underlying policy \u03c0. Then, \u03b8\u2217 can be written as the solution to the following system of equations (see Section 6.3 of [Bertsekas, 2011])\nA\u03b8\u2217 = b, where A = \u03a6T\u03a8(I \u2212 \u03b2P )\u03a6 and b = \u03a6T\u03a8r. (3)\nOur work. We derive non-asymptotic bounds on \u2016\u03b8n \u2212 \u03b8\u2217\u20162, both in high-probability and in expectation, to quantify the rate of convergence of TD(0) with linear function approximators. To the best of our knowledge, there are no non-asymptotic bounds for TD(0) with function approximation, while there are asymptotic convergence and rate results available.\nFinite time analysis is challenging because: (1) The asymptotic limit \u03b8\u2217 is the fixed point of the Bellman operator, which assumes that the underlying MDP is begun from the stationary distribution \u03a8 (whose influence is evident in (3)). However, the samples provided to the algorithm come from simulations of the MDP that are not begun from \u03a8. This is a problem for a finite time analysis, since we do not know exactly the number of steps after which mixing of the underlying Markov chain has occurred, and the distribution of the samples that TD(0) sees has become the stationary distribution. Moreover, an assumption on this mixing rate amounts to assuming (partial) knowledge of the transition dynamics of the Markov chain underlying the policy \u03c0. (2) Standard results from stochastic approximation theory suggest that in order to obtain the optimal rate of convergence for a step size choice of \u03b3n = c/(c + n), one has to chose the constant c carefully. In the case of TD(0), we derive this condition and point out the optimal choice for c requires knowledge of the mixing rate of the underlying Markov chain for policy \u03c0. We handle the first problem by establishing that under a mixing assumption (the same as that used to establish asymptotic convergence for TD(0) in [Tsitsiklis and Van Roy, 1997]), the mixing error can be handled in the non-asymptotic bound. This assumption is broad enough to encompass a reasonable range of MDP problems. We alleviate the second problem by using iterate averaging.\nVariance reduction. One inherent problem with iterative schemes that use a single sample to update the iterate at each time step, is that of variance. This is the reason why it is necessary to carefully choose the step-size sequence: too large and the variance will force divergence; too small and the algorithm will converge, but not to the solution intended. Indeed, iterate averaging is a technique that aims to allow for larger step-sizes, while producing the same overall rate of convergence (and we show that it succeeds in eliminating the necessity to know properties of the stationary distribution of the underlying Markov chain). A more direct approach is to center the updates, and this was pioneered recently for solving batch problems via stochastic gradient descent in convex optimization [Johnson and Zhang, 2013]. We propose a variant of\nTD(0) that uses this approach, though our setting is considerably more complicated as samples arrive online and the function being optimized is not accessible directly.\nOur contributions can be summarized as follows: (1) Concentration bounds. Under assumptions similar to [Tsitsiklis and Van Roy, 1997], we provide nonasymptotic bounds, both in high probability as well as in expectation and these quantify the convergence rate of TD(0) with function approximation. (2) Centered TD. We propose a variant of TD(0) that incorporates a centering sequence and we show that it converges faster than the regular TD(0) algorithm in expectation.\nThe key insights from our finite-time analysis are: (1) Choosing \u03b3n = c0c(c+n) , with c0 < \u00b5(1 \u2212 \u03b2)/(2(1 + \u03b2)2) and c such that \u00b5(1 \u2212 \u03b2)c0c > 1, we obtain the optimal rate of convergence of the order O (1/ \u221a n), both in high-probability as well as in expectation. Here \u00b5 is the smallest eigenvalue of the matrix \u03a6T\u03a8\u03a6 (see Theorem 1). However, obtaining this rate is problematic as it implies (partial) knowledge (via \u00b5) of the transition dynamics of the MDP. (2) With iterate averaging, one can get rid of the step-size dependency and still obtain the optimal rate of convergence, both in high probability as well as in expectation (see Theorem 2). (3) For the centered variant of TD(0), we obtain an exponential convergence rate when the underlying Markov chain mixes fast (see Theorem 3). (4) We illustrate the usefulness of our bounds on two simple synthetic experimental setups. In particular, using the step-sizes suggested by our bounds in Theorems 1\u20133, we are able to establish convergence empirically for TD(0), and both its averaging, as well as centered variants.\nRelated work. Concentration bounds for general stochastic approximation schemes have been derived in [Frikha and Menozzi, 2012] and later expanded to include iterate averaging in [Fathi and Frikha, 2013]. Unlike the aforementioned reference, deriving convergence rate results for TD(0), especially of non-asymptotic nature, requires sophisticated machinery as it involves Markov noise that impacts the mixing rate of the underlying Markov chain. An asymptotic normality result for TD(\u03bb) is available in [Konda, 2002]. The authors establish there that TD(\u03bb) converges asymptotically to a multi-variate Gaussian distribution with a covariance matrix that depends on A (see (3)). This rate result holds true for TD(\u03bb) when combined with iterate averaging, while the non-averaged case does not result in the optimal rate of convergence. Our results are consistent with this observation, as we establish from a finite time analysis that the non-averaged TD(0) can result in optimal convergence only if the step-size constant c in \u03b3n = c/(c+n) is set carefully (as a function of a certain quantity that depends on the stationary distribution - see (A3) below), while one can get rid of this dependency and still obtain the optimal rate with iterate averaging. Least squares temporal difference methods are popular alternatives to the classic TD(\u03bb). Asymptotic convergence rate results for LSTD(\u03bb) and LSPE(\u03bb), two popular least squares methods, are available in [Konda, 2002] and [Yu and Bertsekas, 2009], respectively. However, to the best of our knowledge, there are no concentration bounds that quantify the rate of convergence through a finite time analysis. A related work in this direction is the finite time bounds for LSTD in [Lazaric et al., 2010]. However, the analysis there is under a fast mixing rate assumption, while we provide non-asymptotic rate results without making any such assumption. We note here that assuming a mixing rate implies partial knowledge of the transition dynamics of the MDP under a stationary policy and in typical RL settings, this information is not available.\n2 TD(0) with Linear Approximation\nWe consider an MDP with state space S and action space A. The aim is to estimate the value function V \u03c0 for any given stationary policy \u03c0 : S \u2192 A, where\nV \u03c0(s) := E\n[\n\u221e \u2211\nt=0\n\u03b2tr(st, \u03c0(st)) | s0 = s ] . (4)\nRecall that \u03b2 \u2208 (0, 1) is the discount factor, st denotes the state of the MDP at time t, and r(s, a) denotes the reward obtained in state s under action a. The expectation in (4) is taken with respect to the transition dynamics P . It is well-known that V \u03c0 is the solution to the fixed point relation V = T \u03c0(V ), where the Bellman operator T \u03c0 is defined as\nT \u03c0(V )(s) := r(s, \u03c0(s)) + \u03b2 \u2211\ns\u2032\np(s, \u03c0(s), s\u2032)V (s\u2032), (5)\nTD(0) [Sutton and Barto, 1998] performs a fixed point-iteration using stochastic approximation: Starting with an arbitrary V0, update\nVn(sn) := Vn\u22121(sn) + \u03b3n ( r(sn, \u03c0(sn)) + \u03b2Vn\u22121(sn+1)\u2212 Vn\u22121(sn) ) , (6)\nwhere \u03b3n are step-sizes that satisfy standard stochastic approximation conditions. As discussed in the introduction, while TD(0) algorithm is simple and provably convergent to the fixed point of T \u03c0 for any policy, it suffers from the curse of dimensionality associated with high-dimensional state spaces, and popular method to allieviate this is to parameterize the value function using a linear function approximator, i.e. for every s \u2208 S , approximate V \u03c0(s) \u2248 \u03c6(s)T\u03b8. Here \u03c6(s) is a d-dimensional feature vector with d << |S|, and \u03b8 is a tunable parameter. Incorporating function approximation, an update rule for TD(0) analogous to (6) is given in (1).\n3 Concentration bounds for TD(0)\n3.1 Assumptions\n(A1) Ergodicity: The Markov chain induced by the policy \u03c0 is irreducible and aperiodic. Moreover, there exists a stationary distribution \u03a8(= \u03a8\u03c0) for this Markov chain. Let E\u03a8 denote the expectation w.r.t. this distribution.\n(A2) Bounded rewards: |r(s, \u03c0(s))| \u2264 1, for all s \u2208 S .\n(A3) Linear independence: The feature matrix \u03a6 has full column rank. This assumption implies that the matrix \u03a6T\u03a8\u03a6 has smallest eigenvalue \u00b5 > 0.\n(A4) Bounded features: \u2016\u03c6(s)\u20162 \u2264 1, for all s \u2208 S .\n(A5) The step sizes satisfy \u2211 n \u03b3n = \u221e, and \u2211 n \u03b3 2 n < \u221e.\n(A6) Combined step size and mixing assumption: There exists a non-negative function B\u2032(\u00b7) such that: For all s \u2208 S and m \u2265 0,\n\u221e \u2211\n\u03c4=0\ne3(1+\u03b2) \u2211\u03c4\u22121 j=1 \u03b3\u03c4 \u2016E(r(s\u03c4 , \u03c0(s\u03c4 ))\u03c6(s\u03c4 ) | s0 = s)\u2212 E\u03a8(r(s\u03c4 , \u03c0(s\u03c4 ))\u03c6(s\u03c4 ))\u2016 \u2264 B\u2032(s),\n\u221e \u2211\n\u03c4=0\ne3(1+\u03b2) \u2211\u03c4\u22121 j=1 \u03b3\u03c4 \u2016E(\u03c6(s\u03c4 )\u03c6(s\u03c4+m)T | s0 = s)\u2212 E\u03a8(\u03c6(s\u03c4 )\u03c6(s\u03c4+m)T)\u2016 \u2264 B\u2032(s),\n(A6\u2019) Uniform mixing bound: (A6) holds, and there exists a constant B\u2032 that is an uniformly bound on B(s),\u2200s \u2208 S .\nIn comparison to the assumptions in [Tsitsiklis and Van Roy, 1997], (A1), (A3), (A5) have exact counterparts in [Tsitsiklis and Van Roy, 1997], while (A2), (A4) and (A6) are simplified versions of the corresponding boundedness assumptions in [Tsitsiklis and Van Roy, 1997].\nRemark 1. (Geometric ergodicity) A Markov chain is mixing at a geometric rate if\nP (st = s | s0)\u2212 \u03c8(s)| \u2264 C\u03c1t. (7) For finite state space settings, the above condition holds and hence (A6) is easily satisfied. Moreover, B\u2032 = \u0398 ( 1/(1 \u2212 (1\u2212 \u03c1)1\u2212\u01eb )\n, for any \u01eb > 0. Here \u03c1 is an unknown quantity that relates to the second eigenvalue of the transition probability matrix. See Chapters 15 and 16 of [Meyn and Tweedie, 2009] for a detailed treatment of the subject matter.\n3.2 Non-averaged case\nTheorem 1. Under (A1)-(A6), choosing \u03b3n = c0c(c+n) , with c0 < \u00b5(1 \u2212 \u03b2)/(2(1 + \u03b2)2) and c such that \u00b5(1\u2212 \u03b2)c0c > 1, we have,\nE \u2016\u03b8n \u2212 \u03b8\u2217\u20162 \u2264 K1(n)\u221a n+ c .\nIn addition, assuming (A6\u2019), we have. for any \u03b4 > 0,\nP\n(\n\u2016\u03b8n \u2212 \u03b8\u2217\u20162 \u2264 K2(n)\u221a n+ c\n)\n\u2265 1\u2212 \u03b4, where\nK1(n) :=\n(\nc(\u2016\u03b80 \u2212 \u03b8\u2217\u20162 + C) (n + c)\u00b5(1\u2212\u03b2)c0c\u22121 + (1 + \u2016\u03b8\u2217\u20162)c20c2 + Cc0c \u00b5(1\u2212 \u03b2)c0c\u2212 1\n) 1 2\n,\nK2(n) := c0cB\n\u2032 (2 [2 + c0c] [1 + \u03b2(3\u2212 \u03b2)] ln(1/\u03b4)) 1 2\n(\u00b5(1\u2212 \u03b2)c0c\u2212 1) 1 2\n+K1(n),\nC := 6dB(s0) (\u2016\u03b80\u20162 + d+ \u2016\u03b8\u2217\u20162 1\u2212 \u03b2 )2 .\nProof. See Section 5.1.\nRemark 2. K1(n) and K2(n) above are O(1), i.e., they can be upper bounded by a constant. Thus, one can indeed get the optimal rate of convergence of the order O (1/ \u221a n) with a step-size \u03b3n = c(c+n) . However, this rate is contingent upon on the constant c in the step-size being chosen correctly. This is problematic because the right choice of c requires the knowledge of eigenvalue \u00b5 for expectation bound and and knowing \u00b5 would imply knowledge about the transition probability matrix of the underlying Markov chain. The latter information is unavailable in a typical RL setting. The next section derives bounds for the iterate averaged variant that overcomes this problematic step-size dependency.\n3.3 Iterate Averaging\nThe idea here is to employ larger step-sizes and combine it with averaging of the iterates, i.e., \u03b8\u0304n+1 := (\u03b81 + . . . + \u03b8n)/n. This principle was introduced independently by Ruppert [Ruppert, 1991] and Polyak [Polyak and Juditsky, 1992], for accelerating stochastic approximation schemes. The following theorem establishes that iterate averaging results in the optimal rate of convergence without any step-size dependency:\nTheorem 2. Under (A1)-(A6), choosing \u03b3n = c0 ( c c+n )\u03b1 , with \u03b1 \u2208 (1/2, 1) and c \u2208 (0,\u221e), we have, for all n > n0 := (c\u00b5(1\u2212 \u03b2)/(2c0(1 + \u03b2)2))\u22121/\u03b1,\nE \u2225 \u2225\u03b8\u0304n \u2212 \u03b8\u2217 \u2225 \u2225 2 \u2264 K\nIA 1 (n)\n(n+ c)\u03b1/2 .\nIn addition, assuming (A6)\u2019, we have, for any \u03b4 > 0,\nP\n(\n\u2225 \u2225\u03b8\u0304n \u2212 \u03b8\u2217 \u2225 \u2225 2 \u2264 K\nIA 2 (n)\n(n+ c)\u03b1/2\n)\n\u2265 1\u2212 \u03b4,\nwhere\nKIA1 (n) := ((1 + dc0c\n\u03b1(c+ n0) 1\u2212\u03b1)e(1+\u03b2)c0c \u03b1(c+n0)1\u2212\u03b1) + \u2016\u03b8\u2217\u2016+ C)C \u2032\u2032 (n+ c)(1\u2212\u03b1)/2\n+ n0\n[\n(1 + dc0c \u03b1(c+ n0) 1\u2212\u03b1)e(1+\u03b2)c0c \u03b1(c+n0)1\u2212\u03b1) + \u2016\u03b8\u2217\u2016\n]\nn1\u2212\u03b1/2\n+ c\u03b1c0\n[\n1 + \u2016\u03b8\u2217\u2016 1 2 2 +\n(\nC\nc\u03b1c0\n) 1 2\n]\n(\n\u00b5(1\u2212 \u03b2)c0c\u03b1 1\u2212 \u03b1\n)\u2212 \u03b1+2\u03b1 2\n2(1\u2212\u03b1)\n,\nKIA2 (n) := 4 \u221a (1 + C \u2032)B\u2032 \u00b5(1\u2212 \u03b2) C \u2032\u2032\u2032 n(1\u2212\u03b1)/2 + KIA1 (n\u2212 n0),\nC \u2032 :=\n(\n3\u03b1 +\n[\n4\u03b1\n\u00b5(1\u2212 \u03b2)c0c\u03b1 +\n2\u03b1\n\u03b1\n]2 ) 1 2\n, C \u2032\u2032 :=\n\u221e \u2211\nk=1\nk\u22122\u03b1, and\nC \u2032\u2032\u2032 :=\n\u221e \u2211\nk=1\ne \u2212\n\u00b5c\u03b1(1\u2212\u03b2)c0 2(1\u2212\u03b1)\n((n+c)1\u2212\u03b1\u2212((c+n0)1\u2212\u03b1).\nProof. See Section 5.2.\nRemark 3. The step-size exponent \u03b1 can be chosen arbitrarily close to 1, resulting in a convergence rate of the order O (1/ \u221a n). However although the constants KIA1 (n) and K IA 2 (n) remain O(1), there is a minor tradeoff here since a choice of \u03b1 close to 1 would result in their bounding constants blowing up. One cannot choose c too large or too small for the same reasons.\n4 TD(0) with Centering (CTD)\nCTD is a control variate solution to reduce the variance of the updates of normal TD(0). This is achieved by adding a zero-mean, centering term to the TD(0) update.\nLet Xn = (sn, sn+1). Then, the TD(0) algorithm can be seen to perform the following fixed-point iteration:\n\u03b8n = \u03b8n\u22121 + \u03b3nfXn(\u03b8n). (8)\nwhere fXn(\u03b8) := (r(sn, \u03c0(sn)) + \u03b2\u03b8 T\u03c6(sn+1) \u2212 \u03b8T\u03c6(sn))\u03c6(sn). The limit of (8) is the solution, \u03b8\u2217, of F (\u03b8) = 0, where F (\u03b8) := \u03a0T \u03c0(\u03a6\u03b8) \u2212 \u03a6\u03b8. The idea behind the CTD algorithm is to reduce the variance of the increments fXn(\u03b8n), in order that larger step sizes can be used. This is achieved by choosing an extra iterate \u03b8\u0304n, centred over the previous \u03b8n, and using an increment approximating fXn(\u03b8n)\u2212fXn(\u03b8\u0304n)+F (\u03b8\u0304n). The intuitive motivation for this choice is that when the CTD algorithm arrives close to \u03b8\u2217, the centering term alone ensures the updates become small, while with regular TD(0), one has to rely on a decaying step size to keep the iterates close to \u03b8\u2217.\nThe approach is inspired by the SVRG algorithm, proposed in [Johnson and Zhang, 2013], for a optimising a strongly-convex function. However, the setting for TD(0) with function approximation that we have is considerably more complicated owing to the following reasons: (i) Unlike [Johnson and Zhang, 2013], we are not optimising a function that is a finite-sum of smooth functions in a batch setting. Instead, we are estimating a value function which is an infinite (discounted) sum, with the individual functions making up the sum being made available in an online fashion (i.e. as new samples are generated from the simulation of the underlying MDP for policy \u03c0). (ii) The centering term in SVRG directly uses F (\u00b7), which in our case is a limit function that is neither directly accessible nor can be simulated for any given \u03b8. (iii) Obtaining the exponential convergence rate is also difficult owing to the fact that TD(0) does not initially see samples from the stationary distribution and there is an underlying mixing term that affects the rate. (iv) Finally, there are extra difficulties owing to the fact that we have a fixed point iteration, while the corresponding algorithm in [Johnson and Zhang, 2013] is stochastic gradient descent (SGD).\nThe CTD algorithm that we propose overcomes the difficulties mentioned above and the overall scheme of this epoch-based algorithm is presented in Figure 1. At the start of the mth epoch, a random iterate is picked from the previous epoch, i.e. \u03b8\u0304(m) = \u03b8in , where in is drawn uniformly at random in {(m \u2212 1)M, . . . ,mM}. Thereafter, for the epoch length M , CTD performs the following iteration: Set \u03b8mM = \u03b8\u0304(m) and for n = mM, . . . , (m+ 1)M \u2212 1 update\n\u03b8n+1 =\u03a5\n(\n\u03b8n + \u03b3 ( fXin (\u03b8n)\u2212 fXin (\u03b8\u0304 (m)) + F\u0302 (m)(\u03b8\u0304(m)) )\n)\n, (9)\nwhere F\u0302 (m)(\u03b8) := M\u22121 \u2211mM\ni=(m\u22121)M fXi(\u03b8) and \u03a5 is a projection operator that ensures that the iterates stay within a H-ball. Unlike TD(0), one can choose a large (constant) stepsize \u03b3 in (9). This choice in conjunction with iterate averaging via the choice of \u03b8\u0304(m) results in an exponential convergence rate for CTD (see Remark 4 below).\n4.1 Finite time bound\nTheorem 3 below presents a finite time bound in expectation for CTD under the following mixing assumption:\n(A6\u201d) There exists a non-negative function B\u2032(\u00b7) such that: For all s \u2208 S and m \u2265 0, \u221e \u2211\n\u03c4=0\n\u2016E(r(s\u03c4 , \u03c0(s\u03c4 ))\u03c6(s\u03c4 ) | s0 = s)\u2212 E\u03a8(r(s\u03c4 , \u03c0(s\u03c4 ))\u03c6(s\u03c4 ))\u2016 \u2264 B\u2032(s),\n\u221e \u2211\n\u03c4=0\n\u2016E[\u03c6(s\u03c4 )\u03c6(s\u03c4+m)T | s0 = s]\u2212 E\u03a8[\u03c6(s\u03c4 )\u03c6(s\u03c4+m)T]\u2016 \u2264 B\u2032(s),\nThe above is weaker than assumption (A6) used earlier for regular TD(0), and this is facilitated by the fact that we project the CTD iterates onto a H-ball.\nTheorem 3. Assume (A1)-(A4) and (A6\u201d) and let \u03b8\u2217 denote the solution of F (\u03b8) = 0. Let the epoch length M of the CTD algorithm (9) be chosen such that C1 < 1, where\nC1 := ((2\u00b5\u03b3M) \u22121 + \u03b3d2/2)/((1 \u2212 \u03b2)\u2212 d2\u03b3/2))\n(i) Geometrically ergodic chains: Here the Markov chain underlying policy \u03c0 mixes fast (see (7)) and we obtain1\n\u2016\u03a6(\u03b8\u0304(m) \u2212 \u03b8\u2217)\u20162\u03a8 \u2264 Cm1 ( \u2016\u03a6(\u03b8\u0304(0) \u2212 \u03b8\u2217)\u20162\u03a8 ) + CMC2H(5\u03b3 + 4)max{C1, \u03c1M}(m\u22121), (10)\nwhere C2 = \u03b3/(M((1 \u2212 \u03b2)\u2212 d2\u03b3/2)). (ii) General Markov chains:\n\u2016\u03a6(\u03b8\u0304(m) \u2212 \u03b8\u2217)\u20162\u03a8 \u2264 Cm1 ( \u2016\u03a6(\u03b8\u0304(0) \u2212 \u03b8\u2217)\u20162\u03a8 ) + C2H(5\u03b3 + 4)\nm\u22121 \u2211\nk=1\nC (m\u22122)\u2212k 1 B kM (k\u22121)M (s0), (11)\nwhere BkM(k\u22121)M is an upper bound on the partial sums \u2211kM i=(k\u22121)M (E(\u03c6(si) | s0) \u2212 E\u03a8(\u03c6(si))) and \u2211kM\ni=(k\u22121)M (E(\u03c6(si)\u03c6(si+l) | s0)\u2212 E\u03a8(\u03c6(si)\u03c6(si+l)T)), for l = 0, 1.\nProof. See Section 5.3.\nFor finite state space settings, we obtain exponential convergence rate (10) since they are geometrically ergodic, while for MDPs that do not mix exponentially fast, the second (mixing) term in (11) will dominate and decide the rate of the CTD algorithm.\nRemark 4. Combining the result in (10) with the bound in statement (4) of Theorem 1 in [Tsitsiklis and Van Roy, 1997], we obtain\n\u2016\u03a6\u03b8\u0304(m) \u2212 V \u03c0\u2016\u03a8 \u2264 1\n1\u2212 \u03b2 \u2016\u03a0V \u03c0 \u2212 V \u03c0\u2016\u03a8 + C m/2 1\n( \u2016\u03a6(\u03b8\u0304(0) \u2212 \u03b8\u2217)\u2016\u03a8 ) + \u221a CC2max{C1, \u03c1}(m\u22121)/2.\nThe first term on the RHS above is an artifact of function approximation, while the second and third terms reflect the convergence rate of the CTD algorithm.\nRemark 5. As a consequence of the fact that (\u03b8\u0304(m)\u2212\u03b8\u2217)T I(\u03b8\u0304(m)\u2212\u03b8\u2217) \u2264 1 \u00b5 (\u03b8\u0304(m)\u2212\u03b8\u2217)T\u03a6T\u03a8\u03a6(\u03b8\u0304(m)\u2212\u03b8\u2217), one can obtain the following bound on the parameter error for CTD:\n\u2016\u03b8\u0304(m) \u2212 \u03b8\u2217\u20162 \u2264 (1/\u00b5) ( Cm1 ( \u2016\u03a6(\u03b8\u0304(0) \u2212 \u03b8\u2217)\u20162\u03a8 ) + C2H(5\u03b3 + 4)\nm\u22121 \u2211\nk=1\nC (m\u22122)\u2212k 1 B kM (k\u22121)M (s0)\n)\n.\nComparing the above bound with those in Theorems 1\u20132, we can infer that CTD exhibits an exponential convergence rate of order O(Cm1 ), while TD(0) with/without averaging can converge only at a sublinear rate of order O(n\u22121/2).\n1For any v \u2208 Rd, we take \u2016v\u2016\u03a8 := \u221a v T\u03a8v.\n5 Convergence proofs\n5.1 Non-averaged case: Proof of Theorem 1\nWe split the analysis in two, first considering the bound in high probability, and second the bound in expectation. Both bounds involve a martingale decomposition, the former of the centered error, and the latter of the iteration (1).\n5.1.1 High probability bound\nWe first state and prove a result bounding the error with high probability for general step-sizes:\nProposition 1. (High probability bound) Under (A1)-(A5) and (A6\u2019), we have,\nP (\u2016\u03b8n \u2212 \u03b8\u2217\u20162 \u2212 E \u2016\u03b8n \u2212 \u03b8\u2217\u20162 \u2265 \u01eb) \u2264 e\u2212\u01eb 2(2 \u2211n i=1 L 2 i )\n\u22121\n,\nwhere Li := \u03b3i[e\u2212\u00b5(1\u2212\u03b2) \u2211n k=i \u03b3k(1 + [\u03b3i + \u2211n\u22121 k=i [\u03b3k \u2212 \u03b3k+1]e\u00b5(1\u2212\u03b2) \u2211k+1 j=i \u03b3j ][1 + \u03b2(3\u2212 \u03b2)]B\u2032)] 12 .\nProof. Recall that zn := \u03b8n \u2212 \u03b8\u2217. First, we rewrite \u2016zn\u201622 \u2212 E \u2016zn\u2016 2 2 as a telescoping sum of martingale differences:\n\u2016zn\u20162 \u2212 E \u2016zn\u20162 = n \u2211\ni=1\ngi \u2212 E[gi |Fi\u22121 ] (12)\nwhere Di := gi \u2212E[gi |Fi\u22121 ], gi := E[\u2016zn\u20162 |\u03b8i,Fi\u22121 ], and Fi denotes the sigma algebra generated by the states of the underlying Markov chain, {\u03c31, . . . , \u03c3i}. Note that \u03b8i is Fi-measurable.\nThe above establishes that the centered error, \u2016zn\u20162 \u2212 E \u2016zn\u20162 can be written down as a sum of martingale differences with respect to the filtration {Fi}ni=0. The proof procedes by establishing that these martingale differences are Lipschitz functions of the random inovation at each time, with Lipschitz constants Li. This is the content of Lemma 4, and it makes use of assumption (A3), (A4), and (A7). This is the since the random innovation is, through assumptions (A2)-(A4), bounded, it is subgaussian, and we can invoke a standard concentration argument in Lemma 5 to finish the bound.\nLemma 4. Recall that Xn = (sn, sn+1) and fXn(\u03b8) := (r(sn, \u03c0(sn)) + \u03b2\u03b8 T\u03c6(sn+1)\u2212T \u03c6(sn))\u03c6(sn). Then, conditioned on Fi\u22121, the functions gi are Lipschitz continuous in fXi(\u03b8i\u22121), the random innovation at time i, with constants\nLi := \u03b3i\n[\ne\u2212\u00b5(1\u2212\u03b2) \u2211n k=i \u03b3k\n(\n1 +\n[\n\u03b3i +\nn\u22121 \u2211\nk=i\n[\u03b3k \u2212 \u03b3k+1] ] [1 + \u03b2(3 \u2212 \u03b2)]B\u2032 )]\n1 2\n.\nProof. Let \u0398ij(\u03b8) denote the mapping that returns the value of the iterate \u03b8j at instant j, given that \u03b8i = \u03b8.\n\u0398ij+1(\u03b8)\u2212\u0398ij+1(\u03b8\u2032) = \u0398ij(\u03b8)\u2212\u0398ij(\u03b8\u2032)\u2212 \u03b3j [fXj(\u0398ij(\u03b8))\u2212 fXj(\u0398ij(\u03b8\u2032))] = \u0398ij(\u03b8)\u2212\u0398ij(\u03b8\u2032)\u2212 \u03b3j [\u03c6(sj)\u03c6(sj)T \u2212 \u03b2\u03c6(sj)\u03c6(sj+1)T](\u0398ij(\u03b8)\u2212\u0398ij(\u03b8\u2032))\n= [I \u2212 \u03b3jaj ](\u0398ij(\u03b8)\u2212\u0398ij(\u03b8\u2032)) = ( j \u220f\nk=i\n[I \u2212 \u03b3kak] ) (\u03b8 \u2212 \u03b8\u2032),\nwhere aj := \u03c6(sj)\u03c6(sj)T \u2212 \u03b2\u03c6(sj)\u03c6(sj+1)T. So we have\nE\n(\n\u2225 \u2225\u0398in+1(\u03b8)\u2212\u0398in+1(\u03b8\u2032) \u2225 \u2225\n2 2 | Fi\n) = (\u03b8 \u2212 \u03b8\u2032)TE [( n \u220f\nk=i\n[I \u2212 \u03b3kak] ) T ( n \u220f\nk=i\n[I \u2212 \u03b3kak] ) | Fi ] (\u03b8 \u2212 \u03b8\u2032)\n(13)\nand from the tower property of conditional expectations, it follows that\nE\n[(\nn \u220f\nk=i\n[I \u2212 \u03b3kak] ) T ( n \u220f\nk=i\n[I \u2212 \u03b3kak] ) | Fi ]\n=E\n[(\nn\u22121 \u220f\nk=i\n[I \u2212 \u03b3kak] )T ( I \u2212 2\u03b3nE (\nan \u2212 \u03b3n 2 aTnan | Fn ))\n(\nn\u22121 \u220f\nk=i\n[I \u2212 \u03b3kak] ) | Fi ]\n=E\n[(\nn\u22121 \u220f\nk=i\n[I \u2212 \u03b3kak] )T ( I \u2212 2\u03b3nE\u03a8 (\nan \u2212 \u03b3n 2 aTnan ))\n(\nn\u22121 \u220f\nk=i\n[I \u2212 \u03b3kak] ) | Fi ]\n+ E\n[(\nn\u22121 \u220f\nk=i\n[I \u2212 \u03b3kak] )T 2\u03b3nE (\u01ebn | Fn) ( n\u22121 \u220f\nk=i\n[I \u2212 \u03b3kak] ) | Fi ]\n(14)\nwhere\n\u01eb\u2032n := E [(an \u2212 \u03b3naTnan/2) | Fn]\u2212 E\u03a8 [(an \u2212 \u03b3naTnan/2)]\nTo deal with the term in the second last line of (14), let \u2206 be the diagonal matrix with entries \u2206i,i = \u03a6i,1:d\u03a6 T i,1:d. Then we find that, for any vector \u03b8,\n\u03b8TE\u03a8\n[ aj+1 \u2212 \u03b3j+1 2 aTj+1aj+1 ] \u03b8 = \u03b8T\u03a6T ( I \u2212 \u03b2\u03a8P \u2212 \u03b3j+1 2 (\u2206\u2212 \u03b2P T (2I \u2212 \u03b2\u2206)\u03a8P ) ) \u03a6\u03b8\n= \u03b8T\u03a6T ( I \u2212 \u03b2\u03a8\u03a0P \u2212 \u03b3j+1 2 (\u2206\u2212 \u03b2P T\u03a0T (2I \u2212 \u03b2\u2206)\u03a8\u03a0P ) ) \u03a6\u03b8 (15) \u2265 \u2016\u03a6\u03b8\u20162\u03a8 \u2212 \u03b2 \u2016\u03a6\u03b8\u2016\u03a8 \u2212 \u03b3j+1 2 \u03b8T\u03a6T (\u2206\u2212 \u03b2P T\u03a0T (2I \u2212 \u03b2\u2206)\u03a8\u03a0P ) \u03a6\u03b8 (16) \u2265 \u2016\u03a6\u03b8\u20162\u03a8 \u2212 \u03b2 \u2016\u03a6\u03b8\u20162\u03a8 \u2212 \u03b3j+1 2 \u2016\u03a6\u03b8\u20162\u03a8 + \u03b3j+1 2 \u03b8T\u03a6T\u03b2P T\u03a0T (2I \u2212 \u03b2\u2206)\u03a8\u03a0P\u03a6\u03b8 (17) \u2265 \u2016\u03a6\u03b8\u20162\u03a8 \u2212 \u03b2 \u2016\u03a6\u03b8\u2016 2 \u03a8 \u2212\n\u03b3j+1 2 \u2016\u03a6\u03b8\u20162\u03a8 + \u03b3j+1 2 \u03b2(2\u2212 \u03b2) \u2016\u03a0P\u03a6\u03b8\u20162\u03a8 (18)\n\u2265 \u00b5 ( 1\u2212 \u03b2 \u2212 \u03b3j+1 2 ) \u2016\u03b8\u201622 , (19)\nwhere (15) follows from the fact that \u03b8T\u03a6T\u03a8(I \u2212 \u03a0)x = 0 since \u03a0 is a projection, (16) by an application of Cauchy-Schwarz inequality and from the non-expansiveness property of \u03a0 and P . (17) and (18) follow from the fact that, by (A4), the matrix \u2206\u2212 I is positive semi-definite. The final inequality (19) follows from (A3).\nFor the term on the last line of (14) we notice, that by boundedness of the features, \u2225\n\u2225 \u2225 \u2225 \u2225\nn\u22121 \u220f\nk=i\n[I \u2212 \u03b3kak] \u2225 \u2225 \u2225 \u2225\n\u2225\n2\n\u2264 n\u22121 \u220f\nk=i\n(1 + \u03b3k(1 + \u03b2)) .\nUsing this observation and (19), we can expand (13) with (14) to obtain\nE\n(\n\u2225 \u2225\u0398in+1(\u03b8)\u2212\u0398in+1(\u03b8\u2032) \u2225 \u2225\n2 2 | Fi\n)\n\u2264 xn(\u03b8 \u2212 \u03b8\u2032)E [( n\u22121 \u220f\nk=i\n[I \u2212 \u03b3kak] )T (n\u22121 \u220f\nk=i\n[I \u2212 \u03b3kak] ) | Fi ] (\u03b8 \u2212 \u03b8\u2032) (20)\n+ 2\u03b3n\n\n\nn\u22121 \u220f\nj=i\n(1 + \u03b3j(1 + \u03b2))\n\n\n2\n\u2016E (\u01ebn | Fi)\u20162 \u2225 \u2225\u03b8 \u2212 \u03b8\u2032 \u2225 \u2225 2 2 (21)\n\u2264\n\n\n(\nn \u220f\nk=i\nxk\n)\n+ 2 n \u2211\nk=i\n\u03b3k\n\n\nn \u220f\nj=k+1\nxj\n\n\n\n\nk\u22121 \u220f\nj=i\n(1 + \u03b3j(1 + \u03b2))\n\n\n2\n\u2016E (\u01ebk | Fi)\u20162\n\n\n\u2225 \u2225\u03b8 \u2212 \u03b8\u2032 \u2225 \u2225 2\n2\n\u2264 [ e\u22122 \u2211n k=i \u03b3k\u00b5(1\u2212\u03b2\u2212 \u03b3k 2 ) + 2 n \u2211\nk=i\n\u03b3ke \u22122\n\u2211n j=k+1 \u03b3j\u00b5\n(\n1\u2212\u03b2\u2212 \u03b3j 2\n)\n+2 \u2211k\u22121\nj=i \u03b3j(1+\u03b2)) \u2016E (\u01ebk | Fi)\u20162\n]\n\u2225 \u2225\u03b8 \u2212 \u03b8\u2032 \u2225 \u2225 2\n2\n(22)\n\u2264 e\u22122 \u2211n k=i \u03b3k\u00b5(1\u2212\u03b2\u2212 \u03b3k 2 )\n[\n1 + 2 n \u2211\nk=i\n\u03b3ke 2 \u2211k\nj=i \u03b3j(\u00b5 ( 1\u2212\u03b2\u2212 \u03b3j 2 )\n+(1+\u03b2)) \u2016E (\u01ebk | Fi)\u20162\n]\n\u2225 \u2225\u03b8 \u2212 \u03b8\u2032 \u2225 \u2225 2\n2 (23)\nwhere xn := 1\u2212 2\u03b3n\u00b5 ( 1\u2212 \u03b2 \u2212 \u03b3n2 ) . Now, using discrete integration by parts,\nn \u2211\nk=i\n\u03b3ke 2 \u2211k\nj=i \u03b3j(\u00b5 ( 1\u2212\u03b2\u2212 \u03b3j 2 )\n+(1+\u03b2)) \u2016E (\u01ebk | Fi)\u20162\n=\u03b3i\nn \u2211\nk=i\ne 2 \u2211k\nj=i \u03b3j(\u00b5 ( 1\u2212\u03b2\u2212 \u03b3j 2 )\n+(1+\u03b2)) \u2016E (\u01ebk | Fi)\u20162\n+ n\u22121 \u2211\nk=i\n[\u03b3k+1 \u2212 \u03b3k] n \u2211\nj=k+1\ne2 \u2211j l=i \u03b3l(\u00b5(1\u2212\u03b2\u2212 \u03b3l 2 )+(1+\u03b2)) \u2016E (\u01ebk | Fi)\u20162\n\u2264 [ \u03b3i + n\u22121 \u2211\nk=i\n[\u03b3k+1 \u2212 \u03b3k] ] [1 + \u03b2(3 \u2212 \u03b2)]B\u2032(si)\nwhere for the inequality we have used (A6) with the following bound:\n\u2016E(\u01ebk | Fi)\u20162 \u2264(1\u2212 \u03b3k/2) \u2016E(\u03b2\u03c6(sk)\u03c6(sk)T | Fi)\u2212 E\u03a8(\u03b2\u03c6(sk)\u03c6(sk)T)\u20162 + \u03b2 \u2016E(\u03b2\u03c6(sk)\u03c6(sk+1)T | Fi)\u2212 E\u03a8(\u03b2\u03c6(sk)\u03c6(sk+1)T)\u20162 + \u03b2(2 \u2212 \u03b2) \u2016E(\u03c6(sk+1)\u03c6(sk+1)T | Fi)\u2212 E\u03a8(\u03c6(sk+1)\u03c6(sk+1)T)\u20162 .\nFrom the foregoing, we have\nE [\u2225 \u2225\u0398in (\u03b8)\u2212\u0398in ( \u03b8\u2032 )\u2225 \u2225\n2\n]\n(24)\n\u2264 [ e\u2212\u00b5(1\u2212\u03b2) \u2211n k=i \u03b3k ( 1 + [\n\u03b3i +\nn\u22121 \u2211\nk=i\n[\u03b3k \u2212 \u03b3k+1] ] [1 + \u03b2(3\u2212 \u03b2)]B\u2032(si) )]\n1 2 \u2225\n\u2225\u03b8 \u2212 \u03b8\u2032 \u2225 \u2225\n2 (25)\nFinally, we have \u2223\n\u2223E [\u2016\u03b8n \u2212 \u03b8\u2217\u20162 | Fi\u22121, \u03b8i = \u03b8]\u2212 E [ \u2016\u03b8n \u2212 \u03b8\u2217\u20162 | Fi\u22121, \u03b8i = \u03b8\u2032 ]\u2223 \u2223 2 \u2264 E [\u2225 \u2225\u0398in (\u03b8)\u2212\u0398in ( \u03b8\u2032 )\u2225 \u2225 2 ]\n\u2264 [ e\u2212\u00b5(1\u2212\u03b2) \u2211n k=i \u03b3k ( 1 + [ \u03b3i + n\u22121 \u2211\nk=i\n[\u03b3k \u2212 \u03b3k+1] ] [1 + \u03b2(3 \u2212 \u03b2)]B\u2032(si) )]\n1 2\n\u03b3i \u2225 \u2225f \u2212 f \u2032 \u2225 \u2225\n2\n\u2264 Li \u2225 \u2225f \u2212 f \u2032 \u2225 \u2225\n2 .\nwhere f = \u03b8 \u2212 \u03b8i\u22121 and f \u2032 = \u03b8\u2032 \u2212 \u03b8i\u22121.\nIn the following lemma, we invoke a standard martingale concentration bound using the Li-Lipschitz property of the gi functions and the assumption (A3).\nLemma 5. Under the conditions of Theorem 1, we have\nP (\u2016zn\u20162 \u2212 E \u2016zn\u20162 \u2265 \u01eb) \u2264 exp(\u2212\u03bb\u01eb) exp ( \u03b1\u03bb2\n2\nn \u2211\ni=1\nL2i\n)\n. (26)\nProof. Note that\nP (\u2016zn\u20162 \u2212 E \u2016zn\u20162 \u2265 \u01eb) = P ( n \u2211\ni=1\nDi \u2265 \u01eb ) \u2264 exp(\u2212\u03bb\u01eb)E ( exp ( \u03bb n \u2211\ni=1\nDi\n)\n)\n= exp(\u2212\u03bb\u01eb)E ( exp ( \u03bb n\u22121 \u2211\ni=1\nDi\n)\nE\n( exp(\u03bbDn) |Fn\u22121 )\n)\n.\nThe first equality above follows from (12), while the inequality follows from Markov inequality. Now for any bounded random variable f , and L-Lipschitz function g we have\nE (exp(\u03bbg(f))) \u2264 exp ( \u03bb2L2/2 ) .\nNote that each fi(\u03b8i\u22121) is a bounded random variable by (A2) and (A4), and, conditioned on Fi\u22121, gi is Lipschitz in fi(\u03b8i\u22121) with constant Li (Lemma 4). So we obtain\nE (exp(\u03bbDn) |Fn\u22121 ) \u2264 exp ( \u03bb2L2n 2 ) ,\nand so\nP (\u2016zn\u20162 \u2212 E \u2016zn\u20162 \u2265 \u01eb) \u2264 exp(\u2212\u03bb\u01eb) exp ( \u03b1\u03bb2\n2\nn \u2211\ni=1\nL2i\n)\n.\nThe proof of Proposition 1 follows by optimizing over \u03bb in (26).\n5.1.2 Bound in expectation\nNow we state and prove a result bounding the expected error for general step-size sequences:\nProposition 2. (Bound in expectation) Under (A1)-(A6) and assuming that \u03b3n \u2264 \u00b5(1 \u2212 \u03b2)/(2(1 + \u03b2)2) for all n, we have,\nE(\u2016\u03b8n+1 \u2212 \u03b8\u2217\u20162 \u2016s0 ) \u2264 [ e\u2212\u00b5(1\u2212\u03b2) \u2211n k=1 \u03b3k(\u2016z0\u20162 + C) + (1 + \u2016\u03b8\u2217\u20162) n \u2211\nk=1\n\u03b32ke \u2212\u00b5(1\u2212\u03b2)\n\u2211n j=k \u03b3j\n+ C\nn\u22121 \u2211\nk=1\n(\u03b3k+1 \u2212 \u03b3k)e\u2212\u00b5(1\u2212\u03b2) \u2211n j=k+1 \u03b3j\n] 1 2\n, (27)\nwhere C = 2(2 + \u03b2)(d+ 4)B(s0) ( \u2016\u03b80\u20162+d+\u2016\u03b8 \u2217\u20162\n1\u2212\u03b2\n)2 .\nProof. The update rule (1) can be re-written as follows:\nzn+1 =\u03b8n \u2212 \u03b8\u2217 + \u03b3n[E\u03a8(fXn(\u03b8n)) + E(fXn(\u03b8n) | Fn)\u2212 E\u03a8(fXn(\u03b8n)) + fXn(\u03b8n)\u2212 E(fXn(\u03b8n) | Fn)], =zn + \u03b3n[E\u03a8(fXn(\u03b8n)\u2212 fXn(\u03b8\u2217)) + E(fXn(\u03b8n)\u2212 fXn(\u03b8\u2217) | Fn)\u2212 E\u03a8(fXn(\u03b8n)\u2212 fXn(\u03b8\u2217))\n+ fXn(\u03b8n)\u2212 fXn(\u03b8\u2217)\u2212 E(fXn(\u03b8n)\u2212 fXn(\u03b8\u2217) | Fn) + fXn(\u03b8\u2217)] (28)\nWe notice that\nE\u03a8(fXn(\u03b8n)\u2212 fXn(\u03b8\u2217)) =E\u03a8 ( \u03b2\u03b8Tn\u03c6(sn+1)\u2212 \u03b2\u03b8\u2217T\u03c6(sn+1)\u2212 (\u03b8Tn\u03c6(sn)\u2212 \u03b8\u2217T\u03c6(sn)) )\n=E\u03a8 ((\u03b8n \u2212 \u03b8\u2217)T[\u03b2\u03c6(sn+1)\u2212 \u03c6(sn)]\u03c6(sn)) =E\u03a8 (\u03c6(sn)[\u03b2\u03c6(sn+1)\nT \u2212 \u03c6(sn)T](\u03b8n \u2212 \u03b8\u2217)) =\u2212Azn, (29)\nwhere A := \u03a6T\u03a8(I \u2212 \u03b2P )\u03a6 (here P = P\u03c0 denotes the one-step transition probability matrix of the underlying Markov chain induced under a stationary policy \u03c0). Noticing also that for any vector x\nxT\u03a6T\u03a8P\u03a6x = \u3008xT\u03a6T, P\u03a6x\u30092\u03a8 \u2264 \u2016xT\u03a6T\u2016\u03a8\u2016P\u03a6x\u2016\u03a8 = \u2016xT\u03a6T\u20162\u03a8,\nwhere we have used Lemma 1 in Tsitsiklis and Van Roy [1997] for the final equality. So we deduce that A\u2212 (1\u2212 \u03b2)\u00b5I is positive definite by (A3).\nFurthermore, letting\nan := \u03b2\u03c6(sn)\u03c6(sn+1) T \u2212 \u03c6(sn)\u03c6(sn)T, \u01ebn := E(an | Fn)\u2212 E\u03a8(an), and \u2206Mn := an \u2212 E(an | Fn)),\nthen, using (29), we can rewrite (28) as\nzn+1 = [I \u2212 \u03b3n(A+ \u01ebn +\u2206Mn)] zn + \u03b3n\u01eb\u2032n.\nwhere \u01eb\u2032n = fXn(\u03b8 \u2217)\u2212E\u03a8 (fXn(\u03b8\u2217)). Notice that \u2206Mn is a martingale difference sequence with respect to the filtration F = {Fn}n\u22651, and E(\u01ebn | s0) is mixing-error term. Taking the expectation of the square, and expanding, we have\nE\n( \u2016zn+1\u201622 | Fn ) = E ( \u2016[I \u2212 \u03b3n(A+ \u01ebn +\u2206Mn)] zn\u201622 | Fn )\n(30)\n+ 2\u03b3nE (fXn(\u03b8 \u2217)T [I \u2212 \u03b3n(A+ \u01ebn +\u2206Mn)] zn | Fn) + \u03b32n(1 + (1 + \u03b2) \u2016\u03b8\u2217\u20162)2\n= [zTn[I \u2212 2\u03b3n(A+ E (\u01ebn | Fn)) + \u03b32nE ( (A+ \u01ebn +\u2206Mn) 2 | Fn ) ]zn] (31)\n+ 2\u03b3nE ( (fXn(\u03b8 \u2217)\u2212 E\u03a8 (fXn(\u03b8\u2217)))T [I \u2212 \u03b3n(A+ \u01ebn +\u2206Mn)] zn | Fn ) + \u03b32n(1 + (1 + \u03b2) \u2016\u03b8\u2217\u20162)2\n\u2264 [1\u2212 2\u03b3n(\u00b5(1\u2212 \u03b2)\u2212 2\u03b3n(1 + \u03b2)2)] \u2016zn\u201622 (32)\n+ \u03b3nz T nE (\u01ebn | Fn) zn + 2\u03b3nE ( ( \u01eb\u2032n ) T [I \u2212 \u03b3n(A+ \u01ebn +\u2206Mn)] zn | Fn ) + \u03b32n(1 + (1 + \u03b2) \u2016\u03b8\u2217\u20162)2\nwe have used that\n\u2016A+ \u01ebn +\u2206Mn\u20162 = \u2016\u03b2\u03c6(sn)\u03c6(sn+1)T \u2212 \u03c6(sn)\u03c6(sn)T)\u20162 \u2264 (1 + \u03b2).\nBefore unrolling (32) using the tower property of expectations, we bound the terms involving \u01ebn and \u01eb\u2032n. We notice first that, given a fixed orthonomal basis of vectors {ei}di=1. and a the associated coordinate mapping \u03b1i(\u00b7) for which \u03c6 = \u2211d i=1 \u03b1i(\u03c6)ei holds true,\n\u03b8n+1 = \u03b8n + \u03b3n (r(sn, \u03c0(sn)) + \u03b2\u03b8 T n\u03c6(sn+1)\u2212 \u03b8Tn\u03c6(sn))\u03c6(sn)\n= (1 + \u03b3nan)\u03b8n + \u03b3nr(sn, \u03c0(sn))\u03c6(sn)\n=\nn \u220f\nk=1\n(1 + \u03b3kan)\u03b80 +\nn \u2211\nk=1\n\u03b3k\n\n\nn \u220f\nj=k\n(1 + \u03b3jaj)\n\n r(sk, \u03c0(sk))\u03c6(sk)\n=\n(\nn \u220f\nk=1\n(1 + \u03b3kan)\n)\n\u03b80 + d \u2211\ni=1\n\n\nn \u2211\nk=1\n\u03b1i(\u03c6(sk))r(sk, \u03c0(sk))\u03b3k\n\n\nn \u220f\nj=k\n(1 + \u03b3jaj)\n\n\n\n ei.\nNow, if A is a possibly random matrix such that \u2016A\u20162 \u2264 C , and \u03b8 is a fixed vector, then\nE (\u03b8TATE(\u01ebn | Fn)A\u03b8 | s0) \u2264 E ( C2\u03b8TE(\u01ebn | Fn)\u03b8 | s0 ) \u2264 C2\u03b8TE (\u01ebn | s0) \u03b8.\nFurthermore, for any norm \u2016 \u00b7 \u2016, \u2016\u2211di=1 xi\u20162 \u2264 d \u2211d i=1 \u2016xi\u20162. From these observations we can deduce that\nE (zn+1E(\u01ebn | Fn)Tzn+1 | s0)\n\u2264 (d+ 2)\n\ne2(1+\u03b2) \u2211n k=1 \u03b3k \u2016\u03b80\u201622 + ( n \u2211\nk=1\n\u03b3ke (1+\u03b2)\n\u2211n j=k \u03b3j\n)2\n+ \u2016\u03b8\u2217\u201622\n\n \u2016E(\u01ebn | s0)\u20162\n\u2264 (d+ 2)\n\ne2(1+\u03b2) \u2211n k=1 \u03b3k \u2016\u03b80\u20162 + e2(1+\u03b2) \u2211n k=1 \u03b3k\n(\nn \u2211\nk=1\n\u03b3ke \u2212(1+\u03b2)\n\u2211k\u22121 j=1 \u03b3j\n)2\n+ \u2016\u03b8\u2217\u201622\n\n \u2016E(\u01ebn | s0)\u20162\n\u2264 (d+ 2)\u2016\u03b80\u2016 2 2 + 1 + \u2016\u03b8\u2217\u201622 (1\u2212 \u03b2)2 e2(1+\u03b2) \u2211n k=1 \u03b3k \u2016E(\u01ebn | s0)\u20162 .\nSimilarly, using Cauchy-Schwarz,\nE\n(\nE\n(\n( \u01eb\u2032n ) T [I \u2212 \u03b3n(A+ \u01ebn +\u2206Mn)] zn | Fn ) | s0 )\n= E\n(\n( \u01eb\u2032n ) T [I \u2212 \u03b3n(A+ \u01ebn +\u2206Mn)] n \u220f\nk=1\n(1 + \u03b3kan) | s0 ) \u03b80\n+\nd \u2211\ni=1\nE\n\n\n( \u01eb\u2032n ) T [I \u2212 \u03b3n(A+ \u01ebn +\u2206Mn)] n \u2211\nk=1\n\u03b3k\u03b1i(\u03c6(sk))r(sj , \u03c0(sj))\n\n\nn \u220f\nj=k\n(1 + \u03b3jaj)\n\n | s0\n\n ei\n\u2212 [I \u2212 \u03b3n(A+ \u01ebn +\u2206Mn)]E ( ( \u01eb\u2032n ) T | s0 ) \u03b8\u2217\n\u2264 2e(1+\u03b2) \u2211n k=1 \u03b3k \u2225 \u2225E (( \u01eb\u2032n ) | s0 )\u2225 \u2225 2 \u2016\u03b80\u20162\n+ 2d \u2225 \u2225E (( \u01eb\u2032n ) | s0 )\u2225 \u2225 2 e(1+\u03b2) \u2211n k=1 \u03b3k\nn \u2211\nk=1\n\u03b3ke \u2212(1+\u03b2) \u2211k\u22121 j=1 \u03b3j + 2 \u2225 \u2225E (( \u01eb\u2032n ) | s0 )\u2225 \u2225 2 \u2016\u03b8\u2217\u20162\n\u2264 2\u2016\u03b80\u20162 + d+ \u2016\u03b8 \u2217\u20162\n1\u2212 \u03b2 e (1+\u03b2)\n\u2211n k=1 \u03b3k \u2225 \u2225E (( \u01eb\u2032n ) | s0 )\u2225 \u2225\n2\nSo we can unroll (32) using the tower property of conditional expectations to obtain:\nE(\u2016zn+1\u201622 | s0) \u2264 \u03a0nz0 + (1 + (1 + \u03b2) \u2016\u03b8\u2217\u20162)2 n \u2211\nk=1\n\u03b32k\u03a0n\u03a0 \u22121 k\n+ (d+ 2) \u2016\u03b80\u201622 + d+ \u2016\u03b8\u2217\u2016 2 2 (1\u2212 \u03b2)2 n \u2211\nk=1\n\u03b3k\u03a0n\u03a0 \u22121 k e\n2(1+\u03b2) \u2211k\nj=1 \u03b3j \u2016E(\u01ebk | s0)\u20162\n+ 4 \u2016\u03b80\u20162 + d+ \u2016\u03b8\u2217\u20162\n1\u2212 \u03b2\nn \u2211\nk=1\n\u03b3k\u03a0n\u03a0 \u22121 k e\n(1+\u03b2) \u2211k\nj=1 \u03b3j \u2225 \u2225E(\u01eb\u2032k | s0) \u2225 \u2225\n2\n\u2264 e\u2212 \u2211n k=1 2\u03b3k(\u00b5(1\u2212\u03b2)\u22122\u03b3k(1+\u03b2) 2)z0 + (1 + (1 + \u03b2) \u2016\u03b8\u2217\u20162)2\nn \u2211\nk=1\n\u03b3ke \u2212\n\u2211n j=k \u03b3j(\u00b5(1\u2212\u03b2)\u22122\u03b3j (1+\u03b2) 2)\n+ (d+ 2) \u2016\u03b80\u201622 + d+ \u2016\u03b8\u2217\u2016 2 2 (1\u2212 \u03b2)2 n \u2211\nk=1\n\u03b3ke \u2212\n\u2211n j=k \u03b3j(\u00b5(1\u2212\u03b2)\u22122\u03b3j (1+\u03b2) 2)e2(1+\u03b2) \u2211k\nj=1 \u03b3j \u2016E(\u01ebk | s0)\u20162\n+ 4 \u2016\u03b80\u20162 + d+ \u2016\u03b8\u2217\u20162\n1\u2212 \u03b2\nn \u2211\nk=1\n\u03b3ke \u2212\n\u2211n j=k \u03b3j(\u00b5(1\u2212\u03b2)\u22122\u03b3j (1+\u03b2) 2)e(1+\u03b2) \u2211k j=1 \u03b3j \u2225 \u2225E(\u01eb\u2032k | s0) \u2225 \u2225\n2\nwhere \u03a0n := \u220fn\nk=1\n( 1\u2212 2\u03b3n(\u00b5(1\u2212 \u03b2)\u2212 2\u03b3n(1 + \u03b2)2) )\n. Using that \u03b3n < \u00b5(1\u2212 \u03b2)/(2(1 + \u03b2)2) for all n, we have that\nE(\u2016zn+1\u2016 | s0) \u2264 [ E(\u2016zn+1\u201622 | s0) ] 1 2\n\u2264 [ e\u2212\u00b5(1\u2212\u03b2) \u2211n k=1 \u03b3kz0 + (1 + (1 + \u03b2) \u2016\u03b8\u2217\u20162)2 n \u2211\nk=1\n\u03b32ke \u2212\u00b5(1\u2212\u03b2)\n\u2211n j=k \u03b3j\n+ (d+ 2) \u2016\u03b80\u201622 + d+ \u2016\u03b8\u2217\u2016 2 2 (1\u2212 \u03b2)2 n \u2211\nk=1\n\u03b3ke \u2212\u00b5(1\u2212\u03b2) \u2211n j=k \u03b3je2(1+\u03b2) \u2211k j=1 \u03b3j \u2016E(\u01ebk | s0)\u20162\n+ 4 \u2016\u03b80\u20162 + d+ \u2016\u03b8\u2217\u20162\n1\u2212 \u03b2\nn \u2211\nk=1\n\u03b3ke \u2212\u00b5(1\u2212\u03b2) \u2211n j=k \u03b3je(1+\u03b2) \u2211k j=1 \u03b3j \u2225 \u2225E(\u01eb\u2032k | s0) \u2225 \u2225\n2\n] 1 2\nUsing discrete integration by parts, we have that\nn \u2211\nk=1\ne\u2212\u00b5(1\u2212\u03b2) \u2211n j=k \u03b3je2(1+\u03b2) \u2211k\nj=1 \u03b3j \u2016E(\u01ebk | s0)\u20162\n\u2264e\u2212\u00b5(1\u2212\u03b2) \u2211n k=1 \u03b3j\nn \u2211\nj=1\ne2(1+\u03b2) \u2211k\nj=1 \u03b3j \u2016E(\u01ebk | s0)\u20162\n+ n\u22121 \u2211\nk=1\n(\u03b3k+1 \u2212 \u03b3k)e\u2212\u00b5(1\u2212\u03b2) \u2211n\nj=k+1 \u03b3j k \u2211\nj=1\ne2(1+\u03b2) \u2211j\nl=1 \u03b3l \u2016E(\u01ebj | s0)\u20162\n\u2264(1 + \u03b2)B(s0) [ e\u2212\u00b5(1\u2212\u03b2) \u2211n k=1 \u03b3j + n\u22121 \u2211\nk=1\n(\u03b3k+1 \u2212 \u03b3k)e\u2212\u00b5(1\u2212\u03b2) \u2211n j=k+1 \u03b3j\n]\n.\nTreating the mixing term involving \u01eb\u2032k similarly, we find that:\nE( \u2016zn+1\u20162 | s0) \u2264 [ E(\u2016zn+1\u201622 | s0) ]\n1 2\n\u2264 [ e\u2212\u00b5(1\u2212\u03b2) \u2211n k=1 \u03b3k \u2016z0\u20162 + (1 + \u2016\u03b8\u2217\u20162) n \u2211\nk=1\n\u03b32ke \u2212\u00b5(1\u2212\u03b2)\n\u2211n j=k \u03b3j\n+\n[\n(d+ 2) \u2016\u03b80\u201622 + d+ \u2016\u03b8\u2217\u201622\n(1\u2212 \u03b2)2 (1 + \u03b2)B(s0) + 4 \u2016\u03b80\u20162 + d+ \u2016\u03b8\u2217\u20162 1\u2212 \u03b2 (2 + \u03b2)B(s0)\n]\n\u00d7 [ e\u2212\u00b5(1\u2212\u03b2) \u2211n k=1 \u03b3j + n\u22121 \u2211\nk=1\n(\u03b3k+1 \u2212 \u03b3k)e\u2212\u00b5(1\u2212\u03b2) \u2211n j=k+1 \u03b3j\n] ] 1 2\n\u2264 [ e\u2212\u00b5(1\u2212\u03b2) \u2211n k=1 \u03b3k \u2016z0\u20162 + (1 + \u2016\u03b8\u2217\u20162) n \u2211\nk=1\n\u03b32ke \u2212\u00b5(1\u2212\u03b2)\n\u2211n j=k \u03b3j\n+ 2(2 + \u03b2)(d + 4)B(s0) (\u2016\u03b80\u20162 + d+ \u2016\u03b8\u2217\u20162 1\u2212 \u03b2\n)2 [\ne\u2212\u00b5(1\u2212\u03b2) \u2211n k=1 \u03b3j + n\u22121 \u2211\nk=1\n(\u03b3k+1 \u2212 \u03b3k)e\u2212\u00b5(1\u2212\u03b2) \u2211n j=k+1 \u03b3j\n]] 1 2\n\u2264 [ e\u2212\u00b5(1\u2212\u03b2) \u2211n\nk=1 \u03b3k(\u2016z0\u20162 + C)\n+ (1 + \u2016\u03b8\u2217\u20162) n \u2211\nk=1\n\u03b32ke \u2212\u00b5(1\u2212\u03b2)\n\u2211n j=k \u03b3j + C\nn\u22121 \u2211\nk=1\n(\u03b3k+1 \u2212 \u03b3k)e\u2212\u00b5(1\u2212\u03b2) \u2211n j=k+1 \u03b3j\n] 1 2\nwhere C = 2(2 + \u03b2)(d+ 4)B(s0) ( \u2016\u03b80\u20162+d+\u2016\u03b8 \u2217\u20162\n1\u2212\u03b2\n)2 .\n5.1.3 Derivation of rates\nProof. (High probability bound in Theorem 1) Note that when \u03b3n = c0c (c+n) ,\nn \u2211\ni=1\nL2i \u2264 n \u2211\ni=1\nc20c 2\n(c+ i)2\n[\ne \u2212\u00b5(1\u2212\u03b2)c0c\nn \u2211\nj=i\n1 (c+j)\n[\n1 + c0c\nc+ i +\nn\u22121 \u2211\nk=i\n(\nc0c c+ k \u2212 c0c c+ k + 1\n)\n] [1 + \u03b2(3\u2212 \u03b2)]B\u2032 ]\n\u2264 [1 + \u03b2(3\u2212 \u03b2)]B\u2032 n \u2211\ni=1\nc20c 2\n(c+ i)2\n(\nc+ i\nc+ n\n)\u00b5(1\u2212\u03b2)c0c [\n2 +\nn\u22121 \u2211\nk=i\nc0c\n(c+ k)(c + k + 1)\n]\n\u2264 [2 + c0c] [1 + \u03b2(3\u2212 \u03b2)]B \u2032\n(c+ n)\u00b5(1\u2212\u03b2)c0c\nn \u2211\ni=1\nc20c 2\n(c+ i)2\u2212\u00b5(1\u2212\u03b2)c0c\nWe now find three regimes for the rate of convergence, based on the choice of c: (i) \u2211n\ni=1 L 2 i = O\n( (n+ c)\u00b5(1\u2212\u03b2) 2c )\nwhen \u00b5(1\u2212 \u03b2)c0c \u2208 (0, 1), (ii)\n\u2211n i=1 L 2 i = O\n( n\u22121(ln n)2 ) when \u00b5(1\u2212 \u03b2)c0c = 1, and (iii)\n\u2211n i=1 L 2 i \u2264\n[2+c0c][1+\u03b2(3\u2212\u03b2)]c20c 2B\u2032\n\u00b5(1\u2212\u03b2)c0c\u22121 (n+ c)\u22121 when \u00b5(1\u2212 \u03b2)c0c \u2208 (1,\u221e).\n(We have used comparisons with integrals to bound the summations.) Setting c so that we are in regime (iii), the high probability bound from Proposition 1 gives\nP(\u2016\u03b8n \u2212 \u03b8\u2217\u20162 \u2212 E \u2016\u03b8n \u2212 \u03b8\u2217\u20162 \u2265 \u01eb) \u2264 exp ( \u2212\u01eb 2(n+ c)\n2K\u00b5,c,\u03b2\n)\n(33)\nwhere K\u00b5,c,\u03b2 := [2+c0c][1+\u03b2(3\u2212\u03b2)]c20c 2B\u2032\n\u00b5(1\u2212\u03b2)c0c\u22121 (n+ c)\u22121.\nProof. (Expectation bound in Theorem 1) For the expectation bound, the rate derivation involves bounding each term on the RHS in (27) after choosing step-sizes \u03b3n = c0c (c+n) . Supposing that c is again chosen so that (1\u2212 \u03b2)c0\u00b5c > 1 we have:\nn \u2211\nk=1\n\u03b32ke \u2212\u00b5(1\u2212\u03b2)\u0393nk \u2264\nn \u2211\nk=1\nc20c\n(c+ k)2 e\u2212\u00b5(1\u2212\u03b2)c0c\n\u2211n i=k 1 c+i\n\u2264 c 2 0c 2\n(c+ n)(\u00b5(1\u2212 \u03b2)c0c\u2212 1)\nn \u2211\nk=1\nc20c\n(c+ k)2\u2212\u00b5(1\u2212\u03b2)c0c \u2264 c\n2 0c 2\n\u00b5(1\u2212 \u03b2)c0c\u2212 1 1 c+ n\nand similarly\nn\u22121 \u2211\nk=1\n(\u03b3k+1 \u2212 \u03b3k)e\u2212\u00b5(1\u2212\u03b2)\u0393 n k+1 \u2264 2c0c \u00b5(1\u2212 \u03b2)c0c\u2212 1 1 c+ n\nwhere we have again compared the sums with integrals. Also\ne\u2212(1\u2212\u03b2)\u00b5\u0393 n 1 \u2264\n(\nc\nn+ c\n)(1\u2212\u03b2)\u00b5c0c \u2264 ( c\nn+ c\n) 1 2\n.\nSo from Proposition 2\nE \u2016\u03b8n \u2212 \u03b8\u2217\u20162 \u2264 ( c(\u2016\u03b80 \u2212 \u03b8\u2217\u20162 + C) (n + c)\u00b5(1\u2212\u03b2)c0c\u22121 + (1 + \u2016\u03b8\u2217\u20162)c20c2 + Cc0c \u00b5(1\u2212 \u03b2)c0c\u2212 1 ) (c+ n)\u2212 1 2 , (34)\nand the result in Theorem 1 follows.\n5.2 Iterate Averaging: Proof of Theorem 2\nIn order to prove the results in Theorem 2 we again consider the case of a general step sequence. Recall that \u03b8\u0304n+1 := (\u03b81+ . . .+\u03b8n)/n and let zn = \u03b8\u0304n+1\u2212\u03b8\u2217. We directly give a bound on the error in high probability for the averaged iterates (the bound in expectation can be obtained directly from the bound in Theorem 2):\nProposition 3. Suppose that \u2200n > n0, \u03b3n \u2264 \u00b5(1\u2212 \u03b2)/(2(1 + \u03b2)2). Then, under (A1)-(A5) and (A6\u2019), and we have, \u2200\u01eb \u2265 0 and \u2200n > n0,\nP (\u2016zn\u20162 \u2212 E \u2016zn\u20162 \u2265 \u01eb) \u2264 e\u2212\u01eb 2(2 \u2211n i=1 L 2 i )\n\u22121\n,\nwhere Li := \u03b3i n\n(\n1 + \u2211n\u22121\nl=i+1\n[\ne\u2212\u00b5(1\u2212\u03b2) \u2211l k=i \u03b3k(1 + [\u03b3i + \u2211l k=i[\u03b3k \u2212 \u03b3k+1]][1 + \u03b2(3\u2212 \u03b2)]B\u2032) ] 1 2\n)\n.\nProof. The overall schema of this proof is similar to that used for proving Proposition 1, which is used for establishing a high probability bound of non-averaged TD(0).\nWe first decompose the centered error \u2016zn\u20162 \u2212E \u2016zn\u20162 into a sum of martingale differences as follows:\n\u2016zn\u20162 \u2212 E \u2016zn\u20162 = n \u2211\nk=1\nDk, (35)\nwhere Dk := gk \u2212 E[gk |Fk\u22121 ] and gk := \u2211l k=1 E[\u2016zn\u20162 |Fk ]. We need to prove that the functions gk are Lipschitz continuous in the random innovation at time k with the new constants Lk. Let \u03b61k is the value of the averaged iterate \u03b8\u0304k\u22121 at instant k, \u03b6 2 k is the value of the iterate \u03b8k at instant k, and let \u0398\u0304kj (\u03b6) denote the mapping that returns the value of the averaged iterate at instant j, \u03b8\u0304j , given that \u03b8\u0304k\u22121 = \u03b61 and \u03b8k = \u03b62. Then, we have\nE\n\u2225 \u2225 \u2225 \u0398\u0304kn (\u03b6)\u2212 \u0398\u0304kn ( \u03b6 \u2032 ) \u2225 \u2225 \u2225\n2 \u2264 E\n\u2225 \u2225 \u2225 \u2225 \u2225 k \u2212 1 n ( \u03b61 \u2212 \u03b61\u2032 ) + 1 n n \u2211\nl=k\n(\n\u0398kl ( \u03b62 ) \u2212\u0398kl ( \u03b62 \u2032 ))\n\u2225 \u2225 \u2225 \u2225 \u2225\n2\n\u2264 k \u2212 1 n \u2225 \u2225\u03b61 \u2212 \u03b6 \u20321 \u2225 \u2225 2\n+ 1\nn\nn \u2211\nl=k\n[\ne\u2212\u00b5(1\u2212\u03b2) \u2211l j=k \u03b3j (1 + [\u03b3k +\nl \u2211\nj=k\n[\u03b3j \u2212 \u03b3j+1]][1 + \u03b2(3\u2212 \u03b2)]B\u2032) ] 1 2 \u2225 \u2225\u03b62 \u2212 \u03b6 \u20322 \u2225 \u2225\n2 . (36)\nIn the above, we have used (25) derived in the proof of Proposition 1 to bound \u2225 \u2225\n\u2225\u0398kl ( \u03b62 ) \u2212\u0398kl ( \u03b62 \u2032 )\u2225 \u2225 \u2225\n2 .\nThe rest of the proof amounts to showing that gk (and also Dk) is Lk-Lipschitz in the random innovation at time k and this follows in a similar manner as the proof of Proposition 1.\n5.2.1 Derivation of rates: High Probability Bound in Theorem 2\nFor the rate of the bound in high probability, one has to again separately bound the influence of the first n0 steps, and then use the expectation bound together with 3.\nProof. (High probability bound in Theorem 2) We perform the calculation:\nn \u2211\ni=n0\nL2i =\nn \u2211\ni=n0\n\n \u03b3i n\n\n1 +\nn\u22121 \u2211\nl=i+1\n[\ne\u2212\u00b5(1\u2212\u03b2)\u0393 n i\n(\n1 +\n[\n\u03b3i +\nn\u22121 \u2211\nk=i\n[\u03b3k \u2212 \u03b3k+1] ] [1 + \u03b2(3\u2212 \u03b2)]B\u2032 )]\n1 2 \n\n\n\n2\n\u2264 n \u2211\ni=1\n[\n\u03b3i n\n(\n1 + ( 1 + [ 1 +C \u2032 ] [1 + \u03b2(3\u2212 \u03b2)]B\u2032 )\nn\u22121 \u2211\nl=i+1\ne\u2212 \u00b5(1\u2212\u03b2) 2 \u0393ni\n)]2\n= 1\nn2\nn \u2211\ni=1\n[\nc0\n(\nc\nc+ i\n)\u03b1 (\n1 + ( 1 + [ 1 + C \u2032 ] [1 + \u03b2(3\u2212 \u03b2)]B\u2032 )\nn\u22121 \u2211\nl=i+1\ne\u2212 \u00b5(1\u2212\u03b2) 2 \u0393ni\n)]2\n\u2264 [ 1 + C \u2032 ] [1 + \u03b2(3 \u2212 \u03b2)]B\u2032 ( 2c0 \u00b5(1\u2212 \u03b2)c0n\n)2 n \u2211\ni=1\n[(\nc+ i+ 2\nc+ i\n)\u03b1\n+\n1\n(c+ i)\u03b1\nn\u22121 \u2211\nl=i\ne\u2212 \u00b5(1\u2212\u03b2)c0 2 c\u03b1 ((c+l) 1\u2212\u03b1\u2212(c+i)1\u2212\u03b1) 1\u2212\u03b1 .((c + l + 2)\u03b1 \u2212 (c+ l + 1)\u03b1)\n]2\n\u2264 [ 1 + C \u2032 ] [1 + \u03b2(3 \u2212 \u03b2)]B\u2032 (\n2\n\u00b5(1\u2212 \u03b2)n\n)2 {\n3\u03b1 +\n[\n4\u03b1\n\u00b5(1\u2212 \u03b2)c0c\u03b1 +\n2\u03b1\n\u03b1\n]2 }\nn\nwhere C \u2032 := \u2211\u221e k=1 k \u22122\u03b1. In the second equality we have substituted \u03b3i = (1\u2212 \u03b2)\n(\nc c+n\n)\u03b1 . For the second\ninequality we have used discrete integration by parts (see page 15 in Fathi and Frikha [2013], display (2.2), for details). For the last inequality we have noted, as in page 15 in Fathi and Frikha [2013], that\nn\u22121 \u2211\nl=i+1\ne\u2212 \u00b5(1\u2212\u03b2)c0 2 c\u03b1(1\u2212\u03b2)2((c+l)1\u2212\u03b1\u2212(c+i)1\u2212\u03b1)/(1\u2212\u03b1) ((c+ l + 2)\u03b1 \u2212 (c+ l + 1)\u03b1)\n\u2264 1 1\u2212 \u03b1e \u00b5(1\u2212\u03b2)c0 2 c\u03b1(1\u2212\u03b2)2(c+i)1\u2212\u03b1/(1\u2212\u03b1)\n\u222b (c+n)1\u2212\u03b1\n(c+i+1)1\u2212\u03b1 e\n\u00b5(1\u2212\u03b2)c0 2 c\u03b1(1\u2212\u03b2)2l/(1\u2212\u03b1)l 2\u03b1\u22121 1\u2212\u03b1 dl. (37)\nNow, by taking the derivative and setting it to zero, we find that\nl 7\u2192 e \u00b5(1\u2212\u03b2)c0 2 c(1\u2212\u03b2)l/(1\u2212\u03b1)l 2\u03b1 1\u2212\u03b1\nis decreasing on [4\u03b1/(\u00b5(1 \u2212 \u03b2)c0)c\u03b1(1 \u2212 \u03b2),\u221e), and so we deduce that (37)\u2264 (c + i + 1)\u03b1/\u03b1 when c+ i \u2265 4\u03b1/ (\u00b5(1\u2212 \u03b2)c0). When c+ i < 4\u03b1/ (\u00b5(1\u2212 \u03b2)c0) we use that the summand is bounded by 1.\n5.2.2 Derivation of rates: Expectation bound in Theorem 2\nTo bound the expected error we average the errors of the non-averaged iterates. However, this averaging this is not straightforward as the bound in Theorem 2 holds only if n > n0 (which ensures that \u03b3n is sufficiently small). Note that n0 can be easily derived from the specific form of the step sequece. Hence we analyse the initial phase (n < n0) and later phase n \u2265 n0 separately as follows:\nE \u2016zn\u20162 \u2264 \u2211n0 k=1 E \u2016\u03b8k \u2212 \u03b8\u2217\u20162 n + \u2211n k=n0+1 E \u2016\u03b8k \u2212 \u03b8\u2217\u20162 n\nThe last term on RHS above is bounded using Theorem 1, while the first term is bounded by unrolling TD(0) recursion for the first n0 steps and bounding the individual terms that arise using (A6).\nProof. (Expectation bound in Theorem 2) Let n > n0. Then, with \u03b3n = c0 (c/(c + n)) \u2212\u03b1, from the statement of Proposition 1, we have\nE \u2016\u03b8n \u2212 \u03b8\u2217\u20162 \u2264 e \u2212\n\u00b5c\u03b1(1\u2212\u03b2)c0 2(1\u2212\u03b1)\n((n+c)1\u2212\u03b1\u2212(c+n0)1\u2212\u03b1)(\u2016\u03b80 \u2212 \u03b8\u2217\u20162 + C)\n+ (1 + \u2016\u03b8\u2217\u20162) 1 2\n\n\nn \u2211\nk=n0\nc20\n(\nc\nk + c+ 1\n)2\u03b1\n2e\u2212 \u00b5(1\u2212\u03b2)c0c\n\u03b1\n1\u2212\u03b1 ((n+c)1\u2212\u03b1\u2212(k+1+c)1\u2212\u03b1\n\n\n1 2\n+ C 1 2\n\n\nn \u2211\nk=n0\nc0\n((\nc\nk + c\n)\u03b1 \u2212 (\nc\nk + c+ 1\n)\u03b1)\n2e\u2212 \u00b5(1\u2212\u03b2)c0c\n\u03b1\n1\u2212\u03b1 ((n+c)1\u2212\u03b1\u2212(k+1+c)1\u2212\u03b1\n\n\n1 2\n\u2264e\u2212 \u00b5c\u03b1(1\u2212\u03b2)c0 2(1\u2212\u03b1) ((n+c)1\u2212\u03b1\u2212(c+n0)1\u2212\u03b1)\n[\n(\u2016\u03b80 \u2212 \u03b8\u2217\u20162 + C)\n+ [ (1 + \u2016\u03b8\u2217\u20162) 1 2 c\u03b1c0 + (Cc0c \u03b1) 1 2 ]\n{ \u222b n\n0 x\u22122\u03b12e\n\u00b5(1\u2212\u03b2)c0c \u03b1\n1\u2212\u03b1 x1\u2212\u03b1dx\n} 1 2\n]\n\u2264e\u2212 \u00b5c\u03b1(1\u2212\u03b2)c0 2(1\u2212\u03b1) ((n+c)1\u2212\u03b1\u2212(c+n0)1\u2212\u03b1)\n[\n(\u2016\u03b80 \u2212 \u03b8\u2217\u20162 + C)\n+ [ (1 + \u2016\u03b8\u2217\u20162) 1 2 c\u03b1c0 + (Cc0c \u03b1) 1 e ]\n\n\n\n(\n\u00b5(1\u2212 \u03b2)c0c\u03b1 1\u2212 \u03b1\n)\u22122\u03b1 \u222b ( \u00b5(1\u2212\u03b2)c0c \u03b1\n1\u2212\u03b1\n)1/(1\u2212\u03b1) n\n0 y\u22122\u03b12ey 1\u2212\u03b1 dy\n\n\n\n1 2 ]\n\u2264e\u2212 \u00b5c\u03b1(1\u2212\u03b2)c0 2(1\u2212\u03b1) ((n+c)1\u2212\u03b1\u2212(c+n0)1\u2212\u03b1)\n[\n(\u2016\u03b80 \u2212 \u03b8\u2217\u20162 + C)\n+ [ (1 + \u2016\u03b8\u2217\u20162) 1 2 c\u03b1c0 + (Cc0c \u03b1) 1 2 ]\n{\n(\n\u00b5(1\u2212 \u03b2)c0c\u03b1 1\u2212 \u03b1\n)\u22122\u03b1\n.\n\u222b\n( \u00b5(1\u2212\u03b2)c0c \u03b1\n1\u2212\u03b1\n)1/(1\u2212\u03b1) n\n0 ((1\u2212 \u03b1)y\u22122\u03b1 \u2212 \u03b1y\u2212(1+\u03b1))2ey1\u2212\u03b1dy\n} 1 2 ]\n\u2264e\u2212 \u00b5c\u03b1(1\u2212\u03b2)c0\n2(1\u2212\u03b1) ((n+c)1\u2212\u03b1\u2212(c+n0)1\u2212\u03b1)(\u2016\u03b80 \u2212 \u03b8\u2217\u20162 + C)\n+ [ (1 + \u2016\u03b8\u2217\u20162) 1 2 c\u03b1c0 + (Cc0c \u03b1) 1 2 ]\n(\n\u00b5(1\u2212 \u03b2)c0c\u03b1 1\u2212 \u03b1\n)\u2212\u03b1 1+2\u03b1 2(1\u2212\u03b1)\n(n+ c)\u2212 \u03b1 2\nSo, recalling that\n\u03b8n0 \u2212 \u03b8\u2217 = ( n0 \u220f\nk=1\n(1 + \u03b3kan)\n)\n\u03b80 +\nd \u2211\ni=1\n\n\nn0 \u2211\nk=1\n\u03b1i(\u03c6(sk))r(sk, \u03c0(sk))\u03b3k\n\n\nn \u220f\nj=k\n(1 + \u03b3jaj)\n\n\n\n ei \u2212 \u03b8\u2217\nwe deduce that\nE \u2225 \u2225\u03b8\u0304n \u2212 \u03b8\u2217 \u2225 \u2225\n2\n\u2264 \u2211n0 k=1 E \u2016\u03b8k \u2212 \u03b8\u2217\u20162 n + \u2211n k=n0+1 E \u2016\u03b8k \u2212 \u03b8\u2217\u20162 n\n\u2264 n0\n[\n(1 + dc0c \u03b1(c+ n0) 1\u2212\u03b1)e2(1+\u03b2)c0c \u03b1(c+n0)1\u2212\u03b1) + \u2016\u03b8\u2217\u2016\n]\nn +\n\u2211n k=n0+1 E \u2016\u03b8k \u2212 \u03b8\u2217\u20162 n\n\u2264 n0\n[\n(1 + dc0c \u03b1(c+ n0) 1\u2212\u03b1)e2(1+\u03b2)c0c \u03b1(c+n0)1\u2212\u03b1) + \u2016\u03b8\u2217\u2016\n]\nn\n+ (1 + dc0c\n\u03b1(c+ n0) 1\u2212\u03b1)e2(1+\u03b2)c0c \u03b1(c+n0)1\u2212\u03b1) + \u2016\u03b8\u2217\u2016+ C n \u221e \u2211\nk=1\ne \u2212\n\u00b5c\u03b1(1\u2212\u03b2)c0 2(1\u2212\u03b1) ((k+c)1\u2212\u03b1\u2212(c+n0)1\u2212\u03b1)\n+ [ (1 + \u2016\u03b8\u2217\u20162) 1 2 c\u03b1c0 + (Cc0c \u03b1) 1 2 ]\n(\n\u00b5(1\u2212 \u03b2)c0c\u03b1 1\u2212 \u03b1\n)\u2212\u03b1 1+2\u03b1 2(1\u2212\u03b1)\n(n+ c)\u2212 \u03b1 2\n5.3 TD(0) with centering: Proof of Theorem 3\nProof. The proof proceeds along the following steps:\nStep 1: One-step expansion of the recursion (9).\n\u2016\u03b8n+1 \u2212 \u03b8\u2217\u201622 (38)\n=\u2016\u03a5 [\n(\u03b8n \u2212 \u03b8\u2217) + \u03b3(fXin (\u03b8n)\u2212 fXin (\u03b8\u0304 (m)) + E(fXin (\u03b8\u0304 (m)) | Fn) ]\n\u201622 \u2264\u2016(\u03b8n \u2212 \u03b8\u2217) + \u03b3(fXin (\u03b8n)\u2212 fXin (\u03b8\u0304 (m)) + E(fXin (\u03b8\u0304 (m)) | Fn)\u201622 \u2264 \u2016\u03b8n \u2212 \u03b8\u2217\u201622 + 2\u03b3(\u03b8n \u2212 \u03b8\u2217)T [ fXin (\u03b8n)\u2212 fXin (\u03b8\u0304 (m)) + E(fXin (\u03b8\u0304 (m)) | Fn) ]\n+ \u03b32 [ \u2225 \u2225\n\u2225 fXin (\u03b8n)\u2212 fXin (\u03b8\u0304 (m)) + E(fXin (\u03b8\u0304 (m)) | Fn)\n\u2225 \u2225 \u2225 2\n2\n]\n(39)\nwhere \u03a5(\u00b7) denotes the orthogonal projection onto the H-ball.\nStep 2: Bounding the variance using the centering term. Let\nf\u0304Xin (\u03b8n) :=fXin (\u03b8n)\u2212 fXin (\u03b8\u0304 (m)) + E(fXin (\u03b8\u0304 (m)) | Fn) =fXin (\u03b8n)\u2212 fXin (\u03b8 \u2217)\u2212 (fXin (\u03b8\u0304 (m))\u2212 fXin (\u03b8 \u2217)) + E(fXin (\u03b8\u0304 (m))\u2212 fXin (\u03b8\n\u2217) | Fn) + (E(fXin (\u03b8 \u2217) | Fn)\u2212 E\u03a8,\u03b8n(fXin (\u03b8 \u2217)))\nwhere we have used that E\u03a8,\u03b8n(fXin (\u03b8 \u2217)) = 0. Then, letting\nen(\u03b8) := E [ fXin (\u03b8) \u2223 \u2223Fn ] \u2212 E\u03a8,\u03b8n [ fXin (\u03b8) ]\nwe have,\nE\n(\n\u2225 \u2225f\u0304Xin (\u03b8n) \u2225 \u2225 2 2 | Fn\n)\n\u2264 E ( \u2225\n\u2225fXin (\u03b8n)\u2212 fXin (\u03b8 \u2217) \u2225 \u2225 2 2\n+ \u2225 \u2225\n\u2225 (fXin (\u03b8\u0304 (m))\u2212 fXin (\u03b8 \u2217)) + E(fXin (\u03b8\u0304 (m))\u2212 fXin (\u03b8 \u2217) | Fn)\n\u2225 \u2225 \u2225 2\n2 + \u2016en(\u03b8\u2217)\u201622 | Fn\n)\n\u2264 E ( \u2225\n\u2225fXin (\u03b8n)\u2212 fXin (\u03b8 \u2217) \u2225 \u2225 2 2\n\u2223 \u2223 \u2223Fn ) + E\n(\n\u2225 \u2225 \u2225fXin (\u03b8\u0304 (m))\u2212 fXin (\u03b8 \u2217) \u2225 \u2225 \u2225 2\n2\n\u2223 \u2223 \u2223 \u2223 Fn ) + E ( \u2016en(\u03b8\u2217)\u201622 | Fn ) ,\n(40)\nwhere we have used that for any random variable X, E(\u2016X \u2212 EX\u20162) \u2264 E(\u2016X\u20162). Let\n\u01ebn(\u03b8) = E ( \u2225 \u2225fXin (\u03b8)\u2212 fXin (\u03b8 \u2217) \u2225 \u2225 2 2\n\u2223 \u2223 \u2223Fn ) \u2212 E\u03a8,\u03b8n( \u2225 \u2225fXin (\u03b8)\u2212 fXin (\u03b8 \u2217) \u2225 \u2225 2 2 ).\nThe second term in \u01ebn(\u03b8) can be bounded as follows: For any \u03b8, we have\nE\u03a8,\u03b8n( \u2225 \u2225fXin (\u03b8)\u2212 fXin (\u03b8 \u2217) \u2225 \u2225 2 2 )\n=(\u03b8 \u2212 \u03b8\u2217)TE\u03a8,\u03b8n [(\u03b2\u03c6(sn+1)\u2212 \u03c6(sn))\u03c6(sn)T\u03c6(sn)(\u03b2\u03c6(sn+1)\u2212 \u03c6(sn))T] (\u03b8 \u2212 \u03b8\u2217) =(\u03b8 \u2212 \u03b8\u2217)T (\u03a6T(I \u2212 \u03b2P )\u03a8\u03a6)T \u03a6T\u03a8(I \u2212 \u03b2P )\u03a6(\u03b8 \u2212 \u03b8\u2217) \u2264(\u03b8 \u2212 \u03b8\u2217)T (\u03a6T\u03a8\u03a6)T \u03a6T\u03a8\u03a6(\u03b8 \u2212 \u03b8\u2217) \u2264d2\u2016\u03a6(\u03b8 \u2212 \u03b8\u2217)\u20162\u03a8. (41)\nIn the final inequality, we have used \u2016\u03a6T\u03a8\u03a6\u20162 \u2264 d2. Plugging the above in (40), we obtain\nE\n(\n\u2225 \u2225f\u0304Xin (\u03b8n) \u2225 \u2225 2 2\n\u2223 \u2223 \u2223Fn ) \u2264d2 ( \u2016\u03a6(\u03b8n \u2212 \u03b8\u2217)\u20162\u03a8 + \u2016\u03a6(\u03b8\u0304(m) \u2212 \u03b8\u2217)\u20162\u03a8 )\n+ \u01ebn(\u03b8n) + \u01ebn(\u03b8\u0304 (m)) + E\n( \u2016en(\u03b8\u2217)\u201622 | Fn )\nStep 3: Analysis for a particular epoch. Using the last display, we calculate,\nE ( \u2016\u03b8n+1 \u2212 \u03b8\u2217\u201622 \u2223 \u2223Fn ) \u2264 \u2016\u03b8n \u2212 \u03b8\u2217\u201622 + 2\u03b3(\u03b8n \u2212 \u03b8\u2217)TE [ f\u0304Xin (\u03b8n) \u2223 \u2223Fn ]\n+ \u03b32 ( d2 ( \u2016\u03a6(\u03b8n \u2212 \u03b8\u2217)\u20162\u03a8 + \u2016\u03a6(\u03b8\u0304(m) \u2212 \u03b8\u2217)\u20162\u03a8 ) + \u01ebn(\u03b8n) + \u01ebn(\u03b8\u0304 (m)) + E ( \u2016en(\u03b8\u2217)\u201622 | Fn ) )\n= \u2016\u03b8n \u2212 \u03b8\u2217\u201622 + 2\u03b3(\u03b8n \u2212 \u03b8\u2217)TE [ fXin (\u03b8n) \u2223 \u2223Fn ]\n(42)\n+ \u03b32 ( d2 ( \u2016\u03a6(\u03b8n \u2212 \u03b8\u2217)\u20162\u03a8 + \u2016\u03a6(\u03b8\u0304(m) \u2212 \u03b8\u2217)\u20162\u03a8 ) + \u01ebn(\u03b8n) + \u01ebn(\u03b8\u0304 (m)) + E ( \u2016en(\u03b8\u2217)\u201622 | Fn ) ) .\nThe equality above uses the fact that E [ f\u0304Xin (\u03b8n) \u2223 \u2223Fn ] = E [ fXin (\u03b8n) \u2223 \u2223Fn ] , since\nfXin (\u03b8\u0304 (m))\u2212 E\n[\nfXin (\u03b8\u0304 (m))\n\u2223 \u2223 \u2223Fn ]\nis a martingale difference w.r.t. Fn. We can rewrite (42) as\nE ( \u2016\u03b8n+1 \u2212 \u03b8\u2217\u201622 \u2223 \u2223Fn ) \u2264 \u2016\u03b8n \u2212 \u03b8\u2217\u201622 + 2\u03b3(\u03b8n \u2212 \u03b8\u2217)TE\u03a8,\u03b8n [ fXin (\u03b8n) ] + 2\u03b3(\u03b8n \u2212 \u03b8\u2217)Ten(\u03b8n)\n+ \u03b32 ( d2 ( \u2016\u03a6(\u03b8n \u2212 \u03b8\u2217)\u20162\u03a8 + \u2016\u03a6(\u03b8\u0304(m) \u2212 \u03b8\u2217)\u20162\u03a8 ) + \u01ebn(\u03b8n) + \u01ebn(\u03b8\u0304 (m)) + E ( \u2016en(\u03b8\u2217)\u201622 | Fn )) (43)\nNotice that E\u03a8,\u03b8n [ fXin (\u03b8 \u2217) ] = 0 and hence\nE\u03a8,\u03b8n\n[ fXin (\u03b8n) ] = E\u03a8,\u03b8n((\u03b2\u03c6(sn+1)\u2212 \u03c6(sn))\u03c6(sn)T)(\u03b8n \u2212 \u03b8\u2217) = (\u03a6T\u03a8(I \u2212 \u03b2P )\u03a6)(\u03b8n \u2212 \u03b8\u2217).\nUsing the above, we can simplify (43) as follows:\nE ( \u2016\u03b8n+1 \u2212 \u03b8\u2217\u201622 \u2223 \u2223Fn )\n\u2264\u2016\u03b8n \u2212 \u03b8\u2217\u201622 + \u03b32d2 ( \u2016\u03a6(\u03b8n \u2212 \u03b8\u2217)\u20162\u03a8 + \u2016\u03a6(\u03b8\u0304(m) \u2212 \u03b8\u2217)\u20162\u03a8 ) \u2212 2\u03b3(\u03b8n \u2212 \u03b8\u2217)T [\u03a6T\u03a8(I \u2212 \u03b2P )\u03a6]\n+ 2\u03b3(\u03b8n \u2212 \u03b8\u2217)Ten(\u03b8n) + \u03b32\u01ebn(\u03b8n) + \u03b32\u01ebn(\u03b8\u0304(m)) + E ( \u2016en(\u03b8\u2217)\u201622 | Fn )\n\u2264\u2016\u03b8n \u2212 \u03b8\u2217\u201622 \u2212 2\u03b3((1 \u2212 \u03b2)\u2212 d2\u03b3\n2 )\u2016\u03a6(\u03b8n \u2212 \u03b8\u2217)\u20162\u03a8 + \u03b32d2\u2016\u03a6(\u03b8\u0304(m) \u2212 \u03b8\u2217)\u20162\u03a8\n+ 2\u03b3(\u03b8n \u2212 \u03b8\u2217)Ten(\u03b8n) + \u03b32\u01ebn(\u03b8n) + \u03b32\u01ebn(\u03b8\u0304(m)) + E ( \u2016en(\u03b8\u2217)\u201622 | Fn )\n(44)\nUnrolling the above recursion within an epoch, i.e., from n = (m+ 1)M \u2212 1 to n = mM , we obtain\nE ( \u2016\u03b8(m+1)M\u22121 \u2212 \u03b8\u2217\u201622 \u2223 \u2223Fn ) \u2264 \u2016\u03b8mM \u2212 \u03b8\u2217\u201622\n\u2212 (m+1)M\u22122 \u2211\nn=mM\n2\u03b3((1\u2212 \u03b2)\u2212 d 2\u03b3\n2 )E\n( \u2016\u03a6(\u03b8n \u2212 \u03b8\u2217)\u20162\u03a8 \u2223 \u2223FmM\u22121 ) +M\u03b32d2\u2016\u03a6(\u03b8\u0304(m) \u2212 \u03b8\u2217)\u20162\u03a8\n+ E\n\n\n(m+1)M\u22122 \u2211\nn=mM\n2\u03b3(\u03b8n \u2212 \u03b8\u2217)Ten(\u03b8n) + \u03b32 ( \u01ebn(\u03b8n) + \u01ebn(\u03b8\u0304 (m)) + E ( \u2016en(\u03b8\u2217)\u201622 | Fn ))\n\u2223 \u2223 \u2223 \u2223 \u2223 \u2223 FmM\u22121  \n(45)\nNotice that (\u03b8\u0304(m) \u2212 \u03b8\u2217)TI(\u03b8\u0304(m) \u2212 \u03b8\u2217) \u2264 1 \u00b5 (\u03b8\u0304(m) \u2212 \u03b8\u2217)T\u03a6T\u03a8\u03a6(\u03b8\u0304(m) \u2212 \u03b8\u2217) and hence we obtain the\nfollowing by setting \u03b8mM = \u03b8\u0304(m) and ignoring the non-negative LHS term:\n2\u03b3M ((1\u2212 \u03b2)\u2212 d 2\u03b3\n2 )E\n( \u2016\u03a6(\u03b8\u0304(m+1) \u2212 \u03b8\u2217)\u20162\u03a8 \u2223 \u2223 \u2223 FmM )\n\u2264 ( 1\n\u00b5 +M\u03b32d2\n) \u2016\u03b8\u0304(m) \u2212 \u03b8\u2217\u201622 + \u03b32 (m+1)M\u22122 \u2211\nn=mM\nE\n(\n\u01ebn(\u03b8n) + \u01ebn(\u03b8\u0304 (m)) + \u2016en(\u03b8\u2217)\u201622\n\u2223 \u2223 \u2223FmM )\n+ E\n\n2\u03b3\n(m+1)M\u22121 \u2211\nn=mM\n(\u03b8n \u2212 \u03b8\u2217)Ten(\u03b8n)\n\u2223 \u2223 \u2223 \u2223 \u2223 \u2223 FmM  \nStep 4: Combining across epochs.\nLet C1 :=\n\n  \n1\n2\u00b5\u03b3M((1 \u2212 \u03b2)\u2212 d 2\u03b3\n2 )\n+ \u03b3d2\n2((1 \u2212 \u03b2)\u2212 d 2\u03b3\n2 )\n\n   . Then, we have\nE ( \u2016\u03a6(\u03b8\u0304(m) \u2212 \u03b8\u2217)\u20162\u03a8 \u2223 \u2223 \u2223F0 )\n\u2264 Cm1 \u2016\u03b8\u0304(0) \u2212 \u03b8\u2217\u201622 + \u03b3C2 2\nm\u22121 \u2211\nk=1\nC (m\u22122\u2212k) 1\nkM\u22121 \u2211\ni=(k\u22121)M\nE\n(\n\u01ebi(\u03b8i) + \u01ebi(\u03b8\u0304 ((k\u22121)M)) + \u2016ei(\u03b8\u2217)\u201622\n\u2223 \u2223 \u2223F0 )\n+ C2\nm\u22121 \u2211\nk=1\nC (m\u22122\u2212k) 1\nkM\u22121 \u2211\ni=(k\u22121)M\nE ((\u03b8i \u2212 \u03b8\u2217)Tei(\u03b8i)| F0) ,\nwhere C2 = \u03b3\n2M((1 \u2212 \u03b2)\u2212 d 2\u03b3\n2 )\n.\nStep 5: Controlling the error terms. First note that\n\u01eb(\u03b8) =E ( \u2016(\u03b2\u03c6(sn)\u03c6(sn+1)T \u2212 \u03c6(sn)\u03c6(sn))(\u03b8 \u2212 \u03b8\u2217)T\u201622 | Fn )\n\u2212 E\u03a8,\u03b8n ( \u2016(\u03b2\u03c6(sn)\u03c6(sn+1)T \u2212 \u03c6(sn)\u03c6(sn))(\u03b8 \u2212 \u03b8\u2217)T\u201622 )\n=(\u03b8 \u2212 \u03b8\u2217)T [E(vTv | Fn)\u2212 E\u03a8,\u03b8n(vTv)] (\u03b8 \u2212 \u03b8\u2217)\nwhere v = \u03b2\u03c6(sn)\u03c6(sn+1)T \u2212\u03c6(sn)\u03c6(sn). Supposing that \u2016(\u03b8 \u2212 \u03b8\u2217)\u20162 \u2264 H , and using that \u2016\u03c6(sn)\u20162 \u2264 1 together with the convexity of matrix inner products in the \u2016\u00b7\u20162-matrix norm, we have that\n\u2016\u01eb(\u03b8)\u20162 \u2264 2H \u2016E(v | Fn)\u2212 E\u03a8,\u03b8n(v)\u20162 So by (A6), and the fact the projection step of the algorithm, we have\nkM\u22121 \u2211\ni=(k\u22121)M\nE\n(\n\u2225 \u2225 \u2225 \u01ebi(\u03b8i) + \u01ebi(\u03b8\u0304 ((k\u22121)M)) \u2225 \u2225 \u2225 2\n2\n\u2223 \u2223 \u2223 \u2223 F0 ) \u2264 8HBkM(k\u22121)M (s0). (46)\nSimilarly\nkM\u22121 \u2211\ni=(k\u22121)M\nE\n( \u2016ei(\u03b8\u2217)\u201622 \u2223 \u2223 \u2223 F0 ) , kM\u22121 \u2211\ni=(k\u22121)M\nE ((\u03b8i \u2212 \u03b8\u2217)Tei(\u03b8i)| F0) \u2264 2HBkM(k\u22121)M (s0)\n6 Numerical Experiments\nWe test the performance of TD(0), TD(0) with averaging and CTD algorithms.\nExample 1. This is a two-state toy example, which is borrowed from [Yu and Bertsekas, 2009]. The setting has the transition structure P = [0.2, 0.8; 0.3, 0.7] and the rewards given by r(1, j) = 1, r(2, j) = 2, for j = 1, 2. The features are one-dimensional, i.e., \u03a6 = (1 2)T.\nFig. 2(a) presents the results obtained on this example. For setting the step-sizes of TD(0), we used the guideline from Theorem 1. Note that this results in convergence for TD(0), with the caveat that setting the step-size constant c requires knowledge of underlying transition structure through \u00b5. It is evident that TD(0) with averaging gives performance on par with TD(0) and unlike TD(0), the setting of c is not constrained\nhere. Given that convergence is rapid for TD(0) on this example, we do not plot CTD in Fig 2(a) as the epoch length suggested by Theorem 3 is 100 and this is already enough for TD(0) itself to converge. CTD resulted in a normalized value difference of about 0.03 on this example, but the effect of averaging across epochs for CTD will be seen better in the next example.\nExample 2. Here the number of states are 100, the transitions are governed by a random stochastic matrix and the rewards are random and bounded between 0 and 1. Features are 3-dimensional and are picked randomly in (0, 1). The results obtained for the three algorithms are presented in Fig. 2(b). It is evident that all algorithms converge, with CTD showing the lowest variance. As in example 1, the setting parameters for TD(0) was dictated by Theorem 1, while for CTD, the step-size and epoch length were set such that the constant C1 in Theorem 3 is less than 1.\n7 Conclusions\nTD(0) with linear function approximators is a well-known policy evaluation algorithm. While asymptotic convergence rate results are available for this algorithm, there are no finite-time bounds that quantify the rate of convergence. In this paper, we derived non-asymptotic bounds, both in high-probability as well as in expectation. From our results, we observed that iterate averaging is necessary to obtain the optimal O (1/ \u221a n) rate of convergence. This is because, to obtain the optimal rate with the classic step-size choice \u221d 1/n, it is necessary to know properties of the stationary distribution of the underlying Markov chain. We also proposed a fast variant of TD(0) that incorporates a centering sequence and established that the rate of convergence of this algorithm is exponential. We established the practicality of our bounds by using them to guide the step-size choices in two synthetic experimental setups.\nReferences\nDimitri P Bertsekas. Approximate dynamic programming. 2011.\nS. Bhatnagar, R. Sutton, M. Ghavamzadeh, and M. Lee. Natural actor-critic algorithms. Automatica, 45 (11):2471\u20132482, 2009.\nMax Fathi and Noufel Frikha. Transport-entropy inequalities and deviation estimates for stochastic approximation schemes. arXiv preprint arXiv:1301.7740, 2013.\nNoufel Frikha and St\u00e9phane Menozzi. Concentration Bounds for Stochastic Approximations. Electron. Commun. Probab., 17:no. 47, 1\u201315, 2012.\nRie Johnson and Tong Zhang. Accelerating stochastic gradient descent using predictive variance reduction. In Advances in Neural Information Processing Systems (NIPS), pages 315\u2013323, 2013.\nVijay R Konda. Actor-Critic Algorithms. PhD thesis, Department of Electrical Engineering and Computer Science, MIT, 2002.\nVijay R Konda and John N Tsitsiklis. On Actor-Critic Algorithms. SIAM journal on Control and Optimization, 42(4):1143\u20131166, 2003.\nAlessandro Lazaric, Mohammad Ghavamzadeh, and R\u00e9mi Munos. Finite-sample analysis of lstd. In ICML, pages 615\u2013622, 2010.\nSean P Meyn and Richard L Tweedie. Markov chains and stochastic stability. Cambridge university press, 2009.\nBoris T Polyak and Anatoli B Juditsky. Acceleration of stochastic approximation by averaging. SIAM Journal on Control and Optimization, 30(4):838\u2013855, 1992.\nDavid Ruppert. Stochastic approximation. Handbook of Sequential Analysis, pages 503\u2013529, 1991.\nRichard S Sutton and Andrew G Barto. Reinforcement learning: An introduction, volume 1. Cambridge Univ Press, 1998.\nJohn N Tsitsiklis and Benjamin Van Roy. An analysis of temporal-difference learning with function approximation. IEEE Transactions on Automatic Control, 42(5):674\u2013690, 1997.\nHuizhen Yu and Dimitri P Bertsekas. Convergence results for some temporal difference methods based on least squares. IEEE Transactions on Automatic Control, 54(7):1515\u20131531, 2009."}], "references": [{"title": "Approximate dynamic programming", "author": ["Dimitri P Bertsekas"], "venue": null, "citeRegEx": "Bertsekas.,? \\Q2011\\E", "shortCiteRegEx": "Bertsekas.", "year": 2011}, {"title": "Transport-entropy inequalities and deviation estimates for stochastic approximation schemes", "author": ["Max Fathi", "Noufel Frikha"], "venue": "arXiv preprint arXiv:1301.7740,", "citeRegEx": "Fathi and Frikha.,? \\Q2013\\E", "shortCiteRegEx": "Fathi and Frikha.", "year": 2013}, {"title": "Concentration Bounds for Stochastic Approximations", "author": ["Noufel Frikha", "St\u00e9phane Menozzi"], "venue": "Electron. Commun. Probab.,", "citeRegEx": "Frikha and Menozzi.,? \\Q2012\\E", "shortCiteRegEx": "Frikha and Menozzi.", "year": 2012}, {"title": "Accelerating stochastic gradient descent using predictive variance reduction", "author": ["Rie Johnson", "Tong Zhang"], "venue": "In Advances in Neural Information Processing Systems (NIPS),", "citeRegEx": "Johnson and Zhang.,? \\Q2013\\E", "shortCiteRegEx": "Johnson and Zhang.", "year": 2013}, {"title": "Actor-Critic Algorithms", "author": ["Vijay R Konda"], "venue": "PhD thesis, Department of Electrical Engineering and Computer Science,", "citeRegEx": "Konda.,? \\Q2002\\E", "shortCiteRegEx": "Konda.", "year": 2002}, {"title": "On Actor-Critic Algorithms", "author": ["Vijay R Konda", "John N Tsitsiklis"], "venue": "SIAM journal on Control and Optimization,", "citeRegEx": "Konda and Tsitsiklis.,? \\Q2003\\E", "shortCiteRegEx": "Konda and Tsitsiklis.", "year": 2003}, {"title": "Finite-sample analysis of lstd", "author": ["Alessandro Lazaric", "Mohammad Ghavamzadeh", "R\u00e9mi Munos"], "venue": "In ICML,", "citeRegEx": "Lazaric et al\\.,? \\Q2010\\E", "shortCiteRegEx": "Lazaric et al\\.", "year": 2010}, {"title": "Markov chains and stochastic stability", "author": ["Sean P Meyn", "Richard L Tweedie"], "venue": "Cambridge university press,", "citeRegEx": "Meyn and Tweedie.,? \\Q2009\\E", "shortCiteRegEx": "Meyn and Tweedie.", "year": 2009}, {"title": "Acceleration of stochastic approximation by averaging", "author": ["Boris T Polyak", "Anatoli B Juditsky"], "venue": "SIAM Journal on Control and Optimization,", "citeRegEx": "Polyak and Juditsky.,? \\Q1992\\E", "shortCiteRegEx": "Polyak and Juditsky.", "year": 1992}, {"title": "Stochastic approximation. Handbook of Sequential Analysis, pages 503\u2013529", "author": ["David Ruppert"], "venue": null, "citeRegEx": "Ruppert.,? \\Q1991\\E", "shortCiteRegEx": "Ruppert.", "year": 1991}, {"title": "Reinforcement learning: An introduction, volume 1", "author": ["Richard S Sutton", "Andrew G Barto"], "venue": null, "citeRegEx": "Sutton and Barto.,? \\Q1998\\E", "shortCiteRegEx": "Sutton and Barto.", "year": 1998}, {"title": "An analysis of temporal-difference learning with function approximation", "author": ["John N Tsitsiklis", "Benjamin Van Roy"], "venue": "IEEE Transactions on Automatic Control,", "citeRegEx": "Tsitsiklis and Roy.,? \\Q1997\\E", "shortCiteRegEx": "Tsitsiklis and Roy.", "year": 1997}, {"title": "Convergence results for some temporal difference methods based on least squares", "author": ["Huizhen Yu", "Dimitri P Bertsekas"], "venue": "IEEE Transactions on Automatic Control,", "citeRegEx": "Yu and Bertsekas.,? \\Q2009\\E", "shortCiteRegEx": "Yu and Bertsekas.", "year": 2009}], "referenceMentions": [{"referenceID": 5, "context": "actor-critic algorithms [Konda and Tsitsiklis, 2003], [Bhatnagar et al.", "startOffset": 24, "endOffset": 52}, {"referenceID": 0, "context": "3 of [Bertsekas, 2011]) A\u03b8 = b, where A = \u03a6T\u03a8(I \u2212 \u03b2P )\u03a6 and b = \u03a6T\u03a8r.", "startOffset": 5, "endOffset": 22}, {"referenceID": 3, "context": "A more direct approach is to center the updates, and this was pioneered recently for solving batch problems via stochastic gradient descent in convex optimization [Johnson and Zhang, 2013].", "startOffset": 163, "endOffset": 188}, {"referenceID": 2, "context": "Concentration bounds for general stochastic approximation schemes have been derived in [Frikha and Menozzi, 2012] and later expanded to include iterate averaging in [Fathi and Frikha, 2013].", "startOffset": 87, "endOffset": 113}, {"referenceID": 1, "context": "Concentration bounds for general stochastic approximation schemes have been derived in [Frikha and Menozzi, 2012] and later expanded to include iterate averaging in [Fathi and Frikha, 2013].", "startOffset": 165, "endOffset": 189}, {"referenceID": 4, "context": "An asymptotic normality result for TD(\u03bb) is available in [Konda, 2002].", "startOffset": 57, "endOffset": 70}, {"referenceID": 4, "context": "Asymptotic convergence rate results for LSTD(\u03bb) and LSPE(\u03bb), two popular least squares methods, are available in [Konda, 2002] and [Yu and Bertsekas, 2009], respectively.", "startOffset": 113, "endOffset": 126}, {"referenceID": 12, "context": "Asymptotic convergence rate results for LSTD(\u03bb) and LSPE(\u03bb), two popular least squares methods, are available in [Konda, 2002] and [Yu and Bertsekas, 2009], respectively.", "startOffset": 131, "endOffset": 155}, {"referenceID": 6, "context": "A related work in this direction is the finite time bounds for LSTD in [Lazaric et al., 2010].", "startOffset": 71, "endOffset": 93}, {"referenceID": 10, "context": "s\u2032 p(s, \u03c0(s), s)V (s), (5) TD(0) [Sutton and Barto, 1998] performs a fixed point-iteration using stochastic approximation: Starting with an arbitrary V0, update Vn(sn) := Vn\u22121(sn) + \u03b3n ( r(sn, \u03c0(sn)) + \u03b2Vn\u22121(sn+1)\u2212 Vn\u22121(sn) ) , (6) where \u03b3n are step-sizes that satisfy standard stochastic approximation conditions.", "startOffset": 33, "endOffset": 57}, {"referenceID": 7, "context": "See Chapters 15 and 16 of [Meyn and Tweedie, 2009] for a detailed treatment of the subject matter.", "startOffset": 26, "endOffset": 50}, {"referenceID": 9, "context": "This principle was introduced independently by Ruppert [Ruppert, 1991] and Polyak [Polyak and Juditsky, 1992], for accelerating stochastic approximation schemes.", "startOffset": 55, "endOffset": 70}, {"referenceID": 8, "context": "This principle was introduced independently by Ruppert [Ruppert, 1991] and Polyak [Polyak and Juditsky, 1992], for accelerating stochastic approximation schemes.", "startOffset": 82, "endOffset": 109}, {"referenceID": 3, "context": "The approach is inspired by the SVRG algorithm, proposed in [Johnson and Zhang, 2013], for a optimising a strongly-convex function.", "startOffset": 60, "endOffset": 85}, {"referenceID": 3, "context": "However, the setting for TD(0) with function approximation that we have is considerably more complicated owing to the following reasons: (i) Unlike [Johnson and Zhang, 2013], we are not optimising a function that is a finite-sum of smooth functions in a batch setting.", "startOffset": 148, "endOffset": 173}, {"referenceID": 3, "context": "(iv) Finally, there are extra difficulties owing to the fact that we have a fixed point iteration, while the corresponding algorithm in [Johnson and Zhang, 2013] is stochastic gradient descent (SGD).", "startOffset": 136, "endOffset": 161}, {"referenceID": 1, "context": "For the second inequality we have used discrete integration by parts (see page 15 in Fathi and Frikha [2013], display (2.", "startOffset": 85, "endOffset": 109}, {"referenceID": 1, "context": "For the second inequality we have used discrete integration by parts (see page 15 in Fathi and Frikha [2013], display (2.2), for details). For the last inequality we have noted, as in page 15 in Fathi and Frikha [2013], that n\u22121 \u2211", "startOffset": 85, "endOffset": 219}, {"referenceID": 12, "context": "This is a two-state toy example, which is borrowed from [Yu and Bertsekas, 2009].", "startOffset": 56, "endOffset": 80}], "year": 2015, "abstractText": "We provide non-asymptotic bounds for the well-known temporal difference learning algorithm TD(0) with linear function approximators. These include high-probability bounds as well as bounds in expectation. Our analysis suggests that a step-size inversely proportional to the number of iterations cannot guarantee optimal rate of convergence unless we assume (partial) knowledge of the stationary distribution for the Markov chain underlying the policy considered. We also provide bounds for the iterate averaged TD(0) variant, which gets rid of the step-size dependency while exhibiting the optimal rate of convergence. Furthermore, we propose a variant of TD(0) with linear approximators that incorporates a centering sequence, and establish that it exhibits an exponential rate of convergence in expectation. We demonstrate the usefulness of our bounds on two synthetic experimental settings.", "creator": "LaTeX with hyperref package"}}}