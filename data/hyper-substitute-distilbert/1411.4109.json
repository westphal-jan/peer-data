{"id": "1411.4109", "review": {"conference": "arxiv", "VERSION": "v1", "DATE_OF_SUBMISSION": "15-Nov-2014", "title": "Resolution of Difficult Pronouns Using the ROSS Method", "abstract": "applying new natural language understanding method to disambiguation employing difficult pronouns is patented. difficult pronouns complement those pronouns denote which considerable level of world variables domain name is needed in order or construct such recognition document types object resolution. resolution causes difficult features ambiguous in technical cases constitute insufficient prior step involving the application of inference through a situation that seemed fluent near the natural language language. a system architecture is described : binding means entity resolution \u2014 pronoun resolution. an extension ( the general pronoun resolution suite performs inference as an embedded abstract reasoning method. the general method is the embedded metaphor utilize features of the explicit database model ; in particular the methods create multiple programming classes into the symbolic situation model. the overall method reflects typically macro interface how solves many following winograd schemas : a ) scholar and athlete, m ) person respects person, right ) person pays someone, and d ) councilmen and demonstrators.", "histories": [["v1", "Sat, 15 Nov 2014 03:43:01 GMT  (1461kb)", "http://arxiv.org/abs/1411.4109v1", "106 pages, 2 figures"]], "COMMENTS": "106 pages, 2 figures", "reviews": [], "SUBJECTS": "cs.CL cs.AI", "authors": ["glenn r hofford"], "accepted": false, "id": "1411.4109"}, "pdf": {"name": "1411.4109.pdf", "metadata": {"source": "META", "title": "Resolution of Difficult Pronouns Using the ROSS Method", "authors": ["Glenn R. Hofford"], "emails": [], "sections": [{"heading": null, "text": "A new natural language understanding method for disambiguation of difficult pronouns is described. Difficult pronouns are those pronouns for which a level of world or domain knowledge is needed in order to perform anaphoral or other types of resolution. Resolution of difficult pronouns may in some cases require a prior step involving the application of inference to a situation that is represented by the natural language text. A general method is described: it performs entity resolution and pronoun resolution. An extension to the general pronoun resolution method performs inference as an embedded commonsense reasoning method. The general method and the embedded method utilize features of the ROSS representational scheme; in particular the methods use ROSS ontology classes and the ROSS situation model.\nROSS ontology classes include the object frame class and the behavior class. The ROSS behavior class defines associations among a set of objects that have attribute-based state descriptions and nested behaviors. In addition to the classes of the ontology, the methods use several working memory data structures, including a spanning information data structure and a pronoun feature set structure. The ROSS internal situation model (or \u201cinstance model\u201d) is an instance of a meaning representation; it is a spatial/temporal representation of declarative information from the input natural language text.\nA new representational formalism called \u201csemantic normal form\u201d (SNF) is also introduced. This is a specification at the abstract level for a set of data structures that are used to store the syntax and content of input natural language text that has been transformed and augmented with semantic role and other information. It is an intermediate form of the input information that is processable by a semantic NLU engine that implements the pronoun resolution method.\nThe overall method is a working solution that solves the following Winograd schemas: a) trophy and suitcase, b) person lifts person, c) person pays detective, and d) councilmen and demonstrators.\nMany of the features described in this paper have been productized - the functionality is implemented in an NLU system that is available for use via a RESTful API server (currently English-only).\nContact: glennhofford(at)gmail.com\nTable of Contents\n1. Introduction and Background ............................................................................................... 6\n1.1. The ROSS Representational Method ................................................................................ 7\n1.2. Background: Winograd Schema Challenge ...................................................................... 7\n2. Main Concepts .................................................................................................................... 10\n2.1. Entity Resolution Using a ROSS Ontology .................................................................... 10\n2.2. Ontology Scalability ....................................................................................................... 11\n2.3. The ROSS Instance Model.............................................................................................. 11\n2.4. Features of the ROSS Behavior Class That Support the Resolution Process ................. 12\n2.5. Definitions....................................................................................................................... 12\n2.6. Overview of the Algorithm ............................................................................................. 13\n2.7. Probability-Based Pronoun Resolution ........................................................................... 15\n2.8. Use of ROSS Situation Model to Support Question Answering .................................... 16\n2.9. Optional Representation of the Communicative Agent .................................................. 16\n2.10. Non-Objective: Representation of Deep Structure of Physical Objects ......................... 16\n2.11. Comprehendor NLU System........................................................................................... 17\n3. Pronouns: Types of Pronouns and Syntactic Locations of Pronouns ................................. 18\n4. Semantic Normal Form (SNF) ............................................................................................ 19\n4.1. The Predicate Expression (\u201cPE\u201d) .................................................................................... 19\n4.2. Semantic Role Labels ..................................................................................................... 19\n4.2.1. Predicate Specifier Roles ............................................................................................ 19\n4.2.2. Entity Argument Roles ............................................................................................... 20\n4.2.3. Extra Sub-Roles .......................................................................................................... 21\n4.3. Relative/Subordinate Clauses ......................................................................................... 21\n4.4. Attributive Argument Roles ............................................................................................ 21\n4.5. Other Argument Categories: Abstractions That Represent Aspects ............................... 22\n4.6. Other Enumerated Types ................................................................................................ 22\n4.7. The Structure of the Predicate Expression ...................................................................... 23\n4.8. SNF Example .................................................................................................................. 26\n5. NLU System Architecture and Data Flow .......................................................................... 28\n5.1. Input to a Parser: Communication Unit List ................................................................... 28\n5.2. Data Adapters (Syntax-To-Semantic-Normal-Form Converters) ................................... 29\n5.3. Semantic Engine ............................................................................................................. 31\n6. Semantic Engine Driver: Data Structures and Control Flow .............................................. 34\n6.1. Overview ......................................................................................................................... 34\n6.2. Data Structure for Master Token List ............................................................................. 34\n6.3. Data Structures and Data Types: Input to the Engine ..................................................... 34\n6.4. Data Structures and Data Types: Internal/Operational ................................................... 38\n6.5. Data Structures and Data Types: Instance Model ........................................................... 43\n6.5. Engine Driver Algorithm ................................................................................................ 44\n7. General Pronoun Resolution Method.................................................................................. 50\n8. Embedded Commonsense Reasoning Method.................................................................... 56\n9. Applications: Winograd Schemas #8, #115, #1 .................................................................. 62\n10. Conclusion: Test Results for Schemas ............................................................................ 68\nAppendix 1: Solution for \u201cTrophy and Suitcase\u201d Schema Using a Model of the Communicating\nAgent ........................................................................................................................................... 71\nAppendix 2: Ontology/Knowledge Base .................................................................................... 81\n1. Ontology and KB for Schema: \u201cTrophy and Suitcase\u201d ...................................................... 81\n2. Ontology and KB for Schema: \u201cPerson Lifts Person\u201d ........................................................ 90\n3. Ontology and KB for Schema: \u201cReceiving/Delivering and Paying\u201d .................................. 95\n4. Ontology and KB for Schema: \u201cCouncilmen and Demonstrators\u201d .................................. 102\nAppendix 3: ROSS Instance Models ........................................................................................ 103\n1. Instance Model for Schema: \u201cTrophy and Suitcase\u201d (\u201ctoo big\u201d variant) ......................... 103\n2. Instance Model for Schema: \u201cPerson Lifts Person\u201d (\u201ctoo weak\u201d variant) ........................ 104\n1. Introduction and Background\nDisambiguation of so-called \u201cdifficult\u201d pronouns is a challenging problem for natural\nlanguage processing. Although statistics-based approaches are at least partly effective for some cases, the problem calls for a semantic approach that addresses the representational aspects using deeper and more powerful techniques that involve comprehension of the meaning of natural language. The application of world knowledge and domain knowledge seem to be essential components of the cognitive processes that are used by us as humans in order to comprehend language, i.e. to grasp its meaning in a manner that allows for a reasoning process that reaches conclusions regarding the meaning (i.e. the referent) of pronouns in natural language text or spoken discourse. The challenge lies in somehow emulating this approach in software.\nA new general-use ontology-based artificial intelligence method is presented that uses a\ncomplex multi-stage set of algorithmic processes that effectively resolves important categories of ambiguous pronouns. The method creates an internal situation model of the subject matter of natural language text that enables identification of the referent and the antecedent of a pronoun 1 . A ROSS situation model is an internal memory representation of instances of objects and processes that is constructed as part of the natural language understanding process. The method uses an ontology-based approach that involves ROSS object frame classes and behavior classes. The classes of the ontology are directly involved in the creation of the situation model as they provide a basis for the instantiation of object instances and process instances.\nAn important extension to the basic method is also described. This extension involves an\nembedded inference process that performs commonsense reasoning and that is invoked for pronoun resolution problems that are not adequately handled by the basic resolution method. The embedded inference routine specifically handles natural language sentences wherein there is an indirect association between the semantics for the unresolved pronoun and the set of candidate referents. (A specific example is presented from Winograd schema #1 (\u201ccouncilmen and demonstrators\u201d).\nA second extension is described as it applies to a solution for Winograd schema #2 (\u201ctrophy\nand suitcase\u201d). With this extension, the basic (general) method can be supplemented by the use of a set of ontology classes and situation model features that model not only the semantics of the natural language text, but also the \u201cmeta\u201d entities and aspects of the communication process itself: these include the \u201ccommunicative agent\u201d (the talker), the information that is communicated, the receiving, or \u201cself\u201d agent (the listener), and cognitive processes on the part of the communicative agent or agents.\nWhere the ontology is small, the task of difficult pronoun resolution can be addressed without\nthe use of probabilistic representations in the ontology and situation model and without probabilistic reasoning. However, the introduction of probability data into the ontology becomes necessary in order to scale the method. The ROSS representational scheme has support for probability fields for attribute types, attributes, structure and for nested behaviors within behavior\n1 referent is used here to denote the external thing; antecedent denotes the syntactic item (usually a word or\nphrase).\nclasses. The use of the behavior class probability field is demonstrated by the solution to variant #1 of Winograd schema #1 (\u201ccouncilmen \u2026 feared violence\u201d).\n1.1. The ROSS Representational Method\nThe ROSS method (Hofford 2014 (a, b)) is a new approach in the area of representation that is\nuseful for many artificial intelligence and natural language understanding (NLU) tasks. (ROSS stands for \u201cRepresentation\u201d, \u201cOntology\u201d, \u201cStructure\u2019\u201d, \u201cStar\u201d language). ROSS is a physical symbol-based representational scheme. ROSS provides a complex model for the declarative representation of physical structure and for the representation of processes and causality. From the metaphysical perspective, the ROSS view of external reality involves a 4D model, wherein discrete single-time-point unit-sized locations with states are the basis for all objects, processes and aspects that can be modeled.\nThe ROSS method is also capable of the representation of abstract things \u2013 they are modeled\nby grounding them in a 4D space-time model. Abstract entities that are modeled include the entities that are involved in the representation of representation (\u201cmeta-representation\u201d), including representation of intelligent agent mental representations, cognition and communication.\nROSS is used in two ways in support of the pronoun resolution and inference methods: 1) the\nStar ontology language is used for the specification of object frame classes and for rule-like constructs referred to as behavior classes in the ontology/knowledge base, and 2) the formal scheme of the ROSS situation model (also called \u201cinstance model\u201d) is used for the specification of meaning representations that represent the semantics of a particular situation.\nThe ontology+knowledge base repository stores supporting definitions, object frame classes,\nand representations of conceptual, or world knowledge that use the behavior class. The ontology and knowledge base is organized into three tiers: an upper tier contains supporting definitions and high-level abstract classes, a middle tier contains classes whose primary purpose is functional: middle tier classes are used in many behavior classes, and a lower tier of object classes contains a large number of classes that are distinguishable from other similar classes by a few features. Examples of lower tier classes include \u201chouse cat\u201d, \u201ctrophy\u201d, and \u201cfather-person\u201d.\nThe internal instance model that is used during processing is a proprietary feature of ROSS\nthat is used for representing factual information about particular situations (past, present or hypothetical situations).\n1.2. Background: Winograd Schema Challenge\nThe Winograd Schema (WS) Challenge (Davis: 2011a ) is a set of tests for assessing whether\nor not an automated natural language understanding system has capabilities for \"thinking\" - i.e. does the system use and exhibit true intelligence in some sense, or is it responding to humanentered natural language input using canned (hard-coded) replies, \"tricks\", deception, diversion from the topic, etc. The WS challenge includes a variety of schemas: a schema consists of a pair of descriptive sentences and an associated pair of questions that tests whether or not the system has\nunderstood the sentence and its alternate. The NLP task involves some form of anaphora or coreference resolution for an ambiguous, or difficult pronoun that exists in the original sentence. The purpose of the WS Challenge is not to test for simple disambiguation; rather it is to use this task as a test of underlying intelligent capabilities.\nThe fields of commonsense reasoning for AI and NLU and of anaphora resolution and related\ndisambiguation tasks can be explored from many perspectives. Nevertheless the author has focused particularly on the Winograd Schema Challenge based on the belief that this set of schemas provides a broad-based foundation by its inclusion of a wide variety of problem types that form a sort of \u201ccore set\u201d of use cases for NLU.\nDavis (2011a) describes the Winograd Schema Challenge as follows:\nA Winograd schema is a pair of sentences that differ in only one or two words and that contain an ambiguity that is resolved in opposite ways in the two sentences and requires the use of world knowledge and reasoning for its resolution. The schema takes its name from a well-known example by Terry Winograd (1972)\nThe city councilmen refused the demonstrators a permit because they [feared/advocated] violence.\nIf the word is ``feared'', then ``they'' presumably refers to the city council; if it is ``advocated'' then ``they'' presumably refers to the demonstrators.\nThe schema challenge sentences and test questions for the trophy and suitcase example is\ndescribed in Levesque et al (2012) as follows:\nThe trophy doesn\u2019t fit in the brown suitcase because it\u2019s too big. What is too big?\nAnswer 0: the trophy Answer 1: the suitcase\nThe obvious answer to a human is that it is the trophy that is too big. This answer is obvious to a\nperson at least partly because humans are able to form a picture (a conceptualization) of the situation as it involves physical objects, processes, and causality. A human is also able to do reasoning about the processes and the causality \u2013 i.e. the causal relationships \u2013 that are involved in such a situation.\nLevesque et al (2012) describes a further aspect of the WS schema challenge for this particular\nschema:\n\u2026\n4. There is a word (called the special word) that appears in the sentence and possibly the question. When it is replaced by another word (called the alternate word), everything still makes perfect sense, but the answer changes. \u2026 This is where the fourth requirement comes in. In the first example, the special word is \u201cbig\u201d and its alternate is \u201csmall;\u201d and in the second example, the special word is \u201cgiven\u201d and its alternate is \u201creceived.\u201d These alternate words only show up in alternate versions of the two questions:\n\u2022 The trophy doesn\u2019t fit in the brown suitcase because it\u2019s too small. What is too small?\nAnswer 0: the trophy Answer 1: the suitcase\nLevesque et al (2012) shed light on why this challenge is an appropriate one for purposes of testing whether or not a system that purports to do intelligent thinking and natural language comprehension is actually doing such thinking:\nThe claim is that doing better than guessing requires subjects to figure out what is going on: for example, a failure to fit is caused by one of the objects being too big and the other being too small, and they determine which is which.\nAddressing this topic with another example involving the aforementioned city councilmen and demonstrators as originally conceived by Terry Winograd, they further state:\nThis was the whole point of Winograd\u2019s example! You need to have background knowledge that is not expressed in the words of the sentence to be able to sort out what is going on and decide that it is one group that might be fearful and the other group that might be violent. And it is precisely bringing this background knowledge to bear that we informally call thinking.\nIn his commentary on the difficulty of the \u201ccouncilmen/demonstrators\u201d example, Winograd (1972) states:\n\u201cWe understand this because of our sophisticated knowledge of councilmen, demonstrators, and politics \u2013 no set of syntactic or semantic rules could interpret this pronoun reference without using knowledge of the world.\u201d\nSolutions for the following W.S. schemas are presented here: schema #1: \u201cthe councilmen\nrefused the demonstrators a permit\u201d, #2: \u201ctrophy that doesn\u2019t fit in a suitcase\u201d, #8: \u201cthe man could not lift his son\u201d, and #115: \u201cJoe paid the detective\u201d. The present method uses a mixture of techniques in solving these schemas \u2013 this method is not a \u201cone size fits all\u201d approach.\nIt will be shown that some disambiguation tasks can be adequately handled by an approach\nthat relies on characteristics that are unique to common objects based on a determination of the higher classes from which they can be said to derive functional properties (i.e. a suitcase is a member of a container class that can be \u201cfitted into\u201d). Other tasks involve a prior-stage determination of semantic roles (active or passive) due to the fact that multiple objects of the same class are involved (\u201cthe man could not lift his son\u201d \u2013 a person cannot lift another person). Some resolution problems require knowledge that associates behaviors with what are referred to as \u201cnested behaviors\u201d (or \u201cchained behaviors\u201d). The schema that contains \u201cJoe paid the detective \u2026\u201d requires this approach. Finally, many pronoun resolution tasks require the application of a set of preliminary inferences (commonsense reasoning), using a generate-and-test approach that uses temporary situation representations of the situation that is described in order to test candidate antecedents for the pronoun. (This is demonstrated for the \u201cadvocate violence\u201d variant of the \u201ccity councilmen and demonstrators\u201d schema).\nThe probability aspects are also addressed with the councilmen and demonstrators schema: it\nwill be shown that the present method can handle this type of resolution problem using behavior classes, or rules, that incorporate a probability value. The example involves an examination of multiple behavior class rules that represent the act of \u201crefusing something with fear as a causal feature\u201d, where the causal connection of this behavior to a prior (nested) behavior in one of the rules is compared with that of other (possibly multiple) rules.\n2. Main Concepts\n2.1. Entity Resolution Using a ROSS Ontology\nA ROSS ontology is a repository that contains declarative information about objects and\nprocesses. Pronoun resolution involves a preliminary stage task that identifies, or links, antecedent words or phrases with items in the ROSS-based ontology. This is referred to herein either as \u201centity resolution\u201d or as \u201cclass selection\u201d. (There is possible overlap with word-sense disambiguation which is viewed as describing a closely-related task that is not directly relevant to this method).\nNote that there is no single authoritative ROSS ontology; ROSS ontologies are\ninterchangeable. However a single ontology does exist that supports the pronoun resolution examples described in this document.\n2.2. Ontology Scalability\nTo support scalability, the ontology that supports the procedures of the resolution method\nmust be general purpose as a declarative representation of entities and features for a problem domain (in this case the commonsense reasoning domain). The ontology should not contain entities, attributes or features that are custom-designed for specific procedural pronoun resolution problems. This may at first appear to be the case for the \u201ctrophy and suitcase\u201d schema solution, however it will be shown that the ontology features for that particular schema are generally-useful.\nThe rationale for the requirement of generally-useful ontology classes and attribute types is\nscalability: the method can only scale if it depends solely on a set of ontology definitions that have been created or derived apart from considerations of problem specificity.\n2.3. The ROSS Instance Model\nThe ROSS instance model has an important role in supporting the pronoun resolution and\ninference processes. Declarative content of the input natural language text is used in order to build a central instance model that contains a semantic representation of all objects and processes that can be identified during the execution of the entity resolution processing task. (Note that a situation model is a type of instance model; the terms are used interchangeably in this document). The instance model thus contains a set of referents (referents can be either objects or processes, however for the examples of this paper they are objects). The information in the instance model is also tracked by an internal memory data structure called the \u201cspanning information stack\u201d. Spanning information is tied into the instance model and is used for tracking referents with respect to their level of immediacy to the phrase or clause that contains the unresolved pronoun. The task of pronoun resolution can thus be re-stated as a task that involves a determination of which instance-model-based referent is indicated.\nThe instance model is not limited to containing objects or processes that are explicit in the\ninput NL text: for instance exophoric pronouns refer to objects that are not explicitly described but that can be represented in an instance model. An example of a sentence with an exophor is \u201cNobody came to the beach party because it was too hot\u201d. Although this case may perhaps be interpreted in any of several ways 2 , it can be adequately addressed using a ROSS behavior class that represents weather phenomena (in the locality of the beach where the party would be held) via a behavior class specification that represents a collection of air molecules. As a commonsense representational problem \u2013 not a physics problem \u2013an attribute type such as \u201cRelativeTemperatureExperiencedByPersons\u201d may be adequate as an abstraction for representing the state of being \u201ctoo hot\u201d.\n2 The pronoun \u201cit\u201d, within \u201cit was too hot\u201d may be viewed either as an exophoric reference or as a pleonastic\npronoun.\n2.4. Features of the ROSS Behavior Class That Support the Resolution Process\nROSS behavior classes have a prominent role in providing a set of referent target options;\nthese include objects that are represented by common nouns and nested behaviors that can be represented by either nouns or verbs.\nThe behavior class has the following features that support the resolution and inference\nprocesses:\n Multiple time and space-related constituent elements within a single behavior class, where\nelements can be:\no Physical objects: what is actually stored is the state or states of an object (as\nspecified using ROSS attributes); the physical object and its specified state are part of a wrapper class called a \u201cpopulated object class\u201d.\no Nested behaviors (e.g. one of possibly many behavior classes for \u201crefusing a\npermit request\u201d can contain a nested behavior class that represents \u201cfearing a harmful event\u201d).\n Support for the representation of un-communicated objects (see the \u201cbeach party\u201d\nexample above). Behavior classes can involve a wide variety of objects and nested behaviors that are implicit in a situation: in addition to phenomena like the weather, these may include the ground (earth) and persons that are observers.\n A representational construct called the \u201cbinder\u201d that allows for the representation of the\nspatial and temporal relationships between the various objects that are part of a behavior.\n(Hofford (2014 (b)) \u201cThe ROSS User\u2019s Guide and Reference Manual\u201d describes the behavior\nclass in greater detail).\n2.5. Definitions\nThe following terms are unique to the present method or have unique uses pertaining to the\nmethod.\n meaning unit: a meaning unit (\u201cME\u201d) is a syntactic construct that consists of a subject, a\npredicate and any adverbial modifier words, phrases or clauses. The predicate contains verbbased expressions and includes objects (direct object and indirect object). Meaning units are recursive and nested MEs may occur in any of several places. Generally speaking a meaning unit is the equivalent of a clause. There is usually a one-to-one correspondence between a syntactic ME and a semantic predicate expression, described next. Examples of meaning units include: \u201cBob did walk the dog.\u201d, and \u201cbecause it was too big\u201d.\n predicate expression: (part of semantic normal form (SNF)) - a (semantic) predicate\nexpression (\u201cPE\u201d) is a semantic construct that centers around a single syntactic predicate expression (e.g. \u201cdid walk the dog\u201d). PEs have arguments that have roles such as \u201cactor\u201d and \u201cactee\u201d. Like MEs, PEs can be nested. The PE is explained in greater detail below.\n2.6. Overview of the Algorithm\nThe pronoun resolution general algorithm is part of a larger algorithm called the semantic\nengine driver. The pronoun resolution general algorithm is driven by pronoun instances as they are encountered during execution of an entity resolution routine that itself is invoked within the control flow of the engine driver. When a pronoun is encountered, an attempt is made to resolve its referent and the antecedent word or syntactic phrase that corresponds to the semantic entity. (The referent/ semantic entity is not limited to \u201cobjects\u201d \u2013 e.g. it could be a process or a fact).\nThe semantic engine driver processes a list of semantic normal form 3 predicate expression\n(PE) data structures that corresponds to one or more input NL sentences 4 . In a typical situation that involves an anaphor, the input NL text fragment consists of at least two consecutive meaning units, a main meaning unit and a second (current) meaning unit that contains one or more unresolved pronouns. Several tasks are applied \u2013 the processing described here starts with the main PE, which represents the main meaning unit.\nExample: Main meaning unit: \u201cThe trophy doesn\u2019t fit in the brown suitcase\u201d Current meaning unit: \u201cbecause it\u2019s too big\u201d\nThe first task involves class selection (entity resolution) for all common nouns and proper\nnouns in the main PE (and possibly pronouns, based on earlier resolution results). In the example shown this would involve selecting a TrophyClass and a SuitcaseClass. The selected classes are then used for the second main task: instantiating object instances within the master internal instance model. For this example this creates a new \u201ctrophy\u201d object instance and a \u201csuitcase\u201d object instance within the master instance model.\nThe third task also involves use of the main PE: it is a form of entity resolution referred to as\nbehavior class selection: this selects a behavior class or list of behavior classes that are relevant for the situation. The behavior class selection process takes into account not only the verb word (e.g. \u201cfit\u201d, \u201clifted\u201d, \u201cpayed\u201d, \u201crefused\u201d) but whether or not the event or action is negated, and whether or not the active, passive and \u201cextra\u201d object instances are a match with respect to their class, or higher class in an inheritance hierarchy, and with respect to their use in active, passive or extra roles. The method is further capable of utilizing verb modification phrases (usually adverbs or adverbial phrases) in the input (e.g. \u201ccompletely fit\u201d, or \u201ctightly fit\u201d; e.g. \u201cwalking quickly\u201d versus \u201cwalking\u201d, and \u201ctrying to walk\u201d versus \u201cwalking\u201d) \u2013 this input guides the behavior class selection process via a process that matches verb modification information against behavior class modification parameters.\n3 See section 4. Semantic Normal Form for a description of semantic normal form. 4 Predicate expressions (PEs) and meaning units (MU) are used somewhat interchangeably throughout this\ndocument. The actual method as it has been implemented involves a semantic engine that uses MEs as input; however, the description of the method will usually utilize the PE as the basic input building block.\nFourth task: once the list of behavior classes, each of which matches all search criteria, has\nbeen attained, the NLU system is able to fully describe the situation of the main meaning unit (\u201cThe trophy doesn\u2019t fit in the brown suitcase\u201d). (Note that each of the retrieved behavior classes in the list are equivalent with respect to the information that they provide for instance model generation). The first behavior class in the list is used to generate new object instances in the master instance model. (An alternate approach is to use a higher behavior class rather than the first of multiple similar behavior classes). The step of generating new object instances using the behavior class is called \u201cbehavior class application\u201d. (Details of this process are outside the scope of this document).\nThe transition to the next task involves completion of processing of the main PE and the start\nof the processing of the current PE.\nThe fifth task involves processing of the entity arguments of the current PE: this starts with\nentity resolution and instance model generation for any entity arguments that do not contain pronouns. (The trophy and suitcase example does not have any such entity arguments in the current PE). (Where the current PE only contains adjectival information (as in \u201ctoo big\u201d), this will get saved in the pronoun feature set data structure).\nThe sixth task involves processing of the entity arguments of the current PE that contain\npronoun(s). (For the trophy and suitcase example, this involves processing of the entity argument containing the \u201cit\u201d of the current PE). An early part of this process is entity resolution: it in turn involves the actual pronoun resolution. The pronoun resolution routine involves a search for the constituent element \u2013 usually an object instance - of the master instance model that matches the features of the unresolved pronoun, as they are specified or implied in the current meaning unit (and current PE). The search process is limited to those instance model object instances that are associated via pointers from a spanning information data structure. The search process involves examination of each of the following to find a match (note that all criteria that are provided by the text of the current meaning unit (represented in the pronoun feature set) are necessary for a match to succeed).\n The pronoun feature set: all features of the unidentified object or event that is represented\nby the unresolved pronoun: this includes all of the following that exist. (Note: the features here are described using various possible trophy and suitcase sentences).\no an associated attribute or state if one exists (e.g. \u201cbecause it is too big.\u201d). Matching\nagainst instance model: match this feature against an optional causal feature attribute for a populated object class within the behavior class that is associated with an object instance.\no a behavior of the meaning unit in which the pronoun is contained (e.g. \u201cbecause\nthe packing person did not push it hard enough\u201d) (it participates in a push behavior). Matching against instance model: match this feature against a nested behavior in the behavior class.\no the active/passive/extra role within the meaning unit. (e.g. \u201cbecause it was not\npushed hard enough\u201d (it has passive role). Matching against instance model: match this feature against a PassiveParticipant flag that belongs to passive role populated object classes within a behavior class.\n Instance model features: qualitative attributes/states, spatial/temporal relationship to other\nobjects within the instance model, object frame class or higher class in the hierarchy, and active/passive role. These features may be determined by information in the instance model itself, or indirectly via an inspection of the behavior class that was used in generating the instance model objects from the main meaning unit. If the behavior class is involved, the populated object classes or nested behaviors are examined. Note that the instance model and spanning information structure may in some cases include object instances that are not explicit in the text: this is possible where a behavior class was applied to the main meaning unit and resulted in the generation of non-explicit object instances (e.g. the weather, e.g. the ground). In such cases, an exophoric pronoun will be matched against the object instance.\nIf the pronoun referent and corresponding syntactic antecedent can be resolved, both the\ninstance model object instance and its class are associated with the pronoun, and this newlyacquired information is added to the instance model. (Subsequent processing may also use the newly-acquired semantic information (pronoun class and object instance) during application of a behavior class for the current PE). The new information that identifies the pronoun is also added to the spanning information data structure for possible subsequent use. If the pronoun is not resolved via the matching process described above, other resolution attempts can be made: these include matching based on gender or number. Finally, a default resolution mechanism is invoked if all other resolution attempts have failed; in this case a return code indicates that pronoun resolution did not succeed using the instance model-based approach: this allows for subsequent processing to handle possibly-cataphoric pronouns.\nThe spanning information data structure keeps track of classes and instances for each main\nmeaning unit/PE so that a current meaning unit/PE may refer to them. The spanning information stack extends this concept by keeping track of the classes and instances for up to n prior meaning units, where the value of n is chosen based on practical considerations.\n2.7. Probability-Based Pronoun Resolution\nThe functionality of the method has been described apart from the use of probabilistic\ninformation that may be available. Both the entity resolution method and the pronoun resolution method can be supplemented by using probability fields within the classes. The probabilistic functionality for pronoun resolution will be explained and demonstrated as it has been applied to the \u201cfeared violence\u201d variant of the councilmen and demonstrators schema.\n2.8. Use of ROSS Situation Model to Support Question Answering\nOnce a situation/instance model is generated by the semantic engine, it can be used for a\nvariety of follow-up tasks; a primary example is that of question answering. For instance, for the \u201cman lifting son\u201d schema, the follow up question \u201cWho was so weak?\u201d is processed by searching the instance model that was previously generated when the original sentence was processed.\n2.9. Optional Representation of the Communicative Agent\nThe method can also incorporate an optional model that represents intelligent/communicating\nagents, information that is communicated, and cognitive information and processes. (See Appendix 1: Solution for \u201cTrophy and Suitcase\u201d Schema Using a Model of the Communicating Agent for full details). This optional approach involves generation of extra \u201cmeta\u201d information in the instance model so that the reception of natural language input is represented as a process that involves one or more communicative agents (a \u201ctalker\u201d or \u201ctalkers\u201d). The communicated information is also represented in the instance model. The information is received by a self-agent (the \u201clistener\u201d), i.e. the NLU system, which can also be represented in the instance model.\nThe general pronoun resolution method described in this document does not include\nconsiderations of modeling of the communicative agent and cognition. It makes a set of default epistemological assumptions: that there is a shared ontology, and that the communicative agent adheres to a set of shared rules (e.g. about causality in the physical world) in the realm of cognition; this allows the tasks of entity resolution and pronoun resolution to be handled using an approach that deals directly with the input text and the semantics of the text.\n2.10. Non-Objective: Representation of Deep Structure of Physical Objects\nSome lines of research in the area of commonsense reasoning have focused on spatial\nrepresentations and spatial reasoning. This approach is exemplified by Davis (2011b), wherein he describes the trophy and suitcase example. He states\n\u201cThe first task is to interpret the phrase, \u201cbecause it was too large\u201d in terms of its spatial\ncontent.\u201d\nIn his subsequent analysis, he emphasizes the spatial reasoning aspects of the problem.\nThe present method takes a different tack: it relies on class inheritance that involves a middle\nontology that includes classes such as \u201ccontainer\u201d, or \u201ctwo-sided enclosure\u201d, and \u201cenclosable object\u201d. These middle ontology classes have attribute types such as \u201csize relative to the process of fitting\u201d, from which can be derived attributes with values such as \u201ctoo big\u201d or \u201ctoo small\u201d. Lower ontology objects like trophies and suitcases derive some of their features from the higher classes (e.g. container) that they are associated with via the inheritance mechanism. The anaphora\nresolution method is focused on the task of identifying the entity that is the most likely of the candidate referents.\nThe present approach does not fully emulate human thought processes as they are used to\ndisambiguate pronouns; in some respects it is based only on useful abstractions. As such it does not handle all conceivable pronoun resolution cases: a method that employs a deep structure representation of the objects of a situation may indeed be necessary for many such cases. Such a method could be based on ROSS, and would represent the following aspects:\n Instantiation of object instances using values that represent compositional properties, e.g.\n\u201csubstance\u201d properties. For instance, this approach involves representations of common objects like trophies and suitcases with respect to whether each unit-sized cubicle region (e.g. with dimensions the size of a millimeter) is solid or space. Further depth of analysis and representation involves questions regarding aspects such as flexibility of materials (or the lack thereof) (e.g. a cloth suitcase may be flexible in various parts thus allowing something that seems too big to actually fit into it).\n Specifications of the sizes of objects and of all distances between objects.  The spatial orientation of all object instances.  Behavior classes (causal rules) that redefine coarse-grained rules such as \u201cfitting\u201d in terms\nof fine-grained rules such as a rule that describes that a solid-filled cuboid region at t=1 cannot occupy the same position as another (adjacent) solid-filled cuboid region at t=2 unless the other solid has \u201cmoved out of the way\u201d.\nThe author\u2019s view is that the ROSS method is a promising approach for achieving the deep\nspatial reasoning that would accomplish anaphora resolution using the above guidelines.\n2.11. Comprehendor NLU System\nComprehendor is a natural language understanding (NLU) system that performs a variety of\nNLU tasks. While this paper describes a method and a main set of use cases for difficult pronoun resolution, it also describes a supporting set of uses cases for ontology derivation and knowledge acquisition as performed by the Comprehendor system. The ontology derivation/knowledge acquisition capabilities are viewed as significant in their own right; they have provided a substantial boost in time-savings for purposes of tackling new disambiguation method use cases. (The ontology derivation and knowledge acquisition sub-system is a separate topic of research and development by the author as part of an ongoing effort to create a controlled natural language for ROSS).\n3. Pronouns: Types of Pronouns and Syntactic Locations of Pronouns\n3.1. Types of Pronouns Handled by the Method\nThe class of difficult pronouns that is handled by the method includes the following types of\npronouns:\n Personal subjective: he, she, it, they  Personal objective: him, her, it, them\nFirst and second person personal pronouns require somewhat different handling and are\nviewed by the author as a part of the area of modeling the intelligent agent (not included in this document). Other classes of pronouns include possessive, demonstrative, Wh-pronouns, reflexive and interrogative: resolution of some of these categories of pronouns does not yield to the present method.\n3.2. Pronoun Syntactic Locations\nThe resolution of the third-person personal pronouns that are the focus of the present method\ninvolves a process of analysis that centers on, (or \u201cpivots\u201d around) the imaginary dividing line between a pair of adjacent meaning units. Other configurations are handled as secondary cases \u2013 these include antecedents that are several clauses or sentences back, and exophoric pronouns. The following are the primary configurations for personal pronouns and their antecedents as they appear within the syntactic structure of natural language sentences:\n Anaphora crossing meaning units: the pronoun is within a current meaning unit and the\nantecedent is in an earlier meaning unit. Variations include but are not limited to:\no A main clause (earlier) containing the antecedent, followed by an adverbial clause\n(current) that contains the pronoun as a (noun phrase) subject. (e.g. \u201cThe man could not lift his son because he was too weak.\u201d).\no A main clause (earlier) with antecedent, followed by an adverbial clause (current)\nthat contains the pronoun as direct object, or that contains the pronoun within a prepositional phrase complement. (e.g. \u201cThe man could not lift his son because the building had collapsed on top of him.\u201d).\n Cataphora crossing meaning units: the pronoun is within a current meaning unit and the\nantecedent is in a later meaning unit. (e.g. \u201cWhen he arrived home, John went to bed.\u201d).\n Anaphora within a meaning unit: the current meaning unit contains a sentence with a\npersonal objective pronoun that refers to an antecedent within the same meaning unit. This structure is shown by these sentences: \u201cThe house\u2019s owners sold it last year.\u201d, or \u201cThe owners of the house sold it.\u201d.\n4. Semantic Normal Form (SNF)\nThis section contains a formal specification of the input needed by a semantic engine that\nimplements the present method; this is referred to as semantic normal form (SNF) 5 . Semantic normal form is a syntax-independent formalization; it is an intermediate representation that stands between syntax and the ROSS instance model. SNF has been designed to facilitate instance model creation.\nThe data structure definitions here may be used for the creation of engine input data adapters;\nthis allows for flexibility with respect to parsers that can be integrated into systems that use the present method. SNF is language-independent and thus allows use of the present method with a wide variety of natural languages.\n4.1. The Predicate Expression (\u201cPE\u201d)\nThe predicate expression (\u201cPE\u201d) is the basic building block of semantic normal form 6 . A\npredicate expression consists of a predicate specifier list, a list of entity argument specifiers, or entity arguments, a list of attributive argument specifiers, or attributive arguments, and a list of modification specifiers, or modifiers. Entity arguments are typically associated with semantic entities that correspond to the syntactic subject, direct object, indirect object, and those that are represented by nouns or noun phrases within post-verb (predicate complement) prepositional phrases. Attributive arguments are words or phrases that represent attributes (usually representing an adjective used with a form of \u201cto be\u201d). Modifiers are associated with adverbial syntactic items, e.g. adverbs and adverbial phrases and clauses. Predicate expressions allow for indirect recursion, or nesting: an argument may itself be a predicate expression, a modifier may be a predicate expression or it may be a modification specifier expression that includes a predicate expression.\n4.2. Semantic Role Labels\n4.2.1. Predicate Specifier Roles\nThe predicate specifier has a predicate specifier role label. This label has one of the following\nenumerated values (this list is not exhaustive). (Actors/actees/extras are explained in the following section). enumeration PredicateSpecifierRole { PredicateToBeAttributive, // \u201cThe sky is gray.\u201d PredicateToBeIsA, // \u201cA car is a vehicle.\u201d PredicateHasAVerb, // \u201cA vehicle has wheels.\u201d\n5 Although the term \u201csemantic normal form\u201d may have other prior use(s), the author is unaware of any restrictions regarding its use; any overlap with other concepts represented by the term are unintentional. 6 The term \u201cpredicate expression\u201d connotes that it contains representations that correspond to syntactic expressions; neither the predicate expression itself nor the immediate constituent fields of a predicate expression are themselves true expressions. Note that \u201cpredicate unit\u201d is also used as a synonym for \u201cpredicate expression\u201d.\nPredicateToBeTakingEntityArgument // \u201cThe car is in the garage.\u201d (with actor and extra) PredicateVerbTakingEntityArgument // \u201cThe man walked.\u201d (with actor) // \u201cThe man lifted his son.\u201d (with actor and actee) // \u201cThe ball was thrown.\u201d (with actee) }\nNote that syntactic concepts such as auxiliary/helper verb uses of \u201cto be\u201d are not present here.\nE.g. for the sentence \u201cThe ball was thrown\u201d, the predicate specifier verb word is the \u201cthrow\u201d verb, the role is PredicateVerbTakingEntityArgument, and \u201cwas\u201d is not stored in the data structure.\n4.2.2. Entity Argument Roles\nAn entity argument has an entity argument role label. This identifies the argument as actor\n(active, or causative role), actee (passive role) or extra (neither active nor passive role). enumeration EntityArgumentRole { Actor, Actee, Extra }\nEntity argument roles have their syntactic origination in syntax categories such as subject and\ndirect object, however they are a reflection of the need to represent the phenomenon of causality. The determination of an entity argument role may involve a syntactic analysis of a prepositional phrase: e.g. the sentence \u201cThe man was bitten by the dog\u201d gets processed to generate two arguments: \u201cdog\u201d gets the actor role, and \u201cman\u201d gets the actee role. The extra role is for entities that are neither active nor passive. Extra role entities often come from prepositional phrases that are complements of the main verb or predicate; an example of an entity with the extra role is \u201cbuilding\u201d, in \u201cShe walked away from the building.\u201d.\nFor the \u201cman could not lift his son\u201d schema this results in the following assignments of\nactor/actee/extra roles: Main Meaning Unit - \u201cThe man could not lift his son\u201d\nActor := man, derived from the subject phrase Actee := son, derived from the direct object noun phrase Extra := (none)\nSubsequent Meaning Unit \u2013 \u201cbecause he was so weak.\u201d\nActor := he, derived from the subject phrase Actee := (none) Extra := (none)\n4.2.3. Extra Sub-Roles\nExtra sub-roles are used for entities that have an association with the semantics of a predicate\nthat is neither active nor passive. Many of the sub-roles are directly derived from prepositions. E.g. for the sentence \u201cThe man drove the car around the block.\u201d, the word \u201cblock\u201d has the extra role and the Around sub-role. enumeration ExtraSubRole { IndirectObject, // \u201cthe councilmen refused the demonstrators a permit\u201d About, Above, Around, At, Before, From, Into, Over, Under, // (others here not shown) }\n4.3. Relative/Subordinate Clauses\nRelative/subordinate clauses do not supply entities to the predicate expression in which they\nare contained; rather, they consist of: a) a possible preposition, e.g. \u201cfrom\u201d, b) Wh-pronoun, e.g. \u201cwho\u201d, and c) a nested predicate expression that has its own set of entity arguments. Examples include \u201cThe sheriff arrested the man who had held up the bank.\u201d, \u201cThey followed the stream through the woods to the spring from which it had its source.\u201d The nested predicate expression is handled differently from entity arguments that do not contain nested PEs: it is processed by an indirect recursive call as a PE that is part of the overall syntactic sequence of PEs (cf. PredicateExpressionPointerList in section 6.Semantic Engine Driver: Data Structures and Control Flow).\n4.4. Attributive Argument Roles\nPredicate expressions with predicates having the PredicateToBeAttributive role or the\nPredicateToBeIsA role have attributive arguments. Examples include \u201cThe sky is blue\u201d, \u201cMary is seven years old\u201d, and \u201cA car is a vehicle\u201d.\nenumeration AttributiveArgumentRole { Attribute, HigherClass // (others here not shown) }\nExamples from the Winograd schemas include \u201cit was too big\u201d, and \u201che was so weak\u201d.\n4.5. Other Argument Categories: Abstractions That Represent Aspects\n(This section draft/under review) This is a list of categories of arguments that do not get\nhandled in the same way as other arguments since they are not instantiated within instance models as objects or as behaviors:\n Aspect types: e.g. color (example: \u201cThe intense color of the sky dazzled the observers.\u201d)  Aspects: e.g. \u201cblueness\u201d (example: \u201cThe blueness of the sky extended to the horizon.\u201d)\nOne option for handling such abstractions is reification of the aspect type or aspect in the\nontology and in instance models.\n4.6. Other Enumerated Types\nThe SyntacticRole is used to represent the syntactic origin (currently limited to use for noun\nphrases) enumeration SyntacticRole { Subject, DirectObject, IndirectObject, Other }\nThe DiscourseContext enumerated type represents mood+tense. enumeration DiscourseContext { DeclarativePastSimple, DeclarativePastPerfect, DeclarativePastProgressive, DeclarativePastPerfectProgressive, DeclarativePresentSimple, DeclarativePresentPerfect, DeclarativePresentProgressive, DeclarativePresentPerfectProgressive, DeclarativeFutureSimple, DeclarativeFuturePerfect, DeclarativeFutureProgressive, DeclarativeFuturePerfectProgressive, InterrogativePastSimple, InterrogativePastPerfect,\nInterrogativePastProgressive, InterrogativePastPerfectProgressive, Imperative, Hypothetical // e.g. \u201cif an object is dropped then it will fall\u201d }\n4.7. The Structure of the Predicate Expression\nThe structure of the predicate expression is described here using a hybrid form that mixes data\nstructure pseudo-code with BNF. Lower level items are described after the larger items in which they are contained. Optional items are bracketed with \u2018[\u2018 and \u2018]\u2019. The order of items within a structure is not important unless specifically indicated or implicit within a BNF expression. A list may contain 0, 1 or multiple items unless otherwise noted. (Note: \u201cpredicate unit\u201d is sometimes used as a synonym for \u201cpredicate expression\u201d). (This is a high-level view of SNF and many lowerlevel items such as PrepositionalPhraseComplement are not defined in detail). PredicateExpression { PredicateSpecifierList EntityArgumentSpecifierList AttributiveArgumentSpecifierList ModificationSpecifierList [ IntroductoryWord ] // e.g. \u201cthat\u201d } //======================================== // PredicateSpecifier // PredicateSpecifierList -> PredicateSpecifier | PredicateSpecifier PredicateSpecifierList ; PredicateSpecifier { Ordinal // 0-based position within the list MainVerbWord // e.g. \u201clikes\u201d, \u201ccaused\u201d, \u201cwalk\u201d, \u201crunning\u201d PredicateSpecifierRole // e.g. PredicateToBeAttributive DiscourseContext [TrailingConnectiveWord ] // e.g. \u201cand\u201d } IntroductoryWord -> \u201cthat\u201d | \u2026 ; //======================================== // EntityArgumentSpecifier // EntityArgumentSpecifierList -> EntityArgumentSpecifier | EntityArgumentSpecifier EntityArgumentSpecifierList ;\nEntityArgumentSpecifier { // At least one must exist: [ EntityDesignatorList ] // must be non-empty [ PredicateExpression ] // EntityArgumentSemanticRole // one of: Actor, Actee, Extra ExtraSubRole // (can be NULL) e.g. Around, Into, Over SyntacticRole // (syntactic origin) - Subject, DirectObject etc. PredicateOrdinal // refers to a predicate specifier } EntityDesignatorList -> EntityDesignator | EntityDesignator EntityDesignatorList ; EntityDesignator { // At least one must exist: [ NounPhrase ] [ PrepositionalPhraseComplement ] // [TrailingConnectiveWord ] // e.g. \u201cand\u201d } NounPhrase -> NounHeadWordList | [SpecifierList] [QualifierList] NounHeadWord [PostnominalModifierList] | NounPhrase BoundRelativeClause ; NounHeadWordList -> NounHeadWord | NounHeadWord NounHeadWordList ; NounHeadWord -> Pronoun | CommonNoun | ProperNounPhrase ; // e.g. \u201cEarnest W. Quality\u201d SpecifierList -> Specifier // e.g. \u201cthe\u201d, \u201cthis\u201d, \u201cfirst\u201d | Specifier SpecifierList ; QualifierList -> Qualifier // e.g. \u201cangry\u201d, \u201cold\u201d, \u201cgreen\u201d | Qualifier QualifierList ; PostnominalModifierList -> PostnominalModifier // e.g. \u201cin the garage\u201d | PostnominalModifier PostnominalModifierList ; PostnominalModifier -> PrepositionalPhrase | AdjectivePhrase ; // Note: each of the following may contain nested PEs: PrepositionalPhrase -> // (not shown) e.g. \u201cfrom which its name is derived\u201d BoundRelativeClause -> // (not shown) e.g. \u201cthe man who drives the bus\u201d\nPrepositionalPhraseComplement -> // (not shown) e.g. \u201cin the brown suitcase\u201d //======================================== // AttributiveArgumentSpecifier // AttributiveArgumentSpecifierList -> AttributiveArgumentSpecifier | AttributiveArgumentSpecifier AttributiveArgumentSpecifierList ; AttributiveArgumentSpecifier { [ AttributeDesignatorList ] // (higher classes not shown) } AttributeDesignatorList -> AttributeDesignator | AttributeDesignator AttributeDesignatorList ; AttributeDesignator { AttributeDesignator [TrailingConnectiveWord ] // e.g. \u201cand\u201d } //======================================== // ModificationSpecifier // ModificationSpecifierList -> ModificationSpecifier | ModificationSpecifier ModificationSpecifierList ; ModificationSpecifier { // At least one must exist: [ AdverbialPhrase ] [ AdverbialExpression ] [ PredicateExpression ] // e.g. \u201cslipping past the guard\u201d // SyntacticPosition // e.g. Leading, PreVerb, InVerbSequence, PostVerb, Final PredicateOrdinal // refers to a predicate specifier } AdverbialPhrase -> AdverbWord | AdverbPhrase ; AdverbWord -> literal ; // e.g. \u201cquickly\u201d AdverbPhrase -> \u2026 // e.g. \u201cearly in the morning\u201d AdverbialExpression // e.g. \u201cwhile it was still dark\u201d, \u201cwhen it is not raining\u201d { Wh-Word | AdverbPhraseIntroductoryWord PredicateExpression } Wh-Word -> \u201cwhile\u201d | \u201cwhen\u201d | \u2026 ;\nAdverbPhraseIntroductoryWord -> \u201cbecause\u201d | \u2026 ;\n4.8. SNF Example\nSemantic normal form can be illustrated by a predicate expression that represents the\nfollowing sentence: \u201cThe city councilmen refused the demonstrators a permit because they feared violence.\u201d PredicateExpression { PredicateSpecifierList PredicateSpecifier { MainVerbWord (\u201crefused\u201d) MainVerbSemanticRole (PredicateVerbTakingEntityArgument) DiscourseContext (DeclarativePastSimple) } EntityArgumentSpecifierList ( EntityArgumentSpecifier // \u201cthe city councilmen\u201d { EntityDesignatorList ( EntityDesignator { NounPhrase { SpecifierList Specifier (\u201cthe\u201d) QualifierList Qualifier (\u201ccity\u201d) NounHeadWord (\u201ccouncilmen\u201d) } } ); EntityArgumentSemanticRole (Actor) PredicateOrdinal (0) // refers to \u201crefused\u201d } EntityArgumentSpecifier // \u201cthe demonstrators\u201d { EntityDesignatorList ( EntityDesignator { NounPhrase // (detail not shown) } ); EntityArgumentSemanticRole (Actee) PredicateOrdinal (0) } EntityArgumentSpecifier // \u201ca permit\u201d { EntityDesignatorList ( EntityDesignator { NounPhrase // (detail not shown)\n} ); EntityArgumentSemanticRole (Extra) PredicateOrdinal (0) } ); // EntityArgumentSpecifierList ModificationSpecifierList ModificationSpecifier // \u201cbecause they feared violence\u201d { AdverbialExpression { AdverbPhraseIntroductoryWord (\u201cbecause\u201d) // Nested PE: PredicateExpression { PredicateSpecifierList PredicateSpecifier { MainVerbWord (\u201cfeared\u201d) MainVerbSemanticRole (PredicateVerbTakingEntityArgument) DiscourseContext (DeclarativePastSimple) } EntityArgumentSpecifierList ( EntityArgumentSpecifier // \u201cthey\u201d (actor role) { EntityDesignatorList ( EntityDesignator { NounPhrase { NounHeadWord (\u201cthey\u201d) } } ); EntityArgumentSemanticRole (Actor) PredicateOrdinal (0) // refers to \u201cfeared\u201d } EntityArgumentSpecifier // \u201cviolence\u201d (actee role) { // (not shown) } ); // EntityArgumentSpecifierList } // PredicateExpression } // AdverbialExpression SyntacticPosition (Final) PredicateOrdinal (0) // refers to \u201cfeared\u201d } // ModificationSpecifier } // PredicateExpression\n5. NLU System Architecture and Data Flow\nFigure 1 shows the high-level architecture/dataflow diagram for an NLU system that\nimplements the present method. The diagram is included as background that shows the context wherein the anaphora resolution method operates.\nA parser subsystem will include a number of subsystems that include lexical analysis,\nsentence segmentation, morphological analysis, part of speech tagging (possibly optional depending on the parser capabilities), and a parsing component. The parser subsystem generates a list of syntax trees (or syntactic tree-like data structures) that are processed by a SNF data adapter to create a list of SNF predicate expressions (PEs) that are usable by the engine.\nThe NLU semantic engine subsystem processes the list SNF predicate expressions in order to\ncreate an internal instance model. The engine performs the various tasks that accomplish the entity resolution (class selection) and pronoun resolution/disambiguation. The engine uses the internal instance model both for pronoun resolution and for cases where it performs the embedded commonsense reasoning.\n5.1. Input to a Parser: Communication Unit List\nThis section describes the structure of the natural language text input in its original form, prior\nto conversion to semantic normal form.\nThe root element is Document. A Document is defined as a communication unit list. A\ncommunication unit may be a sentence or some other non-sentence textual expression. Nonsentence textual expressions are useful for handling strings of text containing non-sentence text, e.g. news article headlines, date and time stamps, email addresses, etc. Document -> CommunicationUnitList ; CommunicationUnitList -> CommunicationUnit | CommunicationUnit CommunicationUnitList ; CommunicationUnit -> SingleWordOnLine | TwoWordSequenceOnLine // e.g. \u201cChapter 1\u201d | DateAndTime | EmailAddress | WebAddress | Sentence ;\nThe following are the grammatical elements under sentence. Sentence -> SemicolonExpressionList FullStop | MeaningUnitList FullStop ; SemicolonExpressionList -> SemicolonExpression | SemicolonExpression SemicolonExpressionList ; PredicateExpressionOrderedList -> PredicateExpression | PredicateExpression CoordinatingConjunction PredicateExpressionOrderedList ; CoordinatingConjunction -> \u2018and\u2019 | \u2018or\u2019 | \u2018but\u2019 | ... ; SemicolonExpression -> PredicateExpressionList ';' PredicateExpressionList ; FullStop -> '.' | '!' | '?' ;\n5.2. Data Adapters (Syntax-To-Semantic-Normal-Form Converters)\nA data adapter that converts syntactic data, usually consisting of a list of parser-generated\nsyntax trees, to semantic normal form is called an SNF data adapter, or SNF converter. This process provides input in a form that is usable by a semantic engine that implements the present method using SNF.\n5.2.1. Example: Stanford Parser Output / Data Adapter Input\nThe following syntax tree (context-free phrase structure grammar representation) was\ngenerated by the Stanford parser (online demo at http://nlp.stanford.edu:8080/parser/index.jsp). (This is provided as an example of possible input to an SNF converter).\n(ROOT (S (NP (DT The) (NN trophy)) (VP (VBZ does) (RB n't) (VP (VB fit) (PP (IN in) (NP (DT the) (JJ brown) (NN suitcase))) (SBAR (IN because) (S (NP (PRP it)) (VP (VBZ 's) (ADJP (RB too) (JJ small))))))) (. .)))\n5.2.2. Example: Phrase Structure Parser Output / Data Adapter Input\nThe Comprehendor NLU system includes an English phrase structure parser sub-system. This\nsystem generates a syntax tree like the following for the trophy and suitcase example sentence (the \u201ctoo big\u201d variant). The grammar for this parser is not shown, however most of the items shown below have descriptive names that convey their meaning. Communication unit type: Sentence Sentence contents: The trophy [doesn't] does not fit in the brown suitcase because [it's] it is too big. Syntax tree: MeaningUnit SubjectPhrase: NounPhrase: Specifier List: The Head word: trophy PredicatePhrase: PreVerbAdverb: not AuxVerbWord: does MainVerbWord: fit Prepositional phrase complement: PrepositionalPhrase: Head word: in NounPhrase: Specifier List: the Qualifier List: AdjectivePhrase: Head word: brown Head word: suitcase Final adverbial phrase list: AdverbPhrase:\nMeaningUnit Introductory word: because SubjectPhrase: NounPhrase: Head word: it PredicatePhrase: AuxVerbWord: is PostVerbAdverb: too PostVerbAdjectivePhrase: AdjectivePhrase: Head word: big\n(Note: the test results shown in this document use a version of the Comprehendor semantic\nengine that directly uses this type of input for each of the schemas).\n5.3. Semantic Engine\nThe semantic engine tasks include the following that are particularly relevant for pronoun\nresolution.\n5.3.1. Multi-Stage Process: Main Predicate Expression and Current Predicate Expression\nA processing task of instantiating object instances will usually take place prior to that of\npronoun resolution (exceptions involve sentences that have pleonastic or exophoric pronouns). This task establishes pointers to entity classes and instances within the spanning information data structure. The main predicate expression and the current predicate expression are defined as follows. (Note that, syntactically, the main predicate expression may appear after the current predicate expression, as is the case where cataphoric pronouns are involved).\nmain predicate expression: the predicate expression that contains semantic information about previously-resolved entities:\n It is described by a spanning information data structure.  The master internal instance model contains both structural parent object instances and\ncomponent object instances that were generated from the entity arguments of the main predicate expression. E.g. for the councilmen and demonstrators schema, object instances include an object instance for each of councilmen, demonstrators, and permit.\n The master instance model also contains instantiations of the main meaning unit predicate-\nbased behavior, based on a higher behavior class (the first found behavior class can be used here as it contains commonly-shared information for all behavior classes). E.g. for the councilmen and demonstrators schema, object instances will have had state attribute values set based on the definition of a \u201crefusing something due to fear\u201d behavior class.\ncurrent predicate expression: contains one or more unresolved pronouns:\n It is described by the pronoun feature set data structure rather than the spanning\ninformation data structure.\n The master internal instance model contains partial information based on common nouns,\nproper nouns, any resolvable pronouns (e.g. possessive pronouns), and verb information that can be determined prior to resolution of the unresolved pronoun.\nThe processing of the current predicate expression by the semantic engine is the main focus of the algorithms of the present method; however several other engine preparation tasks are also described.\n5.3.2. Entity Resolution (Class Selection)\nThe task that involves selection of a relevant class from the ontology for a noun head word or\nnoun phrase is referred to herein as \u201centity resolution\u201d; this may to some extent overlap with the common usage of \u201cword sense disambiguation\u201d. The syntactic and SNF (semantic) information about a word or phrase may provide sufficient constraints to allow unambiguous resolution (e.g. where \u201cman\u201d contained in a noun phrase constrains the ontology lookup process to object frame classes; behavior classes in the ontology are not searched). Other aspects of entity resolution that are important but not addressed here include:\n examination of the immediate in-sentence context to determine attribute types and\nbehaviors that apply to one candidate class but not another or others\n probabilistic approaches  commonsense inferences that can be triggered\nThe entity resolution task resolves a word or phrase by associating it with a class in the\nontology. This involves a set of assertions \u2013 i.e. the features of the class - about the entity that is described by the word or phrase. Refer to Hofford (2014 (b)) \u201cThe ROSS User\u2019s Guide and Reference Manual\u201d for detail about the object frame class.\n5.3.3. Generation of Internal Instance Model\nThe semantic engine executes two main tasks that are part of master internal instance model\ngeneration. They are:\n Object instance instantiation: this occurs after entity resolution/class selection. Structural\nparent object instances and component object instances are inserted into the master instance model.\n Behavior class selection and application: this usually occurs after object instance\ninstantiation and involves the application of a behavior class in order to generate additional information that can be determined. A typical case of behavior class application, as it\nwould apply to the meaning unit \u201cBob hit the other man\u201d would add additional attribute information to objects in the instance model (Bob, other man), and would also generate a new structural parent object instance at a separate point along a time-line: this new structural parent instance will hold cloned copies of the object instances (Bob, other man) and these object instances will have state attribute values that represent the results of the \u201chit\u201d action.\n5.3.4. Other Engine Tasks\nThe following tasks are also performed by the engine. Details about pronoun resolution and\nthe embedded inference process will be provided in the following sections.\n Pronoun resolution: this takes place within entity resolution but also performs object\ninstance instantiation (object instances based on pronouns can be instantiated as soon as the pronoun antecedent is resolved, therefore this task is incorporated into the final stages of the pronoun resolution task).\n Embedded inference/commonsense reasoning: this is performed when additional instance\nmodel information is needed. Types of inference include the following (triggered inference is not covered in this document)\no Inferences that can be triggered by information that is gained as the input natural\nlanguage text is processed. E.g. a sentence in a story provides information that gets used to create an instance model, from which an inference can be drawn: \u201cAs the mule slowly descended the rocky trail, suddenly it lost its footing and fell into the vast open space below\u201d. (Triggered inference: the mule got injured or killed).\no Inferences that are used within the pronoun resolution routine in order to handle\nthe pronoun resolution task where other simpler instance-model-based attempts have failed. This is described in a subsequent section and has been applied in order to solve Winograd schema #1 (councilmen and demonstrators) for the \u201cadvocate violence\u201d variant.\n Generation of external instance model: this is an optional step that involves generation of\nan external XML-based instance model.\n Question answering: the Comprehendor NLU system stores instance model information,\nwhich is used for follow-up question answering.\n6. Semantic Engine Driver: Data Structures and Control Flow\n6.1. Overview\nA semantic engine sub-system for the present method will have a high-level function that is\nreferred to as the engine driver. The EngineDriver() function processes an input Document, which is a list of communication units. The engine driver branches to an appropriate subroutine, depending on whether the communication unit is part of a sentence or is of another communication unit type, e.g. a web URL or a standalone email address. When it has finished processing all communication units, the engine driver invokes GenerateOutputInstanceModels() in order to generate the external (XML) version of the internal instance model and any other selected output forms (e.g. a bullet-point summary of a story).\nData structures and code from the Comprehendor NLU system are used to illustrate engine\ndriver concepts. Comprehendor is a C++ implementation; the following sections use C++ or pseudo-code. (Note: data structures shown here and the functions that follow are not intended as full listings of the actual code in the Comprehendor system).\n6.2. Data Structure for Master Token List\nThe engine requires an input master list of lexical tokens: the main data structure that is part of\nthe implementation of this token list, referred to in the following sections, is \u201cTokenListNode\u201d (a list node class).\n6.3. Data Structures and Data Types: Input to the Engine\nThis section describes the following data structures and their supporting definitions:\ncommunication unit, sentence, predicate expression, predicate specifier, entity argument specifier, and modification specifier.\nA communication unit data structure has the following structure: class CommunicationUnit { public: enum CommunicationUnitType communicationUnitType; // pointers to start and end tokens in the master input token list: TokenListNode *pFirstTokenListNode; TokenListNode *pLastTokenListNode; // (e.g. for a declarative sentence, points to period token) Sentence *pSentence; }\nThe CommunicationUnitType enumerated type is as follows (other types may be defined as\nneeded)\nenum CommunicationUnitType { CommunicationUnitTypeSentence = 0, CommunicationUnitTypeURL, CommunicationUnitTypeEmailAddress, CommunicationUnitTypeSingleWordOnLine, CommunicationUnitTypeTwoWordPhraseOnLine, CommunicationUnitTypeAuthorInfo, CommunicationUnitTypeNONE // max value for this enum };\nA sentence has the following structure; note that semicolon expressions are handled as top-\nlevel expressions within a sentence as they are similar to full sentences. (This structure also shows flags relating to paragraphs and quotations that have uses that are not described in detail here). class Sentence { public: char szContentString [MAXLEN_CONTENTSTRING]; // stores the original sentence DiscourseContext discourseContextMajor; bool fSentenceStartIsParagraphBegin; bool fSentenceEndIsParagraphEnd; bool fSentenceIsPrependedWithQuotationBegin; bool fSentenceIsAppendedWithQuotationEnd; // if it contains any semicolon expressions: SemicolonExpressionNode *pSemicolonExpressionHeadNode; // if it does not contain any semicolon expressions: PredicateExpressionList predicateExpressionList; }\nThe DiscourseContext enumerated type is defined as follows. A DiscourseContext value\nroughly corresponds to the grammatical concepts of tense and aspect, with further divisions that are partly based on mood. (\u201cdeclarative\u201d and \u201cinterrogative\u201d, although both are indicative, are separated here due to the needs of the semantic engine).\nenum DiscourseContext { DeclarativePastSimple = 0, DeclarativePastPerfect, DeclarativePastProgressive, DeclarativePastPerfectProgressive, DeclarativePresentSimple, DeclarativePresentPerfect, DeclarativePresentProgressive, DeclarativePresentPerfectProgressive, DeclarativeFutureSimple, DeclarativeFuturePerfect, DeclarativeFutureProgressive, DeclarativeFuturePerfectProgressive,\nInterrogativePastSimple, InterrogativePastPerfect, InterrogativePastProgressive, InterrogativePastPerfectProgressive, Imperative, Hypothetical, // (related to the subjunctive mood) DiscourseContextNONE };\nThe predicate expression list is not shown; a predicate expression has the following structure.\nThe PredicateExpressionPointerList is not shown: this is a list of pointers to predicate expressions (including the current PE) that represents the original syntactic order of meaning units. For instance, given the sentence \u201cThe man could not lift his son because he was so weak.\u201d, the pointer list points to two PEs that represent the two meaning units that are shown here:\n (head of list) \u201cThe man could not lift his son\u201d // pointer to this data object  (next/tail) \u201cbecause he was so weak\u201d // pointer to a PE that is nested within the\nModificationSpecifierList\nThe TokenListNode data structure is not shown: this is for a master token list that is generated\nby a lexical analyzer; token list nodes also store disambiguation information as it is determined by the engine. The pFirstTokenListNode pointer points into the master token list at the location that corresponds to the start of the predicate expression (this is usually the start token of a sentence). class PredicateExpression { public: GrammaticalMood grammaticalMood; char szIntroductoryWord [MAXLEN_SINGLEWORDSTRING]; // e.g. that PredicateSpecifierList predicateSpecifierList; EntityArgumentSpecifierList entityArgumentSpecifierList; AttributiveArgumentSpecifierList attributiveArgumentSpecifierList; ModificationSpecifierList modificationSpecifierList; PredicateExpressionPointerList predicateExpressionPointerList; // list order represents original syntactic order of MUs TokenListNode *pFirstTokenListNode; // start token only; end token is marked and does not need to be stored }\nThe GrammaticalMood enumerated type is defined as follows. enum GrammaticalMood { GrammaticalMoodIndicative = 0, GrammaticalMoodInterrogative, GrammaticalMoodImperative, GrammaticalMoodNONE };\nThe predicate specifier list is not shown; the predicate specifier is defined as follows: class PredicateSpecifier { int ordinal; char szMainVerbWord [MAXLEN_SINGLEWORDSTRING]; // e.g. walked, walking // char szParticleWord [MAXLEN_SINGLEWORDSTRING]; // e.g. up, out, over, in PredicateSpecifierRole semanticRole; DiscourseContext discourseContextActual; char szTrailingConnectiveWord[MAXLEN_SINGLEWORDSTRING]; // e.g. \u201cand\u201d };\nThe PredicateSpecifierRole enum is as follows. enum PredicateSpecifierRole { PredicateToBeAttributive, // \u201cThe sky is gray.\u201d PredicateToBeIsA, // \u201cA car is a vehicle.\u201d PredicateCapability, // \u201ccan\u201d PredicateHasAVerb, // \u201cA vehicle has wheels.\u201d PredicateToBeTakingEntityArgument // \u201cThe car is in the garage.\u201d PredicateVerbTakingEntityArgument // \u201cThe man walked.\u201d };\nThe entity argument specifier list is not shown; the entity argument specifier is shown here.\nNote that the entity argument specifier may contain a predicate expression, allowing for recursivity/nesting of predicate expressions. (Refer to the section above on Semantic Normal Form for definition of the EntityArgumentSemanticRole enumerated type). class EntityArgumentSpecifier { EntityDesignatorList entityDesignatorList; // (empty if unused) PredicateExpression *pPredicateExpression; // (NULL if unused) EntityArgumentSemanticRole semanticRole; // one of: Actor, Actee, Extra ExtraSubRole extraSubRole; SyntacticRole syntacticRole; // e.g. subject, direct object, indirect object int ordinalPredicate; // refers to a predicate specifier };\nThe entity designator list is not shown; the entity designator is defined as follows: class EntityDesignator { NounPhrase *pNounPhrase; PrepositionalPhraseComplement *pPrepositionalPhraseComplement; char szTrailingConnectiveWord[MAXLEN_SINGLEWORDSTRING]; // e.g. \u201cand\u201d };\nThe attributive argument specifier data structures are not shown here. The modification\nspecifier list is not shown; the modification specifier is as follows. Note that the modification specifier may contain a predicate expression, allowing for recursivity/nesting of predicate expressions.\nclass ModificationSpecifier { AdverbialPhrase *pAdverbialPhrase; // e.g. \u201cquickly\u201d AdverbialExpression *pAdverbialExpression; // e.g. \u201cI awoke while it was still dark.\u201d PredicateExpression *pPredicateExpression; // e.g. \u201cThe snows came early that year, // driving the bears into an early hibernation.\u201d SyntacticPosition syntacticPosition; // e.g. Leading, PreVerb, PostVerb, Final int ordinalPredicate; // refers to a predicate specifier };\n6.4. Data Structures and Data Types: Internal/Operational\nThe ObjectInstance structure is shown here: this is the main data structure that is used for\ninformation within an internal instance model. (Note: this shows one of two alternatives (fixedlength array) for storing attributes and relationships \u2013 the second approach uses a list). class ObjectInstance { private: ObjectFrameClass *m_pReferenceObjectFrameClass; // (ptr to class from which it was instantiated) public: char szContentString [MAXLEN_CONTENTSTRING_STAR]; // e.g. stores \u201ccouncilmen\u201d char szUniqueIdentifier [MAXLEN_UNIQUEID_STRING]; // unique id bool fMultiple; // specifies this as a collection (set) of object instances //------------------------------------------------------- // Features of the Object Instance: // // - upon instantiation, each of the following is derived using any // available features from the object frame class. // - during subsequent instance model generation, new features may be added. // RelationshipToParent relationshipToParent; // (from ObjectFrameClass::Structure structure) InstanceStructure structure; // (from ObjectFrameClass::Attributes attributes) AttributeBaseExpression *rgpAttributeExpressions [MAX_OBJECTFRAMEINSTANCE_ATTRIBUTES]; // (from ObjectFrameClass::Relationships relationships) RelationshipExpression *rgpRelationshipExpressions [MAX_OBJECTFRAMEINSTANCE_RELATIONSHIPS]; //------------------------------------------------------- // List of associated behaviors: // BehaviorClassList behaviorClassList; // Methods not shown };\nThe InstanceStructure member contains embedded objects: this is of particular importance for\ninstance models, insofar as a structural parent object instance is only a \u201cholder\u201d. (Structural parent object instances exist at the top level in an instance model as members of Contexts, described later). For instance, a structural parent instance based on the EverydayObjectStructuralParentClass may contain an object instance for a HouseClass and a DrivewayClass. An analogy that may help illustrate these concepts is the diorama: a structural parent object instance is like a diorama that is frozen at one instant of time; the object instances that it contains (e.g. a house, a car) are like objects in a diorama. (The representation of time is accomplished by the use of the Context).\nThe ObjectInstanceSemanticWrapper structure is used by the spanning information data structure: class ObjectInstanceSemanticWrapper { // (reference-only: do not deallocate this pointer) ObjectInstance *pObjectInstance; //------------------------------------------------------- // SNF Information: // EntityArgumentSemanticRole semanticRole; // one of: Actor, Actee, Extra ExtraSubRole extraSubRole; SyntacticRole syntacticRole; // e.g. subject, direct object, indirect object int ordinalOfPredicate; };\nThe BehaviorClassesPerMainVerbWrapper stores a main verb word and the associated\nbehavior classes. E.g. given the sentence, \u201cThe man could not lift his son or carry his daughter because he was too weak.\u201d, this stores information to relate a list of behavior classes for each predicate separately: class BehaviorClassesPerMainVerbWrapper { char szMainVerbWord [MAXLEN_SINGLEWORDSTRING]; // e.g. \u201clift\u201d, \u201ccarry\u201d BehaviorClassList behaviorClassList; // e.g. NotPersonLiftsPerson01, NotPersonLiftsPerson02 };\nThere are several ActivePointer structures that are maintained per predicate expression and\nthat are used internally by the engine: they are not shown here. The SpanningInformation structure contains information that normally corresponds to the previous predicate expression; it stores pointers to object instances in the master internal instance model. struct SpanningInformation { DiscourseContext discourseContextSaved; // (do not call delete for these pointers) Context *pContextMRU; // (most-recently-used Context in the master instance model) ObjectFrameClass *pObjectFrameClassStructuralParent;\nObjectInstance *pObjectInstanceStructuralParent; // The main list of ObjectInstanceSemanticWrappers: // ObjectInstanceSemanticWrapperList objectInstanceSemanticWrapperList; BehaviorClassPerMainVerbWrapperList behaviorClassPerMainVerbWrapperList; // (Methods not shown) }; // struct SpanningInformation\nThe SpanningInfoStack allows for the storage of multiple spanning infos.\nSpanningInformation pointers (referred to as \u201cspanning info\u2019s\u201d) are pushed onto the stack in an order that is dependent on the control strategy for processing of PEs (by default this order reflects the order of original syntactic meaning units). The engine uses a stack trim operation (not shown) in order to limit the size of the stack: this is based on the heuristic assumption that there is a limit to the number of prior sentences/clauses that may intervene between an antecedent referent and an anaphoral pronoun. E.g. the stack trim may be invoked so that the size of the stack stays in the range of 10 to 15 meaning units. //---------------------------------------------------------------------------- // // class SpanningInfoStack // //---------------------------------------------------------------------------- // struct SpanningInfoStackNode { // Data: SpanningInformation *pSpanningInformation; SpanningInfoStackNode *up; SpanningInfoStackNode *down; // (Methods not shown) }; class SpanningInfoStack { private: SpanningInfoStackNode *curr; public: SpanningInfoStackNode *top; // Methods: SpanningInfoStack (); void Push (SpanningInformation *pSpanningInformation); bool Pop (SpanningInformation **ppSpanningInformation); bool Current (SpanningInformation **ppSpanningInformation); void ResetCurrentToTop (); void DiscardAll();\n}; // struct SpanningInfoStack\nThe PronounFeatureSet data structure stores all information that can be gathered about the\npronoun and its context within the clause in which it appears. Several supporting enumerated types are shown first: //---------------------------------------------------------------------------- // // enum PredicateExpressionTemporalOrderIndicator // //---------------------------------------------------------------------------- // enum PredicateExpressionTemporalOrderIndicator { PredicateExpressionTemporalOrderIndicatorFollowing, PredicateExpressionTemporalOrderIndicatorPreceding, // e.g. for \u201cafter\u201d PredicateExpressionTemporalOrderIndicatorUndetermined, // PredicateExpressionTemporalOrderIndicatorNONE }; //---------------------------------------------------------------------------- // // enum PredicateExpressionHypotheticalUsage // // Note: a predicate expression may have a hypothetical usage (\"because ...\") // and at the same time convey declarative information. // //---------------------------------------------------------------------------- // enum PredicateExpressionHypotheticalUsage { PredicateExpressionHypotheticalUsageExplanationOfCause, // \"because\" PredicateExpressionHypotheticalUsageExplantionOfEffect, // \"causing ...\" PredicateExpressionHypotheticalUsageExplantionOfObjective, // \"in order to ...\" // PredicateExpressionHypotheticalUsageNONE }; //---------------------------------------------------------------------------- // // enum PronounGender // //---------------------------------------------------------------------------- // enum PronounGender { PronounGenderMale = 0, PronounGenderFemale, PronounGenderNonspecific, // PronounGenderNONE }; //---------------------------------------------------------------------------- //\n// enum PronounCardinality // //---------------------------------------------------------------------------- // enum PronounCardinality { PronounCardinalitySingular = 0, PronounCardinalityPlural, PronounCardinalityNonspecific, // PronounCardinalityNONE }; //---------------------------------------------------------------------------- // // enum PronounActiveOrPassive // (e.g. \"they\" (active) versus \"them\" (passive)) // //---------------------------------------------------------------------------- // enum PronounActiveOrPassive { PronounActiveOrPassiveActive = 0, PronounActiveOrPassivePassive, PronounActiveOrPassiveNonspecific, // PronounActiveOrPassiveNONE }; //---------------------------------------------------------------------------- // // enum SyntacticRole // //---------------------------------------------------------------------------- // enum SyntacticRole { SyntacticRoleSubject = 0, SyntacticRoleDirectObject, SyntacticRoleIndirectObject, // SyntacticRoleNONE }; //---------------------------------------------------------------------------- // // enum SemanticRole // //---------------------------------------------------------------------------- // enum SemanticRole { SemanticRoleActor = 0, SemanticRoleActee, SemanticRoleExtra, // SemanticRoleNONE };\n//---------------------------------------------------------------------------- // // struct PronounFeatureSet // //---------------------------------------------------------------------------- // struct PronounFeatureSet { char szPronounWord [MAXLEN_SINGLEWORDSTRING]; PronounGender pronounGender; PronounCardinality pronounCardinality; PronounActiveOrPassive pronounActiveOrPassive; // PredicateExpression Fields: PredicateExpressionTemporalOrderIndicator predicateExpressionTemporalOrderIndicator; PredicateExpressionHypotheticalUsage predicateExpressionHypotheticalUsage; DiscourseContext discourseContext; SyntacticRole syntacticRole; SemanticRole semanticRole; //======================================== // Other Object Instances: (non-pronouns or resolved pronouns) // ObjectInstanceSemanticWrapperList objectInstanceSemanticWrapperList; //======================================== bool fNegationOfSearchKeyWord; PredicateSpecifierRole predicateSpecifierRole; char *pszSearchKeyWordAdjective; // non-null for AttributiveArgumentRole = Attribute char *pszSearchKeyWordVerb; // e.g. \u201crefused\u201d // (Methods not shown) }; // struct PronounFeatureSet\n6.5. Data Structures and Data Types: Instance Model\nThe instance model is implemented as a ContextList. The following listing contains the\nContext data structure and the ContextList structure. The map that contains all top-level structural parent instances is in bold: struct Context { char szUniqueIdentifier [MAX_SIZE_UNIQUEID_STRING]; DiscourseContext discourseContext; char szLeadingObjectInstanceClassName [MAXLEN_CONTENTSTRING_STAR]; char szTemporalAttributeValueLastUsed [ATTRIBUTE_VALUE_MAX_SIZE];\n//-------------------------------------------------------------------------------------------------------- // Map that contains all structural parent instances, indexed by time attributes: // MapObjectInstances *pMapObjectInstances; // Methods not shown: }; struct ContextListNode { Context *pContext; struct ContextListNode *prev; struct ContextListNode *next; // Methods not shown: }; class ContextList { private: ContextListNode *m_head; ContextListNode *m_tail; public: // Public methods not shown: };\nThe MapObjectInstances structure stores structural parent object instances, each of which is\nindexed by a temporal attribute value. // MapObjectInstances: // // - the wrapper class is not shown; the map of object instances contains ObjectInstance pointers: // typedef map <string, ObjectInstance*> MapTypeObjectInstances; typedef pair<MapTypeObjectInstances::iterator,bool> retvalMapTypeObjectInstances;\n6.5. Engine Driver Algorithm\nThe following is the control flow for the engine driver that iteratively processes all\ncommunication units and does several other tasks. During processing, the engine driver builds the master internal instance model, generates spanning information within the spanning info stack, and also adds disambiguation information, as it is determined, to the master token list that is associated with the syntactic and semantic normal form information. It also generates an external instance model, and any other external information artifacts (e.g. bulleted summary) that have been specified. EngineDriver ( input: list of communication units (containing embedded PEs using SNF) output: disambiguation information (stored in master token list), output: instance model and other selected models ) // other tasks here not shown\nProcessAllCommunicationUnits () GenerateOutputInstanceModels () Return\nProcessAllCommunicationUnits() is shown next. For each communication unit that is a\nsentence, this routine extracts a pointer to the first predicate expression in the list and passes it to the function ProcessPredicateExpression() (shown inline). The iterative processing performs the same task for all subsequent predicate expressions within the same list within the sentence. ProcessAllCommunicationUnits () pCommUnitList->First() while (!pCommUnitList->IsDone()) { if (pCommUnit->communicationUnitType != CommunicationUnitTypeSentence) // Handle other comm unit types and continue \u2026 Sentence *pSentence = pCommUnit->pSentence; PredicateExpression *pPredicateExpression = pSentence->GetFirstPredicateExpression(); while (pSentence->IsDonePredicateExpressionList()) // (loop to get all predicate expressions) { // process one predicate expression: if (pPredicateExpression != NULL) ProcessPredicateExpression () { switch (pPredicateExpression->grammaticalMood) { case GrammaticalMoodIndicative: ProcessPredicateUnitIndicative () case GrammaticalMoodInterrogative: ProcessPredicateUnitInterrogative () case GrammaticalMoodImperative: ProcessPredicateUnitImperative () } } pPredicateExpression = pSentence->GetNextPredicateExpression (); } // while (loop to get all predicate expressions) pCommUnitList->Next() } // while (loop to get all communication units)\nReturn // from ProcessAllCommunicationUnits ()\nProcessPredicateUnitIndicative processes a predicate expression as follows. The details of\nthe control strategy for populating and maintaining the spanning information stack are not provided here; by default, the spanning information stack items get pushed onto the stack in the order in which they appear within the input natural language text. The PredicateExpression::PredicateExpressionPointerList is used by default to support population of the spanning info stack using a sequence that corresponds to the syntactic order of the original input meaning units. For instance, a leading adverbial clause such as \u201cBefore the first light dawned\u201d, will generate a spanning info that gets pushed onto the stack before the subsequent main clause with the same sentence. (E.g. full sentence: \u201cBefore the first light dawned, Joe ran several miles.\u201d).\nBecause the main control strategy within this function is iterative, and indirect recursive calls\nare used to process nested PEs, there is a limit to the levels of nesting in the input that are processed recursively. Examples:\n \u201cThe trophy that Tim won doesn\u2019t fit in the suitcase.\u201d \u2013 one level of nesting, processed by a\nrecursive call.\n \u201cThe trophy that Tim won for the contest that he entered last year doesn\u2019t fit in the\nsuitcase.\u201d \u2013 two levels of potential recursion, however the second bound relative clause is not handled by a nested recursive call; rather \u201cthat he entered last year\u201d is processed in the iteration sequence since it is pointed to by a node in the PredicateExpressionPointerList.\n(Note: the functionality of ProcessPredicateUnitInterrogative() and ProcessPredicateUnitImperative() are similar and are not shown here). ProcessPredicateUnitIndicative (IN: PredicateExpression *pPredicateExpressionMain, OUT: SpanningInfoStack *pSpanningInfoStack, OUT: InstanceModel *pInstanceModel) SetTimelineHintInformation () // examine adverbial information that indicates time and temporal order PredicateExpressionPointer *pPredicateExpressionPointer = pPredicateExpressionMain->GetFirstPEPointer(); while (!pPredicateExpressionMain->IsDonePredicateExpressionPointerList()) { If (pPredicateExpressionPointer points to self/this) { // (not shown: process arguments for predicate type PredicateToBeAttributive; new attribute // information gets added to the appropriate instance model object instance) // (not shown: process arguments for each of predicate types: PredicateToBeIsA, PredicateHasAVerb) // Process non-nested entity argument, e.g. \u201cJoe\u201d, \u201cmiles\u201d that do not contain pronouns: ProcessNonPronounEntityArguments (pPredicateExpressionMain-> entityArgumentSpecifierList, pSpanningInfoStack, pInstanceModel ); ProcessPronounEntityArguments (pPredicateExpressionMain-> entityArgumentSpecifierList, pSpanningInfoStack,\npInstanceModel ); if (failed to resolve the pronoun) { // Lookahead: (possibly a cataphoric pronoun) // // E.g. \u201cBecause it was too big, the trophy did not fit in the suitcase.\u201d pPredicateExpressionPointer = pPredicateExpressionMain->GetNextPEPointer(); // process non-nested entity arguments in the PE, populate a temporary spanning info // retry: ProcessPronounEntityArguments() // use temp spanning info } // Extract predicate adverbials: get adverbs and adverb phrases that modify a verb // in the predicate specifer, (e.g. \u201cnot\u201d, e.g. \u201cquickly\u201d) ExtractPredicateAdverbials (); if (predicateSpecifierRole == PredicateVerbTakingEntityArgument) { ProcessPredicateSpecifierList (); } } Else { // The following will do indirect recursion to process the PE pointed to by pPredicateExpressionPointer: If (nested PE is within a modification specifier) { ProcessModificationSpecifier (); // e.g. leading adverbial phrase, e.g. final adverbial phrase } Else if (nested PE is within an entity argument) { ProcessNestedEntityArgument (); // e.g. gerundive phrase, e.g. \u201cwalking to the corner\u201d // e.g. nested bound relative clause, e.g. \u201cthe person who fell ill\u201d } } pPredicateExpressionPointer = pPredicateExpressionMain->GetNextPEPointer(); } // while (loop to get top-level and nested PEs from pPredicateExpressionMain) Return\nProcessNonPronounEntityArguments () iteratively process the entity arguments that do not\ncontain pronouns:\nProcessNonPronounEntityArguments (IN: entityArgumentSpecifierList, OUT: pSpanningInfoStack, OUT: pInstanceModel) while (entityArgumentSpecifierList is not empty) { If (entity argument specifier does not contain a pronoun)\nProcessEntityArgument (pEntityArgumentSpecifier, pSpanningInfoStack, pInstanceModel) } // while () Return\nProcessEntityArgument () - this function processes information that was originally part of\nthe syntactic subject, direct object, indirect object and any other entities within prepositional phrase complements within the meaning unit that corresponds to the predicate expression. The entity resolution (class selection) tasks for the actors, actees, and extras of the predicate unit are performed within ProcessEntityArgument (). For all noun phrases except those that contain unresolved pronouns, internal instance model instantiation takes place. (MainDriverForInstanceModelGeneration() represents a complex sub-system, the functionality of which is outside the scope of this document). The control flow of ProcessEntityArgument () is as follows (showing the lower level functions inline). ProcessEntityArgument ( IN: EntityArgumentSpecifier *pEntityArgumentSpecifier, OUT: pSpanningInfoStack, OUT: pInstanceModel) // EntityArgumentSpecifier: // EntityDesignatorList entityDesignatorList; // EntityDesignator // NounPhrase *pNounPhrase; // PrepositionalPhrase *pPrepositionalPhrase; // char szTrailingConnectiveWord; // e.g. \u201cand\u201d // EntityArgumentSemanticRole semanticRole; // one of: Actor, Actee, Extra // ExtraSubRole extraSubRole; // SyntacticRole syntacticRole; // e.g. subject, direct object, indirect object // int ordinalPredicate; // refers to a predicate specifier Loop: // process each item in entityDesignatorList: switch (type) // noun phrase or prepositional phrase { case NounPhrase: ProcessNounPhrase () { EntityResolutionRoutine (pEntityDesignator->pNounPhrase, pSpanningInfoStack) } break; case PrepositionalPhrase: ProcessPrepositionalPhrase () { // (note: if role is Extra, SubRole is available here) // Extract noun phrase (not shown) EntityResolutionRoutine (pEntityDesignator->pPrepositionalPhrase->pNounPhrase, pSpanningInfoStack) }\nbreak; } // switch MainDriverForInstanceModelGeneration () // Instance Model Generation (not shown) End Loop Return\nProcessPronounEntityArguments () is similar to ProcessNonPronounEntityArguments(); it\ncalls ProcessPronounEntityArgument (), which is similar to ProcessEntityArgument(), and only processes entity arguments that contain pronouns. (Detail not shown).\nProcessModificationSpecifier () is shown next; the main processing task is to handle the\nnested predicate expression, for which ProcessPredicateExpression() is invoked. ProcessModificationSpecifier (IN: pPredicateExpression, OUT: pSpanningInfoStack) // other tasks here not shown ProcessPredicateExpression (pPredicateExpression, pSpanningInfoStack) Return\nProcessPredicateSpecifierList() is outlined here. Like ProcessEntityArgument(), this function also generates instance model information, but it is based on main verbs that represent processes (it is only invoked for predicateSpecifierRole == PredicateVerbTakingEntityArgument). (Note: C++ arguments are shown for some calls to lower-level routines).\nProcessPredicateSpecifierList () pPredicateSpecifier = PredicateSpecifierList->First(); while (!PredicateSpecifierList ->IsDone()) { // Search to get list of all relevant behavior classes: iResult = SearchObjectFrameClassBehaviorClasses (pPredicatePhrase->szMainVerbWord, NULL, // word2 NULL, // word3 RuleDirectionUnspecified, fNegation, pActivePointersForClasses->clustSem.pObjectFrameClassActorList, pActivePointersForClasses->clustSem.pObjectFrameClassActeeList, pActivePointersForClasses->clustSem.pObjectFrameClassExtraList, &pBehaviorClassList); // check iResult \u2026 // Apply/process the behavior class (first behavior class or higher behavior class) // (this performs possibly extensive Instance Model Generation (not shown))\niResult = ProcessBehaviorClassForSubjectActive (pInfopedia, pActivePointersForClasses, pActivePointersForInstances, // (contains linkage into master instance model) pBehaviorClassList->GetFirstBehaviorClass()); // check iResult \u2026 // Completion tasks for Instance Model Generation (not shown) // Set SpanningInfo fields (not shown) pPredicateSpecifier = PredicateSpecifierList ->Next(); } Return\n7. General Pronoun Resolution Method\nThis section explains the general pronoun resolution method. This method has been used to\nprocess the following Winograd Schema Challenge schemas:\n trophy and suitcase schema (this schema is processed using the general pronoun resolution\nmethod as it is supplemented by the modeling of the communicative agent (see Appendix 1: Solution for \u201cTrophy and Suitcase\u201d Schema Using a Model of the Communicating Agent).\n man cannot lift his son  Joe paid the detective  city councilmen refusing a permit because they feared violence.\nA subsequent section describes the embedded commonsense reasoning method that is invoked\nduring execution of the general pronoun resolution method when a situation is encountered that cannot be solved by the general method. The embedded commonsense reasoning method is applied when resolving this schema:\n city councilmen refusing a permit because they advocated violence.\n7.1. Entity Resolution (Class Selection)\nThis function is called EntityResolutionRoutine (). For situations where a pronoun exists in\nany meaning unit/predicate expression other than the first within the input text, this function will get invoked twice:\n During processing of the main predicate expression  During processing of the current predicate expression\nEntityResolutionRoutine (IN: EntityArgumentSpecifier *pEntityArgumentSpecifier, IN/OUT: ActivePointers *pActivePointers,\nOUT: SpanningInfoStack *pSpanningInfoStack) { // Loop: iterate through the list of noun phrase head words: e.g. \"Fred and Mary walked their dog.\" NounHeadWordListNode *pNounHeadWordCurrNode = pNounPhrase->pMainWordHeadNode; while (pNounHeadWordCurrNode != NULL) { switch (pNounHeadWordCurrNode->nounWordPhraseType) { case NounWordPhraseTypePronoun: ProcessPronoun (pSpanningInfoStack, pActivePointers, pPronounFeatureSet); break; case NounWordPhraseTypeExistentialThere: ProcessExistentialThere(); break; case NounWordPhraseTypeCommonNoun: ProcessCommonNounPhrase (); case NounWordPhraseTypeProperNoun: ProcessProperNounPhrase (); }; // switch() pNounHeadWordCurrNode = pNounHeadWordCurrNode->next; } // while () // Determine a structural parent class that can be used for the entity or entities: iResult = GetBaseStructuralParentClass (); Return from EntityResolutionRoutine()\nThe functions to process common nouns, proper nouns, and the existential \u201cthere\u201d are not\ndescribed here. ProcessPronoun() is described next.\n7.2. ProcessPronoun() -> PronounResolutionGeneralMethod()\nThe ProcessPronoun() routine attempts to determine both the referent and the antecedent for a\npronoun. Determination of the referent involves identifying both the object frame class and the specific instance model object instance. The spanning information stack is used throughout the functions that are invoked by ProcessPronoun(). An ActivePointers data object is also used (it is similar to the spanning information structure but it represents the current meaning unit).\nProcessPronoun() is not shown here: its primary function is to pass control to\nPronounResolutionGeneralMethod(), which is the main driver and worker routine for pronoun resolution. (The following functions show the C++ return types and several instances of error codes, such as E_SUCCESS and E_NOTFOUND).\nint PronounResolutionGeneralMethod (SpanningInfoStack *pSpanningInfoStack, IN/OUT: ActivePointers *pActivePointers, PronounFeatureSet *pPronounFeatureSet, { //---------------------------------------------------------------------------------- // If pronoun is post-verb object (e.g. him/her/them/it) attempt to resolve it to a pre-verb entity // (return if successful) // (e.g. \u201cThe owners of the house sold it.\u201d) //---------------------------------------------------------------------------------- // Main driver for searching the instance model via the spanning information: // iResult = ExploratorySearchUsingSpanningInfoStack (pSpanningInfoStack, pPronounFeatureSet, &pMatchingObjectInstance, // other parameters not shown); // check iResult \u2026 //------------------------------------------------------------------------ // Check results from the exploratory search routine: // if (found a referent) { *ppObjectFrameClassReferent = pMatchingObjectInstance->GetReferenceObjectFrameClass(); // Save for disambiguation: pszOriginalObjInstWord = pMatchingObjectInstance->szContentString; // \"trophy\", \"Joe\", \"detective\" } // Modify the object instance within the (actual situation) instance model: SetAttributeWithinActualSituationEntity (pMatchingObjectInstance, szCausalFeatureAttributeType, // e.g. \u201cFunctionalAttribute1\u201d szCausalFeatureValue); // e.g. \u201cTooSmall\u201d //--------------------------------------------------------------------------------- // Process disambiguation tasks: // if (disambiguationTask == DisambiguationTaskPronouns) { iResult = SetPronounResolutionInformationInMasterTokenList (pszOriginalObjInstWord, pPronounFeatureSet, pFirstTokenNode); if (iResult != E_SUCCESS) { return iResult; } } // if (disambiguationTask == DisambiguationTaskPronouns) return E_SUCCESS; } // PronounResolutionWorkerRoutine ()\n7.3. SetPronounResolutionInformationInMasterTokenList ()\nSetPronounResolutionInformationInMasterTokenList () inserts the results of the pronoun\nresolution into the master token list. (The following feature not yet implemented: insert all words for a noun phrase, not just the noun head word (e.g. \u201ctrophy\u201d)). int SetPronounResolutionInformationInMasterTokenList (char *pszOriginalObjInstWord, PronounFeatureSet *pPronounFeatureSet, TokenListNode *pFirstTokenNode) { if (pszOriginalObjInstWord == NULL) { return E_NOTFOUND_REQUIREDITEM; } if (pPronounFeatureSet->szPronounWord[0] != '\\0') { TokenListNode *pTokenNodeTEMP = pFirstTokenNode; // Search the token sub-list for the pronoun: while (pTokenNodeTEMP != NULL && pTokenNodeTEMP->pMarkers->commUnitMarker != CommUnitMarkerEnd && 0 != strcmp (pTokenNodeTEMP->tokenvalue, pPronounFeatureSet->szPronounWord)) { pTokenNodeTEMP = pTokenNodeTEMP->next; } if (pTokenNodeTEMP == NULL) { return E_NOTFOUND_REQUIREDITEM; } else { strcpy (pTokenNodeTEMP->tokenResolvedWord, pszOriginalObjInstWord); } } return E_SUCCESS; }\n7.4. ExploratorySearchUsingSpanningInfoStack()\nExploratorySearchUsingSpanningInfoStack () is a driver function that iterates to perform the\npronoun resolution search logic against each spanning info in the spanning info stack. int ExploratorySearchUsingSpanningInfoStack ( // IN: SpanningInfoStack *pSpanningInfoStack, PronounFeatureSet *pPronounFeatureSet, // OUT: char *pszCausalFeatureAttributeType, char *pszCausalFeatureValue, bool *pfFoundPopObj, bool *pfFoundMatchingNestedBehavior, ObjectInstance **ppMatchingObjectInstance,\nBehaviorClass **ppBehaviorClassNested) { int iResult = E_NOTFOUND; // Main Loop: until reach bottom of StackOfSpanningInfos SpanningInformation *pSpanningInformation = NULL; pSpanningInfoStack->ResetCurrentToTop(); while (pSpanningInfoStack->Current(&pSpanningInformation)) { iResult = ExploratorySearchUsingOneSpanningInfo pSpanningInformation, pPronounFeatureSet, pszCausalFeatureAttributeType, pszCausalFeatureValue, pfFoundPopObj, pfFoundMatchingNestedBehavior, ppMatchingObjectInstance, ppBehaviorClassNested); if (iResult == E_SUCCESS) { break; // Found } } // End Main Loop pSpanningInfoStack->ResetCurrentToTop(); return iResult; }\n7.5. ExploratorySearchUsingOneSpanningInfo()\nExploratorySearchUsingOneSpanningInfo () iterates to test each candidate object instance in\nthe instance model against the pronoun feature set. If multiple behavior classes are a match, the probabilities of the nested behaviors of each are compared in order to select the nested behavior and the object that have the highest probability. ExploratorySearchUsingOneSpanningInfo ( // IN: SpanningInformation *pSpanningInfo, PronounFeatureSet *pPronounFeatureSet, // OUT: char *pszCausalFeatureAttributeType, char *pszCausalFeatureValue, bool *pfFoundPopObj, bool *pfFoundMatchingNestedBehavior, ObjectInstance **ppMatchingObjectInstance, BehaviorClass **ppBehaviorClassNested) while (candidates exist) { TestOneCandidateObjectInstance (candidate) }\n// Compare Probabilities, allowing for the following to be set: (compare logic not shown) *ppMatchingObjectInstance = pSpanningInformation->GetObjectInstance(idx); *ppBehaviorClassNested = pBehaviorClassNested[idx]; }\n7.6. TestOneCandidateObjectInstance()\nTestOneCandidateObjectInstance () branches to an appropriate subroutine depending on the\ninformation that is available in the pronoun feature set:\n Adjective info: TryToMatchCausalFeatureAgainstSpanningInfoObjectInstance()  Verb info: TryToMatchVerbCausalFeatureAgainstSpanningInfoObjectInstance()\n(The logic of these two functions is not shown here). If the input pronoun feature set contains a verb word, and if pronoun resolution fails after\nattempting to resolve it with TryToMatchVerbCausalFeatureAgainstSpanningInfoObjectInstance(), then GenerateAndTestForCausativeSituation() is invoked. This is the embedded sandbox-based generate and test method. Example of object instance candidates for W.S. schema #1 are \"councilmen\", \"demonstrators\", and \u201cpermit\u201d. Here is the logic that is used when invoking the embedded reasoning routine:\nTestOneCandidateObjectInstance () // Test the candidate using TryToMatchVerbCausalFeatureAgainstSpanningInfoObjectInstance() if (iResult == E_NOTFOUND) { // GenerateAndTest: Try doing a forward inference for this candidate (e.g. \"demonstrators\") if (pPronounFeatureSet->meaningUnitHypotheticalUsage == MeaningUnitHypotheticalUsageExplanationOfCause && pPronounFeatureSet->pszSearchKeyWordVerb != NULL) { iResult = GenerateAndTestForCausativeSituation (pSpanningInformation, pPronounFeatureSet, pObjInstCandidate, semanticRoleCandidate, pBehavClassHeadNodeForCandidate, pfFoundMatchingNestedBehavior, ppBehaviorClassNested); if (iResult != E_SUCCESS && iResult != E_NOTFOUND) { return iResult; } }\nGenerateAndTestForCausativeSituation() is the driver for the embedded reasoning tasks and is\ndescribed in the next section.\n8. Embedded Commonsense Reasoning Method\nGenerateAndTestForCausativeSituation() is one of the main routines that implements the\nembedded commonsense reasoning method. This section will describe the embedded reasoning method using the example of WS schema #1/variant 2 (\u201cadvocated violence\u201d).\nGenerateAndTestForCausativeSituation() is one of multiple possible routines \u2013 each of which\nperforms inference for a similar purpose. GenerateAndTestForCausativeSituation() handles cases that involve finding a referent for which the antecedent exists in a clause (e.g. a \u201cbecause\u201d clause) that is an explanation of the cause for a situation. (Other such routines are not described in this document).\nThe main task of this function is that of testing the input object instance candidate (e.g. \u201cthe\ncity councilmen\u201d, e.g. \u201cthe demonstrators\u201d, e.g. \u201ca permit\u201d) to determine if it could have participated in a behavior that led to the fact that was stated in the main clause (e.g. \u201cthe city councilmen refused the demonstrators a permit\u201d). Because it is not known at this stage whether or not the candidate is the referent (e.g. it was the demonstrators who advocated violence, not the councilmen), there is a need to create a temporary \u201csandbox\u201d instance model that exists apart from the engine\u2019s master internal instance model. (Once the correct candidate has been identified, the master instance model will get updated with the newly-acquired information).\nThe sandbox instance model is a staging area that actually involves two separate instance\nmodel contexts: to avoid confusion these will be referred to as \u201ceast\u201d side (earlier) and \u201cwest\u201d side (later). The task of the routine is to build the two \u201csides\u201d of the instance model and then determine whether or not they \u201cmeet up\u201d using a final matching routine (similar to building an East railroad line and a West line and joining them in the middle). An overview of the process is as follows:\n(West: represents earlier points along the time-line, starting with a candidate that might have\n\u201cadvocated violence\u201d) (the following is done iteratively for each main rule matching \u201cadvocated violence\u201d)\n- given the object instance candidate, e.g. councilmen - find a main rule (i.e. a rule for \u201cadvocate violence\u201d \u2013 e.g.\nTalkerAdvocatesActionWithListenersWhoAnticipateSomething)\n- create a sandbox context and insert an earliest structural parent instance into it - apply the main rule to derive consequential information, save a pointer to a nested rule - apply the nested rule (e.g. AnticipateHarmfulEvent) to generate new information into the\nWest-side temporary context.\n(East: represents later points along the time-line, working backward from the time point where\n\u201cthe city councilmen refused the demonstrators a permit\u201d) (the following is done iteratively)\n- e.g. given \u201cthe city councilmen refused the demonstrators a permit\u201d utilize master instance\nmodel information to create the East-side temporary context\n- apply nested rule that is contained within the \u201crefuse \u2026\u201d rule\n- (see subsequent section for logic that matches attribute state values from the West and\nEast contexts)\nGenerateAndTestForCausativeSituation( // IN: PronounFeatureSet *pPronounFeatureSet, ObjectInstance *pObjInstCandidate, SpanningInformation *pSpanningInformation, // IN/OUT BehaviorClassListNode *pBehavClassHeadNodeForCandidate, // list // OUT: bool *pfFoundMatchingNestedBehavior, BehaviorClass **ppBehaviorClassNested) // (example values for pBehavClassHeadNodeForCandidate; this parameter is not used here // but is passed into GenerateAndTest_ProcessOneForwardRule() // - RefusingSomethingDueToFearBehaviorClass // - RefusingSomethingDueToFearOnPartOfRequestorBehaviorClass) //------------------------------------------------------------------ // Use pPronounFeatureSet->semanticRole to determine roles within current clause: // // e.g. set pObjFrameClassActorTemp (not shown) //------------------------------------------------------------------ // SearchObjectFrameClassBehaviorClasses BehaviorClassListNode *pBehaviorClassListNodeHeadForwardRule = NULL; iResult = SearchObjectFrameClassBehaviorClasses (pPronounFeatureSet->pszSearchKeyWordVerb, // e.g. \"advocated\" NULL, // word2 NULL, // word3 RuleDirectionForward, false, // fNegationNestedBehavior, pObjFrameClassActorTemp, pObjFrameClassActeeTemp, pObjFrameClassExtraTemp, &pBehaviorClassListNodeHeadForwardRule); if (iResult != E_SUCCESS) { if (iResult == E_NOTFOUND_REQUIREDITEM) { return E_NOTFOUND; } return iResult; } //------------------------------------------------------------------ // Loop: // - search each nested behavior class: (e.g. \" TalkerAdvocatesActionWithListenersWhoAnticipateSomething\") // BehaviorClassListNode *pBehavClassCurrNode = pBehaviorClassListNodeHeadForwardRule; while (pBehavClassCurrNode != NULL) { if (pBehavClassCurrNode->pBehaviorClass->pBehaviorClassExpression->fCausalRule)\n{ iResult = GenerateAndTest_ProcessOneForwardRule( pSpanningInformation, pPronounFeatureSet, pObjInstCandidate, pBehavClassCurrNode->pBehaviorClass, // pBehaviorClassForwardRule pBehavClassHeadNodeForCandidate, pfFoundMatchingNestedBehavior, ppBehaviorClassNested); if (iResult == E_SUCCESS && (*pfFoundMatchingNestedBehavior)) { break; // (done, since only one match is needed) } } pBehavClassCurrNode = pBehavClassCurrNode->next; } Return from GenerateAndTestForCausativeSituation()\nGenerateAndTest_ProcessOneForwardRule () has the following inputs:\n A pointer to the object instance candidate (e.g. an object instance representing the\n\u201ccouncilmen\u201d, or an object instance representing the \u201cdemonstrators\u201d). The object instance data structure also contains a pointer to the object frame class from which it is derived so that object frame class information, such as structural parent class can be obtained.\n A behavior class that has been retrieved by a prior search process that provided one or\nmore object frame classes and a verb-based expression. An example such behavior class is called \u201cTalkerAdvocatesActionWithListenersWhoAnticipateSomething\u201d \u2013 this behavior class was retrieved based on the verb \u201cadvocates\u201d along with other criteria.\n The pronoun feature set data structure; this includes information about the other syntactic\nand semantic entities of the clause or phase wherein the pronoun is contained. E.g. for \u201cbecause they advocated violence\u201d, it includes \u201cviolence\u201d as a syntactic direct object and as an object that fills the actee semantic role within that clause.\nThis routine first creates the temporary working memory sandbox (West) context. The output\nof this routine as shown below is the West context as it has been added to by the insertion of a major structural parent instance, a minor structural parent instance, and object instances within the structural parent instances. The object instances have had their state attributes set with values that will later get matched against attribute values of other object instances from the East sandbox context in order to determine if the candidate is the correct antecedent for the unresolved pronoun.\nNote that the example rule shown here contains an object for the \u201cTalker\u201d \u2013 this is handled as\na single talker even though it needs to be matched against a possible group of talkers (e.g. councilmen or demonstrators) because the singular/plural aspect is not relevant for the inference process (either \u201ccouncilman\u201d or \u201ccouncilmen\u201d will work). In contrast, the \u201clisteners\u201d are\nrepresented as a collection since it is necessary to represent the fact that there is a set of possible listeners; there is logic that determines that that set can include the councilmen, for the cases where the councilmen are not the talker. GenerateAndTest_ProcessOneForwardRule () // Original NL sentence example: // \"The city councilmen refused the demonstrators a permit because they advocated violence.\" // // INPUT: Main forward behavior class: TalkerAdvocatesActionWithListenersWhoAnticipateSomething // // ANTECEDENT: (not shown) // ... // CONSEQUENT: // // PopulatedObjectClass \"ConsequentActor\" ( // Talker // <ObjectFrameClass ref = PersonObjectFrameClass /> // <Attribute ref = CommunicatingState val = \"CommunicatingCompleted\" /> // ); // PopulatedObjectClass \"ConsequentActee\" ( // Representation-of-Action // <ObjectFrameClass ref = CommunicationUnitProposedActionObjectFrameClass /> // e.g. violence // <PassiveParticipant val = \"true\" /> // <Attribute ref = PassiveIsCommunicatedState val = \"Communicated\" /> // ); // PopulatedObjectClass \"ConsequentExtra\" ( // Listener(s) // <ObjectFrameClass ref = PersonObjectFrameClass /> // <Multiple val = \"true\" /> // Collection // <ExtraParticipant val = \"true\" /> // <Attribute ref = CommunicationReceivedState val = \"CommunicationReceived\" /> // <Attribute ref = UniqueIdentityAttributeType var = extra$ /> // ); // // reference to a nested rule: this represents that whoever is the listener will fear violence: // BehaviorClassReference ( // <BehaviorClass ref = AnticipateHarmfulEventBehaviorClass /> // <ParameterActor ref = PersonObjectFrameClass expr = extra$ /> // (reference to the listener(s)) // <ParameterActee ref = CognitiveRepresentationOfHarmfulEvent /> // ); //------------------------------------------------------------------------------------------------------------------ // (WEST SIDE) //------------------------------------------------------------------------------------------------------------------ //------------------------------------------------------------------------------------------------------------------ // Create a new temporary context along with a structural parent instance (\u201cmajor\u201d), // - sets context fields, and inserts the structural parent instance into the context. // - (by default use the first ordinal temporal attribute value of the structural parent class) // CreateSandboxContext() //------------------------------------------------------------------------------------------------------------------ // Create object instances and set values for semantic roles: // - create clone of the candidate object instance (pObjInstCandidate) // e.g. \u201ccouncilmen\u201d // - use the pronoun feature set to determine other object instances, e.g. \u201cviolence\u201d // EstablishObjectInstances()\n//------------------------------------------------------------------------------------------------------------------ // Attach all object instances to the structural parent (\u201cmajor\u201d) within the sandbox context: // AttachObjectInstancesToStructuralParentMajorAndInstantiate() //------------------------------------------------------------------------------------------------------------------ // Invoke the Main Inference Routine: // PerformForwardDirectedInferenceWithNestedBehavior() // (the West context has now been populated with all information based on the application of // the TalkerAdvocatesActionWithListenersWhoAnticipateSomething rule and the nested rule // that it contains - AnticipateHarmfulEventBehaviorClass //------------------------------------------------------------------------------------------------------------------ // (EAST SIDE) //------------------------------------------------------------------------------------------------------------------ ProcessLaterTemporalSandboxContextAndPerformMatchingTest () Return from GenerateAndTest_ProcessOneForwardRule ()\nRefer to Hofford (2014 (b)) \u201cThe ROSS User\u2019s Guide and Reference Manual\u201d, 15.6.2. Main\nInference Routine: Application of Two Rules for details on the functionality of PerformForwardDirectedInferenceWithNestedBehavior(). The inference involves an application of the main rule combined with a subsequent application of the nested rule in order to derive new information that represents that there is a set of listeners that anticipate/fear a harmful event (i.e. which includes violence).\nProcessLaterTemporalSandboxContextAndPerformMatchingTest () utilizes the later\ntemporal information that was provided by the original clause (e.g. \u201cthe city councilmen refused the demonstrators a permit\u201d). (This clause has already been used by the engine: the semantics that it represents exist in the master instance model and the spanning info data structure contains links that point at the relevant object instances).\nUsing the example, the main tasks are to iteratively: 1) derive a nested rule, if one exists, from\nthe main rule (e.g. main rule = RefusingSomethingDueToFearBehaviorClass), 2) apply the nested rule (e.g. AnticipateHarmfulEventBehaviorClass), and 3) determine if the generated information (from this East side context) matches the earlier generated information from the West side context. ProcessLaterTemporalSandboxContextAndPerformMatchingTest ( // IN: ObjectInstance *pObjInstCandidate, SpanningInformation *pSpanningInformation, // IN/OUT BehaviorClassListNode *pBehavClassHeadNodeForCandidate, // list // OUT: bool *pfFoundMatchingNestedBehavior, BehaviorClass **ppBehaviorClassNested) //------------------------------------------------------------------------------------------------------------------ // Loop: try each behavior class: e.g.: // // - RefusingSomethingDueToFearBehaviorClass\n// - RefusingSomethingDueToScheduleConflictBehaviorClass BehaviorClassListNode *pBehavClassCurrNode = pBehavClassHeadNodeForCandidate; while (pBehavClassCurrNode != NULL) { //------------------------------------------------------------------------------------- // Generate new object instances and states: // // Class: PersonObjectFrameClass (q$) -> Instance: AnticipatingHarmfulEventState = \"Anticipating\" // Class: CognitiveRepresentationOfHarmfulEvent -> Instance: PassiveIsAnticipatedState = \"Anticipated\" // CreateSandboxContext () // \u201cEast\u201d side context // Populate the context/put the object instances into the structural parent within the sandbox context: CloneObjectInstancesFromSpanningInfoObjectInstances() ; AttachObjectInstancesToStructuralParentAndInstantiate(); // Get nested rule from the next behavior class from the input list: pBehaviorClassNestedReference = NULL; GetNestedBehaviorClassReferenceFromBehaviorClass (pBehavClassCurrNode->pBehaviorClass, &pBehaviorClassNestedReference); // E.g. Nested behavior within RefusingSomethingDueToFearBehaviorClass: // // <BehaviorClass ref = AnticipateHarmfulEventBehaviorClass /> // <ParameterActor ref = PersonObjectFrameClass expr = q$ /> // <ParameterActee ref = CognitiveRepresentationOfHarmfulEvent /> // APPLY: Nested Rule/BehaviorClass: AnticipateHarmfulEventBehaviorClass ApplyBehaviorClass (pInfopedia, &activePointersForInstancesPOST, pBehaviorClassNestedReference->GetReferenceBehaviorClass()); // Check for match: information from West (earlier) versus East (later) iResult = MatchNewObjectInstanceStatesLatestPriorAgainstEarliestPost (pStructuralParentLATESTPRIOR, pStructuralParentEARLIESTPOST); if (iResult == E_SUCCESS) { *pfFoundMatchingNestedBehavior = true; *ppBehaviorClassNested = pBehaviorClassForwardRule; break; // !FOUND! } pBehavClassCurrNode = pBehavClassCurrNode->next; } // while (pBehavClassCurrNode != NULL) Return from ProcessLaterTemporalSandboxContextAndPerformMatchingTest ()\nThe details of MatchNewObjectInstanceStatesLatestPriorAgainstEarliestPost() are not\nshown. This function matches object instances, based on criteria that includes their respective object frame classes, and attribute state values. A set of example values is shown here: //================================================================================= // WEST: StructuralParent contains: // Instance: PersonObjectFrameClass (extra$) -> Attr:AnticipatingHarmfulEventState = \"Anticipating\" // Instance: CognitiveRepresentationOfHarmfulEvent -> Attr:PassiveIsAnticipatedState = \"Anticipated\" //================================================================================= // EAST: StructuralParent contains: // Instance: PersonObjectFrameClass (q$) -> Attr:AnticipatingHarmfulEventState = \"Anticipating\" // Instance: CognitiveRepresentationOfHarmfulEvent -> Attr:PassiveIsAnticipatedState = \"Anticipated\" //=================================================================================\nWhen MatchNewObjectInstanceStatesLatestPriorAgainstEarliestPost() is called for the\n\u201cdemonstrators\u201d as the object instance candidate, the earlier application of the nested behavior on the West side had generated an object instance that is a set of \u201clisteners\u201d that is exclusive of the demonstrators. MatchNewObjectInstanceStatesLatestPriorAgainstEarliestPost () searches the West context for each object instance in the structural parent instance; it finds a set of \u201clisteners\u201d (PersonObjectFrameClass (extra$), above) that has an attribute with attribute type = \u201cAnticipatingHarmfulEventState\u201d and attribute value = \u201cAnticipating\u201d. When the object instance from the East side context\u2019s structural parent instance contains a similar such object instance, the test succeeds: several flags are set and E_SUCCESS is returned from the function. The caller functions will utilize the information that the object instance candidate (e.g. the demonstrators) was successfully used by the set of inference processes and the instance model-based matching routine in order to determine its validity as a candidate referent.\n9. Applications: Winograd Schemas #8, #115, #1\nThis section describes solutions for Winograd schemas #8, #115, and #1. (The two variants for\nschema #1 \u2013 \u201cfeared violence\u201d and \u201cadvocated violence\u201d are described separately). The solutions are described in terms of how they address the schemas as general pronoun resolution use cases.\n(The trophy and suitcase schema solution is described in Appendix 1: Solution for \u201cTrophy\nand Suitcase\u201d Schema Using a Model of the Communicating Agent).\n9.1. Schema #8: \u201cThe man could not lift his son\u201d\nThis use case involves a main meaning unit that contains declarative text about a past situation,\nfollowed by second meaning unit (clause) that describes something that occurred or was true at an earlier point in time. An earlier event or state may exist within an explanatory (\u201cbecause\u201d) clause. The pronoun in the current meaning unit refers back to an antecedent in the main meaning unit. This use case includes the following sub-use cases:\n Dependent clause introduced by \u201cbecause\u201d, \u201csince\u201d, etc., where the semantics of the clause\nare of an explanatory nature.\n Dependent adverbial clause introduced by \u201cafter\u201d.\nThe pronoun resolution algorithm makes use of the behavior class that was used to generate\ninstance model information; in doing so it needs a specification of whether or not to examine the object frame classes of the behavior class\u2019s PriorStates (rule antecedent) section or the behavior class\u2019s PostStates (rule consequent section). Therefore the caller function for the pronoun resolution algorithm contains logic that sets an enumerated value for PredicateExpressionTemporalOrderIndicator (to PredicateExpressionTemporalOrderIndicatorPreceding). This is passed to PronounResolutionGeneralMethod() via the pronoun feature set structure.\n9.1.1. How to Handle Duplicate Classes and Actor/Actee Identification\nThe \u201cperson lifts person\u201d schema builds on the basic resolution method but it also needs a\nfeature that is shown in the following code from \u201cNotLift_Weak_BehaviorClass\u201d: the PassiveParticipant flag.\nThe ontology and knowledge base features that were used for this schema include:\n Object frame classes:\no Person class and several sub-classes, including \u201cman\u201d and \u201cson\u201d.\n Behavior classes:\no NotLift_Weak_BehaviorClass o NotLift_Heavy_BehaviorClass\nA portion of NotLift_Weak_BehaviorClass is shown here in order to illustrate the use of the\nfunctional attribute type that has a value that is used to match the \u201cweak\u201d of \u201ctoo weak\u201d. This also illustrates the use of the passive participant flag.\nBehaviorClass \"NotLift_Weak_BehaviorClass\" \u2026 PopulatedObjectClass \"AntecedentActor\" ( <ObjectFrameClass ref = PersonObjectFrameClass /> <BinderSourceFlag val = \"true\" /> <DimensionSystem ref = RelativePosition /> <Attribute ref = RelativeLocation var = a$ /> <Attribute ref = RelativeTime var = t1$ /> <Attribute ref = LiftingState val = \"NotLifting\" /> <Attribute ref = FunctionalAttributeType1 val = \"TooWeak\" /> );\nPopulatedObjectClass \"AntecedentActee\" ( <ObjectFrameClass ref = PersonObjectFrameClass /> <PassiveParticipant val = \"true\" /> <DimensionSystem ref = RelativePosition /> <Attribute ref = RelativeLocation expr = (a$+1) /> <Attribute ref = RelativeTime expr = t1$ /> <Attribute ref = PassiveIsLiftedState val = \"NotLifted\" /> );\n(The appendix contains full listings for the classes that are used in processing this schema).\n9.2. Schema #115: \u201cJoe paid the detective\u201d\nThe \u201cperson pays detective\u201d schema builds on the basic resolution method but it also needs a\nfeature that is shown in the following code from the \u201cPayAfterReceivingBehaviorClass\u201d behavior class: the feature is the nested behavior. (note: by way of comparison, in the terminology of Discourse Representation Theory, this is similar to an event within a DRS).\nThe ontology and knowledge base features that were used for this schema include:\n Object frame classes:\no Person class and several sub-classes: detective and deliverable. (The concept of a\n\u201cdeliverable\u201d is used here as a high-level abstraction that includes any of services, products, a report, etc. This is one of several possible ways to model the semantics of the input schema text \u201creceived the final report\u201d).\n Behavior classes:\no ReceiveBehaviorClass o DeliverBehaviorClass o PayAfterReceivingBehaviorClass o PersonIsPaidAfterDeliveringBehaviorClass\nThe nested behavior class feature is illustrated here in that PayAfterReceivingBehaviorClass\ncontains a nested behavior class reference that refers to a separate behavior class called \u201cReceiveBehaviorClass\u201d (full details are in the appendix).\nBehaviorClass \"PayAfterReceivingBehaviorClass\" (\n\u2026 PriorStates ( PopulatedObjectClass \"AntecedentActor\" ( <ObjectFrameClass ref = PersonObjectFrameClass /> <BinderSourceFlag val = \"true\" /> <DimensionSystem ref = RelativePosition /> <Attribute ref = RelativeLocation var = a$ /> <Attribute ref = RelativeTime var = t1$ /> <Attribute ref = PayingState val = \"NotPaying\" />\n<Attribute ref = UniqueIdentityAttributeType var = q$ /> // (identity) ); BehaviorClassReference ( <BehaviorClass ref = ReceiveBehaviorClass /> // -->> DEFINED-BEHAVIOR-CLASS <ParameterActor ref = PersonObjectFrameClass expr = q$ /> // (identity) <ParameterActee ref = DeliverableObjectObjectFrameClass /> <ParameterExtra ref = PersonObjectFrameClass /> ); PopulatedObjectClass \"AntecedentActee\" ( <ObjectFrameClass ref = PersonObjectFrameClass /> <PassiveParticipant val = \"true\" /> <DimensionSystem ref = RelativePosition /> <Attribute ref = RelativeLocation expr = (a$+1) /> <Attribute ref = RelativeTime expr = t1$ /> <Attribute ref = PassiveIsPayedState val = \"NotPayed\" /> ); );\n9.3. Schema #1/Variant #1: \u201cCity councilmen refused \u2026 feared violence\u201d\nThe sentence for this schema is: \u201cThe city councilmen refused the demonstrators a permit\nbecause they feared violence.\u201d. Resolution of the difficult pronoun for this variant of this schema uses the general pronoun resolution method; the embedded inference process is not needed since the instance model contains sufficient information to make the determination. The main ROSS rule that is used in the processing of the input sentence is the following. (This shows only key parts of the rule). //---------------------------------------------------------------------------- // // BehaviorClass: \"RefusingSomethingDueToFearBehaviorClass\" // // \"If a person(s) anticipates a harmful event // then he/she/they will not grant a thing that was requested (e.g. a permit request).\" // //---------------------------------------------------------------------------- // BehaviorClass \"RefusingSomethingDueToFearBehaviorClass\" ( <CausalRule val = \"true\" /> <BridgeObjectFrameClass ref = BehavioralStructuralParentClass /> Dictionary ( English ( { \"refuse\", \"refused\", \"refused\", \"refuses\", \"refusing\" } );); PriorStates // (antecedent) ( PopulatedObjectClass \"AntecedentActor\" ( <ObjectFrameClass ref = PersonObjectFrameClass /> // e.g. government official(s) <Attribute ref = RefusingState val = \"NotRefusing\" />\n<Attribute ref = UniqueIdentityAttributeType var = q$ /> ); BehaviorClassReference // (\u201cif a person anticipates a harmful event\u201d) ( // <Probability expr = 0.9 /> // (not used here) <BehaviorClass ref = AnticipateHarmfulEventBehaviorClass /> // --> defined behavior class <ParameterActor ref = PersonObjectFrameClass expr = q$ /> // (refers to the actor) <ParameterActee ref = CognitiveRepresentationOfHarmfulEvent /> ); // Actee (not shown) e.g. a person class from which demonstrators inherits // Extra (not shown) e.g. a class from which permit inherits PostStates // (consequent) ( PopulatedObjectClass \"ConsequentActor\" ( <ObjectFrameClass ref = PersonObjectFrameClass /> // e.g. government official(s) <Attribute ref = RefusingState val = \"Refusing\" /> ); // (others not shown) ); );\nThe nested behavior class is called \u201cAnticipateHarmfulEventBehaviorClass\u201d (not shown here).\nA call stack for the processing of this schema is shown below (note: this uses the meaning unit\nrather than the predicate expression). The call stack shows how the main meaning unit is processed first, by ProcessMeaningUnitIndicative() \u2013 this processing generates instance model object instances which constitute the possible referents for the pronoun that is subsequently processed. The spanning information structure points to the newly-created object instances in the instance model. The processing of the current meaning unit (\u201cbecause they feared violence\u201d) occurs in a subsequent call to ProcessMeaningUnitIndicative(). In this case, the pronoun that needs resolution is in the syntactic subject, thus there are two intervening calls for handling the subject, leading to the call to EntityResolutionRoutine(). This function calls ProcessPronoun(), passing in a fully populated PronounFeatureSet data structure. Some fields of the PronounFeatureSet are used to direct the call (since the PronounFeatureSet designates the current meaning unit as a \u201cbecause clause\u201d, PronounResolutionExplanatoryClauseForCognitiveExplanation() is invoked.\nPronounResolutionWorkerRoutine() is the main anaphora resolution routine. It invokes\nExploratorySearchUsingSpanningInfoStack(), a high-level driver function for the \u201cexploratory searches\u201d that will take place. This function loops through all spanning info\u2019s in the stack. ExploratorySearchUsingOneSpanningInfo() invokes TestOneCandidateObjectInstance() for each of the actor object instances, actee object instances and extra object instances in the spanning information data structure. TestOneCandidateObjectInstance() again looks at the PronounFeatureSet: if an adjective is available it attempts to match it as the causal feature. In this case a verb is available (\u201crefused\u201d), and thus\nTryToMatchVerbCausalFeatureAgainstSpanningInfoObjectInstance() is invoked. Some details of TryToMatchVerbCausalFeatureAgainstSpanningInfoObjectInstanceSingleBehaviorClass() are not described here: the mechanism involves a set of preparatory steps leading up to the call to SearchUsingNestedBehaviorForMatchingCausalFeature(). The lowest-level function in this call stack is SearchUsingNestedBehaviorForMatchingCausalFeature(). It does these tasks:\n searches the behavior classes that are associated with the object instance candidate\u2019s class\n(e.g. CityCouncilmanObjectFrameClass) for one that matches the verb (\u201crefused\u201d). This retrieves a behavior class pointer.\n compares the nested behavior class that was supplied as a parameter to the behavior class\npointer that was just retrieved \u2013 if they match, the object instance candidate is flagged as the pronoun antecedent and control returns up to PronounResolutionWorkerRoutine() for a set of follow-up tasks that include adding new information to the instance model.\nCall Stack: EngineDriver() ProcessCommunicationUnitList() ProcessMeaningUnitList() ProcessMeaningUnit() ProcessMeaningUnitIndicative() // \u201cThe city councilmen refused the demonstrators a permit\u201d ProcessPredicatePhrase() ProcessMeaningUnit() ProcessMeaningUnitIndicative() // \u201cbecause they feared violence\u201d ProcessSubjectPhrase() ProcessSubjectPhraseNounPhrase() EntityResolutionRoutine() ProcessPronoun() // resolve \u201cit\u201d PronounResolutionExplanatoryClauseForCognitiveExplanation() // handle a \u201cbecause\u201d clause PronounResolutionWorkerRoutine() ExploratorySearchUsingSpanningInfoStack() // loop: search each spanning info in the stack ExploratorySearchUsingOneSpanningInfo() // invoke the tests TestOneCandidateObjectInstance() // branch based on available keyword // (\u201crefused\u201d) in PronounFeatureSet TryToMatchVerbCausalFeatureAgainstSpanningInfoObjectInstance() // loop for all // behavior classes TryToMatchVerbCausalFeatureAgainstSpanningInfoObjectInstanceSingleBehaviorClass() SearchUsingNestedBehaviorForMatchingCausalFeature()\nThe present method can also utilize probability values that are associated with nested\nbehaviors in order to select the most appropriate behavior class from among several. Refer to Hofford (2014 (b)) \u201cThe ROSS User\u2019s Guide and Reference Manual\u201d, Appendix: Star Classes for the Solution for Winograd Schema #1, 5.3.1. RefusingSomethingDueToFearOnPartOfRequestorBehaviorClass for full details.\n9.4. Schema #1/Variant #2: \u201cCity councilmen refused \u2026 advocated violence\u201d\nThe sentence for this schema is: \u201cThe city councilmen refused the demonstrators a permit\nbecause they advocated violence.\u201d. Refer to section 8. Embedded Commonsense Reasoning Method for details of this logic.\n10. Conclusion: Test Results for Schemas\nThe method has been fully implemented in a working system that processes sentences, creates\ninstance models, and then answers relevant questions based on its internal knowledge 7 . The Comprehendor system is also usable via a RESTful API server.\nThe following were derived from or directly adopted from the Winograd Schema Challenge\nschemas. (A minor change to one of the original schemas is noted).\n(Note: the API call results show the antecedents in parenthesis after the pronoun (e.g.\n\u201cit(trophy)\u201d). The method is capable of determining the noun phrase, not just the noun head word and this will be addressed in a future version so that the system will generate the phrase, e.g. \u201cit(the trophy) and \u201cit(the brown suitcase)\u201d).\n10.1. Trophy and Suitcase Schema\n10.1.1. Original Winograd Schema\nThe trophy doesn't fit into the brown suitcase because it's too [small/large]. What is too [small/large]?\nAnswers: The suitcase/the trophy.\n10.1.2. Test Results\nThe test results were as follows.\n>The trophy doesn\u2019t fit in the brown suitcase because it\u2019s too big.\n>What is too big?\n>The trophy is too big.\n>The trophy doesn\u2019t fit in the brown suitcase because it\u2019s too small.\n>What is too small?\n>The suitcase is too small.\n7 Information about a demo for the working system is available on the author\u2019s web site (Hofford (2014 (c)).\nThe same test can be run using Comprehendor as a RESTful API server. (This test and the\nfollowing tests use the cURL tool to submit requests to the Comprehendor server). The responses are shown in italics. (Note: Comprehendor expands contractions, e.g. \u201cdoesn\u2019t\u201d -> \u201cdoes not\u201d; thus the resulting output sentence shows the un-contracted form of contractions that exist in the input sentence). C:\\ cURL>curl --data \"Task=DisambiguateSentences&InputText=The trophy doesn\u2019t fit in the brown suitcase because it\u2019s too big.\" http://192.168.1.3/ServerMethod.NLUTask The trophy does not fit in the brown suitcase because it(trophy) is too big . C:\\ cURL>curl --data \"Task=DisambiguateSentences&InputText=The trophy doesn\u2019t fit in the brown suitcase because it\u2019s too small.\" http://192.168.1.3/ServerMethod.NLUTask The trophy does not fit in the brown suitcase because it(suitcase) is too small .\n10.2. Person Lifts Person Schema\n10.2.1. Original Schema\nThe man couldn't lift his son because he was so [weak/heavy]. Who was [weak/heavy]?\nAnswers: The man/the son.\n10.2.2. Test Results\nThe test results were as follows. (Changes: \u201ccouldn\u2019t\u201d changed to \u201cdidn\u2019t\u201d; \u201cso\u201d to \u201ctoo\u201d). C:\\ cURL>curl --data \"Task=DisambiguateSentences&InputText=The man didn\u2019t lift his son because he was too weak.\" http://192.168.1.3/ServerMethod.NLUTask The man did not lift his son because he(man) was too weak . C:\\ cURL>curl --data \"Task=DisambiguateSentences&InputText=The man didn\u2019t lift his son because he was too heavy.\" http://192.168.1.3/ServerMethod.NLUTask The man did not lift his son because he(son) was too heavy .\n10.3. Person Pays Person Schema\n10.3.1. Original Schema\nJoe paid the detective after he [received/delivered] the final report on the case. Who [received/delivered] the final report?\nAnswers: Joe/the detective.\n10.3.2. Test Results\nThe test results were as follows.\nC:\\cURL>curl --data \"Task=DisambiguateSentences&InputText=Joe paid the detective after he received the final report on the case.\" http://192.168.1.3/ServerSideTask.NLUTask Joe paid the detective after he(Joe) received the final report on the case .\nC:\\cURL>curl --data \"Task=DisambiguateSentences&InputText=Joe paid the detective after he delivered the final report on the case.\" http://192.168.1.3/ServerSideTask.NLUTask Joe paid the detective after he(detective) delivered the final report on the case .\n10.4. Councilmen and Demonstrators Schema\n10.4.1. Original Schema\nThe city councilmen refused the demonstrators a permit because they [feared /advocated] violence. Who [feared/advocated] violence?\nAnswers: The councilmen/the demonstrators.\n10.4.2. Test Results\nThe test results were as follows.\nC:\\cURL >curl --data \"Task=DisambiguateSentences&InputText=The city councilmen refused the demonstrators a permit because they feared violence.\" http://192.168.1.2/ServerMethod.NLUTask\nThe city councilmen refused the demonstrators a permit because they(councilmen) feared violence . C:\\\\cURL>curl --data \"Task=DisambiguateSentences&InputText=The city councilmen refused the demonstrators a permit because they advocated violence.\" http://192.168.1.2/ServerMethod.NLUTask The city councilmen refused the demonstrators a permit because they(demonstrators) advocated violence .\nAppendix 1: Solution for \u201cTrophy and Suitcase\u201d Schema Using a Model of the Communicating Agent\nThe original anaphora resolution method, as developed by the author and applied to solve the\ntrophy and suitcase schema, involved a paradigm that models the process of communication itself. This process of communication involves the following elements; each of these is represented by object instances in a ROSS instance model. The object instances are based on ontology classes, as follows:\n Intelligent/Communicative Agents:\no The communicating agent or agents (also referred to as the talker). o The listening agent (the NLU system itself, also referred to as the listener)\n The information that is communicated  Cognitive entities that belong to the communicating agent:\no Beliefs and knowledge about facts and about behaviors of objects in the agent\u2019s\nenvironment\no The processes of cognition \u2013 reasoning on the part of the agent o The process of communicating, i.e. conveying information to a listener\n1. Rationale for Modeling the Communicating Agent\nThe \u201ccommunicating agent paradigm\u201d is useful for NLU and anaphora resolution situations\nthat include the following:\n (NLU) Two-way or multi-way dialog or written communication (not covered here)  (anaphora resolution) Sentences that involve ambiguity where the specific beliefs of\nthe communicating agent are not known by the listener. An example would involve the following sentence:\n\u201cThe bat did not hit the baseball because it moved too fast.\u201d\nHere the pronoun it refers to either the bat or the baseball. It is possible to imagine two\nsituations where this might be spoken or conveyed:\n By a batter who has just swing and missed a fast pitch: this person explains the cause\nof his or her not hitting the ball from the perspective of a cognitive rule that describes bats and baseballs, wherein the causative behavioral feature of interest is pitches (balls) that are so fast that they are missed.\n By a batting coach who is coaching a rookie batter who tends to swing too fast. The\nbatting coach explains the cause from the perspective of a cognitive rule that involves\na causative behavioral feature: missed pitches caused by a batter who swings too quickly.\nDespite a possible lack of plausibility of this particular example, it illustrates that some\ninstances of natural language understanding can benefit from a model that takes into consideration the probability that the talker has a particular set of beliefs constituting the causative aspects of external phenomena.\nThe probability aspects are not addressed here, but the mechanisms involved in modeling a\ncommunicating agent, communicated information, and cognitive entities are explained.\n2. Overview\nTwo distinct aspects are involved for the sentence \u201cThe trophy didn\u2019t fit in the suitcase\nbecause it was too big\u201d 8 . The first of these is the process of communication on the part of an intelligent agent, including the abstract cognition (mental) entities that exist in the mind/brain of the intelligent agent. The second of these involves a representation of the actual, or external situation that the intelligent agent describes \u2013 for this schema it is modeled as a physical process of attempting to fit an object (trophy) into another object (suitcase).\nThe trophy and suitcase example sentences associate a behavior (described by the verb phrase\n\u201cdoes not fit\u201d) with an attributive state that describes a causal feature (\u201cbigness\u201d or \u201csmallness\u201d).\n3. Ontology\nAn overview is described here: the appendix contains full listings for some of these classes.\n3.1. Object Frame Classes\nThese include the following:\n higher-level classes:\no a special class for a structural parent object that is used to construct a 4D frame of\nreference for a situation (EverydayObjectStructuralParentClass)\no a class of objects that are capable of being instantiated in an instance of a\nEverydayObjectStructuralParentClass (EverydayObjectFrameClass)\no a class of objects that can fit into a container (EnclosableObjectFrameClass) o a class of container objects (ContainerObjectFrameClass) o a class of common objects that provides other attribute types such as color\n(CommonObjectFrameClass)\n a trophy class that inherits properties from the EverydayObjectFrameClass, the\nEnclosableObjectFrameClass, and the CommonObjectFrameClass.\n8 For purposes of analysis, the sentence that is used in the remainder of this section refers to the trophy and\nsuitcase in past tense (\u201cdidn\u2019t fit\u201d, versus \u201cdoesn\u2019t fit\u201d).\n a suitcase class that inherits properties from the EverydayObjectFrameClass, the\nContainerObjectFrameClass, and the CommonObjectFrameClass.\n human intelligent agent class: it models an agent that performs cognition, and\ncommunication \u2013 i.e. this is the person that communicates (spoken or written) the sentences of the schema (IntelligentAgentObjectFrameClass)\n a mental conceptual representation (referred to as an \u201cimage\u201d, although it is not necessarily\npictorial) of a static or process-wise situation, e.g. an image of the process of a person attempting to fit a trophy into a suitcase (CognitiveImageForSituationObjectFrameClass)\n a mental conceptual representation of the intelligent agent\u2019s cognitive representation of the\ncausal explanation for the situation (CognitiveExplanationObjectFrameClass)\n a higher-level more generic \u201cinformation\u201d class from which the cognitive causal\nexplanation class gets most of its properties: (RepresentationOfCausalExplanationObjectFrameClass)\n the information items: the spoken or written forms of the sentence and its constituent parts\n(CommunicationUnitSentenceObjectFrameClass, CommunicationFragmentMeaningUnitObjectFrameClass, CommunicationFragmentWordObjectFrameClass)\n3.2. Behavior Classes\nInternal knowledge base behavior class definitions are used as specifications of causality.\nDefinitions exist for each of the following:\n the \u201cfitting\u201d process or behavior (FitsBehaviorClass)  the \u201cnot fitting\u201d behavior (NotFit_Big_BehaviorClass, NotFit_Small_BehaviorClass)\n4. Instance Model\nThe internal instance model is generated from the main sentence in several stages. (\u201cThe\ntrophy doesn\u2019t fit in the brown suitcase because it\u2019s too big.\u201d). It consists of a main/overall model that contains an embedded model:\n The main/overall instance model represents the communicating agent (the talker) and the\nprocess of communicating information. This main instance model contains an embedded instance model that represents the \u201cfitting\u201d action of the actual situation. The main instance model also involves representation of a cognitive process (on the part of the talker) involving reasoning about the causal aspects of the embedded instance model.\n The embedded instance model represents the actual situation: it involves the objects \u2013\ntrophy, suitcase, person, and an instance of the behavior \u201cto fit\u201d as a process that occurs along a timeline (it is a 4D representation of the situation). It includes:\no attachment of a structural parent instance that is based on a structural parent\nobject frame class (EverydayObjectStructuralParentClass).\no use of a timeline with time points such as \u201cT01\u201d, \u201cT02\u201d. o object instances with attributes: suitcase, trophy and person instances. An\nexample attribute for the trophy is one that represents \u201cnot fitted into\u201d, at T01.\no behavior instances are implicitly implemented along the timeline. This involves\nspecification of the suitcase and the trophy in an initial state, specification of the next state involving the action of moving the trophy towards/into the suitcase, and a final state where the trophy comes to rest outside of the suitcase.\no Once the pronoun is resolved, an attribute for \u201ctoo big\u201d or \u201ctoo small\u201d is added to\nthe embedded instance model as an attribute of either the trophy or suitcase depending on which object has been determined as the pronoun antecedent.\n5. Diagram of Overall Situation\nThe overall situation involves a process wherein an intelligent agent (the talker) communicates\ntwo clauses within a single sentence. (The first clause is \u201cThe trophy did not fit in the suitcase\u201d; the second clause is \u201cbecause it was too big\u201d). Figure 2 shows the cognitive and communicative aspects of the situation (note that the listener agent is not shown).\nThe semantic engine generates an overall instance model that corresponds to the diagram of\nfigure 2. The overall instance model contains object instances, as follows. The intelligent agent is the talker, labeled as IntelligentAgent-01. The talker agent has a set of general beliefs (about how things work in the physical world) that is represented in brackets to the left of the this agent. An ActualPastSituation exists and occurred earlier, but it is only represented indirectly within the bubble in the upper left: this involves a trophy, a person, a suitcase and a \u201cfitting attempt\u201d action. (1) CognitiveImageForSituation-01 \u2013 this represents the intelligent agent\u2019s cognitive representation of the actual past situation. (2) CognitiveExplanation-01: this is what the intelligent agent believes about the cause(s) involved in the specific actual situation. (3) CommunicationUnitSentence-01 is an object instance that represents the sentence communicated by IntelligentAgent-01. CommunicationUnitSentence-01 consists of CommunicationFragmentMeaningUnit-01(not labeled \u2013 \u201cThe trophy did not fit in the suitcase\u201d) and CommunicationFragmentMeaningUnit-02 (not labeled \u2013 \u201cbecause it was too big\u201d).\nThe timeline has two important time points. The timeline numbers have been selected only for\nillustration purposes and are intended to represent a typical scenario. (The working prototype uses an enumerated type consisting of timeline values such as \u201cT01\u201d, \u201cT02\u201d, etc.). At t=3 seconds, IntelligentAgent-01 forms the mental image as shown, and also at t=3 the intelligent agent forms a cognitive explanation of the past situation. At t = 10 the agent communicates by speaking \u201cThe trophy did not fit in the suitcase because it was too big\u201d.\n6. Semantic Engine Tasks\nThe entity resolution and pronoun resolution tasks are described here. Underlying the pronoun\nresolution process is an assumption of a shared set of beliefs - between the talker agent and the listener agent - about \u201chow things work\u201d. I.e. the listener agent builds a model of what the talker agent is thinking with respect to the talker\u2019s explanation of the cause of the trophy not fitting in the suitcase. The listener uses this model to reason about the possible meanings of the unresolved pronouns that were communicated to it.\n6.1. Entity Resolution/Class Selection for Common Nouns and Verbs\nThe first task involves the selection of appropriate classes from the internal knowledge base\nthat correspond to each of the common nouns and to the main verb phrase (representing \u201cto not fit\u201d). Although a ROSS knowledge base may contain classes that map the word \u201ctrophy\u201d and \u201csuitcase\u201d to any of a number of classes, for the purpose of simplifying this example the following mappings from common words to knowledge base classes have been used:\n \u201ctrophy\u201d \u2013 TrophyObjectFrameClass (inherits from EverydayObjectFrameClass,\nCommonObjectFrameClass and EnclosableObjectFrameClass) { an ordinary object with varying size, shape, color, composition, etc. }\n \u201csuitcase\u201d \u2013 SuitCaseObjectFrameClass (inherits from EverydayObjectFrameClass,\nCommonObjectFrameClass and from ContainerObjectFrameClass) { an ordinary object with varying size, shape, color, composition, etc. }\n \u201cnot fit\u201d \u2013 NotFit_Big_BehaviorClass, NotFit_Small_BehaviorClass { behavior\nclasses that are associated with both EnclosableObjectFrameClass and ContainerObjectFrameClass }\n6.2. Pronoun Resolution\nThe pronoun resolution task (for \u201cit\u201d within the second clause) draws inferences about the\nundetermined entities, mental concepts, or words (each is represented by x).\n x within the actual past situation \u2013 e.g. which physical object was too big?  x within the talker\u2019s cognitive image of the past situation  x within the talker\u2019s cognitive explanation of the causality of the situation - i.e. within\nCognitiveExplanation -01 which item is associated with the (causal) feature that has a causative effect on the \u201cnot fitting\u201d behavior?\n x within the natural language text: i.e. what is the pronoun antecedent within the first\nclause (\u201ctrophy\u201d or \u201csuitcase\u201d)?\nThe output of the resolution process is a determination of the unknown facts, and is contained\nin the instance model for the overall situation that involves detail that includes the resolution of the pronoun.\nThe following is a form of pseudo-code using first-order logic to show the specifications of\nthe rules that are used to support the inference. (Since the logic within the antecedents for each of the three rules is similar, for the last two rules only the logic of the consequent is shown). Each of the three rules contains several main groups of logical expressions in the antecedent:\n Expressions that specify the actual/external situation (e.g. the situation involving an\ninstance of a trophy not fitting into a suitcase).\n Expressions that specify the natural language text itself (the main organizing predicate is\n\u201cCommunicationUnitSentence\u201d).\n Expressions that specify shared, or generally-known commonsense cognitive knowledge,\ne.g. about containers and things that can fit into containers (these expressions represent two ROSS behavior classes \u2013 one for \u201cnot fitting due to enclosable being too big\u201d, and another for \u201cnot fitting due to container being too small\u201d).\n Expressions that specify an instance of a CognitiveExplanationObjectFrameClass.\nRule 1: This rule uses an abstraction centering around an instance of a CognitiveExplanationObjectFrameClass. (The CognitiveExplanationObjectFrameClass inherits its properties from a RepresentationOfCausalExplanationObjectFrameClass class, which is actually\nused). This rule resolves the referent for a representational entity (the unknown entity) that exists within an instance of RepresentationOfCausalExplanationObjectFrameClass, referred to using the variable name \u201cunknown-entity\u201d. This rule describes the logic that is used to figure out what the intelligent agent was thinking when he/she said \u201cbecause it was too big\u201d. (Note that this rule example uses \u201cContainerClass\u201d as an equivalent for the Infopedia class called \u201cContainerObjectFrameClass\u201d). (Note: logic for the \u201ctoo small\u201d case not shown).\nRule 1: for \u201cx was too big\u201d\n\u2200 unknown-entity: // (Rule Antecedent) // Variables that represent specific attribute values: \u018eattval1: CausalFeatureAttributeValue(attval1) \u0245 StringValue(attval1, \u201cTooBig\u201d) \u018eattval2: CausalFeatureAttributeValue(attval2) \u0245 StringValue(attval2, \u201cTooSmall\u201d) // The actual past situation. E.g. this models the failed \u201cfitting attempt\u201d instance, where something was too big: \u018esit: Situation(sit) \u0245 // (@ t = n-2) \u018eentity1: IsRepresentedByClassName(entity1, entity-class-name1) \u0245 PartOf(entity1,sit) \u0245 // e.g. TrophyClass \u018eentity2: IsRepresentedByClassName (entity2, entity-class-name2) \u0245 PartOf(entity2,sit) \u0245 // e.g. SuitcaseClass \u018eaction1: AttemptToFitEnclosableIntoContainer(action1) \u0245 PartOf(action1,sit) \u0245 NotFittedInsideContainer(entity1) \u0245 // Att-type = PassiveIsFittedInsideContainerState NotIsFittedInto(entity2) \u0245 // Att-type = PassiveIsFittedIntoState ( CausalFeature(entity1,atttype-name, attval1) V // disjunction CausalFeature(entity2,atttype-name, attval1) ) \u0245 // The input natural language text (the sentence and its constituent parts) \u018es: CommunicationUnitSentence (s) \u0245 // the input sentence // (@ t = n) \u018em1,m2: // the two clauses of the sentence MeaningUnit (m1) \u0245 PartOf(m1,s) \u0245 // clause that is a description of a past situation \u018esubj: ReferentPhraseSubject(subj,entity1) \u0245 PartOf(subj,m1) \u0245 // e.g. enclosable object \u018eadv: VerbModifierWord(adv) \u0245 PartOf(adv,m1) \u0245 // e.g. negation \u018everb: WordBehavior(verb) \u0245 PartOf(verb,m1) \u0245 // e.g. \u201cfitting\u201d behavior \u018edobj: ReferentPhraseDirObject(dobj,entity2) \u0245 PartOf(dobj,m1) \u0245 // e.g. container object MeaningUnit (m2) \u0245 PartOf(m2,s) \u0245 // clause that is a causal explanation for the situation \u018eadv2: CauseExplanationIntroducerWord(adv2) \u0245 PartOf(adv2,m2) \u0245 // e.g. \u201cbecause\u201d \u018epron: PronounWord(pron) \u0245 PartOf(pron,m2) \u0245 // the unresolved \u201cvariable\u201d \u018everbtobe: AuxiliaryVerbToBeWord(verbtobe) \u0245 PartOf(verbtobe,m2) \u0245 // e.g. \u201cwas\u201d \u018e:caufeat: ReferentPhraseCausalFeatureAttValue(caufeat, attval1) \u0245 PartOf(caufeat,m2) // \u201ctoo big\u201d \u0245 // (Meta) Common/shared cognitive knowledge about behaviors (these exist in the ontology) // Higher-level Entity classes: \u018eenclosable: EnclosableObjectFrameClass(enclosable) \u0245 \u018econtainer: ContainerObjectFrameClass(container) \u0245\n// Inherited Entity classes: \u018etrophy: InheritsPropertiesFrom(enclosable) \u0245 \u018esuitcase: InheritsPropertiesFrom (container) \u0245 // (1) Behavior class for \u201can enclosable does not fit in a container if the enclosable is too big\u201d // \u018eb1: CognitiveRepresentationOfBehaviorClass(b1) \u0245 // (@ t = any) \u018eb1a: CogReprAntecedent(b1a) \u0245 PartOf(b1a, b1) \u0245 \u018ereprentity1: Represents(repentity1, enclosable) \u0245 PartOf(repentity1,b1a) \u0245 CausalFeature(reprentity1,atttype-name, attval1) \u018ereprentity2: Represents(repentity2, container) \u0245 PartOf(repentity2,b1a) \u0245 \u018erepaction: CogReprAction(repaction, action) \u0245 PartOf(repaction,b1) \u0245 \u018eb1c: CogReprConsequent \u0245 PartOf(b1c, b1) \u0245 // (the following is shorthand for the Consequent result states) NotFittedInsideContainer(repentity1) \u0245 // Att-type = PassiveIsFittedInsideContainerState NotIsFittedInto(repentity2) \u0245 // Att-type = PassiveIsFittedIntoState \u0245 // (2) Behavior class for \u201can enclosable does not fit in a container if the container is too small\u201d // \u018eb2: CognitiveRepresentationOfBehaviorClass(b2) \u0245 // (@ t = any) \u018eb2a: CogReprAntecedent(b2a) \u0245 PartOf(b2a,b2) \u0245 \u018ereprentity1: Represents(repentity1, enclosable) \u0245 PartOf(repentity1,b2a) \u0245 \u018ereprentity2: Represents(repentity2, container) \u0245 PartOf(repentity2,b2a) \u0245 CausalFeature(reprentity2,atttype-name, attval2) \u018erepaction: CogReprAction(repaction, action) \u0245 PartOf(repaction,b2) \u0245 \u018eb2c: CogReprConsequent \u0245 PartOf(b2c, b2) \u0245 // (the following is shorthand for the Consequent result states) NotFittedInsideContainer(repentity1) \u0245 // Att-type = PassiveIsFittedInsideContainerState NotIsFittedInto(repentity2) \u0245 // Att-type = PassiveIsFittedIntoState \u0245 // (Meta) The agent\u2019s cognitive explanation of the causal aspects of this situation: \u018ece: RepresentationOfCausalExplanationObjectFrameClass(ce) \u0245 // (@ t = n-1) \u018ece-cause: Repr-CauseEntity(cexplcause) \u0245 PartOf(ce-cause,ce) \u0245 \u018eunknown-entity: Repr-AntecedentCausalAgent \u0245 PartOf(unknown-entity, ce-cause) \u0245 ( RepresentedClassName(unknown-entity, entity-class-name1) \u0245 // e.g. \u201cTrophyClass\u201d V // disjunction RepresentedClassName(unknown-entity, entity-class-name2)) \u0245 // e.g. \u201cSuitcaseClass\u201d CausalFeatureAttributeTypeName(unknown-entity,atttype-name) \u0245 // e.g. \u201cFunctionalSize\u201d CausalFeatureAttributeValue(unknown-entity, attval1) \u0245 // e.g. \u201cTooBig\u201d \u2192 // (Rule Consequent) // (@ t = n) RepresentationalRelationship(unknown-entity, entity-class-name1)\nThe rule consequent expresses the fact that the unknown entity (within the mind of the cognitive agent) has a representational relationship with entity-class-name-1, which is an instance of the trophy class. What is not shown here (due to the complexities of specifying it with FOL), is the way in which the substitution takes place: the pronoun resolution algorithm uses the behavior class of the embedded situation (the \u201cnot fitting due to too big\u201d behavior) in order to derive the higher\nclass of the object (the enclosable object or the container object) that can affect the behavior result, which in this case is the enclosable object. It uses this class to determine which actual object is referred to based on the inheritance tree for the object frame class of each of the objects. (Note: for purpose of ontology scalability, the use of probability values is viewed as a necessary requirement: given that both a trophy and a suitcase can be a container object (and each can be an enclosable object), the use of a probability value for the higher classes mechanism within the object frame class is envisioned. For instance, this would specify by implication (comparison of respective probability values) that it is more likely that a suitcase is a container than is a trophy).\nRule 2: This rule associates the unresolved NL text pronoun (e.g. \u201cit\u201d) with an entity in the represented, or external world. Given the unresolved pronoun within the explanatory (\u201cbecause clause\u201d), it resolves which actual entity in the external situation is referred to (e.g. the trophy object instance or the suitcase object instance). (The Comprehendor engine implements this rule in code subsequent to the resolution of Rule 1; it sets the appropriate attribute for the entity of the actual situation (FunctionalSize = \u201cTooBig\u201d, or FunctionalSize = \u201cTooSmall\u201d). (note: \u201cpron\u201d designates the pronoun).\n\u2200 pron: // (rule antecedent not shown) \u2192 // (Rule Consequent) // (@ t = n) // relationship of pronoun to actual situation entity: RepresentationalRelationshipWordToActualSituationEntity (pron, entity)\nRule 3: This rule centers around the natural language text. Given the unresolved pronoun within the explanatory (\u201cbecause clause\u201d), it resolves which word (anaphor antecedent) in the main clause the pronoun refers to (e.g. \u201ctrophy\u201d or \u201csuitcase\u201d).\n\u2200 pron: // (rule antecedent not shown) \u2192 // (Rule Consequent) // (@ t = n) // relationship of pronoun to CommunicationFragmentWord: RepresentationalRelationshipCoreferent (pron, subj)\nNote that in the actual system Rule 3 is not implemented, since the question answering system of the semantic engine is capable of searching the actual instance model that corresponds to the communicated sentence.\nAppendix 2: Ontology/Knowledge Base\nThe main Star language object frame classes and behavior classes that are used by the\nComprehendor NLU system to process the schemas are shown in this appendix, with the exception of those for schema #1, which is contained in Hofford (2014 (b)) \u201cThe ROSS User\u2019s Guide and Reference Manual\u201d. The Star language definitions exist within several different Infopedia include files; these include files such as BasicDefinitions.h and PersonRelatedClass.h.\n1. Ontology and KB for Schema: \u201cTrophy and Suitcase\u201d\nMost of the middle and lower ontology classes that are needed for this schema were auto-\ngenerated from natural language input, using the Comprehendor Ontology Builder sub-system. The actual sentences are shown here:\nNatural language input:\nA container object is an everyday object. An enclosable object is an everyday object that fits in a container object. If an enclosable object is too big then it does not fit in the container object. If a container object is too small then an enclosable object does not fit in it. A trophy is an enclosable object. A suitcase is a container object.\n1.1. Supporting Definitions\nSupporting definitions are described in the \u201cROSS User\u2019s Guide and Reference Manual\u201d\n(Hofford 2014 (b)).\n1.2. Object Frame Classes\n1.2.1. Upper Ontology Classes\nThe following upper ontology classes/definitions are described in the \u201cROSS User\u2019s Guide\nand Reference Manual\u201d (Hofford 2014 (b)).\n Structural parent class: EverydayObjectStructuralParentClass  Higher-level class: EverydayObjectFrameClass  Structural parent class: BehavioralStructuralParentClass\n1.2.2. Middle Ontology Classes: Auto-Generated Classes\n(Note: comments were added by hand after completion of the auto-generation process).\n//----------------------------------------------------------------- // // ContainerObjectObjectFrameClass // //----------------------------------------------------------------- // ObjectFrameClass \"ContainerObjectObjectFrameClass\" ( <StructureTrait val = \"Compound\"/> DictionaryPriorWord ( <DictionaryWordIsNoun val = \"true\" /> English ( { \"container\", \"containers\" } ); ); Dictionary ( English ( { \"object\", \"objects\" } );); HigherClasses ( { \"EverydayObjectFrameClass\" } ); AttributeTypes ( AttributeType \"PassiveIsFittedState\" // or, \u201cPassiveIsFittedIntoState\u201d ( <SuperType val = \"Qualitative\"/> <StateAttributeType val = \"true\" /> \"Values\" ( { \"NotFitted\", // i.e. \u201cNotFittedInto\u201d (not containing an object) \"Fitted\" // i.e. \u201cFittedInto\u201d (containing an object) } ); ); AttributeType \"FunctionalAttributeType1\" ( <SuperType val = \"Qualitative\"/> <StateAttributeType val = \"true\" /> <OptionalCausalFeature val = \"true\" /> \"Values\" ( { \"NotTooSmall\",\n\"TooSmall\" : Dictionary ( English ( { \"small\" } ); ); } ); ); ); ); //----------------------------------------------------------------- // // EnclosableObjectObjectFrameClass // e.g. a trophy, an apple // //----------------------------------------------------------------- // ObjectFrameClass \"EnclosableObjectObjectFrameClass\" ( <StructureTrait val = \"Compound\"/> DictionaryPriorWord ( English ( { \"enclosable\", \"enclosables\" } ); ); Dictionary ( English ( { \"object\", \"objects\" } );); HigherClasses ( { \"EverydayObjectFrameClass\" } ); AttributeTypes ( AttributeType \"FittingState\" ( <SuperType val = \"Qualitative\"/> <StateAttributeType val = \"true\" /> \"Values\" ( { \"NotFitting\", // e.g. not starting motion to fit into something \"Fitting\" // e.g. in motion to fit into something } ); ); AttributeType \"FunctionalAttributeType1\" ( <SuperType val = \"Qualitative\"/> <StateAttributeType val = \"true\" /> <OptionalCausalFeature val = \"true\" />\n\"Values\" ( { \"NotTooBig\", \"TooBig\" : Dictionary ( English ( { \"big\" } ); ); } ); ); ); ); //---------------------------------------------------------------------------- // // \"CommonObjectFrameClass\" // (not auto-generated) // //---------------------------------------------------------------------------- // ObjectFrameClass \"CommonObjectFrameClass\" ( <StructureTrait val = \"Compound\"/> HigherClasses ( { \"ObjectObjectFrameClass\", // (not shown in this document) \"EverydayObjectFrameClass\", \"EarthBoundObjectFrameClass\" } // (not shown in this document) ); StructuralParentClassesBase ( { \"EverydayObjectStructuralParentClass\" } ); AttributeTypes ( AttributeType \"ExteriorColor\" ( <SuperType val = \"Qualitative\"/> \"Values\" ( { \"Black\" : Dictionary ( English ( { \"black\" } ); ); , \"Silver\" : Dictionary ( English ( { \"silver\" } ); ); , \"White\" : Dictionary ( English ( { \"white\" } ); ); , } ); ); // (one of many possible state attributes) AttributeType \"StolenState\" ( <SuperType val = \"Qualitative\"/> <StateAttributeType val = \"true\"/> \"Values\" ( { \"NotStolen\",\n\"Stolen\" } ); ); ); // other attribute types here not shown DimensionSystems (); Structure (); ); // \"CommonObjectFrameClass\"\n1.2.3. Lower Ontology: Auto-Generated Classes\nObjectFrameClass \"TrophyObjectFrameClass\" ( <StructureTrait val = \"Compound\"/> Dictionary ( English ( { \"trophy\", \"trophys\" } // (bug in morphology analyzer: should be generated as \u201ctrophies\u201d) );); HigherClasses ( { \"EnclosableObjectObjectFrameClass\" } ); ); ObjectFrameClass \"SuitcaseObjectFrameClass\" ( <StructureTrait val = \"Compound\"/> Dictionary ( English ( { \"suitcase\", \"suitcases\" } );); HigherClasses ( { \"ContainerObjectObjectFrameClass\", //TODO: add \"CommonObjectFrameClass\", // (has color attribute type) } ); );\nNote that the trophy and suitcase classes that are shown here only inherit properties from the\nenclosable object and container object classes, respectively. Since ROSS allows for multiple inheritance, other middle ontology classes can be added to the \u201cHigherClasses\u201d lists, e.g. \u201cPropertyObjectFrameClass\u201d (a class of objects that are owned as property).\n1.3. Auto-Generated Behavior Classes\n1.3.1. Observations\nThe behavior classes shown here were also generated from the same sentences (above), copied\nhere for clarity:\nNatural language input:\nAn enclosable object is an everyday object that fits in a container object. // (positive case) If an enclosable object is too big then it does not fit in the container object. If a container object is too small then an enclosable object does not fit in it.\nNote that the first behavior class below is a positive \u201cfits\u201d behavior class that is shown for comparision purposes (it is not used by the trophy and suitcase schema).\n1.3.2. Listing\nBehaviorClass \"FitsBehaviorClass\" // (positive case) ( <BridgeObjectFrameClass ref = BehavioralStructuralParentClass /> Dictionary ( English ( { \"fit\", // (infinitive/base) \"fitted\", // (simple past) \"fitted\", // (past participle) \"fits\", // (simple present, 3rd p.s.) \"fitting\" // (present participle) } );); PriorStates ( PopulatedObjectClass \"AntecedentActor\" ( <ObjectFrameClass ref = EnclosableObjectObjectFrameClass /> <BinderSourceFlag val = \"true\" /> <DimensionSystem ref = RelativePosition /> <Attribute ref = RelativeLocation var = a$ /> <Attribute ref = RelativeTime var = t1$ /> <Attribute ref = FittingState val = \"NotFitting\" /> ); PopulatedObjectClass \"AntecedentActee\" ( <ObjectFrameClass ref = ContainerObjectObjectFrameClass /> <PassiveParticipant val = \"true\" /> <DimensionSystem ref = RelativePosition /> <Attribute ref = RelativeLocation expr = (a$+1) /> <Attribute ref = RelativeTime expr = t1$ />\n<Attribute ref = PassiveIsFittedState val = \"NotFitted\" /> ); ); PostStates ( PopulatedObjectClass \"ConsequentActor\" ( <ObjectFrameClass ref = EnclosableObjectObjectFrameClass /> <DimensionSystem ref = RelativePosition /> <Attribute ref = RelativeLocation expr = (a$+1) /> <Attribute ref = RelativeTime expr = (t1$+1) /> <Attribute ref = FittingState val = \"Fitting\" /> ); PopulatedObjectClass \"ConsequentActee\" ( <ObjectFrameClass ref = ContainerObjectObjectFrameClass /> <PassiveParticipant val = \"true\" /> <DimensionSystem ref = RelativePosition /> <Attribute ref = RelativeLocation expr = (a$+1) /> <Attribute ref = RelativeTime expr = (t1$+1) /> <Attribute ref = PassiveIsFittedState val = \"Fitted\" /> ); ); ); // FitsBehaviorClass\nBehaviorClass \"NotFit_Big_BehaviorClass\" ( <CausalRule val = \"true\" /> <BridgeObjectFrameClass ref = BehavioralStructuralParentClass /> <Negation val = \"true\" /> Dictionary ( English ( { \"fit\", \"fit\", \"fitted\", \"fits\", \"fitting\" } );); PriorStates ( PopulatedObjectClass \"AntecedentActor\" ( <ObjectFrameClass ref = EnclosableObjectObjectFrameClass /> <BinderSourceFlag val = \"true\" /> <DimensionSystem ref = RelativePosition /> <Attribute ref = RelativeLocation var = a$ /> <Attribute ref = RelativeTime var = t1$ /> <Attribute ref = FittingState val = \"NotFitting\" /> <Attribute ref = FunctionalAttributeType1 val = \"TooBig\" /> // (optional causal feature) ); PopulatedObjectClass \"AntecedentActee\" ( <ObjectFrameClass ref = ContainerObjectObjectFrameClass /> <PassiveParticipant val = \"true\" /> <DimensionSystem ref = RelativePosition /> <Attribute ref = RelativeLocation expr = (a$+1) /> <Attribute ref = RelativeTime expr = t1$ /> <Attribute ref = PassiveIsFittedState val = \"NotFitted\" /> );\n); PostStates ( PopulatedObjectClass \"ConsequentActor\" ( <ObjectFrameClass ref = EnclosableObjectObjectFrameClass /> <DimensionSystem ref = RelativePosition /> <Attribute ref = RelativeLocation expr = (a$+1) /> <Attribute ref = RelativeTime expr = (t1$+1) /> <Attribute ref = FittingState val = \"Fitting\" /> ); PopulatedObjectClass \"ConsequentActee\" ( <ObjectFrameClass ref = ContainerObjectObjectFrameClass /> <PassiveParticipant val = \"true\" /> <DimensionSystem ref = RelativePosition /> <Attribute ref = RelativeLocation expr = (a$+1) /> <Attribute ref = RelativeTime expr = (t1$+1) /> <Attribute ref = PassiveIsFittedState val = \"Fitted\" /> ); ); );\nBehaviorClass \"NotFit_Small_BehaviorClass\" ( <CausalRule val = \"true\" /> <BridgeObjectFrameClass ref = BehavioralStructuralParentClass /> <Negation val = \"true\" /> Dictionary ( English ( { \"fit\", \"fit\", \"fitted\", \"fits\", \"fitting\" } );); PriorStates ( PopulatedObjectClass \"AntecedentActor\" ( <ObjectFrameClass ref = EnclosableObjectObjectFrameClass /> <BinderSourceFlag val = \"true\" /> <DimensionSystem ref = RelativePosition /> <Attribute ref = RelativeLocation var = a$ /> <Attribute ref = RelativeTime var = t1$ /> <Attribute ref = FittingState val = \"NotFitting\" /> ); PopulatedObjectClass \"AntecedentActee\" ( <ObjectFrameClass ref = ContainerObjectObjectFrameClass /> <PassiveParticipant val = \"true\" /> <DimensionSystem ref = RelativePosition /> <Attribute ref = RelativeLocation expr = (a$+1) /> <Attribute ref = RelativeTime expr = t1$ /> <Attribute ref = PassiveIsFittedState val = \"NotFitted\" /> <Attribute ref = FunctionalAttributeType2 val = \"TooSmall\" /> // (optional causal feature) ); ); PostStates\n( PopulatedObjectClass \"ConsequentActor\" ( <ObjectFrameClass ref = EnclosableObjectObjectFrameClass /> <DimensionSystem ref = RelativePosition /> <Attribute ref = RelativeLocation expr = (a$+1) /> <Attribute ref = RelativeTime expr = (t1$+1) /> <Attribute ref = FittingState val = \"Fitting\" /> ); PopulatedObjectClass \"ConsequentActee\" ( <ObjectFrameClass ref = ContainerObjectObjectFrameClass /> <PassiveParticipant val = \"true\" /> <DimensionSystem ref = RelativePosition /> <Attribute ref = RelativeLocation expr = (a$+1) /> <Attribute ref = RelativeTime expr = (t1$+1) /> <Attribute ref = PassiveIsFittedState val = \"Fitted\" /> ); ); );\n2. Ontology and KB for Schema: \u201cPerson Lifts Person\u201d\nThe following classes were auto-generated using the Comprehendor NLU system\u2019s Ontology\nBuilder sub-system. The natural language input that was used is as follows. (note: although the examples use \u201che\u201d and \u201chim\u201d, he/she and him/her can be used here interchangeably).\nNatural language input:\nIf a person is too weak then he cannot lift another person. If a person is too heavy then another person cannot lift him.\nSince the ontology already contains a person class, the Comprehendor Ontology Builder subsystem only needed to generate lower ontology object frame class attributes and behavior classes. These classes are shown here. This demonstrates the Comprehendor Ontology Builder \u201cpartial class definition\u201d feature, which allows for adding attributes or other information to a class that already exists in the ontology. For instance, the ontology contains PersonObjectFrameClass; the first definition below adds several attribute types to this class: \u201cFunctionalAttributeType1\u201d, \u201cLiftingState\u201d, and \u201cPassiveIsLiftedState\u201d. A second definition adds another attribute type called \u201cFunctionalAttributeType2\u201d.\n2.1. Object Frame Classes\n2.1.1. Lower Ontology: Auto-Generated Class Information\nObjectFrameClass \"PersonObjectFrameClass\" ( <StructureTrait val = \"Compound\"/> AttributeTypes ( AttributeType \"FunctionalAttributeType1\" ( <SuperType val = \"Qualitative\"/> <StateAttributeType val = \"true\" /> <OptionalCausalFeature val = \"true\" /> \"Values\" ( { \"NotTooWeak\", \"TooWeak\" : Dictionary ( English ( { \"weak\" } ); ); } ); ); AttributeType \"LiftingState\" (\n<SuperType val = \"Qualitative\"/> <StateAttributeType val = \"true\" /> \"Values\" ( { \"NotLifting\", \"Lifting\" } ); ); AttributeType \"PassiveIsLiftedState\" ( <SuperType val = \"Qualitative\"/> <StateAttributeType val = \"true\" /> \"Values\" ( { \"NotLifted\", \"Lifted\" } ); ); ); ); ObjectFrameClass \"PersonObjectFrameClass\" ( <StructureTrait val = \"Compound\"/> AttributeTypes ( AttributeType \"FunctionalAttributeType2\" ( <SuperType val = \"Qualitative\"/> <StateAttributeType val = \"true\" /> <OptionalCausalFeature val = \"true\" /> \"Values\" ( { \"NotTooHeavy\", \"TooHeavy\" : Dictionary ( English ( { \"heavy\" } ); ); } ); ); ); );\n2.2. Behavior Classes\n2.2.1. Observations\nThe behavior classes shown here were also generated from the same two sentences (above),\ncopied here for clarity.\nNatural language input:\nIf a person is too weak then he cannot lift another person. If a person is too heavy then another person cannot lift him.\n2.2.2. Listing\nBehaviorClass \"NotLift_Weak_BehaviorClass\" ( <CausalRule val = \"true\" /> <BridgeObjectFrameClass ref = BehavioralStructuralParentClass /> <Negation val = \"true\" /> Dictionary ( English ( { \"lift\", \"lifted\", \"lifted\", \"lifts\", \"lifting\" } );); PriorStates ( PopulatedObjectClass \"AntecedentActor\" ( <ObjectFrameClass ref = PersonObjectFrameClass /> <BinderSourceFlag val = \"true\" /> <DimensionSystem ref = RelativePosition /> <Attribute ref = RelativeLocation var = a$ /> <Attribute ref = RelativeTime var = t1$ /> <Attribute ref = LiftingState val = \"NotLifting\" /> <Attribute ref = FunctionalAttributeType1 val = \"TooWeak\" /> ); PopulatedObjectClass \"AntecedentActee\" ( <ObjectFrameClass ref = PersonObjectFrameClass /> <PassiveParticipant val = \"true\" /> <DimensionSystem ref = RelativePosition /> <Attribute ref = RelativeLocation expr = (a$+1) /> <Attribute ref = RelativeTime expr = t1$ />\n<Attribute ref = PassiveIsLiftedState val = \"NotLifted\" /> ); ); PostStates ( PopulatedObjectClass \"ConsequentActor\" ( <ObjectFrameClass ref = PersonObjectFrameClass /> <DimensionSystem ref = RelativePosition /> <Attribute ref = RelativeLocation expr = (a$+1) /> <Attribute ref = RelativeTime expr = (t1$+1) /> <Attribute ref = LiftingState val = \"Lifting\" /> ); PopulatedObjectClass \"ConsequentActee\" ( <ObjectFrameClass ref = PersonObjectFrameClass /> <PassiveParticipant val = \"true\" /> <DimensionSystem ref = RelativePosition /> <Attribute ref = RelativeLocation expr = (a$+1) /> <Attribute ref = RelativeTime expr = (t1$+1) /> <Attribute ref = PassiveIsLiftedState val = \"Lifted\" /> ); ); );\nBehaviorClass \" NotLift_Heavy_BehaviorClass \" ( <CausalRule val = \"true\" /> <BridgeObjectFrameClass ref = BehavioralStructuralParentClass /> <Negation val = \"true\" /> Dictionary ( English ( { \"lift\", \"lifted\", \"lifted\", \"lifts\", \"lifting\" } );); PriorStates ( PopulatedObjectClass \"AntecedentActor\" ( <ObjectFrameClass ref = PersonObjectFrameClass /> <BinderSourceFlag val = \"true\" /> <DimensionSystem ref = RelativePosition /> <Attribute ref = RelativeLocation var = a$ /> <Attribute ref = RelativeTime var = t1$ /> <Attribute ref = LiftingState val = \"NotLifting\" /> ); PopulatedObjectClass \"AntecedentActee\" ( <ObjectFrameClass ref = PersonObjectFrameClass />\n<PassiveParticipant val = \"true\" /> <DimensionSystem ref = RelativePosition /> <Attribute ref = RelativeLocation expr = (a$+1) /> <Attribute ref = RelativeTime expr = t1$ /> <Attribute ref = PassiveIsLiftedState val = \"NotLifted\" /> <Attribute ref = FunctionalAttributeType2 val = \"TooHeavy\" /> ); ); PostStates ( PopulatedObjectClass \"ConsequentActor\" ( <ObjectFrameClass ref = PersonObjectFrameClass /> <DimensionSystem ref = RelativePosition /> <Attribute ref = RelativeLocation expr = (a$+1) /> <Attribute ref = RelativeTime expr = (t1$+1) /> <Attribute ref = LiftingState val = \"Lifting\" /> ); PopulatedObjectClass \"ConsequentActee\" ( <ObjectFrameClass ref = PersonObjectFrameClass /> <PassiveParticipant val = \"true\" /> <DimensionSystem ref = RelativePosition /> <Attribute ref = RelativeLocation expr = (a$+1) /> <Attribute ref = RelativeTime expr = (t1$+1) /> <Attribute ref = PassiveIsLiftedState val = \"Lifted\" /> ); ); );\n3. Ontology and KB for Schema: \u201cReceiving/Delivering and Paying\u201d\nThe behavior classes that are needed for this schema involve nested behaviors.\nComprehendor\u2019s OntologyBuilder does not yet generate nested behaviors in behavior classes. However the following object frame class information items were auto-generated.\nNatural language input:\nA deliverable object is a common object. A person can receive something. A person can deliver something. A person can pay a person. A detective is a person.\nThe concept of a \u201cdeliverable\u201d is used here as a high-level abstraction that includes any of:\nservices, products, a report, etc. This is one of several possible ways to model the semantics of the input schema text \u201creceived the final report\u201d. (Although the behavior classes shown in the following section were hand-coded, not auto-generated, the following NL input could be used once this auto-generation feature is implemented in the Comprehendor NLU system).\nIf a person receives a deliverable then he/she does pay another person. If a person delivers a deliverable then he/she is paid by another person.\n3.1. Object Frame Classes\n3.1.1. Lower Ontology: Auto-Generated Classes\nObjectFrameClass \"PersonObjectFrameClass\" ( <StructureTrait val = \"Compound\"/> AttributeTypes ( AttributeType \"PayingState\" ( <SuperType val = \"Qualitative\"/> <StateAttributeType val = \"true\" /> \"Values\" ( { \"NotPaying\", \"Paying\" } ); );\nAttributeType \"PassiveIsPayedState\" ( <SuperType val = \"Qualitative\"/> <StateAttributeType val = \"true\" /> \"Values\" ( { \"NotPayed\", \"Payed\" } ); ); AttributeType \"ReceivingState\" ( <SuperType val = \"Qualitative\"/> <StateAttributeType val = \"true\" /> \"Values\" ( { \"NotReceiving\", \"Receiving\" } ); ); AttributeType \"DeliveringState\" ( <SuperType val = \"Qualitative\"/> <StateAttributeType val = \"true\" /> \"Values\" ( { \"NotDelivering\", \"Delivering\" } ); ); ); ); ObjectFrameClass \"DeliverableObjectObjectFrameClass\" ( <StructureTrait val = \"Compound\"/> DictionaryPriorWord ( <DictionaryWordIsNoun val = \"true\" /> English (\n{ \"deliverable\", \"deliverables\" } ); ); Dictionary ( English ( { \"object\", \"objects\" } );); HigherClasses ( { \"CommonObjectFrameClass\" } ); ); ObjectFrameClass \"DeliverableObjectObjectFrameClass\" ( <StructureTrait val = \"Compound\"/> AttributeTypes ( AttributeType \"PassiveIsReceivedState\" ( <SuperType val = \"Qualitative\"/> <StateAttributeType val = \"true\" /> \"Values\" ( { \"NotReceived\", \"Received\" } ); ); ); ); ObjectFrameClass \"DeliverableObjectObjectFrameClass\" ( <StructureTrait val = \"Compound\"/> AttributeTypes ( AttributeType \"PassiveIsDeliveredState\" ( <SuperType val = \"Qualitative\"/> <StateAttributeType val = \"true\" /> \"Values\" ( { \"NotDelivered\", \"Delivered\" } );\n); ); ); ObjectFrameClass \"DetectiveObjectFrameClass\" ( <StructureTrait val = \"Compound\"/> Dictionary ( English ( { \"detective\", \"detectives\" } );); HigherClasses ( { \"PersonObjectFrameClass\" } ); );\n3.2. Behavior Classes\n3.2.1. Observations\nThe first two behavior classes shown here are for the actions \u201cto deliver\u201d and \u201cto receive\u201d\n(involving persons and deliverables).\nWithin the \u201cpaying\u201d behavior classes, the nested behavior is in bold.\n3.2.2. Listing\nBehaviorClass \"ReceiveBehaviorClass\" ( <BridgeObjectFrameClass ref = BehavioralStructuralParentClass /> Dictionary ( English ( { \"receive\", \"received\", \"received\", \"receives\", \"receiving\" } );); PriorStates ( PopulatedObjectClass \"AntecedentActor\" ( <ObjectFrameClass ref = PersonObjectFrameClass /> <BinderSourceFlag val = \"true\" /> <DimensionSystem ref = RelativePosition /> <Attribute ref = RelativeLocation var = a$ /> <Attribute ref = RelativeTime var = t1$ /> <Attribute ref = ReceivingState val = \"NotReceiving\" />\n); PopulatedObjectClass \"AntecedentActee\" ( <ObjectFrameClass ref = DeliverableObjectObjectFrameClass /> <PassiveParticipant val = \"true\" /> <DimensionSystem ref = RelativePosition /> <Attribute ref = RelativeLocation expr = (a$+1) /> <Attribute ref = RelativeTime expr = t1$ /> <Attribute ref = PassiveIsReceivedState val = \"NotReceived\" /> ); ); PostStates ( PopulatedObjectClass \"ConsequentActor\" ( <ObjectFrameClass ref = PersonObjectFrameClass /> <DimensionSystem ref = RelativePosition /> <Attribute ref = RelativeLocation expr = (a$+1) /> <Attribute ref = RelativeTime expr = (t1$+1) /> <Attribute ref = ReceivingState val = \"Receiving\" /> ); PopulatedObjectClass \"ConsequentActee\" ( <ObjectFrameClass ref = DeliverableObjectObjectFrameClass /> <PassiveParticipant val = \"true\" /> <DimensionSystem ref = RelativePosition /> <Attribute ref = RelativeLocation expr = (a$+1) /> <Attribute ref = RelativeTime expr = (t1$+1) /> <Attribute ref = PassiveIsReceivedState val = \"Received\" /> ); ); ); BehaviorClass \"DeliverBehaviorClass\" ( <BridgeObjectFrameClass ref = BehavioralStructuralParentClass /> Dictionary ( English ( { \"deliver\", \"delivered\", \"delivered\", \"delivers\", \"delivering\" } );); PriorStates ( PopulatedObjectClass \"AntecedentActor\" ( <ObjectFrameClass ref = PersonObjectFrameClass /> <BinderSourceFlag val = \"true\" /> <DimensionSystem ref = RelativePosition /> <Attribute ref = RelativeLocation var = a$ /> <Attribute ref = RelativeTime var = t1$ /> <Attribute ref = DeliveringState val = \"NotDelivering\" /> );\nPopulatedObjectClass \"AntecedentActee\" ( <ObjectFrameClass ref = DeliverableObjectObjectFrameClass /> <PassiveParticipant val = \"true\" /> <DimensionSystem ref = RelativePosition /> <Attribute ref = RelativeLocation expr = (a$+1) /> <Attribute ref = RelativeTime expr = t1$ /> <Attribute ref = PassiveIsDeliveredState val = \"NotDelivered\" /> ); ); PostStates ( PopulatedObjectClass \"ConsequentActor\" ( <ObjectFrameClass ref = PersonObjectFrameClass /> <DimensionSystem ref = RelativePosition /> <Attribute ref = RelativeLocation expr = (a$+1) /> <Attribute ref = RelativeTime expr = (t1$+1) /> <Attribute ref = DeliveringState val = \"Delivering\" /> ); PopulatedObjectClass \"ConsequentActee\" ( <ObjectFrameClass ref = DeliverableObjectObjectFrameClass /> <PassiveParticipant val = \"true\" /> <DimensionSystem ref = RelativePosition /> <Attribute ref = RelativeLocation expr = (a$+1) /> <Attribute ref = RelativeTime expr = (t1$+1) /> <Attribute ref = PassiveIsDeliveredState val = \"Delivered\" /> ); ); );\nBehaviorClass \"PayAfterReceivingBehaviorClass\" ( <CausalRule val = \"true\" /> <BridgeObjectFrameClass ref = BehavioralStructuralParentClass /> Dictionary ( English ( { \"pay\", \"payed\", \"paid\", \"pays\", \"paying\" } );); PriorStates ( PopulatedObjectClass \"AntecedentActor\" ( <ObjectFrameClass ref = PersonObjectFrameClass /> <BinderSourceFlag val = \"true\" /> <DimensionSystem ref = RelativePosition /> <Attribute ref = RelativeLocation var = a$ /> <Attribute ref = RelativeTime var = t1$ /> <Attribute ref = PayingState val = \"NotPaying\" /> <Attribute ref = UniqueIdentityAttributeType var = q$ /> // (identity) ); BehaviorClassReference ( <BehaviorClass ref = ReceiveBehaviorClass /> // -->> DEFINED-BEHAVIOR-CLASS <ParameterActor ref = PersonObjectFrameClass expr = q$ /> // (identity)\n<ParameterActee ref = DeliverableObjectObjectFrameClass /> <ParameterExtra ref = PersonObjectFrameClass /> ); PopulatedObjectClass \"AntecedentActee\" ( <ObjectFrameClass ref = PersonObjectFrameClass /> <PassiveParticipant val = \"true\" /> <DimensionSystem ref = RelativePosition /> <Attribute ref = RelativeLocation expr = (a$+1) /> <Attribute ref = RelativeTime expr = t1$ /> <Attribute ref = PassiveIsPayedState val = \"NotPayed\" /> ); ); PostStates ( PopulatedObjectClass \"ConsequentActor\" ( <ObjectFrameClass ref = PersonObjectFrameClass /> <DimensionSystem ref = RelativePosition /> <Attribute ref = RelativeLocation expr = (a$+1) /> <Attribute ref = RelativeTime expr = (t1$+1) /> <Attribute ref = PayingState val = \"Paying\" /> ); PopulatedObjectClass \"ConsequentActee\" ( <ObjectFrameClass ref = PersonObjectFrameClass /> <PassiveParticipant val = \"true\" /> <DimensionSystem ref = RelativePosition /> <Attribute ref = RelativeLocation expr = (a$+1) /> <Attribute ref = RelativeTime expr = (t1$+1) /> <Attribute ref = PassiveIsPayedState val = \"Payed\" /> ); ); );\nBehaviorClass \"PersonIsPaidAfterDeliveringBehaviorClass\" ( <CausalRule val = \"true\" /> <BridgeObjectFrameClass ref = BehavioralStructuralParentClass /> Dictionary ( English ( { \"pay\", \"payed\", \"paid\", \"pays\", \"paying\" } );); PriorStates ( PopulatedObjectClass \"AntecedentActor\" ( <ObjectFrameClass ref = PersonObjectFrameClass /> <BinderSourceFlag val = \"true\" /> <DimensionSystem ref = RelativePosition /> <Attribute ref = RelativeLocation var = a$ /> <Attribute ref = RelativeTime var = t1$ /> <Attribute ref = PayingState val = \"NotPaying\" /> ); BehaviorClassReference ( <BehaviorClass ref = DeliverBehaviorClass /> // -->> DEFINED-BEHAVIOR-CLASS <ParameterActor ref = PersonObjectFrameClass expr = q$ /> // (identity)\n<ParameterActee ref = DeliverableObjectObjectFrameClass /> <ParameterExtra ref = PersonObjectFrameClass /> ); PopulatedObjectClass \"AntecedentActee\" ( <ObjectFrameClass ref = PersonObjectFrameClass /> <PassiveParticipant val = \"true\" /> <DimensionSystem ref = RelativePosition /> <Attribute ref = RelativeLocation expr = (a$+1) /> <Attribute ref = RelativeTime expr = t1$ /> <Attribute ref = PassiveIsPayedState val = \"NotPayed\" /> <Attribute ref = UniqueIdentityAttributeType var = q$ /> // (identity) ); ); PostStates ( PopulatedObjectClass \"ConsequentActor\" ( <ObjectFrameClass ref = PersonObjectFrameClass /> <DimensionSystem ref = RelativePosition /> <Attribute ref = RelativeLocation expr = (a$+1) /> <Attribute ref = RelativeTime expr = (t1$+1) /> <Attribute ref = PayingState val = \"Paying\" /> ); PopulatedObjectClass \"ConsequentActee\" ( <ObjectFrameClass ref = PersonObjectFrameClass /> <PassiveParticipant val = \"true\" /> <DimensionSystem ref = RelativePosition /> <Attribute ref = RelativeLocation expr = (a$+1) /> <Attribute ref = RelativeTime expr = (t1$+1) /> <Attribute ref = PassiveIsPayedState val = \"Payed\" /> ); ); );\n4. Ontology and KB for Schema: \u201cCouncilmen and Demonstrators\u201d\nThe ontology and KB for Winograd schema #1 are contained in Hofford (2014 (b)) \u201cThe\nROSS User\u2019s Guide and Reference Manual\u201d.\nAppendix 3: ROSS Instance Models\nThese listings are of external instance models for selected schema sentences. The generated\ninstance models contain object instances, not classes: the object instances refer back to the ontology classes from which they have been instantiated.\n1. Instance Model for Schema: \u201cTrophy and Suitcase\u201d (\u201ctoo big\u201d variant)\nThe external instance model shown here is for the sentence: \u201cThe trophy did not fit in the\nsuitcase because it was too big.\u201d\n<?xml version=\"1.0\" encoding=\"US-ASCII\" standalone=\"yes\"?> <InstanceModel> <TranscriptHeader> <TextSource value=\"SubmittedFromWebClient\"> </TextSource> </TranscriptHeader> <ConceptualModel> <LocalContext contextId = \"1\"> <MoodAndTense> Declarative-PastSimple </MoodAndTense> <StructuralParent name=\u201dEverydayObjectStructuralParentClass\u201d > <Timeline name = \"EverydayObjectStructuralParentClass.EverydayObjectDimensionSystem\"/> </StructuralParent> <TimelineTimePoint value = \"T01\"> <InstanceStructure> <Component> TrophyObjectFrameClass.TrophyObjectFrameClass-1 (trophy) <Attributes> <Attribute> EnclosableObjectFrameClass.FittingIntoState = FittingInto </Attribute> <Attribute> EnclosableObjectFrameClass.FunctionalAttributeType1 = TooBig </Attribute> </Attributes> </Component> <Component> SuitcaseObjectFrameClass.SuitcaseObjectFrameClass-1 (suitcase) <Attributes> <Attribute> ContainerObjectFrameClass.PassiveIsFittedIntoState = NotIsFittedInto </Attribute> </Attributes> </Component> </InstanceStructure> </TimelineTimePoint>\n<TimelineTimePoint value = \"T02\"> <InstanceStructure> <Component> TrophyObjectFrameClass.TrophyObjectFrameClass-1 (trophy) <Attributes> <Attribute> EnclosableObjectFrameClass.PassiveIsFittedInsideContainerState = NotFittedInsideContainer </Attribute> </Attributes> </Component> <Component> SuitcaseObjectFrameClass.SuitcaseObjectFrameClass-1 (suitcase) <Attributes> <Attribute> ContainerObjectFrameClass.PassiveIsFittedIntoState = NotIsFittedInto </Attribute> </Attributes> </Component> </InstanceStructure> </TimelineTimePoint> </LocalContext> </ConceptualModel> </InstanceModel>\nEnd listing.\n2. Instance Model for Schema: \u201cPerson Lifts Person\u201d (\u201ctoo weak\u201d variant)\nThe external instance model for the person lifts person schema is as follows (\u201cThe man could\nnot lift his son because he was too/so weak.\u201d).\n<?xml version=\"1.0\" encoding=\"US-ASCII\" standalone=\"yes\"?> <InstanceModel> <TranscriptHeader> <TextSource value=\"DocumentFile\"> </TextSource> <DocumentFile name=\"Samples\\Sentence-02.txt\"> </DocumentFile> </TranscriptHeader> <ConceptualModel> <LocalContext contextId = \"1\"> <MoodAndTense> Declarative-PastSimple </MoodAndTense> <StructuralParent name=\u201dEverydayObjectStructuralParentClass\u201d > <Timeline name = \"EverydayObjectStructuralParentClass.EverydayObjectDimensionSystem\"/> </StructuralParent>\n<TimelineTimePoint value = \"T01\"> <InstanceStructure> <Component> ManObjectFrameClass.ManObjectFrameClass-1 (man) <Attributes> <Attribute> PersonObjectFrameClass.LiftingState = NotLifting </Attribute> <Attribute> PersonObjectFrameClass.FunctionalAttributeType1 = TooWeak </Attribute> </Attributes> </Component> <Component> SonObjectFrameClass.SonObjectFrameClass-1 (son) <Attributes> <Attribute> PersonObjectFrameClass.PassiveIsLiftedState = NotLifted </Attribute> </Attributes> </Component> </InstanceStructure> </TimelineTimePoint> <TimelineTimePoint value = \"T02\"> <InstanceStructure> <Component> ManObjectFrameClass.ManObjectFrameClass-1 (man) <Attributes> <Attribute> PersonObjectFrameClass.LiftingState = Lifting </Attribute> </Attributes> </Component> <Component> SonObjectFrameClass.SonObjectFrameClass-1 (son) <Attributes> <Attribute> PersonObjectFrameClass.PassiveIsLiftedState = NotLifted </Attribute> </Attributes> </Component> </InstanceStructure> </TimelineTimePoint> </LocalContext> </ConceptualModel> </InstanceModel>\nReferences\nErnest Davis. 2011. (a) Online resource at: http://www.cs.nyu.edu/davise/papers/WS.html. (Created 9/8/2011 by Ernest Davis. Last update: 8/19/2011).\nErnest Davis. 2011. (b) Qualitative Spatial Reasoning in Interpreting Text and Narrative, Retrieved from http://www.cs.nyu.edu/davise/papers/cosit.pdf, Last accessed June, 2014.\nGlenn Hofford. 2014. (a) Introduction to ROSS: A New Representational Scheme, Retrieved from https://www.academia.edu/7145283/Introduction_to_ROSS_A_New_Representational_Scheme, Last accessed July, 2014, (also available from http://www.softwareengineeringconcepts.com).\nGlenn Hofford. 2014. (b) ROSS User\u2019s Guide and Reference Manual, Retrieved from https://www.academia.edu/9190207/ROSS_Users_Guide_and_Reference_Manual_Version_1.0_, Last accessed November, 2014.\nGlenn Hofford. 2014. (c) Online resource at http://www.softwareengineeringconcepts.com.\nHector J Levesque, Ernest Davis and Leora Morgenstern. 2012. \"The Winograd Schema Challenge.\" KR-2012. n.d. Retrieved from http://www.cs.nyu.edu/davise/papers/WSKR2012.pdf.\nTerry Winograd. 1971. \u201cProcedures as a Representation for Data in a Computer Program for Understanding Natural Language\u201d. (Dissertation submitted to the Department of Mathematics, Massachusetts Institute of Technology).\nTerry Winograd. 1972. Understanding Natural Language, Academic Press, Orlando."}], "references": [{"title": "http://www.cs.nyu.edu/davise/papers/WS.html. (Created 9/8/2011 by Ernest Davis. Last update: 8/19/2011)", "author": ["Ernest Davis"], "venue": "Ernest Davis", "citeRegEx": "Davis.,? \\Q2011\\E", "shortCiteRegEx": "Davis.", "year": 2011}, {"title": "The Winograd Schema Challenge.\" KR-2012", "author": ["Glenn Hofford"], "venue": "n.d. Retrieved from http://www.cs.nyu.edu/davise/papers/WSKR2012.pdf. Terry Winograd", "citeRegEx": "Hofford.,? \\Q2014\\E", "shortCiteRegEx": "Hofford.", "year": 2014}], "referenceMentions": [{"referenceID": 0, "context": "This approach is exemplified by Davis (2011b), wherein he describes the trophy and suitcase example.", "startOffset": 32, "endOffset": 46}], "year": 2014, "abstractText": null, "creator": "Microsoft\u00ae Office Word 2007"}}}