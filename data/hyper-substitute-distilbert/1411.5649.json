{"id": "1411.5649", "review": {"conference": "arxiv", "VERSION": "v1", "DATE_OF_SUBMISSION": "20-Nov-2014", "title": "No-Regret Learnability for Piecewise Linear Losses", "abstract": "in the conceptual optimization attitude to problem error minimization, procedural methods have been developed to uncover a $ o ( \\ arc { s } ) $ regret target for subdifferentiable zero loss functions with bounded output by means zero positive median or item _ restored functions. this suggests that the maximum tend tae be the hardest satisfying criterion to learn otherwise. we investigate this question following a systematic fashion utilizing supplying $ \\ omega ( \\ sqrt { h } ) $ lower bounds hence decreasing minimal cost regret for which guaranteed 1 piecewise linear loss returns that subsumes the \\ h symmetric linear recover functions. negative results belong in a completely adversarial setting. assessing probability, we show plainly the minimum achievable criterion doesn be significantly smaller regardless the opponent is present.", "histories": [["v1", "Thu, 20 Nov 2014 19:38:11 GMT  (50kb,D)", "https://arxiv.org/abs/1411.5649v1", null], ["v2", "Wed, 7 Jan 2015 01:41:37 GMT  (57kb,D)", "http://arxiv.org/abs/1411.5649v2", null], ["v3", "Thu, 8 Jan 2015 08:40:58 GMT  (57kb,D)", "http://arxiv.org/abs/1411.5649v3", null], ["v4", "Fri, 27 May 2016 21:29:52 GMT  (23kb)", "http://arxiv.org/abs/1411.5649v4", null], ["v5", "Sat, 17 Sep 2016 16:14:50 GMT  (26kb)", "http://arxiv.org/abs/1411.5649v5", null]], "reviews": [], "SUBJECTS": "cs.LG", "authors": ["arthur flajolet", "patrick jaillet"], "accepted": false, "id": "1411.5649"}, "pdf": {"name": "1411.5649.pdf", "metadata": {"source": "CRF", "title": "No-Regret Learnability for Piecewise Linear Losses", "authors": ["Arthur Flajolet"], "emails": ["flajolet@mit.edu", "jaillet@mit.edu"], "sections": [{"heading": null, "text": "ar X\niv :1\n41 1.\n56 49\nv5 [\ncs .L\nG ]\n1 7\nSe p\n\u221a T ) bound on regret for subdifferentiable\nconvex loss functions with bounded subgradients, by using a reduction to linear loss functions. This suggests that linear loss functions tend to be the hardest ones to learn against, regardless of the underlying decision spaces. We investigate this question in a systematic fashion looking at the interplay between the set of possible moves for both the decision maker and the adversarial environment. This allows us to highlight sharp distinctive behaviors about the learnability of piecewise linear loss functions. On the one hand, when the decision set of the decision maker is a polyhedron, we establish \u2126( \u221a T ) lower bounds on regret for a large class of piecewise linear loss functions with important applications in online linear optimization, repeated zero-sum Stackelberg games, online prediction with side information, and online two-stage optimization. On the other hand, we exhibit o( \u221a T ) learning rates, achieved by the Follow-The-Leader algorithm, in online linear optimization when the boundary of the decision maker\u2019s decision set is curved and when 0 does not lie in the convex hull of the environment\u2019s decision set. Hence, the curvature of the decision maker\u2019s decision set is a determining factor for the optimal learning rate. These results hold in a completely adversarial setting."}, {"heading": "1 Introduction", "text": "Online convex optimization has emerged as a popular approach to online learning, bringing together convex optimization methods to tackle problems where repeated decisions need to be made in an unknown, possibly adversarial, environment. A full-information online convex optimization problem is a repeated zero-sum game between a learner (the player) and the environment (the opponent). There are T time periods. At each round t, the player has to choose ft in a convex set F . Subsequent to the choice of ft, the environment reveals zt \u2208 Z and the loss incurred to the player is \u2113(zt, ft), for a loss function \u2113 that is convex in its second argument. Both players are aware of all the parameters of the game, namely \u2113, Z , and F , prior to starting the game. Additionally, at the end of each period, the opponent\u2019s move is revealed to the player. The performance of the player is measured in terms of a quantity coined regret, defined as the gap between the accumulated losses incurred by the player and the best performance he could have achieved in hindsight with a non-adaptive strategy:\nrT ((zt)t=1,\u00b7\u00b7\u00b7 ,T , (ft)t=1,\u00b7\u00b7\u00b7 ,T ) = T \u2211\nt=1\n\u2113(zt, ft)\u2212 inf f\u2208F\nT \u2211\nt=1\n\u2113(zt, f).\nIn this field, one of the primary focus is to design algorithms, i.e., strategies to select (ft)t=1,\u00b7\u00b7\u00b7 ,T so as to keep the regret as small as possible even when facing an adversarial opponent. Particular\nemphasis is placed on how the regret scales with T because this dependence relates to a notion of learning rate. If rT = o(T ), the player is, in some sense, learning the game in the long-run since the gap between experienced and best achievable average cumulative payoffs vanishes as T \u2192 \u221e. Furthermore, the smaller the growth rate of rT , the faster the learning. A natural question to ask is what is the best learning rate that can be achieved for a given game (\u2113,Z,F). Mathematically, this is equivalent to characterizing the growth rate of the smallest regret that can be achieved by a player against a completely adversarial opponent, expressed as:\nRT (\u2113,Z,F) = inf f1\u2208F sup z1\u2208Z \u00b7 \u00b7 \u00b7 inf fT \u2208F sup zT\u2208Z [\nT \u2211\nt=1\n\u2113(zt, ft)\u2212 inf f\u2208F\nT \u2211\nt=1\n\u2113(zt, f) ], (1)\nwhich we refer to as the value of the game (\u2113,Z,F). Aside from pure learning considerations, the growth rate of RT (\u2113,Z,F) has important consequences in a variety of fields where no-regret algorithms are used to compute complex quantities, e.g. Nash equilibria in Game Theory [14] or solutions to optimization problems in convex optimization [7], in which case this growth rate translates into the number of iterations required to compute the quantity with a given precision. We investigate this question in a systematic fashion by looking at the interplay between F and Z for the following class of piecewise linear loss functions:\n\u2113(z, f) = max x\u2208X (z) (C(z)f + c(z))Tx, (2)\nwhere, for any z \u2208 Z , C(z) is a matrix, c(z) is a vector, and X (z) \u2282 Rd is either a finite set or a polyhedron {x \u2208 Rd | A(z)x \u2264 b(z)} with A(z) a matrix and b(z) a vector. This type of loss functions arises in a number of important contexts such as online linear optimization, repeated zerosum Stackelberg games, online prediction with side information, and online two-stage optimization, as illustrated in Section 1.1. Throughout the paper, we make the following standard assumption so as to have the game well-defined.\nAssumption 1 Z is a non-empty compact subset of Rdz and F is a non-empty, convex, and compact subset of Rdf . For any choice of z \u2208 Z , the set X (z) is not empty. The loss function \u2113 is bounded on Z \u00d7 F . Moreover, either Z has finite cardinality or \u2113(\u00b7, f) is continuous for any f \u2208 F .\nContributions. A number of no-regret algorithms developed in the literature can be used as a black box for the settings considered in this paper in order to get O( \u221a T ) bounds on regret, e.g. Exponential Weights [20], Online Gradient Descent [22], and more generally Online Mirror Descent [9], to cite a few. To get better learning rates, other approaches have been proposed but they usually rely on either the curvature of \u2113, for instance if \u2113 is strongly convex in its second argument [8], which is not the case here, or more information about the sequence (zt)t=1,\u00b7\u00b7\u00b7 ,T , see for example [17], which is not available in the fully adversarial setting. Aside from particular instances, e.g. [6] and [1], it is in general unknown how the interplay between \u2113, Z , and F determines the growth rate of RT (\u2113,Z,F). The main insight from this paper is that the curvature of the decision maker\u2019s set of moves is a determining factor for the growth rate of RT (\u2113,Z,F): if F has rough edges then we are doomed to a rate of \u0398( \u221a T ), otherwise, if it is curved, the rate can be exponentially smaller. Specifically, we show that:\n1. When F is a polyhedron, either RT (\u2113,Z,F) = 0 or RT (\u2113,Z,F) = \u2126( \u221a T ). This lower\nbound applies to online combinatorial optimization where F is a combinatorial set, to many experts settings and repeated zero-sum Stackelberg games where the player resorts to a randomized strategy, as well as to many online prediction problems with side information and online two-stage optimization problems.\n2. When (i) \u2113 is linear, (ii) F = {f \u2208 Rdf | F (f) \u2264 0}, for F either a strongly convex function or F (f) = \u2016f\u2016F \u2212C where C \u2265 0 and \u2016 \u2016F is a q\u2212uniformly convex norm with q \u2208 [2, 3], and (iii) 0 does not lie in the convex hull of Z , we have RT (\u2113,Z,F) = o( \u221a T ),\nachieved by the Follow-The-Leader algorithm [12]. This result applies to repeated zerosum games where the player picks a cost vector (e.g. arc costs) of bounded euclidean norm and the opponent chooses an element in a combinatorial set (e.g. a path). This also applies to non-linear loss functions when 0 does not lie in the convex hull of the set of subgradients of \u2113 with respect to the second-coordinate by a standard reduction to linear loss functions,\nsee [22]. Note that assumption (iii) is required to get o( \u221a T ) rates as it is well known that RT (\u2113,Z,F) = \u2126( \u221a T ) for linear losses when 0 lies in the interior of the convex hull of Z , see Section 2."}, {"heading": "1.1 Applications", "text": "We list examples of situations where losses of the type (2) arise.\nOnline linear optimization In this setting, the loss function is given by \u2113(z, f) = zTf . This includes, in particular:\n\u2022 online combinatorial optimization where the opponent picks a cost in [0, 1]dz and F is defined as the convex hull of a finite set of elements (e.g. paths, spanning trees, and matchings),\n\u2022 experts settings where the player picks a distribution over the experts\u2019 advice (in which case F is also a polyhedron) and the opponent reveals a cost for each of the experts.\nIn online linear optimization, regret lower bounds are often derived by introducing a randomized zero-mean i.i.d. opponent, see [1]. However, this is possible only if 0 is in interior of the convex hull of Z , which is typically not the case in online combinatorial optimization. A general feature of online linear optimization that will turn out to be important in the analysis is that there is no loss of generality in assuming that Z is a convex set in the following sense.\nLemma 1 When \u2113(z, f) = zTf , the games (\u2113,Z,F) and (\u2113, conv(Z),F) are equivalent, i.e.:\nRT (\u2113,Z,F) = RT (\u2113, conv(Z),F).\nRepeated zero-sum Stackelberg games A repeated zero-sum Stackelberg game is a repeated zero-sum game with the particularity that one of the players, referred to as the leader, has to commit first to a randomized strategy f without even knowing which of the N other players, indexed by z, he is going to face at the next round. The interaction between the leader and player z \u2208 {1, \u00b7 \u00b7 \u00b7 , N} is captured by a payoff matrixM(z). Once the leader is set on a strategy, the identity of the other player is revealed and the latter best-responds to the leader\u2019s strategy, leading to the following expression for the loss function:\n\u2113(z, f) = max i=1,\u00b7\u00b7\u00b7 ,Iz eTiM(z)f,\nwhere Iz is the number of possible moves for player z. We illustrate with a network security problem that has applications in urban network security [10] and fare evasion prevention in transit networks [11]. Consider a directed graph G = (V,E). The leader has a limited number of patrols that can be assigned to arcs in order to intercept the attackers. A configuration \u03b3 \u2208 \u0393 corresponds to a valid assignment of patrols to arcs and is represented by a vector (Y \u03b3ij )(i,j)\u2208E with Y \u03b3 ij = 1 if a patrol is assigned to arc (i, j) and Y \u03b3ij = 0 otherwise. The leader chooses a mixed strategy f over the set of feasible allocations. Attacker z \u2208 {(i1, j1), \u00b7 \u00b7 \u00b7 , (iN , jN )} wants to go from z1 to z2 while minimizing the probability of being intercepted. This interaction is captured by the loss function:\n\u2113(z, f) = max x\u2208X (z)\n\u2211 \u03b3\u2208\u0393 \u2212f\u03b3x\u03b3 ,\nwith: X (z) = {( max\n(i,j)\u2208E X\u03c0ijY \u03b3 ij )\u03b3\u2208\u0393 | \u03c0 \u2208 \u03a0(z)},\nwhere \u03a0(z) is the set of directed paths joining z1 to z2 in G and X\u03c0ij = 1 if (i, j) \u2208 \u03c0 and X\u03c0ij = 0 otherwise. The presentation of repeated Stackelberg games given here follows the model introduced by Balcan et al. [3] for general, i.e. not necessarily zero-sum, Stackelberg security games. In this more general setting, the loss function may not be convex and a possible approach, see [3], is to add another layer of randomization which casts the problem back into the realm of online linear optimization.\nOnline prediction with side-information This setting has a slightly different flavor as the opponent provides some side information x before the player gets to pick f \u2208 F , subsequent to what the opponent reveals the correct prediction y. Nonetheless, the lower bounds established in this paper also apply to this setting through a reduction to the setting without side-information, as detailed at the end of Section 2. In the standard linear binary prediction problem, where F is a L2 ball, y \u2208 {\u22121, 1}, and x lies in a L2 ball, loss functions of the form (2) are commonly used, e.g. the absolute loss \u2113((x, y), f) = |y \u2212 xTf | and the hinge loss \u2113((x, y), f) = max(0, 1\u2212 yxTf). This is also true for linear multiclass prediction problems with the multiclass hinge loss:\n\u2113(f, (x, y)) = max j=1,\u00b7\u00b7\u00b7 ,N\n(1{j 6= y}+ f Tj x\u2212 f Tyx),\nwhere N denotes the number of classes, y \u2208 {1, \u00b7 \u00b7 \u00b7 , N}, and f is a vector obtained by concatenation of the vectors f1, \u00b7 \u00b7 \u00b7 , fN . In the online approach to collaborative filtering, a typical loss function is \u2113(M, (i, j, y)) = |M(i, j) \u2212 y| where M is a (user, item) matrix with bounded trace norm, (i, j) is a (user, item) pair, and y is the rating of item j by user i.\nOnline two-stage optimization This setting captures situations where the decision making process can be broken down into two consecutive stages. In the first stage, the player makes a decision represented by f \u2208 F . Subsequently, the opponent discloses some information z \u2208 Z , e.g. a demand vector, and then the player chooses another decision vector x in the second stage, taking into account this newly available information to optimize his objective function. The loss function takes on the following form:\n\u2113(z, f) = cT1f + min x\u2208Rd\nAf+Bx\u2264z\ncT2x,\nwhere c1 and c2 are cost vectors and A and B are matrices. Using strong duality, this loss function can be expressed in the canonical form (2). This framework finds applications in the operation of power grids, where z represents the demand in electricity or the availability of various energy sources. Since z is unknown when it is time to set up conventional generators, the decision maker has to adjust the production or buy additional capacity from a spot market to meed the demand, see for example [13].\nCongestion control We consider a variant of the congestion network game described in [4]. A decision maker has to decide how to ship a given set commodities through a network G = (V,E). His decision can be equivalently represented by a flow vector f . Because the amount of commodities is assumed to be substantial, implementing f will cause congestion which will impact the other users of the network, represented by a flow vector z. The problem faced by the decision maker is to cause as little delay as possible to the other users with the additional difficulty that the traffic pattern z is not known ahead of time. Each arc e \u2208 E has an associated latency function that is convex in the flow on this arc:\nce(f + z) = max k=1,\u00b7\u00b7\u00b7 ,K\n(cke \u00b7 (fe + ze) + ske),\nAs a result, the total delay incurred to the other users can be expressed as:\n\u2113(z, f) = \u2211\ne\u2208E ze max k=1,\u00b7\u00b7\u00b7 ,K (cke \u00b7 (fe + ze) + ske)."}, {"heading": "1.2 Related work", "text": "Asymptotically matching lower and upper bounds on RT (\u2113,Z,F) can be found in the literature for a variety of loss functions although the discussion tends to be restrictive as far as the decision sets F and Z are concerned. The value of the game is shown to be \u0398(logT ) for three standard examples of curved loss functions. The first example, studied by Abernethy et al. [1], is the quadratic loss where \u2113(z, f) = z \u00b7 f + \u03c3\u2016f\u201622 for \u03c3 > 0, with Z and F bounded L2 balls. The second, studied by Vovk [21], is the online linear regression setting where the opponent plays z = (y, x) \u2208 Z = [\u2212Cy, Cy]\u00d7 B\u221e(0, 1) for Cy > 0 (B\u221e(0, 1) denotes the unit L\u221e ball), the loss is \u2113((y, x), f) = (y\u2212x\u00b7f)2, and F is an L2 ball. The last one, from Ordentlich and Cover [15], is the log-loss \u2113(z, f) = \u2212 log z \u00b7 f with Z any compact set in Rd and F the simplex of dimension d. For non-curved losses, evidence suggests that the value of the game increases exponentially to \u0398( \u221a T ). Indeed,\u2126( \u221a T ) lower bounds are proved for several instances involving the absolute loss \u2113(z, f) = |z \u2212 f | in [5], typically with\nZ = {0, 1} and F = [0, 1]. For purely linear loss functions, Abernethy et al. [1] establish a \u2126( \u221a T ) lower bound on RT (\u2113,Z,F) when Z is an L2 ball centered at 0 and F is either an L2 ball or a bounded rectangle. This result was later generalized in [2] and shown to hold for F a unit ball in any norm centered at 0 and Z its dual ball. Cesa-Bianchi and Lugosi [6] investigate the experts setting, i.e. Z = [0, 1]d and F is the simplex in dimension d, and proves the same \u2126( \u221a T ) lower bound (which also holds if Z is the simplex in dimension d, see [2]). Rakhlin et al. [19] establish \u2126( \u221a T ) lower bounds on regret when \u2113 is the absolute loss for a prediction with side-information setting more general than the one considered in this paper where the player picks a function f(\u00b7), the opponent picks a pair (x, y), and the loss is \u2113(f(\u00b7), (x, y)) = |f(x) \u2212 y|. The list of results listed above is far from being exhaustive but provides a good picture of the current state of the art. For each loss function, the intrinsic limitations of online algorithms are well-understood, usually with the construction of a particular example of F and Z for which a lower bound on RT (\u2113,Z,F) asymptotically matches the best guarantee achieved by one of these algorithms. We aim at studying lower bounds on the value of the game in a more systematic fashion using tools rooted in duality theory and sensitivity analysis. All the proofs are deferred to the Appendix.\nNotations For a set S \u2282 Rd, conv(S) (resp. int(S)) refers to the convex hull (resp interior) of this set. When S is a compact, we define P(S) as the set of probability measures on S. For x \u2208 Rd, \u2016x\u2016 refers to the L2 norm of x while B2(x, \u01eb) denotes the closed L2 ball centered at x with width \u01eb. For a collection of random variables (Z1, \u00b7 \u00b7 \u00b7 , Zt), \u03c3(Z1, \u00b7 \u00b7 \u00b7 , Zt) refers to the sigma-field generated by Z1, \u00b7 \u00b7 \u00b7 , Zt. For a random variable Z and a probability distribution p, we write Z \u223c p if Z is distributed according to p."}, {"heading": "2 Lower bounds", "text": "Unless otherwise stated, we assume throughout this section that \u2113 can be written in the form (2). In particular, \u2113(z, \u00b7) is continuous for any z \u2208 Z . We build on a powerful result rooted in von Neumann\u2019s minimax theorem that enables the derivation of tight lower and upper bounds on RT (\u2113,Z,F) by recasting the value of the game in a backward order.\nTheorem 1 From [2]\nRT (\u2113,Z,F) = sup p E[\nT \u2211\nt=1\ninf ft\u2208F E[\u2113(Zt, ft)|Z1, \u00b7 \u00b7 \u00b7 , Zt\u22121]\u2212 inf f\u2208F\nT \u2211\nt=1\n\u2113(Zt, f) ],\nwhere the supremum is taken over the distribution p of the random variable (Z1, \u00b7 \u00b7 \u00b7 , ZT ) in ZT .\nAny choice for p yields a lower bound on RT (\u2113,Z,F). The following result identifies a canonical choice for p that leads to \u2126( \u221a T ) lower bounds on regret.\nLemma 2 Adapted from [2] If we can find a distribution p on Z and two points f1 and f2 in argminf\u2208F E[\u2113(Z, f)] such that \u2113(Z, f1) 6= \u2113(Z, f2) with positive probability for Z \u223c p, then RT (\u2113,Z,F) = \u2126( \u221a T ).\nA distribution p satisfying the requirements of Lemma 2 can be viewed as an equalizing strategy for the opponent. This concept, formalized in [18], roughly refers to randomized strategies played by the opponent that cause the player\u2019s decisions to be completely irrelevant from a regret standpoint. These strategies are intrinsically hard to play against and often lead to tight lower bounds. To gain some intuition about this result, suppose that that the opponent generates an independent copy of Z at each round t, which we denote by Zt. In the adversarial setting considered in this paper, the player is aware of the opponent\u2019s strategy but does not get to see the realization of Zt before committing to a decision. For this reason, at any round, f1 and f2 are optimal moves that are completely equivalent from the player\u2019s perspective. However, in hindsight, i.e. once all the realizations of the Zt\u2019s have been revealed, f1 and f2 are typically not equivalent because \u2113(Zt, f1) 6= \u2113(Zt, f2) with positive probability and one of these two moves will turn out to be\nmax(0,\nT \u2211\nt=1\n\u2113(Zt, f1)\u2212 \u2113(Zt, f2))\nsuboptimal which, in expectations, is of order \u2126( \u221a T ) by the central limit theorem. Given the conditions imposed on p, it is convenient to work with the following equivalence relation.\nDefinition 1 We define the equivalence relation \u223c\u2113 on F by fa \u223c\u2113 fb for fa, fb \u2208 F if and only if \u2113(z, fa) = \u2113(z, fb) for all z \u2208 Z .\nIn what follows, we show, using sensitivity analysis for linear programming, that we can systematically, with the only exception of trivial games defined below, construct a distribution p with support Z such that there are at least two equivalent classes in argminf\u2208F E[\u2113(Z, f)] whenever F is a polyhedron, for Z \u223c p.\nDefinition 2 The game (\u2113,Z,F) is said to be trivial if and only if \u2203f\u2217 \u2208 F such that \u2200z \u2208 Z, \u2113(z, f\u2217) \u2264 min\nf\u2208F \u2113(z, f).\nA simple example of a trivial game is (\u2113(z, f) = zf, [0, 1], [0, 1]), where \u2113(z, f) \u2265 0 \u2200f \u2208 [0, 1] and \u2200z \u2208 [0, 1], with \u2113(z, f) = 0 if f = 0 irrespective of z. If the game is trivial, the player will always play f\u2217 irrespective of the time horizon and of the opponent\u2019s strategy observed so far to obtain zero regret. As it turns out, this uniquely identifies trivial games as we establish in Lemma 3.\nLemma 3 For any T \u2208 N, RT (\u2113,Z,F) \u2265 0. Moreover in any of the following cases:\n1. Z has finite cardinality, 2. \u2113(\u00b7, f) is continuous for any choice of f \u2208 F ,"}, {"heading": "RT (\u2113,Z,F) = 0 if and only if the game is trivial.", "text": "The following result shows that, in most cases of interest, we can drastically restrict the power of the opponent while still preserving the nature of the game. This enables us to focus on the case where Z is finite.\nLemma 4 Suppose that \u2113(\u00b7, f) is continuous for any choice of f \u2208 F . If the game (\u2113,Z,F) is not trivial, there exists a finite subset Z\u0303 \u2286 Z such that the game (\u2113, Z\u0303,F) is not trivial.\nWe are now ready to present the main results of this section. To the best of our knowledge, these results constitute the first systematic \u2126( \u221a T ) lower bounds on regret obtained for a large class of piecewise linear loss functions.\nTheorem 2 Suppose that F is a polyhedron. In any of the following cases:\n1. Z has finite cardinality, 2. \u2113(\u00b7, f) is continuous for any choice of f \u2208 F ,\neither the game is trivial or RT (\u2113,Z,F) = \u2126( \u221a T ).\nAn immediate consequence of Theorem 2 for linear games is the following:\nTheorem 3 Suppose that F is a polyhedron and that \u2113(z, f) = zTf . Then, either the game is trivial or RT (\u2113,Z,F) = \u2126( \u221a T ).\nThe proofs rely on Lemma 2 which is based on Theorem 1 and may, as a result, seem rather obscure. We stress that these lower bounds are derived by means of an equalizing strategy. We present this more intuitive view in the Appendix by exhibiting an equalizing strategy in the online linear optimization setting when int(conv(Z)) 6= \u2205. Note that Theorems 2 and 3 imply \u2126( \u221a T ) regret for a number of repeated Stackelberg games and online linear optimization problems as discussed in Section 1.1. Furthermore, we stress that Theorem 2 can also be used when F is not a polyhedron but this typically requires a preliminary step which boils down to restricting the opponent\u2019s decision set. For instance, the following well-known result is almost a direct consequence of Theorem 3.\nLemma 5 Suppose that \u2113(z, f) = zTf , that 0 \u2208 int(conv(Z)), and that F contains at least two elements. Then RT (\u2113,Z,F) = \u2126( \u221a T ).\nNote that Lemma 5 is consistent with Theorem 3 as the game (\u2113(z, f) = zTf,Z,F) is non-trivial if 0 \u2208 int(conv(Z)) as soon as F contains at least two elements. Indeed:\n\u2113(\u01eb f2 \u2212 f1 \u2016f2 \u2212 f1\u2016 , f2) > \u2113(\u01eb f2 \u2212 f1 \u2016f2 \u2212 f1\u2016 , f1) and \u2113(\u01eb f1 \u2212 f2 \u2016f2 \u2212 f1\u2016 , f1) > \u2113(\u01eb f1 \u2212 f2 \u2016f2 \u2212 f1\u2016 , f2),\nfor a small enough \u01eb > 0 and any pair f1 6= f2 \u2208 F . When 0 \u2208 int(Z), the opponent has some freedom to play, at each time period, a random vector with expected value zero, making every strategy available to the player equally bad. In other words, any i.i.d. zero-mean distribution is an equalizing strategy for the opponent in this case. A preliminary step is also required to derive \u2126( \u221a T ) lower bounds on regret for prediction problems with side information where F is typically not a polyhedron. We sketch this simple argument for the canonical classification problem with the hinge loss, i.e. the game :\n(\u2113((x, y), f) = max(0, 1\u2212 yxTf),Z = B2(0, 1)\u00d7 {\u22121, 1},F = B2(0, 1)), but the method readily extends to any of the prediction problems described in Section 1.1. The idea is to restrict the opponent\u2019s decision set by taking a fixed vector x of norm 1 and impose that, at any round t, the opponent\u2019s move be (x, yt) for yt \u2208 {\u22121, 1}. Since \u2113((x, y), f) only depends on f through the scalar product between f and x, the player\u2019s decision set can be equivalently described by this value, which lies in [\u22121, 1]. Formally, we define a new loss function \u2113\u0303(y, f) = max(0, 1\u2212yf) with Z\u0303 = {\u22121, 1} and F\u0303 = [\u22121, 1] and we have:\nRT (\u2113,Z,F) \u2265 RT (\u2113\u0303, Z\u0303, F\u0303). Observe now that the game (\u2113\u0303, Z\u0303, F\u0303) is not trivial, that Z is discrete, and that:\n\u2113\u0303(y, f) = max \u03b1\u2208{0,1}\n(\u03b1,\u2212y\u03b1)T(1, f).\nWe conclude with Theorem 2 that RT (\u2113\u0303, Z\u0303, F\u0303) = \u2126( \u221a T ) which implies that RT (\u2113,Z,F) =\n\u2126( \u221a T ).\nRemark about Lemma 2 We point out that, in general, it is not possible to weaken the assumptions of Lemma 2 (which, in fact, applies to a much more general class of loss functions than the one given by (2)). In particular, finding z \u2208 Z such that there are two equivalence classes f1 and f2 in argminf\u2208F \u2113(z, f) does not guarantee that RT (\u2113,Z,F) = \u2126( \u221a T ) as we illustrate with a counterexample. This is because the result of Lemma 2 is intrinsically tied to the central limit theorem. Consider the following (non-trivial) online linear regression game:\n(\u2113(z, f) = (zTf)2,Z = B2(z\u2217, 1),F = [f1, f2]), where f1 = (1, 0, \u00b7 \u00b7 \u00b7 , 0), f2 = (0, 1, 0, \u00b7 \u00b7 \u00b7 ), and z\u2217 = (1, 1, 0, \u00b7 \u00b7 \u00b7 , 0). Observe that \u2200z \u2208 Z, \u2200f \u2208 F , zTf \u2265 0. Hence argminf\u2208F \u2113(z, f) = argminf\u2208F f Tz. Furthermore, argminf\u2208F f Tz\u2217 = [f1, f2] but f1 and f2 are clearly not in the same equivalence class. Yet, even though \u2113 is not strongly convex in f , there exists an algorithm achieving O(log(T )) regret, see [21]."}, {"heading": "3 Upper bounds", "text": "Looking at Theorem 2, Theorem 3, and Lemma 5, it is tempting to conclude that the existence of pieces where \u2113 is linear in its second argument dooms us to \u2126( \u221a T ) regret bounds. We argue that the growth rate of RT (\u2113,Z,F) is determined by a more involved interplay between \u2113, Z , and F so that this assertion requires further examination. In fact, we show that O(log(T )) regret bounds are even possible in online linear optimization. The fundamental reason is that the curvature of the boundary of F can make up for the lack of thereof of \u2113. Curvature is key to enforce stability of the player\u2019s strategy with respect to perturbations in the opponent\u2019s moves. Sometimes, when the predictions are stable, e.g. when \u2113 is the square loss \u2113(z, f) = \u2016z \u2212 f\u20162, a very simple algorithm, known as Follow-The-Leader, yields O(log(T )) regret.\nDefinition 3 From [12] The Follow-The-Leader (FTL) strategy consists in playing:\nft \u2208 argmin f\u2208F\n1\nt\u2212 1\nt\u22121 \u2211\n\u03c4=1\n\u2113(z\u03c4 , f).\nIt is well-known that FTL fails to yield sublinear regret for online linear optimization in general. However, when F has a strongly curved boundary and 0 /\u2208 conv(Z), the FTL strategy becomes stable, leading to O(log(T )) regret as we next show using sensitivity analysis.\nTheorem 4 Suppose that (i) \u2113 is linear, (ii) F = {f \u2208 Rdf | F (f) \u2264 0} for F a strongly convex function with respect to the L2 norm, and (iii) 0 /\u2208 conv(Z). Then, FTL yields O(log(T )) regret.\nAs an example of application of Theorem 4, consider a repeated network game where the player picks the arc costs in a L2 ball, the opponent picks a path, and the loss incurred to the opponent is the sum of the arc costs along the path. In this setting, FTL yields O(log(T )) regret even though the game is not trivial. Theorem 4 also has some implications for non-linear convex loss functions when the boundary of F is curved and 0 is not in the convex hull of the set of subgradients of \u2113 with respect to the player\u2019s moves. Indeed suppose that, at any time period t, the player follows the FTL strategy as if the loss function were linear and the past moves of the opponents were y1, \u00b7 \u00b7 \u00b7 , yt\u22121, i.e.:\nft \u2208 argmin f\u2208F\n1\nt\u2212 1\nt\u22121 \u2211\n\u03c4=1\nyT\u03c4f,\nwhere, for any \u03c4 = 1, \u00b7 \u00b7 \u00b7 , t \u2212 1, y\u03c4 is a subgradient of \u2113(zt, \u00b7) at ft. Then, for any sequence of moves (z1, \u00b7 \u00b7 \u00b7 , zT ), we have:\nrT ((zt)t=1,\u00b7\u00b7\u00b7 ,T , (ft)t=1,\u00b7\u00b7\u00b7 ,T ) \u2264 T \u2211\nt=1\nyTtft \u2212 inf f\u2208F\nT \u2211\nt=1\nyTtf\n= O(log(T )).\nIt is, however, a priori unclear whether log(T ) is the optimal growth rate for games satisfying the assumptions of Theorem 4. Quite surprisingly, i.i.d. opponents appear to be particularly weak for this kind of games, incurring at most a O(1) regret lower bound as shown in the following lemma. This is in stark contrast with the situations of Section 2 where the (tight) \u2126( \u221a T ) lower bounds are always derived through i.i.d. opponents.\nLemma 6 Consider the game (\u2113(z, f) = zTf,Z,F) with 0 /\u2208 conv(Z) and F = B2(0, 1). Any lower bound derived from Theorem 1 with i.i.d. random variables Z1, \u00b7 \u00b7 \u00b7 , ZT \u223c p is O(1) for any choice of p \u2208 P(Z).\nAbernethy et al. [2] remark that restricting the study to i.i.d. sequences is in general not enough to get tight bounds for non-linear losses such as \u2113(z, f) = \u2016z \u2212 f\u20162. It turns out that this is also true for linear losses when F is strongly curved and 0 /\u2208 conv(Z) as the value of the game is in fact \u0398(log(T )).\nTheorem 5 When \u2113(z, f) = zTf , 0 /\u2208 conv(Z), and F = B2(0, 1), the value of the game is: RT (\u2113,Z,F) = \u0398(log(T )).\nSo far, we have studied two scenarios that are diametrically opposed in terms of the curvature of the decision sets with polyhedra on one side in Section 2, with \u0398( \u221a T ) regret, and euclidean balls, with \u0398(log(T )) regret, on the other side of the spectrum. Interestingly, bridging this gap leads to the rise of intermediate learning rates that can be quantified through the modulus of convexity of F . Specifically, consider any norm \u2016 \u2016F . The modulus of convexity of the associated unit ball is defined as:\n\u03b4F : \u01eb \u2192 inf \u2016f\u2016\nF ,\u2016f\u0303\u2016 F \u22641\n\u2016f\u2212f\u0303\u2016 F \u2265\u01eb\n1\u2212 \u2225 \u2225 \u2225\n\u2225 \u2225\nf + f\u0303\n2\n\u2225 \u2225 \u2225 \u2225 \u2225\nF .\nThe norm \u2016 \u2016F is said to be uniformly convex if its characteristic of convexity is equal to 0, i.e.: sup{\u01eb \u2265 0 | \u03b4F(\u01eb) = 0} = 0.\nPisier [16] show that if \u2016 \u2016F is uniformly convex, there must exist q \u2265 2 and c > 0 such that \u03b4F(\u01eb) \u2265 c\u01ebq for all \u01eb \u2208 [0, 2], in which case we say that \u2016 \u2016F is q\u2212uniformly convex. This parameter quantifies how curved \u2016 \u2016F balls are and determines the growth rate of the value of the game when F is a \u2016 \u2016F ball and 0 /\u2208 conv(Z).\nLemma 7 Consider the game (\u2113(z, f) = zTf,Z,F) with 0 /\u2208 conv(Z) and F = {f | \u2016f\u2016F \u2264 C}, where \u2016 \u2016F is a q-uniformly convex norm and C \u2265 0. Then, FTL yields regret O(log(T )) if q = 2 and regret O(T q\u22122 q\u22121 ) if q \u2208 (2, 3].\nSituations where 0 lies on the boundary of Z when \u2113 is linear Observe that this situation is not covered by Lemma 5, Theorem 4, Theorem 5, nor Lemma 7. We stress that zero-mean i.i.d. opponents are not helpful to derive \u2126( \u221a T ) regret when 0 lies exactly on the boundary of Z (in fact, in the relative interior of an edge of Z), as we illustrate with an example. Therefore, the growth rate of RT (\u2113,Z,F) remains unknown in this setup. Define Z = conv(z1, z2, z3, z4) with z1 = (\u22121, 1, 0, 0), z2 = (1,\u22121, 0, 0), z3 = (0, 0, 0, 1), and z4 = (0, 0, 1, 0). Also define F = [f\u2217, f\u2217\u2217] with f\u2217 = (0, 0, 0, 0) and f\u2217\u2217 = (1, 1,\u22121, 1). Observe that the game (\u2113(z, f) = zTf,Z,F) is not trivial because argminf\u2208F f \u00b7 z3 = {f\u2217} while argminf\u2208F f \u00b7 z4 = {f\u2217\u2217}. For any zero-mean i.i.d. opponent Z1, \u00b7 \u00b7 \u00b7 , ZT , the only possibility is to have Zt \u2208 [z1, z2]. We get, irrespective of the player\u2019s strategy:\nE[rT ((Zt)t=1,\u00b7\u00b7\u00b7 ,T , (ft)t=1,\u00b7\u00b7\u00b7 ,T )] = \u2212E[ inf f\u2208F\nf \u00b7 T \u2211\nt=1\nZt].\nWe have f\u2217 \u2208 argminf\u2208F f \u00b7 z for any z \u2208 [z1, z2]. Hence:\nE[rT ((Zt)t=1,\u00b7\u00b7\u00b7 ,T , (ft)t=1,\u00b7\u00b7\u00b7 ,T )] = \u2212E[f\u2217 \u00b7 T \u2211\nt=1\nZt],\nwhich finally yields E[rT ((Zt)t=1,\u00b7\u00b7\u00b7 ,T , (ft)t=1,\u00b7\u00b7\u00b7 ,T )] = 0."}, {"heading": "Acknowledgments", "text": "The authors would like to thank Alexander Rakhlin for his valuable input, and in particular, for bringing to our attention the possibility of having o( \u221a T ) bounds on regret in the linear setting."}, {"heading": "4 Appendix: proofs", "text": ""}, {"heading": "4.1 Proof of Theorem 1", "text": "The assumptions of Theorem 1 in [2] are satisfied for the game (\u2113,Z,F) using Assumption 1 and the fact that any loss function \u2113 of the form (2) is such that \u2113(z, \u00b7) is continuous for any z \u2208 Z ."}, {"heading": "4.2 Proof of Lemma 1", "text": "The proof follows from the repeated use of the Von Neumann\u2019s minimax theorem developed in [2]. To simplify the presentation, we prove the result when T = 2 but the general proof follows the same principle. We have:\nR2 = inf f1\u2208F sup z1\u2208Z inf f2\u2208F sup z2\u2208Z [\n2 \u2211\nt=1\n\u2113(zt, ft)\u2212 inf f\u2208F\n2 \u2211\nt=1\n\u2113(zt, f) ].\nConsider fixed vectors f1, f2 \u2208 F and z1 \u2208 Z and define the function M(z2) = \u22112 t=1 \u2113(zt, ft) \u2212 inff\u2208F \u22112 t=1 \u2113(zt, f). Observe that M is convex. Indeed, z2 \u2192 \u2113(z1, f1) + \u2113(z2, f2) is affine and z2 \u2192 inff\u2208F \u22112 t=1 \u2113(zt, f) is concave as the infimum of affine functions. Therefore:\nsup z2\u2208Z M(z2) = sup z2\u2208conv(Z) M(z2).\nWe obtain:\nR2 = inf f1\u2208F sup z1\u2208Z inf f2\u2208F sup z2\u2208conv(Z) [\n2 \u2211\nt=1\n\u2113(zt, ft)\u2212 inf f\u2208F\n2 \u2211\nt=1\n\u2113(zt, f) ].\nBy randomizing the choice of z2, we can use Von Neumann\u2019s minimax theorem to derive:\nR2 = inf f1\u2208F sup z1\u2208Z { \u2113(z1, f1) + sup p2\u2208P(conv(Z)) { inf f2\u2208F Ez\u223cp2\u2113(z, f2)\u2212 Ez2\u223cp2 inf f\u2208F\n2 \u2211\nt=1\n\u2113(zt, f) } }.\nFor a fixed f1 \u2208 F , define:\nA(z1) = \u2113(z1, f1) + sup p2\u2208P(conv(Z)) { inf f2\u2208F Ez\u223cp2\u2113(z, f2)\u2212 Ez2\u223cp2 inf f\u2208F\n2 \u2211\nt=1\n\u2113(zt, f) }.\nObserve that, for a fixed p2 \u2208 P(conv(Z)), the function:\nz1 \u2192 inf f2\u2208F Ez\u223cp2\u2113(z, f2)\u2212 Ez2\u223cp2 inf f\u2208F\n2 \u2211\nt=1\n\u2113(zt, f)\nis convex as the difference between a constant and the expected value of the infimum of affine functions. Since the supremum of convex functions is convex, A is convex and supz1\u2208Z A(z1) = supz1\u2208conv(Z) A(z1). We derive:\nR2 = inf f1\u2208F sup z1\u2208conv(Z) [ \u2113(z1, f1)+ sup p2\u2208P(conv(Z)) { inf f2\u2208F Ez\u223cp2\u2113(z, f2)\u2212Ez2\u223cp2 inf f\u2208F\n2 \u2211\nt=1\n\u2113(zt, f)}].\nTo conclude, we unwind the first step, i.e. we use the minimax theorem in reverse order. This yields:\nR2 = inf f1\u2208F sup z1\u2208conv(Z) inf f2\u2208F sup z2\u2208conv(Z) [\n2 \u2211\nt=1\n\u2113(zt, ft)\u2212 inf f\u2208F\n2 \u2211\nt=1\n\u2113(zt, f) ],\ni.e. R2(\u2113(z, f) = zTf,Z,F) = R2(\u2113(z, f) = zTf, conv(Z),F). Moreover, Z is a compact set which implies that conv(Z) is also a compact set by a standard topological argument. As a result, the game (\u2113(z, f) = zTf, conv(Z),F) also satisfies Assumption 1."}, {"heading": "4.3 Proof of Lemma 2", "text": "We follow the analysis of Theorem 19 of [2]. Using Theorem 1 with p taken as the distribution of i.i.d. copies of Z , we get the lower bound:\nRT \u2265 T inf f\u2208F E[\u2113(Zt, f)]\u2212 E[ inf f\u2208F\nT \u2211\nt=1\n\u2113(Zt, f)]\n\u2265 T sup f\u2208{f1,f2} E[\u2113(Zt, f)]\u2212 E[ inf f\u2208{f1,f2}\nT \u2211\nt=1\n\u2113(Zt, f)]\n\u2265 E[max{ T \u2211\nt=1\nE[\u2113(Zt, f1)]\u2212 \u2113(Zt, f1), T \u2211\nt=1\nE[\u2113(Zt, f2)]\u2212 \u2113(Zt, f2)}]\n\u2265 E[max{0, T \u2211\nt=1\n\u2113(Zt, f1)\u2212 \u2113(Zt, f2)}],\nwhere we use the fact that inff\u2208F E[\u2113(Zt, f)] = E[\u2113(Zt, f1)] = E[\u2113(Zt, f2)]. Since \u2113(Z, f2) 6= \u2113(Z, f1) with positive probability, the random variables (\u2113(Zt, f1) \u2212 \u2113(Zt, f2))t=1,\u00b7\u00b7\u00b7 ,T are i.i.d. with zero mean and positive variance and we can conclude with the central limit theorem since \u2113 is bounded."}, {"heading": "4.4 Proof of Lemma 3", "text": "The fact that RT \u2265 0 is proved in Lemma 3 of [2] and follows from Theorem 1 by taking the Zt\u2019s to be deterministic and all equal to any z \u2208 Z . Clearly, if the game is trivial then RT = 0 because this value is attained for f1, \u00b7 \u00b7 \u00b7 , fT = f\u2217 irrespective of the decisions made by the opponent. Conversely, suppose RT = 0. Consider p to be the product of T uniform distributions on Z . Then, using again Theorem 1:\n0 \u2265 E[ T \u2211\nt=1\ninf ft\u2208F E[\u2113(Zt, ft)]\u2212 inf f\u2208F\nT \u2211\nt=1\n\u2113(Zt, f) ],\nas Z1, \u00b7 \u00b7 \u00b7 , ZT are independent random variables. Since they are also identically distributed, we obtain:\n0 \u2265 T \u00b7 inf f\u2208F E[\u2113(Z, f)]\u2212 E[ inf f\u2208F\nT \u2211\nt=1\n\u2113(Zt, f)].\nYet E[ inf f\u2208F\n\u2211T t=1 \u2113(Zt, f)] \u2264 inf f\u2208F E[ \u2211T t=1 \u2113(Zt, f)] = T \u00b7 inf f\u2208F E[\u2113(Z, f)] and we derive:\nT \u00b7 inf f\u2208F E[\u2113(Z, f)]\u2212 E[ inf f\u2208F\nT \u2211\nt=1\n\u2113(Zt, f)] = 0.\nSince \u2113 is bounded, Z is compact, and \u2113(z, \u00b7) is continuous for any z \u2208 Z , f \u2192 E[\u2113(Z, f)] is continuous by dominated convergence so we can take f\u2217 \u2208 argminf\u2208F E[\u2113(Z, f)] (F is compact). We obtain:\nE[\nT \u2211\nt=1\n\u2113(Zt, f \u2217)\u2212 inf\nf\u2208F\nT \u2211\nt=1\n\u2113(Zt, f)] = 0.\nAs \u2211T t=1 \u2113(Zt, f \u2217)\u2212 inf\nf\u2208F\n\u2211T t=1 \u2113(Zt, f) \u2265 0, we derive that:\n(z1, \u00b7 \u00b7 \u00b7 , zT ) \u2192 T \u2211\nt=1\n\u2113(zt, f \u2217)\u2212 inf\nf\u2208F\nT \u2211\nt=1\n\u2113(zt, f) = 0\nalmost everywhere on ZT . If Z is discrete, this implies equality on ZT , which in particular implies \u2113(z, f\u2217) = inf\nf\u2208F \u2113(z, f) for all z \u2208 Z and we are done. If, on the other hand, \u2113(\u00b7, f) is continuous for\nall f \u2208 F , we have: T \u2211\nt=1\n\u2113(zt, f \u2217) \u2264\nT \u2211\nt=1\n\u2113(zt, f), \u2200f \u2208 F , \u2200(z1, \u00b7 \u00b7 \u00b7 , zT ) \u2208 Z\u0303,\nfor Z\u0303 a subset of Z with Lebesgue measure equal to that of Z . Since a non-empty open set cannot have Lebesgue measure 0, Z\u0303 is dense in Z and by taking limits in the above inequality for each f \u2208 F separately, we conclude that:\nT \u2211\nt=1\n\u2113(zt, f \u2217) \u2264\nT \u2211\nt=1\n\u2113(zt, f), \u2200f \u2208 F , \u2200(z1, \u00b7 \u00b7 \u00b7 , zT ) \u2208 Z,\nwhich in particular implies that \u2113(z, f\u2217) = inf f\u2208F \u2113(z, f) for all z \u2208 Z and the game is trivial."}, {"heading": "4.5 Proof of Lemma 4", "text": "Suppose by contradiction that we cannot find such a finite subset. Since Z is compact, it is also separable thus it contains a countable dense subset {zn | n \u2208 N}. By assumption, the game (\u2113, {zk | k \u2264 n},F) must be trivial for any n, i.e. there exists fn \u2208 F such that:\n\u2113(zk, fn) \u2264 min f\u2208F \u2113(z, f), \u2200k \u2264 n.\nSince F is compact, we can find a subsequence of (fn)n\u2208N such that fn \u2192 f\u2217 \u2208 F . Without loss of generality, we continue to refer to this sequence as (fn)n\u2208N. Taking the limit n \u2192 \u221e in the above inequality for any fixed k \u2208 N yields:\n\u2113(zk, f \u2217) \u2264 \u2113(zk, f), \u2200f \u2208 F , \u2200k \u2208 N.\nConsider a fixed f \u2208 F , since {zn | n \u2208 N} is dense in Z and since \u2113(\u00b7, f\u2217) and \u2113(\u00b7, f) are continuous, we get: \u2113(z, f\u2217) \u2264 \u2113(z, f), \u2200f \u2208 F , \u2200z \u2208 Z, which shows that (\u2113,Z,F) is trivial, a contradiction."}, {"heading": "4.6 Proof of Theorem 2", "text": "Without loss of generality we can assume that the game is not trivial and that X (z) is finite for any z \u2208 Z since otherwise if X (z) is a polyhedron, the maximum in (2) must be attained at an extreme point of X (z) (\u2113 is bounded by Assumption 1) and there are finitely many such points for any z. Moreover, we can also assume that Z is discrete by Lemma 4 since, borrowing the notations of Lemma 4, we have: RT (\u2113,Z,F) \u2265 RT (\u2113, Z\u0303,F). Write Z = {zn | n \u2264 N} and denote by p0 the uniform distribution on Z , i.e. p0 = 1 N \u2211N n=1 \u03b4zn , where \u03b4zn is the Dirac distribution supported at zn. We may assume that there is a single equivalence class in argminf\u2208F Ep0 [\u2113(Z, f)], otherwise we are done by Lemma 2. Take f\u2217 \u2208 argminf\u2208F Ep0 [\u2113(Z, f)]. Since the game (\u2113,Z,F) is not trivial, there exists zk in Z and f\u2217\u2217 in F such that \u2113(zk, f\u2217\u2217) < \u2113(zk, f\u2217). Therefore, we can find \u01eb > 0 small enough such that (N \u2212 1)\u01eb < 1 and:\n(1\u2212 (N \u2212 1)\u01eb)\u2113(zk, f\u2217\u2217) + \u2211\nn6=k \u01eb\u2113(zn, f\n\u2217\u2217) < (1\u2212 (N \u2212 1)\u01eb)\u2113(zk, f\u2217) + \u2211\nn6=k \u01eb\u2113(zn, f\n\u2217).\nDefine p1 as the corresponding distribution, i.e. p1 = (1 \u2212 (N \u2212 1)\u01eb)\u03b4zk + \u01eb \u2211\nn6=k \u03b4zn . By construction, the equivalence class of f\u2217 is not in argminf\u2208F Ep1 [\u2113(Z, f)]. Once again, without loss of generality, we may assume that there is a single equivalence class in argminf\u2208F Ep1 [\u2113(Z, f)], otherwise we are done by Lemma 2. Moreover, we can now redefine f\u2217\u2217 as a representative of the only equivalence class contained in argminf\u2208F Ep1 [\u2113(Z, f)]. We now move on to show that there must exist \u03b1 \u2208 (0, 1) such that there are at least two equivalence classes in argminf\u2208F Ep\u03b1 [\u2113(Z, f)],\nwhere the distribution p\u03b1 is defined as p\u03b1 = (1 \u2212 \u03b1)p0 + \u03b1p1. Observe that minf\u2208F Ep\u03b1 [\u2113(Z, f)] can be written as the linear program:\nmin q1,\u00b7\u00b7\u00b7 ,qN ,f\nq \u00b7 ((1 \u2212 \u03b1)x0 + \u03b1x1)\nsubject to q = (q1, \u00b7 \u00b7 \u00b7 , qN ) qn \u2265 (C(zn)f + c(zn))Tx \u2200x \u2208 X (zn), \u2200n = 1, \u00b7 \u00b7 \u00b7 , N f \u2208 F , q1, \u00b7 \u00b7 \u00b7 , qN \u2208 R\n(3)\nwhere x0 and x1 are vectors of size N defined as follows:\nx0 = 1\nN (1, \u00b7 \u00b7 \u00b7 , 1)\nand x1 = (1\u2212 (N \u2212 1)\u01eb)(0, \u00b7 \u00b7 \u00b7 , 0, 1, 0, \u00b7 \u00b7 \u00b7 ) + \u01eb(1, \u00b7 \u00b7 \u00b7 , 1, 0, 1, \u00b7 \u00b7 \u00b7 , 1), i.e. all the components of x1 are equal to \u01eb except for the kth one which is equal to (1\u2212 (N \u2212 1)\u01eb). We are interested in the function \u03c6 : \u03b1 \u2192 argminf\u2208F Ep\u03b1 [\u2113(Z, f)]. For any f \u2208 F , define I(f) = {\u03b1 \u2208 [0, 1] | f \u2208 \u03c6(\u03b1)}. Since \u03b1 \u2192 Ep\u03b1 [\u2113(Z, f)] is linear in \u03b1, I(f) = {\u03b1 \u2208 [0, 1] | f \u2208 \u03c6(\u03b1)} is a closed interval in [0, 1] for any f \u2208 F . Moreover, F being a polyhedron, the feasible set of (3) is also a polyhedron, hence it has a finitely many extreme points. We denote by {f1, \u00b7 \u00b7 \u00b7 , fL} the projection of the set of extreme points onto the f coordinate. Since (3) is a linear program, this shows that, for any \u03b1 \u2208 [0, 1], there exists l \u2208 {1, \u00b7 \u00b7 \u00b7 , L} such that fl \u2208 \u03c6(\u03b1). Therefore, we can write [0, 1] = \u222aLl=1I(fl). We can further simplify this description by assuming that the fl\u2019s belong to different equivalence classes (because I(f) = I(f \u2032) if f is equivalent to f \u2032). Now observe that if I(fl) \u2229 I(fj) 6= \u2205 for all any l 6= j \u2264 K , then there are two classes of equivalence in argminf\u2208F Ep\u03b1 [\u2113(Z, f)] for any \u03b1 \u2208 I(fl) \u2229 I(fj) and we are done. Suppose by contradiction that we cannot find such a pair of indices. Because the only way to partition [0, 1] into L < \u221e non-overlapping closed intervals is to have L = 1, we get [0, 1] = I(f1). This implies that f\u2217 and f\u2217\u2217 belong to the same equivalence class, a contradiction."}, {"heading": "4.7 Alternative proof of Theorem 2 by exhibiting an equalizing strategy when \u2113 is linear", "text": "Using Lemma 1, we can assume without loss of generality that Z is convex. When \u2113 is linear, the procedure developed in the proof of Theorem 2 boils down to finding a point z \u2208 int(Z) such that | argminf\u2208F zTf | > 1 and, with further examination, we can also guarantee that there exists \u01eb > 0, e \u2208 Rn and f1, f2 \u2208 argminf\u2208F zTf such that f1 \u2208 argminf\u2208F(z \u2212 xe)Tf while f2 /\u2208 argminf\u2208F(z \u2212 xe)Tf for all x \u2208 (0, \u01eb] and symmetrically for x \u2208 [\u2212\u01eb, 0). Consider a randomized opponentZt = z+(\u01ebt\u01eb)e for (\u01ebt)t=1,\u00b7\u00b7\u00b7 ,T i.i.d. Rademacher random variables. Then for any player\u2019s strategy:\nE[rT ((Zt)t=1,\u00b7\u00b7\u00b7 ,T , (ft)t=1,\u00b7\u00b7\u00b7 ,T )] = T \u2211\nt=1\nE[Zt] Tft \u2212 E[ inf f\u2208F f T\nT \u2211\nt=1\nZt].\nThis yields:\nE[rT ((Zt)t=1,\u00b7\u00b7\u00b7 ,T , (ft)t=1,\u00b7\u00b7\u00b7 ,T )] = T \u2211\nt=1\nzTft \u2212 E[ inf f\u2208F\nf T T \u2211\nt=1\nZt].\nWe can lower bound the last quantity by:\nE[rT ((Zt)t=1,\u00b7\u00b7\u00b7 ,T , (ft)t=1,\u00b7\u00b7\u00b7 ,T )] \u2265 T (zTf1)\u2212 TE[ inf f\u2208F\nf T(z + (\u01eb \u00b7 \u2211T\nt=1 \u01ebt T )e)],\nas f1 \u2208 argminf\u2208F zTf , but we could have equivalently picked f2 as f T1z = f T2z. Furthermore, as | \u2211 T t=1\n\u01ebt T | \u2264 1, f1 is optimal in the inner optimization problem when \u2211T t=1 \u01ebt \u2264 0 while f2 is optimal when\n\u2211T t=1 \u01ebt \u2265 0. Hence:\nE[rT ((Zt)t=1,\u00b7\u00b7\u00b7 ,T , (ft)t=1,\u00b7\u00b7\u00b7 ,T )] \u2265 T (zTf1)\u2212 TE[ f T1 (z + (\u01eb \u00b7 \u2211T t=1 \u01ebt T )e) \u00b7 1\u2211T t=1 \u01ebt\u22640+\nf T2 (z + (\u01eb \u00b7 \u2211T t=1 \u01ebt T )e) \u00b7 1\u2211T t=1 \u01ebt\u22650 ].\nObserve that the term T (zTf1) cancels out and we get:\nE[rT ((Zt)t=1,\u00b7\u00b7\u00b7 ,T , (ft)t=1,\u00b7\u00b7\u00b7 ,T )] \u2265 E[|\u2211t=1 \u01ebt|]\nT \u00b7 \u01eb \u00b7 (f T1e\u2212 f T2e).\nBy Khintchine\u2019s inequality E[|\u2211Tt=1 \u01ebt|] \u2265 1\u221a2 \u221a T . Moreover f T1e \u2212 f T2e > 0 because f2 \u2208 argminf\u2208F(z + \u01ebe) Tf while f1 does not and f T1z = f T 2z. We finally derive\nE[rT ((Zt)t=1,\u00b7\u00b7\u00b7 ,T , (ft)t=1,\u00b7\u00b7\u00b7 ,T )] \u2265 (f T1e\u2212 f T2e)\u221a\n2\n\u221a T .\nThis enables us to conclude RT = \u2126( \u221a T ) as this shows that for any player\u2019s strategy, there exists a sequence z1, \u00b7 \u00b7 \u00b7 , zT such that rT ((zt)t=1,\u00b7\u00b7\u00b7 ,T , (ft)t=1,\u00b7\u00b7\u00b7 ,T ) \u2265 E[rT ((Zt)t=1,\u00b7\u00b7\u00b7 ,T , (ft)t=1,\u00b7\u00b7\u00b7 ,T )]."}, {"heading": "4.8 Proof of Theorem 3", "text": "Straightforward from Theorem 2 since \u2113 is jointly continuous."}, {"heading": "4.9 Proof of Lemma 5", "text": "Using Lemma 1, we can assume that Z is convex. Consider f1 6= f2 \u2208 F and define e = f1\u2212f2\u2016f1\u2212f2\u2016 . Since 0 \u2208 int(Z), there exists \u01eb > 0 such that \u01ebe and \u2212\u01ebe are in Z . We restrict the opponent\u2019s decision set by imposing that, at any round t, the opponent\u2019s move be yt\u01ebe for yt \u2208 Z\u0303 = {\u22121, 1}. Since \u2113(yt\u01ebe, f) only depends on f through the scalar product between f and e, the player\u2019s decision set can equivalently be described by F\u0303 = {f Te | f \u2208 F} which is a closed interval (since F is convex and compact) and thus a polyhedron. Defining a new loss function as \u2113\u0303(y, f) = y\u01ebf , we have: RT (\u2113,Z,F) \u2265 RT (\u2113\u0303, Z\u0303, F\u0303). Observe that the game (\u2113\u0303, Z\u0303, F\u0303) is linear and not trivial, otherwise there would exist f\u2217 such that eTf\u2217 \u2264 eTf2 and \u2212eTf\u2217 \u2264 \u2212eTf1 which would imply \u2016e\u2016 = 0. With Theorem 3, we conclude RT (\u2113\u0303, Z\u0303, F\u0303) = \u2126( \u221a T ) and thus RT (\u2113,Z,F) = \u2126( \u221a T )."}, {"heading": "4.10 Proof of Theorem 4", "text": "A common inequality on the regret incurred for the FTL strategy is:\nrT ((zt)t=1,\u00b7\u00b7\u00b7 ,T , (ft)t=1,\u00b7\u00b7\u00b7 ,T ) \u2264 T \u2211\nt=1\nzTt (ft \u2212 ft+1),\nWe use sensitivity analysis to control this last quantity. Specifically we show that the mapping \u03c6 : z \u2192 argminf,F (f)=0 zTf is Lipschitz on Z . Using this property:\nrT ((zt)t=1,\u00b7\u00b7\u00b7 ,T , (ft)t=1,\u00b7\u00b7\u00b7 ,T ) \u2264 T \u2211\nt=1\n\u2016zt\u2016 \u2016ft \u2212 ft+1\u2016\n= O(\nT \u2211\nt=1\n\u2225 \u2225 \u2225 \u2225 \u2225 1 t\u2212 1 t\u22121 \u2211\n\u03c4=1\nz\u03c4 \u2212 1\nt\nt \u2211\n\u03c4=1\nz\u03c4\n\u2225 \u2225 \u2225 \u2225 \u2225 )\n= O(\nT \u2211\nt=1\n\u2225 \u2225 \u2225 \u2225 \u2225 1 t(t\u2212 1) t\u22121 \u2211\n\u03c4=1\nz\u03c4 \u2212 1\nt zt\n\u2225 \u2225 \u2225 \u2225 \u2225 )\n= O( T \u2211\nt=1\n1\nt(t\u2212 1)\n\u2225 \u2225 \u2225 \u2225 \u2225 t\u22121 \u2211\n\u03c4=1\nz\u03c4\n\u2225 \u2225 \u2225 \u2225 \u2225 + 1 t \u2016zt\u2016)\n= O(\nT \u2211\nt=1\n1 t )\n= O(log(T )),\nsince Z is compact. We now move on to show that \u03c6 is Lipschitz. As conv(Z) is closed and convex, we can strictly separate 0 from conv(Z). Hence, there exists a 6= 0 \u2208 Rd and c > 0 such that a \u00b7 z > c, \u2200z \u2208 Z . We get \u2016z\u2016 \u2265 c\u2016a\u2016 > 0 \u2200z \u2208 Z . Let us use the shorthand C = c\u2016a\u2016 . Take (z1, z2) \u2208 Z2 and (f(z1), f(z2)) \u2208 \u03c6(z1) \u00d7 \u03c6(z2). Observe that the constraint qualifications are automatically satisfied at f(z1) and f(z2) as \u2207F cannot vanish on {f | F (f) = 0} since F does cannot attain its minimum on this set (F is assumed to contain at least two points). Hence, there exist \u03bb1, \u03bb2 \u2265 0 such that z1 + \u03bb1\u2207F (f(z1)) = 0 and z2 + \u03bb2\u2207F (f(z2)) = 0. As z1, z2 6= 0, we must have \u03bb1, \u03bb2 6= 0. We obtain \u2207F (f1) = \u2212 1\u03bb1 z1 and \u2207F (f(z2)) = \u2212 1 \u03bb2 z2. Since F is strongly convex, there exists \u03b2 > 0 such that:\n(\u2207F (f \u2032)\u2212\u2207F (f \u2032\u2032))T(f \u2032 \u2212 f \u2032\u2032) \u2265 \u03b2 \u2016f \u2032 \u2212 f \u2032\u2032\u20162 , for all f \u2032, f \u2032\u2032 \u2208 F . Applying this inequality for f \u2032 = f(z1) and f \u2032\u2032 = f(z2), we obtain:\n( 1\n\u03bb2 z2 \u2212\n1\n\u03bb1 z1)\nT(f(z1)\u2212 f(z2)) \u2265 \u03b2 \u2016f(z1)\u2212 f(z2)\u20162 .\nWe can break down the last expression in two pieces:\n1\n\u03bb2 zT2(f(z1)\u2212 f(z2)) +\n1\n\u03bb1 zT1(f(z2)\u2212 f(z1)) \u2265 \u03b2 \u2016f(z1)\u2212 f(z2)\u20162 .\nObserve that zT2(f(z1) \u2212 f(z2)) \u2265 0 since both f(z1) and f(z2) belong to F and since f(z2) is the minimizer of zT2f for f ranging in F . Symmetrically, zT1(f(z2) \u2212 f(z1)) \u2265 0. Note that 1 \u03bb1 = 1|\u03bb1| = \u2016\u2207F (f(z1))\u2016\n\u2016z1\u2016 . As \u2207F is continuous and F is compact, there exists K > 0 such that \u2016\u2207F (f)\u2016 \u2264 K for any f \u2208 F . Hence, we get 1\n\u03bb1 \u2264 K C and the same inequality holds for \u03bb2.\nPlugging this upper bound back into the last inequality yields:\nK C (z2 \u2212 z1)T(f(z1)\u2212 f(z2)) \u2265 \u03b2\u2016f(z1)\u2212 f(z2)\u20162.\nUsing the Cauchy-Schwarz inequality and simplifying on both sides by \u2016f(z2)\u2212 f(z1)\u2016 yields: K\n\u03b2C \u2016z2 \u2212 z1\u2016 \u2265 \u2016f(z1)\u2212 f(z2)\u2016,\ni.e. K \u03b2C \u2016z2 \u2212 z1\u2016 \u2265 \u2016\u03c6(z1)\u2212 \u03c6(z2)\u2016."}, {"heading": "4.11 Proof of Lemma 6", "text": "Using Lemma 1, we can assume that Z is convex. Since Z is compact and convex and since 0 /\u2208 Z , we can strictly separate 0 from Z and find z\u2217 6= 0 such that Z \u2286 B2(z\u2217, \u03b1 \u2016z\u2217\u2016) with \u03b1 < 1. By rescaling Z , we can assume that \u03b1 \u2016z\u2217\u2016 = 1 and \u2016z\u2217\u2016 > 1. In the sequel, \u03c3t\u22121 serves as a shorthand for \u03c3(Z1, \u00b7 \u00b7 \u00b7 , Zt\u22121). We prove more generally that, for any choice of random variables (Z1, \u00b7 \u00b7 \u00b7 , ZT ) such that E[Zt|\u03c3t\u22121] is constant almost surely, the lower bound on regret derived from Theorem 1 is O(1). Write Zt = z\u2217+Wt and E[Wt|\u03c3t\u22121] = ct with \u2016Wt\u2016 \u2264 1 and \u2016ct\u2016 \u2264 1. Define w\u2217 = T \u00b7 z\u2217 +\u2211Tt=1 ct. Observe that \u2016w\u2217\u2016 \u2265 T \u00b7 \u2016z\u2217\u2016 \u2212 \u2016 \u2211T t=1 ct\u2016 \u2265 T \u00b7 (\u2016z\u2217\u2016 \u2212 1) > 0. Write Wt = Xt w\u2217\n\u2016w\u2217\u2016 + W\u0303t + ct with W\u0303 T t w \u2217 = 0. Projecting down the equality E[Wt \u2212 ct|\u03c3t\u22121] = 0 onto\nw\u2217, we get E[Xt|\u03c3t\u22121] = 0 and E[W\u0303t|\u03c3t\u22121] = 0. The bound that results from an application of Theorem 1 is:\nRT \u2265 E[\u2016w\u2217 + T \u2211\nt=1\nWt \u2212 ct\u2016]\u2212 T \u2211\nt=1\n\u2016z\u2217 + ct\u2016].\nWe now focus on finding an upper bound on the right-hand side. Expanding the first term yields:\n\u2016w\u2217 + T \u2211\nt=1\nWt \u2212 ct\u2016 =\n\u221a \u221a \u221a \u221a(1 + T \u2211\nt=1\nXt \u2016w\u2217\u2016)\n2 \u00b7 \u2016w\u2217\u20162 + \u2016 T \u2211\nt=1\nW\u0303t\u20162.\nBy concavity of the squared root function:\nE[\u2016w\u2217 + T \u2211\nt=1\nWt \u2212 ct\u2016] \u2264\n\u221a \u221a \u221a\n\u221a\u2016w\u2217\u20162 \u00b7 E[(1 + T \u2211\nt=1\nXt \u2016w\u2217\u2016)\n2] + E[\u2016 T \u2211\nt=1\nW\u0303t\u20162].\nWe expand the two inner terms:\nE[(1 +\nT \u2211\nt=1\nXt \u2016w\u2217\u2016 ) 2] = 1 + 2\nT \u2211\nt=1\nE[Xt] \u2016w\u2217\u2016 + 1 \u2016w\u2217\u20162 \u00b7 E[( T \u2211\nt=1\nXt) 2].\nLooking at each term individually, we have E[Xt] = E[E[Xt|\u03c3t\u22121] = 0 and E[( \u2211T t=1 Xt) 2] = E[( \u2211T\u22121\nt=1 Xt) 2] + 2E[XT \u00b7 ( \u2211T\u22121 t=1 Xt)] + E[X 2 T ], yet E[XT \u00b7 ( \u2211T\u22121 t=1 Xt)] = E[E[XT |\u03c3T\u22121] \u00b7\n( \u2211T\u22121 t=1 Xt)] = 0. Hence, E[(1 + \u2211T t=1 Xt \u2016w\u2217\u2016 ) 2] = 1 +\nE[ \u2211\nT t=1 X 2 t ]\n\u2016w\u2217\u20162 . Similarly E[\u2016 \u2211T t=1 W\u0303t\u20162] = \u2211T\nt=1 E[\u2016W\u0303t\u20162]. We obtain:\nE[\u2016w\u2217 + T \u2211\nt=1\nWt \u2212 ct\u2016] \u2264\n\u221a \u221a \u221a\n\u221a\u2016w\u2217\u20162 + T \u2211\nt=1\nE[X2t + \u2016W\u0303t\u20162].\nRemark that \u2016Wt \u2212 ct\u2016 \u2264 \u2016Wt\u2016+ \u2016ct\u2016 \u2264 2. Hence, X2t + \u2016W\u0303t\u20162 \u2264 2. We obtain:\nE[\u2016w\u2217 + T \u2211\nt=1\nWt \u2212 ct\u2016] \u2264 \u221a \u2016w\u2217\u20162 + 2T .\nWe have \u221a \u2016w\u2217\u20162 + 2T = \u2016w\u2217\u2016 \u00b7 \u221a\n1 + 2T\u2016w\u2217\u20162 \u2264 \u2016w\u2217\u2016 + T\u2016w\u2217\u2016 for T big enough as \u2016w\u2217\u2016 \u2265 T \u00b7 (\u2016z\u2217\u2016 \u2212 1). Yet \u2016w\u2217\u2016 = \u2016\u2211Tt=1 z\u2217 + ct\u2016 \u2264 \u2211T t=1 \u2016z\u2217 + ct\u2016. Hence, the lower bound derived is:\nE[\u2016w\u2217 + T \u2211\nt=1\nWt \u2212 ct\u2016]\u2212 T \u2211\nt=1\n\u2016z\u2217 + ct\u2016 \u2264 T \u2016w\u2217\u2016 \u2264 1 \u2016z\u2217\u2016 \u2212 1 = O(1)."}, {"heading": "4.12 Proof of Theorem 5", "text": "Since Z has non-empty interior, we can find z\u2217 6= 0 and \u03b1 \u2208 (0, 132 ] such that B2(z\u2217, \u03b1 \u2016z\u2217\u2016) \u2286 Z . Define e as a unit vector orthogonal to z\u2217 and Z\u0303 = {z |z = z\u2217 + (w\u03b1 \u2016z\u2217\u2016)e, |w| \u2264 1}. Since Z\u0303 \u2286 Z , we have:\nRT (\u2113,Z,F) \u2265 RT (\u2113, Z\u0303,F),\nand we can focus on developing a \u2126(log(T )) lower bound on regret for the game (\u2113, Z\u0303,F). Using the minimax reformulation of Theorem 1, we have:\nRT (\u2113, Z\u0303,F)\n= sup p E\n[\n\u2212 T \u2211\nt=1\n\u2016z\u2217 + (\u03b1 \u2016z\u2217\u2016E[Wt|W1, \u00b7 \u00b7 \u00b7 ,Wt\u22121])e\u2016+ \u2225 \u2225 \u2225 \u2225\n\u2225\nTz\u2217 + (\u03b1 \u2016z\u2217\u2016 T \u2211\nt=1\nWt)e\n\u2225 \u2225 \u2225 \u2225 \u2225 ]\n= sup p E\n  \u2212 T \u2211\nt=1\n\u221a\n\u2016z\u2217\u20162 + (\u03b1 \u2016z\u2217\u2016E[Wt|W1, \u00b7 \u00b7 \u00b7 ,Wt\u22121])2 +\n\u221a \u221a \u221a\n\u221aT 2 \u2016z\u2217\u20162 + (\u03b1 \u2016z\u2217\u2016 T \u2211\nt=1\nWt)2\n\n\nwhere the supremum is taken over the distribution p of the random variable (W1, \u00b7 \u00b7 \u00b7 ,WT ) in [\u22121, 1]T . Rearranging this expression yields:\nRT (\u2113, Z\u0303,F) = \u2016z\u2217\u2016 sup p E\n\n T\n\u221a\n1 + (\u03b1 \u2211T t=1 Wt T )2 \u2212 T \u2211\nt=1\n\u221a 1 + (\u03b1E[Wt|W1, \u00b7 \u00b7 \u00b7 ,Wt\u22121])2  \n= \u2016z\u2217\u2016 sup p {E[ T (1 +\n\u221e \u2211\nn=1\n(1 2\nn\n)\n\u03b12n( \u2211T t=1 Wt T )2n)\n\u2212 T \u2211\nt=1\n(1 +\n\u221e \u2211\nn=1\n( 1 2\nn\n)\n\u03b12nE[Wt|W1, \u00b7 \u00b7 \u00b7 ,Wt\u22121]2n)]}\n= \u2016z\u2217\u2016 sup p {\u03b1\n2\n2 E\n[\n( \u2211T t=1 Wt) 2\nT \u2212\nT \u2211\nt=1\nE[Wt|W1, \u00b7 \u00b7 \u00b7 ,Wt\u22121]2 ]\n+ \u221e \u2211\nn=2\n(1 2\nn\n)\n\u03b12nE\n[\n( \u2211T t=1 Wt) 2n\nT 2n\u22121 \u2212\nT \u2211\nt=1\nE[Wt|W1, \u00b7 \u00b7 \u00b7 ,Wt\u22121]2n ] },\nwhere the second equality results from a series expansion (valid since (\u03b1E[Wt|W1, \u00b7 \u00b7 \u00b7 ,Wt\u22121])2, (\u03b1 \u2211T t=1 Wt T )2 \u2264 \u03b12 < 1) and the third inequality is derived from Fubini, observing that: \u221e \u2211\nn=1\n| (1 2\nn\n) |\u03b12nE[( \u2211T\nt=1 Wt T\n)2n] \u2264 \u221e \u2211\nn=1\n\u03b12n = 1\n1\u2212 \u03b12 < \u221e\nand similarly: \u221e \u2211\nn=1\n| ( 1 2\nn\n) |\u03b12nE[E[Wt|W1, \u00b7 \u00b7 \u00b7 ,Wt\u22121]2n] \u2264 \u221e \u2211\nn=1\n\u03b12n = 1\n1\u2212 \u03b12 < \u221e.\nInterestingly, the first-order term of this series expansion, i.e.\nE\n[\n( \u2211T t=1 Wt) 2\nT \u2212\nT \u2211\nt=1\nE[Wt|W1, \u00b7 \u00b7 \u00b7 ,Wt\u22121]2 ] ,\nis precisely the expression of the minimax regret for the game (\u2113(z, f) = (z \u2212 f)2, [\u22121, 1], [\u22121, 1]) which is known to have optimal regret\u0398(log(T )), see Section 7.3 of [2]. This motivates the introduction of the probability distribution p used in [2] to establish the \u2126(log(T )) lower bound. Specifically, we use the conditional distributions:\npt(Wt = w|W1, \u00b7 \u00b7 \u00b7 ,Wt\u22121) = { 1+ctW1:t\u22121 2 if w = 1 1\u2212ctW1:t\u22121\n2 if w = \u22121 t = 2, \u00b7 \u00b7 \u00b7 , T\nwhere W1:t\u22121 = \u2211t\u22121 \u03c4=1 W\u03c4 and the sequence (ct)t=1,\u00b7\u00b7\u00b7 ,T is recursively defined as:\ncT = 1\nT\nct\u22121 = ct + c 2 t t = T, \u00b7 \u00b7 \u00b7 , 2.\nTogether with W1 taken as a Rademacher random variable, these conditional distributions define a joint distribution p as it can be shown that ct \u2208 [0, 1t ]. Abernethy et al. [2] show that:\nE\n[\n( \u2211T t=1 Wt) 2\nT \u2212\nT \u2211\nt=1\nE[Wt|W1, \u00b7 \u00b7 \u00b7 ,Wt\u22121]2 ] = log(T ) +O(log log(T )). (4)\nHence, it remains to control the terms of order n \u2265 2 in the series expansion. First observe that, by definition:\nE[W 2n1:T ] = E[E[W 2n 1:T |W1, \u00b7 \u00b7 \u00b7 ,WT\u22121]]\n= E[ 1 + ctW1:T\u22121\n2 (W1:T\u22121 + 1)\n2n + 1\u2212 ctW1:T\u22121\n2 (W1:T\u22121 + 1)\n2n]\n= 1 +\nn \u2211\nk=1\n(\n(\n2n\n2k\n)\n+\n(\n2n\n2k \u2212 1\n)\ncT )E[(W1:T\u22121) 2k],\nwhich implies that:\n|c2n\u22121T E[W 2n1:T ]\u2212 (c2n\u22121T + 2nc2nT )E[W 2n1:T\u22121]| \u2264 ( 2n\n2(n\u2212 1)\n)\ncT + 2\nn \u2211\nk=0\n(\n2n\n2k\n)\nc2T\n\u2264 2n2cT + 24nc2T , (5)\nsince cT |W1:T\u22121| \u2264 1. Additionally, we have, using the recursive definition of the sequence (ct)t=1,\u00b7\u00b7\u00b7 ,T :\nc2n\u22121T\u22121 = (cT + c 2 T ) 2n\u22121\n=\n2n\u22121 \u2211\nk=0\n( 2n\u2212 1 k ) c2n\u22121+kT ,\nwhich implies:\n|c2n\u22121T\u22121 \u2212 (c2n\u22121T + (2n\u2212 1)c2nT )| \u2264 2n2c2n+1T + 4nc2n+2T . (6)\nUsing E[WT |W1, \u00b7 \u00b7 \u00b7 ,WT\u22121] = cTW1:T\u22121, we get:\n|E[c2n\u22121T W 2n1:T\u2212 T \u2211\nt=1\nE[Wt|W1, \u00b7 \u00b7 \u00b7 ,Wt\u22121]2n]|\n\u2264 |E[(c2n\u22121T + 2(n\u2212 1)c2nT )W 2n1:T\u22121]\u2212 T\u22121 \u2211\nt=1\nE[Wt|W1, \u00b7 \u00b7 \u00b7 ,Wt\u22121]2n]|\n+ 2n2cT + 24 nc2T \u2264 |E[c2n\u22121T\u22121 W 2n1:T\u22121 \u2212 T\u22121 \u2211\nt=1\nE[Wt|W1, \u00b7 \u00b7 \u00b7 ,Wt\u22121]2n]|\n+ (2n2c2n+1T + 4 nc2n+2T )E[W 2n 1:T\u22121] + 2n 2cT + 24 nc2T \u2264 4n2cT + 34nc2T \u2264 4n2 1\nT + 34n\n1\nT 2 ,\nwhere the first (resp. second) inequality is obtained by applying (5) (resp. (6)) and the fifth inequality is derived using cT \u2208 [0, 1T ] and |W1:T\u22121| \u2264 T \u2212 1. By induction on t, we get:\n|E [\nc2n\u22121T W 2n 1:T \u2212\nT \u2211\nt=1\nE[Wt|W1, \u00b7 \u00b7 \u00b7 ,Wt\u22121]2n ] | \u2264 4n2 T \u2211\nt=1\n1 t + 34n\nT \u2211\nt=1\n1\nt2\n\u2264 4n2 log(T ) + 4n\u03c0 2\n2 .\nBringing everything together, we derive:\n| \u221e \u2211\nn=2\n(1 2\nn\n)\n\u03b12nE\n[\n( \u2211T t=1 Wt) 2n\nT 2n\u22121 \u2212\nT \u2211\nt=1\nE[Wt|W1, \u00b7 \u00b7 \u00b7 ,Wt\u22121]2n ] |\n\u2264 4( \u221e \u2211\nn=2\n(1 2\nn\n)\n\u03b12nn2) log(T )\n+ (\n\u221e \u2211\nn=2\n(1 2\nn\n)\n(2\u03b1)2n) \u03c02\n2\n\u2264 8\u03b14( \u221e \u2211\nn=2\nn(n\u2212 1)(\u03b12)n\u22122) log(T )\n+ (\n\u221e \u2211\nn=0\n(2\u03b1)2n) \u03c02\n2\n\u2264 8 \u03b1 4 (1 \u2212 \u03b12)3 log(T ) + \u03c02 2(1\u2212 2\u03b1)\n\u2264 8 \u03b1 4\n(1 \u2212 \u03b12)3 log(T ) + \u03c0 2,\nsince \u03b1 \u2264 14 . Using (4), we conclude that:\nRT (\u2113, Z\u0303,F) \u2265 \u2016z\u2217\u2016\u03b12\n2 (1\u2212 16 \u03b1\n2\n(1 \u2212 \u03b12)3 ) log(T ) +O(log log(T )),\nwhich implies that RT (\u2113, Z\u0303,F) = \u2126(log(T )) as \u03b12(1\u2212 16 \u03b1 2 (1\u2212\u03b12)3 ) > 0 for \u03b1 \u2208 (0, 132 ]."}, {"heading": "4.13 Proof of Lemma 7", "text": "The proof is along the same lines as for Theorem 4. We start with the same inequality:\nrT ((zt)t=1,\u00b7\u00b7\u00b7 ,T , (ft)t=1,\u00b7\u00b7\u00b7 ,T ) \u2264 T \u2211\nt=1\nzTt (ft \u2212 ft+1),\nand use sensitivity analysis to control this last quantity. Specifically, we show that the mapping \u03c6 : z \u2192 argminf\u2208F zTf is 1q\u22121 -H\u00f6lder continuous on Z , i.e. there exists c > 0 such that:\n\u2016\u03c6(z1)\u2212 \u03c6(z2)\u20162 \u2264 c \u2016z1 \u2212 z2\u2016 1 q\u22121\n2 \u2200(z1, z2) \u2208 Z2. Using this property, we get:\nrT ((zt)t=1,\u00b7\u00b7\u00b7 ,T , (ft)t=1,\u00b7\u00b7\u00b7 ,T ) \u2264 T \u2211\nt=1\n\u2016zt\u20162 \u2016ft \u2212 ft+1\u20162\n= O(\nT \u2211\nt=1\n\u2225 \u2225 \u2225 \u2225 \u2225 1 t\u2212 1 t\u22121 \u2211\n\u03c4=1\nz\u03c4 \u2212 1\nt\nt \u2211\n\u03c4=1\nz\u03c4\n\u2225 \u2225 \u2225 \u2225 \u2225\n1\nq\u22121\n2\n)\n= O(\nT \u2211\nt=1\n\u2225 \u2225 \u2225 \u2225 \u2225 1 t(t\u2212 1) t\u22121 \u2211\n\u03c4=1\nz\u03c4 \u2212 1\nt zt\n\u2225 \u2225 \u2225 \u2225 \u2225\n1\nq\u22121\n2\n)\n= O( T \u2211\nt=1\n( 1\nt(t\u2212 1)\n\u2225 \u2225 \u2225 \u2225 \u2225 t\u22121 \u2211\n\u03c4=1\nz\u03c4\n\u2225 \u2225 \u2225 \u2225 \u2225\n2\n+ 1\nt \u2016zt\u20162)\n1\nq\u22121 )\n= O(\nT \u2211\nt=1\n1\nt 1 q\u22121\n),\nfrom which we derive that rT ((zt)t=1,\u00b7\u00b7\u00b7 ,T , (ft)t=1,\u00b7\u00b7\u00b7 ,T ) = O(log(T )) if q = 2 and rT ((zt)t=1,\u00b7\u00b7\u00b7 ,T , (ft)t=1,\u00b7\u00b7\u00b7 ,T ) = O(T q\u22122 q\u22121 ) if q \u2208 (2, 3]. We now move on to show that \u03c6 is 1 q\u22121 -H\u00f6lder continuous. Just like in Theorem 4, we can find A > 0 such that \u2016z\u20162 \u2265 A for all z \u2208 Z . Take (z1, z2) \u2208 Z2 and (f1, f2) \u2208 \u03c6(z1) \u00d7 \u03c6(z2). Since we are optimizing a linear function, we may assume, without loss of generality, that C = 1 and f1 and f2 lie on the boundary of F , i.e. \u2016f1\u2016F = \u2016f2\u2016F = 1. By definition, we have:\n\u2225 \u2225 \u2225 \u2225 f1 + f2 2 \u2225 \u2225 \u2225 \u2225 F \u2264 1\u2212 \u03b4F (\u2016f1 \u2212 f2\u2016F ).\nAs a consequence, we have:\nf1 + f2 2 \u2212 \u03b4F (\u2016f1 \u2212 f2\u2016F) z2 \u2016z2\u2016F \u2208 F .\nWe get:\nzT2( f1 + f2\n2 \u2212 \u03b4F(\u2016f1 \u2212 f2\u2016F ) z2 \u2016z2\u2016F ) \u2265 inf f\u2208F zT2f = z T 2f2.\nRearranging this last inequality yields:\nzT2 f1 \u2212 f2 2 \u2265 \u2016z2\u2016 2 2 \u2016z2\u2016F \u03b4F (\u2016f1 \u2212 f2\u2016F ),\nwhich implies that:\nzT2 f1 \u2212 f2\n2 \u2265 K \u2016f1 \u2212 f2\u2016q2 ,\nfor some K > 0 independent of z1 and z2 since Z is compact, \u2016z2\u20162 \u2265 A > 0, \u2016 \u2016F is q-uniformly convex, and by the equivalence of norms in finite dimensions. By optimality of f1, we also have zT1 f2\u2212f1 2 \u2265 0. Summing up the last two inequalities, we get:\n(z2 \u2212 z1)T f1 \u2212 f2\n2 \u2265 K \u2016f1 \u2212 f2\u2016q2 ,\nand (by Cauchy-Schwartz): \u2016z2 \u2212 z1\u20162 \u2265 2K \u2016f1 \u2212 f2\u2016 q\u22121 2 ,\nwhich concludes the proof."}], "references": [], "referenceMentions": [], "year": 2016, "abstractText": "<lb>In the convex optimization approach to online regret minimization, many methods<lb>have been developed to guarantee a O(<lb>\u221a<lb>T ) bound on regret for subdifferentiable<lb>convex loss functions with bounded subgradients, by using a reduction to linear<lb>loss functions. This suggests that linear loss functions tend to be the hardest ones<lb>to learn against, regardless of the underlying decision spaces. We investigate this<lb>question in a systematic fashion looking at the interplay between the set of pos-<lb>sible moves for both the decision maker and the adversarial environment. This<lb>allows us to highlight sharp distinctive behaviors about the learnability of piece-<lb>wise linear loss functions. On the one hand, when the decision set of the deci-<lb>sion maker is a polyhedron, we establish \u03a9(<lb>\u221a<lb>T ) lower bounds on regret for a<lb>large class of piecewise linear loss functions with important applications in on-<lb>line linear optimization, repeated zero-sum Stackelberg games, online prediction<lb>with side information, and online two-stage optimization. On the other hand, we<lb>exhibit o(<lb>\u221a<lb>T ) learning rates, achieved by the Follow-The-Leader algorithm, in<lb>online linear optimization when the boundary of the decision maker\u2019s decision set<lb>is curved and when 0 does not lie in the convex hull of the environment\u2019s decision<lb>set. Hence, the curvature of the decision maker\u2019s decision set is a determining<lb>factor for the optimal learning rate. These results hold in a completely adversarial<lb>setting.<lb>", "creator": "LaTeX with hyperref package"}}}