{"id": "1501.01924", "review": {"conference": "arxiv", "VERSION": "v1", "DATE_OF_SUBMISSION": "8-Jan-2015", "title": "Less is More: Building Selective Anomaly Ensembles", "abstract": "mesh techniques : tuning and clustering have long proven effective, if anomaly ensembles have been barely constrained. in the development, innovative tap into this gap structure propose and new ensemble approach utilizing graph analysis, with application to correlated detection in temporal graphs. our method employs to combine results from heterogeneous flows with variable outputs, and repeat the sampling from natural sources to yield statistical measurement. however, trusting performing the experiment may deteriorate its measurement ensemble accuracy, for some filters may fall out and provide inaccurate comparisons largely on geometric nature of the data in comparison. this suggests experiment being integrated in target fields to manipulate vary vital than building effective scenarios - - - hence \" less is more \".", "histories": [["v1", "Thu, 8 Jan 2015 18:54:09 GMT  (1271kb,D)", "http://arxiv.org/abs/1501.01924v1", "14 pages, 5 pages Appendix, 10 Figures, 15 Tables, to appear at SDM 2015"]], "COMMENTS": "14 pages, 5 pages Appendix, 10 Figures, 15 Tables, to appear at SDM 2015", "reviews": [], "SUBJECTS": "cs.DB cs.LG", "authors": ["shebuti rayana", "leman akoglu"], "accepted": false, "id": "1501.01924"}, "pdf": {"name": "1501.01924.pdf", "metadata": {"source": "CRF", "title": "Less is More: Building Selective Anomaly Ensembles with Application to Event Detection in Temporal Graphs", "authors": ["Shebuti Rayana", "Leman Akoglu"], "emails": ["srayana@cs.stonybrook.edu", "leman@cs.stonybrook.edu"], "sections": [{"heading": null, "text": "In this paper we propose SELECT; an ensemble approach for anomaly mining that employs novel techniques to automatically and systematically select the results to assemble in a fully unsupervised fashion. We apply our method to event detection in temporal graphs, where SELECT successfully utilizes five base detectors and seven consensus methods under a unified ensemble framework. We provide extensive quantitative evaluation of our approach on five realworld datasets (four with ground truth), including Enron email communications, New York Times news corpus, and World Cup 2014 Twitter news feed. Thanks to its selection mechanism, SELECT yields superior performance compared to individual detectors alone, the full ensemble (naively combining all results), and an existing diversity-based ensemble."}, {"heading": "1 Introduction", "text": "Ensemble methods utilize multiple algorithms to obtain better performance than the constituent algorithms alone and produce more robust results [5]. Thanks to these advantages, a large body of research has been devoted to ensemble learning in classification [13, 21, 23, 26] and clustering [8, 11, 12, 25]. On the other hand, building effective ensembles for anomaly detection has proven to be a challenging task [1, 27]. A key challenge is the lack of ground-truth; which makes it hard to measure detector accuracy and to accordingly select accurate detectors to combine, unlike in\nclassification. Moreover, there exist no objective or \u2018fitness\u2019 functions for anomaly mining, unlike in clustering.\nExisting attempts for anomaly ensembles either combine outcomes from all the constituent detectors [9, 10, 16, 19], or induce diversity among their detectors to increase the chance that they make independent errors [24, 28]. However, as our prior work [22] suggests, neither of these strategies would work well in the presence of inaccurate detectors. In particular, combining all, including inaccurate results would deteriorate the overall ensemble performance. Similarly, diversity-based ensembles would combine inaccurate results for the sake of diversity.\nIn this work, we tap into the gap between anomaly mining and ensemble methods, and propose SELECT, one of the first selective ensemble approaches for anomaly detection. As the name implies, the key property of our ensemble is its selection mechanism which carefully decides which results to combine from multiple different methods in the ensemble. We summarize our contributions as follows. \u2022 We identify and study the problem of building selective\nanomaly ensembles in a fully unsupervised fashion. \u2022 We propose SELECT, a new ensemble approach for\nanomaly detection, which utilizes not only multiple heterogeneous detectors, but also various consensus methods under a unified ensemble framework. \u2022 SELECT employs two novel unsupervised selection strategies that we design to choose the detector/consensus results to combine, which render the ensemble not only more robust but improve its performance further over its non-selective counterpart. \u2022 Our ensemble approach is general and flexible. It does not rely on specific data types, and allows other detectors and consensus methods to be incorporated. We apply our ensemble approach to the event detection problem in temporal graphs, where SELECT utilizes five heterogeneous event detection algorithms and seven different consensus methods. Extensive evaluation on datasets with ground truth shows that SELECT outperforms the average individual detector, the full ensemble that naively combines all results, as well as the diversity-based ensemble in [24]. ar X iv :1\n50 1.\n01 92\n4v 1\n[ cs\n.D B\n] 8\nJ an\n2 01"}, {"heading": "2 Background and Preliminaries", "text": "2.1 Event Detection Problem Temporal graphs change dynamically over time in which new nodes and edges arrive or existing nodes and edges disappear. Many dynamic systems can be modeled as temporal graphs, such as computer, trading, transaction, and communication networks.\nEvent detection in temporal graph data is the task of finding the points in time at which the graph structure notably differs from its past. These change points may correspond to significant events; such as critical state changes, anomalies, faults, intrusion, etc. depending on the application domain. Formally, the problem can be stated as follows. Given a sequence of graphs {G1, G2, . . . , Gt, . . . , GT }; Find time points t\u2032 s.t. Gt\u2032 differs significantly from Gt\u2032\u22121.\n2.2 Motivation for Ensembles Several different methods have been proposed for the above problem, a survey of which is given in [3]. To date, however, there exists no single method that has been shown to outperform all the others. The lack of a winner technique is not a freak occurrence. In fact, it is unlikely that a given method could perform consistently well on different data of varying nature. Further, different techniques may identify different classes or types of anomalies depending on their particular formulation. This suggests that effectively combining the results from various different detection methods (detectors from here onwards) could help improve the detection performance.\n2.3 Motivation for Selective Ensembles Ensembles are expected to perform superior to their average constituent detector, however a naive ensemble that trusts results from all detectors may not work well. The reason is, some methods may not be as effective as desired depending on the nature of the data in hand, and fail to identify the anomalies of interest. As a result, combining accurate results with inaccurate ones may deteriorate the overall ensemble performance [22]. This suggests that selecting which detectors to assemble is a critical aspect of building robust ensembles\u2014which implies that \u201cless is more\u201d.\nTo illustrate the motivation for (selective) ensemble building further, consider the example in Figure 1. The rows show the anomaly scores assigned by five different detectors to time points in the Enron Inc.\u2019s time line. Notice that the scores are of varying nature and scale, due to different formulations of the detectors. We realize that the detectors mostly agree on the events that they detect; e.g., \u2018J. Skilling new CEO\u2019. On the other hand, they assign different magnitude of anomalousness to the time points; e.g., the top anomaly of methods varies. These suggest that combining the outcomes could help build improved ranking of the anomalies. Next notice the result provided by \u201cProbabilistic Approach\u201d which, while identifying one major event also detected by other detectors, fails to provide a reliable ranking for the rest; e.g., it scores many other time points higher than\n\u2018F. Cooper new CEO\u2019. As such, including this detector in the ensemble is likely to deteriorate the overall performance.\nIn summary, inspired by the success of classification and clustering ensembles and driven by the limited work on anomaly ensembles, we aim to systematically combine the strengths of accurate detectors while alleviating the weaknesses of the less accurate ones to build selective detection ensembles for anomaly mining. While we build ensembles for the event detection problem in this paper, our approach is general and can directly be employed on a collection of detection methods for other anomaly mining problems.\n3 SELECT: Selective Ensemble Learning for anomaly detECTion \u2014 Application to Event Detection\n3.1 Overview Our SELECT approach takes the input data, in this case a sequence of graphs {G1, . . . , Gt, . . . , GT }, and outputs a rank list R of objects, in this case of time points 1 \u2264 t \u2264 T , ranked from most to least anomalous.\nThe main steps of SELECT are given in Algorithm 1. Step 1 employs (five) different event detection algorithms as base detectors of the ensemble. Each detector has a specific and different measure to score the individual time points by anomalousness. As such, the ensemble embodies heterogeneous detectors. As motivated earlier, Step 2 selects a subset of the detector results to assemble through a proposed selection strategy. Step 3 then combines the selected results into\na consensus. Besides several different event detection algorithms, there also exist various different consensus finding approaches. In spirit of building ensembles, SELECT also leverages (seven) different consensus techniques to create intermediate aggregate results. Similar to Step 2, Step 4 then selects a subset of the consensus results to assemble. Finally, Step 5 combines this subset into the final rank list of time points using inverse rank aggregation (Section 3.3).\nAlgorithm 1 SELECT Input: Data: graph sequence {G1, . . . , Gt, . . . , GT } Output: Rank list of objects (time points) by anomaly\n1: Obtain results from (5) base detectors 2: Select set E of detectors to assemble 3: Combine E by (7) consensus techniques 4: Select set C of consensus results to assemble 5: Combine C into final rank list\nDifferent from prior works, (i) SELECT is a two-phase ensemble that not only leverages multiple detectors but also multiple consensus techniques, and (ii) it employs novel strategies to carefully select the ensemble components to assemble without any supervision, which outperform naive (no selection) and diversity-based selection (Section 4). Moreover, (iii) SELECT is the first ensemble method for event detection in temporal graphs, although the same general framework as presented in Algorithm 1 can be deployed for other anomaly mining tasks, where the base detectors are replaced with a set of algorithms for the particular task at hand.\nNext we fill in the details on the three main components of the proposed SELECT ensemble. In particular, we describe the base detectors (Section 3.2), consensus techniques (Section 3.3), and the selection strategies (Section 3.4).\n3.2 Base Detectors There exist various methods for the event detection problem in temporal graphs [3]. In this work SELECT employs five base detectors (Algorithm 1, Line 1), while one can easily expand the ensemble with others: (1) eigen-behavior based event detection (EBED) from our prior work [2], (2) probabilistic time series anomaly detection (PTSAD) we developed recently [22], (3) Streaming Pattern DIscoveRy in multIple Time-Series (SPIRIT) by Papadimitriou et al. [20], (4) anomalous subspace based event detection (ASED) by Lakhina et al. [18], and (5) moving-average based event detection (MAED). All methods extract graphcentric features (e.g., degree) for all nodes over time and detect events in multi-variate time series. We provide brief descriptions of the methods in Appendix A due to space limit.\n3.3 Consensus Finding Our ensemble consists of heterogeneous detectors. That is, the detectors employ different anomaly scoring functions and hence their scores may vary in range and interpretation (see Figure 1). Unifying these various outputs to find a consensus among detectors is an essential step toward building an ensemble.\nA number of different consensus finding approaches have been proposed in the literature, which can be categorized into two, as rank based and score based aggregation methods. Without choosing one over the other, we utilize seven well-established methods as we describe below. Rank based consensus. Rank based methods use the anomaly scores to order the data points (here, time points) into a rank list. This ranking makes the algorithm outputs comparable and facilitates combining them. Merging multiple rank lists into a single ranking is known as rank aggregation, which has a rich history in theory of social choice and information retrieval [6]. SELECT employs three rank based consensus methods. Kemeny-Young [14] is a voting technique that uses preferential ballot and pair-wise comparison counts to combine multiple rank lists, in which the detectors are treated as voters and the points as the candidates they vote for. Robust Rank Aggregation (RRA) [15] utilizes order statistics to compute the probability that a given ordering of ranks for a point across detectors is generated by the null model where the ranks are sampled from a uniform distribution. The final ranking is done based on this probability, where more anomalous points receive a lower probability. The third approach is based on Inverse Rank aggregation, in which we score each point by 1ri where ri denotes its rank by detector i and average these scores across detectors based on which we sort the points into a final rank list. Score based consensus. Rank-based aggregation provides a crude ordering of the data points, as it ignores the actual anomaly scores and their spacing. For instance, quite different rankings can yield equal performance in binary decision. Score-based aggregation approaches tackle the calibration of different anomaly scores and unify them within a shared range. SELECT employs two score based consensus methods. Mixture Modeling [10] converts the anomaly scores into probabilities by modeling them as sampled from a mixture of exponential (for inliers) and Gaussian (for outliers) distributions. Unification [16] also converts the scores into probability estimates through regularization, normalization, and scaling steps. The probabilities are then comparable across detectors, which we aggregate by both max and avg. This yields four score based methods.\n3.4 Ensemble Learning Given different base detectors and various consensus methods, the final task remains to utilize them under a unified ensemble framework. In this section, we discuss four different approaches for building anomaly ensembles. These approaches differ in whether and how they select their ensemble components.\n3.4.1 Full ensemble The full ensemble selects all the detector results (Step 2 of Alg.1) and later all the consensus results (Step 4 of Alg.1) to aggregate at both phases of SELECT. As such, it is a naive approach that is prone to obtain inferior results in the presence of inaccurate detectors.\n3.4.2 Selective ensembles As motivated earlier in Section 2.3, carefully selecting which detectors to assemble in Step 2 may help prevent the final ensemble from going astray, provided that some base detectors may fail to reliably identify the anomalies of interest to a given application. Similarly, pruning away consensus results that may be noisy in Step 4 could help reach a stronger final consensus. In anomaly mining, however, it is challenging to identify the components with inferior results given the lack of ground truth to estimate their generalization errors externally. In this section, we present two orthogonal selection strategies that leverage internal clues across detectors or consensuses and work in a fully unsupervised fashion: (i) a vertical strategy that exploits correlations among the results, and (ii) a horizontal strategy that uses order statistics to filter out far-off results. Strategy I: Vertical Selection. Our first approach to selecting the ensemble components is through correlation analysis among the score lists from different methods, based on which we successively enhance the ensemble one list at a time (hence vertical). The work flow of the vertical selection strategy is given in Algorithm 2.\nGiven a set of anomaly score lists S, we first unify the scores by converting them to probability estimates using Unification [16]. Then we average the probability scores across lists to construct a target vector, which we treat as the \u201cpseudo ground-truth\u201d (Lines 1-6).\nWe initialize the ensemble E with the list l \u2208 S that has the highest weighted Pearson correlation to target. In computing the correlation, the weights we use for the list elements are equal to 1r , where r is the rank of an element in target when sorted in descending order, i.e., the more anomalous elements receive higher weight (Lines 7-11).\nNext we sort the remaining lists S\\l in descending order by their correlation to the current \u201cprediction\u201d of the ensemble, which is defined as the average probability of lists in the ensemble. We test whether adding the top list to the ensemble would increase the correlation of the prediction to target. If the correlation improves by this addition, we update the ensemble and reorder the remaining lists by their correlation to the updated prediction, otherwise we discard the list. As such, a list gets either included or discarded at each iteration until all lists are processed (Lines 12-19).\nStrategy II: Horizontal Selection. We are interested in finding time points that are ranked high in a set of accurate rank lists (from either base detectors or consensus methods), ignoring a (small) fraction of inaccurate rank lists. Thus, we also present an element-based (hence horizontal) approach for selecting ensemble components.\nTo identify the accurate lists, this strategy focuses on the anomalous elements. It assumes that the normalized ranks of the anomalies should come from a distribution skewed toward zero. Based on this, lists in which the anomalies are not ranked sufficiently high (i.e., have large normalized\nAlgorithm 2 Vertical Selection Input: S := set of anomaly score lists Output: E := ensemble set of selected lists\n1: P := \u2205 2: /* convert scores to probability estimates */ 3: for each s \u2208 S do 4: P := P \u222a Unification(s) 5: end for 6: target := avg(P ) /*target vector*/ 7: r := ranklist after sorting target in descending order 8: E := \u2205 9: sort P by weighted Pearson (wP ) correlation to target 10: /* in descending order, weights: 1r */ 11: l := fetchF irst(P ), E := E \u222a l 12: while P 6= \u2205 do 13: p := avg(E) /*current prediction of E*/ 14: sort P by wP correlation to p /*descending order*/ 15: l := fetchF irst(P ) 16: if wP (avg(E \u222a l), target) > wP (p, target) then 17: E := E \u222a l /*select list*/ 18: end if 19: end while 20: return E\nranks) are considered to be inaccurate and voted for being discarded. The work flow of the horizontal selection strategy is given in Algorithm 3.\nSimilar to the vertical strategy we first identify a \u201cpseudo ground truth\u201d, in this case a list of anomalies. In particular, we use Mixture Modeling [10] to convert each score list in S into a binary list in which outliers are denoted by 1, and inliers by 0. We then employ majority voting across lists to obtain a final set of target anomalies O (Lines 1-7).\nGiven that S containsm lists, we construct a normalized rank vector r = [r(1), . . . , r(m)] for each anomaly o \u2208 O, such that r(1) \u2264 . . . \u2264 r(m), where r(l) denotes the rank of o in list l \u2208 S normalized by the total number of elements in l. Following similar ideas to Robust Rank Aggregation [15], we then compute order statistics based on these sorted normalized rank lists to identify the lists that provide statistically large ranks for each anomaly.\nSpecifically, for each ordered list l in a given r, we compute how probable it is to obtain r\u0302(l) \u2264 r(l) when the ranks r\u0302 are generated by a uniform null distribution. We denote the probability that r\u0302(l) \u2264 r(l) by pl,m(r). Under the uniform null model, the probability that r\u0302(l) is smaller or equal to r(l) can be expressed as a binomial probability\npl,m(r) = m\u2211 t=l ( m t ) rt(l)(1\u2212 r(l)) m\u2212t,\nsince at least l normalized rankings drawn uniformly from [0, 1] must be in the range [0, r(l)].\nAlgorithm 3 Horizontal Selection Input: S := set of anomaly score lists Output: E := ensemble set of selected lists\n1: M := \u2205 , R := \u2205 , F := \u2205 , E := \u2205 2: for each l \u2208 S do 3: /* label score lists with 1 (outliers) & 0 (inliers) */ 4: class := MixtureModel(l) , M := M \u222a class 5: R := R \u222a ranklist(l) 6: end for 7: O := majorityV oting(M) /*target anomalies*/ 8: [Ssort, pV als] := RobustRankAggregation(R,O) 9: for each o \u2208 O do\n10: mind := min(pV als(o, :)) 11: F := F \u222a Ssort(o, (mind + 1) : end) 12: end for 13: for each l \u2208 S do 14: count := number of occurrences of l in F 15: end for 16: Cluster non-zero counts into two clusters, Cl and Ch 17: E := S \\ {s \u2208 Ch} /* discard high-count lists */ 18: return E\nFor a sequence of accurate lists that rank the anomalies at the top, and hence that yield low normalized ranks r(l), this probability is expected to drop with the ordering, i.e., for increasing l \u2208 {1 . . .m}. An example sequence of p probabilities (y-axis) are shown in Figure 2 for an anomaly based on 20 score lists. The lists are sorted by their normalized ranks of the anomaly on the x-axis. The figure suggests that the 5 lists at the end of the ordering are likely inaccurate, as the ranks of the given anomaly in those lists are larger than what is expected based on the ranks in the other lists.\nBased on this intuition, we count the frequency that each list l is ordered after the list with minl=1,...,m pl,m(r) among all the normalized rank lists r of the target anomalies (Lines 8-15). We then group these counts into two clusters1 and discard the lists in the cluster with the higher average count (Lines 16-17). This way we eliminate the lists with larger counts, but retain the lists that appear inaccurate only a few times which may be a result of the inherent uncertainty or noise in which we construct the target anomaly set.\n1We cluster the counts by k-means clustering with k = 2, where the centroids are initialized with the smallest and largest counts, respectively.\n3.4.3 Diversity-based ensemble In classification, two basic conditions for an ensemble to improve over the constituent classifiers are that the base classifiers are (i) accurate (better than random), and (ii) diverse (making uncorrelated errors) [5, 26]. Achieving better-than-random accuracy in supervised learning is not hard, and several studies have shown that ensembles tend to yield better results when there is a significant diversity among the models [4, 17].\nFollowing on these insights, Schubert et al. proposed a diversity-based ensemble [24], which is similar to our vertical selection in Alg. 2. The main distinction is the ascending ordering in Lines 9 and 14, which yields a diversity-favored, in contrast to a correlation-favored, selection.2\nUnlike classification ensembles, however, it is not realistic for anomaly ensembles to assume that all the detectors will be reasonably accurate (i.e., better than random), as some may fail to spot the (type of) anomalies in the given data. In the existence of inaccurate detectors, the diversitybased approach would likely yield inferior results as it is prone to selecting inaccurate detectors for the sake of diversity. As we show in our experiments, too much diversity is in fact bound to limit accuracy for event detection ensembles."}, {"heading": "4 Evaluation", "text": "We evaluate our selective ensemble approach on the event detection problem using five real-world datasets, both previously used as well as newly collected by us, including email communications, news corpora, and social media. For four of these datasets we compiled ground truths for the temporal anomalies, for which we present quantitative results. We use the remaining data for illustrating case studies.\nWe compare the performance of SELECT with vertical selection (SelectV), and horizontal selection (SelectH) to that of individual detectors, the full ensemble with no selection (Full), and the diversity-based ensemble (DivE) [24]. This makes ours one of the few works that quantitatively compares and contrasts anomaly ensembles at a scale that includes as many datasets with ground truth.\nIn a nutshell, our results illustrate that (i) base detectors do not always all produce accurate results, (ii) ensemble approach alleviates the shortcomings of the inaccurate detectors, (iii) a careful selection of ensemble components increases the overall performance, and (iv) introducing noisy results decreases overall ensemble accuracy where the diversity-based ensemble is affected the most.\n4.1 Dataset Description In the following we describe the five real-world temporal graph datasets we used in this work. All datasets with ground truth events are made available at http://shebuti.com/SelectiveAnomalyEnsemble/.\n2There are other differences between our vertical selection (Algorithm 2) and the diversity-based ensemble in [24], such as the construction of the pseudo ground truth and the choice of weights in correlation computation.\nDataset 1: EnronInc. We use four years (1999\u20132002) of Enron email communications. In the temporal graphs, the nodes represent email addresses and directed edges depict sent/received relations. Enron email network contains a total of 80, 884 nodes. We analyze the data with daily sample rate skipping the weekends (700 time points). The ground truth captures the major events in the company\u2019s history, such as CEO changes, revenue losses, restatements of earnings, etc. Dataset 2: RealityMining Reality Mining is comprised of communication and proximity data of 97 faculty, student, and staff at MIT recorded continuously via pre-installed software on their mobile devices over 50 weeks [7]. From the raw data we built sequences of weekly temporal graphs for three types of relations; voice calls, short messages, and bluetooth scans. For voice call and short message graphs a directed edge denotes an incoming/outgoing call or message, and for bluetooth graphs an edge depicts physical proximity between two subjects. The ground truth captures semester breaks, exam and sponsor weeks, and holidays. Dataset 3: TwitterSecurity We collect tweet samples using the Twitter Streaming API for four months (May 12\u2013Aug 1, 2014). We filter the tweets containing Department of Homeland Security keywords related to terrorism or domestic security.3 After named entity extraction and resolution (including URLs, hashtags, @ mentions), we build entity-entity comention temporal graphs on daily basis (80 time ticks). We compile the ground truth to include major world news of 2014, such as the Turkey mine accident, Boko Haram kidnapping school girls, killings during Yemen raids, etc. Dataset 4: TwitterWorldCup Our Twitter collection also spans the World Cup 2014 season (June 12\u2013July 13). This time, we filter the tweets by popular/official World Cup hashtags, such as #worldcup, #fifa, #brazil, etc. Similar to TwitterSecurity, we construct entity-entity co-mention temporal graphs on 5 minute sample rate (8640 time points). The ground truth contains the goals, penalties, and injuries in all the matches that involve at least one of the renowned teams (Brazil, Germany, Argentina, Netherlands, Spain, France). Dataset 5: NYTNews This corpus contains all of the published articles in New York Times over 7.5 years (Jan 2000\u2013July 2007) (available from https://catalog.ldc. upenn.edu/LDC2008T19). The named entities (people, places, organizations) are hand-annotated by human editors. We construct weekly temporal graphs (390 time points) in which each node corresponds to a named entity and edges depict co-mention relations in the articles. The data contains around 320, 000 entities, however no ground truth events.\n4.2 Event Detection Performance Next we quantitatively evaluate the ensemble methods on detection accuracy. The final result output by each ensemble is a rank list, based\n3http://www.huffingtonpost.com/2012/02/24/ homeland-security-manual_n_1299908.html\non which we create the precision-recall (PR) plot for a given ground truth. We report the area under the PR plot, namely average precision, as the measure of accuracy.\nTable 1 shows the accuracies for all four ensemble methods on EnronInc., along with the accuracies of the base detectors and consensus methods. Notice that some detectors yield quite low accuracy (e.g., ASED (wout)) on this dataset. Further, MM (max) consensus provides low accuracy across ensembles no matter which detector results are combined. SELECT ensembles successfully filter out relatively inferior results and achieve higher accuracy. We also note that DivE yields lower performance than all, including Full.\nTo investigate the significance of the selections made by SELECT ensembles, we compare them to ensembles that randomly select the same number of components to assemble at each phase. In Table 2 we report the average and standard deviation of accuracies achieved by 100 such random ensembles, denoted by RandE, and the gain achieved by SelectV and SelectH over their respective random ensembles.\nWe show the final anomaly scores of the time points provided by SelectH on EnronInc. for visual analysis in Figure 3. The figure also depicts the ground truth events by vertical (red) lines, which we note to align well with the time points with high scores.\nTable 1 shows results when we use weighted node in/out-degree features on the directed Enron graphs to construct the input time series for the base detectors. As such, the ensembles utilize 10 components in the first phase. We also build the ensembles using 20 components where we include the unweighted in-/out-degree features. Table 3 in Appendix B gives all the accuracy results and selections made, a summary of which is provided in Table 2. We notice that the unweighted graph features are less informative and yield lower accuracies across detectors on average. This affects the performance of Full and DivE, where the accuracies drop significantly. On the other hand, SELECT ensembles are able to achieve comparable accuracies with increased significance under the additional noisy input.\nThus far, we used the exact time points of the events to compute precision and recall. In practice, some time delay in detecting an event is often tolerable. Therefore, we also compute the detection accuracy when delay is allowed; e.g., for delay 2, detecting an event that occurred at t within time window [t\u2212 2, t+ 2] is counted as accurate. Figure 4 shows the accuracy for 0 to 5 time point delays (days) for EnronInc., where delay 0 is the same as exact detection. We notice that SELECT ensembles and Full can detect almost all the events within 5 days before or after each event occurs.\nNext we analyze the results for RealityMining. Similar to EnronInc., we build the ensembles using both 10 and 20 components for the directed Voice Call and SMS graphs. Bluetooth graphs are undirected, as they capture (symmetric) proximity of devices, for which we build ensembles with 10 components using weighted and unweighted degree features. All the details on detector and consensus accuracies as well as selections made are given in Appendix B due to space limit (Table 4 and Table 5 for Voice Call, Table 6 for Bluetooth, Table 7 and Table 8 for SMS). We provide the summary of results in Table 2. We note that SELECT ensembles provide superior results to Full and DivE.\nFigure 5 illustrates the accuracy-delay plots which show that SELECT ensembles for Bluetooth and SMS detect almost all the events within a week before or after they occur, while the changes in Voice Call are relatively less reflective of the changes in the school year calendar.\nFinally, we study event detection using Twitter. Table 9 in Appendix B contains accuracy details for detecting world\nnews on TwitterSecurity, a summary of which is included in Table 2. Results are in agreement with prior ones, where SelectH outperforms the other ensembles. This further becomes evident in Figure 6 (left), where SelectH can detect all the ground truth events within 3 days delay.\nThe detection dynamics change when TwitterWorldCup is analyzed. The events in this data such as goals and injuries are quite instantaneous (recall the 4 goals in 6 minutes by Germany against Brazil), where we use a sample rate of 5 minutes. Moreover, such events are likely to be reflected on Twitter with some delay by social media users. As such, it\nis extremely hard to pinpoint the exact time of the events by the ensembles. As we notice in Figure 6 (right), the initial accuracies at zero delay are quite low. When delay is allowed for up to 288 time points (i.e., one day), the accuracies incline to a reasonable level within half a day delay. In addition, all the detector and consensus results seem to contain signals in this case where most of them are selected by the ensembles, hence comparable accuracies. In fact, DivE selects all of them and performs the same as Full.\n4.3 Noise Analysis Provided that selecting which results to combine would especially be beneficial in the presence of inaccurate detectors, we design experiments where we introduce increasing number of noisy results into our ensembles. In particular, we create noisy results by randomly shuffling the rank lists output by the base detectors and treat them as additional detector results. Figure 7 shows accuracies (avg.\u2019ed over 10 independent runs) on all of our datasets for 10 component ensembles (results using 20 components are similar, and provided in Figure 10 in Appendix B). We notice that SELECT ensembles provide the most stable and effective performance under increasing number of noisy results. More importantly, these results show that DivE degenerates quite fast in the presence of noise, i.e., when the assumption that all results are reasonably accurate fails to hold.\n4.4 Case Studies In this section we evaluate our ensemble approach qualitatively using the NYTNews corpus dataset, for which we do not have a compiled list of ground truth events. Figure 8 shows the anomaly scores for the 2000-2007 time line, provided by the five base detectors using weighted degree feature (we have demonstrated a similar figure for EnronInc. in Figure 1 for additional qualitative analysis).\nTop three events by SelectH are marked within boxes in the figure, and corresponds to major events such as the 2001\nelections, 9/11 WTC attacks, and the 2003 Columbia Space Shuttle disaster. SelectH also ranks entities by association to a detected event for attribution. We note that for the Columbia disaster, NASA and the seven astronauts killed in the explosion rank at the top. The visualization of the change in Figure 9 shows that a heavy clique with high degree nodes emerges in the graph structure at the time of the event."}, {"heading": "5 Conclusion", "text": "In this work we have proposed SELECT, a new selective ensemble approach for anomaly mining, and applied it to the event detection problem in temporal graphs. SELECT is a two-phase approach that combines multiple detector results and then multiple consensuses, respectively. Motivated by our earlier observations [22] that inaccurate detectors may deteriorate overall ensemble accuracy, we designed two unsupervised selection strategies, SelectV and SelectH, which carefully choose which detector/consensus outcomes to assemble. We compared SELECT to Full, the ensemble that combines all results, and DivE, an existing ensemble [24] that combines diverse, i.e., least correlated results.\nOur quantitative evaluation on real-world datasets with ground truth show that building selective ensembles is effective in boosting detection performance. SelectH appears to be a better strategy than SelectV, where it either provides the best result (6/8 in Table 2) or achieves comparable accuracy when SelectV is the winner. Selecting results based on diversity turns out to be a poor strategy for anomaly ensembles as DivE yields even worse results than the Full ensemble (6/8 in Table 2). Noise analysis further corroborates the fact that DivE selects inaccurate/noisy results for the sake of diversity and declines in accuracy much faster than the rest.\nFuture work will investigate how to go beyond binary selection and estimate weights for the detector/consensus results. We will also apply SELECT to the outlier mining problem in multi-dimensional point data and continue to enhance it with other detector and consensus methods."}, {"heading": "Appendix", "text": "A SELECT Base Algorithms for Event Detection"}, {"heading": "A.1 Eigen Behavior based Event Detection (EBED).", "text": "The multi-variate time series contain the feature values of each node over time and can be represented as a n \u00d7 t data matrix, for n nodes and t time points. EBED [29] defines sliding time windows of length w over the series and computes the principal left singular vector of each n \u00d7 w matrix W . This vector is the same as the principal eigenvector of WWT and is always positive due to the Perron-Frobenius theorem [34]. Each eigenvector u(t) is treated as the \u201ceigen-behavior\u201d of the system during time window t, the entries of which are interpreted as the \u201cactivity\u201d of each node.\nTo score the time points, EBED computes the similarity between eigen-behavior u(t) and a summary of past eigenbehaviors r(t), where r(t) is the arithmetic average of u(t\u2032)\u2019s for t\u2032 < t. The anomalousness score of time point t is then Z = 1 \u2212 u(t)\u00b7r(t) \u2208 [0, 1], where high value of Z indicates a change point. For each anomalous time point t\u0304, EBED performs attribution by computing the relative change |ui(t\u0304)\u2212ri(t\u0304)|\nui(t\u0304) of each node i at t\u0304. The higher the relative\nchange, the more anomalous the node is.\nA.2 Probabilistic Time Series Anomaly Detection (PTSAD). A common approach to time series anomaly detection is to probabilistically model a given series and detect anomalous time points based on their likelihood under the model. PTSAD models each series with four different parametric models and performs model selection to identify the best fit for each series. Our first model is the Poisson, which is used often for fitting count data. However, Poisson is not sufficient for sparse series with many zeros. Since real-world data is frequently characterized by over-dispersion and excess number of zeros, we employ a second model called Zero-Inflated Poisson (ZIP) [32] to account for data sparsity.\nWe further look for simpler models which fit data with many zeros and employ the Hurdle models [35]. Rather than using a single but complex distribution, Hurdle models assume that the data is generated by two simple, separate processes; (i) the hurdle and (ii) the count processes. The hurdle process determines whether there exists activity at a given time point and in case of activity the count process determines the actual (positive) counts. For the hurdle process, we employ two different models. First is the independent Bernoulli and the second is the first order Markov model which better captures the dependencies, where an activity influences the probability of subsequent activities. For the count process, we use the Zero-Truncated Poisson (ZTP) [30].\nOverall we model each time series with four different models: Poisson, ZIP, Bernoulli+ZTP and Markov+ZTP. We\nthen employ Vuong\u2019s likelihood ratio test [36] to select the best model for individual series. Note that the best-fit model for each series may be different.\nTo score the time points, we perform a single-sided test to compute a p-value for each value x in a given series; i.e., P (X \u2265 x) = 1 \u2212 cdfH(x) + pdfH(x), where H is the best-fit model for the series. The lower the p-value, the more anomalous the time point is. We then aggregate all the p-values from all the series per time point by taking the normalized sum of the p-values and inverting them to obtain scores \u2208 [0, 1] (s.t. higher is more anomalous). For each anomalous time point t\u0304, attribution is done by sorting the nodes (i.e., the series) based on their p-values at t\u0304.\nA.3 Streaming Pattern DIscoveRy in multIple TimeSeries (SPIRIT). SPIRIT [33] can incrementally capture correlations, discover trends, and dynamically detect change points in multi-variate time series. The main idea is to represent the underlying trends of a large number of numerical streams with a few hidden variables, where the hidden variables are the projections of the observed streams onto the principal direction vectors (eigenvectors). These discovered trends are exploited for detecting change points in the series.\nThe algorithm starts with a specific number of hidden variables that capture the main trends of the data. Whenever the main trends change, new hidden variables are introduced or several of existing ones are discarded to capture the change. SPIRIT can further quantify the change in the individual time series for attribution through their participation weights, which are the entries in the principal direction vectors. For further details on the algorithm, we refer the reader to the original paper by Papadimitriou et al. [33].\nA.4 Anomalous Subspace based Event Detection (ASED). ASED [31] is based on the separation of highdimensional space occupied by the time series into two disjoint subspaces, the normal and the anomalous subspaces. Principal Component Analysis is used to separate the highdimensional space, where the major principal components capture the most variance of the data and hence, construct the normal subspace and the minor principal components capture the anomalous subspace. The projection of the time series data onto these two subspaces reflect the normal and anomalous behavior. To score the time points, ASED uses the squared prediction error (SPE) of the residuals in the anomalous subspace. The residual values associated with individual series at the anomalous time points are used to measure the anomalousness of nodes for attribution. For the specifics of the algorithm, we refer to the original paper by Lakhina et al. [31]."}, {"heading": "A.5 Moving Average based Event Detection (MAED).", "text": "MAED is a simple approach that calculates the moving\naverage \u00b5t and the moving standard deviation \u03c3t of each time series corresponding to each node by extending the time window one point at a time. If the value at a specific time point is more than three moving standard deviations away from the mean, then the point is considered as anomalous and assigned a non-zero score. The anomalousness score is the difference between the original value and (\u00b5t + 3\u03c3t) at t. To score the time points collectively, MAED aggregates their scores across all the series. For each anomalous time point t\u0304, attribution is done by sorting the nodes (i.e., the series) based on the individual scores they assign to t\u0304."}, {"heading": "B Additional Evaluation Results", "text": ""}], "references": [], "referenceMentions": [], "year": 2015, "abstractText": "Ensemble techniques for classification and clustering have long proven effective, yet anomaly ensembles have been barely studied. In this work, we tap into this gap and propose a new ensemble approach for anomaly mining, with application to event detection in temporal graphs. Our method aims to combine results from heterogeneous detectors with varying outputs, and leverage the evidence from multiple sources to yield better performance. However, trusting all the results may deteriorate the overall ensemble accuracy, as some detectors may fall short and provide inaccurate results depending on the nature of the data in hand. This suggests that being selective in which results to combine is vital in building effective ensembles\u2014hence \u201cless is more\u201d. In this paper we propose SELECT; an ensemble approach for anomaly mining that employs novel techniques to automatically and systematically select the results to assemble in a fully unsupervised fashion. We apply our method to event detection in temporal graphs, where SELECT successfully utilizes five base detectors and seven consensus methods under a unified ensemble framework. We provide extensive quantitative evaluation of our approach on five realworld datasets (four with ground truth), including Enron email communications, New York Times news corpus, and World Cup 2014 Twitter news feed. Thanks to its selection mechanism, SELECT yields superior performance compared to individual detectors alone, the full ensemble (naively combining all results), and an existing diversity-based ensemble.", "creator": "LaTeX with hyperref package"}}}