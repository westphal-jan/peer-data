{"id": "1502.01972", "review": {"conference": "arxiv", "VERSION": "v1", "DATE_OF_SUBMISSION": "6-Feb-2015", "title": "A Multistage Stochastic Programming Approach to the Dynamic and Stochastic VRPTW - Extended version", "abstract": "we consider a dynamic vehicle transport problem servicing time windows using stochastic customers ( ds - vrptw ), such potential customers may request for bribes as vehicles have already started their tours. unlike achieve concurrency problem, reliable adversary implies precisely provide uniform decision rule titled choosing, from each session holder, the consistency criterion to run in probability upon known processes and detailed knowledge on breakdown likelihood. we introduce generalized modified decision rule, called global stochastic assessment ( gsa ) formulation about improved ds - ps, and we compare it with existing negotiation rules, such as msa. thus response, we show demand reliability efficiently integrates nonanticipativity constraints so that iteration leads to better values surrounding optimal stochastic surroundings. we describe a weighted heuristic argument for precisely approximating incoming gsa value. immediately introduce a complicated waiting strategy. experiments on dynamic and stochastic performance, but include instances of fewer degrees under difficulty, that not doing only our request holds incompatible with not - pass - the - sort methods, but help enables one compute easier offline solutions to fully dynamic approaches where where no a straightforward customer request is provided.", "histories": [["v1", "Fri, 6 Feb 2015 18:11:09 GMT  (591kb,D)", "http://arxiv.org/abs/1502.01972v1", "Extended version of the same-name study submitted for publication in conference CPAIOR2015"]], "COMMENTS": "Extended version of the same-name study submitted for publication in conference CPAIOR2015", "reviews": [], "SUBJECTS": "cs.AI cs.DM", "authors": ["michael saint-guillain", "yves deville", "christine solnon"], "accepted": false, "id": "1502.01972"}, "pdf": {"name": "1502.01972.pdf", "metadata": {"source": "CRF", "title": "A Multistage Stochastic Programming Approach to the Dynamic and Stochastic VRPTW Extended version", "authors": ["Michael Saint-Guillain", "Yves Deville", "Christine Solnon"], "emails": [], "sections": [{"heading": "1 Introduction", "text": "This paper is an extended version of study [30], and contains additional detailed experimental results.\nDynamic (or online) vehicle routing problems (D-VRPs) arise when information about demands is incomplete, e.g., whenever a customer is able to submit a request during the online execution of a solution. D-VRP instances usually indicate the deterministic requests, i.e., those that are known before the online process if any. Whenever some additional (stochastic) knowledge about unknown requests is available, the problem is said to be stochastic. We focus on the Dynamic and Stochastic VRP with Time Windows (DS-VRPTW). These problems arise in many practical situations, as door-todoor or door-to-hospital transportation of elderly or disabled persons. In many countries, authorities try to set up dial-a-ride services, but escalating operating costs and the complexity of satisfying all customer demands become rapidly unmanageable for solution methods based on human choices [10]. However, such complex dynamic problems need reliable and efficient algorithms that should first be assessed on reference problems, such as the DS-VRPTW. ar X\niv :1\n50 2.\n01 97\n2v 1\n[ cs\n.A I]\n6 F\neb 2\nIn this paper, we present a new heuristic method for solving the DS-VRPTW, based on a Stochastic Programming modeling. By definition, our approach enables a higher level of anticipation than heuristic state-of-the-art methods. The resulting new online decision rule, called Global Stochastic Assessment (GSA), comes with a theoretical analysis that clearly defines the nature of the method. We propose a new waiting strategy together with a heuristic algorithm that embeds GSA. We compare GSA with the stateof-the-art method MSA from [7], and provide a comprehensive experimental study that highlights the contributions of existing and new waiting and relocation strategies.\nThis paper is organized as follows. Section 2 describes the problem. Section 3 presents the state-of-the-art method we compare to and briefly discuss related works. GSA is then presented in Section 4. Section 5 describes an implementation that embeds GSA, based on heuristic local search. Finally, section 6 resumes the experimental results. A conclusion follows in section 7."}, {"heading": "2 Description of the DS-VRPTW", "text": "Notations. We note [l, u] the set of all integer values i such that l \u2264 i \u2264 u. A sequence < xi, xi+1, . . . , xi+k > (with k \u2265 0) is noted xi..i+k, and the concatenation of two sequences xi..j and xj+1..k (with i \u2264 j < k) is noted xi..j .xj+1..k. Random variables are noted \u03be and their realizations are noted \u03be. We note \u03be \u2208 \u03be the fact that \u03be is a realization of \u03be, and p(\u03be = \u03be) the probability that the random variable \u03be is realized to \u03be. Finally, we note E\u03be[f(\u03be)] the expected value of f(\u03be) which is defined by E\u03be[f(\u03be)] = \u2211 \u03be\u2208\u03be p(\u03be = \u03be) \u00b7 f(\u03be).\nInput Data of a DS-VRPTW. We consider a discrete time horizon [1, H] such that each online event or decision occurs at a discrete time t \u2208 [1, H], whereas each offline event or decision occurs at time t = 0. The DS-VRPTW is defined on a complete and directed graph G = (V,E). The set of vertices V = [0, n] is composed of a depot (vertex 0) and n customer regions (vertices 1 to n). To each arc (i, j) \u2208 E is associated a travel time ti,j \u2208 R\u22650, that is the time needed by a vehicle to travel from i to j, with ti,j 6= tj,i in general. To each customer region i \u2208 [1, n] is associated a load qi, a service duration di \u2208 [1, H] and a time window [ei, li] with ei, li \u2208 [1, H] and ei \u2264 li.\nThe set of all customer requests is R \u2286 [1, n]\u00d7 [0, H]. For each request (i, t) \u2208 R, t is the time when the request is revealed. When t = 0, the request is known before the online execution and it is said to be deterministic. When t > 0, the request is revealed during the online execution at time t and it is said to be online (or dynamic). There may be several requests for a same vertex i which are revealed at different times. During the online execution, we only know a subset of the requests of R (i.e., those which have already been revealed). However, for each time t \u2208 [1, H], we are provided a probability vector P t such that, for each vertex i \u2208 [1, n], P t[i] is the probability that a request is revealed for i at time t.\nThere are k vehicles and all vehicles have the same capacity Q.\nSolution of a DS-VRPTW. At the end of the time horizon, a solution is a subset of requests Ra \u2286 R together with k routes (one for each vehicle). Requests in Ra are said\nto be accepted, whereas requests in R \\ Ra are said to be rejected. The routes must satisfy the constraints of the classical VRPTW restricted to the subset Ra of accepted requests, i.e., each route must start at the depot at a time t \u2265 1 and end at the depot at a time t\u2032 \u2264 H , and for each accepted request (i, t) \u2208 Ra, there must be exactly one route that arrives at vertex i at a time t\u2032 \u2208 [ei, li] with a current load l \u2264 Q \u2212 qi and leaves vertex i at a time t\u2032\u2032 \u2265 t\u2032+ di. The goal is to minimize the number of rejected requests.\nAs not all requests are known at time 0, the solution cannot be computed offline, and it is computed during the online execution. More precisely, at each time t \u2208 [1, H], an action at is computed. Each action at is composed of two parts: first, for each request (i, t) \u2208 R revealed at time t, the action at must either accept the request or reject it; second, for each vehicle, the action at must give operational decisions for this vehicle at time t (i.e., service a request, travel towards a vertex, or wait at its current position). Before the online execution (at time 0), some decisions are computed offline. Therefore, we also have to compute a first action a0.\nA solution is a sequence of actions a0..H which covers the whole time horizon. This sequence must satisfy VRPTW constraints, i.e., the actions of a0..H must define k routes such that each request accepted in a0..H is served once by one of these routes within the time window associated with the served vertex and without violating capacity constraints. We define the objective function \u03c9 such that \u03c9(a0..t) is +\u221e if a0..t does not satisfy VRPTW constraints, and \u03c9(a0..t) is the number of requests rejected in a0..t otherwise. Hence, a solution is a sequence a0..H such that \u03c9(a0..H) is minimal at the end of the horizon.\nStochastic program. There are different notations used for formulating stochastic programs; we mainly use those from [8]. For each time t \u2208 [1, H], we have a vector of random variables \u03bet such that, for each vertex i \u2208 [1, n], \u03bet[i] is realized to 1 if a request for i is revealed at time t, and to 0 otherwise. The probability distribution of \u03bet is defined by P t, i.e., p(\u03bet[i] = 1) = P t[i] and p(\u03bet[i] = 0) = 1\u2212P t[i]. We note \u03be1..t the random matrix composed of the random vectors \u03be1 to \u03bet. A realization \u03be1..H \u2208 \u03be1..H is called a scenario.\nAt each time t \u2208 [1, H], the action at must contain one accept or reject for each request which is revealed in \u03bet. Therefore, we note A(\u03bet) the set of all actions that contain an accept or a reject for each vertex i \u2208 [1, n] such that \u03bet[i] = 1. Of course, these actions also contain other decisions related to the k vehicles. We also note A(\u03bet1..t2) the sequence of sets < A(\u03bet1), . . . , A(\u03bet2) > where t1 \u2264 t2.\nHence, at each time t, given the sequence a0..t\u22121 of past actions, the best action at is obtained by solving the multistage stochastic problem defined by eq. (1):\nat = argmin at\u2208A(\u03bet)\nE\u03bet+1 [\nmin at+1\u2208A(\u03bet+1)\nE\u03bet+2 [ \u00b7 \u00b7 \u00b7 min\naH\u22121\u2208A(\u03beH\u22121) E\u03beH\n[ min\naH\u2208A(\u03beH ) \u03c9(a0..H)\n] \u00b7 \u00b7 \u00b7 ]]\n(1) Note that this multistage stochastic problem is different from the two-stage stochastic\nproblem defined by eq. (2):\nat = argmin at\u2208A(\u03bet) E\u03bet+1..H [ min at+1..H\u2208A(\u03bet+1..H) \u03c9(a0..H)] (2)\nIndeed, eq. (1) enforces nonanticipativity constraints so that, at each time t\u2032 > t, we consider the action at \u2032 which minimizes the expectation with respect to \u03bet \u2032 only, without considering the possible realizations of \u03bet \u2032+1..H . Eq. (2) does not enforce these constraints and considers the best sequence at+1..H for each realization \u03bet+1..H \u2208 \u03bet+1..H . Therefore, eq. (1) may lead to a larger expectation of \u03c9 than eq. (2), as it is more constrained. However, the expectation computed in eq. (1) leads to better decisions in our context where some requests are not revealed at time t. This is illustrated in Fig. 1."}, {"heading": "3 Related Work", "text": "The first D-VRP is proposed in [29], which introduces a single vehicle Dynamic Diala-Ride Problem (D-DARP) in which customer requests appear dynamically. Then, [20] introduced the concept of immediate requests that must be serviced as soon as possible, implying a replanning of the current vehicle route. Complete reviews on D-VRP may be found in [21,18]. In this section, we more particularly focus on stochastic DVRP. [18] classifies approaches for stochastic D-VRP in two categories, either based on stochastic modeling or on sampling. Stochastic modeling approaches formally capture the stochastic nature of the problem, so that solutions are computed in the light of an overall stochastic context. Such holistic approaches usually require strong assumptions and efficient computation of complex expected values. Sampling approaches try to capture stochastic knowledge by sampling scenarios, so that they tend to be more focused on local stochastic evidences. Their local decisions however allow sample-based methods to scale up to larger problem instances, even under challenging timing constraints.\nAlgorithm 1: The ChooseRequest-\u03b5 Expectation Algorithm 1 for at \u2208 A(\u03bet) do f(at)\u2190 0 Generate a set S of \u03b1 scenarios using Monte Carlo\nsampling 2 for each scenario s \u2208 S and each action at \u2208 A(\u03bet) do 3 f(at)\u2190 f(at)+cost of (approximate) solution to scenario s starting with at\n4 return argminat\u2208A(\u03bet) f(a t)\nOne usually needs to find a good compromise between having a high number of scenarios, providing a better representation of the real distributions, and a more restricted number of these leading to less computational effort.\n[7] studies the DS-VRPTW and introduces the Multiple Scenario Approach (MSA). A key element of MSA is an adaptive memory that stores a pool of solutions. Each solution is computed by considering a particular scenario which is optimized for a few seconds. The pool is continuously populated and filtered such that all solutions are consistent with the current system state. Another important element of MSA is the ranking function used to make operational decisions involving idle vehicles. The authors designed 3 algorithms for that purpose:\n\u2013 Expectation [3,4] samples a set of scenarios and selects the next request to be serviced by considering its average cost on the sampled set of scenarios. Algorithm 1 [27] depicts how it chooses the next action at to perform. It requires an optimization for each action at \u2208 A(\u03bet) and each scenario s \u2208 S (lines 3-4), which is computationally very expensive, even with a heuristic approach. \u2013 Regret [3,6] approximates the expectation algorithm by recognizing that, given a solution sol\u2217s to a particular scenario s, it is possible to compute a good approximation of the local loss inquired by performing another action than the next planned one in sol\u2217s . \u2013 Consensus [4,7] selects the request that appears the most frequently as the next serviced request in the solution pool.\nQuite similar to the consensus algorithm is the Dynamic Sample Scenario Hedging Heuristic introduced by [14] for the stochastic VRP. Also, [15] designed a Tabu Search heuristic for the DS-VRPTW and introduced a vehicle-waiting strategy computed on a future request probability threshold in the near region. Finally, [5] extends MSA with waiting and relocation strategies so that the vehicles are now able to relocate to promising but unrequested yet vertices. As the performances of MSA has been demonstrated in several studies [5,12,22,19], it is still considered as a state-of-the-art method for dealing with DS-VRPTW.\nOther studies of particular interest for our paper are [13], on the dynamic and stochastic pickup and delivery problem, and [22], on the DS-DARP. Both consider local search based algorithms. Instead of a solution pool, they exploit one single solution that minimizes the expected cost over a set of scenarios. However, in order to limit computational effort, only near future requests are sampled within each scenario. Although the approach of [22] is similar to the one of [13], the set of scenarios considered is reduced to one scenario. Although these later papers show some similarities with the\napproach we propose, they do not provide any mathematical motivation and analysis of their methods."}, {"heading": "4 The global Stochastic Assessment decision rule", "text": "The two-stage stochastic problem defined by eq. (2) may be solved by a sampling solving method such as MSA, which solves a deterministic VRPTW for each possible scenario (i.e., realization of the random variables) and selects the action at which minimizes the sum of all minimum objective function values weighted by scenario probabilities. However, we have shown in Section 2 that eq. (2) does not enforce nonanticipativity constraints because the different deterministic VRPTW are solved independently. To enforce nonanticipativity constraints while enabling sampling methods, we push these constraints in the computation of the optimal solutions for all different scenarios: Instead of computing these different optimal solutions independently, we propose to compute them all together so that we can ensure that whenever two scenarios share a same prefix of realizations, the corresponding actions are enforced to be equal.\nAt each time t \u2208 [0, H], let r be the number of different possible realizations of \u03bet+1..H , and let us note \u03bet+1..H1 , . . . , \u03be t+1..H r these realizations. Given the sequence a0..t\u22121 of past actions, we choose action at by using eq. (3)\nat = argmin at\u2208A(\u03bet) Q(a0..t, {\u03bet+1..H1 , . . . , \u03bet+1..Hr }) (3)\nwhich is called the deterministic equivalent form of eq. (1). Q(a0..t, {\u03bet+1..H1 , . . . , \u03bet+1..Hr }) solves the deterministic optimization problem\nmin at+1..H1 \u2208A(\u03be t+1..H 1 ),...,a t+1..H r \u2208A(\u03bet+1..Hr ) r\u2211 i=1 p(\u03bet+1..H=\u03bet+1..Hi ) \u00b7 \u03c9(a 0..t.at+1..Hi ) (4)\ns.t. (\u03bet+1..t \u2032 i = \u03be t+1..t\u2032 j )\u21d2 (a t+1..t\u2032 i = a t+1..t\u2032 j ), \u2200t \u2032 \u2208 [t+ 1, H], \u2200i, j \u2208 [1, r] (5)\nThe nonanticipativity constraints (5) state that, when 2 realizations \u03bet+1..Hi and \u03be t+1..H j share a same prefix from t+ 1 to t\u2032, the corresponding actions must be equal [23]. Solving eq. (3) is computationally intractable for two reasons. First, since the number r of possible realizations of \u03bet+1..H is exponential in the number of vertices and in the remaining horizon size H \u2212 t, considering every possible scenario is intractable in practice. We therefore consider a smaller set of \u03b1 scenarios S = {s1, ..., s\u03b1} such that each scenario si \u2208 S is a realization of \u03bet+1..H , i.e., \u2200i \u2208 [1, \u03b1], si \u2208 \u03bet+1..H . This set S is obtained by Monte Carlo sampling [2]. All elements of S share the same probability, i.e., p(\u03bet+1..H = s1) = . . . = p(\u03bet+1..H = s\u03b1).\nSecond, solving eq. (3) basically involves solving to optimality problemQ for each possible action at \u2208 A(\u03bet). Each problem Q involves solving a VRPTW for each possible scenario of S, while ensuring nonanticipativity constraints between the different solutions. As the VRPTW problem is anNP-hard problem, we propose to compute an upper boundQ ofQ based on a given sequence at+1..HR of future route actions. Because we impose the sequence at+1..HR , the set of possible actions at time t is limited to those\ndirectly compatible with it, denoted A\u0303(\u03bet, at+1..HR ) \u2286 A(\u03bet). That limitation enforces \u03c9(a0..H) < +\u221e. This finally leads to the GSA decision rule:\n(GSA) at = argmin at\u2208A\u0303(\u03bet,at+1..HR ) Q(a0..t, at+1..HR , S) (6)\nwhich, provided realization \u03bet, sampled scenarios S and future route actions at+1..HR , selects the action at that minimizes the expected approximate cost over scenarios S. Notice that almost all the anticipative efficiency of the GSA decision rule relies on the sequence at+1..HR , which directly affects the quality of the upper bound Q.\nSequence at+1..HR of future route actions. This sequence is used to compute an upper bound ofQ. For each time t\u2032 \u2208 [t+1, H], the route action at\u2032R only contains operational decisions related to vehicle routing (i.e., for each vehicle, travel towards a vertex, or wait at its current position) and does not contain decisions related to requests (i.e., request acceptance or rejection). The more flexible at \u2032\nR with respect to S, the better the bound Q. We describe in Section 5 how a flexible sequence is computed through local search.\nComputation of an upper bound Q of Q. Algorithm 2 depicts the computation of an upper bound Q of Q given a sequence at+1..HR of route actions consistent with past actions a0..t. For each scenario si of S, Algorithm 2 builds a sequence b0..H for si, which starts with a0..t, and whose end bt+1..H is computed from at+1..HR in a greedy way. At each time t\u2032 \u2208 [t + 1..H], each request revealed at time t\u2032 in scenario si is accepted if it is possible to modify bt\n\u2032..H so that one vehicle can service it; it is rejected otherwise. One can consider bt\n\u2032..H as being a set of vehicle routes, each defined by a sequence of planned vertices. Each planned vertex comes with specific decisions: a waiting time and whether a service is performed. In this context, trytoServe performs a deterministic linear time modification of bt\n\u2032..H such that (j, t\u2032) corresponds to the insertion of the vertex j in one of the routes defined by bt\n\u2032..H , at the best position with respect to VRPTW constraints and travel times, without modifying the order of the remaining vertices. At the end, Algorithm 2 returns the average number of rejected\nAlgorithm 2: The Q(a0..t, at+1..HR , S) approximation function 1 Precondition: at+1..HR is a sequence of route actions consistent with a 0..t 2 for each scenario si \u2208 S do 3 nbRejected [i]\u2190 0; b0..t \u2190 a0..t; bt+1..H \u2190 at+1..HR 4 for t\u2032 \u2208 [t+ 1..H] do 5 for each request (j, t\u2032) revealed at time t\u2032 for a vertex j in scenario si do 6 ct \u2032..H \u2190 trytoServe((j, t\u2032), bt \u2032..H) 7 if bt+1..t \u2032\u22121 \u00b7 ct \u2032..H is feasible then bt \u2032..H \u2190 ct \u2032..H 8 else add the decision reject(j,t\u2019) to bt \u2032 and increment nbRejected [i] 9 return 1|S| \u00b7 \u2211 si\u2208S nbRejected [i]\nrequests for all scenarios. Note that, when modifying a sequence of actions so that a request can be accepted (line 6), actions bt \u2032..H can be modified, but b0..t \u2032\u22121 are not modified. This ensures that Q preserves the nonanticipativity constraints. Indeed, the fact that two identical scenarios prefixes could be assigned two different subsequences of actions implies that either trytoServe((j, t\u2032), bt\n\u2032..H) is able to modify an action bt<t \u2032 or is a nondeterministic function. In both cases, there is a contradiction. Finally, notice that contrary to other local search methods based on Monte Carlo simulation as in [13,22], GSA considers the whole timing horizon when evaluating a first-stage solution against a scenario.\nComparison to MSA GSA has two major differences with MSA. Given a set of scenarios, GSA maintains only one solution, namely the sequence at+1..HR , that best suits to a pool of scenarios whilst MSA computes a set of solutions, each specialized to one scenario from the pool. Furthermore, by preserving nonanticipativity GSA approximates the multistage problem of equations (1,3). In contrary, MSA relaxes these constraints and therefore approximates the two-stage problem (2) [27].\nIn particular, given a pool of scenarios obtained by Monte Carlo sampling, MSA Expectation Algorithm 1 reformulates eq. (2) as a sample average approximation (SAA, [1,28]) problem. The SAA tackles each scenario as a separate deterministic problem. For a specific scenario \u03bet+1..H , it considers the recourse cost of a solution starting with actions a0..t. Because the scenarios are not linked by nonanticipativity constraints, two scenarios i and j that share the same prefix \u03bet+1..t \u2032 can actually be assigned two solutions performing completely different actions a0..t \u2032\ni and a 0..t\u2032 j , for some t \u2032 > t. The\nevaluation of action at over the set of scenarios is therefore too optimistic, leading to a suboptimal choice. By definition, the Regret algorithm approximates the Expectation algorithm. The Regret algorithm then also approximates a two-stage problem. The Consensus algorithm selects the most suggested action among plans of the pool. By selecting the most frequent action in the pool, Consensus somehow encourages nonanticipation. However, the nonanticipativity constraints are not enforced as each scenario is solved separately. Consensus also approximates a two-stage problem."}, {"heading": "5 Solving the Dynamic and Stochastic VRPTW", "text": "GSA alone does not permit to solve a DS-VRPTW instance. In this section, we now show how the decision rule, as defined in eq. 6, can be embedded in an online algorithm that solves the DS-VRPTW. Finally, we present the different waiting and relocation strategies we exploit, including a new waiting strategy."}, {"heading": "5.1 Embedding GSA", "text": "In order to solve the DS-VRPTW, we design Algorithm 3, which embeds the GSA decision rule.\nAlgorithm 3: LS-based GSA 1 Initialize S with \u03b1 scenarios and compute initial solution a1..HR w.r.t. known requests 2 t\u2190 1; 3 while real time has not reached the end of the time horizon do\n/* Beginning of the time unit */\n4 (at, at+1..HR )\u2190handleRequests(a 0..t\u22121, at..HR , \u03be t) 5 execute action at and update the pool S of scenarios w.r.t. to \u03bet /* Remaining of the time unit */ 6 while real time has not reached the end of time unit t do 7 bt+1..HR \u2190 shakeSolution(a t+1..H R ) 8 ifQ(a0..t, bt+1..HR , S) < Q(a 0..t, at+1..HR , S) then a t+1..H R \u2190 b t+1..H R if the number of iterations since the last re-initialization of S is equal to \u03b2 then 9 Re-initialize the pool S of scenarios w.r.t. \u03bet+1..H\n10 t\u2190 t+ 1 /* Skip to next time unit */ 11 Function handleRequests(a0..t\u22121, at..HR , \u03bet) 12 b0..t\u22121 \u2190 a0..t\u22121; bt..H \u2190 at..HR 13 for each request revealed for a vertex j in realization \u03bet do 14 if we find, in less than \u03b4ins, how to modify bt..H s.t. request (j, t) is served then 15 modify bt..H to accept request (j, t) 16 else 17 modify bt..H to reject request (j, t)\n18 return (bt, bt+1..H)\nMain Algorithm. It is parameterized by: \u03b1 which determines the size of the pool S of scenarios; \u03b2 which determines the frequency for re-initializing S; and \u03b4ins which limits the time spent for trying to insert a request in a sequence.\nIt runs in real time. It is started before the beginning of the time horizon, in order to compute an initial pool S of \u03b1 scenarios and an initial solution a1..HR with respect to offline requests (revealed at time 0). It runs during the whole time horizon, and loops on lines 3 to 11. It is stopped when reaching the end of the time horizon. The real time is discretized in H time units, and the variable t represents the current time unit: It is incremented when real time exceeds the end of the tth time unit. In order to be correct, Algorithm 3 requires the real computation time of lines 4 to 11 to be smaller than the real time spent in one time unit. This is achieved by choosing suitable values for parameters \u03b1 and \u03b4ins.\nLines 4 and 5 describe what happens whenever the algorithm enters a new time unit: Function handleRequests (described below) chooses the next action at and updates at+1..HR ; Finally, S is updated such that it stays coherent with respect to realization \u03be\nt. Each scenario \u03bet..H \u2208 S is composed of a sequence of sampled requests. To each customer region i is associated an upper bound ri = min(l0\u2212 ti,0\u2212di, li\u2212 t0,i) on the time unit at which a request can be revealed in that region, like in [7]. That constraint prevents tricky or inserviceable requests to be sampled. At time t, a sampled request\n(i, t) which doesn\u2019t appear in \u03bet is either removed if t \u2265 ri or randomly delayed in \u03bet+1..H \u2208 S otherwise.\nThe algorithm spends the rest of the time unit to iterate over lines 7 to 10, in order to improve the sequence of future route actions at+1..HR . We consider a hill climbing strategy: The current solution at+1..HR is shaked to obtain a new candidate solution b t+1..H R , and if this solution leads to a better upper bound Q of Q, then it becomes the new current solution. Shaking is performed by the shakeSolution function. This function considers different neighborhoods, corresponding to the following move operators: relocate, swap, inverted 2-opt, and cross-exchange (see [16,26] for complete descriptions). As explained in Section 5.2, depending on the chosen waiting and relocation strategy, additional move operators are exploited. At each call to the shakeSolution function, the considered move operator is changed, such that the operators are equally selected one after another in the list. Every \u03b2 iterations, the pool S of scenarios is resampled (lines 9-10). This re-sampling introduces diversification as the upper bound computed by Q changes. We therefore do not need any other meta-heuristic such as Simulated Annealing.\nFunction handleRequest is called at the beginning of a new time unit t, to compute action at in light of online requests (if any). It implements the GSA decision rule defined in eq. (6). The function considers each request revealed at time t for a vertex j, in a sequential way. For each request, it tries to insert it into the sequence at..HR (i.e., modify the routes so that a vehicle visits j during its time window). As in shakeSolution, local search operations are performed during that computation. The time spent to find a feasible solution including the new request is limited to \u03b4ins. If such a feasible solution is found, then the request is accepted, otherwise it is rejected. If there are several online requests for the same discretized time t, we process these requests in their real-time order of arrival, and we assume that all requests are revealed at different real times."}, {"heading": "5.2 Waiting and Relocation strategies", "text": "As defined in section 2, a vehicle that just visited a vertex usually has the choice between traveling right away to the next planned vertex or first waiting for some time at its current position. Unlike in the static (and deterministic) case, in the dynamic (and stochastic) VRPTW these choices may have a significant impact on the solution quality.\nWaiting and relocation strategies have attracted a great interest on dynamic and stochastic VRP\u2019s. In this section, we present and describe how waiting and relocation strategies are integrated to our framework, including a new waiting strategy called relocation-only.\nRelocation strategies Studies in [8,9] already showed that for a dynamic VRP with no stochastic information, it is optimal to relocate the vehicle(s) either to the center (in case of single-vehicle) or to strategical points (multiple-vehicle case) of the service region. The idea evolved and has been successfully adapted to routing problems with customer stochastic information, in reoptimization approaches as well as sampling approaches.\nRelocation strategies explore solutions obtained when allowing a vehicle to move towards a customer vertex even if there is no request received for that vertex at the\ncurrent time slice. Doing so, one recognizes the fact that, in the context of dynamic and stochastic vehicle routing, a higher level of anticipation can be obtained by considering to reposition the vehicle after having serviced a request to a more stochastically fruitful location. Such a relocation strategy has already been applied to the DS-VRPTW in [5].\nWaiting strategies In a dynamic context, the planning of a vehicle usually contains more time than needed for traveling and servicing requests. When it finishes to service a request, a vehicle has the choice between waiting for some time at its location or leaving for the next planned vertex. A good strategy for deciding where and how long to wait can potentially help at anticipating future requests and hence increase the dynamic performances. We consider three existing waiting strategies and introduce a new one:\n\u2013 Drive-First (DF ): The basic strategy aims at leaving each serviced request as soon as possible, and possibly wait at the next vertex before servicing it if the vehicle arrives before its time window. \u2013 Wait-First (WF ): Another classical waiting strategy consists in delaying as much as possible the service time of every planned requests, without violating their time windows. After having serviced a request, the vehicle hence waits as long as possible before moving to the next planned request. \u2013 Custom-Wait (CW ): A more tailored waiting strategy aims at controlling the waiting time at each vertex, which becomes part of the online decisions. \u2013 Relocation-Only waiting (RO): In order to take maximum benefit of relocation strategy while avoiding the computational overhead due to additional decision variables involved in custom waiting, we introduce a new waiting strategy. It basically applies drive-first scheduling to every request and then applies wait-first waiting only to those requests that follow a relocation one. By doing so, a vehicle will try to arrive as soon as possible at a planned relocation request, and wait there as long as possible. In contrary, it will spend as less time as possible at non-relocation request vertices. Note that if it is not coupled to a relocation strategy, RO reduces to DF . Furthermore, RO also reduces to the dynamic waiting strategy described in [17] if we define the service zones as being delimited by relocation requests. However, our strategy differs by the fact that service zones in our approach are computed in light of stochastic information instead of geometrical considerations.\nDepending on the waiting strategy we apply and whether we use relocation or not, additional LS move operators are exploited. Specifically, among the waiting strategies, only custom-wait requires additional move operators aiming at either increasing or decreasing the waiting time at a random planned vertex. Relocation also requires two additional move operators that modify a given solution by either inserting or removing a relocation action at a random vertex."}, {"heading": "6 Experimentations", "text": "We now describe our experimentations and compare our results with those of the state of the art MSA algorithm of [7]."}, {"heading": "6.1 Algorithms", "text": "Different versions of Algorithm 3 have been experimentally assessed, depending on which waiting strategy is implemented and whether in addition we use the relocation strategy or not.\nSurprisingly, the wait-first waiting strategy, as well as its version including relocation, produced very bad results in comparison to other strategies, rejecting more than twice more online requests in average. Because of its computational overhead, the custom-wait strategy also produced bad results, even with relocation. For conciseness we therefore do not report these strategies in the result plots.\nThe 3 different versions of Algorithm 3 we thus consider are the following: GSAdf, which stands for GSA with drive-first waiting strategy, GSAdfr which stands for GSA with drive-first and relocation strategies, and finally GSAro with means GSA using relocation-only strategy. Recall that, by definition, the relocation-only strategy involves relocation. In addition to those 3 algorithms, as a baseline we consider the GLSdf algorithm, which stands for greedy local search with drive-first waiting. This algorithm is similar to the dynamic LS described in [22], to which we coupled a Simulated Annealing metaheuristic. In this algorithm, stochastic information about future request is not taken into account and a neighboring solution is solely evaluated by its total travel cost.\nFinally, GSA and GLS are compared to two MSA algorithms, namely MSAd and MSAc depending on whether the travel distance or the consensus function are used as ranking functions."}, {"heading": "6.2 Benchmarks", "text": "The selected benchmarks are borrowed from [7] which considers a set of benchmarks initially designed for the static and deterministic VRPTW in [25], each of these containing 100 customers. In our stochastic and dynamic context, each customer becomes a request region, where dynamic requests can occur during the online execution.\nThe original problems from [7] are divided into 4 classes of 15 instances. Each class is characterized by its degree of dynamism (DOD, the ratio of the number of dynamic requests revealed at time t > 0 over the number of a priori request known at time t = 0) and whether the dynamic requests are known early or lately along the online execution. The time horizon H = 480 is divided into 3 time slices. A request is said to be early if it is revealed during the first time slice t \u2208 [1, 160]. A late request is revealed during the second time slice t \u2208 [161, 320]. There is no request revealed during the third time slice t \u2208 [321, 480], but the vehicles can use it to perform customer operations.\nIn Class 1 there are many initial requests, many early requests and very few late requests. Class 2 instances have many initial requests, very few early requests and some late requests. Class 3 is a mix of classes 1 and 2. In Class 4, there are few initial requests, few early requests and many late requests. Finally, classes 1, 2 and 3 have an average DOD of 44%, whilst Class 4 has an average DOD of 57%.\nIn [5], a fifth class is proposed with a higher DOD of 81% in average. Unfortunately, we were not able to get those Class 5 instances. We complete these classes by providing a sixth class of instance, with DOD of 100%. Each instance hence contains no initial request, an early request with probability 0.3 and a late request with probability 0.7.\nFigure 2 summarizes the different instance classes."}, {"heading": "6.3 Results", "text": "Computations are performed on a cluster composed of 32 64-bits AMD Opteron(tm) Processor 6284 SE cores, with CPU frequencies ranging from 1400 to 2600 MHz. Executables were developed with C++ and compiled on a Linux Red Hat environment with GCC 4.4.7. Average results over 10 runs are reported. In [7], 25 minutes of offline computation are allocated to MSA, in order to decide the first online action at time t = 1. During online execution, each time unit within the time horizon was executed during 7.5 seconds by the simulation framework. In order to compensate the technology difference, we decided in this study to allow only 10 minutes of offline computation and 4 seconds of online computation per time unit. Thereafter, in order to highlight the contribution of the offline computation in our approach, the amount of time allowed at pre-computation is increased to 60 minutes, while each time unit still lasts 4 seconds. According to preliminary experiments, both the size of the scenario pool and the resampling rate are set to \u03b1 = \u03b2 = 150 for all our algorithms except GLSdf.\nFigure 3 gives a graphical representation of our algorithms results, through performance profiles. Performance profiles provide, for each algorithm, a cumulative distribution of its performance compared to other algorithms. For a given algorithm, a point (x, y) on its curve means that, in (100\u00b7y)% of the instances, this algorithm performed at most x times worse than the best algorithm on each instance taken separately. Instances are grouped by DOD and by offline computation time. Classes 1, 2 and 3 have a DOD of 44%, hence they are grouped together. An algorithm is strictly better than another one if its curve stays above the other algorithm\u2019s curve. For example on the 60min plot of Class 6, GLSdf is the worst algorithm in 95% of Class 6 instances, outperforming GSAdf in the remaining 5% (but not the other algorithms). On the other hand, provided these 60 minutes of offline computation, GSAro obtains the best results in 55% of the instances, whereas only 30% for GSAdf and GSAdfr. See [11] for a complete description of performance profiles. Detailed results are provided in the appendix.\nOur algorithms compare fairly with MSA, especially on lately dynamic instances of Class 4. Given more offline computation, our algorithms get stronger, although that MSA benefits of the same offline time in every plots. Surprisingly, GLSdf performs well compared to other algorithms on classes 1,2 and 3. The low DOD that characterizes these instances tends to lower the contribution of stochastic knowledge against the computational power of GLSdf. Indeed, approximating the stochastic evaluation function over 150 scenarios is about 103 times more expensive than GLSdf evaluation\nfunction. However, as the offline computation time and the DOD increase, stochastic algorithms tend to outperform their deterministic counterpart.\nWe notice that the relocation strategy gets stronger as the offline computation time increases. This is due to the computational overhead induced by relocation vertices. GSAdf is then the good choice under limited offline computation time. However, both GSAro and GSAdfr tend to outperform the other strategies when provided enough offline computation and high DOD.\nAs it contains no deterministic request, in Class 6 the offline computation is not applicable to those algorithms that does not exploit the relocation strategy, i.e. GLSdf and GSAdf. Class 6 shows that, despite the huge difference in the number of iterations performed by GLSdf on one hand and stochastic algorithms on the other, the laters clearly outperform GLSdf under fully dynamic instances. We also notice in this highly dynamic context that GSAro tends to outperform GSAdfr as offline computation increases, highlighting the anticipative contribution provided by the relocation-only strategy, centering waiting times on relocation vertices."}, {"heading": "7 Conclusions", "text": "We proposed GSA, a decision rule for dynamic and stochastic vehicle routing with time windows (DS-VRPTW), based on a stochastic programming heuristic approach. Existing related studies, such as MSA, simplify the problem as a two-stage problem by using sample average approximation. In contrary, the theoretical singularity of our method is to approximate a multistage stochastic problem through Monte Carlo sampling, using a heuristic evaluation function that preserves the nonanticipativity constraints. By maintaining one unique anticipative solution designed to be as flexible as possible according to a set of scenarios, our method differs in practice from MSA which computes as many solutions as scenarios, each being specialized for its associated scenario. Experimental results show that GSA produces competitive results with respect to state-of-the-art. This paper also proposes a new waiting strategy, relocation-only, aiming at taking full benefit of relocation strategy.\nIn a future study we plan to address a limitation of our solving algorithm which embeds GSA, namely the computational cost of its evaluation function. One possible direction would be to take more benefit of each evaluation, by spending much more computational effort in constructing neighboring solutions, e.g. by using Large Neighborhood Search [24]. Minimizing the operational cost, such as the total travel distance, is usually also important in stochastic VRPs. Studying the aftereffect when incorporating it as a second objective should be of worth. It is also necessary to consider other types of DS-VRPTW instances, such as problem sets closer to public or good transportation. Finally, the conclusions we made in section 2 about the shortcoming of a two-stage formulation (showed in Fig. 1) are theoretical only, and should be experimentally assessed."}, {"heading": "Acknowledgement", "text": "Christine Solnon is supported by the LABEX IMU (ANR-10-LABX-0088) of Universit\u00e9 de Lyon, within the program \"Investissements d\u2019Avenir\" (ANR-11-IDEX-0007) operated by the French National Research Agency (ANR). This research is also partially supported by the UCLouvain Action de Recherche Concert\u00e9e ICTM22C1."}, {"heading": "Appendix: Detailed experimental results", "text": "The present appendix provides detailed experimental results on the different instance classes.\nTables 1, 2, 3 and 4 show detailed results on each algorithms for classes 1-4, with both 10 and 60 minutes allowed at offline computation. Note that both MSAd and MSAc should only be compared with our algorithms when allowing 10 minutes at offline computation. Table 5 shows the results obtained on Class 6 problem instances. Since the instances belonging to Class 6 contain no deterministic request, offline computation can only be performed on these instance when allowing relocation."}], "references": [{"title": "The sample average approximation method for stochastic programs with integer recourse", "author": ["Shabbir Ahmed", "Alexander Shapiro"], "venue": "Submitted for publication,", "citeRegEx": "1", "shortCiteRegEx": "1", "year": 2002}, {"title": "Stochastic Simulation: Algorithms and Analysis: Algorithms and Analysis, volume 57", "author": ["S\u00f8 ren Asmussen", "Peter W Glynn"], "venue": null, "citeRegEx": "2", "shortCiteRegEx": "2", "year": 2007}, {"title": "Regrets only! online stochastic optimization under time constraints", "author": ["Russell Bent", "Pascal Van Hentenryck"], "venue": null, "citeRegEx": "3", "shortCiteRegEx": "3", "year": 2004}, {"title": "The Value of Consensus in Online", "author": ["Russell Bent", "Pascal Van Hentenryck"], "venue": "Stochastic Scheduling. ICAPS,", "citeRegEx": "4", "shortCiteRegEx": "4", "year": 2004}, {"title": "Waiting and Relocation Strategies in Online Stochastic Vehicle Routing", "author": ["Russell Bent", "Pascal Van Hentenryck"], "venue": null, "citeRegEx": "5", "shortCiteRegEx": "5", "year": 2007}, {"title": "Sub-optimality approximations. Principles and Practice of Constraint", "author": ["Russell Bent", "Irit Katriel", "Pascal Van Hentenryck"], "venue": null, "citeRegEx": "6", "shortCiteRegEx": "6", "year": 2005}, {"title": "Scenario-based planning for partially dynamic vehicle routing with stochastic customers", "author": ["Russell W Bent", "Pascal Van Hentenryck"], "venue": "Operations Research,", "citeRegEx": "7", "shortCiteRegEx": "7", "year": 2004}, {"title": "A stochastic and dynamic vehicle routing problem in the Euclidean plane", "author": ["DJ Bertsimas", "G Van Ryzin"], "venue": "Operations Research,", "citeRegEx": "8", "shortCiteRegEx": "8", "year": 1991}, {"title": "Stochastic and Dynamic Vehicle Routing in the Euclidean Plane with Multiple Capacitated Vehicles", "author": ["DJ Bertsimas", "G Van Ryzin"], "venue": "Operations Research,", "citeRegEx": "9", "shortCiteRegEx": "9", "year": 1993}, {"title": "The dial-a-ride problem (DARP): Variants, modeling issues and algorithms", "author": ["Jean-Fran\u00e7ois Cordeau", "Gilbert Laporte"], "venue": "4OR: A Quarterly Journal of Operations Research,", "citeRegEx": "10", "shortCiteRegEx": "10", "year": 2003}, {"title": "Benchmarking optimization software with performance profiles", "author": ["Elizabeth D Dolan", "Jorge J Mor\u00e9"], "venue": "Mathematical programming,", "citeRegEx": "11", "shortCiteRegEx": "11", "year": 2002}, {"title": "Dynamic and stochastic vehicle routing in practice", "author": ["Truls Flatberg", "Geir Hasle", "Oddvar Kloster", "Eivind J Nilssen", "Atle Riise"], "venue": "In Dynamic Fleet Management,", "citeRegEx": "12", "shortCiteRegEx": "12", "year": 2007}, {"title": "Anticipatory algorithms for same-day courier dispatching", "author": ["Gianpaolo Ghiani", "Emanuele Manni", "Antonella Quaranta", "Chefi Triki"], "venue": "Transportation Research Part E: Logistics and Transportation Review,", "citeRegEx": "13", "shortCiteRegEx": "13", "year": 2009}, {"title": "Solving a Dynamic and Stochastic Vehicle Routing Problem with a Sample Scenario Hedging Heuristic", "author": ["Lars M. Hvattum", "Arne L\u00f8 kketangen", "Gilbert Laporte"], "venue": "Transportation Science,", "citeRegEx": "14", "shortCiteRegEx": "14", "year": 2006}, {"title": "Exploiting Knowledge About Future Demands for Real-Time Vehicle Dispatching", "author": ["Soumia Ichoua", "Michel Gendreau", "Jean-Yves Potvin"], "venue": "Transportation Science,", "citeRegEx": "15", "shortCiteRegEx": "15", "year": 2006}, {"title": "Vehicle routing: handling edge exchanges", "author": ["Gerard A P Kindervater", "Martin W P Savelsbergh"], "venue": "Local search in combinatorial optimization,", "citeRegEx": "16", "shortCiteRegEx": "16", "year": 1997}, {"title": "Waiting strategies for the dynamic pickup and delivery problem with time windows", "author": ["Sne\u017eana Mitrovi\u0107-Mini\u0107", "Gilbert Laporte"], "venue": "Transportation Research Part B: Methodological,", "citeRegEx": "17", "shortCiteRegEx": "17", "year": 2004}, {"title": "A review of dynamic vehicle routing problems", "author": ["Victor Pillac", "Michel Gendreau", "Christelle Gu\u00e9ret", "Andr\u00e9s L Medaglia"], "venue": "European Journal of Operational Research,", "citeRegEx": "18", "shortCiteRegEx": "18", "year": 2013}, {"title": "An event-driven optimization framework for dynamic vehicle routing", "author": ["Victor Pillac", "Christelle Gu\u00e9ret", "Andr\u00e9s L. Medaglia"], "venue": "Decision Support Systems,", "citeRegEx": "19", "shortCiteRegEx": "19", "year": 2012}, {"title": "A dynamic programming solution to the single vehicle many-to-many immediate request dial-a-ride problem", "author": ["Harilaos N Psaraftis"], "venue": "Transportation Science,", "citeRegEx": "20", "shortCiteRegEx": "20", "year": 1980}, {"title": "Dynamic vehicle routing: Status and prospects", "author": ["Harilaos N Psaraftis"], "venue": "annals of Operations Research,", "citeRegEx": "21", "shortCiteRegEx": "21", "year": 1995}, {"title": "Metaheuristics for the dynamic stochastic dial-a-ride problem with expected return transports", "author": ["M Schilde", "K F Doerner", "R F Hartl"], "venue": "Computers & operations research,", "citeRegEx": "22", "shortCiteRegEx": "22", "year": 2011}, {"title": "Ruszczy\\\u2019nski. Lectures on stochastic programming: modeling and theory, volume", "author": ["Alexander Shapiro", "Darinka Dentcheva", "Andrzej P"], "venue": null, "citeRegEx": "23", "shortCiteRegEx": "23", "year": 2009}, {"title": "Using constraint programming and local search methods to solve vehicle routing problems", "author": ["Paul Shaw"], "venue": "In Principles and Practice of Constraint", "citeRegEx": "24", "shortCiteRegEx": "24", "year": 1998}, {"title": "Algorithms for the vehicle routing and scheduling problems with time window constraints", "author": ["MM Solomon"], "venue": "Operations research,", "citeRegEx": "25", "shortCiteRegEx": "25", "year": 1987}, {"title": "A tabu search heuristic for the vehicle routing problem with soft time windows", "author": ["\u00c9 Taillard", "P Badeau"], "venue": null, "citeRegEx": "26", "shortCiteRegEx": "26", "year": 1997}, {"title": "Online stochastic optimization under time constraints, volume 177", "author": ["Pascal Van Hentenryck", "Russell Bent", "Eli Upfal"], "venue": null, "citeRegEx": "27", "shortCiteRegEx": "27", "year": 2009}, {"title": "The sample average approximation method applied to stochastic routing problems: a computational study", "author": ["Bram Verweij", "Shabbir Ahmed", "Anton J Kleywegt", "George Nemhauser", "Alexander Shapiro"], "venue": "Computational Optimization and Applications,", "citeRegEx": "28", "shortCiteRegEx": "28", "year": 2003}, {"title": "Computer control of the Rochester dial-a-ride system", "author": ["Nigel H M Wilson", "Neil J Colvin"], "venue": "Massachusetts Institute of Technology, Center for Transportation Studies,", "citeRegEx": "29", "shortCiteRegEx": "29", "year": 1977}, {"title": "A Multistage Stochastic Programming Approach to the Dynamic and Stochastic VRPTW", "author": ["Michael Saint-Guillain", "Yves Deville", "Christine Solnon"], "venue": "Submitted for publication,", "citeRegEx": "30", "shortCiteRegEx": "30", "year": 2015}], "referenceMentions": [{"referenceID": 29, "context": "This paper is an extended version of study [30], and contains additional detailed experimental results.", "startOffset": 43, "endOffset": 47}, {"referenceID": 9, "context": "In many countries, authorities try to set up dial-a-ride services, but escalating operating costs and the complexity of satisfying all customer demands become rapidly unmanageable for solution methods based on human choices [10].", "startOffset": 224, "endOffset": 228}, {"referenceID": 6, "context": "We compare GSA with the stateof-the-art method MSA from [7], and provide a comprehensive experimental study that highlights the contributions of existing and new waiting and relocation strategies.", "startOffset": 56, "endOffset": 59}, {"referenceID": 7, "context": "There are different notations used for formulating stochastic programs; we mainly use those from [8].", "startOffset": 97, "endOffset": 100}, {"referenceID": 4, "context": "g h i j t=1 [5,5] [7,7] [9,9]", "startOffset": 12, "endOffset": 17}, {"referenceID": 4, "context": "g h i j t=1 [5,5] [7,7] [9,9]", "startOffset": 12, "endOffset": 17}, {"referenceID": 6, "context": "g h i j t=1 [5,5] [7,7] [9,9]", "startOffset": 18, "endOffset": 23}, {"referenceID": 6, "context": "g h i j t=1 [5,5] [7,7] [9,9]", "startOffset": 18, "endOffset": 23}, {"referenceID": 8, "context": "g h i j t=1 [5,5] [7,7] [9,9]", "startOffset": 24, "endOffset": 29}, {"referenceID": 8, "context": "g h i j t=1 [5,5] [7,7] [9,9]", "startOffset": 24, "endOffset": 29}, {"referenceID": 6, "context": "[7,7] [9,9] [5,5] Time 2 3 4 5 6 7 8 9 Scenario \u03be 1 \u2205 \u2205 {d, e, f} \u2205 \u2205 \u2205 \u2205 \u2205 Scenario \u03be 2 \u2205 \u2205 {g, h, i} \u2205 \u2205 \u2205 \u2205 \u2205", "startOffset": 0, "endOffset": 5}, {"referenceID": 6, "context": "[7,7] [9,9] [5,5] Time 2 3 4 5 6 7 8 9 Scenario \u03be 1 \u2205 \u2205 {d, e, f} \u2205 \u2205 \u2205 \u2205 \u2205 Scenario \u03be 2 \u2205 \u2205 {g, h, i} \u2205 \u2205 \u2205 \u2205 \u2205", "startOffset": 0, "endOffset": 5}, {"referenceID": 8, "context": "[7,7] [9,9] [5,5] Time 2 3 4 5 6 7 8 9 Scenario \u03be 1 \u2205 \u2205 {d, e, f} \u2205 \u2205 \u2205 \u2205 \u2205 Scenario \u03be 2 \u2205 \u2205 {g, h, i} \u2205 \u2205 \u2205 \u2205 \u2205", "startOffset": 6, "endOffset": 11}, {"referenceID": 8, "context": "[7,7] [9,9] [5,5] Time 2 3 4 5 6 7 8 9 Scenario \u03be 1 \u2205 \u2205 {d, e, f} \u2205 \u2205 \u2205 \u2205 \u2205 Scenario \u03be 2 \u2205 \u2205 {g, h, i} \u2205 \u2205 \u2205 \u2205 \u2205", "startOffset": 6, "endOffset": 11}, {"referenceID": 4, "context": "[7,7] [9,9] [5,5] Time 2 3 4 5 6 7 8 9 Scenario \u03be 1 \u2205 \u2205 {d, e, f} \u2205 \u2205 \u2205 \u2205 \u2205 Scenario \u03be 2 \u2205 \u2205 {g, h, i} \u2205 \u2205 \u2205 \u2205 \u2205", "startOffset": 12, "endOffset": 17}, {"referenceID": 4, "context": "[7,7] [9,9] [5,5] Time 2 3 4 5 6 7 8 9 Scenario \u03be 1 \u2205 \u2205 {d, e, f} \u2205 \u2205 \u2205 \u2205 \u2205 Scenario \u03be 2 \u2205 \u2205 {g, h, i} \u2205 \u2205 \u2205 \u2205 \u2205", "startOffset": 12, "endOffset": 17}, {"referenceID": 28, "context": "The first D-VRP is proposed in [29], which introduces a single vehicle Dynamic Diala-Ride Problem (D-DARP) in which customer requests appear dynamically.", "startOffset": 31, "endOffset": 35}, {"referenceID": 19, "context": "Then, [20] introduced the concept of immediate requests that must be serviced as soon as possible, implying a replanning of the current vehicle route.", "startOffset": 6, "endOffset": 10}, {"referenceID": 20, "context": "Complete reviews on D-VRP may be found in [21,18].", "startOffset": 42, "endOffset": 49}, {"referenceID": 17, "context": "Complete reviews on D-VRP may be found in [21,18].", "startOffset": 42, "endOffset": 49}, {"referenceID": 17, "context": "[18] classifies approaches for stochastic D-VRP in two categories, either based on stochastic modeling or on sampling.", "startOffset": 0, "endOffset": 4}, {"referenceID": 6, "context": "[7] studies the DS-VRPTW and introduces the Multiple Scenario Approach (MSA).", "startOffset": 0, "endOffset": 3}, {"referenceID": 2, "context": "\u2013 Expectation [3,4] samples a set of scenarios and selects the next request to be serviced by considering its average cost on the sampled set of scenarios.", "startOffset": 14, "endOffset": 19}, {"referenceID": 3, "context": "\u2013 Expectation [3,4] samples a set of scenarios and selects the next request to be serviced by considering its average cost on the sampled set of scenarios.", "startOffset": 14, "endOffset": 19}, {"referenceID": 26, "context": "Algorithm 1 [27] depicts how it chooses the next action a to perform.", "startOffset": 12, "endOffset": 16}, {"referenceID": 2, "context": "\u2013 Regret [3,6] approximates the expectation algorithm by recognizing that, given a solution sol\u2217 s to a particular scenario s, it is possible to compute a good approximation of the local loss inquired by performing another action than the next planned one in sol\u2217 s .", "startOffset": 9, "endOffset": 14}, {"referenceID": 5, "context": "\u2013 Regret [3,6] approximates the expectation algorithm by recognizing that, given a solution sol\u2217 s to a particular scenario s, it is possible to compute a good approximation of the local loss inquired by performing another action than the next planned one in sol\u2217 s .", "startOffset": 9, "endOffset": 14}, {"referenceID": 3, "context": "\u2013 Consensus [4,7] selects the request that appears the most frequently as the next serviced request in the solution pool.", "startOffset": 12, "endOffset": 17}, {"referenceID": 6, "context": "\u2013 Consensus [4,7] selects the request that appears the most frequently as the next serviced request in the solution pool.", "startOffset": 12, "endOffset": 17}, {"referenceID": 13, "context": "Quite similar to the consensus algorithm is the Dynamic Sample Scenario Hedging Heuristic introduced by [14] for the stochastic VRP.", "startOffset": 104, "endOffset": 108}, {"referenceID": 14, "context": "Also, [15] designed a Tabu Search heuristic for the DS-VRPTW and introduced a vehicle-waiting strategy computed on a future request probability threshold in the near region.", "startOffset": 6, "endOffset": 10}, {"referenceID": 4, "context": "Finally, [5] extends MSA with waiting and relocation strategies so that the vehicles are now able to relocate to promising but unrequested yet vertices.", "startOffset": 9, "endOffset": 12}, {"referenceID": 4, "context": "As the performances of MSA has been demonstrated in several studies [5,12,22,19], it is still considered as a state-of-the-art method for dealing with DS-VRPTW.", "startOffset": 68, "endOffset": 80}, {"referenceID": 11, "context": "As the performances of MSA has been demonstrated in several studies [5,12,22,19], it is still considered as a state-of-the-art method for dealing with DS-VRPTW.", "startOffset": 68, "endOffset": 80}, {"referenceID": 21, "context": "As the performances of MSA has been demonstrated in several studies [5,12,22,19], it is still considered as a state-of-the-art method for dealing with DS-VRPTW.", "startOffset": 68, "endOffset": 80}, {"referenceID": 18, "context": "As the performances of MSA has been demonstrated in several studies [5,12,22,19], it is still considered as a state-of-the-art method for dealing with DS-VRPTW.", "startOffset": 68, "endOffset": 80}, {"referenceID": 12, "context": "Other studies of particular interest for our paper are [13], on the dynamic and stochastic pickup and delivery problem, and [22], on the DS-DARP.", "startOffset": 55, "endOffset": 59}, {"referenceID": 21, "context": "Other studies of particular interest for our paper are [13], on the dynamic and stochastic pickup and delivery problem, and [22], on the DS-DARP.", "startOffset": 124, "endOffset": 128}, {"referenceID": 21, "context": "Although the approach of [22] is similar to the one of [13], the set of scenarios considered is reduced to one scenario.", "startOffset": 25, "endOffset": 29}, {"referenceID": 12, "context": "Although the approach of [22] is similar to the one of [13], the set of scenarios considered is reduced to one scenario.", "startOffset": 55, "endOffset": 59}, {"referenceID": 22, "context": "H j share a same prefix from t+ 1 to t\u2032, the corresponding actions must be equal [23].", "startOffset": 81, "endOffset": 85}, {"referenceID": 1, "context": "This set S is obtained by Monte Carlo sampling [2].", "startOffset": 47, "endOffset": 50}, {"referenceID": 12, "context": "Finally, notice that contrary to other local search methods based on Monte Carlo simulation as in [13,22], GSA considers the whole timing horizon when evaluating a first-stage solution against a scenario.", "startOffset": 98, "endOffset": 105}, {"referenceID": 21, "context": "Finally, notice that contrary to other local search methods based on Monte Carlo simulation as in [13,22], GSA considers the whole timing horizon when evaluating a first-stage solution against a scenario.", "startOffset": 98, "endOffset": 105}, {"referenceID": 26, "context": "In contrary, MSA relaxes these constraints and therefore approximates the two-stage problem (2) [27].", "startOffset": 96, "endOffset": 100}, {"referenceID": 0, "context": "(2) as a sample average approximation (SAA, [1,28]) problem.", "startOffset": 44, "endOffset": 50}, {"referenceID": 27, "context": "(2) as a sample average approximation (SAA, [1,28]) problem.", "startOffset": 44, "endOffset": 50}, {"referenceID": 6, "context": "To each customer region i is associated an upper bound ri = min(l0\u2212 ti,0\u2212di, li\u2212 t0,i) on the time unit at which a request can be revealed in that region, like in [7].", "startOffset": 163, "endOffset": 166}, {"referenceID": 15, "context": "This function considers different neighborhoods, corresponding to the following move operators: relocate, swap, inverted 2-opt, and cross-exchange (see [16,26] for complete descriptions).", "startOffset": 152, "endOffset": 159}, {"referenceID": 25, "context": "This function considers different neighborhoods, corresponding to the following move operators: relocate, swap, inverted 2-opt, and cross-exchange (see [16,26] for complete descriptions).", "startOffset": 152, "endOffset": 159}, {"referenceID": 7, "context": "Relocation strategies Studies in [8,9] already showed that for a dynamic VRP with no stochastic information, it is optimal to relocate the vehicle(s) either to the center (in case of single-vehicle) or to strategical points (multiple-vehicle case) of the service region.", "startOffset": 33, "endOffset": 38}, {"referenceID": 8, "context": "Relocation strategies Studies in [8,9] already showed that for a dynamic VRP with no stochastic information, it is optimal to relocate the vehicle(s) either to the center (in case of single-vehicle) or to strategical points (multiple-vehicle case) of the service region.", "startOffset": 33, "endOffset": 38}, {"referenceID": 4, "context": "Such a relocation strategy has already been applied to the DS-VRPTW in [5].", "startOffset": 71, "endOffset": 74}, {"referenceID": 16, "context": "Furthermore, RO also reduces to the dynamic waiting strategy described in [17] if we define the service zones as being delimited by relocation requests.", "startOffset": 74, "endOffset": 78}, {"referenceID": 6, "context": "We now describe our experimentations and compare our results with those of the state of the art MSA algorithm of [7].", "startOffset": 113, "endOffset": 116}, {"referenceID": 21, "context": "This algorithm is similar to the dynamic LS described in [22], to which we coupled a Simulated Annealing metaheuristic.", "startOffset": 57, "endOffset": 61}, {"referenceID": 6, "context": "The selected benchmarks are borrowed from [7] which considers a set of benchmarks initially designed for the static and deterministic VRPTW in [25], each of these containing 100 customers.", "startOffset": 42, "endOffset": 45}, {"referenceID": 24, "context": "The selected benchmarks are borrowed from [7] which considers a set of benchmarks initially designed for the static and deterministic VRPTW in [25], each of these containing 100 customers.", "startOffset": 143, "endOffset": 147}, {"referenceID": 6, "context": "The original problems from [7] are divided into 4 classes of 15 instances.", "startOffset": 27, "endOffset": 30}, {"referenceID": 0, "context": "A request is said to be early if it is revealed during the first time slice t \u2208 [1, 160].", "startOffset": 80, "endOffset": 88}, {"referenceID": 4, "context": "In [5], a fifth class is proposed with a higher DOD of 81% in average.", "startOffset": 3, "endOffset": 6}, {"referenceID": 0, "context": "DOD t = 0 t \u2208 [1, 160] t \u2208 [161, 320] t \u2208 [321, 480] Class 1,2,3 44% P [i] = 0.", "startOffset": 14, "endOffset": 22}, {"referenceID": 6, "context": "In [7], 25 minutes of offline computation are allocated to MSA, in order to decide the first online action at time t = 1.", "startOffset": 3, "endOffset": 6}, {"referenceID": 10, "context": "See [11] for a complete description of performance profiles.", "startOffset": 4, "endOffset": 8}, {"referenceID": 0, "context": "Performance profiles on classes [1, 2 ,3], Class 4 and Class 6 problem instances", "startOffset": 32, "endOffset": 41}, {"referenceID": 1, "context": "Performance profiles on classes [1, 2 ,3], Class 4 and Class 6 problem instances", "startOffset": 32, "endOffset": 41}, {"referenceID": 2, "context": "Performance profiles on classes [1, 2 ,3], Class 4 and Class 6 problem instances", "startOffset": 32, "endOffset": 41}, {"referenceID": 23, "context": "by using Large Neighborhood Search [24].", "startOffset": 35, "endOffset": 39}], "year": 2015, "abstractText": "We consider a dynamic vehicle routing problem with time windows and stochastic customers (DS-VRPTW), such that customers may request for services as vehicles have already started their tours. To solve this problem, the goal is to provide a decision rule for choosing, at each time step, the next action to perform in light of known requests and probabilistic knowledge on requests likelihood. We introduce a new decision rule, called Global Stochastic Assessment (GSA) rule for the DS-VRPTW, and we compare it with existing decision rules, such as MSA. In particular, we show that GSA fully integrates nonanticipativity constraints so that it leads to better decisions in our stochastic context. We describe a new heuristic approach for efficiently approximating our GSA rule. We introduce a new waiting strategy. Experiments on dynamic and stochastic benchmarks, which include instances of different degrees of dynamism, show that not only our approach is competitive with state-of-the-art methods, but also enables to compute meaningful offline solutions to fully dynamic problems where absolutely no a priori customer request is provided.", "creator": "LaTeX with hyperref package"}}}