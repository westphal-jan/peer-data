{"id": "1503.00980", "review": {"conference": "arxiv", "VERSION": "v1", "DATE_OF_SUBMISSION": "3-Mar-2015", "title": "On memetic search for the max-mean dispersion problem", "abstract": "given one query $ u $ of $ } $ 5 and a distance o $ [ bits _ { \u0192 } ] _ { when \\ times ~ } $ among objects, the input - mean dispersion problem ( maxmeandp ) consists in scheduling a subset $ m $ item $ v $ such that applying combined dispersion ( or distance ) among \\ n elements is insufficient. assuming a useful parameter to formulate several relevant estimates, maxmeandp schemes known thus operate np - hard and thus computationally dense. in dependency equation, we present a highly conceptual memetic algorithm for designers which relies on solution methods and local routing to get high quality solutions. visual experiments on some set of 160 feasible computers with slightly almost 1000 elements previously used in performance literature show that the objective algorithm meets or matches the six explicitly known results for identifying instances quite a short exponential time, suffering only one exception, routinely achieving a subsequent best results being 100 \\ %. in 2009, both deliver four previous best results - satisfying the 60 most challenging instances. exploits running a time exceeding 40 new target implementations with relatively about 5000 elements are also presented. important key ingredients concerning their desired algorithm initially investigated to shed light on and operations affect the adverse effect the algorithm.", "histories": [["v1", "Tue, 3 Mar 2015 15:43:36 GMT  (59kb)", "http://arxiv.org/abs/1503.00980v1", "22 pages"]], "COMMENTS": "22 pages", "reviews": [], "SUBJECTS": "cs.AI", "authors": ["xiangjing lai", "jin-kao hao"], "accepted": false, "id": "1503.00980"}, "pdf": {"name": "1503.00980.pdf", "metadata": {"source": "CRF", "title": null, "authors": [], "emails": ["laixiangjing@gmail.com", "hao@info.univ-angers.fr"], "sections": [{"heading": null, "text": "ar X\niv :1\n50 3.\n00 98\n0v 1\n[ cs\n.A I]\n3 M\nGiven a set V of n elements and a distance matrix [dij ]n\u00d7n among elements, the max-mean dispersion problem (MaxMeanDP) consists in selecting a subset M from V such that the mean dispersion (or distance) among the selected elements is maximized. Being a useful model to formulate several relevant applications, MaxMeanDP is known to be NP-hard and thus computationally difficult. In this paper, we present a highly effective memetic algorithm for MaxMeanDP which relies on solution recombination and local optimization to find high quality solutions. Computational experiments on the set of 160 benchmark instances with up to 1000 elements commonly used in the literature show that the proposed algorithm improves or matches the published best known results for all instances in a short computing time, with only one exception, while achieving a high success rate of 100%. In particular, we improve 59 previous best results out of the 60 most challenging instances. Results on a set of 40 new large instances with 3000 and 5000 elements are also presented. The key ingredients of the proposed algorithm are investigated to shed light on how they affect the performance of the algorithm.\nKeywords: Dispersion Problem; Memetic Algorithm; Tabu Search; Heuristics."}, {"heading": "1 Introduction", "text": "Given a weighted complete graph G = (V,E,D), where V is the set of n vertices, E is the set of n\u00d7(n\u22121) 2\nedges, and D represents the set of edge weights dij (i 6= j), the generic equitable dispersion problem consists in selecting a subset M from V such that some objective function f defined on the subgraph\n\u2217 Corresponding author. Email addresses: laixiangjing@gmail.com (Xiangjing Lai), hao@info.univ-angers.fr (Jin-Kao Hao).\nPreprint submitted to Elsevier 4 March 2015\ninduced by M is optimized [20]. In the related literature, a vertex v \u2208 V is also called an element, and the edge weight dij \u2208 D is called the distance (or diversity) between elements i and j.\nAccording to the objective function to be optimized as well as the constraints on the cardinality of subset M , several specific equitable dispersion problem can be defined. At first, if the cardinality of M is fixed to a given number m, the related equitable dispersion problems include the following four classic variants: (1) the max-sum diversity problem, also known as the maximum diversity problem (MDP), which is to maximize the sum of distances among the selected elements [1,2,7,12,15,21,24]; (2) the max-min diversity problem that aims to maximize the minimum distance among the selected elements [5,19,22,23]; (3) the maximum minsum dispersion problem (MaxMinsumDP) that aims to maximize the minimum aggregate dispersion among the selected elements [3,20]; (4) the minimum differential dispersion problem (MinDiffDP) whose goal is to minimize the difference between the maximum and minimum aggregate dispersion among the selected elements to guarantee that each selected element has the approximately same total distance from the other selected elements [3,8,20]. In addition, when the cardinality of subset M is not fixed, i.e., the size of M is allowed to vary from 2 to n, the related equitable dispersion problems include the max-mean dispersion problem (MaxMeanDP) and the weighted MaxMeanDP [4,6,16,20].\nIn this study, we focus on MaxMeanDP which can be described as follows [20]. Given a set V of n elements and a distance matrix (dij)n\u00d7n where dij represents the distance between elements i and j and can take a positive or negative value, the max-mean dispersion problem consists in selecting a subset M (|M | is not fixed) from V such that the mean dispersion among the selected\nelements, i.e.,\n\u2211\ni,j\u2208M;i<j dij\n|M | , is maximized.\nMaxMeanDP can be naturally expressed as a quadratic integer program with binary variables xi that takes 1 if element i is selected and 0 otherwise [16,20], i.e.,\nMaximize f(s) =\n\u2211i=n\u22121 i=1 \u2211n j=i+1 dijxixj\n\u2211n i=1 xi\n(1)\nSubject to n \u2211\ni=1\nxi \u2265 2 (2)\nxi \u2208 {0, 1}, i = 1, 2, . . . , n; (3)\nwhere the constraint (2) guarantees that at least two elements are selected.\nIn addition to its theoretical signification as a strongly NP-hard problem [20], MaxMeanDP is notable for its ability to model a variety of real-world applications, such as web pages ranks [14], community mining [25], and others mentioned in [4].\nGiven the interest of MaxMeanDP, several useful solution approaches have been proposed in the literature to deal with this hard combinatorial optimization problem. First of all, Prokopyev et al. presented a mixed-integer 0-1 linear programming formulation and solved small instances with up to 100 elements with the CPLEX solver [20]. In the same work, they also introduced a GRASP method and made a comparison between the GRASP method and the MILP method to show the superiority of GRASP. Subsequently, Mart\u00ed and Sandoya proposed a GRASP with the path relinking method (GRASPPR) [16], and the computational results show that GRASP-PR outperforms the previously reported methods. Very recently, Della et al. reported a hybrid heuristic approach based on a quadratic knapsack formulation [6], and their computational experiment shows that the hybrid approach is superior to the GRASP-PR method. In another very recent work, Carrasco et al. proposed a diversified tabu search algorithm by combining a short-term tabu search procedure and a long-term tabu search procedure [4], and the computational results show that this algorithm clearly dominates the previous GRASP-PR method.\nIn this paper, we propose the first population-based memetic algorithm for solving MaxMeanDP (called MAMMDP). The proposed algorithm combines a random crossover operator to generate new offspring solutions and a tabu search method to find good local optima.\nThe performance of our algorithm is assessed on a set of 160 benchmark instances (20 \u2264 n \u2264 1000) commonly used in the literature and a set of additional 40 large-sized instances that we generate (n = 3000, 5000). For the first set of existing benchmarks, the experimental results show that the proposed algorithm is able to attain, in a short or very short computing time, all current best known results established by any existing algorithms, except for one instance. Furthermore, it can even improve the previous best known result for a number of these instances. The effectiveness of the proposed algorithm is also verified on much larger instances of the second set with 3000 and 5000 elements.\nThe remaining part of the paper is organized as follows. In Section 2, we describe in detail the general scheme and the ingredients of the proposed algorithm. In Section 3, we present the computational results based on the 200 benchmark instances and compare them with those of the existing state-of-theart algorithms from the literature. In Section 4, some important ingredients of the proposed algorithm are analyzed and discussed. Finally, we conclude the paper in the last Section."}, {"heading": "2 Memetic Algorithm for Max-Mean Dispersion Problem", "text": "Memetic search is a well-known metaheuristic framework which aims to provide the search with a desirable trade-off between intensification and diversification through the combined use of a crossover operator (to generate new promising solutions) and a local optimization procedure (to locally improve the generated solutions) [17,18]."}, {"heading": "2.1 General Procedure", "text": "The proposed memetic algorithm (denoted by MAMMDP) adopts the principles and guidelines of designing effective MA for discrete combinatorial problems [13]. Indeed, the overall performance of a memetic algorithm depends largely on the implementation of these two key components that need to be carefully designed according to the specific problem structure. Additionally, the proposed MAMMDP algorithm uses a population scheme which borrows from the path relinking method [11] to ensure a strong intensification search.\nThe general procedure of our MAMMDP algorithm is shown in Algorithm 1, where s\u2217 and sw respectively represent the best solution found so far and the worst solution in the population in terms of the objective value, and PairSet is the set of solution pairs (si, sj), which is initially composed of all the possible solution pairs (si, sj) in the population and is dynamically updated as the search progresses.\nOur MAMMDP algorithm starts with an initial population P (line 4) which includes p different solutions, where each of them is randomly generated and then improved by the tabu search procedure. After the initialization of population (Section 2.3), the algorithm enters a while loop (lines 11 to 25) to make a number of generations. At each generation, a solution pair (si, sj) is randomly selected from PairSet and then the crossover operator (line 14) is applied to the selected solution pair (si, sj) to generate a new solution so (Section 2.5). Subsequently, so is improved by the tabu search procedure (line 15) (Section 2.4). After that, a population updating rule is used to update the population (lines 20 to 24) (Section 2.6). Meanwhile, the PairSet is accordingly updated as follows: First, the solution pair (si, sj) is removed from PairSet (line 13); Then, if an offspring solution so replaces the worst solution sw in the population, all the solution pairs containing sw are removed from PairSet and all the solution pairs that can be generated by combining so with other solutions in the population are added into PairSet (lines 23 to 24). The while loop ends when PairSet becomes empty, then the population is recreated, while preserving the best solution (s\u2217) found so for in the new population (lines 4\nto 8), and the above while loop is repeated if the timeout limit is not reached.\nIt is worth noting that compared with the traditional random selection scheme, the proposed MAMMDP algorithm uses the set PairSet to contain the solution pairs of the population for crossover operations. This strategy ensures that every pair of solutions in the population is combined exactly once, favoring an more intensified search.\nAlgorithm 1 Memetic algorithm for Max-mean Dispersion Problem 1: Input: The set V = {v1, v2, . . . , vn} of n elements and the distance matrix D =\n[dij ]n\u00d7n, the population size p, the timeout limit tout. 2: Output: the best solution s\u2217 found 3: repeat 4: P = {s1, . . . , sp} \u2190 Population_Initialization(V ) /\u2217 Section 2.3 \u2217/ 5: if it is not in the first loop then 6: sw \u2190 arg min{f(si) : i = 1, . . . , p} 7: P \u2190 P \u222a {s\u2217} \\ {sw} 8: end if 9: s\u2217 \u2190 arg max{f(si) : i = 1, . . . , p} /\u2217 s\u2217 keeps the best solution found\n\u2217/ 10: PairSet \u2190 {(si, sj) : 1 \u2264 i < j \u2264 p} 11: while PairSet 6= \u2205 and time < tout do 12: Randomly pick a solution pair (si, sj) \u2208 PairSet 13: PairSet \u2190 PairSet \\ {(si, sj)} 14: so \u2190 CrossoverOperator(si, sj) /\u2217 Section 2.5 \u2217/ 15: so \u2190 TabuSearch(so) /\u2217 Section 2.4 \u2217/ 16: if f(so) > f(s\u2217) then 17: s\u2217 \u2190 so 18: end if 19: sw \u2190 arg min{f(si) : i = 1, . . . , p} 20: if so dose not exist in P and f(so) > f(sw) then 21: P \u2190 P \u222a {so} \\ {sw} 22: PairSet \u2190 PairSet \\ {(sw, sk) : sk \u2208 P} 23: PairSet \u2190 PairSet \u222a {(so, sk) : sk \u2208 P} 24: end if /\u2217 Section 2.6 \u2217/ 25: end while 26: until time \u2265 tout"}, {"heading": "2.2 Search Space and Solution Representation", "text": "Given a MaxMeanDP instance denoted by a set V of n elements as well as its distance matrix D = [dij]n\u00d7n, the search space \u2126 explored by our MAMMDP algorithm is composed of all possible subsets of V , i.e, \u2126 = {M : M \u2286 V }. Formally, a subset M of V can be expressed by a n-dimensional binary vector, (x1, x2, . . . , xn), where xi takes 1 if element i belongs to M , and 0 otherwise.\nIn other words, the search space \u2126 is composed of all possible n-dimensional binary vectors, i.e.,\n\u2126 = {(x1, x2, . . . , xn) : xi \u2208 {0, 1}, 1 \u2264 i \u2264 n}\nClearly, the size of the search space \u2126 is bounded by O(2n).\nFor any candidate solution s = (x1, x2, ..., xn) \u2208 \u2126, its quality is given by the objective value (f(s), Formula (1)) of the max-mean dispersion problem."}, {"heading": "2.3 Population Initialization", "text": "In our memetic algorithm, the initial population of p solutions is generated as follows. First, we generate p random solutions, where each component xi (i = 1, 2, . . . , n) of a solution (x1, x2, ..., xn) is randomly assigned a value from {0, 1} using a uniform probability distribution. Then, the tabu search method (see Section 2.4) is applied to each of the generated solutions to optimize them to a local optimum solution, and the resulting solutions are used to form the initial population."}, {"heading": "2.4 Local Optimization using Tabu Search", "text": "Local optimization is a key component of a memetic algorithm and ensures generally the role of an intensified search to locate high quality local optimum. In this study, we devise a tabu search (TS) method as the local optimization procedure which proves to be highly effective when when it is applied alone.\nGiven a neighborhood structure (N(s)) and a starting solution (s0), our tabu search procedure iteratively replaces the incumbent solution s by a best eligible neighboring solution (s \u2032\n) until the stopping condition is met, i.e., the best solution (sb) is not improved for \u03b1 consecutive iterations (called the depth of TS). At each iteration of TS, the performed move is recorded in the tabu list to prevent the reverse move from being performed for the next tt iterations. Here, tt is called the tabu tenure and controlled by a special tabu list management strategy. Note that in this tabu search method a move is identified to be eligible if it is not forbidden by the tabu list or it leads to a solution better than the best solution found so far in terms of the objective function value (aspiration criterion).\nThe general scheme of our TS method is described in Algorithm 2, and the neighborhood structure employed by our TS method and the tabu list management strategy are described in the following subsections.\nAlgorithm 2 TabuSearch(s0, N(s), \u03b1)\n1: Input: Input solution s0, neighborhood N(s), search depth \u03b1 2: Output: The best solution sb found during the tabu search process 3: s \u2190 s0 /* s is the current solution */ 4: sb \u2190 s /* sb is the best solution found so far */ 5: d = 0 /* d counts the consecutive iterations where sb is not updated */ 6: repeat 7: Choose a best eligible neighboring solution s\u2032 \u2208 N(s) 8: s \u2190 s\u2032\n9: Update tabu list 10: if f(s) > f(sb) then 11: sb \u2190 s, 12: d = 0 13: else 14: d = d+ 1 15: end if 16: until d = \u03b1 17: return sb"}, {"heading": "2.4.1 Move and Neighborhood", "text": "The neighborhood N1 of our tabu search algorithm is defined by the one-flip move operator which consists of changing the value of a single variable xi to its complementary vale 1 \u2212 xi. As such, given a solution s, the one-flip neighborhood N1(s) of s is composed of all possible solutions that can be obtained by applying the one-flip move to s. The size of the neighborhood N1(s) is thus bounded by O(n), where n is the number of components in s."}, {"heading": "2.4.2 Fast Neighborhood Evaluation Technique", "text": "In our TS method, we employ a fast neighborhood evaluation technique to examine the neighborhood N1. For this purpose, we maintain a n-dimensional vector W = (p1, p2, . . . , pn) to effectively calculate the move value (i.e., the change of objective value) of each possible move applicable to the current solution, where the entry pi represents the sum of distances between the element i and the selected elements for the current solution, i.e., pi = \u2211\nj\u2208M ;j 6=i dij , where M is the set of selected elements.\nGiven the current solution s, if an one-flip move is performed, i.e., a variable xi is flipped as xi \u2190 (1\u2212xi), then the move value \u2206i can be rapidly computed as follows:\n\u2206i =\n     \n    \n\u2212f(s)\n|M | + 1 +\npi\n|M | + 1 , for xi = 0; (4)\nf(s)\n|M | \u2212 1 \u2212\npi\n|M | \u2212 1 , for xi = 1; (5)\nwhere f(s) is the objective value of the current solution s and |M | is the number of selected elements in s. Subsequently, the vector W is accordingly updated as:\npj =\n\n \n \npj + dij, for xi = 0, j 6= i; (6) pj \u2212 dij, for xi = 1, j 6= i; (7) pj, for j = i; (8)\nNote that the vector W is initialized at the beginning of each call of TS with the complexity of O(n2), and is updated in O(n) after each move."}, {"heading": "2.4.3 Tabu List Management Strategy", "text": "In our TS procedure, we use a tabu list management strategy to dynamically tune the tabu tenure tt, which is adapted according to a technique proposed in [9] where the tabu tenure is given by a periodic step function. If the current iteration is y, then the tabu tenure of a move is denoted by tt(y).\nPrecisely, our tabu tenure function is defined, for each period, by a sequence of values (a1, a2, \u00b7 \u00b7 \u00b7 , aq+1) and a sequence of interval margins (y1, y2, \u00b7 \u00b7 \u00b7 , yq+1) such that for each y in [yi, yi+1 \u2212 1], tt(y) = ai + rand(2), where rand(2) denotes a random integer between 0 to 2. Here, q is fixed to 15, (a)i=1,\u00b7\u00b7\u00b7 ,15 = Tmax 8\n(1, 2, 1, 4, 1, 2, 1, 8, 1, 2, 1, 4, 1, 2, 1), where Tmax is a parameter which represents the maximum tabu tenure. Finally, the interval margins are defined by y1 = 1, yi+1 = yi + 5ai (i \u2264 15).\nThus, this function varies periodically and for each period, 15 tabu tenures are used dynamically, each being kept for a number of consecutive iterations. In principle, this function helps the tabu search procedure reach a desirable tradeoff between intensification and diversification during its search."}, {"heading": "2.5 Crossover Operator", "text": "In a memetic algorithm, the crossover operator is another essential ingredient whose main goal is to bring the search process to new promising search regions to diversify the search. In this work, we investigate two crossover operators for MaxMeanDP; the first one is the standard uniform crossover (denoted by\nAlgorithm 3 The Uniform Crossover Operator for MaxMeanDP\n1: Input: Two parent solutions s1 = (x11, x 1 2, . . . , x 1 n) and s 2 = (x21, x 2 2, . . . , x 2 n). 2: Output: Offspring solution so = (xo1, x o 2, . . . , x o n) 3: for i = 1 to n do 4: r \u2190 rand[0, 1) /* rand[0,1) denotes a random number between 0 and 1 */ 5: if r < 0.5 then 6: xoi \u2190 x 1 i 7: else 8: xoi \u2190 x 2 i\n9: end if 10: end for 11: return so = (xo1, x o 2, . . . , x o n)\nAlgorithm 4 The Greedy Crossover Operator for MaxMeanDP\n1: Input: Two parent solutions s1 and s2, and their subsets of selected elements are respectively denoted by M1 and M2 2: Output: Offspring solution so whose subset of selected elements is denoted by Mo 3: m \u2190 (|M1|+ |M2|)/2 /* Determine approximately the size of the set Mo */\n/*Generate a partial solution by preserving the common elements of M1 and M2 */\n4: Mo \u2190 M1 \u2229M2 5: M \u2032\n1 \u2190 M1 \\Mo, M \u2032\n2 \u2190 M2 \\Mo 6: while |Mo| < m do 7: if M \u2032\n1 6= \u2205 then 8: vo \u2190 argmax{\u2206f (v) : v \u2208 M \u2032\n1} /* \u2206f (v) represents the move value of adding element v to Mo */\n9: Mo \u2190 Mo \u222a {vo}, M \u2032 1 \u2190 M \u2032\n1 \\ {vo} 10: end if 11: if M \u2032\n2 6= \u2205 then 12: uo \u2190 argmax{\u2206f (u) : u \u2208 M \u2032\n2} 13: Mo \u2190 Mo \u222a {uo}, M \u2032 2 \u2190 M \u2032\n2 \\ {uo} 14: end if 15: end while 16: return so(i.e.,Mo)\nUC) operator, and the other is a specific greedy crossover (denoted by GC) operator.\nUC is very simple and is described in Algorithm 3. Given two parent solutions s1 = (x11, x 1 2, . . . , x 1 n) and s 2 = (x21, x 2 2, . . . , x 2 n), the value of each component xoi (i = 1, 2, . . . , n) of the offspring solution s o is randomly chosen from the set {x1i , x 2 i } with the same probability of 0.5. In spite of its simplicity, UC has shown to be quite robust and effective in many settings.\nThe dedicated GC operator is shown in Algorithm 4. Given two parent solutions s1 and s2 whose subsets of selected elements are respectively represented by M1 and M2, we first estimate the size of the set Mo of selected elements\nfor the offspring solution so such that the Hamming distances of so to s1 as well as s2 are approximately the same, i.e., m \u2190 |M1|+|M2|\n2 . Then a partial\nsolution is generated by preserving the common elements of M1 and M2, i.e., Mo \u2190 M1 \u2229M2. After that, we complete the offspring solution s\no in a step by step way by choosing in turn a best element from M1 \\ Mo or M2 \\ Mo and adding it to Mo. More specifically, we first choose an element (vo) that yields the largest move value from M1\\Mo and add it to Mo, then we choose another element (uo) that yields the largest move value from M2 \\ Mo and add it to Mo. We repeat these two steps until the size of Mo reaches m.\nIntuitively, UC is more disruptive than GC and thus is suitable for the purpose of diversifying the search. On the other hand, GC is more conservative and computationally more expensive. Based on the computational outcomes presented in Section 4.2, we adopt in this study the UC operator as the main crossover operator of our memetic algorithm, while using GC as a reference operator for our analysis on crossovers."}, {"heading": "2.6 Population Updating Rule", "text": "When a new offspring solution is generated by the crossover operator, it is first improved the tabu search procedure and then used to update the population according to the following rule. If the offspring solution is distinct from any existing solution in the population and is better than the worst solution in the population in terms of objective value, then the offspring solution replaces the worst solution of the population. Otherwise, the population is kept unchanged."}, {"heading": "3 Experimental Results and Comparisons", "text": "In this section, we run extensive computational experiments to assess the performance of our memetic algorithm based on a large number of MaxMeanDP benchmark instances."}, {"heading": "3.1 Benchmark Instances", "text": "Our computational experiments are carried out on two types of instances, namely Type I and Type II. The distances of Type I instances are randomly generated in the interval [\u221210, 10] with a uniform probability distribution, while the distances of Type II instances are generated from [\u221210,\u22125]\u222a [5, 10] with the same probability distribution.\nAdditionally, the set of benchmark instances used in our experiments is composed of two subsets. The first subset consists of 80 Type I instances and 80 Type II instances with the number of elements n ranging from 20 to 1000. These 160 instances were extensively adopted by the previous studies [4,6,16] and are available online at http://www.optsicom.es. The second subset consists of 20 Type I and 20 Type II large instances with n = 3000 or 5000. The source code of the generator used to obtain these 40 large instances will be available 1 ."}, {"heading": "3.2 Parameter Settings and Experimental Protocol", "text": "Our memetic algorithm relies on only three parameters: the population size p, the depth of tabu search \u03b1 and the maximum tabu tenure Tmax. For p and \u03b1, we follow [24] and set p = 10, \u03b1 = 50000 while setting Tmax = 120 empirically. This parameter setting is used for all the experiments reported in the paper. Even if fine-tuning these parameters would lead to better results, as we show below, our algorithm with this fixed setting is able to attain a high performance with respect to the state of the art results.\nOur memetic algorithm is programmed in C++ and compiled using g++ compiler with the \u2019-O2\u2019 flag 2 . All experiments are carried out on a computer with an Intel Xeon E5440 processor (2.83 GHz CPU and 2Gb RAM), running the Linux operating system. Following the DIMACS machine benchmark procedure 3 , our machine requires respectively 0.23, 1.42, and 5.42 seconds for the graphs r300.5, r400.5, r500.5.\nGiven the stochastic nature of our algorithm, we solve each tested problem instance 20 times, where the stopping condition is given by a cutoff time limit which depends on the size of the instances. Specifically, the cutoff limit tout is set to be 10 seconds for n \u2264 150, 100 seconds for n \u2208 [500, 1000], 1000 seconds for n = 3000, and 2000 seconds for n = 5000. As we discuss in Section 3.3, these time limits are significantly shorter than those used by the reference algorithms of the literature."}, {"heading": "3.3 Computational Results and Comparisons on Small and Medium Sized Instances", "text": "Our first experiment aims to evaluate the performance of our MAMMDP algorithm on the set of 160 popular instances with up to 1000 elements. The\n1 The source code of generating these instances will be available from our website. 2 Our best results and the source code of our algorithm will be made available online. 3 dmclique, ftp://dimacs.rutgers.edu/pub/dsj/clique, the benchmark procedure is complied by gcc compiler with the \u2019-O2\u2019 flag\ncomputational results of MAMMDP on the 60 medium sized instances are summarized in Table 1, whereas the results of the 100 small instances with n \u2264 150 are given in the Appendix 6 with the same computational statistics.\nThe first two columns of the table give respectively the name and size of instances. Column 3 indicates the best objective values (fpre) of the literature which are compiled from the best results yielded by three recent and best performing algorithms, namely GRASP-PR [16], a hybrid heuristic approach [6], and a diversified tabu search method [4] (from http://www.optsicom.es). Note that the previous best known results (fpre) are given with two decimal in the literature. In [4,16], the cutoff time limits are set to 90, 600, and 1800 seconds for instances with the size 500, 750, and 1000, respectively, and in [6] the cutoff time limits are respectively set to 60 and 600 seconds for the instances with the size 150 and 500. The GRASP-PR method was performed on a computer with an Intel Core Solo 1.4 GHz CPU with 3 GB RAM [16]; the hybrid heuristic approach was run on a computer with an Intel Core i5-3550 3.30GHz CPU with 4GB RAM [6] and the diversified tabu search method was run on a computer with an Intel Core 2 Quad CPU and 6 GB RAM [4].\nOur results are reported in columns 4 to 7, including the best objective value (fbest) yielded over 20 independent runs, the average objective value (favg), the success rate (SR) to achieve fbest, and the average computing time in seconds (t(s)) to achieve fbest. The last three rows Better, Equal, Worse of the table respectively show the number of instances for which our result is better, equal to and worse than fpre. The improved results are indicated in bold compared to fpre.\nFirst, one observes from Table 1 that our MAMMDP algorithm improves the previous best known result for all instances except for one instance for which our result matches the previous best known result. Therefore, these results clearly indicate the superiority of the proposed MAMMDP algorithm compared to the previous MaxMeanDP algorithms. Second, when examining the success rate of the algorithm, one can find that the MAMMDP algorithm achieves a success rate of 100% for all tested instances, which means a good robustness of our MAMMDP algorithm. Third, in terms of average computing time, one observes that for all instances our MAMMDP algorithm obtains its best result with an average time of less than 14 seconds, which are much shorter than those of the previous algorithms in the literature."}, {"heading": "3.4 Computational Results on Large-Scale Instances", "text": "In order to further assess the performance of the proposed MAMMDP algorithm on the large-scale instances, we run independently MAMMDP 20 times\nto solve each instance of the second set of benchmarks with n \u2265 3000, and report the computational statistics in Table 2 with the same information as in Table 1.\nTable 2 discloses that for the instances with 3000 elements, our MAMMDP algorithm reaches a success rate of at least 10/20, which is an interesting indicator as to its good performance for these instances. However, for the still larger instances with n = 5000, the success rate of the algorithm significantly varies between 4/20 and 19/20, which means that these large instances are clearly more difficult. Nevertheless, one observes that the difference between the best and average objective values is very small for all instances. These results can be served as reference lower bounds for future comparisons of new MaxMeanDP algorithms."}, {"heading": "4 Analysis and Discussions", "text": "In this section, we study some essential ingredients of the proposed algorithm to understand their impacts on the performance of the proposed algorithm."}, {"heading": "4.1 Effectiveness of the Tabu Search Procedure", "text": "First, to show the effectiveness of the underlying tabu search procedure of the proposed algorithm, we carry out an additional experiment on 30 representative instances, where each instance is independently solved 20 times by the tabu search procedure with randomly generated initial solutions. The computational results are summarized in Table 3, where f \u2217 and t(s) represent respectively the previous best known result and the average computing time over 20 runs, other symbols are the same as those in Table 1. Note that the improved results compared to the previous best known values fpre are indicated in bold.\nTable 3 discloses that our tabu search procedure alone is able to attain the previous best known result for the tested instances. Moreover, for all tested instances, the obtained average objective value (favg) is still better than the previous best known result (fpre) on 29 out of 30 instances. These results indicate that our tabu search method is quite effective with respect to the existing algorithms designed for MaxMeanDP. In terms of computational time, one observes that one run of the tabu search procedure takes on average less than 2 seconds for instances with n \u2264 1000, much shorter than those required\nby the state of the art algorithms [4,6,16]. To sum, this experiment shows that our tabu search procedure is highly effective compared with the existing state-of-the-art algorithms in the literature.\nIt should be mentioned that compared to the previous methods for MaxMeanDP, such as those in [4], the success of our tabu search method may be attributed to the combined use of the neighborhood N1, the fast neighborhood evaluation technique and its dynamic tabu list management strategy."}, {"heading": "4.2 Influence of the Crossover Operator", "text": "In this section, we show a study about the influence of the crossover operator on the performance of the proposed algorithm by comparing the uniform crossover (UC) operator and the greedy crossover (GC) operator. The experiment is carried out on a set of 40 large instance with n \u2265 3000, where the memetic algorithms with UC and GC are respectively performed 20 times\nfor each of the tested instances. The computational results of the both algorithms are summarized in Table 4, including the best (fbest) and average (favg) objective values obtained over 20 runs, the success rate (SR) and average computing time in seconds (t(s)) to achieve the associated fbest, where better results between these two algorithms are indicated in bold. The rows, Better, Equal, Worse denote respectively the number of instances for which an algorithm yields better, equal, worse results compared to the other algorithm. Finally, to verify whether there exists a significant difference between the two crossover operators in terms of the best and average objective values, the p-values from the non-parametric Friedman test are reported in the last row.\nOne observes from Table 4 that the UC and GC operators are comparable in the overall performance of the algorithm in terms of best and average results, which is confirmed by the Friedman test (p-values > 0.05). First, in terms of the best objective value, UC and GC yield respectively better result on 1 and 2 instances compared to another operator. Second, in terms of the average objective value, it can be found the UC operator produces a better and worse result respectively for 16 and 9 instances. As to the success rate and computing time, these two crossover operators also achieve similar performances. This experiment demonstrates that there is no dominance of one crossover over the other. Instead, they are complementary to solve different instances. One interesting future study would be to investigate the ways of using jointly these two operators with the search algorithm."}, {"heading": "4.3 Improvement of Memetic Algorithm Over the Tabu Search Procedure", "text": "As shown in Section 4.1, our tabu search procedure is very competitive compared to the existing algorithms in the literature. So it is interesting to know whether our MAMMDP algorithm has a significant improvement over its underlying local optimization (the tabu search) procedure. To compare the performances of the MAMMDP algorithm and its underlying tabu search procedure, the multi-start tabu search (MTS) and MAMMDP algorithms are respectively performed 20 times for each of the 40 representative instances with n = 3000 or 5000 under the same cutoff time limits given in Section 3.2. Notice that for MTS, the tabu search procedure is run in a multi-start way with a randomly generated initial solution for each re-start until the timeout limit is reached, the tabu search procedure being re-started once the depth of tabu search \u03b1 (which is set to 5\u00d7 104) is reached. The computational results of both algorithms are respectively summarized in Table 5 which is composed of two parts, where the symbols are the same with those in Table 4.\nTable 5 discloses that for the 20 instances with n = 3000 the MAMMDP\nalgorithm performs slightly better than the MTS algorithm, but the differences is small. However, for the 20 larger instances with n = 5000, the MAMMDP algorithm significantly outperforms the the MTS algorithm. First, compared with the MTS algorithm, the MAMMDP algorithm obtains better and worse results in terms of the best objective value on 11 and 2 instances respectively. Second, in terms of average objective value, the MAMMDP algorithm yields better results on 19 out of 20 instances. In addition, from the Friedman test, one observes that the obtained p-values are 1.26e\u2212 2 (<0.05) and 5.699e\u2212 5 (<0.05) respectively for the best and average objective values, implying there exists a significant difference between these two methods. These outcomes demonstrate that the memetic framework is particularly useful to solve large and difficult instances."}, {"heading": "5 Conclusions", "text": "In this paper, we propose the first population-based memetic algorithm (MAMMDP) for solving the NP-hard max-mean dispersion problem (MaxMeanDP). MAMMDP integrates an effective tabu search procedure and a random crossover operator while adopting an original scheme for parent selection. The computational results on a large number of 200 benchmark instances show that the proposed algorithm is very competitive compared with the state-of-the-art algorithms in the literature. Specifically, it improves or matches the previous best known results for all tested instances with n \u2264 1000 with an average computing time of less than 14 seconds and a success rate of 100%, with only one exception. In particular, we found new and improved best results for 59 out of the 60 most challenging instances. We also show computational results on 40 large instances with 3000 or 5000 elements which can serve as reference lower bounds for evaluating new MaxMeanDP algorithms.\nThe investigations of several important ingredients confirm that both the underlying tabu search procedure and the crossover operator of the proposed algorithm contribute to the high performance of the proposed algorithm. It is shown that the population-based memetic framework is particularly suitable to solve large and difficult problem instances.\nThe proposed algorithm could be adapted to the weighted version of the maxmean dispersion problem with several small modifications. Some ideas of the proposed algorithm could be applied to other other binary optimization problems (including some dispersion problems) where no constraint is imposed on the number of variables taking the value of one."}, {"heading": "Acknowledgments", "text": "The work is partially supported by the LigeRo project (2009-2014) and a post-doc grant for X.J. Lai from the Region of Pays de la Loire (France) and the PGMO (2014-0024H) project from the Jacques Hadamard Mathematical Foundation."}], "references": [{"title": "Tabu search versus GRASP for the maximum diversity problem", "author": ["R. Aringhieri", "R. Cordone", "Y. Melzani"], "venue": "4OR: A Quarterly Journal of Operations Research 6(1),45\u201360", "citeRegEx": "1", "shortCiteRegEx": "1", "year": 2008}, {"title": "Comparing local search metaheuristics for the maximum diversity problem", "author": ["R. Aringhieri", "R. Cordone"], "venue": "Journal of the Operational Research Society", "citeRegEx": "2", "shortCiteRegEx": "2", "year": 2011}, {"title": "Construction and improvement algorithms for dispersion problems", "author": ["R. Aringhieri", "R. Cordone", "A. Grosso"], "venue": "European Journal of Operational Research", "citeRegEx": "3", "shortCiteRegEx": "3", "year": 2015}, {"title": "Tabu search for the max-mean dispersion problem. http://www.uv.es/rmarti/paper/docs/mdp10.pdf", "author": ["Carrasco R", "P.T. Anthanh", "M. Gallego", "F. Gort\u00e1zar", "A. Duarte", "R. Mart\u00ed"], "venue": null, "citeRegEx": "4", "shortCiteRegEx": "4", "year": 2014}, {"title": "A heuristic approach for the maxmin diversity problem based on max-clique", "author": ["F. Della Croce", "A. Grosso", "M. Locatelli"], "venue": "Computers & Operations Research", "citeRegEx": "5", "shortCiteRegEx": "5", "year": 2009}, {"title": "A hybrid heuristic approach based on a quadratic knapsack formulation for the max-mean dispersion problem", "author": ["F. Della Croce", "M. Garraffa", "F. Salassa"], "venue": "Lecture Notes in Computer Science,", "citeRegEx": "6", "shortCiteRegEx": "6", "year": 2014}, {"title": "Tabu search and grasp for the maximum diversity problem", "author": ["A. Duarte", "R. Mart\u00ed"], "venue": "European Journal of Operational Research", "citeRegEx": "7", "shortCiteRegEx": "7", "year": 2007}, {"title": "Greedy randomized search procedure with exterior path relinking for differential dispersion minimization", "author": ["A. Duarte", "J. S\u00e1nchez-Oro", "M.G.C. Resende", "F. Glover", "R. Mart\u00ed"], "venue": "Information Sciences", "citeRegEx": "8", "shortCiteRegEx": "8", "year": 2015}, {"title": "An efficient memetic algorithm for the graph partitioning problem", "author": ["P. Galinier", "Z. Boujbel", "C. Fernandes M"], "venue": "Annals of Operations Research", "citeRegEx": "9", "shortCiteRegEx": "9", "year": 2011}, {"title": "Fundamentals of scatter search and path relinking", "author": ["Glover F", "M. Laguna", "R. Mart\u00ed"], "venue": "Control Cybernetics", "citeRegEx": "11", "shortCiteRegEx": "11", "year": 2000}, {"title": "Heuristic algorithms for the maximum diversity problem", "author": ["F. Glover", "C.C. Kuo", "K.S. Dhir"], "venue": "Journal of Information and Optimization Sciences", "citeRegEx": "12", "shortCiteRegEx": "12", "year": 1998}, {"title": "Memetic algorithms in discrete optimization", "author": ["J.K. Hao"], "venue": "Handbook of Memetic Algorithms. Studies in Computational Intelligence 379, Springer,", "citeRegEx": "13", "shortCiteRegEx": "13", "year": 2012}, {"title": "The page trust algorithm: how to rank web pages when negative links are allowed", "author": ["C. Kerchove", "P.V. Dooren"], "venue": "Proceedings SIAM International Conference on Data Mining,", "citeRegEx": "14", "shortCiteRegEx": "14", "year": 2008}, {"title": "A branch and bound algorithm for the maximum diversity problem", "author": ["R. Mart\u00ed", "M. Gallego", "A. Duarte"], "venue": "European Journal of Operational Research", "citeRegEx": "15", "shortCiteRegEx": "15", "year": 2010}, {"title": "GRASP and path relinking for the equitable dispersion problem", "author": ["R. Mart\u00ed", "F. Sandoya"], "venue": "Computers & Operations Research 40(12),", "citeRegEx": "16", "shortCiteRegEx": "16", "year": 2013}, {"title": "A gentle introduction to memetic algorithms", "author": ["P. Moscato", "C. Cotta"], "venue": "Handbook of Metaheuristics,", "citeRegEx": "17", "shortCiteRegEx": "17", "year": 2003}, {"title": "P.(Eds.) Handbook of Memetic Algorithms", "author": ["F. Neri", "C. Cotta", "Moscato"], "venue": "Studies in Computational Intelligence", "citeRegEx": "18", "shortCiteRegEx": "18", "year": 2011}, {"title": "A simple and effective algorithm for the MaxMin diversity problem", "author": ["D.C. Porumbel", "J.K. Hao", "F. Glover"], "venue": "Annals of Operations Research", "citeRegEx": "19", "shortCiteRegEx": "19", "year": 2011}, {"title": "The equitable dispersion problem", "author": ["O.A. Prokopyev", "N. Kong", "D.L. Martinez-Torres"], "venue": "European Journal of Operational Research", "citeRegEx": "20", "shortCiteRegEx": "20", "year": 2009}, {"title": "Iterated tabu search for the maximum diversity problem", "author": ["G. Palubeckis"], "venue": "Applied Mathematics and Computation", "citeRegEx": "21", "shortCiteRegEx": "21", "year": 2007}, {"title": "MaxMinMin p-dispersion problem: A variable neighborhood search approach", "author": ["B. Saboonchi", "P. Hansen", "S. Perron"], "venue": "Computers & Operations Research", "citeRegEx": "23", "shortCiteRegEx": "23", "year": 2014}, {"title": "A hybrid metaheuristic method for the maximum diversity problem", "author": ["Q.H. Wu", "J.K. Hao"], "venue": "European Journal of Operational Research", "citeRegEx": "24", "shortCiteRegEx": "24", "year": 2013}], "referenceMentions": [{"referenceID": 18, "context": "induced by M is optimized [20].", "startOffset": 26, "endOffset": 30}, {"referenceID": 0, "context": "At first, if the cardinality of M is fixed to a given number m, the related equitable dispersion problems include the following four classic variants: (1) the max-sum diversity problem, also known as the maximum diversity problem (MDP), which is to maximize the sum of distances among the selected elements [1,2,7,12,15,21,24]; (2) the max-min diversity problem that aims to maximize the minimum distance among the selected elements [5,19,22,23]; (3) the maximum minsum dispersion problem (MaxMinsumDP) that aims to maximize the minimum aggregate dispersion among the selected elements [3,20]; (4) the minimum differential dispersion problem (MinDiffDP) whose goal is to minimize the difference between the maximum and minimum aggregate dispersion among the selected elements to guarantee that each selected element has the approximately same total distance from the other selected elements [3,8,20].", "startOffset": 307, "endOffset": 326}, {"referenceID": 1, "context": "At first, if the cardinality of M is fixed to a given number m, the related equitable dispersion problems include the following four classic variants: (1) the max-sum diversity problem, also known as the maximum diversity problem (MDP), which is to maximize the sum of distances among the selected elements [1,2,7,12,15,21,24]; (2) the max-min diversity problem that aims to maximize the minimum distance among the selected elements [5,19,22,23]; (3) the maximum minsum dispersion problem (MaxMinsumDP) that aims to maximize the minimum aggregate dispersion among the selected elements [3,20]; (4) the minimum differential dispersion problem (MinDiffDP) whose goal is to minimize the difference between the maximum and minimum aggregate dispersion among the selected elements to guarantee that each selected element has the approximately same total distance from the other selected elements [3,8,20].", "startOffset": 307, "endOffset": 326}, {"referenceID": 6, "context": "At first, if the cardinality of M is fixed to a given number m, the related equitable dispersion problems include the following four classic variants: (1) the max-sum diversity problem, also known as the maximum diversity problem (MDP), which is to maximize the sum of distances among the selected elements [1,2,7,12,15,21,24]; (2) the max-min diversity problem that aims to maximize the minimum distance among the selected elements [5,19,22,23]; (3) the maximum minsum dispersion problem (MaxMinsumDP) that aims to maximize the minimum aggregate dispersion among the selected elements [3,20]; (4) the minimum differential dispersion problem (MinDiffDP) whose goal is to minimize the difference between the maximum and minimum aggregate dispersion among the selected elements to guarantee that each selected element has the approximately same total distance from the other selected elements [3,8,20].", "startOffset": 307, "endOffset": 326}, {"referenceID": 10, "context": "At first, if the cardinality of M is fixed to a given number m, the related equitable dispersion problems include the following four classic variants: (1) the max-sum diversity problem, also known as the maximum diversity problem (MDP), which is to maximize the sum of distances among the selected elements [1,2,7,12,15,21,24]; (2) the max-min diversity problem that aims to maximize the minimum distance among the selected elements [5,19,22,23]; (3) the maximum minsum dispersion problem (MaxMinsumDP) that aims to maximize the minimum aggregate dispersion among the selected elements [3,20]; (4) the minimum differential dispersion problem (MinDiffDP) whose goal is to minimize the difference between the maximum and minimum aggregate dispersion among the selected elements to guarantee that each selected element has the approximately same total distance from the other selected elements [3,8,20].", "startOffset": 307, "endOffset": 326}, {"referenceID": 13, "context": "At first, if the cardinality of M is fixed to a given number m, the related equitable dispersion problems include the following four classic variants: (1) the max-sum diversity problem, also known as the maximum diversity problem (MDP), which is to maximize the sum of distances among the selected elements [1,2,7,12,15,21,24]; (2) the max-min diversity problem that aims to maximize the minimum distance among the selected elements [5,19,22,23]; (3) the maximum minsum dispersion problem (MaxMinsumDP) that aims to maximize the minimum aggregate dispersion among the selected elements [3,20]; (4) the minimum differential dispersion problem (MinDiffDP) whose goal is to minimize the difference between the maximum and minimum aggregate dispersion among the selected elements to guarantee that each selected element has the approximately same total distance from the other selected elements [3,8,20].", "startOffset": 307, "endOffset": 326}, {"referenceID": 19, "context": "At first, if the cardinality of M is fixed to a given number m, the related equitable dispersion problems include the following four classic variants: (1) the max-sum diversity problem, also known as the maximum diversity problem (MDP), which is to maximize the sum of distances among the selected elements [1,2,7,12,15,21,24]; (2) the max-min diversity problem that aims to maximize the minimum distance among the selected elements [5,19,22,23]; (3) the maximum minsum dispersion problem (MaxMinsumDP) that aims to maximize the minimum aggregate dispersion among the selected elements [3,20]; (4) the minimum differential dispersion problem (MinDiffDP) whose goal is to minimize the difference between the maximum and minimum aggregate dispersion among the selected elements to guarantee that each selected element has the approximately same total distance from the other selected elements [3,8,20].", "startOffset": 307, "endOffset": 326}, {"referenceID": 21, "context": "At first, if the cardinality of M is fixed to a given number m, the related equitable dispersion problems include the following four classic variants: (1) the max-sum diversity problem, also known as the maximum diversity problem (MDP), which is to maximize the sum of distances among the selected elements [1,2,7,12,15,21,24]; (2) the max-min diversity problem that aims to maximize the minimum distance among the selected elements [5,19,22,23]; (3) the maximum minsum dispersion problem (MaxMinsumDP) that aims to maximize the minimum aggregate dispersion among the selected elements [3,20]; (4) the minimum differential dispersion problem (MinDiffDP) whose goal is to minimize the difference between the maximum and minimum aggregate dispersion among the selected elements to guarantee that each selected element has the approximately same total distance from the other selected elements [3,8,20].", "startOffset": 307, "endOffset": 326}, {"referenceID": 4, "context": "At first, if the cardinality of M is fixed to a given number m, the related equitable dispersion problems include the following four classic variants: (1) the max-sum diversity problem, also known as the maximum diversity problem (MDP), which is to maximize the sum of distances among the selected elements [1,2,7,12,15,21,24]; (2) the max-min diversity problem that aims to maximize the minimum distance among the selected elements [5,19,22,23]; (3) the maximum minsum dispersion problem (MaxMinsumDP) that aims to maximize the minimum aggregate dispersion among the selected elements [3,20]; (4) the minimum differential dispersion problem (MinDiffDP) whose goal is to minimize the difference between the maximum and minimum aggregate dispersion among the selected elements to guarantee that each selected element has the approximately same total distance from the other selected elements [3,8,20].", "startOffset": 433, "endOffset": 445}, {"referenceID": 17, "context": "At first, if the cardinality of M is fixed to a given number m, the related equitable dispersion problems include the following four classic variants: (1) the max-sum diversity problem, also known as the maximum diversity problem (MDP), which is to maximize the sum of distances among the selected elements [1,2,7,12,15,21,24]; (2) the max-min diversity problem that aims to maximize the minimum distance among the selected elements [5,19,22,23]; (3) the maximum minsum dispersion problem (MaxMinsumDP) that aims to maximize the minimum aggregate dispersion among the selected elements [3,20]; (4) the minimum differential dispersion problem (MinDiffDP) whose goal is to minimize the difference between the maximum and minimum aggregate dispersion among the selected elements to guarantee that each selected element has the approximately same total distance from the other selected elements [3,8,20].", "startOffset": 433, "endOffset": 445}, {"referenceID": 20, "context": "At first, if the cardinality of M is fixed to a given number m, the related equitable dispersion problems include the following four classic variants: (1) the max-sum diversity problem, also known as the maximum diversity problem (MDP), which is to maximize the sum of distances among the selected elements [1,2,7,12,15,21,24]; (2) the max-min diversity problem that aims to maximize the minimum distance among the selected elements [5,19,22,23]; (3) the maximum minsum dispersion problem (MaxMinsumDP) that aims to maximize the minimum aggregate dispersion among the selected elements [3,20]; (4) the minimum differential dispersion problem (MinDiffDP) whose goal is to minimize the difference between the maximum and minimum aggregate dispersion among the selected elements to guarantee that each selected element has the approximately same total distance from the other selected elements [3,8,20].", "startOffset": 433, "endOffset": 445}, {"referenceID": 2, "context": "At first, if the cardinality of M is fixed to a given number m, the related equitable dispersion problems include the following four classic variants: (1) the max-sum diversity problem, also known as the maximum diversity problem (MDP), which is to maximize the sum of distances among the selected elements [1,2,7,12,15,21,24]; (2) the max-min diversity problem that aims to maximize the minimum distance among the selected elements [5,19,22,23]; (3) the maximum minsum dispersion problem (MaxMinsumDP) that aims to maximize the minimum aggregate dispersion among the selected elements [3,20]; (4) the minimum differential dispersion problem (MinDiffDP) whose goal is to minimize the difference between the maximum and minimum aggregate dispersion among the selected elements to guarantee that each selected element has the approximately same total distance from the other selected elements [3,8,20].", "startOffset": 586, "endOffset": 592}, {"referenceID": 18, "context": "At first, if the cardinality of M is fixed to a given number m, the related equitable dispersion problems include the following four classic variants: (1) the max-sum diversity problem, also known as the maximum diversity problem (MDP), which is to maximize the sum of distances among the selected elements [1,2,7,12,15,21,24]; (2) the max-min diversity problem that aims to maximize the minimum distance among the selected elements [5,19,22,23]; (3) the maximum minsum dispersion problem (MaxMinsumDP) that aims to maximize the minimum aggregate dispersion among the selected elements [3,20]; (4) the minimum differential dispersion problem (MinDiffDP) whose goal is to minimize the difference between the maximum and minimum aggregate dispersion among the selected elements to guarantee that each selected element has the approximately same total distance from the other selected elements [3,8,20].", "startOffset": 586, "endOffset": 592}, {"referenceID": 2, "context": "At first, if the cardinality of M is fixed to a given number m, the related equitable dispersion problems include the following four classic variants: (1) the max-sum diversity problem, also known as the maximum diversity problem (MDP), which is to maximize the sum of distances among the selected elements [1,2,7,12,15,21,24]; (2) the max-min diversity problem that aims to maximize the minimum distance among the selected elements [5,19,22,23]; (3) the maximum minsum dispersion problem (MaxMinsumDP) that aims to maximize the minimum aggregate dispersion among the selected elements [3,20]; (4) the minimum differential dispersion problem (MinDiffDP) whose goal is to minimize the difference between the maximum and minimum aggregate dispersion among the selected elements to guarantee that each selected element has the approximately same total distance from the other selected elements [3,8,20].", "startOffset": 891, "endOffset": 899}, {"referenceID": 7, "context": "At first, if the cardinality of M is fixed to a given number m, the related equitable dispersion problems include the following four classic variants: (1) the max-sum diversity problem, also known as the maximum diversity problem (MDP), which is to maximize the sum of distances among the selected elements [1,2,7,12,15,21,24]; (2) the max-min diversity problem that aims to maximize the minimum distance among the selected elements [5,19,22,23]; (3) the maximum minsum dispersion problem (MaxMinsumDP) that aims to maximize the minimum aggregate dispersion among the selected elements [3,20]; (4) the minimum differential dispersion problem (MinDiffDP) whose goal is to minimize the difference between the maximum and minimum aggregate dispersion among the selected elements to guarantee that each selected element has the approximately same total distance from the other selected elements [3,8,20].", "startOffset": 891, "endOffset": 899}, {"referenceID": 18, "context": "At first, if the cardinality of M is fixed to a given number m, the related equitable dispersion problems include the following four classic variants: (1) the max-sum diversity problem, also known as the maximum diversity problem (MDP), which is to maximize the sum of distances among the selected elements [1,2,7,12,15,21,24]; (2) the max-min diversity problem that aims to maximize the minimum distance among the selected elements [5,19,22,23]; (3) the maximum minsum dispersion problem (MaxMinsumDP) that aims to maximize the minimum aggregate dispersion among the selected elements [3,20]; (4) the minimum differential dispersion problem (MinDiffDP) whose goal is to minimize the difference between the maximum and minimum aggregate dispersion among the selected elements to guarantee that each selected element has the approximately same total distance from the other selected elements [3,8,20].", "startOffset": 891, "endOffset": 899}, {"referenceID": 3, "context": ", the size of M is allowed to vary from 2 to n, the related equitable dispersion problems include the max-mean dispersion problem (MaxMeanDP) and the weighted MaxMeanDP [4,6,16,20].", "startOffset": 169, "endOffset": 180}, {"referenceID": 5, "context": ", the size of M is allowed to vary from 2 to n, the related equitable dispersion problems include the max-mean dispersion problem (MaxMeanDP) and the weighted MaxMeanDP [4,6,16,20].", "startOffset": 169, "endOffset": 180}, {"referenceID": 14, "context": ", the size of M is allowed to vary from 2 to n, the related equitable dispersion problems include the max-mean dispersion problem (MaxMeanDP) and the weighted MaxMeanDP [4,6,16,20].", "startOffset": 169, "endOffset": 180}, {"referenceID": 18, "context": ", the size of M is allowed to vary from 2 to n, the related equitable dispersion problems include the max-mean dispersion problem (MaxMeanDP) and the weighted MaxMeanDP [4,6,16,20].", "startOffset": 169, "endOffset": 180}, {"referenceID": 18, "context": "In this study, we focus on MaxMeanDP which can be described as follows [20].", "startOffset": 71, "endOffset": 75}, {"referenceID": 14, "context": "MaxMeanDP can be naturally expressed as a quadratic integer program with binary variables xi that takes 1 if element i is selected and 0 otherwise [16,20], i.", "startOffset": 147, "endOffset": 154}, {"referenceID": 18, "context": "MaxMeanDP can be naturally expressed as a quadratic integer program with binary variables xi that takes 1 if element i is selected and 0 otherwise [16,20], i.", "startOffset": 147, "endOffset": 154}, {"referenceID": 18, "context": "In addition to its theoretical signification as a strongly NP-hard problem [20], MaxMeanDP is notable for its ability to model a variety of real-world applications, such as web pages ranks [14], community mining [25], and others mentioned in [4].", "startOffset": 75, "endOffset": 79}, {"referenceID": 12, "context": "In addition to its theoretical signification as a strongly NP-hard problem [20], MaxMeanDP is notable for its ability to model a variety of real-world applications, such as web pages ranks [14], community mining [25], and others mentioned in [4].", "startOffset": 189, "endOffset": 193}, {"referenceID": 3, "context": "In addition to its theoretical signification as a strongly NP-hard problem [20], MaxMeanDP is notable for its ability to model a variety of real-world applications, such as web pages ranks [14], community mining [25], and others mentioned in [4].", "startOffset": 242, "endOffset": 245}, {"referenceID": 18, "context": "presented a mixed-integer 0-1 linear programming formulation and solved small instances with up to 100 elements with the CPLEX solver [20].", "startOffset": 134, "endOffset": 138}, {"referenceID": 14, "context": "Subsequently, Mart\u00ed and Sandoya proposed a GRASP with the path relinking method (GRASPPR) [16], and the computational results show that GRASP-PR outperforms the previously reported methods.", "startOffset": 90, "endOffset": 94}, {"referenceID": 5, "context": "reported a hybrid heuristic approach based on a quadratic knapsack formulation [6], and their computational experiment shows that the hybrid approach is superior to the GRASP-PR method.", "startOffset": 79, "endOffset": 82}, {"referenceID": 3, "context": "proposed a diversified tabu search algorithm by combining a short-term tabu search procedure and a long-term tabu search procedure [4], and the computational results show that this algorithm clearly dominates the previous GRASP-PR method.", "startOffset": 131, "endOffset": 134}, {"referenceID": 15, "context": "Memetic search is a well-known metaheuristic framework which aims to provide the search with a desirable trade-off between intensification and diversification through the combined use of a crossover operator (to generate new promising solutions) and a local optimization procedure (to locally improve the generated solutions) [17,18].", "startOffset": 326, "endOffset": 333}, {"referenceID": 16, "context": "Memetic search is a well-known metaheuristic framework which aims to provide the search with a desirable trade-off between intensification and diversification through the combined use of a crossover operator (to generate new promising solutions) and a local optimization procedure (to locally improve the generated solutions) [17,18].", "startOffset": 326, "endOffset": 333}, {"referenceID": 11, "context": "The proposed memetic algorithm (denoted by MAMMDP) adopts the principles and guidelines of designing effective MA for discrete combinatorial problems [13].", "startOffset": 150, "endOffset": 154}, {"referenceID": 9, "context": "Additionally, the proposed MAMMDP algorithm uses a population scheme which borrows from the path relinking method [11] to ensure a strong intensification search.", "startOffset": 114, "endOffset": 118}, {"referenceID": 8, "context": "In our TS procedure, we use a tabu list management strategy to dynamically tune the tabu tenure tt, which is adapted according to a technique proposed in [9] where the tabu tenure is given by a periodic step function.", "startOffset": 154, "endOffset": 157}, {"referenceID": 4, "context": "The distances of Type I instances are randomly generated in the interval [\u221210, 10] with a uniform probability distribution, while the distances of Type II instances are generated from [\u221210,\u22125]\u222a [5, 10] with the same probability distribution.", "startOffset": 194, "endOffset": 201}, {"referenceID": 3, "context": "These 160 instances were extensively adopted by the previous studies [4,6,16] and are available online at http://www.", "startOffset": 69, "endOffset": 77}, {"referenceID": 5, "context": "These 160 instances were extensively adopted by the previous studies [4,6,16] and are available online at http://www.", "startOffset": 69, "endOffset": 77}, {"referenceID": 14, "context": "These 160 instances were extensively adopted by the previous studies [4,6,16] and are available online at http://www.", "startOffset": 69, "endOffset": 77}, {"referenceID": 21, "context": "For p and \u03b1, we follow [24] and set p = 10, \u03b1 = 50000 while setting Tmax = 120 empirically.", "startOffset": 23, "endOffset": 27}, {"referenceID": 3, "context": "Each instance is independently solved 20 times, and improved results are indicated in bold compared to the previous best known results fpre of the literature reported in [4,6,16].", "startOffset": 170, "endOffset": 178}, {"referenceID": 5, "context": "Each instance is independently solved 20 times, and improved results are indicated in bold compared to the previous best known results fpre of the literature reported in [4,6,16].", "startOffset": 170, "endOffset": 178}, {"referenceID": 14, "context": "Each instance is independently solved 20 times, and improved results are indicated in bold compared to the previous best known results fpre of the literature reported in [4,6,16].", "startOffset": 170, "endOffset": 178}, {"referenceID": 3, "context": "Memetic Algorithm Instance n fpre [4,6,16] fbest favg SR t(s)", "startOffset": 34, "endOffset": 42}, {"referenceID": 5, "context": "Memetic Algorithm Instance n fpre [4,6,16] fbest favg SR t(s)", "startOffset": 34, "endOffset": 42}, {"referenceID": 14, "context": "Memetic Algorithm Instance n fpre [4,6,16] fbest favg SR t(s)", "startOffset": 34, "endOffset": 42}, {"referenceID": 14, "context": "Column 3 indicates the best objective values (fpre) of the literature which are compiled from the best results yielded by three recent and best performing algorithms, namely GRASP-PR [16], a hybrid heuristic approach [6], and a diversified tabu search method [4] (from http://www.", "startOffset": 183, "endOffset": 187}, {"referenceID": 5, "context": "Column 3 indicates the best objective values (fpre) of the literature which are compiled from the best results yielded by three recent and best performing algorithms, namely GRASP-PR [16], a hybrid heuristic approach [6], and a diversified tabu search method [4] (from http://www.", "startOffset": 217, "endOffset": 220}, {"referenceID": 3, "context": "Column 3 indicates the best objective values (fpre) of the literature which are compiled from the best results yielded by three recent and best performing algorithms, namely GRASP-PR [16], a hybrid heuristic approach [6], and a diversified tabu search method [4] (from http://www.", "startOffset": 259, "endOffset": 262}, {"referenceID": 3, "context": "In [4,16], the cutoff time limits are set to 90, 600, and 1800 seconds for instances with the size 500, 750, and 1000, respectively, and in [6] the cutoff time limits are respectively set to 60 and 600 seconds for the instances with the size 150 and 500.", "startOffset": 3, "endOffset": 9}, {"referenceID": 14, "context": "In [4,16], the cutoff time limits are set to 90, 600, and 1800 seconds for instances with the size 500, 750, and 1000, respectively, and in [6] the cutoff time limits are respectively set to 60 and 600 seconds for the instances with the size 150 and 500.", "startOffset": 3, "endOffset": 9}, {"referenceID": 5, "context": "In [4,16], the cutoff time limits are set to 90, 600, and 1800 seconds for instances with the size 500, 750, and 1000, respectively, and in [6] the cutoff time limits are respectively set to 60 and 600 seconds for the instances with the size 150 and 500.", "startOffset": 140, "endOffset": 143}, {"referenceID": 14, "context": "4 GHz CPU with 3 GB RAM [16]; the hybrid heuristic approach was run on a computer with an Intel Core i5-3550 3.", "startOffset": 24, "endOffset": 28}, {"referenceID": 5, "context": "30GHz CPU with 4GB RAM [6] and the diversified tabu search method was run on a computer with an Intel Core 2 Quad CPU and 6 GB RAM [4].", "startOffset": 23, "endOffset": 26}, {"referenceID": 3, "context": "30GHz CPU with 4GB RAM [6] and the diversified tabu search method was run on a computer with an Intel Core 2 Quad CPU and 6 GB RAM [4].", "startOffset": 131, "endOffset": 134}, {"referenceID": 3, "context": "by the state of the art algorithms [4,6,16].", "startOffset": 35, "endOffset": 43}, {"referenceID": 5, "context": "by the state of the art algorithms [4,6,16].", "startOffset": 35, "endOffset": 43}, {"referenceID": 14, "context": "by the state of the art algorithms [4,6,16].", "startOffset": 35, "endOffset": 43}, {"referenceID": 3, "context": "It should be mentioned that compared to the previous methods for MaxMeanDP, such as those in [4], the success of our tabu search method may be attributed to the combined use of the neighborhood N1, the fast neighborhood evaluation technique and its dynamic tabu list management strategy.", "startOffset": 93, "endOffset": 96}], "year": 2015, "abstractText": "Given a set V of n elements and a distance matrix [dij ]n\u00d7n among elements, the max-mean dispersion problem (MaxMeanDP) consists in selecting a subset M from V such that the mean dispersion (or distance) among the selected elements is maximized. Being a useful model to formulate several relevant applications, MaxMeanDP is known to be NP-hard and thus computationally difficult. In this paper, we present a highly effective memetic algorithm for MaxMeanDP which relies on solution recombination and local optimization to find high quality solutions. Computational experiments on the set of 160 benchmark instances with up to 1000 elements commonly used in the literature show that the proposed algorithm improves or matches the published best known results for all instances in a short computing time, with only one exception, while achieving a high success rate of 100%. In particular, we improve 59 previous best results out of the 60 most challenging instances. Results on a set of 40 new large instances with 3000 and 5000 elements are also presented. The key ingredients of the proposed algorithm are investigated to shed light on how they affect the performance of the algorithm.", "creator": "LaTeX with hyperref package"}}}