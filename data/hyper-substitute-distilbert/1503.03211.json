{"id": "1503.03211", "review": {"conference": "arxiv", "VERSION": "v1", "DATE_OF_SUBMISSION": "11-Mar-2015", "title": "A Multi-Gene Genetic Programming Application for Predicting Students Failure at School", "abstract": "several efforts who predict student failure rate ( hr ) at which teaching still remains are core scientific area faced that many in the educational sector. prediction criteria for forecasting sfr proved rigid and most often contain required data transfer or differentiation into continuous dimensions such as is commonly phenomenon of false logistic variance which may have to lose spatial information and effect variance combinations. also, the experiment yielding underlying factors, incomplete data unbalanced expression, and variable cell traits contained in structured neural networks and fuzzy logic systems exposes disadvantaged audience for more efficient tools. currently scientific application of functional programming ( gp ) are great promises and has produced tremendous ongoing successes in different sectors. the new realm, this study developed gpsfarps, a software application to provide a simulation solution to neural prediction machine template resistant alternative evolutionary scheme known as multi - gene regression programming. the implementation is validated using feeding a testing intensity set supporting the evolved gp models. result obtained beneath gpsfarps simulations show demonstrated unique strength to evolve locally suitable fail rate expression with a fast convergence at 30 pulses from a normally complete generation of 500. the multi - gene system was also formulated to integrate the evolved disorder expression and accurately calculate effective crush rate a approximation subset to the original expression", "histories": [["v1", "Wed, 11 Mar 2015 08:17:11 GMT  (434kb)", "http://arxiv.org/abs/1503.03211v1", "14 pages, 9 figures, Journal paper. arXiv admin note: text overlap witharXiv:1403.0623by other authors"]], "COMMENTS": "14 pages, 9 figures, Journal paper. arXiv admin note: text overlap witharXiv:1403.0623by other authors", "reviews": [], "SUBJECTS": "cs.CY cs.AI cs.NE", "authors": ["j o orove", "n e osegi", "b o eke"], "accepted": false, "id": "1503.03211"}, "pdf": {"name": "1503.03211.pdf", "metadata": {"source": "CRF", "title": "A Multi-Gene Genetic Programming Application for Predicting Students Failure at School", "authors": ["J.O. Orove", "N.E. Osegi", "B.O. Eke"], "emails": ["joshuaorove2012@gmail.com", "geeqwam@gmail.com", "bathoyol@gmail.com"], "sections": [{"heading": null, "text": "1 A Multi-Gene Genetic Programming Application for Predicting Students Failure at School\nKeywords: Genetic Programming, Student Failure Rate, Multi-Gene GP"}, {"heading": "1. INTRODUCTION", "text": "SFR has always being and will continue to be a major concern to stakeholders in the educational sector. It refers to the proportion (or more correctly percentage) of students not graduating in a chosen course of study [1]. It is an important aspect of educational curricula assessment as this will help educational administrators to evaluate the performance of their existing curricula, teaching system, infrastructure and student relations programmes. Since the performance of any school system is largely affected by the failure rate of the students, it becomes necessary to study this obviously very important parameter. In particular, there has been a\nglobal call to reduce the failure rates of science school students, especially in the Mathematics courses [2]. Social graphs and data mining techniques [3, 4] have been suggested and some cases. Logistic and multiple linear regression techniques have also been used to study student failures rates [5, 14]. Methodologies for investigating student failure rates or decline in academic performance using artificial intelligence techniques such as Neuro-Genetic Algorithms (NGAs), Artificial Neural Networks (ANNs), Genetic Algorithms and decision trees [6,7,8, 9], have been suggested and developed in the literature. More recently, GP has been applied in a grammar guided genetic programming algorithm to predict if the student will fail or pass a determined course and\n2 identifies activities to stimulate its learning in a positive or negative way through the use of True Positive (TP) and True Negative (TN) concepts [10]. 1.1 Statement of Problem In our educational institutions today there is currently the need to improve student\u2019s performance by reducing the number of students who fail at school. This requirements demand that school administrators and managers employ specific tools, methods and approaches to effectively study and predict student\u2019s performance overtime. Currently, such predictive tools are either not flexible, or are very expensive and scarce. This paper seeks to fill this gap by introducing a Multigene genetic programming application, GPSFARPS, to facilitate the process of student failure rate analysis and to aid educational administrators predict student\u2019s failure at school more cost-effectively. 1.2 Theoretical Framework Using the GP Model The prediction of student failure rate can be carried out using different approaches with consequently different kinds of results but with the sole purpose of evaluating the number of failing students in an exam or course of study. Models such as the Logistic Regression Model [5] have been used to predict the actual probability that a student will pass or fail a Chemistry test. However, when dealing with input data of the continuous form and with a small data set, this approach becomes ineffective leading to effect size attenuation [17]. Also the issue of coding and proper labelling has to be taken into account if the logistic technique is to be utilized as a viable predictor model. Classification and Regression trees [18] have been used to predict students passing or failing a subject taking into consideration six sociodemographic variables (age, gender, ethnicity, education, work status, and disability). However, as the author [18] pointed out in his concluding remarks, limitations do exist with the use of classification trees which could distort results obtained in the classification process and as in the case of the logistic regression, the prevalence of small data sets leads to low prediction accuracies. More recently, educational data mining techniques [4, 6] have been applied to the growing problem of predicting student failure rate with high degree of success rates. 1.3 Research purpose We intend to bridge the gap in this area, which is to develop a software application that can evolve a model expression for predicting student failure at school given a history of class/exam scores- called the historical data set. These model expressions can then be easily utilized by the school administrators in carrying out their predictions or failure rate calculations for a future data set. 2. RELATED LITERATURE Prediction is one of the most frequently studied problems on Data Mining and Machine Learning researchers. It consists on predicting the value of a categorical attribute based on the values of other attributes, the predicting attributes. One of the most useful Data Mining tasks on educational data mining is classification [16]. It makes possible the prediction/classification of a student\u2019s performance, for example. There are different educational objectives for using classification, such as: discovery of potential student groups with similar characteristics and reactions to a particular pedagogical strategy[19], to detect student\u2019s \u201fmisuse or game-playing\u201f the system which is correlated with substantially lower learning [27], to group students that are hint-driven or failure driven and find common misconceptions that students possess [20], to identify learners with a low rate of motivation and find remedial actions to lower drop-out rates [21], to classify/predict students when Intelligent Tutoring Systems (ITS) are being used [22]. To predict student outcome, some studies have been made: prediction of student\u2019s grades, on a scale from A to F, from test scores using neural networks (counter propagation networks and back propagation networks) [23]; prediction of the relevance of classes, i.e., if classes are relevant or not to student\u2019s academic success, using discriminant function analysis [24] Predicting a student\u2019s academic success (low, medium or high risk) using decision trees, random forests and neural networks [25]. Using GeSES [26], a method that has been designed specifically to work with students logs, based on C4.5 rules, a main goal was established by its authors: to test if symptoms of a bad adaptation in an adaptive course where detected. A bad adaptation was detected if the course generated a low performance, caused by bad student\u2019s inadequate environment. Genetic programming is also a broadly used method on Educational Data Mining. G3PMI [10], a grammar guided genetic programming algorithm, has been applied to predict if the student will fail or pass a determined course and identifies activities to stimulate its learning in a positive or negative way through the use of True Positive (TP) and True Negative (TN) concepts. Results show that G3P-MI achieves better performance with more accurate models than a better trade-off between such contradictory metrics as sensitivity and specificity. Also, it adds comprehensibility to the knowledge discovered and finds interesting relationships between certain tasks and the time expended to solving exercises with the final marks obtained in the course. Tanner [28] used a k-nearest neighbour (kNN) method to predict student performance in an online course environment. Extensive experimental results from a 12- lesson course on touch-typing, with a database of close to 15000 students were presented. The results indicate that kNN can predict student performance accurately, and already after the very first lessons. They also concluded that early tests on skills can be strong predictors for final scores also in other skill-based courses. Kalles [9] used Genetic Algorithms and Decision trees for a posteriori analysis of tutoring practices based on Student\u2019s failure models. Their results showed that genetic induction of decision trees\n3 could indeed produce very short and accurate trees that could be used for explaining failures. In [10], data mining techniques and real data of about 670 middleschool students from Zacatecas, M\u00e9xico were used to predict school failure. Several experiments were carried out in an attempt to improve accuracy in the prediction of final student performance and, specifically, students that were likely to fail. In the first experiment the best 15 attributes was selected. Then two different approaches (Data Balancing and Cost-Sensitive approaches) were applied in order to resolve the problem of classifying unbalanced data by rebalancing data and using cost sensitive classification. The outcomes of each one of the approaches using the 10 classification algorithms and 10 fold cross validation were compared in order to select the best approach to the problem. From the results, it was deduced that OneR fared better with a TN (True Negative \u2013 Fail) rate of about 88.3% when using data balancing approach, whereas Jrip fared better with a TN rate of 93.3% with the cost sensitive approach. They examined the differential effects of prior academic achievement, psychosocial, behavioural, demographic, and school context factors on early high school grade point average (GPA) using a prospective study of 4,660 middle-school students from 24 schools and a combined Multiple Linear Regression (MLR)/ Hierarchical Linear Modeling (HLM) approach. Their findings suggest that: (a) Prior grades and standardized achievement are the strongest predictors of high school GPA and (b) Psychosocial and behavioural factors (e.g., motivation, self-regulation, and social control) add incremental validity to the prediction of GPA. When comparing the relative importance of each set of predictors (the dominance analysis technique), the variance accounted for by psychosocial and behavioural factors is comparable to that accounted for by prior grades. These findings highlight the importance of effective risk assessment based on multiple measures (i.e., academic, psychosocial, and behavioural) for the purpose of identifying risk, referring students to intervention, and improving academic success [10]. They also used a new form of genetic programming called Grammar based Genetic Programming (G3P), combined with an Interpretable Rule Classification Mining Scheme (ICRM) for the prediction of student failure rate at school using real data from high school students in Mexico. These data were based on class marks and of high dimensions (variable intensive) and imbalanced, thus, the need for variable (dimension) reduction, cost sensitive classification/re-sampling of original datasets respectively to reduce these irregularities was emphasized. They compared three versions of their G3P/ICRM model with 10 classification algorithms to evaluate the Fail (or True Negative) rates and they found out that the best results were those obtained by their G3P/ICRM models. However, one thing that is missing in most of the techniques is having a structured user friendly application that will facilitate the generation of a symbolic model expression for describing student failure rate over a particular period of time. Such expressions can make the job of the educational administrator easier particularly in the area of recomputation using a supportive regression approach."}, {"heading": "3. SOFTWARE METHODOLOGY", "text": "In this section, a multi-gene genetic programming approach is employed. This approach uses an iterative radical unified modelling process wherein In particular we have used an open source framework for genetic programming GPTIPS\u00ae [11], as a basis for the developed GP application. The system is robust, modular and customizable with user friendly interfaces."}, {"heading": "3.1 Theoretical Foundations", "text": "GP operates based on the Darwinian principle of evolution, natural selection, and survival of the fittest. Typically, GP solutions are evolved individual programs encoded in a structure referred to as a gene or gene tree. At the beginning of a GP algorithm the genes or expression trees are randomly initialized within a feasible solution space, and then they undergo reproduction, crossover and mutation. Reproduction is a technique used to replicate new genes from the original parent genes akin to sexual reproduction in the programming tournament. The programming tournament can be likened to be an environment of competing programs where the best of them is selected as the eventual winners. The two core genetic operations during reproduction are [13]: (i) Crossover: This involves the interchange of genetic material among the solutions or genes (ii) Mutation: This involves random changes (additions and deletions) within a gene itself. The crossover operation employs a swapping function in software while the mutation operation uses a knockout technique."}, {"heading": "3.2 Genetic Programming Process", "text": "The fundamental mathematical formulations guiding a genetic programming application and corresponding pseudo-codes are not new and are given in [12]. In general a GP system seeks to minimize the mean square error of the fitted data set by evolving multiple solutions at different intervals of time. A typical architecture of a GP Programming sequence is shown in Fig1. A genetic programming process starts from providing genetic programming with basic building blocks of the solution and some method of analyzing how well a proposed solution solves the problem. This is also followed by supplying the Genetic programming with the fitness metrics which the Genetic programming (GP) will use in generating solution. In Fig 1 the process analysis of the genetic programming is\n4 presented and it shows clearly that the first set of solutions generated does not become the final solution. Instead the solutions keep evolving over and over certain number of times till an optimal solution is arrived at. In the figure it is clear that the GP begins with some initial guess at a solution and successively attempts to improve the solution over time. Once some criterion for termination (either an ideal individual or some predefined run time) GP returns the best individual so far. That individual is deemed the result of GP or the Optimal Solution. In Fig 2 the more detail diagram shows what happens internally inside the Genetic Programming box. It begins by generating some initial population. The fitness of all individuals in the population is then assessed. It is unlikely that this initial generation will contain an ideal individual, but some will likely be better than others. We begin the GP loop by selecting the individuals that solve the problem best and allowing them to reproduce, making small random changes to their construction. As this process repeats numerous times, we find that on average, the fitness of the population tends to increase. GP Building Block Fitness Metrics Genetic Programming Optimal Solution Evolving solutions Fig1: Simplified Genetic Programming Process Analysis GP Building Block Fitness Metrics Genetic Programming Optimal Solution Evolving solutions Randomly Generate initial population Does satisfactory individual exist? Select Individual based on Fitness Make Random Changes Access Fitness of population Fig2: Main Genetic Programming Process Analysis\n5"}, {"heading": "3.3 GP Model Solutions and Methodology", "text": "The first step in the design of a Genetic Programming is the design of the problem representation. In this section we will present the representation design of the system."}, {"heading": "3.3.1 Representation (Building Block)", "text": "In our analysis above we have been talking a lot about individuals, for instance \u201cSelect Individual based on Fitness\u201d but not really discussing what these individuals are made of. We know that GP aims to evolve computer programs, but what kind of computer programs? The computer programs GP evolves are programs written in some functional programming language. In functional programs, the idea is to take some input and simply return a value without dealing with computer state. You can think of functional programming more like mathematical expressions than instructions for somebody to follow. There are many functional programming languages, including LISP and OCaml. Another option is to represent the individuals using objects of whatever programming language that are been used to code the GP system. This is the way our Darwin GP Environment handles representation. However whether we choose to represent individuals in some functional programming language or with objects in memory, GP evolves individuals that can be represented as a tree structure. It is more functionally useful to consider them in this way when thinking about GP. The tree structure design in Fig 3 is the building block for our genetic programming. 3.3.2 Multiple Gene Symbolic Regression Genetic Programming (GP) Model: A multigene individual consists of one or more genes, each of which is a \u201ctraditional\u201d GP tree. Genes acquired incrementally by individuals in order to improve fitness (e.g. to reduce a model\u2019s sum of squared errors on a data set). The overall model is a weighted linear combination of each gene. Optimal weights for the genes are automatically obtained (using ordinary least squares to regress the genes against the output data). The resulting pseudo-linear model can capture nonlinear behaviour. In multigene symbolic regression based GP, each prediction of the output variable y is formed by the weighted output of each of the trees/genes in the multigene individual plus a bias term. Each tree is a function of zero or more of the N input variables x1, \u2026 xn. Mathematically, a multigene regression model can be written as: y = do + d1*tree1+...+dm*treeM.................... (1) where do = bias (offset) term and d1,..., dm are gene weights and M is the number of genes (i.e. trees) comprising the current individual. The weights (i.e. regression coefficients) are automatically determined by a least squares procedure for each multigene individual. If Score is above 70 Pass With A If Score is above 60 If Score is above 50 If Score is above 45 If Score is above 40 If Score is below 40 Pass With E Pass With D Pass with C Pass With B FAIL Fig3: A Tree Representation of the Student Failure GP\n6\nThe number and structure of the trees is evolved automatically during a run (subject to user defined constraints) using training data, i.e. a set of existing input values and corresponding output values. Testing data (another set of input and corresponding output values from the process or system you are modelling) can be used, after the run, to evaluate the evolved models. The testing data is not used to evolve the models and serves to give an indication of how well the models generalise to new data. A pseudolinear multigene model of predictor output y with inputs x1 to x6; the weights d0, d1, d2 are automatically obtained by least squares. Multiple gene model (transfer function): Y = do + d1*x1+ d2*x2+d3*x3+d4*x4+ d5*x5+ d6*x6 \u2026\u2026\u2026. (2) The architecture of the developed system is given in Fig 4."}, {"heading": "3.3.3 Solution Representation and Methodology", "text": "Genetic programming creates computer programs in the Lisp or scheme computer languages as the solution. Genetic algorithms create a string of numbers that represent the solution. In our model, an inductiveevolutionary approach is employed. The developed application based on Genetic programming uses the"}, {"heading": "3.3.4 Application Development", "text": "The application has been built in phases. The development phases use the concepts of windowing and navigation common to most modern GUI\u2019s. Windows are basically clickable user interfaces that facilitate data entry, retrieval and visualization in a compact and easy to use way using components such as buttons, text fields, menus, etc. The application is designed and developed in phases using callback functions or classes within a scripting program. It basically consists of three core windows (not shown): Start window: serves as front end for application\n7\nMain window: for specifying core GP parameters and running the GP prediction system Grammar Window: for failure rate classification and estimation. A display has been added to the Main window and Grammar window to print the solution model expression for prediction and failure classifications respectively. It is possible for the user to move between windows by using callback buttons or menus. Fig 5 shows the class diagram including the core computational functions used in the developed application."}, {"heading": "3.3.2 GP Model Input Data and Specifications", "text": "A continuous set of student raw scores used in the developed GP applications are proposed with sample student net scores labelled Q1 to Q5, and net continuous assessment, labelled CA score, jointly referred to as the Predictor Variables, while the output parameter (response variable) is the total score (TOTAL) which is as usual is graded and scaled to a maximum of 100 and minimum of 0. These data were obtained from historical records and are provided in Table 1. We have made the assumption that the scores represent a time series so future forecasts can be easily achieved and assured even when there is great variation in size, the principles remain the same i.e. we could easily scale down to a suitable range. In Table2, the GP parameters for the analysis and prediction process are presented taking into account bloat constraints [8].\nTable1: Sample of Student Raw Score Data Time x1 x2 x3 x4 x5 EXAM SCORE C.A. SCORE (x6) TOTAL GRADE 1 0 7 0 0 0 7 16 23 F 2 6 7 0 6 5 24 20 44 E 3 1 6 3 0 0 10 16 26 F 4 0 4 4 3 2 13 17 30 F 5 0 4 2 2 1 9 16 25 F 6 0 5 0 9 6 20 20 40 E 7 0 2 1 1 0 4 16 20 F 8 0 4 0 0 0 4 16 20 F 9 5 10 0 0 5 20 20 40 E 10 0 11 4 6 5 26 21 47 D 11 8 4 2 0 0 14 16 30 F 12 0 8 6 6 0 20 21 41 E 13 0 7 0 0 4 11 16 27 F 14 0 2 0 0 0 2 16 18 F Table2: GP Parameter Settings"}, {"heading": "GP algorithm parameters Parameter Settings", "text": "Population size 150 Number of generations 500 Selection method Plain Lexicographic Tournament Selection Tournament size 4 Termination criteria 0 Maximum depth of each tree 4 Maximum number of trees 4 Maximum Number of Genes 4 Mathematical operators for symbolic regression {+ , \u2013 , x}"}, {"heading": "4. RESULTS", "text": "In this study GPSFARPS application is used to train the raw score data from table 1 with specifications given in\nTable 2. A lexicographic tournament selection strategy is chosen for selecting the parent genes from the pool of available solutions. The tournament size is set to 4. The maximum depth of each tree in the multi-gene representation is set to 4 and this allows some control\nover the complexity of the evolved expressions. The instruction set or the functions that are used for symbolic regression are {+ , \u2013 , x}.\n9\nThe generated modelled expression is captured in Fig 9 which can be written as Y = x6 + x5 +x3 + x4 \u2026\u2026\u2026\u2026\u2026. (3)\n10\n11"}, {"heading": "5. DISCUSSIONS", "text": "In this study we have implemented the principles of GP using the multi-gene approach in a friendly user interface application. We applied the concept of cross-over and mutation to evolve a random population of individual solution programs and obtained a best fitted model for the specified GP parameters. The graphical reports are generated using MATLAB \u00a9 handle graphics technology [15]. Using the interactive software GPSFARPS, GP parameters can be specified and meaningful features observed at run time. A parsimonious model can be achieved if the core GP parameters, in particular, the number of generations, population size, tournament size, tree depth, number of gene trees and number of genes are constrained. From Fig 8, we have shown that specifying arbitrary number of generations does not significantly improve the system performance beyond possible achievable limits (Log Fitness versus Generation Plot). We should also point out here that the problem of local minima common to other AI schemes such as neural networks and fuzzy logic can be avoided with this evolutionary technique. Fast convergence has been achieved at approximately 30 generations from a maximum of 500 generations. This fast convergence rate may be attributed to the close correlation between predictor and response variables but should not be expected at all times. Also four candidate response variables, x6, x5, x4, and x3, were generated by the system and then used in the prediction process. This clearly shows the strength of multi-gene GP in minimizing or simplifying complex predictor equations. Another issue what considering is the need for flexible specification of functional operators or function data set(s), since the function set plays a vital role in the structure of the evolved expression, such a technique can be valuable if the school administrator has first hand knowledge of the shape of the failure rate. The failure shape or failure rate graph may be discovered using simple graph operations on test data from which an initial guess for suitable candidate functions may be arrived at. Once candidate function(s) have been deduced, it can then be programmed into GPSFARPS using end-user programming call back functions. In this way, novel solutions to the failure rate problem may be discovered by the endusers themselves."}, {"heading": "6. CONCLUSIONS", "text": "A object-oriented evolutionary software application for evolving model expressions that can predict student failure rates at school has been developed. The system was fed with incomplete raw score data and simulated response was satisfactory with a fast convergence rate \u2013 about 30 generations for a specified maximum generation of 500 and a minimal model expression consisting of only 4 predictor variables from a total of six predictor variables. The system can safely be used to facilitate predictions on complex data by using the software interface. The application will be open sourced and made available on the web to facilitate further development."}, {"heading": "7. SIGNIFICANCE AND RECOMMENDATIONS FOR FUTURE WORK", "text": "This paper has presented a software application for predicting student failure rate at school. The software is capable of regenerating failure rate model expressions using a time \u2013series dependent student\u2019s raw scores as input parameters and these model expressions can in turn be used by school administrators to determine student failure rate at school The software can be made more useful if a bloat checking mechanism is incorporated. Further investigations need to be carried to test the effect of two state logic data on the GP software system developed, improving the function set database and making the program platform independent. Also, One-step in this direction will be to build a suitable software framework that will encourage end-user programming of the function data set. An interactive-agile function data set to facilitate end user programming of GPSFARPS in a future design is thus proposed."}], "references": [{"title": "The Failure Rate of Hospitality Management Students in Win Courses at Tshwane University of Technology: Exploring Probable Causes", "author": ["J Annelize"], "venue": "Faculty of Management Sciences Tshwane", "citeRegEx": "1", "shortCiteRegEx": "1", "year": 2009}, {"title": "Predicting Student Exam\u2019s Scores by Analyzing Social Network Data", "author": ["M Fire", "G. Katz", "Y Elovici", "B Shapira", "L Rokach"], "venue": "AMT'12 Proceedings of the 8th international conference on Active Media Technology Springer-Verlag Berlin,", "citeRegEx": "3", "shortCiteRegEx": "3", "year": 2012}, {"title": "Predicting Student Failure Using Data Mining, Journal of Applied Intelligence", "author": ["C.M. Vera", "C. Romero", "S. Ventura"], "venue": "MA, USA,", "citeRegEx": "4", "shortCiteRegEx": "4", "year": 2011}, {"title": "Predicting Student Success on the Texas Chemistry STAAR Test: A Logistic Regression Analysis, http://eric.ed.gov/?id=ED534647", "author": ["W.L. Johnson", "A.M. Johnson", "Johnson J"], "venue": null, "citeRegEx": "5", "shortCiteRegEx": "5", "year": 2012}, {"title": "Neural Networks Refined: using a Genetic Algorithm to Identify Predictors of IS Student Success", "author": ["S Randall S"], "venue": "The Journal of Computer Information Systems,", "citeRegEx": "6", "shortCiteRegEx": "6", "year": 2001}, {"title": "Predictive Modeling and Analysis of Student Academic Performance in an Engineering  12  Dynamics Course", "author": ["S. Huang"], "venue": "All Graduate Theses and Dissertations.Paper1086,http://digitalcommons.usu.edu/etd", "citeRegEx": "7", "shortCiteRegEx": "7", "year": 2011}, {"title": "Predicting student academic performance in an engineering dynamics course: A comparison of four types of predictive mathematical models", "author": ["Huang S", "N. Fang"], "venue": "Journal of Computers and Education, Elsevier,", "citeRegEx": "8", "shortCiteRegEx": "8", "year": 2013}, {"title": "Using Genetic Algorithms and Decision Trees for a posteriori Analysis and Evaluation of Tutoring Practices based on Student Failure Models, in IFIP Intemational Federation for", "author": ["D. Kalles", "C. Pierrakeas"], "venue": "Information Processing,", "citeRegEx": "9", "shortCiteRegEx": "9", "year": 2006}, {"title": "Predicting student failure at school using Genetic Programming and different data mining approaches with high dimensional and imbalanced data, Springer Science", "author": ["C.M. Rquez-Vera", "A. Cano", "C. Romero", "S. Ventura"], "venue": "Business Media,", "citeRegEx": "10", "shortCiteRegEx": "10", "year": 2013}, {"title": "GPTIPS: Genetic Programming & SymbolicRegressionforMATLAB,http://gptips.sourceforge .net", "author": ["P. Searson"], "venue": null, "citeRegEx": "11", "shortCiteRegEx": "11", "year": 2009}, {"title": "Global solar irradiation prediction using a multi-gene genetic programming approach", "author": ["P Indranil", "S.P Daya", "D. Saptarshi"], "venue": "Journal of Renewable and Sustainable Energy, vol.5,", "citeRegEx": "12", "shortCiteRegEx": "12", "year": 2013}, {"title": "Secondary Student Perceptions of Factors affecting Failure in Science in Portugal, Eurasia", "author": ["M. Jesu\u00edna", "B. Fonseca", "C. Joseph E"], "venue": "Journal of Mathematics, Science and Technology Education,", "citeRegEx": "14", "shortCiteRegEx": "14", "year": 2006}, {"title": "Data Mining Algorithms to Classify Students, Proceedings of the 1 International Conference on Educational Data", "author": ["C. Romero", "S. Ventura", "P.G. Espejo", "C. Herv\u00e1s"], "venue": null, "citeRegEx": "16", "shortCiteRegEx": "16", "year": 2008}, {"title": "Predicting student success by mining enrolment data, Research in Higher Education Journal, pp.1-20", "author": ["J.K. Zlatko"], "venue": null, "citeRegEx": "18", "shortCiteRegEx": "18", "year": 2011}, {"title": "Discovering Decision Knowledge from Web Log Portfolio for Managing Classroom Processes by Applying Decision Tree and Data Cube Technology", "author": ["G. Chen"], "venue": "Journal of Educational Computing Research", "citeRegEx": "19", "shortCiteRegEx": "19", "year": 2000}, {"title": "Mining Student Learning Data to Develop High Level Pedagogic Strategy in a Medical ITS", "author": ["M.V. Yudelson"], "venue": "AAAI Workshop on Educational Data mining,", "citeRegEx": "20", "shortCiteRegEx": "20", "year": 2006}, {"title": "Can Log Files Analysis Estimate Learners", "author": ["M. Cocea", "S. Weibelzahl"], "venue": "Level of Motivation?, Workshop on Adaptivity and User Modeling in Interactive Systems, Hidelsheim,", "citeRegEx": "21", "shortCiteRegEx": "21", "year": 2006}, {"title": "Classifiers for educational data mining", "author": ["Hamalainen W", "M. Vinni"], "venue": "Chapman & Hall/VCRC London.pp", "citeRegEx": "22", "shortCiteRegEx": "22", "year": 2011}, {"title": "Predicting Performance from Test Scores using Backpropagation and Counter propagation", "author": ["L. Fausett", "W. Elwasif"], "venue": "IEEE Congress on Computational. pp", "citeRegEx": "23", "shortCiteRegEx": "23", "year": 1994}, {"title": "Predicting Student Outcome using Discriminant Function Analysis, Annual Meeting of the Research and Planning", "author": ["D. Martinez"], "venue": "Group, California,", "citeRegEx": "24", "shortCiteRegEx": "24", "year": 2001}, {"title": "Determination of Factors Influencing the Achievement of the First-year University Students using Data Mining Methods", "author": ["J.F. Superby", "J.P. Vandamme", "N. Meskens"], "venue": "Workshop on Educational Data Mining,", "citeRegEx": "25", "shortCiteRegEx": "25", "year": 2006}, {"title": "Checking the Reliability of GeSES: Method for Detecting Symptoms of Low Performance", "author": ["J. Bravo"], "venue": "Proceedings of the 9 International Conference on Intelligent Systems Design and Applications", "citeRegEx": "26", "shortCiteRegEx": "26", "year": 2009}, {"title": "Developing a generalizable detector of when student game the system, User Modeling and User-Adapted Interaction, April", "author": ["J. Baker"], "venue": null, "citeRegEx": "27", "shortCiteRegEx": "27", "year": 2002}, {"title": "Predicting and preventing student failure \u2013 using the k-nearest neighbour method to predict student performance in an online course environment", "author": ["T. Tanner", "H. Toivonen"], "venue": "Dept of Comp.Sc Helnsiki, Finland,", "citeRegEx": "28", "shortCiteRegEx": "28", "year": 2010}], "referenceMentions": [{"referenceID": 0, "context": "It refers to the proportion (or more correctly percentage) of students not graduating in a chosen course of study [1].", "startOffset": 114, "endOffset": 117}, {"referenceID": 1, "context": "Social graphs and data mining techniques [3, 4] have been suggested and some cases.", "startOffset": 41, "endOffset": 47}, {"referenceID": 2, "context": "Social graphs and data mining techniques [3, 4] have been suggested and some cases.", "startOffset": 41, "endOffset": 47}, {"referenceID": 3, "context": "Logistic and multiple linear regression techniques have also been used to study student failures rates [5, 14].", "startOffset": 103, "endOffset": 110}, {"referenceID": 11, "context": "Logistic and multiple linear regression techniques have also been used to study student failures rates [5, 14].", "startOffset": 103, "endOffset": 110}, {"referenceID": 4, "context": "Methodologies for investigating student failure rates or decline in academic performance using artificial intelligence techniques such as Neuro-Genetic Algorithms (NGAs), Artificial Neural Networks (ANNs), Genetic Algorithms and decision trees [6,7,8, 9], have been suggested and developed in the literature.", "startOffset": 244, "endOffset": 254}, {"referenceID": 5, "context": "Methodologies for investigating student failure rates or decline in academic performance using artificial intelligence techniques such as Neuro-Genetic Algorithms (NGAs), Artificial Neural Networks (ANNs), Genetic Algorithms and decision trees [6,7,8, 9], have been suggested and developed in the literature.", "startOffset": 244, "endOffset": 254}, {"referenceID": 6, "context": "Methodologies for investigating student failure rates or decline in academic performance using artificial intelligence techniques such as Neuro-Genetic Algorithms (NGAs), Artificial Neural Networks (ANNs), Genetic Algorithms and decision trees [6,7,8, 9], have been suggested and developed in the literature.", "startOffset": 244, "endOffset": 254}, {"referenceID": 7, "context": "Methodologies for investigating student failure rates or decline in academic performance using artificial intelligence techniques such as Neuro-Genetic Algorithms (NGAs), Artificial Neural Networks (ANNs), Genetic Algorithms and decision trees [6,7,8, 9], have been suggested and developed in the literature.", "startOffset": 244, "endOffset": 254}, {"referenceID": 8, "context": "2 identifies activities to stimulate its learning in a positive or negative way through the use of True Positive (TP) and True Negative (TN) concepts [10].", "startOffset": 150, "endOffset": 154}, {"referenceID": 3, "context": "Models such as the Logistic Regression Model [5] have been used to predict the actual probability that a student will pass or fail a Chemistry test.", "startOffset": 45, "endOffset": 48}, {"referenceID": 13, "context": "Classification and Regression trees [18] have been used to predict students passing or failing a subject taking into consideration six sociodemographic variables (age, gender, ethnicity, education, work status, and disability).", "startOffset": 36, "endOffset": 40}, {"referenceID": 13, "context": "However, as the author [18] pointed out in his concluding remarks, limitations do exist with the use of classification trees which could distort results obtained in the classification process and as in the case of the logistic regression, the prevalence of small data sets leads to low prediction accuracies.", "startOffset": 23, "endOffset": 27}, {"referenceID": 2, "context": "More recently, educational data mining techniques [4, 6] have been applied to the growing problem of predicting student failure rate with high degree of success rates.", "startOffset": 50, "endOffset": 56}, {"referenceID": 4, "context": "More recently, educational data mining techniques [4, 6] have been applied to the growing problem of predicting student failure rate with high degree of success rates.", "startOffset": 50, "endOffset": 56}, {"referenceID": 12, "context": "One of the most useful Data Mining tasks on educational data mining is classification [16].", "startOffset": 86, "endOffset": 90}, {"referenceID": 14, "context": "There are different educational objectives for using classification, such as: discovery of potential student groups with similar characteristics and reactions to a particular pedagogical strategy[19], to detect student\u2019s \u201fmisuse or game-playing\u201f the system which is correlated with substantially lower learning [27], to group students that are hint-driven or failure driven and find common misconceptions that students possess [20], to identify learners with a low rate of motivation and find remedial actions to lower drop-out rates [21], to classify/predict students when Intelligent Tutoring Systems (ITS) are being used [22].", "startOffset": 195, "endOffset": 199}, {"referenceID": 22, "context": "There are different educational objectives for using classification, such as: discovery of potential student groups with similar characteristics and reactions to a particular pedagogical strategy[19], to detect student\u2019s \u201fmisuse or game-playing\u201f the system which is correlated with substantially lower learning [27], to group students that are hint-driven or failure driven and find common misconceptions that students possess [20], to identify learners with a low rate of motivation and find remedial actions to lower drop-out rates [21], to classify/predict students when Intelligent Tutoring Systems (ITS) are being used [22].", "startOffset": 311, "endOffset": 315}, {"referenceID": 15, "context": "There are different educational objectives for using classification, such as: discovery of potential student groups with similar characteristics and reactions to a particular pedagogical strategy[19], to detect student\u2019s \u201fmisuse or game-playing\u201f the system which is correlated with substantially lower learning [27], to group students that are hint-driven or failure driven and find common misconceptions that students possess [20], to identify learners with a low rate of motivation and find remedial actions to lower drop-out rates [21], to classify/predict students when Intelligent Tutoring Systems (ITS) are being used [22].", "startOffset": 427, "endOffset": 431}, {"referenceID": 16, "context": "There are different educational objectives for using classification, such as: discovery of potential student groups with similar characteristics and reactions to a particular pedagogical strategy[19], to detect student\u2019s \u201fmisuse or game-playing\u201f the system which is correlated with substantially lower learning [27], to group students that are hint-driven or failure driven and find common misconceptions that students possess [20], to identify learners with a low rate of motivation and find remedial actions to lower drop-out rates [21], to classify/predict students when Intelligent Tutoring Systems (ITS) are being used [22].", "startOffset": 534, "endOffset": 538}, {"referenceID": 17, "context": "There are different educational objectives for using classification, such as: discovery of potential student groups with similar characteristics and reactions to a particular pedagogical strategy[19], to detect student\u2019s \u201fmisuse or game-playing\u201f the system which is correlated with substantially lower learning [27], to group students that are hint-driven or failure driven and find common misconceptions that students possess [20], to identify learners with a low rate of motivation and find remedial actions to lower drop-out rates [21], to classify/predict students when Intelligent Tutoring Systems (ITS) are being used [22].", "startOffset": 624, "endOffset": 628}, {"referenceID": 18, "context": "To predict student outcome, some studies have been made: prediction of student\u2019s grades, on a scale from A to F, from test scores using neural networks (counter propagation networks and back propagation networks) [23]; prediction of the relevance of classes, i.", "startOffset": 213, "endOffset": 217}, {"referenceID": 19, "context": ", if classes are relevant or not to student\u2019s academic success, using discriminant function analysis [24] Predicting a student\u2019s academic success (low, medium or high risk) using decision trees, random forests and neural networks [25].", "startOffset": 101, "endOffset": 105}, {"referenceID": 20, "context": ", if classes are relevant or not to student\u2019s academic success, using discriminant function analysis [24] Predicting a student\u2019s academic success (low, medium or high risk) using decision trees, random forests and neural networks [25].", "startOffset": 230, "endOffset": 234}, {"referenceID": 21, "context": "Using GeSES [26], a method that has been designed specifically to work with students logs, based on C4.", "startOffset": 12, "endOffset": 16}, {"referenceID": 8, "context": "G3PMI [10], a grammar guided genetic programming algorithm, has been applied to predict if the student will fail or pass a determined course and identifies activities to stimulate its learning in a positive or negative way through the use of True Positive (TP) and True Negative (TN) concepts.", "startOffset": 6, "endOffset": 10}, {"referenceID": 23, "context": "Tanner [28] used a k-nearest neighbour (kNN) method to predict student performance in an online course environment.", "startOffset": 7, "endOffset": 11}, {"referenceID": 7, "context": "Kalles [9] used Genetic Algorithms and Decision trees for a posteriori analysis of tutoring practices based on Student\u2019s failure models.", "startOffset": 7, "endOffset": 10}, {"referenceID": 8, "context": "In [10], data mining techniques and real data of about 670 middleschool students from Zacatecas, M\u00e9xico were used to predict school failure.", "startOffset": 3, "endOffset": 7}, {"referenceID": 8, "context": ", academic, psychosocial, and behavioural) for the purpose of identifying risk, referring students to intervention, and improving academic success [10].", "startOffset": 147, "endOffset": 151}, {"referenceID": 9, "context": "This approach uses an iterative radical unified modelling process wherein In particular we have used an open source framework for genetic programming GPTIPS\u00ae [11], as a basis for the developed GP application.", "startOffset": 158, "endOffset": 162}, {"referenceID": 10, "context": "2 Genetic Programming Process The fundamental mathematical formulations guiding a genetic programming application and corresponding pseudo-codes are not new and are given in [12].", "startOffset": 174, "endOffset": 178}, {"referenceID": 9, "context": "Step 2 to 7 is achieved using the rungp functional class [11].", "startOffset": 57, "endOffset": 61}, {"referenceID": 6, "context": "In Table2, the GP parameters for the analysis and prediction process are presented taking into account bloat constraints [8].", "startOffset": 121, "endOffset": 124}, {"referenceID": 10, "context": "In other words, if another solution has a lower fitness value then it must have a higher model complexity and vice-versa [12].", "startOffset": 121, "endOffset": 125}], "year": 2014, "abstractText": "Several efforts to predict student failure rate (SFR) at school accurately still remains a core problem area faced by many in the educational sector. The procedure for forecasting SFR are rigid and most often times require data scaling or conversion into binary form such as is the case of the logistic model which may lead to lose of information and effect size attenuation. Also, the high number of factors, incomplete and unbalanced dataset, and black boxing issues as in Artificial Neural Networks and Fuzzy logic systems exposes the need for more efficient tools. Currently the application of Genetic Programming (GP) holds great promises and has produced tremendous positive results in different sectors. In this regard, this study developed GPSFARPS, a software application to provide a robust solution to the prediction of SFR using an evolutionary algorithm known as multi-gene genetic programming. The approach is validated by feeding a testing data set to the evolved GP models. Result obtained from GPSFARPS simulations show its unique ability to evolve a suitable failure rate expression with a fast convergence at 30 generations from a maximum specified generation of 500. The multigene system was also able to minimize the evolved model expression and accurately predict student failure rate using a subset of the original expression.", "creator": "Nitro Pro 8  (8. 0. 10. 7)"}}}