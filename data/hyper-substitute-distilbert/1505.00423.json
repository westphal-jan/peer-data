{"id": "1505.00423", "review": {"conference": "arxiv", "VERSION": "v1", "DATE_OF_SUBMISSION": "3-May-2015", "title": "Optimal Time-Series Motifs", "abstract": "motifs are geographically most repetitive / complex patterns of a time - graph. the discovery where motifs offers historical tool techniques in linguistics to understand and interpret cyclic interaction occurring generating sequential data. currently, motifs are searched among series poly - sequences, aiming at retrieval the most structurally varied ones. search - sensing methods, which filtered out long sub - sequence as motif candidates, currently traditionally believed to be the best searches versus finding the most recurring patterns.", "histories": [["v1", "Sun, 3 May 2015 12:11:43 GMT  (249kb,D)", "http://arxiv.org/abs/1505.00423v1", "Submitted to KDD2015"]], "COMMENTS": "Submitted to KDD2015", "reviews": [], "SUBJECTS": "cs.AI cs.LG", "authors": ["josif grabocka", "nicolas schilling", "lars schmidt-thieme"], "accepted": false, "id": "1505.00423"}, "pdf": {"name": "1505.00423.pdf", "metadata": {"source": "CRF", "title": "Optimal Time-Series Motifs", "authors": ["Josif Grabocka", "Nicolas Schilling", "Lars Schmidt-Thieme"], "emails": ["josif@ismll.de", "schilling@ismll.de", "schmidt-thieme@ismll.de"], "sections": [{"heading": null, "text": "However, this paper proposes an entirely new perspective in finding motifs. We demonstrate that searching is nonoptimal since the domain of motifs is restricted, and instead we propose a principled optimization approach able to find optimal motifs. We treat the occurrence frequency as a function and time-series motifs as its parameters, therefore we learn the optimal motifs that maximize the frequency function. In contrast to searching, our method is able to discover the most repetitive patterns (hence optimal), even in cases where they do not explicitly occur as sub-sequences. Experiments on several real-life time-series datasets show that the motifs found by our method are highly more frequent than the ones found through searching, for exactly the same distance threshold.\nKeywords Time series, Repeating patterns, Motifs"}, {"heading": "1. INTRODUCTION", "text": "Time-series are arguably the most widespread type of data which occur in virtually all the application domains of our modern lives, wherever measurements have associated time stamps (e.g.: physiological and medical, financial, meteorological, sound and video, monitoring system sensors, astronomy light intensities, and many more ).\nIn many cases, the underlying patterns of those datasets are not known to the domain practitioners and a visual inspection is often infeasible given the complexity and size of the data. For this reason, finding the most repetitive\nPermission to make digital or hard copies of all or part of this work for personal or classroom use is granted without fee provided that copies are not made or distributed for profit or commercial advantage and that copies bear this notice and the full citation on the first page. To copy otherwise, to republish, to post on servers or to redistribute to lists, requires prior specific permission and/or a fee. XXX XXXX XXXXXXXXXXXXXXXX Copyright 20XX ACM X-XXXXX-XX-X/XX/XX ...$15.00.\npatterns in time-series help the domain experts understand the underlying phenomena within diverse sources of data [2, 26]. The most repetitive time-series patterns are called motifs and their discovery has recently attracted considerable research [25, 20, 30, 14]. In brief terms, optimal motifs are those which repeat the most (i.e. have the highest frequency) given a distance/similarity threshold value. The approach of the current state-of-the-art motif discovery methods is to search the motifs from the segments (a.k.a sub-sequences) of time series [25, 28, 14, 3]. More concretely, series segments are considered to be motif candidates and the most frequent segments are sorted out.\nIn this paper we present an entirely new and orthogonally different perspective to the search-based approach. First of all, we treat frequency as a function and motifs as its variable. Naturally our task becomes finding the values of motifs which maximize the value of the frequency function. In this perspective we formalize motif discovery as a principled optimization problem and devise an optimization technique to learn the optimal motifs. The learning process uses the first order derivative of the frequency function, in order to find its maximum. In that way, our method can learn motifs which yield the maximum frequency (a.k.a the highest number of matches). The proposed learning method is theoretically superior to the search-based approach, because in the case of searching the motif candidates are limited to the domain of sub-sequences and cannot discover latent series patterns (Section 4.1) .\nAs the empirical results (Section 6) over various reallife datasets will indicate, our optimal motifs have significantly more matches (higher frequency) than the ones found through searching, for exactly the same distance threshold."}, {"heading": "2. RELATED WORK", "text": "The research on discovering time-series motifs has suffered from a terminological ambiguity. Initially, motifs were defined to be the most frequently occurring patterns in a timeseries [25]. However, another stream of papers redefined the term \u201dmotif\u201d as the closest pair among series segments [23, 21]. In this paper we mean \u201dthe most frequently occurring patterns\u201d [25] when referring to motifs. The closest pair of series segments, on the other hand, will be referred to as \u201dpair-motif\u201d following the suggestion of [19]."}, {"heading": "2.1 Pair-motif discovery", "text": "The closest pair of series segments can be perceived as a sub-variation of the general motif discovery task. The brute-force search that computes the distance of every seg-\nar X\niv :1\n50 5.\n00 42\n3v 1\n[ cs\n.A I]\n3 M\nay 2\n01 5\nment pair is computationally expensive, therefore efforts are devoted towards scaling the brute force up. A fast, yet exact, method that discovers pair-wise motifs has been introduced by [23]. Enumerations of all motifs having variable lengths has also been researched [20, 19]. In a streaming scenario an algorithm can not rely on accessing the full past series, therefore we need to find the top-k motif search via an on-line method as in [12]. In addition, the statistical significance of the motifs found has also been a topic of interest [4, 5].\nNote: Finding motif-pairs is equivalent to the problem of locating the closest pair of points in a geometrical space and is a historic problem in computational geometry [8]."}, {"heading": "2.2 Motif Discovery", "text": "Repeating patterns in sequential data have initially been studied in bio-informatics [2]. However, finding motifs is beneficial in understanding physiological human data [26], while being also useful in understanding behavioral patterns of living organisms [1]. The concept of recurrent patterns was transferred to the realm of time-series data under the term \u201dmotifs\u201d [25] and a search-based approach to discovering motifs was proposed. In order to find motifs that are immune to noisy variations, a probabilistic search of timeseries motifs was based on random projections [7]. Another work has explored the employment of uniform scaling as the similarity distance used for discovering the motifs [28]. Furthermore, a hybrid combination of supervised and unsupervised learning has been used for searching recurring patterns [24]. The first step involves a teacher which labels whether or not a time series includes a particular pattern, while in the next step an unsupervised learning from the series in order to reconstruct the teacher is exploited. The task of finding the most recurring motifs has also been tackled through searching for candidate motifs organized in a tree structure [15].\nThe brute-force approach which tries out every segment (sub-sequence) as a potential motif has a quadratic complexity in the number of segments. Therefore approximate motif discovery methods have been exploited. Conversion of motifs into a symbolic representation (named SAX) is a preprocessing alternative [10]. Over the new representation an agglomerative clustering can be used to find motifs [10]. A scalable alternative that can approximately discover multiresolution motifs in a single scan utilizes different cardinalities of the symbolic representation [3]. Last but not least, a scalable version of the pair-wise motifs has been extended to the general motifs discovery for large-scale data [22].\nGiven the widespread of multi-dimensional time series, there has also been interest in mining multi-dimensional motifs too. Several strategies were inspected, where motifs span all versus a subset of the dimensions, with or without temporal overlap [17]. The algorithm is based on random projections of the symbolic sub-sequence representations [17]. Discovering regions of high density in the space of sub-sequencies is another alternative to mining multivariate motifs [18]. Graph clustering implemented as a two-staged algorithm was also employed in detecting multidimensional motifs [27]. In the first step single-dimensional motifs are discovered and later blended through clustering [27].\nSince motifs are previously unknown patterns, there is little information on the motifs\u2019 lengths too. Under such a reality authors attempted to discover the optimal motif\nlength, for instance by inspecting the compressibility of the data [30]. In addition, variable-length motifs can be extracted using a grammar-inspired inference process [13]. Interest has been attracted in terms of visualizing variablelength motifs [14], finding them in linear time [6], or using them for classification purposes [29].\nIn contrast to the related work, our novel contribution relies in computing an optimal set of motifs given a threshold distance and the motifs\u2019 length. We are the first to propose a principled optimization method for the task. As a consequence, our approach leads to significantly improved motif quality (frequency) compared to brute-force search."}, {"heading": "3. PRELIMINARIES", "text": ""}, {"heading": "3.1 Notations", "text": "3.1.1 Time Series and Motifs A time series is a long ordered sequence of real-valued\nmeasurements. Such a series is abstracted as a list of J-many Z-normalized sliding-window segments of length L and is denoted as S \u2208 RJ\u00d7L. On the other hand, a repetitive pattern, a.k.a motif, is simply a sequence of L points. The definition can be generalized to a set of K-motifs and consecutively denoted as M \u2208 RK\u00d7L.\n3.1.2 Motif Frequency The occurrence frequency of a motif is defined as the non-\ntrivial (see Section 3.2.2) number of matches between a motif and all the normalized segments of the time series. The current approach of counting the matching frequency of the k-th motif, denotedMk,: \u2208 RL, iterates over all the j \u2208 {1, . . . , J} sliding window segments Sj,: and check whether the motif of interest matches the segments within a threshold distance T \u2208 R+.\nF(M) = K\u2211 k=1 J\u2211 j=1 Fk,j (1)\nFk,j =\n{ 1 if (\u2211L l=1 (Mk,l \u2212 Sj,l) 2 ) < T\n0 otherwise (2)\nEquation 1 presents the formalism for the overall frequency as a sum of motifs\u2019 frequencies, while Equation 2 encapsulates the concept of a match. If the distance between a segment Sj,: and a motif Mk,: is less than the threshold T , then a matching value of one is granted."}, {"heading": "3.2 Problem Definition", "text": "3.2.1 Optimal Motifs Following the established literature definition, the only\noptimality criterion of a motif is its frequency at a particular distance threshold. Therefore, the only legitimate metric to compare the qualities of motifs is frequency (a.k.a. support, or number of matches). The optimal motifs M\u2217 for a time series are defined in Equation 3 as the candidate motifs M that achieve the maximum frequency value F(M) from Equation 1. There is, nevertheless, an important constraint in the search for motifs: The K motifs should be different from each other [25], otherwise, the motifs risk being close variations of the single most repetitive motif. Such a constraint is presented under a \u201dsuch that (s.t.)\u201d clause in\nEquation 3, which enforces each pair of motifs (Mk,:,Mp,:) to be different from each other by a distance of at least 2T (so each pair does not overlap within a threshold T , details in [25]).\nM\u2217 := argmax M\u2208RK\u00d7L F(M) (3)\ns.t.: ( L\u2211 l=1 (Mk,l \u2212Mp,l)2 ) > 2T,\n\u2200k \u2208 {1, . . . ,K}, \u2200p \u2208 {k + 1, . . . ,K}\n3.2.2 Trivial Matches Stated shortly, trivial matches are consecutive segments\nwhich match the same motif [25]. For instance, this case might happen if the sliding window is incremented by one. In that case two subsequent segments will share exactly L\u2212 1 points and therefore the distance of any motif to those close-by segments will be very similar. Some related work increment the sliding window by an offset of points, therefore trivial matches can be trans-passed at the risk of potentially missing certain matches [3, 18]. However, in our paper all the reported figures on frequency do not include any trivial match throughout the experiments."}, {"heading": "3.3 Searching The Motifs", "text": "The state-of-the-art methods referred in Section 2 focusing on searching motifs are primarily concerned with trying candidate motifs from the series segments. Despite proposing important novelties in their scope (scalability, length analysis, etc . . . ) still these techniques are upper bounded in terms of quality by the brute-force motif search.\nAlgorithm 1 describes a speed-wise naive, yet qualitatively search-optimal implementation of a brute-force motif search. We can pre-compute the frequencies of all series segments in O(J2L) runtime complexity and then search the top-K motifs using the computed frequencies in O(K2JL) time. Since K is typically a small number compared to the segments J >> K, therefore the overall brute-force search has a complexity of O(J2L + K2JL) \u223c O(J2L), meaning quadratic in the number of segments. In this paper we propose a learning (not searching) method that outputs motifs having higher frequencies than those discovered by the brute-force approach."}, {"heading": "4. PROPOSED METHOD", "text": ""}, {"heading": "4.1 Motivation", "text": "The state-of-the-art methods used for finding motifs are based on searching for the most frequently occurring candidate segment. In other words, any motif has to explicitly occur as a series segments Mk,: \u2208 S, \u2200k \u2208 NKk=1. Unfortunately, such constrained motifs are very restricted in the finite space of possible values they can have, compared to the space of real matrices M \u2208 RK\u00d7L (infinitely more candidates than M \u2208 S). In this paper, we hypothesize and empirically show that the optimal motifs are located in the space of real numbers M \u2208 RK\u00d7L, while the space of segments contains sub-optimal motifs. Figure 1 provides a hint for the comparison between restricted motifs (M \u2208 S) and un-restricted optimal ones. From a geometrical perspective the segments and the motifs are points in an L-dimensional\nAlgorithm 1 BruteForceMotifSearch()\n1: Input: Threshold T \u2208 R+, Motif length L \u2208 N+, Number of Motifs K \u2208 N+, Segments S \u2208 RJ\u00d7L 2: Output: M \u2208 RK\u00d7L 3: // Precompute frequencies of all segments 4: for j = 1, . . . , J do 5: Fj \u2190 0 6: lastMatchIndex\u2190 \u2212\u221e 7: for r = 1, . . . , J do 8: if ||Sj,: \u2212 Sr,:||22 < T then 9: // Avoid trivial matches\n10: if r \u2212 lastMatchIndex > 1 then 11: Fj \u2190 Fj + 1 12: end if 13: lastMatchIndex\u2190 r 14: end if 15: end for 16: end for 17: // Select top-K motifs 18: for k = 1, . . . ,K do 19: bestj \u2190 0 20: for j = 1, . . . , J do 21: // Check if the j-th segment is diverse 22: if ||Sj,: \u2212Mp,:||22 > 2T, \u2200p = k \u2212 1, . . . , 1 then 23: if Fbestj > Fj then 24: bestj \u2190 j 25: end if 26: end if 27: end for 28: Mk,: \u2190 Sbestj ,: 29: end for 30: return M\nspace. In the example of Figure 1 the segments and motifs have a length of 2, thus the scenario is 2-dimensional.\nThe frequency of a motif M , given a threshold T , can be interpreted as the number of segment points (blue in the illustration) that lies within a radius of the threshold distance from the motif (shown in red). The radius is \u221a T because we used the squared-Euclidean distance in Equation 2, however this poses no problems since T is anyway a hyperparameter of our method. The most frequently occurring motif is defined to be the point that covers the maximum number of blue points (segments) inside the circle of radius\u221a T that is centered at the motif, hence the densest geometrical ball [15]. The best segment-motif is shown in the\nleft plot of Figure 1 and has a frequency of three. However, the optimal motif is located in the right plot and has a frequency of four. As clearly seen, the optimal solution is hidden in the space of real numbers, outside the very restricted set of segment points. The method proposed in this paper learns optimal motifs lying in the real-numbers space through a tailored numerical optimization technique. Even though the aforementioned 2-dimensional example was created to awake the reader on the need for learning motifs, still empirical results of Section 6.2 will demonstrate that learning motifs yields more frequently occurring patterns, compared to searching them, on real-life time series."}, {"heading": "4.2 Smooth (Differentiable) Motif Frequency", "text": "We are going to find the optimal motif through a mathematical maximization of the frequency as a function of the motifs. Unfortunately, the frequency of Equation 1 has two problems (i) it is not continuous at point ||Mk,: \u2212 Sj,:|| = T and (ii) first derivative is zero in all other points (i.e. frequency is flat having values 1 or 0). Therefore we cannot compute the optimal motifs using gradient-based optimization. However, we can use a differentiable approximation for the frequency function using the Gaussian kernel of Equations 4-5.\nF\u0302(M) = 1 KJ K\u2211 k=1 J\u2211 j=1 F\u0302k,j (4)\nF\u0302k,j = e\u2212 \u03b1 T\n\u2211L l=1(Mk,l\u2212Sj,l) 2\n(5)\nThe smooth frequency function of Equation 5 is both an accurate approximation to the frequency measure from Equation 2, but also a differentiable alternative, as illustrated in Figure 2 (left plot). The parameter \u03b1 controls the smoothness of the soft frequency. For optimization reasons (details in Section 4.4) the frequency sum of Equation 4 is divided by KJ to limit the value of F\u0302 between 0 and 1. In terms of notation, the approximated frequency is distinguished by a hat (F vs F\u0302)."}, {"heading": "4.3 Motif Diversity Violation", "text": "As previously described in Equation 3 the motifs need to be distant by a margin of 2T . We call such a property as motif diversity. In that line, this section is devoted to formalizing a differentiable penalty function for the violations of the distances among motifs from the diversity threshold of 2T . As a first step, the distance between two motifs Mk,: \u2208 RL\nand Mp,: \u2208 RL is defined as \u03c6k,p : ( RL \u00d7 RL ) \u2192 R and formalized in Equation 6.\n\u03c6k,p = L\u2211 l=1 (Mk,l \u2212Mp,l)2 (6)\nThe distance \u03c6k,p of any pair of motifs Mk,:,Mp,: should obey to the diversity constraint shown in Equation 7.\n\u03c6k,p > 2T, \u2200k \u2208 ({1, . . . ,K}, \u2200p \u2208 {k + 1, . . . ,K}) (7)\nWe introduce the concept of diversity violation by Equa-\ntions 8-9. For each of the K(K\u22121) 2\npairs of motifs, the violation is 0 if the distance between the pair motifs is greater than 2T . Otherwise, if the distance is zero then the motifs are identical (hence not at all diverse) and a maximum violation of one is returned. For all the distances between 0 and 2T a linear violation between 0 and 1 is returned as formalized in Equation 9. The constant term 2\nK(K\u22121) makes\nsure that the violation function has a range between 0 and 1, the same range as the approximative frequency.\nV(M) = 2 K(K \u2212 1) K\u2211 k=1 K\u2211 p=k+1 Vk,p (8)\nVk,p =\n{ 1\u2212 \u03c6k,p\n2T \u03c6k,p < 2T\n0 \u03c6k,p \u2265 2T (9)\nDespite achieving its aim, the violation penalty of Equations 8-9 still it suffers in terms of differentiability at the point \u03c6k,p = 2T . Therefore, we are proposing a smooth and differentiable variant of the violation penalty in Equations 10-11 by squaring the hard violation of Equation 9.\nV\u0302(M) = 2 K(K \u2212 1) K\u2211 k=1 K\u2211 p=k+1 V\u0302k,p (10)\nV\u0302k,p =  ( 1\u2212 \u03c6k,p 2T )2 \u03c6k,p < 2T\n0 \u03c6k,p \u2265 2T (11)\nAs in the case of the frequency, we denote the smooth approximative version of the violation penalty by a hat (V for hard and V\u0302 for smooth). The violation penalty as a function of the distance between motif pairs is depicted in the right plot of Figure 2."}, {"heading": "4.4 Motif Learning Through Optimization", "text": "This section fuses the smooth motif frequency and smooth motif diversity violation into a meaningful objective function. Our aim is to learn a set of K motifs that maximize the frequencies and minimize (have no) violations. Such an objective can be elegantly constructed as the maximization task of Equation 12.\nM\u2217 = argmax M O(M)\n= argmax M\nF\u0302(M)\u2212 V\u0302(M) (12)\nThe universally optimal motifs are those which achieve the universal maximum value of our objective function O(M) = F\u0302(M)\u2212 V\u0302(M). As both terms are positive, the objective is maximized for the highest motif frequencies and zero violations. In this paper we will optimize the objective function\nthrough gradient ascent motif updates in a series of iterations. Since both ranges of F\u0302 and V\u0302 are between 0 and 1, no term over-scales the other and the overall learning does converge. In our preliminary experiments we found out that a trade-off coefficient \u03b2 in the form F\u0302(M)\u2212\u03b2V\u0302(M) was not needed as both terms converge quickly.\nThe output of the learning process is a set of motifs M , as shown in Figure 3 for the \u201dInsect B\u201d time series. In this illustration the top three motifs (K = 3) are shown on the right plots, while the matches of the motifs on the time series are shown in the upper-left plot. Z-normalized versions of the matched segments are shown in the middle-left plot and the lower-left plot illustrates the per-segment smooth frequency scores of the motifs.\n4.4.1 Gradient Ascent Optimization Since the objective function of Equation 12 is a subtrac-\ntion of frequency and diversity violations, the partial gradient of the objective function with respect to each point l of any k-th motif is decomposable as shown in Equation 13.\n\u2202O(M) \u2202Mk,l = \u2202F\u0302(M) \u2202Mk,l \u2212 \u2202V\u0302(M) \u2202Mk,l\n(13)\nThe partial derivative of the smooth frequency with respect to the motif is computed as the first derivative of Equation 4 in terms of M and shown below in Equation 14.\n\u2202F\u0302(M) \u2202Mk,l = \u22122\u03b1 KJT J\u2211 j=1 (Mk,l \u2212 Sj,l) F\u0302k,j (14)\nSimilarly the partial derivative of the diversity violation with respect to each motif\u2019s point is defined in Equation 15.\n\u2202V\u0302(M) \u2202Mk,l = 2 K(K \u2212 1) K\u2211 q=1 \u2202V\u0302k,q \u2202Mk,l\n(15)\n\u2202V\u0302k,q \u2202Mk,l =\n{ (\u03c6k,q\u22122T)(Mk,l\u2212Mq,l)\nT2 \u03c6k,q < 2T\n0 \u03c6k,q \u2265 2T"}, {"heading": "4.5 Learning Algorithm", "text": "Having defined the partial derivative needed for gradient ascent, we can present the complete learning method. Our method is detailed in Algorithm 2 and in this section we will explain the steps of the algorithm in detail. There are a set of hyper-parameters to the learning process, starting with the frequency smoothness \u03b1. The other important hyperparameters are the number of motifs K, the threshold T and the motif length L, to be set by a practitioner. The learning rate \u03b7 and the number of iterations I are less critical hyperparameters that control the number of steps needed until convergence. For small learning rates and large number of iterations, the convergence is safely achievable.\nThe algorithm starts with a set of motifs initialized from random segments and updates them in the direction of the partial gradients using a learning rate step size. The learning rate is dynamically updated per each point of each motif using an adaptive technique known as AdaGrad [9]. We accumulate the square of the partial gradients into accumulators denoted by \u2207. In order to speed-up the updates we pre-compute the per-segment frequencies F\u0302k,j and pair distances \u03c6k,q in lines 9-12. Then every point of each motif Mk,l is updated in the positive direction of the derivative in lines 13-25. The partial gradients correspond to the ones previously explained in Section 4.4.1. The update of line 24 adjusts the learning rate by the square root of the accumulated square gradients [9].\nAs a consequence of the gradient ascent updates, the motifs undergo a metamorphosis as is shown in Figure 4 for the \u201dFull EOG\u201d time series. The illustrative motifs are learned on the first 10000 non-overlapping segments of the time series having length L = 150. At the beginning (Iteration 0) the motifs are random and the corresponding frequencies zero, however the motifs start to take form after approximately 20 iterations and converge after 40 iterations. The metamorphosis of the motifs is conducted such that their matching frequencies (lower plots) are maximized."}, {"heading": "4.6 Convergence of The Learning Algorithm", "text": "The learning algorithm converges by updating the motifs so that the approximative frequency is maximized and\nAlgorithm 2 LearnMotifs()\n1: Input: Threshold T \u2208 R+, Motif length L \u2208 N+, Number of Motifs K \u2208 N+, Segments S \u2208 RJ\u00d7L, Learning Rate \u03b7 \u2208 R+, Number of iterations I \u2208 N+, Smoothness \u03b1 \u2208 R+ 2: Output: Motif M \u2208 RK\u00d7L 3: // Initialize random motifs and gradient accumulators: 4: M \u2190 ( SU(1,J),: )K ,\u2207 \u2190 0K\u00d7L 5: // Initialize constant values: 6: cV\u0302 \u2190 2 K(K\u22121)T2 , cF\u0302 \u2190 \u22122\u03b1 KJT 7: // Iterate the learning method: 8: for iter= 1, . . . , I do 9: // Precompute the per-segment occurence scores:\n10: F\u0302k,j \u2190 e\u2212 \u03b1 T\n\u2211L l=1(Mk,l\u2212Sj,l) 2\n\u2200k \u2208 NK1 ,\u2200j \u2208 NJ1 11: // Precompute the pair-wise motif distances:\n12: \u03c6k,q \u2190 L\u2211 l=1\n(Mk,l \u2212Mq,l)2 , \u2200k \u2208 NK1 , \u2200q \u2208 NK1 13: // Update the motifs : 14: for k = 1, . . . ,K; l = 1, . . . , L do 15: // Gradient of frequency w.r.t. the motif:\n16: \u2202F\u0302(M) \u2202Mk,l = cF\u0302 J\u2211 j=1 (Mk,l \u2212 Sj,l) F\u0302k,j 17: // Gradient of diversity violation w.r.t. the motif:\n18: \u2202V\u0302(M) \u2202Mk,l = cV\u0302 K\u2211 q=1 { (\u03c6k,q \u2212 2T ) (Mk,l \u2212Mq,l) \u03c6k,q < 2T 0 \u03c6k,q \u2265 2T\n19: // Gradient of the final objective w.r.t. the motif: 20: \u2202O(M) \u2202Mk,l \u2190 \u2202F\u0302(M) \u2202Mk,l \u2212 \u2202V\u0302(M) \u2202Mk,l 21: // Update the history of gradients:\n22: \u2207k,l \u2190 \u2207k,l + ( \u2202O(M) \u2202Mk,l )2 23: // Update the motif point: 24: Mk,l \u2190Mk,l + \u03b7\u221a\u2207k,l \u2202O(M) \u2202Mk,l 25: end for 26: end for 27: return M\nthe diversity violations minimized to zero as shown in Figure 5 (left plot) for an execution on the \u201dInsect B\u201d dataset. It is worth noting that the inclusion of the penalty on the diversity violation is crucial for preserving the diversity constraint. An experiment is shown on the right plot of Figure 5. In this experiment the line 24 of Algorithm 2 is edited so the motifs are updated only with respect to the frequency and not diversity violation (see plot title). As we can clearly see,\nmaximizing the frequencies without penalizing diversity violations causes the motifs to be similar to each other. That is demonstrated by the fact that the violation measure increases, as shown in the right plot of Figure 5."}, {"heading": "5. OPTIMALITY OF OUR METHOD", "text": "The objective function of Equation 12 is not concave, because the frequency function is a sum of Gaussians and not concave. We demonstrate the non-concavity of the frequency function in Figure 6 using the TAO and EEG LSF5 datasets. Here we generate all possible motifs of length 500 using two values, (for the sake of a 3d-plot), one value for all the first 250 points in X-axis and another value for the last 250 points in the Y-axis. As can be clearly seen, frequency is not a concave function in terms of motifs and has multiple local maxima.\nIn case of non-concave functions (or non-convex for minimization problems), an effective cook-book solution is to combine gradient descent with a random-restart strategy [16]. In order to avoid getting stuck in local maxima, the gradient descent optimization is restarted multiple times with random initial values for the motifs. The run that achieves the highest F(M) is selected, as is formalized in Equation 16, where the number of restarts is denoted by R \u2208 N. It is important to recognize that we select the motifs yielding the highest hard frequency F , not the proxy smooth one F\u0302 . The hard frequency F does avoid counting trivial matches in our implementation.\nM\u2217 := argmax M(r), r=1,...,R F(M (r)) (16)\ns.t. M (r) \u2190 LearnMotif() from Alg 2\nFigure 7 illustrates the effect of 50 random restarts on the frequency function F(M) values over the TAO dataset. On the left plot we see that the maximum values of the objective are reached after a few restarts. The distribution of the frequency values, shown in the right plot, demonstrates that the histogram is normally distributed. That means there is a normal probability that a restart will yield an optimal value on the right portion (maximal) of the values within."}, {"heading": "5.1 Runtime Algorithmic Complexity", "text": "The runtime complexity of Algorithm 2 is determined by the pre-computation steps and the update steps. Computing of the frequency terms has an algorithmic complexity order of O(RIKJL), while computing the pairwise distances has a computational complexity of O(RIK2L). The computation of the partial gradients of the frequency with re-\nspect to the motifs has a complexity of O(RIKJL). Similarly the complexity of computing the gradients of the diversity violation with respect to the motif has a complexity of O(RIK2L). The overall complexity of the algorithm is O(RIKJL+RIK2L+RIKJL+RIK2L), which translates to O(2RIK (J +K)L) \u223c O(RIKJL) since K << J . The brute force search on the other hand, has a complexity of O(J2L) which is quadratic in terms of the number of segments J . In contrast our method is linear in terms of the number of segments J and faster than the brute-force search in case RIK < J . It is worth reminding that our algorithm learns optimal motifs (brute-force finds non-optimal motifs) and the primary strength is quality at a feasible runtime."}, {"heading": "6. EMPIRICAL RESULTS", "text": ""}, {"heading": "6.1 Experimental Setup", "text": "We compare the quality of the proposed methods against the brute-force search strategy using a battery of six timeseries datasets from diverse application domains. In addition, we employ an evaluation protocol which compares the frequencies of the computed motifs per different number of motifs, motif lengths and distance thresholds.\n6.1.1 Datasets\n\u2022 Insect B is a time series of insect behavior data and has a length of 73929 points [23].\n\u2022 TAO is a long time series representing Tropical Atmosphere Ocean temperature measurements having 741528 measurements1.\n\u2022 RandomWalk is a time-series dataset consisting of 1000000 points, among which motifs at randomly selected time-stamps are implanted [23].\n\u2022 EEG is a series of 1802136 continuous measurements from electroencephalographic sensors, measuring voltage differences across the scalp [23].\n\u2022 Salinity is a time series containing recordings on the level of oceanic salt concentration. The data has a length of 2324134 points and is provided by the National Oceanographic Data Center2.\n1www.pmel.noaa.gov/tao 2http://www.nodc.noaa.gov/General/salinity.html\n\u2022 EOG is the longest series in our collection consisting of 8099500 points. The data is collected by an ElectroOculogram and represent electrical potential between the front and the back of a human eye [11].\n6.1.2 Baseline Many motif discovery method are based on searching for\nfrequent patterns among the series segments (e.g. [25, 28, 7, 14, 13], enumerated in a broader scope in Section 2). While those search-based methods are successful in terms of scalability, data representation, on-line learning, etc..., they are still upper bounded in quality (a.k.a. frequency) by the Brute-Force search. That is trivial to show, because all the frequent sub-sequences those methods could find are also detectable by Brute-Force search. In that aspect, it is sufficient to demonstrate that our method is superior to Brute-Force searching in terms of quality (a.k.a. frequency) and that naturally translates into qualitative superiority against all the other scalable/approximate/on-line search-based methods.\n6.1.3 Evaluation Protocol We will compare against the brute-force search algorithm\nas the most qualitative search-based baseline. Our protocol involves comparisons across all the parameters of both the searching- and learning- based methods.\nThree different number of motifs will be computed K \u2208 {3, 10, 30} having two different lengths L \u2208 {500, 1000}. Furthermore, the threshold (T ) of the experiments is chosen as a percentile in the distribution of distances between segments. To illustrate the setup, a length corresponding to the 1%-th percentile, (denoted Pct = 1 in Table 1) means that 1-% of segments pairs have a pairwise Euclidean distance smaller than the threshold. In that way we can compare our method against the brute-force search across a range of thresholds computed by different percentiles T \u2208 {0.001%, 0.01%, 0.1%, 1%} of the pairwise distances of segments. In that way we avoid hand-picking different thresholds values per dataset and select the threshold in a datadriven neutral manner. In order to ensure convergence, the learning rate was set to an initial value of \u03b7 = 0.1 and the number of iterations to I = 1000. In addition, the optimization was restarted R = 200 times. The segments were extracted from the series by sliding a window and normalizing the clipped segment, while the window is slid by half of the motif length. For every combination of the number of motifs K, length L and threshold T (computed from the percentile), three different values of frequency smoothness were searched \u03b1 \u2208 {1, 2, 3}, keeping the one yielding the highest F value.\nThe brute-force search baseline was executed using the same K,L, T (Pct) combination parameters as the learningbased approach, and for both methods the final frequency F does not include trivial matches. In order to be entirely transparent to the research community we publicly shared our source code and the data used in this paper in an on-line repository3."}, {"heading": "6.2 Results", "text": "In the conducted experiments, for all the different thresholds T (computed through the percentile), for all the different number of motifs K and for different motif lengths L,\n3http://fs.ismll.de/publicspace/LearnMotifs/\nthe motifs learned through our method almost always had a higher frequency than the ones found through brute-force search. Table 1 displays the empirical results comparing the frequency score of the optimal learned motif (denoted LM) against the motifs found through brute-force search (denoted BFM).\nThe results of Table 1 indicate that learning the motifs (LM) is better than searching (BFM) them in 99.31% of the experiments (143/144). The improvement arising from learning motifs (LM) in terms of motif frequencies is in average 67\u00b156% better than the search-based approach (BFM). The famous Bland-Altman plot is used to assess the significance of the improvements. Figure 8 (left plot) shows the dominating ratio of LM through least-squares fitting. Moreover, the right plot shows that the difference LM-BFM and its standard deviations are above zero, thus we have a significant difference in terms of frequencies.\nEven though the proposed method is significantly better\nin quality that the search-based alternatives, it is not the fastest method in the literature (which we never claimed). Yet, it is feasible in terms of run-time, since learning the Top-30 motifs of Insect B (smallest dataset) took 4.7 minutes, while learning the Top-30 motifs of EOG (largest dataset) took 33.57 hours, in a cluster having Intel Xeon E5-2670v2 processors with speed 2.50GHz."}, {"heading": "7. CASE STUDY: AUDIO MOTIFS", "text": "In this case study we extract motifs from audio files. The case discussed in this thread is a poem by Edgar Allen Poe, titled \u201dThe Bells\u201d and famous for its onomatopoeic nature in terms of repeating the word \u201dBells\u201d. We extract a time-series representation of the audio file through the first channel of the Mel-frequency cepstral coefficients (MFCC). For the sake of illustration we took the first 300000 measurements of the original WAV file, corresponding to a 68 seconds audio reading of the poem.\nFigure 9 illustrates shows the MFCC representation timeseries together with the results of the brute force search algorithm in blue and our proposed method in red. We extracted three motifs K = 3 of length L = 300 for both methods. The distance threshold used in the experiment is the 0.1%- th percentile of pair-wise segment distances corresponding to a value of T = 171.56. For each method, we display the location of the motif matches over series segments with a filled oval mark. Under the plots of the matches we show the found motifs together with the corresponding frequencies. For the same distance threshold, the learned motifs have totally 50 matches while the searched motifs have 35 matches, for an improvement of 42% in terms of frequency. Our method learns patterns that for exactly the same distance threshold match more frequently than the brute-force\nmotifs. An investigation of the motif sounds reveals that the topK repetitive sounds are different pronunciations of the word bell. All the motifs are different from each other by 2T, so they are all legit motifs by definition. Let us analyze how optimality translates in concrete terms. For instance we can consider the segment between points 10000-15000 in the times series, which corresponds to the following poem text:\n... Of the rapture that impels To the swinging and the ringing Of the bells, bells, bells - Of the bells, bells, bells, bells, Bells, bells, bells - To the rhyming and the chiming of the bells! ...\nWithin the above segment, the brute-force motifs can find 7, 10, 7 occurrences of the word bell within a threshold T . Our motifs can find 9, 11, 9 matches within the same interval and for exactly the same distance threshold T. As the ground truth text above indicate, there are 11 \u201dbells\u201d pronunciations in total. In average, given the specified threshold T , the brute-force motifs find similar sounds that match to the word Bells in 72% of the cases, the matches of our optimal motifs correspond to the word Bells in average on 88% of the cases. This is a very important detection accuracy given that we used only the first channel of the MFCC\nrepresentation, which is a low-resolution representation that encapsulates only the overall loudness of the sound."}, {"heading": "8. CONCLUSION", "text": "This paper proposed a new perspective in learning timeseries motifs. In contrast to current state of the art techniques which searches out motif candidates from series segments, our method learns them in a principled optimization. The motif frequency is approximated as a differentiable function and a gradient ascent method is proposed to find the motif values which maximize the objective function. In order to avoid local optima, a random restart strategy is combined with the gradient ascent learning of the motifs.\nLearned optimal motifs have more segment matches than the motifs found through searching, for the same distance threshold. The optimal motifs represent latent patterns not necessarily present as sub-sequences in an explicit form, therefore can identify motifs which are in the center of the densest hyper-balls including segment points. Detailed experimental results demonstrate that learning optimal motifs always produces more qualitative motifs than searching them."}, {"heading": "9. ACKNOWLEDGMENT", "text": "This research has been co-funded by the Seventh Framework Programme of the European Commission, through the REDUCTION project (#288254)4 and by Deutsche Forschungsgemeinschaft within the project HyLAP5. The authors also acknowledge Prof. Eamonn Keogh, University of California, Riverside, and Dr. Lucas Drumond, ISMLL, University of Hildesheim, whose suggestions helped improving the quality of the work."}, {"heading": "10. REFERENCES", "text": "[1] A. E. Brown, E. I. Yemini, L. J. Grundy, T. Jucikas,\nand W. R. Schafer. A dictionary of behavioral motifs reveals clusters of genes affecting caenorhabditis elegans locomotion. Proceedings of the National Academy of Sciences, 110(2):791\u2013796, 2013.\n[2] J. Buhler and M. Tompa. Finding motifs using random projections. In Proceedings of the Fifth Annual International Conference on Computational Biology, RECOMB \u201901, pages 69\u201376, New York, NY, USA, 2001. ACM.\n[3] N. Castro and P. Azevedo. Multiresolution Motif Discovery in Time Series. In Proceedings of the SIAM International Conference on Data Mining, SDM 2010, 2010, Columbus, Ohio, USA, pages 665\u2013676. SIAM, 2010.\n[4] N. Castro and P. Azevedo. Time Series Motifs Statistical Significance. In Proceedings of the SIAM International Conference on Data Mining, SDM 2011, 2011, Mesa, Arizona, USA, pages 687\u2013698. SIAM, 2011.\n[5] N. C. Castro and P. J. Azevedo. Significant motifs in time series. Stat. Anal. Data Min., 5(1):35\u201353, Feb. 2012.\n[6] J. Catalano, T. Armstrong, and T. Oates. Discovering\npatterns in real-valued time series. In J. FA\u0303ijrnkranz,\n4www.reduction-project.eu 5www.autonomous-learning.org\nT. Scheffer, and M. Spiliopoulou, editors, Knowledge Discovery in Databases: PKDD 2006, volume 4213 of Lecture Notes in Computer Science, pages 462\u2013469. Springer Berlin Heidelberg, 2006.\n[7] B. Chiu, E. Keogh, and S. Lonardi. Probabilistic discovery of time series motifs. In Proceedings of the Ninth ACM SIGKDD International Conference on Knowledge Discovery and Data Mining, KDD \u201903, pages 493\u2013498, New York, NY, USA, 2003. ACM.\n[8] T. H. Cormen, C. Stein, R. L. Rivest, and C. E. Leiserson. Introduction to Algorithms. McGraw-Hill Higher Education, 2nd edition, 2001.\n[9] J. Duchi, E. Hazan, and Y. Singer. Adaptive subgradient methods for online learning and stochastic optimization. J. Mach. Learn. Res., 12:2121\u20132159, July 2011.\n[10] P. Ferreira, P. Azevedo, C. Silva, and R. Brito. Mining approximate motifs in time series. In L. Todorovski, N. Lavrac, and K. Jantke, editors, Discovery Science, volume 4265 of Lecture Notes in Computer Science, pages 89\u2013101. Springer Berlin Heidelberg, 2006.\n[11] A. L. Goldberger, L. A. N. Amaral, L. Glass, J. M. Hausdorff, P. C. Ivanov, R. G. Mark, J. E. Mietus, G. B. Moody, C.-K. Peng, and H. E. Stanley. PhysioBank, PhysioToolkit, and PhysioNet: Components of a new research resource for complex physiologic signals. Circulation, 101(23):e215\u2013e220, 2000 (June 13).\n[12] H. T. Lam, N. D. Pham, and T. Calders. Online Discovery of Top-k Similar Motifs in Time Series Data, chapter 86, pages 1004\u20131015.\n[13] Y. Li and J. Lin. Approximate variable-length time series motif discovery using grammar inference. In Proceedings of the Tenth International Workshop on Multimedia Data Mining, MDMKDD \u201910, pages 10:1\u201310:9, New York, NY, USA, 2010. ACM.\n[14] Y. Li, J. Lin, and T. Oates. Visualizing variable-length time series motifs. In Proceedings of the Twelfth SIAM International Conference on Data Mining, Anaheim, California, USA, April 26-28, 2012., pages 895\u2013906. SIAM / Omnipress, 2012.\n[15] Z. Liu, J. Yu, X. Lin, H. Lu, and W. Wang. Locating motifs in time-series data. In T. Ho, D. Cheung, and H. Liu, editors, Advances in Knowledge Discovery and Data Mining, volume 3518 of Lecture Notes in Computer Science, pages 343\u2013353. Springer Berlin Heidelberg, 2005.\n[16] M. Lones. Sean luke: essentials of metaheuristics. Genetic Programming and Evolvable Machines, 12(3):333\u2013334, 2011.\n[17] D. Minnen, C. Isbell, I. Essa, and T. Starner. Detecting subdimensional motifs: An efficient algorithm for generalized multivariate pattern discovery. In Proceedings of the 2007 Seventh IEEE International Conference on Data Mining, ICDM \u201907, pages 601\u2013606, Washington, DC, USA, 2007. IEEE Computer Society.\n[18] D. Minnen, C. L. Isbell, I. Essa, and T. Starner. Discovering multivariate motifs using subsequence density estimation and greedy mixture learning. In Proceedings of the 22Nd National Conference on Artificial Intelligence - Volume 1, AAAI\u201907, pages\n615\u2013620. AAAI Press, 2007.\n[19] Y. Mohammad and T. Nishida. Exact discovery of length-range motifs. In N. Nguyen, B. Attachoo, B. TrawiA\u030aD\u030cski, and K. Somboonviwat, editors, Intelligent Information and Database Systems, volume 8398 of Lecture Notes in Computer Science, pages 23\u201332. Springer International Publishing, 2014.\n[20] A. Mueen. Enumeration of time series motifs of all lengths. 2013 IEEE 13th International Conference on Data Mining, 0:547\u2013556, 2013.\n[21] A. Mueen and E. Keogh. Online discovery and maintenance of time series motifs. In Proceedings of the 16th ACM SIGKDD International Conference on Knowledge Discovery and Data Mining, KDD \u201910, pages 1089\u20131098, New York, NY, USA, 2010. ACM.\n[22] A. Mueen, E. Keogh, and N. Bigdely-Shamlo. Finding time series motifs in disk-resident data. In Proceedings of the 2009 Ninth IEEE International Conference on Data Mining, ICDM \u201909, pages 367\u2013376, Washington, DC, USA, 2009. IEEE Computer Society.\n[23] A. Mueen, E. J. Keogh, Q. Zhu, S. Cash, and M. B. Westover. Exact discovery of time series motifs. In Proceedings of the SIAM International Conference on Data Mining, SDM 2009. SIAM, 2009.\n[24] T. Oates. Peruse: An unsupervised algorithm for finding recurring patterns in time series. In Data Mining, 2002. ICDM 2003. Proceedings. 2002 IEEE International Conference on, pages 330\u2013337, 2002.\n[25] P. Patel, E. Keogh, J. Lin, and S. Lonardi. Mining motifs in massive time series databases. In Proceedings of the 2002 IEEE International Conference on Data Mining, ICDM \u201902, pages 370\u2013, Washington, DC, USA, 2002. IEEE Computer Society.\n[26] Z. Syed, C. Stultz, M. Kellis, P. Indyk, and J. Guttag. Motif discovery in physiological datasets: A methodology for inferring predictive elements. ACM Trans. Knowl. Discov. Data, 4(1):2:1\u20132:23, Jan. 2010.\n[27] A. Vahdatpour, N. Amini, and M. Sarrafzadeh. Toward unsupervised activity discovery using multi-dimensional motif detection in time series. In Proceedings of the 21st International Jont Conference on Artifical Intelligence, IJCAI\u201909, pages 1261\u20131266, San Francisco, CA, USA, 2009. Morgan Kaufmann Publishers Inc.\n[28] D. Yankov, E. Keogh, J. Medina, B. Chiu, and V. Zordan. Detecting time series motifs under uniform scaling. In Proceedings of the 13th ACM SIGKDD International Conference on Knowledge Discovery and Data Mining, KDD \u201907, pages 844\u2013853, New York, NY, USA, 2007. ACM.\n[29] M. Yin, S. Tangsripairoj, and B. Pupacdi. Variable length motif-based time series classification. In S. Boonkrong, H. Unger, and P. Meesad, editors, Recent Advances in Information and Communication Technology, volume 265 of Advances in Intelligent Systems and Computing, pages 73\u201382. Springer International Publishing, 2014.\n[30] S. Yingchareonthawornchai, H. Sivaraks, T. Rakthanmanon, and C. Ratanamahatana. Efficient proper length time series motif discovery. In Data Mining (ICDM), 2013 IEEE 13th International Conference on, pages 1265\u20131270, Dec 2013."}], "references": [{"title": "A dictionary of behavioral motifs reveals clusters of genes affecting caenorhabditis elegans locomotion", "author": ["A.E. Brown", "E.I. Yemini", "L.J. Grundy", "T. Jucikas", "W.R. Schafer"], "venue": "Proceedings of the National Academy of Sciences,", "citeRegEx": "1", "shortCiteRegEx": "1", "year": 2013}, {"title": "Finding motifs using random projections", "author": ["J. Buhler", "M. Tompa"], "venue": "In Proceedings of the Fifth Annual International Conference on Computational Biology,", "citeRegEx": "2", "shortCiteRegEx": "2", "year": 2001}, {"title": "Multiresolution Motif Discovery in Time Series", "author": ["N. Castro", "P. Azevedo"], "venue": "In Proceedings of the SIAM International Conference on Data Mining, SDM 2010,", "citeRegEx": "3", "shortCiteRegEx": "3", "year": 2010}, {"title": "Time Series Motifs Statistical Significance", "author": ["N. Castro", "P. Azevedo"], "venue": "In Proceedings of the SIAM International Conference on Data Mining, SDM 2011,", "citeRegEx": "4", "shortCiteRegEx": "4", "year": 2011}, {"title": "Significant motifs in time series", "author": ["N.C. Castro", "P.J. Azevedo"], "venue": "Stat. Anal. Data Min.,", "citeRegEx": "5", "shortCiteRegEx": "5", "year": 2012}, {"title": "Discovering patterns in real-valued time series", "author": ["J. Catalano", "T. Armstrong", "T. Oates"], "venue": "In J. FA\u0303ijrnkranz,", "citeRegEx": "6", "shortCiteRegEx": "6", "year": 2006}, {"title": "Probabilistic discovery of time series motifs", "author": ["B. Chiu", "E. Keogh", "S. Lonardi"], "venue": "In Proceedings of the Ninth ACM SIGKDD International Conference on Knowledge Discovery and Data Mining, KDD", "citeRegEx": "7", "shortCiteRegEx": "7", "year": 2003}, {"title": "Introduction to Algorithms", "author": ["T.H. Cormen", "C. Stein", "R.L. Rivest", "C.E. Leiserson"], "venue": "McGraw-Hill Higher Education,", "citeRegEx": "8", "shortCiteRegEx": "8", "year": 2001}, {"title": "Adaptive subgradient methods for online learning and stochastic optimization", "author": ["J. Duchi", "E. Hazan", "Y. Singer"], "venue": "J. Mach. Learn. Res.,", "citeRegEx": "9", "shortCiteRegEx": "9", "year": 2011}, {"title": "Mining approximate motifs in time series", "author": ["P. Ferreira", "P. Azevedo", "C. Silva", "R. Brito"], "venue": "Discovery Science,", "citeRegEx": "10", "shortCiteRegEx": "10", "year": 2006}, {"title": "PhysioBank, PhysioToolkit, and PhysioNet: Components of a new research resource for complex physiologic", "author": ["A.L. Goldberger", "L.A.N. Amaral", "L. Glass", "J.M. Hausdorff", "P.C. Ivanov", "R.G. Mark", "J.E. Mietus", "G.B. Moody", "C.-K. Peng", "H.E. Stanley"], "venue": "signals. Circulation,", "citeRegEx": "11", "shortCiteRegEx": "11", "year": 2000}, {"title": "Approximate variable-length time series motif discovery using grammar inference", "author": ["Y. Li", "J. Lin"], "venue": "In Proceedings of the Tenth International Workshop on Multimedia Data Mining, MDMKDD", "citeRegEx": "13", "shortCiteRegEx": "13", "year": 2010}, {"title": "Visualizing variable-length time series motifs", "author": ["Y. Li", "J. Lin", "T. Oates"], "venue": "In Proceedings of the Twelfth SIAM International Conference on Data Mining,", "citeRegEx": "14", "shortCiteRegEx": "14", "year": 2012}, {"title": "Locating motifs in time-series data", "author": ["Z. Liu", "J. Yu", "X. Lin", "H. Lu", "W. Wang"], "venue": "Advances in Knowledge Discovery and Data Mining,", "citeRegEx": "15", "shortCiteRegEx": "15", "year": 2005}, {"title": "luke: essentials of metaheuristics", "author": ["M. Lones. Sean"], "venue": "Genetic Programming and Evolvable Machines,", "citeRegEx": "16", "shortCiteRegEx": "16", "year": 2011}, {"title": "Detecting subdimensional motifs: An efficient algorithm for generalized multivariate pattern discovery", "author": ["D. Minnen", "C. Isbell", "I. Essa", "T. Starner"], "venue": "In Proceedings of the 2007 Seventh IEEE International Conference on Data Mining,", "citeRegEx": "17", "shortCiteRegEx": "17", "year": 2007}, {"title": "Discovering multivariate motifs using subsequence density estimation and greedy mixture learning", "author": ["D. Minnen", "C.L. Isbell", "I. Essa", "T. Starner"], "venue": "In Proceedings of the 22Nd National Conference on Artificial Intelligence - Volume 1,", "citeRegEx": "18", "shortCiteRegEx": "18", "year": 2007}, {"title": "Exact discovery of length-range motifs", "author": ["Y. Mohammad", "T. Nishida"], "venue": "Intelligent Information and Database Systems,", "citeRegEx": "19", "shortCiteRegEx": "19", "year": 2014}, {"title": "Enumeration of time series motifs of all lengths", "author": ["A. Mueen"], "venue": "IEEE 13th International Conference on Data Mining,", "citeRegEx": "20", "shortCiteRegEx": "20", "year": 2013}, {"title": "Online discovery and maintenance of time series motifs", "author": ["A. Mueen", "E. Keogh"], "venue": "In Proceedings of the 16th ACM SIGKDD International Conference on Knowledge Discovery and Data Mining, KDD", "citeRegEx": "21", "shortCiteRegEx": "21", "year": 2010}, {"title": "Finding time series motifs in disk-resident data", "author": ["A. Mueen", "E. Keogh", "N. Bigdely-Shamlo"], "venue": "In Proceedings of the 2009 Ninth IEEE International Conference on Data Mining,", "citeRegEx": "22", "shortCiteRegEx": "22", "year": 2009}, {"title": "Exact discovery of time series motifs", "author": ["A. Mueen", "E.J. Keogh", "Q. Zhu", "S. Cash", "M.B. Westover"], "venue": "In Proceedings of the SIAM International Conference on Data", "citeRegEx": "23", "shortCiteRegEx": "23", "year": 2009}, {"title": "Peruse: An unsupervised algorithm for finding recurring patterns in time series", "author": ["T. Oates"], "venue": "In Data Mining,", "citeRegEx": "24", "shortCiteRegEx": "24", "year": 2002}, {"title": "Mining motifs in massive time series databases", "author": ["P. Patel", "E. Keogh", "J. Lin", "S. Lonardi"], "venue": "In Proceedings of the 2002 IEEE International Conference on Data Mining,", "citeRegEx": "25", "shortCiteRegEx": "25", "year": 2002}, {"title": "Motif discovery in physiological datasets: A methodology for inferring predictive elements", "author": ["Z. Syed", "C. Stultz", "M. Kellis", "P. Indyk", "J. Guttag"], "venue": "ACM Trans. Knowl. Discov. Data,", "citeRegEx": "26", "shortCiteRegEx": "26", "year": 2010}, {"title": "Toward unsupervised activity discovery using multi-dimensional motif detection in time series", "author": ["A. Vahdatpour", "N. Amini", "M. Sarrafzadeh"], "venue": "In Proceedings of the 21st International Jont Conference on Artifical Intelligence,", "citeRegEx": "27", "shortCiteRegEx": "27", "year": 2009}, {"title": "Detecting time series motifs under uniform scaling", "author": ["D. Yankov", "E. Keogh", "J. Medina", "B. Chiu", "V. Zordan"], "venue": "In Proceedings of the 13th ACM SIGKDD International Conference on Knowledge Discovery and Data Mining, KDD", "citeRegEx": "28", "shortCiteRegEx": "28", "year": 2007}, {"title": "Variable length motif-based time series classification", "author": ["M. Yin", "S. Tangsripairoj", "B. Pupacdi"], "venue": "Recent Advances in Information and Communication Technology,", "citeRegEx": "29", "shortCiteRegEx": "29", "year": 2014}, {"title": "Efficient proper length time series motif discovery", "author": ["S. Yingchareonthawornchai", "H. Sivaraks", "T. Rakthanmanon", "C. Ratanamahatana"], "venue": "In Data Mining (ICDM),", "citeRegEx": "30", "shortCiteRegEx": "30", "year": 2013}], "referenceMentions": [{"referenceID": 1, "context": "patterns in time-series help the domain experts understand the underlying phenomena within diverse sources of data [2, 26].", "startOffset": 115, "endOffset": 122}, {"referenceID": 24, "context": "patterns in time-series help the domain experts understand the underlying phenomena within diverse sources of data [2, 26].", "startOffset": 115, "endOffset": 122}, {"referenceID": 23, "context": "The most repetitive time-series patterns are called motifs and their discovery has recently attracted considerable research [25, 20, 30, 14].", "startOffset": 124, "endOffset": 140}, {"referenceID": 18, "context": "The most repetitive time-series patterns are called motifs and their discovery has recently attracted considerable research [25, 20, 30, 14].", "startOffset": 124, "endOffset": 140}, {"referenceID": 28, "context": "The most repetitive time-series patterns are called motifs and their discovery has recently attracted considerable research [25, 20, 30, 14].", "startOffset": 124, "endOffset": 140}, {"referenceID": 12, "context": "The most repetitive time-series patterns are called motifs and their discovery has recently attracted considerable research [25, 20, 30, 14].", "startOffset": 124, "endOffset": 140}, {"referenceID": 23, "context": "a sub-sequences) of time series [25, 28, 14, 3].", "startOffset": 32, "endOffset": 47}, {"referenceID": 26, "context": "a sub-sequences) of time series [25, 28, 14, 3].", "startOffset": 32, "endOffset": 47}, {"referenceID": 12, "context": "a sub-sequences) of time series [25, 28, 14, 3].", "startOffset": 32, "endOffset": 47}, {"referenceID": 2, "context": "a sub-sequences) of time series [25, 28, 14, 3].", "startOffset": 32, "endOffset": 47}, {"referenceID": 23, "context": "Initially, motifs were defined to be the most frequently occurring patterns in a timeseries [25].", "startOffset": 92, "endOffset": 96}, {"referenceID": 21, "context": "However, another stream of papers redefined the term \u201dmotif\u201d as the closest pair among series segments [23, 21].", "startOffset": 103, "endOffset": 111}, {"referenceID": 19, "context": "However, another stream of papers redefined the term \u201dmotif\u201d as the closest pair among series segments [23, 21].", "startOffset": 103, "endOffset": 111}, {"referenceID": 23, "context": "In this paper we mean \u201dthe most frequently occurring patterns\u201d [25] when referring to motifs.", "startOffset": 63, "endOffset": 67}, {"referenceID": 17, "context": "The closest pair of series segments, on the other hand, will be referred to as \u201dpair-motif\u201d following the suggestion of [19].", "startOffset": 120, "endOffset": 124}, {"referenceID": 21, "context": "A fast, yet exact, method that discovers pair-wise motifs has been introduced by [23].", "startOffset": 81, "endOffset": 85}, {"referenceID": 18, "context": "Enumerations of all motifs having variable lengths has also been researched [20, 19].", "startOffset": 76, "endOffset": 84}, {"referenceID": 17, "context": "Enumerations of all motifs having variable lengths has also been researched [20, 19].", "startOffset": 76, "endOffset": 84}, {"referenceID": 3, "context": "In addition, the statistical significance of the motifs found has also been a topic of interest [4, 5].", "startOffset": 96, "endOffset": 102}, {"referenceID": 4, "context": "In addition, the statistical significance of the motifs found has also been a topic of interest [4, 5].", "startOffset": 96, "endOffset": 102}, {"referenceID": 7, "context": "Note: Finding motif-pairs is equivalent to the problem of locating the closest pair of points in a geometrical space and is a historic problem in computational geometry [8].", "startOffset": 169, "endOffset": 172}, {"referenceID": 1, "context": "Repeating patterns in sequential data have initially been studied in bio-informatics [2].", "startOffset": 85, "endOffset": 88}, {"referenceID": 24, "context": "However, finding motifs is beneficial in understanding physiological human data [26], while being also useful in understanding behavioral patterns of living organisms [1].", "startOffset": 80, "endOffset": 84}, {"referenceID": 0, "context": "However, finding motifs is beneficial in understanding physiological human data [26], while being also useful in understanding behavioral patterns of living organisms [1].", "startOffset": 167, "endOffset": 170}, {"referenceID": 23, "context": "The concept of recurrent patterns was transferred to the realm of time-series data under the term \u201dmotifs\u201d [25] and a search-based approach to discovering motifs was proposed.", "startOffset": 107, "endOffset": 111}, {"referenceID": 6, "context": "In order to find motifs that are immune to noisy variations, a probabilistic search of timeseries motifs was based on random projections [7].", "startOffset": 137, "endOffset": 140}, {"referenceID": 26, "context": "Another work has explored the employment of uniform scaling as the similarity distance used for discovering the motifs [28].", "startOffset": 119, "endOffset": 123}, {"referenceID": 22, "context": "Furthermore, a hybrid combination of supervised and unsupervised learning has been used for searching recurring patterns [24].", "startOffset": 121, "endOffset": 125}, {"referenceID": 13, "context": "The task of finding the most recurring motifs has also been tackled through searching for candidate motifs organized in a tree structure [15].", "startOffset": 137, "endOffset": 141}, {"referenceID": 9, "context": "Conversion of motifs into a symbolic representation (named SAX) is a preprocessing alternative [10].", "startOffset": 95, "endOffset": 99}, {"referenceID": 9, "context": "Over the new representation an agglomerative clustering can be used to find motifs [10].", "startOffset": 83, "endOffset": 87}, {"referenceID": 2, "context": "A scalable alternative that can approximately discover multiresolution motifs in a single scan utilizes different cardinalities of the symbolic representation [3].", "startOffset": 159, "endOffset": 162}, {"referenceID": 20, "context": "Last but not least, a scalable version of the pair-wise motifs has been extended to the general motifs discovery for large-scale data [22].", "startOffset": 134, "endOffset": 138}, {"referenceID": 15, "context": "Several strategies were inspected, where motifs span all versus a subset of the dimensions, with or without temporal overlap [17].", "startOffset": 125, "endOffset": 129}, {"referenceID": 15, "context": "The algorithm is based on random projections of the symbolic sub-sequence representations [17].", "startOffset": 90, "endOffset": 94}, {"referenceID": 16, "context": "Discovering regions of high density in the space of sub-sequencies is another alternative to mining multivariate motifs [18].", "startOffset": 120, "endOffset": 124}, {"referenceID": 25, "context": "Graph clustering implemented as a two-staged algorithm was also employed in detecting multidimensional motifs [27].", "startOffset": 110, "endOffset": 114}, {"referenceID": 25, "context": "In the first step single-dimensional motifs are discovered and later blended through clustering [27].", "startOffset": 96, "endOffset": 100}, {"referenceID": 28, "context": "Under such a reality authors attempted to discover the optimal motif length, for instance by inspecting the compressibility of the data [30].", "startOffset": 136, "endOffset": 140}, {"referenceID": 11, "context": "In addition, variable-length motifs can be extracted using a grammar-inspired inference process [13].", "startOffset": 96, "endOffset": 100}, {"referenceID": 12, "context": "Interest has been attracted in terms of visualizing variablelength motifs [14], finding them in linear time [6], or using them for classification purposes [29].", "startOffset": 74, "endOffset": 78}, {"referenceID": 5, "context": "Interest has been attracted in terms of visualizing variablelength motifs [14], finding them in linear time [6], or using them for classification purposes [29].", "startOffset": 108, "endOffset": 111}, {"referenceID": 27, "context": "Interest has been attracted in terms of visualizing variablelength motifs [14], finding them in linear time [6], or using them for classification purposes [29].", "startOffset": 155, "endOffset": 159}, {"referenceID": 23, "context": "There is, nevertheless, an important constraint in the search for motifs: The K motifs should be different from each other [25], otherwise, the motifs risk being close variations of the single most repetitive motif.", "startOffset": 123, "endOffset": 127}, {"referenceID": 23, "context": "Equation 3, which enforces each pair of motifs (Mk,:,Mp,:) to be different from each other by a distance of at least 2T (so each pair does not overlap within a threshold T , details in [25]).", "startOffset": 185, "endOffset": 189}, {"referenceID": 23, "context": "Stated shortly, trivial matches are consecutive segments which match the same motif [25].", "startOffset": 84, "endOffset": 88}, {"referenceID": 2, "context": "Some related work increment the sliding window by an offset of points, therefore trivial matches can be trans-passed at the risk of potentially missing certain matches [3, 18].", "startOffset": 168, "endOffset": 175}, {"referenceID": 16, "context": "Some related work increment the sliding window by an offset of points, therefore trivial matches can be trans-passed at the risk of potentially missing certain matches [3, 18].", "startOffset": 168, "endOffset": 175}, {"referenceID": 13, "context": "The most frequently occurring motif is defined to be the point that covers the maximum number of blue points (segments) inside the circle of radius \u221a T that is centered at the motif, hence the densest geometrical ball [15].", "startOffset": 218, "endOffset": 222}, {"referenceID": 8, "context": "The learning rate is dynamically updated per each point of each motif using an adaptive technique known as AdaGrad [9].", "startOffset": 115, "endOffset": 118}, {"referenceID": 8, "context": "The update of line 24 adjusts the learning rate by the square root of the accumulated square gradients [9].", "startOffset": 103, "endOffset": 106}, {"referenceID": 14, "context": "In case of non-concave functions (or non-convex for minimization problems), an effective cook-book solution is to combine gradient descent with a random-restart strategy [16].", "startOffset": 170, "endOffset": 174}, {"referenceID": 21, "context": "\u2022 Insect B is a time series of insect behavior data and has a length of 73929 points [23].", "startOffset": 85, "endOffset": 89}, {"referenceID": 21, "context": "\u2022 RandomWalk is a time-series dataset consisting of 1000000 points, among which motifs at randomly selected time-stamps are implanted [23].", "startOffset": 134, "endOffset": 138}, {"referenceID": 21, "context": "\u2022 EEG is a series of 1802136 continuous measurements from electroencephalographic sensors, measuring voltage differences across the scalp [23].", "startOffset": 138, "endOffset": 142}, {"referenceID": 10, "context": "The data is collected by an ElectroOculogram and represent electrical potential between the front and the back of a human eye [11].", "startOffset": 126, "endOffset": 130}, {"referenceID": 23, "context": "[25, 28, 7, 14, 13], enumerated in a broader scope in Section 2).", "startOffset": 0, "endOffset": 19}, {"referenceID": 26, "context": "[25, 28, 7, 14, 13], enumerated in a broader scope in Section 2).", "startOffset": 0, "endOffset": 19}, {"referenceID": 6, "context": "[25, 28, 7, 14, 13], enumerated in a broader scope in Section 2).", "startOffset": 0, "endOffset": 19}, {"referenceID": 12, "context": "[25, 28, 7, 14, 13], enumerated in a broader scope in Section 2).", "startOffset": 0, "endOffset": 19}, {"referenceID": 11, "context": "[25, 28, 7, 14, 13], enumerated in a broader scope in Section 2).", "startOffset": 0, "endOffset": 19}], "year": 2015, "abstractText": "Motifs are the most repetitive/frequent patterns of a timeseries. The discovery of motifs is crucial for practitioners in order to understand and interpret the phenomena occurring in sequential data. Currently, motifs are searched among series sub-sequences, aiming at selecting the most frequently occurring ones. Search-based methods, which try out series sub-sequence as motif candidates, are currently believed to be the best methods in finding the most frequent patterns. However, this paper proposes an entirely new perspective in finding motifs. We demonstrate that searching is nonoptimal since the domain of motifs is restricted, and instead we propose a principled optimization approach able to find optimal motifs. We treat the occurrence frequency as a function and time-series motifs as its parameters, therefore we learn the optimal motifs that maximize the frequency function. In contrast to searching, our method is able to discover the most repetitive patterns (hence optimal), even in cases where they do not explicitly occur as sub-sequences. Experiments on several real-life time-series datasets show that the motifs found by our method are highly more frequent than the ones found through searching, for exactly the same distance threshold.", "creator": "LaTeX with hyperref package"}}}