{"id": "1506.02264", "review": {"conference": "aaai", "VERSION": "v1", "DATE_OF_SUBMISSION": "7-Jun-2015", "title": "Visual Learning of Arithmetic Operations", "abstract": "cooperative learning theories combine perceptual \u2013 formal ( pl. g. subjective, symbolic ) sous - tasks. in some cases line - to - goal preparation involves the stimulus and cognitive quarter - instructions can be simpler rigorous than attempting sequential pre - task one. within other cases such end - to - end learning can be dangerously efficient. as means - point - end learning is becoming more prevalent in ai, coordination is important to recall when agile approach can assist efficiently.", "histories": [["v1", "Sun, 7 Jun 2015 13:44:15 GMT  (494kb,D)", "https://arxiv.org/abs/1506.02264v1", null], ["v2", "Fri, 27 Nov 2015 12:18:48 GMT  (459kb,D)", "http://arxiv.org/abs/1506.02264v2", "To appear in AAAI 2016"]], "reviews": [], "SUBJECTS": "cs.LG cs.AI cs.CV", "authors": ["yedid hoshen", "shmuel peleg"], "accepted": true, "id": "1506.02264"}, "pdf": {"name": "1506.02264.pdf", "metadata": {"source": "CRF", "title": "Visual Learning of Arithmetic Operations", "authors": ["Yedid Hoshen", "Shmuel Peleg"], "emails": [], "sections": [{"heading": null, "text": "A simple Neural Network model is presented for end-to-end visual learning of arithmetic operations from pictures of numbers. The input consists of two pictures, each showing a 7-digit number. The output, also a picture, displays the number showing the result of an arithmetic operation (e.g., addition or subtraction) on the two input numbers. The concepts of a number, or of an operator, are not explicitly introduced. This indicates that addition is a simple cognitive task, which can be learned visually using a very small number of neurons.\nOther operations, e.g., multiplication, were not learnable using this architecture. Some tasks were not learnable end-to-end (e.g., addition with Roman numerals), but were easily learnable once broken into two separate sub-tasks: a perceptual Character Recognition and cognitive Arithmetic sub-tasks. This indicates that while some tasks may be easily learnable end-to-end, other may need to be broken into sub-tasks."}, {"heading": "1. Introduction", "text": "Visual learning of arithmetic operations is naturally broken into two sub-tasks: A perceptual sub-task of optical character recognition (OCR) and a cognitive sub-task of learning arithmetic. A common approach in such cases is to learn each sub-task separately. Examples of popular perceptual sub-tasks in other domains include object recognition and segmentation. Cognitive sub-tasks include language modeling and translation.\nWith the progress of deep neural networks it has become possible to learn complete tasks end-to-end. Systems now exist for end-to-end training of image to sentence generation [17] and speech to sentence generation [6]. But end-toend learning may introduce an extra difficulty: sub-tasks do\nnot have unique training data, but depend on the results of other sub-tasks.\nWe examine end-to-end learning from a neural network perspective as a model for perception and cognition: performing arithmetic operations (e.g., addition) for visual input and visual output. Both input and output examples of the network are pictures (as in Fig. 1). For each training example we give the student (the network) two input pictures, each showing a 7 digit integer number written in a standard font. The target output is also a picture, displaying the sum of the two input numbers.\nIn order to succeed at this task, the network is required to implicitly be able to learn the arithmetic operation without being taught the meaning of numbers. This can be seen as similar to teaching arithmetic to a person with whom we do not possess a common language.\nWe model the learning process as a feed-forward artificial neural network [2, 7]. The input to the network are pictures of numbers, and the output is also a picture (of the sum of the input numbers). The network is trained on a sufficient number of examples, which are only a tiny fraction of all possible inputs. After training, given pictures of two previously unseen numbers, the network generates the picture displaying their sum. It has therefore learned the concept of numbers without direct supervision and also learned the addition operation.\nAlthough initially a surprising result, we present an analysis of visual learning of addition and demonstrate that it is realizable using simple neural network architectures. Other arithmetic operations such as subtraction are also shown to be learnable with similar networks. Multiplication, however, was not learned successfully under the same setting. It is shown that the multiplication sub-task is more difficult to realize than addition under such architecture. Interestingly, for addition with Roman numerals both the OCR and the arithmetic sub-tasks are shown to be realizable, but the endto-end training of the task fails. This demonstrates the extra difficultly of end-to-end training.\nOur results suggest that some mathematical concepts are learnable purely from vision. An exciting possible implica-\nar X\niv :1\n50 6.\n02 26\n4v 2\n[ cs\n.L G\n] 2\n7 N\nov 2\n01 5\ntion is that some arithmetic concepts can be taught visually across different cultures. It has also been shown that endto-end learning fails for some tasks, even though their subtasks can be learned easily. This work deals with arithmetic tasks, and future research is required to characterize what other non-visual sub-tasks can be learned visually e.g., by video frame prediction."}, {"heading": "2. Arithmetic as Neural Frame Prediction", "text": "In this section we describe a visual protocol for learning arithmetic by image prediction. This is done by training an artificial neural network with input and output examples."}, {"heading": "2.1. Learning Arithmetic from Visual Examples", "text": "Our protocol for visual learning of arithmetic is based on image prediction. Given two input pictures F1, F2, target picture E is the correct prediction. The learner is required to predict the output picture, and the predicted picture is denoted P . The prediction loss is evaluated by the sum of square differences (SSD) between the pixel intensities of the predicted picture P and the target picture E.\nThe input integers are randomly selected in a prespecified range (for addition we use the range of [0,4999999]), and are written on the input pictures. The result of the arithmetic operation on the input numbers (e.g., their sum) is written on the target output picture E. The numbers were written on the pictures using a standard font, and were always placed at the same image position. See Fig. 1 for examples.\nLearning consists of training the network with N such input/output examples (we use N = 150, 000)."}, {"heading": "2.2. Network Architecture", "text": "In this section we present a method to test the feasibility of learning arithmetic given the protocol presented in\nSec. 2.1. Our simple but powerful learner is a feed-forward fully-connected artificial neural network as shown in Fig. 2.\nThe network consists of an input layer of dimensions Fx\u00d7Fy\u00d72 where Fx and Fy are the dimensions of the 2 input pictures. We used Fx\u00d7Fy = 15\u00d760 unless specified otherwise. The network has three hidden layers each with 256 nodes with ReLU activation functions (max(0, x)) and an output layer (of the same height and width as the input pictures) with sigmoid activation. All nodes between adjacent layers were fully connected. An L2 loss function is used to score the difference between the predicted picture and the expected picture. The network is trained via minibatch stochastic gradient descent using the backpropogation algorithm."}, {"heading": "3. Experiments", "text": "The objective of this paper is to examine if arithmetic operations can be learned end-to-end using purely visual information. To this end several experiments were carried out:"}, {"heading": "3.1. Experimental Procedure", "text": "Using the protocol from Sec. 2.1 we generated 2 input pictures per example, each showing a single integer number. The numbers were randomly generated from a pre-specified range as detailed below. The output pictures were created similarly, displaying the result of the arithmetic operation on the input.\nThe following arithmetic operations were examined:\n\u2022 Addition: Sum of two 7 digit numbers, each in the range [0,4999999].\n\u2022 Subtraction: Difference between two 7 digit numbers in the range [0,9999999]. The first number was chosen to be larger or equal to the second number to ensure a positive result.\n\u2022 Multiplication: Product of two numbers, each in the range [0,3160].\n\u2022 Addition of Roman Numerals: Sum of two numbers in the range [0,4999999]. Both input and output were written in Roman numerals (IVXLCDM and another 7 numerals we \u201dinvented\u201d from 5000 to 5000000). The longest number 9,999,999 was 35 numerals long. The medieval notation (IV instead of IIII) was not used.\nFor each experiment, 150,000 input/output pairs were randomly generated for training and 30,000 pairs were randomly created for testing. The proportion of numbers used for training is a very small fraction of all possible combinations.\nWe have also examined robustness to image noise of the addition experiment. Both input and output pictures were corrupted with a strong additive Gaussian noise.\nA feed-forward artificial network was trained with the architecture described in Fig. 2. The network was trained using mini-batch stochastic gradient descent with learning rate 0.1, momentum 0.9 and mini-batch size was 256. 50 epochs of training were carried out. The network was implemented using the Caffe package [10]."}, {"heading": "3.2. Results", "text": "The correctness of the test set was measured using an OCR software (Tesseract [16] ) which was applied to the output pictures. The OCR results were compared to the desired output, and the percentage of incorrect digits was computed. The effectiveness of the neural network approach has been tested on the following operations.\nAddition: Three results from the test set are shown in Fig. 1. The input and the output numbers were not included in the training set. The examples qualitatively demonstrate the effectiveness of the network at learning addition from\npurely visual information. Quantitatively, the network has been able to learn addition with great accuracy, with incorrect digit prediction rate being only 1.9%.\nSubtraction: We trained a neural network having identical architecture to the network used for addition. Subtraction of a small number from a larger one was found to be of comparable difficulty to addition. The predicted digit error rate was around 3.2% which is comparable to addition.\nMultiplication: This task was found to be a much more challenging operation for a feed-forward Neural Network. The data for this experiment consisted of two input pictures with 4-digit integers, resulting in an output picture with 7 digit number, and the network used was similar to the one used for addition. As theoretical work (e.g., [3]) has shown that multiplication of binary numbers may require two more layers than their addition, we experimented with adding more hidden layers. The network, even with 5 hidden layers, did not perform well on this task, giving very large train and test errors. An example input/output pair can be seen in Fig.3. It can be seen that the least significant digit and two most significant digits were predicted correctly, as enumeration of the different possibilities is feasible, but the network was uncertain about the central 4 digits. The predicted digit error rate was as high as 71%, and the OCR engine was often unable to read numbers that had several blurry (uncertain) digits.\nAddition of Roman numerals: It has been hypothesized by Marr [12] and others (see [13]) that arithmetic using Roman numerals can be more challenging than using Arabic numerals. We have repeated the addition experiment with all numbers written as Roman numerals, which can be up to 35 digits long. As is demonstrated quantitatively in Tab. 1 the network was not able to predict the output frame in Roman numeral basis. This suggests that end-to-end visual learning of addition in Roman numeral basis is more challenging, in agreement with Marr\u2019s hypothesis. We further analyze this result in Sec. 5.\nAddition with Noisy Pictures: In one experiment we added a strong Gaussian noise (\u03c3=0.3) to all input and output pictures, as can be seen in Fig.3. The network achieved very good performance on this task, giving output pictures that display the correct result, which are also clean from noise. Failures can occur when the input digits are almost illegible. In such cases the network generated a \u201dprobabilistic\u201d output digit displaying a mixture of two digits. Mixture of digits caused problems to our verification using an OCR, reporting 9.8% digit error rate whereas human inspection obtained only 3.2% error rate. See Fig.5 for further details."}, {"heading": "4. Previous Work", "text": "Theoretical characterization of the operations learnable by neural networks is an established area of research. A pioneering paper presented by [5] used threshold circuits\nas a model for neural network capacity. A line of papers (e.g., [8, 15, 3]) established the feasibility of the implementation of several arithmetic operations on binary numbers. Recently [4] has addressed implementing Universal Turing Machines using neural networks. Most theoretical work in the field used binary representation of numbers, and did not address arithmetic operations in decimal form. Notably, a general result (see [14]), shows that operations implementable by Turing machine in time T (n) can be implemented by a neural network of O(T (n)) layers and with O(T (n)2) nodes. It has sample complexity O(T (n)2) but has no guarantees on training time. Research has also not dealt with visual learning.\nHypotheses about the difference in difficulty of learning arithmetic using decimal vs. Roman representations was made by Marr [12] and others. see [13] for a review and algorithms for Roman numeral addition and multiplication.\nOptical Character Recognition (OCR) [11, 9] is a well studied field. In this work we only deal with a very simple OCR scenario, dealing with more complex characters and backgrounds is out of scope of this work.\nLearning to execute Python code (including arithmetic) from textual data has been shown to be possible using LSTMs by Zaremba and Sutskever [20]. Adding two MNIST digits randomly located in a blank picture has been performed by Ba et al. [1]. In [19], Recurrent Neural Networks (RNNs) were used for algebraic expression simplification. These works, however, required a non-visual representation of a number either in the input or in the output. In this paper we show for the first time that end-to-end visual learning of arithmetic is possible.\nEnd-to-end learning of Image-to-Sentence [17] and of Speech-to-Sentence [6] has been described by multiple researchers. A recent related work by Vondrick et al. [18] successfully learned to predict the objects to appear in a future video frame from several previous frames. Our work can also be seen as frame prediction, requiring the network to implicitly understand the concepts driving the change between input and output frames. But our visual arithmetic is an easier task: easier to interpret and to analyze. The greater simplicity of our task allows us to use raw frames rather than an intermediate representation as used in [18]."}, {"heading": "5. Discussion", "text": "In this paper we have shown that feed-forward deep neural networks are able to learn certain arithmetic operations end-to-end by purely visual cues. Several other operations were not learned by the same architecture. In this section we give some intuition for the method the network employs to learn addition and subtraction, and the reasons why multiplication and Roman numerals were more challenging. A\nproof by construction of the capability of a shallow DNN (Deep Neural Network) to perform visual addition is presented in Sec. 6.\nWhen looking at the network weights for both addition and subtraction, we can see that each bottom hidden layer node is sensitive to a particular digit at a given position. Example bottom layer weights can be observed in Fig. 4.a-b. The bottom hidden layer nodes therefore represent each of the two M -digit numbers as a vector of length 10\u00d7M , each element representing the presence of digit 0\u2212 9 in position m \u2208 [1,M ]. This representation of converting a variable with D possible values (here 10) as D binary variables all being 0 apart from a single 1 at the dth position is known as \u201d1-hot\u201d. The top hidden layer contains a similar representation of the output number representing the presence of digit 0\u22129 in positionm \u2208 [1,M ] with total size 10\u00d7M . The task of the central hidden layers is mapping between the 1-hot representations of the input numbers (size 10\u00d7M\u00d72) and the 1-hot representation of the output number (size 10\u00d7M ).\nThe task is therefore split into 2 sub-tasks:\n\u2022 Perception: learn to represent numbers as a set of 1-hot vectors.\n\u2022 Cognition: map between the binary vectors as performed by the arithmetic operation.\nNote that the second sub-task is different from arithmetic operations on binary numbers (and is often harder).\nIn order to evaluate the above sub-tasks separately, we repeated the experiments with the (input and output) data transformed to 1-hot representation, thereby bypassing the visual sub-task. We used the same architecture as in the end-to-end case, except that we removed the first and last hidden layers (that are used for detecting or drawing images of numbers at each location).\nThe results on the test sets measured as the percentage of wrong digits in the output number is presented in Tab. 1. Addition and subtraction are both performed very accurately as in the visual case. The network was not able to learn multiplication due to the difficulty of the arithmetic\nsub-task, in line with the results of the visual case. This is also justified theoretically as (i) Binary multiplication was shown by previous papers [15, 3] to require deeper networks than binary addition. (ii) The Turing Machine complexity of the basic multiplication algorithm (effective for short numbers) is O(n2) as opposed to O(n) for decimal addition (n is the number of digits). This means [14] that the operation is realizable only by a deeper (O(n2) vs. O(n) layers) and larger network (O(n4) vs. O(n2) nodes).\nMore interesting is the relative accuracy at which Roman numeral addition was performed, as opposed to the failure in the visual case. We believe this is due to the high number of digits for large numbers in Roman numerals (35 digits), which causes both input and output images to be very high dimensional. We hypothesize that convergence may be improved with preliminary unsupervised learning of the OCR tasks (i.e. teaching the network what numbers are by clustering). We conclude that Roman arithmetic can be learned by DNNs, but visual end-to-end learning is more challenging due to the difficulty of joint optimization with the OCR sub-task.\nVisual learning when data were corrupted by strong noise was quite successful. In fact the concepts were learned well enough that the output pictures were denoised by the network. The performance on illegible digits is particularly interesting. We found that on corrupted digits that could possibly be read as multiple possibilities (In Fig. 5, digits 8 or 5), the output digit also reflected this uncertainly, resulting in a mixture of the two possible outputs (In Fig. 5, digits 1 or 8) with their respective probabilities. In other experiments (not shown) we have found that visual learning works for unary operations too (e.g., division by 2).\nA significant difference between our model and the cognitive system is its invariance to a fixed permutation of the pixels. A human would struggle to learn from such images, but the artificial neural networks manages very well. This invariance can be broken by slight random displacement of the training data or by the introduction of a convolutional architecture.\nAlthough Recurrent Neural Networks are generally better for learning algorithms (such as multiplication), we have chosen to use a fully connected architecture for ease of analysis. We hypothesize that better performance on multiplication can be obtained using an LSTM-RNN (Long Short Term Memory - Recurrent Neural Network) but we leave this investigation for future work."}, {"heading": "6. Feasibility of a Visual Addition Network", "text": "In this section we provide a feasibility proof by construction of a neural network architecture that can learn addition from visual data end-to-end. The construction of the network is illustrated in Fig. 6.\nWe rely on logic gates for simplicity. A logic gate can be implemented to an arbitrary accuracy by a single sigmoid or by a linear combination of 2 ReLU units \u0398(x > 0) = (ReLU(x+ \u03b4)\u2212ReLU(x))/\u03b4. Although our reported results were obtained using a network utilizing ReLU units, we have also tested our network with ReLU units replaced by sigmoid units obtaining similar results but much slower convergence. Logic gates are therefore a sufficiently good model of our network.\nAn input example is shown in Fig. 1. The first layer of the network is a dimensionality reduction layer. We choose weights that correspond to the set of filters containing each digit n (n \u2208 0..9) at each position m. Our experimental network in fact chooses more complex filters usually concentrated between similar digits to increase accuracy of digit detection (see Fig. 6 for examples). We construct 10\u00d7M\u00d72 nodes in the HL1 layer indicating if each of the templates is triggered. Each first hidden layer node responds to a specific template, for example T2nm corresponds to the template detecting if the digit n is present at the mth position in picture 2. It has value 1 if a template appears and 0 if it does not. Similarly the output layer is represented as a set of templates each corresponding to a digit (0..9) at a given position (1..M ).\nIt is worth noticing that given two digits d1m and d2m at the mth position in numbers 1 and 2 respectively, the mth digit in the output dmo can be either (d m 1 + d m 2 )mod10 or (dm1 +d m 2 +1)mod10. For each pair of digits, the arithmetic problem is to choose the correct result from the possible two.\nIn HL2 we compute an indicator function for each digit m, where node vmi is on when the sum of digits d1 and d2 and the possible increment from previous digits is larger than its threshold i (i \u2208 0..19). This is formulated as\nvmi = 1 \u2211m\nj=1 (d1m+d2m)\u221710j>=i\u00d710m (1)\nIt is easily implemented for each node vmi with weights from HL1 nodes T1mn and T2 m n with values n \u2217 10j for j \u2208 1..m, n \u2208 0..9 and threshold i\u00d710m. For later convenience we denote vm20 = 0.\nIn HL3, output template omn corresponding to the digit n at position m is turned on if in HL2 indicator vmn = 1 or vmn+10 = 1 while v m n+1 = 0 or v m n+11 = 0 respectively. This corresponds to the cases where the summation result of the numbers up to digitm is n\u00d710m \u2264 result < (n+1)\u00d710m or (n+10)\u00d710m \u2264 result < (n+11)\u00d710m. The equation is therefore:\nomn = 1vmn \u2212vmn+1+vmn+10\u2212vmn+11>0 (2)\nFinally the values are projected onto the output picture using the corresponding digit templates.\nBy end-to-end training of the network with a sufficient number of examples the network can arrive at the above weights (although it is by no means guaranteed to), and in practice good performance is achieved. End-to-end training from visual data is therefore theoretically shown and experimentally demonstrated to be able to learn addition with little guidance. This is a powerful paradigm that can generalize to visual learning of non-visual concepts that are not easily directly communicated to the learner."}, {"heading": "7. Conclusions", "text": "We have examined the capacity of neural networks for learning arithmetic operations from pictures, using a visual end-to-end learning protocol. Our neural network was able to learn addition and subtraction, and was robust to strong image noise. The concept of numbers was not explicitly used. We have shown that the network was not able to learn some other operations such as multiplication, and visual addition using Roman numerals. For the latter we have shown that although all sub-tasks are easily learned, the end-to-end task is not.\nIn order to better understand the capabilities of the network, a theoretical analysis was presented showing how a network capable of performing visual addition may be constructed. This theoretical framework can help determine if a new arithmetic operation is learnable using a feed-forward DNN architecture. We note that such analysis is quite restrictive, and hypothesize that experimental confirmation of the end-to-end learnability of complex tasks will often result in surprising findings.\nAlthough this work dealt primarily with arithmetic operations, the same approach can be used for general cognitive sub-task learning using frame prediction. The sub-tasks need not be restricted to the field of arithmetic, and can include more general concepts such as association. Generating data for the cognitive sub-task in not trivial, but generating visual examples is easy, e.g., by predicting future frames in video.\nWhile our experiments use two input pictures and one output picture, the protocol can be generalized for more complex operations involving more input and output\npictures. For learning non-arithmetic concepts, the pictures may contain other objects beside numbers.\nAcknowledgments. This research was supported by IntelICRC and by the Israel Science Foundation. The authors thank T. Poggio, S. Shalev-Shwartz, Y. Weiss, and L. Wolf for fruitful discussions."}], "references": [{"title": "Multiple object recognition with visual attention", "author": ["J. Ba", "V. Mnih", "K. Kavukcuoglu"], "venue": "arXiv:1412.7755", "citeRegEx": "1", "shortCiteRegEx": null, "year": 2014}, {"title": "Neural networks for Pattern Recognition", "author": ["C.M. Bishop"], "venue": "Oxford Univ. Press", "citeRegEx": "2", "shortCiteRegEx": null, "year": 1995}, {"title": "Solving arithmetic problems using feed-forward neural networks", "author": ["L. Franco", "S.A. Cannas"], "venue": "Neurocomputing, 18(1):61\u201379", "citeRegEx": "3", "shortCiteRegEx": null, "year": 1998}, {"title": "Neural turing machines", "author": ["A. Graves", "G. Wayne", "I. Danihelka"], "venue": "arXiv:1410.5401", "citeRegEx": "4", "shortCiteRegEx": null, "year": 2014}, {"title": "Threshold circuits of bounded depth", "author": ["A. Hajnal", "W. Maass", "P. Pudl\u00e1k", "M. Szegedy", "G. Turan"], "venue": "Annual Symposium on Foundations of Computer Science, pages 99\u2013110. IEEE", "citeRegEx": "5", "shortCiteRegEx": null, "year": 1987}, {"title": "A", "author": ["A. Hannun", "C. Case", "J. Casper", "B. Catanzaro", "G. Diamos", "E. Elsen", "R. Prenger", "S. Satheesh", "S. Sengupta"], "venue": "Coates, et al. Deepspeech: Scaling up end-to-end speech recognition. arXiv:1412.5567", "citeRegEx": "6", "shortCiteRegEx": null, "year": 2014}, {"title": "Reducing the dimensionality of data with neural networks", "author": ["G.E. Hinton", "R.R. Salakhutdinov"], "venue": "Science, 313(5786):504\u2013507", "citeRegEx": "7", "shortCiteRegEx": null, "year": 2006}, {"title": "Some notes on threshold circuits", "author": ["T. Hofmeister", "W. Hohberg", "S. K\u00f6hling"], "venue": "and multiplication in depth 4. In Int. Conf. Fundamentals of Computation Theory, pages 230\u2013239. Springer", "citeRegEx": "8", "shortCiteRegEx": null, "year": 1991}, {"title": "Deep features for text spotting", "author": ["M. Jaderberg", "A. Vedaldi", "A. Zisserman"], "venue": "ECCV\u201914, pages 512\u2013 528. Springer", "citeRegEx": "9", "shortCiteRegEx": null, "year": 2014}, {"title": "Caffe: Convolutional architecture for fast feature embedding", "author": ["Y. Jia", "E. Shelhamer", "J. Donahue", "S. Karayev", "J. Long", "R. Girshick", "S. Guadarrama", "T. Darrell"], "venue": "arXiv:1408.5093", "citeRegEx": "10", "shortCiteRegEx": null, "year": 2014}, {"title": "Handwritten digit recognition with a back-propagation network", "author": ["Y. LeCun", "B.E. Boser", "J.S. Denker", "D. Henderson", "R.E. Howard", "W.E. Hubbard", "L.D. Jackel"], "venue": "NIPS\u201989", "citeRegEx": "11", "shortCiteRegEx": null, "year": 1990}, {"title": "Vision: A Computational Investigation into the Human Representation and Processing of Visual Information", "author": ["D. Marr"], "venue": "W.H. Freeman & Co", "citeRegEx": "12", "shortCiteRegEx": null, "year": 1982}, {"title": "Modeling ancient and modern arithmetic practices: Addition and multiplication 7  with arabic and roman numerals", "author": ["D. Schlimm", "H. Neth"], "venue": "30th Annual Conference of the Cognitive Science Society, pages 2097\u2013 2102", "citeRegEx": "13", "shortCiteRegEx": null, "year": 2008}, {"title": "Understanding Machine Learning: From Theory to Algorithms", "author": ["S. Shalev-Shwartz", "S. Ben-David"], "venue": "Cambridge University Press", "citeRegEx": "14", "shortCiteRegEx": null, "year": 2014}, {"title": "Depth efficient neural networks for division and related problems", "author": ["K.-Y. Siu", "J. Bruck", "T. Kailath", "T. Hofmeister"], "venue": "IEEE Trans. Information Theory, 39(3):946\u2013956", "citeRegEx": "15", "shortCiteRegEx": null, "year": 1993}, {"title": "An overview of the tesseract ocr engine", "author": ["R. Smith"], "venue": "Int. Conf. on Document Analysis and Recognition (ICDAR), pages 629\u2013633", "citeRegEx": "16", "shortCiteRegEx": null, "year": 2007}, {"title": "Show and tell: A neural image caption generator", "author": ["O. Vinyals", "A. Toshev", "S. Bengio", "D. Erhan"], "venue": "arXiv:1411.4555", "citeRegEx": "17", "shortCiteRegEx": null, "year": 2014}, {"title": "Anticipating the future by watching unlabeled video", "author": ["C. Vondrick", "H. Pirsiavash", "A. Torralba"], "venue": "arXiv:1504.08023", "citeRegEx": "18", "shortCiteRegEx": null, "year": 2015}, {"title": "Learning to discover efficient mathematical identities", "author": ["W. Zaremba", "K. Kurach", "R. Fergus"], "venue": "NIPS\u201914, pages 1278\u20131286", "citeRegEx": "19", "shortCiteRegEx": null, "year": 2014}, {"title": "Learning to execute", "author": ["W. Zaremba", "I. Sutskever"], "venue": "arXiv:1410.4615", "citeRegEx": "20", "shortCiteRegEx": null, "year": 2014}], "referenceMentions": [{"referenceID": 16, "context": "Systems now exist for end-to-end training of image to sentence generation [17] and speech to sentence generation [6].", "startOffset": 74, "endOffset": 78}, {"referenceID": 5, "context": "Systems now exist for end-to-end training of image to sentence generation [17] and speech to sentence generation [6].", "startOffset": 113, "endOffset": 116}, {"referenceID": 1, "context": "We model the learning process as a feed-forward artificial neural network [2, 7].", "startOffset": 74, "endOffset": 80}, {"referenceID": 6, "context": "We model the learning process as a feed-forward artificial neural network [2, 7].", "startOffset": 74, "endOffset": 80}, {"referenceID": 9, "context": "The network was implemented using the Caffe package [10].", "startOffset": 52, "endOffset": 56}, {"referenceID": 15, "context": "The correctness of the test set was measured using an OCR software (Tesseract [16] ) which was applied to the output pictures.", "startOffset": 78, "endOffset": 82}, {"referenceID": 2, "context": ", [3]) has shown that multiplication of binary numbers may require two more layers than their addition, we experimented with adding more hidden layers.", "startOffset": 2, "endOffset": 5}, {"referenceID": 11, "context": "Addition of Roman numerals: It has been hypothesized by Marr [12] and others (see [13]) that arithmetic using Roman numerals can be more challenging than using Arabic numerals.", "startOffset": 61, "endOffset": 65}, {"referenceID": 12, "context": "Addition of Roman numerals: It has been hypothesized by Marr [12] and others (see [13]) that arithmetic using Roman numerals can be more challenging than using Arabic numerals.", "startOffset": 82, "endOffset": 86}, {"referenceID": 4, "context": "A pioneering paper presented by [5] used threshold circuits", "startOffset": 32, "endOffset": 35}, {"referenceID": 7, "context": ", [8, 15, 3]) established the feasibility of the implementation of several arithmetic operations on binary numbers.", "startOffset": 2, "endOffset": 12}, {"referenceID": 14, "context": ", [8, 15, 3]) established the feasibility of the implementation of several arithmetic operations on binary numbers.", "startOffset": 2, "endOffset": 12}, {"referenceID": 2, "context": ", [8, 15, 3]) established the feasibility of the implementation of several arithmetic operations on binary numbers.", "startOffset": 2, "endOffset": 12}, {"referenceID": 3, "context": "Recently [4] has addressed implementing Universal Turing Machines using neural networks.", "startOffset": 9, "endOffset": 12}, {"referenceID": 13, "context": "Notably, a general result (see [14]), shows that operations implementable by Turing machine in time T (n) can be implemented by a neural network of O(T (n)) layers and with O(T (n)) nodes.", "startOffset": 31, "endOffset": 35}, {"referenceID": 11, "context": "Roman representations was made by Marr [12] and others.", "startOffset": 39, "endOffset": 43}, {"referenceID": 12, "context": "see [13] for a review and algorithms for Roman numeral addition and multiplication.", "startOffset": 4, "endOffset": 8}, {"referenceID": 10, "context": "Optical Character Recognition (OCR) [11, 9] is a well studied field.", "startOffset": 36, "endOffset": 43}, {"referenceID": 8, "context": "Optical Character Recognition (OCR) [11, 9] is a well studied field.", "startOffset": 36, "endOffset": 43}, {"referenceID": 19, "context": "Learning to execute Python code (including arithmetic) from textual data has been shown to be possible using LSTMs by Zaremba and Sutskever [20].", "startOffset": 140, "endOffset": 144}, {"referenceID": 0, "context": "[1].", "startOffset": 0, "endOffset": 3}, {"referenceID": 18, "context": "In [19], Recurrent Neural Networks (RNNs) were used for algebraic expression simplification.", "startOffset": 3, "endOffset": 7}, {"referenceID": 16, "context": "End-to-end learning of Image-to-Sentence [17] and of Speech-to-Sentence [6] has been described by multiple researchers.", "startOffset": 41, "endOffset": 45}, {"referenceID": 5, "context": "End-to-end learning of Image-to-Sentence [17] and of Speech-to-Sentence [6] has been described by multiple researchers.", "startOffset": 72, "endOffset": 75}, {"referenceID": 17, "context": "[18] successfully learned to predict the objects to appear in a future video frame from several previous frames.", "startOffset": 0, "endOffset": 4}, {"referenceID": 17, "context": "The greater simplicity of our task allows us to use raw frames rather than an intermediate representation as used in [18].", "startOffset": 117, "endOffset": 121}, {"referenceID": 14, "context": "This is also justified theoretically as (i) Binary multiplication was shown by previous papers [15, 3] to require deeper networks than binary addition.", "startOffset": 95, "endOffset": 102}, {"referenceID": 2, "context": "This is also justified theoretically as (i) Binary multiplication was shown by previous papers [15, 3] to require deeper networks than binary addition.", "startOffset": 95, "endOffset": 102}, {"referenceID": 13, "context": "This means [14] that the operation is realizable only by a deeper (O(n) vs.", "startOffset": 11, "endOffset": 15}], "year": 2015, "abstractText": "A simple Neural Network model is presented for end-to-end visual learning of arithmetic operations from pictures of numbers. The input consists of two pictures, each showing a 7-digit number. The output, also a picture, displays the number showing the result of an arithmetic operation (e.g., addition or subtraction) on the two input numbers. The concepts of a number, or of an operator, are not explicitly introduced. This indicates that addition is a simple cognitive task, which can be learned visually using a very small number of neurons. Other operations, e.g., multiplication, were not learnable using this architecture. Some tasks were not learnable end-to-end (e.g., addition with Roman numerals), but were easily learnable once broken into two separate sub-tasks: a perceptual Character Recognition and cognitive Arithmetic sub-tasks. This indicates that while some tasks may be easily learnable end-to-end, other may need to be broken into sub-tasks.", "creator": "LaTeX with hyperref package"}}}