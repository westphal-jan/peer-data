{"id": "1506.02930", "review": {"conference": "arxiv", "VERSION": "v1", "DATE_OF_SUBMISSION": "9-Jun-2015", "title": "Theory of the effectivity of human problem solving", "abstract": "cognitive method to solve constraint critically is one below the elements regulating human cognition. yet, per our opinion it gets at less research overhead than our essentially explains. especially this paper we recognize a framework in creating digital device can be studied ; it identify theoretically possible levels and scope of this effectivity and appropriate cognitive processes directly involved. too particularly, we have warned that prototypes can perform dynamic mechanisms significantly drive problem solving simulations performing same manner on which perhaps optimal implicit theoretical constraint embodied by solomonoff ( 1986 ) is relied. furthermore, models provide evidence as cognitive causal hypothesis ( goldman, 1974 ) yet understanding comparatively higher level ai in all domains can be managed by a relatively small sequence of cognitive mechanisms. its results presented in preliminary paper can serve both cognitive psychology in better understanding of human problem solving processes, and artificial intelligence in designing more human like interacting agents.", "histories": [["v1", "Tue, 9 Jun 2015 14:28:12 GMT  (23kb)", "http://arxiv.org/abs/1506.02930v1", null], ["v2", "Tue, 19 Sep 2017 13:31:27 GMT  (19kb)", "http://arxiv.org/abs/1506.02930v2", null]], "reviews": [], "SUBJECTS": "cs.AI", "authors": ["frantisek duris"], "accepted": false, "id": "1506.02930"}, "pdf": {"name": "1506.02930.pdf", "metadata": {"source": "CRF", "title": null, "authors": ["Frantisek Duris"], "emails": ["fduris@dcs.fmph.uniba.sk"], "sections": [{"heading": null, "text": "ar X\niv :1\n50 6.\n02 93\n0v 1\n[ cs\n.A I]\n9 J\nThe ability to solve problems effectively is one of the hallmarks of human cognition. Yet, in our opinion it gets far less research focus than it rightly deserves. In this paper we outline a framework in which this effectivity can be studied; we identify the possible roots and scope of this effectivity and the cognitive processes directly involved. More particularly, we have observed that people can use cognitive mechanisms to drive problem solving by the same manner on which an optimal problem solving strategy suggested by Solomonoff (1986) is based. Furthermore, we provide evidence for cognitive substrate hypothesis (Cassimatis, 2006) which states that human level AI in all domains can be achieved by a relatively small set of cognitive mechanisms. The results presented in this paper can serve both cognitive psychology in better understanding of human problem solving processes, and artificial intelligence in designing more human like intelligent agents.\nKeywords: human problem solving, effectivity, mechanisms, artificial intelligence, cognitive architecture\n\u2217fduris@dcs.fmph.uniba.sk"}, {"heading": "1 Introduction", "text": "Problem solving is probably the most common activity of all organisms, especially of humans. We deal with various problems throughout our lives, from infancy to adulthood. Therefore, it is not surprising that an extensive effort has been made to understand the cognitive processes responsible for this ability, and many models of human problem solving have been presented (Polya, 1957; Davidson and Sternberg, 1986; Ohlsson, 1992; Weisberg, 1992; Davidson, 1995; Hummel and Holyoak, 1997; Woods, 2000; Davidson, 2003). Additional models of problem solving and, generally, of human cognitive skills have been proposed by research groups on cognitive architectures like ICARUS (Langley and Rogers, 2005; Langley, 2005; Langley and Choi, 2006; Langley et al., 2009; Langley and Trivedi, 2013), ACT-R (Anderson, 1996; Anderson et al., 2004), SOAR (Nason and Laird, 2005; Laird, 2008; Langley et al., 2009), Polyscheme (Cassimatis, 2006; Cassimatis et al., 2007; Kurup et al., 2011), and others (see Duch et al., 2008; Langley et al., 2009). Yet further approaches to problem solving were introduced in the field of theoretical computer science, although these models/algorithms were not much concerned with human approach to problem solving but rather with the objective effectivity of such algorithms (Solomonoff, 1986; Hutter, 2002; Schmidhuber, 2004; Hutter, 2005).\nOf these (and many others) research ideas and results we especially note two. First, the Cognitive substrate hypothesis by Cassimatis (2006) states that there is a relatively small set of computational problems such that once the problems of artificial intelligence are effectively solved for these, then the rest of the human intelligence can be achieve by the relatively simple problems of adapting the cognitive substrate to solve other problems. Cassimatis\u2019 preliminary guess of what this substrate consist of includes reasoning about time, space, parthood, categories, causation, uncertainty, belief, and desire. Second, Solomonoff (1986) in his general problem solving system applied a theorem in probability that describes the probabilistically optimal problem solving strategy (see Section 2 and Theorem 2.1 in our paper). In this paper we argue that there is a relatively small set of cognitive processes (mechanisms, abilities) which allow humans to drive the problem solving by the same manner on which the Solomonoff (1986) probabilistically optimal problem solving strategy is based. Thus, we identify the possible roots and scope of the effectivity of human problem solving as well as provide an indirect evidence for Cognitive substrate hypothesis (Cassimatis, 2006) by arguing that only a few mechanisms are crucial for the effective problem solving.\nOur results and the layout of the paper are as follows. In Section 2 we describe the Solomonoff\u2019 (1986) optimal problem solving strategy (Theorem 2.1). In Section 3 (Proposition 3.1) we propose a list of six cognitive processes (mechanisms, abilities) that, we argue, significantly help humans to generate in the effective order (according to Theorem 2.1) and in short time the appropriate candidate ideas for solving the (sub)problems. Thus, in our opinion these are the mechanisms that give rise to the effectivity of human problem solving and as such should be implemented in cognitive architectures for this reason. Section 4 deals with the general human problem solving mechanisms. In Section 4.1 (Proposition 4.2) we propose 4 classes of processes related to a certain outcome in the problem solving process (e.g., new informa-\ntion, problem manipulation), and we give arguments for the hypothesis (Hypothesis 4.3) that all conscious actions the solver does during the problem solving fall into one of these classes. In Section 4.2 (Proposition 4.5) we present a subtler version of the 4 classes of processes from the previous section. We give arguments for the hypothesis (Hypothesis 4.6) that the presented processes (mechanisms, abilities) are sufficient for the general human problem solving. Finally, in Section 4.3 (Proposition 4.7, Hypothesis 4.8) we link these general human problem solving mechanisms with the effective cognitive mechanisms from Section 3. In Section 5 we use the results of Sections 3 and 4 to draw conclusions about the scope and roots of the effectivity of human problem solving (Hypothesis 5.1). We relate this conclusion to some other results in the area of general human problem solving.\nHuman problem solving is an extensively researched area, and many authors have already addressed related issues; we claim no primacy here. Nevertheless, we believe that we are the first to explicitly argue that the general human problem solving mechanisms from the Proposition 4.5 are necessary and probably sufficient for general human problem solving. More importantly though, to our best knowledge we are the first to establish the link between human problem solving and the effective problem solving strategy used by Solomonoff (1986) (Theorem 2.1, Corollary 2.2, Propositions 3.1, 4.5, 4.7, and Hypotheses 4.8, 5.1), thus drawing important conclusions about the scope and roots of the effectivity of human problem solving as well as establishing the framework in which this effectivity can be further studied. By understanding the principles behind the effectivity of human problem solving, the development in AI (like cognitive architectures) can advance along more specific paths towards attaining human level abilities."}, {"heading": "2 The effective problem solving strategy", "text": "Let us call by Blind search a method of solving problems by checking all potential solution candidates. It follows that this method can solve any problem (provided the problem has a finite solution), although the time required, which depends on the number of solution candidates, is usually huge. Therefore, Blind search is a universal but not an effective method, if there are too many solution candidates to check them one by one. Solomonoff (1986) in his general problem solving system exploited a theorem in probability stating that if an appropriate order could be imposed on the solution candidates, then checking them in this order would yield probabilistically optimal problem solving strategy.\nTheorem 2.1 (Solomonoff, 1986). Let m1,m2,m3, ... be candidates/ideas that can be used to solve a problem. Let pk be probability that the candidate mk will solve the problem, and tk the time required to generate and test this candidate. Then, testing the candidates in the decreasing order pk tk gives the minimal expected time before a solution is found.\nCorollary 2.2. The effectivity of problem solving depends on\n1. Knowledge and experience, 2. Ability to generate \u2212 in the effective order (Theorem 2.1) and in a short time \u2212 the\nappropriate candidate ideas for solving the (sub)problems."}, {"heading": "3 Cognitive mechanisms related to the effective human problem", "text": "solving\nIn this section we propose a list of six cognitive abilities or mechanisms that, we argue, significantly help humans to generate in the effective order and in short time the appropriate candidate ideas for solving the (sub)problems. Thus, in our opinion these are the mechanisms that give rise to the effectivity of human problem solving, and as such should be implemented in cognitive architectures for this reason.\nProposition 3.1. The following processes (mechanisms, abilities) are related to the effectivity of human problem solving (with respect to Theorem 2.1, especially to the second point of Corollary 2.2):\n1. Discovering similarities 2. Discovering relations, connections, and associations 3. Generalization, specification 4. Abstraction 5. Intuition 6. Context sensitivity and the ability to focus and forget"}, {"heading": "3.1 Discovering similarities", "text": "Hypothesis 3.2. Similar problems often have similar solutions.\nThe arguments for this hypothesis can be found in Case-based reasoning (Slade, 1991; Kolodner, 1992) \u2013 a process of solving new problems based on the solutions of similar past problems. A general case of finding a similarity among problems is when the solver identifies a set of problem concepts (properties, features, structure, . . . ) based on which he can quickly access similar concepts stored in his memory that are associated with an idea how to solve a known problem. In such a case the new problem and the known one are similar via this set of concepts. According to the Hypothesis 3.2, this process provides the solver with relevant solution candidates and vice versa, the solution candidates that are not similar to the current problem in this way are not recalled. In terms of Theorem 2.1 and Corollary 2.2, the solutions of similar (and therefore relevant) problems with high chance of solving the problem have high probability value (in Theorem 2.1), and this is confirmed by the fact that they are recalled, while problems that are not similar (with probably1 low probability value) are not recalled.\nHuman solvers have cognitive abilities that support effective search for similarities and patterns (Bejar et al., 1991; Gentner et al., 1993; Robertson, 2003). Moreover, this ability is robust: the solver is able to discover partial similarities and patterns by adding, removing, or replacing problem concepts or parts \u2212 this enables the solver to formulate hypotheses, observe rules, make abstractions and so on. Given that for various reasons we often add superficial\n1Problems that are dissimilar can still be related. For example, gravitational and other physical laws can be\nused in leader election problem in distributed computing.\nelements/concepts to the remembered problems and solutions (Medin and Ross, 1989), very few of them are actually directly similar, and this ability is able to overcome such shortcomings.\nThus the solver is able to (often quickly) identify and access concepts representing relevant information and solution candidates/ideas with high chance of solving the problem (Hypothesis 3.2). Therefore, discovering similarities participates in cognitive realization of the second part of the Corollary 2.2."}, {"heading": "3.2 Discovering relations, connections, associations", "text": "The role of finding related, connected, or associated concepts is similar to that of finding similarities \u2013 it provides the solver with relevant solution candidates (ideas, information) and/or helps him to exclude some of them from further consideration.\nHypothesis 3.3. A rational solver does not explore solution candidates (ideas, information) that are not in any way related to the given problem \u2013 whatever the solver does during the problem solving he always has some rational reasons for doing it, however vague they may be, like intuition or automated procedures.\nThis hypothesis follows from the semantic network model of memory (Quillian, 1968;\nCollins and Quillian, 1969), spreading activation mechanism (Collins and Loftus, 1975; Anderson, 1983; Ohlsson, 1992), and Hebb rule (Hebb, 1949). The activation in the semantic network can spread only to those concepts that are connected, and because of the Hebb rule the concepts get connected if they were (often) held active together or in close time succession in the past2. Therefore, any ideas (which are represented by a set of concepts) how to solve the problem the solver gets are connected with, and therefore (at least statistically) related to, the set of currently or recently active concepts.\nIn this way the solver effectively filters out unrelated solution candidates (ideas, information) represented by sets of concepts simply by not recalling them. In terms of the Theorem 2.1 this is the same as assigning a low probability to solution candidates that are not likely to solve the problem. On the other hand, the candidates that were recalled must be somehow related to the current problem, and by this fact they have higher chance of leading to a solution than other, unrelated candidates. In accordance with Theorem 2.1 they are also explored preferentially by the fact that they are recalled.\nNotice also that Hebb rule (and, temporarily, context as well) strengthens the associations among those concepts that the solver perceived or experienced (consciously or unconsciously) as related in the past. Therefore, the strongest related candidates (ideas, information) are likely to be recalled first. In this way the solver is able to effectively filter the related candidates (ideas, information) so that the most promising ones are recalled and examined among the first (see also Knowledge deployment in Anderson (1996) and The declarative Memory Module from Anderson et al., 2004).\n2If the activation of concepts is strong enough, one concurrent activation may suffice as well (e.g., touching\na hot stove).\nFurthermore, complex problems that require a creative solution often have too many possible approaches (solution candidates) to try them one by one. Logic, knowledge, common sense, or experience as well as various strategies, methods, or heuristics can be used to deduce conditions that all candidates must satisfy in order to lead to a solution, thus eliminating candidates with no chance of success. As an example, consider Zebra puzzle3 (also known as Einstein\u2019s puzzle) where there is a set of houses with several properties (e.g., colour, resident\u2019s nationality, kept pet and others), and the solver is given a number of constraints based on which he is required to determine who owns a zebra. In this problem logical inference can be used to eliminate wrong solution candidates because they contradict some of the constraints. The act of ignoring these candidates (i.e., excluding them from further consideration) can be viewed as assigning these candidates a very low probability of success in accordance with Theorem 2.1, thus saving the solver time by not examining them. Moreover, the same mechanisms can be used to generate or discover additional related solution candidates as well. For example, a well known general problem solving strategy TRIZ (Altshuller, 1994, 2000; Kaplan, 1996) exploits already solved related problems to suggest potential solution candidates/ideas. Further general problem solving strategies also rely on finding related problems and situations (Polya, 1957; Newell, 1981, Woods, 2000).\nAs was the case with finding similarities, the solver may need to invest time in the identification of these relations and associations. However, a solver that does not look for and find some vital information (e.g., a crucial association) may be forced to check many solution candidates before finding a solution, hence spending a lot of time. Additionally, an ineffective solution that requires lot of steps increases a chance of making an error. For example, consider Gauss\u2019 problem of summing integers between 1 and 100. The solver can start to laboriously add the numbers thus spending a lot of time with an additional high chance of making an arithmetic error, or he can look for relations that will allow him to find the solution in a much more effective way. A problem model that incorporates the numerical property 100+1 = 99+2 = ... = 1+100 = 101 offers a lot faster derivation of the sought result (see also beginning of Section 4 for other view).\nHence, discovering relations, connections and associations participates in cognitive realiza-\ntion of the second part of the Corollary 2.2."}, {"heading": "3.3 Generalization, specification", "text": "In case of generalization, the problem concepts are substituted with more general, more abstract versions. Additionally, some (specific) parts of the problem (e.g., some restrictions posed on the problem solution, or not important details) may be omitted. For example, consider gravitational force between Earth and an apple \u2212 Newton generalized this relation to the force between any two physical objects (by omitting the particularity of the original objects).\nMore generally, assume that a new problem and a known one are similar via a set of concepts, and that the solution of the known problem can help the solver to solve the new one (see the upper part of the Section 3.1). However, the solver may not, for some reasons, be able to\n3http://en.wikipedia.org/wiki/Zebra_Puzzle, on 28.2.2015\ndiscover this similarity. It may happen, though, that the solver can discover this similarity, if the concepts of the new problem are substituted with more general/abstract ones because general and abstract concepts have generally more associations (hence the increased chance of discovering similarity). Thus, generalization improves human ability to find similar problems, and therefore improves problem solving effectivity by the same reasons as mentioned in Section 3.1.\nIn case of specification, it may happen that the solver has many solution candidates (ideas, information) to consider \u2212 too many to try them one by one and no rational reason to prefer one over another. Here, the additional restrictions on the problem solution and/or more concrete, specific concepts can eliminate some portion of these potential candidates (ideas, information) and reduce the problem space, hence improve the effectivity of problem solving. For example, it is often easier to prove a special version of a statement and then generalize it than proving the general case immediately. Finding a general form of the solution to the cubic equation (ax3 + bx2 + cx + d = 0) can be made a lot easier, if we first restrict ourselves to one specific equation (namely x3+px+ q = 0), and then show how to obtain this form from any other cubic equation (i.e., how to transform the special solution to a general one).\nNotice also that in both cases the solver may no longer solve the original problem; however, solutions to these general/specific versions of the original problem may help the solver to solve the problem because they are similar (see Section 3.1)."}, {"heading": "3.4 Abstraction", "text": "Hypothesis 3.4. Problems with the same gist/core have probably the same or a similar solution.\nAbstraction is the ability to see a problem in simplified, abstract, general concepts (terms), i.e., construction of the problem\u2019s gist or core which represents what is the problem really about (as far as solver\u2019s knowledge, experience, and his cognitive abilities permit). For example, consider a problem in which two cyclists, 50 miles apart, are racing towards each other from opposite directions at constant speeds of 18mph and 22mph. A fly buzzes back and forth between the noses of the cyclists at 100mph until it is smashed when the cyclists collide. How far did the fly travel before it died? This problem becomes very simple \u201cdistance = speed x time\u201d problem when we abstract from the shape of the fly\u2019s trajectory.\nAbstraction extends the discovering similarities. Gist as such is usually smaller than the original problem because we omit information that is not important for the solution according to our problem model. Moreover, gists contain simplified and abstract concepts (again omitting unimportant information). As a result, working with gists reduces the problem space as many problems coalesce into one gist what increases the effectivity what allows superficially different problems to be classified as similar (i.e., recalled), if they are similar on a deeper/gist level. Additionally, the reduced problem space allows faster comparisons between the problems. Furthermore, simplified, general, or abstract concepts have more associations which also increases a chance for their similarity.\nAccording to Hypothesis 3.4 (as well as Hypothesis 3.2), problems similar on this abstract level are relevant solution candidates. In this way, the abstraction improves human ability to find similar problems, hence improves problem solving effectivity, by the same reasons as discovering similarities (see Section 3.1)."}, {"heading": "3.5 Intuition", "text": "By intuition we mean something similar to a preschool child learning a grammar. The child can use the rules mostly correctly, but he or she cannot formulate them. However, the rules are in some accessible way stored in the child\u2019s memory.\nHence, intuition is based on the ability to find similarities and/or relations (connections, associations) with the only difference that now the solver cannot articulate the reasons for them. Thus, intuition and discovering similarities and relations (connections, associations) participate in cognitive realization of the second part of Corollary 2.2 by the same reasons."}, {"heading": "3.6 Context sensitivity and the ability to focus and forget", "text": "Concepts in solver\u2019s memory have, in general, many associations (Ohlsson, 1992). Each such association is a potential clue to the problem, and hence a solution candidate. However, it may happen that only a few concepts are truly relevant to the solution \u2212 those that do not fit the context or problem situation are probably not going to be part of the solution, and therefore should not be considered preferentially (although they still can be considered later in problem solving, if nothing else worked).\nCognitive ability that blocks these seemingly unrelated concepts helps to increase the problem solving effectivity because solution candidates (represented by sets of concepts) with low chance of success do not get in the way of candidates with higher potential. The act of not recalling these probably unrelated concepts and information (i.e., solution candidates) can be interpreted as assigning them a low probability of success which is in partial accord with Theorem 2.1. On one hand, there could be a simple, but unusual or unexpected solution hidden in these unrelated concepts that we can miss in this way. On the other hand, this should not happen very often \u2212 the gain from this mechanisms in average case outweighs the occasional failure.\nSimilarly, the ability to focus on some (small) set of concepts and to ignore some other set of concepts decreases the corresponding problem space, and hence generally increases the effectivity of the problem solving. This ability helps the solver to better utilization of his limited mental resources (e.g., working memory), thus enabling him to explore more involved relations, associations, problem manipulations and so on. In this way, this ability supports finding similarities and relations, and therefore improves effectivity of the problem solving by the same reasons (see Sections 3.1 and 3.2).\nFinally, there is the ability to forget, i.e., remove concepts from the solver\u2019s working memory (consciousness). The active concepts tend to return to the inactive state unless there is some conscious effort from the solver or there is some stimulus from the outside world\n(Peterson and Peterson, 1959). As a consequence, the amount of active concepts is reduced what frees some of the solver\u2019s limited cognitive resources which possibly improves his focus (less concepts to focus on), and also helps him to overcome impasse or functional fixedness."}, {"heading": "3.7 Final remarks", "text": "It follows that each of these cognitive mechanisms participate in making human problem solving effective with respect to the innate quality of these mechanisms and solver\u2019s knowledge and experience database (according to the Corollary 2.2). However, how much effective the general human problem solving process really is depends on the extent to which these cognitive mechanisms participate in this process. That is, should these cognitive mechanisms be sufficient for the general problem solving (i.e., should there be no other crucial mechanism of which effectivity we know little), the human problem solving guided by these cognitive mechanisms would be, according to Solomonoff, in the expected case effective.\nOn the other hand, the order in which the solver tests the found candidates does not need to match exactly the Solomonoff order from Theorem 2.1. This depends on the solver\u2019s knowledge and experience, on the quality of his cognitive skills, and on his system for choosing among multiple alternatives4 \u2212 this distinguishes domain novice and expert problem solvers (see Chase and Simon, 1973) as well as average people from geniuses (see Deary et al., 2000). However, given these limitations the human problem solver approximates the Solomonoff optimal problem solving strategy, and that is, perhaps, the best he can do."}, {"heading": "4 General human problem solving mechanisms", "text": "The topic of this section are mechanisms that are necessary and probably sufficient for the successful (see bellow) human problem solving in general case because the mechanisms described in the previous section, even though employed during the problem solving, may not be the whole story. More precisely, if we want to argue that human problem solving process is effective in general, then we need to establish which mechanisms are used in this process in the first place. Once this is done (see Propositions 4.5 and Hypothesis 4.6), we can compare these general problem solving mechanisms with the effective cognitive mechanisms from the Proposition 3.1 (see Proposition 4.7 and Hypothesis 4.8).\nNote that by successful problem solving we also mean effective5, although this does not necessarily mean that the found solution is itself effective. More particularly, sometimes it may be easier to use a simple non-effective method because trying to discover something more effective may actually take more time or effort than the simple non-effective approach. For example, recall the Gauss summation problem from Section 3.2. Summing the numbers is the most obvious and simplest of solutions, but it is also a terribly non-effective one. However, many\n4Solver\u2019s mood, motivation and so on may also play an important role (see Woods, 2000), but we do not consider these factors here. For implementation of emotions into cognitive architecture (and reasons for doing so) see Laird (2008); Wayne and Langley (2011); Hudlicka (2004). 5Non-effective approach being Blind search (see Section 2).\nsolvers may be done in 10 minutes (that\u2019s six seconds for each summation). Besides, searching for the relation 100 + 1 = 99 + 2 = ... = 101 may actually be a lot more difficult for them, i.e., much more time and effort consuming. Therefore, for these solvers the effective solution (from their point of view) is to use a method that is objectively non-effective (i.e., there exist much faster methods). Thus, we observe a trade-off between the effectivity of the problem solution versus the effectivity of the search method that finds this solution. Ideally, the effectivity of (i.e., time spent by doing) search and solution should not be very different. For example, Gauss (or anyone for that matter) would probably not bother to look for a sophisticated solution, if he was supposed to sum the numbers from 1 to 10. On the other hand, no one will try apply the simple summation method for numbers from 1 to 1 000 000 (at least not for a long time).\nThe layout of this section is as follows. In Section 4.1 we propose 4 classes of processes related to a certain outcome in the problem solving process (e.g., new information, problem manipulation), and we give arguments for the hypothesis that all conscious actions the solver does during the problem solving fall into one of these classes. In Section 4.2 we present a subtler version of the 4 classes of processes form the previous section. We give arguments for the hypothesis that the presented processes (mechanisms, abilities) are sufficient for the general human problem solving. Finally, in Section 4.3 we link these general human problem solving mechanisms with the effective cognitive mechanisms from Proposition 3.1."}, {"heading": "4.1 General human problem solving schema", "text": "Here we present a general human problem solving schema \u2212 a set of 4 states and transitions among them that generalize the process of human problem solving. The purpose of these states is to characterize the human problem solving process in a general \u2212 not task specific \u2212 way. Each state represents an abstract goal the solver is trying to achieve.\nState A1 (Follow the instructions)\nThe solver knows or thinks he knows what to do, and he follows this plan (i.e., executes some sequence of instructions). Note that this does not necessarily mean that the solver knows how to solve the whole problem. Take, as an example, Rubik cube. The solver may know how to build one side of the cube, but after this side is finished, he needs to find the next steps.\nNote also that the solver may generate, gather, construct new information or methods, and/or manipulate with the problem or situation during this execution, but in this state the solver does not get stuck, i.e., he always knows what to do.\nState A2 (Find a better approach)\nThe solver knows or thinks he knows what he should/could do, but instead of following the plan, he deliberates whether this course of action (solution algorithm, problem or situation model, ...) is correct, best possible, or effective enough, and possibly looks for/considers other approaches/problem models. The solver can generate, gather, construct new information or methods related to the problem, manipulate with the problem model (perform\nmental experiments), produce new models, or transform the problem to another (easier, similar, more general, ...) problem to correctly asses the situation and the effectivity of the current and alternative approaches.\nState B (Find any acceptable approach)\nThe solver does not know what to do, and he can try to generate, gather, construct, observe, extract new information or methods, or he can transforms the problem to another (easier, similar, more general, ...) problem, or he can try to find another suitable problem model (i.e., change the current approach) so that he can make the next step towards a solution6. The difference between this and the previous state is that here the solver is stuck, i.e., he does not have any clear idea how to proceed/get closer to the goal. The solver may know of several (many) possible approaches, but he, so far, cannot assess the suitability of any of them. He can either try them all one by one to see if any of them works (e.g., Blind search), or he can try to generate more information to exclude some/all of them and/or find a better approach(es) (i.e., find additional solution candidates/ideas).\nState C (Take a break)\nIncubation \u2212 the solver takes a break from the problem. Such break can help the solver to forget old/useless/misleading information and access new problem related information from long-term memory, and/or to gather new information from the environment by processing it in light of the unsolved problem (see opportunistic-assimilation model in Seifert et al., 1994).\nProposition 4.1. At each moment during the problem solving process, the solver is in one of the states A1\u2212 C.\nProof. Given a problem, the solver either knows or does not know what to do. If he knows what to do, he can choose to execute these steps (A1), or he can choose not to execute these steps. In the latter case (A2) the reasonable/rational thing to do is to think about these steps \u2212 to assess the suitability of these steps and/or to consider alternative approaches. If the solver does not know what to do, then he has no choice but to gather more information related to the problem within the currently chosen approach and/or reappraise his approach (B). Finally, the solver can (temporarily) abandon the problem at any time (C).\nDepending on the problem the solver can start in each of the states A1, A2, B. Subsequently, the solver can go from any state to any. For example, the solver may follow a learnt routine (A1) to build one side of Rubik cube, but once this side has been finished our solver gets stuck, and he moves to state B. The problem is always solved in the state A1.\nThe previous abstract description of the problem solving states gives us some intuition as to what kind of general goals the solver pursues when solving the problem (follow the instructions in A1, find a better approach in A2, find any acceptable approach in B, take a break in C). Given\n6The solver can get into this state also by following a plan/heuristic that is formulated too generally/vaguely\nor for a similar problem instead, and he does not know how to precisely apply its steps.\nthese goals we now want to understand what processes (mechanisms, abilities) the solver can apply or use to solve the problem (i.e., to achieve the partial goals given by A1 \u2013 C). However, in order to avoid enumerating all relevant processes the solver can employ (consciously or unconsciously), we will focus on some larger classes of these processes, call them macro processes, which we characterize through their outcome. We propose 4 such classes (or macro processes) which, we argue, are used in successful human problem solving. We further hypothesize that they are also sufficient.\nProposition 4.2. The following macro processes (mechanisms, abilities) are necessary for successful human problem solving:\n1. Generation (i.e., discovering, construction, extraction7) of new information.\nHere are the processes (mechanisms, abilities) that provide the solver with access to new information, methods, problems, situations, models and so on (themselves represented by sets of concepts) by means of recall (e.g., discovering similar, related, or associated concepts), construction, derivation, inference of new concepts (e.g., application of logic, methods), experimentation (mental or real), or by searching external sources (e.g., library, Internet, colleagues). The processes can be both conscious (e.g., using logical inference) and unconscious (e.g., recalling a similar problem, concept).\n2. Manipulation with the information, problem or situation representation. Here\nare the processes (mechanisms, abilities) that allow the solver to manipulate with the problem and situation representation (model), perform mental experiments, imagine a different situation and so on. The solver can, for example, add new concepts to the problem representation, assume new problem properties/features, transform the problem into a different one, require additional conditions on the solution, formulate sub-problems and so on. In other words, the solver can change his perception of the problem and its situation/context (consciously or unconsciously). Note that there can be same processes in this class and the previous one. For example, the solver can apply logic to either derive new information as well as to adjust problem representation according to logical rules.\n3. Assessment of the approach. Here are the processes (mechanisms, abilities) that al-\nlow the solver to \u201dstep outside\u201d the process of solving the problem and/or to appraise his current or some alternative approach (including planning, monitoring, guiding, decision making, comparing the situation with problem goal). Again, this class shares many processes with both previous classes as both generation of new information and problem manipulation can be used in such assessment. Note that regarding the problem solving effectivity the crucial part of this (macro)process is the solver\u2019s ability to stop executing his current plan of action and start thinking about this plan. This may save the solver a lot of time by abandoning wrong/non-effective approaches as soon as possible.\n4. Incubation. The solver can always choose to give the problem solving a rest. There\nare some unconscious processes (e.g., relaxation of temporarily strengthened links in the\n7From the external world through experiment or database query, for example.\nsemantic network of the solver\u2019s memory) that can help the problem solving (see also the opportunistic-assimilation model of incubation in Seifert et al., 1994).\nProof. Generation of new information is downright obvious. The importance of problem representation manipulation comes from, for example, research on insight problems (Duncker, 1945; Gick and Holyoak, 1980; Kaplan and Simon, 1990). Maier\u2019s (1931) Two-string problem is an example that, without the change of initial problem representation, many test participants were not able to solve the problem. On the other hand, the problem with the two cyclists and a fly mentioned in the Section 3.4 can be solved much faster (i.e., effectively), if the initial model of zigzagging fly is changed to \u201cdistance = speed x time\u201d problem.\nThe importance of the approach assessment is harder to argue but a good example is the solution to the more difficult version of the already mentioned Gauss\u2019 problem of summing integers (see Section 3.2), this time from 1 to, say, 1 000 000. A long and laborious approach of blindly adding the numbers is ineffective (in fact probably impossible), and it will most likely lead to arithmetic errors that will prevent the solver from ever reaching the correct solution. Thus, the solver needs to assess this approach as very poor, and look for a better one. Some arguments for this class also come from the insight problems where the solver, in order to solve the problem, must come to a point where he questions his (initially wrong) approach. Finally, the various accounts of the importance of incubation can be found in Koestler (1964) or in Dorfman et al. (1996).\nGiven the mentioned problem solving states A1 \u2013 C and their associated sub-goals (or sub-problems), are there any important/relevant macro processes (mechanisms, abilities) not included in the Proposition 4.2 that the solver uses to solve problems (i.e., to achieve the subgoals from the problem solving states A1 \u2013 C)? Perhaps, but any such process would leave the solver with no new information (because otherwise it would belong to the generation of new information group), nor it would change his perception of and approach to the problem and situation (problem manipulation or problem assessment group). Similarly, this new process cannot make the solver to stop solving the problem (incubation group). For this reasons we formulate the following hypothesis.\nHypothesis 4.3. The (conscious) actions of the solver during the problem solving process can be classified into 4 categories form the Proposition 4.2.\nOn the other hand, there may be other processes (mechanisms, abilities) not directly linked with problem solving which, however, also play an important, albeit implicit, role in human problem solving (such processes can be implicitly used by the processes from the classes described in the Proposition 4.2). For example, consider the importance of (inner) speech and language comprehension. It can help the solver to formulate new (sub)problems, and many problem solving methods are stored/remembered as mental texts (e.g., a recipe). It was shown that the individuals (undergraduate students) most successful in the task (Raven progressive matrices) necessarily used inner speech that sometimes addressed the problem, sometimes themselves, in a relatively evenly distributed manner (DaSilveira and Gomes, 2012). Additionally,\nBaldo et al. (2005) writes that \u201clanguage being a symbolic representation system allows us to not simply represent concepts, but more importantly for problem solving, facilitates our ability to manipulate those concepts and generate novel solutions. When language is disrupted, either by neurological insult or verbal interference, we are left with a less sophisticated, less flexible capacity for analysing and solving complex problems.\u201d On the other hand, Croft and Cruse (2004) hypothesise that \u201clanguage may not be an autonomous cognitive faculty in the sense that the representation of linguistic knowledge is essentially the same as the representation of other conceptual structures, and that the processes in which that knowledge is used are not fundamentally different from cognitive abilities that human beings use outside the domain of knowledge.\u201d Either way, we believe that language certainly has a role to play in human problem solving as it probably is the only way in which we can convey, understand, or manipulate with complex and abstract concepts8. Whether this is its only role in problem solving is still a matter of debate.\nAnother elemental cognitive processes implicit in human problem solving are the processes related to the operation of working memory (support processes for executing, guiding, and monitoring the execution of the intended activities). These processes are essential in problem solving, but they cannot do any complex step in the problem solving process on their own. Furthermore, the solver also has the ability to interpret/understand a recalled content of his memory or experience. If he recalls, say, a method, then he understands which actions he ought to take, although it may happen that he does not know how (i.e., he knows what to do, but does not know how to do it). This may happen when the recalled method was originally used with different but similar problem. Consequently, we formulate the main hypothesis of this section.\nHypothesis 4.4. The macro processes (mechanisms, abilities) described in Proposition 4.2 are sufficient for successful human problem solving, although successful problem solving probably implicitly depends on other (elemental) cognitive processes as well, including\n(a) language processing, (b) working memory processes (coordinating, monitoring, and executing the intended activi-\nties),\n(c) ability to interpret/understand memories and experience."}, {"heading": "4.2 General human problem solving mechanisms", "text": "In the Section 4.1 we identified 4 macro processes that are necessary (see Proposition 4.2) and probably sufficient (see Hypothesis 4.4) for the successful human problem solving. In this section we are mainly interested in human approach to acquiring new information (new with respect to solver\u2019s attention). That is, we replace the first macro process from Proposition 4.2 with other, more subtle cognitive processes; other macro processes from this proposition are kept untouched.\n8Groups, fields, block designs are abstract mathematical concepts that probably cannot be expressed without\nproper language.\nProposition 4.5. The following processes (mechanisms, abilities) are necessary for successful human problem solving\n1. Discovering similar concepts (representing information, experience, properties, prob-\nlems, situations, models, ...)\n2. Discovering related, connected, and associated concepts (representing informa-\ntion, experience, properties, problems, situations, models, ...)\n3. Manipulation with the information, problem, or situation or its representation\n(e.g., transform, split, add or remove concepts, features, attributes, imagine, experiment, ...)\n4. Assessing the situation/progress and deciding what to do next 5. Incubation (stop solving the problem)\nFurthermore, other cognitive processes not directly linked with problem solving, including\n(a) language processing, (b) working memory processes (coordinating, monitoring, and executing the intended activi-\nties),\n(c) ability to interpret/understand memories and experience,\nare (most likely) used as well.\nNote that by Manipulation with the information, problem, or situation or its representation and Assessing the situation/progress we mean the application of some method, procedure, heuristic, experience, common sense, logic, ... that performs manipulation/assessment action on something. Also note that when we talk about human problem solving, the processes 1 & 2 from Proposition 4.5 actually mean the processes 1 \u2013 6 from Proposition 3.1 (we argued in Section 3 that processes 3 \u2013 6 from Proposition 3.1 are special cases (or modifications) of the processes 1 & 2 from the same proposition). Moreover, the items 3 & 4 from Proposition 4.5 can again be viewed as macro processes (see text above Proposition 4.2), rather than some (elemental) cognitive processes (e.g., biologically motivated). On the other hand, items 1 & 2 from the same proposition are biologically motivated (semantic network models, Hebb rule).\nProof. The arguments for the processes (mechanisms, abilities) numbered 3 \u2013 5 can be found in the proof of the Proposition 4.2. As for the discovering similar or related/associated concepts, they are crucial for analogising and analogical problem solving of which immense importance Robertson (2003) writes: \u201cThe importance that has been attached to the role of analogising in human thinking cannot be emphasised too strongly. ... Andersons ACT-R and the various analogical models produced by Hofstadter and the Fluid Analogies Research Group, for example, consider analogising to be fundamental to human thinking and learning.\u201d On the other hand, processes (a) \u2013 (c) in the Proposition 4.5 are necessary for normal cognitive functioning as such, which also include problem solving (see also Kyllonen, 1996; Baldo et al., 2005 for the role of these processes in problem solving).\nLet us now consider the human approach to acquiring new information (new with respect to the solver\u2019s attention) \u2013 the first macro process from Proposition 4.2. We want to argue that this macro process can be replaced with a combination of processes listed in Proposition 4.5 (all of them). We can split the processes related to the generation of new information into two classes: unconscious and conscious.\nConsider the first case. It was already mentioned in Section 3.2 (Hypothesis 3.3) that humans are rational solvers in the sense that whatever we do during the problem solving we always have our rational reasons for doing it, however vague they may be (e.g., intuition). This conclusion follows from the semantic network model of memory (Quillian, 1968; Collins and Quillian, 1969), spreading activation mechanisms (Collins and Loftus, 1975; Anderson, 1983; Ohlsson, 1992), and Hebb rule (Hebb, 1949). The activation in the semantic network can spread only to those concepts that are connected, and because of the Hebb rule the concepts get connected if they were (often) held active together or in close time succession in the past9. Thus, in this model of memory, no information (i.e., no concept) can be accessed without it being similar to, related to, or associated with the currently or recently active concepts (otherwise there would be no path for the activation to spread there). From this we conclude that the unconscious information gathering from the solver\u2019s long-term memory is achieved through similarity or spreading activation (from active concepts to related/associated concepts), and that processes/abilities 1 & 2 from the Proposition 4.5 play a key role here. Additionally, solver can also spot (new) similarities or relations/associations between concepts held in his working memory (or on a piece of paper for that matter).\nIn case of conscious processes, the solver can acquire new information from his memory by recall10, or he can construct it from the information he so far gathered, or he can extract it from the environment through interaction, experimenting, or observation. Now, however the solver consciously generates the new information, it is always11 according to something, be it a method, heuristic, experience, or just an intuition. In all of these cases the motivation for his conduct (this method, heuristic, and so on) lies either in his memory (working or long term), or in the external world, and it needs to be fetched (by similarity or spreading activation), constructed, or extracted (from a database through a query, or from an environment through interaction, experiment, or observation) However, the construction and extraction cycle back because the method, according to which the solver wants to construct or extract something (e.g., other method), needs to be acquired prior any use. This can happen through recall (processes/abilities 1 & 2 from the Proposition 4.5 together with (a) \u2013 (c)), or recursively through construction/extraction of another method (which again needs to be acquired etc.). Once a method, heuristic, experience, etc. is recalled, constructed, or extracted, the solver can try to apply/execute its steps.\n9If the activation of concepts is strong enough, one concurrent activation may suffice as well (e.g., touching a hot stove). 10He can use strategies, methods, heuristics to boost his unconscious recall processes (see also Sections 3.3, 3.4, 3.5). 11The information cannot, of course, magically appear in the solvers head (apart from the unconscious processes of recall which we described in the previous paragraph).\nAdditionally, from the broader perspective, we can view the latter case as a process of problem solving12, and the applied/executed methods can manipulate with the problem, information, etc. as well as concern the assessment of the current approach to the problem (processes 3 \u2013 4 from Proposition 4.5).\nThus, the acquiring of new information (new with respect to solver\u2019s attention) is in human problem solving carried out (mainly) by processes 1 & 2 (and also by 3 & 4) from the Proposition 4.5 together with (a) \u2013 (c), and this happens either directly (recall from solver\u2019s memory), or indirectly (through other priorly recalled, constructed, or extracted methods)13. Consequently, we formulate the main hypothesis of this section.\nHypothesis 4.6. If Hypothesis 4.4 holds, then the processes (mechanisms, abilities) from the Proposition 4.5 are sufficient for successful human problem solving.\nAdditionally, if the solver does not know how to apply a particular process from the Proposition 4.5 (e.g., he does not know how to obtain new information, or how to transform the problem to make it easier, etc.), he can formulate this as a new problem to be solved. In this way, the solver creates new problems like \u201cHow do I find similar/related problems\u201d or \u201cIs this a good approach? How do I assess it?\u201d, and he solves these problems using the same process from the Proposition 4.5. Once, for example, a similar problem is identified, the solver can continue solving the original problem by using the solution of this previously solved similar problem. From this point of view, human problem solving is a recursive process (compare this with subgoaling from many cognitive architectures like SOAR, ICARUS, or ACT-R).\nNotice also that the processes from the Proposition 4.5 cover very well the steps/advices from the celebrated problem solving strategy of Polya (1957). Most ideas Polya suggests to the solver are related to the similar or related solved problems/information, manipulation with the problem, its representation, or situation, assuming new problem properties, using the environment for drawing figures, and so on.\n4.3 The relation of Proposition 3.1 and Proposition 4.5\nWhat is the relation between the general problem solving processes (mechanisms, abilities) from Proposition 4.5 and the effective cognitive processes (mechanisms, abilities) from Proposition 3.1? In this section we link these two sets of processes, and from this link we draw conclusions about the effectivity of human problem solving.\nProposition 4.7. In terms of human problem solving capabilities, the processes (mechanisms, abilities) from Proposition 3.1 together with (a) \u2013 (c) from Proposition 4.5 suffice to replace the processes (mechanisms, abilities) from Proposition 4.5.\nProof. Discovering similar and related/associated concepts (representing information, experience, common sense, properties, methods, problems, situations, models and so on) figure in\n12Generating relevant information can be hard, and it can become a new sub-problem to be solved. 13This can also be viewed as a problem solving process: the solver can formulate new problems to solve like\n\u201cHow do I find new relevant information?\u201d and apply the same mechanisms from Proposition 4.5.\nboth lists of Propositions 3.1 and 4.5. Remember here the note (just below the Proposition 4.5) that the processes 1 & 2 from Proposition 4.5 actually mean the processes 1 \u2013 6 from Proposition 3.1. Let us consider the manipulation with the information (or problem and situation representation). The solver manipulates with the information/problem according to something, be it a method, heuristic, experience, or just an intuition. In all cases the motivation for his conduct (this method, heuristic and so on) lies either in his memory (working or long term), or in the external world, and as such needs to be fetched (by similarity or spreading activation), constructed, or extracted (from a database through a query, or from an environment through interaction, experiment, or observation). Here we cycle back because the method according to which we want to construct or extract something (e.g., other method) needs to be acquired prior any use, and so we can apply the same processes. Once a suitable procedure is accessed, constructed, or extracted, the solver can try to follow its instructions.\nIn this way, the manipulation with information is not some elemental cognitive process; rather it is a macro process that consists of two phases: acquisition of the method/experience according to which this manipulation is to be carried out, and application/execution of the steps of this method/experience. The first phase may recursively use the processes from Proposition 4.5, but the initial incentive (i.e., the first step) always comes from the solver\u2019s head where discovering similar and/or related/associated concepts (through spreading activation) is/are most important. The second phase comes from the solver\u2019s ability to understand/interpret his own memories and experience. The assessment of the situation or problem solving progress follows similarly.\nFinally, we formulate the main hypothesis of this section \u2013 the general human problem\nsolving mechanisms.\nHypothesis 4.8. If Hypotheses 4.4 and 4.6 hold, then the processes (mechanisms, abilities) from Proposition 3.1 together with the cognitive processes for\n(a) language processing, (b) working memory process (coordinating, monitoring, and executing the intended activities), (c) ability to interpret/understand memories and experience,\nare sufficient for successful human problem solving. Together, they are the mechanisms for general human problem solving."}, {"heading": "5 The effectivity of human problem solving", "text": "So what do Sections 3 and 4 tell us about the effectivity of human problem solving? In Section 3 we argued that the processes (mechanisms, abilities) from Proposition 3.1 give the human solver the ability to (approximately) follow the Solomonoff optimal problem solving strategy from Theorem 2.1, and in Section 4 we hypothesised that these processes (together with some additional elemental cognitive processes, see Hypothesis 4.8) are sufficient for the successful general human problem solving. From this it follows that there is good evidence that human problem solving is organized according to an optimal (i.e., effective) problem solving strategy.\nHypothesis 5.1. In the probabilistic sense of Theorem 2.1, human problem solving is effective with respect to\n1. solver\u2019s knowledge and experience, 2. quality of his processes, mechanisms, or abilities from Proposition 3.1.\nGiven what we observe in the world, the human problem solving process is indeed fast (i.e., effective). Whence this effectivity comes from is still uncertain, but the results of our work summarized in Hypothesis 5.1 suggests that the roots of the effectivity of human problem solving lie in\n1. optimal problem solving strategy from Solomonoff (1986), 2. solver\u2019s knowledge and experience, 3. quality of the solver\u2019s mechanisms from Proposition 3.1, 4. language processing (in the sense of Baldo et al., 2005).\nAlso, the human problem solving approach can be viewed as a middle path between two extreme theoretical problem solving strategies. The first strategy relies on database of solutions to all problems. This strategy solves problems quickly by a simple look-up, but the time and costs of building (and maintaining) such database are enormous. The second strategy, on the other hand, assumes no such information, but relies only on a few chosen axioms from which it tries to derive all solutions. While it is easy to implement such strategy, using it would require an enormous amounts of time. Human problem solving fits somewhere in the middle. We remember many problems we solved in the past of which solutions we can easily apply, if we were to solve them again (thus reaping the benefits of the first strategy14). On the other hand, we can see similarities and relations between various problems or their parts what allows us to apply a solution of one problem to a similar or related one. In other words, we can manipulate with the information we have to derive new solutions just like in the second strategy with the huge difference that we do not start empty handed, that is, we have more than a few axioms to start with. This greatly increases the range of problems we are able to solve in a reasonable time, while keeping the database of problems/information manageable (compared to the database from the first strategy).\nAdditionally, when we compare the human problem solving approach with the general problem solving system of Solomonoff (1986), both based on the optimal problem solving strategy from Theorem 2.1, we can see that they differ in how they estimate the values of pk for the potential solution candidates. While Solomonoff is using the algorithmic probability (more precisely, its approximation), human approach is based on the similarity and relations/associations between the current problem and the solvers knowledge15. It is our belief that these two processes, mechanisms, or abilities (together with some others, see Hypothesis 4.8) are crucial for\n14And also bearing the costs as it takes us years to become expert problem solvers in a particular domain (Ericsson, 2003). 15We note that finding similarity or relation between objects can be very hard. For example, subgraph isomorphism problem, which can be considered as way of similarity between two graphs, is NP-complete (Cook, 1971).\nthe effectivity of human problem solving (see Hypothesis 5.1). On the other hand, it seems that they are not used in the Solomonoff (1986) general problem solving system, and also, it is not clear how effectively the algorithmic probability or its approximation can be computed in the general case. Either way, understanding the principles behind the effectivity of human problem solving is a sure way of achieving the human-like artificial intelligence because we already know that they work in humans very well.\nFinally, the fact that the effective cognitive mechanisms from the Proposition 3.1 (together with a few additional elemental cognitive processes, see Hypothesis 4.8) are sufficient for human general problem solving gives a strong argument for the Cassimatis (2006) Cognitive substrate hypothesis (see Section 1). The fact that his proposed mechanisms for the hypothetical cognitive substrate (i.e., reasoning about time, space, parthood, categories, causation, uncertainty, belief, and desire) do not match the mechanisms from the Proposition 3.1 may not be a problem because our theory is concerned with the human general problem solving process only, while Cassimatis\u2019 aim is to capture the whole, domain-universal human intelligence."}], "references": [{"title": "Is problem solving", "author": ["J. Baldo", "N.F.D. Dronkers", "Wilkins", "C. Ludy", "P. Raskin", "J. Kim"], "venue": null, "citeRegEx": "Baldo et al\\.,? \\Q1983\\E", "shortCiteRegEx": "Baldo et al\\.", "year": 1983}, {"title": "Cognitive linguistics", "author": ["W. Croft", "D.A. Cruse"], "venue": "ACM symposium on Theory of computing,", "citeRegEx": "Croft and Cruse.,? \\Q1971\\E", "shortCiteRegEx": "Croft and Cruse.", "year": 1971}, {"title": "The roles of similarity in transfer: Separating", "author": ["Press. Cambridge", "England", "2003. D. Gentner", "M. Rattermann", "K. Forbus"], "venue": null, "citeRegEx": "Cambridge et al\\.,? \\Q2003\\E", "shortCiteRegEx": "Cambridge et al\\.", "year": 2003}, {"title": "An adaptive architecture for physical agent", "author": ["P. Langley"], "venue": "Applications", "citeRegEx": "Langley.,? \\Q2008\\E", "shortCiteRegEx": "Langley.", "year": 2008}, {"title": "A unified cognitive architecture for physical agent", "author": ["P. Langley", "D. Choi"], "venue": null, "citeRegEx": "Langley and Choi.,? \\Q2005\\E", "shortCiteRegEx": "Langley and Choi.", "year": 2005}, {"title": "The heuristic of George Polya and its relation to artificial intelligence", "author": ["A. Newell"], "venue": "Research", "citeRegEx": "Newell.,? \\Q2005\\E", "shortCiteRegEx": "Newell.", "year": 2005}, {"title": "Problem Solving: Problem similarity", "author": ["bridge", "MA:MIT Press", "1968. S. Robertson"], "venue": "Machine Learning,", "citeRegEx": "bridge et al\\.,? \\Q2003\\E", "shortCiteRegEx": "bridge et al\\.", "year": 2003}], "referenceMentions": [{"referenceID": 3, "context": "Additional models of problem solving and, generally, of human cognitive skills have been proposed by research groups on cognitive architectures like ICARUS (Langley and Rogers, 2005; Langley, 2005; Langley and Choi, 2006; Langley et al., 2009; Langley and Trivedi, 2013), ACT-R (Anderson, 1996; Anderson et al., 2004), SOAR (Nason and Laird, 2005; Laird, 2008; Langley et al., 2009), Polyscheme (Cassimatis, 2006; Cassimatis et al., 2007; Kurup et al., 2011), and others (see Duch et al., 2008; Langley et al., 2009). Yet further approaches to problem solving were introduced in the field of theoretical computer science, although these models/algorithms were not much concerned with human approach to problem solving but rather with the objective effectivity of such algorithms (Solomonoff, 1986; Hutter, 2002; Schmidhuber, 2004; Hutter, 2005). Of these (and many others) research ideas and results we especially note two. First, the Cognitive substrate hypothesis by Cassimatis (2006) states that there is a relatively small set of computational problems such that once the problems of artificial intelligence are effectively solved for these, then the rest of the human intelligence can be achieve by the relatively simple problems of adapting the cognitive substrate to solve other problems.", "startOffset": 157, "endOffset": 987}, {"referenceID": 3, "context": "Additional models of problem solving and, generally, of human cognitive skills have been proposed by research groups on cognitive architectures like ICARUS (Langley and Rogers, 2005; Langley, 2005; Langley and Choi, 2006; Langley et al., 2009; Langley and Trivedi, 2013), ACT-R (Anderson, 1996; Anderson et al., 2004), SOAR (Nason and Laird, 2005; Laird, 2008; Langley et al., 2009), Polyscheme (Cassimatis, 2006; Cassimatis et al., 2007; Kurup et al., 2011), and others (see Duch et al., 2008; Langley et al., 2009). Yet further approaches to problem solving were introduced in the field of theoretical computer science, although these models/algorithms were not much concerned with human approach to problem solving but rather with the objective effectivity of such algorithms (Solomonoff, 1986; Hutter, 2002; Schmidhuber, 2004; Hutter, 2005). Of these (and many others) research ideas and results we especially note two. First, the Cognitive substrate hypothesis by Cassimatis (2006) states that there is a relatively small set of computational problems such that once the problems of artificial intelligence are effectively solved for these, then the rest of the human intelligence can be achieve by the relatively simple problems of adapting the cognitive substrate to solve other problems. Cassimatis\u2019 preliminary guess of what this substrate consist of includes reasoning about time, space, parthood, categories, causation, uncertainty, belief, and desire. Second, Solomonoff (1986) in his general problem solving system applied a theorem in probability that describes the probabilistically optimal problem solving strategy (see Section 2 and Theorem 2.", "startOffset": 157, "endOffset": 1490}, {"referenceID": 3, "context": "Additional models of problem solving and, generally, of human cognitive skills have been proposed by research groups on cognitive architectures like ICARUS (Langley and Rogers, 2005; Langley, 2005; Langley and Choi, 2006; Langley et al., 2009; Langley and Trivedi, 2013), ACT-R (Anderson, 1996; Anderson et al., 2004), SOAR (Nason and Laird, 2005; Laird, 2008; Langley et al., 2009), Polyscheme (Cassimatis, 2006; Cassimatis et al., 2007; Kurup et al., 2011), and others (see Duch et al., 2008; Langley et al., 2009). Yet further approaches to problem solving were introduced in the field of theoretical computer science, although these models/algorithms were not much concerned with human approach to problem solving but rather with the objective effectivity of such algorithms (Solomonoff, 1986; Hutter, 2002; Schmidhuber, 2004; Hutter, 2005). Of these (and many others) research ideas and results we especially note two. First, the Cognitive substrate hypothesis by Cassimatis (2006) states that there is a relatively small set of computational problems such that once the problems of artificial intelligence are effectively solved for these, then the rest of the human intelligence can be achieve by the relatively simple problems of adapting the cognitive substrate to solve other problems. Cassimatis\u2019 preliminary guess of what this substrate consist of includes reasoning about time, space, parthood, categories, causation, uncertainty, belief, and desire. Second, Solomonoff (1986) in his general problem solving system applied a theorem in probability that describes the probabilistically optimal problem solving strategy (see Section 2 and Theorem 2.1 in our paper). In this paper we argue that there is a relatively small set of cognitive processes (mechanisms, abilities) which allow humans to drive the problem solving by the same manner on which the Solomonoff (1986) probabilistically optimal problem solving strategy is based.", "startOffset": 157, "endOffset": 1882}, {"referenceID": 3, "context": "Additional models of problem solving and, generally, of human cognitive skills have been proposed by research groups on cognitive architectures like ICARUS (Langley and Rogers, 2005; Langley, 2005; Langley and Choi, 2006; Langley et al., 2009; Langley and Trivedi, 2013), ACT-R (Anderson, 1996; Anderson et al., 2004), SOAR (Nason and Laird, 2005; Laird, 2008; Langley et al., 2009), Polyscheme (Cassimatis, 2006; Cassimatis et al., 2007; Kurup et al., 2011), and others (see Duch et al., 2008; Langley et al., 2009). Yet further approaches to problem solving were introduced in the field of theoretical computer science, although these models/algorithms were not much concerned with human approach to problem solving but rather with the objective effectivity of such algorithms (Solomonoff, 1986; Hutter, 2002; Schmidhuber, 2004; Hutter, 2005). Of these (and many others) research ideas and results we especially note two. First, the Cognitive substrate hypothesis by Cassimatis (2006) states that there is a relatively small set of computational problems such that once the problems of artificial intelligence are effectively solved for these, then the rest of the human intelligence can be achieve by the relatively simple problems of adapting the cognitive substrate to solve other problems. Cassimatis\u2019 preliminary guess of what this substrate consist of includes reasoning about time, space, parthood, categories, causation, uncertainty, belief, and desire. Second, Solomonoff (1986) in his general problem solving system applied a theorem in probability that describes the probabilistically optimal problem solving strategy (see Section 2 and Theorem 2.1 in our paper). In this paper we argue that there is a relatively small set of cognitive processes (mechanisms, abilities) which allow humans to drive the problem solving by the same manner on which the Solomonoff (1986) probabilistically optimal problem solving strategy is based. Thus, we identify the possible roots and scope of the effectivity of human problem solving as well as provide an indirect evidence for Cognitive substrate hypothesis (Cassimatis, 2006) by arguing that only a few mechanisms are crucial for the effective problem solving. Our results and the layout of the paper are as follows. In Section 2 we describe the Solomonoff\u2019 (1986) optimal problem solving strategy (Theorem 2.", "startOffset": 157, "endOffset": 2317}, {"referenceID": 3, "context": "For implementation of emotions into cognitive architecture (and reasons for doing so) see Laird (2008); Wayne and Langley (2011); Hudlicka (2004).", "startOffset": 114, "endOffset": 129}, {"referenceID": 3, "context": "For implementation of emotions into cognitive architecture (and reasons for doing so) see Laird (2008); Wayne and Langley (2011); Hudlicka (2004). Non-effective approach being Blind search (see Section 2).", "startOffset": 114, "endOffset": 146}], "year": 2015, "abstractText": "The ability to solve problems effectively is one of the hallmarks of human cognition. Yet, in our opinion it gets far less research focus than it rightly deserves. In this paper we outline a framework in which this effectivity can be studied; we identify the possible roots and scope of this effectivity and the cognitive processes directly involved. More particularly, we have observed that people can use cognitive mechanisms to drive problem solving by the same manner on which an optimal problem solving strategy suggested by Solomonoff (1986) is based. Furthermore, we provide evidence for cognitive substrate hypothesis (Cassimatis, 2006) which states that human level AI in all domains can be achieved by a relatively small set of cognitive mechanisms. The results presented in this paper can serve both cognitive psychology in better understanding of human problem solving processes, and artificial intelligence in designing more human like intelligent agents.", "creator": "LaTeX with hyperref package"}}}