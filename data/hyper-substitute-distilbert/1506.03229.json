{"id": "1506.03229", "review": {"conference": "arxiv", "VERSION": "v1", "DATE_OF_SUBMISSION": "10-Jun-2015", "title": "A cognitive neural architecture able to learn and communicate through natural language", "abstract": "communicative interactions involve linear variation of procedural knowledge application is used by the computational brain for dynamic elaboration of verbal and natural social implications for language understanding. although symbolic weight cannot been done on modeling human logic sequences, it has been difficult to bring them conclusions to a comprehensive tabula rasa algorithm. this work presents potentially realistic advantage, entirely based on any large - scale neural architecture, which lacks shown to shed light on how modern procedural knowledge culminated in language elaboration arises from neural processes. of main function conducting this system is the central computation, executive is a supervising construct that produces the other inputs of functional facial memory. across our model, the node executive is a neural network itself takes cerebral input the continuous muscular states of this short - level memory and yields as natural neurological state, therefore direct the flow related information underlying four working memory components through augmented procedural memory. the embodied system is static engine learning to offer interactive natural memory explaining simple tabula phrases, without getting proper priori knowledge of the structure of it, meaning complex words, role is 20 different classes of vocabulary, whereas internally interacting with a human presenting a text - based information, potentially an open - ended incremental learning process. intent is intended to sense nouns, compounds, adjectives, pronouns and conditional morphological classes, may use broad semantic sentences and to employ this knowledge both in receptive and expressive expression. overall thesis was validated on traditional corpus numbering 1587 essay fragments, based on literature \u2013 early language assessment, at the level of those 25 - years old ;, since has eleven additional blocks, expressing \u0430 broad range of functionalities that characterize human communication in language elaboration.", "histories": [["v1", "Wed, 10 Jun 2015 09:25:59 GMT  (2758kb)", "http://arxiv.org/abs/1506.03229v1", null], ["v2", "Fri, 12 Jun 2015 16:58:57 GMT  (2762kb)", "http://arxiv.org/abs/1506.03229v2", null], ["v3", "Mon, 22 Jun 2015 16:43:59 GMT  (3352kb)", "http://arxiv.org/abs/1506.03229v3", "The source code of the software, the User Guide and the datasets used for its validation are available in the ANNABELL web site atthis https URL"]], "reviews": [], "SUBJECTS": "cs.CL", "authors": ["bruno golosio", "angelo cangelosi", "olesya gamotina", "giovanni luca masala"], "accepted": false, "id": "1506.03229"}, "pdf": {"name": "1506.03229.pdf", "metadata": {"source": "CRF", "title": "A cognitive neural architecture able to learn and communicate through natural language", "authors": ["Bruno Golosio", "Angelo Cangelosi", "Olesya Gamotina", "Giovanni Luca Masala"], "emails": ["golosio@uniss.it"], "sections": [{"heading": null, "text": "The proposed system is capable of learning to communicate through natural language starting from tabula rasa, without any a priori knowledge of the structure of phrases, meaning of words, role of the different classes of words, only by interacting with a human through a text-based interface, using an open-ended incremental learning process. It is able to learn nouns, verbs, adjectives, pronouns and other word classes, to use them in sentences and to generalize this knowledge both in receptive and expressive language. The model was validated on a corpus of 1587 input sentences, based on literature on early language assessment, at the level of about 4-years old child, and produced 521 output sentences, expressing a broad range of functionalities that characterize human communication in language elaboration.\nKeywords: large-scale artificial neural networks, human language understanding, verbal working memory, cognitive architectures, Hebbian learning rule\n*corresponding author; email: golosio@uniss.it"}, {"heading": "1 Introduction", "text": "The attempts to build artificial systems capable of simulating important aspects of human cognitive abilities have a long history, and have contributed to the debate among two different theoretical approaches, the computationalism and the connectionism. According to the computational theory of mind, the brain is an information processing system, and thought can be described as a computation that operates on mental states [1,2]. This perspective has led to the implementation of a class of cognitive architectures called symbolic [3-5] (see Ref.s [6] and [7] for a review). Symbolic architectures can realize high-level cognitive functions, such as complex reasoning and planning. However, the main issue of such architectures is that all information must be represented and processed in the form of symbols pertaining to a predefined domain. This constraint makes it difficult for such systems to recognize regularities in large datasets, particularly in presence of noisy data and in dynamic environments. On the other hand, the central idea of the connectionist approach is that mental processes can be modeled as emergent processes of networks of highly interconnected (subsymbolic) processing units. The most used type of connectionist model is the artificial neural network (ANN) model, which has been widely used to account for different aspects of human cognition, including memory, perception, attention, pattern recognition and language. In many cases, connectionist architectures have been very effective in explaining some features of human behavior described by psychological findings. However, up to now they have never been implemented in large scale simulations for tasks that require complex reasoning [6]. Recently, Eliasmith et al. proposed a 2.5-million neuron model of the brain, able to elaborate visual image sequences and to respond through movements of a physically modeled arm [8]. Other large-scale neural simulations have been reported [9,10], however they focus on biological realism of the neuron model, while none of them deal with the problem of natural language elaboration.\nThe symbolic approach dominated the research in the field of natural language processing (NLP) for several decades. Natural language itself appears to be a strong symbolic activity, because words can be considered symbols used to represent real objects, concepts, events, and actions. On the other hand, the subsymbolic approach demonstrated to be more suitable for modeling the cognitive foundations of language processing and for representing statistical regularities in natural language [11-13]. Neural\nnetwork language models have widely been used in NLP, demonstrating superior performances in next-word prediction and other standard NLP tasks over conventional approaches, such as n-gram models. Fidelman et al. presented a neural network architecture able to parse and paraphrase scriptbased stories [14]. Their model was tested on a small corpus of nine scripts, each of which consisted of 4-7 sentences. Recently, deep learning techniques based on recurrent neural networks (RNNs) have been used successfully for several NLP tasks, including speech recognition [15], parsing [16,17], machine translation [18], sentiment analysis of text [19]."}, {"heading": "1.1 Working memory models", "text": "Although there are different perspectives regarding the organization of memory in the human brain, all approaches recognize at least two types of memory: the short-term memory (STM) and the longterm memory (LTM). STM can be defined as the capacity of the human mind to hold a limited amount of information in a readily accessible state for a short period of time. In contrast, LTM is a large repository of knowledge and of information on prior events, which can be stored in the mind for long periods of time. The term working-memory (WM) has been defined in different ways, however most researchers assume that WM includes the STM and the processing mechanisms used for temporarily storing and manipulating information in the STM.\nIn 1974, Baddeley and Hitch [20] proposed a working memory model composed of three main components: a central executive and two slave systems, i.e. the phonological loop and the visuo-spatial sketchpad. The central executive operates as a supervisory system by controlling the flow of information from and to the slave systems. The slave systems are responsible for short-term maintenance of information: the phonological loop stores verbal content, while the visuo-spatial sketchpad stores visual and spatial information.\nIn 2000, Baddeley [21] extended this model by adding a third slave system, the episodic buffer, which binds information from different domains (phonological, visual, spatial, semantic) to form integrated units of information with chronological ordering.\nFigure 1(a) shows a schematic diagram of Baddeley's model. Figure 1(b) represents the phonological loop, which is composed of two parts: a phonological store, which holds speech-based information that is subject to a rapid decay, and an articulatory reharshal component, which can prevent the verbal information decay by continuously articulating its contents, thus refreshing it in a\nrehearsal loop. Speech input enter the phonological loop directly. Other types of verbal information, as for instance written words or sentences retrieved from LTM, can be converted in articulatory code and thus enter the phonological loop. The phonological store acts as a inner ear, while the articulatory process acts as a inner voice, which repeats words on a loop to prevent them from decaying.\nThe Baddeley's model is supported by evidences from experimental psychology, neuropsychology and cognitive neuroscience (see Ref. [22] for a review). However, some criticism have been raised and alternative models have been proposed. Cowan [23] proposed a working memory model in which the LTM was not a separate component, but a part of the working memory. Cowan's model consists of four components: a central executive, a LTM, an activated memory and a focus of attention. The central executive directs attention and controls voluntary processing. The activated memory is the subset of LTM in a state of temporal activation, and it can hold a large number of activated elements. The focus of attention is a subset of the activated memory. It has a limited capacity and can hold up to about four independent items or chunks. McElree [24] suggested a focus of attention limited to a single chunk. Oberauer [25] proposes an integration of Cowan's and McElree's perspectives into a model that distinguishes three states of representations in WM: the activated part of LTM, the region of direct access and the focus of attention. The region of direct access roughly corresponds to the broader focus of attention in Cowan's model, with a scope of about four chunks. The focus of attention in Oberauer's model roughly corresponds to the single-chunk focus of McElree's model. The function of the focus of attention is to select a single item or chunk from the direct-access region."}, {"heading": "1.2 The mental action sequence", "text": "In classical tasks used to study working memory capacity [25], a subject is asked to hold in mind a short sequence of digits and to perform some simple process on each of these digits (or on a subset), for example adding the number two to each digit. Consider, for instance, the following task:\n\u201cAdd the number two to each of the following digits: 6 3 9 4\u201d\nWe assume that the subject has memorized additions with small numbers in long-term memory, so that the cognitive load for a single addition is small. According to the most accredited working-memory models, the sequence of mental operations that are performed by the subject is the following:\n1) transfer the 4 digits 6 3 9 4 to the phonological store; 2) transfer the first digit (6) to the focus of attention; 3) use this digit as a cue to retrieve the appropriate operation from the LTM; for instance, the following sentence can be retrieved from the LTM and transferred to the phonological store: \"six plus two equal eight\";\n4) transfer the result (\u201ceight\u201d) to the focus of attention, and use it for speech production; 5) transfer again the four digits 6 3 9 4 to the phonological store; 6) transfer the second digit (3) to the focus of attention ..... and so on, until the last digit. Additionally, several studies [26,27] suggest that the task goal should be stored in the working memory in some directly accessible form. Therefore, the previous sequence should be extended by including at the beginning, before step 1, two other operations, such as:\na) transfer the phrase \"add the number two\" to the phonological store; b) transfer this phrase to a goal-task store. There are different perspectives on how the components of the working memory are organized, how the information is coded in short-term and long-term memory, etc. however most researchers agree that the operations a-b and 1-6 are actually performed in the brain. In the next section we will illustrate how this \"mental action sequence\" is used by our system. In the following sections, we will also demonstrate that a broad range of tasks in human language elaboration can be performed using iterations of this basic action sequence. A minimal system that can perform this sequence should include (at least) the following components:\n- a phonological store with a mechanism to produce a phonological loop;\n- a focus of attention; - a retrieval structure that uses the focus of attention as a cue to retrieve information from the LTM; - a goal store (i.e. a goal stack in our model, as in many other cognitive architectures); - a supervising system that controls the flow of information among the other components, i.e. a\ncentral executive.\nAt this point, one may wonder why a neural architecture is necessary to model this process. Apart from the obvious consideration that our brain is a neural architecture, why a symbolic model is not enough? What we try to emphasize in our work is that the decision processes operated by the central executive are not rule-based process, they are statistical decision processes. The central executive is a neural network that takes as input the signal from the STM components (the internal state) and provides as output mental actions that direct the flow of information among the slave systems. Therefore, the central executive should comprise a state-action association system. If the central executive was not a statistical tool, the system would not be able to generalize. But how might the generalization arise? Suppose that an artificial model of the working memory was trained to respond to the \"add the number two\" task described above, and that it is tested on a similar task, but with different numbers:\n\"add the number three to each of the following digits: 7 8 2 5\"\nSince this sentence is similar to that of the first task, the central executive will provide the same\noutput, i.e. the same mental-action sequence.\nThrough this sequence, the system will extract the phrase \"add the number three\" and push it in the goal stack, then it will transfer the sequence \"7 8 2 5\" to the phonological store, it will transfer the first number (\u201c7\u201d) to the focus of attention and use it as a cue to retrieve information from LTM. Now we come to other two questions:\n\u2022 why the retrieval process should be modeled using a neural architecture, or more generally why\nthe retrieval process should be described as a statistical process?\n\u2022 What is a \"comparison structure\" and how does it support the generalization process?\nIn principle there could be thousands of phrases that could be retrieved from the long-term memory using the digit \"7\" as a cue. How can the system choose the appropriate phrase among them? The system can recognize that some of the phrases that can be retrieved from the long term memory using the digit \u201c7\u201d as a cue are similar to the one retrieved during the training stage, which was:\n\"six plus two equal eight\" (phrase 1)\nFor instance\n\"seven plus two equal nine\" (phrase 2), or \"seven plus three equal ten\" (phrase 3)\ncontain the cue (\u201c7\u201d) and are similar to phrase 1, in the sense that both phrase 2 and phrase 3 are\nclose to phrase 1 in the input space of the state-action association system.\nUnfortunately, phrase 2 is closer. Without a comparison structure, the system would choose phrase 2, and following the same action sequence of the training example, it would give a wrong answer, i.e. \u201cnine\u201d instead of \u201cten\u201d. A comparison structure is a component of the STM that recognizes similarities among elements of the other STM components. For instance, it can recognize that one word in the phonological store is equal to a word of the phrase stored in the goal stack. In our example, the comparison structure allows the system to recognize that the third word of phrase 2 (\"three\") is equal to the fourth word in the goal phrase \"add the number three\". In a simple neural model of the comparison structure, the neuron that compares those two words will be activated. Our model includes a comparison structure, which is part of the input to the state-action association system of the central executive. We will show that the connections from the comparison structure to the central executive are weighted more than the connections from the phonological loop to the central executive, therefore in the above example the system will select phrase 3 rather than phrase 2, and it will give the correct answer."}, {"heading": "1.3 Localization of the verbal working memory in the brain", "text": "Localization of brain areas that are involved in language comprehension and production requires the combination of findings from neuroimaging and psycholinguistic research. Several studies on the functional neuroanatomy of language indicate that both semantic and syntactic processes involve mainly the left frontal cortex and part of the temporal cortex. The left frontal cortex is considered to be responsible for strategic and executive aspects of language processing. The left temporal cortex supports the processes that identify phonetic and lexical elements. It is involved in storage and retrieval of phonological, syntactic and semantic information form memory.\nAll classical neurobiological models of language attribute a fundamental role to the Broca's area, which includes Brodmann's areas (BA) 44 and 45, in the left frontal cortex. Several studies show that\nBA 47 and the ventral part of BA 6 are also involved in language processing tasks [28-30]. The language-relevant part of the frontal cortex is thus the left inferior frontal gyrus (LIFG) which comprises BA 44, 45, 47 and 6. Results from neuroimaging and psycholinguistic studies show that LIFG is involved in the unification operations required for binding individual words into larger structures [31,32]. Hagoort [31] proposes a model that distinguishes three functional components of language processing: memory, unification and control. Figure 2 shows the main areas of the cortex that support the three components."}, {"heading": "2 The ANNABELL model", "text": "The model presented in this work, called ANNABELL (Artificial Neural Network with Adaptive Behavior Exploited for Language Learning), is a cognitive neural architecture, designed to help understand the cognitive processes involved in early language development. This section provides an overview of the system architecture and operating modes. See the Supporting Information document The ANNABELL system architecture (available at http://www.neuralsystems.net/annabell/files) for a\ndetailed description of the architecture. The source code of the software, the User Guide and the datasets used for its validation are available in the ANNABELL web site at https://github.com/golosio/annabell/wiki).\nThe global organization of the system is substantially based on Baddeley's working memory model. The building blocks are artificial neurons. The system is based on the concept of sparse-signal map (SSM). A SSM is simply an ANN that has only a small fraction of all neurons active at a given time. The advantage of this representation is that it can be implemented in a very efficient way both in terms of computation time and in terms of memory usage, therefore it can partially compensate for the relatively limited parallelism of available hardware compared to the biological brain. The design of the neuron model focused on computational efficiency rather than biological details. It is important to point out that the purpose of this approach it not an engineering solution to the human-machine dialogue problem, but a cognitive model of how verbal information is processed in the brain. Computational efficiency is necessary for building a large scale-neural model of the verbal working memory, able to sustain a long training procedure on a relatively large dataset.\nThe system is composed by several SSMs, connected to each other either by fixed-weight or by variable-weight (learnable) connections. The latter ones are updated through a discrete version of the Hebbian learning rule. Most of the learnable connections are virtual: they are not actually allocated in memory, unless their default weight value is modified by the Hebbian mechanism. As the signal is sparse, only a small fraction of the neurons is active at a given time, therefore most learnable connections remain virtual. The advantage of this approach is that memory requirements and, most importantly, computational time are greatly reduced compared to conventional techniques. The proposed system is faster by at least three orders of magnitude compared to other large-scale neural systems.\nThe communication between the system and the human interlocutor is achieved through an interface that converts words into input patterns, submits them one by one to the system, extracts output patterns and converts them to words. The network architecture is designed in such a way that the system can elaborate phrases using mental actions, which are elementary operations on word groups and phrases that are used, for instance, for acquiring the words of the input phrases, for memorizing phrases, for extracting word groups from the working phrase, for retrieving memorized phrases from word groups through an association mechanism, etc. Such actions are performed by special neurons, called mental\naction neurons, which can control the flow of signal between different subnetworks. A key feature of the model is that the connections that are affected by the reward mechanism are connected to mental action neurons, rather than being directly connected to output words or phrases. In this way, the system learns preferentially to build the output through sequences of elementary operations on word groups or phrases. This type of architecture underpins the abstraction capabilities of the system, and makes it able to use the natural language as a tool for reasoning.\nThe system was implemented on a PC equipped with a high-performance GPU (graphics processing unit) NVIDIA Kepler GK104 having 1536 processing units (called cores). GPUs are programmable logic chips that are widely used not only for graphical applications, but more generally for highperformance-computing applications that require a high degree of parallelism. The current version of the system is composed by 2.1 million neurons, interconnected through 33 billion virtual connections. At the end of the complete learning process described in this work, the number of real (allocated) connections was 27 million. The size of the system is comparable to that of the neural architecture described in Ref. [8], although our model privileges computational efficiency over biological details. The ability to perform real time communication and the large scale of the network make our system adequate for sustaining a long developmental process (this property is called open-ended, cumulative learning in developmental robotics [33] ). The system is being trained through an approach that, compared to those used for other artificial systems, is much more similar to children language training. This process is conducted by personifying the system as a child in a virtual social environment. The validation of its performance is inspired by the literature on early language assessment. Test sessions are used to assess syntax, semantics, pragmatic language skills, communicative interactions, language processing skills and comprehension of sentence structure. The basic idea that lies behind this approach is that as cognitive architectures becomes more and more close to humans, they should be evaluated using criteria similar to those used for the humans themselves, rather than metrics that have been developed to evaluate the performance of artificial systems in solving specific tasks."}, {"heading": "2.1 Learning mechanisms and signal flow control", "text": "The ANNABELL system is entirely composed of interconnected artificial neurons, and all processes are achieved at the neural level. Although different subsystems can be distinguished by their function,\nthe whole system has a unitary structure. The subnetworks are arranged in layers that determine the update order, with both forward and backward connections among different layers.\nThe system uses a standard artificial neuron model. The neurons are connected among each other by\ndirectional weighted connections (links). Three types of connections are used:\n\u2022 fixed-weight connections, which do not change during the learning process;\n\u2022 variable-weight (learnable) connections, which are modified by the learning process;\n\u2022 forcing connections, which are variable-weight connections that have a positive or negative\nweight much higher in absolute value than that of the other two connection types, thus they can force the target neurons to a high-level or to a low-level state.\nThe total input signal of each neuron is evaluated as the weighted sum of the signals coming from its\ninput connections:\ny i=\u2211 j\u2208 Si w ijo j+bi\nwhere i is the neuron index, yi is its total input signal, Si is the set of neurons that are connected to the other ends of its input connections, j is an index that runs on the set Si, wij are the weights of the input connections, oj are the output signals of the neurons connected to its input, and bi is a bias signal. The neuron output is computed from the total input by a nonlinear activation function [34]:\noi=f ( y i )\nwhich approaches zero as yi tends to minus infinity, or one as yi tends to plus infinity. Two types of activation functions are used in the model, i.e. the Heaviside step function for the neurons that receive their input from fixed-weight connections, and the logistic function [34] for the neurons that receive it from variable-weight connections.\nIn the subnetworks that have learnable input connections, the inhibitory competition among neurons is modeled using the k-winner-take-all rule, i.e. the k neurons with the highest activation state are switched on, while all the remaining neurons are left off. This rule provides a computationally effective approximation of the activation dynamics produced by inhibitory interneurons [35]. The Hebbian theory provides a theoretical basis for the learning mechanisms in biological neural networks [36,37]. According to this theory, the strength of the synaptic junction between two neurons is increased when the outputs of the two neurons are strongly correlated, i.e. when the two neurons fire together. In our model, the learnable connections are modified through a discrete version of the Hebbian learning rule\n(DHL rule), combined with the k-winner-take-all rule: the connection weight is modified only if the postsynaptic neuron is one of the k winners of the k-winner-take-all competition; if the presynaptic neuron at the other end of the connection is in the same activation state as the winner neuron (i.e. in the high level state \u201con\u201d) the connection weight is saturated to its maximum value. In the opposite case, it is saturated to its minimum value. A detailed description of the learning algorithms and of the statistical properties of the state-action association system is provided in Appendix D.\nThe elementary operation of the system on word groups, phrase buffers and other SSMs, called mental actions, are triggered by special neurons that will be called action neurons. Each action neuron can activate one or more gatekeeper neurons, which control the flow of signal between different subnetworks. Neural gating mechanisms play an important role in the cortex and in other regions of the brain [38]. They rely on the action of bistable neurons, i.e. neurons that can oscillate between a quiescent \u201cdown\u201d state, associated with a hyperpolarized membrane potential, and an \u201cup state\u201d, characterized by a membrane potential that is just below the cell's firing threshold. The gatekeeper neurons can modulate the membrane potential of the bistable neurons, shifting them from the \u201cdown\u201d state to the \u201cup\u201d state and vice versa. Different types of neural gating mechanisms have been observed in the brain.\nFigure 3 represents the type of gating mechanism that is exploited in our model. In this example, a gatekeeper neuron is fully connected to a set of bistable neurons. When the gating signal is OFF, the\ngate is closed: the bistable neurons are in the \u201cdown\u201d state, and they do not respond to the input signal. Conversely, when the gating signal is ON the gate is open: the bistable neurons are in the \u201cup\u201d state and they transmit the input signal to the second set of neurons. The bistable neurons therefore perform a type of biological AND relative to their inputs.\nIn the ANNABELL model, the gatekeeper neurons are generally fully connected to one or more SSMs, and they can enhance or suppress the activation state of the SSM neurons, acting in a similar way to a change in the bias signal. In this manner they can control the flow of signal from one part of the system to another. The mental action neurons and the gatekeeper neurons are based on the same simple neuron model used for all neurons of the system. Their specialization is only a result of the way how they are connected to other subnetworks. In particular, the action neurons receive the input signal from the state-action association subnetwork, and they send their output signal to the gatekeeper neurons.\nThe input and the output connections of the state-action association network follow a distributed model, i.e. the state-action association network is fully connected to the subnetworks that represent the internal state of the system (input) and to the action neurons (output). The input and output connections of the state-action association SSM are updated through the DHL rule. On the other hand, the connections between the action neurons and the gatekeeper neurons have fixed, predetermined weights, in such a way that each action neuron corresponds to a well-defined operation. The output connections of the gatekeeper neurons are generally fully connected to one or more subnetworks, in such a way that they can allow or inhibit the flow of signal through such subnetworks. A key feature of the ANNABELL system that is particularly important for his abstraction capabilities is that the learnable connections that are affected by the reward (i.e. the connections of the state-action association SSM) are connected to action neurons, rather than being directly connected to output words or phrases. In this way, the system learns preferentially to build the output through sequences of elementary operations on word groups or phrases."}, {"heading": "2.2 Global organization of the model", "text": "The global organization of our model combines Baddeley's model of the working memory [20-22] with ideas from Cowan's [23] and from Oberauer's [25] models. The ANNABELL model comprises four main components, as shown in Fig. 4: a verbal short-term memory (STM), a verbal long-term memory (LTM), a central executive (CE) and a reward structure.\nThe STM includes a phonological loop, a focus of attention, a goal stack and a comparison structure. The phonological loop stores the working phrase and supports an inner voice and an inner ear processes. The focus of attention holds up to about four words, and is used to perform mental operations on the working phrase or as a cue for retrieving information from LTM. The goal stack is a structure for storing goal chunks that contribute to decision-making processes. The comparison structure recognizes similarities among words in the phonological loop, in the focus of attention and in the goal stack, and is also used for decision-making processes. The LTM includes a structure for memorizing phrases and a retrieval structure that uses the focus of attention as a cue for retrieving\nmemorized phrases. The CE is a supervisory system that controls all decision-dependent processes through neural gating mechanisms. It includes a state-action association system, a set of action neurons and a set of gatekeeper neurons. The state-action association system is a structure that is trained by a rewarding procedure to associates mental actions to the internal states of the system. The gatekeeper neurons are neurons that can control the flow of signal between different subnetworks by acting in a similar way as an increase or a decrease of the bias signal. The mental-action neurons are used to perform elementary operations on phrases, as increasing the phrase index, extracting a single word from the working-phrase buffer and mapping it to the word-group buffer, retrieving a memorized phrase from a word group, storing the working phrase in the goal stack, etc. Each (mental) action neuron corresponds to a well-defined action, which can be executed by activating the state of one or more gatekeeper neurons. The system can perform three types of actions.\n1. Acquisition actions. Those actions are used during the acquisition and during the association\nphases, for acquiring the input phrases, memorizing them and building the associations between word groups and memorized phrases. 2. Elaboration actions. Those actions are used during the exploration and during the exploitation\nphases, for extracting word groups from the working phrase, for retrieving memorized phrases from word groups through the association mechanism, for retrieving memorized phrases belonging to the same context, for composing output phrases. 3. Reward actions. Those actions are used by the rewarding system and can be executed in parallel\nto the elaboration actions. They are used for memorizing the state-action sequences produced during the exploration and during the exploitation phases, for retrieving such sequences after a reward signal and for triggering the changes of the state-action-association connection weights.\nA complete list of the actions is presented in the Supporting Information document The ANNABELL\nsystem architecture.\nThe reward structure memorizes and retrieves the sequences of internal states of the system and the mental actions performed by the system (state-action sequences). When an exploration phase produces a target output, the reward structure retrieves the state-action sequence and rewards the association between each internal state and the corresponding mental action, by triggering synaptic changes of the state-action association output connections.\n2. During the association phase the input phrase is copied to the working-phrase buffer. The whole phrase is mapped into the memorized-phrase buffer, and it is memorized through a discrete version of the Hebbian learning rule. Groups of contiguous words are thus extracted from the working-phrase buffer and copied to the word-group buffer. The association between each word-group and the phrase is memorized by changing the weights of the input and output connections of the \u201cretrieval structure\u201d subnetwork. During the exploration and exploitation phases word groups are extracted from the working phrase buffer, and used as cues to retrieve memorized phrases. When the working phrase represents a task that cannot be immediately performed by the system, it can be copied to a goal-stack, where it is stored until the task is carried out. The equal-word vectors are subnetworks that indicate the presence of words in the working phrase buffer that are equal to words in the word-group buffer or in the goal-word-group buffer. They are an important part of the input of the stateaction-association subnetwork.\nThe ANNABELL system is composed of several subnetworks. Figure 5 represents a schematic diagram of the main subnetworks in the STM and in the LTM. Each rectangular block in this diagram represents a subnetwork composed by interconnected artificial neurons. A detailed description of the system architecture is provided in the Supporting Information document The ANNABELL system architecture.\nThe human-agent communication is achieved through an user interface between the human interlocutor and the system. The interface converts words into input patterns and submits them one by one to the system, extracts output patterns and convert them to words. It also sends reward signals to the system when prompted by the human. The interface includes a monitor tool that can be used to display the content of the SSMs that compose the system.\nThe system can work in five operating modes, which are briefly described below.\n1 Acquisition. In this operating mode, the words of a phrase are acquired one by one and stored\nin the input-phrase buffer.\n2 Association. In this operating mode, the input phrase is copied from the input-phrase buffer to\nthe working-phrase buffer and it is stored in a long term memory (represented by the block Memorized Phrases in Fig. 5). After that, all possible groups of contiguous words (with maximum four words in a group) are extracted from the working phrase and copied to the wordgroup buffer, and the association between the word group and the whole phrase is memorized in the long term memory (the block retrieval structure in Fig. 5). 3 Exploration. In this mode the system executes partially random sequences of elementary\noperations (mental actions) on word groups and phrase buffers. The basic action sequence used during the exploration operating mode is the following:\n\u2022 W_FROM_WK: initializes the phrase index (PhI) to zero, to prepare the extraction of\nwords from the working-phrase buffer;\n\u2022 NEXT_W (N1 times): skips N1 words of the working phrase buffer; \u2022 FLUSH_WG: clears the content of the word-group buffer; \u2022 GET_W, NEXT_W (N2 times): copies N2 consecutive words from the working phrase\nbuffer to the word-group buffer;\n\u2022 WG_OUT (0/1 times): copies the word-group buffer content to the output buffer;\n\u2022 RETR_AS: retrieves a phrase associated to the word group by the association\nmechanism.\nN1 and N2 are random integer numbers. N1 can eventually be null, while N2 must be greater than or equal to one. The range of N1 and N2 depends on the maximum phrase size (ten words in the current implementation). Additionally, the system can eventually execute the following actions:\n\u2022 GET_START_PH: retrieves the starting phrase in the same context of the working\nphrase;\n\u2022 GET_NEXT_PH: retrieves sequentially phrases belonging to the same context;\nThe human interlocutor can suggest to the system a target phrase or a target word group. The exploration process is terminated when it produces the target phrase / target word group, or when the number of iterations becomes greater than a predefined limit. When the working phrase indicates a task that cannot be executed immediately, it can be set as a goal by inserting it in a SSM that acts as a goal stack with the action PUSH_GOAL. When the goal is reached, the phrase can be removed from the stack with the action DROP_GOAL. 4. Exploitation. In this operating mode the state-action association SSM, trained by the rewarding\nprocedure, is used to associate a mental action to each system state. The state-action-association SSM is updated through the k-winner-take-all rule. It receives as input the internal state of the system (represented by a dashed rectangle in Fig. 5), and it sends its output to the elaborationactions SSM, which is updated through the (one) winner-take-all rule. In this way a single elaboration action is selected, the one that is more represented among the outputs of the k winners of the state-action-association SSM. 5. Reward. When the exploration process produces a phrase or a word group that the teacher\nrecognizes as worth to be rewarded (target phrase or target word group) he can activate a rewarding procedure. In this operating mode the system retrieves the state-action sequence that led to the target phrase / target word group. The association between each state of the sequence and each corresponding action is rewarded by changing the connection weights of the stateaction association SSM through the DHL rule.\nAppendix C describes in details, on a concrete example, how the neural activation patterns evolve, how the connection weights are modified during training, and how these weight changes make the system able to generalize the acquired knowledge to new sentences."}, {"heading": "3 The database", "text": "The database of sentences used for training and testing the system is organized in five datasets, each devoted to a thematic group, i.e. people, parts of the body, categorization, communicative interactions and movement in a text-based virtual environment. Each of those datasets includes declarative sentences, conversational sentences and interrogative sentences. Declarative sentences are used to give some information to the system without expecting a response. As the system has no sensory input, apart from that provided by the text-based interface, all the information must be provided in the form of input sentences. Interrogative sentences are questions that expect an answer from the system. In the training stage, for each question the teacher suggests the associations that can be used to build a valid answer. In the test stages, the questions are used to verify whether the system is able to generalize what it learned during the training phase. An answer is considered to be correct only if it is both syntactically and semantically correct.\nConversational sentences that expect a turn taking from the system are treated in the same way as\nthe questions: for this type of sentences, in the training stage the teacher suggests response sentences that are appropriate for the conversation. On the other hand, conversational sentences that do not expect a turn taking are treated as declarative sentences.\n3.1 The people dataset The first dataset is devoted to the subject people, and it is partially inspired by the Language Development Survey work of Rescorla et al. [39,40]. The sentences of this dataset have been prepared by personifying the system in a four years old little girl in her social environment, which includes the two parents, a sister, a friend, two cousins, the four grandparents, two aunts, two uncles and six other children, for a total number of twenty persons. Four of those persons, namely the two parents, the sister and the friend, are considered to have a closer relationship to the system, which means that the dataset provides more information for those four persons than for the others. In some cases, the two cousins are also included in the group of closer persons. Some sentences depend on the possible relationships between the persons and the system. In such case, we distinguish nine types of relationships, i.e. father, mother, sister, friend, cousin, grandmother, grandfather, aunt and uncle. The six other children are included in the social environment mainly for training and evaluating the system in age comparison\ntasks. Some declarative sentences (how-to sentences) are used to provide prescriptions on how to accomplish some specific tasks, as for instance\nto answer if someone is younger or older than you, you should compare your age with his age\nor to express language rules in a simple verbal form, as\nthe possessive pronoun for a woman is her . Table 1 shows the types of declarative sentences used in the people dataset. The total number of\ndeclarative sentences in this dataset is 225.\nThe questions used in the people dataset are also inspired by the work of Rescorla [39,40], and they\nare appropriate for a preschool child, as in the following examples:\nwhat does your father do? what games do you like? do you have a sister? is Dad older than Mum?\netc. A full list of the declarative sentences and of the questions can be found in the files that are distributed with the software package. They explore the meaning of words, but they are also used to train the system for language and reasoning skills, as:\n\u2212 use of personal and possessive pronouns;\n\u2212 answer to polar (yes/no) questions, alternative (choice) questions, wh-questions and question-\nlike imperative sentences (e.g. tell me);\n\u2212 counting and comparing numbers, as for instance in age comparison:\nis Letizia older or younger than your sister?\n\u2212 learning language rules:\nthe possessive pronoun for a female person is her\nThe following question/answer example illustrates some of the abilities acquired by the system:\nQ: is your friend younger than you? A: no, she is older. The system is able to answer to the question Q by following a line of reasoning that it has learned through the communication with the human, thanks to its adaptive behavior. The system uses the past experience listed below.\n1) The system has been taught to count; 2) The system has been taught to decide whether another child is younger or older than the girl that\nit impersonates, through the following phrases:\nto answer if someone is younger or older than you, you should compare your age with his age\n3) The system has learned the age of the girl that it impersonates:\nyou are four years old\n4) The system has learned that the words \u201cyour friend\u201d refer to the friend Letizia\nLetizia is your friend\n5) The system knows the age of Letizia:\nLetizia is five years old\n6) The system has learned how to use personal pronouns, therefore it can answer using the personal\npronoun she instead of the name Letizia.\nThe teacher taught the system to answer questions similar to the question Q, guiding it through a series of mental operations (associations and extractions of word groups from sentences), through the exploration-reward method described previously. At this point the system is able to generalize the procedure and to answer questions similar to those used for training.\nIt is important to emphasize that this whole process takes place in the system at a subsymbolic (neural) level and that phrase memorization and learning take place in the form of changes of the weights of the connections between neurons through the DHL rule. The examples shown in Appendix A show in more detail how the system is trained to answer to a question.\n3.2 The parts of the body dataset The second dataset is devoted to the main parts of the body, and it is also partially based on the words of this subject category included in the Language Development Survey. Through this dataset, the\nsystem is trained to recognize the definition of a word as well as different ways to specify the location of an object. After the training, the system should be able to answer questions of the type what is and where is. Table 2 represents the type of declarative sentences used in this dataset. Thirty-three body parts are considered. For each of them, a declarative sentence provides a simple definition in a form that should be understandable for a preschool child. Other sentences specify the locations of the body parts. It can be observed that in this case the correspondence between body parts and sentences is not one-to-one, because the location of a body part can be described in more than one way. Eight declarative sentences describe in simple terms what is the function of some body parts, e.g.\nwith your legs you can walk, run and jump\nand finally, six sentences are how-to sentences. The total number of declarative sentences in the\nbody parts datasets is 122.\nOnly five types of questions are used in this dataset, i.e.\nwhat is the <part>? what are the <part>s? where is the <part>? where are the <part>s? what can you do with your <part>(s)\nwhere <part> is the name of a body part."}, {"heading": "3.3 The categorization dataset", "text": "The third dataset is used for evaluating the categorization capabilities of the system. This dataset uses 62 different animal names from 6 categories: 13 mammals, 13 birds, 13 fishes, 8 reptiles, 4 amphibians, 11 insects. The animal name memberships to the six categories are specified by 62 declarative sentences of the form:\nthe <animal> is a <category>\nwhere <animal> is an animal name, and <category> is one of the six categories listed previously,\nas for instance:\nthe turtle is a reptile\nOther 6 sentences of the form:\n<category>s are animals\nand one how-to sentence are included to train the system to deal with categorization hierarchies. The\ndataset also includes 48 declarative sentences of the form:\nthe <animal> is <adjective>\nwhere <adjective> is one of the five adjectives: big, dangerous, domestic, fast or small. The total\nnumber of sentences in this dataset is 117.\nIn the training stage, the human teacher asks the system to tell him an animal belonging to one of the\ncategories, e.g.\ntell me a mammal\nthen he guides the system to a correct answer, as shown in detail in Appendix A, Sect. A.2. A single training example, involving one animal name from one category, is sufficient. After that, the system is\nable to answer correctly to the analogous question for all 6 categories. This test shows that the system is able to learn that the \u201cis a\u201d couple is used in sentences as \u201cthe dog is a mammal\u201d to state that a concept belongs to a category, and that the \u201ctell me a\u201d group in a question can be used for asking to retrieve a concept from a category. A more complex categorization task in the same dataset involves the ability to learn categorization hierarchies. In this case, the human asks the system two consecutive questions, as in the following example:\nQ: what is the turtle? A: it is an animal Q: what kind of animal? A: a reptile\nOther questions in this dataset are used to evaluate the capability of the system to combine information on categories and adjectives, as in the following example:\nQ: tell me a big reptile A: crocodile"}, {"heading": "3.4 The communicative interactions dataset", "text": "The fourth session is devoted to communicative interactions, and it is based on a mother/child dialogue extracted from the Warren-Leubecker corpus [41,42], which is part of the CHILDES database [43]. This corpus contains data from 20 children interacting with one of their parents.\nThe sessions took place in the child\u2019s home. The parent was instructed to bring the child into conversation and to talk to him as naturally as possible. This corpus appeared to be more appropriate than others for training the system, because the children ages were appropriate and because verbal communication was predominant over nonverbal communication, play and actions. The session used in this work is based on the file \u201cdavid.cha\u201d, which contains a transcription of the dialogue between a 5- years-and-10-months-old child and his mother.\nThe system was trained in a text-based virtual environment. First, we guessed what kind of past experiences of the child could be compatible with the David dialogue: one day a relative brought the child to an amusement park; the child played to a video game (Pacman). Another day, at the kindergarten, the teacher organized a costume party, where each child should dress as a character that represents a letter of the alphabet. At home, the mother helped the child to prepare his letterman dress.\nThose past experiences are described through a first set of 52 declarative sentences. Then we describe similar possible past experiences of the child impersonated by the system (a little girl, in our case): one day her father brought her, her sister and her cousin to the central park, were they played hide-and-seek and other games; another day, she was in Susan's room; aunt Carol told Susan to tidy up her room, therefore Susan started to put things inside her toy-box... Those experiences are described through another set of 44 declarative sentences, similar in syntax but different in the content from those of the first set. The training is based on this second set. Other 18 sentences in this dataset are how-to sentences. The human teacher guided the system into a conversation similar in syntax to the David dialogue, but related to a different past experience, and suggested either possible answers to the questions, or sentences appropriate for the conversation. In the test stage, the human interlocutor had a conversation with the ANNABELL system similar to that taken from the Warren-Leubecker corpus. Appendix B, Sect. B.2 shows a list of the informative sentences used to build the system experience in a virtual text-based environment. Sect. B.3 shows the sentences used to train the system."}, {"heading": "3.5 The virtual environment dataset", "text": "The fifth dataset represents a text-based virtual environment, where the system is trained to perform simple tasks by means of verbal commands. The training is made in a virtual house with 25 room, named room_0, \u2026, room_24, arranged in a 5\u00d75 square. A person is located in the central room, i.e. room_12, which is also the starting position of the system. Eight objects, named object_1, \u2026, object_8, are distributed randomly in the eight second-nearest-neighbor rooms, with the constraint that different objects should be located in different rooms. Each room has a description that specifies the accessible nearest neighbors and eventually the persons and/or objects that are present in it, as\nyou are in room_12\nto the east there is room_13\nto the north there is room_7\nto the west there is room_11\nto the south there is room_17\nJohn is here\nwhat do you want to do?\nBefore the training, the descriptions of all rooms are presented to the system. Each training example starts by presenting to the system the description of the starting room (room_12) and by asking it to accomplish the task of bringing an object to the person:\nbring an object_5 to John\nthen, the system is trained to issue the commands (north, south, east, west) to move to the room where the object is located. Each time the system moves to a room, it receives the description of that room. When it reaches the target room, it is trained to take the object\ntake the object_5\nto go back to the starting room, and to give the object to the person\ngive the object_5 to John\nThe test is made in the virtual house shown in Fig. 6. Before starting it, the descriptions of all rooms are presented to the system. All possible combinations of starting room and target room are used in the test, using for simplicity the constraint that starting room and target room are second nearest neighbors. The number of combinations for this house is 28. For each combination, the system and a person are located in the starting room, and an object (a book) is located in the target room. After the description of the starting room, the system is asked to bring the object to the person:\nbring a book to Alfred\nAs in the training stage, in order to perform this task, the system should issue the commands for reaching the target room, the command for taking the object, the commands for going back to the starting room, and the command for giving the object to the person."}, {"heading": "4 Results", "text": "The training procedure is organized in five incremental language training sessions, one for each dataset. Each session is divided in two stages. During the first stage, a set of declarative sentences from the corresponding dataset is presented to the system through the interface. As the system does not have any other sensory input, all the information must be provided to it in the form of verbal descriptions. In the subsequent training stage, the teacher trains the system by asking it a set of questions related to the previous sentences. During this stage, the system works in an exploration modality, which combines an association mechanism with partially-random operations on word groups and phrases. The teacher guides the system to retrieve useful associations, and instructs the interface to trigger a reward signal when the system yields a correct answer.\nThe evaluation of the system performance (test stage) is performed at the end of the five learning sessions, after the cumulative training on all five datasets. In this stage, the teacher evaluates the system by asking it a set of questions similar to the ones used during the training stages, and by testing the generalization capabilities of the system, i.e. its ability to elaborate the information provided by the memorized sentences, and to answer questions having a similar structure to those presented during the\ntraining stages but involving different nouns, adjectives or verbs. The teacher also validates the linguistic competences of the system in the use of articles, nouns, verbs, adjectives, personal pronouns, possessive pronouns and other word classes. The system output sentences were considered to be valid when they were syntactically and semantically correct and appropriate for the conversation. The test related to the virtual environment dataset evaluates whether the system is able to generalize the knowledge acquired in the training stage, being able to follow similar commands involving different target rooms, objects, people.\nTable 3 reports the number of declarative sentences, the number of interrogative sentences used for training, the number of interrogative sentences used for the test and the number of output sentences in the five datasets.\nFigure 7 shows how the the interrogative sentences of the first four datasets used in the training stages and those used in the test stages are distributed among the question categories. The virtual environment dataset was excluded from this statistic because in this case the interrogative sentence is always the same, i.e. it is the question \u201cwhat do you want to do?\u201d, which is used to ask the system what action it wants to perform.\nIn order to evaluate quantitatively the system performance, we used a four-rounds cross validation approach. The communicative interaction dataset was excluded, as it was not suitable for a cross validation. All the questions of the first three datasets were organized in groups, each group containing at least four interrogative sentences having similar structure. At each round, the training set was built by randomly extracting one or more questions from each group, with the constraint that the same question should not be used in different rounds. The remaining questions were used for the test. The order of the questions used for training and that of the questions used for the test were both randomized.\nConcerning the virtual environment dataset, the four rounds of the cross validation used different starting seeds for extracting randomly the position of the target rooms used in the training stage. The test was always made in the virtual house shown in Fig. 6, on all possible combinations of starting room and target room.\nFor each round of the cross validation, the system was first trained on all five datasets before testing it. In this way we could test the capabilities of the system to store all the information of the five datasets and to acquire new information without altering the past one.\nIn a single round of the cross validation, the system was trained and evaluated using 1587 input sentences, containing 595 different words, with an average number of 5.6 words per sentence. It produced 521 output sentences, containing 312 different words (expressive vocabulary), with an average number of 4.6 words per sentence. Figure 8 shows the distribution of the number of tokens\n(words) in the input sentences (a) and in the output sentences (b), the distribution of different tokens among word classes (c,d), and the percentage of word classes in the input and output sentences (e,f).\nTable 4 reports the number of correct answers for the first three datasets and for the four rounds of the cross validation. Table 5 reports the number of tasks that were performed correctly by the system on the virtual environment dataset for the four rounds of the cross validation as a function of the number of training examples.\nThe percentage of correct output sentences over the total number of requested output sentences, averaged over the four rounds of the cross validation, was 82.4% for the people dataset, 85.3% for the parts of the body dataset, and 95.3% for the categorization dataset. The communicative interaction dataset is excluded here because it is not suitable for this type of quantitative evaluation. The average percentage of tasks that were performed correctly by the system in the virtual environment over the total number of assigned tasks varies from 83.0% to 100% depending on the number of training examples used in the training stage, as shown in Table 5.\nIn the test related to the communicative interaction dataset, the human interlocutor brought out the system in a conversation similar to the one transcribed in the corpus. Figure 9 shows an extract of a side-by-side comparison between the human/ANNABELL-system conversation on one side and child/parent interaction on the other side. The complete comparison is reported in Appendix B, which also reports the sentences used for the training.\nFigure 10 shows the distributions of the number of tokens in the output sentences of our system and in the child utterances, from the session based on the Warren-Leubecker corpus. The total number of tokens used by the child was 134, while those used by the system in this session were 111. The total numbers of different token types were 86 and 75, respectively. The type/token ratios are close to each\nother, being 0.64 for the child, and 0.68 for our system (this analysis was performed using the CLAN program [43] ).\nFigure 11(a) shows how the average time that the system needs to answer to a question varies with the number of allocated input connections in the state-action association subnetwork. At the end of the whole training process, performed on all five datasets, the average time for an answer, evaluated on a system equipped with a high-performance GPU (graphics processing unit) NVIDIA Kepler GK104 having 1536 cores, is 9.5 seconds.\nFigure 11(b) shows how the number of allocated connections of the state-action-association subnetwork varies according to the number of input sentences. This plot was produced using an extended artificial database, which was obtained from the three datasets people, parts of the body and categorization, by replicating them several times and replacing the open-class words with randomly generated words. The ratio between the number of declarative sentences and the number of interrogative sentences used for the training was kept constant and equal to about 10. In other words, we assumed that about one sentence every ten memorized sentences is used for training and receives a reward. It can be observed that the number of allocated connections increases linearly with the number of sentences. On the other hand, they are nearly independent of the number of words that the system learns. The number of sentences memorized by the system at the end of this process was 81600, while the memory usage was 14.5 GB. For comparison, we can consider that one year of children-languagelearning data corresponds roughly to one million sentences. The latter number is greater by a factor of about ten compared to the number of sentences that can be processed by our system on a 16-GB-RAM PC. In order to process such a large amount of data, our model should be implemented in a high performance-computing (HPC) cluster, unless a more efficient solution to the memorization problem is found. It should be considered that our model is not a technical solution to the problem of humanmachine dialogue. Rather, it is a working neural model designed to help understanding how language is processed in the brain, and it is always worth remembering that there are several hundred trillion connections in the human brain."}, {"heading": "5 Evaluation of the system components and free-parameters", "text": "optimization The STM of the ANNABELL model is organized into different components, as described in Sect. 2. All these components are connected to the central executive, which uses their neural activation\nstates for the decision processes that associate mental actions to the internal states of the system.\nIn this section we discuss the relative importance of each component for this decision process, and\nthe effect of their complete removal from the system.\nTable 6 shows how the system performance is affected by a removal of the connections from the STM components to the central executive, and how it is affected by a complete removal of each of\nthese components from the system. The percentage of correct answers is averaged over the three datasets people, parts of the body and categorization, and over the four rounds of the cross validation. The contents of the STM components are not independent of each other: there is a redundancy in the information that they provide. Therefore, the removal of the connections from a single component to the central executive does not compromise the system functionality completely. The previous-phrases structure and the comparison structure are only used to provide an input to the state-action association system, so their complete removal has the same effect as the removal of their connections to the central executive. It may be noted that this removal produces a decrease in the percentage of correct answers. If the goal structure is completely removed from the system, the processes of insertion and extraction of the phrases in the goal stack will have no effect. The system can still work but since it has lost an important feature, its performance will decrease substantially, as can be observed in Table 6.\nThe other components of the STM are essential to the functionality of the system, as described in\nSect. 2. The system can not work properly if they are completely removed.\nFigures 12(a) and 12(b) show the percentage of correct answers as a function of the parameter Wmax of the DHL rule, used to update the connections from the STM components to the central executive. Wmax is the weight-saturation value. A null value of Wmax has the same effect as a removal of the connections from a STM component to the central executive. A variation of Wmax produces a change in the relative weight of the component in the decision process operated by the central executive, as will\nbeen shown in Appendix D. With the exception of the comparison structure, it can be observed from\nFigs. 12(a) and 12(b) that all plots have a maximum in the range 0.5\u2a7dW max\u2a7d3 , and that the variations of the system performance are relatively small in this range. On the other hand, the plot for the comparison structure has a maximum for Wmax=5. In this work we have used the same value (Wmax=1) for all STM components, except for the comparison structure, for which we used the optimal value.\nFigure 12(c) represents the percentage of correct answers as a function of the parameter k used for the k-winner-take-all rule in the state-action-association system. It can be observed that this percentage does not change with the value of k. This is related to the fact that the system uses a discrete version of the Hebbian learning rule. The value of Wmax for the comparison structure and the value of k are the only two free parameters used in our model."}, {"heading": "6 Generalization", "text": "The global organization of the ANNABELL model is compatible with current knowledge from neurological and psychological observations. Our study is focused on the children age range between about 3 to 5 years, which is a crucial range for the acquisition of linguistic competencies, and therefore is considered particularly interesting for studies on language development. The sentences in the databases described in Sect. 3 have been chosen according to the purpose of this work, based on the literature on early language assessment [39-43]. For such reason, the grammatical structure of the sentences in the datasets described in Sect. 3 is relatively simple. Nevertheless, it is important to evaluate the generalization abilities of the system on a larger dataset and on more complex grammatical constructions. We can distinguish two types of generalization [44]:\n1) handling learned grammatical constructions with new open-class words; 2) compositional generalization, i.e. generalize knowledge to new constructions that were not used\nin the training corpus.\nIn the following paragraphs, we evaluate the system performance in two experiments related to these\ntwo types of generalization."}, {"heading": "6.1 Generalization 1", "text": "For this experiment, we built an extended database by replacing the open-class words of the three\ndatasets people, parts of the body and categorization, with new, randomly generated words.\nThe declarative sentences of this database were produced by using the constructions shown in table 1 for the people dataset, the constructions of table 2 for the parts-of-the-body dataset and the sentences described in Sect. 3.3 for the categorization dataset; the open-class words within the angle brackets of those constructions have been replaced by randomly generated words, i.e. random alphabetical strings. The open-class words in the interrogative sentences used for the test were modified accordingly. By iterating this procedure, we generated a database of 5352 declarative sentences and 4028 interrogative sentences. This database was used as an independent test set for testing the four instances of the system that were trained on the original database during the four rounds of the cross-validation, respectively.\nTable 7 shows the number of correct answers produced by the four instances of the system over the number of interrogative sentences for the three extended datasets people, parts of the body and categorization. The results demonstrate that the system is able to generalize the acquired knowledge to learned construction with different open-class words."}, {"heading": "6.2 Generalization 2", "text": "The compositional generalization capacity of the system was evaluated through an experiment of\nsentence-to-meaning mapping, based on a task that was developed by Caplan et al. [45].\nIn the Caplan task, an aphasic subject listens to sentences and then he is required to indicate the meaning by pointing to images depicting the agent, object and recipient, always in that canonical order.\nIn formal terms, the input is the sequence of words in the sentence, and the output is the sequence agent, object, and recipient, corresponding to a standardized representation of the meaning in terms of thematic role assignment.\nIn our implementation, the surface form of the input sentences is presented word-by-word to the system, which is trained to assign the the thematic roles (predicate, agent, object, recipient) of the openclass words. For this experiment we used a dataset of 462 distinct grammatical constructions developed by Hinaut and Dominey [46], who used a context free grammar to generate systematically distinct grammatical constructions, each consisting of between 1 and 6 nouns, with 1 to 2 levels of hierarchical structure (i.e. with only a main clause or a main and relative clause, respectively). Each grammatical construction of this dataset has a surface form and a coded meaning. The surface form is composed by the word-groups shown in table 8.\nOur model operates in two stages: 1) grouping: the system is trained (on the training set) to split the input sentence in word groups, according to table 8, and to send each word group to the output. In case of ambiguities, the system is trained to use the largest groups. After the whole sentence is split, the output phrases are fed back to the system as new input phrases.\n2) thematic role assignment. The architecture of our model does not include a structure where the open-class words can be explicitly mapped to their thematic role. In order to perform this task without modifying the system architecture, our approach was to explicitly ask the system for the thematic roles:\n? predicate ? agent ? object ? recipient ? relative-clause predicate\n? relative-clause agent ? relative-clause object This approach is more close to the Caplan-task protocol. It should also be noted that our model, in contrast to other approaches to the same problem, does not require a prior specification of the distinction between open-class and closed-class words.\nFollowing the same approach of Ref. [46], the compositional generalization capacity of our model was tested in a ten-fold cross-validation. The dataset was divided in ten partitions (eight partitions with 46 sentences, and two with 47 sentences). In each round of the cross-validation, the system was trained on nine partitions and tested with the one not used for training. This procedure was performed ten times, so that all partitions were used for the test. Table 9 reports the results of the cross validation. Meaning error is the percentage of incorrect thematic role assignment. Sentence error is the percentage of sentences in which there is at least one wrong thematic role assignment. As illustrated in the table, the cross validation yielded 9.2% average meaning error and 36.7% average sentence error rates. The model proposed by Hinaut and Dominey achieved 9.2% average meaning error and 24.4% average sentence error rates through a ten-fold cross validation on the same corpus. This means that the number of errors in thematic role assignment is the same, however in their work the assignment errors are concentrated in a smaller number of sentences. It should be considered that while that work is focused on the problem of thematic role assignment, our model is not optimized for this specific task, because it addresses a wider range of aspects of human language elaboration."}, {"heading": "7 Discussion", "text": "Several examples in the test show that the ANNABELL system expresses a broad range of capabilities compared with other cognitive neural systems. For instance, let us consider the agecomparison example, described in Sect. 3, or the question \"How many games did you play?\" in Appendix B from the CHILDES database. The answers to such questions involve a process quite more complex than simple information retrieval from LTM and rearrangement of input and retrieved sentences. In the first example\nQ: is your friend younger than you? A: no, she is older. the system learns to answer to this question by following a line of reasoning that involves counting skills, ability to compare small numbers, ability to associate the words \"your friend\" to a known person (Letizia), ability to retrieve information about her age from the LTM, ability to use personal pronouns. The system is able to learn how to answer to this question through a rewarding procedure, and to generalize the acquired knowledge to similar questions involving different people with different ages. Importantly, our system does not include a specialized structure for counting, or a specialized structure for number comparison, or a specialized structure for mapping names into personal pronouns.... All its abilities arise from a relatively small set of mental actions, that allow it to extract a word-group from the phrase stored in the phonological loop, to use this word-group as a cue for retrieving other phrases from the long-term memory, to insert and retrieve phrases from a goal stack.\nIn the second example: *TEA: how many games did you play ? *SYS: I played : *SYS: Space_Invaders, one ; *SYS: Pac_Man, two ; *SYS: Donkey_Kong, three ; *SYS: three games . the system is able to retrieve the three games from the LTM and to count them. It is important to point out that the system performs such tasks through sequences of mental operations that are\ncompatible with psychological findings. The components of the system that give it these abilities (i.e. central executive, phonological loop, focus of attention, retrieval structure, goal stack) exist in the brain, according to widely accepted working-memory models. Even though our neural model is extremely simplified (compared to biologically realistic neural models), it can help to understand the link between neural activity and large-scale organization described by theoretical models. Previous neural models of language lack a central executive, i.e. a supervisory system that controls the flow of information among the other subsystems. On the other hand, theoretical models of the working memory do not describe how, at a neural level, the central executive can control this flow of information. We propose that this can be done by neural gating mechanisms. This hypothesis is compatible with recent research, which demonstrates that neural gating mechanisms play a fundamental role in the flow of information in the cortex. We also provide a model of how the central executive can learn how to associate mental actions to the internal states of the system through a rewarding procedure.\nIn the past decades, many researchers emphasized the contrast between localist and distributed models. In our work, word representation is based a localist model. On the other hand, the central executive, which is the heart of our system, follows a distributed model, and our work emphasizes that the decision processes operated by this component are not based on pre-coded rules, but statistical. It is important to point out that word representation is not a central point of our work. The localist representation of words can be regarded as a simplification, mainly motivated by the need for computational efficiency. Conversely, the use of a sparse signal representation is a basic feature of our model. In principle, our model could be modified to use a distributed (but still sparse) representation of the words. The system would have a better ability to recognize similarities (semantical and/or phonetical) among words, at the expense of a much greater number of connections and thus a much larger computation time. This could be a subject for a future work.\nBeyond the debate on word representation, there are several points of novelty of our model\ncompared to previous cognitive models of language:\n\u2022 it is the first system entirely based on an artificial neural network that is able to sustain a dialog,\nexpressing a broad range of functionalities in human language elaboration.\n\u2022 It provides a working neural model for the process of \"inner though\" that occurs between\nlanguage acquisition and language production. This model is compatible with Baddeley's model\nof the verbal working memory, which is supported by a large number of findings from neuroimaging and psycholinguistic. \u2022 The most important novelty of our model, compared to previous neural models of language, is\nthat the system elaborates the information through mental actions, which are controlled by a central executive and are performed by neural gating mechanisms. \u2022 The database used to test our system is based on the work of Rescorla about early language\ndevelopment. The questions used to test the system performance are largely based on protocols that are used by psychologists to assess children language development.\nIn the context of human-computer interaction, human language understanding is often associated to the ability to translate a linguistic input into a standardized functional form. This type of understanding involves the capacity to recognize the thematic role of the open-class words in the surface form of sentences. Meaning in this case is interpreted as a mapping from the surface form to the functional form. Our model does not have a structure where this mapping is explicit, however its ability to identify thematic roles can be tested through a question-answer approach, as in the Caplan task that was discussed in section 6.2.\nThe previous notion of understanding is insufficient for the purpose of our work. Question answering and, more generally, communicative interactions involve a kind of procedural knowledge, which is used to elaborate the linguistic input and to produce the output. This type of understanding refers to the ability to perform the sequences of mental operations that are needed to respond to a verbal input. For instance, let us consider the input sentence \u201cTell me about your classmates\u201d. A response to this sentence requires understanding that the words \u201cyour classmates\u201d refer to a set of individuals, extracting from the long-term memory information about those individuals, selecting part of this information and elaborating it in a form useful for the output sentences. Our work is an attempt to develop a working cognitive model that helps to understand how this procedural knowledge arises in the brain from low level neural activity.\nMany researchers argued that a true understanding can not be achieved if language is not grounded in the agent's physical environment through actions and perceptions [47]. An active field of research is devoted to grounding open-class words to objects (visual elements, bodily sensations and other types of perceptions) and grounding sentences to scenes and actions. Morse et al. [48], Cangelosi and Schlesinger [49] highlighted the role of embodiment in early language development. Dominey and\nBoucher [50] argued that we learn to translate the surface form of language into a functional form through the integration of speech inputs and non-speech inputs. In Baddeley's working memory model, this integration occurs in the episodic buffer. A limit of the current version of our model is that language is not grounded. Language grounding would require the combination of our model with a visual system, or its embodiment in a larger system that integrates language with other forms of perceptions and actions."}, {"heading": "8 Conclusion", "text": "The results of the validation demonstrate that, compared to previous cognitive neural models of language cognition, the ANNABELL model is able to develop a much broader range of functionalities, starting from a tabula rasa condition, on a relatively large database. The ANNABELL system is the first large-scale neural architecture that can learn to dialogue using the natural language through an open-ended incremental learning process. The cross validation and the generalization experiments demonstrate the robustness of the system.\nThe system elaborates verbal information through sequences of mental operations that are compatible with psychological findings. Those results support the hypothesis that the central executive plays a fundamental role for the elaboration of verbal information in the brain. Our work emphasizes that the decision processes operated by the central executive are not based on pre-coded rules. On the contrary, they are statistical decision processes, which are learned by exploration-reward mechanisms. The reward is based on Hebbian changes of the learnable connections of the central executive. A neural architecture is suitable for modeling the development of the procedural knowledge that determines those decision processes. In our model, the central executive controls the flow of information among its slave systems through neural gating mechanisms.\nThe current version of the system sets the scene for subsequent experiments on the fluidity of the human brain and its robustness in the response to noisy or altered input signals. The use of a more realistic neuron model could improve the system performance. Moreover, the addition of sensorimotor knowledge to the system (e.g. visual input and action capabilities) would lead to the extension of the model for handling the developmental stages in the grounding and acquisition of language [48]. The purpose of this process is to bring the language and reasoning competences of the system to the level of\na preschool (4 /5 years old) child. This is an ambitious goal, as the potentialities of a 4-years-old child in language understanding and reasoning are incomparably superior to those of any currently available cognitive architecture. The system could then be used as a language module for artificial systems ready to participate to real children educational settings, as well for interactive robot systems [49].\nAcknowledgments: This work was partially supported by the Regione Autonoma della Sardegna with funds from Operative Program FSE 2007\u20132012 L.R.7/2007 \u201cPromozione della ricerca scientifica e dell\u2019innovazione tecnologica in Sardegna\u201d. Cangelosi\u2019s efforts were funded as part of the UK EPSRC project BABEL and the FP7 Projects POETICON++. We are deeply grateful to Prof. Risto Miikkulainen for his invaluable discussions and suggestions for the improvement of our work."}, {"heading": "Appendix A Examples from the learning sessions", "text": "The following conventions are used when typing phrases and/or commands through the interface:\n\u2022 only lowercase letters are used, with no punctuations, no special characters; uppercase letters\nare used only for the first character of proper nouns; sentences do not start with a capital letter (unless they start with a proper noun);\n\u2022 by convention, questions starts with a question mark, as: \u201c? how old are you\u201d;\n\u2022 words with suffix are split in the form: base -suffix; e.g. animals \u2192 animal -s, writing \u2192 write\n-ing, etc.\nA.1 First example: verbs and personal pronouns In this example the system should combine the use of some verbs with that of personal pronouns.\nThe teacher can start by typing the two phrases:\nthe personal pronoun for a male person is he the personal pronoun for a female person is she\nthen he should type phrases as\nSusan is a female name Susan is a doctor Susan is drive -ing the car Tim is a male name Tim is a student Tim is read -ing a book Elisabeth is a female name Elisabeth is a secretary Elisabeth is write -ing a letter Max is a male name Max is an actor Max is go -ing to the theater \u2026\nand other similar phrases with different names. The order in which the phrases are submitted is not\nimportant, and they can be mixed with other kinds of phrases.\nNow the teacher can ask the question\n? what is Max do -ing\nstarting with a question mark, without other punctuations, and following the rule discussed previously for words with suffixes. Then he can suggest target word groups and target phrases that lead to the correct answer. Since he would like that the system uses the personal pronouns, the first part of the output should be the word \u201che\u201d, which can be obtained through the following word-group extractions and associations:\n.word_group Max .phrase Max is a male name .word_group male .phrase the personal pronoun for a male person is he .word_group he\nThe word group obtained at the end of this exploration phase is the first part of the output. It should be rewarded, however the system should be warned that the output phrase is not complete. The command that the teacher should use in this case is\n.partial_reward\nThe only difference between the partial reward and the complete reward is that the first is terminated\nby a CONTINUE action, while the latter is terminated by a DONE action.\nTo complete the answer, the teacher can suggest the following word-group extractions and\nassociations:\n.word_group Max .phrase Max is go -ing to the theater .word_group is go -ing to the theater\nThe last word group is the second and final part of the desired output, therefore it should be\nrewarded:\n.reward\nNow the teacher can test if the system is able to answer to similar questions, as for instance:\nwhat is Tim do -ing\n.exploitation\nThe system will answer:\nhe is read -ing a book\nNote that it is not necessary to train the system with an example using a female name: the system will be able to use correctly both personal pronouns according to the gender. For instance, if the teacher asks the question:\n? what is Elisabeth do -ing\nthe system will answer correctly, being able to use correctly both personal pronouns according to the\ngender.\nA.2 Second example: categorization This example uses the animal classification to show the categorization ability of the system. A first very simple test can be made by launching the program and typing phrases as:\nthe turtle is a reptile the eagle is a bird the dog is a mammal ...\n(all lowercase, without punctuations) mixed to other phrases, as for instance\nfish -es live in the water reptile -s have cold blood the turtle is slow \u2026\nThe order in which the phrases are submitted is not important. The teacher could now ask the system\nto tell him an animal belonging to one of the categories that he used before, e.g.\ntell me a mammal\nClearly at this point the system has no idea of the meaning of this phrase, because it started from a blank condition (tabula rasa). However, it can use this phrase to start an exploration phase, during which the system can retrieve phrases memorized by the association mechanism and build new phrases through partially-random action sequences. The teacher can suggest to the system a target phrase or a\ntarget word group. The exploration process is terminated when it produces the target phrase / target word group, or when the number of iterations becomes greater than a predefined limit.\nFor instance, if the teacher types the command:\n.word_group mammal\nthe system starts an exploration phase, which terminates when the target word group \u201cmammal\u201d is\nextracted from the working phrase buffer. Therefore, the command:\n.phrase the dog is a mammal\nstarts another exploration phase that is terminated when the working phrase, which is retrieved from the word group through the association mechanism, becomes equal to the target phrase. At this point, the teacher can type the command:\n.word_group dog\nThe system will start a new exploration phase, which terminates when the target word group \u201cdog\u201d is extracted from the working phrase buffer. The word group corresponds to a good output, so the teacher can reward the system using the command\n.reward\nDuring the reward phase, the system retrieves the state-action sequence that led to a good output. The association between each state of the sequence and each corresponding action is rewarded by changing the connection weights of the state-action association SSM through the DHL rule.\nFinally, the teacher can ask the system to say an animal belonging to a category different from the\none used for training it, e.g.\ntell me a reptile\nand start the exploitation operating mode through the command\n.exploitation\nAt the end of the exploitation phase, the system will respond with a correct output. If the question is repeated, the system will answer with another correct answer, generally different from the previous one.\nThis test, as well as several other tests used in the cross validation, show that the ANNABELL system is able to learn that the \u201cis a\u201d couple is used in phrases as \u201cthe dog is a mammal\u201d to state that a concept belongs to a category, and that the \u201ctell me a\u201d group in a question can be used for asking to\nretrieve a concept from a category. There are two key features of the ANNABELL system that are particularly important for this type of abstraction.\n The connections that are affected by the reward (i.e. the connections of the state-action\nassociation SSM) are connected to action neurons, rather than being directly connected to output words or phrases. In this way, the system learns preferentially to build the output through sequences of elementary operations on word groups or phrases.\n The input of the state-action association SSM includes equal-words vectors. In the previous\nexample, when the system retrieves the phrases associated to the word group \u201ca reptile\u201d, it will recognize that the phrase \u201cthe lizard is a reptile\u201d is more appropriate than other similar phrases (as for instance \u201cthe raven is a bird\u201d) because the last word (\u201creptile\u201d) is equal to the second word of the word group and to the last word of the input phrase (\u201ctell me a reptile\u201d), as in the association used in the training example (\u201ca mammal\u201d with \u201cthe dog is a mammal\u201d)."}, {"heading": "Appendix B Example from CHILDES database", "text": "From CHILDES database, Warren-Leubecker corpus, file david.cha.\nB.1 Comparison between ANNABELL system (left) and real child (right)\nANNABELL system Participants: - SYS, Ann, ANNABELL system; - TEA, Teacher.\n*TEA: Ann, why do not you tell, tell Dad about you playing Pac_Man . *SYS: Michael brought me to the bumpers junction . *SYS: I played Pac_Man . *TEA: did you win ? *SYS: yes, I won . *TEA: did you play other games ? *SYS: I played Space_Invaders . *TEA: did you win ? *SYS: no, I did not win . *TEA: how many games did you play ? *SYS: I played : *SYS: Space_Invaders, one ; *SYS: Pac_Man, two ; *SYS: Donkey_Kong, three ; *SYS: three games . *TEA: I know what is better to talk about . *TEA: you need to tell them about jumble junkman . *SYS: jumble junkman will be my letter man . *TEA: how about Harry hair ? *SYS: Harry hair will be Bob's letter man . *TEA: tell me what Mum put on your shirt . *SYS: a sticker . *TEA: a sticker . *SYS: a dress_for_doll . *TEA: ok . *SYS: a wheel . *TEA: right . *SYS: a necklace . *TEA: a necklace . *SYS: a shoestring . *TEA: a shoestring . *SYS: a ring . *TEA: a ring . *SYS: a bracelet . *TEA: right . *SYS: a j@l . *TEA: what kind of j@l was that ? *SYS: a capital j@l .\nReal child Participants: - CHI, David, target child, 5 years 10 months; - MOT, Mother.\n*MOT: Christopher , why don't you tell , tell Daddy about you playing Pac_Man . *MOT: didn't Michael take you to play Pac_Man at bumper's junction ? *MOT: huh ? *CHI: yeh . *MOT: well ? *MOT: did you win ? *MOT: what did you do ? *CHI: I won ! *MOT: how many games did you play ? *CHI: &um , I don't know . *MOT: you don't know ? *MOT: I know what's better to talk about . *MOT: you need to tell (th)em about , &um , junk+man . *CHI: xxx . *MOT: your letter man ! *CHI: no ! *MOT: yes ! *MOT: tell (th)em what I put all over your shirt . *MOT: &um &um . *CHI: sticker . *MOT: sticker . *CHI: and a dress for a Barbie doll , and a wheel , and part of a necklace , and a shoestring , and a ring , or whatever . *MOT: a bracelet . *CHI: a bracelet . *CHI: a key , a coat+hanger . *MOT: and what's on the back ? *CHI: &um . *MOT: a piece of paper . *CHI: piece of paper . *CHI: and i@l , and a j@l , and a pencil , broken , and a button , and a chain , and a ring , and a crayon , and a peanut , two j@l-s +... *MOT: how about those safety+pins ? *CHI: I don't see (th)em . *MOT: all those safety pins that are holding the things on your shirt . *CHI: safety pin . *CHI: string , string , string , string .\n*TEA: how about those safety_pins ? *SYS: Mum used some safety_pins to hold the things on the shirt . *TEA: so, when will you wear your letter man dress ? *SYS: May the twelfth . *TEA: I think you wear it May the third ? *SYS: no May the twelfth . *TEA: May the twelfth ? *SYS: yes . *TEA: tell me the names of the letter men . *SYS: a@l achoo . *TEA: achoo ? *TEA: and what, how about b@l ? *SYS: b@l beautiful buttons . *TEA: and tell me the rest of them . *SYS: c@l cotton candy . *TEA: okay . *SYS: d@l delicious donuts . *TEA: oh, I like that . *TEA: okay . *SYS: e@l exercise . *TEA: right . *SYS: f@l funny feet . *TEA: oh, like mine . *SYS: g@l gooey gum . *TEA: very good . *SYS: h@l Harry hair . *TEA: right . *SYS: i@l itchy itch . *TEA: okay . *SYS: j@l jumble junkman .\n*MOT: and what kind of j@l is that ? *CHI: capital . *MOT: and what kind is that ? *CHI: a lower case . *MOT: a lower case , that's right . *MOT: so when are you gonna wear that to school ? *MOT: May the twelveth [: twelfth] , I think . *CHI: I think we wear it May the third . *MOT: no , it's May the twelveth [: twelfth] . *MOT: is everybody in class gonna be wearing something ? *CHI: mhm . *MOT: well what are the other lettermen , letter people that there's gonna be ? *MOT: tell me some of the names of the letter people . *CHI: a@l . *MOT: and what's a@l stand for ? *CHI: achoo . *MOT: achoo ? *MOT: and what , how (a)bout b@l ? *CHI: beautiful buttons . *MOT: and , tell me the rest of them . *CHI: c@l is cotton candy . *CHI: d@l is delicious donuts . *MOT: oh I like that . *MOT: and how about c@l ? *CHI: I already told you about c@l ! *MOT: you did ? *CHI: &uh huh , cotton candy . *MOT: oh , that's right . *CHI: and e@l , exercise . *MOT: okay . *CHI: and +... *MOT: f@l . *CHI: f@l , funny feet . *MOT: oh ! *MOT: like mine . *CHI: but they're big ! *MOT: oh , okay . *CHI: and +... *MOT: g@l . *CHI: gooey gum . *MOT: gooey gum , alright . *CHI: and , h@l , Harry hair . *MOT: I . *CHI: scratchy scratch . *MOT: no , that's not for i@l . *MOT: is that itchy something ? *CHI: itchy itch . *CHI: and +... *MOT: and you got j@l , and what'd you say that was ? *CHI: jumble junk+man . *MOT: jumble junk+man .\nB.2 Informative sentences used to build the experience of the system in a textbased virtual environment ################################################# you are at the bumpers junction Michael brought you here you play Space_Invaders you do not win you play Pac_Man you win you play Donkey_Kong you do not win you leave\n################################################# you are at school you can see the teacher your classmate -s # the teacher says next week we will put on a show about the letter -s of the alphabet each of you will play a letter man your mum will help you to prepare the dress for your letter man you will wear your letter man dress May the twelfth the letter men are a@l achoo b@l beautiful buttons c@l cotton candy d@l delicious donuts e@l exercise f@l funny feet g@l gooey gum h@l Harry hair i@l itchy itch j@l jumble junkman Susan your letter man will be the achoo Antony your letter man will be beautiful buttons Andy your letter man will be cotton candy Nicole your letter man will be delicious donuts Carol your letter man will be exercise Helen your letter man will be funny feet Matt your letter man will be gooey gum Bob your letter man will be Harry hair Chris your letter man will be itchy itch Ann your letter man will be jumble junkman\n################################################# you are at home you can see Mum #Mum says we have to prepare the dress for your letter man jumble junkman we can put many thing -s all over your shirt # Mum put -s a sticker on your shirt Mum put -s a dress_for_doll on your shirt Mum put -s a wheel on your shirt Mum put -s a necklace on your shirt Mum put -s a shoestring on your shirt Mum put -s a ring on your shirt Mum put -s a bracelet on your shirt Mum put -s a j@l on your shirt Mum has done put -ing things the j@l is a capital j@l Mum use -s some safety_pin -s to hold the thing -s on the shirt\n################################################# you are at the central park Dad brought you here you play hide_and_seek you do not win Susan win -s you play bowl -s you win you play frisbee you do not win Oliver win -s you play tag you win you leave\n################################################# you are at school you can see the teacher your classmate -s # the teacher says Ann your desk mate will be Susan Dale Matt your desk mate will be Bob Fingers Helen your desk mate will be Carol Davis\n################################################# you are in Susan 's room you can see Susan aunt Carol\n# aunt carol says Susan you must tidy up your room # Susan put -s a doll in her toy_box Susan put -s a doll_house in her toy_box Susan put -s a doll_dress in her toy_box Susan put -s a toy_horse in her toy_box Susan put -s a toy_dog in her toy_box Susan put -s a puppet in her toy_box Susan has done put -ing things the puppet is a white cat Susan place -s some book -s in the bookshelf\n################################################# Ann you will celebrate your fifth birthday February the seventh\n################################################# the fantastic four are Mister Fantastic #Reed Richards The Invisible Woman #Susan \"Sue\" Storm The Thing #Ben Grimm The Human Torch #Johnny Storm\n################################################# the seven kings are first Romulus second Numa Pompilius third Tullus Hostilius fourth Ancus Marcius fifth Tarquinius Priscus sixth Tarquinius Superbus seventh Servius Tullius\nB.3 Training sentences *TEA: tell me about you play -ing bowl -s *SYS: Dad brought me to the central park *SYS: I play -ed bowl -s *TEA: ? did you win *SYS: yes I won\n*TEA: ? did you play other game -s *SYS: I play -ed hide_and_seek *TEA: ? did you win *SYS: no I did not win *TEA: ? how many game -s did you play *SYS: I play -ed *SYS: hide_and_seek one *SYS: bowl -s two *SYS: frisbee three *SYS: tag four *SYS: four game -s\n*TEA: tell me about Susan Dale *SYS: Susan Dale will be my desk mate\n*TEA: tell me about Bob Fingers *SYS: Bob Fingers will be Matt's desk mate\n*TEA: tell me what Susan put in her toy_box *SYS: a doll *SYS: a doll_house *SYS: a doll_dress *SYS: a toy_horse *SYS: a toy_dog *SYS: a puppet *TEA: ? what kind of puppet was that *SYS: a white cat *TEA: ? how about those book -s *SYS: Susan place -ed some book -s in the bookshelf\n*TEA: Ann *TEA: ? when will you celebrate your fifth birthday *SYS: February the seventh *TEA: ? February the sixth *SYS: no February the seventh *TEA: ? February the seventh *SYS: yes\n*TEA: tell me the name -s of the fantastic four *SYS: Mister Fantastic *TEA: Mister Fantastic *SYS: The Invisible Woman *TEA: right *SYS: The Thing *TEA: that is right\n*SYS: The Human Torch\n*TEA: tell me the name -s of the seven kings *SYS: first Romulus *TEA: first Romulus *SYS: second Numa Pompilius *TEA: second Numa Pompilius *SYS: third Tullus Hostilius *TEA: that is good *SYS: fourth Ancus Marcius *TEA: right *SYS: fifth Tarquinius Priscus *TEA: very good *SYS: sixth Tarquinius Superbus *TEA: okay *SYS: seventh Servius Tullius"}, {"heading": "Appendix C Neural activation patterns in a concrete example", "text": "This section describes through a concrete example how the neural activation patterns of the system evolve, how the connection weights are modified during the training stage and how these weight changes make the system able to generalize the response to new sentences. A detailed description of the system architecture is provided in the Supporting information document The ANNABELL system architecture.\nC.1 Input phrase acquisition Figure 13 illustrates how an input sentence (\u201cthe turtle is a reptile\u201d in this example) is acquired by the system and stored in the input phrase buffer. When this sentence is written in the terminal or read from a file, the interface submits its words one by one to the system, using the ascii representation,\nstarting from the word \u201cthe\u201d. This word is mapped to the input-word buffer (IW) through the mechanism described in The ANNABELL system architecture, Sect. 2. The input nodes are fully connected to IW, and the connection weights are initialized randomly. IW is updated using the winnertake-all (WTA) rule: the neuron with the highest activation state (winner neuron) is switched to the level one, while all other neurons of IW are switched to zero. The connections from the input nodes to the winner neuron of IW are updated through the discrete-hebbian-learning (DHL) rule: if the input node signal is one, the connection weight is saturated to its maximum value (+1), otherwise it is saturated to its minimum value (-1). This ensures that if this word is submitted again to the system, the winner neuron will be the same.\nPhI (phrase index) is a subnetwork that represents the position of the current word in the phrase: the neuron of PhI corresponding to the position of the word in the phrase is in a high-level state, while all the others are in a low-level state. The words of the input phrase are submitted to the system by loading them, one by one, in the word buffer, and increasing the phrase index from 1 to the number of words in the phrase. The system itself initializes the phrase index at the beginning of a phrase acquisition, and increases it after the acquisition of each word, as discussed in The ANNABELL system architecture, Sect. 9. In this way a couple (word, phrase-index) is mapped to the neuron of InPhFL located in the row i corresponding to the phrase index and in the column j corresponding to the word-mapping neuron index.\nThis structure is suitable for a broad range of problems in adaptive behavior, not only language understanding. In general, a \u201cword\u201d can be defined as a specific input pattern. The system can associate a key to each word received as input and generate a unique pattern corresponding to the couple (key, word). A \u201cphrase\u201d is set of couples (key, word), temporarily stored in the system. The key can be any pattern, not necessarily representing an integer number, however in the SSM approach a single neuron or a small number of neurons should be active for any key pattern. In the case of natural language, the \u201cphrase index\u201d is a key that represents the position of each word in a phrase.\nThe input-phrase front layer is single-connected to the input-phrase buffer (InPhB). The inputphrase buffer is also single-connected to itself (self connection). In this way, it can store all words of a phrase and keep them stored until it is cleared by a flush signal.\nC.2 Copy of the input phrase to the working-phrase buffer After the whole input sentence is acquired, the system executes the action PH_FROM_INPUT, which copies the sentence from the input phrase buffer to the working phrase buffer, as illustrated in Fig. 14. The input-phrase-buffer neurons are connected one by one to the intermediate subnetwork WkPhFL. The action neuron PH_FROM_INPUT activates the gatekeeper neuron WkFlag, which is fully connected to WkPhFL. When the gatekeeper neuron is ON, WkPhFL allows the signal to flow from the input phrase buffer to the working phrase buffer, through the mechanism described in Sect. 2.\nC.3 Memorization of the input phrase in the long-term memory The subnetwork RemPh (remembered phrase) is used as an index for storing and retrieving phrases from the long-term memory. RemPh is fully connected to WkPhB by forcing connections. The active neuron of RemPh represents the current phrase index in the long-term memory. After the input phrase is copied to WkPhB, the connections from this neuron to WkPhB are updated through the DHL rule. In\nthis way, if this neuron is switched ON again, it will retrieve the memorized phrase by forcing the activation states of WkPhB.\nC.4 Extraction of a word-group from the working-phrase buffer Figure 15 shows how a word is extracted from the working phrase buffer. PhI (phrase index) represents the index of the word in the phrase. Each neuron of the intermediate subnetwork WkWfI performs a logical AND between the corresponding neuron of WkPhB and that of PhI. In this way, the row of WkPhB corresponding to the phrase index is copied to the subnetwork that represents the current word, CW.\nThe current word can be extracted from CW and copied to the word-group buffer through the procedure illustrated in Fig. 16, which is controlled by the gatekeeper neuron GetFlag. When GetFlag is ON, the intermediate subnetwork WGCW (word-group corrent word) allows the flow of signal from CW to WGFL (word-group front layer), which operates a logical AND between this signal and the word-group index WGI. In this way, the current word is copied to the row of WGFL that corresponds to the word group index.\nC.5 Memorization and retrieval of the association between a word group and a phrase\nThe group of words in WGB can be used as a cue to retrieve a phrase from the long term memory. Figure 17 shows how the association between a group of words and the whole phrase is stored in the long-term memory. The word group buffer is fully connected to the subnetwork RemPhfWG (remembered-phrase from word group), which is fully connected to RemPh by forcing connections. RemPhfWG is updated through the WTA rule. The connections from WGB to the winner neuron and the connections from this neuron to RemPh are updated through the DHL rule.\nThe association between the word group in WGB and the phrase in WkPhB is memorized in the long-term memory using the architecture shown in Fig. 17. The word group buffer is fully connected to RemPhfWG, which is fully connected to RemPh by forcing connections. RemPhfWG is updated\nthrough the winner-take-all (WTA) rule. The weights of the connections from WGB to the winner neuron and the weights of the connections form this neuron to RemPh are updated through the DHL rule. In this way, the association between the current content of WGB and the current content of RemPh is permanently memorized by the system. During the retrieval process, the word group in WGB is sent as input to RemPhfWG. The neurons having connection weights matching the word group will have the highest activation state, and a single winner is selected among them through the WTA rule. The winner neuron will retrieve the phrase associated to the input word group by using its forcing output connections to set the activation state of WkPhB.\nC.6 Exploration The system is trained to respond to the input sentences through an exploration/reward procedure. Following our example, suppose that the human interlocutor submits the question-like imperative sentence\ntell me a reptile\nDuring the exploration phase, the system performs partially random action sequences. The basic action sequence is that described in Sect. 2:\n\u2022 W_FROM_WK \u2022 NEXT_W (N1 times) \u2022 FLUSH_WG \u2022 GET_W, NEXT_W (N2 times) \u2022 RETR_AS\nwith N1, N2 random integer numbers. The action neuron NEXT_W activates the gatekeeper neuron NextPhIFlag, which triggers an increase of the phrase index PhI, as described in The ANNABELL system architecture, Sect. 9. The action neuron GET_W activates the gatekeeper neuron GetFlag, which controls the copy of the current word from the working phrase to the word group buffer, as described previously. The action neuron RETR_AS activates the gatekeeper neuron RetrAs, which\ncontrols the retrieval of a phrase from the long-term memory using the word group as a cue as discussed in the above paragraphs.\nThe whole sequence is repeated, using different random integer values for N1, N2, until it produces the target output. In our example this can occur, for instance, with N1=2 and N2=2. In fact, in this case the system extracts the word group \u201ca reptile\u201d from the input phrase \u201ctell me a reptile\u201d. The RETR_AS action uses this word group as a cue, and can eventually retrieve the phrase \u201cthe turtle is a reptile\u201d from the long-term memory. The basic action sequence is repeated on the new working phrase, and the system produces the target output \u201cturtle\u201d if N1=1 and N2=1.\nThe state-action sequences are memorized through the mechanism represented in Fig. 18. The stateaction index StActI is initialized to one at the beginning of each sequence, and it is increased every time the system produces a new action. The neurons of StActI are connected one by one to the corresponding neurons of StActMem (state-action memory), which is fully connected to all subnetworks that represent the internal state of the system state (as defined in Sect. 2) and to the action neurons. The output connections of StActMem are updated through the DHL rule. In this way, StActMem can retrieve the state-action sequence by forcing the activation state of the neurons connected to its output connections.\nC.7 Reward When the exploration phase leads to the target output, the system is set to the reward operating mode. The memorized state-action sequence is retrieved, as described in the previous paragraphs.\nThe association between each state of the sequence and the corresponding action is memorized through the state-action association subnetwork ElActfSt, which has input connections fully connected to the system state and output connections fully connected to the action neurons, as illustrated in Fig. 19. In the reward operating mode, ElActfSt is updated through the WTA rule, and both the connections from the verbal working memory to the winner neuron of ElActfSt and the connections from this neuron to the action neurons are updated through the DHL rule.\nC.8 Exploitation Following our example, suppose that the human interlocutor types the sentence\ntell me a mammal\nand that after the acquisition the system is set to the exploitation operating mode.\nThe state-action association subnetwork ElActfSt receives its input from the system state, and it is updated through the k-WTA rule: the k neurons that have the highest activation state are set to one, while all other neurons are set to zero. Those neurons send their output to the action neurons, which are updated through the WTA rule: the action neuron with the highest activation state (which represents the action with the highest score) is set to one, while all other action neurons are set to zero.\nAlthough the input phrase is new for the system, it is similar to the one used for training (\u201ctell me a reptile\u201d). Therefore, at each step of the exploitation phase, the neurons of the central executive with the highest activation state will be those that have been rewarded in the training example, and consequently the action sequence will be the same, i.e.\n\u2022 W_FROM_WK \u2022 NEXT_W (2 times) \u2022 FLUSH_WG \u2022 GET_W, NEXT_W (2 times) \u2022 RETR_AS \u2022 W_FROM_WK \u2022 NEXT_W (1 time) \u2022 FLUSH_WG \u2022 GET_W, NEXT_W (1 time)\nThrough such sequence, the system will extract the word group \u201ca mammal\u201d from the working phrase, retrieve a phrase as \u201cthe dog is a mammal\u201d from the long term memory, extract the word group \u201cdog\u201d and send it to the output."}, {"heading": "Appendix D Mathematical properties of the state-action association system", "text": "The heart of the ANNABELL model is the state-action association system, which is responsible for all decision processes, as described in Sect. 2. This system is implemented as a neural network (stateaction association neural network, abbreviated as SAANN) with input connections fully connected to all subnetworks of the short-term memory (STM), which represents the internal state of the system, and output connections fully connected to the set of mental action neurons. Therefore, the SAANN receives as input the internal state and yields as output a mental action. The input and output connections of this\nsystem have learnable weights, which are updated through a discrete version of the Hebbian learning rule (DHL rule). Furthermore, the activation states of the SAANN are updated through a variant of the k-winner-take-all rule, while those of the action neurons are updated through the (one-) winner-take-all rule.\nIn this section, we describe the update rules in more details and we prove that our model of the stateaction association system is equivalent to a k-nearest-neighbor (k-NN) classifier with a proper definition of the distance in the input space. For large enough training sets, the k-NN algorithm is guaranteed to yield an error rate no worse than twice the Bayes error rate, which is the minimum achievable error rate given the distribution of the data [51].\nThe discrete-Hebbian-learning (DHL) rule used in our model is an extreme simplification compared with other models more focused on biological realism. The same type of simplification is often used in neural models of memory based on the Hopfield recurrent neural networks [34].\nNessler et al. [52] have proven that a more realistic model of Hebbian learning, in combination with a sparse neural code, can learn to infer optimal Bayesian decisions for arbitrarily complex probability distributions. However, a more realistic implementation of the Hebbian learning rule, with small updates of the connection weights, would require very large computational resources for training and evaluating our model on large datasets, and real time interaction with the system would not be possible. O\u2019Reilly [35] have shown that the k-winner-take-all rule is biologically justified.\nOther simplifications are used in our model: \u2022 stability condition: the proof that the state-action association system is equivalent to a k-NN\nclassifier assumes that the STM can be partitioned into M subnetworks each having a fixed number of neurons active at a time. The weight saturation value Wmax, used by the DHL rule, is assumed to be the same for all connections of the same subnetwork. A particular case is when the whole STM has a fixed number of neurons active at a time, and Wmax has the same value for all connections from the STM to the SAANN. In the subnetworks that represent words or phrases, the stability condition is ensured by using default neurons, which represent the null word. In the subnetworks used for word comparison, such property is fulfilled by representing the two conditions, equal/not-equal word, using two complementary neurons instead of one.\n\u2022 During the training stage, the SAANN is updated through the new-winner-take-all rule: a\npreviously unused neuron is set to the high-level activation state (\u201con\u201d), while all other neurons are set to the low-level activation state (\u201coff\u201d).\nThose two simplifications are used only for ensuring validity of the k-NN equivalence theorem, so that the statistical properties of the model are contextualized in a well-known theoretical framework, and good convergence properties of the error rate are guaranteed.\nIt is worth to mention that many biologically inspired neural models of language use the standard backpropagation learning algorithm, even though it does not have a biological justification, because it ensures error minimization. In contrast, our model is based on the same learning principle that is responsible for synaptic plasticity in biological neural networks.\nLet Am and Wmax,m be the number of active neurons and the weight saturation value of the mth subnetwork, respectively. The stability condition ensures that Am is constant. Let smj be the activation state (0 or 1) of the jth neuron of the mth subnetwork. The sum and the square sum of smj weighted with Wmax,m are the following:\n\u2211 m=1\nM\nW max, m\u2211 j=1\nNm\nsmj and \u2211 m=1\nM\nW max ,m\u2211 j=1\nNm\nsmj 2 (1)\nwhere Nm is the number of neurons of the mth subnetwork. The stability condition implies that, for all\nvalues of m,\n\u2211 j=1\nNm\nsmj=\u2211 j=1\nNm\nsmj 2 =Am (2)\ntherefore the following normalization conditions can be derived for the weighted sum and for the\nweighted square sum of the signal:\n\u2211 m=1\nM\nW max ,m\u2211 j=1\nNm\nsmj=U1 and \u2211 m=1\nM\nW max ,m\u2211 j=1\nNm\nsmj 2 =U2 (3)\nwhere\nU1=U 2=\u2211 m=1\nM\nWmax , m Am (4)\nare constants. It is worth to point out that these two normalization conditions are sufficient for the validity of the k-NN equivalence theorem, which we will prove below, even if the stability condition is not satisfied.\nThe weighted distance between two states S1 and S2 of the STM can be defined as:\nd (S1, S2)=\u2211 m=1\nM\nW max ,m\u2211 j=1\nN m\n(s1mj\u2212s2mj) 2=2U2\u22122\u2211\nm=1\nM\nW max ,m\u2211 j=1\nN m\ns1mj s2mj (5)\nwhere we used the second normalization condition of Eq. 3. Let NA be the number of mental action neurons, i.e. the number of possible actions that can be triggered by the state-action association system. A mental action can be represented by an integer value:\na=1,... , N A (6)\nA state-action sequence, starting with a state S1 and ending in a state ST will be called an epoch:\n(S1 \u03b1 , a1 \u03b1) , ... ,(S t \u03b1 , at \u03b1) , ...,(ST\u03b1 \u03b1 , aT \u03b1 \u03b1 ) . (7)\nThe index  represents the epoch, while the index t represents the time step in the epoch:\nt=1,... , T \u03b1 . (8)\nThe number of time steps in all epochs is limited: T \u03b1\u2264Tmax . An epoch can receive a reward depending only on its final state. In the reward phase, the state-action memory retrieves the whole state-action sequence, and the SAANN is trained using the state St as input and the corresponding action at as target output. At each time step t of the sequence, the SAANN is updated using the newwinner-take-all rule: a previously unused neuron i is set to the \u201con\u201d state, while all other neurons are set to the \u201coff\u201d state. The connections from the STM to the winner neuron are updated through the DHL rule:\nw imj={+W max ,m for stmj \u03b1 =1\n\u2212Wmax , m for stmj \u03b1 =0\n(9)\nwhere the two indexes m and j refer to the jth neuron of the mth subnetwork of the STM, stmj is the\nactivation state of this neuron (0 or 1) at the epoch  and time step t, wimj is the weight of the connection to the ith neuron of the SAANN (i.e. the winner neuron) and Wmax,m is the weight-saturation absolute value for the subnetwork m. These two equations can also be written as:\nw imj=W max ,m(2stmj \u03b1 \u22121) (10)\nThe connections from the winner neuron of the SAANN to the action neurons are also updated\nthrough the DHL rule:\nw li={+1 for l=at \u03b1\n\u22121 for l\u2260at \u03b1 (11)\nwhere the index l refers to an action neuron, wli is the weight of the connection from the winner\nneuron of the SAANN to this action neuron and at is the target action.\nDuring the exploitation phase, in general the internal states will be different from those used in the training phase. Let S test be a generic internal state of the system in the exploitation phase. The total input signal to each neuron of the SAANN is:\ny i=\u2211 m=1\nM\n\u2211 j=1\nNm\nwimj smj test (12)\nwhere the bias signal is assumed to be null. From Eq. 10 for wimj it follows that\ny i=\u2211 m=1\nM\n[W max ,m\u2211 j=1\nN m\n(2 stmj \u03b1 \u22121)smj test ]=2\u2211 m=1\nM\nW max ,m\u2211 j=1\nN m\ns tmj \u03b1 smj test\u2212U 1 (13).\nwhere we used the first normalization condition of Eq. 3, and using Eq. 5 for the weighted distance:\ny i=2U2\u2212U1\u2212d (S t \u03b1 , S test ) (14)\nIn the exploitation phase, the SAANN is updated through the k-winner-take-all rule: the k neurons\nwith the highest activation state are set \u201con\u201d, while all the others are set \u201coff\u201d.\nSince the activation function f(yi) is an increasing function of the input signal yi, from Eq. 14 it follows that the neurons with the highest activation state yi are those with the smallest value of\nd (St \u03b1 , S test) . Therefore, the k neurons with the highest activations are those that correspond to the training internal states that have the smallest weighted distance from the current (test) internal state, i.e. to the k nearest neighbors with such metric.\nEach \u201cused\u201d neurons of the SAANN, i.e. each neuron that was classified as a winner neuron during\na reward phase, is connected with a positive-weight connection ( w li=+1 ) to one and only one action neuron, while it is connected to all other action neurons by negative-weight connections ( w li=\u22121 ). We can therefore partition the used neurons of the SAANN in classes, based on the action that they \u201csuggest\u201d.\nThe input signal to each action neuron is equal to the weighted sum of the input from the k winner\nneurons. Since the output of the winner neurons is 1, and the weights are w li=\u00b11 , the input signal is equal to the number of winner neurons that \u201csuggest\u201d that action as the best action, minus the number\nof those that do not. The action neuron with the highest input signal is the one that is \u201csuggested\u201d as the best action by the greatest number of winner neurons. The actions neurons are updated by the (one) winner-take-all rule, therefore this neuron will be set \u201con\u201d, while all the other action neurons will be set \u201coff\u201d. This is equivalent to a k-NN classification. In fact, in k-NN classification an entry is assigned to the class most common among its k nearest neighbors."}], "references": [{"title": "The Language of Thought", "author": ["J Fodor"], "venue": null, "citeRegEx": "1", "shortCiteRegEx": "1", "year": 1975}, {"title": "LOT2: The Language of Thought Revisited (Oxford University Press, Oxford and New York)", "author": ["J Fodor"], "venue": null, "citeRegEx": "2", "shortCiteRegEx": "2", "year": 2010}, {"title": "Soar: An Architecture for General Intelligence", "author": ["JE Laird", "PS Rosenbloom", "A Newell"], "venue": "Artif Intell", "citeRegEx": "3", "shortCiteRegEx": "3", "year": 1987}, {"title": "An overview of the EPIC architecture for cognition and performance with application to human-computer interaction", "author": ["DE Kieras", "DE Meyer"], "venue": "Hum Comput Int", "citeRegEx": "4", "shortCiteRegEx": "4", "year": 1997}, {"title": "An adaptive architecture for physical agents", "author": ["P Langley"], "venue": "Proceedings of the 2005 IEEE/WIC/ACM International Conference on Intelligent Agent Technology (IEEE Computer Society Press, Compiegne,", "citeRegEx": "5", "shortCiteRegEx": "5", "year": 2005}, {"title": "Cognitive architectures: where do we go from here", "author": ["W Duch", "RJ Oentaryo", "M Pasquier"], "venue": "Artificial General Intelligence,", "citeRegEx": "6", "shortCiteRegEx": "6", "year": 2008}, {"title": "Cognitive architectures: Research issues and challenges", "author": ["P Langley"], "venue": "Cognitive Syst Res", "citeRegEx": "7", "shortCiteRegEx": "7", "year": 2009}, {"title": "A large-scale model of the functioning", "author": ["C Eliasmith"], "venue": "brain. Science", "citeRegEx": "8", "shortCiteRegEx": "8", "year": 2012}, {"title": "Anatomy of a cortical simulator, in Proceedings of the 2007 ACM/IEEE Conference on Supercomputing-SC '07 (Association for Computing", "author": ["R Ananthanarayanan", "DS Modha"], "venue": null, "citeRegEx": "9", "shortCiteRegEx": "9", "year": 2007}, {"title": "Large-scale model of mammalian thalamocortical systems", "author": ["EM Izhikevich", "GM Edelman"], "venue": "Proc Natl Acad Sci USA", "citeRegEx": "10", "shortCiteRegEx": "10", "year": 2008}, {"title": "Distributed representations, simple recurrent networks, and grammatical structure", "author": ["JL Elman"], "venue": "Mach Learn", "citeRegEx": "11", "shortCiteRegEx": "11", "year": 1991}, {"title": "Mechanisms of sentence processing: Assigning roles to constituents of sentences. in Parallel Distributed Processing. Explorations in the Microstructure of Cognition, eds", "author": ["JL McClelland", "AH Kawamoto"], "venue": null, "citeRegEx": "12", "shortCiteRegEx": "12", "year": 1986}, {"title": "Subsymbolic Natural Language Processing: An Integrated Model of Scripts, Lexicon, and Memory", "author": ["R Miikkulainen"], "venue": null, "citeRegEx": "13", "shortCiteRegEx": "13", "year": 1993}, {"title": "A Subsymbolic Model of Complex Story Understanding", "author": ["P Fidelman", "R Miikkulainen", "R Hoffman"], "venue": "Proceedings of the 27th Annual Meeting of the Cognitive Science Society", "citeRegEx": "14", "shortCiteRegEx": "14", "year": 2005}, {"title": "Context dependent recurrent neural network language", "author": ["T Mikolov", "G Zweig"], "venue": "Proceedings of the IEEE Workshop on Spoken Language Technology,", "citeRegEx": "15", "shortCiteRegEx": "15", "year": 2012}, {"title": "Parsing natural scenes and natural language with recursive neural networks", "author": ["R Socher", "CC Lin", "AY Ng", "CD Manning"], "venue": "Proceedings of the 26th International Conference on Machine Learning (ICML 2011),", "citeRegEx": "16", "shortCiteRegEx": "16", "year": 2011}, {"title": "Parsing with compositional vector grammars", "author": ["R Socher", "J Bauer", "CD Manning"], "venue": "Proceedings of the 51st Annual Meeting of the Association for Computational Linguistics,", "citeRegEx": "17", "shortCiteRegEx": "17", "year": 2013}, {"title": "Recursive deep models for semantic compositionality over a sentiment treebank", "author": ["R Socher", "A Perelygin", "J Wu", "J Chuang", "CD Manning", "AY Ng", "C. Potts"], "venue": "in Conference on Empirical Methods in Natural Language Processing (EMNLP", "citeRegEx": "19", "shortCiteRegEx": "19", "year": 2013}, {"title": "Advances in research and theory (Vol", "author": ["A.D. Baddeley", "Hitch", "G. Working memory. In G.H. Bower (Ed.)", "The psychology of learning", "motivation"], "venue": "8, pp. 47\u201389). New York: Academic Press", "citeRegEx": "20", "shortCiteRegEx": null, "year": 1974}, {"title": "The episodic buffer: a new component of working memory", "author": ["A.D. Baddeley"], "venue": "Trends in Cognitive Science", "citeRegEx": "21", "shortCiteRegEx": "21", "year": 2000}, {"title": "Theories, Models, and Controversies", "author": ["Baddeley", "A.D. Working Memory"], "venue": "Annual Review of Psychology 63: 1-29", "citeRegEx": "22", "shortCiteRegEx": null, "year": 2012}, {"title": "an integrated framework", "author": ["Cowan", "N. Attention", "memory"], "venue": "Oxford [Oxfordshire]: Oxford University Press", "citeRegEx": "23", "shortCiteRegEx": null, "year": 1995}, {"title": "Working memory and focal attention", "author": ["B. McElree"], "venue": "Journal of Experimental Psychology: Learning, Memory & Cognition", "citeRegEx": "24", "shortCiteRegEx": "24", "year": 2001}, {"title": "exploring the focus of attention", "author": ["Oberauer", "K. Access to information in working memory"], "venue": "Journal of Experimental Psychology. Learning, Memory, and Cognition 28 (3): 411\u201321", "citeRegEx": "25", "shortCiteRegEx": null, "year": 2002}, {"title": "switching or serial order control? Mem", "author": ["RL Bryck", "Mayr", "U. On the role of verbalization during task set selection"], "venue": "Cognit. 33(4), 611-623", "citeRegEx": "26", "shortCiteRegEx": null, "year": 2005}, {"title": "Role of Working Memory in Task Switching", "author": ["A. Vandierendonck"], "venue": "Psychologica Belgica,", "citeRegEx": "27", "shortCiteRegEx": "27", "year": 2012}, {"title": "New approaches to understanding the cortical organization of semantic processing", "author": ["Bookheimer", "S. Functional MRI of Language"], "venue": "Annu. Rev. Neurosci. 25, 151\u2013188", "citeRegEx": "28", "shortCiteRegEx": null, "year": 2002}, {"title": "A combined functional magnetic resonance imaging and transcranial magnetic stimulation study", "author": ["Devlin", "J.T. et al. Semantic processing in the left prefrontal cortex"], "venue": "J. Cogn. Neurosci. 15, 71\u201384", "citeRegEx": "29", "shortCiteRegEx": null, "year": 2003}, {"title": "Integration of word meaning and world knowledge in language comprehension", "author": ["P Hagoort"], "venue": "Science 304,", "citeRegEx": "30", "shortCiteRegEx": "30", "year": 2004}, {"title": "a new framework", "author": ["Hagoort", "P. On Broca", "brain", "binding"], "venue": "TRENDS in Cognitive Sciences 9(9) 416-423", "citeRegEx": "31", "shortCiteRegEx": null, "year": 2005}, {"title": "Towards a neural basis of auditory sentence processing", "author": ["A. Friederici"], "venue": "TRENDS in Cognitive Sciences", "citeRegEx": "32", "shortCiteRegEx": "32", "year": 2002}, {"title": "Integration of action and language knowledge: A roadmap for developmental robotics", "author": ["A Cangelosi"], "venue": "IEEE Trans Auton Ment Dev", "citeRegEx": "33", "shortCiteRegEx": "33", "year": 2010}, {"title": "Neural Networks: A Comprehensive Foundation (Prentice Hall PTR Upper Saddle River, NJ, USA, 2nd edition)", "author": ["S Haykin"], "venue": null, "citeRegEx": "34", "shortCiteRegEx": "34", "year": 1998}, {"title": "Computational Explorations in Cognitive Neuroscience: Understanding the Mind by Simulating the Brain", "author": ["RC O\u2019Reilly", "Y Munakata"], "venue": null, "citeRegEx": "35", "shortCiteRegEx": "35", "year": 2000}, {"title": "Neural Networks: A Comprehensive Foundation (Prentice Hall PTR Upper Saddle River, NJ, USA, 2nd edition)", "author": ["S Haykin"], "venue": null, "citeRegEx": "37", "shortCiteRegEx": "37", "year": 1998}, {"title": "Mechanisms Gating the Flow of Information in the Cortex: What They Might Look Like and What Their Uses may be, Frontiers in Computational Neuroscience", "author": ["M Boukadoum", "T Gisiger"], "venue": null, "citeRegEx": "38", "shortCiteRegEx": "38", "year": 2011}, {"title": "Validation of the language development survey (LDS): a parent report tool for identifying language delay in toddlers", "author": ["L Rescorla", "A Alley"], "venue": "J Speech Lang Hear Res", "citeRegEx": "39", "shortCiteRegEx": "39", "year": 2001}, {"title": "Use of the Language Development Survey (LDS) in a National probability sample of children 18 to 35 months old", "author": ["L Rescorla", "T Achenbach"], "venue": "J Speech Lang Hear Res", "citeRegEx": "40", "shortCiteRegEx": "40", "year": 2002}, {"title": "Intonation patterns in child-directed speech: Mother-father speech", "author": ["A Warren-Leubecker", "JN Bohannon"], "venue": "Child Dev", "citeRegEx": "42", "shortCiteRegEx": "42", "year": 1984}, {"title": "The CHILDES Project: Tools for analyzing talk (Lawrence", "author": ["B MacWhinney"], "venue": "Erlbaum Associates,", "citeRegEx": "43", "shortCiteRegEx": "43", "year": 2000}, {"title": "Recurrent temporal networks and language acquisition\u2014from corticostriatal neurophysiology to reservoir computing", "author": ["P.F. Dominey"], "venue": "Front Psychol", "citeRegEx": "44", "shortCiteRegEx": "44", "year": 2013}, {"title": "Syntactic determinants of sentence comprehension in aphasia", "author": ["D. Caplan", "C. Baker", "F. Dehaut"], "venue": "Cognition 21,", "citeRegEx": "45", "shortCiteRegEx": "45", "year": 1985}, {"title": "A Recurrent Network Simulation Study Using Reservoir Computing", "author": ["Hinaut X.", "Dominey P.F. Real-Time Parallel Processing of Grammatical Structure in the Fronto-Striatal System"], "venue": "PLoS ONE 8(2): e52946", "citeRegEx": "46", "shortCiteRegEx": null, "year": 2013}, {"title": "Connecting language to the world", "author": ["Roy D", "E. Reiter"], "venue": "Artif. Intell. 167,", "citeRegEx": "47", "shortCiteRegEx": "47", "year": 2005}, {"title": "Posture affects how robots and infants map words to objects PLoS ONE", "author": ["A. Morse", "T. Belpaeme", "L. Smith", "A. Cangelosi"], "venue": null, "citeRegEx": "48", "shortCiteRegEx": "48", "year": 2015}, {"title": "Developmental Robotics: From Babies to Robots <http://mitpress.mit.edu/books/developmental-robotics>", "author": ["A. Cangelosi", "M. Schlesinger"], "venue": null, "citeRegEx": "49", "shortCiteRegEx": "49", "year": 2015}, {"title": "Learning to talk about events from narrated video in a construction grammar framework", "author": ["P. Dominey", "J.D. Boucher"], "venue": "Artif. Intell. 167,", "citeRegEx": "50", "shortCiteRegEx": "50", "year": 2005}, {"title": "Nearest neighbor pattern classification", "author": ["T.M. Cover", "P.E. Hart"], "venue": "IEEE Transactions on Information Theory", "citeRegEx": "51", "shortCiteRegEx": "51", "year": 1967}], "referenceMentions": [{"referenceID": 0, "context": "According to the computational theory of mind, the brain is an information processing system, and thought can be described as a computation that operates on mental states [1,2].", "startOffset": 171, "endOffset": 176}, {"referenceID": 1, "context": "According to the computational theory of mind, the brain is an information processing system, and thought can be described as a computation that operates on mental states [1,2].", "startOffset": 171, "endOffset": 176}, {"referenceID": 2, "context": "This perspective has led to the implementation of a class of cognitive architectures called symbolic [3-5] (see Ref.", "startOffset": 101, "endOffset": 106}, {"referenceID": 3, "context": "This perspective has led to the implementation of a class of cognitive architectures called symbolic [3-5] (see Ref.", "startOffset": 101, "endOffset": 106}, {"referenceID": 4, "context": "This perspective has led to the implementation of a class of cognitive architectures called symbolic [3-5] (see Ref.", "startOffset": 101, "endOffset": 106}, {"referenceID": 5, "context": "s [6] and [7] for a review).", "startOffset": 2, "endOffset": 5}, {"referenceID": 6, "context": "s [6] and [7] for a review).", "startOffset": 10, "endOffset": 13}, {"referenceID": 5, "context": "However, up to now they have never been implemented in large scale simulations for tasks that require complex reasoning [6].", "startOffset": 120, "endOffset": 123}, {"referenceID": 7, "context": "5-million neuron model of the brain, able to elaborate visual image sequences and to respond through movements of a physically modeled arm [8].", "startOffset": 139, "endOffset": 142}, {"referenceID": 8, "context": "Other large-scale neural simulations have been reported [9,10], however they focus on biological realism of the neuron model, while none of them deal with the problem of natural language elaboration.", "startOffset": 56, "endOffset": 62}, {"referenceID": 9, "context": "Other large-scale neural simulations have been reported [9,10], however they focus on biological realism of the neuron model, while none of them deal with the problem of natural language elaboration.", "startOffset": 56, "endOffset": 62}, {"referenceID": 10, "context": "On the other hand, the subsymbolic approach demonstrated to be more suitable for modeling the cognitive foundations of language processing and for representing statistical regularities in natural language [11-13].", "startOffset": 205, "endOffset": 212}, {"referenceID": 11, "context": "On the other hand, the subsymbolic approach demonstrated to be more suitable for modeling the cognitive foundations of language processing and for representing statistical regularities in natural language [11-13].", "startOffset": 205, "endOffset": 212}, {"referenceID": 12, "context": "On the other hand, the subsymbolic approach demonstrated to be more suitable for modeling the cognitive foundations of language processing and for representing statistical regularities in natural language [11-13].", "startOffset": 205, "endOffset": 212}, {"referenceID": 13, "context": "presented a neural network architecture able to parse and paraphrase scriptbased stories [14].", "startOffset": 89, "endOffset": 93}, {"referenceID": 14, "context": "Recently, deep learning techniques based on recurrent neural networks (RNNs) have been used successfully for several NLP tasks, including speech recognition [15], parsing [16,17], machine translation [18], sentiment analysis of text [19].", "startOffset": 157, "endOffset": 161}, {"referenceID": 15, "context": "Recently, deep learning techniques based on recurrent neural networks (RNNs) have been used successfully for several NLP tasks, including speech recognition [15], parsing [16,17], machine translation [18], sentiment analysis of text [19].", "startOffset": 171, "endOffset": 178}, {"referenceID": 16, "context": "Recently, deep learning techniques based on recurrent neural networks (RNNs) have been used successfully for several NLP tasks, including speech recognition [15], parsing [16,17], machine translation [18], sentiment analysis of text [19].", "startOffset": 171, "endOffset": 178}, {"referenceID": 17, "context": "Recently, deep learning techniques based on recurrent neural networks (RNNs) have been used successfully for several NLP tasks, including speech recognition [15], parsing [16,17], machine translation [18], sentiment analysis of text [19].", "startOffset": 233, "endOffset": 237}, {"referenceID": 18, "context": "In 1974, Baddeley and Hitch [20] proposed a working memory model composed of three main components: a central executive and two slave systems, i.", "startOffset": 28, "endOffset": 32}, {"referenceID": 19, "context": "In 2000, Baddeley [21] extended this model by adding a third slave system, the episodic buffer, which binds information from different domains (phonological, visual, spatial, semantic) to form integrated units of information with chronological ordering.", "startOffset": 18, "endOffset": 22}, {"referenceID": 20, "context": "[22] for a review).", "startOffset": 0, "endOffset": 4}, {"referenceID": 21, "context": "Cowan [23] proposed a working memory model in which the LTM was not a separate component, but a part of the working memory.", "startOffset": 6, "endOffset": 10}, {"referenceID": 22, "context": "McElree [24] suggested a focus of attention limited to a single chunk.", "startOffset": 8, "endOffset": 12}, {"referenceID": 23, "context": "Oberauer [25] proposes an integration of Cowan's and McElree's perspectives into a model that distinguishes three states of representations in WM: the activated part of LTM, the region of direct access and the focus of attention.", "startOffset": 9, "endOffset": 13}, {"referenceID": 23, "context": "In classical tasks used to study working memory capacity [25], a subject is asked to hold in mind a short sequence of digits and to perform some simple process on each of these digits (or on a subset), for example adding the number two to each digit.", "startOffset": 57, "endOffset": 61}, {"referenceID": 24, "context": "Additionally, several studies [26,27] suggest that the task goal should be stored in the working memory in some directly accessible form.", "startOffset": 30, "endOffset": 37}, {"referenceID": 25, "context": "Additionally, several studies [26,27] suggest that the task goal should be stored in the working memory in some directly accessible form.", "startOffset": 30, "endOffset": 37}, {"referenceID": 26, "context": "BA 47 and the ventral part of BA 6 are also involved in language processing tasks [28-30].", "startOffset": 82, "endOffset": 89}, {"referenceID": 27, "context": "BA 47 and the ventral part of BA 6 are also involved in language processing tasks [28-30].", "startOffset": 82, "endOffset": 89}, {"referenceID": 28, "context": "BA 47 and the ventral part of BA 6 are also involved in language processing tasks [28-30].", "startOffset": 82, "endOffset": 89}, {"referenceID": 29, "context": "Results from neuroimaging and psycholinguistic studies show that LIFG is involved in the unification operations required for binding individual words into larger structures [31,32].", "startOffset": 173, "endOffset": 180}, {"referenceID": 30, "context": "Results from neuroimaging and psycholinguistic studies show that LIFG is involved in the unification operations required for binding individual words into larger structures [31,32].", "startOffset": 173, "endOffset": 180}, {"referenceID": 29, "context": "Hagoort [31] proposes a model that distinguishes three functional components of language processing: memory, unification and control.", "startOffset": 8, "endOffset": 12}, {"referenceID": 7, "context": "[8], although our model privileges computational efficiency over biological details.", "startOffset": 0, "endOffset": 3}, {"referenceID": 31, "context": "The ability to perform real time communication and the large scale of the network make our system adequate for sustaining a long developmental process (this property is called open-ended, cumulative learning in developmental robotics [33] ).", "startOffset": 234, "endOffset": 238}, {"referenceID": 32, "context": "The neuron output is computed from the total input by a nonlinear activation function [34]:", "startOffset": 86, "endOffset": 90}, {"referenceID": 32, "context": "the Heaviside step function for the neurons that receive their input from fixed-weight connections, and the logistic function [34] for the neurons that receive it from variable-weight connections.", "startOffset": 126, "endOffset": 130}, {"referenceID": 33, "context": "This rule provides a computationally effective approximation of the activation dynamics produced by inhibitory interneurons [35].", "startOffset": 124, "endOffset": 128}, {"referenceID": 34, "context": "The Hebbian theory provides a theoretical basis for the learning mechanisms in biological neural networks [36,37].", "startOffset": 106, "endOffset": 113}, {"referenceID": 35, "context": "Neural gating mechanisms play an important role in the cortex and in other regions of the brain [38].", "startOffset": 96, "endOffset": 100}, {"referenceID": 35, "context": "[38]).", "startOffset": 0, "endOffset": 4}, {"referenceID": 18, "context": "The global organization of our model combines Baddeley's model of the working memory [20-22] with ideas from Cowan's [23] and from Oberauer's [25] models.", "startOffset": 85, "endOffset": 92}, {"referenceID": 19, "context": "The global organization of our model combines Baddeley's model of the working memory [20-22] with ideas from Cowan's [23] and from Oberauer's [25] models.", "startOffset": 85, "endOffset": 92}, {"referenceID": 20, "context": "The global organization of our model combines Baddeley's model of the working memory [20-22] with ideas from Cowan's [23] and from Oberauer's [25] models.", "startOffset": 85, "endOffset": 92}, {"referenceID": 21, "context": "The global organization of our model combines Baddeley's model of the working memory [20-22] with ideas from Cowan's [23] and from Oberauer's [25] models.", "startOffset": 117, "endOffset": 121}, {"referenceID": 23, "context": "The global organization of our model combines Baddeley's model of the working memory [20-22] with ideas from Cowan's [23] and from Oberauer's [25] models.", "startOffset": 142, "endOffset": 146}, {"referenceID": 36, "context": "[39,40].", "startOffset": 0, "endOffset": 7}, {"referenceID": 37, "context": "[39,40].", "startOffset": 0, "endOffset": 7}, {"referenceID": 36, "context": "The questions used in the people dataset are also inspired by the work of Rescorla [39,40], and they are appropriate for a preschool child, as in the following examples: what does your father do? what games do you like? do you have a sister? is Dad older than Mum? etc.", "startOffset": 83, "endOffset": 90}, {"referenceID": 37, "context": "The questions used in the people dataset are also inspired by the work of Rescorla [39,40], and they are appropriate for a preschool child, as in the following examples: what does your father do? what games do you like? do you have a sister? is Dad older than Mum? etc.", "startOffset": 83, "endOffset": 90}, {"referenceID": 38, "context": "The fourth session is devoted to communicative interactions, and it is based on a mother/child dialogue extracted from the Warren-Leubecker corpus [41,42], which is part of the CHILDES database [43].", "startOffset": 147, "endOffset": 154}, {"referenceID": 39, "context": "The fourth session is devoted to communicative interactions, and it is based on a mother/child dialogue extracted from the Warren-Leubecker corpus [41,42], which is part of the CHILDES database [43].", "startOffset": 194, "endOffset": 198}, {"referenceID": 39, "context": "68 for our system (this analysis was performed using the CLAN program [43] ).", "startOffset": 70, "endOffset": 74}, {"referenceID": 36, "context": "3 have been chosen according to the purpose of this work, based on the literature on early language assessment [39-43].", "startOffset": 111, "endOffset": 118}, {"referenceID": 37, "context": "3 have been chosen according to the purpose of this work, based on the literature on early language assessment [39-43].", "startOffset": 111, "endOffset": 118}, {"referenceID": 38, "context": "3 have been chosen according to the purpose of this work, based on the literature on early language assessment [39-43].", "startOffset": 111, "endOffset": 118}, {"referenceID": 39, "context": "3 have been chosen according to the purpose of this work, based on the literature on early language assessment [39-43].", "startOffset": 111, "endOffset": 118}, {"referenceID": 40, "context": "We can distinguish two types of generalization [44]: 1) handling learned grammatical constructions with new open-class words; 2) compositional generalization, i.", "startOffset": 47, "endOffset": 51}, {"referenceID": 41, "context": "[45].", "startOffset": 0, "endOffset": 4}, {"referenceID": 42, "context": "For this experiment we used a dataset of 462 distinct grammatical constructions developed by Hinaut and Dominey [46], who used a context free grammar to generate systematically distinct grammatical constructions, each consisting of between 1 and 6 nouns, with 1 to 2 levels of hierarchical structure (i.", "startOffset": 112, "endOffset": 116}, {"referenceID": 42, "context": "[46], the compositional generalization capacity of our model was tested in a ten-fold cross-validation.", "startOffset": 0, "endOffset": 4}, {"referenceID": 43, "context": "Many researchers argued that a true understanding can not be achieved if language is not grounded in the agent's physical environment through actions and perceptions [47].", "startOffset": 166, "endOffset": 170}, {"referenceID": 44, "context": "[48], Cangelosi and Schlesinger [49] highlighted the role of embodiment in early language development.", "startOffset": 0, "endOffset": 4}, {"referenceID": 45, "context": "[48], Cangelosi and Schlesinger [49] highlighted the role of embodiment in early language development.", "startOffset": 32, "endOffset": 36}, {"referenceID": 46, "context": "Boucher [50] argued that we learn to translate the surface form of language into a functional form through the integration of speech inputs and non-speech inputs.", "startOffset": 8, "endOffset": 12}, {"referenceID": 44, "context": "visual input and action capabilities) would lead to the extension of the model for handling the developmental stages in the grounding and acquisition of language [48].", "startOffset": 162, "endOffset": 166}, {"referenceID": 45, "context": "The system could then be used as a language module for artificial systems ready to participate to real children educational settings, as well for interactive robot systems [49].", "startOffset": 172, "endOffset": 176}], "year": 2015, "abstractText": "Communicative interactions involve a kind of procedural knowledge that is used by the human brain for the elaboration of verbal and nonverbal inputs and for language production. Although considerable work has been done on modeling human language abilities, it has been difficult to bring them together to a comprehensive tabula rasa system. This work presents a cognitive system, entirely based on a large-scale neural architecture, which was developed to shed light on how the procedural knowledge involved in language elaboration arises from neural processes. The main component of this system is the central executive, which is a supervising system that coordinates the other components of the working memory. In our model, the central executive is a neural network that takes as input the neural activation states of the short-term memory and yields as output mental actions, which control the flow of information among the working memory components through neural gating mechanisms. The proposed system is capable of learning to communicate through natural language starting from tabula rasa, without any a priori knowledge of the structure of phrases, meaning of words, role of the different classes of words, only by interacting with a human through a text-based interface, using an open-ended incremental learning process. It is able to learn nouns, verbs, adjectives, pronouns and other word classes, to use them in sentences and to generalize this knowledge both in receptive and expressive language. The model was validated on a corpus of 1587 input sentences, based on literature on early language assessment, at the level of about 4-years old child, and produced 521 output sentences, expressing a broad range of functionalities that characterize human communication in language elaboration.", "creator": "Writer"}}}