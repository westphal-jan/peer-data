{"id": "1506.03338", "review": {"conference": "NIPS", "VERSION": "v1", "DATE_OF_SUBMISSION": "10-Jun-2015", "title": "Neural Adaptive Sequential Monte Carlo", "abstract": "cascade statistical methods ( smc ), principally particle filtering, was a popular class of learning capable enhancing automatically stable intractable target distribution following a sequence of simpler intermediate distributions. considering other importance entropy - based methods, coverage is ideally measured on adaptive proposal distribution : a bad result can cause several arbitrarily inaccurate estimates concerning the target chosen. published paper presents a consistent method fully automatically controlling allocation proposal using an approximation utilizing general kullback - leibler transform between optimal true population and acceptable estimates size. filter method feels very flexible, cutting below any parameterised proposal implemented wherever it creates slow and robust populations. we devised yet new models to deploy powerful distribution techniques with mutual uncertainty unlike progressive neural networks liberated from neural adaptive sequential problem carlo ( nasmc ). simulations indicate that nasmc significantly improves inference in a non - linear state space model outperforming adaptive proposal methods on the extended kalman and fuzzy gibbs data. analysis also indicate that noise inference transformed into improved parameter learning when nasmc is used as a subroutine of integrated computational metropolis hastings. finally we imply either nasmc is able to train a neural network - accelerated single recurrent noise model achieving results regularly intersect with ordinary state - of - the - art sequential polymorphic nonlinear modelling. experiment further be seen as bridging linear gap between adaptive estimation optimization and the simpler work in extended, black - box variational inference.", "histories": [["v1", "Wed, 10 Jun 2015 14:52:09 GMT  (403kb)", "https://arxiv.org/abs/1506.03338v1", null], ["v2", "Thu, 11 Jun 2015 07:11:56 GMT  (403kb)", "http://arxiv.org/abs/1506.03338v2", null], ["v3", "Mon, 16 Nov 2015 21:28:48 GMT  (408kb)", "http://arxiv.org/abs/1506.03338v3", null]], "reviews": [], "SUBJECTS": "cs.LG stat.ML", "authors": ["shixiang gu", "zoubin ghahramani", "richard e turner"], "accepted": true, "id": "1506.03338"}, "pdf": {"name": "1506.03338.pdf", "metadata": {"source": "CRF", "title": "Neural Adaptive Sequential Monte Carlo", "authors": ["Shixiang Gu Zoubin Ghahramani", "Richard E. Turner"], "emails": ["sg717@cam.ac.uk,", "zoubin@eng.cam.ac.uk,", "ret26@cam.ac.uk"], "sections": [{"heading": null, "text": "ar X\niv :1\n50 6.\n03 33\n8v 3\n[ cs\n.L G\n] 1\n6 N\nov 2"}, {"heading": "1 Introduction", "text": "Sequential Monte Carlo (SMC) is a class of algorithms that draw samples from a target distribution of interest by sampling from a series of simpler intermediate distributions. More specifically, the sequence constructs a proposal for importance sampling (IS) [1, 2]. SMC is particularly well-suited for performing inference in non-linear dynamical models with hidden variables, since filtering naturally decomposes into a sequence, and in many such cases it is the state-of-the-art inference method [2, 3]. Generally speaking, inference methods can be used as modules in parameter learning systems. SMC has been used in such a way for both approximate maximum-likelihood parameter learning [4] and in Bayesian approaches such as the recently developed Particle MCMC methods [3].\nCritically, in common with any importance sampling method, the performance of SMC is strongly dependent on the choice of the proposal distribution. If the proposal is not well-matched to the target distribution, then the method can produce samples that have low effective sample size and this leads to Monte Carlo estimates that have pathologically high variance [1]. The SMC community has developed approaches to mitigate these limitations such as resampling to improve particle diversity when the effective sample size is low [1] and applying MCMC transition kernels to improve particle diversity [5, 2, 3]. A complementary line of research leverages distributional approximate inference methods, such as the extended Kalman Filter and Unscented Kalman Filter, to construct better proposals, leading to the Extended Kalman Particle Filter (EKPF) and Unscented Particle Fil-\nter (UPF) [5]. In general, however, the construction of good proposal distributions is still an open question that severely limits the applicability of SMC methods.\nThis paper proposes a new gradient-based black-box adaptive SMC method that automatically tunes flexible proposal distributions. The quality of a proposal distribution can be assessed using the (intractable) Kullback-Leibler (KL) divergence between the target distribution and the parametrized proposal distribution. We approximate the derivatives of this objective using samples derived from SMC. The framework is very general and tractably handles complex parametric proposal distributions. For example, here we use neural networks to carry out the parameterization thereby leveraging the large literature and efficient computational tools developed by this community. We demonstrate that the method can efficiently learn good proposal distributions that significantly outperform existing adaptive proposal methods including the EKPF and UPF on standard benchmark models used in the particle filter community. We show that improved performance of the SMC algorithm translates into improved mixing of the Particle Marginal Metropolis-Hasting (PMMH) [3]. Finally, we show that the method allows higher-dimensional and more complicated models to be accurately handled using SMC, such as those parametrized using neural networks (NN), that are challenging for traditional particle filtering methods .\nThe focus of this work is on improving SMC, but many of the ideas are inspired by the burgeoning literature on approximate inference for unsupervised neural network models. These connections are explored in section 6."}, {"heading": "2 Sequential Monte Carlo", "text": "We begin by briefly reviewing two fundamental SMC algorithms, sequential importance sampling (SIS) and sequential importance resampling (SIR). Consider a probabilistic model comprising (possibly multi-dimensional) hidden and observed states z1:T and x1:T respectively, whose joint distribution factorizes as p(z1:T ,x1:T ) = p(z1)p(x1|z1) \u220fT t=2 p(zt|z1:t\u22121)p(xt|z1:t,x1:t\u22121). This general form subsumes common state-space models, such as Hidden Markov Models (HMMs), as well as non-Markovian models for the hidden state, such as Gaussian processes.\nThe goal of the sequential importance sampler is to approximate the posterior distribution over the hidden state sequence, p(z1:T |x1:T ) \u2248 \u2211N n=1 w\u0303 (n) t \u03b4(z1:T \u2212 z(n)1:T ), through a weighted set of N sampled trajectories drawn from a simpler proposal distribution {z(n)1:T }n=1:N \u223c q(z1:T |x1:T ). Any form of proposal distribution can be used in principle, but a particularly convenient one takes the same factorisation as the true posterior q(z1:T |x1:T ) = q(z1|x1) \u220fT t=2 q(zt|z1:t\u22121,x1:t), with filtering dependence on x. A short derivation (see supplementary material) then shows that the normalized importance weights are defined by a recursion:\nw(z (n) 1:T ) =\np(z (n) 1:T ,x1:T ) q(z (n) 1:T |x1:T ) , w\u0303(z (n) 1:T ) = w(z (n) 1:T )\u2211 n w(z (n) 1:T ) \u221d w\u0303(z(n)1:T\u22121) p(z (n) T |z (n) 1:T\u22121)p(xT |z (n) 1:T ,x1:T\u22121) q(z (n) T |z (n) 1:T\u22121,x1:T )\nSIS is elegant as the samples and weights can be computed in sequential fashion using a single forward pass. However, na\u0131\u0308ve implementation suffers from a severe pathology: the distribution of importance weights often become highly skewed as t increases, with many samples attaining very low weight. To alleviate the problem, the Sequential Importance Resampling (SIR) algorithm [1] adds an additional step that resamples z(n)t at time t from a multinomial distribution given by w\u0303(z (n) 1:t ) and gives the new particles equal weight.\n1 This replaces degenerated particles that have low weight with samples that have more substantial importance weights without violating the validity of the method. SIR requires knowledge of the full trajectory of previous samples at each stage to draw the samples and compute the importance weights. For this reason, when carrying out resampling, each new particle needs to update its ancestry information. Letting a(n)\u03c4,t represent the ancestral index of particle n at time t for state z\u03c4 , where 1 \u2264 \u03c4 \u2264 t, and collecting these into the set A\n(n) t = {a(n)1,t , ..., a (n) t,t }, where a(i)\u03c4\u22121,t = a\n(a (i) \u03c4,t)\n\u03c4\u22121,\u03c4\u22121, the resampled trajectory can be denoted z (n) 1:t =\n{zA (n) t\u22121\n1:t\u22121, z (n) t } where z\nA (i) t 1:t = {z a (i) 1,t 1 , ..., z a (i) t,t\nt }. Finally, to lighten notation, we use the shorthand 1More advanced implementations resample only when the effective sample size falls below a threshold [2].\nw (n) t = w(z (n) 1:t ) for the weights. Note that, when employing resampling, these do not depend on the previous weights w(n)t\u22121 since resampling has given the previous particles uniform weight. The implementation of SMC is given by Algorithm 1 in the supplementary material."}, {"heading": "2.1 The Critical Role of Proposal Distributions in Sequential Monte Carlo", "text": "The choice of the proposal distribution in SMC is critical. Even when employing the resampling step, a poor proposal distribution will produce trajectories that, when traced backwards, quickly collapse onto a single ancestor. Clearly this represents a poor approximation to the true posterior p(z1:T |x1:T ). These effects can be mitigated by increasing the number of particles and/or applying more complex additional MCMC moves [5, 2], but these strategies increase the computational cost.\nThe conclusion is that the proposal should be chosen with care. The optimal choice for an unconstrained proposal that has access to all of the observed data at all times is the intractable posterior distribution q\u03c6(z1:T |x1:T ) = p\u03b8(z1:T |x1:T ). Given the restrictions imposed by the factorization, this becomes q(zt|z1:t\u22121,x1:t) = p(zt|z1:t\u22121,x1:t), which is still typically intractable. The bootstrap filter instead uses the prior q(zt|z1:t\u22121,x1:t) = p(zt|z1:t\u22121,x1:t\u22121) which is often tractable, but fails to incorporate information from the current observation xt. A halfway-house employs distributional approximate inference techniques to approximate p(zt|z1:t\u22121,x1:t). Examples include the EKPF and UPF [5]. However, these methods suffer from three main problems. First, the extended and unscented Kalman Filter from which these methods are derived are known to be inaccurate and poorly behaved for many problems outside of the SMC setting [6]. Second, these approximations must be applied on a sample by sample basis, leading to significant additional computational overhead. Third, neither approximation is tuned using an SMC-relevant criterion. In the next section we introduce a new method for adapting the proposal that addresses these limitations."}, {"heading": "3 Adapting Proposals by Descending the Inclusive KL Divergence", "text": "In this work the quality of the proposal distribution will be optimized using the inclusive KL-divergence between the true posterior distribution and the proposal, KL[p\u03b8(z1:T |x1:T )||q\u03c6(z1:T |x1:T )]. (Parameters are made explicit since we will shortly be interested in both adapting the proposal \u03c6 and learning the model \u03b8.) This objective is chosen for four main reasons. First, this is a direct measure of the quality of the proposal, unlike those typically used such as effective sample size. Second, if the true posterior lies in the class of distributions attainable by the proposal family then the objective has a global optimum at this point. Third, if the true posterior does not lie within this class, then this KL divergence tends to find proposal distributions that have higher entropy than the original which is advantageous for importance sampling (the exclusive KL is unsuitable for this reason [7]). Fourth, the derivative of the objective can be approximated efficiently using a sample based approximation that will now be described.\nThe gradient of the negative KL divergence with respect to the parameters of the proposal distribution takes a simple form,\n\u2212 \u2202 \u2202\u03c6\nKL[p\u03b8(z1:T |x1:T )||q\u03c6(z1:T |x1:T )] = \u222b p\u03b8(z1:T |x1:T ) \u2202\n\u2202\u03c6 log q\u03c6(z1:T |x1:T )dz1:T .\nThe expectation over the posterior can be approximated using samples from SMC. One option would use the weighted sample trajectories at the final time-step of SMC, but although asymptotically unbiased such an estimator would have high variance due to the collapse of the trajectories. An alternative, that reduces variance at the cost of introducing some bias, uses the intermediate ancestral trees i.e. a filtering approximation (see the supplementary material for details),\n\u2212 \u2202 \u2202\u03c6 KL[p\u03b8(z1:T |x1:T )||q\u03c6(z1:T |x1:T )] \u2248 \u2211 t \u2211 n w\u0303 (n) t \u2202 \u2202\u03c6 log q\u03c6(z (n) t |x1:t, z A (n) t\u22121 1:t\u22121). (1)\nThe simplicity of the proposed approach brings with it several advantages and opportunities.\nOnline and batch variants. Since the derivatives distribute over time, it is trivial to apply this update in an online way e.g. updating the proposal distribution every time-step. Alternatively, when learning parameters in a batch setting, it might be more appropriate to update the proposal parameters after making a full forward pass of SMC. Conveniently, when performing approximate\nmaximum-likelihood learning the gradient update for the model parameters \u03b8 can be efficiently approximated using the same sample particles from SMC (see supplementary material and Algorithm 1). A similar derivation for maximum likelihood learning is also discussed in [4].\n\u2202\n\u2202\u03b8 log[p\u03b8(x1:T )] \u2248 \u2211 t \u2211 n w\u0303 (n) t \u2202 \u2202\u03b8 log p\u03b8(xt, z (n) t |x1:t\u22121, z A (n) t\u22121 1:t\u22121). (2)\nAlgorithm 1 Stochastic Gradient Adaptive SMC (batch inference and learning variants)\nRequire: proposal: q\u03c6, model: p\u03b8 , observations: X = {x1:Tj}j=1:M , number of particles: N repeat {x(j)1:Tj}j=1:m \u2190 NextMiniBatch(X) {z(i,j)1:t , w\u0303 (i,j) t }i=1:N,j=1:m,t=1:Tj \u2190 SMC(\u03b8, \u03c6,N, {x(j)1:Tj}j=1:m)\n\u25b3\u03c6 = \u2211j \u2211Tjt=1 \u2211i w\u0303(i,j)t \u2202\u2202\u03c6 log q\u03c6(z(i,j)t |x(j)1:t , zA (i,j) t\u22121 1:t\u22121 ) \u25b3\u03b8 = \u2211j \u2211Tjt=1 \u2211i w\u0303(i,j)t \u2202\u2202\u03b8 log p\u03b8(x(j)t , z(i,j)t |x(j)1:t\u22121, zA (i,j) t\u22121\n1:t\u22121 ) (optional) \u03c6 \u2190 Optimize(\u03c6,\u25b3\u03c6) \u03b8 \u2190 Optimize(\u03b8,\u25b3\u03b8) (optional)\nuntil convergence\nEfficiency of the adaptive proposal. In contrast to the EPF and UPF, the new method employs an analytic function for propagation and does not require costly particle-specific distributional approximation as an inner-loop. Similarly, although the method bears similarity to the assumed-density filter (ADF) [8] which minimizes a (local) inclusive KL, the new method has the advantage of minimizing a global cost and does not require particle-specific moment matching.\nTraining complex proposal models. The adaptation method described above can be applied to any parametric proposal distribution. Special cases have been previously treated by [9]. We propose a related, but arguably more straightforward and general approach to proposal adaptation. In the next section, we describe a rich family of proposal distributions, that go beyond previous work, based upon neural networks. This approach enables adaptive SMC methods to make use of the rich literature and optimization tools available from supervised learning.\nFlexibility of training. One option is to train the proposal distribution using samples from SMC derived from the observed data. However, this is not the only approach. For example, the proposal could be trained using data sampled from the generative model instead, which might mitigate overfitting effects for small datasets. Similarly, the trained proposal does not need to be the one used to generate the samples in the first place. The bootstrap filter or more complex variants can be used."}, {"heading": "4 Flexible and Trainable Proposal Distributions Using Neural Networks", "text": "The proposed adaption method can be applied to any parametric proposal distribution. Here we briefly describe how to utilize this flexibility to employ powerful neural network-based parameterizations that have recently shown excellent performance in supervised sequence learning tasks [10, 11]. Generally speaking, applications of these techniques to unsupervised sequence modeling settings is an active research area that is still in its infancy [12] and this work opens a new avenue in this wider research effort.\nIn a nutshell, the goal is to parameterize q\u03c6(zt|z1:t\u22121,x1:t) \u2013 the proposal\u2019s stochastic mapping from all previous hidden states z1:t\u22121 and all observations (up to and including the current observation) x1:t, to the current hidden state, zt \u2013 in a flexible, computationally efficient and trainable way. Here we use a class of functions called Long Short-Term Memory (LSTM) that define a deterministic mapping from an input sequence to an output sequence using parameter-efficient recurrent dynamics, and alleviate the common vanishing gradient problem in recurrent neural networks [13, 10, 11]. The distributions q\u03c6(zt|ht) can be a mixture of Gaussians (a mixture density network (MDN) [14]) in which the mixing proportions, means and covariances are parameterised through another neural network (see the supplementary for details on LSTM, MDN, and neural network architectures)."}, {"heading": "5 Experiments", "text": "The goal of the experiments is three fold. First, to evaluate the performance of the adaptive method for inference on standard benchmarks used by the SMC community with known ground truth. Second, to evaluate the performance when SMC is used as an inner loop of a learning algorithm. Again we use an example with known ground truth. Third, to apply SMC learning to complex models that would normally be challenging for SMC comparing to the state-of-the-art in approximate inference.\nOne way of assessing the success of the proposed method would be to evaluate KL[p(z1:T |x1:T )||q(z1:T |x1:T )]. However, this quantity is hard to accurately compute. Instead we use a number of other metrics. For the experiments where ground truth states z1:T are known we can evaluate the root mean square error (RMSE) between the approximate posterior mean of the latent variables (z\u0304t) and the true value RMSE(z1:T , z\u03041:T ) = ( 1T \u2211 t(zt \u2212 z\u0304t)2)1/2. More gener-\nally, the estimate of the log-marginal likelihood (LML = log p(x1:T ) = \u2211\nt log p(xt|x1:t\u22121) =\u2211 t log( 1 N \u2211 n w (n) t )) and its variance is also indicative of performance. Finally, we also employ a common metric called the effective sample size (ESS) to measure the effectiveness of our SMC method. ESS of particles at time t is given by ESSt = ( \u2211 n(w\u0303 (n) t )\n2)\u22121. If q(z1:T |x1:T ) = p(z1:T |x1:T ), expected ESS is maximized and equals the number of particles (equivalently, the normalized importance weights are uniform). Note that ESS alone is not a sufficient metric, since it does not measure the absolute quality of samples, but rather the relative quality."}, {"heading": "5.1 Inference in a Benchmark Nonlinear State-Space Model", "text": "In order to evaluate the effectiveness of our adaptive SMC method, we tested our method on a standard nonlinear state-space model often used to benchmark SMC algorithms [2, 3]. The model is given by Eq. 3, where \u03b8 = (\u03c3v, \u03c3w). The posterior distribution p\u03b8(z1:T |x1:T ) is highly multi-modal due to uncertainty about the signs of the latent states.\np(zt|zt\u22121) = N (zt; f(zt\u22121, t), \u03c32v), p(z1) = N (z1; 0, 5), p(xt|zt) = N (xt; g(zt\u22121), \u03c32w), f(zt\u22121, t) = zt\u22121/2 + 25zt\u22121/(1 + z 2 t\u22121) + 8 cos(1.2t), g(zt) = z 2 t /20\n(3)\nThe experiments investigated how the new proposal adaptation method performed in comparison to standard methods including the bootstrap filter, EKPF, and UKPF. In particular, we were interested in the following questions: Do rich multi-modal proposals improve inference? For this we compared a Gaussian proposal with a diagonal Gaussian to a mixture density network with three components (- MD-). Does a recurrent parameterization of the proposal help? For this we compared a non-recurrent neural network with 100 hidden units (-NN-) to a recurrent neural network with 50 LSTM units (- RNN-). Can injecting information about the prior dynamics into the proposal improve performance (similar in spirit to [15] for variational methods)? To assess this, we parameterized proposals for vt (process noise) instead of zt (-f-), and let the proposal have access to the prior dynamics f(zt\u22121, t) .\nFor all experiments, the parameters in the non-linear state-space model were fixed to (\u03c3v, \u03c3w) = ( \u221a 10, 1). Adaptation of the proposal was performed on 1000 samples from the generative process at each iteration. Results are summarized in Fig. 1 and Table 1 (see supplementary material for additional results). Average run times for the algorithms over a sequence of length 1000 were: 0.782s bootstrap, 12.1s EKPF, 41.4s UPF, 1.70s NN-NASMC, and 2.67s RNN-NASMC, where EKPF and UPF implementations are provided by [5]. Although these numbers should only be taken as a guide as the implementations had differing levels of acceleration.\nThe new adaptive proposal methods significantly outperform the bootstrap, EKPF, and UPF methods, in terms of ESS, RMSE and the variance in the LML estimates. The multi-modal proposal outperforms a simple Gaussian proposal (compare RNN-MD-f to RNN-f) indicating multi-modal proposals can improve performance. Moreover, the RNN outperforms the non-recurrent NN (compare RNN to NN). Although the proposal models can effectively learn the transition function, injecting information about the prior dynamics into the proposal does help (compare RNN-f to RNN). Interestingly, there is no clear cut winner between the EKPF and UPF, although the UPF does return LML estimates that have lower variance [5]. All methods converged to similar LMLs that were close to the values computed using large numbers of particles indicating the implementations are correct."}, {"heading": "5.2 Inference in the Cart and Pole System", "text": "As a second and more physically meaningful system we considered a cart-pole system that consists of an inverted pendulum that rests on a movable base [16]. The system was driven by a white noise input. An ODE solver was used to simulate the system from its equations of motion. We considered the problem of inferring the true position of the cart and orientation of the pendulum (along with their derivatives and the input noise) from noisy measurements of the location of the tip of the pole. The results are presented in Fig. 2. The system is significantly more intricate than the model in Sec. 5.1, and does not directly admit the usage of EKPF or UPF. Our RNN-MD proposal model successfully learns good proposals without any direct access to the prior dynamics."}, {"heading": "5.3 Bayesian learning in a Nonlinear SSM", "text": "SMC is often employed as an inner loop of a more complex algorithm. One prominent example is Particle Markov Chain Monte Carlo [3], a class of methods that sample from the joint posterior over model parameters \u03b8 and latent state trajectories, p(\u03b8, z1:T |x1:T ). Here we consider the Particle Marginal Metropolis-Hasting sampler (PMMH). In this context SMC is used to construct a proposal distribution for a Metropolis-Hasting (MH) accept/reject step. The proposal is formed by sampling a proposed set of parameters e.g. by perturbing the current parameters using a Gaussian random walk, then SMC is used to sample a proposed set of latent state variables, resulting in a joint proposal q(\u03b8\u2217, z\u22171:T |\u03b8, z1:T ) = q(\u03b8\u2217|\u03b8)p\u03b8\u2217(z\u22171:T |x1:T ). The MH step uses the SMC marginal likelihood estimates to determine acceptance. Full details are given in the supplementary material.\nIn this experiment, we evaluate our method in a PMMH sampler on the same model from Section 5.1 following [3].2 A random walk proposal is used to sample \u03b8 = (\u03c3v, \u03c3w), q(\u03b8\u2217|\u03b8) = N (\u03b8\u2217|\u03b8, diag([0.15, 0.08])). The prior over \u03b8 is set as IG(0.01, 0.01). \u03b8 is initialized as (10, 10), and the PMMH is run for 500 iterations.\nTwo of the adaptive models considered section 5.1 are used for comparison (RNN-MD and RNNMD-f) , where \u201c-pre-\u201d models are pre-trained for 500 iterations using samples from the initial \u03b8 = (10, 10). The results are shown in Fig. 3 and were typical for a range of parameter settings. Given a sufficient number of particles (N = 100), there is almost no difference between the prior proposal and our method. However, when the number of particles gets smaller (N = 10), NASMC enables significantly faster burn-in to the posterior, particularly on the measurement noise \u03c3w and, for similar reasons, NASMC mixes more quickly. The limitation with the NASMC-PMMH is that the model needs to continuously adapt as the global parameter is sampled, but note this is still not as costly as adapting on a particle-by-particle basis as is the case for the EKPF and UPF."}, {"heading": "5.4 Polyphonic Music Generation", "text": "Finally, the new method is used to train a latent variable recurrent neural network (LV-RNN) for modelling four polymorphic music datasets of varying complexity [17]. These datasets are often used to benchmark RNN models because of their high dimensionality and the complex temporal dependencies involved at different time scales [17, 18, 19]. Each dataset contains at least 7 hours of polyphonic music with an average polyphony (number of simultaneous notes) of 3.9 out of 88. LVRNN contains a recurrent neural network with LSTM layers that is driven by i.i.d. stochastic latent variables (zt) at each time-point and stochastic outputs (xt) that are fed back into the dynamics (full details in the supplementary material). Both the LSTM layers in the generative and proposal models are set as 1000 units and Adam [20] is used as the optimizer. The bootstrap filter is compared to the new adaptive method (NASMC). 10 particles are used in the training. The hyperparameters are tuned using the validation set [17]. A diagonal Gaussian output is used in the proposal model, with an additional hidden layer of size 200. The log likelihood on the test set, a standard metric for comparison in generative models [18, 21, 19], is approximated using SMC with 500 particles.\n2Only the prior proposal is compared, since Sec. 5.1 shows the advantage of our method over EKPF/UPF.\nThe results are reported in Table 2.3 The adaptive method significantly outperforms the bootstrap filter on three of the four datasets. On the piano dataset the bootstrap method performs marginally better. In general, the NLLs for the new methods are comparable to the state-of-the-art although detailed comparison is difficult as the methods with stochastic latent states require approximate marginalization using importance sampling or SMC."}, {"heading": "6 Comparison of Variational Inference to the NASMC approach", "text": "There are several similarities between NASMC and Variational Free-energy methods that employ recognition models. Variational Free-energy methods refine an approximation q\u03c6(z|x) to the posterior distribution p\u03b8(z|x) by optimising the exclusive (or variational) KL-divergence KL[q\u03c6(z|x)||p\u03b8(z|x)]. It is common to approximate this integral using samples from the approximate posterior [21, 22, 23]. This general approach is similar in spirit to the way that the proposal is adapted in NASMC, except that the inclusive KL-divergence is employedKL[p\u03b8(z|x)||q\u03c6(z|x)] and this entails that sample based approximation requires simulation from the true posterior. Critically, NASMC uses the approximate posterior as a proposal distribution to construct a more accurate posterior approximation. The SMC algorithm therefore can be seen as correcting for the deficiencies in the proposal approximation. We believe that this can lead to significant advantages over variational free-energy methods, especially in the time-series setting where variational methods are known to have severe biases [24]. Moreover, using the inclusive KL avoids having to compute the entropy of the approximating distribution which can prove problematic when using complex approximating distributions (e.g. mixtures and heavy tailed distributions) in the variational framework. There is a close connection between NASMC and the wake-sleep algorithm [25] . The wake-sleep algorithm also employs the inclusive KL divergence to refine a posterior approximation and recent generalizations have shown how to incorporate this idea into importance sampling [26]. In this context, the NASMC algorithm extends this work to SMC."}, {"heading": "7 Conclusion", "text": "This paper developed a powerful method for adapting proposal distributions within general SMC algorithms. The method parameterises a proposal distribution using a recurrent neural network to model long-range contextual information, allows flexible distributional forms including mixture density networks, and enables efficient training by stochastic gradient descent. The method was found to outperform existing adaptive proposal mechanisms including the EKPF and UPF on a standard SMC benchmark, it improves burn in and mixing of the PMMH sampler, and allows effective training of latent variable recurrent neural networks using SMC. We hope that the connection between SMC and neural network technologies will inspire further research into adaptive SMC methods. In particular, application of the methods developed in this paper to adaptive particle smoothing, high-dimensional latent models and adaptive PMCMC for probabilistic programming are particular exciting avenues."}, {"heading": "Acknowledgments", "text": "SG is generously supported by Cambridge-Tu\u0308bingen Fellowship, the ALTA Institute, and Jesus College, Cambridge. RET thanks the EPSRC (grants EP/G050821/1 and EP/L000776/1). We thank Theano developers for their toolkit, the authors of [5] for releasing the source code, and Roger Frigola, Sumeet Singh, Fredrik Lindsten, and Thomas Scho\u0308n for helpful suggestions on experiments.\n3Results for RNN-NADE are separately provided for reference, since this is a different model class."}], "references": [{"title": "Novel approach to nonlinear/non-gaussian bayesian state estimation", "author": ["N.J. Gordon", "D.J. Salmond", "A.F. Smith"], "venue": "IEE Proceedings F (Radar and Signal Processing), vol. 140, pp. 107\u2013113, IET, 1993.", "citeRegEx": "1", "shortCiteRegEx": null, "year": 1993}, {"title": "Sequential monte carlo methods in practice", "author": ["A. Doucet", "N. De Freitas", "N. Gordon"], "venue": null, "citeRegEx": "2", "shortCiteRegEx": "2", "year": 2001}, {"title": "Particle markov chain monte carlo methods", "author": ["C. Andrieu", "A. Doucet", "R. Holenstein"], "venue": "Journal of the Royal Statistical Society: Series B (Statistical Methodology), vol. 72, no. 3, pp. 269\u2013342, 2010.", "citeRegEx": "3", "shortCiteRegEx": null, "year": 2010}, {"title": "Particle approximations of the score and observed information matrix in state space models with application to parameter estimation", "author": ["G. Poyiadjis", "A. Doucet", "S.S. Singh"], "venue": "Biometrika, vol. 98, no. 1, pp. 65\u2013 80, 2011.", "citeRegEx": "4", "shortCiteRegEx": null, "year": 2011}, {"title": "The unscented particle filter", "author": ["R. Van Der Merwe", "A. Doucet", "N. De Freitas", "E. Wan"], "venue": "Advances in Neural Information Processing Systems, pp. 584\u2013590, 2000.", "citeRegEx": "5", "shortCiteRegEx": null, "year": 2000}, {"title": "Variational gaussian process state-space models", "author": ["R. Frigola", "Y. Chen", "C. Rasmussen"], "venue": "Advances in Neural Information Processing Systems, pp. 3680\u20133688, 2014.", "citeRegEx": "6", "shortCiteRegEx": null, "year": 2014}, {"title": "Information theory, inference, and learning", "author": ["D.J. MacKay"], "venue": null, "citeRegEx": "7", "shortCiteRegEx": "7", "year": 2003}, {"title": "Expectation propagation for approximate bayesian inference", "author": ["T.P. Minka"], "venue": "Proceedings of the Seventeenth conference on Uncertainty in artificial intelligence, pp. 362\u2013369, Morgan Kaufmann Publishers Inc., 2001.", "citeRegEx": "8", "shortCiteRegEx": null, "year": 2001}, {"title": "Adaptive Sequential Monte Carlo Methods", "author": ["J. Cornebise"], "venue": "PhD thesis,", "citeRegEx": "9", "shortCiteRegEx": "9", "year": 2009}, {"title": "Supervised sequence labelling with recurrent neural networks, vol. 385", "author": ["A. Graves"], "venue": null, "citeRegEx": "10", "shortCiteRegEx": "10", "year": 2012}, {"title": "Sequence to sequence learning with neural networks", "author": ["I. Sutskever", "O. Vinyals", "Q.V. Le"], "venue": "Advances in Neural Information Processing Systems, pp. 3104\u20133112, 2014.", "citeRegEx": "11", "shortCiteRegEx": null, "year": 2014}, {"title": "Generating sequences with recurrent neural networks", "author": ["A. Graves"], "venue": "CoRR, vol. abs/1308.0850, 2013.", "citeRegEx": "12", "shortCiteRegEx": null, "year": 2013}, {"title": "Long short-term memory", "author": ["S. Hochreiter", "J. Schmidhuber"], "venue": "Neural computation, vol. 9, no. 8, pp. 1735\u20131780, 1997.", "citeRegEx": "13", "shortCiteRegEx": null, "year": 1997}, {"title": "Mixture density networks", "author": ["C.M. Bishop"], "venue": "1994.", "citeRegEx": "14", "shortCiteRegEx": null, "year": 1994}, {"title": "DRAW: A recurrent neural network for image generation", "author": ["K. Gregor", "I. Danihelka", "A. Graves", "D.J. Rezende", "D. Wierstra"], "venue": "Proceedings of the 32nd International Conference on Machine Learning, ICML 2015, Lille, France, 6-11 July 2015, pp. 1462\u20131471, 2015.", "citeRegEx": "15", "shortCiteRegEx": null, "year": 2015}, {"title": "Nonlinear modelling and control using Gaussian processes", "author": ["A. McHutchon"], "venue": "PhD thesis,", "citeRegEx": "16", "shortCiteRegEx": "16", "year": 2014}, {"title": "Modeling temporal dependencies in highdimensional sequences: Application to polyphonic music generation and transcription", "author": ["N. Boulanger-Lewandowski", "Y. Bengio", "P. Vincent"], "venue": "International Conference on Machine Learning (ICML), 2012.", "citeRegEx": "17", "shortCiteRegEx": null, "year": 2012}, {"title": "Advances in optimizing recurrent networks", "author": ["Y. Bengio", "N. Boulanger-Lewandowski", "R. Pascanu"], "venue": "Acoustics, Speech and Signal Processing (ICASSP), 2013 IEEE International Conference on, pp. 8624\u2013 8628, IEEE, 2013.", "citeRegEx": "18", "shortCiteRegEx": null, "year": 2013}, {"title": "Learning stochastic recurrent networks", "author": ["J. Bayer", "C. Osendorfer"], "venue": "arXiv preprint arXiv:1411.7610, 2014.", "citeRegEx": "19", "shortCiteRegEx": null, "year": 2014}, {"title": "Adam: A method for stochastic optimization", "author": ["D.P. Kingma", "J. Ba"], "venue": "The International Conference on Learning Representations (ICLR), 2015.", "citeRegEx": "20", "shortCiteRegEx": null, "year": 2015}, {"title": "Auto-encoding variational bayes", "author": ["D.P. Kingma", "M. Welling"], "venue": "The International Conference on Learning Representations (ICLR), 2014.", "citeRegEx": "21", "shortCiteRegEx": null, "year": 2014}, {"title": "Stochastic backpropagation and approximate inference in deep generative models", "author": ["D.J. Rezende", "S. Mohamed", "D. Wierstra"], "venue": "International Conference on Machine Learning (ICML), 2014.", "citeRegEx": "22", "shortCiteRegEx": null, "year": 2014}, {"title": "Neural variational inference and learning in belief networks", "author": ["A. Mnih", "K. Gregor"], "venue": "International Conference on Machine Learning (ICML), 2014.", "citeRegEx": "23", "shortCiteRegEx": null, "year": 2014}, {"title": "Two problems with variational expectation maximisation for time-series models", "author": ["R.E. Turner", "M. Sahani"], "venue": "Bayesian Time series models (D. Barber, T. Cemgil, and S. Chiappa, eds.), ch. 5, pp. 109\u2013 130, Cambridge University Press, 2011.", "citeRegEx": "24", "shortCiteRegEx": null, "year": 2011}, {"title": "The\u201d wake-sleep\u201d algorithm for unsupervised neural networks", "author": ["G.E. Hinton", "P. Dayan", "B.J. Frey", "R.M. Neal"], "venue": "Science, vol. 268, no. 5214, pp. 1158\u20131161, 1995.", "citeRegEx": "25", "shortCiteRegEx": null, "year": 1995}, {"title": "Reweighted wake-sleep", "author": ["J. Bornschein", "Y. Bengio"], "venue": "The International Conference on Learning Representations (ICLR), 2015. 9", "citeRegEx": "26", "shortCiteRegEx": null, "year": 2015}], "referenceMentions": [{"referenceID": 0, "context": "More specifically, the sequence constructs a proposal for importance sampling (IS) [1, 2].", "startOffset": 83, "endOffset": 89}, {"referenceID": 1, "context": "More specifically, the sequence constructs a proposal for importance sampling (IS) [1, 2].", "startOffset": 83, "endOffset": 89}, {"referenceID": 1, "context": "SMC is particularly well-suited for performing inference in non-linear dynamical models with hidden variables, since filtering naturally decomposes into a sequence, and in many such cases it is the state-of-the-art inference method [2, 3].", "startOffset": 232, "endOffset": 238}, {"referenceID": 2, "context": "SMC is particularly well-suited for performing inference in non-linear dynamical models with hidden variables, since filtering naturally decomposes into a sequence, and in many such cases it is the state-of-the-art inference method [2, 3].", "startOffset": 232, "endOffset": 238}, {"referenceID": 3, "context": "SMC has been used in such a way for both approximate maximum-likelihood parameter learning [4] and in Bayesian approaches such as the recently developed Particle MCMC methods [3].", "startOffset": 91, "endOffset": 94}, {"referenceID": 2, "context": "SMC has been used in such a way for both approximate maximum-likelihood parameter learning [4] and in Bayesian approaches such as the recently developed Particle MCMC methods [3].", "startOffset": 175, "endOffset": 178}, {"referenceID": 0, "context": "If the proposal is not well-matched to the target distribution, then the method can produce samples that have low effective sample size and this leads to Monte Carlo estimates that have pathologically high variance [1].", "startOffset": 215, "endOffset": 218}, {"referenceID": 0, "context": "The SMC community has developed approaches to mitigate these limitations such as resampling to improve particle diversity when the effective sample size is low [1] and applying MCMC transition kernels to improve particle diversity [5, 2, 3].", "startOffset": 160, "endOffset": 163}, {"referenceID": 4, "context": "The SMC community has developed approaches to mitigate these limitations such as resampling to improve particle diversity when the effective sample size is low [1] and applying MCMC transition kernels to improve particle diversity [5, 2, 3].", "startOffset": 231, "endOffset": 240}, {"referenceID": 1, "context": "The SMC community has developed approaches to mitigate these limitations such as resampling to improve particle diversity when the effective sample size is low [1] and applying MCMC transition kernels to improve particle diversity [5, 2, 3].", "startOffset": 231, "endOffset": 240}, {"referenceID": 2, "context": "The SMC community has developed approaches to mitigate these limitations such as resampling to improve particle diversity when the effective sample size is low [1] and applying MCMC transition kernels to improve particle diversity [5, 2, 3].", "startOffset": 231, "endOffset": 240}, {"referenceID": 4, "context": "ter (UPF) [5].", "startOffset": 10, "endOffset": 13}, {"referenceID": 2, "context": "We show that improved performance of the SMC algorithm translates into improved mixing of the Particle Marginal Metropolis-Hasting (PMMH) [3].", "startOffset": 138, "endOffset": 141}, {"referenceID": 0, "context": "To alleviate the problem, the Sequential Importance Resampling (SIR) algorithm [1] adds an additional step that resamples z t at time t from a multinomial distribution given by w\u0303(z (n) 1:t ) and gives the new particles equal weight.", "startOffset": 79, "endOffset": 82}, {"referenceID": 1, "context": "Finally, to lighten notation, we use the shorthand More advanced implementations resample only when the effective sample size falls below a threshold [2].", "startOffset": 150, "endOffset": 153}, {"referenceID": 4, "context": "These effects can be mitigated by increasing the number of particles and/or applying more complex additional MCMC moves [5, 2], but these strategies increase the computational cost.", "startOffset": 120, "endOffset": 126}, {"referenceID": 1, "context": "These effects can be mitigated by increasing the number of particles and/or applying more complex additional MCMC moves [5, 2], but these strategies increase the computational cost.", "startOffset": 120, "endOffset": 126}, {"referenceID": 4, "context": "Examples include the EKPF and UPF [5].", "startOffset": 34, "endOffset": 37}, {"referenceID": 5, "context": "First, the extended and unscented Kalman Filter from which these methods are derived are known to be inaccurate and poorly behaved for many problems outside of the SMC setting [6].", "startOffset": 176, "endOffset": 179}, {"referenceID": 6, "context": "Third, if the true posterior does not lie within this class, then this KL divergence tends to find proposal distributions that have higher entropy than the original which is advantageous for importance sampling (the exclusive KL is unsuitable for this reason [7]).", "startOffset": 259, "endOffset": 262}, {"referenceID": 3, "context": "A similar derivation for maximum likelihood learning is also discussed in [4].", "startOffset": 74, "endOffset": 77}, {"referenceID": 7, "context": "Similarly, although the method bears similarity to the assumed-density filter (ADF) [8] which minimizes a (local) inclusive KL, the new method has the advantage of minimizing a global cost and does not require particle-specific moment matching.", "startOffset": 84, "endOffset": 87}, {"referenceID": 8, "context": "Special cases have been previously treated by [9].", "startOffset": 46, "endOffset": 49}, {"referenceID": 9, "context": "Here we briefly describe how to utilize this flexibility to employ powerful neural network-based parameterizations that have recently shown excellent performance in supervised sequence learning tasks [10, 11].", "startOffset": 200, "endOffset": 208}, {"referenceID": 10, "context": "Here we briefly describe how to utilize this flexibility to employ powerful neural network-based parameterizations that have recently shown excellent performance in supervised sequence learning tasks [10, 11].", "startOffset": 200, "endOffset": 208}, {"referenceID": 11, "context": "Generally speaking, applications of these techniques to unsupervised sequence modeling settings is an active research area that is still in its infancy [12] and this work opens a new avenue in this wider research effort.", "startOffset": 152, "endOffset": 156}, {"referenceID": 12, "context": "Here we use a class of functions called Long Short-Term Memory (LSTM) that define a deterministic mapping from an input sequence to an output sequence using parameter-efficient recurrent dynamics, and alleviate the common vanishing gradient problem in recurrent neural networks [13, 10, 11].", "startOffset": 278, "endOffset": 290}, {"referenceID": 9, "context": "Here we use a class of functions called Long Short-Term Memory (LSTM) that define a deterministic mapping from an input sequence to an output sequence using parameter-efficient recurrent dynamics, and alleviate the common vanishing gradient problem in recurrent neural networks [13, 10, 11].", "startOffset": 278, "endOffset": 290}, {"referenceID": 10, "context": "Here we use a class of functions called Long Short-Term Memory (LSTM) that define a deterministic mapping from an input sequence to an output sequence using parameter-efficient recurrent dynamics, and alleviate the common vanishing gradient problem in recurrent neural networks [13, 10, 11].", "startOffset": 278, "endOffset": 290}, {"referenceID": 13, "context": "The distributions q\u03c6(zt|ht) can be a mixture of Gaussians (a mixture density network (MDN) [14]) in which the mixing proportions, means and covariances are parameterised through another neural network (see the supplementary for details on LSTM, MDN, and neural network architectures).", "startOffset": 91, "endOffset": 95}, {"referenceID": 1, "context": "In order to evaluate the effectiveness of our adaptive SMC method, we tested our method on a standard nonlinear state-space model often used to benchmark SMC algorithms [2, 3].", "startOffset": 169, "endOffset": 175}, {"referenceID": 2, "context": "In order to evaluate the effectiveness of our adaptive SMC method, we tested our method on a standard nonlinear state-space model often used to benchmark SMC algorithms [2, 3].", "startOffset": 169, "endOffset": 175}, {"referenceID": 14, "context": "Can injecting information about the prior dynamics into the proposal improve performance (similar in spirit to [15] for variational methods)? To assess this, we parameterized proposals for vt (process noise) instead of zt (-f-), and let the proposal have access to the prior dynamics f(zt\u22121, t) .", "startOffset": 111, "endOffset": 115}, {"referenceID": 4, "context": "67s RNN-NASMC, where EKPF and UPF implementations are provided by [5].", "startOffset": 66, "endOffset": 69}, {"referenceID": 4, "context": "Interestingly, there is no clear cut winner between the EKPF and UPF, although the UPF does return LML estimates that have lower variance [5].", "startOffset": 138, "endOffset": 141}, {"referenceID": 15, "context": "As a second and more physically meaningful system we considered a cart-pole system that consists of an inverted pendulum that rests on a movable base [16].", "startOffset": 150, "endOffset": 154}, {"referenceID": 2, "context": "One prominent example is Particle Markov Chain Monte Carlo [3], a class of methods that sample from the joint posterior over model parameters \u03b8 and latent state trajectories, p(\u03b8, z1:T |x1:T ).", "startOffset": 59, "endOffset": 62}, {"referenceID": 2, "context": "1 following [3].", "startOffset": 12, "endOffset": 15}, {"referenceID": 16, "context": "Finally, the new method is used to train a latent variable recurrent neural network (LV-RNN) for modelling four polymorphic music datasets of varying complexity [17].", "startOffset": 161, "endOffset": 165}, {"referenceID": 16, "context": "These datasets are often used to benchmark RNN models because of their high dimensionality and the complex temporal dependencies involved at different time scales [17, 18, 19].", "startOffset": 163, "endOffset": 175}, {"referenceID": 17, "context": "These datasets are often used to benchmark RNN models because of their high dimensionality and the complex temporal dependencies involved at different time scales [17, 18, 19].", "startOffset": 163, "endOffset": 175}, {"referenceID": 18, "context": "These datasets are often used to benchmark RNN models because of their high dimensionality and the complex temporal dependencies involved at different time scales [17, 18, 19].", "startOffset": 163, "endOffset": 175}, {"referenceID": 19, "context": "Both the LSTM layers in the generative and proposal models are set as 1000 units and Adam [20] is used as the optimizer.", "startOffset": 90, "endOffset": 94}, {"referenceID": 16, "context": "The hyperparameters are tuned using the validation set [17].", "startOffset": 55, "endOffset": 59}, {"referenceID": 17, "context": "The log likelihood on the test set, a standard metric for comparison in generative models [18, 21, 19], is approximated using SMC with 500 particles.", "startOffset": 90, "endOffset": 102}, {"referenceID": 20, "context": "The log likelihood on the test set, a standard metric for comparison in generative models [18, 21, 19], is approximated using SMC with 500 particles.", "startOffset": 90, "endOffset": 102}, {"referenceID": 18, "context": "The log likelihood on the test set, a standard metric for comparison in generative models [18, 21, 19], is approximated using SMC with 500 particles.", "startOffset": 90, "endOffset": 102}, {"referenceID": 18, "context": "\u201cFD-RNN\u201d and \u201cSTORN\u201d are from [19], and \u201csRNN\u201d and \u201cRNN-NADE\u201d are results from [18].", "startOffset": 30, "endOffset": 34}, {"referenceID": 17, "context": "\u201cFD-RNN\u201d and \u201cSTORN\u201d are from [19], and \u201csRNN\u201d and \u201cRNN-NADE\u201d are results from [18].", "startOffset": 79, "endOffset": 83}, {"referenceID": 20, "context": "It is common to approximate this integral using samples from the approximate posterior [21, 22, 23].", "startOffset": 87, "endOffset": 99}, {"referenceID": 21, "context": "It is common to approximate this integral using samples from the approximate posterior [21, 22, 23].", "startOffset": 87, "endOffset": 99}, {"referenceID": 22, "context": "It is common to approximate this integral using samples from the approximate posterior [21, 22, 23].", "startOffset": 87, "endOffset": 99}, {"referenceID": 23, "context": "We believe that this can lead to significant advantages over variational free-energy methods, especially in the time-series setting where variational methods are known to have severe biases [24].", "startOffset": 190, "endOffset": 194}, {"referenceID": 24, "context": "There is a close connection between NASMC and the wake-sleep algorithm [25] .", "startOffset": 71, "endOffset": 75}, {"referenceID": 25, "context": "The wake-sleep algorithm also employs the inclusive KL divergence to refine a posterior approximation and recent generalizations have shown how to incorporate this idea into importance sampling [26].", "startOffset": 194, "endOffset": 198}, {"referenceID": 4, "context": "We thank Theano developers for their toolkit, the authors of [5] for releasing the source code, and Roger Frigola, Sumeet Singh, Fredrik Lindsten, and Thomas Sch\u00f6n for helpful suggestions on experiments.", "startOffset": 61, "endOffset": 64}], "year": 2015, "abstractText": "Sequential Monte Carlo (SMC), or particle filtering, is a popular class of methods for sampling from an intractable target distribution using a sequence of simpler intermediate distributions. Like other importance sampling-based methods, performance is critically dependent on the proposal distribution: a bad proposal can lead to arbitrarily inaccurate estimates of the target distribution. This paper presents a new method for automatically adapting the proposal using an approximation of the Kullback-Leibler divergence between the true posterior and the proposal distribution. The method is very flexible, applicable to any parameterized proposal distribution and it supports online and batch variants. We use the new framework to adapt powerful proposal distributions with rich parameterizations based upon neural networks leading to Neural Adaptive Sequential Monte Carlo (NASMC). Experiments indicate that NASMC significantly improves inference in a non-linear state space model outperforming adaptive proposal methods including the Extended Kalman and Unscented Particle Filters. Experiments also indicate that improved inference translates into improved parameter learning when NASMC is used as a subroutine of Particle Marginal Metropolis Hastings. Finally we show that NASMC is able to train a latent variable recurrent neural network (LV-RNN) achieving results that compete with the state-of-the-art for polymorphic music modelling. NASMC can be seen as bridging the gap between adaptive SMC methods and the recent work in scalable, black-box variational inference.", "creator": "LaTeX with hyperref package"}}}