{"id": "1506.04897", "review": {"conference": "arxiv", "VERSION": "v1", "DATE_OF_SUBMISSION": "16-Jun-2015", "title": "Parsing Natural Language Sentences by Semi-supervised Methods", "abstract": "we present our work establishing discrete - loop parsing at natural string sentences, while on multi - step crosslingual transfer of delexicalized dependency parsers. did first demonstrate chain propagation by treebank binding conditions on neural strength, focusing on pattern capture capability. then, we present nonlinear, numerical empirical communication competence measure, designed and tuned for continuous weight weighting amongst concurrent - source delexicalized parser transfer. and finally, from begin a complex verb combination method, providing onboard interpolation of conditional information models.", "histories": [["v1", "Tue, 16 Jun 2015 09:54:27 GMT  (59kb)", "http://arxiv.org/abs/1506.04897v1", "Dissertation interim report. Overlap with papers accepted to ACL 2015 and Depling 2015, and a paper under review at IWPT 2015"]], "COMMENTS": "Dissertation interim report. Overlap with papers accepted to ACL 2015 and Depling 2015, and a paper under review at IWPT 2015", "reviews": [], "SUBJECTS": "cs.CL", "authors": ["rudolf rosa"], "accepted": false, "id": "1506.04897"}, "pdf": {"name": "1506.04897.pdf", "metadata": {"source": "CRF", "title": null, "authors": [], "emails": ["rosa@ufal.mff.cuni.cz"], "sections": [{"heading": null, "text": "ar X\niv :1\n50 6.\n04 89\n7v 1\n[ cs\n.C L\n] 1\n6 Ju\nn 20\n15"}, {"heading": "1 Introduction", "text": "The problem of supervised dependency parsing of natural language sentences has been intensively studied for the past decade, especially since the invention of the graph-based MSTParser by McDonald et al. (2005a), and the transitionbased Malt parser by Nivre et al. (2006). The success of these parsing algorithms, together with several CoNLL shared tasks focused on dependency parsing (Buchholz and Marsi, 2006; Nilsson et al., 2007; Surdeanu et al., 2008; Hajic\u030c et al., 2009), even lead to a general transition from constituency parsing to dependency parsing throughout the NLP community. The current state-of-the-art dependency parsers, such as the Mate parser of Bohnet and Nivre (2012), often achieve around 90% UAS (Unlabelled Attachment Score) for many languages.\nThe supervised parsing approaches require labelled training data, i.e., manually created dependency treebanks. While these are available for dozens of languages (see Section 2), only around 1% of the world\u2019s languages are covered by treebanks. Moreover, treebank annotation is\ncostly, and it is not expected that most of the remaining languages will be processed any time soon, or ever. To make matters worse, the existing treebanks necessarily capture texts from limited domains and limited time periods only, and do not serve us well when we need to parse texts from a different domain, as shown e.g. by Gildea (2001). This naturally motivates research of semi-supervised or unsupervised parsing methods.\nIn our work, we focus on semi-supervised approaches to the multilinguality issue, investigating the possibilities of using the knowledge contained in treebanks for one or more source languages (src) to analyze sentences of a different target language (tgt).1 Specifically, we perform transfer of delexicalized dependency parsers \u2013 see Section 3, in which we review the existing approaches.\nAs noted in Section 2, a plethora of treebank annotation styles exist, and it is not entirely clear how the annotation style relates to parser performance. It is well-known that some annotation styles are more easily learned by dependency parsers than other, but the research in this area is rather rudimentary even for the monolingual supervised setting, and practically non-existent in other areas, including cross-lingual parser transfer. As a prominent example of an annotation difference known to be important for parser accuracy, but also strongly influencing cross-lingual annotation coherence (with opposing effects), in Section 4, we thoroughly study the appropriateness of two adposition annotation styles, Prague and Stanford, for delexicalized parser transfer.\nLinguistic intuition tells us that for cross-lingual\n1While our motivation is the analysis of languages without treebanks, we only evaluate our methods on languages for which treebanks are available, and simulate the underresourced setting by not using the tgt treebanks for training. This is a natural consequence of the fact that without a test treebank, intrinsic evaluation is impossible, and we are not aware of any reliable scenario for extrinsic parser evaluation.\nparser transfer, using a src treebank of a language very close to the tgt language should bring the best results. However, as shown by McDonald et al. (2011), not only is the similarity of languages only a weakly established concept, but the empirical results are often rather counterintuitive \u2013 for example, to parse Swedish, the best treebank to use turned out to be a Portuguese one, performing better than treebanks for Germanic languages (their dataset included, among other, German, Dutch, Danish, and English). Therefore, in Section 5, we introduce a new empirical language similarity measure, designed and tuned specifically for the delexicalized parser transfer approaches, and evaluate its performance in several settings.\nFurthermore, in Section 6, we introduce our own novel method of multisource delexicalized parser transfer, based on interpolation of trained parser models. We evaluate the method both in an unweighted as well as a weighted setting, and compare it to the standard resource combination methods.\nFinally, in Section 7, we present the intention to enrich our approach by semi-supervised lexicalization in future, which other authors have already shown to have a great potential of improving the cross-lingual parser transfer performance."}, {"heading": "2 Data", "text": "One of the positive side-effects of the CoNLL shared tasks was the assembly of dependency treebanks for many languages, usually simply referred to as the CoNLL treebanks, as well as the definition of a file format for representing parsed sentences \u2013 the CoNLL format. The datasets were used for evaluation in the shared tasks, but have also become the de-facto standard for evaluation of later dependency parsers, ensuring strong comparability of the reported results.\nHowever, the CoNLL treebanks generally use different annotation styles on both morphological and syntactic level. For example, all treebanks define a POS (part of speech) tag for each word (or token, more precisely), but the set of POS tags used by each treebank is different, not only in the level of detail, but also in the actual tags used to carry the same information \u2013 a noun can be tagged as n, N, NN, No, S, IZE, etc. On the syntactic level, not only the sets of labels are different, but even the unlabelled dependency structures differ,\nas they correspond to different linguistic theories; probably the highest variance can be found in the annotation of coordination structures, as studied by Popel et al. (2013). While some of the differences may be motivated by inherent properties of the respective languages, they very often correspond merely to more-or-less arbitrary design decisions of technical rather than linguistic nature, taken during the creation of the treebanks. Importantly, such differences constitute unnecessary obstacles in most multilingual experiments. For cross-lingual parser transfer, these are absolutely crucial, leading to low performance of some methods and inapplicability of other.\nThe issues with cross-lingually incoherent annotation first led Zeman (2008) to the development of the Interset, a method of capturing values of most morphological features and for conversions between various tagsets. Later, the HamleDT collection of dependency treebanks was created by Zeman et al. (2012), consisting of treebanks harmonized not only on the morphological level (via Interset), but also on the syntactic level, loosely following the annotation style of the Prague Dependency Treebank of Bo\u0308hmova\u0301 et al. (2003).\nIn parallel, Petrov et al. (2012) defined the Universal POS tagset (UPOS) as a counter-weight to Interset, as it only captures 12 most important values of coarse-grained POS tags, ignoring all other morphological annotation. It was later used for annotation of the (eventually) 11 treebanks of the Google Universal Dependency Treebank collection of McDonald et al. (2013). For syntactic annotation, the authors defined their own version of the Stanford Dependencies (De Marneffe and Manning, 2008), modified to better suit the multilingual setting, as the original annotation style was implicitly designed for English. In turn, de Marneffe et al. (2014) reacted by introducing the Universal Stanford Dependencies as the \u201cofficial\u201d multilingual version of Stanford Dependencies. This annotation style was immediately adopted by Rosa et al. (2014), who modified it slightly and used it to \u201cstanfordize\u201d the HamleDT collection by implementing a languageneutral conversion pipeline and applying it to the harmonized treebanks in HamleDT 2.0.\nRecently, all of the harmonization forces have joined together into the Universal Dependencies\nproject of Nivre et al. (2015),2 both defining an annotation style based mainly on UPOS, Interset and Universal Stanford Dependencies, as well as producing a set of 10 treebanks annotated in this way in the 1.0 version. More treebanks should be available soon, as the 1.1 version is due on 15th May 2015, and there is a firm plan on continuing to release more treebanks and to update the annotation style as appropriate in future. Thus, Universal Dependencies have the ambition of eventually becoming the ultimate annotation style and dataset for dependency parsing.\nIn our work, we carry out all experiments using HamleDT 2.0, as it is currently still the largest and most diverse harmonized treebank collection, consisting of 30 treebanks \u2013 see Table 1. Specifically, we use the stanfordized version of the collection for most experiments,3 and the gold-standard\n2http://universaldependencies.github.io/docs/ 3 We chose the Stanford style conversion, instead of\nthe HamleDT-native Prague style version, because Stanford Dependencies were developed with the objective of crosslingual consistency of dependency structures. Thus, we expected them to perform better than other formalisms in crosslingual experiments. Later evaluation of that decision, presented (non-chronologically) in Section 4, showed this as-\nUPOS tags4 in all experiments. We always use the training sections of the treebanks to train the parsers or to estimate language similarities, and the test section to evaluate the methods.\nWe used 12 of the treebanks as a development set for hyperparameter tuning where appropriate to avoid overfitting to the dataset. The development set consisted of treebanks for Arabic, Bulgarian, Catalan, Greek, Spanish, Estonian, Persian, Finnish, Hindi, Hungarian, Italian, and Japanese;5 the remaining 18 treebanks constitute the test set. For experiments where hyperparameter tuning on the development set was employed, we report the results of our methods separately for the test set and for the development set as tgt treebanks. However, for each tgt treebank, be it a test treebank or a development treebank, all remaining 29 src treebanks are always used for training in the evaluation of the methods.\nInterestingly, the results of our methods results usually turned out to be generally similar or better on the test set than on the development set, suggesting that no overfitting happened. Therefore, we usually discuss both the results on the test set as well as on the development set when evaluating our experiments."}, {"heading": "3 Delexicalized Parser Transfer", "text": "In the task of delexicalized dependency parser transfer, or delex transfer for short, we train a parser on a treebank for a resource-rich src language, using non-lexical features, most notably POS tags, but not using word forms or lemmas. Then, we apply that parser to POS-tagged sentences of a tgt language, to obtain a dependency parse tree. Delexicalized transfer yields worse results than a fully supervised lexicalized parser, trained on a treebank for the target language. However, for languages with no treebanks available, it may be useful to obtain at least a lowerquality parse tree for tasks such as information retrieval..\nsumption to be incorrect, but we have not redone all our experiments yet with respect to that finding.\n4More precisely, the tags had been automatically converted from original gold-standard tags into UPOS tagset with Interset by the authors of HamleDT.\n5To tune our methods to perform well in many different situations, we chose the development set to contain both smaller and larger treebanks, a pair of very close languages (ca, es), a very solitary language (ja), multiple members of several language families (Uralic, Romance), and both primarily left-branching (bg, el) and right-branching (ar, ja) languages.\nThe idea of delexicalized transfer was conceived by Zeman and Resnik (2008), who trained a delexicalized parser on a Danish treebank and evaluated it on a Swedish one. They note that while the lexicon of two languages will most probably differ significantly even if they are very close, they may share many morphological and syntactic properties. As a prerequisite to applying the method, they map the treebank POS tagsets to a common set, an approach later becoming known as conversion to Interset (Zeman, 2008). They also normalize the annotation styles of the treebanks to make them more similar, performing rule-based transformations \u2013 a method that has developed significantly since then and became known as treebank harmonization (Zeman et al., 2012). We largely build upon all of these approaches in our work.\nUsually, multiple src treebanks are available, and it is non-trivial to select the best one for a given tgt language. Therefore, information from some or all src treebanks is usually combined together. The standard ways are to train a parser on the concatenation of all src treebanks (Section 3.2), or to train a separate parser on each src treebank and to combine the parse trees produced by the parsers using a maximum spanning tree algorithm (Section 3.3). The tree combination method typically performs better; it can also be easily extended by weighting the src parser predictions by similarity of the src language to the tgt language, which can further improve its results."}, {"heading": "3.1 MSTperl parser", "text": "Throughout this work, we use the MSTperl parser of Rosa (2014), an implementation of the unlabelled single-best MSTParser of McDonald et al. (2005b), with first-order features and non-projective parsing. We train the parser using 3 iterations of MIRA (Crammer and Singer, 2003).\nThe MSTParser model uses a set of binary features F that are assigned weights wf by training on a treebank. When parsing a sentence, the parser constructs a complete weighted directed graph over the tokens of the input sentence, and assigns each edge e a score se which is the sum of weights of features that are active for that edge:\nse = \u2211\n\u2200f\u2208F\nf(e) \u00b7 wf . (1)\nThe sentence parse tree is the maximum span-\nning tree (MST) over that graph, found using the algorithm of Chu and Liu (1965) and Edmonds (1967).\nOur lexicalized feature set is based on (McDonald et al., 2005a), and consists of various conjunctions of the following features:\nPOS tags We use the coarse 12-value UPOS of Petrov et al. (2012).6 For an edge, we use information about the POS tag of the head, dependent, their neighbours, and all of the nodes between them.\nToken distance We use signed distance of head and dependent (order head \u2212 orderdependent ), bucketed into the following buckets: +1; +2; +3; +4; \u2265+5; \u2265+11; \u22121; \u22122; \u22123; \u22124; \u2264\u22125; \u2264\u221211.\nLexical features We use the word form and the morphological lemma of the head and the dependent.\nThe delexicalized feature set is based on the lexicalized one, but without the lexical features.\nThe usage of only this parser in all experiments somewhat limits the extent of our findings. Therefore, we intend to employ other parsers in future, e.g. the Malt parser of Nivre et al. (2006). For most of our approaches, this will be straightforward, but for the parser model interpolation approach (Section 6), it may be rather intriguing."}, {"heading": "3.2 Treebank concatenation", "text": "McDonald et al. (2011) applied delexicalized transfer in a setting with multiple src treebanks available, finding that a treebank for a language that is typologically close to the tgt language is typically a good choice for the source treebank, but noting that the problem of selecting the best source treebank is non-trivial; we will further refer to the best source treebank as the oracle treebank, since it can hardly be identified without having a tgt language treebank for evaluation. As a workaround, the authors proposed a simple resource combination method \u2013 treebank concatenation \u2013 which consists of the following steps:\n1. Concatenate all src treebanks. 2. Train a delex parser on the resulting treebank. 3. Apply the parser to the tgt text.\n6These 12 values are: NOUN, VERB, ., ADJ, ADP, PRON, CONJ, ADV, PRT, NUM, DET, X.\nApplying this method led to better results than the average over individual single-source parsers, but worse than using only the oracle src parser. In our work, we take the treebank concatenation method as a baseline."}, {"heading": "3.3 Parse tree combination", "text": "An alternative resource combination approach is the parse tree combination, used by Sagae and Lavie (2006) for monolingual parser combination. In this approach, several independent parsers are applied to the same input sentence, and the parse trees they produce are combined into one resulting tree. The combination is performed using the idea of McDonald et al. (2005a), who formulated the problem of finding a parse tree as a problem of finding the maximum spanning tree of a weighted directed graph of potential parse tree edges. In the tree combination method, the weight of each edge is defined as the number of parsers which include that edge in their output (it can thus also be regarded as a parser voting approach). To find the MST, we use the Chu-Liu-Edmonds algorithm (Chu and Liu, 1965; Edmonds, 1967), which was used by McDonald et al. (2005b) in the non-projective MSTParser. Other MST algorithms could be used, such as the Eisner algorithm (Eisner, 1996), which is, unlike Chu-Liu-Edmonds, constrained to producing only projective parse trees, and was used by McDonald et al. (2005a) in the projective MSTParser.\nThe tree combination method can be easily ported from a monolingual to a multilingual setting, where the individual parsers are trained over different languages. We take the tree combination method for our base approach to multi-source transfer, as it yields better results on average than the treebank concatenation method \u2013 probably because in treebank concatenation, larger treebanks have more influence on the result, which may not be well substantiated.\nA nice feature of the tree combination approach is the straightforward possibility of assigning weights to the individual parsers, as done by Surdeanu and Manning (2010) in a monolingual setting. They let each parser contribute with a weight based on its performance (attachment score), thus giving a more powerful vote to parsers that seem to be better on average. While this is\nsensible in a monolingual setting, in multi-source delexicalized transfer we are more interested in the language similarity of the source and target language, as we would like to give more power to parsers trained on closer languages (see Section 5).\nThe parse tree combination method proceeds in the following way:\n1. Train a delex parser on each src treebank. 2. Apply each of the parsers to the tgt sentence,\nobtaining a set of parse trees. 3. Construct a weighted directed graph over tgt\nsentence tokens, with each edge assigned a score equal to the number of parse trees that contain this edge (i.e., each parse tree contributes by 0 or 1 to the edge score). In the weighted variant, the contribution of each src parse tree is multiplied by a weight w(tgt , src), based on language similarity of tgt and src. 4. Find the maximum spanning tree over the graph with the Chu-Liu-Edmonds algorithm (Chu and Liu, 1965; Edmonds, 1967)."}, {"heading": "4 Treebank Annotation Style for Parsing", "text": "One of the prominent features of the newest versions of Stanford style dependencies is their approach to function words. The general rule is that all function words, such as adpositions or conjunctions, are attached as leaf nodes. This is a result of a lexicalist view of syntax, which favours direct dependency relations between lexical nodes directly, not mediated by function words. This also makes dependency structures more similar cross-lingually, as it is very common that the same function is expressed by an adposition in one lan-\nguage, but by other means, such as morphology or word order, in another language \u2013 or even within the same language, as shown in Figure 1.\nThe Prague style dependencies, on the other hand, are based upon a functionalist approach of Sgall (1967), and annotate adpositions as heads of adpositional groups. The lexical nodes are only directly connected in tectogrammatical (deepsyntax) dependency trees, where function words are removed and their functions are captured via node attributes. It is worth noting that in general, there is little difference between representing information by means of node attributes or leaf nodes; thus, Stanford trees and Prague tectogrammatical trees are actually very similar in structure. However, Prague tectogrammatical trees are rarely directly used in parsing \u2013 they are typically obtained either by manual annotation, or by automatic conversion from surface-syntax (analytical) trees.\nWhile Stanford style trees may be more useful for further processing in NLP applications, it has been argued that Prague style trees are easier to obtain by using statistical parsers, as, among other differences, adpositions provide important cues to the parser for adpositional group attachment. This information becomes harder to access when the adpositions are annotated as leafs. The issue of dependency representation learnability has been studied by several authors, generally reaching similar conclusions (Schwartz et al., 2012; S\u00f8gaard, 2013; Ivanova et al., 2013). The approach suggested by de Marneffe et al. (2014) is to use a different annotation style for parsing, with Prague style adposition annotation, among other, and to convert the dependency trees to full Stanford style only after parsing.\nStill, while this seems to be sufficiently proven in the general case, in multi-lingual parsing scenarios, the higher cross-lingual similarity of Stanford style dependency trees may be of benefit. From all of the differences between Prague and Stanford, the adposition attachment seems to be the most important, as adpositions are usually very frequent and diverse in languages, as well as very important in parsing. Therefore, in this section, we evaluate the influence of adposition annotation style in cross-lingual multi-source delexicalized parser transfer.\nIn Section 4.1, we show that the stanfordized version of HamleDT performs much worse for\nparsing than the Prague version. Consequently, in the following subsections, we use only the Prague version as the basis for our experiments, only employing on one of the prominent features of Stanford Dependencies \u2013 the adposition attachment. The other annotation differences are currently of less interest for us, as they concern less frequent phenomena and/or do not seem so promising for cross-lingual experiments. Thus, we alternate between Prague adposition attachment as head (denoted \u201cP\u201d), and Stanford adposition attachment as leaf node (denoted \u201cS\u201d), and thoroughly evaluate the effect of these annotation styles, with a focus on multi-source delexicalized parser transfer by parse tree combination."}, {"heading": "4.1 Full Universal Stanford Dependencies", "text": "As a preliminary experiment, we compared the Prague version with its fully stanfordized version. The results are shown in Table 2. It can be seen that the Stanford version performs much worse than the Prague one \u2013 its results are lower by around 5% UAS absolute.\nCloser inspection showed that many of the errors are actually due to sentence-final punctuation attachment. In Stanford style, sentence-final punctuation is to be attached as a dependent node of the root node of the sentence (typically the main predicate). However, this is difficult for the firstorder parser, as it has no knowledge of the root node when scoring the potential edges, and thus the punctuation gets often attached to a different verb. In Prague style, the sentence-final punctuation is attached to the technical root node, which is marked by special values of the node features, and thus the assignment is very easy to make. While this is an important point to keep in mind when parsing into full Stanford style, it is of little relevance to the goal of this paper \u2013 punctuation at-\ntachment is rarely important in NLP applications, and is not very likely to significantly contribute to cross-lingual dependency structure similarity either. For this reason, we also include UAS measured only on non-punctuation nodes. Still, adposition attachment, which we are mostly interested in, accounts for only a part of the score difference."}, {"heading": "4.2 Conversion between Prague and Stanford adpositions", "text": "Further on, we only use the Prague style annotation of the treebanks, with adpositions annotated either in Prague style (P) or Stanford style (S). To convert between these adposition annotation styles, we implemented two simple transformation blocks in the Treex NLP framework (Z\u030cabokrtsky\u0301, 2011):\n\u2022 The conversion from P to S takes each adposition and attaches it as a dependent of its leftmost non-adpositional child, as well as all of its other non-adpositional children. Thus, the adposition becomes a leaf node, unless it has adpositional dependent nodes (typically this signifies a compound adposition). Coordinating conjunctions are dived through \u2013 if the left-most non-adpositional child is a coordinating conjunction, the leftmost nonadpositional conjunct is taken instead (recursively).\n\u2022 In the conversion from S to P, each adposition with a non-adpositional head is attached as a dependent of its head\u2019s head, and its original head is attached as its dependent.\nThe roundtrip of the conversion (UAS after converting there and back again) is around 98%. The transformation blocks,7 as well as the whole Treex framework, are available on Github.8\nNote that there are three places where a conversion from one annotation style to another may take place \u2013 conversion of the source treebank before training a parser, conversion of the parser output before the parse tree combination, and conversion of the parse tree combination output."}, {"heading": "4.3 29-to-1 delexicalized parser transfer", "text": "This section presents and discusses annotation style conversions applied in semi-supervised pars-\n7HamleDT::Transform::PrepositionDownwardSimple and HamleDT::Transform::PrepositionUpwardSimple\n8https://github.com/ufal/treex/ https://github.com/ufal/treex/tree/master/lib/Treex/Block/HamleDT/Transform\ning of each of the 30 HamleDT 2.0 treebanks as the tgt , using delex parsers trained on the remaining 29 src treebanks, in an unweighted parse tree combination approach.\nAs was already mentioned, one of the two adposition annotation styles (P or S) can be used for parsing, for parse tree combination, and for converting the output dependency tree. This yields a number of possible setups, which we will denote as the styles used for the individual steps, separated by slashes: parsing/combination/output.\nFor example, a \u201cP/S/S\u201d setup means we use the original P style of the treebanks for training the parsers, a conversion from P to S of the parse trees is performed before combining them, and no conversion of the resulting dependency trees takes place (as they already were in S style before the combination). In some of the experiments, we use both P and S parsing \u2013 \u201cP,S/S/P\u201d denotes a setup where both parsers trained on P and S treebanks were applied, the P style parse trees were then converted to S style, all of these were combined using the maximum spanning tree algorithm, and the output dependency tree was then converted to P style.\nThe results are shown in Table 3. For each target language, it shows the UAS of evaluating various setups on the test section of its treebank.\nClearly, the best results are obtained by parsing both to Stanford and Prague adposition annotation style, thus obtaining two parse trees for each source language (58 parse trees for each sentence), converting the parse trees to the desired output style, and combining them. This shows that both of the styles have some advantages, and that the parse tree combination can benefit from these. Moreover, contrary to supervised parsing, the S style performs better than the P style, by +0.26% UAS absolute on average. This is one of the indications that in this multi-lingual setting, the S style of adposition attachment is favourable, as it makes the dependency trees more similar. Overall, using both styles for parsing and Stanford style for combination and output surpasses the Prague-only baseline by +0.39% UAS absolute.\nA further observation to make is that generally, the P style is good for parsing, while the S style is good for parse tree combination. Please note the results of P/P/P and S/P/P, which show a clear dominance (+1.17%) of using P style for everything rather than parsing in S d then converting\nto P. For the S output style, the difference between S/S/S and P/S/S is only 0.08% UAS, and parsing to P and then converting to S and combining actually achieves the best score for 8 target languages, while using S for everything leads to best results for only 7 languages. This can be easily explained, as it has been already shown that the P style is generally favourable for parsing; the S style then makes the parse trees more similar and thus easier to combine correctly.\nAnd finally, there is a general tendency of simpler solutions to perform better \u2013 unless there is a strong benefit of switching styles for a given step, it is preferable to use a low number of conversions."}, {"heading": "4.4 Smaller source treebank subsets", "text": "For a deeper insight and further confirmation of our conclusions, we also performed a set of experiments with smaller subsets of the treebank collection. We selected several treebank groups, based on the ratio of adposition tokens to all tokens. We also only chose large enough treebanks (more than 100,000 tokens). The subsets are listed in Table 4; we also used a larger \u201cAll9\u201d set of all the 9 selected treebanks. Only these were then used for training; the remaining 21 languages were used for testing as target languages.\nThe summary results are to be found in Table 5. It is easy to see that the conclusions presented in the previous section hold even for these datasets. Moreover, the differences in UAS are often much higher, especially for the smaller and highly diverse datasets High, Low and Mix, where the benefit of the Stanford style making the dependency trees more similar becomes quite important. This suggests that the role of Stanford style is stronger with small and heterogeneous datasets. For the High dataset, the best result surpasses the Prague-\nonly baseline by as much as 2.24% UAS absolute."}, {"heading": "4.5 Supervised parsers", "text": "For completeness, we also include results for supervised monolingual lexicalized and delexicalized parsers, using the P and S annotation styles of adpositions. The setup denoted as \u201cP/S\u201d corresponds to a parser trained on a P style target treebank, output of which is converted to S, and then evaluated on the S conversion of the target treebank test section (analogously for \u201cS/P\u201d). For comparison, we also include the two best parser transfer setups (these results are identical to those in Table 3).\nThe results are shown in Table 6. For the lexicalized parser, the P style is clearly better, achieving +0.77% UAS absolute on average. To obtain S style parse trees, it is generally better to parse the text using a parser trained on a P style treebank, and then to convert the output parse trees, which yields a +0.46% higher UAS than parsing directly using an S style treebank. Here, the adpositions clearly provide important information to the parser, and their annotation as heads benefits the results.\nFor the delexicalized parser, the P style still performs better (+0.21% UAS), although the difference is smaller, and parsing directly using the S style is comparable to parsing using P style and then converting to S style. We believe that this is because when word forms and lemmas are removed, the most important information about the adpositions is missing. If the language has a general tendency of where it attaches adpositions, the information that a word is an adposition is still useful, but it has now a limited power towards ad-\nposition attachment disambiguation. And finally, as has already been discussed, the S style actually performs better for delexicalized parser transfer than the P style; in the best setups, the S style achieves +0.26% UAS on average."}, {"heading": "4.6 Conclusion", "text": "We investigated the usefulness of Stanford adposition attachment style as an alternative to the Prague style, using a large set of 30 treebanks for evaluation. We especially focused on multi-source cross-lingual delexicalized parser transfer, as one of the targets behind the design of Universal Stanford Dependencies is to be more cross-lingually consistent than other annotation styles.\nWe managed to confirm that for supervised parsing, Prague annotation style is favourable over Stanford style, as has been already stated in literature. However, in the parser transfer setting, Stanford style adposition attachment proved to generally perform better than the Prague style, thanks to its abstraction from the high interlingual variance in adposition usage. Moreover, even better results are achieved by at once combining outputs of parsers trained on treebanks of both Prague and Stanford adposition attachment style, eventually reaching an improvement of +0.39% UAS absolute over the Prague style baseline. Our results are further confirmed by experiments using smaller and more diverse subsets of training treebanks, where the advantage of Stanford style often becomes even more pronounced, reaching an improvement of up to +2.24% over the Prague style baseline.\nIn future, we intend to evaluate the effect of other annotation style differences, such as the coordination structures. We also plan to try to incorporate more fine-grained morphological information than the UPOS tags, probably by only including a given feature if it seems to be shared between the src and tgt language, as always including all of them performed very poorly in preliminary experiments."}, {"heading": "5 Employing Language Similarity", "text": "The issue of finding a good src treebank for a given tgt language can be approached in two ways. In the single-source approach, we try to find the src language which is most similar to the tgt language, and use the treebank for that language to train a parser to be applied to the tgt . In a\nmulti-source approach, we combine some or all available src resources, either in an unweighted way, as was presented in Section 3, or weighted by src-tgt similarity. Thus, for both the source selection task and the source weighting task, there is a need for a language similarity measure, which serves as a proxy for src and tgt treebank similarity, but cannot access the tgt treebank. Still, it is reasonable, and usual, to presuppose availability of POS-tagged tgt language text (as it constitutes the input to the delex parser), as well as the information about the identity of the tgt language.\nSeveral authors (Naseem et al., 2012; S\u00f8gaard and Wulff, 2012; Ta\u0308ckstro\u0308m et al., 2013) have employed the World Atlas of Language Structures (WALS) of Dryer and Haspelmath (2013) to estimate the similarity of languages for delex transfer. They exploit information about the genealogy distance and shared typological features of the languages, typically word order features. They note that for a tgt language which is rather dissimilar to any of the src languages, delex transfer achieves better results if word order is completely or selectively ignored. This is motivated by the observation that languages, at least when being observed only through POS, become more similar if we disregard word order.\nApart from using WALS, S\u00f8gaard also takes one other approach to estimating language similarity. In (S\u00f8gaard, 2011), he trains a POS language model on a tgt POS-tagged corpus, and uses it to filter the src treebank, keeping only sentences that look like target language sentences to the language model. This method is further improved in (S\u00f8gaard and Wulff, 2012), where the authors move from a selection approach to a weighting approach: they keep all the src sentences, but weight each of them with the score assigned by the language model. This is made possible by modifying their learning algorithm to use weighted perceptron learning (Cavallanti et al., 2010). In this way, they in principle introduce a weighting scheme for the treebank concatenation.\nThe central feature of this section is KLcpos3 , a language similarity measure based on similarity of distributions of coarse POS tag trigrams, computed over POS-tagged corpora for the source and target languages using the Kullback-Leibler divergence (Kullback and Leibler, 1951). The measure is simple and efficient, does not rely on ad-\nditional external resources, and has been designed and tuned specifically to be used in delexicalized transfer approaches. We show that KLcpos3 performs well in selecting the source treebank in the single-source delexicalized transfer, as well as in parser weighting in the multi-source tree combination approach.\n5.1 KLcpos3 language similarity measure\nOur method of estimating language similarity for the purposes of delexicalized transfer is based on comparing distributions of coarse POS trigrams in a source language treebank (Psrc) and in a target language POS-tagged corpus (Ptgt ). This is motivated by the fact that POS tags constitute a key feature for delexicalized parsing. We use UPOS tags; we also tried using more fine-grained tags, but this led to worse results on our development data, probably because more fine-grained features tend to be less shared across languages. We also tried to vary the POS ngram length; bigrams and tetragrams both performed comparably to trigrams on the weighting task, but for the selection task, trigrams outperformed other ngrams.\nThe coarse POS trigram distributions are estimated as frequencies computed on the training parts of the corpora:\nf(cpos i\u22121, cpos i, cpos i+1) =\n= count(cpos i\u22121, cpos i, cpos i+1) \u2211\n\u2200cposa,b,c count(cposa, cposb, cposc)\n; (2)\nwe use a special value for cpos i\u22121 or cpos i+1 if cpos i appears at the beginning or end of a sentence, respectively.\nWe use the Kullback-Leibler divergence9 to compute the similarity of the distributions as DKL(Ptgt ||Psrc).10 The KL divergence of distributions P and Q is defined as\nDKL(P ||Q) = \u2211\n\u2200x\nP (x) \u00b7 log P (x)\nQ(x) , (3)\nwith the value of the addend defined as 0 if P (x) = 0. The value of KL divergence is a nonnegative number; the more divergent (dissimilar) the distributions, the higher its value.\n9We also tried cosine similarity, with much worse results. 10DKL(P ||Q) expresses the amount of information lost when a distribution Q is used to approximate the true distribution P . Thus, in our setting, we use DKL(Ptgt ||Psrc), as we try to minimize the loss of using a parser based on source data as an approximation of a parser based on the target data.\nIn our setting, we compute KLcpos3 as\nKLcpos3(tgt , src) =\n= \u2211\n\u2200cpos3\u2208tgt\nftgt(cpos 3) \u00b7 log\nftgt(cpos 3) fsrc(cpos3) , (4)\nwhere cpos3 is a coarse POS tag trigram. It is sufficient to iterate only over trigrams present in the target, as the addend is defined to be zero in other cases. This is in accord with our needs: we do not actually care about phenomena that the source parser can handle but do not appear in target.\nFor the KL divergence to be well-defined, we set the source count of each unseen trigram to 1."}, {"heading": "5.2 Source selection", "text": "For the single-source parser transfer, we compute KLcpos3 distance of the tgt corpus to each of the src treebanks. We then select the src\u2217 treebank as the closest one:\nsrc\u2217 = argmin \u2200src KLcpos3(tgt , src) , (5)\nand use it to train the delex parser to be applied to tgt ."}, {"heading": "5.3 Source weighting", "text": "To convert KLcpos3 from a negative measure of language similarity to a positive src parser weight, we take the fourth power of its inverted value, KL\u22124\ncpos3 . A high value of the exponent strongly promotes the most similar source language, giving minimal power to the other languages, which is good if there is a very similar source language. A low value enables combining information from a larger number of source languages. We chose a compromise value of 4 based on performance on the development data.\nWe then add weighting by KLcpos3 into the parse tree combination (Section 3.3) by multiplying the contribution of each src parse tree by KL\u22124\ncpos3 (tgt , src)."}, {"heading": "5.4 Evaluation", "text": "To evaluate the language similarity measure, we use it both for the selection task and the weighting task on the stanfordized version of the HamleDT 2.0 treebanks. The exact shape of the measure was tuned on the development set.11\n11We tuned the choice of the similarity measure, POS ngram length, and the way of turning KLcpos3 into KL \u22124 cpos3 .\nPreliminary trials on the subset of CoNLL 2006 and 2007 data sets (Buchholz and Marsi, 2006; Nilsson et al., 2007) used by McDonald et al. (2011) indicated that these are not suitable for our approach, as they are not harmonized on the dependency annotation level.12 There, treebank annotation style similarity seems to become more important than language similarity; the lack of harmonization makes the data unnecessarily noisier.\nTable 7 contains the results of our methods both on the test languages and the development languages. For each target language, we used all remaining 29 source languages for training (in the single-source method, only one of them is selected and applied). We base our evaluation mainly on average UAS on the test tgt languages, and compare the methods by absolute UAS differences.\nOur baseline is the treebank concatenation method of McDonald et al. (2011), i.e., a single delexicalized parser trained on the concatenation of the 29 src treebanks (Section 3.2).\nAs an upper bound,13 we report the results of the oracle single-source delexicalized transfer: for each target language, the oracle source parser is the one that achieves the highest UAS on the target treebank test section.14 We do not include results of a higher upper bound of a supervised delexicalized parser (trained on the tgt treebank), which has an average UAS of 68.5%. It was not surpassed by our methods for any target language, although it was reached for Telugu, and approached within 5% for Czech and Latin.\nThe results show that KLcpos3 performs well both in the selection task and in the weighting task, as both the single-source and the weighted multi-source transfer methods outperform the unweighted tree combination on average, as well as the treebank concatenation baseline. In 8 of 18 cases, KLcpos3 is able to correctly identify the oracle source treebank for the single-source approach. In two of these cases, weighted tree combination further improves upon the result of the single-\n12On the original non-harmonized treebanks, the unweighted tree combination performed best (58.06% UAS), +2.4% absolute over weighted tree combination and +4.9% over single-source transfer. On the harmonized versions of the same treebanks (subset of HamleDT), unweighted tree combination was outperformed both by single-source transfer (+1.0%) and weighted tree combination (+1.67%).\n13This is a hard upper-bound for the single-source transfer, but can be surpassed by the multi-source transfer.\n14We do not report the matrix of all source/target combination results, as this amounts to 870 numbers.\nFor each target language, all 29 remaining non-target treebanks were used for training the parsers. The best score among our transfer methods is marked in bold; the baseline and upper bound scores are marked in bold if equal to or higher than that. Legend: Tgt lang = Target treebank language. TB conc = Treebank concatenation. Oracle del trans = Single-source delexicalized transfer using the oracle source language. Single-src = Single-source delexicalized transfer using source language with lowest KLcpos3 distance to the target language (language bold if identical to oracle). Multi-src = Multi-source delexicalized transfer using parse tree combination, unweighted (\u00d71) and KL\u22124\ncpos3 weighted\n(\u00d7w). Avg = Average UAS (on test/development/all). SD = Standard sample deviation of UAS, serving as an indication of robustness of the method.\nsource transfer, i.e., surpasses the oracle; in the remaining 6 cases, it performs identically to the single-source method. This proves KLcpos3 to be a successful language similarity measure for delexicalized parser transfer, and the weighted multisource transfer to be a better performing approach than the single-source transfer.\nThe weighted tree combination is better than its unweighted variant only for half of the target languages, but it is more stable, as indicated by its lower standard deviation, and achieves an average UAS higher by 4.5%. The unweighted tree combination, as well as treebank concatenation, perform especially poorly for English, German, Tamil, and Turkish, which are rich in determiners, unlike the rest of the treebanks;15 therefore, determiners are parsed rather randomly.16 In the weighted methods, this is not the case anymore, as for a determiner-rich target language, determinerrich source languages are given a high weight.\nFor target languages for which KLcpos3 of the closest source language was lower or equal to its average value of 0.7, the oracle treebank was identified in 7 cases out of 12 and a different but competitive one in 2 cases; when higher than 0.7, an appropriate treebank was only chosen in 1 case out of 6. When KLcpos3 failed to identify the oracle, weighted tree combination was always better or equal to single-source transfer but mostly worse than unweighted tree combination. This shows that for distant languages, KLcpos3 does not perform as good as for close languages.\nWe believe that taking multiple characteristics of the languages into account would improve the results on distant languages. A good approach might be to use an empirical measure, such as KLcpos3 , combined with supervised information from other sources, such as WALS. Alternatively, a backoff approach, i.e. combining KLcpos3 with e.g. KLcpos2 , might help to tackle the issue.\nStill, for target languages dissimilar to any source language, a better similarity measure will not help much, as even the oracle results are usually poor. More fine-grained resource combination methods are probably needed there, such as selectively ignoring word order, or using different sets\n15In the treebanks for these four languages, determiners constitute around 5-10% of all tokens, while most other treebanks contain no determiners at all; in some cases, this is related to properties of the treebank annotation or its harmonization rather than properties of the language.\n16UAS of determiner attachment tends to be lower than 5%, which is several times less than for any other POS.\nof weights based on POS of the dependent node."}, {"heading": "5.5 Conclusion", "text": "We presented KLcpos3 , an efficient language similarity measure designed for delexicalized dependency parser transfer. We evaluated it on a large set of treebanks, and showed that it performs well in selecting the source treebank for single-source transfer, as well as in weighting the source treebanks in multi-source parse tree combination.\nOur method achieves good results when applied to similar languages, but its performance drops for distant languages. In future, we intend to explore combinations of KLcpos3 with other language similarity measures, so that similarity of distant languages is estimated more reliably."}, {"heading": "6 Model Interpolation", "text": "In this section, we present a novel method for src information combination, based on interpolation of trained MSTperl parser models. Our approach was motivated by an intuition that the more fine-grained information provided by the src edge scores could be of benefit, probably serving as src parser confidence. Moreover, model interpolation is significantly less computationally demanding at inference than the parse tree combination method, as instead of running a set of separate src parsers, only one parser is run.\nWe are not aware of any prior work on interpolating dependency parser models; the closest to our approach is the interpolation of multilingual probabilistic context-free grammars of Cohen et al. (2011).\nThe method proceeds as follows:\n1. Train a delex parser model on each src treebank (Section 3.1). 2. Normalize the parser models (Section 6.1). 3. Interpolate the parser models (Section 6.2,\nSection 6.3). 4. Parse the tgt text with a delex parser using\nthe interpolated model.\nWe evaluate the model interpolation method in Section 6.4, comparing it both to the treebank concatenation method as well as the parse tree combination method, in a weighted as well as unweighted setting."}, {"heading": "6.1 Model normalization", "text": "An important preliminary step to model interpolation is to normalize each of the trained models,\nas the feature weights in models trained over different treebanks are often not on the same scale (we do not perform any regularization during the parser training). We use a simplified version of normalization by standard deviation. First, we compute the uncorrected sample standard deviation of the weights of the features in the model as\nsM =\n\u221a\n1\n|M |\n\u2211\n\u2200f\u2208M\n(wf \u2212 w\u0304)2 , (6)\nwhere w\u0304 is the average feature weight, and |M | is the number of feature weights in model M ; only features that were assigned a weight by the training algorithm are taken into account.\nWe then divide each feature weight by the standard deviation:17\n\u2200f \u2208 M : wf := wf\nsM . (7)\nThe choice of normalization by standard deviation is a combination of its high and stable performance on our development set, and of Occam\u2019s razor. We tried 12 normalization schemes, nearly all of which achieved an improvement of 2.5% to 5% UAS absolute over an interpolation of unnormalized models on average, but often with large differences for individual languages.18"}, {"heading": "6.2 Unweighted model interpolation", "text": "The interpolated model is a linear combination of the normalized models trained over the src treebanks. The result is a model that can be used in the same way as a standard MSTperl parser model.\nIn unweighted model interpolation, the weight of each feature (wf ) is computed as the sum of the weights of that feature in the normalized src models (wf,src ):\n\u2200f \u2208 F : wf = \u2211\n\u2200src\nwf,src . (8)"}, {"heading": "6.3 Weighted model interpolation", "text": "In the weighted variant of model interpolation, we extend (8) with multiplication by a weight\n17We have not found any further gains in performance when subtracting the sample mean from the weight before the division; the MSTParser models seem to be typically centered very similarly.\n18Another well-performing method was to divide each feature weight by the sum of absolute values of all feature weights in the model; or a similar method, applied during inference individually for each sentence, using only the feature weights that fired for the sentence to compute the divisor.\nw(tgt , src), corresponding to language similarity of tgt and src:\n\u2200f \u2208 F : wf = \u2211\n\u2200src\nwf,src \u00b7 w(tgt , src) . (9)\nIn our experiments, we use the KL\u22124 cpos3 (tgt , src) weight, which we presented in Section 5."}, {"heading": "6.4 Evaluation", "text": "Table 8 contains the results of our model interpolation methods, as well as the baseline methods. For each tgt language, all remaining 29 src treebanks were used for parser training. We base our evaluation on comparing absolute differences in UAS on the whole set of 30 languages as targets.\nThe performance of the weighted model interpolation is comparable to the weighted tree combination \u2013 the difference in average UAS of the methods is lower than 0.1%, with model interpolation achieving a higher UAS than the tree combination for 16 of the 30 tgt languages. This shows that weighted model interpolation is a good alternative to weighted tree combination.\nIn the unweighted setting, the situation is quite different, with model interpolation scoring much lower than tree combination (-2.4%), and only slightly higher than treebank concatenation (+0.4%) on average. This suggests that, contrary to our original intuition, edge scores assigned by the src models are not a good proxy for parser confidence, not even when appropriately normalized.19 Furthermore, the weighted methods generally outperform the unweighted ones (by +4.0% for tree combination and by +6.4% for model interpolation on average), which suggests, among other, that the src-tgt language similarity is much more important than the exact values of src edge scores for resource combination in delex transfer."}, {"heading": "6.5 Conclusion", "text": "We presented trained parser model interpolation as an alternative method for multi-source crosslingual delexicalized dependency parser transfer. Evaluation on a large collection of treebanks showed that in a setting where the source languages are weighted by their similarity to the target language, model interpolation performs comparably to the parse tree combination approach. Moreover, model interpolation is significantly less\n19The same tendency was observed across all normalization methods evaluated on the development set.\ncomputationally demanding than the tree combination when parsing the target text, as the interpolation can be efficiently performed beforehand, thus only requiring to invoke a single parser at runtime, while in the tree combination approach, each source parser has to be invoked individually.\nIn the unweighted setting, model interpolation consistently performed much worse than tree combination, which we find rather surprising, and we therefore plan to further investigate this in future. Still, the weighted methods generally outperformed the unweighted ones, and as the language similarity measure that we used only requires the source treebanks and a target POS-tagged text, i.e. exactly the resources that are required even for the unweighted delex transfer methods, there is little reason not to employ the weighting. Therefore, the low performance of the unweighted model interpolation is of less importance than its high performance in the weighted setting."}, {"heading": "7 Cross-lingual Lexicalization", "text": "A very popular method of improving the results of delexicalized parser transfer is by lexicalizing the parser in a semi-supervised manner (as manually created parallel treebanks are extremely rare). We did not explore that approach in this work; instead, we focused on improving the underlying delexicalized parser transfer. However, we plan to combine it with semi-supervised lexicalization in future (preliminary experiments indicate that this leads to further improvements)."}, {"heading": "7.1 Employing parallel data", "text": "The typical approach to lexicalization in delex parsing is by using dictionaries, parallel texts, and/or machine translation techniques (Zhao et al., 2009; McDonald et al., 2011; Ta\u0308ckstro\u0308m et al., 2012; Durrett et al., 2012; Ramasamy et al., 2014).\nOne option is to translate the tgt sentence into the src language, which then makes it possible to use a lexicalized src parser instead of a delexicalized one. The correspondence of the words in the translation to the src words can be established by using word alignment.\nIf one-to-many or many-to-many alignment is used, the projection of the syntactic structure through the alignment is non-trivial. Therefore, word-to-word translation can be used instead. Another option is to only include the src information\nthrough additional features, as has been done by Rosa et al. (2012), which does not require a oneto-one alignment.\nIf high-quality src-tgt parallel texts are available (i.e. created by human translators, not machine translation systems), they may be used instead to create an automatic parallel treebank, without the need to use machine translation (but using a word aligner is still necessary).\nA major drawback of all of these methods is the fact that in most cases, large parallel texts, and thus high-quality machine translation, is only available for English as the src language. For some tgt languages, there may be other wellresourced src languages, but generally, and especially for the focus languages, i.e. under-resourced ones, we are constrained to only using English src. As our experiments showed, the English treebank is rarely a good src treebank for delex parser transfer; therefore, we expect that the English-based lexicalization can only serve as a complement to the methods described in this paper, still using all available src treebanks."}, {"heading": "7.2 Employing word embeddings", "text": "Recently, especially since the introduction of the word2vec tool by Mikolov et al. (2013), continuous vector space word representations, also known as word embeddings, have gained huge popularity, and have proven to be useful in many tasks of natural language processing.\nIn our setting, we are especially interested in the approaches that compute bilingual word vectors, trained to assign similar vectors to words with similar meaning, regardless of whether these are src or tgt language words. In this way, we could replace the lexical features by embedding features, thus circumventing the lexicalization problem.\nIt has to be noted though that our parser, as well as parsers of other authors, generally support only categorial features; at least in combinations, but non-combined features are of extremely limited usefulness. Thus, it is necessary to either convert the vectors from the continuous space to categorial features, thus losing many of their attractive properties, or to use a parser that naturally supports combinations of continuous features, which to the best of our knowledge is not available in present, although we are aware of ongoing research in this field."}, {"heading": "7.3 Self-training", "text": "Some lexicalization can also be achieved in an unsupervised way by applying self-training (McClosky et al., 2006), i.e. parsing a (preferably large) POS-tagged tgt corpus by the delex transfer method, and then using the resulting automatic treebank to train a standard lexicalized parser in a supervised way. While it may seem that such a parser has no chance of outperforming the delex parser, this is not entirely true, as simply the presence or non-presence of some phenomena in the corpus may help to adjust some parameters of the parser. Moreover, for practical reasons, it may be useful to obtain a standard tgt parser model to apply for analyzing new tgt data, rather than always applying the full multisource transfer machinery.\nOur preliminary experiments performed using the training sections of the tgt treebanks indicate a small but consistent improvement brought by this approach, both when training a lexicalized as well as a delexicalized parser on the automatically parsed data.\nThe self-training method is quite orthogonal to all the other approaches, and can thus presumably be applied on top of any future parsing system."}, {"heading": "8 Conclusion", "text": "We presented our work on multi-source crosslingual transfer of delexicalized dependency parsers.\nWe evaluated the influence of treebank annotation styles on parsing performance, focusing on adposition attachment style, and found that the Stanford annotation, while being infavourable for supervised parsers, performs promisingly in the multilingual delexicalized parser transfer setting.\nWe then presented KLcpos3 , an empirical language similarity measure designed for source parser weighting in multi-source delexicalized parser transfer. We demonstrated its generally good performance, although improvements still have to be made for cases where the target language is too dissimilar to any available source language.\nAnd finally, we introduced a novel resource combination method, based on interpolation of trained MSTParser models. Although we found its performance to be below our expectations, when combined with KL\u22124\ncpos3 weighting, its re-\nsults match these of the weighted parse tree combination method. As model interpolation is less computationally demanding than parse tree com-\nbination, we find it to be a good alternative multisource delexicalized parser transfer method.\nThroughout our work, we also identified numerous promising paths for further research, the most important being semi-supervised lexicalization of the methods."}, {"heading": "Acknowledgments", "text": "This research was supported by the grants GAUK 1572314 and SVV 260 224. This work has been using language resources developed, stored and distributed by the LINDAT/CLARIN project of the Ministry of Education, Youth and Sports of the Czech Republic (project LM2010013)."}], "references": [{"title": "The prague dependency treebank", "author": ["Jan Haji\u010d", "Eva Haji\u010dov\u00e1", "Barbora Hladk\u00e1"], "venue": "In Treebanks,", "citeRegEx": "B\u00f6hmov\u00e1 et al\\.,? \\Q2003\\E", "shortCiteRegEx": "B\u00f6hmov\u00e1 et al\\.", "year": 2003}, {"title": "A transition-based system for joint part-of-speech tagging and labeled non-projective dependency parsing", "author": ["Bohnet", "Nivre2012] Bernd Bohnet", "Joakim Nivre"], "venue": "In Proceedings of the 2012 Joint Conference on Empirical Methods", "citeRegEx": "Bohnet et al\\.,? \\Q2012\\E", "shortCiteRegEx": "Bohnet et al\\.", "year": 2012}, {"title": "CoNLL-X shared task on multilingual dependency parsing", "author": ["Buchholz", "Marsi2006] Sabine Buchholz", "Erwin Marsi"], "venue": "In Proceedings of the Tenth Conference on Computational Natural Language Learning,", "citeRegEx": "Buchholz et al\\.,? \\Q2006\\E", "shortCiteRegEx": "Buchholz et al\\.", "year": 2006}, {"title": "Linear algorithms for online multitask classification", "author": ["Nicolo Cesa-Bianchi", "Claudio Gentile"], "venue": "The Journal of Machine Learning Research,", "citeRegEx": "Cavallanti et al\\.,? \\Q2010\\E", "shortCiteRegEx": "Cavallanti et al\\.", "year": 2010}, {"title": "On shortest arborescence of a directed graph", "author": ["Chu", "Liu1965] Yoeng-Jin Chu", "Tseng-Hong Liu"], "venue": "Scientia Sinica,", "citeRegEx": "Chu et al\\.,? \\Q1965\\E", "shortCiteRegEx": "Chu et al\\.", "year": 1965}, {"title": "Unsupervised structure prediction with non-parallel multilingual guidance", "author": ["Cohen et al.2011] Shay B. Cohen", "Dipanjan Das", "Noah A. Smith"], "venue": "In Proceedings of the Conference on Empirical Methods in Natural Language Processing,", "citeRegEx": "Cohen et al\\.,? \\Q2011\\E", "shortCiteRegEx": "Cohen et al\\.", "year": 2011}, {"title": "Ultraconservative online algorithms for multiclass problems", "author": ["Crammer", "Singer2003] Koby Crammer", "Yoram Singer"], "venue": "The Journal of Machine Learning Research,", "citeRegEx": "Crammer et al\\.,? \\Q2003\\E", "shortCiteRegEx": "Crammer et al\\.", "year": 2003}, {"title": "The stanford typed dependencies representation", "author": ["De Marneffe", "Christopher D Manning"], "venue": "In Coling 2008: Proceedings of the workshop on Cross-Framework and Cross-Domain Parser Eval-", "citeRegEx": "Marneffe et al\\.,? \\Q2008\\E", "shortCiteRegEx": "Marneffe et al\\.", "year": 2008}, {"title": "Universal Stanford dependencies: A cross-linguistic typology", "author": ["Natalia Silveira", "Timothy Dozat", "Katri Haverinen", "Filip Ginter", "Joakim Nivre", "Christopher D. Manning"], "venue": "In Proc. of LREC\u201914,", "citeRegEx": "Marneffe et al\\.,? \\Q2014\\E", "shortCiteRegEx": "Marneffe et al\\.", "year": 2014}, {"title": "Syntactic transfer using a bilingual lexicon", "author": ["Durrett et al.2012] Greg Durrett", "Adam Pauls", "Dan Klein"], "venue": "In Proceedings of the 2012 Joint Conference on Empirical Methods in Natural Language Processing and Computational Natural Language", "citeRegEx": "Durrett et al\\.,? \\Q2012\\E", "shortCiteRegEx": "Durrett et al\\.", "year": 2012}, {"title": "Optimum branchings", "author": ["Jack Edmonds"], "venue": "Journal of Research of the National Bureau of Standards B,", "citeRegEx": "Edmonds.,? \\Q1967\\E", "shortCiteRegEx": "Edmonds.", "year": 1967}, {"title": "Three new probabilistic models for dependency parsing: An exploration", "author": ["Jason M. Eisner"], "venue": "In Proceedings of the 16th Conference on Computational Linguistics - Volume 1,", "citeRegEx": "Eisner.,? \\Q1996\\E", "shortCiteRegEx": "Eisner.", "year": 1996}, {"title": "Corpus variation and parser performance", "author": ["Daniel Gildea"], "venue": "In Proceedings of the 2001 Conference on Empirical Methods in Natural Language Processing,", "citeRegEx": "Gildea.,? \\Q2001\\E", "shortCiteRegEx": "Gildea.", "year": 2001}, {"title": "Survey on parsing three dependency representations for english", "author": ["Stephan Oepen", "Lilja \u00d8vrelid"], "venue": "In ACL (Student Research Workshop),", "citeRegEx": "Ivanova et al\\.,? \\Q2013\\E", "shortCiteRegEx": "Ivanova et al\\.", "year": 2013}, {"title": "Effective selftraining for parsing", "author": ["Eugene Charniak", "Mark Johnson"], "venue": "In Proceedings of the Main Conference on Human Language Technology Conference of the North American Chapter of the Asso-", "citeRegEx": "McClosky et al\\.,? \\Q2006\\E", "shortCiteRegEx": "McClosky et al\\.", "year": 2006}, {"title": "Online largemargin training of dependency parsers", "author": ["Koby Crammer", "Fernando Pereira"], "venue": "In Proceedings of the 43rd annual meeting on association for computational linguistics,", "citeRegEx": "McDonald et al\\.,? \\Q2005\\E", "shortCiteRegEx": "McDonald et al\\.", "year": 2005}, {"title": "Nonprojective dependency parsing using spanning tree algorithms", "author": ["Fernando Pereira", "Kiril Ribarov", "Jan Haji\u010d"], "venue": "In Proceedings of the conference on Human Language Technology and Empirical Methods", "citeRegEx": "McDonald et al\\.,? \\Q2005\\E", "shortCiteRegEx": "McDonald et al\\.", "year": 2005}, {"title": "Multi-source transfer of delexicalized dependency parsers", "author": ["Slav Petrov", "Keith Hall"], "venue": "In Proceedings of the Conference on Empirical Methods in Natural Language Processing,", "citeRegEx": "McDonald et al\\.,? \\Q2011\\E", "shortCiteRegEx": "McDonald et al\\.", "year": 2011}, {"title": "Universal dependency annotation", "author": ["Joakim Nivre", "Yvonne Quirmbach-Brundage", "Yoav Goldberg", "Dipanjan Das", "Kuzman Ganchev", "Keith B Hall", "Slav Petrov", "Hao Zhang", "Oscar T\u00e4ckstr\u00f6m"], "venue": null, "citeRegEx": "McDonald et al\\.,? \\Q2013\\E", "shortCiteRegEx": "McDonald et al\\.", "year": 2013}, {"title": "Efficient estimation of word representations in vector space", "author": ["Kai Chen", "Greg Corrado", "Jeffrey Dean"], "venue": "Proceedings of Workshop at ICLR", "citeRegEx": "Mikolov et al\\.,? \\Q2013\\E", "shortCiteRegEx": "Mikolov et al\\.", "year": 2013}, {"title": "Selective sharing for multilingual dependency parsing. In Proceedings of the 50th Annual Meeting of the Association for Computational Linguistics: Long Papers - Volume", "author": ["Naseem et al.2012] Tahira Naseem", "Regina Barzilay", "Amir Globerson"], "venue": null, "citeRegEx": "Naseem et al\\.,? \\Q2012\\E", "shortCiteRegEx": "Naseem et al\\.", "year": 2012}, {"title": "The CoNLL 2007 shared task on dependency parsing", "author": ["Nilsson et al.2007] Jens Nilsson", "Sebastian Riedel", "Deniz Yuret"], "venue": "In Proceedings of the CoNLL shared task session of EMNLP-CoNLL,", "citeRegEx": "Nilsson et al\\.,? \\Q2007\\E", "shortCiteRegEx": "Nilsson et al\\.", "year": 2007}, {"title": "Maltparser: A data-driven parsergenerator for dependency parsing", "author": ["Nivre et al.2006] Joakim Nivre", "Johan Hall", "Jens Nilsson"], "venue": "In Proceedings of LREC", "citeRegEx": "Nivre et al\\.,? \\Q2006\\E", "shortCiteRegEx": "Nivre et al\\.", "year": 2006}, {"title": "Universal dependencies 1.0", "author": ["talia Silveira", "Maria Simi", "Aaron Smith", "Reut Tsarfaty", "Veronika Vincze", "Daniel Zeman"], "venue": null, "citeRegEx": "Silveira et al\\.,? \\Q2015\\E", "shortCiteRegEx": "Silveira et al\\.", "year": 2015}, {"title": "A universal part-of-speech tagset", "author": ["Petrov et al.2012] Slav Petrov", "Dipanjan Das", "Ryan McDonald"], "venue": "In Proc. of LREC-2012,", "citeRegEx": "Petrov et al\\.,? \\Q2012\\E", "shortCiteRegEx": "Petrov et al\\.", "year": 2012}, {"title": "Coordination structures in dependency treebanks", "author": ["Popel et al.2013] Martin Popel", "David Mare\u010dek", "Jan \u0160t\u011bp\u00e1nek", "Daniel Zeman", "Zden\u011bk \u017dabokrtsk\u00fd"], "venue": "In Proceedings of the 51st Annual Meeting of the Association", "citeRegEx": "Popel et al\\.,? \\Q2013\\E", "shortCiteRegEx": "Popel et al\\.", "year": 2013}, {"title": "Multilingual dependency parsing: Using machine translated texts instead of parallel corpora", "author": ["David Mare\u010dek", "Zden\u011bk \u017dabokrtsk\u00fd"], "venue": null, "citeRegEx": "Ramasamy et al\\.,? \\Q2014\\E", "shortCiteRegEx": "Ramasamy et al\\.", "year": 2014}, {"title": "Using parallel features in parsing of machine-translated sentences for correction of grammatical errors", "author": ["Rosa et al.2012] Rudolf Rosa", "Ond\u0159ej Du\u0161ek", "David Mare\u010dek", "Martin Popel"], "venue": "In Proceedings of Sixth Workshop on Syntax,", "citeRegEx": "Rosa et al\\.,? \\Q2012\\E", "shortCiteRegEx": "Rosa et al\\.", "year": 2012}, {"title": "HamleDT 2.0: Thirty dependency treebanks stanfordized", "author": ["Rosa et al.2014] Rudolf Rosa", "Jan Ma\u0161ek", "David Mare\u010dek", "Martin Popel", "Daniel Zeman", "Zden\u011bk \u017dabokrtsk\u00fd"], "venue": null, "citeRegEx": "Rosa et al\\.,? \\Q2014\\E", "shortCiteRegEx": "Rosa et al\\.", "year": 2014}, {"title": "Parser combination by reparsing", "author": ["Sagae", "Lavie2006] Kenji Sagae", "Alon Lavie"], "venue": "In Proceedings of the Human Language Technology Conference of the NAACL, Companion Volume: Short Papers,", "citeRegEx": "Sagae et al\\.,? \\Q2006\\E", "shortCiteRegEx": "Sagae et al\\.", "year": 2006}, {"title": "Learnability-based syntactic annotation design", "author": ["Omri Abend", "Ari Rappoport"], "venue": "In Proceedings of COLING", "citeRegEx": "Schwartz et al\\.,? \\Q2012\\E", "shortCiteRegEx": "Schwartz et al\\.", "year": 2012}, {"title": "Functional sentence perspective in a generative description", "author": ["Petr Sgall"], "venue": "Prague studies in mathematical linguistics,", "citeRegEx": "Sgall.,? \\Q1967\\E", "shortCiteRegEx": "Sgall.", "year": 1967}, {"title": "An empirical etudy of non-lexical extensions to delexicalized transfer", "author": ["S\u00f8gaard", "Wulff2012] Anders S\u00f8gaard", "Julie Wulff"], "venue": "In COLING (Posters),", "citeRegEx": "S\u00f8gaard et al\\.,? \\Q2012\\E", "shortCiteRegEx": "S\u00f8gaard et al\\.", "year": 2012}, {"title": "Data point selection for cross-language adaptation of dependency parsers. In Proceedings of the 49th Annual Meeting of the Association for Computational Linguistics: Human Language Technologies: short papers", "author": ["Anders S\u00f8gaard"], "venue": null, "citeRegEx": "S\u00f8gaard.,? \\Q2011\\E", "shortCiteRegEx": "S\u00f8gaard.", "year": 2011}, {"title": "An empirical study of differences between conversion schemes and annotation guidelines", "author": ["Anders S\u00f8gaard"], "venue": "In Proceedings of the Second International Conference on Dependency Linguistics (DepLing", "citeRegEx": "S\u00f8gaard.,? \\Q2013\\E", "shortCiteRegEx": "S\u00f8gaard.", "year": 2013}, {"title": "Ensemble models for dependency parsing: Cheap and good", "author": ["Surdeanu", "Manning2010] Mihai Surdeanu", "Christopher D. Manning"], "venue": "In Human Language Technologies: The 2010 Annual Conference of the North American Chapter", "citeRegEx": "Surdeanu et al\\.,? \\Q2010\\E", "shortCiteRegEx": "Surdeanu et al\\.", "year": 2010}, {"title": "The conll-2008 shared task on joint parsing of syntactic and semantic dependencies", "author": ["Richard Johansson", "Adam Meyers", "Llu\u0131\u0301s M\u00e0rquez", "Joakim Nivre"], "venue": "In Proceedings of the Twelfth Conference on Computa-", "citeRegEx": "Surdeanu et al\\.,? \\Q2008\\E", "shortCiteRegEx": "Surdeanu et al\\.", "year": 2008}, {"title": "Cross-lingual word clusters for direct transfer of linguistic structure", "author": ["Ryan McDonald", "Jakob Uszkoreit"], "venue": "In Proceedings of the 2012 Conference of the North American Chapter of the Association", "citeRegEx": "T\u00e4ckstr\u00f6m et al\\.,? \\Q2012\\E", "shortCiteRegEx": "T\u00e4ckstr\u00f6m et al\\.", "year": 2012}, {"title": "Target language adaptation of discriminative transfer parsers", "author": ["Ryan McDonald", "Joakim Nivre"], "venue": null, "citeRegEx": "T\u00e4ckstr\u00f6m et al\\.,? \\Q2013\\E", "shortCiteRegEx": "T\u00e4ckstr\u00f6m et al\\.", "year": 2013}, {"title": "Cross-language parser adaptation between related languages", "author": ["Zeman", "Resnik2008] Daniel Zeman", "Philip Resnik"], "venue": "In IJCNLP 2008 Workshop on NLP for Less Privileged Languages,", "citeRegEx": "Zeman et al\\.,? \\Q2008\\E", "shortCiteRegEx": "Zeman et al\\.", "year": 2008}, {"title": "Hamledt: To parse or not to parse", "author": ["\u0160t\u011bp\u00e1nek", "Zden\u011bk \u017dabokrtsk\u00fd", "Jan Haji\u010d"], "venue": null, "citeRegEx": "\u0160t\u011bp\u00e1nek et al\\.,? \\Q2012\\E", "shortCiteRegEx": "\u0160t\u011bp\u00e1nek et al\\.", "year": 2012}, {"title": "Reusable tagset conversion using tagset drivers", "author": ["Daniel Zeman"], "venue": "In Proceedings of the 6th International Conference on Language Resources and Evaluation (LREC", "citeRegEx": "Zeman.,? \\Q2008\\E", "shortCiteRegEx": "Zeman.", "year": 2008}, {"title": "Cross language dependency parsing using a bilingual lexicon", "author": ["Zhao et al.2009] Hai Zhao", "Yan Song", "Chunyu Kit", "Guodong Zhou"], "venue": "In Proceedings of the Joint Conference of the 47th Annual Meeting of the ACL and the 4th International Joint Conference", "citeRegEx": "Zhao et al\\.,? \\Q2009\\E", "shortCiteRegEx": "Zhao et al\\.", "year": 2009}], "referenceMentions": [{"referenceID": 21, "context": "The success of these parsing algorithms, together with several CoNLL shared tasks focused on dependency parsing (Buchholz and Marsi, 2006; Nilsson et al., 2007; Surdeanu et al., 2008; Haji\u010d et al., 2009), even lead to a general transition from constituency parsing to dependency parsing throughout the NLP community.", "startOffset": 112, "endOffset": 203}, {"referenceID": 36, "context": "The success of these parsing algorithms, together with several CoNLL shared tasks focused on dependency parsing (Buchholz and Marsi, 2006; Nilsson et al., 2007; Surdeanu et al., 2008; Haji\u010d et al., 2009), even lead to a general transition from constituency parsing to dependency parsing throughout the NLP community.", "startOffset": 112, "endOffset": 203}, {"referenceID": 15, "context": "The problem of supervised dependency parsing of natural language sentences has been intensively studied for the past decade, especially since the invention of the graph-based MSTParser by McDonald et al. (2005a), and the transitionbased Malt parser by Nivre et al.", "startOffset": 188, "endOffset": 212}, {"referenceID": 15, "context": "The problem of supervised dependency parsing of natural language sentences has been intensively studied for the past decade, especially since the invention of the graph-based MSTParser by McDonald et al. (2005a), and the transitionbased Malt parser by Nivre et al. (2006). The success of these parsing algorithms, together with several CoNLL shared tasks focused on dependency parsing (Buchholz and Marsi, 2006; Nilsson et al.", "startOffset": 188, "endOffset": 272}, {"referenceID": 15, "context": "The problem of supervised dependency parsing of natural language sentences has been intensively studied for the past decade, especially since the invention of the graph-based MSTParser by McDonald et al. (2005a), and the transitionbased Malt parser by Nivre et al. (2006). The success of these parsing algorithms, together with several CoNLL shared tasks focused on dependency parsing (Buchholz and Marsi, 2006; Nilsson et al., 2007; Surdeanu et al., 2008; Haji\u010d et al., 2009), even lead to a general transition from constituency parsing to dependency parsing throughout the NLP community. The current state-of-the-art dependency parsers, such as the Mate parser of Bohnet and Nivre (2012), often achieve around 90% UAS (Unlabelled Attachment Score) for many languages.", "startOffset": 188, "endOffset": 690}, {"referenceID": 12, "context": "by Gildea (2001). This naturally motivates research of semi-supervised or unsupervised parsing methods.", "startOffset": 3, "endOffset": 17}, {"referenceID": 15, "context": "However, as shown by McDonald et al. (2011), not only is the similarity of languages only a weakly established concept, but the empirical results are often rather counterintuitive \u2013 for example, to parse Swedish, the best treebank to use turned out to be a Portuguese one, performing better than treebanks for Germanic languages (their dataset included, among other, German, Dutch, Danish, and English).", "startOffset": 21, "endOffset": 44}, {"referenceID": 25, "context": "On the syntactic level, not only the sets of labels are different, but even the unlabelled dependency structures differ, as they correspond to different linguistic theories; probably the highest variance can be found in the annotation of coordination structures, as studied by Popel et al. (2013). While some of the differences may be motivated by inherent properties of the respective languages, they very often correspond merely to more-or-less arbitrary design decisions of technical rather than linguistic nature, taken during the creation of the treebanks.", "startOffset": 277, "endOffset": 297}, {"referenceID": 39, "context": "The issues with cross-lingually incoherent annotation first led Zeman (2008) to the development of the Interset, a method of capturing values of most morphological features and for conversions between various tagsets.", "startOffset": 64, "endOffset": 77}, {"referenceID": 38, "context": "Later, the HamleDT collection of dependency treebanks was created by Zeman et al. (2012), consisting of treebanks harmonized not only on the morphological level (via Interset), but also on the syntactic level, loosely following the annotation style of the Prague Dependency Treebank of B\u00f6hmov\u00e1 et al.", "startOffset": 69, "endOffset": 89}, {"referenceID": 0, "context": "(2012), consisting of treebanks harmonized not only on the morphological level (via Interset), but also on the syntactic level, loosely following the annotation style of the Prague Dependency Treebank of B\u00f6hmov\u00e1 et al. (2003).", "startOffset": 204, "endOffset": 226}, {"referenceID": 18, "context": "In parallel, Petrov et al. (2012) defined the Universal POS tagset (UPOS) as a counter-weight to Interset, as it only captures 12 most important values of coarse-grained POS tags, ignoring all other morphological annotation.", "startOffset": 13, "endOffset": 34}, {"referenceID": 13, "context": "It was later used for annotation of the (eventually) 11 treebanks of the Google Universal Dependency Treebank collection of McDonald et al. (2013). For syntactic annotation, the authors defined their own version of the Stanford Dependencies (De Marneffe and Manning, 2008), modified to better suit the multilingual setting, as the original annotation style was implicitly designed for English.", "startOffset": 124, "endOffset": 147}, {"referenceID": 7, "context": "In turn, de Marneffe et al. (2014) reacted by introducing the Universal Stanford Dependencies as the \u201cofficial\u201d multilingual version of Stanford Dependencies.", "startOffset": 12, "endOffset": 35}, {"referenceID": 7, "context": "In turn, de Marneffe et al. (2014) reacted by introducing the Universal Stanford Dependencies as the \u201cofficial\u201d multilingual version of Stanford Dependencies. This annotation style was immediately adopted by Rosa et al. (2014), who modified it slightly and used it to \u201cstanfordize\u201d the HamleDT collection by implementing a languageneutral conversion pipeline and applying it to the", "startOffset": 12, "endOffset": 227}, {"referenceID": 22, "context": "project of Nivre et al. (2015),2 both defining an annotation style based mainly on UPOS, Interset and Universal Stanford Dependencies, as well as producing a set of 10 treebanks annotated in this way in the 1.", "startOffset": 11, "endOffset": 31}, {"referenceID": 41, "context": "As a prerequisite to applying the method, they map the treebank POS tagsets to a common set, an approach later becoming known as conversion to Interset (Zeman, 2008).", "startOffset": 152, "endOffset": 165}, {"referenceID": 40, "context": "The idea of delexicalized transfer was conceived by Zeman and Resnik (2008), who trained a delexicalized parser on a Danish treebank and evaluated it on a Swedish one.", "startOffset": 52, "endOffset": 76}, {"referenceID": 15, "context": "parser of Rosa (2014), an implementation of the unlabelled single-best MSTParser of McDonald et al. (2005b), with first-order", "startOffset": 84, "endOffset": 108}, {"referenceID": 10, "context": "The sentence parse tree is the maximum spanning tree (MST) over that graph, found using the algorithm of Chu and Liu (1965) and Edmonds (1967).", "startOffset": 128, "endOffset": 143}, {"referenceID": 24, "context": "POS tags We use the coarse 12-value UPOS of Petrov et al. (2012).6 For an edge, we use information about the POS tag of the head, dependent, their neighbours, and all of the nodes between them.", "startOffset": 44, "endOffset": 65}, {"referenceID": 22, "context": "the Malt parser of Nivre et al. (2006). For most of our approaches, this will be straightforward, but for the parser model interpolation approach (Section 6), it may be rather intriguing.", "startOffset": 19, "endOffset": 39}, {"referenceID": 10, "context": "To find the MST, we use the Chu-Liu-Edmonds algorithm (Chu and Liu, 1965; Edmonds, 1967), which was used by McDonald et al.", "startOffset": 54, "endOffset": 88}, {"referenceID": 11, "context": "Other MST algorithms could be used, such as the Eisner algorithm (Eisner, 1996), which is, unlike Chu-Liu-Edmonds, constrained to producing only projective parse trees, and was used by McDonald et al.", "startOffset": 65, "endOffset": 79}, {"referenceID": 13, "context": "The combination is performed using the idea of McDonald et al. (2005a), who formulated the problem of finding a parse tree as a problem of finding the maximum spanning tree of a weighted directed graph of potential parse tree edges.", "startOffset": 47, "endOffset": 71}, {"referenceID": 10, "context": "To find the MST, we use the Chu-Liu-Edmonds algorithm (Chu and Liu, 1965; Edmonds, 1967), which was used by McDonald et al. (2005b) in the non-projective MSTParser.", "startOffset": 36, "endOffset": 132}, {"referenceID": 10, "context": "To find the MST, we use the Chu-Liu-Edmonds algorithm (Chu and Liu, 1965; Edmonds, 1967), which was used by McDonald et al. (2005b) in the non-projective MSTParser. Other MST algorithms could be used, such as the Eisner algorithm (Eisner, 1996), which is, unlike Chu-Liu-Edmonds, constrained to producing only projective parse trees, and was used by McDonald et al. (2005a) in the projective MSTParser.", "startOffset": 36, "endOffset": 374}, {"referenceID": 10, "context": "Find the maximum spanning tree over the graph with the Chu-Liu-Edmonds algorithm (Chu and Liu, 1965; Edmonds, 1967).", "startOffset": 81, "endOffset": 115}, {"referenceID": 31, "context": "The Prague style dependencies, on the other hand, are based upon a functionalist approach of Sgall (1967), and annotate adpositions as heads of adpositional groups.", "startOffset": 93, "endOffset": 106}, {"referenceID": 30, "context": "The issue of dependency representation learnability has been studied by several authors, generally reaching similar conclusions (Schwartz et al., 2012; S\u00f8gaard, 2013; Ivanova et al., 2013).", "startOffset": 128, "endOffset": 188}, {"referenceID": 34, "context": "The issue of dependency representation learnability has been studied by several authors, generally reaching similar conclusions (Schwartz et al., 2012; S\u00f8gaard, 2013; Ivanova et al., 2013).", "startOffset": 128, "endOffset": 188}, {"referenceID": 13, "context": "The issue of dependency representation learnability has been studied by several authors, generally reaching similar conclusions (Schwartz et al., 2012; S\u00f8gaard, 2013; Ivanova et al., 2013).", "startOffset": 128, "endOffset": 188}, {"referenceID": 7, "context": "The approach suggested by de Marneffe et al. (2014) is to use a different annotation style for parsing, with", "startOffset": 29, "endOffset": 52}, {"referenceID": 20, "context": "Several authors (Naseem et al., 2012; S\u00f8gaard and Wulff, 2012; T\u00e4ckstr\u00f6m et al., 2013) have employed the World Atlas of Language Structures (WALS) of Dryer and Haspelmath (2013) to estimate the similarity of languages for delex transfer.", "startOffset": 16, "endOffset": 86}, {"referenceID": 38, "context": "Several authors (Naseem et al., 2012; S\u00f8gaard and Wulff, 2012; T\u00e4ckstr\u00f6m et al., 2013) have employed the World Atlas of Language Structures (WALS) of Dryer and Haspelmath (2013) to estimate the similarity of languages for delex transfer.", "startOffset": 16, "endOffset": 86}, {"referenceID": 20, "context": "Several authors (Naseem et al., 2012; S\u00f8gaard and Wulff, 2012; T\u00e4ckstr\u00f6m et al., 2013) have employed the World Atlas of Language Structures (WALS) of Dryer and Haspelmath (2013) to estimate the similarity of languages for delex transfer.", "startOffset": 17, "endOffset": 178}, {"referenceID": 33, "context": "In (S\u00f8gaard, 2011), he trains a POS language model on a tgt POS-tagged corpus, and uses it to filter the src treebank, keeping only sentences that look like target language sentences to the language model.", "startOffset": 3, "endOffset": 18}, {"referenceID": 3, "context": "This is made possible by modifying their learning algorithm to use weighted perceptron learning (Cavallanti et al., 2010).", "startOffset": 96, "endOffset": 121}, {"referenceID": 21, "context": "Preliminary trials on the subset of CoNLL 2006 and 2007 data sets (Buchholz and Marsi, 2006; Nilsson et al., 2007) used by McDonald et al.", "startOffset": 66, "endOffset": 114}, {"referenceID": 15, "context": ", 2007) used by McDonald et al. (2011) indicated that these are not suitable for our approach, as they are not harmonized on the dependency annotation level.", "startOffset": 16, "endOffset": 39}, {"referenceID": 15, "context": ", 2007) used by McDonald et al. (2011) indicated that these are not suitable for our approach, as they are not harmonized on the dependency annotation level.12 There, treebank annotation style similarity seems to become more important than language similarity; the lack of harmonization makes the data unnecessarily noisier. Table 7 contains the results of our methods both on the test languages and the development languages. For each target language, we used all remaining 29 source languages for training (in the single-source method, only one of them is selected and applied). We base our evaluation mainly on average UAS on the test tgt languages, and compare the methods by absolute UAS differences. Our baseline is the treebank concatenation method of McDonald et al. (2011), i.", "startOffset": 16, "endOffset": 782}, {"referenceID": 5, "context": "We are not aware of any prior work on interpolating dependency parser models; the closest to our approach is the interpolation of multilingual probabilistic context-free grammars of Cohen et al. (2011). The method proceeds as follows:", "startOffset": 182, "endOffset": 202}, {"referenceID": 27, "context": "through additional features, as has been done by Rosa et al. (2012), which does not require a oneto-one alignment.", "startOffset": 49, "endOffset": 68}, {"referenceID": 19, "context": "Recently, especially since the introduction of the word2vec tool by Mikolov et al. (2013), continuous vector space word representations, also known as word embeddings, have gained huge popularity, and have proven to be useful in many tasks of natural language processing.", "startOffset": 68, "endOffset": 90}, {"referenceID": 14, "context": "Some lexicalization can also be achieved in an unsupervised way by applying self-training (McClosky et al., 2006), i.", "startOffset": 90, "endOffset": 113}], "year": 2015, "abstractText": "We present our work on semi-supervised parsing of natural language sentences, focusing on multi-source crosslingual transfer of delexicalized dependency parsers. We first evaluate the influence of treebank annotation styles on parsing performance, focusing on adposition attachment style. Then, we present KLcpos3 , an empirical language similarity measure, designed and tuned for source parser weighting in multi-source delexicalized parser transfer. And finally, we introduce a novel resource combination method, based on interpolation of trained parser models.", "creator": "LaTeX with hyperref package"}}}