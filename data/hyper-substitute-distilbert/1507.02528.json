{"id": "1507.02528", "review": {"conference": "ICML", "VERSION": "v1", "DATE_OF_SUBMISSION": "9-Jul-2015", "title": "Faster Convex Optimization: Simulated Annealing with an Efficient Universal Barrier", "abstract": "start point methods and random walk experiments alike remain currently considered disparate useful for convex optimization. we show how simulated implementations, one consider the most common random running algorithms, were feasible, as your generic sense, to estimate posterior path interior point algorithm applied to the entropic universal block function. using this observation we improve virtual state of almost optimal robust polynomial time distributed configurations. we give a randomized algorithm for optimization over a convex plane, defined by a continuous scale, which improves the semantics of us art behaviour at most square root assuming different dimension. this result is based on then new temperature reverse _ computation procedures, existing after the similarities to the central path following interior route algorithm requiring partially desired universal barrier function.", "histories": [["v1", "Thu, 9 Jul 2015 14:32:55 GMT  (19kb)", "https://arxiv.org/abs/1507.02528v1", null], ["v2", "Thu, 5 Nov 2015 16:50:41 GMT  (96kb,D)", "http://arxiv.org/abs/1507.02528v2", null]], "reviews": [], "SUBJECTS": "math.OC cs.LG", "authors": ["jacob d abernethy", "elad hazan"], "accepted": true, "id": "1507.02528"}, "pdf": {"name": "1507.02528.pdf", "metadata": {"source": "CRF", "title": "Faster Convex Optimization: Simulated Annealing with an Efficient Universal Barrier", "authors": ["Jacob Abernethy"], "emails": ["jabernet@umich.edu", "ehazan@princeton.edu"], "sections": [{"heading": null, "text": "ar X\niv :1\n50 7.\n02 52\n8v 2\n[ m\nat h.\nO C\n] 5"}, {"heading": "1 Introduction", "text": "Convex optimization is by now a well established field and a cornerstone of the fields of algorithms and machine learning. Polynomial time methods for convex optimization belong to relatively few classes: the oldest and perhaps most general is the ellipsoid method with roots back to Kachiyan in the 50s [4]. Despite its generality and simplicity, the ellipsoid method is known to perform poorly in practice.\nA more recent family of algorithms are the celebrated interior point methods, initially developed by Karmarkar in the context of linear programming, and generalized in the seminal work of Nesterov and Nemirovskii [16]. These methods are known to perform well in practice and come with rigorous theoretical guarantees of polynomial running time, but with a significant catch: the underlying constraints must admit an efficiently-computable self-concordant barrier function. Barrier functions are defined as satisfying certain differential inequality conditions that facilitate the path-following scheme developed by Nesterov and Nemirovskii [16], in particular it guarantees that the Newton step procedure maintains feasibility of the iterates. Indeed the iterative path following scheme essentially reduces the optimization problem to the construction of a barrier function, and in many nice scenarios a self-concordant barrier is easy to obtain; e.g., for polytopes the simple logarithmic barrier suffices. Yet up to the present there is no known universal efficient construction of a barrier that applies to any convex set. The problem is seemingly even more difficult in the membership oracle model where our access to K is given only via queries of the form \u201cis x \u2208 K?\u201d.\nThe most recent polynomial time algorithms are random-walk based methods, originally pioneered in the work of Dyer et al. [3] and greatly advanced by Lova\u0301sz and Vempala [13]. These algorithms apply in full generality of convex optimization and require only a membership oracle. The state of the art in polynomial time convex optimization is the random-walk based algorithm of simulated annealing and the specific temperature schedule analyzed in the breakthrough of Kalai and Vempala [7]. Improvements have been given in certain cases, most notably in the work of Narayanan and Rakhlin [14] where barrier functions were utilized.\nIn this paper we tie together two of the three known methodologies for convex optimization, give an efficiently computable universal barrier for interior point methods, and derive a faster algorithm for convex optimization in the membership oracle model. Specifically,\n1. We define the heat path of a simulated annealing method as the (determinisitc) curve formed by the mean of the annealing distribution as the temperature parameter is continuously decreased. We show that the heat path coincides with the central path of an interior point algorithm with the entropic universal barrier function. This intimately ties the two major convex optimization methods together and shows they are approximately equivalent over any convex set.\nWe further enhance this connection by showing that the central path following interior point method applied with the universal entropic barrier is a first-order approximation of simulated annealing.\n2. Using the connection above, we give an efficient randomized interior point method with an efficiently computable universal barrier for any convex set described by a membership oracle. Previously, efficiently computable barriers were known only for particular convex sets.\n3. We give a new temperature schedule for simulated annealing inspired by interior point methods. This gives rise to an algorithm for general convex optimization with running time of O\u0303( \u221a \u03bdn4),\nwhere \u03bd is the self-concordance parameter of the entropic barrier. The previous state of the\nart is O\u0303(n4.5) by [7]. We note that our algorithm does not need explicit access to the entropic barrier, it only appears in the analysis of the temperature schedule.\nIt was recently shown by Bubeck and Eldan [2] that the entropic barrier satisfies all require self-concordance properties and that the associated barrier parameter satisfies \u03bd \u2264 n(1 + o(1)), although this is generally not tight. Our algorithm improves the previous annealing run time by a factor of O\u0303( \u221a n \u03bd ) which in many cases is o(1). For example, in the case of semi-definite programming over matrices in Rn\u00d7n, the entropic barrier is identically the standard log-determinant barrier [5], exhibiting a parameter \u03bd = n, rather than n2, which an improvement of n compared to the state-of-the-art. More details are given in section 4.4.\nThe Problem of Convex Optimization For the remainder of the paper, we will be considering the following algorithmic optimization problem. Assume we are given access to an arbitrary bounded convex set K \u2282 Rn, and we shall assume without loss of generality that K lies in a 2-norm ball of radius 1. Assume we are also given as input a vector \u03b8\u0302 \u2208 Rn. Our goal is to solve the following:\nmin x\u2208K\n\u03b8\u0302>x. (1)\nWe emphasize that this is, in a certain sense, the most general convex optimization problem one can pose. While the objective is linear in x, we can always reduce non-linear convex objectives to the problem (1). If we want to solve minx\u2208K f(x) for some convex f : K \u2192 R, we can instead define a new problem as follows. Letting K\u2032 := {(x, c) \u2208 K \u00d7 R : f(x) \u2212 c \u2264 0}, this non-linear problem is equivalent to solving the linear problem min{(x,c)\u2208K\u2032} c. This equivalence is true in in the membership oracle model, since a membership oracle for K immediately implies an efficient membership oracle for K\u2032."}, {"heading": "1.1 Preliminaries", "text": "This paper ties together notions from probability theory and convex analysis, most definitions are deferred to where they are first used. We try to follow the conventions of interior point literature as in the excellent text of Nemirovski [15], and the simulated annealing and random-walk notation of [7].\nFor some constant C, we say a distribution P is C-isotropic if for any vector v \u2208 Rd we have\n1 C \u2016v\u20162 \u2264 E X\u223cP [(v>X)2] \u2264 C\u2016v\u20162.\nLet P, P \u2032 be two distributions on Rn with means \u00b5, \u00b5\u2032, respectively. We say P is C-isotropic with respect to P \u2032 if\n1 C E X\u223cP \u2032 [(v>X)2] \u2264 E X\u223cP [(v>X)2] \u2264 C E X\u223cP \u2032 [(v>X)2].\nOne measure of the distance between two distributions, often referred to as the `2 norm, is given by \u2225\u2225\u2225\u00b5\n\u03c0 \u2225\u2225\u2225 \u2261 E x\u223c\u00b5 ( \u00b5(x) \u03c0(x) ) = \u222b x\u223c\u00b5 ( \u00b5(x) \u03c0(x) ) d\u00b5(x).\nWe note that this distance is not symmetric in general.\nFor a differentiable convex function f : Rn \u2192 R, the Bregman divergence Df (x, y) between points x, y \u2208 dom(f) is the quantity\nDf (x, y) \u2261 f(x)\u2212 f(y)\u2212\u2207f(y)>(x\u2212 y).\nFurther, we can always define the Fenchel conjugate (or Fenchel dual) [17] which is the function f\u2217 defined as\nf\u2217(\u03b8) := supx\u2208dom(f) \u03b8 >x\u2212 f(x). (2)\nIt is easy to see that f\u2217(\u00b7) is also convex, and under weak conditions one has f\u2217\u2217 = f . A classic duality result (see e.g. [17]) states that when f\u2217 is smooth and strictly convex on its domain and tends to infinity at the boundary, we have a characterization of the gradients of f and f\u2217 in terms of maximizers:\n\u2207f\u2217(\u03b8) = arg max x\u2208dom(f) \u03b8>x\u2212 f(x) and \u2207f(x) = arg max \u03b8\u2208dom(f\u2217) \u03b8>x\u2212 f\u2217(\u03b8). (3)"}, {"heading": "1.2 Structure of this paper", "text": "We start by an overview of random-walk methods for optimization in the next section, and introduce the notion of the heat path for simulated annealing. The following section surveys the important notions from interior point methods for optimization and the entropic barrier function. In section 4 we tie the two approaches together formally by proving that the heat path and central path are the same for the entropic barrier. We proceed to give a new temperature schedule for simulated annealing as well as prove its convergence properties. In the appendix we describe the KalaiVempala methodology for analyzing simulated annealing and its main components for completeness."}, {"heading": "2 An Overview of Simulated Annealing", "text": "Consider the following distribution over the set K for an arbitrary input vector \u03b8 \u2208 Rn.\nP\u03b8(x) := exp(\u2212\u03b8>x)\u222b\nK exp(\u2212\u03b8>x\u2032) dx\u2032 . (4)\nThis is often referred to as the Boltzmann distribution and is a natural exponential family parameterized by \u03b8. It was observed by [7] that the optimization objective (1) can be reduced to sampling from these distributions. That is, if we choose some scaling quantity t > 0, usually referred to as the temperature, then any sample X from the distribution P\u03b8\u0302/t must be nt-optimal in expectation. More precisely, [7] show that\nE X\u223cP\u03b8\u0302/t\n[\u03b8\u0302>X]\u2212min x\u2208K \u03b8\u0302>x \u2264 nt. (5)\nAs we show later, our connection implies an even stronger statement, replacing n above by the self-concordant parameter of the entropic barrier, as we will define in the next section equation (10).\nIt is quite natural that for small temperature parameter t \u2208 R, samples from the P \u03b8 t are essentially optimal \u2013 the exponential nature of the distribution will eventually concentrate all probability mass on a small neightborhood around the maximizing point x\u2217 \u2208 K. The problem, of course, is that sampling from a point mass around x\u2217 is precisely as hard as finding x\u2217.\nThis brings us to the technique of so-called simulated annealing, originally introduced by Kirkpatrick et al. [9] for solving generic problems of the form minx\u2208K f(x), for arbitrary (potentially non-convex) functions f . At a very high level, simulated annealing would begin by sampling from a \u201chigh-entropy\u201d distribution (t very close to 0), and then continue by slowly \u201cturning down the temperature\u201d on the distribution, i.e. decreasing t, which involves sampling according to the pdf Qf,t(x) \u221d exp(\u22121t f(x)). The intuition behind annealing is that, as long as t\n\u2032/t is a small constant, then the distributions Qf,t\u2032 and Qf,t will be \u201cclose\u201d in the sense that a random walk starting from the initial distribution Qf,t\u2032 will mix quickly towards its stationary distribution Qf,t.\nSince its inception, simulated annealing is generally referred to as a heuristic for optimization, as polynomial-time guarantees have been difficult to establish. However, the seminal work of Kalai and Vempala [7] exhibited a poly-time annealing method with formal guarantees for solving linear optimization problems in the form of (1). Their technique possessed a particularly nice feature: the sampling algorithm utilizes a well-studied random walk (Markov chain) known as HitAndRun [18, 10, 13], and the execution of this Markov chain requires only access to a membership oracle on the set K. That is, HitAndRun does not rely on a formal description of K but only the ability to (quickly) answer queries \u201cx \u2208 K?\u201d for arbitrary x \u2208 Rd.\nLet us now describe the HitAndRun algorithm in detail. We note that this Markov chain was first introduced by Smith [18], a poly-time guarantee was given by Lova\u0301sz [10] for uniform sampling, and this was generalized to arbitrary log-concave distributions by Lova\u0301sz and Vempala [11]. HitAndRun requires several inputs, including: (a) the distribution parameter \u03b8, (b) an estimate of the covariance matrix \u03a3 of P\u03b8, (c) the membership oracle OK, for K, (d) a starting point X0, and (e) the number of iterations N of the random walk.\nAlgorithm 1: HitAndRun(\u03b8,OK, N,\u03a3, X0) for approximately sampling P\u03b8 1 Inputs: parameter vector \u03b8, oracle OK for K, covariance matrix \u03a3, #iterations N , initial X0 \u2208 K. 2 for i = 1, 2, . . . , N do 3 Sample a random direction u \u223c N(0,\u03a3) 4 Querying OK, determine the line segment R = {Xi\u22121 + \u03c1u : \u03c1 \u2208 R} \u2229 K 5 Sample a point Xi from R according to the distribution P\u03b8 restricted to R\n6 Return XN\nThe first key fact of HitAndRun(\u03b8) is that the stationary distribution of this Markov chain is indeed the desired P\u03b8; a proof can be found in [19]. The difficulty for this and many other random walk techniques is to show that the Markov chain \u201cmixes quickly\u201d, in that the number of steps N needn\u2019t be too large as a function of n. This issue has been the subject of much research will be discussed below. Before proceeding, we note that a single step of HitAndRun can be executed quite efficiently. Sampling a random gaussian vector with covariance \u03a3 (line 3) can be achieved by simply sampling a standard gaussian vector z and returning \u03a31/2z. Computing the line segment R (line 4) requires simply finding the two locations where the line {Xi\u22121 +\u03c1u : \u03c1 \u2208 R} intersects with the boundary of K, but an -approximation of these points can be found via binary search using O ( log 1 ) queries to OK. Sampling from P\u03b8 restricted to the line segment R can also be achieved efficiently, and we refer the reader to Vempala [19]. The analysis for simulated annealing in [7] proceeds by imagining a sequence of distributions\nP\u03b8k = P\u03b8\u0302/tk where t1 = R is the diameter of the set K and tk := ( 1\u2212 1\u221a n )k . Let k = O( \u221a n log n ), then sampling from P\u03b8k is enough to achieve the desired optimization guarantee. That is, via Equation 5, we see a sample from P\u03b8k is -optimal in expectation.\nTo sample from P\u03b8k , [7] construct a recursive sampling oracle using HitAndRun. The idea is that samples from P\u03b8k+1 can be obtained from a warm start by sampling from P\u03b8k according to a carefully chosen temperature schedule. The details are given in Algorithm 2.\nAlgorithm 2: SimulatedAnnealing with HitAndRun \u2013 Kalai and Vempala [7]\n1 Input: temperature schedule {tk, k \u2208 [T ]}, objective \u03b8\u0302. 2 Set X0 = 0, \u03a31 = I, t1 = R 3 for k = 1, ..., T do 4 \u03b8k \u2190 \u03b8\u0302tk 5 Xk \u2190 HitAndRun(\u03b8k,OK, N,\u03a3k, Xk\u22121) 6 for j = 1, .., n do 7 Y jk = HitAndRun(\u03b8k,OK, N,\u03a3k, Y j k\u22121) 8 Estimate covariance: \u03a3k+1 := CovMtx(Y k 1 , . . . , Y k n )\n9 Return XT\nThe Kalai and Vempala [7] analysis leans on a number of technical but crucial facts which they prove. The temperature update schedule that they devise, namely tk = (1\u2212 1\u221an)tk\u22121, is shown to satisfy these iterative rules and thus return an approximate solution.\nTheorem 1 (Key result of Kalai and Vempala [7] and Lova\u0301sz and Vempala [11]). Fix k and consider the HitAndRun walk used in Algorithm 2 to compute Xk and Y j k for each j. Assume we choose the temperature schedule in order that successive distributions P\u03b8k , P\u03b8k\u22121 are close in `2:\nmax {\u2225\u2225\u2225 P\u03b8kP\u03b8k\u22121 \u2225\u2225\u22252 , \u2225\u2225\u2225P\u03b8k\u22121P\u03b8k \u2225\u2225\u22252 } \u2264 10. (6)\nThen, as long as the warm start samples Xk\u22121 and Y j k\u22121 are (approximately) distributed according to P\u03b8k\u22121, the random walk HitAndRun mixes to P\u03b8k with N = O\u0303(n 3) steps. That is, the output samples Xk and Y j k are distributed according to P\u03b8k up to error \u2264 .\nIn the appendix we sketch the proof of this theorem for completeness.\nCorollary 1. The temperature schedule tk := (1\u2212 1/ \u221a n) k t1 satisfies condition (6), and thus Algorithm 2 with this schedule returns an -approximate solution in time O\u0303(n4.5).\nProof. By equation (5), to achieve error it suffice that 1t \u2265 n , or in other words k needs to be large enough such that (1\u2212 1\u221a n )k \u2264 n for which k = 8 \u221a n log n suffices: (1\u2212 1\u221a n )k \u2264 e\u2212 k 2 \u221a n = e\u22124 log n \u2264 n . Hence the temperature schedule need be applied with T = O\u0303( \u221a n) iterations. Each iteration requires O(n) applications of HitAndRun that cost O(n3), for the total running time of O\u0303(n4.5).\nIn later sections we proceed to give a more refined temperature schedule that satisfies the KalaiVempala conditions, and thus results in a faster algorithm. Our temperature schedule is based on new observations in interior point methods, which we describe next."}, {"heading": "2.1 The heat path for simulated annealing", "text": "Our main result follow from the observation that the path-following interior point method has an analogue in the random walk world. Simulated annealing incorporates a carefully chosen temperature schedule to reach its objective from a near-uniform distribution. We can think of all temperature schedules as performing a random process whose changing mean is a single well-defined curve. For a given convex set K \u2286 Rd and objective \u03b8\u0302, define the heat path as the following set of points, parametrized by the temperature t \u2208 [0,\u221e] as follows:\nHeatPath(t) = E x\u223cP\u03b8\u0302/t [x]\nWe can now define the heat path as HeatPath = \u222at\u22650{HeatPath(t)}. At this point it is not yet clear why this set of points is even a continuous curve in space, let alone equivalent to an analogous notion in the interior point world. We will return to this equivalence in section 4."}, {"heading": "3 An Overview of Interior Point Methods for Optimization", "text": "Let us now review the vast literature on Interior Point Methods (IPMs) for optimization, and in particular the use of the Iterative Newton Step technique. The first instance of polynomial time algorithms for convex optimization using interior point machinery was the linear programming algorithm of Karmarkar [8]. The pioneering book of Nesterov and Nemirovskii [16] brought up\ntechniques in convex analysis that allowed for polynomial time algorithms for much more general convex optimization, ideas that are reviewed in great detail and clarity in [15] .\nThe goal remains the same, to solve the linear optimization problem posed in Equation (1). The intuition behind IPMs is that iterative update schemes such as gradient descent for solving (1) can fail because the boundary of K can be difficult to manage, and \u201cmoving in the direction of descent\u201d will fail to achieve a fast rate of convergence. Thus one needs to \u201csmooth out\u201d the objective with the help of an additional function. In order to produce an efficient algorithm, a well-suited type of function is known as a self-concordant barrier which have received a great deal of attention in the optimization literature.\nA self-concordant barrier function \u03d5 : int(K)\u2192 R, with barrier parameter, \u03bd is a convex function satisfying two differential conditions: for any h \u2208 Rn and any x \u2208 K,\n\u22073\u03d5[h, h, h] \u2264 2(\u22072\u03d5[h, h])3/2, and \u2207\u03d5[h] \u2264 \u221a \u03bd\u22072\u03d5[h, h], (7)\nin addition to the property that the barrier should approach infinity when approaching the boundary of K. Such function possess very desirable properties from the perspective of optimization, several of which we discuss in the present section. We note an important fact: while the existence of such a function \u03d5 for general sets K has been given by Nesterov and Nemirovskii [16]\u2014the universal barrier with parameter parameter \u03bd = O(n), to be discussed further in Section 4.4\u2014an efficient construction of such a function has remained elusive and was considered an important question in convex optimization. This indeed suggests that the annealing results we previously outlined are highly desirable, as HitAndRun requires only a membership oracle on K. However, one of the central results of the present work is the equivalence between annealing and IPMs, where we show that sampling gives one implicit access to a particular barrier function. This will be discussed at length in Section 4.\nLet us now assume we are given such a function \u03d5 with barrier parameter \u03bd. A standard approach to solving (1) is to add the function \u03d5(x) to the primary objective, scaling the linear term by a \u201ctemperature\u201d parameter t > 0:\nmin x\u2208K {t\u03b8\u0302>x+ \u03d5(x)}. (8)\nAs the the temperature t tends to \u221e the solution of (8) will tend towards the optimal solution to 1. This result is proved for completeness in Theorem 2.\nTowards developing in detail the iterative Newton algorithm, let us define the following for every positive integer k:\ntk := (\n1 + c\u221a \u03bd\n)k for some c > 0, (9)\n\u03a6k(x) := tk\u03b8\u0302 >x+ \u03d5(x)\nx\u0304k := arg min x \u03a6k(x)\nAs \u03d5 is a barrier function, it is clear that x\u0304k is in the interior of K and, in particular, \u2207\u03a6k(x\u0304k) = 0 =\u21d2 \u2207\u03d5(x\u0304k) = tk\u03b8\u0302. It is shown in [15] (Equation 3.6) that any \u03bd-SCB (Self-Concordant Barrier) \u03d5 satisfies \u2207\u03d5(x)>(y \u2212 x) \u2264 \u03bd, whence we can bound the difference in objective value between x\u0304k and the optimal point x\u2217:\n\u03b8\u0302>(x\u2217 \u2212 x\u0304k) = \u2207\u03d5(x\u0304k)>(x\u2217 \u2212 x\u0304k)\ntk \u2264 \u03bd tk . (10)\nWe see that the approximation point x\u0304k becomes exponentially better as k increases. Indeed, setting k = d \u221a \u03bd c log(\u03bd/ )e guarantees that the error is bounded by .\nThe iterative Newton\u2019s method technique actually involves approximating x\u0304k with x\u0302k, a nearoptimal maximizer of \u03a6k, at each iteration k. For an arbitrary v \u2208 Rn, x \u2208 int(K), and any k \u2265 1, following [15] we define:\n\u2016v\u2016x := \u221a v>\u22072\u03d5(x)v, the \u201clocal norm\u201d of v w.r.t x; (11)\n\u2016v\u2016\u2217x := \u221a v>\u2207\u22122\u03d5(x)v, the corresponding dual norm of v, (12) \u03bb(x, tk) := \u2016\u2207\u03a6k(x)\u2016\u2217x, the Newton decrement of x for temperature tk. (13)\nNote that, for a fixed point x \u2208 K, the norms \u2016 \u00b7 \u2016x and \u2016 \u00b7 \u2016\u2217x are dual to each other1. It will turn out that \u03bb(x, tk) will be used both as a quantity in the algorithm, and as a kind of potential that we need to keep small.\nIn Algorithm 3 we describe the damped newton update algorithm, henceforth called IterativeNewtonStep. We note that the\nAlgorithm 3: IterativeNewtonStep\n1 Input: \u03b8\u0302 \u2208 Rd, K and barrier function \u03d5 2 Solve: x\u03020 = arg maxx\u2208K \u03b8\u0302\n>x+ \u03d5(x) 3 for k = 1, 2, . . . do 4 x\u0302k \u2190 x\u0302k\u22121 \u2212 11+\u03bb(x\u0302k\u22121,tk)\u2207 \u22122\u03d5(x\u0302k\u22121)\u2207\u03a6k(x\u0302k\u22121)\nThe most difficult part of the analysis is in the following two lemmas, which are crucial elements of the IterativeNewtonStep analysis. A full exposition of these results is found in the excellent survey [15]. The first lemma tells us that when we update the temperature, we don\u2019t perturb the Newton decrement too much. The second lemma establishes the quadratic convergence of the Newton Update for a fixed temperature.\nLemma 1. Let c be the constant chosen in the definition (9). Let t > 0 be arbitrary and let t\u2032 = t (\n1 + c\u221a \u03bd\n) . Then for any x \u2208 int(K), we have \u03bb(x, t\u2032) \u2264 (1 + c)\u03bb(x, t) + c.\nLemma 2. Let k be arbitrary and assume we have some x\u0302k\u22121 such that \u03bb(x\u0302k\u22121, tk) is finite. The Newton update x\u0302k satisfies \u03bb(x\u0302k, tk) \u2264 2\u03bb2(x\u0302k\u22121, tk).\nThe previous two lemmas can be combined to show that the following invariant is maintained. Neither the constant bound of 1/3 on the Newton decrement nor the choice of c = 1/20 are particularly fundamental; they are convenient for the analysis but alternative choices are possible.\nLemma 3. Assume we choose c = 1/20 for the parameter in (9). Then for all k we have \u03bb(x\u0302k, tk) < 1 3 .\n1Technically, for \u2016 \u00b7 \u2016x and its dual to be a norm, we need \u22072\u03d5 to be positive definite and \u03d5 to be strictly convex. One can verify this is the case for bounded sets, which is the focus of this paper.\nProof. We give a simple proof by induction. The base case is satisfied since we assume that \u03bb(x\u03020, t0) = 0, as t0 = 1. 2 For the inductive step, assume \u03bb(x\u0302k\u22121, tk\u22121) < 1/3. Then\n\u03bb(x\u0302k, tk) \u2264 2\u03bb2(x\u0302k\u22121, tk) \u2264 2((1 + c)\u03bb(x\u0302k\u22121, tk\u22121) + c)2 < 2(0.4)2 < 1/3.\nThe first inequality follows by Lemma 2 and the second by Lemma 1, hence we are done.\nTheorem 2. Let x\u2217 be a solution to the objective (1). For every k, x\u0302k is an k-approximate solution to (1), where k = \u03bd+ \u221a \u03bd/4\ntk . In particular, for any > 0, as long as k > \u221a \u03bd c log(2\u03bd/ ) then x\u0302k is an\n-approximation solution.\nProof. Let k be arbitrary. Then,\n\u03b8\u0302>(x\u0302k \u2212 x\u2217) = \u03b8\u0302>(x\u0304k \u2212 x\u2217) + \u03b8\u0302>(x\u0302k \u2212 x\u0304k) (By (10)) \u2264 \u03bdtk + \u03b8\u0302 >(x\u0302k \u2212 x\u0304k)\n(Ho\u0308lder\u2019s Inequality) \u2264 \u03bdtk + \u2016\u03b8\u0302\u2016 \u2217 x\u0304k \u2016x\u0304k \u2212 x\u0302k\u2016x\u0304k\n([15] Eqn. 2.20) \u2264 \u03bdtk + \u2016\u03b8\u0302\u2016 \u2217 x\u0304k \u03bb(x\u0302k,tk) 1\u2212\u03bb(x\u0302k,tk) (Applying Lemma 3 and (14)) \u2264 \u03bdtk + \u2225\u2225\u2225\u2207\u03d5(x\u0304k)tk \u2225\u2225\u2225\u2217x\u0304k 14 \u2264 \u03bd+\u221a\u03bd/4tk\nThe last equation utilizes a fact that derives immediately from the definition (7), namely\n\u2016\u2207\u03d5\u2217(x)\u2016\u2217x = \u2016\u2207\u03d5\u2217(x)\u2016\u03b8(x) \u2264 \u221a \u03bd (14)\nholds for any SCBF \u03d5 with parameter \u03bd, and for any x \u2208 K.\nWe proceed to give a specific barrier function that applies to any convex set and gives rise to an efficient algorithm."}, {"heading": "4 The Equivalence of IterativeNewton and SimulatedAnnealing", "text": "We now show that the previous two techniques, Iterative Newton\u2019s Method and Simulated Annealing, are in a certain sense two sides of the same coin. In particular, with the appropriate choice of barrier function \u03d5 the task of computing the sequence of Newton iterates x\u03021, x\u03022, . . . may be viewed precisely as estimating the means for each of the distributions P\u03b81 , P\u03b82 , . . .. This correspondence helps to unify two very popular optimization methods, but also provides three additional novel results:\n1. We show that the heat path for simulated annealing is equivalent to the central path with the entropic barrier.\n2As stated, Algorithm 3 requires finding the minimizer of \u03d5(\u00b7) on K, but this is not strictly necessary. The convergence rate can be established as long as a \u201creasonable\u201d initial point x\u03020 can be computed\u2014e.g. it suffices that \u03bb(x\u03020, 1) < 1/2.\n2. We show that the running time of Simulated Annealing can be improved to O(n4 \u221a \u03bd) from the\nprevious best of O(n4.5). In the most general case we know that \u03bd = O(n), but there are many convex sets in which the parameter \u03bd is significantly smaller. Notably such is the case for the positive-semi-definite cone, which is the basis of semi-definite programming and a cornerstone of many approximation algorithms. Further examples are surveyed in section 4.4.\n3. We show that Iterative Newton\u2019s Method, which previously required a provided barrier function on the set K, can now be executed efficiently where the only access to K is through a membership oracle. This method relies heavily on previously-developed sampling techniques [7]. Discussion is deferred to Appendix C."}, {"heading": "4.1 The Duality of Optimization and Sampling", "text": "We begin by rewriting our Boltzmann distribution for \u03b8 in exponential family form, P\u03b8(x) := exp(\u2212\u03b8>x\u2212A(\u03b8)) where A(\u03b8) := log \u222b K exp(\u2212\u03b8 >x\u2032)dx\u2032. (15)\nThe function A(\u00b7) is known as the log partition function of the exponential family, and it has several very natural properties in terms of the mean and variance of P\u03b8:\n\u2207A(\u03b8) = \u2212 E X\u223cP\u03b8 [X] (16)\n\u22072A(\u03b8) = E X\u223cP\u03b8 [(X \u2212 EX)(X \u2212 EX)>]. (17)\nWe can also appeal to Convex (Fenchel) Duality [17] to obtain the conjugate\nA\u2217(x) := sup\u03b8 \u03b8 >x\u2212A(\u03b8). (18)\nIt is easy to establish that A\u2217 is smooth and strictly convex. The domain of A\u2217(\u00b7) is precisely the space of gradients of A(\u00b7), and it is straightforward to show that this is the set int(\u2212K), the interior of the reflection of K about the origin. However we want a function defined on (the interior of) K, not its reflection, so let us define a new function A\u2217\u2212(x) := A\n\u2217(\u2212x) whose domain is int(K). We now present a recent result of Bubeck and Eldan [2].\nTheorem 3 ([2]). The function A\u2217\u2212 is a \u03bd-self-concordant barrier function on K with \u03bd \u2264 n(1 + o(1)).\nOne of the significant drawbacks of barrier/Newton techniques is the need for a readily-available self-concordant barrier function. In their early work on interior point methods, Nesterov and Nemirovskii [16] provided such a function, often referred to as the \u201cuniversal barrier\u201d, yet the actual construction was given implicitly without oracle access to function values or derivatives. Bubeck and Eldan [2] refer to function A\u2217\u2212(\u00b7) as the entropic barrier, a term we will also use, as it relates to a notion of differential entropy of the exponential family of distributions.\nIt is important to note that, when our set of interest is a cone K, the entropic barrier on K corresponds exactly to the Fenchel dual of the universal barrier on the dual cone K\u2217 [6], which immediately establishes the self-concordance. Indeed, many beautiful properties of the entropic barrier on cones have been developed, and for a number of special cases A\u2217\u2212(\u00b7) corresponds exactly\nto the canonical barrier used in practice; e.g. A\u2217\u2212(\u00b7) on the PSD cone corresponds to the logdeterminant barrier. In many such cases one obtains a much smaller barrier parameter \u03bd than the n(1 + o(1)) bound. We defer a complete discussion to Section 4.4.\nIn order to utilize A\u2217\u2212(\u00b7) as a barrier function as in (8) we must be able to approximately solve objectives of the form minx\u2208K{\u03b8>x + A\u2217\u2212(x)}. One of the key observations of the paper, given in the following Proposition, is that solving this objective correponds to computing the mean of the distribution P\u03b8.\nProposition 1. Let \u03b8 \u2208 Rn be arbitrary, and let P\u03b8 be defined as in (15). Then we have\nE X\u223cP\u03b8 [X] = arg min x\u2208int(K)\n{ \u03b8>x+A\u2217\u2212(x) } . (19)\nProof. Let \u03b8 be an arbitrary input vector. As we mentioned in (3), standard Fechel duality theory gives us\n\u2207A(\u03b8) = arg max x\u2208dom(A\u2217)\n{ \u03b8>x\u2212A\u2217(x) } = arg min\nx\u2208dom(A\u2217)\n{ \u2212\u03b8>x+A\u2217(x) } .\nIt can be verified that the domain of A\u2217 is precisely the interior of \u2212K, the reflection of K. Thus we have\n\u2207A(\u03b8) = arg min x\u2208int(\u2212K)\n{ \u2212\u03b8>x+A\u2217(x) } = \u2212 ( arg min x\u2208int(K) { \u03b8>x+A\u2217\u2212(x) }) .\nIn addition, we noted in (15) that \u2207A(\u03b8) = \u2212EX\u223cP\u03b8 [X]. Combining the latter two facts gives the result.\nWe now have a direct connection between sampling methods and barrier optimization. For the remainder of this section, we shall assume that our chosen \u03d5(\u00b7) is the entropic barrier A\u2217(\u00b7), and the quantities \u03a6k(\u00b7), \u2016 \u00b7 \u2016x, \u03bb(\u00b7, \u00b7) are defined accordingly. We shall also use the notation x(\u03b8) := EX\u223cP\u03b8 [X] = \u2212\u2207A(\u03b8). Lemma 4. Let \u03b8, \u03b8\u2032 be such that \u2016x(\u03b8\u2032)\u2212 x(\u03b8)\u2016x(\u03b8) \u2264 12 . Then we have\nDA\u2217\u2212(x(\u03b8 \u2032), x(\u03b8)) = KL(P \u2032\u03b8, P\u03b8) = DA(\u03b8, \u03b8 \u2032) \u2264 2\u2016x(\u03b8\u2032)\u2212 x(\u03b8)\u20162x(\u03b8) (20)\nProof. The duality relationship of the Bregman divergence, and its equivalence to Kullback-Leibler divergence, is classical and can be found in, e.g., [20] equation (5.10) The final inequality follow as a direct consequence of [15], Equation 2.4."}, {"heading": "4.2 Equivalence of the heat path and central path", "text": "The most appealing observation on the equivalence between random walk optimization and interior point methods is the following geometric equivalence of curves. For a given convex set K \u2286 Rd and objective \u03b8\u0302, define the heat path as the following set of points:\nHeatPath = \u222a t\u22650 {HeatPath(t)} = \u222a t\u22650 { E x\u223cP \u03b8\u0302\nt\n[x]}\nTo see that this set of points is a continuous curve in space, consider the central path w.r.t. barrier function \u03d5(x):\nCentralPath(\u03d5) = \u222a t\u22650 {CentralPath(t, \u03d5)} = \u222a t\u22650 {arg min x\u2208K {t\u03b8\u0302>x+ \u03d5(x)}\nIt is well known that the central path is a continuous curve in space for any self-concordant barrier function \u03c6. We now have the following immediate corollary of Proposition 1:\nCorollary 2. The central path corresponding to the self-concordant barrier A\u2217 over any set K is equivalent to the heat path over the same set, i.e.\nHeatPath \u2261 CentralPath(A\u2217)\nThis mathematical equivalence is demonstrated in figure 2 generated by simulation over a polytope."}, {"heading": "4.3 IPM techniques for sampling and the new schedule", "text": "We now prove our main theorem, formally stated as: Theorem 4. The temperature schedule of \u03b81 = R where R = diam(K) and \u03b8k := (\n1\u2212 1 4 \u221a \u03bd\n) \u03b8k\u22121,\nfor \u03bd being the self-concordance parameter of the entropic barrier for the set K, satisfies condition (6) of theorem 1. Therefore algorithm 2 with this schedule returns an -approximate solution in time O\u0303( \u221a \u03bdn4).\nCondition (6) is formally proved in the following lemma, which crucially uses the interior point methodology, namely Lemma 3.\nLemma 5. Consider distributions P\u03b8 and P\u03b8\u2032 where \u03b8 \u2032 = (1 + \u03b3)\u03b8 for \u03b3 < 1\n6 \u221a \u03bd . Then we have the\nfollowing bound on the `2 distance between distributions:\nmax {\u2225\u2225\u2225\u2225 P\u03b8P(1+\u03b3)\u03b8 \u2225\u2225\u2225\u2225\n2\n, \u2225\u2225\u2225\u2225P(1+\u03b3)\u03b8P\u03b8 \u2225\u2225\u2225\u2225\n2\n} \u2264 10\nProof. We first show by elementary linear algebra that\n\u2016P\u03b8/P(1\u2212\u03b3)\u03b8\u2016 = \u2016P\u03b8/P(1+\u03b3)\u03b8\u2016 = exp(DA((1 + \u03b3)\u03b8, \u03b8) +DA((1\u2212 \u03b3)\u03b8, \u03b8)).\nLet us consider the log of the 2-norm:\nlog \u2016P\u03b8/P(1+\u03b3)\u03b8\u2016 = log \u222b K exp(\u2212\u03b8>x\u2212A(\u03b8)) exp(\u2212(1 + \u03b3)\u03b8>x\u2212A((1 + \u03b3)\u03b8)) dP\u03b8\n= log \u222b K exp(\u03b3\u03b8>x\u2212A(\u03b8) +A((1 + \u03b3)\u03b8))dP\u03b8\n= log \u222b K exp(\u03b3\u03b8>x\u2212A(\u03b8) +A((1 + \u03b3)\u03b8)) exp(\u2212\u03b8>x\u2212A(\u03b8))dx\n= A((1 + \u03b3)\u03b8)\u2212 2A(\u03b8) + log \u222b K exp(\u2212(1\u2212 \u03b3)\u03b8>x)dx = A((1 + \u03b3)\u03b8)\u2212 2A(\u03b8) +A((1\u2212 \u03b3)\u03b8) = DA((1 + \u03b3)\u03b8, \u03b8) +DA((1\u2212 \u03b3)\u03b8, \u03b8).\nReplacing \u03b3 by \u2212\u03b3, we get a completely symmetrical expression. Next, we observe that\n\u2016P\u03b8(1+\u03b3)/P\u03b8\u2016 = \u2016P\u03b8\u0303/P\u03b8\u0303(1\u2212\u03b3\u0303)\u2016\nwhere \u03b8\u0303 = \u03b8(1 + \u03b3) and 1\u2212 \u03b3\u0303 = 11+\u03b3 = 1\u2212 \u03b3 1+\u03b3 , thus \u03b3\u0303 \u2208 \u03b3 \u00d7 [1, 2]. By this observation, both sides of the lemma follow if we prove an upper bound\u2225\u2225\u2225\u2225 P\u03b8P(1+\u03b3)\u03b8 \u2225\u2225\u2225\u2225 2 \u2264 10 for \u03b3 < 1 6 \u221a \u03bd \u00d7 2 = 1 3 \u221a \u03bd\nLemma 1 implies \u03bb(x(\u03b8), 1 + \u03b3) \u2264 (1 + c)\u03bb(x(\u03b8), 1) + c = c \u2264 14 . Applying Lemma 4,\nDA((1 + \u03b3)\u03b8, \u03b8) \u2264 2\u2016x(\u03b8)\u2212 x((1 + \u03b3)\u03b8)\u20162x((1+\u03b3)\u03b8) Lemma 4 \u2264 2 (\n\u03bb(x(\u03b8),1+\u03b3) 1\u2212\u03bb(x(\u03b8),1+\u03b3)\n)2 (2.28) in [15]\n\u2264 2 (\nc 1\u2212c\n)2 < 2 (1/3) 2\n(2/3)2 = 12 Lemma 1\nNotice that to apply Lemma 4, we need the point x((1 + \u03b3)\u03b8) to lie in the Dikin ellipsoid of x(\u03b8), which is exactly whats proved in the last two lines of the above proof.\nThe bound on DA((1\u2212\u03b3)\u03b8, \u03b8) follows in precisely the same fashion, by similar change of variables as before (again, the condition for applying Lemma 4 is proven in the last few lines of the equations\nbelow):\nDA((1\u2212 \u03b3)\u03b8, \u03b8) = DA(\u03b8\u0303, \u03b8\u0303(1 + \u03b3\u0303)) \u2264 2\u2016x(\u03b8\u0303)\u2212 x((1 + \u03b3\u0303)\u03b8\u0303)\u20162\nx(\u03b8\u0303) Lemma 4 \u2264 2 ( \u03bb(x(\u03b8\u0303),1+\u03b3\u0303)\n1\u2212\u03bb(x(\u03b8\u0303),1+\u03b3\u0302)\n)2 (2.27) in [15]\n\u2264 2 (\nc 1\u2212c\n)2 < 2 (1/3) 2\n(2/3)2 = 12 Lemma 1\nIt follows that \u2016P\u03b8/P(1+\u03b3)\u03b8\u2016 \u2264 eDA((1+\u03b3)\u03b8,\u03b8)+DA((1\u2212\u03b3)\u03b8,\u03b8) \u2264 e 1 2 + 1 2 \u2264 10."}, {"heading": "4.4 Some history on the entropic barrier and the universal barrier for cones", "text": "Let K be a cone in Rn and let K\u2217 = {\u03b8 : \u03b8>x \u2265 0 \u2200x \u2208 K} be its dual cone. We note that a cone K is homogeneous if its automorphism group is transitive; that is, for every x, y \u2208 K there is an automorphism B : K \u2192 K such that Bx = y. Homogeneous cones are very rare, but one notable example is the PD cone (matrices with all positive eigenvalues). Given any point x \u2208 K, we can define a truncated region of K\u2217 as the set K\u2217(x) := {y \u2208 K\u2217 : x>y \u2264 1}. Nesterov and Nemirovskii [16] defined the first generic self-concordant barrier function, known as the universal barrier in terms of these regions. Namely, they show that the function\nuK(x) := log(vol(K \u2217(x)))\nis a self concordant barrier function with an O(n) parameter. There is an alternative characterization of the universal barrier in terms of the larg partition function. Let FK(x) := log \u222b K\u2217 exp(\u03b8 >x)d\u03b8 and equivalently let FK\u2217(\u03b8) := log \u222b K exp(\u03b8\n>x)dx. It was shown by Gu\u0308ler [5] that\nFK(x) = uK(x) + n!,\nthat is, the universal barrier corresponds exactly to a log-partition function but defined on the dual cone K\u2217, modulo a simple additive constant. We note that this is not the entropic barrier construction we have here, as our function of interest is A\u2217\u2212(\u00b7) \u2261 F \u2217K\u2217(\u00b7) (the Fenchel conjugate of FK\u2217(x)), and not FK(x). However, it was also shown by Gu\u0308ler [5] that, when K is a homogeneous cone, we have the identity FK(\u00b7) \u2261 F \u2217K\u2217(\u00b7); in other words, the universal barrier and the entropic barrier are equivalent for homogeneous cones.\nIt is worth noting that, following the connection of Gu\u0308ler [5], A\u2217\u2212(\u00b7) is (up to additive constant) the Fenchel conjugate of the universal barrier uK\u2217 forK\n\u2217. It was shown by Nesterov and Nemirovskii [16] (Theorem 2.4.1) that Fenchel conjugation preserves all required self concordance properties and in particular if g is a \u03bd-self-concordant barrier for a cone K, then g\u2217 will be a self-concordant barrier for K\u2217 with the same parameter \u03bd. With this observation it follows immediately that the entropic barrier F \u2217K\u2217(\u00b7) on K is an O(n)-self-concordant barrier. Bubeck and Eldan [2] took this statement further, proving that F \u2217K\u2217(\u00b7) enjoys an essentially optimal self-concordance parameter \u03bd = n(1 + o(1)).\nIt is important to note that the assumption that the set of interest is a cone is, roughly speaking, without loss of generality. Given any convex set U \u2282 Rn we have the fitted cone K(U) := {\u03b1(x, 1) : x \u2208 U,\u03b1 \u2265 0} \u2286 Rn+1. Hence once can always work with the barrier function F \u2217K(U)\u2217(\u00b7) on K(U),\nand take its restriction to the set U \u00d7 {1} \u2282 K(U) to obtain a barrier on U (affine restriction preserves the barrier properties).\nWe conclude by summarizing several results in Gu\u0308ler [5] regarding the entropic barrier for various cones, as well as the associated barrier parameter of each. In these canonical cases the entropic barrier corresponds exactly to the \u201ctypical\u201d barrier, up to additive and multiplicative constants. We use the notation f(\u00b7) \u223c= g(\u00b7) to denote that f and g are identical up to additive constants.\n1. Assume K := Rn+ the nonnegative orthant. This is a homogeneous cone and we have FK(x) \u223c= F \u2217K\u2217(x) \u223c= \u2212 \u2211n i=1 log xi. This is the optimal barrier for K and the barrier parameter is \u03bd = n.\n2. Assume K := {x \u2208 Rn : x21 + . . .+x2n\u22121 \u2264 x2n} be the Lorentz cone. K is a homogeneous self-dual cone. K can also be described by the fitted cone of the radius-1 L2 ball, so we may parameterize elements of K as \u03b1(x, 1) where \u03b1 \u2265 0 and x is vector in Rn\u22121 with L2 norm bounded by 1. Then FK(\u03b1(x, 1)) \u223c= F \u2217K\u2217(\u03b1(x, 1)) \u223c= \u2212 n+1 2 log(\u03b1\n2 \u2212 x2). This barrier has parameter \u03bd = n + 1 which is indeed not optimal, one has the optimal barrer \u2212 log(\u03b12 \u2212 x2) which has parameter \u03bd = 2, but this is simply a scaled version of the entropic barrier.\n3. The PSD cone K of positive semi-definite matrices, i.e. symmetric matrices with non-negative eigenvalues, is a homogeneous self-dual cone. The entropic barrier is FK(x) \u223c= F \u2217K\u2217(x) \u223c= \u2212n+12 log det(x) and exhibits a parameter of \u03bd = n(n+1) 2 which is multiplicatively n+1 2 worse\nthan the optimal barrier, the log-determined \u2212 log det(x). However, as can be seen this barrier is quite simply a scaled version of the entropic barrier."}, {"heading": "A An Explanation of Newton\u2019s Method via Reweighting", "text": "Proposition 1 brings out a strong connection between interior point techniques and the ability to sample from Boltzmann distributions. But with this stochastic viewpoint, it is not immediately clear why Newton\u2019s method is an appropriate iterative update scheme for optimization. We now provide some evidence along these lines.\nAssuming we have already computed (an approximation of) x(\u03b8), and our distribution parameter is updated to a \u201cnearby\u201d \u03b8\u2032, our goal is now to compute the new mean x(\u03b8\u2032).\n\u2212x(\u03b8\u2032) = \u222b K x dP\u03b8\u2032 = \u222b K x dP\u03b8\u2032(x) dP\u03b8(x) dP\u03b8 = E X\u223cP\u03b8 [ X exp(X>(\u03b8 \u2212 \u03b8\u2032) +A(\u03b8\u2032)\u2212A(\u03b8)) ] Think of the last term as the reweighting factor. Now we are going to rewrite A(\u03b8) \u2212 A(\u03b8\u2032) = \u2212\u2207A(\u03b8)(\u03b8\u2032\u2212\u03b8)\u2212DA(\u03b8\u2032, \u03b8) = x(\u03b8)>(\u03b8\u2032\u2212\u03b8)\u2212KL(P\u03b8, P\u03b8\u2032). We shall use the following approximation of the exponential: exp(z) \u2248 1 + z for small values of z. Proceeding,\n\u2212x(\u03b8\u2032) = E X\u223cP\u03b8\n[ X exp(X>(\u03b8 \u2212 \u03b8\u2032)\u2212 x(\u03b8)>(\u03b8\u2032 \u2212 \u03b8) + KL(P\u03b8, P\u03b8\u2032)) ] = eKL(P\u03b8,P\u03b8\u2032 ) E\nX\u223cP\u03b8\n[ X exp((X \u2212 x(\u03b8))>(\u03b8\u2032 \u2212 \u03b8)) ] \u2248 eKL(P\u03b8,P\u03b8\u2032 ) E\nX\u223cP\u03b8\n[ X(1 + (X \u2212 x(\u03b8))>(\u03b8\u2032 \u2212 \u03b8)) ] = eKL(P\u03b8,P\u03b8\u2032 )(\u2212x(\u03b8) + \u03a3\u03b8(\u03b8\u2032 \u2212 \u03b8)).\nDuality theory tells us that \u03a3\u03b8 = \u22072A(\u03b8) = \u2207\u22122A\u2217(x(\u03b8)) and \u03b8\u2032\u2212 \u03b8 is precisely the gradient of the objective \u03b8\u2032>x\u2212A\u2217(x) at the point x(\u03b8). The eKL(P\u03b8,P\u03b8\u2032 ) term is somewhat mysterious, but it can be interpreted as something of a \u201cdamping\u201d factor akin to the Newton decrement damping of the the Newton update."}, {"heading": "B Proof structure of the Kalai-Vempala theorem", "text": "We hereby sketch the structure of the proof of theorem 1 for completeness. Recall the statement of the theorem:\nAlgorithm 2 with a temperature schedule that satisfies the following condition:\nThe successive distributions are not \u201ctoo far\u201d in total variational distance. That is, for every j,\nmax {\u2225\u2225\u2225\u2225 P\u03b8jP\u03b8j\u22121 \u2225\u2225\u2225\u2225\n2\n, \u2225\u2225\u2225\u2225P\u03b8j\u22121P\u03b8j \u2225\u2225\u2225\u2225\n2\n} \u2264 10\nGuarantees that HitAndRun requires N = O\u0303(n3) steps in order to ensure mixing to the stationary distribution P\u03b8j .\nProof sketch. The proof is based on iteratively applying the following Theorem from [12]:\nTheorem 5. Let f be a density proportional to e\u2212a T x over a convex set K such that\n[a]. the level set of probability 1/64 contains a ball of radius s\n[b]. Ef (\u2016x\u2212 \u00b5f\u20162) \u2264 S, where \u00b5f = Ef [x] is the mean of f\n[c]. the `2 norm of the starting distribution \u03c3 w.r.t. the stationary distribution of HitAndRun denoted \u03c0f , is at most M.\nLet \u03c3m be the distribution of the current point after m steps of HitAndRun applied to f. Then, for any \u03c4 > 0, after m = O(n 2S2\ns2 log5 nM\u03c4 ) steps, the total variation distance of \u03c3 m and \u03c0f is less than \u03c4 .\nThe proof proceeds to show that conditions [a]-[c] of the theorem above are all satisfied if indeed condition (6) is satisfied, along the steps below. Once it is established that the conditions of the theorem hold, then the next HitAndRun walk mixes and computes warm start and variance estimates for the next epoch. Then again, the conditions of the theorem hold, and this whole process is repeated for the entire temperature schedule.\nTo show conditions [a]-[c], first notice that condition (6) is essentially equivalent to condition [c] above. Thus we only need to worry about conditions [a],[b].\n[I]. For simplicity, we assumed that at the current iteration, \u03a3j = I is the identity. This can be assumed by a transformation of the space, and allows for simpler discussion of isotropy of densities (otherwise, the isotropy condition would be replaced by relative-isotropy w.r.t the current variance).\n[II]. A density f is C-isotropic if for any unit vector \u2016v\u2016 = 1,\n1 C \u2264 \u222b Rn (v>(x\u2212 \u00b5f ))2f(x)dx \u2264 C\nIt is shown (Lemma 4.2) that if the density given by f is O(1)-isotropic, then conditions [a],[b] are satisfied with Ss = O\u0303( \u221a n).\n[III]. It is shown (Lemma 4.3) that if f is C-isotropic, and max {\u2225\u2225\u2225fg\u2225\u2225\u22252 , \u2225\u2225\u2225 gf \u2225\u2225\u22252} \u2264 D, then g is\nCD-isotropic.\n[IV]. Since condition (6) holds, together with the previous points [II,III] this implies that f\u03b8j+1 is isotropic for some constant. Thus, conditions [a]-[c] of Theorem 5 hold. Therefore we can sample sufficiently many samples to estimate the covariance matrix \u03a3j+1 and proceed to the next epoch.\nThroughout the proof special care needs to be taken to ensure that repeated samples are nearlyindependent for various concentration lemmas to apply, we omit discussion of these and the reader is referred to the original paper of [7].\nC Interior point methods with a membership oracle\nBelow we sketch a universal IPM algorithm - one that applies to any convex set described by a membership oracle - that can be implemented to run in polynomial time. This algorithm is an instantiation of Algorithm 3 with the particular barrier function A\u2217(x) as defined in section 4.1.\nWithout loss of generality, we can assume our goal is to (approximately) compute the update direction\n\u2207\u22122A\u2217(x)(\u03b8 \u2212\u2207A\u2217(x))\nfor some x which is already within the Dikin ellipsoid of radius 1/2 around x(\u03b8). First, we note that the IPM analysis of [15] allows one to replace the inverse hessian \u2207\u22122A\u2217(x) with the nearby \u2207\u22122A\u2217(x(\u03b8)) = CovMtx(P\u03b8). Of course the latter can be estimated via sampling, in the sense that the estimate \u03a3\u0302 will be \u201c -isotropically close\u201d:\n(1\u2212 )v>\u22072\u03a8(\u03b8\u2032)v \u2264 v>\u03a3\u0302v \u2264 (1 + )v>\u22072\u03a8(\u03b8\u2032)v\nfor any unit vector v. See, for example, [1] on the concentration of empirical covariance matrices. It remains to compute \u2207A\u2217(x). Define \u03b8(x) to be\n\u03b8(x) = arg max \u03b8 \u03b8 \u00b7 x\u2212 log \u222b K exp(\u2212\u03b8 \u00b7 y)dy = \u2207A\u2217(x) (21)\nThen \u03b8(x) can be computed in polynomial time by another interior point algorithm \u2013 this problem, however, is much simpler to work with. Define \u03a8(\u03b8\u2032) := \u03b8\u00b7x\u2212log \u222b K exp(\u2212\u03b8\u00b7y)dy to be the objective we want to optimize. Notice that \u2207\u03a8(\u03b8\u2032) = x \u2212 EX\u2032\u223cP\u03b8\u2032 [X \u2032] and the latter can be estimated to within via SimulatedAnnealing with O\u0303(n/ 2) samples. The hessian \u22072\u03a8(\u03b8\u2032) = \u2212CovMtx(P\u03b8\u2032) can similarly be estimated with an -isotropically close empirical covariance. Because the error gap is multiplicatively close to 1, the inverse operation on \u22072\u03a8(\u03b8\u2032) maintains the approximation."}], "references": [], "referenceMentions": [], "year": 2015, "abstractText": "<lb>This paper explores a surprising equivalence between two seemingly-distinct convex opti-<lb>mization methods. We show that simulated annealing, a well-studied random walk algorithms,<lb>is directly equivalent, in a certain sense, to the central path interior point algorithm for the the<lb>entropic universal barrier function. This connection exhibits several benefits. First, we are able<lb>improve the state of the art time complexity for convex optimization under the membership<lb>oracle model. We improve the analysis of the randomized algorithm of Kalai and Vempala [7]<lb>by utilizing tools developed by Nesterov and Nemirovskii [16] that underly the central path fol-<lb>lowing interior point algorithm. We are able to tighten the temperature schedule for simulated<lb>annealing which gives an improved running time, reducing by square root of the dimension<lb>in certain instances. Second, we get an efficient randomized interior point method with an<lb>efficiently computable universal barrier for any convex set described by a membership oracle.<lb>Previously, efficiently computable barriers were known only for particular convex sets. 1<lb>ar<lb>X<lb>iv<lb>:1<lb>50<lb>7.<lb>02<lb>52<lb>8v<lb>2<lb>[<lb>m<lb>at<lb>h.<lb>O<lb>C<lb>]<lb>5<lb>N<lb>ov<lb>2<lb>01<lb>5", "creator": "LaTeX with hyperref package"}}}