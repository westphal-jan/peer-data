{"id": "1508.04123", "review": {"conference": "arxiv", "VERSION": "v1", "DATE_OF_SUBMISSION": "17-Aug-2015", "title": "Evaluating Classifiers in Detecting 419 Scams in Bilingual Cybercriminal Communities", "abstract": "crime accompanying massive rebellion are possible because mobile criminals collectively securing full financial benefits from incurring low costs to commit crime. as broad digital landscape broadens to accommodate more internet - enabled devices and technologies like wi media, more cybercriminals who and not aware physically likely began invading cyberspace to fetch debts on broadband exploits. in this paper we evaluate legitimate actions by three machine driver classes in its 419 scams in those huge nigerian gaming community. we use quite popular breeds in multimedia processing namely : na \\ \" lazy bayes, memory - nearest \" ( gs ) and sample level machines ( svm ). the internet term describing a real time dataset like every svm virtually outperforms na \\ \" ive bayes and 32 - 9 % threshold level.", "histories": [["v1", "Mon, 17 Aug 2015 19:38:50 GMT  (141kb)", "http://arxiv.org/abs/1508.04123v1", "7 pages"]], "COMMENTS": "7 pages", "reviews": [], "SUBJECTS": "cs.SI cs.CY cs.LG", "authors": ["alex v mbaziira", "ehab abozinadah", "james h jones jr"], "accepted": false, "id": "1508.04123"}, "pdf": {"name": "1508.04123.pdf", "metadata": {"source": "CRF", "title": "Evaluating Classifiers in Detecting 419 Scams in Bilingual Cybercriminal Communities", "authors": ["Alex V Mbaziira", "Ehab Abozinadah", "James H Jones"], "emails": ["ambaziir@masonlive.gmu.edu", "eabozina@masonlive.gmu.edu", "jjonesu@gmu.edu"], "sections": [{"heading": null, "text": "Keywords-Machine Learning; Bilingual Cybercriminals; 419 Scams;\nI. INTRODUCTION (HEADING 1) Cybercrime has evolved from misuse and, or abuse of computer systems to sophisticated organized crime exploiting the internet. The causes of increasing incidents of cybercrime are attributed to: widespread internet access, increasing volume of internet-enabled devices and integration of social networking in computing architectures. These global internetdriven computing architectures continue to expand and build on top of existing immeasurable vulnerabilities, which provide miscreants with low barriers to commit and profit from cybercrime.\nThere are numerous types of cybercrime. Some research categorizes cybercrime into content-based and technologybased crime [1]. Other studies provide elaborate classification of cybercrime to include offences against confidentiality, availability and integrity of information and information technology [2]. In each category is a list of crimes that offer cybercriminals incentives and tools with capabilities to exploit computer system vulnerabilities for high financial rewards. Criminals also use the internet to obtain sophisticated tools for exploiting their victims without being detected or apprehended. Cyberspace provides criminals with capabilities for using dissociative anonymity to assume fake identifies for committing crime [3]. However, with social media, the true identities of cybercriminals can be leaked when the actor's friends in the criminal social network do not implement the same levels of privacy to hide their identities.\nThis study extends work in a previous paper [4] by implementing machine learning algorithms to detect 419 scams within an actual bilingual cybercriminal community. The main contribution of this paper is evaluation of the performance of machine learning algorithms in detecting 419 scams an actual bilingual cybercriminal community in a social network . We use in English as well as English and Nigerian Pidgin to evaluate the classifiers using the unigram and bigram models. We use three classifiers to detect 419 scammers within this cybercriminal community namely: Na\u00efve Bayes, Support Vector Machines and k-Nearest Neighbor. Support Vector Machines significantly out-performed the other classifiers on datasets comprising of both English and Nigerian Pidgin unigram and bigram models at 95% confidence level. This because Nigerian Pidgin vocabulary has fewer words compared to English hence Support Vector Machines tend to work well such datasets.\nThe rest of the paper is organized as follows: in Section 2 we discuss related work. In Section 3 we describe the dataset and criteria for evaluating the performance of these classifiers. In Section 4 we present the results and discussion of our experimental study and in section 5 we draw our conclusions.\nII. RELATED WORK There is a growing body of research investigating the\ncontext and impact of cybercrime due to the increasing number of incidents and numerous vectors that criminals are exploiting to profit from crime [5], [6], [7], [8]. There are numerous types of cybercrime which are categorized as content-based and technology-based crime. Content-based cybercrime includes: scams, phishing, fraud, child pornography, spamming etc., while technology-based crime includes but is not limited to hacking, code injection, espionage [1]. In this section we review existing research on content-based crime in general but scams in particular. We also define scams and bilingual cybercriminal networks in context to this paper."}, {"heading": "A. Nigerian Bilingual Cybercriminals and 419 Scams", "text": "This paper investigates detection of 419 scams within a\nbilingual community of cybercriminals. The actors comprising the community of cybercriminals that we are studying was constructed into a graph in an earlier paper using publicly\nleaked emails obtained from an online data theft service [4]. These scams are known as advance-fee fraud or 419 scams [9], [10]. 419 scams originated from Nigerian in the 1970s at smaller scale but escalated in the 1980s during the oil boom as posted letters and then transitioned to email in the 1990's with commercialization of the Internet [11]. With time the origin of 419 scam cells expanded to different West African countries like Ghana, Cameroon, Ivory Coast, Benin as well other parts of the world. Although these scams usually go unreported, a 2013 report revealed that victims lost $12.7 billion during that year to this category of cyber-criminals [11].\nCybercriminals committing 419 scams speak at least two languages hence are bilingual. For purposes of this paper we use the term bilingual cybercriminal community to refer an online community of criminal actors that use English and Nigerian Pidgin to exploit victims using 419 scams. This because Nigeria as well as other West African countries with 419 scammers are very diverse countries with hundreds of local dialects. However, English and Nigerian Pidgin are the most popular and widely common spoken languages spoken in West Africa.\nNigerian Pidgin is an English-based pidgin comprising words from local Nigerian dialects and English. In Nigerian pidgin, the phrases are short compared to English while the English used in Nigerian pidgin does not follow proper grammar hence is broken English like any pidgin or Creole language."}, {"heading": "B. Content-based Cybercrime Detection", "text": "Various research has studied detection of different types of content-based cybercrime like fraud, phishing and spam [12], [13]. Wang et al., study spam in social networks to build a social spam detection framework that filters spam across multiple social networks namely: MySpace, Twitter and WebbSpam Corpus [14]. Bosma et al., develop a social spam detection framework that uses link analysis and this implemented on a popular social network [15]. Bhat et al., propose a community-based framework and apply ensemble classifiers to detect spammers within community nodes in online social networks [16], [17]. Other studies evaluate predictive accuracy of several machine learning algorithms like Support Vector Machines, Random Forests, Na\u00efve Bayes, Neural Networks in predicting phishing emails [18], [19]. Other research investigates the extent at which malware and spam has infiltrated online social networks [20]. However, these studies have not tackled bilingual datasets with 419 scams which are obtained from an actual cybercriminal community and evaluated performance of machine learning algorithms in detecting such scams within online cybercriminal communities. 419 scams comprise work-at-home scams, high yield investment scams, lottery scams or rewards from pay-perclick online adds."}, {"heading": "C. Machine Learning", "text": "In this section we review supervised machine learning algorithms for our study. In supervised machine learning, the algorithms map inputs to specific outputs using input and output data [21]. We use three classifiers namely Na\u00efve Bayes,\nSupport Vector Machines and Decision Trees to detect scam in a social network of multi-lingual Nigerian cyber-criminals because these classifiers have been well studied and applied to spam and malware classification problems.\na) Na\u00efve Bayes: this a popular classifier which has been applied to a variety of learning problems that are investigating scams like phishing, spamming and injected malicious hyperlinks. The algorithm implements Bayes Theorem which assumes conditional independence in feature variables of a learning set to predict statistical outcomes [22], [23].\nb) Support Vector Machines: this another popular algorithm and that uses hyperplanes in dimensional space to address classification problems. This algorithm has been used in studying spam, fraud, malware , and phishing [24] [25].\nk-Nearest Neighbors (kNN): this is also popular algorithm that uses instance-based learning to predict outcomes in learning problems. With instance-based learning, the kNN algorithm looks at the k-nearest neighbors when determining which instance to predict [26].\nIII. DATASET We use a publicly leaked set of 1036 email addresses of Nigerian cybercriminals who are using an online data theft service called PrivateRecovery (which was formerly called BestRecovery) [27]. These cybercriminals are known for committing specific scams namely: advance-fee, online dating and Nigerian letter scams. Facebook lookups were conducted on each email address to identify corresponding public profiles of the criminal actors and their friends. The Facebook URLs of these actors was used in a previous paper to construct large graph of 43,125 criminal nodes [4]. These Facebook accounts of these criminal actors are real because the actors post and share a lot of personal information in form of text and photographs. The average number of friends for the 150 important criminal actors is 490 while the 4966 is the maximum number of friends these actors have. For this study, we used public data from 150 criminal nodes which had a high PageRank. During data collection, we did not engage with or friend the actors through their Facebook accounts."}, {"heading": "A. Dataset Description", "text": "For our experimental study, we first generate two primary datasets from records which are randomly selected from the 150 Facebook accounts with high PageRank scores. Primary Dataset 1 (PD1) has English only records while Primary Dataset 2 (PD2) has half of the records in English and the other half in Nigerian Pidgin as shown in Table 1. The data in each primary dataset is labeled and then preprocessed to remove all non ASCII characters, symbols and punctuation marks except for the apostrophes, which we escaped. The data used in our classification problem is in two languages namely English and Nigerian Pidgin both of which use Latin characters hence do not use special symbols or non ASCII characters which is typical in languages like French, Spanish etc that use such characters to emphasize accents for certain words. However, in the data there was some evidence of use non ASCII characters in form on text-based emoticons expressing emotion. We do\nnot stem the English words in the sub-datasets but use term frequency-inverse document frequency (tf-idf) to weight the words.\nFrom each of the primary datasets we obtained two subdatasets of unigram words and bigram words as shown in Table I. Sub-datasets (SD) A and B contains English unigram and bigram words respectively while Sub-datasets (SD) C and D has both unigram and bigram words respectively in both English and Nigerian Pidgin."}, {"heading": "B. Classifier Evaluation Metrics", "text": "Our study uses binary classification to train and test text instances in the datasets as either scam or not-scam. To evaluate our classifiers we use Recall, Precision and F1 measure on unigram and bigram word vectors. Recall measures the percentage of scam messages that are detected hence this metric determines how well a classifier performs in identifying a condition. Precision, however, measures how many of the scam messages are detected correctly hence this is a measure of probability that a predicted outcome is the right one [28]. F1 measure is a harmonic mean of precision and recall.\nLet xns\u2192ns be the number of not-scam posts classified as not-scam, xns\u2192s be the number of not-scam posts misclassified as scam, xs\u2192ns be the number of scam posts misclassified as not-scam and xs\u2192s be the scam posts classified as scam. Therefore the equations for recall, precision and F1 will be:\nRecall = (1)\nPrecision = (2)\nF1 Measure = (3)"}, {"heading": "C. Experimental Setup", "text": "In this section we demonstrate how we obtain results on performance of the three classifiers in WEKA[29] using the four sub-datasets. To solve our classification problem we use three classifiers namely: Na\u00efve Bayes (NB)[30], Support Vector Machines (LibSVM), and k-Nearest Neighbor (IBK) [26]. To obtain the results, each of the random sample subdatasets is split into training and testing tests. 80% of the data in each sub-dataset is randomly allocated for training and 20% for testing. We also used 10-fold cross validation method to improve the performance of the classifiers. Using cross validation, each of the four sub-datasets were split up into 10 sets of equal proportion. Training was done on nine sets while testing is done of one. This process was repeated 10 times to ensure independence of the elements in the sample and also to minimize biases in the outcomes."}, {"heading": "NB 0.915 0.911 0.911 0.964 0.96", "text": ""}, {"heading": "A. Results of Evaluation Metrics", "text": "In this section we first present the experimental results for performance of the classifiers on unigram and bigram words for the four sub-datasets. The evaluate the classifiers we use precision, recall, F-measure, ROC Curve and PR-Curve on datasets .\nTable II shows the results for performance of the three classifiers using sub-dataset A of English unigrams. The results in this table reveal has precision of 0.915, recall of 0.911, fmeasure of 0.911, ROC Area of 0.964 and PRC of 0.96. LibSVM has a precision of 0.866, recall of 0.885, f-measure of 0.885, ROC Area of 0.947 and PR-curve of 0.945. IBK has a precision of 0.833, recall of 0.78, f-measure of 0.771, ROCcurve of 0.822 and PR-curve of 0.811.\nTable III presents results of the 3 classifiers using subdataset B of English bigram words. Detailed results in this table indicate that Na\u00efve Bayes has a precision of 0.72. recall of 0.565, f-measure of 0.473, ROC Area of 0.895 and PR curve of\n0.883. Comparatively, LibSVM has precision of 0.673, recall of 0.656, f-measure of 0.648, ROC Area of 0.742 and PRCurve of 0.734. IBK has precision of 0.695, recall of 0.515, fmeasure of 0.371, ROC of 0.644 and PR-curve of 0.659.\nTable IV shows results for the classifier performance on sub-dataset C which contains unigram words in both English and Nigerian Pidgin. The results indicate that Na\u00efve Bayes has a precision of 0.964, recall of 0.964, f-measure of 0.964, ROC area of 0.994 and PR-curve of 0.994. LibSVM has a precision of 0.962, recall of 0.962, f-measure of 0.962, ROC area of 0.963 and PR-curve of 0.994. IBK has a precision of 0.851, recall of 0.79, f-measure of 0.781, ROC area of 0.915 and PRcurve of 0.921.\nTable V indicates results for performance of the three classifiers on sub-dataset D which contains bigrams words in both English and Nigerian Pidgin. The results in this table indicate that LibSVM has a precision of 0.898, recall of 0.895, f-measure of 0.895, ROC Area of 0.94 and PR curve of 0.928. Na\u00efve Bayes has a precision of 0.887, recall of 0.861, fmeasure of 0.859, ROC area of 0.981 and PR-curve of 0.981. Finally, IBK has precision of 0.844, recall of 0.796, f-measure of 0.789, ROC area of 0.901 and PR-curve of 0.909."}, {"heading": "B. Classifier Performance Evaluation", "text": "In this section we evaluate performance of the classifiers\nto determine the best classifier for detecting scam within this community of bilingual cybercriminals using unigram and bigram models. We evaluate LibSVM against Na\u00efve Bayes and IBK to establish the significance of results at 95% confidence level using the four datasets. To achieve this we use a 2-tailed T-test evaluate performance metrics of LibSVM against Na\u00efve Bayes and IBK on the four sub-datasets. To perform this test, we run the experiment five times and for each run we perform 10-fold cross validation. During each run the instances are randomized and the dataset is split into 80% training test and 20% testing set.\nThe performance metrics that we use to evaluate\nperformance of our classifiers on the sub-datasets are ROC area, PR-curve and f-measure. We develop several hypotheses to test significance of the outcomes of the classifiers predicting accuracy in detecting 419 scams on datasets with English only as well as English and Nigerian Pidgin using unigram and bigram models. We use H0 to represent the null hypothesis and H1 to represent the alternate hypothesis. We compare the performance of LibSVM with Na\u00efve Bayes and IBK on the four sub-datasets.\nWe evaluate classifier performance using ROC area as below:\n\u2022 H0: LibSVM's ROC area is greater than IBK's ROC Area for English unigrams while for H1 : LibSVM's ROC area is not greater that IBK's ROC Area for English unigrams. We reject the null hypothesis H0 because LibSVM's ROC area is significantly worse at 0.8 with a standard deviation of 0.02 as shown in Table VI.\n\u2022 H0: LibSVM's ROC area is greater than Na\u00efve Bayes' ROC Area for both English and Nigerian Pidgin unigrams while for H1 : LibSVM's ROC area is not greater that Na\u00efve Bayes ROC Area for English and Nigerian Pidgin unigrams. We accept the null hypothesis H0 because LibSVM's ROC area is significantly better at 1.00 as shown in Table VI.\n\u2022 H0: LibSVM's ROC area is greater than IBK's ROC Area for English and Nigerian Pidgin unigrams while for H1 : LibSVM's ROC area is not greater that IBK's ROC Area for English and Nigerian Pidgin unigrams. We reject the null hypothesis H0 because LibSVM's ROC area for both English and Nigerian unigrams is significantly worse at 0.92 and standard deviation of 0.02 as shown in Table VI.\n\u2022 H0: LibSVM's ROC area is greater than Na\u00efve Bayes' ROC area for English and Nigerian Pidgin bigrams while for H1 : LibSVM's ROC area is not greater that Na\u00efve Bayes' ROC area for English and Nigerian Pidgin bigrams. We accept the null hypothesis H0 because LibSVM's ROC area for both English and Nigerian bigrams is significantly better at 0.99 as shown in Table VI.\nH0: LibSVM's ROC area is greater than IBK's ROC area for English and Nigerian Pidgin bigrams while for H1 : LibSVM's ROC area is not greater that IBK's ROC area for English and Nigerian Pidgin bigrams. We accept the null hypothesis H0 because LibSVM's ROC area for both English and Nigerian bigrams is significantly better at 0.94 and standard deviation of 0.02 as shown in Table VI.\nHere we continue the evaluation for classifier performance using PR area as shown below:\n\u2022 H0: LibSVM's PR area is greater than IBK's PR area for English unigrams while for H1 : LibSVM's PR area is not greater than IBK's PR area for English unigrams. We reject the null hypothesis H0 because LibSVM's PR area for English unigrams is significantly worse at 0.79 and standard deviation of 0.02 as shown in Table VII.\n\u2022 H0: LibSVM's PR area is greater than Na\u00efve Bayes's PR area for English bigrams while for H1: LibSVM's PR area is not greater than Na\u00efve Bayes' PR area for English bigrams. We reject the null hypothesis H0 because LibSVM's PR area for\nEnglish bigrams is significantly worse at 0.86 and standard deviation of 0.02 as shown in Table VII.\n\u2022 H0: LibSVM's PR area is greater than Na\u00efve Bayes's PR area for English and Nigerian Pidgin unigrams while for H1 : LibSVM's PR area is not greater than Na\u00efve Bayes' PR area for English and Nigerian Pidgin unigrams. We accept the null hypothesis H0 because LibSVM's PR area for English and Nigerian Pidgin unigrams is significantly better at 1.00 as shown in Table VII.\n\u2022 H0: LibSVM's PR area is greater than IBK's for English and Nigerian Pidgin unigrams while for H1 : LibSVM's PR area is not greater than IBK's PR area for English and Nigerian Pidgin's unigrams. We reject the null hypothesis H0 because LibSVM's PR area for English and Nigerian Pidgin unigrams is significantly worse at 0.93 and standard deviation of 0.01 as shown in Table VII.\n\u2022 H0: LibSVM's PR area is greater than Na\u00efve Bayes's PR area for English and Nigerian Pidgin bigrams while for H1 : LibSVM's PR area is not greater than Na\u00efve Bayes' PR area for English and Nigerian Pidgin bigrams. We accept the null hypothesis H0 because LibSVM's PR area for English and Nigerian Pidgin bigrams is significantly better at 0.99 as shown in Table VII.\n\u2022 H0: LibSVM's PR area is greater than IBK's PR area for English and Nigerian Pidgin bigrams while for H1 : LibSVM's PR area is not greater than IBK's PR area for English and Nigerian Pidgin bigrams. We accept the null hypothesis H0 because LibSVM's PR area for English and Nigerian Pidgin bigrams is significantly better at 0.94 and standard deviation of 0.02 as shown in Table VII.\nWe conclude the evaluation for classifier performance with\nf-measure as below: \u2022 H0: LibSVM's f-measure is greater than IBK's f-\nmeasure for English unigrams while for H1 : LibSVM's f-measure is not greater than IBK's fmeasure for English unigrams. We reject the null hypothesis H0 because LibSVM's f-measure for English unigrams is significantly worse at 0.76 and standard deviation of 0.01 as shown in Table VIII.\n\u2022 H0: LibSVM's f-measure is greater than Na\u00efve Bayes' f-measure for English bigrams while for H1 : LibSVM's f-measure is not greater than Na\u00efve Bayes' f-measure for English bigrams. We reject the null hypothesis H0 because LibSVM's fmeasure for English bigrams is significantly worse at 0.48 and standard deviation of 0.04 as shown in Table VIII.\n\u2022 H0: LibSVM's f-measure is greater than IBK's fmeasure for English bigrams while for H1 : LibSVM's f-measure is not greater than IBK's fmeasure for English bigrams. We reject the null hypothesis H0 because LibSVM's f-measure for English bigrams is significantly worse at 0.37 and standard deviation of 0.02 as shown in Table VIII.\n\u2022 H0: LibSVM's f-measure is greater than Na\u00efve Bayes' f-measure for English and Nigerian Pidgin unigrams while for H1 : LibSVM's f-measure is not greater than Na\u00efve Bayes' f-measure for English and Nigerian Pidgin unigrams. We accept the null hypothesis H0 because LibSVM's fmeasure for English and Nigerian Pidgin unigrams is significantly better at 0.97 and standard deviation of 0.01 as shown in Table VIII.\n\u2022 H0: LibSVM's f-measure is greater than IBK's fmeasure for English and Nigerian Pidgin unigrams while for H1 : LibSVM's f-measure is not greater than IBK's f-measure for English and Nigerian Pidgin unigrams. We reject the null hypothesis H0 because LibSVM's f-measure for English and Nigerian Pidgin unigrams is significantly worse at 0.79 and standard deviation of 0.03 as shown in Table VIII.\n\u2022 H0: LibSVM's f-measure is greater than Na\u00efve Bayes f-measure for English and Nigerian Pidgin bigrams while for H1 : LibSVM's f-measure is not greater than Na\u00efve Bayes' f-measure for English and Nigerian Pidgin bigrams. We accept the null hypothesis H0 because LibSVM's f-measure for English and Nigerian Pidgin bigrams is significantly better at 0.85 and standard deviation of 0.03 as shown in Table VIII.\nAs shown in Tables VI, VII and VII, 8 of the null hypotheses are accepted while 9 hypotheses are rejected and 6 hypotheses are not rejected. All the 8 null hypotheses which\nare accepted reveal that LibSVM significantly outperformed other classifiers on a unigram and bigram models that comprise both English and Nigerian Pidgin words. The rejected hypotheses reveal that IBK performed significantly worse compared to LibSVM mainly on the English only unigram and bigram models as well as on the unigram model comprising Nigerian Pidgin and English words. The 6 hypotheses that are not rejected were based on unigram and bigram model for English only words.\nThe LibSVM out-performed other classifiers on English and Nigerian Pidgin unigram and bigram model because these sub-datasets had fewer words in their vocabulary compared to the English words. This is because Nigerian Pidgin uses a limited vocabulary of words which are selected from both English and other local Nigerian dialects\nV. CONCLUSION This study evaluated performance of three classifiers in detecting 419 scams within a bilingual cybercriminal community. The three classifiers we used are LibSVM, Na\u00efve Bayes and IBK. We evaluated the performance of the three classifiers using both unigram and bigram models comprising and of English words as well as both English and Nigerian Pidin words. In both models, LibSVM outperformed Na\u00efve Bayes and IBK. We used a 2-tailed t-test at 95% confidence to evaluate the classifiers on both the unigram and bigram models of English words as well as both English and Nigerian Pidgin words. These results motivate future work to explore the use of ensemble learning in detecting scams in bilingual criminal communities."}, {"heading": "ACKNOWLEDGMENT", "text": "We would like to thank Prof Damon McCoy for his initial input and allowing us to use the publicly leaked emails from which we collected data used in the earlier paper. We also want to thank all the anonymous reviewers whose comments were used to improve this paper."}], "references": [{"title": "A framework to detect cybercrime in the virtual environment", "author": ["M. Thangiah", "S. Basri", "S. Sulaiman"], "venue": "2012 International Conference on Computer Information Science (ICCIS), 2012, vol. 1, pp. 553\u2013557.", "citeRegEx": "1", "shortCiteRegEx": null, "year": 2012}, {"title": "Understanding Cybercrime:A Guide For Developing Countries", "author": ["ITU"], "venue": "International Telecommunications Union, Switzerland, Apr. 2009.", "citeRegEx": "2", "shortCiteRegEx": null, "year": 2009}, {"title": "Constructing and Analyzing Criminal Networks", "author": ["H. Sarvari", "E. Abozinadah", "A. Mbaziira", "D. McCoy"], "venue": "IEEE Secur. Priv. Workshop, p. 8, 2014.", "citeRegEx": "4", "shortCiteRegEx": null, "year": 2014}, {"title": "Analysis of online messages for identity tracing in cybercrime investigation", "author": ["S.M. Nirkhi", "R.V. Dharaskar", "V.M. Thakre"], "venue": "2012 International Conference on Cyber Security, Cyber Warfare and Digital Forensic (CyberSec), 2012, pp. 300\u2013305.", "citeRegEx": "5", "shortCiteRegEx": null, "year": 2012}, {"title": "How do consumers react to cybercrime", "author": ["R. Bohme", "T. Moore"], "venue": "eCrime Researchers Summit (eCrime), 2012, 2012, pp. 1\u201312.", "citeRegEx": "6", "shortCiteRegEx": null, "year": 2012}, {"title": "State and trends of Russian cybercrime in 2011", "author": ["A.K. Kuzmin"], "venue": "2012 4th International Congress on Ultra Modern Telecommunications and Control Systems and Workshops (ICUMT), 2012, pp. 933\u2013939.", "citeRegEx": "7", "shortCiteRegEx": null, "year": 2012}, {"title": "Honor among thieves: A common\u2019s analysis of cybercrime economies", "author": ["S. Afroz", "V. Garg", "D. Mccoy", "R. Greenstadt"], "venue": "eCrime Researchers Summit (eCRS), 2013, 2013, pp. 1\u201311.", "citeRegEx": "8", "shortCiteRegEx": null, "year": 2013}, {"title": "Understanding cybercrime perpetrators and the strategies they employ in Nigeria", "author": ["J.O. Aransiola", "S.O. Asindemade"], "venue": "Cyberpsychology Behav. Soc. Netw., vol. 14, no. 12, pp. 759\u2013763, Dec. 2011.", "citeRegEx": "9", "shortCiteRegEx": null, "year": 2011}, {"title": "Who Made That Nigerian Scam", "author": ["D. Engber"], "venue": "The New York Times, 03-Jan-2014.", "citeRegEx": "10", "shortCiteRegEx": null, "year": 2014}, {"title": "419 Advance Fee Fraud Statistics Released in July 2014", "author": ["419 Unit of Ultrascan Advanced Global Investigations"], "venue": "Ultrascan Advanced Global Investigations, Amsterdam, Jul. 2014.", "citeRegEx": "11", "shortCiteRegEx": null, "year": 2014}, {"title": "Outside the Closed World: On Using Machine Learning for Network Intrusion Detection", "author": ["R. Sommer", "V. Paxson"], "venue": "2010 IEEE Symposium on Security and Privacy (SP), 2010, pp. 305\u2013316.", "citeRegEx": "12", "shortCiteRegEx": null, "year": 2010}, {"title": "Toward Scalable Learning with Nonuniform Class and Cost Distributions: A Case Study in Credit Card Fraud Detection", "author": ["P.K. Chan", "S.J. Stolfo"], "venue": "In Proceedings of the Fourth International Conference on Knowledge Discovery and Data Mining, 1998, pp. 164\u2013168.", "citeRegEx": "13", "shortCiteRegEx": null, "year": 1998}, {"title": "A Social-spam Detection Framework", "author": ["D. Wang", "D. Irani", "C. Pu"], "venue": "Proceedings of the 8th Annual Collaboration, Electronic Messaging, Anti-Abuse and Spam Conference, New York, NY, USA, 2011, pp. 46\u201354.", "citeRegEx": "14", "shortCiteRegEx": null, "year": 2011}, {"title": "A Framework for Unsupervised Spam Detection in Social Networking Sites", "author": ["M. Bosma", "E. Meij", "W. Weerkamp"], "venue": "Proceedings of the 34th European Conference on Advances in Information Retrieval, Berlin, Heidelberg, 2012, pp. 364\u2013375.", "citeRegEx": "15", "shortCiteRegEx": null, "year": 2012}, {"title": "Community-based Features for Identifying Spammers in Online Social Networks", "author": ["S.Y. Bhat", "M. Abulaish"], "venue": "Proceedings of the 2013 IEEE/ACM International Conference on Advances in Social Networks Analysis and Mining, New York, NY, USA, 2013, pp. 100\u2013 107.", "citeRegEx": "16", "shortCiteRegEx": null, "year": 2013}, {"title": "Spammer Classification Using Ensemble Methods over Structural Social Network Features", "author": ["S.Y. Bhat", "M. Abulaish", "A.A. Mirza"], "venue": "2014 IEEE/WIC/ACM International Joint Conferences on Web Intelligence (WI) and Intelligent Agent Technologies (IAT), 2014, vol. 2, pp. 454\u2013458.", "citeRegEx": "17", "shortCiteRegEx": null, "year": 2014}, {"title": "A Comparison of Machine Learning Techniques for Phishing Detection", "author": ["S. Abu-Nimeh", "D. Nappa", "X. Wang", "S. Nair"], "venue": "Proceedings of the Anti-phishing Working Groups 2Nd Annual eCrime Researchers Summit, New York, NY, USA, 2007, pp. 60\u201369.", "citeRegEx": "18", "shortCiteRegEx": null, "year": 2007}, {"title": "Learning to Detect Phishing Emails", "author": ["I. Fette", "N. Sadeh", "A. Tomasic"], "venue": "Proceedings of the 16th International Conference on World Wide Web, New York, NY, USA, 2007, pp. 649\u2013656.", "citeRegEx": "19", "shortCiteRegEx": null, "year": 2007}, {"title": "Detecting Spammers on Social Networks", "author": ["G. Stringhini", "C. Kruegel", "G. Vigna"], "venue": "Proceedings of the 26th Annual Computer Security Applications Conference, New York, NY, USA, 2010, pp. 1\u2013 9.", "citeRegEx": "20", "shortCiteRegEx": null, "year": 2010}, {"title": "Supervised Learning", "author": ["C. Sammut", "G.I. Webb", "Eds."], "venue": "Encyclopedia of Machine Learning, Springer US, 2010, pp. 941\u2013941.", "citeRegEx": "21", "shortCiteRegEx": null, "year": 2010}, {"title": "A Simple Approach to Building Ensembles of Naive Bayesian Classifiers for Word Sense Disambiguation", "author": ["T. Pedersen"], "venue": "Proceedings of the 1st North American Chapter of the Association for Computational Linguistics Conference, Stroudsburg, PA, USA, 2000, pp. 63\u201369.", "citeRegEx": "22", "shortCiteRegEx": null, "year": 2000}, {"title": "Locally Weighted Naive Bayes", "author": ["E. Frank", "M. Hall", "B. Pfahringer"], "venue": "Proceedings of the Conference on Uncertainty in Artificial Intelligence, 2003, pp. 249\u2013256.", "citeRegEx": "23", "shortCiteRegEx": null, "year": 2003}, {"title": "LIBSVM: a Library for Support Vector Machines", "author": ["C. Chang", "C.-J. Lin"], "venue": null, "citeRegEx": "24", "shortCiteRegEx": "24", "year": 2001}, {"title": "A Comprehensive Survey of Data Mining-based Fraud Detection Research", "author": ["C. Phua", "V. Lee", "K. Smith", "R. Gayler"], "venue": "Comput. Hum. Behav., vol. 28, no. 3, pp. 1002\u20131013, May 2012.", "citeRegEx": "25", "shortCiteRegEx": null, "year": 2012}, {"title": "Instance-based learning algorithms", "author": ["D.W. Aha", "D. Kibler", "M.K. Albert"], "venue": "Mach. Learn., vol. 6, no. 1, pp. 37\u201366, Jan. 1991.", "citeRegEx": "26", "shortCiteRegEx": null, "year": 1991}, {"title": "Krebs On Security: In-depth security news and investigation", "author": ["B. Krebs"], "venue": "Spy Service Exposes Nigerian \u201cYahoo Boys.\u201d.", "citeRegEx": "27", "shortCiteRegEx": null, "year": 0}, {"title": "Learning from Imbalanced Data", "author": ["H. He", "E. Garcia"], "venue": "IEEE Trans. Knowl. Data Eng., vol. 21, no. 9, pp. 1263\u20131284, Sep. 2009.", "citeRegEx": "28", "shortCiteRegEx": null, "year": 2009}, {"title": "Weka", "author": ["E. Frank", "M. Hall", "G. Holmes", "R. Kirkby", "B. Pfahringer", "I.H. Witten", "L. Trigg"], "venue": "Data Mining and Knowledge Discovery (IJCSIS) International Journal of Computer Science and Information Security, Vol. 13, No.7, July 2015 Handbook, O. Maimon and L. Rokach, Eds. Springer US, 2005, pp. 1305\u20131314.", "citeRegEx": "29", "shortCiteRegEx": null, "year": 2015}, {"title": "Estimating Continuous Distributions in Bayesian Classifiers", "author": ["George H. John", "Pat Langley"], "venue": "Eleventh Conference on Uncertainty in Artificial Intelligence, San Mateo, 1995, pp. 338\u2013345.", "citeRegEx": "30", "shortCiteRegEx": null, "year": 1995}], "referenceMentions": [{"referenceID": 0, "context": "Some research categorizes cybercrime into content-based and technologybased crime [1].", "startOffset": 82, "endOffset": 85}, {"referenceID": 1, "context": "Other studies provide elaborate classification of cybercrime to include offences against confidentiality, availability and integrity of information and information technology [2].", "startOffset": 175, "endOffset": 178}, {"referenceID": 2, "context": "This study extends work in a previous paper [4] by implementing machine learning algorithms to detect 419 scams within an actual bilingual cybercriminal community.", "startOffset": 44, "endOffset": 47}, {"referenceID": 3, "context": "exploiting to profit from crime [5], [6], [7], [8].", "startOffset": 32, "endOffset": 35}, {"referenceID": 4, "context": "exploiting to profit from crime [5], [6], [7], [8].", "startOffset": 37, "endOffset": 40}, {"referenceID": 5, "context": "exploiting to profit from crime [5], [6], [7], [8].", "startOffset": 42, "endOffset": 45}, {"referenceID": 6, "context": "exploiting to profit from crime [5], [6], [7], [8].", "startOffset": 47, "endOffset": 50}, {"referenceID": 0, "context": "includes but is not limited to hacking, code injection, espionage [1].", "startOffset": 66, "endOffset": 69}, {"referenceID": 2, "context": "leaked emails obtained from an online data theft service [4].", "startOffset": 57, "endOffset": 60}, {"referenceID": 7, "context": "These scams are known as advance-fee fraud or 419 scams [9], [10].", "startOffset": 56, "endOffset": 59}, {"referenceID": 8, "context": "These scams are known as advance-fee fraud or 419 scams [9], [10].", "startOffset": 61, "endOffset": 65}, {"referenceID": 9, "context": "419 scams originated from Nigerian in the 1970s at smaller scale but escalated in the 1980s during the oil boom as posted letters and then transitioned to email in the 1990's with commercialization of the Internet [11].", "startOffset": 214, "endOffset": 218}, {"referenceID": 9, "context": "7 billion during that year to this category of cyber-criminals [11].", "startOffset": 63, "endOffset": 67}, {"referenceID": 10, "context": "Various research has studied detection of different types of content-based cybercrime like fraud, phishing and spam [12], [13].", "startOffset": 116, "endOffset": 120}, {"referenceID": 11, "context": "Various research has studied detection of different types of content-based cybercrime like fraud, phishing and spam [12], [13].", "startOffset": 122, "endOffset": 126}, {"referenceID": 12, "context": ", study spam in social networks to build a social spam detection framework that filters spam across multiple social networks namely: MySpace, Twitter and WebbSpam Corpus [14].", "startOffset": 170, "endOffset": 174}, {"referenceID": 13, "context": ", develop a social spam detection framework that uses link analysis and this implemented on a popular social network [15].", "startOffset": 117, "endOffset": 121}, {"referenceID": 14, "context": ", propose a community-based framework and apply ensemble classifiers to detect spammers within community nodes in online social networks [16], [17].", "startOffset": 137, "endOffset": 141}, {"referenceID": 15, "context": ", propose a community-based framework and apply ensemble classifiers to detect spammers within community nodes in online social networks [16], [17].", "startOffset": 143, "endOffset": 147}, {"referenceID": 16, "context": "Other studies evaluate predictive accuracy of several machine learning algorithms like Support Vector Machines, Random Forests, Na\u00efve Bayes, Neural Networks in predicting phishing emails [18], [19].", "startOffset": 187, "endOffset": 191}, {"referenceID": 17, "context": "Other studies evaluate predictive accuracy of several machine learning algorithms like Support Vector Machines, Random Forests, Na\u00efve Bayes, Neural Networks in predicting phishing emails [18], [19].", "startOffset": 193, "endOffset": 197}, {"referenceID": 18, "context": "Other research investigates the extent at which malware and spam has infiltrated online social networks [20].", "startOffset": 104, "endOffset": 108}, {"referenceID": 19, "context": "In supervised machine learning, the algorithms map inputs to specific outputs using input and output data [21].", "startOffset": 106, "endOffset": 110}, {"referenceID": 20, "context": "The algorithm implements Bayes Theorem which assumes conditional independence in feature variables of a learning set to predict statistical outcomes [22], [23].", "startOffset": 149, "endOffset": 153}, {"referenceID": 21, "context": "The algorithm implements Bayes Theorem which assumes conditional independence in feature variables of a learning set to predict statistical outcomes [22], [23].", "startOffset": 155, "endOffset": 159}, {"referenceID": 22, "context": "This algorithm has been used in studying spam, fraud, malware , and phishing [24] [25].", "startOffset": 77, "endOffset": 81}, {"referenceID": 23, "context": "This algorithm has been used in studying spam, fraud, malware , and phishing [24] [25].", "startOffset": 82, "endOffset": 86}, {"referenceID": 24, "context": "With instance-based learning, the kNN algorithm looks at the k-nearest neighbors when determining which instance to predict [26].", "startOffset": 124, "endOffset": 128}, {"referenceID": 25, "context": "We use a publicly leaked set of 1036 email addresses of Nigerian cybercriminals who are using an online data theft service called PrivateRecovery (which was formerly called BestRecovery) [27].", "startOffset": 187, "endOffset": 191}, {"referenceID": 2, "context": "The Facebook URLs of these actors was used in a previous paper to construct large graph of 43,125 criminal nodes [4].", "startOffset": 113, "endOffset": 116}, {"referenceID": 26, "context": "Precision, however, measures how many of the scam messages are detected correctly hence this is a measure of probability that a predicted outcome is the right one [28].", "startOffset": 163, "endOffset": 167}, {"referenceID": 27, "context": "In this section we demonstrate how we obtain results on performance of the three classifiers in WEKA[29] using the four sub-datasets.", "startOffset": 100, "endOffset": 104}, {"referenceID": 28, "context": "To solve our classification problem we use three classifiers namely: Na\u00efve Bayes (NB)[30], Support Vector Machines (LibSVM), and k-Nearest Neighbor (IBK) [26].", "startOffset": 85, "endOffset": 89}, {"referenceID": 24, "context": "To solve our classification problem we use three classifiers namely: Na\u00efve Bayes (NB)[30], Support Vector Machines (LibSVM), and k-Nearest Neighbor (IBK) [26].", "startOffset": 154, "endOffset": 158}], "year": 2015, "abstractText": "Incidents of organized cybercrime are rising because of criminals are reaping high financial rewards while incurring low costs to commit crime. As the digital landscape broadens to accommodate more internet-enabled devices and technologies like social media, more cybercriminals who are not native English speakers are invading cyberspace to cash in on quick exploits. In this paper we evaluate the performance of three machine learning classifiers in detecting 419 scams in a bilingual Nigerian cybercriminal community. We use three popular classifiers in text processing namely: Na\u00efve Bayes, k-nearest neighbors (IBK) and Support Vector Machines (SVM). The preliminary results on a real world dataset reveal the SVM significantly outperforms Na\u00efve Bayes and IBK at 95% confidence level. Keywords-Machine Learning; Bilingual Cybercriminals; 419 Scams;", "creator": "Acrobat PDFMaker 10.1 for Word"}}}