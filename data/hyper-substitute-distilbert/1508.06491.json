{"id": "1508.06491", "review": {"conference": "EMNLP", "VERSION": "v1", "DATE_OF_SUBMISSION": "26-Aug-2015", "title": "Alignment-Based Compositional Semantics for Instruction Following", "abstract": "this paper describes sophisticated alignment - based model for composing natural language correctly inside context. semantics address vision following describing a search including plans, mutual cognition of actions conditioned utilizing structured observations of text and the text. by explicitly combining solely the low - probability frame structure of individual actions by another high - level structure of full plans, readers increase able to learn to complete representations of document meaning although pragmatic constraints on statements. that demonstrate the simulation'framing flexibility, we apply it below a diverse set composing benchmark tasks. on every transaction, we include fixed task - execution sequences, or highlight several new state - of - the - art results.", "histories": [["v1", "Wed, 26 Aug 2015 13:44:54 GMT  (909kb,D)", "https://arxiv.org/abs/1508.06491v1", "in proceedings of EMNLP 2015"], ["v2", "Wed, 12 Apr 2017 19:51:09 GMT  (1062kb,D)", "http://arxiv.org/abs/1508.06491v2", "in proceedings of EMNLP 2015"]], "COMMENTS": "in proceedings of EMNLP 2015", "reviews": [], "SUBJECTS": "cs.CL", "authors": ["jacob andreas", "dan klein"], "accepted": true, "id": "1508.06491"}, "pdf": {"name": "1508.06491.pdf", "metadata": {"source": "CRF", "title": "Alignment-Based Compositional Semantics for Instruction Following", "authors": ["Jacob Andreas"], "emails": ["jda@cs.berkeley.edu", "klein@cs.berkeley.edu"], "sections": [{"heading": "1 Introduction", "text": "In instruction-following tasks, an agent executes a sequence of actions in a real or simulated environment, in response to a sequence of natural language commands. Examples include giving navigational directions to robots and providing hints to automated game-playing agents. Plans specified with natural language exhibit compositionality both at the level of individual actions and at the overall sequence level. This paper describes a framework for learning to follow instructions by leveraging structure at both levels.\nOur primary contribution is a new, alignmentbased approach to grounded compositional semantics. Building on related logical approaches (Reddy et al., 2014; Pourdamghani et al., 2014), we recast instruction following as a pair of nested, structured alignment problems. Given instructions and a candidate plan, the model infers a sequenceto-sequence alignment between sentences and\natomic actions. Within each sentence\u2013action pair, the model infers a structure-to-structure alignment between the syntax of the sentence and a graphbased representation of the action.\nAt a high level, our agent is a block-structured, graph-valued conditional random field, with alignment potentials to relate instructions to actions and transition potentials to encode the environment model (Figure 3). Explicitly modeling sequenceto-sequence alignments between text and actions allows flexible reasoning about action sequences, enabling the agent to determine which actions are specified (perhaps redundantly) by text, and which actions must be performed automatically (in order to satisfy pragmatic constraints on interpretation). Treating instruction following as a sequence prediction problem, rather than a series of independent decisions (Branavan et al., 2009; Artzi and Zettlemoyer, 2013), makes it possible to use general-purpose planning machinery, greatly increasing inferential power.\nThe fragment of semantics necessary to complete most instruction-following tasks is essentially predicate\u2013argument structure, with limited influence from quantification and scoping. Thus the problem of sentence interpretation can reasonably be modeled as one of finding an alignment between language and the environment it describes. We allow this structure-to-structure alignment\u2014 an \u201coverlay\u201d of language onto the world\u2014to be mediated by linguistic structure (in the form of dependency parses) and structured perception (in what we term grounding graphs). Our model thereby reasons directly about the relationship between language and observations of the environment, without the need for an intermediate logical representation of sentence meaning. This, in turn, makes it possible to incorporate flexible feature representations that have been difficult to integrate with previous work in semantic parsing.\nWe apply our approach to three established\nar X\niv :1\n50 8.\n06 49\n1v 2\n[ cs\n.C L\n] 1\n2 A\npr 2\n01 7\n2 1 3\ninstruction-following benchmarks: the map reading task of Vogel and Jurafsky (2010), the maze navigation task of MacMahon et al. (2006), and the puzzle solving task of Branavan et al. (2009). An example from each is shown in Figure 1. These benchmarks exhibit a range of qualitative properties\u2014both in the length and complexity of their plans, and in the quantity and quality of accompanying language. Each task has been studied in isolation, but we are unaware of any published approaches capable of robustly handling all three. Our general model outperforms strong, task-specific baselines in each case, achieving relative error reductions of 15\u201320% over several state-of-the-art results. Experiments demonstrate the importance of our contributions in both compositional semantics and search over plans. We have released all code for this project at github.com/jacobandreas/instructions."}, {"heading": "2 Related work", "text": "Existing work on instruction following can be roughly divided into two families: semantic parsers and linear policy estimators.\nSemantic parsers Parser-based approaches (Chen and Mooney, 2011; Artzi and Zettlemoyer, 2013; Kim and Mooney, 2013; Tellex et al., 2011) map from text into a formal language representing commands. These take familiar structured prediction models for semantic parsing (Zettlemoyer and Collins, 2005; Wong and Mooney, 2006), and train them with task-provided supervision. Instead of attempting to match the structure of a manually-annotated semantic parse, semantic parsers for instruction following are\ntrained to maximize a reward signal provided by black-box execution of the predicted command in the environment. (It is possible to think of response-based learning for question answering (Liang et al., 2013) as a special case.)\nThis approach uses a well-studied mechanism for compositional interpretation of language, but is subject to certain limitations. Because the environment is manipulated only through black-box execution of the completed semantic parse, there is no way to incorporate current or future environment state into the scoring function. It is also in general necessary to hand-engineer a task-specific formal language for describing agent behavior. Thus it is extremely difficult to work with environments that cannot be modeled with a fixed inventory of predicates (e.g. those involving novel strings or arbitrary real quantities).\nMuch of contemporary work in this family is evaluated on the maze navigation task introduced by MacMahon et al. (2006). Dukes (2013) also introduced a \u201cblocks world\u201d task for situated parsing of spatial robot commands.\nLinear policy estimators An alternative family of approaches is based on learning a policy over primitive actions directly (Branavan et al., 2009; Vogel and Jurafsky, 2010).1 Policybased approaches instantiate a Markov decision process representing the action domain, and apply standard supervised or reinforcement-learning approaches to learn a function for greedily selecting among actions. In linear policy approximators, natural language instructions are incorporated di-\n1This is distinct from semantic parsers in which greedy inference happens to have an interpretation as a policy (Vlachos and Clark, 2014).\nrectly into state observations, and reading order becomes part of the action selection process.\nAlmost all existing policy-learning approaches make use of an unstructured parameterization, with a single (flat) feature vector representing all text and observations. Such approaches are thus restricted to problems that are simple enough (and have small enough action spaces) to be effectively characterized in this fashion. While there is a great deal of flexibility in the choice of feature function (which is free to inspect the current and future state of the environment, the whole instruction sequence, etc.), standard linear policy estimators have no way to model compositionality in language or actions.\nAgents in this family have been evaluated on a variety of tasks, including map reading (Anderson et al., 1991) and gameplay (Branavan et al., 2009).\nThough both families address the same class of instruction-following problems, they have been applied to a totally disjoint set of tasks. It should be emphasized that there is nothing inherent to policy learning that prevents the use of compositional structure, and nothing inherent to general compositional models that prevents more complicated dependence on environment state. Indeed, previous work (Branavan et al., 2011; Narasimhan et al., 2015) uses aspects of both to solve a different class of gameplay problems. In some sense, our goal in this paper is simply to combine the strengths of semantic parsers and linear policy estimators for fully general instruction following. As we shall see, however, this requires changes to many aspects of representation, learning and inference."}, {"heading": "3 Representations", "text": "We wish to train a model capable of following commands in a simulated environment. We do so by presenting the model with a sequence of training pairs (x,y), where each x is a sequence of natural language instructions (x1, x2, . . . , xm), e.g.:\n(Go down the yellow hall., Turn left., . . . )\nand each y is a demonstrated action sequence (y1, y2, . . . , yn), e.g.:\n(rotate(90), move(2), . . . )\nGiven a start state, y can equivalently be characterized by a sequence of (state, action, state)\ntriples resulting from execution of the environment model. An example instruction is shown in Figure 2a. An example action, situated in the environment where it occurs, is shown in Figure 2e.\nOur model performs compositional interpretation of instructions by leveraging existing structure inherent in both text and actions. Thus we interpret xi and yj not as raw strings and primitive actions, but rather as structured objects.\nLinguistic structure We assume access to a pretrained parser, and in particular that each of the instructions xi is represented by a tree-structured dependency parse. An example is shown in Figure 2b.\nAction structure By analogy to the representation of instructions as parse trees, we assume that each (state, action, state) triple (provided by the environment model) can be characterized by a grounding graph.2 The structure and content of\n2We note that the instruction following model of Tellex et al. (2011) features a similarly named \u201cGeneralized Ground-\nthis representation is task-specific. An example grounding graph for the maze navigation task is shown in Figure 2d. The example contains a node corresponding to the primitive action move(2) (in the upper left), and several nodes corresponding to locations in the environment that are visible after the action is performed.\nEach node in the graph (and, though not depicted, each edge) is decorated with a list of features. These features might be simple indicators (e.g. whether the primitive action performed was move or rotate), real values (the distance traveled) or even string-valued (English-language names of visible landmarks, if available in the environment description). Formally, a grounding graph consists of a tuple (V,E,L, fV , fE), with\n\u2013 V a set of vertices\n\u2013 E \u2208 V \u00d7 V a set of (directed) edges \u2013 L a space of labels (numbers, strings, etc.) \u2013 fV : V \u2192 2L a vertex feature function \u2013 fE : E \u2192 2L an edge feature function\nIn this paper we have tried to remain agnostic to details of graph construction. Our goal with the grounding graph framework is simply to accommodate a wider range of modeling decisions than allowed by existing formalisms. Graphs might be constructed directly, given access to a structured virtual environment (as in all experiments in this paper), or alternatively from outputs of a perceptual system. For our experiments, we have remained as close as possible to task representations described in the existing literature. Details for each task can be found in the accompanying software package.\nGraph-based representations are extremely common in formal semantics (Jones et al., 2012; Reddy et al., 2014), and the version presented here corresponds to a simple generalization of familiar formal methods. Indeed, if L is the set of all atomic entities and relations, fV returns a unique label for every v \u2208 V , and fE always returns a vector with one active feature, we recover the existentially-quantified portion of first order logic exactly, and in this form can implement large parts of classical neo-Davidsonian semantics (Parsons, 1990) using grounding graphs.\ning Graph\u201d (G3) formalism. A G3 links the syntax of the input command to the action ultimately executed, and is thus more analogous to our structured alignment variable (Figure 2c) than our perceptual representation.\nCrucially, with an appropriate choice of L this formalism also makes it possible to go beyond settheoretic relations, and incorporate string-valued features (like names of entities and landmarks) and real-valued features (like colors and positions) as well.\nLexical semantics We must eventually combine features provided by parse trees with features provided by the environment. Examples here might include simple conjunctions (word=yellow \u2227 rgb=(0.5, 0.5, 0.0)) or more complicated computations like edit distance between landmark names and lexical items. Features of the latter kind make it possible to behave correctly in environments containing novel strings or other features unseen during training.\nThis aspect of the syntax\u2013semantics interface has been troublesome for some logic-based approaches: while past work has used related machinery for selecting lexicon entries (Berant and Liang, 2014) or for rewriting logical forms (Kwiatkowski et al., 2013), the relationship between text and the environment has ultimately been mediated by a discrete (and indeed finite) inventory of predicates. Several recent papers have investigated simple grounded models with realvalued output spaces (Andreas and Klein, 2014; McMahan and Stone, 2015), but we are unaware of any fully compositional system in recent literature that can incorporate observations of these kinds.\nFormally, we assume access to a joining feature function \u03c6 : (2L \u00d7 2L)\u2192 Rd. As with grounding graphs, our goal is to make the general framework as flexible as possible, and for individual experiments have chosen \u03c6 to emulate modeling decisions from previous work."}, {"heading": "4 Model", "text": "As noted in the introduction, we approach instruction following as a sequence prediction problem. Thus we must place a distribution over sequences of actions conditioned on instructions. We decompose the problem into two components, describing interlocking models of \u201cpath structure\u201d and \u201caction structure\u201d. Path structure captures how sequences of instructions give rise to sequences of actions, while action structure captures the compositional relationship between individual utterances and the actions they specify.\nPath structure: aligning utterances to actions\nThe high-level path structure in the model is depicted in Figure 3. Our goal here is to permit both under- and over-specification of plans, and to expose a planning framework which allows plans to be computed with lookahead (i.e. non-greedily).\nThese goals are achieved by introducing a sequence of latent alignments between instructions and actions. Consider the multi-step example in Figure 1b. If the first instruction go down the yellow hall were interpreted immediately, we would have a presupposition failure\u2014the agent is facing a wall, and cannot move forward at all. Thus an implicit rotate action, unspecified by text, must be performed before any explicit instructions can be followed.\nTo model this, we take the probability of a (text, plan, alignment) triple to be log-proportional to the sum of two quantities:\n1. a path-only score \u03c8(n; \u03b8) + \u2211\nj \u03c8(yj ; \u03b8)\n2. a path-and-text score, itself the sum of all pair scores \u03c8(xi, yj ; \u03b8) licensed by the alignment\n(1) captures our desire for pragmatic constraints on interpretation, and provides a means of encoding the inherent plausibility of paths. We take \u03c8(n; \u03b8) and \u03c8(y; \u03b8) to be linear functions of \u03b8. (2) provides context-dependent interpretation of text by means of the structured scoring function \u03c8(x, y; \u03b8), described in the next section.\nFormally, we associate with each instruction xi a sequence-to-sequence alignment variable ai \u2208\n1 . . . n (recalling that n is the number of actions). Then we have3\np(y,a|x; \u03b8) \u221d exp { \u03c8(n) + n\u2211 j=1 \u03c8(yj)\n+ m\u2211 i=1 n\u2211 j=1 1[aj = i] \u03c8(xi, yj) } (1)\nWe additionally place a monotonicity constraint on the alignment variables. This model is globally normalized, and for a fixed alignment is equivalent to a linear-chain CRF. In this sense it is analogous to IBM Model I (Brown et al., 1993), with the structured potentials \u03c8(xi, yj) taking the place of lexical translation probabilities. While alignment models from machine translation have previously been used to align words to fragments of semantic parses (Wong and Mooney, 2006; Pourdamghani et al., 2014), we are unaware of such models being used to align entire instruction sequences to demonstrations.\nAction structure: aligning words to percepts Intuitively, this scoring function \u03c8(x, y) should capture how well a given utterance describes an action. If neither the utterances nor the actions had structure (i.e. both could be represented with simple bags of features), we would recover something analogous to the conventional policy-learning approach. As structure is essential for some of our tasks, \u03c8(x, y) must instead fill the role of a semantic parser in a conventional compositional model.\nOur choice of \u03c8(x, y) is driven by the following fundamental assumptions: Syntactic relations approximately represent semantic relations. Syntactic proximity implies relational proximity. In this view, there is an additional hidden structure-tostructure alignment between the grounding graph and the parsed text describing it. 4 Words line up with nodes, and dependencies line up with relations. Visualizations are shown in Figure 2c and the zoomed-in portion of Figure 3.\nAs with the top-level alignment variables, this approach can viewed as a simple relaxation of a familiar model. CCG-based parsers assume that\n3Here and in the remainder of this paper, we suppress the dependence of the various potentials on \u03b8 in the interest of readability.\n4It is formally possible to regard the sequence-tosequence and structure-to-structure alignments as a single (structured) random variable. However, the two kinds of alignments are treated differently for purposes of inference, so it is useful to maintain a notational distinction.\nsyntactic type strictly determines semantic type, and that each lexical item is associated with a small set of functional forms. Here we simply allow all words to license all predicates, multiple words to specify the same predicate, and some edges to be skipped. We instead rely on a scoring function to impose soft versions of the hard constraints typically provided by a grammar. Related models have previously been used for question answering (Reddy et al., 2014; Pasupat and Liang, 2015).\nFor the moment let us introduce variables b to denote these structure-to-structure alignments. (As will be seen in the following section, it is straightforward to marginalize over all choices of b. Thus the structure-to-structure alignments are never explicitly instantiated during inference, and do not appear in the final form of \u03c8(x, y).) For a fixed alignment, we define \u03c8(x, y, b) according to a recurrence relation. Let xi be the ith word of the sentence, and let yj be the jth node in the action graph (under some topological ordering). Let c(i) and c(j) give the indices of the dependents of xi and children of yj respectively. Finally, let xik and yjl denote the associated dependency type or relation. Define a \u201cdescendant\u201d function:\nd(i, j) = { (k, l) : k \u2208 c(i), l \u2208 c(j), (k, l) \u2208 b } Then,\n\u03c8(xi, yj , b) = exp { \u03b8>\u03c6(xi, yj)\n+ \u2211\n(k,l)\u2208d(x,y)\n[ \u03b8>\u03c6 ( xik, yjl ) \u00b7 \u03c8(xk, yl, b) ]} This is just an unnormalized synchronous derivation between x and y\u2014at any aligned (node, word) pair, the score for the entire derivation is the score produced by combining that word and node, times the scores at all the aligned descendants. Observe that as long as there are no cycles in the dependency parse, it is perfectly acceptable for the relation graph to contain cycles and even self-loops\u2014 the recurrence still bottoms out appropriately."}, {"heading": "5 Learning and inference", "text": "Given a sequence of training pairs (x,y), we wish to find a parameter setting that maximizes p(y|x; \u03b8). If there were no latent alignments a or b, this would simply involve minimization of a convex objective. The presence of latent variables complicates things. Ideally, we would like\nAlgorithm 1 Computing structure-to-structure alignments\nxi are words in reverse topological order yj are grounding graph nodes (root last) chart is an m\u00d7 n array for i = 1 to |x| do\nfor j = 1 to |y| do score\u2190 exp { \u03b8>\u03c6(xi, yj) } for (k, l) \u2208 d(i, j) do\ns\u2190 \u2211\nl\u2208c(j)\n[ exp { \u03b8>\u03c6(xik, yjl) } \u00b7 chart[k, l]\n] score\u2190 score \u00b7 s\nend for chart[i, j]\u2190 score\nend for end for return chart[n,m]\nto sum over the latent variables, but that sum is intractable. Instead we make a series of variational approximations: first we replace the sum with a maximization, then perform iterated conditional modes, alternating between maximization of the conditional probability of a and \u03b8. We begin by initializing \u03b8 randomly.\nAs noted in the preceding section, the variable b does not appear in these equations. Conditioned on a, the sum over structure-to-structure \u03c8(x, y) = \u2211 b \u03c8(x, y, b) can be performed exactly using a simple dynamic program which runs in time O(|x||y|) (assuming out-degree bounded by a constant, and with |x| and |y| the number of words and graph nodes respectively). This is Algorithm 1.\nIn our experiments, \u03b8 is optimized using LBFGS (Liu and Nocedal, 1989). Calculation of the gradient with respect to \u03b8 requires computation of a normalizing constant involving the sum over p(x,y\u2032,a) for all y\u2032. While in principle the normalizing constant can be computed using the forward algorithm, in practice the state spaces under consideration are so large that even this is intractable. Thus we make an additional approximation, constructing a set Y\u0303 of alternative actions and taking p(y,a|x) \u2248 n\u2211 j=1 exp { \u03c8(yj)+ \u2211m i=1 1[ai=j]\u03c8(xi,yi) } \u2211 y\u0303\u2208Y\u0303 exp { \u03c8(y\u0303)+ \u2211m i=1 1[ai=j]\u03c8(xi,y\u0303) }\nY\u0303 is constructed by sampling alternative actions from the environment model. Meanwhile, maximization of a can be performed exactly using the Viterbi algorithm, without computation of normalizers.\nInference at test time involves a slightly different pair of optimization problems. We again perform iterated conditional modes, here on the alignments a and the unknown output path y. Maximization of a is accomplished with the Viterbi algorithm, exactly as before; maximization of y also uses the Viterbi algorithm, or a beam search when this is computationally infeasible. If bounds on path length are known, it is straightforward to adapt these dynamic programs to efficiently consider paths of all lengths."}, {"heading": "6 Evaluation", "text": "As one of the main advantages of this approach is its generality, we evaluate on several different benchmark tasks for instruction following. These exhibit great diversity in both environment structure and language use. We compare our full system to recent state-of-the-art approaches to each task. In the introduction, we highlighted two core aspects of our approach to semantics: compositionality (by way of grounding graphs and structure-to-structure alignments) and planning (by way of inference with lookahead and sequence-to-sequence alignments). To evaluate these, we additionally present a pair of ablation experiments: no grounding graphs (an agent with an unstructured representation of environment state), and no planning (a reflex agent with no lookahead).\nMap reading Our first application is the map navigation task established by Vogel and Jurafsky (2010), based on data collected for a psychological experiment by Anderson et al. (1991) (Figure 1a). Each training datum consists of a map with a designated starting position, and a collection of landmarks, each labeled with a spatial coordinate and a string name. Names are not always unique, and landmarks in the test set are never observed during training. This map is accompanied by a set of instructions specifying a path from the starting position to some (unlabeled) destination point. These instruction sets are informal and redundant, involving as many as a hundred utterances. They are transcribed from spoken text, so grammatical errors, disfluencies, etc. are common. This is a\nprime example of a domain that does not lend itself to logical representation\u2014grammars may be too rigid, and previously-unseen landmarks and real-valued positions are handled more easily with feature machinery than predicate logic.\nThe map task was previously studied by Vogel and Jurafsky (2010), who implemented SARSA with a simple set of features. By combining these features with our alignment model and search procedure, we achieve state-of-the-art results on this task by a substantial margin (Table 1).\nSome learned feature values are shown in Table 2. The model correctly infers cardinal directions (the example shows the preferred side of a destination landmark modified by the word top). Like Vogel et al., we see support for both allocentric references (you are on top of the hill) and egocentric references (the hill is on top of you). We can also see pragmatics at work: the model learns useful text-independent constraints\u2014in this case, that near destinations should be preferred to far ones.\nMaze navigation The next application we consider is the maze navigation task of MacMahon et al. (2006) (Figure 1b). Here, a virtual agent is sit-\nuated in a maze (whose hallways are distinguished with various wallpapers, carpets, and the presence of a small set of standard objects), and again given instructions for getting from one point to another. This task has been the subject of focused attention in semantic parsing for several years, resulting in a variety of sophisticated approaches.\nDespite superficial similarity to the previous navigation task, the language and plans required for this task are quite different. The proportion of instructions to actions is much higher (so redundancy much lower), and the interpretation of language is highly compositional.\nAs can be seen in Table 3, we outperform a number of systems purpose-built for this navigation task. We also outperform both variants of our system, most conspicuously the variant without grounding graphs. This highlights the importance of compositional structure. Recent work by Kim and Mooney (2013) and Artzi et al. (2014) has achieved better results; these systems make use of techniques and resources (respectively, discriminative reranking and a seed lexicon of handannotated logical forms) that are largely orthogonal to the ones used here, and might be applied to improve our own results as well.\nPuzzle solving The last task we consider is the Crossblock task studied by Branavan et al. (2009) (Figure 1c). Here, again, natural language is used to specify a sequence of actions, in this case the solution to a simple game. The environment is simple enough to be captured with a flat feature\n5We specifically targeted the single-sentence version of this evaluation, as an alternative full-sequence evaluation does not align precisely with our data condition.\nrepresentation, so there is no distinction between the full model and the variant without grounding graphs.\nUnlike the other tasks we consider, Crossblock is distinguished by a challenging associated search problem. Here it is nontrivial to find any sequence that eliminates all the blocks (the goal of the puzzle). Thus this example allows us measure the effectiveness of our search procedure.\nResults are shown in Table 4. As can be seen, our model achieves state-of-the-art performance on this task when attempting to match the humanspecified plan exactly. If we are purely concerned with task completion (i.e. solving the puzzle, perhaps not with the exact set of moves specified in the instructions) we can measure this directly. Here, too, we substantially outperform a no-text baseline. Thus it can be seen that text induces a useful heuristic, allowing the model to solve a considerable fraction of problem instances not solved by na\u0131\u0308ve beam search.\nThe problem of inducing planning heuristics from side information like text is an important one in its own right, and future work might focus specifically on coupling our system with a more sophisticated planner. Even at present, the results in this section demonstrate the importance of lookahead and high-level reasoning in instruction following."}, {"heading": "7 Conclusion", "text": "We have described a new alignment-based compositional model for following sequences of natural language instructions, and demonstrated the effectiveness of this model on a variety of tasks. A fully general solution to the problem of contextual interpretation must address a wide range of wellstudied problems, but the work we have described\nhere provides modular interfaces for the study of a number of fundamental linguistic issues from a machine learning perspective. These include:\nPragmatics How do we respond to presupposition failures, and choose among possible interpretations of an instruction disambiguated only by context? The mechanism provided by the sequence-prediction architecture we have described provides a simple answer to this question, and our experimental results demonstrate that the learned pragmatics aid interpretation of instructions in a number of concrete ways: ambiguous references are resolved by proximity in the map reading task, missing steps are inferred from an environment model in the maze navigation task, and vague hints are turned into real plans by knowledge of the rules in Crossblock. A more comprehensive solution might explicitly describe the process by which instruction-givers\u2019 own beliefs (expressed as distributions over sequences) give rise to instructions.\nCompositional semantics The graph alignment model of semantics presented here is an expressive and computationally efficient generalization of classical logical techniques to accommodate environments like the map task, or those explored in our previous work (Andreas and Klein, 2014). More broadly, our model provides a compositional approach to semantics that does not require an explicit formal language for encoding sentence meaning. Future work might extend this approach to tasks like question answering, where logicbased approaches have been successful.\nOur primary goal in this paper has been to explore methods for integrating compositional semantics and the pragmatic context provided by sequential structures. While there is a great deal of work left to do, we find it encouraging that this general approach results in substantial gains across multiple tasks and contexts."}, {"heading": "Acknowledgments", "text": "The authors would like to thank S.R.K. Branavan for assistance with the Crossblock evaluation. The first author is supported by a National Science Foundation Graduate Fellowship."}], "references": [{"title": "Grounding language with points and paths in continuous spaces", "author": ["Jacob Andreas", "Dan Klein."], "venue": "Proceedings of the Conference on Natural Language Learning.", "citeRegEx": "Andreas and Klein.,? 2014", "shortCiteRegEx": "Andreas and Klein.", "year": 2014}, {"title": "Weakly supervised learning of semantic parsers for mapping instructions to actions", "author": ["Yoav Artzi", "Luke Zettlemoyer."], "venue": "Transactions of the Association for Computational Linguistics, 1(1):49\u201362.", "citeRegEx": "Artzi and Zettlemoyer.,? 2013", "shortCiteRegEx": "Artzi and Zettlemoyer.", "year": 2013}, {"title": "Learning compact lexicons for CCG semantic parsing", "author": ["Yoav Artzi", "Dipanjan Das", "Slav Petrov."], "venue": "Proceedings of the Conference on Empirical Methods in Natural Language Processing, pages 1273\u20131283, Doha, Qatar, October. Association for", "citeRegEx": "Artzi et al\\.,? 2014", "shortCiteRegEx": "Artzi et al\\.", "year": 2014}, {"title": "Semantic parsing via paraphrasing", "author": ["Jonathan Berant", "Percy Liang."], "venue": "Proceedings of the Annual Meeting of the Association for Computational Linguistics, page 92.", "citeRegEx": "Berant and Liang.,? 2014", "shortCiteRegEx": "Berant and Liang.", "year": 2014}, {"title": "Reinforcement learning for mapping instructions to actions", "author": ["S.R.K. Branavan", "Harr Chen", "Luke S. Zettlemoyer", "Regina Barzilay."], "venue": "Proceedings of the Annual Meeting of the Association for Computational Linguistics, pages 82\u201390. Association for", "citeRegEx": "Branavan et al\\.,? 2009", "shortCiteRegEx": "Branavan et al\\.", "year": 2009}, {"title": "Learning to win by reading manuals in a Monte-Carlo framework", "author": ["S.R.K. Branavan", "David Silver", "Regina Barzilay."], "venue": "Proceedings of the Human Language Technology Conference of the Association for Computational Linguistics, pages 268\u2013", "citeRegEx": "Branavan et al\\.,? 2011", "shortCiteRegEx": "Branavan et al\\.", "year": 2011}, {"title": "The mathematics of statistical machine translation: Parameter estimation", "author": ["Peter Brown", "Vincent Della Pietra", "Stephen Della Pietra", "Robert Mercer."], "venue": "Computational Linguistics, 19(2):263\u2013311, June.", "citeRegEx": "Brown et al\\.,? 1993", "shortCiteRegEx": "Brown et al\\.", "year": 1993}, {"title": "Learning to interpret natural language navigation instructions from observations", "author": ["David L. Chen", "Raymond J. Mooney."], "venue": "Proceedings of the Meeting of the Association for the Advancement of Artificial Intelligence, volume 2, pages 1\u20132.", "citeRegEx": "Chen and Mooney.,? 2011", "shortCiteRegEx": "Chen and Mooney.", "year": 2011}, {"title": "Fast online lexicon learning for grounded language acquisition", "author": ["David L Chen."], "venue": "Proceedings of the Annual Meeting of the Association for Computational Linguistics, pages 430\u2013439.", "citeRegEx": "Chen.,? 2012", "shortCiteRegEx": "Chen.", "year": 2012}, {"title": "Semantic annotation of robotic spatial commands", "author": ["Kais Dukes."], "venue": "Language and Technology Conference (LTC).", "citeRegEx": "Dukes.,? 2013", "shortCiteRegEx": "Dukes.", "year": 2013}, {"title": "Semantics-based machine translation with hyperedge replacement grammars", "author": ["Bevan Jones", "Jacob Andreas", "Daniel Bauer", "Karl Moritz Hermann", "Kevin Knight."], "venue": "Proceedings of the International Conference on Computational", "citeRegEx": "Jones et al\\.,? 2012", "shortCiteRegEx": "Jones et al\\.", "year": 2012}, {"title": "Unsupervised PCFG induction for grounded language learning with highly ambiguous supervision", "author": ["Joohyun Kim", "Raymond J. Mooney."], "venue": "Proceedings of the Conference on Empirical Methods in Natural Language Processing, pages 433\u2013444.", "citeRegEx": "Kim and Mooney.,? 2012", "shortCiteRegEx": "Kim and Mooney.", "year": 2012}, {"title": "Adapting discriminative reranking to grounded language learning", "author": ["Joohyun Kim", "Raymond J. Mooney."], "venue": "Proceedings of the Annual Meeting of the Association for Computational Linguistics.", "citeRegEx": "Kim and Mooney.,? 2013", "shortCiteRegEx": "Kim and Mooney.", "year": 2013}, {"title": "Scaling semantic parsers with on-the-fly ontology matching", "author": ["Tom Kwiatkowski", "Eunsol Choi", "Yoav Artzi", "Luke Zettlemoyer."], "venue": "Proceedings of the Conference on Empirical Methods in Natural Language Processing.", "citeRegEx": "Kwiatkowski et al\\.,? 2013", "shortCiteRegEx": "Kwiatkowski et al\\.", "year": 2013}, {"title": "Learning dependency-based compositional semantics", "author": ["Percy Liang", "Michael I. Jordan", "Dan Klein."], "venue": "Computational Linguistics, 39(2):389\u2013446.", "citeRegEx": "Liang et al\\.,? 2013", "shortCiteRegEx": "Liang et al\\.", "year": 2013}, {"title": "On the limited memory BFGS method for large scale optimization", "author": ["Dong Liu", "Jorge Nocedal."], "venue": "Mathematical Programming, 45(1-3):503\u2013528.", "citeRegEx": "Liu and Nocedal.,? 1989", "shortCiteRegEx": "Liu and Nocedal.", "year": 1989}, {"title": "Walk the talk: Connecting language, knowledge, and action in route instructions", "author": ["Matt MacMahon", "Brian Stankiewicz", "Benjamin Kuipers."], "venue": "Proceedings of the Meeting of the Association for the Advancement of Artificial Intelligence, 2(6):4.", "citeRegEx": "MacMahon et al\\.,? 2006", "shortCiteRegEx": "MacMahon et al\\.", "year": 2006}, {"title": "A Bayesian model of grounded color semantics", "author": ["Brian McMahan", "Matthew Stone."], "venue": "Transactions of the Association for Computational Linguistics, 3:103\u2013115.", "citeRegEx": "McMahan and Stone.,? 2015", "shortCiteRegEx": "McMahan and Stone.", "year": 2015}, {"title": "Language understanding for textbased games using deep reinforcement learning", "author": ["Karthik Narasimhan", "Tejas Kulkarni", "Regina Barzilay."], "venue": "Proceedings of the Conference on Empirical Methods in Natural Language Processing.", "citeRegEx": "Narasimhan et al\\.,? 2015", "shortCiteRegEx": "Narasimhan et al\\.", "year": 2015}, {"title": "Events in the semantics of English", "author": ["Terence Parsons."], "venue": "MIT Press.", "citeRegEx": "Parsons.,? 1990", "shortCiteRegEx": "Parsons.", "year": 1990}, {"title": "Compositional semantic parsing on semi-structured tables", "author": ["Panupong Pasupat", "Percy Liang."], "venue": "Proceedings of the Annual Meeting of the Association for Computational Linguistics.", "citeRegEx": "Pasupat and Liang.,? 2015", "shortCiteRegEx": "Pasupat and Liang.", "year": 2015}, {"title": "Aligning english strings with abstract meaning representation graphs", "author": ["Nima Pourdamghani", "Yang Gao", "Ulf Hermjakob", "Kevin Knight."], "venue": "Proceedings of the Conference on Empirical Methods in Natural Language Processing.", "citeRegEx": "Pourdamghani et al\\.,? 2014", "shortCiteRegEx": "Pourdamghani et al\\.", "year": 2014}, {"title": "Large-scale semantic parsing without question-answer pairs", "author": ["Siva Reddy", "Mirella Lapata", "Mark Steedman."], "venue": "Transactions of the Association for Computational Linguistics, 2:377\u2013392.", "citeRegEx": "Reddy et al\\.,? 2014", "shortCiteRegEx": "Reddy et al\\.", "year": 2014}, {"title": "Understanding natural language commands for robotic navigation and mobile manipulation", "author": ["Stefanie Tellex", "Thomas Kollar", "Steven Dickerson", "Matthew R. Walter", "Ashis Gopal Banerjee", "Seth Teller", "Nicholas Roy."], "venue": "In Proceedings of the Na-", "citeRegEx": "Tellex et al\\.,? 2011", "shortCiteRegEx": "Tellex et al\\.", "year": 2011}, {"title": "A new corpus and imitation learning framework for contextdependent semantic parsing", "author": ["Andreas Vlachos", "Stephen Clark."], "venue": "Transactions of the Association for Computational Linguistics, 2:547\u2013559.", "citeRegEx": "Vlachos and Clark.,? 2014", "shortCiteRegEx": "Vlachos and Clark.", "year": 2014}, {"title": "Learning to follow navigational directions", "author": ["Adam Vogel", "Dan Jurafsky."], "venue": "Proceedings of the Annual Meeting of the Association for Computational Linguistics, pages 806\u2013814. Association for Computational Linguistics.", "citeRegEx": "Vogel and Jurafsky.,? 2010", "shortCiteRegEx": "Vogel and Jurafsky.", "year": 2010}, {"title": "Learning for semantic parsing with statistical machine translation", "author": ["Yuk Wah Wong", "Raymond Mooney."], "venue": "Proceedings of the Human Language Technology Conference of the North American Chapter of the Association for Computational", "citeRegEx": "Wong and Mooney.,? 2006", "shortCiteRegEx": "Wong and Mooney.", "year": 2006}, {"title": "Learning to map sentences to logical form: Structured classification with probabilistic categorial grammars", "author": ["Luke S. Zettlemoyer", "Michael Collins."], "venue": "Proceedings of the Conference on Uncertainty in Artificial Intelligence, pages 658\u2013666.", "citeRegEx": "Zettlemoyer and Collins.,? 2005", "shortCiteRegEx": "Zettlemoyer and Collins.", "year": 2005}], "referenceMentions": [{"referenceID": 22, "context": "Building on related logical approaches (Reddy et al., 2014; Pourdamghani et al., 2014), we recast instruction following as a pair of nested, structured alignment problems.", "startOffset": 39, "endOffset": 86}, {"referenceID": 21, "context": "Building on related logical approaches (Reddy et al., 2014; Pourdamghani et al., 2014), we recast instruction following as a pair of nested, structured alignment problems.", "startOffset": 39, "endOffset": 86}, {"referenceID": 4, "context": "Treating instruction following as a sequence prediction problem, rather than a series of independent decisions (Branavan et al., 2009; Artzi and Zettlemoyer, 2013), makes it possible to use general-purpose planning machinery, greatly increasing inferential power.", "startOffset": 111, "endOffset": 163}, {"referenceID": 1, "context": "Treating instruction following as a sequence prediction problem, rather than a series of independent decisions (Branavan et al., 2009; Artzi and Zettlemoyer, 2013), makes it possible to use general-purpose planning machinery, greatly increasing inferential power.", "startOffset": 111, "endOffset": 163}, {"referenceID": 22, "context": "instruction-following benchmarks: the map reading task of Vogel and Jurafsky (2010), the maze navigation task of MacMahon et al.", "startOffset": 58, "endOffset": 84}, {"referenceID": 14, "context": "instruction-following benchmarks: the map reading task of Vogel and Jurafsky (2010), the maze navigation task of MacMahon et al. (2006), and the puzzle solving task of Branavan et al.", "startOffset": 113, "endOffset": 136}, {"referenceID": 4, "context": "(2006), and the puzzle solving task of Branavan et al. (2009). An example from each is shown in Figure 1.", "startOffset": 39, "endOffset": 62}, {"referenceID": 7, "context": "Semantic parsers Parser-based approaches (Chen and Mooney, 2011; Artzi and Zettlemoyer, 2013; Kim and Mooney, 2013; Tellex et al., 2011) map from text into a formal language representing commands.", "startOffset": 41, "endOffset": 136}, {"referenceID": 1, "context": "Semantic parsers Parser-based approaches (Chen and Mooney, 2011; Artzi and Zettlemoyer, 2013; Kim and Mooney, 2013; Tellex et al., 2011) map from text into a formal language representing commands.", "startOffset": 41, "endOffset": 136}, {"referenceID": 12, "context": "Semantic parsers Parser-based approaches (Chen and Mooney, 2011; Artzi and Zettlemoyer, 2013; Kim and Mooney, 2013; Tellex et al., 2011) map from text into a formal language representing commands.", "startOffset": 41, "endOffset": 136}, {"referenceID": 23, "context": "Semantic parsers Parser-based approaches (Chen and Mooney, 2011; Artzi and Zettlemoyer, 2013; Kim and Mooney, 2013; Tellex et al., 2011) map from text into a formal language representing commands.", "startOffset": 41, "endOffset": 136}, {"referenceID": 27, "context": "These take familiar structured prediction models for semantic parsing (Zettlemoyer and Collins, 2005; Wong and Mooney, 2006), and train them with task-provided supervision.", "startOffset": 70, "endOffset": 124}, {"referenceID": 26, "context": "These take familiar structured prediction models for semantic parsing (Zettlemoyer and Collins, 2005; Wong and Mooney, 2006), and train them with task-provided supervision.", "startOffset": 70, "endOffset": 124}, {"referenceID": 14, "context": "(It is possible to think of response-based learning for question answering (Liang et al., 2013) as a special case.", "startOffset": 75, "endOffset": 95}, {"referenceID": 15, "context": "Much of contemporary work in this family is evaluated on the maze navigation task introduced by MacMahon et al. (2006). Dukes (2013) also introduced a \u201cblocks world\u201d task for situated parsing of spatial robot commands.", "startOffset": 96, "endOffset": 119}, {"referenceID": 9, "context": "Dukes (2013) also introduced a \u201cblocks world\u201d task for situated parsing of spatial robot commands.", "startOffset": 0, "endOffset": 13}, {"referenceID": 4, "context": "Linear policy estimators An alternative family of approaches is based on learning a policy over primitive actions directly (Branavan et al., 2009; Vogel and Jurafsky, 2010).", "startOffset": 123, "endOffset": 172}, {"referenceID": 25, "context": "Linear policy estimators An alternative family of approaches is based on learning a policy over primitive actions directly (Branavan et al., 2009; Vogel and Jurafsky, 2010).", "startOffset": 123, "endOffset": 172}, {"referenceID": 24, "context": "This is distinct from semantic parsers in which greedy inference happens to have an interpretation as a policy (Vlachos and Clark, 2014).", "startOffset": 111, "endOffset": 136}, {"referenceID": 4, "context": ", 1991) and gameplay (Branavan et al., 2009).", "startOffset": 21, "endOffset": 44}, {"referenceID": 5, "context": "Indeed, previous work (Branavan et al., 2011; Narasimhan et al., 2015) uses aspects of both to solve a different class of gameplay problems.", "startOffset": 22, "endOffset": 70}, {"referenceID": 18, "context": "Indeed, previous work (Branavan et al., 2011; Narasimhan et al., 2015) uses aspects of both to solve a different class of gameplay problems.", "startOffset": 22, "endOffset": 70}, {"referenceID": 23, "context": "We note that the instruction following model of Tellex et al. (2011) features a similarly named \u201cGeneralized Ground-", "startOffset": 48, "endOffset": 69}, {"referenceID": 10, "context": "Graph-based representations are extremely common in formal semantics (Jones et al., 2012; Reddy et al., 2014), and the version presented here corresponds to a simple generalization of familiar formal methods.", "startOffset": 69, "endOffset": 109}, {"referenceID": 22, "context": "Graph-based representations are extremely common in formal semantics (Jones et al., 2012; Reddy et al., 2014), and the version presented here corresponds to a simple generalization of familiar formal methods.", "startOffset": 69, "endOffset": 109}, {"referenceID": 19, "context": "Indeed, if L is the set of all atomic entities and relations, fV returns a unique label for every v \u2208 V , and fE always returns a vector with one active feature, we recover the existentially-quantified portion of first order logic exactly, and in this form can implement large parts of classical neo-Davidsonian semantics (Parsons, 1990) using grounding graphs.", "startOffset": 322, "endOffset": 337}, {"referenceID": 3, "context": "This aspect of the syntax\u2013semantics interface has been troublesome for some logic-based approaches: while past work has used related machinery for selecting lexicon entries (Berant and Liang, 2014) or for rewriting logical forms (Kwiatkowski et al.", "startOffset": 173, "endOffset": 197}, {"referenceID": 13, "context": "This aspect of the syntax\u2013semantics interface has been troublesome for some logic-based approaches: while past work has used related machinery for selecting lexicon entries (Berant and Liang, 2014) or for rewriting logical forms (Kwiatkowski et al., 2013), the relationship between text and the environment has ultimately been mediated by a discrete (and indeed finite) inventory of predicates.", "startOffset": 229, "endOffset": 255}, {"referenceID": 0, "context": "Several recent papers have investigated simple grounded models with realvalued output spaces (Andreas and Klein, 2014; McMahan and Stone, 2015), but we are unaware of any fully compositional system in recent literature that can incorporate observations of these kinds.", "startOffset": 93, "endOffset": 143}, {"referenceID": 17, "context": "Several recent papers have investigated simple grounded models with realvalued output spaces (Andreas and Klein, 2014; McMahan and Stone, 2015), but we are unaware of any fully compositional system in recent literature that can incorporate observations of these kinds.", "startOffset": 93, "endOffset": 143}, {"referenceID": 6, "context": "In this sense it is analogous to IBM Model I (Brown et al., 1993), with the structured potentials \u03c8(xi, yj) taking the place of lexical translation probabilities.", "startOffset": 45, "endOffset": 65}, {"referenceID": 26, "context": "While alignment models from machine translation have previously been used to align words to fragments of semantic parses (Wong and Mooney, 2006; Pourdamghani et al., 2014), we are unaware of such models being used to align entire instruction sequences to demonstrations.", "startOffset": 121, "endOffset": 171}, {"referenceID": 21, "context": "While alignment models from machine translation have previously been used to align words to fragments of semantic parses (Wong and Mooney, 2006; Pourdamghani et al., 2014), we are unaware of such models being used to align entire instruction sequences to demonstrations.", "startOffset": 121, "endOffset": 171}, {"referenceID": 22, "context": "Related models have previously been used for question answering (Reddy et al., 2014; Pasupat and Liang, 2015).", "startOffset": 64, "endOffset": 109}, {"referenceID": 20, "context": "Related models have previously been used for question answering (Reddy et al., 2014; Pasupat and Liang, 2015).", "startOffset": 64, "endOffset": 109}, {"referenceID": 15, "context": "In our experiments, \u03b8 is optimized using LBFGS (Liu and Nocedal, 1989).", "startOffset": 47, "endOffset": 70}, {"referenceID": 25, "context": "Map reading Our first application is the map navigation task established by Vogel and Jurafsky (2010), based on data collected for a psychological experiment by Anderson et al.", "startOffset": 76, "endOffset": 102}, {"referenceID": 25, "context": "Map reading Our first application is the map navigation task established by Vogel and Jurafsky (2010), based on data collected for a psychological experiment by Anderson et al. (1991) (Figure 1a).", "startOffset": 76, "endOffset": 184}, {"referenceID": 0, "context": "48 Andreas and Klein (2014) 0.", "startOffset": 3, "endOffset": 28}, {"referenceID": 25, "context": "Scores are calculated with respect to transitions between landmarks appearing in the reference path (for details see Vogel and Jurafsky (2010)).", "startOffset": 117, "endOffset": 143}, {"referenceID": 25, "context": "The map task was previously studied by Vogel and Jurafsky (2010), who implemented SARSA with a simple set of features.", "startOffset": 39, "endOffset": 65}, {"referenceID": 16, "context": "Maze navigation The next application we consider is the maze navigation task of MacMahon et al. (2006) (Figure 1b).", "startOffset": 80, "endOffset": 103}, {"referenceID": 8, "context": "2 Chen (2012) 57.", "startOffset": 2, "endOffset": 14}, {"referenceID": 2, "context": "8 Artzi et al. (2014) [semi-supervised] 65.", "startOffset": 2, "endOffset": 22}, {"referenceID": 10, "context": "Recent work by Kim and Mooney (2013) and Artzi et al.", "startOffset": 15, "endOffset": 37}, {"referenceID": 2, "context": "Recent work by Kim and Mooney (2013) and Artzi et al. (2014) has achieved better results; these systems make use of techniques and resources (respectively, discriminative reranking and a seed lexicon of handannotated logical forms) that are largely orthogonal to the ones used here, and might be applied to improve our own results as well.", "startOffset": 41, "endOffset": 61}, {"referenceID": 4, "context": "Puzzle solving The last task we consider is the Crossblock task studied by Branavan et al. (2009) (Figure 1c).", "startOffset": 75, "endOffset": 98}, {"referenceID": 4, "context": "Following Branavan et al. (2009), we average across five random train / test folds.", "startOffset": 10, "endOffset": 33}, {"referenceID": 0, "context": "Compositional semantics The graph alignment model of semantics presented here is an expressive and computationally efficient generalization of classical logical techniques to accommodate environments like the map task, or those explored in our previous work (Andreas and Klein, 2014).", "startOffset": 258, "endOffset": 283}], "year": 2017, "abstractText": "This paper describes an alignment-based model for interpreting natural language instructions in context. We approach instruction following as a search over plans, scoring sequences of actions conditioned on structured observations of text and the environment. By explicitly modeling both the low-level compositional structure of individual actions and the high-level structure of full plans, we are able to learn both grounded representations of sentence meaning and pragmatic constraints on interpretation. To demonstrate the model\u2019s flexibility, we apply it to a diverse set of benchmark tasks. On every task, we outperform strong task-specific baselines, and achieve several new state-of-the-art results.", "creator": "LaTeX with hyperref package"}}}