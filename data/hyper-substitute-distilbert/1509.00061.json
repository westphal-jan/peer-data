{"id": "1509.00061", "review": {"conference": "arxiv", "VERSION": "v1", "DATE_OF_SUBMISSION": "31-Aug-2015", "title": "Value function approximation via low-rank models", "abstract": "now propose a simple value difference approximation technique for markov processing processes. namely consider each parameter then compactly determining the symmetric - decay expectation function toward very low - rank and sparse euclidean model. good choice is to decompose a matrix g encodes particular true value function having low - rank and diagonal components, and we achieve this using robust pattern decomposition search ( pca ). under traditional assumptions, this robust inverse problem can be realized exactly via direct dynamic component pursuit decision optimization problem. we experiment the procedure on finer examples and concludes that our model yields estimates essentially contrary to the true gradient.", "histories": [["v1", "Mon, 31 Aug 2015 20:46:23 GMT  (210kb,D)", "http://arxiv.org/abs/1509.00061v1", "arXiv admin note: substantial text overlap witharXiv:0912.3599by other authors"]], "COMMENTS": "arXiv admin note: substantial text overlap witharXiv:0912.3599by other authors", "reviews": [], "SUBJECTS": "cs.LG cs.AI", "authors": ["hao yi ong"], "accepted": false, "id": "1509.00061"}, "pdf": {"name": "1509.00061.pdf", "metadata": {"source": "CRF", "title": "Value Function Approximation via Low Rank Models", "authors": ["Hao Yi Ong"], "emails": ["haoyi@stanford.edu"], "sections": [{"heading": null, "text": "I. INTRODUCTION\nOne way to solve Markov decision processes (MDPs) is to compute the state-action value function from which the optimal policy can be extracted. The value function can be represented as a matrix where each entry corresponds to the value for a state-action pair. For practical MDPs, data encoding the value function routinely lie in millions or even billions of dimensions. The ability to accurately represent this data on a compact basis would presumably have an impact on a wide area of disciplines that rely on stochastic decision making, including robotics, automated control, economics, and manufacturing. We consider the problem of compactly approximating an MDP state-action value function. To alleviate the curse of dimensionality and scale,1 we must leverage on the fact that the value functions have low intrinsic dimensionality. That is, they lie on some low-dimensional subspace [1], are sparse in some basis [2], or lie on some low-dimensional manifold [3], [4]. The foundation of our approach is similar to that in value function approximation in reinforcement learning (RL). In RL, researchers have employed a wide variety of basis function schemes to approximate value functions, most commonly radial basis functions and CMACs [5]. Implicit in these methods is the assumption that the value functions can be captured accurately by a small set of features; i.e., an intrinsic assumption about low-dimensionality. In our problem, we decompose a data matrix formed by the state-action values as a low-rank part plus a residual, which is not necessarily sparse (as we would like). The data matrix is thus modeled as a superposition of a lowrank component and a sparse component. This is posed as a matrix decomposition problem under the broader framework of Robust Principal Component Analysis (PCA). In general,\n1H. Y. Ong is with the Department of Aeronautics and Astronautics, Stanford University, Stanford, CA 94305, USA haoyi@stanford.edu\n1We refer to either the complexity of algorithms that increases drastically as dimension increases, or to their performance that decreases sharply when scale goes up.\naccurate decomposition of a matrix is impossible; but the knowledge that the matrix has low rank radically changes this premise, making the search for solutions meaningful [6], [7]. As far as the author knows, this is a novel application of Robust PCA to value function approximation. The rest of this paper is organized as follows. Section II introduces the mathematical formulation of our problem, followed by Section III, which presents an approach for Robust PCA. Section IV validates our approach through several numerical experiments, and Section V concludes with a few remarks on future work.\nII. VALUE FUNCTION DECOMPOSITION\nWe begin with a brief review on MDPs followed by an abstract definition of the decomposition problem."}, {"heading": "A. Markov decision process", "text": "In an MDP, an agent chooses action at at time t after observing state st . The agent then receives reward rt , and the state evolves probabilistically based on the current stateaction pair. The explicit assumption that the next state only depends on the current state-action pair is referred to as the Markov assumption. An MDP can be defined by the tuple .S;A;T;R/, where S and A are the sets of all possible states and actions, respectively, T is a probabilistic transition function, and R is a reward function. T gives the probability of transitioning into state s0 from taking action a at the current state s, and is often denoted T .s;a;s0/. R gives a scalar value indicating the immediate reward received for taking action a at the current state s and is denoted R.s;a/. To solve an MDP, we compute a policy ? that, if followed, maximizes the expected sum of immediate rewards from any given state. The optimal policy is related to the optimal state-action value function Q? .s;a/, which is the expected value when starting in state s, taking action a, and then following actions dictated by ?. Mathematically, it obeys the Bellman recursion\nQ? .s;a/DR.s;a/C X s02S T s;a;s0 max a02A Q? s0;a0 :\nThe state-action value function can be computed using a dynamic programming algorithm called value iteration. To obtain the optimal policy for state s, we compute\n? .s/D argmax a2A Q? .s;a/ :\nar X\niv :1\n50 9.\n00 06\n1v 1\n[ cs\n.L G\n] 3\n1 A\nug 2\n01 5"}, {"heading": "B. Matrix decomposition", "text": "Suppose matrixM 2Rm n encodes the state-action values of an MDP, where m and n are the cardinalities of the state and action spaces, respectively. Intuitively, this scheme leverages the correlation between action values close to each other. We approximate M via the decomposition\nM D L0CS0;\nwhere L0 has low-rank and S0 is sparse; here, both components are of arbitrary magnitude. We have no knowledge of the low-dimensional column and row space of L0, or its dimensionality. Similarly, we do not know the locations and number of the nonzero entries of S0. We wish to obtain L0 and S0, a low-rank plus sparse approximation of the true state-action value function. This is achieved via Robust PCA."}, {"heading": "C. Robust PCA", "text": "Classical PCA [1], [8], [9] seeks the best (in an `2 sense) rank-k estimate of L0 by solving\nminimize kM Lk2F subject to rankL k;\n(1)\nwith variable L. Here, k kF denotes the Frobenius norm of a matrix, i.e., the square root of the sum of the squares of the entries. This problem can be efficiently solved via the singular value decomposition (SVD) and enjoys a number of optimality properties when the noise S0 is small and i.i.d. Gaussian. While Robust PCA shares the same problem definition (1) as classical PCA, it does not have the same simplifying assumptions about the noise. Unlike the small noise in classical PCA, the entries in S0 can have arbitrarily large magnitude, and their support is assumed to be sparse but unknown.2"}, {"heading": "III. APPROACH", "text": "This section demonstrates how to cast the matrix decomposition problem as Principal Component Pursuit (PCP) and discusses our choice of algorithm to solve it."}, {"heading": "A. Principal Component Pursuit", "text": "We obtain the value function components through the PCP estimate3\nminimize kLk C kSk1 subject to LCS DM; (2)\nwhich can be solved by tractable convex optimization. Here, k k D P i i . / is the nuclear norm of a matrix; i.e., the sum of its singular values. k k1 denotes the `1-norm of a matrix seen as a long vector in Rmn. Assuming that the low-rank component L0 is not sparse and that the sparsity pattern of the sparse component S0 is selected uniformly at random, the\n2The unknown support of the errors makes the problem more difficult than the matrix completion problem that has recently been much studied [10], [11].\n3Although the name naturally suggests an emphasis on obtaining the low-rank component, we are interested in both the low-rank and sparse components.\nsimple PCP solution perfectly recovers the low-rank and the sparse components [12]. In particular, all that PCP requires about L0 is that its singular vectors are not spiky; i.e., the `1-norm of any singular vector is not too large. To avoid any ambiguity, our model for S0 is this: take an arbitrary matrix S and set to zero its entries on a random set; this gives S0.\nB. Identifiability of low-rank and sparse components\nTo make the problem of matrix decomposition meaningful, we impose that the low-rank component L0 is not sparse. We consider the general notion of incoherence introduced in [13] for the matrix completion problem; this assumption concerns the singular vectors of the low-rank component. We write the singular value decomposition of L0 2 Rm n as\nL0 D U\u02d9V T D rX iD1 iuiv T i ;\nwhere r is the rank of the matrix, 1; : : : ; r are the positive singular values, and U D \u0152u1; : : : ;ur , V D \u0152v1; : : : ;vr are the matrices of the left- and right-singular vectors. The incoherence condition with parameter states that\nmax i U T ei 2 2 r m ; max i V T ei 2 2 r n ; (3)\nand UV T 1 r r mn : (4)\nAbove, we define k k1, i.e., the `1 norm of a matrix seen as a long vector. As discussed in [6], [13], [14], the incoherence condition asserts that for small values of , the singular vectors are not spread out; i.e., not sparse. Another issue is if the sparse matrix has low-rank. This will occur if, say, all the nonzero entries of S occur in a column or in a few columns. Consider the case where the first column of S0 is the opposite of that of L0, and where all the other columns of S0 vanish. Then it is clear that we would not be able to recover L0 and S0 since M DL0CS0 would have a column space equal to or included in that of L0. To avoid such situations, we will assume that the sparsity pattern of the sparse component is selected uniformly at random."}, {"heading": "C. Perfect recovery via PCP", "text": "Surprisingly, the simple PCP solution perfectly recovers the low-rank and sparse components under the minimal assumptions above. Of course, we also require that the rank of the low-rank component is not too large, and that the sparse component is reasonably sparse. Below, n1Dmaxfm;ng and n2 Dminfm;ng.\nTheorem 1. Suppose L0 is m n, obeys (3) and (4), and that the support set of S0 is uniformly distributed among all sets of cardinality z. Then there is a numerical constant c such that with probability at least 1 cn 101 (over the choice of support of S0), Principal Component Pursuit (2)\nwith D 1= p n1 is exact; i.e., LDL0 and S D S0, provided that\nrankL0 rn2 1 .logn1/ 2 and z zmn:\nAbove, r and z are positive numerical constants.\nIn other words, matrices L0 whose principal components are reasonably spread can be recovered with probability nearly one from arbitrary and completely unknown corruption patterns as long as these are randomly distributed. In fact, this works for large values of the rank; i.e., on the order of n2=.logn1/2 when is not too large. Another remarkable property is that there is no tuning parameter in this algorithm. Under the assumption of Theorem 1, minimizing\nkLk C 1p\nmaxfm;ng kSk1\nalways returns the correct answer; i.e., in Eq. (2) choose\nD 1p\nmaxfm;ng :\nIn fact, the proof of the theorem in [12] gives a whole range of correct values, and this is a sufficiently simple value in that range."}, {"heading": "D. Algorithm", "text": "For small problem sizes, say maxfm;ng < 100, PCP can be performed using off-the-shelf tools such as interior point methods [15]. This was suggested for low-rank and sparse decomposition in [14]. However, despite their superior convergence rates, interior point methods are limited by the O m6 complexity of computing a step direction. More sophisticated methods with better complexity and convergence rates include iterative thresholding methods using continuation techniques [16], [17], Bregman iterations [18], and Nesterov\u2019s optimal first-order algorithm for smooth and nonsmooth minimization [19]\u2013[21]. An Accelerated Proximal Gradient (APG) algorithm was suggested for low-rank and sparse decomposition in [22]. APG inherits the optimal O 1=k2 convergence rate for this class of problems, and empirical evidence suggests that it can solve the convex PCP problem at least 50 times faster than straightforward iterative thresholding. Despite its good convergence guarantees, however, the practical performance of APG does not show good accuracy and convergence across a wide variety of problem settings [23]. In this paper, we choose to instead solve the convex PCP problem Eq. (1) using an augmented Lagrange multiplier (ALM) algorithm introduced in [23], [24]. [12] reports that ALM achieves much higher accuracy than APG, in fewer iterations, and that it works stably across a wide range of problem settings with no parameter tuning. The ALM method operates on the augmented Lagrangian\nL.L;S;Y /D kLk C kSk1ChY;M L Si\nC 2 kM L Sk2F ;\nwhere h i denotes the standard trace inner product. A generic Lagrange multiplier algorithm would solve PCP by iteratively computing L.k/;S .k/\nWD argminL;S L L;S;Y .k/ ,\nand then updating the Lagrange multiplier matrix via Y .kC1/ WD Y .k/C M L.k/ S .k/ [25].\nFor our decomposition problem, we avoid solving a sequence of convex programs by recognizing that minLL.L;S;Y / and minS L.L;S;Y / both have very simple and efficient solutions [12]. Let S W R ! R denote the shrinkage operator S x D sign.x/max.jxj ;0/, and extend it to matrices by applying it to each element. It can be shown that\nargmin S L.L;S;Y /D S 1 M LC 1Y :\nSimilarly, for matrices X, let D .X/ denote the singular value thresholding operator given by D .X/DUS .\u02d9/V T , where X D U\u02d9V T is any SVD. Again, we can show that\nargmin L L.L;S;Y /DD 1 M SC 1Y :\nThus, a more efficient strategy is to first minimize L with respect to L (fixing S ), minimize L with respect to S (fixing L), and then finally update the Lagrange multipler matrix Y based on the residual M L S . Algorithm 1 summarizes this strategy. We choose D mn=4kMk1, as suggested in [24], and terminate the algorithm when kM L SkF \u0131 kMkF , with \u0131 D 10 5.\nAlgorithm 1 PCP by Alternating Directions [23], [24] 1: initialize: S0 D Y0 D 0, > 0 2: while not converged do 3: L.kC1/ WDD 1 M S .k/C 1Y .k/\n4: S .kC1/ WD S 1 M L.kC1/C 1Y .k/ 5: Y .kC1/ WD Y .k/C M L.kC1/ S .kC1/\n6: output: L, S"}, {"heading": "IV. NUMERICAL EXPERIMENTS", "text": "To validate our approach, we apply it on two classical stochastic problems: the mountain car and inverted pendulum. The performance of our low-rank plus sparse models is evaluated against the true state-action value functions."}, {"heading": "A. Mountain car", "text": "Following the problem definition in [5], the car starts from the position-velocity pair .x; Px/ and follows the dynamics\nPx WD PxC0:001a 0:0025cos.3x/ x WD xC Px;\nwhere a 2 \u0152 1;1 is the acceleration input. The car can take on the state values .x; Px/ 2 \u0152 0:07;0:07 \u0152 1:2;0:6 . To incentivize getting to the top of the mountain at x0 D 0:5, the reward function is defined\nR.x/D 10; x x0 1; otherwise:\nB. Inverted pendulum\nIn this problem, we are interested in balancing an inverted pendulum in its unsteady upright equilibrium position. The system is described by the angle-angular speed tuple ; P ,\nand its dynamics are\nWD C P dt\nP WD P C sin P C dt;\nwhere dt D 0:3 is the time period between decisions and 2 \u0152 1;1 is the torque input. The state space is . ; \u0152 10;10 . The reward function penalizes control effort while favoring an upright pendulum angular position at 0\u0131:\nR.s;a/D exp.cos 1/ 0:1a2:"}, {"heading": "C. Discretization", "text": "The two test problems are continuous MDPs. To solve them via value iteration, their state and action spaces are discretized into fine grids, and their transitions are modeled using the multilinear interpolation [26]\nT s;a;s0 D P rob s0 j s;a\nD X s0c P rob s0 j s0c P rob s0c j s;a ;\nwhere s0c is the continuous state evolved from taking action a at state s. Here, P rob\ns0 j s0c is specified using multilinear\ninterpolation, and P rob s0c j s;a is the problem dynamics. In our problems, s0c is deterministically computed from the state-action pair .s;a/, so T reduces to\nT s;a;s0 D P rob s0 j s0c :\nThe discretization scheme is summarized in Table I.\nWith this scheme, we can extract the low-rank plus sparse policy for some continuous state sc via\nO .sc/D argmax a2A X s P rob .s j sc/ OQ.s;a/ :\nEvaluating OQ.s;a/ involves finding the action corresponding to the column with the maximum value in the row corresponding to state s in the matrixM DLCS . The lookup can be done efficiently in real-time by taking the relevant matrixvector product for the singular vectors and values encoding L and adding that to the appropriate sparse row in S ."}, {"heading": "D. Evaluation criteria", "text": "To evaluate our controllers, we run 1,000,000 simulations on both MDPs and compare the performance of the optimal and low-rank plus sparse model policies.\n1) Mountain car: The evaluation metric for the controllers is how long it takes to reach the mountain top given a randomly and uniformly generated initial configuration.\n2) Inverted pendulum: The metric for the inverted pendulum controllers is how well the controller can keep the pendulum in the upright position. This metric is captured by the average Euclidean distance between the pendulum angular position and the upright position. The initial states are drawn uniformly at random from the state-space.\nE. Implementation\nAll computation was carried out on a system with a dualcore Intel i7 processor, with clock speed 2.7 GHz and 8 GB of RAM, running Mac OS X. The ALM algorithm was implemented by the authors of [22] on a single thread in MATLAB and C, which interacted with MATLAB through a MEX interface [27]. The value iteration algorithm and simulation program were implemented in Julia [28]. All code can be found together with documentation integrated onto a Jupyter notebook at\nhttps://github.com/haoyio/LowRankMDP."}, {"heading": "F. Results", "text": "Table II summarizes the results based on the evaluation criteria described above. Note that sparsity is defined as the fraction of zero elements over the total number of elements in the sparse component S . The results suggest that there is little if any difference between the optimal policy and the one produced by the low-rank and sparse model\u2014they achieve virtually the same level of performance as their optimal counterparts. This is despite the low-rank models requiring less than 2% and 13% of the number of entries in the original matrices for the mountain car and inverted pendulum problems, respectively.\nFigure 1 shows the policy heat maps for the mountain car and inverted pendulum MDPs. The color of any cell indicates the numerical value of the best control input given the state. There is a slight difference between the mountain car policy heat maps on the top left and right corners of the insets. On the other hand, visual inspection reveals little to no difference between the inverted pendulum policy heat maps. Intuitively, this comparison demonstrates why the\nperformance of the low-rank model was essentially identical to that of the original."}, {"heading": "V. CONCLUSION AND FUTURE WORK", "text": "We have demonstrated a novel value function approximation technique that exploits the intrinsic low dimensionality of MDPs. State-action value functions of simple continuous MDPs can be approximated virtually to perfection with far fewer memory requirements. It remains to experiment with a wider variety of MDPs to determine if the approach generalizes well. In the vein of applying Robust PCA to MDPs, an interesting research direction will be to frame reinforcement learning as a sequential noisy matrix completion problem."}], "references": [{"title": "The approximation of one matrix by another of low rank", "author": ["C. Eckart", "G. Young"], "venue": "Psychometrika, vol. 1, no. 3, pp. 211\u2013218, 1936.", "citeRegEx": "1", "shortCiteRegEx": null, "year": 1936}, {"title": "Atomic decomposition by basis pursuit", "author": ["S.S. Chen", "D.L. Donoho", "M.A. Saunders"], "venue": "SIAM Journal on Scientific Computing, vol. 20, no. 1, pp. 33\u201361, 1998.", "citeRegEx": "2", "shortCiteRegEx": null, "year": 1998}, {"title": "Laplacian eigenmaps for dimensionality reduction and data representation", "author": ["M. Belkin", "P. Niyogi"], "venue": "Neural Computation, vol. 15, no. 6, pp. 1373\u20131396, 2003.", "citeRegEx": "3", "shortCiteRegEx": null, "year": 2003}, {"title": "A global geometric framework for nonlinear dimensionality reduction", "author": ["J.B. Tenenbaum", "V. De Silva", "J.C. Langford"], "venue": "Science, vol. 290, no. 5500, pp. 2319\u2013 2323, 2000.", "citeRegEx": "4", "shortCiteRegEx": null, "year": 2000}, {"title": "Reinforcement Learning: An Introduction", "author": ["R.S. Sutton", "A.G. Barto"], "venue": null, "citeRegEx": "5", "shortCiteRegEx": "5", "year": 1998}, {"title": "The power of convex relaxation: Near-optimal matrix completion", "author": ["E.J. Candes", "T. Tao"], "venue": "IEEE Transactions on Information Theory, vol. 56, no. 5, pp. 2053\u20132080, 2010.", "citeRegEx": "6", "shortCiteRegEx": null, "year": 2010}, {"title": "Matrix completion with noise", "author": ["E.J. Candes", "Y. Plan"], "venue": "Proceedings of the IEEE, vol. 98, no. 6, pp. 925\u2013936, 2010.", "citeRegEx": "7", "shortCiteRegEx": null, "year": 2010}, {"title": "Analysis of a complex of statistical variables into principal components", "author": ["H. Hotelling"], "venue": "Journal of Educational Psychology, vol. 24, no. 6, pp. 417\u2013441, 1933.", "citeRegEx": "8", "shortCiteRegEx": null, "year": 1933}, {"title": "Matrix completion from a few entries", "author": ["R.H. Keshavan", "A. Montanari", "S. Oh"], "venue": "IEEE Transactions on Information Theory, vol. 56, no. 6, pp. 2980\u20132998, 2010.", "citeRegEx": "10", "shortCiteRegEx": null, "year": 2010}, {"title": "A simpler approach to matrix completion", "author": ["B. Recht"], "venue": "The Journal of Machine Learning Research, vol. 12, pp. 3413\u20133430, 2011.", "citeRegEx": "11", "shortCiteRegEx": null, "year": 2011}, {"title": "Robust principal component analysis?", "author": ["E.J. Candes", "X. Li", "Y. Ma", "J. Wright"], "venue": "Journal of the Association for Computing Machinery,", "citeRegEx": "12", "shortCiteRegEx": "12", "year": 2011}, {"title": "Exact matrix completion via convex optimization", "author": ["E.J. Candes", "B. Recht"], "venue": "Foundations of Computational Mathematics, vol. 9, no. 6, pp. 717\u2013772, 2009.", "citeRegEx": "13", "shortCiteRegEx": null, "year": 2009}, {"title": "Rank-sparsity incoherence for matrix decomposition", "author": ["V. Chandrasekaran", "S. Sanghavi", "P.A. Parrilo", "A.S. Willsky"], "venue": "SIAM Journal on Optimization, vol. 21, no. 2, pp. 572\u2013596, 2011.", "citeRegEx": "14", "shortCiteRegEx": null, "year": 2011}, {"title": "Cvx: Matlab software for disciplined convex programming, version 2.1, http: //cvxr.com/cvx", "author": ["M. Grant", "S. Boyd"], "venue": null, "citeRegEx": "15", "shortCiteRegEx": "15", "year": 2014}, {"title": "Convergence of fixed-point continuation algorithms for matrix rank minimization", "author": ["D. Goldfarb", "S. Ma"], "venue": "Foundations of Computational Mathematics, vol. 11, no. 2, pp. 183\u2013210, 2011.", "citeRegEx": "16", "shortCiteRegEx": null, "year": 2011}, {"title": "Fixed point and bregman iterative methods for matrix rank minimization", "author": ["S. Ma", "D. Goldfarb", "L. Chen"], "venue": "Mathematical Programming, vol. 128, no. 1-2, pp. 321\u2013353, 2011.", "citeRegEx": "17", "shortCiteRegEx": null, "year": 2011}, {"title": "An iterative regularization method for total variationbased image restoration", "author": ["S. Osher", "M. Burger", "D. Goldfarb", "J. Xu", "W. Yin"], "venue": "SIAM Multisale Modeling & Simulation, vol. 4, no. 1, pp. 460\u2013489, 2005.", "citeRegEx": "18", "shortCiteRegEx": null, "year": 2005}, {"title": "A fast iterative shrinkagethresholding algorithm for linear inverse problems", "author": ["A. Beck", "M. Teboulle"], "venue": "SIAM Journal on Imaging Sciences, vol. 2, no. 1, pp. 183\u2013202, 2009.", "citeRegEx": "19", "shortCiteRegEx": null, "year": 2009}, {"title": "A method of solving a convex programming problem with convergence rate O 1=k", "author": ["Y Nesterov"], "venue": "So-  viet Mathematics Doklady, vol. 27, no. 2, pp. 372\u2013376, 1983.", "citeRegEx": "20", "shortCiteRegEx": null, "year": 1983}, {"title": "Smooth minimization of non-smooth functions", "author": ["\u2014\u2014"], "venue": "Mathematical Programming, vol. 103, no. 1, 2005.", "citeRegEx": "21", "shortCiteRegEx": null, "year": 2005}, {"title": "Fast convex optimization algorithms for exact recovery of a corrupted low-rank matrix", "author": ["Z. Lin", "A. Ganesh", "J. Wright", "L. Wu", "M. Chen", "Y. Ma"], "venue": "Computational Advances in Multi-Sensor Adaptive Processing, vol. 61, 2009.", "citeRegEx": "22", "shortCiteRegEx": null, "year": 2009}, {"title": "The augmented lagrange multiplier method for exact recovery of corrupted lowrank matrices", "author": ["Z. Lin", "M. Chen", "Y. Ma"], "venue": "ArXiv preprint arXiv:1009.5055, 2010.", "citeRegEx": "23", "shortCiteRegEx": null, "year": 2010}, {"title": "Sparse and low-rank matrix decomposition via alternating direction methods", "author": ["X. Yuan", "J. Yang"], "venue": "Preprint, 2009.", "citeRegEx": "24", "shortCiteRegEx": null, "year": 2009}, {"title": "Constrained Optimization and Lagrange Multiplier Method", "author": ["D.P. Bertsekas"], "venue": null, "citeRegEx": "25", "shortCiteRegEx": "25", "year": 2014}, {"title": "Unscented filtering and nonlinear estimation", "author": ["S.J. Julier", "J.K. Uhlmann"], "venue": "Proceedings of the IEEE, vol. 92, no. 3, pp. 401\u2013422, 2004.", "citeRegEx": "26", "shortCiteRegEx": null, "year": 2004}, {"title": "Julia: A fast dynamic language for technical computing", "author": ["J. Bezanson", "S. Karpinski", "V.B. Shah", "A. Edelman"], "venue": "ArXiv preprint arXiv:1209.5145, 2012.", "citeRegEx": "28", "shortCiteRegEx": null, "year": 2012}], "referenceMentions": [{"referenceID": 0, "context": "That is, they lie on some low-dimensional subspace [1], are sparse in some basis [2], or lie on some low-dimensional manifold [3], [4].", "startOffset": 51, "endOffset": 54}, {"referenceID": 1, "context": "That is, they lie on some low-dimensional subspace [1], are sparse in some basis [2], or lie on some low-dimensional manifold [3], [4].", "startOffset": 81, "endOffset": 84}, {"referenceID": 2, "context": "That is, they lie on some low-dimensional subspace [1], are sparse in some basis [2], or lie on some low-dimensional manifold [3], [4].", "startOffset": 126, "endOffset": 129}, {"referenceID": 3, "context": "That is, they lie on some low-dimensional subspace [1], are sparse in some basis [2], or lie on some low-dimensional manifold [3], [4].", "startOffset": 131, "endOffset": 134}, {"referenceID": 4, "context": "In RL, researchers have employed a wide variety of basis function schemes to approximate value functions, most commonly radial basis functions and CMACs [5].", "startOffset": 153, "endOffset": 156}, {"referenceID": 5, "context": "accurate decomposition of a matrix is impossible; but the knowledge that the matrix has low rank radically changes this premise, making the search for solutions meaningful [6], [7].", "startOffset": 172, "endOffset": 175}, {"referenceID": 6, "context": "accurate decomposition of a matrix is impossible; but the knowledge that the matrix has low rank radically changes this premise, making the search for solutions meaningful [6], [7].", "startOffset": 177, "endOffset": 180}, {"referenceID": 0, "context": "Robust PCA Classical PCA [1], [8], [9] seeks the best (in an `2 sense) rank-k estimate of L0 by solving", "startOffset": 25, "endOffset": 28}, {"referenceID": 7, "context": "Robust PCA Classical PCA [1], [8], [9] seeks the best (in an `2 sense) rank-k estimate of L0 by solving", "startOffset": 30, "endOffset": 33}, {"referenceID": 8, "context": "2The unknown support of the errors makes the problem more difficult than the matrix completion problem that has recently been much studied [10], [11].", "startOffset": 139, "endOffset": 143}, {"referenceID": 9, "context": "2The unknown support of the errors makes the problem more difficult than the matrix completion problem that has recently been much studied [10], [11].", "startOffset": 145, "endOffset": 149}, {"referenceID": 10, "context": "simple PCP solution perfectly recovers the low-rank and the sparse components [12].", "startOffset": 78, "endOffset": 82}, {"referenceID": 11, "context": "We consider the general notion of incoherence introduced in [13] for the matrix completion problem; this assumption concerns the singular vectors of the low-rank component.", "startOffset": 60, "endOffset": 64}, {"referenceID": 5, "context": "As discussed in [6], [13], [14], the incoherence condition asserts that for small values of , the singular vectors are not spread out; i.", "startOffset": 16, "endOffset": 19}, {"referenceID": 11, "context": "As discussed in [6], [13], [14], the incoherence condition asserts that for small values of , the singular vectors are not spread out; i.", "startOffset": 21, "endOffset": 25}, {"referenceID": 12, "context": "As discussed in [6], [13], [14], the incoherence condition asserts that for small values of , the singular vectors are not spread out; i.", "startOffset": 27, "endOffset": 31}, {"referenceID": 10, "context": "In fact, the proof of the theorem in [12] gives a whole range of correct values, and this is a sufficiently simple value in that range.", "startOffset": 37, "endOffset": 41}, {"referenceID": 13, "context": "Algorithm For small problem sizes, say maxfm;ng < 100, PCP can be performed using off-the-shelf tools such as interior point methods [15].", "startOffset": 133, "endOffset": 137}, {"referenceID": 12, "context": "This was suggested for low-rank and sparse decomposition in [14].", "startOffset": 60, "endOffset": 64}, {"referenceID": 14, "context": "More sophisticated methods with better complexity and convergence rates include iterative thresholding methods using continuation techniques [16], [17], Bregman iterations [18], and Nesterov\u2019s optimal first-order algorithm for smooth and nonsmooth minimization [19]\u2013[21].", "startOffset": 141, "endOffset": 145}, {"referenceID": 15, "context": "More sophisticated methods with better complexity and convergence rates include iterative thresholding methods using continuation techniques [16], [17], Bregman iterations [18], and Nesterov\u2019s optimal first-order algorithm for smooth and nonsmooth minimization [19]\u2013[21].", "startOffset": 147, "endOffset": 151}, {"referenceID": 16, "context": "More sophisticated methods with better complexity and convergence rates include iterative thresholding methods using continuation techniques [16], [17], Bregman iterations [18], and Nesterov\u2019s optimal first-order algorithm for smooth and nonsmooth minimization [19]\u2013[21].", "startOffset": 172, "endOffset": 176}, {"referenceID": 17, "context": "More sophisticated methods with better complexity and convergence rates include iterative thresholding methods using continuation techniques [16], [17], Bregman iterations [18], and Nesterov\u2019s optimal first-order algorithm for smooth and nonsmooth minimization [19]\u2013[21].", "startOffset": 261, "endOffset": 265}, {"referenceID": 19, "context": "More sophisticated methods with better complexity and convergence rates include iterative thresholding methods using continuation techniques [16], [17], Bregman iterations [18], and Nesterov\u2019s optimal first-order algorithm for smooth and nonsmooth minimization [19]\u2013[21].", "startOffset": 266, "endOffset": 270}, {"referenceID": 20, "context": "An Accelerated Proximal Gradient (APG) algorithm was suggested for low-rank and sparse decomposition in [22].", "startOffset": 104, "endOffset": 108}, {"referenceID": 21, "context": "Despite its good convergence guarantees, however, the practical performance of APG does not show good accuracy and convergence across a wide variety of problem settings [23].", "startOffset": 169, "endOffset": 173}, {"referenceID": 21, "context": "(1) using an augmented Lagrange multiplier (ALM) algorithm introduced in [23], [24].", "startOffset": 73, "endOffset": 77}, {"referenceID": 22, "context": "(1) using an augmented Lagrange multiplier (ALM) algorithm introduced in [23], [24].", "startOffset": 79, "endOffset": 83}, {"referenceID": 10, "context": "[12] reports that ALM achieves much higher accuracy than APG, in fewer iterations, and that it works stably across a wide range of problem settings with no parameter tuning.", "startOffset": 0, "endOffset": 4}, {"referenceID": 23, "context": "k/ [25].", "startOffset": 3, "endOffset": 7}, {"referenceID": 10, "context": "L;S;Y / both have very simple and efficient solutions [12].", "startOffset": 54, "endOffset": 58}, {"referenceID": 22, "context": "We choose D mn=4kMk1, as suggested in [24], and terminate the algorithm when kM L SkF \u0131 kMkF , with \u0131 D 10 .", "startOffset": 38, "endOffset": 42}, {"referenceID": 21, "context": "Algorithm 1 PCP by Alternating Directions [23], [24] 1: initialize: S0 D Y0 D 0, > 0 2: while not converged do 3: L WDD 1 M S C Y .", "startOffset": 42, "endOffset": 46}, {"referenceID": 22, "context": "Algorithm 1 PCP by Alternating Directions [23], [24] 1: initialize: S0 D Y0 D 0, > 0 2: while not converged do 3: L WDD 1 M S C Y .", "startOffset": 48, "endOffset": 52}, {"referenceID": 4, "context": "Following the problem definition in [5], the car starts from the position-velocity pair .", "startOffset": 36, "endOffset": 39}, {"referenceID": 24, "context": "To solve them via value iteration, their state and action spaces are discretized into fine grids, and their transitions are modeled using the multilinear interpolation [26]", "startOffset": 168, "endOffset": 172}, {"referenceID": 20, "context": "The ALM algorithm was implemented by the authors of [22] on a single thread in MATLAB and C, which interacted with MATLAB through a MEX interface [27].", "startOffset": 52, "endOffset": 56}, {"referenceID": 25, "context": "The value iteration algorithm and simulation program were implemented in Julia [28].", "startOffset": 79, "endOffset": 83}], "year": 2015, "abstractText": "We propose a novel value function approximation technique for Markov decision processes. We consider the problem of compactly representing the state-action value function using a low-rank and sparse matrix model. The problem is to decompose a matrix that encodes the true value function into low-rank and sparse components, and we achieve this using Robust Principal Component Analysis (PCA). Under minimal assumptions, this Robust PCA problem can be solved exactly via the Principal Component Pursuit convex optimization problem. We experiment the procedure on several examples and demonstrate that our method yields approximations essentially identical to the true function.", "creator": "LaTeX with hyperref package"}}}