{"id": "1509.02459", "review": {"conference": "arxiv", "VERSION": "v1", "DATE_OF_SUBMISSION": "8-Sep-2015", "title": "Evolving TSP heuristics using Multi Expression Programming", "abstract": "progressive expression programming ( ict ) is an evolutionary technique : works also considered currently answering computationally computational problems. interaction demands a chosen solution representation. each user individual is colored string encoding complex expressions ( computer arrays ). once linear individual may encode ambiguous solutions implementing the current process. in published paper mep is used for evolving a closed likelihood problem ( tsp ) heuristic for so named triangle inequality. like mep heuristic, compared comparing strong neighbor constraint ( nn ) and minimum hash tree heuristic ( nj ) given some difficult problems in tsplib. for most of epsilon ii and hc evolved complexity heuristic computed nn from nr. the common form was matched by programming problems forming tsplib. the results emphasizes that evolved programming techniques is a proven tool worth solving difficult application concerns.", "histories": [["v1", "Tue, 8 Sep 2015 17:37:01 GMT  (73kb)", "http://arxiv.org/abs/1509.02459v1", "International Conference on Computational Sciences, ICCS'04, 6-9 June, Krakow, Poland, Edited by M. Bubak, G.van Albada, P. Sloot, and J. Dongarra, Vol II, pp. 670-673, Springer-Verlag, Berlin, 2004. Source code available for download at:this http URL"]], "COMMENTS": "International Conference on Computational Sciences, ICCS'04, 6-9 June, Krakow, Poland, Edited by M. Bubak, G.van Albada, P. Sloot, and J. Dongarra, Vol II, pp. 670-673, Springer-Verlag, Berlin, 2004. Source code available for download at:this http URL", "reviews": [], "SUBJECTS": "cs.AI cs.NE", "authors": ["mihai oltean", "d dumitrescu"], "accepted": false, "id": "1509.02459"}, "pdf": {"name": "1509.02459.pdf", "metadata": {"source": "CRF", "title": "Evolving TSP heuristics using Multi Expression Programming", "authors": ["Mihai Oltean", "D. Dumitrescu"], "emails": ["ddumitr}@nessie.cs.ubbcluj.ro"], "sections": [{"heading": "1. Introduction", "text": "In [12, 13, 14] a new evolutionary paradigm called Multi Expression Programming (MEP)1 has been proposed. MEP may be considered as an alternative to standard Genetic Programming technique [8]. MEP uses a linear solution representation. Each MEP individual is a string encoding complex expressions (computer programs). A MEP individual may encode multiple solutions of the current problem. Usually the best solution is chosen for fitness assignment purposes.\nOne of the most important applications of MEP is discovering heuristics for solving computationally difficult (mainly NP\u2013Complete) problems. Instead of searching the solution of a particular problem the MEP aim is to discover a heuristic that solves the entire class of instances for a given problem.\nIn this paper MEP technique is used for discovering TSP heuristics for graphs satisfying triangle inequality (TI graphs). This option was chosen due to the existence of a big number of real-world applications implying TI graphs (e.g. plains, trains and vehicles routes). MEP technique is used to learn a path function f that is used for evaluating the reachable nodes. This function serves as a heuristic for detecting the optimum path.\nIn the proposed approach the TSP path starts with a randomly selected node of the graph. Each node reachable from the current node in one step is evaluated using the function (computer program) f evolved by MEP algorithm. The best\n1 MEP source code is available at the address www.mep.cs.ubbcluj.ro.\nnode is added to the already detected path. The algorithm stops when the path contains all graph nodes.\nMEP learning process for TSP has a remarkable quality: the evolved (learned) heuristic works very well for data sets much larger than the training set. For MEP training stage graphs having 3 to 50 nodes are considered. Evolved MEP function was tested and performs well for graphs having maximum 1000 nodes.\nEvolved function f is compared with some well known heuristics. Numerical experiments emphasize that (for considered examples) MEP function outperforms dedicated heuristics."}, {"heading": "2. MEP Technique", "text": "MEP uses a linear solution representation and a special phenotypic transcription model. A MEP chromosome usually encodes several expressions (computer programs). The ability of MEP chromosome to encode several syntactically correct expressions is called strong implicit parallelism."}, {"heading": "2.1. MEP Algorithm", "text": "Standard MEP algorithm starts with a randomly generated population of individuals.\nA fixed number of the high fit individuals enter in the next generation (elitism). The mating pool is filled using binary tournament selection. Individuals from mating pool are randomly paired and recombined. By recombination of two parents two offspring are obtained. The offspring are mutated and enter the next generation."}, {"heading": "2.2. MEP Representation", "text": "MEP genes are substrings of variable length. Number of genes in a chromosome is constant and it represents chromosome length. Each gene encodes a terminal or a function symbol. A gene encoding a function includes pointers towards genes containing the function arguments. Function parameters always have indices of lower values than the position of that function symbol itself in chromosome.\nProposed representation ensures no cycle arises when the chromosome is decoded (phenotypically transcripted). According to the proposed representation scheme the first symbol of the chromosome must be a terminal symbol. In this way only syntactically correct programs are generated by MEP technique. Let T = {a, b, c, d} be the set of terminal symbols and F = {+, *} be the set of function symbols. Consider as an example the MEP chromosome C given below: 1: a 2: b 3: + 1, 2 4: c 5: d 6: * 4, 5\nRemark: Numbers on the left positions stand for gene labels or addresses. Actually labels do not belong to the chromosome, but they are provided for explanation purposes only."}, {"heading": "2.3. MEP phenotypic transcription", "text": "MEP chromosomes are read downstream starting with the first position. A terminal symbol specifies a simple expression. A function symbol specifies a complex expression (formed by connecting the operands specified by the argument positions with the current function symbol).\nConsider the chromosome C specified above (section 2.2). Chromosome C is not able to encode a unique expression that involves all of the genes. But C encodes the expressions:\nE1 = a, E2 = b, E3 = a + b, E4 = c, E5 = d, E6 = c + d.\nEach MEP chromosome is allowed to encode a number of expressions equal to the chromosome length (number of genes). Expression associated to each chromosome position is obtained by interpreting the respective gene."}, {"heading": "2.4. Selection and search operators", "text": "Within MEP technique binary tournament [Goldberg] selection is used. Search operators are recombination and mutation. These possible operators are defined to preserve the chromosome structure. All offspring describe syntactically correct expressions."}, {"heading": "2.4.1. Recombination", "text": "Three variants of recombination operator have been considered and tested within our MEP implementation: one\u2013point crossover, two\u2013point crossover and uniform crossover. These operators are simple versions of standard binary crossover operators (see [4], [6]). Two\u2013point crossover seems to work best with MEP ([12]) and it will be used in all experiments considered in this paper."}, {"heading": "2.4.2. Mutation", "text": "Mutation operator may be applied to each chromosome gene. A mutation probability (pm) is considered when applying mutation operator.\nBy mutation some symbols in chromosome are changed. To preserve the chromosome structure its first gene must encode, also after mutation, a terminal symbol. For other genes there is no restriction in symbols changing.\nIf the gene selected for mutation encodes a terminal symbol, this symbol may be changed into another terminal symbol or into a function symbol. In the last case the positions (addresses) indicating the function arguments are randomly generated.\nIf the mutating gene encodes a function, then the gene may be mutated into a terminal symbol or into another function (i.e. function symbol and pointers towards arguments)."}, {"heading": "3. TSP problem with triangle inequality", "text": "TSP problem for TI graphs (i.e. satisfying triangle inequality) is stated as follows. Consider a set C = {c0, c1,\u2026, cN\u20131} of cities, and a distance d(ci, cj) \u2208 Z+ for each pair ci, cj \u2208 C, d(ci, cj) = d(cj, ci), and for each three cities ci, cj, ck \u2208 C, d(ci, cj) \u2264 d(ci, ck) + d(ck, cj). The tour <c\u03c0(0), c\u03c0(1), \u2026, c\u03c0(N\u20131)> of all cities in C having minimum length is needed ([1], [3])\nTSP problem with triangle inequality is an NP\u2013complete problem [7]. No polynomial time algorithm for solving TSP problem is known. Several heuristics for solving TSP problem have been proposed. The most important are Nearest Neighbor ([3], [7]) and the Minimum Spanning Tree ([3])."}, {"heading": "4. Evolving Heuristics for TSP", "text": "In this section we address the problem of discovering heuristics that can solve TSP rather than solving a particular instance of the problem.\nMEP technique is used for evolving a path function f that gives a way to choose graph vertices in order to obtain a Hamiltonian cycle. The fitness is assigned to a function f in the current population by applying f on several randomly chosen graphs (training set) and evaluating the results.\nEvolved path function may be used for solving particular instances of TSP. For each problem the graph nodes are evaluated using the path function f and are added one by one to the already build path.\nThe algorithm for TSP using evolved path function f may be described as follows:\nS1. Let c\u03c0(0) = c0 {the path starts with the node c0} S2. k = 1; S3. while k < N \u2013 1 do S4. Using function f select c\u03c0(k+1) \u2013 the next node of the path S5. Add c\u03c0(k+1) to the already built path. S6. k = k + 1; S7. endwhile\nS4 is the key step of this algorithm. The procedure that selects the next node of the path in an optimal way uses the function f evolved by the MEP technique as described in sections 4.1 and 4.2."}, {"heading": "4.1. Terminal and Function Symbols for Evolving Heuristic Function f", "text": "Path function f has to use (as input) some information about already build path and some information about unvisited nodes.\nA natural way for defining the set of terminals is to consider the terminals as representing the distances between nodes. Therefore we have: T = {di j, | 0 \u2264 i \u2264 N \u2013 1, 0 \u2264 j \u2264 N \u2013 1}.\nBut this approach leads to some difficulties when applied for graphs having different number of nodes. To avoid this difficulty, we consider a special terminal set which is independent with respect to the number of graph nodes.\nLet us denote by y1 the last visited node (current node). We have to select the next node to be added to the path. In this respect all unvisited nodes are considered. Let us denote by y2 the next node to be visited.\nFor evolving path function f we consider a set T of terminals involving the following elements: (i) d_y1_y2 \u2013 distance between the graph nodes y1 and y2, (ii) min_g_y1 (min_g_y2) \u2013 the minimum distance from the nodes y1 (y2) to\nunvisited nodes, (iii) sum_g_y1 (sum_g_y2) \u2013 the sum of all distances between nodes y1 (y2) and\nunvisited nodes, (iv) prod_g_y1 (prod_g_y2) \u2013 the product of all distances between nodes y1 (y2)\nand unvisited nodes, (v) max_g_y1 (max_g_y2) \u2013 the maximum distance from the nodes y1 (y2) to\nunvisited nodes, (vi) length \u2013 the length of the already built path.\nThe set T of terminals (function variables) is thus:\nT = {d_y1_y2, min_g_y1, min_g_y2, max_g_y1, max_g_y2, sum_g_y1, sum_g_y2, prod_g_y1, prod_g_y2, length}.\nLet us remark that members of T are not actual terminals (in the standard acceptation). For this reason we may call members of T as instantiated (or intermediate) nonterminals.\nSet T of terminals is chosen in such way to be independent of the number of graph nodes. This choice confers flexibility and robustness to the evolved heuristic.\nFor evolving a MEP function for TSP problem we may consider the following set of function symbols: F = {+, \u2013, /, *, cos, sin, min, max}.\nThe node y2 that generates the lowest output of evolved function f is chosen to be the next node of the path. Ties are solved arbitrarily. For instance we may consider the node with the lowest index is selected.\nExample Consider the MEP linear structure: 1: d_y1_y2 2: min_g_y1 3: + 1, 2 4: sum_g_y2 5: * 2, 4 This MEP individual encodes the path functions f1, f2, f3, f4, f5 given by: f1 = d_y1_y2 , f2 = min_g_y1 , f3 = d_y1_y2 + min_g_y1 , f4 = sum_g_y2 , f5 = min_g_y1 * sum_g_y2."}, {"heading": "4.2. Fitness assignment", "text": "In order to obtain a good heuristic we have to train the path function f using several graphs. The training graphs are randomly generated at the beginning of the search process and remain unchanged during the search process. To avoid overfitting (see [15]), another set of randomly generated graphs (validation set) is considered. After each generation the quality of the best-so-far individual is calculated using the validation set in order to check its generalization ability during training. At the end of the search process, the function with the highest quality is supplied as the program output.\nThe fitness (quality) of a detected path function f is defined as the sum of the TSP path length of graphs in the training set. Thus the fitness is to be minimized."}, {"heading": "4.3. A Numerical Experiment", "text": "In this experiment we evolve a heuristic for solving TSP problem.\nThe evolution of the best individual fitness and the average fitness of the best individuals over 30 runs are depicted in Figure 1.\nA path function evolved by the MEP algorithm is: f = (sum_g(y2)) * (d_y1_y2 max(d_y1_y2, max_g(y1))) + d_y1_y2).\nHeuristic function f that is evolved by MEP technique is directly used for building the optimum path. The corresponding learning process has a remarkable quality: the evolved (learned) heuristic works very well on data sets significantly larger than the training set. In our example the training set G50 is significantly smaller than the set G1000 used for testing."}, {"heading": "5. Assessing the Performance of the Evolved MEP Heuristic", "text": "In this section the performance of evolved MEP heuristic, NN and MST are compared. In the first experiment we compare the considered algorithms on some randomly generated graphs. In the second experiment the heuristics are compared against several difficult problems in TSPLIB [16]."}, {"heading": "5.1. Experiment 1", "text": "In this experiment we provide a direct comparison of the evolved MEP heuristic, NN and MST. The considered heuristics are tested for randomly generated graphs satisfying triangle inequality.\nEvolved heuristic was tested for different graphs from the classes G200, G500 and G1000. For each graph class 1000 graphs satisfying triangle inequality have been randomly generated. These graphs have been considered for experiments with evolved MEP heuristic, NN and MST.\nPerformance of evolved MEP heuristic, NN and MST are depicted in Table 2\nTable 2. Evolved MEP heuristic vs. NN, MST. For each graph class we present the number of graphs for which evolved MEP heuristic generates a cycle shorter than the cycle obtained by the algorithm MST and NN.\nGraphs types MST NN\nG200 953 800 G500 974 906 G1000 990 948\nResults obtained emphasizes that evolved MEP heuristic outperforms NN and MST algorithms on random graphs."}, {"heading": "5.2. Experiment 2", "text": "To obtain a stronger evidence of the results above we test the performance of the considered heuristics against some difficult problems in TSPLIB. The results are presented in Table 3.\nts225 136069 7.44 140485 10.92994 187246 47.85 u574 43095.6 16.77 44605.1 20.86465 50066 35.66 u724 46545.7 11.06 50731.4 21.04844 60098.9 43.39\nFrom Table 3 we can see that evolved MEP heuristic performs better than NN and MST on most of the considered problems. Only for five problems (bier127, ch150, d198, d493, fl417) NN performs better than evolved MEP heuristic. MST does not perform better than evolved MEP heuristic for no problem. The highest error obtained by the evolved MEP heuristic is 23.05 (the problem d493) while the highest error obtained by NN is 23.45 (the problem rd400). The lowest error obtained with MEP is 1.72 (problem berlin52) while the lowest error obtained by NN is 8.17 (problem bier127). The mean of errors for all considered problems is 10.61 (for evolved MEP heuristic) 16.33 (for NN heuristic) and 35.77 (for MST heuristic)."}, {"heading": "6. Conclusions and Further Work", "text": "MEP technique is used to evolve heuristics for solving TSP problems. Experimental results emphasizes that evolved heuristic outperforms some well known dedicated heuristics.\nMoreover improvement of MEP results could be realized by allowing more function symbols to appear in the MEP chromosome. Further research will focus on using MEP for discovering better heuristics for solving TSP.\nFurther improvement may be obtained by increasing the chromosome length. In this case the complexity of the evolved formula could increases, but the performances of the obtained heuristic could be significantly better.\nEvolving functions that outperform other dedicated heuristics would be of great practical interest. In this way computer programs that are hard to implement could be simulated by simple functions."}], "references": [{"title": "Cost versus Distance in the Traveling Salesman Problem", "author": ["K. Boese"], "venue": "Tech. Rep. TR-950018, UCLA CS Department", "citeRegEx": "2", "shortCiteRegEx": null, "year": 1995}, {"title": "Introduction to Algorithms", "author": ["T.H. Cormen", "C.E. Leiserson", "R.R. Rivest"], "venue": "MIT Press", "citeRegEx": "3", "shortCiteRegEx": null, "year": 1990}, {"title": "Evolutionary Computation", "author": ["D. Dumitrescu", "B. Lazzerini", "L. Jain", "A. Dumitrescu"], "venue": "CRC Press, Boca Raton, FL", "citeRegEx": "4", "shortCiteRegEx": null, "year": 2000}, {"title": "A Genetic Local Search Algorithm for Solving Symmetric and Asymmetric Traveling Salesman Problems", "author": ["B. Freisleben", "P. Merz"], "venue": "Proceedings of the 1996 IEEE International Conference on Evolutionary Computation, pp. 616-621", "citeRegEx": "5", "shortCiteRegEx": null, "year": 1996}, {"title": "Genetic Algorithms in Search", "author": ["D.E. Goldberg"], "venue": "Optimization, and Machine Learning, Addison-Wesley, Reading, MA", "citeRegEx": "6", "shortCiteRegEx": null, "year": 1989}, {"title": "Computers and Intractability: A Guide to NP\u2013 Completeness", "author": ["M.R. Garey", "D.S. Johnson"], "venue": "Freeman & Co, San Francisco, CA", "citeRegEx": "7", "shortCiteRegEx": null, "year": 1979}, {"title": "Genetic Programming: On the Programming of Computers by Means of Natural Selection", "author": ["J.R. Koza"], "venue": "MIT Press, Cambridge", "citeRegEx": "8", "shortCiteRegEx": null, "year": 1992}, {"title": "Studies on the Theory and Design Space of Memetic Algorithms", "author": ["N. Krasnogor"], "venue": "PhD Thesis, University of the West of England, Bristol", "citeRegEx": "9", "shortCiteRegEx": null, "year": 2002}, {"title": "A Memetic Algorithm with self-adaptive local search: TSP a case study", "author": ["N. Krasnogor", "J.E. Smith"], "venue": "Proceedings of 2000 Genetic and Evolutionary Computation Conference, Morgan Kaufmann", "citeRegEx": "10", "shortCiteRegEx": null, "year": 2000}, {"title": "Genetic Local Search for the TSP: New Results", "author": ["P. Merz", "B. Freisleben"], "venue": "Proceedings of the 1997 IEEE International Conference on Evolutionary Computation, pp. 616-621", "citeRegEx": "11", "shortCiteRegEx": null, "year": 1997}, {"title": "Solving Even-Parity Problems using Multi Expression Programming", "author": ["M. Oltean"], "venue": "Proceedings of the the 7 Joint Conference on Information Sciences, September 26-30, 2003, Research Triangle Park, North Carolina, Edited by Ken Chen (et. al), pp. 315-318", "citeRegEx": "13", "shortCiteRegEx": null, "year": 2003}, {"title": "Evolving Evolutionary Algorithms using Multi Expression Programming, The 7", "author": ["M. C Oltean"], "venue": "European Conference on Artificial Life, September 14-17,", "citeRegEx": "14", "shortCiteRegEx": "14", "year": 2003}, {"title": "PROBEN1 \u2013 A set of neural network problems and benchmarking rules, technical report", "author": ["L. Prechelt"], "venue": "University of Karlsruhe,", "citeRegEx": "15", "shortCiteRegEx": "15", "year": 1994}], "referenceMentions": [{"referenceID": 10, "context": "In [12, 13, 14] a new evolutionary paradigm called Multi Expression Programming (MEP) has been proposed.", "startOffset": 3, "endOffset": 15}, {"referenceID": 11, "context": "In [12, 13, 14] a new evolutionary paradigm called Multi Expression Programming (MEP) has been proposed.", "startOffset": 3, "endOffset": 15}, {"referenceID": 6, "context": "MEP may be considered as an alternative to standard Genetic Programming technique [8].", "startOffset": 82, "endOffset": 85}, {"referenceID": 2, "context": "These operators are simple versions of standard binary crossover operators (see [4], [6]).", "startOffset": 80, "endOffset": 83}, {"referenceID": 4, "context": "These operators are simple versions of standard binary crossover operators (see [4], [6]).", "startOffset": 85, "endOffset": 88}, {"referenceID": 1, "context": ", c\u03c0(N\u20131)> of all cities in C having minimum length is needed ([1], [3]) TSP problem with triangle inequality is an NP\u2013complete problem [7].", "startOffset": 68, "endOffset": 71}, {"referenceID": 5, "context": ", c\u03c0(N\u20131)> of all cities in C having minimum length is needed ([1], [3]) TSP problem with triangle inequality is an NP\u2013complete problem [7].", "startOffset": 136, "endOffset": 139}, {"referenceID": 1, "context": "The most important are Nearest Neighbor ([3], [7]) and the Minimum Spanning Tree ([3]).", "startOffset": 41, "endOffset": 44}, {"referenceID": 5, "context": "The most important are Nearest Neighbor ([3], [7]) and the Minimum Spanning Tree ([3]).", "startOffset": 46, "endOffset": 49}, {"referenceID": 1, "context": "The most important are Nearest Neighbor ([3], [7]) and the Minimum Spanning Tree ([3]).", "startOffset": 82, "endOffset": 85}, {"referenceID": 12, "context": "To avoid overfitting (see [15]), another set of randomly generated graphs (validation set) is considered.", "startOffset": 26, "endOffset": 30}], "year": 2003, "abstractText": "Multi Expression Programming (MEP) is an evolutionary technique that may be used for solving computationally difficult problems. MEP uses a linear solution representation. Each MEP individual is a string encoding complex expressions (computer programs). A MEP individual may encode multiple solutions of the current problem. In this paper MEP is used for evolving a Traveling Salesman Problem (TSP) heuristic for graphs satisfying triangle inequality. Evolved MEP heuristic is compared with Nearest Neighbor Heuristic (NN) and Minimum Spanning Tree Heuristic (MST) on some difficult problems in TSPLIB. For most of the considered problems the evolved MEP heuristic outperforms NN and MST. The obtained algorithm was tested against some problems in TSPLIB. The results emphasizes that evolved MEP heuristic is a powerful tool for solving difficult TSP instances.", "creator": "PSCRIPT.DRV Version 4.0"}}}