{"id": "1510.07889", "review": {"conference": "arxiv", "VERSION": "v1", "DATE_OF_SUBMISSION": "27-Oct-2015", "title": "Learning Constructive Primitives for Online Level Generation and Real-time Content Adaptation in Super Mario Bros", "abstract": "procedural construct generation ( pcg ) is important useful interest to game design and development as it generates the content metadata. motivated by building traditional learn - skills coding framework and other structural engineering works, we propose an underlying meaning whilst improving play generation and analysis in little mario bros ( smb ). unlike parts of existing works in fact, social interaction exploits the synergy whereas rule - proven collaborative methodology - based methods also recognize constructive primitives, quality concerning incomplete game modifications in smb. as a result, potentially complete quality game design was be generated for and integrating correct constructive strategies or controllable parameters regarding distinctive features toward event - level scenarios. similarly the adaptive method can be generated in real time by dynamically selecting proper constructive interfaces satisfying an adaptation criterion, e. t., dynamic difficulty reduction ( dda ). our approach is of several hundred nature via terms regards advanced content assurance, ideally variable > controllability. design simulation results demonstrate that this proposed processes can approach controllable yet quality game levels online and adaptable inputs for dda in current age.", "histories": [["v1", "Tue, 27 Oct 2015 12:42:54 GMT  (804kb,D)", "https://arxiv.org/abs/1510.07889v1", null], ["v2", "Thu, 29 Oct 2015 20:09:42 GMT  (803kb,D)", "http://arxiv.org/abs/1510.07889v2", "12 pages, 13 figures, journal paper submission"], ["v3", "Mon, 2 Nov 2015 11:47:32 GMT  (804kb,D)", "http://arxiv.org/abs/1510.07889v3", "v1 is invalid because a wrong license was chosen"]], "reviews": [], "SUBJECTS": "cs.AI", "authors": ["peizhi shi", "ke chen"], "accepted": false, "id": "1510.07889"}, "pdf": {"name": "1510.07889.pdf", "metadata": {"source": "CRF", "title": "Learning Constructive Primitives for Online Level Generation and Real-time Content Adaptation in Super Mario Bros", "authors": ["Peizhi Shi"], "emails": ["shipa@cs.manchester.ac.uk;", "chen@cs.manchester.ac.uk)."], "sections": [{"heading": null, "text": "Index Terms\u2014Procedural content generation, constructive primitive, online level generation, content adaptation, Super Mario Bros.\nI. INTRODUCTION\nIN video gaming industry, game content construction andgeneration are laborious and costed enormously. As a potential solution, procedural content generation (PCG) [1] is a game design and development methodology that aims generating game content automatically via algorithms, which receives a lot of attention from academic research communities and game industries. It is anticipated that the proper use of PCG techniques would reduce the cost of game design and development dramatically. Moreover, PCG could also provide a way that automatically generates personalized games that can adapt content towards a player\u2019s preference and optimizing their cognitive/affective experience.\nIn the PCG research, a number of methods have been proposed for game content generation. These techniques have been applied to different game genres ranging from platform games to first person shooter (see [1] for review) with different styles, e.g., online or offline content generation [1]. Online style tends to speed up content construction process, while offline style can be used for endless or adaptive game generation. Although wide varieties of PCG techniques have\nThe authors are with School of Computer Science, The University of Manchester, Manchester M13 9PL, United Kingdom (e-mail: shipa@cs.manchester.ac.uk; chen@cs.manchester.ac.uk).\nbeen proposed, there are still some open challenges for content generation, including game quality assurance [2], generation efficiency [1], and controllability [2].\nSuper Mario Bros (SMB), a classic 2D platform game, has become a popular test bed for PCG-related researches [3]. In this platform game, a player runs from the left side of the screen to the right side, fights enemies, and rescues the Princess Peach. SMB has a number of different game elements (e.g., enemies, coins, tubes and cannons) that can be generated via PCG. In recent years, several SMB level generators have been developed for level generation track of the Mario AI Championship [4] as well as presented in publications [5]\u2013 [10]. While those level generators can generate complete levels in SMB, there are still several issues to be addressed:\n\u2022 Quality assurance. The quality of procedural SMB levels is generally not as high as handcrafted levels in real games [2]; levels generated by existing generators often contain aesthetically unappealing items (e.g., weird enemy/coin/box decoration), unplayable or unbalanced structures, unreachable resources (e.g., coins and boxes), and unexplainable difficulty curves. Such problems could result in negative gameplay experience. \u2022 Efficiency. The generation process of some SMB generators (e.g., [6], [9]) is computationally expensive; it may take several seconds to generate a complete game level. Thus, such generators are not suitable for online generation. \u2022 Controllability. The geometrical features (e.g., coordinate of each enemy and tube) and some properties of procedural levels (e.g., linearity [11] and density [7]) are not directly controllable in a number of existing level generators. Instead a game designer has to encode the desired properties in handcrafted rules (e.g., [5]) in order to evaluate or control the procedural levels [2]. However, those heuristic rules may be difficult to formulate [12] and could even slow down the level generation [13].\nUnlike most of the existing works, we propose an alternative approach in this paper in order to tackle the aforementioned issues. Motivated by the learning-based PCG (LBPCG) framework [14] and other existing works [5]\u2013[10], we explore the content space in SMB from a different perspective by taking short game segments into account. To address the quality assurance issue, we exploit the synergy between rule-based and learning-based methods; easy-to-design rules are employed for removal of apparently unappealing game segments, and then\nar X\niv :1\n51 0.\n07 88\n9v 3\n[ cs\n.A I]\n2 N\nov 2\n01 5\n2 active learning by encoding a game designer\u2019s knowledge implicitly is applied to obtain high quality game segments, hereinafter named constructive primitives (CPs). Those CPs not only provide quality building blocks but also enable to control the local geometry and the level properties effectively in the SMB level generation. As a result, a complete quality game level can be efficiently generated online by integrating relevant constructive primitive together via controllable parameters on geometrical features, e.g., coordinates of enemies and cannons, and level properties, e.g., linearity, density and leniency. Moreover, adaptable content can be generated in real time by choosing the proper CPs with a given adaptation criterion, e.g., dynamic difficulty adjustment by matching content difficulty and player\u2019s performance. It is worth stating that our approach presented in this paper significantly distinguishes from existing segment-based works in SMB (e.g., [5]) in terms of quality assurance, efficiency and controllability, which is discussed later on. Thus, learning CPs paves an alternative way in addressing those PCG issues in SMB.\nThe main contributions of this paper are summarized as follows: a) a novel approach to producing quality yet controllable game segments or CPs in SMB; b) a controllable online level generator and enabling techniques for real-time content adaptation based on CPs; and c) a thorough evaluation on our proposed approach.\nThe rest of paper is organized as follows. Sect. II reviews the previous works. Sect. III presents our approach to learning CPs in SMB. Sect. IV describes two methods for applications of CPs in online level generation and real-time content adaptation. Sect. V reports simulation results, and the last section discusses relevant issues and implications of this research."}, {"heading": "II. RELATED WORK", "text": "We review the relevant works in PCG and content adaptation that motivate our work presented in this paper."}, {"heading": "A. Procedural Content Generation", "text": "First of all, many SMB level generators were developed under the search-based procedural content generation (SBPCG) framework [1]. In such approaches, game developers first construct a content space that contains all possible procedural levels and then employ heuristic/stochastic search algorithms, e.g., genetic algorithm, to find out high quality levels from the content space. For instance, Sorenson et al. [6] proposed a search-based SMB level generator for level generation track of the Mario AI Championship [4]. Their approach used a set of handcrafted constraints and a challenge-based metric as evaluation functions. During content generation, game levels were first tested by these constraints. Survivals from the test would be used in the search-based optimization. As a result, only game levels of the highest challenge-related fitness values were released to players. In this approach, the properties of procedural levels can be controlled by parameters used in evaluation functions. However, their level generator has to take several minutes to generate 50 levels together due to the huge content space and the use of multiple evaluation functions that\nmay slow down the level generation [13]. In addition, identifying proper constraints and formulating heuristic evaluation functions need game developers\u2019 wisdom and great efforts. This process is often tedious and time-consuming as game content is observable but hard to explain and abstract. Hence, it is difficult to build up an explicit relationship between game content and its quality measurement via handcrafted constraints and heuristic evaluation functions. Similarly, other search-based SMB level generators, e.g., [6]\u2013[8], suffer from the same problems and some of them do not adequately address the quality assurance issue pointed out in Sect. I.\nAs an alternative methodology in PCG, constructive PCG is also applied in the development of SMB level generators. In such approaches, a set of constructive rules are designed by human experts and then used to convert high-level game parameters, e.g., the number of enemies, game difficulty, style, and random seed to concrete game levels. Furthermore, constructive rules have to assure the game quality. Parameterized Notch generator [15] is a typical constructive level generator for SMB. In this approach, a procedural level is controlled and generated via constructive rules working on several content features, e.g., the number of enemies, the averaging width of gaps, and the spatial diversity of gaps. In comparison to the SBPCG approaches, creating constructive rules might be even more difficult [12]; constructive rules are often more complicated than observable constraints. Hence, imperfect constructive rules may lead to low quality and limited controllability over game levels. This fundamental limitation also exists in other constructive SMB generators, e.g., [4], [10], [16], [17].\nUnlike the SBPCG and the constructive PCG approaches that generate a game level at a global level, there are SMB level generators that first generate segments by exploring the local properties and then merge segments to generate a complete game level. We name such level generators segmentbased approaches. For example, Smith et al. developed the Launchpad level generator [5] for generic 2D platform games including SMB. Instead of generating a complete level directly, they first used a grammar-based method that generates game segments named \u201crhythm groups\u201d. Then they merged these rhythm groups together to form a complete level. Before releasing a generated level to player, they used several critics to examine whether the generated game level is acceptable. As a salient characteristic, this approach provides human designers/users with a variety of parameters to control the procedural levels ranging from frequencies of geometry components to level path equation. However, some procedural level properties, e.g., linearity and component frequencies, had to be controlled by designer-specified evaluation functions, which often slows down its generation process. In addition, coordinates of game elements are not controllable directly in this approach. Although our proposed approach is motivated by the segmented-based approaches, ours considerably distinguishes from the existing works in several aspects including the controllability of geometrical features (e.g., coordinate of each enemies, cannons and hills) and procedural level properties (e.g., density [7], leniency [11] and linearity [11]). In particular, our approach generates quality segments of\n3 the fixed-size via combining rule-based and learning-based evaluation functions rather than the handcrafted ones used in the existing segment-based methods, e.g., [5]."}, {"heading": "B. Content Adaptation", "text": "Content adaptation is demanded in generating the personalized content to optimize cognitive/affective experience during gameplay [12]. In general, such techniques can be applied to different types of game content ranging from non-player character behaviour or game AI to game geometry (see [12] for a review). As our work concerns only the game geometry adaptation, we briefly review the relevant work regarding SMB in this context.\nA typical example of geometry adaptation is the personalized level generator in SMB [17], [18]. This level generator is controllable so that various game levels can be generated with a number of controllable features. For content adaptation, an affective model was created to map a player\u2019s behaviour and the controllable content features onto each of the player\u2019s affective states. With such a model, the level generator can generate personalized game levels for an individual. For an effective mapping, the controllable content features were selected based on their impact on the affective states. With the selected features, the game developers then designed a number of constructive rules to control these content features. As argued in Sect. II-A, proper constructive rules are difficult to be handcrafted and the use of evaluation functions to control a complete procedural level could slow down content generation. Similar to this work [17], [18], other geometry adaptation methods in SMB, e.g., [4], [19]\u2013[21], are also subject to the same limitations. By making use of CPs, we propose a method that tends to overcome such limitations in content adaptation."}, {"heading": "III. LEARNING CONSTRUCTIVE PRIMITIVES", "text": "In this section, we first describe the motivation underlying our approach and then present our approach to producing constructive primitives (CPs) in SMB."}, {"heading": "A. Motivation", "text": "As summarized in Sect. I, there are three non-trivial issues in existing SMB level generators: game quality assurance, generation efficiency, and procedural level controllability.\nBy a close look at existing SMB level generators reviewed in Sect. II, we observe that the content space on all the complete procedural levels is huge. As there are an enormous variety of combinations among game elements and structures at procedural levels, an approach working on such content space inevitably faces a greater challenge in managing quality assurance and efficiency in PCG. Thus, controlling the level generation may be rather complicated and difficult [6]. Nevertheless, a complete procedural level in SMB can be decomposed into a number of segments as evident in segment-based level generators [5]. Thus, partitioning a procedural level into fixed-size game segments without relying on any concepts, e.g., rhythm, allows us to explore the SMB content space from an alternative perspective. As a result, all the possible\nsegments form a new content space of lower complexity. We believe that it is less difficult to understand the properties of short game segments and hence the use of those segments as building blocks would facilitate tackling three non-trivial issues in SMB.\nFor quality assurance, there are generally two methodologies in developing such a mechanism in PCG [1], [14]: deductive vs. inductive. To adopt the deductive methodology, game developers have to understand the content space fully and know how to formulate/encode their knowledge into rules, fitness or constraints explicitly. In the presence of a huge content space, however, it would be extremely difficult to understand the entire content space so that either a small region of a content space is merely taken into account or less accurate (even conflicted) rules/constraints have to be used in PCG. The former could significantly limit the number of games generated by PCG while the latter is responsible for low quality games generated by PCG. Nevertheless, we observe that some rules/constraints are easy to design/identify while a complete set of rules for evaluating the content quality are hard to handcraft. For example, overlapped tubes in SMB is unacceptable and can be easily detected with a simple rule. On the other hand, a learning-based PCG (LBPCG) framework [14] was recently proposed where an inductive methodology, i.e. learning from data, was advocated for quality assurance. As game content is observable but less explainable, it is easier for game developers to make a judgement on quality for a specific game by applying their knowledge implicitly than to encode their knowledge into rules or constraints. Thus, the LBPCG suggests that a quality evaluation function should be learned from data annotated by game developers. Nevertheless, the annotation for producing learning examples may be more time-consuming than designing simple rules to detect those apparent low quality games. Hence, a hybrid approach to quality assurance would allow us to exploit the synergy between rule-based and learning-based methods.\nWith the motivation described above, we propose a hybrid approach to producing CPs, quality yet controllable game segments, in SMB. Fig. 1 illustrates the main steps of our approach. First of all, game developers choose a region of interest from the entire content space via control parameters. Then game segments in the region of interest are evaluated by a set of easy-to-design handcrafted conflict resolution rules and the subsequent data-driven quality evaluation function that deals with more complicated quality issues. Survivals of game segments become CPs."}, {"heading": "B. Content Space", "text": "Based on our observation from empirical studies, it is sufficient to cover rich yet diverse types of games by using a\n4 game segment of 20 in length and 15 in height. Some typical game segment instances are illustrated in Fig. 2.\nThe SMB content is naturally specified by a 2D grid similar to an image. However, this leads to a 300-dimensional content space in our case where there are a lot of redundancy, e.g., the uniform background. Motivated by the previous work [6], we employ a list of design elements as our content space representation where a design element refers to an atomic unit used in a procedural level generation [1], [6], e.g., enemy, boxes, coins, cannon, gap and so on. By using this representation, we can not only specify the content space concisely but also gain the direct controllability on low-level content features, e.g., coordinates of enemies and coins. As listed in Table I, 85 controllable features are employed in our representation. Such representation is similar to the previous work [6]. In our content space, the design elements in each type are sorted in decreasing order along x dimension.\nWhile design element parameters in Table I have a wide range that specifies the entire content space, we confine our concerned content space to a non-trivial region of the entire content space by setting the maximum number of gaps, hills, tubes, cannons, boxes, coins and enemies appeared in a game segment are 3, 2, 3, 3, 2, 2 and 5 respectively. Consequently, there are roughly 9.72 \u00d7 1037 game segments in our content space. This content space should be sufficient for generating content with a variety of geometrical features, level structures and difficulties required by SMB."}, {"heading": "C. Conflict Resolution", "text": "In our content space, there are quite a number of game segments that contain conflicting design elements. For instance, \u201c. . . Tube(7,2,3,4,4,flower). . . Cannon(7,3,1,3,2). . . \u201d represents a game segment of at least one tube and one cannon but their x coordinates are same. Thus, the cannon and tube are overlapped together and this conflicting situation makes the segment aesthetically unappealing.\nMotivated by the previous work [6], [7], we adapt a class of rules presented in [6] for our requirement. As a result, the conflict resolution rules effectively discard those game segments of geometrically overlapped design elements including gap, enemy, tube, cannon, boxes and coins."}, {"heading": "D. Learning Constructive Primitives", "text": "After filtering out those obviously unappealing game segments, the tailored content space still contains a lot of low quality segments, e.g., segments of unreachable coins and boxes, segments of being too difficult/easy to play, segments of\nunbalanced resources and aesthetically unappealing structures. Inspired by the LBPCG work [14], we would learn a quality evaluation function from annotated game segments to remove unplayable/unacceptable segments. To carry out this idea, a binary classifier is trained where its input is the 85D feature vector of a game segment and its output is a binary label that predicts the quality of a game segment. Game segments labeled as positive are CPs and would be used for online level generation and content adaptation described in Sect. IV.\nTo establish a data-driven evaluation function, training examples are required but have to be provided from game developers. As the tailored content space is still huge, it is infeasible to annotate all possible games in this content space. To keep the content space manageable, a proper sampling can be applied to achieve a much smaller data set of the same properties as the content space. Motivated by the success in the LBPCG work [14], we conduct clustering analysis on the data set and further employ active learning based on the clustering results to minimize a game developer\u2019s efforts in data annotation. In summary, this CP learning process is depicted in Fig. 3.\n1) Sampling: For sampling, we apply the simple random sampling with replacement [22], an unbiased sampling technique, to the tailored content space for a manageable data set. As a result, we randomly set all the controllable features in the tailored content space to ensure that each game segment in this content space has the equal probability to be selected. The size of data set is determined via the sample size determination (SSD) algorithm suggested in [22]. With the theoretical justification, the SSD can decide the size of a sampled data set without loss of non-trivial information. By applying the SSD to our tailored content space, it is suggested that a data set of 19,000 games should be sufficient.\n2) Clustering: We apply the CURE algorithm [23] on the sampled game set for clustering analysis since this hierarchical clustering algorithm can deal with a large data set and discover the clusters of different sizes in complex shapes. There are four parameters in CURE algorithm: the number of clusters, sampling rate, shrink factor and the number of representative points. By using the dendrogram tree achieved, the number of clusters is automatically decided based on the longest kcluster lifetime [24]. The rest of parameters are set to defaults suggested in [23]; i.e., 2.5% for sampling rate, 0.5 for shrink factor and 10 representative points, respectively. Due to the existence of two different feature types, i.e. nominal and ordinal, we employ the mixed-variable distance metric [25] in the CURE. After clustering, we found 106 clusters from this sampled data set, and the clustering results would be used to facilitate active learning.\n3) Active Learning: For binary classification, there are two error types: false negative (type-I error) where a high quality\n5\nsegment is misclassified as low quality and false positive (typeII error) where a low quality segment is misclassified as high quality. Obviously, a type-II error could result in a catastrophic effect while a type-I error simply shrinks the content space slightly. As a result, we formulate our classification as a cost-sensitive learning problem where the type-II error incurs a higher cost. By looking into several state-of-the-art classification techniques, we found that the weighted random forests(WRFs) [26], a cost-sensitive oblique random forests [27] classifier, fully meet our requirements for active learning. In our work, the parameters of WRFs [26] are set via validation as follows: 2:1, 50, 5, 10 and 9 for the cost ratio, the number of trees, the number of combined features, the number of feature groups selected at each node, and depth of trees, respectively.\nAfter clustering, a small number of segments are selected from each cluster to form a validation set. The number of segments selected from each cluster is proportional to the cluster size. Totally, there are 800 segments in the validation set. We annotate each game in the validation set by visual inspection in order to evaluate the generalization performance of a classifier during active learning.\nDuring active learning, we randomly choose 100 segments and annotate them visual inspection to train the initial WRFs. In each iteration, we find 100 segments of the highest uncertainty scores, defined by si = 1 \u2212 P (y\u0302|xi) where y\u0302 is the predicted label of segment xi, and P (y\u0302|xi) is the probability of this prediction, and annotated them to be examples for retraining WRFs. The active learning stops when the accuracy of WRFs on the validation set no longer increases. Our active learning algorithm is summarized in Algorithm 1.\nOnce the learning-based evaluation function is constructed, we use it along with the aforementioned rules to produce CPs of favorable properties that ensures to gain the direct control of CPs via the relevant design elements in terms of geometrical features, level structures and difficulties."}, {"heading": "IV. ONLINE GENERATION AND REAL-TIME ADAPTATION", "text": "In this section, we come up with the techniques in applying constructive primitives to online procedural level generation and real-time content adaptation in terms of DDA.\nAlgorithm 1 Active Constructive Primitive Learning Input: Sampled data set U and clustering results on U . Output: WRFs binary classifier. Initialization: Based on the clustering analysis results, create a validation set V of 800 examples. Active Learning: Annotate 100 segments randomly selected from U via visual inspection to form a training set L. Train WRFs on L to obtain an initial binary classifier. repeat\nfor all xi \u2208 U do Label xi with the current WRFs. Calculate the uncertainty score si of xi. end for Annotate 100 segments of the highest uncertainty score in U to form a new training set L. Re-train the WRFs with the examples in L.\nuntil The overall accuracy on V does not increase."}, {"heading": "A. Online Game Generation", "text": "As described in Sect. III, CPs provide quality building blocks and hence lumping them together can easily lead to a procedural level of aesthetically appealing content with a path between entrance and exit. In SMB, there are a variety of procedural levels that can be categorized based on a number of properties, e.g., density [7], leniency [11] and linearity [11]. As our CPs are represented by design elements, we can generate a procedural level of pre-setting property via controllable level generation parameters.\nMotivated by the previous works [7], [11], we employ three controllable level generation parameters, i.e., density, leniency and linearity, to generate a variety of levels online. The density controls the complexity of geometrical structures, e.g., a high density leads to many overlapping hills. The leniency decides the level difficulty in gameplay; intuitively, a high leniency results in an easy-to-play level. The linearity is yet another parameter that ensures there is a linear structure in a generated level; a large value leads to a level of highly linear structures. Each level generation parameter is carried out by setting the proper values to relevant design elements in CPs as follows:\n6 \u2022 Leniency. This parameter is implemented via controlling the number and type of enemies, number and width of gaps, number of cannons and tube flowers in CPs. \u2022 Density. This parameter is decided by the number and coordinates of hills in CPs. \u2022 Linearity. This parameter operates by specifying the height of platform, the number of hills, y coordinates of tubes and cannons in CPs.\nEach level generation parameter is set to {1, 2, 3}, which divides our CPs into three categories reflecting the different properties specified by a specific parameter.\nAlgorithm 2 Online Procedural Level Generation Input: Level generation parameter setting and the number of CPs (specifying the level length to be generated). Output: Procedural level of a fixed length specified by the number of CPs. Generation: Generate an empty segment as the game entry. repeat\nRandomly produce a CP of the specified leniency, density and linearity parameter values. Append this CP to the existing procedural level.\nuntil The level contains the specified number of CPs. Generate the exit for this procedural level.\nTo generate a complete level, we first specify the desired values to level generation parameters that fix the parameter values of relevant design elements and set other irrelevant design elements in CPs randomly. Thus, an iterative process is undertaken by merging the CPs of the specified properties together until reaching a pre-specified length or the number of CPs pre-specified. As each CP is produced very efficiently, our level generator works online. The online level generation algorithm is summarized in Algorithm 2. It is worth stating that linearity may conflict with density. Hence, we stipulate that the value set to density overrides that of linearity for their shared design elements. In other words, we do not want to generate highly linear procedural levels, which is often considered as aesthetically unappealing."}, {"heading": "B. Real-time Content Adaptation", "text": "For content adaptation, we confine our work on CPs to only the dynamic difficulty adjustment (DDA) where the game difficulty is automatically adjusted according to a player\u2019s performance.\nFor DDA, it is essential to define content difficulty and measure a player\u2019s performance. In our work, a difficulty parameter of five levels is defined for each CP based on its relevant design elements that affect a player\u2019s performance, such as the number and the type of enemies, the number and the width of gaps, the number of cannons and tube flowers. For instance, a CP of the highest difficulty level contains as least two enemies, one cannon and one gap while there are at most one Goomba and one flower tube in a CP of the lowest difficulty level. Measuring a player\u2019s performance may be complicate if all the aspects need considering. In our work,\nwe simplify this by only taking the survival rate on CPs into account.\nBy means of the segment-based methodology, we would make use of our CPs for real-time DDA, i.e., the performance is measured locally on a CP instead of a level and the DDA is done instantly in response to a player\u2019s local performance. This is naturally a sequential decision process and we would formulate it as a Markovian decision process (MDP) [28]. Thus, our goal is to find an optimal policy that maximizes the expected long-term performance via adjusting the difficulty of generated CPs. To attain this goal, we define a regret \u03c1 at time T (i.e., after T CPs have been played) as the absolute difference between an expected survival rate and the expectation of rewards:\n\u03c1 = |\u03b8opt \u2212 1\nT E[ T\u2211 t=1 rt]|, (1)\nwhere \u03b8opt is a pre-set optimal survival rate and rt is a binary reward: rt = 1 if the player survives and 0 otherwise. For instance, we set \u03b8opt = 0.8 if the performance of the survival rate 0.8 is expected. For a given \u03b8opt, levels of proper difficulties can be generated for a player to gain the expected performance. Thus, minimizing this regret is key to our content adaptation. To solve this optimization problem, we employ the Thompson sampling [29], an effective and efficient heuristic method used in binary reward case in MDP.\nLet \u03b8i denote a player\u2019s survival rate of difficulty level i (i = 1, \u00b7 \u00b7 \u00b7 , 5). Thus, a player survives with the probability \u03b8i and reciprocally dies with the probability 1\u2212\u03b8i when they play a CP of difficulty level i. During gameplay, one plays a number of CPs of different difficulty levels sequentially. When a CP of difficulty level at = i is completed at time t, a binary reward is assigned. Given the player\u2019s survival rate \u03b8i corresponding to at, the reward likelihood is\nP (rt|at = i, \u03b8i) = \u03b8rti (1\u2212 \u03b8i) 1\u2212rt . (2)\nFurthermore, let DT = (at, rt)Ti=1 denote the historical profile regarding corresponding difficulties and rewards after T CPs have been played. By using a conjugate prior, \u03b8i \u223c Beta(1, 1), the posterior distribution of survival rate based on the likelihood in Eq. (2) is P (\u03b8i|DT ) \u221d \u220fT t=1 P (rt|at, \u03b8i)P (\u03b8i), which leads to \u03b8i|DT \u223c Beta(\u03b1i+1, \u03b2i+1) where \u03b1i and \u03b2i are the number of survives and deaths when playing the CPs of difficulty level i in DT .\nFor content adaptation, we follow the typical setting in real SMB games: at the beginning, a player is put in small state, i.e., the weakest form of Mario, where the player is not allowed to use powerful weapon (e.g., throwing fireballs) and then turns into other states by powering up with a mushroom or fire flower. Based on the gameplay information recorded in DT , CPs are randomly produced according to Beta(\u03b1i+1, \u03b2i+1) and the CP of difficulty level i is chosen as a game segment to play if it results in the least regret defined in Eq. (1). After a CP of difficulty level i is played, the posterior probability Beta(\u03b1i+1, \u03b2i+1) is updated based on the performance on the CP. Thus, this content adaptation process continues until a player quits, as summarized in Algorithm 3. It is worth\n7 stating that this algorithm is presented for a life-long gameplay scenario but easily adapted for multiple gameplay episodes by substituting the Beta conjugate prior, Beta(1, 1), with the posterior obtained from the last episode, Beta(\u03b1i, \u03b2i), in the initialization whenever a new episode starts.\nAlgorithm 3 Real-time Content Adaptation for DDA Input: Optimal survival rate \u03b8opt. Initialization: t\u21900, \u03b1i\u21901 and \u03b2i\u21901 for i = 1, \u00b7 \u00b7 \u00b7 , 5. repeat t\u2190 t+ 1. if t==1 or rt\u22121 == 0 then\nSample CPs according to \u03b8i \u223c Beta(\u03b1i, \u03b2i) for i = 1, \u00b7 \u00b7 \u00b7 , 5. Choose the CP of at = argmini |\u03b8opt \u2212 \u03b8i|.\nelse Sample CPs according to \u03b8i \u223c Beta(\u03b1i, \u03b2i) for i=max(1, at\u22121\u22121), at\u22121 and min(at\u22121+1, 5). Choose the CP of at = argmini |\u03b8opt \u2212 \u03b8i|. end if Generate the chosen CP of at. if rt == 1 then \u03b1at\u2190\u03b1at + 1. //the player survives else \u03b2at\u2190\u03b2at +1. //the player dies and a new game starts\nend if until Gameplay stops."}, {"heading": "V. EXPERIMENTAL RESULTS", "text": "In this section we report results in the CP learning, online level generation and simulated DDA. The game engine adopted in our experiments is a modified version of the opensource Infinite Mario Bros used in the Mario AI Championship [4], [30]. Our level generators that yield results reported in this section are publicly available on our project website1."}, {"heading": "A. Results on Constructive Primitive Learning", "text": "Based on the learning algorithm described in Sect. III, Fig. 4 illustrates the evolutionary performance of our active learning on the validation set, including types I and II error rates as well as their average, the half total error rate (HTER). From Fig. 4, it is observed that the active learning converges after 1100 data points.\nWhile the final HTER is around 11.67%, the corresponding type-I error rate is around 19.66% and some misclassified segment instance are shown in Fig. 5(A). By analyzing the clustering results, we find out that those segments are concentrated in a quite small region in the content space. Therefore, they are unlikely to be sampled so as to missed in establishing the validation set. It is evident from Fig. 4 that our cost-sensitive classifier performs well in minimizing the type-II error; the type-II error rate is approximately 3.69%. Among those low quality segments misclassified as high quality, about 0.74% segments contain unreachable resources (e.g., coins and boxes)\n1http://staff.cs.manchester.ac.uk/\u223cshipa/mario.html\nFig. 4. Performance evolution on the validation set during active learning.\nand the rest segments are either too easy/difficult to play or less appealing aesthetically as exemplified in Fig. 5(B). While such segments may result in negative gameplay experience, fortunately, none of unplayable segments in the validation set was misclassified.\nIn this experiment, we use the permutation test pertaining to RFs [27] to measure the importance of design elements in the CP learning. As a result, Table II list the top 30 design elements that significant affect the quality of CPs. From Table II, it is observed that there is a close connection between the design element such as gap/hill/cannon and quality of a game segment. In addition, x and y coordinates and geometrical properties of game elements (e.g., their width and height) are among the most important features for the CP prediction."}, {"heading": "B. Results on Online Level Generation", "text": "In all our experiments, a game level are confined to a 2D map of 200 in length and 15 in height, as same as the setting in previous works, e.g., [5]\u2013[9]. We evaluate our online level generator in terms of expressive range, controllability and generation efficiency.\n1) Expressive Range: Expressive range refers to the range and variation of procedural levels according to an evaluation metric [11] that measures the property of procedural levels.\n8\nBy using a specific metric, the expressive range is often used to visualize the space of all possible procedural games. For evaluation, we use linearity [11], density [7], leniency [11] and compression distance [7] as our metrics. Such metrics allows us to reveal global properties of game levels generated by a level generator.\nFor linearity, we use the method suggested in [13] to find a line that fits the profile of a procedural level, and the coefficient of determination r2 is used to estimate the degree of linearity. For density, we count the number of all possible standing positions in a game level [7]. For leniency, we assign a value to each type of game elements as same as used in [5], [7] (i.e., enemy: -1.0, gap, cannon or flower tube: -0.5, and powerup: +1.0). The overall leniency score is the sum of the three values. Finally, the normalized compression distance (NCD) [7] is employed to measure the dissimilarity between two game levels; the higher this distance the more dissimilar two levels.\nFor a thorough evaluation, we compare our level generator with a number of typical SMB level generators reviewed in Sect. II, including Notch [16], Parameterized Notch (PN) [15], Grammar Evolution (GE) [7] and Launchpad generators [5]. For fairness, we adopt the experimental protocols suggested in [13]. As a result, each of level generators generates 200 procedural levels for evaluation in terms of linearity, density and leniency2 and the NCD metric is applied to 200 pairs of levels. The level generation parameters used in ours are set randomly and others use their default settings. To our knowledge, the parameters in PN and Launchpad were set randomly, and there is no parameter in GE. The scores measured with a metric are normalized to the range of [0,1].\nThe results on expressive ranges are shown in Fig. 6. It is\n2The levels generated by those generators were provided by N. Shaker and only 200 procedural level images are available.\nobserved from Fig. 6 that Launchpad can generate both linear and nonlinear levels while the rest generators tend to generate non-linear levels. As described in Sect. IV.A, the setting in our generator prefers nonlinear levels. Regarding density, the expressive ranges of GE and ours are wider than others. However, others tend to generate levels with a low density. Regarding leniency, Launchpad and PN tend to generate levels of medium difficulty levels. In contrast, others including ours may generate both difficult and easy game levels. Among all the generators, the expressive range of ours is widest in terms of leniency and density. The expressive range differences among those level generators account for the use of different content spaces and level generation parameters. From Fig. 6, it is evident that PN receives the lowest NCD score, which implies relatively similar levels are generated. In contrast, others generate levels of a greater diversity as there are larger NCD distances among levels they generate, and ours generates levels of medium diversity in comparison to others.\n2) Controllability: We further evaluate the controllability of our level generator. In general, controllability can be reflected in the expressive ranges of procedural levels generated with different level generation parameter settings [5]. As ours have three level generation parameters and each may take one of three values as described in Sect. IV.A, we exhaustedly generate nine sets of levels by fixing one parameter with a specific value and randomly setting all other parameters each time. To see the controlling effect clearly, we also generate a set of levels by setting all the parameters randomly. Thus, we achieve 10 level sets where each contains 1000 levels for reliability. In terms of linearity, density and leniency, the expressive ranges of levels controlled by different parameters are shown in Fig. 7 where it is clearly seen that the levels of a specific property are generated by properly controlling a parameter.\nFor exemplification, Fig. 8 - 10 illustrate some levels generated by controlling parameters in a specific way. By visual inspection, we observe that the level shown in Fig. 8 (C) is smoother than those in Fig. 8 (A) and (B) since it is generated by using the highest linearity value. From Fig. 9, it is seen that the profile shown in Fig. 9 (C) this level is easier to play (e.g., fewer enemies and narrower gaps) than those shown in Fig. 9 (C) due to the use of the highest leniency value. It is evident from Fig. 10 that there are more complicated geometrical structures (e.g., more overlapping hills) in the level shown in Fig. 10 (C) than those shown in Fig. 10 (A)\n9\nand (B) as the highest density value is applied. 3) Efficiency: Generation efficiency is often evaluated by the actual time taken in a level generation. As we do not have codes of level generators used for comparison in our experiments, we can only report the result on ours. By testing on a PC (Intel Core i5-3470 processor with 8GB memory), our level generator takes only 0.057 sec on average to generate a procedural level, 200\u00d715 2D map, which should be able to\nmeet the online generation requirements."}, {"heading": "C. Results on Real-time Content Adaptation", "text": "For the evaluation of our proposed real-time content adaptation for DDA, we conduct simulations with sophisticated Mario controllers of different types instead of human players as suggested in [18]. The use of agents for DDA test may benefit from stable agents\u2019 behavior, their diversified playing styles and a wide range of skills [18]. As a result, we employ 15 agents submitted to the Gameplay track of the Mario AI Competition [30]. To test our adaptive generator, we use completion rate, the ratio of the actual distance travelled over to the length of a game level being played, as a evaluation criterion for DDA [30]. Moreover, we further examine the online learning performance of our adaptation algorithm based on the completion rates of three typical agents in response to adaptive content generated for an optimal survival rate, \u03b8opt. In our simulation, a level generated with our adaptation algorithm is limited to a maximum length of 200.\n10\nFor reliability, each of 15 agent played on three sets of adaptive games generated by Algorithm 3 with different optimal survival rates, \u03b8opt = 0.80, 0.87, 0.95, where each set consists of 200 levels. For a baseline, we also randomly generated 200 levels of the same length and refer them to static games as no DDA is applied and each agent also plays the games in the static game set.\nFig. 11 illustrates the mean and the standard deviation of completion rates achieved on four game sets by 15 agents3. As shown in Fig. 11, Peter\u2019s, Andy\u2019s and Robin\u2019s agents outperform other agents in terms of the averaging completion rate thanks to the A* algorithm used in their implementation. Hence, we regard these three agents as \u201cskilful players\u201d and all the rest are \u201cnovices\u201d. It is observed from Fig. 11 that our real-time adaptation algorithm works well for all the novice agents given the fact that their completion rates on adaptive game sets are higher than that on the static game set, which implies easier levels were dynamically generated to improve their performance. In contrast, the DDA performance varies for three skillful agents. While the completion rates of Robin\u2019s agent are achieved as expected, our adaptation algorithm does not work well for Peter\u2019s and Andy\u2019s agents. According to [30], these two agents can survive from nearly all the procedural levels no matter how difficult they are. Thus, our algorithm could hardly find games to challenge them. From Fig. 11, it is also evident that a higher value of \u03b8opt generally leads to a higher completion rate, as required by DDA.\nTo evaluate the online learning performance of our adaptation algorithm, we adopted Rafael\u2019s, Sergio\u2019s and Robin\u2019s agents since they represent agents at different levels in light of playing styles and skills: Rafael\u2019s and Sergio\u2019s agents are novices and Robin\u2019s agent is a skilful player. In our experiment, each agent played 30 successive games generated in a gameplay episode by our adaptation algorithm via setting \u03b8opt = 0.80. For comparison, three agents also played 30 randomly generated static game levels of the same length. For reliability, we repeated this experiment for 30 trials and the mean and the standard derivation of completion rates achieved by three agents are illustrated in Fig. 12. From Fig. 12(A) and (B), it is seen that the averaging completion rates of Rafael\u2019s and Sergio\u2019s agents on adaptive games are always higher than those on static games thanks to the adaptation that generates easier levels. In particular, the complete rates on adaptive games gradually increase and becomes stable after 5-8 games were played roughly. In contrast, the completion rates of Robin\u2019s agent gradually decrease as observed from Fig. 12(C) where the complete rates on adaptation games are always lower than those on their counterpart static games after 14 games were played thanks to the adaptation that keeps generate more difficult games.\nFor demonstration, we exhibit three procedural levels generated by our adaptation algorithm for three aforementioned agents in Fig. 13. In the level for Rafael\u2019s agent shown in Fig. 13(A), there are fewer enemies than those generated for\n3The slight difference between the performance presented in [30] and that reported here is due to different Mario start state settings: the fire state in theirs but the small state in ours.\nSergio\u2019s and Robin\u2019s agents shown in Figs. 13(B) and 13(C). The level shown in Fig. 13(B) is at the intermediate difficult level where there are several enemies flower tubes, while the one shown in Fig. 13(C) contains a lot of enemies and gaps, a difficult level to play apparently.\nIn summary, the experimental results reported in this section demonstrate that our proposed algorithms based on CPs work effectively in generating quality and adaptable SMB games."}, {"heading": "VI. DISCUSSION", "text": "In this section, we discuss the issues arising from our work and relate ours to pervious works.\nIt is well known that automatically generated procedural SMB levels is generally worse than those handcrafted levels [2]. This is further exacerbated by other simultaneous requirements in generation efficiency and controllability. By exploiting the nature of 2-D platform games, we effectively limit this problem to a smaller yet manageable content space consisting of short game segments without compromising the content diversity. Furthermore, we explore and exploit the synergy between rule-based and learning-based methodologies to produce quality building blocks, i.e., constructive primitives (CPs). While our hybrid quality assurance method appears effective, there is an issue to be addressed: how to tradeoff between two methodologies. On the one hand, strict yet aggressive rules may completely remove all the unplayable content but often get rid of playable content as well so that the diversity of playable content is significantly limited. Due to the high complexity of content space, it is extremely difficult to formulate rules, in particular, concerning all the aspects of game quality [31]. On the other hand, a learningbased approach may address all the quality assurance issues with a single evaluation function. It works efficiently with game developers\u2019 judgment on quality of training examples instead of handcrafting constraints and deductive rules based on the understanding of an entire content space [5]\u2013[9], [15]\u2013 [17]. For example, the developer took only two hours in annotating 1900 games via visual inspection for our CP active learning as described in Sect. III. However, a learning-based approach rarely yields the error-free performance. Thus, our work presented in this paper suggests the ultimate goal for a hybrid approach as follows: without compromising the content diversity, efficient rule-based methods should concentrate on unplayability only to avoid catastrophic failures, and learningbased methods should take charge of other quality assurance aspects after unplayable content removal.\nWhile our online level generator clearly benefits from CPs in efficiency, it gains remarkable controllability via design elements, a direct content representation concerning low-level geometrical features, working at a local level for CPs. By controlling relevant design elements directly, ours generates a procedural level efficiently by integrating CPs of desired properties. It is noticed that similar design elements were used as content representation in previous works [6], [7] where those attributes are specified at an entire procedural level. As a result, such approaches have to formulate constructive rules or evaluation functions to control level properties globally. While\n11\nthose rules or evaluation functions have to be handcrafted with a great effort [12], [31], it may work less efficiently especially for generating procedural levels of a considerable length [13]. Thus, our approach significantly distinguishes those working at a global level [6], [7] in terms of content representation and resultant controllability.\nIn general, our online level generator may be viewed as a hybrid PCG approach if we position it in light of the existing taxonomy [1]. On the one hand, we use a generateand-test method to produce CPs for quality assurance. On the other hand, a procedural level is constructively generated via a number of controllable parameters for efficiency [31]. Apparently, ours distinguishes from those generate-and-test (e.g., [5]\u2013[8]) or constructive (e.g., [10], [15]\u2013[17]) SMB level generators. As a hybrid approach, however, the desired level properties have to be specified via setting controllable parameters at a local level. This would be a potential weakness when such properties are unknown or hard to specify.\nFor real-time DDA, our algorithm seems to resemble some previous works [19], [20]. However, they differ in difficulty\ncontrollability and performance measurement. While a CP of certain difficulty is achieved by setting a controllable parameter in ours, a proper segment in theirs has to be generated via a rhythm-based mechanism or a set of constructive rules [19], [20]. In addition, we use the survival rate, an objective metric, for measuring performance while they adopt the subjective player\u2019s feedback to decide the appropriateness of a difficulty level. While our CP-based adaptation algorithm is promising in performance-driven DDA, it is subject to a number of limitations: (a) the current evaluation is solely based on agents instead of human players and the adaptation process does not seem rapid; and (b) For DDA, the assumption used in our simulation, a strong relationship between player\u2019s performance and experience, may be questionable as suggested in recent studies (e.g., [32]); (c) it is unclear how to adapt content via CPs in the presence of subjective feedback on an entire procedural level (e.g., [17], [18], [21]), which has been studied under the EDPCG framework [12].\nIn conclusion, we have presented a novel approach to online level generation and real-time content adaptation in SMB via\n12\nlearning constructive primitives. Our approach has been evaluated via comparing to state-of-the-art SMB level generators in terms of quality, efficiency and controllability. Experimental results suggest that it meets the online level generation requirements and has a potential in real-time content adaptation. In our ongoing work, we are aiming addressing issues discussed above and further investigate our algorithms in different applications, e.g., experience-driven DDA. Although segmentbased experience-driven content adaptation has been studied for SMB (e.g., [19], [20]), their work entirely relies on the self-reported feedback on each short segment, which severely interrupts the gameplay experience [12]. In our work, we are going to overcome this fundamental weakness by exploring player\u2019s behavior and relevant content features at the CP level for a scenario that only self-reported feedback on a complete procedural level is available. We anticipate that such realtime content adaptation minimizes gameplay interruption and yields optimal gameplay experience reciprocally. Furthermore, we would like to investigate the feasibility in extending our approach proposed in this paper to other game genres such as first-person shooter."}, {"heading": "ACKNOWLEDGMENT", "text": "The authors are grateful to N. Shaker for providing SMB procedural level images used in our comparative study and to those members in the Google PCG Interest Group who responded to our enquiries for useful discussions."}], "references": [{"title": "Searchbased procedural content generation: A taxonomy and survey", "author": ["J. Togelius", "G.N. Yannakakis", "K.O. Stanley", "C. Browne"], "venue": "IEEE Trans. Comput. Intell. AI in Games, vol. 3, no. 3, pp. 172-186, 2011.", "citeRegEx": "1", "shortCiteRegEx": null, "year": 2011}, {"title": "Procedural content generation: goals, challenges and actionable steps", "author": ["J. Togelius", "A.J. Champandard", "P.L. Lanzi", "M. Mateas", "A. Paiva", "M. Preuss", "K.O. Stanley"], "venue": "Artificial and Comput. Intell. in Games, vol. 6, pp. 61-75, 2013.", "citeRegEx": "2", "shortCiteRegEx": null, "year": 2013}, {"title": "Super Mario World", "author": ["EAD Nintendo"], "venue": "(Game) 1990.", "citeRegEx": "3", "shortCiteRegEx": null, "year": 1990}, {"title": "The 2010 Mario AI championship: Level generation track", "author": ["N. Shaker", "J. Togelius", "G.N. Yannakakis", "B. Weber", "T. Shimizu", "T. Hashiyama", "N. Sorenson", "P. Pasquier", "P. Mawhorter", "G. Takahashi", "G. Smith", "R. Baumgarten"], "venue": "IEEE Trans. Comput. Intell. AI in Games, vol. 3, no. 4, pp. 332-347, Sep. 2011.", "citeRegEx": "4", "shortCiteRegEx": null, "year": 2011}, {"title": "Launchpad: A rhythm-based level generator for 2-d platformers", "author": ["G. Smith", "J. Whitehead", "M. Mateas", "M. Treanor", "J. March", "M. Cha"], "venue": "IEEE Trans. Comput. Intell. AI in Games, vol. 3, no. 1, pp. 1-16, Mar. 2011.", "citeRegEx": "5", "shortCiteRegEx": null, "year": 2011}, {"title": "A generic approach to challenge modeling for the procedural creation of video game levels", "author": ["N. Sorenson", "P. Pasquier", "S. DiPaola"], "venue": "IEEE Trans. Comput. Intell. AI in Games, vol. 3, no. 3, pp. 229-244, Sep. 2011.", "citeRegEx": "6", "shortCiteRegEx": null, "year": 2011}, {"title": "Evolving levels for Super Mario Bros using grammatical evolution", "author": ["N. Shaker", "M. Nicolau", "G.N. Yanakakis", "J. Togelius", "M. O\u2019Neill"], "venue": "Proc. IEEE Conf. Comput. Intell. Games, 2012, pp. 304-311.", "citeRegEx": "7", "shortCiteRegEx": null, "year": 2012}, {"title": "A multi-level level generator", "author": ["S. Dahlskog", "J. Togelius"], "venue": "Proc. IEEE Conf. Comput. Intell. Games, 2014, pp. 1-8.", "citeRegEx": "8", "shortCiteRegEx": null, "year": 2014}, {"title": "Procedural level generation using occupancy regulated extension", "author": ["P. Mawhorter", "M. Mateas"], "venue": "Proc. IEEE Conf. Comput. Intell. Games, 2010, pp. 351-358.", "citeRegEx": "9", "shortCiteRegEx": null, "year": 2010}, {"title": "Experiments in map generation using markov chains", "author": ["S. Snodgrass", "S. Onta\u00f1\u00f3n"], "venue": "Proc. FDG Workshop on Procedural Content Generation, 2014.", "citeRegEx": "10", "shortCiteRegEx": null, "year": 2014}, {"title": "Analyzing the expressive range of a level generator", "author": ["G. Smith", "J. Whitehead"], "venue": "Proc. Workshop on Procedural Content Generat. Games, 2010.", "citeRegEx": "11", "shortCiteRegEx": null, "year": 2010}, {"title": "Experience-driven procedural content generation", "author": ["G.N. Yannakakis", "J. Togelius"], "venue": "IEEE Trans. Affective Comput., vol. 2, no. 3, pp. 147- 161, 2011.", "citeRegEx": "12", "shortCiteRegEx": null, "year": 2011}, {"title": "A comparative evaluation of precudural level generators in Mario AI framework", "author": ["B. Horn", "S. Dahlskog", "N. Shaker", "G. Smith", "J. Togelius"], "venue": "Proc. FDG Workshop on Procedural Content Generation, 2014.", "citeRegEx": "13", "shortCiteRegEx": null, "year": 2014}, {"title": "Learning-based procedural content generation", "author": ["J. Roberts", "K. Chen"], "venue": "IEEE Trans. Comput. Intell. AI in Games, vol. 7, no. 1, pp. 88-101, 2015.", "citeRegEx": "14", "shortCiteRegEx": null, "year": 2015}, {"title": "Feature analysis for modeling game content quality", "author": ["N. Shaker", "G.N. Yannakakis", "J. Togelius"], "venue": "Proc. IEEE Conf. Comput. Intell. Games, 2011, pp. 126-133.", "citeRegEx": "15", "shortCiteRegEx": null, "year": 2011}, {"title": "Infinite Mario bros", "author": ["P. Persson"], "venue": "[Online]. Available: http://www. mojang.com/notch/mario/.", "citeRegEx": "16", "shortCiteRegEx": null, "year": 0}, {"title": "Modeling player experience in super mario bros", "author": ["C. Pedersen", "J. Togelius", "G.N. Yannakakis"], "venue": "Proc. IEEE Conf. Comput. Intell. Games, 2009, pp. 132-139.", "citeRegEx": "17", "shortCiteRegEx": null, "year": 2009}, {"title": "Towards automatic personalized content generation for platform games", "author": ["N. Shaker", "G.N. Yannakakis", "J Togelius"], "venue": "Proc. Artif. Intell. Interact. Digital Entertain., 2010.", "citeRegEx": "18", "shortCiteRegEx": null, "year": 2010}, {"title": "Towards challenge balancing for personalised game spaces", "author": ["S. Bakkes", "S. Whiteson"], "venue": "Proc. FDG Workshop on Procedural Content Generation, 2014.", "citeRegEx": "19", "shortCiteRegEx": null, "year": 2014}, {"title": "Polymorph: A model for dynamic level generation", "author": ["M. Jennings-Teats", "G. Smith", "N. Wardrip-Fruin"], "venue": "Proc. Artif. Intell. Interact. Digital Entertain., 2010, pp. 138-143.", "citeRegEx": "20", "shortCiteRegEx": null, "year": 2010}, {"title": "Evolving personalized content for super mario bros using grammatical evolution", "author": ["N. Shaker", "G.N. Yannakakis", "J. Togelius", "M. Nicolau", "M. ONeill"], "venue": "Proc. Artif. Intell. Interact. Digital Entertain., 2012.", "citeRegEx": "21", "shortCiteRegEx": null, "year": 2012}, {"title": "Sampling (second edition)", "author": ["S.K. Thompson"], "venue": "New York: Wiley,", "citeRegEx": "22", "shortCiteRegEx": "22", "year": 2002}, {"title": "CURE: an efficient clustering algorithm for large databases", "author": ["S. Guha", "R. Rastogi", "K. Shim"], "venue": "ACM SIGMOD Record, vol. 27, no. 2, 1998.", "citeRegEx": "23", "shortCiteRegEx": null, "year": 1998}, {"title": "Combining multiple clusterings using evidence accumulation", "author": ["A.L.N. Fred", "A.K. Jain"], "venue": "IEEE Trans. Pattern Anal. Mach. Intell., vol. 27, no. 6, pp. 835-850, 2005.", "citeRegEx": "24", "shortCiteRegEx": null, "year": 2005}, {"title": "Using random forest to learn imbalanced data", "author": ["C. Chen", "A. Liaw", "L. Breiman"], "venue": "Univ. California, Berkeley, CA, Tech. Rep., 2004.", "citeRegEx": "26", "shortCiteRegEx": null, "year": 2004}, {"title": "Random forests", "author": ["L. Breiman"], "venue": "Machine learning, vol. 45, no. 1, pp. 5-32, 2001.", "citeRegEx": "27", "shortCiteRegEx": null, "year": 2001}, {"title": "A Markovian decision process", "author": ["R. Bellman"], "venue": "Journal of Mathematics and Mechanics, vol. 6, pp. 679-684, 1957.", "citeRegEx": "28", "shortCiteRegEx": null, "year": 1957}, {"title": "On the likelihood that one unknown probability exceeds another in view of the evidence of two samples", "author": ["W.R. Thompson"], "venue": "Biometrika, pp. 285-294, 1933.", "citeRegEx": "29", "shortCiteRegEx": null, "year": 1933}, {"title": "Rapid skill capture in a firstperson shooter", "author": ["D. Buckley", "K. Chen", "J. Knowles"], "venue": "IEEE Trans. Comput. Intell. AI in Games, vol. 8, 2016. (to appear)", "citeRegEx": "32", "shortCiteRegEx": null, "year": 2016}], "referenceMentions": [{"referenceID": 0, "context": "As a potential solution, procedural content generation (PCG) [1] is a game design and development methodology that aims generating game content automatically via algorithms, which", "startOffset": 61, "endOffset": 64}, {"referenceID": 0, "context": "games to first person shooter (see [1] for review) with different styles, e.", "startOffset": 35, "endOffset": 38}, {"referenceID": 0, "context": ", online or offline content generation [1].", "startOffset": 39, "endOffset": 42}, {"referenceID": 1, "context": "been proposed, there are still some open challenges for content generation, including game quality assurance [2], generation efficiency [1], and controllability [2].", "startOffset": 109, "endOffset": 112}, {"referenceID": 0, "context": "been proposed, there are still some open challenges for content generation, including game quality assurance [2], generation efficiency [1], and controllability [2].", "startOffset": 136, "endOffset": 139}, {"referenceID": 1, "context": "been proposed, there are still some open challenges for content generation, including game quality assurance [2], generation efficiency [1], and controllability [2].", "startOffset": 161, "endOffset": 164}, {"referenceID": 2, "context": "Super Mario Bros (SMB), a classic 2D platform game, has become a popular test bed for PCG-related researches [3].", "startOffset": 109, "endOffset": 112}, {"referenceID": 3, "context": "In recent years, several SMB level generators have been developed for level generation track of the Mario AI Championship [4] as well as presented in publications [5]\u2013 [10].", "startOffset": 122, "endOffset": 125}, {"referenceID": 4, "context": "In recent years, several SMB level generators have been developed for level generation track of the Mario AI Championship [4] as well as presented in publications [5]\u2013 [10].", "startOffset": 163, "endOffset": 166}, {"referenceID": 9, "context": "In recent years, several SMB level generators have been developed for level generation track of the Mario AI Championship [4] as well as presented in publications [5]\u2013 [10].", "startOffset": 168, "endOffset": 172}, {"referenceID": 1, "context": "The quality of procedural SMB levels is generally not as high as handcrafted levels in real games [2]; levels generated by existing generators often contain aesthetically unappealing items (e.", "startOffset": 98, "endOffset": 101}, {"referenceID": 5, "context": ", [6], [9]) is computationally expensive; it may take several seconds to generate a complete game level.", "startOffset": 2, "endOffset": 5}, {"referenceID": 8, "context": ", [6], [9]) is computationally expensive; it may take several seconds to generate a complete game level.", "startOffset": 7, "endOffset": 10}, {"referenceID": 10, "context": ", linearity [11] and density [7]) are not directly controllable in a number of existing level", "startOffset": 12, "endOffset": 16}, {"referenceID": 6, "context": ", linearity [11] and density [7]) are not directly controllable in a number of existing level", "startOffset": 29, "endOffset": 32}, {"referenceID": 4, "context": ", [5]) in order to evaluate or control the procedural levels [2].", "startOffset": 2, "endOffset": 5}, {"referenceID": 1, "context": ", [5]) in order to evaluate or control the procedural levels [2].", "startOffset": 61, "endOffset": 64}, {"referenceID": 11, "context": "However, those heuristic rules may be difficult to formulate [12] and could even slow down the level generation [13].", "startOffset": 61, "endOffset": 65}, {"referenceID": 12, "context": "However, those heuristic rules may be difficult to formulate [12] and could even slow down the level generation [13].", "startOffset": 112, "endOffset": 116}, {"referenceID": 13, "context": "work [14] and other existing works [5]\u2013[10], we explore the content space in SMB from a different perspective by taking short game segments into account.", "startOffset": 5, "endOffset": 9}, {"referenceID": 4, "context": "work [14] and other existing works [5]\u2013[10], we explore the content space in SMB from a different perspective by taking short game segments into account.", "startOffset": 35, "endOffset": 38}, {"referenceID": 9, "context": "work [14] and other existing works [5]\u2013[10], we explore the content space in SMB from a different perspective by taking short game segments into account.", "startOffset": 39, "endOffset": 43}, {"referenceID": 4, "context": ", [5]) in terms of quality assurance, efficiency and controllability, which is discussed later on.", "startOffset": 2, "endOffset": 5}, {"referenceID": 0, "context": "First of all, many SMB level generators were developed under the search-based procedural content generation (SBPCG) framework [1].", "startOffset": 126, "endOffset": 129}, {"referenceID": 5, "context": "[6] proposed a search-based SMB level generator for level generation track of the Mario AI Championship [4].", "startOffset": 0, "endOffset": 3}, {"referenceID": 3, "context": "[6] proposed a search-based SMB level generator for level generation track of the Mario AI Championship [4].", "startOffset": 104, "endOffset": 107}, {"referenceID": 12, "context": "However, their level generator has to take several minutes to generate 50 levels together due to the huge content space and the use of multiple evaluation functions that may slow down the level generation [13].", "startOffset": 205, "endOffset": 209}, {"referenceID": 5, "context": ", [6]\u2013[8], suffer from the same problems and some of them do not adequately address the quality assurance issue pointed out in Sect.", "startOffset": 2, "endOffset": 5}, {"referenceID": 7, "context": ", [6]\u2013[8], suffer from the same problems and some of them do not adequately address the quality assurance issue pointed out in Sect.", "startOffset": 6, "endOffset": 9}, {"referenceID": 14, "context": "Parameterized Notch generator [15] is a typical constructive level generator for SMB.", "startOffset": 30, "endOffset": 34}, {"referenceID": 11, "context": "In comparison to the SBPCG approaches, creating constructive rules might be even more difficult [12]; constructive rules are often more complicated than observable constraints.", "startOffset": 96, "endOffset": 100}, {"referenceID": 3, "context": ", [4], [10], [16], [17].", "startOffset": 2, "endOffset": 5}, {"referenceID": 9, "context": ", [4], [10], [16], [17].", "startOffset": 7, "endOffset": 11}, {"referenceID": 15, "context": ", [4], [10], [16], [17].", "startOffset": 13, "endOffset": 17}, {"referenceID": 16, "context": ", [4], [10], [16], [17].", "startOffset": 19, "endOffset": 23}, {"referenceID": 4, "context": "developed the Launchpad level generator [5] for generic 2D platform games including SMB.", "startOffset": 40, "endOffset": 43}, {"referenceID": 6, "context": ", density [7], leniency [11] and linearity [11]).", "startOffset": 10, "endOffset": 13}, {"referenceID": 10, "context": ", density [7], leniency [11] and linearity [11]).", "startOffset": 24, "endOffset": 28}, {"referenceID": 10, "context": ", density [7], leniency [11] and linearity [11]).", "startOffset": 43, "endOffset": 47}, {"referenceID": 4, "context": ", [5].", "startOffset": 2, "endOffset": 5}, {"referenceID": 11, "context": "Content adaptation is demanded in generating the personalized content to optimize cognitive/affective experience during gameplay [12].", "startOffset": 129, "endOffset": 133}, {"referenceID": 11, "context": "In general, such techniques can be applied to different types of game content ranging from non-player character behaviour or game AI to game geometry (see [12] for a review).", "startOffset": 155, "endOffset": 159}, {"referenceID": 16, "context": "A typical example of geometry adaptation is the personalized level generator in SMB [17], [18].", "startOffset": 84, "endOffset": 88}, {"referenceID": 17, "context": "A typical example of geometry adaptation is the personalized level generator in SMB [17], [18].", "startOffset": 90, "endOffset": 94}, {"referenceID": 16, "context": "Similar to this work [17], [18], other geometry adaptation methods in SMB, e.", "startOffset": 21, "endOffset": 25}, {"referenceID": 17, "context": "Similar to this work [17], [18], other geometry adaptation methods in SMB, e.", "startOffset": 27, "endOffset": 31}, {"referenceID": 3, "context": ", [4], [19]\u2013[21], are also subject to the same limitations.", "startOffset": 2, "endOffset": 5}, {"referenceID": 18, "context": ", [4], [19]\u2013[21], are also subject to the same limitations.", "startOffset": 7, "endOffset": 11}, {"referenceID": 20, "context": ", [4], [19]\u2013[21], are also subject to the same limitations.", "startOffset": 12, "endOffset": 16}, {"referenceID": 5, "context": "Thus, controlling the level generation may be rather complicated and difficult [6].", "startOffset": 79, "endOffset": 82}, {"referenceID": 4, "context": "posed into a number of segments as evident in segment-based level generators [5].", "startOffset": 77, "endOffset": 80}, {"referenceID": 0, "context": "For quality assurance, there are generally two methodologies in developing such a mechanism in PCG [1], [14]: deductive vs.", "startOffset": 99, "endOffset": 102}, {"referenceID": 13, "context": "For quality assurance, there are generally two methodologies in developing such a mechanism in PCG [1], [14]: deductive vs.", "startOffset": 104, "endOffset": 108}, {"referenceID": 13, "context": "On the other hand, a learning-based PCG (LBPCG) framework [14] was recently proposed where an inductive methodology, i.", "startOffset": 58, "endOffset": 62}, {"referenceID": 5, "context": "Motivated by the previous work [6], we employ a list of design elements as our content space representation where a design element refers to an atomic unit used in a procedural level generation [1], [6], e.", "startOffset": 31, "endOffset": 34}, {"referenceID": 0, "context": "Motivated by the previous work [6], we employ a list of design elements as our content space representation where a design element refers to an atomic unit used in a procedural level generation [1], [6], e.", "startOffset": 194, "endOffset": 197}, {"referenceID": 5, "context": "Motivated by the previous work [6], we employ a list of design elements as our content space representation where a design element refers to an atomic unit used in a procedural level generation [1], [6], e.", "startOffset": 199, "endOffset": 202}, {"referenceID": 5, "context": "Such representation is similar to the previous work [6].", "startOffset": 52, "endOffset": 55}, {"referenceID": 5, "context": "Motivated by the previous work [6], [7], we adapt a class of rules presented in [6] for our requirement.", "startOffset": 31, "endOffset": 34}, {"referenceID": 6, "context": "Motivated by the previous work [6], [7], we adapt a class of rules presented in [6] for our requirement.", "startOffset": 36, "endOffset": 39}, {"referenceID": 5, "context": "Motivated by the previous work [6], [7], we adapt a class of rules presented in [6] for our requirement.", "startOffset": 80, "endOffset": 83}, {"referenceID": 13, "context": "Inspired by the LBPCG work [14], we would learn a quality evaluation function from annotated game segments to remove unplayable/unacceptable segments.", "startOffset": 27, "endOffset": 31}, {"referenceID": 13, "context": "Motivated by the success in the LBPCG work [14], we conduct clustering analysis on the data set and further employ active learning based on the clustering results to minimize a game developer\u2019s efforts in data annotation.", "startOffset": 43, "endOffset": 47}, {"referenceID": 21, "context": "1) Sampling: For sampling, we apply the simple random sampling with replacement [22], an unbiased sampling technique, to the tailored content space for a manageable data set.", "startOffset": 80, "endOffset": 84}, {"referenceID": 21, "context": "The size of data set is determined via the sample size determination (SSD) algorithm suggested in [22].", "startOffset": 98, "endOffset": 102}, {"referenceID": 22, "context": "2) Clustering: We apply the CURE algorithm [23] on the sampled game set for clustering analysis since this hierarchical", "startOffset": 43, "endOffset": 47}, {"referenceID": 23, "context": "of clusters is automatically decided based on the longest kcluster lifetime [24].", "startOffset": 76, "endOffset": 80}, {"referenceID": 22, "context": "The rest of parameters are set to defaults suggested in [23]; i.", "startOffset": 56, "endOffset": 60}, {"referenceID": 24, "context": "By looking into several state-of-the-art classification techniques, we found that the weighted random forests(WRFs) [26], a cost-sensitive oblique random forests [27] classifier, fully meet our requirements for active learning.", "startOffset": 116, "endOffset": 120}, {"referenceID": 25, "context": "By looking into several state-of-the-art classification techniques, we found that the weighted random forests(WRFs) [26], a cost-sensitive oblique random forests [27] classifier, fully meet our requirements for active learning.", "startOffset": 162, "endOffset": 166}, {"referenceID": 24, "context": "In our work, the parameters of WRFs [26] are set via validation as follows: 2:1, 50, 5, 10 and 9 for the cost ratio, the number of trees, the number of combined features, the number of feature groups selected at each node, and depth of trees, respectively.", "startOffset": 36, "endOffset": 40}, {"referenceID": 6, "context": ", density [7], leniency [11] and linearity [11].", "startOffset": 10, "endOffset": 13}, {"referenceID": 10, "context": ", density [7], leniency [11] and linearity [11].", "startOffset": 24, "endOffset": 28}, {"referenceID": 10, "context": ", density [7], leniency [11] and linearity [11].", "startOffset": 43, "endOffset": 47}, {"referenceID": 6, "context": "Motivated by the previous works [7], [11], we employ three controllable level generation parameters, i.", "startOffset": 32, "endOffset": 35}, {"referenceID": 10, "context": "Motivated by the previous works [7], [11], we employ three controllable level generation parameters, i.", "startOffset": 37, "endOffset": 41}, {"referenceID": 26, "context": "This is naturally a sequential decision process and we would formulate it as a Markovian decision process (MDP) [28].", "startOffset": 112, "endOffset": 116}, {"referenceID": 27, "context": "To solve this optimization problem, we employ the Thompson sampling [29], an effective and efficient heuristic method used in binary reward case in MDP.", "startOffset": 68, "endOffset": 72}, {"referenceID": 3, "context": "The game engine adopted in our experiments is a modified version of the opensource Infinite Mario Bros used in the Mario AI Championship [4], [30].", "startOffset": 137, "endOffset": 140}, {"referenceID": 25, "context": "In this experiment, we use the permutation test pertaining to RFs [27] to measure the importance of design elements in the CP learning.", "startOffset": 66, "endOffset": 70}, {"referenceID": 4, "context": ", [5]\u2013[9].", "startOffset": 2, "endOffset": 5}, {"referenceID": 8, "context": ", [5]\u2013[9].", "startOffset": 6, "endOffset": 9}, {"referenceID": 10, "context": "1) Expressive Range: Expressive range refers to the range and variation of procedural levels according to an evaluation metric [11] that measures the property of procedural levels.", "startOffset": 127, "endOffset": 131}, {"referenceID": 10, "context": "For evaluation, we use linearity [11], density [7], leniency [11] and compression distance [7] as our metrics.", "startOffset": 33, "endOffset": 37}, {"referenceID": 6, "context": "For evaluation, we use linearity [11], density [7], leniency [11] and compression distance [7] as our metrics.", "startOffset": 47, "endOffset": 50}, {"referenceID": 10, "context": "For evaluation, we use linearity [11], density [7], leniency [11] and compression distance [7] as our metrics.", "startOffset": 61, "endOffset": 65}, {"referenceID": 6, "context": "For evaluation, we use linearity [11], density [7], leniency [11] and compression distance [7] as our metrics.", "startOffset": 91, "endOffset": 94}, {"referenceID": 12, "context": "For linearity, we use the method suggested in [13] to find a line that fits the profile of a procedural level, and the coefficient of determination r is used to estimate the degree of linearity.", "startOffset": 46, "endOffset": 50}, {"referenceID": 6, "context": "For density, we count the number of all possible standing positions in a game level [7].", "startOffset": 84, "endOffset": 87}, {"referenceID": 4, "context": "For leniency, we assign a value to each type of game elements as same as used in [5], [7] (i.", "startOffset": 81, "endOffset": 84}, {"referenceID": 6, "context": "For leniency, we assign a value to each type of game elements as same as used in [5], [7] (i.", "startOffset": 86, "endOffset": 89}, {"referenceID": 6, "context": "Finally, the normalized compression distance (NCD) [7] is employed to measure the dissimilarity between two game levels; the higher this distance the more dissimilar two levels.", "startOffset": 51, "endOffset": 54}, {"referenceID": 15, "context": "II, including Notch [16], Parameterized Notch (PN) [15], Grammar Evolution (GE) [7] and Launchpad generators [5].", "startOffset": 20, "endOffset": 24}, {"referenceID": 14, "context": "II, including Notch [16], Parameterized Notch (PN) [15], Grammar Evolution (GE) [7] and Launchpad generators [5].", "startOffset": 51, "endOffset": 55}, {"referenceID": 6, "context": "II, including Notch [16], Parameterized Notch (PN) [15], Grammar Evolution (GE) [7] and Launchpad generators [5].", "startOffset": 80, "endOffset": 83}, {"referenceID": 4, "context": "II, including Notch [16], Parameterized Notch (PN) [15], Grammar Evolution (GE) [7] and Launchpad generators [5].", "startOffset": 109, "endOffset": 112}, {"referenceID": 12, "context": "For fairness, we adopt the experimental protocols suggested in [13].", "startOffset": 63, "endOffset": 67}, {"referenceID": 0, "context": "The scores measured with a metric are normalized to the range of [0,1].", "startOffset": 65, "endOffset": 70}, {"referenceID": 4, "context": "In general, controllability can be reflected in the expressive ranges of procedural levels generated with different level generation parameter settings [5].", "startOffset": 152, "endOffset": 155}, {"referenceID": 17, "context": "tation for DDA, we conduct simulations with sophisticated Mario controllers of different types instead of human players as suggested in [18].", "startOffset": 136, "endOffset": 140}, {"referenceID": 17, "context": "The use of agents for DDA test may benefit from stable agents\u2019 behavior, their diversified playing styles and a wide range of skills [18].", "startOffset": 133, "endOffset": 137}, {"referenceID": 1, "context": "It is well known that automatically generated procedural SMB levels is generally worse than those handcrafted levels [2].", "startOffset": 117, "endOffset": 120}, {"referenceID": 4, "context": "It works efficiently with game developers\u2019 judgment on quality of training examples instead of handcrafting constraints and deductive rules based on the understanding of an entire content space [5]\u2013[9], [15]\u2013 [17].", "startOffset": 194, "endOffset": 197}, {"referenceID": 8, "context": "It works efficiently with game developers\u2019 judgment on quality of training examples instead of handcrafting constraints and deductive rules based on the understanding of an entire content space [5]\u2013[9], [15]\u2013 [17].", "startOffset": 198, "endOffset": 201}, {"referenceID": 14, "context": "It works efficiently with game developers\u2019 judgment on quality of training examples instead of handcrafting constraints and deductive rules based on the understanding of an entire content space [5]\u2013[9], [15]\u2013 [17].", "startOffset": 203, "endOffset": 207}, {"referenceID": 16, "context": "It works efficiently with game developers\u2019 judgment on quality of training examples instead of handcrafting constraints and deductive rules based on the understanding of an entire content space [5]\u2013[9], [15]\u2013 [17].", "startOffset": 209, "endOffset": 213}, {"referenceID": 5, "context": "It is noticed that similar design elements were used as content representation in previous works [6], [7] where those attributes are specified at an entire procedural level.", "startOffset": 97, "endOffset": 100}, {"referenceID": 6, "context": "It is noticed that similar design elements were used as content representation in previous works [6], [7] where those attributes are specified at an entire procedural level.", "startOffset": 102, "endOffset": 105}, {"referenceID": 11, "context": "those rules or evaluation functions have to be handcrafted with a great effort [12], [31], it may work less efficiently especially for generating procedural levels of a considerable length [13].", "startOffset": 79, "endOffset": 83}, {"referenceID": 12, "context": "those rules or evaluation functions have to be handcrafted with a great effort [12], [31], it may work less efficiently especially for generating procedural levels of a considerable length [13].", "startOffset": 189, "endOffset": 193}, {"referenceID": 5, "context": "Thus, our approach significantly distinguishes those working at a global level [6], [7] in terms of content representation and", "startOffset": 79, "endOffset": 82}, {"referenceID": 6, "context": "Thus, our approach significantly distinguishes those working at a global level [6], [7] in terms of content representation and", "startOffset": 84, "endOffset": 87}, {"referenceID": 0, "context": "existing taxonomy [1].", "startOffset": 18, "endOffset": 21}, {"referenceID": 4, "context": ", [5]\u2013[8]) or constructive (e.", "startOffset": 2, "endOffset": 5}, {"referenceID": 7, "context": ", [5]\u2013[8]) or constructive (e.", "startOffset": 6, "endOffset": 9}, {"referenceID": 9, "context": ", [10], [15]\u2013[17]) SMB", "startOffset": 2, "endOffset": 6}, {"referenceID": 14, "context": ", [10], [15]\u2013[17]) SMB", "startOffset": 8, "endOffset": 12}, {"referenceID": 16, "context": ", [10], [15]\u2013[17]) SMB", "startOffset": 13, "endOffset": 17}, {"referenceID": 18, "context": "For real-time DDA, our algorithm seems to resemble some previous works [19], [20].", "startOffset": 71, "endOffset": 75}, {"referenceID": 19, "context": "For real-time DDA, our algorithm seems to resemble some previous works [19], [20].", "startOffset": 77, "endOffset": 81}, {"referenceID": 18, "context": "While a CP of certain difficulty is achieved by setting a controllable parameter in ours, a proper segment in theirs has to be generated via a rhythm-based mechanism or a set of constructive rules [19], [20].", "startOffset": 197, "endOffset": 201}, {"referenceID": 19, "context": "While a CP of certain difficulty is achieved by setting a controllable parameter in ours, a proper segment in theirs has to be generated via a rhythm-based mechanism or a set of constructive rules [19], [20].", "startOffset": 203, "endOffset": 207}, {"referenceID": 28, "context": ", [32]); (c) it is unclear how to adapt content via CPs in the presence of subjective feedback on an entire", "startOffset": 2, "endOffset": 6}, {"referenceID": 16, "context": ", [17], [18], [21]), which has been studied under the EDPCG framework [12].", "startOffset": 2, "endOffset": 6}, {"referenceID": 17, "context": ", [17], [18], [21]), which has been studied under the EDPCG framework [12].", "startOffset": 8, "endOffset": 12}, {"referenceID": 20, "context": ", [17], [18], [21]), which has been studied under the EDPCG framework [12].", "startOffset": 14, "endOffset": 18}, {"referenceID": 11, "context": ", [17], [18], [21]), which has been studied under the EDPCG framework [12].", "startOffset": 70, "endOffset": 74}, {"referenceID": 18, "context": ", [19], [20]), their work entirely relies on the self-reported feedback on each short segment, which severely interrupts the gameplay experience [12].", "startOffset": 2, "endOffset": 6}, {"referenceID": 19, "context": ", [19], [20]), their work entirely relies on the self-reported feedback on each short segment, which severely interrupts the gameplay experience [12].", "startOffset": 8, "endOffset": 12}, {"referenceID": 11, "context": ", [19], [20]), their work entirely relies on the self-reported feedback on each short segment, which severely interrupts the gameplay experience [12].", "startOffset": 145, "endOffset": 149}], "year": 2015, "abstractText": "Procedural content generation (PCG) is of great interest to game design and development as it generates game content automatically. Motivated by the recent learning-based PCG framework and other existing PCG works, we propose an alternative approach to online content generation and adaptation in Super Mario Bros (SMB). Unlike most of existing works in SMB, our approach exploits the synergy between rule-based and learning-based methods to produce constructive primitives, quality yet controllable game segments in SMB. As a result, a complete quality game level can be generated online by integrating relevant constructive primitives via controllable parameters regarding geometrical features and procedure-level properties. Also the adaptive content can be generated in real time by dynamically selecting proper constructive primitives via an adaptation criterion, e.g., dynamic difficulty adjustment (DDA). Our approach is of several favorable properties in terms of content quality assurance, generation efficiency and controllability. Extensive simulation results demonstrate that the proposed approach can generate controllable yet quality game levels online and adaptable content for DDA in real time.", "creator": "LaTeX with hyperref package"}}}