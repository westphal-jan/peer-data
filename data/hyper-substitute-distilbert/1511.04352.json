{"id": "1511.04352", "review": {"conference": "arxiv", "VERSION": "v1", "DATE_OF_SUBMISSION": "13-Nov-2015", "title": "Introduzione all'Intelligenza Artificiale", "abstract": "the description presents relatively abstract applying artificial induction ( soc ) in an en - complete most precise form. the paper focuses only the broad aspects from the procedure, presenting the appropriate methodology used among ai systems groped in symbolic knowledge subsymbolic. the last part when the paper is devoted to their discussion ongoing among experts in the field and researchers public at large about examining the gain and disadvantages of fuzzy theory in particular on discovering possible extensions. the personal notes of a author on this subject concludes here paper.", "histories": [["v1", "Fri, 13 Nov 2015 16:40:47 GMT  (129kb,D)", "http://arxiv.org/abs/1511.04352v1", "27 pages, in Italian"], ["v2", "Sun, 16 Oct 2016 17:55:34 GMT  (129kb,D)", "http://arxiv.org/abs/1511.04352v2", "27 pages, in Italian"]], "COMMENTS": "27 pages, in Italian", "reviews": [], "SUBJECTS": "cs.AI", "authors": ["fabrizio riguzzi"], "accepted": false, "id": "1511.04352"}, "pdf": {"name": "1511.04352.pdf", "metadata": {"source": "CRF", "title": "Introduzione all\u2019Intelligenza Artificiale\u2217", "authors": ["Fabrizio Riguzzi"], "emails": ["fabrizio.riguzzi@unife.it"], "sections": [{"heading": null, "text": "Introduzione all\u2019Intelligenza Artificiale\u2217\nFabrizio Riguzzi Dipartimento di Matematica e Informatica \u2013 Universit\u00e0 di Ferrara\nVia Saragat 1, I-44122, Ferrara, Italy fabrizio.riguzzi@unife.it\ngennaio 2006\nSommario\nL\u2019articolo presenta un\u2019introduzione all\u2019Intelligenza Artificiale (IA) in forma divulgativa e informale ma precisa. L\u2019articolo affronta prevalentemente gli aspetti informatici della disciplina, presentando varie tecniche usate nei sistemi di IA e dividendole in simboliche e subsimboliche. L\u2019articolo si conclude presentando il dibattito in corso sull\u2019IA e in particolare sui vantaggi e i pericoli che sono stati individuati, terminando con l\u2019opinione dell\u2019autore al riguardo."}, {"heading": "1 Introduzione", "text": "Il termine Intelligenza Artificiale (d\u2019ora in avanti IA) \u00e8 stato inventato da John McCarthy nel 1956, in occasione di un seminario di due mesi (da lui organizzato al Dartmouth College di Hanover, New Hampshire, USA) che ebbe il merito di far conoscere tra loro 10 studiosi (su teoria degli automi, reti neurali e intelligenza) statunitensi, e di dare l\u2019imprimatur al termine \u201cIntelligenza Artificiale\u201d come nome ufficiale del nuovo campo di ricerca.\nDa allora l\u2019IA si \u00e8 affermata ed evoluta; oggi \u00e8 riconosciuta come branca autonoma, sebbene connessa a informatica, matematica, scienze cognitive, neurobiologia e filosofia.\nMolte definizioni sono state date di questa materia: esse differiscono per i compiti svolti dalle macchine che l\u2019IA cerca di costruire. Tali compiti possono essere classificati secondo due dimensioni ortogonali [RN05]: macchine che pensano o agiscono, e macchine che simulano gli umani (o che si comportano razionalmente). In tutto quattro classi, a seconda che le macchine: pensino\n\u2217Questo articolo \u00e8 stato pubblicato sulla rivista Terre di Confine, Anno 2, Numero 1, gennaio 2006, http://www.terrediconfine.eu/introduzione-all-intelligenza-artificiale/\nar X\niv :1\n51 1.\n04 35\n2v 1\n[ cs\n.A I]\n1 3\nN ov\n2 01\n5\ncome umani, agiscano come umani, pensino razionalmente, agiscano razionalmente. Quattro approcci distinti alla ricerca nel campo dell\u2019IA, dunque, tutti attivamente perseguiti.\nL\u2019obiettivo dell\u2019approccio \u201cmacchine che pensano come umani\u201d \u00e8 quello di riprodurre il ragionamento umano nelle macchine. Pu\u00f2 essere fatto a due livelli: imitando i metodi di ragionamento o replicando il funzionamento del cervello. Nel primo caso, la scienza cognitiva ci fornisce un importante punto di partenza, ottenuto mediante introspezione ed esperimenti psicologici. Nel secondo caso, \u00e8 la neurobiologia a fornirci un modello adeguato. Questo primo criterio si occupa quindi di produrre macchine automi che, oltre a comportarsi come umani, \u201cfunzionino\u201d come umani tali.\nL\u2019obiettivo dell\u2019approccio \u201cmacchine che si comportano come umani\u201d \u00e8 quello di realizzare macchine indistinguibili dagli uomini. Questa propriet\u00e0 \u00e8 stata meglio definita da Alan Turing che, in un suo articolo del 1950 [Tur50], ha proposto il test che prende il suo nome: un \u201cgiudice\u201d ha la facolt\u00e0 di porre a un \u201csoggetto\u201d domande per iscritto e, in base alle risposte, deve decidere se si tratta di un uomo o di una macchina. Al fine di superare il test di Turing, una macchina deve esibire le seguenti capacit\u00e0: \u2022 elaborazione del linguaggio naturale, al fine di comunicare efficacemente\nnella lingua del giudice; \u2022 rappresentazione della conoscenza, per memorizzare quello che sa o im-\npara; \u2022 ragionamento automatico, per inferire (produrre), a partire dalla propria\nconoscenza, le risposte al giudice; \u2022 apprendimento automatico, per aumentare la propria base di conoscenza.\nIl test di Turing non prevede interazione fisica tra il giudice e la macchina, non essendo necessaria. Volendo, si pu\u00f2 pensare a un test di Turing totale in cui, invece delle risposte scritte, il giudice riceve un segnale audio-video, ed ha la possibilit\u00e0 di passare degli oggetti alla macchina attraverso una feritoia. In questo caso la macchina deve esibire anche le seguenti capacit\u00e0: \u2022 visione artificiale, per riconoscere gli oggetti ricevuti; \u2022 robotica, per manipolarli; \u2022 elaborazione del linguaggio parlato, per comprendere le domande del giudice e per rispondere. Il test di Turing totale ricorda il test Voight-Kampf nel film Blade Runner con il quale i poliziotti distinguono gli androidi dagli esseri umani.\nL\u2019approccio \u201cmacchine che pensano razionalmente\u201d non si preoccupa che le macchine realizzate funzionino come umani, ma solo che seguano ragionamenti razionali, dove \u201crazionale\u201d \u00e8 definito in maniera precisa dalla matematica, anche tramite tecniche che gli esseri umani naturalmente non usano. Ad esempio la logica, cio\u00e8 lo studio di come effettuare ragionamenti inattaccabili. La logica svolge un importante ruolo nell\u2019IA, anche se le aspettative iniziali sono\nstate ridimensionate dai limiti pratici del suo uso, soprattutto in situazioni di conoscenza incompleta e/o incerta.\nL\u2019approccio \u201cmacchine che agiscono razionalmente\u201d usa la definizione di \u201cazione razionale\u201d fornita dall\u2019economia, ossia: selezione delle azioni che portano al migliore risultato, o al migliore risultato atteso nel caso ci siano elementi di impredicibilit\u00e0. L\u2019obiettivo di questo approccio \u00e8 quello di realizzare un agente, un\u2019entit\u00e0 in grado di agire in un ambiente al fine di raggiungere uno o pi\u00f9 obbiettivi. L\u2019agente utilizzer\u00e0 il ragionamento razionale per scegliere quali azioni compiere, ma in alcuni casi dovr\u00e0 reagire agli stimoli ambientali in maniera tanto veloce da \u201cscavalcare\u201d la scelta (ad esempio quando una inazione mettesse a rischio la sua esistenza). Se si tocca qualcosa che scotta, si reagisce ritirando immediatamente la mano, senza un ragionamento cosciente; allo stesso modo l\u2019agente, in certe situazioni, deve poter agire senza svolgere un ragionamento. Gli agenti possono essere di due tipi: solo software, e in questo caso si chiamano softbot, o sia hardware che software, chiamati allora robot. Nel caso dei softbot, l\u2019ambiente esterno in cui operano \u00e8 rappresentato da Internet, dove interagiscono con esseri umani e altri softbot. Questo, al momento, \u00e8 l\u2019approccio maggiormente perseguito, in quanto quello che promette i risultati di maggior utilit\u00e0 pratica.\nAl fine di presentare le varie tecniche proposte dall\u2019IA, le suddivideremo in due grandi classi: simboliche e subsimboliche. Le prime si propongono di automatizzare il ragionamento e l\u2019azione, rappresentando le situazioni oggetto di analisi tramite simboli comprensibili agli esseri umani, ed elaborandole mediante algoritmi. Le seconde, invece, non rappresentano esplicitamente la conoscenza in maniera direttamente comprensibile, e sono basate sulla riproduzione di fenomeni naturali."}, {"heading": "2 Tecniche simboliche", "text": "Tra le tecniche simboliche descriveremo la ricerca nello spazio degli stati, il ragionamento automatico e l\u2019apprendimento automatico."}, {"heading": "2.1 Ricerca nello spazio degli stati", "text": "Questa tecnica viene utilizzata quando si vuole scegliere una serie di azioni che portino da uno stato iniziale a uno o pi\u00f9 stati finali desiderati. Condizioni, affinch\u00e9 possa essere utilizzata, sono: che lo stato del mondo esterno possa essere rappresentato in maniera concisa (in forma simbolica), che le azioni disponibili possano essere espresse come regole per il passaggio da uno stato al successivo e che esista un test per stabilire se uno stato \u00e8 finale.\nVediamo un esempio di problema che pu\u00f2 essere trattato in questo modo. Nel gioco dell\u2019otto (o puzzle dell\u2019otto) si ha una scacchiera tre per tre, in cui otto caselle sono occupate da otto tessere numerate dall\u20191 all\u20198 e una casella \u00e8 vuota. Si parte da una configurazione iniziale casuale delle tessere,\n3 8 2\n1 5\n4 7 6\n1 2\n3 4 5\n6 7 8\na) b)\nFigura 1: Stati iniziale e finale del gioco dell\u2019otto.\ncome ad esempio quella rappresentata in Figura 1 a), e si vuole arrivare alla configurazione rappresentata in Figura 1 b).\nLe mosse possibili consistono nello spostare sulla casella vuota una tessera numerata ad essa adiacente. Per questo problema, lo \u201cstato\u201d consiste nella posizione delle otto tessere numerate: lo stato iniziale \u00e8 quello rappresentato in Figura 1 a), e il test per stabilire se si \u00e8 raggiunto uno stato finale verifica semplicemente che lo stato sia identico a quello di Figura 1 b).\nSi tratta di un problema che sembra richiedere intelligenza: un essere umano lo risolverebbe provando diverse mosse e cercando di prevederne il risultato. Il metodo di soluzione proposto dall\u2019IA consiste nel compiere una ricerca nello spazio dei possibili stati. A tal fine, si pu\u00f2 rappresentare lo \u201cspazio\u201d come un albero in cui ogni nodo corrisponde a uno \u201cstato\u201d. La radice dell\u2019albero \u00e8 lo stato iniziale, i figli di un nodo sono quegli stati che si possono raggiungere dallo stato associato al nodo applicando una sola mossa. Ad esempio, nel caso del gioco dell\u2019otto, lo spazio degli stati si pu\u00f2 rappresentare come l\u2019albero di Figura 2.\nIl problema \u00e8 risolto quando si \u00e8 trovato un percorso dallo stato iniziale a uno stato finale. Solitamente non basta trovare una soluzione ma si cerca quella che ha costo minimo. Occorre quindi definire un \u201ccosto\u201d: di norma si assegna un costo alle varie mosse, e il costo di un cammino si misura come somma dei costi delle mosse che lo compongono. Nel caso del gioco dell\u2019otto, ogni mossa costa 1, e si cerca la soluzione che richiede il numero minimo di mosse.\nCitiamo altri problemi che si possono risolvere con una ricerca nello spazio degli stati. Iniziamo da quelli \u201cgiocattolo\u201d, ovvero problemi che non hanno immediato interesse pratico.\nIl problema \u201cdei missionari e dei cannibali\u201d consiste nel far attraversare un fiume a 3 missionari e 3 cannibali, utilizzando una barca ed evitando che i primi mangino i secondi (quando li superano in numero su una delle due sponde). La barca pu\u00f2 contenere al massimo due persone alla volta e, per muoversi da una sponda all\u2019altra del fiume, dev\u2019essere guidata da almeno una persona. Lo stato di questo problema pu\u00f2 essere rappresentato utilizzando una terna di numeri, nella quale i primi due quantifichino i missionari e i cannibali sulla sponda iniziale, e il terzo equivalga a: 1 se la barca \u00e8 sulla sponda iniziale, e 0 se \u00e8 sull\u2019altra. Lo stato iniziale \u00e8 (3,3,1), lo stato finale \u00e8 (0,0,0) e un possibile stato (2,2,1) indica che sulla sponda iniziale ci sono due missionari e due cannibali e che la barca \u00e8 sulla sponda iniziale. Le operazioni\n3 8 2 1 5\n4 7 6\n8 2 3 1 5 4 7 6\n3 8 2 4 1 5\n7 6\n3 8 2 1 5 4 7 6\n3 8 3 1 5\n4 7 6\n3 8 2 4 1 5 7 6 . .. . . . . . . . . . . . . .\n. . . .. . . .\nFigura 2: Spazio degli stati del gioco dell\u2019otto.\npossibili sono cinque: attraversa il fiume con 2 missionari, con 2 cannibali, con un missionario e un cannibale, con un solo cannibale o con un solo missionario. Non tutte le operazioni sono consentite in ogni stato: ad esempio, a partire dallo stato (2,2,1) non \u00e8 possibile applicare l\u2019operazione \u201cattraversa il fiume con un missionario\u201d perch\u00e8 sulla sponda iniziale rimarrebbero un missionario e due cannibali, e quindi i cannibali mangerebbero il missionario. Il costo, in questo caso, \u00e8 unitario per tutte le operazioni, si cercano quindi soluzioni con il minimo numero di attraversamenti del fiume.\nIl problema \u201cdelle n-regine\u201d consiste nel disporre, su una scacchiera n per n, n regine in modo che non si attacchino. Una regina attacca tutti i pezzi che si trovano sulla stessa colonna, riga o diagonale. Lo stato in questo caso \u00e8 rappresentato dalla posizione di i regine sulla scacchiera, con i che va da 0 a n. Lo stato iniziale \u00e8 rappresentato dalla scacchiera senza regine, lo stato finale da una scacchiera con n regine che non si attaccano a vicenda. Le mosse sono l\u2019aggiunta di una regina su una casella della scacchiera. In questo caso tutte le soluzioni hanno uguale costo perch\u00e8 richiedono tutte 8 mosse.\nPassiamo ai problemi reali, come quello di \u201ctrovare un percorso\u201d, che consiste nell\u2019andare da un luogo ad un altro con il minimo costo, transitando per luoghi intermedi, al collegamento tra ognuno dei quali \u00e8 associato un costo. Un esempio \u00e8 il tragitto in macchina da una citt\u00e0 ad un\u2019altra: i collegamenti sono le strade e il costo pu\u00f2 essere la distanza o il tempo necessario a percorrere quel collegamento. Se lo spostamento avviene in aereo, i collegamenti\n9 1 52 8 107643\nFigura 3: Strategia di ricerca in profondit\u00e0.\nsono i voli disponibili, e il costo pu\u00f2 essere il tempo o il prezzo del volo. Gli \u201cstati\u201d sono i luoghi, e le mosse disponibili consistono nell\u2019utilizzare uno dei collegamenti che partono dal luogo corrente per spostarsi in un altro luogo.\nAltro problema reale risolvibile mediante ricerca nello spazio degli stati \u00e8 quello del \u201ctour\u201d, cio\u00e8 un percorso che parta da un luogo e vi ritorni dopo aver \u201cvisitato\u201d almeno una volta tutti i luoghi di un insieme. Questo problema ha le stesse mosse del precedente ma stati diversi: qui lo stato \u00e8 costituito dal luogo corrente pi\u00f9 l\u2019insieme dei luoghi gi\u00e0 visitati. Lo stato finale \u00e8 quindi quello in cui il luogo corrente \u00e8 il luogo iniziale e l\u2019insieme di luoghi visitati corrisponde a quello specificato. Il costo pu\u00f2 essere, anche in questo caso, rappresentato dalla distanza, dal tempo o dal costo monetario delle mosse.\nCome si risolvono problemi di ricerca? Occorre generare e percorrere lo spazio di ricerca dal nodo iniziale fino a trovare uno stato che superi mediante verifica il test di stato finale; quando la verifica non viene superata, occorre \u201cespandere\u201d il nodo, generare i suoi successori utilizzando le possibili mosse od operatori, ed esaminare quelli, fino a trovarne uno che superi il test, o fino a che non si sia esplorato tutto lo spazio degli stati. Si genera cos\u00ec progressivamente l\u2019albero di ricerca.\nGli algoritmi per la ricerca nello spazio degli stati differiscono nella scelta del nodo da espandere (strategia di ricerca). Le due strategie pi\u00f9 comuni sono la ricerca in profondit\u00e0 e la ricerca in ampiezza.\nNella ricerca in profondit\u00e0 si espande sempre il nodo a profondit\u00e0 maggiore che sia stato generato ma non ancora espanso. Questo significa che si procede prima in profondit\u00e0 fino ad arrivare ad un nodo che non pu\u00f2 essere ulteriormente espanso o a trovare una soluzione. Nel primo caso si riparte dai nodi al livello precedente di profondit\u00e0 e cos\u00ec via. Nella ricerca in ampiezza invece si espandono sempre i nodi a profondit\u00e0 minore che siano stati generati ma non ancora espansi. In questo caso si espande prima la radice dell\u2019albero, poi tutti i suoi figli, poi tutti i figli dei figli e cos\u00ec via. In Figura 3 \u00e8 rappresentato l\u2019ordine di espansione dei nodi di un albero secondo la strategia in profondit\u00e0, e in Figura 4 secondo la strategia in ampiezza.\nLo spazio di ricerca in realt\u00e0 pu\u00f2 strutturarsi anche in un \u201cgrafo\u201d, un albero nel quale un nodo pu\u00f2 essere raggiunto seguendo percorsi multipli. In\n9 1 32 4 108765\nFigura 4: Strategia di ricerca in ampiezza.\nquesto caso l\u2019esplorazione pu\u00f2 capitare in un nodo gi\u00e0 espanso in precendenza. \u00c8 importante accorgersene per non ripetere operazioni gi\u00e0 svolte, e non complicare un problema altrimenti risolvibile. Perci\u00f2 esistono algoritmi specifici che svolgono la ricerca in grafi anzich\u00e9 in alberi.\nLe strategie viste precedentemente sono dette non informate, in quanto non utilizzano criteri per scegliere quale nodo espandere quando ve ne siano pi\u00f9 di uno alla stessa profondit\u00e0. Strategie pi\u00f9 efficienti sono invece quelle informate, che, per scegliere, si basano su una conoscenza specifica del problema. Per esempio, la strategia best-first usa una funzione di valutazione f(n) che, dato un nodo n, restituisce un valore numerico; per primi sceglie i nodi con il valore f(n) pi\u00f9 basso.\nNella strategia best-first \u201cgolosa\u201d, f(n) viene scelta uguale ad una funzione h(n) che, dato un nodo n, restituisce una stima del costo del cammino pi\u00f9 economico da n ad un nodo finale. h(n) viene chiamata una funzione euristica, in quanto fornisce esclusivamente una stima, per difetto o per eccesso, non un valore certo.\nNella strategia A* (si legge \u201cA star\u201d) la funzione f(n) \u00e8 data dalla somma di due funzioni, g(n) e h(n). h(n) \u00e8 una funzione euristica come nel caso precedente, mentre g(n) indica il costo del percorso dallo stato iniziale al nodo n. Quindi f(n) in questo caso indica il costo stimato della soluzione pi\u00f9 economica che passa attraverso n. \u00c8 possibile dimostrare che, se h(n) rispetta una certa condizione, la strategia A* \u00e8 completa e ottimale; cio\u00e8, se esiste una soluzione, A* la trova, e al costo minimo. La condizione da rispettare \u00e8 che h(n) sia \u201cottimistica\u201d, ovvero che non valga mai pi\u00f9 del costo reale del cammino pi\u00f9 economico da n ad un nodo finale.\nTutti gli algoritmi visti finora presentano un\u2019architettura comune [Mel02]: essi hanno una memoria di lavoro per archiviare i risultati parziali, una serie di operatori associabili alle varie situazioni, e una strategia (o controllo), per stabilire quali di questi operatori siano applicabili, sceglierli (se pi\u00f9 di uno) e applicarli. Questa architettura, condivisa da molti sistemi di IA, \u00e8 descritta in Figura 5.\nIl tipo di ricerca considerata finora \u00e8 una ricerca \u201cin avanti\u201d (forward o data-driven), che parte dallo stato iniziale e termina in uno stato finale. \u00c8\nMemoria di lavoro\nOperatori applicabili\nOperatori\nMatching\nSelezione\nControllo\nFigura 5: Architettura di un sistema di intelligenza artificiale.\npossibile anche una ricerca che proceda in direzione opposta, \u201call\u2019indietro\u201d (backward o goal-driven), cio\u00e8 partendo dallo stato finale (o goal) e, applicando gli operatori in senso inverso, arrivando ad uno stato iniziale. In genere, conviene utilizzare la ricerca in avanti quando lo stato iniziale sia uno solo, o pochi, e gli stati finali possano essere molti e il fattore di ramificazione sia basso vicino allo stato iniziale; mentre \u00e8 preferibile la ricerca all\u2019indietro quando lo stato finale sia uno solo o pochi, e gli stati iniziali possano essere molti e il fattore di ramificazione sia basso vicino allo stato finale. Esiste infine un terzo tipo di ricerca, che si chiama \u201cbidirezionale\u201d o \u201cmista\u201d, in cui si procede contemporaneamente in avanti a partire dallo stato iniziale e all\u2019indietro a partire dal goal, terminando quando si incontra lo stesso stato nelle due direzioni. Questo tipo di ricerca ha il vantaggio di restituire due alberi finali, costruiti a partire dallo stato iniziale e da quello finale, che possono avere profondit\u00e0 pari alla met\u00e0 della profondit\u00e0 di un singolo albero finale costruito invece a partire dallo stato inziale o dallo stato finale. Dato che la dimensione dell\u2019albero cresce in maniera esponenziale con la profondit\u00e0, la somma delle dimensioni dei due alberi pu\u00f2 essere molto pi\u00f9 piccola della dimensione dell\u2019albero singolo.\nL\u2019approccio alla soluzione dei problemi trattato finora contempla che l\u2019agente intelligente possa prevedere gli effetti delle sue azioni. Il presupposto decade nel caso ci sia pi\u00f9 di un agente, umano o artificiale, nel sistema. In particolare, gli altri agenti potrebbero avere obiettivi in conflitto con quelli dell\u2019agente considerato. Si parla allora di \u201cgiochi\u201d.\nNei giochi di cui ci occuperemo esistono due giocatori che effettuano mosse a turno, l\u2019effetto delle azioni \u00e8 deterministico, e la somma delle utilit\u00e0 dei due giocatori al termine del gioco \u00e8 sempre 0, quindi se uno vince (utilit\u00e0 +1) necessariamente l\u2019altro perde (utilit\u00e0 -1). Inoltre sono giochi in cui si ha informazione perfetta: l\u2019effetto delle mosse \u00e8 direttamente visibile.\nEsempi sono gli scacchi, la dama, l\u2019othello e il go. Giochi a informazione imperfetta sono invece quelli con le carte, nei quali il giocatore non conosce ci\u00f2\nche ha in mano l\u2019avversario. Programmare un computer per giocare a scacchi \u00e8 stato uno dei primi obiettivi dell\u2019IA, e gi\u00e0 nel 1950 esistevano software del genere. I progressi raggiunti sono stati tali che l\u201911 maggio del 1997, per la prima volta nella storia, un computer ha battuto in un torneo il campione del mondo di scacchi Garry Kasparov, per 3,5 a 2,5. Il computer era Deep Blue della IBM. Per quanto riguarda la dama e l\u2019othello, le macchine hanno ormai distanziato gli esseri umani, mentre nel backgammon, come negli scacchi, lasciano loro qualche chanche in pi\u00f9. Ma l\u2019unico gioco che ancora resiste davvero \u00e8 il go, nel quale i computer hanno prestazioni da dilettante.\nGiocare pu\u00f2 essere visto come un problema di ricerca in cui gli stati sono rappresentati dalle configurazioni dei pezzi sul tavolo da gioco, lo stato iniziale \u00e8 rappresentato dalla configurazione di partenza dei pezzi, e le mosse possibili per ciascun giocatore sono quelle concesse dalle regole del gioco stesso. A partire da questi dati, si pu\u00f2 costruire dalla configurazione iniziale un albero, in questo modo: i figli della radice sono le configurazioni che risultano da una mossa del giocatore che muove per primo, i figli dei figli sono le configurazioni che risultano da una mossa dell\u2019altro giocatore, e cos\u00ec via. Quindi i nodi ai livelli dispari riguardano il primo giocatore, quelli ai livelli pari il secondo. L\u2019albero di ricerca pu\u00f2 essere ramificato fino a che non si raggiunga una configurazione finale, nella quale non sia pi\u00f9 possibile muovere.\nNel caso dei giochi, \u00e8 poi necessaria una funzione di utilit\u00e0 che assegna agli stati finali un valore numerico rispecchiante il risultato del gioco stesso: negli scacchi, ad esempio, i valori possono essere +1, -1 o 0, rispettivamente nel caso in cui abbia vinto il primo giocatore, il secondo oppure che la partita sia terminata con un pareggio. In altri giochi i punteggi potrebbero essere diversi; ad esempio, nel backgammon possono andare da +192 a -192. Valori alti dell\u2019utilit\u00e0 sono buoni per il primo giocatore, che chiameremo quindi \u201cmax\u201d, mentre valori bassi dell\u2019utilit\u00e0 sono buoni per il secondo giocatore, che chiameremo quindi \u201cmin\u201d.\nSupponiamo di essere il giocatore max: come selezioniamo la mossa da eseguire in una data configurazione? La soluzione consiste nel costruire l\u2019albero che ha quella configurazione come radice, fino ad arrivare alle configurazioni finali, assegnando poi a ognuna di esse il valore di utilit\u00e0 tramite la funzione di utilit\u00e0. Dopodich\u00e8 si assegna un ulteriore valore, che prende il nome di minimax, a tutti i nodi non finali partendo dal basso e procedendo verso l\u2019alto: se al livello del nodo tocca muovere a min, il minimax del nodo \u00e8 il minimo tra i valori di utilit\u00e0 dei figli; se al livello del nodo tocca muovere a max, il minimax del nodo \u00e8 il massimo tra i valori di utilit\u00e0 dei figli. Si ripete questo processo ricorsivamente, propagando cos\u00ec i valori di utilit\u00e0 verso la radice. In questo modo il minimax di un nodo rappresenta l\u2019utilit\u00e0 (per max) del nodo, supponendo che entrambi i giocatori giochino sempre al meglio. Questo equivale a supporre che min e max facciano sempre la mossa che gli conviene di pi\u00f9, ovvero quella che li conduce all\u2019utilit\u00e0 pi\u00f9 alta. Procedendo a ritroso, si arriva cos\u00ec ad assegnare un valore minimax a tutti i figli della radice. Il giocatore max eseguir\u00e0 la mossa che porta alla configurazione con il minimax pi\u00f9 alto.\nPurtroppo lo spazio di ricerca dei giochi, esclusi i pi\u00f9 semplici come il gioco del tris, \u00e8 enorme e non \u00e8 quindi possibile costruire l\u2019albero fino agli stati finali. Negli scacchi, \u00e8 stato stimato che il numero di configurazioni possibili sia dell\u2019ordine di 10120. In questi casi si costruisce l\u2019albero fino ad una profondit\u00e0 fissata m: le foglie dell\u2019albero allora non saranno necessariamente configurazioni finali, e quindi, in luogo dell\u2019utilit\u00e0, si assegna loro una stima dell\u2019utilit\u00e0, del tutto simila alla funzione euristica vista in precedenza, ottenuta sulla base della configurazione stessa tramite una funzione di valutazione. Questa funzione deve essere fortemente correlata con le possibilit\u00e0 del giocatore di vincere partendo da quella configurazione. Inoltre dev\u2019essere veloce da calcolare, perch\u00e9 la computazione va eseguita molte volte. Nel caso degli scacchi, un esempio di funzione di valutazione \u00e8 dato dalla somma dei valori materiali di ciascun pezzo di max meno la somma dei valori materali di ciascun pezzo di min, dove il valore materiale di un pezzo \u00e8 definito dai testi di scacchi e vale ad esempio 1 per un pedone, 3 per un alfiere o un cavallo, 5 per la torre e cos\u00ec via. Ovviamente le funzioni reali sono pi\u00f9 complicate.\nPer dare un\u2019idea dell\u2019importanza delle funzioni di valutazione: Deep Blue era in grado di esplorare circa 200 milioni (2 \u00b7 108) di posizioni al secondo [But02]. L\u2019esplorazione dell\u2019intero spazio di ricerca avrebbe dunque richiesto a Deep Blue 5 \u00b7 10111 secondi, ovvero 1095 miliardi di anni! Quindi la porzione dello spazio di ricerca effettivamente esplorata \u00e8 stata piccola, e sono state usate complesse e articolate funzioni di valutazione. Al confronto con Kasparov, per\u00f2, le funzioni di valutazione di Deep Blue sono semplici, se si pensa che lo scacchista russo, pur elaborando, secondo una stima, solo 3 posizioni al secondo, \u00e8 riuscito a dare del filo da torcere al computer! Per questo si dice che Deep Blue abbia usato per vincere la forze bruta, piuttosto che una intelligenza raffinata."}, {"heading": "2.2 Ragionamento automatico", "text": "Per ragionamento automatico s\u2019intende l\u2019utilizzo di conoscenza al fine di inferire nuova conoscenza. A questo scopo \u00e8 necessario rappresentare la conoscenza in un formato memorizzabile da un calcolatore, e utilizzabile per effettuare inferenze. Questi requisiti restringono il formato di rappresentazione a linguaggi formali, ovvero linguaggi con una sintassi e una semantica definiti in maniera precisa.\nUno dei linguaggi formali maggiormente studiati \u00e8 quello della logica. Essa ha le sue origini nella filosofia e nella matematica greca antica. Il padre fondatore della logica come disciplina autonoma pu\u00f2 essere considerato Aristotele (384-321 a.C. circa), mentre Crisippo di Soli (280-205 a.C. circa), della scuola stoica, defin\u00ec i connettivi logici, gli assiomi e le regole fondamentali della logica proposizionale.\nLa nascita della moderna logica matematica pu\u00f2 essere fatta risalire a George Boole (1815-1864), che nel 1847 pubblic\u00f2 un metodo per descrivere la teoria dei sillogismi aristotelici e la logica proposizionale sotto forma di equazioni algebriche, e propose un procedimento meccanico per la loro so-\nluzione. Gottlob Frege (1848-1925) fu il primo a sviluppare un sistema di assiomi e regole per la logica del primo ordine, superando cos\u00ec i limiti imposti dai sillogismi e dalla logica proposizionale.\nNel 1965 John Robinsono pubblic\u00f2 il metodo di risoluzione, che consente di automatizzare in maniera efficiente l\u2019inferenza deduttiva nella logica del primo ordine. Su questo metodo \u00e8 basata la programmazione logica, e il linguaggio Prolog (PROgramming in LOGic) in particolare, le cui basi furono gettate da alcuni ricercatori delle Universit\u00e0 di Edimburgo e Marsiglia nei primi anni \u201870. Soprattutto Robert Kowalski, a Edimburgo, si occup\u00f2 di definire i fondamenti teorici della programmazione logica, e propose una interpretazione procedurale delle formule logiche che consente di ridurre il processo di dimostrazione di un teorema ad un processo di computazione su un tradizionale elaboratore. Alain Colmerauer a Marsiglia fu il primo a realizzare, nel 1972, un interprete per il linguaggio Prolog.\nVediamo alcuni rudimenti della programmazione logica, cominciando dalla logica proposizionale. In essa, le unit\u00e0 elementari sono le proposizioni atomiche, cio\u00e8 affermazioni non ulteriormente scomponibili che possono essere vere o false. Le proposizioni arbitrarie o formule proposizionali sono ottenute dalle formule atomiche, combinandole mediante i connettivi logici: negazione, congiunzione, disgiunzione e implicazione.\nEsempi di proposizioni atomiche sono le affermazioni \u201cl\u2019erba \u00e8 bagnata\u201d e \u201coggi piove\u201d. Un esempio di formula proposizionale \u00e8 l\u2019espressione \u201cl\u2019erba \u00e8 bagnata se oggi piove\u201d che \u00e8 una implicazione. Nella logica proposizionale, si utilizzano lettere per indicare le proposizioni e simboli per i connettivi. Ad esempio, b per \u201cl\u2019erba \u00e8 bagnata\u201d, p per \u201coggi piove\u201d e \u2190 per l\u2019implicazione. La formula proposizionale composta, mostrata sopra, si pu\u00f2 dunque scrivere come\nb\u2190 p\nIn programmazione logica, si possono usare sequenze di lettere per rappresentare le proposizioni, e si usa il simbolo :- per l\u2019implicazione logica. Si pu\u00f2 quindi rappresentare la formula proposizionale composta come:\nerba_bagnata :- oggi_piove.\nIn questo caso la sequenza di lettere ci serve per ricordare il significato delle proposizioni.\nInferenze nella logica proposizionale possono essere compiute mediante regole di inferenza. La pi\u00f9 semplice \u00e8 il modus ponens che da p e b\u2190 p deriva b. Questa regola rappresenta un passo elementare di deduzione, ed \u00e8 corretta, nel senso che se sono vere le premesse allora \u00e8 vera anche la conclusione. Quindi se \u00e8 vero che \u201coggi piove\u201d ed \u00e8 vero che \u201cl\u2019erba \u00e8 bagnata se oggi piove\u201d, allora si pu\u00f2 concludere che \u201cl\u2019erba \u00e8 bagnata\u201d. In programmazione logica si scrive il seguente programma:\noggi_piove. erba_bagnata :- oggi_piove.\ne si interroga il sistema sulla verit\u00e0 di erba_bagnata scrivendo erba_bagnata. sulla riga di comando di un interprete Prolog. Si ottiene cos\u00ec la riposta:\nyes\nche significa che erba_bagnata \u00e8 vero. La verit\u00e0 di erba_bagnata pu\u00f2 poi essere utilizzata per derivare altre proposizioni, applicando ripetutamente il modus ponens. Nella logica del primo ordine le formule atomiche differiscono da quelle della logica proposizionale perch\u00e9 possono avere uno o pi\u00f9 argomenti. Gli argomenti sono termini, ovvero rappresentazioni di un individuo del dominio del discorso. Nei casi pi\u00f9 semplici, i termini sono variabili se indicano un individuo imprecisato, o costanti se determinano un individuo specifico. Nel seguito utilizzeremo la convenzione del Prolog di usare parole che iniziano con lettere minuscole per indicare costanti, e parole che iniziano con lettere maiuscole per indicare variabili. Le proposizioni diventano predicati ed esprimono propriet\u00e0 dei loro argomenti. Ad esempio p(a) esprime il fatto che \u201cl\u2019individuo a \u00e8 p\u201d o \u201cl\u2019individuo a ha la propriet\u00e0 p\u201d e q(a, b) esprime il fatto che \u201cla coppia di individui a e b \u00e8 q\u201d ovvero che \u201cla coppia a e b ha la propriet\u00e0 q\u201d, ovvero che \u201ca e b sono legati dalla relazione q\u201d. Esempi di formula atomica della logica proposizionale sono uomo(socrate), che significa che \u201cSocrate \u00e8 un uomo\u201d, e padre(paolo,pietro), che indica che Paolo e Pietro sono legati dalla relazione padre, ovvero che Paolo \u00e8 il padre di Pietro.\nLe formule atomiche nella logica del primo ordine possono essere combinate con gli stessi connettivi logici della logica proposizionale. In pi\u00f9 si possono ottenere nuove formule utilizzando i quantificatori: quello esistenziale che, data una variabile X e una formula \u03b1, produce la formula \u2203X\u03b1 e quello universale che, data una formula \u03b1, produce la formula \u2200X\u03b1. I quantificatori hanno senso se \u03b1 contiene X: in questo caso la formula \u2203X\u03b1 significa che esiste un individuo i del dominio del discorso che, sostituito a X, rende la formula \u03b1 vera, mentre la formula \u2200X\u03b1 significa che, per ogni individuo i del dominio del discorso, sostituendo i ad X in \u03b1 si ottiene una formula vera.\nAd esempio, la formula\n\u2200X(mortale(X)\u2190 uomo(X))\nsignifica che, per qualunque individuo X del dominio del discorso, se X \u00e8 uomo allora X \u00e8 mortale. In Prolog si rappresenta la formula in questo modo\nmortale(X) :- uomo(X).\nsottintendendo il quantificatore universale. Questa formula prende il nome di clausola o regola. Un programma Prolog pu\u00f2 comprendere poi un altro tipo di formule chiamate fatti, che non contengono il simbolo di implicazione. Ad esempio, potremmo aggiungere al programma precedente il fatto uomo(socrate). e interrogare poi il programma Prolog chiedendo se Socrate \u00e8 mortale. Per farlo, dovremo scrivere l\u2019interrogazione mortale(socrate). sulla linea di comando dell\u2019interprete Prolog. Il\nProlog rispondera con yes, in quanto mortale(socrate) \u00e8 conseguenza logica del programma. In questo caso il modus ponens non \u00e8 pi\u00f9 sufficiente, occorre la risoluzione, la regola di inferenza proposta da John Robinson.\nAl programma precedente potremmo anche chiedere se c\u2019\u00e8 qualcuno che \u00e8 mortale, scrivendo mortale(M). sulla riga di comando dell\u2019interprete Prolog. L\u2019interprete non risponde pi\u00f9 semplicemente con un s\u00ec o con un no ma con una istanziazione di M che rende la formula vera. Nel caso precedente risponder\u00e0 con M=socrate e si fermer\u00e0 per chiedere se vogliamo altre istanziazioni per M. Se le chiediamo, in questo caso risponder\u00e0 no, ma se aggiungessimo un altro fatto al programma, ad esempio uomo(platone)., il sistema fornir\u00e0, oltre alla risposta M=socrate, anche la risposta M=platone.\nLe regole in Prolog possono poi contenere, nel lato destro di una implicazione, una congiunzione di formule atomiche. La congiunzione in Prolog \u00e8 rappresentata dalla virgola. Ad esempio, la clausola:\npadre(X,Y) :- genitore(X,Y),maschio(X).\nsignifica che X \u00e8 padre di Y se X \u00e8 genitore di Y e X \u00e8 maschio. Il lato destro pu\u00f2 anche contenere variabili non presenti nel lato sinistro, ad esempio:\nnonno(X,Y) :-padre(X,Z),genitore(Z,Y),\nin questo caso le variabili presenti solo nel lato destro sono quantificate esistenzialmente con ambito di quantificazione il solo lato destro. Quindi la regola precedente si pu\u00f2 interpretare come: X \u00e8 nonno di Y se esiste un Z tale che X \u00e8 padre di Z e Z \u00e8 genitore di Y.\nSi noti che nel lato destro pu\u00f2 comparire anche il predicato della formula nel lato sinistro, ad esempio:\nantenato(X,Y) :- padre(X,Z), antenato(Z,Y).\nQuesta regola si interpreta in questo modo: \u201cX \u00e8 antenato di Y se esiste un Z tale che X \u00e8 padre di Z e Z \u00e8 antenato di Y\u201d. Si parla di definizione ricorsiva.\nIl Prolog, quindi, non \u00e8 altro che un dimostratore di teoremi, quelli scritti sulla riga di comando dell\u2019interprete. L\u2019architettura di un interprete Prolog \u00e8 una istanziazione di quella generale di un sistema di IA: ha una memoria di lavoro, dove risiedono i risultati parziali, ha una serie di operatori che sono le regole e i fatti del programma Prolog, e usa una strategia o controllo per stabilire quali regole o fatti sono applicabili, decidere quali applicare ed applicarli effettivamente.\nL\u2019insieme della memoria di lavoro e della strategia di controllo prende il nome di motore inferenziale, mentre l\u2019insieme delle regole e dei fatti viene chiamato base di conoscenza. In particolare, il Prolog compie una ricerca partendo dal goal o teorema da dimostrare, applicando via via le regole o i fatti del programma. nel modo seguente: si cercano tutte le regole o fatti tali che il loro lato sinistro \u201cunifichi\u201d con il goal o con una parte di esso (\u201cunificare\u201d significa rendere uguali il goal con il lato sinistro, attraverso l\u2019istanziazione di\nvariabili) Ad esempio, nel caso del goal mortale(socrate), esso unifica con il lato sinistro della regola mortale(X):-uomo(X). istanziando X a socrate. Tra le regole che hanno il lato sinistro che unifica, se ne sceglie una (ma non si dimenticano le altre) e si sostituisce il goal con l\u2019elenco di sottogoal nel lato destro della regola. Si procede in questo modo fino a che non si arriva ad un goal vuoto (e allora si termina con successo restituendo le sostituzioni nel goal iniziale), oppure fino a che non ci siano pi\u00f9 regole o fatti applicabili (nel qual caso si retrocede al punto di scelta della regola e se ne sceglie un\u2019altra). Il Prolog esplora quindi un albero in modalit\u00e0 all\u2019indietro. La sua memoria di lavoro consiste del goal corrente pi\u00f9 tutti i punti di scelta lasciati aperti, e la strategia seguita \u00e8 una strategia in profondit\u00e0.\nMediante il Prolog si possono costruire sistemi esperti, anche detti sistemi basati sulla conoscenza, caratterizzati dall\u2019essere dotati di una conoscenza che riguarda uno specifico campo, e dall\u2019essere in grado di risolverne i problemi relativi, che un esperto sarebbe in grado di risolvere. Nel caso di sistemi esperti basati sul Prolog, la conoscenza viene espressa sotto forma di programma logico, e il metodo di inferenza del Prolog \u00e8 usato per trovare soluzioni al problema.\nL\u2019uso del Prolog non \u00e8 l\u2019unico approccio per la realizzazione di sistemi esperti: si possono utilizzare anche sistemi a regole di produzione. Essi condividono la struttura generale dei sistemi di IA: in questo caso la base di conoscenza contiene regole della forma \u201cconseguente se antecedente\u201d simili a quelle del Prolog, ma ove nel conseguente non sia presente una formula da derivare ma una o pi\u00f9 azioni sulla memoria di lavoro. Le azioni possibili sono due: inserimento di un fatto oppure rimozione di un fatto. Tipicamente le regole esprimono conoscenza generale sul dominio mentre la conoscenza specifica sul caso in esame \u00e8 espressa da fatti. La strategia di ricerca pu\u00f2 essere sia all\u2019indietro, come in Prolog (partendo dal goal e applicando le regole a ritroso fino a ottenere una memoria di lavoro con i fatti che descrivono il problema), sia in avanti (si pongono i fatti che descrivono il problema nella memoria di lavoro, si cercano le regole che presentano l\u2019antecedente soddisfatto, se ne sceglie una e si applicano le azioni contenute nel conseguente, aggiungendo o rimuovendo un fatto dalla memoria stessa). La ricerca termina quando il goal appare nella memoria di lavoro. Per stabilire quali regole sono applicabili nei due casi si utilizzano algoritmi di unificazione o che mettano in corrispondenza tra loro (\u201cmatching\u201d) formule atomiche. A differenza del Prolog, in un sistema a regole di produzione quando una regola viene scelta non si considerano pi\u00f9 le possibili alternative.\nAlcuni sistemi a regole di produzione includono inoltre la gestione dell\u2019incertezza, cio\u00e9 sono in grado di assegnare alle proprie conclusioni un livello di confidenza. Attualmente per\u00f2 non \u00e8 stato ancora raggiunto un consenso tra i ricercatori su come utilizzare i livelli di confidenza nell\u2019inferenza.\nSistemi esperti sono stati sviluppati in molti domini. Il primo e forse il pi\u00f9 noto \u00e8 Mycin creato negli anni \u201870 all\u2019Universit\u00e0 di Stanford da Edward Shortliffe. Aveva come obiettivo quello di diagnosticare malattie infettive del sangue e raccomandare antibiotici, con un dosaggio adattato al peso del\npaziente. Il sistema offriva buone prestazioni, ma non venne mai utilizzato, per problemi legali.\nAlcuni settori in cui possono essere impiegati sistemi esperti sono: a) diagnosi, nella quale si cerca di individuare una malattia di un essere\numano o il malfunzionamento di un macchinario sulla base dei sintomi, ovvero delle manifestazioni osservabili della malattia o malfunzionamento;\nb) monitoraggio, in cui l\u2019obiettivo \u00e8 di mantenere sotto controllo un processo, raccogliendo informazioni e effettuando stime sul suo andamento;\nc) pianificazione, in cui l\u2019obiettivo \u00e8 quello di raggiungere un certo obiettivo con le risorse di cui si dispone;\nd) interpretazione di informazioni e segnali, in cui si vuole individuare l\u2019occorrenza di particolari situazioni di interesse nei dati in ingresso.\nLo sviluppo di un sistema esperto richiede la scrittura delle regole generali sul dominio, che devono essere raccolte intervistando un esperto del dominio stesso. Questo processo, conosciuto con il nome di estrazione di conoscenza, \u00e8 risultato essere estremamanente lungo e difficile. Al fine di automatizzarlo, \u00e8 possibile usare l\u2019apprendimento automatico, discusso nella prossima sezione.\nCi si potr\u00e0 chiedere perch\u00e8 siano stati realizzati solo sistemi esperti in domini ristretti e non si siano utilizzate queste tecniche per sviluppare un sistema in grado di essere applicato in ogni possibile situazione, comprese quelle cosiddette di senso comune, ovvero relative a ragionamenti che ciascuno di noi fa quotidianamente. La ragione \u00e8 l\u2019eccessiva complessit\u00e0 della fase di stesura delle regole. Recentemente un\u2019azienda statunitense, la Cycorp, sta tentando nuovamente di codificare il senso comune in un sistema esperto."}, {"heading": "2.3 Apprendimento automatico", "text": "Simon nel 1984 ha dato la seguente definizione di apprendimento [Sim84]: \u201cL\u2019apprendimento consiste di cambiamenti del sistema che siano adattativi, nel senso che mettono in grado il sistema di svolgere lo stesso compito o compiti estratti dalla medesima popolazione in maniera pi\u00f9 efficace ed efficiente la prossima volta\u201d. Di sicuro, al fine di realizzare macchine che possano dirsi intelligenti, \u00e8 necessario dotarle della capacit\u00e0 di estendere la propria conoscenza e le proprie abilit\u00e0 in modo autonomo.\nI due impieghi principali dell\u2019apprendimento automatico sono l\u2019estrazione di conoscenza e il miglioramento delle prestazioni di una macchina. La conoscenza estratta pu\u00f2 poi essere utilizzata da una macchina come base di conoscenza di un sistema esperto, oppure dagli esseri umani, ad esempio nel caso della scoperta di nuove teorie scientifiche. Il miglioramento delle prestazioni di una macchina si ha ad esempio quando si incrementano le capacit\u00e0 percettive e motrici di un robot.\nLe tecniche di apprendimento si possono suddividere, come le tecniche di IA in generale, in simboliche e subsimboliche.\nLa tecnica di apprendimento simbolico pi\u00f9 interessante \u00e8 l\u2019apprendimento induttivo: il sistema parte dai fatti e dalle osservazioni derivanti da un insegnante o dall\u2019ambiente circostante, e li generalizza ottenendo conoscenza che, auspicabilmente, sia valida anche per casi non ancora osservati (induzione).\nNell\u2019apprendimento induttivo da esempi, l\u2019insegnante fornisce un insieme di esempi e controesempi di un concetto, e l\u2019obiettivo \u00e8 quello di inferire una descrizione del concetto stesso. Un esempio \u00e8 composto da una descrizione di una istanza del dominio del discorso e da una etichetta; quest\u2019ultima pu\u00f2 essere + se l\u2019istanza appartiene al concetto da apprendere, o \u2013 se l\u2019istanza non gli appartiene (controesempio). Un concetto, quindi, non \u00e8 altro che un sottoinsieme dell\u2019insieme di tutte le possibili istanze del domino del discorso, o universo. L\u2019insieme di esempi e controesempi forniti dall\u2019insegnante prende il nome di training set. La descrizione del concetto che si vuole apprendere deve essere tale da potersi usare per decidere se una nuova istanza, non appartenente al training set, appartenga o meno al concetto. La descrizione del concetto deve essere quindi un algoritmo che, data in ingresso una descrizione dell\u2019istanza, restituisca in uscita +, se l\u2019istanza appartiene al concetto, o -, se l\u2019istanza non appartiene al concetto. Nel primo caso si parla di esempio appartenente alla classe positiva e nel secondo di esempio appartenente alla classe negativa.\nI sistemi di apprendimento induttivo da esempi possono essere classificati in base al linguaggio con il quale \u00e8 possibile descrivere le istanze e i concetti, che sono principalmente due: linguaggi attributo valore e linguaggi del primo ordine. Ai primi corrispondono, come linguaggi di descrizione dei concetti, gli alberi di decisione e le regole di produzione, mentre ai secondi corrispondono descrizioni dei concetti anch\u2019esse del primo ordine.\nI linguaggi di descrizione delle istanze di tipo attributo valore descrivono ciascuna istanza per mezzo dei valori assunti da un insieme finito di attributi uguali per tutte le istanze. Ad esempio; si supponga che le istanze siano giornate e che il concetto che vogliamo imparare sia \u201cgiornata adatta per giocare a golf\u201d [Mit97]. Supponiamo di aver individuato 4 attributi che pensiamo siano rilevanti rispetto al concetto da imparare: Tempo, Temperatura, Umidit\u00e0 e Vento.\nTempo pu\u00f2 assumere solo tre valori: soleggiato, coperto e pioggia; Vento pu\u00f2 assumere solo due valori: vero (v) e falso (f), nel caso sia presente o non sia presente vento. Temperatura e Umidit\u00e0 invece sono attributi continui, possono assumere quindi valori da un intervallo dell\u2019insieme dei reali. Temperatura \u00e8 espressa in gradi Fahrenheit e Umidit\u00e0 \u00e8 espressa in percentuale. Nel caso di istanze descritte da un linguaggio attributo valore possiamo rappresentare il training set per mezzo di una tabella con una colonna per attributo e una riga per istanza. La tabella inoltre avr\u00e0 una colonna aggiuntiva che conterr\u00e0 la classe di appartenenza dell\u2019istanza, ovvero + se l\u2019istanza appartiene al concetto e \u2013 se l\u2019istanza non appartiene al concetto. Un possibile training set per il problema del golf \u00e8 rappresentato in Tabella 1.\nGli alberi di decisione sono un linguaggio di descrizione dei concetti che pu\u00f2 essere usato quando le istanze sono descritte da linguaggi attributo valore.\nTempo Temperatura Umidit\u00e0 Vento Classe soleggiato 75 70 v + soleggiato 80 90 v - soleggiato 85 85 f - soleggiato 72 95 f - soleggiato 69 70 f + coperto 72 90 v + coperto 83 78 f + coperto 64 65 v + coperto 81 75 f + pioggia 71 80 v - pioggia 65 70 v - pioggia 75 80 f + pioggia 68 80 f + pioggia 70 96 f +\nTabella 1: Istanze di giornate (da [Mit97]).\nNegli alberi di decisione ogni nodo corrisponde ad un test su un attributo, e ciascun ramo che parte dal nodo \u00e8 etichettato con il risultato del test. Il test su un attributo discreto consiste in un test di uguaglianza e i possibili risultati sono i possibili valori discreti dell\u2019attributo. Ad esempio, nel caso di Tempo i possibili risultati sono soleggiato, coperto e pioggia. Il test su un attributo continuo consiste nel confronto dell\u2019attributo con una soglia, e i possibili risultati sono due: attributo minore o uguale della soglia o attributo maggiore della soglia. Le foglie sono etichettate con + o -. L\u2019albero pu\u00f2 essere usato per classificare un nuova istanza in questo modo: si parte dalla radice e si considera il test nella radice. In base al valore per l\u2019istanza dell\u2019attributo usato dal test, si sceglie il ramo lungo cui scendere. Si ripete il procedimento fino a che non si arriva ad una foglia: l\u2019etichetta della foglia indica l\u2019appartenenza o meno dell\u2019istanza al concetto. Un albero di decisione per il problema del golf \u00e8 rappresentato in Figura 6.\nLe regole di produzione sono un altro linguaggio di descrizioni dei concetti che pu\u00f2 essere usato quando le istanze sono descritte da linguaggi attributo valore.\nCome nei sistemi a regole di produzione visti in precedenza, le regole di produzione nell\u2019apprendimento automatico hanno la forma \u201cconseguente se antecedente\u201d con l\u2019unica differenza che nell\u2019apprendimento automatico il conseguente ha una forma fissa: \u00e8 del tipo \u201cClasse=valore\u201d. Nell\u2019antecedente possono comparire confronti di un attributo con un valore: nel caso di attributi discreti il confronto \u00e8 fatto mediante l\u2019uguaglianza, mentre nel caso di attributi continui il confronto \u00e8 fatto mediante una disuguaglianza. Le regole sono utilizzate per classificare una nuova istanza restituendo la classe indicata dalla prima regole il cui antecedente \u00e8 verificato nell\u2019istanza. Vediamo un\nTempo\nVentoUmidit\u00e0 75\n+-+ - +\nsoleggiato coperto\npioggia\nvero verofalso\nFigura 6: Albero di decisione per il problema del golf.\nesempio di insieme di regole di produzione per il problema del golf: Classe = + \u2190 Tempo = coperto Classe = + \u2190 Tempo = pioggia and Vento = falso Classe = - \u2190 Tempo = soleggiato and Umidit\u00e0 > 75 Classe = - \u2190 Tempo = pioggia and Vento = vero Classe = + L\u2019ultima regola viene chiamata regola di default perch\u00e8 indica la classe in delle istanze quando nessuna altra regola \u00e8 applicabile. Si noti che l\u2019insieme di regole di produzione restituite da un sistema di apprendimento automatico costituisce la base di conoscenza di un sistema a regole di produzione, sebbene particolarmente semplice in quanto non presenta concatenazione tra le regole.\nEsistono numerosi sistemi in grado di apprendere alberi di decisione: i pi\u00f9 noti sono Cart, sviluppato da Breiman, Friedman, Olshen e Stone, e ID3, sviluppato da Quinlan, entrambi nei primi anni \u201880. Tra i sistemi in grado di apprendere regole di produzione ricordiamo CN2 di Clark e Niblett sviluappato nella seconda met\u00e0 degli anni \u201880.\nI linguaggi attributo valore hanno alcune limitazioni: essi non sono adatti a descrivere istanze costituite di sottoparti e aventi relazioni tra le sottoparti. Ad esempio, si supponga che le istanze del dominio del discorso siano famiglie. Le famiglie hanno un numero variabile di componenti, quindi per descriverle attraverso un insieme fisso di attributi dovremmo prevedere un numero di attributi pari al numero massimo di componenti di una famiglia moltiplicato per il numero di attributi che vogliamo rappresentare per ogni componente. Per le famiglie con un numero non massimo di componenti, ad alcuni attributi si dovr\u00e0 assegnare un valore di \u201cnon significativo\u201d. In questi casi risulta essere pi\u00f9 efficace utilizzare la programmazione logica come linguaggio di rappresentazione. Ad esempio, se voglio rappresentare la famiglia Rossi con componenti Giorgio, Stefano e Andrea nella quale Giorgio \u00e8 il padre di Stefano e Stefano \u00e8 il padre di Andrea scriver\u00f2 semplicemente:\nfamiglia(rossi,giorgio). famiglia(rossi,stefano). famiglia(rossi,andrea). padre(giorgio,stefano). padre(stefano,andrea).\nIl linguaggio di descrizione dei concetti in questo caso \u00e8 la programmazione logica stessa. Essa risulta essere pi\u00f9 espressiva degli alberi di decisione e delle regole di produzione in quanto i programmi logici possono contenere variabili e quantificatori, e le regole possono essere ricorsive. Mediante la programmazione logica \u00e8 possibile esprimere il concetto di famiglia che contiene un nonno paterno:\nnonno_paterno(Famiglia):famiglia(Famiglia,X), famiglia(Famiglia,Y), famiglia(Famiglia,Z). padre(X,Y), padre(Y,Z).\nCon gli alberi di decisione o le regole di produzione non si sarebbe potuto esprimere questo concetto.\nL\u2019area di ricerca che si occupa dell\u2019apprendimento di programmi logici prende il nome di Programmazione Logica Induttiva. I due sistemi pi\u00f9 noti in grado di apprendere programmi logici sono Progol di Muggleton e Aleph di Srinivasan.\nI sistemi di apprendimento, sia da linguaggi attributo valore che da programmi logici, hanno avuto una vasta gamma di applicazioni, che va dalla diagnosi di malattie alla predizione della relazione struttura-attivit\u00e0 nella progettazione di medicine, alla predizione della carcinogenicit\u00e0 delle sostanze chimiche. Con l\u2019aumento della quantit\u00e0 di dati che vengono memorizzati ogni giorno dalle aziende e dalle organizzazioni in generale, gli algoritmi di apprendimento sono sempre pi\u00f9 importanti in quanto consentono di estrarre da questa massa di dati informazioni nascoste, nuove e potenzialmente utili. Si parla in questo caso di data mining, ovvero di estrazione di conoscenza da dati grezzi."}, {"heading": "3 Tecniche subsimboliche", "text": "Vedremo ora tre tecniche subsimboliche: le reti neurali, gli algoritmi genetici e l\u2019intelligenza degli sciami."}, {"heading": "3.1 Reti neurali", "text": "L\u2019idea di simulare il funzionamento del cervello umano e animale per ottenere comportamenti intelligenti risale a prima della realizzazione del computer, in particolare all\u2019articolo del 1943 di McCulloch e Pitts [MP43] nel quale si propose un modello matematico del neurone umano e si mostr\u00f2 come reti composte di tali neuroni artificiali fossero in grado di rappresentare complesse funzioni booleane.\nIl modello del neurone attualmente pi\u00f9 diffuso \u00e8 chiamato neurone sigmoidale ed \u00e8 costituito da una unit\u00e0 con n ingressi numerici e una uscita numerica.\n  W1 W2\n. . . .\nW n\nx1\nx2\nxn\n-1\nFigura 7: Modello del neurone artificiale.\nL\u2019uscita \u00e8 calcolata in funzione degli ingressi nel seguente modo: ciascun ingresso xi viene moltiplicato per un pesoWi, i prodotti di queste moltiplicazioni sono sommati e il risultato viene fornito in ingresso ad una funzione sigmoidale. Un modello di questo tipo di neurone \u00e8 rappresentato in Figura 7, insieme all\u2019aspetto della funzione sigmoidale. Si noti che nella somma c\u2019\u00e8 un termine costante pari a \u2212\u03b8 che viene assimilato ad un comune ingresso supponendo che l\u2019ingresso sia sempre a -1 e che il peso per quell\u2019ingresso valga i.\nQuesto modello si comporta in maniera simile a un neurone naturale: ovvero si \u201cattiva\u201d quando riceve gli ingressi \u201cgiusti\u201d e si \u201cdisattiva\u201d in corrispondenza di ingressi \u201csbagliati\u201d. Un neurone \u00e8 attivo quando la sua uscita \u00e8 vicina a +1 ed \u00e8 disattivo quando la sua uscita \u00e8 vicina a -1. Quali siano gli ingressi giusti o sbagliati \u00e8 determinato dai valori dei pesi degli ingressi: valori positivi dei pesi fanno s\u00ec che i relativi ingressi tendano a portare il neurone verso l\u2019attivazione e valori negativi verso la disattivazione e viceversa nel caso di pesi negativi. I neuroni sono poi collegati tra di loro in reti, quindi l\u2019uscita di un neurone pu\u00f2 essere l\u2019ingresso di altri neuroni e la sua attivazione condiziona l\u2019attivazione dei neuroni a valle.\nIl neurone sigmoidale deriva dal percettrone proposto nel 1962 da Rosenblatt: differisce da esso perch\u00e8 al posto della funzione sigmoidale il percettrone ne ha una a gradino, cio\u00e8 una funzione che \u00e8 0 per i valori minori di 0 e 1 per i valori maggiori o uguali a 0.\nUn singolo neurone sigmoidale \u00e8 in grado di rappresentare una certa classe di concetti a seconda dei suoi pesi: in particolare, \u00e8 in grado di rappresentare quei concetti nei quali gli esempi sono separati dai controesempi da un iperpiano (immaginando di considerare lo spazio degli ingressi come uno spazio euclideo). Quindi isolano nello spazio degli ingressi un semispazio, ovvero una regione delimiatata da un iperpiano (nel caso di due ingressi si tratta di una retta). Per rappresentare concetti pi\u00f9 complessi \u00e8 necessario comporre i\nneuroni in reti. Le reti pi\u00f9 semplici si chiamano reti \u201cin avanti\u201d (\u201cfeedforward\u201d) e sono formate da strati di neuroni: gli input sono collegati al primo strato di neuroni, gli output del primo strato di neuroni sono collegati agli input del secondo strato e cos\u00ec via, fino ad arrivare all\u2019ultimo strato i cui output diventano gli output della rete. Gli strati di neuroni dal primo al penultimo sono detti \u201cnascosti\u201d.\nSi \u00e8 visto che reti a due strati sono in grado di isolare nello spazio degli ingressi regioni convesse e reti a tre strati sono in grado di isolare regioni arbitrarie (anche non connesse, ovvero divise in parti disgiunte) quindi sono in grado di rappresentare concetti generali.\nCome fare per\u00f2 ad ottenere una rete che identifichi un concetto? A differenza dei sistemi basati sulla conoscenza, nelle reti neurali scegliere i pesi a mano risulterebbe troppo complesso. Per questo si utilizzano algoritmi di apprendimento. Anche in questo caso abbiamo un training set, che contiene un insieme di coppie (ingressi, uscite) con la differenza che gli ingressi sono tutti continui, le uscite possono essere pi\u00f9 di una e anch\u2019esse continue, ovvero non sono + o \u2013 ma numeri reali. Si cerca in questo caso il valore dei pesi per il quale \u00e8 minima una certa funzione dell\u2019errore sul training set, ovvero una funzione delle differenze tra le uscite nel training set e quelle della rete quando in ingresso sono forniti i valori presenti nella coppia. La funzione pi\u00f9 utilizzata \u00e8 la somma degli errori al quadrato.\nL\u2019algoritmo pi\u00f9 diffuso per apprendere in reti neuronali multistrato prende il nome di \u201cbackpropagation\u201d ed \u00e8 stato proposto da Rumelhart, Hinton e Williams nel 1986. Esso consiste nel calcolare l\u2019errore dello strato d\u2019uscita della rete su ciascun esempio e nel propagarlo all\u2019indietro verso i neuroni degli strati nascosti. Sulla base dell\u2019errore propagato vengono poi aggiornati i pesi dei neuroni. Se dopo aver considerato in questo modo tutti gli esempi l\u2019errore \u00e8 sceso sotto una soglia prefissata ci si ferma, altrimenti si considerano un\u2019altra volta tutti gli esempi del training set.\nGrazie a questo algoritmo, le reti multistrato di neuroni sigmoidali hanno avuto un grande successo e sono stati applicati in molti campi, tra cui il riconoscimento di caratteri scritti a macchina o manoscritti, il riconoscimento di targhe, le previsioni finanziarie e il controllo di frodi."}, {"heading": "3.2 Algoritmi genetici", "text": "Mentre le reti neurali guardano al cervello umano per produrre un comportamento intelligente, gli algoritmi genetici guardano alla teoria dell\u2019evoluzionismo. Sono algoritmi per la ricerca nello spazio degli stati, nei quali si considera uno stato come un individuo, all\u2019interno di una popolazione di individui che viene fatta evolvere secondo le leggi dell\u2019evoluzionismo in modo da ottenere stati che siano buone soluzioni del problema.\nPer poter applicare un algoritmo genetico, \u00e8 necessario rappresentare lo stato come una sequenza di simboli (nel caso pi\u00f9 frequente una sequenza di bit), che rappresenta il patrimonio genetico (o genotipo) di un individuo e\nlo caratterizza completamente. \u00c8 poi necessaria una funzione di fitness che, data una sequenza di simboli, dica quanto \u00e8 \u201cfit\u201d l\u2019individuo ovvero quanto \u00e8 adatto a sopravvivere nel suo ambiente. Nel caso di un algoritmo genetico, la funzione di fitness rappresenta la vicinanza dello stato ad una soluzione o la sua bont\u00e0 come soluzione.\nUn algoritmo genetico parte da una popolazione iniziale composta da individui generati a caso. Esegue poi un ciclo che termina quando la fitness del miglior individuo supera una certa soglia, ovvero quando la popolazione contiene una soluzione sufficientemente buona. Ad ogni passo del ciclo si genera una nuova popolazione utilizzando gli operatori di selezione, incrocio e mutazione. In pratica, ogni iterazione del ciclo corrisponde a una generazione. La nuova popolazione \u00e8 generata selezionando coppie di individui a caso ma con una probabilit\u00e0 che dipende dalla loro fitness: individui con fitness pi\u00f9 alta hanno maggiore possibilit\u00e0 di essere selezionati. Poi si applica l\u2019operatore d\u2019incrocio che, data la coppia di individui, ne produce un\u2019altra, ottenuta \u201cmescolando\u201d il patrimonio genetico in diversi modi: nel caso di genotipi rappresentati come sequenze di bit di lunghezza fissa n, l\u2019operatore di incrocio pi\u00f9 semplice sceglie un numero intero a caso i minore di n e copia nel primo discendente i primi i bit del primo genitore e gli ultimi n\u2212 i bit del secondo genitore, mentre nel secondo discendente copia l\u2019inverso. I discendenti cos\u00ec ottenuti sono poi soggetti a mutazione, nella quale si effettuano a caso piccoli cambiamenti del genotipo. Il processo di selezione, incrocio e mutazione viene ripetuto fino a che non si ottiene una nuova popolazione di dimensione prefissata. La fitness di tutti gli individui della nuova popolazione \u00e8 poi calcolata.\nEsistono molte varianti di questo tipo di algoritmo. Ad esempio in alcune una parte della vecchia popolazione viene trasferita direttamente in quella nuova, utilizzando la selezione.\nGli algoritmi genetici possono essere utilizzati anche per svolgere compiti di apprendimento automatico. In questo caso occorre rappresentare le descrizioni del concetto da imparare come sequenza di simboli: la fitness sar\u00e0 data dall\u2019accuratezza con la quale una descrizione del concetto classifica gli esempi del training set.\nGli algoritmi genetici hanno avuto numerose applicazioni in biologia, ingegneria e nelle scienze fisiche e sociali. Una delle pi\u00f9 interessanti consiste nella programmazione automatica, ovvero nella generazione automatica di programmi per calcolatore per risolvere un certo problema. In questo caso il genotipo degli individui \u00e8 costituito da alberi che rappresentano un singolo programma in un dato linguaggio di programmazione. L\u2019operatore di incrocio consiste nel sostituire un sottoalbero di un genitore con un sottoalbero dell\u2019altro genitore. La funzione di fitness \u00e8 calcolata eseguendo il programma su un insieme di dati di ingresso."}, {"heading": "3.3 Intelligenza degli sciami", "text": "Gli algoritmi basati sull\u2019intelligenza degli sciami (swarm intelligence) cercano di riprodurre il comportamento degli insetti che vivono in colonie, come formiche, api, termiti e vespe. Questi insetti sono infatti individualmente semplici ma danno luogo a comportamenti collettivi molto complessi, come ad esempio la costruzione di un formicaio e l\u2019approvvigionamento di cibo. Si dice che il comportamento intelligente \u201cemerga autonomamente\u201d dal comportamento dei singoli insetti, non essendoci un supervisore o coordinatore a dirigere gli individui.\nGli algoritmi pi\u00f9 famosi di questa famiglia sono quelli che riproducono colonie di formiche nella ricerca del cibo. Le formiche sono in grado di trovare la strada pi\u00f9 breve dal formicaio al cibo. Nel loro movimento ciascuna lascia sul terreno una sostanza odorosa chiamata feromone, che svanisce lentamente nel tempo; gli spostamenti puntano verso le zone dove il livello di feromone \u00e8 pi\u00f9 alto.\nLe formiche partono inizialmente dal formicaio seguendo direzioni casuali, in quanto non c\u2019\u00e8 feromone sul terreno. La prima formica che trova il cibo e lo riporta al formicaio \u00e8 quella che ha seguito il percorso pi\u00f9 breve di andata e ritorno. Le altre che partono dal formicaio tendono quindi a seguire la strada percorsa dalla prima formica, essendo quella pi\u00f9 odorosa. Il livello di feromone sul percorso pi\u00f9 breve tende cos\u00ec a rinforzarsi, producendo quella che si chiama retroazione positiva. Dopo una prima fase in cui le formiche vagano casualmente sul terreno, si arriva ad una fase in cui tutte le formiche seguono il cammino pi\u00f9 breve.\nAlgoritmi basati sulla riproduzione di sciami sono stati efficacemente utilizzati in numerosi ambiti: ad esempio, per il problema del commesso viaggiatore, per l\u2019indirizzamento dei pacchetti di dati nelle reti informatiche, per l\u2019indirizzamento di veicoli nella rete stradale e per l\u2019assegnazione di lavorazioni su macchinari."}, {"heading": "4 Dibattito sull\u2019Intelligenza Artificiale", "text": "L\u2019IA ha scatenato un grande dibattito nella comunit\u00e0 scientifica e filosofica riguardo cosa significhi essere intelligenti, se le macchine potranno mai esserlo, se avranno mai una mente, se \u00e8 eticamente corretto costruire macchine intelligenti. . .\nQuesti temi sono in realt\u00e0 discussi da secoli nella comunit\u00e0 filosofica ma recentemente hanno ricevuto molta attenzione a causa dei progressi dell\u2019IA. Anche la letteratura e il cinema vi si sono molto interessati, come \u00e8 testimoniato dalla grande quantit\u00e0 di libri e film in cui compaiono robot \u2013 umanoidi o meno \u2013 e macchine intelligenti. Terminator 2 - Il giorno del giudizio di James Cameron (1991) si apre con la scritta \u201cLos Angeles, 2029 A.D.\u201d mentre sullo sfondo appaiono le immagini di una guerra tra umani e robot, scatenata dal cervello elettronico che comanda tutti i dispositivi di difesa della Terra, Skynet, diventato autocosciente e sfuggito al controllo dei suoi creatori. Skynet \u00e8\nbasato su un potente processore neurale e ha impiegato 25 giorni a diventare autocosciente, attraverso un velocissimo processo di apprendimento.\nI filosofi distinguono due ipotesi: l\u2019IA debole e l\u2019IA forte. L\u2019IA debole afferma che le macchine sono (o saranno) in grado di comportarsi come se fossero intelligenti, ovvero di risolvere tutti i problemi che l\u2019intelligenza umana sa risolvere. L\u2019IA forte invece afferma che le macchine sono (o saranno) in grado di pensare, ovvero di avere una intelligenza indistinguibile dalla mente umana.\nVarie critiche sono state mosse a entrambe le ipotesi. Se consideriamo l\u2019IA debole, molti filosofi hanno affermato: \u201cle macchine non saranno mai in grado di svolgere il compito X\u201d dove X \u00e8 stato di volta in volta \u201cbattere un umano a scacchi\u201d, \u201cscrivere musica\u201d, \u201criconoscere il parlato\u201d, \u201cfare scoperte scientifiche\u201d, \u201csuperare il test di Turing\u201d e altri. In molti casi queste affermazioni sono state smentite dai fatti: una macchina ha battuto il campione del mondo di scacchi, brani musicali generati dal computer sono stati ritenuti indistinguibili da brani composti da un essere umano, la lingua parlata viene compresa dai computer e piccole ma significative scoperte sono state fatte dai computer in matematica, astronomia, chimica, mineralogia, biologia e informatica. \u00c8 difficile quindi affermare ora con certezza che alcuni compiti non potranno mai essere svolti da una macchina.\nComputer che superano il test di Turing invece non sono ancora stati costruiti: ogni anno dal 1991 viene tenuta una competizione chiamata Loebner Prize in cui i partecipanti sono macchine che vengono sottoposte al test. Il costruttore della prima macchina che riuscir\u00e0 a superarlo ricever\u00e0 100.000 dollari. Ciascun giudice, dopo la conversazione, assegna all\u2019interlocutore un punteggio da 1 a 10 dove 1 significa computer e 10 essere umano. I punteggi medi attuali si stanno avvicinando sempre pi\u00f9 a 5.\nIn merito all\u2019IA forte, invce, come facciamo a sapere se una macchina ha un\u2019intelligenza indistinguibile da un essere umano? Abbiamo visto che la macchine svolgono un numero sempre maggiore di compiti in passato esclusivi degli uomini, si pu\u00f2 quindi ipotizzare che, un giorno potranno risultare indistinguibili da un essere umano, a meno che non vengano nel frattempo scoperte impreviste limitazioni tecniche. Ma per essere effettivamente indistinguibili dovranno, secondo molti filosofi, divenire autocoscienti, ovvero consapevoli dei propri stati mentali e delle proprie azioni, come gli umani, ed essere dotate di libero arbitrio.\nAlcuni filosofi escludono questa possibilit\u00e0 dal momento che i comportamenti delle macchine sono regolati da leggi fisiche deterministiche che non lasciano spazio a scelte. Questa obiezione non \u00e8 valida se si crede nel materialismo, ovvero nella teoria secondo la quale non esiste un\u2019anima immateriale separata dal corpo, ma solo oggetti materiali, e di conseguenza ogni stato mentale non \u00e8 altro che uno stato del cervello regolato da leggi fisiche (di natura diversa da quelle che regolano i computer ma pur sempre leggi fisiche): ogni neurone risponde agli stimoli di ingresso in una maniera preordinata secondo precise leggi elettrochimiche. Nonostante questo, noi siamo capaci di libero arbitrio, di provare emozioni e di comportarci irrazionalmente. Ci\u00f2 significa\nche dobbiamo rivedere la nostra nozione ingenua di libero arbitrio e pensare che sistemi molto complessi come il cervello possano manifestare propriet\u00e0 olistiche, ovvero che si applicano al sistema nell\u2019insieme ma non alle singole parti che lo compongono.\nSe si crede nel materialismo, quindi, non si pu\u00f2 escludere che una macchina, un giorno, diventi autocosciente. Questo \u00e8 vero a maggior ragione sulla base dei recenti sviluppi delle reti neurali artificiali, che mirano proprio a riprodurre il funzionamento fisico del cervello umano.\nSe non si crede nel materialismo, si crede nel dualismo, inizialmente proposto da Cartesio (1596-1650), che prevede un\u2019anima separata dal corpo materiale. Questa \u00e8 anche la teoria di molte religioni, secondo le quali l\u2019anima \u00e8 una propriet\u00e0 del solo uomo, donata da Dio e immortale, ed \u00e8 essa che determina la coscienza e il libero arbitrio. In questo caso chiaramente non si ammette che una macchina possa avere queste stesse propriet\u00e0.\nSecondo i filosofi e gli scienziati che non hanno convinzioni religiose, il dualismo \u00e8 per\u00f2 attaccabile sotto vari aspetti [But02]. Prima di tutto, se la mente \u00e8 separata dall\u2019uomo, come fa a comandarne le azioni, ovvero come fa a interagire con i tessuti dell\u2019uomo per provocare quelle reazioni chimiche che risultano in un\u2019azione fisica. Per ammettere il dualismo, occorrerebbe quindi negare le leggi fondamentali della fisica.\nIn secondo luogo, se la mente \u00e8 indipendente dal cervello, perch\u00e9 noi abbiamo un cervello?\nTerzo, se i pensieri e le emozioni ci derivano dall\u2019esterno, perch\u00e9 un cervello stimolato per mezzo di elettrodi e droghe reagisce generando pensieri?\nQuarto e ultimo, perch\u00e9 la rimozione chirurgica di parti del cervello in pazienti affetti da malattie cerebrali porta a una alterazione del loro comportamento?\nSupponendo quindi di credere nel materialismo e che in futuro non si scoprano difficolt\u00e0 tecniche che limitino le capacit\u00e0 delle macchine, ci si pu\u00f2 chiedere quando una macchina diventer\u00e0 autocosciente. Secondo il materialismo, una rete neurale complessa quanto il cervello umano dovrebbe presentarne le stesse propriet\u00e0, tra cui l\u2019autocoscienza e il libero arbitrio. Giorgio Buttazzo in [But02] ha calcolato la data in cui un personal computer sar\u00e0 in grado di simulare una rete neurale complessa quanto il cervello umano. Quest\u2019ultimo possiede ha circa mille miliardi di neuroni (1012), ogni neurone ha circa mille (103) connessioni con gli altri neuroni (sinapsi), per un totale di 1015 sinapsi. Abbiamo visto che ad ogni ingresso di un neurone \u00e8 associato un peso che ha valore reale. Per rappresentare un numero reale in un calcolatore occorrono 4 bytes di memoria. Di conseguenza per simulare 1015 sinapsi occorre una memoria di almeno 4 \u00b7 1015 bytes ovvero 4 milioni di Gigabytes. Stimando in un milione di Gigabytes la memoria necessaria a memorizzare lo stato dei neuroni pi\u00f9 le altre variabili ausiliarie necessarie per la simulazione, si ottiene un totale di 5 milioni di Gigabytes. Quando sar\u00e0 disponibile una tale memoria per personal computer?\nFino ad oggi le capacit\u00e0 dei calcolatori sono state descritte dalla legge enunciata nel 1973 da Gordon Moore, uno dei fondatori dell\u2019Intel, secondo cui\nil numero dei transistor sarebbe raddoppiato ogni 18 mesi fino al raggiungimento dei limiti fisici. Questo equivale a una moltiplicazione per un fattore 10 ogni 4 anni. Dato che la capacit\u00e0 delle memorie \u00e8 una funzione lineare del numero dei transistor, per la capacit\u00e0 C in bytes della memoria RAM di un PC si pu\u00f2 scrivere la seguente legge\nC = 10(Anno \u2212 1966)/4\nQuesta legge \u00e8 stata valida dall\u2019introduzione dei personal computer nel 1980 fino ad oggi. Supponendo che rimanga valida anche nel futuro, l\u2019anno in cui si otterr\u00e0 un certo valore di capacit\u00e0 C \u00e8 dato da\nAnno = 1966 + 4 log10C\nPer C uguale a 5 \u00b7 106 Gigabytes si ottiene Anno = 2029, esattamente l\u2019anno in cui, in Terminator 2, Skynet prende coscienza!\nCi dobbiamo ora chiedere se valga la pena di costruire macchine del genere. Contro l\u2019IA vi sono varie critiche, la pi\u00f9 terrificante delle quali fa riferimento a scenari appunto quali quello di Terminator 2, in cui le macchine prendono il controllo e cercano di annullare la razza umana. Dire oggi se questi scenari si potranno realizzare \u00e8 molto difficile: data la limitatezza delle capacit\u00e0 dei sistemi attuali, prevedere se sar\u00e0 possibile realizzare sistemi autocoscienti (al di la di pronostici azzardati come quello sopra) \u00e8 molto difficile. Supponendo poi che ci si possa riuscire, cosa ci fa pensare che questi sistemi debbano produrre la stessa aggressivit\u00e0 mostrata dall\u2019uomo nel corso della sua storia? Inoltre, la scienza finora ha proceduto per passi incrementali, cosa ci fa pensare che nel futuro si verificheranno delle discontinuit\u00e0 del progresso che porteranno l\u2019uomo a non accorgersi del pericolo e a perdere il controllo?\nA favore dell\u2019IA si pu\u00f2 annoverare la possibilit\u00e0 di aumentare enormemente le capacit\u00e0 dell\u2019uomo di conoscere il mondo circostante, di costruire beni e offrire servizi. Inoltre le macchine possono rispondere ad un nostro desiderio di immortalit\u00e0: possono rappresentare l\u2019opportunit\u00e0 di trasferire la mente umana su un supporto pi\u00f9 duraturo, ad esempio utilizzando le reti neurali artificiali. In questo modo verremmo liberati dalle limitazioni imposte dalla nostra natura biologica. Si tratterebbe della nascita di una nuova umanit\u00e0, forse il passo successivo della nostra evoluzione biologica. C\u2019\u00e8 addirittura un movimento, chiamato transumanismo, che spera in questo futuro. Ovviamente si tratta di un futuro che la maggior parte dei teorici della morale aborrisce, considerando la conservazione della vita umana come un bene supremo. Un tale trasferimento della mente da un substrato biologico ad un substrato tecnologico potrebbe essere per\u00f2 eseguito come ultima risorsa prima della morte di un individuo.\nSono comunque problemi che \u00e8 troppo presto porsi. Siamo ancora troppo lontani dal costruire macchine con intelligenza paragonabile a quella umana, e non \u00e8 detto che lungo la strada non s\u2019incontrino difficolt\u00e0 insormontabili. Se tali macchine potranno essere realizzate, sar\u00e0 sicuramente necessario discutere le implicazioni etiche della loro costruzione.\nRiferimenti bibliografici [But02] G. Buttazzo. Coscienza artificiale: Missione impossibile? Mondo Digitale, 1:16\u201325, marzo 2002. [Mel02] P. Mello. Intelligenza artificiale. In Dizionario interdisciplinare di Scienza e Fede. Urbaniana University Press, 2002. [Mit97] T. M. Mitchell. Machine Learning. McGraw-Hill, 1997. [MP43] W. S. McCulloch and W. Pitts. A logical calculus of the ideas im-\nmanent in nervous activity. Bullettin of Mathematical Biophysics, (5):115\u2013137, 1943.\n[RN05] S. Russell and P. Norvig. Intelligenza artificiale. Un approccio moderno, 2a edizione. Pearson Education Italia, 2005.\n[Sim84] H. A. Simon. Why should machines learn. In R. S. Michalski, J. G. Carbonell, and T. M. Mitchell, editors, Machine Learning - An Artificial Intelligence Approach, page 25\u201437. Springer-Verlag, 1984.\n[Tur50] A. Turing. Computing machinery and intelligence. Mind, 59:433\u2013460, 1950.\nAltre pubblicazioni utili [CAD04] L. Carlucci Aiello and M. Dapor. Intelligenza artificiale: i primi 50 anni. Mondo Digitale, 10, giugno 2004. [CLMM97] L. Console, E. Lamma, P. Mello, and M. Milano. Programmazione logica e Prolog. UTET, 1997. [Gor03] M. Gori. Introduzione alle reti neurali artificiali. Mondo Digitale, 8, dicembre 2003. [Odi04] P. Odifreddi. Il diavolo in cattedra. La logica da Aristotele a G\u00f6del.\nCollana Einaudi Tascabili, Saggi. Einaudi, 2004."}, {"heading": "5 Collegamenti", "text": "\u2022 Associazione Italiana per l\u2019IA: http://www.aixia.it/ \u2022 Associazione Europea per l\u2019IA: http://www.eccai.org/ \u2022 Sito divulgativo sull\u2019Intelligenza Artificiale: http://www.scienzagiovane.\nunibo.it/intartificiale.html"}], "references": [], "referenceMentions": [], "year": 2017, "abstractText": "L\u2019articolo presenta un\u2019introduzione all\u2019Intelligenza Artificiale (IA) in forma divulgativa e informale ma precisa. L\u2019articolo affronta prevalentemente gli aspetti informatici della disciplina, presentando varie tecniche usate nei sistemi di IA e dividendole in simboliche e subsimboliche. L\u2019articolo si conclude presentando il dibattito in corso sull\u2019IA e in particolare sui vantaggi e i pericoli che sono stati individuati, terminando con l\u2019opinione dell\u2019autore al riguardo.", "creator": "LaTeX with hyperref package"}}}