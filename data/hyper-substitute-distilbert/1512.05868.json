{"id": "1512.05868", "review": {"conference": "arxiv", "VERSION": "v1", "DATE_OF_SUBMISSION": "18-Dec-2015", "title": "On Voting and Facility Location", "abstract": "we set mechanisms for various preferences where seek to manipulate the social cost, mean voters and candidates are distributed with them in some quantum metric space. net social cost of a position ignores the sum of its distances to each pole. some of our observations assumes politicians choose points can be modeled on a blank line, but other factors of ours far more fundamental.", "histories": [["v1", "Fri, 18 Dec 2015 07:48:16 GMT  (112kb,D)", "http://arxiv.org/abs/1512.05868v1", null]], "reviews": [], "SUBJECTS": "cs.GT cs.AI", "authors": ["michal feldman", "amos fiat", "iddan golomb"], "accepted": false, "id": "1512.05868"}, "pdf": {"name": "1512.05868.pdf", "metadata": {"source": "CRF", "title": "On Voting and Facility Location", "authors": ["Michal Feldman", "Amos Fiat", "Iddan Golomb", "Kin Hubbard"], "emails": ["michal.feldman@cs.tau.ac.il.", "fiat@tau.ac.il.", "igolomb@gmail.com."], "sections": [{"heading": null, "text": "A question closely related to candidate selection is that of minimizing the sum of distances for facility location. The difference is that in our setting there is a fixed set of candidates, whereas the large body of work on facility location seems to consider every point in the metric space to be a possible candidate. This gives rise to three types of mechanisms which differ in the granularity of their input space (voting, ranking and location mechanisms). We study the relationships between these three classes of mechanisms.\nWhile it may seem that Black\u2019s 1948 median algorithm is optimal for candidate selection on the line, this is not the case. We give matching upper and lower bounds for a variety of settings. In particular, when candidates and voters are on the line, our universally truthful spike mechanism gives a [tight] approximation of two. When assessing candidate selection mechanisms, we seek several desirable properties: (a) efficiency (minimizing the social cost) (b) truthfulness (dominant strategy incentive compatibility) and (c) simplicity (a smaller input space). We quantify the effect that truthfulness and simplicity impose on the efficiency."}, {"heading": "1 Introduction", "text": "The Hotelling-Downs model ([10], [17]) used to study political strategies, assumes that individual voters occupy some point along the real line. Non-principled political parties (or ice cream vendors) strategically position themselves at a point along the left-right axis (or along a beach) so as to garner the greatest number of supporters (clients). Implicitly, voters will vote for the closest candidate.\nWe consider an analogous problem to the Hotelling-Downs model, where candidates are principled (i.e., non-strategic) whereas the voters have preferences but may misrepresent them\n\u2217Tel Aviv University and Microsoft Research, Israel. Email: michal.feldman@cs.tau.ac.il. The work of Michal Feldman was partially supported by the European Research Council under the European Union\u2019s Seventh Framework Programme (FP7/2007-2013) / ERC grant agreement number 337122. \u2020Tel Aviv University. Email: fiat@tau.ac.il. This work was done in part while A. Fiat was visiting the Simons Institute for the Theory of Computing. \u2021Tel Aviv University. Email: igolomb@gmail.com. The work of Iddan Golomb was partially supported by the European Research Council under the European Union\u2019s Seventh Framework Programme (FP7/2007-2013) / ERC grant agreement number 337122. This work was done in part while I. Golomb was visiting the Simons Institute for the Theory of Computing.\nar X\niv :1\n51 2.\n05 86\n8v 1\n[ cs\n.G T\n] 1\n8 D\nec 2\n01 5\nin order to achieve what is a better outcome from their perspective. In this model, in which both voters and candidates are represented by points in the metric space, a closer candidate is preferable to one further away.\nExamples for candidate selection:\n\u2022 A municipality plans to erect a public library on a street, and every resident seeks to be as close as possible to the proposed library. However, the new library can only be built on suitable locations (the candidates).\n\u2022 Social choice issues in which the distance is not physical: there is a set of policies ranging from left to right, and several political candidates stand for election, each one advocating a different policy. Every voter is associated with a point along the real line. An example of a collective decision problem which does not revolve around the political sphere yet may also fit this setting is the task of determining the temperature of an air conditioner in a room, where each individual has a different ideal point along the scale of temperatures (a line). There are many additional settings of relevant candidate selection problems, e.g., in the realms of recommendation systems, electronic commerce and computational economics. While our results do not necessarily apply to all social choice settings, there are many such problems for which they do apply (whether in entirety or partially).\nAssuming quasi-linear utilities, and allowing payments \u2014 then the well known VickreyClarke-Groves (VCG) mechanism is truthful and can achieve the optimal social cost (see, e.g., [20]). However, in many real-life situations we restrict the use of money due to ethical, legal or other considerations, e.g, in democratic elections and in the examples previously mentioned.\nWe study deterministic truthful mechanisms with no payments for the candidate selection problem. In such mechanisms, no agent can benefit from misreporting her location, regardless of the reported locations of the other agents. Such mechanisms are also known as dominant strategy incentive compatible mechanisms. We also consider randomized truthful mechanisms, both universally truthful (ex-post Nash) and truthful in expectation.\nGiven a set of candidate and voter locations, it is polytime to find the candidate that minimizes the social cost.\nWhen restricted to deterministic truthful mechanisms, we show that the optimal candidate cannot be selected in the general case. Moreover, we show that the cost may be as bad as three times the optimal cost (matching lower and upper bounds). When considering randomized mechanisms on the line, the approximation factor drops to two (matching upper and lower bounds).\nThere are other reasons that an optimal candidate may not be chosen. In particular, this depends on the amount of information the agents supply to the mechanism. We formulate three different types of mechanisms, based on the information each agent submits to the mechanism\u2014\n\u2022 Voting mechanisms, in which each agent casts a vote for her favorite candidate.\n\u2022 Ranking mechanisms, in which each agent states her ordinal preferences over the candidates.\n\u2022 Location mechanisms, in which each agent sends her exact position.\nClearly, knowing the true location of an agent allows one to infer the ranking preferred by that agent, which in turn allows one to infer the favorite candidate of the agent (up to tie-breaking).\nIn almost all previous work on the facility location problem every point in the metric space was considered to be a candidate, therefore there was no difference between these three mechanism types.\nThe social choice literature mostly considers ranking mechanisms. Recognize that Arrow\u2019s impossibility theorem does not hold when assuming the preferences are single-peaked.\nThe more information an agent transmits, the mechanism has more tools to devise an accurate solution. Albeit, this information comes at a cost, since it might disclose more private information which the agents wish to keep confidential. Furthermore, behavioral economists have long argued that the agents cannot obtain the full information pertaining to their utility, or that obtaining this information requires a high cognitive cost. Additionally, sending more information also casts a higher burden on the mechanism. For all of these reasons deploying a simple mechanism 1 which requires less information from agents is advantageous, and generally there is a trade-off between the accuracy of a mechanism to its simplicity. Indeed, in practice many election schemes use voting mechanisms rather than ranking mechanisms, largely due to these desiderata."}, {"heading": "1.1 Our Contributions", "text": "In the paper, we show the following:\n\u2022 In Section 3 we formulate a framework of reductions that compare the various mechanism types. We utilize this framework to show the relations (equivalence or strict containment) between the three classes of truthful mechanisms \u2013 voting, ranking and location (see Figure 1). Furthermore, we show that for the case of two candidates, the set of truthful in expectation location mechanisms is equivalent to the set of truthful in expectation voting mechanisms. These results provide a significant step towards a full characterization of truthful mechanisms at large.\n\u2022 In Section 4 we define a family of universally truthful voting mechanisms on the line called weighted percentile voting (WPV) mechanisms, which choose the i\u2019th vote with some predetermined probability pi. We introduce the spike mechanism, which is a WPV mechanism that carefully crafts the probability distribution to account for misreports by any agent - whether they are near the center or close to the extremes (see Figure 2). We then use backwards induction to show that spike achieves an approximation ratio of two (Theorem 8).\n\u2022 In Section 5 we show additional bounds for randomized mechanisms \u2013 On the line there is a lower bound of two, even for location mechanisms, which shows that the result for spike is tight. Furthermore, when combining this understanding with the results of Section 3, it can be concluded that two is also the tight approximation ratio for truthful in expectation mechanisms (voting, ranking or location) and for universally truthful voting mechanisms.\nWe move on to show bounds for randomized mechanisms for more general metric spaces2 (see Figure 3). An immediate result is that the random dictator mechanism achieves an upper bound of three for any metric space. Theorem 14 shows a lower bound of 3 \u2212 2d for any voting mechanism in <d by using a counterexample based on a regular simplex. This is enough to conclude that on an arbitrary metric space, the bound of three is tight for any voting mechanism. Theorem 16 displays a lower bound of 7/3 for any ranking mechanism in <2 (which also holds in any higher dimension Euclidean space <d).\n1We use the term \u201csimplicity\u201d in the perspective of the voters, which have a smaller action space, i.e, less options to choose from. Upon receiving the input, the mechanism itself can act in an arbitrarily complex fashion.\n2We do not present results for deterministic mechanisms in general metric spaces, since in these cases the incentive compatibility constraints take a significant toll on the approximation ratio \u2013 according to Anshelevich et al. [3] in the non-strategic setting it is possible to reach a constant ratio in any metric space, while due to the\nMedian\nVoting\nRanking \u2248 Location\n(a) Deterministic truthful mechanisms\nSpike\nUT Voting\nTIE Voting\nTIE Ranking\nTIE Location\n(b) Randomized mechanisms\nFigure 1: The relationships between classes of mechanisms in candidate elections (Theorem 1): For deterministic truthful mechanisms, the set of ranking mechanisms strictly contains the set of voting mechanisms, yet the set of location mechanisms is equivalent to the set of ranking mechanisms. The lower bound on the social cost for any truthful location mechanism on the line is 3, and it is matched by an upper bound by a voting mechanism - the median mechanism. In the randomized case, there is a hierarchy of strict containment in the following order - truthful in expectation (TIE) location mechanisms, TIE ranking mechanisms, TIE voting mechanisms and universally truthful (UT) voting mechanisms. The lower bound on the social cost of any location mechanism on the line is 2. We introduce the spike mechanism, which is a universally truthful voting mechanism, which achieves a matching upper bound of 2. Refer to Section 3 for formal definitions of equivalence and strict containment in our setting.\n\u2022 In Section 6 we present deterministic bounds on the line \u2013 there is a lower bound of three, which is met by a matching upper bound due to the median mechanism. All the results on the line, deterministic or randomized, are displayed in the table in Figure 4.\nRecognize the following surprising phenomenon apparent in Figure 4. In both deterministic and randomized cases, any constraint in either information or truthfulness, yields the same ratio as taking the both of these constraints simultaneously \u2014 when insisting on truthful mechanisms (in the strategic case), there is no trade-off between high and low information settings, and one can enjoy the benefits of minimal information mechanisms (voting mechanisms) without incurring any additional cost to the approximation ratio; Similarly, when deciding to reduce the information requirements to anything less than location mechanisms, it is possible to devise a truthful [voting] mechanism, without increasing the approximation ratio."}, {"heading": "1.2 Related Work", "text": "Voting systems have been a domain of prolific research for decades. The seminal GibbardSatterthwaite theorem [15] shows that if the rankings of agents can be arbitrary and the amount of candidates is greater than two, then the only onto truthful mechanisms are dictatorships. However, if there are limitations on the rankings, then the impossibility theorem\ncharacterization of Schummer and Vohra [24] there exist metric spaces in which the approximation ratio is \u2126(n) even in the continuous model.\nFigure 2: The density function of the spike mechanism, which gives rise to the mechanism\u2019s name (the cumulative distribution function is written explicitly in Definition 4). In this example there are 10000 agents and 4 candidates. The 4 candidates, when ordered from left to right, receive 2000, 2000, 3000 and 3000 votes respectively. The votes are arranged in ascending order (with ties broken arbitrarily), and the graph depicts probability of each vote being chosen \u2013 votes are chosen with higher probability when they are closer to the 50th percentile. The area beneath the graph represents the probability that each candidate will be elected, e.g., the probability of choosing the second candidate (p2) is the integral of the function between 2000 and 4000.\nof Gibbard-Satterthwaite does not hold. In many cases the rankings can be limited to singlepeaked preferences, a notion used as early as 1948 by Black [4]. In 1980 Moulin showed a complete characterization of truthful deterministic mechanisms for single-peaked preferences [19]. Schummer and Vohra [24] extended this characterization to cycles and general graphs.\nThere has been extensive work describing various candidate selection mechanisms, which have been generally divided to 3 main types ([6], [26]) \u2014 scoring rules (e.g., plurality, Borda, anti-plurality, range voting, cumulative), Condorcet extensions (e.g., Copeland, maxmin, Dodgson, Young, ranked pairs), or other mechanisms (e.g., single transferable vote, Bucklin). Some work on social choice also made use of randomized voting schemes, for instance in order to improve the results of the mechanisms [21] or to make manipulation computationally hard ([8] pages 632-633). Most of these mechanisms have no assumptions on the preferences of the agents, and are rankings mechanisms (i.e., they receive the ordinal preferences of the voters as input). Since in these circumstances the Gibbard-Satterthwaite impossibility theorem holds, the mechanisms are typically not truthful. While the importance of truthfulness and of simple mechanisms (with less options for each voter) has been acknowledged, to the best of our knowledge there has not been a formal framework for reduction or an assessment of the relationships between the different types of mechanisms.\nSince in the lack of cardinal costs no global objective functions can be measured (e.g, the social cost), the focus of many of the aforementioned mechanisms is on achieving some desirable axiomatic properties. Nonetheless, the use of utilitarianism in the realm of social choice has firm and ancient roots (see, e.g, a 1952 paper by Fleming [12] and a 1955 work by Harsanyi [16]). Moreover, a new line of work commenced in recent years regarding distortion, which also refers to the utilitarian goal of minimizing social cost (partly due emergence of new domains such as recommender systems and e-commerce, as previously noted). The term was coined in 2006 by Procaccia and Rosenschein [22], and it was later used, for instance, by Boutilier et. al. [5]. Recently, Anshelevich et al. [3] assessed the distortion of several voting rules, and provided lower bounds on them. In [3], the distortion is the worst case ratio between the social cost of the candidate elected and the social cost of the optimal candidate, over any ranking profile (that is, preference profile) in any metric space. The distortion is a quite similar to the approximation ratio used in this paper, but it differs in two key properties \u2013\nStrategic Non-Strategic\nVoting (low information) LB 3\u2212 2d+1 (Thm. 14) 2 (Lemma 17) UB 3 (Lemma 18) 3 (Lemma 18)\nRanking LB 7/3 (Thm. 16) 2 (Lemma 17) UB 3 (Lemma 18) 3 (Lemma 18)\nLocation (high information) LB 2 (Obs. 15) 1 UB 3 (Lemma 18) 1\nAnshelevich et al. show a deterministic lower bound of 3 on the distortion, and they prove that two mechanisms (social choice functions), Copeland and Uncovered Set, achieve a distortion of 5.\nProcaccia and Tennenholtz introduced game theoretical aspects to the facility location problem. As mentioned before, their setting is similar to the one in this paper, except that the location of the facility is not restricted to a set of candidates, but instead can be located at any point on the line. This model was extended by these authors and by others in many different ways. The metric space researched spanned from a line ([14], [23]) to a circle ([1], [2]), a tree ([1], [11]) or a general graph ([1]). There are many papers regarding building several facilities (or electing a committee of candidates), where the cost of an agent is her distance to the closest facility ([13], [14], [18], [23]). As opposed to the voting scenario, the goal of the vast majority of these papers was to optimize over some global target function, and the most popular target functions were the utilitarian (social cost) and egalitarian (the maximal cost of an agent) (see, e.g, [1], [14], [23]), but there were also works regarding additional target functions like the L2 norm (the sum of the squared distances of the agents, see [11]). Some papers consider \u201cobnoxious facility location\u201d \u2014 a setting in which agents want to be as far away as possible from the facility, e.g., when selecting a location for a central garbage dump ([7]).\nWhen the outcome is constrained to a set of candidates, the facility location literature is far less extensive. In this setting, a recent paper by Sui and Boutilier defines a set of deterministic\nDeterministic Randomized Strategic Non-Strategic Strategic Non-Strategic\nVoting 3 3 2 2 (low information) (LB:Lm. 19, (LB:Thm. 3 in [3], (LB:Lm. 17, (LB:Lm. 15,\nUB:Lm. 21) UB:Lm. 21) UB:Thm. 8 ) UB:Thm.8)\nRanking 3 3 2 2 (LB:Lm. 19, (LB: Thm. 3 in [3], (LB:Lm. 17, (LB:Obs. 15, UB:Lm. 21) UB: Lm. 21) UB:Thm. 8 ) UB:Lm. 21)\nLocation 3 1 2 1 (high information) (LB:Lm. 19, (LB:Lm. 17,\nUB:Lm. 21) UB:Thm. 8 )\nFigure 4: The approximation ratios of mechanisms on the line (<) in various settings. All the results in the table are tight. In particular the upper bound in strategic case is due to the spike mechanism.\nmechanisms which is GSP on the line and -GSP on <n [25]. The paper does not show bounds on global objectives such as the social cost.\nDokow et al. [9] characterize deterministic truthful mechanisms on the discrete line and the discrete circle. They move on to give a lower bound on the social cost for large circles, and to the best of our knowledge this is the only result regarding assessment of the social cost in a constrained setting. It is worthy to note the model in [9] has 2 major properties which differ from the one in this paper: (a) The discrete constraints of the locations apply to the agents as well as to the candidates, so all agents are located precisely on some candidate; (b) The distance between any two neighboring candidates must be constant (for instance: 1,2,3,4,...)."}, {"heading": "2 Model", "text": "Let N = {1 . . . n} be a set of agents, where each agent i \u2208 N is located at some point xi. We refer to the location of agent i as agent i\u2019s type. Let x = (x1 . . . xn) be the location profile of the agents. There exists a fixed set of candidates C = {C1 . . . Cm}. Each candidate Cj , is located at point yj , and this location is publicly known. The agents and candidates are located on some metric space. A significant part of the paper deals with specific metric spaces, and these will be specifically noted. In the parts where the metric space is <, it is assumed that the agents and the candidates are both numbered in ascending order based on their locations (otherwise they could be renamed in this manner).\nA deterministic mechanism M , is a function which maps an action profile a = {a1 . . . an} \u2208 An to a candidate, that is: M : An \u2192 C. We consider three classes of mechanisms that differ in the input they accept, i.e., in the action space A of the agents:\n\u2022 Voting mechanisms, in which each agent casts a vote for a candidate, that is: ai \u2208 C.\n\u2022 Ranking mechanisms, in which every agent reports ordinal preferences over all the m candidates. The notation Cj Ck indicates a preference of candidate Cj over candidate Ck (or is indifferent between the two). In ranking mechanisms ai \u2208 \u03a0, where \u03a0 is the set of all permutations of the set of candidates C. These mechanisms are sometimes referred to in the literature as social choice functions.\n\u2022 Location mechanisms, in which every agent reports their location, that is ai is some point in the metric space.\nGiven a joint action profile a, the cost of point x is its distance to the facility, that is: costx(M,a) = |x\u2212M(a)|. For agent i \u2208 N located at point xi, we refer to costxi(M,a) as the cost of agent i. The goal of each agent is to minimize her cost.\nTruthful mechanisms are usually defined in the context of direct revelation mechanisms. Since in ranking and voting mechanisms the action space does not coincide with the type space, we extend this notion in the following trivial manner for these cases as well. For an agent in location xi and for any mechanism (location, ranking or voting), let A(xi) be the set of true actions of this agent \u2014 the actions which convey the real preferences of this agent. For instance, in voting mechanisms A(xi) is the set of candidates closest to xi, which we refer to as the favorite candidates of xi (this might be a set since there may be ties). An agent reporting ai \u2208 A(xi) is said to be reporting truthfully, and an action profile a in which all agents report truthfully is called a truthful profile. The set of truthful profiles is denoted A(x). A truthful mechanism M is one in which no agent can suffer from reporting truthfully, regardless of the actions of the other agents:\n\u2200i \u2208 N, \u2200xi, \u2200ai \u2208 A(xi),\u2200a\u2212i \u2208 An\u22121,\u2200a\u2032i \u2208 A : costxi (M, (ai, a\u2212i)) \u2264 costxi ( M, (a\u2032i, a\u2212i) ) A randomized mechanism is a mapping from an action profile to a distribution over the candidates, that is: M : An \u2192 \u2206(C). The cost of agent i is the expected cost of this agent according to the probability distribution returned by the mechanism, that is: costxi(M,a) = ECj\u223cM(a)|xi \u2212 yj |.\nTwo different notions of randomized truthful mechanisms have been studied in the literature, and we extend them naturally based on our definitions of truthful reports:\n\u2022 Truthful in expectation (TIE) mechanisms \u2014 where the expected cost of an agent reporting truthfully is never higher than any other action. That is: \u2200i \u2208 N , \u2200ai \u2208 A(xi), \u2200a\u2212i \u2208 An\u22121, \u2200a\u2032i \u2208 A: costxi (M, (ai, a\u2212i)) \u2264 costxi (M, (a\u2032i, a\u2212i)). In these mechanisms the agent may regret her action ex-post for some of the instances.\n\u2022 Universally truthful mechanisms are mechanisms which can be expressed as a probability distribution over deterministic truthful mechanisms. In these mechanisms an agent never regrets reporting truthfully, even after the random outcome is unraveled.\nClearly, every universally truthful mechanism is truthful in expectation mechanisms, but not necessarily vice versa. Throughout the paper, in the randomized setting we use the term \u201ctruthful\u201d to refer to truthful in expectation mechanisms, unless otherwise stated.\nThe social cost of a mechanism is the sum of the agents\u2019 costs. For a location profile x and an action profile a the social cost is: SC(M,x,a) = \u2211 i costxi(M,a). The cost of a candidate\nis the cost of the mechanism which locates the facility on that candidate, that is: SC(Cj ,x) =\u2211 i\u2208N |yj \u2212 xi|. Given a location profile x, the optimal mechanism, denoted OPT(x), is one which chooses a candidate that minimizes the social cost (Copt). For the sake of consistency, when there are several optimal candidates, we refer to the leftmost among them as Copt. For any truthful in expectation mechanism M (including universally truthful mechanisms), the social cost of M given a location profile x is the maximal social cost it yields by any truthful action profile a, that is: SC(M,x) = maxa\u2208A(x) SC(M,x,a). The approximation ratio of a truthful in expectation mechanism M is the maximal ratio for any location profile x, between social cost of M given x and the optimal social cost given x: maxx SC(M,x)\nSC(OPT,x) .\nWe make use of several terms which are relevant for voting mechanisms:\n\u2022 The location of a vote ai (some candidate) is denoted y(ai).\ny1 y2 y3b1 b2\nx1 x2 x3 x4 x5\nV1 V2 V3\nFigure 5: Illustration of candidates (white circles), agents (black circles), voting borders and voting zones when the metric space is <. For example, in this case the favorite candidate of x3 is C2: C(x3) = {C2}. The voting borders divide the distance between two consecutive candidates exactly in half, for example: |b1\u2212 y1| = |y2 \u2212 b1|.\n\u2022 When the network is the line, then there is an inherent order of the votes, and therefore it is possible to make use of percentiles. A percentile mechanism is a voting mechanism that elects the i\u2019th percentile vote (for example, the mechanism which chooses the leftmost vote is the 0 percentile mechanism).\n\u2022 A weighted percentile voting (WPV) mechanism locates the facility on the i\u2019th percentile vote with some probability pi, where {pi} does not depend on the action profile a. For example, \u201crandom dictator\u201d is a WPV mechanism which chooses any vote ai with probability 1n .\nIn voting mechanisms, the set of candidates C induces a partition of the line in the following manner \u2014 the voting zone of candidate Ci, denoted Vi, is the set of points whose favorite candidate is Ci: Vi = {x : \u2200Cj : |x \u2212 Ci| \u2264 |x \u2212 Cj |}. The voting zones are bounded by voting borders. For example, when the metric space is <, there are n \u2212 1 borders, which are the midpoints between two consecutive candidates: bi = yi+yi+1 2 (see Figure 5). When the metric space is <d, the voting zones create a Voronoi diagram. A candidate which has at least one agent in their zone is called active.\nIn ranking mechanisms, C induces a partition which divides the line into ranking zones. All points in some ranking zone Ri share some ranking \u03c0i. In this case, we say that the ranking \u03c0i is consistent with ranking zone Ri. The ranking zones bounded by ranking borders. For example, when the metric space is < the ranking borders are the midpoints between any two candidates: bi,j = yi+yj 2 ."}, {"heading": "3 Classes of Mechanisms", "text": "In this section we go over the containment hierarchy of various classes of truthful mechanisms (e.g., Figure 1). We start with some intuition, then defining some necessary terms, and finally present the main theorem of this section.\nIntuitively, for any mechanism M , there exists a mechanism M \u2032 which receives a \u201cricher\u201d input than M , and acts identically to M . For instance, for some arbitrary voting mechanism M , there obviously exists a ranking mechanism M \u2032 which disregards all of the preferences except the top choice of each agent, and behaves essentially just like M does.\nWe generalize this notion in the following informal definition \u2014 a mechanism M (whether location/ranking/or voting) is said to be reducible to a mechanism M \u2032 (location/ranking/or voting) if for every location profile x and true reports, the output of M is identical to the output of M \u2032 (a formal definition, which is based on M simulating M \u2032, is deferred to appendix A.1).\nAs pointed out, it is clear that every voting mechanism M is reducible to some ranking mechanism M \u2032 (or some location mechanism M \u2032). In these cases, if M is truthful then so is M \u2032, since M \u2032 only uses the information which is inputted to M , so any misreports to M \u2032 which would not change the input of M do not affect the outcome at all. Note that the same reasoning also shows that every ranking mechanism is reducible to some location mechanism, and that any voting mechanism is reducible to some location mechanism.\nOn the other hand, it is not true that every ranking mechanism is reducible to some voting mechanism. Somewhat surprisingly, we will soon show that when we restrict ourselves to deterministic truthful mechanism this does hold, that is \u2014 every deterministic truthful ranking mechanism is reducible to some deterministic truthful voting mechanism.\nTwo sets of mechanisms, A and B, are said to be equivalent if every a \u2208 A is reducible to some b \u2208 B, and every b \u2208 B is reducible to some a \u2208 A.\nA set of mechanisms A is said to be strictly contained in a set of mechanisms B if every mechanism a \u2208 A is reducible to some mechanism b \u2208 B, yet not every mechanism b \u2208 B is reducible to some mechanism a \u2208 A. This is a slight abuse of terminology since the sets A and B may be disjoint, as their input space may be different.\nThe following theorem shows several claims regarding relations (equivalence or strict containment) between sets of truthful mechanisms. Notice that not only does this theorem show the hierarchy of the different classes, but it also provides notions relevant to characterization of truthful mechanisms. For instance, the second claim proves that no mechanism can use any information regarding the location of the agents beyond their ranking, while maintaining truthfulness. In addition, in the claims showing strict containment, the examples in the proofs portray the expressiveness that the additional information gives the mechanism.\nTheorem 1. The following claims hold in the Euclidean metric space <d (for any d \u2208 N):\n1. The set of truthful deterministic ranking mechanisms strictly contains the set of truthful deterministic voting mechanisms.\n2. The set of truthful deterministic location mechanisms is equivalent to the set of truthful deterministic ranking mechanisms.\n3. The set of truthful in expectation randomized ranking mechanisms strictly contains the set of truthful in expectation randomized voting mechanisms.\n4. The set of truthful in expectation randomized location mechanisms strictly contains the set of truthful in expectation randomized ranking mechanisms.\n5. The set of truthful in expectation randomized voting mechanisms strictly contains the set of universally truthful randomized voting mechanisms.\n6. When there are two candidates, the set of truthful in expectation randomized location mechanisms is equivalent to the set of truthful in expectation randomized voting mechanisms.\nFor the ease of readability, we defer the proof of this theorem to the appendix (see A.1)."}, {"heading": "4 Spike Mechanism", "text": "In the next sections we will prove that both the median mechanism and the random dictator mechanism achieve an approximation ratio of three on <. However, the cause for this ratio in these two cases is different - for median it is due to an instance which is bad for the median agent, while for random dictator it is due to a bad instance for an agent in one of the extremes.\nIt is therefore desirable to devise a mechanism which is resistant to bad instances of any agent. The spike mechanism stems from this intuition.\nThis section contains foundations needed for the introduction of the spike mechanism, the definition of the mechanism, and the theorem showing that spike achieves an approximation ratio of 2. In the entirety of this section, the metric space is < and the mechanisms are voting mechanisms.\nWe start by showing a basic lemma regarding WPV mechanisms. Recall that these are voting mechanisms which choose the i\u2019th percentile vote with a predetermined probability pi.\nLemma 2. Any weighted percentile voting mechanism M is universally truthful.\nThe proof is straightforward and deferred to appendix A.2.\nDefinition 3 (Cumulative count of a candidate). Given a voting profile a, the cumulative count of candidate Ci is the amount of agents who voted for any candidate who is not located to the right of yi, that is: t(i) = |j \u2208 N : y(aj) \u2264 yi|.\nDefinition 4 (Spike Mechanism). The spike mechanism is a WPV mechanism 3 that for each voting profile a, chooses candidate Ci according to the following cumulative distribution function:\nF (i) =\n{ t(i)\n2(n\u2212t(i)) if t(i) \u2264 n/2 1.5\u2212 n2t(i) if t(i) > n/2\nThe mechanism is named after the shape of the density function it creates (see Figure 2). Recognize that the result of the mechanism depends on the amount of votes that each candidate received and on the order of the candidate along the line, but not on the distances between the candidates.\nObservation 5. Spike defines a symmetric distribution, that is: \u2200i : F (i) = 1\u2212 F (n\u2212 i).\nProof. Let 1 \u2264 i \u2264 n/2, then:\nF (i) = i\n2(n\u2212 i)\n1\u2212 F (n\u2212 i) = 1\u2212 (\n1.5\u2212 n 2(n\u2212 i)\n) =\nn 2(n\u2212 i) \u2212 1 2 = n\u2212 (n\u2212 i) 2(n\u2212 i) =\ni\n2(n\u2212 i)\nWe now define a few terms needed for the proof of the approximation ratio. Recall that Copt is uniquely defined for a location profile x, since ties are broken in favor of the leftmost candidate. We denote the set of borders {bi}m\u22121i=1 by B.\nDefinition 6 (Tight profile of x, see Figure 6a). Given a location profile x, the profile x\u2032 is said to be the tight profile of x if it moves all agents who are not on a border as close as possible to Copt within their zones, that is:\n\u2200i : x\u2032i =  xi if xi \u2208 B yopt if xi \u2208 Vopt \\B bj if xi \u2208 Vj \\B and j < OPT bj\u22121 if xi \u2208 Vj \\B and j > OPT\nDefinition 7 (Left-compressed profile of x, see Figure 7a). Given a tight location profile x, a left-compressed profile of x moves all the agents on the leftmost border to their neighboring border on the right, if this border is left of yopt. Formally: let the location of the leftmost agent be x1 = bj, then the left-compressed profile of x is:\n\u2200i : x\u2032i = { bj+1 if (xi = bj) \u2227 (bj+1 < yopt) xi otherwise.\nNote that the left compressed profile of a tight profile is also a tight profile. The rightcompressed profile of x is defined in a completely symmetrical fashion.\nAfter compressing location profiles, there are likely to be locations in which there are many agents. We therefore use the following notation: the location profile is written as x = {(x\u03021, n1), ..., (x\u0302k, nk)}, which means that for each j : 1 \u2264 j \u2264 k, there are nj agents located at x\u0302j .\nWe now use these definitions to prove the main result of this section:\n3Spike is a WPV mechanism since it chooses the i\u2019th percentile vote with some probability pi, and pi does not depend on the reports.\nTheorem 8. The spike mechanism is universally truthful, and it achieves an approximation ratio of 2 on <.\nProof. Spike is a WPV mechanism, so according to Lemma 2 it is universally truthful. The analysis of the approximation ratio is more involved and is based on backwards induction which follows these steps (see Figure 8):\n1. Figure 8a: Start with a general location profile x, and compute its optimal candidate, Copt.\n2. Figure 8b: Let x(1) be the tight profile of x. We show that the transition from x to x(1)\ncannot decrease the approximation ratio (Lemma 9).\n3. Figure 8c: Let x(2) be the left-compression of x(1). We show that if the ratio of x(2) is not higher than 2, then so is the ratio of x(1) (Lemma 10).\n4. Figure 8d: Repeat left and right compressions until we can no longer compress. At this stage, the profile is tight with at most 3 active candidates, and we note this profile x(3). We show that the approximation ratio of x(3) is not above 2 (Lemma 11).\nProving these steps is sufficient to complete the proof of the theorem, since in Lemma 11 we show that the ratio of x(3) is not higher than 2 (the base case). According to Lemma 10, this implies that the ratio of x(1) (prior to all of the compressions) is also not higher than 2 (the induction steps). Since the ratio of the x is not higher than that of x(1), this means that the approximation ratio of x is not above 2, as needed.\nNotice that throughout this process Copt remains the optimal candidate, since it was optimal in the original profile x, and in each step all agents move towards it, so the cost of any other candidate can decrease by no more than what the cost of Copt decreases.\nTruthful reports to the spike mechanism (like any other voting mechanism) are not necessarily unique since an agent i who is located on a border can report either of the two candidates closest to her. For these cases of ties, we show that the worst-case ratio always occurs when the agents vote for the candidate located farther away from Copt (Lemma 30, whose formal definition and proof are deferred to the appendix A.2).\nWe now present the lemmas formally. The proofs of the lemmas, which are given in the appendix, prove the backwards induction and conclude the proof of the theorem at large.\nLemma 9. Let x be an arbitrary location profile, let x\u2032 be the tight profile of x and let M be an arbitrary WPV mechanism. Then the approximation ratio of M given x\u2032 is not lower than that of M given x:\nSC(M,x) SC(OPT,x) \u2264 SC(M,x\n\u2032)\nSC(OPT,x\u2032) .\nThe previous lemma holds for any WPV mechanism, in particular for spike.\nLemma 10. Let x be a tight location profile, let x\u2032 be the left-compressed profile of x and let S be the spike mechanism. Then if the approximation ratio of S given x\u2032 is not higher than 2, then so is that of S given x:\nSC(S,x\u2032)\nSC(OPT,x\u2032) \u2264 2\u21d2 SC(S,x) SC(OPT,x) \u2264 2\nSince the cumulative function defining the spike mechanism is symmetrical, the claim can be trivially extended to right-compressions as well.\nAfter reapplying compressions on both sides, the resulting profile has agents in three locations at most (see Figure 8d). The last lemma in the proof states that in this final stage, the ratio is not higher than 2:\nLemma 11. Let x be a tight location profile in which there are at most 3 active candidates: yopt\u22121 < yopt < yopt+1. The ratio of the S given x is not higher than 2: SC(S,x)\nSC(OPT,x) \u2264 2."}, {"heading": "5 Additional Results for Randomized Mechanisms", "text": ""}, {"heading": "5.1 Lower Bounds", "text": "In this section show lower bounds of randomized mechanisms in different settings. When the network is <, we present a lower bound of 2 for any truthful in expectation mechanism, even if it is a location mechanism. By the hierarchy presented in Theorem 1, this lower bound trivially holds for truthful in expectation ranking and voting mechanisms as well (see Figure 1). Ergo, spike is optimal over all truthful in expectation mechanisms.\nAdditionally, we show a lower bound of 2 for any randomized ranking mechanism, even when the mechanism need not be truthful (in the non-strategic setting). These results prove that the approximation ratio achieved by spike is tight. For more general metric spaces the lower bound changes \u2014 In <d, we show a lower bound for any truthful voting mechanism of 3 \u2212 2d+1 . We also present a lower bound of 7/3 for any truthful ranking mechanism in <2 (this bound also holds for <d, for any d > 2).\nWe start by proving a helpful lemma. Informally, the lemma states that when there is an agent located on a border (and can therefore submit several different truthful actions to a ranking or voting mechanism), her cost should not change under any truthful report she submits.\nLemma 12. For any truthful in expectation ranking mechanism M in any metric space, let bi,j be the border between ranking zones Ri,Rj. Let \u03c0i, \u03c0j be the rankings consistent with Ri,Rj respectively. Let agent l be located on this border, that is: xl \u2208 bi,j. Then the cost at point xl remains the same whether the agent reports \u03c0i or \u03c0j, that is:\ncostxl(M, (al = \u03c0i, a\u2212l)) = costxl(M, (al = \u03c0j , a\u2212l))\nThe proof is given in appendix A.3.\nObservation 13. The previous lemma also holds for voting mechanisms.\nThe proof of the observation follows the exact same lines as the proof of the lemma.\nTheorem 14. In the d dimensional real space <d, any truthful in expectation voting mechanism has an approximation ratio of at least 3\u2212 2d+1 .\nProof. Let there be d+ 1 candidates, located on the vertices of a regular simplex H (all d+ 1 vertices are equally distanced from one another). Let there be d + 1 agents, and let M be an arbitrary truthful in expectation voting mechanism.\nLet x be the profile in which each agent i is located precisely on candidate Ci. Therefore a = (C1, C2 . . . Cd+1) is the only truthful voting profile for x. Denote the probability of choosing candidate i as pi(a), that is: pi(a) = Pr(M(a) = Ci). Clearly there exists some candidate which is chosen by M with probability at least 1d+1 . Assume without loss of generality that this candidate is Cd+1, that is: pd+1(a) \u2265 1d+1 . We move on to define another location profile, x\u2032, which is also consistent with the voting profile a. Let H \u2032 be the regular simplex in which candidates C \\ Cd+1 are on the vertices. Let P be the point with equal distance to all d vertices in H \u2032 (H \u2032 is a regular simplex, so such a point necessarily exists). Denote this distance as t. However, this distance is different from the distance from P to Cd+1: |P \u2212 yd+1| = u 6= t. Let x\u2032 be the profile in which there are k agents at P and one agent at Cd+1 (see Figure 9).\nAccording to Observation 13, the cost of an agent at point P should not change under any truthful vote, that is for any vote Cj : 1 \u2264 j \u2264 d. In particular, this holds when any\nagent on point P votes for candidate C1. We make use of this observation several times by changing the votes for each of the points at P to C1, one at a time, such that the final voting profile is a\u2032 = {C1, C1 . . . C1, Cd+1} (d agents vote for C1, one agent votes for Cd+1).. Due to the observation, the cost of point P must remain the same throughout these transitions, that is: costP (M,a\n\u2032) = costP (M,a). Therefore:\ncostP (M,a) = costP (M,a \u2032)\n\u21d2 u \u00b7 pd+1(a) + t \u00b7 (1\u2212 pd+1(a)) = u \u00b7 pd+1(a\u2032) + t \u00b7 (1\u2212 pd+1(a\u2032)) \u21d2 t+ (u\u2212 t) \u00b7 pd+1(a) = t+ (u\u2212 t) \u00b7 pd+1(a\u2032) \u21d2 pd+1(a\u2032) = pd+1(a) \u21d2 pd+1(a\u2032) \u2265 1\nd+ 1\nDenote the midpoint between y1 and yd+1 as Q. Without loss of generality, scale the distances such that |y1 \u2212 Q| = |Q \u2212 yd+1| = 1. Examine the following location profile x\u2032\u2032 = (C1, C1 . . . C1, Q), which is also consistent with the voting profile a\u2032. In this case the cost of C1, which is the optimal candidate, is: SC(C1,x\u2032\u2032) = 1. The cost of Cd+1 is SC(Cd+1,x\u2032\u2032) = d \u00b72+1 = 2d+ 1. Therefore the approximation ratio of M is at least:\nSC(M,x\u2032\u2032)\nSC(OPT,x\u2032\u2032) = pd+1(a\n\u2032)(2d+ 1) + (1\u2212 pd+1(a\u2032))(1)\n= 2d \u00b7 pd+1(a\u2032) + 1 \u2265 (2d) 1 d+ 1 + 1 = 2d+ 2\u2212 2 d+ 1 + 1 = 3\u2212 2 d+ 1\ny1, x1\ny2, x2\ny3, x3\nP\nQ\ny1\ny2\ny3, x3\nQ\nP, x1, x2 y1, x1, x2\ny2\ny3\nP\nQ, x3\n1\nFigure 9: An illustration of the proof of Theorem 14 for the case of d = 2. The three candidates are on the vertices of an equilateral triangle (a regular simplex with 3 vertices). The lines within the triangle denote the borders between a pair of candidates. The simplex H \u2032 is the line between y1, y2, and its midpoint is P . These three figures, from left to right, show the dynamics of the proof (location profiles x,x\u2032 and x\u2032\u2032 respectively). The key observation is that the agents at point P are at equal distance to all candidates except C3, therefore the transition does not change the probability of C3 to be chosen.\nObservation 15. Any truthful in expectation location mechanism has an approximation ratio of at least 2, even on the line.\nProof. Let there be two candidates on the line. According to Theorem 1, any truthful in expectation location mechanism is equivalent to a voting mechanism. One can apply the same proof as in Theorem 14 for the case of d = 1 (in this case, both point P and point Q are the midpoint between the two candidates), to achieve a lower bound of 3\u2212 2d+1 = 2.\nTheorem 16. In <2, any truthful in expectation ranking mechanism has an approximation ratio of at least 7/3.\nProof. Let there be 3 candidates located such that they form an equilateral triangle, and let M be a truthful in expectation ranking mechanism. Let a = (a1, a2, a3) be the following ranking profile:\na1 = C1 C2 C3 a2 = C2 C3 C1 a3 = C3 C1 C2\nLet x be some location profile consistent with a (see Figure 10). Denote pi(a) = Pr[M(a) = Ci]. From symmetry, there exists some candidate chosen with probability at least 1/3. Assume without loss of generality that this is candidate C3, that is: p3(a) \u2265 1/3.\nLet P1 be a point such that |P1\u2212y1| = |P1\u2212y2| = t1, and |P1\u2212y3| = u1, where t1 6= u1. Let x\u2032 = (P1, x2, x3). Let a \u2032 1 = C2 C1 C3 and let a\u2032 = (a\u20321, a2, a3). Notice that x\u2032 is consistent with both a and a\u2032, therefore according to Lemma 12 the cost at P1 should remain the same for a,a\u2032:\ncostP1(M,a) = costP1(M,a \u2032)\n\u21d2 u1 \u00b7 p3(a) + t1 \u00b7 (1\u2212 p3(a)) = u1 \u00b7 p3(a\u2032) + t1 \u00b7 (1\u2212 p3(a\u2032)) \u21d2 t1 + (u1 \u2212 t1) \u00b7 p3(a) = t1 + (u1 \u2212 t1) \u00b7 p3(a\u2032) \u21d2 p3(a\u2032) = p3(a) \u21d2 p3(a\u2032) \u2265 1\n3\nLet P2 be a point such that |P2 \u2212 y2| = |P2 \u2212 y1| = t2, and |P2 \u2212 y3| = u2, where t2 6= u2. Let x\u2032\u2032 = (x\u20321, x2, P2). Let a \u2032\u2032 3 = C3 C2 C1 and let a\u2032\u2032 = (a\u20321, a2, a\u2032\u20323). According to Lemma 12 the cost at P2 should remain the same for a \u2032,a\u2032\u2032:\ncostP2(M,a \u2032) = costP2(M,a \u2032\u2032)\n\u21d2 u2 \u00b7 p3(a) + t2 \u00b7 (1\u2212 p3(a\u2032)) = u2 \u00b7 p3(a\u2032\u2032) + t2 \u00b7 (1\u2212 p3(a\u2032\u2032)) \u21d2 p3(a\u2032\u2032) = p3(a\u2032) \u21d2 p3(a\u2032\u2032) \u2265 1\n3\nLet Q be the midpoint between y2, y3, and let x \u2032\u2032\u2032 = (y2, y2, Q). Without loss of generality, scale the distances such that |y3 \u2212 Q| = |Q \u2212 y2| = 1. Therefore the cost of C2, the optimal candidate, is: SC(C2,x\u2032\u2032\u2032,a\u2032\u2032) = SC(OPT,x\u2032\u2032\u2032,a\u2032\u2032) = 1. The cost of C3 is: SC(C3,x\u2032\u2032\u2032,a\u2032\u2032) = 2 \u00b7 2 + 1 = 5. Therefore the approximation ratio of M is at least:\nSC(M,x\u2032\u2032\u2032,a\u2032\u2032)\nSC(OPT,x\u2032\u2032\u2032,a\u2032\u2032) = p3(a\n\u2032\u2032) \u00b7 5 + (1\u2212 p3(a\u2032\u2032)) \u00b7 1 = 1 + 4 \u00b7 p3(a\u2032\u2032) \u2265 1 + 4\n3 =\n7\n3\ny1\ny2\ny3\nx1\nx2\nx3\ny1\ny2\ny3\nP1, x1 x2\nx3\ny1\ny2\ny3\nP1, x1 x2\nP2, x3\ny1\ny2, x1, x2\ny3\nQ, x3\n1\nFigure 10: An illustration of the proof of Theorem 16. These four figures, from left to right, show the dynamics of the proof (profiles x, x\u2032, x\u2032\u2032 and x\u2032\u2032\u2032 respectively).\nLemma 17. No randomized ranking mechanism can achieve an approximation ratio strictly below 2, even if the metric is < and even if there are no truthfulness requirements from the mechanism (non-strategic case).\nThe proof is deferred to appendix A.3."}, {"heading": "5.2 Upper Bound", "text": "We previously showed that spike achieves an approximation ratio of 2 on the line. We now show that for a general metric space, random dictator achieves a ratio of 3.\nRandom dictator is a simple randomized mechanism which achieves an approximation ratio of 2 in the continuous model. Recall that random dictator locates the facility on vote ai with probability 1/n for all i \u2208 N . We show that in our model, it yields a competitive ratio of 3 for any metric space (but it cannot improve beyond 3 even on the line).\nLemma 18. On any metric space, random dictator achieves an approximation ratio of exactly 3.\nThe proof can be found in appendix A.3. As opposed to the continuous model, in our candidate model random dictator is not groupstrategyproof. Refer to A.3 in the appendix for the definition of group-strategyproofness, and for proof of this statement."}, {"heading": "6 Deterministic Mechanisms", "text": ""}, {"heading": "6.1 Lower Bound", "text": "In the continuous model it is well known that choosing the location of the median agent is both truthful and optimal [23]. The following lemma shows that this does not hold in our candidate model.\nLemma 19. No deterministic truthful mechanism (location, ranking or voting) can achieve an approximation ratio strictly below 3 for the social cost, even when the metric space is <.\nProof. Let there be 2 candidates such that y1 = \u22121 and y2 = 1. According to the sixth claim in Theorem 1 (Claim 29), any truthful location mechanism M is necessarily reducible to a voting mechanism. Let x = (\u22121, ), x\u2032 = (\u2212 , 1) be two location profiles, and let B be the border between them. Clearly, both profiles correspond with the same votes (x1, x \u2032 1 \u2208 V1 \\ B and x2, x \u2032 2 \u2208 V2 \\B), therefore their outcome will be identical.\nIf M(x) = M(x\u2032) = C1, then the approximation ratio for M given x is SC(M,x)SC(OPT,x) = 3\u2212 1+ . If M(x) = M(x\u2032) = C2 then the approximation ratio for M given x\u2032 is SC(M,x \u2032)\nSC(OPT,x\u2032) = 3\u2212 1+ .\nIn either case, the approximation ratio tends to 3 as tends to 0.\nA result by Anshelevich et al. (Theorem 3 in [3]) uses a similar method to show the worst case for ranking mechanisms with non-strategic agents is 3 (the proof in that paper was done for a general metric space, but it can also be applied to <). Lemma 19 makes use of Claim 29 to prove that the same lower bound of 3 also applies even to location mechanisms, under the condition that the mechanism must be truthful (when the agents are strategic)."}, {"heading": "6.2 Upper Bound", "text": "As noted previously, in the continuous model on <, the mechanism which locates the facility on the report of the median agent is truthful and results in the optimal social cost. We define the median mechanism in the context of candidate constraints, and assess its social cost. Definition 20 (Median mechanism). Given a vote profile a, let \u03c0 be a permutation such that y ( a\u03c0(1) ) \u2264 . . . \u2264 y ( a\u03c0(n) ) . Median is a voting mechanism which chooses the median vote, that is a\u03c0(dn/2e).\nLemma 21. Median is a truthful mechanism which results in a 3 approximation of the optimal social cost on <.\nThe proof is given in the appendix A.4."}, {"heading": "7 Open Problems", "text": "As explained in the introduction, we believe that there are many possible manifestations of this setting, though it has barely been investigated, so there is plenty of room for future work. Clearly, there are gaps in some of the bounds in the paper which are currently open. Additionally, one can investigate the questions from the facility location literature in this setting, e.g., electing a committee of several candidates, addressing the problem of \u201cobnoxious facility location\u201d in which the agents wish to elect the candidate farthest away from them, or proving additional bounds for group strategyproofness."}, {"heading": "Acknowledgements", "text": "We would like to thank Alon Eden, Ilan Cohen, Ophir Friedler, Shai Vardi, Rachel Matichin, Sella Nevo, Guy Reiner, Lirong Xia and Elliot Anshelevich for interesting discussions."}, {"heading": "A Appendix", "text": "A.1 Missing Proofs from Section 3\nIn this part we aim to define reducibility of some mechanism type (voting, ranking or location) to some other mechanism type. The definition of the reduction requires a couple of additional definitions, which we will express formally as well as explain intuitively.\nIntuitively, we say that a mechanism type A\u0302 is of finer granularity than mechanism type B\u0302, if the information of a true action in A\u0302 can determine a true action in B\u0302. For instance, a location determines a ranking (or several rankings, if a point is on a border), therefore location mechanisms are of finer granularity than ranking mechanisms. Similarly, ranking mechanisms are of finer granularity than voting mechanisms, and location mechanisms are also of finer granularity than voting mechanisms. However, ranking mechanisms are not of finer granularity than location mechanisms, since a ranking does not determine a location. That is, for a ranking \u03c01 there exist different locations x1, x2 whose true ranking is \u03c01. Formally, a mechanism type A\u0302 : A \u2192 C is of finer granularity than mechanism type B\u0302 : B \u2192 C if for any point x and any a \u2208 A there exists some b \u2208 B such that: if a is a true action of an agent at point x under A\u0302, then b is a true action of point x under B\u0302. In this case we denote A\u0302 B\u0302.\nWe now utilize this notion of granularity to define consistent functions. Intuitively, we would like to define functions which map between inputs of different mechanism types in a \u201cconsistent\u201d manner. For instance, when mapping from rankings (the input to ranking mechanisms) to votes (candidates, that is - the input to voting mechanisms), we search for functions which map each ranking to the top candidate in that ranking. When mapping from votes to rankings, we seek functions which map a vote for a candidate to some ranking in which this candidate is first. Formally, given mechanism types A\u0302 : A \u2192 C and B\u0302 : B \u2192 C such that A\u0302 B\u0302, a function f : A \u2192 B is called consistent if for any point x and for any a \u2208 A, then if a is a true action under A\u0302, then f(a) is a true action under B\u0302. Notice that in these cases a function f is unique (except for the cases in which A\u0302 is a location mechanism and x is a point on a border). If B\u0302 A\u0302 then we define f : A\u2192 B to be consistent if for any point x, if f(a) is a true action for x under B\u0302 then a is a true action for x under A\u0302. In these cases the function f is not unique (for example, there are several rankings in which a specific candidate is first).\nThe function f may be randomized, as long as it is a randomization over deterministic consistent functions. For example, a consistent function f mapping locations (the input of location mechanisms) to candidates (the inputs of voting mechanisms) must map every point which is not on a border to their favorite candidate. On the other hand, for a point x on some border, f may randomize the output of x arbitrarily over the set of favorite candidates of x.\nA candidate selection mechanism M (whether location, ranking or voting) is said to be reducible to a candidate selection mechanism M \u2032 (location, ranking, or voting) if there exists a consistent function f mapping every action profile a, which is an input of M , to some action profile f(a) = a\u2032 which is the input of M \u2032, such that the distribution over the candidates, M(a), is identical to the distribution over candidates M \u2032(a\u2032) (see Figure 11).\nFor example, every voting mechanism, M , is reducible to some ranking mechanism M \u2032. The reduction is as follows: Let f be the consistent function describes previously \u2013 it receives a vector of n candidates, and outputs a vector of n rankings (permutations), where for each i, the i\u2019th candidate is ranked first in the i\u2019th ranking. We choose a ranking mechanism M \u2032 which ignores all entries in the rankings but the first, and simulates the voting mechanism M on the top entries of the rankings. By definition, M is reducible to M \u2032. Moreover, note that M was an arbitrary voting mechanism, so we conclude that indeed every voting mechanism is reducible to some ranking mechanism. This logic further shows that for mechanism types A\u0302, B\u0302 such that B\u0302 A\u0302, any mechanism M of type A\u0302 is reducible to some mechanism M \u2032 of type B\u0302.\nAs written in Section 3, two sets of mechanisms, S1 and S2, are said to be equivalent if every M1 \u2208 S1 is reducible to some M2 \u2208 S2, and every M2 \u2208 S2 is reducible to some M1 \u2208 S1. A set of mechanisms S1 is said to be strictly contained in a set of mechanisms S2 if every mechanism M1 \u2208 S1 is reducible to some mechanism M2 \u2208 S2, yet not every mechanism M2 \u2208 S2 is reducible to some mechanism M1 \u2208 S1. This is a slight abuse of terminology since the sets S1 and S2 may be disjoint, as their input space may be different.\nThe following lemma will be of use in the main theorem of this section.\nLemma 22. In any metric space, let A\u0302, B\u0302 be mechanism types such that B\u0302 A\u0302. Let S1, S2 be the sets of truthful mechanisms of type A\u0302, B\u0302 respectively. Then for any M1 \u2208 S1 there exists some M2 \u2208 S2 such that M1 is reducible to M2.\nProof. By the fact that B\u0302 is of finer granularity than A\u0302 and by the definition of the consistent function f , it is eminent that M1 is reducible to some M2 of type B\u0302 since M2 can completely disregard any input beyond any information in A\u0302 and simulate M1 (as explained previously for the example in which a ranking mechanism disregards any candidate except for the top candidate in each ranking).\nIn order to complete the proof, it is left to show that there exists such a mechanism M2 which is truthful. Since the only reports which change the outcome of M2 are consistent with reports which would change the outcome of M1, then if M2 weren\u2019t truthful this would contradict the truthfulness of M1.\nObservation 23. Notice that this reasoning also holds for truthful in expectation mechanisms (that is if S1, S2 are defined as the sets of truthful in expectation mechanisms of types A\u0302, B\u0302).\nWe move on to proving the main theorem of this section:\nProof. of Theorem 1: The proof of each claim is given separately:\nClaim 24. The class of truthful deterministic ranking mechanisms strictly contains the class of truthful deterministic voting mechanisms.\nProof. According to Lemma 22 any truthful voting mechanism is reducible to some truthful ranking mechanism. We exhibit a deterministic truthful ranking mechanism M which is not reducible to any voting mechanism (even on <). We show this by exhibiting an example in which M acts differently under two ranking profiles which are mapped by any consistent function to the same voting zone.\nLet there be 3 candidates, and denote the ranking zones R1,R2,R3,R4, which match the permutations over candidates \u03c01, \u03c02, \u03c03, \u03c04 respectively (see Figure 12). M acts as follows: If a1 \u2208 \u03c01 \u222a \u03c02 and a2 \u2208 \u03c01 \u222a \u03c02, then choose C1. Otherwise, choose C3.\nC1 C2 C3b1,2 b1,3 b2,3\nR1 R2 R3 R4\nx1 x2\nFigure 12: The 4 ranking zones. Every border bi,j is the midpoint between candidates Ci, Cj . The points x1, x2 have different rankings \u2013 the ranking of x1 is \u03c02 = C2 C1 C3 whereas the ranking of x2 is \u03c03 = C2 C3 C1. However, both strictly prefer C2 over any other candidate, therefore for any consistent function f : f(\u03c02) = f(\u03c03) = C2.\nM is truthful \u2014 if C1 is chosen, then both agents prefer it over C3 and have no incentive to misreport. If C3 is chosen, then at least one of the agents is in zones R3 or R4 - this agent has no incentive to misreport since she prefers C3 over C1. The other agent has no influence over the outcome, therefore also has no incentive to misreport.\nM is not reducible to any voting mechanism \u2014 any consistent function f must map both \u03c02 and \u03c03 to C2. However, whilst M acts differently under inputs (\u03c01, \u03c02) and (\u03c01, \u03c03), then if there were a reduction, then both of these would have been mapped to the same location M \u2032(C1, C2) in contradiction.\nClaim 25. The set of truthful deterministic location mechanisms is equivalent to the set of truthful deterministic ranking mechanisms.\nProof. According to Lemma 22, every truthful deterministic ranking mechanism is reducible to some truthful deterministic location mechanism. It is left to show that every truthful deterministic location mechanism M in <d is reducible to a truthful deterministic ranking mechanism M \u2032.\nThe proof consists of several parts. For an arbitrary location profile x and an arbitrary truthful deterministic mechanism M , we define a location profile x\u2032 which has no locations on borders, and show that it necessarily holds that M(x) = M(x\u2032). We then define a different location profile x\u2032\u2032 and show the same: M(x) = M(x\u2032\u2032). The profile x\u2032\u2032 is special in the sense that it is uniquely defined by some ranking profile \u03c0. Finally, we show that given some input \u03c0 = fM (x) a consistent function fM (a function which depends on M , and will be defined later), there exists a ranking mechanism M \u2032 which simulates M on x\u2032\u2032 (see Figure 13). The result is a constructive reduction which maintains the same output as the original location mechanism M(x), as needed.\nLet M be an arbitrary truthful deterministic location mechanism, and let x be an arbitrary location profile. Let M(x) = Cj for some candidate Cj located at yj . Denote the ranking borders as B.\nInformally, we define x\u2032 as a location profile which moves all agents in x which are on a border, an infinitesimal distance towards the chosen candidate Cj . The resulting profile x\u2032 has no agents on borders. We now define this formally: let be some small positive number. For all i such that xi \u2208 B, let ~ i be a vector of size in direction yj \u2212 xi 4. For any i such that xi /\u2208 B, let |~ i| = 0. Let x\u2032 = (x1 + 1, . . . xn + n). We choose an sufficiently small such that for each i, x\u2032i remains in the ranking zone of xi.\nWe now show that M(x) = M(x\u2032) by moving agents from x to x\u2032 one by one, and showing that if any of these transitions were to change the chosen candidate, this would lead to a violation of truthfulness of M . Let:\nw0 = (x1, . . . , xn) = x w1 = (x \u2032 1, x2, . . . , xn) . . . wi = (x \u2032 1, . . . , x \u2032 i, xi+1, . . . , xn) . . . wn = (x \u2032 1, . . . , x \u2032 n) = x \u2032\nAssume towards a contradiction that M(w0) 6= M(wn). Let i be the minimal index such that M(wi\u22121) 6= M(wi). It is known that M(wi\u22121) = M(x) = Cj . Denote M(wi) = Cl, where Cl is located at point yl. There are two options:\n\u2022 If |yl \u2212 xi| < |yj \u2212 xi|, then in profile wi\u22121, xi has an incentive to misreport to x\u2032i.\n\u2022 If |yl \u2212 xi| \u2265 |yj \u2212 xi|, then |yj \u2212 x\u2032i| = |yj \u2212 xi| \u2212 < |x\u2032i \u2212 yl|. Therefore in profile wi, x\u2032i has an incentive to misreport to xi.\nHence, M(x) = M(x\u2032) as needed. Intuitively, we create the location profile x\u2032\u2032 by moving all agents in x\u2032 to some specific point within their ranking zone. Since x\u2032 contained no agents on borders, each agent in x\u2032 is located in exactly one ranking zone, hence x\u2032\u2032 is well defined. We now define this formally: For any ranking zone Ri such that Ri \\B 6= \u2205, let x\u0302i be some point in Ri \\B (for instance, the centroid of the ranking zone Ri)5. Denote the ranking zone which contains x\u2032i as Rj . For all i \u2208 N , let x\u2032\u2032i = x\u0302j . Let x \u2032\u2032 = (x\u2032\u20321, . . . , x \u2032\u2032 n).\nWe now show that M(x\u2032) = M(x\u2032\u2032) in a similar fashion as we showed that M(x) = M(x\u2032) previously. Let:\nh0 = (x \u2032 1, . . . , x \u2032 n) = x \u2032 h1 = (x \u2032\u2032 1, x \u2032 2, . . . , x \u2032 n) . . . hi = (x \u2032\u2032 1, . . . , x \u2032\u2032 i , x \u2032 i+1, . . . , x \u2032 n) . . . hn = (x \u2032\u2032 1, . . . , x \u2032\u2032 n) = x \u2032\u2032\n4If xi = yj then the direction of ~ i can be set arbitrarily. 5We can safely disregard ranking zones which do not have any points which are not on a border, as no point\nin x\u2032 will be in such a zone, since x\u2032 does not contain any points on borders.\nAssume towards a contradiction that M(h0) 6= M(hn). Let i be the minimal index such that M(hi\u22121) 6= M(hi). Denote M(hi) = Cm such that Cm is located at ym. Since x\u2032i, x\u2032\u2032i are in the same ranking zone and not on a border, there are two options:\n\u2022 If |ym \u2212 x\u2032i| < |yj \u2212 x\u2032i|, then in profile hi\u22121, x\u2032i has an incentive to misreport to x\u2032\u2032i .\n\u2022 If |ym \u2212 x\u2032i| > |yj \u2212 x\u2032i|, then it also holds that |ym \u2212 x\u2032\u2032i | > |yj \u2212 x\u2032\u2032i |, and in profile hi, x\u2032\u2032i has an incentive to misreport to x\u2032i.\nTherefore, M(x\u2032) = M(x\u2032\u2032)\u21d2M(x) = M(x\u2032\u2032). It is left to show that it is possible to perform the \u201cnested reductions\u201d as shown in Figure 13. Let fM be the consistent function which breaks ties just like M does. That is, fM simulates M on input x, finds the candidate Cj and breaks ties in favor of rankings closer to Cj . The output of fM is a ranking profile denoted by \u03c0. Given \u03c0, there exists some M\n\u2032 that simulates M on x\u2032\u20326 \u2014 let f \u2032 be a consistent function which maps every ranking \u03c0i (consistent with ranking zone Ri) to the point x\u0302i. Therefore, such a reduction exists, and the output is M(x\u2032\u2032) = M(x).\nClaim 26. The set of truthful in expectation ranking mechanisms strictly contains the set of truthful in expectation voting mechanisms.\nProof. As shown in Observation 23, any truthful in expectation voting mechanism is reducible to some truthful in expectation ranking mechanism. The proof of Claim 24 exhibits a truthful in expectation ranking mechanism which is not reducible to any voting mechanism.\nClaim 27. The set of truthful in expectation randomized location mechanisms strictly contains the set of truthful in expectation randomized ranking mechanisms.\nProof. As shown in Observation 23, any truthful in expectation ranking mechanism is reducible to some truthful in expectation location mechanism.\nWe will show a truthful in expectation location mechanism M which is not reducible to any ranking mechanism: Let there be 3 candidates at points y1 = 0, y2 = 3, y3 = 4. M acts as follows:\nChoose an agent i uniformly at random. Choose the candidates with the following probabilities:\nM(a) = { C1 = 1/3, C2 = 1/3, C3 = 1/3 if ai \u2264 1 C1 = 1/4, C2 = 1/2, C3 = 1/4 otherwise.\nM is not reducible to any ranking mechanism \u2014 any consistent function f must map both points x1 = 0.75 and x2 = 1.25 to \u03c01 = C1 C2 C3. However, mechanism M treats these two inputs differently.\nIt is left to show that M is truthful in expectation. We do so by assessing all possibilities of misreports. Obviously, the mechanism is not affected by any agents except the one who was chosen. Since there are only two possible outcomes, it is sufficient to compare truthful reports ai with misreports a \u2032 i such that a \u2032 i changes the outcome. Let a = (ai, a\u2212i) and a \u2032 = (a\u2032i, a\u2212i).\n6To avoid a circular definition, one can think of M \u2032 simulating a location mechanism which acts precisely like M does.\n\u2022 If xi \u2264 0 it holds that\ncostxi (M,a) = 1\n3 [\u2212xi + (3\u2212 xi) + (4\u2212 xi)] = \u2212xi + 7/3\ncostxi ( M,a\u2032 ) = 1\n4 [\u2212xi + (4\u2212 xi)] +\n1 2 (3\u2212 xi) = \u2212xi + 5/2.\nTherefore: costxi (M,a) \u2264 costxi (M,a\u2032).\n\u2022 If 0 < xi < 3 it holds that\n\u2013 If the outcome is C1 = 1/3, C2 = 1/3, C3 = 1/3, the cost of agent i is:\n1 3 [xi + (3\u2212 xi) + (4\u2212 xi)] = \u2212xi/3 + 7/3.\n\u2013 If the result is C1 = 1/4, C2 = 1/2, C3 = 1/4 the cost of agent i is:\n1 4 (xi + 4\u2212 xi) + 1 2 (3\u2212 xi) = \u2212xi/2 + 5/2.\nIt holds that \u2212xi/3 + 7/3 \u2265 \u2212xi/2 + 5/2 \u21d4 xi \u2265 1. Therefore the first outcome is preferable to agents for which 0 < xi \u2264 1 and the second is better for agents for which 1 < xi < 3, and the mechanism is truthful in expectation in this interval.\n\u2022 If 3 \u2264 xi < 4 it holds that\ncostxi (M,a) = 1\n4 (xi + 4\u2212 xi) +\n1 2 (xi \u2212 3) = xi/2\u2212 1/2\ncostxi ( M,a\u2032 ) = 1\n3 [xi + (xi \u2212 3) + (4\u2212 xi)] = xi/3 + 1/3.\nTherefore: costxi (M,a) \u2264 costxi (M,a\u2032) \u21d4 xi \u2264 5, therefore agent i cannot benefit from misreporting.\n\u2022 If xi \u2265 4 it holds that\ncostxi (M,a) = 1\n4 (xi + xi \u2212 4) +\n1 2 (xi \u2212 3) = xi \u2212 5/2\ncostxi ( M,a\u2032 ) = 1\n3 [xi + (xi \u2212 3) + (xi \u2212 4)] = xi \u2212 7/3.\nTherefore: costxi (M,a) \u2264 costxi (M,a\u2032).\nClaim 28. The set of truthful in expectation randomized voting mechanisms strictly contains the set of universally truthful randomized voting mechanisms.\nProof. Any universally truthful voting mechanism is reducible to a truthful in expectation voting mechanism using the identity function f (which is consistent).\nWe exhibit a truthful in expectation (TIE) voting mechanism M which is not reducible to any universally truthful mechanism. Let there be 2 candidates. M chooses an agent i uniformly at random, and chooses ai with probability 0.9 and the other candidate C \\ ai with probability 0.1.\nM is truthful in expectation since for any agent j, if they are chosen, they are better off receiving their favorite candidate with probability 0.9 than with probability 0.1. M is\nnot universally truthful, since for each agent i there exist cases in which reporting truthfully would lead to choosing their less favorite candidate, while there exist cases in which reporting non-truthfully would lead to choosing the favorite candidate. Clearly, no composition with a consistent function f can transform M to a universally truthful mechanism (for instance, let ai = Cj for some j. From consistency, f(ai) = Cj , so f does not change the outcome at all).\nClaim 29. When there are two candidates, the set of truthful in expectation randomized location mechanisms is equivalent to the set of truthful in expectation randomized voting mechanisms.\nProof. As shown in Observation 23, any truthful in expectation voting mechanism is reducible to some truthful in expectation location mechanism. This also holds for voting mechanisms for two candidates. We now show that any truthful in expectation location mechanism with two candidates is reducible to some truthful in expectation voting mechanism. The proof follows similar lines as the proof of Claim 25.\nLet x be an arbitrary location profile, let M be an arbitrary truthful in expectation location mechanism, and let B be the border between C1 and C2. Define x\u2032 as the location profile which moves all agents which are not on borders to their favorite candidate, that is:\nx\u2032i =  y1 if xi \u2208 V1 \\B y2 if xi \u2208 V2 \\B xi if xi \u2208 B\nWe now show that M(x) = M(x\u2032) by using a hybrid argument. Define:\nw0 = (x1, . . . , xn) = x w1 = (x \u2032 1, x2, . . . , xn) . . . wi = (x \u2032 1, . . . , x \u2032 i, xi+1, . . . , xn) . . . wn = (x \u2032 1, . . . , x \u2032 n) = x \u2032\nAssume towards a contradiction that M(w0) 6= M(wn). Then there exists some index j such that Pr [M(wj) = C1] 6= Pr [M(wj\u22121) = C1]. If this is the case then necessarily xj /\u2208 B since that would imply that wj\u22121 and wj are precisely the same profile. Assume without loss of generality that Pr [M(wj) = C1] > Pr [M(wj\u22121) = C1]. There are 2 options:\n\u2022 If xj , x\u2032j \u2208 V1, then under location profile wj , agent j has an incentive to misreport to x\u2032j .\n\u2022 If xj , x\u2032j \u2208 V2, then under location profile wj\u22121, agent j has an incentive to misreport to xj .\nTherefore is necessarily holds that M(x) = M(x\u2032). We now use x\u2032 to show the reduction: Let f be a function which maps voting profiles to location profiles, by mapping each vote to candidate Ci to location yi. This function is clearly consistent. Let M \u2032 be a voting mechanism which receives a voting profile, translates it to a location mechanism using the consistent function f , and then simulates M on the output of f (see Figure 14).\nFor cases in which no agent is on the border, then the function f \u2032 mapping location profiles to voting profiles is uniquely defined, and it holds that M(x) = M \u2032(f \u2032(x)) = M(f(f \u2032(x))). It is left to show that in cases of agents on borders, there exists some consistent function f \u2032 which breaks ties in the same manner that M does.\nLet x\u2032(1) be a location profile with n1 agents at y1, n2 agents somewhere on the border B and n3 agents at y2. In short, we note x \u2032(1) = (n1, n2, n3). Recognize that x \u2032(1) is a general location profile, after moving agents to their favorite candidates. Using these amounts, define the following two location profiles:\n\u2022 Let x\u2032(2) be the profile in which there are n1 + n2 agents at y1 and n3 agents at y2 (that is x\u2032(2) = (n1 + n2, 0, n3)).\n\u2022 Let x\u2032(3) be the profile in which there are n1 agents at y1 and n2 + n3 agents at y2 (that is x\u2032(3) = (n1, 0, n2 + n3)).\nLet p1 = Pr[M(x \u2032(1)) = C1], and similarly: p2 = Pr[M(x\u2032(2)) = C1] and p3 = Pr[M(x\u2032(3)) = C1]. Under these definitions, we show that: p3 \u2264 p1 \u2264 p2:\n\u2022 p1 \u2264 p2: Start with the profile x\u2032(1), and move agents on the border one by one to y1. If in each step the probability of choosing C1 does not decrease then p1 \u2264 p2 as needed. Otherwise, there exists a profile x\u0302 = (ni, nj , n3) for which the probability of choosing C1 is smaller than in the profile with x\u0302\u2032 = (ni \u2212 1, nj + 1, n3). If this were the case, then the agents on y1 in profile x\u0302 would benefit from misreporting to the point on a border, in contradiction to truthfulness.\n\u2022 p3 \u2264 p1 is proved in the exact symmetrical manner, by moving agents from B to y2 one by one.\nBy definition, a consistent function can map agents on borders to either of the two candidates, and can also choose any probabilities over the two agents. Therefore, for any 0 \u2264 q \u2264 1, there exists a consistent function which takes n agents on the border and maps all of them to C1 with probability q and maps all of them to C2 with probability 1\u2212 q. For any p1, we choose the consistent function f \u2032 which uses a q such that p2 \u00b7 q+ p3 \u00b7 (1\u2212 q) = p1. Under this function f \u2032, the reduction does not change the outcome of the mechanism, as needed.\nA.2 Missing Proofs from Section 4\nProof. of Lemma 2: Let x be some location profile. Let a be a voting profile, where a is in ascending order, that is: y(a1) \u2264 y(a2) \u2264 . . . \u2264 y(an). Let a\u2032i be a misreport of some agent i,\naj\u22121 aj\u22121\na\u2032j\u22121\naj aj\na\u2032j\na\u2032i\na\u2032j+1\naj+1 aj+1\na\u2032j+2\nai\u22121 ai\u22121\na\u2032i\nai ai+1\ny(ai+1) y(a\u2032i+1)\na:\na\u2032:\nFigure 15: Misreporting in a WPV: a is shown in the first line, the misreport in the second line, and the misreport after renaming the reports in ascending order in the third line.\nand without loss of generality assume y(a\u2032i) < y(ai). Denote the report directly to the left of a \u2032 i as aj , that is: y(aj) \u2264 y(a\u2032i) \u2264 y(aj+1) . Let a\u2032 be the reports (a\u2032i, a\u2212i) in ascending order (see Figure 15).\ncostxi(M,a)\u2212 costxi(M,a\u2032) = n\u2211 k=1 pk|y(ak)\u2212 xi| \u2212 n\u2211 k=1 pk|y(a\u2032k)\u2212 xi|\n= i\u2211\nk=j+1\npk[|y(ak)\u2212 xi| \u2212 |y(a\u2032k)\u2212 xi|]\nThe last equality holds since for any k such that k \u2264 j or k > i: y(ak) = y(a\u2032k). For any k such that: j < k \u2264 i: |y(a\u2032k) \u2264 y(ak)|. In this case:\n\u2022 If xi \u2265 y(ak): |y(a\u2032k)\u2212 xi| \u2265 |y(ak)\u2212 xi| from the triangle inequality.\n\u2022 If xi < y(ak): Then y(ak) = y(ai) and ai is the true action of xi, i.e., there is no candidate closer to xi than it.\nTherefore, for all k: |y(ak)\u2212xi| \u2264 |y(a\u2032k)\u2212xi|. Hence the agent cannot benefit from misreporting regardless of the results of the random bits, so M is universally truthful.\nProof. of Lemma 9: For any candidate j denote pj = Pr[M(a) = yj ] and p \u2032 j = Pr[M(a \u2032) = yj ]. Define \u2206j as the difference in the cost of candidate j under profile x and her cost under x\n\u2032, that is: \u2206j = \u2211n i=1 |yj \u2212xi|\u2212 \u2211n i=1 |yj \u2212x\u2032i|. Since x\u2032 was defined by moving all agents towards Copt, then: \u2200j : \u2206opt \u2265 \u2206j . As noted previously, this means that Copt remains the optimal candidate under a\u2032. According to Lemma 30, the worst-case ratio occurs when all agents on borders vote outwards (farther from yopt), so the probabilities under a\n\u2032 remain the same as under a: \u2200j : pj = p\u2032j .\nWe now assess the approximation ratio under profile x\u2032:\nSC(OPT,x\u2032) = \u2211 i |yopt \u2212 x\u2032i| = SC(OPT,x)\u2212\u2206opt\nThe cost of the spike mechanism on x\u2032 is:\nSC(M,x\u2032) = p\u2032j \u00b7 [\u2211 i |yj \u2212 x\u2032i| ]\n= pj \u00b7 [(\u2211 i |yj \u2212 xi| ) \u2212\u2206j ]\n\u2265 pj \u00b7 [(\u2211 i |yj \u2212 xi| ) \u2212\u2206opt ] = SC(M,x)\u2212\u2206opt\nTherefore, the new approximation ratio is:\nSC(M,x\u2032)\nSC(OPT,x\u2032) \u2265 SC(M,x \u2032)\u2212\u2206opt SC(OPT,x\u2032)\u2212\u2206opt \u2265 SC(M,x) SC(OPT,x)\nProof. of Lemma 10: We use the same notation as in Figures 8b and 8c where there are ni agents at point x\u0302i.\nLet \u2206 = SC(OPT,x) \u2212 SC(OPT,x\u2032) = n1 \u00b7 (x\u03022 \u2212 x\u03021) > 0. It is sufficient to show that SC(S,x,a)\u2212 SC(S,x\u2032,a) \u2264 2\u2206 since that would imply:\nSC(S,x,a) SC(OPT,x) \u2264 SC(S,x\n\u2032,a) + 2\u2206\nSC(OPT,x\u2032) + \u2206 \u2264 2 \u00b7 SC(OPT,x\n\u2032)) + 2\u2206\nSC(OPT,x\u2032) + \u2206 = 2\nDenote the probabilities as follows: pi = Pr[S(a) = yi], p \u2032 i = Pr[S(a \u2032) = yi]. Similarly, the costs of the candidates are denoted: ci = SC(Ci,x) = \u2211n j=1 |xj \u2212 yi| and c\u2032i = SC(Ci,x\u2032) =\u2211n\nj=1 |x\u2032j \u2212 yi|. The probabilities and costs under profile x\u2032 are:\np\u2032i =  0 if i = 1 p1 + p2 if i = 2\npi if i \u2265 3\nDenote \u03b4 = n1 (|x\u03022 \u2212 y2| \u2212 |y2 \u2212 x\u03021|), so the costs are:\nc\u2032i = { c2 + n1 (|x2 \u2212 y2| \u2212 |y2 \u2212 x1|) = c2 + \u03b4 if i = 2 ci \u2212\u2206 if i \u2265 3\nTherefore, the difference in the cost is: SC(S,x)\u2212 SC(S,x\u2032) = \u2211 i ( pici \u2212 p\u2032ic\u2032i ) = p1c1 + p2c2 \u2212 (p1 + p2) (c2 + \u03b4) +\n\u2211 i\u22653 pi [ci \u2212 (ci \u2212\u2206)]\n= p1 (c1 \u2212 c2 \u2212 \u03b4)\u2212 p2 \u00b7 \u03b4 + \u2211 i\u22653 pi\u2206 = p1 (c1 \u2212 c2 \u2212 \u03b4)\u2212 p2 \u00b7 \u03b4 + (1\u2212 p1 \u2212 p2) \u2206\nDue to the triangle inequality:\n|x\u03022 \u2212 y2| \u2264 |x\u03022 \u2212 x\u03021|+ |x\u03021 \u2212 y2| \u21d4 \u03b4 = n1 (|x\u03022 \u2212 y2| \u2212 |x\u03021 \u2212 y2|) \u2264 n1|x\u03022 \u2212 x\u03021| = |\u2206|\nTherefore:\np1 (c1 \u2212 c2 \u2212 \u03b4)\u2212 p2 \u00b7 \u03b4 + (1\u2212 p1 \u2212 p2) \u2206 \u2264 p1 (c1 \u2212 c2 + \u2206) + p2 \u00b7\u2206 + (1\u2212 p1 \u2212 p2) \u2206 = p1 (c1 \u2212 c2) + \u2206\nAlso c1 \u2212 c2 = (n\u2212 n1)|y2 \u2212 y1|, so together:\nSC(S,x)\u2212 SC(S,x\u2032) \u2264 p1 [(n\u2212 n1)|y2 \u2212 y1|] + \u2206\nTo conclude the proof it is left to show that p1 [(n\u2212 n1)|y2 \u2212 y1|] \u2264 \u2206 = |x\u03022 \u2212 x\u03021|n1. Since |y2\u2212y1|\n2 = |y2 \u2212 x\u03021| < |x\u03022 \u2212 x\u03021|, it is sufficient to show that: p1(n \u2212 n1) \u2264 n1 2 . S is a spike\nmechanism, so p1 is:\n\u2022 If n1 \u2264 n/2 then: p1 = n12(n\u2212n1) \u21d2 p1(n\u2212 n1) = n1 2(n\u2212n1)(n\u2212 n1) = n1/2.\n\u2022 If n1 > n/2 then: p1 = 1.5\u2212 n2n1 = 3n1\u2212n 2n1 , so:\np1(n\u2212 n1) = 3n1 \u2212 n\n2n1 (n\u2212 n1) = \u2212n2 \u2212 3n21 + 4nn1 2n1 = \u2212n2 \u2212 4n21 + 4nn1 2n1 + n21 2n1\n= \u2212(n\u2212 2n1)2 2n1 + n1 2 \u2264 n1 2 .\nThis concludes the proof of the lemma.\nProof. of Lemma 11: We use the notations of the location of the left, center and right candidates in the following manner yL = yopt\u22121, yC = yopt, yR = yopt+1, and the amount of agents in bL, yC , bC as L,C,R respectively (see Figure 8d). Denote the probabilities of choosing the candidates as pL = Pr(S(x) = yL), pC = Pr(S(x) = yC), pR = Pr(S(x) = yR). Also, without loss of generality, the distances can be scaled such that bC \u2212 yC = 1. Define: \u03b2 = yC \u2212 bL.\nThe costs of the different candidates are:\nSC(CL,x) = \u03b2 \u00b7 (L+ 2C + 2R) +R SC(CC ,x) = L \u00b7 \u03b2 +R = SC(OPT,x) SC(CR,x) = L\u03b2 + (2L+ 2C +R)\nDue to the definition of the spike mechanism, the proof is broken into two parts:\n1. The median agent is on yC\n2. The median agent is on bL\nNote that the last option (in which the median agent is on bC) is identical to the second case due to symmetry, therefore proving for these two cases is sufficient.\nIn the first case, the median agent is at the center, therefore L < C + R and R < L + C, and from the definition of the spike mechanism:\npL = L\n2(C +R)\npR = R\n2(C + L)\npC = 1\u2212 pL \u2212 pR = 1\u2212 L 2(C +R) \u2212 R 2(C + L)\nTherefore the ratio is:\nSC(M,x)\nSC(OPT,x) = pLSC(CL,x) + pCSC(CC ,x) + pRSC(CR,x) SC(CC ,x)\n= pLSC(CL,x) + pRSC(CR,x)\nSC(CC ,x) + pC\n= 1\nL\u03b2 +R\n[ L(\u03b2(L+ 2C + 2R) +R)\n2(C +R) + R(L\u03b2 + (2L+ 2C +R)) 2(L+ C) ] + ( 1\u2212 L\n2(C +R) \u2212 R 2(L+ C) ) = 1 + L(L\u03b2 + 2C\u03b2 + 2R\u03b2 +R)\n2(C +R)(L\u03b2 +R) \u2212 L(L\u03b2 +R) 2(C +R)(L\u03b2 +R)\n+ R(L\u03b2 + 2L+ 2C +R) 2(L+ C)(L\u03b2 +R) \u2212 R(L\u03b2 +R) 2(L+ C)(L\u03b2 +R)\n= 1 + L(2C\u03b2 + 2R\u03b2)\n2(C +R)(L\u03b2 +R) +\nR(2L+ 2C)\n2(L+ C)(L\u03b2 +R)\n= 1 + L\u03b2\nL\u03b2 +R +\nR\nL\u03b2 +R = 2\nTherefore the ratio cannot exceed 2 in the first case. In the second case the median agent is at bL and the probabilities are:\npL = 1.5\u2212 L+ C +R 2L = 1\u2212 C +R 2L pR = R\n2(C + L) pC = 1\u2212 pL \u2212 pR = 1\u2212 (\n1\u2212 C +R 2L\n) \u2212 R\n2(C + L)\n= C +R 2L \u2212 R 2(C + L)\nTherefore the approximation ratio is:\nSC(M,x) SC(OPT,x) = pLSC(CL,x) + pRSC(CR,x) SC(CC ,x) + pC\n= 1\nL\u03b2 +R\n[( 1\u2212 C +R\n2L\n) (L\u03b2 + 2C\u03b2 + 2R\u03b2 +R) +\nR\n2(L+ C) (L\u03b2 + 2L+ 2C +R) ] + C +R\n2L \u2212 R 2(C + L)\n= 1\nL\u03b2 +R\n[ L\u03b2 +R+ 2C\u03b2 + 2R\u03b2 \u2212 (C +R)(L\u03b2 + 2C\u03b2 + 2R\u03b2 +R)\n2L + R(2L+ 2C + L\u03b2 +R) 2(L+ C) ] + C +R\n2L \u2212 R 2(C + L)\n= 1 + 1\nL\u03b2 +R\n[ 2\u03b2(C +R)\u2212 (C +R)L\u03b2\n2L \u2212 (C +R)(2C\u03b2 + 2R\u03b2 +R) 2L +R+ R(L\u03b2 +R) 2(L+ C) ] + C +R\n2L \u2212 R 2(C + L)\n= 1 + 1\nL\u03b2 +R\n[ 3\u03b2(C +R)\n2 \u2212 (C +R)(2C\u03b2 + 2R\u03b2 +R) 2L +R\n] +\nR\n2(L+ C)\n+ C +R 2L \u2212 R 2(C + L)\n= 1 + 3\u03b2(C +R) + 2R 2(L\u03b2 +R) \u2212 (C +R)(2C\u03b2 + 2R\u03b2 +R) (L\u03b2 +R)2L +\nLR 2L(L+ C) + C +R 2L \u2212 R 2(C + L)\n= 1 + 3\u03b2(C +R) + 2R 2(L\u03b2 +R) \u2212 (C +R)(2C\u03b2 + 2R\u03b2 +R) 2L(L\u03b2 +R) + (C +R) 2L\nNow, in order to show this is a 2 approximation:\n1 + 3\u03b2(C +R) + 2R 2(L\u03b2 +R) \u2212 (C +R)(2C\u03b2 + 2R\u03b2 +R) 2L(L\u03b2 +R) + (C +R) 2L \u2264 2\n\u21d4 3\u03b2(C +R) + 2R 2(L\u03b2 +R) \u2212 (C +R)(2C\u03b2 + 2R\u03b2 +R) 2L(L\u03b2 +R) + (C +R)(L\u03b2 +R) 2L(L\u03b2 +R) \u2264 1\nAnd by multiplying both sides by the common denominator 2L(L\u03b2 +R):\nL[3\u03b2(C +R) + 2R] + (C +R)(\u22122C\u03b2 \u2212 2R\u03b2 \u2212R+ L\u03b2 +R) \u2264 2L(L\u03b2 +R) \u21d4 L[3\u03b2(C +R) + 2R] + (C +R)(L\u03b2 \u2212 2C\u03b2 \u2212 2R\u03b2) \u2264 2L(L\u03b2 +R) \u21d4 L[3\u03b2(C +R)] + \u03b2(C +R)(L\u2212 2C \u2212 2R) \u2264 2L \u00b7 L\u03b2\nSince \u03b2 is always positive, it is possible to divide both sides by \u03b2:\nL[3(C +R)] + (C +R)(L\u2212 2C \u2212 2R) \u2264 2L2\n\u21d4 3LC + 3LR+ LC \u2212 2C2 \u2212 2CR+ LR\u2212 2CR\u2212 2R2 \u2264 2L2 \u21d4 0 \u2264 2L2 + 2C2 + 2R2 \u2212 4LC \u2212 4LR+ 4CR \u21d4 0 \u2264 L2 + C2 +R2 \u2212 2LC \u2212 2LR+ 2CR \u21d4 0 \u2264 (L\u2212 C \u2212R)2\nThis term is indeed always non-negative, so this concludes the proof.\nLemma 30. Let x be an arbitrary location profile, and let agent i be on a border bj such that yj < xi = bj < yj+1 \u2264 yopt. Let a1 = (ai = Cj ,a\u2212i), let a2 = (ai = Cj+1,a\u2212i), and let M be some WPV mechanism. Then SC(M,x,a1) \u2265 SC(M,x,a2).\nProof. Let pi = Pr[M(a1) = Ci] and qi = Pr[M(a2) = Ci]. According to the definition of WPV mechanisms, the change of vote only affects the probabilities of candidates Cj and Cj+1, that is: \u2200k 6= j, j + 1: pk = qk. Denote: pj = qj + \u03b1 and pj+1 + \u03b1 = qj+1 for some \u03b1 > 0. Therefore:\nSC(M,x,a1)\u2212 SC(M,x,a2) = \u2211 k pk \u00b7 SC(Ck,x)\u2212 \u2211 k qk \u00b7 SC(Ck,x)\n= \u03b1 [SC(Cj ,x)\u2212 SC(Cj+1,x)]\nTherefore it is sufficient to show that SC(Cj ,x) \u2265 SC(Cj+1,x). We define the cost function for any point on the line: f(x) = \u2211 k |x\u2212 xk|. By definition, for any candidate Cl: SC(Cl,x) = f(yl). Clearly, f(x) is single-peaked, with a peak at the median xdn/2e, since moving in any direction away from the median only increases the distance to at least half of the agents. We check the different cases:\n\u2022 If yopt \u2264 xdn/2e: Then yj < yj+1 \u2264 yopt \u2264 xdn/2e \u21d0 f(yj) \u2265 f(yj+1).\n\u2022 If yopt > xdn/2e:\n\u2013 If yj+1 = yopt: Then the proof is concluded by definition of optimality.\n\u2013 If yj+1 < yopt then by definition of optimality: yj < yj+1 < xdn/2e < yopt. Therefore: f(yj) \u2265 f(yj+1).\nThe proof also holds for the symmetrical case in which yopt \u2264 yj < bj = xi < yj+1.\nA.3 Missing Proofs from Section 5\nProof. of Lemma 12: Proof via contradiction. Assume costxl(M, (al = \u03c0j , a\u2212l)) = costxl(M, (al = \u03c0i, a\u2212l)) + \u03b4 for some \u03b4 > 0. Let there be an agent k located in ranking zone Rj such that |xk \u2212 xl| = < \u03b42 .\nThen agent k has an incentive to misreport:\ncostxk(M, (ak = \u03c0j , a\u2212k)) \u2265 costxl(M, (ak = \u03c0j , a\u2212k))\u2212 = costxl(M, (ak = \u03c0i, a\u2212k)) + \u03b4 \u2212 > costxl(M, (ak = \u03c0i, a\u2212k)) +\n\u2265 costxk(M, (ak = \u03c0i, a\u2212k))\nThe transitions in the first and last rows are due to the triangle inequality (for any location the mechanism may choose), the second row holds by the assumption, and the third row holds since < \u03b42 .\nAgent k has an incentive to misreport, contradicting the assumption and completing the proof.\nProof. of Lemma 17: We prove the lower bounds for the case of two agents and two candidates. Let y1 = \u22121, y2 = 1. Let a = (a1, a2) be the ranking profile in which the two agents prefer different candidates, that is: a1 = C1 C2, a2 = C2 C1.\nExamine the following two location profiles x,x\u2032, (in both cases for which a is a truthful voting profile): x = (\u22121, ), x\u2032 = (\u2212 , 1).\nWe show that any decision of the mechanism makes will cause an approximation ratio of 2 either in x or in x\u2032.\nIt is easy to see that:\nSC(C1,x) = 1 + = SC(OPT,x) SC(C2,x) = 3\u2212 SC(C1,x\u2032) = 3\u2212 SC(C2,x\u2032) = 1 + = SC(OPT,x\u2032)\nDenote p = Pr[M(a) = C1]. Therefore:\nSC(M,x) = p(1 + ) + (1\u2212 p)(3\u2212 ) SC(M,x\u2032) = p(3\u2212 ) + (1\u2212 p)(1 + )\nThe approximation ratio is therefore at least:\nmin 0\u2264p\u22641\n{ max { SC(M,x)\nSC(OPT,x) ,\nSC(M,x\u2032)\nSC(OPT,x\u2032)\n}} =\nmin 0\u2264p\u22641\n{ max { p(1 + ) + (1\u2212 p)(3\u2212 )\n1 + , (1\u2212 p)(1 + ) + p(3\u2212 ) 1 +\n}} =\nmin 0\u2264p\u22641\n{max {1 + 2p\u2212 p , 3\u2212 2p+ 2p \u2212 }}\nThe optimal value is reached at p = 0.5, and it is 2\u2212 2 , which tends to 2 as tends to 0.\nProof. of Lemma 18 (Random Dictator): Random dictator (RD) is a WPV mechanism and so it is universally truthful according to Lemma 2.\nWe start by showing that the ratio can be arbitrarily close to 3. Let y1 = \u22121, y2 = 1, and let x1 = . . . = xn\u22121 = \u22121 and xn = 1. Therefore the costs are: SC(C1,x) = 1 + = SC(OPT,x) and SC(C2,x) = 2(n\u2212 1) + (1\u2212 ).\nErgo: SC(RD,x) = n\u22121n \u00b7 SC(C1,x) + 1 n \u00b7 SC(C2,x) = 3 \u2212 2 n + 2 n + . The approximation\nratio is therefore:\nSC(RD,x)\nSC(OPT,x) =\n3\u2212 2n + 2 n +\n1 + = 3\u2212\n2 + 2n \u2212 2 n\n1 +\nClearly this ratio tends to 3 as n\u2192\u221e, \u2192 0.\nWe now show that the approximation ratio is bounded from above by 3. The social cost is:\nSC(RD,x) = 1\nn \u2211 i \u2211 j |xj \u2212 y(ai)|  \u2264 1\nn \u2211 i \u2211 j |xj \u2212 yopt|+ |yopt \u2212 y(ai)|  \u2264 1\nn \u2211 i \u2211 j |xj \u2212 yopt|+ |yopt \u2212 xi|+ |xi \u2212 y(ai)|  \u2264 1\nn \u2211 i \u2211 j |xj \u2212 yopt|+ 2|yopt \u2212 xi|  = 1\nn \u2211 i \u2211 j |xj \u2212 yopt| + 1 n \u2211 i \u2211 j 2|yopt \u2212 xi|  = 1\nn \u2211 j\n( |xj \u2212 yopt|\n\u2211 i (1)\n) + 2\nn \u2211 i |yopt \u2212 xi|\u2211 j (1)  = 1\nn \u2211 j (|xj \u2212 yopt| \u00b7 n) + 2 n \u2211 i (|yopt \u2212 xi| \u00b7 n)\n= SC(OPT,x) + 2 \u00b7 SC(OPT,x) = 3 \u00b7 SC(OPT,x)\nThe first two transitions hold due to the triangle inequality, and the third inequality holds due to fact that no candidate is closer to xi than y(ai) is.\nNotice that this holds in any metric space since we only used the triangle inequality, and did not use any notion which is specific to the line.\nA mechanism is group-strategyproof (GSP) if for any location profile and any coalition S \u2286 N , there is no joint deviation of the agents in S from the truthful reports such that they all gain. That is:\n\u2200S \u2286 N, \u2200aS \u2208 A(xS), \u2200a\u2212S \u2208 An\u2212|S|, \u2200a\u2032S \u2208 A|S|,\u2203i \u2208 S : costxi(M, (aS , a\u2212S)) \u2264 costxi(M, (a\u2032S , a\u2212S))\nIn the continuous model, random dictator is GSP on the line (and even on the circle, see [2]). We show that in our candidate model random dictator is not GSP on the line. Notice that random dictator is in particular a WPV mechanism, therefore a corollary of the lemma is that there exist WPV mechanisms which are not GSP.\nLemma 31. Random dictator is not group group-strategyproof\nProof. Let there be three candidates at locations y1 = 1, y2 = 0, y3 = 1 and let there be two agents at x1 = \u22120.51 and x2 = 0.51. When both agents report truthfully (a1 = C1, a2 = C3), the mechanism chooses C1, C3, each with probability 0.5. The cost of each of the agents in this case is: costx1(RD,a) = costx2(RD,a) = 0.5 \u00b7 (0.51 + 1.49) = 1.\nHowever, if both agents misreport together to a\u2032 = (a\u20321 = C2, a\u20322 = C2), then C2 will always be chosen. The costs in this case will be: costx1(RD,a \u2032) = costx2(RD,a \u2032) = 0.51.\nA.4 Missing Proofs from Section 6\nProof. of Lemma 21: This mechanism is truthful - any agent located at the median location has no incentive to misreport since the only possible consequence is for the mechanism to select a different location. Similarly, other agents have no incentive to misreport, since misreporting either has no effect or moves the chosen location further away.\nWe now move on to the approximation ratio - Let \u03c0 be the permutation of {1 . . . n} such that y ( a\u03c0(i) ) \u2264 ( a\u03c0(i+1) ) for each i \u2208 {1 . . . n\u2212 1}. Denote a\u0302i = a\u03c0(i). The median mechanism chooses candidate Cj = a\u0302dn/2e located at yj . Assume without loss of generality that yopt > yj . The social cost of median is:\nSC(M,a) = SC(Cj ,a) = \u2211\ni:y(a\u0302i)\u2264yj\n|xi \u2212 yj |+ \u2211\nk:y(a\u0302k)>yj\n|xi \u2212 yj |\nDenote the first term as \u03b1, and the second as \u03b2. The social cost to the optimal candidate is:\nSC(OPT,x) = \u2211\ni:y(a\u0302i)\u2264yj\n|xi \u2212 yopt|+ \u2211\nk:y(a\u0302k)>yj\n|xi \u2212 yopt|\nDenote the first term by \u03b3, and the second by \u03b4. It is easy to see that \u03b1 \u2264 \u03b3 since for any agent i in these sums (agent whose favorite candidate is not right of yj): |xi \u2212 yj | \u2264 |xi \u2212 yopt|, and this obviously holds when taking the sum.\nWe now show that \u03b2 \u2264 \u03b1 + \u03b3 + \u03b4, due to the following inequalities (justifications for the transitions appear below):\n\u03b2 = \u2211\nk:a\u0302k>yj\n|xk \u2212 yj |\n\u2264 \u2211\nk:a\u0302k>yj\n|yj \u2212 yopt|+ \u2211\nk:a\u0302k>yj\n|yopt \u2212 xk|\n= \u2211\nk:a\u0302k>yj\n|yj \u2212 yopt|+ \u03b4\n\u2264 \u2211\ni:y(a\u0302i)\u2264yj\n|yj \u2212 yopt|+ \u03b4\n\u2264 \u2211\ni:y(a\u0302i)\u2264yj\n(|yj \u2212 xi|+ |xi \u2212 yopt|) + \u03b4 = \u03b1+ \u03b3 + \u03b4\nThe inequalities in the second and fifth lines hold due to the triangle inequality, and the inequality in the fourth line holds because we are summing over a greater or equal amount of non-negative numbers (since |i : y(a\u0302i) \u2264 yj | \u2265 |k : y(a\u0302k) > yj |).\nPutting this all together:\nSC(Cj ,x) SC(OPT,x) = \u03b1+ \u03b2 \u03b3 + \u03b4 \u2264 \u03b3 + \u03b1+ \u03b3 + \u03b4 \u03b3 + \u03b4 \u2264 3\u03b3 + \u03b4 \u03b3 + \u03b4 \u2264 3\u03b3 + 3\u03b4 \u03b3 + \u03b4 = 3"}], "references": [{"title": "Strategyproof approximation mechanisms for location on networks", "author": ["Noga Alon", "Michal Feldman", "Ariel D Procaccia", "Moshe Tennenholtz"], "venue": "arXiv preprint arXiv:0907.2049,", "citeRegEx": "1", "shortCiteRegEx": "1", "year": 2009}, {"title": "Walking in circles", "author": ["Noga Alon", "Michal Feldman", "Ariel D Procaccia", "Moshe Tennenholtz"], "venue": "Discrete Mathematics,", "citeRegEx": "2", "shortCiteRegEx": "2", "year": 2010}, {"title": "Approximating optimal social choice under metric preferences", "author": ["Elliot Anshelevich", "Onkar Bhardwaj", "John Postl"], "venue": null, "citeRegEx": "3", "shortCiteRegEx": "3", "year": 2014}, {"title": "On the rationale of group decision-making", "author": ["Duncan Black"], "venue": "The Journal of Political Economy,", "citeRegEx": "4", "shortCiteRegEx": "4", "year": 1948}, {"title": "Optimal social choice functions: A utilitarian view", "author": ["Craig Boutilier", "Ioannis Caragiannis", "Simi Haber", "Tyler Lu", "Ariel D Procaccia", "Or Sheffet"], "venue": "In Proceedings of the 13th ACM Conference on Electronic Commerce,", "citeRegEx": "5", "shortCiteRegEx": "5", "year": 2012}, {"title": "Computational social choice", "author": ["Felix Brandt", "Vincent Conitzer", "Ulle Endriss"], "venue": "Multiagent systems,", "citeRegEx": "6", "shortCiteRegEx": "6", "year": 2012}, {"title": "Strategy-proof approximation mechanisms for an obnoxious facility game on networks", "author": ["Yukun Cheng", "Wei Yu", "Guochuan Zhang"], "venue": "Theoretical Computer Science,", "citeRegEx": "7", "shortCiteRegEx": "7", "year": 2013}, {"title": "Nonexistence of voting rules that are usually hard to manipulate", "author": ["Vincent Conitzer", "Tuomas Sandholm"], "venue": "In AAAI,", "citeRegEx": "8", "shortCiteRegEx": "8", "year": 2006}, {"title": "Mechanism design on discrete lines and cycles", "author": ["Elad Dokow", "Michal Feldman", "Reshef Meir", "Ilan Nehama"], "venue": "In Proceedings of the 13th ACM Conference on Electronic Commerce,", "citeRegEx": "9", "shortCiteRegEx": "9", "year": 2012}, {"title": "An economic theory of political action in a democracy", "author": ["Anthony Downs"], "venue": "The journal of political economy,", "citeRegEx": "10", "shortCiteRegEx": "10", "year": 1957}, {"title": "Strategyproof facility location and the least squares objective", "author": ["Michal Feldman", "Yoav Wilf"], "venue": "In Proceedings of the fourteenth ACM conference on Electronic commerce,", "citeRegEx": "11", "shortCiteRegEx": "11", "year": 2013}, {"title": "A cardinal concept of welfare", "author": ["Marcus Fleming"], "venue": "The Quarterly Journal of Economics,", "citeRegEx": "12", "shortCiteRegEx": "12", "year": 1952}, {"title": "Strategyproof facility location for concave cost functions", "author": ["Dimitris Fotakis", "Christos Tzamos"], "venue": "In Proceedings of the fourteenth ACM conference on Electronic commerce,", "citeRegEx": "13", "shortCiteRegEx": "13", "year": 2013}, {"title": "On the power of deterministic mechanisms for facility location games", "author": ["Dimitris Fotakis", "Christos Tzamos"], "venue": "ACM Transactions on Economics and Computation,", "citeRegEx": "14", "shortCiteRegEx": "14", "year": 2014}, {"title": "Manipulation of voting schemes: a general result", "author": ["Allan Gibbard"], "venue": "Econometrica: journal of the Econometric Society,", "citeRegEx": "15", "shortCiteRegEx": "15", "year": 1973}, {"title": "Icardinal welfare, individualistic ethics, and interpersonal comparisons of welfare", "author": ["J Harsanyi"], "venue": "J. Polit. Econ,", "citeRegEx": "16", "shortCiteRegEx": "16", "year": 1955}, {"title": "Asymptotically optimal strategy-proof mechanisms for two-facility games", "author": ["Pinyan Lu", "Xiaorui Sun", "Yajun Wang", "Zeyuan Allen Zhu"], "venue": "In Proceedings of the 11th ACM conference on Electronic commerce,", "citeRegEx": "18", "shortCiteRegEx": "18", "year": 2010}, {"title": "On strategy-proofness and single peakedness", "author": ["Herv\u00e9 Moulin"], "venue": "Public Choice,", "citeRegEx": "19", "shortCiteRegEx": "19", "year": 1980}, {"title": "Introduction to mechanism design (for computer scientists)", "author": ["Noam Nisan"], "venue": "Algorithmic game theory,", "citeRegEx": "20", "shortCiteRegEx": "20", "year": 2007}, {"title": "Can approximation circumvent gibbard-satterthwaite", "author": ["Ariel D Procaccia"], "venue": "In AAAI,", "citeRegEx": "21", "shortCiteRegEx": "21", "year": 2010}, {"title": "The distortion of cardinal preferences in voting", "author": ["Ariel D Procaccia", "Jeffrey S Rosenschein"], "venue": "In Cooperative Information Agents X,", "citeRegEx": "22", "shortCiteRegEx": "22", "year": 2006}, {"title": "Approximate mechanism design without money", "author": ["Ariel D Procaccia", "Moshe Tennenholtz"], "venue": "In Proceedings of the 10th ACM conference on Electronic commerce,", "citeRegEx": "23", "shortCiteRegEx": "23", "year": 2009}, {"title": "Strategy-proof location on a network", "author": ["James Schummer", "Rakesh V Vohra"], "venue": "Journal of Economic Theory,", "citeRegEx": "24", "shortCiteRegEx": "24", "year": 2002}, {"title": "Approximately strategy-proof mechanisms for (constrained) facility location", "author": ["Xin Sui", "Craig Boutilier"], "venue": "In Proceedings of the 2015 International Conference on Autonomous Agents and Multiagent Systems,", "citeRegEx": "25", "shortCiteRegEx": "25", "year": 2015}], "referenceMentions": [{"referenceID": 9, "context": "The Hotelling-Downs model ([10], [17]) used to study political strategies, assumes that individual voters occupy some point along the real line.", "startOffset": 27, "endOffset": 31}, {"referenceID": 18, "context": ", [20]).", "startOffset": 2, "endOffset": 6}, {"referenceID": 2, "context": "[3] in the non-strategic setting it is possible to reach a constant ratio in any metric space, while due to the", "startOffset": 0, "endOffset": 3}, {"referenceID": 14, "context": "The seminal GibbardSatterthwaite theorem [15] shows that if the rankings of agents can be arbitrary and the amount of candidates is greater than two, then the only onto truthful mechanisms are dictatorships.", "startOffset": 41, "endOffset": 45}, {"referenceID": 22, "context": "characterization of Schummer and Vohra [24] there exist metric spaces in which the approximation ratio is \u03a9(n) even in the continuous model.", "startOffset": 39, "endOffset": 43}, {"referenceID": 3, "context": "In many cases the rankings can be limited to singlepeaked preferences, a notion used as early as 1948 by Black [4].", "startOffset": 111, "endOffset": 114}, {"referenceID": 17, "context": "In 1980 Moulin showed a complete characterization of truthful deterministic mechanisms for single-peaked preferences [19].", "startOffset": 117, "endOffset": 121}, {"referenceID": 22, "context": "Schummer and Vohra [24] extended this characterization to cycles and general graphs.", "startOffset": 19, "endOffset": 23}, {"referenceID": 5, "context": "There has been extensive work describing various candidate selection mechanisms, which have been generally divided to 3 main types ([6], [26]) \u2014 scoring rules (e.", "startOffset": 132, "endOffset": 135}, {"referenceID": 19, "context": "Some work on social choice also made use of randomized voting schemes, for instance in order to improve the results of the mechanisms [21] or to make manipulation computationally hard ([8] pages 632-633).", "startOffset": 134, "endOffset": 138}, {"referenceID": 7, "context": "Some work on social choice also made use of randomized voting schemes, for instance in order to improve the results of the mechanisms [21] or to make manipulation computationally hard ([8] pages 632-633).", "startOffset": 185, "endOffset": 188}, {"referenceID": 11, "context": "g, a 1952 paper by Fleming [12] and a 1955 work by Harsanyi [16]).", "startOffset": 27, "endOffset": 31}, {"referenceID": 15, "context": "g, a 1952 paper by Fleming [12] and a 1955 work by Harsanyi [16]).", "startOffset": 60, "endOffset": 64}, {"referenceID": 20, "context": "The term was coined in 2006 by Procaccia and Rosenschein [22], and it was later used, for instance, by Boutilier et.", "startOffset": 57, "endOffset": 61}, {"referenceID": 4, "context": "[5].", "startOffset": 0, "endOffset": 3}, {"referenceID": 2, "context": "[3] assessed the distortion of several voting rules, and provided lower bounds on them.", "startOffset": 0, "endOffset": 3}, {"referenceID": 2, "context": "In [3], the distortion is the worst case ratio between the social cost of the candidate elected and the social cost of the optimal candidate, over any ranking profile (that is, preference profile) in any metric space.", "startOffset": 3, "endOffset": 6}, {"referenceID": 13, "context": "The metric space researched spanned from a line ([14], [23]) to a circle ([1], [2]), a tree ([1], [11]) or a general graph ([1]).", "startOffset": 49, "endOffset": 53}, {"referenceID": 21, "context": "The metric space researched spanned from a line ([14], [23]) to a circle ([1], [2]), a tree ([1], [11]) or a general graph ([1]).", "startOffset": 55, "endOffset": 59}, {"referenceID": 0, "context": "The metric space researched spanned from a line ([14], [23]) to a circle ([1], [2]), a tree ([1], [11]) or a general graph ([1]).", "startOffset": 74, "endOffset": 77}, {"referenceID": 1, "context": "The metric space researched spanned from a line ([14], [23]) to a circle ([1], [2]), a tree ([1], [11]) or a general graph ([1]).", "startOffset": 79, "endOffset": 82}, {"referenceID": 0, "context": "The metric space researched spanned from a line ([14], [23]) to a circle ([1], [2]), a tree ([1], [11]) or a general graph ([1]).", "startOffset": 93, "endOffset": 96}, {"referenceID": 10, "context": "The metric space researched spanned from a line ([14], [23]) to a circle ([1], [2]), a tree ([1], [11]) or a general graph ([1]).", "startOffset": 98, "endOffset": 102}, {"referenceID": 0, "context": "The metric space researched spanned from a line ([14], [23]) to a circle ([1], [2]), a tree ([1], [11]) or a general graph ([1]).", "startOffset": 124, "endOffset": 127}, {"referenceID": 12, "context": "There are many papers regarding building several facilities (or electing a committee of candidates), where the cost of an agent is her distance to the closest facility ([13], [14], [18], [23]).", "startOffset": 169, "endOffset": 173}, {"referenceID": 13, "context": "There are many papers regarding building several facilities (or electing a committee of candidates), where the cost of an agent is her distance to the closest facility ([13], [14], [18], [23]).", "startOffset": 175, "endOffset": 179}, {"referenceID": 16, "context": "There are many papers regarding building several facilities (or electing a committee of candidates), where the cost of an agent is her distance to the closest facility ([13], [14], [18], [23]).", "startOffset": 181, "endOffset": 185}, {"referenceID": 21, "context": "There are many papers regarding building several facilities (or electing a committee of candidates), where the cost of an agent is her distance to the closest facility ([13], [14], [18], [23]).", "startOffset": 187, "endOffset": 191}, {"referenceID": 0, "context": "g, [1], [14], [23]), but there were also works regarding additional target functions like the L2 norm (the sum of the squared distances of the agents, see [11]).", "startOffset": 3, "endOffset": 6}, {"referenceID": 13, "context": "g, [1], [14], [23]), but there were also works regarding additional target functions like the L2 norm (the sum of the squared distances of the agents, see [11]).", "startOffset": 8, "endOffset": 12}, {"referenceID": 21, "context": "g, [1], [14], [23]), but there were also works regarding additional target functions like the L2 norm (the sum of the squared distances of the agents, see [11]).", "startOffset": 14, "endOffset": 18}, {"referenceID": 10, "context": "g, [1], [14], [23]), but there were also works regarding additional target functions like the L2 norm (the sum of the squared distances of the agents, see [11]).", "startOffset": 155, "endOffset": 159}, {"referenceID": 6, "context": ", when selecting a location for a central garbage dump ([7]).", "startOffset": 56, "endOffset": 59}, {"referenceID": 2, "context": "3 in [3], (LB:Lm.", "startOffset": 5, "endOffset": 8}, {"referenceID": 2, "context": "3 in [3], (LB:Lm.", "startOffset": 5, "endOffset": 8}, {"referenceID": 23, "context": "mechanisms which is GSP on the line and -GSP on <n [25].", "startOffset": 51, "endOffset": 55}, {"referenceID": 8, "context": "[9] characterize deterministic truthful mechanisms on the discrete line and the discrete circle.", "startOffset": 0, "endOffset": 3}, {"referenceID": 8, "context": "It is worthy to note the model in [9] has 2 major properties which differ from the one in this paper: (a) The discrete constraints of the locations apply to the agents as well as to the candidates, so all agents are located precisely on some candidate; (b) The distance between any two neighboring candidates must be constant (for instance: 1,2,3,4,.", "startOffset": 34, "endOffset": 37}, {"referenceID": 21, "context": "In the continuous model it is well known that choosing the location of the median agent is both truthful and optimal [23].", "startOffset": 117, "endOffset": 121}, {"referenceID": 2, "context": "(Theorem 3 in [3]) uses a similar method to show the worst case for ranking mechanisms with non-strategic agents is 3 (the proof in that paper was done for a general metric space, but it can also be applied to <).", "startOffset": 14, "endOffset": 17}], "year": 2015, "abstractText": "We study mechanisms for candidate selection that seek to minimize the social cost, where voters and candidates are associated with points in some underlying metric space. The social cost of a candidate is the sum of its distances to each voter. Some of our work assumes that these points can be modeled on a real line, but other results of ours are more general. A question closely related to candidate selection is that of minimizing the sum of distances for facility location. The difference is that in our setting there is a fixed set of candidates, whereas the large body of work on facility location seems to consider every point in the metric space to be a possible candidate. This gives rise to three types of mechanisms which differ in the granularity of their input space (voting, ranking and location mechanisms). We study the relationships between these three classes of mechanisms. While it may seem that Black\u2019s 1948 median algorithm is optimal for candidate selection on the line, this is not the case. We give matching upper and lower bounds for a variety of settings. In particular, when candidates and voters are on the line, our universally truthful spike mechanism gives a [tight] approximation of two. When assessing candidate selection mechanisms, we seek several desirable properties: (a) efficiency (minimizing the social cost) (b) truthfulness (dominant strategy incentive compatibility) and (c) simplicity (a smaller input space). We quantify the effect that truthfulness and simplicity impose on the efficiency.", "creator": "LaTeX with hyperref package"}}}