{"id": "1601.04667", "review": {"conference": "arxiv", "VERSION": "v1", "DATE_OF_SUBMISSION": "18-Jan-2016", "title": "Proactive Message Passing on Memory Factor Networks", "abstract": "we introduce a new level of graphical model structure could call we \" memory factor invariant \" ( spd ). we calculate how to use similar generalized model computational structure modeled in many circumstances implementing data sets. we would present an analog message - encoded inference algorithms called \" proactive wire passing \"'( pmp ) that performs inference on failures. probability comes off verification if logic is efficient in comparison to competing phenomena such as variants evolutionary belief theory. we attempt mfns besides pmp to construct subfamily of advanced types of software ( discrete, provisional, labelled ) underlying inference flows ( prediction, hypothesis discovery ), provide examples, and discuss approaches adopting efficient distributions.", "histories": [["v1", "Mon, 18 Jan 2016 19:38:51 GMT  (1414kb,D)", "http://arxiv.org/abs/1601.04667v1", "35 pages, 13 figures"]], "COMMENTS": "35 pages, 13 figures", "reviews": [], "SUBJECTS": "cs.AI cs.CV", "authors": ["patrick eschenfeldt", "dan schmidt", "stark draper", "jonathan yedidia"], "accepted": false, "id": "1601.04667"}, "pdf": {"name": "1601.04667.pdf", "metadata": {"source": "CRF", "title": "Proactive Message Passing on Memory Factor Networks Proactive Message Passing on Memory Factor Networks", "authors": ["Patrick Eschenfeldt", "Dan Schmidt"], "emails": ["peschen@mit.edu", "dan.schmidt@disneyresearch.com", "stark.draper@utoronto.ca", "yedidia@disneyresearch.com"], "sections": [{"heading": null, "text": "Keywords: Machine learning, optimization, pattern recognition models, vision and scene understanding, image restoration"}, {"heading": "1. Introduction and motivations", "text": "In this paper, we introduce \u201cmemory factor networks\u201d (MFNs) and the \u201cproactive message passing\u201d (PMP) algorithm. Our objective is to combine the capability of message passing algorithms, which can make large-scale inferences in a highly efficient manner, with the ability of machine learning algorithms to generalize from experience.\nFactor graphs and message passing (Kschischang et al., 2001; Loeliger et al., 2007; Koller and Friedman, 2009; Yedidia et al., 2005; Sudderth and Freeman, 2008) have proved to be an extremely effective combination when one is faced with an inference task wherein global problem structure decomposes into a large set of local constraints. In applications such as error correction decoding (Richardson and Urbanke, 2008), these local constraints have a\n\u2217. As of January 2016 he is with Analog Devices Lyric Labs, Cambridge, MA 02142.\nar X\niv :1\n60 1.\n04 66\n7v 1\nsimple characterization that makes local inference computationally simple. Message-passing algorithms iterate between making local inferences and combining these local decisions into a global estimate.\nHowever, in many settings the local problem structure is not known ahead of time and engineered, as it is in error correcting codes, but rather must be learned. For instance, a number of examples may be provided and the initial task is to deduce underlying problem structure from these exemplars. Following that, one can make inferences based on the problem structure learned. These tasks\u2014of deducing problem structure and then making inferences based on the structure\u2014are central to many areas of data analysis, statistics, and machine learning.\nIn MFNs a set of variables describe a problem configuration. A collection of \u201cmemory factors\u201d, learned from examples, encode (possibly soft) constraints on overlapping subsets of the variables. The high-level goal of PMP is to find a configuration of variables that is minimally conflicting with the local problem structure represented by the memory factors and with the evidence obtained from the world. Conflicts occur because the constraints overlap and, in general, cannot all be satisfied exactly.\nWhile the above description is somewhat generic, one key innovation in MFNs and PMP is to design the memory factors so that they encode the learned local problem structure in a manner easily accessible for inference. The guiding philosophy is one of joint design of the graphical model and of the message passing algorithm so as to make the necessary computations efficient. In analogy with biology, we need our memories to be easily accessible to our thinking. Thus, while we do not engineer the detailed statistical structure of the problem, what we do engineer is the way in which we store our knowledge of that statistical structure in order to make it easy to exploit in our inference tasks. In this framework, \u201cmemories\u201d correspond to the learned local problem structure encoded by memory factors.\nA second key innovation in PMP is a simple methodology for producing local inferences, one that guarantees global convergence. Because the learned problem structure encoded into the memory factors is extremely rich\u2014in comparison to the factor nodes used in graphical models which belief propagation is typically applied to\u2014a simple methodology for producing local inference is important to maintain computational tractability. PMP accomplishes this through an intuitive voting mechanism that, at each iteration, considers the current messages coming from neighboring memory factors in order only to make choices that reduce a global objective. PMP is thus \u201cproactive\u201d in the sense that it considers the effect that each possible local choice will have on the global situation before deciding which choice to implement. This proactivity ensures that the global objective decreases at each iteration, and guarantees that PMP will converge to a locally optimum configuration. In order to ensure that PMP converges to a good local optimum, we use a powerful heuristic for scheduling factor updates, one that is derived from a novel notion of factor \u201cconfidence.\u201d\nThe general idea of combining a message-passing inference algorithm with a graphical model built up using an example-based learning approach was introduced by Freeman et al. in their VISTA (\u201cVision by Image/Scene training\u201d) approach (Freeman et al., 2000). The main application considered using the VISTA approach was example-based super-resolution (Freeman et al., 2002). The VISTA approach used Markov random field graphical models, built up dynamically in response to each inference problem encountered (that is, only the most probable example patches were included in each Markov random field node) and\nthe inference algorithms used were belief propagation or more efficient one-pass algorithms. One can think of this paper as providing a formal generalization of the VISTA idea. That is, whereas the VISTA work was primarily concerned with finding a good solution to the particular application of super-resolution, our primary concern is to carefully define and demonstrate a general approach to learning-based inference, based on the memory factor network data structure and the proactive message-passing algorithm. We believe this approach can be applied to a wide range of problems going beyond those encountered in computer vision.\nThe rest of the paper is structured as follows. In Section 2 we introduce memory factor networks. In Section 3 we describe the proactive message passing algorithm. Then, in Section 4 we specialize the discussions of Section 2 and 3 to specific types of variable nodes (integer, real, label) and cost functions (absolute difference, quadratic difference, indicator). In Section 5 we turn to memory factors and describe two distinct types of memory factors. We first consider \u201cmemory tables\u201d where each memory factor consists of a database of fragments of observed exemplars. We then consider \u201csubspace factors\u201d where the memory factor constrains local problem structure to reside in some learned lowdimensional subspace. In Section 6 we provide illustrative applications that include face reconstruction from missing and noisy data, music reconstruction, and handwritten digit classification. In some examples we compare and contrast the performance of memory tables with subspace factors. We make concluding remarks in Section 7."}, {"heading": "2. Memory factor networks", "text": "A memory factor network (MFN) contains N variables and M constraints on (subsets of) those variables. Constraints may encode problem structure or may be induced by observations. We capture these two types of constraints through \u201cmemory factor\u201d and \u201cevidence factor\u201d nodes respectively. We seek a configuration of the N variables that minimizes a cost function of the variables induced by the M factors. In the following we use the notation {1, . . . , N} = [N ] to denote an index set of cardinality N .\nThe interconnection of variables and factors is described by an edge-weighted bipartite graph. That graph, and the cost function formulation, is described by the following sets:\n\u2022 A set of variable nodes indexed by Iv = [N ] with values {xi : i \u2208 Iv}. We will discuss various choices for the alphabet Xi of xi \u2014 real, integer, binary, label. Distinct variables can have different alphabets.\n\u2022 A set of factor nodes indexed by If = [M ]. As mentioned, factors are either memory factors, indexed by Im, or evidence factors, indexed by Ie, where Im \u222a Ie = If and Im \u2229 Ie = \u2205.\n\u2022 A set of edges E = {eai : i \u2208 Iv, a \u2208 Ni} induced by the neighborhood structure of the network. With slight (but always resolvable from context) equivocation in notation we write Ni (Na) to denote the set of factor (variable) nodes neighboring variable node i (factor node a). Note that each evidence factor is typically attached to a single variable, so that if a \u2208 Ie, then typically |Na| = 1.\n\u2022 A set of votes {vai : i \u2208 Iv, a \u2208 Ni} and corresponding vote weights {wai : i \u2208 Iv, a \u2208 Ni}. We always have vai \u2208 Xi. The weights wai are fixed real numbers, and we normally restrict them so that all weights associated with the same variable i are equal.\nWhen an MFN is being used for inference, the degrees of freedom in a memory factor network are the values of the variable nodes {xi : i \u2208 Iv} and the votes of the factor nodes {vai : i \u2208 Iv, a \u2208 Ni}. Changes in the state of the world are reflected in changes to the evidence factors. When an MFN is learning, the acquisition of memories is reflected in adjustments to the memory factors which, at inference time, is reflected in the factor\u2019s possible votes.\nWe often have reason to refer to the set of variables or votes or weights associated with a single factor. We use xa = {xi : i \u2208 Na} to refer to the vector of variables neighboring factor a and use va and wa, similarly defined, to denote the \u201cvote\u201d vector and the \u201cweight\u201d vector. Occasionally we have need to refer to, say, the set of variables in some set S \u2282 Iv; we write xS to refer to this set. We also will have need to refer to a set of votes regarding variable i from some subset B \u2286 Ni of neighbors; we denote this set vBi .\nPerhaps other than the edge weights, the above description is standard; it quite neatly fits into the formalism of a \u201cnormal\u201d factor graph due to Forney (Forney, 2001). To map to Forney\u2019s normal representation, the variable and factor nodes would all correspond to factors (the former to equality constraints), and votes would correspond to variables.\nOur objective is to minimize a global cost function \u03a8 that can be factored based on the graphical structure of the problem. \u03a8 will include two types of local costs: mismatch costs and selection costs. The mismatch costs penalize the difference between a variable setting xi and a factor\u2019s vote on that variable v a i . The contribution of mismatches to the global cost is additive in both variable and factor indices, and each contribution is weighted by the particular vote\u2019s weight. We make the mismatch costs a function of the variable index, but not the factor index. The reason is that, other than the weighting, all votes pertaining to a particular variable are compatible in some sense (e.g., all in R or in Z) and therefore the same measure of mismatch should apply to all. The selection costs make various choices of a factor\u2019s vote vector va more or less costly and thus is a function of the pertinent factor\u2019s index a. Unlike the mismatch costs, selection costs, are, in general, only additive in factor indices and not in variable indices. To denote the mismatch costs we use \u03c8i(\u00b7, \u00b7); to denote selection costs we use \u03c7a(\u00b7).\n\u03a8 = \u2211 a\u2208If\n[ \u03c7a(v\na) + \u2211 i\u2208Na \u03c8i(xi, v a i )w a i\n] (1)\nAs we detail more in later sections, we consider various forms for both types of cost functions. For example, for local mismatch costs we may use the absolute difference \u03c8i(u, v) = |u\u2212 v| when u, v \u2208 Z, the squared difference \u03c8i(u, v) = |u \u2212 v|2 when u, v \u2208 R, and an indicator function \u03c8i(u, v) = I[u 6= v] where u, v are in a discrete set. For selection costs, we can design \u03c7a(\u00b7) to limit {vai }i\u2208Na to belong to some discrete set or to lie in a certain subspace of a vector space.\nIn practice, the selection costs arise as a result of a training phase where examples are shown to the system and likely or frequent configurations are learned. Later, when the system is trying to understand a new sample from the world, it tries to minimize the overall\ncost, thus interpreting the new sample in terms of both how well the variables can be made to match the evidence from that sample and how well the variables can match the structure learned from training examples."}, {"heading": "3. Proactive message passing", "text": "In our efforts to minimize (1) we now introduce the proactive message passing (PMP) algorithm. Proactive message passing works through a sequence of iterative subproblems in its attempt to minimize (1). The PMP algorithm can be understood through analogy to an idealized political convention, where the objective of the convention is to determine the party platform. A party platform consists of a number of stances on issues, where each issue corresponds to one variable in the analogy, and a stance is a value for the variable. Each delegate corresponds to one factor and each delegate is concerned with only a (generally small) subset of issues. By the close of the convention we want to identify the optimal vector of stances that results in minimal dissatisfaction amongst delegates; dissatisfaction is measured by (1). While the analogy with a political convention is not exact, we hope it will help elucidate the PMP algorithm and develop intuition.\nIn a convention there is a sequence of rounds of balloting. Each round corresponds to one iteration of the algorithm. In each round some delegates vote on the issues of concern to them, while others abstain from voting. The delegates that vote initially are the ones most confident in their opinions. Other delegates temporarily abstain and delay voting until they become sufficiently confident in their opinions. (In PMP, once a factor votes, it votes on all variables of interest to it, and never abstains again.) After each round of balloting, all delegates reconsider their opinions, which may have changed based on the most recent set of votes cast. When forming opinions, a delegate takes into account all current votes (of non-abstaining delegates) on each issue that is of interest to that delegate. The opinions formed correspond to votes that, if cast, would reduce maximally a cost function derived from (1). This is why the algorithm is termed \u201cproactive,\u201d as each delegate preemptively evaluates how a change in their votes would impact the dissatisfaction of all delegates that have voted on the same set of issues. In the next round of balloting some subset of delegates is chosen to change their votes or to cast their initial set of votes. (Delegates that are not chosen to cast new votes, but that have previously voted, leave their votes unchanged.) This subset is chosen to be the set of delegates most confident in their opinions; that is, they are the delegates least likely to have their opinions change in the future due to other delegates\u2019 votes. The cost function is structured so that, eventually, all delegates must cast votes and not abstain. The convention ends when all delegates\u2019 votes align sufficiently with their opinions that no one wants to change their votes."}, {"heading": "3.1 PMP specification", "text": "We now put a mathematical framework around the intuition described above. As in the above description, each factor has a current \u201copinion\u201d on the value of each variable neighboring it, an opinion that may differ from a vote it has already cast. The opinion vector is in one-to-one correspondence with the vote vector, and is denoted as {oai : i \u2208 Iv, a \u2208 Ni}.\nThe iterative subproblems that PMP works through correspond to the rounds of balloting. In each iteration some subset of factors A \u2286 If \u201cabstain\u201d from voting. One part of\nthe objective of each subproblem is a modification of the original objective that considers only the participating (non-abstaining) factors:\n\u03a8A = \u2211\na\u2208If\\A\n[ \u03c7a(v\na) + \u2211 i\u2208Na \u03c8i(xi, v a i )w a i\n] . (2)\nTo connect to the original objective (1), PMP minimizes a cost tuple (|A|,\u03a8A). The first element of the tuple is the count of abstaining factors, and the second is (2). To compare tuples, we assert a lexicographic order: (a1, b1) \u2264 (a2, b2) if and only if either a1 < a2 or a1 = a2 and b1 \u2264 b2. With this ordering the global optimum of the tuple is (0,\u03a8\u2217) where \u03a8\u2217 minimizes (1). Our PMP algorithm will have the feature that at each iteration, the cost will decrease, and ultimately no factors will abstain, although the algorithm may converge to a local optimum rather than the global one. This feature of guaranteed convergence to at least a local optimum is not shared by most message-passing algorithms operating on factor graphs containing cycles (Yedidia et al., 2005).\nIn addition to the abstaining set, PMP works with three other sets of factors: the votechanging set V, the reacting set R and the dissatisfied set D. At each iteration (ballot) there is a set of factors (delegates) that change their votes. The set of these factors is the vote-changing set V. If a factor is in V and has not voted previously it is removed from the abstaining set A. Note that we never add factors to A and therefore the cardinality of the abstaining set |A| decreases monotonically in iteration count. The reacting set R is the set of factors that neighbor variables connected to the set of factors that most recently changed their votes: R = \u222aa\u2208V(\u222ai\u2208NaNi\\{a}). This is the set of factors that, based on the most recent change in votes, might change their opinions about some variables (issues). The dissatisfied set D contains factors whose recomputed opinion vector does not in fact match their vote vector but have not yet been given a chance to cast votes that match their latest opinions. Note that while the abstaining set plays a fundamental role in the algorithm, the role of the reactive and dissatisfied sets is purely to reduce computation. The algorithm could be defined without tracking these latter two sets, but a number of redundant computations would then be repeated each iteration.\nTo initialize the algorithm we start with a set of factors V that we want to vote in the first iteration. One natural choice is to set V = Ie, the set of evidence nodes, and to set the votes of these factors equal to their observations. Then we set the abstaining set A = If\\V, the reacting set R = \u222aa\u2208V(\u222ai\u2208NaNi\\{a}), and the dissatisfied set D = \u2205.\nWe note that we use selection and mismatch costs, \u03c7a(\u00b7) and \u03c8i(\u00b7, \u00b7), that are nonnegative. Therefore, both elements of the cost tuple associated with PMP are non-negative. If, in a given iteration, any factor node stops abstaining, then the first element of the tuple decreases, reducing the cost. If on the other hand the abstaining set does not change, then only the second element of the tuple can change. Since, by design, any choice of new votes can only decrease (2), then, when the abstaining set does not change, the second element of the tuple is at least as small as in the previous iteration. Thus, the cost tuple is monotonically decreasing.\nThe overall proactive message passing algorithm is summarized in Algorithm 1. The key step in the algorithm is when the optimal opinion vector for each factor is computed using (3). In this step an opinion vector oa is chosen for factor a to minimize the sum of the\nselection cost for this factor \u03c7a(o\u0304), the mismatch costs \u2211\ni\u2208Na \u03c8i(xi, o\u0304i)w a i for this factor,\nand the mismatch costs \u2211 i\u2208Na \u2211 b\u2208(Ni\\{a})\\A \u03c8i(xi, v b i )w b i\nfor the other factors that neighbor the same set of variables that this factor neighbors. We \u201cproactively\u201d choose the value of neighboring variables xi that will optimize the combined costs of the second and third terms, given the current state of the other factors\u2019 votes vbi . This \u201cproactivity\u201d is reminiscent of the \u201ccavity method\u201d introduced in statistical mechanics for the study of spin glasses (Me\u0301zard et al., 1987).\nAnother step that should be highlighted is when we choose the most confident factor(s) to change their votes. We do not simply want to greedily choose the factor that can reduce the overall cost by the most, because there might be two very different choices for the values of variables connected to that factor that both reduce the overall cost by a similar large amount, and committing to one of them prematurely could lead to convergence to a poor local optimum. In particular, this can easily happen for factors that are initially isolated from any other factors, including evidence nodes. They could reduce the overall cost significantly by selecting any \u201cmemory\u201d (set of variable values consistent with any one of the examples learned during training), but voting too early in this way would just lead to premature commitments leading ultimately to convergence to poor local optima. Instead, we want to prioritize factors for which one choice of variable values is significantly better than any other choice\u2014what we call \u201cconfident\u201d factors. Such factors typically share variables with several other factors that are already voting, and given those votes, one choice of a memory would reduce the overall cost much more than any other."}, {"heading": "3.2 Message-passing formulation", "text": "Equation (3) is written in general form, but we want to manipulate it into a form that reveals a message passing interpretation. In particular, we want to obtain \u201cmessages\u201d to a factor node from each of the variable nodes connected to it, informing the factor about the preferences of the rest of the network for each variable node, in the form of some sufficient statistic. To that end, we begin by defining x\u0303i to be the optimal choice of xi based on the votes of variable i\u2019s non-abstaining neighbors other than factor a, i.e.,\nx\u0303i = arg min xi  \u2211 b\u2208N \\ai \u03c8i(xi, v b i )w b i  . (4) where\nN \\ai = (Ni\\{a})\\A (5)\nis defined to be the set of non-abstaining memory factors neighboring variable i, excluding factor a.\nAlgorithm 1 Proactive message passing\n1: while the vote changing set V 6= \u2205 do 2: for each factor in the reacting set a \u2208 R do 3: Compute the opinion vector oa of factor a. The opinion vector is chosen to mini-\nmize a combination of selection cost \u03c7a(\u00b7) of the opinion vector and the aggregate dissatisfaction induced by that choice. Dissatisfaction is measured as the sum of mismatch costs \u03c8i(\u00b7, \u00b7), appropriately weighted, computed with respect to the optimal choice of variable settings for the vector xa for each possible opinion vector. In the following o\u0304 is a vector of the same dimension and alphabet as va.\noa = arg min o\u0304 \u03c7a(o\u0304) + \u2211 i\u2208Na min xi \u03c8i(xi, o\u0304i)wai + \u2211 b\u2208(Ni\\{a})\\A \u03c8i(xi, v b i )w b i  . (3) If there is a set of optimizers, one of which matches the previous vote vector va , set oa = va.\n4: if oa ' va then 5: Factor a\u2019s opinion vector is approximately the same as its current vote vector\nand the factor is satisfied. Set D = D\\{a}. (Note the specification of \u201c '\u2032\u2032 is problem specific.)\n6: else 7: Factor a is dissatisfied. Set D = D \u222a {a}. 8: Compute the confidence \u03ba(a) of factor a. (The computation of \u03ba(a) is problem specific.) 9: end if 10: end for 11: Identify the factor(s) that will change their votes. A sequential update rule would\nupdate the single most confident factor using V = arg maxa\u2208D \u03ba(a) where ties are broken at random. Simultaneous voting rules are also possible, where |V| > 1, for example updating a fixed fraction of the most confident factors.\n12: for each factor a \u2208 V do 13: Set the factor\u2019s vote vector equal to its opinion vector: va = oa. 14: end for 15: Recompute the abstaining set by removing new voters: A = A\\V. 16: Recompute the dissatisfied set by removing factors that just changed their votes: D = D\\V. 17: Determine the reacting set of factors whose opinion vectors may change due to the most recent update in votes: R = \u222aa\u2208V(\u222ai\u2208NaNi\\{a}). 18: end while 19: Define the output set O = {i|i \u2208 \u222aa\u2208If\\ANa}. (For most problems, at this stage A will\nalways equal \u2205 and O will equal Iv.) 20: Compute the optimal set of variable settings given the votes x\u0303O =\narg minxO \u2211 a\u2208If\\A[\u03c7a(v a) + \u2211 i\u2208Na \u03c8i(xi, v a i )w a i ].\n21: Return x\u0303O. For variables not in the output set, {xi|i \u2208 Iv\\O}, return an \u201cunknown\u201d flag.\nWe next rewrite the innermost argument in (3) as\nmin xi \u03c8i(xi, o\u0304i)wai + \u2211 b\u2208N \\ai [\u03c8i(xi, v b i )\u2212 \u03c8i(x\u0303i, vbi ) + \u03c8i(x\u0303i, vbi )]wbi  (6) = min\nxi \u03c8i(xi, o\u0304i)wai + \u2211 b\u2208N \\ai [\u03c8i(xi, v b i )\u2212 \u03c8i(x\u0303i, vbi )]wbi + \u2211 b\u2208N \\ai \u03c8i(x\u0303i, v b i )w b i  , (7) and substitute the result back into (3). We can drop the last term in (7) because it is not a function of either xi or o\u0304, yielding the following modified form of the optimization stated in (3):\noa = arg min o\u0304 \u03c7a(o\u0304) + \u2211 i\u2208Na min xi \u03c8i(xi, o\u0304i)wai + \u2211 b\u2208N \\ai [\u03c8i(xi, v b i )\u2212 \u03c8i(x\u0303i, vbi )]wbi   . (8)\nFor many reasonable choices of mismatch cost functions \u03c8i(\u00b7, \u00b7) and variable alphabets Xi, the minimization over xi requires only a small amount of summary information about the external vote and weight vectors, {vbi} and {wbi}. We think of such summary information as a message mai that is passed from variable i to factor a and rewrite (8) as\noa = arg min o\u0304\n{ \u03c7a(o\u0304) +\n\u2211 i\u2208Na \u03c6i(o\u0304i,m a i , w a i )\n} , (9)\nwhere \u03c6i(o\u0304i,m a i , w a i ) can be interpreted as the incremental cost of factor a casting its vote on variable i. It is always possible to reexpress (8) as (9) simply by setting mai equal to the set of vbi and w b i , i.e., m a i = {vbi , wbi} for all b \u2208 N \\a i . This transformation is thus of real interest only when the dimension (or cardinality) of the message is small and it is easy to compute the incremental cost \u03c6(\u00b7, \u00b7, \u00b7). In Section 4 we present a number of examples of useful mismatch cost functions and variable alphabets that meet these criteria."}, {"heading": "3.3 Parallel updates and simultaneous voting", "text": "The transformation of (3) to (9) enables us to perform the opinion computation relatively efficiently, but it still accounts for an overwhelming fraction of the total running time of PMP, particularly when the set of candidate opinions over which the minimization runs is large. Luckily, this computation is entirely independent for each factor and does not affect any state external to that factor, and so lines 3\u20139 of Algorithm 1 can be executed in parallel for each factor. (The update of D must then happen in a separate loop.) Thus PMP is naturally parallelizable to any available number of cores.\nA different form of parallelism, which actually changes the behavior of the algorithm, is for multiple factors to change their votes simultaneously. In the simplest version of PMP, only the single most confident factor changes its vote during each iteration. For this version, we can easily guarantee convergence because at each iteration one memory factor changes\nits vote vector to make a guaranteed non-increasing change in the overall objective. Other memory factors are then able to adjust to the change before computing their new opinions.\nIn contrast, we could let multiple factors (for example, the most confident 10 percent) simultaneously change their votes: (|V| > 1) . The principal positive effect of this modification is a reduction in the total number of times that the computation (3) is executed over the course of the algorithm. To see this, note that in the non-simultaneous version, each factor enters the reacting set R every time that a nearby factor votes on one of its neighboring variables. With simultaneous voting, if two nearby factors change their vote simultaneously, then our factor will only react once in total rather than twice. Since every factor in the reacting set participates in opinion updates, reducing the number of times a factor enters the reacting set reduces the total number of opinion updates, and the algorithm consumes less CPU time, even on a single core computer. Simultaneous voting also significantly reduces the overall number of iterations required for PMP to converge, as we shall see later.\nIn terms of the quality of the optimum found, it is not clear whether simultaneous voting should be superior or inferior to serial voting. Simultaneous voting has the potential advantage that it can make PMP less sensitive to the whims of a single factor. If the most confident factor disagrees with the next four most confident factors, then letting it vote by itself is likely to move the system in a non-optimal direction; the other factors may now change their opinions based on the first factor\u2019s votes, and may not get a chance to express their majority opinion. On the other hand, if all five factors vote simultaneously, the system will move in a way consistent with the majority. Empirically, we found that PMP converged to slightly better optima on the MNIST handwritten digit classification task when simultaneous voting was used (see Section 6.3). On the other hand, simultaneous voting slightly degraded the empirical performance of PMP on the restoration of corrupted images (see Section 6.4).\nSimultaneous voting does introduce a complication to PMP in that it is no longer true that the cost must be monotonically non-increasing each iteration. Updating factors may share variables and the change that one factor makes in its vote vector could alter the opinion of another factor. In practice, however, we observe that when using this procedure the cost function increases only extremely rarely. Further, it is possible to recover a guarantee of convergence through the following simple modification. We can observe whether the changes in vote vectors in any particular iteration result in a cost increase due to the interference between vote-changing factors. If a cost increase is observed, we roll back those vote changes and, for that iteration, return to the the serial procedure, only allowing the single most confident factor to change its votes. In practice this rollback occurs rarely; in the MNIST task, fewer than 1% of simultaneous votes were retracted."}, {"heading": "4. Types of variables and objective functions", "text": "In this section we consider several options for the alphabet Xi and cost \u03c8i of variable xi, and particularly consider different cases of the minimization\nx\u0303i = arg min xi \u2211 b\u2208B \u03c8i(xi, v b i )w b i (10)\nwith a fixed set of votes vBi for some B \u2286 Ni. A minimization of the above form is used in PMP both in computing the final variable settings to return and in computing the opinion of a factor via (8), which is the version of (3) that can be given a message-passing interpretation. It is thus of great importance that the minimization in (10) is tractable. Indeed for our choices of alphabets and cost functions, we obtain explicit solutions which allows us to write (3) in a simple message-passing form, per our discussion in Sec. 3.2. The messages come from all neighboring variable nodes and summarize the votes (and associated weights) of the memory factors neighboring each of those variables."}, {"heading": "4.1 Real variables with quadratic cost", "text": "First we consider the case where xi \u2208 R and the local cost functions are quadratic, thus \u03c8(x, v) = (x\u2212 v)2. Under a quadratic local cost function, (10) becomes\nx\u0303i = arg min xi \u2211 b\u2208B wbi (xi \u2212 vbi )2.\nFor this cost functional we take the derivative with respect to xi and set the result equal to zero to find the minimizing value of xi:\nx\u0303i =\n\u2211 b\u2208B w b iv\nb i\u2211\nb\u2208B w b i\n. (11)\nIn other words, the minimizing xi is a weighted combination of votes. Note that this result extends to the complex case xi \u2208 C with \u03c8i(x, v) = |x\u2212 v|2.\nWe show in Appendix A that if we apply this result to update opinion vectors for factor a then (3) becomes\noa = arg min o\u0304\n[ \u03c7a(o\u0304) +\n\u2211 i\u2208Na wai (w\u0302i \u2212 wai ) w\u0302i\n(o\u0304i \u2212 x\u0303i)2 ] , (12)\nwhere\nx\u0303i =\n\u2211 b\u2208N \\ai\nvbiw b i\u2211\nb\u2208N \\ai wbi\nis the weighted average of all the votes except for the one from factor a, and\nw\u0302i = \u2211\nb\u2208Ni\\A\nwbi\nis the sum of weights of non-abstaining factors. Note that w\u0302i \u2212 wai = \u2211\nb\u2208N \\ai wbi .\nEquation (12) tells us that, in this setting, the message is mai = {x\u0303i, w\u0302i \u2212 wai } which tells us the value x\u0303i that the rest of the network prefers, and the strength w\u0302i \u2212 wai of that preference."}, {"heading": "4.2 Integer variables with linear cost", "text": "We now consider the situation where xi \u2208 Z and the mismatch cost \u03c8 : Z \u00d7 Z \u2192 Z is absolute difference, i.e., \u03c8(x, v) = |x \u2212 v|. Further, we consider the setting where weights are all identical. We will argue that taking xi to be a median value of the votes minimizes the cost. The median is actually a set of values: for example, if there are four votes with values 1, 2, 3, and 6, the median would be the set {2, 3}. More generally, the median is the set of integers for which at least half of the votes have values no greater than the lower end of the range and at least half the votes have values at least as large as the upper end of the range. Thus,\nx\u0303i \u2208Mmed ( vBi ) = {v : |{vbi : vbi \u2264 v}| \u2265 dn/2e, |{vbi : vbi \u2265 v}| \u2265 dn/2e, b \u2208 B}.\nWe note that the median set can be summarized by its smallest and largest elements l and u asMmed = {l, . . . , u}. Of course, it is possible that that the set contains a single element, in which case l = u.\nWe now argue why a minimizing x\u0303i must be an element of the median set Mmed. First we show that all elements in the median set have equal cost. The set can in fact only have multiple elements if i is an even-degree variable node. In that case half of the elements will be at most equal to the least element of the set and half will be at least equal to the largest element in the set. (This is where the assumption of identical weights is used.) If we change the value of x\u0303i among elements of the median set, the mismatch cost will increase for half the votes the same amount it decreases for the other half. Thus, the votes are balanced in the range of the median set, so we confirm that all elements in the median set have equal cost. Next, to understand why a choice of x\u0303i outside of the median set incurs greater cost, consider the case when x\u0303i is set equal to the largest value in the median set. If we were to increase x\u0303i further by \u2206 > 0 the mismatch cost |x\u0303i \u2212 vbi | would increase by at least \u2206(dn/2e+ 1) due to the fact that at least dn/2e elements have values at most equal to the lowest value in the median set and at least one element has value equal to the largest value in the median set. The mismatch cost for elements with values larger than the largest value in the median set could decrease, but at most by \u2206(dn/2e \u2212 1) and so the cost increases if we take x\u0303i to be anything larger than the largest element of the median set. Similar logic holds if we choose x\u0303i to be smaller than the smallest element in the median set.\nWith this solution to (10), the message-passing from of the opinion update becomes\noa = arg min o\u0304\n[ \u03c7a(o\u0304) +\n\u2211 i\u2208Na \u03c6i(o\u0304i,m a i , w a i )\n] = arg min\no\u0304\n[ \u03c7a(o\u0304) +\n\u2211 i\u2208Na wai d(o\u0304i, li, ui)\n] . (13)\nIn (13), li and ui are the smallest and largest element of Mmed ( vBi )\nwhere B = N \\ai , i.e., the set of non-abstaining memory factor neighboring variable i, exclusive of a. Futher, the function d : Z\u00d7 Z\u00d7 Z\u2192 Z defined as\nd(z, l, u) =  z \u2212 u z > u 0 l \u2264 z \u2264 u l \u2212 z z < l\nis the distance from z to the interval [l, u].\nIn this case the summary message variable i passes to memory factor a is the pair of integers mai = (ui, li). This message is sufficient for factor a to determine the impact of choosing a particular opinion for variable i on the global cost function. The impact is summed across all variables that memory factor a neighbors.\nFinally, we note that the weights wai appearing in Equation (13) are subject to the assumption that all weights for the same variable are the same; e.g. wai = w b i for all b \u2208 Ni. Different weights may be associated with different variables."}, {"heading": "4.3 Labels with histograms", "text": "We now consider a situation relevant to hypothesis testing. In this setting the valid xi values correspond to labels. Generally we consider the set of labels to be finite: |Xi| <\u221e. As with integers we enforce the restriction that weights that are connected to the same variable must be equal. In this setting we take the local cost functions to be indicators \u03c8(x, v) = I(x 6= v).\nWe minimize the cost (10) by picking x\u0303i to be one of the vote values in v B i that occurs most frequently. If we were to pick any other (less frequently observed) vote value then the cost would increase by the decrease in the number of votes. Thus, it is optimal to pick x\u0303i to be an element of the mode set. which we denote as Mmod(vBi ). As with the median set, this set may be a singleton, or it may have multiple distinct elements. Thus we write that x\u0303i is optimal if\nx\u0303i \u2208Mmod ( vBi ) .\nThe message-passing form of the opinion update becomes\noa = arg min o\u0304\n[ \u03c7a(o\u0304) +\n\u2211 i\u2208Na wai I ( o\u0304i 6\u2208 Mmod ( vBi ))] ,\nwhere, as before, B = N \\ai . In this setting the summary message mai can be a binary vector of length |Xi| where the non-zero coordinates indicate possible vote values that are elements of the mode set."}, {"heading": "4.4 Mixing variable types", "text": "If a factor a neighbors variables of different types (real, integer, label), the opinion update problem (3) becomes a combination of problem types described above. In this situation, the sum over i \u2208 Na can be split into sums over different types of variables. For example, if Na = B \u222a C with i \u2208 B corresponding to complex variables and i \u2208 C corresponding to integer variables, we can re-express (3) as\noa = arg min o\u0304\n[ \u03c7a(o\u0304) +\n\u2211 i\u2208B wai (w\u0302i \u2212 wai ) w\u0302i |o\u0304i \u2212 x\u0304i|2 + \u2211 i\u2208C wai d(o\u0304i, li, ui)\n] .\nThe appropriate summary messages and update rules to use for each variable node follow from the discussion above."}, {"heading": "5. Types of Memory Factors", "text": "In this section we describe two ways to construct memory factors\u2014a simple approach using \u201cmemory tables,\u201d and a somewhat more complicated, but perhaps more scalable, approach using reduction to a lower dimensional subspace."}, {"heading": "5.1 Memory Table Factors", "text": "A memory table is simply a database of exemplars, each exemplar encoding a valid configuration of the variables that neighbor the factor in question. Memory factors that are memory tables are trivial to train. If we are given a number of exemplars from which to learn local structure we simply store xa = {xi : i \u2208 Na} for each exemplar. We think of each of these stored local snapshots as a \u201cmemory.\u201d\nFormally, the memory table corresponding to factor a is a database of La (generally) distinct memories {\u00b5al : l \u2208 [La]}. Each memory \u00b5al is a vector of length |Na|, the jth element of which is \u00b5al,j . Each element of this vector corresponds to a particular variable that neighbors factor a. If \u00b5al,j refers to variable xk (k \u2208 Iv is the jth element of Na) , then \u00b5al,j \u2208 Xk. The memory table corresponding to factor a is perhaps most conveniently thought of as an La \u00d7 |Na| array of variable values.\nNote that evidence factors can be thought of as a special case of memory table factors in which there is a single dynamic memory (La = 1) corresponding to the current state of the evidence.\nThe selection cost \u03c7a(\u00b7) we use in PMP for memory table a restricts the factor\u2019s opinions (and thus votes) to memories that are in the table. This is accomplished by using selection cost\n\u03c7a(o\u0304) = { 0 if \u2203 l \u2208 [La] s.t. o\u0304 = \u00b5al \u221e otherwise.\nThis choice simplifies (3) in the PMP algorithm. The outside arg min over o\u0304 restricts the optimization to opinions that exist in memory table a, for which the selection cost is zero.\nThe confidence \u03ba(a) of a memory table factor a is the difference in total cost (as specified by (3)) between the best and second-best distinct sets of opinions corresponding to its memories. Intuitively, a memory table factor has high confidence that its choice of memory is correct, even if that memory is costly, if the next best alternative is much worse. Therefore it makes sense for this factor to cast its votes now and allow other less confident factors to react to its decision.\nAlgorithm 1 requires us to specify the relationship oa ' va denoting whether a factor\u2019s opinion vector is sufficiently close to its vote vector for it to not want to change those votes. Since the set of possible vote vectors in a memory table factor is finite, we simply use equality for this comparison: (oa ' va) \u2261 (oa = va)."}, {"heading": "5.2 Subspace Factors", "text": "Another particular form of learned structure we can utilize for memory factors is reduction to a lower dimensional subspace (or a subset thereof). We refer to memory factors that enforce a dimensionality reduction as \u201csubspace factors.\u201d In particular we consider linear subspaces, which take the form of transformations from hidden variables z \u2208 Zp to visible\nvariables y \u2208 Yn. If Z = R and Y = R then a subspace factor is represented using a matrix W \u2208 Rn\u00d7p where the subspace is {y|y = Wz, z \u2208 Rp}. If the variables are complex, we use complex matrices and hidden variables. Furthermore, we often restrict ourselves to operate on a subset of the subspace so that Z \u2286 R and Y \u2286 R. For example, we will later provide an example where Z = R+ and Wij \u2208 R+. This restricts our subspace factor to the positive (cone) {y|y = Wz, z \u2208 Rp} \u2229 Rn+. With some abuse of terminology we continue to refer to such memory factors as \u201csubspace\u201d factors.\nSubspace factors may be learned from data by a variety of methods, e.g. nonnegative matrix factorization in the case of the cone mentioned above. Because we do not apply any sparsity assumptions to W , nor to the hidden variables z, we generally enforce p < n so that the subspace factor indeed provides a low-dimensional representation of the visible variables, which are constrained to lie in some low dimensional subspace of Yn spanned by the columns of W .\nIn the context of an MFN, let us suppose a particular memory factor a is a subspace factor, which maps pa hidden variables z \u2208 Zpaa to na visible variables y \u2208 Ynaa . We require the set of neighboring variables Na to include all visible variables represented by the subspace factor, as the variables represented in the MFN are presumed to be those of interest in the problem. In this paper we assume Na is precisely the set of visible variables for the subspace factor a. Thus na = |Na| and Ya = Xi for i \u2208 Na. Note that this restricts all variables in Na to have the same alphabet, a restriction that could be lifted by allowing subspace factors to have visible variables in different alphabets. Such subspace factors are possible, but we do not consider them here.\nFor the selection cost \u03c7a for votes from a subspace factor, we use\n\u03c7a(v a) = { 0 if there is a z \u2208 Zpaa s.t. va = Waz \u221e otherwise.\n(14)\nThis cost simply requires the vote va to be in the subspace (or subset thereof) defined by the factor, and allows the hidden variables to take on any value in their domain. Because the selection cost is either zero or infinite, we can replace it in the opinion update optimization with a feasibility constraint, so the problem becomes\noa = arg min o\u0304,z s.t. o\u0304=Waz, z\u2208Zpaa minxa \u2211 i\u2208Na \u03c8i(xi, o\u0304i)wai + \u2211 b\u2208N \\ai \u03c8i(xi, v b i )w b i   .\nWhile this is a reasonable constraint for a variety of variable types, our examples make use of the case where o\u0304 and z are both real (or both complex). Using the notation of Section 4, for real variables with quadratic cost the problem is\narg min \u2211 i\u2208Na wai (w\u0302i \u2212 wai ) w\u0302i (o\u0304i \u2212 x\u0303i)2 (15)\nsubject to o\u0304 = Waz.\nThis convex quadratic program is small and straightforward to solve. Note that linear restrictions can be included in the alphabet Xi without altering the nature of this problem.\nOne example when we restrict variables to be non-negative, i.e., Xi = R+. In this case (for which we will subsequently provide examples) all entries of Wa are constrained to be non-negative. In this case the problem becomes\narg min \u2211 i\u2208Na wai (w\u0302i \u2212 wai ) w\u0302i (o\u0304i \u2212 x\u0304i)2\nsubject to o\u0304 = Waz\no\u0304, z \u2265 0.\nWe can also extend the problem to complex variables with cost \u03c8i(x, v) = |x\u2212 v|2. We will define the confidence \u03ba(a) of a subspace factor a to be\n\u03ba(a) = 1\n|Na| (\u2211 i\u2208Na \u2212\u03bb \u2223\u2223\u2223N \\ai \u2223\u2223\u2223 |o\u0304i \u2212 x\u0304i|2 \u2212 1|Ni \\ A| ) (16)\nwhere \u03bb is a system parameter we can choose to balance the term representing mismatches between an opinion and the incoming messages and the term representing the number of votes those messages represent. Intuitively, a factor should be confident if it has a lot of information from the rest of the system and its opinion closely matches that information. We scale the score by the total number of adjacent variables so the penalty for variables with few votes does not have more relative impact at subspace factors with more variables in total.\nFinally, we choose some parameter \u03b1 > 0 and define the relationship \u201c'\u201d as\noa ' va \u21d0\u21d2 \u2016oa \u2212 va\u201622 \u2264 \u03b1\nwhere \u2016\u00b7\u20162 is the `2 norm. This means that subspace factors will be satisfied if there is only a small difference between their opinion vector and their vote vector. This prevents PMP from making an infinite number of decreasingly small updates."}, {"heading": "6. Applications", "text": "In this section we describe a number of applications that illustrate the basic mechanisms and abilities of memory factor networks. We also compare the behavior of MFNs using memory tables and those using subspace factors."}, {"heading": "6.1 Face reconstruction", "text": "Our first inference application is the reconstruction of missing or noisy data in a twodimensional color image. We use the FEI (fei) dataset of 400 52 \u00d7 72 pixel images, each showing a single face manually aligned so facial features are in the same pixel locations on each image. We use 320 of these images as a training set and hold out 80 for testing. We will describe a memory factor network (with both a memory table version and a subspace factor version) that represents such images and can be used for a variety of tasks with similar images. The set of variables we are interested in are the red, green, and blue pixel values for each pixel position in an image, with an additional set of variables representing the gray\nvalue of each pixel being added for some examples. Variables are therefore nonnegative real numbers. They are also normalized to be at most one, but we do not enforce this explicitly in the MFN, and simply truncate to one in the rare cases the MFN returns a larger value."}, {"heading": "6.1.1 Factor layout", "text": "The factors we use for this problem cover square grids of pixels at a particular location in the image. One basic structure is to create three factors (representing the red, green, and blue channels) for 8 \u00d7 8 squares of pixels in the image, with squares starting every 4 pixels so each factor shares a 4\u00d7 4 pixel square with three neighboring factors of the same type. At corners and edges we follow the same pattern but truncate factors as necessary. This structure essentially creates three parallel factor networks representing the three color channels, since none of these factors connected to 8 \u00d7 8 pixels are adjacent to variables of multiple colors.\nTo link the networks together we introduce factors that include variables of all three colors. To keep these from being overly large we have them cover 4\u00d74 pixel squares (so they have 3 \u00b716 = 48 visible variables). Beyond limiting the total size of each factor this structure of having \u201clinked\u201d factors with 1/4 the size of single channel factors greatly simplifies the connections between factors. In our implementation it is convenient to group variables into sets and have connections between sets of variables and factors rather than directly between variables and factors. With this choice of the size of linked factors all of our sets can be 4 \u00d7 4 grids of single channel pixel values, and each such set thus has connections to four 8\u00d7 8 mono-colored factors and one factor that links the three colors.\nWe also consider another layout in which 8 \u00d7 8 grids of pixels are covered by a single factor encoding all three colors, with the same overlapping structure as the single channel factors above. This greatly increases the size of each individual factor (a typical factor is connected to 8 \u00b7 8 \u00b7 3 = 192 variables), but results in a network with fewer factors and more knowledge of the connections between colors."}, {"heading": "6.1.2 Learning memories", "text": "In the case of memory tables, implementation of these factors is simple: each table includes the appropriate pixel values from each face in the training set. For subspace factors we must learn the matrix W (after choosing some order for the variables so they are represented as a vector). Since pixel values are nonnegative, we choose to use nonnegative matrix factorization (NMF) for this learning step. To be precise, to learn a given matrix W for a subspace factor with n variables from a training set of of m images, we choose some value p < n, construct an n \u00d7 m matrix X where the ith column contains the pixel values at the appropriate positions for the ith training image, and use a standard NMF algorithm to compute an approximate factorization\nX \u2248WH\nwhere W \u2208 Rn\u00d7p+ and H \u2208 R p\u00d7m + . In our implementation we use the NMF.jl package for the Julia programming language and its \u201cAlternate Least Square using Projected Gradient Descent\u201d algorithm. The matrix W is the desired subspace matrix, with H representing the hidden variable values that correspond to each of the training samples. Note that this\napproach works for any arbitrary collection of scalar variables, and is not dependent on having square samples, or on the subspace matrices having a particular size, or on the variables having any particular meaning. We simply need to transform whatever portion of the image we are interested in into a vector of scalars and then stack those vectors into a matrix which we can factorize. The only restriction comes in our choice of p, which should be smaller than n to avoid trivial factorizations. Generally we will choose p much smaller than n so the subspace is in some sense representing the \u201ckey features\u201d of the image segment, as learned from the training set."}, {"heading": "6.1.3 Missing data", "text": "Our primary example problem is that of a test image in which some portion of the image has been erased, for example the eyes (as seen in Fig. 1). In general, the algorithm is able to make reasonably plausible reconstructions of the missing pixels, based on the pixels it does see and its memory of other face images. Naturally, the test image was not in the training set. In this case we provide our network with evidence from nearby sections of the image and run the algorithm to generate pixel values for the occluded region. Because in this case we assume the evidence that is not erased matches the ground truth, the weight of the evidence for those pixels is made sufficiently large to dominate the factor votes in determining the final variable values. Without this modification we have a tendency to blur or distort images, particularly in the subspace case since they must be represented by so few dimensions. Subspace networks tend to generate an \u201caverage\u201d set of eyes, in which the two eyes match each other and the surrounding face but lack any significant notable features. Memory tables, drawing directly from a wide sample of eyes, are more likely to generate unique-looking eyes which may or may not match each other. This can also lead to color anomalies as there is more variation in the sorts of results each factor votes for.\nOne missing data instance where it may be more advantageous to allow blurring of received data, however, is the case where data is missing from random locations of the\nimage rather than only in a given section. When data loss is isolated (e.g. the eyes) there is little to be gained from \u201ccorrecting\u201d the data that is provided, but when data loss is spread among sections of the image where most data is present, treating evidence as absolute truth can result in anomalies as some pixels receive smoothed values while adjacent pixels keep the more variable original. In such cases it may make more sense to simply smooth over the whole image, which usually results in a blurry but consistent-looking face, rather than one with odd blotches. See Fig. 2 for an example of this blurring in an image with randomly missing evidence.\nAnother example of missing data is the case in which the given evidence is the grayscale pixel values rather than any color data. That is, we are given a grayscale image of a face and would like to color it. This requires the introduction of variables for the gray values, which will be attached to some subset of the factors. We find that the best results come from including gray on factors that contain all three color channels. Recall that the gray value of a pixel can be found by taking a linear combination of its RGB values (we use the CIE 1931 standard with Gray = 0.212673 \u00b7 R + 0.715152 \u00b7 G + 0.072175 \u00b7 B). Rather than treating this as a hard constraint, however, the MFN treats gray values as simply another channel, trusting to the learned structure to maintain the appropriate relationships. For the inference problem of coloring a perfect grayscale image we add a post-processing step that scales the RGB pixel values to match the gray values. An example of the results on this problem can be seen in Fig. 3.\nWith colorization we see significant differences in behavior between memory tables and subspace factors. Given strong gray evidence, clusters of memory tables will often choose the same training face, resulting in a MFN image that composites a relatively small number of images. The post-processing step will then often lead to misplaced colors as, for example, pixels that were part of the neck of a training example become part of the background of the colored image. For subspace factors the image directly from the MFN will more closely\nresemble the grayscale image, though it will be blurred. Subspace factors also often leave sections of the colorized image gray, apparently when there is little to distinguish between color options, whereas memory tables will always choose a color from their memories."}, {"heading": "6.1.4 Noisy data", "text": "One case where it will rarely if ever make sense to privilege given evidence is the case of noisy data. If \u201cknown\u201d pixel values have been perturbed in some way we will prefer the smoothed result given by applying our algorithm generally, with equal weights between factors and evidence (or even extra weight for factors). See Fig. 4 for example results in the case of noisy data."}, {"heading": "6.1.5 Results summary", "text": "We ran PMP with the described settings for each of the problems described above on each of the 80 test images, computing the mean square error of the color-pixel values (over the portion of the image used in the MFN). Statistics summarizing the results are presented in Table 1, and images for the best and worst examples of each problem are available in Appendix B."}, {"heading": "6.2 Music reconstruction", "text": "Another application of MFNs is in the processing of audio files. Again the question of interest may be reconstructing missing data or smoothing noisy data, and some design decisions will be different depending on the application, but first we will describe the general process we use for transforming an audio file into a format appropriate for a MFN. For our data set we use 9 second long clips of randomly generated music downloaded from Otomata (Oto) with 142 training samples and 20 test samples. All clips have sample rate 40k Hz. For memory table factors, to limit RAM usage, a random subset of training samples was used in each run of PMP, with each sample being included independently with probability 0.3."}, {"heading": "6.2.1 Creating a spectrogram", "text": "Our MFNs will work on a spectrogram representation of the audio files, so we use the Short-time Fourier Transform (STFT) to process our audio samples. This process begins by splitting the audio into a series of overlapping frames of a given length. The overlap may be varied by changing the \u201chop size\u201d, which determines the distance between the starting time of consecutive frames. We use a frame length of 50ms and a hop size of 25ms. After splitting the frames the data in each frame is multiplied by a window function: we use the Hanning window. Each windowed frame is then individually Fourier transformed. After these Fourier transforms we have a matrix of complex values in which each column represents a frame of time and each row represents a signal frequency. The frequency range\nand resolution is determined by the the sample rate of the audio and the length of the frames, respectively. In particular, the number of frequencies represented is equal to half the number of data points per frame plus 1, so for our 50ms frames with the audio sampled at 40k Hz we will have 1001 frequencies represented, ranging from 0 Hz to 20k Hz. Rather than use the entire matrix, we will decrease it in size by grouping frequencies into bins. For a given number of frequencies nf and desired number of bins nb (we generally use 400) we compute a coefficient a such that\nnb\u2211 j=1 bejac \u2248 nf\nand then use bejac as the number of frequencies to include in the jth bin, starting with the first bin taking the lowest beac frequencies. For bins with multiple frequencies we simply sum the values of all included frequencies. This logarithmic binning scheme reduces the size of the network we work on while maintaining most of the resolution for the lower frequencies that are of more importance to the original signal. With this binned matrix we are prepared to build a memory factor network.\nBecause our variables are now complex valued, to learn subspace factors we follow the work of Baldi and Lu (Baldi and Lu, 2012) and use a PCA approach. More specifically, the matrix W is formed from the p eigenvectors with greatest magnitude eigenvalues of the covariance matrix \u03a3 = \u2211 t xtx \u2217 t where {xt} are the training vectors (note that W in our notation is A in the notation of Baldi and Lu). Memory tables continue to simply store all training examples."}, {"heading": "6.2.2 Factor layout", "text": "Because the perceived quality of a sound generally depends on all frequencies present in that sound (possibly on non-adjacent frequencies), we consider memory factors that cover the entire frequency spectrum over a small period of time. This allows the factor to learn the entire frequency profile of a given sound, which often includes many distant frequencies. For our main test case of randomly generated music we also note that absolute time position has little meaning, as we have no a priori expectation that, for example, the last two seconds of a sample should be any different than the first two seconds. Because of this, instead of learning different memory factors for different parts of the spectrogram, we learn a single subspace matrix or set of memories from all time-positions of all training examples and share this between all memory factors in the network. Note that this results in a very large training set even for a relatively small number of music samples.\nWe note that this time-independence is a feature of our particular choice of audio signal, and would not hold true for something more structured in time, like a short piece of speech. Such examples would more closely resemble the face example, where specific features generally appear at the same time position (and possibly frequency position) in every sample."}, {"heading": "6.2.3 Missing music", "text": "Analogously to the removal of eyes from a face, we consider the inference problem of filling in gaps in a piece of music. In this situation we will give significant weight to the evidence\npresent, preferring to maintain the original signal where possible. It will also generally be advantageous to pick relatively wide memory factors (10-20 spectrogram pixels) to maximize the connection between the newly created signal and the original signal it is adjacent to. For example spectrograms for a reconstruction problem, see Fig. 5.\nFor constructing missing music, memory tables have significantly better properties than subspace factors in our testing. The memory table network selects full notes or sequences of notes and attempts to choose those that fit best with the surrounding music, whereas subspace factors generally match the dominant frequencies of the surrounding music but do not recreate the shape of notes, rather creating a sort of flat buzz, often with a volume spike. We believe part of the reason for this behavior is that the subspace factors are trained on a variety of shifts in time of a note and rather than being forced to choose between these shifts are able to combine them, creating smoother, blended sections of spectrogram that are quite unlike the patterns of notes in the training set."}, {"heading": "6.2.4 Noisy music", "text": "Another problem we consider is that of removing noise from a music sample. To simulate this problem we add normal random noise to our test sample. Because many regions of the spectrogram have value zero in the absence of noise, if evidence is given any significant weight relative to memory factors a certain degree of noise will still be present at the end of the algorithm. To combat this effect we run PMP twice, first with a large weight on the evidence and no votes from factors and then again with very little weight for the evidence but taking the final votes of the factors as the initial votes in the second run. This allows factors to take advantage of the evidence while not allowing it to dominate. Because factors primarily need to match the signal underneath the noise rather than coordinating over time intervals, we use very narrow factors (2 pixels) for noise problems.\nAn example of a noisy music problem can be seen in Fig. 6. Again we see that memory tables are better able to maintain the rich structure of notes, though subspace factors do maintain much more of the structure of music than they did when attempting to create\nstretches of it, and are better able to exactly match the main structures than memory tables, which must try to find matching notes among their memories. Combining these notes from different training samples results in a somewhat more disjointed reconstruction, whereas subspace factors are somewhat fuzzier but smoother."}, {"heading": "6.2.5 Results summary", "text": "We ran PMP with the described settings for the two problems described above on each of the 20 test clips, computing the mean square error of the spectrogram pixel values. Statistics summarizing the results are presented in Table 2, and images for the best and worst examples of each problem are available in Appendix B."}, {"heading": "6.3 Handwritten digit classification", "text": "We now demonstrate the use of label variables and mixed-variable factors by using memory table MFNs to classify handwritten digits. We use the MNIST dataset (LeCun et al.) consisting of 60,000 training examples of 28\u00d728 grayscale images with correct classifications and 10,000 test images with no classification.\nWe work with 32\u00d7 32 images, in which the original images have been centered, in order to facilitate a hierarchy of pixel and label variables. In addition to 322 level-0 variables representing the image\u2019s pixels, there are 162 hidden level-1 variables corresponding to a lower-resolution version of the same image, 82 hidden level-2 variables corresponding to an even lower resolution version, and 42 hidden level-3 variables representing the entire image. A hierarchy of label variables exists in parallel to the hierarchy of pixel variables, with 152 level-0 variables, 72 level-1 variables, 32 level-2 variables, and a single level-3 variable characterizing the entire image. The pixel variables are integer variables with linear cost and weights of 1, while the label variables use an indicator cost as described in Section 4.3 with weights of 32. The label variables have a higher weight than the pixel variables both because there are fewer of them and because the natural scale of a mismatch is lower.\nThis hierarchy has two useful properties. Firstly, it allows locally inferred labels to be synthesized into one global label which can then be read off as the classification of the entire image. Secondly, it provides a \u201cfast lane\u201d for information to propagate from one part of the image to a more remote part. Inferences about pixels or labels can flow up and down the hierarchy in a faster way than if they had to linearly diffuse through the network.\nThe network hierarchy is constructed in the following manner. Each factor at level n is connected to 82 pixel variables and 32 label variables of level n, as well as to 42 pixel variables and 1 label variable of level n+ 1. A sample set of variables connected to a single memory table factor is shown in Fig. 7.\nWhen a training example is presented to the system, all label variables are set to the correct label and all hidden pixel variables are set to the average of the pixel values in the corresponding 2 \u00d7 2 patch of the image at the next lower level. Every memory in each memory table thus is filled with specified values.\nAt testing time, the hidden pixel and label variables are not connected to evidence factors; they only acquire values as a result of being voted on by memory table factors. A level-0 factor that thinks that a group of pixels is characteristic of a 4 will cast votes for its neighboring level-1 pixel variables with a blurred version of its memory and cast a vote of 4 for its neighboring level-1 label variable. Factors pay a mismatch cost for disagreeing both with pixel variables and with label variables, and thus a factor that isn\u2019t sure whether it is looking at a 4 or a 9 may be swayed by the fact that a neighboring factor has cast a vote for the label 4. When the algorithm has converged, we classify the image according to the single label at the top of the hierarchy.\nThis simple Memory Factor Network is sufficient to classify the 10,000 test images of the MNIST data set with 96.15% accuracy when run with a single factor voting at a time, and 96.41% accuracy when using simultaneous votes of the top 10% of factors (see Section 3.3). On average the single-vote implementation required 78.7 iterations and 1148.9 opinion updates, while the simultaneous-vote implementation required 16.9 iterations and 687.2 opinion updates."}, {"heading": "6.4 Restoration of corrupted images", "text": "A natural application for MFNs using memory tables is to reconstruct previously-seen images when presented with versions of them that have been corrupted by noise or erasure. We use a similar network to that of the face reconstruction application and for data we\nLevel 0 Level 1 Level 2 Level 3\nuse the CIFAR-10 dataset of 32 \u00d7 32 RGB images (Krizhevsky, 2009), containing 50,000 images. The provided labeling of the images is irrelevant to our problem.\nAfter all 50,000 images are read, one of the previously-seen images is selected at random and has Gaussian noise applied to every color channel value of every pixel with a standard deviation of 40. In addition, a randomly-generated blob of 144 pixels is completely erased from the center of the image (providing no evidence). This image is then presented to the MFN, which restores the image to its original version, removing the applied noise and filling in the correct pixels of the erased region.\nThis application is particularly convenient because it has a quantitative metric for assessing the quality of the result; we simply measure the L1 distance between the computed image and the original. This makes it a natural choice for evaluating the effect of changes to the algorithm.\nThus, to assess the effects of simultaneous voting, we ran the PMP algorithm over 1000 test images using both the standard serial algorithm and the simultaneous voting version described in Section 3.3, running 10% of all factors every iteration. While the simultaneous voting version was less likely to reproduce the initial image exactly, its average error was comparable to that of the serial version. The serial version restored 91.9% of the images perfectly with an average total L1 error across all color channels of 895.1 (0.291 per pixel per channel), while the simultaneous voting version restored only 83.1% of the images perfectly but with an average total L1 error of 936.7 (0.305 per pixel per channel)."}, {"heading": "7. Conclusions and future work", "text": "We have introduced here a new approach to combining inference with learning from experience. Memory factor networks provide a simple way to store examples learned from experience, while proactive message passing using a confidence-based scheme for prioritizing factor updates gives a reliable way to converge to good optima of the memory factor network cost function.\nWe consider the algorithms and the applications demonstrated here to be just an initial foray into the possibilities raised by this approach. Thus, one might consider factor graphs that combined memory factor nodes with more conventional factor nodes that encoded known statistical dependencies or constraints. The PMP algorithm is well-suited to MFNs, but one might nevertheless consider using other approaches, such as those based on belief propagation or variational approaches (Wainwright and Jordan, 2008), or those based on the alternating directions method of multipliers (Boyd et al., 2011; Derbinsky et al., 2013). There are many potential applications that one might attack with this approach, including just from computer vision the problems of inferring depth from single images, or motion from videos. Finally, an important open question is how well the approach described here can take advantage of massive amounts of data, as are often now available (Halevy et al., 2009)."}, {"heading": "Appendix A: Derivation of opinion update for real variables with quadratic cost", "text": "In this section we derive the messages in the message-passing version of PMP for real variables and quadratic costs. Under these choices, (3) specializes to\noa = arg min o\u0304 \u03c7a(o\u0304) + \u2211 i\u2208Na min xi wai (xi \u2212 o\u0304i)2 + \u2211 b\u2208N \\ai wbi (xi \u2212 vbi )2  . (17)\nwhere we recall the definition of N \\ai = (Ni\\{a})\\A, originally made in (5). We first optimize the choice of xi by taking the derivative with respect to xi:\nx\u0304i = arg min x wbi (x\u2212 o\u0304i)2 + \u2211 b\u2208N \\ai wbi (x\u2212 vbi )2  = o\u0304iwai + \u2211 b\u2208N \\ai vbiw b i\u2211 b\u2208Ni w b i .\nIf we define w\u0302i = \u2211\nb\u2208Ni\\Aw b i then \u2211 b\u2208N \\ai\nwbi = w\u0302i \u2212 wai . Multiplying and dividing the second term by (w\u0302i \u2212 wai ) we get\nx\u0304i = wai o\u0304i + (w\u0302i \u2212 wai ) x\u0303i\nw\u0302i ,\nwhere\nx\u0303i = arg min x \u2211 b\u2208N \\ai wbi (x\u2212 vbi )2 =\n\u2211 b\u2208N \\ai\nvbiw b i\u2211\nb\u2208N \\ai wbi\n=\n\u2211 b\u2208N \\ai vbiw b i\nw\u0302i \u2212 wai (18)\nis the minimization of xi with respect solely to memory factors in N \\ai . This is the same x\u0303i as was defined in Sec. 3.2.\nWe denote the cost associated with a particular variable i \u2208 Na for a given opinion o\u0304i as c(o\u0304i). Then we have\nc(o\u0304i) = w a i (x\u0304i \u2212 o\u0304i)\n2 + \u2211\nb\u2208N \\ai\nwbi ( x\u0304i \u2212 vbi )2\n= wai\n( wai o\u0304i + (w\u0302i \u2212 wai ) x\u0303i\nw\u0302i \u2212 o\u0304i\n)2 + \u2211\nb\u2208N \\ai\nwbi\n( wai o\u0304i + (w\u0302i \u2212 wai ) x\u0303i\nw\u0302i \u2212 vbi\n)2\n= wai (w\u0302i \u2212 wai )2\nw\u03022i (x\u0303i \u2212 o\u0304i)2 +\n1\nw\u03022i ( \u2211 b\u2208N \\ai wbi ( wai o\u0304i + (w\u0302i \u2212 wai ) x\u0303i \u2212 w\u0302ivbi )2)\n= wai (w\u0302i \u2212 wai )2\nw\u03022i (o\u03042i \u2212 2o\u0304ix\u0303i) +\n1\nw\u03022i ( \u2211 b\u2208N \\ai wbi [(w a i o\u0304i) 2 + wai (w\u0302i \u2212 wai ) o\u0304ix\u0303i \u2212 wai w\u0302ivbi o\u0304i] ) + C,\nwhere the constant term C includes all the terms that are not a function of o\u0304. We next simplify the sums over b \u2208 N \\ai by recalling that \u2211 b\u2208N \\ai\nwbi = (w\u0302i\u2212wai ) and that, from (18),\u2211 b\u2208N \\ai wbiv b i = (w\u0302i \u2212 wai )x\u0303i. Hence,\nc(o\u0304i) = wai (w\u0302i \u2212 wai )2\nw\u03022i (o\u03042i \u2212 2o\u0304ix\u0303i) + o\u03042i (wai ) 2 (w\u0302i \u2212 wai ) w\u03022i + o\u0304ix\u0303i wai (w\u0302i \u2212 wai )\n2\nw\u03022i \u2212 o\u0304ix\u0303i wai w\u0302i(w\u0302i \u2212 wai ) w\u03022i + C\n= wai (w\u0302i \u2212 wai )\nw\u0302i\n( o\u03042i \u2212 2x\u0303io\u0304i ) + C,\nwhere in the second equation a number of terms cancel. We substitute this result into (17) noting that the constant C can be dropped and adding a constant to make ( o\u03042i \u2212 2x\u0303io\u0304i ) a quadratic form. This yields the final form of our optimization,\noa = arg min o\u0304\n{ \u03c7a(o\u0304) +\n\u2211 i\u2208Na wai (w\u0302i \u2212 wai ) w\u0302i\n(o\u0304i \u2212 x\u0303i)2 } . (19)"}, {"heading": "Appendix B: Reconstruction results", "text": "So that the reader can have a reasonable sense for the range of possible results, including the nature of artefacts obtained using proactive message passing on memory factor networks, we include here images of the best and worst solutions for a variety of problems and for each type of factor (memory table or subspace), first for reconstructing face images, and then reconstructing for music spectrograms."}], "references": [{"title": "Complex-valued autoencoders", "author": ["P. Baldi", "Z. Lu"], "venue": "Neural Networks,", "citeRegEx": "Baldi and Lu.,? \\Q2012\\E", "shortCiteRegEx": "Baldi and Lu.", "year": 2012}, {"title": "Distributed optimization and statistical learning via the alternating direction method of multipliers", "author": ["S. Boyd", "N. Parikh", "E. Chu", "B. Peleato", "J. Eckstein"], "venue": "Foundations and Trends in Machine Learning,", "citeRegEx": "Boyd et al\\.,? \\Q2011\\E", "shortCiteRegEx": "Boyd et al\\.", "year": 2011}, {"title": "An improved three-weight messagepassing algorithm", "author": ["N. Derbinsky", "J. Bento", "V. Elser", "J.S. Yedidia"], "venue": null, "citeRegEx": "Derbinsky et al\\.,? \\Q1961\\E", "shortCiteRegEx": "Derbinsky et al\\.", "year": 1961}, {"title": "Codes on graphs: Normal realizations", "author": ["G.D. Forney"], "venue": "IEEE Trans. Inform. Theory,", "citeRegEx": "Forney.,? \\Q2001\\E", "shortCiteRegEx": "Forney.", "year": 2001}, {"title": "Learning low-level vision", "author": ["W.T. Freeman", "E.C. Pasztor", "O.T. Carmichael"], "venue": "Int. J. Computer Vision,", "citeRegEx": "Freeman et al\\.,? \\Q2000\\E", "shortCiteRegEx": "Freeman et al\\.", "year": 2000}, {"title": "Example-based super-resolution", "author": ["W.T. Freeman", "T.R. Jones", "E.C. Pasztor"], "venue": "IEEE Computer Graphics and Applications,", "citeRegEx": "Freeman et al\\.,? \\Q2002\\E", "shortCiteRegEx": "Freeman et al\\.", "year": 2002}, {"title": "The unreasonable effectiveness of data", "author": ["A. Halevy", "P. Norvig", "F. Pereira"], "venue": "IEEE Intelligent Systems,", "citeRegEx": "Halevy et al\\.,? \\Q2009\\E", "shortCiteRegEx": "Halevy et al\\.", "year": 2009}, {"title": "Probabilistic Graphical Models: Principles and Techniques", "author": ["D. Koller", "N. Friedman"], "venue": null, "citeRegEx": "Koller and Friedman.,? \\Q2009\\E", "shortCiteRegEx": "Koller and Friedman.", "year": 2009}, {"title": "Learning multiple layers of features from tiny images", "author": ["A. Krizhevsky"], "venue": "Masters Thesis, University of Toronto,", "citeRegEx": "Krizhevsky.,? \\Q2009\\E", "shortCiteRegEx": "Krizhevsky.", "year": 2009}, {"title": "Factor graphs and the sum-product algorithm", "author": ["F.R. Kschischang", "B.J. Frey", "H. Loeliger"], "venue": "IEEE Trans. Inform. Theory,", "citeRegEx": "Kschischang et al\\.,? \\Q2001\\E", "shortCiteRegEx": "Kschischang et al\\.", "year": 2001}, {"title": "The factor graph approach to model-based signal processing", "author": ["H. Loeliger", "J. Dauwels", "J. Hu", "S. Korl", "L. Ping", "F.R. Kschischang"], "venue": "Proc. of the IEEE,", "citeRegEx": "Loeliger et al\\.,? \\Q2007\\E", "shortCiteRegEx": "Loeliger et al\\.", "year": 2007}, {"title": "Modern Coding Theory", "author": ["T.J. Richardson", "R. Urbanke"], "venue": null, "citeRegEx": "Richardson and Urbanke.,? \\Q2008\\E", "shortCiteRegEx": "Richardson and Urbanke.", "year": 2008}, {"title": "Signal and image processing with belief propagation", "author": ["E. Sudderth", "W.T. Freeman"], "venue": "IEEE Signal Process. Mag.,", "citeRegEx": "Sudderth and Freeman.,? \\Q2008\\E", "shortCiteRegEx": "Sudderth and Freeman.", "year": 2008}, {"title": "Graphical models, exponential families, and variational inference", "author": ["M.J. Wainwright", "M.I. Jordan"], "venue": "Foundations and Trends in Machine Learning,", "citeRegEx": "Wainwright and Jordan.,? \\Q2008\\E", "shortCiteRegEx": "Wainwright and Jordan.", "year": 2008}, {"title": "Constructing free energy approximations and generalized belief propagation algorithms", "author": ["J.S. Yedidia", "W.T. Freeman", "Y. Weiss"], "venue": "IEEE Trans. Inform. Theory,", "citeRegEx": "Yedidia et al\\.,? \\Q2005\\E", "shortCiteRegEx": "Yedidia et al\\.", "year": 2005}], "referenceMentions": [{"referenceID": 9, "context": "Factor graphs and message passing (Kschischang et al., 2001; Loeliger et al., 2007; Koller and Friedman, 2009; Yedidia et al., 2005; Sudderth and Freeman, 2008) have proved to be an extremely effective combination when one is faced with an inference task wherein global problem structure decomposes into a large set of local constraints.", "startOffset": 34, "endOffset": 160}, {"referenceID": 10, "context": "Factor graphs and message passing (Kschischang et al., 2001; Loeliger et al., 2007; Koller and Friedman, 2009; Yedidia et al., 2005; Sudderth and Freeman, 2008) have proved to be an extremely effective combination when one is faced with an inference task wherein global problem structure decomposes into a large set of local constraints.", "startOffset": 34, "endOffset": 160}, {"referenceID": 7, "context": "Factor graphs and message passing (Kschischang et al., 2001; Loeliger et al., 2007; Koller and Friedman, 2009; Yedidia et al., 2005; Sudderth and Freeman, 2008) have proved to be an extremely effective combination when one is faced with an inference task wherein global problem structure decomposes into a large set of local constraints.", "startOffset": 34, "endOffset": 160}, {"referenceID": 14, "context": "Factor graphs and message passing (Kschischang et al., 2001; Loeliger et al., 2007; Koller and Friedman, 2009; Yedidia et al., 2005; Sudderth and Freeman, 2008) have proved to be an extremely effective combination when one is faced with an inference task wherein global problem structure decomposes into a large set of local constraints.", "startOffset": 34, "endOffset": 160}, {"referenceID": 12, "context": "Factor graphs and message passing (Kschischang et al., 2001; Loeliger et al., 2007; Koller and Friedman, 2009; Yedidia et al., 2005; Sudderth and Freeman, 2008) have proved to be an extremely effective combination when one is faced with an inference task wherein global problem structure decomposes into a large set of local constraints.", "startOffset": 34, "endOffset": 160}, {"referenceID": 11, "context": "In applications such as error correction decoding (Richardson and Urbanke, 2008), these local constraints have a", "startOffset": 50, "endOffset": 80}, {"referenceID": 4, "context": "in their VISTA (\u201cVision by Image/Scene training\u201d) approach (Freeman et al., 2000).", "startOffset": 59, "endOffset": 81}, {"referenceID": 5, "context": "The main application considered using the VISTA approach was example-based super-resolution (Freeman et al., 2002).", "startOffset": 92, "endOffset": 114}, {"referenceID": 3, "context": "Perhaps other than the edge weights, the above description is standard; it quite neatly fits into the formalism of a \u201cnormal\u201d factor graph due to Forney (Forney, 2001).", "startOffset": 153, "endOffset": 167}, {"referenceID": 14, "context": "This feature of guaranteed convergence to at least a local optimum is not shared by most message-passing algorithms operating on factor graphs containing cycles (Yedidia et al., 2005).", "startOffset": 161, "endOffset": 183}, {"referenceID": 0, "context": "Because our variables are now complex valued, to learn subspace factors we follow the work of Baldi and Lu (Baldi and Lu, 2012) and use a PCA approach.", "startOffset": 107, "endOffset": 127}, {"referenceID": 8, "context": "use the CIFAR-10 dataset of 32 \u00d7 32 RGB images (Krizhevsky, 2009), containing 50,000 images.", "startOffset": 47, "endOffset": 65}, {"referenceID": 13, "context": "The PMP algorithm is well-suited to MFNs, but one might nevertheless consider using other approaches, such as those based on belief propagation or variational approaches (Wainwright and Jordan, 2008), or those based on the alternating directions method of multipliers (Boyd et al.", "startOffset": 170, "endOffset": 199}, {"referenceID": 1, "context": "The PMP algorithm is well-suited to MFNs, but one might nevertheless consider using other approaches, such as those based on belief propagation or variational approaches (Wainwright and Jordan, 2008), or those based on the alternating directions method of multipliers (Boyd et al., 2011; Derbinsky et al., 2013).", "startOffset": 268, "endOffset": 311}, {"referenceID": 6, "context": "Finally, an important open question is how well the approach described here can take advantage of massive amounts of data, as are often now available (Halevy et al., 2009).", "startOffset": 150, "endOffset": 171}], "year": 2016, "abstractText": "We introduce a new type of graphical model that we call a \u201cmemory factor network\u201d (MFN). We show how to use MFNs to model the structure inherent in many types of data sets. We also introduce an associated message-passing style algorithm called \u201cproactive message passing\u201d (PMP) that performs inference on MFNs. PMP comes with convergence guarantees and is efficient in comparison to competing algorithms such as variants of belief propagation. We specialize MFNs and PMP to a number of distinct types of data (discrete, continuous, labelled) and inference problems (interpolation, hypothesis testing), provide examples, and discuss approaches for efficient implementation.", "creator": "LaTeX with hyperref package"}}}