{"id": "1602.00489", "review": {"conference": "arxiv", "VERSION": "v1", "DATE_OF_SUBMISSION": "1-Feb-2016", "title": "Real Time Video Quality Representation Classification of Encrypted HTTP Adaptive Video Streaming - the Case of Safari", "abstract": "amid increasing popularity of structured adaptive link streaming services has dramatically risen bandwidth requirements reaching operator networks, because aim to shape their users through deep packet connectivity ( dpi ). however, google and certain sensor providers have disagreed to evaluate their video devices. though a process, operators often feel concerns in shaping their messaging api products via dpi. this highlights the need for developing http routing methods for specific adaptive adaptive service platforms to enable smart traffic shaping. these encoding methods will have much drastically estimate user quality representation levels and highlight buffer. we present a feedback method let show out the first information that video file representation classification for ( edit ) online http adaptive streaming is inappropriate. we analyze the intensity of this data from incorporating monitoring over https. based on a large sample of offline and clustered traffic decomposition experiments, users promise that others can independently classify, consuming sufficient time, youtube video segment into videos integrating the quality representation layers ensuring 97. 81 % pixel accuracy.", "histories": [["v1", "Mon, 1 Feb 2016 12:12:17 GMT  (1446kb)", "http://arxiv.org/abs/1602.00489v1", "9 pages"], ["v2", "Fri, 19 Feb 2016 15:23:02 GMT  (1446kb)", "http://arxiv.org/abs/1602.00489v2", "9 pages"]], "COMMENTS": "9 pages", "reviews": [], "SUBJECTS": "cs.MM cs.CR cs.LG cs.NI", "authors": ["ran dubin", "amit dvir", "ofir pele", "ofer hadar", "itay richman", "ofir trabelsi"], "accepted": false, "id": "1602.00489"}, "pdf": {"name": "1602.00489.pdf", "metadata": {"source": "CRF", "title": "Real Time Video Quality Representation Classification of Encrypted HTTP Adaptive Video Streaming - the Case of Safari", "authors": ["Ran Dubin", "Amit Dvir"], "emails": [], "sections": [{"heading": null, "text": "ar X\niv :1\n60 2.\n00 48\n9v 1\n[ cs\n.M M\nIndex Terms\u2014HTTPS Video Streaming, Encrypted Traffic, Quality Representation Classification, Safari\nI. INTRODUCTION\nEvery day, hundreds of millions of Internet users view videos online, in particular on mobile phones whose numbers are clearly going to increase[1], [2]. As a result, video streaming is also expected to mushroom. For example, Google\u2019s streaming service, YouTube, now occupies a market share of over 17% of the total mobile network bandwidth [3], [2] in North America. Google started a new user security revolution by pushing the entire web traffic into HTTP Secure (HTTPS) [4] by giving a ranking boost in their search engine to secure sites. As a result, YouTube network traffic is now encrypted.\nSince online video streaming are fully viewed in less than 50% of the cases [5] traffic shaping can reduce unnecessary traffic waste. Network traffic classification algorithms use two\nmain techniques: DPI packet content analysis and statistical feature classification [6], [7], [8], [9], [10], [11], [12], [13]. However, their effectiveness for encrypted traffic is concentrated mainly in recognizing TLS/SSL handshake parameters that help recognize the application content types (video, chat, etc. ) or the application name. They do not try to classify the video stream quality representation or provide any enrichment data on the video streams.\nThe YouTube video streaming solution is based on Adaptive Streaming Over HTTP (DASH) [14]. DASH is a Multi Bit Rate (MBR) streaming method, designed to improve viewers\u2019 Quality of Experience (QoE). In DASH, each video is divided into short segments, typically a few seconds long (2 \u2212 16 seconds), and each segment is encoded several times, each time with a different quality representation level. The user (player) adaptation logic algorithm is responsible for the automatic selection of the most suitable quality representation for each segment, based on the client\u2019s playout buffer and network conditions. As a result, the quality representation layer in DASH can change between segments. A content classification algorithm for encrypted video streaming should recognize each quality representation change. A video quality representation classification of encrypted video streams can help in many ways such as collecting users\u2019 viewing preferences, estimating the client playout buffer, tracking the users\u2019 Quality of Experience (QoE) / Quality of Service (QoS). These are the basic steps needed for designing video network traffic optimization algorithms. These algorithms are used by the ISP for controlling its network bandwidth.\nIn this paper we present a novel real-time video stream quality representation classification for DASH. We classify the video quality representation, and each feature (group of packets) is classified by itself without any dependencies\non past or future samples. Our scheme was tested on the Safari browser with Adobe flash as the player over HTTPS network traffic on offline and online YouTube video traffic streams. It recognizes, in real time, the YouTube video traffic quality representation layer with 97.18% average accuracy. Our method can also be used for estimating the client\u2019s playout buffer and as a basic step in traffic shaping.\nThe remainder of this paper is organized as follows. In Section II we discuss related work. YouTube analysis is presented in Section III. The problem formulation is introduced in Section IV. Section V presents our new algorithm. Section VI presents the performance evaluation. Finally, section VII discuss our conclusions and future work."}, {"heading": "II. RELATED WORK", "text": "Many recent works have suggested methods for encrypted traffic classification and several surveys have presented detailed description of the state of the art methods [6], [7], [8]. Several works have examined different statistical features such as session duration [15], [16], [17], number of packets in a session [16], [18], [19], different variance calculations of the minimum, maximum and average values of interarrival packet time [16], [18], payload size information [18], [20], bit rate [20], [21], Round-Trip Time (RTT) [21], packet direction [22] or server sent bit rate [23]. Not all these features are important for video streams classification. For instance, the packet size is often MTU size in video streaming, as video streaming consumes high bandwidth and re-transmission occurs often. Moreover, TCP parameters such as server sent bit rate, inter-arrival packet time, RTT and packet direction are weak features. Other classification methods have identified the application type and class (VOIP, Video, etc. ) [6], [7], [8], by exploiting encrypted VOIP streams interaction of Variable Bit Rate (VBR) codecs such as phonetic reconstruction [24] and language identification [25]. However, these methods need many trace samples for the training of their classification models.\nMalware traffic fingerprinting methods were suggested by Siboni et al. [26] and Shimoni et al. [27]. Both methods are based on the Lempel Ziv 78 (LZ78) universal compression algorithm [28] and on probability tree classifiers. First, a statistical feature based on time differences of all the training samples is created, quantized and transformed into a discrete sequence over small finite alphabet (a single code-book for all trees). In the next step, the sequence is used for building a LZ87 tree for each training sample with a probabilistic prediction model [26]. In the testing phase, a similar process is activated and tested with the training database trees. Malware fingerprinting is not designed for use in our case. Therefore, we modified the Shimoni et al. algorithm [27] to the streaming world. We used this modified algorithm as one of the methods against which our method is compared.\nIn this work, we use the client\u2019s received bit rate with TCP stack implementation to overcome re-transmissions. We show that using time-based features for video streaming leads to poor classification results. The objective of this work is to\ndevelop a real time classifier for the encrypted video traffic quality representation layer and web browsers, solutions that cannot classify every segment\u2019s quality representation by itself are not suitable. Rather, our proposed solution is a stream based classification method."}, {"heading": "III. YOUTUBE ANALYSIS", "text": "To better understand encrypted video streaming traffic properties, we examined YouTube traffic under different browsers. In Fig. 1 depicts the different traffic download patterns of a single video stream. In each download, we used the same video stream with a fixed quality representation of 720P over different browsers. The different traffic patterns are mainly caused by the browsers\u2019 player algorithms. However, the source video encoding process also affects pattern differences. It is noteworthy that at the time of our database creation, Explorer and Chrome had YouTube HTML5 players while Firefox and Safari had a Flash based player.\nFig. 1 shows that HTML5 players in the fixed quality representation mode and Adobe flash players have significantly different traffic patterns. The flash traces and HTML5 players in the automatic mode have high bursty traffic with a silence separation of around 3 seconds between peaks, whereas the HTML5 traffic has one high and short traffic burst. Chrome downloaded a video stream with a duration of 281 seconds in less than 30 seconds. As a result, different feature extraction methods are needed to identify the different players\u2019 requested streams.\nFig. 2(a) illustrates the YouTube automatic download mode with Safari. Each video download has several flows. In the Safari fixed quality representation, there is one main video flow and 3-5 parallel flows (including audio only flows). Some of the flows can be used for downloading the same quality representation in parallel to accelerate the download. By using the Fiddler [29] web debugging proxy we can view the different requests without the encryption. The small traffic peak periods are the audio while the video peaks take longer to download. This analysis leads to several insights concerning the factors that can hinder classification efforts:\n1) The audio data and the video data can be found in the same 5-tuple flow and in some cases we cannot distinguish between them. This can result in a classification error since the boundaries between the quality representations are very close (see Fig. 3), which illustrates the dataset confidence graph for each of the tested quality representations. In Fig. 3, the 360P , 480P and 720P have overlapping bandwidth ranges. This makes the classification effort harder. This can also be seen in the first flow (Fig. 2(a)) at 14 seconds where the audio download is very close to the video traffic before and after. As a result, we cannot distinguish between them in their network traffic representation. 2) Close video segments\u2019 responses can be found in the same flow. For example, in Fig. 2(a) in the first flow (11 \u2212 14 seconds) there are two downloaded segments\nthat have very small time differences between the responses in the encrypted traffic representation. Distinguishing between segments that were downloaded at 11\u2212 14 seconds is difficult. 3) The first segment in each flow has a high bit rate variance which in most cases is not unique to a specific quality representation. For this reason we chose not to use it in training and testing. 4) The last segment usually consist of data leftovers. Its behavior is different, hard to predict and its classification is less important since this is the end of the stream. Hence this segment was not used.\nAfter filtering the audio responses (Fig. 2(b)) it can be seen that up to the first 10 seconds the 360P quality representation was downloaded in parallel. Afterward, there was a new parallel download for the 720P quality representation. These qualities were observed in the Fiddler traces but other traces evidenced additional quality representation switching.\nYouTube in Chrome can be downloaded not only with HTTP2/SPDY and HTTPS but also with QUIC over UDP. Fig. 4(a)-Fig. 4(c) illustrates the download of the same video with the following quality representations: {360P, 480P, 720P} with QUIC. The download throughput in this case is similar but the download duration is longer because quality representation is higher. The QUIC auto mode behavior, plotted in Fig. 4(d) is similar to HTTP2 behavior.\nWe decided to focus on Safari, due to the fact that the fixed and auto mode have similar behavior. QUIC throughput characterization would be interesting for future work. After many experiments, we found that between the end of one traffic burst and the next there is a time window exceeding 3 seconds of silence. Thus henceforth we define bit rate as bit per peak (traffic burst)."}, {"heading": "IV. PROBLEM FORMULATION", "text": "A server stores a video which is segmented into fixed duration segments. Each segment is encoded into m representations (m can be different for different videos). The user can select to download a constant or adaptive representation download. In the adaptive mode, the client\u2019s video player application (via adaptation logic), based on his network condition estimate and playout buffer selects a suitable representation to download each segment.\nWe used data from static (constant) quality representations to learn a model that can classify segments of constant and adaptive video streams. We used a training set of encrypted video streams, where each was downloaded m times. Each download had different constant video quality representation. We used a fixed m = 3 for all videos. Every segment of the stream is encoded to a feature. The label of each segment is its constant quality representation index: y \u2208 {1 . . .m} (e.g. 1 for 360P , 2 for 480P and 3 for 720P ). In the next section we describe our encoding of a stream segment into a feature vector and how we learn a model that can classify stream segments."}, {"heading": "V. PROPOSED ALGORITHM", "text": "The proposed solution architecture is illustrated in Fig. 5. The first two modules only pass YouTube video streams to the next modules. Each segment of network traffic enters the system separately and is first passed into the Connection Matching filter. This filter is responsible for checking whether the incoming flow is new or ongoing. It does so based on a five-tuple representation: {protocol (TCP/UDP), src IP, dst IP, src port, dst port}. If the incoming flow is new, the DPI filter decides whether it is a YouTube flow. This is done based on the Service Name Indication (SNI) field in the Client Hello message. If the DPI module finds the following string: googlevideos.com (which identifies YouTube) in the SNI, the stream is passed to the Feature Creation module. Any ongoing or new traffic flow that is not recognized by the DPI as video streaming is transparently passed into the network without further analysis. Note that in this paper we assume that we know how to detect Safari browser traffic (in contrast to other browser traffic). This can be done by identifying the audio stream of Safari. This task is left for future work.\nThe Feature Creation module extracts statistical features in real time based on the arriving packets (see section V-A). The Feature Classification module classifies the quality representation (see section V-B).\nFinally, the QoE/QoS Estimator module predicts the client playout buffer and estimates re-buffering events. This information is needed for the shaping of the encrypted traffic. The QoE/QoS Estimator and shaping modules are left for future work."}, {"heading": "A. Feature Creation", "text": "DASH is streamed over a TCP transport protocol. Streaming applications have high bit rate consumption. Thus, feature\ncreation methods need to take TCP limitations such as retransmission caused by network problems into account. Retransmission adds additional data to the stream that can cause classification errors.\nIn section II, we discussed state-of-the-art network traffic feature creation methods such as packet length, inter-arrival packet time and RTT packet direction. However, as the payload size in video streaming is often maximum size, delays in the network are varied and re-transmissions cause false packet counts. Therefore, we suggest a single dimension bit rate feature based on a TCP stack re-transmission filter using the TCP ACK method.\nThe feature creation starts after we identify that this traffic flow is a YouTube video flow. Any packet that enters the algorithm is verified by TCP stack implementation to prevent re-transmission packets from affecting our feature accuracy. We found 3 to be a good traffic feature threshold. We ignored low bit rate traffic features that can represent audio traffic bursts."}, {"heading": "B. Feature Classification", "text": "The proposed classification solution is illustrated in Fig. 6. It has a training step and a testing step. In the training step, first, we constructed our dataset based on YouTube video streaming\ncaptures (PCAP trace files [30]). Each video was downloaded with the three following fixed qualities {360P, 480P, 720P}. In the second stage, we extracted statistical features from the entire labeled data-set. In our proposed solution the statistical feature is a bit rate throughput in a time period based on the user\u2019s TCP stack implementation which filters out unnecessary TCP re-transmissions that occurred regularly in the traffic. Our feature extraction method is customized to the browser generated content (Safari). In the third stage, the entire features set was clustered using k-means++ [31] (step (3) in Fig. 6). The end product of these steps is a single dimension codebook that represent the entire feature set.\nFor each quality, we iterated over all its traces and averaged every peak total bit rate. This yielded an average bit rate vector for each quality. From these vectors and using the codebook from the k-means stage we computed a representative string for each quality. In the classification stage we carried out the bit rate extraction for each segment and then assigned a symbol (the one with the shortest distance to the average) to it from the codebook. Finally we assigned a label by finding which center was the closest."}, {"heading": "VI. PERFORMANCE EVALUATION", "text": "In this section, we evaluate the proposed quality representation classification algorithm. First, we describe the dataset in VI-A. Then we analyze the accuracy with different numbers of k-means centers (step (3) in Fig. 6) in Section VI-B. In Section VI-C we evaluate the accuracy using different training dataset sizes. We analyze the accuracy on the different test sets in Section VI-D. We test the classifier\u2019s robustness to delays and packet losses in Section VI-E. We examine the user buffer estimate accuracy in Section VI-F. Finally, we compare our classification results to two different classifiers in Section VI-G, one of which is a na\u0131\u0308ve algorithm we developed and the other based on a malware anomaly detection algorithm [26], [27] which we modified to the streaming world."}, {"heading": "A. Dataset", "text": "The video titles used in this study are popular YouTube videos from different categories such as news, video action trailers and GoPro videos [30].\nIn this study we decided to focus on the Safari browser since the fixed quality download mode (Fig. 1(d)) and the adaptive quality selection mode (Fig. 1(c)) have similar characteristics. We show that for Safari, we can learn an accurate model for static or automatic quality modes simply by using a fixed training dataset. Future studies will add additional browsers.\nThe training dataset contained 120 video streams of 40 unique video titles each of which was separately downloaded with fixed quality from the following qualities: {360P, 480P, 720P}.\nWe have three testing datasets:\n1) test-fixed-train-titles: 120 video streams of 40 unique video titles (same titles as in the training phase) each of which was separately downloaded with a fixed quality from the following qualities: {360P, 480P, 720P}. 2) test-adaptive-train-titles: 5 video streams of 5 unique video titles (titles taken from the training phase titles) each of which was downloaded with an adaptive quality representation (auto mode). 3) test-adaptive-test-titles: 5 video streams of 5 unique video titles (new titles that were not in the training phase) each of which was downloaded with an adaptive quality representation (auto mode).\nAll the test video streams were different from the ones that were used in the training phase (because of network conditions).\nB. Accuracy Evaluation using Different Numbers of k-means Centers\nOur solution cluster the bit rates into k bins. We tested the classifier with our training dataset (see Fig. 7). We found that k = 14 achieved the highest classification accuracy and this is the k that we used in all the following experiments."}, {"heading": "C. Accuracy Evaluation using Different Training Dataset Sizes", "text": "In Fig. 8 we compare our recognition identification rate with different numbers of training video titles. The figure shows major gains in performance when the number of training video titles increases from 10 to 30. The gains are much smaller when training video titles number increases from 30 to 50 (by only 2.2%). The figure also shows that using the last peak in our solution decreases the identification rate. The last peak size varies (because it corresponds to the stream leftovers) and thus it decreases the identification rate."}, {"heading": "D. Accuracy Evaluation on the Different Test Sets", "text": "Fig. 9(a) shows that our classification errors in the fixed quality representation mode, are between close quality representations and were lower than 3%. Note that Fig. 9(b) is based on the Nearest Neighbor using Average Bit Rate Feature(na\u0131\u0308ve) which uses the average bit rate that was calculated from Fig. 3 for each quality.\nThe average classification accuracy was 2% better when we tested video titles from our training set (Fig. 9(c)) than when we tested video titles that were not in our training set (Fig. 9(d)).\nWe examined why the error of classifying 480P quality representation segments as 720P in adaptive streams was relatively higher than the other errors (see Figs. 9(c) and 9(d)). We found that when the quality representation switches from 360P to 480P there are high bit rate bursts. These bursts cause the erroneous classification of these segments as 720P . In this work, we only trained the classifier based on the fixed quality switch mode. In future work, we will consider quality representation switches in our training."}, {"heading": "E. Evaluation of Robustness to Delays and Packet Losses", "text": "Fig. 10(a) depicts our algorithm\u2019s robustness to network delays. There was a strong decrease in the classification accuracy up to 300 milliseconds delays. Afterward there was a moderate decrease. The video application QoE is very sensitive to network delays and delays of over 300 milliseconds are easily detected. The overall classification accuracy decreased after 1000 milliseconds by only 7%.\nFig. 10(b) plots our algorithm\u2019s robustness to packet losses. Packet losses of 3% decreased our classification accuracy by 20%. We found out that the traffic behavior during packet loss events was different from our normal testing model. After 10% packet losses (the video is practically halted) our classification accuracy decreased to 73%.\nFig 10(c) plots our algorithm\u2019s robustness to combinations of network delays and packet losses. 500ms delays plus 10% packet losses decreased our classification to 70%. However, in real life scenarios it would be impossible to watch this stream (very low QoE).\nTo conclude, our solution (like the other solutions) is somewhat sensitive to packet losses. Increasing its robustness is left as future work."}, {"heading": "F. User Buffer Estimate", "text": "Fig. 11 shows our buffer estimate compared to the real buffer measurement. The experiments were conducted using the entire dataset (fixed and auto modes). For simplicity, we present the total sum. The average estimate drift between the full video duration and our estimate was 0.276 seconds and the STD was 0.25. The average estimate drift per feature was 0.035 seconds with a STD of 0.047."}, {"heading": "G. Classifier Comparisons", "text": "Our proposed solution is the first classifier for encrypted adaptive video streaming over HTTPS. In this section, we describe and compare to two other new classification approaches: a na\u0131\u0308ve bit rate classifier and an algorithm based on a network traffic malware fingerprinting algorithm[27]. Since the malware fingerprinting is not designed for auto representation switching we used the fixed mode dataset in the tests. The na\u0131\u0308ve algorithm uses the average bit rate that was calculated from Fig. 3 for each quality. We used our entire fixed representation testing dataset and found the closest average quality bit rate for each feature. Fig. 9(b) illustrates the na\u0131\u0308ve approach and the proposed algorithm is presented in Figs. 9(a), 9(c), 9(d). Table I summarize this comparison. It shows that our proposed solution (based on bit rate) achieved the highest identification results whereas all the other algorithms using time differences obtained much lower identification results."}, {"heading": "VII. CONCLUSIONS", "text": "We propose a novel algorithm for YouTube HTTP adaptive video streaming quality representation classification. Our solution was tested on the Safari (Flash player) browser with offline and online network traffic over HTTPS. We achieved an average classification accuracy of 97.18% in the fixed mode and 97.14% in the automatic quality representation switching mode. The algorithm estimates the user buffer playout level after each segment download with an average error of 0.035 seconds. The proposed solution exhibited 8.95% better average classification results than a na\u0131\u0308ve classifier approach. In this work we used the one-dimensional bit rate feature. We showed that our solution is more vulnerable to packet losses than to network delays. Adding features to strengthen robustness to packet losses is one of our future goals.\nThe DASH encrypted traffic quality representation classification problem still faces many challenges. In this work, we presented YouTube with the Safari browser over HTTPS as\na use case. Classification of other browsers\u2019 streaming is one of our future goals. The Chrome and Safari auto modes have similar network traffic behavior but our experiments suggest that the Safari dataset is not similar enough (the same videos have different total bit rates) to achieve high accuracy results; thus new datasets for Chrome (fixed/auto) are needed. The use of state-of-the-art network transport protocols such as HTTP2/SPDY and QUIC that have multiplexed connections should be investigated. TOR traffic morphing may also be a challenge to statistical classification [32]. However, we cannot confirm that this is a problem since in our testing the videos failed to play smoothly even in 360P ."}], "references": [{"title": "Issues and future directions in traffic classification", "author": ["A. Dainotti", "A. Pescape", "KC. Claffy"], "venue": "Network, IEEE,", "citeRegEx": "6", "shortCiteRegEx": "6", "year": 2012}, {"title": "Reviewing traffic classification", "author": ["S. Valenti", "D. Rossi", "A. Dainotti", "A. Pescap\u00e8", "A. Finamore", "M. Mellia"], "venue": "In Data Traffic Monitoring and Analysis,", "citeRegEx": "7", "shortCiteRegEx": "7", "year": 2013}, {"title": "A survey on encrypted traffic classification", "author": ["Z. Cao", "G. Xiong", "Y. Zhao", "Z. Li", "L. Guo"], "venue": "In Applications and Techniques in Information Security,", "citeRegEx": "8", "shortCiteRegEx": "8", "year": 2014}, {"title": "Progressive download video rate traffic shaping using tcp window and deep packet inspection", "author": ["R. Dubin", "O. Hadar", "A. Noam", "R. Ohayon"], "venue": "In WORLDCOMP,", "citeRegEx": "9", "shortCiteRegEx": "9", "year": 2012}, {"title": "Identification over encrypted channels", "author": ["B. Niemczyk", "P.Rao"], "venue": "In BlackHat USA,", "citeRegEx": "10", "shortCiteRegEx": "10", "year": 2014}, {"title": "Classification research on ssl encrypted application. In Trustworthy Computing and Services, volume 320 of Communications in Computer and Information Science, pages 404\u2013411", "author": ["P. Fu", "L. Guo", "G. Xiong", "J. Meng"], "venue": null, "citeRegEx": "11", "shortCiteRegEx": "11", "year": 2013}, {"title": "An identification method based on ssl extension", "author": ["P. Fu", "G. Xiong", "Y. Zhao", "M. Song", "P. Zhang"], "venue": "In Symposium on Research in Attacks, Intrusions and Defenses,", "citeRegEx": "12", "shortCiteRegEx": "12", "year": 2013}, {"title": "Classifying service flows in the encrypted skype traffic", "author": ["M. Korczynski", "A. Duda"], "venue": "In IEEE International Conference on Communications (ICC),", "citeRegEx": "13", "shortCiteRegEx": "13", "year": 2012}, {"title": "Empirically derived analytic models of wide-area tcp connections", "author": ["Vern Paxson"], "venue": "IEEE/ACM Transactions on Networking (TON),", "citeRegEx": "15", "shortCiteRegEx": "15", "year": 1994}, {"title": "Unveiling skype encrypted tunnels using gp", "author": ["R. Alshammari", "AN. Zincir-Heywood"], "venue": "In IEEE Congress on Evolutionary Computation (CEC),", "citeRegEx": "16", "shortCiteRegEx": "16", "year": 2010}, {"title": "Self-learning ip traffic classification based on statistical flow characteristics", "author": ["S. Zander", "T. Nguyen", "G. Armitage"], "venue": "In Passive and Active Network Measurement,", "citeRegEx": "17", "shortCiteRegEx": "17", "year": 2005}, {"title": "Identification and analysis of skype peer-to-peer traffic", "author": ["D. Zhang", "C. Zheng", "H. Zhang", "H. Yu"], "venue": "In Fifth International Conference on Internet and Web Applications and Services (ICIW),", "citeRegEx": "18", "shortCiteRegEx": "18", "year": 2010}, {"title": "Practical anomaly detection based on classifying frequent traffic patterns", "author": ["I. Paredes-Oliva", "I. Castell-Uroz", "P. Barlet-Ros", "X. Dimitropoulos", "J. Sole-Pareta"], "venue": "In IEEE Conference on Computer Communications Workshops (INFOCOM WKSHPS),", "citeRegEx": "19", "shortCiteRegEx": "19", "year": 2012}, {"title": "Detailed analysis of skype traffic", "author": ["D. Bonfiglio", "M. Mellia", "M. Meo", "D. Rossi"], "venue": "Multimedia, IEEE Transactions on,", "citeRegEx": "20", "shortCiteRegEx": "20", "year": 2009}, {"title": "Quantifying skype user satisfaction", "author": ["KT. Chen", "CY. Huang", "P. Huang", "CL. Lei"], "venue": "In ACM SIGCOMM Computer Communication Review,", "citeRegEx": "21", "shortCiteRegEx": "21", "year": 2006}, {"title": "Statistical protocol identification with spid: Preliminary results", "author": ["E. Hjelmvik", "W. John"], "venue": "In Swedish National Computer Networking Workshop,", "citeRegEx": "22", "shortCiteRegEx": "22", "year": 2009}, {"title": "Realtime classification for encrypted traffic", "author": ["R. Bar-Yanai", "M. Langberg", "D. Peleg", "L. Roditty"], "venue": "In Experimental Algorithms,", "citeRegEx": "23", "shortCiteRegEx": "23", "year": 2010}, {"title": "Phonotactic reconstruction of encrypted voip conversations: Hookt on fon-iks", "author": ["AM. White", "AR. Matthews", "KZ. Snow", "F. Monrose"], "venue": "In IEEE Symposium on Security and Privacy (SP),", "citeRegEx": "24", "shortCiteRegEx": "24", "year": 2011}, {"title": "Language identification of encrypted voip traffic: Alejandra y roberto or alice and bob", "author": ["CV. Wright", "L. Ballard", "F. Monrose", "GM. Masson"], "venue": "In USENIX Security,", "citeRegEx": "25", "shortCiteRegEx": "25", "year": 2007}, {"title": "Botnet identification via universal anomaly detection", "author": ["S. Siboni", "A. Cohen"], "venue": "In IEEE Workshop on Information Forensics and Security (WIFS),", "citeRegEx": "26", "shortCiteRegEx": "26", "year": 2014}, {"title": "Malicious traffic detection using traffic fingerprint", "author": ["A. Shimoni", "S. Barhom"], "venue": null, "citeRegEx": "27", "shortCiteRegEx": "27", "year": 2014}, {"title": "Compression of individual sequences via variable-rate coding", "author": ["Avraham Lempel", "Jacob Ziv"], "venue": "IEEE Transmissions on Information Theory,", "citeRegEx": "28", "shortCiteRegEx": "28", "year": 1978}, {"title": "k-means++: The advantages of careful seeding", "author": ["D. Arthur", "S. Vassilvitskii"], "venue": "In Proceedings of the eighteenth annual ACM-SIAM symposium on Discrete algorithms,", "citeRegEx": "31", "shortCiteRegEx": "31", "year": 2007}, {"title": "Traffic morphing: An efficient defense against statistical traffic analysis", "author": ["CV. Wright", "SE. Coull", "F. Monrose"], "venue": "In NDSS,", "citeRegEx": "32", "shortCiteRegEx": "32", "year": 2009}], "referenceMentions": [{"referenceID": 0, "context": "Network traffic classification algorithms use two main techniques: DPI packet content analysis and statistical feature classification [6], [7], [8], [9], [10], [11], [12], [13].", "startOffset": 134, "endOffset": 137}, {"referenceID": 1, "context": "Network traffic classification algorithms use two main techniques: DPI packet content analysis and statistical feature classification [6], [7], [8], [9], [10], [11], [12], [13].", "startOffset": 139, "endOffset": 142}, {"referenceID": 2, "context": "Network traffic classification algorithms use two main techniques: DPI packet content analysis and statistical feature classification [6], [7], [8], [9], [10], [11], [12], [13].", "startOffset": 144, "endOffset": 147}, {"referenceID": 3, "context": "Network traffic classification algorithms use two main techniques: DPI packet content analysis and statistical feature classification [6], [7], [8], [9], [10], [11], [12], [13].", "startOffset": 149, "endOffset": 152}, {"referenceID": 4, "context": "Network traffic classification algorithms use two main techniques: DPI packet content analysis and statistical feature classification [6], [7], [8], [9], [10], [11], [12], [13].", "startOffset": 154, "endOffset": 158}, {"referenceID": 5, "context": "Network traffic classification algorithms use two main techniques: DPI packet content analysis and statistical feature classification [6], [7], [8], [9], [10], [11], [12], [13].", "startOffset": 160, "endOffset": 164}, {"referenceID": 6, "context": "Network traffic classification algorithms use two main techniques: DPI packet content analysis and statistical feature classification [6], [7], [8], [9], [10], [11], [12], [13].", "startOffset": 166, "endOffset": 170}, {"referenceID": 7, "context": "Network traffic classification algorithms use two main techniques: DPI packet content analysis and statistical feature classification [6], [7], [8], [9], [10], [11], [12], [13].", "startOffset": 172, "endOffset": 176}, {"referenceID": 0, "context": "Many recent works have suggested methods for encrypted traffic classification and several surveys have presented detailed description of the state of the art methods [6], [7], [8].", "startOffset": 166, "endOffset": 169}, {"referenceID": 1, "context": "Many recent works have suggested methods for encrypted traffic classification and several surveys have presented detailed description of the state of the art methods [6], [7], [8].", "startOffset": 171, "endOffset": 174}, {"referenceID": 2, "context": "Many recent works have suggested methods for encrypted traffic classification and several surveys have presented detailed description of the state of the art methods [6], [7], [8].", "startOffset": 176, "endOffset": 179}, {"referenceID": 8, "context": "Several works have examined different statistical features such as session duration [15], [16], [17], number of packets in a session [16], [18], [19], different variance calculations of the minimum, maximum and average values of interarrival packet time [16], [18], payload size information [18], [20], bit rate [20], [21], Round-Trip Time (RTT) [21], packet direction [22] or server sent bit rate [23].", "startOffset": 84, "endOffset": 88}, {"referenceID": 9, "context": "Several works have examined different statistical features such as session duration [15], [16], [17], number of packets in a session [16], [18], [19], different variance calculations of the minimum, maximum and average values of interarrival packet time [16], [18], payload size information [18], [20], bit rate [20], [21], Round-Trip Time (RTT) [21], packet direction [22] or server sent bit rate [23].", "startOffset": 90, "endOffset": 94}, {"referenceID": 10, "context": "Several works have examined different statistical features such as session duration [15], [16], [17], number of packets in a session [16], [18], [19], different variance calculations of the minimum, maximum and average values of interarrival packet time [16], [18], payload size information [18], [20], bit rate [20], [21], Round-Trip Time (RTT) [21], packet direction [22] or server sent bit rate [23].", "startOffset": 96, "endOffset": 100}, {"referenceID": 9, "context": "Several works have examined different statistical features such as session duration [15], [16], [17], number of packets in a session [16], [18], [19], different variance calculations of the minimum, maximum and average values of interarrival packet time [16], [18], payload size information [18], [20], bit rate [20], [21], Round-Trip Time (RTT) [21], packet direction [22] or server sent bit rate [23].", "startOffset": 133, "endOffset": 137}, {"referenceID": 11, "context": "Several works have examined different statistical features such as session duration [15], [16], [17], number of packets in a session [16], [18], [19], different variance calculations of the minimum, maximum and average values of interarrival packet time [16], [18], payload size information [18], [20], bit rate [20], [21], Round-Trip Time (RTT) [21], packet direction [22] or server sent bit rate [23].", "startOffset": 139, "endOffset": 143}, {"referenceID": 12, "context": "Several works have examined different statistical features such as session duration [15], [16], [17], number of packets in a session [16], [18], [19], different variance calculations of the minimum, maximum and average values of interarrival packet time [16], [18], payload size information [18], [20], bit rate [20], [21], Round-Trip Time (RTT) [21], packet direction [22] or server sent bit rate [23].", "startOffset": 145, "endOffset": 149}, {"referenceID": 9, "context": "Several works have examined different statistical features such as session duration [15], [16], [17], number of packets in a session [16], [18], [19], different variance calculations of the minimum, maximum and average values of interarrival packet time [16], [18], payload size information [18], [20], bit rate [20], [21], Round-Trip Time (RTT) [21], packet direction [22] or server sent bit rate [23].", "startOffset": 254, "endOffset": 258}, {"referenceID": 11, "context": "Several works have examined different statistical features such as session duration [15], [16], [17], number of packets in a session [16], [18], [19], different variance calculations of the minimum, maximum and average values of interarrival packet time [16], [18], payload size information [18], [20], bit rate [20], [21], Round-Trip Time (RTT) [21], packet direction [22] or server sent bit rate [23].", "startOffset": 260, "endOffset": 264}, {"referenceID": 11, "context": "Several works have examined different statistical features such as session duration [15], [16], [17], number of packets in a session [16], [18], [19], different variance calculations of the minimum, maximum and average values of interarrival packet time [16], [18], payload size information [18], [20], bit rate [20], [21], Round-Trip Time (RTT) [21], packet direction [22] or server sent bit rate [23].", "startOffset": 291, "endOffset": 295}, {"referenceID": 13, "context": "Several works have examined different statistical features such as session duration [15], [16], [17], number of packets in a session [16], [18], [19], different variance calculations of the minimum, maximum and average values of interarrival packet time [16], [18], payload size information [18], [20], bit rate [20], [21], Round-Trip Time (RTT) [21], packet direction [22] or server sent bit rate [23].", "startOffset": 297, "endOffset": 301}, {"referenceID": 13, "context": "Several works have examined different statistical features such as session duration [15], [16], [17], number of packets in a session [16], [18], [19], different variance calculations of the minimum, maximum and average values of interarrival packet time [16], [18], payload size information [18], [20], bit rate [20], [21], Round-Trip Time (RTT) [21], packet direction [22] or server sent bit rate [23].", "startOffset": 312, "endOffset": 316}, {"referenceID": 14, "context": "Several works have examined different statistical features such as session duration [15], [16], [17], number of packets in a session [16], [18], [19], different variance calculations of the minimum, maximum and average values of interarrival packet time [16], [18], payload size information [18], [20], bit rate [20], [21], Round-Trip Time (RTT) [21], packet direction [22] or server sent bit rate [23].", "startOffset": 318, "endOffset": 322}, {"referenceID": 14, "context": "Several works have examined different statistical features such as session duration [15], [16], [17], number of packets in a session [16], [18], [19], different variance calculations of the minimum, maximum and average values of interarrival packet time [16], [18], payload size information [18], [20], bit rate [20], [21], Round-Trip Time (RTT) [21], packet direction [22] or server sent bit rate [23].", "startOffset": 346, "endOffset": 350}, {"referenceID": 15, "context": "Several works have examined different statistical features such as session duration [15], [16], [17], number of packets in a session [16], [18], [19], different variance calculations of the minimum, maximum and average values of interarrival packet time [16], [18], payload size information [18], [20], bit rate [20], [21], Round-Trip Time (RTT) [21], packet direction [22] or server sent bit rate [23].", "startOffset": 369, "endOffset": 373}, {"referenceID": 16, "context": "Several works have examined different statistical features such as session duration [15], [16], [17], number of packets in a session [16], [18], [19], different variance calculations of the minimum, maximum and average values of interarrival packet time [16], [18], payload size information [18], [20], bit rate [20], [21], Round-Trip Time (RTT) [21], packet direction [22] or server sent bit rate [23].", "startOffset": 398, "endOffset": 402}, {"referenceID": 0, "context": ") [6], [7], [8], by exploiting encrypted VOIP streams interaction of Variable Bit Rate (VBR) codecs such as phonetic reconstruction [24] and language identification [25].", "startOffset": 2, "endOffset": 5}, {"referenceID": 1, "context": ") [6], [7], [8], by exploiting encrypted VOIP streams interaction of Variable Bit Rate (VBR) codecs such as phonetic reconstruction [24] and language identification [25].", "startOffset": 7, "endOffset": 10}, {"referenceID": 2, "context": ") [6], [7], [8], by exploiting encrypted VOIP streams interaction of Variable Bit Rate (VBR) codecs such as phonetic reconstruction [24] and language identification [25].", "startOffset": 12, "endOffset": 15}, {"referenceID": 17, "context": ") [6], [7], [8], by exploiting encrypted VOIP streams interaction of Variable Bit Rate (VBR) codecs such as phonetic reconstruction [24] and language identification [25].", "startOffset": 132, "endOffset": 136}, {"referenceID": 18, "context": ") [6], [7], [8], by exploiting encrypted VOIP streams interaction of Variable Bit Rate (VBR) codecs such as phonetic reconstruction [24] and language identification [25].", "startOffset": 165, "endOffset": 169}, {"referenceID": 19, "context": "[26] and Shimoni et al.", "startOffset": 0, "endOffset": 4}, {"referenceID": 20, "context": "[27].", "startOffset": 0, "endOffset": 4}, {"referenceID": 21, "context": "Both methods are based on the Lempel Ziv 78 (LZ78) universal compression algorithm [28] and on probability tree classifiers.", "startOffset": 83, "endOffset": 87}, {"referenceID": 19, "context": "In the next step, the sequence is used for building a LZ87 tree for each training sample with a probabilistic prediction model [26].", "startOffset": 127, "endOffset": 131}, {"referenceID": 20, "context": "algorithm [27] to the streaming world.", "startOffset": 10, "endOffset": 14}, {"referenceID": 22, "context": "In the third stage, the entire features set was clustered using k-means++ [31] (step (3) in Fig.", "startOffset": 74, "endOffset": 78}, {"referenceID": 19, "context": "Finally, we compare our classification results to two different classifiers in Section VI-G, one of which is a na\u0131\u0308ve algorithm we developed and the other based on a malware anomaly detection algorithm [26], [27] which we modified to the streaming world.", "startOffset": 202, "endOffset": 206}, {"referenceID": 20, "context": "Finally, we compare our classification results to two different classifiers in Section VI-G, one of which is a na\u0131\u0308ve algorithm we developed and the other based on a malware anomaly detection algorithm [26], [27] which we modified to the streaming world.", "startOffset": 208, "endOffset": 212}, {"referenceID": 20, "context": "In this section, we describe and compare to two other new classification approaches: a na\u0131\u0308ve bit rate classifier and an algorithm based on a network traffic malware fingerprinting algorithm[27].", "startOffset": 190, "endOffset": 194}, {"referenceID": 20, "context": "[27] 38.", "startOffset": 0, "endOffset": 4}, {"referenceID": 20, "context": "[27] 81.", "startOffset": 0, "endOffset": 4}, {"referenceID": 23, "context": "TOR traffic morphing may also be a challenge to statistical classification [32].", "startOffset": 75, "endOffset": 79}], "year": 2017, "abstractText": "The increasing popularity of HTTP adaptive video streaming services has dramatically increased bandwidth requirements on operator networks, which attempt to shape their traffic through Deep Packet Inspection (DPI). However, Google and certain content providers have started to encrypt their video services. As a result, operators often encounter difficulties in shaping their encrypted video traffic via DPI. This highlights the need for new traffic classification methods for encrypted HTTP adaptive video streaming to enable smart traffic shaping. These new methods will have to effectively estimate the quality representation layer and playout buffer. We present a new method and show for the first time that video quality representation classification for (YouTube) encrypted HTTP adaptive streaming is possible. We analyze the performance of this classification method with Safari over HTTPS. Based on a large number of offline and online traffic classification experiments, we demonstrate that it can independently classify, in real time, every video segment into one of the quality representation layers with 97.18% average accuracy.", "creator": "LaTeX with hyperref package"}}}