{"id": "1603.08028", "review": {"conference": "arxiv", "VERSION": "v1", "DATE_OF_SUBMISSION": "25-Mar-2016", "title": "On the Simultaneous Preservation of Privacy and Community Structure in Anonymized Networks", "abstract": "we consider objective ethics of performing community nets covering a territory, while maintaining bounds, assuming independently the resource has access to an auxiliary computing network. we investigate the objective \" normal statistics exist correlation regime where linear network cannot evaluate represented perfectly, yet the community defenses wil be learned?. \" humans answer this case, we derive information neural converses confronting the simultaneous deanonymization problem. integrated stochastic method technique and edge sub - sampling. psychologists do evaluate an almost certain achievability result for causal deanonymization.", "histories": [["v1", "Fri, 25 Mar 2016 20:45:32 GMT  (555kb,D)", "http://arxiv.org/abs/1603.08028v1", "10 pages"]], "COMMENTS": "10 pages", "reviews": [], "SUBJECTS": "cs.LG cs.CR cs.SI", "authors": ["daniel cullina", "kushagra singhal", "negar kiyavash", "prateek mittal"], "accepted": false, "id": "1603.08028"}, "pdf": {"name": "1603.08028.pdf", "metadata": {"source": "CRF", "title": "On the Simultaneous Preservation of Privacy and Community Structure in Anonymized Networks", "authors": ["Daniel Cullina", "Kushagra Singhal", "Negar Kiyavash", "Prateek Mittal"], "emails": ["cullina@illinois.edu", "ksingha2@illinois.edu", "kiyavash@illinois.edu", "pmittal@princeton.edu", "permissions@acm.org."], "sections": [{"heading": null, "text": "We also evaluate the performance of percolation based deanonymization algorithm on Stochastic Block Model datasets that satisfy the conditions of our converse. Although our converse applies to exact deanonymization, the algorithm fails drastically when the conditions of the converse are met. Additionally, we study the effect of edge sub-sampling on the community structure of a real world dataset. Results show that the dataset falls under the purview of the idea of this paper. There results suggest that it may be possible to prove stronger partial deanonymizability converses, which would enable better privacy guarantees."}, {"heading": "1. INTRODUCTION", "text": "Data analytics is a rapidly growing field, aided by the availability of huge amounts of data and significant computing power. An enormous part of data generation is a result of the emergence of Online Social Networks (OSNs) such as Facebook, LinkedIn, Twitter etc. The user base of these networks spans in millions and is still growing. These com-\nPermission to make digital or hard copies of all or part of this work for personal or classroom use is granted without fee provided that copies are not made or distributed for profit or commercial advantage and that copies bear this notice and the full citation on the first page. Copyrights for components of this work owned by others than ACM must be honored. Abstracting with credit is permitted. To copy otherwise, or republish, to post on servers or to redistribute to lists, requires prior specific permission and/or a fee. Request permissions from permissions@acm.org. KDD \u201916 August 13\u201317, 2016, San Francisco, CA, USA c\u00a9 2016 ACM. ISBN 978-1-4503-2138-9. . . $15.00\nDOI: 10.1145/1235\npanies and others perform data analytics for the purpose of increasing revenues, reducing customer service costs, better prediction and possibly prevention of attrition rates, getting feedback on and improving public opinion of their products/services. For instance, LinkedIn has been very successful in converting the data collected on their website into new data products, such as their People You May Know feature. Network providers also create revenue by sharing data with other third parties who create value by performing analytics on the data. For example, due to homophily [21], OSNs are good microcosms to study efficient advertising strategies. With the prevalence of data analytics, concerns about user privacy are growing too and such concerns could hamper the former if not addressed adequately.\nPreprocessing the data prior to its release, with the goal of minimizing the risk of sharing private information of the users, is crucial for addressing privacy concerns. Anonymization is an essential step in the data preprocessing. Perhaps, still the most widely used technique is the naive practice of substituting the personal identifiers (e.g., name, IP address, etc) by random identifiers. More clever techniques such as k-anonymization [12, 19] and differential privacy [8, 17] are also proposed to address the problem in suitable scenarios.\nAs fundamentally any anonymization technique involves modification of the data at some level, it could possibly deteriorate the utility of the data for the initial analytics tasks it was released for. This trade-off between privacy and data utility has been noted in the literature [3, 18], but a theoretical understanding of this trade-off is still missing. Contributions. We investigate the feasibility of performing data analytics, without compromising privacy of the users involved, in the following specific setting. Let G2 denote a graph whose vertices are the identities of the users (e.g. names, email id, etc.) and its edges encode relationships (e.g. friendship, citations, professional relation etc.) among those users. Furthermore, assume that the vertices of G2 are associated with some sensitive information (e.g. sexual orientation, personal preferences, hometown, relationship status, location history, etc.). A third party is interested in studying the relationship between the sensitive tags and the structural properties of G2. To preserve the privacy ar X\niv :1\n60 3.\n08 02\n8v 1\n[ cs\n.L G\n] 2\n5 M\nof the users, a sanitized version of G2 would be released. Assume another graph G1, correlated with G2 and defined on the same vertex set, is available to the third party as auxiliary information. In G1, vertices are labeled with user identities, but no sensitive vertex tags are present. Given the availability of the public graph G1, we ask the question: Can we safely release a sanitized graph without compromising the privacy of the people involved? The challenge lies in the requirement that the sanitized version of G2 should allow for reliably performing analytics, but not allow the third party (referred to as the attacker) to learn the identity of the users (i.e., vertex labels) despite the availability of G1. In the rest of the paper, we limit our attention to a specific problem, the so-called community reconstruction. We selected this as a proxy for a much broader class of grass-analysis questions because it has structural features in common with many other problems and recent research work has established a detailed understanding of its properties.\nOur main contributions are as follows. We derive information theoretic converses for the anonymous exact community recovery problem for a large class of random graphs. That is, we provide a threshold in terms of the problem parameters, which if met, guarantees that no algorithm can deanonymize the graph. More specifically:\n\u2022 We derive a nearly sharp threshold for exact deanonymization problem for the class of SBM graphs.\n\u2022 We characterize partial deanonymity of the system (i.e. the growth rate of number of vertices that cannot be deanonymized) as a function of the correlation between the auxiliary graph G1 and the sensitive graph G2 and the sparsity of these two graphs.\n\u2022 We establish that there is a nonempty parameter space such that G2 cannot be fully deanonymized but exact community recovery is feasible.\n\u2022 We investigate methods of modifying G2 to strengthen its anonymity while preserving community structure.\n\u2022 We study the behavior of the threshold identified by our converse as a function of growth rate of communities with regards to the size of the vertices, n.\nTo the best of our knowledge, this is the first paper to offer a converse: a statement that under certain conditions, any deanonymization algorithm must fail. The previous work on the subject only provides achievability results for the problem, which describe sufficient conditions on the model parameters under which deanonymization is possible. This is done by proving success of specific algorithms in deanonymizing the graph for a range of problem parameters or by providing simulation results on specific datasets [23, 25, 26, 14, 13]. Instead, we seek converses that guarantee no algorithm is able to deanonymize the sanitized graph. As first steps to solving the problem, we study the converse such that no algorithm is able to deanonymize the network perfectly.\nThe rest of the paper is organized as follows. In Section 2, we describe the Stochastic Block Model used in this paper and discuss the community reconstruction problem. We discuss some of the relevant literature in Section 3. The system model describing the generation of correlated graphs and deanonymization attack is discussed in Section 4. Necessary conditions for the anonymity in the Stochastic Block Model are derived in Section 5. In Section 6, we describe the existence of anonymized community recovery region and\ndiscuss approaches to boost the anonymity in networks. We consider the case of growing number of communities in Section 7. We evaluate and relate the performance of a particular deanonymization algorithm to our results in Section 8. We conclude the paper with some remarks in Section 9."}, {"heading": "2. THE STOCHASTIC BLOCK MODEL", "text": "Communities are an integral part of any social network. The community structure also plays an important role in many data analytics\u2019 applications. In Section 3.2, we shed light on some applications of community reconstruction to emphasize its importance. In recent years, community detection/reconstruction problems have been extensively studied for the Stochastic Block Model (SBM) [5, 7, 20, 11, 1]. SBM is a simple generalization of the Erdo\u0308s Re\u0301nyi model that incorporates community structure.\nThe SBM is defined as follows. Suppose that n vertices are partitioned into C disjoint subsets, called communities. A symmetric C\u00d7C matrix, P , specifies edge probabilities: for two vertices u and v in communities i = C(i) and j = C(j), u and v are adjacent with probability Pij . The presence of distinct edges is independent. A special case of SBM is the planted partition model in which the entries of the probability matrix P are a constant p on the diagonal and a constant q off the diagonal. Specifically, Pij = p if the nodes i and j are in the same community, else Pij = q. It is assumed that p > q as nodes in a community are relatively densely connected. Such a network is denoted by SBM(n, p, q).\nThere has been a series of results for the exact community recovery in the planted partition model. These studies assume a sparse regime where p = a logn\nn and q = b logn n , where\na, b > 0 are some fixed constants.1 The case of two communities, C = 2, was studied in [1] in which Abbe et al. analyze the information-theoretic bounds for exact recovery and establish a phase transition phenomenon for the problem. Additionally, they propose a Semidefinite Programming (SDP) based algorithm for exact recovery of communities. Hajek et al. subsequently prove that the SDP algorithm is optimal, that is, it recovers the exact communities whenever it is theoretically possible to do so [10]. Hajek et al. further extended Abbe et al.\u2019s results to an arbitrary fixed C. As this particular result is relevant to our derivations, we state it in Section 6 (See Theorem 3). Remarks. The definition of a community varies with applications and algorithms [9, 4]. Also the varying definitions result in the theoretical analysis becoming intractable. Although the SBM may not capture the community structure in the real world networks perfectly, it lands itself to tractable analysis. Apart from simplicity, it also captures one of the most important elements of communities, assortativity. Hence, we focus on the SBM which has a clear definition of a community and the ground truth is available while evaluating an algorithm. Moreover, our results can be generalized to unequal sized communities which is more practical, but this scenario makes the analysis more involved without providing any new insights into the problem."}, {"heading": "3. RELATED WORK", "text": "In this section, we discuss some of the important deanonymization attacks followed by some applications of commu-\n1Learning the community structure is harder for the sparse regime. Thus, it constitutes the more interesting case.\nnity detection in networks. Due to space limitation we only discuss the most relevant literature."}, {"heading": "3.1 Network De-anonymization", "text": "In [26], Pedarsani and Grossglauser studied the deanonymization problem for two correlated Erdo\u0308s Re\u0301nyi random graphs. They assume that both the anonymized and auxiliary graphs are sampled from a common underlying Erdo\u0308s Re\u0301nyi random graph which results in structural correlation between the two graphs. They derive sufficient conditions on the model parameters under which the two graphs can be matched exactly. Specifically, they prove that the average degree only needs to grow slightly faster than the logarithm of order of the network to achieve perfect deanonymization. A similar problem was considered by Ji et al. in [14]. To generate the correlated graphs, the sampling process as in [26] was used, but the underlying graph is drawn from the configuration model [24]. They derive sufficient conditions on the model parameters for the perfect as well as partial deanonymization of networks.\nJi et al. studied the role seed nodes play in assisting the exact and partial deanonymization process [13]. They derived achievability thresholds for for Erdo\u0308s Re\u0301nyi random graphs as well as graphs from arbitrary distribution models. They also evaluated their results on 24 real world social networks and showed varying degree of vulnerability among the networks to the deanonymization attacks.\nYartseva et al. studied the performance of a specific algorithm, the so called percolation graph matching algorithm, for deanonymizing Erdo\u0308s Re\u0301nyi random graphs [28]. Starting with some seed nodes, the algorithm incrementally maps remaining pair of nodes using a thresholding criterion. They prove sufficient conditions on model parameters which enable this algorithm to match the networks almost perfectly. A phase transition in the initial seed set size is established.\nNarayanan and Shmatikov proposed a two-stage algorithm to deanonymize a network again when the adversary has access to an auxiliary network whose user base overlaps partially with that of the anonymized network [23]. After the seed identification in the first phase, the algorithm propagates this information and identifies further nodes in the second phase. They show that the users who have accounts on both Twitter (anonymized) and Flickr (auxiliary) can be deanonymized with only a 12% error rate. Nilizadeh et al. enhance the performance of the algorithm in [23] using the community structure of the network [25]. Their attack proceeds as follows. First, communities are detected and mapped in both the anonymized and auxiliary graphs. Subsequently, more seeds are identified within the communities and deanonymization is performed for each pair of communities using already existing algorithm of [23]. This algorithm is again run on the whole graph in case some nodes are not mapped in the previous steps. The authors show empirically that this algorithm helps in boosting the deanonymization process on a specific graph derived from Twitter. The results in [23, 25] are great examples of why deanonymization poses a real threat to users, but they do not provide fundamental limits or even insights into when the deanonymization problem is hard or easy."}, {"heading": "3.2 Community Detection Applications", "text": "3.2.1 Privacy Control [15]\nInformation sharing in an OSN, like photos, statuses, emotions and location, is a common practice for individuals using the network. An individual\u2019s social contacts may fall into various categories like family, friends, colleagues and even finer subgroups. However, users may want to share their information among a particular group of contacts only. Hence, it becomes important that users are able to selectively share their information over such networks.\nRecently, community reconstruction has been suggested as a tool to solve this problem. Community is a group of tightly connected users where the tightness may be measured by various metrics for different types of groups. For example, a close friendship community is characterized by frequent message sharing. These metrics may be exploited to automatically detect and label communities which enable users to selectively share their information.\n3.2.2 Sampling in OSNs [29] The popularity of OSNs has grown beyond imagination in\nthe last few years and the size of these networks has grown into millions of users. The data generated by these networks is tremendous and very useful for research and other purposes. As the networks become large, it becomes difficult to analyze the properties of an entire network.\nThe sampled graphs should be representative of the original graph is terms of both the local and global properties like degree distributions, node-edge ratio etc. Community reconstruction plays a crucial role to create such representative samples of the original graph. In a typical application, the hierarchical community structure of anetwork is reconstructed. Sampling is done based on the observed communities, ensuring that local properties are preserved in the sampled version. Then, in a bottom-up fashion, these sampled subgraphs are linked together to form a bigger graph.\n3.2.3 Viral Meme Prediction [27] A meme is \u201can idea, or style that spreads from person to\nperson within a culture \u201d. They are similar to infectious diseases within a network. Out of many memes generated each day only a few of them go viral within a network. This viral behavior is of value to advertising and marketing businesses.\nThere are many factors which contribute to the popularity of memes such as timing, point of beginning and others. Recently, the underlying network structure, specifically community structure, has also been identified as an important feature. Community structure exhibits two important phenomena: social reinforcement and homophily. These features expose community members to a meme more often. This results in higher rates of adoption for a meme. Hence a meme may become more popular within a community with strong social reinforcement and homophily. The features like number of initially infected communities, distribution of infected users across communities, and intra community interaction strength are used to predict the viral memes."}, {"heading": "4. SYSTEM MODEL", "text": "In this section, we discuss the system model, followed by the description of the deanonymization attack and derivation of the Maximum a Posteriori estimator. First, we discuss a few preliminaries.\n4.1 Preliminaries\nFor a graph G, let V (G) and E(G) be the node and edge sets respectively. Let [n] denote the set {1, \u00b7 \u00b7 \u00b7 , n}. All of the n-vertex graphs that we consider will have vertex set [n]. These numerical vertex labels should not be confused with the vertex labels (or alternatively tags) coming from the problem domain. Examples of these tags include names and private information. To anonymize the graph G2, we need to remove the relationship between the numerical vertex labels and the user identities. To do this, we will apply a uniform random permutation to the numerical vertex labels. We will always think of a permutation as a function defined from [n]\u2192 [n]. We denote the collection of all two element subsets of [n] by ( [n] 2 ) . The edge set of a graph G is E(G) \u2286(\n[n] 2\n) . The community label of a node i \u2208 V (G) is denoted\nby C(i) \u2208 [C], where C is the number of communities."}, {"heading": "4.2 Generative Model for Correlated Graphs", "text": "Recall the description of the problem in Section 1. There are two n-vertex graphs, G1 and G2. An attacker has access to a pair of correlated graphs G1 and \u03c0(G2), both graphs defined on the same vertex set, denoting the identities of the users. Here \u03c0 is a uniformly random permuation of [n]. The vertices of the auxiliary graph G1, available to the attacker, are tagged with user identities but not any sensitive information. The vertices of the sensitive graph G2, not available to the attacker, are tagged with sensitive information. The anonymized graph \u03c0(G2) is available to the attacker, but the numerical vertex labels contain no information about user identities because \u03c0 is a uniformly random permutation. Vertex i in G1 and vertex i in G2 correspond to the same user, so given G1, the numerical vertex labels in G2 reveal the user identities.\nTo generate two correlated graphs, G1 and G2, the following mechanism is used. This is essentially the same model which was previously used in [26, 14, 13]. The two correlated graphs are assumed to be sampled from a random underlying graph G on the same set of vertices. Specifically, G is distributed as SBM(n, p, q) with C equally sized communities. Each edge {i, j} \u2208 E(G) is included in G1 independently with probability s1. The graph G2 is created similarly using sampling probability s2 and these choices are independent of all choices made to create G1. As a result, G1 is SBM(n, ps1, qs1), G2 is SBM(n, ps2, qs2), and E(G1) and E(G2) are correlated but in general not equal."}, {"heading": "4.3 Attack Model", "text": "Recall that, G1 is the auxiliary graph and G2 the sensitive graph. An adversary aims to deanonymize \u03c0(G2) using G1. A deanonymization attack can be described as a mapping from the nodes of G1 to the nodes of \u03c0(G2), i.e. a map \u03c0\u0302 : [n] \u2192 [n]. A successful deanonymization attack is the true mapping \u03c0\u0302 = \u03c0. In that case, we say that the network G2 is deanonymized exactly.\nWhen true community labels exist in the graphs, we assume that the adversary knows the true labels of all vertices in both graphs. 2 We say that a permutation preserves the community structure if it maps vertices only to other\n2As we are interested in converses, considering a stronger adversary does not pose a problem. In fact, given the anonymized graph \u03c0(G2), the adversary must be able to perform community detection with high probability (perform the intended data analytics) .\nvertices with the same community label. That is, a permutation \u03c0 is community preserving if \u2200 i \u2208 [n], C(\u03c0(i)) = C(i). Because the adversary can recover the community labels in both graphs, or equivalently can compute both C(i) and C(\u03c0(i)), they can learn some information about the permutation \u03c0. The adversary can group the vertices of \u03c0(G2) by community, producing another graph \u03c0\u2032(G2) such that \u03c0\u2032 preserves communities. In other words, anonymizing G2 using a uniformly random \u03c0 does not create additional uncertainty for the adversary beyond what would be created by a permutation that preserves the community structure. So our analysis considers only the latter type of permutation.\nAn adversary is presented with a statistical estimation problem. By definition, the Maximum a Posteriori (MAP) estimator minimizes the adversary\u2019s probability of error. So, if the MAP estimator does not recover the true permutation with high probability, then no other estimator can succeed. We also assume that all the permutations used to anonymize G2 are equiprobable. Hence, the MAP estimator is same as the Maximum Likelihood estimator.\nIf we fix any randomized estimation procedure, then the adversaries estimate \u03c0\u0302 become a random variable. It will be more convenient to let \u03a6 = \u03c0\u0302 \u25e6 \u03c0\u22121 and work with the random permutation \u03a6 rather than \u03c0\u0302 directly. In a successful attack, \u03a6 = I, the identity permutation. The reason that \u03a6 is more convenient is that \u03a6 is independent of \u03c0. For fixed G1 and G2, any change in \u03c0 results in a corresponding change in \u03c0\u0302 and this does not change \u03a6.\nThe MAP estimator for this problem can be derived as follows. We need to compute the likelihood of the posterior probability of a mapping \u03a6, given the observed graphs G1 and \u03c0(G2), that is, P [\u03a6 = \u03c6|G1, \u03c0(G2)]. Note that a particular mapping \u03c6 : [n] \u2192 [n] induces a mapping \u03c3\u03c6 : ( [n] 2 ) \u2192 ( [n] 2 ) on the node pairs. Define\nS\u03c6 = (E(G1) \u222a \u03c3\u03c6(E(G2))) \\ (E(G1) \u2229 \u03c3\u03c6(E(G2))), (1)\nwhich is the symmetric edge difference of the two edge sets. Also for any graph with community labels, define the following two sets,\nEin\u03c6 ={(i, j) \u2208 S\u03c6 : C(i) = C(j)} (2) Eout\u03c6 ={(i, j) \u2208 S\u03c6 : C(i) 6= C(j)}, (3)\nthe symmetric edge difference sets corresponding to the intra and inter community edges respectively.\nFor SBM graphs defined in Section 2, an easy computation shows that the posterior probability P [\u03a6 = \u03c6|G1, \u03c0(G2)] is proportional to c |Ein\u03c6 | 1 c |Eout\u03c6 | 2 , where\nc1 = p(1\u2212 s1)(1\u2212 s2)\n1\u2212 p+ p(1\u2212 s1)(1\u2212 s2)\nc2 = q(1\u2212 s1)(1\u2212 s2)\n1\u2212 q + q(1\u2212 s1)(1\u2212 s2)\nNote that c1, c2 \u2264 1. Then the MAP estimator is given by\narg min \u03c6 log\n( 1\nc1\n) |Ein\u03c6 |+ log ( 1\nc2\n) |Eout\u03c6 |,\nthe mapping which minimizes a linear combination of |Ein| and |Eout| weighted by fixed positive coefficients.\nResults in the next section find conditions under which the MAP estimator fails with high probability."}, {"heading": "5. CONDITIONS FOR ANONYMITY", "text": "We analyze the anonymity of the graph \u03c0(G2) with the SBM community structure for the attack model described in Section 4.3. Recall that the attacker has access to a correlated graph G1 with known vertex labels. In this section we consider the problem for arbitrary fixed number of communities C. We generalize the result in Section 7 to study the impact of growing number of communities. The following two lemmas are useful in proving the main result. To avoid making the proof too technical and for ease of presentation, we present this result for the case in which the community sizes are equal.\nLemma 1. Let p = a logn n and let q = b logn n . Let G \u223c SBM(n, p, q) with C equally sized communities. Let Xk be the number of isolated vertices in community k of G. If a+(C\u22121)b\nC < \u03b1, then E[Xk] \u2265 n\n1\u2212\u03b1 C (1 \u2212 o(1)). Additionally, P [ Xk \u2264 n 1\u2212\u03b1\n2C\n] \u2192 0.\nProof. Let n\u2032 = n/C. Define a random variable li as an indicator of the event that node i is isolated. Then\nE[li] = (1\u2212 p)n \u2032\u22121(1\u2212 q)(C\u22121)n \u2032\nLet Sk = {i : C(i) = k}, the vertices of community k. Then Xk = \u2211 i\u2208Sk\nli denotes the total number of isolated nodes in a particular community. The expected value of Xk goes to infinity:\nE[Xk] \u2265 n\u2032(1\u2212 p)n \u2032 (1\u2212 q)(C\u22121)n \u2032 = n\u2032 ( 1 + p\n1\u2212 p\n)\u2212n\u2032 ( 1 + q\n1\u2212 q )\u2212(C\u22121)n\u2032 \u2265 n\u2032 ( exp ( p\n1\u2212 p\n))\u2212n\u2032 ( exp ( q\n1\u2212 q ))\u2212(C\u22121)n\u2032 = 1\nC exp\n( logn\u2212 n \u2032p\n1\u2212 p \u2212 (C \u2212 1)n\u2032q 1\u2212 q ) = 1\nC exp\n( logn ( 1\u2212 a\nC(1\u2212 p) \u2212 (C \u2212 1)b C(1\u2212 q) )) \u2265 1 C exp ( logn ( 1\u2212 \u03b1 1\u2212 p\n)) = n1\u2212\u03b1\nC (1\u2212 o(1))\nNote that E[X] \u2192 \u221e if 1 > a+(C\u22121)b C\n. We want to show that V ar(X) is of the same order of E[X]. Then we can use\nP[X \u2264 1 2 E[X]] \u2264 4V ar[X] E[X]2 = 4E[X](1 + o(1)) E[X]2 \u2192 0 (4)\nNow we need to show that the variance is indeed of the order of expectation.\nV ar[X] = \u2211 i\u2208Sk \u2211 j\u2208Sk E[lilj ]\u2212 E[Xk]2\nFor i, j \u2208 Sk, i 6= j, E[lilj ] is equal to\n(1\u2212 p)2n \u2032\u22123(1\u2212 q)2(C\u22121)n \u2032 = E[li]\n2\n1\u2212 p = E[Xk]\n2\n(n\u2032)2(1\u2212 p)\nHence, using E[Xk]\u2192\u221e we have\nV ar[Xk] = E[Xk] + n\u2032(n\u2032 \u2212 1)E[Xk]2\n(n\u2032)2(1\u2212 p) + E[Xk] 2\n= E[Xk](1 + o(1))\nHence we have P[X \u2264 1 2 E[X]] \u2192 0. This means that with probability going to 1, the number of isolated vertices in a community goes to infinity, growing as n1\u2212\u03b1. This completes the proof.\nRecall the MAP decision rule of Section 4.3 which selects the permutation \u03a6 which maximized the posterior probability P [\u03a6|G1, \u03c0(G2)]. Recall that with our choice of notation, if the true permutation is identified then \u03a6 = I, the identity permutation. Next lemma shows that any permutation in the automorphism group of the intersection graph G1 \u2229 G2 achieves at least as large of a posterior probability as the true permutation I.\nLemma 2. Let G1 and G2 be the correlated SBM graphs. Let Aut(G1\u2229G2) denote the automorphism group of G1 \u2229 G2. If \u03c6 \u2208 Aut(G1\u2229G2) preserves the community structure, then\nP [\u03a6 = \u03c6|G1, \u03c0(G2)] \u2265 P [\u03a6 = I|G1, \u03c0(G2)]. Proof. Consider a vertex pair {i, j} \u2208 ( [n] 2 ) . Suppose C(i) = C(j). Note that {i, j} can only affect the intra community edge set symmetric difference defined in (2). If {i, j} \u2208 E(G1 \u2229G2) then its contribution to |Ein\u03c6 | and |EinI | is equal. This is because both \u03c6 and I are in Aut(G1 \u2229G2), so by definition the edges in G1 \u2229 G2 remain intact. If {i, j} /\u2208 E(G1 \u2229 G2), then there are two possibilities. If {i, j} \u2208 E(G1 \u222a G2) then its contribution to |EinI | is 1 and to |Ein\u03c6 | is either 0 or 1. If {i, j} /\u2208 E(G1 \u222a G2) then its contributions to both is 0. Hence, |EinI | \u2265 |Ein\u03c6 |.\nAlternatively, suppose C(i) 6= C(j). Note that {i, j} can only affect the inter community edge set symmetric difference defined in (3). The rest of the arguments are similar to the previous case. Hence, |EoutI | \u2265 |Eout\u03c6 |.\nThus P [\u03a6 = \u03c6|G1, \u03c0(G2)] \u2265 P [\u03a6 = I|G1, \u03c0(G2)].\nTheorem 1 (SBM Converse). If (a+(C\u22121)b)s1s2 C < 1\u2212 \u03b1 then with probability 1\u2212 o(1) at least n\u03b1/2 vertices of the graph \u03c0(G2) cannot be deanonymized. Furthermore, these vertices are all mutually confusable, so there are at least (1 \u2212 o(1))\u03b1 log2 n bits of uncertainty about the identity of these vertices.\nIn particular, if (a+(C\u22121)b)s1s2 C\n< 1 then with probability 1\u2212 o(1), \u03c0(G2) cannot be deanonymized exactly using G1.\nProof. Note that G1 \u2229G2 \u223c SBM(n, ps1s2, qs2s1) with the community labels known. Let Xk be the number of isolated vertices in community k of G1 \u2229 G2. By Lemma 1, with probability 1\u2212 o(1), Xk = \u2126(n1\u2212\u03b1). Any permutation that moves only these isolated vertices, preserving community structure, is an automorphism of G1\u2229G2. By Lemma 2, the adversary\u2019s posterior probability of such a permutation is at least as large as the posterior probability of the identity. Thus the MAP estimator for the whole permutation \u03c6 succeeds with probability at most 1|Aut(G1\u2229G2)| . As long as \u03b1 > 0, Xk \u2192 \u221e for all k and |Aut(G1 \u2229 G2)| \u2192 \u221e. For some isolated vertex i, the MAP estimator for \u03c6(i) succeeds with probability at most 1|XC(i)| = n\u2212\u03b1/2. With probability 1 \u2212 o(1), there are at least (1 \u2212 o(1))\u03b1 log2 n bits of uncertainty about the identity of a particular isolated vertex.\nThe converse implies that sufficiently sparse pairs of SBM graphs cannot be exactly deanonymized. Next we provide a nearly matching achievability region, i.e., a sufficient condition for deanonymizing graph \u03c0(G2) and G1. The importance of this result is that it illustrates the strength of our converse in Theorem 1.\nTheorem 2. Let p = a logn n and let q = b logn n . Let G \u223c SBM(n, p, q) and let G1 and G2 be subsampled from G with probabilities s1 and s2. If (a+(C\u22121)b)s1s2\nC > 2, then there is\nan algorithm which exactly recovers \u03c0 with probability 1 \u2212 o(1) given \u03c0(G2), G1, and the true community labels for each of these graphs.\nThis proof is omitted due to space constraints. Recent work investigates the analogous problem for Erdo\u030bs Re\u0301nyi graphs [6]. Theorem 2 follows from fairly straightforward adaptation of the argument used there. The bound in Theorem 2 has the same dependence on a, b, s1, and s2 as Theorem 1. In the case of exact deanonimization, the threholds differ only by a constant factor of 2. Consequently, the conditions that we require our anonymized graph to satisfy are not excessively conservative."}, {"heading": "6. COMMUNITY RECOVERY", "text": "Our converse identifies a region on parameters of the model that guarantees no adversary can deanonymize \u03c0(G2), the anonymized graph, given access to the auxiliary graph G1. The anonymized graph \u03c0(G2) is useful to the third parties only if they are still able to perform community detection in some portion of the identified region.\nIn this section, we show that there indeed exists a region in which community detection succeeds but deanonymization fails. To do so, we will combine Theorem 1 with a recent result regarding the feasibility of exact recovery of community labels in an SBM graph. This result is tight, but we only need the achievability part. The following theorem was proved for the two-community case by Abbe et al. [1] and independently by Mossel et al. [22], both in 2014. Hajek et al. generalized the result to arbitrary fixed C [11].\nTheorem 3. [11] Let G \u223c SBM(n, p, q) with C communities, where p = a logn\nn and q = b logn n . If \u221a a\u2212 \u221a b > \u221a C,\nthen there is an algorithm that exactly recovers the community labels of G with probability 1\u2212 o(1).\nCorollary 1. As long as s1 < 1, there are parameters s2, a and b such that \u03c0(G2) cannot be deanonymized exactly using G1 but exact community recovery is possible in G2.\nProof. From Theorem 3 we have the inequality \u221a as2 \u2212\u221a\nbs2 > \u221a C. From Theorem 1 we have (a+ (C\u22121)b)s1s2 < C. This region is not empty. For instance, for b\u2192 0, a must lie in the range C\ns2 < a < C s1s2 .\nInstead of releasing \u03c0(G2) in its original form, we could release a edge-subsampled version. By subsampling a graph,\nwe mean randomly including each edge of the graph independently with some probability t. In many cases, some choice of t results in a graph that falls into the safe region.\nThen the necessary condition for community detection becomes \u221a as2t \u2212 \u221a bs2t > \u221a C and the condition preventing exact deanonymization becomes (a + (C \u2212 1)b)s1s2t < C. This region is depicted in Figure 1 for two values of t. For t = 1, we recover the region corresponding to Corollary 1. It can be seen that subsampling with t = 0.2 results in a substantial increase in the parameter space of interest. The subsampling idea works for any number of communities, but in the two-community case, we have a very simple condition.\nCorollary 2. For C = 2, if exact recovery of communities is possible in G2 and ( a\u2212b a+b )2 + (1\u2212 s1)2 > 1, then there is some subsampling probability t such that the t-subsampled version of \u03c0(G2) still allows community detection but cannot be deanonymized given G1.\nThe simple structure of this region is depicted in Figure 2. The ratio a\u2212b\na+b = p\u2212q p+q measures the strength of the com-\nmunity structure in the SBM graph. Note that because 0 \u2264 b \u2264 a, we have 0 \u2264 a\u2212b\na+b \u2264 1. Unsurprisingly, when\nthe community structure is stronger, fewer edges of G2 must be preserved to allow community recovery. This allows us to create a greater degree of anonymity. The other factor (1\u2212 s1), measures the amount of ground truth information included in the auxiliary graph. As more of this information is publicly available, it becomes harder to produce an anonymized version of G2.\nTo produce a graph that can be published, we need to find a parameter range where there are many isolated vertices in G1 \u2229 G2 and none in G2 (because isolated vertices in G2 prevent exact community recovery). When s1 = 1, we have E(G2) \u2286 E(G1), so G2 = G1 \u2229 G2 and and it becomes impossible to produce a safe graph, regardless of the strength of the community structure."}, {"heading": "7. SUBLINEAR COMMUNITIES", "text": "So far, we have only considered graphs with a constant number of communities, or equivalently communities with a number of vertices linear in n. In real world graphs, community structure arises for a variety of reasons. For example, a community derived from common interest in some popular media franchise could easily have linear size. As the overall network grows, the probability of a new user being\na member of this community would be close to constant. In contrast, communities that arise from local real-world interactions will generally be sub-linear in size.\nWe have assumed that the adversary is capable of detecting the community structure in both the public and anonymized graphs and correctly matching a community in one graph to a community in the other. If C is constant, the community level matching reduces the anonymity of a single vertex by an asymptotically negligible amount. Without the community level matching, log2 n bits are required to describe the corresponding vertex in other graph. With it, log2(n/C) = (1 \u2212 o(1)) log2 n bits are required. Because of this, the asymptotic threshold in Theorem 1 does not depend on C, When the number of communities is growing and the size of a typical community is sub-linear, the community level matching contains a non-negligible amount of information about each vertex identity. Consequently, when C \u2192 \u221e, the threshold for anonymity does depend on the growth rate of C. Our converse argument depends on the existence of community preserving automorphisms of G1\u2229G2. If the number of communities is growing with n, it is possible to have a large number of total isolated vertices in the graph, but still no communities with multiple isolated vertices. For this regime, we are not aware of results giving the conditions under which community recovery is possible, but we derive the following converse for the deanonymization problem.\nTheorem 4. Let the number of communities be C = n\u03b2\nfor some 0 < \u03b2 < 1. If (a+(C\u22121)b)s1s2 C < 1\u2212\u03b1\u2212\u03b2 then with probability 1\u2212o(1) at least n\u03b1/2 vertices of the graph \u03c0(G2) cannot be deanonymized. Furthermore, these vertices are all mutually confusable, so there are at least (1 \u2212 o(1))\u03b1 log2 n bits of uncertainty about the identity of these vertices.\nProof. Let Xk be the number of isolated vertices in community k of G1\u2229G2. By Lemma 1, with probability 1\u2212o(1), Xk = n1\u2212\u03b1\n2n\u03b2 = \u2126(n1\u2212\u03b1\u2212\u03b2). The remainder of the proof is\nparallel to that of Theorem 1.\nThis theorem implies that to achieve the same level of uncertainty about identities of vertices as in the constant community case (i. e., (1 \u2212 o(1))\u03b1 log2 n bits), a more conservative threshold is needed (Note the shift by \u03b2)."}, {"heading": "8. EXPERIMENTAL RESULTS", "text": "In this section, we study the utility-privacy trade-off for both synthetic and real networks. The aim of this section is two-fold. First, we want to show that when the conditions of our converse are satisfied, most of the vertices in the network still remain anonymized. Second, we aim to demonstrate the existence of real networks which support community reconstruction without leaking the privacy of most of the users."}, {"heading": "8.1 Results for SBM", "text": "We consider the percolation based deanonymization algorithm proposed in [28], when an adversary knows the community partition in the networks. The choice of this algorithm is motivated by the fact that its performance is guaranteed for random graphs. Other algorithms in the literature are heuristics based and their performance is highly dataset dependent. Because the structure of an SBM network is quite uniform, the structural properties used by the heuristic algorithms are present only in a very few locations.\nThe percolation algorithm starts with \u039b0 number of seed nodes, and incrementally maps the remaining pair of nodes, using a thresholding criteria controlled by parameter r \u2265 2. A large value of r ensures a smaller deanonymization error but requires large number of seeds to percolate. Conversely, small values of r make the percolation easier but increase the error rates. We analyze the performance of this algorithm on the networks drawn from the SBM family with two communities. We provide the algorithm with \u039b0 number of randomly selected seed nodes. In practice, the algorithm has to identify the seeds correctly, so our setting is helping the performance of the algorithms. To make use of the community structure, we only allow those mappings which match nodes belonging to the same community.\nThe underlying graph is drawn from the SBM distribution with two communities, that is, G \u223c SBM(n, a logn\nn , b logn n ).\nGraphs G1 and G2 are generated using sampling probabilities s1 and s2 respectively. We also sub-sample the private graph G2 with probability t. Define the offset for the parameter space, measuring the distance of parameters from the threshold for deanonymization, by, \u03b4 = (a+b)s1s2t 2\n\u2212 1. Note that, \u03b4 < 0 corresponds to the case when exact deanonymization is impossible. We are interested in the performance of the algorithm with varying values of the \u03b4.\nTo generate the datasets, the parameters are fixed as n = 5000, a = 20 and b = 5. We vary the values of the sampling probabilities s1,s2, and t to tune the parameter \u03b4. The parameters are tuned such that the community structure is preserved perfectly, that is, parameters are in the regime where exact community recovery is possible using SDP. We first evaluate the algorithm for the thresholding parameter r = 4, for which the best results were obtained. For each value of r, the results are compared for four values of the offset parameter, \u03b4 = {\u22120.4,\u22120.05, 0.05, 0.75}.\nFigure 3(a) shows the percolation behavior of the algorithm for r = 4 and various values of \u03b4. For \u03b4 = \u22120.05, 0.05, and 0.75, the percolation process exhibits a phase transition. That is, after some critical value of \u039b0, the algorithm maps almost every node in G1 to some node in G2. But for \u03b4 = \u22120.4, the algorithm percolates almost linearly in the number of initial seeds, i.e. it fails to identify many nodes beyond the randomly given seeds. Hence, in this case, the algorithm requires a large value of \u039b0 to map a significantly large number of users which is not reasonable or practical. Figure 3(b) shows the error rates for this scenario. We define the error rate as the ratio of incorrectly mapped nodes to the total number of mapped nodes excluding the seeds. The error rates seem to converge to small values, which means that, when the algorithm managed to percolate, it deanonymized the users correctly.\nGiven that the reason for the failure of the algorithm, at \u03b4 = \u22120.4, is not the errors in mapping the users, but rather not being able to percolate, we tested the performance for r = 2 and r = 3. For r = 2 the percolation process undergoes a phase transition for all the values of \u03b4. In this case the error rates were quite high and smaller values of \u03b4 result in even higher error rates as compared to larger values. In particular, for \u03b4 = \u22120.4, the error rate was more than 0.9 even for a large number of initial seeds, which means that although the algorithm percolates, it deanonymizes only a small fraction of users correctly.\nFigure 4(a) shows the percolation behavior of the algorithm for r = 3 and various values of \u03b4. Note that, in con-\ntrast to the case r = 2, the percolation for \u03b4 = \u22120.4 shows similar behavior to that when r = 4. Hence, even in this case, at lower negative values of \u03b4, the algorithm requires a large number of seeds to percolate efficiently. Figure 4(b) shows the error rates of the algorithm for this case. Although the error rates are not too high, achieving them still requires a large number of seeds, especially for negative values of \u03b4.\nOn the basis of our results, we argue that, although \u03b4 < 0 is the threshold for the exact deanonymizability, the percolation algorithm fails significantly if we go somewhat lower than 0. This is despite the fact that a large number of seed nodes was handed out to the algorithm as opposed to being learnt. The algorithm percolates for r = 2 but makes large number of errors and hence only deanonymizes a small fraction of users. If \u03b4 decreases further, the error rate is expected to increase even more. For r = 4, although the error rate is small, achieving this requires a large number of seeds, if \u03b4 is near or below zero, which imposes a limitation on the applicability of the algorithm in practice."}, {"heading": "8.2 Results for Real Network", "text": "We consider a real world dataset and study its utility and privacy trade-off by varying the subsampling parameter t. We consider Facebook network [16], containing 4039 users and 88234 edges. The average clustering coefficient is 0.6055 and fraction of closed triangles is 0.2647 which suggests strong community structure. We expect the community structure of the dataset to be resistant to edge perturbations. We describe the experimental methodology and results in the following subsections.\n8.2.1 Methodology\nOur first aim is to study the effects of edge subsampling on the community structure. The original dataset is subsampled using the subsampling parameter t = 0.5, 0.6, 0.7, 0.8, and 0.9. As there is no ground truth community labels for the network, we use the communities detected in the original network as our ground truth. To detect the communities, we use the freely available software Pajek [2], utilizing the Louvain modularity maximization method. We aim to measure the change in community structure as a function of t. We define the following parameters.\n\u2022 Number of Communities: A community is considered a true community only if it has at least 4 vertices.\n\u2022 (1\u2212 )-Preservation: We find the best match among the communities of the two networks using the Jac-\ncard index, J(A,B) = |A\u2229B||A\u222aB| . Note that, higher the index, better the community is preserved. Once the best match has been found for all the communities, we define the (1 \u2212 )-Preservation as the number of communities with Jaccard index at least (1 \u2212 ). We consider \u2208 {0.1, 0.15}, which ensures that the communities are preserved extremely well.\nOur second aim is to study the effect of sub-sampling on the anonymity of the dataset. For this purpose, we generate the auxiliary network by rewiring 30 percent of the edges of the original network. This choice models an adversary with access to an auxiliary network which is highly correlated with the anonymized one. We then study the deanonymization results for percolation algorithm [28] for varying values of sub-sampling parameter t.\n8.2.2 Results\nTable 1 shows the results for the Facebook dataset. The number of communities is well preserved, the maximum change being 2 for t = 0.6. The size of the smallest community is preserved perfectly till t = 0.7 whereas size of the largest community is always well preserved. This indicates that small communities tend to break into even smaller ones if we subsample too much. The most interesting part of the results is the (1\u2212 )-Preservation. Subsampling upto t = 0.7 preserves most of the communities to more than 90% of the members. Thinking less conservatively, even going upto t = 0.5 preserves most of the communities to more than 85% members. These results indicate that most of the community structure is well preserved even if we subsample to half the number of edges. Table 2 shows the Jaccard indices for the five largest communities in the network. Note that the minimum size of a community in this scenario was 346, and corresponds to the smallest community for t = 0.6. As is evident from the table, most of these communities are preserved to over 95%. The results seem to be an outcome of the already strong community structure in the original network. The results are motivating in the sense that preservation of community structure after edge perturbation depends on the strength of the communities in the original network.\nFigure 5 shows the deanonymization results using the percolation algorithm with threshold r = 2, 3, 4. We used 500 number of random seeds. This selection was made keeping in mind that the algorithm should percolate while the number of seeds is practical as well. Also, as seen in Figure 3, when near the threshold, the algorithm required around 500 seeds to percolate. As evident in Figure 5(a), the number of mapped users increases with sub-sampling parameter t for every value of r. A decreasing pattern is evident in Figure 5(b) for the error rate. The definition of error rate is the same as in subsection 8.1. Note that for t \u2264 0.7, the error rate is well above 75% for all values of r. Hence subsampling this dataset to around t = 0.7 preserves the anonymity of most of the users while still preserving most of the community structure. The best results seem to be obtained with r = 3 as more users are mapped, compared to r = 4 and the error rates seem to be similar. Even this choice maps\naround 35% users when t = 0.9. The results obtained indicate that the community structure is well preserved in the Facebook network at least upto t = 0.7. Depending on the application, even going as low as t = 0.5 preserves the community structure to a good extent. The deanonymization results also indicate that t \u2264 0.7 ensures that most of the users remain anonymized. These results show that, depending upon the dataset, it is possible to preserve most of the community structure after edge perturbations while preserving the privacy. Most of the studies until now have missed this point. These results call for more dataset oriented research into the utility-privacy trade off."}, {"heading": "9. CONCLUSION", "text": "In this paper, we considered the problem of network deanonymizability and established an information theoretic converse for the exact deanonymizability. This result applies to any deanonymization algorithm and hence provides a fundamental limit for this statistical estimation problem. This is qualitatively different from existing work in this area. We also improve the state of the art in achievability conditions, where significant effort has already been spent designing both efficient algorithms and information theoretically optimal methods. In particular, our converse and achievability bounds have the same parameter dependence. For exact deanonymization, the bounds match up to a factor of 2. Our work supports the idea that the intersection graph of the auxiliary and sensitive networks plays a fundamental role in controlling the feasibility of deanonymization. This adds to existing evidence from [28], where this intersection plays a crucial role in the analysis of percolation algorithm.\nAn important consequence of our result is that it is sometimes possible to prevent deanonymization while preserving other important structural information contained in the sensitive graph, particularly the community structure. The amount of ground truth information available to the public plays an important role in this trade-off.\nThe converse only establishes that a subset of the vertices cannot be deanonymized. However, we make similar strong requirements in the community reconstruction problem: we require the community label of every vertex to be learnable. The existance of a safe region under these very strict definitions of deanonymization and community recovery suggests that one might also exist if the definitions are simultaneously relaxed. Additionally, simulations illustrate that deanonymization algorithms tend to fail drastically when correlation and edge density become too low. The failure conditions for these algorithms are not identical to the conditions of our converse, but they are closely related. Consequently we believe that it is possible to rigorously establish stronger impossibility results for deanonymization."}, {"heading": "10. REFERENCES", "text": "[1] E. Abbe, A. S. Bandeira, and G. Hall. Exact recovery\nin the stochastic block model. arXiv preprint arXiv:1405.3267, 2014.\n[2] V. Batagelj and A. Mrvar. Pajek-program for large network analysis. Connections, 21(2):47\u201357, 1998.\n[3] J. Brickell and V. Shmatikov. The cost of privacy: Destruction of data-mining utility in anonymized data publishing. In Proceedings of the 14th ACM SIGKDD International Conference on Knowledge discovery and data mining, pages 70\u201378. ACM, 2008.\n[4] J. Chen and B. Yuan. Detecting functional modules in the yeast protein\u2013protein interaction network. Bioinformatics, 22(18):2283\u20132290, 2006.\n[5] A. Coja-Oghlan. Graph partitioning via adaptive spectral techniques. Combinatorics, Probability and Computing, 19(02):227\u2013284, 2010.\n[6] D. Cullina and N. Kiyavash. Improved achievability and converse bounds for Erdos Renyi graph matching. arXiv preprint arXiv:1602.01042, 2016.\n[7] A. Decelle, F. Krzakala, C. Moore, and L. Zdeborova\u0301. Asymptotic analysis of the stochastic block model for modular networks and its algorithmic applications. Physical Review E, 84(6):066106, 2011.\n[8] C. Dwork. Differential privacy. In Encyclopedia of Cryptography and Security, pages 338\u2013340. Springer, 2011.\n[9] M. Girvan and M. E. Newman. Community structure in social and biological networks. Proceedings of the national academy of sciences, 99(12):7821\u20137826, 2002.\n[10] B. Hajek, Y. Wu, and J. Xu. Achieving exact cluster recovery threshold via semidefinite programming. arXiv preprint arXiv:1412.6156, 2014.\n[11] B. Hajek, Y. Wu, and J. Xu. Achieving exact cluster recovery threshold via semidefinite programming: Extensions. arXiv preprint arXiv:1502.07738, 2015.\n[12] M. Hay, G. Miklau, D. Jensen, D. Towsley, and P. Weis. Resisting structural re-identification in anonymized social networks. Proceedings of the VLDB Endowment, 1(1):102\u2013114, 2008.\n[13] S. Ji, W. Li, N. Z. Gong, P. Mittal, and R. Beyah. On your social network de-anonymizablity: Quantification and large scale evaluation with seed knowledge. 2015.\n[14] S. Ji, W. Li, M. Srivatsa, and R. Beyah. Structural data de-anonymization: Quantification, practice, and implications. In Proceedings of the 2014 ACM SIGSAC Conference on Computer and Communications Security, pages 1040\u20131053. ACM, 2014.\n[15] S. Jones and E. O\u2019Neill. Feasibility of structural network clustering for group-based privacy control in social networks. In Proceedings of the Sixth Symposium on Usable Privacy and Security, page 9. ACM, 2010.\n[16] J. Leskovec and A. Krevl. SNAP Datasets: Stanford large network dataset collection. http://snap.stanford.edu/data, June 2014.\n[17] N. Li, W. Qardaji, D. Su, Y. Wu, and W. Yang. Membership privacy: a unifying framework for privacy\ndefinitions. In Proceedings of the 2013 ACM SIGSAC conference on Computer & communications security, pages 889\u2013900. ACM, 2013.\n[18] T. Li and N. Li. On the tradeoff between privacy and utility in data publishing. In Proceedings of the 15th ACM SIGKDD International Conference on Knowledge discovery and data mining, pages 517\u2013526. ACM, 2009.\n[19] K. Liu and E. Terzi. Towards identity anonymization on graphs. In Proceedings of the 2008 ACM SIGMOD international conference on Management of data, pages 93\u2013106. ACM, 2008.\n[20] L. Massoulie\u0301. Community detection thresholds and the weak ramanujan property. In Proceedings of the 46th Annual ACM Symposium on Theory of Computing, pages 694\u2013703. ACM, 2014.\n[21] M. McPherson, L. Smith-Lovin, and J. M. Cook. Birds of a feather: Homophily in social networks. Annual review of sociology, pages 415\u2013444, 2001.\n[22] E. Mossel, J. Neeman, and A. Sly. Consistency thresholds for binary symmetric block models. arXiv preprint arXiv:1407.1591, 2014.\n[23] A. Narayanan and V. Shmatikov. De-anonymizing social networks. In Security and Privacy, 2009 30th IEEE Symposium on, pages 173\u2013187. IEEE, 2009.\n[24] M. Newman. Networks: An Introduction. Oxford University Press, 2010.\n[25] S. Nilizadeh, A. Kapadia, and Y.-Y. Ahn. Community-enhanced de-anonymization of online social networks. In Proceedings of the 2014 ACM SIGSAC Conference on Computer and Communications Security, pages 537\u2013548. ACM, 2014.\n[26] P. Pedarsani and M. Grossglauser. On the privacy of anonymized networks. In Proceedings of the 17th ACM SIGKDD international conference on Knowledge discovery and data mining, pages 1235\u20131243. ACM, 2011.\n[27] L. Weng, F. Menczer, and Y.-Y. Ahn. Predicting successful memes using network and community structure. arXiv preprint arXiv:1403.6199, 2014.\n[28] L. Yartseva and M. Grossglauser. On the performance of percolation graph matching. In Proceedings of the first ACM conference on Online social networks, pages 119\u2013130. ACM, 2013.\n[29] S.-H. Yoon, K.-N. Kim, J. Hong, S.-W. Kim, and S. Park. A community-based sampling method using\ndpl for online social networks. Information Sciences, 306:53\u201369, 2015."}], "references": [{"title": "Exact recovery in the stochastic block model", "author": ["E. Abbe", "A.S. Bandeira", "G. Hall"], "venue": "arXiv preprint arXiv:1405.3267", "citeRegEx": "1", "shortCiteRegEx": null, "year": 2014}, {"title": "Pajek-program for large network analysis", "author": ["V. Batagelj", "A. Mrvar"], "venue": "Connections, 21(2):47\u201357", "citeRegEx": "2", "shortCiteRegEx": null, "year": 1998}, {"title": "The cost of privacy: Destruction of data-mining utility in anonymized data publishing", "author": ["J. Brickell", "V. Shmatikov"], "venue": "Proceedings of the 14th ACM SIGKDD International Conference on Knowledge discovery and data mining, pages 70\u201378. ACM", "citeRegEx": "3", "shortCiteRegEx": null, "year": 2008}, {"title": "Detecting functional modules in the yeast protein\u2013protein interaction network", "author": ["J. Chen", "B. Yuan"], "venue": "Bioinformatics, 22(18):2283\u20132290", "citeRegEx": "4", "shortCiteRegEx": null, "year": 2006}, {"title": "Graph partitioning via adaptive spectral techniques", "author": ["A. Coja-Oghlan"], "venue": "Combinatorics, Probability and Computing, 19(02):227\u2013284", "citeRegEx": "5", "shortCiteRegEx": null, "year": 2010}, {"title": "Improved achievability and converse bounds for Erdos Renyi graph matching", "author": ["D. Cullina", "N. Kiyavash"], "venue": "arXiv preprint arXiv:1602.01042", "citeRegEx": "6", "shortCiteRegEx": null, "year": 2016}, {"title": "Asymptotic analysis of the stochastic block model for modular networks and its algorithmic applications", "author": ["A. Decelle", "F. Krzakala", "C. Moore", "L. Zdeborov\u00e1"], "venue": "Physical Review E, 84(6):066106", "citeRegEx": "7", "shortCiteRegEx": null, "year": 2011}, {"title": "Differential privacy", "author": ["C. Dwork"], "venue": "Encyclopedia of Cryptography and Security, pages 338\u2013340. Springer", "citeRegEx": "8", "shortCiteRegEx": null, "year": 2011}, {"title": "Community structure in social and biological networks", "author": ["M. Girvan", "M.E. Newman"], "venue": "Proceedings of the national academy of sciences, 99(12):7821\u20137826", "citeRegEx": "9", "shortCiteRegEx": null, "year": 2002}, {"title": "Achieving exact cluster recovery threshold via semidefinite programming", "author": ["B. Hajek", "Y. Wu", "J. Xu"], "venue": "arXiv preprint arXiv:1412.6156", "citeRegEx": "10", "shortCiteRegEx": null, "year": 2014}, {"title": "Achieving exact cluster recovery threshold via semidefinite programming: Extensions", "author": ["B. Hajek", "Y. Wu", "J. Xu"], "venue": "arXiv preprint arXiv:1502.07738", "citeRegEx": "11", "shortCiteRegEx": null, "year": 2015}, {"title": "Resisting structural re-identification in anonymized social networks", "author": ["M. Hay", "G. Miklau", "D. Jensen", "D. Towsley", "P. Weis"], "venue": "Proceedings of the VLDB Endowment, 1(1):102\u2013114", "citeRegEx": "12", "shortCiteRegEx": null, "year": 2008}, {"title": "On your social network de-anonymizablity: Quantification and large scale evaluation with seed knowledge", "author": ["S. Ji", "W. Li", "N.Z. Gong", "P. Mittal", "R. Beyah"], "venue": null, "citeRegEx": "13", "shortCiteRegEx": "13", "year": 2015}, {"title": "Structural data de-anonymization: Quantification", "author": ["S. Ji", "W. Li", "M. Srivatsa", "R. Beyah"], "venue": "practice, and implications. In Proceedings of the 2014 ACM SIGSAC Conference on Computer and Communications Security, pages 1040\u20131053. ACM", "citeRegEx": "14", "shortCiteRegEx": null, "year": 2014}, {"title": "Feasibility of structural network clustering for group-based privacy control in social networks", "author": ["S. Jones", "E. O\u2019Neill"], "venue": "In Proceedings of the Sixth Symposium on Usable Privacy and Security,", "citeRegEx": "15", "shortCiteRegEx": "15", "year": 2010}, {"title": "Krevl. SNAP Datasets: Stanford large network dataset collection", "author": ["A.J. Leskovec"], "venue": "http://snap.stanford.edu/data,", "citeRegEx": "16", "shortCiteRegEx": "16", "year": 2014}, {"title": "Membership privacy: a unifying framework for privacy  definitions", "author": ["N. Li", "W. Qardaji", "D. Su", "Y. Wu", "W. Yang"], "venue": "Proceedings of the 2013 ACM SIGSAC conference on Computer & communications security, pages 889\u2013900. ACM", "citeRegEx": "17", "shortCiteRegEx": null, "year": 2013}, {"title": "On the tradeoff between privacy and utility in data publishing", "author": ["T. Li", "N. Li"], "venue": "Proceedings of the 15th ACM SIGKDD International Conference on Knowledge discovery and data mining, pages 517\u2013526. ACM", "citeRegEx": "18", "shortCiteRegEx": null, "year": 2009}, {"title": "Towards identity anonymization on graphs", "author": ["K. Liu", "E. Terzi"], "venue": "Proceedings of the 2008 ACM SIGMOD international conference on Management of data, pages 93\u2013106. ACM", "citeRegEx": "19", "shortCiteRegEx": null, "year": 2008}, {"title": "Community detection thresholds and the weak ramanujan property", "author": ["L. Massouli\u00e9"], "venue": "Proceedings of the 46th Annual ACM Symposium on Theory of Computing, pages 694\u2013703. ACM", "citeRegEx": "20", "shortCiteRegEx": null, "year": 2014}, {"title": "Birds of a feather: Homophily in social networks", "author": ["M. McPherson", "L. Smith-Lovin", "J.M. Cook"], "venue": "Annual review of sociology, pages 415\u2013444", "citeRegEx": "21", "shortCiteRegEx": null, "year": 2001}, {"title": "Consistency thresholds for binary symmetric block models", "author": ["E. Mossel", "J. Neeman", "A. Sly"], "venue": "arXiv preprint arXiv:1407.1591", "citeRegEx": "22", "shortCiteRegEx": null, "year": 2014}, {"title": "De-anonymizing social networks", "author": ["A. Narayanan", "V. Shmatikov"], "venue": "Security and Privacy, 2009 30th IEEE Symposium on, pages 173\u2013187. IEEE", "citeRegEx": "23", "shortCiteRegEx": null, "year": 2009}, {"title": "Networks: An Introduction", "author": ["M. Newman"], "venue": "Oxford University Press", "citeRegEx": "24", "shortCiteRegEx": null, "year": 2010}, {"title": "Community-enhanced de-anonymization of online social networks", "author": ["S. Nilizadeh", "A. Kapadia", "Y.-Y. Ahn"], "venue": "Proceedings of the 2014 ACM SIGSAC Conference on Computer and Communications Security, pages 537\u2013548. ACM", "citeRegEx": "25", "shortCiteRegEx": null, "year": 2014}, {"title": "On the privacy of anonymized networks", "author": ["P. Pedarsani", "M. Grossglauser"], "venue": "Proceedings of the 17th ACM SIGKDD international conference on Knowledge discovery and data mining, pages 1235\u20131243. ACM", "citeRegEx": "26", "shortCiteRegEx": null, "year": 2011}, {"title": "Predicting successful memes using network and community structure", "author": ["L. Weng", "F. Menczer", "Y.-Y. Ahn"], "venue": "arXiv preprint arXiv:1403.6199", "citeRegEx": "27", "shortCiteRegEx": null, "year": 2014}, {"title": "On the performance of percolation graph matching", "author": ["L. Yartseva", "M. Grossglauser"], "venue": "Proceedings of the first ACM conference on Online social networks, pages 119\u2013130. ACM", "citeRegEx": "28", "shortCiteRegEx": null, "year": 2013}, {"title": "A community-based sampling method using  dpl for online social networks", "author": ["S.-H. Yoon", "K.-N. Kim", "J. Hong", "S.-W. Kim", "S. Park"], "venue": "Information Sciences, 306:53\u201369", "citeRegEx": "29", "shortCiteRegEx": null, "year": 2015}], "referenceMentions": [{"referenceID": 20, "context": "For example, due to homophily [21], OSNs are good microcosms to study efficient advertising strategies.", "startOffset": 30, "endOffset": 34}, {"referenceID": 11, "context": "More clever techniques such as k-anonymization [12, 19] and differential privacy [8, 17] are also proposed to address the problem in suitable scenarios.", "startOffset": 47, "endOffset": 55}, {"referenceID": 18, "context": "More clever techniques such as k-anonymization [12, 19] and differential privacy [8, 17] are also proposed to address the problem in suitable scenarios.", "startOffset": 47, "endOffset": 55}, {"referenceID": 7, "context": "More clever techniques such as k-anonymization [12, 19] and differential privacy [8, 17] are also proposed to address the problem in suitable scenarios.", "startOffset": 81, "endOffset": 88}, {"referenceID": 16, "context": "More clever techniques such as k-anonymization [12, 19] and differential privacy [8, 17] are also proposed to address the problem in suitable scenarios.", "startOffset": 81, "endOffset": 88}, {"referenceID": 2, "context": "This trade-off between privacy and data utility has been noted in the literature [3, 18], but a theoretical understanding of this trade-off is still missing.", "startOffset": 81, "endOffset": 88}, {"referenceID": 17, "context": "This trade-off between privacy and data utility has been noted in the literature [3, 18], but a theoretical understanding of this trade-off is still missing.", "startOffset": 81, "endOffset": 88}, {"referenceID": 22, "context": "This is done by proving success of specific algorithms in deanonymizing the graph for a range of problem parameters or by providing simulation results on specific datasets [23, 25, 26, 14, 13].", "startOffset": 172, "endOffset": 192}, {"referenceID": 24, "context": "This is done by proving success of specific algorithms in deanonymizing the graph for a range of problem parameters or by providing simulation results on specific datasets [23, 25, 26, 14, 13].", "startOffset": 172, "endOffset": 192}, {"referenceID": 25, "context": "This is done by proving success of specific algorithms in deanonymizing the graph for a range of problem parameters or by providing simulation results on specific datasets [23, 25, 26, 14, 13].", "startOffset": 172, "endOffset": 192}, {"referenceID": 13, "context": "This is done by proving success of specific algorithms in deanonymizing the graph for a range of problem parameters or by providing simulation results on specific datasets [23, 25, 26, 14, 13].", "startOffset": 172, "endOffset": 192}, {"referenceID": 12, "context": "This is done by proving success of specific algorithms in deanonymizing the graph for a range of problem parameters or by providing simulation results on specific datasets [23, 25, 26, 14, 13].", "startOffset": 172, "endOffset": 192}, {"referenceID": 4, "context": "In recent years, community detection/reconstruction problems have been extensively studied for the Stochastic Block Model (SBM) [5, 7, 20, 11, 1].", "startOffset": 128, "endOffset": 145}, {"referenceID": 6, "context": "In recent years, community detection/reconstruction problems have been extensively studied for the Stochastic Block Model (SBM) [5, 7, 20, 11, 1].", "startOffset": 128, "endOffset": 145}, {"referenceID": 19, "context": "In recent years, community detection/reconstruction problems have been extensively studied for the Stochastic Block Model (SBM) [5, 7, 20, 11, 1].", "startOffset": 128, "endOffset": 145}, {"referenceID": 10, "context": "In recent years, community detection/reconstruction problems have been extensively studied for the Stochastic Block Model (SBM) [5, 7, 20, 11, 1].", "startOffset": 128, "endOffset": 145}, {"referenceID": 0, "context": "In recent years, community detection/reconstruction problems have been extensively studied for the Stochastic Block Model (SBM) [5, 7, 20, 11, 1].", "startOffset": 128, "endOffset": 145}, {"referenceID": 0, "context": "The case of two communities, C = 2, was studied in [1] in which Abbe et al.", "startOffset": 51, "endOffset": 54}, {"referenceID": 9, "context": "subsequently prove that the SDP algorithm is optimal, that is, it recovers the exact communities whenever it is theoretically possible to do so [10].", "startOffset": 144, "endOffset": 148}, {"referenceID": 8, "context": "The definition of a community varies with applications and algorithms [9, 4].", "startOffset": 70, "endOffset": 76}, {"referenceID": 3, "context": "The definition of a community varies with applications and algorithms [9, 4].", "startOffset": 70, "endOffset": 76}, {"referenceID": 25, "context": "In [26], Pedarsani and Grossglauser studied the deanonymization problem for two correlated Erd\u00f6s R\u00e9nyi random graphs.", "startOffset": 3, "endOffset": 7}, {"referenceID": 13, "context": "in [14].", "startOffset": 3, "endOffset": 7}, {"referenceID": 25, "context": "To generate the correlated graphs, the sampling process as in [26] was used, but the underlying graph is drawn from the configuration model [24].", "startOffset": 62, "endOffset": 66}, {"referenceID": 23, "context": "To generate the correlated graphs, the sampling process as in [26] was used, but the underlying graph is drawn from the configuration model [24].", "startOffset": 140, "endOffset": 144}, {"referenceID": 12, "context": "studied the role seed nodes play in assisting the exact and partial deanonymization process [13].", "startOffset": 92, "endOffset": 96}, {"referenceID": 27, "context": "studied the performance of a specific algorithm, the so called percolation graph matching algorithm, for deanonymizing Erd\u00f6s R\u00e9nyi random graphs [28].", "startOffset": 145, "endOffset": 149}, {"referenceID": 22, "context": "Narayanan and Shmatikov proposed a two-stage algorithm to deanonymize a network again when the adversary has access to an auxiliary network whose user base overlaps partially with that of the anonymized network [23].", "startOffset": 211, "endOffset": 215}, {"referenceID": 22, "context": "enhance the performance of the algorithm in [23] using the community structure of the network [25].", "startOffset": 44, "endOffset": 48}, {"referenceID": 24, "context": "enhance the performance of the algorithm in [23] using the community structure of the network [25].", "startOffset": 94, "endOffset": 98}, {"referenceID": 22, "context": "Subsequently, more seeds are identified within the communities and deanonymization is performed for each pair of communities using already existing algorithm of [23].", "startOffset": 161, "endOffset": 165}, {"referenceID": 22, "context": "The results in [23, 25] are great examples of why deanonymization poses a real threat to users, but they do not provide fundamental limits or even insights into when the deanonymization problem is hard or easy.", "startOffset": 15, "endOffset": 23}, {"referenceID": 24, "context": "The results in [23, 25] are great examples of why deanonymization poses a real threat to users, but they do not provide fundamental limits or even insights into when the deanonymization problem is hard or easy.", "startOffset": 15, "endOffset": 23}, {"referenceID": 14, "context": "1 Privacy Control [15] Information sharing in an OSN, like photos, statuses, emotions and location, is a common practice for individuals using the network.", "startOffset": 18, "endOffset": 22}, {"referenceID": 28, "context": "2 Sampling in OSNs [29]", "startOffset": 19, "endOffset": 23}, {"referenceID": 26, "context": "3 Viral Meme Prediction [27]", "startOffset": 24, "endOffset": 28}, {"referenceID": 25, "context": "This is essentially the same model which was previously used in [26, 14, 13].", "startOffset": 64, "endOffset": 76}, {"referenceID": 13, "context": "This is essentially the same model which was previously used in [26, 14, 13].", "startOffset": 64, "endOffset": 76}, {"referenceID": 12, "context": "This is essentially the same model which was previously used in [26, 14, 13].", "startOffset": 64, "endOffset": 76}, {"referenceID": 5, "context": "Recent work investigates the analogous problem for Erd\u0151s R\u00e9nyi graphs [6].", "startOffset": 70, "endOffset": 73}, {"referenceID": 0, "context": "[1] and independently by Mossel et al.", "startOffset": 0, "endOffset": 3}, {"referenceID": 21, "context": "[22], both in 2014.", "startOffset": 0, "endOffset": 4}, {"referenceID": 10, "context": "generalized the result to arbitrary fixed C [11].", "startOffset": 44, "endOffset": 48}, {"referenceID": 10, "context": "[11] Let G \u223c SBM(n, p, q) with C communities, where p = a logn n and q = b logn n .", "startOffset": 0, "endOffset": 4}, {"referenceID": 27, "context": "We consider the percolation based deanonymization algorithm proposed in [28], when an adversary knows the community partition in the networks.", "startOffset": 72, "endOffset": 76}, {"referenceID": 15, "context": "We consider Facebook network [16], containing 4039 users and 88234 edges.", "startOffset": 29, "endOffset": 33}, {"referenceID": 1, "context": "To detect the communities, we use the freely available software Pajek [2], utilizing the Louvain modularity maximization method.", "startOffset": 70, "endOffset": 73}, {"referenceID": 27, "context": "We then study the deanonymization results for percolation algorithm [28] for varying values of sub-sampling parameter t.", "startOffset": 68, "endOffset": 72}], "year": 2016, "abstractText": "We consider the problem of performing community detection on a network, while maintaining privacy, assuming that the adversary has access to an auxiliary correlated network. We ask the question \u201cDoes there exist a regime where the network cannot be deanonymized perfectly, yet the community structure could be learned?.\u201d To answer this question, we derive information theoretic converses for the perfect deanonymization problem using the Stochastic Block Model and edge sub-sampling. We also provide an almost tight achievability result for perfect deanonymization. We also evaluate the performance of percolation based deanonymization algorithm on Stochastic Block Model datasets that satisfy the conditions of our converse. Although our converse applies to exact deanonymization, the algorithm fails drastically when the conditions of the converse are met. Additionally, we study the effect of edge sub-sampling on the community structure of a real world dataset. Results show that the dataset falls under the purview of the idea of this paper. There results suggest that it may be possible to prove stronger partial deanonymizability converses, which would enable better privacy guarantees.", "creator": "LaTeX with hyperref package"}}}