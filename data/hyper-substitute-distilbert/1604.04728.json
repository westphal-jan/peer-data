{"id": "1604.04728", "review": {"conference": "arxiv", "VERSION": "v1", "DATE_OF_SUBMISSION": "16-Apr-2016", "title": "Reaching Unanimous Agreements Within Agent-Based Negotiation Teams With Linear and Monotonic Utility Functions", "abstract": "giving this analogy, sophisticated agent - based negotiation methodology for negotiation teams could negotiate a deal captures an apparatus already presented. agent - based negotiation teams this example of agents commonly engage together as whatever formal negotiation party ensure they share an instrument that is related to optimal negotiation process. that model relies on a mutual mediator that coordinates and checks team decisions review the decisions that team have to take during the negotiation phases : which company is invited by the opponent, and whether the offers requests from previous opponent are accepted. the predominant force in the interaction negotiation comes... the highly cooperative interaction guarantees communication within team decisions since decisions report a utility to team management that is greater than merely equal to their aspiration levels at past negotiation goal. this firm analyzes those unanimous decisions are taken for the team affects the facts around the effect against different types considering manipulations. that empirical discussion laboratory also performed to study the impact of some different choices of the model.", "histories": [["v1", "Sat, 16 Apr 2016 11:42:38 GMT  (466kb,D)", "http://arxiv.org/abs/1604.04728v1", "IEEE Transactions on Systems, Man, and Cybernetics, Part B (Cybernetics), 2012"]], "COMMENTS": "IEEE Transactions on Systems, Man, and Cybernetics, Part B (Cybernetics), 2012", "reviews": [], "SUBJECTS": "cs.MA cs.AI cs.GT", "authors": ["victor sanchez-anguix", "vicente julian", "vicente botti", "ana garcia-fornes"], "accepted": false, "id": "1604.04728"}, "pdf": {"name": "1604.04728.pdf", "metadata": {"source": "CRF", "title": "Reaching Unanimous Agreements within Agent-Based Negotiation Teams with Linear and Monotonic Utility Functions", "authors": ["Victor Sanchez-Anguix", "Vicente Julian", "Vicente Botti", "Ana Garc\u0131\u0301a-Fornes"], "emails": ["sanguix@dsic.upv.es", "vinglada@dsic.upv.es", "vbotti@dsic.upv.es", "agarcia@dsic.upv.es"], "sections": [{"heading": null, "text": "Index Terms\u2014Negotiation teams, automated negotiation, agreement technologies, multiagent systems.\nI. INTRODUCTION\nA negotiation team is a group of two or more interdepen-dent individuals who join together as a single negotiation party because of their similar interests and objectives related to the negotiation and who are all present at the bargaining table [1]. Therefore, this group of individuals unites because their members share goals that are related to a negotiation with an opponent. For instance, negotiation teams formed by different stakeholders are usually sent to the negotiation table when a company decides to sell a product line to another company. Nevertheless, as it has been stated in social sciences, negotiation teams are not necessarily unitary players since team members may have different preferences regarding the possible outcomes of the negotiation process [2]. Thus, given the divergence in preferences between teammates, the team has to agree upon, not only a negotiation strategy to carry out with the opponent, but also upon those agreements that are acceptable to the team. Despite being studied in social sciences to some extent [1], [2], as far as we know, negotiation teams have been overlooked by artificial intelligence research. We argue that a negotiation team is also an element that may be appropriate for some scenarios involving software\nV. Sanchez-Anguix, V. Julian, V. Botti, and A. Garcia-Fornes are with the Departamento de Sistemas Informa\u0301ticos y Computacio\u0301n, Universidad Polite\u0301cnica de Valencia, Valencia, Spain, Cam\u0131\u0301 de Vera s/n, 46022 e-mails: {sanguix,vinglada,vbotti,agarcia}@dsic.upv.es\nThis work is supported by TIN2008-04446, PROMETEO/2008/051, TIN2009-13839-C03-01, CSD2007-00022 of the Spanish government, and FPU grant AP2008-00600 awarded to V\u0131\u0301ctor Sa\u0301nchez-Anguix.\nagents. For instance, let us imagine an example based on an electronic market for travel and tourism. In this system, a group of friends (each friend is represented by a software agent) has decided to go on a trip together. This goal requires a negotiation with a travel agency agent. The fact that the group of agents (group of friends) has a common and shared goal (which is going on a trip together), is clear, and it requires an agreement with an opponent (the travel agency agent). However, it also seems reasonable to assume that friends may have different preferences regarding the negotiable trip conditions: hotel quality, price, number of days to stay, etc. For example, while some friends may care more about comfort, others may be more interested in money. In this type of scenario, and specially in open multi-agent systems, mediated preference aggregation is complicated since i) agents may be inclined to exaggerate their preferences in order to ensure a certain level of utility; ii) preferences are delicate information which may not be revealed to anyone; iii) utility functions may be different and require an extensive and costly aggregation. Hence, mechanisms that allow an agent-based negotiation team to handle intra-team conflict (divergences in preferences) while trying to get a deal from travel agencies\u2019 agents are needed. Thus, it is necessary to provide agent-based models for negotiation teams.\nThis article describes a mediated negotiation model for agent-based negotiation teams that negotiate with an opponent. The negotiation model defines the communications protocol with the opponent, what decisions are taken by the negotiation team, and how and when these decisions are taken (i.e., team dynamics) [3]. More specifically, our preliminary study presented about this model (Full Unanimity Mediated or FUM) in [4] is extended further. FUM is able to guarantee unanimity in decisions taken within the negotiation team as long as team members share the same type of monotonicity for valuation functions of the attributes. This assumption is relatively natural in buyer-seller settings found in electronic commerce (e.g., a team of buyers may value with the same type of valuation function attributes like the price, the quality of the product, and the time of dispatch). The proposed model relies on unanimity rules regarding the opponent\u2019s offer acceptance and an iterated offer construction process to determine which offer is sent to the opponent. This article is organized as follows. First, we describe our negotiation model. Then, we analyze how unanimity is assured within the team as well as the robustness of this model against different types of attacks. Then, we evaluate the empirical response of the proposed model depending on ar X iv :1\n60 4.\n04 72\n8v 1\n[ cs\n.M A\n] 1\n6 A\npr 2\n01 6\n2 the impact of the different model parameters and we analyze possible incentives that team members may have to deviate from the proposed behavior. We then relate our work to other works found in artificial intelligence. Finally, we summarize the conclusions of this work and discuss our future research."}, {"heading": "II. NEGOTIATION MODEL", "text": "Traditionally, a negotiation model is composed of a negotiation protocol, which defines the set of actions that are available for agents at each instant, and the negotiation strategy, which defines the decision making mechanisms employed by agents during the negotiation. In this article, we present a negotiation model where a negotiation team negotiates with an opponent. Despite resembling a bilateral negotiation scenario, negotiations that have teams as participants are slightly different since team dynamics also play a key role. Thus, three different elements have to be specified when a team negotiation model is proposed: negotiation protocol with the opponent, the negotiation strategy used by the opponent, and the intra-team negotiation strategy followed by team members in order to decide the actions to perform during the negotiation process. An intra-team strategy defines which decisions are taken by the team, and how and when these decisions are taken. More specifically, it is defined by the negotiation protocol followed among team members within the team and by the strategies followed by agents within the team. In this section, the general assumptions of our negotiation model and our negotiation model itself are described. Special attention is focused on the interactions among team members, which are carried out before and during the negotiation process and the negotiation strategy followed by team members within the team."}, {"heading": "A. General Assumptions", "text": "\u2022 In our model, a group of agents has formed a team A = {a1, a2, ..., aM} whose goal is to negotiate a successful deal with an opponent op. However, each team member ai may have different preferences about the negotiation issues. \u2022 Communications between the team and the opponent are carried out by means of a mediator that is trusted by the team. This mediator sends team decisions to the opponent and receives, and later broadcasts, decisions from the opponent to team members. Thus, the fact that the opponent is communicating with a team is not known by the opponent, which only interacts with the trusted mediator. The trusted mediator also performs other tasks that allow team members to reach unanimous decisions regarding the offer that is sent to the opponent and whether or not the opponent\u2019s offer is accepted. \u2022 The negotiation domain is comprised of n real-valued attributes whose domain is [0, 1]. Thus, the possible number of offers is [0, 1]n. \u2022 A complete offer is represented as X = {x1, x2, ..., xn}, where xi is the value assigned to the i-th attribute. The notation Xti\u2192j is employed to indicate that X is the offer sent by agent/team i to agent j at round t.\n\u2022 Team composition will remain static during the negotiation process. It is acknowledged that team members may leave or join the group in certain specific situations. However, membership dynamics is not considered in this article, and it is designated as future work. \u2022 All of the agents use linear utility functions to represent their private preferences. Negotiation attributes are supposed to be independent. Thus, the value of a specific attribute does not affect the valuation of other attributes\u2019 values. These functions can be formalized as follows:\nUi(X) = n\u2211 j=1 wi,j Vi,j(xj) (1)\nwhere Vi,j(.) is a monotonic valuation function that transforms the attribute value to [0, 1], and wi,j is the weight or importance that is given by the agent i to the j-th attribute. Weights are normalized so that \u2211n j=1 wi,j = 1 holds for every utility function. It is assumed that teammates share the same type of monotonic valuation function (either increasing or decreasing) for each negotiation attribute. In contrast to team members, the opponent valuation function is always the opposite type of monotonic function. Thus, if team members employ monotonically increasing functions, the opponent will be modeled using monotonically decreasing functions. It is reasonable to assume this model for valuation functions in e-commerce scenarios. Buyers usually share the same type of valuation function for attributes such as the price (monotonically decreasing), product quality (monotonically increasing), and the dispatch time (monotonically decreasing), whereas sellers usually use the opposite type of monotonic functions (monotonically increasing for price, monotonically decreasing for product quality, and monotonically increasing for dispatch time). As for attributes\u2019 weights, it is considered that each team member may assign different weight/importance to each negotiation issue. Therefore, differences among teammates are introduced by assigning different weights to negotiation attributes. Nevertheless, it should be highlighted that since team members share the same type of monotonic function, if one of the team members increases its welfare by increasing/decreasing one of the attribute values, the other team members will stay at the same welfare level or they will also increase their welfare. Thus, there is potential for cooperation among team members. Weights given by the opponent to attributes may also be different to those given by teammates. Agents do not know the form of other agents\u2019 utility functions, even if they are teammates. \u2022 The opponent has a private deadline Top, which defines his maximum number of negotiation rounds. Once Top has been reached in the negotiation process, the opponent will exit the process and the negotiation will end in failure. The team has a private joint deadline TA, which is common information for team members. Once this deadline has been reached, the team will exit the negotiation process and the negotiation will end in failure. We consider that TA has been agreed upon by team\n3 members before the negotiation process starts. \u2022 The opponent has a reservation utility RUop. Any offer\nwhose utility is lower than RUop is rejected. Each team member has a private reservation utility RUai , where ai is a team member. This individual reservation utility is not shared among teammates. Therefore, a team member ai rejects any offer whose value is under RUai . In this setting, reservation utilities represent the individual utility of each agent if the negotiation process fails."}, {"heading": "B. Negotiation Protocol with the Opponent", "text": "In this section, the negotiation process between a negotiation team and an opponent is studied. The fact that one of the parties is a team is transparent to the other party. Thus, superficially, the scenario resembles a bilateral negotiation scenario. Because of this, we decided to model the interaction between the team and the opponent as an alternating bilateral negotiation process [5]. In this protocol, one of the two agents is the initiator and sends the first offer to the other party or responding agent. The responding agent receives the offer and decides whether he/she accepts the offer or he/she sends a counter-offer as response. If the responding agent sends a counter-offer, the initiator agent has to decide whether he/she accepts the counter-offer or not. If the counter-offer is rejected, a new round starts and the process is repeated again until a deal is accepted (successful negotiation) or one of the parties decides to quit the negotiation since its deadline has been reached (failed negotiation). In our negotiation model, we consider that a trusted mediator is responsible for sending team decisions to the opponent and broadcasting opponent decisions to team members. Nevertheless, this mediator not only acts as a coordinator but also helps the team to reach unanimous agreements by means of an iterated process for offer generation and unanimity rules for opponent offer acceptance."}, {"heading": "C. Opponent Negotiation Strategy", "text": "A negotiation strategy defines the decision-making of an agent in a negotiation process. In this case, the negotiation strategy is constituted by the concession strategy, which marks the aspiration level of the opponent in terms of utility at each negotiation round, and the acceptance criterion, which determines whether the team offer is accepted or not. \u2022 It is assumed that the opponent uses a concession strategy\nto carry out during the negotiation process. A concession strategy typically (although not necessarily) starts by demanding the maximum aspiration and, as the negotiation process advances, the aspiration demanded tends to be lowered. The amount of concession/reduction applied at each step may depend on the specific tactic selected by the opponent. In this article, our main focus of interest is the general behavior of the proposed intra-team strategy. Thus, a set of well-known negotiation tactics was selected as the opponent negotiation strategy: timedependent tactics [6], [7]. We formalized time-dependent tactics as suggested by [7]:\nsop(t) = 1\u2212 (1\u2212RUop)( t\nTop )\n1 \u03b2op (2)\nA B A\nC D A AEFE\nA\nC E A E\nE\nE\nA\nC D A AEFE\nA A\nE E D A A E\n!\" #A D D\nA\nC D A\nA A E A E\"\nC D A AEFE $% % $ A A ! E A A\n& A A\n' D\nC D A AEFE\n$% %\n!E\nE\nA A\nA\nA E\nA A E E\nA E\n( %D A$\n! E\n! E A\nA D AD A % D\" A ( %D A$E\nD. Intra-Team Strategy: Negotiation Protocol within the Team\nThe negotiation protocol followed by team members for team communications can be divided into two different phases: the protocol followed during the pre-negotiation, and the protocol used during the negotiation process. Both of them are thoroughly described below. A general overview of the process followed by team members can be observed in Fig. 1.\n1) Pre-negotiation: In the pre-negotiation, team members confidentially share certain information about their preferences with the trusted mediator. Each team member specifies which attributes\u2019 decision rights it is willing to hand over when\n4 {Start pre-negotiation phase} \u2200i, j, I(i, j) = true Ask for NIai to each ai Receive responses NIai from each ai for ai \u2208 A do\nfor j \u2208 NIai do I(i, j) = false\nend for end for {End pre-negotiation phase}\nFig. 2. Pre-negotiation protocol followed by team A and the trusted mediator. In this schema, we show the protocol from the point of view of the mediator. The protocol followed by team members is analogous and straight-forward.\nthe team proposes an offer. It is reasonable that each team member may be willing to sacrifice decision rights pertaining to negotiation attributes that have little importance or no importance at all for one\u2019s own interests. This decision may help to find a more satisfactory agreement for the opponent while maintaining good quality for one\u2019s own utility. The fact that some attributes may yield little or no importance at all for some team members is also feasible in a team setting, since some of these attributes may have been introduced to satisfy the interests of a subgroup of team members.\nTherefore, for each team member ai, the trusted mediator asks the set of attributes NIai whose decision rights conform the set of rights that ai is willing to hand over when building an offer for the opponent. This information is annotated by the mediator in an interest matrix I . Each matrix position I(i, j) indicates whether the team member ai holds decision rights for attribute j (I(i, j) = true) or not (I(i, j) = false). How each team member ai specifies this set of attributes NIai is described later in Subsection II-E. The communication protocol carried out during the pre-negotiation phase, described from the point of view of the mediator, is shown in Fig. 2.\n2) Negotiation: Three possible actions can be carried out by the negotiation team at each negotiation round t: (a) accept/reject opponent offer acA(Xtop\u2192A) (Offer acceptance in Fig. 1); (b) send an offer/counter-offer XtA\u2192op (Offer construction in Fig. 1); (c) abandon the negotiation process. This last action is performed when the team deadline TA is reached. Thus, when t > TA, the mediator informs the opponent about the team\u2019s withdrawal. The mediator also has a very important role in the coordination mechanisms employed by the team to decide upon action (a) and (b). The coordination processes (a) and (b) are described in a detailed way. Furthermore, a finite state machine formalization of the negotiation from the point of view of the mediator can be observed in Fig. 3. It shows the offer construction and the opponent offer acceptance processes.\na) Offer acceptance: When team A has to decide whether or not to accept the opponent\u2019s offer (acA(Xtop\u2192A)), first, the mediator receives the opponent\u2019s offer Xtop\u2192A. This offer is publicly announced to all of the team members by the mediator. Then, the mediator opens a private voting process where each team member ai should specify whether or not it supports acceptance of the opponent\u2019s offer acai(X t op\u2192A).\nA\nB\nC D\nE\nFD F D FD F D\nHow each team member decides whether or not the opponent offer is supported will be described in Subsection II-E. Once every vote has been received, the mediator counts the number of positive votes (votes that support the opponent\u2019s offer). The offer is accepted if the number of positive votes is equal to the number of team members. Otherwise, the offer is rejected. A complete view of this communication protocol can be observed in Fig. 4.\nb) Offer construction: The mediator coordinates an iterated offer-building process in order to ensure unanimity in the offer XtA\u2192op sent to the opponent. For that purpose, each\n5 attribute value is adjusted one by one. Before the iterated process starts, the mediator considers every team member ai as an active member in the offer construction process. Once the iterated offer construction process starts, the trusted mediator selects an attribute j from the set of attributes that have not yet been set. Given the partial offer X\n\u2032t A\u2192op built until the\nmoment, the mediator asks each active team member ai who is interested in j (I(i, j) = true) about the value xai,j needed to get as close as possible to its current aspiration level sai(t). When private responses have been gathered from every team member, the mediator decides a value xj for the attribute j. Here, the morphology of the proposed utility functions comes into play. Due to the fact that team members share the same type of monotonicity for valuation functions, the trusted mediator can aggregate agents\u2019 opinions by means of the max function (monotonically increasing) or the min function (monotonically decreasing). As will be proved in Section III, the value decided for xj ensures unanimity among team members under certain assumptions. The value xj is set in a new partial offer X\n\u2032t A\u2192op which is publicly announced to\nteam members. Then, the mediator asks every active agent in the offer construction process whether or not the new partial offer is satisfactory at round t, ac\u2032ai(X \u2032t A\u2192op). Those agents that agree with the current state of X \u2032t A\u2192op are eliminated from the active list. Those attributes which are not interesting for any team member are maximized according to the opponent\u2019s preferences. The process steps back to the selection of a new attribute j until all of them have been set. A more detailed description of this process can be observed in Fig. 5. As will be reviewed in Section III, when agents comply with certain assumptions, the proposed iterated process is able to reach an offer that is supported by all of the team members at each negotiation round (unanimity). Obviously, the resultant offer depends on the agenda of attributes employed by the mediator. Since unanimity is guaranteed independently of the agenda employed by the mediator, the offer constructed should be as satisfactory as possible for the opponent. Ideally, the team should try to fulfill its own interests with those attributes that are less important for the opponent.\nE. Intra-Team Strategy: Team Members\u2019 Strategy within the Team\nThis subsection specifies how team members answer the mediator\u2019s petitions. On the one hand, during the pre-negotiation, team members decide upon which attribute decision rights are handed over. On the other hand, during the negotiation, agents have to decide whether they accept the opponent\u2019s offer and which values should be set for the offer to be sent to the opponent. The behavior of team members in these decision making processes is described below.\n1) Pre-negotiation: In the pre-negotiation phase, the mediator asks each team member the set of attributes\u2019 decision rights that it is willing to hand over. Its size may range from 0 attributes to the whole set of attributes. How many decision rights ai is willing to hand over depends on an individual and private value ai \u2208 [0, 1]. When ai = 0, the agent is only willing to hand over rights that yield no interest at all (i.e.,\nX \u2032t A\u2192op = \u2205 A\u2032 = A {For each attribute} for j \u2208 N do V = \u2205 {Check opinion of team members who are active in the building phase and are interested in the attribute} for ai \u2208 A\u2032 \u2227 I(i, j) = true do\nAsk for xai,j Receive xai,j V = V \u22c3 xai,j\nend for {Aggregate agents\u2019 opinions} if |V | = 0 then xj = best value for opponent(j) else xj = max(V ) or min(V ) end if X \u2032t A\u2192op = X \u2032t A\u2192op \u22c3 xj Make public new X \u2032t A\u2192op among team members {Update list of agents who are active in the building phase} for ai \u2208 A\u2032 do\nAsk for ac\u2032ai(X \u2032t A\u2192op) Receive ac\u2032ai(X \u2032t A\u2192op) if ac\u2032ai(X \u2032t A\u2192op) = true then\nA\u2032 = A\u2032 \u2212 ai end if\nend for end for XtA\u2192op = X \u2032t A\u2192op\nFig. 5. Negotiation protocol followed by team A and the trusted mediator to build an offer to be sent to the opponent. In this schema, we show the protocol from the point of view of the mediator. The protocol followed by team members is analogous and straight-forward.\nattributes j whose wai,j = 0), whereas when ai = 1, the agent is willing to hand over all of the attributes\u2019 decision rights. The set of attributes NIai whose decision rights are handed over by agent ai follow this equation:\u2211\nj\u2208NIai\nwai,j \u2264 ai (4)\nThus, ai acts as an upper limit that determines the total importance given by ai to the attributes whose decision rights are handed over. Given a value for ai , there are multiple sets NIai that fulfill Eq. 4. A reasonable heuristic is to assume that the agent is willing to concede as many decision rights as possible since this will enhance the possibility of finding an agreement with the opponent. Hence, each team member ai chooses the largest possible set NIai that fulfills Eq. 4.\n2) Negotiation: In the negotiation process, two different decisions are taken by the team: whether or not they accept the opponent\u2019s offer, and which offer is sent to the opponent.\nFirst, the decision making mechanism acai(.), used by each agent ai to decide whether or not it supports the opponent\u2019s offer, is described. It seems appropriate to assume that the\n6 agent will accept the opponent\u2019s offer if it reports a utility that is greater than or equal to the aspiration level marked by the concession strategy in the next round:\nacai(X) = { true if sai(t+ 1) \u2264 Uai(X) false otherwise (5)\nwhere true means that the agent supports the opponent\u2019s offer, false has the opposite meaning, and sai(.) is the concession strategy employed by agent ai to calculate the aspiration level at each negotiation round t. Regarding the concession strategy employed by team members, it is considered that team members have agreed upon a time-based concession strategy with a common \u03b2A. Thus, the concession strategy sai(.) followed by each team member ai can be formalized as depicted below. It is a modification of the well-known concession strategy used in Equation 2.\nsai(t) = (1\u2212 ai)\u2212 (1\u2212 ai \u2212RUai)( t\nTA )\n1 \u03b2A (6)\nFor the expression above, it can be observed that each agent\u2019s aspiration level, despite being governed by the same \u03b2A, depends on the private reservation utility of each agent RUai . ai acts as a limit for the maximum utility demanded by the concession strategy. Since the agent has handed over decision rights for a set of attributes whose weights sum up to ai , the maximum utility that the agent is able to demand by itself is (1\u2212 ai). This is reflected in the equation above.\nSecond, in the case of the iterated construction process, team members take two decisions: which value xai,j is requested for attribute j given the partial offer X\n\u2032t A\u2192op, and whether or\nnot the new partial offer is acceptable ac\u2032ai(X \u2032t A\u2192op). When requesting a value for j, each team member communicates anonymously the value xai,j which gets as close as possible to its desired aspiration level sai(t). This value can be calculated by obtaining the attribute value xai,j whose weighted utility (wai,jVai,j(xai,j)) is the closest to the utility needed by the partial offer in order to reach the desired utility level (sai(t)\u2212 Uai(X \u2032t A\u2192op)) :\nxai,j = argmin x\u2208[0,1]\n(sai(t)\u2212 Uai(X \u2032t A\u2192op)\u2212 wai,jVai,j(x)) (7)\nwhere xai,j is set so that the new offer\u2019s utility does not exceed the aspiration level marked by the concession strategy:\nsai(t)\u2212 Uai(X \u2032t A\u2192op)\u2212 wai,jVai,j(xai,j) \u2265 0 (8)\nOnce the partial offer X \u2032t A\u2192op has been updated by the mediator, those agents that are still active in the construction process are asked whether or not the new offer is acceptable for the current negotiation round. Again, we consider that a partial offer is acceptable for an agent ai if it reports a utility that is greater than or equal to the aspiration level marked by its concession strategy:\nac\u2032ai(X) = { true if Uai(X) \u2265 sai(t) false otherwise (9)\nwhere true indicates that the partial offer is acceptable at its current state for agent ai, and false indicates the opposite. A simplistic trace of a negotiation round, and how team members would behave, can be found in Fig. 6."}, {"heading": "III. THEORETICAL ANALYSIS", "text": "In this section, we analyze some of the important characteristics of our negotiation model in depth. The two main aspects that we analyze are how unanimous decisions are guaranteed regarding team decisions and how robust the proposed model is against manipulations. In the first case, the model assures that each team member gets a utility that is greater than or equal to its current aspiration level. In the second case, we analyze how the proposed model is robust against agents from the opponent, but it is easily attacked by agents from the competition that try to sabotage a deal with the opponent."}, {"heading": "A. Unanimity within the Team", "text": "As mentioned in this article, the proposed negotiation model allows team members to reach unanimity in team\u2019s decisions. These decisions include the offer that is sent to the opponent and the acceptance/rejection of the opponent\u2019s offers. In the latter, it is clear that the proposed acceptance mechanism ensures unanimity since an opponent offer is only accepted when it is considered acceptable by all of the team members. In the former, the definition of unanimity is not straightforward.\nWe define that an offer sent to the opponent XtA\u2192op is a strict unanimous decision for the team when, for any team member ai, the offer reports a utility that is greater than or equal to its current aspiration level sai(t):\n\u2200ai\u2208AUai(XtA\u2192op) \u2265 sai(t) (10)\nAchieving this definition of unanimity within the team ensures that if a final agreement is found, it reports a utility that is greater than or equal to each agent\u2019s private reservation utility. In order to achieve the proposed definition of unanimous decision, some assumptions have to be made regarding the behavior of team members. These assumptions have already been presented in this article. Basically, team members have to be truthful in their responses to the mediator, following the behavior specified in Eq. 7,8 and 9. Next, we prove that, if team members follow these behaviors, unanimity is achieved in team\u2019s decisions according to Equation 10.\nProof: \u2200ai\u2208AUai(XtA\u2192op) \u2265 sai(t) subject to: Eq. 7, Eq. 8, Eq. 9, and the same type of monotonicity for valuation functions Vai,j in team members\u2019 utility functions. For the sake of simplicity, we assume that team members\u2019 valuation functions are monotonically increasing for any negotiation attribute. It should be pointed out that, in that case, the aggregation operation carried out by the trusted mediator is the max operator. In any case, for any attribute j, its value will be determined as xj = max(xa1,j , xa2,j , ..., xaM ,j) and then it holds true that \u2200ai \u2208 A,wai,jVai,j(xj) \u2265 wai,jVai,j(xai,j). The proof is quite straightforward. When the mediator declares that an attribute j must be set, three different situations may arise for an agent ai: \u2022 ai has already reached its aspiration level with the partial\noffer Uai(X \u2032t A\u2192op) \u2265 sai(t). Therefore, the value determined for xj will add utility to the partial offer and the utility reported to ai will further exceed its aspirations Uai(X \u2032t A\u2192op) + wai,jVai,j(xj) \u2265 sai(t).\n7\n\u2022 ai can reach its current aspiration level sai(t) if it asks for a value xai,j . Thus, Uai(X \u2032t A\u2192op)+wai,jVi,j(xai,j) =\nsai(t). Since the aggregation operation is xj = max(xa1,j , xa2,j , ..., xaM ,j), the new partial offer will have a utility that is equal to or greater than its aspirations, Uai(X \u2032t A\u2192op) + wai,jVai,j(xj) \u2265 sai(t). \u2022 ai cannot reach its aspirations by just setting xj . In this case, ai will demand the maximum possible value for j and then xj = xai,j . ai will have to reach its aspiration level by adjusting the next attributes in the agenda. In the worst case scenario, the next attribute to be set xN is the last one in the agenda. This means that ai has demanded the maximum value for the previous attributes and succeeded in getting its desired value for them. Thus, before the last attribute is set, the utility\nreported by the partial offer to ai is N\u22121\u2211 j wai,j . Since\nN\u2211 j wai,j = 1 and 0 \u2264 sai(t) \u2264 1, the agent will reach its aspiration level by demanding a value for xN that\nfulfills Vai,N (xN ) \u2265 sai(t)\u2212\nN\u22121\u2211 j wai,j\nwai,N , which is ensured\nthanks to the morphology of the valuation functions (0 \u2264 Vai,j(x) \u2264 1).\nOne might wonder whether or not it is reasonable to think that agents are truthful in this process. However, members are not tempted to demand lesser value for attributes since the process would not ensure that the final agreement would achieve its current aspiration level. On the other hand, it is true that agents may be inclined to demand a greater value for attributes since the process ensures that the offer will be more profitable for them. Nevertheless, it should be pointed out that, generally, if more value is demanded for attributes the offer may be less profitable for the opponent and the probabilities\nof reaching an agreement may be greatly reduced. This issue is studied in Subsection IV-D, where we analyze whether or not team members have strong incentives to deviate from the proposed behavior."}, {"heading": "B. Manipulation within the Team", "text": "1) Opponent: Here, we refer to agents that infiltrate the team in order to increase the quality of the final agreement from the point of view of the opponent party. In a negotiation team setting formed by buyers, we are concerned about the fact that some seller parties may attempt to introduce agents among team members. This way, opponents may be able to maximize their own preferences by manipulating the decisions taken by the team. However, our proposed negotiation model is robust to this kind of manipulation.\nLet us imagine a situation where a negotiation team wants to buy a product and a seller has been able to infiltrate agents in the team. Due to the mechanism that is employed to build the offer sent to the opponent and the mechanism employed to decide upon whether or not to accept the opponent\u2019s offer, it is not possible for opponent agents to manipulate the decisions taken within the team. Regarding the iterated offer construction process, an opponent agent would try to demand values that are close to the preferences of the opponent. In a generic electronic commerce application, an opponent agent might demand high values for the price and the dispatch date and low values for the product quality. However, the aggregation rules employed by the trusted mediator (max or min depending on the type of monotonic function that represents the preferences of the team members) will ensure that team preferences prevail independently of the number of infiltrated opponent agents. As for the unanimous voting process, opponent agents might try to engage team members in accepting the opponent\u2019s offer. However, this is not possible due to the fact that as long as one team member does not support the opponent\u2019s offer, it will not be accepted. Thus, it does not require further demonstration.\n8 This is the case even in situations where the group of opponent agents is larger than the number of real team members.\nFor instance, let us imagine a negotiation team, formed by 5 buyers, that negotiates with a seller. Two agents (a1, a2) of such team are real buyers, whereas the other three (a3, a4, a5) are agents infiltrated by the seller. The negotiation problem is based on two negotiation attributes, price and quality, whose domains have been scaled to [0, 1]. The valuation function used for the price in the case of the buyers is assumed to be monotonically decreasing (buyers prefer low prices to high prices), and the type of monotonic function used for the quality is assumed to be monotonically increasing (buyers prefer high quality to low quality). Thus, the mediator uses the min function to aggregate the price attribute, and the max function to aggregate the quality attribute. Assuming that the opponent\u2019s valuation functions are of the opposite monotonic type to those of the buyers, team members first demand the following values for the price: xa1,price = 0.1, xa2,price = 0.2, xa3,price = 0.9, xa4,price = 0.85, xa5,price = 1. The mediator aggregates such values and the final value for the attribute price is xprice = min(0.1, 0.2, 0.9, 0.85, 1) = 0.1, which is actually preferred by the two real buyers. Thus, even if the number of opponent agents is larger than the number of real buyers, infiltrated agents from the opponent are not able to manipulate the team. The example for the quality attribute is analogous and does not require further explanation. In the end, the preferences of real buyers will prevail over opponent agents\u2019 demands and the team is not manipulated.\n2) Competitors: Another kind of possible manipulation is the one carried out by competitor agents. Competitors are buyer agents (in the case that the team is made up of buyer agents) that are interested in the same product as the team. Some competitors may be interested in sabotaging team deals if that assures that competitors get better deals from the opponent. This is especially true in environments where goods or services are limited (e.g., personal sellers on Ebay). Thus, competitor agents may attempt to prevent the team from reaching an agreement with the opponent.\nEven though the proposed model is robust against opponent agents, robustness is not maintained when dealing with infiltrated competitor agents. In that case, the strengths shown by the model become its weaknesses. In the voting process carried out to decide upon whether or not to accept the opponent\u2019s offer, only a single agent is needed to manipulate the process and prevent the team from accepting the opponent\u2019s offers. On the other hand, competitor agents may manipulate the offer construction phase by being highly demanding. In a generic electronic commerce application, the competitor agent would demand very low values for the price, short dispatch dates and very high product quality. This way, competitor agents make offers extremely undesirable for opponent agents, preventing the team from reaching a final agreement with the opponent. Due to the aggregation operators employed by the trusted mediator, only one competitor agent is needed to manipulate the offer construction process. Thus, this model should be employed only when team members are extremely sure that no competitor agent has infiltrated the team. It would be possible to employ sophisticated mechanisms to detect these agents;\nhowever this is a topic for future research."}, {"heading": "IV. EMPIRICAL EVALUATION", "text": "In this section, we explore the impact of the different parameters of our proposed model. More specifically, we study the importance of the agenda of issues imposed by the mediator on the negotiation process, the impact of the number of decision rights that are handed over during the pre-negotiation, the empirical robustness of the model against attacks (i.e., agents from the competition that try to sabotage the negotiation), and whether or not team members have incentives to deviate from the proposed strategy."}, {"heading": "A. Studying the Impact of Intra-Team Agenda", "text": "The mediator uses an agenda to determine which attributes are set first in the iterated building process. A reasonable heuristic is to try to satisfy team members with those attributes that are less important for the opponent. Otherwise, the resultant offer may be too demanding and the negotiation process may end in failure. Thus, ideally, the agenda should order the attributes in ascendant order of importance for the opponent.\nHowever, it is acknowledged that the situations where the opponent may reveal its full ranking of preferences are very limited or almost non-existent. Thus, it is necessary to provide the mediator with mechanisms that approximately learn the opponent\u2019s preferences. In this article, we propose a simple learning mechanism that is based on the idea that one agent may concede less in its important attributes during the first negotiation rounds. The mechanism takes into account the offers received in the first k negotiation rounds and sums up the accumulated amount of concession for each negotiation attribute. Then, the mediator orders the attributes in descendant order according to the amount of concession and it becomes the agenda of attributes for the negotiation. If the number of current rounds is lower than k, the agenda is built based on the available information. Thus, in the first few rounds, the learning mechanism is not expected to accurately match the opponent\u2019s preferences; however, as the negotiation process advances, more information is available and the learning mechanism should match the opponent\u2019s preferences better.\nIn the first experiment, we decided to study the importance of the agenda on the negotiation process. While every team member gets a utility that is greater than or equal to its desired aspiration level, the offer may be more or less demanding for the opponent. If the offer is less demanding for the opponent, it is more probable that it will be accepted by him. Therefore, we decided to study the utility reported by the teams\u2019 offer to the opponent at each negotiation round. We simulated a negotiation process where offers are not accepted (i.e., it always reaches the negotiation deadline) just to observe the utility of the offers proposed by the team from the opponent\u2019s perspective. Two different environments were tested: one with a short deadline Top = TA = 10, and one with a long deadline Top = TA = 50. Other parameters were set to the standard values of our negotiation model: \u03b2op = \u03b2A = 1, ai = 0, and RUop = RUai = 0. Three different types of agendas for the FUM model were compared: a perfect agenda where\n9 the mediator knows perfectly the order of importance given by the opponent (FUM-perfect); the simple learning method described above (FUM-simple); and a random agenda that is built at each negotiation round (FUM-random). For FUMsimple, the number of initial negotiation rounds to be taken into account was set to k = bTA4 c. Additionally, the proposed negotiation model is compared with a representative model (RE) and a similarity simple voting model (SSV) which were proposed in our previous work [4]. On the one hand, the representative model does not assure any kind of consensus among team members. One of the team members is chosen as representative and decides on behalf of the team according to its own private utility function. On the other hand, SSV uses majority/plurality to take team decisions. Each round, each team member is allowed to propose an offer to be sent to the opponent. This offer is proposed based on a similarity heuristic that considers the last opponent\u2019s offer and the last offer proposed by team members in the previous round. These two models are expected to be less demanding in terms of utility due to the fact that less conflict is introduced with the opponent (i.e., a fewer number of team members may reach their aspiration level). A total of 100 random teams with size M = 4 and random utility functions (4 attributes) were confronted with 11 randomly generated opponents. In order to capture stochastic variations in the different models, each possible negotiation was repeated 4 times. Thus, a total of 4400 negotiations were carried out per model and environment (i.e., short/long deadline). The results for this first experiment can be observed in Fig. 7.\nAs can be observed in the short deadline scenario (Fig. 7), the offers proposed by the representative model are more attractive for the opponent. This is reasonable since, in this case, the representative only negotiates attending to its own utility function. Therefore, it results in less conflict with the opponent and more trade-off possibilities. The behavior observed for the perfect agenda model and the similarity simple voting model are more surprising. Even though, in the first rounds, SSV proposes offers that report more utility for the opponent than those built by the perfect agenda model, as the negotiation advances, the perfect agenda model outperforms SSV. This happens at negotiation round 6. This may be explained by the fact that, at that point, more trade-off possibilities arise between all of the team members and the opponent, and the perfect agenda model is capable of exploiting them while assuring the desired aspiration level for each teammate. As for the simple agenda model, it performs slightly better than the random agenda model, but worse than the other methods in the experiment. This is explainable by the fact that, since the negotiation deadline is short, limited information can be used to learn the opponent\u2019s preferences. Consequently, the agenda built is closer to a random agenda than to the perfect agenda. In the case of the long deadline scenario, a similar tendency can be observed. Nevertheless, there are some differences that are worth highlighting. First, the representative model is still the one that is the most attractive for the opponent\u2019s interests. However, in this scenario, both the perfect agenda model and the simple agenda model are able to outperform SSV at some points of the negotiation process. Obviously, this\n0\n0.1\n0.2\n0.3\n0.4\n0.5\n0.6\n0.7\n0.8\n0.9\n1\n1 2 3 4 5 6 7 8 9 10\nU til\nity\nNegotiation Round\nUtility reported to the opponent from the team\u2019s offer at each round\nRepresentative Similarity Simple Voting\nFull Unanimity Mediated (Random Agenda) Full Unanimity Mediated (Simple Agenda) Full Unanimity Mediated (Perfect Agenda)\n0\n0.1\n0.2\n0.3\n0.4\n0.5\n0.6\n0.7\n0.8\n0.9\n1\n10 20 30 40 50\nU til\nity\nNegotiation Round\nUtility reported to the opponent from the team\u2019s offer at each round\nRepresentative Similarity Simple Voting\nFull Unanimity Mediated (Random Agenda) Full Unanimity Mediated (Simple Agenda) Full Unanimity Mediated (Perfect Agenda)\nFig. 7. The upper graphic shows the average utility reported to the opponent by the team\u2019s proposal at each negotiation round for the short deadline scenario. The lower graphic shows the results for the long deadline scenario.\nhappens earlier for the perfect agenda model since it represents perfect knowledge about the opponent\u2019s preferences. Hence, it is able to take advantage of possible trade-offs earlier in the negotiation. It happens approximately at round 22. Regarding the simple agenda model, it is able to outperform SSV around round 33. Differently to the first scenario, since the amount of information to learn from is greater, the simple agenda model is able to get closer to the perfect agenda and offer more attractive offers to the opponent.\nIn conclusion, methods proposed in the literature like RE and SSV (in the short deadline scenario) are less demanding for the opponent; however it should be pointed out that they do not ensure unanimity as FUM. Thus, the preferences of all the team members are not represented in the deals found by RE and SSV. In fact, we ran additional tests to ascertain this conclusion. The experimental conditions were set to the same parameters found in this first batch of experiments, but in this experiment the two parties were able to accept offers, thus ending the negotiation before the deadline. We tested the performance of RE, SSV, and FUM-simple according to different quality measures such as the minimum utility of the team members and the average utility of the team members. The results of this experiment can be observed in Table I.\n10\nAs shown, FUM-simple is able to obtain better agreements in terms of utility (both measures) for the team members. Thus, the results suggest the aforementioned claim: even though RE and SSV are less demanding for the opponent, they do not represent the preferences of the team members as FUM does."}, {"heading": "B. Studying the Impact of ai", "text": "In this second experiment, we decided to study the impact of ai on the team\u2019s performance. It seems reasonable to think that low values of this parameter should help to construct offers that are more interesting for the opponent, but high values should impact negatively on the utility obtained by ai. We devised an experiment where the value of ai was set in a uniform way for all of the team members. More specifically, we used the values 0, 0.02, 0.05, 0.07, 0.1, 0.12, 0.15, 0.17, 0.2 for ai . For the quality measures, we observed the minimum and the average utility of the team members. Two different environments were tested: short/long deadline, whose lengths are drawn from the uniform distributions Top = TA = U [5, 10], Top = TA = U [30, 60], respectively. The concession speed for both parties was set to be drawn from \u03b2op = \u03b2A = U [0.4, 0.99] since initial experiments have suggested that boulware strategies may provide more utility for both parties in absence of other outside options [4]. The reservation utility for the agents was drawn from a uniform distribution RUop = RUai = U [0, 0.25]. In this case, the learning method for the agenda was set to FUM-simple and the number of initial rounds to be taken into account was set to k = bTA4 c. A total of 100 randomly generated teams with size M = 4 and random utility functions (4 attributes) were confronted with 12 randomly generated opponents. Each possible negotiation was repeated 4 times. Thus, a total of 4800 negotiation were carried out per model and environment. The results for this experiment are shown in Table II.\nThe results show a slight decrease in the utility (minimum utility and average utility) as ai gets larger. This behavior is found in almost every scenario tested. Those configurations that do not show this pattern usually obtain very similar results for all of the configurations. Thus, the agents should choose ai = 0 independently of the type of scenario where they negotiate. In the best case, the agent will get a slightly better utility than other values of the parameter. In the worst case scenario, the agent will get a very similar utility to other values of the parameter ai . The value ai = 0 corresponds to the agents only handing over those decision rights associated to attributes that yield no interest at all for the agent.\nIt can also be observed that the average utility is impacted more negatively by increment of the ai parameter in the long deadline scenario than in the short deadline scenario. A thorough analysis of our results gave an answer to this phenomenon. The results suggest that higher values of ai reduce the average utility for the team members. However, the number of negotiations that ended with no agreement in the long deadline scenario when ai = 0 was 151 (3.1% of the negotiation cases ended with an average utility equal to 0), whereas the number of failed negotiations was 404 (8.41%) when ai = 0 and the deadline was short. As ai was increased to 0.2, the number of failed negotiations decreased to 35 (0.7%) in the long deadline scenario and 91 (1.8%) in the short deadline scenario. Thus, higher values for ai contribute to reaching an agreement in cases where no deal was found. This effect is more notorious in the short deadline scenario. Since the number of failed negotiations is greatly reduced in the short deadline scenario, the negative effect of higher ai is moderated since the new negotiations contribute with values for the average utility that are greater than or equal to 0. Despite this, the reduction in the number of failed negotiations is not enough to counter the negative impact of ai .\nIn general, ai can be considered as some sort of moderator for the initial demand. According to our results, in general, agents should not give up any decision right over an attribute that yields interest for him. Only those decision rights associated to attributes that yield no interest at all should be handed over. Hence, team members should always start demanding their highest aspiration level. This situation resembles results obtained in bilateral negotiation [6], where it was found that if the deadline is reasonably long, the agent should start demanding values close to their maximum utility."}, {"heading": "C. Studying the Impact of Infiltrated Competitors", "text": "In Section III, we described the robustness of the proposed negotiation model against agents that try to sabotage the negotiation team. It was shown that agents from the opponent may not be able to manipulate the negotiation process. Nevertheless, when agents from the competition infiltrate the team, they may be able to stop the team from reaching an agreement. Thus, one of our concerns is how different levels of risk may affect the performance of teams acting according\n11\nto our model. We decided to test the performance of FUM in different adverse negotiation scenarios.\nThese scenarios differ in the probability P that at least one of the team members comes from the competition. The infiltrated agent tries to stop the team from reaching an agreement with the opponent. To do so, the agent always rejects the offer received from the opponent and is extremely demanding when asking for value in the iterated offer building process. Since an agent that always asks for the most demanding value can be easily spotted (i.e., the agent does not concede at all), we decided to model this competitor agent as an agent that tries to mimic a team member with a high reservation utility RUai . This way, the agent concedes during the negotiation process, but its requests are always high since its reservation utility is high. Hence, we decided that the infiltrated agent would follow the same concession strategy as the rest of the teammates, but the infiltrated agent would have an unexpectedly high reservation utility drawn from the uniform distribution RUai = U [0.8, 1.0]. According to this strategy, an infiltrated agent would be more difficult to identify than an agent that always asks for the most demanding value. However, this does not assure that the team will be sabotaged. This will also depend on other factors such as deadline lengths and concession strategies carried out by both parties.\nIn this experiment, we propose to analyze the performance of the FUM model in scenarios where P = {0, 25, 50, 75, 100%}. Additionally, we include two modifications of FUM with two different unanimity levels: 50% (FUM50), and 75% (FUM75). These levels of unanimity are applied when accepting the opponent\u2019s offer. The infiltrated agent will act according to the \u03b2A = U [0.4, 0.99] imposed by the team, but he will act as an agent with a high reservation utility RU = U [0.8, 1.0]. The reservation utility for the rest of the agents was drawn from a uniform distribution RUop = RUai = U [0, 0.25]. As in previous experiments, the concession speed of the opponent was set to \u03b2op = U [0.4, 0.99] and we simulated two different scenarios: one with short deadlines (TA = Top = U [5, 10]) and one with long deadlines (TA = Top = U [30, 60]). For ai , it was set to ai = 0 since the previous experiment showed that it may be more beneficial in terms of utility to team members. The learning method for the agenda was set to FUM-simple and the number of initial negotiation rounds to be taken into account was set to k = bTA4 c. A total of 100 randomly generated teams with size M = 4 and random utility functions (4 attributes) were confronted with 12 randomly generated opponents. Each negotiation was repeated 4 times. Thus, a total of 4800 negotiations were carried out per model and environment. The results are shown in Table III.\nThe results showed the expected tendency: as the probability P increased, the utilitarian values for the team members decreased. This effect is observable due to the fact that the environment was more distrustful and the agents were able to successfully sabotage the team by acting as highly demanding team members. The average utility of the team members was reduced by 67%-73% in the highest risk scenario for FUM. As a solution for this problem, other unanimity rules could be useful. In fact, it can be observed that when P is high,\nFUM50 and FUM75 perform better than FUM and are not so affected by the infiltrated agent (16%-33% performance reduction for FUM75 in the highest risk scenario, and 9%- 10% performance reduction for FUM50). Thus, it is acknowledged that without any additional mechanism (e.g., trust and reputation models [8]) the proposed negotiation model is not convenient for scenarios where it is very likely that competitor agents may enter a team. In cases where there is a high risk of encountering manipulators, models based on majority/plurality voting paradigms such as SSV [4] or modifications of FUM like FUM50 and FUM75 may prove to be more fit since a large number of competitor agents may be needed to sabotage the negotiation. However, the unanimity would not be assured anymore, which we consider highly desirable for teams."}, {"heading": "D. Strategy Deviation", "text": "The proposed model assumes that team members state the truth when asked about which attribute values they need to reach their desired utility level during the offer construction phase. When dealing with selfish agents, one risk faced is the fact that selfish agents may not tell the truth in order to maximize their own utility. In this case, it seems clear that team members have no incentives to ask for less attribute value than they need since it may end up in an agreement with a utility inferior to the desired level of utility. However, team members may have incentives to demand more value if that maximizes their utilities (be more demanding). For a team member to play strategically, it would need to have some knowledge about team members\u2019 and opponent\u2019s utility functions, deadlines, reservation utilities, and other agents\u2019 strategies. We aim to propose negotiation models for open environments, where information is private. Therefore, agents usually have limited and uncertain information regarding the negotiation conditions. This leads to the question of whether or not team members would achieve higher utilities by deviating from the proposed strategy.\nIn this subsection we analyze whether or not team members have incentives to deviate from the proposed strategy in the offer construction phase. For this matter, we designed two types of deviated team members. The first type of deviated agent, which we will name slightly deviated, behaves exactly as the standard behavior proposed for team members in this article. However, during the iterated offer construction phase, the agent does not ask for the value it needs from attribute j, but a value that reports higher utility than it needs. The amount\nof extra utility that it attempts to achieve is controlled by a parameter di. When di > 1, the team member demands more value than it needs, as it can be appreciated in the formula:\nxai,j = argmin x\u2208[0,1]\n(di\u00d7 (sai(t)\u2212Uai(X \u2032t A\u2192op))\u2212wai,jVai,j(x))\n(11) When the utility of the partial offer exceeds or equals the desired utility level sai(t), the agent abandons the offer construction phase at that round. The effect of this behavior is that, when the agent is asked to set an attribute which can report the desired utility, it demands more value for that attribute and then leaves the iterated building process. For instance, if a seller agent needs 0.50 for the price attribute in order to reach its desired utility level and di = 1.25, it will ask for 0.50 \u00d7 1.25 = 0.625 instead. The second type of deviated team member, named highly deviated, behaves as the slightly deviated team member but when it has reached its desired utility level, it stays an additional attribute in the iterated building process. When asked about the value of that extra attribute, the highly deviated agent asks for a random value that reports between 10% and 50% of the attribute\u2019s utility. For instance, assuming that the price is scaled between 0 and 1, a highly deviated seller that has reached its desired utility level would ask for a price value between 0.1 and 0.5. After setting the extra negotiation attribute, the highly deviated team member leaves the offer construction phase.\nWe set the parameters of our model to the same values used in the previous experiment: TA = Top = U [30, 60] for long deadline scenarios, TA = Top = U [5, 10] for short deadline scenarios, RUai = RUop = U [0, 0.25],and \u03b2A = \u03b2op = U [0.4, 0.99]. A total of 100 randomly generated teams with size M = 4 and random utility functions (4 attributes) were confronted with 12 randomly generated opponents. Each possible negotiation was repeated 4 times. Thus, a total of 4800 negotiations were carried out per model and environment. We studied the effect of the number of slightly deviated agents |A|sd = {1, 2, 3, 4} (the rest of team members having the standard behavior), the effect of the number of highly deviated agents |A|hd = {1, 2, 3, 4} (the rest of team members having the standard behavior), and different values for di = {1.25, 1.50, 1.75} (all of the deviated agents were set to have the same di). The quality measure studied was the average utility since an increment in the utility of one of the team members will always have a positive effect on the average utility (same type of valuation functions). The results of the experiment are depicted in Table IV. We only show the results for the long deadline scenario, but it should be noted that the same pattern was found for short deadline scenarios. It can be observed that all the combinations obtain similar results in terms of average utility. There is only a slight decrement in the average utility as we move to more demanding attitudes (e.g., |A|hd = 4, di = 1.75). Even though, the differences between the most demanding behaviors and other behaviors are not large enough to be considered significant. Thus, the experimental results suggest that team members may not have incentives to deviate much from the proposed strategy. A closer look at the negotiation traces explained the previous results. While being more demanding may obtain higher\nutilities in successful negotiations, it may also lead to a higher number of failed negotiations, thus leading to lower or equal average utilities. These results can be observed also at Table IV, where there is a clear tendency for the number of failed negotiations to increase as team members deviate further from the standard behavior."}, {"heading": "V. RELATED WORK", "text": "In the last few years, there has been growing interest in multiagent systems as a support for complex and distributed systems. Among these complex systems, there is special interest in scenarios where multiple agents, with possibly conflicting goals, cooperate with each other to reach their own goals. The benefits of cooperation and coordination are well known, and, as stated by Klein [9], computer systems may help us to identify and apply the appropriate coordination mechanism. Due to the inherent conflict among agents, techniques that allow agents to solve their own conflicts and cooperate are needed. This need is what has given birth to a group of technologies which have recently been referred to as agreement technologies [10]. Trust and reputation [8], norms [11], agent organizations [12], [13], argumentation [14], [15] and automated negotiation [16], [17] are part of the core that makes up this new family of technologies.\nDespite being part of agreement technologies, automated negotiation has been studied by scholars for a few years. Automated negotiation consists of an automated search process for an agreement between two or more parties where participants exchange proposals. Two different research trends can be distinguished in automated negotiation models. The first type of model aims to calculate the optimum strategy given certain information about the opponent and the negotiation environment [18], [19]. The second type of model encloses heuristics that do not calculate the optimum strategy but obtain results that aim to be as close to the optimum as possible [6],\n13\n[20], [21], [7]. These models assume imperfect knowledge about the opponent and the environment, and aim to be computationally tractable while obtaining good results. This present work can be classified into the latter type of models.\nMost of the research has concentrated on bilateral models where each party is a single individual. Our article studies bilateral negotiations where at least one of the parties is a negotiation team, made up of more than a single individual. It should be noted that the problem of finding an agreement for a negotiation team is inherently complex since it not only requires finding an agreement with the other party but it also entails reaching some type of consensus within the team. Even though communications with the opponent party may be similar to classic bilateral models, negotiation teams may require an additional level of negotiation that involves team members. Thus, classical bilateral models cannot be applied directly if a certain level of consensus is necessary regarding team decisions. As far as we know, our previous work is [4] is the only work that focuses on negotiation teams. Despite that, bilateral negotiation is perhaps the most similar topic to our current research. Hence, we describe some of the most important negotiation models that use imperfect knowledge. A brief overview of these models can be observed in Table V.\nFaratin et al. [6] propose a non-mediated bilateral negotiation model for service negotiation where agents apply and mix different concession tactics (i.e., time-dependent, imitative and resource-dependent). In their work, they analyze the impact of the model\u2019s parameters and determine which configurations work better in different scenarios by means of experiments. Our proposed work also assumes the use of time-dependent concession strategies for the calculation of agents\u2019 aspirations at each negotiation round. Additionally, we also take an experimental approach to validate the impact of our model\u2019s parameters. Later, the authors proposed a nonmediated bilateral negotiation model [21] whose main novelty was the use of trade-offs to improve agreements between two parties. A trade-off consists of reducing the utility obtained from some negotiation issues with the goal of obtaining the same exact utility from other negotiation issues. The rationale behind trade-offs is to make the offer more likable for the opponent while maintaining the same level of satisfaction for the proposing agent. For that purpose, the authors propose a fuzzy similarity heuristic that proposes the most similar offer to the last offer received from the opponent. Our model does not leave room for trade-offs since the offer that is calculated\nat each negotiation round is deterministic with respect to the agenda of issues and the current aspiration level of team members. However, its main strength lies in the fact that it is capable of guaranteeing the desired level of utility for each team member at each round.\nJonker and Treur propose the Agent-Based Market Place (ABMP) non-mediated model [20] where agents, engage in bilateral negotiations. ABMP is a negotiation model where proposed bids are concessions to previous bids. The amount of concession is regulated by the concession factor (i.e., reservation utility), the negotiation speed, the acceptable utility gap (maximal difference between the target utility and the utility of an offer that is acceptable), and the impatience factor (which governs the probability of the agent leaving the negotiation process).\nLai et al. [7] propose a non-mediated bilateral negotiation model where agents are allowed to propose up to k different offers at each negotiation round. Offers are proposed from the current iso-utility curve according to a similarity mechanism that selects the most similar offer to the last offer received from the opponent. The selected similarity heuristic is the Euclidean distance since it is general and does not require domainspecific knowledge and information regarding the opponent\u2019s utility function. Results showed that the strategy is capable of reaching agreements that are very close to the Pareto Frontier. Sanchez-Anguix et al. [17] proposed an enhancement for this non-mediated strategy in environments where computational resources are very limited and utility functions are complex. It relies on genetic algorithms to sample offers that are interesting for the agent itself and creates new offers during the negotiation process that are interesting for both parties. Results showed that the model is capable of obtaining statistically equivalent results to similar models that had the full iso-utility curve sampled, while being computationally more tractable.\nAnother topic that resembles team negotiations are multiparty negotiations. Several works have been proposed in the literature along this line [22], [23], [24]. For instance, Ehtamo et al. [22] propose a mediated multi-party negotiation protocol which looks for joint gains in an iterated way. The algorithm starts from a tentative agreement and moves in a direction according to what the agents prefer regarding some offers\u2019 comparison. Results showed that the algorithm converges quickly to Pareto optimal points. Klein et al. [23] propose a mediated negotiation model which can be extended to multiple parties. Their main goal is to provide solutions for negotiation processes that use complex utility functions to model agents\u2019 preferences. The negotiation attributes are no longer independent, and, thus, preference spaces cannot be explored as easily as in the linear case. Later, Ito et al. [24] proposed different types of utility functions (cube and cone constraints) and multiparty mediated negotiation models that obtain good quality results for the proposed utility functions. The main difference between our work and multiparty negotiations lies in the nature of the conflict and how protocols are devised. Even though each team member could be viewed as a participant in a multi-party negotiation with the opponent, it is natural to think that team members\u2019 preferences are more similar (e.g., a team of buyers, a group of friends,\n14\netc.) and they trust other teammates more than the opponent (i.e., they may share more information). Furthermore, multiparty negotiation models may be unfair for agents that are alien to the team if the number of team members exceeds the number of other participants. In that case, multi-party models may be inclined to move the negotiation towards agreements that maximize the preferences of team members.\nMulti-agent teamwork is also a close research topic. Agent teams have been proposed for a variety of tasks such as Robocup [25], rescue tasks [26], and transportation tasks [27]. However, as far as we know, there is no published work that considers teams of agents negotiating with an opponent. Most works in agent teamwork consider fully cooperative agents that work to maximize shared goals. The team negotiation setting is different since, even though team members share a common interest related to the negotiation, there may be competition among team members to maximize one\u2019s own preferences.\nFinally, given the results obtained by our proposed model, consensus building should be mentioned as a close research topic outside agent research. Our proposed model is capable of attaining consensus/unanimity regarding team decisions under the assumption of private information. Consensus building works like [28], [29] usually take the assumption that all the information regarding parties is available to a trusted mediator. Cook et al. [28], generalize the use of distance-based measures to obtain consensus over multiple decision makers with ordinal preferences by assigning utility weights to ordinal positions. They show that this representation is equivalent to the commonly used model of using ordinal positions as utility weights for options. Herrera-Viedma et al. [29] propose a computational model that is able to help humans/experts to reach soft consensus over a set of alternatives. The model is based on an iterative process where two measures are used to achieve this result: a soft consensus measure, and a proximity measure. Both measures are used to evaluate how close the individual expert opinion with respect to the collective opinion is, and help the computational system to provide feedback to experts that are far from the group\u2019s opinion. Even though the goal is similar to our work, the assumptions are different. We advocate for open systems like e-commerce systems, where agents act semi-automatically on behalf of their users. Since any type of agent can be found in open environments, privacy is a big concern due to distrust and risk of exploitation. Thus, it is not possible for a mediator to know the preferences and all of the information about the participants in the negotiation. In our approach, we only consider that a limited amount of information is transmitted to the mediator."}, {"heading": "VI. CONCLUSIONS AND FUTURE WORK", "text": "In this article, we have proposed an agent-based negotiation model for negotiation teams that interact with an opponent using the bilateral alternating protocol in electronic systems. A negotiation team is a group of two or more agents that join together as a single negotiation party because they share a common goal which is related to the negotiation process. Thus, as a team, they have to decide which offers are sent to the opponent and whether or not the offers received from\nthe opponent are acceptable. The main strength of our proposed model lies in the fact that decisions within the team are unanimous (i.e., the utility reported by the decision is greater than or equal to the desired utility level by each team member). The negotiation model relies on a trusted mediator that coordinates voting processes, regulates an iterated process for offer construction, and guarantees unanimity.\nAfter describing our proposal, we have shown how the model is capable of ensuring unanimity regarding team decisions. Then, we theoretically analyzed the robustness of our model against different types of attacks. The proposed model is robust against manipulations from the opponent, but it is sensitive to manipulations coming from agents from the competition that try to sabotage a possible agreement with the opponent. We also presented different experiments analyzing the impact of different parameters of the model such as the negotiation agenda followed by the mediator to decide which attributes are set first, and the impact of the number of attribute decision rights that are handed over by team members prior to the negotiation. Additionally, we carried out an empirical evaluation of the robustness of the proposed model against attacks from agents that represent the competition, which reflects our initial concerns in the theoretical analysis. Finally, we studied whether or not team members have incentives to deviate from the proposed strategy. Empirical results suggest that there is not much incentive to deviate from the proposed strategy since deviations may impact the number of failed negotiations and, thus, the average utility.\nFuture work includes the evaluation of the present negotiation model and other models proposed in the literature [4] in different negotiation scenarios. The rationale behind this analysis is to determine which strategies are more appropriate for team members according to different criteria such as utilitarian measures (minimum, average, maximum) and computational measures (number of messages exchanged, number of negotiation rounds). Our goal is using this knowledge in a decision-making mechanism that allows teams to select the most appropriate negotiation model according to their needs.\nWe acknowledge that the current model is capable of reaching unanimity given the assumption of monotonic valuation functions and linear utility functions. Therefore, future work also includes exploring aggregation mechanisms that reach consensus/soft consensus for non-monotonic attributes like colors, brands, etc. In this sense, fuzzy consensus/similarity measures as the ones proposed in [21], [29] can help to aggregate agents\u2019 opinions over this type of attributes.\nMoreover, in the last few years there has been a growing interest in modeling negotiation as a dynamic process [30], [31]. Despite being an interesting approach, its study is still at early stages and focused on simple negotiations, while our current model involves a negotiation team, and a negotiation party, which increments the complexity of the modeling problem. In this sense, the use of new search and optimization algorithms like gravitational search algorithms [32], pomdp [31], and machine learning approaches with efficient data selection [33] can help to further improve the state of the art in negotiation. Nevertheless, dynamic modeling of agent negotiation teams is a topic that should be studied in the future.\n15"}], "references": [{"title": "Negotiation within and between groups in organizations: Levels of analysis", "author": ["S. Brodt", "L. Thompson"], "venue": "Group Dynam., pp. 208\u2013219, 2001.", "citeRegEx": "1", "shortCiteRegEx": null, "year": 2001}, {"title": "Team negotiation: Social, epistemic, economic, and psychological consequences of subgroup conflict", "author": ["N. Halevy"], "venue": "Pers. Soc. Psychol. Bull., vol. 34, pp. 1687\u20131702, 2008.", "citeRegEx": "2", "shortCiteRegEx": null, "year": 2008}, {"title": "Towards agent-based negotiation teams", "author": ["V. S\u00e1nchez-Anguix", "V. Julian", "V. Botti", "A. Garc\u0131\u0301a-Fornes"], "venue": "Group Decision and Negotiation 2010, 2010, pp. 328\u2013331.", "citeRegEx": "3", "shortCiteRegEx": null, "year": 2010}, {"title": "Analyzing Intra-Team Strategies for Agent-Based Negotiation Teams", "author": ["\u2014\u2014"], "venue": "10th International Conference on Autonomous Agents and Multiagent Systems, 2011, pp. 929\u2013936.", "citeRegEx": "4", "shortCiteRegEx": null, "year": 2011}, {"title": "Perfect equilibrium in a bargaining model", "author": ["A. Rubinstein"], "venue": "Econometrica, vol. 50, no. 1, pp. 97\u2013109, 1982.", "citeRegEx": "5", "shortCiteRegEx": null, "year": 1982}, {"title": "Negotiation decision functions for autonomous agents", "author": ["P. Faratin", "C. Sierra", "N.R. Jennings"], "venue": "Robot. Autonom. Syst., vol. 24, no. 3-4, pp. 159\u2013182, 1998.", "citeRegEx": "6", "shortCiteRegEx": null, "year": 1998}, {"title": "A decentralized model for automated multi-attribute negotiations with incomplete information and general utility functions", "author": ["G. Lai", "K. Sycara", "C. Li"], "venue": "Multiagent and Grid Systems, vol. 4, no. 1, pp. 45\u201365, 2008.", "citeRegEx": "7", "shortCiteRegEx": null, "year": 2008}, {"title": "Review on computational trust and reputation models", "author": ["J. Sabater", "C. Sierra"], "venue": "Artif. Intell. Rev., vol. 24, no. 1, pp. 33\u201360, 2005.", "citeRegEx": "8", "shortCiteRegEx": null, "year": 2005}, {"title": "Coordination science: Challenges and directions", "author": ["M. Klein"], "venue": "Coordination Technology for Collaborative Applications-Organizations, Processes, and Agents, 1998, pp. 161\u2013176.", "citeRegEx": "9", "shortCiteRegEx": null, "year": 1998}, {"title": "Agreement computing", "author": ["C. Sierra", "V. Botti", "S. Ossowski"], "venue": "KI- Kunstliche Intelligenz, pp. 1\u20135, 2011.", "citeRegEx": "10", "shortCiteRegEx": null, "year": 2011}, {"title": "Autonomous agents with norms", "author": ["F. Dignum"], "venue": "Artif. Intell. Law, vol. 7, no. 1, pp. 69\u201379, 1999.", "citeRegEx": "11", "shortCiteRegEx": null, "year": 1999}, {"title": "A survey of multi-agent organizational paradigms", "author": ["B. Horling", "V. Lesser"], "venue": "Knowl. Eng. Rev., vol. 19, no. 04, pp. 281\u2013316, 2004.", "citeRegEx": "12", "shortCiteRegEx": null, "year": 2004}, {"title": "Formalizing Virtual Organizations", "author": ["S. Esparcia", "E. Argente"], "venue": "3rd International Conference on Agents and Artificial Intelligence, vol. 2, 2011, pp. 84\u201393.", "citeRegEx": "13", "shortCiteRegEx": null, "year": 2011}, {"title": "Argumentation-based negotiation", "author": ["I. Rahwan", "S. Ramchurn", "N. Jennings", "P. Mcburney", "S. Parsons", "L. Sonenberg"], "venue": "Knowl. Eng. Rev., vol. 18, no. 04, pp. 343\u2013375, 2003.", "citeRegEx": "14", "shortCiteRegEx": null, "year": 2003}, {"title": "Multiagent Argumentation for Cooperative Planning in DeLP-POP", "author": ["P. Pardo", "S. Pajares", "E. Onaind\u0131\u0301a", "L. Godo", "P. Dellunde"], "venue": "10th International Conference on Autonomous Agents and Multiagent Systems, 2011, pp. 971\u2013978.", "citeRegEx": "15", "shortCiteRegEx": null, "year": 2011}, {"title": "Automated negotiation: Prospects, methods and challenges", "author": ["N.R. Jennings", "P. Faratin", "A.R. Lomuscio", "S. Parsons", "M.J. Wooldridge", "C. Sierra"], "venue": "Group Decis. Negot., vol. 10, pp. 199\u2013215, 2001.", "citeRegEx": "16", "shortCiteRegEx": null, "year": 2001}, {"title": "Evolutionary-aided negotiation model for bilateral bargaining in Ambient Intelligence domains with complex utility functions", "author": ["V. S\u00e1nchez-Anguix", "S. Valero", "V. Julian", "V. Botti", "A. Garc\u0131\u0301a- Fornes"], "venue": "Inf. Sci., 2010.", "citeRegEx": "17", "shortCiteRegEx": null, "year": 2010}, {"title": "Agenda restrictions in multi-issue bargaining (ii): unrestricted agendas", "author": ["Y. In", "R. Serrano"], "venue": "Econ. Lett., vol. 79, no. 3, pp. 325\u2013331, 2003.", "citeRegEx": "18", "shortCiteRegEx": null, "year": 2003}, {"title": "Multi-issue negotiation with deadlines", "author": ["S.S. Fatima", "M. Wooldridge", "N.R. Jennings"], "venue": "J. Artif. Intell. Res., vol. 27, pp. 381\u2013417, 2006.", "citeRegEx": "19", "shortCiteRegEx": null, "year": 2006}, {"title": "An agent architecture for multi-attribute negotiation", "author": ["C.M. Jonker", "J. Treur"], "venue": "17th International Joint Conference on Artificial Intelligence, 2001, pp. 1195\u20131201.", "citeRegEx": "20", "shortCiteRegEx": null, "year": 2001}, {"title": "Using similarity criteria to make issue trade-offs in automated negotiations", "author": ["P. Faratin", "C. Sierra", "N.R. Jennings"], "venue": "Artif. Intell., vol. 142, pp. 205\u2013237, 2002.", "citeRegEx": "21", "shortCiteRegEx": null, "year": 2002}, {"title": "Searching for joint gains in multi-party negotiations", "author": ["H. Ehtamo", "E. Kettunen", "R.P. Hamalainen"], "venue": "Eur. J. Oper. Res., vol. 130, no. 1, pp. 54\u201369, 2001.", "citeRegEx": "22", "shortCiteRegEx": null, "year": 2001}, {"title": "Negotiating complex contracts", "author": ["M. Klein", "P. Faratin", "H. Sayama", "Y. Bar-Yam"], "venue": "Group Decis. Negot., vol. 12, no. 2, pp. 111\u2013125, 2003.", "citeRegEx": "23", "shortCiteRegEx": null, "year": 2003}, {"title": "Secure and efficient protocols for multiple interdependent issues negotiation", "author": ["K. Fujita", "T. Ito", "M. Klein"], "venue": "J. Intell. Fuzzy Syst., vol. 21, no. 3, pp. 175\u2013185, 2010.", "citeRegEx": "24", "shortCiteRegEx": null, "year": 2010}, {"title": "Task decomposition, dynamic role assignment, and low-bandwidth communication for real-time strategic teamwork", "author": ["P. Stone", "M. Veloso"], "venue": "Artif. Intell., vol. 110, no. 2, pp. 241\u2013273, 1999.", "citeRegEx": "25", "shortCiteRegEx": null, "year": 1999}, {"title": "Robocup rescue: A grand challenge for multiagent and intelligent systems", "author": ["H. Kitano", "S. Tadokoro"], "venue": "AI Mag., vol. 22, no. 1, pp. 39\u201352, 2001.", "citeRegEx": "26", "shortCiteRegEx": null, "year": 2001}, {"title": "Controlling cooperative problem solving in industrial multi-agent systems using joint intentions", "author": ["N.R. Jennings"], "venue": "Artif. Intell., vol. 75, no. 2, pp. 195\u2013240, 1995.", "citeRegEx": "27", "shortCiteRegEx": null, "year": 1995}, {"title": "A general framework for distance-based consensus in ordinal ranking models", "author": ["W.D. Cook", "M. Kress", "L.M. Seiford"], "venue": "Eur. J. Oper. Res., vol. 96, pp. 392\u2013397, 1996.", "citeRegEx": "28", "shortCiteRegEx": null, "year": 1996}, {"title": "A consensus model for multiperson decision making with different preference structures", "author": ["E. Herrera-Viedma", "F. Herrera", "F. Chiclana"], "venue": "IEEE Trans. Syst. Man Cybern. Part A-Syst. Hum., vol. 32, no. 3, pp. 394\u2013402, 2002.", "citeRegEx": "29", "shortCiteRegEx": null, "year": 2002}, {"title": "Dynamic decision making: A comparison of approaches", "author": ["P.C. Da Costa", "D.M. Buede"], "venue": "J. multi-criteria decis. anal., vol. 9, pp. 243\u2013262, 2000.", "citeRegEx": "30", "shortCiteRegEx": null, "year": 2000}, {"title": "Pomdp based negotiation modeling", "author": ["P. Parachuri", "N. Chakraborty", "R. Zivan", "K. Sycara", "M. Dudik", "G. Gordon"], "venue": "Modeling Intercultural Collaboration and Negotiation Workshop, 2009, pp. 66\u201378.", "citeRegEx": "31", "shortCiteRegEx": null, "year": 2009}, {"title": "Decision function estimation using intelligent gravitational search algorithm", "author": ["H. Askari", "S. Zahiri"], "venue": "Int. J. Mach. Learn. Cybern., pp. 1\u201310.", "citeRegEx": "32", "shortCiteRegEx": null, "year": 0}], "referenceMentions": [{"referenceID": 0, "context": "table [1].", "startOffset": 6, "endOffset": 9}, {"referenceID": 1, "context": "negotiation teams are not necessarily unitary players since team members may have different preferences regarding the possible outcomes of the negotiation process [2].", "startOffset": 163, "endOffset": 166}, {"referenceID": 0, "context": "Despite being studied in social sciences to some extent [1], [2], as far as we know, negotiation teams have been overlooked by artificial intelligence research.", "startOffset": 56, "endOffset": 59}, {"referenceID": 1, "context": "Despite being studied in social sciences to some extent [1], [2], as far as we know, negotiation teams have been overlooked by artificial intelligence research.", "startOffset": 61, "endOffset": 64}, {"referenceID": 2, "context": "team dynamics) [3].", "startOffset": 15, "endOffset": 18}, {"referenceID": 3, "context": "More specifically, our preliminary study presented about this model (Full Unanimity Mediated or FUM) in [4] is extended further.", "startOffset": 104, "endOffset": 107}, {"referenceID": 0, "context": "\u2022 The negotiation domain is comprised of n real-valued attributes whose domain is [0, 1].", "startOffset": 82, "endOffset": 88}, {"referenceID": 0, "context": "Thus, the possible number of offers is [0, 1].", "startOffset": 39, "endOffset": 45}, {"referenceID": 0, "context": ") is a monotonic valuation function that transforms the attribute value to [0, 1], and wi,j is the weight or importance that is given by the agent i to the j-th attribute.", "startOffset": 75, "endOffset": 81}, {"referenceID": 4, "context": "Because of this, we decided to model the interaction between the team and the opponent as an alternating bilateral negotiation process [5].", "startOffset": 135, "endOffset": 138}, {"referenceID": 5, "context": "Thus, a set of well-known negotiation tactics was selected as the opponent negotiation strategy: timedependent tactics [6], [7].", "startOffset": 119, "endOffset": 122}, {"referenceID": 6, "context": "Thus, a set of well-known negotiation tactics was selected as the opponent negotiation strategy: timedependent tactics [6], [7].", "startOffset": 124, "endOffset": 127}, {"referenceID": 6, "context": "We formalized time-dependent tactics as suggested by [7]:", "startOffset": 53, "endOffset": 56}, {"referenceID": 0, "context": "How many decision rights ai is willing to hand over depends on an individual and private value ai \u2208 [0, 1].", "startOffset": 100, "endOffset": 106}, {"referenceID": 0, "context": "xai,j = argmin x\u2208[0,1] (sai(t)\u2212 Uai(X \u2032t A\u2192op)\u2212 wai,jVai,j(x)) (7)", "startOffset": 17, "endOffset": 22}, {"referenceID": 0, "context": "domains have been scaled to [0, 1].", "startOffset": 28, "endOffset": 34}, {"referenceID": 3, "context": "(RE) and a similarity simple voting model (SSV) which were proposed in our previous work [4].", "startOffset": 89, "endOffset": 92}, {"referenceID": 4, "context": "Two different environments were tested: short/long deadline, whose lengths are drawn from the uniform distributions Top = TA = U [5, 10], Top = TA = U [30, 60], respectively.", "startOffset": 129, "endOffset": 136}, {"referenceID": 9, "context": "Two different environments were tested: short/long deadline, whose lengths are drawn from the uniform distributions Top = TA = U [5, 10], Top = TA = U [30, 60], respectively.", "startOffset": 129, "endOffset": 136}, {"referenceID": 29, "context": "Two different environments were tested: short/long deadline, whose lengths are drawn from the uniform distributions Top = TA = U [5, 10], Top = TA = U [30, 60], respectively.", "startOffset": 151, "endOffset": 159}, {"referenceID": 3, "context": "99] since initial experiments have suggested that boulware strategies may provide more utility for both parties in absence of other outside options [4].", "startOffset": 148, "endOffset": 151}, {"referenceID": 5, "context": "This situation resembles results obtained in bilateral negotiation [6], where it was found that if the deadline is reasonably long, the agent should start demanding values close to their maximum utility.", "startOffset": 67, "endOffset": 70}, {"referenceID": 4, "context": "99] and we simulated two different scenarios: one with short deadlines (TA = Top = U [5, 10]) and one with long deadlines (TA = Top = U [30, 60]).", "startOffset": 85, "endOffset": 92}, {"referenceID": 9, "context": "99] and we simulated two different scenarios: one with short deadlines (TA = Top = U [5, 10]) and one with long deadlines (TA = Top = U [30, 60]).", "startOffset": 85, "endOffset": 92}, {"referenceID": 29, "context": "99] and we simulated two different scenarios: one with short deadlines (TA = Top = U [5, 10]) and one with long deadlines (TA = Top = U [30, 60]).", "startOffset": 136, "endOffset": 144}, {"referenceID": 7, "context": ", trust and reputation models [8]) the proposed negotiation model is not convenient for scenarios where it is very likely that competitor agents may enter a team.", "startOffset": 30, "endOffset": 33}, {"referenceID": 3, "context": "In cases where there is a high risk of encountering manipulators, models based on majority/plurality voting paradigms such as SSV [4] or modifications of FUM", "startOffset": 130, "endOffset": 133}, {"referenceID": 0, "context": "xai,j = argmin x\u2208[0,1] (di\u00d7 (sai(t)\u2212Uai(X \u2032t A\u2192op))\u2212wai,jVai,j(x))", "startOffset": 17, "endOffset": 22}, {"referenceID": 29, "context": "We set the parameters of our model to the same values used in the previous experiment: TA = Top = U [30, 60] for long deadline scenarios, TA = Top = U [5, 10] for short deadline scenarios, RUai = RUop = U [0, 0.", "startOffset": 100, "endOffset": 108}, {"referenceID": 4, "context": "We set the parameters of our model to the same values used in the previous experiment: TA = Top = U [30, 60] for long deadline scenarios, TA = Top = U [5, 10] for short deadline scenarios, RUai = RUop = U [0, 0.", "startOffset": 151, "endOffset": 158}, {"referenceID": 9, "context": "We set the parameters of our model to the same values used in the previous experiment: TA = Top = U [30, 60] for long deadline scenarios, TA = Top = U [5, 10] for short deadline scenarios, RUai = RUop = U [0, 0.", "startOffset": 151, "endOffset": 158}, {"referenceID": 8, "context": "The benefits of cooperation and coordination are well known, and, as stated by Klein [9], computer systems may help us to identify and apply the appropriate coordination mechanism.", "startOffset": 85, "endOffset": 88}, {"referenceID": 9, "context": "This need is what has given birth to a group of technologies which have recently been referred to as agreement technologies [10].", "startOffset": 124, "endOffset": 128}, {"referenceID": 7, "context": "Trust and reputation [8], norms [11], agent organizations [12], [13], argumentation [14], [15] and automated negotiation [16], [17] are part of the core that", "startOffset": 21, "endOffset": 24}, {"referenceID": 10, "context": "Trust and reputation [8], norms [11], agent organizations [12], [13], argumentation [14], [15] and automated negotiation [16], [17] are part of the core that", "startOffset": 32, "endOffset": 36}, {"referenceID": 11, "context": "Trust and reputation [8], norms [11], agent organizations [12], [13], argumentation [14], [15] and automated negotiation [16], [17] are part of the core that", "startOffset": 58, "endOffset": 62}, {"referenceID": 12, "context": "Trust and reputation [8], norms [11], agent organizations [12], [13], argumentation [14], [15] and automated negotiation [16], [17] are part of the core that", "startOffset": 64, "endOffset": 68}, {"referenceID": 13, "context": "Trust and reputation [8], norms [11], agent organizations [12], [13], argumentation [14], [15] and automated negotiation [16], [17] are part of the core that", "startOffset": 84, "endOffset": 88}, {"referenceID": 14, "context": "Trust and reputation [8], norms [11], agent organizations [12], [13], argumentation [14], [15] and automated negotiation [16], [17] are part of the core that", "startOffset": 90, "endOffset": 94}, {"referenceID": 15, "context": "Trust and reputation [8], norms [11], agent organizations [12], [13], argumentation [14], [15] and automated negotiation [16], [17] are part of the core that", "startOffset": 121, "endOffset": 125}, {"referenceID": 16, "context": "Trust and reputation [8], norms [11], agent organizations [12], [13], argumentation [14], [15] and automated negotiation [16], [17] are part of the core that", "startOffset": 127, "endOffset": 131}, {"referenceID": 17, "context": "certain information about the opponent and the negotiation environment [18], [19].", "startOffset": 71, "endOffset": 75}, {"referenceID": 18, "context": "certain information about the opponent and the negotiation environment [18], [19].", "startOffset": 77, "endOffset": 81}, {"referenceID": 5, "context": "The second type of model encloses heuristics that do not calculate the optimum strategy but obtain results that aim to be as close to the optimum as possible [6],", "startOffset": 158, "endOffset": 161}, {"referenceID": 5, "context": "[6], [21] No No 2 Jonker et al.", "startOffset": 0, "endOffset": 3}, {"referenceID": 20, "context": "[6], [21] No No 2 Jonker et al.", "startOffset": 5, "endOffset": 9}, {"referenceID": 19, "context": "[20] No No 2 Lai et al.", "startOffset": 0, "endOffset": 4}, {"referenceID": 6, "context": "[7] No No 2 Sanchez-Anguix et al.", "startOffset": 0, "endOffset": 3}, {"referenceID": 16, "context": "[17] No No 2 Ehtamo et al.", "startOffset": 0, "endOffset": 4}, {"referenceID": 21, "context": "[22] No Yes n", "startOffset": 0, "endOffset": 4}, {"referenceID": 22, "context": "[23] No Yes n", "startOffset": 0, "endOffset": 4}, {"referenceID": 23, "context": "[24] No Yes n", "startOffset": 0, "endOffset": 4}, {"referenceID": 3, "context": "(2011) [4] Yes Yes 2", "startOffset": 7, "endOffset": 10}, {"referenceID": 19, "context": "[20], [21], [7].", "startOffset": 0, "endOffset": 4}, {"referenceID": 20, "context": "[20], [21], [7].", "startOffset": 6, "endOffset": 10}, {"referenceID": 6, "context": "[20], [21], [7].", "startOffset": 12, "endOffset": 15}, {"referenceID": 3, "context": "As far as we know, our previous work is [4] is the only work that focuses on negotiation teams.", "startOffset": 40, "endOffset": 43}, {"referenceID": 5, "context": "[6] propose a non-mediated bilateral negotiation model for service negotiation where agents apply and mix different concession tactics (i.", "startOffset": 0, "endOffset": 3}, {"referenceID": 20, "context": "Later, the authors proposed a nonmediated bilateral negotiation model [21] whose main novelty", "startOffset": 70, "endOffset": 74}, {"referenceID": 19, "context": "Jonker and Treur propose the Agent-Based Market Place (ABMP) non-mediated model [20] where agents, engage in bilateral negotiations.", "startOffset": 80, "endOffset": 84}, {"referenceID": 6, "context": "[7] propose a non-mediated bilateral negotiation model where agents are allowed to propose up to k different", "startOffset": 0, "endOffset": 3}, {"referenceID": 16, "context": "[17] proposed an enhancement for this non-mediated strategy in environments where computational resources are very limited and utility functions are complex.", "startOffset": 0, "endOffset": 4}, {"referenceID": 21, "context": "Several works have been proposed in the literature along this line [22], [23], [24].", "startOffset": 67, "endOffset": 71}, {"referenceID": 22, "context": "Several works have been proposed in the literature along this line [22], [23], [24].", "startOffset": 73, "endOffset": 77}, {"referenceID": 23, "context": "Several works have been proposed in the literature along this line [22], [23], [24].", "startOffset": 79, "endOffset": 83}, {"referenceID": 21, "context": "[22] propose a mediated multi-party negotiation protocol which looks for joint gains in an iterated way.", "startOffset": 0, "endOffset": 4}, {"referenceID": 22, "context": "[23] propose a mediated negotiation model which can be extended to multiple parties.", "startOffset": 0, "endOffset": 4}, {"referenceID": 23, "context": "[24] proposed different types of utility functions (cube and cone constraints) and multiparty mediated negotiation", "startOffset": 0, "endOffset": 4}, {"referenceID": 24, "context": "teams have been proposed for a variety of tasks such as Robocup [25], rescue tasks [26], and transportation tasks [27].", "startOffset": 64, "endOffset": 68}, {"referenceID": 25, "context": "teams have been proposed for a variety of tasks such as Robocup [25], rescue tasks [26], and transportation tasks [27].", "startOffset": 83, "endOffset": 87}, {"referenceID": 26, "context": "teams have been proposed for a variety of tasks such as Robocup [25], rescue tasks [26], and transportation tasks [27].", "startOffset": 114, "endOffset": 118}, {"referenceID": 27, "context": "Consensus building works like [28], [29] usually take the assumption that all the information regarding parties is available to a trusted mediator.", "startOffset": 30, "endOffset": 34}, {"referenceID": 28, "context": "Consensus building works like [28], [29] usually take the assumption that all the information regarding parties is available to a trusted mediator.", "startOffset": 36, "endOffset": 40}, {"referenceID": 27, "context": "[28], generalize the use of distance-based measures to obtain consensus over multiple decision makers with ordinal preferences by assigning utility weights to ordinal", "startOffset": 0, "endOffset": 4}, {"referenceID": 28, "context": "[29] propose a computational model that is able to help humans/experts to reach soft consensus over a set of alternatives.", "startOffset": 0, "endOffset": 4}, {"referenceID": 3, "context": "Future work includes the evaluation of the present negotiation model and other models proposed in the literature [4] in different negotiation scenarios.", "startOffset": 113, "endOffset": 116}, {"referenceID": 20, "context": "In this sense, fuzzy consensus/similarity measures as the ones proposed in [21], [29] can help to", "startOffset": 75, "endOffset": 79}, {"referenceID": 28, "context": "In this sense, fuzzy consensus/similarity measures as the ones proposed in [21], [29] can help to", "startOffset": 81, "endOffset": 85}, {"referenceID": 29, "context": "Moreover, in the last few years there has been a growing interest in modeling negotiation as a dynamic process [30], [31].", "startOffset": 111, "endOffset": 115}, {"referenceID": 30, "context": "Moreover, in the last few years there has been a growing interest in modeling negotiation as a dynamic process [30], [31].", "startOffset": 117, "endOffset": 121}, {"referenceID": 31, "context": "In this sense, the use of new search and optimization algorithms like gravitational search algorithms [32], pomdp [31], and machine learning approaches with efficient data selection [33] can help to further improve the state of the art in negotiation.", "startOffset": 102, "endOffset": 106}, {"referenceID": 30, "context": "In this sense, the use of new search and optimization algorithms like gravitational search algorithms [32], pomdp [31], and machine learning approaches with efficient data selection [33] can help to further improve the state of the art in negotiation.", "startOffset": 114, "endOffset": 118}], "year": 2016, "abstractText": "In this article, an agent-based negotiation model for negotiation teams that negotiate a deal with an opponent is presented. Agent-based negotiation teams are groups of agents that join together as a single negotiation party because they share an interest that is related to the negotiation process. The model relies on a trusted mediator that coordinates and helps team members in the decisions that they have to take during the negotiation process: which offer is sent to the opponent, and whether or not the offers received from the opponent are accepted. The main strength of the proposed negotiation model is the fact that it guarantees unanimity within team decisions since decisions report a utility to team members that is greater than or equal to their aspiration levels at each negotiation round. This work analyzes how unanimous decisions are taken within the team and the robustness of the model against different types of manipulations. An empirical evaluation is also performed to study the impact of the different parameters of the model.", "creator": "LaTeX with hyperref package"}}}