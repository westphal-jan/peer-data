{"id": "1605.06955", "review": {"conference": "ICML", "VERSION": "v1", "DATE_OF_SUBMISSION": "23-May-2016", "title": "Semi-Supervised Classification Based on Classification from Positive and Unlabeled Data", "abstract": "partially - transparent learning based on its low - density separation principle model as implicit cluster operator manifold assumptions seemed already adequately studied in the last decades. however, such semi - bounded learning methods do well always perform completely due to violation of generalized cluster and manifold assumption. in subsequent paper, we propose a novel approach involving semi - supervised development who does not interpret such localized distributions. is typical idea arises to combine learning from strings and repetitive data ( vector supervised learning ) and learning generates positive and unlabeled data ( synthetic learning ), the logic is required to require processed into utilize unlabeled data without ignoring distributions'manifold assumptions. we theoretically and sometimes show considerable usefulness of our approach.", "histories": [["v1", "Mon, 23 May 2016 09:37:48 GMT  (153kb,D)", "http://arxiv.org/abs/1605.06955v1", null], ["v2", "Fri, 14 Oct 2016 14:04:24 GMT  (261kb,D)", "http://arxiv.org/abs/1605.06955v2", null], ["v3", "Wed, 1 Mar 2017 11:39:31 GMT  (406kb,D)", "http://arxiv.org/abs/1605.06955v3", null], ["v4", "Fri, 16 Jun 2017 11:14:36 GMT  (1750kb,D)", "http://arxiv.org/abs/1605.06955v4", "Accepted to the 34th International Conference on Machine Learning (ICML 2017)"]], "reviews": [], "SUBJECTS": "cs.LG", "authors": ["tomoya sakai", "marthinus christoffel du plessis", "gang niu", "masashi sugiyama"], "accepted": true, "id": "1605.06955"}, "pdf": {"name": "1605.06955.pdf", "metadata": {"source": "CRF", "title": "Beyond the Low-density Separation Principle: A Novel Approach to Semi-supervised Learning", "authors": ["Tomoya Sakai", "Masashi Sugiyama"], "emails": ["sakai@ms.k.u-tokyo.ac.jp", "christo@ms.k.u-tokyo.ac.jp", "gang@ms.k.u-tokyo.ac.jp", "sugi@k.u-tokyo.ac.jp"], "sections": [{"heading": "1 Introduction", "text": "In the last decades, learning from labeled and unlabeled data called semi-supervised learning has been extensively studied [1\u20133]. The basic principle of semi-supervised learning is the low-density separation principle: the decision boundary for classification does not go through high-density regions. Following this principle, various semi-supervised learning methods based on the cluster assumption (samples in the same cluster share the same class label) and the manifold assumption (the learning target function is smooth over the input data manifolds) have been developed.\nHowever, in many real-world problems, such cluster and manifold assumptions are not necessarily satisfied, which causes standard semi-supervised learning methods to perform poorly. Furthermore, there is no practical way to assess whether the cluster and manifold assumptions are satisfied, which is a critical limitation when applying semi-supervised learning to real-world problems. The purpose of this paper is to go beyond the low-density separation principle: we propose a novel approach to semi-supervised learning that does not require the cluster and manifold assumptions.\nOur key idea is based on learning only from positive and unlabeled data (PU learning), which has gathered a great deal of attention recently [4\u20138]. An interesting property of such PU learning methods is that they are theoretically guaranteed to perform well without restrictive cluster and manifold assumptions. In other words, unlabeled data can be effectively used irrespective of the low-density separation principle.\nBased on this useful fact, we propose to combine PU learning and PN learning (learning from positive and negative data, i.e. standard supervised learning) \u2014 thus, we use all positive, negative, and\n29th Conference on Neural Information Processing Systems (NIPS 2016), Barcelona, Spain.\nar X\niv :1\n60 5.\n06 95\n5v 1\n[ cs\n.L G\n] 2\nunlabeled data as standard semi-supervised learning. In our companion paper [9], we have theoretically proved that PU learning (or its counterpart, NU learning, learning from negative and unlabeled data) can outperform PN learning under some condition. Thus, it is naturally expected that our proposed methods, a convex combination of PN learning and PU (or NU) learning, can further improve the performance.\nWe validate this expectation by theoretically analyzing the stability and generalization error of the proposed combined estimators. We first prove, given that the combined classifiers are unbiased, their variance is almost always lower than the classifier trained by PN learning, without the low-density separation principle. We then provide the generalization error bounds for the combined classifiers, showing that they achieve the optimal parametric convergence rate. Finally, we numerically illustrate the behavior of the proposed semi-supervised classifiers.\nThe rest of this paper is structured as follows. In Section 2, we formulate our target classification problem and review PN learning and PU (NU) learning methods. We then describe our proposed semi-supervised learning methods in Section 3 and give optimization algorithms in Section 3.2. We theoretically analyze the behavior of the proposed estimators in Section 4 and experimentally evaluate the performance of the proposed methods in Section 5. Finally, we conclude in Section 6."}, {"heading": "2 Background", "text": "In this section, we first formulate our target classification problem and then briefly review PN learning and PU (NU) learning methods that will be used for developing a novel semi-supervised learning method in the following sections."}, {"heading": "2.1 Problem Settings", "text": "Let X \u2208 Rd for d \u2208 N and Y = \u00b11, which are equipped with underlying joint probability density p(x, y). Let p+(x) = p(x | y = +1), p\u2212(x) = p(x | y = \u22121), and \u03c0 = p(y = +1). Suppose that we are given no data from p(x, y), but instead we observe the following three data sets: X+ = {x+i}n+i=1 \u223c p+(x),X\u2212 = {x \u2212 i } n\u2212 i=1 \u223c p\u2212(x), andXu = {xui } nu i=1 \u223c pu(x). Each of the three data sets contains independent and identically distributed data from the corresponding marginal density. We call X+, X\u2212 and Xu positive (P), negative (N) and unlabeled (U) data, respectively. A learning problem using P and N data is called PN learning, and that using P and U data, or N and U data, is PU learning, or NU learning. Finally, a learning problem using all of P, N and U data is referred to as PNU learning. See Figure 1."}, {"heading": "2.2 PN Learning", "text": "Let g : Rd 7\u2192 R be an arbitrary real-valued decision function for binary classification and ` : R 7\u2192 R be a bounded Lipschitz-continuous loss function. Let\nR+(g) = E+[`(g(X))], R\u2212(g) = E\u2212[`(\u2212g(X))], where E\u00b1[\u00b7] = EX\u223cp\u00b1 [\u00b7]. Then the risk of g w.r.t. ` under p(x, y) is given by\nR(g) = E(X,Y )[`(Y g(X))] = \u03c0R+(g) + (1\u2212 \u03c0)R\u2212(g). (1) Approximating R(g) based on Eq. (1), we obtain an unbiased estimator of the risk in PN learning:\nR\u0302pn(g) = \u03c0\nn+ n+\u2211 i=1 `(g(x+i )) + 1\u2212 \u03c0 n\u2212 n\u2212\u2211 i=1 `(\u2212g(x\u2212i )),\nwhose convergence rate is Op(1/ \u221a n+ + 1/ \u221a n\u2212) [10]. Here, Op(\u00b7) denotes the asymptotic order in probability."}, {"heading": "2.3 PU Learning", "text": "Let Ru,\u2212(g) = EX [`(\u2212g(X))], where EX = EX\u223cpu [\u00b7]. du Plessis et al. [7] has shown that with the following symmetric condition `(t) + `(\u2212t) = 1, (2)\nwe have Ru,\u2212(g) = \u03c0(1\u2212R+(g)) + (1\u2212 \u03c0)R\u2212(g), and hence R(g) = 2\u03c0R+(g) +Ru,\u2212(g)\u2212 \u03c0. (3) Approximating R(g) based on Eq. (3), we obtain an unbiased estimator to the risk in PU learning:\nR\u0302pu(g) = \u2212\u03c0 + 2\u03c0\nn+ n+\u2211 i=1 `(g(x+i)) + 1 nu nu\u2211 i=1 `(\u2212g(xui )),\nwhose convergence rate is Op(1/ \u221a n+ + 1/ \u221a nu) [7]."}, {"heading": "2.4 NU Learning", "text": "Likewise, R(g) could be estimated using NU data: R(g) = Ru,+(g) + 2(1\u2212 \u03c0)R\u2212(g)\u2212 (1\u2212 \u03c0), (4)\nwhere Ru,+(g) = EX [`(g(X))]. Approximating R(g) based on Eq. (4), we obtain an unbiased estimator to the risk in NU learning:\nR\u0302nu(g) = 1\nnu nu\u2211 i=1 `(g(xui )) + 2(1\u2212 \u03c0) n\u2212 n\u2212\u2211 i=1 `(\u2212g(x\u2212i ))\u2212 (1\u2212 \u03c0),\nwhose convergence rate is Op(1/ \u221a n\u2212 + 1/ \u221a nu)."}, {"heading": "3 Learning from PNU Data", "text": "In this section, we describe our semi-supervised learning methods which combine PN learning and PU learning (or NU learning)."}, {"heading": "3.1 PNPU and PNNU Estimators", "text": "Let Rpn(g) denote R(g) in Eq. (1), Rpu(g) denote R(g) in Eq. (3), and \u03b3 be a real scalar such that 0 \u2264 \u03b3 \u2264 1. Then the convex combination of Rpn(g) and Rpu(g) gives\nR(g) = \u03b3Rpn(g) + (1\u2212 \u03b3)Rpu(g) = (2\u03c0 \u2212 \u03b3\u03c0)R+(g) + \u03b3(1\u2212 \u03c0)R\u2212(g) + (1\u2212 \u03b3)Ru,\u2212(g)\u2212 (1\u2212 \u03b3)\u03c0. (5)\nApproximating R(g) based on Eq. (5), we obtain an unbiased estimator to the risk:\nR\u0302\u03b3pnpu(g) = \u03b3R\u0302pn(g) + (1\u2212 \u03b3)R\u0302pu(g)\n= c+ n+\u2211 i=1 `(g(x+i)) + c\u2212 n\u2212\u2211 i=1 `(\u2212g(x\u2212i )) + cu nu\u2211 i=1 `(\u2212g(xui ))\u2212 (1\u2212 \u03b3)\u03c0, (6)\nwhere c+ = (2 \u2212 \u03b3)\u03c0/n+, c\u2212 = \u03b3(1 \u2212 \u03c0)n\u2212, and cu = (1 \u2212 \u03b3)/nu. R\u0302\u03b3pnpu(g) converges in Op(1/ \u221a n+ + 1/ \u221a n\u2212 + 1/ \u221a nu).\nLikewise, the risk of PNNU estimator is obtained by the convex combination ofRpn(g) andRpu(g), R(g) = \u03b3\u03c0R+(g) + (2\u2212 \u03b3)(1\u2212 \u03c0)R\u2212(g) + (1\u2212 \u03b3)Ru,+(g)\u2212 (1\u2212 \u03b3)(1\u2212 \u03c0), (7) whose empirical approximator R\u0302\u03b3pnnu(g) = \u03b3R\u0302pn(g) + (1\u2212 \u03b3)R\u0302nu(g) converges in Op(1/ \u221a n+ + 1/ \u221a n\u2212 + 1/ \u221a nu)."}, {"heading": "3.2 Algorithm", "text": "Here, we give an algorithm to minimize the empirical loss (6) for PNPU learning. PNNU learning can be performed in the same manner. For simplicity, we introduce a set of triple {(xi, \u03bai, ci)}ni=1, where n = n+ +n\u2212+nu, \u03ba takes +1 for positive sample and\u22121 for negative and unlabeled sample (for PNNU, \u03ba takes +1 for unlabeled sample), and c is the cost for each sample, i.e., ci = c+ for positive, ci = c\u2212 for negative, and ci = cu for unlabeled sample. We use the ramp loss, which satisfies the symmetric condition (2): `R(z) := 12 max(0,min(2, 1\u2212z)). Since the ramp loss can be separated into convex and concave parts, we use the ConCave-Convex Procedure (CCCP) [11, 12]. The CCCP method iteratively tightens a linear upper-bound for the concave part, and minimizes the convex part and the linear upper bound. The procedure is discussed in detail below.\nConvex-Concave Partitioning The scaled ramp loss function can be split into a convex and concave part:\n`R(z) = H1(z)\ufe38 \ufe37\ufe37 \ufe38 convex \u2212H\u22121(z)\ufe38 \ufe37\ufe37 \ufe38 concave ,\nwhere Hs(z) := 12 max(0, s\u2212 z) is the hinge loss. Assuming that the function gw(x) is parameterized by w, we can express the objective function (6) as\nJ(w) = n\u2211 i=1 ci`R(\u03baigw(xi)) + \u03bb 2 w>w,\nwhere the last term is an additional `2-regularization term with regularization parameter \u03bb \u2265 0. This objective function can then be partitioned into a convex part and a concave part:\nJ(w) = n\u2211 i=1 ciH1(\u03baigw(xi)) + \u03bb\n2 w>w\ufe38 \ufe37\ufe37 \ufe38\nJvex(w)\n\u2212 n\u2211 i=1\nciH\u22121(\u03baigw(xi))\ufe38 \ufe37\ufe37 \ufe38 Jcave(w) .\nUsing the Fenchel inequality \u2212H\u22121(z) \u2264 H\u2217\u22121(t)\u2212 zt, the concave part can be upper-bounded as\nJ\u0304cave(w,u) = n\u2211 i=1 ci(H \u2217 \u22121(ui)\u2212 ui\u03baigw(xi)),\nwhere u is the bound parameter, and H\u2217\u22121(t) is \u2212t if \u22121/2 \u2264 t \u2264 0, \u221e otherwise. H\u2217\u22121(t) is known as the convex conjugate or Fenchel dual. The upper-bound J\u0304cave(w,u) can be analytically minimized w.r.t. u by ui = \u22121/2 if \u03baigw(xi) \u2264 \u22121, and 0 otherwise.\nOptimization problems The tightened upper-bound of the objective function J\u0304(w) = Jvex(w) + J\u0304cave(w) can be minimized as\nminimize w\u2208Rb\n1\n2 n\u2211 i=1 ci max(0, 1\u2212 \u03baigw(xi)) + 1 2 \u2211 i\u2208V ci\u03baigw(xi) + \u03bb 2 w>w,\nwhere V = {i \u2208 [n] | \u03baigw(xi) \u2264 \u22121} is the active set and [n] = {1, . . . , n}.\nLet us use a model gw(x) = w>\u03c6(x) + b, then the dual problem is obtained by\nmaximize \u03b1\u2208Rn\n\u03b1>1n \u2212 1\n2\u03bb \u03b1>[(\u03ba\u03ba>) \u25e6K]\u03b1\nsubject to \u03b1>\u03ba = 0 \u2212 \u03b7 \u03b1 c\u2212 \u03b7,\nwhere denotes element-wise inequality for vectors, \u25e6 denotes element-wise multiplication of matrices, Ki,j = \u03c6(xi)>\u03c6(xj), \u03ba := (\u03ba1, . . . , \u03ban)>, c := (c1/2, . . . , cn/2)>, \u03b7 := (\u03b71, . . . , \u03b7n)>, and \u03b7i = ci if i \u2208 V and \u03b7i = 0 if i 6\u2208 V . Those problems can be solved as the quadratic program by an off-the-shelf optimizer such as Gurobi Optimizer [13].\nThis algorithm includes PN, PU, and NU learning with the ramp loss. For example, when \u03b3 = 1 and \u03bai = yi, the above optimization problems is equivalent to that of ramp loss SVMs with R\u22121(z) = H1(z)\u2212H\u22121(z) proposed by [12]. Thus, this formulation can be regarded as a more general version of that algorithm."}, {"heading": "4 Theoretical Analyses", "text": "In this section, we theoretically analyze the behavior of the proposed method."}, {"heading": "4.1 Variance Analysis", "text": "All estimators to R(g) so far are unbiased. A natural question would be raised: Could R\u0302\u03b3pnpu(g) and R\u0302\u03b3pnnu(g) have smaller variances than R\u0302pn(g)?\nTo answer this question, let g be fixed and assume that\nn+ nu, n\u2212 nu,\nwhich should be natural in PU and NU learning. Then we have the following lemmas (their proofs are given in Appendix A and Appendix B): Lemma 1. For any fixed g, if\n1\nn+ \u03c02\u03c32+(g) <\n1\nn\u2212 (1\u2212 \u03c0)2\u03c32\u2212(g) (8)\nis true, the combination R\u0302\u03b3pnpu(g) at\n\u03b3\u2217pnpu = 2\n( 1 +\n(1\u2212 \u03c0)2\u03c32\u2212(g)/n\u2212 \u03c02\u03c32+(g)/n+\n)\u22121 (9)\nis guaranteed to reduce the variance of R\u0302pn as nu \u2192 \u221e; otherwise, R\u0302pn has already achieved the minimal variance among all possible combinations implied by R\u0302\u03b3pnpu(g). Lemma 2. For any fixed g, if\n1\nn+ \u03c02\u03c32+(g) >\n1\nn\u2212 (1\u2212 \u03c0)2\u03c32\u2212(g) (10)\nis true, the combination R\u0302\u03b3pnnu(g) at\n\u03b3\u2217pnnu = 2\n( 1 +\n\u03c02\u03c32+(g)/n+\n(1\u2212 \u03c0)2\u03c32\u2212(g)/n\u2212 )\u22121 is guaranteed to reduce the variance of R\u0302pn as nu \u2192 \u221e; otherwise, R\u0302pn has already achieved the minimal variance among all possible combinations implied by R\u0302\u03b3pnnu(g).\nObserving that (8) and (10) are essentially complimentary, we immediately obtain the following theorem: Theorem 3. For any fixed g, either R\u0302\u03b3pnpu(g) or R\u0302\u03b3pnnu(g) could almost always reduce the variance of R\u0302pn. The only exception is\n1\nn+ \u03c02\u03c32+(g) =\n1\nn\u2212 (1\u2212 \u03c0)2\u03c32\u2212(g),\nwith probability zero over choices of n+, n\u2212, and g.\nThis theorem shows that either PNPU learning and PNNU learning almost always improves the variance over PN learning without the low-density separation principle."}, {"heading": "4.2 Generalization Error Bounds", "text": "Next, we analyze the generalization error of PNPU learning and PNNU learning.\nLet G be a function class of hyperplanes with bounded normals and feature maps:\nG = {g(x) = \u3008w,\u03c6(x)\u3009 | \u2016w\u2016 \u2264 Cw, \u2016\u03c6(x)\u2016 \u2264 C\u03c6},\nwhere Cw and C\u03c6 are certain positive constants. Since we have added the `2-regularization, we can naturally assume that the optimal g returned by our CCCP solver always belongs to certain G. Let `01(z) = (1\u2212 sign(z))/2 be the zero-one loss and I(g) = E(X,Y )[`01(Y g(X))] be the risk of g w.r.t. `01 under p(x, y). We then can obtain two generalization error bounds. Theorem 4. For any \u03b4 > 0, with probability at least 1\u2212\u03b4, the following generalization error bounds hold for any g \u2208 G separately:\nI(g) \u2264 2R\u0302\u03b3pnpu(g) + ( 2CwC\u03c6 + 3 \u221a 2 ln(6/\u03b4) )( (2\u2212 \u03b3)\u03c0\n\u221a n+ + \u03b3(1\u2212 \u03c0) \u221a n\u2212 + 1\u2212 \u03b3 \u221a nu\n) , (11)\nI(g) \u2264 2R\u0302\u03b3pnnu(g) + ( 2CwC\u03c6 + 3 \u221a 2 ln(6/\u03b4) )( \u03b3\u03c0 \u221a n+ + (2\u2212 \u03b3)(1\u2212 \u03c0) \u221a n\u2212 + 1\u2212 \u03b3 \u221a nu ) . (12)\nSketch of proof (See Appendix C for full proof): A key observation is that `01(z) \u2264 2`R(z) for any z, and consequently I(g) \u2264 2R(g). Then, according to the decomposition of R(g) in Eq. (5) and the definition of R\u0302\u03b3pnpu(g) in Eq. (6), the bound in (11) can be proved using the Rademacher complexity [14], Talagrand\u2019s contraction lemma [15], and the fact that the Lipschitz constant of our ramp loss is 1/2. Similarly, according to the decomposition of R(g) in Eq. (7) and the definition of R\u0302\u03b3pnnu(g), the bound in (12) can be proved.\nTheorem 4 guarantees that for any g, the generalization error I(g) can be bounded from above by two times the empirical risks, i.e., 2R\u0302\u03b3pnpu(g) and 2R\u0302 \u03b3 pnnu(g), plus a confidence term of order\nOp(1/ \u221a n+ + 1/ \u221a n\u2212 + 1/ \u221a nu).\nAs n+, n\u2212 and nu can increase independently, this is already the optimal convergence rate of the confidence term without any additional assumption."}, {"heading": "5 Experiments", "text": "In this section, we experimentally evaluate the performance of the proposed method."}, {"heading": "5.1 Numerical illustration", "text": "We numerically illustrate the behavior of the proposed method using simple Gaussian data. The PNU data is generated from the following distributions:\np+(x) = N(x; (1, 0) >, I2), p\u2212(x) = N(x; (\u22121, 0)>, I2),\nwhere N(x;\u00b5,\u03a3) denotes the normal density with mean \u00b5 and covariance matrix \u03a3, and I2 is the 2 \u00d7 2 identity matrix. We generate 6 positive, 2 negative samples, and 30 unlabeled samples using class priors of \u03c0 = 0.2, 0.5. The class prior is assumed to be known in this and subsequent experiments, but in practice it can be accurately estimated with methods proposed in [6, 16, 17]. A linear model g(x) = w>x + b and a fixed regularization parameter of \u03bb = 0.001 is used for training. The misclassification rate is evaluated on a dataset of 100, 000 samples.\nFigure 2(a) shows the mean and standard error of the PNPU classifier over 100 trials when \u03c0 = 0.2 and \u03c0 = 0.5, for different \u03b3 values. When \u03b3 = 0, it corresponds to pure PU learning, and when \u03b3 = 1, it corresponds to pure PN learning. By assuming that the unknown variances are equal, i.e., \u03c32+(g) = \u03c3 2 \u2212(g), we can select \u03b3 according to (9) (the \u03b3 values selected according to this rule is indicated by a cross on the figure).\nWhen \u03c0 = 0.2, PU learning is much better than PN learning. In this situation, the \u03b3 selected according to our heuristic is close to the value for PU learning. When \u03c0 = 0.5, we see that PU learning is worse than PN learning. However, the convex combination of both objective functions, with \u03b3 = 0.5 (as selected by the rule), still improves on PN learning.\nFigures 2(b) and 2(c) show typical examples of two cases of PNPU learning. Here, the black dotted, green dashed, and red solid lines show the true decision boundary and boundaries obtained by PN learning and PNPU learning with \u03b3 selected according to the rule. When \u03c0 = 0.2, the PNPU decision boundary is close to the optimal decision boundary and differs from the PN boundary. When \u03c0 = 0.5, the PU and PNPU decision boundaries are very similar. In both cases, the PN boundary is far from ideal."}, {"heading": "5.2 Benchmark data sets", "text": "We compare our method against two standard semi-supervised (i.e. PNU) learning methods, Laplacian SVM (LapSVM) [3] and logistic regression with entropy regularization (ER) [18], on various benchmarks. 1 In the experiments, we fix n+ and n\u2212 and vary \u03c0. Since the class-prior of the labeled data may differ from the target class prior, we reweighted SVM for LapSVM and reweighted logistic regression for ER.\nTo ensure fair comparison, all methods used a Gaussian kernel model\ng(x) = n\u2211 i=1 \u03b1iK(x,xi), where K(x,x\u2032) = exp ( \u2212\u2016x\u2212 x \u2032\u20162 2\u03c32 ) .\nThe bandwidth of the kernel was selected from {10\u22123, 10\u22122, . . . , 101}. The hyper-parameters in all methods were selected via 5-fold cross-validation. In LapSVM and ER, unlabeled data is incorporated as a regularization term. Therefore the parameter controlling the strength of unlabeled data was selected (as was all other hyper-parameters) based on cross-validation score calculated solely from the PN data. For LapSVM, the number of nearest neighbors for constructing the Laplacian matrix is chosen from {5, 6, . . . , 10}, and other options are the same as default value of implementation provided on the author\u2019s website [3]. ER has a single hyper-parameter term that controls the strength of L2-regulation on the model and entropy regularization term. This parameter is selected from {10\u22123, 10\u22122, . . . , 101}. In PNPU and PNNU learning, the unlabeled samples are incorporated in the objective function. Therefore, if \u03b3 is fixed a priori, the cross-validation is based on the misclassification rate estimated from both the PN and PU data (i.e., empirical versions of (5) and (7) with the zero-one loss). If \u03b3 is appropriately set, PNPU and PNPU learning may potentially have estimates of the misclassification rate with a lower variance than other semi-supervised methods (cf. Appendix A), which in turn may translate to better hyper-parameter selection.\nTable 1 reports the mean and standard error of misclassification rate over 50 trials. Overall, our proposed method works well compared to the conventional methods on most data sets. Note that when \u03c0 = 0.2, 0.8, the error rate in the competing methods may be in some instances higher than the\n1The benchmark data sets are from the semi-supervised learning book [2], UCI machine learning repository [19], IDA benchmark repository [20], and the European ESPRIT 5516 project. The data for the ESPRIT project is available from: https://www.elen.ucl.ac.be/neural-nets/Research/ Projects/ELENA/elena.htm\nchance rate. One possible explanation on why this occurs is that the assumptions on unlabeled data, such as the manifold assumption in LapSVM, are violated in the datasets. This may for instance occur in the banana dataset, since the two classes are highly overlapping.\nAccording to our rule for selecting \u03b3, when the sample sizes, are the same (n+ = n\u2212) and the target class prior is \u03c0 = 0.5, our semi-supervised method is reduced to PN learning. This is due to the assumption used in the rule that the variances of the two classes are equal. It may however still be possible to select \u03b3 that will cause an improvement, since the variances of the two classes may differ (this may occur in situations such as one-versus-rest). Developing such a rule is an important avenue for future research."}, {"heading": "6 Conclusions", "text": "In this paper, we proposed a novel approach to semi-supervised learning that is not based on the low-density separation principle. Our key idea was to combine PN learning and PU learning or NU learning. We theoretically showed that either PNPU learning and PNNU learning almost always improves the variance over PN learning without the low-density separation principle. We further proved that PNPU learning and PNNU learning achieve the optimal parametric convergence rate in terms of the generalization error. Numerical experiments illustrated the effectiveness of the proposed methods."}, {"heading": "A Proof of Lemma 1", "text": "Proof. Due to the independence of X+, X\u2212 and Xu and the assumptions n+ nu and n\u2212 nu, we have\nVar[R\u0302\u03b3pnpu(g)] = (2\u03c0 \u2212 \u03b3\u03c0)2\nn+ \u03c32+(g) +\n\u03b32(1\u2212 \u03c0)2\nn\u2212 \u03c32\u2212(g) +\n(1\u2212 \u03b3)2\nnu \u03c32u,\u2212(g)\n\u2248 (2\u03c0 \u2212 \u03b3\u03c0) 2\nn+ \u03c32+(g) +\n\u03b32(1\u2212 \u03c0)2\nn\u2212 \u03c32\u2212(g) (13)\nas nu \u2192 \u221e, where \u03c32+(g) = VarX\u223cp+(x)[`(g(X))], \u03c3 2 \u2212(g) = VarX\u223cp\u2212(x)[`(\u2212g(X))], and \u03c3 2 u,\u2212(g) = VarX\u223cp(x)[`(\u2212g(X))]. Then,\n\u03b3\u2217pnpu = argmin \u03b3\n(2\u03c0 \u2212 \u03b3\u03c0)2\nn+ \u03c32+(g) +\n\u03b32(1\u2212 \u03c0)2\nn\u2212 \u03c32\u2212(g) = 2\n( 1 +\n(1\u2212 \u03c0)2\u03c32\u2212(g)/n\u2212 \u03c02\u03c32+(g)/n+\n)\u22121 .\nIt is clear that 0 < \u03b3\u2217pnpu < 1 if and only if\n1\nn+ \u03c02\u03c32+(g) <\n1\nn\u2212 (1\u2212 \u03c0)2\u03c32\u2212(g).\nNote that Eq. (13) is quadratic in \u03b3, and thus we have Lemma 1."}, {"heading": "B Proof of Lemma 2", "text": "Proof. With the assumptions n+ nu and n\u2212 nu, we have\nVar[R\u0302\u03b3pnnu(g)] \u2248 \u03b32\u03c02\nn+ \u03c32+(g) +\n(2\u2212 \u03b3)2(1\u2212 \u03c0)2\nn\u2212 \u03c32\u2212(g) (14)\nas nu \u2192\u221e, and then\n\u03b3\u2217pnnu = argmin \u03b3\n\u03b32\u03c02\nn+ \u03c32+(g) +\n(2\u2212 \u03b3)2(1\u2212 \u03c0)2\nn\u2212 \u03c32\u2212(g) = 2\n( 1 +\n\u03c02\u03c32+(g)/n+ (1\u2212 \u03c0)2\u03c32\u2212(g)/n\u2212\n)\u22121 .\nIt is clear that 0 < \u03b3\u2217pnnu < 1 if and only if\n1\nn+ \u03c02\u03c32+(g) >\n1\nn\u2212 (1\u2212 \u03c0)2\u03c32\u2212(g).\nEq. (14) is also quadratic in \u03b3, and thus we have Lemma 2."}, {"heading": "C Proof of Theorem 4", "text": "Let R\u0302+(g), R\u0302\u2212(g), R\u0302u,+(g) and R\u0302u,\u2212(g) be empirical approximations of R+(g), R\u2212(g), Ru,+(g) and Ru,\u2212(g) of sizes n+, n\u2212, nu and nu, respectively. Then we have the following concentration results, which will be used to prove Theorem 4:\nLemma 5. For any \u03b4 > 0, with probability at least 1 \u2212 \u03b4/3, the following uniform deviation bounds hold separately:\nsupg\u2208G(R+(g)\u2212 R\u0302+(g)) \u2264 CwC\u03c6\u221a n+ + 3\n\u221a ln(6/\u03b4)\n2n+ ,\nsupg\u2208G(R\u2212(g)\u2212 R\u0302\u2212(g)) \u2264 CwC\u03c6\u221a n\u2212 + 3\n\u221a ln(6/\u03b4)\n2n\u2212 ,\nsupg\u2208G(Ru,+(g)\u2212 R\u0302u,+(g)) \u2264 CwC\u03c6\u221a nu + 3\n\u221a ln(6/\u03b4)\n2nu ,\nsupg\u2208G(Ru,\u2212(g)\u2212 R\u0302u,\u2212(g)) \u2264 CwC\u03c6\u221a nu + 3\n\u221a ln(6/\u03b4)\n2nu .\nAll four bounds in Lemma 5 are from the basic uniform deviation bound using the Rademacher complexity [14], Talagrand\u2019s contraction lemma [15], and the fact that the Lipschitz constant of our ramp loss is 1/2. For these reasons, the detailed proof of Lemma 5 is omitted.\nProof. Recall that\nR\u03b3pnpu(g) = (2\u2212 \u03b3)\u03c0R+(g) + \u03b3(1\u2212 \u03c0)R\u2212(g) + (1\u2212 \u03b3)Ru,\u2212(g)\u2212 (1\u2212 \u03c0)\u03b3,\nR\u0302\u03b3pnpu(g) = (2\u2212 \u03b3)\u03c0R\u0302+(g) + \u03b3(1\u2212 \u03c0)R\u0302\u2212(g) + (1\u2212 \u03b3)R\u0302u,\u2212(g)\u2212 (1\u2212 \u03c0)\u03b3.\nThen, we have\nsupg\u2208G(R \u03b3 pnpu \u2212 R\u0302\u03b3pnpu) = (2\u2212 \u03b3)\u03c0 supg\u2208G(R\u2212(g)\u2212 R\u0302\u2212(g)) + \u03b3(1\u2212 \u03c0) supg\u2208G(R+(g)\u2212 R\u0302+(g))\n+ \u03b3 supg\u2208G(Ru,\u2212(g)\u2212 R\u0302u,\u2212(g)).\nFor any \u03b4 > 0, with probability at least 1\u2212 \u03b4, we have the following uniform deviation bounds\nsupg\u2208G(R \u03b3 pnpu \u2212 R\u0302\u03b3pnpu) \u2264 (2\u2212 \u03b3)\u03c0 ( CwC\u03c6\u221a n+ + 3 \u221a ln(6/\u03b4) 2n+ ) + \u03b3(1\u2212 \u03c0) ( CwC\u03c6\u221a n\u2212 + 3 \u221a ln(6/\u03b4) 2n\u2212 )\n+ (1\u2212 \u03b3) ( CwC\u03c6\u221a nu + 3 \u221a ln(6/\u03b4) 2nu )\n= 1\n2\n( 2CwC\u03c6 + 3 \u221a 2 ln(6/\u03b4) )( (2\u2212 \u03b3)\u03c0 \u221a n+ + \u03b3(1\u2212 \u03c0) \u221a n\u2212 + 1\u2212 \u03b3\u221a nu ) ,\nwhere each supremum is bounded with probability 1\u2212 \u03b4/3 based on Lemma 5. Since I(g) \u2264 2R(g), we have Eq. (11). Likewise, the generalization error bounds in Eq.(12) holds."}], "references": [], "referenceMentions": [], "year": 2017, "abstractText": "Semi-supervised learning based on the low-density separation principle such as<lb>the cluster and manifold assumptions has been extensively studied in the last<lb>decades. However, such semi-supervised learning methods do not always per-<lb>form well due to violation of the cluster and manifold assumptions. In this paper,<lb>we propose a novel approach to semi-supervised learning that does not require<lb>such restrictive assumptions. Our key idea is to combine learning from positive<lb>and negative data (standard supervised learning) and learning from positive and<lb>unlabeled data (PU learning), the latter is guaranteed to be able to utilize unla-<lb>beled data without the cluster and manifold assumptions. We theoretically and<lb>experimentally show the usefulness of our approach.", "creator": "LaTeX with hyperref package"}}}