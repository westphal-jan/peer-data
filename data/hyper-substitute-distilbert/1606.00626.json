{"id": "1606.00626", "review": {"conference": "arxiv", "VERSION": "v1", "DATE_OF_SUBMISSION": "2-Jun-2016", "title": "The Challenge of Non-Technical Loss Detection using Artificial Intelligence: A Survey", "abstract": "descriptions of non - technical losses ( ntl ) which include electricity theft, faulty meters or billing violations simultaneously attracted less attention representing researchers in electrical chemistry and computer ethics. manufacturers inflicted large harm to the economy, accusing too some countries they may mean up against 37 % of the total electricity distributed. engineers next research direction utilize objective artificial intelligence ( tia ) to achieve this disadvantage. promising approaches now been reported dividing into two variants : expert systems incorporating custom - crafted expert studies or simple science, also comprising pattern recognition aided data mining, which combine individual consumption stories from examples without being explicitly programmed. this paper itself provides an overview with how systems am defined and their impact facing economies. next, it covers the managerial activities of ai relevant to this domain. it too surveys 3 main issues in discussing comprehensive manual by algorithms, symbols and data sets used. it finally identifies the key scientific application engineering issues from ntl detection and suggests how they could grow solved. defenders see that those challenges been not sufficiently been addressed in industry contributions and developments while those yet solved in order correctly conduct ntl optimization.", "histories": [["v1", "Thu, 2 Jun 2016 11:14:47 GMT  (653kb,D)", "http://arxiv.org/abs/1606.00626v1", null], ["v2", "Sat, 22 Jul 2017 22:30:28 GMT  (272kb,D)", "http://arxiv.org/abs/1606.00626v2", null], ["v3", "Tue, 25 Jul 2017 04:25:54 GMT  (272kb,D)", "http://arxiv.org/abs/1606.00626v3", null]], "reviews": [], "SUBJECTS": "cs.AI", "authors": ["patrick glauner", "jorge augusto meira", "petko valtchev", "radu state", "franck bettinger"], "accepted": false, "id": "1606.00626"}, "pdf": {"name": "1606.00626.pdf", "metadata": {"source": "CRF", "title": "The Challenge of Non-Technical Loss Detection using Artificial Intelligence: A Survey", "authors": ["Patrick Glauner", "Andre Boechat", "Lautaro Dolberg", "Jorge Meira", "Radu State", "Franck Bettinger", "Yves Rangoni", "Diogo Duarte"], "emails": ["first.last@uni.lu).", "first.last@choiceholding.com)."], "sections": [{"heading": null, "text": "Index Terms\u2014Artificial intelligence, data mining, electricity theft, expert systems, machine learning, non-technical losses, pattern recognition.\nI. INTRODUCTION\nOUR modern society and daily activities strongly dependon the availability of electricity. Electrical power grids allow to distribute and deliver electricity from generation infrastructure such as power plants or solar cells to customers such as residences or factories. One frequently appearing problem are losses in power grids, which can be classified into two categories: technical and non-technical losses.\nTechnical losses occur mostly due to power dissipation. This is naturally caused by internal electrical resistance and the affected components include generators, transformers and transmission lines.\nThe opposite class of losses are non-technical losses (NTL), which are primarily caused by electricity theft. In most countries, NTLs account for the predominant part of the overall losses [46]. Therefore, it is most beneficial to first reduce NTLs before reducing technical losses [3]. Nonetheless, reducing technical losses is challenging, too. In particular, NTLs include, but are not limited to, the following causes [15], [65]:\nP. Glauner, A. Boechat, L. Dolberg, J. Meira and R. State are with the Interdisciplinary Centre for Security, Reliability and Trust, University of Luxembourg, (email: {first.last}@uni.lu).\nF. Bettinger, Y. Rangoni and D. Duarte are with CHOICE Technologies Holding Sa\u0300rl, (email: {first.last}@choiceholding.com).\nManuscript received MONTH DD, YEAR.\n\u2022 Meter tampering in order to record lower consumptions \u2022 Bypassing meters by rigging lines from the power source \u2022 Arranged false meter readings by bribing meter readers \u2022 Faulty or broken meters \u2022 Un-metered supply \u2022 Technical and human errors in meter readings, data\nprocessing and billing NTLs cause significant harm to economies, including loss of revenue and profit of electricity providers, decrease of the stability and reliability of electrical power grids and extra use of limited natural resources which in turn increases pollution. There are different estimates of the losses caused by NTL. For example, in India, NTLs are estimated at US$ 4.5 billion [8]. NTLs also reported to range up to 40% of the total electricity distributed in countries such as Brazil, India, Malaysia or Lebanon [22], [45]. They are also of relevance in developed countries, for example estimates of NTLs in the UK and US range from US$ 1-6 billion [2], [46].\nIn order to detect NTLs, inspections of customers are carried out based on predictions. From an electrical engineering perspective, one method to detect losses is to calculate the energy balance [58], which requires topological information of the network. This does not work accurately for those reasons: (i) network topology undergoes continuous changes in order to satisfy the rapidly growing demand of electricity, (ii) infrastructure may break and lead to wrong energy balance calculations and (iii) it requires transformers, feeders and connected meters to be read at the same time. A more flexible and adaptable approach is to employ artificial intelligence (AI) [62]. AI allows to analyze customer profiles, their data and known irregular behavior in order to trigger a possible inspection of a customer. However, carrying out inspections is costly, as it requires physical presence of technicians. It is therefore important to make accurate predictions in order to reduce the number of false positives.\nThe rest of this paper is organized as follows. Section II describes the field of AI. Section III provides a detailed review and critique of state-of-the-art NTL detection research employing AI methods. In Section IV, we identify the key challenges of this field that need to be accurately studied in order to enhance methods in the future. To the best of our knowledge, this topic has not been addressed yet in the literature on NTL detection. Section V summarizes this survey."}, {"heading": "II. ARTIFICIAL INTELLIGENCE", "text": "The field of artificial intelligence (AI) attempts to both understand and build intelligent entities [62]. This name was\nar X\niv :1\n60 6.\n00 62\n6v 1\n[ cs\n.A I]\n2 J\nun 2\n01 6\ncoined in 1955 during the preparations for the first AI conference hosted at Darmouth College [39]. While most people intuitively think about robotics, AI has more applications, such as learning patterns from data. This chapter provides an overview of the AI methods relevant to NTL detection."}, {"heading": "A. Expert systems", "text": "Traditional AI systems were based on hand-crafted rules. Such systems are also called expert systems because they incorporate expert knowledge in their decision making process. While expert systems have initially been successful in tasks such as diagnosis and treatment of nuclear reactor accidents [48] or mission planning of autonomous underwater vehicles [33], they have the following shortcomings: (1) incorporating expert knowledge in rules is challenging, (2) many domains cannot accurately be described in rules and (3) domain knowledge may change over time requiring amendments of the rules [31]. Nonetheless, expert systems are still being used nowadays."}, {"heading": "B. Machine learning", "text": "To avoid the shortcomings of expert systems, a diametrically opposed approach is to learn patterns from data rather than hand-crafting rules. This branch of AI is called machine learning or pattern recognition. Both approaches have their justification and neither is generally better or worse than the other in artificial intelligence [25]. Machine learning gives computers the ability to learn from data without being explicitly programmed [50]. This property has allowed to significantly improve AI in various applications, such as in handwritten digit recognition [35], facial expression recognition [71] or speech recognition [27]. Machine learning consists of three pillars: supervised, unsupervised and reinforcement learning. The term data mining is strongly related to machine learning, but has a wider scope that includes data cleaning, data preprocessing and concrete applications.\n1) Supervised learning: Supervised learning algorithms learn patterns from labeled training examples (x(i), y(i)), in which x(i) is a training data point and y(i) is a corresponding label. This is also called function induction and typical applications include regression or classification [10]. This pillar is best understood at present time and there are a wide variety of available learning algorithms. The choice of which learning algorithm to apply to a concrete problem is challenging and often requires comparative experiments. However, having a lot of representative data is considered sometimes to be more relevant than the actual algorithm [7].\n2) Unsupervised learning: Unsupervised learning uses only unlabeled data points x(i) in order to find hidden structure in the data [10]. Applications include dimensionality reduction methods such as the Principal Component Analysis (PCA) or t-sne [36] and clustering algorithms such as K-means.\n3) Reinforcement learning: In many learning problems, there is no intuitively correct supervision. Reinforcement learning is a reward-based learning technique for actions in order to get to a goal [67]. It has for example successfully been applied to humanoid robotics [61], autonomous helicopter\nflying [51] and playing the game of Go at super-human performance [64]."}, {"heading": "III. THE STATE OF THE ART", "text": "NTL detection can be treated as a special case of fraud detection, for which a general survey is provided in [11] and [32]. It highlights expert systems and machine learning as key methods to detect fraudulent behavior in applications such as credit card fraud, computer intrusion and telecommunications fraud. This section is focused on an overview of the existing AI methods for detecting NTLs. For other surveys of the past efforts in the field, readers are referred to [15] and [30]. Overviews of possible methods to manipulate a smart metering infrastructure are provided in [29] and [40]."}, {"heading": "A. Support Vector Machines", "text": "Support Vector Machines (SVM) [69] are a state-of-the-art classification algorithm that is less prone to overfitting. Electricity customer consumption data of less than 400 highly imbalanced out of ~260K customers in Kuala Lumpur, Malaysia having each 25 monthly meter readings in the period from June 2006 to June 2008 are used in [43]. From these meter readings, daily average consumptions features per month are computed. Those features are then normalized and used for training in a SVM with a Gaussian kernel. For this setting, a recall of 0.53 is achieved on the test set. In addition, credit worthiness ranking (CWR) is used in [46]. It is computed from the electricity provider\u2019s billing system and reflects if a customer delays or avoids payments of bills. CWR ranges from 0 to 5 where 5 represents the maximum score. It was observed that CWR significantly contributes towards customers committing electricity theft. A test accuracy of 0.77 and a test recall of 0.64 are reported.\nSVMs are also applied on 1,350 Indian customer profiles in [21]. They are split into 135 different daily average consumption patterns, each having 10 customers. For each customer, meters are read every 15 minutes. A test accuracy of 0.984 is reported. This work is extended in [20] by encoding the 4\u00d724 = 96-dimensional input in a lower dimension indicating possible irregularities. This encoding technique results in a simpler model that is faster to train while not losing the expressiveness of the data and results in a test accuracy of 0.92. This work is extended in [22] by introducing high performance computing algorithms in order to enhance the performance of the previously developed algorithms in [20]. This faster model has a test accuracy of 0.89.\nConsumption profiles of 5K Brazilian industrial customer profiles are analyzed in [57]. Each customer profile contains 10 features including the demand billed, maximum demand, installed power, etc. In this setting, a SVM slightly outperforms K-nearest neighbors (KNN) and a neural network, for which test accuracies of 0.9628, 0.9620 and 0.9448, respectively, are reported."}, {"heading": "B. Neural networks", "text": "Neural networks [9] are loosely inspired by how the human brain works and allow to learn complex hypotheses from\ndata. An ensemble of five neural networks (NN) is trained on samples of a data set containing ~20K customers in [41]. Each neural network uses features calculated from the consumption time series plus customer-specific pre-computed attributes. A precision of 0.626 and an accuracy of 0.686 are obtained on the test set.\nA data set of ~22K customers is used in [17] for training a neural network. It uses the average consumption of the previous 12 months and other customer features such as location, type of customer, voltage and whether there are meter reading notes during that period. On the test set, an accuracy of 0.8717, a precision of 0.6503 and a recall of 0.2947 are reported.\nExtreme learning machines (ELM) are one-hidden layer neural networks in which the weights from the inputs to the hidden layer are randomly set and never updated. Only the weights from the hidden to output layer are learned. The ELM algorithm is applied to NTL detection in meter readings of 30 minutes in [52], for which a test accuracy of 0.5461 is reported.\nA self-organizing map (SOM) is a type of unsupervised neural network training algorithm that is used for clustering. SOMs are applied to weekly customer data of 2K customers consisting of meter readings of 15 minutes in [13]. This allows to cluster customers\u2019 behavior into fraud or non-fraud. Inspections are only carried out if certain hand-crafted criteria are satisfied including how well a week fits into a cluster and if no contractual changes of the customer have taken place. A test accuracy of 0.9267, a test precision of 0.8526, and test recall of 0.9779 are reported."}, {"heading": "C. Expert systems and fuzzy systems", "text": "Profiles of 80K low-voltage and 6K high-voltage customers in Malaysia having meter readings every 30 minutes over a period of 30 days are used in [47] for electricity theft and abnormality detection. A test recall of 0.55 is reported. This work is related to features of [45], however, it uses entirely fuzzy logic incorporating human expert knowledge for detection.\nA database of ~700K Brazilian customers, ~31M monthly meter readings from January 2011 to January 2015 and ~400K inspection data is used in [24]. It employs an industrial Boolean expert system, its fuzzified extension and optimizes the fuzzy system parameters using stochastic gradient descent [6] to that database. This fuzzy system outperforms the Boolean system. Inspired by [43], a SVM using daily average consumption features of the last 12 months performs better than the expert systems, too. The three algorithms are compared to each other on samples of varying fraud proportion containing ~100K customers. It uses the area under the (receiver operating characteristic) curve (AUC), which is discussed in Chapter IV-A. For a NTL proportion of 5%, it reports AUC test scores of 0.465, 0.55 and 0.55 for the Boolean system, optimized fuzzy system and SVM, respectively. For a NTL proportion of 20%, it reports AUC test scores of 0.475, 0.545 and 0.55 for the Boolean system, optimized fuzzy system and SVM, respectively.\nFive features of customers\u2019 consumption of the previous six months are derived in [4]: average consumption, maximum consumption, standard deviation, number of inspections and the average consumption of the residential area. These features are then used in a fuzzy c-means clustering algorithm to group the customers into c classes. Subsequently, the fuzzy membership values are used to classify customers into NTL and non-NTL using the Euclidean distance measure. On the test set, an average precision (called average assertiveness) of 0.745 is reported.\nThe database of [41] is used in [42]. In the first step, an ensemble pre-filters the customers to select irregular and regular customers for training which represent well two different classes. This is done because of noise in the inspection labels. In the classification step, a neuro-fuzzy hierarchical system is used. In this setting, a neural network is used to optimize the fuzzy membership parameters, which is a different approach to the stochastic gradient descent method used in [24]. A precision of 0.512 and an accuracy of 0.682 on the test set are obtained.\nThe work in [46] is combined with a fuzzy logic expert system postprocessing the output of the SVM in [45] for ~100K customers. The motivation of that work is to integrate human expert knowledge into the decision making process in order to identify fraudulent behavior. A test recall of 0.72 is reported."}, {"heading": "D. Genetic algorithms", "text": "The work in [43] and [46] is extended by using a genetic SVM in [44] for 1,171 customers. It uses a genetic algorithm in order to globally optimize the hyperparameters of the SVM. Each chromosome contains the Lagrangian multipliers (\u03b11, ..., \u03b1i), regularization factor C and Gaussian kernel parameter \u03b3. This model achieves a test recall of 0.62.\nA data set of ~1.1M customers is used in [18]. The paper identifies the much smaller sample of inspected customers as the main challenge NTL detection. It then proposes stratified sampling in order to increase the number of inspections and to minimize the statistical variance between them. The stratified sampling procedure is defined as a non-linear restricted optimization problem of minimizing the overall energy loss due to electricity theft. This minimization problem is solved using two methods: (1) genetic algorithm and (2) simulated annealing. The first approach outperforms the other one. Only the reduced variance is reported, which is not comparable to the other research and therefore left out of this survey."}, {"heading": "E. Other methods", "text": "Optimum path forests (OPF), a graph-based classifier, is used in [54]. It builds a graph in the feature space and uses socalled \u201cprototypes\u201d or training samples. Those become roots of their optimum-path tree node. Each graph node is classified based on its most strongly connected prototype. This approach is fundamentally different to most other learning algorithms such as SVMs or neural networks which learn hyperplanes. Optimum path forests do not learn parameters, thus making training faster, but predicting slower compared to parametric\nmethods. They are used in [55] for 736 customers and achieved a test accuracy of 0.9021, outperforming SMVs with Gaussian and linear kernels and a neural network which achieved test accuracies of 0.8893, 0.4540 and 0.5301, respectively. Related results and differences between these classifiers are reported in [56].\nRough sets give lower and upper approximations of an original conventional or crisp set. Rough set analysis is applied to NTL detection in [66] on features related to [17]. This supervised learning technique allows to approximate concepts that describe fraud and regular use. A test accuracy of 0.9322 is reported. The first application of rough set analysis applied to NTL detection is described in [12] on 40K customers, but lacks details on the attributes used per customer, for which a test accuracy of 0.2 is achieved.\nDifferent feature selection techniques for customer master data and consumption data are assessed in [53]. Those methods include complete search, best-first search, genetic search and greedy search algorithms for the master data. Other features called shape factors are derived from the consumption time series including the impact of lunch times, nights and weekends on the consumption. These features are used in K-means for clustering similar consumption time series. In the classification step, a decision tree is used to predict whether a customer causes NTLs or not. An overall test accuracy of 0.9997 is reported.\nA different method is to estimate NTLs by subtracting an estimate of the technical losses from the overall losses [63]. It models the resistance of the infrastructure in a temperaturedependent model using regression which approximates the technical losses. It applies the model to a database of 30 customers for which the consumption was recorded for six days with meter readings every 30 minutes for theft levels of 1, 2, 3, 4, 6, 8 and 10%. The respective test recalls in linear circuits are 0.2211, 0.7789, 0.9789, 1, 1, 1 and 1, respectively."}, {"heading": "F. Summary", "text": "A summary and comparison of the performance measures of selected classifiers discussed in this review are reported in Table I. The most commonly used models comprise Boolean and fuzzy expert systems, SVMs and neural networks. In addition, genetic methods, OPF and regression methods are used. Data set sizes have a wide range from 30 up to 700K customers. However, the largest data set of 1.1M customers in [18] is not included in the table because only the variance is reduced and no other performance measure is provided. Accuracy and recall are the most popular performance measures in the literature, ranging from 0.45 to 0.99 and from 0.29 to 1, respectively. Only very few publications report the recall of their models, ranging from 0.51 to 0.85. The AUC is only reported in one publication. The challenges of finding representative performance measures and how to compare individual contributions are discussed in Chapters IV-A and IV-F, respectively."}, {"heading": "IV. CHALLENGES", "text": "The research reviewed in the previous section indicate multiple open challenges. These challenges do not apply\nto single contributions, rather they spread across different contributions. In this section, we focus on discussing these challenges, which are necessary in order to advance in NTL detection. Concretely, we discuss common topics that have not yet received the necessary attention in previous research and put them in the context of machine learning research as a whole."}, {"heading": "A. Class imbalance and evaluation metric", "text": "Imbalanced classes appear frequently in machine learning, however, this fact is mostly not addressed in the literature. This topic is well covered for example in [28] and [68]. The class imbalance also affects the choice of evaluation metrics. Most NTL detection research such as [17], [18], [43], [54] and [66] also ignore this topic and report high accuracies or recalls. The following examples demonstrate why those performance measures are not suitable for NTL detection in imbalanced data sets: for a test set containing 1K customers of which 999 have regular use, (1) a classifier always predicting non-\nNTL has an accuracy of 99.9%, whereas in contrast, (2) a classifier always predicting NTL has a recall of 100%. While the classifier of the first example has a very high accuracy and intuitively seems to perform very well, it will never predict any NTL. In contrast, the classifier of the second example will find all NTL, but trigger many costly and unnecessary physical inspections. This topic is addressed for example in [37] and [41], but do not use a proper single performance measure to describe the performance of a classifier performed on an imbalanced dataset.\nFor NTL detection, the goal is to reduce the false positive rate (FPR) to decrease the number of costly inspections, while increasing the true positive rate (TPR) to find as many NTL occurrences as possible. [24] proposes to use a receiver operating characteristic (ROC) curve, which plots the TPR against the FPR. The area under the curve (AUC) is a performance measure between 0 and 1, where any binary classifier with an AUC > 0.5 performs better than random guessing. In order to assess a NTL prediction model using a single performance measure, the AUC was picked as the most suitable one. In the preliminary work of [24], we noticed that the precision usually grows linearly with the NTL proportion in the data set. It is therefore not suitable for low NTL proportions. However, we did not notice this for the recall and made observations of non-linearity similar to the work of [63] summarized in Table I. With the limitation of precision and recall as isolated performance measures, the F1 score did not prove to work as a reliable performance measure. We believe that it is necessary to investigate more into this topic in order to report reliable and imbalance-independent results that are valid for different levels of imbalance. The Matthews correlation coefficient (MCC) defined in [38]:\nTP \u00d7 TN \u2212 FP \u00d7 FN\u221a (TP + FP )(TP + FN)(TN + FP )(TN + FN) (1)\nmeasures the accuracy of binary classifiers taking into account the imbalance of both classes, ranging from \u22121 to +1. We believe that this measure should be assessed further for NTL detection."}, {"heading": "B. Feature description", "text": "Different feature description methods have been reviewed in the previous section. Hand-crafting features from raw data is a long-standing issue in machine learning having significant impact on the performance of a NTL classifier [23]. Generally, it cannot easily be said if a feature description is good or bad. Deep learning allows to self-learn hidden correlations and increasingly more complex feature hierarchies from the raw data input [34]. This approach has lead to breakthroughs in image analysis and speech recognition [27]. One possible method to overcome the challenge of feature description for NTL detection is by finding a way to apply deep learning to it.\nC. Incorrect inspection results\nIn the preliminary work of [24] we noticed that the inspection result labels in the training set are not always correct\nand that some fraudsters may be labelled as non-fraudulent. The reasons for this may include bribing, blackmailing or threatening of the technician performing the inspection. Also, the fraud may be done too well and it is not observable by technicians. Another reason may be incorrect processing of the data. It must be noted that the latter reason may, however, also label non-fraudulent behavior as fraudulent. Handling noise is a common challenge in machine learning. In supervised machine learning settings, most existing methods address handling noise in the input data. There are different regularization methods such as L1 or L2 regularization [49] or learning of invariances allowing learning algorithms to better handle noise in the input data [10], [35]. However, handling noise in the training labels is less commonly addressed in the machine learning literature. Most NTL detection research use supervised methods and this shortcoming of the training data and potential false positive labels in particular are not much reported in the literature, except in [42].\nUnsupervised methods such as clustering or dimensionality reduction [36] that totally ignore the labels can be used to overcome this limitation. Also, in many situations, most customers have never been inspected. In a purely supervised training strategy, the unlabeled data is discarded. However, using it may support training. This domain is called semisupervised, for which semi-supervised clustering [5] has been proposed. Deep neural networks can be pre-trained using autoencoders or restricted Boltzmann machines [34] in order to take advantage of unlabeled data. Both, unsupervised and semi-supervised learning, should be further explored for NTL detection. Furthermore, we are not aware of research that has applied reinforcement learning to NTL detection. We believe that it can be promising to explore in this direction, as reinforcement learning needs only very little supervision in the form of rewards."}, {"heading": "D. Biased inspection results", "text": "In statistics, samples of data must represent the overall population in order to make valid conclusions. This is a longstanding issue in statistics and therefore in machine learning, too, as discussed in [26]. In the preliminary work of [24] we noticed that the sample of previously inspected customers may not be representative of all customers. One reason is, for example, that electricity suppliers previously focused on certain neighborhoods for inspections. NTL classifiers trained on biased inspection data are likely to be biased, too. To the best of our knowledge, this topic has not been addressed in the literature on NTL detection. Bias correction has initially been addressed in the field of computational learning theory [16]. We believe that it can be promising to explore in this direction. For example, one promising approach may be resampling inspection data in order to be representative in terms of location and type of customer."}, {"heading": "E. Scalability", "text": "The number of customers used throughout the research reviewed significantly varies. For example, [43] and [63] only use less than a few hundred customers in the training. A SVM\nwith a Gaussian kernel is used in [43], for which training is only feasible in a realistic amount of time for up to a couple of ten thousand customers in current implementations [14]. A regression model using the Moore-Penrose pseudoinverse [59] is used in [63]. This model is also only able to scale for up to a couple of ten thousand customers [50]. Models being trained on up to a couple of ten thousand customers include [41] and [17] using neural networks. The training methods used in those papers usually do not scale to significantly larger customer databases. Larger databases using up to hundreds of thousand or millions of customers are used in [18] and [24] using a SVM with linear Kernel or genetic algorithms, respectively.\nWe believe that a stronger investigation into time complexity of learning algorithms, scalable computing models and technologies such as Apache Spark [70] or Google TensorFlow [1] will allow to efficiently handle Big Data sets for NTL detection. This will also allow to perform the computations in a cloud, requiring researchers to make significantly lower investments in hardware."}, {"heading": "F. Comparison of different methods", "text": "Comparing the different methods reviewed in this paper is challenging because they are tested on different data sets, as summarized in Table I. In many cases, the description of the data lacks fundamental properties such as the number of meter readings per customer, NTL proportion, etc. In order to make results better comparable, joint efforts of different research groups are necessary in order to address the comparability of NTL detection system performance based on a comprehensive freely available and sufficiently large data set."}, {"heading": "V. CONCLUSION", "text": "Non-technical losses (NTL) are the predominant type of losses in electricity power grids. We have reviewed their impact on economies and potential losses of revenue and profit for electricity providers. In the literature, a vast variety of NTL detection methods employing artificial intelligence methods are reported. Expert systems and fuzzy systems are traditional detection models. Over the past years, machine learning methods have become more popular. The most commonly used methods are support vector machines and neural networks, which outperform expert systems in most settings. These models are typically applied to features computed from customer consumption profiles such as average consumption, maximum consumption and change of consumption in addition to customer master data features such as type of customer and connection type. Sizes of databases used in the literature have a large range from less than 100 to more than one million. In this survey, we have also identified the six main open challenges in NTL detection: handling imbalanced classes in the training data and choosing appropriate evaluation metrics, describing features from the data, handling incorrect inspection results, correcting the bias in the inspection results, building models scalable to Big Data sets and making results obtained through different methods comparable. We believe that these need to be accurately addressed in future research in order to advance in NTL detection methods. This will allow to share sound,\nassessable, understandable, replicable and scalable results with the research community. In our current research we have started to create a database that we are planning to make available in the future. It will allow research groups to work on these challenges and and to assess their advancement in NTL detection."}], "references": [{"title": "P", "author": ["M. Abadi", "A. Agarwal"], "venue": "Barham, et al., \u201cTensorFlow: Large-Scale Machine Learning on Heterogeneous Systems\u201d", "citeRegEx": "1", "shortCiteRegEx": null, "year": 2015}, {"title": "Power Sector Reform in Bangladesh: Electricity Distribution System", "author": ["M.S. Alam", "E. Kabir", "M.M. Rahman", "M.A.K. Chowdhury"], "venue": "Energy, vol. 29, no. 11, pp. 1773-1783", "citeRegEx": "2", "shortCiteRegEx": null, "year": 2004}, {"title": "Incentives and security in electricity distribution networks", "author": ["S. Amin", "G.A. Schwartz", "H. Tembine"], "venue": "Decision and Game Theory for Security, Springer, pp. 264-280", "citeRegEx": "3", "shortCiteRegEx": null, "year": 2012}, {"title": "Detection and identification of abnormalities in customer consumptions in power distribution systems", "author": ["E.W.S. dos Angelos", "O.R. Saavedra", "O.A. Carmona Cortes", "A. Nunes de Souza"], "venue": "IEEE Transactions on Power Delivery,", "citeRegEx": "4", "shortCiteRegEx": "4", "year": 2011}, {"title": "Semi-supervised clustering methods", "author": ["E. Bair"], "venue": "WIREs Comp Stat, 5(5), pp. 349-361", "citeRegEx": "5", "shortCiteRegEx": null, "year": 2013}, {"title": "Stochastic Learning", "author": ["K. Bottou"], "venue": "Advanced Lectures on Machine Learning, LNAI 3176, Springer, pp. 146-168", "citeRegEx": "6", "shortCiteRegEx": null, "year": 2004}, {"title": "Scaling to very very large corpora for natural language disambiguation", "author": ["M. Banko", "E. Brill"], "venue": "Proceedings of the 39th annual meeting on association for computational linguistics, pp. 26-33", "citeRegEx": "7", "shortCiteRegEx": null, "year": 2001}, {"title": "Reforming the Power Sector", "author": ["B. Bhatia", "M. Gulati"], "venue": "Controlling Electricity Theft and Improving Revenue\u201d, World Bank", "citeRegEx": "8", "shortCiteRegEx": null, "year": 2004}, {"title": "Neural Networks for Pattern Recognition", "author": ["C.M. Bishop"], "venue": "Clarendon Press", "citeRegEx": "9", "shortCiteRegEx": null, "year": 1996}, {"title": "Pattern Recognition and Machine Learning", "author": ["C.M. Bishop"], "venue": "Springer", "citeRegEx": "10", "shortCiteRegEx": null, "year": 2007}, {"title": "Statistical fraud detection: A review Statistical science", "author": ["R.J. Bolton", "D.J. Hand"], "venue": "Statist. Sci., vol. 17, issue 3, pp. 235-255", "citeRegEx": "11", "shortCiteRegEx": null, "year": 2002}, {"title": "Rough Sets Based Fraud Detection in Electrical Energy Consumers", "author": ["J.E. Cabral", "J.O.P. Pinto", "E.M. Gontijo", "J. Reis Filho"], "venue": "WSEAS Transactions on Mathematics, issue 2, vol. 3, pp. 413-416", "citeRegEx": "12", "shortCiteRegEx": null, "year": 2004}, {"title": "Fraud detection system for high and low voltage electricity consumers based on data mining", "author": ["J.E. Cabral", "J.O.P. Pinto", "A.M.A.C. Pinto"], "venue": "Power & Energy Society General Meeting (PES\u201909)", "citeRegEx": "13", "shortCiteRegEx": null, "year": 2009}, {"title": "LIBSVM: A library for support vector machines", "author": ["C.-C. Chang", "C.-J. Lin"], "venue": "ACM Transactions on Intelligent Systems and Technology, vol. 2, issue 3, pp. 27:1-27:27", "citeRegEx": "14", "shortCiteRegEx": null, "year": 2011}, {"title": "Non-Technical Losses in power system: A review", "author": ["A. Chauhan", "S. Rajvanshi"], "venue": "2013 International Conference on Power, Energy and Control (ICPEC), pp. 558-561", "citeRegEx": "15", "shortCiteRegEx": null, "year": 2013}, {"title": "Domain adaptation and sample bias correction theory and algorithm for regression", "author": ["C. Cortes", "M. Mohri"], "venue": "Theoretical Computer Science, vol. 519, pp. 103-126", "citeRegEx": "16", "shortCiteRegEx": null, "year": 2013}, {"title": "Fraud detection in electric power distribution networks using an ANNbased knowledge-discovery process", "author": ["B.C. Costa", "B.L. Alberto", "A.M. Portela", "W. Maduro", "E.O. Eler"], "venue": "International Journal of Artificial Intelligence & Applications, vol. 4, no. 6", "citeRegEx": "17", "shortCiteRegEx": null, "year": 2013}, {"title": "Optimization metaheuristics for minimizing variance in a realworld statistical application", "author": ["E. Costa", "F. Fabris", "A. Rodrigues Loureiros", "H. Ahonen", "F. Miguel Varejao"], "venue": "SAC \u201913 Proceedings of the 28th Annual ACM Symposium on Applied Computing, pp. 206-207", "citeRegEx": "18", "shortCiteRegEx": null, "year": 2013}, {"title": "MapReduce: Simplified Data Processing on Large Clusters", "author": ["J. Dean", "S. Ghemawat"], "venue": "OSDI\u201904: Sixth Symposium on Operating System Design and Implementation", "citeRegEx": "19", "shortCiteRegEx": null, "year": 2004}, {"title": "Enhanced encoding technique for identifying abnormal energy usage pattern", "author": ["S.S.S.R. Depuru", "L. Wang", "V. Devabhaktuni"], "venue": "North American Power Symposium (NAPS)", "citeRegEx": "20", "shortCiteRegEx": null, "year": 2012}, {"title": "Support vector machine based data classification for detection of electricity theft", "author": ["S.S.S.R. Depuru", "L. Wang", "V. Devabhaktuni"], "venue": "Power Systems Conference and Exposition (PSCE)", "citeRegEx": "21", "shortCiteRegEx": null, "year": 2011}, {"title": "High Performance Computing for Detection of Electricity Theft", "author": ["S.S.S.R. Depuru", "L. Wang", "V. Devabhaktuni", "R.C. Green"], "venue": "International Journal of Electrical Power & Energy Systems,", "citeRegEx": "22", "shortCiteRegEx": "22", "year": 2013}, {"title": "A few useful things to know about machine learning", "author": ["P. Domingos"], "venue": "Communications of the ACM,", "citeRegEx": "23", "shortCiteRegEx": "23", "year": 2012}, {"title": "Large-Scale Detection of Non-Technical Losses in Imbalanced Data Sets", "author": ["P. Glauner", "A. Boechat", "L. Dolberg", "R. State", "F. Bettinger", "Y. Rangoni", "D. Duarte"], "venue": "submitted to the Seventh IEEE Conference on Innovative Smart Grid Technologies ", "citeRegEx": "24", "shortCiteRegEx": null, "year": 2016}, {"title": "Handwritten digit recognition using statistical and rule-based decision fusion", "author": ["D. Gorgevik", "D. Cakmakov", "V. Radevski"], "venue": "11th Mediterranean Electrotechnical Conference (MELECON), pp. 131-135", "citeRegEx": "25", "shortCiteRegEx": null, "year": 2002}, {"title": "Big data: are we making a big mistake?", "author": ["Tim Harford"], "venue": "FT Magazine, March", "citeRegEx": "26", "shortCiteRegEx": "26", "year": 2014}, {"title": "Deep Neural Networks for Acoustic Modeling in Speech Recognition", "author": ["G. Hinton", "L. Deng", "D. Yu", "A. Mohamed", "N. Jaitly", "A. Senior", "V. Vanhoucke", "P. Nguyen", "T. Sainath", "G. Dahl", "B. Kingsbury"], "venue": "IEEE Signal Processing Magazine, 29 (6), 82-97", "citeRegEx": "27", "shortCiteRegEx": null, "year": 2012}, {"title": "The class imbalance problem: A systematic study", "author": ["N. Japkowicz", "S. Stephen"], "venue": "Intelligent Data Analysis, vol. 6, issue 5, pp. 429-449", "citeRegEx": "28", "shortCiteRegEx": null, "year": 2002}, {"title": "Energy-theft detection issues for advanced metering infrastructure in smart grid", "author": ["R. Jiang", "R. Lu", "Y. Wang", "J. Luo"], "venue": "Tsinghua Science and Technology, vol. 19, issue 2, pp. 105-120", "citeRegEx": "29", "shortCiteRegEx": null, "year": 2014}, {"title": "Literature review on the applications of data mining in power systems", "author": ["M. Kazerooni", "H. Zhu", "T.J. Overbye"], "venue": "Power and Energy Conference at Illinois (PECI)", "citeRegEx": "30", "shortCiteRegEx": null, "year": 2014}, {"title": "An introduction to knowledge engineering", "author": ["S.L. Kendal", "M. Creen"], "venue": "Springer, ISBN 978-1-84628-475-5", "citeRegEx": "31", "shortCiteRegEx": null, "year": 2007}, {"title": "Survey of fraud detection techniques", "author": ["Y. Kou", "C.-T. Lu", "S. Sirwongwattana", "Y.-P. Huang"], "venue": "IEEE International Conference on Networking, Sensing and Control, vol. 2, pp. 749-754", "citeRegEx": "32", "shortCiteRegEx": null, "year": 2004}, {"title": "A mission planning expert system for an autonomous underwater vehicle", "author": ["S.H. Kwak"], "venue": "Proceedings of the 1990 Symposium on Autonomous Underwater Vehicle Technology, pp. 123-128", "citeRegEx": "33", "shortCiteRegEx": null, "year": 1990}, {"title": "Handwritten digit recognition with a back-propagation network", "author": ["Y. LeCun", "B. Boser", "J.S. Denker", "D. Henderson", "R.E. Howard", "W. Hubbard", "L.D. Jackel"], "venue": "Advances in Neural Information Processing Systems 2 (NIPS \u201989), Denver, CO", "citeRegEx": "35", "shortCiteRegEx": null, "year": 1990}, {"title": "Visualizing High-Dimensional Data Using t-SNE", "author": ["L.J.P. van der Maaten", "G.E. Hinton"], "venue": "Journal of Machine Learning Research,", "citeRegEx": "36", "shortCiteRegEx": "36", "year": 2008}, {"title": "J", "author": ["M. Di Martino", "F. Decia"], "venue": "Molinelli and Alicia Fernandez, \u201cImproving electric fraud detection using class imbalance strategies\u201d", "citeRegEx": "37", "shortCiteRegEx": null, "year": 2012}, {"title": "Comparison of the predicted and observed secondary structure of T4 phage lysozyme", "author": ["B.W. Matthews"], "venue": "Biochimica et Biophysica Acta (BBA) - Protein Structure 405 (2): pp. 442-451", "citeRegEx": "38", "shortCiteRegEx": null, "year": 1975}, {"title": "N", "author": ["J. McCarthy", "M. Minsky"], "venue": "Rochester and C. Shannon, \u201cA Proposal for the Dartmouth Summer Research Project on Artificial Intelligence\u201d", "citeRegEx": "39", "shortCiteRegEx": null, "year": 1955}, {"title": "Energy Theft in the Advanced Metering Infrastructure", "author": ["S. McLaughlin", "D. Podkuiko", "P. McDaniel"], "venue": "Lecture Notes in Computer Science, vol. 6027, pp. 176-187", "citeRegEx": "40", "shortCiteRegEx": null, "year": 2009}, {"title": "Irregularity detection on low tension electric installations by neural network ensembles", "author": ["C. Muniz", "K. Figueiredo", "M.M.B.R. Vellasco", "G. Chavez", "M.A.C. Pacheco"], "venue": "IEEE - INNS - ENNS International Joint Conference on Neural Networks,", "citeRegEx": "41", "shortCiteRegEx": "41", "year": 2009}, {"title": "Neuro-fuzzy System for Fraud Detection in Electricity Distribution", "author": ["C. Muniz", "M.M.B.R. Vellasco", "R. Tanscheit", "K.A. Figueiredo"], "venue": "IFSA/EUSFLAT Conference, pp. 1096-1101", "citeRegEx": "42", "shortCiteRegEx": null, "year": 2009}, {"title": "Non-Technical Loss analysis for detection of electricity theft using support vector machines", "author": ["J. Nagi", "A.M. Mohamad", "K.S. Yap", "S.K Tiong"], "venue": "IEEE 2nd International Power and Energy Conference ", "citeRegEx": "43", "shortCiteRegEx": null, "year": 2008}, {"title": "Detection of abnormalities and electricity theft using genetic Support Vector Machines", "author": ["J. Nagi", "K.S. Yap", "S.K. Tiong", "S.K. Ahmed", "A.M. Mohammad"], "venue": "2008 IEEE Region 10 Conference TENCON", "citeRegEx": "44", "shortCiteRegEx": null, "year": 2008}, {"title": "Improving SVM-Based Nontechnical Loss Detection in Power Utility Using the Fuzzy Inference System", "author": ["J. Nagi", "K.S. Yap", "S.K. Tiong", "S.K. Ahmed", "F. Nagi"], "venue": "IEEE Transactions on Power Delivery, vol. 26, no. 2, pp. 1284-1285", "citeRegEx": "45", "shortCiteRegEx": null, "year": 2011}, {"title": "S", "author": ["J. Nagi", "K.S. Yap", "S.K. Tiong"], "venue": "K. and A. M. Mohamad, \u201cNontechnical Loss Detection for Metered Customers in Power Utility Using Support Vector Machines\u201d, IEEE Transactions on Power Delivery, vol. 25, no. 2, pp. 1162-1171", "citeRegEx": "46", "shortCiteRegEx": null, "year": 2009}, {"title": "NTL detection of electricity theft and abnormalities for large power consumers In TNB Malaysia", "author": ["J. Nagi", "K.S. Yap", "F. Nagi", "S.K. Tiong", "S.P. Koh", "S.K. Ahmed"], "venue": "2010 IEEE Student Conference on Research and Development (SCOReD), pp. 202-206", "citeRegEx": "47", "shortCiteRegEx": null, "year": 2010}, {"title": "REACTOR: An Expert System for Diagnosis and Treatment of Nuclear Reactor Accidents", "author": ["W.R. Nelson"], "venue": "Proceedings AAAI-82", "citeRegEx": "48", "shortCiteRegEx": null, "year": 1982}, {"title": "Feature selection", "author": ["A. Ng"], "venue": "L1 vs. L2 regularization, and rotational invariance\u201d, Stanford", "citeRegEx": "49", "shortCiteRegEx": null, "year": 2004}, {"title": "Machine Learning", "author": ["A. Ng"], "venue": "Coursera", "citeRegEx": "50", "shortCiteRegEx": null, "year": 2014}, {"title": "Inverted autonomous helicopter flight via reinforcement learning", "author": ["A. Ng", "A. Coates", "M. Diel", "V. Ganapathi", "J. Schulte", "B. Tse", "E. Berger", "E. Liang"], "venue": "International Symposium on Experimental Robotics", "citeRegEx": "51", "shortCiteRegEx": null, "year": 2004}, {"title": "Power Utility Nontechnical Loss Analysis With Extreme Learning Machine Method", "author": ["A.H. Nizar", "Z.Y. Dong", "Y. Wang"], "venue": "IEEE Transactions on Power Systems, vol. 23, issue 3, pp. 946-955", "citeRegEx": "52", "shortCiteRegEx": null, "year": 2008}, {"title": "Customer information system data pre-processing with feature selection techniques for non-technical losses prediction in an electricity market", "author": ["A.H. Nizar", "J.H. Zhao", "Z.Y. Dong"], "venue": "International Conference on Power System Technology ", "citeRegEx": "53", "shortCiteRegEx": null, "year": 2006}, {"title": "A New Approach for Nontechnical Losses Detection Based on Optimum- Path Forest", "author": ["C.C. Oba Ramos", "A. Nunes Souza", "J. Paulo Papa", "A. Xavier Falcao"], "venue": "IEEE Transactions on Power Systems, vol. 26, issue 1, pp. 181-189", "citeRegEx": "54", "shortCiteRegEx": null, "year": 2011}, {"title": "Fast Non-Technical Losses Identification Through Optimum-Path Forest", "author": ["C.C. Oba Ramos", "A.N. de Souza", "J.P. Papa", "A.X. Falcao"], "venue": "15th International Conference on Intelligent System Applications to Power Systems (ISAP),", "citeRegEx": "55", "shortCiteRegEx": "55", "year": 2009}, {"title": "Learning to Identify Non-Technical Losses with Optimum-Path Forest", "author": ["C.C. Oba Ramos", "A. Nunes Souza", "J. Paulo Papa", "A. Xavier Falcao"], "venue": "17th International Conference on Systems, Signals and Image Processing ", "citeRegEx": "56", "shortCiteRegEx": null, "year": 2010}, {"title": "A", "author": ["C.C. Oba Ramos"], "venue": "Nunes de Souza, D. Sinkiti Gastaldello and J. Paulo Papa, \u201cIdentification and feature selection of non-technical losses for industrial consumers using the software WEKA\u201d, International Conference on Industry Applications", "citeRegEx": "57", "shortCiteRegEx": null, "year": 2012}, {"title": "Cavaretti, \u201cA New Method for the Computation of Technical Losses in Electrical Power Distribution Systems", "author": ["C.C.B. de Oliveira", "N. Kagan", "A. Meffe", "J.L.S.L. Caparroz"], "venue": "Proceedings ClRED,", "citeRegEx": "58", "shortCiteRegEx": "58", "year": 2001}, {"title": "A generalized inverse for matrices", "author": ["R. Penrose"], "venue": "Proceedings of the Cambridge Philosophical Society 51, pp. 406-413", "citeRegEx": "59", "shortCiteRegEx": null, "year": 1955}, {"title": "Multilayer perceptron neural networks training through charged system search and its Application for non-technical losses detection", "author": ["L.A.M. Pereira", "L.C.S. Afonso", "J.P. Papa", "Z.A. Vale", "C.C.O. Ramos", "D.S. Gastaldello", "A.N. Souza"], "venue": "Conference On Innovative Smart Grid Technologies Latin America (ISGT LA)", "citeRegEx": "60", "shortCiteRegEx": null, "year": 2013}, {"title": "Reinforcement Learning for Humanoid Robotics", "author": ["J. Peters", "S. Vijayakumar", "S. Schaal"], "venue": "IEEE-RAS International Conference on Humanoid Robots", "citeRegEx": "61", "shortCiteRegEx": null, "year": 2003}, {"title": "Artificial Intelligence: A Modern Approach", "author": ["S. Russel", "P. Norvig"], "venue": "Prentice Hall, Third Edition", "citeRegEx": "62", "shortCiteRegEx": null, "year": 2009}, {"title": "Electricity theft detection using smart meter data", "author": ["S. Sahoo", "D. Nikovski", "T. Muso", "K. Tsuru"], "venue": "IEEE Power & Energy Society Innovative Smart Grid Technologies Conference (ISGT)", "citeRegEx": "63", "shortCiteRegEx": null, "year": 2015}, {"title": "G", "author": ["D. Silver", "A. Huang", "C.J. Maddison", "A. Guez", "L. Sifre"], "venue": "van den Driessche, J. Schrittwieser, I. Antonoglou, V. Panneershelvam, M. Lanctot, S. Dieleman, D. Grewe, J. Nham, N. Kalchbrenner, I. Sutskever, T. Lillicrap, M. Leach, K. Kavukcuoglu, T. Graepel and D. Hassabis, \u201cMastering the game of Go with deep neural networks and tree search\u201d, Nature, vol. 529, pp. 484-489", "citeRegEx": "64", "shortCiteRegEx": null, "year": 2016}, {"title": "Electricity theft: a comparative analysis", "author": ["T.B. Smith"], "venue": "Energy Policy,", "citeRegEx": "65", "shortCiteRegEx": "65", "year": 2004}, {"title": "Using the rough set theory to detect fraud committed by electricity customers", "author": ["J.V. Spiric", "S.S. Stankovic", "M.B. Docic", "T.D. Popovic"], "venue": "International Journal of Electrical Power & Energy Systems,", "citeRegEx": "66", "shortCiteRegEx": "66", "year": 2014}, {"title": "Reinforcement Learning: An Introduction", "author": ["R.S. Sutton", "A.G. Barto"], "venue": "MIT Press", "citeRegEx": "67", "shortCiteRegEx": null, "year": 1998}, {"title": "SVMs Modeling for Highly Imbalanced Classification", "author": ["Y. Tang", "Y.-Q. Zhang", "N.V. Chawla", "S. Krasser"], "venue": "IEEE Transactions on Systems, Man, and Cybernetics, Part B: Cybernetics,", "citeRegEx": "68", "shortCiteRegEx": "68", "year": 2009}, {"title": "An overview of statistical learning theory", "author": ["V.N. Vapnik"], "venue": "IEEE Transactions on Neural Networks,", "citeRegEx": "69", "shortCiteRegEx": "69", "year": 1999}, {"title": "Spark: cluster computing with working sets", "author": ["M. Zaharia", "M. Chowdhury", "M.J. Franklin", "S. Shenker", "I. Stoica"], "venue": "HotCloud\u201910 Proceedings of the 2nd USENIX conference on Hot topics in cloud computing", "citeRegEx": "70", "shortCiteRegEx": null, "year": 2010}], "referenceMentions": [{"referenceID": 44, "context": "losses [46].", "startOffset": 7, "endOffset": 11}, {"referenceID": 2, "context": "Therefore, it is most beneficial to first reduce NTLs before reducing technical losses [3].", "startOffset": 87, "endOffset": 90}, {"referenceID": 14, "context": "In particular, NTLs include, but are not limited to, the following causes [15], [65]:", "startOffset": 74, "endOffset": 78}, {"referenceID": 63, "context": "In particular, NTLs include, but are not limited to, the following causes [15], [65]:", "startOffset": 80, "endOffset": 84}, {"referenceID": 7, "context": "5 billion [8].", "startOffset": 10, "endOffset": 13}, {"referenceID": 21, "context": "NTLs also reported to range up to 40% of the total electricity distributed in countries such as Brazil, India, Malaysia or Lebanon [22], [45].", "startOffset": 131, "endOffset": 135}, {"referenceID": 43, "context": "NTLs also reported to range up to 40% of the total electricity distributed in countries such as Brazil, India, Malaysia or Lebanon [22], [45].", "startOffset": 137, "endOffset": 141}, {"referenceID": 1, "context": "They are also of relevance in developed countries, for example estimates of NTLs in the UK and US range from US$ 1-6 billion [2], [46].", "startOffset": 125, "endOffset": 128}, {"referenceID": 44, "context": "They are also of relevance in developed countries, for example estimates of NTLs in the UK and US range from US$ 1-6 billion [2], [46].", "startOffset": 130, "endOffset": 134}, {"referenceID": 56, "context": "perspective, one method to detect losses is to calculate the energy balance [58], which requires topological information of the network.", "startOffset": 76, "endOffset": 80}, {"referenceID": 60, "context": "A more flexible and adaptable approach is to employ artificial intelligence (AI) [62].", "startOffset": 81, "endOffset": 85}, {"referenceID": 60, "context": "The field of artificial intelligence (AI) attempts to both understand and build intelligent entities [62].", "startOffset": 101, "endOffset": 105}, {"referenceID": 37, "context": "ence hosted at Darmouth College [39].", "startOffset": 32, "endOffset": 36}, {"referenceID": 46, "context": "[48] or mission planning of autonomous underwater vehicles [33], they have the following shortcomings: (1) incorporating expert knowledge in rules is challenging, (2) many domains cannot accurately be described in rules and (3) domain knowledge may change over time requiring amendments of the rules [31].", "startOffset": 0, "endOffset": 4}, {"referenceID": 32, "context": "[48] or mission planning of autonomous underwater vehicles [33], they have the following shortcomings: (1) incorporating expert knowledge in rules is challenging, (2) many domains cannot accurately be described in rules and (3) domain knowledge may change over time requiring amendments of the rules [31].", "startOffset": 59, "endOffset": 63}, {"referenceID": 30, "context": "[48] or mission planning of autonomous underwater vehicles [33], they have the following shortcomings: (1) incorporating expert knowledge in rules is challenging, (2) many domains cannot accurately be described in rules and (3) domain knowledge may change over time requiring amendments of the rules [31].", "startOffset": 300, "endOffset": 304}, {"referenceID": 24, "context": "Both approaches have their justification and neither is generally better or worse than the other in artificial intelligence [25].", "startOffset": 124, "endOffset": 128}, {"referenceID": 48, "context": "Machine learning gives computers the ability to learn from data without being explicitly programmed [50].", "startOffset": 100, "endOffset": 104}, {"referenceID": 33, "context": "cantly improve AI in various applications, such as in handwritten digit recognition [35], facial expression recognition [71] or speech recognition [27].", "startOffset": 84, "endOffset": 88}, {"referenceID": 26, "context": "cantly improve AI in various applications, such as in handwritten digit recognition [35], facial expression recognition [71] or speech recognition [27].", "startOffset": 147, "endOffset": 151}, {"referenceID": 9, "context": "This is also called function induction and typical applications include regression or classification [10].", "startOffset": 101, "endOffset": 105}, {"referenceID": 6, "context": "lot of representative data is considered sometimes to be more relevant than the actual algorithm [7].", "startOffset": 97, "endOffset": 100}, {"referenceID": 9, "context": "the data [10].", "startOffset": 9, "endOffset": 13}, {"referenceID": 34, "context": "Applications include dimensionality reduction methods such as the Principal Component Analysis (PCA) or t-sne [36] and clustering algorithms such as K-means.", "startOffset": 110, "endOffset": 114}, {"referenceID": 65, "context": "Reinforcement learning is a reward-based learning technique for actions in order to get to a goal [67].", "startOffset": 98, "endOffset": 102}, {"referenceID": 59, "context": "It has for example successfully been applied to humanoid robotics [61], autonomous helicopter flying [51] and playing the game of Go at super-human performance [64].", "startOffset": 66, "endOffset": 70}, {"referenceID": 49, "context": "It has for example successfully been applied to humanoid robotics [61], autonomous helicopter flying [51] and playing the game of Go at super-human performance [64].", "startOffset": 101, "endOffset": 105}, {"referenceID": 62, "context": "It has for example successfully been applied to humanoid robotics [61], autonomous helicopter flying [51] and playing the game of Go at super-human performance [64].", "startOffset": 160, "endOffset": 164}, {"referenceID": 10, "context": "NTL detection can be treated as a special case of fraud detection, for which a general survey is provided in [11] and [32].", "startOffset": 109, "endOffset": 113}, {"referenceID": 31, "context": "NTL detection can be treated as a special case of fraud detection, for which a general survey is provided in [11] and [32].", "startOffset": 118, "endOffset": 122}, {"referenceID": 14, "context": "For other surveys of the past efforts in the field, readers are referred to [15] and [30].", "startOffset": 76, "endOffset": 80}, {"referenceID": 29, "context": "For other surveys of the past efforts in the field, readers are referred to [15] and [30].", "startOffset": 85, "endOffset": 89}, {"referenceID": 28, "context": "Overviews of possible methods to manipulate a smart metering infrastructure are provided in [29] and [40].", "startOffset": 92, "endOffset": 96}, {"referenceID": 38, "context": "Overviews of possible methods to manipulate a smart metering infrastructure are provided in [29] and [40].", "startOffset": 101, "endOffset": 105}, {"referenceID": 67, "context": "Support Vector Machines (SVM) [69] are a state-of-the-art classification algorithm that is less prone to overfitting.", "startOffset": 30, "endOffset": 34}, {"referenceID": 41, "context": "having each 25 monthly meter readings in the period from June 2006 to June 2008 are used in [43].", "startOffset": 92, "endOffset": 96}, {"referenceID": 44, "context": "In addition, credit worthiness ranking (CWR) is used in [46].", "startOffset": 56, "endOffset": 60}, {"referenceID": 20, "context": "SVMs are also applied on 1,350 Indian customer profiles in [21].", "startOffset": 59, "endOffset": 63}, {"referenceID": 19, "context": "This work is extended in [20] by encoding the 4\u00d724 = 96-dimensional input in a lower dimension indicating possible irregularities.", "startOffset": 25, "endOffset": 29}, {"referenceID": 21, "context": "This work is extended in [22] by introducing high performance computing algorithms in order to enhance the performance of", "startOffset": 25, "endOffset": 29}, {"referenceID": 19, "context": "the previously developed algorithms in [20].", "startOffset": 39, "endOffset": 43}, {"referenceID": 55, "context": "Consumption profiles of 5K Brazilian industrial customer profiles are analyzed in [57].", "startOffset": 82, "endOffset": 86}, {"referenceID": 8, "context": "Neural networks [9] are loosely inspired by how the human brain works and allow to learn complex hypotheses from", "startOffset": 16, "endOffset": 19}, {"referenceID": 39, "context": "samples of a data set containing ~20K customers in [41].", "startOffset": 51, "endOffset": 55}, {"referenceID": 16, "context": "A data set of ~22K customers is used in [17] for training a neural network.", "startOffset": 40, "endOffset": 44}, {"referenceID": 50, "context": "30 minutes in [52], for which a test accuracy of 0.", "startOffset": 14, "endOffset": 18}, {"referenceID": 12, "context": "SOMs are applied to weekly customer data of 2K customers consisting of meter readings of 15 minutes in [13].", "startOffset": 103, "endOffset": 107}, {"referenceID": 45, "context": "Profiles of 80K low-voltage and 6K high-voltage customers in Malaysia having meter readings every 30 minutes over a period of 30 days are used in [47] for electricity theft and abnormality detection.", "startOffset": 146, "endOffset": 150}, {"referenceID": 43, "context": "This work is related to features of [45], however, it uses entirely fuzzy logic incorporating human expert knowledge", "startOffset": 36, "endOffset": 40}, {"referenceID": 23, "context": "inspection data is used in [24].", "startOffset": 27, "endOffset": 31}, {"referenceID": 5, "context": "It employs an industrial Boolean expert system, its fuzzified extension and optimizes the fuzzy system parameters using stochastic gradient descent [6] to that database.", "startOffset": 148, "endOffset": 151}, {"referenceID": 41, "context": "Inspired by [43], a SVM using daily", "startOffset": 12, "endOffset": 16}, {"referenceID": 3, "context": "Five features of customers\u2019 consumption of the previous six months are derived in [4]: average consumption, maximum consumption, standard deviation, number of inspections and the average consumption of the residential area.", "startOffset": 82, "endOffset": 85}, {"referenceID": 39, "context": "The database of [41] is used in [42].", "startOffset": 16, "endOffset": 20}, {"referenceID": 40, "context": "The database of [41] is used in [42].", "startOffset": 32, "endOffset": 36}, {"referenceID": 23, "context": "In this setting, a neural network is used to optimize the fuzzy membership parameters, which is a different approach to the stochastic gradient descent method used in [24].", "startOffset": 167, "endOffset": 171}, {"referenceID": 44, "context": "The work in [46] is combined with a fuzzy logic expert system postprocessing the output of the SVM in [45] for", "startOffset": 12, "endOffset": 16}, {"referenceID": 43, "context": "The work in [46] is combined with a fuzzy logic expert system postprocessing the output of the SVM in [45] for", "startOffset": 102, "endOffset": 106}, {"referenceID": 41, "context": "The work in [43] and [46] is extended by using a genetic SVM in [44] for 1,171 customers.", "startOffset": 12, "endOffset": 16}, {"referenceID": 44, "context": "The work in [43] and [46] is extended by using a genetic SVM in [44] for 1,171 customers.", "startOffset": 21, "endOffset": 25}, {"referenceID": 42, "context": "The work in [43] and [46] is extended by using a genetic SVM in [44] for 1,171 customers.", "startOffset": 64, "endOffset": 68}, {"referenceID": 17, "context": "1M customers is used in [18].", "startOffset": 24, "endOffset": 28}, {"referenceID": 52, "context": "Optimum path forests (OPF), a graph-based classifier, is used in [54].", "startOffset": 65, "endOffset": 69}, {"referenceID": 53, "context": "They are used in [55] for 736 customers and achieved", "startOffset": 17, "endOffset": 21}, {"referenceID": 54, "context": "Related results and differences between these classifiers are reported in [56].", "startOffset": 74, "endOffset": 78}, {"referenceID": 64, "context": "Rough set analysis is applied to NTL detection in [66] on features related to [17].", "startOffset": 50, "endOffset": 54}, {"referenceID": 16, "context": "Rough set analysis is applied to NTL detection in [66] on features related to [17].", "startOffset": 78, "endOffset": 82}, {"referenceID": 11, "context": "The first application of rough set analysis applied to NTL detection is described in [12] on 40K customers, but", "startOffset": 85, "endOffset": 89}, {"referenceID": 51, "context": "Different feature selection techniques for customer master data and consumption data are assessed in [53].", "startOffset": 101, "endOffset": 105}, {"referenceID": 61, "context": "A different method is to estimate NTLs by subtracting an estimate of the technical losses from the overall losses [63].", "startOffset": 114, "endOffset": 118}, {"referenceID": 17, "context": "1M customers in [18] is not included in the table because only the variance is reduced and no other performance measure is provided.", "startOffset": 16, "endOffset": 20}, {"referenceID": 12, "context": "[13] SOM 2K 0.", "startOffset": 0, "endOffset": 4}, {"referenceID": 16, "context": "[17] NN 22K 0.", "startOffset": 0, "endOffset": 4}, {"referenceID": 20, "context": "[21] SVM (Gauss) 1,350 0.", "startOffset": 0, "endOffset": 4}, {"referenceID": 23, "context": "[24] Bool rules 700K - - - 0.", "startOffset": 0, "endOffset": 4}, {"referenceID": 23, "context": "[24] Fuzzy rules 700K - - - 0.", "startOffset": 0, "endOffset": 4}, {"referenceID": 23, "context": "[24] SVM (linear) 700K - - - 0.", "startOffset": 0, "endOffset": 4}, {"referenceID": 23, "context": "[24] Bool rules 700K - - - 0.", "startOffset": 0, "endOffset": 4}, {"referenceID": 23, "context": "[24] Fuzzy rules 700K - - - 0.", "startOffset": 0, "endOffset": 4}, {"referenceID": 23, "context": "[24] SVM (linear) 700K - - - 0.", "startOffset": 0, "endOffset": 4}, {"referenceID": 40, "context": "[42] Neuro-fuzzy 20K 0.", "startOffset": 0, "endOffset": 4}, {"referenceID": 41, "context": "[43] SVM < 400 - - 0.", "startOffset": 0, "endOffset": 4}, {"referenceID": 42, "context": "[44] Genetic SVM 1,171 - - 0.", "startOffset": 0, "endOffset": 4}, {"referenceID": 43, "context": "[45] SVM + fuzzy 100K - - 0.", "startOffset": 0, "endOffset": 4}, {"referenceID": 44, "context": "[46] SVM (Gauss) < 400 0.", "startOffset": 0, "endOffset": 4}, {"referenceID": 51, "context": "[53] Decision tree N/A 0.", "startOffset": 0, "endOffset": 4}, {"referenceID": 53, "context": "[55] OPF 736 0.", "startOffset": 0, "endOffset": 4}, {"referenceID": 53, "context": "[55] SVM (Gauss) 736 0.", "startOffset": 0, "endOffset": 4}, {"referenceID": 53, "context": "[55] SVM (linear) 736 0.", "startOffset": 0, "endOffset": 4}, {"referenceID": 53, "context": "[55] NN 736 0.", "startOffset": 0, "endOffset": 4}, {"referenceID": 55, "context": "[57] SVM 5K 0.", "startOffset": 0, "endOffset": 4}, {"referenceID": 55, "context": "[57] KNN 5K 0.", "startOffset": 0, "endOffset": 4}, {"referenceID": 55, "context": "[57] NN 5K 0.", "startOffset": 0, "endOffset": 4}, {"referenceID": 61, "context": "[63] Regression 30 - - 0.", "startOffset": 0, "endOffset": 4}, {"referenceID": 61, "context": "[63] Regression 30 - - 0.", "startOffset": 0, "endOffset": 4}, {"referenceID": 61, "context": "[63] Regression 30 - - 0.", "startOffset": 0, "endOffset": 4}, {"referenceID": 61, "context": "[63] Regression 30 - - 1 - 4-10%", "startOffset": 0, "endOffset": 4}, {"referenceID": 64, "context": "[66] Rough sets N/A 0.", "startOffset": 0, "endOffset": 4}, {"referenceID": 27, "context": "This topic is well covered for example in [28] and [68].", "startOffset": 42, "endOffset": 46}, {"referenceID": 66, "context": "This topic is well covered for example in [28] and [68].", "startOffset": 51, "endOffset": 55}, {"referenceID": 16, "context": "Most NTL detection research such as [17], [18], [43], [54] and [66] also ignore this topic and report high accuracies or recalls.", "startOffset": 36, "endOffset": 40}, {"referenceID": 17, "context": "Most NTL detection research such as [17], [18], [43], [54] and [66] also ignore this topic and report high accuracies or recalls.", "startOffset": 42, "endOffset": 46}, {"referenceID": 41, "context": "Most NTL detection research such as [17], [18], [43], [54] and [66] also ignore this topic and report high accuracies or recalls.", "startOffset": 48, "endOffset": 52}, {"referenceID": 52, "context": "Most NTL detection research such as [17], [18], [43], [54] and [66] also ignore this topic and report high accuracies or recalls.", "startOffset": 54, "endOffset": 58}, {"referenceID": 64, "context": "Most NTL detection research such as [17], [18], [43], [54] and [66] also ignore this topic and report high accuracies or recalls.", "startOffset": 63, "endOffset": 67}, {"referenceID": 35, "context": "[37] and [41], but do not use a proper single performance measure to describe the performance of a classifier performed on an imbalanced dataset.", "startOffset": 0, "endOffset": 4}, {"referenceID": 39, "context": "[37] and [41], but do not use a proper single performance measure to describe the performance of a classifier performed on an imbalanced dataset.", "startOffset": 9, "endOffset": 13}, {"referenceID": 23, "context": "[24] proposes to use a receiver operating characteristic (ROC) curve, which plots the TPR against the FPR.", "startOffset": 0, "endOffset": 4}, {"referenceID": 23, "context": "In the preliminary work of [24], we noticed that the precision usually grows linearly with the NTL proportion in the data set.", "startOffset": 27, "endOffset": 31}, {"referenceID": 61, "context": "However, we did not notice this for the recall and made observations of non-linearity similar to the work of [63] summarized in", "startOffset": 109, "endOffset": 113}, {"referenceID": 36, "context": "defined in [38]:", "startOffset": 11, "endOffset": 15}, {"referenceID": 22, "context": "Hand-crafting features from raw data is a long-standing issue in machine learning having significant impact on the performance of a NTL classifier [23].", "startOffset": 147, "endOffset": 151}, {"referenceID": 26, "context": "This approach has lead to breakthroughs in image analysis and speech recognition [27].", "startOffset": 81, "endOffset": 85}, {"referenceID": 23, "context": "In the preliminary work of [24] we noticed that the inspection result labels in the training set are not always correct and that some fraudsters may be labelled as non-fraudulent.", "startOffset": 27, "endOffset": 31}, {"referenceID": 47, "context": "There are different regularization methods such as L1 or L2 regularization [49] or learning of invariances allowing learning algorithms to better", "startOffset": 75, "endOffset": 79}, {"referenceID": 9, "context": "handle noise in the input data [10], [35].", "startOffset": 31, "endOffset": 35}, {"referenceID": 33, "context": "handle noise in the input data [10], [35].", "startOffset": 37, "endOffset": 41}, {"referenceID": 40, "context": "Most NTL detection research use supervised methods and this shortcoming of the training data and potential false positive labels in particular are not much reported in the literature, except in [42].", "startOffset": 194, "endOffset": 198}, {"referenceID": 34, "context": "reduction [36] that totally ignore the labels can be used to overcome this limitation.", "startOffset": 10, "endOffset": 14}, {"referenceID": 4, "context": "This domain is called semisupervised, for which semi-supervised clustering [5] has been", "startOffset": 75, "endOffset": 78}, {"referenceID": 25, "context": "This is a longstanding issue in statistics and therefore in machine learning, too, as discussed in [26].", "startOffset": 99, "endOffset": 103}, {"referenceID": 23, "context": "In the preliminary work of [24] we noticed that the sample of previously inspected customers", "startOffset": 27, "endOffset": 31}, {"referenceID": 15, "context": "addressed in the field of computational learning theory [16].", "startOffset": 56, "endOffset": 60}, {"referenceID": 41, "context": "For example, [43] and [63] only use less than a few hundred customers in the training.", "startOffset": 13, "endOffset": 17}, {"referenceID": 61, "context": "For example, [43] and [63] only use less than a few hundred customers in the training.", "startOffset": 22, "endOffset": 26}, {"referenceID": 41, "context": "with a Gaussian kernel is used in [43], for which training is", "startOffset": 34, "endOffset": 38}, {"referenceID": 13, "context": "only feasible in a realistic amount of time for up to a couple of ten thousand customers in current implementations [14].", "startOffset": 116, "endOffset": 120}, {"referenceID": 57, "context": "A regression model using the Moore-Penrose pseudoinverse [59] is used in [63].", "startOffset": 57, "endOffset": 61}, {"referenceID": 61, "context": "A regression model using the Moore-Penrose pseudoinverse [59] is used in [63].", "startOffset": 73, "endOffset": 77}, {"referenceID": 48, "context": "This model is also only able to scale for up to a couple of ten thousand customers [50].", "startOffset": 83, "endOffset": 87}, {"referenceID": 39, "context": "Models being trained on up to a couple of ten thousand customers include [41] and", "startOffset": 73, "endOffset": 77}, {"referenceID": 16, "context": "[17] using neural networks.", "startOffset": 0, "endOffset": 4}, {"referenceID": 17, "context": "Larger databases using up to hundreds of thousand or millions of customers are used in [18] and [24] using a SVM with linear Kernel or genetic algorithms, respectively.", "startOffset": 87, "endOffset": 91}, {"referenceID": 23, "context": "Larger databases using up to hundreds of thousand or millions of customers are used in [18] and [24] using a SVM with linear Kernel or genetic algorithms, respectively.", "startOffset": 96, "endOffset": 100}, {"referenceID": 68, "context": "We believe that a stronger investigation into time complexity of learning algorithms, scalable computing models and technologies such as Apache Spark [70] or Google TensorFlow [1] will allow to efficiently handle Big Data sets for NTL detection.", "startOffset": 150, "endOffset": 154}, {"referenceID": 0, "context": "We believe that a stronger investigation into time complexity of learning algorithms, scalable computing models and technologies such as Apache Spark [70] or Google TensorFlow [1] will allow to efficiently handle Big Data sets for NTL detection.", "startOffset": 176, "endOffset": 179}], "year": 2017, "abstractText": "Detection of non-technical losses (NTL) which include electricity theft, faulty meters or billing errors has attracted increasing attention from researchers in electrical engineering and computer science. NTLs cause significant harm to the economy, as in some countries they may range up to 40% of the total electricity distributed. The predominant research direction is employing artificial intelligence (AI) to solve this problem. Promising approaches have been reported falling into two categories: expert systems incorporating hand-crafted expert knowledge or machine learning, also called pattern recognition or data mining, which learns fraudulent consumption patterns from examples without being explicitly programmed. This paper first provides an overview about how NTLs are defined and their impact on economies. Next, it covers the fundamental pillars of AI relevant to this domain. It then surveys these research efforts in a comprehensive review of algorithms, features and data sets used. It finally identifies the key scientific and engineering challenges in NTL detection and suggests how they could be solved. We believe that those challenges have not sufficiently been addressed in past contributions and that covering those is necessary in order to advance NTL detection.", "creator": "LaTeX with hyperref package"}}}