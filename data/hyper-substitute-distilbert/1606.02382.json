{"id": "1606.02382", "review": {"conference": "arxiv", "VERSION": "v1", "DATE_OF_SUBMISSION": "8-Jun-2016", "title": "Deep Learning Convolutional Networks for Multiphoton Microscopy Vasculature Segmentation", "abstract": "recently google has been \" increasing appreciation to use shared learning frameworks containing both biomedical transparency images and integrated 3d marketing scenarios. comparatively, that appears been little effort on use deep frameworks for volumetric light correction. students test / apply that practice providing overall freely available dataset of 12 concurrent mixed - way vasculature rendering applications. we complement the use of deep curriculum framework to both 2d : 4 convolutional filters ( ct ). our resultant 4 - scan models produced promising segmentation result. we derived the architectures from zhao et al. ourselves constructed your znn framework primarily designed for lcd microscope image modeling. colleagues hope that by sharing digital neural vasculature datasets, we will exclude one researchers yet experiment with vasculature dataset and improve the used network architectures.", "histories": [["v1", "Wed, 8 Jun 2016 02:57:00 GMT  (3776kb,D)", "http://arxiv.org/abs/1606.02382v1", "23 pages, 10 figures"]], "COMMENTS": "23 pages, 10 figures", "reviews": [], "SUBJECTS": "cs.CV cs.AI", "authors": ["petteri teikari", "marc santos", "charissa poon", "kullervo hynynen"], "accepted": false, "id": "1606.02382"}, "pdf": {"name": "1606.02382.pdf", "metadata": {"source": "CRF", "title": "Deep Learning Convolutional Networks for Multiphoton Microscopy Vasculature Segmentation", "authors": ["Petteri Teikari\u2217a", "Marc Santosa", "Charissa Poona", "Kullervo Hynynena"], "emails": ["petteri.teikari@gmail.com;"], "sections": [{"heading": null, "text": "Contents"}, {"heading": "1 Introduction 1", "text": ""}, {"heading": "2 Related work 4", "text": ""}, {"heading": "3 Methods 5", "text": "3.1 Dataset . . . . . . . . . . . . . . . . . . . . 5\n3.1.1 Data import . . . . . . . . . . . . . 6 3.1.2 Data annotation . . . . . . . . . . . 6 3.1.3 Denoising (Image Restoration) . . . 6 3.1.4 Error metrics . . . . . . . . . . . . . 6\n3.2 Deep learning network . . . . . . . . . . . . 6 3.2.1 Training with ZNN . . . . . . . . . . 6 3.2.2 Network architecture . . . . . . . . . 7 3.2.3 Training procedure . . . . . . . . . . 7\n\u2217E-mail: petteri.teikari@gmail.com; Corresponding author"}, {"heading": "1 Introduction", "text": "Quantitative analysis of brain vasculature is used in a variety of fields, including vascular development [32, 187, 150] and physiology [191], neurovascular coupling [222, 34], and blood-brain barrier studies [151, 18]. Distinguishing blood vessels from the surrounding tissue (vessel segmentation) is often a necessary preliminary step that enables more accurate and efficient analyses of the vascular network. For example, characteristics of vasculature morphology such as tortuosity, length, and diameter, can be obtained without confounding factors from the extravascular space, such as dendrites. In addition to characterizing the vasculature itself, vessel segmentation also facilitates analyses of other dynamic factors, including cortical blood flow and angiogenesis.\nClinically, quantitative analysis of vessels will assist in making diagnoses and planning surgeries [116, 175, 245]. For example, retinal vasculature imaging [162, 201] allows inexpensive and fast screening of several eye-related and systematic pathologies such as glaucoma, age-related macular degeneration, diabetic retinopathy, hypertension, arteriosclerosis and Alzheimer\u2019s disease [75]. Differentiating blood vessels from the surrounding tissue also allows more accurate analyses of extravascular structures, such as tumor volume quantification [169] and pulmonary lobes structural analysis [108]. Given that vascular diseases, such as coronary heart disease, are among the largest public health problems in developed countries [154], accurate and efficient image analysis will only become more relevant. [154]. Thus, the segmentation of vascular structures from surrounding tissue is useful for both basic research and clinical applications. There have been various approaches for vessel segmentation (for reviews see [97, 116]), but to date, no single method have been able to successfully segment vessels from every imaging modality and every organ [175].\nOur group uses vessel segmentation for two purposes: 1) To analyze changes in vascular morphology after focused ultrasound mediated blood-brain barrier opening [74, 17], and 2) to observe tumor pathophysiology and drug kinetics following application of focused ultrasound stimulated microbubbles (unpublished). Both of these projects use the two-photon microscope for acquiring high-resolution images. We were motivated to improve our vessel segmentation pipelines from previous custom-written semiautomatic Matlab scripts [151], and labor-intensive manual approaches using commercial Imaris (Bitplane AG, Zurich,\nar X\niv :1\n60 6.\n02 38\n2v 1\n[ cs\n.C V\n] 8\nSwitzerland) platform and open-source ImageJ/FIJI platform [182], to be more automatic and robust. Delineating blood vessels from the extravascular space enables quantification of the rate and duration of dye leakage, which can be correlated with kinetics and characteristics of bloodbrain barrier integrity [28, 151, 18]. Other groups have used vessel segmentation as an image processing tool to analyze other factors from two-photon datasets, including neurovascular coupling [219], neuronal calcium imaging [35, 131], and low-intensity focused ultrasound brain modulation paradigms [224, 19, 143].\nTwo-photon microscopy, or more generally, multiphoton microscopy, has become the workhorse of neuronal imaging [66]. Multiphoton microscopy allows better optical sectioning and reduced photobleaching outside of the imaging plane compared to the traditional confocal techniques due to the nonlinear nature of the two-photon excitation fluorescence. Traditional two-photon microscopy operates on scanning point-by-point compared to whole-field approach of confocal microscopy, limiting also the maximum frame rates achieved by scanning two-photon microscopy. Twophoton light-sheet imaging operates on a line or a plane basis instead of a point, speeding the volumetric imaging by one or two orders of magnitude if faster faster rates are needed [221]. Additionally two-photon fluorescence imaging can be combined with other nonlinear processes such as with third-harmonic generation (THG) for label-free vascular imaging [234], and other microscopy techniques such as electron microscopy for more detailed analysis [12]. Silvestri et al. [194] for example integrate in vivo two-photon microscopy with ex vivo light sheet microscopy and use the major blood vessels as landmark points for registration.\nCompared to the literature focused on clinical angiography with various modalities and anatomical applications, there exists very little literature devoted on processing multiphoton vasculature images. Likewise, not much work has been done on open-source software and/or code for multiphoton vasculature analysis. The work by SantamariaPang et al. [179] on tubular 3D neuronal structures representing one of the few examples for \u201cmorphological\u201d multiphoton microscopy analysis, and Python-based VMTK ([4], http://www.vmtk.org/) for open-source vessel analysis. This is in stark contrast to work devoted on calcium imaging analysis with various freely available toolboxes (e.g. [148, 218, 147, 156]).\nTraditionally vessel segmentation have been done on some combination of vascular models, image features and extraction schemes often relying on prior knowledge about the tubularity of vessels [97, 116]. Typically in computer vision/image analysis field, algorithms and pipelines are developed using reference dataset as benchmarks for performance. In biomedical image analysis, almost all open image segmentation challenges are listed in http://grandchallenge.org/ with only challenge (VESSEL12, [175]) devoted to vessel segmentation. It is common that many fields suffer from lack of annotated datasets [47] as they are expensive to generate such as is the case for example in high content screening (HCS) technologies labeled at cell level [102, 124], and in electron microscopy [5]. Additional standardized datasets can be found for evaluating coronary artery centerline extraction algorithms [181], and for evaluating coronary artery stenosis detection, stenosis\nquantification and lumen segmentation algorithms in computed tomography angiography [98].\nThus, despite the numerous papers on vessel segmentation there has been very little effort for creating standardized three-dimensional vascular datasets. The the most similar datasets can be found for example for twodimension retinal vessels in DRIVE dataset [203], and three-dimension tubular fibers in DIADEM challenge [16]. Among the 23 submitted methods to the VESSEL12 challenge, only two submission were machine-learning based with the other one of them ending up providing the best overall performance in terms of segmentation accuracy. Similarly with natural images, research teams compete against each other trying to improve the performance of the classifier. One example of such challenge is the ImageNet Large Scale Visual Recognition Challenge (ILSVRC) challenge that is taking place annually with the same database of images [176].\nDuring past few years, data-driven machine learning algorithms have replaced \u201chand-crafted\u201d filter pipelines on many fields of image processing. Majority of the emerged approaches have relied on deep learning networks [113, 184, 107] opposed to \u201ctraditional\u201d shallow networks [11]. From different deep learning architectures, convolutional neural networks (CNN or ConvNet) have been the mostly used in image classification and image segmentation. While ConvNets have been around for decades (e.g. [79, 111]), the recent success had been due to the combination of bigger annotated datasets, more powerful hardware, new ideas, algorithms and improved network architectures enabling this sort of \u201cparadigm shift\u201d in machine learning. Since 2011, graphical processing unit (GPU)-based ConvNets have dominated classification ([105]), and segmentation contests ([30]).\nConvNets are loosely inspired of biological networks (e.g. [25]) allowing hierarchical feature learning starting from low-level features such as edges into higher-level features such as faces for example. ConvNets possess two key properties that make them useful in image analysis: spatially shared weights and spatial pooling ([163]). This allows feature learning that is shift-invariant, i.e. filter that is useful across the entire image as image statistics are stationary [195]. Typical convolutional networks are composed of multiple stages (figure 1.1), and the output of each stage is made of two or three dimensional arrays depending on the training data, called feature maps. Each feature map is the output of one convolutional filter (or pooling) applied over the full image. This is typically followed by non-linear activation function such as sigmoid, rectifying linear unit (ReLU) or hyperbolic tangent (tanh).\nAfter the final pooling layer of the network, there might be one or more fully-connected (FC) layers that aim to perform high-level reasoning. They take all neurons from the previous layer and connect them to every single neuron of current layer (i.e. fully-connected). No spatial information is preserved in typical fully-connected layer configurations. In the end of the networks there is typically a terminal (\u201coutput\u201d) classification layer that based on the number of classes produces real-valued or binary scalar for each image in image classification dataset, or for the each pixel in each image image segmentation dataset. The most typical output layer uses a softmax regression that generates\nprobability distribution of the outputs [60]. The shortcoming of softmax is that does not capture model uncertainty and often it is interpreted erroneously as model confidence [52]. If model uncertainty is needed, there have been effort to cast deep learning models as Bayesian models[52]. The networks are typically regularized to mitigate over-fitting either using technique called DropOut [202] in which each neuron has a probability of 0.5 to be reset with 0-value, typically only used in last fully-connected layers. Alternatively one can regularize the network by injecting noise for example just before the nonlinear activation function [164].\nConvNets are typically trained using stochastic gradient descent (SDG) optimization method with mini-batches so that the gradient on each training iteration is computed using more than one training example (i.e. patch of image/volume) resulting in smoother convergence, and more efficient use of vectorization libraries, thus faster computation times. ConvNets can be roughly divided to two basic types [246]: feedforward networks which are organized in layers with unidirectional connections (e.g. the proposed approach here from Lee et al. [114]), and recurrent network in which feedback connectivity is dominant (e.g. used by Pinheiro et al. [163] for semantic segmentation). Feedfor-\nward networks are typically used for image classification and segmentation, whereas recurrent networks are used for sequential data such as language, and sound processing.\nSurprisingly even though the ConvNets have been highly successful, the success of the ConvNets are not well understood even by the people designing new algorithms and architectures (e.g. [60]). The ultimate goal of artificial intelligence (AI) including image segmentation would be to build machines that understand the world around us, i.e. disentangle the factors and causes it involves ([9]), or in more practical terms, to have an image segmentation system that would have an \u201cunderstanding\u201d of the vesselness. In our case eventually exceeding the human expertise in determining which part of the image is part of the vessel. This human-level concept learning was recently demonstrated for written character recognition by Lake et al. [107] from very limited training samples starting from just one examples. For \u201cbrute-force approaches\u201d, there have been ConvNets that have surpassed human-level performance on image classification [65, 77].\nWe aim to improve the accuracy of the vessel segmentation for multiphoton microscopy by training a deep learning framework based on convolutional networks (Con-\nvNets) in supervised manner with no free parameters for the user to adjust. We have implemented our threedimension vessel segmentation using open-source CPUaccelerated ZNN framework [114, 254] previously used for three-dimensional electron microscope segmentation. Our main motivation for this proof-of-concept work is to inspire more researchers to work on biomedical segmentation problems by providing public available annotated dataset of two-photon fluorescence microscopy vasculature stacks with the code needed to easily fine-tune the network using your own training data and improve our model.\nOur work tries to integrate the fields of machine learning, biomedical image analysis, and neuroscience and motivating applications. Two-photon microscopy is capable of providing beautiful high-resolution images of biological processes in vivo. By creating an open source, reproducible method of vascular segmentation, quantitative results can be more readily attained and compared. We hope to decrease the time overhead required for image processing by the average microscope user and accelerate the educational translation of new information to the scientific community."}, {"heading": "2 Related work", "text": "Typical simplified schematic of vasculature segmentation pipeline used to process two-photon microscope stacks is shown in figure 2.1. The image stacks suffer mainly from photon noise following a Poisson distribution [10] (i.e. the noise intensity depends on the underlying signal) with some Gaussian noise component added, which can be denoised directly with methods developed for Poisson noise (e.g. PURE-LET [128]). Alternatively the signal-dependency of the Poisson noise can be removed with a suitable transform such as Anscombe transform [135] that allows one to use denoising methods developed for Gaussian noise (e.g. BM3D/BM4D [132, 36]). Deconvolution is not done as commonly for multiphoton microscopy as compared to confocal microscopy [141], but if it is been done in can be done jointly with other image restoration operations [160] or as its independent step [92]. This part can be seen as the image restoration part with an attempt to recover the \u201coriginal image\u201d as well as possible corrupted by the imaging process.\nIn some cases the restored image is further simplified using some edge-aware smoothing operator such as anisotropic diffusion [139, 165], or as done by Persch et al. [160] who jointly apply the anisotropic diffusion inpainting (operation that attempts to replace lost or corrupted parts of the image data) with deconvolution and interpolation.\nThis step is followed by some \u201cvesselness filter\u201d or \u201cvesselness enhancement\u201d filter that is designed to enhance tubular structures such as vessels in the image. The best known filter of those is the Frangi\u2019s filter [49] that has become outdated as it cannot properly handle crossings nor bifurcation methods, and several filters [109, 226, 198, 62, 144] have been proposed to correct the shortcomings of Frangi\u2019s filter with none of them reaching a de facto standard status.\nIn our proposed deep learning-based network we are trying to replace the vessel enhancement and segmentation steps, and keep still using \"traditional\" filters with the im-\nage restoration part (see discussion on how to get upgrade them as well in 5.1). There have been various \"traditional\" segmentation algorithms for vessel segmentations (for reviews see [97, 116]), and only the most relevant ones are analyzed here below.\nIn the schematic (figure 2.1) z-interpolation is placed after the segmentation, but it might have been placed as well before the segmentation algorithm [121, 228], or jointly with other image restoration operators [160]. The exact placing of the interpolation depends on the computation before and after it, but in our case we placed in the end to emphasize the gains of z-direction interpolation to mesh reconstruction as all our stacks used in this work are anisotropic (see table 1). Reconstructing meshes from noninterpolated anisotropic stacks with traditional Marching Cubes algorithm [117] typically leads to \u201cstaircasing effect\u201d of the mesh while interpolation gives smoother reconstruction. Advanced mesh reconstruction methods are beyond the scope of this algorithm, but there have been efforts to improve biomedical mesh reconstruction [145, 177] mitigating the problems of triangulation based such as Marching Cubes. With the reconstructed vasculature mesh, it is then possible to for example do morphological analysis [140], calculate hemodynamic parameters [90], or analyze the functional diameter changes in response to external stimulus [121].\nTo the knowledge of the authors, deep learning frameworks including ConvNets have not yet been applied to segmentation of three-dimensional volumetric vasculature images. Despite the limited use of machine learning techniques in VESSEL12 challenge for lung vessels [175], there have been some work using machine learning techniques for vessel segmentation. Sironi et al. [196] for example used an unsupervised dictionary learning [103] approach that learned optimal separable convolutional filter banks for 2D vasculature segmentation (DRIVE dataset [203]), and for 3D olfactory projection fibers (DIADEM challenge [16]). The filter banks were then used with the popular Random Forests classifier [15] continuing the previous work from the same lab [58, 170]. The authors used their separable filter banks with ConvNets for image classification task but did not discuss about the possibility of using ConvNets with the image segmentation task. Very recently Maji et al. [134] applied ConvNets for the two-dimensional vasculature DRIVE database with promising performance.\nSantamaria-Pang et al. [178] similarly used a dictionary learning approach to learn linear filters for detection of tubular-like structures from multiphoton microscopy stacks. The learned filters were fed to a Support Vector Machine (SVM, [210]) which was shown to provide a better segmentation accuracy compared to the vesselness filter introduced by Sato et al. [180]. Recently, Schneider et al. [185] used Random Forests for classification with multivariate Hough forests to infer probabilistic votes about the vessel center, jointly segmenting vasculature and extracting vessel centerline. The features were learned using steerable filter templates ([80]) at multiple scales instead of the dictionary learning approach. They showed that their learning-based approach outperformed both Oriented Optimal Flow (OOF, [109]) and Frangi\u2019s filter [49] for vessel segmentation.\nSironi et al. [197] take a different approach in their paper\ninspired by recent work on structured learning-based edge detectors ([39]). They combine structured learning with nearest neighbor-based output refinement step designed for situations where edges or thin objects are hard to detect explicitly by the neural network ([53]). They were able to reduce spatial discontinuities, isolated erroneous responses and topological errors of initial score maps from outputs of other algorithms, and when directly trained to segment two-dimensional blood vessels (DRIVE dataset [203]).\nThere is relatively more work devoted on natural image processing compared to biomedical image analysis. In natural image processing literature, the corresponding application to our biomedical image segmentation is semantic segmentation [125, 155, 24, 23], also referred as scene parsing [163] or scene labeling [45]. Semantic segmentation with natural images tries to answer to the question \u201cWhat is where in your image?\u201d for example segmenting the \u201cdriver view\u201d in autonomous driving to road, lanes and other vehicles [89]. In typical semantic segmentation tasks there are a lot more possible labels than in our two-label segmentation of vessels and non-vessel voxels, further complicating the segmentation.\nMost existing biomedical segmentation pipelines start with slice-by-slice two-dimensional processing for volumetric stacks, and only later transition to three-dimensional processing due to high computational cost of fully threedimensional pipelines [123, 214]. ConvNets with 3D filters had been used for example with block face EM images before [67], most of the 3D filter use being employed in video processing [83, 220, 243] where the 2D image with the time can be viewed as an anisotropic 3D image. Due to everincreasing computational performance in local GPU clusters, and cloud-based services such as Amazon AWS, IBM Softlayer, Microsoft Azure and Google Cloud Platform we expect to see more purely three-dimensional approaches such as the one proposed by Kamnitsas et al. [86] for brain lesion segmentation from MRI images.\nDeep learning based approaches have been extensively used for volumetric electron microscopy (EM) segmentation [72, 133, 236, 114, 173]. Other biomedical image segmentation tasks with deep learning frameworks include for example brain segmentation [64, 129, 85, 205], prediction of Alzheimer\u2019s disease from magnetic resonance imaging (MRI) scans [158], microscopic cell segmentation [102], glaucoma detection [26], computational mammography [40], pancreas segmentation [40], bi-ventrical volume estimation [251], and carotid artery bifurcation detection\n[252] The use of deep learning neural networks is not limited to image analysis, and it can employed in various fields that can benefit from data-driven analysis in exploratory or predictive fashion. In neuroscience, in general the datasets are getting increasingly larger and more complex requiring more sophisticated data analysis tools [174]. There have been systems capable of constructing theories automatically in data-driven fashion [55]. Artificial neural networks lend themselves well for modeling complex brain function that emerge from activation of ensembles of neurons in which the studying of single neuron at a time is not sufficient [174].\nFor example, the circuit architecture of the mammalian hippocampus have been modeled to consist of series of sequential feedforward and recurrent neural networks [172]. Harvey et al. [63] used two-photon imaging to measure the calcium activity of mouse making behavioral choices in virtual maze. The temporal trajectory of neuron populations was shown to be predictive of the behavioral choice, thus being suitable for the use of recurrent neural networks to model the behavior. In addition to basic neuroscience, deep learning \u201cexpert systems\u201d have been extended to clinical settings [232] for example for predicting clinical outcomes of radiation therapy [87], electroencephalographic (EEG) recording analysis [204], and future disease diagnosis and medicine prescription in routine clinical practice [29]."}, {"heading": "3 Methods", "text": ""}, {"heading": "3.1 Dataset", "text": "The vessel dataset described here were acquired from mouse cortex, and from GFP-labelled human squamous cell carcinoma tumors, xenografted onto the dorsal skin of mice with implanted dorsal window chambers (FaDu-GFP, AntiCancer Inc.), tumors summarized in table 1 (see the maximum-intensity projections of stacks in 3.1). Fluorescent dextran (70 kDa Texas Red, dissolved in PBS, Invitrogen) was used to visualize the vasculature in mouse cortex by [18], and fluorescent dextran (2MDa FITC, dissolved in PBS, Invitrogen) to label the tumor vasculature. Imaging was performed using the FV1000 MPE two-photon laser scanning microscope (Olympus) with tunable mode-locked Ti:Sapphire laser using several excitation wavelengths and water-immersion objective lenses.\nThe auxiliary Matlab code for our im-\nplementation of ZNN is provided in https://github.com/petteriTeikari/vesselNN, with the annotated dataset available from https://github.com/petteriTeikari/vesselNN_dataset."}, {"heading": "3.1.1 Data import", "text": "We used the Java-based Bio-Formats library (OME - The Open Microscopy Environment, https://www.openmicroscopy.org/, [122, 142]) with Matlab[118] to open the OIB files from Olympus FluoView 2-photon microsopy setup. We selected representative substacks from each original stack to reduce the time needed for manual annotation by us researchers. The substacks were converted to 16-bit OME-TIFF image files containing all the original metadata."}, {"heading": "3.1.2 Data annotation", "text": "The ground truth for the vessels were manually annotated slice-by-slice using custom-written Matlab code to produce a \u201cseed binary\u201d image containing the strongest edges which then had to be refined manually using the pencil tool of GIMP (http://www.gimp.org). We used more conservative criteria for labeling vasculature than the traditional \u201c50% of the voxel\u201d to account the partial volume effect [213], and we tried to include all the vessel-like structures to the label mask."}, {"heading": "3.1.3 Denoising (Image Restoration)", "text": "After converting the substacks to OME-TIFF files, we denoised the microscopy stacks using the state-of-the art denoising algorithm BM4D ([132]) implemented in Matlab. BM4D is a volumetric extension of the commonly used BM3D denoising algorithm [33] for 2D images, which was for example used to denoise two-photon microscope images by Danielyan et al. [36]. They also demonstrated that the two-photon microscopy noise can be modeled well using the models developed for digital cameras. BM3D/BM4D were\ndesigned for denoising images degraded by Gaussian noise, thus we applied first Anscombe transform to reduce the signal-dependency of the noise as done with BM4D for denoising of magnetic resonance imaging (MRI) images [135]. After the BM4D denoising, an inverse Anscombe transform was applied to convert the stacks back to original intensity domain.\nTwo of the stacks (burgess2014 bbbDisruption, and burgess2014 noisySparseVessels) were degraded by horizontal periodic \u201cbanding\u201d caused by improperly balanced microscope stage, and the degradation was mitigated using spatial notch filters in frequency domain applying fast Fourier Transform (FFT) in Matlab. Noise components were manually identified and then removed before denoising those images. We did not apply any blind deconvolution (e.g. [41]) for our microscope stacks to improve the image quality. There was no significant spectral crosstalk in any of the stacks, thus no spectral unmixing or blind image separation (e.g. [37]) was done for the image stacks. Likewise, no motion compensation algorithms (e.g. [200]) was needed for the dataset."}, {"heading": "3.1.4 Error metrics", "text": "To analyze the segmentation quality of our proposed architecture we used Average Hausdorff Distance (AVD) as the error metric. The AVD between the ground truth and output of the proposed architecture was computed using the EvaluateSegmentation package (http://github.com/codalab/EvaluateSegmentation) published by Taha et al. [213]. AVD was chosen as the metric as it is well suited for evaluating complex boundary delimitation. Disadvantage of the AVD is that it is based on calculating the distances between all pairs of voxels, making it computationally intensive and not feasible to be integrated to network training for example."}, {"heading": "3.2 Deep learning network", "text": "We trained our 3D vessel segmentation deep ConvNet using ZNN framework [253], that uses multicore CPU parallelism for speed instead of typical GPU-accelerated frameworks such as Theano for example [215]. At the time of our training, there were not many frameworks available that would take the 3D context into account. Commonly used library Caffe [84] had only 2D networks available, while DeepLab built on top of Caffe would have had GPU-accelerated 3D networks implemented. Our approach for vessel segmentation is inspired by the success of ZNN in segmenting threedimensional electron microscope (EM) image stacks [114], and we chose to start with the networks described for EM segmentation."}, {"heading": "3.2.1 Training with ZNN", "text": "ZNN produces a dense output with pixel-by-pixel segmentation maps in contrast to image-level labels in object recognition. ConvNets have excelled in object recognition which typically only require single output value for an entire input image [i.e. is there a dog in the image? yes (1),\nTable 1: Dataset used in the study (check resolution from .oib files, and re-denoise the image at some point with correct metadata as ImageJ lost it). Additional possible parameters: depth, FOV, and dye, excitation wavelength, percentage of vessel labels (see [30]).\n# Resolution (\u00b5m3) Dimension (voxel3) # samples % of vessel labels Source Usage 1 0.994\u00d70.994\u00d75 512\u00d7512\u00d715 3.75M 12.4% Mouse cortex Train 2 1.59\u00d71.59\u00d75 320\u00d7320\u00d726 2.54M 29.8% Mouse cortex Train 3 0.994\u00d70.994\u00d75 512\u00d7512\u00d710 2.5M 42.1% Mouse cortex Train 4 0.994\u00d70.994\u00d75 512\u00d7512\u00d715 3.75M 36.1% Mouse cortex Train 5 0.994\u00d70.994\u00d75 512\u00d7512\u00d725 6.25M 3.2% Mouse cortex Train 6 0.994\u00d70.994\u00d75 512\u00d7512\u00d725 6.25M 3.7% Mouse cortex Test 7 0.994\u00d70.994\u00d75 512\u00d7512\u00d723 5.75M 9.5% Mouse cortex Test 8 0.994\u00d70.994\u00d75 512\u00d7512\u00d725 6.25M 9.0% Mouse cortex Train 9 2.485\u00d72.485\u00d75 512\u00d7512\u00d714 3.5M 34.0% Mouse cortex Train 10 0.621\u00d70.621\u00d75 512\u00d7512\u00d715 3.75M 10.5% Tumor Train 11 0.621\u00d70.621\u00d75 512\u00d7512\u00d721 5.25M 24.1% Tumor Train 12 0.621\u00d70.621\u00d75 512\u00d7512\u00d727 6.75M 14.2% Tumor Train\nFigure 3.2: An overview of our proposed framework (left) and model architectures (right,). The number of trainable parameters in each model is 230K (VD2D), 310K (VD2D3D).([114]).\nor no (0)]. ZNN employs max-filtering which slides a window across image and applies the maximum operation to that window retaining original image resolution. Traditionally, in semantic segmentation ([125]) and biomedical image segmentation ([173]) pipelines, max-pooling is used instead of max-filtering which reduces the dimensions of the output map requiring either post-processing using for example some graphical model ([23]), or upsampling back to the original resolution ([173]). The max-filtering employed by ZNN can be thought as the dense variant of max-pooling filter as it keeps image dimensions intact while making all filtering operation sparse both via convolution and maxfiltering. This approach is also called \u201cskip-kernels\u201d ([188]) or \u201cfilter rarefaction\u201d ([125]), and is equivalent in its results to \u201cmax-fragmentation-pooling\u201d ([57, 137]). In practice with ZNN we can control the sparseness of filters independent of max-filtering."}, {"heading": "3.2.2 Network architecture", "text": "We adopted the recursive architecture from Lee et al. [114] used to segment electron microscopy (EM) stacks.\nVD2D The chosen recursive architecture first involved a two-dimensional VD2D (\u201cVery Deep 2D\u201d) \u201cpre-training\u201d stage that is shown in figure 3.3 and in figure 3.2. All convolutions filters have sizes of 3\u00d73\u00d71, except that Conv1c uses a 2\u00d72\u00d71 filter to make the \u201creceptive field\u201d for a single output pixel to have an odd-numbered size, and thus centerable around the output pixel. Some convolution layers are employing hyperbolic tangent (tanh) nonlinearities rather than traditionally used rectifying linear units (ReLUs) as the authors argued that this might suppress variations in the feature maps due to image quality variations. This was left however untested in their original paper.\nVD2D3D The two-dimensional convolutional layers of the following second stage named VD2D3D (\u201cVery Deep 2D-3D\u201d, see figure 3.3 and figure 3.2) are initialized with the trained weights of the VD2D without enforcing weight sharing as done by some recurrent ConvNets ([163]). The main idea behind having initial 2D layers in the VD2D3D is to make the network faster to run and train, while the 3D filters in the layers enable the network to use 3D context in vessel segmentation providing more accurate predictions.\nIn theory the accuracy could be further improved by transforming all the layers to 3D but this would in practice come with increased computational cost and memory requirements. The VD2D3D could be used directly for the denoised input images without the initial VD2D training, but Lee et al. [114] showed that providing the output of VD2D recursively as the input to the VD2D3D produced a significant improvement in performance. The layers Conv1a, Conv1b, and Conv1c are used to process the recursive inputs along with the denoised input images, which then are combined together after Conv1c. This parallel processing stream should allow more complex, highly nonlinear interaction between low-level features and contextual information in the recursive input. The increase of trainable parameters due to switch from 2D filters to 3D filters were compensated by trimming the size of later layer feature map from 200 (Conv5 of VD2D) to 100 (Conv4c of VD2D3D)\nVD2D3D_v2 We changed the last two-dimensional layer (Conv3 into three-dimensional layer (see VD2D3D_v2 in figure 3.3) keeping the VD2D3D otherwise the same.\nVD2D3D_v3 .We wanted to see what would be the effect of changing the first layer into three-dimensional. This in practice would correspond to the low-level features and should improve the detection of three-dimensional structures rather over two-dimensional filters that could confuse \u201cfeature-like\u201d two-dimensional noise to \u201creal\u201d threedimensional vasculature."}, {"heading": "3.2.3 Training procedure", "text": "The network training procedure was similar to the one described by Lee et al. [114]. We trained our network using backpropagation with the cross-entropy loss function. The VD2D was first trained for 60K updates using 100\u00d7100\u00d71 output patches. The initial learning rate was set to 0.01, the momentum of 0.9, and an annealing factor of 0.999\nwhich was applied every 6 updates giving us a learning rate of 0.000000452 at the end of VD2D training. Each update took around 2.9 seconds in our Intel Dual Intel Xeon E5650 Quad CPU (16 hyperthreads, 24 GB RAM) workstation on Ubuntu 14.04, with all the 16 threads in use giving us a total of 2 days for the VD2D training. After completing VD2D training, we continued with the training of VD2D3D for 90,000 updates as in the original paper by Lee et al. [114] with an initial learning rate of 0.01, the momentum of 0.9 and with the same annealing factor of 0.999 which was applied on every update for 15K updates, after which the learning rate was set 0.0001 with the same annealing factor that was this time applied on every 10th update. Each update took around 23 seconds, giving us a total of 24 days for the training of VD2D3D with the same 90K updates.\nFor the modified architectures with extended 3D support (v2 and v3) higher memory were required, and fully 3D pipeline was not possible with the current implementation of ZNN with just 24 GB of RAM. Each update with v2 took around 27.2 seconds (90,000 updates took slightly over 28 days), and with v3 each update took around 24.4 /seconds (90,000 updates took slightly over 25 hours).\nLike Lee et al. [114], we rebalanced the classes (vessels/non-vessels) by differentially weighing the perpixel loss to deal with the imbalance between vessels and non-vessel pixels which was however lower than the imbalance seen in electron microscope images between boundary and non-boundary pixels.\nWe also augmented the data by randomly rotating and flipping 2D image patches as implemented in ZNN. Additionally we could have introduced photometric distortions ([71]) to further counteract the possible overfitting due to limited training data, but they were seen unnecessary at the time of the training.\nWe also used dropout ([202]) to further avoid overfitting that was implemented in ZNN. Dropout was applied to the Conv4c layer with a probability of 0.5 to be reset with a 0-valued activation."}, {"heading": "3.3 Sharing", "text": "Our proposed segmentation pipeline is based on the ZNN framework that is freely available online at https://github.com/seung-lab/znn-release by the original authors [114, 253]. We have develop some helper function for that using Matlab, and all those files are available from our Github repository at https://github.com/petteriTeikari/vesselNN. In the spirit of reproducible research [230, 38, 88, 115] we release also our annotated dataset for other research teams to be used. The dataset is available from https://github.com/petteriTeikari/vesselNN."}, {"heading": "4 Results", "text": "See the summary of results of the training in table 2 which basically shows that VD2D3D is better than VD2D as ex-\npected, and that stack 10 ruins the statistics as it was not segmented that well. Otherwise the Average Hausdorff Distance might be a a bit abstract, but smaller distance the better, and it was recommended for complex boundaries such as vessels and neurons in the review by Taha and Hanbury [213].\nThe more detailed results of VD2D and VD2D3D architecture with thresholding and dense CRF post-processing can be seen in table 4, quantified using Hausdorff average distance (AVD). The difference in performance between different variants of the VD2D3D and VD2D is shown in table 3, quantified using the same AVD metric. Comparison of different metrics for the baseline VD2D3D is shown in table 4 to provide better interpretability compared to other studies as AVD is not the most typically used metric. Rand Index and Area Under the Curve (AUC) was chosen as metrics as they are typically used as error metrics in medical segmentation studies [213]. . Mutual information quantifies recall (i.e. the segmentation should have all the regions marked in the ground truth, while not penalizing the added regions too much) on cost of precision. Hausdorff distance and Mahalanobis distance are spatial distance based metrics closely related to our method of choice Average Hausdorff Distance (AVD) that is basically a more robust version of Hausdorff distance handling outliers better. Mahalanobis distance would be preferred in segmentation where general shape and alignment are important.\nThe segmentation results are visualized for the best slice for each stack in figure 4.1, and for the worst slice for each stack in figure 4.2. For each stack there are four columns: 1) the first column shows the denoised input slice, 2) Label that corresponds to the manually annotated vessels, 3) the real-valued ZNN output from the proposed architecture, 4) the Mask that is a binary mask obtained with dense twodimensional CRF. It should be noted that the ground truth labels are not optimally defined, as can be seen for example in the worst case scenario of stack #3 (figure 4.2) with high AVD value, but visually the segmentation seems quite good. The high value of AVD value simply comes from the difference between the suboptimal manual label and the \u201creal\u201d vasculature labels that could have been drawn better.\nVisualized segmentation results and the performance metrics for other VD2D3D variants are shown in the Wiki of our Github repository at https://github.com/petteriTeikari/vesselNN/wiki.\nVisualization of the behavior of the network training for VD2D (figure 4.3) and for VD2D3D (figure 4.4) show that for our datasets the training error (accuracy) and the test error (if too high with low training error, the system is overfitting the training data) converged well before the hardcoded limits taken from the study of Lee et al. [114] for electron microscopy stacks."}, {"heading": "5 Discussion", "text": "Our proposed networks based on the ZNN framework [114, 254] for vasculature segmentation from volumetric two-photon microscope stacks provided promising results of segmentation quality. There is still room for many im-\nprovements and optimizations to our proof-of-concept approach which are discussed in more detail below."}, {"heading": "5.1 Deep learning", "text": "Refinements to network In this work, we chose to use the \u201cvanilla\u201d network architecture from Lee et al. [114] termed VD2D3D (\u201cVery Deep 2D-3D\u201d) with 2D layers in the initial layers, and 3D layers at higher abstraction layers to make the network faster to run and train. The VD2D3D employed commonly used components of ConvNets with mixed nonlinear activation functions of hyperbolic tangent (tanh) and rectified linear units (ReLU), and maximum filtering variant of max pooling that kept the resolution the same throughout the architecture without any need for upsampling as needed for some architectures (e.g. Ronneberger et al. [173] for biomedical image segmentation).\nThe whole field of deep learning and ConvNets is rapidly advancing (see for example a recent review by Gu et al. [60]). We can thus expect that with future optimization and testing, the \u201cvanilla\u201d network can be improved for our application and for volumetric biomedical segmentation in general. For example the convolutional layers used now can be regarded as a generalized linear model (GLM) for the the underlying local image patch, and the nonlinear learning is introduced to the network via nonlinear activation function such as Rectified Linear Units (ReLU). It has been proposed that the convolutional filter itself could be made nonlinear with \u201cNetwork in Network\u201d (NIN) model of Lin et al. [120] or with the Inception module by Szegedy et al.[211, 212]. These modifications enhance the abstraction ability of the local model compared to the current GLM convolution model.\nVery recently there has been interesting work of replacing convolutional filter with bilateral filter [91, 51, 81, 7] that is very commonly used edge-preserving smoothing fil-\nter [217]. The convolutional filters were replaced both from earlier layers [91], as well as from later fully-connected layers [51] offering faster runtime especially for higherdimensional signals. Gadde et al. [51] replaced the Inception modules with \u201cbilateral Inception\u201d superpixels yielding better segmentation results than strictly pixel-wise implementations. Bilateral Inception allowed long-range edgepreserving inference directly removing the need for dense CRF as post-processing step according to the authors [51]. In contrast, Jampani et al. [81] trained the bilateral filter to be used within the dense CRF inference, demonstrating better segmentation performance compared to traditional dense CRF. In general, introducing bilateral filter or some other image-adaptive kernel at the convolutional layer level should allow better edge-preserving properties of the network that is very useful when we are interested in segmenting the vessel boundaries.\nThere have been many attempts to improve the maxpooling [60] of which the maximum filtering used here is a dense variant that retains original volume resolution. Pooling in general is used to lower the computation burden by reducing connections between successive layers. From the recent efforts, especially spectral pooling seems like an interesting upgrade [171] as it can be implemented with little computational cost for Fast Fourier Transform (FFT) based convolution networks such as the VD2D3D used here. In contrast to max-pooling, the information is reduced in frequency domain in linear low-pass filter fashion that will retain more information for the same output dimensionality. The use of spectral pooling provided the best classification performance on CIFAR (10 and 100) image classification dataset [104] compared to other state-of-theart methods such as stochastic pooling[247], Maxout [59], \u201cNetwork in Network\u201d (NIN) [120], and deeply-supervised nets [114].\nSimilarly, the traditional nonlinear activation functions such as sigmoid, tanh, and ReLUs could be improved. ReLUs are probably the most commonly used activation function in ConvNets [149], with their main disadvantage being that it has zero gradient when the unit is not active. This in practice may cause that the units are not initially active never will become active during the gradient-based\noptimization (stochastic gradient descent, SDG). To alleviate this problem, Clevert et al. [31] recently proposed exponential linear units (ELUs) which also employ negative values unlike ReLU, and according to the authors the use of ELUs lead not only to faster learning, but also give better generalization performance especially when the networks have at least 5 layers. On CIFAR-100 dataset, the ELUs yielded the best published result. The use of ELUs would be in theory complimentary to spectral pooling and they could also be used together with the nonlinear modifications of convolution layer (e.g. NIN and Inception). It should be noted that at the moment there is no nonlinear activation function for frequency domain [171], thus there is a computational bottleneck with the inverse FFT and FFT transforms needed before and after the activation function.\nWe employed Dropout [202] for regularization of our network by applying it before the output layer. Recently, Poole et al. [164] showed that injecting Gaussian noise instead of applying Dropout led to improved performance, and Rasmus et al. [168] found no practical difference between Dropout and Gaussian noise injection. Interestingly for Dropout, Gal and Ghahramani [52]; and Kingma et al. [96] demonstrated how deep learning network with Dropout can be cast as a Bayesian model. This in practice allows the estimation uncertainty based on Bayesian statistics [55]. The estimate of uncertainty is currently lacking in most of the deep learning frameworks. The advantage of the Dropout-based Bayesian estimation is that one can turn existing dropout networks to include model uncertainty, rather than having to re-define the whole architecture. This Dropout-based estimation was used by Kendall et al. [89] for semantic segmentation showing comparable performance to state-of the-art architectures by applying Dropout in the central layers of their encoder-decoder architecture. In analysis pipelines where a quantitative analysis of morphological vessel behavior (e.g. [121]) follows the image processing, it is useful to propagate the uncertainties involved in the image processing pipeline to the final statistical analysis.\nThe most obvious improvement for the used VD2D3D architecture here would be the conversion of all the con-\nAUC - Area Under the Curve, ADJRIND - Adjust Rand Index considering a correction for chance, MUTINF - Mutual information, HDRFDST - Hausdorff distance with the 0.95 quantile method, AVGDIST - Average Hausdorff Distance, MAHLNBS - Mahalanobis Distance.\nvolutional layers to be three-dimensional. However, this is not computationally that feasible using current ZNN implementation with most commonly available hardware around. In the future with increased computational power, and speed optimization this should become feasible either by using Intel Xeon coprocessor [171, 254], supercomputing clusters [249], or GPU-accelerated frameworks such as Theano [215]. In our current implementation we chose to do the dense CRF in slice-by-slice manner due to the available implementation of it. In the future, we could upgrade the used dense CRF to three dimension as done for example by Kundu et al. [106]. In the architecture employed here, multi-scale representation is not explicitly included. We have tried to provide\nstacks with different magnifications in our dataset to help the network learn different scales like done by Lee et al. [114]. Typically in semantic segmentation networks, multiscale representation is implemented in two main ways [24], either by using so called skip-net that combine features from the intermediate layers of network [188, 23, 125], or via share-net that are fed input resized to different scales [119, 45]. The discussed bilateral filter modification would be able to encode scale invariance defined on continuous range of image scales without the typically used finite number of subsampled inputs simplifying the network architecture [91].\nIn addition to concentrating on the individual components of the ConvNets, there have been alternative approaches to improve computational efficiency [27, 250, 77, 61]. Our vessel segmentation network took over 20 days (see 3.2.3) to train on a typical multicore desktop computer, which emphasizes the utility of faster computation.\nBatch Normalization technique by Ioffe et al. [77] has received a lot of attention as the authors showed that the same classification accuracy can be obtained with 14 times fewer training steps while exceeding accuracy of human raters with an ensemble of batch-normalized networks. By normalizing for each training mini-batch, higher learning rates could be used with the training being less sensitive to initialization as well.\nAnother typically used speedup scheme is to use superpixels [152, 46, 51] with two-dimensional images, or supervoxels [127, 100] with volumetric three-dimensional images to reduce the dimensionality of the input. Within the superpixel/supervoxel pixels/voxels carry similarities in color, texture, intensity, etc., generally aligning with region edges, and their shapes being generally circular/spherical rather than rectangular patches. The main downside of superpixels/supervoxels are that they introduce a quantization error [51] whenever pixels/voxels within one segment\nhave different ground truth label assignments (i.e. in our case supervoxel would have both non-vessel and vessel labels).\nOne of the main bottlenecks currently in deep learning networks, is the lack of efficient algorithms and libraries for sparse data, as majority of the libraries are optimized for dense data [211]. The already discussed introduction of bilateral filters, and their computation using permutohedral lattices [2, 91] is a one way to speedup the computation of sparse data. In addition to permutohedral lattice, Ghesu et al. [56] introduced a Marginal Space Deep Learning (MSDL) framework for segmenting volumetric medical images by replacing the standard, pre-determined feature sampling pattern with a sparse, adaptive, self-learned pattern showing increased runtime efficiency.\nImproved annotation We manually annotated our ground truths using Matlab-created seeds and GIMP (GNU Image Manipulation Program). This was extremely time-consuming and required a person familiar with the two-photon microscopy vasculature images. Recently Mosinska et al. [146] extended the active learning (AL) approach ([189]) for delineation of curvilinear structures including blood vessels. Active learning is designed to reduce the effort of the manual annotator by selecting from non-annotated dataset, the image stacks for manual annotation that would the most beneficial for improving the performance of the network. Surprisingly and counterintuitively, recent work on electron microscope image segmentation [100] found that the classifier performance of their implementation was better using only a subset of the training data instead of using the whole available training data. This phenomenon had been reported before by [186], suggesting that a well chosen subset of training data can produce better generalization than the complete set.\nCrowdsourcing Kim et al. [94] demonstrate an interesting approach for acquiring annotations for electron microscopy datasets by developing a game called EyeWire (http://eyewire.org/) for non-experts where they can solve spatial puzzles made out from neuronal boundaries. This crowdsourcing have been traditionally used in tasks that does not require expert-level knowledge such as teaching autonomous cars to drive [166], but have been thought to be impractical for tasks that require expertise such as medical segmentation [146]. The innovative approach used in their game is able to transform the biomedical \u201cexpert\u201d annotation problem to the masses.\nAdditionally to the \u201cgamification\u201d of segmentation efforts, one could create a segmentation challenge of our dataset to popular machine learning sites such as Kaggle (https://www.kaggle.com/) and Grand Challenges in Biomedical Analysis (http://grand-challenge.org/) to bring up the volumetric vascular segmentation in par with the rest of biomedical image analysis domains with existing datasets.\nUnsupervised pre-training\nAnother way to reduce the labor-intensive ground truth annotation required for our supervised approach, would be to\ninitialize our supervised network using unsupervised pretraining from non-annotated dataset ([8]). In practice, we would feed the unsupervised learning network all our existing vascular image stacks without any annotation labels, and the network would learn the most representative features of that dataset that could be then fed into the first layer of our supervised network (Conv1a of figure 3.2). Erhan et al. [43] have suggested that this pre-training initialization serves as a kind of regularization mechanism that is retained even during the supervised part with the classification performance not deteriorating with the additional supervised training. We could for example use the dictionary learning approach with sparsity priors for 2D vessel images and 3D neuron dendrites proposed by [196] as the pre-processing step, or alternatively use some stacked autoencoder variant used for medical image segmentation [193, 207].\nMore elegant alternative for unsupervised pre-training is to simultaneously apply both unsupervised and supervised learning, instead of having unsupervised pre-training and supervised training as separate steps [168, 130]. Rasmus et al. [168] proposed a modified Ladder Network [229] which demonstrate how by adding their unsupervised Ladder Network to existing supervised learning methods including convolutional networks improved significantly classification performance in handwriting classification (MNIST database [112]), and in image classification (CIFAR-10 database [104]) compared to previous state-of-the-art approaches. Their approach excelled when the amount of labels were small, and especially when number of free parameters was large compared to the number of available samples, showing that the model was able to use the unsupervised learning part efficiently. Particularly attractive detail of their publicly available approach , is that it can be added relatively easy on a network originally developed for supervised learning such as ours, allowing hopefully a better use of our limited annotated dataset.\nJoint training of the image processing pipeline\nIn our work, we have only focused on replacing the vessel enhancement step (see figure 2.1) with automated datadriven ConvNet assisted by various parametrized filters requiring some degree of user interaction. Ideally we would like to all relevant steps starting from image restoration to post-processing of the volumetric ConvNet output, all the way to the mesh generation to be automated using training data to increase the robustness and minimize user interaction.\nWork has already been done for each individual components that could be simply stacked together as separate units, or one could jointly train all components in end-toend fashion. For example recent work by Vemulapalli et al. [231] showed that their deep learning network based on a Gaussian Conditional Random Field (GCRF) model outperformed existing methods in two-dimensional image denoising including the two-dimensional variant BM3D [33] of the BM4D algorithm [132] that we used to denoise our vessel stacks. For other image restoration task such as blind deconvolution [242] for sharpening the stacks, blind inpainting [20] for filling possibly broken vessels, vibrationartifacts, or other image quality artifacts, and motion-blur\ncorrection [209] deep learning based solutions have been proposed with promising results.\nRecent work by Xu et al. [241] demonstrate a deep convolutional networks designed to learn blindly the output of any deterministic filter or a combination of different filters. Authors demonstrated this by learning two different edgepreserving smoothing filters bilateral filter ([217, 7]), and L0 gradient minimization smoothing ([240]) jointly without needing to know anything about the implementations of such filters given that input and output images can be accessed. This edge-aware smoothing could be used as a refining step for our image denoising/deconvolution output to further suppress irrelevant structure for the vessel segmentation. Alternatively, the same framework could be potentially to learn the behavior of commercial software as demonstrated by the authors with \u201ccopycat filter scheme\u201d using Photoshop R\u00a9 filters [241]. One could generate training data for deconvolution for example using some commonly used software package such as Imaris (Bitplane AG, Zurich, Switzerland) or AutoQuant (AutoQuant Imaging/Media Cybernetics), and integrating that \u201cknowledge\u201d to the same deep learning framework without having to jump between different software packages during the analysis of microscopy stacks.\nLee et al. [114] argue that the recursive input from VD2D can be viewed as modulatory \u2019gate\u2019 that the feature activations for structures of interest are enhanced while suppressing activations unrelated to structures of interest. Based on that assumption, it would be interesting to try to replace the VD2D altogether for example with datadriven edge detection network such as the N4-fields [53] or holistically-nested edge detection [238]. N4-fields [53] was shown to segment two-dimension retinal vasculature from the DRIVE dataset [203] better than the Structured Edge detector [39] while the performance was not compared to traditional vessel enhancement filters. Alternatively one could try to integrate recent vessel enhancement filters as structured layers [78] within the ConvNet architecture to try to incorporate some domain knowledge without having to resort to totally hand-crafted features. Recent vesselness filters of interest include the scale-invariant enhancement filter by Moreno et al. [144], and the nearest neighborinspired detection of elongated structures by Sironi et al. [197].\nThe deep learning can be seen as a \u201cbrute force\u201d method for vessel segmentation as it does not explicitly model the geometrical relationships that exist between neighboring \u201cvessel pixels\u201d as pointed out by Sironi et al. [197]. The probability maps can have isolated erroneous responses, discontinuities and topological errors that are typically mitigated using post-processing techniques such as Conditional Random Fields (CRF, [101, 23, 119]), narrowband level sets [99], learned graph-cut segmentation [235] or Auto-Context [223] among others. Authors of the ZNN framework [114] chose to refine their segmentation of electron microscope stacks using a watershed-based algorithm developed by themselves [254], whereas recent work by Almasi et al. [3] reconstructed microvascular networks from the output of active contours [22], and Sironi et al. [197] train an algorithm inspired by Nearest Neighbor Fields [53] to induce global consistency for the probability maps. Both those recent works [3, 197] can be seen complimentary and\nrefining post-processing steps to our approach. At the moment we are only training individual stacks at the time, but it is common in biomedical microscopy to image the same stack over multiple time points. We could extend our model to exploit the temporal dependency among multiple time points, as it is done in 2D video processing where the time can be regarded as the third dimension. Huang et al. [73] for example employ a recurrent neural network (RNN) for modeling temporal context in a video sequence for multi-frame super-resolution reconstruction. This potentially can improve the vessel segmentation as the vessels are not typically deformed heavily between successive stacks when using typical acquisition intervals. The time-extended super-resolution approach should in theory improve the quality of the interpolation in z- dimension when isotropic voxels are wanted, compared to deep learning based single-frame super-resolution [95], and traditional B-spline interpolation [76].\nTo the knowledge of the authors, there has been no attempt to improve the mesh reconstruction step using deep learning framework. Closest example to deep learning in surface reconstruction were demonstrated by Xiong et al. [239], who used a dictionary learning for surface reconstruction from a point cloud, which outperformed state-ofthe art methods in terms of accuracy, robustness to noise and outliers, and geometric feature preservation among other criteria. Jampani et al. [81] demonstrated how they could learn optimal bilateral filter parameters for threedimensional mesh denoising that could be thus used as a post-processing step for surface reconstruction. This is an improvement of the bilateral filter mesh denoising algorithm implemented in Computational Geometry Algorithms Library (CGAL, http://www.cgal.org/) that requires user-set parameters.\nThe simplified schematic of the components for joint optimization is shown in figure 5.1. In our proposed approach we have only focused on the segmentation part whereas in optimal case we would like to have training data of all the different phases of the image processing pipeline. The schematic does not show any more sophisticated layers that could be embedded inside of more generalistic convolutional networks. For example Ionescu et al. [78] demonstrated how to backpropagate global structured matrix computation such as normalized cuts or higher-order pooling. The training of normalized cuts within deep learning framework is similar to the approach taken bu Turaga et al. [225] for optimizing a Rand index with simple connected component labeling (MALIS, which is to be implemented in the ZNN framework used by us). Inclusion of such global layers was shown to increase the segmentation performance compared to more generalized deep networks.\nOther libraries\nCurrently there are not many publicly available software for dense image segmentation for volumetric 3D data, so we were constrained in our choice between GPU-accelerated Theano [215] and the CPU-accelerated ZNN [253]. We chose to use the ZNN framework for our vessel segmentation pipeline. The Caffe-derived DeepLab [23, 155] with both CPU and GPU acceleration options was not supporting efficient 3D ConvNets as it were the case with Caffe\nitself [84] as benchmarked by Jampani et al. [81] for example. The CPU-accelerated ZNN was shown to have efficient computational performance compared to GPU-accelerated Theano [253], and considering the recent price drop of Intel Xeon PhiTM Knights Corner generation of CPU accelerator cards, and introduction of supposedly more user-friendly Knights Landing generation, our choice of implementation seems relatively easy to accelerate in the future. Recently published Python library Keras (http://keras.io/) functions as a high level abstraction library for either Theano and for TensorFlow [167] so that the researcher can focus on the ideas and change flexibly the underlying backend between Theano and TensorFlow as one wishes."}, {"heading": "5.2 Connection to other software frameworks", "text": "Our vessel segmentation pipeline essentially replaces the previously used handcrafted vesselness filters (e.g. [49, 227, 144]) still requiring a refining segmentation algorithm for the ZNN output as the output is not a binary-valued mask, but rather a real-valued probability map. Sumbul et al. [208] used connected component clustering (bwlabeln of Matlab, union-find algorithm, [48]) with morphological filters to refine the ZNN output for retinal ganglion cell (RGC) arbor, while the most recent paper with ZNN [114] compared clustering to more sophisticated watershedbased segmentation [254] for segmenting neuronal boundaries from EM stacks.\nOur work can be seen also as a pre-processing step for morphological reconstruction of vessel networks in mesh domain. The output from our pipeline could be for example used as an input for the mesh reconstruction pipeline of Python-based open source Vessel Modeling Toolkit (VMTK, http://www.vmtk.org/),\nand its inexpensive graphical front-end VMTKLab (http://vmtklab.orobix.com/). This would be more robust segmentation pre-processing step compared to the ones provided by VMTK. VMTK provided the following four vesselness enhancing filters: 1) Frangi\u2019s method [49], 2) Sato\u2019s method [180], 3) Vessel Enhancing Diffusion Filter [42], and 4) Vessel enhancing diffusion [136], with the Frangi\u2019s method being the default option. Vessel enhancing filter works as a pre-processing step in VMTK pipeline for the level set based vessel segmentation of VMTK before running the Marching Cubes algorithm derivative [126] for mesh reconstruction.\nFor researchers who are the most comfortable using graphical tools such as Imaris (Bitplane AG, Zurich, Switzerland), or open-source ImageJ/FIJI platform [182], the proposed approach can be seen as automatic preprocessing step improving the performance of the following manual processing steps. For example the two-class (vessels, and non-vessels) vessel segmentation in Imaris by [121], required many user-supplied intensity thresholds which could have been automatized with our ConvNetbased approach, and the remaining steps for graph reconstruction could have done with existing pipeline."}, {"heading": "5.3 2-PM/Microscopy specific suggestions", "text": "In addition to optimizing our algorithm, image parameters should also be carefully chosen to facilitate vessel segmentation. We are interested in quantifying the degree of blood-brain barrier opening (BBBO) following focused ultrasound stimulation [28, 151, 18]. Experimentally, this is achieved by injecting a fluorescent dextran into the systemic vasculature, and then measuring the difference in fluorescence intensity between the vessels (foreground) and the surrounding tissue during BBBO [151, 18, 244]. Thus,\nby the nature of the experiment, we are making the task harder for the segmentation network as the edges between the vessels and the background will become progressively blurred.\nOne way to improve such a loss of contrast is to quantify the BBBO by using two vascular dyes simultaneously, one which readily leaks out from vessels upon BBBD, and another one with a high molecular weight that leaks out less. An alternative to using high-molecular weight dextrans is to use quantum dots that have narrower emission spectra for reduced dye crosstalk [233], and less leakage from vessels. Quantum dots have already been used to study the tumor vasculature [206]. Another option is to use Alexa Fluor 633 dye, which selectively labels the walls of arteries that are greater than 15-\u00b5m in diameter[190]. This would make vessel segmentation easier as the \u2019leakage\u2019 channel (with the dextran) and \u2019vessel\u2019 channel (with the labeled vessel walls) can be analyzed separately. Recently, multiphoton fluorescent dyes with longer emission and excitation wavelengths [153, 93] have been gaining popularity due to their better transmission through biological tissue yielding improved penetration depths and signal-to-noise ratios (SNRs) [199, 70].\nAnother promising, yet not commonly employed, technique is to increase excitation laser wavelengths up to 1,700 nm [70], and switch to three-photon excitation. This also improves depth penetration, but also allows better optical sectioning due to higher non-linearity due to the z4 attenuation from the focal plane instead of z2 attenuation in two-photon regime, where z is the distance [70]. This reduces noise from out-of-planes and tissue autofluorescence [13]. In terms of our future versions of deep learning framework, we would like to simultaneously dyes for both two-photon and three-photon process so that the crosstalk in z-dimension would be minimized for threephoton process dye allowing that to be used as the ground truth for the super-resolution training (see figure 5.1) for two-photon process dyes. Likewise the improved SNR either with longer-wavelength dye and/or three-photon microscopy could be used as the ground truth for the denoising block for denoising shorter-wavelength fluorescent dyes.\nAnother way to improve SNR is to correct the optical aberrations caused by brain tissue in real-time by using adaptive optics [14]. The use of adaptive optics originated from astronomy [6], where the correction of aberrations caused by atmospheric was able to give better image quality to astronomers. Ji et al. [82] demonstrated the increase in SNR for in vivo calcium imaging was especially significant atgreater depths. The better image quality with adaptive optics could be used as the ground truth for the deconvolution block (see figure 5.1) and the stack without adaptive optics as the training data. Ideally, one could combine all the above methods for optimized imaging quality.\nPhysiological refinement\nIn the proposed architecture here, we did not explicitly try to further refine the segmented vasculature to subclasses, but rather simply differentiated vessel and non-vessel voxels. There have been some work devoted to separating\narteries from veins either using computational techniques [138, 44], or using specific fluorescent labels that specifically label arteries such as Alexa Fluor 633 used by Shen et al. [190]. In the future, we would like extend our network to differentiate arteries from veins by acquiring training data using such an artery-specific dye concurrently with a fluorescent dextran that would label the entire vascular network.\nExtension to other medical applications\nIn our \u201cvanilla network\u201d (see 5.1) we did not have any vasculature specific optimization, and we decided to leverage on the ability of deep learning network to learn the relevant features itself of relying on handcrafted features. Thus, the same network proposed initially for electron microscope image segmentation [208, 114] can be extended to other applications as demonstrated here for volumetric two-photon vasculature image segmentation. To extend the framework for other application, annotated training data is needed for training the network for the given task. To be used with vasculature datasets such as the VESSEL12 [175], it would be sufficient to use our pre-trained network and fine-tune the model, training with small learning rate, rather having to learn from scratch as typically done in specific image classification tasks exploiting some pre-trained network with broader dataset [21, 248]. This is known as transfer learning or domain adaptation depending on the marginal data distribution [157].\nIn practice with vascular segmentation, transfer learning approach correspond to a situation when a network trained for tubular dataset such as DIADEM [16, 159] is used as a basis, and fine-tuning that network using limited samples of multiphoton microscopy data. Domain adaptation would correspond to a situation where we would have trained our network to segment vasculature using some other imaging modality than multiphoton microscopy in which the vasculature (foreground) itself might have similar appearance to multiphoton microscopy, but the background from which we try to segment the vasculature would be different. Xie et al. [237] combined ConvNet with a traditional dictionary-learning approach for domain adaptation that was able to exploit the local discriminative and structural information more efficiently than just using a ConvNet. This is of a relevance for us, as we could use the unsupervised dictionary-based learning approach for vessel stacks proposed by Sironi et al. [196], and combine that to our ConvNet-based approach to exploit the large number of unlabeled vessel stacks.\nIn medical applications, there have been some effort of going around the high annotation cost by exploiting auxiliary data such as textual reports [183, 192], or image-level labels [102] (i.e. whether the whole stack/slice image contains a vessel or not). This type of learning is known as weakly-supervised segmentation, and cannot understandingly reach the segmentation performance as full pixel-level \u201cstrong\u201d annotated supervised learning. Hong et al. [69] recently demonstrated that the gap between fully supervised and weakly-supervised can be reduced compared to previous approaches by exploiting pre-trained ImageNet model for transfer learning with weak labels. In multiphoton microscopy, it is not typically possible to use whole-image la-\nbels as the vasculature is typically so dense that there are not a lot of empty slices with no vessel labels.. Sometimes in practice, the dye loading is unsuccessful or there are technical glitches, and these empty acquired empty stacks could be used to characterize the noise characteristics of non-vessel areas."}, {"heading": "5.4 Open-source code, reproducibility", "text": "We share our annotated two-photon vasculature dataset to the scientific community to address the lack of standardized datasets for multiphoton microscopy. We believe that part of the reason for lack of published work on volumetric vessel segmentation is due to lack of suitable training data, most of the biomedical image segmentation efforts being directed to fields such as electron microscopy [236, 114, 133, 173], and various clinical applications [64, 205, 183, 40] as the training data is readily available. We want to be part of creating a cultural shift from independent efforts of research groups toward an open source and collaborative neuroscience as datasets get larger and more complex [50, 54], as well as ensuring that our framework can be easily reproduced and developed further [161]. In the future, we would like to move away from proprietary Matlab environment to totally open-source code in Python as well."}, {"heading": "6 Conclusion", "text": "We have a proposed a deep learning based framework for two-class segmentation (vessel, and non-vessel) of vascular networks obtained via two-photon microscopy from mouse cortex and human squamous cell carcinoma tumors. We have made the Matlab code available based on the opensource ZNN framework [114, 253]. In contrast to GPUaccelerated frameworks such as Theano [215], the ZNN is optimized to run on CPU while reaching relatively similar performance compared GPU-accelerated approaches [253]. We have already made our training set freely available to address the lack of annotated reference dataset for multiphoton microscopy vasculature segmentation. We are hoping that this will both inspire other research groups sharing their vasculature datasets, as well as improving our proposed framework. Our future work will focus on enhancing the computational performance and accuracy of the network for multiphoton microscopy vessel segmentation."}, {"heading": "Acknowledgements", "text": "We would like to thank Sharan Sankar for his work as a summer student writing wrapper for various wrappers for ITK C++ functions."}], "references": [{"title": "Blind Separation of Image Sources via Adaptive Dictionary Learning", "author": ["V. Abolghasemi", "S. Ferdowsi", "S. Sanei"], "venue": "IEEE Transactions on Image Processing, 21(6):2921\u20132930, June", "citeRegEx": "1", "shortCiteRegEx": null, "year": 2012}, {"title": "Fast High-Dimensional Filtering Using the Permutohedral Lattice", "author": ["A. Adams", "J. Baek", "M.A. Davis"], "venue": "Computer Graphics  Forum, 29(2):753\u2013762,", "citeRegEx": "2", "shortCiteRegEx": null, "year": 2010}, {"title": "A novel method for identifying a graph-based representation of 3-D microvascular networks from fluorescence microscopy image stacks", "author": ["S. Almasi", "X. Xu", "A. Ben-Zvi", "B. Lacoste", "C. Gu"], "venue": "Medical Image Analysis,", "citeRegEx": "3", "shortCiteRegEx": "3", "year": 2015}, {"title": "Crowdsourcing the creation of image segmentation algorithms for connectomics", "author": ["I. Arganda-Carreras", "S.C. Turaga", "D.R. Berger", "D. Cire\u015fan", "A. Giusti"], "venue": "Frontiers in Neuroanatomy,", "citeRegEx": "5", "shortCiteRegEx": "5", "year": 2015}, {"title": "The Possibility of Compensating Astronomical Seeing", "author": ["H. Babcock"], "venue": "Publications of the Astronomical Society of the Pacific, 65(386):229,", "citeRegEx": "6", "shortCiteRegEx": null, "year": 1953}, {"title": "The Fast Bilateral Solver", "author": ["J.T. Barron", "B. Poole"], "venue": "arXiv preprint, arXiv:1511.03296,", "citeRegEx": "7", "shortCiteRegEx": null, "year": 2015}, {"title": "Greedy layer-wise training of deep networks", "author": ["Y. Bengio", "P. Lamblin", "D. Popovici", "H. Larochelle", "others"], "venue": "Advances in neural information processing systems,", "citeRegEx": "8", "shortCiteRegEx": "8", "year": 2007}, {"title": "Better Mixing via Deep Representations", "author": ["Y. Bengio", "G. Mesnil", "Y. Dauphin", "S. Rifai"], "venue": "arXiv:1207.4404 [cs], July", "citeRegEx": "9", "shortCiteRegEx": null, "year": 2012}, {"title": "Image deblurring with Poisson data: from cells to galaxies", "author": ["M. Bertero", "P. Boccacci", "G. Desider\u00e0", "G. Vicidomini"], "venue": "Inverse Problems, 25(12):123006, December", "citeRegEx": "10", "shortCiteRegEx": null, "year": 2009}, {"title": "On the Complexity of Neural Network Classifiers: A Comparison Between Shallow and Deep Architectures", "author": ["M. Bianchini", "F. Scarselli"], "venue": "IEEE Transactions on Neural Networks and Learning Systems, 25(8):1553\u20131565, August", "citeRegEx": "11", "shortCiteRegEx": null, "year": 2014}, {"title": "Near-infrared branding efficiently correlates light and electron microscopy", "author": ["D. Bishop", "I. Niki\u0107", "M. Brinkoetter", "S. Knecht", "S. Potz"], "venue": "Nature Methods,", "citeRegEx": "12", "shortCiteRegEx": "12", "year": 2011}, {"title": "Two-photon excitation action cross-sections of the autofluorescent proteins", "author": ["G.A. Blab", "P.H.M. Lommerse", "L. Cognet", "G.S. Harms", "T. Schmidt"], "venue": "Chemical Physics Letters, 350(1\u20132):71\u201377, December", "citeRegEx": "13", "shortCiteRegEx": null, "year": 2001}, {"title": "Adaptive optical microscopy: the ongoing quest for a perfect image", "author": ["M.J. Booth"], "venue": "Light: Science & Applications, 3(4):e165, April", "citeRegEx": "14", "shortCiteRegEx": null, "year": 2014}, {"title": "Random Forests", "author": ["L. Breiman"], "venue": "Machine Learning, 45(1):5\u201332, October", "citeRegEx": "15", "shortCiteRegEx": null, "year": 2001}, {"title": "The DIADEM Data Sets: Representative Light Microscopy Images of Neuronal Morphology to Advance Automation of Digital Reconstructions", "author": ["K.M. Brown", "G. Barrionuevo", "A.J. Canty", "V.D. Paola", "J.A. Hirsch"], "venue": "URL: http://dx.doi.org/10.1007/s12021-010-9095-5", "citeRegEx": "16", "shortCiteRegEx": "16", "year": 2011}, {"title": "Microbubble-Assisted Ultrasound for Drug Delivery in the Brain and Central Nervous System", "author": ["A. Burgess", "K. Hynynen"], "venue": "J.-M. Escoffre and A. Bouakaz, editors, Therapeutic Ultrasound, number 880 in Advances in Experimental Medicine and Biology, pages 293\u2013308. Springer International Publishing,", "citeRegEx": "17", "shortCiteRegEx": null, "year": 2016}, {"title": "Analysis of focused ultrasound-induced blood\u2013brain barrier permeability in a mouse model of Alzheimer\u2019s disease using two-photon microscopy", "author": ["A. Burgess", "T. Nhan", "C. Moffatt", "A.L. Klibanov", "K. Hynynen"], "venue": "Journal of Controlled Release, 192:243\u2013248, October", "citeRegEx": "18", "shortCiteRegEx": null, "year": 2014}, {"title": "A Review of Low-Intensity Transcranial Focused Ultrasound for Clinical Applications", "author": ["A. Bystritsky", "A.S. Korb"], "venue": "Current Behavioral Neuroscience Reports, pages 1\u20137, March", "citeRegEx": "19", "shortCiteRegEx": null, "year": 2015}, {"title": "Blind inpainting using the fully convolutional neural network", "author": ["N. Cai", "Z. Su", "Z. Lin", "H. Wang", "Z. Yang"], "venue": "The Visual Computer,", "citeRegEx": "20", "shortCiteRegEx": "20", "year": 2015}, {"title": "Unregistered Multiview Mammogram Analysis with Pre-trained Deep Learning Models", "author": ["G. Carneiro", "J. Nascimento", "A.P. Bradley"], "venue": "N. Navab, J. Hornegger, W. M. Wells, and A. F. Frangi, editors, Medical Image Computing and Computer-Assisted Intervention \u2013 MICCAI 2015, number 9351 in Lecture Notes in Computer Science, pages 652\u2013660. Springer International Publishing, October", "citeRegEx": "21", "shortCiteRegEx": null, "year": 2015}, {"title": "Active contours without edges", "author": ["T. Chan", "L. Vese"], "venue": "Image Processing, IEEE Transactions on, 10(2):266\u2013277,", "citeRegEx": "22", "shortCiteRegEx": null, "year": 2001}, {"title": "Semantic Image Segmentation with Deep Convolutional Nets and Fully Connected CRFs", "author": ["L.-C. Chen", "G. Papandreou", "I. Kokkinos", "K. Murphy", "A.L. Yuille"], "venue": "ICLR,", "citeRegEx": "23", "shortCiteRegEx": null, "year": 2015}, {"title": "Attention to Scale: Scale-aware Semantic Image Segmentation", "author": ["L.-C. Chen", "Y. Yang", "J. Wang", "W. Xu", "A.L. Yuille"], "venue": "arXiv:1511.03339 [cs], November", "citeRegEx": "24", "shortCiteRegEx": null, "year": 2015}, {"title": "Incremental Integration of Global Contours through Interplay between Visual Cortical Areas", "author": ["M. Chen", "Y. Yan", "X. Gong", "C.D. Gilbert", "H. Liang"], "venue": null, "citeRegEx": "25", "shortCiteRegEx": "25", "year": 2014}, {"title": "Automatic Feature Learning for Glaucoma", "author": ["X. Chen", "Y. Xu", "S. Yan", "D.W.K. Wong", "T.Y. Wong"], "venue": "Detection Based on Deep Learning", "citeRegEx": "26", "shortCiteRegEx": "26", "year": 2015}, {"title": "An exploration of parameter redundancy in deep networks with circulant projections", "author": ["Y. Cheng", "F.X. Yu", "R.S. Feris", "S. Kumar", "A. Choudhary"], "venue": "In Proceedings of the IEEE International Conference on Computer Vision,", "citeRegEx": "27", "shortCiteRegEx": "27", "year": 2015}, {"title": "Two-photon fluorescence microscopy study of cerebrovascular dynamics in ultrasound-induced blood\u2013brain barrier opening", "author": ["E.E. Cho", "J. Drazic", "M. Ganguly", "B. Stefanovic", "K. Hynynen"], "venue": "Journal of Cerebral Blood Flow & Metabolism, 31(9):1852\u20131862, September", "citeRegEx": "28", "shortCiteRegEx": null, "year": 2011}, {"title": "Doctor AI: Predicting Clinical Events via Recurrent Neural Networks", "author": ["E. Choi", "M.T. Bahadori", "J. Sun"], "venue": "arXiv:1511.05942 [cs], November", "citeRegEx": "29", "shortCiteRegEx": null, "year": 2015}, {"title": "Deep Neural Networks Segment Neuronal Membranes in Electron Microscopy Images", "author": ["D. Ciresan", "A. Giusti", "L.M. Gambardella", "J. Schmidhuber"], "venue": "F. Pereira, C. J. C. Burges, L. Bottou, and K. Q. Weinberger, editors, Advances in Neural Information Processing Systems 25, pages 2843\u20132851. Curran Associates, Inc.,", "citeRegEx": "30", "shortCiteRegEx": null, "year": 2012}, {"title": "Fast and Accurate Deep Network Learning by Exponential Linear Units (ELUs)", "author": ["D.-A. Clevert", "T. Unterthiner", "S. Hochreiter"], "venue": "arXiv:1511.07289 [cs], November", "citeRegEx": "31", "shortCiteRegEx": null, "year": 2015}, {"title": "An integrated approach to quantitative modelling in angiogenesis research", "author": ["A.J. Connor", "R.P. Nowak", "E. Lorenzon", "M. Thomas", "F. Herting"], "venue": "Journal of The Royal Society Interface,", "citeRegEx": "32", "shortCiteRegEx": "32", "year": 2015}, {"title": "Image Denoising by Sparse 3-D Transform-Domain Collaborative Filtering", "author": ["K. Dabov", "A. Foi", "V. Katkovnik", "K. Egiazarian"], "venue": "IEEE Transactions on Image Processing, 16(8):2080\u20132095, August", "citeRegEx": "33", "shortCiteRegEx": null, "year": 2007}, {"title": "Cerebral microvascular pericytes and neurogliovascular signaling in health and disease", "author": ["T. Dalkara", "L. Alarcon-Martinez"], "venue": "Brain Research, 1623:3\u201317, October", "citeRegEx": "34", "shortCiteRegEx": null, "year": 2015}, {"title": "Optical electrocorticogram (OECoG) using wide-field calcium imaging reveals the divergence of neuronal and glial activity during acute rodent seizures", "author": ["A.G.S. Daniel", "P. Laffont", "M. Zhao", "H. Ma", "T.H. Schwartz"], "venue": "Epilepsy & Behavior,", "citeRegEx": "35", "shortCiteRegEx": null, "year": 2015}, {"title": "Denoising of two-photon fluorescence images with Block- Matching 3d filtering", "author": ["A. Danielyan", "Y.-W. Wu", "P.-Y. Shih", "Y. Dembitskaya", "A. Semyanov"], "venue": "Methods, 68(2):308\u2013316, July", "citeRegEx": "36", "shortCiteRegEx": null, "year": 2014}, {"title": "Use of independent component analysis to improve signal-to-noise ratio in multi-probe fluorescence microscopy", "author": ["L. Dao", "B. Lucotte", "B. Glancy", "L.-C. Chang", "L.-Y. Hsu"], "venue": "Journal of Microscopy,", "citeRegEx": "37", "shortCiteRegEx": "37", "year": 2014}, {"title": "Icy: an open bioimage informatics platform for extended reproducible research", "author": ["F. de Chaumont", "S. Dallongeville", "N. Chenouard", "N. Herv\u00e9", "S. Pop"], "venue": "Nature Methods,", "citeRegEx": "38", "shortCiteRegEx": "38", "year": 2012}, {"title": "Fast Edge Detection Using Structured Forests", "author": ["P. Dollar", "C. Zitnick"], "venue": "IEEE Transactions on Pattern Analysis and Machine Intelligence, 37(8):1558\u20131570, August", "citeRegEx": "39", "shortCiteRegEx": null, "year": 2015}, {"title": "Computational Mammography using Deep Neural Networks", "author": ["A. Dubrovina", "P. Kisilev", "B. Ginsburg", "S. Hashoul", "R. Kimmel"], "venue": null, "citeRegEx": "40", "shortCiteRegEx": "40", "year": 2015}, {"title": "A Proximal Iteration for Deconvolving Poisson Noisy Images Using Sparse Representations", "author": ["F.-X. Dupe", "J. Fadili", "J.-L. Starck"], "venue": "IEEE Transactions on Image Processing, 18(2):310\u2013321, February", "citeRegEx": "41", "shortCiteRegEx": null, "year": 2009}, {"title": "Vessel Enhancing Diffusion Filter", "author": ["A. Enquobahrie", "L. Ibanez", "E. Bullitt", "S. Aylward"], "venue": "The Insight Journal - 2007 MICCAI Open Science Workshop,", "citeRegEx": "42", "shortCiteRegEx": null, "year": 2007}, {"title": "Why Does Unsupervised Pre-training Help Deep Learning", "author": ["D. Erhan", "Y. Bengio", "A. Courville", "P.-A. Manzagol", "P. Vincent"], "venue": "J. Mach. Learn. Res.,", "citeRegEx": "43", "shortCiteRegEx": "43", "year": 2010}, {"title": "Retinal Artery-Vein Classification via Topology Estimation", "author": ["R. Estrada", "M. Allingham", "P. Mettu", "S. Cousins", "C. Tomasi"], "venue": "IEEE Transactions on Medical Imaging,", "citeRegEx": "44", "shortCiteRegEx": "44", "year": 2015}, {"title": "Learning Hierarchical Features for Scene Labeling", "author": ["C. Farabet", "C. Couprie", "L. Najman", "Y. LeCun"], "venue": "IEEE Transactions on Pattern Analysis and Machine Intelligence, 35(8):1915\u20131929, August", "citeRegEx": "45", "shortCiteRegEx": null, "year": 2013}, {"title": "A Bottom-up Approach for Pancreas Segmentation using Cascaded Superpixels and (Deep) Image Patch Labeling", "author": ["A. Farag", "L. Lu", "H.R. Roth", "J. Liu", "E. Turkbey"], "venue": "[cs],", "citeRegEx": "46", "shortCiteRegEx": "46", "year": 2015}, {"title": "Big data from small data: data-sharing in the \u2019long tail\u2019 of neuroscience", "author": ["A.R. Ferguson", "J.L. Nielson", "M.H. Cragin", "A.E. Bandrowski", "M.E. Martone"], "venue": "Nature Neuroscience, 17(11):1442\u20131447, November", "citeRegEx": "47", "shortCiteRegEx": null, "year": 2014}, {"title": "Two linear time Union-Find strategies for image processing", "author": ["C. Fiorio", "J. Gustedt"], "venue": "Theoretical Computer Science, 154(2):165\u2013181, February", "citeRegEx": "48", "shortCiteRegEx": null, "year": 1996}, {"title": "Multiscale vessel enhancement filtering", "author": ["A.F. Frangi", "W.J. Niessen", "K.L. Vincken", "M.A. Viergever"], "venue": "W. M. Wells, A. Colchester, and S. Delp, editors, Medical Image Computing and Computer-Assisted Interventation \u2014 MICCAI\u201998, number 1496 in Lecture Notes in Computer Science, pages 130\u2013137. Springer Berlin Heidelberg, October", "citeRegEx": "49", "shortCiteRegEx": null, "year": 1998}, {"title": "Open source tools for large-scale neuroscience", "author": ["J. Freeman"], "venue": "Current Opinion in Neurobiology, 32:156\u2013163, June", "citeRegEx": "50", "shortCiteRegEx": null, "year": 2015}, {"title": "Superpixel Convolutional Networks using Bilateral Inceptions", "author": ["R. Gadde", "V. Jampani", "M. Kiefel", "P.V. Gehler"], "venue": "arXiv preprint arXiv:1511.06739,", "citeRegEx": "51", "shortCiteRegEx": null, "year": 2015}, {"title": "Dropout as a Bayesian Approximation: Representing Model Uncertainty in Deep Learning", "author": ["Y. Gal", "Z. Ghahramani"], "venue": "arXiv:1506.02142 [cs, stat], June", "citeRegEx": "52", "shortCiteRegEx": null, "year": 2015}, {"title": "N^4-Fields: Neural Network Nearest Neighbor Fields for Image Transforms", "author": ["Y. Ganin", "V. Lempitsky"], "venue": "D. Cremers, I. Reid, H. Saito, and M.-H. Yang, editors, Computer Vision \u2013 ACCV 2014, number 9004 in Lecture Notes in Computer Science, pages 536\u2013551. Springer International Publishing, November", "citeRegEx": "53", "shortCiteRegEx": null, "year": 2014}, {"title": "On simplicity and complexity in the brave new world of large-scale neuroscience", "author": ["P. Gao", "S. Ganguli"], "venue": "Current Opinion in Neurobiology, 32:148\u2013155, June", "citeRegEx": "54", "shortCiteRegEx": null, "year": 2015}, {"title": "Probabilistic machine learning and artificial intelligence", "author": ["Z. Ghahramani"], "venue": "Nature, 521(7553):452\u2013459, May", "citeRegEx": "55", "shortCiteRegEx": null, "year": 2015}, {"title": "Marginal Space Deep Learning: Efficient Architecture for Detection in Volumetric Image Data", "author": ["F.C. Ghesu", "B. Georgescu", "Y. Zheng", "J. Hornegger", "D. Comaniciu"], "venue": "N. Navab, J. Hornegger, W. M. Wells, and A. F. Frangi, editors, Medical Image Computing and Computer-Assisted Intervention \u2013 MICCAI 2015, number 9349 in Lecture Notes in Computer Science, pages 710\u2013 718. Springer International Publishing, October", "citeRegEx": "56", "shortCiteRegEx": null, "year": 2015}, {"title": "Fast Image Scanning with Deep Max-Pooling Convolutional Neural Networks", "author": ["A. Giusti", "D.C. Cire\u015fan", "J. Masci", "L.M. Gambardella", "J. Schmidhuber"], "venue": "arXiv:1302.1700 [cs], February", "citeRegEx": "57", "shortCiteRegEx": null, "year": 2013}, {"title": "Learning rotational features for filament detection", "author": ["G. Gonzalez", "F. Fleurety", "P. Fua"], "venue": "IEEE Conference on Computer Vision and Pattern Recognition, 2009. CVPR 2009, pages 1582\u20131589, June", "citeRegEx": "58", "shortCiteRegEx": null, "year": 2009}, {"title": "Maxout Networks", "author": ["I.J. Goodfellow", "D. Warde-Farley", "M. Mirza", "A. Courville", "Y. Bengio"], "venue": "arXiv:1302.4389 [cs, stat], February", "citeRegEx": "59", "shortCiteRegEx": null, "year": 2013}, {"title": "Recent Advances in Convolutional Neural Networks", "author": ["J. Gu", "Z. Wang", "J. Kuen", "L. Ma", "A. Shahroudy"], "venue": "[cs],", "citeRegEx": "60", "shortCiteRegEx": "60", "year": 2015}, {"title": "Model Accuracy and Runtime Tradeoff in Distributed Deep Learning", "author": ["S. Gupta", "W. Zhang", "J. Milthorpe"], "venue": "arXiv:1509.04210 [cs, stat], September", "citeRegEx": "61", "shortCiteRegEx": null, "year": 2015}, {"title": "Vesselness via Multiple Scale Orientation Scores", "author": ["J. Hannink", "R. Duits", "E. Bekkers"], "venue": "arXiv:1402.4963 [cs], February", "citeRegEx": "62", "shortCiteRegEx": null, "year": 2014}, {"title": "Choice-specific sequences in parietal cortex during a virtual-navigation decision task", "author": ["C.D. Harvey", "P. Coen", "D.W. Tank"], "venue": "Nature, 484(7392):62\u201368, March", "citeRegEx": "63", "shortCiteRegEx": null, "year": 2012}, {"title": "Brain Tumor Segmentation with Deep Neural Networks", "author": ["M. Havaei", "A. Davy", "D. Warde-Farley", "A. Biard", "A. Courville"], "venue": "[cs],", "citeRegEx": "64", "shortCiteRegEx": "64", "year": 2015}, {"title": "Delving Deep into Rectifiers: Surpassing Human-Level Performance on ImageNet Classification", "author": ["K. He", "X. Zhang", "S. Ren", "J. Sun"], "venue": "arXiv:1502.01852 [cs], February", "citeRegEx": "65", "shortCiteRegEx": null, "year": 2015}, {"title": "Deep tissue two-photon microscopy", "author": ["F. Helmchen", "W. Denk"], "venue": "Nature Methods, 2(12):932\u2013940, December", "citeRegEx": "66", "shortCiteRegEx": null, "year": 2005}, {"title": "Connectomic reconstruction of the inner plexiform layer in the mouse", "author": ["M. Helmstaedter", "K.L. Briggman", "S.C. Turaga", "V. Jain", "H.S. Seung"], "venue": "retina. Nature,", "citeRegEx": "67", "shortCiteRegEx": "67", "year": 2013}, {"title": "Icasso: software for investigating the reliability of ICA estimates by clustering and visualization", "author": ["J. Himberg", "A. Hyvarinen"], "venue": "2003 IEEE 13th Workshop on Neural Networks for Signal Processing, 2003. NNSP\u201903, pages 259\u2013268, September", "citeRegEx": "68", "shortCiteRegEx": null, "year": 2003}, {"title": "Learning Transferrable Knowledge for Semantic Segmentation with Deep Convolutional Neural Network", "author": ["S. Hong", "J. Oh", "B. Han", "H. Lee"], "venue": "arXiv:1512.07928 [cs], December", "citeRegEx": "69", "shortCiteRegEx": null, "year": 2015}, {"title": "In vivo three-photon microscopy of subcortical structures within an intact mouse brain", "author": ["N.G. Horton", "K. Wang", "D. Kobat", "C.G. Clark", "F.W. Wise"], "venue": "Nature Photonics,", "citeRegEx": "70", "shortCiteRegEx": "70", "year": 2013}, {"title": "Some Improvements on Deep Convolutional Neural Network Based Image Classification", "author": ["A.G. Howard"], "venue": "arXiv:1312.5402 [cs], December", "citeRegEx": "71", "shortCiteRegEx": null, "year": 2013}, {"title": "Deep and Wide Multiscale Recursive Networks for Robust Image Labeling", "author": ["G.B. Huang", "V. Jain"], "venue": "arXiv:1310.0354 [cs], October", "citeRegEx": "72", "shortCiteRegEx": null, "year": 2013}, {"title": "Bidirectional Recurrent Convolutional Networks for Multi-Frame Super-Resolution", "author": ["Y. Huang", "W. Wang", "L. Wang"], "venue": "C. Cortes, N. D. Lawrence, D. D. Lee, M. Sugiyama, R. Garnett et al., editors, Advances in Neural Information Processing Systems 28, pages 235\u2013243. Curran Associates, Inc.,", "citeRegEx": "73", "shortCiteRegEx": null, "year": 2015}, {"title": "Local and reversible blood\u2013brain barrier disruption by noninvasive focused ultrasound at frequencies suitable for trans-skull sonications", "author": ["K. Hynynen", "N. McDannold", "N.A. Sheikov", "F.A. Jolesz", "N. Vykhodtseva"], "venue": "NeuroImage, 24(1):12\u201320, January", "citeRegEx": "74", "shortCiteRegEx": null, "year": 2005}, {"title": "Retinal Vascular Caliber Measurements: Clinical Significance, Current Knowledge and Future Perspectives", "author": ["M.K. Ikram", "Y.T. Ong", "C.Y. Cheung", "T.Y. Wong"], "venue": "Ophthalmologica, 229(3):125\u2013 136,", "citeRegEx": "75", "shortCiteRegEx": null, "year": 2013}, {"title": "Adaptiveweighted cubic B-spline using lookup tables for fast and efficient axial resampling of 3d confocal microscopy images", "author": ["C. Indhumathi", "Y. Cai", "Y. Guan", "M. Opas", "J. Zheng"], "venue": "Microscopy Research and Technique, 75(1):20\u201327, January", "citeRegEx": "76", "shortCiteRegEx": null, "year": 2012}, {"title": "Batch normalization: Accelerating deep network training by reducing internal covariate shift", "author": ["S. Ioffe", "C. Szegedy"], "venue": "arXiv preprint arXiv:1502.03167,", "citeRegEx": "77", "shortCiteRegEx": null, "year": 2015}, {"title": "Matrix Backpropagation for Deep Networks with Structured Layers", "author": ["C. Ionescu", "O. Vantzos", "C. Sminchisescu"], "venue": "Proceedings of the IEEE International Conference on Computer Vision, pages 2965\u20132973,", "citeRegEx": "78", "shortCiteRegEx": null, "year": 2015}, {"title": "Polynomial theory of complex systems", "author": ["A.G. Ivakhnenko"], "venue": "Systems, Man and Cybernetics, IEEE Transactions on, (4):364\u2013378,", "citeRegEx": "79", "shortCiteRegEx": null, "year": 1971}, {"title": "Design of steerable filters for feature detection using canny-like criteria", "author": ["M. Jacob", "M. Unser"], "venue": "IEEE Transactions on Pattern Analysis and Machine Intelligence, 26(8):1007\u20131019, August", "citeRegEx": "80", "shortCiteRegEx": null, "year": 2004}, {"title": "Learning Sparse High Dimensional Filters: Image Filtering, Dense CRFs and Bilateral Neural Networks", "author": ["V. Jampani", "M. Kiefel", "P.V. Gehler"], "venue": "ArXiv e-prints, 1503:arXiv:1503.04949, March", "citeRegEx": "81", "shortCiteRegEx": null, "year": 2015}, {"title": "Characterization and adaptive optical correction of aberrations during in vivo imaging in the mouse cortex", "author": ["N. Ji", "T.R. Sato", "E. Betzig"], "venue": "Proceedings of the National Academy of Sciences, 109(1):22\u201327, March", "citeRegEx": "82", "shortCiteRegEx": null, "year": 2012}, {"title": "3d Convolutional Neural Networks for Human Action Recognition", "author": ["S. Ji", "W. Xu", "M. Yang", "K. Yu"], "venue": "IEEE Transactions on Pattern Analysis and Machine Intelligence, 35(1):221\u2013231, January", "citeRegEx": "83", "shortCiteRegEx": null, "year": 2013}, {"title": "Caffe: Convolutional Architecture for Fast Feature Embedding", "author": ["Y. Jia", "E. Shelhamer", "J. Donahue", "S. Karayev", "J. Long"], "venue": "arXiv preprint arXiv:1408.5093,", "citeRegEx": "84", "shortCiteRegEx": "84", "year": 2014}, {"title": "Multi-Scale 3d Convolutional Neural Networks for Lesion Segmentation in Brain MRI", "author": ["K. Kamnitsas", "L. Chen", "C. Ledig", "D. Rueckert", "B. Glocker"], "venue": "Ischemic Stroke Lesion Segmentation, page 13,", "citeRegEx": "85", "shortCiteRegEx": null, "year": 2015}, {"title": "Efficient Multi-Scale 3d CNN with Fully Connected CRF for Accurate Brain Lesion Segmentation", "author": ["K. Kamnitsas", "C. Ledig", "V.F. Newcombe", "J.P. Simpson", "A.D. Kane"], "venue": "arXiv preprint arXiv:1603.05959,", "citeRegEx": "86", "shortCiteRegEx": "86", "year": 2016}, {"title": "Machine Learning Approaches for Predicting Radiation Therapy Outcomes: A Clinician\u2019s Perspective", "author": ["J. Kang", "R. Schwartz", "J. Flickinger", "S. Beriwal"], "venue": "International Journal of Radiation Oncology*Biology*Physics, 93(5):1127\u20131135, December", "citeRegEx": "87", "shortCiteRegEx": null, "year": 2015}, {"title": "Better reporting for better research: a checklist for reproducibility", "author": ["A. Kenall", "S. Edmunds", "L. Goodman", "L. Bal", "L. Flintoft"], "venue": "BMC Neuroscience,", "citeRegEx": "88", "shortCiteRegEx": "88", "year": 2015}, {"title": "Bayesian SegNet: Model Uncertainty in Deep Convolutional Encoder-Decoder Architectures for Scene Understanding", "author": ["A. Kendall", "V. Badrinarayanan", "R. Cipolla"], "venue": "arXiv:1511.02680 [cs], November", "citeRegEx": "89", "shortCiteRegEx": null, "year": 2015}, {"title": "Vascular Flow Modelling Using Computational Fluid Dynamics", "author": ["A. Keshmiri", "K. Andrews"], "venue": "M. Slevin and G. McDowell, editors, Handbook of Vascular Biology Techniques, pages 343\u2013361. Springer Netherlands,", "citeRegEx": "90", "shortCiteRegEx": null, "year": 2015}, {"title": "Permutohedral Lattice CNNs", "author": ["M. Kiefel", "V. Jampani", "P.V. Gehler"], "venue": "arXiv:1412.6618 [cs], December", "citeRegEx": "91", "shortCiteRegEx": null, "year": 2014}, {"title": "Blind Depth-variant Deconvolution of 3d Data in Wide-field Fluorescence Microscopy", "author": ["B. Kim", "T. Naemura"], "venue": "Scientific Reports, 5:9894, May", "citeRegEx": "92", "shortCiteRegEx": null, "year": 2015}, {"title": "Two- Photon Absorbing Dyes with Minimal Autofluorescence in Tissue Imaging: Application to in Vivo Imaging of Amyloid-\u03b2 Plaques with a Negligible Background Signal", "author": ["D. Kim", "H. Moon", "S.H. Baik", "S. Singha", "Y.W. Jun"], "venue": "Journal of the American Chemical Society,", "citeRegEx": "93", "shortCiteRegEx": "93", "year": 2015}, {"title": "Space-time wiring specificity supports direction selectivity in the retina", "author": ["J.S. Kim", "M.J. Greene", "A. Zlateski", "K. Lee", "M. Richardson"], "venue": "Nature,", "citeRegEx": "94", "shortCiteRegEx": "94", "year": 2014}, {"title": "Deeply-Recursive Convolutional Network for Image Super-Resolution", "author": ["J. Kim", "J.K. Lee", "K.M. Lee"], "venue": "arXiv:1511.04491 [cs], November", "citeRegEx": "95", "shortCiteRegEx": null, "year": 2015}, {"title": "Variational Dropout and the Local Reparameterization Trick", "author": ["D.P. Kingma", "T. Salimans", "M. Welling"], "venue": "arXiv:1506.02557 [cs, stat], June", "citeRegEx": "96", "shortCiteRegEx": null, "year": 2015}, {"title": "A Review of Vessel Extraction Techniques and Algorithms", "author": ["C. Kirbas", "F. Quek"], "venue": "ACM Comput. Surv., 36(2):81\u2013121, June", "citeRegEx": "97", "shortCiteRegEx": null, "year": 2004}, {"title": "Standardized evaluation framework for evaluating coronary artery stenosis detection, stenosis quantification and lumen segmentation algorithms in computed tomography angiography", "author": ["H.A. Kiri\u015fli", "M. Schaap", "C.T. Metz", "A.S. Dharampal", "W.B. Meijboom"], "venue": "Medical Image Analysis,", "citeRegEx": "98", "shortCiteRegEx": "98", "year": 2013}, {"title": "Automatic Multi-organ Segmentation Using Learning-Based Segmentation and Level Set Optimization", "author": ["T. Kohlberger", "M. Sofka", "J. Zhang", "N. Birkbeck", "J. Wetzl"], "venue": "Medical Image Computing and Computer- Assisted Intervention \u2013 MICCAI 2011,", "citeRegEx": "99", "shortCiteRegEx": "99", "year": 2011}, {"title": "Introducing Geometry in Active Learning for Image Segmentation", "author": ["K. Konyushkova", "R. Sznitman", "P. Fua"], "venue": "arXiv:1508.04955 [cs], August", "citeRegEx": "100", "shortCiteRegEx": null, "year": 2015}, {"title": "Efficient Inference in Fully Connected CRFs with Gaussian Edge Potentials", "author": ["P. Kr\u00e4henb\u00fchl", "V. Koltun"], "venue": "arXiv:1210.5644 [cs], October", "citeRegEx": "101", "shortCiteRegEx": null, "year": 2012}, {"title": "Classifying and Segmenting Microscopy Images Using Convolutional Multiple Instance Learning", "author": ["O.Z. Kraus", "L.J. Ba", "B. Frey"], "venue": "arXiv preprint arXiv:1511.05286,", "citeRegEx": "102", "shortCiteRegEx": null, "year": 2015}, {"title": "Dictionary Learning Algorithms for Sparse Representation", "author": ["K. Kreutz-Delgado", "J.F. Murray", "B.D. Rao", "K. Engan", "T.-W. Lee"], "venue": "Neural Computation,", "citeRegEx": "103", "shortCiteRegEx": "103", "year": 2003}, {"title": "Learning Multiple Layers of Features from Tiny Images", "author": ["A. Krizhevsky"], "venue": null, "citeRegEx": "104", "shortCiteRegEx": "104", "year": 2009}, {"title": "ImageNet Classification with Deep Convolutional Neural Networks", "author": ["A. Krizhevsky", "I. Sutskever", "G.E. Hinton"], "venue": "F. Pereira, C. J. C. Burges, L. Bottou, and K. Q. Weinberger, editors, Advances in Neural Information Processing Systems 25, pages 1097\u2013 1105. Curran Associates, Inc.,", "citeRegEx": "105", "shortCiteRegEx": null, "year": 2012}, {"title": "Feature Space Optimization for Semantic Video Segmentation", "author": ["A. Kundu", "V. Vineet", "V. Koltun"], "venue": "CVPR,", "citeRegEx": "106", "shortCiteRegEx": null, "year": 2016}, {"title": "Human-level concept learning through probabilistic program induction", "author": ["B.M. Lake", "R. Salakhutdinov", "J.B. Tenenbaum"], "venue": "Science, 350(6266):1332\u20131338, November", "citeRegEx": "107", "shortCiteRegEx": null, "year": 2015}, {"title": "Automatic Segmentation of the Pulmonary Lobes From Chest CT Scans Based on Fissures, Vessels, and Bronchi", "author": ["B. Lassen", "E. van Rikxoort", "M. Schmidt", "S. Kerkstra", "B. van Ginneken"], "venue": "IEEE Transactions on Medical Imaging,", "citeRegEx": "108", "shortCiteRegEx": "108", "year": 2013}, {"title": "Three Dimensional Curvilinear Structure Detection Using Optimally Oriented Flux", "author": ["M.W.K. Law", "A.C.S. Chung"], "venue": "D. Forsyth, P. Torr, and A. Zisserman, editors, Computer Vision \u2013 ECCV 2008, number 5305 in Lecture Notes in Computer Science, pages 368\u2013382. Springer Berlin Heidelberg,", "citeRegEx": "109", "shortCiteRegEx": null, "year": 2008}, {"title": "An Oriented Flux Symmetry Based Active Contour Model for Three Dimensional Vessel Segmentation", "author": ["M.W.K. Law", "A.C.S. Chung"], "venue": "K. Daniilidis, P. Maragos, and N. Paragios, editors, Computer Vision \u2013 ECCV 2010, number 6313 in Lecture Notes in Computer Science, pages 720\u2013734. Springer Berlin Heidelberg,", "citeRegEx": "110", "shortCiteRegEx": null, "year": 2010}, {"title": "Backpropagation Applied to Handwritten Zip Code Recognition", "author": ["Y. LeCun", "B. Boser", "J.S. Denker", "D. Henderson", "R.E. Howard"], "venue": "Neural Computation,", "citeRegEx": "111", "shortCiteRegEx": "111", "year": 1989}, {"title": "Gradient-based learning applied to document recognition", "author": ["Y. Lecun", "L. Bottou", "Y. Bengio", "P. Haffner"], "venue": "Proceedings of the IEEE, 86(11):2278\u20132324, November", "citeRegEx": "112", "shortCiteRegEx": null, "year": 1998}, {"title": "Deep learning", "author": ["Y. LeCun", "Y. Bengio", "G. Hinton"], "venue": "Nature, 521(7553):436\u2013444, May", "citeRegEx": "113", "shortCiteRegEx": null, "year": 2015}, {"title": "Recursive Training of 2d-3d Convolutional Networks for Neuronal Boundary Detection", "author": ["K. Lee", "A. Zlateski", "A. Vishwanathan", "H.S. Seung"], "venue": "arXiv:1508.04843 [cs], August", "citeRegEx": "114", "shortCiteRegEx": null, "year": 2015}, {"title": "Opinion: Reproducible research can still be wrong: Adopting a prevention approach", "author": ["J.T. Leek", "R.D. Peng"], "venue": "Proceedings of the National Academy of Sciences, 112(6):1645\u20131646, October", "citeRegEx": "115", "shortCiteRegEx": null, "year": 2015}, {"title": "A review of 3d vessel lumen segmentation techniques: Models, features and extraction schemes", "author": ["D. Lesage", "E.D. Angelini", "I. Bloch", "G. Funka-Lea"], "venue": "Medical Image Analysis, 13(6):819\u2013845, December", "citeRegEx": "116", "shortCiteRegEx": null, "year": 2009}, {"title": "Mesh Processing in Medical-Image Analysis&# x2014; a Tutorial", "author": ["J.A. Levine", "R.R. Paulsen", "Y. Zhang"], "venue": "IEEE computer graphics and applications, (5):22\u201328,", "citeRegEx": "117", "shortCiteRegEx": null, "year": 2012}, {"title": "Metadata management for high content screening in OMERO", "author": ["S. Li", "S. Besson", "C. Blackburn", "M. Carroll", "R.K. Ferguson"], "venue": null, "citeRegEx": "118", "shortCiteRegEx": "118", "year": 2015}, {"title": "Efficient piecewise training of deep structured models for semantic segmentation", "author": ["G. Lin", "C. Shen", "I. Reid", "A. v. d. Hengel"], "venue": "[cs],", "citeRegEx": "119", "shortCiteRegEx": "119", "year": 2015}, {"title": "Network In Network", "author": ["M. Lin", "Q. Chen", "S. Yan"], "venue": "arXiv:1312.4400 [cs], December", "citeRegEx": "120", "shortCiteRegEx": null, "year": 2013}, {"title": "Cerebral microvascular network geometry changes in response to functional stimulation", "author": ["L. Lindvere", "R. Janik", "A. Dorr", "D. Chartash", "B. Sahota"], "venue": null, "citeRegEx": "121", "shortCiteRegEx": "121", "year": 2013}, {"title": "Metadata matters: access to image data in the real world", "author": ["M. Linkert", "C.T. Rueden", "C. Allan", "J.-M. Burel", "W. Moore"], "venue": "The Journal of Cell Biology,", "citeRegEx": "122", "shortCiteRegEx": "122", "year": 2010}, {"title": "A modular hierarchical approach to 3d electron microscopy image segmentation", "author": ["T. Liu", "C. Jones", "M. Seyedhosseini", "T. Tasdizen"], "venue": "Journal of Neuroscience Methods, 226:88\u2013102, April", "citeRegEx": "123", "shortCiteRegEx": null, "year": 2014}, {"title": "Annotated highthroughput microscopy image sets for validation", "author": ["V. Ljosa", "K.L. Sokolnicki", "A.E. Carpenter"], "venue": "Nature Methods, 9(7):637\u2013637, June 2012. URL: http://dx.doi.org/10.1038/nmeth.", "citeRegEx": "124", "shortCiteRegEx": null, "year": 2083}, {"title": "Fully Convolutional Networks for Semantic Segmentation", "author": ["J. Long", "E. Shelhamer", "T. Darrell"], "venue": "arXiv:1411.4038 [cs], November", "citeRegEx": "125", "shortCiteRegEx": null, "year": 2014}, {"title": "Marching Cubes: A High Resolution 3d Surface Construction Algorithm", "author": ["W.E. Lorensen", "H.E. Cline"], "venue": "Proceedings of the 14th Annual Conference on Computer Graphics and Interactive Techniques, SIGGRAPH \u201987, pages 163\u2013169, New York, NY, USA,", "citeRegEx": "126", "shortCiteRegEx": null, "year": 1987}, {"title": "Supervoxel- Based Segmentation of Mitochondria in EM Image Stacks With Learned Shape Features", "author": ["A. Lucchi", "K. Smith", "R. Achanta", "G. Knott", "P. Fua"], "venue": "IEEE Transactions on Medical Imaging, 31(2):474\u2013486, February", "citeRegEx": "127", "shortCiteRegEx": null, "year": 2012}, {"title": "Image Denoising in Mixed Poisson-Gaussian Noise", "author": ["F. Luisier", "T. Blu", "M. Unser"], "venue": "IEEE Transactions on Image Processing, 20(3):696\u2013708, March", "citeRegEx": "128", "shortCiteRegEx": null, "year": 2011}, {"title": "An Ensemble of 2d Convolutional Neural Networks for Tumor Segmentation", "author": ["M. Lyksborg", "O. Puonti", "M. Agn", "R. Larsen"], "venue": "R. R. Paulsen and K. S. Pedersen, editors, Image Analysis, number 9127 in Lecture Notes in Computer Science, pages 201\u2013211. Springer International Publishing, June", "citeRegEx": "129", "shortCiteRegEx": null, "year": 2015}, {"title": "Improving Semi-Supervised Learning with Auxiliary Deep Generative Models", "author": ["L. Maal\u00f8e", "C.K. S\u00f8nderby", "S.K. S\u00f8nderby", "O. Winther"], "venue": "NIPS Workshop on Advances in Approximate Bayesian Inference,", "citeRegEx": "130", "shortCiteRegEx": null, "year": 2015}, {"title": "Weak Sinusoidal Electric Fields Entrain Spontaneous Ca Transients in the Dendritic Tufts of CA1 Pyramidal Cells in Rat Hippocampal Slice Preparations", "author": ["K. Maeda", "R. Maruyama", "T. Nagae", "M. Inoue", "T. Aonishi"], "venue": "PLoS ONE,", "citeRegEx": "131", "shortCiteRegEx": "131", "year": 2015}, {"title": "Nonlocal Transform-Domain Filter for Volumetric Data Denoising and Reconstruction", "author": ["M. Maggioni", "V. Katkovnik", "K. Egiazarian", "A. Foi"], "venue": "IEEE Transactions on Image Processing, 22(1):119\u2013 133, January", "citeRegEx": "132", "shortCiteRegEx": null, "year": 2013}, {"title": "Combinatorial Energy Learning for Image Segmentation", "author": ["J. Maitin-Shepard", "V. Jain", "M. Januszewski", "P. Li", "J. Kornfeld"], "venue": "[cs],", "citeRegEx": "133", "shortCiteRegEx": "133", "year": 2015}, {"title": "Ensemble of Deep Convolutional Neural Networks for Learning to Detect Retinal Vessels in Fundus Images", "author": ["D. Maji", "A. Santara", "P. Mitra", "D. Sheet"], "venue": "arXiv preprint arXiv:1603.04833,", "citeRegEx": "134", "shortCiteRegEx": null, "year": 2016}, {"title": "Optimal Inversion of the Anscombe Transformation in Low-Count Poisson Image Denoising", "author": ["M. Makitalo", "A. Foi"], "venue": "IEEE Transactions on Image Processing, 20(1):99\u2013109, January", "citeRegEx": "135", "shortCiteRegEx": null, "year": 2011}, {"title": "Vessel enhancing diffusion: A scale space representation of vessel structures", "author": ["R. Manniesing", "M.A. Viergever", "W.J. Niessen"], "venue": "Medical Image Analysis, 10(6):815\u2013825, December", "citeRegEx": "136", "shortCiteRegEx": null, "year": 2006}, {"title": "A fast learning algorithm for image segmentation with max-pooling convolutional networks", "author": ["J. Masci", "A. Giusti", "D. Ciresan", "G. Fricout", "J. Schmidhuber"], "venue": "2013 20th IEEE International Conference on Image Processing (ICIP), pages 2713\u20132717, September", "citeRegEx": "137", "shortCiteRegEx": null, "year": 2013}, {"title": "A constrained independent component analysis technique for artery\u2013vein separation of two-photon laser scanning microscopy images of the cerebral microvasculature", "author": ["H. Mehrabian", "L. Lindvere", "B. Stefanovic", "A.L. Martel"], "venue": "Medical Image Analysis, 16(1):239\u2013251, January", "citeRegEx": "138", "shortCiteRegEx": null, "year": 2012}, {"title": "Evaluation of Diffusion Techniques for Improved Vessel Visualization and Quantification in Three-Dimensional Rotational Angiography", "author": ["E. Meijering", "W. Niessen", "J. Weickert", "M. Viergever"], "venue": "W. J. Niessen and M. A. Viergever, editors, Medical Image Computing and Computer-Assisted Intervention \u2013 MIC- CAI 2001, number 2208 in Lecture Notes in Computer Science, pages 177\u2013185. Springer Berlin Heidelberg, October", "citeRegEx": "139", "shortCiteRegEx": null, "year": 2001}, {"title": "Altered morphology and 3d architecture of brain vasculature in a mouse model for Alzheimer\u2019s disease", "author": ["E.P. Meyer", "A. Ulmann-Schuler", "M. Staufenbiel", "T. Krucker"], "venue": "Proceedings of the National Academy of Sciences, 105(9):3587\u20133592, April", "citeRegEx": "140", "shortCiteRegEx": null, "year": 2008}, {"title": "Image Reconstruction for Fluorescence Microscopy", "author": ["P.P. Mondal", "A. Diaspro"], "venue": "Fundamentals of Fluorescence Microscopy, pages 189\u2013202. Springer Netherlands,", "citeRegEx": "141", "shortCiteRegEx": null, "year": 2014}, {"title": "OMERO and Bio-Formats 5: flexible access to large bioimaging datasets at scale", "author": ["J. Moore", "M. Linkert", "C. Blackburn", "M. Carroll", "R.K. Ferguson"], "venue": null, "citeRegEx": "142", "shortCiteRegEx": "142", "year": 2015}, {"title": "Manipulating neuronal activity in the mouse brain with ultrasound: A comparison with optogenetic activation of the cerebral cortex", "author": ["M.E. Moore", "J.M. Loft", "W.C. Clegern", "J.P. Wisor"], "venue": "Neuroscience Letters, 604:183\u2013187, September", "citeRegEx": "143", "shortCiteRegEx": null, "year": 2015}, {"title": "Gradient-based enhancement of tubular structures in medical images", "author": ["R. Moreno", "\u00d6. Smedby"], "venue": "Medical Image Analysis, 26(1):19\u201329, December", "citeRegEx": "144", "shortCiteRegEx": null, "year": 2015}, {"title": "High quality surface reconstruction in radiotherapy: Cross-sectional contours to 3d mesh using wavelets", "author": ["S. Moriconi", "E. Scalco", "S. Broggi", "B. Avuzzi", "R. Valdagni"], "venue": "In 2015 37th Annual International Conference of the IEEE Engineering in Medicine and Biology Society (EMBC),", "citeRegEx": "145", "shortCiteRegEx": "145", "year": 2015}, {"title": "Active Learning for Delineation of Curvilinear Structures", "author": ["A. Mosinska", "R. Sznitman", "P. G\u0142owacki", "P. Fua"], "venue": "arXiv:1512.00747 [cs], December", "citeRegEx": "146", "shortCiteRegEx": null, "year": 2015}, {"title": "FocusStack and StimServer: a new open source MATLAB toolchain for visual stimulation and analysis of two-photon calcium neuronal imaging data", "author": ["D.R. Muir", "B. Kampa"], "venue": "Frontiers in Neuroinformatics, 8:85,", "citeRegEx": "147", "shortCiteRegEx": null, "year": 2015}, {"title": "Automated Analysis of Cellular Signals from Large-Scale Calcium Imaging Data", "author": ["E.A. Mukamel", "A. Nimmerjahn", "M.J. Schnitzer"], "venue": "Neuron, 63(6):747\u2013760, September", "citeRegEx": "148", "shortCiteRegEx": null, "year": 2009}, {"title": "Rectified linear units improve restricted boltzmann machines", "author": ["V. Nair", "G.E. Hinton"], "venue": "Proceedings of the 27th International Conference on Machine Learning (ICML-10), pages 807\u2013 814,", "citeRegEx": "149", "shortCiteRegEx": null, "year": 2010}, {"title": "Testing Foundations of Biological Scaling Theory Using Automated Measurements of Vascular Networks", "author": ["M.G. Newberry", "D.B. Ennis", "V.M. Savage"], "venue": "PLoS Comput Biol, 11(8):e1004455, August", "citeRegEx": "150", "shortCiteRegEx": null, "year": 2015}, {"title": "Drug delivery to the brain by focused ultrasound induced blood\u2013brain barrier disruption: Quantitative evaluation of enhanced permeability of cerebral vasculature using two-photon microscopy", "author": ["T. Nhan", "A. Burgess", "E.E. Cho", "B. Stefanovic", "L. Lilge"], "venue": "Journal of Controlled Release,", "citeRegEx": "151", "shortCiteRegEx": "151", "year": 2013}, {"title": "Machine learning of hierarchical clustering to segment 2d and 3d images", "author": ["J. Nunez-Iglesias", "R. Kennedy", "T. Parag", "J. Shi", "D.B. Chklovskii"], "venue": "PloS One, 8(8):e71715,", "citeRegEx": "152", "shortCiteRegEx": null, "year": 2013}, {"title": "New red-fluorescent calcium indicators for optogenetics, photoactivation and multi-color imaging", "author": ["M. Oheim", "M. van \u2019t Hoff", "A. Feltz", "A. Zamaleeva", "J.-M. Mallet"], "venue": "Biochimica et Biophysica Acta (BBA) - Molecular Cell Research,", "citeRegEx": "153", "shortCiteRegEx": "153", "year": 2014}, {"title": "The top ten causes of death-Fact sheet N310", "author": ["W.H. Organization"], "venue": "World Health Organization, Geneva,", "citeRegEx": "154", "shortCiteRegEx": null, "year": 2008}, {"title": "Weaklyand Semi-Supervised Learning of a DCNN for Semantic Image Segmentation", "author": ["G. Papandreou", "L.-C. Chen", "K. Murphy", "A.L. Yuille"], "venue": "arxiv:1502.02734,", "citeRegEx": "155", "shortCiteRegEx": null, "year": 2015}, {"title": "Automated quantification of neuronal networks and single-cell calcium dynamics using calcium imaging", "author": ["T.P. Patel", "K. Man", "B.L. Firestein", "D.F. Meaney"], "venue": "Journal of Neuroscience Methods, 243:26\u201338, March", "citeRegEx": "156", "shortCiteRegEx": null, "year": 2015}, {"title": "Learning to Learn, from Transfer Learning to Domain Adaptation: A Unifying Perspective", "author": ["N. Patricia", "B. Caputo"], "venue": "2014 IEEE Conference on Computer Vision and Pattern Recognition (CVPR), pages 1442\u20131449, June", "citeRegEx": "157", "shortCiteRegEx": null, "year": 2014}, {"title": "Predicting Alzheimer\u2019s disease: a neuroimaging study with 3d convolutional neural networks", "author": ["A. Payan", "G. Montana"], "venue": "arXiv:1502.02506 [cs, stat], February", "citeRegEx": "158", "shortCiteRegEx": null, "year": 2015}, {"title": "From DIADEM to BigNeuron", "author": ["H. Peng", "E. Meijering", "G.A. Ascoli"], "venue": "Neuroinformatics, 13(3):259\u2013260, April", "citeRegEx": "159", "shortCiteRegEx": null, "year": 2015}, {"title": "Enhancing 3-D cell structures in confocal and STED microscopy: a joint model for interpolation, deblurring and anisotropic smoothing", "author": ["N. Persch", "A. Elhayek", "M. Welk", "A. Bruhn", "S. Grewenig"], "venue": "Measurement Science and Technology,", "citeRegEx": "160", "shortCiteRegEx": "160", "year": 2013}, {"title": "Tools and techniques for computational reproducibility", "author": ["S.R. Piccolo", "A.B. Lee", "M.B. Frampton"], "venue": "bioRxiv, page 022707, July", "citeRegEx": "161", "shortCiteRegEx": null, "year": 2015}, {"title": "In vivo imaging of human retinal microvasculature using adaptive optics scanning light ophthalmoscope fluorescein angiography", "author": ["A. Pinhas", "M. Dubow", "N. Shah", "T.Y. Chui", "D. Scoles"], "venue": "Biomedical Optics Express,", "citeRegEx": "162", "shortCiteRegEx": "162", "year": 2013}, {"title": "Recurrent Convolutional Neural Networks for Scene Parsing", "author": ["P.H.O. Pinheiro", "R. Collobert"], "venue": "arXiv:1306.2795 [cs], June", "citeRegEx": "163", "shortCiteRegEx": null, "year": 2013}, {"title": "Analyzing noise in autoencoders and deep networks", "author": ["B. Poole", "J. Sohl-Dickstein", "S. Ganguli"], "venue": "arXiv:1406.1831 [cs], June", "citeRegEx": "164", "shortCiteRegEx": null, "year": 2014}, {"title": "Multiscale tensor anisotropic filtering of fluorescence microscopy for denoising microvasculature", "author": ["V. Prasath", "R. Pelapur", "O. Glinskii", "V. Glinsky", "V. Huxley"], "venue": "In IEEE ISBI,", "citeRegEx": "165", "shortCiteRegEx": "165", "year": 2015}, {"title": "Driverseat: Crowdstrapping Learning Tasks for Autonomous Driving", "author": ["P. Rajpurkar", "T. Migimatsu", "J. Kiske", "R. Cheng-Yue", "S. Tandon"], "venue": "[cs],", "citeRegEx": "166", "shortCiteRegEx": "166", "year": 2015}, {"title": "TensorFlow: Biology\u2019s Gateway to Deep Learning", "author": ["L. Rampasek", "A. Goldenberg"], "venue": "Cell Systems,", "citeRegEx": "167", "shortCiteRegEx": "167", "year": 2016}, {"title": "Semi-supervised Learning with Ladder Networks", "author": ["A. Rasmus", "M. Berglund", "M. Honkala", "H. Valpola", "T. Raiko"], "venue": "C. Cortes, N. D. Lawrence, D. D. Lee, M. Sugiyama, R. Garnett et al., editors, Advances in Neural Information Processing Systems 28, pages 3532\u20133540. Curran Associates, Inc.,", "citeRegEx": "168", "shortCiteRegEx": null, "year": 2015}, {"title": "On measuring the change in size of pulmonary nodules", "author": ["A. Reeves", "A. Chan", "D. Yankelevitz", "C. Henschke", "B. Kressler"], "venue": "IEEE Transactions on Medical Imaging,", "citeRegEx": "169", "shortCiteRegEx": "169", "year": 2006}, {"title": "Accurate and Efficient Linear Structure Segmentation by Leveraging Ad Hoc Features with Learned Filters", "author": ["R. Rigamonti", "V. Lepetit"], "venue": "N. Ayache, H. Delingette, P. Golland, and K. Mori, editors, Medical Image Computing and Computer-Assisted Intervention \u2013 MICCAI 2012, number 7510 in Lecture Notes in Computer Science, pages 189\u2013197. Springer Berlin Heidelberg, October", "citeRegEx": "170", "shortCiteRegEx": null, "year": 2012}, {"title": "Spectral Representations for Convolutional Neural Networks", "author": ["O. Rippel", "J. Snoek", "R.P. Adams"], "venue": "C. Cortes, N. D. Lawrence, D. D. Lee, M. Sugiyama, R. Garnett et al., editors, Advances in Neural Information Processing Systems 28, pages 2440\u20132448. Curran Associates, Inc.,", "citeRegEx": "171", "shortCiteRegEx": null, "year": 2015}, {"title": "Neural networks and brain function", "author": ["E.T. Rolls", "A. Treves", "E.T. Rolls"], "venue": "Oxford university press Oxford,", "citeRegEx": "172", "shortCiteRegEx": null, "year": 1998}, {"title": "U-Net: Convolutional Networks for Biomedical Image Segmentation", "author": ["O. Ronneberger", "P. Fischer", "T. Brox"], "venue": "arXiv:1505.04597 [cs], May", "citeRegEx": "173", "shortCiteRegEx": null, "year": 2015}, {"title": "Neural networks in the future of neuroscience research", "author": ["M. Rubinov"], "venue": "Nature Reviews Neuroscience, advance online publication, October", "citeRegEx": "174", "shortCiteRegEx": null, "year": 2015}, {"title": "Comparing algorithms for automated vessel segmentation in computed tomography scans of the lung: the VESSEL12 study", "author": ["R.D. Rudyanto", "S. Kerkstra", "E.M. van Rikxoort", "C. Fetita", "P.-Y. Brillet"], "venue": "Medical Image Analysis,", "citeRegEx": "175", "shortCiteRegEx": "175", "year": 2014}, {"title": "ImageNet Large Scale Visual Recognition Challenge", "author": ["O. Russakovsky", "J. Deng", "H. Su", "J. Krause", "S. Satheesh"], "venue": "[cs],", "citeRegEx": "176", "shortCiteRegEx": "176", "year": 2014}, {"title": "Digital Topology and Geometry in Medical Imaging: A Survey", "author": ["P. Saha", "R. Strand", "G. Borgefors"], "venue": "IEEE Transactions on Medical Imaging, 34(9):1940\u20131964, September", "citeRegEx": "177", "shortCiteRegEx": null, "year": 2015}, {"title": "Automatic Centerline Extraction of Irregular Tubular Structures Using Probability Volumes from Multiphoton Imaging", "author": ["A. Santamar\u00eda-Pang", "C.M. Colbert", "P. Saggau", "I.A. Kakadiaris"], "venue": "N. Ayache, S. Ourselin, and A. Maeder, editors, Medical Image Computing and Computer-Assisted Intervention \u2013 MICCAI 2007, number 4792 in Lecture Notes in Computer Science, pages 486\u2013494. Springer Berlin Heidelberg, October", "citeRegEx": "178", "shortCiteRegEx": null, "year": 2007}, {"title": "Automatic Morphological Reconstruction of Neurons from Multiphoton and Confocal Microscopy Images Using 3d Tubular Models", "author": ["A. Santamar\u00eda-Pang", "P. Hernandez-Herrera", "M. Papadakis", "P. Saggau", "I.A. Kakadiaris"], "venue": "Neuroinformatics, 13(3):297\u2013320, January", "citeRegEx": "179", "shortCiteRegEx": null, "year": 2015}, {"title": "3d multi-scale line filter for segmentation and visualization of curvilinear structures in medical images", "author": ["Y. Sato", "S. Nakajima", "H. Atsumi", "T. Koller", "G. Gerig"], "venue": "Lecture Notes in Computer Science,", "citeRegEx": "180", "shortCiteRegEx": "180", "year": 1997}, {"title": "Standardized evaluation methodology and reference database for evaluating coronary artery centerline extraction algorithms", "author": ["M. Schaap", "C.T. Metz", "T. van Walsum", "A.G. van der Giessen", "A.C. Weustink"], "venue": "Medical Image Analysis,", "citeRegEx": "181", "shortCiteRegEx": "181", "year": 2009}, {"title": "The ImageJ ecosystem: An open platform for biomedical image analysis", "author": ["J. Schindelin", "C.T. Rueden", "M.C. Hiner", "K.W. Eliceiri"], "venue": "Molecular Reproduction and Development, 82(7-8):518\u2013529, July", "citeRegEx": "182", "shortCiteRegEx": null, "year": 2015}, {"title": "Predicting Semantic Descriptions from Medical Images with Convolutional Neural Networks", "author": ["T. Schlegl", "S.M. Waldstein", "W.-D. Vogl", "U. Schmidt-Erfurth", "G. Langs"], "venue": "S. Ourselin, D. C. Alexander, C.-F. Westin, and M. J. Cardoso, editors, Information Processing in Medical Imaging, number 9123 in Lecture Notes in Computer Science, pages 437\u2013448. Springer International Publishing, June", "citeRegEx": "183", "shortCiteRegEx": null, "year": 2015}, {"title": "Deep learning in neural networks: An overview", "author": ["J. Schmidhuber"], "venue": "Neural Networks, 61:85\u2013117, January", "citeRegEx": "184", "shortCiteRegEx": null, "year": 2015}, {"title": "Joint 3-D vessel segmentation and centerline extraction using oblique Hough forests with steerable filters", "author": ["M. Schneider", "S. Hirsch", "B. Weber", "G. Sz\u00e9kely", "B.H. Menze"], "venue": "Medical Image Analysis, 19(1):220\u2013249, January", "citeRegEx": "185", "shortCiteRegEx": null, "year": 2015}, {"title": "Less is more: Active learning with support vector machines", "author": ["G. Schohn", "D. Cohn"], "venue": "ICML, pages 839\u2013846. Citeseer,", "citeRegEx": "186", "shortCiteRegEx": null, "year": 2000}, {"title": "A vascular perspective on neuronal migration", "author": ["M. Segarra", "B.C. Kirchmaier", "A. Acker-Palmer"], "venue": "Mechanisms of Development, 138, Part 1:17\u201325, November", "citeRegEx": "187", "shortCiteRegEx": null, "year": 2015}, {"title": "OverFeat: Integrated Recognition, Localization and Detection using Convolutional Networks", "author": ["P. Sermanet", "D. Eigen", "X. Zhang", "M. Mathieu", "R. Fergus"], "venue": "[cs],", "citeRegEx": "188", "shortCiteRegEx": "188", "year": 2013}, {"title": "Active learning literature survey", "author": ["B. Settles"], "venue": "University of Wisconsin, Madison, 52(55-66):11,", "citeRegEx": "189", "shortCiteRegEx": null, "year": 2010}, {"title": "An artery-specific fluorescent dye for studying neurovascular coupling", "author": ["Z. Shen", "Z. Lu", "P.Y. Chhatbar", "P. O\u2019Herron", "P. Kara"], "venue": "Nature Methods,", "citeRegEx": "190", "shortCiteRegEx": "190", "year": 2012}, {"title": "Robust and Fragile Aspects of Cortical Blood Flow in Relation to the Underlying Angioarchitecture", "author": ["A.Y. Shih", "C. R\u00fchlmann", "P. Blinder", "A. Devor", "P.J. Drew"], "venue": "URL: http://dx.doi.org/10.1111/micc.12195", "citeRegEx": "191", "shortCiteRegEx": "191", "year": 2015}, {"title": "Interleaved Text/Image Deep Mining on a Large-Scale Radiology Database for Automated Image Interpretation", "author": ["H.-C. Shin", "L. Lu", "L. Kim", "A. Seff", "J. Yao"], "venue": "[cs],", "citeRegEx": "192", "shortCiteRegEx": "192", "year": 2015}, {"title": "Stacked Autoencoders for Unsupervised Feature Learning and Multiple Organ Detection in a Pilot Study Using 4d Patient Data", "author": ["H.-C. Shin", "M. Orton", "D. Collins", "S. Doran", "M. Leach"], "venue": "IEEE Transactions on Pattern Analysis and Machine Intelligence, 35(8):1930\u20131943, August", "citeRegEx": "193", "shortCiteRegEx": null, "year": 2013}, {"title": "Correlative two-photon and light sheet microscopy", "author": ["L. Silvestri", "A.L. Allegra Mascaro", "I. Costantini", "L. Sacconi", "F.S. Pavone"], "venue": "Methods, 66(2):268\u2013272, March", "citeRegEx": "194", "shortCiteRegEx": null, "year": 2014}, {"title": "Natural image statistics and neural representation", "author": ["E.P. Simoncelli", "B.A. Olshausen"], "venue": "Annual Review of Neuroscience, 24:1193\u2013 1216, 2001. URL: http://dx.doi.org/10.1146/annurev.neuro.24.1.", "citeRegEx": "195", "shortCiteRegEx": null, "year": 1193}, {"title": "Learning Separable Filters", "author": ["A. Sironi", "B. Tekin", "R. Rigamonti", "V. Lepetit", "P. Fua"], "venue": "IEEE Transactions on Pattern Analysis and Machine Intelligence, 37(1):94\u2013106, January", "citeRegEx": "196", "shortCiteRegEx": null, "year": 2015}, {"title": "Projection onto the Manifold of Elongated Structures for Accurate Extraction", "author": ["A. Sironi", "V. Lepetit", "P. Fua"], "venue": "Proceedings of the IEEE International Conference on Computer Vision, pages 316\u2013324,", "citeRegEx": "197", "shortCiteRegEx": null, "year": 2015}, {"title": "GPU accelerated segmentation and centerline extraction of tubular structures from medical images", "author": ["E. Smistad", "A.C. Elster", "F. Lindseth"], "venue": "International Journal of Computer Assisted Radiology and Surgery, 9(4):561\u2013575, November", "citeRegEx": "198", "shortCiteRegEx": null, "year": 2013}, {"title": "Bioimaging: Second window for in vivo imaging", "author": ["A.M. Smith", "M.C. Mancini", "S. Nie"], "venue": "Nature Nanotechnology, 4(11):710\u2013 711, November", "citeRegEx": "199", "shortCiteRegEx": null, "year": 2009}, {"title": "Automated Filtering of Intrinsic Movement Artifacts during Two-Photon Intravital Microscopy", "author": ["D. Soulet", "A. Par\u00e9", "J. Coste", "S. Lacroix"], "venue": "PLoS ONE, 8(1):e53942, January", "citeRegEx": "200", "shortCiteRegEx": null, "year": 2013}, {"title": "Retinal vascular layers imaged by fluorescein angiography and optical coherence tomography angiography", "author": ["R.F. Spaide", "J.M. Klancnik", "M.J. Cooney"], "venue": "JAMA ophthalmology, 133(1):45\u201350,", "citeRegEx": "201", "shortCiteRegEx": null, "year": 2015}, {"title": "Dropout: A Simple Way to Prevent Neural Networks from Overfitting", "author": ["N. Srivastava", "G. Hinton", "A. Krizhevsky", "I. Sutskever", "R. Salakhutdinov"], "venue": "J. Mach. Learn. Res., 15(1):1929\u20131958, January", "citeRegEx": "202", "shortCiteRegEx": null, "year": 2014}, {"title": "Ridge based vessel segmentation in color images of the retina", "author": ["J.J. Staal", "M.D. Abramoff", "M. Niemeijer", "M.A. Viergever", "B. v. Ginneken"], "venue": "IEEE Transactions on Medical Imaging,", "citeRegEx": "203", "shortCiteRegEx": "203", "year": 2004}, {"title": "Deep Feature Learning for EEG Recordings", "author": ["S. Stober", "A. Sternin", "A.M. Owen", "J.A. Grahn"], "venue": "arXiv:1511.04306 [cs], November", "citeRegEx": "204", "shortCiteRegEx": null, "year": 2015}, {"title": "Parallel Multi-Dimensional LSTM, With Application to Fast Biomedical Volumetric Image Segmentation", "author": ["M.F. Stollenga", "W. Byeon", "M. Liwicki", "J. Schmidhuber"], "venue": "arXiv:1506.07452 [cs], June", "citeRegEx": "205", "shortCiteRegEx": null, "year": 2015}, {"title": "Quantum dots spectrally distinguish multiple species within the tumor milieu in vivo", "author": ["M. Stroh", "J.P. Zimmer", "D.G. Duda", "T.S. Levchenko", "K.S. Cohen"], "venue": "Nature Medicine,", "citeRegEx": "206", "shortCiteRegEx": "206", "year": 2005}, {"title": "Deep Learning in Diagnosis of Brain Disorders", "author": ["H.-I. Suk", "D. Shen", "A.D.N. Initiative"], "venue": "S.-W. Lee, H. H. B\u00fclthoff, and K.-R. M\u00fcller, editors, Recent Progress in Brain and Cognitive Engineering, number 5 in Trends in Augmentation of Human Performance, pages 203\u2013213. Springer Netherlands,", "citeRegEx": "207", "shortCiteRegEx": null, "year": 2015}, {"title": "Automated computation of arbor densities: a step toward identifying neuronal cell types", "author": ["U. S\u00fcmb\u00fcl", "A. Zlateski", "A. Vishwanathan", "R.H. Masland", "H.S. Seung"], "venue": "Frontiers in Neuroanatomy, 8, November", "citeRegEx": "208", "shortCiteRegEx": null, "year": 2014}, {"title": "Learning a Convolutional Neural Network for Non-uniform Motion Blur Removal", "author": ["J. Sun", "W. Cao", "Z. Xu", "J. Ponce"], "venue": "arXiv:1503.00593 [cs], March", "citeRegEx": "209", "shortCiteRegEx": null, "year": 2015}, {"title": "Least Squares Support Vector Machine Classifiers", "author": ["J. a. K. Suykens", "J. Vandewalle"], "venue": "Neural Processing Letters,", "citeRegEx": "210", "shortCiteRegEx": "210", "year": 1999}, {"title": "Going Deeper with Convolutions", "author": ["C. Szegedy", "W. Liu", "Y. Jia", "P. Sermanet", "S. Reed"], "venue": "[cs],", "citeRegEx": "211", "shortCiteRegEx": "211", "year": 2014}, {"title": "Rethinking the Inception Architecture for Computer Vision", "author": ["C. Szegedy", "V. Vanhoucke", "S. Ioffe", "J. Shlens", "Z. Wojna"], "venue": "arXiv:1512.00567 [cs], December", "citeRegEx": "212", "shortCiteRegEx": null, "year": 2015}, {"title": "Metrics for evaluating 3d medical image segmentation: analysis, selection, and tool", "author": ["A.A. Taha", "A. Hanbury"], "venue": "BMC Medical Imaging, 15(1), December", "citeRegEx": "213", "shortCiteRegEx": null, "year": 2015}, {"title": "A visual motion detection circuit suggested by Drosophila", "author": ["S.-y. Takemura", "A. Bharioke", "Z. Lu", "A. Nern", "S. Vitaladevuni"], "venue": "connectomics. Nature,", "citeRegEx": "214", "shortCiteRegEx": "214", "year": 2013}, {"title": "Theano: A Python framework for fast computation of mathematical expressions", "author": ["T.T.D. Team", "R. Al-Rfou", "G. Alain", "A. Almahairi", "C. Angermueller"], "venue": "[cs],", "citeRegEx": "215", "shortCiteRegEx": "215", "year": 2016}, {"title": "Interpolation revisited [medical images application", "author": ["P. Thevenaz", "T. Blu", "M. Unser"], "venue": "IEEE Transactions on Medical Imaging, 19(7):739\u2013758, July", "citeRegEx": "216", "shortCiteRegEx": null, "year": 2000}, {"title": "Bilateral filtering for gray and color images", "author": ["C. Tomasi", "R. Manduchi"], "venue": "pages 839\u2013846,", "citeRegEx": "217", "shortCiteRegEx": null, "year": 1998}, {"title": "Two-Photon Processor and SeNeCA: a freely available software package to process data from two-photon calcium imaging at speeds down to several milliseconds per frame", "author": ["J. Tomek", "O. Novak", "J. Syka"], "venue": "Journal of Neurophysiology, 110(1):243\u2013256, July", "citeRegEx": "218", "shortCiteRegEx": null, "year": 2013}, {"title": "Acute two-photon imaging of the neurovascular unit in the cortex of active mice", "author": ["C.H.T. Tran", "G.R. Gordon"], "venue": "Frontiers in Cellular Neuroscience, 9:11,", "citeRegEx": "219", "shortCiteRegEx": null, "year": 2015}, {"title": "Learning Spatiotemporal Features With 3d Convolutional Networks", "author": ["D. Tran", "L. Bourdev", "R. Fergus", "L. Torresani", "M. Paluri"], "venue": "pages 4489\u20134497,", "citeRegEx": "220", "shortCiteRegEx": null, "year": 2015}, {"title": "Deep and fast live imaging with two-photon scanned lightsheet microscopy", "author": ["T.V. Truong", "W. Supatto", "D.S. Koos", "J.M. Choi", "S.E. Fraser"], "venue": "Nature Methods, 8(9):757\u2013760, September", "citeRegEx": "221", "shortCiteRegEx": null, "year": 2011}, {"title": "Correlations of Neuronal and Microvascular Densities in Murine Cortex Revealed by Direct Counting and Colocalization of Nuclei and Vessels", "author": ["P.S. Tsai", "J.P. Kaufhold", "P. Blinder", "B. Friedman", "P.J. Drew"], "venue": "The Journal of Neuroscience,", "citeRegEx": "222", "shortCiteRegEx": "222", "year": 2009}, {"title": "Auto-Context and Its Application to High-Level Vision Tasks and 3d Brain Image Segmentation", "author": ["Z. Tu", "X. Bai"], "venue": "IEEE Transactions on Pattern Analysis and Machine Intelligence, 32(10):1744\u2013 1757, October", "citeRegEx": "223", "shortCiteRegEx": null, "year": 2010}, {"title": "Ultrasonic neuromodulation by brain stimulation with transcranial ultrasound", "author": ["Y. Tufail", "A. Yoshihiro", "S. Pati", "M.M. Li", "W.J. Tyler"], "venue": "Nature Protocols, 6(9):1453\u20131470, September", "citeRegEx": "224", "shortCiteRegEx": null, "year": 2011}, {"title": "Maximin affinity learning of image segmentation", "author": ["S. Turaga", "K. Briggman", "M. Helmstaedter", "W. Denk", "H. Seung"], "venue": "Advances in Neural Information Processing Systems 22 (NIPS 2009), 22(2):6,", "citeRegEx": "225", "shortCiteRegEx": null, "year": 2009}, {"title": "Detecting Irregular Curvilinear Structures in Gray Scale and Color Imagery Using Multi-directional Oriented Flux", "author": ["E. T\u00fcretken", "C. Becker", "P. Glowacki", "F. Benmansour", "P. Fua"], "venue": "2013 IEEE International Conference on Computer Vision (ICCV), pages 1553\u2013 1560, December", "citeRegEx": "226", "shortCiteRegEx": null, "year": 2013}, {"title": "Automated reconstruction of tree structures using path classifiers and Mixed Integer Programming", "author": ["E. Turetken", "F. Benmansour", "P. Fua"], "venue": "2012 IEEE Conference on Computer Vision and Pattern Recognition (CVPR), pages 566\u2013573, June", "citeRegEx": "227", "shortCiteRegEx": null, "year": 2012}, {"title": "Carotid Multi-Region MRI Segmentation by Globally Optimal Evolution of Coupled Surfaces", "author": ["E. Ukwatta", "J. Yuan", "M. Rajchl", "W. Qiu", "D. Tessier"], "venue": "Medical Imaging, IEEE Transactions on,", "citeRegEx": "228", "shortCiteRegEx": "228", "year": 2013}, {"title": "From neural PCA to deep unsupervised learning", "author": ["H. Valpola"], "venue": "arXiv:1411.7783 [cs, stat], November", "citeRegEx": "229", "shortCiteRegEx": null, "year": 2014}, {"title": "Reproducible research in signal processing", "author": ["P. Vandewalle", "J. Kovacevic", "M. Vetterli"], "venue": "IEEE Signal Processing Magazine, 26(3):37\u2013 47, May", "citeRegEx": "230", "shortCiteRegEx": null, "year": 2009}, {"title": "Deep Gaussian Conditional Random Field Network: A Model-based Deep Network for Discriminative Denoising", "author": ["R. Vemulapalli", "O. Tuzel", "M.-Y. Liu"], "venue": "arXiv:1511.04067 [cs], November", "citeRegEx": "231", "shortCiteRegEx": null, "year": 2015}, {"title": "Machine Learning in Medicine: A Primer for Physicians", "author": ["A.K. Waljee", "P.D.R. Higgins"], "venue": "The American Journal of Gastroenterology, 105(6):1224\u20131226, June", "citeRegEx": "232", "shortCiteRegEx": null, "year": 2010}, {"title": "Quantum dots: bright and versatile in vitro and in vivo fluorescence imaging biosensors", "author": ["K.D. Wegner", "N. Hildebrandt"], "venue": "Chemical Society Reviews, 44(14):4792\u20134834, July", "citeRegEx": "233", "shortCiteRegEx": null, "year": 2015}, {"title": "Label-free live brain imaging and targeted patching with third-harmonic generation microscopy", "author": ["S. Witte", "A. Negrean", "J.C. Lodder", "C.P.J. de Kock", "G. Testa Silva"], "venue": "Proceedings of the National Academy of Sciences of the United States of America,", "citeRegEx": "234", "shortCiteRegEx": "234", "year": 2011}, {"title": "Automated Abdominal Multi-Organ Segmentation With Subject- Specific Atlas Generation", "author": ["R. Wolz", "C. Chu", "K. Misawa", "M. Fujiwara", "K. Mori"], "venue": "IEEE Transactions on Medical Imaging,", "citeRegEx": "235", "shortCiteRegEx": "235", "year": 2013}, {"title": "An Iterative Convolutional Neural Network Algorithm Improves Electron Microscopy Image Segmentation", "author": ["X. Wu"], "venue": "arXiv:1506.05849 [cs], June", "citeRegEx": "236", "shortCiteRegEx": null, "year": 2015}, {"title": "Hybrid CNN and Dictionary-Based Models for Scene Recognition and Domain Adaptation", "author": ["G.-S. Xie", "X.-Y. Zhang", "S. Yan", "C.-L. Liu"], "venue": "IEEE Transactions on Circuits and Systems for Video Technology, PP(99):1\u20131,", "citeRegEx": "237", "shortCiteRegEx": null, "year": 2015}, {"title": "Holistically-Nested Edge Detection", "author": ["S. Xie", "Z. Tu"], "venue": "arXiv:1504.06375 [cs], April", "citeRegEx": "238", "shortCiteRegEx": null, "year": 2015}, {"title": "Robust Surface Reconstruction via Dictionary Learning", "author": ["S. Xiong", "J. Zhang", "J. Zheng", "J. Cai", "L. Liu"], "venue": "ACM Trans. Graph., 33(6):201:1\u2013201:12, November", "citeRegEx": "239", "shortCiteRegEx": null, "year": 2014}, {"title": "Image Smoothing via L0 Gradient Minimization", "author": ["L. Xu", "C. Lu", "Y. Xu", "J. Jia"], "venue": "Proceedings of the 2011 SIGGRAPH Asia Conference, SA \u201911, pages 174:1\u2013174:12, New York, NY, USA,", "citeRegEx": "240", "shortCiteRegEx": null, "year": 2011}, {"title": "Deep Edge-Aware Filters", "author": ["L. Xu", "J. Ren", "Q. Yan", "R. Liao", "J. Jia"], "venue": "Proceedings of the 32nd International Conference on Machine Learning (ICML-15), pages 1669\u20131678,", "citeRegEx": "241", "shortCiteRegEx": null, "year": 2015}, {"title": "Deep Convolutional Neural Network for Image Deconvolution", "author": ["L. Xu", "J.S. Ren", "C. Liu", "J. Jia"], "venue": "Z. Ghahramani, M. Welling, C. Cortes, N. D. Lawrence, and K. Q. Weinberger, editors, Advances in Neural Information Processing Systems 27, pages 1790\u2013 1798. Curran Associates, Inc.,", "citeRegEx": "242", "shortCiteRegEx": null, "year": 2014}, {"title": "Describing Videos by Exploiting Temporal Structure", "author": ["L. Yao", "A. Torabi", "K. Cho", "N. Ballas", "C. Pal"], "venue": null, "citeRegEx": "243", "shortCiteRegEx": "243", "year": 2015}, {"title": "In vivo multi-photon luminescence imaging of cerebral vasculature and blood\u2013brain barrier integrity using gold nanoparticles", "author": ["H.-J. Yoon", "E.-S. Lee", "M. Kang", "Y. Jeong", "J.-H. Park"], "venue": "Journal of Materials Chemistry B, 3(15):2935\u20132938, April", "citeRegEx": "244", "shortCiteRegEx": null, "year": 2015}, {"title": "Stenosis map for volume visualization of constricted tubular structures: Application to coronary artery stenosis", "author": ["J. Yun", "Y.K. Kim", "E.J. Chun", "Y.-G. Shin", "J. Lee"], "venue": "Computer Methods and Programs in Biomedicine,", "citeRegEx": "245", "shortCiteRegEx": "245", "year": 2015}, {"title": "From the neuron doctrine to neural networks", "author": ["R. Yuste"], "venue": "Nature Reviews Neuroscience, 16(8):487\u2013497, August", "citeRegEx": "246", "shortCiteRegEx": null, "year": 2015}, {"title": "Stochastic Pooling for Regularization of Deep Convolutional Neural Networks", "author": ["M.D. Zeiler", "R. Fergus"], "venue": "arXiv:1301.3557 [cs, stat], January", "citeRegEx": "247", "shortCiteRegEx": null, "year": 2013}, {"title": "Deep Model Based Transfer and Multi-Task Learning for Biological Image Analysis", "author": ["W. Zhang", "R. Li", "T. Zeng", "Q. Sun", "S. Kumar"], "venue": "In Proceedings of the 21th ACM SIGKDD International Conference on Knowledge Discovery and Data Mining, KDD", "citeRegEx": "248", "shortCiteRegEx": "248", "year": 2015}, {"title": "A Reliable Distributed Convolutional Neural Network for Biology Image Segmentation", "author": ["X. Zhang", "G. Tan", "M. Chen"], "venue": "2015 15th IEEE/ACM International Symposium on Cluster, Cloud and Grid Computing (CCGrid), pages 777\u2013780, May", "citeRegEx": "249", "shortCiteRegEx": null, "year": 2015}, {"title": "Supervised Hashing with Deep Neural Networks", "author": ["Z. Zhang", "Y. Chen", "V. Saligrama"], "venue": "arXiv:1511.04524 [cs], November", "citeRegEx": "250", "shortCiteRegEx": null, "year": 2015}, {"title": "Multi-Scale Deep Networks and Regression Forests for Direct Bi-ventricular Volume Estimation", "author": ["X. Zhen", "Z. Wang", "A. Islam", "M. Bhaduri", "I. Chan"], "venue": "Medical Image Analysis,", "citeRegEx": "251", "shortCiteRegEx": "251", "year": 2015}, {"title": "3d Deep Learning for Efficient and Robust Landmark Detection in Volumetric Data", "author": ["Y. Zheng", "D. Liu", "B. Georgescu", "H. Nguyen", "D. Comaniciu"], "venue": "N. Navab, J. Hornegger, W. M. Wells, and A. F. Frangi, editors,Medical Image Computing and Computer-Assisted Intervention \u2013 MICCAI 2015, number 9349 in Lecture Notes in Computer Science, pages 565\u2013572. Springer International Publishing,", "citeRegEx": "252", "shortCiteRegEx": null, "year": 2015}, {"title": "ZNN - A Fast and Scalable Algorithm for Training 3d Convolutional Networks on Multi-Core and Many-Core Shared Memory Machines", "author": ["A. Zlateski", "K. Lee", "H.S. Seung"], "venue": "arXiv:1510.06706 [cs], October", "citeRegEx": "253", "shortCiteRegEx": null, "year": 2015}, {"title": "Image Segmentation by Size- Dependent Single Linkage Clustering of a Watershed Basin Graph", "author": ["A. Zlateski", "H.S. Seung"], "venue": "arXiv:1505.00249 [cs], May", "citeRegEx": "254", "shortCiteRegEx": null, "year": 2015}], "referenceMentions": [{"referenceID": 30, "context": "Quantitative analysis of brain vasculature is used in a variety of fields, including vascular development [32, 187, 150] and physiology [191], neurovascular coupling [222, 34], and blood-brain barrier studies [151, 18].", "startOffset": 106, "endOffset": 120}, {"referenceID": 185, "context": "Quantitative analysis of brain vasculature is used in a variety of fields, including vascular development [32, 187, 150] and physiology [191], neurovascular coupling [222, 34], and blood-brain barrier studies [151, 18].", "startOffset": 106, "endOffset": 120}, {"referenceID": 148, "context": "Quantitative analysis of brain vasculature is used in a variety of fields, including vascular development [32, 187, 150] and physiology [191], neurovascular coupling [222, 34], and blood-brain barrier studies [151, 18].", "startOffset": 106, "endOffset": 120}, {"referenceID": 189, "context": "Quantitative analysis of brain vasculature is used in a variety of fields, including vascular development [32, 187, 150] and physiology [191], neurovascular coupling [222, 34], and blood-brain barrier studies [151, 18].", "startOffset": 136, "endOffset": 141}, {"referenceID": 220, "context": "Quantitative analysis of brain vasculature is used in a variety of fields, including vascular development [32, 187, 150] and physiology [191], neurovascular coupling [222, 34], and blood-brain barrier studies [151, 18].", "startOffset": 166, "endOffset": 175}, {"referenceID": 32, "context": "Quantitative analysis of brain vasculature is used in a variety of fields, including vascular development [32, 187, 150] and physiology [191], neurovascular coupling [222, 34], and blood-brain barrier studies [151, 18].", "startOffset": 166, "endOffset": 175}, {"referenceID": 149, "context": "Quantitative analysis of brain vasculature is used in a variety of fields, including vascular development [32, 187, 150] and physiology [191], neurovascular coupling [222, 34], and blood-brain barrier studies [151, 18].", "startOffset": 209, "endOffset": 218}, {"referenceID": 16, "context": "Quantitative analysis of brain vasculature is used in a variety of fields, including vascular development [32, 187, 150] and physiology [191], neurovascular coupling [222, 34], and blood-brain barrier studies [151, 18].", "startOffset": 209, "endOffset": 218}, {"referenceID": 114, "context": "Clinically, quantitative analysis of vessels will assist in making diagnoses and planning surgeries [116, 175, 245].", "startOffset": 100, "endOffset": 115}, {"referenceID": 173, "context": "Clinically, quantitative analysis of vessels will assist in making diagnoses and planning surgeries [116, 175, 245].", "startOffset": 100, "endOffset": 115}, {"referenceID": 243, "context": "Clinically, quantitative analysis of vessels will assist in making diagnoses and planning surgeries [116, 175, 245].", "startOffset": 100, "endOffset": 115}, {"referenceID": 160, "context": "For example, retinal vasculature imaging [162, 201] allows inexpensive and fast screening of several eye-related and systematic pathologies such as glaucoma, age-related macular degeneration, diabetic retinopathy, hypertension, arteriosclerosis and Alzheimer\u2019s disease [75].", "startOffset": 41, "endOffset": 51}, {"referenceID": 199, "context": "For example, retinal vasculature imaging [162, 201] allows inexpensive and fast screening of several eye-related and systematic pathologies such as glaucoma, age-related macular degeneration, diabetic retinopathy, hypertension, arteriosclerosis and Alzheimer\u2019s disease [75].", "startOffset": 41, "endOffset": 51}, {"referenceID": 73, "context": "For example, retinal vasculature imaging [162, 201] allows inexpensive and fast screening of several eye-related and systematic pathologies such as glaucoma, age-related macular degeneration, diabetic retinopathy, hypertension, arteriosclerosis and Alzheimer\u2019s disease [75].", "startOffset": 269, "endOffset": 273}, {"referenceID": 167, "context": "Differentiating blood vessels from the surrounding tissue also allows more accurate analyses of extravascular structures, such as tumor volume quantification [169] and pulmonary lobes structural analysis [108].", "startOffset": 158, "endOffset": 163}, {"referenceID": 106, "context": "Differentiating blood vessels from the surrounding tissue also allows more accurate analyses of extravascular structures, such as tumor volume quantification [169] and pulmonary lobes structural analysis [108].", "startOffset": 204, "endOffset": 209}, {"referenceID": 152, "context": "Given that vascular diseases, such as coronary heart disease, are among the largest public health problems in developed countries [154], accurate and efficient image analysis will only become more relevant.", "startOffset": 130, "endOffset": 135}, {"referenceID": 152, "context": "[154].", "startOffset": 0, "endOffset": 5}, {"referenceID": 95, "context": "There have been various approaches for vessel segmentation (for reviews see [97, 116]), but to date, no single method have been able to successfully segment vessels from every imaging modality and every organ [175].", "startOffset": 76, "endOffset": 85}, {"referenceID": 114, "context": "There have been various approaches for vessel segmentation (for reviews see [97, 116]), but to date, no single method have been able to successfully segment vessels from every imaging modality and every organ [175].", "startOffset": 76, "endOffset": 85}, {"referenceID": 173, "context": "There have been various approaches for vessel segmentation (for reviews see [97, 116]), but to date, no single method have been able to successfully segment vessels from every imaging modality and every organ [175].", "startOffset": 209, "endOffset": 214}, {"referenceID": 72, "context": "Our group uses vessel segmentation for two purposes: 1) To analyze changes in vascular morphology after focused ultrasound mediated blood-brain barrier opening [74, 17], and 2) to observe tumor pathophysiology and drug kinetics following application of focused ultrasound stimulated microbubbles (unpublished).", "startOffset": 160, "endOffset": 168}, {"referenceID": 15, "context": "Our group uses vessel segmentation for two purposes: 1) To analyze changes in vascular morphology after focused ultrasound mediated blood-brain barrier opening [74, 17], and 2) to observe tumor pathophysiology and drug kinetics following application of focused ultrasound stimulated microbubbles (unpublished).", "startOffset": 160, "endOffset": 168}, {"referenceID": 149, "context": "We were motivated to improve our vessel segmentation pipelines from previous custom-written semiautomatic Matlab scripts [151], and labor-intensive manual approaches using commercial Imaris (Bitplane AG, Zurich,", "startOffset": 121, "endOffset": 126}, {"referenceID": 180, "context": "Switzerland) platform and open-source ImageJ/FIJI platform [182], to be more automatic and robust.", "startOffset": 59, "endOffset": 64}, {"referenceID": 26, "context": "Delineating blood vessels from the extravascular space enables quantification of the rate and duration of dye leakage, which can be correlated with kinetics and characteristics of bloodbrain barrier integrity [28, 151, 18].", "startOffset": 209, "endOffset": 222}, {"referenceID": 149, "context": "Delineating blood vessels from the extravascular space enables quantification of the rate and duration of dye leakage, which can be correlated with kinetics and characteristics of bloodbrain barrier integrity [28, 151, 18].", "startOffset": 209, "endOffset": 222}, {"referenceID": 16, "context": "Delineating blood vessels from the extravascular space enables quantification of the rate and duration of dye leakage, which can be correlated with kinetics and characteristics of bloodbrain barrier integrity [28, 151, 18].", "startOffset": 209, "endOffset": 222}, {"referenceID": 217, "context": "used vessel segmentation as an image processing tool to analyze other factors from two-photon datasets, including neurovascular coupling [219], neuronal calcium imaging [35, 131], and low-intensity focused ultrasound brain modulation paradigms [224, 19, 143].", "startOffset": 137, "endOffset": 142}, {"referenceID": 33, "context": "used vessel segmentation as an image processing tool to analyze other factors from two-photon datasets, including neurovascular coupling [219], neuronal calcium imaging [35, 131], and low-intensity focused ultrasound brain modulation paradigms [224, 19, 143].", "startOffset": 169, "endOffset": 178}, {"referenceID": 129, "context": "used vessel segmentation as an image processing tool to analyze other factors from two-photon datasets, including neurovascular coupling [219], neuronal calcium imaging [35, 131], and low-intensity focused ultrasound brain modulation paradigms [224, 19, 143].", "startOffset": 169, "endOffset": 178}, {"referenceID": 222, "context": "used vessel segmentation as an image processing tool to analyze other factors from two-photon datasets, including neurovascular coupling [219], neuronal calcium imaging [35, 131], and low-intensity focused ultrasound brain modulation paradigms [224, 19, 143].", "startOffset": 244, "endOffset": 258}, {"referenceID": 17, "context": "used vessel segmentation as an image processing tool to analyze other factors from two-photon datasets, including neurovascular coupling [219], neuronal calcium imaging [35, 131], and low-intensity focused ultrasound brain modulation paradigms [224, 19, 143].", "startOffset": 244, "endOffset": 258}, {"referenceID": 141, "context": "used vessel segmentation as an image processing tool to analyze other factors from two-photon datasets, including neurovascular coupling [219], neuronal calcium imaging [35, 131], and low-intensity focused ultrasound brain modulation paradigms [224, 19, 143].", "startOffset": 244, "endOffset": 258}, {"referenceID": 64, "context": "Two-photon microscopy, or more generally, multiphoton microscopy, has become the workhorse of neuronal imaging [66].", "startOffset": 111, "endOffset": 115}, {"referenceID": 219, "context": "Twophoton light-sheet imaging operates on a line or a plane basis instead of a point, speeding the volumetric imaging by one or two orders of magnitude if faster faster rates are needed [221].", "startOffset": 186, "endOffset": 191}, {"referenceID": 232, "context": "Additionally two-photon fluorescence imaging can be combined with other nonlinear processes such as with third-harmonic generation (THG) for label-free vascular imaging [234], and other microscopy techniques such as electron microscopy for more detailed analysis [12].", "startOffset": 169, "endOffset": 174}, {"referenceID": 10, "context": "Additionally two-photon fluorescence imaging can be combined with other nonlinear processes such as with third-harmonic generation (THG) for label-free vascular imaging [234], and other microscopy techniques such as electron microscopy for more detailed analysis [12].", "startOffset": 263, "endOffset": 267}, {"referenceID": 192, "context": "[194] for example integrate in vivo two-photon microscopy with ex vivo light sheet microscopy and use the major blood vessels as landmark points for registration.", "startOffset": 0, "endOffset": 5}, {"referenceID": 177, "context": "[179] on tubular 3D neuronal structures representing one of the few examples for \u201cmorphological\u201d multiphoton microscopy analysis, and Python-based VMTK ([4], http://www.", "startOffset": 0, "endOffset": 5}, {"referenceID": 146, "context": "[148, 218, 147, 156]).", "startOffset": 0, "endOffset": 20}, {"referenceID": 216, "context": "[148, 218, 147, 156]).", "startOffset": 0, "endOffset": 20}, {"referenceID": 145, "context": "[148, 218, 147, 156]).", "startOffset": 0, "endOffset": 20}, {"referenceID": 154, "context": "[148, 218, 147, 156]).", "startOffset": 0, "endOffset": 20}, {"referenceID": 95, "context": "Traditionally vessel segmentation have been done on some combination of vascular models, image features and extraction schemes often relying on prior knowledge about the tubularity of vessels [97, 116].", "startOffset": 192, "endOffset": 201}, {"referenceID": 114, "context": "Traditionally vessel segmentation have been done on some combination of vascular models, image features and extraction schemes often relying on prior knowledge about the tubularity of vessels [97, 116].", "startOffset": 192, "endOffset": 201}, {"referenceID": 173, "context": "org/ with only challenge (VESSEL12, [175]) devoted to vessel segmentation.", "startOffset": 36, "endOffset": 41}, {"referenceID": 45, "context": "It is common that many fields suffer from lack of annotated datasets [47] as they are expensive to generate such as is the case for example in high content screening (HCS) technologies labeled at cell level [102, 124], and in electron microscopy [5].", "startOffset": 69, "endOffset": 73}, {"referenceID": 100, "context": "It is common that many fields suffer from lack of annotated datasets [47] as they are expensive to generate such as is the case for example in high content screening (HCS) technologies labeled at cell level [102, 124], and in electron microscopy [5].", "startOffset": 207, "endOffset": 217}, {"referenceID": 122, "context": "It is common that many fields suffer from lack of annotated datasets [47] as they are expensive to generate such as is the case for example in high content screening (HCS) technologies labeled at cell level [102, 124], and in electron microscopy [5].", "startOffset": 207, "endOffset": 217}, {"referenceID": 3, "context": "It is common that many fields suffer from lack of annotated datasets [47] as they are expensive to generate such as is the case for example in high content screening (HCS) technologies labeled at cell level [102, 124], and in electron microscopy [5].", "startOffset": 246, "endOffset": 249}, {"referenceID": 179, "context": "Additional standardized datasets can be found for evaluating coronary artery centerline extraction algorithms [181], and for evaluating coronary artery stenosis detection, stenosis quantification and lumen segmentation algorithms in computed tomography angiography [98].", "startOffset": 110, "endOffset": 115}, {"referenceID": 96, "context": "Additional standardized datasets can be found for evaluating coronary artery centerline extraction algorithms [181], and for evaluating coronary artery stenosis detection, stenosis quantification and lumen segmentation algorithms in computed tomography angiography [98].", "startOffset": 265, "endOffset": 269}, {"referenceID": 201, "context": "The the most similar datasets can be found for example for twodimension retinal vessels in DRIVE dataset [203], and three-dimension tubular fibers in DIADEM challenge [16].", "startOffset": 105, "endOffset": 110}, {"referenceID": 14, "context": "The the most similar datasets can be found for example for twodimension retinal vessels in DRIVE dataset [203], and three-dimension tubular fibers in DIADEM challenge [16].", "startOffset": 167, "endOffset": 171}, {"referenceID": 174, "context": "One example of such challenge is the ImageNet Large Scale Visual Recognition Challenge (ILSVRC) challenge that is taking place annually with the same database of images [176].", "startOffset": 169, "endOffset": 174}, {"referenceID": 111, "context": "Majority of the emerged approaches have relied on deep learning networks [113, 184, 107] opposed to \u201ctraditional\u201d shallow networks [11].", "startOffset": 73, "endOffset": 88}, {"referenceID": 182, "context": "Majority of the emerged approaches have relied on deep learning networks [113, 184, 107] opposed to \u201ctraditional\u201d shallow networks [11].", "startOffset": 73, "endOffset": 88}, {"referenceID": 105, "context": "Majority of the emerged approaches have relied on deep learning networks [113, 184, 107] opposed to \u201ctraditional\u201d shallow networks [11].", "startOffset": 73, "endOffset": 88}, {"referenceID": 9, "context": "Majority of the emerged approaches have relied on deep learning networks [113, 184, 107] opposed to \u201ctraditional\u201d shallow networks [11].", "startOffset": 131, "endOffset": 135}, {"referenceID": 77, "context": "[79, 111]), the recent success had been due to the combination of bigger annotated datasets, more powerful hardware, new ideas, algorithms and improved network architectures enabling this sort of \u201cparadigm shift\u201d in machine learning.", "startOffset": 0, "endOffset": 9}, {"referenceID": 109, "context": "[79, 111]), the recent success had been due to the combination of bigger annotated datasets, more powerful hardware, new ideas, algorithms and improved network architectures enabling this sort of \u201cparadigm shift\u201d in machine learning.", "startOffset": 0, "endOffset": 9}, {"referenceID": 103, "context": "Since 2011, graphical processing unit (GPU)-based ConvNets have dominated classification ([105]), and segmentation contests ([30]).", "startOffset": 90, "endOffset": 95}, {"referenceID": 28, "context": "Since 2011, graphical processing unit (GPU)-based ConvNets have dominated classification ([105]), and segmentation contests ([30]).", "startOffset": 125, "endOffset": 129}, {"referenceID": 23, "context": "[25]) allowing hierarchical feature learning starting from low-level features such as edges into higher-level features such as faces for example.", "startOffset": 0, "endOffset": 4}, {"referenceID": 161, "context": "erties that make them useful in image analysis: spatially shared weights and spatial pooling ([163]).", "startOffset": 94, "endOffset": 99}, {"referenceID": 193, "context": "filter that is useful across the entire image as image statistics are stationary [195].", "startOffset": 81, "endOffset": 86}, {"referenceID": 58, "context": "probability distribution of the outputs [60].", "startOffset": 40, "endOffset": 44}, {"referenceID": 50, "context": "The shortcoming of softmax is that does not capture model uncertainty and often it is interpreted erroneously as model confidence [52].", "startOffset": 130, "endOffset": 134}, {"referenceID": 50, "context": "If model uncertainty is needed, there have been effort to cast deep learning models as Bayesian models[52].", "startOffset": 102, "endOffset": 106}, {"referenceID": 200, "context": "either using technique called DropOut [202] in which each neuron has a probability of 0.", "startOffset": 38, "endOffset": 43}, {"referenceID": 162, "context": "Alternatively one can regularize the network by injecting noise for example just before the nonlinear activation function [164].", "startOffset": 122, "endOffset": 127}, {"referenceID": 244, "context": "ConvNets can be roughly divided to two basic types [246]: feedforward networks which are organized in layers with unidirectional connections (e.", "startOffset": 51, "endOffset": 56}, {"referenceID": 112, "context": "[114]), and recurrent network in which feedback connectivity is dominant (e.", "startOffset": 0, "endOffset": 5}, {"referenceID": 161, "context": "[163] for semantic segmentation).", "startOffset": 0, "endOffset": 5}, {"referenceID": 58, "context": "[60]).", "startOffset": 0, "endOffset": 4}, {"referenceID": 7, "context": "disentangle the factors and causes it involves ([9]), or in more practical terms, to have an image segmentation system that would have an \u201cunderstanding\u201d of the vesselness.", "startOffset": 48, "endOffset": 51}, {"referenceID": 105, "context": "[107] from very limited training samples starting from just one examples.", "startOffset": 0, "endOffset": 5}, {"referenceID": 63, "context": "For \u201cbrute-force approaches\u201d, there have been ConvNets that have surpassed human-level performance on image classification [65, 77].", "startOffset": 123, "endOffset": 131}, {"referenceID": 75, "context": "For \u201cbrute-force approaches\u201d, there have been ConvNets that have surpassed human-level performance on image classification [65, 77].", "startOffset": 123, "endOffset": 131}, {"referenceID": 112, "context": "We have implemented our threedimension vessel segmentation using open-source CPUaccelerated ZNN framework [114, 254] previously used for three-dimensional electron microscope segmentation.", "startOffset": 106, "endOffset": 116}, {"referenceID": 252, "context": "We have implemented our threedimension vessel segmentation using open-source CPUaccelerated ZNN framework [114, 254] previously used for three-dimensional electron microscope segmentation.", "startOffset": 106, "endOffset": 116}, {"referenceID": 8, "context": "The image stacks suffer mainly from photon noise following a Poisson distribution [10] (i.", "startOffset": 82, "endOffset": 86}, {"referenceID": 126, "context": "PURE-LET [128]).", "startOffset": 9, "endOffset": 14}, {"referenceID": 133, "context": "Alternatively the signal-dependency of the Poisson noise can be removed with a suitable transform such as Anscombe transform [135] that allows one to use denoising methods developed for Gaussian noise (e.", "startOffset": 125, "endOffset": 130}, {"referenceID": 130, "context": "BM3D/BM4D [132, 36]).", "startOffset": 10, "endOffset": 19}, {"referenceID": 34, "context": "BM3D/BM4D [132, 36]).", "startOffset": 10, "endOffset": 19}, {"referenceID": 139, "context": "Deconvolution is not done as commonly for multiphoton microscopy as compared to confocal microscopy [141], but if it is been done in can be done jointly with other image restoration operations [160] or as its independent step [92].", "startOffset": 100, "endOffset": 105}, {"referenceID": 158, "context": "Deconvolution is not done as commonly for multiphoton microscopy as compared to confocal microscopy [141], but if it is been done in can be done jointly with other image restoration operations [160] or as its independent step [92].", "startOffset": 193, "endOffset": 198}, {"referenceID": 90, "context": "Deconvolution is not done as commonly for multiphoton microscopy as compared to confocal microscopy [141], but if it is been done in can be done jointly with other image restoration operations [160] or as its independent step [92].", "startOffset": 226, "endOffset": 230}, {"referenceID": 137, "context": "In some cases the restored image is further simplified using some edge-aware smoothing operator such as anisotropic diffusion [139, 165], or as done by Persch et al.", "startOffset": 126, "endOffset": 136}, {"referenceID": 163, "context": "In some cases the restored image is further simplified using some edge-aware smoothing operator such as anisotropic diffusion [139, 165], or as done by Persch et al.", "startOffset": 126, "endOffset": 136}, {"referenceID": 158, "context": "[160] who jointly apply the anisotropic diffusion inpainting (operation that attempts to replace lost or corrupted parts of the image data) with deconvolution and interpolation.", "startOffset": 0, "endOffset": 5}, {"referenceID": 47, "context": "The best known filter of those is the Frangi\u2019s filter [49] that has become outdated as it cannot properly handle crossings nor bifurcation methods, and several filters [109, 226, 198, 62, 144] have been proposed to correct the shortcomings of Frangi\u2019s filter with none of them reaching a de facto standard status.", "startOffset": 54, "endOffset": 58}, {"referenceID": 107, "context": "The best known filter of those is the Frangi\u2019s filter [49] that has become outdated as it cannot properly handle crossings nor bifurcation methods, and several filters [109, 226, 198, 62, 144] have been proposed to correct the shortcomings of Frangi\u2019s filter with none of them reaching a de facto standard status.", "startOffset": 168, "endOffset": 192}, {"referenceID": 224, "context": "The best known filter of those is the Frangi\u2019s filter [49] that has become outdated as it cannot properly handle crossings nor bifurcation methods, and several filters [109, 226, 198, 62, 144] have been proposed to correct the shortcomings of Frangi\u2019s filter with none of them reaching a de facto standard status.", "startOffset": 168, "endOffset": 192}, {"referenceID": 196, "context": "The best known filter of those is the Frangi\u2019s filter [49] that has become outdated as it cannot properly handle crossings nor bifurcation methods, and several filters [109, 226, 198, 62, 144] have been proposed to correct the shortcomings of Frangi\u2019s filter with none of them reaching a de facto standard status.", "startOffset": 168, "endOffset": 192}, {"referenceID": 60, "context": "The best known filter of those is the Frangi\u2019s filter [49] that has become outdated as it cannot properly handle crossings nor bifurcation methods, and several filters [109, 226, 198, 62, 144] have been proposed to correct the shortcomings of Frangi\u2019s filter with none of them reaching a de facto standard status.", "startOffset": 168, "endOffset": 192}, {"referenceID": 142, "context": "The best known filter of those is the Frangi\u2019s filter [49] that has become outdated as it cannot properly handle crossings nor bifurcation methods, and several filters [109, 226, 198, 62, 144] have been proposed to correct the shortcomings of Frangi\u2019s filter with none of them reaching a de facto standard status.", "startOffset": 168, "endOffset": 192}, {"referenceID": 95, "context": "There have been various \"traditional\" segmentation algorithms for vessel segmentations (for reviews see [97, 116]), and only the most relevant ones are", "startOffset": 104, "endOffset": 113}, {"referenceID": 114, "context": "There have been various \"traditional\" segmentation algorithms for vessel segmentations (for reviews see [97, 116]), and only the most relevant ones are", "startOffset": 104, "endOffset": 113}, {"referenceID": 119, "context": "1) z-interpolation is placed after the segmentation, but it might have been placed as well before the segmentation algorithm [121, 228], or jointly with other image restoration operators [160].", "startOffset": 125, "endOffset": 135}, {"referenceID": 226, "context": "1) z-interpolation is placed after the segmentation, but it might have been placed as well before the segmentation algorithm [121, 228], or jointly with other image restoration operators [160].", "startOffset": 125, "endOffset": 135}, {"referenceID": 158, "context": "1) z-interpolation is placed after the segmentation, but it might have been placed as well before the segmentation algorithm [121, 228], or jointly with other image restoration operators [160].", "startOffset": 187, "endOffset": 192}, {"referenceID": 115, "context": "Reconstructing meshes from noninterpolated anisotropic stacks with traditional Marching Cubes algorithm [117] typically leads to \u201cstaircasing effect\u201d of the mesh while interpolation gives smoother reconstruction.", "startOffset": 104, "endOffset": 109}, {"referenceID": 143, "context": "Advanced mesh reconstruction methods are beyond the scope of this algorithm, but there have been efforts to improve biomedical mesh reconstruction [145, 177] mitigating the problems of triangulation based such as Marching Cubes.", "startOffset": 147, "endOffset": 157}, {"referenceID": 175, "context": "Advanced mesh reconstruction methods are beyond the scope of this algorithm, but there have been efforts to improve biomedical mesh reconstruction [145, 177] mitigating the problems of triangulation based such as Marching Cubes.", "startOffset": 147, "endOffset": 157}, {"referenceID": 138, "context": "With the reconstructed vasculature mesh, it is then possible to for example do morphological analysis [140], calculate hemodynamic parameters [90], or analyze the functional diameter changes in response to external stimulus [121].", "startOffset": 102, "endOffset": 107}, {"referenceID": 88, "context": "With the reconstructed vasculature mesh, it is then possible to for example do morphological analysis [140], calculate hemodynamic parameters [90], or analyze the functional diameter changes in response to external stimulus [121].", "startOffset": 142, "endOffset": 146}, {"referenceID": 119, "context": "With the reconstructed vasculature mesh, it is then possible to for example do morphological analysis [140], calculate hemodynamic parameters [90], or analyze the functional diameter changes in response to external stimulus [121].", "startOffset": 224, "endOffset": 229}, {"referenceID": 173, "context": "Despite the limited use of machine learning techniques in VESSEL12 challenge for lung vessels [175], there have been some work using machine learning techniques for vessel segmentation.", "startOffset": 94, "endOffset": 99}, {"referenceID": 194, "context": "[196] for example used an unsupervised dictionary learning [103] approach that learned optimal separable convolutional filter banks for 2D vasculature segmentation (DRIVE dataset [203]), and for 3D olfactory projection fibers (DIADEM challenge [16]).", "startOffset": 0, "endOffset": 5}, {"referenceID": 101, "context": "[196] for example used an unsupervised dictionary learning [103] approach that learned optimal separable convolutional filter banks for 2D vasculature segmentation (DRIVE dataset [203]), and for 3D olfactory projection fibers (DIADEM challenge [16]).", "startOffset": 59, "endOffset": 64}, {"referenceID": 201, "context": "[196] for example used an unsupervised dictionary learning [103] approach that learned optimal separable convolutional filter banks for 2D vasculature segmentation (DRIVE dataset [203]), and for 3D olfactory projection fibers (DIADEM challenge [16]).", "startOffset": 179, "endOffset": 184}, {"referenceID": 14, "context": "[196] for example used an unsupervised dictionary learning [103] approach that learned optimal separable convolutional filter banks for 2D vasculature segmentation (DRIVE dataset [203]), and for 3D olfactory projection fibers (DIADEM challenge [16]).", "startOffset": 244, "endOffset": 248}, {"referenceID": 13, "context": "Forests classifier [15] continuing the previous work from the same lab [58, 170].", "startOffset": 19, "endOffset": 23}, {"referenceID": 56, "context": "Forests classifier [15] continuing the previous work from the same lab [58, 170].", "startOffset": 71, "endOffset": 80}, {"referenceID": 168, "context": "Forests classifier [15] continuing the previous work from the same lab [58, 170].", "startOffset": 71, "endOffset": 80}, {"referenceID": 132, "context": "[134] applied ConvNets for the two-dimensional vasculature DRIVE database with promising performance.", "startOffset": 0, "endOffset": 5}, {"referenceID": 176, "context": "[178] similarly used a dictionary learning approach to learn linear filters for detection of tubular-like structures from multiphoton microscopy stacks.", "startOffset": 0, "endOffset": 5}, {"referenceID": 208, "context": "The learned filters were fed to a Support Vector Machine (SVM, [210]) which was shown to provide a better segmentation accuracy compared to the vesselness filter introduced by Sato et al.", "startOffset": 63, "endOffset": 68}, {"referenceID": 178, "context": "[180].", "startOffset": 0, "endOffset": 5}, {"referenceID": 183, "context": "[185] used Random Forests for classification with multivariate Hough forests to infer probabilistic votes about the vessel center, jointly segmenting vasculature and extracting vessel centerline.", "startOffset": 0, "endOffset": 5}, {"referenceID": 78, "context": "The features were learned using steerable filter templates ([80]) at multiple scales instead of the dictionary learning approach.", "startOffset": 60, "endOffset": 64}, {"referenceID": 107, "context": "They showed that their learning-based approach outperformed both Oriented Optimal Flow (OOF, [109]) and Frangi\u2019s filter [49] for vessel segmentation.", "startOffset": 93, "endOffset": 98}, {"referenceID": 47, "context": "They showed that their learning-based approach outperformed both Oriented Optimal Flow (OOF, [109]) and Frangi\u2019s filter [49] for vessel segmentation.", "startOffset": 120, "endOffset": 124}, {"referenceID": 195, "context": "[197] take a different approach in their paper", "startOffset": 0, "endOffset": 5}, {"referenceID": 130, "context": "BM4D [132]), and then deconvolved (e.", "startOffset": 5, "endOffset": 10}, {"referenceID": 139, "context": "blind Richardson-Lucy deconvolution [141]), or this image restoration can be done jointly.", "startOffset": 36, "endOffset": 41}, {"referenceID": 47, "context": "This is followed by a vesselness enhancement filter such as Frangi\u2019s filter [49], Optimal Oriented Flux (OOF) [109], or some more recent method (e.", "startOffset": 76, "endOffset": 80}, {"referenceID": 107, "context": "This is followed by a vesselness enhancement filter such as Frangi\u2019s filter [49], Optimal Oriented Flux (OOF) [109], or some more recent method (e.", "startOffset": 110, "endOffset": 115}, {"referenceID": 142, "context": "[144]).", "startOffset": 0, "endOffset": 5}, {"referenceID": 108, "context": "active contours [110]) that produces a binary mask (or real-valued probability mask) that can be used to weigh the input.", "startOffset": 16, "endOffset": 21}, {"referenceID": 214, "context": "This weighed image stack might be then interpolated in z-direction to obtain an isotropic stack with equal-sized voxel sides for example using a B-spline interpolation [216].", "startOffset": 168, "endOffset": 173}, {"referenceID": 115, "context": "If needed for analysis or visualization, this interpolated stack can be reconstructed into a three-dimensional mesh that is typically obtained via the Marching Cubes algorithm variants [117].", "startOffset": 185, "endOffset": 190}, {"referenceID": 37, "context": "inspired by recent work on structured learning-based edge detectors ([39]).", "startOffset": 69, "endOffset": 73}, {"referenceID": 51, "context": "They combine structured learning with nearest neighbor-based output refinement step designed for situations where edges or thin objects are hard to detect explicitly by the neural network ([53]).", "startOffset": 189, "endOffset": 193}, {"referenceID": 201, "context": "They were able to reduce spatial discontinuities, isolated erroneous responses and topological errors of initial score maps from outputs of other algorithms, and when directly trained to segment two-dimensional blood vessels (DRIVE dataset [203]).", "startOffset": 240, "endOffset": 245}, {"referenceID": 123, "context": "In natural image processing literature, the corresponding application to our biomedical image segmentation is semantic segmentation [125, 155, 24, 23], also referred as scene parsing [163] or scene labeling [45].", "startOffset": 132, "endOffset": 150}, {"referenceID": 153, "context": "In natural image processing literature, the corresponding application to our biomedical image segmentation is semantic segmentation [125, 155, 24, 23], also referred as scene parsing [163] or scene labeling [45].", "startOffset": 132, "endOffset": 150}, {"referenceID": 22, "context": "In natural image processing literature, the corresponding application to our biomedical image segmentation is semantic segmentation [125, 155, 24, 23], also referred as scene parsing [163] or scene labeling [45].", "startOffset": 132, "endOffset": 150}, {"referenceID": 21, "context": "In natural image processing literature, the corresponding application to our biomedical image segmentation is semantic segmentation [125, 155, 24, 23], also referred as scene parsing [163] or scene labeling [45].", "startOffset": 132, "endOffset": 150}, {"referenceID": 161, "context": "In natural image processing literature, the corresponding application to our biomedical image segmentation is semantic segmentation [125, 155, 24, 23], also referred as scene parsing [163] or scene labeling [45].", "startOffset": 183, "endOffset": 188}, {"referenceID": 43, "context": "In natural image processing literature, the corresponding application to our biomedical image segmentation is semantic segmentation [125, 155, 24, 23], also referred as scene parsing [163] or scene labeling [45].", "startOffset": 207, "endOffset": 211}, {"referenceID": 87, "context": "Semantic segmentation with natural images tries to answer to the question \u201cWhat is where in your image?\u201d for example segmenting the \u201cdriver view\u201d in autonomous driving to road, lanes and other vehicles [89].", "startOffset": 202, "endOffset": 206}, {"referenceID": 121, "context": "Most existing biomedical segmentation pipelines start with slice-by-slice two-dimensional processing for volumetric stacks, and only later transition to three-dimensional processing due to high computational cost of fully threedimensional pipelines [123, 214].", "startOffset": 249, "endOffset": 259}, {"referenceID": 212, "context": "Most existing biomedical segmentation pipelines start with slice-by-slice two-dimensional processing for volumetric stacks, and only later transition to three-dimensional processing due to high computational cost of fully threedimensional pipelines [123, 214].", "startOffset": 249, "endOffset": 259}, {"referenceID": 65, "context": "ConvNets with 3D filters had been used for example with block face EM images before [67], most of the 3D filter use being employed in video processing [83, 220, 243] where the 2D image with the time can be viewed as an anisotropic 3D image.", "startOffset": 84, "endOffset": 88}, {"referenceID": 81, "context": "ConvNets with 3D filters had been used for example with block face EM images before [67], most of the 3D filter use being employed in video processing [83, 220, 243] where the 2D image with the time can be viewed as an anisotropic 3D image.", "startOffset": 151, "endOffset": 165}, {"referenceID": 218, "context": "ConvNets with 3D filters had been used for example with block face EM images before [67], most of the 3D filter use being employed in video processing [83, 220, 243] where the 2D image with the time can be viewed as an anisotropic 3D image.", "startOffset": 151, "endOffset": 165}, {"referenceID": 241, "context": "ConvNets with 3D filters had been used for example with block face EM images before [67], most of the 3D filter use being employed in video processing [83, 220, 243] where the 2D image with the time can be viewed as an anisotropic 3D image.", "startOffset": 151, "endOffset": 165}, {"referenceID": 84, "context": "[86] for brain lesion segmentation from MRI images.", "startOffset": 0, "endOffset": 4}, {"referenceID": 70, "context": "Deep learning based approaches have been extensively used for volumetric electron microscopy (EM) segmentation [72, 133, 236, 114, 173].", "startOffset": 111, "endOffset": 135}, {"referenceID": 131, "context": "Deep learning based approaches have been extensively used for volumetric electron microscopy (EM) segmentation [72, 133, 236, 114, 173].", "startOffset": 111, "endOffset": 135}, {"referenceID": 234, "context": "Deep learning based approaches have been extensively used for volumetric electron microscopy (EM) segmentation [72, 133, 236, 114, 173].", "startOffset": 111, "endOffset": 135}, {"referenceID": 112, "context": "Deep learning based approaches have been extensively used for volumetric electron microscopy (EM) segmentation [72, 133, 236, 114, 173].", "startOffset": 111, "endOffset": 135}, {"referenceID": 171, "context": "Deep learning based approaches have been extensively used for volumetric electron microscopy (EM) segmentation [72, 133, 236, 114, 173].", "startOffset": 111, "endOffset": 135}, {"referenceID": 62, "context": "Other biomedical image segmentation tasks with deep learning frameworks include for example brain segmentation [64, 129, 85, 205], prediction of Alzheimer\u2019s disease from magnetic resonance imaging (MRI) scans [158], microscopic cell segmentation", "startOffset": 111, "endOffset": 129}, {"referenceID": 127, "context": "Other biomedical image segmentation tasks with deep learning frameworks include for example brain segmentation [64, 129, 85, 205], prediction of Alzheimer\u2019s disease from magnetic resonance imaging (MRI) scans [158], microscopic cell segmentation", "startOffset": 111, "endOffset": 129}, {"referenceID": 83, "context": "Other biomedical image segmentation tasks with deep learning frameworks include for example brain segmentation [64, 129, 85, 205], prediction of Alzheimer\u2019s disease from magnetic resonance imaging (MRI) scans [158], microscopic cell segmentation", "startOffset": 111, "endOffset": 129}, {"referenceID": 203, "context": "Other biomedical image segmentation tasks with deep learning frameworks include for example brain segmentation [64, 129, 85, 205], prediction of Alzheimer\u2019s disease from magnetic resonance imaging (MRI) scans [158], microscopic cell segmentation", "startOffset": 111, "endOffset": 129}, {"referenceID": 156, "context": "Other biomedical image segmentation tasks with deep learning frameworks include for example brain segmentation [64, 129, 85, 205], prediction of Alzheimer\u2019s disease from magnetic resonance imaging (MRI) scans [158], microscopic cell segmentation", "startOffset": 209, "endOffset": 214}, {"referenceID": 100, "context": "[102], glaucoma detection [26], computational mammography [40], pancreas segmentation [40], bi-ventrical volume estimation [251], and carotid artery bifurcation detection [252] The use of deep learning neural networks is not limited to image analysis, and it can employed in various fields that can benefit from data-driven analysis in exploratory or predictive fashion.", "startOffset": 0, "endOffset": 5}, {"referenceID": 24, "context": "[102], glaucoma detection [26], computational mammography [40], pancreas segmentation [40], bi-ventrical volume estimation [251], and carotid artery bifurcation detection [252] The use of deep learning neural networks is not limited to image analysis, and it can employed in various fields that can benefit from data-driven analysis in exploratory or predictive fashion.", "startOffset": 26, "endOffset": 30}, {"referenceID": 38, "context": "[102], glaucoma detection [26], computational mammography [40], pancreas segmentation [40], bi-ventrical volume estimation [251], and carotid artery bifurcation detection [252] The use of deep learning neural networks is not limited to image analysis, and it can employed in various fields that can benefit from data-driven analysis in exploratory or predictive fashion.", "startOffset": 58, "endOffset": 62}, {"referenceID": 38, "context": "[102], glaucoma detection [26], computational mammography [40], pancreas segmentation [40], bi-ventrical volume estimation [251], and carotid artery bifurcation detection [252] The use of deep learning neural networks is not limited to image analysis, and it can employed in various fields that can benefit from data-driven analysis in exploratory or predictive fashion.", "startOffset": 86, "endOffset": 90}, {"referenceID": 249, "context": "[102], glaucoma detection [26], computational mammography [40], pancreas segmentation [40], bi-ventrical volume estimation [251], and carotid artery bifurcation detection [252] The use of deep learning neural networks is not limited to image analysis, and it can employed in various fields that can benefit from data-driven analysis in exploratory or predictive fashion.", "startOffset": 123, "endOffset": 128}, {"referenceID": 250, "context": "[102], glaucoma detection [26], computational mammography [40], pancreas segmentation [40], bi-ventrical volume estimation [251], and carotid artery bifurcation detection [252] The use of deep learning neural networks is not limited to image analysis, and it can employed in various fields that can benefit from data-driven analysis in exploratory or predictive fashion.", "startOffset": 171, "endOffset": 176}, {"referenceID": 172, "context": "In neuroscience, in general the datasets are getting increasingly larger and more complex requiring more sophisticated data analysis tools [174].", "startOffset": 139, "endOffset": 144}, {"referenceID": 53, "context": "There have been systems capable of constructing theories automatically in data-driven fashion [55].", "startOffset": 94, "endOffset": 98}, {"referenceID": 172, "context": "Artificial neural networks lend themselves well for modeling complex brain function that emerge from activation of ensembles of neurons in which the studying of single neuron at a time is not sufficient [174].", "startOffset": 203, "endOffset": 208}, {"referenceID": 170, "context": "For example, the circuit architecture of the mammalian hippocampus have been modeled to consist of series of sequential feedforward and recurrent neural networks [172].", "startOffset": 162, "endOffset": 167}, {"referenceID": 61, "context": "[63] used two-photon imaging to measure the calcium activity of mouse making behavioral choices in virtual maze.", "startOffset": 0, "endOffset": 4}, {"referenceID": 230, "context": "In addition to basic neuroscience, deep learning \u201cexpert systems\u201d have been extended to clinical settings [232] for example for predicting clinical outcomes of radiation therapy [87], electroencephalographic (EEG) recording analysis [204], and future disease diagnosis and medicine prescription in routine clinical practice [29].", "startOffset": 106, "endOffset": 111}, {"referenceID": 85, "context": "In addition to basic neuroscience, deep learning \u201cexpert systems\u201d have been extended to clinical settings [232] for example for predicting clinical outcomes of radiation therapy [87], electroencephalographic (EEG) recording analysis [204], and future disease diagnosis and medicine prescription in routine clinical practice [29].", "startOffset": 178, "endOffset": 182}, {"referenceID": 202, "context": "In addition to basic neuroscience, deep learning \u201cexpert systems\u201d have been extended to clinical settings [232] for example for predicting clinical outcomes of radiation therapy [87], electroencephalographic (EEG) recording analysis [204], and future disease diagnosis and medicine prescription in routine clinical practice [29].", "startOffset": 233, "endOffset": 238}, {"referenceID": 27, "context": "In addition to basic neuroscience, deep learning \u201cexpert systems\u201d have been extended to clinical settings [232] for example for predicting clinical outcomes of radiation therapy [87], electroencephalographic (EEG) recording analysis [204], and future disease diagnosis and medicine prescription in routine clinical practice [29].", "startOffset": 324, "endOffset": 328}, {"referenceID": 16, "context": "Fluorescent dextran (70 kDa Texas Red, dissolved in PBS, Invitrogen) was used to visualize the vasculature in mouse cortex by [18], and fluorescent dextran (2MDa FITC, dissolved in PBS, Invitrogen) to label the tumor vasculature.", "startOffset": 126, "endOffset": 130}, {"referenceID": 120, "context": "org/, [122, 142]) with Matlab[118] to open the OIB files from Olympus FluoView 2-photon microsopy setup.", "startOffset": 6, "endOffset": 16}, {"referenceID": 140, "context": "org/, [122, 142]) with Matlab[118] to open the OIB files from Olympus FluoView 2-photon microsopy setup.", "startOffset": 6, "endOffset": 16}, {"referenceID": 116, "context": "org/, [122, 142]) with Matlab[118] to open the OIB files from Olympus FluoView 2-photon microsopy setup.", "startOffset": 29, "endOffset": 34}, {"referenceID": 211, "context": "We used more conservative criteria for labeling vasculature than the traditional \u201c50% of the voxel\u201d to account the partial volume effect [213], and we tried to include all the vessel-like structures to the label", "startOffset": 137, "endOffset": 142}, {"referenceID": 130, "context": "After converting the substacks to OME-TIFF files, we denoised the microscopy stacks using the state-of-the art denoising algorithm BM4D ([132]) implemented in Matlab.", "startOffset": 137, "endOffset": 142}, {"referenceID": 31, "context": "BM4D is a volumetric extension of the commonly used BM3D denoising algorithm [33] for 2D images, which was for example used to denoise two-photon microscope images by Danielyan et al.", "startOffset": 77, "endOffset": 81}, {"referenceID": 34, "context": "[36].", "startOffset": 0, "endOffset": 4}, {"referenceID": 133, "context": "BM3D/BM4D were designed for denoising images degraded by Gaussian noise, thus we applied first Anscombe transform to reduce the signal-dependency of the noise as done with BM4D for denoising of magnetic resonance imaging (MRI) images [135].", "startOffset": 234, "endOffset": 239}, {"referenceID": 39, "context": "[41]) for our microscope stacks to improve the image quality.", "startOffset": 0, "endOffset": 4}, {"referenceID": 35, "context": "[37]) was done for the image stacks.", "startOffset": 0, "endOffset": 4}, {"referenceID": 198, "context": "[200]) was needed for the dataset.", "startOffset": 0, "endOffset": 5}, {"referenceID": 211, "context": "[213].", "startOffset": 0, "endOffset": 5}, {"referenceID": 251, "context": "We trained our 3D vessel segmentation deep ConvNet using ZNN framework [253], that uses multicore CPU parallelism for speed instead of typical GPU-accelerated frameworks such as Theano for example [215].", "startOffset": 71, "endOffset": 76}, {"referenceID": 213, "context": "We trained our 3D vessel segmentation deep ConvNet using ZNN framework [253], that uses multicore CPU parallelism for speed instead of typical GPU-accelerated frameworks such as Theano for example [215].", "startOffset": 197, "endOffset": 202}, {"referenceID": 82, "context": "Commonly used library Caffe [84] had only 2D networks available, while DeepLab built on top of Caffe would have had GPU-accelerated 3D networks implemented.", "startOffset": 28, "endOffset": 32}, {"referenceID": 112, "context": "Our approach for vessel segmentation is inspired by the success of ZNN in segmenting threedimensional electron microscope (EM) image stacks [114], and we chose to start with the networks described for EM segmentation.", "startOffset": 140, "endOffset": 145}, {"referenceID": 28, "context": "Additional possible parameters: depth, FOV, and dye, excitation wavelength, percentage of vessel labels (see [30]).", "startOffset": 109, "endOffset": 113}, {"referenceID": 112, "context": "([114]).", "startOffset": 1, "endOffset": 6}, {"referenceID": 123, "context": "Traditionally, in semantic segmentation ([125]) and biomedical image segmentation ([173]) pipelines, max-pooling is used instead of max-filtering which reduces the dimensions of the output map requiring either post-processing using for example some graphical model ([23]), or upsampling back to the original resolution ([173]).", "startOffset": 41, "endOffset": 46}, {"referenceID": 171, "context": "Traditionally, in semantic segmentation ([125]) and biomedical image segmentation ([173]) pipelines, max-pooling is used instead of max-filtering which reduces the dimensions of the output map requiring either post-processing using for example some graphical model ([23]), or upsampling back to the original resolution ([173]).", "startOffset": 83, "endOffset": 88}, {"referenceID": 21, "context": "Traditionally, in semantic segmentation ([125]) and biomedical image segmentation ([173]) pipelines, max-pooling is used instead of max-filtering which reduces the dimensions of the output map requiring either post-processing using for example some graphical model ([23]), or upsampling back to the original resolution ([173]).", "startOffset": 266, "endOffset": 270}, {"referenceID": 171, "context": "Traditionally, in semantic segmentation ([125]) and biomedical image segmentation ([173]) pipelines, max-pooling is used instead of max-filtering which reduces the dimensions of the output map requiring either post-processing using for example some graphical model ([23]), or upsampling back to the original resolution ([173]).", "startOffset": 320, "endOffset": 325}, {"referenceID": 186, "context": "This approach is also called \u201cskip-kernels\u201d ([188]) or \u201cfilter rarefaction\u201d ([125]), and is equivalent in its results to \u201cmax-fragmentation-pooling\u201d ([57, 137]).", "startOffset": 45, "endOffset": 50}, {"referenceID": 123, "context": "This approach is also called \u201cskip-kernels\u201d ([188]) or \u201cfilter rarefaction\u201d ([125]), and is equivalent in its results to \u201cmax-fragmentation-pooling\u201d ([57, 137]).", "startOffset": 77, "endOffset": 82}, {"referenceID": 55, "context": "This approach is also called \u201cskip-kernels\u201d ([188]) or \u201cfilter rarefaction\u201d ([125]), and is equivalent in its results to \u201cmax-fragmentation-pooling\u201d ([57, 137]).", "startOffset": 150, "endOffset": 159}, {"referenceID": 135, "context": "This approach is also called \u201cskip-kernels\u201d ([188]) or \u201cfilter rarefaction\u201d ([125]), and is equivalent in its results to \u201cmax-fragmentation-pooling\u201d ([57, 137]).", "startOffset": 150, "endOffset": 159}, {"referenceID": 112, "context": "[114] used to segment electron microscopy (EM) stacks.", "startOffset": 0, "endOffset": 5}, {"referenceID": 161, "context": "2) are initialized with the trained weights of the VD2D without enforcing weight sharing as done by some recurrent ConvNets ([163]).", "startOffset": 125, "endOffset": 130}, {"referenceID": 112, "context": "[114] showed that providing the output of VD2D recursively as the input to the VD2D3D produced a significant improvement in performance.", "startOffset": 0, "endOffset": 5}, {"referenceID": 112, "context": "[114].", "startOffset": 0, "endOffset": 5}, {"referenceID": 112, "context": "[114] with an initial learning rate of 0.", "startOffset": 0, "endOffset": 5}, {"referenceID": 112, "context": "[114], we rebalanced the classes (vessels/non-vessels) by differentially weighing the perpixel loss to deal with the imbalance between vessels and non-vessel pixels which was however lower than the imbalance seen in electron microscope images between boundary and non-boundary pixels.", "startOffset": 0, "endOffset": 5}, {"referenceID": 69, "context": "Additionally we could have introduced photometric distortions ([71]) to further counteract the possible overfitting due to limited training data, but they were seen unnecessary at the time of the training.", "startOffset": 63, "endOffset": 67}, {"referenceID": 200, "context": "We also used dropout ([202]) to further avoid overfitting that was implemented in ZNN.", "startOffset": 22, "endOffset": 27}, {"referenceID": 112, "context": "com/seung-lab/znn-release by the original authors [114, 253].", "startOffset": 50, "endOffset": 60}, {"referenceID": 251, "context": "com/seung-lab/znn-release by the original authors [114, 253].", "startOffset": 50, "endOffset": 60}, {"referenceID": 228, "context": "In the spirit of reproducible research [230, 38, 88, 115] we release also our annotated dataset for other research teams to be used.", "startOffset": 39, "endOffset": 57}, {"referenceID": 36, "context": "In the spirit of reproducible research [230, 38, 88, 115] we release also our annotated dataset for other research teams to be used.", "startOffset": 39, "endOffset": 57}, {"referenceID": 86, "context": "In the spirit of reproducible research [230, 38, 88, 115] we release also our annotated dataset for other research teams to be used.", "startOffset": 39, "endOffset": 57}, {"referenceID": 113, "context": "In the spirit of reproducible research [230, 38, 88, 115] we release also our annotated dataset for other research teams to be used.", "startOffset": 39, "endOffset": 57}, {"referenceID": 211, "context": "Otherwise the Average Hausdorff Distance might be a a bit abstract, but smaller distance the better, and it was recommended for complex boundaries such as vessels and neurons in the review by Taha and Hanbury [213].", "startOffset": 209, "endOffset": 214}, {"referenceID": 211, "context": "Rand Index and Area Under the Curve (AUC) was chosen as metrics as they are typically used as error metrics in medical segmentation studies [213].", "startOffset": 140, "endOffset": 145}, {"referenceID": 112, "context": "[114] for electron microscopy stacks.", "startOffset": 0, "endOffset": 5}, {"referenceID": 112, "context": "Our proposed networks based on the ZNN framework [114, 254] for vasculature segmentation from volumetric two-photon microscope stacks provided promising results of segmentation quality.", "startOffset": 49, "endOffset": 59}, {"referenceID": 252, "context": "Our proposed networks based on the ZNN framework [114, 254] for vasculature segmentation from volumetric two-photon microscope stacks provided promising results of segmentation quality.", "startOffset": 49, "endOffset": 59}, {"referenceID": 112, "context": "[114] termed VD2D3D (\u201cVery Deep 2D-3D\u201d) with 2D layers in the initial layers, and 3D layers at higher abstraction layers to make the network faster to run and train.", "startOffset": 0, "endOffset": 5}, {"referenceID": 171, "context": "[173] for biomedical image segmentation).", "startOffset": 0, "endOffset": 5}, {"referenceID": 58, "context": "[60]).", "startOffset": 0, "endOffset": 4}, {"referenceID": 118, "context": "[120] or with the Inception module by Szegedy et al.", "startOffset": 0, "endOffset": 5}, {"referenceID": 209, "context": "[211, 212].", "startOffset": 0, "endOffset": 10}, {"referenceID": 210, "context": "[211, 212].", "startOffset": 0, "endOffset": 10}, {"referenceID": 89, "context": "Very recently there has been interesting work of replacing convolutional filter with bilateral filter [91, 51, 81, 7] that is very commonly used edge-preserving smoothing fil-", "startOffset": 102, "endOffset": 117}, {"referenceID": 49, "context": "Very recently there has been interesting work of replacing convolutional filter with bilateral filter [91, 51, 81, 7] that is very commonly used edge-preserving smoothing fil-", "startOffset": 102, "endOffset": 117}, {"referenceID": 79, "context": "Very recently there has been interesting work of replacing convolutional filter with bilateral filter [91, 51, 81, 7] that is very commonly used edge-preserving smoothing fil-", "startOffset": 102, "endOffset": 117}, {"referenceID": 5, "context": "Very recently there has been interesting work of replacing convolutional filter with bilateral filter [91, 51, 81, 7] that is very commonly used edge-preserving smoothing fil-", "startOffset": 102, "endOffset": 117}, {"referenceID": 215, "context": "ter [217].", "startOffset": 4, "endOffset": 9}, {"referenceID": 89, "context": "The convolutional filters were replaced both from earlier layers [91], as well as from later fully-connected layers [51] offering faster runtime especially for higherdimensional signals.", "startOffset": 65, "endOffset": 69}, {"referenceID": 49, "context": "The convolutional filters were replaced both from earlier layers [91], as well as from later fully-connected layers [51] offering faster runtime especially for higherdimensional signals.", "startOffset": 116, "endOffset": 120}, {"referenceID": 49, "context": "[51] replaced the Inception modules with \u201cbilateral Inception\u201d superpixels yielding better segmentation results than strictly pixel-wise implementations.", "startOffset": 0, "endOffset": 4}, {"referenceID": 49, "context": "Bilateral Inception allowed long-range edgepreserving inference directly removing the need for dense CRF as post-processing step according to the authors [51].", "startOffset": 154, "endOffset": 158}, {"referenceID": 79, "context": "[81] trained the bilateral filter to be used within the dense CRF inference, demonstrating better segmentation performance compared to traditional dense CRF.", "startOffset": 0, "endOffset": 4}, {"referenceID": 58, "context": "There have been many attempts to improve the maxpooling [60] of which the maximum filtering used here is a dense variant that retains original volume resolution.", "startOffset": 56, "endOffset": 60}, {"referenceID": 169, "context": "From the recent efforts, especially spectral pooling seems like an interesting upgrade [171] as it can be implemented with little computational cost for Fast Fourier Transform (FFT) based convolution networks such as the VD2D3D used here.", "startOffset": 87, "endOffset": 92}, {"referenceID": 102, "context": "The use of spectral pooling provided the best classification performance on CIFAR (10 and 100) image classification dataset [104] compared to other state-of-theart methods such as stochastic pooling[247], Maxout [59], \u201cNetwork in Network\u201d (NIN) [120], and deeply-supervised nets [114].", "startOffset": 124, "endOffset": 129}, {"referenceID": 245, "context": "The use of spectral pooling provided the best classification performance on CIFAR (10 and 100) image classification dataset [104] compared to other state-of-theart methods such as stochastic pooling[247], Maxout [59], \u201cNetwork in Network\u201d (NIN) [120], and deeply-supervised nets [114].", "startOffset": 198, "endOffset": 203}, {"referenceID": 57, "context": "The use of spectral pooling provided the best classification performance on CIFAR (10 and 100) image classification dataset [104] compared to other state-of-theart methods such as stochastic pooling[247], Maxout [59], \u201cNetwork in Network\u201d (NIN) [120], and deeply-supervised nets [114].", "startOffset": 212, "endOffset": 216}, {"referenceID": 118, "context": "The use of spectral pooling provided the best classification performance on CIFAR (10 and 100) image classification dataset [104] compared to other state-of-theart methods such as stochastic pooling[247], Maxout [59], \u201cNetwork in Network\u201d (NIN) [120], and deeply-supervised nets [114].", "startOffset": 245, "endOffset": 250}, {"referenceID": 112, "context": "The use of spectral pooling provided the best classification performance on CIFAR (10 and 100) image classification dataset [104] compared to other state-of-theart methods such as stochastic pooling[247], Maxout [59], \u201cNetwork in Network\u201d (NIN) [120], and deeply-supervised nets [114].", "startOffset": 279, "endOffset": 284}, {"referenceID": 147, "context": "ReLUs are probably the most commonly used activation function in ConvNets [149], with their main disadvantage be-", "startOffset": 74, "endOffset": 79}, {"referenceID": 29, "context": "[31] recently proposed exponential linear units (ELUs) which also employ negative values unlike ReLU, and according to the authors the use of ELUs lead not only to faster learning, but also give better generalization performance especially when the networks have at least 5 layers.", "startOffset": 0, "endOffset": 4}, {"referenceID": 169, "context": "It should be noted that at the moment there is no nonlinear activation function for frequency domain [171], thus there is a computational bottleneck with the inverse FFT and FFT transforms needed before and after the activation function.", "startOffset": 101, "endOffset": 106}, {"referenceID": 200, "context": "We employed Dropout [202] for regularization of our network by applying it before the output layer.", "startOffset": 20, "endOffset": 25}, {"referenceID": 162, "context": "[164] showed that injecting Gaussian noise instead of applying Dropout led to improved performance, and Rasmus et al.", "startOffset": 0, "endOffset": 5}, {"referenceID": 166, "context": "[168] found no practical difference between Dropout and Gaussian noise injection.", "startOffset": 0, "endOffset": 5}, {"referenceID": 50, "context": "Interestingly for Dropout, Gal and Ghahramani [52]; and Kingma et al.", "startOffset": 46, "endOffset": 50}, {"referenceID": 94, "context": "[96] demonstrated how deep learning network with Dropout can be cast as a Bayesian model.", "startOffset": 0, "endOffset": 4}, {"referenceID": 53, "context": "This in practice allows the estimation uncertainty based on Bayesian statistics [55].", "startOffset": 80, "endOffset": 84}, {"referenceID": 87, "context": "[89] for semantic segmentation showing comparable performance to state-of the-art architectures by applying Dropout in the central layers of their encoder-decoder architecture.", "startOffset": 0, "endOffset": 4}, {"referenceID": 119, "context": "[121]) follows the image processing, it is useful to propagate the uncertainties involved in the image processing pipeline to the final statistical analysis.", "startOffset": 0, "endOffset": 5}, {"referenceID": 169, "context": "In the future with increased computational power, and speed optimization this should become feasible either by using Intel Xeon coprocessor [171, 254], supercomputing clusters [249], or GPU-accelerated frameworks such as Theano [215].", "startOffset": 140, "endOffset": 150}, {"referenceID": 252, "context": "In the future with increased computational power, and speed optimization this should become feasible either by using Intel Xeon coprocessor [171, 254], supercomputing clusters [249], or GPU-accelerated frameworks such as Theano [215].", "startOffset": 140, "endOffset": 150}, {"referenceID": 247, "context": "In the future with increased computational power, and speed optimization this should become feasible either by using Intel Xeon coprocessor [171, 254], supercomputing clusters [249], or GPU-accelerated frameworks such as Theano [215].", "startOffset": 176, "endOffset": 181}, {"referenceID": 213, "context": "In the future with increased computational power, and speed optimization this should become feasible either by using Intel Xeon coprocessor [171, 254], supercomputing clusters [249], or GPU-accelerated frameworks such as Theano [215].", "startOffset": 228, "endOffset": 233}, {"referenceID": 104, "context": "[106].", "startOffset": 0, "endOffset": 5}, {"referenceID": 112, "context": "[114].", "startOffset": 0, "endOffset": 5}, {"referenceID": 22, "context": "scale representation is implemented in two main ways [24], either by using so called skip-net that combine features from the intermediate layers of network [188, 23, 125], or via share-net that are fed input resized to different scales [119, 45].", "startOffset": 53, "endOffset": 57}, {"referenceID": 186, "context": "scale representation is implemented in two main ways [24], either by using so called skip-net that combine features from the intermediate layers of network [188, 23, 125], or via share-net that are fed input resized to different scales [119, 45].", "startOffset": 156, "endOffset": 170}, {"referenceID": 21, "context": "scale representation is implemented in two main ways [24], either by using so called skip-net that combine features from the intermediate layers of network [188, 23, 125], or via share-net that are fed input resized to different scales [119, 45].", "startOffset": 156, "endOffset": 170}, {"referenceID": 123, "context": "scale representation is implemented in two main ways [24], either by using so called skip-net that combine features from the intermediate layers of network [188, 23, 125], or via share-net that are fed input resized to different scales [119, 45].", "startOffset": 156, "endOffset": 170}, {"referenceID": 117, "context": "scale representation is implemented in two main ways [24], either by using so called skip-net that combine features from the intermediate layers of network [188, 23, 125], or via share-net that are fed input resized to different scales [119, 45].", "startOffset": 236, "endOffset": 245}, {"referenceID": 43, "context": "scale representation is implemented in two main ways [24], either by using so called skip-net that combine features from the intermediate layers of network [188, 23, 125], or via share-net that are fed input resized to different scales [119, 45].", "startOffset": 236, "endOffset": 245}, {"referenceID": 89, "context": "be able to encode scale invariance defined on continuous range of image scales without the typically used finite number of subsampled inputs simplifying the network architecture [91].", "startOffset": 178, "endOffset": 182}, {"referenceID": 25, "context": "In addition to concentrating on the individual components of the ConvNets, there have been alternative approaches to improve computational efficiency [27, 250, 77, 61].", "startOffset": 150, "endOffset": 167}, {"referenceID": 248, "context": "In addition to concentrating on the individual components of the ConvNets, there have been alternative approaches to improve computational efficiency [27, 250, 77, 61].", "startOffset": 150, "endOffset": 167}, {"referenceID": 75, "context": "In addition to concentrating on the individual components of the ConvNets, there have been alternative approaches to improve computational efficiency [27, 250, 77, 61].", "startOffset": 150, "endOffset": 167}, {"referenceID": 59, "context": "In addition to concentrating on the individual components of the ConvNets, there have been alternative approaches to improve computational efficiency [27, 250, 77, 61].", "startOffset": 150, "endOffset": 167}, {"referenceID": 75, "context": "[77] has received a lot of attention as the authors showed that the same classification accuracy can be obtained with 14 times fewer training steps while exceeding accuracy of human raters with an ensemble of batch-normalized networks.", "startOffset": 0, "endOffset": 4}, {"referenceID": 150, "context": "Another typically used speedup scheme is to use superpixels [152, 46, 51] with two-dimensional images, or supervoxels [127, 100] with volumetric three-dimensional images to reduce the dimensionality of the input.", "startOffset": 60, "endOffset": 73}, {"referenceID": 44, "context": "Another typically used speedup scheme is to use superpixels [152, 46, 51] with two-dimensional images, or supervoxels [127, 100] with volumetric three-dimensional images to reduce the dimensionality of the input.", "startOffset": 60, "endOffset": 73}, {"referenceID": 49, "context": "Another typically used speedup scheme is to use superpixels [152, 46, 51] with two-dimensional images, or supervoxels [127, 100] with volumetric three-dimensional images to reduce the dimensionality of the input.", "startOffset": 60, "endOffset": 73}, {"referenceID": 125, "context": "Another typically used speedup scheme is to use superpixels [152, 46, 51] with two-dimensional images, or supervoxels [127, 100] with volumetric three-dimensional images to reduce the dimensionality of the input.", "startOffset": 118, "endOffset": 128}, {"referenceID": 98, "context": "Another typically used speedup scheme is to use superpixels [152, 46, 51] with two-dimensional images, or supervoxels [127, 100] with volumetric three-dimensional images to reduce the dimensionality of the input.", "startOffset": 118, "endOffset": 128}, {"referenceID": 49, "context": "The main downside of superpixels/supervoxels are that they introduce a quantization error [51] whenever pixels/voxels within one segment", "startOffset": 90, "endOffset": 94}, {"referenceID": 209, "context": "dense data [211].", "startOffset": 11, "endOffset": 16}, {"referenceID": 1, "context": "The already discussed introduction of bilateral filters, and their computation using permutohedral lattices [2, 91] is a one way to speedup the computation of sparse data.", "startOffset": 108, "endOffset": 115}, {"referenceID": 89, "context": "The already discussed introduction of bilateral filters, and their computation using permutohedral lattices [2, 91] is a one way to speedup the computation of sparse data.", "startOffset": 108, "endOffset": 115}, {"referenceID": 54, "context": "[56] introduced a Marginal Space Deep Learning (MSDL) framework for segmenting volumetric medical images by replacing the standard, pre-determined feature sampling pattern with a sparse, adaptive, self-learned pattern showing increased runtime efficiency.", "startOffset": 0, "endOffset": 4}, {"referenceID": 144, "context": "[146] extended the active learning (AL) approach ([189]) for delineation of curvilinear structures including blood vessels.", "startOffset": 0, "endOffset": 5}, {"referenceID": 187, "context": "[146] extended the active learning (AL) approach ([189]) for delineation of curvilinear structures including blood vessels.", "startOffset": 50, "endOffset": 55}, {"referenceID": 98, "context": "Surprisingly and counterintuitively, recent work on electron microscope image segmentation [100] found that the classifier performance of their implementation was better using only a subset of the training data instead of using the whole available training data.", "startOffset": 91, "endOffset": 96}, {"referenceID": 184, "context": "This phenomenon had been reported before by [186], suggesting that a well chosen subset of training data can produce better generalization than the complete set.", "startOffset": 44, "endOffset": 49}, {"referenceID": 92, "context": "[94] demonstrate an interesting approach for acquiring annotations for electron microscopy datasets by developing a game called EyeWire (http://eyewire.", "startOffset": 0, "endOffset": 4}, {"referenceID": 164, "context": "This crowdsourcing have been traditionally used in tasks that does not require expert-level knowledge such as teaching autonomous cars to drive [166], but have been thought to be impractical for tasks that require expertise such as medical segmentation [146].", "startOffset": 144, "endOffset": 149}, {"referenceID": 144, "context": "This crowdsourcing have been traditionally used in tasks that does not require expert-level knowledge such as teaching autonomous cars to drive [166], but have been thought to be impractical for tasks that require expertise such as medical segmentation [146].", "startOffset": 253, "endOffset": 258}, {"referenceID": 6, "context": "Another way to reduce the labor-intensive ground truth annotation required for our supervised approach, would be to initialize our supervised network using unsupervised pretraining from non-annotated dataset ([8]).", "startOffset": 209, "endOffset": 212}, {"referenceID": 41, "context": "[43] have suggested that this pre-training initialization serves as a kind of regularization mechanism that is retained even during the supervised part with the classification performance not deteriorating with the additional supervised training.", "startOffset": 0, "endOffset": 4}, {"referenceID": 194, "context": "We could for example use the dictionary learning approach with sparsity priors for 2D vessel images and 3D neuron dendrites proposed by [196] as the pre-processing step, or alternatively use some stacked autoencoder variant used for medical image segmentation [193, 207].", "startOffset": 136, "endOffset": 141}, {"referenceID": 191, "context": "We could for example use the dictionary learning approach with sparsity priors for 2D vessel images and 3D neuron dendrites proposed by [196] as the pre-processing step, or alternatively use some stacked autoencoder variant used for medical image segmentation [193, 207].", "startOffset": 260, "endOffset": 270}, {"referenceID": 205, "context": "We could for example use the dictionary learning approach with sparsity priors for 2D vessel images and 3D neuron dendrites proposed by [196] as the pre-processing step, or alternatively use some stacked autoencoder variant used for medical image segmentation [193, 207].", "startOffset": 260, "endOffset": 270}, {"referenceID": 166, "context": "More elegant alternative for unsupervised pre-training is to simultaneously apply both unsupervised and supervised learning, instead of having unsupervised pre-training and supervised training as separate steps [168, 130].", "startOffset": 211, "endOffset": 221}, {"referenceID": 128, "context": "More elegant alternative for unsupervised pre-training is to simultaneously apply both unsupervised and supervised learning, instead of having unsupervised pre-training and supervised training as separate steps [168, 130].", "startOffset": 211, "endOffset": 221}, {"referenceID": 166, "context": "[168] proposed a modified Ladder Network [229] which demonstrate how by adding their unsupervised Ladder Network to existing supervised learning methods including convolutional networks improved significantly classification performance in handwriting classification (MNIST database [112]), and in image classification (CIFAR-10 database [104]) compared to previous state-of-the-art approaches.", "startOffset": 0, "endOffset": 5}, {"referenceID": 227, "context": "[168] proposed a modified Ladder Network [229] which demonstrate how by adding their unsupervised Ladder Network to existing supervised learning methods including convolutional networks improved significantly classification performance in handwriting classification (MNIST database [112]), and in image classification (CIFAR-10 database [104]) compared to previous state-of-the-art approaches.", "startOffset": 41, "endOffset": 46}, {"referenceID": 110, "context": "[168] proposed a modified Ladder Network [229] which demonstrate how by adding their unsupervised Ladder Network to existing supervised learning methods including convolutional networks improved significantly classification performance in handwriting classification (MNIST database [112]), and in image classification (CIFAR-10 database [104]) compared to previous state-of-the-art approaches.", "startOffset": 282, "endOffset": 287}, {"referenceID": 102, "context": "[168] proposed a modified Ladder Network [229] which demonstrate how by adding their unsupervised Ladder Network to existing supervised learning methods including convolutional networks improved significantly classification performance in handwriting classification (MNIST database [112]), and in image classification (CIFAR-10 database [104]) compared to previous state-of-the-art approaches.", "startOffset": 337, "endOffset": 342}, {"referenceID": 229, "context": "[231] showed that their deep learning network based on a Gaussian Conditional Random Field (GCRF) model outperformed existing methods in two-dimensional image denoising including the two-dimensional variant BM3D [33] of the BM4D algorithm [132] that we used to denoise our vessel stacks.", "startOffset": 0, "endOffset": 5}, {"referenceID": 31, "context": "[231] showed that their deep learning network based on a Gaussian Conditional Random Field (GCRF) model outperformed existing methods in two-dimensional image denoising including the two-dimensional variant BM3D [33] of the BM4D algorithm [132] that we used to denoise our vessel stacks.", "startOffset": 212, "endOffset": 216}, {"referenceID": 130, "context": "[231] showed that their deep learning network based on a Gaussian Conditional Random Field (GCRF) model outperformed existing methods in two-dimensional image denoising including the two-dimensional variant BM3D [33] of the BM4D algorithm [132] that we used to denoise our vessel stacks.", "startOffset": 239, "endOffset": 244}, {"referenceID": 240, "context": "For other image restoration task such as blind deconvolution [242] for sharpening the stacks, blind inpainting [20] for filling possibly broken vessels, vibrationartifacts, or other image quality artifacts, and motion-blur", "startOffset": 61, "endOffset": 66}, {"referenceID": 18, "context": "For other image restoration task such as blind deconvolution [242] for sharpening the stacks, blind inpainting [20] for filling possibly broken vessels, vibrationartifacts, or other image quality artifacts, and motion-blur", "startOffset": 111, "endOffset": 115}, {"referenceID": 207, "context": "correction [209] deep learning based solutions have been proposed with promising results.", "startOffset": 11, "endOffset": 16}, {"referenceID": 239, "context": "[241] demonstrate a deep convolutional networks designed to learn blindly the output of any deterministic filter or a combination of different filters.", "startOffset": 0, "endOffset": 5}, {"referenceID": 215, "context": "preserving smoothing filters bilateral filter ([217, 7]), and L0 gradient minimization smoothing ([240]) jointly without needing to know anything about the implementations of such filters given that input and output images can be accessed.", "startOffset": 47, "endOffset": 55}, {"referenceID": 5, "context": "preserving smoothing filters bilateral filter ([217, 7]), and L0 gradient minimization smoothing ([240]) jointly without needing to know anything about the implementations of such filters given that input and output images can be accessed.", "startOffset": 47, "endOffset": 55}, {"referenceID": 238, "context": "preserving smoothing filters bilateral filter ([217, 7]), and L0 gradient minimization smoothing ([240]) jointly without needing to know anything about the implementations of such filters given that input and output images can be accessed.", "startOffset": 98, "endOffset": 103}, {"referenceID": 239, "context": "Alternatively, the same framework could be potentially to learn the behavior of commercial software as demonstrated by the authors with \u201ccopycat filter scheme\u201d using Photoshop R \u00a9 filters [241].", "startOffset": 188, "endOffset": 193}, {"referenceID": 112, "context": "[114] argue that the recursive input from VD2D can be viewed as modulatory \u2019gate\u2019 that the feature activations for structures of interest are enhanced while suppressing activations unrelated to structures of interest.", "startOffset": 0, "endOffset": 5}, {"referenceID": 51, "context": "Based on that assumption, it would be interesting to try to replace the VD2D altogether for example with datadriven edge detection network such as the N4-fields [53] or holistically-nested edge detection [238].", "startOffset": 161, "endOffset": 165}, {"referenceID": 236, "context": "Based on that assumption, it would be interesting to try to replace the VD2D altogether for example with datadriven edge detection network such as the N4-fields [53] or holistically-nested edge detection [238].", "startOffset": 204, "endOffset": 209}, {"referenceID": 51, "context": "N4-fields [53] was shown to segment two-dimension retinal vasculature from the DRIVE dataset [203] better than the Structured Edge detector [39] while the performance was not compared to traditional vessel enhancement filters.", "startOffset": 10, "endOffset": 14}, {"referenceID": 201, "context": "N4-fields [53] was shown to segment two-dimension retinal vasculature from the DRIVE dataset [203] better than the Structured Edge detector [39] while the performance was not compared to traditional vessel enhancement filters.", "startOffset": 93, "endOffset": 98}, {"referenceID": 37, "context": "N4-fields [53] was shown to segment two-dimension retinal vasculature from the DRIVE dataset [203] better than the Structured Edge detector [39] while the performance was not compared to traditional vessel enhancement filters.", "startOffset": 140, "endOffset": 144}, {"referenceID": 76, "context": "Alternatively one could try to integrate recent vessel enhancement filters as structured layers [78] within the ConvNet architecture to try to incorporate some domain knowledge without having to resort to totally hand-crafted features.", "startOffset": 96, "endOffset": 100}, {"referenceID": 142, "context": "[144], and the nearest neighborinspired detection of elongated structures by Sironi et al.", "startOffset": 0, "endOffset": 5}, {"referenceID": 195, "context": "[197].", "startOffset": 0, "endOffset": 5}, {"referenceID": 195, "context": "[197].", "startOffset": 0, "endOffset": 5}, {"referenceID": 99, "context": "The probability maps can have isolated erroneous responses, discontinuities and topological errors that are typically mitigated using post-processing techniques such as Conditional Random Fields (CRF, [101, 23, 119]), narrowband level sets [99], learned graph-cut segmentation [235] or Auto-Context [223] among others.", "startOffset": 201, "endOffset": 215}, {"referenceID": 21, "context": "The probability maps can have isolated erroneous responses, discontinuities and topological errors that are typically mitigated using post-processing techniques such as Conditional Random Fields (CRF, [101, 23, 119]), narrowband level sets [99], learned graph-cut segmentation [235] or Auto-Context [223] among others.", "startOffset": 201, "endOffset": 215}, {"referenceID": 117, "context": "The probability maps can have isolated erroneous responses, discontinuities and topological errors that are typically mitigated using post-processing techniques such as Conditional Random Fields (CRF, [101, 23, 119]), narrowband level sets [99], learned graph-cut segmentation [235] or Auto-Context [223] among others.", "startOffset": 201, "endOffset": 215}, {"referenceID": 97, "context": "The probability maps can have isolated erroneous responses, discontinuities and topological errors that are typically mitigated using post-processing techniques such as Conditional Random Fields (CRF, [101, 23, 119]), narrowband level sets [99], learned graph-cut segmentation [235] or Auto-Context [223] among others.", "startOffset": 240, "endOffset": 244}, {"referenceID": 233, "context": "The probability maps can have isolated erroneous responses, discontinuities and topological errors that are typically mitigated using post-processing techniques such as Conditional Random Fields (CRF, [101, 23, 119]), narrowband level sets [99], learned graph-cut segmentation [235] or Auto-Context [223] among others.", "startOffset": 277, "endOffset": 282}, {"referenceID": 221, "context": "The probability maps can have isolated erroneous responses, discontinuities and topological errors that are typically mitigated using post-processing techniques such as Conditional Random Fields (CRF, [101, 23, 119]), narrowband level sets [99], learned graph-cut segmentation [235] or Auto-Context [223] among others.", "startOffset": 299, "endOffset": 304}, {"referenceID": 112, "context": "Authors of the ZNN framework [114] chose to refine their segmentation of electron microscope stacks using a watershed-based algorithm developed by themselves [254], whereas recent work by Almasi et al.", "startOffset": 29, "endOffset": 34}, {"referenceID": 252, "context": "Authors of the ZNN framework [114] chose to refine their segmentation of electron microscope stacks using a watershed-based algorithm developed by themselves [254], whereas recent work by Almasi et al.", "startOffset": 158, "endOffset": 163}, {"referenceID": 2, "context": "[3] reconstructed microvascular networks from the output of active contours [22], and Sironi et al.", "startOffset": 0, "endOffset": 3}, {"referenceID": 20, "context": "[3] reconstructed microvascular networks from the output of active contours [22], and Sironi et al.", "startOffset": 76, "endOffset": 80}, {"referenceID": 195, "context": "[197] train an algorithm inspired by Nearest Neighbor Fields [53] to induce global consistency for the probability maps.", "startOffset": 0, "endOffset": 5}, {"referenceID": 51, "context": "[197] train an algorithm inspired by Nearest Neighbor Fields [53] to induce global consistency for the probability maps.", "startOffset": 61, "endOffset": 65}, {"referenceID": 2, "context": "Both those recent works [3, 197] can be seen complimentary and refining post-processing steps to our approach.", "startOffset": 24, "endOffset": 32}, {"referenceID": 195, "context": "Both those recent works [3, 197] can be seen complimentary and refining post-processing steps to our approach.", "startOffset": 24, "endOffset": 32}, {"referenceID": 71, "context": "[73] for example employ a recurrent neural network (RNN) for modeling temporal context in a video sequence for multi-frame super-resolution reconstruction.", "startOffset": 0, "endOffset": 4}, {"referenceID": 93, "context": "The time-extended super-resolution approach should in theory improve the quality of the interpolation in z- dimension when isotropic voxels are wanted, compared to deep learning based single-frame super-resolution [95], and traditional B-spline interpolation [76].", "startOffset": 214, "endOffset": 218}, {"referenceID": 74, "context": "The time-extended super-resolution approach should in theory improve the quality of the interpolation in z- dimension when isotropic voxels are wanted, compared to deep learning based single-frame super-resolution [95], and traditional B-spline interpolation [76].", "startOffset": 259, "endOffset": 263}, {"referenceID": 237, "context": "[239], who used a dictionary learning for surface reconstruction from a point cloud, which outperformed state-ofthe art methods in terms of accuracy, robustness to noise and outliers, and geometric feature preservation among other criteria.", "startOffset": 0, "endOffset": 5}, {"referenceID": 79, "context": "[81] demonstrated how they could learn optimal bilateral filter parameters for threedimensional mesh denoising that could be thus used as a post-processing step for surface reconstruction.", "startOffset": 0, "endOffset": 4}, {"referenceID": 76, "context": "[78] demonstrated how to backpropagate global structured matrix computation such as normalized cuts or higher-order pooling.", "startOffset": 0, "endOffset": 4}, {"referenceID": 223, "context": "[225] for optimizing a Rand index with simple connected component labeling (MALIS, which is to be implemented in the ZNN framework used by us).", "startOffset": 0, "endOffset": 5}, {"referenceID": 213, "context": "Currently there are not many publicly available software for dense image segmentation for volumetric 3D data, so we were constrained in our choice between GPU-accelerated Theano [215] and the CPU-accelerated ZNN [253].", "startOffset": 178, "endOffset": 183}, {"referenceID": 251, "context": "Currently there are not many publicly available software for dense image segmentation for volumetric 3D data, so we were constrained in our choice between GPU-accelerated Theano [215] and the CPU-accelerated ZNN [253].", "startOffset": 212, "endOffset": 217}, {"referenceID": 21, "context": "The Caffe-derived DeepLab [23, 155] with both CPU and GPU acceleration options was not supporting efficient 3D ConvNets as it were the case with Caffe", "startOffset": 26, "endOffset": 35}, {"referenceID": 153, "context": "The Caffe-derived DeepLab [23, 155] with both CPU and GPU acceleration options was not supporting efficient 3D ConvNets as it were the case with Caffe", "startOffset": 26, "endOffset": 35}, {"referenceID": 229, "context": "The image restoration part could for example consist of joint model for denoising [231], deconvolution [242], interpolation (super-resolution) [95], inpainting [20], motion artifact correction, and image-based spectral unmixing if multiple dyes were used.", "startOffset": 82, "endOffset": 87}, {"referenceID": 240, "context": "The image restoration part could for example consist of joint model for denoising [231], deconvolution [242], interpolation (super-resolution) [95], inpainting [20], motion artifact correction, and image-based spectral unmixing if multiple dyes were used.", "startOffset": 103, "endOffset": 108}, {"referenceID": 93, "context": "The image restoration part could for example consist of joint model for denoising [231], deconvolution [242], interpolation (super-resolution) [95], inpainting [20], motion artifact correction, and image-based spectral unmixing if multiple dyes were used.", "startOffset": 143, "endOffset": 147}, {"referenceID": 18, "context": "The image restoration part could for example consist of joint model for denoising [231], deconvolution [242], interpolation (super-resolution) [95], inpainting [20], motion artifact correction, and image-based spectral unmixing if multiple dyes were used.", "startOffset": 160, "endOffset": 164}, {"referenceID": 198, "context": "The added temporal support is needed to estimate motion artifacts [200], and it is able exploit the temporal dependency of vasculature (i.", "startOffset": 66, "endOffset": 71}, {"referenceID": 71, "context": "vascular diameter and position changes are not dramatic, better phrase here maybe) and in theory should improve the estimates of all the sub-components compared to the single stack scheme, as for example is the case for super-resolution [73].", "startOffset": 237, "endOffset": 241}, {"referenceID": 0, "context": "If multiple dyes are used simultaenously there is a potential problem of the dye signals \u201cleaking\u201d to other spectral channels that need to be mitigated computationally using for example some blind image separation technique [1].", "startOffset": 224, "endOffset": 227}, {"referenceID": 66, "context": "with fast independent component analysis [68] ).", "startOffset": 41, "endOffset": 45}, {"referenceID": 82, "context": "itself [84] as benchmarked by Jampani et al.", "startOffset": 7, "endOffset": 11}, {"referenceID": 79, "context": "[81] for example.", "startOffset": 0, "endOffset": 4}, {"referenceID": 251, "context": "The CPU-accelerated ZNN was shown to have efficient computational performance compared to GPU-accelerated Theano [253], and considering the recent price drop of Intel Xeon PhiTM Knights Corner generation of CPU accelerator cards, and introduction of supposedly more user-friendly Knights Landing generation, our choice of implementation seems relatively easy to accelerate in the future.", "startOffset": 113, "endOffset": 118}, {"referenceID": 165, "context": "io/) functions as a high level abstraction library for either Theano and for TensorFlow [167] so that the researcher can focus on the ideas and change flexibly the underlying backend between Theano and TensorFlow as one wishes.", "startOffset": 88, "endOffset": 93}, {"referenceID": 47, "context": "[49, 227, 144]) still requiring a refining segmentation algorithm for the ZNN output as the output is not a binary-valued mask, but rather a real-valued probability map.", "startOffset": 0, "endOffset": 14}, {"referenceID": 225, "context": "[49, 227, 144]) still requiring a refining segmentation algorithm for the ZNN output as the output is not a binary-valued mask, but rather a real-valued probability map.", "startOffset": 0, "endOffset": 14}, {"referenceID": 142, "context": "[49, 227, 144]) still requiring a refining segmentation algorithm for the ZNN output as the output is not a binary-valued mask, but rather a real-valued probability map.", "startOffset": 0, "endOffset": 14}, {"referenceID": 206, "context": "[208] used connected component clustering (bwlabeln of Matlab, union-find algorithm, [48]) with morphological filters to refine the ZNN output for retinal ganglion cell (RGC) arbor, while the most recent paper with ZNN [114] compared clustering to more sophisticated watershedbased segmentation [254] for segmenting neuronal boundaries from EM stacks.", "startOffset": 0, "endOffset": 5}, {"referenceID": 46, "context": "[208] used connected component clustering (bwlabeln of Matlab, union-find algorithm, [48]) with morphological filters to refine the ZNN output for retinal ganglion cell (RGC) arbor, while the most recent paper with ZNN [114] compared clustering to more sophisticated watershedbased segmentation [254] for segmenting neuronal boundaries from EM stacks.", "startOffset": 85, "endOffset": 89}, {"referenceID": 112, "context": "[208] used connected component clustering (bwlabeln of Matlab, union-find algorithm, [48]) with morphological filters to refine the ZNN output for retinal ganglion cell (RGC) arbor, while the most recent paper with ZNN [114] compared clustering to more sophisticated watershedbased segmentation [254] for segmenting neuronal boundaries from EM stacks.", "startOffset": 219, "endOffset": 224}, {"referenceID": 252, "context": "[208] used connected component clustering (bwlabeln of Matlab, union-find algorithm, [48]) with morphological filters to refine the ZNN output for retinal ganglion cell (RGC) arbor, while the most recent paper with ZNN [114] compared clustering to more sophisticated watershedbased segmentation [254] for segmenting neuronal boundaries from EM stacks.", "startOffset": 295, "endOffset": 300}, {"referenceID": 47, "context": "VMTK provided the following four vesselness enhancing filters: 1) Frangi\u2019s method [49], 2) Sato\u2019s method [180], 3) Vessel Enhancing Diffusion Filter [42], and 4) Vessel enhancing diffusion [136], with the Frangi\u2019s method being the default option.", "startOffset": 82, "endOffset": 86}, {"referenceID": 178, "context": "VMTK provided the following four vesselness enhancing filters: 1) Frangi\u2019s method [49], 2) Sato\u2019s method [180], 3) Vessel Enhancing Diffusion Filter [42], and 4) Vessel enhancing diffusion [136], with the Frangi\u2019s method being the default option.", "startOffset": 105, "endOffset": 110}, {"referenceID": 40, "context": "VMTK provided the following four vesselness enhancing filters: 1) Frangi\u2019s method [49], 2) Sato\u2019s method [180], 3) Vessel Enhancing Diffusion Filter [42], and 4) Vessel enhancing diffusion [136], with the Frangi\u2019s method being the default option.", "startOffset": 149, "endOffset": 153}, {"referenceID": 134, "context": "VMTK provided the following four vesselness enhancing filters: 1) Frangi\u2019s method [49], 2) Sato\u2019s method [180], 3) Vessel Enhancing Diffusion Filter [42], and 4) Vessel enhancing diffusion [136], with the Frangi\u2019s method being the default option.", "startOffset": 189, "endOffset": 194}, {"referenceID": 124, "context": "Vessel enhancing filter works as a pre-processing step in VMTK pipeline for the level set based vessel segmentation of VMTK before running the Marching Cubes algorithm derivative [126] for mesh reconstruction.", "startOffset": 179, "endOffset": 184}, {"referenceID": 180, "context": "For researchers who are the most comfortable using graphical tools such as Imaris (Bitplane AG, Zurich, Switzerland), or open-source ImageJ/FIJI platform [182], the proposed approach can be seen as automatic preprocessing step improving the performance of the following manual processing steps.", "startOffset": 154, "endOffset": 159}, {"referenceID": 119, "context": "For example the two-class (vessels, and non-vessels) vessel segmentation in Imaris by [121], required many user-supplied intensity thresholds which could have been automatized with our ConvNetbased approach, and the remaining steps for graph reconstruction could have done with existing pipeline.", "startOffset": 86, "endOffset": 91}, {"referenceID": 26, "context": "We are interested in quantifying the degree of blood-brain barrier opening (BBBO) following focused ultrasound stimulation [28, 151, 18].", "startOffset": 123, "endOffset": 136}, {"referenceID": 149, "context": "We are interested in quantifying the degree of blood-brain barrier opening (BBBO) following focused ultrasound stimulation [28, 151, 18].", "startOffset": 123, "endOffset": 136}, {"referenceID": 16, "context": "We are interested in quantifying the degree of blood-brain barrier opening (BBBO) following focused ultrasound stimulation [28, 151, 18].", "startOffset": 123, "endOffset": 136}, {"referenceID": 149, "context": "Experimentally, this is achieved by injecting a fluorescent dextran into the systemic vasculature, and then measuring the difference in fluorescence intensity between the vessels (foreground) and the surrounding tissue during BBBO [151, 18, 244].", "startOffset": 231, "endOffset": 245}, {"referenceID": 16, "context": "Experimentally, this is achieved by injecting a fluorescent dextran into the systemic vasculature, and then measuring the difference in fluorescence intensity between the vessels (foreground) and the surrounding tissue during BBBO [151, 18, 244].", "startOffset": 231, "endOffset": 245}, {"referenceID": 242, "context": "Experimentally, this is achieved by injecting a fluorescent dextran into the systemic vasculature, and then measuring the difference in fluorescence intensity between the vessels (foreground) and the surrounding tissue during BBBO [151, 18, 244].", "startOffset": 231, "endOffset": 245}, {"referenceID": 231, "context": "An alternative to using high-molecular weight dextrans is to use quantum dots that have narrower emission spectra for reduced dye crosstalk [233], and less leakage from vessels.", "startOffset": 140, "endOffset": 145}, {"referenceID": 204, "context": "Quantum dots have already been used to study the tumor vasculature [206].", "startOffset": 67, "endOffset": 72}, {"referenceID": 188, "context": "Another option is to use Alexa Fluor 633 dye, which selectively labels the walls of arteries that are greater than 15-\u03bcm in diameter[190].", "startOffset": 132, "endOffset": 137}, {"referenceID": 151, "context": "Recently, multiphoton fluorescent dyes with longer emission and excitation wavelengths [153, 93] have been gaining popularity due to their better transmission through biological tissue yielding improved penetration depths and signal-to-noise ratios (SNRs) [199, 70].", "startOffset": 87, "endOffset": 96}, {"referenceID": 91, "context": "Recently, multiphoton fluorescent dyes with longer emission and excitation wavelengths [153, 93] have been gaining popularity due to their better transmission through biological tissue yielding improved penetration depths and signal-to-noise ratios (SNRs) [199, 70].", "startOffset": 87, "endOffset": 96}, {"referenceID": 197, "context": "Recently, multiphoton fluorescent dyes with longer emission and excitation wavelengths [153, 93] have been gaining popularity due to their better transmission through biological tissue yielding improved penetration depths and signal-to-noise ratios (SNRs) [199, 70].", "startOffset": 256, "endOffset": 265}, {"referenceID": 68, "context": "Recently, multiphoton fluorescent dyes with longer emission and excitation wavelengths [153, 93] have been gaining popularity due to their better transmission through biological tissue yielding improved penetration depths and signal-to-noise ratios (SNRs) [199, 70].", "startOffset": 256, "endOffset": 265}, {"referenceID": 68, "context": "Another promising, yet not commonly employed, technique is to increase excitation laser wavelengths up to 1,700 nm [70], and switch to three-photon excitation.", "startOffset": 115, "endOffset": 119}, {"referenceID": 68, "context": "This also improves depth penetration, but also allows better optical sectioning due to higher non-linearity due to the z attenuation from the focal plane instead of z attenuation in two-photon regime, where z is the distance [70].", "startOffset": 225, "endOffset": 229}, {"referenceID": 11, "context": "This reduces noise from out-of-planes and tissue autofluorescence [13].", "startOffset": 66, "endOffset": 70}, {"referenceID": 12, "context": "Another way to improve SNR is to correct the optical aberrations caused by brain tissue in real-time by using adaptive optics [14].", "startOffset": 126, "endOffset": 130}, {"referenceID": 4, "context": "The use of adaptive optics originated from astronomy [6], where the correction of aberrations caused by atmospheric was able to give better image quality to astronomers.", "startOffset": 53, "endOffset": 56}, {"referenceID": 80, "context": "[82] demonstrated the increase in SNR for in vivo calcium imaging was especially significant atgreater depths.", "startOffset": 0, "endOffset": 4}, {"referenceID": 136, "context": "There have been some work devoted to separating arteries from veins either using computational techniques [138, 44], or using specific fluorescent labels that specifically label arteries such as Alexa Fluor 633 used by Shen et al.", "startOffset": 106, "endOffset": 115}, {"referenceID": 42, "context": "There have been some work devoted to separating arteries from veins either using computational techniques [138, 44], or using specific fluorescent labels that specifically label arteries such as Alexa Fluor 633 used by Shen et al.", "startOffset": 106, "endOffset": 115}, {"referenceID": 188, "context": "[190].", "startOffset": 0, "endOffset": 5}, {"referenceID": 206, "context": "Thus, the same network proposed initially for electron microscope image segmentation [208, 114] can be extended to other applications as demonstrated here for volumetric two-photon vasculature image segmentation.", "startOffset": 85, "endOffset": 95}, {"referenceID": 112, "context": "Thus, the same network proposed initially for electron microscope image segmentation [208, 114] can be extended to other applications as demonstrated here for volumetric two-photon vasculature image segmentation.", "startOffset": 85, "endOffset": 95}, {"referenceID": 173, "context": "To be used with vasculature datasets such as the VESSEL12 [175], it would be sufficient to use our pre-trained network and fine-tune the model, training with small learning rate, rather having to learn from scratch as typically done in specific image classification tasks exploiting some pre-trained network with broader dataset [21, 248].", "startOffset": 58, "endOffset": 63}, {"referenceID": 19, "context": "To be used with vasculature datasets such as the VESSEL12 [175], it would be sufficient to use our pre-trained network and fine-tune the model, training with small learning rate, rather having to learn from scratch as typically done in specific image classification tasks exploiting some pre-trained network with broader dataset [21, 248].", "startOffset": 329, "endOffset": 338}, {"referenceID": 246, "context": "To be used with vasculature datasets such as the VESSEL12 [175], it would be sufficient to use our pre-trained network and fine-tune the model, training with small learning rate, rather having to learn from scratch as typically done in specific image classification tasks exploiting some pre-trained network with broader dataset [21, 248].", "startOffset": 329, "endOffset": 338}, {"referenceID": 155, "context": "This is known as transfer learning or domain adaptation depending on the marginal data distribution [157].", "startOffset": 100, "endOffset": 105}, {"referenceID": 14, "context": "In practice with vascular segmentation, transfer learning approach correspond to a situation when a network trained for tubular dataset such as DIADEM [16, 159] is used as a basis, and fine-tuning that network using limited samples of multiphoton microscopy data.", "startOffset": 151, "endOffset": 160}, {"referenceID": 157, "context": "In practice with vascular segmentation, transfer learning approach correspond to a situation when a network trained for tubular dataset such as DIADEM [16, 159] is used as a basis, and fine-tuning that network using limited samples of multiphoton microscopy data.", "startOffset": 151, "endOffset": 160}, {"referenceID": 235, "context": "[237] combined ConvNet with a traditional dictionary-learning approach for domain adaptation that was able to exploit the local discriminative and structural information more efficiently than just using a ConvNet.", "startOffset": 0, "endOffset": 5}, {"referenceID": 194, "context": "[196], and combine that to our ConvNet-based approach to exploit the large number of unlabeled vessel stacks.", "startOffset": 0, "endOffset": 5}, {"referenceID": 181, "context": "In medical applications, there have been some effort of going around the high annotation cost by exploiting auxiliary data such as textual reports [183, 192], or image-level labels [102] (i.", "startOffset": 147, "endOffset": 157}, {"referenceID": 190, "context": "In medical applications, there have been some effort of going around the high annotation cost by exploiting auxiliary data such as textual reports [183, 192], or image-level labels [102] (i.", "startOffset": 147, "endOffset": 157}, {"referenceID": 100, "context": "In medical applications, there have been some effort of going around the high annotation cost by exploiting auxiliary data such as textual reports [183, 192], or image-level labels [102] (i.", "startOffset": 181, "endOffset": 186}, {"referenceID": 67, "context": "[69] recently demonstrated that the gap between fully supervised and weakly-supervised can be reduced compared to previous approaches by exploiting pre-trained ImageNet model for transfer learning with weak labels.", "startOffset": 0, "endOffset": 4}, {"referenceID": 234, "context": "We believe that part of the reason for lack of published work on volumetric vessel segmentation is due to lack of suitable training data, most of the biomedical image segmentation efforts being directed to fields such as electron microscopy [236, 114, 133, 173], and various clinical applications [64, 205, 183, 40] as the training data is readily available.", "startOffset": 241, "endOffset": 261}, {"referenceID": 112, "context": "We believe that part of the reason for lack of published work on volumetric vessel segmentation is due to lack of suitable training data, most of the biomedical image segmentation efforts being directed to fields such as electron microscopy [236, 114, 133, 173], and various clinical applications [64, 205, 183, 40] as the training data is readily available.", "startOffset": 241, "endOffset": 261}, {"referenceID": 131, "context": "We believe that part of the reason for lack of published work on volumetric vessel segmentation is due to lack of suitable training data, most of the biomedical image segmentation efforts being directed to fields such as electron microscopy [236, 114, 133, 173], and various clinical applications [64, 205, 183, 40] as the training data is readily available.", "startOffset": 241, "endOffset": 261}, {"referenceID": 171, "context": "We believe that part of the reason for lack of published work on volumetric vessel segmentation is due to lack of suitable training data, most of the biomedical image segmentation efforts being directed to fields such as electron microscopy [236, 114, 133, 173], and various clinical applications [64, 205, 183, 40] as the training data is readily available.", "startOffset": 241, "endOffset": 261}, {"referenceID": 62, "context": "We believe that part of the reason for lack of published work on volumetric vessel segmentation is due to lack of suitable training data, most of the biomedical image segmentation efforts being directed to fields such as electron microscopy [236, 114, 133, 173], and various clinical applications [64, 205, 183, 40] as the training data is readily available.", "startOffset": 297, "endOffset": 315}, {"referenceID": 203, "context": "We believe that part of the reason for lack of published work on volumetric vessel segmentation is due to lack of suitable training data, most of the biomedical image segmentation efforts being directed to fields such as electron microscopy [236, 114, 133, 173], and various clinical applications [64, 205, 183, 40] as the training data is readily available.", "startOffset": 297, "endOffset": 315}, {"referenceID": 181, "context": "We believe that part of the reason for lack of published work on volumetric vessel segmentation is due to lack of suitable training data, most of the biomedical image segmentation efforts being directed to fields such as electron microscopy [236, 114, 133, 173], and various clinical applications [64, 205, 183, 40] as the training data is readily available.", "startOffset": 297, "endOffset": 315}, {"referenceID": 38, "context": "We believe that part of the reason for lack of published work on volumetric vessel segmentation is due to lack of suitable training data, most of the biomedical image segmentation efforts being directed to fields such as electron microscopy [236, 114, 133, 173], and various clinical applications [64, 205, 183, 40] as the training data is readily available.", "startOffset": 297, "endOffset": 315}, {"referenceID": 48, "context": "We want to be part of creating a cultural shift from independent efforts of research groups toward an open source and collaborative neuroscience as datasets get larger and more complex [50, 54], as well as ensuring that our framework can be easily reproduced and developed further [161].", "startOffset": 185, "endOffset": 193}, {"referenceID": 52, "context": "We want to be part of creating a cultural shift from independent efforts of research groups toward an open source and collaborative neuroscience as datasets get larger and more complex [50, 54], as well as ensuring that our framework can be easily reproduced and developed further [161].", "startOffset": 185, "endOffset": 193}, {"referenceID": 159, "context": "We want to be part of creating a cultural shift from independent efforts of research groups toward an open source and collaborative neuroscience as datasets get larger and more complex [50, 54], as well as ensuring that our framework can be easily reproduced and developed further [161].", "startOffset": 281, "endOffset": 286}, {"referenceID": 112, "context": "We have made the Matlab code available based on the opensource ZNN framework [114, 253].", "startOffset": 77, "endOffset": 87}, {"referenceID": 251, "context": "We have made the Matlab code available based on the opensource ZNN framework [114, 253].", "startOffset": 77, "endOffset": 87}, {"referenceID": 213, "context": "In contrast to GPUaccelerated frameworks such as Theano [215], the ZNN is optimized to run on CPU while reaching relatively similar performance compared GPU-accelerated approaches [253].", "startOffset": 56, "endOffset": 61}, {"referenceID": 251, "context": "In contrast to GPUaccelerated frameworks such as Theano [215], the ZNN is optimized to run on CPU while reaching relatively similar performance compared GPU-accelerated approaches [253].", "startOffset": 180, "endOffset": 185}], "year": 2016, "abstractText": "Recently there has been an increasing trend to use deep learning frameworks for both 2D consumer images and for 3D medical images. However, there has been little effort to use deep frameworks for volumetric vascular segmentation. We wanted to address this by providing a freely available dataset of 12 annotated two-photon vasculature microscopy stacks. We demonstrated the use of deep learning framework consisting both 2D and 3D convolutional filters (ConvNet). Our hybrid 2D-3D architecture produced promising segmentation result. We derived the architectures from Lee et al. who used the ZNN framework initially designed for electron microscope image segmentation. We hope that by sharing our volumetric vasculature datasets, we will inspire other researchers to experiment with vasculature dataset and improve the used network architectures.", "creator": "LaTeX with hyperref package"}}}