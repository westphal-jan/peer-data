{"id": "1606.02556", "review": {"conference": "nips", "VERSION": "v1", "DATE_OF_SUBMISSION": "8-Jun-2016", "title": "DISCO Nets: DISsimilarity COefficient Networks", "abstract": "examples present no new type dubbed probabilistic conditioning incorporating so call phantom coefficient networks ( disco currents ). theta channels allow learners towards efficiently exit from a posterior system weighted under a neural model. during training, disco nets continuously accessed by minimising the dissimilarity coefficient beyond the prior distribution and target actual distribution. this allows for directly tailor the training to random loss inherent upon the response at hand. we well describe cv ( i ) are modeling uncertainty on the output value, disco nat complement equivalent non - probabilistic predictive networks f ( ii ) induced nets loosely model the value of calculated output, outperforming existing probabilistic variables via replacing current neural protocols.", "histories": [["v1", "Wed, 8 Jun 2016 13:57:44 GMT  (4407kb,D)", "http://arxiv.org/abs/1606.02556v1", null], ["v2", "Wed, 15 Jun 2016 16:01:04 GMT  (4408kb,D)", "http://arxiv.org/abs/1606.02556v2", null], ["v3", "Thu, 16 Jun 2016 07:45:20 GMT  (4410kb,D)", "http://arxiv.org/abs/1606.02556v3", null], ["v4", "Wed, 24 Aug 2016 15:19:45 GMT  (4410kb,D)", "http://arxiv.org/abs/1606.02556v4", null], ["v5", "Fri, 28 Oct 2016 11:27:45 GMT  (4377kb,D)", "http://arxiv.org/abs/1606.02556v5", null]], "reviews": [], "SUBJECTS": "cs.CV cs.AI", "authors": ["diane bouchacourt", "m pawan kumar", "sebastian nowozin"], "accepted": true, "id": "1606.02556"}, "pdf": {"name": "1606.02556.pdf", "metadata": {"source": "CRF", "title": "DISCO Nets: DISsimilarity COefficient Networks", "authors": ["Diane Bouchacourt", "Sebastian Nowozin", "Pawan Kumar"], "emails": ["diane@robots.ox.ac.uk", "sebastian.nowozin@microsoft.com", "pawan@robots.ox.ac.uk"], "sections": [{"heading": "1 Introduction", "text": "We are interested in the class of problems that require the prediction of a structured output y \u2208 Y given an input x \u2208 X . Complex applications often have large uncertainty on the correct value of y. For example, consider the task of hand pose estimation from depth images, where one wants to accurately estimate the pose y of a hand given a depth image x. The depth image often has some occlusions and missing depth values and this results in some uncertainty on the pose of the hand. It is, therefore, natural to use probabilistic models that are capable of representing this uncertainty. Often, the capacity of the model is restricted and cannot represent the true distribution perfectly. In this case, the choice of the learning objective influences final performance. Similar to Lacoste-Julien et al. [11], we argue that the learning objective should be tailored to the evaluation loss in order to obtain the best performance with respect to this loss. In details, we denote by \u2206training the loss function employed during model training, and by \u2206task the loss employed to evaluate the model\u2019s performance.\nWe present a simple example to illustrate the point made above. We consider a training dataset D = {xn, n = 1..N} sampled from a mixture of two bidimensional Gaussian. We train two probabilistic models, Model A and Model B, to capture the data probability distribution. Each model is able to represent a bidimensional Gaussian distribution with diagonal covariance parametrised by (\u00b51, \u00b52, \u03c31, \u03c32). Each model is trained by minimising its probabilistic objective function, defined by the training loss \u2206training. We refer the reader to the appendix for details on the objective function. For x = (x1, x2),x\u2032 = (x\u20321, x \u2032 2) \u2208 R2, the training loss of Model A emphasises the first dimension of the data, that is, \u2206A(x\u2212 x\u2032) = (10\u00d7 (x1 \u2212 x\u20321)2 + 0.1\u00d7 (x2 \u2212 x\u20322)2) 1/2. In the case of Model B this is the opposite, that is, \u2206B(x \u2212 x\u2032) = (0.1 \u00d7 (x1 \u2212 x\u20321)2 + 10 \u00d7 (x2 \u2212 x\u20322)2) 1/2. None of the models will be able to recover the true data distribution since they do not have the ability to represent a mixture of Gaussian. In other words, we cannot avoid model error, similarly to the real data scenario. Each model performs a grid search over the best parameters values for (\u00b51, \u00b52, \u03c31, \u03c32). Figure 1 shows the contours of the Mixture of Gaussian distribution of the data (in black), and the contour of the Gaussian fitted by each model (in red and green). Detailed setting of this example is available in the appendix.\n29th Conference on Neural Information Processing Systems (NIPS 2016), Barcelona, Spain.\nar X\niv :1\n60 6.\n02 55\n6v 1\n[ cs\n.C V\n] 8\nJ un\nAs expected, the fitted Gaussian distributions differ according to \u2206training employed. Table 1 shows that the loss on the test set, evaluated with \u2206task, is minimised if \u2206training = \u2206task. This simple example illustrates the advantage to being able to tailor the model\u2019s training objective function to have \u2206training = \u2206task. This is in contrast to the commonly employed learning objectives we present in Section 2, that are agnostic of the evaluation loss.\nIn order to alleviate the aforementioned deficiency of the state-of-the-art, we introduce DISCO Nets, a new class of probabilistic model. DISCO Nets represent PT , the true posterior distribution of the data, with a distribution PG parametrised by a neural network. We design a learning objective based on a dissimilarity coefficient between PT and PG. The dissimilarity coefficient we employ was first introduced by Rao [21] and is defined for any non-negative symmetric loss function. Thus, any loss function can be incorporated in our setting, allowing the user to tailor DISCO Nets to his or her needs. Finally, contrarily to existing probabilistic models presented in Section 2, DISCO Nets do not require any specific architecture or training procedure, making them an efficient and easy-to-use class of model."}, {"heading": "2 Related Work", "text": "Deep neural networks, and in particular, Convolutional Neural Networks (CNNs) are comprised of several convolutional layers, followed by one or more fully connected (dense) layers, interleaved by non-linear function(s) and (optionally) pooling. Recent probabilistic models use CNNs to represent non-linear functions of the data. We observe that such models separate into two types. The first type of model does not explicitly compute the probability distribution of interest. Rather, these models allow the user to sample from this distribution by feeding the CNN with some noise z. Among such models, Generative Adversarial Networks (GAN) presented in Goodfellow et al. [6] are very popular and have been used in several computer vision applications, for example in Denton et al. [1], Radford et al. [20], Springenberg [24] and Yan et al. [27]. A GAN model consists of two networks, simultaneously trained in an adversarial manner. A generative model, referred as the Generator G, is trained to replicate the data from noise, while an adversarial discriminative model, referred as the Discriminator D, is trained to identify whether a sample comes from the true data or from G. The GAN training objective is based on a minimax game between the two networks and approximately optimizes a Jensen-Shannon divergence. However, as mentioned in Goodfellow et al. [6] and Radford et al. [20], GAN models require very careful design of the networks\u2019 architecture. Their training procedure is tedious and tends to oscillate. GAN models have been generalized to conditional GAN (cGAN) in Mirza and Osindero [15], where some additional input information can be fed to the Generator and the Discriminator. For example in Mirza and Osindero [15] a cGAN model generates tags corresponding to an image. Gauthier [4] applies cGAN to face generation. Reed et al. [22] propose to generate images of flowers with a cGAN model, where the conditional information is a word description of the flower to generate1. While the application of cGAN is very promising, little quantitative evaluation has been done. Furthermore, cGAN models suffer from the same difficulties we mentioned for non-conditional GAN. Another line of work has developed towards the use of statistical hypothesis testing to learn probabilistic models. The works presented in Dziugaite et al. [2] and Li et al. [13] propose to train generative deep networks with an objective function based on the Maximum Mean Discrepancy (MMD) method. The MMD method, from Gretton et al. [7, 8], is a statistical hypothesis testing method to assess if two probabilistic\n1At the time writing, we do not have access to the full paper of Reed et al. [22] and therefore cannot take advantage of this work in our experimental comparison.\ndistributions are similar. As mentioned in Dziugaite et al. [2], the MMD test can been seen as playing the role of an adversary.\nThe second type of model approximates intractable posterior distributions with use of variational inference. The Variational Auto-Encoders (VAE) presented in Kingma and Welling [9] is composed of a probabilistic encoder and a probabilistic decoder. The probabilistic encoder is fed with the input x \u2208 X and produces a posterior distribution P (z|x) over the possible values of noise z that could have generated x. The probabilistic decoder learns to map the noise z back to the data space X . The training of VAE uses an objective function based on a Kullback-Leibler Divergence. VAE and GAN models have been combined in Makhzani et al. [14], where the authors propose to regularise autoencoders with an adversarial network. The adversarial network ensures that the posterior distribution P (z|x) matches an arbitrary prior P (z).\nIn hand pose estimation, imagine the user wants to obtain accurate positions of the thumb and the index finger but does not need accurate locations of the other fingers. The task loss \u2206task might be based on a weighted L2-norm between the predicted and the ground-truth poses, with high weights on the thumb and the index. Existing probabilistic models cannot be tailored to task-specific losses and we propose the DISsimilarity COefficient Networks (DISCO Nets) to alleviate this deficiency."}, {"heading": "3 DISCO Nets", "text": "We begin the description of our model by specifying how it can be used to generate samples from the posterior distribution, and how the samples can in turn be employed to provide a pointwise estimate. In the subsequent subsection, we describe how to estimate the parameters of the model using a training data set."}, {"heading": "3.1 Prediction", "text": "Sampling. A DISCO Net consists of several convolutional and dense layers (interleaved by nonlinear function(s) and possibly pooling) and takes as input a pair (x, z) \u2208 X \u00d7 Z , where x is input data and z is some random noise. Given one pair (x, z), the DISCO Net produces a value for the output y. In the example of hand pose estimation, the input depth image x is fed to the convolutional layers. The output of the last convolutional layer is flattened and concatenated with a noise sample z. The resulting vector is fed to several dense layers, and the last dense layer outputs a pose y. From a single depth image x, by using different noise samples, the DISCO Net produces different pose candidates for the depth image. This process is illustrated in Figure 2. Importantly, DISCO Nets are flexible in the choice of the architecture. For example, the noise could be concatenated at any stage of the network, including at the start.\nWe denote PG the distribution that is parametrised by the DISCO Net\u2019s neural network. For a given input x, DISCO Nets provide the user with samples y drawn from PG(y|x) without requiring the expensive computation of (often intractable) partition function. In the remainder of the paper we consider x \u2208 Rdx ,y \u2208 Rdy and z \u2208 Rdz .\nPointwise Prediction. In order to obtain a single prediction y for a given input x, DISCO Nets use the principle of Maximum Expected Utility (MEU), similarly to Premachandran et al. [19].\nThe prediction y\u2206task maximises the expected utility, or rather minimises the expected task-specific loss \u2206task, estimated using the sampled candidates. Formally, the prediction is made as follows:\ny\u2206task = argmax k\u2208[1,K] EU(yk) = argmin k\u2208[1,K] K\u2211 k\u2032=1 \u2206task(yk,y \u2032 k) (1)\nwhere (y1, ...,yK) are the candidate outputs sampled for the single input x. Details on the MEU method are in the appendix."}, {"heading": "3.2 Learning DISCO Nets", "text": "Objective Function. We want DISCO Nets to accurately model, with PG(y|x), the true probability of the data PT (y|x). In other words, PG(y|x) should be as similar as possible to PT (y|x). This similarity should be evaluated with respect to the loss specific to the task at hand. Thus, given any non-negative symmetric loss function between two outputs \u2206(y,y\u2032) with (y,y\u2032) \u2208 Y \u00d7 Y , we employ a diversity coefficient that is the expected loss between two samples drawn randomly from the two distributions. Formally, the diversity coefficient is defined as:\nDIV\u2206(PT , PG) = \u222b x\u2208X \u222b y\u2208Y \u222b y\u2032\u2208Y \u2206(y,y\u2032)PT (y|x)PG(y\u2032|x)PT (x)dydy\u2032dx (2)\nIntuitively, we should minimise this diversity so that PG(y|x) is as similar as possible to PT (y|x). However there is uncertainty on the output y to predict for a given x. In other words, PT (y|x) is diverse and PG(y|x) should be diverse as well. Thus we encourage PG(y|x) to provide sample outputs, for a given x, that are different from each other by minimising the following dissimilarity coefficient:\nDISC\u2206(PT , PG) = DIV\u2206(PT , PG)\u2212 \u03b3DIV\u2206(PG, PG)\u2212 (1\u2212 \u03b3)DIV\u2206(PT , PT ) (3) with \u03b3 \u2208 [0, 1]. The dissimilarity DISC\u2206(PT , PG) is the difference between the diversity between PT and PG, and an affine combination of the diversity of each distribution. These coefficients were introduced by Rao [21] with \u03b3 = 1/2 and used for latent variable models in Kumar et al. [10]. We do not need to consider the term DIV\u2206(PT , PT ) as it is a constant in our problem, and thus DISCO Nets\u2019 objective function is defined as follows:\nF = DIV\u2206(PT , PG)\u2212 \u03b3DIV\u2206(PG, PG) (4) When minimising F , the term \u03b3DIV\u2206(PG, PG) encourages PG(y|x) to be diverse. The value of \u03b3 balances between the two goals of PG(y|x), that are providing accurate outputs while being diverse.\nOptimisation. Let us consider a composed ofN examples input-output pairs D = {(xn,yn), n = 1..N}. In order to train DISCO Nets, we need to compute the objective function (4). We do not have access to the true probability distributions PT (y,x) and PT (x). To overcome this deficiency, we construct estimators of each diversity term DIV\u2206(PT , PG) and DIV\u2206(PG, PG). First, we take an empirical distribution of the data, that is, taking ground-truth pairs (xn,yn). We then estimate each distribution PG(y|xn) by sampling K outputs from our model for each xn. This gives us an unbiased estimate of each diversity term, defined as:\nD\u0302IV\u2206(PT , PG) = 1\nN N\u2211 n=1 1 K K\u2211 k=1 \u2206(yn, G(zk,xn;\u03b8))\nD\u0302IV\u2206(PG, PG) = 1\nK(K \u2212 1) K\u2211 k=1 K\u2211 k\u2032=1,k\u2032 6=k \u2206(G(zk,xn;\u03b8), G(zk\u2032 ,xn;\u03b8))\n(5)\nTo summarise, we have an unbiased estimate of the DISCO Nets\u2019 objective function of equation (4) defined as:\nF\u0302 (\u2206,\u03b8) = D\u0302IV\u2206(PT , PG)\u2212 \u03b3D\u0302IV\u2206(PG, PG) (6) where yk = G(zk,xn;\u03b8) is a candidate output sampled from DISCO Nets for (xn,zk), and \u03b8 are the parameters of DISCO Nets. It is important to note that the second term of equation (6) is summing over k and k\u2032 6= k since G(zk,xn;\u03b8) and G(zk\u2032 ,xn;\u03b8) must be two independent samples. The parameters \u03b8 are learned by Gradient Descent. Algorithm 1 shows the training of DISCO Nets. In steps 4 and 5 of Algorithm 1, we draw K random noise vectors (zn,1, ...zn,k) per input example xn, and generateK candidate outputsG(zn,k,xn;\u03b8) for this input. This allow us to compute an unbiased estimate of the gradient in step 7. For clarity, in the remainder of the paper we do not explicitely write the parameters \u03b8 and write G(zk,xn).\nAlgorithm 1: DISCO Nets Training algorithm. 1 for t=1...T epochs do 2 Sample minibatch of b training example pairs {(x1,y1)...(xb,yb)}. 3 for n=1...b do 4 Sample K random noise vectors (zn,1, ...zn,k) for training example xn 5 Generate K candidate outputs G(zn,k,xn;\u03b8), k = 1..K for training example xn 6 end 7 Update parameters \u03b8t \u2190 \u03b8t\u22121 by descending the gradient of equation (6) : \u2207\u03b8F\u0302 (\u2206,\u03b8). 8 end\nProper Scoring Rule. Any non-negative symmetric loss function \u2206 can be incorporated in the objective function of DISCO Nets. However, if the dissimilarity coefficient of equation (4) is a strictly proper scoring rule as defined in Gneiting and Raftery [5], it is ensured to be minimised only when PG(y|x) is the true conditional distribution PT (y|x). By theorem 5 in Gneiting and Raftery [5], this is the case, for example, if we take as loss function \u2206\u03b2(y,y\u2032) = ||y \u2212 y\u2032||\u03b22 = ( \u2211dy i=1 |(yi \u2212 y\u2032i|2)\n\u03b2/2 with \u03b2 \u2208 [0, 2] excluding 0 and 2, and use \u03b3 = 12 . In this setting, our training objective boils down to:\nF\u0302 (\u2206,\u03b8) = 1\nN\n\u2211N n=1 [ 1 K \u2211 k ||yn \u2212G(zk,xn)|| \u03b2 2 \u2212 1 2\n1 K(K \u2212 1) \u2211 k \u2211 k\u2032 6=k ||G(zk\u2032 ,xn)\u2212G(zk,xn)|| \u03b2 2 ] (7)\nThis specific case of our objective function is related to the Maximum Mean Discrepancy method (MMD) of Gretton et al. [7, 8]. Indeed as shown in Proposition 3 of Sch\u00f6lkopf [23], the function k : Y \u00d7 Y \u2192 R defined as k(y,y\u2032) = ||y \u2212 y\u2032||\u03b22 for 0 < \u03b2 \u2264 2 is a conditionally positive definite kernel, that is a specific type of positive definite kernel. It would be interesting to see if the properties of the MMD estimator extend to conditionally positive definite kernels and to our setting where the posterior distribution is conditioned on the input x."}, {"heading": "4 Experiments : Hand Pose Estimation", "text": "Given a depth image x, which often contains occlusions and missing values, we wish to predict the hand pose y. We use the NYU Hand Pose dataset of Tompson et al. [26] to estimate the efficiency of DISCO Nets for this task."}, {"heading": "4.1 Experimental Setup", "text": "NYU Hand Pose Dataset. The NYU Hand pose dataset of Tompson et al. [26] contains 8252 testing and 72,757 training frames of captured RGBD data with ground-truth hand pose information. The training set is composed of images of one person whereas the testing set gathers samples from two persons. For each frame, the RGBD data from 3 Kinects is provided: a frontal view and 2 side views. In our experiments we use only the depth data from the frontal view. While the ground truth contains J = 36 annotated joints, we follow the evaluation protocol of Oberweger et al. [16, 17] and use the same subset of J = 14 joints. We also perform the same data preprocessing as in Oberweger et al. [16, 17], and extract a fixed-size metric cube around the hand from the depth image. We resize the depth values within the cube to a 128\u00d7 128 patch and normalized them in [\u22121, 1]. Pixels deeper than the back of the cube and missing depth values are both set to a depth of 1.\nMethods. We employ loss functions between two outputs of the form used in equation (7), that is, \u2206training = \u2206\u03b2(y,y\u2032) = ||y \u2212 y\u2032||\u03b22 . With this loss the dissimilarity coefficient is a strictly proper scoring rule when \u03b3 = 12 . Our first goal is to assess the advantages of DISCO Nets with respect to non-probabilistic deep networks. To do so, we compare two models. One model, referred as DISCO\u03b2,\u03b3 , is a DISCO Nets probabilistic model, with \u03b3 6= 0 in the dissimilarity coefficient of equation (6). The other model, referred as BASE\u03b2 , is a non-probabilistic model, by taking \u03b3 = 0 in the objective function of equation (6) and no noise is concatenated. This corresponds to a classic deep network which for a given input x generates a single output y = G(x). Note that we write G(x) and not G(z,x) since no noise is concatenated.\nEvaluation Metrics. We use the metrics of Table 2. These metrics include classic non-probabilistic metrics for hand pose estimation employed in Oberweger et al. [16, 17] and Taylor et al. [25], that\nare, the Mean Joint Euclidean Error (MeJEE), the Max Joint Euclidean Error (MaJEE) and the Fraction of Frames within distance (FF). Oberweger et al. [16, 17] present the metric FF as the most challenging metric for hand pose estimation. These metrics use losses based on the norm ||.||jointj2 , that is the Euclidean distance between the prediction and the ground-truth for the joint j. They require a single pointwise prediction referred as y\u2206, where \u2206 is specific to each metric. The pointwise y\u2206 is chosen with the MEU method among the K candidates. For the non-probabilistic model BASE\u03b2 , only a single pointwise predicted output y is available. Thus we artificially construct theK candidates by adding some Gaussian random noise2 of mean 0 and diagonal covariance \u03a3 = \u03c3I. We use \u03c3 \u2208 {1mm, 5mm, 10mm} and refer to the model as BASE\u03b2,\u03c3. We added a probabilistic metric that we call ProbLoss, evaluated on K candidate poses for a given depth image. As observed in Fukumizu et al. [3], kernel density estimation fails in this scenario due to the high dimensionality of y.\nArchitecture. The novelty of DISCO Nets resides in their objective function. They do not require the use of a specific network architecture. This allows us to design a simple network architecture inspired by Oberweger et al. [17]. The architecture is shown in Figure 2. The input depth image x is fed to 2 convolutional layers, each having 8 filters, with kernels of size 5 \u00d7 5, with stride 1, followed by Rectified Linear Units (ReLUs) and Max Pooling layers of kernel size 3\u00d7 3. A third and last convolutional layer has 8 filters, with kernels of size 5 \u00d7 5, with stride 1, followed by a Rectified Linear Unit. The ouput of the convolution is concatenated to the random noise vector z of size dz = 200, drawn from a uniform distribution in [\u22121, 1]. The result of the concatenation is fed to 2 dense layers of output size 1024, with ReLUs, and a third dense layer that outputs the candidate pose y \u2208 R3\u00d7J . For the non-probabilistic BASE\u03b2,\u03c3 model no noise is concatenated as only a pointwise estimate is produced.\nTraining. For DISCO\u03b2,\u03b3 , we used \u03b3 = 0.5. We use \u03b2 = 1 in the loss function \u2206training(y,y\u2032) = ||y \u2212 y\u2032||\u03b22 , that is the Euclidean distance. This is a relevant choice to hand pose estimation given the evaluation metrics employed. We use 10,000 examples from the 72,757 training frames to construct a validation dataset and train only on 62,757 examples. Back-propagation is used with Stochastic Gradient Descent with a batchsize of 256. The learning rate is fixed to \u03bb = 0.01 and we use a momentum of m = 0.9 (see Polyak [18]). We also add L2-regularisation controlled by the parameter C. We use C = [0.0001, 0.001, 0.01] which is a relevant range as the comparative model BASE\u03b2 is best performing for C = 0.001. Note that DISCO Nets report consistent performances across the different values C, contrarily to BASE\u03b2 . We use 3 different random seeds to initialize each model network parameters. We report the performance of each model with its best cross-validated seed and C. We train all models for 400 epochs as it results in a change of less than 3% in the value of the loss on the validation dataset for BASE\u03b2 . Each epoch takes \u223c 20 seconds including monitoring of the loss on the validation set, that is more than 3000 training example frame per second on a single GPU NVIDIA-Titan X. We refer the reader to the appendix for details on the setting and the results. During training, K = 2 in Algorithm 1 and K = 100 for metrics evaluation.\n2We also evaluate the non-probabilistic model BASE\u03b2 using its pointwise prediction rather than the MEU method. Results are consistent and detailed in the appendix."}, {"heading": "4.2 The Advantage of DISCO Nets over Non-Probabilistic Networks", "text": "Quantitative Evaluation. Table 3 reports performances on the test dataset, with parameters crossvalidated using the validation set, of the two models we compare. We can see that our probabilistic model DISCO\u03b2=1,\u03b3=0.5 outperforms the non-probabilistic models BASE\u03b2=1,\u03c3 on all metrics. This confirms that by accurately modeling the uncertainty on the pose to output given the input depth image, DISCO Nets provide better prediction. Details in appendix show that the DISCO\u03b2=1,\u03b3=0.5 is best-performing on all metrics for all values of C.\nQualitative Evaluation. In Figure 3 we show candidate poses generated by DISCO\u03b2=1,\u03b3=0.5 for 3 testing examples. The top image shows the input depth image, and the bottom image shows the ground-truth pose (in grey) with 100 candidate outputs (superimposed in transparent red). The model predict the joint locations and we interpolate the joints with edges. If an edge is thinner and more opaque, it means the different predictions overlap and that the uncertainty on the location of the edge\u2019s joints is low. We can see that DISCO\u03b2=1,\u03b3=0.5 is able to capture relevant information on the structure of the hand.\n(a) When there are no occlusions, DISCO Nets model low uncertainty on all joints.\n(b) When the hand is half-fisted, DISCO Nets model the uncertainty on the location of the fingertips.\n(c) Here the fingertips of all fingers but the forefinger are occluded and DISCO Nets model high uncertainty on them.\nFigure 3: Visualisation of DISCO\u03b2=1,\u03b3=0.5 predictions for 3 examples from the testing dataset. The top image shows the input depth image, and the bottom image shows the ground-truth pose in grey with 100 candidate outputs superimposed in transparent red. Best viewed in color."}, {"heading": "4.3 Comparison with existing probabilistic models.", "text": "We consider the applications of the conditional Generative Adversarial Networks (cGAN) model from Mirza and Osindero [15] and to the best of our knowledge cGAN has not been applied to pose estimation. In order to compare cGAN to DISCO Nets on hand pose estimation, several issues must be overcome. First, we must design a network architecture for the Discriminator. This is a first disadvantage of cGAN compared to DISCO Nets which require no adversary. Second, as mentioned in Goodfellow et al. [6] and Radford et al. [20], GAN (and thus cGAN) require very careful design of the networks\u2019 architecture and training procedure. In order to do a fair comparison, we followed the work in Mirza and Osindero [15] and practical advice for GAN presented in Larsen and S\u00f8nderby [12]. The Generator G has the same network architecture as DISCO\u03b2=1,\u03b3=0.5. We add batch normalization to help the training. The Discriminator D is composed a convolutional part that also take a depth image x as input. This part is the same as the convolutional part of G. The output of the convolutions is concatenated either the ground-truth pose for x or the pose generated by G and fed to 2 dense layers with 200 hidden units. Dense layers apply dropout with a ratio of 0.5 and ReLUs. We use Maxout activation after the second dense layer. A third dense layer outputs a scalar value, on which we apply a sigmoid activation function. We try (i) cGAN, initialising all layers of D and G randomly, and (ii) cGANinit, fixed initialising the convolutional layers of G and D\nwith the trained best-performing DISCO\u03b2=1,\u03b3=0.5 of Section 6.3, and keeping these layers fixed (hence training only the dense layers). That is, the convolutional parts of G and D are fixed feature extractors for the depth image. This is a setting similar to the one employed for tag-annotation of images in Mirza and Osindero [15] 3. We refer the reader to appendix for details. Table 4 shows that the cGAN model obtains relevant results only when the convolutional layers of G and D are initialised with our trained model and kept fixed, that is cGANinit, fixed. These results are still worse than DISCO Nets performances. Moreover, since cGAN model require the training of the additional Discriminator network, each epoch of training requires \u223c 60 seconds compared to \u223c 20 seconds for the DISCO Nets model. Finally, we showed that we can easily construct an unbiased estimate of our probabilistic objective function of equation (4). Thus we compute the probabilistic objective of DISCO Nets, that is the metric ProbLoss. However it is not straightforward to estimate the objective function of cGAN, based on the Jensen-Shannon Divergence. As mentioned in Section 4.1 the output space size is too large to employ density estimation methods. While there may be a better architecture for cGAN, our experiments demonstrate the difficulty of training cGAN over DISCO Nets."}, {"heading": "4.4 Reference state-of-the-art values.", "text": "We train the best-performing DISCO\u03b2=1,\u03b3=0.5 of Section 6.3 on the entire dataset, and compare performances with state-of-the-art methods in Table 5 and Figure 4. These state-of-the-art methods are specifically designed for hand pose estimation. In Oberweger et al. [16] a constrained prior hand model, referred as NYU-Prior, is refined on each hand joint position to increase accuracy, referred as NYU-Prior-Refined. In Oberweger et al. [17], the input depth image is fed to a first network NYU-Init, that outputs a pose used to synthesize an image with a second network. The synthesized image is used with the input depth image to derive a pose update. We refer to the whole model as NYU-Feedback. On the contrary, DISCO Nets uses a single network whose architecture is similar to NYU-Prior (without constraining on a pose prior). By accurately modeling the distribution of the pose given the depth image, DISCO Nets are able to obtain comparable performances to NYU-Prior and NYU-Prior-Refined. Furthermore, without any extra effort, DISCO Nets could be embedded in the presented refinement and feedback methods, possibly boosting state-of-the-art performances."}, {"heading": "5 Discussion.", "text": "We presented DISCO Nets, a new family of probabilistic model based on deep networks. DISCO Nets employ a prediction and training procedure based on the minimisation of a dissimilarity coefficient. Theoretically, this ensures that DISCO Nets accurately capture uncertainty on the correct output to predict given an input. Experimental results on the task of hand pose estimation consistently support our theoretical hypothesis as DISCO Nets outperform non-probabilistic equivalent models, and existing probabilistic models. Furthermore, DISCO Nets can be tailored to the task to perform. This allows a possible user to train them to tackle different problems of interest. As their novelty resides mainly in their objective function, DISCO Nets do not require any specific architecture and can be easily applied to new problems.\nWe contemplate several directions for future work. First, we will apply DISCO Nets to other prediction problems where there is uncertainty on the ouput. Second, we would like to extend DISCO Nets to latent variables models, allowing us to apply DISCO Nets to diverse dataset where ground-truth annotations are missing or incomplete.\n3We also tried (iii) initialising the convolutional layers of G and D with the best DISCO\u03b2=1,\u03b3=0.5 from Section 6.3 and do not keep them fixed, but training was always divergent."}, {"heading": "6 Appendix", "text": ""}, {"heading": "6.1 Toy example experimental details.", "text": "In this section, we provide details on the toy example presented in Section 1. We used the following simple experimental setting. All covariances for the bidimensional distributions are diagonal, therefore all bidimensional Gaussian distributions are parametrised by 4 parameters (\u00b51, \u00b52, \u03c31, \u03c32) where \u00b5, \u03c3 is a mean-variance pair on each dimension. We consider a data distribution that is a mixture of 2 bidimensional Gaussian distributions, referred as GMM. The first Gaussian of the mixture, G1, is parametrised by (1, 1.5, 2, 0.8) and the second Gaussian G2 is parametrised by (0,\u22120.5, 0.7, 0.6). The mixture weights are 0.7 and 0.3, such that GMM = 0.7 \u00d7 G1 + 0.3 \u00d7 G2. We consider two models to capture the true data distribution GMM. Each model is able to represent a bidimensional Gaussian distribution parametrised by (\u00b51, \u00b52, \u03c31, \u03c32). The sets in which to search for the parameters are the same in both dimensions and both models. The set to search the means ranges from \u22123 to 3 by 1, and the set to search the variances ranges 0.1 to 2 by 0.5. The training dataset is composed of N = 10000 examples drawn randomly from GMM, denoted as (x1, ...,xN ). The testing dataset is composed of 1000 examples drawn randomly from GMM. During training, we draw K = 2 samples from the model and estimate the probabilistic loss defined as:\n1\nN N\u2211 n=1 [ 1 K \u2211 k \u2206M (xn, GM (zk))\u2212 1 2\n1 K(K \u2212 1) \u2211 k \u2211 k\u2032 6=k \u2206M (GM (zk\u2032), GM (zk)) ]\n(8)\nwhere M indexes the model, \u2206M is the model\u2019s specific loss, and G(zk))M is the kth sample drawn from M for the training data xn. During testing of a model, we draw K = 10 samples from the model and choose a pointwise prediction with the MEU method. The MEU method employs the same loss as the evaluation loss. Each model is tested with its own loss and the loss of the other model."}, {"heading": "6.2 Details on the MEU method", "text": "For an input x, to choose a single prediction y among K candidate outputs sampled for x, DISCO Nets use the principle of Maximum Expected Utility (MEU). The prediction y\u2206task maximises the expected utility, or rather minimises the expected task-specific loss \u2206task, estimated using the sampled candidates. Formally, the prediction is made as follows:\ny\u2206task = argmax k\u2208[1,K] EU(yk) = argmin k\u2208[1,K] K\u2211 k\u2032=1 \u2206task(yk,y \u2032 k) (9)\nwhere (y1, ...,yK) are the candidates output corresponding to the single input x. For example, for a given intput x, we need to choose a pointwise output to evaluate the Mean Joint Euclidean Error (MeJEE). We sample K candidate ouputs values for the input x, and pick:\ny\u2206MeJEE = argmin k\u2208[1,K] K\u2211 k\u2032=1 \u2206task(yk,y \u2032 k) = argmin k\u2208[1,K] K\u2211 k=1 1 J J\u2211 j=1 ||yj \u2212 yjk||2 (10)\nThen when we evaluate MeJEE, the loss encountered on the example x is \u2206MeJEE(yGT,y\u2206MeJEE ) where yGT is the ground-truth output that corresponds to x."}, {"heading": "6.3 Experimental details", "text": "We provide in this section additional details on the Hand Pose experiment of Section 6.3. We denote the training loss function \u2206training = \u2206\u03b2(y,y\u2032) = ||y \u2212 y\u2032||\u03b22 .\nCross-validation procedure. We substract I = 10000 examples from the 72757 training frames to construct a validation dataset. The validation examples are chosen at random and are the same for all experiments. Let us denote the examples pairs from the validation dataset as V = {xi,yi, i = 1..I}, and y\u2206training,i is the prediction for the ith example. During training, we monitor the value of the loss \u2206training on the validation dataset. In details, this loss is: Lval = 1\nI I\u2211 i=1 ||yi \u2212 y\u2206training,i|| \u03b2 2 (11)\nIn order to evaluate Lval for the model BASE\u03b2 , we simply use for y\u2206training the pointwise prediction of BASE\u03b2 . To monitor Lval for DISCO\u03b2,\u03b3 , we use the MEU method to pick y\u2206training . In the MEU method, we draw K = 100 samples per validation example. In order to reduce variance, we draw the 100 random noise vectors per example, {z1,1, ...zi,K , ..., zI,1, ...zI,K} once for all before starting the optimisation Algorithm 1. Indeed, contrarily to the random noise vector drawn to estimate the gradient of the training objective in step 4 of Algorithm 1, these noise vectors do not influence the training but are only used for monitoring purposes. They remain independent when the network\u2019s parameters are optimised. Finally, we choose for each model the best value of C and the best seed by taking the setting that gives the lowest final value of Lval.\nTraining procedure All network weights are initialised at random with a Gaussian distribution of mean 0 and standard deviation 0.01, all biases are initialised to 0. During training, the number of candidates outputs generated by the probabilistic models DISCO\u03b2,\u03b3 is K = 2. This is sufficient to construct an unbiased estimate of the gradient in step 7 of Algorithm 1. Note that in step 4 of Algorithm 1 we must draw new noise samples (zn,1, ...zn,k) for each training example at each iteration. Indeed, let us consider the iteration t on a training example xn. The values of the noise sampled for xn at iteration t \u2212 1, (zt\u22121n,1 , ...z t\u22121 n,k ), were used in the estimation of the gradient, and thus influenced the update \u03b8t \u2190 \u03b8t\u22121. Thus, we need to draw new sample to ensure that the K candidate outputs for xn, yn = G(ztn,k,xn;\u03b8t), k = 1..K, remain independent given xn and \u03b8t. We train all models for 400 epochs as it results in a change of less than 3% in the value of Lval for BASE\u03b2 . Convergence behavior is shown in Figures 5, 6 and 7.\nDetailed results We list here all results of the experiment presented in Section for all values of C, for the best seed for each C value. We report performances using the MEU method for choosing a pointwise prediction y\u2206 for an input x. However we can use 3 different methods that are:\n\u2022 MEU method. \u2022 MEAN method : pick for the non-probabilistic model BASE\u03b2,\u03c3 its pointwise prediction. Therefore\nthe value of the metrics MeJEE, MaJEE and FF are the same regardless of \u03c3. For DISCO\u03b3,\u03b2 , pick the mean of the K candidates.\n\u2022 RANDOM method : pick an output y at random among K candidates.\nDetailed results show that the model DISCO\u03b2=1,\u03b3=0.5 consistently outperforms BASE\u03b2=1,\u03c3 for all values of C and all methods, and that results are consistent across the pointwise prediction method employed. Tables 6, 7 and 8 present the results when we use the MEU method to choose the pointwise estimate.Tables 9, 10 and 11 present the results when we use the MEAN method. Tables 12, 13 and 14 present the results when we use the RANDOM method.\nDetailed comparison with cGAN. We aim at performing a fair comparison with the conditional Generative Adversarial Networks (cGAN) model presented in Mirza and Osindero [15]. However as mentioned in Section 4.3 we encountered several challenges. We present here additional details on the comparison with cGAN models.\nAs mentioned in Section 4.3, we tried 3 different training setting in order to apply cGAN to hand pose estimation on the NYU dataset. The setting cGAN initialises randomly the Discriminator and the Generator parameters. The setting cGANinit initialises the convolutional layers of both the Discriminator and the Generator with the trained convolutional layers of our best DISCO Nets from Section 6.3 without keeping it fixed. That is, we try to perform fine-tuning only. The setting cGANinit, fixed initialises the convolutional layers of both the Discriminator and the Generator with the trained convolutional layers of our best DISCO Nets from Section 6.3 and keep these part fixed. That is, the convolutional parts of the Generator and the Discriminator are feature extractors that are not trained. This is a setting similar to the one employed for tag-annotation of images in Mirza and Osindero [15].\nSince cGAN model require the training of the additional Discriminator network, each epoch of training requires \u223c 60 seconds compared to \u223c 20 seconds for DISCO Nets. Therefore, we were only able to use one random seed for the initialisation of the network parameters. However, DISCO Nets present a consistent behavior regardless of the seed employed for initialisation. We could expect a similar behavior for the cGAN model. The experimental setting is similar to the one of Section 6.3. We use the exact same training and validation sets as in Section 6.3. Back-propagation was used with Stochastic Gradient Descent. The learning rate is fixed to \u03bb = 0.01 and we use a momentum of m = 0.9. We use a batchsize of 256 samples. We also add L2-regularisation controlled by a parameter C. We use C = [1e\u22124, 1e\u22123, 1e\u22122]. We use the cross-validation procedure presented in Section 6.3 to cross-validate C. We train all models for 400 epochs. For C = 1e\u22124 we train for more epochs since 400 were not enough to have the final convergence of cGANinit, fixed (see Figure 8b). However, this does not help the cGAN performances compared to the one reported for 400 epochs, see Table 15. Figure 8 show the training behavior of the different settings of cGAN. When the curve is missing, it means that the model has diverged after the few first iterations and thus we cannot show its behavior. This is always the case forcGANinit.\n(a) Lval monitoring for cGan with C = 1e\u22124 for 400 epochs. (b) Lval monitoring for cGan with C = 1e\u22124. We trained for more than 1400 epochs as 400 epochs were not enough."}], "references": [{"title": "Deep generative image models using a Laplacian pyramid of adversarial networks", "author": ["E.L. Denton", "S. Chintala", "A. Szlam", "R. Fergus"], "venue": "In NIPS", "citeRegEx": "1", "shortCiteRegEx": "1", "year": 2015}, {"title": "Training generative neural networks via maximum mean discrepancy optimization", "author": ["G.K. Dziugaite", "D.M. Roy", "Z. Ghahramani"], "venue": "UAI", "citeRegEx": "2", "shortCiteRegEx": null, "year": 2015}, {"title": "Kernel Bayes\u2019 rule: Bayesian inference with positive definite kernels", "author": ["K. Fukumizu", "L. Song", "A. Gretton"], "venue": "JMLR", "citeRegEx": "3", "shortCiteRegEx": null, "year": 2013}, {"title": "Conditional generative adversarial nets for convolutional face generation", "author": ["J. Gauthier"], "venue": "Class Project for Stanford CS231N: Convolutional Neural Networks for Visual Recognition", "citeRegEx": "4", "shortCiteRegEx": null, "year": 2014}, {"title": "Strictly proper scoring rules", "author": ["T. Gneiting", "A.E. Raftery"], "venue": "prediction, and estimation. Journal of the American Statistical Association", "citeRegEx": "5", "shortCiteRegEx": null, "year": 2007}, {"title": "Generative adversarial nets", "author": ["I.J. Goodfellow", "J. Pouget-Abadie", "M. Mirza", "Bing Xu", "D. Warde-Farley", "S. Ozair", "A. Courville", "Y. Bengio"], "venue": "In NIPS", "citeRegEx": "6", "shortCiteRegEx": "6", "year": 2014}, {"title": "A kernel method for the two-sample problem", "author": ["A. Gretton", "K.M. Borgwardt", "M.J. Rasch", "B. Scholkopf", "A.J. Smola"], "venue": "NIPS", "citeRegEx": "7", "shortCiteRegEx": null, "year": 2007}, {"title": "A kernel two-sample test", "author": ["A. Gretton", "K.M. Borgwardt", "M.J. Rasch", "B. Scholkopf", "A.J. Smola"], "venue": "JMLR", "citeRegEx": "8", "shortCiteRegEx": null, "year": 2012}, {"title": "Auto-encoding variational Bayes", "author": ["D.P. Kingma", "M. Welling"], "venue": "ICLR", "citeRegEx": "9", "shortCiteRegEx": null, "year": 2014}, {"title": "Modeling latent variable uncertainty for loss-based learning", "author": ["M.P. Kumar", "B. Packer", "D. Koller"], "venue": "ICML", "citeRegEx": "10", "shortCiteRegEx": null, "year": 2012}, {"title": "Approximate inference for the loss-calibrated Bayesian", "author": ["S. Lacoste-Julien", "F. Huszar", "Z. Ghahramani"], "venue": "AISTATS", "citeRegEx": "11", "shortCiteRegEx": null, "year": 2011}, {"title": "Generative moment matching networks", "author": ["Y. Li", "K. Swersky", "R. Zemel"], "venue": "ICML", "citeRegEx": "13", "shortCiteRegEx": null, "year": 2015}, {"title": "Adversarial autoencoders", "author": ["A. Makhzani", "J. Shlens", "N. Jaitly", "I.J. Goodfellow"], "venue": "ICLR Workshop", "citeRegEx": "14", "shortCiteRegEx": null, "year": 2015}, {"title": "Conditional generative adversarial nets", "author": ["M. Mirza", "S. Osindero"], "venue": "NIPS Deep Learning Workshop", "citeRegEx": "15", "shortCiteRegEx": null, "year": 2014}, {"title": "Hands deep in deep learning for hand pose estimation", "author": ["M. Oberweger", "P. Wohlhart", "V. Lepetit"], "venue": "Computer Vision Winter Workshop", "citeRegEx": "16", "shortCiteRegEx": null, "year": 2015}, {"title": "Training a Feedback Loop for Hand Pose Estimation", "author": ["M. Oberweger", "P. Wohlhart", "V. Lepetit"], "venue": "ICCV", "citeRegEx": "17", "shortCiteRegEx": null, "year": 2015}, {"title": "Some methods of speeding up the convergence of iteration methods", "author": ["B.T. Polyak"], "venue": null, "citeRegEx": "18", "shortCiteRegEx": "18", "year": 1964}, {"title": "Empirical minimum Bayes risk prediction: How to extract an extra few% performance from vision models with just three more parameters", "author": ["V. Premachandran", "D. Tarlow", "D. Batra"], "venue": "CVPR", "citeRegEx": "19", "shortCiteRegEx": null, "year": 2014}, {"title": "Unsupervised representation learning with deep convolutional generative adversarial networks", "author": ["A. Radford", "L. Metz", "S. Chintala"], "venue": "ICLR", "citeRegEx": "20", "shortCiteRegEx": null, "year": 2015}, {"title": "Diversity and dissimilarity coefficients: A unified approach", "author": ["C.R. Rao"], "venue": "Theoretical Population Biology, pages Vol. 21, No. 1, pp 24\u201343", "citeRegEx": "21", "shortCiteRegEx": null, "year": 1982}, {"title": "Generative adversarial text to image synthesis", "author": ["S. Reed", "Z. Akata", "X. Yan", "L. Logeswaran", "H. Lee", "B. Schiele"], "venue": "ICML", "citeRegEx": "22", "shortCiteRegEx": null, "year": 2016}, {"title": "The kernel trick for distances", "author": ["B. Sch\u00f6lkopf"], "venue": "In NIPS", "citeRegEx": "23", "shortCiteRegEx": "23", "year": 2001}, {"title": "Unsupervised and semi-supervised learning with categorical generative adversarial networks", "author": ["J.T. Springenberg"], "venue": "ICLR", "citeRegEx": "24", "shortCiteRegEx": null, "year": 2016}, {"title": "The vitruvian Manifold: Inferring dense correspondences for oneshot human pose estimation", "author": ["J. Taylor", "J. Shotton", "T. Sharp", "A. Fitzgibbon"], "venue": "CVPR", "citeRegEx": "25", "shortCiteRegEx": null, "year": 2012}, {"title": "Real-time continuous pose recovery of human hands using convolutional networks", "author": ["J. Tompson", "M. Stein", "Y. Lecun", "K. Perlin"], "venue": "ACM Transactions on Graphics", "citeRegEx": "26", "shortCiteRegEx": null, "year": 2014}, {"title": "Attribute2image: Conditional image generation from visual attributes", "author": ["X. Yan", "J. Yang", "K. Sohn", "H. Lee"], "venue": "URL http://arxiv.org/abs/1512.00570", "citeRegEx": "27", "shortCiteRegEx": "27", "year": 2015}], "referenceMentions": [{"referenceID": 10, "context": "[11], we argue that the learning objective should be tailored to the evaluation loss in order to obtain the best performance with respect to this loss.", "startOffset": 0, "endOffset": 4}, {"referenceID": 19, "context": "The dissimilarity coefficient we employ was first introduced by Rao [21] and is defined for any non-negative symmetric loss function.", "startOffset": 68, "endOffset": 72}, {"referenceID": 5, "context": "[6] are very popular and have been used in several computer vision applications, for example in Denton et al.", "startOffset": 0, "endOffset": 3}, {"referenceID": 0, "context": "[1], Radford et al.", "startOffset": 0, "endOffset": 3}, {"referenceID": 18, "context": "[20], Springenberg [24] and Yan et al.", "startOffset": 0, "endOffset": 4}, {"referenceID": 22, "context": "[20], Springenberg [24] and Yan et al.", "startOffset": 19, "endOffset": 23}, {"referenceID": 25, "context": "[27].", "startOffset": 0, "endOffset": 4}, {"referenceID": 5, "context": "[6] and Radford et al.", "startOffset": 0, "endOffset": 3}, {"referenceID": 18, "context": "[20], GAN models require very careful design of the networks\u2019 architecture.", "startOffset": 0, "endOffset": 4}, {"referenceID": 13, "context": "GAN models have been generalized to conditional GAN (cGAN) in Mirza and Osindero [15], where some additional input information can be fed to the Generator and the Discriminator.", "startOffset": 81, "endOffset": 85}, {"referenceID": 13, "context": "For example in Mirza and Osindero [15] a cGAN model generates tags corresponding to an image.", "startOffset": 34, "endOffset": 38}, {"referenceID": 3, "context": "Gauthier [4] applies cGAN to face generation.", "startOffset": 9, "endOffset": 12}, {"referenceID": 20, "context": "[22] propose to generate images of flowers with a cGAN model, where the conditional information is a word description of the flower to generate1.", "startOffset": 0, "endOffset": 4}, {"referenceID": 1, "context": "[2] and Li et al.", "startOffset": 0, "endOffset": 3}, {"referenceID": 11, "context": "[13] propose to train generative deep networks with an objective function based on the Maximum Mean Discrepancy (MMD) method.", "startOffset": 0, "endOffset": 4}, {"referenceID": 6, "context": "[7, 8], is a statistical hypothesis testing method to assess if two probabilistic", "startOffset": 0, "endOffset": 6}, {"referenceID": 7, "context": "[7, 8], is a statistical hypothesis testing method to assess if two probabilistic", "startOffset": 0, "endOffset": 6}, {"referenceID": 20, "context": "[22] and therefore cannot take advantage of this work in our experimental comparison.", "startOffset": 0, "endOffset": 4}, {"referenceID": 1, "context": "[2], the MMD test can been seen as playing the role of an adversary.", "startOffset": 0, "endOffset": 3}, {"referenceID": 8, "context": "The Variational Auto-Encoders (VAE) presented in Kingma and Welling [9] is composed of a probabilistic encoder and a probabilistic decoder.", "startOffset": 68, "endOffset": 71}, {"referenceID": 12, "context": "[14], where the authors propose to regularise autoencoders with an adversarial network.", "startOffset": 0, "endOffset": 4}, {"referenceID": 24, "context": "[26], preprocessed as in Oberweger et al.", "startOffset": 0, "endOffset": 4}, {"referenceID": 14, "context": "[16].", "startOffset": 0, "endOffset": 4}, {"referenceID": 17, "context": "[19].", "startOffset": 0, "endOffset": 4}, {"referenceID": 0, "context": "DISC\u2206(PT , PG) = DIV\u2206(PT , PG)\u2212 \u03b3DIV\u2206(PG, PG)\u2212 (1\u2212 \u03b3)DIV\u2206(PT , PT ) (3) with \u03b3 \u2208 [0, 1].", "startOffset": 81, "endOffset": 87}, {"referenceID": 19, "context": "These coefficients were introduced by Rao [21] with \u03b3 = 1/2 and used for latent variable models in Kumar et al.", "startOffset": 42, "endOffset": 46}, {"referenceID": 9, "context": "[10].", "startOffset": 0, "endOffset": 4}, {"referenceID": 4, "context": "However, if the dissimilarity coefficient of equation (4) is a strictly proper scoring rule as defined in Gneiting and Raftery [5], it is ensured to be minimised only when PG(y|x) is the true conditional distribution PT (y|x).", "startOffset": 127, "endOffset": 130}, {"referenceID": 4, "context": "By theorem 5 in Gneiting and Raftery [5], this is the case, for example, if we take as loss function \u2206\u03b2(y,y) = ||y \u2212 y||\u03b22 = ( \u2211dy i=1 |(y \u2212 y\u2032i|2) \u03b2/2 with \u03b2 \u2208 [0, 2] excluding 0 and 2, and use \u03b3 = 1 2 .", "startOffset": 37, "endOffset": 40}, {"referenceID": 1, "context": "By theorem 5 in Gneiting and Raftery [5], this is the case, for example, if we take as loss function \u2206\u03b2(y,y) = ||y \u2212 y||\u03b22 = ( \u2211dy i=1 |(y \u2212 y\u2032i|2) \u03b2/2 with \u03b2 \u2208 [0, 2] excluding 0 and 2, and use \u03b3 = 1 2 .", "startOffset": 161, "endOffset": 167}, {"referenceID": 6, "context": "[7, 8].", "startOffset": 0, "endOffset": 6}, {"referenceID": 7, "context": "[7, 8].", "startOffset": 0, "endOffset": 6}, {"referenceID": 21, "context": "Indeed as shown in Proposition 3 of Sch\u00f6lkopf [23], the function k : Y \u00d7 Y \u2192 R defined as k(y,y\u2032) = ||y \u2212 y||\u03b22 for 0 < \u03b2 \u2264 2 is a conditionally positive definite kernel, that is a specific type of positive definite kernel.", "startOffset": 46, "endOffset": 50}, {"referenceID": 24, "context": "[26] to estimate the efficiency of DISCO Nets for this task.", "startOffset": 0, "endOffset": 4}, {"referenceID": 24, "context": "[26] contains 8252 testing and 72,757 training frames of captured RGBD data with ground-truth hand pose information.", "startOffset": 0, "endOffset": 4}, {"referenceID": 14, "context": "[16, 17] and use the same subset of J = 14 joints.", "startOffset": 0, "endOffset": 8}, {"referenceID": 15, "context": "[16, 17] and use the same subset of J = 14 joints.", "startOffset": 0, "endOffset": 8}, {"referenceID": 14, "context": "[16, 17], and extract a fixed-size metric cube around the hand from the depth image.", "startOffset": 0, "endOffset": 8}, {"referenceID": 15, "context": "[16, 17], and extract a fixed-size metric cube around the hand from the depth image.", "startOffset": 0, "endOffset": 8}, {"referenceID": 14, "context": "[16, 17] and Taylor et al.", "startOffset": 0, "endOffset": 8}, {"referenceID": 15, "context": "[16, 17] and Taylor et al.", "startOffset": 0, "endOffset": 8}, {"referenceID": 23, "context": "[25], that", "startOffset": 0, "endOffset": 4}, {"referenceID": 14, "context": "[16, 17] present the metric FF as the most challenging metric for hand pose estimation.", "startOffset": 0, "endOffset": 8}, {"referenceID": 15, "context": "[16, 17] present the metric FF as the most challenging metric for hand pose estimation.", "startOffset": 0, "endOffset": 8}, {"referenceID": 2, "context": "[3], kernel density estimation fails in this scenario due to the high dimensionality of y.", "startOffset": 0, "endOffset": 3}, {"referenceID": 15, "context": "[17].", "startOffset": 0, "endOffset": 4}, {"referenceID": 16, "context": "9 (see Polyak [18]).", "startOffset": 14, "endOffset": 18}, {"referenceID": 13, "context": "We consider the applications of the conditional Generative Adversarial Networks (cGAN) model from Mirza and Osindero [15] and to the best of our knowledge cGAN has not been applied to pose estimation.", "startOffset": 117, "endOffset": 121}, {"referenceID": 5, "context": "[6] and Radford et al.", "startOffset": 0, "endOffset": 3}, {"referenceID": 18, "context": "[20], GAN (and thus cGAN) require very careful design of the networks\u2019 architecture and training procedure.", "startOffset": 0, "endOffset": 4}, {"referenceID": 13, "context": "In order to do a fair comparison, we followed the work in Mirza and Osindero [15] and practical advice for GAN presented in Larsen and S\u00f8nderby [12].", "startOffset": 77, "endOffset": 81}, {"referenceID": 13, "context": "This is a setting similar to the one employed for tag-annotation of images in Mirza and Osindero [15] 3.", "startOffset": 97, "endOffset": 101}, {"referenceID": 14, "context": "[16] a constrained prior hand model, referred as NYU-Prior, is refined on each hand joint position to increase accuracy, referred as NYU-Prior-Refined.", "startOffset": 0, "endOffset": 4}, {"referenceID": 15, "context": "[17], the input depth image is fed to a first network NYU-Init, that outputs a pose used to synthesize an image with a second network.", "startOffset": 0, "endOffset": 4}], "year": 2017, "abstractText": "We present a new type of probabilistic model which we call DISsimilarity COefficient Networks (DISCO Nets). DISCO Nets allow us to efficiently sample from a posterior distribution parametrised by a neural network. During training, DISCO Nets are learned by minimising the dissimilarity coefficient between the true distribution and the estimated distribution. This allows us to tailor the training to the loss related to the task at hand. We empirically show that (i) by modeling uncertainty on the output value, DISCO Nets outperform equivalent non-probabilistic predictive networks and (ii) DISCO Nets accurately model the uncertainty of the output, outperforming existing probabilistic models based on deep neural networks.", "creator": "LaTeX with hyperref package"}}}