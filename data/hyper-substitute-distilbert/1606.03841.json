{"id": "1606.03841", "review": {"conference": "ICML", "VERSION": "v1", "DATE_OF_SUBMISSION": "13-Jun-2016", "title": "Efficient Learning with a Family of Nonconvex Regularizers by Redistributing Nonconvexity", "abstract": "the limitation of balanced transforms permits for structured optimization, for they overall produce better filters and problem prediction aid. recently, nonconvex tools have attracted a volume of collectors nor favor database managers. anyway, considering empirical optimization problem proving hence harder. in older paper, designing a top class known nonconvex techniques, we need to move the nonconvexity from 1 regularizer joining the original. the feedback regularizer is then transformed above a familiar convex regularizer, ensured the resultant loss function has still be guaranteed to occur smooth. learning with efficient convexified machine can be performed by adding efficient algorithms originally designed for earlier regularizers ( such as the optimal conditional error featuring self - price algorithm ). nonetheless, it states are shown here critical points of random transformed problem are also critical points below the original problem. extensive experiments incorporating a cluster of particular smooth improvements show that the proposed approximation is notably faster than the state - of - the - loop nonconvex attempt.", "histories": [["v1", "Mon, 13 Jun 2016 07:21:31 GMT  (482kb,D)", "https://arxiv.org/abs/1606.03841v1", "Full version of ICML 2016 paper with same title"], ["v2", "Thu, 20 Oct 2016 05:57:58 GMT  (446kb,D)", "http://arxiv.org/abs/1606.03841v2", null], ["v3", "Mon, 13 Feb 2017 01:27:29 GMT  (2689kb,D)", "http://arxiv.org/abs/1606.03841v3", "Journal version of previous conference paper appeared at ICML-2016 with same title"]], "COMMENTS": "Full version of ICML 2016 paper with same title", "reviews": [], "SUBJECTS": "math.OC cs.LG stat.ML", "authors": ["quanming yao", "james t kwok"], "accepted": true, "id": "1606.03841"}, "pdf": {"name": "1606.03841.pdf", "metadata": {"source": "CRF", "title": "Efficient Learning with a Family of Nonconvex Regularizers by Redistributing Nonconvexity", "authors": ["Quanming Yao", "James T. Kwok"], "emails": ["QYAOAA@CSE.UST.HK", "JAMESK@CSE.UST.HK"], "sections": [{"heading": "1. Introduction", "text": "Risk minimization is fundamental to machine learning. It admits a tradeoff between the empirical loss and regularization as:\nmin x F (x) \u2261 f(x) + g(x), (1)\nwhere x is the model parameter, f is the loss and g is the regularizer. The choice of regularizers is important and application-specific, and is often the crux to obtain good prediction performance. Popular examples include the sparsity-inducing regularizers, which have been commonly used in image processing (Beck and Teboulle, 2009; Mairal et al., 2009; Jenatton et al., 2011) and highdimensional feature selection (Tibshirani et al., 2005; Jacob et al., 2009; Liu and Ye, 2010); and the low-rank regularizer in matrix and tensor learning, with good empirical performance on tasks such as recommender systems (Cande\u0300s and Recht, 2009; Mazumder et al., 2010) and visual data analysis (Liu et al., 2013; Lu et al., 2014).\nMost of these regularizers are convex. Well-known examples include the `1-regularizer for sparse coding (Donoho, 2006), and the nuclear norm regularizer in low-rank matrix learning\nc\u00a9\u2014 Quanming Yao and James T. Kwok.\nar X\niv :1\n60 6.\n03 84\n1v 3\n[ m\nat h.\nO C\n] 1\n3 Fe\n(Cande\u0300s and Recht, 2009). Besides having nice theoretical guarantees, convex regularizers also allow easy optimization. Popular optimization algorithms in machine learning include the proximal algorithm (Parikh and Boyd, 2013), Frank-Wolfe (FW) algorithm (Jaggi, 2013), the alternating direction method of multipliers (ADMM) (Boyd et al., 2011), stochastic gradient descent and its variants (Bottou, 1998; Xiao and Zhang, 2014). Many of these are efficient, scalable, and have sound convergence properties.\nHowever, convex regularizers often lead to biased estimation. For example, in sparse coding, the solution obtained by the `1-regularizer is often not as sparse and accurate (Zhang, 2010b). In lowrank matrix learning, the estimated rank obtained with the nuclear norm regularizer is often much higher (Mazumder et al., 2010). To alleviate this problem, a number of nonconvex regularizers have been recently proposed (Geman and Yang, 1995; Fan and Li, 2001; Cande\u0300s et al., 2008; Zhang, 2010a; Trzasko and Manduca, 2009). As can be seen from Table 1, they are all (i) nonsmooth at zero, which encourage a sparse solution; and (ii) concave, which place a smaller penalty than the `1-regularizer on features with large magnitudes. Empirically, these nonconvex regularizers usually outperform convex regularizers.\nEven with a convex loss, the resulting nonconvex problem is much harder to optimize. One can use general-purpose nonconvex optimization solvers such as the concave-convex procedure (Yuille and Rangarajan, 2002). However, the subproblem in each iteration can be as expensive as the original problem, and the concave-convex procedure is thus often slow in practice (Gong et al., 2013; Zhong and Kwok, 2014).\nRecently, the proximal algorithm has also been extended for nonconvex problems. Examples include the NIPS (Sra, 2012), IPiano (Ochs et al., 2014), UAG (Ghadimi and Lan, 2016), GIST (Gong et al., 2013), IFB (Bot et al., 2016), and nmAPG (Li and Lin, 2015). Specifically, NIPS, IPiano and UAG allow f in (1) to be Lipschitz smooth (possibly nonconvex) but g has to be convex; while GIST, IFB and nmAPG further allow g to be nonconvex. The current state-of-the-art is nmAPG. However, efficient computation of the underlying proximal operator is only possible for simple nonconvex regularizers. When the regularizer is complicated, such as the nonconvex versions of the fused lasso and overlapping group lasso regularizers (Zhong and Kwok, 2014),\nthe corresponding proximal step has to be solved numerically and is again expensive. Another approach is by using the proximal average (Zhong and Kwok, 2014), which computes and averages the proximal step of each underlying regularizer. However, because the proximal step is only approximate, convergence is usually slower than typical applications of the proximal algorithm (Li and Lin, 2015).\nWhen f is smooth, there are endeavors to extend other algorithms from convex to nonconvex optimization. For the global consensus problem, standard ADMM converges only when g is convex (Hong et al., 2016). When g is nonconvex, convergence of ADMM is only established for problems of the form minx,y f(x) + g(y) : y = Ax, where matrix A has full row rank (Li and Pong, 2015). The convergence of ADMM in more general cases is an open issue. More recently, the stochastic variance reduced gradient (SVRG) algorithm (Johnson and Zhang, 2013), which is a variant of the popular stochastic gradient descent with reduced variance in the gradient estimates, has also been extended for problems with nonconvex f . However, the regularizer g is still required to be convex (Reddi et al., 2016a; Zhu and Hazan, 2016).\nSometimes, it is desirable to have a nonsmooth loss f . For example, the absolute loss is more robust to outliers than the square loss, and has been popularly used in applications such as image denoising (Yan, 2013), robust dictionary learning (Zhao et al., 2011) and robust PCA (Cande\u0300s et al., 2011). The resulting optimization problem becomes more challenging. When both f and g are convex, ADMM is often the main optimization tool for problem (1) (He and Yuan, 2012). However, when either f or g is nonconvex, ADMM no longer guarantees convergence. Besides a nonconvex g, we may also want to use a nonconvex loss f , such as `0-norm (Yan, 2013) and capped-`1 norm (Sun et al., 2013), as they are more robust to outliers and can obtain better performance. However, when f is nonsmooth and nonconvex, none of the above-mentioned algorithms (i.e., proximal algorithms, FW algorithms, ADMM, and SVRG) can be used. As a last resort, one can use more general nonconvex optimization approaches such as convex concave programming (CCCP) (Yuille and Rangarajan, 2002). However, they are slow in general.\nIn this paper, we first consider the case where the loss function f is smooth (possibly nonconvex) and the regularizer g is nonconvex. We propose to handle nonconvex regularizers by reusing the abundant repository of efficient convex algorithms originally designed for convex regularizers. The key is to shift the nonconvexity associated with the nonconvex regularizer to the loss function, and transform the nonconvex regularizer to a familiar convex regularizer. To illustrate the practical usefulness of this convexification scheme, we show how it can be used with popular optimization algorithms in machine learning. For example, for the proximal algorithm, the resultant proximal step can be much easier after transformation. Specifically, for the nonconvex tree-structured lasso and nonconvex sparse group lasso, we show that the corresponding proximal steps have closedform solutions on the transformed problems, but not on the original ones. For the nonconvex total variation problem, though there is no closed-form solution for the proximal step before and after the transformation, we show that the proximal step is still cheaper and easier for optimization after the transformation. To allow further speedup, we propose a proximal algorithm variant that allows the use of inexact proximal steps with convex g when it has no closed-form proximal step solution. For the FW algorithm, we consider its application to nonconvex low-rank matrix learning problems, and propose a variant with guaranteed convergence to a critical point of the nonconvex problem. For SVRG in stochastic optimization and ADMM in consensus optimization, we show that these algorithms have convergence guarantees on the transformed problems but not on the original ones.\nWe further consider the case where f is also nonconvex and nonsmooth (and g is nonconvex). We demonstrate that problem (1) can be transformed to an equivalent problem with a smooth loss and convex regularizer using our proposed idea. However, as the proximal step with the transformed regularizer has to be solved numerically and exact proximal step is required, usage with the proximal algorithm may not be efficient. We show that this problem can be addressed by the proposed inexact proximal algorithm. Finally, in the experiments, we demonstrate the above-mentioned advantages of optimizing the transformed problems instead of the original ones on various tasks, and show that running algorithms on the transformed problems can be much faster than the state-of-art on the original ones.\nThe rest of the paper is organized as follows. Section 2 provides a review on the related works. The main idea for problem transformation is presented in Section 3, and its usage with various algorithms are discussed in Section 4. Experimental results are shown in Section 5, and the last section gives some concluding remarks. All the proofs are in Appendix A. Note that this paper extends a shorter version published in the proceedings of the International Conference of Machine Learning (Yao and Kwok, 2016)."}, {"heading": "Notation", "text": "We denote vectors and matrices by lowercase and uppercase boldface letters, respectively. For a vector x \u2208 Rd, \u2016x\u20162 = ( \u2211d i=1 |xi|2)1/2 is its `2-norm, Diag(x) returns a diagonal matrixX \u2208 Rd\u00d7d with Xii = xi. For a matrix X \u2208 Rm\u00d7n (where m \u2264 n without loss of generality), its nuclear norm is \u2016X\u2016\u2217 = \u2211m i=1 \u03c3i(X), where \u03c3i(X)\u2019s are the singular values of X , and its Frobenius norm\nis \u2016X\u2016F = \u221a\u2211m\ni=1 \u2211n j=1X 2 ij , and \u2016X\u2016\u221e = maxi,j |Xij |. For a square matrix X , X \u2208 S+\nindicates it is a positive semidefinite. For two matrices X and Y , \u3008X,Y \u3009 = \u2211\ni,j XijYij . For a smooth function f , \u2207f(x) is its gradient at x. For a convex but nonsmooth f , \u2202f(x) = {u : f(y) \u2265 f(x) + \u3008u, y \u2212 x\u3009} is its subdifferential at x, and g \u2208 \u2202f(x) is a subgradient."}, {"heading": "2. Related Works", "text": "In this section, we review some popular algorithms for solving (1). Here, f is assumed to be Lipschitz smooth."}, {"heading": "2.1 Convex-Concave Procedure (CCCP)", "text": "The convex-concave procedure (CCCP) (Yuille and Rangarajan, 2002; Lu, 2012) is a popular and general solver for (1). It assumes thatF can be decomposed as a difference of convex (DC) functions (Hiriart-Urruty, 1985), i.e., F (x) = F\u0303 (x) + F\u0302 (x) where F\u0303 is convex and F\u0302 is concave. In each CCCP iteration, F\u0302 is linearized at xt, and xt+1 is generated as\nxt+1 = arg min x F\u0303 (x) + F\u0302 (xt)\u2212 (x\u2212 xt)>st, (2)\nwhere st \u2208 \u2202[\u2212F\u0302 (xt)] is a subgradient. Note that as the last two terms are linear, (2) is a convex problem and can be easier than the original problem F .\nHowever, CCCP is expensive as (2) needs to be exactly solved. Sequential convex programming (SCP) (Lu, 2012) improves its efficiency when F is in form of (1). It assumes that f is L-Lipschitz smooth (possibly nonconvex); while g can be nonconvex, but admits a DC decomposition as g(x) =\n\u03c2\u0303(x) + \u03c2\u0302(x). It then generates xt+1 as\nxt+1 = arg min x f(xt) + (x\u2212 xt)>\u2207f(xt) +\nL 2 \u2016x\u2212 xt\u201622 + \u03c2\u0303(x) + \u03c2\u0302(xt)\u2212 (x\u2212 xt)>st\n= arg min x\n1 2 \u2016x\u2212 xt \u2212 st + 1 L \u2207f(xt)\u201622 + \u03c2\u0303(x), (3)\nwhere st \u2208 \u2202 (\u2212\u03c2\u0302(xt)). When \u03c2\u0303 is simple, (3) has a closed-form solution, and SCP can be faster than CCCP. However, its convergence is still slow in general (Gong et al., 2013; Zhong and Kwok, 2014; Li and Lin, 2015)."}, {"heading": "2.2 Proximal Algorithm", "text": "The proximal algorithm (Parikh and Boyd, 2013) has been popularly used for optimization problems of the form in (1). Let f be convex and L-Lipschitz smooth, and g is convex. The proximal algorithm generates iterates {xt} as\nxt+1 = arg min x f(xt) + (x\u2212 xt)>\u2207f(xt) +\nL 2 \u2016x\u2212 xt\u201622 + g(x)\n= prox 1 L g\n( xt \u2212 1\nL \u2207f(xt)\n) ,\nwhere proxg(z) \u2261 arg minx 12\u2016x \u2212 z\u2016 2 2 + g(x) is the proximal step, The proximal algorithm converges at a rate of O(1/T ). This can be further accelerated to O(1/T 2) by modifying the generation of {xt} as (Beck, 2009; Nesterov, 2013):\nyt = xt + \u03b1t\u22121 \u2212 1\n\u03b1t (xt \u2212 xt\u22121),\nxt+1 = prox 1 L g\n( yt \u2212 1\nL \u2207f(yt)\n) ,\nwhere \u03b10 = \u03b11 = 1 and \u03b1t+1 = 12( \u221a\n4\u03b12t + 1 + 1). Recently, the proximal algorithm has been extended to nonconvex optimization. In particular, NIPS (Sra, 2012), IPiano (Ochs et al., 2014) and UAG (Ghadimi and Lan, 2016) allow f to be nonconvex, while g is still required to be convex. GIST (Gong et al., 2013), IFB (Bot et al., 2016) and nmAPG (Li and Lin, 2015) further remove this restriction and allow g to be nonconvex. It is desirable that the proximal step has a closed-form solution. This is true for many convex regularizers such as the lasso regularier (Tibshirani, 1996), tree-structured lasso regularizer (Liu and Ye, 2010; Jenatton et al., 2011) and sparse group lasso regularizer (Jacob et al., 2009). However, when g is nonconvex, such solution only exists for some simple g, e.g., nonconvex lasso regularizer (Gong et al., 2013), and usually do not exist for more general cases, e.g., nonconvex tree-structured lasso regularizer (Zhong and Kwok, 2014).\nOn the other hand, Zhong and Kwok (2014) used proximal average (Bauschke et al., 2008) to handle complicate g which is in the form g(x) = \u2211K i=1 \u00b5igi(x), where each gi has a simple proximal step. The iterates are generated as\nxt+1 = K\u2211 i=1 \u00b5i \u00b7 prox\u00b5i L gi ( xt \u2212 1 L \u2207f(xt) ) / K\u2211 i=1 \u00b5i.\nEach of the constituent proximal steps prox\u00b5i L gi (\u00b7) can be computed inexpensively, and thus the per-iteration complexity is low. It only converges to an approximate solution to proxg(z), but an approximation guarantee is provided. However, empirically, the convergence can be slow."}, {"heading": "2.3 Frank-Wolfe (FW) Algorithm", "text": "The FW algorithm (Frank and Wolfe, 1956) is used for solving optimization problems of the form\nmin x f(x) : x \u2208 C, (4)\nwhere f is Lipschitz-smooth and convex, and C is a compact convex set. Recently, it has been popularly used in machine learning (Jaggi, 2013). In each iteration, the FW algorithm generates the next iterate xt+1 as\nst = arg min s\u2208C\ns>\u2207f(xt), (5)\n\u03b3t = arg min \u03b3\u2208[0,1]\nf((1\u2212 \u03b3)xt + \u03b3st), (6)\nxt+1 = (1\u2212 \u03b3t)xt + \u03b3tst. (7)\nHere, (5) is a linear subproblem which can often be easily solved; (6) performs line search, and the next iterate xt+1 is generated from a convex combination of xt and st in (7). The FW algorithm has a convergence rate of O(1/T ) (Jaggi, 2013).\nIn this paper, we will focus on using the FW algorithm to learn a low-rank matrix X \u2208 Rm\u00d7n. Without loss of generality, we assume that m \u2264 n. Let \u03c3i(X)\u2019s be the singular values of X . The nuclear norm of X , \u2016X\u2016\u2217 = \u2211m i=1 \u03c3i(X), is the tightest convex envelope of rank(X), and is often used as a low-rank regularizer (Cande\u0300s and Recht, 2009). The low-rank matrix learning problem can be written as\nmin X\nf(X) + \u00b5\u2016X\u2016\u2217, (8)\nwhere f is the loss. For example, in matrix completion (Cande\u0300s and Recht, 2009),\nf(X) = 1\n2 \u2016P\u2126(X \u2212O)\u20162F , (9)\nwhere O is the observed incomplete matrix, \u2126 \u2208 {0, 1}m\u00d7n contains indices to the observed entries in O, and [P\u2126(A)]ij = Aij if \u2126ij = 1, and 0 otherwise.\nThe FW algorithm for this nuclear norm regularized problem is shown in Algorithm 1 (Zhang et al., 2012). Let the iterate at the tth iteration be Xt. As in (5), the following linear subproblem has to be solved (Jaggi, 2013):\nmin S:\u2016S\u2016\u2217\u22641\n\u3008S,\u2207f(Xt)\u3009. (10)\nThis can be obtained from the rank-one SVD of \u2207f(Xt) (step 3). Similar to (6), line search is performed at step 4. As a rank-one matrix is added intoXt in each iteration, it is convenient to write Xt as\nt\u2211 i=1 uiv > i = UtV > t , (11)\nwhere Ut = [u1, . . . , ut] and Vt = [v1, . . . , vt]. The FW algorithm has a convergence rate of O(1/T ) (Jaggi, 2013). To make it empirically faster, Algorithm 1 also performs optimization at step 6 (Laue, 2012; Zhang et al., 2012). Substituting \u2016X\u2016\u2217 = minX=UV > 12 ( \u2016U\u20162F + \u2016V \u20162F ) (Srebro et al., 2004) into (8), we have the following local optimization problem:\nmin U,V\nf(UV >) + \u00b5\n2 (\u2016U\u20162F + \u2016V \u20162F ). (12)\nThis can be solved by standard solvers such as L-BFGS (Nocedal and Wright, 2006).\nAlgorithm 1 Frank-Wolfe algorithm for problem (8) with f convex (Zhang et al., 2012). 1: U1 = [ ] and V1 = [ ]; 2: for t = 1 . . . T do 3: [ut, st, vt] = rank1SVD(\u2207f(Xt)); 4: [\u03b1t, \u03b2t] = arg min\u03b1\u22650,\u03b2\u22650 f(\u03b1Xt + \u03b2utv > t ) + \u00b5(\u03b1\u2016Xt\u2016\u2217 + \u03b2);\n5: U\u0304t = [\u221a \u03b1tUt; \u221a \u03b2tut ] and V\u0304t = [\u221a \u03b1tVt; \u221a \u03b2tvt ] ; 6: obtain [Ut+1, Vt+1] from (12), using U\u0304t and V\u0304t for warm-start; // Xt+1 = Ut+1V >t+1 7: end for 8: return UT+1 and VT+1."}, {"heading": "2.4 Alternating Direction Method of Multipliers (ADMM)", "text": "ADMM is a simple but powerful algorithm first introduced in the 1970s (Glowinski and Marroco, 1975). Recently, it has been popularly used in diverse fields such as machine learning, data mining and image processing (Boyd et al., 2011). It can be used to solve optimization problems of the form\nmin x,y f(x) + g(y) : Ax+By = c, (13)\nwhere f, g are convex functions, and A,B (resp. c) are constant matrices (resp. vector) of appropriate sizes. Consider the augmented Lagrangian L(x, y, u) = f(x) + g(y) + u>(Ax + By \u2212 c) + \u03c42\u2016Ax + By \u2212 c\u2016 2 2, where u is the vector of Lagrangian multipliers, and \u03c4 > 0 is a penalty parameter. At the tth iteration of ADMM, the values of x, y and u are updated as\nxt+1 = arg min x L(x, yt, ut), (14) yt+1 = arg min y L(xt+1, y, ut), (15) ut+1 = ut + \u03c4(Axt+1 +Byt+1 \u2212 c).\nBy minimizing L(x, y, uk) w.r.t. x and y in an alternating manner ((14) and (15)), ADMM can more easily decompose the optimization problem when f, g are separable.\nIn this paper, we will focus a special case of (13), namely, the consensus optimization problem:\nmin y,x1,...,xM M\u2211 i=1 fi(x i) + g(y) : x1 = \u00b7 \u00b7 \u00b7 = xM = y, (16)\nHere, each fi is Lipschitz-smooth, xi is the variable in the local objective fi, and y is the global consensus variable. This type of problems is often encountered in machine learning, signal\nprocessing and wireless communication (Bertsekas and Tsitsiklis, 1989; Boyd et al., 2011). For example, in regularized risk minimization, y is the model parameter, fi is the regularized risk functional defined on data subset i, and g is the regularizer. When fi is smooth and g is convex, ADMM converges to a critical point of (16) (Hong et al., 2016). However, when g is nonconvex, its convergence is still an open issue."}, {"heading": "3. Shifting Nonconvexity from Regularizer to Loss", "text": "In recent years, a number of nonconvex regularizers have been proposed. Examples include the Geman penalty (GP) (Geman and Yang, 1995), log-sum penalty (LSP) (Cande\u0300s et al., 2008) and Laplace penalty (Trzasko and Manduca, 2009). In general, learning with nonconvex regularizers is much more difficult than learning with convex regularizers. In this section, we show how to move the nonconvex component from the nonconvex regularizers to the loss function. Existing algorithms can then be reused to learn with the convexified regularizers.\nFirst, we make the following standard assumptions on (1).\nA1. F is bounded from below and lim\u2016x\u20162\u2192\u221e F (x) =\u221e; A2. f is L-Lipschitz smooth (i.e., \u2016\u2207f(x)\u2212\u2207f(y)\u20162 \u2264 L\u2016x\u2212 y\u20162), but possibly nonconvex.\nLet \u03ba be a function that is concave, non-decreasing, \u03c1-Lipschitz smooth with \u03ba\u2032 nondifferentiable at finite points, and \u03ba(0) = 0. With the exception of the capped-`1 norm penalty (Zhang, 2010a) and `0-norm regularizer, all regularizers in Table 1 satisfy requirements on \u03ba. We consider g of the following forms.\nC1. g(x) = \u2211K\ni=1 \u00b5igi(x), where \u00b5i \u2265 0,\ngi(x) = \u03ba(\u2016Aix\u20162), (17)\nand Ai is a matrix. When \u03ba is the identity function, g(x) reduces to the convex regularizer\u2211K i=1 \u00b5i\u2016Aix\u20162. By using different Ai\u2019s, g becomes various structured sparsity regularizers such as the group lasso (Jacob et al., 2009), fused lasso (Tibshirani et al., 2005), and graphical lasso (Jacob et al., 2009).\nC2. g(X) = \u00b5 \u2211m\ni=1 \u03ba(\u03c3i(X)), where X is a matrix and \u00b5 \u2265 0. When \u03ba is the identity function, g reduces to the nuclear norm.\nFirst, consider g in C1. Rewrite each nonconvex gi in (17) as\ngi(x) = g\u0304i(x) + \u03ba0\u2016Aix\u20162, (18)\nwhere \u03ba0 = \u03ba\u2032(0), and g\u0304i(x) = \u03ba(\u2016Aix\u20162) \u2212 \u03ba0\u2016Aix\u20162. Obviously, \u03ba0\u2016Aix\u20162 is convex but nonsmooth. The following shows that g\u0304i, though nonconvex, is concave and Lipschitz smooth. In the sequel, a function with a bar on top (e.g., f\u0304 ) denotes that it is smooth; whereas a function with breve (e.g., g\u0306) denotes that it may be nonsmooth.\nProposition 1 \u03ba(\u2016z\u20162)\u2212 \u03ba0\u2016z\u20162 is concave and 2\u03c1-Lipschitz smooth.\nCorollary 2 g\u0304i is concave and Lipschitz smooth with modulus L\u0304i = 2\u03c1\u2016Ai\u2016F .\nCorollary 3 g(x) can be decomposed as g\u0304(x) + g\u0306(x), where g\u0304(x) \u2261 \u2211K\ni=1 \u00b5ig\u0304i(x) is concave and Lipschitz-smooth, while g\u0306(x) \u2261 \u03ba0 \u2211K i=1 \u00b5i\u2016Aix\u20162 is convex but nonsmooth.\nRemark 4 When Ai = Diag(ei), where ei is the unit vector for dimension i, \u2016Aix\u20162 = |xi| and\ng(x) = d\u2211 i=1 \u00b5i\u03ba(\u2016Aix\u20162) = d\u2211 i=1 \u00b5i\u03ba(|xi|). (19)\nUsing Corollary 3, g can be decomposed as g\u0304(x) + g\u0306(x), where g\u0304(x) \u2261 \u2211d\ni=1 \u00b5i(\u03ba(|xi|)\u2212 \u03ba0|xi|) is concave and 2\u03c1-Lipschitz smooth, while g\u0306(x) \u2261 \u03ba0 \u2211d i=1 \u00b5i|xi| is convex and nonsmooth. When d = 1 and \u00b51 = 1, an illustration of g(x) = \u03ba(|x|), g\u0304(x) = \u03ba(|x|) \u2212 \u03ba0|x| and g\u0306(x) = \u03ba0|x| for the various nonconvex regularizers is shown in Figure 1. When \u03ba is the identity function and \u00b51 = \u00b7 \u00b7 \u00b7 = \u00b5m = \u00b5, g in (19) reduces to the lasso regularizer \u00b5\u2016x\u20161.\nUsing Corollary 3, problem (1) can then be rewritten as\nmin x f\u0304(x) + g\u0306(x), (20)\nwhere f\u0304(x) \u2261 f(x) + g\u0304(x). Note that f\u0304 (which can be viewed as an augmented loss) is Lipschitz smooth while g\u0306 (viewed as a convexified regularizer) is convex but possibly nonsmooth. In other words, nonconvexity is shifted from the regularizer g to the loss f , while ensuring that the augmented loss is smooth.\nWhen X is a matrix, similar to Corollary 3, the following Proposition 5 holds for g in C2.\nProposition 5 Any g in C2 can be decomposed as g\u0304(X) + g\u0306(X), where\ng\u0304(X) \u2261 \u00b5 m\u2211 i=1 \u03ba(\u03c3i(X))\u2212 \u00b5\u03ba0\u2016X\u2016\u2217 (21)\nis concave and 2\u03c1-Lipschitz smooth, while g\u0306(X) \u2261 \u03ba0\u2016X\u2016\u2217 is convex and nonsmooth.\nSince g\u0304 is concave and g\u0306 is convex, the nonconvex regularizer g = g\u0306\u2212 (\u2212g\u0304) can be viewed as a difference of convex functions (DC) (Hiriart-Urruty, 1985). Lu (2012); Gong et al. (2013); Zhong and Kwok (2014) also relied on DC decompositions of the nonconvex regularizer. However, they do not utilize this in the computational procedures, while we use the DC decomposition to simplify the regularizers. As will be seen, though the DC decomposition of a nonconvex function is not unique in general, the particular one proposed here is crucial for efficient optimization."}, {"heading": "4. Example Use Cases", "text": "In this section, we provide concrete examples to show how the proposed convexification scheme can be used with various optimization algorithms. An overview is summarized in Table 2."}, {"heading": "4.1 Proximal Algorithms", "text": "In this section, we provide example applications on using the proximal algorithm for nonconvex structured sparse learning. The proximal algorithm has been commonly used for learning with convex regularizers (Parikh and Boyd, 2013). With a nonconvex regularizer, the underlying proximal step becomes much more challenging. Gong et al. (2013); Li and Lin (2015) and Bot et al. (2016) extended proximal algorithm to simple nonconvex g, but cannot handle more complicated nonconvex regularizers such as the tree-structured lasso regularizer (Liu and Ye, 2010; Schmidt et al., 2011), sparse group lasso regularizer (Jacob et al., 2009) and total variation regularizer (Nikolova, 2004). Using the proximal average (Bauschke et al., 2008), Zhong and Kwok (2014) can handle nonconvex regularizers of the form g = \u2211K i=1 \u00b5igi, where each gi is simple. However, the solutions obtained are only approximate. General nonconvex optimization techniques such as the concave-convex procedure (CCCP) (Yuille and Rangarajan, 2002) or its variant sequential convex programming (SCP) (Lu, 2012) can also be used, though they are slow in general (Gong et al., 2013; Zhong and Kwok, 2014).\nUsing the proposed transformation, one only needs to solve the proximal step of a standard convex regularizer instead of that of a nonconvex regularizer. This allows reuse of existing solutions for the proximal step and is much less expensive. As proximal algorithms have the same\nconvergence guarantee for convex and nonconvex f (Gong et al., 2013; Li and Lin, 2015), solving the transformed problem can be much faster. The following gives some specific examples."}, {"heading": "4.1.1 NONCONVEX SPARSE GROUP LASSO", "text": "In sparse group lasso, the feature vector x is divided into groups. Assume that group Gj contains dimensions in x that group j contains. Let [ xGj ] i\n= xi if i \u2208 Gj , and 0 otherwise. Given training samples {(a1, y1), . . . , (aN , yN )}, (convex) sparse group lasso is formulated as (Jacob et al., 2009):\nmin x N\u2211 i=1 `(yi, a > i x) + \u03bb\u2016x\u20161 + K\u2211 j=1 \u00b5j\u2016xGj\u20162, (22)\nwhere ` is a smooth loss, and K is the number of (non-overlapping) groups. For the nonconvex extension, the regularizer becomes\ng(x) = \u03bb d\u2211 i=1 \u03ba(|xi|) + K\u2211 j=1 \u00b5j\u03ba(\u2016xGj\u20162). (23)\nUsing Corollary 3 and Remark 4, the convexified regularizer is g\u0306(x) = \u03ba0(\u03bb\u2016x\u20161 +\u2211K j=1 \u00b5j\u2016xGj\u20162). Its proximal step can be easily computed by the algorithm in (Yuan et al., 2011). Specifically, the proximal operator of g\u0306 can be obtained by computing prox\u00b5j\u2016\u00b7\u20162(prox\u03bb\u2016\u00b7\u20161(xGj )) for each group separately. This can then be used with any proximal algorithm that can handle nonconvex objectives (as f\u0304 is nonconvex). In particular, we will adopt the state-of-the-art nonmontonic APG (nmAPG) algorithm (Li and Lin, 2015) (shown in Algorithm 2). Note that nmAPG cannot be directly used with the nonconvex regularizer g in (23), as the corresponding proximal step has no inexpensive closed-form solution.\nAs mentioned in Section 3, the proposed decomposition of the nonconvex regularizer g can be regarded as a DC decomposition, which is not unique in general. For example, we might try to add a quadratic term to convexify the nonconvex regularizer. Specifically, we can decompose g(x) in (23) as \u03c2\u0303(x) + \u03c2\u0302(x), where\n\u03c2\u0303(x) = \u03bb d\u2211 i=1 ( \u03ba(|xi|) + \u03c1 2 x2i ) + K\u2211 j=1 \u00b5j ( \u03ba(\u2016xGj\u20162) + \u03c1 2 \u2016xGj\u201622 ) , (24)\nand \u03c2\u0302(x) = \u2212\u03c12 \u2211K\nj=1(\u00b5j + \u03bb)\u2016xGj\u201622. It can be easily shown that \u03c2\u0302 is concave, and Proposition 6 shows that \u03c2\u0303 is convex. Thus, F can be transformed as F (x) = f\u0304(x) + \u03c2\u0303(x), where f\u0304(x) = f(x) + \u03c2\u0302(x) is Lipschitz-smooth, and \u03c2\u0303 is convex but nonsmooth. However, the proximal step associated with \u03c2\u0303 has no simple closed-form solution.\nProposition 6 \u03ba(\u2016 \u00b7 \u20162) + \u03c12\u2016 \u00b7 \u2016 2 2 is convex."}, {"heading": "4.1.2 NONCONVEX TREE-STRUCTURED GROUP LASSO", "text": "In (convex) tree-structured group lasso (Liu and Ye, 2010; Jenatton et al., 2011), the dimensions in x are organized as nodes in a tree, and each group corresponds to a subtree. The regularizer is of the form \u2211K j=1 \u03bbj\u2016xGj\u20162. Interested readers are referred to (Liu and Ye, 2010) for details.\nAlgorithm 2 Nonmonotonic APG (nmAPG) (Li and Lin, 2015). 1: Initialize z1 = x1 = x0, \u03b10 = 0, \u03b11 = 1, \u03b7 \u2208 [0, 1), c1 = F (x1), q1 = 1, and stepsize \u03c4 > L\u0304, \u03b4 \u2208 (0, \u03c4 \u2212 L\u0304);\n2: for t = 1, . . . , T do 3: yt = xt +\n\u03b1t\u22121 \u03b1t (zt \u2212 xt) + \u03b1t\u22121\u22121\u03b1t (xt \u2212 xt\u22121); 4: zt+1 = prox 1\n\u03c4 g\u0306(yt \u2212 1 \u03c4\u2207f\u0304(yt));\n5: if F (zt+1) \u2264 ct \u2212 \u03b42\u2016zt+1 \u2212 yt\u2016 2 2 then 6: xt+1 = zt+1; 7: else 8: vt+1 = prox 1\n\u03c4 g\u0306(xt \u2212 1 \u03c4\u2207f\u0304(xt));\n9: xt+1 = { zt+1 F (zt+1) \u2264 F (vt+1) vt+1 otherwise ;\n10: end if 11: \u03b1t+1 = 1 2( \u221a\n4\u03b12t + 1 + 1); 12: qt+1 = \u03b7qt + 1; 13: ct+1 =\n\u03b7qtct+F (xt+1) qt+1 ; 14: end for 15: return xT+1;\nFor the nonconvex extension, g(x) becomes \u2211K\nj=1 \u03bbj\u03ba(\u2016xGj\u20162). Again, there is no closedform solution of its proximal step. On the other hand, the convexified regularizer is g\u0306(x) \u2261 \u03ba0 \u2211K\nj=1 \u03bbj\u2016xGj\u20162. As shown in (Liu and Ye, 2010), its proximal step can be computed efficiently by processing all the groups once in some appropriate order."}, {"heading": "4.1.3 NONCONVEX TOTAL VARIATION (TV) REGULARIZER", "text": "In an image, nearby pixels are usually strongly correlated. The TV regularizer captures such behavior by assuming that changes between nearby pixels are small. Given an image X \u2208 Rm\u00d7n, the TV regularizer is defined as TV(X) = \u2016DvX\u20161 + \u2016XDh\u20161 (Nikolova, 2004), Dv =\u22121 1. . . . . .\n\u22121 1\n \u2208 R(m\u22121)\u00d7m and Dh =  \u22121 1 . . . . . . \u22121\n1  \u2208 Rn\u00d7(n\u22121) are the horizontal and vertical partial derivative operators, respectively. Thus, it is popular on image processing problems, such as image denoising and deconvolution (Nikolova, 2004; Beck and Teboulle, 2009).\nAs in previous sections, the nonconvex extension of TV regularizer can be defined as\nm\u22121\u2211 i=1 m\u2211 j=1 \u03ba (\u2223\u2223\u2223[DvX]ij\u2223\u2223\u2223)+ n\u2211 i=1 n\u22121\u2211 j=1 \u03ba (\u2223\u2223\u2223[XDh]ij\u2223\u2223\u2223) . (25)\nAgain, it is not clear how its proximal step can be efficiently computed. However, with the proposed transformation, the transformed problem is\nmin X f\u0304(X) + \u00b5\u03ba0TV(X),\nwhere \u00b5 is the regularization parameter, f\u0304(X) = f(X) + \u00b5 \u2211m\u22121\ni=1 \u2211m j=1(\u03ba(|[DvX]ij |) \u2212\n\u03ba0|[DvX]ij |)+\u00b5 \u2211n\ni=1 \u2211n\u22121 j=1 (\u03ba(|[XDh]ij |)\u2212\u03ba0|[XDh]ij |) is concave and Lipschitz smooth. One\nthen only needs to compute the proximal step of the standard TV regularizer. However, unlike the proximal steps in Sections 4.1.1 and 4.1.2, the proximal step of the TV regularizer has no closed-form solution and needs to be solved iteratively. In this case, Schmidt et al. (2011) showed that using inexact proximal steps can make proximal algorithms faster. However, they only considered the situation where both f and g are convex. In the following, we extend nmAPG (Algorithm 2), which can be used with nonconvex objectives, to allow for inexact proximal steps (steps 5 and 9 of Algorithm 3). However, Lemma 2 of (Li and Lin, 2015), which is key to the convergence of nmAPG, no longer holds dues to inexact proximal step. To fix this problem, in step 6 of Algorithm 3, we use F (Xt) instead of ct in Algorithm 2. Besides, we also drop the comparison of F (Zt+1) and F (Vt+1) (originally in step 9 of Algorithm 2).\nAlgorithm 3 Inexact nmAPG. 1: Initialize Z\u03031 = X1 = X0, \u03b10 = 0, \u03b11 = 1 and stepsize \u03c4 > L\u0304, \u03b4 \u2208 (0, \u03c4 \u2212 L\u0304); 2: for t = 1, . . . , T do 3: choose tolerance t; 4: Yt = Xt +\n\u03b1t\u22121 \u03b1t (Zt \u2212Xt) + \u03b1t\u22121\u22121\u03b1t (Xt \u2212Xt\u22121); 5: Z\u0303t+1 = approximate prox 1\n\u03c4 g\u0306(Yt \u2212 1 \u03c4\u2207f\u0304(Yt)), with inexactness \u03d1t+1 \u2264 t;\n6: if F (Z\u0303t+1) \u2264 F (Xt)\u2212 \u03b42\u2016Z\u0303t+1 \u2212 Yt\u2016 2 F then 7: Xt+1 = Z\u0303t+1; 8: else 9: Xt+1 = approximate prox 1\n\u03c4 g\u0306(Xt \u2212 1 \u03c4\u2207f\u0304(Xt)), with inexactness \u03d1t+1 \u2264 t;\n10: end if 11: \u03b1t+1 = 1 2( \u221a\n4\u03b12t + 1 + 1); 12: end for 13: return XT+1;\nInexactness of the proximal step can be controlled as follows. Let P = X \u2212 1\u03c4\u2207f\u0304(X), and h(X) \u2261 12\u2016X \u2212 P\u2016 2 F + 1 \u03c4 g\u0306(X) be the objective in prox 1\u03c4 g\u0306(P ). As g\u0306(X) = \u03ba0TV(X) is convex, h is also convex. Let X\u0303 be an inexact solution of this proximal step. The inexactness h(X\u0303) \u2212 h(prox 1\n\u03c4 g\u0306(P )) is upper-bounded by the duality gap \u03d1 \u2261 h(X\u0303) \u2212 D(W\u0303 ), where D is the dual of\nh, and W\u0303 is the corresponding dual variable. In step 5 (resp. step 9) of Algorithm 3, we solve the proximal step until its duality gap \u03d1t+1 is smaller than a given threshold t. The following Theorem shows convergence of Algorithm 3. Theorem 7 Let \u2211\u221e\nt=1 t < \u221e. The sequence {Xt} generated from Algorithm 3 has at least one limit point, and every limit point is also a critical point of (1).\nIf the proximal step is exact, \u2016Vt \u2212 prox 1 \u03c4 g\u0306(Vt \u2212 1 \u03c4\u2207f\u0304(Vt))\u2016 2 F can be used to measure how far Vt is from a critical point (Gong et al., 2013; Ghadimi and Lan, 2016). In Algorithm 3, the proximal step is inexact, and Xt+1 is an inexact solution to prox 1\n\u03c4 g\u0306(Vt \u2212 1 \u03c4\u2207f\u0304(Vt)), where Vt = Yt if step 7\nis executed, and Vt = Xt if step 9 is executed. As Xt+1 converges to a critical point of (1), we\npropose using dt \u2261 \u2016Xt+1 \u2212 Vt\u20162F to measure how far Xt+1 is from a critical point. The following Proposition shows a O(1/T ) convergence rate on mint=1,...,T dt.\nProposition 8 (i) limt\u2192\u221e dt = 0; and (ii) mint=1,...,T dt converges to zero at a rate of O(1/T ).\nNote that the (exact) nmAPG in Algorithm 2 cannot handle the nonconvex g in (25) efficiently, as the corresponding proximal step has no closed-form solutions but has to be solved exactly. Even the proposed inexact nmAPG (Algorithm 3) cannot be directly used with nonconvex g. As the dual of the nonconvex proximal step is difficult to derive and the optimal duality gap is nonzero in general, the proximal step\u2019s inexactness cannot be easily controlled."}, {"heading": "4.2 Frank-Wolfe Algorithm", "text": "In this section, we use the Frank-Wolfe algorithm to learn a low-rank matrix X \u2208 Rm\u00d7n for matrix completion as reviewed in Section 2.3. The nuclear norm regularizer in (8) may over-penalize top singular values. Recently, there is growing interest to replace this with nonconvex regularizers (Lu et al., 2014, 2015; Yao et al., 2015; Gui et al., 2016). Hence, instead of (8), we consider\nmin X f(X) + \u00b5 m\u2211 i=1 \u03ba(\u03c3i(X)). (26)\nWhen \u03ba is the identity function, (26) reduces to (8). Note that the FW algorithm cannot be directly used on (8), as its linear subproblem in (10) then becomes minS:\u2211mi=1 \u03ba(\u03c3i(S))\u22641\u3008S,\u2207f(Xt)\u3009, which is difficult to osolve.\nUsing Proposition 5, problem (26) is transformed into\nmin X\nf\u0304(X) + \u00b5\u0304\u2016X\u2016\u2217, (27)\nwhere\nf\u0304(X) = f(X) + g\u0304(X), g\u0304(X) = \u00b5 m\u2211 i=1 (\u03ba(\u03c3i(X))\u2212 \u03ba0\u03c3i(X)), (28)\nand \u00b5\u0304 = \u00b5\u03ba0. This only involves the standard nuclear norm regularizer. However, Algorithm 1 still cannot be used as f\u0304 in (28) is no longer convex. A FW variant allowing nonconvex f\u0304 is proposed in (Bredies et al., 2009). However, condition 1 in (Bredies et al., 2009) requires g to satisfy lim\u2016X\u2016F\u2192\u221e g(X) \u2016X\u2016F =\u221e. Such condition does not hold with g(X) = \u2016X\u2016\u2217 in (27) as\n\u2016X\u2016\u2217 \u2016X\u2016F =\n\u221a ( \u2211m\ni=1 \u03c3i) 2\u2211m\ni=1 \u03c3 2 i\n\u2264\n\u221a m \u2211m\ni=1 \u03c3 2 i\u2211m\ni=1 \u03c3 2 i\n= \u221a m <\u221e.\nIn the following, we propose a nonconvex FW variant (Algorithm 4) for the transformed problem (27). It is similar to Algorithm 1, but with three important modifications. First, g\u0304(X) in (28) depends on the singular values of X , which cannot be directly obtained from the UV > factorization in (11). Instead, we use the low-rank factorization\nX = UBV >, (29)\nwhere U \u2208 Rm\u00d7k, V \u2208 Rn\u00d7k are orthogonal and B \u2208 Sk\u00d7k+ is positive semidefinite.\nAlgorithm 4 Frank-Wolfe algorithm for solving the nonconvex problem (27). 1: U1 = [ ], B1 = [ ] and V1 = [ ]; 2: for t = 1 . . . T do 3: [ut, st, vt] = rank1SVD(\u2207f\u0304(Xt)); 4: obtain \u03b1t and \u03b2t from (32); 5: [U\u0304t, B\u0304t, V\u0304t] = warmstart(Ut, ut, Vt, vt, Bt, \u03b1t, \u03b2t); 6: obtain [Ut+1, Bt+1, Vt+1] from (33), using U\u0304t, B\u0304t and V\u0304t for warm-start;\n// Xt+1 = Ut+1Bt+1V >t+1 7: end for 8: return UT+1, BT+1 and VT+1.\nThe second problem is that line search in Algorithm 1 is inefficient in general when operated on a nonconvex f\u0304 . Specifically, step 4 in Algorithm 1 then becomes\n[\u03b1t, \u03b2t] = arg min \u03b1\u22650,\u03b2\u22650\nf\u0304(\u03b1Xt + \u03b2utv > t ) + \u00b5\u0304(\u03b1\u2016Xt\u2016\u2217 + \u03b2). (30)\nTo solve (30), we have to compute \u2202f\u0304(S)\u2202\u03b1 and \u2202f\u0304(S) \u2202\u03b2 , where S = \u03b1Xt + \u03b2utv > t . As shown in Proposition 9, this requires the SVD of S and can be expensive.\nProposition 9 Let the SVD of S be USDiag([\u03c31(S), . . . , \u03c3m(S)])V >S . Then\n\u2202f\u0304(S)\n\u2202\u03b1 = \u03b1\u3008Xt,\u2207f\u0304(S)\u3009, and\n\u2202f\u0304(S)\n\u2202\u03b2 = \u03b2u>t \u2207f\u0304(S)vt,\nwhere\u2207f\u0304(S) = \u2207f(S) + \u00b5USDiag(w)V >S , and w = [\u03ba\u2032(\u03c3i(S))\u2212 \u03ba0] \u2208 Rm.\nCorollary 10 For X in (29), let the SVD of B be UBDiag([\u03c31(B), . . . , \u03c3k(B)])V >B . Then, \u2207f\u0304(X) = \u2207f(X) + \u00b5\u0304(UUB)Diag(w)(V VB)>, where w = [\u03ba\u2032(\u03c3i(B))\u2212 \u03ba0] \u2208 Rk.\nAlternatively, as S is a rank one updates of Xt, one can perform incremental update on SVD, which takes O((m+ n)t2) time (Golub and Van Loan, 2012). However, every time \u03b1, \u03b2 are changed, this incremental SVD has to be recomputed, and is thus inefficient.\nTo alleviate this problem, we approximate f\u0304(S) by the upper bound as\nf\u0304(S) = f\u0304(Xt + (\u03b1\u2212 1)Xt + \u03b2utv>t )\n\u2264 f\u0304(Xt) + \u3008(\u03b1\u2212 1)Xt + \u03b2utv>t ,\u2207f\u0304(Xt)\u3009+ L\u0304 2 \u2016(\u03b1\u2212 1)Xt + \u03b2utv>t \u20162F . (31)\nAs (ut, vt) is obtained from the rank-1 SVD of\u2207f\u0304(Xt), we have \u2016utv>t \u2016F = 1 and u>t \u2207f\u0304(Xt)vt = st. Moreover, Xt = UtBtV >t , and so \u2016Xt\u2016F = \u2016Bt\u2016F and \u2016Xt\u2016\u2217 = Tr (Bt). Substituting these and the upper bound (31) into (30), we obtain a simple quadratic program:\nmin\u03b1\u22650,\u03b2\u22650 (\u03b1\u2212 1)2L\u0304\n2 \u2016Bt\u20162F + (\u03b1\u2212 1)\u03b2L\u0304(u>t Ut)Bt(V >t vt) +\n\u03b22L\u0304\n2 + \u03b2st\n+\u03b1\u3008Bt, U>t \u2207f\u0304(Xt)Vt\u3009+ \u00b5\u0304(\u03b1\u2016Bt\u2016\u2217 + \u03b2). (32)\nNote that the objective in (32) is convex, as the RHS in (31) is convex and the last term from (30) is affine. Moreover, using Corollary 10, \u3008Bt, U>t \u2207f\u0304(Xt)Vt\u3009 in (32) can be obtained as\n\u3008Bt, U>t \u2207f\u0304(Xt)Vt\u3009 = \u3008Bt, U>t \u2207f(Xt)Vt\u3009+ \u00b5\u0304 t\u2211 i=1 \u03c3i(Bt)(\u03ba \u2032(\u03c3i(Bt))\u2212 \u03ba0).\nInstead of requiring SVD onXt, it only requires SVD onBt (which is of size t\u00d7t at the tth iteration of Algorithm 4). As the target matrix is supposed to be low-rank, t m. Hence, all the coefficients in (32) can be obtained in O((m + n)t2 + \u2016\u2126\u20161t) time. Besides, (32) is a quadratic program with only two variables, and thus can be very efficiently solved.\nThe third modification is that with f\u0304 instead of f , (12) can no longer be used for local optimization, as g\u0304(X) in (28) depends on the singular values of X . On the other hand, with the decomposition of X in (29) and Proposition 11 below, (27) can be rewritten as\nminU,B,V f(UBV >) + g\u0304(B) + \u00b5\u0304Tr (B) (33)\ns.t. U>U = I, V >V = I,B \u2208 S+. (34)\nThis can be efficiently solved using matrix optimization techniques on the Grassmann manifold (Ngo and Saad, 2012).\nProposition 11 For orthogonal matrices U and V , g\u0304(UBV >) = g\u0304(B).\nIn Algorithm 4, step 5 is used to warm-start (33), and the procedure is shown in Algorithm 5. It expresses Xt = \u03b1tUt\u22121Bt\u22121V >t\u22121 + \u03b2tutv > t obtained in step 4 to the form UtBtV > t so that the orthogonal constraints on Ut, Vt in (34) are satisfied.\nAlgorithm 5 warmstart(Ut, ut, Vt, vt, Bt, \u03b1t, \u03b2t). 1: [U\u0304t, RU\u0304t ] = QR([Ut, ut]); // QR denotes the QR factorization 2: [V\u0304t , RV\u0304t ] = QR([Vt, vt]);\n3: B\u0304t = RU\u0304t\n[ \u03b1tBt 0\n0 \u03b2t\n] R> V\u0304t ;\n4: return U\u0304t, B\u0304t and V\u0304t;\nExisting analysis for the FW algorithm cannot be used on this nonconvex problem. The following Theorem shows convergence of Algorithm 4 to a critical point of (8).\nTheorem 12 If (8) has a rank-r critical point, then Algorithm 4 converges to a critical point of (8) after r iterations."}, {"heading": "4.3 Alternating Direction Method of Multipliers (ADMM)", "text": "In this section, we consider using ADMM on the consensus optimization problem (16). When all the fi\u2019s and g are convex, ADMM has a convergence rate of O(1/T ) (He and Yuan, 2012). Recently, ADMM has been extended to problems where g is convex but fi\u2019s are nonconvex (Hong et al., 2016). However, when g is nonconvex, such as when a nonconvex regularizer is used in regularized risk minimization, the convergence of ADMM is still an open reseach problem.\nUsing the proposed transformation, we can decompose a nonconvex g as g\u0304 + g\u0306, where g\u0304 is concave and Lipschitz-smooth, while g\u0306 is convex but possibly nonsmooth. Problem (16) can then be rewritten as\nmin y,x1,...,xM M\u2211 i=1 f\u0304i(x i) + g\u0306(y) : x1 = \u00b7 \u00b7 \u00b7 = xM = y, (35)\nwhere f\u0304i(x) = fi(x)+ 1M g\u0304(x). Let p i be the dual variable for the constraint xi = y. The augmented Lagrangian for (35) is\nL ( y, x1, . . . , xM , p1, . . . , pM ) = g\u0306(y) + M\u2211 i=1 f\u0304i(x i) + (pi)>(xi \u2212 y) + \u03c4 2 \u2016xi \u2212 y\u201622. (36)\nUsing (14) and (15), we have the following update equations at iteration t:\nxit+1 = arg min xi f\u0304i(x i) + (pit)\n>(xi \u2212 yt) + \u03c4\n2 \u2016xi \u2212 yt\u201622,\nyt+1 = arg min y\n1\n2 \u2225\u2225\u2225\u2225\u2225y \u2212 M\u2211 i=1 ( xit + 1 \u03c4 pit )\u2225\u2225\u2225\u2225\u2225 2\n2\n+ 1\n\u03c4 g\u0306(y) = prox 1 \u03c4 g\u0306 ( M\u2211 i=1 xit + 1 \u03c4 pit ) . (37)\nAs in previous sections, the proximal step in (37), which is associated with the convex g\u0306, is usually easier to compute than the proximal step associated with the original nonconvex g. Moreover, since g\u0306 is convex, convergence results in Theorem 2.4 of (Hong et al., 2016) can now be applied. Specifically, the sequence {yt, {xit}} generated by the ADMM procedure converges to a critical point of (35)."}, {"heading": "4.4 Stochastic Variance Reduced Gradient", "text": "Variance reduction methods have been commonly used to speed up the often slow convergence of stochastic gradient descent (SGD). Examples are stochastic variance reduced gradient (SVRG) (Johnson and Zhang, 2013) and its proximal extension Prox-SVRG (Xiao and Zhang, 2014). They can be used for the following optimization problem\nmin x N\u2211 i=1 `(yi, a > i x) + g(x), (38)\nwhere {(a1, y1), . . . , (aN , yN )} are the training samples, ` is a smooth convex loss function, and g is a convex regularizer. Recently, Prox-SVRG is also extended for nonconvex objectives. Reddi et al. (2016a) and Zhu and Hazan (2016) considered smooth nonconvex ` but without g. This is further extended to the case of smooth ` and convex nonsmooth g in (Reddi et al., 2016b). However, convergence is still unknown for the more general case where the regularizer g is also nonconvex.\nUsing the proposed transformation, (38) can be rewritten as\nmin x N\u2211 i=1 ( `(yi, a > i x) + 1 N g\u0304(x) ) + g\u0306(x),\nwhere ` + 1N g\u0304 is smooth and g\u0306 is convex. As a result, convergence results in (Reddi et al., 2016b) can now be applied."}, {"heading": "4.5 With OWL-QN", "text": "In this section, we consider OWL-QN (Andrew and Gao, 2007) and its variant mOWL-QN (Gong and Ye, 2015b), which are efficient algorithms for the `1-regularization problem\nmin x f(x) + \u00b5\u2016x\u20161. (39)\nRecently, Gong and Ye (2015a) proposed a nonconvex generalization for (39), in which the standard `1 regularizer is replaced by the nonconvex g(x) = \u00b5 \u2211d i=1 \u03ba(|xi|):\nmin x f(x) + \u00b5 d\u2211 i=1 \u03ba(|xi|). (40)\nGong and Ye (2015a) proposed a sophisticated algorithm (HONOR) which involves a combination of quasi-Newton and gradient descent steps. Though the algorithm is similar to OWL-QN and mOWL-QN, the convergence analysis in (Gong and Ye, 2015b) cannot be directly applied as the regularizer is nonconvex. Instead, a non-trivial extension was developed in (Gong and Ye, 2015a).\nHere, by convexifying the nonconvex regularizer, (40) can be rewritten as\nmin x f\u0304(x) + \u00b5\u03ba0\u2016x\u20161, (41)\nwhere f\u0304(x) = f(x) + g\u0304(x), and g\u0304(x) = \u00b5 \u2211d\ni=1(\u03ba(|xi|)\u2212\u03ba0|xi|). It is easy to see that the analysis in (Gong and Ye, 2015b) can be extended to handle smooth but nonconvex f\u0304 . Thus, mOWL-QN is still guaranteed to converge to a critical point.\nAs demonstrated in previous sections, other DC decompositions of g are not as useful. For example, with the one in Proposition 6, we obtain the convex regularizer \u03c2\u0306(x) = \u03c1\u00b52 \u2016x\u2016 2 2 +\n\u00b5 \u2211d\ni=1 \u03ba(|xi|). However, mOWL-QN can no longer be applied, as it works only with the `1- regularizer.\nProblem (40) can be solved by either (i) directly using HONOR, or (ii) using mOWL-QN on the transformed problem (41). We believe that the latter approach is computationally more efficient. In (40), the Hessian depends on both terms in the objective, as the second-order derivative of \u03ba is not zero in general. However, HONOR constructs the approximate Hessian using only information from f , and thus ignores the curvature information due to \u2211d i=1 \u03ba(|xi|). On the other hand, the Hessian in (41) depends only on f\u0304 , as the Hessian due to \u2016x\u20161 is zero (Andrew and Gao, 2007), and mOWL-QN now extracts Hessian from f\u0304 . Hence, optimizing (41) with mOWL-QN is potentially faster, as all the second-order information is utilized. This will be verified empirically in Section 5.4."}, {"heading": "4.6 Nonsmooth and Nonconvex Loss", "text": "In many applications, besides having nonconvex regularizers, the loss function may also be nonconvex and nonsmooth. Thus, neither f nor g in (1) is convex, smooth. The optimization problem becomes even harder, and many existing algorithms cannot be used. In particular, the proximal algorithm requires f in (1) to be smooth (possibly nonconvex) (Gong et al., 2013; Li and Lin, 2015; Bot et al., 2016). The FW algorithm requires f in (4) to be smooth and convex (Jaggi, 2013). For the ADMM, it allows f in the consensus problem to be smooth, but g has to be convex (Hong et al., 2016). For problems of the form minx,z f(y) + g(y) : y = Ax, ADMM requires A to have full row-rank (Li and Pong, 2015). As will be seen, it is not satisfied for problems considered\nin this section. CCCP (Yuille and Rangarajan, 2002) and smoothing (Chen, 2012) are more general and can still be used, but are usually very slow.\nIn this section, we consider two application examples, and show how they can be efficiently solved with the proposed transformation."}, {"heading": "4.6.1 TOTAL VARIATION IMAGE DENOISING", "text": "Using the `1 loss and TV regularizer introduced in Section 4.1.3, consider the following optimization problem:\nmin X \u2016Y \u2212X\u20161 + \u00b5TV(X), (42)\nwhere Y \u2208 Rm\u00d7n is a given corrupted image, and X is the target image to be recovered. The use of nonconvex loss and regularizer often produce better performance (Yan, 2013). Thus, we consider the following nonconvex extension:\nmin X m\u2211 i=1 n\u2211 j=1 \u03ba (\u2223\u2223\u2223[Y \u2212X]ij\u2223\u2223\u2223)+ \u00b5m\u22121\u2211 i=1 m\u2211 j=1 \u03ba (\u2223\u2223\u2223[DvX]ij\u2223\u2223\u2223)+ \u00b5 n\u2211 i=1 n\u22121\u2211 j=1 \u03ba (\u2223\u2223\u2223[XDh]ij\u2223\u2223\u2223) , (43)\nwhere both the loss and regularizer are nonconvex and nonsmooth. As discussed above, this can be solved by CCCP and smoothing. However, as will be experimentally demonstrated in Section 5.5, their convergence is slow.\nUsing the proposed transformation on both the loss and regularizer, problem (43) can be transformed to the following problem:\nmin X\nf\u0304(X) + \u03ba0\u2016X \u2212 Y \u20161 + \u03ba0\u00b5TV(X), (44)\nwhere\nf\u0304(X) = m\u2211 i=1 n\u2211 j=1 \u03ba (\u2223\u2223\u2223[Y \u2212X]ij\u2223\u2223\u2223)\u2212 \u03ba0\u2016Y \u2212X\u20161\n+ \u00b5 m\u22121\u2211 i=1 m\u2211 j=1 \u03ba (\u2223\u2223\u2223[DvX]ij\u2223\u2223\u2223)\u2212 \u03ba0\u2016DvX\u20161 + n\u2211 i=1 n\u22121\u2211 j=1 \u03ba (\u2223\u2223\u2223[XDh]ij\u2223\u2223\u2223)\u2212 \u03ba0\u2016XDh\u20161  is smooth and nonconvex. As (44) is not a consensus problem, the method in (Hong et al., 2016) cannot be used. To use the ADMM algorithm in (Li and Pong, 2015), extra variables and constraints Zv = DvX and Zh = XDh have to be imposed. However, the full row-rank condition in (Li and Pong, 2015) does not hold.\nIn this section, we consider the proximal algorithm. Given some Z, the proximal step in (44) is\narg min X\n1 2 \u2016X \u2212 Z\u20162F + 1 \u03c4 (\u2016X \u2212 Y \u20161 + \u00b5TV(X)) , (45)\nwhere \u03c4 is the stepsize. Though this has no closed-form solution, \u2016X \u2212 Y \u20161 + \u00b5TV(X) in (45) is convex and one can thus monitor inexactness of the proximal step via the duality gap. Thus, we can\nuse the proposed inexact nmAPG algorithm in Algorithm 3 for (44). It can be shown that the dual of (45) is\nminW,P,Q 1 2\u03c4 \u2016W + \u00b5D>v P + \u00b5QD>h \u20162F \u2212 \u3008Z,W \u3009 \u2212 \u00b5\u3008DvZ,P \u3009 \u2212 \u00b5\u3008ZDh, Q\u3009+ \u3008Y,W \u3009\ns.t. \u2016W\u2016\u221e \u2264 1, \u2016P\u2016\u221e \u2264 1 and \u2016Q\u2016\u221e \u2264 1, (46)\nand the primal variable can be recovered as X = Z \u2212 1\u03c4 (W + \u00b5D > v P + \u00b5QD > h ). By substituting the obtained X into (45) and {W,P,Q} into (46), the duality gap can be computed in O(mn) time. As (46) is a smooth and convex problem, both accelerated gradient descent (Nesterov, 2013) and L-BFGS (Nocedal and Wright, 2006) can be applied. Algorithm 3 is then guaranteed to converge to a critical point of (43) (Theorem 7 and Proposition 8).\nNote that it is more advantageous to transform both the loss and regularizer in (44). If only the regularizer in (43) is transformed, we obtain\nf\u0304TV(X) + m\u2211 i=1 n\u2211 j=1 \u03ba (\u2223\u2223\u2223[Y \u2212X]ij\u2223\u2223\u2223)+ \u03ba0\u00b5TV(X), (47)\nwhere\nf\u0304TV(X) = \u00b5 m\u22121\u2211 i=1 m\u2211 j=1 \u03ba (\u2223\u2223\u2223[DvX]ij\u2223\u2223\u2223)\u2212 \u03ba0\u2016DvX\u20161 + n\u2211 i=1 n\u22121\u2211 j=1 \u03ba (\u2223\u2223\u2223[XDh]ij\u2223\u2223\u2223)\u2212 \u03ba0\u2016XDh\u20161  is nonconvex. The corresponding proximal step for (47) is\narg min X\n1 2 \u2016X \u2212 Z\u20162F + 1 \u03c4  m\u2211 i=1 n\u2211 j=1 \u03ba (\u2223\u2223\u2223[Y \u2212X]ij\u2223\u2223\u2223)+ \u03ba0\u00b5TV(X)  . (48) While the proximal steps in both (45) and (48) have no closed-form solution, working with (45) is more efficient. As (45) is convex, its dual can be efficiently solved with methods such as accelerated gradient descent and L-BFGS. In contrast, (48) is nonconvex, its duality gap is nonzero, and so can only be solved in the primal with slower methods like CCCP and smoothing. Besides, one can only use the more expensive nmAPG (Algorithm 2) but not the proposed inexact proximal algorithm."}, {"heading": "4.6.2 ROBUST SPARSE CODING", "text": "The second application is robust sparse coding, which has been popularly used in face recognition (Yang et al., 2011), image analysis (Lu et al., 2013) and background modeling (Zhao et al., 2011). Given an observed signal y \u2208 Rm, the goal is to seek a robust sparse representation x \u2208 Rd of y based on the dictionary D \u2208 Rm\u00d7d (which is assumed to be fixed here). Mathematically, it is formulated as the following optimization problem:\nmin x \u2016y \u2212Dx\u20161 + \u00b5\u2016x\u20161.\nIts nonconvex extension is:\nmin x m\u2211 j=1 \u03ba(|[y \u2212Dx]j |) + \u00b5 d\u2211 i=1 \u03ba(|xi|). (49)\nUsing the proposed transformation, problem (49) becomes\nmin x f\u0304(x) + \u03ba0\u2016y \u2212Dx\u20161 + \u00b5\u03ba0\u2016x\u20161, (50)\nwhere\nf\u0304(x) = \u00b5 d\u2211 j=1 \u03ba(|xj |)\u2212 \u03ba0\u00b5\u2016x\u20161 + m\u2211 j=1 \u03ba(|[y \u2212Dx]j |)\u2212 \u03ba0\u2016y \u2212Dx\u20161\nis smooth and nonconvex. Again, we use the inexact nmAPG algorithm in Algorithm 3. The proximal step for (50) is\narg min x\n1 2 \u2016x\u2212 z\u201622 + 1 \u03c4 (\u2016y \u2212Dx\u20161 + \u00b5\u2016x\u20161), (51)\nwhere \u03c4 is the stepsize and z is given. As in Section 4.6.1, \u2016y \u2212Dx\u20161 + \u00b5\u2016x\u20161 in (51) is convex, and one can monitor inexactness of the proximal step by the duality gap. The dual of (51) is\nmin p,q\n1\n2\u03c4 \u2016D>p+ \u00b5q\u201622 \u2212 p>Dz \u2212 \u00b5q>z : \u2016p\u2016\u221e \u2264 1, \u2016q\u2016\u221e \u2264 1. (52)\nAs in (46), this can be solved with L-BFGS or accelerated gradient descent. The primal variable can be recovered as x = z \u2212 1\u03c4 (D\n>p+ \u00b5q), and the duality gap can be checked in O(md) time. If only the regularizer is transformed, we obtain\nmin x m\u2211 j=1 \u03ba(|[y \u2212Dx]j |) + f\u0304RSC(x) + \u03ba0\u00b5\u2016x\u20161, (53)\nwhere f\u0304RSC(x) = \u00b5 \u2211d j=1 \u03ba(|xj |)\u2212 \u03ba0\u00b5\u2016x\u20161. The corresponding proximal step is\narg min x\n1 2 \u2016x\u2212 z\u201622 + m\u2211 j=1 \u03ba(|[y \u2212Dx]j |) + \u03ba0\u00b5\u2016x\u20161, (54)\nwhich still involve the nonconvex function \u03ba. As in Section 4.6.1, (52) is easier to solve than (54)."}, {"heading": "5. Experiments", "text": "In this section, we perform experiments on using the proposed procedure with (i) proximal algorithms (Sections 5.1 and 5.2); (ii) Frank-Wolfe algorithm (Section 5.3); (iii) comparision with HONOR (Section 5.4) and (vi) image denoising (Section 5.5). Experiments are performed on a PC with Intel i7 CPU and 32GB memory. All algorithms are implemented in Matlab."}, {"heading": "5.1 Nonconvex Sparse Group Lasso", "text": "In this section, we perform experiments on the nonconvex sparse group lasso model in Section 4.1.1. For simplicity, assume that \u00b51 = \u00b7 \u00b7 \u00b7 = \u00b5K = \u00b5. Using the square loss, (22) becomes\nmin x\n1 2 \u2016y \u2212A>x\u201622+\u03bb d\u2211 i=1 \u03ba(|xi|)+\u00b5 K\u2211 j=1 \u03ba(\u2016xGj\u20162), (55)\nwhere A = [a1, . . . , aN ]. In this experiment, we use the LSP regularizer in Table 1 (with \u03b8 = 0.5) as \u03ba(\u00b7). The synthetic data set is generated as follows. Let d = 10000. The ground-truth parameter x\u0304 \u2208 R10000 is divided into 100 non-overlapping groups: {1, . . . , 100}, {101, . . . , 200}, . . . , {9901, . . . , 10000} (Figure 2). We randomly set 75% of the groups to zero. In each nonzero group, we randomly set 25% of its features to zero, and generate the nonzero features from the standard normal distribution N (0, 1). The whole data set has 20, 000 samples, and entries of the input matrix A \u2208 R10000\u00d720000 are generated from N (0, 1). The ground-truth output is y\u0304 = A>x\u0304. This is then corrupted by random Gaussian noise in N (0, 0.05) to produce y = y\u0304 + .\nThe proposed algorithm will be called N2C (Nonconvex-to-Convex). The proximal step of the convexified regularizer g\u0306(x) = \u03ba0(\u03bb\u2016x\u20161 + \u2211K j=1 \u00b5j\u2016xGj\u20162) is obtained using the algorithm in (Yuan et al., 2011). The nmAPG algorithm (Algorithm 2) in (Li and Lin, 2015) is used for optimization. This will be compared with the following state-of-the-art algorithms:\n1. SCP: Sequential convex programming (Lu, 2012), in which the LSP regularizer is decomposed following (24).\n2. GIST (Gong et al., 2013): Since the nonconvex regularizer is not separable, the associated proximal operator has no closed-form solution. Instead, we use SCP (with warm-start) to solve it numerically.\n3. GD-PAN (Zhong and Kwok, 2014): It performs gradient descent with proximal average (Bauschke et al., 2008) of the nonconvex regularizers. Closed-form solutions for the proximal operator of each regularizer are obtained separately, and then averaged.\n4. nmAPG with the original nonconvex regularizer: As in GIST, the proximal step is solved numerically by SCP.\n5. As a baseline, we also compare with the FISTA (Beck, 2009) algorithm, which solves the convex sparse group lasso model (with \u03ba removed from (55)).\nWe do not compare with the concave-convex procedure (Yuille and Rangarajan, 2002), which has been shown to be slow (Gong et al., 2013; Zhong and Kwok, 2014).\nWe use 50% of the data for training, another 25% as validation set to tune \u03bb, \u00b5 in (55), and the rest for testing. The stepsize is fixed at \u03c4 = \u03c31(A>A). For performance evaluation, we use the (i) testing root-mean-squared error (RMSE) on the predictions; (ii) absolute error between the obtained parameter x\u0302 with ground-truth x\u0304: ABS = \u2016x\u0302 \u2212 x\u0304\u20161/d; and (iii) CPU time. To reduce statistical variability, the experimental results are averaged over 5 repetitions.\nResults are shown in Table 3. As can be seen, all the nonconvex models obtain better errors (RMSE and ABS) than the convex FISTA. As for the training speed, N2C is the fastest. SCP, GIST, nmAPG and N2C targets the original problem (1), and they have the same recovery performance. GD-PAN solves an approximate problem in each of its iterations, and its error is slightly worse than the other nonconvex algorithms on this data set.\nFigure 3 shows convergence of the objective with time and iterations for a typical run. SCP, GIST, nmAPG and N2C all converge towards the same objective value. GD-PAN can only approximate the original problem. Thus, it converges to an objective value which is larger than others. nmAPG and N2C are based on the state-of-the-art proximal algorithm (Algorithm 2. Both require nearly the same number of iterations for convergence (Figure 3(a)). However, as N2C has cheap closed-form solution for its proximal step, it is much faster when measured in terms of time (Figure 3(b)). Overall, N2C, which uses acceleration and inexpensive proximal step, is the fastest."}, {"heading": "5.2 Nonconvex Tree-Structured Group Lasso", "text": "In this section, we perform experiments on the nonconvex tree-structured group lasso model in Section 4.1.2. We use the face data set JAFFE1, which contains 213 images with seven facial expressions: anger, disgust, fear, happy, neutral, sadness and surprise. Following (Liu and Ye, 2010), we resize each image from 256 \u00d7 256 to 64 \u00d7 64. Their tree structure, which is based on pixel neighborhoods, is also used here. The total number of groups K is 85.\nSince our goal is only to demonstrate usefulness of the proposed convexification scheme, we focus on the binary classification problem \u201canger vs not-anger\u201d (with 30 anger images and 183 nonanger images). The logistic loss is used, which is more appropriate for classification. Given training samples {(a1, y1), . . . , (aN , yN )}, the optimization problem is then\nmin x N\u2211 i=1 wi log(1 + exp(\u2212yi \u00b7 a>i x)) + \u00b5 K\u2211 i=1 \u03bbi\u03ba(\u2016xGi\u20162),\n1. http://www.kasrl.org/jaffe.html\nwhere \u03ba(\u00b7) is the LSP regularizer (with \u03b8 = 0.5),, wi\u2019s are weights (set to be the reciprocal of the size of sample i\u2019s class) used to alleviate class imbalance, and \u03bbi = 1/ \u221a \u2016Gi\u20161 as in (Liu and Ye, 2010). We use 60% of the data for training, 20% for validation and the rest for testing. For the proposed N2C algorithm, the proximal step of the convexified regularizer is obtained as in (Liu and Ye, 2010).\nAs in Section 5.1, it is compared with SCP, GIST, GD-PAN, nmAPG, and FISTA. The stepsize \u03b7 is obtained by line search. For performance evaluation, we use (i) the testing accuracy; (ii) solution sparsity (i.e., percentage of nonzero elements); and (iii) CPU time. To reduce statistical variability, the experimental results are averaged over 5 repetitions.\nResults are shown in Table 4. As can be seen, all nonconvex models have similar testing accuracies, and they again outperform the convex model. Moreover, solutions from the nonconvex models are sparser. Overall, N2C is the fastest and has the sparsest solution.\nFigure 4 shows convergence of the algorithms versus CPU time and number of iterations. As can be seen, N2C is the fastest. GIST is the slowest, as it does not utilize acceleration and its proximal step is solved numerically which is expensive. GD-PAN converges to a less optimal solution due to its use of approximation. Moreover, as in Section 5.1, nmAPG and N2C show\nsimilar convergence behavior w.r.t. the number of iterations (Figure 4(b)), but N2C is much faster w.r.t. time (Figure 4(a))."}, {"heading": "5.3 Nonconvex Low-Rank Matrix Completion", "text": "In this section, we perform experiments on nonconvex low-rank matrix completion (Section 4.2), with square loss in (26). The LSP regularizer is used, with \u03b8 = \u221a \u00b5 as in (Yao et al., 2015). We use the MovieLens data sets2 (Table 5), which have been commonly used for evaluating matrix completion (Hsieh and Olsen, 2014; Yao et al., 2015). They contain ratings {1, 2, . . . , 5} assigned by various users on movies.\nThe proposed Frank-Wolfe procedure (Algorithm 4), denoted N2C-FW, is compared with the following algorithms:\n1. FaNCL (Yao et al., 2015): This is a recent nonconvex matrix regularization algorithm. It is based on the proximal algorithm using efficient approximate SVD and automatic thresholding of singular values.\n2. LMaFit (Wen et al., 2012): It factorizes X as a product of low-rank matrices U \u2208 Rm\u00d7k and V \u2208 Rn\u00d7k. The nonconvex objective 12\u2016P\u2126(UV\n> \u2212 O)\u20162F is then minimized by alternating minimization on U and V using gradient descent.\n2. http://grouplens.org/datasets/movielens/\n3. Active subspace selection (denoted \u201cactive\u201d) (Hsieh and Olsen, 2014): This solves the (convex) nuclear norm regularized problem (with \u03ba being the identity function in (8)) by using the active row/column subspaces to reduce the optimization problem size.\nWe do not compare with IRNN (Lu et al., 2014) and GPG (Lu et al., 2015), which have been shown to be much slower than FaNCL (Yao et al., 2015).\nFollowing (Yao et al., 2015), we use 50% of the ratings for training, 25% for validation and the rest for testing. For performance evaluation, we use (i) the testing RMSE; and (ii) the recovered rank. To reduce statistical variability, the experimental results are averaged over 5 repetitions.\nResults are shown in Table 6. As can be seen, the nonconvex models (N2C-FW, FaNCL and LMaFit) achieve lower RMSEs than the convex model (active), with N2C-FW having the smallest RMSE. Moreover, the convex model needs a much higher rank than the nonconvex models, which agrees with the previous observations in (Mazumder et al., 2010; Yao et al., 2015). Thus, its running time is also much longer than the others. Figure 5 shows the convergence of the objective with CPU time. As the recovered matrixs rank for the nonconvex models are very low (2 to 9 in Table 6), N2C-FW is much faster than the others as it starts from a rank-one matrix and only increases its rank by one in each iteration. Though FaNCL uses singular value thresholding to truncate the SVD, it does not control the rank as directly as N2C-FW and so is still slower."}, {"heading": "5.4 Comparison with HONOR", "text": "In this section, we experimentally compare the proposed method with HONOR (Section 4.5) on the model in (40), using the logistic loss and LSP regularizer. Following (Gong and Ye, 2015a), we fix \u00b5 = 1 in (40), and \u03b8 in the LSP regularizer to 0.01\u00b5. Experiments are performed on three large data sets, kdd2010a, kdd2010b and url 3 (Table 7). Both kdd2010a and kdd2010b are educational data sets, and the task is to predict students\u2019 successful attempts to answer concepts related to algebra.\n3. https://www.csie.ntu.edu.tw/\u02dccjlin/libsvmtools/datasets/binary.html\nThe url data set contains a collection of websites, and the task is to predict whether a particular website is malicious. We compare\n1. running HONOR (Gong and Ye, 2015a) directly on (40). The threshold of the hybrid step in HONOR is set to 10\u221210, which yields the best empirical performance in (Gong and Ye, 2015a);\n2. running mOWL-QN (Gong and Ye, 2015b)) on the transformed problem (41).\nTo reduce statistical variability, the experimental results are averaged over 5 repetitions. As (40) and (41) have the same optimization objective, Figure 6 shows the convergence of the objective with CPU time. As can be seen, mOWL-QN converges faster than HONOR. This validates our claim that the curvature information of the nonconvex regularizer helps."}, {"heading": "5.5 Image Denoising", "text": "In this section, we perform experiments on total variation image denoising with nonconvex loss and nonconvex regularizer (as introduced in Section 4.6.1). The LSP function (with \u03b8 = 1) is used as \u03ba in (43) on both the loss and regularizer. Eight popular images4 from (Dabov et al., 2007) are used (Figure 7). They are then corrupted by pepper-and-salt noise, with 10% of the pixels randomly set to 0 or 255 with equal probabilities.\nFor performance evaluation, we use the RMSE = \u221a\n1 mn \u2211m i=1 \u2211n j=1(Xij \u2212 X\u0304ij)2, where X\u0304 \u2208\nRm\u00d7n is the clean image, and X \u2208 Rm\u00d7n is the recovered image. To tune \u00b5, we pick the value\n4. http://www.cs.tut.fi/\u02dcfoi/GCF-BM3D/\nthat leads to the smallest RMSE on the first four images (boat, couple, fprint, hill). Denoising performance is then reported on the remaining images (house, lena, man, peppers).\nThe following algorithms will be compared:\n1. CCCP (Yuille and Rangarajan, 2002): Proposition 6 is used to construct DC decomposition for \u03ba (Details are at Appendix B.1);\n2. Smoothing (Chen, 2012): The nonsmooth \u03ba is smoothed, and then gradient descent is used (Details are at Appendix B.2);\n3. nmAPG (Li and Lin, 2015): This optimizes (47) with Algorithm 2, and the exact proximal step is solved numerically using CCCP;\n4. inexact-nmAPG: This optimizes (44) with Algorithm 3 (with t = 0.95t), and the inexact proximal step is solved numerically using L-BFGS.\n5. As a baseline, we also compare with ADMM (Boyd et al., 2011) with the convex formulation.\nTo reduce statistical variability, the experimental results are averaged over 5 repetitions. The RMSE results are shown in Table 8. As can be seen, the (convex) ADMM formulation leads to the highest RMSE, while CCCP, smoothing, nmAPG and inexact-nmAPG have the same RMSE which is lower than that of ADMM. This agrees with previous observations that nonconvex formulations can yield better performance than the convex ones. Timing results are shown in Table 9 and Figure 8. As can be seen, smoothing has low iteration complexity but suffers from slow convergence. CCCP and nmAPG both need to exactly solve a subproblem, and thus are also slow. The inexactnmAPG algorithm does not guarantee the objective value to be monotonically decreasing as iteration proceeds. As the inexactness is initially large, there is an initial spike in the objective. However, inexact-nmAPG then quickly converges, and is much faster than all the baselines."}, {"heading": "6. Conclusion", "text": "In this paper, we proposed a novel approach to learning with nonconvex regularizers. By moving the nonconvexity associated with the nonconvex regularizer to the loss, the nonconvex regularizer is convexified to become a familiar convex regularizer while the augmented loss is still Lipschitz smooth. This allows one to reuse efficient algorithms originally designed for convex regularizers\non the transformed problem. To illustrate usages with the proposed transformation, we plug it into many popular optimization algorithms. First, we consider the proximal algorithm, and showed that while the proximal step is expensive on the original problem, it becomes much easier on the transformed problem. We further propose an inexact proximal algorithm, which allows inexact update of proximal step when it does not have a closed-form solution. Second, we combine the proposed convexification scheme with the Frank-Wolfe algorithm on learning low-rank matrices, and showed that its crucial linear programming step becomes cheaper and more easily solvable. As no convergence results exist on this nonconvex problem, we designed a novel Frank-Wolfe algorithm based on the proposed transformation and with convergence guarantee. Third, when using with ADMM and SVRG, we showed that the existing convergence results can be applied on the transformed problem but not on the original one. We further extend the proposed transformation to handle nonconvex and nonsmooth loss functions, and illustrate its benefits on the total variation model and robust sparse coding. Finally, we demonstrate the empirical advantages of working with the transformed problems on various tasks with both synthetic and real-world data sets. Experimental results show that better performance can be obtained with nonconvex regularizers, and algorithms on the transformed problems run much faster than the state-of-the-art on the original problems."}, {"heading": "Appendix A. Proofs", "text": ""}, {"heading": "A.1 Proposition 1", "text": "Proof First, we introduce a few Lemmas.\nLemma 13 (Golub and Van Loan, 2012) For x 6= 0, the gradient of the `2-norm is \u2207xi\u2016x\u20162 = xi/\u2016x\u20162.\nLet h(z) = \u03ba(\u2016z\u20162)\u2212 \u03ba0\u2016z\u20162.\nLemma 14\n\u2207zih(z) =\n{ \u03ba\u2032(\u2016z\u20162)\u2212\u03ba0 \u2016z\u20162 zi if z 6= 0\n0 otherwise . (56)\nProof For z 6= 0, \u2016z\u20162 is differentiable (Lemma 13), and we obtain the first part of (56). For z = 0, let h\u0304i(z) = \u03ba\u2032(\u2016z\u20162)\u2212\u03ba0 \u2016z\u20162 zi. Consider any \u2206 with \u2016\u2206\u20162 = 1.\nlim \u03b1\u21920+ h\u0304i(0 + \u03b1\u2206) = lim \u03b1\u21920+ \u03ba\u2032(\u2016\u03b1\u2206\u20162)\u2212 \u03ba0 \u2016\u03b1\u2206\u20162 \u03b1\u2206i,\n= lim \u03b1\u21920+\n(\u03ba\u2032(\u03b1)\u2212 \u03ba0)\u2206i = 0,\nas lim\u03b1\u21920+ \u03ba\u2032(\u03b1)\u2212\u03ba0 = 0. Thus, h(z) is smooth at z = 0, and we obtain the second part of (56).\nLemma 15 (Eriksson et al., 2004) Let f : R \u2192 R be a differentiable function. (i) If its derivative f \u2032 is bounded, then f is Lipschitz-continuous with constant equal to the maximum value of |f \u2032|.\nLemma 16 (Eriksson et al., 2004) If a continuous function f : R\u2192 R isL1-Lipschitz continuous in [a, b] and L2-Lipschitz continuous in [b, c] (where \u2212\u221e \u2264 a < b < c \u2264 \u221e), then it is max(L1, L2)Lipschitz continuous in [a, c].\nLemma 17 Let z be an arbitrary vector, and ei be the unit vector with only its ith dimension equal to 1. Define h\u0302i(\u03b3) =\n\u03ba\u2032(\u2016z+ei\u03b3\u20162)\u2212\u03ba0 \u2016z+ei\u03b3\u20162 (zi + \u03b3). Then, h\u0302 is 2\u03c1-Lipschitz continuous.\nProof Since \u03ba\u2032 is non-differentiable only at finite points, and let them be {\u03b1\u03021, . . . , \u03b1\u0302k} where \u03b1\u03021 < \u00b7 \u00b7 \u00b7 < \u03b1\u0302k. We partition (\u2212\u221e,\u221e) into intervals (\u2212\u221e, \u03b1\u03021] \u222a [\u03b1\u03021, \u03b1\u03022] \u222a \u00b7 \u00b7 \u00b7 \u222a [\u03b1\u0302k,\u221e), such that \u03ba\u2032\u2032 exists in each interval. Let w = z + ei\u03b3. For any interval,\nh\u0302\u2032i(\u03b3) = \u03ba\u2032\u2032(\u2016w\u20162) \u2016w\u20162 (zi + \u03b3) 2 +\n( 1\u2212 (zi + \u03b3) 2\n\u2016w\u201622 ) \u03ba\u2032(\u2016w\u20162)\u2212 \u03ba0 \u2016w\u20162 . (57)\nLet \u03c6(\u03b1) = \u03ba\u2032(\u03b1) \u2212 \u03ba0, where \u03b1 \u2265 0. Note that \u03c6(0) = 0. Moreover, \u03c6(\u03b1) is \u03c1-Lipschitz continuous as \u03ba is \u03c1-Lipschitz smooth. Thus,\n|\u03c6(\u03b1)\u2212 \u03c6(0)| = |\u03ba\u2032(\u03b1)\u2212 \u03ba0| \u2264 \u03c1\u03b1,\nand so \u2223\u2223\u03ba\u2032(\u2016w\u20162)\u2212 \u03ba0\u2223\u2223 \u2264 \u03c1\u2016w\u20162. (58) Note that (zi + \u03b3)2 \u2264 \u2016w\u201622, (57) can be written as\u2223\u2223\u2223h\u0302\u2032i(\u03b3)\u2223\u2223\u2223 \u2264 \u2223\u2223\u2223\u2223\u03ba\u2032\u2032(\u2016w\u20162)\u2016w\u20162 (zi + \u03b3)2 \u2223\u2223\u2223\u2223+ \u2223\u2223\u2223\u2223(1\u2212 (zi + \u03b3)2\u2016w\u201622 ) \u03ba\u2032(\u2016w\u20162)\u2212 \u03ba0 \u2016w\u20162\n\u2223\u2223\u2223\u2223 \u2264 \u2223\u2223\u03ba\u2032\u2032(\u2016w\u20162)\u2223\u2223+ \u2223\u2223\u2223\u2223\u03ba\u2032(\u2016w\u20162)\u2212 \u03ba0\u2016w\u20162\n\u2223\u2223\u2223\u2223 \u2264 2\u03c1, where the last inequality is due to that \u03ba is \u03c1-Lipschitz smooth and (58). Thus, |h\u0302\u2032i(\u03b3)| \u2264 2\u03c1, and by Lemma 15, we have h\u0302i(\u03b3) is 2\u03c1-Lipschitz continuous on any interval. Obviously h\u0302i is continuous, and we conclude that h\u0302i is also 2\u03c1-Lipschitz continuous by Lemma 16.\nFrom Lemma 17, h\u0302i is 2\u03c1-Lipschitz continuous. Thus, \u2207h is 2\u03c1-Lipschitz continuous in each of its dimensions. For any x, y \u2208 Rd,\n\u2016\u2207h(x)\u2212\u2207h(y)\u201622 = d\u2211 i=1 [\u2207xih(x)\u2212\u2207yih(y)] 2\n\u2264 4\u03c12 d\u2211 i=1 (xi \u2212 yi)2 = 4\u03c12\u2016x\u2212 y\u201622,\nand hence h is 2\u03c1-Lipschitz smooth. Finally, we will show that h(z) is also concave.\nLemma 18 (Boyd and Vandenberghe, 2004) \u03c6(x) = \u03c0(q(x)) is concave if \u03c0 is concave, nonincreasing and q is convex.\nLet \u03c0(\u03b1) = \u03ba(\u03b1) \u2212 \u03ba0\u03b1, where \u03b1 \u2265 0. Note that \u03c0 is concave. Moreover, \u03c0(0) = 0 and \u03c0\u2032(\u03b1) \u2264 0. Thus, \u03c0(\u03b1) is non-increasing on \u03b1 \u2265 0. Next, let q(z) = \u2016z\u20162. Then, h(z) \u2261 \u03ba(\u2016z\u20162)\u2212 \u03ba0\u2016z\u20162 = \u03c0(q(z)). As q is convex, h(z) is concave from Lemma 18."}, {"heading": "A.2 Corollary 2", "text": "Proof From Proposition 1 and definition of g\u0304i, we can see it is concave. Then, for any x, y,\n\u2016\u2207h(Aix)\u2212\u2207h(Aiy)\u201622 \u2264 4\u03c12\u2016Aix\u2212Aiy\u201622 \u2264 4\u03c12\u2016Ai\u20162F \u2016x\u2212 y\u201622.\nThus, g\u0304i is 2\u03c1\u2016Ai\u2016F -Lipschitz smooth."}, {"heading": "A.3 Corollary 3", "text": "Proof It is easy to see that g\u0306(x) = \u03ba0 \u2211K\ni=1 \u00b5i\u2016Aix\u20162 is convex but not smooth. Using Corollary 2, as each g\u0304i is concave and Lipschitz-smooth, g\u0304 is also concave and Lipschitz-smooth."}, {"heading": "A.4 Proposition 5", "text": "Proof First, we introduce a few lemmas.\nDefinition 19 (Bertsekas, 1999) A function f : Rm \u2192 R is absolute symmetric if f ([x1; . . . ;xm]) = f ([ |x\u03c0(1)|; . . . ; |x\u03c0(m)| ]) for any permutation \u03c0.\nLemma 20 (Lewis and Sendov, 2005) Let \u03c3(X) = [\u03c31(X); . . . ;\u03c3m(X)] be the vector containing singular values of X . For an absolute symmetric function f : Rm \u2192 R, \u03c6(X) \u2261 f(\u03c3(X)) is concave on X if and only if f is concave.\nFrom the definition of g\u0304 in (21),\ng\u0304(X) = \u00b5\u0304 m\u2211 i=1 (\u03ba(\u03c3i(X))\u2212 \u03ba0\u2016X\u2016\u2217) = \u00b5\u0304 m\u2211 i=1 (\u03ba(\u03c3i(X))\u2212 \u03ba0\u03c3i(X)) .\nLet\nh(x) = \u00b5\u0304 m\u2211 i=1 (\u03ba(|xi|)\u2212 \u03ba0|xi|). (59)\nObviously, h is absolute symmetric. From Remark 4, h is concave. Thus, g\u0304 is also concave by Lemma 20.\nLemma 21 (Lewis and Sendov, 2005) Let the SVD of X be UDiag(\u03c3(X))V >, where \u03c3(X) = [\u03c31(X); . . . ;\u03c3m(X)], f : Rm \u2192 R be smooth and absolute symmetric, and \u03c6(X) \u2261 f(\u03c3(X)). We have\n1. \u2207\u03c6(X) = UDiag(\u2207f(\u03c3(X)))V >; and\n2. If f is L-Lipschitz smooth, then \u03c6 is also L-Lipschitz smooth.\nFrom Remark 4, h in (59) is 2\u03c1-Lipschitz smooth. Hence, from Lemma 21, g\u0304(X) is also 2\u03c1Lipschitz smooth and\u2207g\u0304(X) = UDiag(\u2207h(\u03c3(X)))V >."}, {"heading": "A.5 Proposition 6", "text": "Proof First, we introduce the following lemma.\nLemma 22 (Boyd and Vandenberghe, 2004) \u03c6(x) = \u03c0(q(x)) is convex if \u03c0 is convex, nondecreasing and q is convex.\nLet q(x) = \u2016x\u20162, and \u03c0(\u03b1) = \u03ba(\u03b1) + \u03c12\u03b1 2 where \u03b1 \u2265 0. Thus, \u03c6(x) = \u03c0(q(x)) = \u03ba(\u2016x\u20162) + \u03c12\u2016x\u2016 2 2. Obviously, q is convex. For \u03b1 \u2265 \u03b2 \u2265 0, 0 \u2264 \u03ba\u2032(\u03b1) \u2264 \u03ba\u2032(\u03b2). As \u03ba is \u03c1Lipschitz smooth, \u03ba\u2032(\u03b2)\u2212\u03ba\u2032(\u03b1) \u2264 \u03c1(\u03b1\u2212\u03b2). Thus, \u03c0\u2032(\u03b1)\u2212\u03c0\u2032(\u03b2) = \u03ba\u2032(\u03b1)+\u03c1\u03b1\u2212\u03ba\u2032(\u03b2)\u2212\u03c1\u03b2 \u2265 0, i.e., \u03c0 is convex. Besides, \u03c0\u2032(0) = \u03ba\u2032(0) \u2265 0. Thus, \u03c0\u2032(\u03b1) \u2265 0 and \u03c0 is also non-decreasing. By Lemma 22, \u03c6 is also convex."}, {"heading": "A.6 Theorem 7", "text": "Proof First, we introduce a few lemmas.\nLemma 23 Let X\u0303 be an inexact solution of the proximal step minZ h(Z), where h(Z) = 12\u2016Z \u2212 (X \u2212 1\u03c4\u2207f\u0304(X))\u2016 2 F + 1 \u03c4 g\u0306(Z). Let X\u0302 = arg minZ h(Z). If h(X\u0303)\u2212 h(X\u0302) \u2264 , then\nF (X\u0303) \u2264 F (X)\u2212 \u03c4 \u2212 L\u0304 2 \u2016X\u0303 \u2212X\u20162F + \u03c4 .\nProof Let \u03c6(Z) = \u3008Z \u2212X,\u2207f(X)\u3009+ \u03c42\u2016Z \u2212X\u2016 2 F + g\u0306(Z). We have\nX\u0302 = arg min Z h(Z) = arg min Z \u03c6(Z), (60) \u03c6(Z) = \u03c4h(Z)\u2212 1 \u03c4 \u2016\u2207f\u0304(X)\u20162F . (61)\nFrom (60), we have\n\u03c6(X\u0302) = \u3008X\u0302 \u2212X,\u2207f(X)\u3009+ \u03c4 2 \u2016X\u0302 \u2212X\u20162F + g\u0306(X\u0302) \u2264 g\u0306(X). (62)\nAs h(X\u0303)\u2212 h(X\u0302) \u2264 , from (61) (note that \u2016\u2207f\u0304(X)\u20162F is a constant), we have\n\u03c6(X\u0303)\u2212 \u03c6(X\u0302) = \u03c4(h(X\u0303)\u2212 h(X\u0302)) \u2264 \u03c4\nThen with (62), we have \u03c6(X\u0303) \u2264 \u03c4 + \u03c6(X\u0302) \u2264 g\u0306(X) + \u03c4 , i.e.,\n\u3008X\u0303 \u2212X,\u2207f(X)\u3009+ \u03c4 2 \u2016X\u0303 \u2212X\u20162F + g\u0306(X\u0303) \u2264 g\u0306(X) + \u03c4 . (63)\nAs f\u0304 is L\u0304-Lipschitz smooth,\nf\u0304(X\u0303) \u2264 f\u0304(X) + \u3008X\u0303 \u2212X,\u2207f(X)\u3009+ L\u0304 2 \u2016X\u0303 \u2212X\u20162F .\nCombining with (63), we obtain\nf\u0304(X\u0303) + \u03c4\n2 \u2016X\u0303 \u2212X\u201622 + g\u0306(X\u0303) \u2264 f\u0304(X) +\nL\u0304 2 \u2016X\u0303 \u2212X\u20162F + g\u0306(X) + \u03c4 .\nThus, F (X\u0303) \u2264 F (X)\u2212 \u03c4\u2212L\u03042 \u2016X\u0303 \u2212X\u2016 2 F + \u03c4 .\nIf step 6 in Algorithm 3 is satisfied, Xt+1 = Z\u0303t+1, and\nF (Xt+1) \u2264 F (Xt)\u2212 \u03b4\n2 \u2016Xt+1 \u2212 Yt\u20162F . (64)\nOtherwise, step 9 is executed, and from Lemma 23, we have\nF (Xt+1) \u2264 F (Xt)\u2212 \u03c4 \u2212 L\u0304\n2 \u2016Xt+1 \u2212Xt\u20162F + \u03c4 t. (65)\nPartition \u2126(T ) = {1, 2, . . . , T} into \u21261(T ) and \u21262(T ), such that step 7 is performed if t \u2208 \u21261(T ); and execute step 9 otherwise. Combining (64) and (65), we have\nF (X1)\u2212 F (XT+1)\n\u2265 \u03b4 2 \u2211 t\u2208\u21261(T ) \u2016Xt+1 \u2212 Yt\u20162F + \u03c4 \u2212 L\u0304 2 \u2211 t\u2208\u21262(T ) ( \u2016Xt+1 \u2212Xt\u20162F \u2212 \u03c4 t ) ,\n\u2265 \u03b4 2 \u2211 t\u2208\u21261(T ) \u2016Xt+1 \u2212 Yt\u20162F + \u03c4 \u2212 L\u0304 2 \u2211 t\u2208\u21262(T ) \u2016Xt+1 \u2212Xt\u20162F \u2212 (\u03c4 \u2212 L\u0304)\u03c4 2 \u2211 t\u2208\u21262(T ) t\n\u2265 \u03b4 2 \u2211 t\u2208\u21261(T ) \u2016Xt+1 \u2212 Yt\u20162F + \u03c4 \u2212 L\u0304 2 \u2211 t\u2208\u21262(T ) \u2016Xt+1 \u2212Xt\u20162F \u2212 (\u03c4 \u2212 L\u0304)\u03c4 2 \u221e\u2211 t=1 t\n\u2265 \u03b4 2 \u2211 t\u2208\u21261(T ) \u2016Xt+1 \u2212 Yt\u20162F \u2212 c1 + \u03c4 \u2212 L\u0304 2 \u2211 t\u2208\u21262(T ) \u2016Xt+1 \u2212Xt\u20162F , (66)\nwhere c1 = (\u03c4\u2212L\u0304)\u03c4\n2\n\u2211\u221e t=1 t <\u221e and c1 \u2265 0. From (66), we have\nF (X1)\u2212 inf X F (X) + c1 \u2265 F (X1)\u2212 lim T\u2192\u221e F (XT+1) + c1\n\u2265 lim T\u2192\u221e\n\u03b4\n2 \u2211 t\u2208\u21261(T ) \u2016Xt+1 \u2212 Yt\u20162F + \u03c4 \u2212 L\u0304 2 \u2211 t\u2208\u21262(T ) \u2016Xt+1 \u2212Xt\u20162F \u2261 c2. (67)\nFrom Assumption A1, c2 \u2264 F (X1) \u2212 infX F (X) + c1 < \u221e, thus c2 \u2265 0 is a finite constant. Let \u2126\u221e1 = limT\u2192\u221e\u21261(T ), and \u2126 \u221e 2 = limT\u2192\u221e\u21262(T ). Consider the three cases:\n1. |\u2126\u221e1 | is finite, and |\u2126\u221e2 | is infinite. As |\u2126\u221e2 | = \u221e and lim\u2016X\u2016F\u2192\u221e F (X) = \u221e from Assumption A1 and (67), we must have\nlim t\u2208\u2126\u221e2 ,t\u2192\u221e\n\u2016Xt+1 \u2212Xt\u20162F = 0.\nThus, there exists a limit point such that X\u2217 = limtj\u2208\u2126\u221e2 ,tj\u2192\u221eXtj for a subsequence {Xtj} of {Xt}. Since limtj\u2192\u221e tj = 0, then\nlim tj\u2208\u2126\u221e2 ,tj\u2192\u221e Xtj+1 = lim tj\u2208\u2126\u221e2 ,tj\u2192\u221e prox 1 \u03c4 g\u0306(Xtj \u2212\n1 \u03c4 \u2207f\u0304(Xtj )).\nAs a result,\n0 \u2208 lim tj\u2208\u2126\u221e2 ,tj\u2192\u221e\n1 \u03c4 \u2207f\u0304(Xtj ) + (Xtj+1 \u2212Xtj ) + 1 \u03c4 \u2202g\u0306(Xtj+1).\nSince both limtj\u2208\u2126\u221e2 ,tj\u2192\u221eXtj = limtj\u2208\u2126\u221e2 ,tj\u2192\u221eXtj+1 = X\u2217, we then have \u2207f\u0304(X\u2217) + \u2202g\u0306(X\u2217) 3 0, and X\u2217 is a critical point of (1).\n2. |\u2126\u221e1 | is infinite, and |\u2126\u221e2 | is finite. As \u2126\u221e1 is infinite and lim\u2016X\u2016F\u2192\u221e F (X) = \u221e from Assumption A1 and (67), we must have\nlim tj\u2208\u2126\u221e1 ,tj\u2192\u221e\n\u2016Xtj+1 \u2212 Ytj\u20162F = 0.\nfor a subsequence {Xtj} of {Xt}. Thus, there must exist a limit point such that\nX\u2217 = lim tj\u2208\u2126\u221e1 ,tj\u2192\u221e Xtj+1 = lim tj\u2208\u2126\u221e1 ,tj\u2192\u221e Ytj . (68)\nAs limtj\u2192\u221e tj = 0, we have\n0 \u2208 lim tj\u2208\u2126\u221e1 ,tj\u2192\u221e\n1 \u03c4 \u2207f\u0304(Ytj ) + (Xtj+1 \u2212 Ytj ) + 1 \u03c4 \u2202g\u0306(Xtj+1).\nFrom (68), thus we have\u2207f\u0304(X\u2217) + \u2202g\u0306(X\u2217) 3 0 and X\u2217 is a critical point of (1).\n3. Both \u2126\u221e1 and \u2126 \u221e 2 are infinite. From above two cases, we can see {Xt} is bounded and, the\nlimit points of {Xt} are also critical points either |\u2126\u221e1 | or |\u2126\u221e2 | is infinite. In the third case, both of them are infinite, thus any limit points of {Xt} are also critical points of (1).\nAs a result, {Xt} are bounded and its limits points are all critical points of (1)."}, {"heading": "A.7 Proposition 8", "text": "Proof From (67), we have\n\u03b4\n2 \u2211 t1\u2208\u21261(T ) \u2016Xt1+1 \u2212 Yt1\u20162F + \u03c4 \u2212 L\u0304 2 \u2211 t2\u2208\u21262(T ) \u2016Xt2+1 \u2212Xt2\u20162F < c2, (69)\nwhere c2 \u2208 (0,\u221e) is a positive constant. Let c3 = min( \u03b42 , \u03c4\u2212L\u0304\n2 ) and using the definition of Vt, (69) can be written as\nc3 T\u2211 t=1 \u2016Xt+1 \u2212 Vt\u20162F \u2264 \u03b4 2 \u2211 t1\u2208\u21261(T ) \u2016Xt1+1 \u2212 Yt1\u20162F + \u03c4 \u2212 L\u0304 2 \u2211 t2\u2208\u21262(T ) \u2016Xt2+1 \u2212Xt2\u20162F \u2264 c2.\nSince c2 is finite, thus limt\u2192\u221e dt \u2261 \u2016Xt+1 \u2212 Vt\u20162F = 0. Besides, we have\nmin t=1,...,T T\u2211 t=1 \u2016Xt+1 \u2212 Vt\u20162F \u2264 1 T T\u2211 t=1 \u2016Xt+1 \u2212 Vt\u20162F \u2264 c2 c3T ."}, {"heading": "A.8 Proposition 9", "text": "Proof Note from (28) that \u2207f\u0304(S) = \u2207f(S) + \u2207g\u0304(S). Using the matrix chain rule, since S = \u03b1Xt + \u03b2utv > t and \u2202S \u2202\u03b1 = Xt, then\n\u2202f\u0304(S)\n\u2202\u03b1 =\n\u2329 \u2207f\u0304(S), \u2202S\n\u2202\u03b1\n\u232a = \u03b1\u3008Xt,\u2207f\u0304(S)\u3009.\nSimilarly, since \u2202S\u2202\u03b2 = utv > t\n\u2202f\u0304(S)\n\u2202\u03b2 =\n\u2329 \u2207f\u0304(S), \u2202S\n\u2202\u03b2\n\u232a = \u03b2 \u2329 utv > t ,\u2207f\u0304(S) \u232a = \u03b2 ( u>t \u2207f\u0304(S)vt ) .\nAs g\u0304(S) = \u00b5 \u2211m\ni=1 \u03ba(\u03c3i(S))\u2212\u00b5\u03ba0\u03c3i(S), using Lemma 21,\u2207f\u0304(X) = \u2207f(S) +\u00b5USDiag(w)V >S and wi = \u03ba\u2032(\u03c3i(S))\u2212 \u03ba0."}, {"heading": "A.9 Corollary 10", "text": "Proof Note that the SVD of X is (UUB)Diag([\u03c31(B), . . . , \u03c3k(B)])(V VB)>. Using Lemma 21,\n\u2207f\u0304(X) = \u2207f(X) +\u2207g\u0304(X) = \u2207f(X) + \u00b5(UUB)Diag(w)(V VB)>.\nwhere w \u2208 Rk with wi = \u03ba\u2032(\u03c3i(B))\u2212 \u03ba0."}, {"heading": "A.10 Proposition 11", "text": "Proof As g\u0304(X) is defined on singular values of the input matrix X , we only need to show UBV > and B have exactly the same singular values. Let SVD of B = UBDiag(\u03c3(B))V >B where \u03c3(B) = [\u03c31(B), . . . , \u03c3m(B)]. As U and V are orthogonal, it is easy to see (UUB) Diag(\u03c3(B)) (VBV )\n> is the SVD of X . Thus, the Proposition holds."}, {"heading": "A.11 Theorem 12", "text": "Proof We first introduce two propositions.\nProposition 24 (Mishra et al., 2013) For a square matrix X , let sym(X) = 12(X + X >). The first-order optimality conditions for (33) are\n\u2207f\u0304(X)V B \u2212 U sym(U>\u2207f\u0304(X)V B) = 0, (\u2207f\u0304(X))>UB \u2212 V sym(V >\u2207f\u0304(X)UB) = 0,\nsym(U>\u2207f\u0304(X)V ) + \u00b5\u0304I = 0.\nProposition 25 If (27) has a critical point with rank-r, choose matrix size of U \u2208 Rm\u00d7r, V \u2208 Rn\u00d7r and B \u2208 Sr\u00d7r+ , then any critical points of (33) is also a critical point of (27).\nProof Subdifferential of the nuclear norm can be obtained as (Watson, 1992)\n\u2202\u2016X\u2016\u2217 = {UV > +W : U>W = 0,WV = 0, \u2016W\u2016\u221e \u2264 1}, (70)\nwhere X = UBV >. Let X\u0302 = U\u0302 B\u0302V\u0302 > be a critical point of (33), we have sym(U\u0302>\u2207f\u0304(X\u0302)V\u0302 ) + \u00b5\u0304I = 0 dues to Proposition 24. From property of matrix norm, we have\n\u03bb = \u2016 sym(U\u0302>\u2207f\u0304(X\u0302)V\u0302 )\u2016\u221e \u2264 \u2016U\u0302>\u2207f\u0304(X\u0302)V\u0302 \u2016\u221e \u2264 \u2016\u2207f\u0304(X\u0302)\u2016\u221e.\nThe equality holds only when\u2207f\u0304(X\u0302) = \u2212\u00b5\u0304U\u0302 V\u0302 > \u2212 \u00b5\u0304U\u0302\u22a5\u03a3\u0302\u22a5V\u0302 >\u22a5 where U\u0302\u22a5 and V\u0302\u22a5 are orthogonal matrix with U\u0302>U\u0302\u22a5 = 0 and V\u0302 >V\u0302\u22a5 = 0, and \u03a3\u0302\u22a5 is a diagonal matrix with positive elements [\u03a3\u22a5]ii \u2264 1. Combining this fact with (70), we can see\n\u2207f\u0304(X\u0302) \u2208 \u2212\u00b5\u0304\u2202\u2016X\u0302\u2016\u2217. (71)\nThen, for (27), if X\u2217 is a critical point then we have\n\u2207f\u0304(X\u2217) \u2208 \u2212\u00b5\u0304\u2202\u2016X\u2217\u2016\u2217. (72)\nComparing (71) and (72), the difference is on rank of X\u0302 and X\u2217. As (27) has a critical point with rank-r a critical point of (33), X\u0302 is also a critical point of (27).\nIn Algorithm 4, the size of U , V and B are picked up as m \u00d7 t, n \u00d7 t and t \u00d7 t. If (27) has a critical point with rank-r, then as iteration goes and t = r, from Proposition 25, Algorithm 4 will return a critical point of (27)."}, {"heading": "Appendix B. Details in Section 5.5", "text": ""}, {"heading": "B.1 CCCP", "text": "Using Proposition 6, we can decompose \u03ba(|x|) = \u03c2\u0302(x) + \u03c2\u0303(x) where \u03c2\u0302(x) = \u2212\u03c12x 2 is convex and \u03c2\u0303(x) = \u03ba(|x|) + \u03c12x 2 is concave. We can apply above decomposition on \u03ba into (43) and get a DC\ndecomposition as\nF\u0303 (X) = m\u2211 i=1 n\u2211 j=1 \u03c2\u0303 ( [Y \u2212X]ij ) + \u00b5 m\u22121\u2211 i=1 m\u2211 j=1 \u03c2\u0303 ( [DvX]ij ) + \u00b5 n\u2211 i=1 n\u22121\u2211 j=1 \u03c2\u0303 ( [XDh]ij ) ,\nF\u0302 (X) = m\u2211 i=1 n\u2211 j=1 \u03c2\u0302 ( [Y \u2212X]ij ) + \u00b5 m\u22121\u2211 i=1 m\u2211 j=1 \u03c2\u0302 ( [DvX]ij ) + \u00b5 n\u2211 i=1 n\u22121\u2211 j=1 \u03c2\u0302 ( [XDh]ij ) .\nThen, CCCP procedures at Section 2.1 can be applied."}, {"heading": "B.2 Smoothing", "text": "As LSP function is used as \u03ba, a smoothed version of it can be obtained as \u03ba\u0303\u03bb(x) = \u03b2 log (\n1 + h\u03bb(x)\u03b8 ) where h\u03bb(x) = { |x| if |x| \u2265 \u03bb x2\n2\u03bb + \u03bb 2 otherwise\n. Thus, (43) is smoothed as\nF\u0303\u03bb(X) = m\u2211 i=1 n\u2211 j=1 \u03ba\u0303\u03bb ( [Y \u2212X]ij ) + \u00b5 m\u22121\u2211 i=1 m\u2211 j=1 \u03ba\u0303\u03bb ( [DvX]ij ) + \u00b5 n\u2211 i=1 n\u22121\u2211 j=1 \u03ba\u0303\u03bb ( [XDh]ij ) .\nThen, gradient descent is used for optimization (Chen, 2012). Specifically, we need to minimize a sequence of subproblems {F\u0303\u03bb1(X), F\u0303\u03bb2(X), . . . } with \u03bbi = \u03bb0 \u00b7 \u03bdi, and using X from F\u0303\u03bbi\u22121(X) to warm start F\u0303\u03bbi(X). In the experiment, we set \u03bb0 = 0.1 and \u03bd = 0.95."}], "references": [{"title": "Scalable training of `1-regularized log-linear models", "author": ["G. Andrew", "J. Gao"], "venue": "In Proceedings of the 24th International Conference on Machine learning,", "citeRegEx": "Andrew and Gao.,? \\Q2007\\E", "shortCiteRegEx": "Andrew and Gao.", "year": 2007}, {"title": "The proximal average: Basic theory", "author": ["H. Bauschke", "R. Goebel", "Y. Lucet", "X. Wang"], "venue": "SIAM Journal on Optimization,", "citeRegEx": "Bauschke et al\\.,? \\Q2008\\E", "shortCiteRegEx": "Bauschke et al\\.", "year": 2008}, {"title": "Fast gradient-based algorithms for constrained total variation image denoising and deblurring problems", "author": ["A. Beck", "M. Teboulle"], "venue": "IEEE Transactions on Image Processing,", "citeRegEx": "Beck and Teboulle.,? \\Q2009\\E", "shortCiteRegEx": "Beck and Teboulle.", "year": 2009}, {"title": "A fast iterative shrinkage-thresholding algorithm for linear inverse problems", "author": ["A.M. Beck", "Teboulle"], "venue": "SIAM Journal on Imaging Sciences,", "citeRegEx": "Beck and Teboulle.,? \\Q2009\\E", "shortCiteRegEx": "Beck and Teboulle.", "year": 2009}, {"title": "Nonlinear Programming", "author": ["D.P. Bertsekas"], "venue": "Athena Scientific,", "citeRegEx": "Bertsekas.,? \\Q1999\\E", "shortCiteRegEx": "Bertsekas.", "year": 1999}, {"title": "Parallel and Distributed Computation", "author": ["D.P. Bertsekas", "J.N. Tsitsiklis"], "venue": "Numerical Methods. Prentice-Hall,", "citeRegEx": "Bertsekas and Tsitsiklis.,? \\Q1989\\E", "shortCiteRegEx": "Bertsekas and Tsitsiklis.", "year": 1989}, {"title": "An inertial forward-backward algorithm for the minimization of the sum of two nonconvex functions", "author": ["R.I. Bot", "E. Robert Csetnek", "S.C. L\u00e1szl\u00f3"], "venue": "EURO Journal on Computational Optimization,", "citeRegEx": "Bot et al\\.,? \\Q2016\\E", "shortCiteRegEx": "Bot et al\\.", "year": 2016}, {"title": "Online learning and stochastic approximations", "author": ["L. Bottou"], "venue": "On-line Learning in Neural Networks,", "citeRegEx": "Bottou.,? \\Q1998\\E", "shortCiteRegEx": "Bottou.", "year": 1998}, {"title": "Convex Optimization", "author": ["S. Boyd", "L. Vandenberghe"], "venue": null, "citeRegEx": "Boyd and Vandenberghe.,? \\Q2004\\E", "shortCiteRegEx": "Boyd and Vandenberghe.", "year": 2004}, {"title": "Distributed optimization and statistical learning via the alternating direction method of multipliers", "author": ["S. Boyd", "N. Parikh", "E. Chu", "B. Peleato", "J. Eckstein"], "venue": "Foundations and Trends in Machine Learning,", "citeRegEx": "Boyd et al\\.,? \\Q2011\\E", "shortCiteRegEx": "Boyd et al\\.", "year": 2011}, {"title": "A generalized conditional gradient method and its connection to an iterative shrinkage method", "author": ["K. Bredies", "D.A. Lorenz", "P. Maass"], "venue": "Computational Optimization and Applications,", "citeRegEx": "Bredies et al\\.,? \\Q2009\\E", "shortCiteRegEx": "Bredies et al\\.", "year": 2009}, {"title": "Exact matrix completion via convex optimization", "author": ["E.J. Cand\u00e8s", "B. Recht"], "venue": "Foundations of Computational Mathematics,", "citeRegEx": "Cand\u00e8s and Recht.,? \\Q2009\\E", "shortCiteRegEx": "Cand\u00e8s and Recht.", "year": 2009}, {"title": "Enhancing sparsity by reweighted `1 minimization", "author": ["E.J. Cand\u00e8s", "M.B. Wakin", "S. Boyd"], "venue": "Journal of Fourier Analysis and Applications,", "citeRegEx": "Cand\u00e8s et al\\.,? \\Q2008\\E", "shortCiteRegEx": "Cand\u00e8s et al\\.", "year": 2008}, {"title": "Robust principal component analysis", "author": ["E.J. Cand\u00e8s", "X. Li", "Yi Ma", "J. Wright"], "venue": "Journal of the ACM,", "citeRegEx": "Cand\u00e8s et al\\.,? \\Q2011\\E", "shortCiteRegEx": "Cand\u00e8s et al\\.", "year": 2011}, {"title": "Smoothing methods for nonsmooth, nonconvex minimization", "author": ["X. Chen"], "venue": "Mathematical Programming,", "citeRegEx": "Chen.,? \\Q2012\\E", "shortCiteRegEx": "Chen.", "year": 2012}, {"title": "Image denoising by sparse 3-D transformdomain collaborative filtering", "author": ["K. Dabov", "A. Foi", "V. Katkovnik", "K. Egiazarian"], "venue": "IEEE Transactions on Image Processing,", "citeRegEx": "Dabov et al\\.,? \\Q2007\\E", "shortCiteRegEx": "Dabov et al\\.", "year": 2007}, {"title": "Compressed sensing", "author": ["D.L. Donoho"], "venue": "IEEE Transactions on Information Theory,", "citeRegEx": "Donoho.,? \\Q2006\\E", "shortCiteRegEx": "Donoho.", "year": 2006}, {"title": "Applied Mathematics: Body and Soul: Volume 1: Derivatives and Geometry in IR3", "author": ["K. Eriksson", "F. Estep", "C. Johnson"], "venue": null, "citeRegEx": "Eriksson et al\\.,? \\Q2004\\E", "shortCiteRegEx": "Eriksson et al\\.", "year": 2004}, {"title": "Variable selection via nonconcave penalized likelihood and its oracle properties", "author": ["J. Fan", "R. Li"], "venue": "Journal of the American Statistical Association,", "citeRegEx": "Fan and Li.,? \\Q2001\\E", "shortCiteRegEx": "Fan and Li.", "year": 2001}, {"title": "An algorithm for quadratic programming", "author": ["M. Frank", "P. Wolfe"], "venue": "Naval Research Logistics,", "citeRegEx": "Frank and Wolfe.,? \\Q1956\\E", "shortCiteRegEx": "Frank and Wolfe.", "year": 1956}, {"title": "Nonlinear image recovery with half-quadratic regularization", "author": ["D. Geman", "C. Yang"], "venue": "IEEE Transactions on Image Processing,", "citeRegEx": "Geman and Yang.,? \\Q1995\\E", "shortCiteRegEx": "Geman and Yang.", "year": 1995}, {"title": "Accelerated gradient methods for nonconvex nonlinear and stochastic programming", "author": ["S. Ghadimi", "G. Lan"], "venue": "Mathematical Programming,", "citeRegEx": "Ghadimi and Lan.,? \\Q2016\\E", "shortCiteRegEx": "Ghadimi and Lan.", "year": 2016}, {"title": "Sur l\u2019approximation, par \u00e9l\u00e9ments finis d\u2019ordre un, et la r\u00e9solution, par p\u00e9nalisation-dualit\u00e9 d\u2019une classe de probl\u00e8mes de dirichlet non lin\u00e9aires. Revue fran\u00e7aise d\u2019automatique, informatique, recherche op\u00e9rationnelle", "author": ["R. Glowinski", "A. Marroco"], "venue": "Analyse nume\u0301rique,", "citeRegEx": "Glowinski and Marroco.,? \\Q1975\\E", "shortCiteRegEx": "Glowinski and Marroco.", "year": 1975}, {"title": "Matrix Computations", "author": ["G.H. Golub", "C.F. Van Loan"], "venue": null, "citeRegEx": "Golub and Loan.,? \\Q2012\\E", "shortCiteRegEx": "Golub and Loan.", "year": 2012}, {"title": "HONOR: Hybrid Optimization for NOn-convex Regularized problems", "author": ["P. Gong", "J. Ye"], "venue": "In Advances in Neural Information Processing Systems,", "citeRegEx": "Gong and Ye.,? \\Q2015\\E", "shortCiteRegEx": "Gong and Ye.", "year": 2015}, {"title": "A modified orthant-wise limited memory quasi-Newton method with convergence analysis", "author": ["P. Gong", "J. Ye"], "venue": "In Proceedings of the 32nd International Conference on Machine Learning,", "citeRegEx": "Gong and Ye.,? \\Q2015\\E", "shortCiteRegEx": "Gong and Ye.", "year": 2015}, {"title": "A general iterative shrinkage and thresholding algorithm for non-convex regularized optimization problems", "author": ["P. Gong", "C. Zhang", "Z. Lu", "J. Huang", "J. Ye"], "venue": "In Proceedings of the 30th International Conference on Machine Learning,", "citeRegEx": "Gong et al\\.,? \\Q2013\\E", "shortCiteRegEx": "Gong et al\\.", "year": 2013}, {"title": "Towards faster rates and oracle property for low-rank matrix estimation", "author": ["H. Gui", "J. Han", "Q. Gu"], "venue": "In Proceedings of the 33nd International Conference on Machine Learning,", "citeRegEx": "Gui et al\\.,? \\Q2016\\E", "shortCiteRegEx": "Gui et al\\.", "year": 2016}, {"title": "On the o(1/n) convergence rate of the douglas-rachford alternating direction method", "author": ["B. He", "X. Yuan"], "venue": "SIAM Journal on Numerical Analysis,", "citeRegEx": "He and Yuan.,? \\Q2012\\E", "shortCiteRegEx": "He and Yuan.", "year": 2012}, {"title": "Generalized differentiability, duality and optimization for problems dealing with differences of convex functions", "author": ["J.B. Hiriart-Urruty"], "venue": "Convexity and Duality in Optimization,", "citeRegEx": "Hiriart.Urruty.,? \\Q1985\\E", "shortCiteRegEx": "Hiriart.Urruty.", "year": 1985}, {"title": "Convergence analysis of alternating direction method of multipliers for a family of nonconvex problems", "author": ["M. Hong", "Z.-Q. Luo", "M. Razaviyayn"], "venue": "SIAM Journal on Optimization,", "citeRegEx": "Hong et al\\.,? \\Q2016\\E", "shortCiteRegEx": "Hong et al\\.", "year": 2016}, {"title": "Nuclear norm minimization via active subspace selection", "author": ["C.-J. Hsieh", "P. Olsen"], "venue": "In Proceedings of the 31st International Conference on Machine Learning,", "citeRegEx": "Hsieh and Olsen.,? \\Q2014\\E", "shortCiteRegEx": "Hsieh and Olsen.", "year": 2014}, {"title": "Group lasso with overlap and graph lasso", "author": ["L. Jacob", "G. Obozinski", "J.-P. Vert"], "venue": "In Proceedings of the 26th International Conference on Machine Learning,", "citeRegEx": "Jacob et al\\.,? \\Q2009\\E", "shortCiteRegEx": "Jacob et al\\.", "year": 2009}, {"title": "Revisiting Frank-Wolfe: Projection-free sparse convex optimization", "author": ["M. Jaggi"], "venue": "In Proceedings of the 30th International Conference on Machine Learning,", "citeRegEx": "Jaggi.,? \\Q2013\\E", "shortCiteRegEx": "Jaggi.", "year": 2013}, {"title": "Proximal methods for hierarchical sparse coding", "author": ["R. Jenatton", "J. Mairal", "G. Obozinski", "F. Bach"], "venue": "Journal of Machine Learning Research,", "citeRegEx": "Jenatton et al\\.,? \\Q2011\\E", "shortCiteRegEx": "Jenatton et al\\.", "year": 2011}, {"title": "Accelerating stochastic gradient descent using predictive variance reduction", "author": ["R. Johnson", "T. Zhang"], "venue": "In Advances in Neural Information Processing Systems,", "citeRegEx": "Johnson and Zhang.,? \\Q2013\\E", "shortCiteRegEx": "Johnson and Zhang.", "year": 2013}, {"title": "A hybrid algorithm for convex semidefinite optimization", "author": ["S. Laue"], "venue": "In Proceedings of the 29th International Conference on Machine Learning,", "citeRegEx": "Laue.,? \\Q2012\\E", "shortCiteRegEx": "Laue.", "year": 2012}, {"title": "Nonsmooth analysis of singular values", "author": ["A.S. Lewis", "H.S. Sendov"], "venue": "Part ii: Applications. SetValued Analysis,", "citeRegEx": "Lewis and Sendov.,? \\Q2005\\E", "shortCiteRegEx": "Lewis and Sendov.", "year": 2005}, {"title": "Global convergence of splitting methods for nonconvex composite optimization", "author": ["G. Li", "T.K. Pong"], "venue": "SIAM Journal on Optimization,", "citeRegEx": "Li and Pong.,? \\Q2015\\E", "shortCiteRegEx": "Li and Pong.", "year": 2015}, {"title": "Accelerated proximal gradient methods for nonconvex programming", "author": ["H. Li", "Z. Lin"], "venue": "In Advances in Neural Information Processing Systems,", "citeRegEx": "Li and Lin.,? \\Q2015\\E", "shortCiteRegEx": "Li and Lin.", "year": 2015}, {"title": "Moreau-Yosida regularization for grouped tree structure learning", "author": ["J. Liu", "J. Ye"], "venue": "In Advances in Neural Information Processing Systems,", "citeRegEx": "Liu and Ye.,? \\Q2010\\E", "shortCiteRegEx": "Liu and Ye.", "year": 2010}, {"title": "Tensor completion for estimating missing values in visual data", "author": ["J. Liu", "P. Musialski", "P. Wonka", "J. Ye"], "venue": "IEEE Transactions on Pattern Analysis and Machine Intelligence,", "citeRegEx": "Liu et al\\.,? \\Q2013\\E", "shortCiteRegEx": "Liu et al\\.", "year": 2013}, {"title": "Online robust dictionary learning", "author": ["C. Lu", "J. Shi", "J. Jia"], "venue": "In IEEE Conference on Computer Vision and Pattern Recognition,", "citeRegEx": "Lu et al\\.,? \\Q2013\\E", "shortCiteRegEx": "Lu et al\\.", "year": 2013}, {"title": "Generalized nonconvex nonsmooth low-rank minimization", "author": ["C. Lu", "J. Tang", "S. Yan", "Z. Lin"], "venue": "In Proceedings of the International Conference on Computer Vision and Pattern Recognition,", "citeRegEx": "Lu et al\\.,? \\Q2014\\E", "shortCiteRegEx": "Lu et al\\.", "year": 2014}, {"title": "Generalized singular value thresholding", "author": ["C. Lu", "C. Zhu", "C. Xu", "S. Yan", "Z. Lin"], "venue": "In Proceedings of the 29th AAAI Conference on Artificial Intelligence,", "citeRegEx": "Lu et al\\.,? \\Q2015\\E", "shortCiteRegEx": "Lu et al\\.", "year": 2015}, {"title": "Sequential convex programming methods for a class of structured nonlinear programming", "author": ["Z. Lu"], "venue": "Preprint arXiv:1210.3039,", "citeRegEx": "Lu.,? \\Q2012\\E", "shortCiteRegEx": "Lu.", "year": 2012}, {"title": "Online dictionary learning for sparse coding", "author": ["J. Mairal", "F. Bach", "J. Ponce", "G. Sapiro"], "venue": "In Proceedings of the 26th International Conference on Machine Learning,", "citeRegEx": "Mairal et al\\.,? \\Q2009\\E", "shortCiteRegEx": "Mairal et al\\.", "year": 2009}, {"title": "Spectral regularization algorithms for learning large incomplete matrices", "author": ["R. Mazumder", "T. Hastie", "R. Tibshirani"], "venue": "Journal of Machine Learning Research,", "citeRegEx": "Mazumder et al\\.,? \\Q2010\\E", "shortCiteRegEx": "Mazumder et al\\.", "year": 2010}, {"title": "Low-rank optimization with trace norm penalty", "author": ["B. Mishra", "G. Meyer", "F. Bach", "R. Sepulchre"], "venue": "SIAM Journal on Optimization,", "citeRegEx": "Mishra et al\\.,? \\Q2013\\E", "shortCiteRegEx": "Mishra et al\\.", "year": 2013}, {"title": "Gradient methods for minimizing composite functions", "author": ["Y. Nesterov"], "venue": "Mathematical Programming,", "citeRegEx": "Nesterov.,? \\Q2013\\E", "shortCiteRegEx": "Nesterov.", "year": 2013}, {"title": "Scaled gradients on Grassmann manifolds for matrix completion", "author": ["T. Ngo", "Y. Saad"], "venue": "In Advances in Neural Information Processing Systems,", "citeRegEx": "Ngo and Saad.,? \\Q2012\\E", "shortCiteRegEx": "Ngo and Saad.", "year": 2012}, {"title": "A variational approach to remove outliers and impulse noise", "author": ["M. Nikolova"], "venue": "Journal of Mathematical Imaging and Vision,", "citeRegEx": "Nikolova.,? \\Q2004\\E", "shortCiteRegEx": "Nikolova.", "year": 2004}, {"title": "iPiano: Inertial proximal algorithm for nonconvex optimization", "author": ["P. Ochs", "Y. Chen", "T. Brox", "T. Pock"], "venue": "SIAM Journal on Imaging Sciences,", "citeRegEx": "Ochs et al\\.,? \\Q2014\\E", "shortCiteRegEx": "Ochs et al\\.", "year": 2014}, {"title": "Stochastic variance reduction for nonconvex optimization", "author": ["S.J. Reddi", "A. Hefny", "S. Sra", "B. P\u00f3czos", "A.J. Smola"], "venue": "In Proceedings of the 33nd International Conference on Machine Learning,", "citeRegEx": "Reddi et al\\.,? \\Q2016\\E", "shortCiteRegEx": "Reddi et al\\.", "year": 2016}, {"title": "Fast stochastic methods for nonsmooth nonconvex optimization", "author": ["S.J. Reddi", "S. Sra", "B. Poczos", "A. Smola"], "venue": "In Advances in Neural Information Processing Systems,", "citeRegEx": "Reddi et al\\.,? \\Q2016\\E", "shortCiteRegEx": "Reddi et al\\.", "year": 2016}, {"title": "Convergence rates of inexact proximal-gradient methods for convex optimization", "author": ["M. Schmidt", "N.L. Roux", "F. Bach"], "venue": "In Advances in Neural Information Processing Systems,", "citeRegEx": "Schmidt et al\\.,? \\Q2011\\E", "shortCiteRegEx": "Schmidt et al\\.", "year": 2011}, {"title": "Scalable nonconvex inexact proximal splitting", "author": ["S. Sra"], "venue": "In Advances in Neural Information Processing Systems,", "citeRegEx": "Sra.,? \\Q2012\\E", "shortCiteRegEx": "Sra.", "year": 2012}, {"title": "Maximum-margin matrix factorization", "author": ["N. Srebro", "J. Rennie", "T.S. Jaakkola"], "venue": "In Advances in Neural Information Processing Systems,", "citeRegEx": "Srebro et al\\.,? \\Q2004\\E", "shortCiteRegEx": "Srebro et al\\.", "year": 2004}, {"title": "Robust principal component analysis via capped norms", "author": ["Q. Sun", "S. Xiang", "J. Ye"], "venue": "In Proceedings of the 19th International Conference on Knowledge Discovery and Data Mining,", "citeRegEx": "Sun et al\\.,? \\Q2013\\E", "shortCiteRegEx": "Sun et al\\.", "year": 2013}, {"title": "Regression shrinkage and selection via the lasso", "author": ["R. Tibshirani"], "venue": "Journal of the Royal Statistical Society. Series B,", "citeRegEx": "Tibshirani.,? \\Q1996\\E", "shortCiteRegEx": "Tibshirani.", "year": 1996}, {"title": "Sparsity and smoothness via the fused lasso", "author": ["R. Tibshirani", "M. Saunders", "S. Rosset", "J. Zhu", "K. Knight"], "venue": "Journal of the Royal Statistical Society: Series B,", "citeRegEx": "Tibshirani et al\\.,? \\Q2005\\E", "shortCiteRegEx": "Tibshirani et al\\.", "year": 2005}, {"title": "Highly undersampled magnetic resonance image reconstruction via homotopic-minimization", "author": ["J. Trzasko", "A. Manduca"], "venue": "IEEE Transactions on Medical Imaging,", "citeRegEx": "Trzasko and Manduca.,? \\Q2009\\E", "shortCiteRegEx": "Trzasko and Manduca.", "year": 2009}, {"title": "Characterization of the subdifferential of some matrix norms", "author": ["G.A. Watson"], "venue": "Linear Algebra and its Applications,", "citeRegEx": "Watson.,? \\Q1992\\E", "shortCiteRegEx": "Watson.", "year": 1992}, {"title": "Solving a low-rank factorization model for matrix completion by a nonlinear successive over-relaxation algorithm", "author": ["Z. Wen", "W. Yin", "Y. Zhang"], "venue": "Mathematical Programming Computation,", "citeRegEx": "Wen et al\\.,? \\Q2012\\E", "shortCiteRegEx": "Wen et al\\.", "year": 2012}, {"title": "A proximal stochastic gradient method with progressive variance reduction", "author": ["L. Xiao", "T. Zhang"], "venue": "SIAM Journal on Optimization,", "citeRegEx": "Xiao and Zhang.,? \\Q2014\\E", "shortCiteRegEx": "Xiao and Zhang.", "year": 2014}, {"title": "Restoration of images corrupted by impulse noise and mixed gaussian impulse noise using blind inpainting", "author": ["M. Yan"], "venue": "SIAM Journal on Imaging Sciences,", "citeRegEx": "Yan.,? \\Q2013\\E", "shortCiteRegEx": "Yan.", "year": 2013}, {"title": "Robust sparse coding for face recognition", "author": ["M. Yang", "L. Zhang", "J. Yang", "D. Zhang"], "venue": "In IEEE Conference on Computer Vision and Pattern Recognition,", "citeRegEx": "Yang et al\\.,? \\Q2011\\E", "shortCiteRegEx": "Yang et al\\.", "year": 2011}, {"title": "Efficient learning with a family of nonconvex regularizers by redistributing nonconvexity", "author": ["Q Yao", "J.T. Kwok"], "venue": "In Proceedings of the 33rd International Conference on Machine Learning,", "citeRegEx": "Yao and Kwok.,? \\Q2016\\E", "shortCiteRegEx": "Yao and Kwok.", "year": 2016}, {"title": "Fast low-rank matrix learning with nonconvex regularization", "author": ["Q. Yao", "J.T. Kwok", "W. Zhong"], "venue": "In Proceedings of IEEE International Conference on Data Mining,", "citeRegEx": "Yao et al\\.,? \\Q2015\\E", "shortCiteRegEx": "Yao et al\\.", "year": 2015}, {"title": "Efficient methods for overlapping group lasso", "author": ["L. Yuan", "J. Liu", "J. Ye"], "venue": "In Advances in Neural Information Processing Systems,", "citeRegEx": "Yuan et al\\.,? \\Q2011\\E", "shortCiteRegEx": "Yuan et al\\.", "year": 2011}, {"title": "The concave-convex procedure (CCCP)", "author": ["A.L. Yuille", "A. Rangarajan"], "venue": "In Advances in Neural Information Processing Systems,", "citeRegEx": "Yuille and Rangarajan.,? \\Q2002\\E", "shortCiteRegEx": "Yuille and Rangarajan.", "year": 2002}, {"title": "Nearly unbiased variable selection under minimax concave penalty", "author": ["C.H. Zhang"], "venue": "Annals of Statistics,", "citeRegEx": "Zhang.,? \\Q2010\\E", "shortCiteRegEx": "Zhang.", "year": 2010}, {"title": "Analysis of multi-stage convex relaxation for sparse regularization", "author": ["T. Zhang"], "venue": "Journal of Machine Learning Research,", "citeRegEx": "Zhang.,? \\Q2010\\E", "shortCiteRegEx": "Zhang.", "year": 2010}, {"title": "Accelerated training for matrix-norm regularization: A boosting approach", "author": ["X. Zhang", "D. Schuurmans", "Y.-L. Yu"], "venue": "In Advances in Neural Information Processing Systems,", "citeRegEx": "Zhang et al\\.,? \\Q2012\\E", "shortCiteRegEx": "Zhang et al\\.", "year": 2012}, {"title": "Background subtraction via robust dictionary learning", "author": ["C. Zhao", "X. Wang", "W.-K. Cham"], "venue": "EURASIP Journal on Image and Video Processing,", "citeRegEx": "Zhao et al\\.,? \\Q2011\\E", "shortCiteRegEx": "Zhao et al\\.", "year": 2011}, {"title": "Gradient descent with proximal average for nonconvex and composite regularization", "author": ["W. Zhong", "J.T. Kwok"], "venue": "In Proceedings of the 28th AAAI Conference on Artificial Intelligence,", "citeRegEx": "Zhong and Kwok.,? \\Q2014\\E", "shortCiteRegEx": "Zhong and Kwok.", "year": 2014}, {"title": "Variance reduction for faster non-convex optimization", "author": ["Z.A. Zhu", "E. Hazan"], "venue": "In Proceedings of the 33nd International Conference on Machine Learning,", "citeRegEx": "Zhu and Hazan.,? \\Q2016\\E", "shortCiteRegEx": "Zhu and Hazan.", "year": 2016}], "referenceMentions": [{"referenceID": 2, "context": "Popular examples include the sparsity-inducing regularizers, which have been commonly used in image processing (Beck and Teboulle, 2009; Mairal et al., 2009; Jenatton et al., 2011) and highdimensional feature selection (Tibshirani et al.", "startOffset": 111, "endOffset": 180}, {"referenceID": 46, "context": "Popular examples include the sparsity-inducing regularizers, which have been commonly used in image processing (Beck and Teboulle, 2009; Mairal et al., 2009; Jenatton et al., 2011) and highdimensional feature selection (Tibshirani et al.", "startOffset": 111, "endOffset": 180}, {"referenceID": 34, "context": "Popular examples include the sparsity-inducing regularizers, which have been commonly used in image processing (Beck and Teboulle, 2009; Mairal et al., 2009; Jenatton et al., 2011) and highdimensional feature selection (Tibshirani et al.", "startOffset": 111, "endOffset": 180}, {"referenceID": 60, "context": ", 2011) and highdimensional feature selection (Tibshirani et al., 2005; Jacob et al., 2009; Liu and Ye, 2010); and the low-rank regularizer in matrix and tensor learning, with good empirical performance on tasks such as recommender systems (Cand\u00e8s and Recht, 2009; Mazumder et al.", "startOffset": 46, "endOffset": 109}, {"referenceID": 32, "context": ", 2011) and highdimensional feature selection (Tibshirani et al., 2005; Jacob et al., 2009; Liu and Ye, 2010); and the low-rank regularizer in matrix and tensor learning, with good empirical performance on tasks such as recommender systems (Cand\u00e8s and Recht, 2009; Mazumder et al.", "startOffset": 46, "endOffset": 109}, {"referenceID": 40, "context": ", 2011) and highdimensional feature selection (Tibshirani et al., 2005; Jacob et al., 2009; Liu and Ye, 2010); and the low-rank regularizer in matrix and tensor learning, with good empirical performance on tasks such as recommender systems (Cand\u00e8s and Recht, 2009; Mazumder et al.", "startOffset": 46, "endOffset": 109}, {"referenceID": 11, "context": ", 2009; Liu and Ye, 2010); and the low-rank regularizer in matrix and tensor learning, with good empirical performance on tasks such as recommender systems (Cand\u00e8s and Recht, 2009; Mazumder et al., 2010) and visual data analysis (Liu et al.", "startOffset": 156, "endOffset": 203}, {"referenceID": 47, "context": ", 2009; Liu and Ye, 2010); and the low-rank regularizer in matrix and tensor learning, with good empirical performance on tasks such as recommender systems (Cand\u00e8s and Recht, 2009; Mazumder et al., 2010) and visual data analysis (Liu et al.", "startOffset": 156, "endOffset": 203}, {"referenceID": 41, "context": ", 2010) and visual data analysis (Liu et al., 2013; Lu et al., 2014).", "startOffset": 33, "endOffset": 68}, {"referenceID": 43, "context": ", 2010) and visual data analysis (Liu et al., 2013; Lu et al., 2014).", "startOffset": 33, "endOffset": 68}, {"referenceID": 16, "context": "Well-known examples include the `1-regularizer for sparse coding (Donoho, 2006), and the nuclear norm regularizer in low-rank matrix learning", "startOffset": 65, "endOffset": 79}, {"referenceID": 20, "context": "\u03ba(\u03b1) \u03ba\u2032(\u03b1) \u03ba0 \u03c1 GP (Geman and Yang, 1995) \u03b2\u03b1 \u03b8+\u03b1 \u03b2\u03b8 (\u03b8+\u03b1)2 \u03b2 \u03b8 2\u03b2 \u03b82 LSP (Cand\u00e8s et al.", "startOffset": 19, "endOffset": 41}, {"referenceID": 12, "context": "\u03ba(\u03b1) \u03ba\u2032(\u03b1) \u03ba0 \u03c1 GP (Geman and Yang, 1995) \u03b2\u03b1 \u03b8+\u03b1 \u03b2\u03b8 (\u03b8+\u03b1)2 \u03b2 \u03b8 2\u03b2 \u03b82 LSP (Cand\u00e8s et al., 2008) \u03b2 log(1 + \u03b1\u03b8 ) \u03b2 \u03b8+\u03b1 \u03b2 \u03b8 \u03b2 \u03b82", "startOffset": 73, "endOffset": 94}, {"referenceID": 61, "context": "MCP (Zhang, 2010a) { \u03b2\u03b1\u2212 \u03b12 2\u03b8 \u03b1 \u2264 \u03b2\u03b8 1 2\u03b8\u03b2 2 \u03b1 > \u03b2\u03b8 { \u03b2 \u2212 \u03b1\u03b8 \u03b1 \u2264 \u03b2\u03b8 0 \u03b1 > \u03b2\u03b8 \u03b2 1\u03b8 Laplace (Trzasko and Manduca, 2009) \u03b2(1\u2212 exp(\u2212\u03b1\u03b8 )) \u03b2 \u03b8 exp ( \u2212\u03b1\u03b8 ) \u03b2 \u03b8 \u03b2 \u03b82", "startOffset": 91, "endOffset": 118}, {"referenceID": 18, "context": "SCAD (Fan and Li, 2001) \uf8f4\uf8f2\uf8f4\uf8f3 \u03b2\u03b1 \u03b1 \u2264 \u03b2 \u2212\u03b12+2\u03b8\u03b2\u03b1\u2212\u03b22 2(\u03b8\u22121) \u03b2 < \u03b1 \u2264 \u03b8\u03b2 \u03b22(1+\u03b8) 2 \u03b1 > \u03b8\u03b2 \uf8f4\uf8f2\uf8f4\uf8f3 \u03b2 \u03b1 \u2264 \u03b2 \u2212\u03b1+\u03b8\u03b2 \u03b8\u22121 \u03b2 < \u03b1 \u2264 \u03b8\u03b2 0 \u03b1 > \u03b8\u03b2 \u03b2 1 \u03b8\u22121", "startOffset": 5, "endOffset": 23}, {"referenceID": 11, "context": "(Cand\u00e8s and Recht, 2009).", "startOffset": 0, "endOffset": 24}, {"referenceID": 33, "context": "Popular optimization algorithms in machine learning include the proximal algorithm (Parikh and Boyd, 2013), Frank-Wolfe (FW) algorithm (Jaggi, 2013), the alternating direction method of multipliers (ADMM) (Boyd et al.", "startOffset": 135, "endOffset": 148}, {"referenceID": 9, "context": "Popular optimization algorithms in machine learning include the proximal algorithm (Parikh and Boyd, 2013), Frank-Wolfe (FW) algorithm (Jaggi, 2013), the alternating direction method of multipliers (ADMM) (Boyd et al., 2011), stochastic gradient descent and its variants (Bottou, 1998; Xiao and Zhang, 2014).", "startOffset": 205, "endOffset": 224}, {"referenceID": 7, "context": ", 2011), stochastic gradient descent and its variants (Bottou, 1998; Xiao and Zhang, 2014).", "startOffset": 54, "endOffset": 90}, {"referenceID": 64, "context": ", 2011), stochastic gradient descent and its variants (Bottou, 1998; Xiao and Zhang, 2014).", "startOffset": 54, "endOffset": 90}, {"referenceID": 47, "context": "In lowrank matrix learning, the estimated rank obtained with the nuclear norm regularizer is often much higher (Mazumder et al., 2010).", "startOffset": 111, "endOffset": 134}, {"referenceID": 20, "context": "To alleviate this problem, a number of nonconvex regularizers have been recently proposed (Geman and Yang, 1995; Fan and Li, 2001; Cand\u00e8s et al., 2008; Zhang, 2010a; Trzasko and Manduca, 2009).", "startOffset": 90, "endOffset": 192}, {"referenceID": 18, "context": "To alleviate this problem, a number of nonconvex regularizers have been recently proposed (Geman and Yang, 1995; Fan and Li, 2001; Cand\u00e8s et al., 2008; Zhang, 2010a; Trzasko and Manduca, 2009).", "startOffset": 90, "endOffset": 192}, {"referenceID": 12, "context": "To alleviate this problem, a number of nonconvex regularizers have been recently proposed (Geman and Yang, 1995; Fan and Li, 2001; Cand\u00e8s et al., 2008; Zhang, 2010a; Trzasko and Manduca, 2009).", "startOffset": 90, "endOffset": 192}, {"referenceID": 61, "context": "To alleviate this problem, a number of nonconvex regularizers have been recently proposed (Geman and Yang, 1995; Fan and Li, 2001; Cand\u00e8s et al., 2008; Zhang, 2010a; Trzasko and Manduca, 2009).", "startOffset": 90, "endOffset": 192}, {"referenceID": 70, "context": "One can use general-purpose nonconvex optimization solvers such as the concave-convex procedure (Yuille and Rangarajan, 2002).", "startOffset": 96, "endOffset": 125}, {"referenceID": 26, "context": "However, the subproblem in each iteration can be as expensive as the original problem, and the concave-convex procedure is thus often slow in practice (Gong et al., 2013; Zhong and Kwok, 2014).", "startOffset": 151, "endOffset": 192}, {"referenceID": 75, "context": "However, the subproblem in each iteration can be as expensive as the original problem, and the concave-convex procedure is thus often slow in practice (Gong et al., 2013; Zhong and Kwok, 2014).", "startOffset": 151, "endOffset": 192}, {"referenceID": 56, "context": "Examples include the NIPS (Sra, 2012), IPiano (Ochs et al.", "startOffset": 26, "endOffset": 37}, {"referenceID": 52, "context": "Examples include the NIPS (Sra, 2012), IPiano (Ochs et al., 2014), UAG (Ghadimi and Lan, 2016), GIST (Gong et al.", "startOffset": 46, "endOffset": 65}, {"referenceID": 21, "context": ", 2014), UAG (Ghadimi and Lan, 2016), GIST (Gong et al.", "startOffset": 13, "endOffset": 36}, {"referenceID": 26, "context": ", 2014), UAG (Ghadimi and Lan, 2016), GIST (Gong et al., 2013), IFB (Bot et al.", "startOffset": 43, "endOffset": 62}, {"referenceID": 6, "context": ", 2013), IFB (Bot et al., 2016), and nmAPG (Li and Lin, 2015).", "startOffset": 13, "endOffset": 31}, {"referenceID": 39, "context": ", 2016), and nmAPG (Li and Lin, 2015).", "startOffset": 19, "endOffset": 37}, {"referenceID": 75, "context": "When the regularizer is complicated, such as the nonconvex versions of the fused lasso and overlapping group lasso regularizers (Zhong and Kwok, 2014),", "startOffset": 128, "endOffset": 150}, {"referenceID": 75, "context": "Another approach is by using the proximal average (Zhong and Kwok, 2014), which computes and averages the proximal step of each underlying regularizer.", "startOffset": 50, "endOffset": 72}, {"referenceID": 39, "context": "However, because the proximal step is only approximate, convergence is usually slower than typical applications of the proximal algorithm (Li and Lin, 2015).", "startOffset": 138, "endOffset": 156}, {"referenceID": 30, "context": "For the global consensus problem, standard ADMM converges only when g is convex (Hong et al., 2016).", "startOffset": 80, "endOffset": 99}, {"referenceID": 38, "context": "When g is nonconvex, convergence of ADMM is only established for problems of the form minx,y f(x) + g(y) : y = Ax, where matrix A has full row rank (Li and Pong, 2015).", "startOffset": 148, "endOffset": 167}, {"referenceID": 35, "context": "More recently, the stochastic variance reduced gradient (SVRG) algorithm (Johnson and Zhang, 2013), which is a variant of the popular stochastic gradient descent with reduced variance in the gradient estimates, has also been extended for problems with nonconvex f .", "startOffset": 73, "endOffset": 98}, {"referenceID": 76, "context": "However, the regularizer g is still required to be convex (Reddi et al., 2016a; Zhu and Hazan, 2016).", "startOffset": 58, "endOffset": 100}, {"referenceID": 65, "context": "For example, the absolute loss is more robust to outliers than the square loss, and has been popularly used in applications such as image denoising (Yan, 2013), robust dictionary learning (Zhao et al.", "startOffset": 148, "endOffset": 159}, {"referenceID": 74, "context": "For example, the absolute loss is more robust to outliers than the square loss, and has been popularly used in applications such as image denoising (Yan, 2013), robust dictionary learning (Zhao et al., 2011) and robust PCA (Cand\u00e8s et al.", "startOffset": 188, "endOffset": 207}, {"referenceID": 13, "context": ", 2011) and robust PCA (Cand\u00e8s et al., 2011).", "startOffset": 23, "endOffset": 44}, {"referenceID": 28, "context": "When both f and g are convex, ADMM is often the main optimization tool for problem (1) (He and Yuan, 2012).", "startOffset": 87, "endOffset": 106}, {"referenceID": 65, "context": "Besides a nonconvex g, we may also want to use a nonconvex loss f , such as `0-norm (Yan, 2013) and capped-`1 norm (Sun et al.", "startOffset": 84, "endOffset": 95}, {"referenceID": 58, "context": "Besides a nonconvex g, we may also want to use a nonconvex loss f , such as `0-norm (Yan, 2013) and capped-`1 norm (Sun et al., 2013), as they are more robust to outliers and can obtain better performance.", "startOffset": 115, "endOffset": 133}, {"referenceID": 70, "context": "As a last resort, one can use more general nonconvex optimization approaches such as convex concave programming (CCCP) (Yuille and Rangarajan, 2002).", "startOffset": 119, "endOffset": 148}, {"referenceID": 67, "context": "Note that this paper extends a shorter version published in the proceedings of the International Conference of Machine Learning (Yao and Kwok, 2016).", "startOffset": 128, "endOffset": 148}, {"referenceID": 70, "context": "1 Convex-Concave Procedure (CCCP) The convex-concave procedure (CCCP) (Yuille and Rangarajan, 2002; Lu, 2012) is a popular and general solver for (1).", "startOffset": 70, "endOffset": 109}, {"referenceID": 45, "context": "1 Convex-Concave Procedure (CCCP) The convex-concave procedure (CCCP) (Yuille and Rangarajan, 2002; Lu, 2012) is a popular and general solver for (1).", "startOffset": 70, "endOffset": 109}, {"referenceID": 29, "context": "It assumes thatF can be decomposed as a difference of convex (DC) functions (Hiriart-Urruty, 1985), i.", "startOffset": 76, "endOffset": 98}, {"referenceID": 45, "context": "Sequential convex programming (SCP) (Lu, 2012) improves its efficiency when F is in form of (1).", "startOffset": 36, "endOffset": 46}, {"referenceID": 26, "context": "However, its convergence is still slow in general (Gong et al., 2013; Zhong and Kwok, 2014; Li and Lin, 2015).", "startOffset": 50, "endOffset": 109}, {"referenceID": 75, "context": "However, its convergence is still slow in general (Gong et al., 2013; Zhong and Kwok, 2014; Li and Lin, 2015).", "startOffset": 50, "endOffset": 109}, {"referenceID": 39, "context": "However, its convergence is still slow in general (Gong et al., 2013; Zhong and Kwok, 2014; Li and Lin, 2015).", "startOffset": 50, "endOffset": 109}, {"referenceID": 49, "context": "This can be further accelerated to O(1/T 2) by modifying the generation of {xt} as (Beck, 2009; Nesterov, 2013): yt = xt + \u03b1t\u22121 \u2212 1 \u03b1t (xt \u2212 xt\u22121), xt+1 = prox 1 L g ( yt \u2212 1 L \u2207f(yt) ) ,", "startOffset": 83, "endOffset": 111}, {"referenceID": 56, "context": "In particular, NIPS (Sra, 2012), IPiano (Ochs et al.", "startOffset": 20, "endOffset": 31}, {"referenceID": 52, "context": "In particular, NIPS (Sra, 2012), IPiano (Ochs et al., 2014) and UAG (Ghadimi and Lan, 2016) allow f to be nonconvex, while g is still required to be convex.", "startOffset": 40, "endOffset": 59}, {"referenceID": 21, "context": ", 2014) and UAG (Ghadimi and Lan, 2016) allow f to be nonconvex, while g is still required to be convex.", "startOffset": 16, "endOffset": 39}, {"referenceID": 26, "context": "GIST (Gong et al., 2013), IFB (Bot et al.", "startOffset": 5, "endOffset": 24}, {"referenceID": 6, "context": ", 2013), IFB (Bot et al., 2016) and nmAPG (Li and Lin, 2015) further remove this restriction and allow g to be nonconvex.", "startOffset": 13, "endOffset": 31}, {"referenceID": 39, "context": ", 2016) and nmAPG (Li and Lin, 2015) further remove this restriction and allow g to be nonconvex.", "startOffset": 18, "endOffset": 36}, {"referenceID": 59, "context": "This is true for many convex regularizers such as the lasso regularier (Tibshirani, 1996), tree-structured lasso regularizer (Liu and Ye, 2010; Jenatton et al.", "startOffset": 71, "endOffset": 89}, {"referenceID": 40, "context": "This is true for many convex regularizers such as the lasso regularier (Tibshirani, 1996), tree-structured lasso regularizer (Liu and Ye, 2010; Jenatton et al., 2011) and sparse group lasso regularizer (Jacob et al.", "startOffset": 125, "endOffset": 166}, {"referenceID": 34, "context": "This is true for many convex regularizers such as the lasso regularier (Tibshirani, 1996), tree-structured lasso regularizer (Liu and Ye, 2010; Jenatton et al., 2011) and sparse group lasso regularizer (Jacob et al.", "startOffset": 125, "endOffset": 166}, {"referenceID": 32, "context": ", 2011) and sparse group lasso regularizer (Jacob et al., 2009).", "startOffset": 43, "endOffset": 63}, {"referenceID": 26, "context": ", nonconvex lasso regularizer (Gong et al., 2013), and usually do not exist for more general cases, e.", "startOffset": 30, "endOffset": 49}, {"referenceID": 75, "context": ", nonconvex tree-structured lasso regularizer (Zhong and Kwok, 2014).", "startOffset": 46, "endOffset": 68}, {"referenceID": 1, "context": "On the other hand, Zhong and Kwok (2014) used proximal average (Bauschke et al., 2008) to handle complicate g which is in the form g(x) = \u2211K i=1 \u03bcigi(x), where each gi has a simple proximal step.", "startOffset": 63, "endOffset": 86}, {"referenceID": 5, "context": ", 2013), IFB (Bot et al., 2016) and nmAPG (Li and Lin, 2015) further remove this restriction and allow g to be nonconvex. It is desirable that the proximal step has a closed-form solution. This is true for many convex regularizers such as the lasso regularier (Tibshirani, 1996), tree-structured lasso regularizer (Liu and Ye, 2010; Jenatton et al., 2011) and sparse group lasso regularizer (Jacob et al., 2009). However, when g is nonconvex, such solution only exists for some simple g, e.g., nonconvex lasso regularizer (Gong et al., 2013), and usually do not exist for more general cases, e.g., nonconvex tree-structured lasso regularizer (Zhong and Kwok, 2014). On the other hand, Zhong and Kwok (2014) used proximal average (Bauschke et al.", "startOffset": 14, "endOffset": 707}, {"referenceID": 19, "context": "3 Frank-Wolfe (FW) Algorithm The FW algorithm (Frank and Wolfe, 1956) is used for solving optimization problems of the form", "startOffset": 46, "endOffset": 69}, {"referenceID": 33, "context": "Recently, it has been popularly used in machine learning (Jaggi, 2013).", "startOffset": 57, "endOffset": 70}, {"referenceID": 33, "context": "The FW algorithm has a convergence rate of O(1/T ) (Jaggi, 2013).", "startOffset": 51, "endOffset": 64}, {"referenceID": 11, "context": "The nuclear norm of X , \u2016X\u2016\u2217 = \u2211m i=1 \u03c3i(X), is the tightest convex envelope of rank(X), and is often used as a low-rank regularizer (Cand\u00e8s and Recht, 2009).", "startOffset": 133, "endOffset": 157}, {"referenceID": 11, "context": "For example, in matrix completion (Cand\u00e8s and Recht, 2009),", "startOffset": 34, "endOffset": 58}, {"referenceID": 73, "context": "The FW algorithm for this nuclear norm regularized problem is shown in Algorithm 1 (Zhang et al., 2012).", "startOffset": 83, "endOffset": 103}, {"referenceID": 33, "context": "As in (5), the following linear subproblem has to be solved (Jaggi, 2013): min S:\u2016S\u2016\u2217\u22641 \u3008S,\u2207f(Xt)\u3009.", "startOffset": 60, "endOffset": 73}, {"referenceID": 33, "context": "The FW algorithm has a convergence rate of O(1/T ) (Jaggi, 2013).", "startOffset": 51, "endOffset": 64}, {"referenceID": 36, "context": "To make it empirically faster, Algorithm 1 also performs optimization at step 6 (Laue, 2012; Zhang et al., 2012).", "startOffset": 80, "endOffset": 112}, {"referenceID": 73, "context": "To make it empirically faster, Algorithm 1 also performs optimization at step 6 (Laue, 2012; Zhang et al., 2012).", "startOffset": 80, "endOffset": 112}, {"referenceID": 57, "context": "Substituting \u2016X\u2016\u2217 = minX=UV > 1 2 ( \u2016U\u2016F + \u2016V \u2016F ) (Srebro et al., 2004) into (8), we have the following local optimization problem:", "startOffset": 51, "endOffset": 72}, {"referenceID": 73, "context": "Algorithm 1 Frank-Wolfe algorithm for problem (8) with f convex (Zhang et al., 2012).", "startOffset": 64, "endOffset": 84}, {"referenceID": 22, "context": "4 Alternating Direction Method of Multipliers (ADMM) ADMM is a simple but powerful algorithm first introduced in the 1970s (Glowinski and Marroco, 1975).", "startOffset": 123, "endOffset": 152}, {"referenceID": 9, "context": "Recently, it has been popularly used in diverse fields such as machine learning, data mining and image processing (Boyd et al., 2011).", "startOffset": 114, "endOffset": 133}, {"referenceID": 5, "context": "processing and wireless communication (Bertsekas and Tsitsiklis, 1989; Boyd et al., 2011).", "startOffset": 38, "endOffset": 89}, {"referenceID": 9, "context": "processing and wireless communication (Bertsekas and Tsitsiklis, 1989; Boyd et al., 2011).", "startOffset": 38, "endOffset": 89}, {"referenceID": 30, "context": "When fi is smooth and g is convex, ADMM converges to a critical point of (16) (Hong et al., 2016).", "startOffset": 78, "endOffset": 97}, {"referenceID": 20, "context": "Examples include the Geman penalty (GP) (Geman and Yang, 1995), log-sum penalty (LSP) (Cand\u00e8s et al.", "startOffset": 40, "endOffset": 62}, {"referenceID": 12, "context": "Examples include the Geman penalty (GP) (Geman and Yang, 1995), log-sum penalty (LSP) (Cand\u00e8s et al., 2008) and Laplace penalty (Trzasko and Manduca, 2009).", "startOffset": 86, "endOffset": 107}, {"referenceID": 61, "context": ", 2008) and Laplace penalty (Trzasko and Manduca, 2009).", "startOffset": 28, "endOffset": 55}, {"referenceID": 32, "context": "By using different Ai\u2019s, g becomes various structured sparsity regularizers such as the group lasso (Jacob et al., 2009), fused lasso (Tibshirani et al.", "startOffset": 100, "endOffset": 120}, {"referenceID": 60, "context": ", 2009), fused lasso (Tibshirani et al., 2005), and graphical lasso (Jacob et al.", "startOffset": 21, "endOffset": 46}, {"referenceID": 32, "context": ", 2005), and graphical lasso (Jacob et al., 2009).", "startOffset": 29, "endOffset": 49}, {"referenceID": 29, "context": "Since \u1e21 is concave and \u011f is convex, the nonconvex regularizer g = \u011f\u2212 (\u2212\u1e21) can be viewed as a difference of convex functions (DC) (Hiriart-Urruty, 1985).", "startOffset": 129, "endOffset": 151}, {"referenceID": 28, "context": "Since \u1e21 is concave and \u011f is convex, the nonconvex regularizer g = \u011f\u2212 (\u2212\u1e21) can be viewed as a difference of convex functions (DC) (Hiriart-Urruty, 1985). Lu (2012); Gong et al.", "startOffset": 130, "endOffset": 163}, {"referenceID": 26, "context": "Lu (2012); Gong et al. (2013); Zhong and Kwok (2014) also relied on DC decompositions of the nonconvex regularizer.", "startOffset": 11, "endOffset": 30}, {"referenceID": 26, "context": "Lu (2012); Gong et al. (2013); Zhong and Kwok (2014) also relied on DC decompositions of the nonconvex regularizer.", "startOffset": 11, "endOffset": 53}, {"referenceID": 40, "context": "(2016) extended proximal algorithm to simple nonconvex g, but cannot handle more complicated nonconvex regularizers such as the tree-structured lasso regularizer (Liu and Ye, 2010; Schmidt et al., 2011), sparse group lasso regularizer (Jacob et al.", "startOffset": 162, "endOffset": 202}, {"referenceID": 55, "context": "(2016) extended proximal algorithm to simple nonconvex g, but cannot handle more complicated nonconvex regularizers such as the tree-structured lasso regularizer (Liu and Ye, 2010; Schmidt et al., 2011), sparse group lasso regularizer (Jacob et al.", "startOffset": 162, "endOffset": 202}, {"referenceID": 32, "context": ", 2011), sparse group lasso regularizer (Jacob et al., 2009) and total variation regularizer (Nikolova, 2004).", "startOffset": 40, "endOffset": 60}, {"referenceID": 51, "context": ", 2009) and total variation regularizer (Nikolova, 2004).", "startOffset": 40, "endOffset": 56}, {"referenceID": 1, "context": "Using the proximal average (Bauschke et al., 2008), Zhong and Kwok (2014) can handle nonconvex regularizers of the form g = \u2211K i=1 \u03bcigi, where each gi is simple.", "startOffset": 27, "endOffset": 50}, {"referenceID": 70, "context": "General nonconvex optimization techniques such as the concave-convex procedure (CCCP) (Yuille and Rangarajan, 2002) or its variant sequential convex programming (SCP) (Lu, 2012) can also be used, though they are slow in general (Gong et al.", "startOffset": 86, "endOffset": 115}, {"referenceID": 45, "context": "General nonconvex optimization techniques such as the concave-convex procedure (CCCP) (Yuille and Rangarajan, 2002) or its variant sequential convex programming (SCP) (Lu, 2012) can also be used, though they are slow in general (Gong et al.", "startOffset": 167, "endOffset": 177}, {"referenceID": 26, "context": "General nonconvex optimization techniques such as the concave-convex procedure (CCCP) (Yuille and Rangarajan, 2002) or its variant sequential convex programming (SCP) (Lu, 2012) can also be used, though they are slow in general (Gong et al., 2013; Zhong and Kwok, 2014).", "startOffset": 228, "endOffset": 269}, {"referenceID": 75, "context": "General nonconvex optimization techniques such as the concave-convex procedure (CCCP) (Yuille and Rangarajan, 2002) or its variant sequential convex programming (SCP) (Lu, 2012) can also be used, though they are slow in general (Gong et al., 2013; Zhong and Kwok, 2014).", "startOffset": 228, "endOffset": 269}, {"referenceID": 24, "context": "Gong et al. (2013); Li and Lin (2015) and Bot et al.", "startOffset": 0, "endOffset": 19}, {"referenceID": 24, "context": "Gong et al. (2013); Li and Lin (2015) and Bot et al.", "startOffset": 0, "endOffset": 38}, {"referenceID": 5, "context": "(2013); Li and Lin (2015) and Bot et al. (2016) extended proximal algorithm to simple nonconvex g, but cannot handle more complicated nonconvex regularizers such as the tree-structured lasso regularizer (Liu and Ye, 2010; Schmidt et al.", "startOffset": 30, "endOffset": 48}, {"referenceID": 1, "context": "Using the proximal average (Bauschke et al., 2008), Zhong and Kwok (2014) can handle nonconvex regularizers of the form g = \u2211K i=1 \u03bcigi, where each gi is simple.", "startOffset": 28, "endOffset": 74}, {"referenceID": 26, "context": "convergence guarantee for convex and nonconvex f (Gong et al., 2013; Li and Lin, 2015), solving the transformed problem can be much faster.", "startOffset": 49, "endOffset": 86}, {"referenceID": 39, "context": "convergence guarantee for convex and nonconvex f (Gong et al., 2013; Li and Lin, 2015), solving the transformed problem can be much faster.", "startOffset": 49, "endOffset": 86}, {"referenceID": 32, "context": ", (aN , yN )}, (convex) sparse group lasso is formulated as (Jacob et al., 2009):", "startOffset": 60, "endOffset": 80}, {"referenceID": 69, "context": "Its proximal step can be easily computed by the algorithm in (Yuan et al., 2011).", "startOffset": 61, "endOffset": 80}, {"referenceID": 39, "context": "In particular, we will adopt the state-of-the-art nonmontonic APG (nmAPG) algorithm (Li and Lin, 2015) (shown in Algorithm 2).", "startOffset": 84, "endOffset": 102}, {"referenceID": 40, "context": "2 NONCONVEX TREE-STRUCTURED GROUP LASSO In (convex) tree-structured group lasso (Liu and Ye, 2010; Jenatton et al., 2011), the dimensions in x are organized as nodes in a tree, and each group corresponds to a subtree.", "startOffset": 80, "endOffset": 121}, {"referenceID": 34, "context": "2 NONCONVEX TREE-STRUCTURED GROUP LASSO In (convex) tree-structured group lasso (Liu and Ye, 2010; Jenatton et al., 2011), the dimensions in x are organized as nodes in a tree, and each group corresponds to a subtree.", "startOffset": 80, "endOffset": 121}, {"referenceID": 40, "context": "Interested readers are referred to (Liu and Ye, 2010) for details.", "startOffset": 35, "endOffset": 53}, {"referenceID": 39, "context": "Algorithm 2 Nonmonotonic APG (nmAPG) (Li and Lin, 2015).", "startOffset": 37, "endOffset": 55}, {"referenceID": 40, "context": "As shown in (Liu and Ye, 2010), its proximal step can be computed efficiently by processing all the groups once in some appropriate order.", "startOffset": 12, "endOffset": 30}, {"referenceID": 51, "context": "Given an image X \u2208 Rm\u00d7n, the TV regularizer is defined as TV(X) = \u2016DvX\u20161 + \u2016XDh\u20161 (Nikolova, 2004), Dv = \uf8ef\uf8f0\u22121 1 .", "startOffset": 82, "endOffset": 98}, {"referenceID": 51, "context": "Thus, it is popular on image processing problems, such as image denoising and deconvolution (Nikolova, 2004; Beck and Teboulle, 2009).", "startOffset": 92, "endOffset": 133}, {"referenceID": 2, "context": "Thus, it is popular on image processing problems, such as image denoising and deconvolution (Nikolova, 2004; Beck and Teboulle, 2009).", "startOffset": 92, "endOffset": 133}, {"referenceID": 39, "context": "However, Lemma 2 of (Li and Lin, 2015), which is key to the convergence of nmAPG, no longer holds dues to inexact proximal step.", "startOffset": 20, "endOffset": 38}, {"referenceID": 54, "context": "In this case, Schmidt et al. (2011) showed that using inexact proximal steps can make proximal algorithms faster.", "startOffset": 14, "endOffset": 36}, {"referenceID": 26, "context": "If the proximal step is exact, \u2016Vt \u2212 prox 1 \u03c4 \u011f(Vt \u2212 1 \u03c4\u2207f\u0304(Vt))\u2016 2 F can be used to measure how far Vt is from a critical point (Gong et al., 2013; Ghadimi and Lan, 2016).", "startOffset": 129, "endOffset": 171}, {"referenceID": 21, "context": "If the proximal step is exact, \u2016Vt \u2212 prox 1 \u03c4 \u011f(Vt \u2212 1 \u03c4\u2207f\u0304(Vt))\u2016 2 F can be used to measure how far Vt is from a critical point (Gong et al., 2013; Ghadimi and Lan, 2016).", "startOffset": 129, "endOffset": 171}, {"referenceID": 68, "context": "Recently, there is growing interest to replace this with nonconvex regularizers (Lu et al., 2014, 2015; Yao et al., 2015; Gui et al., 2016).", "startOffset": 80, "endOffset": 139}, {"referenceID": 27, "context": "Recently, there is growing interest to replace this with nonconvex regularizers (Lu et al., 2014, 2015; Yao et al., 2015; Gui et al., 2016).", "startOffset": 80, "endOffset": 139}, {"referenceID": 10, "context": "A FW variant allowing nonconvex f\u0304 is proposed in (Bredies et al., 2009).", "startOffset": 50, "endOffset": 72}, {"referenceID": 10, "context": "However, condition 1 in (Bredies et al., 2009) requires g to satisfy lim\u2016X\u2016F\u2192\u221e g(X) \u2016X\u2016F =\u221e.", "startOffset": 24, "endOffset": 46}, {"referenceID": 50, "context": "(34) This can be efficiently solved using matrix optimization techniques on the Grassmann manifold (Ngo and Saad, 2012).", "startOffset": 99, "endOffset": 119}, {"referenceID": 28, "context": "When all the fi\u2019s and g are convex, ADMM has a convergence rate of O(1/T ) (He and Yuan, 2012).", "startOffset": 75, "endOffset": 94}, {"referenceID": 30, "context": "Recently, ADMM has been extended to problems where g is convex but fi\u2019s are nonconvex (Hong et al., 2016).", "startOffset": 86, "endOffset": 105}, {"referenceID": 30, "context": "4 of (Hong et al., 2016) can now be applied.", "startOffset": 5, "endOffset": 24}, {"referenceID": 35, "context": "Examples are stochastic variance reduced gradient (SVRG) (Johnson and Zhang, 2013) and its proximal extension Prox-SVRG (Xiao and Zhang, 2014).", "startOffset": 57, "endOffset": 82}, {"referenceID": 64, "context": "Examples are stochastic variance reduced gradient (SVRG) (Johnson and Zhang, 2013) and its proximal extension Prox-SVRG (Xiao and Zhang, 2014).", "startOffset": 120, "endOffset": 142}, {"referenceID": 53, "context": "Reddi et al. (2016a) and Zhu and Hazan (2016) considered smooth nonconvex ` but without g.", "startOffset": 0, "endOffset": 21}, {"referenceID": 53, "context": "Reddi et al. (2016a) and Zhu and Hazan (2016) considered smooth nonconvex ` but without g.", "startOffset": 0, "endOffset": 46}, {"referenceID": 0, "context": "5 With OWL-QN In this section, we consider OWL-QN (Andrew and Gao, 2007) and its variant mOWL-QN (Gong and Ye, 2015b), which are efficient algorithms for the `1-regularization problem min x f(x) + \u03bc\u2016x\u20161.", "startOffset": 50, "endOffset": 72}, {"referenceID": 0, "context": "5 With OWL-QN In this section, we consider OWL-QN (Andrew and Gao, 2007) and its variant mOWL-QN (Gong and Ye, 2015b), which are efficient algorithms for the `1-regularization problem min x f(x) + \u03bc\u2016x\u20161. (39) Recently, Gong and Ye (2015a) proposed a nonconvex generalization for (39), in which the standard `1 regularizer is replaced by the nonconvex g(x) = \u03bc \u2211d i=1 \u03ba(|xi|):", "startOffset": 51, "endOffset": 239}, {"referenceID": 0, "context": "On the other hand, the Hessian in (41) depends only on f\u0304 , as the Hessian due to \u2016x\u20161 is zero (Andrew and Gao, 2007), and mOWL-QN now extracts Hessian from f\u0304 .", "startOffset": 95, "endOffset": 117}, {"referenceID": 26, "context": "In particular, the proximal algorithm requires f in (1) to be smooth (possibly nonconvex) (Gong et al., 2013; Li and Lin, 2015; Bot et al., 2016).", "startOffset": 90, "endOffset": 145}, {"referenceID": 39, "context": "In particular, the proximal algorithm requires f in (1) to be smooth (possibly nonconvex) (Gong et al., 2013; Li and Lin, 2015; Bot et al., 2016).", "startOffset": 90, "endOffset": 145}, {"referenceID": 6, "context": "In particular, the proximal algorithm requires f in (1) to be smooth (possibly nonconvex) (Gong et al., 2013; Li and Lin, 2015; Bot et al., 2016).", "startOffset": 90, "endOffset": 145}, {"referenceID": 33, "context": "The FW algorithm requires f in (4) to be smooth and convex (Jaggi, 2013).", "startOffset": 59, "endOffset": 72}, {"referenceID": 30, "context": "For the ADMM, it allows f in the consensus problem to be smooth, but g has to be convex (Hong et al., 2016).", "startOffset": 88, "endOffset": 107}, {"referenceID": 38, "context": "For problems of the form minx,z f(y) + g(y) : y = Ax, ADMM requires A to have full row-rank (Li and Pong, 2015).", "startOffset": 92, "endOffset": 111}, {"referenceID": 70, "context": "CCCP (Yuille and Rangarajan, 2002) and smoothing (Chen, 2012) are more general and can still be used, but are usually very slow.", "startOffset": 5, "endOffset": 34}, {"referenceID": 14, "context": "CCCP (Yuille and Rangarajan, 2002) and smoothing (Chen, 2012) are more general and can still be used, but are usually very slow.", "startOffset": 49, "endOffset": 61}, {"referenceID": 65, "context": "The use of nonconvex loss and regularizer often produce better performance (Yan, 2013).", "startOffset": 75, "endOffset": 86}, {"referenceID": 30, "context": "As (44) is not a consensus problem, the method in (Hong et al., 2016) cannot be used.", "startOffset": 50, "endOffset": 69}, {"referenceID": 38, "context": "To use the ADMM algorithm in (Li and Pong, 2015), extra variables and constraints Zv = DvX and Zh = XDh have to be imposed.", "startOffset": 29, "endOffset": 48}, {"referenceID": 38, "context": "However, the full row-rank condition in (Li and Pong, 2015) does not hold.", "startOffset": 40, "endOffset": 59}, {"referenceID": 49, "context": "As (46) is a smooth and convex problem, both accelerated gradient descent (Nesterov, 2013) and L-BFGS (Nocedal and Wright, 2006) can be applied.", "startOffset": 74, "endOffset": 90}, {"referenceID": 66, "context": "2 ROBUST SPARSE CODING The second application is robust sparse coding, which has been popularly used in face recognition (Yang et al., 2011), image analysis (Lu et al.", "startOffset": 121, "endOffset": 140}, {"referenceID": 42, "context": ", 2011), image analysis (Lu et al., 2013) and background modeling (Zhao et al.", "startOffset": 24, "endOffset": 41}, {"referenceID": 74, "context": ", 2013) and background modeling (Zhao et al., 2011).", "startOffset": 32, "endOffset": 51}, {"referenceID": 69, "context": "The proximal step of the convexified regularizer \u011f(x) = \u03ba0(\u03bb\u2016x\u20161 + \u2211K j=1 \u03bcj\u2016xGj\u20162) is obtained using the algorithm in (Yuan et al., 2011).", "startOffset": 119, "endOffset": 138}, {"referenceID": 39, "context": "The nmAPG algorithm (Algorithm 2) in (Li and Lin, 2015) is used for optimization.", "startOffset": 37, "endOffset": 55}, {"referenceID": 45, "context": "SCP: Sequential convex programming (Lu, 2012), in which the LSP regularizer is decomposed following (24).", "startOffset": 35, "endOffset": 45}, {"referenceID": 26, "context": "GIST (Gong et al., 2013): Since the nonconvex regularizer is not separable, the associated proximal operator has no closed-form solution.", "startOffset": 5, "endOffset": 24}, {"referenceID": 75, "context": "GD-PAN (Zhong and Kwok, 2014): It performs gradient descent with proximal average (Bauschke et al.", "startOffset": 7, "endOffset": 29}, {"referenceID": 1, "context": "GD-PAN (Zhong and Kwok, 2014): It performs gradient descent with proximal average (Bauschke et al., 2008) of the nonconvex regularizers.", "startOffset": 82, "endOffset": 105}, {"referenceID": 70, "context": "We do not compare with the concave-convex procedure (Yuille and Rangarajan, 2002), which has been shown to be slow (Gong et al.", "startOffset": 52, "endOffset": 81}, {"referenceID": 26, "context": "We do not compare with the concave-convex procedure (Yuille and Rangarajan, 2002), which has been shown to be slow (Gong et al., 2013; Zhong and Kwok, 2014).", "startOffset": 115, "endOffset": 156}, {"referenceID": 75, "context": "We do not compare with the concave-convex procedure (Yuille and Rangarajan, 2002), which has been shown to be slow (Gong et al., 2013; Zhong and Kwok, 2014).", "startOffset": 115, "endOffset": 156}, {"referenceID": 40, "context": "Following (Liu and Ye, 2010), we resize each image from 256 \u00d7 256 to 64 \u00d7 64.", "startOffset": 10, "endOffset": 28}, {"referenceID": 40, "context": "5),, wi\u2019s are weights (set to be the reciprocal of the size of sample i\u2019s class) used to alleviate class imbalance, and \u03bbi = 1/ \u221a \u2016Gi\u20161 as in (Liu and Ye, 2010).", "startOffset": 142, "endOffset": 160}, {"referenceID": 40, "context": "For the proposed N2C algorithm, the proximal step of the convexified regularizer is obtained as in (Liu and Ye, 2010).", "startOffset": 99, "endOffset": 117}, {"referenceID": 68, "context": "The LSP regularizer is used, with \u03b8 = \u221a \u03bc as in (Yao et al., 2015).", "startOffset": 48, "endOffset": 66}, {"referenceID": 31, "context": "We use the MovieLens data sets2 (Table 5), which have been commonly used for evaluating matrix completion (Hsieh and Olsen, 2014; Yao et al., 2015).", "startOffset": 106, "endOffset": 147}, {"referenceID": 68, "context": "We use the MovieLens data sets2 (Table 5), which have been commonly used for evaluating matrix completion (Hsieh and Olsen, 2014; Yao et al., 2015).", "startOffset": 106, "endOffset": 147}, {"referenceID": 68, "context": "FaNCL (Yao et al., 2015): This is a recent nonconvex matrix regularization algorithm.", "startOffset": 6, "endOffset": 24}, {"referenceID": 63, "context": "LMaFit (Wen et al., 2012): It factorizes X as a product of low-rank matrices U \u2208 Rm\u00d7k and V \u2208 Rn\u00d7k.", "startOffset": 7, "endOffset": 25}, {"referenceID": 31, "context": "Active subspace selection (denoted \u201cactive\u201d) (Hsieh and Olsen, 2014): This solves the (convex) nuclear norm regularized problem (with \u03ba being the identity function in (8)) by using the active row/column subspaces to reduce the optimization problem size.", "startOffset": 45, "endOffset": 68}, {"referenceID": 43, "context": "We do not compare with IRNN (Lu et al., 2014) and GPG (Lu et al.", "startOffset": 28, "endOffset": 45}, {"referenceID": 44, "context": ", 2014) and GPG (Lu et al., 2015), which have been shown to be much slower than FaNCL (Yao et al.", "startOffset": 16, "endOffset": 33}, {"referenceID": 68, "context": ", 2015), which have been shown to be much slower than FaNCL (Yao et al., 2015).", "startOffset": 60, "endOffset": 78}, {"referenceID": 68, "context": "Following (Yao et al., 2015), we use 50% of the ratings for training, 25% for validation and the rest for testing.", "startOffset": 10, "endOffset": 28}, {"referenceID": 47, "context": "Moreover, the convex model needs a much higher rank than the nonconvex models, which agrees with the previous observations in (Mazumder et al., 2010; Yao et al., 2015).", "startOffset": 126, "endOffset": 167}, {"referenceID": 68, "context": "Moreover, the convex model needs a much higher rank than the nonconvex models, which agrees with the previous observations in (Mazumder et al., 2010; Yao et al., 2015).", "startOffset": 126, "endOffset": 167}, {"referenceID": 15, "context": "Eight popular images4 from (Dabov et al., 2007) are used (Figure 7).", "startOffset": 27, "endOffset": 47}, {"referenceID": 70, "context": "CCCP (Yuille and Rangarajan, 2002): Proposition 6 is used to construct DC decomposition for \u03ba (Details are at Appendix B.", "startOffset": 5, "endOffset": 34}, {"referenceID": 14, "context": "Smoothing (Chen, 2012): The nonsmooth \u03ba is smoothed, and then gradient descent is used (Details are at Appendix B.", "startOffset": 10, "endOffset": 22}, {"referenceID": 39, "context": "nmAPG (Li and Lin, 2015): This optimizes (47) with Algorithm 2, and the exact proximal step is solved numerically using CCCP; 4.", "startOffset": 6, "endOffset": 24}, {"referenceID": 9, "context": "As a baseline, we also compare with ADMM (Boyd et al., 2011) with the convex formulation.", "startOffset": 41, "endOffset": 60}, {"referenceID": 17, "context": "Lemma 15 (Eriksson et al., 2004) Let f : R \u2192 R be a differentiable function.", "startOffset": 9, "endOffset": 32}, {"referenceID": 17, "context": "Lemma 16 (Eriksson et al., 2004) If a continuous function f : R\u2192 R isL1-Lipschitz continuous in [a, b] and L2-Lipschitz continuous in [b, c] (where \u2212\u221e \u2264 a < b < c \u2264 \u221e), then it is max(L1, L2)Lipschitz continuous in [a, c].", "startOffset": 9, "endOffset": 32}, {"referenceID": 8, "context": "Lemma 18 (Boyd and Vandenberghe, 2004) \u03c6(x) = \u03c0(q(x)) is concave if \u03c0 is concave, nonincreasing and q is convex.", "startOffset": 9, "endOffset": 38}, {"referenceID": 4, "context": "Definition 19 (Bertsekas, 1999) A function f : Rm \u2192 R is absolute symmetric if f ([x1; .", "startOffset": 14, "endOffset": 31}, {"referenceID": 37, "context": "Lemma 20 (Lewis and Sendov, 2005) Let \u03c3(X) = [\u03c31(X); .", "startOffset": 9, "endOffset": 33}, {"referenceID": 37, "context": "Lemma 21 (Lewis and Sendov, 2005) Let the SVD of X be UDiag(\u03c3(X))V >, where \u03c3(X) = [\u03c31(X); .", "startOffset": 9, "endOffset": 33}, {"referenceID": 8, "context": "Lemma 22 (Boyd and Vandenberghe, 2004) \u03c6(x) = \u03c0(q(x)) is convex if \u03c0 is convex, nondecreasing and q is convex.", "startOffset": 9, "endOffset": 38}, {"referenceID": 48, "context": "Proposition 24 (Mishra et al., 2013) For a square matrix X , let sym(X) = 12(X + X >).", "startOffset": 15, "endOffset": 36}, {"referenceID": 62, "context": "Proof Subdifferential of the nuclear norm can be obtained as (Watson, 1992) \u2202\u2016X\u2016\u2217 = {UV > +W : U>W = 0,WV = 0, \u2016W\u2016\u221e \u2264 1}, (70) where X = UBV >.", "startOffset": 61, "endOffset": 75}], "year": 2017, "abstractText": "The use of convex regularizers allows for easy optimization, though they often produce biased estimation and inferior prediction performance. Recently, nonconvex regularizers have attracted a lot of attention and outperformed convex ones. However, the resultant optimization problem is much harder. In this paper, for a large class of nonconvex regularizers, we propose to move the nonconvexity from the regularizer to the loss. The nonconvex regularizer is then transformed to a familiar convex regularizer, while the resultant loss function can still be guaranteed to be smooth. Learning with the convexified regularizer can be performed by existing efficient algorithms originally designed for convex regularizers (such as the proximal algorithm, FrankWolfe algorithm, alternating direction method of multipliers and stochastic gradient descent). Extensions are made when the convexified regularizer does not have closed-form proximal step, and when the loss function is nonconvex, nonsmooth. Extensive experiments on a variety of machine learning application scenarios show that optimizing the transformed problem is much faster than running the state-of-the-art on the original problem.", "creator": "LaTeX with hyperref package"}}}