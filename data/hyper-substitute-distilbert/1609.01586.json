{"id": "1609.01586", "review": {"conference": "arxiv", "VERSION": "v1", "DATE_OF_SUBMISSION": "6-Sep-2016", "title": "A Bootstrap Machine Learning Approach to Identify Rare Disease Patients from Electronic Health Records", "abstract": "rare diseases although very difficult to observe among large genes n other possible variations. better availability of chromosome numbers and improvement improved computational learning settings empower participants therefore measure this problem computationally. see older paper, we target one such rare non - cardiac disease. guidelines aim to perform surgical procedures of identifying known cardiac inflammation processes with good help like machine learning algorithms and also learn relevant predictive problems. with the help on experienced cardiologists, we implement minimum core standard with 73 trials ( cardiac amyloidosis ) and 78 negative instances. we achieved wide validation cost - validation interval level of 0. 98 using an ensemble machine learning architecture. some of the predictive variables measured : age and diagnosis greater cardiac arrest, chest reaction, functional knee failure, infections, respect for angle disease, and breast tenderness. statistical constraints are needed to increase the accuracy extending the system across globally optimal health field and its generalizability outside treating diseases.", "histories": [["v1", "Tue, 6 Sep 2016 14:54:58 GMT  (235kb)", "http://arxiv.org/abs/1609.01586v1", null]], "reviews": [], "SUBJECTS": "cs.LG cs.CL", "authors": ["ravi garg", "shu dong", "sanjiv shah", "siddhartha r jonnalagadda"], "accepted": false, "id": "1609.01586"}, "pdf": {"name": "1609.01586.pdf", "metadata": {"source": "CRF", "title": "A Bootstrap Machine Learning Approach to Identify Rare Disease Patients from Electronic Health Records", "authors": ["Ravi Garg", "Shu Dong", "Sanjiv Shah"], "emails": [], "sections": [{"heading": null, "text": "Rare diseases are very difficult to identify among large number of other possible diagnoses. Better availability of patient data and improvement in machine learning algorithms empower us to tackle this problem computationally. In this paper, we target one such rare disease \u2013 cardiac amyloidosis. We aim to automate the process of identifying potential cardiac amyloidosis patients with the help of machine learning algorithms and also learn most predictive factors. With the help of experienced cardiologists, we prepared a gold standard with 73 positive (cardiac amyloidosis) and 197 negative instances. We achieved high average cross-validation F1 score of 0.98 using an ensemble machine learning classifier. Some of the predictive variables were: Age and Diagnosis of cardiac arrest, chest pain, congestive heart failure, hypertension, prim open angle glaucoma, and shoulder arthritis. Further studies are needed to validate the accuracy of the system across an entire health system and its generalizability for other diseases."}, {"heading": "Introduction", "text": "Because of several well-established factors such as a) subjectivity involved in human decision-making, b) domain knowledge, and c) prior experience,1,2 there is a possibility of type-1 and type-2 errors in identifying whether patients satisfy a known set of inclusion and exclusion criteria. Furthermore, clinicians typically rely on patterns learnt from patients encountered in their own settings, thereby missing out on the advantage of screening patients or diagnosing them based on latent knowledge and patterns present across an entire health system. An automated process for prescreening and early diagnosis would be quicker and serve as an independent judge. Rare or orphan diseases defined by the Rare Diseases Act of 2002 as diseases that affect fewer than 200,000 people in the United States (equivalent to approximately 6.5 patients per 10,000 inhabitants3) present a special case of this. There are about 8,000 rare diseases such as cardiac amyloidosis today and they appear early in life often proving to be fatal or chronically debilitating.4,5 Cardiac amyloidosis is caused by abnormal deposits of protein called amyloid in the heart tissue.6 These tissues make it hard for the heart to work properly. It is very difficult to successfully recognize a potential cardiac amyloidosis patient manually among large number of other patients. For enrolling rare disease patients for clinical trials, clinicians usually assign pre-defined constraints to filter out most negative patients. However, they still have to manually go through the remaining large part of each patient\u2019s medical record to precisely arrive at a correct decision. For decision making, clinicians have a higher chance of missing the diagnosis of a rare disease since the symptoms are largely unknown for many rare diseases and such patients are encountered only a few times during normal care.\nThe creation and adoption of electronic health records (EHRs) ignited widespread interest and created abundant opportunities for clinical and translational research.7 As Friedman et al noted, the extensive use of clinical data provides great potential to transform our healthcare system into a \u201cSelf-learning Health System.\u201d8,9 In addition to its primary purpose of providing improved clinical practice, the use of EHRs offers means for the identification of participants who satisfy predefined criteria. This can be used for a variety of applications, including clinical trial recruitment, outcome prediction, survival analysis, and other retrospective studies.10-13 The overall goal of this research is to develop a platform that identifies patients potentially with any rare disease or has the risk of any risk disease. We are testing this approach initially on cardiac amyloidosis; however, our approach is scalable to all rare\ndiseases. The main components of our platform are to represent each patient as a multidimensional vector and then to use machine-learning algorithms based on available data on rare diseases to automatically identify them."}, {"heading": "Methods", "text": "Figure 1 describes the architecture of our approach.\nFirst, we created a reasonable sized dataset of positive and negative cardiac amyloidosis patients using information from past and ongoing clinical trials of cardiac amyloidosis at Northwestern Medicine. A total of 73 cardiac amyloidosis patients were identified and formed the positive instances. A random sample of 197 patients that visited cardiologists at Northwestern Medicine but were not diagnosed to have cardiac amyloidosis (based on their ICD-9 codes) formed the negative instances. The negative patients were chosen in such a way so as to maintain similarity with the positive patients but not have cardiac amyloidosis. A total of 270 patients formed our training dataset as summarized in Table 1.\nNext, we represented each patient as a vector using information from their EHRs stored in Northwestern Medicine Enterprise Data warehouse (NMEDW). Each patient record was then processed so that all relevant sections of the patient records which are potentially useful for creating features space were extracted. The relevant sections or feature types we have considered in this study are Demographics (such as Gender, Race, Ethnicity and Age), Diagnosis, Medication, Problems, Surgical data and Progress Notes. Demographics, Diagnosis and Medication, Problems and Surgical data are available in structured form, whereas Progress notes are only available as unstructured text. The value of each feature type is then transformed in order to be useful for machine learning classifier. Each value of Demographics, Diagnosis and Medication is treated as a binary feature. For example, if a patient has diagnosis \u201cAnemia\u201d, we assigned a vector for \u201cAnemia\u201d and assigned a value of 1 for that patient and 0 for other patients. Similarly the presence of each medication such \u201cParacetamol\u201d is treated as a separate feature. Certain variable such as \u2018age\u2019 in Demographics are numeric with a wide range of values. Such features are discretized14 by transforming the numbers to assignment in bins or ranges. That is, rather than representing the age of the patient by its numeric value (for e.g. 43), we represent it by a range (e.g. 40-49). Processing the records this way generated, 15 Demographics features, 5002 Diagnosis features, 3521 Medication features, 2124 Problem features and 101 Surgical data features. For transforming Progress notes to informative features, we follow the\nwidely used Bag-of-Words model. The progress notes from all patient records are first preprocessed (lowercase, removal of punctuation and stop words, normalizing numeric values to placeholders) and then tokenized to unigrams and bigrams bag of words. These are then further pruned by ignoring the very high frequency unigrams or bigrams. After the transformation, in total, we get 1766 unigram features and 1044 bigram features for this dataset. The features are summarized in Table 2.\nOn this dataset of 223 instances and 8011 features several machine learning classifiers which we describe next are trained.\nThe machine learning classification algorithms we have considered in our study are K Nearest Neighbors,15,16 Support Vector Machines,17,18 Decision Trees,19 Random Forests,20 AdaBoost,21 and Na\u00efve Bayes22,23. K-nearest neighbors (KNN) is an instance based learning algorithm that stores all the training instances and classifies the new cases based on the distance functions. K-NN works on the principle of classifying the new test case by a majority vote, with the test case being assigned to the class most common amongst its K nearest neighbors. Each point in the neighborhood may be assigned equal importance or given some sort of weight such as distance (larger the distance smaller the weight/importance).\nSupport Vector Machine (SVM) performs classification by finding the hyperplane that maximizes the margin between the two classes. The instances that define the hyperplane are called support vectors. SVM is high performing machine learning classifier due to the fact that if the data is linearly separable, SVM would produce a hyperplane that completely separates the vectors into two classes. However, in real life scenario perfect separation may not be possible. In such a case we can use different kernel function to project the data point into a different feature space where data may be linearly separable. Kernel function can be viewed as feature extraction techniques which take the existing features as input, performs the transformation and output a new feature space.\nNa\u00efve Bayes (NB) algorithm is based on the Bayes theorem with assumption that the features are independent of each other. NB model is easy to develop with no parameter estimation. Despite its simplicity, NB model is widely used and outperforms other sophisticated machine learning algorithms such as SVM. NB provides a method of calculating posterior probability of class given the prior probability and learning the likelihood of features given the class.\nDecision trees (DT) builds classification models using a tree like structure. It works on the principle of divide and conquer breaking the dataset at each feature according to the best split and at the same time incrementally building the tree. The final result of the algorithm is a tree with decision node and leaf nodes. Decision node makes a certain conclusion depending upon the feature and has two or more branches. Leaf node does the final classification.\nRandom Forest (RF) and AdaBoost are two ensemble algorithms which we have also used in our experiments. The principle behind working of RF algorithm is to construct many decision trees during the training and classifies the test case based on the mode of the classes given by individual trees. AdaBoost is another ensemble methods in which various other machine learning classifiers or also weak learners are combined to give a weighted sum that represents the output of the final classifier. It begins by fitting a classifier first on the data and then learning more classifiers by adjusting the weights of the previously misclassified data points.\nIn addition, there are also a variety of hyper-parameters that were tuned in tandem for each of these classification algorithms. Table 3 lists the various algorithms and the corresponding hyper-parameters and their value ranges involved with each algorithm. We perform grid search24 technique which is a brute-force exhaustive method to search for the best parameters through the manually specified subset of the hyper-parameter space of a learning algorithm.\nIn addition to various algorithms and models, we also employed feature selection methods to improve upon the accuracy of the classification models. First, features with very low variance are removed. That is, the features whose 85% of values are either \u20180\u2019 or \u20181\u2019 are removed since they do not give much information about either category. We then used L1 regularization25 to do more feature selection and thereby identify top features to identify those that play decisive roles in classifying the patient into each category. L1 regularization adds a weight penalty to the loss function. Since each non-zero weight adds to the penalty, it forces weak features to have zero weight. Thus, this produces a sparse solution by intrinsically performing feature selection.\nTo evaluate the system, we perform tenfold cross-validation and report the average F1 score26 (harmonic mean of precision and recall)."}, {"heading": "Results", "text": "Table 4 shows the optimal configuration for each classification algorithm used as measured by average tenfold cross-validation F1 score. Since the number of positive instances in the dataset is very small, the number of nearest neighbors (KNN) take the least possible value 1 (K in KNN). KNN and NB gives a very low F1 score as compared to other complex algorithms since they are sensitive to outliers and also do not perform adequate feature selection. These algorithms give equal importance to all the features, which leads to poor performance. On the other hand, SVM, DT and Ensemble methods give a large F1-score due to complexity in models and ability to intrinsically performing feature selection. Also, as expected, ensemble method AdaBoost outperforms rest of the algorithms since it combines the output of other weak learners to arrive at the final hypothesis.\nWe list some of the important features obtained after performing feature selection in Table 5. It can be seen that patients in age range 70-90 are more likely to have cardiac amyloidosis than patients of other ages. Also, presence of other cardiac diagnosis such as congestive heart failure and chest pain as important features shows that cardiac amyloidosis are comorbid with other heart problems. Some of the medications are also suggestive of this hypothesis. However, this requires further analysis and inputs from multiple cardiologists.\nThe accuracy measures on re-running the machine learning algorithms using only the features filtered from feature selection technique are listed in Table 6. All the algorithms give nearly high and similar average cross-validation F1 score. As anticipated, there is also rise in scores of KNN and NB due to removal of noisy insignificant features."}, {"heading": "Discussion", "text": "This work is very relevant to an emerging direction in clinical informatics research focusing on developing patient similarity measures derived from EHR data for application in a variety of areas.27-36 For example, Zhang et al used patient similarity and drug similarity for personalized medicine.35 Wang et al attempted to implement treatment recommendations and Sanders et al used similarity measure for visualizing which patients are similar.27,28 Li et al used topological similarity measures to identify subgroups of type 2 diabetes patients.31 Huang et al applied such metrics for analyzing clinical pathways and Lee et al and Ng et al applied for predicting mortality for individual patients.32,36 There are systems such as PSF that are evaluating novel metric learning approaches and those that are using external knowledge resources such as PubMed to improved patient similarity measures.33,34 We also used Apache cTAKES37 to extract more features from unstructured Progress notes. However, since we are already accomplishing a very high average cross-validation F1 score and the unigram and bigram features that are also obtained from progress notes are not very predictive, we decided not to currently use them in further experiments. These would have only further escalated the curse of dimensionality38 and will not have contributed significantly to increase the accuracy of the models. However, we might implement NLP-based features as we are expanding our algorithm to other rare diseases. In spite of the high accuracy of our system, there is a limitation. In our training set, the instances are moderately balanced, i.e., positive and negative instances are 1:3 in ratio. However, as we have mentioned in the Introduction, cardiac amyloidosis is a rare disease. The ratio in real scenario will be closer to 1:1000. If we directly use the models produced through our methods, we may get a large number of false positives and thereby low precision rate because of failure to generalize and the sample data not being true representative of real world data39. To counter this, we need to do preprocessing using high recall rules to filter out the very obvious negative instances. The goal of these rules will be to reduce the skewness of the real world data. After the filtering step, our models can be applied on the resulting dataset. These high recall rules can be implemented using the factors identified through our methods as most predictive in Table 5. We can also employ other feature selection techniques such as wrapper methods, tree based induction methods40 or use association mining41,42 for doing. We consider this beyond the scope of this initial work."}, {"heading": "Conclusion", "text": "We have developed a machine learning system to automatically identify cardiac amyloidosis patients using EHR data. We performed data processing, parameter estimation, feature selection and model selection to achieve a very high tenfold cross-validation F1 score of 0.98 using Random Forest, an ensemble machine learning classifier. We have also reported some of the most predictive features. However, our system needs to be validated for its operational value across an entire healthcare system by executing it on system-wide EHR data for identifying rare disease patients and manually verifying the accuracy."}, {"heading": "Acknowledgement", "text": "This project was partially supported by National Library of Medicine (grant R00LM011389).\nReferences\n1. Sox HC, Higgins MC. Medical decision making: ACP Press; 1988. 2. Sullivan J. Subject Recruitment and Retention: Barrier to Success. Applied Clinical Trials 2004. 3. Zhang M, Zhu C, Jacomy A, Lu LJ, Jegga AG. The orphan disease networks. The American Journal of Human Genetics 2011;88:755-66. 4. Schieppati A, Henter JI, Daina E, Aperia A. Why rare diseases are an important medical and social issue. Lancet 2008;371:2039-41. 5. Stolk P, Willemen MJ, Leufkens HG. Rare essentials: drugs for rare diseases as essential medicines. Bulletin of the World Health Organization 2006;84:745-51. 6. Quarta CC, Kruger JL, Falk RH. Cardiac Amyloidosis. Circulation 2012;126:e178-e82. 7. Jensen PB, Jensen LJ, Brunak S. Mining electronic health records: towards better research applications and clinical care. Nat Rev Genet 2012;13:395-405.\n8. Friedman CP, Wong AK, Blumenthal D. Achieving a Nationwide Learning Health System. Science Translational Medicine 2010;2. 9. Friedman C, Rigby M. Conceptualising and creating a global learning health system. Int J Med Inform 2013;82:e63-71. 10. Ma X-J, Wang Z, Ryan PD, et al. A two-gene expression ratio predicts clinical outcome in breast cancer patients treated with tamoxifen. Cancer Cell 2004;5:607-16. 11. Strom BL, Schinnar R, Jones J, et al. Detecting pregnancy use of non-hormonal category X medications in electronic medical records. Journal of the American Medical Informatics Association 2011;18:i81-i6. 12. Mathias JS, Gossett D, Baker DW. Use of electronic health record data to evaluate overuse of cervical cancer screening. Journal of the American Medical Informatics Association 2012;19:e96-e101. 13. De Pauw R, Kregel J, De Blaiser C, et al. Identifying prognostic factors predicting outcome in patients with chronic neck pain after multimodal treatment: A retrospective study. Man Ther 2015;20:592-7. 14. Liu H, Hussain F, Tan CL, Dash M. Discretization: An enabling technique. Data mining and knowledge discovery 2002;6:393-423. 15. Altman NS. An introduction to kernel and nearest-neighbor nonparametric regression. The American Statistician 1992;46:175-85. 16. Ruiz EV. An algorithm for finding nearest neighbours in (approximately) constant average time. Pattern Recognition Letters 1986;4:145-57. 17. Suykens JA, Vandewalle J. Least squares support vector machine classifiers. Neural processing letters 1999;9:293-300. 18. Cortes C, Vapnik V. Support vector machine. Machine learning 1995;20:273-97. 19. Quinlan JR. Induction of decision trees. Machine learning 1986;1:81-106. 20. Liaw A, Wiener M. Classification and regression by randomForest. R news 2002;2:18-22. 21. R\u00e4tsch G, Onoda T, M\u00fcller K-R. Soft margins for AdaBoost. Machine learning 2001;42:287-320. 22. Rish I. An empirical study of the naive Bayes classifier. IJCAI 2001 workshop on empirical methods in artificial intelligence; 2001: IBM New York. p. 41-6. 23. McCallum A, Nigam K. A comparison of event models for naive bayes text classification. AAAI-98 workshop on learning for text categorization; 1998: Citeseer. p. 41-8. 24. Bergstra J, Bengio Y. Random search for hyper-parameter optimization. The Journal of Machine Learning Research 2012;13:281-305. 25. Ng AY. Feature selection, L 1 vs. L 2 regularization, and rotational invariance. Proceedings of the twentyfirst international conference on Machine learning; 2004: ACM. p. 78. 26. Powers DM. Evaluation: from precision, recall and F-measure to ROC, informedness, markedness and correlation. 2011. 27. Wang Y, Tian Y, Tian LL, Qian YM, Li JS. An electronic medical record system with treatment recommendations based on patient similarity. Journal of medical systems 2015;39:55. 28. Sanders M, Winters P, Fiscella K. Preliminary validation of a scale to measure patient perceived similarity to their navigator. BMC Res Notes 2015;8:388. 29. Panahiazar M, Taslimitehrani V, Pereira NL, Pathak J. Using EHRs for Heart Failure Therapy Recommendation Using Multidimensional Patient Similarity Analytics. Stud Health Technol Inform 2015;210:369- 73. 30. Ng K, Sun J, Hu J, Wang F. Personalized Predictive Modeling and Risk Factor Identification using Patient Similarity. AMIA Joint Summits on Translational Science proceedings AMIA Summit on Translational Science 2015;2015:132-6. 31. Li L, Cheng WY, Glicksberg BS, et al. Identification of type 2 diabetes subgroups through topological analysis of patient similarity. Sci Transl Med 2015;7:311ra174. 32. Lee J, Maslove DM, Dubin JA. Personalized mortality prediction driven by electronic medical data and a patient similarity metric. PLoS One 2015;10:e0127428. 33. Fei W, Sun J. PSF: A Unified Patient Similarity Evaluation Framework Through Metric Learning With Weak Supervision. IEEE journal of biomedical and health informatics 2015;19:1053-60. 34. Chan LW, Liu Y, Chan T, et al. PubMed-supported clinical term weighting approach for improving interpatient similarity measure in diagnosis prediction. BMC Med Inform Decis Mak 2015;15:43. 35. Zhang P, Wang F, Hu J, Sorrentino R. Towards personalized medicine: leveraging patient similarity and drug similarity analytics. AMIA Joint Summits on Translational Science proceedings AMIA Summit on Translational Science 2014;2014:132-6.\n36. Huang Z, Dong W, Duan H, Li H. Similarity measure between patient traces for clinical pathway analysis: problem, method, and applications. IEEE journal of biomedical and health informatics 2014;18:4-14. 37. Savova GK, Masanz JJ, Ogren PV, et al. Mayo clinical Text Analysis and Knowledge Extraction System (cTAKES): architecture, component evaluation and applications. Journal of the American Medical Informatics Association 2010;17:507-13. 38. Friedman JH. On bias, variance, 0/1\u2014loss, and the curse-of-dimensionality. Data mining and knowledge discovery 1997;1:55-77. 39. Kotsiantis S, Kanellopoulos D, Pintelas P. Handling imbalanced datasets: A review. GESTS International Transactions on Computer Science and Engineering 2006;30:25-36. 40. Kohavi R, John GH. Wrappers for feature subset selection. Artificial intelligence 1997;97:273-324. 41. Ceglar A, Roddick JF. Association mining. ACM Computing Surveys (CSUR) 2006;38:5. 42. Agrawal R, Srikant R. Fast algorithms for mining association rules. Proc 20th int conf very large data bases, VLDB; 1994. p. 487-99."}], "references": [{"title": "Medical decision making: ACP", "author": ["Sox HC", "Higgins MC"], "venue": null, "citeRegEx": "1", "shortCiteRegEx": "1", "year": 1988}, {"title": "Subject Recruitment and Retention: Barrier to Success", "author": ["J. Sullivan"], "venue": "Applied Clinical Trials", "citeRegEx": "2", "shortCiteRegEx": "2", "year": 2004}, {"title": "The orphan disease", "author": ["M Zhang", "C Zhu", "A Jacomy", "LJ Lu", "AG. Jegga"], "venue": "networks. The American Journal of Human Genetics", "citeRegEx": "3", "shortCiteRegEx": "3", "year": 2011}, {"title": "Why rare diseases are an important medical and social issue", "author": ["A Schieppati", "JI Henter", "E Daina", "A. Aperia"], "venue": null, "citeRegEx": "4", "shortCiteRegEx": "4", "year": 2008}, {"title": "Rare essentials: drugs for rare diseases as essential medicines", "author": ["P Stolk", "MJ Willemen", "HG. Leufkens"], "venue": "Bulletin of the World Health Organization", "citeRegEx": "5", "shortCiteRegEx": "5", "year": 2006}, {"title": "Cardiac Amyloidosis. Circulation 2012;126:e178-e82", "author": ["CC Quarta", "JL Kruger", "RH. Falk"], "venue": null, "citeRegEx": "6", "shortCiteRegEx": "6", "year": 2012}, {"title": "Mining electronic health records: towards better research applications and clinical care", "author": ["PB Jensen", "LJ Jensen", "S. Brunak"], "venue": "Nat Rev Genet", "citeRegEx": "7", "shortCiteRegEx": "7", "year": 2012}, {"title": "Achieving a Nationwide Learning Health System. Science Translational Medicine 2010;2", "author": ["CP Friedman", "AK Wong", "D. Blumenthal"], "venue": null, "citeRegEx": "8", "shortCiteRegEx": "8", "year": 2010}, {"title": "Conceptualising and creating a global learning health system", "author": ["C Friedman", "M. Rigby"], "venue": "Int J Med Inform 2013;82:e63-71", "citeRegEx": "9", "shortCiteRegEx": "9", "year": 2013}, {"title": "A two-gene expression ratio predicts clinical outcome in breast cancer patients treated with tamoxifen", "author": ["X-J Ma", "Z Wang", "PD Ryan"], "venue": "Cancer Cell 2004;5:607-16", "citeRegEx": "10", "shortCiteRegEx": "10", "year": 2004}, {"title": "Detecting pregnancy use of non-hormonal category X medications in electronic medical records. Journal of the American Medical Informatics Association 2011;18:i81-i6", "author": ["BL Strom", "R Schinnar", "J Jones"], "venue": null, "citeRegEx": "11", "shortCiteRegEx": "11", "year": 2011}, {"title": "Use of electronic health record data to evaluate overuse of cervical cancer screening", "author": ["JS Mathias", "D Gossett", "DW. Baker"], "venue": "Journal of the American Medical Informatics Association 2012;19:e96-e101", "citeRegEx": "12", "shortCiteRegEx": "12", "year": 2012}, {"title": "Identifying prognostic factors predicting outcome in patients with chronic neck pain after multimodal treatment: A retrospective study", "author": ["R De Pauw", "J Kregel", "C De Blaiser"], "venue": "Man Ther 2015;20:592-7", "citeRegEx": "13", "shortCiteRegEx": "13", "year": 2015}, {"title": "Discretization: An enabling technique. Data mining and knowledge discovery 2002;6:393-423", "author": ["H Liu", "F Hussain", "CL Tan", "M. Dash"], "venue": null, "citeRegEx": "14", "shortCiteRegEx": "14", "year": 2002}, {"title": "An introduction to kernel and nearest-neighbor nonparametric regression", "author": ["Altman NS"], "venue": "The American Statistician", "citeRegEx": "15", "shortCiteRegEx": "15", "year": 1992}, {"title": "An algorithm for finding nearest neighbours in (approximately) constant average time. Pattern Recognition Letters 1986;4:145-57", "author": ["Ruiz EV"], "venue": null, "citeRegEx": "16", "shortCiteRegEx": "16", "year": 1986}, {"title": "Least squares support vector machine classifiers. Neural processing letters 1999;9:293-300", "author": ["JA Suykens", "J. Vandewalle"], "venue": null, "citeRegEx": "17", "shortCiteRegEx": "17", "year": 1999}, {"title": "Support vector machine. Machine learning 1995;20:273-97", "author": ["C Cortes", "V. Vapnik"], "venue": null, "citeRegEx": "18", "shortCiteRegEx": "18", "year": 1995}, {"title": "Induction of decision trees. Machine learning 1986;1:81-106", "author": ["Quinlan JR"], "venue": null, "citeRegEx": "19", "shortCiteRegEx": "19", "year": 1986}, {"title": "Classification and regression by randomForest. R news 2002;2:18-22", "author": ["A Liaw", "M. Wiener"], "venue": null, "citeRegEx": "20", "shortCiteRegEx": "20", "year": 2002}, {"title": "Soft margins for AdaBoost. Machine learning 2001;42:287-320", "author": ["G R\u00e4tsch", "T Onoda", "K-R. M\u00fcller"], "venue": null, "citeRegEx": "21", "shortCiteRegEx": "21", "year": 2001}, {"title": "An empirical study of the naive Bayes classifier", "author": ["I. Rish"], "venue": "IJCAI 2001 workshop on empirical methods in artificial intelligence;", "citeRegEx": "22", "shortCiteRegEx": "22", "year": 2001}, {"title": "A comparison of event models for naive bayes text classification. AAAI-98 workshop on learning for text categorization; 1998: Citeseer", "author": ["A McCallum", "K. Nigam"], "venue": null, "citeRegEx": "23", "shortCiteRegEx": "23", "year": 1998}, {"title": "Random search for hyper-parameter optimization. The Journal of Machine Learning Research 2012;13:281-305", "author": ["J Bergstra", "Y. Bengio"], "venue": null, "citeRegEx": "24", "shortCiteRegEx": "24", "year": 2012}, {"title": "Feature selection, L 1 vs. L 2 regularization, and rotational invariance", "author": ["Ng AY"], "venue": "Proceedings of the twentyfirst international conference on Machine learning; 2004: ACM", "citeRegEx": "25", "shortCiteRegEx": "25", "year": 2004}, {"title": "Evaluation: from precision, recall and F-measure to ROC, informedness, markedness and correlation", "author": ["Powers DM"], "venue": null, "citeRegEx": "26", "shortCiteRegEx": "26", "year": 2011}, {"title": "An electronic medical record system with treatment recommendations based on patient similarity", "author": ["Y Wang", "Y Tian", "LL Tian", "YM Qian", "JS. Li"], "venue": "Journal of medical systems", "citeRegEx": "27", "shortCiteRegEx": "27", "year": 2015}, {"title": "Preliminary validation of a scale to measure patient perceived similarity to their navigator", "author": ["M Sanders", "P Winters", "K. Fiscella"], "venue": "BMC Res Notes", "citeRegEx": "28", "shortCiteRegEx": "28", "year": 2015}, {"title": "Using EHRs for Heart Failure Therapy Recommendation Using Multidimensional Patient Similarity Analytics", "author": ["M Panahiazar", "V Taslimitehrani", "NL Pereira", "J. Pathak"], "venue": "Stud Health Technol Inform 2015;210:36973", "citeRegEx": "29", "shortCiteRegEx": "29", "year": 2015}, {"title": "Personalized Predictive Modeling and Risk Factor Identification using Patient Similarity", "author": ["K Ng", "J Sun", "J Hu", "F. Wang"], "venue": "AMIA Joint Summits on Translational Science proceedings AMIA Summit on Translational Science", "citeRegEx": "30", "shortCiteRegEx": "30", "year": 2015}, {"title": "Identification of type 2 diabetes subgroups through topological analysis of patient similarity", "author": ["L Li", "WY Cheng", "BS Glicksberg"], "venue": "Sci Transl Med 2015;7:311ra174", "citeRegEx": "31", "shortCiteRegEx": "31", "year": 2015}, {"title": "Personalized mortality prediction driven by electronic medical data and a patient similarity metric", "author": ["J Lee", "DM Maslove", "JA. Dubin"], "venue": "PLoS One 2015;10:e0127428", "citeRegEx": "32", "shortCiteRegEx": "32", "year": 2015}, {"title": "PSF: A Unified Patient Similarity Evaluation Framework Through Metric Learning With Weak Supervision", "author": ["W Fei", "J. Sun"], "venue": "IEEE journal of biomedical and health informatics 2015;19:1053-60", "citeRegEx": "33", "shortCiteRegEx": "33", "year": 2015}, {"title": "PubMed-supported clinical term weighting approach for improving interpatient similarity measure in diagnosis prediction", "author": ["LW Chan", "Y Liu", "T Chan"], "venue": "BMC Med Inform Decis Mak 2015;15:43", "citeRegEx": "34", "shortCiteRegEx": "34", "year": 2015}, {"title": "Towards personalized medicine: leveraging patient similarity and drug similarity analytics", "author": ["P Zhang", "F Wang", "J Hu", "R. Sorrentino"], "venue": "AMIA Joint Summits on Translational Science proceedings AMIA Summit on Translational Science", "citeRegEx": "35", "shortCiteRegEx": "35", "year": 2014}, {"title": "Similarity measure between patient traces for clinical pathway analysis: problem, method, and applications. IEEE journal of biomedical and health informatics 2014;18:4-14", "author": ["Z Huang", "W Dong", "H Duan", "H. Li"], "venue": null, "citeRegEx": "36", "shortCiteRegEx": "36", "year": 2014}, {"title": "Mayo clinical Text Analysis and Knowledge Extraction System (cTAKES): architecture, component evaluation and applications", "author": ["GK Savova", "JJ Masanz", "PV Ogren"], "venue": "Journal of the American Medical Informatics Association", "citeRegEx": "37", "shortCiteRegEx": "37", "year": 2010}, {"title": "On bias, variance, 0/1\u2014loss, and the curse-of-dimensionality. Data mining and knowledge discovery 1997;1:55-77", "author": ["Friedman JH"], "venue": null, "citeRegEx": "38", "shortCiteRegEx": "38", "year": 1997}, {"title": "Handling imbalanced datasets: A review", "author": ["S Kotsiantis", "D Kanellopoulos", "P. Pintelas"], "venue": "GESTS International Transactions on Computer Science and Engineering", "citeRegEx": "39", "shortCiteRegEx": "39", "year": 2006}, {"title": "Wrappers for feature subset selection. Artificial intelligence 1997;97:273-324", "author": ["Kohavi R", "John GH"], "venue": null, "citeRegEx": "40", "shortCiteRegEx": "40", "year": 1997}, {"title": "Association mining. ACM Computing Surveys (CSUR) 2006;38:5", "author": ["Ceglar A", "Roddick JF"], "venue": null, "citeRegEx": "41", "shortCiteRegEx": "41", "year": 2006}, {"title": "Fast algorithms for mining association rules", "author": ["R Agrawal", "R. Srikant"], "venue": "Proc 20th int conf very large data bases,", "citeRegEx": "42", "shortCiteRegEx": "42", "year": 1994}], "referenceMentions": [], "year": 2016, "abstractText": "Rare diseases are very difficult to identify among large number of other possible diagnoses. Better availability of patient data and improvement in machine learning algorithms empower us to tackle this problem computationally. In this paper, we target one such rare disease \u2013 cardiac amyloidosis. We aim to automate the process of identifying potential cardiac amyloidosis patients with the help of machine learning algorithms and also learn most predictive factors. With the help of experienced cardiologists, we prepared a gold standard with 73 positive (cardiac amyloidosis) and 197 negative instances. We achieved high average cross-validation F1 score of 0.98 using an ensemble machine learning classifier. Some of the predictive variables were: Age and Diagnosis of cardiac arrest, chest pain, congestive heart failure, hypertension, prim open angle glaucoma, and shoulder arthritis. Further studies are needed to validate the accuracy of the system across an entire health system and its generalizability for other diseases.", "creator": "Word"}}}