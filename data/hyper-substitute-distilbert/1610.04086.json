{"id": "1610.04086", "review": {"conference": "arxiv", "VERSION": "v1", "DATE_OF_SUBMISSION": "13-Oct-2016", "title": "Unorganized Malicious Attacks Detection", "abstract": "sophisticated system patterns attracted much concern during frequent bidding season, while many attack detection algorithms have been developed for better consistency. most previous approaches run on the shilling attacks, because targeted analyst systematically fakes a large number of user edges through the active strategy to obtain or adjust to object. in related paper, we tell its different attack case : unorganized site attacks, where attackers respectively use a small few 000 user profiles to deliver their own target items without any organizer. this fashion nevertheless occurs in many real applications, yet actual study follows open. recalling this paper, we qualify the unorganized malicious attacks method as a variant adaptive matrix objective grammar, and prove that attackers also achieve saved theoretically. findings propose naive statistical malicious attacks detection ( uma ) graph, whilst possible be viewed when any linear diagonal splitting augmented lagrangian method. we verify, again actively and empirically, predict effectiveness of another response algorithm.", "histories": [["v1", "Thu, 13 Oct 2016 14:02:49 GMT  (453kb,D)", "http://arxiv.org/abs/1610.04086v1", null]], "reviews": [], "SUBJECTS": "cs.IR cs.LG", "authors": ["ming pang", "wei gao", "min tao", "zhi-hua zhou"], "accepted": false, "id": "1610.04086"}, "pdf": {"name": "1610.04086.pdf", "metadata": {"source": "CRF", "title": "Unorganized Malicious Attacks Detection", "authors": ["Ming Pang", "Wei Gao", "Zhi-Hua Zhou"], "emails": ["pangm@lamda.nju.edu.cn", "gaow@lamda.nju.edu.cn", "taom@nju.edu.cn", "zhouzh@lamda.nju.edu.cn"], "sections": [{"heading": null, "text": "Keywords: attacks detection, recommender systems, alternating direction method, augmented Lagrangian method"}, {"heading": "1. Introduction", "text": "Online activities have been an essential part in our daily life as the flourish of the Internet, e.g., increasing customers prefer shopping on Amazon and eBay; Lots of people enjoy watching different movies and TV shows on Youtube and Netflix, etc. There is a big challenge to recommend suitable products effectively as the number of users and items increases drastically; therefore, various collaborative filtering techniques have been developed in diverse\nc\u00a9xxxx Ming Pang, Wei Gao, Min Tao and Zhi-Hua Zhou.\nar X\niv :1\n61 0.\n04 08\n6v 1\nsystems so as to help customers choose their favorite products in a set of items (Bresler et al., 2014; Li et al., 2009; Rao et al., 2015).\nMany collaborative filtering approaches are vulnerable to spammers and manipulations of ratings (Gunes et al., 2014; Ling et al., 2013), and attackers may bias systems by inserting fake rating scores into the user-item rating matrix. Some attackers may increase the popularity of their own items (push attack) while some others may decrease the popularity of their competitors\u2019 items (nuke attack). Most attack detection studies focus on shilling attacks and show good detection performance on kinds of shilling attack strategies (Hurley et al., 2009; Ling et al., 2013; Mehta, 2007). They consider the situation that all the fake user profiles are produced by the same strategy to promote or demote a particular item. For example, an attack organizer may produce hundreds of fake users by a strategy that each fake users gives high scores to the most popular movies and low scores to the target movie to demote it.\nVarious techniques have been developed to control shilling attacks, e.g., online sites require real names and telephone numbers for registrations; CAPTCHA is used to determine that the response is not generated by a robot; customers are allowed to rate a product after purchasing this product on the shopping website. Based on these measures, traditional shilling attacks may suffer high cost. For example, small online sellers in e-commerce like Amazon might not be willing to fake hundreds of customer rating profiles to implement a shilling attack.\nIn this paper, we investigate a new attacks model named unorganized malicious attack, where attackers respectively use a small number of user profiles to attack their own targets without any organizer. This attack style happens in many real applications, e.g., online sellers on Amazon may fake a few customer rating profiles to nuke their competitors\u2019 highquality shoes; writers may hire several readers to give high scores to their low-quality books. In fact, it has been shown that systems are seriously affected by small amounts of unorganized malicious attacks.12\nWe first formulate the unorganized malicious attacks detection as a variant of matrix completion problem. Let X denote the ground-truth rating matrix without attacks and noises, and the matrix is low-rank since the users\u2019 preferences are affected by several factors (Salakhutdinov et al., 2007). Let Y be the sparse attack-score matrix, and Z denotes a noisy matrix. What we can observe is a (or partial) matrix M such that M = X+Y +Z. As far as we know, previous works do not make similar formulation for attack detection. The main difference between our optimization problem and robust PCA (Cande\u0300s et al., 2011) is that roubst PCA focuses on recovering low-rank part X from complete or incomplete matrix and we pay more attention to distinguishing the sparse attack term Y from the small perturbation noise term Z.\nTheoretically, we prove that the low-rank rating matrix X and the sparse matrix Y can be recovered under some classical matrix-completion assumptions, but with a different optimization problem. We propose the Unorganized Malicious Attacks detection (UMA) algorithm, which can be viewed as a proximal alternating splitting augmented Lagrangian method. Some new techniques have been developed to prove its global convergence. Finally,\n1. http://www.forbes.com/sites/suwcharmananderson/. 2. http://how-to-post-fake-reviews-on-amazon.blogspot.com/.\nexperimental results verify the effectiveness of our proposed algorithm in comparison with the state-of-the-art methods of attack detection.\nThe rest of this paper is organized as follows. Section 2 reviews some related works. Section 3 introduces the framework of unorganized malicious attacks, and Section 4 proposes our UMA algorithm. Section 5 presents theoretical justification for attack detection, matrix recovery and convergence of UMA algorithm. Section 6 shows our experiments, and Section 7 concludes this work."}, {"heading": "2. Related Work", "text": "Collaborative filtering (CF) is one of the most successful techniques to build recommender systems. The core assumption of CF is that if users express similar interests in the past, they will share common interest in the future (Goldberg et al., 1992). Significant progress about CF has been made since then (Bresler et al., 2014; Li et al., 2009; Rao et al., 2015; Salakhutdinov et al., 2007). There are two main categories of conventional CF (based on the user-item rating matrix) which are memory-based and model-based CF algorithms. Memory-based CF predicts a user\u2019s rating on an item based on the entire or part of the user-item matrix. It can be subdivided into user-based and item-based CF. A typical userbased CF approach predicts the ratings of a user by aggregating the ratings of some similar users. User similarity is defined by a similarity metric, usually the cosine similarity or the Pearson correlation (Singhal, 2001). Many modifications and adjustments about the similarity metric have been proposed (Adomavicius and Singhal, 2005; Zhang and Pu, 2007). Item-based CF approaches predict the rating of an item for a user according to the ratings of items the user has given (Deshpande and Karypis, 2004).\nModel-based CF approaches use the user-item matrix to train prediction models and recommendations are generated from the prediction models (Ekstrand et al., 2011). For example, the mixture model learns the probability distribution of items in each clusters (Kleinberg and Sandler, 2008); Matrix factorization techniques learn latent factors of users and items from the user-item matrix and then use the low-rank approximation matrix to predict the score of unrated items; From probabilistic perspective, Salakhutdinov and Mnih (2008a) propose probabilistic matrix factorization framework. Considering about side information besides the user-item matrix, many works expand the CF paradigm (Basilico and Hofmann, 2004; Salakhutdinov et al., 2007; Li et al., 2009).\nHowever the two main categories of CF schemes are both vulnerable to attacks (Gunes et al., 2014; Ling et al., 2013). Increasing attention has been given to attack detection. Researchers have proposed several kinds of methods which can be mainly thought as statistical, clustering, classification and data reduction-based methods (Gunes et al., 2014). These methods mainly focus on shilling attacks where the attack organizer fakes a large number of user profiles by the same strategy to promote or demote a particular item. Statistical methods are used to detect anomalies who give suspicious ratings. Hurley et al. (2009) propose a Neyman-Pearson statistical attack detection method to distinguish attackers from normal users. Similarly, probabilistic Bayesian network models are used in Li and Luo (2011). Based on attributes derived from user profiles, classification methods (Mobasher et al., 2009) detect attacks by kNN, SVM, rough set theory, etc.\nAn unsupervised clustering algorithm based on several classification attributes (Bryan et al., 2008) is presented in Bhaumik et al. (2011). They apply k-means clustering based on these attributes and classify users in the smallest cluster as attackers. Instead of using traditional nearest neighbor methods, Mehta (2007) proposes a PLSA-based clustering method. Mehta and Nejdl (2009) propose the variable selection method, which treats users as variables and calculates their covariance matrix. By analyzing the principal components of the covariance matrix, those users with the smallest coefficient in the first l principal components are chosen in the final variable selection. Ling et al. (2013) try to predict the users\u2019 ratings by using a low-rank matrix factorization method and classify users with the lowest reputation as attackers.\nThese methods implement detection based on the attack strategy about how the fake user rating profiles are produced. When recommender systems are under unorganized malicious attacks, different attackers adopt different strategies to produce fake user rating profiles or hire existing users to attack. The traditional attack detection methods may be not suitable in this case."}, {"heading": "3. The Formulation", "text": "In this section, we introduce the general form of an attack profile, and then we give a detailed comparison of unorganized malicious attacks compared to shilling attacks. The formal definition of unorganized malicious attacks and the corresponding detection problem formulation are also presented."}, {"heading": "3.1 Notations", "text": "We begin with some notations used throughout this paper. Let \u2016X\u2016, \u2016X\u2016F and \u2016X\u2016\u2217 denote the operator norm, Frobenius norm and nuclear norm of matrix X, respectively. Let \u2016X\u20161 and \u2016X\u2016\u221e be the `1 and `\u221e norm of matrix X seen as vectors, respectively. Further, we define the Euclidean inner product between two matrices as \u3008X,Y \u3009 := trace(XY >), where Y > means the transposition of Y . Therefore, We have \u2016X\u20162F = \u3008X,X\u3009.\nLet P\u2126 denote an operator of linear transformation which acts on matrices space, and we also denote P\u2126 by the linear space of matrices supported on \u2126 when it is clear from the context. Then, P\u2126> represents the space of matrices supported on \u2126\nc. For an integer m, let [m] := {1, 2, . . . ,m}."}, {"heading": "3.2 Problem Formulation", "text": "The general form of an attack profile is shown in Figure 1 which is first defined by Bhaumik et al. (2006). the selected items, IS , are rated by the rating function \u03b4. The filler items of IF are seleted randomly and rated by the function \u03b8. The function \u03a5 determines the rating of the target item it. The remaining items are unrated.\nIn each kind of shilling attacks, the target item it is fixed; the number of rated items (k + l) is fixed; the rating functions are fixed. For example, in random attacks, the filler items IF are randomly chosen and the function \u03b8 gives IF the mean score of the system. In bandwagon attacks, the selected items IS are chosen from the popular items and the function gives IS a high score. The patterns of attack profiles are the same in each kind of\nshilling attack. Besides, the number of attack profiles requires to be large in the common settings of shilling attacks.\nHowever, in unorganized malicious attacks, the number of rated items, the target item and the rating functions are not constrained to be the same. Besides, we assume that each attackers produces a small number of attack profiles. The formal definition of unorganized malicious attacks is given in the following.\nLet U[m] = {U1, U2, . . . , Um} and I[n] = {I1, I2, . . . , In} denote m users and n items, respectively. Let X \u2208 Rm\u00d7n be the rating matrix. Xij denotes the score that user Ui gives item Ij without any attack or noise, i.e., Xij reflects the ground-truth feeling of user Ui on item Ij . Suppose that the highest score is Rmax, then 0 < X \u2264 Rmax. Throughout this work, we assume that X is a low-rank matrix as in classical matrix completion (Salakhutdinov and Mnih, 2008b). The intuition behind this assumption is that only a few factors influence users\u2019 preferences.\nUsually, the ground-truth matrix X may be corrupted by a system noisy matrix Z. For example, if Xij = 4.8 for i \u2208 [m], then, it is acceptable that user Ui gives item Ij score 5 or 4.6. In this paper, we consider the independent Gaussian noise, i.e., Z = (Zij)m\u00d7n where each element Zij is drawn i.i.d. from the Gaussian distribution N (0, \u03c3) with parameter \u03c3.\nLet M be the observed matrix which is corrupted by random noise and unorganized malicious attacks. We define an unorganized malicious attack with respect to a user set UK (K \u2282 [m]) if |K| \u2264 \u03b9 and |Mij \u2212Xij | \u2265 for some j \u2208 [n] and every i \u2208 K. The parameter \u03ba controls the number of users and parameter is used to distinguish malicious users from the normal. Intuitively, unorganized malicious attacks mean that attackers respectively use a small number of user profiles to attack their own targets.\nIt is necessary to distinguish unorganized malicious attacks from noise. Generally speaking, user Ui gives item Ij a normal score if |Mij \u2212Xij | is very small, while user Ui makes an attack to item Ij if |Mij \u2212Xij | > . For example, if the ground-truth score of item Ij is 4.9 for user Ui, then user Ui makes a noisy rating by giving Ij score 5, yet makes an attack by giving Ij score 2. Therefore, we assume that \u2016Z\u2016F \u2264 \u03b4, where \u03b4 is a small parameter.\nLet Y = M \u2212X \u2212Z = (Yij)m\u00d7n be the malicious-attack-score matrix. Then, Yij = 0 if user Ui does not attack item Ij , otherwise |Yij | \u2265 . We assume that Y is a sparse matrix, and the intuition behind this assumption is that each malicious user attacks a small number\nof items. Notice that we can not directly recover X and Y from M because such recovery is an NP-Hard problem (Cande\u0300s et al., 2011). We consider the following optimization problem.\nmin X,Y,Z\n\u2016X\u2016\u2217 + \u03c4\u2016Y \u20161 + \u03b1\u3008X,Y \u3009\ns.t. X + Y + Z = M,\n\u2016Z\u2016F \u2264 \u03b4,\n(1)\nwhere the term \u3008X,Y \u3009 is introduced to control the impact of Y in the nuke attack detection. The intuition behind this term is that the malicious rating bias Yij and the true rating Xij are always opposite in nuke attack, i.e. XijYij \u2264 0. So we need to minimize \u3008X,Y \u3009 to better distinguish sparse matrix Y and noisy matrix Z. The third term is \u03b1\u3008(X \u2212 Rmax), Y \u3009 in the push attack detection.\nIn many real applications, we can not get a full matrix M , and only partial entries can be observed. Let \u2126 \u2208 [m] \u00d7 [n] be the set of observed entries. We define an orthogonal projection P\u2126 onto the linear space of matrices supported on \u2126 \u2282 [m]\u00d7 [n] as follows.\nP\u2126M = { Mij for (i, j) \u2208 \u2126, 0 otherwise.\nOur final optimization framework for unorganized malicious nuke attack detection can be formulated as follows.\nmin X,Y,Z\n\u2016X\u2016\u2217 + \u03c4\u2016Y \u20161 + \u03b1\u3008X,Y \u3009\ns.t. P\u2126(X + Y + Z) = P\u2126M,\n\u2016P\u2126(Z)\u2016F \u2264 \u03b4.\n(2)\nThere have been many works (Cande\u0300s et al., 2011; Feng et al., 2013; Mackey et al., 2011; Peng et al., 2012) on recovering low-rank part X from complete or incomplete matrix. However, we pay more attention to distinguishing the sparse noise term Y from the small perturbation term Z. In order to find nonzero entries of Y , a new term \u3008X,Y \u3009 is added which leads to a more challenging optimization task and gets a much better performance. Further details about the proposed approach, theoretical analysis and experiments are explained below in Section 4, 5, 6."}, {"heading": "4. The Proposed Approach", "text": "It is rather difficult to optimize the formulations of Eqns. (1) and (2) with theoretical guarantees, because this optimization includes three-block non-convex programming with coupled objective function \u03b1\u3008X,Y \u3009. The difficulties lie in three hands: i) the objective function is non-convex due to the existence of coupled term; ii) the subgradients of the involved three functions are non-Lipschitz; and iii) there are three blocks variables involved. Therefore, we consider the following perturbation formulation inspired by Cai et al. (2010);\nCande\u0300s et al. (2011).\nmin X,Y,Z\n\u2016X\u2016\u2217 + \u03c4\u2016Y \u20161 + \u03b1\u3008X,Y \u3009+ \u03ba\n2 \u2016X\u20162F +\n\u03ba 2 \u2016Y \u20162F\ns.t. X + Y + Z = P\u2126M,\nZ \u2208 B, B := {Z|\u2016P\u2126(Z)\u2016F \u2264 \u03b4},\nwhere \u03ba > 0 is a regularization parameter. As \u03ba \u2192 0, this formulation degenerates into Eqn. (2). We further get the augmented Lagrangian function as follows.\nL(X,Y, Z,\u039b, \u03b2) :=\u2016X\u2016\u2217 + \u03c4\u2016Y \u20161 + \u03b1\u3008X,Y \u3009\n+ \u03ba\n2 \u2016X\u20162F +\n\u03ba 2 \u2016Y \u20162F \u2212 \u3008\u039b, L\u3009+ \u03b2 2 \u2016L\u20162F ,\nwhere L = X + Y + Z \u2212 P\u2126M and \u03b2 is a positive constant. It is noteworthy that there is a coupling term in our objective function, and some traditional algorithms (He et al., 2015; Tao and Yuan, 2011) can not be applied directly. We propose a proximal alternating splitting augmented Lagrangian method to solve this optimization, which inherits the advantages of ASALM (Tao and Yuan, 2011). We will provide global convergence guarantee for this algorithm in Section 5.\nMore specifically, let \u03b3 > 0 and (Xk, Y k,\u039bk) is given. We first update\nZk+1 = arg min Z\u2208B LA(Xk, Y k, Z,\u039bk, \u03b2),\nand it is easy to get the closed form solution\nZk+1ij = { min{1, \u03b4/\u2016P\u2126N\u2016F }Nij if (i, j) \u2208 \u2126 Nij otherwise.\n(3)\nwhere N = 1\u03b2\u039b k + P\u2126M \u2212Xk \u2212 Y k. Then, we update\nXk+1 = arg min X\u2208Rm\u00d7n LA(X,Y k, Zk+1,\u039bk, \u03b2) + \u03b3\u03b2\u2016X \u2212Xk\u20162F /2.\nLemma 2 gives the closed solution Xk+1 as\nD\u00b5(\u03b2\u00b5(P\u2126M + 1 \u03b2 \u039bk \u2212 Y k \u2212 Zk+1 \u2212 \u03b1 \u03b2 Y k + \u03b3Xk)), (4)\nwhere \u00b5 = 1/(\u03ba+ \u03b3\u03b2 + \u03b2) and D\u00b5 is defined by Lemma 2. Further, we update\nY k+1 = arg min Y \u2208Rm\u00d7n LA(Xk+1, Y, Zk+1,\u039bk, \u03b2).\nLemma 1 gives the closed form solution Y k+1 as\nS\u03c4\u03c5(\u03c5\u03b2(P\u2126M + 1\n\u03b2 \u039bk \u2212 Zk+1 \u2212Xk+1)\u2212 \u03c5\u03b1Xk+1), (5)\nwhere \u03c5 = 1/(\u03b2 + \u03ba) and S\u03c4\u03c5 is defined by Lemma 1. Finally, we update\n\u039bk+1 = \u039bk \u2212 \u03b2(Xk+1 + Y k+1 + Zk+1 \u2212 P\u2126M). (6)\nThe pseudocode of the proposed UMA method is given in Algorithm 1.\nAlgorithm 1 The UMA Algorithm\nInput: matrix M and parameters \u03c4 , \u03b1, \u03b2, \u03b4, \u03ba and \u03b3. Output: Label vector [y1, . . . , ym] where yi = 1 if user Ui is a malicious user; otherwise yi = 0. Initialize: Y 0 = X0 = \u039b0 = 0, yi = 0 (i = 1, . . . ,m), k = 0 Process:\n1: while not converged do 2: Compute Zk+1 by Eqn. (3). 3: Compute Xk+1 by Eqn. (4). 4: Compute Y k+1 by Eqn. (5). 5: Update the Lagrange multiplier \u039bk+1 by \u039bk \u2212 \u03b2(Xk+1 + Y k+1 + Zk+1 \u2212 P\u2126M). 6: k = k + 1. 7: end while 8: if max(|Yi,:|) > 0, then yi = 1 (i = 1, . . . ,m)."}, {"heading": "5. Theoretical Analysis", "text": "In this section, we first prove that attacks can be detected theoreteically. Then we give a convergence analysis of our algorithm UMA and prove its global convergence."}, {"heading": "5.1 Detection Guarantees", "text": "We begin with two useful lemmas for the deviation of our proposed algorithms as follows.\nLemma 1 (Bruckstein et al., 2009) For \u03c4 > 0 and T \u2208 Rm\u00d7n, the closed solution of minY \u03c4\u2016Y \u20161 + \u2016Y \u2212 T\u20162F /2 is given by matrix S\u03c4 (T ) with (S\u03c4 (T ))ij = max{|Tij | \u2212 \u03c4, 0} \u00b7 sgn(Tij), where sgn(\u00b7) means the sign function.\nLemma 2 (Cai et al., 2010) For \u00b5 > 0 and Y \u2208 Rm\u00d7n with rank r, the closed solution of minX \u00b5\u2016X\u2016\u2217 + \u2016X \u2212 Y \u20162F /2 is given by\nD\u00b5(Y ) = Sdiag(S\u00b5(\u03a3))D>\nwhere Y = S\u03a3D> denotes the singular value decomposition of Y , and S\u00b5(\u03a3) is defined in Lemma 1.\nFor simplicity, our theoretical analysis focuses on square matrix, and it is easy to generalize our results to the general rectangular matrices. Let the singular value decomposition of X0 \u2208 Rn\u00d7n be given by\nX0 = S\u03a3D > = \u2211r i=1 \u03c3isid > i\nwhere r is the rank of matrix X0, \u03c31, . . . , \u03c3r are the positive singular values, and S = [s1, . . . , sr] and D = [d1, . . . , dr] are the left- and right-singular matrices, respectively. For \u00b5 > 0, we assume\nmax i \u2016S>ei\u20162 \u2264 \u00b5r/n,\nmax i \u2016D>ei\u20162 \u2264 \u00b5r/n, (7)\n\u2016SD>\u20162\u221e \u2264 \u00b5r/n2.\nWe now present our first main result as follows.\nTheorem 3 Suppose that the support set of Y0 be uniformly distributed for all sets of cardinality k, and X0 satisfies the incoherence condition given by Eqn. (7). Let X and Y be the solution of optimization problem given by Eqn. (1) with parameter \u03c4 = O(1/ \u221a n) and \u03b1 = O(1/n). For some constant c > 0 and sufficiently large n, the following holds with probability at least 1\u2212 cn\u221210 over the choice on the support of Y0\n\u2016X0 \u2212X\u2016 \u2264 \u03b4 and \u2016Y0 \u2212 Y \u2016F \u2264 \u03b4\nif rank(X0)\u2264 \u03c1rn/\u00b5/log2n and k \u2264 \u03c1sn2, where \u03c1r and \u03c1s are positive constant.\nProof Let \u2126 be the space of matrices with the same support as Y0, and let T denote the linear space of matrices\nT := {SX\u2217 + Y D\u2217, X, Y \u2208 Rn\u00d7r}.\nWe will first prove that, for \u2016P\u2126PT \u2016 \u2264 1/2, (X0, Y0) is the unique solution if there is a pair (W,F ) satisfying\nSD\u2217 +W = \u03c4(sgn(Y0) + F + P\u2126K) (8)\nwhere PTW = 0 and \u2016W\u2016 \u2264 1/2, P\u2126F = 0 and \u2016F\u2016\u221e \u2264 1/2 and \u2016P\u2126K\u2016F \u2264 1/4. Notice that SD\u2217 + W0 + \u03b1Y0 is an arbitrary subgradient of \u2016X\u2016\u2217 + \u03b1\u3008X,Y \u3009 at (X0, Y0), and \u03c4(sgn(Y0) +F0) +\u03b1X0 is an arbitrary subgradient of \u03c4\u2016Y \u20161 +\u03b1\u3008X,Y \u3009 at (X0, Y0). For any matrix H, we have, by the definition of subgradient,\n\u2016X +H\u2016\u2217 + \u03c4\u2016Y \u2212H\u20161 + \u03b1\u3008X +H,Y \u2212H\u3009 \u2265 \u2016X0\u2016\u2217 + \u03c4\u2016Y0\u20161 + \u03b1\u3008X0, Y0\u3009+ \u03b1\u3008Y0 \u2212X0, H\u3009\n+\u3008SD\u2217 +W0, H\u3009 \u2212 \u03c4\u3008sgn(Y0) + F0, H\u3009. (9)\nBy setting W0 and F0 satisfying \u3008W0, H\u3009 = \u2016PT\u22a5H\u2016\u2217 and \u3008F0, H\u3009 = \u2212\u2016P\u2126\u22a5H\u20161, we have\n\u3008SD\u2217 +W0, H\u3009 \u2212 \u03c4\u3008sgn(Y0) + F0, H\u3009 = \u2016PT\u22a5H\u2016\u2217 + \u03c4\u2016P\u2126\u22a5H\u20161 + \u3008SD\u2217 \u2212 \u03c4sgn(Y0), H\u3009 = \u2016PT\u22a5H\u2016\u2217 + \u03c4\u2016P\u2126\u22a5H\u20161 + \u3008\u03c4(F + P\u2126K)\u2212W,H\u3009\n\u2265 1 2 (\u2016PT\u22a5H\u2016\u2217 + \u03c4\u2016P\u2126\u22a5H\u20161) + \u03c4\u3008P\u2126D,H\u3009 (10)\nwhere the second equality holds from Eqn. (8), and the last inequality holds from\n\u3008\u03c4F \u2212W,H\u3009 \u2265 \u2212|\u3008W,H\u3009| \u2212 |\u3008\u03c4F,H\u3009| \u2265 \u2212(\u2016PT\u22a5H\u2016\u2217 + \u03c4\u2016P\u2126\u22a5H\u20161)/2\nfor \u2016W\u2016 \u2264 1/2 and \u2016F\u2016\u221e \u2264 1/2. We further have\n\u3008\u03c4P\u2126K,H\u3009 \u2265 \u2212 \u03c4\n4 \u2016P\u2126\u22a5H\u2016F \u2212\n\u03c4 2 \u2016PT\u22a5H\u2016F (11)\nfrom \u2016P\u2126K\u2016F \u2264 1/4 and\n\u2016P\u2126H\u2016F \u2264 \u2016P\u2126PTH\u2016F + \u2016P\u2126PT\u22a5H\u2016F \u2264 \u2016P\u2126PT\u22a5H\u2016F + \u2016H\u2016F /2 \u2264 (\u2016P\u2126H\u2016F + \u2016P\u2126\u22a5H\u2016F )/2 + \u2016P\u2126PT\u22a5H\u2016F .\nCombing with Eqns. (9) to (11), we have\n\u2016X +H\u2016\u2217 + \u03c4\u2016Y \u2212H\u20161 + \u03b1\u3008X +H,Y \u2212H\u3009 \u2265 \u2016X0\u2016\u2217 + \u03c4\u2016Y0\u20161 + \u03b1\u3008X0, Y0\u3009+ \u03b1\u3008Y0 \u2212X0, H\u3009\n+ 1\u2212 \u03c4\n2 \u2016PT\u22a5H\u2016\u2217 +\n\u03c4 4 \u2016P\u2126\u22a5H\u20161\nFrom the conditions that \u2126 \u2229 T = {0}, \u03c4 = O(1/ \u221a n) and \u03b1 = O(1/n), we have\n\u03b1\u3008Y0 \u2212X0, H\u3009+ 1\u2212 \u03c4\n2 \u2016PT\u22a5H\u2016\u2217 +\n\u03c4 4 \u2016P\u2126\u22a5H\u20161 > 0\nfor sufficient large n. Therefore, we can recover X0 and Y0 if there is a pair (W,F ) satisfying Eqn. (8), and the pair (W,F ) can be easily constructed according to Cande\u0300s et al. (2011). We complete the proof from the condition \u2016Z\u2016F \u2264 \u03b4.\nSimilarly to the proof of Theorem 3, we present the following theorem for the minimization problem of Eqn. (2).\nTheorem 4 Suppose that X0 satisfies the incoherence condition given by Eqn. (7), and \u2126 is uniformly distributed among all sets of size m \u2265 n2/10. We assume that each entry is corrupted independently with probability \u03c4 . Let X and Y be the solution of optimization problem given by Eqn. (2) with parameter \u03c4 = O(1/ \u221a n) and \u03b1 = O(1/n). For some constant c > 0 and sufficiently large n, the following holds with probability at least 1\u2212cn\u221210\n\u2016X0 \u2212X\u2016F \u2264 \u03b4 and \u2016Y0 \u2212 Y \u2016F \u2264 \u03b4\nif rank(X0)\u2264 \u03c1rn/\u00b5/log2n and \u03c4 \u2264 \u03c1s, where \u03c1r and \u03c1s are positive constants."}, {"heading": "5.2 Convergence Analysis", "text": "Before starting to show the convergence, we derive its optimality condition of (3). LetW := B\u00d7Rm\u00d7n\u00d7Rm\u00d7n\u00d7Rm\u00d7n. It follows from Corollaries 28.2.2 and 28.3.1 of Rockafellar (1970) that the solution set of (3) is non-empty. Then, let W \u2217 = ((Z\u2217)>, (X\u2217)>, (Y \u2217)>, (\u039b\u2217)>)> be a saddle point of (3). It is easy to see that (3) is equivalent to finding W \u2217 \u2208 W such that \u2200 W = (Z>, X>, Y >,\u039b>)> \u2208 W, (Z \u2212 Z\u2217)>(\u2212\u039b\u2217) \u2265 0, \u2016X\u2016\u2217 \u2212 \u2016X\u2217\u2016\u2217 + (X \u2212X\u2217)>(\u03baX\u2217 + \u03b1Y \u2217 \u2212 \u039b\u2217) \u2265 0, \u03c4\u2016Y \u20161 \u2212 \u03c4\u2016Y \u2217\u20161 + (Y \u2212 Y \u2217)>(\u03b1X\u2217 + \u03baY \u2217 \u2212 \u039b\u2217) \u2265 0, X\u2217 + Y \u2217 + Z\u2217 \u2212M = 0, (12)\nor, in a more compact form VI(W,\u03a8, \u03b8),\n\u03b8(U)\u2212 \u03b8(U\u2217) + (W \u2212W \u2217)>\u03a8(W \u2217) \u2265 0, \u2200 W \u2208 W, (13a)\nwhere\nU =  ZX Y  , \u03b8(U) = \u2016X\u2016\u2217 \u2212 \u2016X\u2217\u2016\u2217 + \u03c4\u2016Y \u20161 \u2212 \u03c4\u2016Y \u2217\u20161, (13b)\nand W =  Z X Y \u039b  , V =  XY \u039b  , \u03a8(W ) =  \u2212\u039b \u03baX + \u03b1Y \u2212 \u039b \u03b1X + \u03baY \u2212 \u039b X + Y + Z \u2212M  . (13c) Note that U collects all the primal variables in (12) and it is a sub-vector of W . Moreover, we use W\u2217 to denote the solution set of VI(W,\u03a8, \u03b8) and define V \u2217 = ((X\u2217)>, (Y \u2217)>, (\u039b\u2217)>)> and V\u2217 := {V \u2217|W \u2217 \u2208 W}.\nRemark 5 Note there is a coupling term in the objective function of the problem (3). The VASALM in Tao and Yuan (2011); He et al. (2015) can not be applied directly. Because, the splitting methods developed in Tao and Yuan (2011); He et al. (2015) with global convergence aims to solve the separable convex programming. Therefore, these existing methods can not be applied to solve problem (3) with global convergence. Hence, we propose a new splitting method, i.e., UMA which aims to solve the problem (3) with coupling objective function. Moreover, UMA inherits the advantage of ASALM in Tao and Yuan (2011), i.e., it updates three blocks variables Z, X and Y in Gauss-Seidel manner. The proximal term introducing in X-subproblem is to ensure the global convergence of UMA.\nIn the following, we concentrate on the convergence of the proposed UMA. We first prove some properties of the sequence generated by the proposed UMA, which play crucial roles in the coming convergence analysis.\nLemma 6 Let {W k} be generated by UMA. Then, we have the following inequality:\n\u03b8(Uk+1)\u2212 \u03b8(U\u2217) + (W k+1 \u2212W \u2217)>\u03a8(W k+1) \u2265 (\u03ba\u2212 \u03b1)(\u2016Xk+1 \u2212X\u2217\u20162F + \u2016Y k+1 \u2212 Y \u2217\u20162F ). (14)\nProof First, due to (13c), we have\n(\u2206W )>(\u03a8(W k+1)\u2212\u03a8(W \u2217))\n= (\u2206W )>  0 0 0 \u2212I 0 \u03baIm \u03b1Im \u2212I 0 \u03b1Im \u03baIm \u2212I I I I 0  (\u2206W ) \u2265 (\u03ba\u2212 \u03b1)(\u2016Xk+1 \u2212X\u2217\u20162F + \u2016Y k+1 \u2212 Y \u2217\u20162F ), (15)\nwhere \u2206W = W k+1 \u2212W \u2217. Consequently,\n\u03b8(Uk+1)\u2212 \u03b8(U\u2217) + (W k+1 \u2212W \u2217)>\u03a8(W k+1) = \u03b8(Uk+1)\u2212 \u03b8(U\u2217) + (W k+1 \u2212W \u2217)>\u03a8(W \u2217)\n+(W k+1 \u2212W \u2217)>(\u03a8(W k+1)\u2212\u03a8(W \u2217)) \u2265 (W k+1 \u2212W \u2217)>(\u03a8(W k+1)\u2212\u03a8(W \u2217)) \u2265 (\u03ba\u2212 \u03b1)(\u2016Xk+1 \u2212X\u2217\u20162F + \u2016Y k+1 \u2212 Y \u2217\u20162F ).\nThe first and the second inequalities follow from (13a), (15), respectively. Thus, the conclusion follows directly.\nLemma 7 Let {W k} be generated by UMA. Then, we have the following inequality:\n\u03b8(U)\u2212 \u03b8(Uk+1) + (W \u2212W k+1)>\u03a8(W k+1)\n+(W \u2212W k+1)>  \u03b2[Xk \u2212Xk+1 + Y k \u2212 Y k+1] \u03b2[Xk \u2212Xk+1 + Y k \u2212 Y k+1] \u03b2[Xk \u2212Xk+1 + Y k \u2212 Y k+1]\n0  \u2265 \u3008V \u2212 V k+1, G\u0303(V k \u2212 V k+1)\u3009, \u2200W \u2208 W. (16)\nwhere the matrix\nG\u0303 =  (\u03b3 + 1)\u03b2Im \u2212\u03b1Im 0\u03b2Im \u03b2Im 0 0 0 1\u03b2 Im  . (17) Proof First, based on the optimal condition (12) and the update scheme of \u039bk+1, we have \u3008\u2212\u039bk+1 + \u03b2[Xk \u2212Xk+1 + Y k \u2212 Y k+1], Z \u2212 Zk+1\u3009 \u2265 0; \u2016X\u2016\u2217 \u2212 \u2016Xk+1\u2016\u2217 + \u3008X \u2212Xk+1, \u03b1Y k + \u03baXk+1 \u2212\u039bk+1 + \u03b2(Y k \u2212 Y k+1) + \u03b3\u03b2(Xk+1 \u2212Xk)\u3009 \u2265 0; \u03c4\u2016Y \u20161 + \u3008Y \u2212 Y k+1, \u03b1Xk+1 + \u03baY k+1 \u2212 \u039bk+1\u3009 \u2212 \u03c4\u2016Y k+1\u20161 \u2265 0; \u3008Xk+1 + Y k+1 + Zk+1 \u2212M \u2212 1\u03b2 (\u039b k \u2212 \u039bk+1),\u039b\u2212 \u039bk+1\u3009 \u2265 0; \u2200W \u2208 W. (18)\nConsequently, \u3008\u2212\u039bk+1 + \u03b2[Xk \u2212Xk+1 + Y k \u2212 Y k+1], Z \u2212 Zk+1\u3009 \u2265 0; \u2016X\u2016\u2217 \u2212 \u2016Xk+1\u2016\u2217 + \u3008X \u2212Xk+1, \u03b1Y k+1 + \u03baXk+1 \u2212 \u039bk+1\u3009+ \u3008X \u2212Xk+1, (1 + \u03b3)\u03b2(Xk+1 \u2212Xk) + \u03b2(Xk \u2212Xk+1 + Y k \u2212 Y k+1)\u3009 \u2265 0; \u03c4\u2016Y \u20161 + \u3008Y \u2212 Y k+1, \u03b1Xk+1 + \u03baY k+1 \u2212 \u039bk+1\u3009 \u2212 \u03c4\u2016Y k+1\u20161 \u2265 0; \u3008Xk+1 + Y k+1 + Zk+1 \u2212M \u2212 1\u03b2 (\u039b k \u2212 \u039bk+1),\u039b\u2212 \u039bk+1\u3009 \u2265 0;\n\u2200W \u2208 W.\nFinally, combining the definitions of matrix G\u0303 in (17), \u03b8(U) in (13b) and \u03a8(W ) in (13c), the assertion follows directly.\nIn the following, we show another important property of UMA.\nLemma 8 Let {W k} be generated by UMA. Then, it holds that\n\u3008Y k \u2212 Y k+1, \u03b1(Xk \u2212Xk+1)\u3009+ \u03ba\u2016Y k \u2212 Y k+1\u20162F \u2264 \u3008\u039bk \u2212 \u039bk+1, Y k \u2212 Y k+1\u3009. (19)\nProof By setting Y = Y k in the third inequality of (18) we get\n\u03c4\u2016Y k\u20161 \u2212 \u03c4\u2016Y k+1\u20161 + \u3008Y k \u2212 Y k+1, \u03b1Xk+1 + \u03baY k+1 \u2212 \u039bk+1\u3009 \u2265 0.\nSimilarly, taking k := k \u2212 1 and Y = Y k+1 in the third inequality of (18) we have\n\u03c4\u2016Y k+1\u20161 \u2212 \u03c4\u2016Y k\u20161 + \u3008Y k+1 \u2212 Y k, \u03b1Xk + \u03baY k \u2212 \u039bk\u3009 \u2265 0.\nBy adding the above two inequalities, we complete the proof.\nTheorem 9 Let {W k} be generated by UMA. Assume that \u03b1 < 1 in model (3) and \u03b2 > 0, \u03b3 > 0 in Algorithm (1). Then, we have the following contractive property:\n\u2016V k+1 \u2212 V \u2217\u20162G \u2264 \u2016V k \u2212 V \u2217\u20162G \u2212\u2206k+1, (20)\nwhere\n\u2206k+1 := 1 2\u03b2 \u2016\u039bk \u2212 \u039bk+1\u20162F + 2\u2016Y k \u2212 Y k+1\u20162F + \u03b6\u2016Xk \u2212Xk+1\u20162F , (21)\n\u03b6 =\n( \u03b3 + 1\n2 \u03b2 \u2212 \u03b2 2(1\u2212 1) \u2212 \u03b1\n4(\u03b22 + \u03ba\u2212 \u03b1 4(\u03ba\u2212\u03b1) \u2212 2) \u2212 \u03b2\n2\n4(\u03ba\u2212 \u03b1)\n) ,\nand the matrix\nG =  (\u03b3 + 1)\u03b2Im 0 00 \u03b2Im 0 0 0 1\u03b2 Im  , and the positive scalars 1,2 are sufficient small.\nProof First, note that\n\u2329 W \u2217 \u2212W k+1,  \u03b2[Xk \u2212Xk+1 + Y k \u2212 Y k+1] \u03b2[Xk \u2212Xk+1 + Y k \u2212 Y k+1] \u03b2[Xk \u2212Xk+1 + Y k \u2212 Y k+1]\n0\n \u232a\n= \u3008M \u2212Xk+1 \u2212 Y k+1 \u2212 Zk+1, \u03b2[Xk \u2212Xk+1 + Y k \u2212 Y k+1]\u3009 = \u3008\u039bk+1 \u2212 \u039bk, Xk \u2212Xk+1 + Y k \u2212 Y k+1\u3009. (22)\nThe first and second equalities follows from X\u2217+ Y \u2217+Z\u2217\u2212M = 0 and the \u039bk+1-updating scheme of (6). Then, by setting W = W \u2217 in inequality (16) we get\n0 \u2265 \u03b8(Uk+1)\u2212 \u03b8(U\u2217) + (W k+1 \u2212W \u2217)>\u03a8(W k+1)\n+ \u2329 W k+1 \u2212W \u2217,  \u03b2[Xk \u2212Xk+1 + Y k \u2212 Y k+1] \u03b2[Xk \u2212Xk+1 + Y k \u2212 Y k+1] \u03b2[Xk \u2212Xk+1 + Y k \u2212 Y k+1]\n0\n \u232a\n+\u3008V \u2217 \u2212 V k+1, G\u0303(V k \u2212 V k+1)\u3009 \u2265 (\u03ba\u2212 \u03b1)\u2016Xk+1 \u2212X\u2217\u20162F + (\u03ba\u2212 \u03b1)\u2016Y k+1 \u2212 Y \u2217\u20162F\n+\u3008V \u2217 \u2212 V k+1, G\u0303(V k \u2212 V k+1)\u3009 (23) +\u3008\u039bk \u2212 \u039bk+1, Xk \u2212Xk+1 + Y k \u2212 Y k+1\u3009.\nThe last inequality follows from (14) and (22). Next, we analyze the right hand side of (23). Due to (19) and the definitions of matrices G\u0303 (17) and G (9), we have\n(\u03ba\u2212 \u03b1)\u2016Xk+1 \u2212X\u2217\u20162F + (\u03ba\u2212 \u03b1)\u2016Y k+1 \u2212 Y \u2217\u20162F + \u3008V \u2217 \u2212 V k+1, G\u0303(V k \u2212 V k+1)\u3009 +\u3008\u039bk \u2212 \u039bk+1, Xk \u2212Xk+1 + Y k \u2212 Y k+1\u3009\n\u2265 (\u03ba\u2212 \u03b1)\u2016Xk+1 \u2212X\u2217\u20162F + (\u03ba\u2212 \u03b1)\u2016Y k+1 \u2212 Y \u2217\u20162F +\u3008\u039bk \u2212 \u039bk+1, Xk \u2212Xk+1\u3009+ \u3008Y k \u2212 Y k+1, \u03b1(Xk \u2212Xk+1)\u3009 +\u03ba\u2016Y k \u2212 Y k+1\u20162F + \u3008V \u2217 \u2212 V k+1, G(V k \u2212 V k+1) (24) +\u03b2\u3008Y \u2217 \u2212 Y k+1, Xk \u2212Xk+1\u3009 \u2212 \u03b1\u3008X\u2217 \u2212Xk+1, Y k \u2212 Y k+1\u3009\u3009.\nOn the other hand, we have the following identity:\n\u3008V \u2217 \u2212 V k+1, G(V k \u2212 V k+1)\u3009\n= 1\n2 \u2016V k+1 \u2212 V \u2217\u20162G \u2212\n1 2 \u2016V k \u2212 V \u2217\u20162G + 1 2 \u2016V k+1 \u2212 V k\u20162G. (25)\nFrom the definition (9), the matrix G is positive definite matrix. Then, using Cauchy-Schwarz inequalities, we have\n\u03b2\u3008Y \u2217 \u2212 Y k+1, Xk \u2212Xk+1\u3009 \u2265 (\u03b1\u2212 \u03ba)\u2016Y k+1 \u2212 Y \u2217\u20162F \u2212 \u03b22\n4(\u03ba\u2212 \u03b1) \u2016Xk \u2212Xk+1\u20162F ,\n\u3008Y k \u2212 Y k+1, \u03b1(Xk \u2212Xk+1)\u3009 \u2265 \u2212(\u03b2 2 + \u03ba\u2212 \u03b1 4(\u03ba\u2212 \u03b1) \u2212 2)\u2016Y k \u2212 Y k+1\u20162F\n\u2212 \u03b1 4(\u03b22 \u2212 \u03b1 4(\u03ba\u2212\u03b1) + \u03ba\u2212 2) \u2016Xk \u2212Xk+1\u20162F ,\n\u3008\u039bk \u2212 \u039bk+1, Xk \u2212Xk+1\u3009 \u2265 \u22121\u2212 1 2\u03b2 \u2016\u039bk \u2212 \u039bk+1\u20162F \u2212\n\u03b2\n2(1\u2212 1) \u2016Xk \u2212Xk+1\u20162,\n\u2212\u03b1\u3008X\u2217 \u2212Xk+1, Y k \u2212 Y k+1\u3009 \u2265 \u2212(\u03ba\u2212 \u03b1)\u2016Xk+1 \u2212X\u2217\u20162 \u2212 \u03b1 4(\u03ba\u2212 \u03b1) \u2016Y k \u2212 Y k+1\u20162F .\nwhere 1,2 > 0. Note the last inequality uses \u03b1 < 1. Then, substituting the above four inequalities and (25) into the right-hand-side of (24),\nwe get\n(\u03ba\u2212 \u03b1)\u2016Xk+1 \u2212X\u2217\u20162F + (\u03ba\u2212 \u03b1)\u2016Y k+1 \u2212 Y \u2217\u20162F + \u3008V \u2217 \u2212 V k+1, G\u0303(V k \u2212 V k+1)\u3009 +\u3008\u039bk \u2212 \u039bk+1, Xk \u2212Xk+1 + Y k \u2212 Y k+1\u3009 \u2265 \u2206k+1 + 1\n2 \u2016V k+1 \u2212 V \u2217\u20162G \u2212\n1 2 \u2016V k \u2212 V \u2217\u20162G.\nFinally, combing the above inequality and (23), the inequality (20) follows directly.\nBased on the above theorem, we have the following corollary immediately.\nTheorem 10 Let the sequence {V k} be generated by the proposed UMA. Assume that\n\u03ba > \u03b1 and \u03ba2 \u2212 \u03b1\u03ba\u2212 \u03b1 4 < 0. (26)\n\u03b2 \u2208 ( 0, (\u03ba\u2212 \u03b1)\u03b3 + (\u03ba\u2212 \u03b1) \u221a \u03b32 \u2212 4\u03b1\n\u03ba2 \u2212 \u03b1\u03ba\u2212 \u03b14\n) . (27)\nThen, we have\n1. The sequence {V k} is bounded.\n2. limk\u2192\u221e{\u2016Y k \u2212 Y k+1\u20162F + \u2016Xk \u2212Xk+1\u20162F + \u2016\u039bk \u2212 \u039bk+1\u20162F } = 0.\nProof The first assertion follows from (20) directly. We now prove the second assertion. Since \u03ba > \u03b1 and \u03b2 is satisfied with (27), and 1,2 \u2192 0+, it holds that\n\u03b3 + 1 2 \u03b2 \u2212 \u03b2 2(1\u2212 1) \u2212 \u03b1\n4(\u03b22 + \u03ba\u2212 \u03b1 4(\u03ba\u2212\u03b1) \u2212 2) \u2212 \u03b2\n2\n4(\u03ba\u2212 \u03b1) > 0.\nConsequently, \u2206k+1 \u2265 0, where \u2206k+1 is defined in (21). Then, it follows from (20) that \u221e\u2211 k=0 \u2206k+1 \u2264 \u2016V 0 \u2212 V \u2217\u20162G < +\u221e,\nwhich immediately implies that\nlim k\u2192\u221e\n\u2016Y k \u2212 Y k+1\u2016F = 0,\nlim k\u2192\u221e\n\u2016Xk \u2212Xk+1\u2016F = 0, (28)\nlim k\u2192\u221e\n\u2016\u039bk \u2212 \u039bk+1\u2016F = 0,\ni.e., the second assertion.\nWe are now ready to prove the convergence of the proposed UMA.\nTheorem 11 Let {V k} and {W k} be the sequences generated by the proposed UMA. Assume that the model\u2019s parameters \u03b1, \u03ba are satisfies with (26) and the penalty parameter \u03b2 is satisfied with (27). Then, we have\n1. Any cluster point of {W k} is a solution point of (12).\n2. The sequence {V k} converges to some V\u221e \u2208 V\u2217.\n3. The sequence {Uk} converges to a solution point of (3).\nProof Because of the assertion (28), it follows from (16) that\n\u03b8(U)\u2212 \u03b8(Uk+1) + (W \u2212W k+1)>\u03a8(W k+1) \u2265 0, \u2200W = (Z>, X>, Y >,\u039b>)> \u2208 W. (29)\nWe also have \u03b8(U)\u2212 \u03b8(Uk) + (W \u2212W k)>\u03a8(W k) \u2265 0, \u2200W = (Z>, X>, Y >,\u039b>)> \u2208 W. Since {W k} is bounded, it has at least one cluster point. Let W\u221e be a cluster point of {W k} and the subsequence {W kj} converges to W\u221e. It follows from (29) that\nlimj\u2192\u221e\u03b8(U)\u2212 \u03b8(Ukj ) + (W \u2212W kj )>\u03a8(W kj ) \u2265 0, \u2200W = (Z>, X>, Y >,\u039b>)> \u2208 W.\nThis means that W\u221e is a solution of VI(W,\u03a8, \u03b8). Then the inequality (20) is also valid if V \u2217 is replaced by V\u221e. Therefore, the non-increasing sequence \u2016V k \u2212 V\u221e\u20162G converges to 0 since V\u221e is a cluster point of {V k}.\nAlso, the updating scheme of \u039bk+1 in (6) implies that\nZk+1 = M \u2212Xk+1 \u2212 Y k+1 + 1 \u03b2 (\u039bk \u2212 \u039bk+1).\nCombining the above equality, (28) and limk\u2192\u221e \u2016V k \u2212 V\u221e\u20162G = 0, we have W k converges to W\u221e. It implies that the sequence Uk converges to a solution point of (3). Thus, the third assertion holds."}, {"heading": "6. Experiments", "text": "In this section, we compare our proposed approach UMA with the state-of-the art approaches for attack detection.\nTo evaluate the performance of these methods, we use attacks detection precision, recall and F1 as the performance measures. These performance measures can be calculated as follows (Gunes et al., 2014),\nPrecision = #true postives\n#true postives + #false positives\nRecall = #true postives\n#true postives + #false negatives\nF1 = 2\u00d7 precision\u00d7 recall\nprecision + recall\nin which # true positives is the number of attack profiles correctly detected, # false positives is the number of misclassified normal profiles, and # false negatives is the number of attack profiles that are missed."}, {"heading": "6.1 Datasets", "text": "We first conduct our experiments on the common-used datasets MovieLens 100K and MovieLens 1M collected and released by GroupLens.3 The rating scores are integers from 1 to 5, where 1 and 5 are the worst and best, respectively. Dataset MovieLens 100K contains 100000 ratings of 943 users over 1682 movies, and Dataset MovieLens 1M contains 1000209 ratings of 6040 users over 3706 movies. It is noteworthy that those datasets do not contain attackers and we have to add simulation attack profiles, which will be discussed in Section 6.3.\nWe also collect a real dataset Douban 10K with 35 attack profiles identified by the Douban website, where registered users record rating information over various films, books, clothes, etc.4 We gather 12095 ratings of 213 users over 155 items, where rating scores are integers from 1 to 5. Among all the 213 user profiles, 35 profiles are attack profiles."}, {"heading": "6.2 Comparison Methods and Implementation Details", "text": "We compare with the state-of-the-art approaches for attack detection and robust PCA as follows.\n\u2022 N-P: A statistical algorithm which identifies attack profiles based on the NeymanPearson statistics (Hurley et al., 2009).\n\u2022 k-means: A cluster algorithm based on classification attributes (Bhaumik et al., 2011).\n\u2022 PCAVarSel: A PCA-based variable selection algorithm by computing covariance between users to locate malicious users (Mehta and Nejdl, 2009).\n\u2022 MF-based: A matrix factorization algorithm by computing the reputation scores among users (Ling et al., 2013).\n\u2022 RPCA: A low-rank matrix recovery method considering sparse and small perturbation noise (Cande\u0300s et al., 2011). In our experiments, we set \u03c4 = 10/ \u221a m and \u03b1 = 10/m. A rating can be viewed as malicious rating if the deviation is greater than 3 from the ground-truth rating since the scale of rating in our systems is between 1 and 5; therefore, we set parameter \u03b2 = \u03c4/3 as the entries of Y will be nullified if they are smaller than \u03c4/\u03b2 according to Eqn. (5). We finally select \u03b4 = \u221a mn/200. We use the power method (Halko et al., 2011) to approximate Eqn. (4) so that our method has the same scalability as the power method."}, {"heading": "6.3 Comparison Results", "text": "As mentioned before, the datasets MovieLens 100K and MovieLens 1M do not contain attackers; therefore, we first use a combination of several traditional attack strategies to construct the datasets with unorganized malicious attacks. These traditional attack strategies include average attack strategy, random attack strategy and bandwagon attack strategy (Lam and\n3. http://grouplens.org/datasets/movielens/. 4. http://www.douban.com/.\nRiedl, 2004). Here, each attacker randomly chooses one strategy to fake the user rating profiles and promote one item whose average rating is lower than 2. In line with the setting of previous attack detection works, we set the filler ratio (percentage of rated items in total items) as 0.01 and the filler items are drawn from the top 10% most popular items. We set the spam ratio (number of attack profiles/number of all user profiles) as 0.2. Table 6.3 shows the experimental results on datasets MovieLens 100K and MovieLens 1M which are under unorganized malicious attacks based on a combination of traditional strategies.\nBesides inserting new user profiles into the rating matrix, attackers can hire existing users to attack. We reconstruct datasets from MovieLens 100K and MovieLens 1M as follows. We set the filler ratio as 0.01, and the filler items are drawn from the top 10% most popular items. Most attack profiles (75%) are generated by i) randomly selecting an item with average rating lower than 2, ii) randomly selecting a user profile with a rating lower than 2 to the chosen item, and iii) the selected user profile can be viewed as an attack profile by modifying the rating to 5. The other attack profiles (25%) are produced similar to that of the above paragraph. Table 6.3 demonstrates the comparison results on the simulated datasets from MovieLens 100K and MovieLens 1M.\nTable 6.3 shows the experiments on dataset Douban 10K. The experimental results in Table 6.3, 6.3, 6.3 show that our proposed UMA approach achieves the best performance on three measures: Precision, Recall and F1, and our approach takes superiority in all\ndatasets. It is easy to observe that traditional attack detection approaches fail to work for unorganized malicious attacks, because those methods depend on the properties of shilling attacks, e.g., the k-means method and N-P method work if the attack profiles are similar in the view of the supervised features or their latent categories, and the PCAVarSel method achieves good performance only if attack profiles have more common unrated items than normal profiles. However, those good properties do not exist in the unorganized malicious attacks.\nThe RPCA and MF-based methods try to find the ground-truth matrix from the observed matrix, whereas they hardly separate the sparse attack matrix from the noisy matrix, and tend to suffer from low precision, especially on large-scale and heavily sparse datasets.\nSince different systems may contain different spam ratios (number of attack profiles/number of all user profiles), we compare our UMA algorithm with other methods by varying the spam ratio from 2% to 20% in Figure 2. Our UMA approach always gets robust and better performance in different spam ratios, whereas the comparison methods (except the RPCA method) achieve worse performance for small spam ratio, e.g., the N-P approach detects almost nothing. Although the RPCA method is as stable as our method UMA in different spam ratios, there is a performance gap between RPCA and UMA which becomes bigger when the dataset gets larger and sparser from MovieLens 100K to MovieLens 1M."}, {"heading": "7. Conclusion", "text": "The attack detection plays an important role to improve the quality of recommendation in systems, whereas most previous methods focus on shilling attacks. In this paper, we first formulate the unorganized malicious attacks detection as a variant of matrix completion problem. Then we propose the Unorganized Malicious Attacks detection (UMA) algorithm, which can be viewed as a proximal alternating splitting augmented Lagrangian method. We give the proof of global convergence theoretically, and experimental results show that our proposed algorithm achieves significantly better performance than the state-of-the-art approaches for attack detection."}], "references": [{"title": "Toward the next generation of recommender systems: A survey of the state-of-the-art and possible extensions", "author": ["G. Adomavicius", "A. Singhal"], "venue": "IEEE Transactions on Knowledge and Data Engineering,", "citeRegEx": "Adomavicius and Singhal.,? \\Q2005\\E", "shortCiteRegEx": "Adomavicius and Singhal.", "year": 2005}, {"title": "Unifying collaborative and content-based filtering", "author": ["J. Basilico", "T. Hofmann"], "venue": "In Proceedings of the 21st International Conference on Machine Learning,", "citeRegEx": "Basilico and Hofmann.,? \\Q2004\\E", "shortCiteRegEx": "Basilico and Hofmann.", "year": 2004}, {"title": "Securing collaborative filtering against malicious attacks through anomaly detection", "author": ["R. Bhaumik", "C. Williams", "B. Mobasher", "R. Burke"], "venue": "In Proceedings of the 4th Workshop on Intelligent Techniques for Web Personalization,", "citeRegEx": "Bhaumik et al\\.,? \\Q2006\\E", "shortCiteRegEx": "Bhaumik et al\\.", "year": 2006}, {"title": "A clustering approach to unsupervised attack detection in collaborative recommender systems", "author": ["R. Bhaumik", "B. Mobasher", "R.D. Burke"], "venue": "In Proceedings of the 7th International Conference on Data Mining,", "citeRegEx": "Bhaumik et al\\.,? \\Q2011\\E", "shortCiteRegEx": "Bhaumik et al\\.", "year": 2011}, {"title": "A latent source model for online collaborative filtering", "author": ["G. Bresler", "G. Chen", "D. Shah"], "venue": "In Proceedings of the 28th Advances in Neural Information Processing Systems,", "citeRegEx": "Bresler et al\\.,? \\Q2014\\E", "shortCiteRegEx": "Bresler et al\\.", "year": 2014}, {"title": "From sparse solutions of systems of equations to sparse modeling of signals and images", "author": ["A.M. Bruckstein", "D.L. Donoho", "M. Elad"], "venue": "SIAM Review,", "citeRegEx": "Bruckstein et al\\.,? \\Q2009\\E", "shortCiteRegEx": "Bruckstein et al\\.", "year": 2009}, {"title": "Unsupervised retrieval of attack profiles in collaborative recommender systems", "author": ["K. Bryan", "M. O\u2019Mahony", "P. Cunningham"], "venue": "In Proceedings of the 2nd ACM Conference on Recommender Systems,", "citeRegEx": "Bryan et al\\.,? \\Q2008\\E", "shortCiteRegEx": "Bryan et al\\.", "year": 2008}, {"title": "A singular value thresholding algorithm for matrix completion", "author": ["J.-F. Cai", "E.J. Cand\u00e8s", "Z.-W. Shen"], "venue": "SIAM Journal on Optimization,", "citeRegEx": "Cai et al\\.,? \\Q1956\\E", "shortCiteRegEx": "Cai et al\\.", "year": 1956}, {"title": "Robust principal component analysis", "author": ["E.J. Cand\u00e8s", "X.D. Li", "Y. Ma", "J. Wright"], "venue": "Journal of the ACM,", "citeRegEx": "Cand\u00e8s et al\\.,? \\Q2011\\E", "shortCiteRegEx": "Cand\u00e8s et al\\.", "year": 2011}, {"title": "Item-based top-n recommendation algorithms", "author": ["M. Deshpande", "G. Karypis"], "venue": "ACM Transactions on Information Systems,", "citeRegEx": "Deshpande and Karypis.,? \\Q2004\\E", "shortCiteRegEx": "Deshpande and Karypis.", "year": 2004}, {"title": "Collaborative filtering recommender systems", "author": ["M.D. Ekstrand", "J.T. Riedl", "J.A. Konstan"], "venue": "Foundations and Trends in Human-Computer Interaction,", "citeRegEx": "Ekstrand et al\\.,? \\Q2011\\E", "shortCiteRegEx": "Ekstrand et al\\.", "year": 2011}, {"title": "Online robust pca via stochastic optimization", "author": ["J.-S. Feng", "H. Xu", "S.-C. Yan"], "venue": "In Proceedings of the 27th Advances in Neural Information Processing Systems,", "citeRegEx": "Feng et al\\.,? \\Q2013\\E", "shortCiteRegEx": "Feng et al\\.", "year": 2013}, {"title": "Using collaborative filtering to weave an information tapestry", "author": ["D. Goldberg", "D. Nichols", "B.M. Oki", "D. Terry"], "venue": "Communications of the ACM,", "citeRegEx": "Goldberg et al\\.,? \\Q1992\\E", "shortCiteRegEx": "Goldberg et al\\.", "year": 1992}, {"title": "Shilling attacks against recommender systems: a comprehensive survey", "author": ["I. Gunes", "C. Kaleli", "A. Bilge", "H. Polat"], "venue": "Artificial Intelligence Review,", "citeRegEx": "Gunes et al\\.,? \\Q2014\\E", "shortCiteRegEx": "Gunes et al\\.", "year": 2014}, {"title": "Finding structure with randomness: Probabilistic algorithms for constructing approximate matrix decompositions", "author": ["N. Halko", "P.-G. Martinsson", "J.A. Tropp"], "venue": "SIAM review,", "citeRegEx": "Halko et al\\.,? \\Q2011\\E", "shortCiteRegEx": "Halko et al\\.", "year": 2011}, {"title": "A splitting method for separable convex programming", "author": ["B.-S. He", "M. Tao", "X.-M. Yuan"], "venue": "IMA Journal of Numerical Analysis,", "citeRegEx": "He et al\\.,? \\Q2015\\E", "shortCiteRegEx": "He et al\\.", "year": 2015}, {"title": "Statistical attack detection", "author": ["N.J. Hurley", "Z.P. Cheng", "M. Zhang"], "venue": "In Proceedings of the 3rd ACM Conference on Recommender Systems,", "citeRegEx": "Hurley et al\\.,? \\Q2009\\E", "shortCiteRegEx": "Hurley et al\\.", "year": 2009}, {"title": "Using mixture models for collaborative filtering", "author": ["J. Kleinberg", "M. Sandler"], "venue": "Journal of Computer and System Sciences,", "citeRegEx": "Kleinberg and Sandler.,? \\Q2008\\E", "shortCiteRegEx": "Kleinberg and Sandler.", "year": 2008}, {"title": "Shilling recommender systems for fun and profit", "author": ["S.K. Lam", "J. Riedl"], "venue": "In Proceedings of the 13th International Conference on World Wide Web,", "citeRegEx": "Lam and Riedl.,? \\Q2004\\E", "shortCiteRegEx": "Lam and Riedl.", "year": 2004}, {"title": "Transfer learning for collaborative filtering via a ratingmatrix generative model", "author": ["B. Li", "Q. Yang", "X.-Y. Xue"], "venue": "In Proceedings of the 26th International Conference on Machine Learning,", "citeRegEx": "Li et al\\.,? \\Q2009\\E", "shortCiteRegEx": "Li et al\\.", "year": 2009}, {"title": "Detection of shilling attacks in collaborative filtering recommender systems", "author": ["C. Li", "Z.-G. Luo"], "venue": "In Proceedings of the 2nd International Conference of Soft Computing and Pattern Recognition,", "citeRegEx": "Li and Luo.,? \\Q2011\\E", "shortCiteRegEx": "Li and Luo.", "year": 2011}, {"title": "A unified framework for reputation estimation in online rating systems", "author": ["G. Ling", "I. King", "M.R. Lyu"], "venue": "In Proceedings of the 23rd International Joint Conference on Artificial Intelligence,", "citeRegEx": "Ling et al\\.,? \\Q2013\\E", "shortCiteRegEx": "Ling et al\\.", "year": 2013}, {"title": "Divide-and-conquer matrix factorization", "author": ["L.W. Mackey", "M.I. Jordan", "A. Talwalkar"], "venue": "In Proceedings of the 25th Advances in Neural Information Processing Systems,", "citeRegEx": "Mackey et al\\.,? \\Q2011\\E", "shortCiteRegEx": "Mackey et al\\.", "year": 2011}, {"title": "Unsupervised shilling detection for collaborative filtering", "author": ["B. Mehta"], "venue": "In Proceedings of the 22nd International Conference on Artificial Intelligence,", "citeRegEx": "Mehta.,? \\Q2007\\E", "shortCiteRegEx": "Mehta.", "year": 2007}, {"title": "Unsupervised strategies for shilling detection and robust collaborative filtering", "author": ["B. Mehta", "W. Nejdl"], "venue": "User Modeling and User-Adapted Interaction,", "citeRegEx": "Mehta and Nejdl.,? \\Q2009\\E", "shortCiteRegEx": "Mehta and Nejdl.", "year": 2009}, {"title": "Attacks and remedies in collaborative recommendation", "author": ["B. Mobasher", "R. Burke", "R. Bhaumik", "J.J. Sandvig"], "venue": "Intelligent Systems,", "citeRegEx": "Mobasher et al\\.,? \\Q2009\\E", "shortCiteRegEx": "Mobasher et al\\.", "year": 2009}, {"title": "Rasl: Robust alignment by sparse and low-rank decomposition for linearly correlated images", "author": ["Y.-G. Peng", "A. Ganesh", "J. Wright", "W.-L. Xu", "Y. Ma"], "venue": "Pattern Analysis and Machine Intelligence,", "citeRegEx": "Peng et al\\.,? \\Q2012\\E", "shortCiteRegEx": "Peng et al\\.", "year": 2012}, {"title": "Collaborative filtering with graph information: Consistency and scalable methods", "author": ["N. Rao", "H.-F. Yu", "P. Ravikumar", "I. Dhillon"], "venue": "In Proceedings of the 29th Advances in Neural Information Processing Systems,", "citeRegEx": "Rao et al\\.,? \\Q2015\\E", "shortCiteRegEx": "Rao et al\\.", "year": 2015}, {"title": "Convex Analysis", "author": ["R.T. Rockafellar"], "venue": null, "citeRegEx": "Rockafellar.,? \\Q1970\\E", "shortCiteRegEx": "Rockafellar.", "year": 1970}, {"title": "Bayesian probabilistic matrix factorization using markov chain monte carlo", "author": ["R. Salakhutdinov", "A. Mnih"], "venue": "In Proceedings of the 25th International Conference on Machine Learning,", "citeRegEx": "Salakhutdinov and Mnih.,? \\Q2008\\E", "shortCiteRegEx": "Salakhutdinov and Mnih.", "year": 2008}, {"title": "Probabilistic matrix factorization", "author": ["R. Salakhutdinov", "A. Mnih"], "venue": "In Proceedings of the 22nd Advances in Neural Information Processing Systems,", "citeRegEx": "Salakhutdinov and Mnih.,? \\Q2008\\E", "shortCiteRegEx": "Salakhutdinov and Mnih.", "year": 2008}, {"title": "Restricted boltzmann machines for collaborative filtering", "author": ["R. Salakhutdinov", "A. Mnih", "G. Hinton"], "venue": "In Proceedings of the 24th International Conference on Machine Learning,", "citeRegEx": "Salakhutdinov et al\\.,? \\Q2007\\E", "shortCiteRegEx": "Salakhutdinov et al\\.", "year": 2007}, {"title": "Modern information retrieval: A brief overview", "author": ["A. Singhal"], "venue": "IEEE Data Engineering Bulletin,", "citeRegEx": "Singhal.,? \\Q2001\\E", "shortCiteRegEx": "Singhal.", "year": 2001}, {"title": "Recovering low-rank and sparse components of matrices from incomplete and noisy observations", "author": ["M. Tao", "X.-M. Yuan"], "venue": "SIAM Journal on Optimization,", "citeRegEx": "Tao and Yuan.,? \\Q2011\\E", "shortCiteRegEx": "Tao and Yuan.", "year": 2011}, {"title": "A recursive prediction algorithm for collaborative filtering recommender systems", "author": ["J.-Y. Zhang", "P. Pu"], "venue": "In Proceedings of the 1st ACM Conference on Recommender Systems,", "citeRegEx": "Zhang and Pu.,? \\Q2007\\E", "shortCiteRegEx": "Zhang and Pu.", "year": 2007}], "referenceMentions": [{"referenceID": 4, "context": "systems so as to help customers choose their favorite products in a set of items (Bresler et al., 2014; Li et al., 2009; Rao et al., 2015).", "startOffset": 81, "endOffset": 138}, {"referenceID": 19, "context": "systems so as to help customers choose their favorite products in a set of items (Bresler et al., 2014; Li et al., 2009; Rao et al., 2015).", "startOffset": 81, "endOffset": 138}, {"referenceID": 27, "context": "systems so as to help customers choose their favorite products in a set of items (Bresler et al., 2014; Li et al., 2009; Rao et al., 2015).", "startOffset": 81, "endOffset": 138}, {"referenceID": 13, "context": "Many collaborative filtering approaches are vulnerable to spammers and manipulations of ratings (Gunes et al., 2014; Ling et al., 2013), and attackers may bias systems by inserting fake rating scores into the user-item rating matrix.", "startOffset": 96, "endOffset": 135}, {"referenceID": 21, "context": "Many collaborative filtering approaches are vulnerable to spammers and manipulations of ratings (Gunes et al., 2014; Ling et al., 2013), and attackers may bias systems by inserting fake rating scores into the user-item rating matrix.", "startOffset": 96, "endOffset": 135}, {"referenceID": 16, "context": "Most attack detection studies focus on shilling attacks and show good detection performance on kinds of shilling attack strategies (Hurley et al., 2009; Ling et al., 2013; Mehta, 2007).", "startOffset": 131, "endOffset": 184}, {"referenceID": 21, "context": "Most attack detection studies focus on shilling attacks and show good detection performance on kinds of shilling attack strategies (Hurley et al., 2009; Ling et al., 2013; Mehta, 2007).", "startOffset": 131, "endOffset": 184}, {"referenceID": 23, "context": "Most attack detection studies focus on shilling attacks and show good detection performance on kinds of shilling attack strategies (Hurley et al., 2009; Ling et al., 2013; Mehta, 2007).", "startOffset": 131, "endOffset": 184}, {"referenceID": 31, "context": "Let X denote the ground-truth rating matrix without attacks and noises, and the matrix is low-rank since the users\u2019 preferences are affected by several factors (Salakhutdinov et al., 2007).", "startOffset": 160, "endOffset": 188}, {"referenceID": 8, "context": "The main difference between our optimization problem and robust PCA (Cand\u00e8s et al., 2011) is that roubst PCA focuses on recovering low-rank part X from complete or incomplete matrix and we pay more attention to distinguishing the sparse attack term Y from the small perturbation noise term Z.", "startOffset": 68, "endOffset": 89}, {"referenceID": 12, "context": "The core assumption of CF is that if users express similar interests in the past, they will share common interest in the future (Goldberg et al., 1992).", "startOffset": 128, "endOffset": 151}, {"referenceID": 4, "context": "Significant progress about CF has been made since then (Bresler et al., 2014; Li et al., 2009; Rao et al., 2015; Salakhutdinov et al., 2007).", "startOffset": 55, "endOffset": 140}, {"referenceID": 19, "context": "Significant progress about CF has been made since then (Bresler et al., 2014; Li et al., 2009; Rao et al., 2015; Salakhutdinov et al., 2007).", "startOffset": 55, "endOffset": 140}, {"referenceID": 27, "context": "Significant progress about CF has been made since then (Bresler et al., 2014; Li et al., 2009; Rao et al., 2015; Salakhutdinov et al., 2007).", "startOffset": 55, "endOffset": 140}, {"referenceID": 31, "context": "Significant progress about CF has been made since then (Bresler et al., 2014; Li et al., 2009; Rao et al., 2015; Salakhutdinov et al., 2007).", "startOffset": 55, "endOffset": 140}, {"referenceID": 32, "context": "User similarity is defined by a similarity metric, usually the cosine similarity or the Pearson correlation (Singhal, 2001).", "startOffset": 108, "endOffset": 123}, {"referenceID": 0, "context": "Many modifications and adjustments about the similarity metric have been proposed (Adomavicius and Singhal, 2005; Zhang and Pu, 2007).", "startOffset": 82, "endOffset": 133}, {"referenceID": 34, "context": "Many modifications and adjustments about the similarity metric have been proposed (Adomavicius and Singhal, 2005; Zhang and Pu, 2007).", "startOffset": 82, "endOffset": 133}, {"referenceID": 9, "context": "Item-based CF approaches predict the rating of an item for a user according to the ratings of items the user has given (Deshpande and Karypis, 2004).", "startOffset": 119, "endOffset": 148}, {"referenceID": 10, "context": "Model-based CF approaches use the user-item matrix to train prediction models and recommendations are generated from the prediction models (Ekstrand et al., 2011).", "startOffset": 139, "endOffset": 162}, {"referenceID": 17, "context": "For example, the mixture model learns the probability distribution of items in each clusters (Kleinberg and Sandler, 2008); Matrix factorization techniques learn latent factors of users and items from the user-item matrix and then use the low-rank approximation matrix to predict the score of unrated items; From probabilistic perspective, Salakhutdinov and Mnih (2008a) propose probabilistic matrix factorization framework.", "startOffset": 93, "endOffset": 122}, {"referenceID": 1, "context": "Considering about side information besides the user-item matrix, many works expand the CF paradigm (Basilico and Hofmann, 2004; Salakhutdinov et al., 2007; Li et al., 2009).", "startOffset": 99, "endOffset": 172}, {"referenceID": 31, "context": "Considering about side information besides the user-item matrix, many works expand the CF paradigm (Basilico and Hofmann, 2004; Salakhutdinov et al., 2007; Li et al., 2009).", "startOffset": 99, "endOffset": 172}, {"referenceID": 19, "context": "Considering about side information besides the user-item matrix, many works expand the CF paradigm (Basilico and Hofmann, 2004; Salakhutdinov et al., 2007; Li et al., 2009).", "startOffset": 99, "endOffset": 172}, {"referenceID": 13, "context": "However the two main categories of CF schemes are both vulnerable to attacks (Gunes et al., 2014; Ling et al., 2013).", "startOffset": 77, "endOffset": 116}, {"referenceID": 21, "context": "However the two main categories of CF schemes are both vulnerable to attacks (Gunes et al., 2014; Ling et al., 2013).", "startOffset": 77, "endOffset": 116}, {"referenceID": 13, "context": "Researchers have proposed several kinds of methods which can be mainly thought as statistical, clustering, classification and data reduction-based methods (Gunes et al., 2014).", "startOffset": 155, "endOffset": 175}, {"referenceID": 25, "context": "Based on attributes derived from user profiles, classification methods (Mobasher et al., 2009) detect attacks by kNN, SVM, rough set theory, etc.", "startOffset": 71, "endOffset": 94}, {"referenceID": 0, "context": "Many modifications and adjustments about the similarity metric have been proposed (Adomavicius and Singhal, 2005; Zhang and Pu, 2007). Item-based CF approaches predict the rating of an item for a user according to the ratings of items the user has given (Deshpande and Karypis, 2004). Model-based CF approaches use the user-item matrix to train prediction models and recommendations are generated from the prediction models (Ekstrand et al., 2011). For example, the mixture model learns the probability distribution of items in each clusters (Kleinberg and Sandler, 2008); Matrix factorization techniques learn latent factors of users and items from the user-item matrix and then use the low-rank approximation matrix to predict the score of unrated items; From probabilistic perspective, Salakhutdinov and Mnih (2008a) propose probabilistic matrix factorization framework.", "startOffset": 83, "endOffset": 820}, {"referenceID": 0, "context": "Many modifications and adjustments about the similarity metric have been proposed (Adomavicius and Singhal, 2005; Zhang and Pu, 2007). Item-based CF approaches predict the rating of an item for a user according to the ratings of items the user has given (Deshpande and Karypis, 2004). Model-based CF approaches use the user-item matrix to train prediction models and recommendations are generated from the prediction models (Ekstrand et al., 2011). For example, the mixture model learns the probability distribution of items in each clusters (Kleinberg and Sandler, 2008); Matrix factorization techniques learn latent factors of users and items from the user-item matrix and then use the low-rank approximation matrix to predict the score of unrated items; From probabilistic perspective, Salakhutdinov and Mnih (2008a) propose probabilistic matrix factorization framework. Considering about side information besides the user-item matrix, many works expand the CF paradigm (Basilico and Hofmann, 2004; Salakhutdinov et al., 2007; Li et al., 2009). However the two main categories of CF schemes are both vulnerable to attacks (Gunes et al., 2014; Ling et al., 2013). Increasing attention has been given to attack detection. Researchers have proposed several kinds of methods which can be mainly thought as statistical, clustering, classification and data reduction-based methods (Gunes et al., 2014). These methods mainly focus on shilling attacks where the attack organizer fakes a large number of user profiles by the same strategy to promote or demote a particular item. Statistical methods are used to detect anomalies who give suspicious ratings. Hurley et al. (2009) propose a Neyman-Pearson statistical attack detection method to distinguish attackers from normal users.", "startOffset": 83, "endOffset": 1672}, {"referenceID": 0, "context": "Many modifications and adjustments about the similarity metric have been proposed (Adomavicius and Singhal, 2005; Zhang and Pu, 2007). Item-based CF approaches predict the rating of an item for a user according to the ratings of items the user has given (Deshpande and Karypis, 2004). Model-based CF approaches use the user-item matrix to train prediction models and recommendations are generated from the prediction models (Ekstrand et al., 2011). For example, the mixture model learns the probability distribution of items in each clusters (Kleinberg and Sandler, 2008); Matrix factorization techniques learn latent factors of users and items from the user-item matrix and then use the low-rank approximation matrix to predict the score of unrated items; From probabilistic perspective, Salakhutdinov and Mnih (2008a) propose probabilistic matrix factorization framework. Considering about side information besides the user-item matrix, many works expand the CF paradigm (Basilico and Hofmann, 2004; Salakhutdinov et al., 2007; Li et al., 2009). However the two main categories of CF schemes are both vulnerable to attacks (Gunes et al., 2014; Ling et al., 2013). Increasing attention has been given to attack detection. Researchers have proposed several kinds of methods which can be mainly thought as statistical, clustering, classification and data reduction-based methods (Gunes et al., 2014). These methods mainly focus on shilling attacks where the attack organizer fakes a large number of user profiles by the same strategy to promote or demote a particular item. Statistical methods are used to detect anomalies who give suspicious ratings. Hurley et al. (2009) propose a Neyman-Pearson statistical attack detection method to distinguish attackers from normal users. Similarly, probabilistic Bayesian network models are used in Li and Luo (2011). Based on attributes derived from user profiles, classification methods (Mobasher et al.", "startOffset": 83, "endOffset": 1856}, {"referenceID": 6, "context": "An unsupervised clustering algorithm based on several classification attributes (Bryan et al., 2008) is presented in Bhaumik et al.", "startOffset": 80, "endOffset": 100}, {"referenceID": 2, "context": ", 2008) is presented in Bhaumik et al. (2011). They apply k-means clustering based on these attributes and classify users in the smallest cluster as attackers.", "startOffset": 24, "endOffset": 46}, {"referenceID": 2, "context": ", 2008) is presented in Bhaumik et al. (2011). They apply k-means clustering based on these attributes and classify users in the smallest cluster as attackers. Instead of using traditional nearest neighbor methods, Mehta (2007) proposes a PLSA-based clustering method.", "startOffset": 24, "endOffset": 228}, {"referenceID": 2, "context": ", 2008) is presented in Bhaumik et al. (2011). They apply k-means clustering based on these attributes and classify users in the smallest cluster as attackers. Instead of using traditional nearest neighbor methods, Mehta (2007) proposes a PLSA-based clustering method. Mehta and Nejdl (2009) propose the variable selection method, which treats users as variables and calculates their covariance matrix.", "startOffset": 24, "endOffset": 292}, {"referenceID": 2, "context": ", 2008) is presented in Bhaumik et al. (2011). They apply k-means clustering based on these attributes and classify users in the smallest cluster as attackers. Instead of using traditional nearest neighbor methods, Mehta (2007) proposes a PLSA-based clustering method. Mehta and Nejdl (2009) propose the variable selection method, which treats users as variables and calculates their covariance matrix. By analyzing the principal components of the covariance matrix, those users with the smallest coefficient in the first l principal components are chosen in the final variable selection. Ling et al. (2013) try to predict the users\u2019 ratings by using a low-rank matrix factorization method and classify users with the lowest reputation as attackers.", "startOffset": 24, "endOffset": 608}, {"referenceID": 2, "context": "2 Problem Formulation The general form of an attack profile is shown in Figure 1 which is first defined by Bhaumik et al. (2006). the selected items, IS , are rated by the rating function \u03b4.", "startOffset": 107, "endOffset": 129}, {"referenceID": 8, "context": "Notice that we can not directly recover X and Y from M because such recovery is an NP-Hard problem (Cand\u00e8s et al., 2011).", "startOffset": 99, "endOffset": 120}, {"referenceID": 8, "context": "There have been many works (Cand\u00e8s et al., 2011; Feng et al., 2013; Mackey et al., 2011; Peng et al., 2012) on recovering low-rank part X from complete or incomplete matrix.", "startOffset": 27, "endOffset": 107}, {"referenceID": 11, "context": "There have been many works (Cand\u00e8s et al., 2011; Feng et al., 2013; Mackey et al., 2011; Peng et al., 2012) on recovering low-rank part X from complete or incomplete matrix.", "startOffset": 27, "endOffset": 107}, {"referenceID": 22, "context": "There have been many works (Cand\u00e8s et al., 2011; Feng et al., 2013; Mackey et al., 2011; Peng et al., 2012) on recovering low-rank part X from complete or incomplete matrix.", "startOffset": 27, "endOffset": 107}, {"referenceID": 26, "context": "There have been many works (Cand\u00e8s et al., 2011; Feng et al., 2013; Mackey et al., 2011; Peng et al., 2012) on recovering low-rank part X from complete or incomplete matrix.", "startOffset": 27, "endOffset": 107}, {"referenceID": 7, "context": "Therefore, we consider the following perturbation formulation inspired by Cai et al. (2010);", "startOffset": 74, "endOffset": 92}, {"referenceID": 15, "context": "It is noteworthy that there is a coupling term in our objective function, and some traditional algorithms (He et al., 2015; Tao and Yuan, 2011) can not be applied directly.", "startOffset": 106, "endOffset": 143}, {"referenceID": 33, "context": "It is noteworthy that there is a coupling term in our objective function, and some traditional algorithms (He et al., 2015; Tao and Yuan, 2011) can not be applied directly.", "startOffset": 106, "endOffset": 143}, {"referenceID": 33, "context": "We propose a proximal alternating splitting augmented Lagrangian method to solve this optimization, which inherits the advantages of ASALM (Tao and Yuan, 2011).", "startOffset": 139, "endOffset": 159}, {"referenceID": 5, "context": "Lemma 1 (Bruckstein et al., 2009) For \u03c4 > 0 and T \u2208 Rm\u00d7n, the closed solution of minY \u03c4\u2016Y \u20161 + \u2016Y \u2212 T\u2016F /2 is given by matrix S\u03c4 (T ) with (S\u03c4 (T ))ij = max{|Tij | \u2212 \u03c4, 0} \u00b7 sgn(Tij), where sgn(\u00b7) means the sign function.", "startOffset": 8, "endOffset": 33}, {"referenceID": 8, "context": "(8), and the pair (W,F ) can be easily constructed according to Cand\u00e8s et al. (2011). We complete the proof from the condition \u2016Z\u2016F \u2264 \u03b4.", "startOffset": 64, "endOffset": 85}, {"referenceID": 28, "context": "1 of Rockafellar (1970) that the solution set of (3) is non-empty.", "startOffset": 5, "endOffset": 24}, {"referenceID": 32, "context": "The VASALM in Tao and Yuan (2011); He et al.", "startOffset": 14, "endOffset": 34}, {"referenceID": 15, "context": "The VASALM in Tao and Yuan (2011); He et al. (2015) can not be applied directly.", "startOffset": 35, "endOffset": 52}, {"referenceID": 15, "context": "The VASALM in Tao and Yuan (2011); He et al. (2015) can not be applied directly. Because, the splitting methods developed in Tao and Yuan (2011); He et al.", "startOffset": 35, "endOffset": 145}, {"referenceID": 15, "context": "The VASALM in Tao and Yuan (2011); He et al. (2015) can not be applied directly. Because, the splitting methods developed in Tao and Yuan (2011); He et al. (2015) with global convergence aims to solve the separable convex programming.", "startOffset": 35, "endOffset": 163}, {"referenceID": 15, "context": "The VASALM in Tao and Yuan (2011); He et al. (2015) can not be applied directly. Because, the splitting methods developed in Tao and Yuan (2011); He et al. (2015) with global convergence aims to solve the separable convex programming. Therefore, these existing methods can not be applied to solve problem (3) with global convergence. Hence, we propose a new splitting method, i.e., UMA which aims to solve the problem (3) with coupling objective function. Moreover, UMA inherits the advantage of ASALM in Tao and Yuan (2011), i.", "startOffset": 35, "endOffset": 525}, {"referenceID": 13, "context": "These performance measures can be calculated as follows (Gunes et al., 2014),", "startOffset": 56, "endOffset": 76}, {"referenceID": 16, "context": "\u2022 N-P: A statistical algorithm which identifies attack profiles based on the NeymanPearson statistics (Hurley et al., 2009).", "startOffset": 102, "endOffset": 123}, {"referenceID": 3, "context": "\u2022 k-means: A cluster algorithm based on classification attributes (Bhaumik et al., 2011).", "startOffset": 66, "endOffset": 88}, {"referenceID": 24, "context": "\u2022 PCAVarSel: A PCA-based variable selection algorithm by computing covariance between users to locate malicious users (Mehta and Nejdl, 2009).", "startOffset": 118, "endOffset": 141}, {"referenceID": 21, "context": "\u2022 MF-based: A matrix factorization algorithm by computing the reputation scores among users (Ling et al., 2013).", "startOffset": 92, "endOffset": 111}, {"referenceID": 8, "context": "\u2022 RPCA: A low-rank matrix recovery method considering sparse and small perturbation noise (Cand\u00e8s et al., 2011).", "startOffset": 90, "endOffset": 111}, {"referenceID": 14, "context": "We use the power method (Halko et al., 2011) to approximate Eqn.", "startOffset": 24, "endOffset": 44}], "year": 2016, "abstractText": "Recommender system has attracted much attention during the past decade, and many attack detection algorithms have been developed for better recommendation. Most previous approaches focus on the shilling attacks, where the attack organizer fakes a large number of user profiles by the same strategy to promote or demote an item. In this paper, we study a different attack style: unorganized malicious attacks, where attackers respectively use a small number of user profiles to attack their own target items without any organizer. This attack style occurs in many real applications, yet relevant study remains open. In this paper, we formulate the unorganized malicious attacks detection as a variant of matrix completion problem, and prove that attackers can be detected theoretically. We propose the Unorganized Malicious Attacks detection (UMA) algorithm, which can be viewed as a proximal alternating splitting augmented Lagrangian method. We verify, both theoretically and empirically, the effectiveness of our proposed algorithm.", "creator": "LaTeX with hyperref package"}}}