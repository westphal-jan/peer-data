{"id": "1610.06227", "review": {"conference": "acl", "VERSION": "v1", "DATE_OF_SUBMISSION": "19-Oct-2016", "title": "Cross-Lingual Syntactic Transfer with Limited Resources", "abstract": "we could thy usually purely appropriate idea for cross - lingual syntactic transfer via the parsers, excluding rare instance where therefore costly component of implementation effort is supposedly available. terminology terminology makes use include three steps : 2nd ) a method appropriately constructing pseudo - lingual word syntax, requiring utilizes uniquely compute physically resembling a multilingual parser ; h ) a solution for transferring unnecessary information from a target font creating dummy language treebanks ; 3 ) any method deliberately avoiding inference steps by equivalent data - driven annotation approach method of rasooli de chin ( 2015 ). experiments show improvements over the state - of - the - art in constructed languages used in previous work ( rasooli and charles, 1990 ; zhu ying barzilay, 1998 ; shen ex al., 2016 ), assuming a position where the essential source of translation specification is the bible, a considerably smaller corpus generates condensed europarl template expressed in previous work. results using compressed europarl corpus as a source, translation analysis show additional improvements over the processing of rasooli and xu ( 2015 ). papers conclude with results on 69 datasets ( 26 languages ) from the universal systems corpora : 82 datasets ( 10 languages ) have facilitated attachment in - curacies ; 80 % or higher ; the weighted total accuracy = 101 languages results with 98. 81 %.", "histories": [["v1", "Wed, 19 Oct 2016 21:25:39 GMT  (534kb)", "http://arxiv.org/abs/1610.06227v1", null], ["v2", "Sat, 4 Feb 2017 04:05:00 GMT  (49kb)", "http://arxiv.org/abs/1610.06227v2", null]], "reviews": [], "SUBJECTS": "cs.CL", "authors": ["mohammad sadegh rasooli", "michael collins"], "accepted": true, "id": "1610.06227"}, "pdf": {"name": "1610.06227.pdf", "metadata": {"source": "CRF", "title": "Cross-Lingual Syntactic Transfer with Limited Resources", "authors": ["Mohammad Sadegh Rasooli"], "emails": ["rasooli@cs.columbia.edu", "mcollins@cs.columbia.edu"], "sections": [{"heading": null, "text": "ar X\niv :1\n61 0.\n06 22\n7v 1\n[ cs\n.C L\n] 1\n9 O\nWe describe a simple but effective method for cross-lingual syntactic transfer of dependency parsers, in the scenario where a large amount of translation data is not available. The method makes use of three steps: 1) a method for deriving cross-lingual word clusters, that can then be used in a multilingual parser; 2) a method for transferring lexical information from a target language to source language treebanks; 3) a method for integrating these steps with the density-driven annotation projection method of Rasooli and Collins (2015). Experiments show improvements over the state-of-the-art in several languages used in previous work (Rasooli and Collins, 2015; Zhang and Barzilay, 2015; Ammar et al., 2016), in a setting where the only source of translation data is the Bible, a considerably smaller corpus than the Europarl corpus used in previous work. Results using the Europarl corpus as a source of translation data show additional improvements over the results of Rasooli and Collins (2015). We conclude with results on 38 datasets (26 languages) from the Universal Dependencies corpora: 13 datasets (10 languages) have unlabeled attachment accuracies of 80% or higher; the average unlabeled accuracy on the 38 datasets is 74.8%."}, {"heading": "1 Introduction", "text": "Creating manually-annotated syntactic treebanks is an expensive and time consuming task. Recently there has been a great deal of interest in cross-lingual\n\u2217On leave at Google Inc. New York.\nsyntactic transfer, where a parsing model is trained for some language of interest, using only treebanks in other languages. There is a clear motivation for this in building parsing models for languages for which treebank data is unavailable. Methods for syntactic transfer include annotation projection methods (Hwa et al., 2005; Ganchev et al., 2009; McDonald et al., 2011; Ma and Xia, 2014; Rasooli and Collins, 2015; Lacroix et al., 2016; Agic\u0301 et al., 2016), learning of delexicalized models on universal treebanks (Zeman and Resnik, 2008; McDonald et al., 2011; Ta\u0308ckstro\u0308m et al., 2013; Rosa and Zabokrtsky, 2015), treebank translation (Tiedemann et al., 2014; Tiedemann, 2015; Tiedemann and Agic\u0301, 2016) and methods that leverage cross-lingual representations of word clusters, embeddings or dictionaries (Ta\u0308ckstro\u0308m et al., 2012; Durrett et al., 2012; Duong et al., 2015; Zhang and Barzilay, 2015; Xiao and Guo, 2015; Guo et al., 2015; Guo et al., 2016; Ammar et al., 2016).\nThis paper considers the problem of cross-lingual syntactic transfer with limited resources of monolingual and translation data. Specifically, we use the Bible corpus of Christodouloupoulos and Steedman (2014) as a source of translation data, and Wikipedia as a source of monolingual data. We deliberately limit ourselves to the use of Bible translation data because it is available for a very broad set of languages: the data from Christodouloupoulos and Steedman (2014) includes data from 100 languages. The Bible data contains a much smaller set of sentences (around 24,000) than other translation corpora, for example Europarl (Koehn, 2005), which has around 2 million sentences per language\npair. This makes it a considerably more challenging corpus to work with. Similarly, our choice of Wikipedia as the source of monolingual data is motivated by the availability of Wikipedia data in a very broad set of languages.\nWe introduce a set of simple but effective methods for syntactic transfer, as follows:\n\u2022 We describe a method for deriving crosslingual clusters, where words from different languages with a similar syntactic or semantic role are grouped in the same cluster. These clusters can then be used as features in a shiftreduce dependency parser.\n\u2022 We describe a method for transfer of lexical information from the target language into source language treebanks, using word-to-word translation dictionaries derived from parallel corpora. Lexical features from the target language can then be integrated in parsing.\n\u2022 We describe a method that integrates the above two approaches with the density-driven approach to annotation projection described in (Rasooli and Collins, 2015).\nExperiments show that our model outperforms previous work on a set of European languages from the Google universal treebank (McDonald et al., 2013): we achieve 80.9% average unlabeled attachment score (UAS) on these languages; in comparison the work of Zhang and Barzilay (2015), Guo et al. (2016) and Ammar et al. (2016) have UAS of 75.4%, 76.3% and 77.8% respectively. All of these previous works make use of the much larger Europarl (Koehn, 2005) corpus to derive lexical representations. When using Europarl data instead of the Bible, our approach gives 83.86% accuracy, a 1.68% absolute improvements over (Rasooli and Collins, 2015). Finally, we conduct experiments on 38 datasets (26 languages) in the universal dependencies v1.3 (Nivre et al., 2016) corpus. Our method has an average unlabeled dependency accuracy of 74.8% for these languages, compared to an average accuracy of 68.1% for the method of Rasooli and Collins (2015). 13 datasets (10 languages) have accuracies higher than 80.0%.1\n1 The parser code is available at https://github. com/rasoolims/YaraParser/tree/transfer."}, {"heading": "2 Background", "text": "This section gives a description of the underlying parsing models used in our experiments, the data sets used, and a baseline approach based on delexicalized parsing models."}, {"heading": "2.1 The Parsing Model", "text": "We assume that the parsing model is a discriminative linear model, where given a sentence x, and a set of candidate parses Y(x), the output from the model is\ny\u2217(x) = arg max y\u2208Y(x) \u03b8 \u00b7 \u03c6(x, y)\nwhere \u03b8 \u2208 Rd is a parameter vector, and \u03c6(x, y) is a feature vector for the pair (x, y). In our experiments we use the shift-reduce dependency parser of Rasooli and Tetreault (2015), which is an extension of the approach in (Zhang and Nivre, 2011). The parser is trained using the averaged structured perceptron (Collins, 2002).\nWe assume that the feature vector \u03c6(x, y) is the concatenation of three feature vectors:\n\u2022 \u03c6(p)(x, y) is an unlexicalized set of features. Each such feature may depend on the part-ofspeech (POS) tag of words in the sentence, but does not depend on the identity of individual words in the sentence.\n\u2022 \u03c6(c)(x, y) is a set of cluster features. These features require access to some dictionary that maps each word in the sentence to an underlying cluster identity. Clusters may for example be learned using the Brown clustering algorithm (Brown et al., 1992). The features may make use of cluster identities in combination with POS tags.\n\u2022 \u03c6(l)(x, y) is a set of lexicalized features. Each such feature may depend directly on word identities in the sentence. These features may also depend on part-of-speech tags or cluster information, in conjunction with lexical information.\nAppendix A has a full description of the features used in our experiments."}, {"heading": "2.2 Data Assumptions", "text": "Throughout this paper we will assume that we have m source languages L1 . . .Lm, and a single target language Lm+1. We assume the following data sources:\nSource language treebanks. We have a treebank Ti for each language i \u2208 {1 . . . m}.\nPart-of-speech (POS) data. We have handannotated POS data for all languages L1 . . .Lm+1. We assume that the data uses a universal POS set that is common across all languages.\nMonolingual data. We have monolingual raw data for each of the (m+1) languages. We use Di to refer to the monolingual data for the i\u2019th language.\nTranslation data. We have translation data for all language pairs. We use Bi,j to refer to translation data for the language pair (i, j) where i, j \u2208 {1 . . . (m+ 1)} and i 6= j.\nIn our main experiments we use the Google universal treebank (McDonald et al., 2013) as our source language treebanks2 (this treebank provides universal dependency relations and POS tags), Wikipedia data as our monolingual data, and the Bible data from Christodouloupoulos and Steedman (2014) as the source of our translation data. In additional experiments we use the Europarl corpus as a source of translation data, in order to measure the impact of using the smaller Bible corpus."}, {"heading": "2.3 A Baseline Approach: Delexicalized Parsers with Self-Training", "text": "Given the data assumption of a universal POS set, the feature vectors \u03c6(p)(x, y) can be shared across languages. A simple approach is then to simply train a delexicalized parser using treebanks T1 . . . Tm, using the representation \u03c6(x, y) = \u03c6(p)(x, y) (see (McDonald et al., 2013; Ta\u0308ckstro\u0308m et al., 2013)).\nOur baseline approach makes use of a delexicalized parser, with two refinements:\nWALS properties. We use the six properties from the world atlas of language structures (WALS) (Dryer and Haspelmath, 2013) to select a subset of\n2We also train our best performing model on the newly released universal treebank v1.3 (Nivre et al., 2016). See \u00a74.3 for more details.\nclosely related languages for each target language. These properties are shown in Table 1. The model for a target language is trained on treebank data from languages where at least 4 out of 6 WALS properties are common between the source and target language.3 This gives a slightly stronger baseline: our experiments showed an improvement in average labeled dependency accuracy for the languages from 62.52% to 63.18%. Table 2 shows the set of source languages used for each target language; these source languages are used for all experiments in the paper.\nSelf-training. We use self-training (McClosky et al., 2006) to further improve parsing performance. Specifically, we first train a delexicalized model on treebanks T1 . . . Tm; then use the resulting model to parse a dataset Tm+1 that includes target-language sentences which have POS tags but do not have dependency structures. We finally use the automatically parsed data T \u2032m+1 as the treebank data and retrain the model; this last model is trained using all features (unlexicalized, clusters, and lexicalized). Self-training in this way gives an improvement in labeled accuracy from 63.18% to 63.91%."}, {"heading": "2.4 Translation Dictionaries", "text": "Our only use of the translation data Bi,j for i, j \u2208 {1 . . . (m + 1)} is to construct a translation dictionary t(w, i, j). Here i and j are two languages, w is a word in language Li, and the output w\u2032 = t(w, i, j) is a word in language Lj corresponding to the most frequent translation of w into this language.\n3There was no effort to optimize this choice; future work may consider more sophisticated sharing schemes.\nWe define the function t(w, i, j) as follows. We first run the GIZA++ alignment process (Och and Ney, 2000) on the data Bi,j . We then keep intersected alignments between sentences in the two languages. Finally, for each word w in Li, we define w\u2032 = t(w, i, j) to be the target language word most frequently aligned to w in the aligned data. If a word w is never seen aligned to a target language word w\u2032, we define t(w, i, j) = NULL.\nFuture work may consider the use of probabilistic lexicons, or hand-crafted lexicons, as an alternative to the method described above."}, {"heading": "3 Our Approach", "text": "This section describes our approach on improving over the baseline delexicalized approach. The following subsections describe our approach: \u00a73.1 describes a method for deriving cross-lingual clusters, allowing us to add cluster features \u03c6(c)(x, y) to the model. \u00a73.2 describes a method for adding lexical features \u03c6(l)(x, y) to the model. \u00a73.3 describes a method for integrating the approach with the density-driven approach of Rasooli and Collins (2015). Finally, \u00a74 describes experiments. We show that each of the above steps leads to improvements in accuracy."}, {"heading": "3.1 Learning Cross-Lingual Clusters", "text": "We now describe a method for learning crosslingual clusters. This follows previous work on cross-lingual clustering algorithms (Ta\u0308ckstro\u0308m et al., 2012). A clustering is a function C(w) that maps\nInputs: 1) Monolingual texts Di for i = 1 . . . (m+ 1); 2) a function t(w, i, j) that translates a word w \u2208 Li to w\u2032 \u2208 Lj ; and 3) a parameter \u03b1 such that 0 < \u03b1 < 1.\neach word w in a vocabulary to a cluster C(w) \u2208 {1 . . . K}, where K is the number of clusters. A hierarchical clustering is a function C(w, l) that maps a word w together with an integer l to a cluster at level l in the hierarchy. As one example, the Brown clustering algorithm (Brown et al., 1992) gives a hierarchical clustering. The level l allows cluster features at different levels of granularity.\nA cross-lingual hierarchical clustering is a function C(w, l) where the clusters are shared across the (m + 1) languages of interest: that is, the word w can be from any of the (m + 1) languages. Ideally, a cross-lingual clustering should put words across different languages which have a similar syntactic and/or semantic role in the same cluster. There is a clear motivation for cross-lingual clustering in the parsing context. We can use the cluster-based features \u03c6(c)(x, y) on the source language treebanks T1 . . . Tm, and these features will now generalize beyond these treebanks to the target language Lm+1.\nWe learn a cross-lingual clustering by leveraging the monolingual data sets D1 . . .Dm+1, together\nwith the translation dictionaries t(w, i, j) learned from the translation data. Figure 1 shows the algorithm that learns a cross-lingual clustering. The algorithm first prepares a multilingual corpus, as follows: for each sentence s in the monolingual data Di, for each word in s, with probability \u03b1 we replace the word with its translation into some randomly chosen language. Once this data is created, we can easily obtain a cross-lingual clustering. Figure 1 shows the complete algorithm. The intuition behind this method is that by creating the crosslingual data in this way, we bias the clustering algorithm towards putting words that are translations of each other in the same cluster."}, {"heading": "3.2 Treebank Lexicalization", "text": "We now describe how to introduce lexical representations \u03c6(l)(x, y) to the model. Our approach is simple: we take the treebank data T1 . . . Tm for the m source languages, together with the translation lexicons t(w, i,m + 1). For any word w in the source treebank data, we can look up its translation t(w, i,m+1) in the lexicon, and add this translated form to the underlying sentence. Features can now consider lexical identities derived in this way. In many cases the resulting translation will be the NULL word. However, we still make use of the representations \u03c6(p)(x, y) and \u03c6(c)(x, y) as previously defined; these representations are useful when the NULL translation is observed.\n3.3 Integration with the Density-Driven Projection Method of Rasooli and Collins (2015)\nIn this section we describe a method for integrating our approach with the cross-lingual transfer method of Rasooli and Collins (2015), which makes use of density-driven projections.\nIn annotation projection methods (Hwa et al., 2005; McDonald et al., 2011), it is assumed that we have translation data Bi,j for a source and target language, and that we have a dependency parser in the source language Li. The translation data consists of pairs (e, f) where e is a source language sentence, and f is a target language sentence. A method such as GIZA++ is used to derive an alignment between the words in e and f , for each sentence pair; the source language parser is used to\nparse e. Each dependency in e is then potentially transferred through the alignments to create a dependency in the target sentence f . Once dependencies have been transferred in this way, a dependency parser can be trained on the dependencies in the target language.\nThe density-driven approach of Rasooli and Collins (2015) makes use of various definitions of \u201cdensity\u201d of the projected dependencies. For example, P100 is the set of projected structures where the projected dependencies form a full projective parse tree for the sentence; P80 is the set of projected structures where at least 80% of the words in the projected structure are a modifier in some dependency. An iterative training process is used, where the parsing algorithm is first trained on the set T100 of complete structures, and where progressively less dense structures are introduced in learning.\nWe integrate our approach with the density-driven approach of Rasooli and Collins (2015) as follows: Consider the treebanks T1 . . . Tm created using the lexicalization method of \u00a73.2. We add all trees in these treebanks to the set P100 of full trees used to initialize the method of Rasooli and Collins (2015). In addition we make use of the representations \u03c6(p), \u03c6(c) and \u03c6(l), throughout the learning process."}, {"heading": "4 Experiments", "text": "This section first describes the experimental settings, then reports results."}, {"heading": "4.1 Data and Tools", "text": "Data In a first set of experiments, we consider the 7 European languages studied in previous work (Ma and Xia, 2014; Zhang and Barzilay, 2015; Guo et al., 2016; Ammar et al., 2016; Lacroix et al., 2016). More specifically, we use the 7 European languages in the Google universal treebank (v.2; standard data) (McDonald et al., 2013). As in previous work, gold part-of-speech tags are used for evaluation. We use the concatenation of the treebank training sentences, Wikipedia data and the Bible monolingual sentences as our monolingual raw text. Table 3 shows statistics for the monolingual data. We use the Bible data from Christodouloupoulos and Steedman (2014), which includes data for 100 languages, as the source of translations. We also con-\nduct experiments with the Europarl data (both with the original size and a subset of it with the same size as the Bible text) to study the effects of translation data size and domain shift. The statistics for translation data is shown in Table 4.\nIn a second set of experiments, we run experiments on 38 datasets (26 languages) in the more recent Universal Dependencies v1.3 corpus (Nivre et al., 2016).4\nBrown Clustering Algorithm We use the off-theshelf Brown clustering tool5 (Liang, 2005) to train monolingual Brown clusters with 500 clusters. The monolingual Brown clusters are used as features over lexicalized values created in \u03c6(l), and in selftraining experiments. We train our cross-lingual clustering with the off-the-shelf-tool6 from Stratos et al. (2015). We set the window size to 2 with cluster size of 500.7\nParsing Model We use the k-beam arc-eager dependency parser of Rasooli and Tetreault (2015), which is similar to the model of Zhang and Nivre (2011). We modify the parser such that it can use both monolingual and cross-lingual word cluster features. The parser is trained using the the maximum violation update strategy (Huang et al., 2012).\n4We excluded languages that are not completely present in the Bible corpus of Christodouloupoulos and Steedman (2014) (Ancient Greek, Basque, Catalan, Galician, Gothic, Irish, Kazakh, Latvian, Old Church Slavonic, and Tamil). We also excluded Arabic, Hebrew, Japanese and Chinese, as these languages have tokenization and/or morphological complexity that goes beyond the scope of this paper. Future work should consider these languages.\n5https://github.com/percyliang/ brown-cluster\n6https://github.com/karlstratos/singular 7Usually the original Brown clusters are better features for parsing but their training procedure does not scale on big datasets. Therefore we use the more efficient algorithm from Stratos et al. (2015) on the larger cross-lingual datasets to obtain word clusters.\nData Lang. en de es fr it pt sv\nBible tokens 1.5M 665K 657K 732K 613K 670K 696K types 16K 20K 27K 22K 29K 29K 23K\nEU-S tokens 718K 686K 753K 799K 717K 739K 645K types 22K 41K 31K 27K 30K 32K 39K\nEuroparl tokens 56M 50M 57M 62M 55M 56M 46M types 133K 400K 195K 153K 188K 200K 366K\nTable 4: Statistics for the Bible, sampled Europarl (EU-S) and Europarl datasets. Each individual Bible text file from Christodouloupoulos and Steedman (2014) consists of 24720 sentences, except for English datasets, where two translations into English are available, giving double the amount of data. Each text file from the sampled Europarl datasets consists of 25K sentences and Europarl has approximately 2 million sentences per language pair.\nWe use three epochs of training for all experiments.\nWord alignment We use the intersected alignments from Giza++ (Och and Ney, 2000) on translation data. We exclude sentences in translation data with more than 100 words."}, {"heading": "4.2 Results on the Google Treebank", "text": "Table 5 shows the dependency parsing accuracy for the baseline delexicalized approach, and for models which add 1) cross-lingual clusters (\u00a73.1); 2) lexical features (\u00a73.2); 3) integration with the densitydriven method of Rasooli and Collins (2015). It can be seen that each of these three steps gives significant improvements in performance. The final LAS/UAS of 73.90/80.28% is several percentage points higher than the baseline accuracy of 63.91/72.94%.\nWe also run experiments with a subset of the Europarl data to see the effect of domain shift. As shown in Table 5, we observe that there is a slight drop in accuracy when we use the Bible data. The main exception is the English language, where the number of translation sentences is twice more than the sampled Europarl sentences.\nComparison to the Density-Driven Approach using Europarl Data Table 6 shows accuracies for the density-driven approach of Rasooli and Collins\n(2015), first using Europarl data8 and second using the Bible data alone (with no cross-lingual clusters or lexicalization). The Bible data is considerably smaller than Europarl (around 100 times smaller), and it can be seen that results using the Bible are several percentage points lower than the results for Europarl (75.75% UAS vs. 81.33% UAS). Integrating cluster and lexicalized features described in the current paper with the density-driven approach closes much of this gap in performance (80.28% UAS). Thus we have demonstrated that we can get close to the performance of the Europarl-based models using only the Bible as a source of translation data. Using our appraoch on the full Europarl data gives an average UAS of 82.95%, an improvement from the 81.33% UAS of Rasooli and Collins (2015).\nTable 6 also shows results when we use a random subset of the Europarl data, where the number of sentences (25,000) is chosen to give a very similar size to the Bible dataset. It can be seen that accuracies using the Bible data vs. Europarl-Sample are very similar (80.28% vs. 80.37% UAS), suggesting that the size of the translation corpus is much more important than the genre.\nComparison to Other Previous Work Table 7 compares the accuracy of our method to the following related work: 1) Zhang and Barzilay (2015), who describe a method that learns cross-lingual embeddings and bilingual dictionaries from Europarl data, and uses these features in a discriminative parsing model; 2) Guo et al. (2016), who describe a method that learns cross-lingual embeddings from Europarl data and uses a shift-reduce neural parser with these representations; 3) Ammar et al. (2016), who use the same embeddings as Guo et al. (2016), within an LSTM-based parser; and 4) Rasooli and Collins (2015) who use the density-driven approach on the Europarl data. Our method gives significant improvements over the first three models, in spite of using the Bible translation data rather than Europarl. When using the Europarl data, our method improves the state-of-the-art model of Rasooli and Collins (2015). It is worth noting that our model significantly outperform the UAS reported in other\n8Rasooli and Collins (2015) do not report results on English. We use the same setting as in their paper to obtain the English results.\nprevious work (McDonald et al., 2011; Ma and Xia, 2014; Lacroix et al., 2016) but we do not put theirs because of space restrictions.\nPerformance with Automatic POS Tags For completeness, Table 8 gives results for our method with automatic part-of-speech tags. Although there is a drop in accuracy when using the automatic POS tags, our model has still a high accuracy even higher than those from the density driven approach of Rasooli and Collins (2015)."}, {"heading": "4.3 Results on the Universal Dependencies v1.3", "text": "Table 9 gives results on 38 datasets (26 languages) from the newly released universal dependencies corpus (Nivre et al., 2016). Given the number of treebanks and to speed up training, we pick source languages that have at least 5 out of 6 common WALS properties with each target language. Our experiments are carried out using the Bible as our translation data. As shown in Table 9, our method consistently outperforms the density-driven method of Rasooli and Collins (2015) and for many languages the accuracy of our method gets close to the accuracy of the supervised parser. Accuracy on some languages (e.g., Persian (fa) and Turkish (tr)) is low, suggesting that future work should consider more powerful techniques for these languages."}, {"heading": "5 Analysis", "text": "We conclude this paper with some examples from the English development data (Figures 3 and 4). We\nfind interesting examples for which our method predicts the correct tree, including some long sentences (Figures 3a and 3b). Except for very short sentences with basic grammatical structures, the baseline parser completely fails to recover the correct structure. In Figure 2, two examples are depicted for which the baseline parser has a very low accuracy while our method is fully accurate. In the first example, the baseline parser attaches the root node to a wrong verb (\u201cplug\u201d instead of \u201cgoes\u201d) and subsequently attaches incorrect dependents. In the first example in Figure 2, the baseline parser cannot find the head of the noun phrase (\u201cdiversified Fidelity funds\u201d). Because of the lack of lexical features, the baseline parser attaches the word \u201cafter\u201d as a prepositional phrase instead of assigning it as a dependent\nfor the adverbial clause (\u201cthey reported earnings\u201d). Figure 3a shows two examples in which the parser trained using the Europarl data is the only model to parse the sentences perfectly. As expected, the baseline parser does a poor job in parsing these sentences. Surprisingly however, the parser from our approach using the Bible data is able to predict the majority of dependencies correctly. In the first example, it has two labeled errors and one punctuation attachment error9 and just one attachment error: it\n9Punctuation is not included in evaluation.\nattaches \u201ctaking\u201d as a conjunction for \u201cstraightening\u201d instead of attaching it as a \u201cparataxis\u201d for the word \u201cseems\u201d. In the second example, there is a prepositional attachment error for the word \u201cabout\u201d and consequently another attachment error because \u201cabout\u201d is not the dependent of \u201cprediction\u201d in that sentence. In general, we can see that the parser trained with the Bible data is able to recover correct dependencies, largely beating the baseline.\nFigure 4 shows an example in which the fully supervised parser is completely accurate but our best parser makes some errors. In this specific example, the word \u201cwhich\u201d has a determiner POS tag and is wrongly attached as a determiner to the next noun, while it should be a prepositional object. To compensate for that, the parser wrongly attaches \u201cCNN\u201d to \u201cunder\u201d as a prepositional object. There is also a labeled attachment error for the word \u201cunder\u201d.\nFrom the above examples, we can conclude that having more translation data helps distinguish between correct and incorrect attachments. Having more accurate projected trees help improve the syntactic ordering, and having more translation data gives rise to the quality of word clusters and lexical features."}, {"heading": "6 Related Work", "text": "There has recently been a great deal of work on syntactic transfer. A number of methods (Zeman and Resnik, 2008; McDonald et al., 2011; Cohen et al., 2011; Naseem et al., 2012; Ta\u0308ckstro\u0308m et al., 2013; Rosa and Zabokrtsky, 2015) directly learn delexicalized models that can be trained on universal treebank data from one or more source languages, then applied to the target language. More recent work\nhas introduced cross-lingual representations \u2013for example cross-lingual word-embeddings\u2013 that can be used to improve performance (Zhang and Barzilay, 2015; Guo et al., 2015; Duong et al., 2015; Guo et al., 2016; Ammar et al., 2016). These crosslingual representations are usually learned from parallel translation data. We show results for the methods of (Zhang and Barzilay, 2015; Guo et al., 2016; Ammar et al., 2016) in Table 7 of this paper.\nThe annotation projection approach, where dependencies from one language are transferred through translation alignments to another language, has been considered by several authors (Hwa et al., 2005; Ganchev et al., 2009; McDonald et al., 2011; Ma and Xia, 2014; Rasooli and Collins, 2015; Lacroix et al., 2016; Agic\u0301 et al., 2016). The work of Rasooli and Collins (2015) gives the best results of these methods on the Europarl data, as shown in Table 7.\nOther recent work (Tiedemann et al., 2014; Tiedemann, 2015; Tiedemann and Agic\u0301, 2016) has considered treebank translation, where a statistical machine translation system (e.g., MOSES (Koehn et al., 2007)) is used to translate a source language treebank into the target language, complete with reordering of the input sentence. The lexicalization approach described in this paper is a simple form of treebank translation, where we use a word-to-word translation model. In spite of its simplicity, it is a very effective approach.\nA number of authors have considered incorporating universal syntactic properties such as dependency order by selectively learning syntactic attributes from similar source languages (Naseem et al., 2012; Ta\u0308ckstro\u0308m et al., 2013; Zhang and Barzilay, 2015; Ammar et al., 2016). Selective sharing of syntactic properties is complementary to our work; we used a very limited form of selective sharing, through the WALS properties, in our baseline approach.\nA number of authors (Ta\u0308ckstro\u0308m et al., 2012; Guo et al., 2015; Guo et al., 2016) have introduced methods that learn cross-lingual representations that are then used in syntactic transfer. Most of these approaches introduce constraints to a clustering or embedding algorithm that encourage words that are translations of each other to have similar representations. Our method of deriving a cross-lingual corpus\n(see Figure 1) which is then used as input to a clustering algorithm is closely related to (Duong et al., 2015; Gouws and S\u00f8gaard, 2015; Wick et al., 2015)."}, {"heading": "7 Conclusions", "text": "We have described a method for cross-lingual syntactic transfer that is effective in the scenario where a large amount of translation data is not available. We have introduced a simple, direct method for deriving cross-lingual clusters, and for transferring lexical information across treebanks for different languages. Experiments with the method show that the method gives improved performance over previous work that makes use of Europarl, a much larger translation corpus."}, {"heading": "Appendix A Parsing Features", "text": "We used all features in (Zhang and Nivre, 2011, Table 1 and 2), which describes features based on the word and part-of-speech at various positions on the stack and buffer of the transition system. In addition, we expand the Zhang and Nivre (2011, Table 1) features to include clusters, as follows: whenever a feature tests the part-of-speech for a word in position 0 of the stack or buffer, we introduce features that replace the part-of-speech with the Brown clustering bit-string of length 4 and 6. Whenever a feature tests for the word identity at position 0 of the stack or buffer, we introduce a cluster feature that replaces the word with the full cluster feature. We take the cross product of all features corresponding to the choice of 4 or 6 length bit string for part-ofspeech features."}], "references": [{"title": "Multilingual projection for parsing truly low-resource languages. Transactions of the Association for Computational Linguistics", "author": ["\u017deljko Agi\u0107", "Anders Johannsen", "Barbara Plank", "H\u00e9ctor Alonso Mart\u0131\u0301nez", "Natalie Schluter", "Anders S\u00f8gaard"], "venue": null, "citeRegEx": "Agi\u0107 et al\\.,? \\Q2016\\E", "shortCiteRegEx": "Agi\u0107 et al\\.", "year": 2016}, {"title": "One parser, many languages", "author": ["Waleed Ammar", "George Mulcaire", "Miguel Ballesteros", "Chris Dyer", "Noah A Smith."], "venue": "arXiv preprint arXiv:1602.01595.", "citeRegEx": "Ammar et al\\.,? 2016", "shortCiteRegEx": "Ammar et al\\.", "year": 2016}, {"title": "Classbased n-gram models of natural language", "author": ["Peter F Brown", "Peter V Desouza", "Robert L Mercer", "Vincent J Della Pietra", "Jenifer C Lai."], "venue": "Computational linguistics, 18(4):467\u2013479.", "citeRegEx": "Brown et al\\.,? 1992", "shortCiteRegEx": "Brown et al\\.", "year": 1992}, {"title": "A massively parallel corpus: the bible in 100 languages", "author": ["Christos Christodouloupoulos", "Mark Steedman."], "venue": "Language Resources and Evaluation, pages 1\u201321.", "citeRegEx": "Christodouloupoulos and Steedman.,? 2014", "shortCiteRegEx": "Christodouloupoulos and Steedman.", "year": 2014}, {"title": "Unsupervised structure prediction with non-parallel multilingual guidance", "author": ["Shay B. Cohen", "Dipanjan Das", "Noah A. Smith."], "venue": "Proceedings of the 2011 Conference on Empirical Methods in Natural Language Processing, pages 50\u201361, Edinburgh, Scotland,", "citeRegEx": "Cohen et al\\.,? 2011", "shortCiteRegEx": "Cohen et al\\.", "year": 2011}, {"title": "Discriminative training methods for hidden markov models: Theory and experiments with perceptron algorithms", "author": ["Michael Collins."], "venue": "Proceedings of the 2002 Conference on Empirical Methods in Natural Language Processing, pages 1\u20138. Association for", "citeRegEx": "Collins.,? 2002", "shortCiteRegEx": "Collins.", "year": 2002}, {"title": "Cross-lingual transfer for unsupervised dependency parsing without parallel data", "author": ["Long Duong", "Trevor Cohn", "Steven Bird", "Paul Cook."], "venue": "Proceedings of the Nineteenth Conference on Computational Natural Language Learning, pages 113\u2013122, Beijing, China,", "citeRegEx": "Duong et al\\.,? 2015", "shortCiteRegEx": "Duong et al\\.", "year": 2015}, {"title": "Syntactic transfer using a bilingual lexicon", "author": ["Greg Durrett", "Adam Pauls", "Dan Klein."], "venue": "Proceedings of the 2012 Joint Conference on Empirical Methods in Natural Language Processing and Computational Natural Language Learning, pages 1\u201311, Jeju Island,", "citeRegEx": "Durrett et al\\.,? 2012", "shortCiteRegEx": "Durrett et al\\.", "year": 2012}, {"title": "Dependency grammar induction via bitext projection constraints", "author": ["Kuzman Ganchev", "Jennifer Gillenwater", "Ben Taskar."], "venue": "Proceedings of the Joint Conference of the 47th Annual Meeting of the ACL and the 4th International Joint Conference on Natural Lan-", "citeRegEx": "Ganchev et al\\.,? 2009", "shortCiteRegEx": "Ganchev et al\\.", "year": 2009}, {"title": "Simple taskspecific bilingual word embeddings", "author": ["Stephan Gouws", "Anders S\u00f8gaard."], "venue": "Proceedings of the 2015 Conference of the North American Chapter of the Association for Computational Linguistics: Human Language Technologies, pages 1386\u20131390, Den-", "citeRegEx": "Gouws and S\u00f8gaard.,? 2015", "shortCiteRegEx": "Gouws and S\u00f8gaard.", "year": 2015}, {"title": "Cross-lingual dependency parsing based on distributed representations", "author": ["Jiang Guo", "Wanxiang Che", "David Yarowsky", "Haifeng Wang", "Ting Liu."], "venue": "Proceedings of the 53rd Annual Meeting of the Association for Computational Linguistics and the 7th Inter-", "citeRegEx": "Guo et al\\.,? 2015", "shortCiteRegEx": "Guo et al\\.", "year": 2015}, {"title": "A representation learning framework for multi-source transfer parsing", "author": ["Jiang Guo", "Wanxiang Che", "David Yarowsky", "Haifeng Wang", "Ting Liu."], "venue": "The Thirtieth AAAI Conference on Artificial Intelligence (AAAI-16), Phoenix, Arizona, USA.", "citeRegEx": "Guo et al\\.,? 2016", "shortCiteRegEx": "Guo et al\\.", "year": 2016}, {"title": "Structured perceptron with inexact search", "author": ["Liang Huang", "Suphan Fayong", "Yang Guo."], "venue": "Proceedings of the 2012 Conference of the North American Chapter of the Association for Computational Linguistics: Human Language Technologies, pages 142\u2013", "citeRegEx": "Huang et al\\.,? 2012", "shortCiteRegEx": "Huang et al\\.", "year": 2012}, {"title": "Bootstrapping parsers via syntactic projection across parallel texts", "author": ["Rebecca Hwa", "Philip Resnik", "Amy Weinberg", "Clara Cabezas", "Okan Kolak."], "venue": "Natural language engineering, 11(03):311\u2013325.", "citeRegEx": "Hwa et al\\.,? 2005", "shortCiteRegEx": "Hwa et al\\.", "year": 2005}, {"title": "Moses: Open source toolkit for statistical machine translation", "author": ["Philipp Koehn", "Hieu Hoang", "Alexandra Birch", "Chris Callison-Burch", "Marcello Federico", "Nicola Bertoldi", "Brooke Cowan", "Wade Shen", "Christine Moran", "Richard Zens"], "venue": null, "citeRegEx": "Koehn et al\\.,? \\Q2007\\E", "shortCiteRegEx": "Koehn et al\\.", "year": 2007}, {"title": "Europarl: A parallel corpus for statistical machine translation", "author": ["Philipp Koehn."], "venue": "MT summit, volume 5, pages 79\u201386.", "citeRegEx": "Koehn.,? 2005", "shortCiteRegEx": "Koehn.", "year": 2005}, {"title": "Frustratingly easy cross-lingual transfer for transition-based dependency parsing", "author": ["Oph\u00e9lie Lacroix", "Lauriane Aufrant", "Guillaume Wisniewski", "Fran\u00e7ois Yvon."], "venue": "Proceedings of the 2016 Conference of the North American Chapter of the Association for Com-", "citeRegEx": "Lacroix et al\\.,? 2016", "shortCiteRegEx": "Lacroix et al\\.", "year": 2016}, {"title": "Semi-supervised learning for natural language", "author": ["Percy Liang."], "venue": "Ph.D. thesis, Massachusetts Institute of Technology.", "citeRegEx": "Liang.,? 2005", "shortCiteRegEx": "Liang.", "year": 2005}, {"title": "Unsupervised dependency parsing with transferring distribution via parallel guidance and entropy regularization", "author": ["Xuezhe Ma", "Fei Xia."], "venue": "Proceedings of the 52nd Annual Meeting of the Association for Computational Linguistics (Volume 1: Long Papers),", "citeRegEx": "Ma and Xia.,? 2014", "shortCiteRegEx": "Ma and Xia.", "year": 2014}, {"title": "Effective self-training for parsing", "author": ["David McClosky", "Eugene Charniak", "Mark Johnson."], "venue": "Proceedings of the Main Conference on Human Language Technology Conference of the North American Chapter of the Association of Computational Linguistics,", "citeRegEx": "McClosky et al\\.,? 2006", "shortCiteRegEx": "McClosky et al\\.", "year": 2006}, {"title": "Multi-source transfer of delexicalized dependency parsers", "author": ["Ryan McDonald", "Slav Petrov", "Keith Hall."], "venue": "Proceedings of the 2011 Conference on Empirical Methods in Natural Language Processing, pages 62\u201372, Edinburgh, Scotland, UK., July. Associ-", "citeRegEx": "McDonald et al\\.,? 2011", "shortCiteRegEx": "McDonald et al\\.", "year": 2011}, {"title": "Selective sharing for multilingual dependency parsing", "author": ["Tahira Naseem", "Regina Barzilay", "Amir Globerson."], "venue": "Proceedings of the 50th Annual Meeting of the Association for Computational Linguistics: Long Papers-Volume 1, pages 629\u2013637. Association", "citeRegEx": "Naseem et al\\.,? 2012", "shortCiteRegEx": "Naseem et al\\.", "year": 2012}, {"title": "Universal dependencies 1.3. LINDAT/CLARIN digital library", "author": ["Gertjan van Noord", "Viktor Varga", "Veronika Vincze", "Jing Xian Wang", "Jonathan North Washington", "Zden\u011bk \u017dabokrtsk\u00fd", "Daniel Zeman", "Hanzhi Zhu"], "venue": null, "citeRegEx": "Noord et al\\.,? \\Q2016\\E", "shortCiteRegEx": "Noord et al\\.", "year": 2016}, {"title": "Giza++: Training of statistical translation models", "author": ["Franz Josef Och", "Hermann Ney"], "venue": null, "citeRegEx": "Och and Ney.,? \\Q2000\\E", "shortCiteRegEx": "Och and Ney.", "year": 2000}, {"title": "Density-driven cross-lingual transfer of dependency parsers", "author": ["Mohammad Sadegh Rasooli", "Michael Collins."], "venue": "Proceedings of the 2015 Conference on Empirical Methods in Natural Language Processing, pages 328\u2013338, Lisbon, Portugal, September. Associ-", "citeRegEx": "Rasooli and Collins.,? 2015", "shortCiteRegEx": "Rasooli and Collins.", "year": 2015}, {"title": "Yara parser: A fast and accurate dependency parser", "author": ["Mohammad Sadegh Rasooli", "Joel Tetreault."], "venue": "arXiv preprint arXiv:1503.06733.", "citeRegEx": "Rasooli and Tetreault.,? 2015", "shortCiteRegEx": "Rasooli and Tetreault.", "year": 2015}, {"title": "Klcpos3 a language similarity measure for delexicalized parser transfer", "author": ["Rudolf Rosa", "Zdenek Zabokrtsky."], "venue": "Proceedings of the 53rd Annual Meeting of the Association for Computational Linguistics and the 7th International Joint Conference on Natural", "citeRegEx": "Rosa and Zabokrtsky.,? 2015", "shortCiteRegEx": "Rosa and Zabokrtsky.", "year": 2015}, {"title": "Model-based word embeddings from decompositions of count matrices", "author": ["Karl Stratos", "Michael Collins", "Daniel Hsu."], "venue": "Proceedings of the 53rd Annual Meeting of the Association for Computational Linguistics and the 7th International Joint Conference on Nat-", "citeRegEx": "Stratos et al\\.,? 2015", "shortCiteRegEx": "Stratos et al\\.", "year": 2015}, {"title": "Cross-lingual word clusters for direct transfer of linguistic structure", "author": ["Oscar T\u00e4ckstr\u00f6m", "Ryan McDonald", "Jakob Uszkoreit."], "venue": "Proceedings of the 2012 conference of the North American chapter of the association for computational linguistics: Human language", "citeRegEx": "T\u00e4ckstr\u00f6m et al\\.,? 2012", "shortCiteRegEx": "T\u00e4ckstr\u00f6m et al\\.", "year": 2012}, {"title": "Target language adaptation of discriminative transfer parsers", "author": ["Oscar T\u00e4ckstr\u00f6m", "Ryan McDonald", "Joakim Nivre."], "venue": "Transactions for ACL.", "citeRegEx": "T\u00e4ckstr\u00f6m et al\\.,? 2013", "shortCiteRegEx": "T\u00e4ckstr\u00f6m et al\\.", "year": 2013}, {"title": "Synthetic treebanking for cross-lingual dependency parsing", "author": ["J\u00f6rg Tiedemann", "\u017deljko Agi\u0107."], "venue": "Journal of Artificial Intelligence Research, 55:209\u2013248.", "citeRegEx": "Tiedemann and Agi\u0107.,? 2016", "shortCiteRegEx": "Tiedemann and Agi\u0107.", "year": 2016}, {"title": "Treebank translation for cross-lingual parser induction", "author": ["J\u00f6rg Tiedemann", "\u017deljko Agi\u0107", "Joakim Nivre."], "venue": "Proceedings of the Eighteenth Conference", "citeRegEx": "Tiedemann et al\\.,? 2014", "shortCiteRegEx": "Tiedemann et al\\.", "year": 2014}, {"title": "Improving the cross-lingual pro", "author": ["J\u00f6rg Tiedemann"], "venue": null, "citeRegEx": "Tiedemann.,? \\Q2015\\E", "shortCiteRegEx": "Tiedemann.", "year": 2015}], "referenceMentions": [{"referenceID": 24, "context": "Experiments show improvements over the state-of-the-art in several languages used in previous work (Rasooli and Collins, 2015; Zhang and Barzilay, 2015; Ammar et al., 2016), in a setting where the only source of translation data is the Bible, a considerably smaller corpus than the Europarl corpus used in previous work.", "startOffset": 99, "endOffset": 172}, {"referenceID": 1, "context": "Experiments show improvements over the state-of-the-art in several languages used in previous work (Rasooli and Collins, 2015; Zhang and Barzilay, 2015; Ammar et al., 2016), in a setting where the only source of translation data is the Bible, a considerably smaller corpus than the Europarl corpus used in previous work.", "startOffset": 99, "endOffset": 172}, {"referenceID": 4, "context": "The method makes use of three steps: 1) a method for deriving cross-lingual word clusters, that can then be used in a multilingual parser; 2) a method for transferring lexical information from a target language to source language treebanks; 3) a method for integrating these steps with the density-driven annotation projection method of Rasooli and Collins (2015). Experiments show improvements over the state-of-the-art in several languages used in previous work (Rasooli and Collins, 2015; Zhang and Barzilay, 2015; Ammar et al.", "startOffset": 349, "endOffset": 364}, {"referenceID": 1, "context": "Experiments show improvements over the state-of-the-art in several languages used in previous work (Rasooli and Collins, 2015; Zhang and Barzilay, 2015; Ammar et al., 2016), in a setting where the only source of translation data is the Bible, a considerably smaller corpus than the Europarl corpus used in previous work. Results using the Europarl corpus as a source of translation data show additional improvements over the results of Rasooli and Collins (2015). We conclude with results on 38 datasets (26 languages) from the Universal Dependencies corpora: 13 datasets (10 languages) have unlabeled attachment accuracies of 80% or higher; the average unlabeled accuracy on the 38 datasets is 74.", "startOffset": 153, "endOffset": 463}, {"referenceID": 13, "context": "Methods for syntactic transfer include annotation projection methods (Hwa et al., 2005; Ganchev et al., 2009; McDonald et al., 2011; Ma and Xia, 2014; Rasooli and Collins, 2015; Lacroix et al., 2016; Agi\u0107 et al., 2016), learning of delexicalized models on universal treebanks (Zeman and Resnik, 2008; McDonald et al.", "startOffset": 69, "endOffset": 218}, {"referenceID": 8, "context": "Methods for syntactic transfer include annotation projection methods (Hwa et al., 2005; Ganchev et al., 2009; McDonald et al., 2011; Ma and Xia, 2014; Rasooli and Collins, 2015; Lacroix et al., 2016; Agi\u0107 et al., 2016), learning of delexicalized models on universal treebanks (Zeman and Resnik, 2008; McDonald et al.", "startOffset": 69, "endOffset": 218}, {"referenceID": 20, "context": "Methods for syntactic transfer include annotation projection methods (Hwa et al., 2005; Ganchev et al., 2009; McDonald et al., 2011; Ma and Xia, 2014; Rasooli and Collins, 2015; Lacroix et al., 2016; Agi\u0107 et al., 2016), learning of delexicalized models on universal treebanks (Zeman and Resnik, 2008; McDonald et al.", "startOffset": 69, "endOffset": 218}, {"referenceID": 18, "context": "Methods for syntactic transfer include annotation projection methods (Hwa et al., 2005; Ganchev et al., 2009; McDonald et al., 2011; Ma and Xia, 2014; Rasooli and Collins, 2015; Lacroix et al., 2016; Agi\u0107 et al., 2016), learning of delexicalized models on universal treebanks (Zeman and Resnik, 2008; McDonald et al.", "startOffset": 69, "endOffset": 218}, {"referenceID": 24, "context": "Methods for syntactic transfer include annotation projection methods (Hwa et al., 2005; Ganchev et al., 2009; McDonald et al., 2011; Ma and Xia, 2014; Rasooli and Collins, 2015; Lacroix et al., 2016; Agi\u0107 et al., 2016), learning of delexicalized models on universal treebanks (Zeman and Resnik, 2008; McDonald et al.", "startOffset": 69, "endOffset": 218}, {"referenceID": 16, "context": "Methods for syntactic transfer include annotation projection methods (Hwa et al., 2005; Ganchev et al., 2009; McDonald et al., 2011; Ma and Xia, 2014; Rasooli and Collins, 2015; Lacroix et al., 2016; Agi\u0107 et al., 2016), learning of delexicalized models on universal treebanks (Zeman and Resnik, 2008; McDonald et al.", "startOffset": 69, "endOffset": 218}, {"referenceID": 0, "context": "Methods for syntactic transfer include annotation projection methods (Hwa et al., 2005; Ganchev et al., 2009; McDonald et al., 2011; Ma and Xia, 2014; Rasooli and Collins, 2015; Lacroix et al., 2016; Agi\u0107 et al., 2016), learning of delexicalized models on universal treebanks (Zeman and Resnik, 2008; McDonald et al.", "startOffset": 69, "endOffset": 218}, {"referenceID": 20, "context": ", 2016), learning of delexicalized models on universal treebanks (Zeman and Resnik, 2008; McDonald et al., 2011; T\u00e4ckstr\u00f6m et al., 2013; Rosa and Zabokrtsky, 2015), treebank translation (Tiedemann et al.", "startOffset": 65, "endOffset": 163}, {"referenceID": 29, "context": ", 2016), learning of delexicalized models on universal treebanks (Zeman and Resnik, 2008; McDonald et al., 2011; T\u00e4ckstr\u00f6m et al., 2013; Rosa and Zabokrtsky, 2015), treebank translation (Tiedemann et al.", "startOffset": 65, "endOffset": 163}, {"referenceID": 26, "context": ", 2016), learning of delexicalized models on universal treebanks (Zeman and Resnik, 2008; McDonald et al., 2011; T\u00e4ckstr\u00f6m et al., 2013; Rosa and Zabokrtsky, 2015), treebank translation (Tiedemann et al.", "startOffset": 65, "endOffset": 163}, {"referenceID": 31, "context": ", 2013; Rosa and Zabokrtsky, 2015), treebank translation (Tiedemann et al., 2014; Tiedemann, 2015; Tiedemann and Agi\u0107, 2016) and methods that leverage cross-lingual representations of word clusters, embeddings or dictionaries (T\u00e4ckstr\u00f6m et al.", "startOffset": 57, "endOffset": 124}, {"referenceID": 32, "context": ", 2013; Rosa and Zabokrtsky, 2015), treebank translation (Tiedemann et al., 2014; Tiedemann, 2015; Tiedemann and Agi\u0107, 2016) and methods that leverage cross-lingual representations of word clusters, embeddings or dictionaries (T\u00e4ckstr\u00f6m et al.", "startOffset": 57, "endOffset": 124}, {"referenceID": 30, "context": ", 2013; Rosa and Zabokrtsky, 2015), treebank translation (Tiedemann et al., 2014; Tiedemann, 2015; Tiedemann and Agi\u0107, 2016) and methods that leverage cross-lingual representations of word clusters, embeddings or dictionaries (T\u00e4ckstr\u00f6m et al.", "startOffset": 57, "endOffset": 124}, {"referenceID": 28, "context": ", 2014; Tiedemann, 2015; Tiedemann and Agi\u0107, 2016) and methods that leverage cross-lingual representations of word clusters, embeddings or dictionaries (T\u00e4ckstr\u00f6m et al., 2012; Durrett et al., 2012; Duong et al., 2015; Zhang and Barzilay, 2015; Xiao and Guo, 2015; Guo et al., 2015; Guo et al., 2016; Ammar et al., 2016).", "startOffset": 152, "endOffset": 320}, {"referenceID": 7, "context": ", 2014; Tiedemann, 2015; Tiedemann and Agi\u0107, 2016) and methods that leverage cross-lingual representations of word clusters, embeddings or dictionaries (T\u00e4ckstr\u00f6m et al., 2012; Durrett et al., 2012; Duong et al., 2015; Zhang and Barzilay, 2015; Xiao and Guo, 2015; Guo et al., 2015; Guo et al., 2016; Ammar et al., 2016).", "startOffset": 152, "endOffset": 320}, {"referenceID": 6, "context": ", 2014; Tiedemann, 2015; Tiedemann and Agi\u0107, 2016) and methods that leverage cross-lingual representations of word clusters, embeddings or dictionaries (T\u00e4ckstr\u00f6m et al., 2012; Durrett et al., 2012; Duong et al., 2015; Zhang and Barzilay, 2015; Xiao and Guo, 2015; Guo et al., 2015; Guo et al., 2016; Ammar et al., 2016).", "startOffset": 152, "endOffset": 320}, {"referenceID": 10, "context": ", 2014; Tiedemann, 2015; Tiedemann and Agi\u0107, 2016) and methods that leverage cross-lingual representations of word clusters, embeddings or dictionaries (T\u00e4ckstr\u00f6m et al., 2012; Durrett et al., 2012; Duong et al., 2015; Zhang and Barzilay, 2015; Xiao and Guo, 2015; Guo et al., 2015; Guo et al., 2016; Ammar et al., 2016).", "startOffset": 152, "endOffset": 320}, {"referenceID": 11, "context": ", 2014; Tiedemann, 2015; Tiedemann and Agi\u0107, 2016) and methods that leverage cross-lingual representations of word clusters, embeddings or dictionaries (T\u00e4ckstr\u00f6m et al., 2012; Durrett et al., 2012; Duong et al., 2015; Zhang and Barzilay, 2015; Xiao and Guo, 2015; Guo et al., 2015; Guo et al., 2016; Ammar et al., 2016).", "startOffset": 152, "endOffset": 320}, {"referenceID": 1, "context": ", 2014; Tiedemann, 2015; Tiedemann and Agi\u0107, 2016) and methods that leverage cross-lingual representations of word clusters, embeddings or dictionaries (T\u00e4ckstr\u00f6m et al., 2012; Durrett et al., 2012; Duong et al., 2015; Zhang and Barzilay, 2015; Xiao and Guo, 2015; Guo et al., 2015; Guo et al., 2016; Ammar et al., 2016).", "startOffset": 152, "endOffset": 320}, {"referenceID": 15, "context": "The Bible data contains a much smaller set of sentences (around 24,000) than other translation corpora, for example Europarl (Koehn, 2005), which has around 2 million sentences per language", "startOffset": 125, "endOffset": 138}, {"referenceID": 3, "context": "lation data because it is available for a very broad set of languages: the data from Christodouloupoulos and Steedman (2014) includes data from 100 languages.", "startOffset": 85, "endOffset": 125}, {"referenceID": 24, "context": "\u2022 We describe a method that integrates the above two approaches with the density-driven approach to annotation projection described in (Rasooli and Collins, 2015).", "startOffset": 135, "endOffset": 162}, {"referenceID": 17, "context": "Experiments show that our model outperforms previous work on a set of European languages from the Google universal treebank (McDonald et al., 2013): we achieve 80.9% average unlabeled attachment score (UAS) on these languages; in comparison the work of Zhang and Barzilay (2015), Guo et al.", "startOffset": 125, "endOffset": 279}, {"referenceID": 9, "context": "9% average unlabeled attachment score (UAS) on these languages; in comparison the work of Zhang and Barzilay (2015), Guo et al. (2016) and Ammar et al.", "startOffset": 117, "endOffset": 135}, {"referenceID": 1, "context": "(2016) and Ammar et al. (2016) have UAS of 75.", "startOffset": 11, "endOffset": 31}, {"referenceID": 15, "context": "these previous works make use of the much larger Europarl (Koehn, 2005) corpus to derive lexical", "startOffset": 58, "endOffset": 71}, {"referenceID": 24, "context": "68% absolute improvements over (Rasooli and Collins, 2015).", "startOffset": 31, "endOffset": 58}, {"referenceID": 5, "context": "68% absolute improvements over (Rasooli and Collins, 2015). Finally, we conduct experiments on 38 datasets (26 languages) in the universal dependencies v1.3 (Nivre et al., 2016) corpus. Our method has an average unlabeled dependency accuracy of 74.8% for these languages, compared to an average accuracy of 68.1% for the method of Rasooli and Collins (2015). 13 datasets (10 languages) have accuracies higher than 80.", "startOffset": 44, "endOffset": 358}, {"referenceID": 5, "context": "The parser is trained using the averaged structured perceptron (Collins, 2002).", "startOffset": 63, "endOffset": 78}, {"referenceID": 24, "context": "In our experiments we use the shift-reduce dependency parser of Rasooli and Tetreault (2015), which is an extension of the approach in (Zhang and Nivre, 2011).", "startOffset": 64, "endOffset": 93}, {"referenceID": 2, "context": "Clusters may for example be learned using the Brown clustering algorithm (Brown et al., 1992).", "startOffset": 73, "endOffset": 93}, {"referenceID": 3, "context": ", 2013) as our source language treebanks2 (this treebank provides universal dependency relations and POS tags), Wikipedia data as our monolingual data, and the Bible data from Christodouloupoulos and Steedman (2014) as the source of our translation data.", "startOffset": 176, "endOffset": 216}, {"referenceID": 29, "context": "Tm, using the representation \u03c6(x, y) = \u03c6(p)(x, y) (see (McDonald et al., 2013; T\u00e4ckstr\u00f6m et al., 2013)).", "startOffset": 55, "endOffset": 102}, {"referenceID": 19, "context": "We use self-training (McClosky et al., 2006) to further improve parsing performance.", "startOffset": 21, "endOffset": 44}, {"referenceID": 23, "context": "We first run the GIZA++ alignment process (Och and Ney, 2000) on the data Bi,j .", "startOffset": 42, "endOffset": 61}, {"referenceID": 28, "context": "cross-lingual clustering algorithms (T\u00e4ckstr\u00f6m et al., 2012).", "startOffset": 36, "endOffset": 60}, {"referenceID": 27, "context": "Use the algorithm of Stratos et al. (2015) on D to learn a clustering C.", "startOffset": 21, "endOffset": 43}, {"referenceID": 2, "context": "As one example, the Brown clustering algorithm (Brown et al., 1992) gives a hierarchical clustering.", "startOffset": 47, "endOffset": 67}, {"referenceID": 5, "context": "3 Integration with the Density-Driven Projection Method of Rasooli and Collins (2015)", "startOffset": 71, "endOffset": 86}, {"referenceID": 5, "context": "of Rasooli and Collins (2015), which makes use of density-driven projections.", "startOffset": 15, "endOffset": 30}, {"referenceID": 13, "context": "In annotation projection methods (Hwa et al., 2005; McDonald et al., 2011), it is assumed that we have translation data Bi,j for a source and target language, and that we have a dependency parser in the source language Li.", "startOffset": 33, "endOffset": 74}, {"referenceID": 20, "context": "In annotation projection methods (Hwa et al., 2005; McDonald et al., 2011), it is assumed that we have translation data Bi,j for a source and target language, and that we have a dependency parser in the source language Li.", "startOffset": 33, "endOffset": 74}, {"referenceID": 5, "context": "The density-driven approach of Rasooli and Collins (2015) makes use of various definitions of \u201cdensity\u201d of the projected dependencies.", "startOffset": 43, "endOffset": 58}, {"referenceID": 5, "context": "We integrate our approach with the density-driven approach of Rasooli and Collins (2015) as follows: Consider the treebanks T1 .", "startOffset": 74, "endOffset": 89}, {"referenceID": 5, "context": "We integrate our approach with the density-driven approach of Rasooli and Collins (2015) as follows: Consider the treebanks T1 . . . Tm created using the lexicalization method of \u00a73.2. We add all trees in these treebanks to the set P100 of full trees used to initialize the method of Rasooli and Collins (2015). In addition we make use of the representations \u03c6(p), \u03c6(c) and \u03c6(l), throughout the learning process.", "startOffset": 74, "endOffset": 311}, {"referenceID": 18, "context": "Data In a first set of experiments, we consider the 7 European languages studied in previous work (Ma and Xia, 2014; Zhang and Barzilay, 2015; Guo et al., 2016; Ammar et al., 2016; Lacroix et al., 2016).", "startOffset": 98, "endOffset": 202}, {"referenceID": 11, "context": "Data In a first set of experiments, we consider the 7 European languages studied in previous work (Ma and Xia, 2014; Zhang and Barzilay, 2015; Guo et al., 2016; Ammar et al., 2016; Lacroix et al., 2016).", "startOffset": 98, "endOffset": 202}, {"referenceID": 1, "context": "Data In a first set of experiments, we consider the 7 European languages studied in previous work (Ma and Xia, 2014; Zhang and Barzilay, 2015; Guo et al., 2016; Ammar et al., 2016; Lacroix et al., 2016).", "startOffset": 98, "endOffset": 202}, {"referenceID": 16, "context": "Data In a first set of experiments, we consider the 7 European languages studied in previous work (Ma and Xia, 2014; Zhang and Barzilay, 2015; Guo et al., 2016; Ammar et al., 2016; Lacroix et al., 2016).", "startOffset": 98, "endOffset": 202}, {"referenceID": 3, "context": "We use the Bible data from Christodouloupoulos and Steedman (2014), which includes data for 100 languages, as the source of translations.", "startOffset": 27, "endOffset": 67}, {"referenceID": 17, "context": "Brown Clustering Algorithm We use the off-theshelf Brown clustering tool5 (Liang, 2005) to train monolingual Brown clusters with 500 clusters.", "startOffset": 74, "endOffset": 87}, {"referenceID": 17, "context": "Brown Clustering Algorithm We use the off-theshelf Brown clustering tool5 (Liang, 2005) to train monolingual Brown clusters with 500 clusters. The monolingual Brown clusters are used as features over lexicalized values created in \u03c6(l), and in selftraining experiments. We train our cross-lingual clustering with the off-the-shelf-tool6 from Stratos et al. (2015). We set the window size to 2 with cluster size of 500.", "startOffset": 75, "endOffset": 363}, {"referenceID": 12, "context": "The parser is trained using the the maximum violation update strategy (Huang et al., 2012).", "startOffset": 70, "endOffset": 90}, {"referenceID": 24, "context": "Parsing Model We use the k-beam arc-eager dependency parser of Rasooli and Tetreault (2015), which is similar to the model of Zhang and Nivre (2011).", "startOffset": 63, "endOffset": 92}, {"referenceID": 24, "context": "Parsing Model We use the k-beam arc-eager dependency parser of Rasooli and Tetreault (2015), which is similar to the model of Zhang and Nivre (2011). We modify the parser such that it can use both monolingual and cross-lingual word cluster features.", "startOffset": 63, "endOffset": 149}, {"referenceID": 3, "context": "We excluded languages that are not completely present in the Bible corpus of Christodouloupoulos and Steedman (2014) (Ancient Greek, Basque, Catalan, Galician, Gothic, Irish, Kazakh, Latvian, Old Church Slavonic, and Tamil).", "startOffset": 77, "endOffset": 117}, {"referenceID": 27, "context": "Therefore we use the more efficient algorithm from Stratos et al. (2015) on the larger cross-lingual datasets to obtain word clusters.", "startOffset": 51, "endOffset": 73}, {"referenceID": 3, "context": "Each individual Bible text file from Christodouloupoulos and Steedman (2014) consists of 24720 sentences, except for English datasets, where two translations into English are available, giving double the amount of data.", "startOffset": 37, "endOffset": 77}, {"referenceID": 23, "context": "Word alignment We use the intersected alignments from Giza++ (Och and Ney, 2000) on translation data.", "startOffset": 61, "endOffset": 80}, {"referenceID": 5, "context": "2); 3) integration with the densitydriven method of Rasooli and Collins (2015). It can be seen that each of these three steps gives", "startOffset": 64, "endOffset": 79}, {"referenceID": 4, "context": "\u201cDensity\u201d refers to the method of Rasooli and Collins (2015); \u201cThis paper\u201d gives results using the methods described in sections 3.", "startOffset": 46, "endOffset": 61}, {"referenceID": 3, "context": "The \u201cBible\u201d experiments use the Bible data of Christodouloupoulos and Steedman (2014). The \u201cEuroparl\u201d experiments use the Europarl data of Koehn (2005).", "startOffset": 46, "endOffset": 86}, {"referenceID": 3, "context": "The \u201cBible\u201d experiments use the Bible data of Christodouloupoulos and Steedman (2014). The \u201cEuroparl\u201d experiments use the Europarl data of Koehn (2005). The \u201cEuroparl-Sample\u201d experiments use 25K randomly chosen sentences from Europarl; this gives a similar number of sentences to the Bible data.", "startOffset": 46, "endOffset": 152}, {"referenceID": 11, "context": "Barzilay, 2015), GCY16 (Guo et al., 2016), AMB 16 (Ammar et al.", "startOffset": 23, "endOffset": 41}, {"referenceID": 1, "context": ", 2016), AMB 16 (Ammar et al., 2016), and RC15 (Rasooli and Collins, 2015).", "startOffset": 16, "endOffset": 36}, {"referenceID": 24, "context": ", 2016), and RC15 (Rasooli and Collins, 2015).", "startOffset": 18, "endOffset": 45}, {"referenceID": 5, "context": "33% UAS of Rasooli and Collins (2015).", "startOffset": 23, "endOffset": 38}, {"referenceID": 8, "context": "Comparison to Other Previous Work Table 7 compares the accuracy of our method to the following related work: 1) Zhang and Barzilay (2015), who describe a method that learns cross-lingual embeddings and bilingual dictionaries from Europarl data, and uses these features in a discriminative parsing model; 2) Guo et al. (2016), who describe a method that learns cross-lingual embeddings from Europarl data and uses a shift-reduce neural parser with these representations; 3) Ammar et al.", "startOffset": 307, "endOffset": 325}, {"referenceID": 1, "context": "(2016), who describe a method that learns cross-lingual embeddings from Europarl data and uses a shift-reduce neural parser with these representations; 3) Ammar et al. (2016), who use the same embeddings as Guo et al.", "startOffset": 155, "endOffset": 175}, {"referenceID": 1, "context": "(2016), who describe a method that learns cross-lingual embeddings from Europarl data and uses a shift-reduce neural parser with these representations; 3) Ammar et al. (2016), who use the same embeddings as Guo et al. (2016), within an LSTM-based parser; and 4) Rasooli and Collins (2015) who use the density-driven approach on the Europarl data.", "startOffset": 155, "endOffset": 225}, {"referenceID": 1, "context": "(2016), who describe a method that learns cross-lingual embeddings from Europarl data and uses a shift-reduce neural parser with these representations; 3) Ammar et al. (2016), who use the same embeddings as Guo et al. (2016), within an LSTM-based parser; and 4) Rasooli and Collins (2015) who use the density-driven approach on the Europarl data.", "startOffset": 155, "endOffset": 289}, {"referenceID": 5, "context": "improves the state-of-the-art model of Rasooli and Collins (2015). It is worth noting that our model significantly outperform the UAS reported in other", "startOffset": 51, "endOffset": 66}, {"referenceID": 5, "context": "Rasooli and Collins (2015) do not report results on English.", "startOffset": 12, "endOffset": 27}, {"referenceID": 5, "context": "RC15 refers to the best performing model of Rasooli and Collins (2015).", "startOffset": 56, "endOffset": 71}, {"referenceID": 20, "context": "previous work (McDonald et al., 2011; Ma and Xia, 2014; Lacroix et al., 2016) but we do not put theirs because of space restrictions.", "startOffset": 14, "endOffset": 77}, {"referenceID": 18, "context": "previous work (McDonald et al., 2011; Ma and Xia, 2014; Lacroix et al., 2016) but we do not put theirs because of space restrictions.", "startOffset": 14, "endOffset": 77}, {"referenceID": 16, "context": "previous work (McDonald et al., 2011; Ma and Xia, 2014; Lacroix et al., 2016) but we do not put theirs because of space restrictions.", "startOffset": 14, "endOffset": 77}, {"referenceID": 5, "context": "Although there is a drop in accuracy when using the automatic POS tags, our model has still a high accuracy even higher than those from the density driven approach of Rasooli and Collins (2015).", "startOffset": 179, "endOffset": 194}, {"referenceID": 5, "context": "sooli and Collins (2015) and for many languages the accuracy of our method gets close to the accuracy of the supervised parser.", "startOffset": 10, "endOffset": 25}, {"referenceID": 20, "context": "A number of methods (Zeman and Resnik, 2008; McDonald et al., 2011; Cohen et al., 2011; Naseem et al., 2012; T\u00e4ckstr\u00f6m et al., 2013; Rosa and Zabokrtsky, 2015) directly learn delexicalized models that can be trained on universal treebank data from one or more source languages, then applied to the target language.", "startOffset": 20, "endOffset": 159}, {"referenceID": 4, "context": "A number of methods (Zeman and Resnik, 2008; McDonald et al., 2011; Cohen et al., 2011; Naseem et al., 2012; T\u00e4ckstr\u00f6m et al., 2013; Rosa and Zabokrtsky, 2015) directly learn delexicalized models that can be trained on universal treebank data from one or more source languages, then applied to the target language.", "startOffset": 20, "endOffset": 159}, {"referenceID": 21, "context": "A number of methods (Zeman and Resnik, 2008; McDonald et al., 2011; Cohen et al., 2011; Naseem et al., 2012; T\u00e4ckstr\u00f6m et al., 2013; Rosa and Zabokrtsky, 2015) directly learn delexicalized models that can be trained on universal treebank data from one or more source languages, then applied to the target language.", "startOffset": 20, "endOffset": 159}, {"referenceID": 29, "context": "A number of methods (Zeman and Resnik, 2008; McDonald et al., 2011; Cohen et al., 2011; Naseem et al., 2012; T\u00e4ckstr\u00f6m et al., 2013; Rosa and Zabokrtsky, 2015) directly learn delexicalized models that can be trained on universal treebank data from one or more source languages, then applied to the target language.", "startOffset": 20, "endOffset": 159}, {"referenceID": 26, "context": "A number of methods (Zeman and Resnik, 2008; McDonald et al., 2011; Cohen et al., 2011; Naseem et al., 2012; T\u00e4ckstr\u00f6m et al., 2013; Rosa and Zabokrtsky, 2015) directly learn delexicalized models that can be trained on universal treebank data from one or more source languages, then applied to the target language.", "startOffset": 20, "endOffset": 159}, {"referenceID": 24, "context": "Table 9: Results for the density driven method (Rasooli and Collins, 2015) and ours using the Bible data on the universal dependencies v1.", "startOffset": 47, "endOffset": 74}, {"referenceID": 10, "context": "has introduced cross-lingual representations \u2013for example cross-lingual word-embeddings\u2013 that can be used to improve performance (Zhang and Barzilay, 2015; Guo et al., 2015; Duong et al., 2015; Guo et al., 2016; Ammar et al., 2016).", "startOffset": 129, "endOffset": 231}, {"referenceID": 6, "context": "has introduced cross-lingual representations \u2013for example cross-lingual word-embeddings\u2013 that can be used to improve performance (Zhang and Barzilay, 2015; Guo et al., 2015; Duong et al., 2015; Guo et al., 2016; Ammar et al., 2016).", "startOffset": 129, "endOffset": 231}, {"referenceID": 11, "context": "has introduced cross-lingual representations \u2013for example cross-lingual word-embeddings\u2013 that can be used to improve performance (Zhang and Barzilay, 2015; Guo et al., 2015; Duong et al., 2015; Guo et al., 2016; Ammar et al., 2016).", "startOffset": 129, "endOffset": 231}, {"referenceID": 1, "context": "has introduced cross-lingual representations \u2013for example cross-lingual word-embeddings\u2013 that can be used to improve performance (Zhang and Barzilay, 2015; Guo et al., 2015; Duong et al., 2015; Guo et al., 2016; Ammar et al., 2016).", "startOffset": 129, "endOffset": 231}, {"referenceID": 11, "context": "We show results for the methods of (Zhang and Barzilay, 2015; Guo et al., 2016; Ammar et al., 2016) in Table 7 of this paper.", "startOffset": 35, "endOffset": 99}, {"referenceID": 1, "context": "We show results for the methods of (Zhang and Barzilay, 2015; Guo et al., 2016; Ammar et al., 2016) in Table 7 of this paper.", "startOffset": 35, "endOffset": 99}, {"referenceID": 13, "context": "The annotation projection approach, where dependencies from one language are transferred through translation alignments to another language, has been considered by several authors (Hwa et al., 2005; Ganchev et al., 2009; McDonald et al., 2011; Ma and Xia, 2014; Rasooli and Collins, 2015; Lacroix et al., 2016; Agi\u0107 et al., 2016).", "startOffset": 180, "endOffset": 329}, {"referenceID": 8, "context": "The annotation projection approach, where dependencies from one language are transferred through translation alignments to another language, has been considered by several authors (Hwa et al., 2005; Ganchev et al., 2009; McDonald et al., 2011; Ma and Xia, 2014; Rasooli and Collins, 2015; Lacroix et al., 2016; Agi\u0107 et al., 2016).", "startOffset": 180, "endOffset": 329}, {"referenceID": 20, "context": "The annotation projection approach, where dependencies from one language are transferred through translation alignments to another language, has been considered by several authors (Hwa et al., 2005; Ganchev et al., 2009; McDonald et al., 2011; Ma and Xia, 2014; Rasooli and Collins, 2015; Lacroix et al., 2016; Agi\u0107 et al., 2016).", "startOffset": 180, "endOffset": 329}, {"referenceID": 18, "context": "The annotation projection approach, where dependencies from one language are transferred through translation alignments to another language, has been considered by several authors (Hwa et al., 2005; Ganchev et al., 2009; McDonald et al., 2011; Ma and Xia, 2014; Rasooli and Collins, 2015; Lacroix et al., 2016; Agi\u0107 et al., 2016).", "startOffset": 180, "endOffset": 329}, {"referenceID": 24, "context": "The annotation projection approach, where dependencies from one language are transferred through translation alignments to another language, has been considered by several authors (Hwa et al., 2005; Ganchev et al., 2009; McDonald et al., 2011; Ma and Xia, 2014; Rasooli and Collins, 2015; Lacroix et al., 2016; Agi\u0107 et al., 2016).", "startOffset": 180, "endOffset": 329}, {"referenceID": 16, "context": "The annotation projection approach, where dependencies from one language are transferred through translation alignments to another language, has been considered by several authors (Hwa et al., 2005; Ganchev et al., 2009; McDonald et al., 2011; Ma and Xia, 2014; Rasooli and Collins, 2015; Lacroix et al., 2016; Agi\u0107 et al., 2016).", "startOffset": 180, "endOffset": 329}, {"referenceID": 0, "context": "The annotation projection approach, where dependencies from one language are transferred through translation alignments to another language, has been considered by several authors (Hwa et al., 2005; Ganchev et al., 2009; McDonald et al., 2011; Ma and Xia, 2014; Rasooli and Collins, 2015; Lacroix et al., 2016; Agi\u0107 et al., 2016).", "startOffset": 180, "endOffset": 329}, {"referenceID": 0, "context": ", 2016; Agi\u0107 et al., 2016). The work of Rasooli and Collins (2015) gives the best results of these methods on the Europarl data, as shown in Table 7.", "startOffset": 8, "endOffset": 67}, {"referenceID": 31, "context": "Other recent work (Tiedemann et al., 2014; Tiedemann, 2015; Tiedemann and Agi\u0107, 2016) has considered treebank translation, where a statistical machine translation system (e.", "startOffset": 18, "endOffset": 85}, {"referenceID": 32, "context": "Other recent work (Tiedemann et al., 2014; Tiedemann, 2015; Tiedemann and Agi\u0107, 2016) has considered treebank translation, where a statistical machine translation system (e.", "startOffset": 18, "endOffset": 85}, {"referenceID": 30, "context": "Other recent work (Tiedemann et al., 2014; Tiedemann, 2015; Tiedemann and Agi\u0107, 2016) has considered treebank translation, where a statistical machine translation system (e.", "startOffset": 18, "endOffset": 85}, {"referenceID": 14, "context": ", MOSES (Koehn et al., 2007)) is used to translate a source language treebank into the target language, complete with reordering of the input sentence.", "startOffset": 8, "endOffset": 28}, {"referenceID": 21, "context": "A number of authors have considered incorporating universal syntactic properties such as dependency order by selectively learning syntactic attributes from similar source languages (Naseem et al., 2012; T\u00e4ckstr\u00f6m et al., 2013; Zhang and Barzilay, 2015; Ammar et al., 2016).", "startOffset": 181, "endOffset": 272}, {"referenceID": 29, "context": "A number of authors have considered incorporating universal syntactic properties such as dependency order by selectively learning syntactic attributes from similar source languages (Naseem et al., 2012; T\u00e4ckstr\u00f6m et al., 2013; Zhang and Barzilay, 2015; Ammar et al., 2016).", "startOffset": 181, "endOffset": 272}, {"referenceID": 1, "context": "A number of authors have considered incorporating universal syntactic properties such as dependency order by selectively learning syntactic attributes from similar source languages (Naseem et al., 2012; T\u00e4ckstr\u00f6m et al., 2013; Zhang and Barzilay, 2015; Ammar et al., 2016).", "startOffset": 181, "endOffset": 272}, {"referenceID": 28, "context": "A number of authors (T\u00e4ckstr\u00f6m et al., 2012; Guo et al., 2015; Guo et al., 2016) have introduced methods that learn cross-lingual representations that are then used in syntactic transfer.", "startOffset": 20, "endOffset": 80}, {"referenceID": 10, "context": "A number of authors (T\u00e4ckstr\u00f6m et al., 2012; Guo et al., 2015; Guo et al., 2016) have introduced methods that learn cross-lingual representations that are then used in syntactic transfer.", "startOffset": 20, "endOffset": 80}, {"referenceID": 11, "context": "A number of authors (T\u00e4ckstr\u00f6m et al., 2012; Guo et al., 2015; Guo et al., 2016) have introduced methods that learn cross-lingual representations that are then used in syntactic transfer.", "startOffset": 20, "endOffset": 80}, {"referenceID": 6, "context": "(see Figure 1) which is then used as input to a clustering algorithm is closely related to (Duong et al., 2015; Gouws and S\u00f8gaard, 2015; Wick et al., 2015).", "startOffset": 91, "endOffset": 155}, {"referenceID": 9, "context": "(see Figure 1) which is then used as input to a clustering algorithm is closely related to (Duong et al., 2015; Gouws and S\u00f8gaard, 2015; Wick et al., 2015).", "startOffset": 91, "endOffset": 155}], "year": 2016, "abstractText": "We describe a simple but effective method for cross-lingual syntactic transfer of dependency parsers, in the scenario where a large amount of translation data is not available. The method makes use of three steps: 1) a method for deriving cross-lingual word clusters, that can then be used in a multilingual parser; 2) a method for transferring lexical information from a target language to source language treebanks; 3) a method for integrating these steps with the density-driven annotation projection method of Rasooli and Collins (2015). Experiments show improvements over the state-of-the-art in several languages used in previous work (Rasooli and Collins, 2015; Zhang and Barzilay, 2015; Ammar et al., 2016), in a setting where the only source of translation data is the Bible, a considerably smaller corpus than the Europarl corpus used in previous work. Results using the Europarl corpus as a source of translation data show additional improvements over the results of Rasooli and Collins (2015). We conclude with results on 38 datasets (26 languages) from the Universal Dependencies corpora: 13 datasets (10 languages) have unlabeled attachment accuracies of 80% or higher; the average unlabeled accuracy on the 38 datasets is 74.8%.", "creator": "dvips(k) 5.991 Copyright 2011 Radical Eye Software"}}}