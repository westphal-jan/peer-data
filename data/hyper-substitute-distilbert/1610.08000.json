{"id": "1610.08000", "review": {"conference": "arxiv", "VERSION": "v1", "DATE_OF_SUBMISSION": "25-Oct-2016", "title": "Statistical Machine Translation for Indian Languages: Mission Hindi 2", "abstract": "this paper presents centre semantic development of advanced computing mumbai'1st ( jp ) submission to nlp tools contest 2011 statistical hindi translation aka microsoft college ( ilsmt ) workshop ( collocated latin icon award ). the aim of the conference was to better explore promising possibilities when accelerated computing translation ( smt ) applications translating within indian schools and between several other slavic regions. beside a paper, commentators report groundbreaking work on utilizing five conceptual pairs, namely filipino - hindi ( \\ bnhi ), khmer - hindi ( \\ tai ), nepali - persian ( \\ tahi ), telugu - persian ( \\ adi ), and anglo - hindi ( \\ enhi ) for science, tourism, various cultural domains. we clearly used word separation, compound recognition into preordering prior onto smt input center screening.", "histories": [["v1", "Tue, 25 Oct 2016 18:20:08 GMT  (19kb,D)", "http://arxiv.org/abs/1610.08000v1", "4 pages, Published in the Proceedings of NLP Tools Contest: Statistical Machine Translation in Indian Languages"]], "COMMENTS": "4 pages, Published in the Proceedings of NLP Tools Contest: Statistical Machine Translation in Indian Languages", "reviews": [], "SUBJECTS": "cs.CL", "authors": ["raj nath patel", "prakash b pimpale"], "accepted": false, "id": "1610.08000"}, "pdf": {"name": "1610.08000.pdf", "metadata": {"source": "CRF", "title": "Statistical Machine Translation for Indian Languages: Mission Hindi 2", "authors": ["Raj Nath Patel", "Prakash B. Pimpale"], "emails": ["rajnathp@cdac.in", "prakash@cdac.in"], "sections": [{"heading": "1 Introduction", "text": "In this paper, we present our SMT experiments from Bengali, Marathi, Tamil, Telugu and English to Hindi. From the set of languages involved, Bengali, Hindi and Marathi belong to the Indo-Aryan family and Tamil and Telugu are from Dravidian language family. All languages except English, have the same flexibility towards word order, canonically following the Subject-ObjectVerb (SOV) structure.\nWith reference to morphology Bengali, Marathi, Tamil, and Telugu are more agglutinative compared to Hindi. It is known that SMT produces unknown words resulting in bad translation quality if morphological divergence between source and target languages is high. Koehn and Knight (2003), Popovic and Ney (2004), nd Popovic\u0301 et al. (2006) have demonstrated\nways to handle this issue with morphological segmentation of words in the source sentences before training the SMT system. To handle this morphological difference we have used suffix separation and compound word splitting developed by Pimpale et al. (2014) and Patel et al. (2014).\nFor English-Hindi SMT, we achieve better alignment using preordering (Patel et al., 2013) and stem as an alignment factor (Koehn and Hoang, 2007).\nAll machine translation (MT) systems suffer from Out of Vocabulary (OOV) words. These OOV words are mostly named entities, technical terms and foreign words which can be translated using transliteration system. We used Durrani et al. (2014), which is a fully unsupervised approach for developing a transliteration system using parallel corpus meant for the SMT training.\nThe rest of the paper is organized as follows. In section 2, we discuss dataset and experimental setup. Section 3 discusses experiments and results. Submitted systems to the shared task are described in section 4 followed by the conclusion and future work in section 5."}, {"heading": "2 Data-set and Experimental Setup", "text": "In the following subsections, we describe Training and Testing corpus followed by pre-processing and SMT system setup for experiments."}, {"heading": "2.1 Corpus for SMT Training and Testing", "text": "We have used corpus shared by ILSMT detailed in Table 1 for the experiments. Testing for the experiments was done using Test1 which is the development set. The submitted systems were evaluated against Test2 corpus, by the organizers. For unconstrained systems, additional data (Bojar et al., 2014; Khapra et al., 2010) has been used for language modeling.\nar X\niv :1\n61 0.\n08 00\n0v 1\n[ cs\n.C L\n] 2\n5 O\nct 2\n01 6"}, {"heading": "2.2 SMT System Set Up", "text": "The baseline system was setup by using the phrase-based model (Och and Ney, 2003; Brown et al., 1990; Marcu and Wong, 2002; Koehn et al., 2003; Koehn et al., 2007) and Koehn and Hoang (2007) was used for factored model. The language model was trained using KenLM (Heafield, 2011) toolkit with modified Kneser-Ney smoothing (Chen and Goodman, 1996). For factored SMT training source and target side stem were used as an alignment factor. Stemming was done using a lightweight stemmer for Hindi (Ramanathan and Rao, 2003). For English, we used porter stemmer (Minnen et al., 2001)."}, {"heading": "2.3 Evaluation Metrics", "text": "The different experimental systems were compared using, BLEU (Papineni et al., 2002), NIST (Doddington, 2002), translation error rate (TER) (Snover et al., 2006). For an MT system is to be better, higher BLEU and NIST scores with lower TER are desired."}, {"heading": "2.4 Pre-Processing (PP)", "text": "To tackle the morphological divergence between the source and target languages for the purpose of a better SMT system, we preprocessed the source (Bengali, Marathi, Tamil, and Telugu) for suffix separation and compound word splitting (Pimpale et al., 2014; Patel et al., 2014) prior to training and testing. To handle the structural divergence (enhi), we used source side reordering (Patel et al., 2013)."}, {"heading": "2.5 Transliteration (TR)", "text": "We developed transliteration systems using Durrani et al. (2014) inbuilt with the Moses tool. We used n-best transliteration output for OOV words. These candidates were then plugged in and rescored with the language model to get the best translation for the given source sentence."}, {"heading": "2.6 Language Modelling", "text": "We trained 5-gram LM using KenLM with modified Kneser-Ney smoothing. LM size was quite large (ARPA-88.7GB, binary-27.4GB), even after binarization. Training LM with the huge amount of monolingual data like Bojar et al. (2014) (approx. 10GB ) required good computing resources (60GB RAM and 200GB storage space in the working dir). Also, Bojar et al. (2014) corpus contains unwanted symbols (<s>) for KenLM which we need to remove prior training."}, {"heading": "3 Experiments and Results", "text": "Table 2 shows evaluation scores for various systems tried under constrained submission, that is, systems trained only on the shared data. We can see the use of the preprocessing and transliteration contributed to the improvement of around 1-5 bleu points across the language pairs. Detailed evaluation scores for unconstrained systems, that is, systems using language model built on external data, are in Table 3. Significant improvement can be observed from the table when additional data was used for language modeling."}, {"heading": "4 Submission to the Shared Task", "text": "We submitted two different results for the contest, namely constrained and unconstrained. The constrained systems were trained only on the data\nshared by the organizers. For unconstrained systems, we used additional monolingual data which include Bojar et al. (2014) and Khapra et al. (2010), for language modeling."}, {"heading": "5 Conclusion and Feature Work", "text": "In this paper, we presented systems for translation from Bengali, English, Marathi, Tamil and Telugu to Hindi. These SMT systems with the use of source side suffix separation, compound splitting, preordering and bigger language model shows significantly higher accuracy over the baseline. Adding more complex features for factored models and formulating preprocessing with better way could be the next step."}], "references": [{"title": "A Statistical Approach", "author": ["Brown et al.1990] Peter F Brown", "John Cocke", "Stephen A Della Pietra", "Vincent J Della Pietra", "Fredrick Jelinek", "John D Lafferty", "Robert L Mercer", "Paul S Roossin"], "venue": null, "citeRegEx": "Brown et al\\.,? \\Q1990\\E", "shortCiteRegEx": "Brown et al\\.", "year": 1990}, {"title": "An Empirical Study of Smoothing Techniques for Language Modeling", "author": ["Chen", "Goodman1996] Stanley F Chen", "Joshua Goodman"], "venue": "In Proceedings of the 34th annual meeting on Association for Computational Linguistics,", "citeRegEx": "Chen et al\\.,? \\Q1996\\E", "shortCiteRegEx": "Chen et al\\.", "year": 1996}, {"title": "Automatic Evaluation of Machine Translation Quality using N-gram Co-occurrence Statistics", "author": ["George Doddington"], "venue": "In Proceedings of the second international conference on Human Language Technology Research,", "citeRegEx": "Doddington.,? \\Q2002\\E", "shortCiteRegEx": "Doddington.", "year": 2002}, {"title": "Integrating an unsupervised transliteration model into statistical machine translation", "author": ["Hassan Sajjad", "Hieu Hoang", "Philipp Koehn"], "venue": "In Proceedings of the 15th Conference of the European Chapter of the ACL", "citeRegEx": "Durrani et al\\.,? \\Q2014\\E", "shortCiteRegEx": "Durrani et al\\.", "year": 2014}, {"title": "KenLM: Faster and Smaller Language Model Queries", "author": ["Kenneth Heafield"], "venue": "In Proceedings of the Sixth Workshop on Statistical Machine Translation,", "citeRegEx": "Heafield.,? \\Q2011\\E", "shortCiteRegEx": "Heafield.", "year": 2011}, {"title": "All Words Domain Adapted WSD: Finding a Middle Ground between Supervision and Unsupervision", "author": ["Anup Kulkarni", "Saurabh Sohoney", "Pushpak Bhattacharyya"], "venue": "In Proceedings of the 48th Annual Meet-", "citeRegEx": "Khapra et al\\.,? \\Q2010\\E", "shortCiteRegEx": "Khapra et al\\.", "year": 2010}, {"title": "Factored translation models", "author": ["Koehn", "Hoang2007] Philipp Koehn", "Hieu Hoang"], "venue": "In EMNLP-CoNLL,", "citeRegEx": "Koehn et al\\.,? \\Q2007\\E", "shortCiteRegEx": "Koehn et al\\.", "year": 2007}, {"title": "Empirical Methods for Compound Splitting", "author": ["Koehn", "Knight2003] Philipp Koehn", "Kevin Knight"], "venue": "In Proceedings of the tenth conference on European chapter of the Association for Computational Linguistics-Volume", "citeRegEx": "Koehn et al\\.,? \\Q2003\\E", "shortCiteRegEx": "Koehn et al\\.", "year": 2003}, {"title": "Statistical Phrase-Based Translation", "author": ["Koehn et al.2003] Philipp Koehn", "Franz Josef Och", "Daniel Marcu"], "venue": "In Proceedings of the 2003 Conference of the North American Chapter of the Association for Computational Linguistics on Human Language", "citeRegEx": "Koehn et al\\.,? \\Q2003\\E", "shortCiteRegEx": "Koehn et al\\.", "year": 2003}, {"title": "A Phrase-Based, Joint Probability Model for Statistical Machine Translation", "author": ["Marcu", "Wong2002] Daniel Marcu", "William Wong"], "venue": "In Proceedings of the ACL-02 conference on Empirical methods in natural language processing-Volume", "citeRegEx": "Marcu et al\\.,? \\Q2002\\E", "shortCiteRegEx": "Marcu et al\\.", "year": 2002}, {"title": "Applied morphological processing of english", "author": ["Minnen et al.2001] Guido Minnen", "John Carroll", "Darren Pearce"], "venue": "Natural Language Engineering,", "citeRegEx": "Minnen et al\\.,? \\Q2001\\E", "shortCiteRegEx": "Minnen et al\\.", "year": 2001}, {"title": "A Systematic Comparison of Various Statistical Alignment Models", "author": ["Och", "Ney2003] Franz Josef Och", "Hermann Ney"], "venue": "Computational linguistics,", "citeRegEx": "Och et al\\.,? \\Q2003\\E", "shortCiteRegEx": "Och et al\\.", "year": 2003}, {"title": "BLEU: A Method for Automatic Evaluation of Machine Translation", "author": ["Salim Roukos", "Todd Ward", "Wei-Jing Zhu"], "venue": "In Proceedings of the 40th annual meeting on association for computational linguis-", "citeRegEx": "Papineni et al\\.,? \\Q2002\\E", "shortCiteRegEx": "Papineni et al\\.", "year": 2002}, {"title": "Reordering rules for english-hindi smt", "author": ["Patel et al.2013] Raj Nath Patel", "Rohit Gupta", "Prakash B Pimpale", "Sasikumar M"], "venue": "In Proceedings of the Second Workshop on Hybrid Approaches to Translation,", "citeRegEx": "Patel et al\\.,? \\Q2013\\E", "shortCiteRegEx": "Patel et al\\.", "year": 2013}, {"title": "Statistical Machine Translation for Indian Languages: Mission Hindi", "author": ["Patel et al.2014] Raj Nath Patel", "Prakash B Pimpale", "Sasikumar M"], "venue": "In Proceedings of NLP Tools contest. ICON-2014: 11th International Conference on Natural Language Pro-", "citeRegEx": "Patel et al\\.,? \\Q2014\\E", "shortCiteRegEx": "Patel et al\\.", "year": 2014}, {"title": "SMT from Agglutinative Languages: Use of Suffix Separation and Word Splitting", "author": ["Raj Nath Patel", "Sasikumar M"], "venue": "In Proceedings of ICON-2014: 11th International Conference on Natural Language Process-", "citeRegEx": "Pimpale et al\\.,? \\Q2014\\E", "shortCiteRegEx": "Pimpale et al\\.", "year": 2014}, {"title": "Towards the Use of Word Stems and Suffixes for Statistical Machine Translation", "author": ["Popovic", "Ney2004] Maja Popovic", "Hermann Ney"], "venue": null, "citeRegEx": "Popovic et al\\.,? \\Q2004\\E", "shortCiteRegEx": "Popovic et al\\.", "year": 2004}, {"title": "Statistical Machine Translation of German Compound Words", "author": ["Popovi\u0107 et al.2006] Maja Popovi\u0107", "Daniel Stein", "Hermann Ney"], "venue": "In Advances in Natural Language Processing,", "citeRegEx": "Popovi\u0107 et al\\.,? \\Q2006\\E", "shortCiteRegEx": "Popovi\u0107 et al\\.", "year": 2006}, {"title": "A Lightweight Stemmer for Hindi", "author": ["Ramanathan", "Durgesh D Rao"], "venue": "In The Proceedings of EACL", "citeRegEx": "Ramanathan et al\\.,? \\Q2003\\E", "shortCiteRegEx": "Ramanathan et al\\.", "year": 2003}, {"title": "A Study of Translation Edit Rate with Targeted Human Annotation. In Proceedings of association for machine translation in the Ameri", "author": ["Bonnie Dorr", "Richard Schwartz", "Linnea Micciulla", "John Makhoul"], "venue": null, "citeRegEx": "Snover et al\\.,? \\Q2006\\E", "shortCiteRegEx": "Snover et al\\.", "year": 2006}], "referenceMentions": [{"referenceID": 14, "context": "Koehn and Knight (2003), Popovic and Ney (2004), nd Popovi\u0107 et al. (2006) have demonstrated ways to handle this issue with morphological segmentation of words in the source sentences before training the SMT system.", "startOffset": 52, "endOffset": 74}, {"referenceID": 13, "context": "To handle this morphological difference we have used suffix separation and compound word splitting developed by Pimpale et al. (2014) and Patel et al.", "startOffset": 112, "endOffset": 134}, {"referenceID": 13, "context": "(2014) and Patel et al. (2014).", "startOffset": 11, "endOffset": 31}, {"referenceID": 13, "context": "For English-Hindi SMT, we achieve better alignment using preordering (Patel et al., 2013) and stem as an alignment factor (Koehn and Hoang, 2007).", "startOffset": 69, "endOffset": 89}, {"referenceID": 3, "context": "We used Durrani et al. (2014), which is a fully unsupervised approach for developing a transliteration system using parallel corpus meant for the SMT training.", "startOffset": 8, "endOffset": 30}, {"referenceID": 5, "context": "For unconstrained systems, additional data (Bojar et al., 2014; Khapra et al., 2010) has been used for language modeling.", "startOffset": 43, "endOffset": 84}, {"referenceID": 0, "context": "The baseline system was setup by using the phrase-based model (Och and Ney, 2003; Brown et al., 1990; Marcu and Wong, 2002; Koehn et al., 2003; Koehn et al., 2007) and Koehn and Hoang (2007) was used for factored model.", "startOffset": 62, "endOffset": 163}, {"referenceID": 7, "context": "The baseline system was setup by using the phrase-based model (Och and Ney, 2003; Brown et al., 1990; Marcu and Wong, 2002; Koehn et al., 2003; Koehn et al., 2007) and Koehn and Hoang (2007) was used for factored model.", "startOffset": 62, "endOffset": 163}, {"referenceID": 6, "context": "The baseline system was setup by using the phrase-based model (Och and Ney, 2003; Brown et al., 1990; Marcu and Wong, 2002; Koehn et al., 2003; Koehn et al., 2007) and Koehn and Hoang (2007) was used for factored model.", "startOffset": 62, "endOffset": 163}, {"referenceID": 4, "context": "The language model was trained using KenLM (Heafield, 2011) toolkit with modified Kneser-Ney smoothing (Chen and Goodman, 1996).", "startOffset": 43, "endOffset": 59}, {"referenceID": 10, "context": "For English, we used porter stemmer (Minnen et al., 2001).", "startOffset": 36, "endOffset": 57}, {"referenceID": 0, "context": "The baseline system was setup by using the phrase-based model (Och and Ney, 2003; Brown et al., 1990; Marcu and Wong, 2002; Koehn et al., 2003; Koehn et al., 2007) and Koehn and Hoang (2007) was used for factored model.", "startOffset": 82, "endOffset": 191}, {"referenceID": 12, "context": "The different experimental systems were compared using, BLEU (Papineni et al., 2002), NIST (Doddington, 2002), translation error rate (TER) (Snover et al.", "startOffset": 61, "endOffset": 84}, {"referenceID": 2, "context": ", 2002), NIST (Doddington, 2002), translation error rate (TER) (Snover et al.", "startOffset": 14, "endOffset": 32}, {"referenceID": 19, "context": ", 2002), NIST (Doddington, 2002), translation error rate (TER) (Snover et al., 2006).", "startOffset": 63, "endOffset": 84}, {"referenceID": 15, "context": "To tackle the morphological divergence between the source and target languages for the purpose of a better SMT system, we preprocessed the source (Bengali, Marathi, Tamil, and Telugu) for suffix separation and compound word splitting (Pimpale et al., 2014; Patel et al., 2014) prior to training and testing.", "startOffset": 234, "endOffset": 276}, {"referenceID": 14, "context": "To tackle the morphological divergence between the source and target languages for the purpose of a better SMT system, we preprocessed the source (Bengali, Marathi, Tamil, and Telugu) for suffix separation and compound word splitting (Pimpale et al., 2014; Patel et al., 2014) prior to training and testing.", "startOffset": 234, "endOffset": 276}, {"referenceID": 13, "context": "To handle the structural divergence (enhi), we used source side reordering (Patel et al., 2013).", "startOffset": 75, "endOffset": 95}, {"referenceID": 3, "context": "We developed transliteration systems using Durrani et al. (2014) inbuilt with the Moses tool.", "startOffset": 43, "endOffset": 65}, {"referenceID": 5, "context": "(2014) and Khapra et al. (2010), for language modeling.", "startOffset": 11, "endOffset": 32}], "year": 2016, "abstractText": "This paper presents Centre for Development of Advanced Computing Mumbai\u2019s (CDACM) submission to NLP Tools Contest on Statistical Machine Translation in Indian Languages (ILSMT) 2015 (collocated with ICON 2015). The aim of the contest was to collectively explore the effectiveness of Statistical Machine Translation (SMT) while translating within Indian languages and between English and Indian languages. In this paper, we report our work on all five language pairs, namely Bengali-Hindi (bn-hi), Marathi-Hindi (mrhi), Tamil-Hindi (ta-hi), Telugu-Hindi (tehi), and English-Hindi (en-hi) for Health, Tourism and General domains. We have used suffix separation, compound splitting and preordering prior to SMT training and testing.", "creator": "LaTeX with hyperref package"}}}