{"id": "1611.06953", "review": {"conference": "arxiv", "VERSION": "v1", "DATE_OF_SUBMISSION": "18-Nov-2016", "title": "Associative Adversarial Networks", "abstract": "we explain a higher - level identification pathway for evaluating adversarial responses. generative adversarial network ( gan ) framework has a discriminator and intensity generator implementation. the activation ( g ) compares white invariant ( z ) to factor distributions while matrix backup ( d ) maps data objects surrounding multiple single matrix. ct do so, g learns how to map composite high - level representation space to data averages, and d training to do the opposite. feldman concluded that higher - level representation spaces need not necessarily follow a uniform probability test. analyzing this hypothesis, neurons evaluate restricted representation machines ( rbms ) or naive higher - level associative learning wherein assign the adaptive coding for corresponding high - average features generated between d. subsequent primal memory strategies indicate underlying probability distribution and b calculate how to return these boundaries to data space. alternative expert network controller networks ( rr ) utilize generative processes in these multi - levels of the cortex, and use adversarial non - stochastic constraints \u03c1 and rd for constructing the interaction between data and higher - pass study zones. so exploit the useful benefit comparing proposed nets.", "histories": [["v1", "Fri, 18 Nov 2016 02:11:40 GMT  (1388kb,D)", "http://arxiv.org/abs/1611.06953v1", "NIPS 2016 Workshop on Adversarial Training"]], "COMMENTS": "NIPS 2016 Workshop on Adversarial Training", "reviews": [], "SUBJECTS": "cs.LG cs.AI", "authors": ["tarik arici", "asli celikyilmaz"], "accepted": false, "id": "1611.06953"}, "pdf": {"name": "1611.06953.pdf", "metadata": {"source": "CRF", "title": "Associative Adversarial Networks", "authors": ["Tarik Arici"], "emails": ["aslicel}@microsoft.com"], "sections": [{"heading": "1 Introduction", "text": "The generative adversarial network (GAN) framework [1] is a relatively new type of framework that introduces a generator G and a discriminator D, both of which are often chosen to be a type of multilayer perceptron (MLP) network, and are trained in an adversarial manner. D is trained to label training examples as true, and outputs of G as false, while G is trained to maximize the probability of D\u2019s classification errors.\nRecent works have reported that models trained using the GAN framework (especially for the image generation task) can generate excellent samples [2]. Nevertheless, it is widely reported that GAN models are difficult to train and different techniques are proposed (which are summarized in [3, 4, 5]). Most of these work try to deal with the difficulty of optimizing the G and D simultaneously in a synchronized manner and their joint convergence[6]. [3] proposes to train the generator by a new objective that guides G to match the statistics of features on an intermediate layer of the discriminator. This helps to avoid over-training of the current discriminator and discourages learning mappings that are not useful in generating realistic data. Another major difficulty in training GANs is the tendency for G to collapse by converging to a parameter setting which maps all z\u2019s to the same data. [3] uses minibatch discrimination so that D can generate different gradients for data samples and continue guiding G via backpropagation and force G to diversify its outputs and avoid collapsing.\nIn this paper, we argue that using noise for the generator contributes to the difficulty of training GANs. The generator is assigned the task of learning the mapping from the input signal z, which is a uniformly distributed noise to data space. In [7], a strong evidence is presented for better disentangling of the underlying factors of variation in data by higher-level representation spaces, and this might explain why a uniformly distributed random noise as input to G works. However, learning the mapping from a flat representation space to data space is difficult. This can be explained with an example from human-face image generation task. A completely disentangled representation space\n30th Conference on Neural Information Processing Systems (NIPS 2016), Barcelona, Spain.\nar X\niv :1\n61 1.\n06 95\n3v 1\n[ cs\n.L G\n] 1\n8 N\nov 2\n01 6\nfor human faces would likely consist of features including pose, illumination, gender, mood, facial expressions, 3-D model of face etc. The generator\u2019s task is then to find good mappings from this flat representation space to face images, which requires significant training. It is difficult for the generator network to achieve this goal and this might be one of the reasons why generator collapses during training. However, mapping a higher-level representation that does not assume complete disentanglement of factors of variation, such as mapping facial areas to a face image, can be expected to be an easier task. This higher-level representation-space features will be correlated (e.g., the existence of vertical symmetry in the facial parts or the location of distinct facial areas depending on the pose). By using an associative memory on z and generating samples from this memory as an input to G, our goal is to alleviate G\u2019s learning task. Also, mapping data samples to a lower dimensional but higher-level representation space by using D and then learning an associative memory model causes the Markov chain (used in the model training) to mix faster - thanks to a more uniform distribution in this new space [7].\nThe associative adversarial networks (AANs) uses an associative memory that is located in between the generator and the discriminator networks, connecting the two networks together. We explore the special case that uses a Restricted Boltzmann Machine (RBM) as an associative memory, which learns a probability distribution over the features of an intermediate layer of the discriminator. Gibbs sampling is used to sample from this distribution, and the samples are fed to G. Figure 1 depicts an example AAN, which we present in this work.\nThe main contributions of this work are the following:\n\u2022 We introduce a higher-level associative memory, a stochastic generative model that connects the two non-stochastic GAN models; the discriminator and the generator. \u2022 Training on CelebA face image dataset, we show convincing evidence that the associative memory can learn a probabilistic model on the higher-level representation space of the discriminator. It can then produce samples to be used as an input to the generator thereby alleviating its learning task. \u2022 We further evaluate the performance of the assoicative memory, RBM\u2019s performance, by investigating the held-out likelihood of the model for varying parameters."}, {"heading": "2 Related Work", "text": "Neural network models that generate data have been getting more attention recently due to their ability to learn reusable feature representations from large unlabeled data sets as well as generate realistic data samples. The generative adversarial networks (GANs) [1], variational autoencoders (VAE) [8], generative maximum mean discrepeancy networks [9], deep generative models[10], generative moment matching networks [11], etc., have shown that a deep generative network can learn a distribution over samples. Specifically, GANs have been a promising family of generative models in the computer vision field, because they can produce sharp images by applying stochastic gradient descent on well-defined loss functions. Some GAN extensions have looked at laplacian pyramid extensions [12] showing higher quality images, a recurrent network approach [13] and a de-convolution network approach [14] demonstrating reasonable success with generating natural images. Several recent papers focus on improving the stability of training and the quality of generated GAN samples [2, 12, 15, 16]. Among recent ones (as recently summarized in [5]) the following pop out for stabilizing GAN training: balancing/freezing: to prevent the generator or discriminator to outpace one another, minibatch discrimination: to prevent the generator to collapse on to a single sample and enable back-propagation of gradients to improve weights, historical averaging [3], a technique common used in game theory that uses a historical average of parameters as a regularization term in optimization.\nIn this work we build up on these techniques. We use some of the DCGAN architectural suggestions proposed in Radford et al. [2], which uses strided convolutions in the initial layers of the discriminator and fractional-strided convolutions in the later layers of the generator, which will be discussed in the experiments section. In a way, our proposed technique resembles the learning algorithm for deep belief nets presented in [17], which utilizes a contrastive version of the wake-sleep algorithm proposed in [18]. Deep belief nets have a top-level undirected associative memory together with directed generative models in the lower levels. To generate samples from a model, Gibbs sampling is used in the top-level associative memory and a sample from this memory is passed down stochastically\nthrough the directed generative connections in the lower layers. The model is learned by performing a contrastive version of the wake-sleep algorithm after a greedy layerwise initialization process. In the wake phase, a stochastic \"up-pass\" starts and generative weights between two adjacent layers are updated locally to maximize the likelihood of upper layer samples generating lower level samples. In the sleep phase, a stochastic \"down-pass\" starts and recognition weights between two adjacent layers are updated similarly. Our proposed method uses D for the up-pass and G for the down-pass."}, {"heading": "3 Generative Adversarial Networks (GAN)", "text": "GANs [1] are a class of generative models that pose the training process as a game between a generator network (G) and a discriminator network (D) both of which are non-stochastic models. The generator network, G(z; \u03b8(G)), is typically chosen as a feed forward or convolutional neural network depending on the task. It produces samples, by transforming vectors of noise z as x = G(z; \u03b8(G)). The discriminatorD, is trained by taking the samples from the generator, pG(x), as negative instances and from the real data pdata(x) as positive instances and is trained to distinguish generated samples from the real (training) data.\nD takes the output of G and maps to a binary classification probability. Generator then tries to \u201ctrick\u201d the discriminator by generating fake samples. The learning framework is a two-player game and is cast as a minmax optimization of a differentiable objective and solved greedily by iteratively performing gradient descent steps to improve G and D and eventually reaching a Nash equilibrium [19]. The GAN problem can be formulated as a zero-sum game (minimax) which has a distinguishability game value function, V (D,G) [6]:\nmin G max D = Ex\u223cpdata(x)[logD(x)] + Ez\u223cpz(z)[log(1\u2212D(G(z)))]\nThe first term in the cost function forces D to label real data samples as one, while the second term forces D to label fake data samples as zero. G tries to fake D into labeling its output as one so minimizes the given cost function, while D tries to maximize it."}, {"heading": "4 Using RBMs as an Associative Memory for GANs", "text": "An RBM is an energy based model for unsupervised learning with an underlying undirected graph. It consists of two layers of binary stochastic units: one visible layer v representing the data and one hidden layer h for the latent variables. wij determines the strength of the interaction between the hidden hj and visible vi units. An energy function between visible and hidden variables E(v, h), the probability P (v, h) and the partition function Z is defined as below:\nE(v, h) = 1\n2 \u2211 i v2i \u2212 \u2211 i,j vihjwij\u2212 \u2211 i vibi\u2212 \u2211 j hjcj ; P (v, h) = e\u2212E(v,h) Z ; Z = \u2211 x,y e\u2212E(x,y)\nThe probability of a data point (represented by the visible state v) is defined by marginalizing over the hidden variables P (v) = \u2211 h P (v, h). The training data log-likelihood for one sample is:\n\u03c6 = logP (v) = \u03c6+ + \u03c6\u2212; \u03c6+ = log \u2211 h e\u2212E(v,h); \u03c6\u2212 = logZ = \u2211 x,y e\u2212E(x,y)\nThe gradient of the log-likelihood involves a positive and a negative term. The positive gradient is \u2202\u03c6 +\n\u2202wij = vi \u00b7 P (hj = 1|v) but the negative gradient \u2202\u03c6\n\u2212\n\u2202wij is intractable and requires summation\nof all values of hidden and visible variables which grows exponentially. A common method is to approximate the expectation in the second term by generating samples. Contrastive Divergence (CD) algorithm [20] runs the Markov chain for a few steps after clamping the visible layer to data examples. Another technique is to use persistent chains without clamping the visible layer [21]. In our experiments, we use the CD algorithm with two steps of alternating Gibbs sampling for learning the RBM model."}, {"heading": "5 Associative Adversarial Networks (AAN)", "text": "The discriminator model D tries to discriminate between the real and fake data. In doing so, D learns features that can explain factors of variation in data and uses these features to achieve its classification goal. On the other hand G tries to map a low-dimensional input to data. Contrary to common approaches, instead of representing the G\u2019s input as a flat space, we think of it as an intermediate but higher-level representation corresponding to one of the intermediate layers of D. We use an RBM to learn a distribution in this space. The samples generated via contrastive divergence for updating the RBM model is used an input to G. Therefore we connect D and G through a high-level feature space.\nLet F (x) denote an intermediate layer activations of D, while C(y) denotes the operations in the remaining layers in D. Then, D(x) = C(F (x)). The associative memory learns the distribution pf of f = F (x). Similar to the regular GANs, AAN optimization becomes:\nmin G max p\u0302f max D = Ex\u223cpdata(x)[logD(x)] + Ef\u223cp\u0302f (f)[log(1\u2212D(G(f)))] + Ef\u223cpf (f)[log p\u0302f ] (1)\nThe second expectation is over the estimated p\u0302f since G is inputted with samples from the associative memory. Minimizing the third expectation forces the associative memory to estimate the probability distribution function of f ."}, {"heading": "6 Details of Associative Adversarial Training", "text": "We trained the AANs on Large-scale CelebFaces Attributes (CelebA) and the MNIST dataset. Images in the dataset are linearly scaled to the [-1, 1] range. GAN models are trained with mini-batch sizes of 256. Similar to [2], we used an Adam optimizer. For the RBM learning, we used the same mini-batch\nsize with a learning rate of 0.001 and stochastic gradient descent (SGD) with momentum. We picked a momentum rate of 0.8. A contrastive divergence with two steps is used to create the negative samples. We used leaky rectified linear activations (LeakyReLU) [22] for D with one exception to be discussed below and rectified linear activation [23] for G as activation functions. Using an intermediate layer of D with LeakyReLU activation as a visible layer to the RBM requires it to be a Gaussian RBM which does not work well in practice. Hence, we used tanh activation for the layer that connects as a visible layer to a binary RBM. We chose binary variable states as (-1) and (+1) similar to spin states in an Ising model [24]. The expected value of a unit in the RBM is p \u2217 1 + (1\u2212 p) \u2217 \u22121 = 2p\u2212 1 where p is the conditional probability of a variable to be (1), which is a sigmoid. Thus, the expected value 2p\u2212 1 becomes a tanh non-linearity. The negative samples created for RBM\u2019s contrastive divergence learning are used as inputs for the G."}, {"heading": "6.1 CelebA", "text": "Discriminator for this dataset has four strided convolutional layers with depth 64, 128, 256, 512 as the first four layers. Stride size is set to match the filter width and height both of which is five. The last convolutional layer\u2019s outputs are reshaped into a one-dimensional representation f which is fully connected to a layer that has the same dimension as the RBM\u2019s visible layer. After this layer there are two more layers of size 500. The two final layers can be thought as hidden layers of a classification network C as defined in Section 5, which has f as input so that their cascaded application composes D (i.e. D(x) = C(F (x))). F defines a mapping to a feature space, and the RBM model learns the distribution of data set samples in this space.\nFigure 3 shows some face images generated using negative samples from the RBM generated by increasing the number of Gibbs steps from one to ten. RBM\u2019s Markov chain is initialized with f created by real images from the data set which are given in the leftmost column. Figure 3a uses an RBM with 1000-dimensional visible and hidden layer units and Figure 3b uses an RBM with 100-dimensional visible and hidden layer units. With a 1000\u00d71000 RBM, the generated images using the Gibbs samples change slowly; as more Gibbs steps are performed facial features, expressions change gradually. For example a pose or gender change does not happen quickly. This shows it requires many steps for the Gibbs sample to jump to other modes of the distribution. However, using a 100\u00d7 100 RBM one sampling step is sufficient to change gender, race etc. as can be seen in Figure 3b. This shows that f features are distributed more uniformly in the space, helping the Gibbs sample jump from one mode of the distribution to another. Compared to a 1000-D f , a 100-D f has to be more efficient in packing the information to pass on to C for the correct classification, so F ends up learning a mapping that more uniformly distributes mapped dataset samples in this space."}, {"heading": "6.2 Convergence Analysis of the Generator and the Discriminator", "text": "G implicitly defines a probability distribution pG as the distribution of samplesG(f) it generates when f \u223c pf . The goal is to obtain a pG that is a good approximation to pdata. The minimax game that underlines the adversarial learning has a global optimum which is pG = pdata and logD(x) = 1/2. Therefore the value function given in 1 is log 4 at the optimal solution. As discussed in the introduction section, one of the difficulties with adversarial training is that D improves its cost significantly faster than G, and G lags behind so much so that it can not receive good gradients back-propagating from D and loses the game. For a good adversarial training, one would expect G to lag behind at an acceptable level so that D can guide G.\nTo analyze the convergence of adversarial models, we monitored Ex\u223cpdata(x)[logD(x)] and Ef\u223cp\u0302f (f)[logD(G(f))] during training. The first expectation measures the objective associated with real images and the second with generated images. If D and G both converge to the global optimal solution than both expectations should converge to log1/2. However, in practice the first expectation becomes extremely close to zero while the second expectation diverges from zero. We analyzed the ratio Ex\u223cpdata(x)[logD(x)]/Ef\u223cp\u0302f (f)[logD(G(f))] for AAN and GAN where noise z is sampled uniformly to feed G. Learning to map 1000-dimensional f or z to an image is more difficult as there is more learning associated with each dimension of G\u2019s input. Hence G lags behind significantly. However, using a 100-dimensional input, G\u2019s learning task is less difficult. This can be seen in Figure 2. Similarly, AAN alleviates G\u2019s learning task by producing inputs from the manifold that f lies in."}, {"heading": "7 Conclusion and Future Work", "text": "We proposed associate adversarial networks for improving the training of generative adversarial networks (GAN). GANs are a promising class of generative models. However, previous works have reported several issues pertaining to its stability during training. In this work, we argue that inputting noise to the generator makes G\u2019s learning task difficult. Instead, we propose using an additional network, the RBM associative memory network, that connects the two networks of the GANs, the discriminator and generator. The associative memory networks can learn a probabilistic model using a higher level representation discovered by the discriminator and can be sampled to produce inputs for the generator network.\nAlthough we empirically tested the efficacy of the proposed associative adversarial networks, we hope to develop a more rigorous theoretical understanding in future work. Inspecting equation (1), one can see that it is possible for the associative memory to collapse to a degenerate probability distribution, similar to G\u2019s collapsing when it lags behind D significantly. As a future work, we are planning to study entropy-maximizing regularizers for the associative memory.\nAnother future work would be to study probabilistic objectives for the generator, which can be obtained from the associative network. This is in agreement with the idea proposed in [3], which suggest changing G\u2019s objective to match an intermediate discriminator layer\u2019s statistics."}], "references": [{"title": "Generative adversarial nets", "author": ["Ian Goodfellow", "Jean Pouget-Abadie", "Mehdi Mirza", "Bing Xu", "Warde-Farley David", "Sherjil Ozair", "Courville Aaron", "Yoshua Bengio"], "venue": null, "citeRegEx": "1", "shortCiteRegEx": "1", "year": 2014}, {"title": "Unsupervised representation learning with deep convolutional generative adversarial networks", "author": ["Alec Radford", "Luke Metz", "Soumith Chintala"], "venue": null, "citeRegEx": "2", "shortCiteRegEx": "2", "year": 2015}, {"title": "Improved techniques for training gans", "author": ["Tim Salimans", "Ian Goodfellow", "Wojciech Zaremba", "Vicki Cheung", "Alex Radfors", "Xi Chen"], "venue": "arXiv preprint arXiv:1606.03498,", "citeRegEx": "3", "shortCiteRegEx": "3", "year": 2016}, {"title": "Connecting generative adversarial networks and actor-critic methods", "author": ["David Pfau", "Oriol Vinyals"], "venue": null, "citeRegEx": "5", "shortCiteRegEx": "5", "year": 1945}, {"title": "On distinguishability criteria for estimating generative models", "author": ["Ian Goodfellow"], "venue": "ICLR 2015,", "citeRegEx": "6", "shortCiteRegEx": "6", "year": 2014}, {"title": "Better mixing via deep representations", "author": ["Yann Dauphin Yoshua Bengio", "Gr\u00e9goire Mesnil", "Salah Rifai"], "venue": "Proc. of the ICML,", "citeRegEx": "7", "shortCiteRegEx": "7", "year": 2013}, {"title": "Auto-encoding variational bayes", "author": ["Diederik P Kingma", "Max Welling"], "venue": "ICLR,", "citeRegEx": "8", "shortCiteRegEx": "8", "year": 2014}, {"title": "Training generative neural networks via maximum mean discrepancy optimization", "author": ["Gintare Karolina Dziugaite", "Daniel M. Roy", "Zoubin Ghahramani"], "venue": "Uncertainty in Artificial Intelligence (UAI),", "citeRegEx": "9", "shortCiteRegEx": "9", "year": 2015}, {"title": "Stochastic backpropagation and approximate inference in deep generative models", "author": ["Daan Wierstra"], "venue": null, "citeRegEx": "10", "shortCiteRegEx": "10", "year": 2014}, {"title": "Generative moment matching networks", "author": ["Yujia Li", "Kevin Swersky", "Richard Zemel"], "venue": null, "citeRegEx": "11", "shortCiteRegEx": "11", "year": 2016}, {"title": "Deep generative image models using a laplacian pyramid of adversarial networks", "author": ["Emily Denton", "Soumith Chintala", "Arthur Szlam", "Rob Fergus"], "venue": "arXiv preprint arXiv:1506.05751,", "citeRegEx": "12", "shortCiteRegEx": "12", "year": 2015}, {"title": "Draw: A recurrent neural network for image generation", "author": ["Karol Gregor", "Ivo Danihelka", "Alex Graves", "Daan Wierstra"], "venue": null, "citeRegEx": "13", "shortCiteRegEx": "13", "year": 2015}, {"title": "Learning to generate chairs with convolutional neural networks", "author": ["Jost Tobias Dosovitskiy", "Alexey Springenberg", "Brox Thomas"], "venue": "arXiv preprint arXiv:1411.5928,", "citeRegEx": "14", "shortCiteRegEx": "14", "year": 2014}, {"title": "Generating images with recurrent adversarial networks", "author": ["Daniel Jiwoong Im", "Chris Dongjoo Kim", "Hui Jiang", "Roland Memisevic"], "venue": null, "citeRegEx": "15", "shortCiteRegEx": "15", "year": 2016}, {"title": "Pixel-level domain transfer", "author": ["Donggeun Yoo", "Namil Kim", "Sunggyun Park", "Anthony Paek", "In-So Kweon"], "venue": "arXiv preprint arXiv:1603.07442,", "citeRegEx": "16", "shortCiteRegEx": "16", "year": 2016}, {"title": "A fast learning algorithm for deep belief nets", "author": ["Geoffrey E. Hinton", "Simon Osindero", "Yee Whye Teh"], "venue": "Neural Computation,", "citeRegEx": "17", "shortCiteRegEx": "17", "year": 2006}, {"title": "Training products of experts by minimizing contrastive divergence", "author": ["G.E. Hinton"], "venue": "Neural Computation, pages 1771\u20131800", "citeRegEx": "18", "shortCiteRegEx": null, "year": 2002}, {"title": "A practicle guide to restricted boltzmann machines", "author": ["G.E. Hinton"], "venue": "Technical Report: UTML TR 2010\u2013003", "citeRegEx": "20", "shortCiteRegEx": null, "year": 2010}, {"title": "Training restricted boltzmann machines using approximations to the likelihood gradient", "author": ["Tijmen Tieleman"], "venue": "In Proceedings of the 25th International Conference on Machine Learning,", "citeRegEx": "21", "shortCiteRegEx": "21", "year": 2008}, {"title": "Rectifier nonlinearities improve neural network acoustic models", "author": ["A.Y. Hannun A.L. Maas", "A.Y. Ng"], "venue": "Proc. of the ICML,", "citeRegEx": "22", "shortCiteRegEx": "22", "year": 2013}, {"title": "Rectifier linear units improve restricted boltsmann machines", "author": ["V. Nair", "G.E. Hinton"], "venue": "ICML", "citeRegEx": "23", "shortCiteRegEx": null, "year": 2010}, {"title": "Ising model", "author": ["K. Binder"], "venue": "Hazewinkel, Michiel, Encyclopedia of Mathematics, Springer", "citeRegEx": "24", "shortCiteRegEx": null, "year": 2001}], "referenceMentions": [{"referenceID": 0, "context": "The generative adversarial network (GAN) framework [1] is a relatively new type of framework that introduces a generator G and a discriminator D, both of which are often chosen to be a type of multilayer perceptron (MLP) network, and are trained in an adversarial manner.", "startOffset": 51, "endOffset": 54}, {"referenceID": 1, "context": "Recent works have reported that models trained using the GAN framework (especially for the image generation task) can generate excellent samples [2].", "startOffset": 145, "endOffset": 148}, {"referenceID": 2, "context": "Nevertheless, it is widely reported that GAN models are difficult to train and different techniques are proposed (which are summarized in [3, 4, 5]).", "startOffset": 138, "endOffset": 147}, {"referenceID": 3, "context": "Nevertheless, it is widely reported that GAN models are difficult to train and different techniques are proposed (which are summarized in [3, 4, 5]).", "startOffset": 138, "endOffset": 147}, {"referenceID": 4, "context": "Most of these work try to deal with the difficulty of optimizing the G and D simultaneously in a synchronized manner and their joint convergence[6].", "startOffset": 144, "endOffset": 147}, {"referenceID": 2, "context": "[3] proposes to train the generator by a new objective that guides G to match the statistics of features on an intermediate layer of the discriminator.", "startOffset": 0, "endOffset": 3}, {"referenceID": 2, "context": "[3] uses minibatch discrimination so that D can generate different gradients for data samples and continue guiding G via backpropagation and force G to diversify its outputs and avoid collapsing.", "startOffset": 0, "endOffset": 3}, {"referenceID": 5, "context": "In [7], a strong evidence is presented for better disentangling of the underlying factors of variation in data by higher-level representation spaces, and this might explain why a uniformly distributed random noise as input to G works.", "startOffset": 3, "endOffset": 6}, {"referenceID": 5, "context": "Also, mapping data samples to a lower dimensional but higher-level representation space by using D and then learning an associative memory model causes the Markov chain (used in the model training) to mix faster - thanks to a more uniform distribution in this new space [7].", "startOffset": 270, "endOffset": 273}, {"referenceID": 0, "context": "The generative adversarial networks (GANs) [1], variational autoencoders (VAE) [8], generative maximum mean discrepeancy networks [9], deep generative models[10], generative moment matching networks [11], etc.", "startOffset": 43, "endOffset": 46}, {"referenceID": 6, "context": "The generative adversarial networks (GANs) [1], variational autoencoders (VAE) [8], generative maximum mean discrepeancy networks [9], deep generative models[10], generative moment matching networks [11], etc.", "startOffset": 79, "endOffset": 82}, {"referenceID": 7, "context": "The generative adversarial networks (GANs) [1], variational autoencoders (VAE) [8], generative maximum mean discrepeancy networks [9], deep generative models[10], generative moment matching networks [11], etc.", "startOffset": 130, "endOffset": 133}, {"referenceID": 8, "context": "The generative adversarial networks (GANs) [1], variational autoencoders (VAE) [8], generative maximum mean discrepeancy networks [9], deep generative models[10], generative moment matching networks [11], etc.", "startOffset": 157, "endOffset": 161}, {"referenceID": 9, "context": "The generative adversarial networks (GANs) [1], variational autoencoders (VAE) [8], generative maximum mean discrepeancy networks [9], deep generative models[10], generative moment matching networks [11], etc.", "startOffset": 199, "endOffset": 203}, {"referenceID": 10, "context": "Some GAN extensions have looked at laplacian pyramid extensions [12] showing higher quality images, a recurrent network approach [13] and a de-convolution network approach [14] demonstrating reasonable success with generating natural images.", "startOffset": 64, "endOffset": 68}, {"referenceID": 11, "context": "Some GAN extensions have looked at laplacian pyramid extensions [12] showing higher quality images, a recurrent network approach [13] and a de-convolution network approach [14] demonstrating reasonable success with generating natural images.", "startOffset": 129, "endOffset": 133}, {"referenceID": 12, "context": "Some GAN extensions have looked at laplacian pyramid extensions [12] showing higher quality images, a recurrent network approach [13] and a de-convolution network approach [14] demonstrating reasonable success with generating natural images.", "startOffset": 172, "endOffset": 176}, {"referenceID": 1, "context": "Several recent papers focus on improving the stability of training and the quality of generated GAN samples [2, 12, 15, 16].", "startOffset": 108, "endOffset": 123}, {"referenceID": 10, "context": "Several recent papers focus on improving the stability of training and the quality of generated GAN samples [2, 12, 15, 16].", "startOffset": 108, "endOffset": 123}, {"referenceID": 13, "context": "Several recent papers focus on improving the stability of training and the quality of generated GAN samples [2, 12, 15, 16].", "startOffset": 108, "endOffset": 123}, {"referenceID": 14, "context": "Several recent papers focus on improving the stability of training and the quality of generated GAN samples [2, 12, 15, 16].", "startOffset": 108, "endOffset": 123}, {"referenceID": 3, "context": "Among recent ones (as recently summarized in [5]) the following pop out for stabilizing GAN training: balancing/freezing: to prevent the generator or discriminator to outpace one another, minibatch discrimination: to prevent the generator to collapse on to a single sample and enable back-propagation of gradients to improve weights, historical averaging [3], a technique common used in game theory that uses a historical average of parameters as a regularization term in optimization.", "startOffset": 45, "endOffset": 48}, {"referenceID": 2, "context": "Among recent ones (as recently summarized in [5]) the following pop out for stabilizing GAN training: balancing/freezing: to prevent the generator or discriminator to outpace one another, minibatch discrimination: to prevent the generator to collapse on to a single sample and enable back-propagation of gradients to improve weights, historical averaging [3], a technique common used in game theory that uses a historical average of parameters as a regularization term in optimization.", "startOffset": 355, "endOffset": 358}, {"referenceID": 1, "context": "[2], which uses strided convolutions in the initial layers of the discriminator and fractional-strided convolutions in the later layers of the generator, which will be discussed in the experiments section.", "startOffset": 0, "endOffset": 3}, {"referenceID": 15, "context": "In a way, our proposed technique resembles the learning algorithm for deep belief nets presented in [17], which utilizes a contrastive version of the wake-sleep algorithm proposed in [18].", "startOffset": 100, "endOffset": 104}, {"referenceID": 16, "context": "In a way, our proposed technique resembles the learning algorithm for deep belief nets presented in [17], which utilizes a contrastive version of the wake-sleep algorithm proposed in [18].", "startOffset": 183, "endOffset": 187}, {"referenceID": 0, "context": "GANs [1] are a class of generative models that pose the training process as a game between a generator network (G) and a discriminator network (D) both of which are non-stochastic models.", "startOffset": 5, "endOffset": 8}, {"referenceID": 4, "context": "The GAN problem can be formulated as a zero-sum game (minimax) which has a distinguishability game value function, V (D,G) [6]:", "startOffset": 123, "endOffset": 126}, {"referenceID": 17, "context": "Contrastive Divergence (CD) algorithm [20] runs the Markov chain for a few steps after clamping the visible layer to data examples.", "startOffset": 38, "endOffset": 42}, {"referenceID": 18, "context": "Another technique is to use persistent chains without clamping the visible layer [21].", "startOffset": 81, "endOffset": 85}, {"referenceID": 0, "context": "Images in the dataset are linearly scaled to the [-1, 1] range.", "startOffset": 49, "endOffset": 56}, {"referenceID": 1, "context": "Similar to [2], we used an Adam optimizer.", "startOffset": 11, "endOffset": 14}, {"referenceID": 19, "context": "We used leaky rectified linear activations (LeakyReLU) [22] for D with one exception to be discussed below and rectified linear activation [23] for G as activation functions.", "startOffset": 55, "endOffset": 59}, {"referenceID": 20, "context": "We used leaky rectified linear activations (LeakyReLU) [22] for D with one exception to be discussed below and rectified linear activation [23] for G as activation functions.", "startOffset": 139, "endOffset": 143}, {"referenceID": 21, "context": "We chose binary variable states as (-1) and (+1) similar to spin states in an Ising model [24].", "startOffset": 90, "endOffset": 94}, {"referenceID": 2, "context": "This is in agreement with the idea proposed in [3], which suggest changing G\u2019s objective to match an intermediate discriminator layer\u2019s statistics.", "startOffset": 47, "endOffset": 50}], "year": 2016, "abstractText": "We propose a higher-level associative memory for learning adversarial networks. Generative adversarial network (GAN) framework has a discriminator and a generator network. The generator (G) maps white noise (z) to data samples while the discriminator (D) maps data samples to a single scalar. To do so, G learns how to map from high-level representation space to data space, and D learns to do the opposite. We argue that higher-level representation spaces need not necessarily follow a uniform probability distribution. In this work, we use Restricted Boltzmann Machines (RBMs) as a higher-level associative memory and learn the probability distribution for the high-level features generated by D. The associative memory samples its underlying probability distribution and G learns how to map these samples to data space. The proposed associative adversarial networks (AANs) are generative models in the higher-levels of the learning, and use adversarial nonstochastic models D and G for learning the mapping between data and higher-level representation spaces. Experiments show the potential of the proposed networks.", "creator": "LaTeX with hyperref package"}}}