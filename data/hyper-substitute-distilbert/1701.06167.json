{"id": "1701.06167", "review": {"conference": "arxiv", "VERSION": "v1", "DATE_OF_SUBMISSION": "22-Jan-2017", "title": "Binary Matrix Guessing Problem", "abstract": "others introduce complementary reverse matrix guessing practice and provide two games might solve this problem. the first develop but introduce is elementwise finding algorithm ( sas ) which is very sparse under a score which utilizes frobenius theorem. the second algorithm is linear sorting graph algorithm which combines methodology from perceptron algorithm to robust learning algorithm. ecological algorithm moves significantly happier compared to balanced one, but less restrictive against useful statistics. we replicate computational performance across both algorithms and provide numerical analysis.", "histories": [["v1", "Sun, 22 Jan 2017 14:19:25 GMT  (8kb)", "http://arxiv.org/abs/1701.06167v1", "9 pages, 4 tables"]], "COMMENTS": "9 pages, 4 tables", "reviews": [], "SUBJECTS": "cs.AI", "authors": ["\\c{c}a\\u{g}r{\\i} latifo\\u{g}lu"], "accepted": false, "id": "1701.06167"}, "pdf": {"name": "1701.06167.pdf", "metadata": {"source": "CRF", "title": null, "authors": [], "emails": ["cagri.latifoglu@tedu.edu.tr"], "sections": [{"heading": null, "text": "ar X\niv :1\n70 1.\n06 16\n7v 1\n[ cs\n.A I]\n2 2\nJa n\n20 17"}, {"heading": "1 Introduction", "text": "Consider the following game: Alice creates an n \u00d7 n square binary matrix A with elements [aij ] \u2208 {0, 1} \u2200i, j \u2208 {1, . . . , n}. A is hidden from Bob. Bob is trying to guess A. Alice never reveals A however returns a score if Bob submits a guess B where [Bij ] \u2208 {0, 1} \u2200i, j \u2208 {1, . . . , n}. The scoring function f takes A and B as inputs and returns score s \u2208 IR. Note that Bob does not know scoring function f or A and can only observe s values for his guess B1. We will assume the maximum value of score s, smax, is known by both parties, and is attained when A = B. Furthermore we will assume the function f provides \u201cinformative\u201d values of s for partially correct guesses. For example a scoring function which returns 1 if A == B and 0 otherwise is not really informative as the Bob can not infer the correct positions of 0s and 1s from partial matches. However, a scoring function that utilizes the Frobenius Distance (FD) between A and B can be considered informative as one can measure a sense of proximity. For the rest of the paper, we will assume the scoring function, f , is defined as in the following2:\nFD(A,B) = \u221a\ntrace((A\u2212 B) \u2217 (A\u2212B)\u22a4) (1) smax = FD(C,D) (2) f(A,B) = smax \u2212 FD(A,B) = s (3) where (A\u2212 B)\u22a4 is the conjugate transpose of (A\u2212 B), and,\nCn\u00d7n =\n\n    1 1 \u00b7 \u00b7 \u00b7 1 1 1 \u00b7 \u00b7 \u00b7 1 ... ... . . .\n... 1 1 \u00b7 \u00b7 \u00b7 1\n\n    , Dn\u00d7n =\n\n    0 0 \u00b7 \u00b7 \u00b7 0 0 0 \u00b7 \u00b7 \u00b7 0 ... ... . . .\n... 0 0 \u00b7 \u00b7 \u00b7 0\n\n    .\n1One might consider brute force enumeration to guess the target matrix. For matrices of small dimensions, this approach might be viable, however the number of possibilities increases exponentially as dimension of the matrix increase. For example for a 10\u00d7 10 matrix, there are 2100 possibilities\n2One could have approached this problem as a matrix distance minimization problem, i.e. smaller distances correspond to closer matches between the guess matrix, and the target matrix, however in our setting we would like use the term \u201cscore\u201d instead of \u201cdistance\u201d so we subtract the distance between target matrix and guess matrix from the maximum possible distance,smax.\nFD between two binary matrices of equal dimensions, is simply square root of sum of squares of elementwise differences. See Appendix A. Next we present our first solution approach, the Elementwise Probing Algorithm."}, {"heading": "2 Elementwise Probing", "text": "Consider the following: Let B0 and B1 be identical n \u00d7 n binary matrices except at index {l,m}, therefore B0i,j = B1i,j \u2200(i, j) \u2208 {(i, j)|{1, . . . , n} \u00d7 {1, . . . , n} \\ {l,m}}. Without loss of generality, assume B0l,m = 0 and B1l,m = 1. At the other indices these two matrices are exactly the same. Now consider the scores they would get when evaluated against an arbitrary target binary matrix, A: s0 = f(A,B0) and s1 = f(A,B1). It is trivial to see that s0 6= s1 and either s0 > s1 or s0 < s1. Furthermore, Al,m = 0 =\u21d2 s0 > s1 and Al,m = 1 =\u21d2 s0 < s1 since scores increase as corresponding entries in matrices A (target) and B (guess) match. See Appendix B. Utilizing this observation, we can construct the following algorithm:\nAlgorithm 1 Elementwise Probing Algorithm (EPA)\n1: Randomly create a binary (guess) matrix B 2: for all i \u2208 {1, . . . , n} do 3: for all j \u2208 {1, . . . , n} do 4: Set Bi,j = 0, get score s0 5: Set Bi,j = 1, get score s1 6: (Note that s0 6= s1) 7: if s0 > s1 then 8: Guess Ai,j as 0 9: Set Bi,j as 0\n10: else 11: Guess Ai,j as 1 12: Set Bi,j as 1 13: end if\n14: end for 15: end for\nWith Algorithm 1, after a maximum of 2 \u00d7 n2 FD evaluations, we can extract the target matrix A. We\u2019ve implemented a serial3 version of this algorithm in Python, run the code on a computer with Intel Core i7-920 processor with base frequency 2.66 GHz and 18 GB RAM, with Ubuntu 16.04 as the operating system. The computational results are presented in Table 1. In Table 1, GridSize is simply equal to n, ACC is the percentage of times the Algorithm 1 completely extracted the target in 100 trials (1.00 means 100% success), timeAVR is average solution time (in seconds) of 100 trials, and timeSD is the standard deviation of the solution times (in seconds) of 100 trials. In the next section we present our second solution algorithm: Additive Reinforcement Learning Algorithm."}, {"heading": "3 Additive Reinforcement Learning Algorithm", "text": "For solving the binary matrix guessing problem, we have developed a perceptron-like [1] learning algorithm, called Additive Reinforcement Learning Algorithm (ARLA) which learns the target matrix after making a certain number of queries. ARLA, in spirit, is close to perceptron and reinforcement learning [2], as close matches between the guess and the target reinforces ARLA\u2019s current guess of the positions of 0s and 1s in the target matrix. Perceptron algorithm is a supervised learning algorithm. It solves a binary classification problem, uses vector inputs, and updates weights of the elements in the vector in an additive manner. In\n3Note that Algorithm 1 is easily parallelizable, as each index pair (i, j) can be tested independently from other pairs.\nreinforcement learning there are multiple components which are states, actions, rewards, and various rules that capture state transitions, and reflect the constraints on learning agent\u2019s perception of the environment. The objective is to learn a policy that would map the states to actions so that the reward the agent obtains is maximized. From a reinforcement learning perspective, the scores in ARLA can be classified as rewards, and the guesses can be classified as states. However there are no constraints on state transition, states do not depend on each other or past history, as each guess is created randomly and independently from other guesses. Due to this independence property, ARLA training is embarrassingly parallelizable. ARLA algorithm combines the additive updates feature of the perceptron algorithm and the reward for state idea of reinforcement learning. Unlike perceptron algorithm, in ARLA the inputs are matrices (i.e. guesses) instead of vectors. Rewards of the guesses (i.e. scores in our case) are multiplied with the guess matrix and added on top of each other during the training period. In its current form, ARLA requires many samples (i.e. a guess, B, and its score, s) for training to deduce the correct target, A. The number of samples required increases as the matrix dimensions increase. To model this dependence, we will first define the number of queries ARLA makes (i.e. the number of samples it will collect) during the training period as sc \u00d7 n where n is the dimension of the matrix, and sample coefficient, sc, is a multiplier that is selected empirically. In our numerical experiments, we observed that setting sc to 10000 for a 10\u00d7 10 matrix is enough. This means during the training period, ARLA will use 10\u00d7 10000 samples. To illustrate the algorithm we will first define an all zeros matrix:\nEn\u00d7n =\n\n    0 0 \u00b7 \u00b7 \u00b7 0 0 0 \u00b7 \u00b7 \u00b7 0 ... ... . . .\n... 0 0 \u00b7 \u00b7 \u00b7 0\n\n   \nDuring the training period, we will capture the information about the guess and its score in E . We will randomly create a binary matrix B, obtain s = f(A,B), update E and repeat this process sc\u00d7 n times. E is updated during the sampling period in the following manner:\nAlgorithm 2 Additive Learning Algorithm (ARLA)\n1: for all i \u2208 {1, . . . , n \u2217 sc} do 2: Randomly create n\u00d7 n binary guess matrix B 3: Get s = f(A,B) 4: E \u2190 E + s \u2217 B 5: end for\nIn Algorithm 2, the key idea is good guess layouts which give high scores give two key pieces of information: the layout itself, namely the current guess B and the score of this layout, namely s. We combine these two pieces by multiplying them and adding the resulting matrix to E , so that after learning period terminates, the accumulated score and layout information will be captured in E in a cumulative manner. If the learning period was long enough, the positions of 1s and 0s in the target matrix, A, can be deduced from E . The key observation here is, the scores accumulated in E at positions that correspond to positions of 1s in A will be greater than the scores accumulated in E at positions that correspond to positions of 0s in A. Following this idea, first we find the minimum of E , and call it m = min(E). Now subtract m from all elements of E .\nm = min(E) (4) E := E \u2212m (5)\nThen we take the average of all elements of E , and call it avg. Then we create a matrix of all zeros,\nFn\u00d7n =\n\n    0 0 \u00b7 \u00b7 \u00b7 0 0 0 \u00b7 \u00b7 \u00b7 0 ... ... . . .\n... 0 0 \u00b7 \u00b7 \u00b7 0\n\n   \nthen we do the following operation:\nAlgorithm 3 Additive Learning Algorithm: Final Inference\n1: for all i \u2208 {1, . . . , n} do 2: for all j \u2208 {1, . . . , n} do 3: if Ei,j \u2265 avg then 4: Fi,j = 1 5: else 6: Fi,j = 0 7: end if\n8: end for\n9: end for\nThe output of Algorithm 3, F , will be equal to A if the learning period was long enough. The probability of F converging to A is dependent on the length of the sampling process. We have implemented ARLA on Python, the computational results for different dimension sizes, and different sampling coefficients, can be seen in Table C2, Table C3, and Table C4. 4 GridSize is simply the dimension of the matrices, n, SampleCoefficient is the multiplier we use to control the number of training samples, Accuracy the percentage of times Algorithm 2 completely extracted the target in 100 trials (1.00 means 100% success), timeAVR is average solution time (in seconds) of 100 trials, and timeSD is the standard deviation of the solution times (in seconds) of 100 trials. Our results on performance of ARLA for this problem are empirical. We are currently working on the mathematical proof of ARLA, and will present the results along with convergence properties and\n4One can easily parallelize the training period by distributing the workload of the for loop in Algorithm 2 to multiple computers.\ncharacterization of the optimal number of samples required for convergence to the target matrix in a future publication. Compared to EPA, ARLA is orders of magnitude slower. For successful target matrix recovery, it needs a lot of samples. The largest instance reported in Table C4 has n = 15 and the average solution time is 1145.78 seconds. ARLA is embarrassingly parallelizable and the solution time decreases linearly with the number of compute instances allocated to training period. With 10 computers working in parallel, it would take approximately 113 seconds to solve the 15 \u00d7 15 instance with ARLA which is still significantly slower than EPA."}, {"heading": "4 Conclusion", "text": "We have introduced the Binary Matrix Guessing Problem and provided two algorithms to solve this problem: Elementwise Probing Algorithm (EPA) and Additive Learning Algorithm (ARLA). EPA is very fast and can be made even faster if parallelized however it requires a scoring metric that is responsive to elementwise changes. ARLA can also be used to solve the same problem and compared to EPA it generalizes better, however it is slower compared to EPA but can be improved speedwise since its embarrassingly parallelizable. We have used ARLA to design a photonic crystal with very good focusing/coupling properties [citation goes here] where the scoring function doesn\u2019t have necessarily good qualities, such as elementwise sensitivity, as we have in Frobenius Distance. As future work, ARLA will be extended to consider the rewards from complements. Consider a guess matrix B which is the complement of the target matrix A. This means wherever A has zeros B has ones, and A has ones B has zeros. The score of f(A,B) = 0 since FD(A,B) = n. So in its current form of ARLA, during the training period, when we do the following update E \u2190 E +0 \u2217B, E doesn\u2019t change. However a smarter algorithm might recognize having a zero score would mean complementing current guess could yield the target, and act accordingly. The other research direction is evaluating the performance of a multiplicative algorithm such as Winnow Algorithm [3] for Binary Matrix Guessing Problem."}, {"heading": "5 Acknowledgements", "text": "The author thanks Dr. Tayfun Ku\u0308c\u0327u\u0308ky\u0131lmaz, Dr. Mirbek Turduev, Dr. Utku I\u0307nan Tu\u0308rkmen and Dr. Sinan Hanay from TED University for the helpful discussions. We have designed these algorithms to solve a problem posed by Dr. Mirbek Turduev. Dr. Tayfun Ku\u0308c\u0327u\u0308ky\u0131lmaz provided keen observations during the design process of EPA. Dr. Utku I\u0307nan Tu\u0308rkmen provided helpful comments on ARLA algorithm. Dr. Sinan Hanay provided helpful comments throughout the development process."}, {"heading": "Appendix B Matrix Proof", "text": "Consider two 2\u00d7 2 binary matrices K and L which will be used as our guess matrices:\nK2\u00d72 = ( a b\n0 d\n) , L2\u00d72 = ( a b\n1 d\n)\n.\nNote that K and L are identical except at index (2, 1). K(2, 1) = 0 and L(2, 1) = 1. Also note that, smax = 2 since n = 2. Consider the 2\u00d7 2 binary matrix M which will be used as our target matrix:\nM2\u00d72 = ( e f\ng h\n)\n.\nFD(K,M) = \u221a\n(a\u2212 e)2 + (b\u2212 f)2 + (0\u2212 g)2 + (d\u2212 h)2. FD(L,M) = \u221a\n(a\u2212 e)2 + (b\u2212 f)2 + (1\u2212 g)2 + (d\u2212 h)2. In above equations, note that except the terms involving g, all the other squared difference terms are identical. This helps us compare FD(K,M) and FD(L,M) without knowing the values of a, e, b, f, d, h. Let s0 = f(K,M) = 2\u2212 FD(K,M) and s1 = f(L,M) = 2\u2212 FD(L,M) Now g, which is the element at (2, 1) position in the target binary matrix M, is either 0 or 1. If g = 0 then FD(K,M) < FD(L,M), and consequently s0 > s1. If g = 1 then FD(K,M) > FD(L,M), and consequently s0 < s1.\nAppendix C ARLA Computational Results\nGridSize SampleCoefficient Accuracy timeAVR (secs) timeSD (secs)\n4 10000 1.00 2.50 0.14 4 20000 1.00 5.01 0.29 4 30000 1.00 7.51 0.43 4 40000 1.00 10.00 0.61 4 50000 1.00 12.52 0.71 4 60000 1.00 15.05 0.91 4 70000 1.00 17.61 1.25 4 80000 1.00 20.03 1.22 4 90000 1.00 22.52 1.30 4 100000 1.00 25.03 1.45 5 10000 1.00 3.87 0.26 5 20000 1.00 7.72 0.52 5 30000 1.00 11.58 0.78 5 40000 1.00 15.43 1.04 5 50000 1.00 19.32 1.33 5 60000 1.00 23.22 1.62 5 70000 1.00 27.16 2.11 5 80000 1.00 30.85 2.09 5 90000 1.00 34.71 2.35 5 100000 1.00 38.59 2.61 6 10000 1.00 5.66 0.44 6 20000 1.00 11.29 0.68 6 30000 1.00 16.95 1.04 6 40000 1.00 22.57 1.37 6 50000 1.00 28.23 1.73 6 60000 1.00 33.92 2.07 6 70000 1.00 39.57 2.44 6 80000 1.00 45.18 2.72 6 90000 1.00 50.78 2.91 6 100000 1.00 56.26 2.77\nTable C2: Additive Reinforcement Learning Computational Results 1\nGridSize SampleCoefficient Accuracy timeAVR (secs) timeSD (secs)\n7 10000 1.00 8.08 0.57 7 20000 1.00 16.14 1.11 7 30000 1.00 24.24 1.70 7 40000 1.00 32.32 2.24 7 50000 1.00 40.35 2.79 7 60000 1.00 48.42 3.35 7 70000 1.00 56.44 3.96 7 80000 1.00 64.55 4.25 7 90000 1.00 72.82 5.75 7 100000 1.00 80.81 5.28 8 10000 1.00 11.05 0.74 8 20000 1.00 22.18 1.47 8 30000 1.00 33.35 2.42 8 40000 1.00 44.45 3.01 8 50000 1.00 55.93 4.47 8 60000 1.00 67.20 5.68 8 70000 1.00 78.49 6.44 8 80000 1.00 89.29 6.95 8 90000 1.00 100.11 6.56 8 100000 1.00 110.73 5.72 9 10000 1.00 14.79 0.98 9 20000 1.00 29.53 1.96 9 30000 1.00 44.34 2.88 9 40000 1.00 59.05 3.43 9 50000 1.00 73.88 4.89 9 60000 1.00 88.45 5.05 9 70000 1.00 103.35 6.07 9 80000 1.00 118.30 7.87 9 90000 1.00 133.38 9.18 9 100000 1.00 148.22 10.25\n10 10000 0.99 19.40 1.53 10 20000 1.00 38.81 3.02 10 30000 1.00 58.13 4.21 10 40000 1.00 77.29 5.23 10 50000 1.00 96.43 5.55 10 60000 1.00 115.80 6.77 10 70000 1.00 135.03 7.83 10 80000 1.00 154.55 10.13 10 90000 1.00 173.59 9.64 10 100000 1.00 193.07 11.72\nTable C3: Additive Reinforcement Learning Computational Results 2\nGridSize SampleCoefficient Accuracy timeAVR (secs) timeSD (secs)\n11 100 0.00 0.50 0.00 11 1000 0.00 4.99 0.01 11 10000 0.89 49.85 0.22 11 100000 1.00 497.92 1.18 12 100 0.00 0.65 0.06 12 1000 0.00 6.49 0.24 12 10000 0.72 64.72 2.14 12 100000 1.00 647.08 20.84 13 100 0.00 0.82 0.15 13 1000 0.00 7.92 0.28 13 10000 0.41 80.08 7.90 13 100000 1.00 798.90 70.81 14 100 0.00 0.96 0.16 14 1000 0.00 9.56 1.59 14 10000 0.15 94.81 7.17 14 100000 1.00 945.17 49.22 15 100 0.00 1.15 0.05 15 1000 0.00 11.48 0.22 15 10000 0.01 114.62 2.17 15 100000 1.00 1145.78 21.49\nTable C4: Additive Reinforcement Learning Computational Results 3"}], "references": [{"title": "The perceptron: A probabilistic model for information storage and organization in the brain", "author": ["F. Rosenblatt"], "venue": "Psych. Rev.,", "citeRegEx": "1", "shortCiteRegEx": "1", "year": 1958}, {"title": "Introduction to Reinforcement Learning", "author": ["Richard S. Sutton", "Andrew G. Barto"], "venue": null, "citeRegEx": "2", "shortCiteRegEx": "2", "year": 1998}], "referenceMentions": [{"referenceID": 0, "context": "For solving the binary matrix guessing problem, we have developed a perceptron-like [1] learning algorithm, called Additive Reinforcement Learning Algorithm (ARLA) which learns the target matrix after making a certain number of queries.", "startOffset": 84, "endOffset": 87}, {"referenceID": 1, "context": "ARLA, in spirit, is close to perceptron and reinforcement learning [2], as close matches between the guess and the target reinforces ARLA\u2019s current guess of the positions of 0s and 1s in the target matrix.", "startOffset": 67, "endOffset": 70}], "year": 2017, "abstractText": "We introduce the Binary Matrix Guessing Problem and provide two algorithms to solve this problem. The first algorithm we introduce is Elementwise Probing Algorithm (EPA) which is very fast under a score which utilizes Frobenius Distance. The second algorithm is Additive Reinforcement Learning Algorithm which combines ideas from perceptron algorithm and reinforcement learning algorithm. This algorithm is significantly slower compared to first one, but less restrictive and generalizes better. We compare computational performance of both algorithms and provide numerical results.", "creator": "LaTeX with hyperref package"}}}