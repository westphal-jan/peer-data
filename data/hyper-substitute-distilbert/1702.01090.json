{"id": "1702.01090", "review": {"conference": "arxiv", "VERSION": "v1", "DATE_OF_SUBMISSION": "3-Feb-2017", "title": "Multi-level computational methods for interdisciplinary research in the HathiTrust Digital Library", "abstract": "we show how analytic search forms its broader, traditional academic systems and mixed - membership models can function beyond keyword search to inform resource acquisition, hypothesis formulation, neural argument extraction for cognitive discussions. our test domain creates interactive history and understanding of scientific work under animal mind and cognition. stakeholders demonstrate an transfer of collective data to the disciplines whereby identifying insights extracting attitudes about empathy retaining a critical position beneath the development, comparative psychology. participants view whether a balance of class systems and mixed - emotion technology acquired over research collections facilities can inform resource discovery in this view, using protocols that can apply generalized to other interdisciplinary research horizons. through a novel approach / dial - down topic modeling, we are able to measure a collection requiring 320, 315 fulltext volumes to 640 focal volumes for february not appear in the select ten search results in the scholarly digital library. this ultimately supports intelligent candidate for semi - automatic identification of academic structures to explore the kind of \" intellectual reading \" ( converts to novel interpretations at your root influencing scholarly work from the humanities, drilling down from massive quantities of text containing monumental coherent passages. beyond multi - level view advances understanding shaping the intellectual and academic contexts in whereas writings are spent.", "histories": [["v1", "Fri, 3 Feb 2017 17:36:19 GMT  (476kb,D)", "http://arxiv.org/abs/1702.01090v1", "23 pages, 3 figures"], ["v2", "Thu, 8 Jun 2017 00:22:59 GMT  (1053kb,D)", "http://arxiv.org/abs/1702.01090v2", "revised, 29 pages, 3 figures"]], "COMMENTS": "23 pages, 3 figures", "reviews": [], "SUBJECTS": "cs.DL cs.CL cs.IR", "authors": ["jaimie murdock", "colin allen", "katy b\\\"orner", "robert light", "simon mcalister", "andrew ravenscroft", "robert rose", "doori rose", "jun otsuka", "david bourget", "john lawrence", "chris reed"], "accepted": false, "id": "1702.01090"}, "pdf": {"name": "1702.01090.pdf", "metadata": {"source": "CRF", "title": "Multi-level computational methods for interdisciplinary research in the HathiTrust Digital Library", "authors": ["Jaimie Murdock", "Colin Allen", "Katy B\u00f6rner", "Robert Light", "Simon McAlister", "Robert Rose", "Doori Rose", "Jun Otsuka", "David Bourget", "John Lawrence", "Andrew Ravenscroft", "Chris Reed"], "emails": ["colallen@indiana.edu"], "sections": [{"heading": null, "text": "ar X\niv :1\n70 2."}, {"heading": "Introduction", "text": "Just as Britain and America have been described as two nations separated by a common language, different academic disciplines often use the same words with divergent meanings [1]. Interdisciplinary research thus poses unique challenges for information retrieval (IR). Word sense disambiguation [2, 3], differing publication practices across disciplines [4\u20136] and disjoint authorship networks [7] pose special challenges to information retrieval for interdisciplinary work. When the dimension of time is added, terminological shifts [8, 9], changing citation standards [10\u201313], and shifting modes of scholarly communication [4, 5, 14, 15] all amplify the challenges for IR to serve the need of interdisciplinary scholars.\nWidespread digitization of monographs and journals by HathiTrust [16, 17] and Google Books [18, 19] enable new longitudinal studies of change in language and discourse [8, 9, 12, 20\u201322], an approach known as \u201cdistant reading\u201d [23]. These data-driven distant readings contrast with \u201cclose readings\u201d, in which short passages and particular details are emphasized for scholarly interpretation. Newly digitized materials, which enable distant reading, differ from born-digital scholarly editions in three key ways: First, the reliance on optical character recognition (OCR) over scanned page images introduces noise into the plain-text representations of the text. Second, the unstructured text does not contain any markup that may differentiate page header and footer information, section headings, or bibliographic information from the main text. Finally, metadata is often automatically extracted and lacks the provenance information important to many humanities scholars. Researchers seeking to marry these \u201cdistant readings\u201d to more traditional \u201cclose readings\u201d are impacted by these factors [24].\nOur goal is to develop computational methods for scholarly analysis of large-scale digital collections that are robust across both the technological inconsistency of the digitized materials and the variations of meaning and practice among fields and across time. A further goal of our approach is that these methods should inform interdisciplinary research by suggesting novel interpretations and hypotheses. These methods should support scholars who wish to drill down from high level overviews of the available materials to specific pages and sentences that are relevant for understanding the various responses of scientists to contentious issues within their fields.\nIn this paper, we focus on meeting these challenges within the interdisciplinary field of history and philosophy of science (HPS). HPS must not only bridge the humanities and the sciences, but also the temporal divide between historically-significant materials and the present [25\u201328]. We show how faceted search using a combination of traditional classification systems and mixed-membership models can move beyond keyword search to inform resource\ndiscovery, hypothesis formulation, and argument extraction in our test domain, delivering methods that can be generalized to other domains.\nUsing a novel approach of drill-down topic-modeling, we demonstrate how a set of 1,315 fulltext volumes obtained by a keyword search from the HathiTrust digital library is reduced to 6 focal volumes that did not appear in the top 10 HathiTrust search results. Topic modeling of these volumes at various levels, from whole book down to individual sentences, provides the contexts for word-sense disambiguation, is relatively robust in the face of OCR errors, and ultimately supports a system for semi-automatic identification of argument structure. We show how visualizations designed for macroanalysis of disciplinary scientific journals can be extended to highlight interdisciplinarity in arguments from book data [29]. This guides researchers to passages important for the kind of \u201cclose reading\u201d that lies at the heart of scholarly work in the humanities, supporting and augmenting the interpretative work that helps us understand the intellectual and societal contexts in which scientific writings are produced and received.\nWhile the extension of computational methods to various questions in the humanities may eventually provide ways to test specific hypotheses, the main focus of such research is likely to remain exploratory and interpretative, in keeping with the humanities themselves [24, 30]. This approach nevertheless shares something with the sciences: it is experimental to the extent that it opens up a space of investigation within which quantitatively defined parameters can be systematically varied and results compared. Such exploratory experimentation is common not just in the social sciences, but also in the natural sciences [31, 32].\nOur study consisted of six stages. (1) We used a keyword search of the HathiTrust collection to generate an initial search space for the faceted search. (2) We constructed probabilistic topic models for the volumes in the initial search results. This model is a type of mixed-membership model, which captures the multiple contexts of the selected volumes and allows us to reduce the original search space even further. Topic models are also a type of bag-of-words model, making them well-suited for the unstructured text found in the HT. (3) Third, we used drill-down topic modeling to construct page-level models of the reduced set of volumes selected at the previous stage. (4) Using the page-level results to select pages for close-reading analysis, we thus supported semi-automatic argument extraction to showcase the interpretive results of our search process. (5) We exploited the close reading of arguments for exploratory investigation of sentence-level topic modeling in a single volume. (6) We used scientific mapping to find relevant volumes [33]. As current science maps represent journal data and data overlays are created based on journal names, we used a classification crosswalk from the UCSD Map of Science to the Library of Congress Classifications of these journals, allowing us to project books onto the science map."}, {"heading": "Materials", "text": ""}, {"heading": "HathiTrust Digital Library", "text": "The HathiTrust Digital Library is a collaboration between over ninety institutions to provide common access and copyright management to books digitized through a combination of Google, Internet Archive, and local initiatives. As of October 24, 2016, it consisted of over 14.7 million volumes represented both as raw page images and OCR-processed text1.\nDue to copyright concerns, access is given only to pre-1928 materials, which are assumed to be in the public domain in the United States.2 When the work described in this paper was initiated in 2012, the public domain portion of the HathiTrust consisted of approximately 300,000 volumes. At the end of the funding period in 2014, the public domain consisted of 2.1 million volumes. That number is now 5.7 million volumes, as of October 24, 2016.\nWhile the corpus size has increased 20-fold, the methods presented in this paper are aimed to reduce the portion of the corpus for analysis. For example, the first step described below is keyword search, with our initial results returning 1,315 volumes (referred to as the HT1315 corpus). Using the same query on October 24, 2016, we returned 3,497 volumes. Both of these datasets are computationally-tractable on modern workstations, in contrast to (for example) the 1.2 terabyte HTRC Extracted Features Dataset, derived from 4.8 million volumes [35].\nFrom the HT1315 corpus, we selected 86 volumes to model at the page-level (the HT86 corpus). This corpus was then further reduced to a 6-volume collection for argument mapping (HT6)."}, {"heading": "Stop Lists", "text": "Before analyzing the texts, it is common to apply a \u2018stop list\u2019 to the results, which omits words that are poor index terms [36]. Frequently, these are high-frequency words such as articles (\u2018a\u2019, \u2018an\u2019, \u2018the\u2019), prepositions (\u2018by\u2019, \u2018of\u2019, \u2018on\u2019), and pronouns (\u2018he\u2019, \u2018she\u2019, \u2018him\u2019), which contain little predictive power for statistical analysis of semantic content [37]. We use the English language stop list in the Natural Language Toolkit, which contains 153 words [38]. Additionally, we filtered words occurring 5 or fewer times, which both excludes uncommon words and infrequent non-words generated by OCR errors.\n1https://www.hathitrust.org/statistics info 2During the funding period, the fulltext of post-1928 materials were impossible to access for computational analysis from the HathiTrust. Recently, the HathiTrust Research Center (HTRC) Data Capsule has been developed to enable tightly restricted access to in-copyright materials [34]."}, {"heading": "UCSD Map of Science", "text": "For our macroanalysis, we want to see how our selected texts divide among the different academic disciplines. As a base map for the disciplinary space (analogous to a world map for geospatial space), we use the UCSD Map of Science [29] which was created by mining scientific and humanities journals indexed by Thomson Reuters\u2019 Web of Science and Elsevier\u2019s Scopus and laying them out as a map of 554 sub-disciplines \u2013 e.g., Contemporary Philosophy, Zoology, Earthquake Engineering \u2013 that are further aggregated into 13 core disciplines \u2013 e.g., Biology, Earth Sciences, Humanities. Each of the 554 sub-disciplines has a set of journals and keywords associated with it."}, {"heading": "Library of Congress Classification Outline (LCCO)", "text": "The Library of Congress Classification Outline (LCCO) is a system for classifying books, journals, and other media in physical and digital libraries. It is different from the Library of Congress Control Number (LCCN), which provides an authority record for each volume. The HathiTrust stores the LCCN, which we then use to query the Library of Congress database for the call number, which contains the LCCO, providing us with a disciplinary classification for each volume in the HT1315, HT86, and HT6 datasets."}, {"heading": "Target Domain: History and Philosophy of Scientific Work on An-", "text": "imal Cognition\nOur specific test domain is the history and philosophy of scientific work on animal cognition [39\u201341]. We aimed to identify and extract arguments about anthropomorphism from a relevant subset of the scientific works published in the late 19th and early 20th century. This period represents a critical time for the development of comparative psychology, framed at one end by the work of Charles Darwin and at the other end by the rise of the behaviorist school of psychology (see [42] for a full historical review). Using the methods described in this paper, we progressively narrowed the 300,000 volumes to a subset of 1,315 selected for topic modeling at the full-volume level, then 86 of these selected for page-level topic modeling, and then 6 specific volumes selected for manual analysis of the arguments.\nThe term \u201canthropomorphism\u201d itself illustrates the problem of word sense disambiguation. In the theological context, anthropomorphism refers to the attribution of human-like qualities to gods. In the animal cognition context, it refers to the projection of human psychological properties to animals. Given the theological controversy evoked by Darwin, our inquiry demands our system be robust in partitioning these separate discourses."}, {"heading": "Methods and Results", "text": ""}, {"heading": "Keyword Search: From Library to Reading List", "text": ""}, {"heading": "Methods", "text": "We began by conducting a keyword search in the HathiTrust collection using the HathiTrust\u2019s Solr index. We searched using terms intended to reduce the hundreds of thousands of public domain works to a set of potentially relevant texts that could be efficiently modeled with the available computing resources. Specifically, we searched for \u201cDarwin\u201d, \u201ccomparative psychology\u201d, \u201canthropomorphism\u201d, and \u201cparsimony\u201d. While the specificity of our query may be seen as too restrictive, we emphasize that we are following an exploratory research paradigm - we are not narrowing in on a particular fact, but rather surveying the available literature at the intersection of our interest in the history and philosophy of animal mind and cognition."}, {"heading": "Results", "text": "The search yielded a set of 1,315 books published between 1800 and 1962. We refer to this set of results as HT1315.3 The same query conducted in August 2015 yielded 3,027 full-text results. Notably, it took Charles Darwin 23 years to read a number of books comparable in size to HT1315, as documented in his Reading Notebooks [43]. Even at the unlikely rate of one book a day, it would take nearly four years to read this set of books in its entirety. About one fifth of the volumes retrieved were course catalogs, but even eliminating those would leave a daunting, if not quite Olympian, reading task. As the majority of the volumes selected by keyword search were not directly relevant to the research project, the potential payoff made possible by more sophisticated computational analysis of the full texts is critical for information retrieval tasks.\n3A list of titles and HT handles is provided in the supplemental materials. Because the HT collection has changed over time, this exact set of results cannot be recreated by doing the same keyword search at hathitrust.org (see http://bit.ly/1LBbqnS). At the time our project started, there were over 300,000 public domain works in the HathiTrust digital library. Currently there are over 5.5 million public domain works in the collection (see https://www.hathitrust.org/visualizations dates pd)."}, {"heading": "Probabilistic Topic Modeling of Volumes: Narrowing the Reading", "text": ""}, {"heading": "Lists", "text": ""}, {"heading": "Methods", "text": "Probabilistic topic models [44] are a family of mixed-membership models that describe documents as a distribution of topics, where each topic is itself a distribution over all words in a corpus. Topic models are generative models, that we interpret as providing a theory about context blending during the writing process [43].\nTo construct the topic models used in this study, we use Latent Dirichlet Allocation (LDA \u2013 [45]) with priors estimated via Gibbs sampling [46] as implemented in the InPhO Topic Explorer [47].\nWe initially modeled the HTRC1315 set at four different values for the number of topics, k = {20, 40, 60, 80}. We applied cosine-similarity measures to the topic mixtures attributed to each volume by the model."}, {"heading": "Results", "text": "Manual inspection of the topics generated for the different values of k showed that while all four of the models produced interpretable results, we judged that k = 60 provided the best balance between specificity and generality for our HPS goals.\nTable 1 shows the top ten topics related to the word \u2018anthropomorphism\u2019 in the k=60topic model. Inspection of this list indicates that \u2018anthropomorphism\u2019 relates to a theological topic (38), a biological topic (16), a philosophical topic (51), an anthropological topic (58), etc. The topic model checking problem [44] \u2013 i.e., how to assess the quality of the model\u2019s topics \u2013 remains an important open problem in topic modeling. Nevertheless, most of the topics in the model can be quickly summarized, with the second topic (16) being the most obvious attractor for researchers interested in comparative psychology. The second-to-last topic (1) is targeted on bibliographic citations, and is dominated by common German words that were not in the English language stop list used during initial corpus preparation.\nWe use the topic model to narrow the search by querying topics with a combination of words. We do this by finding the topic or topics with the highest sum of the probabilities for each word. For example, Table 2 shows the top ten topics returned using \u2018anthropomorphism\u2019, \u2018animal\u2019, and \u2018psychology\u2019 as input. This new query reveals two relevant topics (numbers 26 and 10) that were not returned using \u2018anthropomorphism\u2019 alone.\nSubsequently, we used all three topics (10, 16, and 26) to filter relevant books from the original set of 1,315 books. We took the cosine distance between each of the three topics to each book in HT1315. We took the sum of these three distances and filtered them at the\nthreshold of 1.25, yielding a smaller corpus of 86 volumes which we refer to as the HT86 collection. The top ten volumes identified in this way are shown in Table 3."}, {"heading": "Drill-down Topic Modeling: From Books to Pages", "text": ""}, {"heading": "Methods", "text": "We re-modeled the HT86 set at the level of individual pages, moving towards our goal of identifying arguments in text by \u201czooming in \u201d to select books which had a high number of apparently relevant pages. These reduced sets of pages become appropriate targets for manual argument identification by a human reader.\nThe notion of a \u201cdocument\u201d in LDA topic modeling is flexible. One can consider a full volume as a single document with a particular topic distribution. However, finer-grained models can also be made, in which each page, paragraph, or sentence receives its own topic distribution. Since OCR document scans in the HathiTrust have very little structural information \u2014 there is no encoding for section headings or paragraph breaks, let alone chapter breaks \u2014 page-level was the next level below the full volume that we could reliably recover."}, {"heading": "Results", "text": "For the sake of direct comparison to results reported above with the HT1315 model, we probed the k = 60 page-level model with \u2018anthropomorphism\u2019 as the query term. Results are shown in Table 4. Note that topic numbers do not correlate across the HT86 and HT1315 models. Although a theological topic (18) is at the top of the list, it is clear that biological and psychological topics have become more prevalent. Even within topic 18, \u2018evolution\u2019 and \u2018science\u2019 are now among the ten highest probability words indicating that the topic is closer\nto a \u201creligion and science\u201d topic than the more general religion topic 38 from the HT1315 model (Table 1), and reflecting the tighter range of books in the HT86 subset.\nUsing \u2018anthropomorphism\u2019, \u2018animal\u2019 and \u2018psychology\u2019 in combination as the query, topic 1 is the highest ranked topic (Table 5). In comparison to the earlier topics 10 and 16 from the HT1315 results in Table 2, this topic has more terms relevant to psychology (i.e., stimulus, experience, instinct, reaction), suggesting that for the purposes of locating specific pages in HT86 collection relevant to our initial interests, topic 1 provides the best starting point. Table 6 shows the first rows of a list of 800 highest ranked pages from HT86 using topic 1 as the query.\nWe selected six volumes from the HT86 collection which had the most pages in the top 800 highest ranked pages. None of these volumes were in the top 10 keyword search results. These volumes formed the HT6 collection:\n1. The Animal Mind: A Textbook of Comparative Psychology, 1908 (first edition), by\nMargaret Floy Washburn, psychologist. Washburn\u2019s textbook was foundational for comparative psychology and she is notable as the second woman to be president of the American Psychological Association. 2. Comparative studies in the psychology of ants and of higher animals, 1905, a monograph\nby Erich Wasmann, an entomologist who only partly accepted evolution within species, rejecting common descent, speciation via natural selection, and human evolution. 3. The Principles of Heredity, 1906, a scientific monograph by G. Archdall Reid, a physi-\ncian who argued against the Lamarckian idea of inheritance of acquired characteristics. 4. General Biology, 1910, a text book by James G. Needham, entomologist and limnolo-\ngist.\n5. The Nature and Development of Animal Intelligence, 1888, a compilation of articles by\nWesley Mills, physiologist, physician and veterinarian.\n6. Progress of Science in the Century, 1908, a book on the history of science for general\nreaders by J. Arthur Thomson, naturalist.\nThese books provide a broad array of perspectives on animal intelligence and psychology, from specialist monographs to textbooks to general-audience nonfiction. The texts were written by two Americans (Washburn and Needham), two Scots (Reid and Thomson), a Canadian (Mills), and an Austrian (Wasmann)."}, {"heading": "Argument Extraction: From Pages to Arguments", "text": ""}, {"heading": "Methods", "text": "From the HT6 collection, we selected 108 pages for further analysis (Table 7). These pages were annotated using the Argument Interchange Format ontology (AIF \u2013 [48]), which defines a vocabulary for describing arguments and argument networks. We generated 43 argument maps using AIF annotated documents, providing a visual representation of the structure of each argument (e.g., Figure 1).\nThe argument content was marked up with OVA+4, an application which links blocks of text using argument nodes. OVA+ provides a drag-and-drop interface for analyzing textual arguments. It also natively handles AIF structures. Each argument, as selected in the previous section, was divided into propositions and marked up as a set of text blocks.\n4http://ova.arg-tech.org/, see also [49]\nThese text blocks containing propositions were linked to propositions that they support, or undercut, to create an argument map."}, {"heading": "Results", "text": "We performed two types of argument analysis: Pass 1 aimed to summarize the arguments presented in each volume. Pass A aimed to sequence the arguments presented in each volume. All argument maps can be found at http://bit.ly/1bwJwF9. A full description of the study, including analysis of the arguments can be found in [50].\nAs a proof of concept, these arguments show the utility of new techniques for faceted search enabling access from a library of over 300,000 books to volume-level analysis of a subset of 1,315 books all the way down to page-level analyses of 108 pages for the purpose of identifying, encoding, modeling, and visualizing arguments. These argument diagrams function as a type of close reading, common in the humanities, and drawing on a rich tradition of philosophical literature (reviewed in [51])."}, {"heading": "Drilling Down Again: From Arguments to Sentences", "text": ""}, {"heading": "Methods", "text": "To further investigate the utility of combining distant reading methods with close reading, we applied topic modeling to the relatively small units of text comprising the sentences within a single volume. We selected Washburn\u2019s The Animal Mind text book because of its historical significance, and modeled its 17,544 sentences as a collection of documents. To explore the power of topic modeling to identify latent but meaningful relationships at the micro-level,\nwe arbitrarily chose a sentence from Argument 15 in the Washburn set and used it to query the sentence-level model of The Animal Mind for the most similar sentences using the cosine of the sentence-topic vectors."}, {"heading": "Results", "text": "The query sentence and the first half dozen results (with their similarity scores) are shown below.5\nQuery: Every statement that another being possesses psychic qualities is a conclusion from analogy, not a certainty; it is a matter of faith. (1.0000) 1. If any consciousness accompanies it, then the nearest human analogy to such con-\nsciousness is to be found in organic sensations, and these, as has just been said, must necessarily be in the human mind wholly different in quality from anything to be found in an animal whose structure is as simple as the Amoeba\u2019s. (0.8413) 2. Fancy, for example, one of us entering a room in the dark and groping about among\nthe furniture. (0.8239)\n3. This, of course, does not refer to the power to judge distance. (0.8235) 4. Again, a bodily structure entirely unlike our own must create a background of organic\nsensation which renders the whole mental life of an animal foreign and unfamiliar to us. (0.8224) 5. She disposes of the psychic learning by experience theory of Nagel by saying that the\nonly experience upon which the animal could reject the filter paper must be experience that it is not good for food. (0.8198)\n6. We speak, for example, of an \u201dangry\u201d wasp (0.7924)\nSentence 1 is obviously related in meaning to the query sentence: they overlap in some words, and directly express related ideas. But the relevance of the other examples is less direct. Sentence 6 provides a nice illustration of anthropomorphic attribution with no word overlap whatsoever. The inclusion of sentences 2 and 3 is, more puzzling. However, in the context of where these sentences appear in Washburn\u2019s book, the relationship become plainer. Sentence 2 comes in the context of the discussion of what it might be like to be an amoeba. It is thus related to sentence 1, and it is used by Washburn to make the point that our experience in the dark, which still involves visual imagination and memories of what we touch, must be \u201cwholly different in quality\u201d (per sentence 1) from what an amoeba might\n5It is important to note that LDA topic modeling is a \u201cbag of words\u201d approach; i.e., it uses only an unordered list of words in each document. It has no information about word order, punctuation, or other formatting in the text, and some of the most common words are not included. The full sentences are shown here only to aid the reader.\nexperience. Sentence 3 occurs in a footnote on page 238, and it is worth quoting the footnote in full:\nPorter observed that the distance at which spiders of the genera Argiope and Epeira could apparently see objects was increased six or eight times if the spider was previously disturbed by shaking her web (612). This, of course, does not refer to the power to judge distance. [Italics in original.]\nHere, then, we see the author cautioning the reader not to jump to a high-level interpretation of the spider behavior. The spiders may perceive objects at various distances but they don\u2019t judge it. The term \u2018judge\u2019 here is philosophically interesting, as it suggests an influence of Immanuel Kant on framing the debate. While Kant\u2019s name does not appear in Washburn\u2019s book, the term \u2018judgment\u2019 is important to Kant\u2019s theory of cognition, and fundamental to the cognitive divide he posits between humans and animals. We emphasize that this is just a speculative suggestion about Washburn\u2019s influences, but it does show how the topic modeling process can bring certain interpretive possibilities to the fore, moving the digital humanities another step closer to the goal of generating new insight into human intellectual activity."}, {"heading": "Zooming Out Again: Macroanalysis by Science Mapping", "text": ""}, {"heading": "Methods", "text": "We created visualization of the retrieved books overlaid on a map of science [33] to help understand the distribution of the retrieved books with respect to scientific disciplines.\nNew datasets are overlaid on this map by matching records via journal names or keywords to the 554 sub-disciplines. However, the present work is the first instance of using book data on a science map. We constructed a classification crosswalk to align the journal-based subdisciplines with a book classification system. The Library of Congress Classification Outline (LCCO) provides a disciplinary taxonomy similar to that of the UCSD Map of Science. By using the Library of Congress Control Numbers (LCCN) assigned to each of the 25,258 journal sources in the UCSD Map of Science, we were able to assign likelihoods of each LCCN belonging to each subdiscipline.\nWe assigned each book in our HathiTrust collection a UCSD sub-discipline based on its LCCN. A number of items in the HathiTrust collection never receive LCCNs. For example, university library collections frequently contain course bulletins that are not catalogued by the Library of Congress. We removed the uncatalogued items and projected the remaining volumes onto the UCSD map of science."}, {"heading": "Results", "text": "Using the LCCO classification crosswalk, we located 776 out of 1,315 books on the UCSD Map of Science, as shown in Figure 2.\nIn general, the map confirms that the initial keyword-based selection from the HathiTrust retrieved books that are topically positioned below the \u201cequator\u201d of the map, with particular concentrations in the life sciences and humanities, as was to be expected. The map provides additional visual confirmation that the further selections via topic modeling to a subset of 86 and then six of the original collection of 1,315 managed to target books in appropriate areas of interest. In the interactive online version, nodes can be selected, showing which volumes are mapped and providing the title and links to various external sources of metadata.\nUltimately, the map overlay provides a grand overview and a potential guide to specific books that were topic modeled, although without further guidance from the topic models,\nthe map does not fully meet the desired objective of linking a high-level overview to more detailed textual analysis."}, {"heading": "General Discussion", "text": "The notion of \u201ddistant reading\u201d [23] has captured the imagination of many in the digital humanities. But the proper interpretation of large-scale quantitative models itself depends on having a feel for the texts, similar to Barbara McClintock\u2019s stress on having a \u201cfeeling for the organism\u201d [52] or Richard Feynman on the importance for nascent physicists of developing \u201ca \u2018feel\u2019 for the subject\u201d beyond rote knowledge of the basic laws [53]. The interpretation of data and models, whether in science or the humanities, is itself (as yet, and despite a few small successes in fields such as medical diagnosis) a task at which humans vastly outperform machines. For this reason, the digital humanities remain a fundamentally hermeneutic enterprise [30], and one in which distant readings and close readings must be tightly linked if anything is to make sense.\nIn this paper we have motivated, introduced, and exemplified a multi-level computational process for connecting macro-analyses of massive amounts of documents to micro-level close reading and careful interpretation of specific passages within those documents. Thus we\nhave demonstrated how existing computational methods can be combined in novel ways to go from a high-level representation of many documents to the discovery and analysis of specific arguments contained within documents.\nWe have also shown how to zoom out to a macro-level overview of the search results. We presented a novel classification crosswalk between the Library of Congress Classification Outline (LCCO) and the UCSD Map of Science, which was constructed using only journal data, to extend the data to books. Because of the mismatch between the book data and the journal metadata, the crosswalk is not perfect, and the method of averaging locations places many books in uninterpretable regions of the map. Nevertheless, the visualization provides some useful information about the effectiveness of a simple keyword search in locating items of interest within a collection of hundreds of thousands of books.\nThat our method succeeded in discovering texts relevant to a highly specific interdisciplinary inquiry shows its robustness to inconsistent and incomplete data. The HathiTrust Digital Library had OCR errors in 2.4% of volumes as of May 2010 [54]. While the quality of the HathiTrust has increased in the intervening years, it is still a pervasive issue in digital archives [55].\nMulti-level topic modeling combined with an information-theoretic measure of distance can efficiently locate materials that are germane to a specific research project, going from more than a thousand books, to fewer than a hundred using book-level topic models, and further narrowing this set down to a small number of pages within a handful of books using page-level topic models. The similarity measure we used is mediated by the topics in the model, and because every topic assigns a probability to every word in the corpus, this approach is highly adept at finding implicit relationships among the documents. Typical applications of topic modeling, such as graphing the rise and fall of topics through time, may show large-scale trends, but do not mediate the interplay between distant reading and close reading that leads to deeper understanding. By connecting abstract, machine-discovered topics to specific arguments within the text, we have shown how topic modeling can bridge this gap."}, {"heading": "Conclusion", "text": "The process and results of our iterative drill-down method are summarized in Figure 3, showing the reduction of the 300,000 public domain volumes in the HathiTrust in August 2012 to the HT1315 collection, to the roughly 32,000 pages in the HT86 collection, to the over 17,000 sentences of the HT6 collection, to smaller set of the 108 pages selected for close reading and argument markup. This reduction allowed us to identify key elements of late 19th\nand early 20th Century arguments about anthropomorphizing of nonhuman organisms, and to uncover the surprising taxonomic range of these arguments to include consideration even of consciousness in amoebae. The alternative approach of simply counting the occurrence of species names within these books would only have hinted at the presence of such discussions whereas, by putting words into context, topic modeling enabled researchers to zero in on passages worthy of detailed analysis and humanistic interpretation."}, {"heading": "Acknowledgments", "text": "This work was funded by the National Endowment for Humanities (NEH) Office of Digital Humanities (ODH) Digging Into Data Challenge (\u201cDigging by Debating\u201d; PIs Allen, Bo\u0308rner, Ravenscroft, McAllister, Reed, and Bourget; award no. HJ-50092-12). The authors thank the Indiana University Cognitive Science Program for continued supplemental research funding, and especially for research fellowships for Jaimie Murdock and Robert Rose. We also thank the HathiTrust Research Center (HTRC) for their support of research activities and generous access to materials."}, {"heading": "Author\u2019s contributions", "text": "CA motivated the research for the history and philosophy of comparative psychology. RL and JM constructed the LoC-UCSD crosswalk. DR, JO, and RR programmed the vsm topic model implementation. JM constructed the interactive UCSD map of science, with feedback from RL and KB. SM carried out the argument analysis using the OVA+ tool built by CR and JL, and a protocol devised by CA, DB, and AR. CA, RL, JM and KB wrote the paper."}], "references": [{"title": "Argue, observe, assess: Measuring disciplinary identities and differences through socio-epistemic discourse", "author": ["Bradford Demarest", "Cassidy R Sugimoto"], "venue": "Journal of the Association for Information Science and Technology,", "citeRegEx": "1", "shortCiteRegEx": "1", "year": 2015}, {"title": "Word Sense Disambiguation, pages 1027\u20131030", "author": ["Rada Mihalcea"], "venue": null, "citeRegEx": "2", "shortCiteRegEx": "2", "year": 2010}, {"title": "Word Sense Disambiguation: Algorithms and Applications", "author": ["Eneko Agirre", "Philip Edmonds"], "venue": "Text Speech and Language Technology,", "citeRegEx": "3", "shortCiteRegEx": "3", "year": 2006}, {"title": "Scholarly communication and bibliometrics", "author": ["Christine L Borgman", "Jonathan Furner"], "venue": "Annual Review of Information Science and Technology,", "citeRegEx": "4", "shortCiteRegEx": "4", "year": 2002}, {"title": "Scholarly communication and epistemic cultures", "author": ["Blaise Cronin"], "venue": "New Review of Academic Librarianship,", "citeRegEx": "5", "shortCiteRegEx": "5", "year": 2003}, {"title": "Disciplinary differences in Twitter scholarly communication", "author": ["Kim Holmberg", "Mike Thelwall"], "venue": "Scientometrics, 101(2):1027\u20131042,", "citeRegEx": "6", "shortCiteRegEx": "6", "year": 2014}, {"title": "Searching for bridges between disciplines: an author co-citation analysis on the research into scholarly communication", "author": ["Riitta K\u00e4rki"], "venue": "Journal of Information Science,", "citeRegEx": "7", "shortCiteRegEx": "7", "year": 1996}, {"title": "Diachronic Word Embeddings Reveal Statistical Laws of Semantic Change", "author": ["William L Hamilton", "Jure Leskovec", "Dan Jurafsky"], "venue": "Association for Computational Linguistics (ACL),", "citeRegEx": "8", "shortCiteRegEx": "8", "year": 2016}, {"title": "Cultural Shift or Linguistic Drift", "author": ["William L Hamilton", "Jure Leskovec", "Dan Jurafsky"], "venue": "Comparing Two Computational Measures of Semantic Change. CoRR,", "citeRegEx": "9", "shortCiteRegEx": "9", "year": 2016}, {"title": "The norms of citation behavior: Prolegomena to the footnote", "author": ["Norman Kaplan"], "venue": "American Documentation,", "citeRegEx": "10", "shortCiteRegEx": "10", "year": 1965}, {"title": "Progress in Documentation - The Complexities of Citation Practice: A Review of Citation Studies", "author": ["Mengxiong Liu"], "venue": "Journal of Documentation,", "citeRegEx": "11", "shortCiteRegEx": "11", "year": 1993}, {"title": "Long-term variations in the aging of scientific literature: From exponential growth to steady-state science (1900\u20132004)", "author": ["Vincent Larivi\u00e8re", "\u00c9ric Archambault", "Yves Gingras"], "venue": "Journal of the American Society for Information Science and Technology,", "citeRegEx": "12", "shortCiteRegEx": "12", "year": 2008}, {"title": "Evaluation practices and effects of indicator use\u2013a literature review", "author": ["Sarah de Rijcke", "Paul F Wouters", "Alex D Rushforth", "Thomas P Franssen", "Bj\u00f6rn Hammarfelt"], "venue": "Research Evaluation,", "citeRegEx": "13", "shortCiteRegEx": "13", "year": 2016}, {"title": "The rapid evolution of scholarly communication", "author": ["Andrew Odlyzko"], "venue": "Learned Publishing,", "citeRegEx": "14", "shortCiteRegEx": "14", "year": 2002}, {"title": "Electronic Publication and the Narrowing of Science and Scholarship", "author": ["James A Evans"], "venue": "LP \u2013 399,", "citeRegEx": "15", "shortCiteRegEx": "15", "year": 2008}, {"title": "This library never forgets: Preservation, cooperation, and the making of HathiTrust Digital Library", "author": ["Jeremy York"], "venue": "Archiving 2009: Final Program & Proceedings,", "citeRegEx": "16", "shortCiteRegEx": "16", "year": 2009}, {"title": "HathiTrust: A research library at web scale", "author": ["Heather Christenson"], "venue": "Library Resources and Technical Services,", "citeRegEx": "17", "shortCiteRegEx": "17", "year": 2011}, {"title": "Mass Digitization of Books", "author": ["Karen Coyle"], "venue": "The Journal of Academic Librarianship,", "citeRegEx": "18", "shortCiteRegEx": "18", "year": 2006}, {"title": "Google Book Search: Document Understanding on a Massive Scale", "author": ["Luc Vincent"], "venue": "In International Conference on Document Analysis and Recognition,", "citeRegEx": "19", "shortCiteRegEx": "19", "year": 2007}, {"title": "Beyond Word Frequency: Bursts, Lulls, and Scaling in the Temporal Distributions of Words", "author": ["Eduardo G Altmann", "Janet B Pierrehumbert", "Adilson E Motter"], "venue": "PLoS ONE,", "citeRegEx": "20", "shortCiteRegEx": "20", "year": 2009}, {"title": "Quantitative Analysis of Culture", "author": ["Jean-Baptiste Michel", "Yuan Kui Shen", "Aviva Presser Aiden", "Adrian Veres", "Matthew K Gray", "The Google Books Team", "Joseph P Pickett", "Dale Hoiberg", "Dan Clancy", "Peter Norvig", "Jon Orwant", "Steven Pinker", "Martin A Nowak", "Erez Lieberman Aiden"], "venue": "Using Millions of Digitized Books. Science,", "citeRegEx": "21", "shortCiteRegEx": "21", "year": 2011}, {"title": "Rank Diversity of Languages: Generic Behavior in Computational Linguistics", "author": ["Germinal Cocho", "Jorge Flores", "Carlos Gershenson", "Carlos Pineda", "Sergio S\u00e1nchez"], "venue": "PLoS ONE,", "citeRegEx": "22", "shortCiteRegEx": "22", "year": 2015}, {"title": "Distant Reading", "author": ["Franco Moretti"], "venue": "Verso Books, London, illustrate edition,", "citeRegEx": "23", "shortCiteRegEx": "23", "year": 2013}, {"title": "Theorizing Research Practices We Forgot to Theorize", "author": ["Ted Underwood"], "venue": "Twenty Years Ago. Representations,", "citeRegEx": "24", "shortCiteRegEx": "24", "year": 2014}, {"title": "The Relations Between the History and the Philosophy of Science", "author": ["Thomas Kuhn"], "venue": "In The Essential Tension,", "citeRegEx": "25", "shortCiteRegEx": "25", "year": 1979}, {"title": "Scientific change: Philosophical models and historical research", "author": ["Larry Laudan", "Arthur Donovan", "Rachel Laudan", "Peter Barker", "Harold Brown", "Jarrett Leplin", "Paul Thagard", "Steve Wykstra"], "venue": null, "citeRegEx": "26", "shortCiteRegEx": "26", "year": 1986}, {"title": "Two Kinds of \u201dNew Historicism\u201d for Philosophers", "author": ["Ian Hacking"], "venue": "New Literary History,", "citeRegEx": "27", "shortCiteRegEx": "27", "year": 1990}, {"title": "Design and Update of a Classification System: The UCSD Map of Science", "author": ["Katy B\u00f6rner", "Richard Klavans", "Michael Patek", "Angela M. Zoss", "Joseph R. Biberstine", "Robert P. Light", "Vincent Larivi\u00e8re", "Kevin W. Boyack"], "venue": "PLoS ONE,", "citeRegEx": "29", "shortCiteRegEx": "29", "year": 2012}, {"title": "Entering New Fields: Exploratory Uses of Experimentation", "author": ["Friedrich Steinle"], "venue": "Philosophy of Science,", "citeRegEx": "31", "shortCiteRegEx": "31", "year": 1997}, {"title": "The Nature and Context of Exploratory Experimentation : An Introduction to Three Case Studies of Exploratory Research", "author": ["C. Kenneth Waters"], "venue": "History and Philosophy of the Life Sciences,", "citeRegEx": "32", "shortCiteRegEx": "32", "year": 2007}, {"title": "Atlas of Science: Visualizing What We Know", "author": ["Katy B\u00f6rner"], "venue": null, "citeRegEx": "33", "shortCiteRegEx": "33", "year": 2010}, {"title": "Cloud Computing Data Capsules for Non-Consumptive Use of Texts", "author": ["Jiaan Zeng", "Guangchen Ruan", "Alexander Crowell", "Atul Prakash", "Beth Plale"], "venue": "ScienceCloud", "citeRegEx": "34", "shortCiteRegEx": "34", "year": 2014}, {"title": "Extracted Feature Dataset from 4.8 Million HathiTrust Digital Library Public Domain Volumes", "author": ["Boris Capitanu", "Ted Underwood", "Peter Organisciak", "Sayan Bhattacharyya", "Loretta Auvil", "Colleen Fallaw", "J. Stephen Downie"], "venue": null, "citeRegEx": "35", "shortCiteRegEx": "35", "year": 2015}, {"title": "A stop list for general text", "author": ["Christopher Fox"], "venue": "SIGIR Forum,", "citeRegEx": "36", "shortCiteRegEx": "36", "year": 1989}, {"title": "A statistical approach to mechanized encoding and searching of literary information", "author": ["Hans Peter Luhn"], "venue": "IBM Journal of research and development,", "citeRegEx": "37", "shortCiteRegEx": "37", "year": 1957}, {"title": "Species of Mind: The Philosophy and Biology of Cognitive Ethology. A Bradford book", "author": ["Colin Allen", "Marc Bekoff"], "venue": null, "citeRegEx": "39", "shortCiteRegEx": "39", "year": 1999}, {"title": "Animal cognition", "author": ["Kristin Andrews"], "venue": "The Stanford Encyclopedia of Philosophy. Summer 2016 edition,", "citeRegEx": "40", "shortCiteRegEx": "40", "year": 2016}, {"title": "Animal consciousness", "author": ["Colin Allen", "Michael Trestman"], "venue": "The Stanford Encyclopedia of Philosophy. Summer 2015 edition,", "citeRegEx": "41", "shortCiteRegEx": "41", "year": 2015}, {"title": "From Darwin to Behaviourism: Psychology and the Minds of Animals", "author": ["Robert Boakes"], "venue": null, "citeRegEx": "42", "shortCiteRegEx": "42", "year": 1984}, {"title": "Exploration and Exploitation of Victorian Science in Darwin\u2019s Reading Notebooks", "author": ["Jaimie Murdock", "Colin Allen", "Simon DeDeo"], "venue": null, "citeRegEx": "43", "shortCiteRegEx": "43", "year": 2015}, {"title": "Probabilistic Topic Models", "author": ["David M Blei"], "venue": "Communications of the ACM,", "citeRegEx": "44", "shortCiteRegEx": "44", "year": 2012}, {"title": "Latent Dirichlet Allocation", "author": ["David M Blei", "Andrew Y Ng", "Michael I Jordan"], "venue": "Journal of Machine Learning Research,", "citeRegEx": "45", "shortCiteRegEx": "45", "year": 2003}, {"title": "Finding scientific topics", "author": ["Thomas L Griffiths", "Mark Steyvers"], "venue": "Proceedings of the National Academy of Sciences,", "citeRegEx": "46", "shortCiteRegEx": "46", "year": 2004}, {"title": "Visualization Techniques for Topic Model Checking", "author": ["Jaimie Murdock", "Colin Allen"], "venue": "In Proceedings of the 29th AAAI Conference (AAAI-15),", "citeRegEx": "47", "shortCiteRegEx": "47", "year": 2015}, {"title": "Towards an argument interchange format", "author": ["Carlos Ches\u00f1evar", "Sanjay Modgil", "Iyad Rahwan", "Chris Reed", "Guillermo Simari", "Matthew South", "Gerard Vreeswijk", "Steven Willmott"], "venue": "The Knowledge Engineering Review,", "citeRegEx": "48", "shortCiteRegEx": "48", "year": 2006}, {"title": "AIFdb: Infrastructure for the Argument Web", "author": ["John Lawrence", "Floris Bex", "Chris Reed", "Mark Snaith"], "venue": "In Frontiers in Artificial Intelligence and Applications,", "citeRegEx": "49", "shortCiteRegEx": "49", "year": 2012}, {"title": "Mining Arguments From 19th Century Philosophical Texts Using Topic Based Modelling", "author": ["John Lawrence", "Chris Reed", "Colin Allen", "Simon McAlister", "Andrew Ravenscroft"], "venue": "In Proceedings of the First Workshop on Argumentation Mining,", "citeRegEx": "50", "shortCiteRegEx": "50", "year": 2014}, {"title": "Argument diagramming in logic, law and artificial intelligence", "author": ["Chris Reed", "Douglas Walton", "Fabrizio Macagno"], "venue": "The Knowledge Engineering Review,", "citeRegEx": "51", "shortCiteRegEx": "51", "year": 2007}, {"title": "A Feeling for the Organism: The Life and Work of Barbara McClintock", "author": ["Evelyn Fox Keller"], "venue": "W.H. Freeman and Co., San Francisco,", "citeRegEx": "52", "shortCiteRegEx": "52", "year": 1983}, {"title": "Measuring Content Quality in a Preservation Repository: HathiTrust and Large-Scale Book Digitization", "author": ["Paul Conway"], "venue": "In Proceedings of 7th International Conference on Preservation of Digital Objects,", "citeRegEx": "54", "shortCiteRegEx": "54", "year": 2010}, {"title": "Falling Characters and Sentences: The Persistence of the OCR Problem in Digital Repository E-Books", "author": ["Diana Kichuk. Loose"], "venue": null, "citeRegEx": "55", "shortCiteRegEx": "55", "year": 2015}], "referenceMentions": [{"referenceID": 0, "context": "Just as Britain and America have been described as two nations separated by a common language, different academic disciplines often use the same words with divergent meanings [1].", "startOffset": 175, "endOffset": 178}, {"referenceID": 1, "context": "Word sense disambiguation [2, 3], differing publication practices across disciplines [4\u20136] and disjoint authorship networks [7] pose special challenges to information retrieval for interdisciplinary work.", "startOffset": 26, "endOffset": 32}, {"referenceID": 2, "context": "Word sense disambiguation [2, 3], differing publication practices across disciplines [4\u20136] and disjoint authorship networks [7] pose special challenges to information retrieval for interdisciplinary work.", "startOffset": 26, "endOffset": 32}, {"referenceID": 3, "context": "Word sense disambiguation [2, 3], differing publication practices across disciplines [4\u20136] and disjoint authorship networks [7] pose special challenges to information retrieval for interdisciplinary work.", "startOffset": 85, "endOffset": 90}, {"referenceID": 4, "context": "Word sense disambiguation [2, 3], differing publication practices across disciplines [4\u20136] and disjoint authorship networks [7] pose special challenges to information retrieval for interdisciplinary work.", "startOffset": 85, "endOffset": 90}, {"referenceID": 5, "context": "Word sense disambiguation [2, 3], differing publication practices across disciplines [4\u20136] and disjoint authorship networks [7] pose special challenges to information retrieval for interdisciplinary work.", "startOffset": 85, "endOffset": 90}, {"referenceID": 6, "context": "Word sense disambiguation [2, 3], differing publication practices across disciplines [4\u20136] and disjoint authorship networks [7] pose special challenges to information retrieval for interdisciplinary work.", "startOffset": 124, "endOffset": 127}, {"referenceID": 7, "context": "When the dimension of time is added, terminological shifts [8, 9], changing citation standards [10\u201313], and shifting modes of scholarly communication [4, 5, 14, 15] all amplify the challenges for IR to serve the need of interdisciplinary scholars.", "startOffset": 59, "endOffset": 65}, {"referenceID": 8, "context": "When the dimension of time is added, terminological shifts [8, 9], changing citation standards [10\u201313], and shifting modes of scholarly communication [4, 5, 14, 15] all amplify the challenges for IR to serve the need of interdisciplinary scholars.", "startOffset": 59, "endOffset": 65}, {"referenceID": 9, "context": "When the dimension of time is added, terminological shifts [8, 9], changing citation standards [10\u201313], and shifting modes of scholarly communication [4, 5, 14, 15] all amplify the challenges for IR to serve the need of interdisciplinary scholars.", "startOffset": 95, "endOffset": 102}, {"referenceID": 10, "context": "When the dimension of time is added, terminological shifts [8, 9], changing citation standards [10\u201313], and shifting modes of scholarly communication [4, 5, 14, 15] all amplify the challenges for IR to serve the need of interdisciplinary scholars.", "startOffset": 95, "endOffset": 102}, {"referenceID": 11, "context": "When the dimension of time is added, terminological shifts [8, 9], changing citation standards [10\u201313], and shifting modes of scholarly communication [4, 5, 14, 15] all amplify the challenges for IR to serve the need of interdisciplinary scholars.", "startOffset": 95, "endOffset": 102}, {"referenceID": 12, "context": "When the dimension of time is added, terminological shifts [8, 9], changing citation standards [10\u201313], and shifting modes of scholarly communication [4, 5, 14, 15] all amplify the challenges for IR to serve the need of interdisciplinary scholars.", "startOffset": 95, "endOffset": 102}, {"referenceID": 3, "context": "When the dimension of time is added, terminological shifts [8, 9], changing citation standards [10\u201313], and shifting modes of scholarly communication [4, 5, 14, 15] all amplify the challenges for IR to serve the need of interdisciplinary scholars.", "startOffset": 150, "endOffset": 164}, {"referenceID": 4, "context": "When the dimension of time is added, terminological shifts [8, 9], changing citation standards [10\u201313], and shifting modes of scholarly communication [4, 5, 14, 15] all amplify the challenges for IR to serve the need of interdisciplinary scholars.", "startOffset": 150, "endOffset": 164}, {"referenceID": 13, "context": "When the dimension of time is added, terminological shifts [8, 9], changing citation standards [10\u201313], and shifting modes of scholarly communication [4, 5, 14, 15] all amplify the challenges for IR to serve the need of interdisciplinary scholars.", "startOffset": 150, "endOffset": 164}, {"referenceID": 14, "context": "When the dimension of time is added, terminological shifts [8, 9], changing citation standards [10\u201313], and shifting modes of scholarly communication [4, 5, 14, 15] all amplify the challenges for IR to serve the need of interdisciplinary scholars.", "startOffset": 150, "endOffset": 164}, {"referenceID": 15, "context": "Widespread digitization of monographs and journals by HathiTrust [16, 17] and Google Books [18, 19] enable new longitudinal studies of change in language and discourse [8, 9, 12, 20\u201322], an approach known as \u201cdistant reading\u201d [23].", "startOffset": 65, "endOffset": 73}, {"referenceID": 16, "context": "Widespread digitization of monographs and journals by HathiTrust [16, 17] and Google Books [18, 19] enable new longitudinal studies of change in language and discourse [8, 9, 12, 20\u201322], an approach known as \u201cdistant reading\u201d [23].", "startOffset": 65, "endOffset": 73}, {"referenceID": 17, "context": "Widespread digitization of monographs and journals by HathiTrust [16, 17] and Google Books [18, 19] enable new longitudinal studies of change in language and discourse [8, 9, 12, 20\u201322], an approach known as \u201cdistant reading\u201d [23].", "startOffset": 91, "endOffset": 99}, {"referenceID": 18, "context": "Widespread digitization of monographs and journals by HathiTrust [16, 17] and Google Books [18, 19] enable new longitudinal studies of change in language and discourse [8, 9, 12, 20\u201322], an approach known as \u201cdistant reading\u201d [23].", "startOffset": 91, "endOffset": 99}, {"referenceID": 7, "context": "Widespread digitization of monographs and journals by HathiTrust [16, 17] and Google Books [18, 19] enable new longitudinal studies of change in language and discourse [8, 9, 12, 20\u201322], an approach known as \u201cdistant reading\u201d [23].", "startOffset": 168, "endOffset": 185}, {"referenceID": 8, "context": "Widespread digitization of monographs and journals by HathiTrust [16, 17] and Google Books [18, 19] enable new longitudinal studies of change in language and discourse [8, 9, 12, 20\u201322], an approach known as \u201cdistant reading\u201d [23].", "startOffset": 168, "endOffset": 185}, {"referenceID": 11, "context": "Widespread digitization of monographs and journals by HathiTrust [16, 17] and Google Books [18, 19] enable new longitudinal studies of change in language and discourse [8, 9, 12, 20\u201322], an approach known as \u201cdistant reading\u201d [23].", "startOffset": 168, "endOffset": 185}, {"referenceID": 19, "context": "Widespread digitization of monographs and journals by HathiTrust [16, 17] and Google Books [18, 19] enable new longitudinal studies of change in language and discourse [8, 9, 12, 20\u201322], an approach known as \u201cdistant reading\u201d [23].", "startOffset": 168, "endOffset": 185}, {"referenceID": 20, "context": "Widespread digitization of monographs and journals by HathiTrust [16, 17] and Google Books [18, 19] enable new longitudinal studies of change in language and discourse [8, 9, 12, 20\u201322], an approach known as \u201cdistant reading\u201d [23].", "startOffset": 168, "endOffset": 185}, {"referenceID": 21, "context": "Widespread digitization of monographs and journals by HathiTrust [16, 17] and Google Books [18, 19] enable new longitudinal studies of change in language and discourse [8, 9, 12, 20\u201322], an approach known as \u201cdistant reading\u201d [23].", "startOffset": 168, "endOffset": 185}, {"referenceID": 22, "context": "Widespread digitization of monographs and journals by HathiTrust [16, 17] and Google Books [18, 19] enable new longitudinal studies of change in language and discourse [8, 9, 12, 20\u201322], an approach known as \u201cdistant reading\u201d [23].", "startOffset": 226, "endOffset": 230}, {"referenceID": 23, "context": "Researchers seeking to marry these \u201cdistant readings\u201d to more traditional \u201cclose readings\u201d are impacted by these factors [24].", "startOffset": 121, "endOffset": 125}, {"referenceID": 24, "context": "HPS must not only bridge the humanities and the sciences, but also the temporal divide between historically-significant materials and the present [25\u201328].", "startOffset": 146, "endOffset": 153}, {"referenceID": 25, "context": "HPS must not only bridge the humanities and the sciences, but also the temporal divide between historically-significant materials and the present [25\u201328].", "startOffset": 146, "endOffset": 153}, {"referenceID": 26, "context": "HPS must not only bridge the humanities and the sciences, but also the temporal divide between historically-significant materials and the present [25\u201328].", "startOffset": 146, "endOffset": 153}, {"referenceID": 27, "context": "We show how visualizations designed for macroanalysis of disciplinary scientific journals can be extended to highlight interdisciplinarity in arguments from book data [29].", "startOffset": 167, "endOffset": 171}, {"referenceID": 23, "context": "While the extension of computational methods to various questions in the humanities may eventually provide ways to test specific hypotheses, the main focus of such research is likely to remain exploratory and interpretative, in keeping with the humanities themselves [24, 30].", "startOffset": 267, "endOffset": 275}, {"referenceID": 28, "context": "Such exploratory experimentation is common not just in the social sciences, but also in the natural sciences [31, 32].", "startOffset": 109, "endOffset": 117}, {"referenceID": 29, "context": "Such exploratory experimentation is common not just in the social sciences, but also in the natural sciences [31, 32].", "startOffset": 109, "endOffset": 117}, {"referenceID": 30, "context": "(6) We used scientific mapping to find relevant volumes [33].", "startOffset": 56, "endOffset": 60}, {"referenceID": 32, "context": "8 million volumes [35].", "startOffset": 18, "endOffset": 22}, {"referenceID": 33, "context": "Before analyzing the texts, it is common to apply a \u2018stop list\u2019 to the results, which omits words that are poor index terms [36].", "startOffset": 124, "endOffset": 128}, {"referenceID": 34, "context": "Frequently, these are high-frequency words such as articles (\u2018a\u2019, \u2018an\u2019, \u2018the\u2019), prepositions (\u2018by\u2019, \u2018of\u2019, \u2018on\u2019), and pronouns (\u2018he\u2019, \u2018she\u2019, \u2018him\u2019), which contain little predictive power for statistical analysis of semantic content [37].", "startOffset": 231, "endOffset": 235}, {"referenceID": 31, "context": "Recently, the HathiTrust Research Center (HTRC) Data Capsule has been developed to enable tightly restricted access to in-copyright materials [34].", "startOffset": 142, "endOffset": 146}, {"referenceID": 27, "context": "As a base map for the disciplinary space (analogous to a world map for geospatial space), we use the UCSD Map of Science [29] which was created by mining scientific and humanities journals indexed by Thomson Reuters\u2019 Web of Science and Elsevier\u2019s Scopus and laying them out as a map of 554 sub-disciplines \u2013 e.", "startOffset": 121, "endOffset": 125}, {"referenceID": 35, "context": "Our specific test domain is the history and philosophy of scientific work on animal cognition [39\u201341].", "startOffset": 94, "endOffset": 101}, {"referenceID": 36, "context": "Our specific test domain is the history and philosophy of scientific work on animal cognition [39\u201341].", "startOffset": 94, "endOffset": 101}, {"referenceID": 37, "context": "Our specific test domain is the history and philosophy of scientific work on animal cognition [39\u201341].", "startOffset": 94, "endOffset": 101}, {"referenceID": 38, "context": "This period represents a critical time for the development of comparative psychology, framed at one end by the work of Charles Darwin and at the other end by the rise of the behaviorist school of psychology (see [42] for a full historical review).", "startOffset": 212, "endOffset": 216}, {"referenceID": 39, "context": "Notably, it took Charles Darwin 23 years to read a number of books comparable in size to HT1315, as documented in his Reading Notebooks [43].", "startOffset": 136, "endOffset": 140}, {"referenceID": 40, "context": "Probabilistic topic models [44] are a family of mixed-membership models that describe documents as a distribution of topics, where each topic is itself a distribution over all words in a corpus.", "startOffset": 27, "endOffset": 31}, {"referenceID": 39, "context": "Topic models are generative models, that we interpret as providing a theory about context blending during the writing process [43].", "startOffset": 126, "endOffset": 130}, {"referenceID": 41, "context": "To construct the topic models used in this study, we use Latent Dirichlet Allocation (LDA \u2013 [45]) with priors estimated via Gibbs sampling [46] as implemented in the InPhO Topic Explorer [47].", "startOffset": 92, "endOffset": 96}, {"referenceID": 42, "context": "To construct the topic models used in this study, we use Latent Dirichlet Allocation (LDA \u2013 [45]) with priors estimated via Gibbs sampling [46] as implemented in the InPhO Topic Explorer [47].", "startOffset": 139, "endOffset": 143}, {"referenceID": 43, "context": "To construct the topic models used in this study, we use Latent Dirichlet Allocation (LDA \u2013 [45]) with priors estimated via Gibbs sampling [46] as implemented in the InPhO Topic Explorer [47].", "startOffset": 187, "endOffset": 191}, {"referenceID": 40, "context": "The topic model checking problem [44] \u2013 i.", "startOffset": 33, "endOffset": 37}, {"referenceID": 44, "context": "These pages were annotated using the Argument Interchange Format ontology (AIF \u2013 [48]), which defines a vocabulary for describing arguments and argument networks.", "startOffset": 81, "endOffset": 85}, {"referenceID": 45, "context": "org/, see also [49]", "startOffset": 15, "endOffset": 19}, {"referenceID": 46, "context": "A full description of the study, including analysis of the arguments can be found in [50].", "startOffset": 85, "endOffset": 89}, {"referenceID": 47, "context": "These argument diagrams function as a type of close reading, common in the humanities, and drawing on a rich tradition of philosophical literature (reviewed in [51]).", "startOffset": 160, "endOffset": 164}, {"referenceID": 30, "context": "We created visualization of the retrieved books overlaid on a map of science [33] to help understand the distribution of the retrieved books with respect to scientific disciplines.", "startOffset": 77, "endOffset": 81}, {"referenceID": 22, "context": "The notion of \u201ddistant reading\u201d [23] has captured the imagination of many in the digital humanities.", "startOffset": 32, "endOffset": 36}, {"referenceID": 48, "context": "But the proper interpretation of large-scale quantitative models itself depends on having a feel for the texts, similar to Barbara McClintock\u2019s stress on having a \u201cfeeling for the organism\u201d [52] or Richard Feynman on the importance for nascent physicists of developing \u201ca \u2018feel\u2019 for the subject\u201d beyond rote knowledge of the basic laws [53].", "startOffset": 190, "endOffset": 194}, {"referenceID": 49, "context": "4% of volumes as of May 2010 [54].", "startOffset": 29, "endOffset": 33}, {"referenceID": 50, "context": "While the quality of the HathiTrust has increased in the intervening years, it is still a pervasive issue in digital archives [55].", "startOffset": 126, "endOffset": 130}], "year": 2017, "abstractText": "We show how faceted search using a combination of traditional classification systems and mixed-membership models can move beyond keyword search to inform resource discovery, hypothesis formulation, and argument extraction for interdisciplinary research. Our test domain is the history and philosophy of scientific work on animal mind and cognition. We demonstrate an application of our methods to the problem of identifying and extracting arguments about anthropomorphism during a critical period in the development of comparative psychology. We show how a combination of classification systems and mixed-membership models trained over large digital libraries can inform resource discovery in this domain, using methods that can be generalized to other interdisciplinary research questions. Through a novel approach of drill-down topic modeling, we are able to reduce a collection of 1,315 fulltext volumes to 6 focal volumes that did not appear in the first ten search results in the HathiTrust digital library. This ultimately supports a system for semi-automatic identification of argument structures to augment the kind of \u201cclose reading\u201d that leads to novel interpretations at the heart of scholarly work in the humanities, drilling down from massive quantities of text to very specific passages. This multi-level view advances understanding of the intellectual and societal contexts in which writings are interpreted. 1 ar X iv :1 70 2. 01 09 0v 1 [ cs .D L ] 3 F eb 2 01 7", "creator": "LaTeX with hyperref package"}}}