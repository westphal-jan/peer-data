{"id": "1702.07103", "review": {"conference": "arxiv", "VERSION": "v1", "DATE_OF_SUBMISSION": "23-Feb-2017", "title": "Discriminating Traces with Time", "abstract": "what properties modify the outputs as a program explain the apparent differences in processing concurrently running logic using various inputs? in every direction, we defined a linguistic framework for considering this problems we dub trace - set discrimination. we show and perhaps though all algorithmic way of interpreting partial likelihood discriminants is np - spanning, approaches based on negative linear numbers ( ilp ) and nonlinear system integration can be extended but zeroing - coding on differing program internals. on overcoming proliferation of java benchmarks, scholars find these code - represented decision trees collectively discriminate with prior estimates - - - overall probability than maximum anticipated discriminants and with comparable data. pending update to we larger case projects this decision - tree discriminants perceived by our tool perform useful despite debugging timing side - projection vulnerabilities ( i. eu., where a given observer estimates secrets simply from regularly watching surveillance times ) and channel vulnerabilities.", "histories": [["v1", "Thu, 23 Feb 2017 05:48:22 GMT  (2259kb,D)", "http://arxiv.org/abs/1702.07103v1", "Published in TACAS 2017"]], "COMMENTS": "Published in TACAS 2017", "reviews": [], "SUBJECTS": "cs.PL cs.CR cs.FL cs.LG cs.SE", "authors": ["saeid tizpaz-niari", "pavol cerny", "bor-yuh evan chang", "sriram sankaranarayanan", "ashutosh trivedi"], "accepted": false, "id": "1702.07103"}, "pdf": {"name": "1702.07103.pdf", "metadata": {"source": "CRF", "title": "Discriminating Traces with Time", "authors": ["Saeid Tizpaz-Niari", "Pavol \u010cern\u00fd", "Bor-Yuh Evan Chang", "Sriram Sankaranarayanan", "Ashutosh Trivedi"], "emails": ["ashutosh.trivedi}@colorado.edu"], "sections": [{"heading": "1 Introduction", "text": "Different control-flow paths in a program can have varying execution times. Such observable differences in execution times may be explainable by information about the program internals, such as whether or not a given function or functions were called. How can a software developer (or security analyst) determine what internals may or may not explain the varying execution times of the program? In this paper, we consider the problem of helping developers and analysts to identify such explanations.\nWe identify a core problem for this task\u2014the trace-set discrimination problem. Given a set of execution traces with observable execution times binned (or clustered) into a finite set of labels, a discriminant (or classifier) is a map relating each label to a property (i.e., a Boolean formula) satisfied by the traces assigned to that label. Such a discriminant model can then be used, for example, to predict a property satisfied by some trace given the timing label of that trace.\nThis problem is, while related, different than the profiling problem. In performance profiling, the question is given an execution trace, how do the various parts of the program contribute to the overall execution time? The trace-set discrimination problem, in contrast, looks for distinguishing features among multiple traces that result in varying execution times.\n? This research was supported by DARPA under agreement FA8750-15-2-0096.\nar X\niv :1\n70 2.\n07 10\n3v 1\n[ cs\n.P L\n] 2\n3 Fe\nb 20\nCrucially, once we can explain the timing differences in terms of properties of traces (e.g., what functions are called only in traces with long execution time), the analyst can use the explanation to diagnose the possible timing side-channel and potentially find a fix for the vulnerability. Section 2 shows on an example how a security analyst might use the tool for debugging information leaks.\nIn this paper, we consider the discriminating properties of traces to be Boolean combinations of a given set of atomic predicates. These atomic predicates correspond to actions that can be observed through instrumentation in a training set of execution traces. Examples of such predicates are as follows: (1) Does the trace have a call to the function f in the program? (2) Does the trace have a call to the sort function with an array of more than a 1000 numbers? In our case study, we consider atomic predicates corresponding to the number of times each function is called.\nConcretely, our overall approach is to first obtain a set of execution traces with information recorded to determine the satisfiability of the given atomic predicates along with corresponding execution times. Then, we cluster these training traces based on their overall execution times to bin them into timing labels. Finally, we learn a trace-set discriminant model from these traces (using various techniques) to capture what is common amongst the traces with the same timing labels and what is different between traces with different labels.\nIn particular, we make the following contributions:\n\u2013 We formalize the problem of trace-set discrimination with timing differences and show that the algorithmic problem of finding the maximum likelihood conjunctive discriminant is NP-hard (Section 3). \u2013 We describe two methods for learning trace-set discriminants:(1) a direct method for inferring the maximum likelihood conjunctive discriminant using an encoding into integer linear programming (ILP) and (2) by applying decision tree learning that each offer different trade-offs (Section 4). For instance, decision tree algorithms are designed to tolerate noisy labels and work effectively on large data sets but do not have formal guarantees. On a set of microbenchmarks, we find that the methods have similar accuracy but decision tree learning appears more scalable. \u2013 We present three case studies in identifying and debugging timing sidechannel and availability vulnerabilities, armed with a prototype tool Discriminer that performs label clustering and decision tree-discriminant learning (Section 5). These case studies were conducted on medium-sized Java applications, which range in size from approximately 300 to 3,000 methods and were developed by a third party vendor as challenge problems for identifying and debugging such side-channel vulnerabilities. We show that the decision trees produced by Discriminer are useful for explaining the timing differences amongst trace sets and performing this debugging task.\nIn our approach, we need to execute both an instrumented and an uninstrumented version of the program of interest on the same inputs. This is because a trace of the instrumented program is needed to determine the satisfiability of the atomic predicates, while the execution time of interest is for the uninstrumented\nprogram. Therefore we need to assume that the program is deterministic. Since timing observations are noisy due to many sources of non-determinism, each trace is associated with a distribution over the labels. For instance, a trace may have a label `1 with probability 0.9 and label `2 with probability 0.1.\nLike with profiling, we also assume the test inputs that drive the program of interest to expose interesting behavior are given. It is a separate problem to get such interesting inputs: whether the analyst has logged some suspicious inputs from a deployment or whether the developer generates tests using random or directed test-case generation.\n2 Timing Side-Channel Debugging with Discriminer\nIn this section, we demonstrate by example how Discriminer can be useful in identifying timing side-channel vulnerabilities and suggesting ways to fix them. We use an application called SnapBuddy1 as an example. SnapBuddy is a Java application with 3,071 methods, implementing a mock social network in which each user has their own page with a photograph.\nIdentifying a Timing Side-Channel with Clustering. The analyst interacts with the application by issuing download requests to the pages of various users to record execution times. Figure 1 shows a scatter plot of the running times of various traces with each trace represented by a point in the figure. The running times are clustered into 6 different clusters using a standard k-means clustering algorithm and shown using different colors. We see that for some users, the download times were roughly 15 seconds, whereas for some others they were roughly 7.5 seconds. This significant time differential suggests a potential timing side-channel if the difference can be correlated with sensitive program state and thus this differential should be investigated further with Discriminer. To see how such a time differential could be a timing side-channel, let us consider an attacker that (a) downloads the public profile pages of all users and learns each download time, and (b) can observe timing between packets by sniffing the network traffic between legitimate users. If the attacker observes user Alice downloading the page of another user whose identity is supposed to be a secret and sees that the download took approximately 7.5 seconds, the attacker can infer that Alice downloaded the page of one of the six users corresponding to the six squares (with time close to 7.5 seconds) in Figure 1. The timing information leak thus helped the attacker narrow down the possibilities from hundreds of users to six.\nDebugging Timing Side-Channels with Decision Tree Learning. How can the analyst go about debugging the SnapBuddy application to eliminate this timing side-channel? We show how Discriminer can help. Recall that the analyst downloaded pages of all the users. Now the same download queries are\n1 From DARPA STAC (www.darpa.mil/program/space-time-analysis-for-cybersecurity).\nexecuted over an instrumented version of the SnapBuddy server to record the number of times each method in the application is called by the trace. As a result, we obtain a set of traces with their (uninstrumented) overall running times and set of corresponding method calls.\nThen Discriminer uses the standard CART decision tree learning algorithm [5] to infer a decision tree that succinctly represents a discriminant using atomic predicates that characterize whether or not the trace invoked a particular method (shown in Figure 2). For instance, the cluster representing the longest running time (around 15 seconds) is discriminated by the property snapservice.model.Filter.filter\u2227image.OilFilter.filterPixels, indicating that the two methods are both invoked by the trace. Likewise, the cluster representing the running time around 7.5 seconds is discriminated by the property snapservice.model.Filter.filter \u2227 \u00acimage.OilFilter.filterPixels \u2227 image.ChromeFilter.filter, indicating that image.OilFilter.filterPixels must not be invoked while the other two must be.\nThe analyst might now suspect what is going on: the timing differences are caused by the filters that each user chooses to apply to their picture. Note that the analyst running Discriminer did not need to know that the filters are important for causing this time differential, or even that they existed. The tool discovers them simply because the trace contains all method calls, and the decision tree learning algorithm produces a useful discriminant.\nA possible fix now suggests itself: make sure that the execution of each type of filter takes the same amount of time (though of course an implementation of such a fix still requires development effort). Overall, the example demonstrates how the decision tree produced by Discriminer can be used to debug (and potentially fix) side-channel vulnerabilities."}, {"heading": "3 Trace-Set Discrimination Problem", "text": "A discrete probability distribution, or just distribution, over a finite set L is a function d : L\u2192[0, 1] such that \u2211 `\u2208L d(`) = 1. Let D(L) denote the set of all discrete distributions over L.\nLet p1, . . . , pm represent a set of atomic predicates over traces. Each predicate evaluates to a Boolean value over a given trace. Therefore, for simplicity, we represent a trace simply by the truth valuations of the predicates over the trace. In addition to atomic predicates, traces are associated with a distribution over labels. These distributions are generated by first measuring the execution time t of the trace. The execution time is obtained as the average over some fixed number of measurements M > 0. Therefore, the timing is taken to be a Gaussian random variable with mean t and a standard deviation \u03c3t. Using this information, we derive a discrete distribution d \u2208 D(L) over the set of labels in L.\nDefinition 1 (Traces, Predicates and Label Distributions). An execution trace T of the program is a tuple \u3008\u03c4, d\u3009 wherein \u03c4 = \u3008\u03c11, . . . , \u03c1m\u3009 represents the truth valuations to the predicates p1, . . . , pm, respectively and d \u2208 D(L) is the associated label distribution over the finite set of labels L.\nWe define a trace discriminant as a tuple of Boolean formulae that predict the labels of the traces given the truth valuations in the following fashion.\nDefinition 2. Given a set of labels L = {`1, . . . , `K} and predicates P = {p1, . . . , pm}, a discriminant \u03a8 is a tuple \u3008\u03d51, . . . , \u03d5K\u3009 of Boolean formulae where each formula \u03d5i is over the predicates in P and corresponds to a label `i.\nA trace \u3008\u03c4, d\u3009 receives a label `k under trace discriminant \u03a8 = \u3008\u03d51, . . . , \u03d5K\u3009, and we write Label(\u3008\u03c4, d\u3009 , \u03a8) = `k, if k is the smallest index 1 \u2264 i \u2264 K such that \u03c4 |= \u03d5i, i.e. \u03d5i evaluates to true for the truth valuation \u03c4 . Formally,\nLabel(\u3008\u03c4, d\u3009 , \u03a8) =  `1 if \u03c4 |= \u03d51, else `2 if \u03c4 |= \u03d52, else ... ...\n`K if \u03c4 |= \u03d5K .\nDefinition 3. Given a set of predicates {p1, . . . , pm}, set of labels {`1, . . . , `K}, and a set of traces {\u3008\u03c41, d1\u3009 , . . . , \u3008\u03c4N , dN \u3009}, the trace set discriminant problem (TDLP ) is to learn a trace discriminant \u03a8 = \u3008\u03d51, . . . , \u03d5K\u3009.\nIn general, there are numerous possible discriminants that can be inferred for a given instance of the tdlp. We consider two approaches in this paper: (a) a formal maximum likelihood learning model over a structured set of discriminants and (b) an informal decision tree learning approach to maximize accuracy while minimizing the discriminant size."}, {"heading": "3.1 Maximum Likelihood Learning", "text": "Given a discriminant and a set of traces, we define the likelihood of the discriminant as the probability that each trace \u3008\u03c4i, di\u3009 receives the label Label(\u3008\u03c4i, di\u3009 , \u03a8) dictated by the discriminant.\nDefinition 4. The likelihood \u03bb(\u03a8) of a discriminant \u03a8 over a set of traces {\u3008\u03c41, d1\u3009 , . . . , \u3008\u03c4N , dN \u3009} is given by \u03bb(\u03a8) = \u220fN i=1 di (Label(\u3008\u03c4i, di\u3009 , \u03a8)) .\nThe maximum likelihood discriminant \u03a8ml is defined as the discriminant amongst all possible Boolean formulae that maximizes \u03bb(\u03a8), i.e. \u03a8ml = argmax\u03a8 (\u03bb(\u03a8)). This maximization runs over the all possible tuples ofK Boolean formulae overm\natomic predicates, i.e, a space of (K!) ( 22 m\nK\n) possible discriminants! In particular,\nHyafil and Rivest [11] show that the problem of learning optimal decision trees is NP-hard. Therefore, for our formal approach, we consider the following simpler class of discriminants by restricting the form of the Boolean formulae \u03d5j that make up the discriminants to monotone conjunctive formulae.\nDefinition 5 (Conjunctive Discriminants). A monotone conjunctive formula over predicates P = {p1, . . . , pm} is a finite conjunction of the form\u2227r j=1 pij such that 1 \u2264 i1, . . . , ir \u2264 m. A discriminant \u03a8 = \u3008\u03d51, . . . , \u03d5K\u3009 is a (monotone) conjunctive discriminant if each \u03d5i is a monotone conjunctive formula for 1 \u2264 i \u2264 K. In order to make a traces discriminant exhaustive, we assume \u03d5K to be the formula true.\nThe number of conjunctive discriminants is (K \u2212 1)! ( 2m K\u22121 ) . However, they can be easily represented and learned using SAT or ILP solvers, as shown subsequently. Moreover, working with simpler monotone conjunctive discriminants is preferable [8] in the presence of noisy data, as using formal maximum likelihood model to learn arbitrary complex Boolean function would lead to over-fitting. The problem of maximum likelihood conjunctive discriminant is then naturally defined. We refine the result of [11] in our context to show that the problem of learning (monotone) conjunctive discriminants is already NP-hard.\nTheorem 1. Given an instance of tdlp, the problem of finding the maximum likelihood conjunctive discriminant is NP-hard.\nProof. We prove the NP-hardness of the problem of finding maximum likelihood conjunctive discriminant by giving a reduction from the minimum weight monotone SAT problem that is already known to be NP-hard. Recall that a monotone Boolean formula is propositional logic formula where all the literals are positive. Given a monotone instance of SAT \u03c6 = \u2227n j=1 Cj over the set of variable X = {x1, . . . , xm}, the minimum weight monotone SAT problem is to find a truth assignment satisfying \u03c6 with as few variables set to true as possible.\nConsider the trace-set discrimination problem P\u03c6 where there is one predicate pi per variable xi \u2208 X of \u03c6, two labels `1 and `2, and the set of traces such that\n\u2013 there is one trace \u3008\u03c4j , dj\u3009 per clause Cj of \u03c6 such that predicate pi evaluates to true in the trace \u03c4j if variable xi does not occur in clause Cj , and the label distribution dj is such that dj(`1) = 0 and dj(`2) = 1. \u2013 there is one trace \u3008\u03c4 i, di\u3009 per variable xi of \u03c6 such that only the predicate pi evaluates to false in the trace \u03c4\ni and the label distribution di is such that di(`1) = 1\u2212 \u03b5 and di(`2) = \u03b5 where 0 < \u03b5 < 12 .\nObserve that for every truth assignment (x\u22171, . . . , x \u2217 m) to variables in X, there is a conjunctive discriminant \u2227x\u2217i =1pi such that if the clause Cj is satisfied then the trace \u3008\u03c4j , dj\u3009 receives the label `2. This implies that the likelihood of the discriminant is non-zero only for the discriminant corresponding to satisfying valuations of \u03c6. Moreover, for every variable xi receiving a true assignment, the trace \u3008\u03c4 i, di\u3009 receives the label `2 with \u03b5 contributed to the likelihood term and for every variable xi receiving false assignment, the trace \u3008\u03c4 i, di\u3009 receives the label `1 with 1\u2212 \u03b5 being contributed to the likelihood. This construction implies that a maximum likelihood discriminant should give label `2 to all of the traces \u3008\u03c4j , dj\u3009 and label `1 to as many traces in { \u03c4 i, di } as possible. It is easy to verify that there exists a truth assignment of size k for \u03c6 if and only if there exists a conjunctive discriminant in P\u03c6 with likelihood \u220fk i=1 \u03b5 \u00b7 \u220fm\u2212k i=1 (1\u2212 \u03b5). ut"}, {"heading": "3.2 Decision Tree Learning", "text": "As noted earlier, the max likelihood approach over structured Boolean formulae can be prohibitively expensive when the number of traces, predicates and labels are large. An efficient alternative is to consider decision tree learning approaches that can efficiently produce accurate discriminants while keeping the size of the discriminant as small as possible. The weighted accuracy of a discriminant \u03a8 over traces \u3008\u03c4i, di\u3009 , i = 1, . . . , N is defined additively as \u03b1(\u03a8) : 1N \u2211N i=1 di (Label(\u3008\u03c4i, di\u3009 , \u03a8)). This accuracy is a fraction between [0, 1] with higher accuracy representing a better discriminant. A decision tree learning algorithm seeks to learn a discriminant as a decision tree over the predicates p1, . . . , pm and outcome labels `1, . . . , `K . Typically, algorithms will maximize \u03b1(\u03a8) while keeping the description length |\u03a8 | as small as possible. A variety of efficient tree learning algorithms have been defined including ID3 [16], CART [6], CHAID [12] and many others [15, 19]. These algorithms have been supported by popular machine learning tools such as Scikit-learn python library (http://scikit-learn.org/stable/) and RapidMiner [2]."}, {"heading": "4 Discriminant Analysis", "text": "In this section, we provide details of max likelihood and decision tree approaches, and compare their performances over a scalable set of micro-benchmarks."}, {"heading": "4.1 Maximum Likelihood Approach", "text": "We now present an approach for inferring a conjunctive discriminant \u03a8 using integer linear programming (ILP) that maximizes the likelihood \u03bb(\u03a8) for given predicates p1, . . . , pm, labels `1, . . . , `K and traces \u3008\u03c41, d1\u3009, . . ., \u3008\u03c4N , dN \u3009. This problem was already noted to be NP-hard in Theorem 1.\nWe first present our approach for the special case ofK = 2 labels. Let `1, `2 be the two labels. Our goal is to learn a conjunctive formula \u03d51 for `1. We use binary decision variables x1, . . . , xm wherein xi = 1 denotes that \u03d51 has the predicate\npi as a conjunct, whereas xi = 0 denotes that pi is not a conjunct in \u03d51. Also we add binary decision variables w1, . . . , wN corresponding to each of the N traces, respectively. The variable wi = 1 denotes that the trace \u3008\u03c4i, di\u3009 receives label `2 under \u03d51 and wi = 0 indicates that the trace receives label `1. The likelihood\nof the discriminant \u03a8 can be given as \u03bb(\u03a8) def = \u220fN i=1 { di(`1) if wi = 0 di(`2) if wi = 1 . Rather than maximize \u03bb(\u03a8), we equivalently maximize log(\u03bb(\u03a8))\nlog(\u03bb(\u03a8)) = N\u2211 i=1 { log(di(`1)) if wi = 0 log(di(`2)) if wi = 1 .\nLet ri := di(`1) = 1 \u2212 di(`2), and simplify the expression for log(\u03bb(\u03a8)) as\u2211N i=1(1\u2212 wi) log(ri) + wi log(1\u2212 ri). Next, the constraints need to relate the values of xi to each wi. Specifically, let for each trace \u3008\u03c4i, di\u3009, Ri \u2286 {p1, . . . , pm} denote the predicates that are valued false in the trace. We can verify that if wi = 0, then none of the predicates in Ri can be part of \u03d51, and if wi = 1, at least one of the predicates in Ri must be part of \u03d51. This is expressed by the following inequality\n1 |Ri| ( \u2211 pk\u2208Ri xk) \u2264\nwi \u2264 \u2211 pk\u2208Ri xk. If any of the pk \u2208 Ri is included in the conjunction, then the LHS of the inequality is at least 1|Ri| , forcing wi = 1. Otherwise, if all pk are not included, the RHS of the inequality is 0, forcing wi = 0. The overall ILP is given by\nmax \u2211N i=1(1\u2212 wi) log(ri) + wi log(1\u2212 ri)\ns.t. 1|Ri| ( \u2211 pk\u2208Ri xk) \u2264 wi i = 1, . . . , N\nwi \u2264 \u2211 pk\u2208Ri xk i = 1, . . . , N\nxj \u2208 {0, 1}, wi \u2208 {0, 1} i = 1, . . . , N, j = 1, . . . ,m (1)\nTheorem 2. Let x\u22171, . . . , x \u2217 m denote the solution for ILP (1) over a given TDLP\ninstance with labels {`1, `2}. The discriminant \u03a8 = \u3008\u03d51, true\u3009 wherein \u03d51 =\u2227 x\u2217i =1 pi maximizes the likelihood \u03bb(\u03a8) over all conjunctive discriminants.\nWith the approach using the ILP in Eq. (1), we can tackle an instance with K > 2 labels by recursively applying the two label solution. First, we learn a formula \u03d51 for `1 and L \\ `1. Next, we eliminate all traces that satisfy \u03d51 and eliminate the label `1. We then recursively consider L\u0302 : L \\ `1 as the new label set. Doing so, we obtain a discriminant \u03a8 : \u3008\u03d51, \u03d52, . . . , \u03d5K\u22121, true\u3009.\nIn theory, the ILP in (1) has N + m variables, which can be prohibitively large. However, for the problem instances considered, we drastically reduced the problem size through standard preprocessing/simplification steps that allowed us to resolve the values of xi, wj for many of the variables to constants."}, {"heading": "4.2 Decision Tree Learning Appraoch", "text": "In order to discriminate traces, Discriminer employs decision tree learning to learn classifiers that discriminate the traces. Given a set of N traces on a\ndependent variable (labels) L that takes finitely-many values in the domain {`1, . . . , `K} and m feature variables (predicates) F = {f1, . . . , fm}, the goal of a classification algorithm is to produce a partition the space of the feature variables into K disjoint sets A1, . . . , AK such that the predicted value of L is i if the F -variables take value in Ai. Decision-tree methods yield rectangular sets Ai by recursively partitioning the data set one F variable at a time. CART (Classification and Regression Trees) is a popular and effective algorithm to learn decision-tree based classifiers. It constructs binary decision trees by iteratively exploring features and thresholds that yield the largest information gain (Gini index) at each node. For a detailed description of the CART, we refer to [5]."}, {"heading": "4.3 Performance Evaluation", "text": "We created a set of micro-benchmarks\u2014containing a side-channel in time\u2014 to evaluate the performance of the decision-tree discriminator computed using scikit-learn implementation of CART and the maximum likelihood conjunctive discriminant using an ILP implementation from the GLPK library.\nThese micro-benchmarks consist of a set of programs that take as an input a sequence of binary digits (say a secret information), and perform some computation whose execution time (enforced using sleep commands) depends on some property of the secret information. For the micro-benchmark series LSB0 and MSB0, the execution time is a Gaussian-distributed random variable whose mean is proportional to the position of least significant 0 and most significant 0 in the secret, respectively. In addition, we have a micro-benchmark series Patd whose execution time is a random variable whose mean depends upon the position of the pattern d in the input. For instance, the micro-benchmark Pat101 takes a 20-bit input data and the leftmost occurrence i of the pattern 101 executes three methods Fi, Fi+1, Fi+2 with mean exec. time of a method Fj being 10\u2217j ms.\nIn our experiments with micro-benchmarks, we generate the dataset by randomly generating the input. For each input, we execute the benchmark programs 10 times to approximate the mean and the standard deviation of the observation, and log the list of method called for each such input. For a given set of execution traces, we cluster the execution time based on their mean and assign weighted labels to each trace according to Gaussian distribution. We defer the details of this data collection to Section 5. Our dataset consists of trace id, label, weight, and method calls for every execution trace. We use this common dataset to both the decision-tree and the maximum likelihood algorithms.\nTable 1 shows the performance of the decision-tree classifiers and the maxlikelihood approach for given micro-benchmarks. The table consists of benchmark scales (based on the number of methods and traces), the accuracy of approaches, time of computing decision tree and max-likelihood discriminant, the height of decision tree, and the maximum number of conjuncts among all learned discriminants in the max-likelihood approach. In order to compute the performance of both models and avoid overfitting, we train and test data sets using group k-fold cross-validation procedure with k set to 20.\nTable 1 shows that both decision tree and max-likelihood approaches have decent accuracy in small and medium sized benchmarks. On the other hand, decision tree approach stands out as highly scalable: it takes only 4.2 seconds for the decision-tree approach to building a classifier for the benchmark Pat1010101 with 400 methods and 4000 traces, while it takes 652.4 seconds for the maxlikelihood approach to constructing the discriminants. Table 1 shows that the discriminants learned using decision tree approach are simpler than the ones learned using max-likelihood approach requiring a fewer number of tests."}, {"heading": "5 Case Study: Understanding Traces with Decision Trees", "text": "The data on microbenchmarks suggest that the decision tree learning approach is more scalable and has comparable accuracy as the max-likelihood approach. Therefore, we consider three case studies to evaluate whether the decision tree approach produces useful artifacts for debugging program vulnerabilities.\nResearch Question. We consider the following question:\nDoes the learned discriminant pinpoint code fragments that explain differences in the overall execution times?\nWe consider this question to be answered positively if we can identify an explanation for timing differences (which can help debug to side channel or availability vulnerabilities) through Discriminer2.\nMethodology. We consider the discriminant analysis approach based on decision tree learning from Section 4. Table 2 summarizes the particular instantiations for the discriminant analysis that we consider here.\nAttributes: Called Methods. For this case study, we are interested in seeing whether the key methods that explain the differences in execution time can\n2 https://github.com/cuplv/Discriminer\nbe pinpointed. Thus, we consider attributes corresponding to the called methods in a trace. In order to collect information regarding the called methods, we instrumented Java bytecode applications using Javassist analysis framework (http://jboss-javassist.github.io/javassist/).\nClass Label: Total Execution Time Ranges. To identify the most salient attributes, we fix a small number of possible labels, and cluster traces according to total execution time. Each cluster is defined by a corresponding time interval. The clusters and their intervals are learned using k-means clustering algorithm.\nWe consider the execution time for each trace to be a random variable and assume a normal distribution. We obtain the mean and variance through 10 repeated measurements. We apply clustering to the mean execution times of each trace to determine the class labels. Henceforth, when we speak of the execution time of a trace, we refer to the mean of the measurements for that trace.\nA class label (or cluster) can be identified by the mean of all execution times belonging to that cluster. Then, considering the class labels sorted in increasing order, we define the lower boundary of a bucket for classifying new traces by averaging the maximum execution time in the previous bucket and the minimum execution time in this bucket (and analogously for the upper boundary).\nWeighted Labeling of Traces. Given a set of time ranges (clusters), we define a weighted labeling of traces that permits a trace to be assigned to different clusters with different weights. For a given trace, the weights to clusters are determined by the probability mass that belongs to the time range of the cluster. For example, consider a sample trace whose execution-time distribution straddles the boundary of two clusters C0 and C1, with 22% area of the distribution intersecting with cluster C0 and 78% with cluster C1. In this case, we assign the trace to both clusters C0 and C1 with weights according to their probability mass in their respective regions. Note that this provides a smoother interpretation of the class labels rather than assigning the most likely label.\nDecision Tree Learning. From a training set with this weighted labeling, we apply the weighted decision tree learning algorithm CART described in Sec. 4. We use Discriminer both for clustering in the time domain as described above to determine the class labels and weights of each trace and for learning the classification model. We use group k-fold cross validation procedure to find accuracy.\ntotal total observed program methods traces methods\n(num) (num) (num)\nSnapBuddy 3071 439 160 GabFeed 573 368 30 TextCrunchr 327 180 35\ntotal 3971 987 225 Objects of Study. We consider three programs drawn from benchmarks provided by the DARPA STAC project. These medium-sized Java programs were developed to be realistic applications that may potentially have timing side-channel or availability security vulnerabilities. SnapBuddy is a web application for social image sharing. The profile page of a user includes their picture (with a filter). The profile page is publicly accessible. GabFeed is a web application for hosting community forums. Users and servers can mutually authenticate using public-key infrastructure. TextCrunchr is a text analysis program capable of performing standard text analysis including word frequency, word length, and so on. It uses sorting algorithms to perform the analysis.\nIn the inset table, we show the basic characteristics of these benchmarks. The benchmarks, in total, consist of 3,971 methods. From these programs, we generated 987 traces by using a component of each applications web API (scripted via curl). In these recorded traces, we observed 225 distinct methods called. Note that some methods are called thousands to millions of times.\nDecision Trees Produced by Discriminer. In Fig. 3(b)\u2013(d)\u2013(f), we show the decision tree learned from the SnapBuddy, GabFeed, and TextCrunchr traces, respectively. As a decision tree is interpreted by following a path from the root to a leaf where the leaf yields the class label and the conjunction of the internal nodes describes the discriminator, one can look for characteristics of discriminated trace sets by following different paths in the tree. The class labels at leaves are annotated with the bucket\u2019s mean time. For example, in (b), the label 15.7 shows that the path to this label which calls image.OilFilter.filterPixels takes 15.7 seconds to execute. The colors in bars in the leaves represent the actual labels of the training traces that would be classified in this bucket according to the learned discriminator. Multiple colors in the bars mean that a discriminator, while not perfectly accurate on the training traces, is also able to tolerate noise. The height of the bar gives an indication of the number of training traces following this discriminator. The scatter plots in (a)\u2013(c)\u2013(e) show the time of each trace, with the color indicating the corresponding cluster.\nFindings for SnapBuddy. For SnapBuddy, the traces exercise downloading the public profile pages of all user from a mock database. We have explained in Sec. 2 how clustering (in Fig. 3(a)) helps to identify a timing side-channel, and how the decision tree (in Fig. 3b) helps in debugging the vulnerability.\nFindings for GabFeed. Inputs. For GabFeed, the traces exercise the authentication web API by fixing the user public key and by sampling uniformly from the server private key space (3064-bit length keys). Identifying a Timing SideChannel with Clustering. Considering scatter plot of GabFeed in Fig. 3c (bound-\naries show different clusters), we can see less definitive timing clusters. However, it shows timing differences that indicate a side channel. Debugging Timing SideChannels with Decision Tree Learning. The (part of) decision tree for GabFeed in Fig. 3d is also less definitive than for SnapBuddy as we might expect given the less well-defined execution time clusters. However, the part of the decision tree discriminants OptimizedMultiplier.standardMultiply for time differences. Note that the attributes on the outgoing edge labels correspond to a range for the number of times a particular method is called. The decision tree explains that the different number of calls for OptimizedMultiplier.standardMultiply leads to different time buckets. By going back to the source code, we observed\nthat standardMultiply is called for each 1-bit in the server\u2019s private key. The method standardMultiply is called from a modular exponentiation method called during authentication. What leaks is thus the number of 1s in the private key. A potential fix could be to rewrite the modular exponentiation method to pad the timing differences.\nFindings for TextCrunchr. Inputs. For TextCrunchr, we provided four types of text inputs to analyze timing behaviors: sorted, reverse-sorted, randomly generated, and reversed-shuffled arrays of characters (reverse-shuffle is an operation that undoes a shuffle that TextCrunchr performs internally). It is the reverse shuffled inputs that lead to high execution time. Although the input provided to Discriminer for analyzing TextCrunchr include carefully crafted inputs (reversed shuffled sorted array), it can be argued that a system administrator interested in auditing a security of a server has access to a log of previous inputs including some that resulted in high execution time. Identifying Availability Vulnerabilities with Clustering. Considering scatter plot of TextCrunchr in Fig. 3e we can see well-defined timing clusters which can potentially lead to security issues. It shows that a small fraction of inputs takes comparably higher time of execution in comparison to the others. Thus an attacker can execute a denial-ofservice (availability) attack by repeatedly providing the costly inputs (for some inputs, it will take more than 600 seconds to process the text). The system administrator mentioned above probably knew from his logs about possible inputs with high execution time. What he did not know is why these inputs lead to high execution time. Debugging Availability Vulnerabilities with Decision Tree Learning. The decision tree for TextCrunchr in Fig. 3f shows that the number of calls on stac.sort.qsPartition as the explanation for time differences (out of 327 existing methods in the application). This can help identify the sorting algorithm (Quicksort) used as a source of the problem and leads to the realization that certain inputs trigger the worst-case execution time of Quicksort.\nThreats to Validity. These case studies provide evidence that decision tree learning helps in identifying code fragments that correlate with differential execution time. Clearly, the most significant threat to validity is whether these programs are representative of other applications. To mitigate, we considered programs not created by us nor known to us prior to this study. These applications were designed to faithfully represent real-world Java programs\u2014for example, using Java software engineering patterns and best practices. Another threat concerns the representativeness of the training sets. To mitigate this threat, we created sample traces directly using the web interface for the whole application, rather than interposing at any intermediate layer. This interface is for any user of these web applications and specifically the interface available to a potential attacker. A training set focuses on exercising a particular feature of the application, which also corresponds to the ability of an attacker to build training sets specific to different features of the application."}, {"heading": "6 Related Work", "text": "Machine learning techniques have been used for specification mining, that is, for learning succinct representations of the set of all program traces. Furthermore, machine learning techniques have been applied to learn classifiers of programs for malware detection and for software bug detection.\nSpecification Mining. In [3], machine learning techniques are used to synthesize an NFA (nondeterministic finite automaton) that represents all the correct traces of a program. In our setting, this would correspond to learning a discriminant for one cluster (of correct traces). In contrast, our decision trees discriminate multiple clusters. However, the discriminants we considered in this paper are less expressive than NFAs. The survey [22] provides an overview of other specification mining approaches.\nMalware and Bug Detection. In malware detection, machine learning techniques are used to learn classifiers that classify programs into benign and malicious [1, 4, 7, 10, 13, 17, 21]. In software bug detection, the task is to learn classifiers that classify programs behaviors into faulty and non-faulty [9, 14, 18, 20]. In contrast, we consider more clusters of traces. In particular, Lo et al. [14] constructs a classifier to generalize known failures of software systems and to further detect (predict) other unknown failures. First, it mines iterative patterns from program traces of known normal and failing executions. Second, it applies a feature selection method to identify highly discriminative patterns which distinguish failing traces from normal ones. In all these works, the training set is labeled: all the programs are labeled either benign or malicious (faulty or non-faulty). In contrast, we start with an unlabeled set of traces, and construct their labels by clustering in the time domain."}, {"heading": "7 Conclusion", "text": "Summary. We introduced the trace set discrimination problem as a formalization of the practical problem of finding what can be inferred from limited run time observations of the system. We have shown that the problem is NP-hard, and have proposed two scalable techniques to solve it. The first is ILP-based, and it can give formal guarantees about the discriminant that was found but infers discriminants of a limited form. The second is based on decision trees, infers general discriminants, but does not give formal guarantees. For three realistic applications, our tool produces a decision tree useful for explaining timing differences between executions.\nFuture Work. There are several intriguing directions for future research. First, we will investigate the extension of our framework to reactive systems, by generalizing our notion of execution time observations to sequences of timed events. Second, we will build up the network traffic monitoring ability of our tool, to make it usable by security analysts for distributed architectures."}], "references": [{"title": "DroidAPIMiner: Mining API-level features for robust malware detection in Android", "author": ["Yousra Aafer", "Wenliang Du", "Heng Yin"], "venue": "In SPCN,", "citeRegEx": "1", "shortCiteRegEx": "1", "year": 2013}, {"title": "Rapidminer 5 operator reference", "author": ["Fareed Akthar", "Caroline Hahne"], "venue": "Rapid-I GmbH,", "citeRegEx": "2", "shortCiteRegEx": "2", "year": 2012}, {"title": "Automated classification and analysis of internet malware", "author": ["Michael Bailey", "Jon Oberheide", "Jon Andersen", "Z Morley Mao", "Farnam Jahanian", "Jose Nazario"], "venue": "In RAID,", "citeRegEx": "4", "shortCiteRegEx": "4", "year": 2007}, {"title": "Classification and Regression Trees", "author": ["L. Breiman", "J. Friedman", "R. Olshen", "C. Stone"], "venue": null, "citeRegEx": "5", "shortCiteRegEx": "5", "year": 1984}, {"title": "Classification and regression trees", "author": ["L. Breiman", "J.H. Friedman", "R.A. Olshen", "C.I. Stone"], "venue": null, "citeRegEx": "6", "shortCiteRegEx": "6", "year": 1984}, {"title": "Crowdroid: behaviorbased malware detection system for Android", "author": ["Iker Burguera", "Urko Zurutuza", "Simin Nadjm-Tehrani"], "venue": "In Workshop on Security and privacy in smartphones and mobile devices,", "citeRegEx": "7", "shortCiteRegEx": "7", "year": 2011}, {"title": "The role of Occam\u2019s razor in knowledge discovery", "author": ["Pedro Domingos"], "venue": "Data Mining and Knowledge Discovery,", "citeRegEx": "8", "shortCiteRegEx": "8", "year": 1999}, {"title": "Predicting defect-prone software modules using support vector machines", "author": ["Karim O Elish", "Mahmoud O Elish"], "venue": "Journal of Systems and Software,", "citeRegEx": "9", "shortCiteRegEx": "9", "year": 2008}, {"title": "Near-optimal malware specifications from suspicious behaviors", "author": ["Matt Fredrikson", "Somesh Jha", "Mihai Christodorescu", "Reiner Sailer", "Xifeng Yan"], "venue": "In Security and Privacy (SP),", "citeRegEx": "10", "shortCiteRegEx": "10", "year": 2010}, {"title": "Constructing optimal binary decision trees is np-complete", "author": ["Laurent Hyafil", "Ronald L Rivest"], "venue": "Information Processing Letters,", "citeRegEx": "11", "shortCiteRegEx": "11", "year": 1976}, {"title": "An exploratory technique for investigating large quantities of categorical data", "author": ["G.V. Kass"], "venue": "Journal of the Royal Statistical Society. Series C (Applied Statistics),", "citeRegEx": "12", "shortCiteRegEx": "12", "year": 1980}, {"title": "Effective and efficient malware detection at the end host", "author": ["Clemens Kolbitsch", "Paolo Milani Comparetti", "Christopher Kruegel", "Engin Kirda", "Xiao-yong Zhou", "XiaoFeng Wang"], "venue": "In USENIX Security,", "citeRegEx": "13", "shortCiteRegEx": "13", "year": 2009}, {"title": "Classification of software behaviors for failure detection: a discriminative pattern mining approach", "author": ["David Lo", "Hong Cheng", "Jiawei Han", "Siau-Cheng Khoo", "Chengnian Sun"], "venue": "In SIGKDD,", "citeRegEx": "14", "shortCiteRegEx": "14", "year": 2009}, {"title": "Foundations of Machine Learning", "author": ["Mehryar Mohri", "Afshin Rostamizadeh", "Ameet Talwalkar"], "venue": "ISBN 026201825X,", "citeRegEx": "15", "shortCiteRegEx": "15", "year": 2012}, {"title": "Induction of decision trees", "author": ["J. Ross Quinlan"], "venue": "Machine Learning,", "citeRegEx": "16", "shortCiteRegEx": "16", "year": 1986}, {"title": "Learning and classification of malware behavior", "author": ["Konrad Rieck", "Thorsten Holz", "Carsten Willems", "Patrick D\u00fcssel", "Pavel Laskov"], "venue": "In Detection of Intrusions and Malware, and Vulnerability Assessment,", "citeRegEx": "17", "shortCiteRegEx": "17", "year": 2008}, {"title": "A discriminative model approach for accurate duplicate bug report retrieval", "author": ["Chengnian Sun", "David Lo", "Xiaoyin Wang", "Jing Jiang", "Siau-Cheng Khoo"], "venue": "In ICSE,", "citeRegEx": "18", "shortCiteRegEx": "18", "year": 2010}, {"title": "Introduction to data mining, volume 1", "author": ["Pang-Ning Tan", "Michael Steinbach", "Vipin Kumar"], "venue": null, "citeRegEx": "19", "shortCiteRegEx": "19", "year": 2006}, {"title": "Mining temporal specifications for error detection", "author": ["Westley Weimer", "George C Necula"], "venue": "In TACAS,", "citeRegEx": "20", "shortCiteRegEx": "20", "year": 2005}, {"title": "Droidmat: Android malware detection through manifest and api calls tracing", "author": ["Dong-Jie Wu", "Ching-Hao Mao", "Te-En Wei", "Hahn-Ming Lee", "Kuo-Ping Wu"], "venue": "In JCIS,", "citeRegEx": "21", "shortCiteRegEx": "21", "year": 2012}, {"title": "Specifications for free", "author": ["Andreas Zeller"], "venue": "In NFM,", "citeRegEx": "22", "shortCiteRegEx": "22", "year": 2011}], "referenceMentions": [{"referenceID": 3, "context": "Then Discriminer uses the standard CART decision tree learning algorithm [5] to infer a decision tree that succinctly represents a discriminant using atomic predicates that characterize whether or not the trace invoked a particular method (shown in Figure 2).", "startOffset": 73, "endOffset": 76}, {"referenceID": 0, "context": "A discrete probability distribution, or just distribution, over a finite set L is a function d : L\u2192[0, 1] such that \u2211 `\u2208L d(`) = 1.", "startOffset": 99, "endOffset": 105}, {"referenceID": 9, "context": "K ) possible discriminants! In particular, Hyafil and Rivest [11] show that the problem of learning optimal decision trees is NP-hard.", "startOffset": 61, "endOffset": 65}, {"referenceID": 6, "context": "Moreover, working with simpler monotone conjunctive discriminants is preferable [8] in the presence of noisy data, as using formal maximum likelihood model to learn arbitrary complex Boolean function would lead to over-fitting.", "startOffset": 80, "endOffset": 83}, {"referenceID": 9, "context": "We refine the result of [11] in our context to show that the problem of learning (monotone) conjunctive discriminants is already NP-hard.", "startOffset": 24, "endOffset": 28}, {"referenceID": 0, "context": "This accuracy is a fraction between [0, 1] with higher accuracy representing a better discriminant.", "startOffset": 36, "endOffset": 42}, {"referenceID": 14, "context": "A variety of efficient tree learning algorithms have been defined including ID3 [16], CART [6], CHAID [12] and many others [15, 19].", "startOffset": 80, "endOffset": 84}, {"referenceID": 4, "context": "A variety of efficient tree learning algorithms have been defined including ID3 [16], CART [6], CHAID [12] and many others [15, 19].", "startOffset": 91, "endOffset": 94}, {"referenceID": 10, "context": "A variety of efficient tree learning algorithms have been defined including ID3 [16], CART [6], CHAID [12] and many others [15, 19].", "startOffset": 102, "endOffset": 106}, {"referenceID": 13, "context": "A variety of efficient tree learning algorithms have been defined including ID3 [16], CART [6], CHAID [12] and many others [15, 19].", "startOffset": 123, "endOffset": 131}, {"referenceID": 17, "context": "A variety of efficient tree learning algorithms have been defined including ID3 [16], CART [6], CHAID [12] and many others [15, 19].", "startOffset": 123, "endOffset": 131}, {"referenceID": 1, "context": "org/stable/) and RapidMiner [2].", "startOffset": 28, "endOffset": 31}, {"referenceID": 3, "context": "For a detailed description of the CART, we refer to [5].", "startOffset": 52, "endOffset": 55}, {"referenceID": 20, "context": "The survey [22] provides an overview of other specification mining approaches.", "startOffset": 11, "endOffset": 15}, {"referenceID": 0, "context": "In malware detection, machine learning techniques are used to learn classifiers that classify programs into benign and malicious [1, 4, 7, 10, 13, 17, 21].", "startOffset": 129, "endOffset": 154}, {"referenceID": 2, "context": "In malware detection, machine learning techniques are used to learn classifiers that classify programs into benign and malicious [1, 4, 7, 10, 13, 17, 21].", "startOffset": 129, "endOffset": 154}, {"referenceID": 5, "context": "In malware detection, machine learning techniques are used to learn classifiers that classify programs into benign and malicious [1, 4, 7, 10, 13, 17, 21].", "startOffset": 129, "endOffset": 154}, {"referenceID": 8, "context": "In malware detection, machine learning techniques are used to learn classifiers that classify programs into benign and malicious [1, 4, 7, 10, 13, 17, 21].", "startOffset": 129, "endOffset": 154}, {"referenceID": 11, "context": "In malware detection, machine learning techniques are used to learn classifiers that classify programs into benign and malicious [1, 4, 7, 10, 13, 17, 21].", "startOffset": 129, "endOffset": 154}, {"referenceID": 15, "context": "In malware detection, machine learning techniques are used to learn classifiers that classify programs into benign and malicious [1, 4, 7, 10, 13, 17, 21].", "startOffset": 129, "endOffset": 154}, {"referenceID": 19, "context": "In malware detection, machine learning techniques are used to learn classifiers that classify programs into benign and malicious [1, 4, 7, 10, 13, 17, 21].", "startOffset": 129, "endOffset": 154}, {"referenceID": 7, "context": "In software bug detection, the task is to learn classifiers that classify programs behaviors into faulty and non-faulty [9, 14, 18, 20].", "startOffset": 120, "endOffset": 135}, {"referenceID": 12, "context": "In software bug detection, the task is to learn classifiers that classify programs behaviors into faulty and non-faulty [9, 14, 18, 20].", "startOffset": 120, "endOffset": 135}, {"referenceID": 16, "context": "In software bug detection, the task is to learn classifiers that classify programs behaviors into faulty and non-faulty [9, 14, 18, 20].", "startOffset": 120, "endOffset": 135}, {"referenceID": 18, "context": "In software bug detection, the task is to learn classifiers that classify programs behaviors into faulty and non-faulty [9, 14, 18, 20].", "startOffset": 120, "endOffset": 135}, {"referenceID": 12, "context": "[14] constructs a classifier to generalize known failures of software systems and to further detect (predict) other unknown failures.", "startOffset": 0, "endOffset": 4}], "year": 2017, "abstractText": "What properties about the internals of a program explain the possible differences in its overall running time for different inputs? In this paper, we propose a formal framework for considering this question we dub trace-set discrimination. We show that even though the algorithmic problem of computing maximum likelihood discriminants is NP-hard, approaches based on integer linear programming (ILP) and decision tree learning can be useful in zeroing-in on the program internals. On a set of Java benchmarks, we find that compactly-represented decision trees scalably discriminate with high accuracy\u2014more scalably than maximum likelihood discriminants and with comparable accuracy. We demonstrate on three larger case studies how decision-tree discriminants produced by our tool are useful for debugging timing side-channel vulnerabilities (i.e., where a malicious observer infers secrets simply from passively watching execution times) and availability vulnerabilities.", "creator": "LaTeX with hyperref package"}}}