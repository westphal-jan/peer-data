{"id": "1702.08367", "review": {"conference": "nips", "VERSION": "v1", "DATE_OF_SUBMISSION": "27-Feb-2017", "title": "Differentiable Learning of Logical Rules for Knowledge Base Reasoning", "abstract": "static behaviour composed of probabilistic construction rules only useful for manipulating tasks, normally as knowledge base problems. unfortunately this formulation problem is difficult, since determining sentence structure where the components normally constitute locally small discrete optimization problem. in this paper, we propose an alternative approach : employing completely differentiable model for alternating sets of infinite - stage rules. the approach is inspired by various recently - developed hierarchical logic, i. e. a subset of user - execution logic into which data tasks can be compiled into sequences of automated solutions. analysts could describe detailed neural controller system which examines how to properly contend with entire naturally differentiable forms towards induce reasoning situations, and also importantly, to ease knowledge base completion. the next - term research objective this paper is systematically develop integrated, first - to - end systems consequently may attempt to perform high - level hierarchical reasoning as widely as lower - level perceptual tasks.", "histories": [["v1", "Mon, 27 Feb 2017 16:44:38 GMT  (156kb,D)", "http://arxiv.org/abs/1702.08367v1", null], ["v2", "Sun, 4 Jun 2017 04:17:58 GMT  (419kb,D)", "http://arxiv.org/abs/1702.08367v2", null]], "reviews": [], "SUBJECTS": "cs.AI", "authors": ["fan yang", "zhilin yang", "william w cohen"], "accepted": true, "id": "1702.08367"}, "pdf": {"name": "1702.08367.pdf", "metadata": {"source": "META", "title": "Differentiable Learning of Logical Rules for Knowledge Base Completion", "authors": ["Fan Yang", "Zhilin Yang", "William W. Cohen"], "emails": ["<fanyang1@cs.cmu.edu>,", "<zhiliny@cs.cmu.edu>,", "<wcohen@cs.cmu.edu>."], "sections": [{"heading": "1. Introduction", "text": "A large body of work in AI and machine learning has considered the problem of learning models composed of sets of first-order logical rules, such as the rule: for all a,b,c,\nAthletePlaysForTeam(a, b) \u2227 TeamPlaysInLeague(b, c) =\u21d2 AthletePlaysInLeague(a,c)\nThis problem is often called inductive logic programming (ILP) (Muggleton et al., 1992) or statistical relational learning (SRL) (Getoor, 2007) and typically the underlying logic is a probabilistic logic, such as Markov Logic Networks (Richardson & Domingos, 2006) or ProPPR (Wang et al., 2013). Learned models composed of probabilistic logical rules are useful for a number of tasks, including\n1School of Computer Science, Carnegie Mellon University, Pittsburgh, PA, USA. Correspondence to: Fan Yang <fanyang1@cs.cmu.edu>, Zhilin Yang <zhiliny@cs.cmu.edu>, William W. Cohen <wcohen@cs.cmu.edu>.\nFigure 1. An overview of the model: a memory-augmented recurrent neural network acts as a controller that learns to compose primitive logic operators. At each step, the controller \u201csoftly\u201d chooses operators and inputs from memory. The operators correspond to one-hop reasoning in the knowledge base.\nknowledge base completion (Lao et al., 2011; Wang et al., 2015b). Unfortunately the learning problem is quite difficult, since determining the structure of the theory (i.e., the particular sets of rules included) is a discrete optimization problem, and one that involves search over a potentially large space of alternatives. Most past learning systems have thus used local-search based optimization methods that interleave moves in a discrete space with moves in parameter space (Kok & Domingos, 2007; Lao & Cohen, 2010; Wang et al., 2014).\nIn this paper, we propose an alternative approach: a completely differentiable model for learning models defined by sets of first-order rules. The approach is inspired by a differentiable logic called TensorLog (Cohen, 2016), a subset of first-order logic for which inference tasks for can be compiled into sequences of differentiable numerical operations on matrices. TensorLog, however, assumes that a human programmer chooses the set of logical rules, and then uses gradient-based learning methods to optimize parameters (which represent confidences for facts and rules): in other words, it includes no mechanism for structure search.\nIn this paper, we describe a neural controller system (Neelakantan et al., 2015; Andreas et al., 2016) which learns how to sequentially compose the primitive operations used\nar X\niv :1\n70 2.\n08 36\n7v 1\n[ cs\n.A I]\n2 7\nFe b\n20 17\nby TensorLog. The space of programs which can be learned by this controller system includes the space of TensorLog programs, but the controller is fully differentiable, and can be learned end-to-end with gradient methods. In outline, our system includes (1) a memory, which holds vectors holding a distribution of potential bindings for logical variables, (2) a neural controller, which is recurrent neural network that takes actions based on the current hidden state, and (3) a set of operations, analogous to the operations used in TensorLog, which perform \u201cprimitive logical inference steps\u201d. Each operation takes as input one or more previously-bound memory cells, and populates a new memory cell. At each stage of the computation, the controller uses an attention mechanism to pick an operation to perform and inputs to the operation, performs the operation, and finally updates its hidden state.\nWe conduct experiments on four knowledge base completion tasks of varying scale. Our differentiable rule learning method outperforms a strong iterated structure gradient (Wang et al., 2014) baseline.\nThe long-term goal of this work is to develop integrated, end-to-end systems that can both perform compositional, logical reasoning, as well as lower-level perception tasks. A differentiable rule learning method is a step toward integration of these two types of learning. While the end result is less interpretable than an explicit set of logical rules, the input and output of the can be interpreted as hidden states or probability distributions for \u201cupstream\u201d or \u201cdownstream\u201d modules.\nIn the remainder of the paper, we introduce the knowledge base completion task in Section 2. In Section 3, we describe in detail the aforementioned TensorLog operators and how to learn rules differentiably. In the Section 4, we compare our method with a strong discrete rule learning baseline on four knowledge bases. Lastly in Section 5, we draw the connections among our methods and other rule learning models."}, {"heading": "2. Knowledge Base Completion", "text": ""}, {"heading": "2.1. Definitions", "text": "Knowledge bases (KB) are sets of facts about real-world entities (such as people, places, and things). The facts in the knowledge base are usually stored in RDF format, i.e. each fact is a triple of the format (head, relation, tail), or equivalently relation(head, tail). For example, a fact Father(Tom, Amy) means that Tom is the father of Amy. Modern knowledge bases such as Freebase (Bollacker et al., 2008) contains millions of entities and billions of facts. Such large amount of structured data has promising applications in many problems, such as information retrieval, natural language understanding, and biological data mining.\nKnowledge bases are usually incomplete. There are facts about the entities not included in the database. Hence an important task regarding knowledge base is to automatically discover the missing facts, i.e. knowledge base completion. In some scenarios, the missing facts can be inferred by reasoning from the existing facts. This is based on the assumptions that structure in knowledge bases provides sufficient information. We adopt this assumption and proposes a rule learning method that leverages the structure among relations.\nRepresentation based knowledge base completion methods rely on learning embeddings for entities (Socher et al., 2013). This entity-dependent memorization approach is not as inductively generalizable as our method. Our rule learning method is capable of entity-independent reasoning, a feature that is absent in representation based methods."}, {"heading": "2.2. Logic rules for KB completion", "text": "We are interested in learning chain-like logic rules of the following form,\nRA1(y1, x) \u2227 \u00b7 \u00b7 \u00b7 \u2227RAn(z, yn) =\u21d2 RC(z, x) (1)\nwhere n \u2264 N , and N is any fixed integer. RA1 , . . . , RAn , and RC are relations in the knowledge base, and y1, . . . , yn, x, z are entities. These rules can be used for knowledge base completion because if we want to infer the missing fact RC(z, x), this can be reduced to checking if there exists y1, . . . , yn such that RA1(y1, x), . . . , RAn(z, yn) are all facts in the knowledge base.\nConsidering the complexity of modern knowledge bases and the fact that they often contain noisy information, it is unlikely to find rules that are consistent with all the data. Thus, we associate each rule with a real number \u03b1 \u2208 (0, 1) as its confidence. The rules now become\nRA1(y1, x) \u2227 \u00b7 \u00b7 \u00b7 \u2227RAn(z, yn) =\u21d2 RC(z, x), 0.9 (2)\nDuring inference, we will compute the confidence of RC(z, x) by adding the confidences of all the rules that imply it."}, {"heading": "3. Differentiable Rule Learning", "text": ""}, {"heading": "3.1. TensorLog representation of KB and logic rule inference", "text": "In order to make rule learning differentiable, we first introduce a matrix representation of the knowledge base and logic rule inference, as used in TensorLog (Cohen, 2016). In this representation, entities are numerically encoded. We represent each entity e with a one hot vector ve \u2208 {0, 1}N , where N is the number of entities, and only the e-th component is 1. For each relation C in the KB, we use a matrix\nMC \u2208 {0, 1}N\u00d7N to store all the facts about this relation. Then entry MCi,j is 1 if and only if RC(i, j) is a fact in the knowledge base.\nUsing this matrix representation, we can imitate the rule inference RA(y, x)\u2227RB(z, y) =\u21d2 RC(z, x) for all y by computing\nuz,B,A,x . = vTzM BMAvx. (3)\nIn the context of this paper, the TensorLog operators indeed refer to multiplying with matrixMR for some relation R. Figure 2 shows a graph-based equivalent view of applying TensorLog operators. In other words, each TensorLog operators (i.e. multiplications with certain matrices) allow the model to perform one-hop reasoning in the knowledge base.\nIt is straightforward from the representation definition that\n|{y | RA(y, x) \u2227RB(z, y) holds }| = uz,B,A,x (4)\nIn other words, given z and x, the number of y\u2019s that satisfy RA(y, x) \u2227 RB(z, y) is equal to the matrix product vTzM BMAvx.\nSince RA(y, x) and RB(z, y) together implies RC(z, x), It is natural to assume that the more such y\u2019s, the more likely RC(z, x) holds. Thus, we will use u . = MBMAvx to represent the confidence, denoted C(\u00b7), over entities {z} such that RC(z, x) holds. Mathematically, this means\nui = |{y | RA(y, x) \u2227RB(zi, y)}| \u221d C[RC(zi, x) holds] (5)\nAs we mentioned before, there could be multiple rules that imply RC , each with different confidences. Let these rules be\nRAl(y, x) \u2227RBl(z, y) =\u21d2 RC(z, x) (6)\nLet the confidence of these rules be \u03b1l, where l = 1, . . . , L. Therefore, the confidence of RC(zi, x) is\nC[RC(\u00b7, x) holds] \u221d \u2211 l \u03b1lM BlMAlvx (7)\nThough we have described the rules in terms of length two, it is straightforward to generalize to cases where rule lengths varies, resulting the following mathematical formulation,\nC[RC(\u00b7, x) holds] \u221d \u2211 l \u03b1l \u220f j\u2208\u03b2l M jvx (8)\nwhere \u03b2l contains the indices of relations in rule l. It is worth pointing out that matrix multiplication is not commutative in this scenario, and we must multiply the relation matrices in the particular order specified by the rules."}, {"heading": "3.2. Learning the logic rules", "text": "We will now discuss the rule learning process, including learnable parameters and model architecture. As shown in Equation 8, for each query RC(\u00b7, x), we need to learn the set of rules that imply it and the confidences associated with these rules. Since these parameters are dependent on the query relation, we augment the notation with raising indices to make this explicit. The learnable parameters of our model is {\u03b1Cl , \u03b2Cl }, for each relation C.\nHowever, it is difficult to formulate a differentiable process to directly learn the parameters {\u03b1Cl , \u03b2Cl } (Lao & Cohen, 2010). This is because each parameter is associated with a particular rule, and enumerating rules is an inherently discrete task. To overcome this difficulty, we observe that an almost equivalent way to write Equation 8 is to interchange the summation and product, resulting the following\nformula with different parameterization,\nT\u220f t K\u2211 k aktM kvx (9)\nwhere T is the max length of rules and K is the number of relations in the knowledge base. The key parameterization difference between Equation 8 and Equation 9 is that in the latter we associate each relation in the rule with a weight. This combines the rule enumeration and confidence assignment.\nHowever, there is a problem with Equation 9 that it assumes all rules are of the same length. This issue can be solved by using a similar but recurrent formulation\nu0 = vx, ut = t\u22121\u2211 \u03c4 bt\u03c4u\u03c4 , ut+1 = K\u2211 k aktM kut (10)\nEquation 10 can represent rules of different lengths because of the memory vectors ut. The memory vector allows the model to append relations to any partially enumerated rules, hence the various rule lengths.\nGiven the formulation in Equation 10, the learnable parameters for each relation RC becomes {akt , bt\u03c4} for t = 1, . . . , T and k = 1, . . .K. We use a memory-augmented Long short-term memory network (Hochreiter & Schmidhuber, 1997; Weston et al., 2014; Graves et al., 2016), denoted controller, to model this recurrent process. The number of unroll steps in the controller is the maximum length of the logic rules that we want to learn. The controller mechanism is the following:\nht, ct = update(ht\u22121, ct\u22121, inputt) (11) at = softmax(Wht + b) (12)\nbt = softmax([h1, . . . , ht\u22121]Tht) (13)\nThe ht and ct are hidden states of the controller. The inputt is a continuous representation of the relation RC . The controller predicts relation weights akt based on the relation and previous hidden states. The weights bt\u03c4 on previous memory are based on comparing current hidden states with all previous hidden states.\nThe objective function is to minimize the negative cross entropy between normalized uT , denote uT and vz for all z that RC(z, x) holds but are not available in the knowledge base.\nLoss = \u2212 (uT log vz + (1\u2212 uT log(1\u2212 vz)) (14)\nThe loss function in Equation 14 indeed represents our goal of using logic rules for knowledge base completion. It aims to learn logic rules that when executed return the same result as if directly infer the relation RC .\nWe can naturally extend the model to include entities information in the knowledge base. The idea is to use the entity to control how much information flow from the hidden state ht to the relation weights at by adding a gate on the hidden states (Dhingra et al., 2016; Yang et al., 2016). Mathematically, this means\nht = ht sigmoid(W1f(x) +W2ht\u22121 + b\u2032) (15)\nwhere f(x) is a continuous representation of the entity x. This will make the learned logic rules not only relation dependent, but also entity dependent, which can be considered as adding a condition term in the logic rules, such as\nIf entity is x, then RA(y, x) \u2227RB(z, y) =\u21d2 RC(z, x) (16)"}, {"heading": "4. Experiments", "text": "To study the effectiveness of our differentiable rule learning model, we apply it to the knowledge base completion task on four knowledge bases. We compare the experiment results from our model and those from an iterated structural gradient (ISG) (Wang et al., 2014) structure learning method based on ProPPR, an efficient and scalable first-order probabilistic logic program (Wang et al., 2013). The ProPPR based ISG method has been compared with other popular ILP methods such as FOIL (Quinlan, 1990), or pseudo-likelihood based structure learning methods for MLNs (Richardson & Domingos, 2006)."}, {"heading": "4.1. Data sets", "text": "We use the following four knowledge bases in our experiment: Unified Medical Language System (UMLS) (Kok & Domingos, 2007), Alyawarra kinship (Kok & Domingos, 2007), Wordnet (Miller, 1995), and a subset of Freebase (Bordes et al., 2013). The statistics of the databases are shown in Table 1.\nThe UMLS knowledge base contains facts about medicalrelated objects and symptoms, such as (bacterium, affects, anatomical abnormality). The Alyawarra kinship knowledge base contains facts about demographical information of an aboriginal tribe in central Australia. The Wordnet knowledge base contains lexical information about English words. The Freebase15k knowledge base is a subset of Freebase, it contains general facts about movies, sports, etc."}, {"heading": "4.2. Experiment setup", "text": "We now describe the experiment setup of rule learning for knowledge base completion. The completion task involves three type of data during training and testing. Firstly, we need a database DB that store the facts we already know. Secondly, we need training samples and labels of the form\n(query, answer) for the completion task. Each (query, answer) example can be derived from a fact (z, RC , x). The query is RC(?, x) and answer is z. The model will use the database DB to find answer for the query.\nThere are multiple ways to divide the knowledge base facts into database, training examples, and test examples. We describe the data splitting and training/testing protocols used in our experiments in the next Section 4.2.1."}, {"heading": "4.2.1. DATA SPLITTING AND TRAINING/TESTING PROTOCOLS", "text": "The first protocol divides the facts in knowledge base into four disjoint sets: train database DBtrain, train examples (qtrain, atrain), test database DBtest, and test examples (qtest, atest). During training (testing), the model will use DBtrain (DBtest) to answer queries qtrain (qtest).\nThe second protocol first divides the knowledge base into two disjoint sets: DBall, and test examples (qtest, atest). During each iteration in training, a mini-batch of facts ftrain is removed from the database DBall to derive (qtrain, atrain). And the database during this training iteration is DBall \\ ftrain. During testing, the database DBall is used by the model to find answers atest for qtest. This protocol allows more training examples then the first one."}, {"heading": "4.3. Result and analysis", "text": ""}, {"heading": "4.3.1. BASELINE", "text": "We consider a structure learning strong baseline which is an iterated structural gradient structure learning method. Details about this method can be found in Section 5.1. The data splitting and training/testing setup used in this method is the first protocol described in Section 4.2.1. As mentioned in Section 2.2, since our method aims to learn logic rule, we only compare with logic-based inference method."}, {"heading": "4.3.2. IMPLEMENTATION", "text": "In our differentiable rule learning model, we can use either setup described in Section 4.2.1 and conduct experiments for both protocols. For the optimization part of the model, we use a stochastic gradient descent algorithm\nADAM (Kingma & Ba, 2014) with learning rate 0.001. We set the maximum rule length to be two. The input to the neural controller at each step is a continuous representation of the query relation. This is done by looking up the relation embedding matrix. This embedding matrix is randomly initialized.\nThe hidden states size and query continuous representation size are both 128. The mini-batch size is 128 or 64 depending on whether the mini-batch can fit in GPU memory. The model is implemented in TensorFlow (Abadi et al., 2016). We store the matrices M \u2019s in Equation 10 as sparse matrices. The model is run on both CPU and GPU, since sparse matrix related operators are only supported on CPU in TensorFlow."}, {"heading": "4.3.3. EXPERIMENT RESULTS", "text": "In the context of knowledge base completion, the answer to a query is usually a ranked list of entities. Therefore we use Hits@10 (Bordes et al., 2013) as the evaluation metric. This metric checks if the target entity is ranked in the top 10.\nWe show the evaluation results on the four data sets in Table 2 and Table 3. The upper half of the table are experiments that use the first data splitting protocol. The lower half of the table are experiments that use the second data splitting protocol. The baseline iterated structure gradient (ISG) method is only implemented using the first protocol. Diff Rule refers to our differentiable rule learning method. Diff Rule Embed refers to where we also use entity embeddings to gate the neural controller hidden states, as described in Equation 15.\nUsing both data splitting and training/testing protocols, our differentiable rule learning method performs better then iterated structural gradient. This is because our method learns rules for all query relations jointly, so it could leverage the similarity among relations and learn rules more ef-\ninstance hyponym (z, x) =\u21d2 similiar to (z, x), 0.5\nderivationally related form (z, x) =\u21d2 similar to (z, x), 0.3\nprocess of (z, y) \u2227 affects(y, z) =\u21d2 affects(z, x), 0.4\nresult of (z, y) \u2227 affects (y, x) =\u21d2 affects (z, x), 0.3\nresult of (z, y) \u2227 causes (y, x) =\u21d2 complicates (z, x), 0.45\ncauses (z, y) \u2227 assesses effect of (y, x) =\u21d2 diagnoses (z, x), 0.43\nfectively.\nIn Table 4, we display some learned logic rules with relative high confidences from the knowledge bases. The logic rules and their confidences are derived based on Equation 8 and Equation 10. Intuitively speaking, we compute the rule confidences \u03b1l by multiplying together the attention akt of each relations that compose the rule."}, {"heading": "5. Related Work", "text": ""}, {"heading": "5.1. Inductive logic programming", "text": "A number of approaches have been explored to perform a data-driven search for for logical theories. Except in trivial cases, this problem is intractable (Cohen & Page, 1995), so heuristics are usually used to search this discrete space. For example, the FOIL system (Quinlan, 1990; Quinlan & Cameron-Jones, 1993) uses decision-tree like information gain measures to guide a greedy search, in which rules are constructed by incrementally adding conditions to an empty rule body, and theories are constructed by incrementally adding rules to an empty theory. Similar heuristics have been applied to search for zeroth-order (propositional\nrule sets) (e.g., (Cohen, 1995)). Other discrete search methods used to search for logical theories include searches that exploit special operators, such as finding the least general generalization of two candidate rules (Muggleton et al., 1990) or inverse entailment (Muggleton, 1995). While these techniques are often successful they do not exploit the power of modern gradient-based optimization methods, and are not well-suited to use in integrated, end-to-end systems that can combine logical reasoning with neural approaches for lower-level tasks.\nIn order to model statistically complex data, more recent approaches to learning logical theories adopt probabilistic logics, rather than standard logics. For instance, Kok and Domingos (Kok & Domingos, 2005) describe a system which interleaves parameter optimization of weights for Markov Logic Network (MLN) rules and beam search to find the structure of a MLN (Richardson & Domingos, 2006). These approaches are robust but computationally expensive in practice, especially since for many probabilistic logics, parameter optimization (and often inference) is expensive.\nAlternatively, search can be made more efficient by restricting the space of logical rules. For instance, the Path Ranking Algorithm (PRA) (Lao et al., 2011) first enumerates a subset of all possible rules, consisting of chain rules of limited length. Using these rules, the algorithm assigns features to each pair of entities, based on a confidence score derived from a random-walk semantics for the rule. Finally, it trains a classifier using these features that classifies relations between entities, using L1-regularization to eliminate unnecessary rules. Our method is broadly similar to PRA: in particular, we also consider chain rules (in these experiments) and associate weights with rules. However, our method jointly enumerates rules and assigns weights in an end-to-end differentiable manner.\nPRA has since been extended in several ways, for instance, by adopting \u201csofter paths\u201d (Gardner et al., 2014) based on vector space similarity. One extension is the logic ProPPR (Wang et al., 2015a), which generalizes the paths of PRA to a full logic, which extends stochastic logic programs (Muggleton et al., 1996). ProPPR has also been combined with Iterative Structural Gradient (ISG), a variant of a structure learning method based on use of meta-interpreters (Muggleton & Lin, 2013). Briefly, a ProPPR meta-interpreter is constructed which behaves like a theory which contains a large number of rules\u2014in particular, every rule which can be generated by a set of rule templates\u2014such that the parameters of this \u201ctemplate theory\u201d correspond to specific instantiations of a rule. By computing a gradient of the cost function with respect to the parameters, it is possible to identify rule instantiations which would reduce loss. These are added to the meta-interpreter as special cases, and the\nprocess is repeated. After several iterations of rule introduction based on \u201cstructural gradient\u201d, weights are learned for the learned rules using ordinary parameter learning (by gradient descent.) Though ISG is a fairly scalable and general method, this approach still requires discrete moves through structure space, and hence it is not clear how to integrate with other perception tasks in an end-to-end differentiable fashion. ISG is used in the experiments of Section 4 as our strong baseline, and the experiments suggest a substantial improvement in performance on most datasets."}, {"heading": "5.2. Neural programmer and Differentiable Neural Computer", "text": "Our learning approach is based on past work in learning neural controllers which learn to perform sequences of (usually differentiable) operations on memory. For instance, the Neural Programmer (Neelakantan et al., 2015; 2016) is a similar neural controller model that uses an attention mechanism to \u201csoftly\u201d choose which actions to take at each step. Our method differs from Neural Programmer in several details, but notably in the choice of operators. The goal of Neural Programmer is to parse natural language utterances into sequences of actions, and hence each of its action is an independent task, such as table lookup or summation. In contrast, we select operations (such as sparse matrix multiplication) and a database encoding such that operations, properly sequenced, can be used to implement logical reasoning.\nThe operators we use are based on operations used internally in TensorLog (Cohen, 2016), a recently developed deductive database, for which the reasoning process is differentiable. While we adopt the same data representation and operators of TensorLog, one key difference between our method and TensorLog that TensorLog assumes given the logic programs, it then performs inference using the logic programs. In contrast, in our method, we aim to learn the structure of the logic program.\nThe Differentiable Neural Computer (DNC) (Graves et al., 2016) is a more general model and is capable of modeling more complex programs than our method. However, during training, DNC requires full supervision, such as step by step program executions, while our method only requires weak supervision: the only \u201creward signal\u201d in our method is whether the composed logic rules return the desired entity."}, {"heading": "5.3. Representation learning", "text": "Knowledge base completion, the task considered in the experimental part of this paper, can also be addressed with representation learning methods (Bordes et al., 2013; Socher et al., 2013; Lin et al., 2015; Shen et al., 2016), in which knowledge bases entities and relations are repre-\nsented as low-dimensional continuous vectors, so that similarity in this space can be used to make certain inferences. A common approach in knowledge-base embedding models is to learn representations of relations (denoted WR) and entities (denoted ve) such that for some measurement function f , the value f(ve1 ,WR, ve2) is maximized for all R(e1, e2) facts. To infer whether some fact R\u2032(e1, e2) holds, we can compute and if necessary threshold the value f(ve1 ,WR\u2032 , ve2). Unfortunately, embedding methods will always fail to infer R\u2032(e\u0302, e2) if e\u0302 is a entity not seen in training, because the representation of the new entity ve\u0302 is unavailable to the model.\nRule learning approaches model the structure of inferences, rather than the structure of entities, so they do not suffer from the same problem. Hence in many ways these approaches are complementary to knowledge-base embedding approaches, and the relative performance of the methods on a task probably depends on the sparsity of relations associated with entities (with more relations per entity favoring embedding models) versus the regularity of the inference process (with logically simpler inferences favoring rule learning approaches). We note that on some standard knowledge-base embedding tasks, previous comparisons have shown that ISG is quantitatively competitive with knowledge-base embedding approaches (Wang & Cohen, 2016)."}, {"heading": "6. Conclusions and Future Work", "text": "We present a differentiable rule learning method for the knowledge base completion task. Our method builds upon a recently developed differentiable deductive database TensorLog. The input and output of our rule learning method are real-valued vectors that can be interpreted as hidden states and probability distributions, which are objects that can be conveniently connected with \u201cupstream\u201d and \u201cdownstream\u201d learning tasks. We hope this differentiable rule learning method can enable various integrations of reasoning and pattern recognition tasks.\nIn the future, we plan to work on more problem settings where composition of logic operators is essential and complementary to pattern recognition, such as data integration, reading comprehension, etc."}], "references": [{"title": "Learning to compose neural networks for question answering", "author": ["Andreas", "Jacob", "Rohrbach", "Marcus", "Darrell", "Trevor", "Klein", "Dan"], "venue": "In Proceedings of NAACL-HLT,", "citeRegEx": "Andreas et al\\.,? \\Q2016\\E", "shortCiteRegEx": "Andreas et al\\.", "year": 2016}, {"title": "Freebase: a collaboratively created graph database for structuring human knowledge", "author": ["Bollacker", "Kurt", "Evans", "Colin", "Paritosh", "Praveen", "Sturge", "Tim", "Taylor", "Jamie"], "venue": "In Proceedings of the 2008 ACM SIGMOD international conference on Management of data,", "citeRegEx": "Bollacker et al\\.,? \\Q2008\\E", "shortCiteRegEx": "Bollacker et al\\.", "year": 2008}, {"title": "Translating embeddings for modeling multi-relational data", "author": ["Bordes", "Antoine", "Usunier", "Nicolas", "Garcia-Duran", "Alberto", "Weston", "Jason", "Yakhnenko", "Oksana"], "venue": "In Advances in neural information processing systems,", "citeRegEx": "Bordes et al\\.,? \\Q2013\\E", "shortCiteRegEx": "Bordes et al\\.", "year": 2013}, {"title": "Fast effective rule induction", "author": ["Cohen", "William W"], "venue": "In Proceedings of the twelfth international conference on machine learning,", "citeRegEx": "Cohen and W.,? \\Q1995\\E", "shortCiteRegEx": "Cohen and W.", "year": 1995}, {"title": "Tensorlog: A differentiable deductive database", "author": ["Cohen", "William W"], "venue": "arXiv preprint arXiv:1605.06523,", "citeRegEx": "Cohen and W.,? \\Q2016\\E", "shortCiteRegEx": "Cohen and W.", "year": 2016}, {"title": "Polynomial learnability and inductive logic programming: Methods and results", "author": ["Cohen", "William W", "Page", "C David"], "venue": "New Generation Computing,", "citeRegEx": "Cohen et al\\.,? \\Q1995\\E", "shortCiteRegEx": "Cohen et al\\.", "year": 1995}, {"title": "Gated-attention readers for text comprehension", "author": ["Dhingra", "Bhuwan", "Liu", "Hanxiao", "Cohen", "William W", "Salakhutdinov", "Ruslan"], "venue": "arXiv preprint arXiv:1606.01549,", "citeRegEx": "Dhingra et al\\.,? \\Q2016\\E", "shortCiteRegEx": "Dhingra et al\\.", "year": 2016}, {"title": "Incorporating vector space similarity in random walk inference over knowledge bases", "author": ["Gardner", "Matt", "Talukdar", "Partha", "Krishnamurthy", "Jayant", "Mitchell", "Tom"], "venue": "In Proceedings of the 2014 Conference on Empirical Methods in Natural Language Processing (EMNLP),", "citeRegEx": "Gardner et al\\.,? \\Q2014\\E", "shortCiteRegEx": "Gardner et al\\.", "year": 2014}, {"title": "Introduction to statistical relational learning", "author": ["Getoor", "Lise"], "venue": "MIT press,", "citeRegEx": "Getoor and Lise.,? \\Q2007\\E", "shortCiteRegEx": "Getoor and Lise.", "year": 2007}, {"title": "Long shortterm memory", "author": ["Hochreiter", "Sepp", "Schmidhuber", "J\u00fcrgen"], "venue": "Neural computation,", "citeRegEx": "Hochreiter et al\\.,? \\Q1997\\E", "shortCiteRegEx": "Hochreiter et al\\.", "year": 1997}, {"title": "Adam: A method for stochastic optimization", "author": ["Kingma", "Diederik", "Ba", "Jimmy"], "venue": "arXiv preprint arXiv:1412.6980,", "citeRegEx": "Kingma et al\\.,? \\Q2014\\E", "shortCiteRegEx": "Kingma et al\\.", "year": 2014}, {"title": "Learning the structure of markov logic networks", "author": ["Kok", "Stanley", "Domingos", "Pedro"], "venue": "In Proceedings of the 22nd international conference on Machine learning,", "citeRegEx": "Kok et al\\.,? \\Q2005\\E", "shortCiteRegEx": "Kok et al\\.", "year": 2005}, {"title": "Statistical predicate invention", "author": ["Kok", "Stanley", "Domingos", "Pedro"], "venue": "In Proceedings of the 24th international conference on Machine learning,", "citeRegEx": "Kok et al\\.,? \\Q2007\\E", "shortCiteRegEx": "Kok et al\\.", "year": 2007}, {"title": "Relational retrieval using a combination of path-constrained random walks", "author": ["Lao", "Ni", "Cohen", "William W"], "venue": "Machine learning,", "citeRegEx": "Lao et al\\.,? \\Q2010\\E", "shortCiteRegEx": "Lao et al\\.", "year": 2010}, {"title": "Random walk inference and learning in a large scale knowledge base", "author": ["Lao", "Ni", "Mitchell", "Tom", "Cohen", "William W"], "venue": "In Proceedings of the Conference on Empirical Methods in Natural Language Processing,", "citeRegEx": "Lao et al\\.,? \\Q2011\\E", "shortCiteRegEx": "Lao et al\\.", "year": 2011}, {"title": "Modeling relation paths for representation learning of knowledge bases", "author": ["Lin", "Yankai", "Liu", "Zhiyuan", "Luan", "Huanbo", "Sun", "Maosong", "Rao", "Siwei", "Song"], "venue": "arXiv preprint arXiv:1506.00379,", "citeRegEx": "Lin et al\\.,? \\Q2015\\E", "shortCiteRegEx": "Lin et al\\.", "year": 2015}, {"title": "Wordnet: a lexical database for english", "author": ["Miller", "George A"], "venue": "Communications of the ACM,", "citeRegEx": "Miller and A.,? \\Q1995\\E", "shortCiteRegEx": "Miller and A.", "year": 1995}, {"title": "Inverse entailment and progol", "author": ["Muggleton", "Stephen"], "venue": "New generation computing,", "citeRegEx": "Muggleton and Stephen.,? \\Q1995\\E", "shortCiteRegEx": "Muggleton and Stephen.", "year": 1995}, {"title": "Efficient induction of logic programs", "author": ["Muggleton", "Stephen", "Feng", "Cao"], "venue": "Citeseer,", "citeRegEx": "Muggleton et al\\.,? \\Q1990\\E", "shortCiteRegEx": "Muggleton et al\\.", "year": 1990}, {"title": "Inductive logic programming, volume 38", "author": ["Muggleton", "Stephen", "Otero", "Ramon", "TamaddoniNezhad", "Alireza"], "venue": null, "citeRegEx": "Muggleton et al\\.,? \\Q1992\\E", "shortCiteRegEx": "Muggleton et al\\.", "year": 1992}, {"title": "Stochastic logic programs", "author": ["Muggleton", "Stephen"], "venue": "Advances in inductive logic programming,", "citeRegEx": "Muggleton and Stephen,? \\Q1996\\E", "shortCiteRegEx": "Muggleton and Stephen", "year": 1996}, {"title": "Metainterpretive learning of higher-order dyadic datalog: Predicate invention revisited", "author": ["Muggleton", "Stephen H", "Lin", "Dianhuan"], "venue": "In Twenty-Third International Joint Conference on Artificial Intelligence,", "citeRegEx": "Muggleton et al\\.,? \\Q2013\\E", "shortCiteRegEx": "Muggleton et al\\.", "year": 2013}, {"title": "Neural programmer: Inducing latent programs with gradient descent", "author": ["Neelakantan", "Arvind", "Le", "Quoc V", "Sutskever", "Ilya"], "venue": "arXiv preprint arXiv:1511.04834,", "citeRegEx": "Neelakantan et al\\.,? \\Q2015\\E", "shortCiteRegEx": "Neelakantan et al\\.", "year": 2015}, {"title": "Learning a natural language interface with neural programmer", "author": ["Neelakantan", "Arvind", "Le", "Quoc V", "Abadi", "Martin", "McCallum", "Andrew", "Amodei", "Dario"], "venue": "arXiv preprint arXiv:1611.08945,", "citeRegEx": "Neelakantan et al\\.,? \\Q2016\\E", "shortCiteRegEx": "Neelakantan et al\\.", "year": 2016}, {"title": "Learning logical definitions from relations", "author": ["Quinlan", "J. Ross"], "venue": "Machine learning,", "citeRegEx": "Quinlan and Ross.,? \\Q1990\\E", "shortCiteRegEx": "Quinlan and Ross.", "year": 1990}, {"title": "Foil: A midterm report", "author": ["Quinlan", "J Ross", "Cameron-Jones", "R Mike"], "venue": "In European conference on machine learning,", "citeRegEx": "Quinlan et al\\.,? \\Q1993\\E", "shortCiteRegEx": "Quinlan et al\\.", "year": 1993}, {"title": "Implicit reasonet: Modeling large-scale structured relationships with shared memory", "author": ["Shen", "Yelong", "Huang", "Po-Sen", "Chang", "Ming-Wei", "Gao", "Jianfeng"], "venue": "arXiv preprint arXiv:1611.04642,", "citeRegEx": "Shen et al\\.,? \\Q2016\\E", "shortCiteRegEx": "Shen et al\\.", "year": 2016}, {"title": "Reasoning with neural tensor networks for knowledge base completion", "author": ["Socher", "Richard", "Chen", "Danqi", "Manning", "Christopher D", "Ng", "Andrew"], "venue": "In Advances in neural information processing systems,", "citeRegEx": "Socher et al\\.,? \\Q2013\\E", "shortCiteRegEx": "Socher et al\\.", "year": 2013}, {"title": "Learning first-order logic embeddings via matrix factorization", "author": ["Wang", "William Yang", "Cohen", "William W"], "venue": "In Proceedings of the 25th International Joint Conference on Artificial Intelligence (IJCAI", "citeRegEx": "Wang et al\\.,? \\Q2015\\E", "shortCiteRegEx": "Wang et al\\.", "year": 2015}, {"title": "Structure learning via parameter learning", "author": ["Wang", "William Yang", "Mazaitis", "Kathryn", "Cohen", "William W"], "venue": "In CIKM 2014,", "citeRegEx": "Wang et al\\.,? \\Q2014\\E", "shortCiteRegEx": "Wang et al\\.", "year": 2014}, {"title": "Efficient inference and learning in a large knowledge base", "author": ["Wang", "William Yang", "Mazaitis", "Kathryn", "Lao", "Ni", "Cohen", "William W"], "venue": "Machine Learning,", "citeRegEx": "Wang et al\\.,? \\Q2015\\E", "shortCiteRegEx": "Wang et al\\.", "year": 2015}, {"title": "Efficient inference and learning in a large knowledge base", "author": ["Wang", "William Yang", "Mazaitis", "Kathryn", "Lao", "Ni", "Cohen", "William W"], "venue": "Machine Learning,", "citeRegEx": "Wang et al\\.,? \\Q2015\\E", "shortCiteRegEx": "Wang et al\\.", "year": 2015}, {"title": "Words or characters? fine-grained gating for reading comprehension", "author": ["Yang", "Zhilin", "Dhingra", "Bhuwan", "Yuan", "Ye", "Hu", "Junjie", "Cohen", "William W", "Salakhutdinov", "Ruslan"], "venue": "arXiv preprint arXiv:1611.01724,", "citeRegEx": "Yang et al\\.,? \\Q2016\\E", "shortCiteRegEx": "Yang et al\\.", "year": 2016}], "referenceMentions": [{"referenceID": 19, "context": "This problem is often called inductive logic programming (ILP) (Muggleton et al., 1992) or statistical relational learning (SRL) (Getoor, 2007) and typically the underlying logic is a probabilistic logic, such as Markov Logic Networks (Richardson & Domingos, 2006) or ProPPR (Wang et al.", "startOffset": 63, "endOffset": 87}, {"referenceID": 14, "context": "knowledge base completion (Lao et al., 2011; Wang et al., 2015b).", "startOffset": 26, "endOffset": 64}, {"referenceID": 29, "context": "Most past learning systems have thus used local-search based optimization methods that interleave moves in a discrete space with moves in parameter space (Kok & Domingos, 2007; Lao & Cohen, 2010; Wang et al., 2014).", "startOffset": 154, "endOffset": 214}, {"referenceID": 22, "context": "In this paper, we describe a neural controller system (Neelakantan et al., 2015; Andreas et al., 2016) which learns how to sequentially compose the primitive operations used ar X iv :1 70 2.", "startOffset": 54, "endOffset": 102}, {"referenceID": 0, "context": "In this paper, we describe a neural controller system (Neelakantan et al., 2015; Andreas et al., 2016) which learns how to sequentially compose the primitive operations used ar X iv :1 70 2.", "startOffset": 54, "endOffset": 102}, {"referenceID": 29, "context": "Our differentiable rule learning method outperforms a strong iterated structure gradient (Wang et al., 2014) baseline.", "startOffset": 89, "endOffset": 108}, {"referenceID": 1, "context": "Modern knowledge bases such as Freebase (Bollacker et al., 2008) contains millions of entities and billions of facts.", "startOffset": 40, "endOffset": 64}, {"referenceID": 27, "context": "Representation based knowledge base completion methods rely on learning embeddings for entities (Socher et al., 2013).", "startOffset": 96, "endOffset": 117}, {"referenceID": 6, "context": "The idea is to use the entity to control how much information flow from the hidden state ht to the relation weights at by adding a gate on the hidden states (Dhingra et al., 2016; Yang et al., 2016).", "startOffset": 157, "endOffset": 198}, {"referenceID": 32, "context": "The idea is to use the entity to control how much information flow from the hidden state ht to the relation weights at by adding a gate on the hidden states (Dhingra et al., 2016; Yang et al., 2016).", "startOffset": 157, "endOffset": 198}, {"referenceID": 29, "context": "We compare the experiment results from our model and those from an iterated structural gradient (ISG) (Wang et al., 2014) structure learning method based on ProPPR, an efficient and scalable first-order probabilistic logic program (Wang et al.", "startOffset": 102, "endOffset": 121}, {"referenceID": 2, "context": "We use the following four knowledge bases in our experiment: Unified Medical Language System (UMLS) (Kok & Domingos, 2007), Alyawarra kinship (Kok & Domingos, 2007), Wordnet (Miller, 1995), and a subset of Freebase (Bordes et al., 2013).", "startOffset": 215, "endOffset": 236}, {"referenceID": 2, "context": "Therefore we use Hits@10 (Bordes et al., 2013) as the evaluation metric.", "startOffset": 25, "endOffset": 46}, {"referenceID": 18, "context": "Other discrete search methods used to search for logical theories include searches that exploit special operators, such as finding the least general generalization of two candidate rules (Muggleton et al., 1990) or inverse entailment (Muggleton, 1995).", "startOffset": 187, "endOffset": 211}, {"referenceID": 14, "context": "For instance, the Path Ranking Algorithm (PRA) (Lao et al., 2011) first enumerates a subset of all possible rules, consisting of chain rules of limited length.", "startOffset": 47, "endOffset": 65}, {"referenceID": 7, "context": "PRA has since been extended in several ways, for instance, by adopting \u201csofter paths\u201d (Gardner et al., 2014) based on vector space similarity.", "startOffset": 86, "endOffset": 108}, {"referenceID": 22, "context": "For instance, the Neural Programmer (Neelakantan et al., 2015; 2016) is a similar neural controller model that uses an attention mechanism to \u201csoftly\u201d choose which actions to take at each step.", "startOffset": 36, "endOffset": 68}, {"referenceID": 2, "context": "Knowledge base completion, the task considered in the experimental part of this paper, can also be addressed with representation learning methods (Bordes et al., 2013; Socher et al., 2013; Lin et al., 2015; Shen et al., 2016), in which knowledge bases entities and relations are represented as low-dimensional continuous vectors, so that similarity in this space can be used to make certain inferences.", "startOffset": 146, "endOffset": 225}, {"referenceID": 27, "context": "Knowledge base completion, the task considered in the experimental part of this paper, can also be addressed with representation learning methods (Bordes et al., 2013; Socher et al., 2013; Lin et al., 2015; Shen et al., 2016), in which knowledge bases entities and relations are represented as low-dimensional continuous vectors, so that similarity in this space can be used to make certain inferences.", "startOffset": 146, "endOffset": 225}, {"referenceID": 15, "context": "Knowledge base completion, the task considered in the experimental part of this paper, can also be addressed with representation learning methods (Bordes et al., 2013; Socher et al., 2013; Lin et al., 2015; Shen et al., 2016), in which knowledge bases entities and relations are represented as low-dimensional continuous vectors, so that similarity in this space can be used to make certain inferences.", "startOffset": 146, "endOffset": 225}, {"referenceID": 26, "context": "Knowledge base completion, the task considered in the experimental part of this paper, can also be addressed with representation learning methods (Bordes et al., 2013; Socher et al., 2013; Lin et al., 2015; Shen et al., 2016), in which knowledge bases entities and relations are represented as low-dimensional continuous vectors, so that similarity in this space can be used to make certain inferences.", "startOffset": 146, "endOffset": 225}], "year": 2017, "abstractText": "Learned models composed of probabilistic logical rules are useful for many tasks, such as knowledge base completion. Unfortunately this learning problem is difficult, since determining the structure of the theory normally requires solving a discrete optimization problem. In this paper, we propose an alternative approach: a completely differentiable model for learning sets of first-order rules. The approach is inspired by a recently-developed differentiable logic, i.e. a subset of first-order logic for which inference tasks can be compiled into sequences of differentiable operations. Here we describe a neural controller system which learns how to sequentially compose the these primitive differentiable operations to solve reasoning tasks, and in particular, to perform knowledge base completion. The long-term goal of this work is to develop integrated, end-to-end systems that can learn to perform high-level logical reasoning as well as lower-level perceptual tasks.", "creator": "LaTeX with hyperref package"}}}