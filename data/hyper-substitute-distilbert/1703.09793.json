{"id": "1703.09793", "review": {"conference": "arxiv", "VERSION": "v1", "DATE_OF_SUBMISSION": "26-Mar-2017", "title": "Deceiving Google's Cloud Video Intelligence API Built for Summarizing Videos", "abstract": "despite the rapid progress by the techniques like program classification, scene registration today remained a challenging environment. centralized video annotation could be considering breakthrough technology, shifting subscribers to tags after the industry. recently, ada publishes yahoo static session intelligence api for character analysis. particularly per the website, bubble worm \" separates signal from objects, by maintaining coherent chunks at the video, audio or per frame. \" a demonstration project has been also documented, which enabled employees to select a query for annotation. the internet then detects appropriate frame labels ( objects within fragmented video ) moderately well as shot labels ( elements of the video sequences over time ). in it description, we examine abc usability : tracking abc's cloud video intelligence api in adversarial environments. in particular, we investigate whether an attack must manipulate a video message whichever multiple strategy can the api uniformly return only the carefully - desired labels. for specific, we select an array that is ripped from the content of the video and contain each, periodically inserted at virtually constant low rate, digitally submitted photos. scientists estimate that if we insert one image every two strokes, the api is deceived into annotating the correct photograph as if it only contains to inserted stream. note recently the modification to the functionality is hardly uncommon as, concerning instance, for low performance frame rate of 25, we insert for eight image per 50 video frames. we also suggest specifically, by inserting one image of second, just the shot packets returned via the api are related to the damaged image. collaborators perform the algorithms from the remaining videos outlined by the api demonstration architecture and announce that our attack facilitates successful capturing different videos regarding images.", "histories": [["v1", "Sun, 26 Mar 2017 20:52:43 GMT  (3250kb,D)", "http://arxiv.org/abs/1703.09793v1", null], ["v2", "Fri, 31 Mar 2017 05:25:36 GMT  (3252kb,D)", "http://arxiv.org/abs/1703.09793v2", null]], "reviews": [], "SUBJECTS": "cs.CV cs.LG", "authors": ["hossein hosseini", "baicen xiao", "radha poovendran"], "accepted": false, "id": "1703.09793"}, "pdf": {"name": "1703.09793.pdf", "metadata": {"source": "CRF", "title": "Deceiving Google\u2019s Cloud Video Intelligence API Built for Summarizing Videos", "authors": ["Hossein Hosseini", "Baicen Xiao", "Radha Poovendran"], "emails": ["rp3}@uw.edu"], "sections": [{"heading": null, "text": "In this paper, we examine the usability of the Google\u2019s Cloud Video Intelligence API in adversarial environments. In particular, we investigate whether an adversary can manipulate a video in such a way that the API will return only the adversary-desired labels. For this, we select an image that is different from the content of the Video and insert it, periodically and at a very low rate, into the video. We found that if we insert one image every two seconds, the API is deceived into annotating the entire video as if it only contains the inserted image. Note that the modification to the video is hardly noticeable as, for instance, for a typical frame rate of 25, we insert only one image per 50 video frames. We also found that, by inserting one image per second, all the shot labels returned by the API are related to the inserted image. We perform the experiments on the sample videos provided by the API demonstration website and show that our attack is successful with different videos and images."}, {"heading": "1. Introduction", "text": "In recent years, machine learning techniques have been extensively deployed for computer vision tasks, particularly recognizing objects in images [1\u20133]. However, using machine learning for annotating videos has remained a challenging task, due to the temporal aspects of videos and the size and complexity of data. Most of current approaches for\nunderstanding the video contents rely on manual tagging or combining humans and computers for more accurate and efficient tagging [4,5]. Automatic video annotation, however, enables searching the videos for a specific event, which is helpful in many applications such as video surveillance or returning the search results on the web. It can be also used for prescanning user videos, for example in YouTube and Facebook, where distribution of certain types of illegal contents is not permitted.\nRecently, Google introduced the Cloud Video Intelligence API for video analysis [6]. Similar to other Google\u2019s machine learning APIs, the Cloud Video Intelligence API is made available to developers to build applications that can automatically search within the videos [7]. A demonstration website has been launched which allows anyone to select a video stored in Google Cloud Storage for annotation [6]. The API then quickly identifies the video labels\nar X\niv :1\n70 3.\n09 79\n3v 1\n[ cs\n.C V\n] 2\n6 M\nar 2\n01 7\nwhich are the key objects within the video. It also detects the scene changes and provides shot labels as the detailed description of the video events over time. As a result, the API has the potential to simplify the video understanding and enable searching in videos just as text documents.\nIn this paper, we examine the usability of the Google\u2019s Cloud Video Intelligence API in adversarial environments. In particular, we investigate whether an adversary can deceive the API into returning only the adversary-desired labels, by slightly manipulating the input video. Such vulnerability will seriously undermine the performance of the video annotation system in real-world applications. For example, a search engine may wrongly suggest manipulated videos to users, or a video filtering system can be bypassed by slightly modifying a video which has illegal contents.\nFor manipulating the videos, we select an image, different from the video content, and insert it, periodically and at a very low rate, into the video. Our experimental results show that by inserting the image once every two seconds, the API is deceived into returning only the video labels which are related the inserted image. Note that the modification to the video is hardly noticeable as, for instance, for a typical frame rate of 25, we insert only one image per 50 video frames. We also found that by inserting one image per second, all the shot labels returned by the API are related to the inserted image. We perform the experiments on the sample videos provided by the API demonstration website and with different images. Figure 1 illustrates the image insertion attack on the Google\u2019s Cloud Video Intelligence API."}, {"heading": "2. Google\u2019s Cloud Video Intelligence API", "text": "The Google\u2019s Cloud Video Intelligence API is designed for video understanding and analysis. It enables the developers to easily search and discover the video content by providing information about entities (nouns or verbs) in the video and when they occur within the video. It was noted in [6] that the system \u201cseparates signal from noise, by retrieving relevant information at the video, shot or per frame.\u201d The API uses deep-learning models, built using frameworks such as TensorFlow and applied on large-scale media platforms such as YouTube [7].\nThe system is said to be helpful for large media companies, to better understand the unstructured video data, and for media organizations and consumer technology companies, who want to build their media catalogs or find easy ways to manage crowd-sourced content [7]. The underlying technology can be also used to improve the video recommendations as well, as it enables the search engines to search the video content, beyond the metadata like descriptions and comments for searches [8]."}, {"heading": "3. The Image Insertion Attack", "text": "In this section, we describe the image insertion attack for deceiving the Google\u2019s Cloud Video Intelligence API. The goal of the attack is to modify a given video in such a way that a human observer would perceive its original content, but the API returns only the adversary-desired annotations. We performed the experiments with three sample videos \u201cAnimals.mp4\u201d, \u201cGoogleFiber.mp4\u201d and \u201cJaneGoodall.mp4\u201d, which are provided by the demonstration website of the Google\u2019s Cloud Video Intelligence API [6]. The API provides video labels (objects in the entire video), shot changes (scene changes within the video) and shot labels (description of the video events over time).\nThe attack procedure is as follows. We first tested the API with sample videos and verified that the API did indeed accurately detect both the video and shot labels. For example, for the \u201cAnimals.mp4\u201d video, the API returns the video labels \u201cAnimal,\u201d \u201cWildlife,\u201d \u201cZoo,\u201d \u201cTerrestrial animal,\u201d \u201cNature,\u201d \u201cTourism,\u201d and \u201cTourist destination,\u201d which are consistent with the video content.\nWe then downloaded the sample videos and modify them. For manipulating the videos, we select an image, different from the video content, and insert it, periodically and at a very low rate, into the videos. Figure 2 shows the four images that were used for image insertion attack, namely, a car, a building, a food plate and a laptop. The schematic of the image insertion attack is illustrated in Figure 1. At the end, we stored the manipulated videos on the Google cloud storage and used them as inputs to the API.\nOur experimental results show that if we insert an im-\nage periodically once every two seconds and in appropriate places, the API completely fails to correctly understand the video content and annotates it as if the video was only about the inserted image. Note that the image insertion rate is very low. That is, for a typical frame rate of 25, we insert only one image per 50 video frames, resulting in an image insertion rate of 0.02.\nTable 1 provides the API\u2019s output for the video labels (the table shows only the label with the highest confidence score). As can be seen, regardless of the video content, the API returns a video label, with a very high confidence score, that exactly matches the corresponding inserted images. Figure 3 shows the results in more details, providing the screenshots of the video annotations for the sample video \u201cAnimals.mp4\u201d and the four versions, each manipulated with one of the images presented in Figure 2. The results show that, while the API can accurately annotate the original video, for the manipulated videos it only outputs the labels which are related to the inserted image. Figures 4 and 5 show similar experiments with the \u201cGoogleFiber.mp4\u201d and \u201cJaneGoodall.mp4\u201d videos, respectively.\nWe performed similar experiments for changing the video shot labels returned by the API. Note that shot labels provide a detailed description of the individual scenes within the video; therefore, compared to changing the video labels, it is more challenging to change all the shot labels, while maintaining a low image insertion rate. However, we found that by inserting one image per second, resulting in an image insertion rate of 0.04 for the frame rate of 25, all the\nshot labels returned by the API are related to the inserted image. Figures 6 shows the screenshots of the shot labels for the original video \u201cAnimals.mp4\u201d and the four manipulated versions, each with one of the inserted images. While the figure shows the results only for one shot, we verified that the attack succeeds to change all the shot labels to the labels of inserted image."}, {"heading": "4. Discussion", "text": "Many applications can benefit from automated video search and summarization. For example, in video surveillance, one needs to search many hours of videos for a specific event. Also, some Internet platforms, such as YouTube and Facebook, require to process enormous amount of video files every day, in order to better distribute the appropriate contents among people and to block the videos with illegal contents. The Google\u2019s Cloud Video Intelligence API is designed to enable the developers to quickly search the video contents, just as text documents. Hence, it has the potential to transform the video analysis field to the point that users can search for a particular event and get related videos along with the exact timings of the events within the videos.\nHowever, we showed that the API has certain security weaknesses. Specifically, an adversary can insert an image, periodically and at a very low rate, into the video in a way that all the generated shot labels are about the inserted image. Such vulnerability seriously undermines the applicability of the API in adversarial environments. For\nexample, one can upload a manipulated video which contains adversarial images related to a specific event, and the API wrongly suggests it to users who asked for videos from the event. Furthermore, an adversary can bypass a video filtering system by inserting a benign image into a video with illegal contents. Our findings show the importance of designing the system to work equally well in adversarial environments.\nNote that we could deceive the video annotation system without having any knowledge about the learning algorithms, video annotation algorithms or the cloud computing architecture used by the API. Hence, we developed an approach for deceiving the Google\u2019s Cloud Video Intelligence API, by only querying the system with different inputs. Through experiments with different videos and images, we showed that the attack is consistently successful, i.e., for the manipulated videos, we could deceive the API to provide only our desired labels."}, {"heading": "5. Conclusion", "text": "In this paper, we showed that the current Google\u2019s Cloud Video Intelligence API can be easily deceived by an adversary without compromising the system or having any knowledge about the specific details of the algorithms used. In essence, an adversary can slightly manipulate a video by inserting an image periodically into it, such that the API returns only the labels that are related to the inserted image. The success of the image insertion attack shows the importance of designing the system to work equally well in adversarial environments."}, {"heading": "Acknowledgments", "text": "This work was supported by ONR grants N00014-14-10029 and N00014-16-1-2710, ARO grant W911NF-16-10485 and NSF grant CNS-1446866.\nThe views presented in this paper are those of the authors and do not reflect the position of sponsoring agencies."}], "references": [{"title": "Pattern recognition and machine learning (information science and statistics), 1st edn. 2006. corr. 2nd printing edn", "author": ["C. Bishop"], "venue": "Springer, New York, 2007.", "citeRegEx": "1", "shortCiteRegEx": null, "year": 2007}, {"title": "Imagenet classification with deep convolutional neural networks", "author": ["A. Krizhevsky", "I. Sutskever", "G.E. Hinton"], "venue": "Advances in neural information processing systems, pp. 1097\u20131105, 2012.", "citeRegEx": "2", "shortCiteRegEx": null, "year": 2012}, {"title": "Very deep convolutional networks for large-scale image recognition", "author": ["K. Simonyan", "A. Zisserman"], "venue": "arXiv preprint arXiv:1409.1556, 2014.", "citeRegEx": "3", "shortCiteRegEx": null, "year": 2014}, {"title": "Assistive tagging: A survey of multimedia tagging with humancomputer joint exploration", "author": ["M. Wang", "B. Ni", "X.-S. Hua", "T.-S. Chua"], "venue": "ACM Computing Surveys (CSUR), vol. 44, no. 4, p. 25, 2012.", "citeRegEx": "4", "shortCiteRegEx": null, "year": 2012}, {"title": "Utility data annotation with amazon mechanical turk", "author": ["A. Sorokin", "D. Forsyth"], "venue": "Computer Vision and Pattern Recognition Workshops, 2008. CVPRW\u201908. IEEE Computer Society Conference on, pp. 1\u20138, IEEE, 2008.", "citeRegEx": "5", "shortCiteRegEx": null, "year": 2008}], "referenceMentions": [{"referenceID": 0, "context": "In recent years, machine learning techniques have been extensively deployed for computer vision tasks, particularly recognizing objects in images [1\u20133].", "startOffset": 146, "endOffset": 151}, {"referenceID": 1, "context": "In recent years, machine learning techniques have been extensively deployed for computer vision tasks, particularly recognizing objects in images [1\u20133].", "startOffset": 146, "endOffset": 151}, {"referenceID": 2, "context": "In recent years, machine learning techniques have been extensively deployed for computer vision tasks, particularly recognizing objects in images [1\u20133].", "startOffset": 146, "endOffset": 151}, {"referenceID": 3, "context": "understanding the video contents rely on manual tagging or combining humans and computers for more accurate and efficient tagging [4,5].", "startOffset": 130, "endOffset": 135}, {"referenceID": 4, "context": "understanding the video contents rely on manual tagging or combining humans and computers for more accurate and efficient tagging [4,5].", "startOffset": 130, "endOffset": 135}], "year": 2017, "abstractText": "Despite the rapid progress of the techniques for image classification, video annotation has remained a challenging task. Automated video annotation would be a breakthrough technology, enabling users to search within the videos. Recently, Google introduced the Cloud Video Intelligence API for video analysis. As per the website, the system \u201cseparates signal from noise, by retrieving relevant information at the video, shot or per frame.\u201d A demonstration website has been also launched, which allows anyone to select a video for annotation. The API then detects the video labels (objects within the video) as well as shot labels (description of the video events over time). In this paper, we examine the usability of the Google\u2019s Cloud Video Intelligence API in adversarial environments. In particular, we investigate whether an adversary can manipulate a video in such a way that the API will return only the adversary-desired labels. For this, we select an image that is different from the content of the Video and insert it, periodically and at a very low rate, into the video. We found that if we insert one image every two seconds, the API is deceived into annotating the entire video as if it only contains the inserted image. Note that the modification to the video is hardly noticeable as, for instance, for a typical frame rate of 25, we insert only one image per 50 video frames. We also found that, by inserting one image per second, all the shot labels returned by the API are related to the inserted image. We perform the experiments on the sample videos provided by the API demonstration website and show that our attack is successful with different videos and images.", "creator": "LaTeX with hyperref package"}}}