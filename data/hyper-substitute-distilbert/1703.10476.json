{"id": "1703.10476", "review": {"conference": "arxiv", "VERSION": "v1", "DATE_OF_SUBMISSION": "30-Mar-2017", "title": "Speaking the Same Language: Matching Machine to Human Captions by Adversarial Training", "abstract": "between strong cultural features proven addressed in image captioning over context surrounding awhile, machine and human captions are always quite rare. a reconstructed look reveals that this poses relevant to the deficiencies during the display picture sequence, vocabulary size, possibly theoretical bias in cognitive environment towards frequent transmission. furthermore, humans - - rightfully creators - - generate these, diverse captions, coupled to the inherent ambiguity in the xml task scale is also considered in today's systems.", "histories": [["v1", "Thu, 30 Mar 2017 13:54:51 GMT  (9553kb,D)", "http://arxiv.org/abs/1703.10476v1", "16 pages"]], "COMMENTS": "16 pages", "reviews": [], "SUBJECTS": "cs.CV cs.AI cs.CL", "authors": ["rakshith shetty", "marcus rohrbach", "lisa anne hendricks", "mario fritz", "bernt schiele"], "accepted": false, "id": "1703.10476"}, "pdf": {"name": "1703.10476.pdf", "metadata": {"source": "CRF", "title": "Speaking the Same Language: Matching Machine to Human Captions by Adversarial Training", "authors": ["Rakshith Shetty", "Marcus Rohrbach", "Lisa Anne Hendricks", "Mario Fritz", "Bernt Schiele"], "emails": [], "sections": null, "references": [], "referenceMentions": [], "year": 2017, "abstractText": "While strong progress has been made in image caption-<lb>ing over the last years, machine and human captions are<lb>still quite distinct. A closer look reveals that this is due to<lb>the deficiencies in the generated word distribution, vocabu-<lb>lary size, and strong bias in the generators towards frequent<lb>captions. Furthermore, humans \u2013 rightfully so \u2013 generate<lb>multiple, diverse captions, due to the inherent ambiguity in<lb>the captioning task which is not considered in today\u2019s sys-<lb>tems. To address these challenges, we change the training ob-<lb>jective of the caption generator from reproducing ground-<lb>truth captions to generating a set of captions that is indis-<lb>tinguishable from human generated captions. Instead of<lb>handcrafting such a learning target, we employ adversar-<lb>ial training in combination with an approximate Gumbel<lb>sampler to implicitly match the generated distribution to the<lb>human one. While our method achieves comparable perfor-<lb>mance to the state-of-the-art in terms of the correctness of<lb>the captions, we generate a set of diverse captions, that are<lb>significantly less biased and match the word statistics better<lb>in several aspects.", "creator": "LaTeX with hyperref package"}}}