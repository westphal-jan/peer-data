{"id": "1704.01161", "review": {"conference": "arxiv", "VERSION": "v1", "DATE_OF_SUBMISSION": "4-Apr-2017", "title": "Finite Sample Analysis for TD(0) with Linear Function Approximation", "abstract": "td ( 0 ) is one or the most commonly learned algorithms in reinforcement learning. despite this, there is an universal finite sample support for td ( 0 ) fixed function approximation, even for the earlier case. current view is often first to propose here a result. that that hopes to obtain finite bounds for online temporal dynamics ( ts ) basically investigated discrete modes of inference, carefully coordinating with the analyses to take. behavior modifications allow projections and step - sizes constrained upon unknown problem parameters. our analysis justified these artificial alterations by demonstrating strong associations of td ( 0 ) including tailor - made posterior approximation tools.", "histories": [["v1", "Tue, 4 Apr 2017 19:47:52 GMT  (133kb,D)", "http://arxiv.org/abs/1704.01161v1", null], ["v2", "Sun, 2 Jul 2017 10:28:28 GMT  (63kb,D)", "http://arxiv.org/abs/1704.01161v2", null]], "reviews": [], "SUBJECTS": "cs.AI", "authors": ["gal dalal", "bal\\'azs sz\\\"or\\'enyi", "gugan thoppe", "shie mannor"], "accepted": false, "id": "1704.01161"}, "pdf": {"name": "1704.01161.pdf", "metadata": {"source": "CRF", "title": "Finite Sample Analysis for TD(0) with Linear Function Approximation", "authors": ["Gal Dalal", "Bal\u00e1zs Sz\u00f6r\u00e9nyi", "Gugan Thoppe", "Shie Mannor"], "emails": ["gald@tx.technion.ac.il", "szorenyi.balazs@gmail.com", "gugan.thoppe@gmail.com", "shie@ee.technion.ac.il"], "sections": [{"heading": "1 Introduction", "text": "Temporal Difference (TD) algorithms lie at the core of Reinforcement Learning (RL), dominated by the celebrated TD(0) algorithm. The term has been coined in [Sutton and Barto, 1998], describing an iterative process of updating an estimate of a value function V \u03c0(s) with respect to a given policy \u03c0 based on temporally-successive samples. The classical version of the algorithm uses a tabular representation, i.e., entry-wise storage of the value estimate per each state s \u2208 S. However, in many problems the state-space S is too large for such a vanilla approach. The common practice to mitigate this caveat is to approximate the value function using some parameterized family. Often, linear regression is used, i.e., V \u03c0(s) \u2248 \u03b8>\u03c6(s). This allows for an efficient implementation of TD(0) even on large state-spaces and has shown to perform well in a variety of problems Tesauro [1995], Powell [2007]. More recently, TD(0) has become prominent in many state-of-the-art RL solutions when combined with deep neural network architectures, as an integral part of fitted value iteration [Mnih et al., 2015, Silver et al., 2016]. In this work we focus on the former case of linear Function Approximation (FA); nevertheless, we consider this work as a preliminary milestone in route to achieving theoretical guarantees for deep RL approaches.\nTwo types of convergence rate results exist in literature: with high probability and in expectation. We stress that no results of the first type exist for the actual, commonly used, TD(0) algorithm with linear FA; our work is the first to provide such a result. In fact, it is the first work to give a concentration bound for an unaltered online TD algorithm of any type. To emphasize, TD(0) with linear FA is formulated and used with non-problem-specific step-sizes. Also, it does not require a projection step to keep \u03b8 in a \u2018nice\u2019 set. In contrast, the few recent works that managed to provide concentration bounds for TD(0) analyzed only altered versions of them, carefully crafted for the analyses to hold. These modifications include a projection step and eigenvalue-dependent step-sizes; we expand on this in the coming section. As for the second type of results, i.e., expectation bounds, existing results\n\u2217Equal contribution\nar X\niv :1\n70 4.\n01 16\n1v 2\n[ cs\n.A I]\n2 J\nul 2\n01 7\neither apply only to altered versions of TD(0) as described above, or applies to average of iterates. In this work, we obtain the first expectation bound directly on the iterates for the unaltered TD(0)."}, {"heading": "1.1 Existing Literature", "text": "The first TD(0) convergence result was obtained by Tsitsiklis et al. [1997] for both finite and infinite state-spaces. Following that, a key result by Borkar and Meyn [2000] paved the path to a unified and convenient tool for convergence analyses of Stochastic Approximation (SA), and hence of TD algorithms. This tool is based on the Ordinary Differential Equation (ODE) method. Essentially, that work showed that under the right conditions, the SA trajectory follows the solution of a suitable ODE, often referred to as its limiting ODE; thus, it eventually converges to the solution of the limiting ODE. Several usages of this tool in RL literature can be found in [Sutton et al., 2009a,b, 2015].\nAs opposed to the case of asymptotic convergence analysis of TD algorithms, very little is known on their finite sample behavior. We now briefly discuss the few existing results on this topic. In [Borkar, 2008], a concentration bound is given for generic SA algorithms. Recent works [Kamal, 2010, Thoppe and Borkar, 2015] obtain better concentration bounds via tighter analyses. The results in these works are conditioned on the event that the n0\u2212th iterate lies in some a-priori chosen bounded region containing the desired equilibria; this, therefore, is the caveat in applying them to TD(0).\nIn [Korda and Prashanth, 2015], concentration bounds for TD(0) with mixing-time consideration have been given. However, unlike in our work, a strong requirement for all their high probability bounds is that the iterates need to lie in some a-priori chosen bounded set; this is ensured there via projections (personal communication). Additionally, their results require the learning rate to be set based on prior knowledge about system dynamics, which, as argued in the paper, is problematic; alternatively, they apply to average of iterates. An additional work by Liu et al. [2015] considered the gradient TD algorithms GTD(0) and GTD2, which were first introduced in [Sutton et al., 2009b,a]. That work interpreted the algorithms as gradient methods to some saddle-point optimization problem. This enabled them to obtain concentration bounds on altered versions of these algorithms using results from the convex optimization literature. Despite the alternate approach, in similar fashion to the results above, a projection step that keeps the parameter vectors in a convex set is needed there.\nBounds similar in flavor to ours are also given in [Frikha and Menozzi, 2012, Fathi and Frikha, 2013]. However, they apply only to a class of SA methods satisfying strong assumptions, which do not hold for TD(0). In particular, neither the uniformly Lipschitz assumption nor its weakened version, the Lyapunov Stability-Domination criteria, hold for TD(0) when formulated in their iid noise setup.\nTwo additional works [Yu and Bertsekas, 2009, Lazaric et al., 2010] provide sample complexity bounds on the batch LSTD algorithms. However, in the context of finite sample analysis, these belong to a different class of algorithms. The case of online TD learning has proved to be more practical, at the expense of increased analysis difficulty compared to LSTD methods."}, {"heading": "1.2 Our Contribution", "text": "Our work is the first to give a bound on the convergence rate of TD(0) in its original, unaltered form. In fact, it is the first to obtain a concentration bound for an unaltered online TD algorithm of any type. Indeed, as discussed earlier, existing convergence rates apply only to online TD algorithms with alterations such as projections and step-sizes dependent on unknown problem parameters; alternatively, they only apply to average of iterates. The key ingredients in our approach to obviate these alterations are i) show that the n-th iterate at worst is only O(n) away from the solution \u03b8\u2217; and ii) based on that, show that after some additional steps all subsequent iterates are -close to the solution w.h.p. We believe this approach is not limited to TD(0) alone.\nMoreover, we provide the first expectation decay rate of the actual TD(0) iterates. It applies for a general family of step-sizes that is not restricted to square-summable sequences, as is assumed in most works."}, {"heading": "2 Problem Setup", "text": "We consider the problem of policy evaluation for a Markov Decision Process (MDP). A MDP is defined by the 5-tuple (S,A , P,R, \u03b3) [Sutton, 1988], where S is the set of states, A is the set of\nactions, P = P (s\u2032|s, a) is the transition kernel,R(s, a, s\u2032) is the reward function, and \u03b3 \u2208 (0, 1) is the discount factor. In each time-step, the process is in some state s \u2208 S, an action a \u2208 A is taken, the system transitions to a next state s\u2032 \u2208 S according to the transition kernel P , and an immediate reward r is received according toR(s, a, s\u2032). Let policy \u03c0 : S \u2192 A be a stationary mapping from states to actions. Assuming the associated Markov chain is ergodic and uni-chain, let \u03bd be the induced stationary distribution. Moreover, let V \u03c0(s) be the value function at state s w.r.t. \u03c0 defined via the Bellman equation V \u03c0(s) = E\u03bd [r + \u03b3V \u03c0(s\u2032)]. In our policy evaluation setting, the goal is to estimate V \u03c0(s) using linear regression, i.e., V \u03c0(s) \u2248 \u03b8>\u03c6(s), where \u03c6(s) \u2208 Rd is a feature vector at state s, and \u03b8 \u2208 Rd is a weight vector. For brevity, we omit the notation \u03c0 and denote \u03c6(s), \u03c6(s\u2032) by \u03c6, \u03c6\u2032. Let {(\u03c6n, \u03c6\u2032n, rn)}n be iid samples of (\u03c6, \u03c6\u2032, r). Then the TD(0) algorithm has the update rule\n\u03b8n+1 = \u03b8n + \u03b1n[rn + \u03b3\u03c6 \u2032> n \u03b8n \u2212 \u03c6>n \u03b8n]\u03c6n, (1)\nwhere \u03b1n is the step-size. For analysis, we can rewrite the above as\n\u03b8n+1 = \u03b8n + \u03b1n[h(\u03b8n) +Mn+1] , (2)\nwhere h(\u03b8) = b\u2212A\u03b8 and Mn+1 = ( rn + \u03b3\u03c6 \u2032> n \u03b8n \u2212 \u03c6>n \u03b8n ) \u03c6n \u2212 [b\u2212A\u03b8n] , (3)\nwith A = E\u03bd [\u03c6(\u03c6\u2212 \u03b3\u03c6\u2032)>] and b = E\u03bd [r\u03c6]. It is known that A is positive definite [Bertsekas, 2012] and that (2) converges to \u03b8\u2217 := A\u22121b [Borkar, 2008]. Note that\nh(\u03b8) = \u2212A[\u03b8 \u2212 \u03b8\u2217] . (4)\nWe make the following assumption:\nA1 . All rewards r(s, a, s\u2032) and feature vectors \u03c6(s) are uniformly bounded, i.e., \u2016\u03c6(s)\u2016 \u2264 1/2, \u2200s \u2208 S, and |r(s, a, s\u2032)| \u2264 1, \u2200s, s\u2032 \u2208 S, a \u2208 A ."}, {"heading": "3 Main Result", "text": "Our main result is the following. The O\u0303 notation hides problem dependent constants and polylogarithmic terms.\nTheorem 1 (TD(0) Concentration Bound). Let \u03bb \u2208 (0,mini\u2208[d]{real(\u03bbi(A))}), where \u03bbi(A) is the i-th eigenvalue of A. Let \u03b1n = (n+ 1)\u22121. Then for > 0 and \u03b4 \u2208 (0, 1), there exists a function\nN( , \u03b4) = O\u0303 ( max {[ 1 ]1+ 1\u03bb [ ln 1\n\u03b4\n]1+ 1\u03bb , [ 1 ]2 [ ln 1\n\u03b4 ]3}) such that\nPr {\u2016\u03b8n \u2212 \u03b8\u2217\u2016 \u2264 \u2200n \u2265 N( , \u03b4)} \u2265 1\u2212 \u03b4 .\nThe proof of Theorem 1 also gives the following result; instead of fixed , we have a decreasing rate.\nTheorem 2. Let \u03bb, \u03b1n be as in Theorem 1. Fix \u03b4 \u2208 (0, 1). Then there exists some function N0(\u03b4) = O(ln(1/\u03b4)) such that for all n \u2265 N0(\u03b4),\nPr { \u2016\u03b8n \u2212 \u03b8\u2217\u2016 = O\u0303 ( n\u2212min{1/2,\u03bb/(\u03bb+1)} )} \u2265 1\u2212 \u03b4.\nRemark 1. Theorem 1, Korda and Prashanth [2015] requires the TD(0) step-sizes to satisfy: \u03b1n = fn(\u03bb) for some function fn, where \u03bb is as above. Further, Theorem 2 there applies to average of iterates. Also, concentration bounds in these results require projecting the iterates to some bounded set (personal communication). In contrast, our result applies directly to the original TD(0) algorithm and we obviate all the above modifications. However, our result is weaker than Theorem 1 there when \u03bb < 1.\nOur other main result is a bound on the expected decay rate of the TD(0) iterates.\nTheorem 3 (Expected Decay Rate for TD(0)). Fix \u03c3 \u2208 (0, 1) and let \u03b1n = (n + 1)\u2212\u03c3. Fix \u03bb \u2208 (0, \u03bbmin(A+A>)). Then, for n \u2265 0,\nE\u2016\u03b8n+1 \u2212 \u03b8\u2217\u20162 \u2264 K1e\u2212(\u03bb/2)(n+2) 1\u2212\u03c3 + K2\n(n+ 1)\u03c3 ,\nwhere K1,K2 \u2265 0 are some constants that depend on both \u03bb and \u03c3; see Theorem 12 for the exact expression. Remark 2. The exponentially decaying term in Theorem 3 corresponds to the convergence rate of the noiseless TD(0) algorithm, while the inverse polynomial term appears due to the martingale noise Mn. The inverse impact of \u03c3 on these two terms introduces the following tradeoff:\n1. For \u03c3 close to 0, the first term converges faster and corresponds to slowly decaying stepsizes, which, in turn, speed up the noiseless TD(0) convergence.\n2. For \u03c3 close to 1, the second term decays quickly and corresponds to small step-sizes that better mitigate the effect of martingale noise; this originates in the term \u03b1nMn+1.\nWhile this insight is folklore, a formal estimate of the tradeoff, to the best of our knowledge, has been obtained here for the first time. Remark 3. The expectation bound in Theorem 1, Korda and Prashanth [2015] again requires the stepsize sequence be scaled as in Remark 1. Theorem 2 there obviates this, but it applies to average of iterates. In contrast, our expectation bound applies directly to the TD(0) iterates and does not need any scaling of the above kind. Moreover, our result applies to a broader family of stepsizes; see Remark 4. Our expectation bound when compared to that of Theorem 2, Korda and Prashanth [2015] is of the same order (even though theirs is for average of iterates). Remark 4. In Theorem 3, unlike most works, \u2211 n\u22650 \u03b1 2 n need not be finite. Thus this result is applicable for a wider class of stepsizes; e.g., 1/n\u03ba with \u03ba \u2208 (0, 1/2]. In [Borkar, 2008], on which much of the existing RL literature is based on, the square summability assumption is due to the Gronwall inequality. In contrast, in our work, we use the Variation of Parameters Formula [Lakshmikantham and Deo, 1998] for comparing the SA trajectory to appropriate trajectories of the limiting ODE; it is a stronger tool than Gronwall inequality. Remark 5. In the proof of Theorem 3, one can see that the requirement on the martingale noise is of the form E[||Mn+1||2|Fn] \u2264 C(1 + ||\u03b8n||2) where C is a constant, in correspondence to Remark 6. It is in fact a weaker requirement than the one obtained for TD(0), as is given in Lemma 4."}, {"heading": "4 Proof of Theorem 1", "text": "This section outlines the analysis conducted for Theorem 1. All proofs are given in Appendix B."}, {"heading": "4.1 Outline of Approach", "text": "We compare the TD(0) iterates {\u03b8n} with suitable solutions of its limiting ODE using the Variation of Parameters (VoP) method [Lakshmikantham and Deo, 1998]. As the solutions of the ODE are continuous functions of time, we first define a linear interpolation {\u03b8\u0304(t)} of {\u03b8n}. Let t0 = 0. For n \u2265 0, let tn+1 = tn + \u03b1n and let\n\u03b8\u0304(\u03c4)= { \u03b8n if \u03c4 = tn , \u03b8n +\n\u03c4\u2212tn \u03b1n\n[\u03b8n+1 \u2212 \u03b8n] if \u03c4 \u2208 (tn, tn+1) . (5)\nThe limiting ODE for (2) is\n\u03b8\u0307(t) = h(\u03b8(t)) = b\u2212A\u03b8(t) = \u2212A(\u03b8(t)\u2212 \u03b8\u2217) . (6)\nLet \u03b8(t, s, u0), t \u2265 s, denote the solution to the above ODE starting at u0 at time t = s. When the starting point and time are unimportant, we will denote this solution by \u03b8(t) .\nInitially, \u03b8\u0304(t) could stray away from \u03b8\u2217 when the step-sizes may not be small enough to tame the noise. However, we show that \u2016\u03b8\u0304(tn)\u2212 \u03b8\u2217\u2016 = O(n), i.e., \u03b8n does not stray away from \u03b8\u2217 too fast. Later, we show that we can fix some n0 so that first the TD(0) iterates for n \u2265 n0 stay within a O(n0) distance from \u03b8\u2217; then after for some additional time when the stepsizes decay enough the TD(0) iterates start behaving almost like a noiseless version. These three different behaviours are summarized in Table 1 and illustrated in Figure 1."}, {"heading": "4.2 Preliminaries", "text": "We establish some preliminary results here that will be used throughout this section. Let s \u2208 R, and u0 \u2208 Rd. Using results from Chapter 6, [Hirsch et al., 2012], it follows that the solution \u03b8(t, s, u0), t \u2265 s, of (6) satisfies the relation\n\u03b8(t, s, u0) = \u03b8 \u2217 + e\u2212A(t\u2212s)(u0 \u2212 \u03b8\u2217) . (7)\nAs the matrix A is positive definite, for \u03b8(t) \u2261 \u03b8(t, s, u0), d\ndt \u2016\u03b8(t)\u2212 \u03b8\u2217\u20162 = \u22122(\u03b8(t)\u2212 \u03b8\u2217)>A(\u03b8(t)\u2212 \u03b8\u2217) < 0 .\nHence \u2016\u03b8(t\u2032, s, u0)\u2212 \u03b8\u2217\u2016 \u2264 \u2016\u03b8(t, s, u0)\u2212 \u03b8\u2217\u2016 , (8) for all t\u2032 \u2265 t \u2265 s and u0. Let \u03bb be as in Theorem 1. From Corollary 3.6, p71, [Teschl, 2012], \u2203K\u03bb \u2265 1 so that \u2200t \u2265 s\n\u2016e\u2212A(t\u2212s)\u2016 \u2264 K\u03bb e\u2212\u03bb(t\u2212s) . (9) Separately, as tn+1 \u2212 tk+1 = \u2211n `=k+1 \u03b1` = \u2211n `=k+1 1 `+1 ,\n(k + 1)\u03bb\n(n+ 1)\u03bb \u2264 e\u2212\u03bb(tn+1\u2212tk+1) \u2264 (k + 2)\n\u03bb\n(n+ 2)\u03bb . (10)\nThe following result gives a bound on the martingale difference noise as a function of the iterates. We emphasize that this bound is significant in our work and that this strong behavior of TD(0) is usually overlooked in existing literature.\nLemma 4 (Martingale Noise Behavior). For all n \u2265 0,\n\u2016Mn+1\u2016 \u2264 Km [1 + \u2016\u03b8n \u2212 \u03b8\u2217\u2016] ,\nwhere\nKm := 1\n4 max\n{ 2 + [1 + \u03b3]\u2016A\u22121\u2016\u2016b\u2016, 1 + \u03b3 + 4\u2016A\u2016 } .\nRemark 6. The noise behavior usually used in the literature (e.g., [Sutton et al., 2009a]) is\nE[||Mn+1||2|Fn] \u2264 C(1 + ||\u03b8n||2) ,\nfor some constant C \u2265 0. The result on the noise behavior in Lemma 4 is in fact stronger than that. For easier comparison, we also provide following result (the proof technique is similar to that in Lemma 4). For all n \u2265 0,\n\u2016|Mn+1||2 \u2264 3[1 + \u03b3 + max(\u2016A\u2016, \u2016b\u2016)]2(1 + ||\u03b8n||2).\nThe remaining parts of the analysis rely on the comparison of the discrete TD(0) trajectory {\u03b8n} to the continuous solution \u03b8(t) of the limiting ODE. For this, we first switch from directly treating {\u03b8n} to treating their linear interpolation {\u03b8\u0304(t)} as defined in (5). The key idea then is to use the VoP method [Lakshmikantham and Deo, 1998] and express \u03b8\u0304(t) as a perturbation of \u03b8(t) due to two factors: the discretization error and the martingale difference noise. This is discussed further in Lemma 13 in Appendix A.\nFor the interval [t`1 , t`2 ], let E d [`1,`2] := \u2211`2\u22121 k=`1 \u222b tk+1 tk\ne\u2212A(tn+1\u2212\u03c4)A[\u03b8\u0304(\u03c4)\u2212 \u03b8k]d\u03c4 , and Em[`1,`2] :=\u2211`2\u22121 k=`1 [\u222b tk+1 tk e\u2212A(tn+1\u2212\u03c4)d\u03c4 ] Mk+1 . Corollary 5 below shows that \u03b8\u0304(t`2) \u2212 \u03b8\u2217 differs from \u03b8(t`2 , t`1 , \u03b8\u0304(t`1))\u2212\u03b8\u2217 byEd[`1,`2]+E m [`1,`2]\n.We highlight that both the paths, \u03b8\u0304(t) and \u03b8(t, t`1 , \u03b8\u0304(t`1)), t \u2265 t`1 , start at the same point \u03b8\u0304(t`1) at time t`1 . As mentioned above, Ed[`1,`2] and E m [`1,`2]\nrespectively denote the cumulative discretization error and martingale difference noise over the interval [t`1 , t`2 ].\nCorollary 5 (Comparison of SA Trajectory and ODE Solution). For every `2 \u2265 `1,\n\u03b8\u0304(t`2)\u2212 \u03b8\u2217 = \u03b8(t`2 , t`1 , \u03b8\u0304(t`1))\u2212 \u03b8\u2217 + Ed[`1,`2] + E m [`1,`2] .\nWe shall use this result later in Lemmas 14 and 15, in Appendix B."}, {"heading": "4.3 Part I \u2013 Initial Possible Divergence", "text": "In this section we show that the TD(0) iterates lie in a O(n)-ball around \u03b8\u2217. We emphasize that this is one of the results that enables us to accomplish more than existing literature. Previously, the distance of the initial iterates from \u03b8\u2217 was bounded using various assumptions, often justified with an artificial projection step which we are able to avoid.\nLet R0 := 1 + \u2016\u03b80 \u2212 \u03b8\u2217\u2016. Lemma 6 (Worst-case Iterates Bound). For n \u2265 0,\n\u2016\u03b8n \u2212 \u03b8\u2217\u2016 \u2264 Rwc(n) ,\nwhere Rwc(n) := [n+ 1]C\u2217R0\nand C\u2217 := 1 + \u2016\u03b8\u2217\u2016 \u2264 1 + \u2016A\u22121\u2016 \u2016b\u2016\nNext, since \u2016Mn+1\u2016 is linearly bounded by \u2016\u03b8n \u2212 \u03b8\u2217\u2016, the following result shows that \u2016Mn+1\u2016 is O(n) as well. It follows from Lemmas 4 and 6.\nCorollary 7 (Worst-case Noise Bound). For n \u2265 0,\n\u2016Mn+1\u2016 \u2264 Km [1 + C\u2217R0][n+ 1] ."}, {"heading": "4.4 Part II \u2013 Rate of Convergence", "text": "Our formal aim here is to obtain an estimate on the probability of the event\nE(n0, n1) := {\u2016\u03b8n \u2212 \u03b8\u2217\u2016 \u2264 \u2200n > n0 + n1}\nfor sufficiently large n0, n1 \u2265 1; how large they ought to be will be elaborated later. We do this by comparing the TD(0) trajectory \u03b8n+1 with the ODE solution \u03b8(tn+1, tn0 , \u03b8\u0304(tn0)) \u2200n \u2265 n0; for that we use Corollary 5 along with Lemma 6. In this section we show that if n0 is sufficiently large, or equivalently the stepsizes {\u03b1n}n\u2265n0 are small enough, then after a finite number of iterations from n0, the TD(0) iterates are \u2212close to \u03b8\u2217 w.h.p. This holds as the small stepsize and sufficiently long waiting time ensure that the ODE solution \u03b8(tn+1, tn0 , \u03b8\u0304(tn0)) is \u2212close to \u03b8\u2217, the discretization error Ed[n0,n+1] is small and martingale difference noise E m [n0,n+1] is small w.h.p.\nLet \u03b4 \u2208 (0, 1), and let be such that > 0. Also, for an event E , let Ec denote its complement and let {E1, E2} denote E1 \u2229 E2. We begin with a careful decomposition of Ec(n0, n1), the complement of the event of interest. The idea is to break it down into an incremental union of events. Each such event has an inductive structure: good up to iterate n (denoted by Gn0,n below) and the (n+ 1)\u2212th iterate is bad. The good event Gn0,n holds when all the iterates up to n remain in an O(n0) ball around \u03b8\u2217. For n < n0 + n1, the bad event means that \u03b8n+1 is outside the O(n0) ball around \u03b8\u2217, while for n \u2265 n0 + n1, the bad event means that \u03b8n+1 is outside the ball around \u03b8\u2217. Formally, for n1 \u2265 1, define the events\nEmidn0,n1 := n0+n1\u22121\u22c3 n=n0 {Gn0,n, \u2016\u03b8n+1 \u2212 \u03b8\u2217\u2016>2Rwc(n0)} ,\nEaftern0,n1 := \u221e\u22c3\nn=n0+n1\n{Gn0,n, \u2016\u03b8n+1 \u2212 \u03b8\u2217\u2016 > min{ , 2Rwc(n0)}} ,\nand, \u2200n \u2265 n0, let\nGn0,n :=\n{ n\u22c2\nk=n0\n{\u2016\u03b8k \u2212 \u03b8\u2217\u2016\u22642Rwc(n0)} } .\nUsing the above definitions, the decomposition of Ec(n0, n1) is the following relation. Lemma 8 (Decomposition of Event of Interest). For n0, n1 \u2265 1,\nEc(n0, n1) \u2286 Emidn0,n1 \u222a E after n0,n1 .\nFor the following results, define the constants\nCm2 :=\n{ 6KmK\u03bb 2\n\u03bb\u22120.5 \u221a 2\u03bb\u22121 if \u03bb > 0.5\n6KmK\u03bb\u221a 1\u22122\u03bb if \u03bb < 0.5 .\nNext we show that on the \u201cgood\u201d event Gn0,n, the discretization error is small for all sufficiently large n.\nLemma 9 (Part II Discretization Error Bound). For any n \u2265 n0 \u2265 K\u03bb6\u2016A\u2016(\u2016A\u2016+2Km )\u03bb ,\n\u2016Ed[n0,n+1]\u2016 \u2264 1 3 [n0 + 1]C\u2217R0 = 1 3Rwc(n0).\nFurthermore, for n \u2265 nc \u2265 (\n1 + K\u03bb6\u2016A\u2016(\u2016A\u2016+2Km )C\u2217R0\u03bbmin{ ,Rwc(n0)} ) (n0 + 1) it thus also holds on Gn0,n that\n\u2016Ed[nc,n+1]\u2016 \u2264 1 3 min{ , [n0 + 1]C\u2217R0} = 1 3 min{ , Rwc(n0)} .\nThe next result gives a bound on the probability that, on the \u201cgood\u201d event Gn0,n, the martingale difference noise is small when n is large. The bound has two forms for the different values of \u03bb.\nLemma 10 (Part II Martingale Difference Noise Concentration). Let n0 \u2265 1 and R \u2265 0. Let n \u2265 n\u2032 \u2265 n0. For \u03bb > 1/2,\nPr{Gn0,n, \u2016Em[n\u2032,n+1]\u2016 \u2265 R} \u2264 2d 2 exp\n[ \u2212 (n+ 1)R 2\n2d3C2m2R 2 wc(n0)\n] .\nFor \u03bb < 1/2,\nPr{Gn0,n, \u2016Em[n\u2032,n+1]\u2016 \u2265 R} \u2264 2d 2 exp\n[ \u2212 [n \u2032 + 1]1\u22122\u03bb(n+ 1)2\u03bbR2\n2d3C2m2R 2 wc(n0)\n] .\nLemmas 8, 9 and 10 are the key ingredients for proving Theorem 1. The detailed proof is given in Appendix B. However, we now outline the underlying idea.\nFrom Lemma 8, by a union bound,\nPr{Ec(n0, n1)} = Pr{Ec(n0, n1)} \u2264 Pr{Emidn0,n1}+ Pr{E after n0,n1} .\nNext, we use Lemmas 9 and 10 to set n0 and n1 in the following way to bound the terms on the RHS. The behavior of Emidn0,n1 is dictated by n0, while the behavior of E after n0,n1 by n1. We set n0 so that E mid n0,n1\nis less than \u03b4/2 by substituting Rwc(n0)2 in r from Lemma 10, resulting in the condition n0 = O ( ln 1\u03b4 ) . Next, we set r = 3 for bounding E after n0,n1 by \u03b4/2, resulting in n1 = O\u0303 ([ (1/ ) ln (1/\u03b4)\n]max{1+1/\u03bb,2}) for \u03bb > 1/2, and n1 = O\u0303 ([ (1/ ) ln (1/\u03b4) ]1+1/\u03bb) for \u03bb < 1/2."}, {"heading": "5 Proof of Theorem 3", "text": "The expectation bound is due to an inductive argument and an application of a subtle trick from Kamal [2010]. Building on the approach there, our key steps are: identifying a \u201cnice\" Liapunov function V of the TD(0) method\u2019s limiting ODE; and then using conditional expectation suitably to get rid of the linear noise terms in the relation between V (\u03b8n) and V (\u03b8n+1). Induction then leads to the desired result.\nThroughout this section only, {\u03b1n} is a stepsize sequence satisfying \u2211 n\u22650 \u03b1n =\u221e, limn\u2192\u221e \u03b1n = 0 and supn\u22650 \u03b1n \u2264 1. The proofs in this section are provided in Appendix C.\nRecall that all eigenvalues of a symmetric matrix are real. For a symmetric matrix X, let \u03bbmin(X) and \u03bbmax(X) be its minimum and maximum eigenvalues, respectively.\nTheorem 11 (Technical Result: Expectation Bound). Fix \u03bb \u2208 (0, \u03bbmin(A+A>)).\nE\u2016\u03b8n+1 \u2212 \u03b8\u2217\u20162 \u2264 Kp [ e\u2212\u03bb \u2211n k=0 \u03b1k ] E\u2016\u03b80 \u2212 \u03b8\u2217\u20162 + 4K2mKp n\u2211 i=0 [ e\u2212\u03bb \u2211n k=i+1 \u03b1k ] \u03b12i ,\nwhere Kp,Km \u2265 0 are constants as defined in Lemmas 16 and 4, respectively.\nThe next result provides closed form estimates of the expectation bound given in Theorem 11 for the specific stepsize sequence \u03b1n = 1/(n+ 1)\u03c3, with \u03c3 \u2208 (0, 1). Theorem 12. Fix \u03c3 \u2208 (0, 1) and let \u03b1n = 1/(n+ 1)\u03c3. Then\nE\u2016\u03b8n+1 \u2212 \u03b8\u2217\u20162 \u2264 [ Kpe \u03bbE\u2016\u03b80 \u2212 \u03b8\u2217\u20162e\u2212(\u03bb/2)(n+2) 1\u2212\u03c3 + 8K2mKpKbe \u03bb\n\u03bb\n] e\u2212(\u03bb/2)(n+2) 1\u2212\u03c3\n+ 8K2mKpe \u03bb/2\n\u03bb\n1\n(n+ 1)\u03c3 ,\nwhere Kb = e[(\u03bb/2) \u2211i0 k=0 \u03b1k] with i0 denoting a number larger than (2\u03c3/\u03bb)1/(1\u2212\u03c3)."}, {"heading": "6 Discussion", "text": "In this work we obtained the first concentration bound for an unaltered version of the celebrated TD(0); it is, in fact, the first to show the convergence rate of an unaltered online TD algorithm of any type. Our proof technique is general and can be used to provide convergence rates for additional TD methods. Specifically, using the non-linear analysis presented in [Thoppe and Borkar, 2015], we believe it can be extended to a broader family of function approximators, e.g., neural networks. Furthermore, future work can extend to a more general family learning rates, including the commonly used adaptive ones. Building upon Remark 5, we believe that a stronger expectation bound may hold for TD(0). This may enable obtaining tighter concentration bounds for TD(0) even with generic stepsizes."}, {"heading": "B Supplementary Material for Proof of Theorem 1", "text": "Proof of Lemma 4. We have\n\u2016Mn+1\u2016 = \u2016rn\u03c6n + (\u03b3\u03c6\u2032n \u2212 \u03c6n)>\u03b8n\u03c6n \u2212 [b\u2212A\u03b8n]\u2016 = \u2016rn\u03c6n + (\u03b3\u03c6\u2032n \u2212 \u03c6n)>(\u03b8n \u2212 \u03b8\u2217)\u03c6n\n+(\u03b3\u03c6\u2032n \u2212 \u03c6n)>\u03b8\u2217\u03c6n +A(\u03b8n \u2212 \u03b8\u2217)\u2016\n\u2264 1 2 + [1 + \u03b3] 4 \u2016A\u22121\u2016 \u2016b\u2016+ [1 + \u03b3 + 4\u2016A\u2016] 4 \u2016\u03b8n \u2212 \u03b8\u2217\u2016,\nwhere the first relation follows from (3), the second holds as b = A\u03b8\u2217, while the third follows since A1 holds and \u03b8\u2217 = A\u22121b. The desired result is now easy to see.\nProof of Corollary 5. The result follows by using Lemma 13 from Appendix A, with i = `1, t = t`2 , and subtracting \u03b8\u2217 from both sides.\nProof of Lemma 6. The proof is by induction. The claim holds trivially for n = 0. Assume the claim for n. Then from (1),\n\u2016\u03b8n+1 \u2212 \u03b8\u2217\u2016 \u2264 \u2016\u03b8n \u2212 \u03b8\u2217\u2016+ \u03b1n\u2016[\u03b3\u03c6\u2032n \u2212 \u03c6n]>\u03b8\u2217\u03c6n\u2016 + \u03b1n\u2016rn\u03c6n\u2016+ \u03b1n\u2016[\u03b3\u03c6\u2032n \u2212 \u03c6n]>[\u03b8n \u2212 \u03b8\u2217]\u03c6n\u2016 .\nApplying the Cauchy-Schwarz inequality, and usingA1 and the fact that \u03b3 \u2264 1, we have\n\u2016\u03b8n+1 \u2212 \u03b8\u2217\u2016 \u2264 \u2016\u03b8n \u2212 \u03b8\u2217\u2016+ \u03b1n 2 C\u2217 + \u03b1n 2 \u2016\u03b8n \u2212 \u03b8\u2217\u2016.\nNow as 1 \u2264 R0, we have \u2016\u03b8n+1 \u2212 \u03b8\u2217\u2016 \u2264 [ 1 +\n\u03b1n 2\n] \u2016\u03b8n \u2212 \u03b8\u2217\u2016+\n\u03b1n 2 C\u2217R0.\nUsing the induction hypothesis and the stepsize choice, the claim for n+ 1 is now easy to see. The desired result thus follows.\nProof of Lemma 8. For any two events E1 and E2, note that E1 = [Ec2 \u2229 E1] \u222a [E2 \u2229 E1] \u2286 Ec2 \u222a [E2 \u2229 E1] . (13)\nSeparately, for any sequence of events {Ek}, observe that m\u22c3 k=1 Ek = [ m\u22c3 k=1 ([ k\u22121\u22c3 i=1 Ei ]c \u2229 Ek )] , (14)\nwhere \u22c3i2 i=i1 Ei = \u2205 whenever i1 > i2. Using (13), we have\nEc(n0, n1) \u2286 Gcn0,n0+n1 \u222a [Gn0,n0+n1 \u2229 E c(n0, n1)] . (15)\nFrom Lemma 6, {\u2016\u03b8n0 \u2212 \u03b8\u2217\u2016 \u2264 Rwc(n0)} is a certain event. Hence it follows from (14) that\nGcn0,n0+n1 = E mid n0,n1 . (16)\nSimilarly, from (14) and the fact that \u2264 R0,\nGn0,n0+n1 \u2229 Ec(n0, n1) \u2286 Eaftern0,n1 . (17) Substituting (16) and (17) in (15) gives\nEc(n0, n1) \u2286 Emidn0,n1 \u222a E after n0,n1 .\nThe claimed result follows.\nProof of Lemma 9. For n \u2265 n\u2032 \u2265 n0 \u2265 0, by its definition and the triangle inequality,\n\u2016Ed[n\u2032,n+1]\u2016\u2264 n\u2211\nk=n\u2032\n\u222b tk+1 tk \u2016e\u2212A(tn+1\u2212\u03c4)\u2016\u2016A\u2016\u2016\u03b8\u0304(\u03c4)\u2212 \u03b8k\u2016d\u03c4.\nFix a k \u2208 {n\u2032, . . . , n} and \u03c4 \u2208 [tk, tk+1). Then using (5), (2), (4), and the fact that (\u03c4 \u2212 tk) \u2264 \u03b1k, we have \u2016\u03b8\u0304(\u03c4)\u2212 \u03b8k\u2016 \u2264 \u03b1k[\u2016A\u2016\u2016\u03b8k \u2212 \u03b8\u2217\u2016+ \u2016Mk+1\u2016] . Combining this with Lemma 4, we get\n\u2016\u03b8\u0304(\u03c4)\u2212 \u03b8k\u2016 \u2264 \u03b1k[Km + (\u2016A\u2016+Km )\u2016\u03b8k \u2212 \u03b8\u2217\u2016] . As the event Gn0,n holds, and since \u03b1k \u2264 \u03b1n\u2032 and Rwc(n0) \u2265 1, we have\n\u2016\u03b8\u0304(\u03c4)\u2212 \u03b8k\u2016 \u2264 2[\u2016A\u2016+ 2Km ]\u03b1n\u2032 [n0 + 1]C\u2217R0 . From the above discussion, (9), the step-size choice, and the facts that\nn\u2211 k=n\u2032 \u222b tk+1 tk e\u2212\u03bb(tn+1\u2212\u03c4)d\u03c4 = \u222b tn+1 tn\u2032 e\u2212\u03bb(tn+1\u2212\u03c4)d\u03c4 \u2264 1 \u03bb ,\nand \u03b1k \u2264 \u03b1n\u2032 \u2264 \u03b1n0 , we get\n\u2016Ed[n\u2032,n+1]\u2016 \u2264 K\u03bb2\u2016A\u2016(\u2016A\u2016+2Km )(n0+1)C\u2217R0 \u03bb(n\u2032+1) .\nThe desired results now follow by substituting n\u2032 first with n0 and then with nc. Proof of Lemma 10. Let Qk,n = \u222b tk+1 tk e\u2212A(tn+1\u2212\u03c4)d\u03c4. Then, for any n0 \u2264 n\u2032 \u2264 n,\nEm[n\u2032,n+1] = n\u2211 k=n\u2032 Qk,nMk+1 ,\na sum of martingale differences. When the event Gn0,n holds, it follows that the indicator 1Gn0,k = 1 \u2200k \u2208 {n0, . . . , n\u2032, . . . n}. Hence, for any R \u2265 0,\nPr{Gn0,n, \u2016Em[n\u2032,n+1]\u2016 \u2265 R} = Pr { Gn0,n, \u2225\u2225\u2225\u2225\u2225 n\u2211\nk=n\u2032\nQk,nMk+11Gn0,k \u2225\u2225\u2225\u2225\u2225 \u2265 R }\n\u2264 Pr {\u2225\u2225\u2225\u2225\u2225 n\u2211\nk=n\u2032\nQk,nMk+11Gn0,k \u2225\u2225\u2225\u2225\u2225 \u2265 R } .\nLet Qijk,n be the i, j\u2212th entry of the matrix Qk,n and let M j k+1 be the j\u2212th coordinate of Mk+1. Then using the union bound twice on the above relation, we have\nPr{Gn0,n, \u2016Em[n\u2032,n+1]\u2016 \u2265 R} \u2264 d\u2211 i=1 d\u2211 j=1 Pr {\u2223\u2223\u2223\u2223\u2223 n\u2211 k=n\u2032 Qijk,nM j k+11Gn0,k \u2223\u2223\u2223\u2223\u2223 \u2265 Rd\u221ad } .\nAs |Qijk,nM j k+1|1Gn0,k \u2264 \u2016Qk,n\u2016\u2016Mk+1\u20161Gn0,k =: \u03b2k,n, Azuma-Hoeffding inequality now gives\nPr{Gn0,n, \u2016Em[n\u2032,n+1]\u2016 \u2265 R} \u2264 2d 2 exp\n[ \u2212 R 2\n2d3 \u2211n k=n\u2032 \u03b2 2 k,n\n] . (18)\nOn the event Gn0,k, \u2016\u03b8k \u2212 \u03b8\u2217\u2016 \u2264 2Rwc(n0) by definition. Hence from Lemma 4, we have\n\u2016Mk+1\u20161Gk \u2264 3KmRwc(n0) . (19)\nAlso from (9), \u2016Qk,n\u2016 \u2264 K\u03bb e\u2212\u03bb(tn+1\u2212tk+1)\u03b1k. Combining the two inequalities, and using (10) along with the fact that 1/(k + 1) \u2264 2/(k + 2), we get\n\u03b2k,n \u2264 3KmK\u03bbRwc(n0)e\u2212\u03bb(tn+1\u2212tk+1)\u03b1k\n\u2264 6KmK\u03bbRwc(n0) (k + 2)\u03bb\u22121\n(n+ 2)\u03bb .\nConsider the case \u03bb > 1/2. By treating the sum as a right Riemann sum, we have n\u2211\nk=n\u2032\n(k + 2)2\u03bb\u22122 \u2264 (n+ 3)2\u03bb\u22121/(2\u03bb\u2212 1) .\nAs (n+ 3) \u2264 2(n+ 2) and (n+ 2) \u2265 (n+ 1), we have n\u2211\nk=n\u2032\n\u03b22k,n \u2264 C2m2 R2wc(n0)\nn+ 1 .\nNow consider the case \u03bb < 1/2. Again treating the sum as a right Riemann sum, we have n\u2211\nk=n\u2032\n(k + 2)2\u03bb\u22122 \u2264 1 (1\u2212 2\u03bb)[n\u2032 + 1]1\u22122\u03bb .\nAs (n+ 2) \u2265 (n+ 1), it follows that n\u2211\nk=n\u2032\n\u03b22k,n \u2264 C2m2 R2wc(n0)\n[n\u2032 + 1]1\u22122\u03bb(n+ 1)2\u03bb .\nSubstituting \u2211n k=n0 \u03b22k,n bounds in (18), the desired result is easy to see.\nB.1 Conditional Results on the Bad Events\nOn the first \u201cbad\u201d event Emidn0,n1 , the TD(0) iterate \u03b8n for at least one n between n0 + 1 and n0 + n1 leaves the 2Rwc(n0) ball around \u03b8\u2217. The next lemma shows that this event has low probability.\nLemma 14 (Bound on Probability of Emidn0,n1 ). Let n0 \u2265 max { K\u03bb6\u2016A\u2016(\u2016A\u2016+2Km ) \u03bb , 2 1 \u03bb } and n1 \u2265 1.\n\u2022 If \u03bb > 1/2, then\nPr{Emidn0,n1} \u2264 16d 5C2m2 exp\n[ \u2212 n0\n8d3C2m2\n] .\n\u2022 If \u03bb < 1/2, then\nPr{Emidn0,n1} \u2264 2d 2\n[ 8d3C2m2\n\u03bb\n] 1 2\u03bb exp[\u2212 n0\n64d3C2m2 ]\n(n0 + 1) 1\u22122\u03bb 2\u03bb\n.\nProof. From Corollary 5, we have\n\u2016\u03b8n+1 \u2212 \u03b8\u2217\u2016 \u2264 \u2016\u03b8(tn+1, tn0 , \u03b8n0)\u2212 \u03b8\u2217\u2016+ \u2016Ed[n0,n+1]\u2016+ \u2016E m [n0,n+1] \u2016 .\nSuppose the event Gn0,n holds. Then from (8),\n\u2016\u03b8(tn+1, tn0 , \u03b8n0)\u2212 \u03b8\u2217\u2016 \u2264 \u2016\u03b8n0 \u2212 \u03b8\u2217\u2016 \u2264 Rwc(n0) .\nAlso, as n0 \u2265 K\u03bb6\u2016A\u2016(\u2016A\u2016+2Km )\u03bb , by Lemma 9, \u2016E d [n0,n+1]\n\u2016 \u2264 Rwc(n0)/3. From all of the above, we have\n{Gn0,n, \u2016\u03b8n+1 \u2212 \u03b8\u2217\u2016 > 2Rwc(n0)} \u2286 {Gn0,n, \u2016Em[n0,n+1]\u2016 > Rwc(n0)/2} .\nFrom this, we get\nEmidn0,n1 \u2286 n0+n1\u22121\u22c3 n=n0 { Gn0,n, \u2016Em[n0,n+1]\u2016 > Rwc(n0) 2 } \u2286 \u221e\u22c3\nn=n0\n{ Gn0,n, \u2016Em[n0,n+1]\u2016 > Rwc(n0) 2 } .\nConsequently,\nPr{Emidn0,n1} \u2264 \u221e\u2211\nn=n0\nPr { Gn0,n, \u2016Em[n0,n+1]\u2016> Rwc(n0) 2 } . (20)\nConsider the case \u03bb > 1/2. Lemma 10 shows that\nPr { Gn0,n, \u2016Em[n0,n+1]\u2016 > Rwc(n0) 2 } \u2264 2d2 exp [ \u2212 n+ 1\n8d3C2m2\n] .\nSubstituting this in (20) and treating the resulting expression as a right Riemann sum, the desired result is easy to see.\nNow consider the case \u03bb < 1/2. From Lemma 10, we get\nPr { Gn0,n, \u2016Em[n0,n+1]\u2016 > Rwc(n0) 2 } \u2264 2d2 exp [ \u2212 (n0 + 1) 1\u22122\u03bb(n+ 1)2\u03bb\n8d3C2m2\n] .\nLet `n0 := (n0 + 1) 1\u22122\u03bb/8d3C2m2. Observe that \u221e\u2211\nn=n0\nexp[\u2212`n0(n+ 1)2\u03bb]\n\u2264 \u221e\u2211\ni=b(n0+1)2\u03bbc\ne\u2212i`n0 |{n : b(n+ 1)2\u03bbc = i}|\n\u2264 1 2\u03bb \u221e\u2211 i=b(n0+1)2\u03bbc e\u2212i`n0 (i+ 1) 1\u22122\u03bb 2\u03bb (21)\n\u2264 1 2\u03bb \u221e\u2211 i=b(n0+n1)2\u03bbc e\u2212i`n0/2e\u2212i`n0/2 (i+ 1) 1\u22122\u03bb 2\u03bb\n\u2264 1 2\u03bb [ (1\u2212 2\u03bb) `n0\u03bb ] 1\u22122\u03bb 2\u03bb e 1 2 [`n0\u2212 1\u22122\u03bb \u03bb ] \u221e\u2211 i=b(n0+1)2\u03bbc e\u2212i`n0/2 (22)\n\u2264 1 `n0\u03bb [ (1\u2212 2\u03bb) `n0\u03bb ] 1\u22122\u03bb 2\u03bb e 1 2 [`n0\u2212 1\u22122\u03bb \u03bb ]e\u2212 `n0 n0 2\u03bb 4 (23)\n\u2264 [\n1\u2212 2\u03bb e\n] 1\u22122\u03bb 2\u03bb [\n8d3C2m2 \u03bb\n] 1 2\u03bb exp[\u2212 n0\n64d3C2m2 ]\n(n0 + 1) 1\u22122\u03bb 2\u03bb\n(24)\n\u2264 [\n8d3C2m2 \u03bb\n] 1 2\u03bb exp[\u2212 n0\n64d3C2m2 ]\n(n0 + 1) 1\u22122\u03bb 2\u03bb\n. (25)\nThe relation (21) follows, as by calculus,\n|{n : b(n+ 1)2\u03bbc = i}| \u2264 1 2\u03bb (i+ 1) 1\u22122\u03bb 2\u03bb ,\n(22) holds since, again by calculus,\nmax i\u22650\ne\u2212i`n0/2(i+ 1) 1\u22122\u03bb 2\u03bb \u2264 [ (1\u2212 2\u03bb) `n0\u03bb ] 1\u22122\u03bb 2\u03bb e 1 2 [`n0\u2212 1\u22122\u03bb \u03bb ] ,\n(23) follows by treating the sum as a right Riemann sum, (24) follows by substituting the value of `n0 and using the fact that n 2\u03bb 0 \u2265 4 and (25) holds since 1\u2212 2\u03bb \u2264 1. Substituting (25) in (20), the desired result follows.\nOn the second \u201cbad\u201d event Eaftern0,n1 , the TD(0) iterate \u03b8n for at least one n > n0 + n1 lies outside the min{ , 2Rwc(n0)} radius ball around \u03b8\u2217. The next result shows that this event also has low probability.\nLemma 15 (Bound on Probability of Eaftern0,n1 ). Let n0 \u2265 max { K\u03bb6\u2016A\u2016(\u2016A\u2016+2Km ) \u03bb , 2 1 \u03bb } and\nnc \u2265 (\n1 + K\u03bb6\u2016A\u2016(\u2016A\u2016+2Km )\u03bbmin{ ,Rwc(n0)}\n) Rwc(n0),\nLet n1 \u2261 n1( , nc, n0) \u2265 (nc + 1) [ 6K\u03bb Rwc(n0) ]1/\u03bb \u2212 n0.\nIf \u03bb > 1/2, then\nPr{Eaftern0,n1} \u2264 36d 5C2m2\n[ Rwc(n0) ]2 exp \u2212 (6K\u03bb )1/\u03bb 18d3C2m2 (nc + 1) [ Rwc(n0) ]2\u2212 1\u03bb . If \u03bb < 1/2, then\nPr{Eaftern0,n1} \u2264 2d 2\n[ 18d3C2m2[Rwc(n0)] 2\n2\u03bb\n] 1 2\u03bb\nexp [ \u2212 K 2 \u03bb\n4d3C2m2 (nc + 1)\n] .\nProof. Assume the event Gn0,n holds for some n \u2265 nc. Then\n\u2016\u03b8nc \u2212 \u03b8\u2217\u2016 \u2264 2Rwc(n0).\nHence from (7) and (9), for t \u2265 tnc , we have\n\u2016\u03b8(t, tnc , \u03b8nc)\u2212 \u03b8\u2217\u2016 \u2264 K\u03bb e\u2212\u03bb(t\u2212tnc )2Rwc(n0) . (26)\nNow as n1 \u2265 (nc + 1) [ 6K\u03bb Rwc(n0) ]1/\u03bb \u2212 n0, it follows that \u2200n \u2265 n0 + n1,\n\u2016\u03b8(tn+1, tnc , \u03b8nc)\u2212 \u03b8\u2217\u2016 \u2264\n3 . Also, as nc \u2265 (\n1 + K\u03bb6\u2016A\u2016(\u2016A\u2016+2Km )C\u2217R0\u03bbmin{ ,Rwc(n0)} ) (n0 + 1), from Lemma 9, we have \u2016Ed[nc,n+1]\u2016 \u2264 /3\nfor all n \u2265 nc. Combining these with Corollary 5, it follows that \u2200n \u2265 n0 + n1,\n{Gn0,n, \u2016\u03b8n+1 \u2212 \u03b8\u2217\u2016 > min{ , 2Rwc(n0)}} \u2286 {Gn0,n, \u2016\u03b8n+1 \u2212 \u03b8\u2217\u2016 > }\n\u2286 {Gn0,n, \u2016Em[nc,n+1]\u2016 \u2265 3} .\nHence from the definition of Eaftern0,n1 ,\nPr{Eaftern0,n1} \u2264 \u221e\u2211\nn=n0+n1\nPr { Gn0,n, \u2016Em[nc,n+1]\u2016 \u2265 3 } . (27)\nConsider the case \u03bb > 1/2. Lemma 10 and the definition of Rwc(n0) in Theorem 6 shows that Pr { Gn0,n, \u2016Em[nc,n+1]\u2016 \u2265 3 } \u2264 2d2 exp [ \u2212 (n0 + 1) \u22122(n+ 1) 2\n18d3C2m2C 2 \u2217R 2 0\n] .\nUsing this in (27) and treating the resulting expression as a right Riemann sum, we get\nPr{Eaftern0,n1} \u2264 36d 5C2m2\n[ Rwc(n0) ]2 exp [ \u2212 (n0 + n1) 2\n18d3C2m2[Rwc(n0)] 2\n] .\nSubstituting the given relation between n1 and nc, the desired result is easy to see.\nConsider the case \u03bb < 1/2. From Lemma 10 and the definition of Rwc(n0) in Theorem 6, we have Pr { Gn0,n, \u2016Em[nc,n+1]\u2016 \u2265 3 } \u2264 2d2 exp [ \u2212 (nc + 1) 1\u22122\u03bb(n+ 1)2\u03bb 2\n18d3C2m2[Rwc(n0)] 2\n] .\nLet knc := 2(nc + 1) 1\u22122\u03bb/(18d3C2m2[Rwc(n0)] 2). Pr { Gn0,n, \u2016Em[nc,n+1]\u2016 \u2265 3 } \u2264 2d2 exp [ \u2212knc (n+ 1)2\u03bb ] .\nThen by the same technique that we use to obtain (23) in the proof for Lemma 14, we have \u221e\u2211\nn=n0+n1\nexp[\u2212knc(n+ 1)2\u03bb]\n\u2264 1 knc\u03bb [ (1\u2212 2\u03bb) knc\u03bb ] 1\u22122\u03bb 2\u03bb e 1 2 [knc\u2212 1\u22122\u03bb \u03bb ]e\u2212 knc (n0+n1) 2\u03bb 4\n\u2264 [ 1\nknc\u03bb\n] 1 2\u03bb\ne\u2212 knc (n0+n1)\n2\u03bb\n8\n=\n[ 18d3C2m2[Rwc(n0)] 2\n2\u03bb(nc + 1)1\u22122\u03bb\n] 1 2\u03bb\nexp [ \u2212 2(nc + 1) 1\u22122\u03bb(n0 + n1) 2\u03bb\n144d3C2m2[Rwc(n0)] 2 ] where the second inequality is obtained using the facts that (n0 + n1)2\u03bb \u2265 n2\u03bb0 \u2265 4 and 1\u2212 2\u03bb \u2264 1 and the last equality is obtained by substituting the value of knc . From this, after substituting the given relation between nc and n1, the desired result is easy to see.\nProof of Theorem 1. From Lemma 8, by a union bound,\nPr{Ec(n0, n1)} \u2264 Pr{Emidn0,n1}+ Pr{E after n0,n1} .\nWe now show how to set n0 and n1 so that each of the two terms above is less than \u03b4/2.\nConsider the case \u03bb > 1/2. Let N0(\u03b4) = max { K\u03bb6\u2016A\u2016(\u2016A\u2016+2Km ) \u03bb , 2 1 \u03bb , 8d3C2m2 ln [ 32d5C2m2 \u03b4 ]} =O ( ln 1\u03b4 ) , (28)\nNc( , \u03b4, n0) = max {[( 1 + K\u03bb6\u2016A\u2016(\u2016A\u2016+2Km )\u03bbmin{ ,Rwc(n0)} ) Rwc(n0) ] ,\n18d3C2m2 (6K\u03bb )1/\u03bb\n[ Rwc(n0) ]2\u2212 1\u03bb ln [ 72d5C2m2 [ 1\n\u03b4\n] [ Rwc(n0) ]2]} ,\nso that Nc( , \u03b4,N0(\u03b4)) = O\u0303 ( max { 1 ln [ 1 \u03b4 ] , [ 1 ]2\u2212 1\u03bb [ln 1\u03b4 ]3\u2212 1\u03bb}) , and let N1( , nc, n0) = (nc + 1) [ 6K\u03bbRwc(n0) ]1/\u03bb \u2212 n0,\nso that\nN1( ,Nc( , \u03b4,N0(\u03b4)), N0(\u03b4)) = O\u0303\n( max {[ 1 ]1+ 1\u03bb [ ln 1\n\u03b4\n]1+ 1\u03bb , [ 1 ]2 [ ln 1\n\u03b4\n]3}) . (29)\nLet n0 \u2265 N0(\u03b4), nc \u2265 Nc( , \u03b4, n0) and n1 \u2265 N1( , nc, n0). Then from Lemma 14, Pr{Emidn0,n1} \u2264 \u03b4/2 and from Lemma 15, Pr{Eaftern0,n1} \u2264 \u03b4/2. Hence Pr{E\nc(n0, n1)} \u2264 \u03b4. Consequently, N( , \u03b4) = N1( ,Nc( , \u03b4,N0(\u03b4)), N0(\u03b4)) satisfies the desired properties, which completes the proof for \u03bb > 1/2.\nNow consider the case \u03bb < 1/2. The same exact proof can be repeated, with the following N0, Nc and N1.\nN0(\u03b4) = max { K\u03bb6\u2016A\u2016(\u2016A\u2016+2Km ) \u03bb , 2 1 \u03bb , 64d3C2m2 2\u03bb ln ( 32d5C2m2 \u03b4\u03bb )} =O ( ln 1\u03b4 ) , (30)\nNc( , \u03b4, n0) = max {[( 1 + K\u03bb6\u2016A\u2016(\u2016A\u2016+2Km )\u03bbmin{ ,Rwc(n0)} ) Rwc(n0) ] ,\n4d3C2m2 2\u03bbK2\u03bb ln\n( 72d5C2m2\n\u03bb\n[ 1\n\u03b4\n] [Rwc(n0)] 2\n2\n)} ,\nso that Nc( , \u03b4,N0(\u03b4)) = O\u0303 ( 1 ln 1 \u03b4 ) and let\nN1( , nc, n0) = (nc + 1)\n[ 6K\u03bbRwc(n0) ]1/\u03bb \u2212 n0, (31)\nso that N1( ,Nc( , \u03b4,N0(\u03b4)), N0(\u03b4)) = O\u0303 ([ (1/ ) ln (1/\u03b4) ]1+1/\u03bb)\n. Thus N( , \u03b4) = N1( ,Nc( , \u03b4,N0(\u03b4)), N0(\u03b4)) satisfies the desired properties for the case \u03bb < 1/2.\nFor \u03bb = 1/2, the same process can be repeated, resulting in the same O and O\u0303 results as in (30) and (31)."}, {"heading": "C Supplementary Material for Proof of Theorem 3", "text": "Notice that the matrices (A>+A) and (A>A+KmI) are symmetric. Further, asA is positive definite, the above matrices are also positive definite. Hence their minimum and maximum eigenvalues are strictly positive. Lemma 16. For n \u2265 0, let \u03bbn := \u03bbmax(\u039bn), where\n\u039bn := I\u2212 \u03b1n(A+A>) + \u03b12n(A>A+ 4K2m I).\nFix \u03bb \u2208 (0, \u03bbmin(A+A>)). Let m be so that \u2200k \u2265 m, \u03b1k \u2264 \u03bbmin(A+A >)\u2212\u03bb\n\u03bbmax(A>A+4K2m I) . Then for any k, n\nsuch that n \u2265 k \u2265 0, n\u220f i=k \u03bbk \u2264 Kpe\u2212\u03bb[ \u2211n i=k \u03b1`] ,\nwhere\nKp := max `1\u2264`2\u2264m `2\u220f `=`1 e\u03b1`(\u00b5+\u03bb) ,\nwith \u00b5 = \u2212\u03bbmin(A+A>) + \u03bbmax(A>A+ 4K2m I).\nRemark 7. Such m exists since \u03b1k \u2192 0 as k \u2192\u221e.\nProof. Using Weyl\u2019s inequality, we have\n\u03bbn \u2264 \u03bbmax(I\u2212 \u03b1n(A+A>)) + \u03b12n\u03bbmax(A>A+ 4K2m I). (32)\nSince \u03bbmax(I\u2212 \u03b1n(A+A>)) \u2264 (1\u2212 \u03b1n\u03bbmin(A+A>)), we have\n\u03bbn \u2264 e[\u2212\u03b1n\u03bbmin(A >+A)+\u03b12n\u03bbmax(A >A+4K2m I)].\nFor n < m, using \u03b1n \u2264 1 and hence \u03b12n \u2264 \u03b1n, we have the following weak bound:\n\u03bbn \u2264 e\u03b1n\u00b5. (33)\nOn the other hand, for n \u2265 m, we have\n\u03bbn \u2264 e\u2212\u03bb\u03b1ne\u2212\u03b1n[(\u03bbmin(A >+A)\u2212\u03bb)\u2212\u03b1n\u03bbmax(A>A+4K2m I)] \u2264 e\u2212\u03bb\u03b1n . (34)\nTo prove the desired result, we consider three cases: k \u2264 n \u2264 m, m \u2264 k \u2264 n and k \u2264 m \u2264 n. For the last case, using (33) and (34), we have\nn\u220f `=k \u03bb` \u2264 [ m\u220f `=k \u03bb` ] e\u2212\u03bb( \u2211n `=m+1 \u03b1`) = [ m\u220f `=k \u03bb` ] e\u03bb( \u2211m `=k \u03b1`)e\u2212\u03bb( \u2211n `=k \u03b1`) \u2264 Kpe\u2212\u03bb( \u2211n `=k \u03b1`) ,\nas desired. Similarly, it can be shown that bound holds in other cases as well. The desired result thus follows.\nProof of Theorem 11. Let V (\u03b8) = \u2016\u03b8 \u2212 \u03b8\u2217\u20162. Using (2) and (4), we have\n\u03b8n+1 \u2212 \u03b8\u2217 = (I \u2212 \u03b1nA)(\u03b8n \u2212 \u03b8\u2217) + \u03b1nMn+1.\nHence\nV (\u03b8n+1) =(\u03b8n+1 \u2212 \u03b8\u2217)>(\u03b8n+1 \u2212 \u03b8\u2217) =[(I \u2212 \u03b1nA)(\u03b8n \u2212 \u03b8\u2217) + \u03b1nMn+1]>[(I \u2212 \u03b1nA)(\u03b8n \u2212 \u03b8\u2217) + \u03b1nMn+1] =(\u03b8n \u2212 \u03b8\u2217)>[I \u2212 \u03b1n(A> +A) + \u03b12nA>A](\u03b8n \u2212 \u03b8\u2217)\n+ \u03b1n(\u03b8n \u2212 \u03b8\u2217)>(I \u2212 \u03b1nA)>Mn+1 + \u03b1nM>n+1(I \u2212 \u03b1nA)(\u03b8n \u2212 \u03b8\u2217) + \u03b12n\u2016Mn+1\u20162.\nTaking conditional expectation and using E[Mn+1|Fn] = 0, we get\nE[V (\u03b8n+1)|Fn] = (\u03b8n \u2212 \u03b8\u2217)>[I \u2212 \u03b1n(A> +A) + \u03b12nA>A](\u03b8n \u2212 \u03b8\u2217) + \u03b12nE[\u2016Mn+1\u20162|Fn].\nFrom Lemma 4 and as |x| \u2264 1 + x2, we have \u2016Mn+1\u20162 \u2264 4K2m [1 + \u2016\u03b8n\u2212 \u03b8\u2217\u20162]. This immediately shows that E[\u2016Mn+1\u20162|Fn] \u2264 4K2m [1 + \u2016\u03b8n \u2212 \u03b8\u2217\u20162]. Hence\nE[V (\u03b8n+1)|Fn] \u2264 (\u03b8n \u2212 \u03b8\u2217)>\u039bn(\u03b8n \u2212 \u03b8\u2217) + 4K2m \u03b12n,\nwhere \u039bn = [I \u2212 \u03b1n(A> + A) + \u03b12n(A>A + 4K2m I)]. Since \u039bn is a symmetric matrix, all its eigenvalues are real. With \u03bbn := \u03bbmax(\u039bn), we have\nE[V (\u03b8n+1)|Fn] \u2264 \u03bbnV (\u03b8n) + 4K2m \u03b12n.\nTaking expectation on both sides and letting wn = E[V (\u03b8n)], we have\nwn+1 \u2264 \u03bbnwn + 4K2m \u03b12n.\nSequentially using the above inequality, we have\nwn+1 \u2264 [ n\u220f k=1 \u03bbk ] w0 + 4K 2 m n\u2211 i=0 [ n\u220f k=i+1 \u03bbk ] \u03b12i .\nUsing Lemma 16 and using the constant Kp defined there, the desired result follows.\nProof of Theorem 12. Let {tn} be as defined in Subsection 4.1. Observe that n\u2211 i=0 [ e\u2212(\u03bb/2) \u2211n k=i+1 \u03b1k ] \u03b1i \u2264 ( sup i\u22650 e(\u03bb/2)\u03b1i ) n\u2211 i=0 [ e\u2212(\u03bb/2) \u2211n k=i \u03b1k ] \u03b1i\n= ( sup i\u22650 e(\u03bb/2)\u03b1i ) n\u2211 i=0 [ e\u2212(\u03bb/2)(tn+1\u2212tk) ] \u03b1i\n\u2264 (\nsup i\u22650\ne(\u03bb/2)\u03b1i )\u222b tn+1\n0\ne\u2212(\u03bb/2)(tn+1\u2212s)ds\n\u2264 (\nsup i\u22650\ne(\u03bb/2)\u03b1i ) 2\n\u03bb\n\u2264 2e \u03bb/2\n\u03bb ,\nwhere the third relation follows by treating the sum as right Riemann sum, and the last inequality follows since supi\u22650 \u03b1i \u2264 1. Hence it follows that\nn\u2211 i=0 [ e\u2212\u03bb \u2211n k=i+1 \u03b1k ] \u03b12i \u2264 ( sup 0\u2264i\u2264n [ \u03b1ie \u2212(\u03bb/2) \u2211n k=i+1 \u03b1k ]) n\u2211 i=0 [ e\u2212(\u03bb/2) \u2211n k=i+1 \u03b1k ] \u03b1i\n\u2264 2e \u03bb/2\n\u03bb\n( sup\n0\u2264i\u2264n\n[ \u03b1ie \u2212(\u03bb/2) \u2211n k=i+1 \u03b1k ]) . (35)\nWe claim that for all n \u2265 i0,\nsup i0\u2264i\u2264n\n[ \u03b1ie \u2212(\u03bb/2) \u2211n k=i+1 \u03b1k ] \u2264 1\n(n+ 1)\u03c3 . (36)\nTo establish this, we show that for any n \u2265 i0, \u03b1ie\u2212(\u03bb/2)[ \u2211n k=i+1 \u03b1k] monotonically increases as i is varied from i0 to n. To prove the latter, it suffices to show that \u03b1ie\u2212(\u03bb/2)\u03b1i+1 \u2264 \u03b1i+1, or equivalently (i+ 2)\u03c3/(i+ 1)\u03c3 \u2264 e\u03bb/[2(i+2)\u03c3 ] for all i \u2265 i0. But the latter is indeed true. Thus (36) holds. From (35) and (36), we then have\nn\u2211 i=0 [ e\u2212\u03bb \u2211n k=i+1 \u03b1k ] \u03b12i\n\u2264 2e \u03bb/2\n\u03bb\n[( sup\n0\u2264i\u2264i0\n[ \u03b1ie \u2212(\u03bb/2) \u2211n k=i+1 \u03b1k ]) + ( sup\ni0\u2264i\u2264n\n[ \u03b1ie \u2212(\u03bb/2) \u2211n k=i+1 \u03b1k ])] \u2264 2e \u03bb/2\n\u03bb\n[( sup\n0\u2264i\u2264i0\n[ \u03b1ie \u2212(\u03bb/2) \u2211n k=i+1 \u03b1k ]) +\n1\n(n+ 1)\u03c3 ] \u2264 2e \u03bb/2\n\u03bb\n[ e\u2212[(\u03bb/2) \u2211n k=0 \u03b1k] ( sup\n0\u2264i\u2264i0\n[ \u03b1ie (\u03bb/2) \u2211i k=0 \u03b1k ]) +\n1\n(n+ 1)\u03c3 ] \u2264 2e \u03bb/2\n\u03bb\n[ Kbe \u2212[(\u03bb/2) \u2211n k=0 \u03b1k] +\n1\n(n+ 1)\u03c3\n] ,\nwhere the first relation holds as sup{a0, . . . , an} \u2264 sup{a0, . . . , ai0} + sup{ai0 , . . . , an} for any positive sequence {a0, . . . , an} with 0 \u2264 i0 \u2264 n, and the last relation follows as \u03b1i \u2264 1 and sup0\u2264i\u2264i0 e (\u03bb/2) \u2211i k=0 \u03b1k \u2264 Kb. Combining the above inequality with the relation from Theorem 11, we have\nE\u2016\u03b8n+1\u2212\u03b8\u2217\u20162 \u2264 Kp [ e \u2212\u03bb n\u2211 k=0 \u03b1k ] E\u2016\u03b80\u2212\u03b8\u2217\u20162+ 8K2mKpe \u03bb/2\n\u03bb\n[ Kbe \u2212[(\u03bb/2) n\u2211 k=0 \u03b1k] +\n1\n(n+ 1)\u03c3\n] ,\nSince n\u2211 k=0 \u03b1k \u2265 \u222b n+1 0\n1\n(x+ 1)\u03c3 dx = (n+ 2)1\u2212\u03c3 \u2212 1,\nthe desired result follows."}], "references": [{"title": "Dynamic Programming and Optimal Control", "author": ["D.P. Bertsekas"], "venue": "Vol II. Athena Scientific, fourth edition,", "citeRegEx": "Bertsekas.,? \\Q2012\\E", "shortCiteRegEx": "Bertsekas.", "year": 2012}, {"title": "Stochastic approximation: a dynamical systems viewpoint", "author": ["Vivek S Borkar"], "venue": null, "citeRegEx": "Borkar.,? \\Q2008\\E", "shortCiteRegEx": "Borkar.", "year": 2008}, {"title": "The ode method for convergence of stochastic approximation and reinforcement learning", "author": ["Vivek S Borkar", "Sean P Meyn"], "venue": "SIAM Journal on Control and Optimization,", "citeRegEx": "Borkar and Meyn.,? \\Q2000\\E", "shortCiteRegEx": "Borkar and Meyn.", "year": 2000}, {"title": "Transport-entropy inequalities and deviation estimates for stochastic approximation schemes", "author": ["Max Fathi", "Noufel Frikha"], "venue": "Electron. J. Probab.,", "citeRegEx": "Fathi and Frikha.,? \\Q2013\\E", "shortCiteRegEx": "Fathi and Frikha.", "year": 2013}, {"title": "Concentration bounds for stochastic approximations", "author": ["Noufel Frikha", "St\u00e9phane Menozzi"], "venue": "Electron. Commun. Probab.,", "citeRegEx": "Frikha and Menozzi.,? \\Q2012\\E", "shortCiteRegEx": "Frikha and Menozzi.", "year": 2012}, {"title": "Differential equations, dynamical systems, and an introduction to chaos", "author": ["Morris W Hirsch", "Stephen Smale", "Robert L Devaney"], "venue": "Academic press,", "citeRegEx": "Hirsch et al\\.,? \\Q2012\\E", "shortCiteRegEx": "Hirsch et al\\.", "year": 2012}, {"title": "On the convergence, lock-in probability, and sample complexity of stochastic approximation", "author": ["Sameer Kamal"], "venue": "SIAM Journal on Control and Optimization,", "citeRegEx": "Kamal.,? \\Q2010\\E", "shortCiteRegEx": "Kamal.", "year": 2010}, {"title": "On td (0) with function approximation: Concentration bounds and a centered variant with exponential convergence", "author": ["Nathaniel Korda", "LA Prashanth"], "venue": "In ICML,", "citeRegEx": "Korda and Prashanth.,? \\Q2015\\E", "shortCiteRegEx": "Korda and Prashanth.", "year": 2015}, {"title": "Method of variation of parameters for dynamic systems", "author": ["Vangipuram Lakshmikantham", "Sadashiv Deo"], "venue": null, "citeRegEx": "Lakshmikantham and Deo.,? \\Q1998\\E", "shortCiteRegEx": "Lakshmikantham and Deo.", "year": 1998}, {"title": "Finite-sample analysis of lstd", "author": ["Alessandro Lazaric", "Mohammad Ghavamzadeh", "R\u00e9mi Munos"], "venue": "In ICML-27th International Conference on Machine Learning,", "citeRegEx": "Lazaric et al\\.,? \\Q2010\\E", "shortCiteRegEx": "Lazaric et al\\.", "year": 2010}, {"title": "Finite-sample analysis of proximal gradient td algorithms", "author": ["Bo Liu", "Ji Liu", "Mohammad Ghavamzadeh", "Sridhar Mahadevan", "Marek Petrik"], "venue": "In UAI,", "citeRegEx": "Liu et al\\.,? \\Q2015\\E", "shortCiteRegEx": "Liu et al\\.", "year": 2015}, {"title": "Human-level control through deep reinforcement learning", "author": ["Volodymyr Mnih", "Koray Kavukcuoglu", "David Silver", "Andrei A Rusu", "Joel Veness", "Marc G Bellemare", "Alex Graves", "Martin Riedmiller", "Andreas K Fidjeland", "Georg Ostrovski"], "venue": "Nature, 518(7540):529\u2013533,", "citeRegEx": "Mnih et al\\.,? \\Q2015\\E", "shortCiteRegEx": "Mnih et al\\.", "year": 2015}, {"title": "Approximate Dynamic Programming: Solving the curses of dimensionality, volume 703", "author": ["Warren B Powell"], "venue": null, "citeRegEx": "Powell.,? \\Q2007\\E", "shortCiteRegEx": "Powell.", "year": 2007}, {"title": "Mastering the game of go with deep neural networks and tree", "author": ["David Silver", "Aja Huang", "Chris J Maddison", "Arthur Guez", "Laurent Sifre", "George Van Den Driessche", "Julian Schrittwieser", "Ioannis Antonoglou", "Veda Panneershelvam", "Marc Lanctot"], "venue": "search. Nature,", "citeRegEx": "Silver et al\\.,? \\Q2016\\E", "shortCiteRegEx": "Silver et al\\.", "year": 2016}, {"title": "Learning to predict by the methods of temporal differences", "author": ["Richard S Sutton"], "venue": "Machine learning,", "citeRegEx": "Sutton.,? \\Q1988\\E", "shortCiteRegEx": "Sutton.", "year": 1988}, {"title": "Introduction to Reinforcement Learning", "author": ["Richard S. Sutton", "Andrew G. Barto"], "venue": null, "citeRegEx": "Sutton and Barto.,? \\Q1998\\E", "shortCiteRegEx": "Sutton and Barto.", "year": 1998}, {"title": "A convergent o (n) temporal-difference algorithm for off-policy learning with linear function approximation", "author": ["Richard S Sutton", "Hamid R Maei", "Csaba Szepesv\u00e1ri"], "venue": "In Advances in neural information processing systems,", "citeRegEx": "Sutton et al\\.,? \\Q2009\\E", "shortCiteRegEx": "Sutton et al\\.", "year": 2009}, {"title": "Fast gradient-descent methods for temporal-difference learning with linear function approximation", "author": ["Richard S Sutton", "Hamid Reza Maei", "Doina Precup", "Shalabh Bhatnagar", "David Silver", "Csaba Szepesv\u00e1ri", "Eric Wiewiora"], "venue": "In Proceedings of the 26th Annual International Conference on Machine Learning,", "citeRegEx": "Sutton et al\\.,? \\Q2009\\E", "shortCiteRegEx": "Sutton et al\\.", "year": 2009}, {"title": "An emphatic approach to the problem of off-policy temporal-difference learning", "author": ["Richard S Sutton", "A Rupam Mahmood", "Martha White"], "venue": "The Journal of Machine Learning Research,", "citeRegEx": "Sutton et al\\.,? \\Q2015\\E", "shortCiteRegEx": "Sutton et al\\.", "year": 2015}, {"title": "Temporal difference learning and td-gammon", "author": ["Gerald Tesauro"], "venue": "Communications of the ACM,", "citeRegEx": "Tesauro.,? \\Q1995\\E", "shortCiteRegEx": "Tesauro.", "year": 1995}, {"title": "A concentration bound for stochastic approximation via alekseev\u2019s formula", "author": ["Gugan Thoppe", "Vivek S Borkar"], "venue": null, "citeRegEx": "Thoppe and Borkar.,? \\Q2015\\E", "shortCiteRegEx": "Thoppe and Borkar.", "year": 2015}, {"title": "An analysis of temporal-difference learning with function approximation", "author": ["John N Tsitsiklis", "Benjamin Van Roy"], "venue": "IEEE transactions on automatic control,", "citeRegEx": "Tsitsiklis and Roy,? \\Q1997\\E", "shortCiteRegEx": "Tsitsiklis and Roy", "year": 1997}, {"title": "Convergence results for some temporal difference methods based on least squares", "author": ["Huizhen Yu", "Dimitri P Bertsekas"], "venue": "IEEE Transactions on Automatic Control,", "citeRegEx": "Yu and Bertsekas.,? \\Q2009\\E", "shortCiteRegEx": "Yu and Bertsekas.", "year": 2009}], "referenceMentions": [{"referenceID": 15, "context": "The term has been coined in [Sutton and Barto, 1998], describing an iterative process of updating an estimate of a value function V (s) with respect to a given policy \u03c0 based on temporally-successive samples.", "startOffset": 28, "endOffset": 52}, {"referenceID": 11, "context": "The term has been coined in [Sutton and Barto, 1998], describing an iterative process of updating an estimate of a value function V (s) with respect to a given policy \u03c0 based on temporally-successive samples. The classical version of the algorithm uses a tabular representation, i.e., entry-wise storage of the value estimate per each state s \u2208 S. However, in many problems the state-space S is too large for such a vanilla approach. The common practice to mitigate this caveat is to approximate the value function using some parameterized family. Often, linear regression is used, i.e., V (s) \u2248 \u03b8>\u03c6(s). This allows for an efficient implementation of TD(0) even on large state-spaces and has shown to perform well in a variety of problems Tesauro [1995], Powell [2007].", "startOffset": 29, "endOffset": 754}, {"referenceID": 11, "context": "This allows for an efficient implementation of TD(0) even on large state-spaces and has shown to perform well in a variety of problems Tesauro [1995], Powell [2007]. More recently, TD(0) has become prominent in many state-of-the-art RL solutions when combined with deep neural network architectures, as an integral part of fitted value iteration [Mnih et al.", "startOffset": 151, "endOffset": 165}, {"referenceID": 1, "context": "In [Borkar, 2008], a concentration bound is given for generic SA algorithms.", "startOffset": 3, "endOffset": 17}, {"referenceID": 7, "context": "In [Korda and Prashanth, 2015], concentration bounds for TD(0) with mixing-time consideration have been given.", "startOffset": 3, "endOffset": 30}, {"referenceID": 0, "context": "Following that, a key result by Borkar and Meyn [2000] paved the path to a unified and convenient tool for convergence analyses of Stochastic Approximation (SA), and hence of TD algorithms.", "startOffset": 32, "endOffset": 55}, {"referenceID": 0, "context": "Following that, a key result by Borkar and Meyn [2000] paved the path to a unified and convenient tool for convergence analyses of Stochastic Approximation (SA), and hence of TD algorithms. This tool is based on the Ordinary Differential Equation (ODE) method. Essentially, that work showed that under the right conditions, the SA trajectory follows the solution of a suitable ODE, often referred to as its limiting ODE; thus, it eventually converges to the solution of the limiting ODE. Several usages of this tool in RL literature can be found in [Sutton et al., 2009a,b, 2015]. As opposed to the case of asymptotic convergence analysis of TD algorithms, very little is known on their finite sample behavior. We now briefly discuss the few existing results on this topic. In [Borkar, 2008], a concentration bound is given for generic SA algorithms. Recent works [Kamal, 2010, Thoppe and Borkar, 2015] obtain better concentration bounds via tighter analyses. The results in these works are conditioned on the event that the n0\u2212th iterate lies in some a-priori chosen bounded region containing the desired equilibria; this, therefore, is the caveat in applying them to TD(0). In [Korda and Prashanth, 2015], concentration bounds for TD(0) with mixing-time consideration have been given. However, unlike in our work, a strong requirement for all their high probability bounds is that the iterates need to lie in some a-priori chosen bounded set; this is ensured there via projections (personal communication). Additionally, their results require the learning rate to be set based on prior knowledge about system dynamics, which, as argued in the paper, is problematic; alternatively, they apply to average of iterates. An additional work by Liu et al. [2015] considered the gradient TD algorithms GTD(0) and GTD2, which were first introduced in [Sutton et al.", "startOffset": 32, "endOffset": 1758}, {"referenceID": 14, "context": "A MDP is defined by the 5-tuple (S,A , P,R, \u03b3) [Sutton, 1988], where S is the set of states, A is the set of", "startOffset": 47, "endOffset": 61}, {"referenceID": 0, "context": "It is known that A is positive definite [Bertsekas, 2012] and that (2) converges to \u03b8\u2217 := A\u22121b [Borkar, 2008].", "startOffset": 40, "endOffset": 57}, {"referenceID": 1, "context": "It is known that A is positive definite [Bertsekas, 2012] and that (2) converges to \u03b8\u2217 := A\u22121b [Borkar, 2008].", "startOffset": 95, "endOffset": 109}, {"referenceID": 7, "context": "Theorem 1, Korda and Prashanth [2015] requires the TD(0) step-sizes to satisfy: \u03b1n = fn(\u03bb) for some function fn, where \u03bb is as above.", "startOffset": 11, "endOffset": 38}, {"referenceID": 1, "context": "In [Borkar, 2008], on which much of the existing RL literature is based on, the square summability assumption is due to the Gronwall inequality.", "startOffset": 3, "endOffset": 17}, {"referenceID": 8, "context": "In contrast, in our work, we use the Variation of Parameters Formula [Lakshmikantham and Deo, 1998] for comparing the SA trajectory to appropriate trajectories of the limiting ODE; it is a stronger tool than Gronwall inequality.", "startOffset": 69, "endOffset": 99}, {"referenceID": 6, "context": "The expectation bound in Theorem 1, Korda and Prashanth [2015] again requires the stepsize sequence be scaled as in Remark 1.", "startOffset": 36, "endOffset": 63}, {"referenceID": 6, "context": "The expectation bound in Theorem 1, Korda and Prashanth [2015] again requires the stepsize sequence be scaled as in Remark 1. Theorem 2 there obviates this, but it applies to average of iterates. In contrast, our expectation bound applies directly to the TD(0) iterates and does not need any scaling of the above kind. Moreover, our result applies to a broader family of stepsizes; see Remark 4. Our expectation bound when compared to that of Theorem 2, Korda and Prashanth [2015] is of the same order (even though theirs is for average of iterates).", "startOffset": 36, "endOffset": 481}, {"referenceID": 8, "context": "1 Outline of Approach We compare the TD(0) iterates {\u03b8n} with suitable solutions of its limiting ODE using the Variation of Parameters (VoP) method [Lakshmikantham and Deo, 1998].", "startOffset": 148, "endOffset": 178}, {"referenceID": 5, "context": "Using results from Chapter 6, [Hirsch et al., 2012], it follows that the solution \u03b8(t, s, u0), t \u2265 s, of (6) satisfies the relation \u03b8(t, s, u0) = \u03b8 \u2217 + e(u0 \u2212 \u03b8\u2217) .", "startOffset": 30, "endOffset": 51}, {"referenceID": 8, "context": "The key idea then is to use the VoP method [Lakshmikantham and Deo, 1998] and express \u03b8\u0304(t) as a perturbation of \u03b8(t) due to two factors: the discretization error and the martingale difference noise.", "startOffset": 43, "endOffset": 73}, {"referenceID": 6, "context": "The expectation bound is due to an inductive argument and an application of a subtle trick from Kamal [2010]. Building on the approach there, our key steps are: identifying a \u201cnice\" Liapunov function V of the TD(0) method\u2019s limiting ODE; and then using conditional expectation suitably to get rid of the linear noise terms in the relation between V (\u03b8n) and V (\u03b8n+1).", "startOffset": 96, "endOffset": 109}, {"referenceID": 20, "context": "Specifically, using the non-linear analysis presented in [Thoppe and Borkar, 2015], we believe it can be extended to a broader family of function approximators, e.", "startOffset": 57, "endOffset": 82}, {"referenceID": 8, "context": "From the above two relations and the VoP formula [Lakshmikantham and Deo, 1998], the desired result follows.", "startOffset": 49, "endOffset": 79}], "year": 2017, "abstractText": "TD(0) is one of the most commonly used algorithms in reinforcement learning. Despite this, there is no existing finite sample analysis for TD(0) with function approximation, even for the linear case. Our work is the first to provide such a result. Works that managed to obtain concentration bounds for online Temporal Difference (TD) methods analyzed modified versions of them, carefully crafted for the analyses to hold. These modifications include projections and step-sizes dependent on unknown problem parameters. Our analysis obviates these artificial alterations by exploiting strong properties of TD(0) and tailor-made stochastic approximation tools.", "creator": "LaTeX with hyperref package"}}}