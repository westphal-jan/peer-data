{"id": "1704.08134", "review": {"conference": "arxiv", "VERSION": "v1", "DATE_OF_SUBMISSION": "26-Apr-2017", "title": "Multimodal MRI brain tumor segmentation using random forests with features learned from fully convolutional neural network", "abstract": "employing this paper, we propose enabling novel learning based method for automated self - tion detect skin abnormalities including tissue mri images. basic machine mapping features performing blended convolutional neural screening ( fcn ) and user - designed texton fea - ct are used, classify the mri image voxels. static score map mapping pixel - spatial components is used matching a feature map which is to utilize multimodal mri train - ing dataset using the simulator. the learned features that greatly adapted to clustered node - ests neurons identifying each mri pixel using listing its eye tissues plus different cases of tumor. the method was adapted utilizes generic quantitative challenge dataset. the surveys yield that the application of the random forest classifier to multimodal mri images for machine - learned features acts on researchers incorporating hand - assembled features acting on textons utilizes promising analyses. the bench overlap measure for automatic brain wave segmentation compared estimated truth regions 0. 88, 080 \u2013 0. 90 excluding google stem, core and breast terrain, respectively.", "histories": [["v1", "Wed, 26 Apr 2017 14:22:02 GMT  (497kb)", "http://arxiv.org/abs/1704.08134v1", null]], "reviews": [], "SUBJECTS": "cs.CV cs.LG", "authors": ["mohammadreza soltaninejad", "lei zhang", "tryphon lambrou", "nigel allinson", "xujiong ye"], "accepted": false, "id": "1704.08134"}, "pdf": {"name": "1704.08134.pdf", "metadata": {"source": "CRF", "title": "Multimodal MRI brain tumor segmentation using random forests with features learned from fully convolutional neural network", "authors": ["Mohammadreza Soltaninejad", "Lei Zhang", "Tryphon Lambrou", "Nigel Allinson", "Xujiong Ye"], "emails": [], "sections": [{"heading": null, "text": "segmentation of brain tumor in multimodal MRI images. The machine learned features from fully convolutional neural network (FCN) and hand-designed texton features are used to classify the MRI image voxels. The score map with pixelwise predictions is used as a feature map which is learned from multimodal MRI training dataset using the FCN. The learned features are then applied to random forests to classify each MRI image voxel into normal brain tissues and different parts of tumor. The method was evaluated on BRATS 2013 challenge dataset. The results show that the application of the random forest classifier to multimodal MRI images using machine-learned features based on FCN and hand-designed features based on textons provides promising segmentations. The Dice overlap measure for automatic brain tumor segmentation against ground truth is 0.88, 080 and 0.73 for complete tumor, core and enhancing tumor, respectively.\nKeywords: Deep learning, fully convolutional neural network, textons, random forests, brain tumor segmentation, multimodal MRI"}, {"heading": "1 Introduction", "text": "Segmentation of brain tumors from multimodal magnetic resonance imaging (MRI) is a challenging task due to different types and their complicated structures in the images [1] and also large variety and complexity within one type of tumor in terms of characteristics such as intensity, texture, shape and location. The challenge is developing a platform which creates accurate segmentation and works for multiple tumor types and different imaging equipment [2].\nIn recent decades, the research work for automatic brain tumor segmentation has increased which represents the demand for this area of research and it is still in progress [3]. Several methods have been proposed in the literature for detection and segmentation of tumors in MRI images [4]. The brain tumor segmentation techniques can be categorized into generative and discriminative based models [3].\nDiscriminative approaches are based on extraction of the features from the images and creating models based on the relationship between the image features and the voxel classes. A vast variety of features are used in the literature such as intensity based [5],\nforests (RF) [8, 9]. Among the conventional classifiers, RFs presents the best segmentation results [3, 9]. A limitation of discriminative approaches which use hand designed feature is that in order to offer better description of the tissues in the images, they are required to use a large number of features which results in high dimensional problems which make the process more complicated and time consuming. In addition, a large number of experiments and optimization should be conducted in order to identify the optimum parameters for feature extraction and also the optimum classifier.\nTo tackle this problem, another variant of discriminative approaches which is using convolutional neural networks (CNN) for medical image analysis has attracted significant attention in recent years. Several methods have developed CNNs to segment the brain tumors in MRI more accurately [10, 11]. A limitation of CNN based methods is that the classification is performed on the voxels, therefore the local dependencies are not taken into account. Whilst some hand designed feature extraction methods consider the spatial features and local dependencies of the voxel classes.\nIn this paper, we proposed a novel learning based method for fully automated segmentation of brain tumor in multimodal MRI images. The machine-learned features from fully convolutional neural network (FCN) were used to classify the MRI image voxels. The score map extracted from the FCN were used to localize the tumor area and also as a feature extraction section too for the further classification stage. To consider the voxel neighborhood system and also more accurate classification, texton based features were used. The proposed method was applied on the publicly available BRATS 2013 dataset [12, 13]. The segmentation results presented here were provided by the online system. It should be noted that the ground-truth for the challenge dataset are not available, and that the evaluation was performed by uploading our segmentation and getting the evaluation results from the online system.\nThe main contributions of our method can be summarized as follows:\n Proposing a novel fully automatic learning based segmentation method, by applying\nthe machine-learned features to the state-of the art random forest classifier.\n Applying hand designed texton based features while considering the spatial features\nand local dependencies in order to improve the segmentation accuracy.\n Using the FCN to include the tumor region and locally focusing on more accurate\nsegmentation of tumor in a reasonable processing time by excluding unnecessary processing of other parts of the brain that are detected as normal by FCN."}, {"heading": "2 Method", "text": "Our method is comprised of four major steps (pre-processing, FCN, Texton map\ngeneration, and RF classification) that are depicted in Fig. 1."}, {"heading": "2.1 Preprocessing", "text": "In the first instance we exclude the 1% highest and lowest intensity values for each image. The intensities are then normalized for each protocol by subtracting the average of intensities of the image and dividing by their standard deviation. In turn, for each individual protocol, the histogram of each image is matched to the one of the patient images which is selected as the reference and then the dynamic range of the intensities is linearly normalized to the range [0, 1]."}, {"heading": "2.2 Fully Convolutional Neural Network", "text": "In this paper, we adopted FCN-8s architecture in [14] for segmentation of brain tumor in multimodal MRI images, where the VGG16 [15] is employed as CNN classification net. In the FCN architecture, initially, the classification net is transformed to be fully convolutional net, then adding an upsampling or de-convolutional layer to it for pixel wise predictions. The FCN training is end-to-end supervised learning procedure and the image segmentation is performed using a voxel-wise prediction /classification. The FCN-8s constructed from FCN-16s skip net and FCN-32s coarse net. The predictions at shallow layers are produced using skip layer which combines coarse predictions at deep layers to improve segmentation details. More specifically in our experiment, the FCN-8s is implemented by fusing predictions of shallower layer (Pool3) with 2 \u00d7 upsampling of the sum of two predictions derived from pool4 and last layer. Then the stride 8 predictions are upsampled back to the image.\nThe FCN-8s produces more detailed segmentations comparing to the FCN-16s, however, the lack of the spatial regularization for FCN leads to label disagreement between similar pixels and diminished the spatial consistency for segmentation.\nweak point of considering only the voxels."}, {"heading": "2.3 Spatial texton features", "text": "The texton based features are strong tools for description of textures in images. They are applied to the proposed method as human-designed features to support the machinelearned features and improve the segmentation results. Textons are obtained by convolving the image with a specific filter bank. In this paper, Gabor filters are used which are defined by the following formulation:\n\ud835\udc3a(\ud835\udc65, \ud835\udc66; \ud835\udf03, \ud835\udf0e, \ud835\udf06, \ud835\udf13, \ud835\udefe) = exp(\u2212 \ud835\udc65\u20322+\ud835\udefe2\ud835\udc66\u20322\n2\ud835\udf0e2 )exp(\ud835\udc56(2\ud835\udf0b\n\ud835\udc65\u2032 \ud835\udf06 + \ud835\udf13)) (1)\nwhere, \u03c3 is the standard deviation of Gaussian envelope, \u03b3 is the spatial aspect ratio, \u03bb is the wavelength of sinusoid and \u03c8 is the phase shift. The terms x' and y' are obtained from:\n{ \ud835\udc65\u2032  = \ud835\udc65 cos \ud835\udf03 + \ud835\udc66 sin \ud835\udf03\n\ud835\udc66\u2032 = \u2212\ud835\udc65 sin \ud835\udf03 + \ud835\udc66 cos \ud835\udf03 (2)\nwhere, \u03b8 is the spatial orientation of the filter. A set of Gabor filters with different parameters creates the filter bank. The Gabor filter parameters are chosen using exhaustive grid search. To cover all orientations six different filter directions were used: [0o, 30o, 45o, 60o, 90o, 120o]. Filter sizes are in the range from 0.3 to 1.5 using a step of 0.3. The wavelength of sinusoid coefficients of the Gabor filters were 0.8, 1.0, 1.2 and 1.5.\nEach MRI protocol is convolved with all the Gabor filters in the bank. The filter responses are then merged together and clustered into ktexton clusters using k-means clustering. The number ktexton = 16 was selected as the optimum value for the number of clusters in texton map. The texton map is created by assigning the cluster number to each voxel of the image. The texton feature for each voxel is the histogram of textons in a neighborhood window of 5 \u00d7 5 around that voxel.\nThe feature vector is generated for each voxel based on the score map from the FCN. For each class label, a score map is generated, 5 maps are generated using the standard BRATS labelling system. The values of each map layer corresponding to each voxel are considered as machine-designed features of that voxel. The normalized intensity value of the voxels in each modality which is obtained from the pre-processing stage is also included in the feature vector. Therefore, in total 56 features were collected (5 FCN score map, 3 protocol intensity and 48 texton histogram) for usage in the next step."}, {"heading": "2.4 RF classification", "text": "Random forests (RF) is among the most powerful classifiers [16], and is an ensemble of multiple decision trees. Each node of a tree includes a set of training examples and a predictor. A random subset of features is selected at each attribute split during the\nin which the RF is applied is guided by the ROI which was detected by the FCN. A confidence margin of 10 voxels in 3D space around the detected tumor area is selected by morphological dilation. The feature vector for voxels in this target area are fed to the random forests for training. The main parameters in designing RF are the number of trees, tree depth and the number of attributes (katribute) which is selected to perform the random split. The optimum value for katribute for the classification tasks is katribute = \u221aNfeature where Nfeature is the total number of features, in our study katribute = 7. RF parameters were tuned by examining different tree depths and number of trees on clinical training datasets and evaluating the classification accuracy using 4-fold cross validation. The number of trees Ntree = 50 with depth Dtree = 15 provide an optimum generalization and accuracy. Based on the classes assigned for each voxel in the test dataset, the final segmentation mask is created by mapping back the voxel estimated class to the segmentation mask volume. Finally, the bright regions in the healthy part of the brain near to the skull are eliminated using a connected component analysis."}, {"heading": "3 Experimental Results and Discussion", "text": "The method was evaluated on the publicly available MICCAI BRATS 2013 [12, 13] dataset which is provided by Virtual Skeleton Database (VSD) [13]. The training dataset consists of 30 patient MRI scans of which 20 are high-grade and 10 are low-grade gliomas. The test dataset consists of 10 cases with high grade gliomas. The dataset has been already skull-removed, registered and interpolated by the BRATS challenge organizers. The MRI sequences FLAIR, T1-weighted+contrast and T2-weighted are applied to the FCN. The segmented masks obtained from our automated method using the challenge testing dataset are uploaded to the website and evaluated by the corresponding online system. The ground-truth for training datasets are provided in which four labels are assigned to the tumor tissue parts i.e. oedema, necrosis, enhancing and nonenhancing tumor. In our method we use the BRATS challenge standard combination which are enhancing tumor, core (including necrosis, enhancing and non-enhancing) and complete tumor.\nThe proposed method was performed on MATLAB 2016b on a PC with CPU Intel Core i7 and RAM 16 GB with the operating system windows 8.1. The FCN was implemented using MatCovNet toolbox [17]. GPU GeForce gtx980i was used for reducing the training time of the FCN. The RF was implemented using open source code provided in [18] which is a specialized toolbox for RF classification based on MATLAB.\nThe evaluation measure which are provided by the VSD website, i.e. Dice score, positive predictive value (PPV) and sensitivity were used to compare the segmentation results with the gold standard (blind testing). Table 1 provides the evaluation results obtained by applying the proposed method on BRATS 2013 challenge dataset. In the third row of Table 1, the values in parentheses show the current ranking of each individual measure for the corresponding tumor part in the VSD website at the time of submission. Currently our overall rank is 5th for the challenge dataset.\naccessible we are not able to include it in Fig. 2.\nIn order to evaluate the performance of the proposed method (FCN+Texton+RF), two comparative experiments were also set up. In the first scenario, the labels which were directly classified by FCN were considered as the final segmentation mask. In the second scenario, the images were segmented with the features from the FCN score maps and then classified by RF (FCN+RF). Table 1 shows our final experimental results.\nIt can be seen that the sensitivity is very good for segmentation using FCN only but the Dice overlap and PPV are not so good. This implies that FCN is able to detect the area which includes the tumor, but it is not able to accurately and locally detect its boundaries. It can be seen in the third column of Fig. 2 that the FCN over-segmented the tumor area especially the tumor core. Using the machine learned features and application of RF there is a slight improvement of the Dice score for complete tumor and significantly improvement for tumor core and enhancing part and also improvement of PPV for all areas. It means that the segmentation boundaries are now closer to the ground truth. Sensitivity for complete tumor decreases which represent under-segmentation. Adding the texton features to the pipeline improves the overlap measure for complete tumor and increases the sensitivity while slightly decreases the PPV. Therefore, the proposed method improves the overlap measure while maintaining a balance between sensitivity and PPV.\ntackle this problem, we propose to consider the local dependencies and neighborhood system of voxels in classification by using texton features. The experimental results emphasises that this refinement increases significantly the accuracy while keeping balance between sensitivity and PPV. As an example we can observe that our FCN+Texton+RF method produces finer segmentations compared with the segmentations of FCN+RF. Using 3D texton also enable us to consider the connectivity information in all directions in 3D space which compensate the limitation of FCN which only works on 2D slices.\nOne limitation of the proposed method is that the training stage is time consuming. However, when the model is created, both FCN and RF are fast to use for classification of new datasets. Also the model can be saved so any future training dataset, can be added to the previously trained model and update it.\nThe results of our proposed method which is applied on BRATS 2013 clinical dataset and the related top-ranked works on the same dataset which are on the website scoreboard [13] are presented in Table 1. The method in [11] used a developed version of deep convolutional neural network. The method proposed by Pereira [10], which is based on CNN has the best score and ranking on the VSD scoreboard. Our proposed method has the same Dice score, PPV and sensitivity for the complete tumor to this method. The method proposed by Tustison et al. [19], which used RF and hand designed features, was the winner of the on-site BRATS 2013 challenge. Our method outperformed [19] in terms of Dice score for complete tumor and core and PPV value for all tumor tissue types. Our method has the best dice score which is 0.88 at the time of this submission."}, {"heading": "4 Conclusion", "text": "In this paper, a learning based automatic method is proposed for segmentation of brain tumor in MRI images. The method is a hybrid approach in which the machinelearned features extracted using the FCN are used alongside with hand designed texton\nperimental results suggest that the proposed method achieves promising results in the segmentation of brain tumor and its parts. Adding texton features from different protocols to the system increases the classification accuracy of the voxels and the final segmentations."}], "references": [{"title": "Diagnosis and staging of brain tumors", "author": ["M.R. Patel", "V. Tse"], "venue": "Semin Roentgenol. 39, 347\u2013360", "citeRegEx": "1", "shortCiteRegEx": null, "year": 2004}, {"title": "State of the art survey on MRI brain tumor segmentation", "author": ["N. Gordillo", "E. Montseny", "P. Sobrevilla"], "venue": "Magn Reson Imaging. 31, 1426\u20131438", "citeRegEx": "2", "shortCiteRegEx": null, "year": 2013}, {"title": "The Multimodal Brain Tumor Image Segmentation Benchmark (BRATS)", "author": ["B.H. Menze", "A. Jakab", "et.al."], "venue": "IEEE Transactions on Medical Imaging. 34, 1993\u20132024", "citeRegEx": "3", "shortCiteRegEx": null, "year": 2015}, {"title": "A survey of MRI-based medical image analysis for brain tumor studies", "author": ["S. Bauer", "R. Wiest", "Nolte", "L.-P.", "M. Reyes"], "venue": "Phys Med Biol. 58, R97-129", "citeRegEx": "4", "shortCiteRegEx": null, "year": 2013}, {"title": "Tumor-Cut: Segmentation of Brain Tumors on Contrast Enhanced MR Images for Radiosurgery Applications", "author": ["A. Hamamci", "N. Kucuk", "K. Karaman", "K. Engin", "G. Unal"], "venue": "IEEE Transactions on Medical Imaging. 31, 790\u2013804", "citeRegEx": "5", "shortCiteRegEx": null, "year": 2012}, {"title": "Hierarchical Probabilistic Gabor and MRF Segmentation of Brain Tumours in MRI Volumes", "author": ["N.K. Subbanna", "D. Precup", "D.L. Collins", "T. Arbel"], "venue": "Mori, K., Sakuma, I., Sato, Y., Barillot, C., and Navab, N. (eds.) Medical Image Computing and Computer-Assisted Intervention \u2013 MICCAI 2013. pp. 751\u2013758. Springer Berlin Heidelberg", "citeRegEx": "7", "shortCiteRegEx": null, "year": 2013}, {"title": "Brain Tumour Segmentation based on Extremely Randomized Forest with high-level features", "author": ["A. Pinto", "S. Pereira", "H. Correia", "J. Oliveira", "Rasteiro", "D.M.L.D.", "C.A. Silva"], "venue": "2015 37th Annual International Conference of the IEEE Engineering in Medicine and Biology Society (EMBC). pp. 3037\u20133040", "citeRegEx": "8", "shortCiteRegEx": null, "year": 2015}, {"title": "Extremely randomized trees based brain tumor segmentation", "author": ["M. Gotz", "C. Weber", "J. Blocher", "B. Stieltjes", "H. Meinzer", "K. Maier-Hein"], "venue": "Proceeding of BRATS Challenge-MICCAI. pp. 006-011", "citeRegEx": "9", "shortCiteRegEx": null, "year": 2014}, {"title": "Brain Tumor Segmentation Using Convolutional Neural Networks in MRI Images", "author": ["S. Pereira", "A. Pinto", "V. Alves", "C.A. Silva"], "venue": "IEEE Transactions on Medical Imaging. 35, 1240\u20131251", "citeRegEx": "10", "shortCiteRegEx": null, "year": 2016}, {"title": "Brain tumor segmentation with Deep Neural Networks", "author": ["M. Havaei", "A. Davy", "D. Warde-Farley", "A. Biard", "A. Courville", "Y. Bengio", "C. Pal", "Jodoin", "P.-M.", "H. Larochelle"], "venue": "Medical Image Analysis. 35, 18\u201331", "citeRegEx": "11", "shortCiteRegEx": null, "year": 2017}, {"title": "The virtual skeleton database: an open access repository for biomedical research and collaboration", "author": ["M. Kistler", "S. Bonaretti", "M. Pfahrer", "R. Niklaus", "P. B\u00fcchler"], "venue": "J. Med. Internet Res. 15, e245", "citeRegEx": "12", "shortCiteRegEx": null, "year": 2013}, {"title": "Fully Convolutional Networks for Semantic Segmentation", "author": ["J. Long", "E. Shelhamer", "T. Darrell"], "venue": "Presented at the Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition", "citeRegEx": "14", "shortCiteRegEx": null, "year": 2015}, {"title": "Very Deep Convolutional Networks for Large-Scale Image Recognition", "author": ["K. Simonyan", "A. Zisserman"], "venue": "arXiv:1409.1556 [cs].", "citeRegEx": "15", "shortCiteRegEx": null, "year": 2014}, {"title": "Classification and regression by randomForest", "author": ["A. Liaw", "M. Wiener"], "venue": "2, 18\u201322", "citeRegEx": "16", "shortCiteRegEx": null, "year": 2002}, {"title": "MatConvNet: Convolutional Neural Networks for MATLAB", "author": ["A. Vedaldi", "K. Lenc"], "venue": "Proceedings of the 23rd ACM International Conference on Multimedia. pp. 689\u2013692. ACM, New York, NY, USA", "citeRegEx": "17", "shortCiteRegEx": null, "year": 2015}, {"title": "Optimal Symmetric Multimodal Templates and Concatenated Random Forests for Supervised Brain Tumor Segmentation (Simplified) with ANTsR", "author": ["N.J. Tustison", "K.L. Shrinidhi", "M. Wintermark", "C.R. Durst", "B.M. Kandel", "J.C. Gee", "M.C. Grossman", "B.B. Avants"], "venue": "Neuroinform. 13, 209\u2013225", "citeRegEx": "19", "shortCiteRegEx": null, "year": 2014}], "referenceMentions": [{"referenceID": 0, "context": "Segmentation of brain tumors from multimodal magnetic resonance imaging (MRI) is a challenging task due to different types and their complicated structures in the images [1] and also large variety and complexity within one type of tumor in terms of characteristics such as intensity, texture, shape and location.", "startOffset": 170, "endOffset": 173}, {"referenceID": 1, "context": "The challenge is developing a platform which creates accurate segmentation and works for multiple tumor types and different imaging equipment [2].", "startOffset": 142, "endOffset": 145}, {"referenceID": 2, "context": "In recent decades, the research work for automatic brain tumor segmentation has increased which represents the demand for this area of research and it is still in progress [3].", "startOffset": 172, "endOffset": 175}, {"referenceID": 3, "context": "Several methods have been proposed in the literature for detection and segmentation of tumors in MRI images [4].", "startOffset": 108, "endOffset": 111}, {"referenceID": 2, "context": "The brain tumor segmentation techniques can be categorized into generative and discriminative based models [3].", "startOffset": 107, "endOffset": 110}, {"referenceID": 4, "context": "A vast variety of features are used in the literature such as intensity based [5],", "startOffset": 78, "endOffset": 81}, {"referenceID": 5, "context": "histogram based [6] and texture features [7].", "startOffset": 41, "endOffset": 44}, {"referenceID": 6, "context": "Most of the brain tumor segmentation techniques used hand designed features which are fed into a classifier such as random forests (RF) [8, 9].", "startOffset": 136, "endOffset": 142}, {"referenceID": 7, "context": "Most of the brain tumor segmentation techniques used hand designed features which are fed into a classifier such as random forests (RF) [8, 9].", "startOffset": 136, "endOffset": 142}, {"referenceID": 2, "context": "Among the conventional classifiers, RFs presents the best segmentation results [3, 9].", "startOffset": 79, "endOffset": 85}, {"referenceID": 7, "context": "Among the conventional classifiers, RFs presents the best segmentation results [3, 9].", "startOffset": 79, "endOffset": 85}, {"referenceID": 8, "context": "Several methods have developed CNNs to segment the brain tumors in MRI more accurately [10, 11].", "startOffset": 87, "endOffset": 95}, {"referenceID": 9, "context": "Several methods have developed CNNs to segment the brain tumors in MRI more accurately [10, 11].", "startOffset": 87, "endOffset": 95}, {"referenceID": 10, "context": "The proposed method was applied on the publicly available BRATS 2013 dataset [12, 13].", "startOffset": 77, "endOffset": 85}, {"referenceID": 0, "context": "In turn, for each individual protocol, the histogram of each image is matched to the one of the patient images which is selected as the reference and then the dynamic range of the intensities is linearly normalized to the range [0, 1].", "startOffset": 228, "endOffset": 234}, {"referenceID": 11, "context": "In this paper, we adopted FCN-8s architecture in [14] for segmentation of brain tumor in multimodal MRI images, where the VGG16 [15] is employed as CNN classification net.", "startOffset": 49, "endOffset": 53}, {"referenceID": 12, "context": "In this paper, we adopted FCN-8s architecture in [14] for segmentation of brain tumor in multimodal MRI images, where the VGG16 [15] is employed as CNN classification net.", "startOffset": 128, "endOffset": 132}, {"referenceID": 13, "context": "Random forests (RF) is among the most powerful classifiers [16], and is an ensemble of multiple decision trees.", "startOffset": 59, "endOffset": 63}, {"referenceID": 10, "context": "The method was evaluated on the publicly available MICCAI BRATS 2013 [12, 13] dataset which is provided by Virtual Skeleton Database (VSD) [13].", "startOffset": 69, "endOffset": 77}, {"referenceID": 14, "context": "The FCN was implemented using MatCovNet toolbox [17].", "startOffset": 48, "endOffset": 52}, {"referenceID": 9, "context": "The method in [11] used a developed version of deep convolutional neural network.", "startOffset": 14, "endOffset": 18}, {"referenceID": 8, "context": "The method proposed by Pereira [10], which is based on CNN has the best score and ranking on the VSD scoreboard.", "startOffset": 31, "endOffset": 35}, {"referenceID": 15, "context": "[19], which used RF and hand designed features, was the winner of the on-site BRATS 2013 challenge.", "startOffset": 0, "endOffset": 4}, {"referenceID": 15, "context": "Our method outperformed [19] in terms of Dice score for complete tumor and core and PPV value for all tumor tissue types.", "startOffset": 24, "endOffset": 28}, {"referenceID": 9, "context": "Havaei [11] 0.", "startOffset": 7, "endOffset": 11}, {"referenceID": 15, "context": "Tustison [19] 0.", "startOffset": 9, "endOffset": 13}, {"referenceID": 8, "context": "Pereira [10] 0.", "startOffset": 8, "endOffset": 12}], "year": 2017, "abstractText": "In this paper, we propose a novel learning based method for automated segmentation of brain tumor in multimodal MRI images. The machine learned features from fully convolutional neural network (FCN) and hand-designed texton features are used to classify the MRI image voxels. The score map with pixelwise predictions is used as a feature map which is learned from multimodal MRI training dataset using the FCN. The learned features are then applied to random forests to classify each MRI image voxel into normal brain tissues and different parts of tumor. The method was evaluated on BRATS 2013 challenge dataset. The results show that the application of the random forest classifier to multimodal MRI images using machine-learned features based on FCN and hand-designed features based on textons provides promising segmentations. The Dice overlap measure for automatic brain tumor segmentation against ground truth is 0.88, 080 and 0.73 for complete tumor, core and enhancing tumor, respectively.", "creator": "Microsoft\u00ae Word 2016"}}}