{"id": "1704.08797", "review": {"conference": "arxiv", "VERSION": "v1", "DATE_OF_SUBMISSION": "28-Apr-2017", "title": "Risk Stratification of Lung Nodules Using 3D CNN-Based Multi-task Learning", "abstract": "genome stratification underlying lung nodules is some metric under primary importance in analyzing cancer diagnosis. eliminating hurdle in overall 3d accurate nodule characterization can resulting in identifying associated toxicity, prognosis, and therapeutic treatment planning. in simple study, we propose a sophisticated convolutional shape chart ( cnn ) based nodule characterization scenarios. with the completely 3d approach, engineers utilize stored volumetric information creating a ct scan which would previously continually lost reflecting all existing 2d cnn based diagnosis. in example we assess broader need for a conserved amount for training data supporting cnn, we resort to morphological learning to obtain highly matching features. moreover, we can acquire additional new design feature representation for determining species - scale visual maps and interpret this complementary data via a multi - task learning ( mtl ) profile. furthermore, we propose to discover potential data about radiologists while determining different behavioral measures in generic graph showing sparse multi - task learning. developers view our proposed approach sampled 133 of the largest publicly available ct nodule datasets comprising 1018 scans and obtained free - of - the - art techniques in separate initial estimate scores.", "histories": [["v1", "Fri, 28 Apr 2017 03:32:54 GMT  (467kb,D)", "http://arxiv.org/abs/1704.08797v1", "Accepted for publication at Information Processing in Medical Imaging (IPMI) 2017"]], "COMMENTS": "Accepted for publication at Information Processing in Medical Imaging (IPMI) 2017", "reviews": [], "SUBJECTS": "cs.CV cs.LG", "authors": ["sarfaraz hussein", "kunlin cao", "qi song", "ulas bagci"], "accepted": false, "id": "1704.08797"}, "pdf": {"name": "1704.08797.pdf", "metadata": {"source": "CRF", "title": "Risk Stratification of Lung Nodules Using 3D CNN-Based Multi-task Learning", "authors": ["Sarfaraz Hussein", "Kunlin Cao", "Qi Song", "Ulas Bagci"], "emails": ["shussein@knights.ucf.edu", "bagci@crcv.ucf.edu"], "sections": [{"heading": null, "text": "Keywords: Computer-Aided Diagnosis (CAD), Lung nodule characterization, 3D Convolutional Neural Network, Multi-task learning, Transfer learning, Computed Tomography (CT), Deep learning"}, {"heading": "1 Introduction", "text": "Cancer is the number-one cause of deaths in the world. Out of 8.2 million deaths due to cancer worldwide, lung cancer accounts for the highest number of mortalities i.e. 1.59 million [1]. Risk stratification of lung nodules can aid in identifying cancer stage leading to improved treatment and higher chances of survival. In addition, any significant development to accurately and automatically characterize lung nodules can save significant manual exertion as well as valuable time.\nEarly diagnosis is one of the ways to reduce deaths related to lung cancer [2]. In this regard, lung screening programs are especially beneficial. Low Dose Computed Tomography (CT) scans are usually used to perform lung nodule diagnosis, including both detection and risk stratification. Although CT imaging remains\nar X\niv :1\n70 4.\n08 79\n7v 1\n[ cs\n.C V\n] 2\n8 A\npr 2\n01 7\nthe gold standard for lung cancer detection and diagnosis, Computer-Aided Diagnosis (CAD) and quantification tools are often necessary. Moreover, research in developing CAD algorithms can help explore the domain of imaging features and biomarkers which can be then studied by radiologists to further improve clinical decision making.\nThe development of a fast, robust and accurate system to perform risk stratification of lung nodules is therefore of significant importance. Specially the availability of large publicly available datasets such as LIDC-IDRI from Lung Image Database Consortium [3] has helped accelerate the research in this regard. However, the variability in nodule characteristics, including shape, size, intensity, location and uncertainty among radiologists\u2019 interpretation have made this problem particularly challenging. The advancement in machine learning methods, including the development of novel classification and feature learning techniques, has increased the efficacy of this task. However, there remains a substantial progress to be done in order to develop a CAD system attractive enough to be used in routine clinical evaluations of lung nodules.\nIn this work, we address the challenge of risk-stratification of lung nodules in low-dose CT scans. Capitalizing on the significant progress of deep learning technologies for image classification and their potential applications in radiology [4], we propose a 3D Convolutional Neural Network (CNN) based approach for rich feature representation of lung nodules. We argue that the use of 3D CNN is paramount in the classification of lung nodules in low-dose CT scans which are 3D by nature. By using the conventional CNN methods, however, we implicitly lose the important volumetric information which can be very significant for accurate risk stratification. The superior performance of 3D CNN over 2D networks is well studied in [5]. We also avoid hand-crafted feature extraction, painstaking feature engineering, and parameter tuning. Moreover, any information about six high-level nodule attributes such as calcification, sphericity, margin, lobulation, spiculation and texture (Figure 1) can help in improving the benign-malignant risk assessment of the nodules. Taking forward this idea, we identify features corresponding to these high-level nodule attributes and fuse them in a multi-task learning framework to obtain the final risk assessment scores. An overview of the proposed approach is presented in Figure 2. Overall, our main contributions in this work can be summarized as follows:\n\u2013 We propose a 3D CNN based method to utilize the volumetric information from a CT scan which would be otherwise lost in the conventional 2D CNN based approaches. Moreover, we also circumvent the need for a large amount of volumetric training data to train the 3D network by transfer learning. We use the CT data to fine-tune a network which is trained on 1 million videos. To the best of our knowledge, our work is the first to empirically validate the success of transfer learning of a 3D network for lung nodules.\n\u2013 We perform experimental evaluations on one of the largest publicly available datasets comprising lung nodules from more than 1000 low-dose CT scans.\n\u2013 We employ graph regularized sparse multi-task learning to fuse the complementary feature information from high-level nodule attributes for malignancy determination. We also propose a scoring function to measure the inconsistency in risk assessment among different experts (radiologists)."}, {"heading": "2 Related Work", "text": "Conventionally, the characterization of lung nodules comprised nodule segmentation, extraction of hand-crafted imaging features, followed by the application of an off-the-shelf classifier/regressor. The method by Uchiyama et al. [6] was based on the extraction of various physical measures, including intensity statistics and then classification using Artificial Neural Networks. El-Baz et al. [7] first segmented the lung nodules using appearance-based models and used spherical harmonic analysis to perform shape analysis. The final step was the classification using k-nearest neighbor. Proposing a study based on texture analysis, Han et al. [8] extracted 2D texture features such as Haralick, Gabor and Local Binary Patterns (LBP) and extended them to 3D. Support Vector Machine (SVM) was employed to perform the classification. In another classical work by Way et al. [9], segmentation is performed using 3D active contours followed by the extraction of texture features from the rubber band straightening transform of the surrounding voxels. The classification was performed using Linear Discriminant Analysis (LDA) classifier. In another study, Lee et al. [10] proposed a feature\nselection based approach using both imaging and clinical data. An ensemble classifier, combining genetic algorithm (GA) and random subspace method (RSM) was then used to gauge feature relevance and information content. Finally, LDA was employed to perform classification on the reduced feature set.\nFollowing up on the success of deep learning, the medical imaging community has moved from feature engineering to feature learning. In those frameworks, CNN had been used for feature extraction and an off-the-shelf classifier such as Random Forest (RF) was employed for classification [11,12]. Recently, Buty et al. [12] combined spherical harmonics along with deep CNN features and then classified them using RF. However, the use of CNN for lung nodule classification has been confined to 2D image analysis [13], thus falling short of utilizing the important volumetric and contextual information.\nMoreover, the use of high-level image attributes had been found to be instrumental in the risk assessment and classification of lung nodules. In an effort to study the relationship between nodules attributes and malignancy, Furuya et al. [14] found that in a particular dataset, 82% of the lobulated, 97% of the densely spiculated, 93% of the ragged and 100% of the halo nodules were malignant. Moreover, 66% of the round nodules were found to be benign. Inspired by this study, in this work we utilize 3D CNN to learn discriminative feature set corre-\nsponding to each of the 6 attributes. We then fuse these feature representations via MTL to determine the malignancy likelihood."}, {"heading": "3 Method", "text": ""}, {"heading": "3.1 Problem Formulation", "text": "Let X = [x1, x2 . . . xn] \u2208 Rn\u00d7d be the data matrix comprising features from n data points in Rd. Each sample corresponds with a regression score given by Y = [y1, y2 . . . yn] where Y \u2208 Rn\u00d71. Here the objective is to learn the coefficient vector or the regression estimator W from the training data. In this case, the `1 regularized least square regressor is defined as:\nmin W \u2016XW \u2212 Y \u201622 + \u03bb \u2016W\u20161 , (1)\nwhere \u03bb controls the sparsity level for coefficient vector W = [w1, w2 . . . wd]. The problem in Eq. 1 is an unconstrained convex optimization problem, and it remains non-differentiable when wi = 0. Hence, the closed form solution corresponding to the global minimum for Eq. 1 is not possible. Thus, the above equation is represented in the following way as a constrained optimization function:\nmin W \u2016XW \u2212 Y \u201622 ,\ns.t. \u2016W\u20161 \u2264 t, (2)\nwhere t is inversely proportional to \u03bb. In the representation given in Eq. 2, both optimization function and the constraint are convex."}, {"heading": "3.2 Network Architecture and Transfer Learning", "text": "We use the lung nodules dataset to fine-tune a 3D CNN trained on Sports-1M dataset [15]. The sports dataset comprises 1 million videos with 487 classes. In the absence of a large number of training examples from lung nodules, we use transfer learning strategy to obtain rich feature representation from a larger dataset (Sports-1M) for lung nodule characterization. The Sports-1M dataset is used to train a 3D CNN [5]. The network comprises 5 convolution, 5 max-pooling, 2 fully-connected and 1 soft-max classification layers. The input to the network is 3\u00d716\u00d7128\u00d7171 where there are 16 non-overlapping slices in the input volume. The first 2 convolution layers have 64 and 128 filters respectively, whereas there are 256 filters in the last 3 layers. The outputs of the fully connected layers are of 4096 dimensions."}, {"heading": "3.3 Multi-task learning", "text": "Consider a problem with M tasks representing different attributes corresponding to a given dataset D. These tasks may be related and share some feature representation, both of which are unknown. The goal in Multi-task learning (MTL) is to perform joint learning of these tasks while exploiting dependencies in feature space so as to improve regressing one task using the others. In contrast to multilabel learning, tasks may have different features in MTL. Each task has model parameters denoted by Wm, used to regress the corresponding task m. Moreover, when W = [W1,W2 . . .WM ] \u2208 RM\u00d7d represents a rectangular matrix, rank is considered as an extension to the cardinality. In that case, trace norm, which is the sum of singular values is a replacement to the `1-norm. Trace norm, also known as nuclear norm is the convex envelope of the rank of a matrix (which is non-convex), where the matrices are considered on a unit ball. By replacing `1-norm with trace norm in Eq. 1, the trace norm regularized least square loss function is given by:\nmin W M\u2211 i=1 \u2016XiWi \u2212 Yi\u201622 + \u03c1 \u2016W\u2016\u2217 , (3)\nwhere \u03c1 tunes the rank of the matrix W, and trace-norm is defined as: \u2016W\u2016\u2217 =\u2211 i=1 \u03c3i(W) with \u03c3 representing singular values. Another regularizer, pertinent to MTL, is the regularization on the graph representing the relationship between the tasks [16,17]. Consider a complete graph G = (V, E), such that nodes V represent the tasks and the edges E encode any relativity between the tasks. The complete graph can be represented as a structure matrix S = [e1, e2 . . . e\u2016E\u2016] and the difference between all the pairs connected in the graph is penalized by the following regularizer:\n\u2016WS\u20162F = \u2016E\u2016\u2211 i=1 \u2225\u2225Wei\u2225\u22252 2 = \u2016E\u2016\u2211 i=1 \u2225\u2225\u2225Weia \u2212Weib\u2225\u2225\u222522 . (4) Herein, eia, e i b are the edges between the nodes a and b. The above regularizer\ncan also be written as:\n\u2016WS\u20162F = tr((WS) T (WS)) = tr(WSSTWT ) = tr(WLWT ), (5)\nwhere \u2018tr\u2019 represents trace of a matrix and L = SST is the Laplacian matrix. Since there may exist disagreements between the scores from different experts (radiologists), we propose a scoring function to measure potential inconsistencies:\n\u03a8(j) = (e \u2212\n\u2211 i(x j i \u2212\u00b5j)2\n2\u03c3p )\u22121. (6)\nThe inconsistency measure corresponding to a particular example j is represented by \u03a8(j). xji is the score given by the expert (radiologist) i and \u00b5\nj and \u03c3j denote mean and standard deviation of the scores, respectively. Here, for\nAlgorithm 1 Algorithm for the proposed MTL method Input: Generated features from 3D CNN: XNM for M attributes and N examples Attributes scores: Y NM Output: Coefficient matrix W Step 1 \u2013 for each task i = 1 to M and each example j = 1 to N do\nSolve equation (6) to find \u03a8 end for\nStep 2 \u2013 Formulate objective function as in equation (7) Step 3 \u2013 Use accelerated proximal gradient method to optimize equation (7) return W\nsimplicity, we have dropped the index for the task; however, note that the inconsistency measure is computed for all the tasks. The final proposed graph regularized sparse least square optimization function with the inconsistency measure can then be written as:\nmin W M\u2211 i=1 1\u00a9\ufe37 \ufe38\ufe38 \ufe37 \u2016(Xi + \u03a8i)Wi \u2212 Yi\u201622 + 2\u00a9\ufe37 \ufe38\ufe38 \ufe37 \u03c11 \u2016WS\u20162F + 3\u00a9\ufe37 \ufe38\ufe38 \ufe37 \u03c12 \u2016W\u20161, (7)\nwhere \u03c11 controls the level of penalty for graph structure and \u03c12 controls the sparsity. In the above optimization, the least square loss function 1\u00a9 considers tasks to be decoupled whereas 2\u00a9 and 3\u00a9 consider the interdependencies between different tasks."}, {"heading": "3.4 Optimization", "text": "The optimization function in Eq. 7 cannot be solved through standard gradient descent because the `1\u2212norm is not differentiable at W = 0. Since the optimization function in Eq. 7 has both smooth and non-smooth convex parts, estimating the non-smooth part can help solve the optimization function. Therefore, accelerated proximal gradient method [18,19] is employed to solve the Eq. 7. The accelerated proximal method is the first order gradient method with a complexity of O(1/k2), where k is the iteration counter. Note that in Eq. 7, the `1-norm comprises the non-smooth part and the proximal operator is used for its estimation. The steps in the proposed approach are summarized in Algorithm 1."}, {"heading": "4 Experiments", "text": ""}, {"heading": "4.1 Data", "text": "For evaluating our proposed approach, we used LIDC-IDRI dataset from Lung Image Database Consortium [3], which is one of the largest publicly available lung cancer screening datasets. There were 1018 CT scans in the dataset, where the slice thickness varied from 0.45 mm to 5.0 mm. The nodules having diameters larger than or equal to 3 mm were annotated by at most four radiologists.\nThe nodules which were annotated by at least three radiologists were used for the evaluations. There were 1340 nodules satisfying this criterion. We used the mean malignancy and attribute scores of different radiologists for experiments. The nodules have ratings corresponding to malignancy and the other six attributes which are (i) calcification, (ii) lobulation, (iii) spiculation, (iv) sphericity, (v) margin and (vi) texture. The malignancy ratings varied from 1 to 5 where 1 indicated benign and 5 represented highly malignant nodules. We excluded nodules with an average score equal to 3 to account for the indecision among the radiologists. Our final dataset consisted of 635 benign and 509 malignant nodules for classification. The images were resampled to have 0.5 mm spacing in each dimension."}, {"heading": "4.2 Results", "text": "We used the 3D CNN trained on Sports-1M dataset [15] which had 487 classes. We fine-tuned the network using samples from lung nodule dataset. In order to generate the binary labels for the six attributes and the malignancy, we used the center point and gave positive (or negative) labels to samples having scores greater (or lesser) than the center point. In the context of our work, tasks represented six attributes and malignancy. We fine-tuned the network with these 7 tasks and performed 10 fold cross validation. By fine-tuning the network, we circumvented the need to have a large amount of training data. Since the 3D network was trained on image sequences with 3 channels and with at least 16 frames, we replicated the same gray level axial channel for the other two. More-\nover, we also ensured that all input volumes have 16 slices by interpolation when necessary. We used the 4096-dimensional output from the first fully connected layer of the 3D CNN as a feature representation.\nTo find the structure matrix S, we computed the correlation between tasks by finding an initial normalized coefficient matrix W using lasso with least square loss function and followed by computing the correlation coefficient matrix [17]. We then apply a threshold on the correlation coefficient matrix to obtain a binary graph structure matrix. For testing, we multiply the features from network\ntrained on malignancy with the corresponding coefficient vector W to obtain the score.\nFor evaluation, we used metrics for both classification and regression. We calculated classification accuracy by considering classification to be successful if the predicted score lies in \u00b11 of the true score. We also reported average absolute score difference between the predicted score and the true score. Table 1 shows the comparison of our proposed Multi-task learning method with GIST features [20] +LASSO and 3D CNN Multi-task learning with trace norm. Our proposed graph regularized MTL outperforms the other methods with a significant margin. Our approach improves the classification accuracy over GIST features by about 15% and over trace norm regularization by 11%. Moreover, the average absolute score difference reduces by 32% and 27% when compared with GIST and trace norm respectively.\nWe also plotted classification accuracy against different thresholds for average absolute score difference. Figure 3 (a) and (b) show the plot on different cross-validation sets. It can be noticed that across different validation sets, the predicted malignancy scores of around 70% of the nodules lie within a margin of \u00b10.6 which increases to around 90% when \u00b11 margin is used. Figure 3 (c) shows the comparison with the other methods, where the proposed approach outperforms them over all values of average absolute score difference. Figure 4 shows the qualitative results from our proposed approach.\nIn order to evaluate the significance of transfer learning via fine-tuning, we project the features onto a low dimensional space. This is done by computing the proximity, between boundary points using t-distributed stochastic neighbor-\nhood embedding (t-SNE) [21]. As our feature space is high dimensional (4096- dimension), t-SNE is useful in revealing the structure of data at different scales. It can be seen in Figure 5 that fine-tuning the network on the lung nodule dataset distinctively improves the separation between benign and malignant classes."}, {"heading": "5 Discussion and Conclusion", "text": "In this work, we proposed a framework to stratify the malignancy of lung nodules using 3D CNN and graph regularized sparse multi-task learning. To the best of our knowledge, this is for the first time, transfer learning is employed over 3D CNN to improve lung nodule characterization. The task of data collection, especially in medical imaging fields, is highly regulated and the availability of experts for annotating these images is restricted. In this scenario, leveraging on the availability of crowdsourced and annotated data such as user captured videos can be instrumental in training discriminative models. However, given the diversity in data from these two domains (i.e. medical and non-medical user collected videos), it is vital to perform transfer learning from source domain (user collected videos) to the target domain (medical imaging data). To establish this observation and to visualize features, we used t-SNE to project high dimensional features onto a low dimensional space (2D space), where the separation between classes was evident in the case of transfer learning.\nMoreover, in this work, we also empirically explored the importance of highlevel nodule attributes such as calcification, sphericity, lobulation and others to improve malignancy determination. Rather than manually determining these attributes we used 3D CNN to learn discriminative features corresponding to these attributes. The 3D CNN based features from these attributes are fused in a graph regularized sparse multi-task learning.\nAnother important imaging modality for lung nodule diagnosis is Positron Emission Tomography (PET). It has been found that the combination of PET and CT can improve the diagnostic accuracy of solitary lung nodules [22]. With the increase in the availability of PET/CT scanners, our future work will involve their utilization for simultaneous detection and characterization of pulmonary nodules."}], "references": [{"title": "World Cancer Report 2014", "author": ["B. Stewart", "Wild", "C.P"], "venue": "World", "citeRegEx": "1", "shortCiteRegEx": null, "year": 2016}, {"title": "Lung cancer screening: Computed tomography or chest radiographs", "author": ["E.J. van Beek", "S. Mirsadraee", "J.T. Murchison"], "venue": "World Journal of Radiology 7(8),", "citeRegEx": "2", "shortCiteRegEx": "2", "year": 2015}, {"title": "The lung image database consortium (LIDC) and image database resource initiative (IDRI): a completed reference database of lung nodules on CT scans", "author": ["S. Armato III", "G. McLennan", "L. Bidaut", "M.F. McNitt-Gray", "C.R. Meyer", "A.P. Reeves", "B. Zhao", "D.R. Aberle", "C.I. Henschke", "Hoffman", "E.A"], "venue": "Medical Physics 38(2), 915\u2013931", "citeRegEx": "3", "shortCiteRegEx": null, "year": 2011}, {"title": "Deep convolutional neural networks for computer-aided detection: CNN architectures, dataset characteristics and transfer learning", "author": ["H. Shin", "H.R. Roth", "M. Gao", "L. Lu", "Z. Xu", "I. Nogues", "J. Yao", "D. Mollura", "R.M. Summers"], "venue": "IEEE Transactions on Medical Imaging 35(5), 1285\u20131298", "citeRegEx": "4", "shortCiteRegEx": null, "year": 2016}, {"title": "Learning spatiotemporal features with 3D convolutional networks", "author": ["D. Tran", "L. Bourdev", "R. Fergus", "L. Torresani", "M. Paluri"], "venue": "2015 IEEE International Conference on Computer Vision (ICCV). pp. 4489\u20134497. IEEE", "citeRegEx": "5", "shortCiteRegEx": null, "year": 2015}, {"title": "Quantitative computerized analysis of diffuse lung disease in high-resolution computed tomography", "author": ["Y. Uchiyama", "S. Katsuragawa", "H. Abe", "J. Shiraishi", "F. Li", "Q. Li", "C.T. Zhang", "K. Suzuki", "K. Doi"], "venue": "Medical Physics 30(9), 2440\u20132454", "citeRegEx": "6", "shortCiteRegEx": null, "year": 2003}, {"title": "3D shape analysis for early diagnosis of malignant lung nodules", "author": ["A. El-Baz", "M. Nitzken", "F. Khalifa", "A. Elnakib", "G. Gimelfarb", "R. Falk", "M.A. ElGhar"], "venue": "Biennial International Conference on Information Processing in Medical Imaging. pp. 772\u2013783. Springer", "citeRegEx": "7", "shortCiteRegEx": null, "year": 2011}, {"title": "Texture feature analysis for computer-aided diagnosis on pulmonary nodules", "author": ["F. Han", "H. Wang", "G. Zhang", "H. Han", "B. Song", "L. Li", "W. Moore", "H. Lu", "H. Zhao", "Z. Liang"], "venue": "Journal of Digital Imaging 28(1), 99\u2013115", "citeRegEx": "8", "shortCiteRegEx": null, "year": 2015}, {"title": "Computer-aided diagnosis of pulmonary nodules on CT scans: segmentation and classification using 3D active contours", "author": ["T.W. Way", "L.M. Hadjiiski", "B. Sahiner", "H.P. Chan", "P.N. Cascade", "E.A. Kazerooni", "N. Bogot", "C. Zhou"], "venue": "Medical Physics 33(7), 2323\u20132337", "citeRegEx": "9", "shortCiteRegEx": null, "year": 2006}, {"title": "Computer-aided diagnosis of pulmonary nodules using a two-step approach for feature selection and classifier ensemble construction", "author": ["M. Lee", "L. Boroczky", "K. Sungur-Stasik", "A. Cann", "A. Borczuk", "S. Kawut", "C. Powell"], "venue": "Artificial Intelligence in Medicine 50(1), 43\u201353", "citeRegEx": "10", "shortCiteRegEx": null, "year": 2010}, {"title": "Lung nodule classification using deep features in CT images", "author": ["D. Kumar", "A. Wong", "D.A. Clausi"], "venue": "Computer and Robot Vision (CRV), 2015 12th Conference on. pp. 133\u2013138. IEEE", "citeRegEx": "11", "shortCiteRegEx": null, "year": 2015}, {"title": "Characterization of lung nodule malignancy using hybrid shape and appearance features", "author": ["M. Buty", "Z. Xu", "M. Gao", "U. Bagci", "A. Wu", "D.J. Mollura"], "venue": "International Conference on Medical Image Computing and Computer-Assisted Intervention (MICCAI). pp. 662\u2013670. Springer", "citeRegEx": "12", "shortCiteRegEx": null, "year": 2016}, {"title": "Bridging Computational Features Toward Multiple Semantic Features with Multi-task Regression: A Study of CT Pulmonary Nodules", "author": ["S. Chen", "D. Ni", "J. Qin", "B. Lei", "T. Wang", "J.Z. Cheng"], "venue": "MICCAI. pp. 53\u201360. Springer", "citeRegEx": "13", "shortCiteRegEx": null, "year": 2016}, {"title": "New classification of small pulmonary nodules by margin characteristics on highresolution CT", "author": ["K. Furuya", "S. Murayama", "H. Soeda", "J. Murakami", "Y. Ichinose", "H. Yauuchi", "Y. Katsuda", "M. Koga", "K. Masuda"], "venue": "Acta Radiologica 40(5), 496\u2013504", "citeRegEx": "14", "shortCiteRegEx": null, "year": 1999}, {"title": "Largescale video classification with convolutional neural networks", "author": ["A. Karpathy", "G. Toderici", "S. Shetty", "T. Leung", "R. Sukthankar", "L. Fei-Fei"], "venue": "Proceedings of the IEEE conference on Computer Vision and Pattern Recognition. pp. 1725\u20131732", "citeRegEx": "15", "shortCiteRegEx": null, "year": 2014}, {"title": "Regularized multi\u2013task learning", "author": ["T. Evgeniou", "M. Pontil"], "venue": "Proceedings of the tenth ACM SIGKDD International Conference on Knowledge discovery and Data mining. pp. 109\u2013117. ACM", "citeRegEx": "16", "shortCiteRegEx": null, "year": 2004}, {"title": "MALSAR: Multi-task learning via structural regularization", "author": ["J. Zhou", "J. Chen", "J. Ye"], "venue": null, "citeRegEx": "17", "shortCiteRegEx": "17", "year": 2012}, {"title": "Introductory lectures on convex optimization: A basic course, vol", "author": ["Y. Nesterov"], "venue": "87. Springer Science & Business Media", "citeRegEx": "18", "shortCiteRegEx": null, "year": 2013}, {"title": "Modeling the shape of the scene: A holistic representation of the spatial envelope", "author": ["A. Oliva", "A. Torralba"], "venue": "International Journal of Computer Vision 42(3), 145\u2013175", "citeRegEx": "20", "shortCiteRegEx": null, "year": 2001}, {"title": "Visualizing data using t-SNE", "author": ["Maaten", "L.v.d.", "G. Hinton"], "venue": "Journal of Machine Learning Research 9(Nov), 2579\u20132605", "citeRegEx": "21", "shortCiteRegEx": null, "year": 2008}, {"title": "Evidence based imaging strategies for solitary pulmonary nodule", "author": ["Y.X.J. Wang", "J.S. Gong", "K. Suzuki", "S.K. Morcos"], "venue": "Journal of thoracic disease 6(7), 872\u2013887", "citeRegEx": "22", "shortCiteRegEx": null, "year": 2014}], "referenceMentions": [{"referenceID": 0, "context": "59 million [1].", "startOffset": 11, "endOffset": 14}, {"referenceID": 1, "context": "Early diagnosis is one of the ways to reduce deaths related to lung cancer [2].", "startOffset": 75, "endOffset": 78}, {"referenceID": 2, "context": "Specially the availability of large publicly available datasets such as LIDC-IDRI from Lung Image Database Consortium [3] has helped accelerate the research in this regard.", "startOffset": 118, "endOffset": 121}, {"referenceID": 3, "context": "Capitalizing on the significant progress of deep learning technologies for image classification and their potential applications in radiology [4], we propose a 3D Convolutional Neural Network (CNN) based approach for rich feature representation of lung nodules.", "startOffset": 142, "endOffset": 145}, {"referenceID": 4, "context": "The superior performance of 3D CNN over 2D networks is well studied in [5].", "startOffset": 71, "endOffset": 74}, {"referenceID": 5, "context": "[6] was based on the extraction of various physical measures, including intensity statistics and then classification using Artificial Neural Networks.", "startOffset": 0, "endOffset": 3}, {"referenceID": 6, "context": "[7] first segmented the lung nodules using appearance-based models and used spherical harmonic analysis to perform shape analysis.", "startOffset": 0, "endOffset": 3}, {"referenceID": 7, "context": "[8] extracted 2D texture features such as Haralick, Gabor and Local Binary Patterns (LBP) and extended them to 3D.", "startOffset": 0, "endOffset": 3}, {"referenceID": 8, "context": "[9], segmentation is performed using 3D active contours followed by the extraction of texture features from the rubber band straightening transform of the surrounding voxels.", "startOffset": 0, "endOffset": 3}, {"referenceID": 9, "context": "[10] proposed a feature", "startOffset": 0, "endOffset": 4}, {"referenceID": 10, "context": "In those frameworks, CNN had been used for feature extraction and an off-the-shelf classifier such as Random Forest (RF) was employed for classification [11,12].", "startOffset": 153, "endOffset": 160}, {"referenceID": 11, "context": "In those frameworks, CNN had been used for feature extraction and an off-the-shelf classifier such as Random Forest (RF) was employed for classification [11,12].", "startOffset": 153, "endOffset": 160}, {"referenceID": 11, "context": "[12] combined spherical harmonics along with deep CNN features and then classified them using RF.", "startOffset": 0, "endOffset": 4}, {"referenceID": 12, "context": "However, the use of CNN for lung nodule classification has been confined to 2D image analysis [13], thus falling short of utilizing the important volumetric and contextual information.", "startOffset": 94, "endOffset": 98}, {"referenceID": 13, "context": "[14] found that in a particular dataset, 82% of the lobulated, 97% of the densely spiculated, 93% of the ragged and 100% of the halo nodules were malignant.", "startOffset": 0, "endOffset": 4}, {"referenceID": 14, "context": "We use the lung nodules dataset to fine-tune a 3D CNN trained on Sports-1M dataset [15].", "startOffset": 83, "endOffset": 87}, {"referenceID": 4, "context": "The Sports-1M dataset is used to train a 3D CNN [5].", "startOffset": 48, "endOffset": 51}, {"referenceID": 15, "context": "Another regularizer, pertinent to MTL, is the regularization on the graph representing the relationship between the tasks [16,17].", "startOffset": 122, "endOffset": 129}, {"referenceID": 16, "context": "Another regularizer, pertinent to MTL, is the regularization on the graph representing the relationship between the tasks [16,17].", "startOffset": 122, "endOffset": 129}, {"referenceID": 17, "context": "Therefore, accelerated proximal gradient method [18,19] is employed to solve the Eq.", "startOffset": 48, "endOffset": 55}, {"referenceID": 2, "context": "For evaluating our proposed approach, we used LIDC-IDRI dataset from Lung Image Database Consortium [3], which is one of the largest publicly available lung cancer screening datasets.", "startOffset": 100, "endOffset": 103}, {"referenceID": 14, "context": "We used the 3D CNN trained on Sports-1M dataset [15] which had 487 classes.", "startOffset": 48, "endOffset": 52}, {"referenceID": 16, "context": "To find the structure matrix S, we computed the correlation between tasks by finding an initial normalized coefficient matrix W using lasso with least square loss function and followed by computing the correlation coefficient matrix [17].", "startOffset": 233, "endOffset": 237}, {"referenceID": 18, "context": "Table 1 shows the comparison of our proposed Multi-task learning method with GIST features [20] +LASSO and 3D CNN Multi-task learning with trace norm.", "startOffset": 91, "endOffset": 95}, {"referenceID": 19, "context": "hood embedding (t-SNE) [21].", "startOffset": 23, "endOffset": 27}, {"referenceID": 20, "context": "It has been found that the combination of PET and CT can improve the diagnostic accuracy of solitary lung nodules [22].", "startOffset": 114, "endOffset": 118}], "year": 2017, "abstractText": "Risk stratification of lung nodules is a task of primary importance in lung cancer diagnosis. Any improvement in robust and accurate nodule characterization can assist in identifying cancer stage, prognosis, and improving treatment planning. In this study, we propose a 3D Convolutional Neural Network (CNN) based nodule characterization strategy. With a completely 3D approach, we utilize the volumetric information from a CT scan which would be otherwise lost in the conventional 2D CNN based approaches. In order to address the need for a large amount for training data for CNN, we resort to transfer learning to obtain highly discriminative features. Moreover, we also acquire the task dependent feature representation for six high-level nodule attributes and fuse this complementary information via a Multi-task learning (MTL) framework. Finally, we propose to incorporate potential disagreement among radiologists while scoring different nodule attributes in a graph regularized sparse multi-task learning. We evaluated our proposed approach on one of the largest publicly available lung nodule datasets comprising 1018 scans and obtained state-of-the-art results in regressing the malignancy scores.", "creator": "LaTeX with hyperref package"}}}