{"id": "1705.07318", "review": {"conference": "arxiv", "VERSION": "v1", "DATE_OF_SUBMISSION": "20-May-2017", "title": "Formalized Lambek Calculus in Higher Order Logic (HOL4)", "abstract": "in temporal dimension, a rather complete work - theoretical error parameter lambek fraction ( non - associative minimum arbitrary length ) has survived granted from coq / assistent to turing theorem prover, despite some interpretations following new theorems.", "histories": [["v1", "Sat, 20 May 2017 15:04:34 GMT  (50kb)", "http://arxiv.org/abs/1705.07318v1", "37 pages"]], "COMMENTS": "37 pages", "reviews": [], "SUBJECTS": "cs.CL cs.LO", "authors": ["chun tian"], "accepted": false, "id": "1705.07318"}, "pdf": {"name": "1705.07318.pdf", "metadata": {"source": "CRF", "title": "Formalized Lambek Calculus in Higher Order Logic (HOL4)", "authors": ["Chun Tian"], "emails": ["chun.tian@studio.unibo.it"], "sections": [{"heading": null, "text": "ar X\niv :1\n70 5.\n07 31\n8v 1\n[ cs\n.C L\n] 2\n0 M\nay 2\n01 7\nThree deduction systems (Syntactic Calculus, Natural Deduction and Sequent Calculus) of Lambek Calculus are defined with many related theorems proved. The equivalance between these systems are formally proved. Finally, a formalization of Sequent Calculus proofs (where Coq has built-in supports) has been designed and implemented in HOL4. Some basic results including the subformula properties of the so-called \u201ccut-free\u201d proofs are formally proved. This work can be considered as the preliminary work towards a language parser based on category grammars which is not multimodal but still has ability to support context-sensitive languages through customized extensions."}, {"heading": "1 Introduction", "text": ""}, {"heading": "1.1 Phrase structure grammars and Chomsky Hierarchy", "text": "Roughly speaking, sentences in formal and natural languages are constructed by sequences of smaller units, i.e. phrases and words. And determining if any given sequence of phrases or words (coming from a finite lexicon of certain language) forms a grammatically correct sentence in that language, and when it\u2019s correct, finding out the \u201cstructure\u201d (and even the \u201cmeaning\u201d) of that sentence, are the central goals in both linguistics and Natural Language Processing in computer science.\nSince the year when Noam Chomsky published his famous \u201cHierarchy\u201d [1] and his work on phrase structures of English and Spanish [2] in 1950s, the concepts of context-free and context-sensitive languages (and the intemediate areas between them) with the uses of rewriting rules to represent the phrase structure grammar of any given language, has dominated the parsing theory until today.\nThe rule-based grammar for context-free languages and certain more restricted languages, together with the related parsing theory and algorithms, worked so well in handing artificial languages (formal languages and programming languages). But parsing natural languages has always been a complex and difficult area.\nThe first clue is that, natural languages are NOT context-free, although the precise statement only says: there exist some natural languages which are not context-free, and the proof is totally based on some rare phenomenons in certain languages, e.g. the so-called cross-serial dependencies in Swiss German and Dutch. For most of other natural languages, e.g. English and Italian, a proof that these languages are not context-free, doesn\u2019t exist yet. Therefore, it\u2019s quite fair to say, after ignoring some rarely used part, all natural languages can indeed be defined by context-free grammars.\nWhile it\u2019s quite common for any programming langauge compiler to use a complete, hand-written or program-generated grammar to describe their targeting language, the task of writing down all the grammar rules for a natural language, e.g. English and Italian, is incredibly hard. (Nevertherless they do exist for English). Efficiency is not a big problem (given the fact that each sentence as parsing unit is relative small, e. g.. almost always less than 100 words), ambiguities are indeed problems, but it\u2019s now generally accepted for any grammar parsing tool to output more than one possible interpretations for any given sentences (then there\u2019re higher level linguistic theories to help disambiguiting them).\nThe real problem is, the grammar rules for each languages are so different, none of rewriting rules can be considered as universal to all human languages. For example, one may think that all sentences have a Noun Phrase (NP) followed by a Verb Phrase (VP) at top level, e.g. in the Italian sentence \u201cmolti esperti arriveranno\u201d, NP is \u201cmolti esperti\u201d and VP is \u201carriverranno\u201d. But in Italian one can also put the subject after the verb and say \u201carriveranno esperti\u201d instead. If we have to maintain the order between NP and VP, then this new sentence must be interpreted in a different way (see p. 33 of [3]) with an\nS NP\n(Molti esperti)\nVP\narriveranno\nS\nNP\n\u01eb\nVP\nV\nArriveranno\nNP\n(molti esperti)\nempty NP at the beginning (see Fig 1.1). 1 . Here the main argument is, phrase structures of the two sentences shouldn\u2019t be such different when Italian speakers simply wanted to emphasize the action (Verb) by speaking that word first. But within the framework of Chomksy, such complexity is inevitable.\nChomsky further developped his phrase structure theory into a more complex theory called \u201cGovernment and Binding\u201d (GB) in 1990s, and by distinguishing the so-called surface structure and deep structure, different speaking ways of the same sentence now can be finally turned into the same structure. This new GB theory is dedicated for parsing only natural languages, but the attepmts to find evidences for the existence of universal grammars failed again.\nSeveral years later, Chomsky almost completely abandoned GB theory and turned into the \u201cMinimalist Program\u201d, which this new grammar theory is much simplier than GB theory while is still capable to analyze the phrase structure of context-sensitive languages."}, {"heading": "1.2 Categorial Grammars and Lambek Calculus", "text": "On the other side, different grammar theories have been introduced in parallel. One of them is the so-called Categorial Grammar.\nCategorial Grammar was firstly introduced by Polish philosopher and logician Kazimierz Ajdukiewicz in 1935 [4], which is based on ideas from precedent Polish logicians. In this whole new grammar system, Ajdukiewicz assigned each word (or lexical entry) a \u201ccategory\u201d which is defined inductively:\n1. Basic categories. The two primitive types n (for entities or individuals or first order terms) and s (for propositions or truth values) are categories. 2. Functor categorites. Whenever N is a category and D1, . . . , Dn is a sequence or multiset of categories,\nthen N\nD1 \u00b7 \u00b7 \u00b7Dn is itself a category.\nTo decide the category of syntactically connected expressions, the following rules are used:\n1. a word or lexical entry is syntactically connected, and its category is the basic their assigned category, 2. given n syntactically connected expressions d1, . . . , dn of respective categoriesD1, . . . , Dn, and an ex-\npression f of category N\nD1 \u00b7 \u00b7 \u00b7Dn , the expression fd1 \u00b7 \u00b7 \u00b7 dn (or any permutation of it!) is syntactically\nconnected and has category N .\nThere\u2019re two notable observations about Ajdukiewicz\u2019s categorial grammar:\n1. The calculus of categorites works just like elementary arithmetics: functor categorites are divisions of categories, and syntactic connections are multiplications of categories. Thus if one word has category A\nB , the other has category B, their connecion has category\nA B \u00b7 B = A.\n2. Although the original purpose of the grammar is to check logical formulae in Polish notation, in which the word order is not really a problem, but we can imagine that, for highly inflected languages like Latin and Sanskrit, which has rather flexible word orders, this category grammar may result into quite compat while still correct grammars (for at least a small portion). Nevertheless it\u2019s impossible to handle English.\nIn 1953, just two years before Chomsky published his phrase structure grammar theory and the famous hierarchy, Israeli philosopher, mathematician, and linguist Yehoshua Bar-Hillel made an important enhancement [5] to Ajdukiewicz\u2019s categorial grammar. The resulting new categorial grammar is now called Ajdukiewicz-Bar grammar or AB grammar.\n1 Relaxing the order of NP and VP in the grammar is not an option, because it will be illegal in English\nIn AB grammar, word orders are now respected, and the single \u201cdivision\u201d operator in categories are\nnot divided into two different directions, i.e. A\nB now becomes A/B (read as \u201cA over B\u201d) and A\\B (read\nas \u201cB under A\u201d, and the syntactic connections cannot be permutated with changing the overall category, i.e. in general, AB 6= BA. In formal languages, the so-called category is defined as follows:\nC ::= P | (C/C) | (C \\ C)\nwhere P is a basic category usually containing S (for sentences) and np (for noun phrases) and n (for nouns). And the only rules in this grammar systems are, \u2200u, v \u2208 C,\nu(u \\ v) \u2212\u2192 v (\\e)\n(v/u)u \u2212\u2192 v (/e)\nAlthough AB grammar system looks quite simple, it\u2019s proved that AB grammar is weakly equivalent to a corresponding context-free grammar, and there\u2019re algorithms to learn AB grammars from parsing results. [6]. However, having only elimination rules, it\u2019s impossible to derive fomulae like (x/y)(y/z) \u2212\u2192 (x/z), because the only purposes of the rules is to reduce two categories into a small one, which is part of the two categories. AB grammar is just a rule-based system but formal system.\nFinally, in 1958, Joachim Lambek [7] succesfully defined a formal system for syntactic calculus in which all category formulae can be derived from a basic set of rules (as axioms) and basic logic formulae. It\u2019s later called (Associative) Lambek Calculus, or L. In Lambek Calculus, now the syntactic connections are representated explicitly by a new connective \u201cdot\u201d (\u00b7) and the associativity (A \u00b7B) \u00b7 C = A \u00b7 (B \u00b7 C) is assumed as axiom (or rule). Thus, the category in Lambek calculus is defined as follows:\nL ::= P | (L/L) | (L \\ L) | L \u00b7 L\nwhere P is a basic category. Lambek introduced a relation \u2192 and use x \u2192 y to indicate that any expression (string of words) of type (or category) x also has type y, and the following rules were used as axioms of the formal system:\n(a) x \u2192 x; (b) (x \u00b7 y) \u00b7 z \u2192 x \u00b7 (y \u00b7 z); (b\u2019) x \u00b7 (y \u00b7 z) \u2192 (x \u00b7 y) \u00b7 z; (c) if x \u00b7 y \u2192 z, then x \u2192 z/y; (c\u2019) if x \u00b7 y \u2192 z, then y \u2192 x \\ z; (d) if x \u2192 z/y, then x \u00b7 y \u2192 z; (d\u2019) if y \u2192 x \\ z, then x \u00b7 y \u2192 z; (e) if x \u2192 y and y \u2192 z, then x \u2192 z.\nHere are a few observations about Lambek Calculus:\n1. Although Lambek calculues has more rules then AB grammar, but they\u2019re actually equivalent: \u201ca set of strings of words forms a categorial language of one type if and only if it forms a categorial language of the other type\u201d [8]; 2. The \u2192 relation is reflexisive (by (a)) and transitive (by (e)), but it\u2019s not symmetric, i.e. in general x \u2192 y ; y \u2192 x, thus it\u2019s not an equivalence relation at all. 3. The dot (\u00b7) connective usually doesn\u2019t appears in the lexion, in which each word is associated with one or more categories which is made by only basic categories and two connectives slash (/) and backslash (\\). 4. Lambek calculus can only be used to decide if a given string of words has a specific category (e. g. the category of a legal sentence, S), the phrase structure, however, is not immediately known. 5. Lambek calculus has a decision procedure through Gentzen\u2019s Sequent Calculus and the corresponding Cut-elimination theorem. This was proved by Lambek (1958) [7]. 6. Lambek calculus is NP-complete [9], L-complete [10], and Lambek grammars are context-free [11].\nAmong other issues, to resolve the key limitation that Lambek calculus cannot be used as a language parser, in 1961, Lambek introduced the so-called Non-associative Lambek Calculus [12], or NL. There\u2019re two major modifications comparing to previous associative Lambek Calculus:\n1. The associative rule (b) and (b\u2019) have been removed from axiom rules, and all theorems derivated from them are not derivable any more. It\u2019s found that such changes also removed some strange non-language sentences which are acceptable before.\n2. To decide the category of a sentence, now the first step is to put all the words into a binary tree with the original order respected, i. e. the bracketing process, then applications of inference rules are limited at each tree node.\nUsing as a language parser, non-associative Lambek Calculus works in this way: for any given string of words, if there exists a bracketing such that the resulting category is the target category (e. g. S), then it\u2019s grammatically correct and the corresponding binary tree represent the phrase structures, with the category of each node representing the phrase structure at different levels. It\u2019s proven that nonassociative Lambek Calculus also has a decision procedure, which surprisingly is polynomial. And for product-free NL (there\u2019s no dots in lexicon), the parsing process is also polynomial. (see Chapter 4.6 of [6] for detailed discussions and links tooriginal papers)\nBeside L and NL, there\u2019s also NLP in which the commutativity of products is respect based on NL, i. e. x \u00b7y = y \u00b7x. With such assumption, the resulting grammar is quite similar to the original Ajdukiewicz grammar. When both commutativity and associativity are respected, the resulting Lambek calculus is called LP."}, {"heading": "1.3 Categorial grammars and universal grammar", "text": "Chomsky believes that there\u2019s an innate universal grammar in human mind, and when children start learning languages from very limited vocabulary and extremely incomplete corpus (where machine learning is impossible to converge), what they actually do is to adapt this universal grammar to their mother languages. However, from Chomsky\u2019s phrase structure theory and the related grammars based on rewriting rules, terminals and non-terminals, we can\u2019t see any evidence for the existence of Universal gammars.\nOn the other side, in Categorial grammars we see two separated parts:\n1. Language independent part: the inference rules for categories; 2. Language dependent part: the lexicon.\nTherefore, if we treat the first part at \u201cunversal grammar\u201d, what remains to be learn by children (and machine learning program), is just the lexion which associates words to their syntactic categories (which then indicate how a word gets used in this language) and their meanings. This connection (to universal grammars) has made Category Grammars quite attractive. Maybe the language parsing process based on categorial grammars are more natural and close to the natural language processing in human mind."}, {"heading": "1.4 Categorial Type Logics", "text": "Since natural language is not context-free, while either L and NL can only handle context-free languages, people seek ways to extend Lambek Calculus to support context-sensitive languages. On the other side, none of L, NL and NLP is perfect for all languages, thus people seek ways to combine different Lambek calculus and use them for different portions of the target language.\nOne such attempts is the so-called Multimodal Lambek Calculus. In this calculus system, there\u2019re many copies of category connectives, each associated with a mode index i:\nL ::= P | (L/iL) | (L \\i L) | L \u00b7i L\nDifferent versions of Lambek Calculus were identified with different mode identifiers, and properties like commutativity and associativity are respected for only connectives of certain modes. Then there\u2019s structure rules to bring different modes together. (see Chapter 5 of [6]).\nEven further extension includes the unary connectives from linear logics: \u2666 and . With all such things, the resulting calculus system has so many rules and operators, and goes far beyond Lambek Calculus, has a new name called Categorial Type Logics (CTL).\nCategorial Type Logics has the folloing characteristics:\n1. From the view of proof theory, there\u2019re still decision procedures, and the cut-elimination theorem can still be proved. However, to find the proofs for category derivations, more complex algorithms must be used (e.g. proof nets) and the time complexity is at least NP-complete. 2. From the view of model theory, CTL were proved to be sound and complete. 3. Learning CTL grammars from corpus has no known results. Given the fact that the structure of\ncategories now contains more connectives in different modes, the learning process is much harder than the normal uni-modal Lambek calculus.\nThus CTL is not quite practical so far, as one of the main authors said in his book: \u201cSo the big open question for multimodal categorial grammars is to find the \u2018right\u2019 combination of structural rules both from the point of view of being able to make the relevant linguistic generalizations and from the point of view of computational complexity.\u201d. (page. 184 of [6])\nIn this paper, we have tried another possibility to extend Lambek Calculus. We think NL is good enough as a basis, because it\u2019s as simple as rewriting rules in context-free grammars, and it has known polinomial parsing alghrithm and reasonable learning algorithms. To handle certain context-sentive portions of the target language, we use restrictive extensions to extend the NL inference rules. These extensions, when satisfying certain restrictions, won\u2019t break the validity of existing parsing and learning algorithms while it\u2019s possible to handle context-sensitive languages."}, {"heading": "1.5 Trusted software and theorem provers", "text": "Software cannot be trusted in general, their outputs may be wrong due to either issues in their program code, or issues in the development platform in which they were written. On the other side, either operating systems or development platform (including programming languages) evolve quickly. Any program, once being written, must be maintained continuously, otherwise it soon becomes unusable.\nTherefore, we try to convince the audiences the following principles:\n1. For any research task in computer science, the last solution is to write a whole new software. Because once the research is done (or paper is published), the software may not be well maintained any more, and in a few years it\u2019s dead. 2. Choose programming languages which has long history (at least 10 years), with more than one stable implemenations. 3. Whenever possible, generate program code from higher level tools instead of writing them directly.\nOn the other side, to gurantee the correctness of algorithms or their implementations, it\u2019s preferred to use theorem provers. Many theorem proving software have the ability to generte program code from proved theorems. Coq 2 and Isabelle 3 are such examples.\nSometimes, the theorem prover itself is written as an extension to the development platform, and in this case user can continue extending the theorem prover to make the whole platform into any application software. ACL2 4 and HOL4 5 are two notable examples written in this way."}, {"heading": "1.6 Why Higher Order Logic?", "text": "Comparing to other theorem provers, the Higher Order Logic (HOL) family of theorem provers (HOL4, HOL light, Isabelle) has relatively simple logic foundation: just simple typed lambda calculus with type variables. Comparing to the logic foundation of Coq (Calculus of Inductive Construction, CIC), higier order logic is easier to understand and use, because it has few primitive derivation rules, and students who has just finished studying \u03bb-calculus (typed and untyped) could easily get started with HOL.\nHOL has also a small and verified kernel. And when HOL is implemented in Standard ML language, which is the case of HOL4 and Isabelle, the programming platform itself could be also formally verified 6\nTherefore, we choose HOL4 for several reasons:\n1. It\u2019s a theorem prover well maintained and with long history (30 years). Wigh high chances it will continue living for next 30 years, so is the proof scripts we wrote in it today. 2. The logical foundation of HOL4 is easy to understand, and the primitive inference rule set is small and clear. 3. HOL4 has a rich builtin theory library and a very large set of example code library for reference purposes. 4. The software is written as a natural extension to Standard ML programming language. The theorem prover, the proof scripts, and the tacticals, they\u2019re all written in Standard ML. In theory, user can build any customized software upon the theorem prover. Besides, the CakeML project has demonstrated how to write a formally verified programming language compiler and interpreter in HOL4.\n2 https://coq.inria.fr 3 http://isabelle.in.tum.de 4 http://www.cs.utexas.edu/users/moore/acl2/ 5 https://hol-theorem-prover.org 6 The CakeML project (https://cakeml.org) represents one such efforts.\n5. The type variable in HOL4 types are especially suited for expresing syntactic categories in Categorial Grammars. (this will be explained in next section).\nSome more differences between HOL and Coq will be discussed later, in section 6."}, {"heading": "2 Lambek Calculus in HOL4", "text": "In this project, we have implemented Lambek Calculus in HOL4. The exact variant of Lambek Calculus is NL (non-associative) with arbitrary extensions. Three deduction systems are implemented: (Axiomatic) Syntactic Calculus, Natural Deduction, and Gentzen\u2019s Sequent Calculus. 7\nThis work is based on an implementation of Lambek Calculus 8 in Coq proof assistant. In fact, our work so far can be considered as a partial porting of the Coq-based proof scripts: most definitions and theorems are from previous work, with necessary modifications. Here are some major differences:\n1. Whenever a relation can be defined as a reflexitive transivive closure (RTC) of another relation, instead of define it manuall as in Coq, now we use HOL\u2019s builtin relationTheory to define it and get the related theorems. 2. Coq\u2019s built-in support on proofs are not directly portable to HOL, therefore we defined whole new data structures and fill the gaps."}, {"heading": "2.1 Syntactic Categories", "text": "In HOL, syntactic categories are defined by an algebraic datatype Form with a type variable \u03b1:\nDatatype \u2018Form = At \u2019a | Slash Form Form | Backslash Form Form | Dot Form Form \u2018\nIn this way, all theorems we proved are actually theorem schemas in which there\u2019s always a type variable. In practice, user can either define another data structure with enumerated categories (S, n, np, . . .), or directly use strings. For example, in later mode, the basic category \u201cS\u201d can be simply represented as At \u201cS\u201d, and category \u201cS/np\u201d will be Slash (At \"S\") (At \"np\") or At \u201cS\u201d / At \u201cnp\u201d when grammar supports are enabled."}, {"heading": "2.2 Syntactic Calculus", "text": "(Axiomatic) Syntactic Calculus is a theory about the arrow relation which indicates that a string of words having the first category will also have the seoncd category, it\u2019s reflexitive and transitive. In HOL4, such a inductive relation can be easily defined by Hol_reln [13] command:\nval (arrow_rules , arrow_ind , arrow_cases ) = Hol_reln \u2018\n(!X A. arrow X A A) /\\ (!X A B C. arrow X (Dot A B) C ==> arrow X A (Slash C B)) /\\ (!X A B C. arrow X A (Slash C B) ==> arrow X (Dot A B) C) /\\ (!X A B C. arrow X (Dot A B) C ==> arrow X B (Backslash A C)) /\\ (!X A B C. arrow X B (Backslash A C) ==> arrow X (Dot A B) C) /\\ (!X A B C. arrow X A B /\\ arrow X B C ==> arrow X A C) /\\ (!(X :\u2019a arrow_extension ) A B. X A B ==> arrow X A B) \u2018;\nwhich is then broken into the following separated rules:\none:\n\u22a2 arrow X A A beta:\n\u22a2 arrow X (A \u00b7 B) C \u21d2 arrow X A (C / B) beta\u2019:\n\u22a2 arrow X A (C / B) \u21d2 arrow X (A \u00b7 B) C gamma:\n\u22a2 arrow X (A \u00b7 B) C \u21d2 arrow X B (A \\ C) gamma\u2019:\n\u22a2 arrow X B (A \\ C) \u21d2 arrow X (A \u00b7 B) C\n7 Project code can be found at https://github.com/binghe/informatica-public/tree/master/lambek 8 https://github.com/coq-contribs/lambek\ncomp:\n\u22a2 arrow X A B \u2227 arrow X B C \u21d2 arrow X A C arrow_plus:\n\u22a2 X A B \u21d2 arrow X A B\nNoticed that, the relation arrow is a 3-ary relation with the type \u201c\u03b1 arrow_extension -> \u03b1 arrow_extension\u201d, in which the type abbreviation \u201carrow extension\u201d is defined as\ntype_abbrev (\"arrow_extension \", \u2018\u2018:\u2019a Form -> \u2019a Form -> bool \u2018\u2018);\nAn arrow extension defined some extra properties beyond the basic rules. This connection was made by the arrow_plus theorem. Thus for any arrow extension X , arrow X can be considered as a normal 2-ary relation between two categories with the type \u201c\u03b1 Form\u201d.\nSince arrow extensions are nothing but normal relations, the union of two such relations can be considered as the \u201csum\u201d of two arrow extensions, and the subset/superset of relations can be considered as restrictions (or further extensions) to an arrow extension. Then, the arrow extensions of the four different Lambek Calculus, NL, L, NLP and LP are defined respectively:\n\u22a2 NL = \u22a2 (\u2200A B C. L (A \u00b7 (B \u00b7 C)) (A \u00b7 B \u00b7 C)) \u2227\n\u2200A B C. L (A \u00b7 B \u00b7 C) (A \u00b7 (B \u00b7 C)) \u22a2 NLP (A \u00b7 B) (B \u00b7 A) \u22a2 LP = add_extension NLP L\nin which EMPTY_REL represents an empty relation, and add_extension equals to the union of relations. Thus LP is nothing but a sum of NLP and L.\nThen we have proved some common theorems for all Lambek Calculus (i. e. for whatever arrow extensions):\nDot_mono_right:\n\u22a2 arrow X B \u2032 B \u21d2 arrow X (A \u00b7 B \u2032) (A \u00b7 B) Dot_mono_left:\n\u22a2 arrow X A\u2032 A \u21d2 arrow X (A\u2032 \u00b7 B) (A \u00b7 B) Dot_mono:\n\u22a2 arrow X A C \u2227 arrow X B D \u21d2 arrow X (A \u00b7 B) (C \u00b7 D) Slash_mono_left:\n\u22a2 arrow X C \u2032 C \u21d2 arrow X (C \u2032 / B) (C / B) Slash_antimono_right:\n\u22a2 arrow X B \u2032 B \u21d2 arrow X (C / B) (C / B \u2032) Backslash_antimono_left:\n\u22a2 arrow X A A\u2032 \u21d2 arrow X (A\u2032 \\ C) (A \\ C) Backslash_mono_right:\n\u22a2 arrow X C \u2032 C \u21d2 arrow X (A \\ C \u2032) (A \\ C)\nThe monotonity of arrow relation with respect to arrow extensions is proved too (by induction on all basic arrow rules):\nmono_X:\n\u22a2 arrow X A B \u21d2 extends X X \u2032 \u21d2 arrow X \u2032 A B\nFor Lambek extensions supporting permutations, the following theorems are proved:\npi:\n\u22a2 extends NLP X \u21d2 \u2200A B. arrow X (A \u00b7 B) (B \u00b7 A) pi_NLP:\n\u22a2 arrow NLP (A \u00b7 B) (B \u00b7 A) pi_LP:\n\u22a2 arrow LP (A \u00b7 B) (B \u00b7 A)\nFor Lambek extensions supporting associativity, the following theorems are proved:\nalfa:\n\u22a2 extends L X \u21d2 \u2200A B C. arrow X (A \u00b7 (B \u00b7 C)) (A \u00b7 B \u00b7 C)\nalfa\u2019:\n\u22a2 extends L X \u21d2 \u2200A B C. arrow X (A \u00b7 B \u00b7 C) (A \u00b7 (B \u00b7 C)) alfa_L:\n\u22a2 arrow L (A \u00b7 (B \u00b7 C)) (A \u00b7 B \u00b7 C) alfa\u2019_L:\n\u22a2 arrow L (A \u00b7 B \u00b7 C) (A \u00b7 (B \u00b7 C)) alfa_LP:\n\u22a2 arrow LP (A \u00b7 (B \u00b7 C)) (A \u00b7 B \u00b7 C) alfa\u2019_LP:\n\u22a2 arrow LP (A \u00b7 B \u00b7 C) (A \u00b7 (B \u00b7 C))"}, {"heading": "2.3 Associative Lambek Calculus", "text": "For the original associative Lambek Calculus, we have proved all arrow theorems mentioned in Lambek (1958) [7]. All these theorems are named as L_ plus single letters (with optional prim). The first five are L axioms (but actually they\u2019re proved from previous definition on the arrow relation:\nL_a: \u22a2 arrow L x x L_b: \u22a2 arrow L (x \u00b7 y \u00b7 z) (x \u00b7 (y \u00b7 z)) L_b\u2019: \u22a2 arrow L (x \u00b7 (y \u00b7 z)) (x \u00b7 y \u00b7 z) L_c: \u22a2 arrow L (x \u00b7 y) z \u21d2 arrow L x (z / y) L_c\u2019: \u22a2 arrow L (x \u00b7 y) z \u21d2 arrow L y (x \\ z) L_d: \u22a2 arrow L x (z / y) \u21d2 arrow L (x \u00b7 y) z L_d\u2019: \u22a2 arrow L y (x \\ z) \u21d2 arrow L (x \u00b7 y) z L_e: \u22a2 arrow L x y \u2227 arrow L y z \u21d2 arrow L x z\nBased on these axioms, the rest L theorems about arrow relations can easily be proved by automatic first-order proof searching:\nL_f: \u22a2 arrow L x (x \u00b7 y / y) L_g: \u22a2 arrow L (z / y \u00b7 y) z L_h: \u22a2 arrow L y ((z / y) \\ z) L_i: \u22a2 arrow L (z / y \u00b7 (y / x)) (z / x) L_j: \u22a2 arrow L (z / y) (z / x / (y / x)) L_k: \u22a2 arrow L (x \\ y / z) (x \\ (y / z)) L_k\u2019: \u22a2 arrow L (x \\ (y / z)) (x \\ y / z) L_l: \u22a2 arrow L (x / y / z) (x / (z \u00b7 y)) L_l\u2019: \u22a2 arrow L (x / (z \u00b7 y)) (x / y / z) L_m: \u22a2 arrow L x x \u2032 \u2227 arrow L y y \u2032 \u21d2 arrow L (x \u00b7 y) (x \u2032 \u00b7 y \u2032) L_n: \u22a2 arrow L x x \u2032 \u2227 arrow L y y \u2032 \u21d2 arrow L (x / y \u2032) (x \u2032 / y)\nFinally, the monotone theorems specific to L are proved:\nL_dot_mono_r:\n\u22a2 arrow L B B \u2032 \u21d2 arrow L (A \u00b7 B) (A \u00b7 B \u2032) L_dot_mono_l:\n\u22a2 arrow L A A\u2032 \u21d2 arrow L (A \u00b7 B) (A\u2032 \u00b7 B) L_slash_mono_l:\n\u22a2 arrow L C C \u2032 \u21d2 arrow L (C / B) (C \u2032 / B) L_slash_antimono_r:\n\u22a2 arrow L B B \u2032 \u21d2 arrow L (C / B \u2032) (C / B) L_backslash_antimono_l:\n\u22a2 arrow L A A\u2032 \u21d2 arrow L (A\u2032 \\ C) (A \\ C) L_backslash_mono_r:\n\u22a2 arrow L C C \u2032 \u21d2 arrow L (A \\ C) (A \\ C \u2032)\nThe main problem of axiomatic syntactic calculus is that, for complicated categories, it\u2019s not easy to \u201cfind\u201d the proofs. Automatic proof searching also doesn\u2019t work here, because the searching space is infinite. Further more, the arrow relation is not a reduction, because there\u2019s no congruence here: if a sub-formula is known to have another category, we can\u2019t just replace that sub-formula and expect the whole formula still has the same category. Thus in practice, we have to use other deduction systems which is more convinence for manual proofs or automatic proofs. But for what ever other deduction systems, to be useful they must be proved to be equivalent with Syntactic calculus."}, {"heading": "2.4 Natural Deduction for Lambek Calculus", "text": "Natural deduction was first invented by Dag Prawitz [14] as a non-semantic approach to derive propositional logic formulae.9 From a structure view, Natural deduction is nothing but a group of inference rules, each concerns about the introduction or eliminatiob of a logic connective. Natural deduction is indeed natural: it\u2019s successfully adopted in hand-proofs and also the primitive deduction systems of many theorem provers.\nNatural deduction has two styles, the original Prawitz style and the Gentzen style (which is borrowed from Genzen\u2019s Sequent Calculus, we\u2019ll talk about this in next section). The two styles are not totally equivalent in expressive power, sometimes the Prawitz style is unnatural to express certain logic extensions. Thus, in Lambek Calculus, most of time, only the Gentzen style of Natural Deduction is used, and when we\u2019re talking \u201cNatural deduction\u201d in this paper, we always refer to its Gentzen style.\nThe basic unit in Natural Deduction (in Gentzen style) is based on the concept of Sequent which represents a statement of the calculus in the following form:\nA1, A2, . . . , An \u22a2 C\nIf we think the whole statement as a theorem, then C is the conclusion, and A1, A2, . . . , An is a list of hypotheses or assumptions in which their orders are irrelevant. In terminalogy of sequents, such a list is called the antecedent, or the hypotheses of the statement. The purpose of inference rules is to derive new statements from existing statements.\nTo adopt Natural Deduction for Lambek Calculus, especially the non-associative version, two steps are done here:\n1. The arrow relation between two categories, i.e. A \u2212\u2192 B, is now represented by logic theorem A \u21d2 B, and then a sequent A \u22a2 B, which means by assuming A we can prove B. 2. A sentence as a string of categories of each words, is now represented as the antecedentsA1, A2, . . . , An of a sequent. However, now the order is essential (for Lambek calculus without P). And for Lambek calculus based on NL, the binary bracketing is also necessary.\nTo represent sentence structures as binary trees, a new data structure called Term is now defined in HOL4:\nDatatype \u2018Term = OneForm (\u2019a Form ) | Comma Term Term \u2018;\nNotice the similarity between the Comma connective between two Terms and the Dot connective between two Forms. In fact, most of times they\u2019re convertable from each others, but it\u2019s Comma representing the boundary of categories of words. To translate a Term into Form, a recursive function called deltaTranslation is defined as follows10:\n\u22a2 (\u2200 f . deltaTranslation (OneForm f ) = f ) \u2227 \u2200 t1 t2. deltaTranslation (Comma t1 t2) = deltaTranslation t1 \u00b7 deltaTranslation t2\nSimiar to arrow extensions, which is a 2-ary relation between Terms, now we have another kind of extensions, called Sequent extensions or gentzen_extension, which is again abbreviated type as 2-ary relation between Terms:\ntype_abbrev (\"gentzen_extension \", \u2018\u2018:\u2019a Term -> \u2019a Term -> bool \u2018\u2018);\nSequent extensions for L, NL, NLP and LP are defined as follows:\n\u22a2 NL_Sequent = \u22a2 NLP_Sequent (Comma A B) (Comma B A) \u22a2 (\u2200A B C.\nL_Sequent (Comma A (Comma B C)) (Comma (Comma A B) C)) \u2227 \u2200A B C. L_Sequent (Comma (Comma A B) C) (Comma A (Comma B C))\n\u22a2 LP_Sequent = add_extension NLP_Sequent L_Sequent\n9 the semantic approach is to build a truth table to explicitly check if the given formula is true for all possible combinations of boolean values for each variables\n10 The reverse translation is not unique, and it\u2019s not needed to have such translations.\nTo define the inference rules for Natural Deduction, we still need one more device: the ability to replace the sub-formula of a Term into another Term:\n\u22a2 (\u2200F1 F2. replace F1 F2 F1 F2) \u2227 (\u2200Gamma1 Gamma2 Delta F1 F2.\nreplace Gamma1 Gamma2 F1 F2 \u21d2 replace (Comma Gamma1 Delta) (Comma Gamma2 Delta) F1\nF2) \u2227 \u2200Gamma1 Gamma2 Delta F1 F2. replace Gamma1 Gamma2 F1 F2 \u21d2 replace (Comma Delta Gamma1) (Comma Delta Gamma2) F1 F2\nTherefore when replace A B C D is true, it means in Term A, there\u2019s a sub-formula C, and by replacing it with D, we obtain B. In many papers, the Term A is actually A[C], and B is written as A[D].\nRelated to replace, if the goal is to just replace some Commas into Dots, there\u2019s a simplified relation called replaceCommaDot. To define it, we first define its one-step version is called replaceCommaDot1:\n\u22a2 replace T1 T2 (Comma (OneForm A) (OneForm B)) (OneForm (A \u00b7 B)) \u21d2\nreplaceCommaDot1 T1 T2\nThen replaceCommaDot is nothing but the RTC of replaceCommaDot1:\n\u22a2 replaceCommaDot = replaceCommaDot1\u2217\nTo make these replace operators actually useful, we have proved many theorems about them (some have complicated proofs):\nreplaceTransitive\u2019:\n\u22a2 replaceCommaDot T1 T2 \u2227 replaceCommaDot T2 T3 \u21d2 replaceCommaDot T1 T3\nreplaceCommaDot_rules:\n\u22a2 (\u2200T. replaceCommaDot T T) \u2227 (\u2200T1 T2 A B.\nreplace T1 T2 (Comma (OneForm A) (OneForm B)) (OneForm (A \u00b7 B)) \u21d2\nreplaceCommaDot T1 T2) \u2227 (\u2200T1 T2 T3 A B.\nreplaceCommaDot T1 T2 \u2227 replace T2 T3 (Comma (OneForm A) (OneForm B)) (OneForm (A \u00b7 B)) \u21d2\nreplaceCommaDot T1 T3) \u2227 \u2200T1 T2 T3 A B. replace T1 T2 (Comma (OneForm A) (OneForm B)) (OneForm (A \u00b7 B)) \u2227 replaceCommaDot T2 T3 \u21d2\nreplaceCommaDot T1 T3 replaceMonoRight:\n\u22a2 replaceCommaDot T1 T2 \u21d2 replaceCommaDot (Comma T1 T3) (Comma T2 T3)\nreplaceMonoLeft:\n\u22a2 replaceCommaDot T1 T2 \u21d2 replaceCommaDot (Comma T3 T1) (Comma T3 T2)\nreplaceMono:\n\u22a2 replaceCommaDot T1 T2 \u2227 replaceCommaDot T3 T4 \u21d2 replaceCommaDot (Comma T1 T3) (Comma T2 T4)\nreplaceTranslation:\n\u22a2 replaceCommaDot T (OneForm (deltaTranslation T)) replace_inv1:\n\u22a2 replace (OneForm C) Gamma\u2032 (OneForm X ) Delta \u21d2 (Gamma\u2032 = Delta) \u2227 (X = C)\nreplace_inv2:\n\u22a2 replace (Comma Gamma1 Gamma2) Gamma \u2032 (OneForm X ) Delta \u21d2\n(\u2203G. (Gamma\u2032 = Comma G Gamma2) \u2227 replace Gamma1 G (OneForm X ) Delta) \u2228 \u2203G. (Gamma\u2032 = Comma Gamma1 G) \u2227 replace Gamma2 G (OneForm X ) Delta\ndoubleReplace:\n\u22a2 replace Gamma Gamma\u2032 T1 T2 \u21d2 \u2200Gamma2 A T3. replace Gamma\u2032 Gamma2 (OneForm A) T3 \u21d2 (\u2203G.\nreplace Gamma G (OneForm A) T3 \u2227 replace G Gamma2 T1 T2) \u2228\n\u2203G. replace T2 G (OneForm A) T3 \u2227 replace Gamma Gamma2 T1 G\nreplaceSameP:\n\u22a2 replace T1 T2 T3 T4 \u21d2 \u2200G. \u2203G \u2032. replace T1 G \u2032 T3 G \u2227 replace G \u2032 T2 G T4\nreplaceTrans:\n\u22a2 replace T1 T2 T3 T4 \u21d2 replace T3 T4 T5 T6 \u21d2 replace T1 T2 T5 T6\nThe replace theorems about three deduction systems are more difficult to prove:\nreplace_arrow:\n\u22a2 replace Gamma Gamma\u2032 T1 T2 \u21d2 arrow X (deltaTranslation T2) (deltaTranslation T1) \u21d2 arrow X (deltaTranslation Gamma\u2032) (deltaTranslation Gamma)\nreplace_arrow\u2019:\n\u22a2 replace Gamma Gamma\u2032 T1 T2 \u21d2 arrow X (deltaTranslation T2) (deltaTranslation T1) \u21d2 arrow X (deltaTranslation Gamma) C \u21d2 arrow X (deltaTranslation Gamma\u2032) C\nreplaceGentzen:\n\u22a2 replace Gamma Gamma\u2032 Delta Delta\u2032 \u21d2 gentzenSequent E Delta\u2032 (deltaTranslation Delta) \u21d2 gentzenSequent E Gamma\u2032 (deltaTranslation Gamma)\nreplaceGentzen\u2019:\n\u22a2 replace Gamma Gamma\u2032 Delta Delta\u2032 \u2227 gentzenSequent E Delta\u2032 (deltaTranslation Delta) \u2227 gentzenSequent E Gamma C \u21d2 gentzenSequent E Gamma\u2032 C\nreplaceNatDed:\n\u22a2 replace Gamma Gamma\u2032 Delta Delta\u2032 \u21d2 natDed E Delta\u2032 (deltaTranslation Delta) \u21d2 natDed E Gamma\u2032 (deltaTranslation Gamma)\nNow we use natDed E Gamma A to represent Gamma \u22a2 A under extension E. The type of natDed is \u201c\u03b1 gentzen_extension -> \u03b1 Term -> \u03b1 Form -> bool\u201d. And the inference rules about Natural Deduction on Lambek Calculus are defined by an inductive relation and then broken into the following separated rules:\nNatAxiom:\n\u22a2 natDed E (OneForm A) A SlashIntro:\n\u22a2 natDed E (Comma Gamma (OneForm B)) A \u21d2 natDed E Gamma (A / B)\nBackslashIntro:\n\u22a2 natDed E (Comma (OneForm B) Gamma) A \u21d2 natDed E Gamma (B \\ A)\nDotIntro:\n\u22a2 natDed E Gamma A \u2227 natDed E Delta B \u21d2 natDed E (Comma Gamma Delta) (A \u00b7 B)\nSlashElim:\n\u22a2 natDed E Gamma (A / B) \u2227 natDed E Delta B \u21d2 natDed E (Comma Gamma Delta) A\nBackslashElim:\n\u22a2 natDed E Gamma B \u2227 natDed E Delta (B \\ A) \u21d2 natDed E (Comma Gamma Delta) A\nDotElim:\n\u22a2 replace Gamma Gamma\u2032 (Comma (OneForm A) (OneForm B)) Delta \u2227 natDed E Delta (A \u00b7 B) \u2227 natDed E Gamma C \u21d2 natDed E Gamma\u2032 C\nNatExt:\n\u22a2 replace Gamma Gamma\u2032 Delta Delta\u2032 \u2227 E Delta Delta\u2032 \u2227 natDed E Gamma C \u21d2 natDed E Gamma\u2032 C\nThese natural deduction rules are quite similar with those arrow rules of Syntactic Calculus. And the elimination rules SlashElim and BackslashElim are even more close to AB grammar rules. Besides, replace operations only appear in DotElim and NatExt rules. All these characteristics made natural deduction easier to use for proving facts about Lambek Calculus.\nWe have proved a few theorems as simplified version of above primitive rules, sometimes it\u2019s easier to use them instead of the primitive rules:\nNatAxiomGeneralized:\n\u22a2 natDed E Gamma (deltaTranslation Gamma) DotElimGeneralized:\n\u22a2 replaceCommaDot Gamma Gamma\u2032 \u21d2 natDed E Gamma C \u21d2 natDed E Gamma\u2032 C\nNatTermToForm:\n\u22a2 natDed E Gamma C \u21d2 natDed E (OneForm (deltaTranslation Gamma)) C\nNatExtSimpl:\n\u22a2 E Gamma Gamma\u2032 \u2227 natDed E Gamma C \u21d2 natDed E Gamma\u2032 C\nThe main problem for Natural Deduction is the lacking of decision procedures. When proving any theorem in backward way, one has to \u201cguess\u201d many unknown variables to correctly apply those elimination rules. To see this, let\u2019s take a look at one elimination rules, e. g. SlashElim:\n\u22a2 natDed E Gamma (A / B) \u2227 natDed E Delta B \u21d2 natDed E (Comma Gamma Delta) A\nIn this rule, variable B only appears in the antecedents but the conclusion, and when applying this rule from backwards, we have to guess out the value of B, and different values of B may completely change the rest proofs (only the correct guess can lead to a success proof). Thus, automatic proof searching based on these Natural deduction rules are impossible. But if our final goal is to get a langauge parser, we have to have a more reasonable set of rules in which there\u2019s essential no guess (this is the so-called \u201csub-formula property\u201d in sequent calculus, we\u2019ll get to this property later).\nThus, to make both manual proving and automatic proof searching possible, now we represent the final solution for the inference system of Lambek Calculus: the Gentzen\u2019s Sequent Calculus."}, {"heading": "2.5 Gentzen\u2019s Sequent Calculus for Lambek Calculus", "text": "Sequent Calculus was original introduced by Gerhard Gentzen in two German papers [15] [16] written in 1935. It\u2019s a great achievements in the proof theory of classical and intuitionistic logic. To understnad its\ndifference with Natural Deduction, it\u2019s better to watch directly the inference rules for Lambek Calculus. In our implementation, the Sequent Calculus is defined through an inductive definition of the relation gentzenSequent which has the same type as previous natDed relation. Here are its inference rules:\nSeqAxiom:\n\u22a2 gentzenSequent E (OneForm A) A RightSlash:\n\u22a2 gentzenSequent E (Comma Gamma (OneForm B)) A \u21d2 gentzenSequent E Gamma (A / B)\nRightBackslash:\n\u22a2 gentzenSequent E (Comma (OneForm B) Gamma) A \u21d2 gentzenSequent E Gamma (B \\ A)\nRightDot:\n\u22a2 gentzenSequent E Gamma A \u2227 gentzenSequent E Delta B \u21d2 gentzenSequent E (Comma Gamma Delta) (A \u00b7 B)\nLeftSlash:\n\u22a2 replace Gamma Gamma\u2032 (OneForm A) (Comma (OneForm (A / B)) Delta) \u2227\ngentzenSequent E Delta B \u2227 gentzenSequent E Gamma C \u21d2 gentzenSequent E Gamma\u2032 C\nLeftBackslash:\n\u22a2 replace Gamma Gamma\u2032 (OneForm A) (Comma Delta (OneForm (B \\ A))) \u2227\ngentzenSequent E Delta B \u2227 gentzenSequent E Gamma C \u21d2 gentzenSequent E Gamma\u2032 C\nLeftDot:\n\u22a2 replace Gamma Gamma\u2032 (Comma (OneForm A) (OneForm B)) (OneForm (A \u00b7 B)) \u2227 gentzenSequent E Gamma C \u21d2\ngentzenSequent E Gamma\u2032 C CutRule:\n\u22a2 replace Gamma Gamma\u2032 (OneForm A) Delta \u2227 gentzenSequent E Delta A \u2227 gentzenSequent E Gamma C \u21d2 gentzenSequent E Gamma\u2032 C\nSeqExt:\n\u22a2 replace Gamma Gamma\u2032 Delta Delta\u2032 \u2227 E Delta Delta\u2032 \u2227 gentzenSequent E Gamma C \u21d2 gentzenSequent E Gamma\u2032 C\nComparing with Natural Deduction rules, the following differences are notable:\n1. For each of the three connectives (\u00b7, / and \\), there\u2019re Left and Right rules for them; For Natural deduction, instead they\u2019re Introduction and Elimination rules. 2. Except for the different relation name, the rule SeqAxiom is the same as NatAxiom, RightSlash is the same as SlashIntro, RightBackslash is the same as BackslashIntro, RightDot is the same as DotIntro, and finally the rule SeqExt is the same as NatExt. 3. All Left rules are new, and they all make use of the replace predicates. And the result of these rules is to introduce one of the three connectives in the antecedents without changing the conclusion. 4. The rule CutRule is new in Sequent Calculus, it\u2019s not present in Natural Deduction, nor can be proved in Natural Deduction.\nBeside above observations, there\u2019s one more important fact:\n\u2013 All rules except for CutRule satisfy the so-called \u201csub-formula property\u201d, that is, all variables in the antecedents are sub-formulae of the conclusion.\nTo see why this is true, let\u2019s take a deeper look at LeftSlash:\n\u22a2 replace Gamma Gamma\u2032 (OneForm A) (Comma (OneForm (A / B)) Delta) \u2227\ngentzenSequent E Delta B \u2227 gentzenSequent E Gamma C \u21d2 gentzenSequent E Gamma\u2032 C\nIf we consider the meaning of replace, we may rewrite this rule into the following form:\nDelta \u22a2 B Gamma[A] \u22a2 C (LeftSlash)\nGamma[(A/B,Delta)] \u22a2 C\nTo some extents, this rule is just saying A/B \u00b7 B \u2192 A as in AB grammar. What\u2019s more important is the fact that, all variables appearing in the conclusion, i.e. Gamma, A, B, Delta and C, are variables borrowing from antecedents. The same fact is true for all other gentzenSequent rules, except for CutRule:\nDelta \u22a2 A Gamma[A] \u22a2 C (CutRule)\nGamma[Delta] \u22a2 C\nin which the variable A appears only in antecedents but conclusion. The sub-formula property is extremely useful for automatic proof searching, because there\u2019s nothing to guess when applying these rules from backwards. Based on above primitive inference rules, we have proved a large amount of derived theorems which is true for all Lambek calculus (i. e. extended from NL):\nSeqAxiomGeneralized:\n\u22a2 gentzenSequent E Gamma (deltaTranslation Gamma) LeftDotSimpl:\n\u22a2 gentzenSequent E (Comma (OneForm A) (OneForm B)) C \u21d2 gentzenSequent E (OneForm (A \u00b7 B)) C\nLeftDotGeneralized:\n\u22a2 replaceCommaDot T1 T2 \u21d2 gentzenSequent E T1 C \u21d2 gentzenSequent E T2 C\nSeqTermToForm:\n\u22a2 gentzenSequent E Gamma C \u21d2 gentzenSequent E (OneForm (deltaTranslation Gamma)) C\nLeftSlashSimpl:\n\u22a2 gentzenSequent E Gamma B \u2227 gentzenSequent E (OneForm A) C \u21d2 gentzenSequent E (Comma (OneForm (A / B)) Gamma) C\nLeftBackslashSimpl:\n\u22a2 gentzenSequent E Gamma B \u2227 gentzenSequent E (OneForm A) C \u21d2 gentzenSequent E (Comma Gamma (OneForm (B \\ A))) C\nCutRuleSimpl:\n\u22a2 gentzenSequent E Gamma A \u2227 gentzenSequent E (OneForm A) C \u21d2 gentzenSequent E Gamma C\nDotRightSlash\u2019:\n\u22a2 gentzenSequent E (OneForm A) (C / B) \u21d2 gentzenSequent E (OneForm (A \u00b7 B)) C\nDotRightBackslash\u2019:\n\u22a2 gentzenSequent E (OneForm B) (A \\ C) \u21d2 gentzenSequent E (OneForm (A \u00b7 B)) C\nSeqExtSimpl:\n\u22a2 E Gamma Gamma\u2032 \u2227 gentzenSequent E Gamma C \u21d2 gentzenSequent E Gamma\u2032 C\napplication:\n\u22a2 gentzenSequent E (OneForm (A / B \u00b7 B)) A application\u2019:\n\u22a2 gentzenSequent E (OneForm (B \u00b7 B \\ A)) A RightSlashDot:\n\u22a2 gentzenSequent E (OneForm (A \u00b7 C)) B \u21d2 gentzenSequent E (OneForm A) (B / C)\nRightBackslashDot:\n\u22a2 gentzenSequent E (OneForm (B \u00b7 A)) C \u21d2 gentzenSequent E (OneForm A) (B \\ C)\ncoApplication:\n\u22a2 gentzenSequent E (OneForm A) (A \u00b7 B / B)\ncoApplication\u2019:\n\u22a2 gentzenSequent E (OneForm A) (B \\ (B \u00b7 A)) mono_E:\n\u22a2 gentzenSequent E Gamma A \u21d2 extends E E \u2032 \u21d2 gentzenSequent E \u2032 Gamma A\nmonotonicity:\n\u22a2 gentzenSequent E (OneForm A) B \u2227 gentzenSequent E (OneForm C) D \u21d2 gentzenSequent E (OneForm (A \u00b7 C)) (B \u00b7 D)\nisotonicity:\n\u22a2 gentzenSequent E (OneForm A) B \u21d2 gentzenSequent E (OneForm (A / C)) (B / C)\nisotonicity\u2019:\n\u22a2 gentzenSequent E (OneForm A) B \u21d2 gentzenSequent E (OneForm (C \\ A)) (C \\ B)\nantitonicity:\n\u22a2 gentzenSequent E (OneForm A) B \u21d2 gentzenSequent E (OneForm (C / B)) (C / A)\nantitonicity\u2019:\n\u22a2 gentzenSequent E (OneForm A) B \u21d2 gentzenSequent E (OneForm (B \\ C)) (A \\ C)\nlifting:\n\u22a2 gentzenSequent E (OneForm A) (B / A \\ B) lifting\u2019:\n\u22a2 gentzenSequent E (OneForm A) ((B / A) \\ B)\nFor Lambek Calculus extended from L,which supports associativity, we have proved some extra theorems:\nLextensionSimpl:\n\u22a2 extends L_Sequent E \u2227 gentzenSequent E (Comma T1 (Comma T2 T3)) C \u21d2 gentzenSequent E (Comma (Comma T1 T2) T3) C\nLextensionSimpl\u2019:\n\u22a2 extends L_Sequent E \u2227 gentzenSequent E (Comma (Comma T1 T2) T3) C \u21d2 gentzenSequent E (Comma T1 (Comma T2 T3)) C\nLextensionSimplDot:\n\u22a2 extends L_Sequent E \u2227 gentzenSequent E (OneForm (A \u00b7 (B \u00b7 C))) D \u21d2 gentzenSequent E (OneForm (A \u00b7 B \u00b7 C)) D\nLextensionSimplDot\u2019:\n\u22a2 extends L_Sequent E \u2227 gentzenSequent E (OneForm (A \u00b7 B \u00b7 C)) D \u21d2 gentzenSequent E (OneForm (A \u00b7 (B \u00b7 C))) D\nmainGeach:\n\u22a2 extends L_Sequent E \u21d2 gentzenSequent E (OneForm (A / B)) (A / C / (B / C))\nmainGeach\u2019:\n\u22a2 extends L_Sequent E \u21d2 gentzenSequent E (OneForm (B \\ A)) ((C \\ B) \\ C \\ A)\nsecondaryGeach:\n\u22a2 extends L_Sequent E \u21d2 gentzenSequent E (OneForm (B / C)) ((A / B) \\ (A / C))\nsecondaryGeach\u2019:\n\u22a2 extends L_Sequent E \u21d2 gentzenSequent E (OneForm (C \\ B)) (C \\ A / B \\ A)\ncomposition:\n\u22a2 extends L_Sequent E \u21d2 gentzenSequent E (OneForm (A / B \u00b7 (B / C))) (A / C)\ncomposition\u2019:\n\u22a2 extends L_Sequent E \u21d2 gentzenSequent E (OneForm (C \\ B \u00b7 B \\ A)) (C \\ A)\nrestructuring:\n\u22a2 extends L_Sequent E \u21d2 gentzenSequent E (OneForm (A \\ B / C)) (A \\ (B / C))\nrestructuring\u2019:\n\u22a2 extends L_Sequent E \u21d2 gentzenSequent E (OneForm (A \\ (B / C))) (A \\ B / C)\ncurrying:\n\u22a2 extends L_Sequent E \u21d2 gentzenSequent E (OneForm (A / (B \u00b7 C))) (A / C / B)\ncurrying\u2019:\n\u22a2 extends L_Sequent E \u21d2 gentzenSequent E (OneForm (A / C / B)) (A / (B \u00b7 C))\ndecurrying:\n\u22a2 extends L_Sequent E \u21d2 gentzenSequent E (OneForm ((A \u00b7 B) \\ C)) (B \\ A \\ C)\ndecurrying\u2019:\n\u22a2 extends L_Sequent E \u21d2 gentzenSequent E (OneForm (B \\ A \\ C)) ((A \u00b7 B) \\ C)\nFor Lambek Calculus extended from NLP, which supports both commutativity we have proved the following extra theorems:\nNLPextensionSimpl:\n\u22a2 extends NLP_Sequent E \u2227 gentzenSequent E (Comma T1 T2) C \u21d2 gentzenSequent E (Comma T2 T1) C\nNLPextensionSimplDot:\n\u22a2 extends NLP_Sequent E \u2227 gentzenSequent E (OneForm (A \u00b7 B)) C \u21d2 gentzenSequent E (OneForm (B \u00b7 A)) C\npermutation:\n\u22a2 extends NLP_Sequent E \u21d2 gentzenSequent E (OneForm A) (B \\ C) \u21d2 gentzenSequent E (OneForm B) (A \\ C)\nexchange:\n\u22a2 extends NLP_Sequent E \u21d2 gentzenSequent E (OneForm (A / B)) (B \\ A)\nexchange\u2019:\n\u22a2 extends NLP_Sequent E \u21d2 gentzenSequent E (OneForm (B \\ A)) (A / B)\npreposing:\n\u22a2 extends NLP_Sequent E \u21d2 gentzenSequent E (OneForm A) (B / (B / A))\npostposing:\n\u22a2 extends NLP_Sequent E \u21d2 gentzenSequent E (OneForm A) ((A \\ B) \\ B)\nFor Lambek Calculus extended from LP, which supports both commutativity and associativity, we have proved the following theorems:\nmixedComposition:\n\u22a2 extends LP_Sequent E \u21d2 gentzenSequent E (OneForm (A / B \u00b7 C \\ B)) (C \\ A)\nmixedComposition\u2019:\n\u22a2 extends LP_Sequent E \u21d2 gentzenSequent E (OneForm (B / C \u00b7 B \\ A)) (A / C)"}, {"heading": "3 Equivalences between three deduction systems", "text": "So far we have introduced three deduction systems for Lambek Calculus: (axiomatic) syntactic calculus, natural deduction and gentzen\u2019s sequent calculus. The convincing of syntactic calculus comes from intuition and the fact that all axiom rules are extremely simple, while the correctness of natural deduction rules and sequent calculus rules is not that clear. Before fully switching to use natural deduction or sequent calculus as the alternative deduction system, we have to prove the equivalences between them and the original syntactic calculus."}, {"heading": "3.1 Equivalence between Syntactic Calculus and Sequent Calculus", "text": "By equivalence, basically we want to know if any theorem about categories in arrow relation has also a proof in natural deduction and sequent calculus, and conversely if any theorems in latter systems has also a proof in syntactac calculus. In another words, the set of theorems about syntactic categories proven in these three deduction systems are exactly the same. However, there\u2019re two difficulties we must resolve first:\n1. the corresponce between arrow extensions (from Form to Form) and gentzen extensions (from Term to Term) must be defined and proved. 2. There\u2019s unique translation from Term to Form, but the other direction is not unique.\nThe first problem are handled in two directions: from arrow to gentzen extensions, then from genzen to arrow extensions. In the first direction we have the following definition:\n\u22a2 arrowToGentzenExt X E \u21d0\u21d2 \u2200A B. X A B \u21d2 gentzenSequent E (OneForm A) B\nNoticed that, this is not a function mapping any arrow extension to a gentzen extension, instead we need to use gentzenSequent relation to handle the OneForm quoting of the first parameter of arrow extension. Based on this definition, we have proved the correspondences between arrow and gentzen extensions for NL, L, NLP, LP:\nNLToNL_Sequent:\n\u22a2 arrowToGentzenExt NL NL_Sequent NLPToNLP_Sequent:\n\u22a2 arrowToGentzenExt NLP NLP_Sequent LToL_Sequent:\n\u22a2 arrowToGentzenExt L L_Sequent LPToLP_Sequent:\n\u22a2 arrowToGentzenExt LP LP_Sequent\nThe other direction is more subtle. From gentzen extension to arrow extension, since the translation from Term to Form is unique, the relationship between two kind of extensions can be defined just by characteristics of themselves:\n\u22a2 gentzenToArrowExt E X \u21d0\u21d2 \u2200T1 T2.\nE T1 T2 \u21d2 X (deltaTranslation T2) (deltaTranslation T1)\nHowever, noticed the interesting part: instead of saying E T1 T2 \u21d2 X (deltaTranslation T1) (deltaTranslation T we must use swap the order of deltaTranslation T1 and deltaTranslation T2. The reason seems connected with the CutRule, and without defing like this we can\u2019t prove the equivalece between the three deduction systems. However, we do can prove correspondences between arrow and gentzen extensions for NL, L, NLP, LP and other general results using this definition:\nNL_SequentToNL:\n\u22a2 gentzenToArrowExt NL_Sequent NL NLP_SequentToNLP:\n\u22a2 gentzenToArrowExt NLP_Sequent NLP L_SequentToL:\n\u22a2 gentzenToArrowExt L_Sequent L LP_SequentToLP:\n\u22a2 gentzenToArrowExt LP_Sequent LP\nAlso noticed that, in the definition of gentzenToArrowExt, when the gentzen extension contains more contents (i.e. more pairs of Terms satisfy the relation) then what\u2019s required by arrow extension, the whole definition is still satisfied. To actually define a function which precisely translate a gentzen extension into unique arrow extension and make sure the resulting arrow extension satisfy the definition of gentzenToArrowExt, we can define this function like this:\n\u22a2 ToArrowExt E = CURRY\n{(deltaTranslation y,deltaTranslation x) | (x,y) \u2208 UNCURRY E }\nHere we used HOL4\u2019s set theory package, and the use of CURRY and UNCURRY is to converse between standard mathemics definition of relations (with type \u201c\u03b1 Form \u00b7 \u03b1 Form -> bool\u201d) and relations in higher order logics (with type \u201c\u03b1 arrow_extension\u201d. We can prove that, the output of this function indeed satisfy the definition of gentzenToArrowExt:\ngentzenToArrowExt_thm:\n\u22a2 gentzenToArrowExt E (ToArrowExt E)\nWith all above devices, now the equivalences between (axiomatic) syntactic calculus and gentzen\u2019s Sequent calculus and their common extensions have been proved by the following theorems:\narrowToGentzen:\n\u22a2 arrow X A B \u21d2 arrowToGentzenExt X E \u21d2 gentzenSequent E (OneForm A) B\narrowToGentzenNL:\n\u22a2 arrow NL A B \u21d2 gentzenSequent NL_Sequent (OneForm A) B arrowToGentzenNLP:\n\u22a2 arrow NLP A B \u21d2 gentzenSequent NLP_Sequent (OneForm A) B arrowToGentzenL:\n\u22a2 arrow L A B \u21d2 gentzenSequent L_Sequent (OneForm A) B arrowToGentzenLP:\n\u22a2 arrow LP A B \u21d2 gentzenSequent LP_Sequent (OneForm A) B\ngentzenToArrow:\n\u22a2 gentzenToArrowExt E X \u2227 gentzenSequent E Gamma A \u21d2 arrow X (deltaTranslation Gamma) A\nNLGentzenToArrow:\n\u22a2 gentzenSequent NL_Sequent Gamma A \u21d2 arrow NL (deltaTranslation Gamma) A\nNLPGentzenToArrow:\n\u22a2 gentzenSequent NLP_Sequent Gamma A \u21d2 arrow NLP (deltaTranslation Gamma) A\nLGentzenToArrow:\n\u22a2 gentzenSequent L_Sequent Gamma A \u21d2 arrow L (deltaTranslation Gamma) A\nLPGentzenToArrow:\n\u22a2 gentzenSequent LP_Sequent Gamma A \u21d2 arrow LP (deltaTranslation Gamma) A\nThis means, if we translated all Comma into Dots, gentzen\u2019s Sequent Calculus actually doesn\u2019t prove anything new beyond the Syntactic Calculus, although it has more rules, especially the CutRule."}, {"heading": "3.2 Equivalence between Natural Deduction and Sequent Calculus", "text": "Surprisely, the equivalance between Natural Deduction and Sequent Calculus requires extra assumptions about properties on gentzen extensions. Generally speaking, without any restriction on gentzen extension, Gentzen\u2019s sequent calculus has a larger theorem set, therefore is stronger than Natural Deduction.\nFrom Natural Deduction to Sequence Calculus, i.e. the easy direction, we can prove the following theorem by induction on the structure of gentzenSequent relation:\nnatDedToGentzen:\n\u22a2 natDed E Gamma C \u21d2 gentzenSequent E Gamma C\nThe other direction is more difficult to prove, and it contains an extra property called condCutExt about the extensions. First we present directly the following important result:\ngentzenToNatDed:\n\u22a2 gentzenSequent E Gamma C \u21d2 condCutExt E \u21d2 natDed E Gamma C\nits the formal proof of this theorem is the longest proof in our LambekTheory, and to successfully prove it, many lemmas are needed.\nThe definition of condCutExt used in above theorem is defined as follows:\n\u22a2 condCutExt E \u21d0\u21d2 \u2200Gamma T1 T2 A Delta.\nE T1 T2 \u21d2 replace T2 Gamma (OneForm A) Delta \u21d2 \u2203Gamma\u2032.\nE Gamma\u2032 Gamma \u2227 replace T1 Gamma \u2032 (OneForm A) Delta\nto understand the precise meaning of this definition, we may consider the meaning of the replace operator and rewrite above definition into the following mathematic definition:\nE T1[A] T2[A] =\u21d2 \u2203T1[Delta]. E T1[Delta] T2[Delta]\nThis seems like a kind of completeness of the arrow extension: whenever we replace any OneForm term into another Term in the pairs satisfying the gentzen extension, the resulting pairs must also satisfy this extension. However, whenever the definition of extension concerns only about Commas, like in L_Sequent_def and others, this condition is naturally satisfied: (although the formal proofs are quite long for some of them)\nconditionOKNL:\n\u22a2 condCutExt NL_Sequent conditionOKNLP:\n\u22a2 condCutExt NLP_Sequent conditionOKL:\n\u22a2 condCutExt L_Sequent\nBesides, we have proved that, if two gentzen extensions both satisfy above condCutExt property, so is their sum relation:\ncondAddExt:\n\u22a2 condCutExt E \u2227 condCutExt E \u2032 \u21d2 condCutExt (add_extension E E \u2032)\nThe formal proofs of gentzenToNatDed also depends on the following lemmas which themselves have long proofs:\nCutNatDed:\n\u22a2 natDed E Gamma C \u21d2 condCutExt E \u21d2 natDed E Delta A \u21d2 \u2200Gamma\u2032. replace Gamma Gamma\u2032 (OneForm A) Delta \u21d2 natDed E Gamma\u2032 C\nnatDedComposition:\n\u22a2 condCutExt E \u2227 natDed E Gamma F1 \u2227 natDed E (OneForm F1) F2 \u21d2 natDed E Gamma F2\nFinally, we can merge the two direction together and get the following equivalence theorems about natural deduction and gentzen\u2019s sequent calculus for Lambek Calculus (both general and special cases), although they\u2019re not used anywhere so far:\ngentzenEqNatDed:\n\u22a2 condCutExt E \u21d2 (gentzenSequent E Gamma C \u21d0\u21d2 natDed E Gamma C)\nNLgentzenEqNatDed:\n\u22a2 gentzenSequent NL_Sequent Gamma C \u21d0\u21d2 natDed NL_Sequent Gamma C\nLgentzenEqNatDed:\n\u22a2 gentzenSequent L_Sequent Gamma C \u21d0\u21d2 natDed L_Sequent Gamma C NLPgentzenEqNatDed:\n\u22a2 gentzenSequent NLP_Sequent Gamma C \u21d0\u21d2 natDed NLP_Sequent Gamma C"}, {"heading": "3.3 Equivalence between Syntactic Calculus and Natural Deduction", "text": "Combining results from previous two sections, the equivalence between Syntactic Calculus and Natural Deduction can be easily proved with gentzen\u2019s Sequent Calculus as intermediate steps:\nnatDedToArrow:\n\u22a2 gentzenToArrowExt E X \u21d2 natDed E Gamma A \u21d2 arrow X (deltaTranslation Gamma) A\nnatDedToArrow_E:\n\u22a2 natDed E Gamma A \u21d2 arrow (ToArrowExt E) (deltaTranslation Gamma) A\narrowToNatDed:\n\u22a2 condCutExt E \u2227 arrowToGentzenExt X E \u2227 arrow X A B \u21d2 natDed E (OneForm A) B\nThere seems no way to get equivalence theorems between Syntactic Calculus and Natural Deduction/Sequent Calculus, because of the translations between Terms and Forms."}, {"heading": "4 A proof-theoretic formalization of Sequent Calculus", "text": "Above formalizations for Lambek Calculus may have provided a good basis for proving theorems about categories using any of the three deduction systems, but one can only do this manually. For the following two purposes, the current work is not enough:\n1. Proving theorems about Sequent Calculus proofs, e. g. the cut-elimination theorem (for any Sequent Calculus proof, there exists a corresponding proof without using the CutRule). 2. Finding and generating Sequent Calculus proofs programmatically.\nFor any of above purpose, we need a data structure to represent a whole proof. HOL theorem prover has already provided data structures to represent terms and theorems, but there\u2019s no built-in facility to represent a whole proof. In another word, a \u201cproof\u201d is not a first-class object in HOL.\nHowever, Coq has built-in support for first-class proof object. In Coq, it\u2019s possible to define the \u201cdegree\u201d of a gentzenSequent proof like this:\nFixpoint degreeProof (Atoms : Set) (Gamma : Term Atoms)\n(B : Form Atoms) (E : gentzen_extension ) (p : gentzenSequent E Gamma B) {struct p} : nat :=\nmatch p with | Ax _ => 0 | RightSlash _ _ _ H => degreeProof H | RightBackSlash _ _ _ H => degreeProof H | RightDot _ _ _ _ H1 H2 => max ( degreeProof H1) (degreeProof H2) | LeftSlash _ _ _ _ _ _ R H1 H2 => max (degreeProof H1) ( degreeProof H2) | LeftBackSlash _ _ _ _ _ _ R H1 H2 =>\nmax (degreeProof H1) (degreeProof H2)\n| LeftDot _ _ _ _ _ R H => degreeProof H | CutRule _ _ _ A _ R H1 H2 =>\nmax (max (degreeFormula A) ( degreeProof H1)) (degreeProof H2)\n| SequentExtension _ _ _ _ _ E R H => degreeProof H end.\nIn HOL, it\u2019s impossible to defined the same thing directly, because gentzenSequent E Gamma B has the type bool. To fill the gaps, we have to model a proof by a proof tree \u201dobject\u201d by using a datatype definition. Our datatype definition is based on similar modelling work in Isabelle/HOL for Display Logic [17], then all other related inductive relation definitions and theorems are new. (But once the gaps are filled, those theorems in Coq has also the same internal structure in HOL."}, {"heading": "4.1 Proof objects", "text": "A proof object in Sequent Calculus is represented as a datatype called Dertree. A Dertree has at least a sequent as its head, and by applying a rule it\u2019s derived from one or more other sequents. Thus Dertree is nothing but a tree of sequent with each node identified by a rule name. A Dertree as a proof can also be \u201cunfinished\u201d, and in this case it contains only a (unproved) sequent, nothing else:\nDatatype \u2018Sequent = Sequent (\u2019a gentzen_extension ) (\u2019a Term ) (\u2019a Form )\u2018; Datatype \u2018Rule = SeqAxiom\n| RightSlash | RightBackslash | RightDot | LeftSlash | LeftBackslash | LeftDot | CutRule | SeqExt \u2018;\nDatatype \u2018Dertree = Der (\u2019a Sequent) Rule (Dertree list )\n| Unf (\u2019a Sequent )\u2018;\nHere the datatype Sequent is just a simple container of three inner objects: a gentzen extension, a Term and a Form. The datatype Rule is just an atomic symbol, which takes values from 9 possible rule names as primitive Sequent Calculus rules. So in our formal system, a sequent gentzenSequent E Gamma B has the type bool, there\u2019s no way to access its internat structure, and when it can appears along as a theorem. On the other side a sequent Sequent E Gamma B has the type \u03b1 Sequent, it\u2019s just a container with accessors and its correctness has to be proved separately.\nWith above data structures, the following accessors are defined to access their internal structures:\n\u22a2 (\u2200 seq v0 v1. head (Der seq v0 v1) = seq) \u2227 \u2200 seq. head (Unf seq) = seq \u22a2 (concl (Unf (Sequent E Delta A)) = A) \u2227 (concl (Der (Sequent E Delta A) v0 v1) = A) \u22a2 (prems (Unf (Sequent E Delta A)) = Delta) \u2227 (prems (Der (Sequent E Delta A) v0 v1) = Delta) \u22a2 (exten (Unf (Sequent E Delta A)) = E) \u2227 (exten (Der (Sequent E Delta A) v0 v1) = E)\nAnd now we can define degreeProof as follows:\n\u22a2 (\u2200S. degreeProof (Der S SeqAxiom []) = 0) \u2227 (\u2200S H . degreeProof (Der S RightSlash [H ]) = degreeProof H ) \u2227 (\u2200S H .\ndegreeProof (Der S RightBackslash [H ]) = degreeProof H ) \u2227 (\u2200S H2 H1.\ndegreeProof (Der S RightDot [H1; H2]) = MAX (degreeProof H1) (degreeProof H2)) \u2227 (\u2200S H2 H1. degreeProof (Der S LeftSlash [H1; H2]) = MAX (degreeProof H1) (degreeProof H2)) \u2227 (\u2200S H2 H1. degreeProof (Der S LeftBackslash [H1; H2]) = MAX (degreeProof H1) (degreeProof H2)) \u2227 (\u2200S H . degreeProof (Der S LeftDot [H ]) = degreeProof H ) \u2227 (\u2200S H . degreeProof (Der S SeqExt [H ]) = degreeProof H ) \u2227 \u2200S H2 H1. degreeProof (Der S CutRule [H1; H2]) = MAX (degreeFormula (concl H1)) (MAX (degreeProof H1) (degreeProof H2))\nAnother closely related concept is the degreeFormulawhich assign each Form as integer as its degree:\n\u22a2 (\u2200C. degreeFormula (At C) = 1) \u2227 (\u2200F1 F2.\ndegreeFormula (F1 / F2) = SUC (MAX (degreeFormula F1) (degreeFormula F2))) \u2227 (\u2200F1 F2. degreeFormula (F1 \\ F2) = SUC (MAX (degreeFormula F1) (degreeFormula F2))) \u2227 \u2200F1 F2. degreeFormula (F1 \u00b7 F2) = SUC (MAX (degreeFormula F1) (degreeFormula F2))\nThe concept of sub-formula between two Forms that we mentioned several times in previous sections, is now formally defined as an inductive relation:\n\u22a2 (\u2200A. subFormula A A) \u2227 (\u2200A B C. subFormula A B \u21d2 subFormula A (B / C)) \u2227 (\u2200A B C. subFormula A B \u21d2 subFormula A (C / B)) \u2227 (\u2200A B C. subFormula A B \u21d2 subFormula A (B \\ C)) \u2227 (\u2200A B C. subFormula A B \u21d2 subFormula A (C \\ B)) \u2227 (\u2200A B C. subFormula A B \u21d2 subFormula A (B \u00b7 C)) \u2227 \u2200A B C. subFormula A B \u21d2 subFormula A (C \u00b7 B)\nAnd we have also proved many theorems about subFormula:\nsubAt:\n\u22a2 subFormula A (At a) \u21d2 (A = At a) subSlash:\n\u22a2 subFormula A (B / C) \u21d2 (A = B / C) \u2228 subFormula A B \u2228 subFormula A C\nsubBackslash:\n\u22a2 subFormula A (B \\ C) \u21d2 (A = B \\ C) \u2228 subFormula A B \u2228 subFormula A C\nsubDot:\n\u22a2 subFormula A (B \u00b7 C) \u21d2 (A = B \u00b7 C) \u2228 subFormula A B \u2228 subFormula A C\nsubFormulaTrans:\n\u22a2 subFormula A B \u21d2 subFormula B C \u21d2 subFormula A C\nThe sub-formula between a Form and a Term is called subFormTerm, which is defined inductively upon subFormula:\n\u22a2 (\u2200A B. subFormula A B \u21d2 subFormTerm A (OneForm B)) \u2227 (\u2200A T1 T2. subFormTerm A T1 \u21d2 subFormTerm A (Comma T1 T2)) \u2227 \u2200A T1 T2. subFormTerm A T1 \u21d2 subFormTerm A (Comma T2 T1)\nThen we have proved several important theorems about subFormTerm, most concering about the replace operator:\noneFormSubEQ:\n\u22a2 subFormTerm A (OneForm B) \u21d0\u21d2 subFormula A B comSub:\n\u22a2 subFormTerm f (Comma T1 T2) \u21d2 subFormTerm f T1 \u2228 subFormTerm f T2\nsubReplace1:\n\u22a2 replace T1 T2 T3 T4 \u21d2 subFormTerm f T3 \u21d2 subFormTerm f T1 subReplace2:\n\u22a2 replace T1 T2 T3 T4 \u21d2 subFormTerm f T4 \u21d2 subFormTerm f T2 subReplace3:\n\u22a2 replace T1 T2 T3 T4 \u21d2 subFormTerm X T1 \u21d2 subFormTerm X T2 \u2228 subFormTerm X T3"}, {"heading": "4.2 Derivations of proof tree", "text": "So how can we (manually) construct a proof for any theorem in Sequent calculus of Lambek Calculus and prove the resulting Dertree object is indeed a valid proof for this theorem? Unfortunately previous Coq proof scripts didn\u2019t give any hint, for this part the author has built everything needed from the ground.\nThe idea comes from beta-reduction in \u03bb-Calculus. First we define the one-step derivation from any unfinished Dertree by applying one rule which is equivalent with one of gentzenSequent rules:\n\u22a2 (\u2200E A. derivOne (Unf (Sequent E (OneForm A) A)) (Der (Sequent E (OneForm A) A) SeqAxiom [])) \u2227\n(\u2200E Gamma A B. derivOne (Unf (Sequent E Gamma (A / B))) (Der (Sequent E Gamma (A / B)) RightSlash [Unf (Sequent E (Comma Gamma (OneForm B)) A)])) \u2227 (\u2200E Gamma A B.\nderivOne (Unf (Sequent E Gamma (B \\ A))) (Der (Sequent E Gamma (B \\ A)) RightBackslash\n[Unf (Sequent E (Comma (OneForm B) Gamma) A)])) \u2227 (\u2200E Gamma Delta A B.\nderivOne (Unf (Sequent E (Comma Gamma Delta) (A \u00b7 B))) (Der (Sequent E (Comma Gamma Delta) (A \u00b7 B)) RightDot\n[Unf (Sequent E Gamma A); Unf (Sequent E Delta B)])) \u2227\n(\u2200E Gamma Gamma\u2032 Delta A B C. replace Gamma Gamma\u2032 (OneForm A) (Comma (OneForm (A / B)) Delta) \u21d2\nderivOne (Unf (Sequent E Gamma\u2032 C)) (Der (Sequent E Gamma\u2032 C) LeftSlash\n[Unf (Sequent E Gamma C); Unf (Sequent E Delta B)])) \u2227\n(\u2200E Gamma Gamma\u2032 Delta A B C. replace Gamma Gamma\u2032 (OneForm A) (Comma Delta (OneForm (B \\ A))) \u21d2\nderivOne (Unf (Sequent E Gamma\u2032 C)) (Der (Sequent E Gamma\u2032 C) LeftBackslash\n[Unf (Sequent E Gamma C); Unf (Sequent E Delta B)])) \u2227\n(\u2200E Gamma Gamma\u2032 A B C. replace Gamma Gamma\u2032 (Comma (OneForm A) (OneForm B)) (OneForm (A \u00b7 B)) \u21d2\nderivOne (Unf (Sequent E Gamma\u2032 C)) (Der (Sequent E Gamma\u2032 C) LeftDot\n[Unf (Sequent E Gamma C)])) \u2227 (\u2200E Delta Gamma Gamma\u2032 A C.\nreplace Gamma Gamma\u2032 (OneForm A) Delta \u21d2 derivOne (Unf (Sequent E Gamma\u2032 C)) (Der (Sequent E Gamma\u2032 C) CutRule\n[Unf (Sequent E Gamma C); Unf (Sequent E Delta A)])) \u2227\n\u2200E Gamma Gamma\u2032 Delta Delta\u2032 C. replace Gamma Gamma\u2032 Delta Delta\u2032 \u2227 E Delta Delta\u2032 \u21d2 derivOne (Unf (Sequent E Gamma\u2032 C)) (Der (Sequent E Gamma\u2032 C) SeqExt\n[Unf (Sequent E Gamma C)])\nThe second step is to define \u201cstructure rules\u201d as a new inductive relation deriv based on derivOne. With this relation, one can repeatly apply one-step derivation for all the unfinished sub-proofs in the derivation tree, until all leaves are finished:\n\u22a2 (\u2200D1 D2. derivOne D1 D2 \u21d2 deriv D1 D2) \u2227 (\u2200S R D1 D \u2032 1.\nderiv D1 D \u2032 1 \u21d2 deriv (Der S R [D1]) (Der S R [D \u2032 1 ])) \u2227\n(\u2200S R D1 D \u2032 1 D.\nderiv D1 D \u2032 1 \u21d2 deriv (Der S R [D1; D]) (Der S R [D \u2032 1 ; D])) \u2227\n(\u2200S R D2 D \u2032 2 D. deriv D2 D \u2032 2 \u21d2\nderiv (Der S R [D; D2]) (Der S R [D; D \u2032 2 ])) \u2227\n\u2200S R D1 D \u2032 1 D2 D \u2032 2.\nderiv D1 D \u2032 1 \u2227 deriv D2 D \u2032 2 \u21d2 deriv (Der S R [D1; D2]) (Der S R [D \u2032 1 ; D \u2032 2 ])\nThe last step is to define the chain of derivations as a reduction, so that any two derivation trees are related with each other. This is done by defining a new relation Deriv as the reflexitive transitive closure (RTC) of deriv:\n\u22a2 Deriv = deriv\u2217\nMerging all above definitions together, we have proved all needed theorems for contructing a whole new proof tree, either manually or automatically:\n(One step rules) DerivSeqAxiom:\n\u22a2 Deriv (Unf (Sequent E (OneForm A) A)) (Der (Sequent E (OneForm A) A) SeqAxiom [])\nDerivRightSlash:\n\u22a2 Deriv (Unf (Sequent E Gamma (A / B))) (Der (Sequent E Gamma (A / B)) RightSlash\n[Unf (Sequent E (Comma Gamma (OneForm B)) A)]) DerivRightBackslash:\n\u22a2 Deriv (Unf (Sequent E Gamma (B \\ A))) (Der (Sequent E Gamma (B \\ A)) RightBackslash\n[Unf (Sequent E (Comma (OneForm B) Gamma) A)]) DerivRightDot:\n\u22a2 Deriv (Unf (Sequent E (Comma Gamma Delta) (A \u00b7 B))) (Der (Sequent E (Comma Gamma Delta) (A \u00b7 B)) RightDot\n[Unf (Sequent E Gamma A); Unf (Sequent E Delta B)]) DerivLeftSlash:\n\u22a2 replace Gamma Gamma\u2032 (OneForm A) (Comma (OneForm (A / B)) Delta) \u21d2\nDeriv (Unf (Sequent E Gamma\u2032 C)) (Der (Sequent E Gamma\u2032 C) LeftSlash\n[Unf (Sequent E Gamma C); Unf (Sequent E Delta B)]) DerivLeftBackslash:\n\u22a2 replace Gamma Gamma\u2032 (OneForm A) (Comma Delta (OneForm (B \\ A))) \u21d2\nDeriv (Unf (Sequent E Gamma\u2032 C)) (Der (Sequent E Gamma\u2032 C) LeftBackslash\n[Unf (Sequent E Gamma C); Unf (Sequent E Delta B)]) DerivLeftDot:\n\u22a2 replace Gamma Gamma\u2032 (Comma (OneForm A) (OneForm B)) (OneForm (A \u00b7 B)) \u21d2\nDeriv (Unf (Sequent E Gamma\u2032 C)) (Der (Sequent E Gamma\u2032 C) LeftDot\n[Unf (Sequent E Gamma C)]) DerivCutRule:\n\u22a2 replace Gamma Gamma\u2032 (OneForm A) Delta \u21d2 Deriv (Unf (Sequent E Gamma\u2032 C)) (Der (Sequent E Gamma\u2032 C) CutRule\n[Unf (Sequent E Gamma C); Unf (Sequent E Delta A)]) DerivSeqExt:\n\u22a2 replace Gamma Gamma\u2032 Delta Delta\u2032 \u2227 E Delta Delta\u2032 \u21d2 Deriv (Unf (Sequent E Gamma\u2032 C)) (Der (Sequent E Gamma\u2032 C) SeqExt\n[Unf (Sequent E Gamma C)])\n(Structure rules) DerivOne:\n\u22a2 Deriv D1 D \u2032 1 \u21d2 Deriv (Der S R [D1]) (Der S R [D \u2032 1])\nDerivLeft:\n\u22a2 Deriv D1 D \u2032 1 \u21d2 Deriv (Der S R [D1; D]) (Der S R [D \u2032 1 ; D])\nDerivRight:\n\u22a2 Deriv D2 D \u2032 2 \u21d2 Deriv (Der S R [D; D2]) (Der S R [D; D \u2032 2 ])\nDerivBoth:\n\u22a2 Deriv D1 D \u2032 1 \u21d2\nDeriv D2 D \u2032 2 \u21d2 Deriv (Der S R [D1; D2]) (Der S R [D \u2032 1; D \u2032 2])\n(RTC rules) Deriv_refl:\n\u22a2 Deriv x x Deriv_trans:\n\u22a2 Deriv x y \u2227 Deriv y z \u21d2 Deriv x z\nA Dertree is a proof if all its leaves are finished sub-proofs. It has to be defined as another inductive unary relation:\n\u22a2 (\u2200S R. Proof (Der S R [])) \u2227 (\u2200S R D. Proof D \u21d2 Proof (Der S R [D])) \u2227 \u2200S R D1 D2. Proof D1 \u2227 Proof D2 \u21d2 Proof (Der S R [D1; D2])\nFinally we have proved the following theorem which partially guaranteed the correctness of Deriv rules. It says for each true sequent, there\u2019s a finished proof tree which is derivable from a unfinished Dertree having that sequent as head:11\ngentzenToDeriv:\n\u22a2 gentzenSequent E Gamma A \u21d2 \u2203D. Deriv (Unf (Sequent E Gamma A)) D \u2227 Proof D"}, {"heading": "4.3 Cut-free proofs", "text": "In Gentzen\u2019s original Sequent Calculus for intuitionistic propositional logic, the so-called cut-elimination theorem (Hauptsatz) stands at the central position. Cut-elimination theorem for Lambek Calculus was proved by Lambek for L [7] and NL [12].\nRoughly speaking, this important theorem said that the Cut rule is admissible. In other words, the Cut rule doesn\u2019t increase the set of theorems provable from other rules. It\u2019s this theorem which guaranteed the existence of decision procedures, because all other rules has the sub-formula property, which is essential for automatic proof searching.\nIn our project, due to the complexity and large amount of preparation before reaching the Cutelimination theorem, it\u2019s not formally proved yet. Nor the original Coq work has done this proof.12\nA cut-free proof is a proof (Dertree) without using the CutRule of gentzen\u2019s Sequent Calculus. One way to define cut-free proofs is simply through the degreeProof property:\n\u22a2 CutFreeProof p \u21d0\u21d2 (degreeProof p = 0)\n11 The other direction remains unproved: for any sequent, if it leads to a finished Dertree, then it must be a true sequent. We leave this difficult theorem to future work."}, {"heading": "12 to our knowledge, the Cut-elimination theorem for Lambek calculus is never formally verified. This topic along", "text": "may become another paper after this project, since it\u2019s big enough.\nThis is because, in the definition of degreeProof, only the CutRule has a non-zero degree, while all other rules has zero degrees. So if the entire Dertree has zero degree, it must not contain any CutRule. Saying the same thing in another way, that\u2019s the following theorem:\nnotCutFree:\n\u22a2 replace T1 T2 (OneForm A) D \u2227 (p1 = Sequent E D A) \u2227 (p2 = Sequent E T1 C) \u21d2 \u00acCutFreeProof (Der _ CutRule [Der p1 _ _; Der p2 _ _])\nThe next important concept is sub-proof. A proof q is a sub-proof of another proof p if and only if p can be found in one leave of the Dertree of p. The one-step version of this relation is defined as another inductive relation subProofOne. Here we omitted its long definition but only show one example, the two LeftSlash cases:\nls1:\n\u22a2 (p0 = Sequent E Gamma \u2032 C) \u2227\n(p1 = Der (Sequent E Delta B) R D) \u2227 (p2 = Der (Sequent E Gamma C) R D) \u2227 replace Gamma Gamma\u2032 (OneForm A) (Comma (OneForm (A / B)) Delta) \u21d2\nsubProofOne p1 (Der p0 LeftSlash [p1; p2]) ls2:\n\u22a2 (p0 = Sequent E Gamma \u2032 C) \u2227\n(p1 = Der (Sequent E Delta B) R D) \u2227 (p2 = Der (Sequent E Gamma C) R D) \u2227 replace Gamma Gamma\u2032 (OneForm A) (Comma (OneForm (A / B)) Delta) \u21d2 subProofOne p2 (Der p0 LeftSlash [p1; p2])\nBased on subProofOne, now the full version subProof is just a RTC of subProofOne: (there\u2019s no structure rules here)\n\u22a2 subProof = subProofOne\u2217\nFinally we have proved an important sub-formula property if we already have a Cut-free proof. The one-step version (subFormulaPropertyOne) is the longest proofs we met in the whole project, the full version is then provable by doing induction on the one-step version.\nsubFormulaPropertyOne:\n\u22a2 subProofOne q p \u21d2 extensionSub (exten p) \u21d2 CutFreeProof p \u21d2 \u2200 x. subFormTerm x (prems q) \u2228 subFormula x (concl q) \u21d2 subFormTerm x (prems p) \u2228 subFormula x (concl p)\nsubFormulaPropertyOne\u2019:\n\u22a2 (p = Der (Sequent E Gamma1 B) _ _) \u21d2 (q = Der (Sequent E Gamma2 C) _ _) \u21d2 extensionSub E \u21d2 subProofOne q p \u21d2 CutFreeProof p \u21d2 subFormTerm x Gamma2 \u2228 subFormula x C \u21d2 subFormTerm x Gamma1 \u2228 subFormula x B\nsubFormulaProperty:\n\u22a2 subProof q p \u21d2 extensionSub (exten p) \u21d2 CutFreeProof p \u21d2 \u2200 x. subFormTerm x (prems q) \u2228 subFormula x (concl q) \u21d2 subFormTerm x (prems p) \u2228 subFormula x (concl p)\nsubFormulaProperty\u2019:\n\u22a2 (p = Der (Sequent E Gamma1 B) _ _) \u21d2 (q = Der (Sequent E Gamma2 C) _ _) \u21d2 extensionSub E \u21d2 subProof q p \u21d2 CutFreeProof p \u21d2 subFormTerm x Gamma2 \u2228 subFormula x C \u21d2 subFormTerm x Gamma1 \u2228 subFormula x B\nBasically these theorems said, if we have a cut-free proof, then any sub-formula in its sub-proofs (either in antecedents or conclusion of the sequent) is also a sub-formula of the sequent for whole proof. In another word, NO new formula appears during the proof searching process, or NO need to guess anything! So, if the cut-free proof indeed exists for every sequent proof using CutRule, then we do have the decision procedure!\nThe last thing to explain, is the meaning of extensionSub appearing in above theorems. The purpose is to make sure the gentzen extension in the related Lambek Calculus has also the sub-formula property:\n\u22a2 extensionSub E \u21d0\u21d2 \u2200Form T1 T2.\nE T1 T2 \u21d2 subFormTerm Form T1 \u21d2 subFormTerm Form T2"}, {"heading": "5 Examples", "text": "Our first example demonstrates how to use the Lambek Calculus formulization as a toolkit for manual proving derivations about categories of sentences. Suppose we have the following minimal Italian lexicon:\nword category\ncosa S/(S/np) guarda S/inf passare inf/np\nAnd the goal is to check if \u201ccosa guarda passare\u201d is an Italian sentance (and then parse it). There\u2019re only two ways to bracketing the three words \u201ccosa\u201d, \u201cguarda\u201d and \u201cpassare\u201d:\n1. ((\u201ccosa\u201d, \u201cguarda\u201d), \u201cpassare\u201d); 2. (\u201ccosa\u201d, (\u201cguarda\u201d, \u201cpassare\u201d)).\nThe first way leads to nothing, while the second way (as also a parsing tree) can be proved to have the category S in either Natural Deduction or Sequent Calculus:\n\u22a2 natDed L_Sequent (Comma (OneForm (At \u201cS\u201d / (At \u201cS\u201d / At \u201cnp\u201d)))\n(Comma (OneForm (At \u201cS\u201d / At \u201cinf\u201d)) (OneForm (At \u201cinf\u201d / At \u201cnp\u201d)))) (At \u201cS\u201d)\n\u22a2 gentzenSequent L_Sequent (Comma (OneForm (At \u201cS\u201d / (At \u201cS\u201d / At \u201cnp\u201d)))\n(Comma (OneForm (At \u201cS\u201d / At \u201cinf\u201d)) (OneForm (At \u201cinf\u201d / At \u201cnp\u201d)))) (At \u201cS\u201d)\nHere is the proof tree in Natural Deduction with L extension:\nS/(S/np) \u22a2 S/(S/np)\nS/inf \u22a2 S/inf\ninf/np \u22a2 inf/np np \u22a2 np /e\ninf/np, np \u22a2 inf /e\nS/inf, (inf/np, np) \u22a2 S L Sequent (S/inf, inf/np), np \u22a2 S /i\nS/inf, inf/np \u22a2 S/np /e\nS/(S/np), (S/inf, inf/np) \u22a2 S Lex\n(\u201ccosa\u201d, (\u201cguarda\u201d, \u201cpassare\u201d)) \u22a2 S\nAnd the proof tree in Sequent Calculus with L extension:\nS \u22a2 S\nS \u22a2 S inf \u22a2 inf /L\nS/inf, inf \u22a2 S np \u22a2 np /L\nS/inf, (inf/np, np) \u22a2 S L Sequent (S/inf, inf/np), np \u22a2 S /R\nS/inf, inf/np \u22a2 S/np /L\nS/(S/np), (S/inf, inf/np) \u22a2 S Lex\n(\u201ccosa\u201d, (\u201cguarda\u201d, \u201cpassare\u201d)) \u22a2 S\nIf we compare the two proof trees, we can see that, the Sequent Calculus proof is \u201csmaller\u201d in the sense that, all applications of SeqAxiom are based on sub-formulae of lower level formulae in the proof tree (in this case they\u2019re all basic categories, but it\u2019s not always like this). To see the advantages of Sequent Calculus more clearly, for the first time we give the formal proof scripts in HOL4 for above two theorems:\nval cosa_guarda_passare_natDed = store_thm (\n\" cosa_guarda_passare_natDed\",\n\u2018\u2018natDed L_Sequent (Comma (OneForm ^cosa )\n(Comma ( OneForm ^guarda) (OneForm ^passare )))\n(At \"S\")\u2018\u2018,\nMATCH_MP_TAC SlashElim\n>> EXISTS_TAC \u2018\u2018(At \"S\") / (At \"np\")\u2018\u2018 (* guess 1 *) >> CONJ_TAC (* 2 sub -goals here *) >| [ (* goal 1 *)\nREWRITE_TAC [NatAxiom ], (* goal 2 *) MATCH_MP_TAC SlashIntro \\\\ MATCH_MP_TAC NatExtSimpl \\\\ EXISTS_TAC \u2018\u2018(Comma (OneForm (At \"S\" / At \"inf\"))\n(Comma (OneForm (At \"inf\" / At \"np\"))\n(OneForm (At \"np\"))))\u2018\u2018 \\\\\nCONJ_TAC >- REWRITE_TAC [ L_Sequent_rules ] \\\\ MATCH_MP_TAC SlashElim \\\\ EXISTS_TAC \u2018\u2018At \"inf\"\u2018\u2018 \\\\ (* guess 2 *) CONJ_TAC >| (* 2 sub -goals here *) [ (* goal 2.1 *)\nREWRITE_TAC [ NatAxiom ], (* goal 2.2 *) MATCH_MP_TAC SlashElim \\\\ EXISTS_TAC \u2018\u2018At \"np\"\u2018\u2018 \\\\ (* guess 3 *) REWRITE_TAC [ NatAxiom ] ] ]);\nval cosa_guarda_passare_gentzenSequent = store_thm (\n\" cosa_guarda_passare_gentzenSequent\",\n\u2018\u2018 gentzenSequent L_Sequent (Comma (OneForm ^cosa )\n(Comma (OneForm ^guarda) (OneForm ^passare )))\n(At \"S\")\u2018\u2018,\nMATCH_MP_TAC LeftSlashSimpl\n>> CONJ_TAC (* 2 sub -goals here *) >| [ (* goal 1 *)\nMATCH_MP_TAC RightSlash \\\\ MATCH_MP_TAC SeqExtSimpl \\\\ EXISTS_TAC \u2018\u2018(Comma (OneForm (At \"S\" / At \"inf\"))\n(Comma (OneForm (At \"inf\" / At \"np\"))\n(OneForm (At \"np\"))))\u2018\u2018 \\\\\nCONJ_TAC >- REWRITE_TAC [ L_Sequent_rules ] \\\\ MATCH_MP_TAC LeftSlashSimpl \\\\ CONJ_TAC >| (* 2 sub -goals here *) [ (* goal 1.1 *)\nMATCH_MP_TAC LeftSlashSimpl \\\\ REWRITE_TAC [ SeqAxiom ], (* goal 1.2 *) REWRITE_TAC [ SeqAxiom ] ],\n(* goal 2 *) REWRITE_TAC [SeqAxiom ] ]);\nIn the first proof based on Natural Deduction, after rule applications of SlashElim, SlashElim and the second SlashElim, the parameter of EXISTS_TAC tactical must be correctly guessed. Since there\u2019re infinite possibilities, automatica proof searching will fail with Natural Deduction rules. But in the second proof based on Sequent Calculus, there\u2019s no such guess at all. Automatic proof searching algorithm could just try each possible rules (the number is finite) and then does the same strategy for each searching branches, since the formulae at next levels always become smaller, the proof searching process will definitely terminate. (And there\u2019re even better algorithms with polinomial time complexity)\nThe next example is to demonstrates how to manually construct a proof tree object for above sentence and prove that the Dertree is indeed a valid proof.\nAt the beginning we have the following unfinished Dertree:\nval r0 =\n\u2018\u2018(Unf (Sequent L_Sequent (Comma ( OneForm (At \"S\" / (At \"S\" / At \"np\")))\n(Comma (OneForm (At \"S\" / At \"inf\"))\n(OneForm (At \"inf\" / At \"np\"))))\n(At \"S\")))\u2018\u2018;\nIf we try to manually expand this Dertree into the final proof tree according to above manual proof, at the next step we could have a new Dertree like this:\nval r1 =\n\u2018\u2018(Der (Sequent L_Sequent (Comma ( OneForm (At \"S\" / (At \"S\" / At \"np\")))\n(Comma (OneForm (At \"S\" / At \"inf\"))\n(OneForm (At \"inf\" / At \"np\"))))\n(At \"S\"))\nLeftSlash\n[ (Unf (Sequent L_Sequent (OneForm (At \"S\")) (At \"S\"))) ;\n(Unf (Sequent L_Sequent (Comma (OneForm (At \"S\" / At \"inf\"))\n(OneForm (At \"inf\" / At \"np\")))\n(At \"S\" / At \"np\"))) ])\u2018\u2018;\nAnd we can prove this new Dertree is derived from the last one:\n\u22a2 Deriv (Unf\n(Sequent L_Sequent\n(Comma (OneForm (At \u201cS\u201d / (At \u201cS\u201d / At \u201cnp\u201d))) (Comma (OneForm (At \u201cS\u201d / At \u201cinf\u201d))\n(OneForm (At \u201cinf\u201d / At \u201cnp\u201d)))) (At \u201cS\u201d))) (Der\n(Sequent L_Sequent\n(Comma (OneForm (At \u201cS\u201d / (At \u201cS\u201d / At \u201cnp\u201d))) (Comma (OneForm (At \u201cS\u201d / At \u201cinf\u201d))\n(OneForm (At \u201cinf\u201d / At \u201cnp\u201d)))) (At \u201cS\u201d)) LeftSlash [Unf (Sequent L_Sequent (OneForm (At \u201cS\u201d)) (At \u201cS\u201d)); Unf\n(Sequent L_Sequent\n(Comma (OneForm (At \u201cS\u201d / At \u201cinf\u201d)) (OneForm (At \u201cinf\u201d / At \u201cnp\u201d))) (At \u201cS\u201d / At \u201cnp\u201d))])\nIf we repeat this process and manually expand the Dertree while prove the new Dertree is derived from the last Dertree, finally the transitivity of Deriv relation will let us prove that, the final finished Dertree is indeed a valid proof for the original unfinished Dertree, and thus it\u2019s indeed a valid proof for the original Sequent theorem. We omited the intermediate steps and show only the proof script of the final step:\nval r0_to_final = store_thm (\n\"r0_to_final \", \u2018\u2018Deriv ^r0 ^r_final \u2018\u2018,\nASSUME_TAC r0_to_r1 \u2019\u2019\n>> ASSUME_TAC (derivToDeriv r1_to_r2 ) >> ASSUME_TAC (derivToDeriv r2_to_r3 ) >> ASSUME_TAC (derivToDeriv r3_to_r4 ) >> ASSUME_TAC (derivToDeriv r4_to_r5 ) >> ASSUME_TAC (derivToDeriv r5_to_r6 ) >> ASSUME_TAC (derivToDeriv r6_to_final ) >> REPEAT (IMP_RES_TAC Deriv_trans ));\nAnd the actual proved theorem:\n\u22a2 Deriv (Unf\n(Sequent L_Sequent\n(Comma (OneForm (At \u201cS\u201d / (At \u201cS\u201d / At \u201cnp\u201d))) (Comma (OneForm (At \u201cS\u201d / At \u201cinf\u201d))\n(OneForm (At \u201cinf\u201d / At \u201cnp\u201d)))) (At \u201cS\u201d))) (Der\n(Sequent L_Sequent\n(Comma (OneForm (At \u201cS\u201d / (At \u201cS\u201d / At \u201cnp\u201d))) (Comma (OneForm (At \u201cS\u201d / At \u201cinf\u201d))\n(OneForm (At \u201cinf\u201d / At \u201cnp\u201d)))) (At \u201cS\u201d)) LeftSlash [Der (Sequent L_Sequent (OneForm (At \u201cS\u201d)) (At \u201cS\u201d)) SeqAxiom [];\nDer\n(Sequent L_Sequent\n(Comma (OneForm (At \u201cS\u201d / At \u201cinf\u201d)) (OneForm (At \u201cinf\u201d / At \u201cnp\u201d)))\n(At \u201cS\u201d / At \u201cnp\u201d)) RightSlash [Der\n(Sequent L_Sequent\n(Comma\n(Comma (OneForm (At \u201cS\u201d / At \u201cinf\u201d)) (OneForm (At \u201cinf\u201d / At \u201cnp\u201d)))\n(OneForm (At \u201cnp\u201d))) (At \u201cS\u201d)) SeqExt [Der\n(Sequent L_Sequent\n(Comma (OneForm (At \u201cS\u201d / At \u201cinf\u201d)) (Comma (OneForm (At \u201cinf\u201d / At \u201cnp\u201d))\n(OneForm (At \u201cnp\u201d)))) (At \u201cS\u201d)) LeftSlash [Der\n(Sequent L_Sequent\n(Comma (OneForm (At \u201cS\u201d / At \u201cinf\u201d)) (OneForm (At \u201cinf\u201d))) (At \u201cS\u201d))\nLeftSlash [Der\n(Sequent L_Sequent (OneForm (At \u201cS\u201d)) (At \u201cS\u201d)) SeqAxiom [];\nDer\n(Sequent L_Sequent (OneForm (At \u201cinf\u201d)) (At \u201cinf\u201d)) SeqAxiom []];\nDer\n(Sequent L_Sequent (OneForm (At \u201cnp\u201d)) (At \u201cnp\u201d)) SeqAxiom []]]]])\nThe final Dertree is quite long and hard to read, but it does contain all necessary information about the details of the proof. If there\u2019s an automatic proof searching algorithm, in theory we can implement it either as a special tactical for proving theorems about relation gentzenSequent, or as a program taking an initial Dertree and produce a finished Dertree with a related theorem as above one. If we\nneed a language parser instead, then the useful output will be the bracketed binary tree, together with categories at each node of the tree."}, {"heading": "6 Differences between HOL and Coq", "text": "There\u2019re essential differences between HOL and Coq for many logical definitions that we have ported from Coq, although they looks similiar."}, {"heading": "6.1 Inductive datatypes and relations", "text": "In Coq, both inductive data types and relations are defined as Inductive sets. For instance, the definition of type Form and the arrow relation for Syntactic Calculus:\nInductive Form (Atoms : Set) : Set :=\n| At : Atoms -> Form Atoms | Slash : Form Atoms -> Form Atoms -> Form Atoms | Dot : Form Atoms -> Form Atoms -> Form Atoms | Backslash : Form Atoms -> Form Atoms -> Form Atoms.\nInductive arrow (Atoms : Set) : Form Atoms -> Form Atoms -> Set :=\n| one : forall A : Form Atoms , arrow A A | comp : forall A B C : Form Atoms , arrow A B -> arrow B C -> arrow A C | beta :\nforall A B C : Form Atoms , arrow (Dot A B) C -> arrow A (Slash C B)\n| beta \u2019 :\nforall A B C : Form Atoms , arrow A (Slash C B) -> arrow (Dot A B) C\n| gamma :\nforall A B C : Form Atoms , arrow (Dot A B) C -> arrow B (Backslash A C)\n| gamma \u2019 :\nforall A B C : Form Atoms , arrow B (Backslash A C) -> arrow (Dot A B) C\n| arrow_plus : forall A B : Form Atoms , X A B -> arrow A B.\nwhile in HOL, although they\u2019re still inductive defintions, but they\u2019re handled differently: the former is defined by Define, and latter is defined by Hol_reln:\nval _ = Datatype \u2018Form = At \u2019a | Slash Form Form | Backslash Form Form | Dot Form Form \u2018;\nval (arrow_rules , arrow_ind , arrow_cases ) = Hol_reln \u2018\n(!X A. arrow X A A) /\\ (* one *) (!X A B C. arrow X (Dot A B) C ==> arrow X A (Slash C B)) /\\ (* beta *) (!X A B C. arrow X A (Slash C B) ==> arrow X (Dot A B) C) /\\ (* beta \u2019 *) (!X A B C. arrow X (Dot A B) C ==> arrow X B (Backslash A C)) /\\ (* gamma *) (!X A B C. arrow X B (Backslash A C) ==> arrow X (Dot A B) C) /\\ (* gamma \u2019 *) (!X A B C. arrow X A B /\\ arrow X B C ==> arrow X A C) /\\ (* comp *) (!(X :\u2019a arrow_extension ) A B. X A B ==> arrow X A B) \u2018; (* arrow_plus *)\nThere\u2019s no magic behind HOL\u2019s datatype definition, because what the Datatype does is to prove a series of theorems which completely characteries the type Form:\nForm_TY_DEF:\n\u22a2 \u2203 rep. TYPE_DEFINITION\n(\u03bb a\u20320. \u2200 \u2032Form \u2032 . (\u2200 a\u2032\n0 . (\u2203 a. a\u2032 0 =\n(\u03bb a. ind_type$CONSTR 0 a (\u03bbn. ind_type$BOTTOM))\na) \u2228 (\u2203 a0 a1.\n(a\u2032 0 =\n(\u03bb a0 a1. ind_type$CONSTR (SUC 0) ARB (ind_type$FCONS a0\n(ind_type$FCONS a1 (\u03bbn. ind_type$BOTTOM)))) a0 a1) \u2227\n\u2032Form \u2032 a0 \u2227 \u2032Form \u2032 a1) \u2228\n(\u2203 a0 a1. (a\u2032\n0 =\n(\u03bb a0 a1. ind_type$CONSTR (SUC (SUC 0)) ARB (ind_type$FCONS a0\n(ind_type$FCONS a1 (\u03bbn. ind_type$BOTTOM)))) a0 a1) \u2227\n\u2032Form \u2032 a0 \u2227 \u2032Form \u2032 a1) \u2228\n(\u2203 a0 a1. (a\u2032\n0 =\n(\u03bb a0 a1. ind_type$CONSTR (SUC (SUC (SUC 0))) ARB (ind_type$FCONS a0\n(ind_type$FCONS a1 (\u03bbn. ind_type$BOTTOM)))) a0 a1) \u2227\n\u2032Form \u2032 a0 \u2227 \u2032Form \u2032 a1) \u21d2\n\u2032Form \u2032 a\u2032 0 ) \u21d2\n\u2032Form \u2032 a\u2032 0 ) rep\nForm_case_def:\n\u22a2 (\u2200 a f f1 f2 f3. Form_CASE (At a) f f1 f2 f3 = f a) \u2227 (\u2200 a0 a1 f f1 f2 f3.\nForm_CASE (a0 / a1) f f1 f2 f3 = f1 a0 a1) \u2227 (\u2200 a0 a1 f f1 f2 f3.\nForm_CASE (a0 \\ a1) f f1 f2 f3 = f2 a0 a1) \u2227 \u2200 a0 a1 f f1 f2 f3. Form_CASE (a0 \u00b7 a1) f f1 f2 f3 = f3 a0 a1\nForm_size_def:\n\u22a2 (\u2200 f a. Form_size f (At a) = 1 + f a) \u2227 (\u2200 f a0 a1.\nForm_size f (a0 / a1) = 1 + (Form_size f a0 + Form_size f a1)) \u2227 (\u2200 f a0 a1. Form_size f (a0 \\ a1) = 1 + (Form_size f a0 + Form_size f a1)) \u2227 \u2200 f a0 a1. Form_size f (a0 \u00b7 a1) = 1 + (Form_size f a0 + Form_size f a1)\nForm_11:\n\u22a2 (\u2200 a a\u2032. (At a = At a\u2032) \u21d0\u21d2 (a = a\u2032)) \u2227 (\u2200 a0 a1 a \u2032 0 a\u2032 1 .\n(a0 / a1 = a \u2032 0 / a \u2032 1) \u21d0\u21d2 (a0 = a \u2032 0) \u2227 (a1 = a \u2032 1)) \u2227 (\u2200 a0 a1 a \u2032 0 a\u2032 1 .\n(a0 \\ a1 = a \u2032 0 \\ a\u2032 1 ) \u21d0\u21d2 (a0 = a \u2032 0 ) \u2227 (a1 = a \u2032 1 )) \u2227\n\u2200 a0 a1 a \u2032 0 a \u2032 1.\n(a0 \u00b7 a1 = a \u2032 0 \u00b7 a\u2032 1 ) \u21d0\u21d2 (a0 = a \u2032 0 ) \u2227 (a1 = a \u2032 1 )\nForm_Axiom:\n\u22a2 \u2203 fn. (\u2200 a. fn (At a) = f0 a) \u2227 (\u2200 a0 a1. fn (a0 / a1) = f1 a0 a1 (fn a0) (fn a1)) \u2227 (\u2200 a0 a1. fn (a0 \\ a1) = f2 a0 a1 (fn a0) (fn a1)) \u2227 \u2200 a0 a1. fn (a0 \u00b7 a1) = f3 a0 a1 (fn a0) (fn a1)\nForm_case_cong:\n\u22a2 (M = M \u2032) \u2227 (\u2200 a. (M \u2032 = At a) \u21d2 (f a = f \u2032 a)) \u2227 (\u2200 a0 a1. (M \u2032 = a0 / a1) \u21d2 (f1 a0 a1 = f \u2032\n1 a0 a1)) \u2227 (\u2200 a0 a1. (M \u2032 = a0 \\ a1) \u21d2 (f2 a0 a1 = f \u2032 2 a0 a1)) \u2227 (\u2200 a0 a1. (M \u2032 = a0 \u00b7 a1) \u21d2 (f3 a0 a1 = f \u2032 3 a0 a1)) \u21d2 (Form_CASE M f f1 f2 f3 = Form_CASE M \u2032 f \u2032 f \u20321 f \u2032 2 f \u2032 3)\nForm_distinct:\n\u22a2 (\u2200 a1 a0 a. At a 6= a0 / a1) \u2227 (\u2200 a1 a0 a. At a 6= a0 \\ a1) \u2227 (\u2200 a1 a0 a. At a 6= a0 \u00b7 a1) \u2227 (\u2200 a\u2032\n1 a1 a\n\u2032 0 a0. a0 / a1 6= a \u2032 0 \\ a\u2032 1 ) \u2227\n(\u2200 a\u20321 a1 a \u2032 0 a0. a0 / a1 6= a \u2032 0 \u00b7 a \u2032 1) \u2227 \u2200 a\u2032\n1 a1 a\n\u2032 0 a0. a0 \\ a1 6= a \u2032 0 \u00b7 a\u2032 1\nForm_induction:\n\u22a2 (\u2200 a. P (At a)) \u2227 (\u2200F \u2032 F0. P F \u2032 \u2227 P F0 \u21d2 P (F \u2032 / F0)) \u2227 (\u2200F \u2032 F0. P F \u2032 \u2227 P F0 \u21d2 P (F \u2032 \\ F0)) \u2227\n(\u2200F \u2032 F0. P F \u2032 \u2227 P F0 \u21d2 P (F \u2032 \u00b7 F0)) \u21d2 \u2200F \u2032. P F \u2032\nForm_nchotomy:\n\u22a2 (\u2203 a. F \u2032F \u2032 = At a) \u2228 (\u2203F \u2032 F0. F \u2032F \u2032 = F \u2032 / F0) \u2228\n(\u2203F \u2032 F0. F \u2032F \u2032 = F \u2032 \\ F0) \u2228 \u2203F \u2032 F0. F \u2032F \u2032 = F \u2032 \u00b7 F0\nwhere the constant TYPE_DEFINITION is defined in the theory bool by:\n\u22a2 TYPE_DEFINITION = (\u03bbP rep.\n(\u2200 x \u2032 x \u2032\u2032. (rep x \u2032 = rep x \u2032\u2032) \u21d2 (x \u2032 = x \u2032\u2032)) \u2227 \u2200 x. P x \u21d0\u21d2 \u2203 x \u2032. x = rep x \u2032)\nWith all above theorems, any theorem in which the type Form is used, can be handled by combining above theorems with other related theorems, although most of time, some HOL\u2019s tacticals can benefit from these generated theorems implicitly. In Coq, datatypes are handled in black-box like ways: user has no direct access to any theorem related to datatype themselves.\nSimilarily, an induction relation arrow in HOL is just defined by some generated theorems:\narrow_def:\n\u22a2 arrow = (\u03bb a0 a1 a2.\n\u2200 arrow \u2032. (\u2200 a0 a1 a2.\n(a2 = a1) \u2228 (\u2203B C. (a2 = C / B) \u2227 arrow\n\u2032 a0 (a1 \u00b7 B) C) \u2228 (\u2203A B. (a1 = A \u00b7 B) \u2227 arrow\n\u2032 a0 A (a2 / B)) \u2228 (\u2203A C. (a2 = A \\ C) \u2227 arrow\n\u2032 a0 (A \u00b7 a1) C) \u2228 (\u2203A B. (a1 = A \u00b7 B) \u2227 arrow\n\u2032 a0 B (A \\ a2)) \u2228 (\u2203B. arrow \u2032 a0 a1 B \u2227 arrow\n\u2032 a0 B a2) \u2228 a0 a1 a2 \u21d2 arrow \u2032 a0 a1 a2) \u21d2\narrow \u2032 a0 a1 a2) arrow_rules:\n\u22a2 (\u2200X A. arrow X A A) \u2227 (\u2200X A B C. arrow X (A \u00b7 B) C \u21d2 arrow X A (C / B)) \u2227 (\u2200X A B C. arrow X A (C / B) \u21d2 arrow X (A \u00b7 B) C) \u2227 (\u2200X A B C. arrow X (A \u00b7 B) C \u21d2 arrow X B (A \\ C)) \u2227 (\u2200X A B C. arrow X B (A \\ C) \u21d2 arrow X (A \u00b7 B) C) \u2227 (\u2200X A B C. arrow X A B \u2227 arrow X B C \u21d2 arrow X A C) \u2227 \u2200X A B. X A B \u21d2 arrow X A B\narrow_strongind:\n\u22a2 (\u2200X A. arrow \u2032 X A A) \u2227 (\u2200X A B C.\narrow X (A \u00b7 B) C \u2227 arrow \u2032 X (A \u00b7 B) C \u21d2 arrow \u2032 X A (C / B)) \u2227\n(\u2200X A B C.\narrow X A (C / B) \u2227 arrow \u2032 X A (C / B) \u21d2 arrow \u2032 X (A \u00b7 B) C) \u2227\n(\u2200X A B C. arrow X (A \u00b7 B) C \u2227 arrow \u2032 X (A \u00b7 B) C \u21d2 arrow \u2032 X B (A \\ C)) \u2227 (\u2200X A B C. arrow X B (A \\ C) \u2227 arrow \u2032 X B (A \\ C) \u21d2 arrow \u2032 X (A \u00b7 B) C) \u2227 (\u2200X A B C. arrow X A B \u2227 arrow \u2032 X A B \u2227 arrow X B C \u2227 arrow \u2032 X B C \u21d2 arrow \u2032 X A C) \u2227 (\u2200X A B. X A B \u21d2 arrow \u2032 X A B) \u21d2 \u2200 a0 a1 a2. arrow a0 a1 a2 \u21d2 arrow \u2032 a0 a1 a2\narrow_ind:\n\u22a2 (\u2200X A. arrow \u2032 X A A) \u2227 (\u2200X A B C. arrow \u2032 X (A \u00b7 B) C \u21d2 arrow \u2032 X A (C / B)) \u2227 (\u2200X A B C. arrow \u2032 X A (C / B) \u21d2 arrow \u2032 X (A \u00b7 B) C) \u2227 (\u2200X A B C. arrow \u2032 X (A \u00b7 B) C \u21d2 arrow \u2032 X B (A \\ C)) \u2227 (\u2200X A B C. arrow \u2032 X B (A \\ C) \u21d2 arrow \u2032 X (A \u00b7 B) C) \u2227 (\u2200X A B C. arrow \u2032 X A B \u2227 arrow \u2032 X B C \u21d2 arrow \u2032 X A C) \u2227 (\u2200X A B. X A B \u21d2 arrow \u2032 X A B) \u21d2 \u2200 a0 a1 a2. arrow a0 a1 a2 \u21d2 arrow\n\u2032 a0 a1 a2 arrow_cases:\n\u22a2 arrow a0 a1 a2 \u21d0\u21d2 (a2 = a1) \u2228 (\u2203B C. (a2 = C / B) \u2227 arrow a0 (a1 \u00b7 B) C) \u2228 (\u2203A B. (a1 = A \u00b7 B) \u2227 arrow a0 A (a2 / B)) \u2228 (\u2203A C. (a2 = A \\ C) \u2227 arrow a0 (A \u00b7 a1) C) \u2228 (\u2203A B. (a1 = A \u00b7 B) \u2227 arrow a0 B (A \\ a2)) \u2228 (\u2203B. arrow a0 a1 B \u2227 arrow a0 B a2) \u2228 a0 a1 a2\nWith all above theorems, any theorem in which the relation arrow is used, can be handled by combining above theorems with other related theorems.\nHere is the essential differences between Coq and HOL that we have observed on inductive relations: In HOL, terms like arrow X A B has type bool; while in Coq, its type is Set.\nHere is the consequence: in HOL, in terms like arrow X A B \u2227 arrow X B C or arrow X A B \u21d2 arrow X A C they\u2019re normal logical connectives between boolean values (first is \u201cand\u201d, second is \u201cimplies\u201d). But in Coq, logical connectives never appears between two Sets. Instead, theorems like A / B ==> C were always represented as A -> B -> C in which -> serves as logical implication but actually has more complex meanings."}, {"heading": "6.2 Further on logical connectives", "text": "In HOL, basic Boolean connectives and first-order logic quantifiers like \u201cforall\u201d, \u201cexists\u201d, \u201cand\u201d, \u201cor\u201d, \u201cnot\u201d and even \u201ctrue\u201d, \u201cfalse\u201d, are all defined as \u03bb terms:\n\u22a2 T \u21d0\u21d2 ((\u03bb x. x) = (\u03bb x. x)) \u22a2 (\u2200 ) = (\u03bbP. P = (\u03bb x. T)) \u22a2 (\u2203 ) = (\u03bbP. P ((\u03b5) P)) \u22a2 (\u2227) = (\u03bb t1 t2. \u2200 t. (t1 \u21d2 t2 \u21d2 t) \u21d2 t) \u22a2 (\u2228) = (\u03bb t1 t2. \u2200 t. (t1 \u21d2 t) \u21d2 (t2 \u21d2 t) \u21d2 t) \u22a2 F \u21d0\u21d2 \u2200 t. t \u22a2 (\u00ac) = (\u03bb t. t \u21d2 F) \u22a2 (\u2203!) = (\u03bbP. (\u2203 ) P \u2227 \u2200 x y. P x \u2227 P y \u21d2 (x = y))\nSince they\u2019re all \u03bb terms, any facts about their relationship can be proved within the framework of \u03bb-calculus, using \u03b2-reductions and other basic deduction rules. That\u2019s so clear!\nWhile in Coq, it\u2019s surprised to notice that, the quantifier forall is something quite primitive: it\u2019s a keyword in Coq. While there\u2019s no exists keyword at all. And to express the existence of something in any theorem, user must write it as a lambda function. For instance, our replace_inv2 theorem in HOL contains two existence quantifier variables:\n\u22a2 replace (Comma Gamma1 Gamma2) Gamma \u2032 (OneForm X ) Delta \u21d2\n(\u2203G. (Gamma\u2032 = Comma G Gamma2) \u2227 replace Gamma1 G (OneForm X ) Delta) \u2228 \u2203G. (Gamma\u2032 = Comma Gamma1 G) \u2227 replace Gamma2 G (OneForm X ) Delta\nThe meaning of above theorem is quite clear just by reading it. While in Coq, the same theorem must be expressed in this strange way:\nLemma replace_inv2 :\nforall (Gamma1 Gamma2 Gamma \u2019 Delta : Term Atoms) (X : Form Atoms), replace (Comma Gamma1 Gamma2) Gamma \u2019 (OneForm X) Delta -> sigS\n(fun Gamma \u20191 : Term Atoms =>\n{x_ : replace Gamma1 Gamma \u20191 (OneForm X) Delta | Gamma \u2019 = Comma Gamma \u20191 Gamma2 }) +\nsigS\n(fun Gamma \u20192 : Term Atoms =>\n{x_ : replace Gamma2 Gamma \u20192 (OneForm X) Delta | Gamma \u2019 = Comma Gamma1 Gamma \u20192}).\nplease notice that, how logical \u201cand\u201d and \u201cor\u201d must be expressed as | and + between Sets in Coq. The author hope these examples could convince the readers that, Coq is very unnatural for representing logical theorems."}, {"heading": "6.3 On Coq\u2019s built-in supports of proofs", "text": "In previous section, we have mentioned that, Coq has built-in supports on \u201cproofs\u201d. This fact seems coming from the fact that, in Coq, each logical theorems has essentially the type Set which is indeed a mathematical set, and each element in such sets is one possible \u201cproof\u201d for that theorem! This is really a convenient feature when people need to prove results about proof themselves, but the drawback is, most of such theorems has large amount of variables.\nFor instance, our last theorem in CutFreeTheory is subFormulaProperty, which has the following representation in HOL:\n\u22a2 subProof q p \u21d2 extensionSub (exten p) \u21d2 CutFreeProof p \u21d2 \u2200 x. subFormTerm x (prems q) \u2228 subFormula x (concl q) \u21d2 subFormTerm x (prems p) \u2228 subFormula x (concl p)\nThis theorem was actually ported from Coq, from the following theorem:\nLemma subFormulaProperty :\nforall (Atoms : Set) (Gamma1 Gamma2 : Term Atoms)\n(B C x : Form Atoms) (E : gentzen_extension ) (p : gentzenSequent E Gamma1 B) (q : gentzenSequent E Gamma2 C),\nextensionSub Atoms E -> subProof q p -> CutFreeProof p -> subFormTerm x Gamma2 \\/ subFormula x C -> subFormTerm x Gamma1 \\/ subFormula x B.\nNow let\u2019s count how many variables are used in above theorem in Coq: Atoms, Gamma1, Gamma2, B, C, x, E, p, q, 9 variables totally. While in the HOL version, 3 variables are just enough (two \u201cproofs\u201d plus one Term).\nOnce we have proved above HOL theorem, we can also easily prove the following theorem which has the same amount of variables as Coq:\n\u22a2 (p = Der (Sequent E Gamma1 B) _ _) \u21d2 (q = Der (Sequent E Gamma2 C) _ _) \u21d2 extensionSub E \u21d2 subProof q p \u21d2 CutFreeProof p \u21d2 subFormTerm x Gamma2 \u2228 subFormula x C \u21d2 subFormTerm x Gamma1 \u2228 subFormula x B\nbut the other direction is not easy (maybe just impossible): if we have already this last theorem in HOL, no way to get the previous theorem with only 3 variables.\nNevertheless, for Coq\u2019s built-in supports of proof, HOL users can prove the same theorems, although they have to invent the concept and structure of \u201cproofs\u201d from almost ground, and case by case. But the author thinks, it\u2019s quite fair to say that, all theorems provers have exactly the same set of theorems that they\u2019re capable to prove. So the remain question is how to choose between them. Most of time, it\u2019s just a matter of personal preferences, experiences and environment requirements (e.g. when you were doing formalization studies in France, you have to use Coq and OCaml, which are both invented by Franch people)."}, {"heading": "7 Future directions", "text": "From the view of theorem proving, the following theorems are worth to prove in the future:\n1. Cut-elimination theorem for Lambek Calculus with arbitrary sequent extensions. 2. Lambek calculus L is context-free. [11]\nThe cut-elimination theorem can be proved directly using the existing framework in our CutFreeTheory, while for the second goal, a full treatment of Lambek Calculus in model-theoretic approach with many new foundamental definitions and theorems must be done first.\nFrom the view of language parsing, the following goals remain to be finished:\n1. Implement an automatic proof searching algorithm for Sequent Calculus as a HOL tactical. 2. Implement the same algorithm for generating first-class proof trees (Dertree). 3. Implement a language parser as ML functions which generates both parsing trees and validation\ntheorems. 4. Design a lexicon data structure for holding large amount of words, each with more than one categories. 5. Design and implement machine learning algorithms to build a large enough lexicon for Italian lan-\nguage."}, {"heading": "8 Conclusions", "text": "In this project, we have implemented a rather complete proof-theoretical formalization of Lambek Calculus (non-associative, with arbitrary extensions).\nThe current status is enough as a tool kit for manually proving category theorems in three deduction systems of Lambek Calculus: Axiomatic Syntactic Calculus, Natural Deduction (in Gentzen style) and Gentzen\u2019s Sequent Calculus. It can also be considered as a base framework for further formalization of more deep theorems of Lambek Calculus, e.g. the cut-elimination theorem of Gentzen\u2019s Sequent Calculus of Lambek Calculus.\nThis work is based on the Lambek Calculus formalization in Coq, by Houda ANOUN and Pierre Casteran in 2002-2003. For the modules that we have migrated from Coq, we improved definitions and proved many new theorems. For the proof-theoretic formalization of Sequent Calculus proofs, our work (first-class proof trees in HOL, including related derivation definitions and theorems) is completely new.\nThanks to Prof. Fabio Tambrini, who has introduced Lambek Calculus to the author in his NLP course at University of Bologna."}, {"heading": "1. Chomsky, N.: On certain formal properties of grammars. Information and Computation 2 (1959) 137\u2013167", "text": "2. Chomsky, N.: Syntactic Structures. Walter de Gruyter (January 2002)\n3. Napoli, D.J., Burzio, L.: Italian Syntax: A Government-Binding Approach. Language 64(1) (1988) 130 4. Ajdukiewicz, K.: Syntactic Connexion (1936). In: The Scientific World-Perspective and Other Essays,\n1931\u20131963. Springer Netherlands, Dordrecht (1978) 118\u2013139 5. Bar-Hillel, Y.: A quasi-arithmetical notation for syntactic description. Language 29(1) (1953) 47 6. Moot, R., Retore, C.: The Logic of Categorial Grammars. Volume 6850 of Lecture Notes in Computer Science.\nSpringer Berlin Heidelberg, Berlin, Heidelberg (2012) 7. Lambek, J.: The mathematics of sentence structure. The American Mathematical Monthly 65(3) (1958)\n154\u2013170 8. Cohen, J.M.: The equivalence of two concepts of categorial grammar. Information and Control 10(5) (1967)\n475\u2013484 9. Pentus, M.: Lambek calculus is NP-complete. Theoretical Computer Science 357(1-3) (July 2006) 186\u2013201 10. Pentus, M.: Lambek calculus is L-complete. Institute for Logic (1993) 11. Pentus, M.: Lambek grammars are context free. In: Eighth Annual IEEE Symposium on Logic in Computer\nScience (Montreal, PQ, 1993). IEEE Comput. Soc. Press, Los Alamitos, CA (1993) 429\u2013433 12. Lambek, J.: On the calculus of syntactic types. Proceedings of Symposia in Applied Mathematics 12 (1961)\n166\u2013178 13. Melham, T.F.: A Package for Inductive Relation Definitions in HOL. (January 2017) 1\u201310 14. Prawitz, D.: Natural deduction. A proof-theoretical study. Acta Universitatis Stockholmiensis. Stockholm\nStudies in Philosophy, No. 3. Almqvist & Wiksell, Stockholm (1965) 15. Gentzen, G.: Untersuchungen u\u0308ber das logische Schlie en. I. Mathematische Zeitschrift 39(1) (1935) 176\u2013210 16. Gentzen, G.: Untersuchungen u\u0308ber das logische Schlie en. II. Mathematische Zeitschrift 39(1) (1935) 405\u2013431 17. Dawson, J.E., Gore\u0301, R.: Machine-checked Cut-elimination for Display Logic. (2006)"}], "references": [{"title": "On certain formal properties of grammars", "author": ["N. Chomsky"], "venue": "Information and Computation 2", "citeRegEx": "1", "shortCiteRegEx": null, "year": 1959}, {"title": "Syntactic Structures", "author": ["N. Chomsky"], "venue": "Walter de Gruyter", "citeRegEx": "2", "shortCiteRegEx": null, "year": 2002}, {"title": "Italian Syntax: A Government-Binding Approach", "author": ["D.J. Napoli", "L. Burzio"], "venue": "Language 64(1)", "citeRegEx": "3", "shortCiteRegEx": null, "year": 1988}, {"title": "Syntactic Connexion (1936)", "author": ["K. Ajdukiewicz"], "venue": "The Scientific World-Perspective and Other Essays, 1931\u20131963. Springer Netherlands, Dordrecht", "citeRegEx": "4", "shortCiteRegEx": null, "year": 1978}, {"title": "A quasi-arithmetical notation for syntactic description", "author": ["Y. Bar-Hillel"], "venue": "Language 29(1)", "citeRegEx": "5", "shortCiteRegEx": null, "year": 1953}, {"title": "The Logic of Categorial Grammars", "author": ["R. Moot", "C. Retore"], "venue": "Volume 6850 of Lecture Notes in Computer Science. Springer Berlin Heidelberg, Berlin, Heidelberg", "citeRegEx": "6", "shortCiteRegEx": null, "year": 2012}, {"title": "The mathematics of sentence structure", "author": ["J. Lambek"], "venue": "The American Mathematical Monthly 65(3)", "citeRegEx": "7", "shortCiteRegEx": null, "year": 1958}, {"title": "The equivalence of two concepts of categorial grammar", "author": ["J.M. Cohen"], "venue": "Information and Control 10(5)", "citeRegEx": "8", "shortCiteRegEx": null, "year": 1967}, {"title": "Lambek calculus is NP-complete", "author": ["M. Pentus"], "venue": "Theoretical Computer Science 357(1-3)", "citeRegEx": "9", "shortCiteRegEx": null, "year": 2006}, {"title": "Lambek calculus is L-complete", "author": ["M. Pentus"], "venue": "Institute for Logic", "citeRegEx": "10", "shortCiteRegEx": null, "year": 1993}, {"title": "Lambek grammars are context free", "author": ["M. Pentus"], "venue": "Eighth Annual IEEE Symposium on Logic in Computer Science (Montreal, PQ, 1993). IEEE Comput. Soc. Press, Los Alamitos, CA", "citeRegEx": "11", "shortCiteRegEx": null, "year": 1993}, {"title": "On the calculus of syntactic types", "author": ["J. Lambek"], "venue": "Proceedings of Symposia in Applied Mathematics 12", "citeRegEx": "12", "shortCiteRegEx": null, "year": 1961}, {"title": "A Package for Inductive Relation Definitions in HOL", "author": ["T.F. Melham"], "venue": null, "citeRegEx": "13", "shortCiteRegEx": "13", "year": 2017}, {"title": "Natural deduction", "author": ["D. Prawitz"], "venue": "A proof-theoretical study. Acta Universitatis Stockholmiensis. Stockholm Studies in Philosophy, No. 3. Almqvist & Wiksell, Stockholm", "citeRegEx": "14", "shortCiteRegEx": null, "year": 1965}, {"title": "Untersuchungen \u00fcber das logische Schlie en", "author": ["G. Gentzen"], "venue": "I. Mathematische Zeitschrift 39(1)", "citeRegEx": "15", "shortCiteRegEx": null, "year": 1935}, {"title": "Untersuchungen \u00fcber das logische Schlie en", "author": ["G. Gentzen"], "venue": "II. Mathematische Zeitschrift 39(1)", "citeRegEx": "16", "shortCiteRegEx": null, "year": 1935}, {"title": "Machine-checked Cut-elimination for Display Logic", "author": ["J.E. Dawson", "R. Gor\u00e9"], "venue": null, "citeRegEx": "17", "shortCiteRegEx": "17", "year": 2006}], "referenceMentions": [{"referenceID": 0, "context": "Since the year when Noam Chomsky published his famous \u201cHierarchy\u201d [1] and his work on phrase structures of English and Spanish [2] in 1950s, the concepts of context-free and context-sensitive languages (and the intemediate areas between them) with the uses of rewriting rules to represent the phrase structure grammar of any given language, has dominated the parsing theory until today.", "startOffset": 66, "endOffset": 69}, {"referenceID": 1, "context": "Since the year when Noam Chomsky published his famous \u201cHierarchy\u201d [1] and his work on phrase structures of English and Spanish [2] in 1950s, the concepts of context-free and context-sensitive languages (and the intemediate areas between them) with the uses of rewriting rules to represent the phrase structure grammar of any given language, has dominated the parsing theory until today.", "startOffset": 127, "endOffset": 130}, {"referenceID": 2, "context": "33 of [3]) with an", "startOffset": 6, "endOffset": 9}, {"referenceID": 3, "context": "Categorial Grammar was firstly introduced by Polish philosopher and logician Kazimierz Ajdukiewicz in 1935 [4], which is based on ideas from precedent Polish logicians.", "startOffset": 107, "endOffset": 110}, {"referenceID": 4, "context": "In 1953, just two years before Chomsky published his phrase structure grammar theory and the famous hierarchy, Israeli philosopher, mathematician, and linguist Yehoshua Bar-Hillel made an important enhancement [5] to Ajdukiewicz\u2019s categorial grammar.", "startOffset": 210, "endOffset": 213}, {"referenceID": 5, "context": "[6].", "startOffset": 0, "endOffset": 3}, {"referenceID": 6, "context": "Finally, in 1958, Joachim Lambek [7] succesfully defined a formal system for syntactic calculus in which all category formulae can be derived from a basic set of rules (as axioms) and basic logic formulae.", "startOffset": 33, "endOffset": 36}, {"referenceID": 7, "context": "Although Lambek calculues has more rules then AB grammar, but they\u2019re actually equivalent: \u201ca set of strings of words forms a categorial language of one type if and only if it forms a categorial language of the other type\u201d [8]; 2.", "startOffset": 223, "endOffset": 226}, {"referenceID": 6, "context": "This was proved by Lambek (1958) [7].", "startOffset": 33, "endOffset": 36}, {"referenceID": 8, "context": "Lambek calculus is NP-complete [9], L-complete [10], and Lambek grammars are context-free [11].", "startOffset": 31, "endOffset": 34}, {"referenceID": 9, "context": "Lambek calculus is NP-complete [9], L-complete [10], and Lambek grammars are context-free [11].", "startOffset": 47, "endOffset": 51}, {"referenceID": 10, "context": "Lambek calculus is NP-complete [9], L-complete [10], and Lambek grammars are context-free [11].", "startOffset": 90, "endOffset": 94}, {"referenceID": 11, "context": "Among other issues, to resolve the key limitation that Lambek calculus cannot be used as a language parser, in 1961, Lambek introduced the so-called Non-associative Lambek Calculus [12], or NL.", "startOffset": 181, "endOffset": 185}, {"referenceID": 5, "context": "6 of [6] for detailed discussions and links tooriginal papers) Beside L and NL, there\u2019s also NLP in which the commutativity of products is respect based on NL, i.", "startOffset": 5, "endOffset": 8}, {"referenceID": 5, "context": "(see Chapter 5 of [6]).", "startOffset": 18, "endOffset": 21}, {"referenceID": 5, "context": "184 of [6]) In this paper, we have tried another possibility to extend Lambek Calculus.", "startOffset": 7, "endOffset": 10}, {"referenceID": 12, "context": "In HOL4, such a inductive relation can be easily defined by Hol_reln [13] command:", "startOffset": 69, "endOffset": 73}, {"referenceID": 6, "context": "For the original associative Lambek Calculus, we have proved all arrow theorems mentioned in Lambek (1958) [7].", "startOffset": 107, "endOffset": 110}, {"referenceID": 13, "context": "Natural deduction was first invented by Dag Prawitz [14] as a non-semantic approach to derive propositional logic formulae.", "startOffset": 52, "endOffset": 56}, {"referenceID": 14, "context": "Sequent Calculus was original introduced by Gerhard Gentzen in two German papers [15] [16] written in 1935.", "startOffset": 81, "endOffset": 85}, {"referenceID": 15, "context": "Sequent Calculus was original introduced by Gerhard Gentzen in two German papers [15] [16] written in 1935.", "startOffset": 86, "endOffset": 90}, {"referenceID": 16, "context": "Our datatype definition is based on similar modelling work in Isabelle/HOL for Display Logic [17], then all other related inductive relation definitions and theorems are new.", "startOffset": 93, "endOffset": 97}, {"referenceID": 6, "context": "Cut-elimination theorem for Lambek Calculus was proved by Lambek for L [7] and NL [12].", "startOffset": 71, "endOffset": 74}, {"referenceID": 11, "context": "Cut-elimination theorem for Lambek Calculus was proved by Lambek for L [7] and NL [12].", "startOffset": 82, "endOffset": 86}, {"referenceID": 10, "context": "[11]", "startOffset": 0, "endOffset": 4}], "year": 2017, "abstractText": "In this project, a rather complete proof-theoretical formalization of Lambek Calculus (non-associative with arbitrary extensions) has been ported from Coq proof assistent to HOL4 theorem prover, with some improvements and new theorems. Three deduction systems (Syntactic Calculus, Natural Deduction and Sequent Calculus) of Lambek Calculus are defined with many related theorems proved. The equivalance between these systems are formally proved. Finally, a formalization of Sequent Calculus proofs (where Coq has built-in supports) has been designed and implemented in HOL4. Some basic results including the subformula properties of the so-called \u201ccut-free\u201d proofs are formally proved. This work can be considered as the preliminary work towards a language parser based on category grammars which is not multimodal but still has ability to support context-sensitive languages through customized extensions.", "creator": "LaTeX with hyperref package"}}}