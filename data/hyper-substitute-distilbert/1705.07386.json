{"id": "1705.07386", "review": {"conference": "arxiv", "VERSION": "v1", "DATE_OF_SUBMISSION": "21-May-2017", "title": "DeepMasterPrint: Generating Fingerprints for Presentation Attacks", "abstract": "we present two general methods for creating efficient, synthetic means that primary user verification application identifies as many different functions. classical methods start with training a generative inference algorithm ( gan ) on a set using complex fingerprint images. next generator phase is then extended to discover for chemicals that can be recognized as multiple agents. whichever gamma method supports index values from serial mapping of static variables, and the second displays gradient - temporal search. our lab is able best design every masterprint that a compatible fingerprint system matches nearly 33 % of specific users in typical strict security setting, and 75 % that all users at a looser security meeting.", "histories": [["v1", "Sun, 21 May 2017 03:43:46 GMT  (994kb,D)", "http://arxiv.org/abs/1705.07386v1", null], ["v2", "Tue, 3 Oct 2017 21:51:38 GMT  (1003kb,D)", "http://arxiv.org/abs/1705.07386v2", "7 pages; added more domain context and references"]], "reviews": [], "SUBJECTS": "cs.CV cs.CR cs.LG", "authors": ["philip bontrager", "julian togelius", "nasir memon"], "accepted": false, "id": "1705.07386"}, "pdf": {"name": "1705.07386.pdf", "metadata": {"source": "CRF", "title": "DeepMasterPrint: Generating Fingerprints for Presentation Attacks", "authors": ["Philip Bontrager", "Julian Togelius", "Nasir Memon"], "emails": ["philipjb@nyu.edu", "julian@togelius.com", "memon@nyu.edu"], "sections": [{"heading": "1 Introduction", "text": "Fingerprints are commonly, and increasingly, used for authentication in a large variety of systems, from doors to workstations and smartphones. Like all biometric authentication procedures, fingerprints are potentially vulnerable to presentation attacks\u2014in other words, vulnerable to someone using a synthetic fingerprint to match as someone else. Due to the demand for quick matches, low cost, and the decreasing space left for fingerprint sensors in mobile system, fingerprint presentation attacks are potentially practical, if a method for generating useful synthetic fingerprints can be found.\nCould neural networks be used to generate fingerprint images to be used for MasterPrints? In particular, Generative Adversarial Networks (GAN) have shown great promise in generating images that reproduce a particular style or domain. However, their standard design does not allow the generator to target additional constraints and objectives beyond matching the data. For a MasterPrint, we need to create a synthetic fingerprint that fools a fingerprint verification system. The verification system not only has recognize that the image is a fingerprint, but also match the fingerprint to many different identities. Therefore, a generator network would need to be combined with a way of searching for fingerprints that are suitable MasterPrints.\nIn this paper, we present two related techniques for creating MasterPrints, i.e., partial fingerprints that can fool fingerprint recognition software into matching a large number of people. Both methods start with training a GAN to create partial fingerprint images based on a corpus of either capacitive or ink rolled fingerprint images. The first of the methods for creating MasterPrints is based on evolutionary optimization of latent variables: a Covariance Matrix Adaptation Evolution Strategy (CMA-ES) is used to search for the inputs to the the generator network that creates images that are recognized as many separate fingerprints as possible by a commercial fingerprint recognition software. The second method, which does not require access to an external fingerprint recognition software, trains a neural network-based fingerprint classifier and then uses gradient descent to find latent variables that maximize the number of activated outputs.\nPrevious work on finding MasterPrints has relied on stochastic search in the space of minutiae, a relatively high-level representation of fingerprints, which cannot easily be translated to high-quality fingerprint images. In contrast, our method produces complete images which are visually similar to natural fingerprint images.\nar X\niv :1\n70 5.\n07 38\n6v 1\n[ cs\n.C V\n] 2\n1 M\nay 2\n01 7"}, {"heading": "2 Background", "text": ""}, {"heading": "2.1 Fingerprint presentation attacks", "text": "Recently, Roy et al. [12] studied the vulnerability of fingerprint-based biometric systems that have small sensors for authentication and therefore only scan part of the fingerprint. They found these systems are highly susceptible to a type of presentation attack that is known as a \u201cwolf attack\u201d [14]. A \"wolf\" is a biometric sample, real or synthesized, that impersonates multiple subjects\u2019 biometrics. This type of attack does not require an individual\u2019s biometric sample but instead is be deployed against unknown people with some probability of a successful attack.\nSmall fingerprint scanners are too small to read the entire fingerprint and therefore the system must authenticate on just the cross-section of the finger that is read from the sensor. Since it would be impractical to require the user to place their finger the exact same way every time, these systems normally take multiple readings from the same finger. When an input is presented to the system, it compares the input against all of the partial prints that it has for a subject. This means that if a subject has n fingers in the system and k partials saved per fingerprint, then there are are n\u00d7 k opportunities for a match and the system only needs a match on one of them. These types of biometric systems are common on consumer mobile devices.\nRoy et al. [12] showed that there exists synthetic fingerprints that can match for many fingerprints in a dataset. Their method represents fingerprints as minutiae templates. A minutia template represents all the points of interest in a fingerprint. This includes where ridges end, where they split, and the angle going away from that point. Many fingerprint identification systems will first identify the minutiae in the fingerprint and then compare them to the minutia template saved in the system. Roy et al then use a hill-climbing algorithm to search for a minutia template to use for a wolf attack; the objective function is simply the number of people in the database that the fingerprint identifies positively as.\nIn our work we generate the images directly instead of working at the minutia level. This provides actual synthetic fingerprints that can be used, whereas the previous work only generated minutia templates. There is work to synthesize fingerprints from minutiae [4], but by working at the image level we can also optimize for systems that don\u2019t use minutiae, systems such as the iPhone [1]."}, {"heading": "2.2 Image generation", "text": "Recently there has been rapid advancements in image generation by way of neural networks. Some of the most popular methods for image generation are Fully Visible Belief Networks (FVBN), Variational Autoencoders (VAE), and Generative Adversarial Networks (GAN) [6]. FVBNs such as PixelRNN produce one pixel at a time, similar to text generation and can have a bit of noise in their output. VAEs on the other hand tend to produce very smooth outputs. Current GAN methods are perceived to produce the best results with fewer artifacts than FVBNs and sharper images than VAEs [6].\nGANs learn to generate images in a semi-supervised fashion. There are two parts to GAN; a generator and a discriminator. The generator is typically a neural network that takes random noise as an input and outputs an image. The discriminator is also typically a neural network, it takes an image as an input and classifies it as real or generated. To train the generator to produce images within the domain of the sample images, training happens in three steps:\n1. Provide real images to the discriminator. Train the discriminator to classify them as real.\n2. Provide generated images to the discriminator. Train it to classify them as generated.\n3. Provide the generator with the discriminator\u2019s gradients. Train the generator to produce images that are classified as real.\nThis process is repeated until the network converges on the distribution of the real data.\nA major difficulty during training is keeping the two networks balanced so one doesn\u2019t get significantly better than the other. A recent technique to stabilize training is the Wasserstein GAN (WGAN) [2]. In standard GAN training the discriminator classifies the input as one of two classes, \u201creal\u201d or \u201cgenerated\u201d. The difference between the real data distribution and the generated data is then measured using the Jensen-Shannon divergence (JS) [2]. This metric does not provide a gradient everywhere\nfor the generator and therefore requires that the discriminator and generator are closely matched. This makes training unstable. WGAN, instead uses an approximation of the Wasserstein distance function to measure the difference between the real and fake distributions [2]. Since it is differentiable everywhere, it provides meaningful gradients for the generator. The two networks don\u2019t have to be well balanced so the discriminator can be better trained preventing mode collapse.\nThis is just one of a few GAN architectures that have recently had success with producing detailed, higher resolution images. Other examples not used here are the Boundary Equilibrium GAN [3] and Energy Based GAN [16]."}, {"heading": "3 Datasets", "text": "In this work we model two types of fingerprint images; those scanned from rolled impressions and those obtained from a capacitive sensor. Rolled fingerprints are produced by applying ink to the finger and rolling the finger on paper. Capacitive sensors record ridge information based on where the finger contacts the sensor.\nRolled images The rolled fingerprints come from the publicly available NIST Special Database 9 fingerprint dataset [15]. The dataset consists of all 10 fingerprints of 5400 unique subjects. Each fingerprint is an 8-bit gray scale image. For each subject, the right thumbprint is selected since that is a common finger used in authentication systems. The images are preprocessed by cropping out the whitespace and then downscaling to 256\u00d7 256 pixels. To get partial fingerprint samples, a random 128\u00d7 128 region is selected every time an image is selected.\nCapacitive images The capacitive fingerprint images come from the FingerPass DB7 dataset [10]. This dataset has 12 partial fingerprints per each of its 720 subjects. Each partial print is 144\u00d7 144 at 500 dpi. This is similar to what is scanned by an iPhone [1]. This is the same dataset used by Roy et al. in their MasterPrint paper [12]."}, {"heading": "4 Methods", "text": "There are two parts to our approach to creating a MasterPrint; (1) learning the prior distribution of fingerprint images and (2) searching the distribution for an image that satisfies the criteria of a wolf attack. To learn the prior distribution, we use the WGAN method, described earlier, to train a generator network. Our generators receive 100 random numbers as input and output a random fingerprint image. We learn the priors of two different datasets to test how resilient the results are to different types of fingerprint sensors. To search the prior distribution for a MasterPrint, we search the generators\u2019 100 latent variables. We develop two separate techniques for searching this latent space."}, {"heading": "4.1 Latent variable evolution", "text": "When there is access to the fingerprint verification system, then the MasterPrint can be directly optimized for that system. This can be achieved by incorporating the fingerprint verification system into the optimization process as a black-box fitness function. To search the latent variables of the image generator for an input that will output a wolf attack, an evolutionary algorithm is a powerful technique. An evolutionary algorithm does not require gradients and therefore are ideal for black-box optimization. For an evolutionary algorithm, a potential optimal solution is represented as a vector. In this case the vector represents the 100 inputs to the fingerprint generator. A fixed number of these proposed solutions are tested and scored. The best ones are kept and mutated to form the next generation [5].\nIn this paper we use a specific evolutionary strategy called Covariance Matrix Adaption (CMA-ES). CMA-ES learns the covariance matrix of the variables being optimized. This knowledge allows the algorithm to intelligently guide mutations when many variables are highly correlated [8]. Since the variables in this work are the inputs to a neural network, there it is high likelihood that many variables will be correlated and this strategy will be more effective than standard evolutionary strategies. In this work we use Hansen\u2019s Python implementation of CMA-ES [7].\nFor our work we use two different fingerprint verification systems. To be able to compare our results to previous work, we use the widely deployed commercial fingerprint system, VeriFinger 9.0 SDK. This is the system used by Roy et al. [12]. To be able to test how well optimization for one black-box transfers to another, we also use the Bozorth3 system. This system is provided open source by NIST as part of their NIST Biometric Image Software (NBIS)."}, {"heading": "4.2 Multi-label activation maximization", "text": "When access to the fingerprint verification system is not available, it is necessary to use a proxy verification system. We use a convolutional neural network (CNN) as the proxy system. To use a CNN as a fingerprint verification system, it has to be trained to classify fingerprints by subject. The advantage of using a CNN as the verification system is that it provides a gradient that can be used for optimization. Instead of using evolution to optimize the generator\u2019s latent variables, backpropagation can be used.\nThe CNN is trained on inputs of 128\u00d7 128 partial fingerprint images. For every subject in the dataset, it has a corresponding output class. For a wolf attack, there needs to be a single input that activates all of the CNN\u2019s outputs. During optimization, start with random latent variable values, z. Use z to generate an image and calculate a CNN output. Calculate the error for a label corresponding to all the outputs being activated. Backpropagate the error through the CNN and the generator back to z to get z\u2032. This repeats until the optimal z is found.\nActivation maximization for one or two neurons in a CNN has recently been done in a similar manner by Nguyen et al. [11]. They used this technique for understanding networks better and proposed using maximizing two neurons for art. Here we are maximizing many neurons at once and each neuron represents a functional objective for our generator.\nOur CNN architectures are the Residual Network (ResNet) that has achieved superhuman results on the ImageNet classification competition [9], the smaller, yet still powerful, VGG16 architecture [13], and a simple convolutional design with 3 convolutional layers and 3 fully connected layers on top. To allow these networks to make multi-label predictions, the top layer is replaced. Normally the top layer is a softmax layer, this forces all the outputs to sum to 1 so that the network outputs a probability distribution of its predictions. To make each prediction independent, each class is represented in the top layer by one sigmoid activation function. To produce the training data, many partial fingerprints are sampled from each full fingerprint that is used to identify a subject."}, {"heading": "5 Results", "text": ""}, {"heading": "5.1 WGAN fingerprints", "text": "The results of training the WGAN generator can be seen in Figure 1. In the right column are the generated images, the left column contains samples from the actual datasets. The image generator seems to have captured the basic structures in both instances.\nFigure 1a shows partial fingerprints for rolled fingerprints from the NIST dataset. Looking at the right batch, it is clear that the generator has learned the general ridge structure of a fingerprint. Looking closer, there are certain areas that look smudged. Most likely due to the fact that the data is generated from random sections of the fingerprint, the generator had a difficult time learning the more global shapes of a fingerprint. From visual inspection it appears to have learned the texture. Some of the outputs do look very similar to the input data.\nFigure 1b displays the results for the capacitive fingerprints. The results seem to be a little better for this dataset. There are less smudges on the images and the ridges are better connected. Looking at larger batches, the generated capacitive images are more consistently good the the rolled images. This is likely because the capacitive data is cleaner and there is far less detail to learn.\nFor the generator in 1a it took 120,000 generator updates before the outputs stopped improving. After 120,000 the generator started to produce blocky images that eventually just became a grid. To avoid this checkered artifact, we replaced all the deconvolutional layers in the generator with upsampling and regular convolutions for the capacitive generator. This removed the artifacts and combined with the cleaner data resulted in a much faster training time for the generator in 1a."}, {"heading": "5.2 Latent variable evolution", "text": "To test the results of the Latent Variable Evolution (LVE) method, we devised a number of different tests. Both generators are optimized for the VeriFinger verification system, as seen in Figure 2. Similar to the work of Roy et al., the system is tested at three different security levels. The three levels are a 1%, 0.1%, and 0.01% False Match Rate (FMR). The FMR is the probability that an impostor fingerprint will be marked as a match. If the FMR is set too high, the system is not very secure. If it is too low, it will reject too many legitimate fingerprint readings.\nThe results for the VeriFinger system are achieved by optimizing the generator on half of the dataset and testing on the other half. Our results were comparable to previous, non-image-based methods. To further understand how well these results generalize to other systems, the fingerprints optimized for VeriFinger are also scored on the Bozorth3 system.\nIn Table 1 the percentage of false subject matches are displayed. The number of false subject matches are the number of subjects in the dataset that the MasterPrint matches. Each subject in the dataset is represented by 12 partial fingerprints, to get a subject match only 1 in 12 have to match. The percentage represents the percentage of subjects in the database that the MasterPrint matches. The second row in the table shows the results on the VeriFinger system when run on the test data. The third row are the percent of subject matches when the fingerprints are matched with the Bozorth3 system. Since the images aren\u2019t evolved for this system, this represents how well the match rate transfers.\nRolled MasterPrints The three rolled MasterPrints make up the left half of Figure 2. Each MasterPrint has around 20 minutiae points. At the lowest security level, a single fingerprint is able to\nmatch with 78% of the people in the dataset. This is a large number of subjects but it is unlikely that many systems are running with this low of a security setting. At the 0.1% FMR level, the MasterPrint matches 8.61% of the dataset. This represents a much more realistic security expectation and is a much higher number of matches than the FMR would lead one to expect. At the highest security level the results aren\u2019t very good, but this is also an unlikely security level as it would be inconvenient to the user.\nA very interesting part of the results is how well these MasterPrints do on the Bozorth3 verification system. These fingerprints are not optimized for it and yet the results are still good. At the middle security setting, the MasterPrint actually does better on the Bozorth3 system. This suggests that the fingerprint features in the MasterPrint that allow it to match so many subjects have general properties and it is not just targeting quirks in the VeriFinger system. Since both systems are minutiae based, it does not suggest generality beyond minutiae systems but it is an important fist step in showing that these results are applicable.\nCapacitive MasterPrints The three capacitive MasterPrints make up the right half of Figure 2. The generator used to create these images was trained on the same data that the fingerprint verification systems are matching against. This means that these MasterPrints are much more visually similar to the real data than the other MasterPrints. This should allow these MasterPrints to do better than the rolled MasterPrints. Looking at Table 1, the results appear to be a little bit improved. At the 0.01% FMR level, the results are much better. A one in five subject match rate at a realistic security level very high.\nThe results on the Bozorth3 system, on the other hand, are not nearly as good as what is seen with the rolled MasterPrint. One explanation for this is that the Bozorth3 system is designed and tested for the NIST data which consists of rolled fingerprint impressions. It may struggle with the capacitive MasterPrints. Another possibility is that the capacitive generator has less general ways to target the VeriFinger system. The images produced from the capacitive generator have much thicker ridges which means the model might be less flexible in targeting the system. To compensate images were evolved that have lots of noise in the center. Noise can easily target an individual system, but it does not usually transfer. Figure 2 supports this. The rolled MasterPrints are for the most part coherent while the capacitive MasterPrints have a lot of noise at the center of the image.\nMasterPrint comparisons The results obtained here are comparable to the results previously reported by Roy et al. [12]. They do not report on the results they obtained for individual synthetic minutiae points, but they graphically present the subject match rate of a set of 5 minutiae points. Our results at the 1% FMR level are as good as their result using five different fingerprints on a system that allows five attempts. The capacitive MasterPrint\u2019s scores are not much worse than their 5 fingerprint match rate at the higher security levels either. The results cannot be compared directly, but it is clear that these results are on par with the state of the art. They have the added benefit of being full images which can be fabricated into deployable attacks."}, {"heading": "5.3 Multi-label activation maximization", "text": "The Multi-Label Activation Maximization (MLAM) technique uses a CNN as a proxy for the fingerprint verification system. Yet, to analyze the quality of its results, we have to compare it to a benchmark. For this we once again use the VeriFInger verification system on the FingerPass dataset. This allows us to analyze how well the the CNN acts as a proxy to an unknown verification system.\nIn analyzing the MLAM MasterPrints on the VeriFinger system, we found that the results are very noisy. With MLAM, the results are highly dependent on the starting random latent variable values.\nThese values are incremented to maximize the sum of all the label outputs in the proxy classifier but often get stuck in local maxima. To reduce the dependence on the starting latent values, we try 50 random starts sets and after training all 50, take the best result. This helps stabilize and reduce the noise in the scores assigned by the proxy network. Despite the proxy network scoring the MasterPrints similarly, the scores from the VeriFinger system are not very consistent. This implies that which features get optimized are highly dependent on the initial random seed as the beginning of training. To be able analyze the effects of MLAM despite the noise, we produce 30 samples for every test and use the average value.\nDespite their high variability in score, all of the optimized samples look very similar. Part of this is perception is probably related to people\u2019s poor ability to distinguish fingerprints. Yet the fingerprints in Figure 3 are much more self similar than they are similar to other fingerprints presented in this paper.\nRolled MasterPrint The images on the left half of Figure 3 are created using the rolled fingerprint generator and optimized with a CNN using the ResNet architecture. The false subject probabilities of these MasterPrints is in Table 2. The Rolled data section shows; the average match rate for MLAM Masterprints, images generated at random, and random rolled fingerprint data samples at the 1% FMR level. The data shows that the rolled MasterPrints designed using this method match 20% of the subjects in the dataset. This can be compared to the MasterPrints optimized through evolution which has a match rate of 78%. The difference here is the design system has no knowledge of the verification system or even of minutiae. Verification systems that use minutiae will have an emphasis on endpoints and parts of the fingerprint deemed important by the people that designed the concept of minutiae. The score on this proxy system shows the general feature optimization that is happening irrespective of the verification design.\nDue to the high variance in the results, it is important to prove that the system is optimizing the fingerprints. To do this, we run a 1 way ANOVA on the three groups to test for statistical significance between the groups. This results in F = 22.88 with a p value much lower than 0.01. Running Tukey\u2019s HSD post-hoc test shows more specifically that the difference between the optimized fingerprint and both random fingerprints are significant at p < .01. This means that we can be over 99% certain that the optimized results are better than the unoptimized results and that both results are better than random data. We tried to test against random noise, but the verification system could not detect any minutiae points.\nWhile we expected the optimized results to be better than the unoptimized results, we did not expect the the generated results to have a higher match rate in general than the data that the generator is trained on. This suggests that the adversarial training used to train the image generator is already capitalizing on general features found in the dataset. The images being generated are already prototypical fingerprints which make them natural MasterPrints. For this particular context, loss of variability in the generated images has its advantages.\nOptimizing for the proxy CNN verification system doubles the match rate from the randomly generated results. Looking at these images in Figure 3, they do not really look like fingerprints. Of all the outputs we looked at from both generators, these images looked the least like real fingerprints. They look like fingerprints with parts whited out. One possibility is that the bottom and right edge of the fingerprints in our data have a lot of similarities while the rest of the image is where most of the unique aspects are. By having nothing in the unique regions, the fingerprints are less likely to get rejected for individual matches.\nCapacitive MasterPrint The images on right half of Figure 3 are created using the capacitive fingerprint generator and optimized with a CNN using the ResNet architecture. The results for the capacitive generator are on the right side of Table 2. For the capacitive data we experimented with the proxy architectures to test how the CNN architecture effects the effectiveness of the fingerprint designs.\nAs was done with the rolled MasterPrint results, the five groups of \u201cMasterPrints\u201d are analyzed with a 1 way ANOVA. This results in F = 6.18 with a p value much lower than 0.01. This is a lower F than the rolled data results but still significant. Running Tukey\u2019s HSD post-hoc test shows that the three optimized groups are significantly different than the random data at p < .01. The effect size here is not large but the results follow what we have already seen. The randomly generated results have roughly twice the number of matches as the real data, and the optimized results are roughly twice as good as the random results. The main difference is the capacitive data gets fewer matches than the rolled data. This may again be related to the much lower number of ridges in the capacitive images.\nThe different CNN architectures did not make a difference. It is interesting that a 6, 16, and 50 layer network all have the same effect in terms of optimizing a MasterPrint. This demonstrates a robustness in the results but also makes us question what features these networks are all optimizing. Looking at the MasterPrint images for all three architectures, they all appear similar. If we had optimized for hidden layers instead of the output of the CNN, then the internal representations of these networks might have been more important. This analysis indicates that the underlying data is one of the most important aspects in generating a MasterPrint."}, {"heading": "6 Conclusion", "text": "This paper presents two related methods for generating MasterPrints; partial fingerprints which can be used in presentation attacks on fingerprint authorization systems. Both methods start with training a Wasserstein GAN on a fingerprint dataset. They then search for latent variable values (\u201cinputs\u201d), for the GAN generator, that maximize the number of people the output of the generator can match. The first method, which requires access to an external fingerprint recognition system, uses evolutionary computation to find the variable values. The second method instead trains a neural network to do multi-label classification of the fingerprints, and uses gradient descent to find the latent variable values. The results of our methods are state of the art, and, unlike previous work, our method generates complete fingerprint images. Testing with three different CNN architectures and two different external fingerprint recognition systems show that the method is robust and not dependent on the artifacts of any particular fingerprint recognition system.\nFuture testing should verify the effectiveness of this system in the wild, against e.g. smartphone fingerprint recognition systems. It is also plausible that the method could be extended to many other types authentication modalities that are vulnerable to presentation attacks."}], "references": [{"title": "Began: Boundary equilibrium generative adversarial networks", "author": ["David Berthelot", "Tom Schumm", "Luke Metz"], "venue": "arXiv preprint arXiv:1703.10717,", "citeRegEx": "3", "shortCiteRegEx": "3", "year": 2017}, {"title": "Learning fingerprint reconstruction: From minutiae to image", "author": ["Kai Cao", "Anil K Jain"], "venue": "IEEE Transactions on information forensics and security,", "citeRegEx": "4", "shortCiteRegEx": "4", "year": 2015}, {"title": "Introduction to evolutionary computing, volume 53", "author": ["Agoston E Eiben", "James E Smith"], "venue": null, "citeRegEx": "5", "shortCiteRegEx": "5", "year": 2003}, {"title": "Nips 2016 tutorial: Generative adversarial networks", "author": ["Ian Goodfellow"], "venue": "arXiv preprint arXiv:1701.00160,", "citeRegEx": "6", "shortCiteRegEx": "6", "year": 2016}, {"title": "The cma evolution strategy: a comparing review", "author": ["Nikolaus Hansen"], "venue": "Towards a new evolutionary computation,", "citeRegEx": "7", "shortCiteRegEx": "7", "year": 2006}, {"title": "Completely derandomized self-adaptation in evolution strategies", "author": ["Nikolaus Hansen", "Andreas Ostermeier"], "venue": "Evolutionary computation,", "citeRegEx": "8", "shortCiteRegEx": "8", "year": 2001}, {"title": "Deep residual learning for image recognition", "author": ["Kaiming He", "Xiangyu Zhang", "Shaoqing Ren", "Jian Sun"], "venue": "In Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition,", "citeRegEx": "9", "shortCiteRegEx": "9", "year": 2016}, {"title": "A cross-device matching fingerprint database from multi-type sensors", "author": ["Xiaofei Jia", "Xin Yang", "Yali Zang", "Ning Zhang", "Jie Tian"], "venue": "In Pattern Recognition (ICPR),", "citeRegEx": "10", "shortCiteRegEx": "10", "year": 2012}, {"title": "Synthesizing the preferred inputs for neurons in neural networks via deep generator networks", "author": ["Anh Nguyen", "Alexey Dosovitskiy", "Jason Yosinski", "Thomas Brox", "Jeff Clune"], "venue": "In Advances in Neural Information Processing Systems,", "citeRegEx": "11", "shortCiteRegEx": "11", "year": 2016}, {"title": "Masterprint: Exploring the vulnerability of partial fingerprint-based authentication systems", "author": ["Aditi Roy", "Nasir Memon", "Arun Ross"], "venue": "IEEE Transactions on Information Forensics and Security,", "citeRegEx": "12", "shortCiteRegEx": "12", "year": 2017}, {"title": "Very deep convolutional networks for large-scale image recognition", "author": ["Karen Simonyan", "Andrew Zisserman"], "venue": null, "citeRegEx": "13", "shortCiteRegEx": "13", "year": 2015}, {"title": "Wolf attack probability: A new security measure in biometric authentication systems", "author": ["Masashi Une", "Akira Otsuka", "Hideki Imai"], "venue": "In International Conference on Biometrics,", "citeRegEx": "14", "shortCiteRegEx": "14", "year": 2007}, {"title": "Nist special database 9, mated fingerprint card pairs", "author": ["Craig I Watson"], "venue": "National Institute of Standard and Technology", "citeRegEx": "15", "shortCiteRegEx": "15", "year": 1993}, {"title": "Energy-based generative adversarial network", "author": ["Junbo Zhao", "Michael Mathieu", "Yann LeCun"], "venue": "arXiv preprint arXiv:1609.03126,", "citeRegEx": "16", "shortCiteRegEx": "16", "year": 2016}], "referenceMentions": [{"referenceID": 9, "context": "[12] studied the vulnerability of fingerprint-based biometric systems that have small sensors for authentication and therefore only scan part of the fingerprint.", "startOffset": 0, "endOffset": 4}, {"referenceID": 11, "context": "They found these systems are highly susceptible to a type of presentation attack that is known as a \u201cwolf attack\u201d [14].", "startOffset": 114, "endOffset": 118}, {"referenceID": 9, "context": "[12] showed that there exists synthetic fingerprints that can match for many fingerprints in a dataset.", "startOffset": 0, "endOffset": 4}, {"referenceID": 1, "context": "There is work to synthesize fingerprints from minutiae [4], but by working at the image level we can also optimize for systems that don\u2019t use minutiae, systems such as the iPhone [1].", "startOffset": 55, "endOffset": 58}, {"referenceID": 3, "context": "Some of the most popular methods for image generation are Fully Visible Belief Networks (FVBN), Variational Autoencoders (VAE), and Generative Adversarial Networks (GAN) [6].", "startOffset": 170, "endOffset": 173}, {"referenceID": 3, "context": "Current GAN methods are perceived to produce the best results with fewer artifacts than FVBNs and sharper images than VAEs [6].", "startOffset": 123, "endOffset": 126}, {"referenceID": 0, "context": "Other examples not used here are the Boundary Equilibrium GAN [3] and Energy Based GAN [16].", "startOffset": 62, "endOffset": 65}, {"referenceID": 13, "context": "Other examples not used here are the Boundary Equilibrium GAN [3] and Energy Based GAN [16].", "startOffset": 87, "endOffset": 91}, {"referenceID": 12, "context": "Rolled images The rolled fingerprints come from the publicly available NIST Special Database 9 fingerprint dataset [15].", "startOffset": 115, "endOffset": 119}, {"referenceID": 7, "context": "Capacitive images The capacitive fingerprint images come from the FingerPass DB7 dataset [10].", "startOffset": 89, "endOffset": 93}, {"referenceID": 9, "context": "in their MasterPrint paper [12].", "startOffset": 27, "endOffset": 31}, {"referenceID": 2, "context": "The best ones are kept and mutated to form the next generation [5].", "startOffset": 63, "endOffset": 66}, {"referenceID": 5, "context": "This knowledge allows the algorithm to intelligently guide mutations when many variables are highly correlated [8].", "startOffset": 111, "endOffset": 114}, {"referenceID": 4, "context": "In this work we use Hansen\u2019s Python implementation of CMA-ES [7].", "startOffset": 61, "endOffset": 64}, {"referenceID": 9, "context": "[12].", "startOffset": 0, "endOffset": 4}, {"referenceID": 8, "context": "[11].", "startOffset": 0, "endOffset": 4}, {"referenceID": 6, "context": "Our CNN architectures are the Residual Network (ResNet) that has achieved superhuman results on the ImageNet classification competition [9], the smaller, yet still powerful, VGG16 architecture [13], and a simple convolutional design with 3 convolutional layers and 3 fully connected layers on top.", "startOffset": 136, "endOffset": 139}, {"referenceID": 10, "context": "Our CNN architectures are the Residual Network (ResNet) that has achieved superhuman results on the ImageNet classification competition [9], the smaller, yet still powerful, VGG16 architecture [13], and a simple convolutional design with 3 convolutional layers and 3 fully connected layers on top.", "startOffset": 193, "endOffset": 197}, {"referenceID": 9, "context": "[12].", "startOffset": 0, "endOffset": 4}], "year": 2017, "abstractText": "We present two related methods for creating MasterPrints, synthetic fingerprints that a fingerprint verification system identifies as many different people. Both methods start with training a Generative Adversarial Network (GAN) on a set of real fingerprint images. The generator network is then used to search for images that can be recognized as multiple individuals. The first method uses evolutionary optimization in the space of latent variables, and the second uses gradient-based search. Our method is able to design a MasterPrint that a commercial fingerprint system matches to 22% of all users in a strict security setting, and 75% of all users at a looser security setting.", "creator": "LaTeX with hyperref package"}}}