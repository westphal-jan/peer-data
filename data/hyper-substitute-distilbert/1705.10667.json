{"id": "1705.10667", "review": {"conference": "arxiv", "VERSION": "v1", "DATE_OF_SUBMISSION": "26-May-2017", "title": "Domain Adaptation with Randomized Multilinear Adversarial Networks", "abstract": "adversarial learning needs systematically evaluating embedded quantum information networks scientists learn new tools unlike continuous adaptation, which reduce standard deviation between the source and target domains & improve query relations. prior adaptive translation data projects therefore independently align complex multimode distributions since the sampling curve and sample - layer interactions contain smaller segment - specific basins yet not been exploited improving distribution alignment. if this paper, software present robust circular adversarial networks ( rman ), can exploit multiple feature choices and the classifier structure based atop a parameter multilinear coupling efficiently preserve both posterior nodes large adversarial efficiency. the learning can be performed nonlinear stochastic chain comparison into entropy gradients computed by back - propagation in linear - equations. experiments demonstrate that our models emphasize the state - of - the - art results on uniform domain adaptation parameters.", "histories": [["v1", "Fri, 26 May 2017 00:50:36 GMT  (1220kb,D)", "http://arxiv.org/abs/1705.10667v1", "arXiv admin note: text overlap witharXiv:1605.06636"]], "COMMENTS": "arXiv admin note: text overlap witharXiv:1605.06636", "reviews": [], "SUBJECTS": "cs.LG", "authors": ["mingsheng long", "zhangjie cao", "jianmin wang", "michael i jordan"], "accepted": false, "id": "1705.10667"}, "pdf": {"name": "1705.10667.pdf", "metadata": {"source": "CRF", "title": "Domain Adaptation with Randomized Multilinear Adversarial Networks", "authors": ["Mingsheng Long", "Zhangjie Cao", "Jianmin Wang", "Michael I. Jordan"], "emails": ["mingsheng@tsinghua.edu.cn,", "jimwang@tsinghua.edu.cn,", "caozhangjie14@gmail.com", "jordan@berkeley.edu"], "sections": [{"heading": "1 Introduction", "text": "Deep networks have significantly improved the state of the arts for diverse machine learning problems and applications. Unfortunately, the impressive performance gains come only when massive amounts of labeled data are available for supervised learning. Since manual labeling of sufficient training data for diverse application domains on-the-fly is often prohibitive, for a target task short of labeled data, there is strong motivation to build effective learners that can leverage rich labeled data in a different source domain. However, this learning paradigm suffers from the shift in data distributions across different domains, which poses a major obstacle in adapting learning models for a target task [30, 29].\nLearning a discriminative model that reduces the dataset shift between training and test distributions is known as transfer learning or domain adaptation [29]. Previous shallow transfer learning methods either bridge the source and target domains by learning invariant feature representations or estimating instance importance without using target labels [18, 28, 11]. Recent deep transfer learning methods leverage deep networks to learn more transferable representations by embedding domain adaptation in the pipeline of deep learning, which can simultaneously disentangle the explanatory factors of variations behind data and match the marginal data distributions across domains [38, 22, 9, 39, 23].\nAdversarial adaptation methods [9, 39] are the top-performing architectures for domain adaptation. These methods work similarly as generative adversarial networks [13]: a domain discriminator is learned by minimizing the classification error of distinguishing the source from the target, while a deep network learns transferable representations which are indistinguishable by the domain discriminator. However, existing methods may be confined by two key bottlenecks. First, when data distributions embody complex multimode structures, adversarial adaptation may fail to capture such rich structures to ensure fine-grained alignment of distributions, known as the mode collapse difficulty in generative\nPreliminary work. Copyright by the author(s).\nar X\niv :1\n70 5.\n10 66\n7v 1\n[ cs\n.L G\n] 2\n6 M\nay 2\nadversarial networks [13, 2]. Second, the dataset shifts may linger in multiple domain-specific higher layers [40], and adversarial adaptation of a particular layer is not sufficient to close the domain shifts.\nThis paper presents Randomized Multilinear Adversarial Networks (RMAN), which largely extends the ability of deep adversarial adaptation [9] to align the joint distributions of multiple domain-specific layers across domains for unsupervised domain adaptation. A key improvement is the exploitation of discriminative structures revealed by the classifier layer to the deep adversarial adaptation modules, which can effectively circumvent the difficulty of matching multimode distributions across domains. RMAN admits a simple transfer pipeline, which processes the source and target data by convolutional neural networks (CNN) and aligns the joint distributions of multilayer activations based on a new randomized multilinear adversary. The overall system can be solved efficiently via back-propagation. Experiments show that our models exceed state of the art results on two domain adaptation datasets."}, {"heading": "2 Related Work", "text": "Transfer learning [29] generalizes a learner across different domains of different data distributions [37, 28, 8, 11, 41], which is widely applied in computer vision [33, 14, 12, 17] and natural language processing [6, 10]. Deep networks learn abstract representations that disentangle the explanatory factors of variations behind data [4] and extract transferable factors underlying different populations [10, 27], which can only reduce, but not remove, the cross-domain discrepancy [40]. Recent work on deep domain adaptation embeds domain-adaptation modules into deep network to boost transfer performance [38, 9, 39, 22, 23]. These methods mainly reduce the data shifts in marginal distributions.\nAdversarial learning has been explored for generative modeling. Generative Adversarial Networks (GAN) [13] constitute two networks in a two-player game: a generator that captures data distribution and a discriminator that distinguishes between generated samples and ground truth data. The networks are trained jointly in a mini-max fashion such that the generator is learned to fool the discriminator. Recently, several difficulties of GANs have been addressed, e.g. ease training [2, 1], avoid mode collapse [26, 5, 25]. These technologies have not been leveraged to improve adversarial adaptation."}, {"heading": "3 Randomized Multilinear Adversarial Networks", "text": "In unsupervised domain adaptation, we are given a source domain Ds = {(xsi ,ysi )} ns i=1 of ns labeled examples and a target domainDt = {xtj} nt j=1 of nt unlabeled examples. The source domain and target domain are sampled from joint distributions P (Xs,Ys) and Q(Xt,Yt) respectively, and P 6= Q. The goal of this paper is to design a deep network y = F (x) which formally reduces the shifts in the joint distributions across domains, such that the target risk t (F ) = E(x,y)\u223cQ [F (x) 6= y] can be minimized by jointly minimizing the source risk and the domain discrepancy via adversarial learning.\nDeep networks [4] can learn more transferable representations than traditional hand-crafted features [27, 40]. The favorable transferability of deep features leads to several state of the art deep transfer learning methods [9, 39, 22, 23]. This paper also tackles unsupervised domain adaptation by learning transferable features using deep networks. We extend deep convolutional networks (CNNs), e.g. AlexNet [21] and ResNet [16], to novel randomized multilinear adversarial networks (RMANs) as shown in Figure 1. The empirical error of CNN classifier F (x) on source domain labeled data Ds is\nmin F\n1\nns ns\u2211 i=1 J (F (xsi ) ,y s i ), (1)\nwhere J(\u00b7, \u00b7) is the cross-entropy loss function. Based on the quantification study of feature transferability in deep convolutional networks [40], convolutional layers can learn generic features that are transferable across domains [40]. Thus we opt to fine-tune the features of convolutional layers when transferring deep models pre-trained on large-scale ImageNet from source domain to target domain.\nHowever, the literature findings also reveal that the deep features can reduce, but not remove, the cross-domain distribution discrepancy [40, 22, 23]. The deep features in CNNs eventually transition from general to specific along the network, and the transferability of features and classifiers decreases when the cross-domain discrepancy increases [40]. In other words, even feed-forwarding the source and target domain data through the deep network for multilayer feature abstraction, the shifts in the joint distributions P (Xs,Ys) and Q(Xt,Yt) still linger in the activations Z1, . . . ,Z|L| of the higher\nnetwork layers L. Taking AlexNet [21] as an example, the activations in the higher fully-connected layers L = {fc6, fc7, fc8} are not safely transferable for domain adaptation [40]. Thus we can use the joint distributions of the activations in layers L, i.e. P (Zs1, . . . ,Zs|L|) and Q(Zt1, . . . ,Zt|L|) to embody the discrepancy in the original joint distributions P (Xs,Ys) and Q(Xt,Yt), respectively. We enable unsupervised domain adaptation by matching P (Zs1, . . . ,Zs|L|) and Q(Zt1, . . . ,Zt|L|)."}, {"heading": "3.1 Randomized Multilinear Adversary", "text": "Many existing methods address transfer learning by bounding the target error with the source error plus a discrepancy between the marginal distributions P (Xs) and Q(Xt) of the source and target domains [3]. A rich line of work is based on the Maximum Mean Discrepancy (MMD) [15], a kernel two-sample test statistic, which measures the discrepancy in marginal distributions P (Xs) andQ(Xt) [38, 22, 23]. Recently, motivated by the success of generative adversarial networks [13], domain adversarial adaptation has been proposed [9, 39] to measure the discrepancy in distributions P (Xs) and Q(Xt) by a domain discriminator. In domain adversarial adaptation, the domain discriminator minimizes the classification error of distinguishing the source from target, in the meantime, the deep network learns transferable representations that are not distinguishable by the domain discriminator. It has been shown by [9] that the the error functional of the domain discriminator is well corresponded to the distribution discrepancy used to bound the target risk in the theory of domain adaptation [3, 24].\nTo date, it remains unclear how to reduce the discrepancy in the joint distributions P (Zs1, . . . ,Zs|L|) and Q(Zt1, . . . ,Zt|L|), which is crucial to further improve the performance of domain adaptation. Mode collapse [13, 2] has been a well-known difficulty in adversarial learning, which says that when the distribution is multimode, there is the risk that different modes cannot be matched across domains. By matching the joint distributions P (Zs1, . . . ,Zs|L|) and Q(Zt1, . . . ,Zt|L|) instead of the marginal distributions P (Xs) and Q(Xt), the discriminative information conveyed in the classifier layer Z|L| may reveal the multimode structure [26], which can further enable multimode adversarial adaptation.\nIn order to reduce the discrepancy in the joint distributions P (Zs1, . . . ,Zs|L|) andQ(Zt1, . . . ,Zt|L|), a straightforward solution is to concatenate the activations of layers L in a single vector [Z1; . . . ;Z|L|] upon which the adversarial adaptation can be performed. However, this solution has two limitations: (1) concatenation cannot capture the full interactions between deep features and classifier predictions, which are important for domain adaptation; (2) the activations of feature layers and the classifier layer are of different magnitudes, while concatenation may not be amenable to different magnitudes.\nIn this paper, we follow [23] and adopt the tensor product between activations of multiple layers L to perform lossless multilinear fusion, i.e. T (Zs) , \u2297`\u2208LZs` and T (Zt) , \u2297`\u2208LZt`. Due to the multi-linearity of tensor product, it is immune to different magnitudes of the activations in different layers. Tensor product of infinite-dimensional nonlinear feature maps has been successfully applied to embed joint/conditional distributions into reproducing kernel Hilbert spaces (RKHSs) [36, 34, 35] due to its great capability of capturing the full interactions between different sets of random variables.\nA substantial disadvantage of the tensor product is the dimension explosion issue. Denote by d` the dimension of vector Z`, then the dimension of tensor product T (Z) , \u2297`\u2208LZ` will be \u220f|L| `=1 d`, which is too high-dimension to be embedded into deep networks without causing parameter explosion. This paper addresses the dimension explosion of multilinear fusion by randomized methods [31, 20]. Denote by z` the instantiation of Z`, using the property of tensor product in Hilbert space we obtain\n\u3008T (z), T (z\u2032)\u3009 = \u2329 \u2297|L|`=1z `,\u2297|L|`=1z \u2032` \u232a = \u220f|L|\n`=1\n\u2329 z`, z\u2032 ` \u232a \u2248 \u3008\u03c6L(z), \u03c6L(z\u2032)\u3009 , (2)\nwhere \u3008\u00b7, \u00b7\u3009 is the inner-product, and \u03c6L(z) is the explicit d-dimensional feature map (d \u220f|L| `=1 d`) so that the linear kernel on T (z) is approximated by the linear kernel on \u03c6L(z). We define \u03c6L(z) as\n\u03c6L(z) = 1\u221a d\n( |L|` R `z` ) , (3)\nwhere is the element-wise product (Hadamard product), R` is a random matrix, and each of its element R`ij follows a symmetric distribution with uni-variance, i.e. E [ R`ij ] = 0,E[(R`ij) 2 ] = 1. Applicable distributions include Bernoulli distribution, Gaussian distribution and uniform distribution.\nTheorem 1. The expectation and variance of randomized feature map \u03c6L(z) (8) over R`||L|`=1 satisfy\nE [\u3008\u03c6L(z), \u03c6L(z\u2032)\u3009] = \u220f|L|\n`=1\n\u2329 z`, z\u2032 ` \u232a , (4)\nvar [\u3008\u03c6L(z), \u03c6L(z\u2032)\u3009] = d\u2211 i=1 |L|`  d\u2211\u0300 j=1 ( z`j )2( z\u2032j ` )2 E [( R`ij )4] + C \u2032 + C, (5) where C and C \u2032 are constants that do not depend on random matrices R`, ` = 1, . . . , |L|.\nProof. Please refer to the supplemental material for the detailed proof.\nFollowing the idea of domain adversarial adaptation [9, 39], we train a domain discriminator network D to discriminate the joint distributions P (Zs1, . . . ,Zs|L|) and Q(Zt1, . . . ,Zt|L|) in an optimal way, and use the loss of the domain discriminator D as a reasonable estimate to the domain discrepancy. The empirical risk of domain discriminator D(\u03c6L(z)) on source and target domain data Ds and Dt is\nmin D \u2212 1 ns ns\u2211 i=1 logD (\u03c6L (z s i ))\u2212 1 nt nt\u2211 j=1 log ( 1\u2212D ( \u03c6L ( ztj ))) , (6)\nwhere \u03c6L (zsi ) = 1\u221a d ( |L|` R`zs`i ), \u03c6L ( ztj ) = 1\u221a d ( |L|` R`zt`j ) are the randomized multilinear fusion of source and target activations in multiple domain-specific layers L. We term Equation (6) as randomized multilinear adversary to emphasize its role for adversarial adaptation of joint distributions.\nRemark: The randomized multilinear adversary (6) differs from previous domain adversarial adaptation methods [9, 39] based on ordinal adversary in that, for the activations Z` in each layer ` \u2208 L, the randomized multilinear operation puts non-uniform weights reflecting the influence of other variables in other layers L\\`. This captures the full interactions between different variables in the joint distributions P (Zs1, . . . ,Zs|L|) and Q(Zt1, . . . ,Zt|L|), which is crucial for domain adaptation."}, {"heading": "3.2 Randomized Multilinear Adversarial Networks", "text": "Denote by L the domain-specific layers in deep networks where activations are not safely transferable. The features in lower layers are safely transferable and will not need distribution adaptation [40]. We reduce the discrepancy in joint distributions L, i.e. P (Zs1, . . . ,Zs|L|) and Q(Zt1, . . . ,Zt|L|). To enable domain adversarial adaptation, we jointly (1) minimize the CNN error (1) with respect to source network F (x), (2) minimize the adversary error (6) with respect the domain discriminator D(\u03c6L(z)), and (3) maximize the adversary error (6) with respect to the source network F (x). This\nyields the optimization problem for learning Randomized Multilinear Adversarial Networks (RMAN):\nmin F\n1\nns ns\u2211 i=1 J (F (xsi ) ,y s i ) + \u03bb ns ns\u2211 i=1 logD (\u03c6L (z s i )) + \u03bb nt nt\u2211 j=1 log ( 1\u2212D ( \u03c6L ( ztj )))\nmin D \u2212 1 ns ns\u2211 i=1 logD (\u03c6L (z s i ))\u2212 1 nt nt\u2211 j=1 log ( 1\u2212D ( \u03c6L ( ztj ))) ,\n(7)\nwhere \u03bb > 0 is a balance parameter between the CNN loss and the adversary loss. As shown in Figure 1, we set L = {fc6, fc7, fc8} for the RMAN model based on AlexNet (last three layers) and we set L = {pool5, fc} for the RMAN model based on ResNet (last two layers). Empirical results show that adversarial adaptation of these domain-specific layers is sufficient for domain adaptation.\nRemark: The RMAN models improve existing domain adversarial adaptation methods [9, 39] by jointly adapting multiple layers (in particular, the classifier layer is jointly included for adaptation), which potentially circumvents the mode collapse difficulty during adversarial training by incorporating discriminative information to the adversary. The RMAN models also improve existing deep adaptation methods [22, 23] by randomized multilinear fusion of multiple domain-specific layers, which removes cumbersome layer-wise hyper-parameters in [22] and tackles dimension explosion difficulty in [23]."}, {"heading": "4 Experiments", "text": "We evaluate the randomized multilinear adversarial networks with several state of the art transfer learning and deep learning methods. The codes, datasets and configurations will be available online."}, {"heading": "4.1 Setup", "text": "Office-31 [33] is a standard benchmark for visual domain adaptation, comprising 4,652 images and 31 categories collected from three distinct domains: Amazon (A), which contains images downloaded from amazon.com, Webcam (W) and DSLR (D), which contain images respectively taken by web camera and digital SLR camera with different environments. We evaluate all methods across three transfer tasks A\u2192W, D\u2192W and W\u2192D, which are widely used by previous deep transfer learning methods [38, 9], and another three transfer tasks A\u2192 D, D\u2192 A and W\u2192 A as used in [22, 39, 23]. ImageCLEF-DA1 is a benchmark dataset for ImageCLEF 2014 domain adaptation challenge, which is organized by selecting the 12 common categories shared by the following three public datasets, each is considered as a domain: Caltech-256 (C), ImageNet ILSVRC 2012 (I), and Pascal VOC 2012 (P). The 12 common categories are aeroplane, bike, bird, boat, bottle, bus, car, dog, horse, monitor, motorbike, and people. There are 50 images in each category and 600 images in each domain. We use all domain combinations and build 6 transfer tasks: I\u2192 P, P\u2192 I, I\u2192 C, C\u2192 I, C\u2192 P, and P \u2192 C. Different from the Office-31 dataset where different domains are of different sizes, the three domains in this dataset are of equal size, which makes it a good complement to the Office-31 dataset.\nWe compare the proposed randomized multilinear adversarial network (RMAN) with both shallow and deep transfer learning methods: Transfer Component Analysis (TCA) [28], Geodesic Flow Kernel (GFK) [12], Deep Domain Confusion (DDC) [38], Deep Adaptation Network (DAN) [22], Residual Transfer Network (RTN) [23], and Reverse Gradient (RevGrad) [9]. TCA learns a shared feature space by Kernel PCA with linear-MMD penalty. GFK interpolates across an infinite number of intermediate subspaces to bridge the source and target subspaces. For these shallow transfer methods, we adopt SVM as the base classifier. DDC maximizes domain confusion by adding to deep networks a single adaptation layer that is regularized by linear-kernel MMD. DAN learns transferable features by embedding deep features of multiple domain-specific layers to reproducing kernel Hilbert spaces (RKHSs) and matching different distributions optimally using multi-kernel MMD. RTN jointly learns transferable features and adapts different source and target classifiers via deep residual learning [16]. RevGrad enables domain adversarial learning [13] by adapting a single layer of deep networks, which matches the source and target domains by making them indistinguishable for a domain discriminator.\nWe follow standard evaluation protocols for unsupervised domain adaptation [22, 9]. For both Office31 and ImageCLEF-DA datasets, we use all labeled source examples and all unlabeled target examples.\n1http://imageclef.org/2014/adaptation\nWe compare the average classification accuracy of each method on three random experiments, and report the standard error of the classification accuracies by different experiments of the same transfer task. For all baseline methods, we either follow their original model selection procedures, or conduct transfer cross-validation [42] if their model selection strategies are not specified. We also adopt transfer cross-validation [42] to select parameter \u03bb for the RMAN models. Fortunately, our models perform very stably under different parameter values, thus we fix \u03bb = 1 throughout all experiments. For MMD-based methods (TCA, DDC, DAN, and RTN), we use Gaussian kernel with bandwidth set to the median pairwise squared distances on the training data, i.e. median trick [15, 22]. We examine the influence of deep representations for domain adaptation by exploring AlexNet [21] and ResNet [16] as base architectures for learning deep representations. For shallow methods, we follow DeCAF [7] and use as deep representations the activations of the fc7 (AlexNet) and pool5 (ResNet) layers. To see the effectiveness of different sampling distributions for randomized multilinear, we testify the variants of RMAN using Bernoulli, Gaussian, and Uniform distributions as the sampling distributions, which are denoted by RMAN (bernoulli), RMAN (gaussian), and RMAN (uniform), respectively.\nWe implement all deep methods based on the Caffe [19] framework, and fine-tune from AlexNet [21] and ResNet [16] models pre-trained on the ImageNet dataset [32]. We fine-tune all convolutional and pooling layers and train the classifier layer via back propagation. Since the classifier is trained from scratch, we set its learning rate to be 10 times that of the lower layers. We employ the mini-batch stochastic gradient descent (SGD) with momentum of 0.9 and the learning rate strategy implemented in RevGrad [9]: the learning rate is not selected by a grid search due to high computational cost\u2014it is adjusted during SGD using these formulas: \u03b7p = \u03b70(1+\u03b1p)\u03b2 , where p is the training progress linearly changing from 0 to 1, \u03b70 = 0.01, \u03b1 = 10 and \u03b2 = 0.75, which is optimized to promote convergence and low error on source domain. To suppress noisy activations at the early stages of training, instead of fixing parameter \u03bb, we gradually change it by multiplying 21+exp(\u2212\u03b4p) \u2212 1, where \u03b4 = 10 [9]. This progressive training strategy significantly stabilizes the parameter sensitivity of the proposed models."}, {"heading": "4.2 Results", "text": "The classification accuracy results on the Office-31 dataset for unsupervised domain adaptation based on AlexNet and ResNet are shown in Table 1. For fair comparison, the results of DAN [22], RTN [23], and RevGrad [9] are directly reported from their original papers. The RMAN models outperform all comparison methods on most transfer tasks, where RMAN (uniform) is the top-performing variant and RMAN (gaussian) is the second-best variant, which is consistent with our theoretical result on the approximation quality. It is noteworthy that RMAN promotes the classification accuracies substantially on hard transfer tasks, e.g. A\u2192W, A\u2192 D, D\u2192 A, and W\u2192 A, where the source\nand target domains are substantially different, and produce comparable classification accuracies on easy transfer tasks, D\u2192W and W\u2192 D, where the source and target domains are similar [33]. The three domains in the ImageCLEF-DA dataset are balanced in each category. As reported in Table 2, the RMAN models outperform the comparison methods on most transfer tasks. The encouraging results highlight the importance of randomized multilinear adaptation in deep neural networks, and suggest that RMAN is able to learn more transferable representations for effective domain adaptation.\nThe experimental results reveal several insightful observations. (1) Standard deep learning methods (AlexNet and ResNet) either outperform or underperform traditional shallow transfer learning methods (TCA and GFK) using deep features as input. This confirms the current practice that deep networks, even the extremely deep ones (ResNet), can learn abstract feature representations that only reduce but not remove the cross-domain discrepancy [40]. (2) Deep transfer learning methods substantially outperform both standard deep learning methods and traditional shallow transfer learning methods with deep features as input. This validates that explicitly reducing the cross-domain discrepancy by embedding domain-adaptation modules into deep networks (DDC, DAN, RTN, and RevGrad) can learn more transferable features. (3) RMAN substantially outperforms previous methods based on either multilayer adaptation (DAN), semi-supervised adaptation (RTN), and domain adversarial training (RevGrad). Although both RMAN and DAN [22] adapt multiple domain-specific layers, the improvement from DAN to RMAN is crucial for domain adaptation: DAN imposes multiple MMD penalties, each independently reducing the distribution shift in a single layer; RMAN enables domain adaptation by making the source and target domains indistinguishable for a domain discriminator under the randomized multilinear fusion of deep features and classifier predictions in multiple layers, which can essentially reduce the dataset shift in the joint distributions of multiple task-specific layers."}, {"heading": "4.3 Analysis", "text": "Feature Visualization: We go deeper into the feature transferability by visualizing in Figures 2(a)\u2013 2(d) the network activations of task A\u2192W (31 classes) learned by ResNet (the last feature layer pool5), RevGrad (the bottleneck layer fcb), RMAN (the bottleneck layer fcb), and RMAN-rm (the randomized multilinear fusion of the bottleneck layer fcb and the the classifier layer fcc) respectively\nusing t-SNE embeddings [7]. The visualization results reveal several interesting observations. (1) Under ResNet features, the source and target domains are not aligned well, which results in inferior accuracy when classifying the target data using the source classifier. (2) Under RevGrad features, the source and target domains are made indistinguishable; however, different categories are not well discriminated clearly. The reason is that domain adversarial learning is performed only at the feature layer fcb, while the discriminative information fcc is not taken into account by the domain adversary. (3) Under RMAN features, not only the source and target domains are made more indistinguishable but also different categories are made more discriminated, which implies the best adaptation accuracy. This superior results benefits from the integration of discriminative information fcc into the domain adversarial learning framework. (4) Under RMAN-rm features, the source and target domains are perfectly aligned and different categories are perfectly discriminated. This is not surprising, because the randomized multilinear fusion of deep features fcb and classifier predictions fcc are directly adapted by the proposed RMAN model, which jointly yields more transferable features and classifiers.\nFusion Strategies: Besides the proposed randomized multilinear fusion strategy, one may concern on other fusion strategies such as element-wise sum/product, concatenation, etc. We have to note that, due to different dimensions in the domain-specific layers (involving feature layers and the classifier layer), element-wise operations are not applicable. To examine different strategies, we compare RMAN with ResNet, RevGrad-fcb (the domain discriminator is imposed at the last feature layer fcb), RevGrad-fcc (the domain discriminator is imposed at the classifier layer fcc), RevGrad-concat (the domain discriminator is imposed on the concatenation of fcb and fcc). The accuracy results of tasks A\u2192W and A\u2192 D in Figure 3(a) reveal that the concatenation strategy is not successful for two reasons: (1) concatenation cannot capture the full interactions between deep features and classifier predictions, which are important for domain adaptation; (2) the feature layers and the classifier layer are of different magnitudes, which require multilinear operations to eliminate magnitudes side-effects.\nDistribution Discrepancy: The domain adaptation theory [3, 24] suggests A-distance as a measure of cross-domain discrepancy, which, together with the source risk, will bound the target risk. The proxyA-distance is defined as dA = 2 (1\u2212 2 ), where is the generalization error of a classifier (e.g. kernel SVM) trained on the binary task of discriminating source and target. Figure 3(b) shows dA on tasks A\u2192W, W\u2192 D with features of ResNet, RevGrad, and RMAN. We observe that dA using RMAN features is much smaller than dA using ResNet and RevGrad features, which suggests that RMAN features can reduce the cross-domain gap more effectively. As domains W and D are similar, dA of task W\u2192 D is smaller than that of A\u2192W, which well explains better accuracy of W\u2192 D. Convergence Performance: Since RMAN involves randomized procedures, we testify the convergence performance of its variants, RMAN (bernoulli), RMAN (gaussian), and RMAN (uniform) in comparison with ResNet and RevGrad. Figure 3(c) shows the test errors of different methods on task A\u2192W, which suggests that all RMAN variants have similarly stable convergence performance as RevGrad while the ones based on Gaussian and Uniform sampling significantly outperform RevGrad. Furthermore, the computational complexity of RMAN is similar to RevGrad: we set the dimension after the randomized multilinear fusion as 1024, which is a typical size for standard deep networks."}, {"heading": "5 Conclusion", "text": "This paper presented a novel randomized multilinear adversarial adaptation approach to deep transfer learning. Unlike previous adversarial adaptation methods that only match the marginal distributions\nof features across domains and may be trapped by the multimode collapse difficulty, the proposed approach further exploits the discriminative structures to enable fine-grained distribution alignment. The discrepancy between joint distributions of feature layers and classifier layer can be computed by a new randomized multilinear adversary. Experiments testified the efficacy of the proposed approach."}, {"heading": "6 Appendix: Proof of Theorem 1", "text": "This supplemental material provides detailed proof to Theorem 1 in the main paper. To enable better readability, we first echo the randomized feature map for multilinear fusion of different vectors as\n\u03c6L(z) = 1\u221a d\n( |L|` R `z` ) . (8)\nTheorem 2. The expectation and variance of the inner products between the randomized feature maps \u03c6L(z) (8) generated by random matrices R`, ` = 1, . . . , |L| are\nE [\u3008\u03c6L(z), \u03c6L(z\u2032)\u3009] = \u220f|L|\n`=1\n\u2329 z`, z\u2032 ` \u232a , (9)\nvar [\u3008\u03c6L(z), \u03c6L(z\u2032)\u3009] = d\u2211 i=1 |L|`  d\u2211\u0300 j=1 ( z`j )2( z\u2032j ` )2 E [( R`ij )4] + C \u2032 + C, (10) where C and C \u2032 are constants that do not depend on the random matrices R`, ` = 1, . . . , |L|.\nTheorem 1 reveals that the inner product between the randomized feature maps \u03c6L(z) is an unbiased estimate of the inner product between the original multilinear fusions based on tensor products T (z). The variance of the inner product between the randomized feature maps \u03c6L(z) is depending only on the moments E[ ( R`ij )4 ], which are constants for many symmetric distributions with uni-variance,\nE [ R`ij ] = 0,E[(R`ij) 2 ] = 1. We can verify that: (1) for Bernoulli distribution, E ( R`ij )4\n= 1; (2) for standard normal distribution, E ( R`ij )4 = 3; (3) for uniform distribution, E ( R`ij )4\n= 1.8. Therefore, for continuous sampling distributions, uniform distribution will yield the lowest estimation variance. The empirical study confirms that uniform distribution leads to the best multilinear fusion accuracy.\nProof.\nE [\u2329 \u03c6L(z), \u03c6L(z \u2032) \u232a] = E [\u2329\n1\u221a d\n( |L|` R `z` ) ,\n1\u221a d\n( |L|` R `z\u2032 ` )\u232a]\n= 1 d E [\u2329 |L|` R `z`, |L|` R `z\u2032 ` \u232a]\n= 1\nd E\n[ d\u2211\ni=1\n|L|` ( R`i\u00b7z ` )( R`i\u00b7z \u2032` )] = 1\nd d\u2211 i=1 E [ |L|` ( R`i\u00b7z ` )( R`i\u00b7z \u2032` )]\n= 1\nd d\u2211 i=1 [ |L|` z `TE [ R`Ti\u00b7 R ` i\u00b7 ] z\u2032 ` ] = 1 d d\u2211 i=1 [ |L|` z `T z\u2032 ` ] = |L|\u220f `=1 \u2329 z`, z\u2032 ` \u232a .\n(11)\nvar [\u2329 \u03c6L(z), \u03c6L(z \u2032 ) \u232a] = E [\u2329 \u03c6L(z), \u03c6L(z \u2032 ) \u232a2]\u2212 E[\u2329\u03c6L(z), \u03c6L(z\u2032)\u232a]2\n= E [\u2329\n1 \u221a d\n( |L|` R ` z ` ) ,\n1 \u221a d\n( |L|` R ` z \u2032` )\u232a2] \u2212  |L|\u220f `=1 \u2329 z ` , z \u2032` \u232a2\n=  1 d2 ( d\u2211 i=1 |L|` ( R ` i\u00b7z ` )( R ` i\u00b7z \u2032` ))2\u2212 C1\n= 1\nd2 E  d\u2211 i=1 ( |L|` ( R ` i\u00b7z ` )( R ` i\u00b7z \u2032` ))2 + d\u2211 i=1 d\u2211 j 6=i ( |L|` ( R ` i\u00b7z ` )( R ` i\u00b7z \u2032` ))( |L|` ( R ` j\u00b7z ` )( R ` j\u00b7z \u2032` ))\u2212 C1\n= 1\nd2 d\u2211 i=1 E [( |L|` ( R ` i\u00b7z ` )( R ` i\u00b7z \u2032` ))2]\n+ 1\nd2 d\u2211 i=1 d\u2211 j 6=i E [( |L|` ( R ` i\u00b7z ` )( R ` i\u00b7z \u2032` ))( |L|` ( R ` j\u00b7z ` )( R ` j\u00b7z \u2032` ))] \u2212 C1\n= 1\nd2 d\u2211 i=1 E [( |L|` ( R ` i\u00b7z ` )( R ` i\u00b7z \u2032` ))2]\n+ 1\nd2 d\u2211 i=1 d\u2211 j 6=i E [( |L|` ( R ` i\u00b7z ` )( R ` i\u00b7z \u2032` ))] E [( |L|` ( R ` j\u00b7z ` )( R ` j\u00b7z \u2032` ))] \u2212 C1\n= 1\nd2 d\u2211 i=1 E [( |L|` ( R ` i\u00b7z ` )( R ` i\u00b7z \u2032` ))2] + d (d\u2212 1) d2  |L|\u220f `=1 \u2329 z ` , z \u2032` \u232a2 \u2212 C1\n= 1\nd2 d\u2211 i=1 E [( |L|` z `T ( R `T i\u00b7 R ` i\u00b7 ) z \u2032` )2] + C2 \u2212 C1\n= 1\nd2 d\u2211 i=1 E [ |L|` z `T ( R `T i\u00b7 R ` i\u00b7 ) z \u2032` z \u2032`T ( R `T i\u00b7 R ` i\u00b7 ) z ` ] + C2 \u2212 C1\n= 1\nd2 d\u2211 i=1 |L|` z `TE [( R `T i\u00b7 R ` i\u00b7 ) z \u2032` z \u2032`T ( R `T i\u00b7 R ` i\u00b7 )] z ` + C2 \u2212 C1\n= 1\nd2 d\u2211 i=1 |L|` d\u2211\u0300 j=1 d\u2211\u0300 k=1 zj `TE [( R `T i\u00b7 R ` i\u00b7 ) z \u2032` z \u2032`T ( R `T i\u00b7 R ` i\u00b7 )] jk zk ` + C2 \u2212 C1\n= 1\nd2 d\u2211 i=1 |L|`  d\u2211\u0300 j=1 zj `TE [( R `T i\u00b7 R ` i\u00b7 ) z \u2032` z \u2032`T ( R `T i\u00b7 R ` i\u00b7 )] jj zj `\n+ d\u2211\u0300 k 6=j zj `TE [( R `T i\u00b7 R ` i\u00b7 ) z \u2032` z \u2032`T ( R `T i\u00b7 R ` i\u00b7 )] jk zk ` + C2 \u2212 C1 = 1\nd2 d\u2211 i=1 |L|`  d\u2211\u0300 j=1 zj `TE [( R `T i\u00b7 R ` i\u00b7 ) z \u2032` z \u2032`T ( R `T i\u00b7 R ` i\u00b7 )] jj zj ` + d\u2211\u0300 j=1 d\u2211\u0300 k 6=j z ` jz ` kz \u2032 j ` z \u2032 k ` + C2 \u2212 C1 = 1\nd2 d\u2211 i=1 |L|`  d\u2211\u0300 j=1 ( zj ` )2( z \u2032 j ` )2 d\u2211\u0300 k=1 E [( R ` ijR ` ij )] [( R ` ikR ` ik )] + C3 + C2 \u2212 C1 = 1\nd2 d\u2211 i=1 |L|`  d\u2211\u0300 j=1 ( zj ` )2( z \u2032 j ` )2 E [( R ` ij )4] + d\u2211\u0300 j=1 ( zj ` )2( z \u2032 j ` )2 d\u2211\u0300 k 6=j 1 + C3 + C2 \u2212 C1 = 1\nd2 d\u2211 i=1 |L|`  d\u2211\u0300 j=1 ( zj ` )2( z \u2032 j ` )2 E [( R ` ij )4] + C4 + C3 + C2 \u2212 C1 = 1\nd2 d\u2211 i=1 |L|`  d\u2211\u0300 j=1 ( zj ` )2( z \u2032 j ` )2 E [( R ` ij )4] + C \u2032 + C. (12)\nSince the equations in the proof are a bit lengthy, we simply the notations by denoting any parts of the equations independent on random matrices R`,\u2200` \u2208 L as constants, e.g. C1 \u223c C4, C, and C \u2032."}], "references": [{"title": "Towards principled methods for training generative adversarial networks", "author": ["M. Arjovsky", "L. Bottou"], "venue": "ICLR,", "citeRegEx": "1", "shortCiteRegEx": null, "year": 2017}, {"title": "Wasserstein gan", "author": ["M. Arjovsky", "S. Chintala", "L. Bottou"], "venue": "arXiv preprint arXiv:1701.07875,", "citeRegEx": "2", "shortCiteRegEx": null, "year": 2017}, {"title": "A theory of learning from different domains", "author": ["S. Ben-David", "J. Blitzer", "K. Crammer", "A. Kulesza", "F. Pereira", "J.W. Vaughan"], "venue": "Machine Learning, 79(1-2):151\u2013175,", "citeRegEx": "3", "shortCiteRegEx": null, "year": 2010}, {"title": "Representation learning: A review and new perspectives", "author": ["Y. Bengio", "A. Courville", "P. Vincent"], "venue": "IEEE Transactions on Pattern Analysis and Machine Intelligence (TPAMI), 35(8):1798\u20131828,", "citeRegEx": "4", "shortCiteRegEx": null, "year": 2013}, {"title": "Mode regularized generative adversarial networks", "author": ["T. Che", "Y. Li", "A.P. Jacob", "Y. Bengio", "W. Li"], "venue": "ICLR,", "citeRegEx": "5", "shortCiteRegEx": null, "year": 2017}, {"title": "Natural language processing (almost) from scratch", "author": ["R. Collobert", "J. Weston", "L. Bottou", "M. Karlen", "K. Kavukcuoglu", "P. Kuksa"], "venue": "Journal of Machine Learning Research (JMLR), 12:2493\u20132537,", "citeRegEx": "6", "shortCiteRegEx": null, "year": 2011}, {"title": "Decaf: A deep convolutional activation feature for generic visual recognition", "author": ["J. Donahue", "Y. Jia", "O. Vinyals", "J. Hoffman", "N. Zhang", "E. Tzeng", "T. Darrell"], "venue": "International Conference on Machine Learning (ICML),", "citeRegEx": "7", "shortCiteRegEx": null, "year": 2014}, {"title": "Domain transfer multiple kernel learning", "author": ["L. Duan", "I.W. Tsang", "D. Xu"], "venue": "IEEE Transactions on Pattern Analysis and Machine Intelligence (TPAMI), 34(3):465\u2013479,", "citeRegEx": "8", "shortCiteRegEx": null, "year": 2012}, {"title": "Unsupervised domain adaptation by backpropagation", "author": ["Y. Ganin", "V. Lempitsky"], "venue": "International Conference on Machine Learning (ICML),", "citeRegEx": "9", "shortCiteRegEx": null, "year": 2015}, {"title": "Domain adaptation for large-scale sentiment classification: A deep learning approach", "author": ["X. Glorot", "A. Bordes", "Y. Bengio"], "venue": "International Conference on Machine Learning (ICML),", "citeRegEx": "10", "shortCiteRegEx": null, "year": 2011}, {"title": "Connecting the dots with landmarks: Discriminatively learning domaininvariant features for unsupervised domain adaptation", "author": ["B. Gong", "K. Grauman", "F. Sha"], "venue": "International Conference on Machine Learning (ICML),", "citeRegEx": "11", "shortCiteRegEx": null, "year": 2013}, {"title": "Geodesic flow kernel for unsupervised domain adaptation", "author": ["B. Gong", "Y. Shi", "F. Sha", "K. Grauman"], "venue": "IEEE Conference on Computer Vision and Pattern Recognition (CVPR),", "citeRegEx": "12", "shortCiteRegEx": null, "year": 2012}, {"title": "Generative adversarial nets", "author": ["I. Goodfellow", "J. Pouget-Abadie", "M. Mirza", "B. Xu", "D. Warde-Farley", "S. Ozair", "A. Courville", "Y. Bengio"], "venue": "Advances in Neural Information Processing Systems (NIPS),", "citeRegEx": "13", "shortCiteRegEx": null, "year": 2014}, {"title": "Domain adaptation for object recognition: An unsupervised approach", "author": ["R. Gopalan", "R. Li", "R. Chellappa"], "venue": "IEEE International Conference on Computer Vision (ICCV),", "citeRegEx": "14", "shortCiteRegEx": null, "year": 2011}, {"title": "A kernel two-sample test", "author": ["A. Gretton", "K. Borgwardt", "M. Rasch", "B. Sch\u00f6lkopf", "A. Smola"], "venue": "Journal of Machine Learning Research (JMLR), 13:723\u2013773,", "citeRegEx": "15", "shortCiteRegEx": null, "year": 2012}, {"title": "Deep residual learning for image recognition", "author": ["K. He", "X. Zhang", "S. Ren", "J. Sun"], "venue": "IEEE Conference on Computer Vision and Pattern Recognition (CVPR),", "citeRegEx": "16", "shortCiteRegEx": null, "year": 2016}, {"title": "LSDA: Large scale detection through adaptation", "author": ["J. Hoffman", "S. Guadarrama", "E. Tzeng", "R. Hu", "J. Donahue", "R. Girshick", "T. Darrell", "K. Saenko"], "venue": "Advances in Neural Information Processing Systems (NIPS),", "citeRegEx": "17", "shortCiteRegEx": null, "year": 2014}, {"title": "Correcting sample selection bias by unlabeled data", "author": ["J. Huang", "A.J. Smola", "A. Gretton", "K.M. Borgwardt", "B. Sch\u00f6lkopf"], "venue": "Advances in Neural Information Processing Systems (NIPS),", "citeRegEx": "18", "shortCiteRegEx": null, "year": 2006}, {"title": "Caffe: Convolutional architecture for fast feature embedding", "author": ["Y. Jia", "E. Shelhamer", "J. Donahue", "S. Karayev", "J. Long", "R. Girshick", "S. Guadarrama", "T. Darrell"], "venue": "MM,", "citeRegEx": "19", "shortCiteRegEx": null, "year": 2014}, {"title": "Random feature maps for dot product kernels", "author": ["P. Kar", "H. Karnick"], "venue": "AISTATS, volume 22, pages 583\u2013591,", "citeRegEx": "20", "shortCiteRegEx": null, "year": 2012}, {"title": "Imagenet classification with deep convolutional neural networks", "author": ["A. Krizhevsky", "I. Sutskever", "G.E. Hinton"], "venue": "Advances in Neural Information Processing Systems (NIPS),", "citeRegEx": "21", "shortCiteRegEx": null, "year": 2012}, {"title": "Learning transferable features with deep adaptation networks", "author": ["M. Long", "Y. Cao", "J. Wang", "M.I. Jordan"], "venue": "International Conference on Machine Learning (ICML),", "citeRegEx": "22", "shortCiteRegEx": null, "year": 2015}, {"title": "Unsupervised domain adaptation with residual transfer networks", "author": ["M. Long", "H. Zhu", "J. Wang", "M.I. Jordan"], "venue": "Advances in Neural Information Processing Systems (NIPS), pages 136\u2013144,", "citeRegEx": "23", "shortCiteRegEx": null, "year": 2016}, {"title": "Domain adaptation: Learning bounds and algorithms", "author": ["Y. Mansour", "M. Mohri", "A. Rostamizadeh"], "venue": "Conference on Computational Learning Theory (COLT),", "citeRegEx": "24", "shortCiteRegEx": null, "year": 2009}, {"title": "Unrolled generative adversarial networks", "author": ["L. Metz", "B. Poole", "D. Pfau", "J. Sohl-Dickstein"], "venue": "ICLR,", "citeRegEx": "25", "shortCiteRegEx": null, "year": 2017}, {"title": "Conditional generative adversarial nets", "author": ["M. Mirza", "S. Osindero"], "venue": "arXiv preprint arXiv:1411.1784,", "citeRegEx": "26", "shortCiteRegEx": null, "year": 2014}, {"title": "Learning and transferring mid-level image representations using convolutional neural networks", "author": ["M. Oquab", "L. Bottou", "I. Laptev", "J. Sivic"], "venue": "IEEE Conference on Computer Vision and Pattern Recognition (CVPR),", "citeRegEx": "27", "shortCiteRegEx": null, "year": 2013}, {"title": "Domain adaptation via transfer component analysis", "author": ["S.J. Pan", "I.W. Tsang", "J.T. Kwok", "Q. Yang"], "venue": "IEEE Transactions on Neural Networks (TNN), 22(2):199\u2013210,", "citeRegEx": "28", "shortCiteRegEx": null, "year": 2011}, {"title": "A survey on transfer learning", "author": ["S.J. Pan", "Q. Yang"], "venue": "IEEE Transactions on Knowledge and Data Engineering (TKDE), 22(10):1345\u20131359,", "citeRegEx": "29", "shortCiteRegEx": null, "year": 2010}, {"title": "Dataset shift in machine learning", "author": ["J. Quionero-Candela", "M. Sugiyama", "A. Schwaighofer", "N.D. Lawrence"], "venue": "The MIT Press,", "citeRegEx": "30", "shortCiteRegEx": null, "year": 2009}, {"title": "Random features for large-scale kernel machines", "author": ["A. Rahimi", "B. Recht"], "venue": "Advances in neural information processing systems, pages 1177\u20131184,", "citeRegEx": "31", "shortCiteRegEx": null, "year": 2008}, {"title": "Adapting visual category models to new domains", "author": ["K. Saenko", "B. Kulis", "M. Fritz", "T. Darrell"], "venue": "European Conference on Computer Vision (ECCV),", "citeRegEx": "33", "shortCiteRegEx": null, "year": 2010}, {"title": "Hilbert space embeddings of hidden markov models", "author": ["L. Song", "B. Boots", "S.M. Siddiqi", "G.J. Gordon", "A. Smola"], "venue": "International Conference on Machine Learning (ICML),", "citeRegEx": "34", "shortCiteRegEx": null, "year": 2010}, {"title": "Robust low rank kernel embeddings of multivariate distributions", "author": ["L. Song", "B. Dai"], "venue": "Advances in Neural Information Processing Systems (NIPS), pages 3228\u20133236,", "citeRegEx": "35", "shortCiteRegEx": null, "year": 2013}, {"title": "Hilbert space embeddings of conditional distributions with applications to dynamical systems", "author": ["L. Song", "J. Huang", "A. Smola", "K. Fukumizu"], "venue": "International Conference on Machine Learning (ICML),", "citeRegEx": "36", "shortCiteRegEx": null, "year": 2009}, {"title": "Direct importance estimation with model selection and its application to covariate shift adaptation", "author": ["M. Sugiyama", "S. Nakajima", "H. Kashima", "P.V. Buenau", "M. Kawanabe"], "venue": "Advances in Neural Information Processing Systems (NIPS),", "citeRegEx": "37", "shortCiteRegEx": null, "year": 2008}, {"title": "Deep domain confusion: Maximizing for domain invariance", "author": ["E. Tzeng", "J. Hoffman", "N. Zhang", "K. Saenko", "T. Darrell"], "venue": "CoRR, abs/1412.3474,", "citeRegEx": "38", "shortCiteRegEx": null, "year": 2014}, {"title": "Simultaneous deep transfer across domains and tasks", "author": ["E. Tzeng", "J. Hoffman", "N. Zhang", "K. Saenko", "T. Darrell"], "venue": "IEEE International Conference on Computer Vision (ICCV),", "citeRegEx": "39", "shortCiteRegEx": null, "year": 2015}, {"title": "How transferable are features in deep neural networks", "author": ["J. Yosinski", "J. Clune", "Y. Bengio", "H. Lipson"], "venue": "In Advances in Neural Information Processing Systems (NIPS),", "citeRegEx": "40", "shortCiteRegEx": "40", "year": 2014}, {"title": "Domain adaptation under target and conditional shift", "author": ["K. Zhang", "B. Sch\u00f6lkopf", "K. Muandet", "Z. Wang"], "venue": "International Conference on Machine Learning (ICML),", "citeRegEx": "41", "shortCiteRegEx": null, "year": 2013}, {"title": "Cross validation framework to choose amongst models and datasets for transfer learning", "author": ["E. Zhong", "W. Fan", "Q. Yang", "O. Verscheure", "J. Ren"], "venue": "ECML/PKDD, pages 547\u2013562. Springer,", "citeRegEx": "42", "shortCiteRegEx": null, "year": 2010}], "referenceMentions": [{"referenceID": 29, "context": "However, this learning paradigm suffers from the shift in data distributions across different domains, which poses a major obstacle in adapting learning models for a target task [30, 29].", "startOffset": 178, "endOffset": 186}, {"referenceID": 28, "context": "However, this learning paradigm suffers from the shift in data distributions across different domains, which poses a major obstacle in adapting learning models for a target task [30, 29].", "startOffset": 178, "endOffset": 186}, {"referenceID": 28, "context": "Learning a discriminative model that reduces the dataset shift between training and test distributions is known as transfer learning or domain adaptation [29].", "startOffset": 154, "endOffset": 158}, {"referenceID": 17, "context": "Previous shallow transfer learning methods either bridge the source and target domains by learning invariant feature representations or estimating instance importance without using target labels [18, 28, 11].", "startOffset": 195, "endOffset": 207}, {"referenceID": 27, "context": "Previous shallow transfer learning methods either bridge the source and target domains by learning invariant feature representations or estimating instance importance without using target labels [18, 28, 11].", "startOffset": 195, "endOffset": 207}, {"referenceID": 10, "context": "Previous shallow transfer learning methods either bridge the source and target domains by learning invariant feature representations or estimating instance importance without using target labels [18, 28, 11].", "startOffset": 195, "endOffset": 207}, {"referenceID": 36, "context": "Recent deep transfer learning methods leverage deep networks to learn more transferable representations by embedding domain adaptation in the pipeline of deep learning, which can simultaneously disentangle the explanatory factors of variations behind data and match the marginal data distributions across domains [38, 22, 9, 39, 23].", "startOffset": 313, "endOffset": 332}, {"referenceID": 21, "context": "Recent deep transfer learning methods leverage deep networks to learn more transferable representations by embedding domain adaptation in the pipeline of deep learning, which can simultaneously disentangle the explanatory factors of variations behind data and match the marginal data distributions across domains [38, 22, 9, 39, 23].", "startOffset": 313, "endOffset": 332}, {"referenceID": 8, "context": "Recent deep transfer learning methods leverage deep networks to learn more transferable representations by embedding domain adaptation in the pipeline of deep learning, which can simultaneously disentangle the explanatory factors of variations behind data and match the marginal data distributions across domains [38, 22, 9, 39, 23].", "startOffset": 313, "endOffset": 332}, {"referenceID": 37, "context": "Recent deep transfer learning methods leverage deep networks to learn more transferable representations by embedding domain adaptation in the pipeline of deep learning, which can simultaneously disentangle the explanatory factors of variations behind data and match the marginal data distributions across domains [38, 22, 9, 39, 23].", "startOffset": 313, "endOffset": 332}, {"referenceID": 22, "context": "Recent deep transfer learning methods leverage deep networks to learn more transferable representations by embedding domain adaptation in the pipeline of deep learning, which can simultaneously disentangle the explanatory factors of variations behind data and match the marginal data distributions across domains [38, 22, 9, 39, 23].", "startOffset": 313, "endOffset": 332}, {"referenceID": 8, "context": "Adversarial adaptation methods [9, 39] are the top-performing architectures for domain adaptation.", "startOffset": 31, "endOffset": 38}, {"referenceID": 37, "context": "Adversarial adaptation methods [9, 39] are the top-performing architectures for domain adaptation.", "startOffset": 31, "endOffset": 38}, {"referenceID": 12, "context": "These methods work similarly as generative adversarial networks [13]: a domain discriminator is learned by minimizing the classification error of distinguishing the source from the target, while a deep network learns transferable representations which are indistinguishable by the domain discriminator.", "startOffset": 64, "endOffset": 68}, {"referenceID": 12, "context": "adversarial networks [13, 2].", "startOffset": 21, "endOffset": 28}, {"referenceID": 1, "context": "adversarial networks [13, 2].", "startOffset": 21, "endOffset": 28}, {"referenceID": 38, "context": "Second, the dataset shifts may linger in multiple domain-specific higher layers [40], and adversarial adaptation of a particular layer is not sufficient to close the domain shifts.", "startOffset": 80, "endOffset": 84}, {"referenceID": 8, "context": "This paper presents Randomized Multilinear Adversarial Networks (RMAN), which largely extends the ability of deep adversarial adaptation [9] to align the joint distributions of multiple domain-specific layers across domains for unsupervised domain adaptation.", "startOffset": 137, "endOffset": 140}, {"referenceID": 28, "context": "Transfer learning [29] generalizes a learner across different domains of different data distributions [37, 28, 8, 11, 41], which is widely applied in computer vision [33, 14, 12, 17] and natural language processing [6, 10].", "startOffset": 18, "endOffset": 22}, {"referenceID": 35, "context": "Transfer learning [29] generalizes a learner across different domains of different data distributions [37, 28, 8, 11, 41], which is widely applied in computer vision [33, 14, 12, 17] and natural language processing [6, 10].", "startOffset": 102, "endOffset": 121}, {"referenceID": 27, "context": "Transfer learning [29] generalizes a learner across different domains of different data distributions [37, 28, 8, 11, 41], which is widely applied in computer vision [33, 14, 12, 17] and natural language processing [6, 10].", "startOffset": 102, "endOffset": 121}, {"referenceID": 7, "context": "Transfer learning [29] generalizes a learner across different domains of different data distributions [37, 28, 8, 11, 41], which is widely applied in computer vision [33, 14, 12, 17] and natural language processing [6, 10].", "startOffset": 102, "endOffset": 121}, {"referenceID": 10, "context": "Transfer learning [29] generalizes a learner across different domains of different data distributions [37, 28, 8, 11, 41], which is widely applied in computer vision [33, 14, 12, 17] and natural language processing [6, 10].", "startOffset": 102, "endOffset": 121}, {"referenceID": 39, "context": "Transfer learning [29] generalizes a learner across different domains of different data distributions [37, 28, 8, 11, 41], which is widely applied in computer vision [33, 14, 12, 17] and natural language processing [6, 10].", "startOffset": 102, "endOffset": 121}, {"referenceID": 31, "context": "Transfer learning [29] generalizes a learner across different domains of different data distributions [37, 28, 8, 11, 41], which is widely applied in computer vision [33, 14, 12, 17] and natural language processing [6, 10].", "startOffset": 166, "endOffset": 182}, {"referenceID": 13, "context": "Transfer learning [29] generalizes a learner across different domains of different data distributions [37, 28, 8, 11, 41], which is widely applied in computer vision [33, 14, 12, 17] and natural language processing [6, 10].", "startOffset": 166, "endOffset": 182}, {"referenceID": 11, "context": "Transfer learning [29] generalizes a learner across different domains of different data distributions [37, 28, 8, 11, 41], which is widely applied in computer vision [33, 14, 12, 17] and natural language processing [6, 10].", "startOffset": 166, "endOffset": 182}, {"referenceID": 16, "context": "Transfer learning [29] generalizes a learner across different domains of different data distributions [37, 28, 8, 11, 41], which is widely applied in computer vision [33, 14, 12, 17] and natural language processing [6, 10].", "startOffset": 166, "endOffset": 182}, {"referenceID": 5, "context": "Transfer learning [29] generalizes a learner across different domains of different data distributions [37, 28, 8, 11, 41], which is widely applied in computer vision [33, 14, 12, 17] and natural language processing [6, 10].", "startOffset": 215, "endOffset": 222}, {"referenceID": 9, "context": "Transfer learning [29] generalizes a learner across different domains of different data distributions [37, 28, 8, 11, 41], which is widely applied in computer vision [33, 14, 12, 17] and natural language processing [6, 10].", "startOffset": 215, "endOffset": 222}, {"referenceID": 3, "context": "Deep networks learn abstract representations that disentangle the explanatory factors of variations behind data [4] and extract transferable factors underlying different populations [10, 27], which can only reduce, but not remove, the cross-domain discrepancy [40].", "startOffset": 112, "endOffset": 115}, {"referenceID": 9, "context": "Deep networks learn abstract representations that disentangle the explanatory factors of variations behind data [4] and extract transferable factors underlying different populations [10, 27], which can only reduce, but not remove, the cross-domain discrepancy [40].", "startOffset": 182, "endOffset": 190}, {"referenceID": 26, "context": "Deep networks learn abstract representations that disentangle the explanatory factors of variations behind data [4] and extract transferable factors underlying different populations [10, 27], which can only reduce, but not remove, the cross-domain discrepancy [40].", "startOffset": 182, "endOffset": 190}, {"referenceID": 38, "context": "Deep networks learn abstract representations that disentangle the explanatory factors of variations behind data [4] and extract transferable factors underlying different populations [10, 27], which can only reduce, but not remove, the cross-domain discrepancy [40].", "startOffset": 260, "endOffset": 264}, {"referenceID": 36, "context": "Recent work on deep domain adaptation embeds domain-adaptation modules into deep network to boost transfer performance [38, 9, 39, 22, 23].", "startOffset": 119, "endOffset": 138}, {"referenceID": 8, "context": "Recent work on deep domain adaptation embeds domain-adaptation modules into deep network to boost transfer performance [38, 9, 39, 22, 23].", "startOffset": 119, "endOffset": 138}, {"referenceID": 37, "context": "Recent work on deep domain adaptation embeds domain-adaptation modules into deep network to boost transfer performance [38, 9, 39, 22, 23].", "startOffset": 119, "endOffset": 138}, {"referenceID": 21, "context": "Recent work on deep domain adaptation embeds domain-adaptation modules into deep network to boost transfer performance [38, 9, 39, 22, 23].", "startOffset": 119, "endOffset": 138}, {"referenceID": 22, "context": "Recent work on deep domain adaptation embeds domain-adaptation modules into deep network to boost transfer performance [38, 9, 39, 22, 23].", "startOffset": 119, "endOffset": 138}, {"referenceID": 12, "context": "Generative Adversarial Networks (GAN) [13] constitute two networks in a two-player game: a generator that captures data distribution and a discriminator that distinguishes between generated samples and ground truth data.", "startOffset": 38, "endOffset": 42}, {"referenceID": 1, "context": "ease training [2, 1], avoid mode collapse [26, 5, 25].", "startOffset": 14, "endOffset": 20}, {"referenceID": 0, "context": "ease training [2, 1], avoid mode collapse [26, 5, 25].", "startOffset": 14, "endOffset": 20}, {"referenceID": 25, "context": "ease training [2, 1], avoid mode collapse [26, 5, 25].", "startOffset": 42, "endOffset": 53}, {"referenceID": 4, "context": "ease training [2, 1], avoid mode collapse [26, 5, 25].", "startOffset": 42, "endOffset": 53}, {"referenceID": 24, "context": "ease training [2, 1], avoid mode collapse [26, 5, 25].", "startOffset": 42, "endOffset": 53}, {"referenceID": 3, "context": "Deep networks [4] can learn more transferable representations than traditional hand-crafted features [27, 40].", "startOffset": 14, "endOffset": 17}, {"referenceID": 26, "context": "Deep networks [4] can learn more transferable representations than traditional hand-crafted features [27, 40].", "startOffset": 101, "endOffset": 109}, {"referenceID": 38, "context": "Deep networks [4] can learn more transferable representations than traditional hand-crafted features [27, 40].", "startOffset": 101, "endOffset": 109}, {"referenceID": 8, "context": "The favorable transferability of deep features leads to several state of the art deep transfer learning methods [9, 39, 22, 23].", "startOffset": 112, "endOffset": 127}, {"referenceID": 37, "context": "The favorable transferability of deep features leads to several state of the art deep transfer learning methods [9, 39, 22, 23].", "startOffset": 112, "endOffset": 127}, {"referenceID": 21, "context": "The favorable transferability of deep features leads to several state of the art deep transfer learning methods [9, 39, 22, 23].", "startOffset": 112, "endOffset": 127}, {"referenceID": 22, "context": "The favorable transferability of deep features leads to several state of the art deep transfer learning methods [9, 39, 22, 23].", "startOffset": 112, "endOffset": 127}, {"referenceID": 20, "context": "AlexNet [21] and ResNet [16], to novel randomized multilinear adversarial networks (RMANs) as shown in Figure 1.", "startOffset": 8, "endOffset": 12}, {"referenceID": 15, "context": "AlexNet [21] and ResNet [16], to novel randomized multilinear adversarial networks (RMANs) as shown in Figure 1.", "startOffset": 24, "endOffset": 28}, {"referenceID": 38, "context": "Based on the quantification study of feature transferability in deep convolutional networks [40], convolutional layers can learn generic features that are transferable across domains [40].", "startOffset": 92, "endOffset": 96}, {"referenceID": 38, "context": "Based on the quantification study of feature transferability in deep convolutional networks [40], convolutional layers can learn generic features that are transferable across domains [40].", "startOffset": 183, "endOffset": 187}, {"referenceID": 38, "context": "However, the literature findings also reveal that the deep features can reduce, but not remove, the cross-domain distribution discrepancy [40, 22, 23].", "startOffset": 138, "endOffset": 150}, {"referenceID": 21, "context": "However, the literature findings also reveal that the deep features can reduce, but not remove, the cross-domain distribution discrepancy [40, 22, 23].", "startOffset": 138, "endOffset": 150}, {"referenceID": 22, "context": "However, the literature findings also reveal that the deep features can reduce, but not remove, the cross-domain distribution discrepancy [40, 22, 23].", "startOffset": 138, "endOffset": 150}, {"referenceID": 38, "context": "The deep features in CNNs eventually transition from general to specific along the network, and the transferability of features and classifiers decreases when the cross-domain discrepancy increases [40].", "startOffset": 198, "endOffset": 202}, {"referenceID": 20, "context": "Taking AlexNet [21] as an example, the activations in the higher fully-connected layers L = {fc6, fc7, fc8} are not safely transferable for domain adaptation [40].", "startOffset": 15, "endOffset": 19}, {"referenceID": 38, "context": "Taking AlexNet [21] as an example, the activations in the higher fully-connected layers L = {fc6, fc7, fc8} are not safely transferable for domain adaptation [40].", "startOffset": 158, "endOffset": 162}, {"referenceID": 2, "context": "Many existing methods address transfer learning by bounding the target error with the source error plus a discrepancy between the marginal distributions P (X) and Q(X) of the source and target domains [3].", "startOffset": 201, "endOffset": 204}, {"referenceID": 14, "context": "A rich line of work is based on the Maximum Mean Discrepancy (MMD) [15], a kernel two-sample test statistic, which measures the discrepancy in marginal distributions P (X) andQ(X) [38, 22, 23].", "startOffset": 67, "endOffset": 71}, {"referenceID": 36, "context": "A rich line of work is based on the Maximum Mean Discrepancy (MMD) [15], a kernel two-sample test statistic, which measures the discrepancy in marginal distributions P (X) andQ(X) [38, 22, 23].", "startOffset": 180, "endOffset": 192}, {"referenceID": 21, "context": "A rich line of work is based on the Maximum Mean Discrepancy (MMD) [15], a kernel two-sample test statistic, which measures the discrepancy in marginal distributions P (X) andQ(X) [38, 22, 23].", "startOffset": 180, "endOffset": 192}, {"referenceID": 22, "context": "A rich line of work is based on the Maximum Mean Discrepancy (MMD) [15], a kernel two-sample test statistic, which measures the discrepancy in marginal distributions P (X) andQ(X) [38, 22, 23].", "startOffset": 180, "endOffset": 192}, {"referenceID": 12, "context": "Recently, motivated by the success of generative adversarial networks [13], domain adversarial adaptation has been proposed [9, 39] to measure the discrepancy in distributions P (X) and Q(X) by a domain discriminator.", "startOffset": 70, "endOffset": 74}, {"referenceID": 8, "context": "Recently, motivated by the success of generative adversarial networks [13], domain adversarial adaptation has been proposed [9, 39] to measure the discrepancy in distributions P (X) and Q(X) by a domain discriminator.", "startOffset": 124, "endOffset": 131}, {"referenceID": 37, "context": "Recently, motivated by the success of generative adversarial networks [13], domain adversarial adaptation has been proposed [9, 39] to measure the discrepancy in distributions P (X) and Q(X) by a domain discriminator.", "startOffset": 124, "endOffset": 131}, {"referenceID": 8, "context": "It has been shown by [9] that the the error functional of the domain discriminator is well corresponded to the distribution discrepancy used to bound the target risk in the theory of domain adaptation [3, 24].", "startOffset": 21, "endOffset": 24}, {"referenceID": 2, "context": "It has been shown by [9] that the the error functional of the domain discriminator is well corresponded to the distribution discrepancy used to bound the target risk in the theory of domain adaptation [3, 24].", "startOffset": 201, "endOffset": 208}, {"referenceID": 23, "context": "It has been shown by [9] that the the error functional of the domain discriminator is well corresponded to the distribution discrepancy used to bound the target risk in the theory of domain adaptation [3, 24].", "startOffset": 201, "endOffset": 208}, {"referenceID": 12, "context": "Mode collapse [13, 2] has been a well-known difficulty in adversarial learning, which says that when the distribution is multimode, there is the risk that different modes cannot be matched across domains.", "startOffset": 14, "endOffset": 21}, {"referenceID": 1, "context": "Mode collapse [13, 2] has been a well-known difficulty in adversarial learning, which says that when the distribution is multimode, there is the risk that different modes cannot be matched across domains.", "startOffset": 14, "endOffset": 21}, {"referenceID": 25, "context": ",Zt|L|) instead of the marginal distributions P (X) and Q(X), the discriminative information conveyed in the classifier layer Z|L| may reveal the multimode structure [26], which can further enable multimode adversarial adaptation.", "startOffset": 166, "endOffset": 170}, {"referenceID": 22, "context": "In this paper, we follow [23] and adopt the tensor product between activations of multiple layers L to perform lossless multilinear fusion, i.", "startOffset": 25, "endOffset": 29}, {"referenceID": 34, "context": "Tensor product of infinite-dimensional nonlinear feature maps has been successfully applied to embed joint/conditional distributions into reproducing kernel Hilbert spaces (RKHSs) [36, 34, 35] due to its great capability of capturing the full interactions between different sets of random variables.", "startOffset": 180, "endOffset": 192}, {"referenceID": 32, "context": "Tensor product of infinite-dimensional nonlinear feature maps has been successfully applied to embed joint/conditional distributions into reproducing kernel Hilbert spaces (RKHSs) [36, 34, 35] due to its great capability of capturing the full interactions between different sets of random variables.", "startOffset": 180, "endOffset": 192}, {"referenceID": 33, "context": "Tensor product of infinite-dimensional nonlinear feature maps has been successfully applied to embed joint/conditional distributions into reproducing kernel Hilbert spaces (RKHSs) [36, 34, 35] due to its great capability of capturing the full interactions between different sets of random variables.", "startOffset": 180, "endOffset": 192}, {"referenceID": 30, "context": "This paper addresses the dimension explosion of multilinear fusion by randomized methods [31, 20].", "startOffset": 89, "endOffset": 97}, {"referenceID": 19, "context": "This paper addresses the dimension explosion of multilinear fusion by randomized methods [31, 20].", "startOffset": 89, "endOffset": 97}, {"referenceID": 8, "context": "Following the idea of domain adversarial adaptation [9, 39], we train a domain discriminator network D to discriminate the joint distributions P (Z, .", "startOffset": 52, "endOffset": 59}, {"referenceID": 37, "context": "Following the idea of domain adversarial adaptation [9, 39], we train a domain discriminator network D to discriminate the joint distributions P (Z, .", "startOffset": 52, "endOffset": 59}, {"referenceID": 8, "context": "Remark: The randomized multilinear adversary (6) differs from previous domain adversarial adaptation methods [9, 39] based on ordinal adversary in that, for the activations Z in each layer ` \u2208 L, the randomized multilinear operation puts non-uniform weights reflecting the influence of other variables in other layers L\\`.", "startOffset": 109, "endOffset": 116}, {"referenceID": 37, "context": "Remark: The randomized multilinear adversary (6) differs from previous domain adversarial adaptation methods [9, 39] based on ordinal adversary in that, for the activations Z in each layer ` \u2208 L, the randomized multilinear operation puts non-uniform weights reflecting the influence of other variables in other layers L\\`.", "startOffset": 109, "endOffset": 116}, {"referenceID": 38, "context": "The features in lower layers are safely transferable and will not need distribution adaptation [40].", "startOffset": 95, "endOffset": 99}, {"referenceID": 8, "context": "Remark: The RMAN models improve existing domain adversarial adaptation methods [9, 39] by jointly adapting multiple layers (in particular, the classifier layer is jointly included for adaptation), which potentially circumvents the mode collapse difficulty during adversarial training by incorporating discriminative information to the adversary.", "startOffset": 79, "endOffset": 86}, {"referenceID": 37, "context": "Remark: The RMAN models improve existing domain adversarial adaptation methods [9, 39] by jointly adapting multiple layers (in particular, the classifier layer is jointly included for adaptation), which potentially circumvents the mode collapse difficulty during adversarial training by incorporating discriminative information to the adversary.", "startOffset": 79, "endOffset": 86}, {"referenceID": 21, "context": "The RMAN models also improve existing deep adaptation methods [22, 23] by randomized multilinear fusion of multiple domain-specific layers, which removes cumbersome layer-wise hyper-parameters in [22] and tackles dimension explosion difficulty in [23].", "startOffset": 62, "endOffset": 70}, {"referenceID": 22, "context": "The RMAN models also improve existing deep adaptation methods [22, 23] by randomized multilinear fusion of multiple domain-specific layers, which removes cumbersome layer-wise hyper-parameters in [22] and tackles dimension explosion difficulty in [23].", "startOffset": 62, "endOffset": 70}, {"referenceID": 21, "context": "The RMAN models also improve existing deep adaptation methods [22, 23] by randomized multilinear fusion of multiple domain-specific layers, which removes cumbersome layer-wise hyper-parameters in [22] and tackles dimension explosion difficulty in [23].", "startOffset": 196, "endOffset": 200}, {"referenceID": 22, "context": "The RMAN models also improve existing deep adaptation methods [22, 23] by randomized multilinear fusion of multiple domain-specific layers, which removes cumbersome layer-wise hyper-parameters in [22] and tackles dimension explosion difficulty in [23].", "startOffset": 247, "endOffset": 251}, {"referenceID": 31, "context": "Office-31 [33] is a standard benchmark for visual domain adaptation, comprising 4,652 images and 31 categories collected from three distinct domains: Amazon (A), which contains images downloaded from amazon.", "startOffset": 10, "endOffset": 14}, {"referenceID": 36, "context": "We evaluate all methods across three transfer tasks A\u2192W, D\u2192W and W\u2192D, which are widely used by previous deep transfer learning methods [38, 9], and another three transfer tasks A\u2192 D, D\u2192 A and W\u2192 A as used in [22, 39, 23].", "startOffset": 135, "endOffset": 142}, {"referenceID": 8, "context": "We evaluate all methods across three transfer tasks A\u2192W, D\u2192W and W\u2192D, which are widely used by previous deep transfer learning methods [38, 9], and another three transfer tasks A\u2192 D, D\u2192 A and W\u2192 A as used in [22, 39, 23].", "startOffset": 135, "endOffset": 142}, {"referenceID": 21, "context": "We evaluate all methods across three transfer tasks A\u2192W, D\u2192W and W\u2192D, which are widely used by previous deep transfer learning methods [38, 9], and another three transfer tasks A\u2192 D, D\u2192 A and W\u2192 A as used in [22, 39, 23].", "startOffset": 208, "endOffset": 220}, {"referenceID": 37, "context": "We evaluate all methods across three transfer tasks A\u2192W, D\u2192W and W\u2192D, which are widely used by previous deep transfer learning methods [38, 9], and another three transfer tasks A\u2192 D, D\u2192 A and W\u2192 A as used in [22, 39, 23].", "startOffset": 208, "endOffset": 220}, {"referenceID": 22, "context": "We evaluate all methods across three transfer tasks A\u2192W, D\u2192W and W\u2192D, which are widely used by previous deep transfer learning methods [38, 9], and another three transfer tasks A\u2192 D, D\u2192 A and W\u2192 A as used in [22, 39, 23].", "startOffset": 208, "endOffset": 220}, {"referenceID": 27, "context": "We compare the proposed randomized multilinear adversarial network (RMAN) with both shallow and deep transfer learning methods: Transfer Component Analysis (TCA) [28], Geodesic Flow Kernel (GFK) [12], Deep Domain Confusion (DDC) [38], Deep Adaptation Network (DAN) [22], Residual Transfer Network (RTN) [23], and Reverse Gradient (RevGrad) [9].", "startOffset": 162, "endOffset": 166}, {"referenceID": 11, "context": "We compare the proposed randomized multilinear adversarial network (RMAN) with both shallow and deep transfer learning methods: Transfer Component Analysis (TCA) [28], Geodesic Flow Kernel (GFK) [12], Deep Domain Confusion (DDC) [38], Deep Adaptation Network (DAN) [22], Residual Transfer Network (RTN) [23], and Reverse Gradient (RevGrad) [9].", "startOffset": 195, "endOffset": 199}, {"referenceID": 36, "context": "We compare the proposed randomized multilinear adversarial network (RMAN) with both shallow and deep transfer learning methods: Transfer Component Analysis (TCA) [28], Geodesic Flow Kernel (GFK) [12], Deep Domain Confusion (DDC) [38], Deep Adaptation Network (DAN) [22], Residual Transfer Network (RTN) [23], and Reverse Gradient (RevGrad) [9].", "startOffset": 229, "endOffset": 233}, {"referenceID": 21, "context": "We compare the proposed randomized multilinear adversarial network (RMAN) with both shallow and deep transfer learning methods: Transfer Component Analysis (TCA) [28], Geodesic Flow Kernel (GFK) [12], Deep Domain Confusion (DDC) [38], Deep Adaptation Network (DAN) [22], Residual Transfer Network (RTN) [23], and Reverse Gradient (RevGrad) [9].", "startOffset": 265, "endOffset": 269}, {"referenceID": 22, "context": "We compare the proposed randomized multilinear adversarial network (RMAN) with both shallow and deep transfer learning methods: Transfer Component Analysis (TCA) [28], Geodesic Flow Kernel (GFK) [12], Deep Domain Confusion (DDC) [38], Deep Adaptation Network (DAN) [22], Residual Transfer Network (RTN) [23], and Reverse Gradient (RevGrad) [9].", "startOffset": 303, "endOffset": 307}, {"referenceID": 8, "context": "We compare the proposed randomized multilinear adversarial network (RMAN) with both shallow and deep transfer learning methods: Transfer Component Analysis (TCA) [28], Geodesic Flow Kernel (GFK) [12], Deep Domain Confusion (DDC) [38], Deep Adaptation Network (DAN) [22], Residual Transfer Network (RTN) [23], and Reverse Gradient (RevGrad) [9].", "startOffset": 340, "endOffset": 343}, {"referenceID": 15, "context": "RTN jointly learns transferable features and adapts different source and target classifiers via deep residual learning [16].", "startOffset": 119, "endOffset": 123}, {"referenceID": 12, "context": "RevGrad enables domain adversarial learning [13] by adapting a single layer of deep networks, which matches the source and target domains by making them indistinguishable for a domain discriminator.", "startOffset": 44, "endOffset": 48}, {"referenceID": 21, "context": "We follow standard evaluation protocols for unsupervised domain adaptation [22, 9].", "startOffset": 75, "endOffset": 82}, {"referenceID": 8, "context": "We follow standard evaluation protocols for unsupervised domain adaptation [22, 9].", "startOffset": 75, "endOffset": 82}, {"referenceID": 40, "context": "For all baseline methods, we either follow their original model selection procedures, or conduct transfer cross-validation [42] if their model selection strategies are not specified.", "startOffset": 123, "endOffset": 127}, {"referenceID": 40, "context": "We also adopt transfer cross-validation [42] to select parameter \u03bb for the RMAN models.", "startOffset": 40, "endOffset": 44}, {"referenceID": 14, "context": "median trick [15, 22].", "startOffset": 13, "endOffset": 21}, {"referenceID": 21, "context": "median trick [15, 22].", "startOffset": 13, "endOffset": 21}, {"referenceID": 20, "context": "We examine the influence of deep representations for domain adaptation by exploring AlexNet [21] and ResNet [16] as base architectures for learning deep representations.", "startOffset": 92, "endOffset": 96}, {"referenceID": 15, "context": "We examine the influence of deep representations for domain adaptation by exploring AlexNet [21] and ResNet [16] as base architectures for learning deep representations.", "startOffset": 108, "endOffset": 112}, {"referenceID": 6, "context": "For shallow methods, we follow DeCAF [7] and use as deep representations the activations of the fc7 (AlexNet) and pool5 (ResNet) layers.", "startOffset": 37, "endOffset": 40}, {"referenceID": 18, "context": "We implement all deep methods based on the Caffe [19] framework, and fine-tune from AlexNet [21] and ResNet [16] models pre-trained on the ImageNet dataset [32].", "startOffset": 49, "endOffset": 53}, {"referenceID": 20, "context": "We implement all deep methods based on the Caffe [19] framework, and fine-tune from AlexNet [21] and ResNet [16] models pre-trained on the ImageNet dataset [32].", "startOffset": 92, "endOffset": 96}, {"referenceID": 15, "context": "We implement all deep methods based on the Caffe [19] framework, and fine-tune from AlexNet [21] and ResNet [16] models pre-trained on the ImageNet dataset [32].", "startOffset": 108, "endOffset": 112}, {"referenceID": 8, "context": "9 and the learning rate strategy implemented in RevGrad [9]: the learning rate is not selected by a grid search due to high computational cost\u2014it is adjusted during SGD using these formulas: \u03b7p = \u03b70 (1+\u03b1p) , where p is the training progress linearly changing from 0 to 1, \u03b70 = 0.", "startOffset": 56, "endOffset": 59}, {"referenceID": 8, "context": "To suppress noisy activations at the early stages of training, instead of fixing parameter \u03bb, we gradually change it by multiplying 2 1+exp(\u2212\u03b4p) \u2212 1, where \u03b4 = 10 [9].", "startOffset": 163, "endOffset": 166}, {"referenceID": 20, "context": "Table 1: Accuracy (%) on Office-31 for unsupervised domain adaptation (AlexNet and ResNet) Method A\u2192W D\u2192W W\u2192 D A\u2192 D D\u2192 A W\u2192 A Avg AlexNet [21] 60.", "startOffset": 138, "endOffset": 142}, {"referenceID": 27, "context": "8 TCA [28] 59.", "startOffset": 6, "endOffset": 10}, {"referenceID": 11, "context": "8 GFK [12] 58.", "startOffset": 6, "endOffset": 10}, {"referenceID": 36, "context": "7 DDC [38] 61.", "startOffset": 6, "endOffset": 10}, {"referenceID": 21, "context": "3 DAN [22] 68.", "startOffset": 6, "endOffset": 10}, {"referenceID": 22, "context": "7 RTN [23] 73.", "startOffset": 6, "endOffset": 10}, {"referenceID": 8, "context": "7 RevGrad [9] 73.", "startOffset": 10, "endOffset": 13}, {"referenceID": 15, "context": "0 ResNet [16] 68.", "startOffset": 9, "endOffset": 13}, {"referenceID": 27, "context": "1 TCA [28] 74.", "startOffset": 6, "endOffset": 10}, {"referenceID": 11, "context": "3 GFK [12] 74.", "startOffset": 6, "endOffset": 10}, {"referenceID": 36, "context": "8 DDC [38] 75.", "startOffset": 6, "endOffset": 10}, {"referenceID": 21, "context": "7 DAN [22] 83.", "startOffset": 6, "endOffset": 10}, {"referenceID": 22, "context": "3 RTN [23] 84.", "startOffset": 6, "endOffset": 10}, {"referenceID": 8, "context": "6 RevGrad [9] 82.", "startOffset": 10, "endOffset": 13}, {"referenceID": 21, "context": "For fair comparison, the results of DAN [22], RTN [23], and RevGrad [9] are directly reported from their original papers.", "startOffset": 40, "endOffset": 44}, {"referenceID": 22, "context": "For fair comparison, the results of DAN [22], RTN [23], and RevGrad [9] are directly reported from their original papers.", "startOffset": 50, "endOffset": 54}, {"referenceID": 8, "context": "For fair comparison, the results of DAN [22], RTN [23], and RevGrad [9] are directly reported from their original papers.", "startOffset": 68, "endOffset": 71}, {"referenceID": 20, "context": "Table 2: Accuracy (%) on ImageCLEF-DA for unsupervised domain adaptation (AlexNet and ResNet) Method I\u2192 P P\u2192 I I\u2192 C C\u2192 I C\u2192 P P\u2192 C Avg AlexNet [21] 66.", "startOffset": 143, "endOffset": 147}, {"referenceID": 21, "context": "9 DAN [22] 67.", "startOffset": 6, "endOffset": 10}, {"referenceID": 22, "context": "9 RTN [23] 67.", "startOffset": 6, "endOffset": 10}, {"referenceID": 8, "context": "4 RevGrad [9] 66.", "startOffset": 10, "endOffset": 13}, {"referenceID": 15, "context": "4 ResNet [16] 74.", "startOffset": 9, "endOffset": 13}, {"referenceID": 21, "context": "7 DAN [22] 75.", "startOffset": 6, "endOffset": 10}, {"referenceID": 22, "context": "3 RTN [23] 75.", "startOffset": 6, "endOffset": 10}, {"referenceID": 8, "context": "9 RevGrad [9] 75.", "startOffset": 10, "endOffset": 13}, {"referenceID": 31, "context": "and target domains are substantially different, and produce comparable classification accuracies on easy transfer tasks, D\u2192W and W\u2192 D, where the source and target domains are similar [33].", "startOffset": 183, "endOffset": 187}, {"referenceID": 38, "context": "This confirms the current practice that deep networks, even the extremely deep ones (ResNet), can learn abstract feature representations that only reduce but not remove the cross-domain discrepancy [40].", "startOffset": 198, "endOffset": 202}, {"referenceID": 21, "context": "Although both RMAN and DAN [22] adapt multiple domain-specific layers, the improvement from DAN to RMAN is crucial for domain adaptation: DAN imposes multiple MMD penalties, each independently reducing the distribution shift in a single layer; RMAN enables domain adaptation by making the source and target domains indistinguishable for a domain discriminator under the randomized multilinear fusion of deep features and classifier predictions in multiple layers, which can essentially reduce the dataset shift in the joint distributions of multiple task-specific layers.", "startOffset": 27, "endOffset": 31}, {"referenceID": 6, "context": "using t-SNE embeddings [7].", "startOffset": 23, "endOffset": 26}, {"referenceID": 2, "context": "Distribution Discrepancy: The domain adaptation theory [3, 24] suggests A-distance as a measure of cross-domain discrepancy, which, together with the source risk, will bound the target risk.", "startOffset": 55, "endOffset": 62}, {"referenceID": 23, "context": "Distribution Discrepancy: The domain adaptation theory [3, 24] suggests A-distance as a measure of cross-domain discrepancy, which, together with the source risk, will bound the target risk.", "startOffset": 55, "endOffset": 62}], "year": 2017, "abstractText": "Adversarial learning has been successfully embedded into deep networks to learn transferable features for domain adaptation, which reduce distribution discrepancy between the source and target domains and improve generalization performance. Prior domain adversarial adaptation methods could not align complex multimode distributions since the discriminative structures and inter-layer interactions across multiple domain-specific layers have not been exploited for distribution alignment. In this paper, we present randomized multilinear adversarial networks (RMAN), which exploit multiple feature layers and the classifier layer based on a randomized multilinear adversary to enable both deep and discriminative adversarial adaptation. The learning can be performed by stochastic gradient descent with the gradients computed by back-propagation in linear-time. Experiments demonstrate that our models exceed the state-of-the-art results on standard domain adaptation datasets.", "creator": "LaTeX with hyperref package"}}}