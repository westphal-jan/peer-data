{"id": "1706.00188", "review": {"conference": "arxiv", "VERSION": "v1", "DATE_OF_SUBMISSION": "1-Jun-2017", "title": "Deep Learning for Hate Speech Detection in Tweets", "abstract": "adobe speech detection / yahoo is usable for applications like angry event extraction, adaptive ai chatterbots, identity recommendation, aggressive sentiment filtering. we define this task : being attempted to classify a victim under racist, sexist vs neither. the complexity of identifying natural language constructs makes translating work very challenging. kids perform analytical experiments with simple behavior learning architectures at learn hard word analyses to handle expressive complexity. our experience on social benchmark dataset or 16k annotated tweets show feasible such hard learning methods measure product - of - origin - forest semantic / word n - net points by ~ 130 db points.", "histories": [["v1", "Thu, 1 Jun 2017 07:25:22 GMT  (25kb,D)", "http://arxiv.org/abs/1706.00188v1", "In Proceedings of ACM WWW'17 Companion, Perth, Western Australia, Apr 2017 (WWW'17), 2 pages"]], "COMMENTS": "In Proceedings of ACM WWW'17 Companion, Perth, Western Australia, Apr 2017 (WWW'17), 2 pages", "reviews": [], "SUBJECTS": "cs.CL cs.IR", "authors": ["pinkesh badjatiya", "shashank gupta", "manish gupta", "vasudeva varma"], "accepted": false, "id": "1706.00188"}, "pdf": {"name": "1706.00188.pdf", "metadata": {"source": "CRF", "title": "Deep Learning for Hate Speech Detection in Tweets", "authors": ["Pinkesh Badjatiya", "Shashank Gupta", "Manish Gupta", "Vasudeva Varma"], "emails": ["shashank.gupta}@research.iiit.ac.in,", "gmanish@microsoft.com,", "vv@iiit.ac.in"], "sections": [{"heading": "1. INTRODUCTION", "text": "With the massive increase in social interactions on online social networks, there has also been an increase of hateful activities that exploit such infrastructure. On Twitter, hateful tweets are those that contain abusive speech targeting individuals (cyber-bullying, a politician, a celebrity, a product) or particular groups (a country, LGBT, a religion, gender, an organization, etc.). Detecting such hateful speech is important for analyzing public sentiment of a group of users towards another group, and for discouraging associated wrongful activities. It is also useful to filter tweets before content recommendation, or learning AI chatterbots from tweets1.\nThe manual way of filtering out hateful tweets is not scalable, motivating researchers to identify automated ways. In this work, we focus on the problem of classifying a tweet as racist, sexist or neither. The task is quite challenging due to the inherent complexity of the natural language constructs \u2013 different forms of hatred, different kinds of targets, different ways of representing the same meaning. Most of the earlier work revolves either around manual feature extraction [6] or use representation learning methods followed by a linear classifier [1, 4]. However, recently deep learning methods have shown accuracy improvements across a large number\n\u2020authors contributed equally 1https://en.wikipedia.org/wiki/Tay (bot)\nc\u00a92017 International World Wide Web Conference Committee (IW3C2), published under Creative Commons CC BY 4.0 License. WWW 2017 Companion, April 3-7, 2017, Perth, Australia. ACM 978-1-4503-4914-7/17/04. http://dx.doi.org/10.1145/3041021.3054223\n.\nof complex problems in speech, vision and text applications. To the best of our knowledge, we are the first to experiment with deep learning architectures for the hate speech detection task.\nIn this paper, we experiment with multiple classifiers such as Logistic Regression, Random Forest, SVMs, Gradient Boosted Decision Trees (GBDTs) and Deep Neural Networks(DNNs). The feature spaces for these classifiers are in turn defined by task-specific embeddings learned using three deep learning architectures: FastText, Convolutional Neural Networks (CNNs), Long Short-Term Memory Networks (LSTMs). As baselines, we compare with feature spaces comprising of char n-grams [6], TF-IDF vectors, and Bag of Words vectors (BoWV).\nMain contributions of our paper are as follows: (1) We investigate the application of deep learning methods for the task of hate speech detection. (2) We explore various tweet semantic embeddings like char n-grams, word Term FrequencyInverse Document Frequency (TF-IDF) values, Bag of Words Vectors (BoWV) over Global Vectors for Word Representation (GloVe), and task-specific embeddings learned using FastText, CNNs and LSTMs. (3) Our methods beat stateof-the-art methods by a large margin (\u223c18 F1 points better)."}, {"heading": "2. PROPOSED APPROACH", "text": "We first discuss a few baseline methods and then discuss the proposed approach. In all these methods, an embedding is generated for a tweet and is used as its feature representation with a classifier. Baseline Methods: As baselines, we experiment with three broad representations. (1) Char n-grams: It is the state-ofthe-art method [6] which uses character n-grams for hate speech detection. (2) TF-IDF: TF-IDF are typical features used for text classification. (3) BoWV: Bag of Words Vector approach uses the average of the word (GloVe) embeddings to represent a sentence. We experiment with multiple classifiers for both the TF-IDF and the BoWV approaches. Proposed Methods: We investigate three neural network architectures for the task, described as follows. For each of the three methods, we initialize the word embeddings with either random embeddings or GloVe embeddings. (1) CNN: Inspired by Kim et. al [3]\u2019s work on using CNNs for sentiment classification, we leverage CNNs for hate speech detection. We use the same settings for the CNN as described in [3]. (2) LSTM: Unlike feed-forward neural networks, recurrent neural networks like LSTMs can use their internal memory to process arbitrary sequences of inputs. Hence, we use LSTMs to capture long range dependencies in tweets, which may play a role in hate speech detection. ar X iv :1 70 6.\n00 18\n8v 1\n[ cs\n.C L\n] 1\nJ un\n2 01\n7\n(3) FastText: FastText [2] represents a document by average of word vectors similar to the BoWV model, but allows update of word vectors through Back-propagation during training as opposed to the static word representation in the BoWV model, allowing the model to fine-tune the word representations according to the task.\nAll of these networks are trained (fine-tuned) using labeled data with back-propagation. Once the network is learned, a new tweet is tested against the network which classifies it as racist, sexist or neither. Besides learning the network weights, these methods also learn task-specific word embeddings tuned towards the hate speech labels. Therefore, for each of the networks, we also experiment by using these embeddings as features and various other classifiers like SVMs and GBDTs as the learning method."}, {"heading": "3. EXPERIMENTS", "text": ""}, {"heading": "3.1 Dataset and Experimental Settings", "text": "We experimented with a dataset of 16K annotated tweets made available by the authors of [6]. Of the 16K tweets, 3383 are labeled as sexist, 1972 as racist, and the remaining are marked as neither sexist nor racist. For the embedding based methods, we used the GloVe [5] pre-trained word embeddings. GloVe embeddings2 have been trained on a large tweet corpus (2B tweets, 27B tokens, 1.2M vocab, uncased). We experimented with multiple word embedding sizes for our task. We observed similar results with different sizes, and hence due to lack of space we report results using embedding size=200. We performed 10-Fold Cross Validation and calculated weighted macro precision, recall and F1-scores.\nWe use \u2018adam\u2019 for CNN and LSTM, and \u2018RMS-Prop\u2019 for FastText as our optimizer. We perform training in batches of size 128 for CNN & LSTM and 64 for FastText. More details on the experimental setup can be found from our publicly available source code3."}, {"heading": "3.2 Results and Analysis", "text": "Table 1 shows the results of various methods on the hate speech detection task. Part A shows results for baseline methods. Parts B and C focus on the proposed methods where part B contains methods using neural networks only, while part C uses average of word embeddings learned by DNNs as features for GBDTs. We experimented with mul-\n2http://nlp.stanford.edu/projects/glove/ 3https://github.com/pinkeshbadjatiya/twitter-hatespeech\ntiple classifiers but report results mostly for GBDTs only, due to lack of space.\nAs the table shows, our proposed methods in part B are significantly better than the baseline methods in part A. Among the baseline methods, the word TF-IDF method is better than the character n-gram method. Among part B methods, CNN performed better than LSTM which was better than FastText. Surprisingly, initialization with random embeddings is slightly better than initialization with GloVe embeddings when used along with GBDT. Finally, part C methods are better than part B methods. The best method is \u201cLSTM + Random Embedding + GBDT\u201d where tweet embeddings were initialized to random vectors, LSTM was trained using back-propagation, and then learned embeddings were used to train a GBDT classifier. Combinations of CNN, LSTM, FastText embeddings as features for GBDTs did not lead to better results. Also note that the standard deviation for all these methods varies from 0.01 to 0.025.\nTo verify the task-specific nature of the embeddings, we show top few similar words for a few chosen words in Table 2 using the original GloVe embeddings and also embeddings learned using DNNs. The similar words obtained using deep neural network learned embeddings clearly show the \u201chatred\u201d towards the target words, which is in general not visible at all in similar words obtained using GloVe."}, {"heading": "4. CONCLUSIONS", "text": "In this paper, we investigated the application of deep neural network architectures for the task of hate speech detection. We found them to significantly outperform the existing methods. Embeddings learned from deep neural network models when combined with gradient boosted decision trees led to best accuracy values. In the future, we plan to explore the importance of the user network features for the task."}, {"heading": "5. REFERENCES", "text": "[1] N. Djuric, J. Zhou, R. Morris, M. Grbovic, V. Radosavljevic,\nand N. Bhamidipati. Hate Speech Detection with Comment Embeddings. In WWW, pages 29\u201330, 2015. [2] A. Joulin, E. Grave, P. Bojanowski, and T. Mikolov. Bag of Tricks for Efficient Text Classification. arXiv preprint arXiv:1607.01759, 2016. [3] Y. Kim. Convolutional Neural Networks for Sentence Classification. In EMNLP, pages 1746\u20131751, 2014. [4] C. Nobata, J. Tetreault, A. Thomas, Y. Mehdad, and Y. Chang. Abusive Language Detection in Online User Content. In WWW, pages 145\u2013153, 2016. [5] J. Pennington, R. Socher, and C. D. Manning. GloVe: Global Vectors for Word Representation. In EMNLP, volume 14, pages 1532\u201343, 2014. [6] Z. Waseem and D. Hovy. Hateful Symbols or Hateful People? Predictive Features for Hate Speech Detection on Twitter. In NAACL-HLT, pages 88\u201393, 2016."}], "references": [{"title": "Hate Speech Detection with Comment Embeddings", "author": ["N. Djuric", "J. Zhou", "R. Morris", "M. Grbovic", "V. Radosavljevic", "N. Bhamidipati"], "venue": "In WWW,", "citeRegEx": "1", "shortCiteRegEx": "1", "year": 2015}, {"title": "Bag of Tricks for Efficient Text Classification", "author": ["A. Joulin", "E. Grave", "P. Bojanowski", "T. Mikolov"], "venue": "arXiv preprint arXiv:1607.01759,", "citeRegEx": "2", "shortCiteRegEx": "2", "year": 2016}, {"title": "Convolutional Neural Networks for Sentence Classification", "author": ["Y. Kim"], "venue": "In EMNLP, pages 1746\u20131751,", "citeRegEx": "3", "shortCiteRegEx": "3", "year": 2014}, {"title": "Abusive Language Detection in Online User Content", "author": ["C. Nobata", "J. Tetreault", "A. Thomas", "Y. Mehdad", "Y. Chang"], "venue": "In WWW,", "citeRegEx": "4", "shortCiteRegEx": "4", "year": 2016}, {"title": "GloVe: Global Vectors for Word Representation", "author": ["J. Pennington", "R. Socher", "C.D. Manning"], "venue": "In EMNLP,", "citeRegEx": "5", "shortCiteRegEx": "5", "year": 2014}, {"title": "Hateful Symbols or Hateful People? Predictive Features for Hate Speech Detection on Twitter", "author": ["Z. Waseem", "D. Hovy"], "venue": "In NAACL-HLT,", "citeRegEx": "6", "shortCiteRegEx": "6", "year": 2016}], "referenceMentions": [{"referenceID": 5, "context": "Most of the earlier work revolves either around manual feature extraction [6] or use representation learning methods followed by a linear classifier [1, 4].", "startOffset": 74, "endOffset": 77}, {"referenceID": 0, "context": "Most of the earlier work revolves either around manual feature extraction [6] or use representation learning methods followed by a linear classifier [1, 4].", "startOffset": 149, "endOffset": 155}, {"referenceID": 3, "context": "Most of the earlier work revolves either around manual feature extraction [6] or use representation learning methods followed by a linear classifier [1, 4].", "startOffset": 149, "endOffset": 155}, {"referenceID": 5, "context": "As baselines, we compare with feature spaces comprising of char n-grams [6], TF-IDF vectors, and Bag of Words vectors (BoWV).", "startOffset": 72, "endOffset": 75}, {"referenceID": 5, "context": "(1) Char n-grams: It is the state-ofthe-art method [6] which uses character n-grams for hate speech detection.", "startOffset": 51, "endOffset": 54}, {"referenceID": 2, "context": "al [3]\u2019s work on using CNNs for sentiment classification, we leverage CNNs for hate speech detection.", "startOffset": 3, "endOffset": 6}, {"referenceID": 2, "context": "We use the same settings for the CNN as described in [3].", "startOffset": 53, "endOffset": 56}, {"referenceID": 5, "context": "Part A: Baselines Char n-gram+Logistic Regression [6] 0.", "startOffset": 50, "endOffset": 53}, {"referenceID": 1, "context": "(3) FastText: FastText [2] represents a document by average of word vectors similar to the BoWV model, but allows update of word vectors through Back-propagation during training as opposed to the static word representation in the BoWV model, allowing the model to fine-tune the word representations according to the task.", "startOffset": 23, "endOffset": 26}, {"referenceID": 5, "context": "We experimented with a dataset of 16K annotated tweets made available by the authors of [6].", "startOffset": 88, "endOffset": 91}, {"referenceID": 4, "context": "For the embedding based methods, we used the GloVe [5] pre-trained word embeddings.", "startOffset": 51, "endOffset": 54}], "year": 2017, "abstractText": "Hate speech detection on Twitter is critical for applications like controversial event extraction, building AI chatterbots, content recommendation, and sentiment analysis. We define this task as being able to classify a tweet as racist, sexist or neither. The complexity of the natural language constructs makes this task very challenging. We perform extensive experiments with multiple deep learning architectures to learn semantic word embeddings to handle this complexity. Our experiments on a benchmark dataset of 16K annotated tweets show that such deep learning methods outperform state-of-the-art char/word n-gram methods by \u223c18 F1 points.", "creator": "LaTeX with hyperref package"}}}