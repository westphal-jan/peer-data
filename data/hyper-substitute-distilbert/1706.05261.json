{"id": "1706.05261", "review": {"conference": "arxiv", "VERSION": "v1", "DATE_OF_SUBMISSION": "16-Jun-2017", "title": "From Propositional Logic to Plausible Reasoning: A Uniqueness Theorem", "abstract": "we transform the converse of akin propositional logic to a logic of formal reasoning, along provide four limits that asserting such expectation should satisfy. firstly is a requirement asserting some property of classical propositional logic be asserted in the true answer ; as such, ethical answers are narrower and less problematic ; those used in kant's model and its predecessor. as with cox'v hypothesis, those requirements such that the extended integral further became isomorphic to ( theta - rational ) - function. we strongly insert specific numerical values for the probabilities, making the universal definition of probability as a theorem, giving truth assignments necessarily satisfy the premise playing the role deciding the \" possible cases. \"", "histories": [["v1", "Fri, 16 Jun 2017 13:13:45 GMT  (44kb,D)", "http://arxiv.org/abs/1706.05261v1", "Submitted to Int'l Journal of Approximate Reasoning"]], "COMMENTS": "Submitted to Int'l Journal of Approximate Reasoning", "reviews": [], "SUBJECTS": "cs.AI cs.LO", "authors": ["kevin s van horn"], "accepted": false, "id": "1706.05261"}, "pdf": {"name": "1706.05261.pdf", "metadata": {"source": "CRF", "title": "From Propositional Logic to Plausible Reasoning: A Uniqueness Theorem", "authors": ["Kevin S. Van Horn"], "emails": ["vanhorn@adobe.com"], "sections": [{"heading": null, "text": "We consider the question of extending propositional logic to a logic of plausible reasoning, and posit four requirements that any such extension should satisfy. Each is a requirement that some property of classical propositional logic be preserved in the extended logic; as such, the requirements are simpler and less problematic than those used in Cox\u2019s Theorem and its variants. As with Cox\u2019s Theorem, our requirements imply that the extended logic must be isomorphic to (finite-set) probability theory. We also obtain specific numerical values for the probabilities, recovering the classical definition of probability as a theorem, with truth assignments that satisfy the premise playing the role of the \u201cpossible cases.\u201d\nKeywords: Bayesian, Carnap, Cox, Jaynes, logic, probability"}, {"heading": "1. Introduction", "text": "E. T. Jaynes [13, p. xxii] proposes the view that probability theory is the uniquely determined extension of classical propositional logic (CPL) to a \u201clogic of plausible reasoning\u201d :\nOur theme is simply: probability theory as extended logic. . . . the mathematical rules of probability theory are not merely rules for calculating frequencies of \u2018random variables\u2019; they are also the unique consistent rules for conducting inference (i.e. plausible reasoning) of any kind. . .\nThis view is grounded in the work of P\u00f3lya [17] and Cox [9], especially the latter. In this paper we aim to set the notion of probability theory as the necessary extension of CPL on solid footing.\nISubmitted and currently under review at International Journal of Approximate Reasoning.\nII c\u00a92017. This manuscript version is made available under the CC-BY-NC-ND 4.0 license http://creativecommons.org/licenses/by-nc-nd/4.0/.\nEmail address: vanhorn@adobe.com (Kevin S. Van Horn)\nPreprint submitted to Elsevier\nar X\niv :1\n70 6.\n05 26\n1v 1\n[ cs\n.A I]\n1 6\nJu n\n20 17\nOur goal is to generalize the logical consequence relation, which deals only in certitudes, to handle degrees of certainty. Whereas X |= A means that A (the conclusion) is a logical consequence of X (the premise), we write A | X for \u201cthe reasonable credibility of the proposition A (the query) when the proposition X (the premise) is known to be true\u201d (paraphrasing Cox [9].) We call (\u00b7 | \u00b7) the plausibility function. If X |= A then A | X is some value indicating \u201ccertainly true,\u201d if X |= \u00acA then A | X is some value indicating \u201ccertainly false,\u201d and otherwise A | X is a value indicating some intermediate level of plausibility. Our task is to determine what the plausibility function must be, based on logical criteria.\nAs a generalization of the logical consequence relation, the plausibility function must depend only on its two explicit arguments; the value it returns must not depend on any additional information that varies according to the problem domain to which it is applied, nor according to the intended meanings of the propositional symbols. This is a formal logical theory we are developing, and so any intended semantics of the propositional symbols must be expressed axiomatically in the premise.\nOne might question whether all relevant information for determining the plausibility of some proposition A can be expressed in propositional form for inclusion in the premise X. Might not our background information include \u201csoft\u201d relationships, mere propensities for propositions to be associated in some way? Although we provide some suggestive examples, we do not attempt to resolve that question. Instead we ask, given that the background information and intended semantics are expressed in propositional form and included in the premise, with no other information available, what can we conclude about the plausibility function?\nWe posit four Requirements for the plausibility function. Each of these requires that some property of the logical consequence relation be retained in the generalization to a plausibility function. Three are invariance properties, and the fourth is a requirement to preserve distinctions in degree of plausibility that already exist within CPL. These Requirements (discussed in detail later) are the following:\nR1. If X and Y are logically equivalent, and A and B are logically equivalent assuming X, then A | X = B | Y (Section 4.)\nR2. We may define a new propositional symbol without affecting the plausibility of any proposition that does not mention that symbol. Specifically, if s is a propositional symbol not appearing in A, X, or E, then A | X = A | (s\u2194 E) \u2227X (Section 5.)\nR3. Adding irrelevant information to the premise does not affect the plausibility of the query. Specifically, if Y is a satisfiable propositional formula that uses no propositional symbol occurring in A or X, then A | X = A | Y \u2227X (Section 6.)\nR4. The implication ordering is preserved: if X |= A\u2192 B but not X |= B \u2192 A\nthen A | X is a plausibility value that is strictly less than B | X (Section 7.)\nNote that we do not assume that plausibility values are real numbers, nor that they are totally ordered; R4 presumes only that there is some partial order on plausibility values.\nGiven R1\u2013R4, we prove that plausibilities are essentially probabilities in disguise. Specifically, we show that\n1. there is an order-preserving isomorphism P between the set of plausibility values P and the set of rational probabilities Q \u2229 [0, 1];\n2. P (A | X), the plausibility A | X mapped via P to the unit interval, is necessarily the ratio of the number of truth assignments that satisfy both A and X to the number of truth assignments that satisfy X; and\n3. hence the usual laws of probability follow as a consequence.\nThis identifies finite-set probability theory as the uniquely determined extension of CPL to a logic of plausible reasoning.\nThe body of this paper is organized as follows:\n\u2022 In Section 2 we compare this work to Cox\u2019s Theorem and variants, as well as Carnap\u2019s system of logical probability.\n\u2022 In Section 3 we review some notions from CPL, discuss the partial plausibility ordering that already exists within CPL, and discuss the nature of the plausibility function.\n\u2022 Our main result is proven in Sections 4, 5, 6, and 7, which also introduce the Requirements, discuss the motivation behind them, and explore some of their consequences. Along the way we discuss how Carnap\u2019s system violates R3.\n\u2022 In Section 8 we prove that R1\u2013R4 are consistent.\n\u2022 Section 9 discusses three topics: the connection of our results to the classical definition of probability, the issue of non-uniform probabilities, and an initial attempt at extending our results to infinite domains."}, {"heading": "2. Relation to Prior Work", "text": "To set the context for this paper, clarify our goals, and head off possible misconceptions, we now review similar prior work and point out the differences."}, {"heading": "2.1. Cox\u2019s Theorem", "text": "R. T. Cox [9] proposes a handful of intuitively-appealing, qualitative requirements for any system of plausible reasoning, and shows that these requirements imply that any such system is just probability theory in disguise. Specifically, he shows that there is an order isomorphism between plausibilities and the unit\ninterval [0, 1] such that A | X, after mapping from plausibilities to [0, 1], respects the laws of probability.\nOver the years Cox\u2019s arguments have been refined by others [1, 13, 16, 20, 21], making explicit some requirements that were only implicit in Cox\u2019s original presentation, and replacing some of the requirements with slightly less demanding assumptions than those used in Cox\u2019s original proof. One version of the requirements [21] may be summarized as follows:\nC1. A | X is a real number.\nC2. A | X = A\u2032 | X whenever A is logically equivalent to A\u2032, and B | X \u2264 A | X for any tautology A.\nC3. There exists a nonincreasing function S such that \u00acA | X = S (A | X) for all A and satisfiable X.\nC4. The set of plausibility triples (y1, y2, y3) where y1 = A1 | X, y2 = A2 | A1\u2227X, and y3 = A3 | A2 \u2227A1 \u2227X for some A1, A2, A3, and X, is dense in [0, 1]3.\nC5. There exists a continuous function F : [f, t]2 \u2192 [f, t], strictly increasing in both arguments on (f, t]2, such that A \u2227B | X = F (A | B \u2227X, B | X) for any A, B, and satisfiable X. Here we use t , A | X for any tautology A, and f , S (t).\nThese requirements have not been without controversy. For example, Shafer [18] objects to C1, C3, and C5; Halpern [11, 12] questions C4; and Colyvan [8] objects to C2 on the basis that it presumes the law of the excluded middle.\nOur approach has no equivalent of C1, C3, C4, or C5:\n\u2022 We are agnostic as to the set of allowed plausibility values. We do not even require that plausibility values be totally ordered.\n\u2022 We have no requirement on how the plausibility \u00acA decomposes.\n\u2022 We have no density requirement on plausibility values.\n\u2022 We have no requirement on how the plausibility of A\u2227B decomposes, much less any continuity or strictness requirements for such decompositions.\nWe do retain a variant of C2. Our goal is to extend the classical propositional logic; we make no attempt to address intuitionistic logic.\nOur requirements are all based on preserving in the extended logic some existing property of CPL. Three of these are invariances\u2014ways in which A or X may be modified without altering A | X\u2014and the last is a requirement to preserve those distinctions in degree of plausibility already present in CPL. We believe that such an approach leaves far less room for objections to the requirements.\nThe results we obtain are similar to those of Cox\u2019s Theorem, with these differences:\n\u2022 We obtain an order isomorphism P between plausibility values and rational probability values.\n\u2022 We obtain specific numerical values for P (A | X), and not just the laws for decomposing P (A | X).\n\u2022 The conditioning information X is necessarily a propositional formula. (Some variants [7, 13, 21] of Cox\u2019s Theorem allow X to be an undefined \u201cstate of information\u201d to which we may add additional propositional information.)\n\u2022 Our results apply only to finite problem domains or finite approximations of infinite domains. (In Section 9.3 we discuss how to extend our results to infinite domains.)"}, {"heading": "2.2. Clayton and Waddington: bridging the intution gap", "text": "In a recent paper, Clayton and Waddington [7] seek to \u201cbridge the intuition gap\u201d in Cox\u2019s Theorem by proposing alternative requirements they argue are more intuitively reasonable, and then proving C4 and the strictness of F in C5 as theorems. We find their most interesting and important contributions to be the following:\n\u2022 Rather than just tweaking Cox\u2019s Theorem, they have instead created an entirely new proof of its result. The meat of the proof of Cox\u2019s Theorem lies in deriving functional equations that F and S must satisfy, then solving those equations. But by the time they have \u201cbridged the intuition gap\u201d in the requirements, they already have most of the proof completed, without any need to solve functional equations.\n\u2022 Jaynes [13] argues that, if one\u2019s background information is \u201cindifferent\u201d between two propositions, then they should be assigned equal plausibility. They formalize this idea as an invariance principle: if A\u2032 | X \u2032 is obtained from A | X by consistently renaming all propositional symbols used via a one-to-one mapping, then the two plausibilities are equal.\n\u2022 Their proof yields the classical definition of probability\u2014the ratio of the number of positive cases to the number of all possible cases\u2014as a theorem in certain cases they call \u201cN -urns.\u201d\nHowever, the list of assumptions they use is fairly long: 11 altogether. We obtain similar results with fewer and simpler requirements, given in Sections 4\u20137. Here is a comparison:\n\u2022 Clayton and Waddington use a variant of C2 that replaces \u201cA is logically equivalent to A\u2032\u201d with \u201cA \u2227X is logically equivalent to A\u2032 \u2227X\u201d; this and their Assumption 2.1 are comparable to our R1 (replacement of premise or query with a logically equivalent formula).\n\u2022 Our R4 (preservation of the implication ordering) is a stronger (more general) version of their Assumption 2.7. We do not actually need this more general form\u2014Lemma 13 only uses a restricted form that corresponds to their Assumption 2.7\u2014but we feel that the rationale for the requirement is more clearly seen in this more general form.\n\u2022 Our R2 (invariance under definition of new propositional symbols) and R3 (invariance under addition of irrelevant information) have no direct equivalent among their assumptions, but are inspired by their discussion of the Principle of Indifference and their Assumption 2.3 (translation invariance).\n\u2022 We use no equivalent of C1 nor their Assumptions 1.2, 1.3, 1.4, 3.2, 3.3, and 3.5.\nFrom the above comparison one can see that it is the replacement of Assumption 2.3 with R2 and R3 that allows a drastic pruning of the assumptions used in obtaining the main results of their paper.\nOur approach was inspired by Clayton and Waddington\u2019s notion of an \u201cN - urn\u201d and the results they prove for N -urns. Our most important innovation is Lemma 6 showing how to reduce every allowable query-premise pair to a certain kind of N -urn."}, {"heading": "2.3. Carnap: logical probability", "text": "Carnap [5] undertakes an extensive investigation of \u201clogical probability.\u201d He mentions two notions of probability: probability1 is epistemic probability1 (\u201cthe degree of confirmation of a hypothesis h with respect to an evidence statement e\u201d), and probability2 is relative frequency. His focus is on probability1 and the problem of induction. Our terminology and his correspond roughly as follows:\n\u2022 Instead of a \u201cplausibility function\u201d Carnap discusses a \u201cconfirmation function\u201d c.\n\u2022 The rough equivalent of A | X in Carnap\u2019s system is c(A,X), with a crucial difference described below.\n\u2022 We call A and X the query and premise, respectively; he calls them the hypothesis and evidence.\nWe take A and X to be propositional formulas, whereas Carnap allows them to be sentences in a variant of first-order predicate logic in which the only allowed terms are variables and constant symbols. The domain of discourse is taken to be a countably infinite set of individuals, and for each individual there is a corresponding constant symbol. He calls this most general form of the language L\u221e.\n1Carnap later favored a decision-theoretic view of probability1 [5, Preface to the Second Edition].\nCarnap also considers restricted languages LN , N \u2265 1, in which only the first N constant symbols are allowed and the domain of discourse is only the first N individuals. Most of the focus is on the finite languages LN , with confirmation functions for L\u221e defined via a limiting process on the sequence of languages LN , N \u2265 1. This is similar in spirit, though not in detail, to our approach to infinite domains.\nA difference between Carnap\u2019s approach and ours is that we posit a single language and single set of propositional symbols S to be used for all problem domains, whereas in Carnap\u2019s system each problem domain has its own language L\u221e with its own set of predicate symbols and associated arities and interpretations.\nCarnap\u2019s finite languages LN are equivalent to propositional languages with a finite number of propositional symbols. Let an atomic sentence be a formula of the form p (s1, . . . , sk) for some k-ary predicate symbol p and constant symbols s1, . . . , sk. There are a finite number of distinct atomic sentences in LN . Define the propositional language L\u2032N to have as propositional symbols the atomic sentences of LN . We can transform any sentence A \u2208 LN into an equivalent propositional formula A\u2032 \u2208 L\u2032N :\n1. Remove all quantifiers by repeatedly replacing any occurrence of a subformula \u2200x\u03d5(x) with the semantically equivalent finite conjunction \u03d5 (s1) \u2227 \u00b7 \u00b7 \u00b7 \u2227 \u03d5 (sN ), where s1, . . . , sN are the constant symbols for the first N individuals.\n2. If equality is allowed, replace any subformula si = si with a logically valid sentence, and any subformula si = sj , i 6= j, with an unsatisfiable sentence. In both cases choose replacement sentences that contain no quantifiers nor use of equality. (Carnap specifies that distinct constant symbols are assumed to reference distinct individuals.)\nWe end up with propositional formulas in which the propositional symbols have internal structure, but this internal structure is of no consequence from the standpoint of deductive logic. To have logical effect, any intended meaning for this internal structure must be given by additional formulas in L\u2032N , axioms that are added to the set of premises used. For example, suppose that we are deducing the logical consequences of a set of premises \u0393, that we have a twoplace predicate lt, and that the intended meaning of lt(x, y) is that individual x precedes individuals y in some total ordering. Then we must add to \u0393 a set of axioms such as the following:\n\u2200x\u00aclt(x, x) \u2200x\u2200y (lt(x, y) \u2228 lt(y, x) \u2228 x = y)\n\u2200x\u2200y \u2200z (lt(x, y) \u2227 lt(y, z)\u2192 lt(x, z))\nMore precisely, we must add to \u0393 the result of transforming the above sentences of LN into equivalent propositional formulas of L\u2032N .\nCarnap, however, is unwilling to axiomatize the intended interpretations of the predicate symbols in this way. He writes [5, p. 55],\nSince we intend to construct inductive logic as a theory of degree of confirmation, based upon the meanings of the sentences involved\u2014in contradistinction to a mere calculus\u2014we shall construct the language systems L with an interpretation, hence as a system of semantical rules, not as uninterpreted syntactical systems.\n(Emphasis added.) This is an important difference between Carnap\u2019s system and ours, one that we discuss further in Section 3.4 and Section 9.2. Thus the equivalent of Carnap\u2019s c(h, e) in our scheme is not h | e, but instead h | e \u2227X, where X is a conjunction of\n\u2022 propositional axioms expressing the logical structure of the problem domain, and\n\u2022 propositional formulas expressing any other background information. Unlike Cox [9], Carnap makes no attempt to derive the laws of probability from more fundamental considerations; instead, his \u201cconventions on adequacy\u201d [5, p. 285] require that a valid confirmation function should conform to the laws of probability. He ensures this by proceeding as follows:\n1. A state description for LN amounts to a truth assignment on the set of atomic sentences of LN . 2. A regular measure function for LN amounts to a strictly positive probability mass function over the set of state descriptions for LN . 3. A regular confirmation function c for LN is then a confirmation function defined as\nc(h, e) = m(h \u2227 e)/m(e) for some regular measure function m on LN .\n4. These notions are extended to L\u221e by imposing a consistency condition on a sequence of regular measure functions mN on LN , N \u2265 1, considering the associated regular confirmation functions cN , and defining c\u221e(h, e) = limN\u2192\u221e cN (h, e).\nWe see therefore that, although it is the conditional probabilities c(h, e) that most interest Carnap, unconditional probabilities are for him more fundamental. In contrast, we take conditional plausibilities as the fundamental concept and, rather than imposing the laws of probability, seek to derive them.\nCarnap\u2019s goal is that the confirmation function appropriate to a problem domain should be uniquely determined by the semantics of the language L\u221e, specifically, the intended interpretation of the predicate symbols and constant symbols. In this he fails. Limiting his attention to systems that contain monadic predicates (\u201cproperties\u201d) only, he proposes a specific confirmation function c\u2217, but says [5, p. 563],\nNow the chief arguments in favor of the function c\u2217. . . will consist in showing that this function is free of the inadequacies in the other methods. It may then still be inadequate in other respects. It will not be claimed that c\u2217 is a perfectly adequate explicatum for probability1, let alone that it is the only adequate one. . .\nHe later [5, Preface to Second Edition][6] proposes instead an entire family of confirmation functions c\u03bb parameterized by a positive number \u03bb.\nIn contrast, we show in Theorem 14 that there is (up to isomorphism) a single, unique plausibility function satisfying our criteria. Ironically, it corresponds to the one confirmation function explicitly rejected by Carnap: a uniform distribution over the set of truth assignments satisfying the premise / evidence. We discuss this further in Section 9.2."}, {"heading": "3. Logical Preliminaries", "text": "In this section we review some concepts from CPL, introduce some additional logical concepts of our own, and discuss the nature of the plausibility function as extending the logical consequence relation |=."}, {"heading": "3.1. Review of classical propositional logic", "text": "A proposition is a statement or assertion that must be true or false; it is atomic if it cannot be decomposed into simpler assertions. A propositional symbol is one of a countably infinite set of symbols S that are used to represent atomic propositions. We abbreviate this to just \u201csymbol\u201d when the meaning is clear.\nIf S \u2286 S then a propositional formula on S is one of the following:\n\u2022 a propositional symbol from S;\n\u2022 a formula \u00acA, meaning \u201cnot A\u201d, for some propositional formula A on S; or\n\u2022 a formula A \u2227 B, meaning \u201cA and B,\u201d where A and B are propositional formulas on S.\nThe other common logical operators\u2014A\u2228B (or), A\u2192 B (implies), and A\u2194 B (if and only if)\u2014are defined in terms of \u00ac and \u2227 in the usual way. We abbreviate \u201cpropositional formula\u201d as just \u201cformula\u201d when the meaning is clear.\nWe write \u03a6 (S) for the set of all propositional formulas on S, and \u03a6+(S) for the satisfiable formulas.\nWe write \u03c3 JA1, . . . , AnK for the set of all propositional symbols occuring in any of the propositional formulas A1, . . . , An.\nA truth assignment on S is a function \u03c1 : S \u2192 {0, 1}, with 0 and 1 standing for falsity and truth, respectively. We recursively extend it to all formulas on S in the obvious way:\n\u03c1 JAK = \u03c1(A) if A \u2208 S \u03c1 J\u00acAK = 1\u2212 \u03c1 JAK\n\u03c1 JA \u2227BK = \u03c1 JAK \u00b7 \u03c1 JBK\nwhere \u2018\u00b7\u2019 is just integer multiplication.\nA truth assignment \u03c1 on S satisfies a formula A on S if \u03c1 JAK = 1. A formula A is satisfiable if there is some truth assignment \u03c1 on \u03c3 JAK that satisfies A. A formula A is logically valid, written |= A, if every truth assignment on \u03c3 JAK satisfies A.\nWe say that B is a logical consequence of A, or A logically implies B, written A |= B, if every truth assignment on \u03c3 JA,BK that satisfies A also satisfies B. This captures the notion of a logically valid argument: conclusion B follows as a logical consequence of premises A1, . . . , An if A1 \u2227 \u00b7 \u00b7 \u00b7 \u2227 An |= B. Note that A |= B if and only if |= A\u2192 B.\nThe restriction of a truth assignment \u03c1 on S to some S\u2032 \u2286 S is the truth assignment \u03c1\u2032 on S\u2032 such that \u03c1\u2032(s) = \u03c1(s) for every s \u2208 S\u2032.\nNote that \u03c1 JAK depends only on the truth values assigned to those symbols that actually appear in A; if A is a formula on S\u2032 \u2286 S, \u03c1 is a truth assignment on S, and \u03c1\u2032 is the restriction of \u03c1 to S\u2032, then \u03c1\u2032 JAK = \u03c1 JAK. Because of this, we have some leeway in choosing the set of propositional symbols to use in the definitions of \u201clogically valid,\u201d \u201csatisfiable,\u201d and \u201clogical consequence.\u201d If \u03c3 JAK \u2286 SA and \u03c3 JA,BK \u2286 SAB , then \u2022 A is logically valid iff every truth assignment on SA satisfies A.\n\u2022 A is satisfiable iff some truth assignment on SA satisfies A.\n\u2022 A |= B iff every truth assignment on SAB that satisfies A also satisfies B.\nSome notation.\n\u2022 Two formulas are logically equivalent, written A \u2261 B, if |= A\u2194 B.\n\u2022 A and B are logically equivalent assuming X, written A \u2261X B, if X |= A\u2194 B.\n\u2022 We will use finite quantification as an abbreviation where convenient, for example writing \u2227n i=1Ai for A1 \u2227 \u00b7 \u00b7 \u00b7 \u2227An.\n\u2022 If we write A1 \u2227 \u00b7 \u00b7 \u00b7 \u2227 An and n = 0, we understand this to mean some logically valid formula such as s \u2228 \u00acs.\n\u2022 If we write A1 \u2228 \u00b7 \u00b7 \u00b7 \u2228 An and n = 0, we understand this to mean some unsatisfiable formula such as s \u2227 \u00acs."}, {"heading": "3.2. Finite sample spaces", "text": "The development of probability theory usually begins with the idea of a sample space, which has been downplayed so far\u2014the focus has been on propositions. We find in Theorem 14 that A | X can be characterized in terms of an induced sample space: the set of truth assignments that satisfy X.2 In particular, we find that A | X is a function of the proportion of points from this induced sample space that satisfy A. This motivates the following:\n2This is similar to Carnap\u2019s system, in which the set of state descriptions serve as a sample space.\nDefinition 1. #S(X) is the number of truth assignments on S satisfying X, for any formula X and finite S such that \u03c3 JXK \u2286 S \u2286 S.\nThe size of the induced sample space is #S(X), and the proportion of points from the induced sample space that satisfy A is #S (A \u2227X) /#S(X), for S \u2287 \u03c3JA,XK.\nTypically one thinks of a finite sample space as an arbitrary set of n > 0 distinct values \u2126 = {\u03c91, . . . , \u03c9n} representing different possible states of some system under consideration. We can relate this to our notion of an induced sample space by choosing a set of n propositional symbols S = {s1, . . . , sn}, with the intended interpretation of si being that the state of the system is \u03c9i. If our premise X is a formula expressing that exactly one of the si is true, then there is a one-to-one correspondence between our original sample space \u2126 and the induced sample space of truth assignments, with \u03c9i corresponding to the single truth assignment \u03c1 on S satisfying si \u2227X. This motivates the following:\nDefinition 2. Given any sequence of n > 0 propositional symbols s1, . . . , sn, \u3008s1, . . . , sn\u3009 = (s1 \u2228 \u00b7 \u00b7 \u00b7 \u2228 sn) \u2227 \u2227\n1\u2264i<j\u2264n\n\u00ac (si \u2227 sj) ;\nthat is, \u3008s1, . . . , sn\u3009 means that exactly one of the si is true."}, {"heading": "3.3. The implication ordering", "text": "At first blush it would seem that CPL tells us very little about the relative plausibilities of different propositions, beyond determining which are certainly true and which are certainly false given a premise X. The reality is quite the opposite: CPL comes equipped with a rich inherent plausibility ordering that we call the implication ordering.\nDefinition 3. Let A,B,X \u2208 \u03a6 (S) with X satisfiable. We define\n(A XB) \u21d4 (X |= A\u2192 B) (A \u227aXB) \u21d4 (A XB) and not (B XA) .\nThe following properties are easily verified:\n\u2022 The relation X is a preorder: it is reflexive and transitive, but not antisymmetric.\n\u2022 A \u227aXB is the same as (A XB and not A \u2261XB).\n\u2022 A \u2261XB if and only A XB and B XA.\n\u2022 If A \u2261XA\u2032 and B \u2261XB\u2032 and A XB then A\u2032 XB\u2032.\nHence X defines a partial order on the equivalence classes of propositional formulas under the relation \u2261X. This partial order is essentially just the subset ordering on truth assignments:\nProperty. Let A1, A2, X \u2208 \u03a6 (S) with X satisfiable. Then A1 X A2 if and only if \u03b1 JA1K \u2286 \u03b1 JA2K, where \u03b1 JAK is the set of truth assignments on S that satisfy both A and X.\nAssuming X, we therefore conclude the following:\n\u2022 If A X B then B is at least as plausible as A, since B is true for any possible world (truth assignment satisfying X) for which A is true.\n\u2022 If A \u2261X B then A XB and B XA, hence A and B are equally plausible.\n\u2022 If A \u227aXB then B is strictly more plausible than A, since there are possible worlds for which B is true and A is not, but not vice versa.\nConsider an example that uses three propositional symbols s1, s2, s3 with X defined to be the formula stating that exactly one of these three is true: X = \u3008s1, s2, s3\u3009. Let F be any unsatisfiable formula and T be any logically valid formula. Then\nF \u227aX s1 \u227aX (s1 \u2228 s2) \u227aX (s1 \u2228 s2 \u2228 s3) \u2261X T.\nNote that adding additional information to the premise yields additional formulas A \u2192 B as logical consequences, and hence may collapse previously distinct plausibilities. Continuing the example, if we add additional information to X to obtain Y = X \u2227 \u00acs2, then\nF \u227aY s1 \u2261Y (s1 \u2228 s2) \u227aY (s1 \u2228 s2 \u2228 s3) \u2261Y T."}, {"heading": "3.4. The plausibility function", "text": "We extend CPL to Jaynes\u2019s \u201clogic of plausible reasoning\u201d by introducing a plausibility function (\u00b7 | \u00b7) whose domain is \u03a6 (S) \u00d7 \u03a6+ (S). Think of (\u00b7 | \u00b7) as extending the logical consequence relation: whereas X |= A means that A is known true (given X), and X |= \u00acA means that A is known false, it may be that neither of these relations hold; (\u00b7 | \u00b7) fills in the gaps, so to speak, by assigning intermediate plausibilities in such a case.\nThe logical consequence relation, as we have defined it, takes only a single premise X on the left-hand side, rather than a set of premises X . The compactness theorem for CPL says that if A is a logical consequence of a set of premises X , then it is a logical consequence of a finite subset of X [14, p. 16]; but any finite set of premises X1, . . . , Xn can be combined into a single premise X = X1 \u2227 \u00b7 \u00b7 \u00b7 \u2227Xn. Likewise, the plausibility function (\u00b7 | \u00b7) takes only a single premise as its second argument.\nWe write P for the range of the plausibility function, but leave it otherwise unspecified:\nDefinition 4. P is the set of achievable and meaningful plausibility values; that is,\nP = {(A | X) : A,X \u2208 \u03a6 (S) and X is satisfiable} .\nThere has been much unnecessary controversy over Cox\u2019s Theorem due to differing implicit assumptions as to the nature of its plausibility function. Halpern [11, 12] claims to demonstrate a counterexample to Cox\u2019s Theorem by examining a finite problem domain, but his argument presumes that there is a different plausibility function for every problem domain. Others [9, 16] seem to presume a single plausibility function, but with domain-specific information serving as an implicit extra argument3. A third interpretation [7, 13, 21] presumes a single plausibility function with all relevant information about the problem domain encapsulated in the second argument, the \u201cstate of information.\u201d\nWe follow this third interpretation, with the premise\u2014a propositional formula\u2014serving as the state of information:\n\u2022 In CPL there is only a single logical consequence relation |=, defined on \u03a6 (S), rather than entirely different logical consequence relations for each problem domain. In our extended logic there is likewise only a single plausibility function, defined on \u03a6 (S)\u00d7\u03a6+ (S), and a single set of plausibility values P that are used for all problem domains.\n\u2022 In CPL any information about the problem domain that we wish to use for deduction must be included in the premise(s) to the logical consequence relation. Likewise in our extended logic, all relevant background information about the problem domain must be included in the premise to the plausibility function.\nThink of the plausibility function as something one could implement as a pure function in some programming language, taking as input two strings matching the grammar for propositional formulas (or their corresponding parse trees), and having access to no other source of information about the problem domain.\nNote that we use the same set of propositional symbols S for all problem domains, rather than having a different set of propositional symbols for each problem domain. The latter option would make the set of allowed propositional symbols an implicit extra argument to the plausibility function. The set of symbols S is countably infinite to allow modeling arbitrarily complex problem domains.\nAs an example of incorporating background information into the premise, suppose that we wish to discuss the outcome of rolling a six-sided die, and our background knowledge is simply the list of distinct possible outcomes. Let symbols si, 1 \u2264 i \u2264 6, have the intended interpretation that the outcome is i. The formula \u3008s1, . . . , s6\u3009 expresses our background knowledge, and so\ns2 | \u3008s1, . . . , s6\u3009\n3Strictly speaking, this also amounts to a different plausibility function for every problem domain, but the practical difference is that certain structural properties of the plausibility function, such as its range and the choice of the functions F and S, remain the same across problem domains.\nis the plausibility of rolling a 2, and\ns1 \u2228 s2 | (s1 \u2228 s3 \u2228 s5) \u2227 \u3008s1, . . . , s6\u3009\nis the plausibility of rolling a 1 or 2 given that the outcome is odd. This stands in stark contrast to Carnap, who as previously mentioned rejects such an axiomatic approach. The second argument to his confirmation function is the evidence, which is \u201can observational report\u201d that \u201crefer[s] to facts\u201d [5, pp. 19\u201320]; background knowledge about the meaning of the symbols and logical structure of the domain is excluded. Given a situation like our die roll, in which there is a \u201cfamily of related properties,\u201d exactly one of which holds true for each individual, Carnap goes so far as to require modifying the definition of a fundamental concept in his system, the state-description, rather than simply including this information in the evidence [5, p. 77]."}, {"heading": "4. Invariance from Logical Equivalence", "text": "In this and the following sections we introduce our Requirements on the plausibility function and prove their consequences. These are all based on preserving existing properties of CPL. We shall consider properties of the logical consequence relation |=, as well as the implication ordering X for a given premise X.\nThe first property we consider is invariance under replacement of premise or query by a logically equivalent formula.\nThe logical consequence relation |= is invariant to replacement of premise by a logically equivalent formula: if X \u2261 Y then for all formulas A we have X |= A if and only if Y |= A. We require that the plausibility function exhibit this same invariance. This may be further justified by noting that the implication orderings X and Y are identical when X \u2261 Y .\nThe relation |= is also invariant to replacement of conclusion by a logically equivalent formula. In fact, the replacement formula need only be logically equivalent assuming the premise: if A \u2261XB, then X |= A if and only if X |= B. We require that the plausibility function exhibit this invariance also, for the query. This may be further justified by our argument in Section 3.3 that we should consider A and B equally plausible, assuming X, whenever A \u2261XB.\nWe combine these into a single requirement:\nR1. If X \u2261 Y and A \u2261X B then A | X = B | Y ."}, {"heading": "5. Invariance under Definition of New Symbols", "text": "It is common in mathematical proofs to define new symbols as abbreviations for complex expressions or formulas. The same may be done in propositional logic: we may introduce a new propositional symbol s (that appears in neither the premises nor conclusion) and use it as an abbreviation for some complex propositional formula E, by adding the definition s\u2194 E to our premises. This\ndoes not invalidate any logical consequence we already had, nor any create any new logical consequence that does not mention s.\nSpecifically, let s be a symbol not occurring in X, E, or A, and define Y = (s\u2194 E) \u2227X . Then X |= A if and only if Y |= A, and consequently, X and Y are identical on \u03a6 (S \\ {s}). We require that the plausibility function exhibit the same invariance:\nR2. Let s \u2208 S but s /\u2208 \u03c3 JA,X,EK. Then A | X = A | (s\u2194 E) \u2227X.\nOne cannot evade the force of this Requirement by supposing a problem domain with a limited set of symbols. Recall that there is only one plausibility function, used for all problem domains, and that S is countably infinite. Furthermore, even if the plausibility function were to take as a third argument a finite set of symbols from which the query and premise are constructed, the notion of extending a domain by defining an additional variable as a function of existing variables would still make sense. Forbidding such extension would be an artificial and unreasonable restriction, as one can already do this in CPL."}, {"heading": "5.1. Invariance under renaming", "text": "To build some intuition for R2 we now explore some of its more straightforward consequences, in conjunction with R1 (logical equivalence). Let us write B [s/C] for the result of replacing every occurrence of symbol s in formula B with the formula C. If s and t are distinct symbols, with t not occurring in formulas A or X, then using R2 to introduce a definition and later remove a different one gives us\nA | X = A | (t\u2194 s) \u2227X = A[s/t] | (t\u2194 s) \u2227X[s/t] = A[s/t] | (s\u2194 t) \u2227X[s/t] = A[s/t] | X[s/t].\nThat is, we can rename any single symbol, replacing it throughout A and X with a new symbol, and this leaves the plausibility unchanged.\nRepeating the process, the plausibility is invariant if we rename any set of symbols S = {s1, . . . , sn} to new symbols T = {t1, . . . , tn} not occurring in A or X. We can also permute the symbol names, by renaming from s1, . . . , sn to t1, . . . , tn and then to a permuation s\u20321, . . . , s\u2032n of s1, . . . , sn. That is, if we write B [s1/C1, . . . , sn/Cn] for the formula obtained by simultaneously replacing each symbol si with the formula Ci, we have\nA | X = A [s1/s\u20321, . . . , sn/s\u2032n] | X [s1/s\u20321, . . . , sn/s\u2032n] .\nThis result is the same as Clayton & Waddington\u2019s Assumption 2.3 (translation invariance) [7], which they motivate via Jaynes\u2019s \u201cindifference\u201d criterion [13, p. 19]:\nThe robot always represents equivalent states of knowledge by equivalent plausibility assignments. That is, if in two problems the robot\u2019s state of knowledge is the same (except perhaps for the labeling of the propositions), then it must assign the same plausibilities in both.\nFor example, if a, b, c, d are distinct symbols, then the following equalities hold:\na | a \u2228 b = c | c \u2228 d a | a\u2192 b = b | b\u2192 a\nConsider specifically the case where X treats symbols s and t symmetrically: that is, X is logically equivalent to X \u2032 = X[s/t, t/s]. One example would be\nX = (s \u2228 t) \u2227 \u00ac (s \u2227 t) X \u2032 = (t \u2228 s) \u2227 \u00ac (t \u2227 s) .\nIn this case we find that s and t must be equally plausible:\ns | X = t | X \u2032 = t | X.\nThis result is similar in spirit to the principle of insufficient reason: our premise X provides no information that differs between s and t, so intuition suggests these propositions should be equally plausible. The result is more general, however, in that s and t need not be mutually exclusive nor exhaustive.\nAnother transformation we can consider is that of replacing all occurrences of symbol s with \u00acs in both premise and query. As before, let s and t be distinct symbols, with t not occurring in formulas A nor X. Again we use R2 to introduce a definition and later remove a different one; we also add a final step that invokes the above-demonstrated invariance under renaming. This yields the following:\nA | X = A | (t\u2194 \u00acs) \u2227X = A[s/\u00ac\u00acs] | (t\u2194 \u00acs) \u2227X[s/\u00ac\u00acs] = A[s/\u00act] | (t\u2194 \u00acs) \u2227X[s/\u00act] = A[s/\u00act] | (s\u2194 \u00act) \u2227X[s/\u00act] = A[s/\u00act] | X[s/\u00act] = A[s/\u00act][t/s] | X[s/\u00act][t/s] = A[s/\u00acs] | X[s/\u00acs].\nThat is, the plausibility is invariant to a transformation in which we uniformly replace any single symbol with its negation throughout both A and X. In particular, if X is logically equivalent to X[s/\u00acs], then\ns | X = \u00acs | X.\nThis result may be viewed as an instance of the principle of insufficient reason applied to the case of two indistinguishable possibilities.\nTake note of the common pattern in the above two derivations:\n1. Use R2 to introduce a definition of some symbol t in terms of symbol s appearing in the premise or query.\n2. Use logical equivalence and the definition of t to rewrite premise and query in a way that removes all occurrences of s except its occurrence in the right-hand side of the definition of t.\n3. Use logical equivalence to rewrite the definition of t in terms of s as a definition of s in terms of t.\n4. Use R2 to drop the definition of s, as this symbol is now used nowhere else in the premise or query.\nLemma 6 in Section 5.3 extends this pattern to sets of symbols, simultaneously introducing multiple definitions in step 1, and this yields a stronger form of transformation invariance that subsumes the results derived here."}, {"heading": "5.2. Invariance under change of variables", "text": "Renaming symbols and swapping s for \u00acs throughout both premise and query are special cases of more general change of variables transformations. As an example of this, suppose that we are considering a problem domain in which there is some quantity x that can take on any of n discrete, ordered values v1 < v2 < \u00b7 \u00b7 \u00b7 < vn. There are two different vocabularies we might use for this domain:\n1. Use symbols s1, . . . , sn with the intended meaning of si being \u201cx = vi,\u201d and express \u201cx \u2264 vi\u201d as s1 \u2228 \u00b7 \u00b7 \u00b7 \u2228 si. 2. Use symbols t1, . . . , tn with the intended meaning of ti being \u201cx \u2264 vi,\u201d and express \u201cx = vi\u201d as ti \u2227 \u00acti\u22121 when i > 1, or just ti when i = 1.\nThe two vocabularies can express exactly the same propositions, so there is no fundamental reason to choose one over the other, and it seems that the plausibility A | X should not depend on which vocabulary we use. Going from one vocabulary to the other is just a change of variables: we can express each of the si in terms of t1, . . . , tn, or we can express each of the ti in terms of s1, . . . , sn.\nThis isn\u2019t quite enough, though. Defining\n\u03c4st(A) = A [s1 / t1, s2 / t2 \u2227 \u00act1, . . . , sn / tn \u2227 \u00actn\u22121] \u03c4ts(B) = B [t1 / s1, t2 / s1 \u2228 s2, . . . , tn / s1 \u2228 \u00b7 \u00b7 \u00b7 \u2228 sn]\nwe want \u03c4st and \u03c4ts to be inverses of each other (up to logical equivalence). We find that \u03c4ts (\u03c4st (A)) is logically equivalent to A, but\n\u03c4st (\u03c4ts (B)) \u2261 B [t1 / t1, t2 / t1 \u2228 t2, . . . , tn / t1 \u2228 \u00b7 \u00b7 \u00b7 \u2228 tn]\nwhich is not, in general, logically equivalent to B. We need to assume that ti \u2192 ti+1 for 1 \u2264 i < n to get the desired equivalence. Such an assumption concords with the intended meaning of ti, and must be implied by the premise when vocabulary 2 is used. (Likewise, the premise must imply \u3008s1, . . . , sn\u3009 when\nvocabulary 1 is used.) So this notion of change of variables is more subtle than it appears at first glance; how do we define a general rule that accounts for issues like this?\nThe solution is to define a change of variables in terms of a bijection between\n\u2022 the set of truth assignments satisfying the premise when vocabulary 1 is used, and\n\u2022 the set of truth assignments satisfying the premise when vocabulary 2 is used.\nThis motivates the following:\nDefinition 5. f is a change-of-variables transformation between the pairs (A,X) and (A\u2032, X \u2032) if it is a bijection between\n\u2022 the set of truth assignments on some S \u2287 \u03c3 JA,XK satisfying X, and\n\u2022 the set of truth assignments on some S\u2032 \u2287 \u03c3 JA\u2032, X \u2032K satisfying X \u2032,\nwith the additional property that any truth assignment \u03c1 on S satisfies A \u2227X if and only if f(\u03c1) satisfies A\u2032 \u2227X \u2032.\nNote that the logical consequence relation trivially satisfies invariance under change of variables:\nX |= A\u21d4 X \u2032 |= A\u2032 if there exists a change-of-variables transformation f between (A,X) and (A\u2032, X \u2032).\nFor the plausibility function, invariance under change of variables means the following:\nA | X = A\u2032 | X \u2032 if there exists a change-of-variables transformation f between (A,X) and (A\u2032, X \u2032).\nInvariance under definition of new symbols is a special case of invariance under change of variables: we have A\u2032 = A, X \u2032 = (s\u2194 E) \u2227 X, S = \u03c3 JA,X,EK, S\u2032 = S \u222a {s}, and f(\u03c1) = \u03c1\u2032 where\n\u03c1\u2032(s) = \u03c1 JEK \u03c1\u2032(t) = \u03c1(t) if t \u2208 S.\nThe inverse of f maps \u03c1\u2032 to the restriction of \u03c1\u2032 to S. We show in Corollary 9 that R1 and R2 together imply invariance under change of variables. So, given R1, invariance under change of variables and invariance under definition of new symbols are equivalent. We chose the latter as our requirement because it is easier to explain and justify."}, {"heading": "5.3. Reduction to canonical form", "text": "We take the first step towards our main result by showing that we can reduce every query-premise pair to a canonical form in which the premise merely states that we have a sample space of n distinct possibilities, and the query merely states that one of the first m \u2264 n possibilities is true. In the following, keep in mind our convention that A1 \u2228 \u00b7 \u00b7 \u00b7 \u2228 Am stands for some unsatisfiable formula when m = 0.\nLemma 6. Let S \u2286 S be finite, A \u2208 \u03a6 (S), and X \u2208 \u03a6+(S). Then R1 and R2 together imply that\nA | X = (t1 \u2228 \u00b7 \u00b7 \u00b7 \u2228 tm | \u3008t1, . . . , tn\u3009)\nwhere n = #S(X) > 0, m = #S (A \u2227X) \u2264 n, and T = {t1, . . . , tn} is any set of n propositional symbols disjoint from S.\nProof. Let \u03c11, . . . , \u03c1n be the truth assignments on S that satisfy X, ordered so that the first m also satisfy A. Enumerate the elements of S as s1, . . . , sp. The proof proceeds in four steps.\nStep 1. For each 1 \u2264 i \u2264 n and 1 \u2264 j \u2264 p define\nZi = Li,1 \u2227 \u00b7 \u00b7 \u00b7 \u2227 Li,p\nLi,j = { sj if \u03c1i (sj) = 1 \u00acsj if \u03c1i (sj) = 0.\nNote that \u03c1i is the one and only truth assignment on S that satisfies Zi. Define the formulas\nDt,i = ti \u2194 Zi Dt = Dt,1 \u2227 \u00b7 \u00b7 \u00b7 \u2227Dt,n.\nThen by R2, A | X = A | Dt \u2227X. (5.1)\nStep 2. The formulas Zi were constructed such that\nA \u2227X \u2261 Z1 \u2228 \u00b7 \u00b7 \u00b7 \u2228 Zm\nand hence Dt \u2227X |= (A\u2194 Z1 \u2228 \u00b7 \u00b7 \u00b7 \u2228 Zm) .\nR1 then gives A | Dt \u2227X = (t1 \u2228 \u00b7 \u00b7 \u00b7 \u2228 tm | Dt \u2227X) . (5.2)\nStep 3. Define the following:\nIj = {i : 1 \u2264 i \u2264 n, \u03c1i (sj) = 1} Ds,j = sj \u2194 \u2228 i\u2208Ij ti\nDs = Ds,1 \u2227 \u00b7 \u00b7 \u00b7 \u2227Ds,p.\nConsider how to construct the set of truth assignments \u03c1\u0303 on S \u222a T that satisfy both \u3008t1, . . . , tn\u3009 and Ds:\n1. Choose any i \u2208 {1, . . . , n}. 2. Set \u03c1\u0303 (ti) = 1 and \u03c1\u0303 (th) = 0 for h 6= i. 3. For j \u2208 {1, . . . , p}, set \u03c1\u0303 (sj) to the unique value required to satisfy Ds,j ;\nthis value is 1 iff i \u2208 Ij , and i \u2208 Ij iff \u03c1i (sj) = 1, so the required value is just \u03c1i (sj).\n1 and 2 construct all the ways of ensuring that \u3008t1, . . . , tn\u3009 is satisfied, and 3 then is the only way to finish defining \u03c1\u0303 that satisfies Ds.\nSimilarly, consider how to construct the set of truth assignments \u03c1\u0303 on S \u222a T that satisfy both X and Dt:\n1. Choose any i \u2208 {1, . . . , n}. Recall that \u03c1i is one of the truth assignments satisfying X. 2. For j \u2208 {1, . . . , p}, set \u03c1\u0303 (sj) = \u03c1i (sj). 3. For h \u2208 {1, . . . , n}, set \u03c1\u0303 (th) to the unique value required to satisfy Dt,h.\nThis is just \u03c1i JZhK, which is 1 for h = i and 0 for h 6= i. 1 and 2 construct all the ways of ensuring that X is satisfied, and 3 then is the only way to finish defining \u03c1\u0303 that satisfies Dt.\nBut these two sets of truth assignments are the same set! Therefore\nDs \u2227 \u3008t1, . . . , tn\u3009 \u2261 Dt \u2227X\nand so, by R1,\n(t1 \u2228 \u00b7 \u00b7 \u00b7 \u2228 tm | Dt \u2227X) = (t1 \u2228 \u00b7 \u00b7 \u00b7 \u2228 tm | Ds \u2227 \u3008t1, . . . , tn\u3009) . (5.3)\nStep 4. Using R2 we have\n(t1 \u2228 \u00b7 \u00b7 \u00b7 \u2228 tm | Ds \u2227 \u3008t1, . . . , tn\u3009) = (t1 \u2228 \u00b7 \u00b7 \u00b7 \u2228 tm | \u3008t1, . . . , tn\u3009) (5.4)\nsince the symbols s1, . . . , sp appear only on the left-hand-sides of the definitions in Ds.\nCombining (5.1)\u2013(5.4) yields the theorem."}, {"heading": "5.4. Additional consequences", "text": "In light of Lemma 6 we define the following:\nDefinition 7. For any n > 0 and 0 \u2264 m \u2264 n,\n\u03a52 (m,n) = (s1 \u2228 \u00b7 \u00b7 \u00b7 \u2228 sm | \u3008s1, . . . , sn\u3009) ,\nwhere s1, . . . , sn \u2208 S are n distinct propositional symbols.\nWe may then restate Lemma 6 as follows:\nCorollary 8. Let A \u2208 \u03a6 (S) and X \u2208 \u03a6+ (S) for some finite S \u2286 S. Then R1 and R2 together imply that\nA | X = \u03a52 (#S (A \u2227X) ,#S (X)) .\nProof. Let m = #S (A \u2227X) and n = #S (X) > 0. Choose any n symbols t1, . . . , tn \u2208 S disjoint from both \u03c3 JA,XK and the set of symbols {s1, . . . , sn} in the definition of \u03a52. Then two applications of Lemma 6 yields\nA | X = (t1 \u2228 \u00b7 \u00b7 \u00b7 \u2228 tm | \u3008t1, . . . , tn\u3009) = (s1 \u2228 \u00b7 \u00b7 \u00b7 \u2228 sm | \u3008s1, . . . , sn\u3009) = \u03a52(m,n).\nWe also obtain invariance under change of variables as an immediate consequence:\nCorollary 9. Let f be a change-of-variables transformation between (A,X) and (A\u2032, X \u2032). Then R1 and R2 together imply that\nA\u2032 | X \u2032 = A | X.\nProof. Let f map from truth assignments on S \u2287 \u03c3 JA,XK to truth assignments on S\u2032 \u2287 \u03c3 JA\u2032, X \u2032K. Then #S (X) = #S\u2032 (X \u2032) and #S (A \u2227X) = #S\u2032 (A\u2032 \u2227X \u2032); the result then follows from Corollary 8."}, {"heading": "6. Invariance under Addition of Irrelevant Information", "text": "Suppose we are interested in a problem domain whose concepts are represented by the propositional symbols in some set S. A formula Y containing no symbol from S tells us nothing about this domain; it is irrelevant information. Adding Y to the premise does not allow us to draw any new conclusions involving only symbols in S.\nSpecifically, let Y be a satisfiable formula having no symbols in common with X or A, and define Z = Y \u2227X. Then X |= A if and only if Z |= A, and consequently the implication orderings X and Z are identical on \u03a6 (S \\ \u03c3 JY K). We require the plausibility function to be invariant in the same way:\nR3. Let Y be a satisfiable formula with \u03c3 JX,AK \u2229 \u03c3 JY K = \u2205. Then A | X = A | Y \u2227X.\nAgain, one cannot evade the force of this Requirement by supposing a problem domain with a limited set of symbols, as discussed for R2. Furthermore, even if we were to associate a finite set of allowable symbols with each different problem domain, the notion of combining two unrelated problem domains into one would still make sense. Forbidding such a combining operation would be an artificial and unreasonable restriction, as one can already do this in CPL."}, {"heading": "6.1. Independence", "text": "The Requirements so far do not force A | X to be any sort of conditional probability; but if A | X is the conditional probability of A given X for some probability distribution, R3 implies that we don\u2019t come pre-supplied with dependencies between the atomic propositions. Any such dependencies have to be created by information in X. This is in line with our intention that the plausibility function be universal, one single function used in all problem domains, computed using no source of information other than the query and premise themselves, with any information needed to distinguish different problem domains required to be included in the premise.\nCarnap\u2019s proposed confirmation function c\u2217 in particular violates R3, as it imposes a probabilistic dependency between any two atomic sentences having the same predicate and the same number of distinct arguments. In particular, it is a violation of R3 that, for distinct individual constants a1, . . . , ak+1 and monadic predicate \u03c0, we have\nc\u2217 (\u03c0 (ak+1)) = 1\n2\nbut c\u2217 (\u03c0 (ak+1) | \u03c0 (a1) \u2227 \u00b7 \u00b7 \u00b7 \u2227 \u03c0 (ak)) \u2248 1 for large k.\nCarnap finds it necessary to introduce this dependency between atomic sentences to allow induction, but as we will show in Section 9.2, the problem arises only because he omits background information from the premise / evidence. Once the necessary background information is included in the premise there is no longer a violation of R3."}, {"heading": "6.2. Scale invariance of \u03a52", "text": "Suppose that S = \u03c3 JA,XK and T is obtained from S by adding r symbols not found in S. Then #T (X) = 2r \u00b7#S(X) and #T (A \u2227X) = 2r \u00b7#S (A \u2227X), from which we conclude that \u03a52 (2rm, 2rn) = \u03a52(m,n). Adding R3 allows us to extend this scale invariance to multipliers k that are not powers of 2, and hence to show that A | X is a function only of the ratio of #S (A \u2227X) to #S(X).\nLemma 10. Suppose that R1, R2, and R3 hold. Then for every n, k > 0 and 0 \u2264 m \u2264 n,\n\u03a52 (km, kn) = \u03a52 (m,n) .\nProof. Let S1 = {s11, . . . , s1n} and S2 = {s21, . . . , s2k} be two disjoint sets of propositional symbols. There are kn truth assignments on S1 \u222a S2 satisfying both \u3008s21, . . . , s2k\u3009 and \u3008s11, . . . , s1n\u3009, and km of these truth assignments also satisfy s11 \u2228 \u00b7 \u00b7 \u00b7 \u2228 s1m. Then\n\u03a52 (m,n) = (s11 \u2228 \u00b7 \u00b7 \u00b7 \u2228 s1m | \u3008s11, . . . , s1n\u3009) = (s11 \u2228 \u00b7 \u00b7 \u00b7 \u2228 s1m | \u3008s21, . . . , s2k\u3009 \u2227 \u3008s11, . . . , s1n\u3009) = \u03a52 (km, kn) .\nThe first and third equalities follows from Corollary 8. The second equality follows from R3, invariance under addition of irrelevant information.\nDefinition 11. For any n > 0 and 0 \u2264 m \u2264 n,\n\u03a51 (m n ) = \u03a52 (m,n) .\nLemma 10 ensures that \u03a51 (r) is uniquely defined for any rational r in the unit interval when the appropriate Requirements hold. We then obtain the following:\nCorollary 12. Let S \u2286 S be finite, A \u2208 \u03a6 (S), and X \u2208 \u03a6+(S). Then R1, R2, and R3 together imply that\nA | X = \u03a51 (\n#S (A \u2227X) #S (X)\n) .\nProof. Let m = #S (A \u2227X) and n = #S (X). From Corollary 8 and Lemma 10 we get\nA | X = \u03a52 (m,n) = \u03a51 (m/n) ."}, {"heading": "7. Preservation of Existing Distinctions in Degree of Plausibility", "text": "Our final requirement is that the plausibility function be consistent with the implication ordering for the premise. Strictly more plausible queries, according to the implication ordering, must yield strictly greater plausibility values.\nR4. There is a partial order \u2264P on P such that, for any satisfiable formula X, if A \u227aXB then A | X <P B | X.\nAs usual, we understand p1 <P p2 to mean p1 \u2264P p2 and p1 6= p2. The previous Requirements all have the effect of collapsing together what might otherwise be distinct plausibilities, but say nothing about when plausibilities must remain distinct from each other. They do not even rule out the possibility that all plausibilities collapse down to a single value. Adding R4 prevents any further collapse of plausibility values beyond that of Corollary 12, as we prove with Lemma 13 below."}, {"heading": "7.1. A too-simple plausibility function", "text": "Suppose that we choose the plausibility function to be a direct translation of the logical consequence relation, defining\nA | X =  F if X |= \u00acA T if X |= A u otherwise\nwith P = {F, u,T} and F <P u <P T. It is straightforward to verify that this definition satisfies R1, R2, and R3, by appealing to the corresponding properties of the logical equivalence relation |=. However, this definition violates R4, since R4 implies that P must be infinite.\nTo see this, suppose that P is finite. Choose n > |P| distinct symbols s1, . . . , sn and define\nX = n\u22121\u2227 i=1 (si \u2192 si+1) .\nThen s1 \u227aX s2 \u227aX \u00b7 \u00b7 \u00b7 \u227aX sn\nand R4 therefore mandates that\ns1 | X < s2 | X < \u00b7 \u00b7 \u00b7 < sn | X;\nbut this cannot be, as P contains fewer than n elements."}, {"heading": "7.2. Probability from plausibility", "text": "We proceed with the proof of our main result, starting with a lemma.\nLemma 13. If R1\u2013R4 hold then for all r, r\u2032 \u2208 Q01 , Q \u2229 [0, 1] we have\n\u03a51 (r) = \u03a51 (r \u2032)\u21d4 r = r\u2032 \u03a51 (r) <P \u03a5 (r \u2032)\u21d4 r < r\u2032.\nProof. We may express r and r\u2032 as ratios with a common denominator n > 0 as r = m/n and r\u2032 = m\u2032/n. Using R4 and writing X for \u3008s1, . . . , sn\u3009 we have\nr < r\u2032 \u21d2 m < m\u2032\n\u21d2 (s1 \u2228 \u00b7 \u00b7 \u00b7 \u2228 sm) \u227aX (s1 \u2228 \u00b7 \u00b7 \u00b7 \u2228 sm\u2032) \u21d2 \u03a51(r) <P \u03a51(r\u2032). (7.1)\nFurthermore, using antisymmetry of the partial order \u2264P and (7.1),\nr 6< r\u2032 \u21d2 (r = r\u2032) \u2228 (r\u2032 < r) \u21d2 \u03a51 (r\u2032) \u2264P \u03a51 (r) \u21d2 \u03a51 (r) 6<P \u03a51 (r\u2032) .\nTrivially, r = r\u2032 \u21d2 \u03a51 (r) = \u03a51 (r\u2032) .\nFurthermore, using (7.1) again,\nr 6= r\u2032 \u21d2 (r < r\u2032) \u2228 (r\u2032 < r) \u21d2 \u03a51 (r) 6= \u03a51 (r\u2032) .\nAnd now we arrive at the central result of this paper.\nTheorem 14. If R1\u2013R4 hold then\n1. \u03a51 is an order isomorphism between the posets (Q01,\u2264) and (P,\u2264P); 2. for all finite S \u2286 S, A \u2208 \u03a6(S), and X \u2208 \u03a6+(S) we have\nP (A | X) = #S (A \u2227X) #S(X) .\nwhere P = \u03a5\u221211 .\nProof. By Corollary 12, \u03a51 : Q01 \u2192 P is onto, and by Lemma 13, \u03a51 is a strictly increasing function (hence also one-to-one). So \u03a51 is an order-preserving bijection between Q01 and P, that is, it is an order isomorphism.\nSince \u03a51 is a bijection, its inverse P exists. The second claim is then just a restatement of Corollary 12.\nThe laws of probability follow directly from Theorem 14. In stating them it is convenient to extend the plausibility function to unsatisfiable premises using the convention that A | X = \u03a51(1), and hence P (A | X) = 1, when X is unsatisfiable. This may be justified by noting that for satisfiable X we have P (A | X) = 1 whenever X |= A, and when X is unsatisfiable we have X |= A for all formulas A.\nCorollary 15. If R1\u2013R4 hold and we define A | X = \u03a51(1) for unsatisfiable X, then\n1. 0 \u2264 P (A | X) \u2264 1. 2. P (A | X) = 1 if X |= A. 3. P (A | X) = 0 if X |= \u00acA and X is satisfiable. 4. P (\u00acA | X) = 1\u2212 P (A | X) if X is satisfiable. 5. P (A \u2227B | X) = P (B | X) \u00b7 P (A | B \u2227X).\nProof. (1)\u2013(4) are trivial, but (5) merits comment because care must be taken in handling unsatisfiable premises. There are three cases:\n1. If X is unsatisfiable then so is B \u2227X, and the claim reduces to 1 = 1 \u00b7 1. 2. If X is satisfiable but B \u2227X is not then X logically implies both \u00acB and \u00ac (A \u2227B), so P (B | X) = 0 and P (A \u2227B | X) = 0 and P (A | B \u2227X) = 1, and the claim reduces to 0 = 0 \u00b7 1. 3. If X and B \u2227X are both satisfiable, let S = \u03c3 JA,B,XK, n = #S(X) > 0, p = #S (B \u2227X) > 0, and m = #S (A \u2227B \u2227X); then\nP (A \u2227B | X) = m n = p n \u00b7 m p = P (B | X) \u00b7 P (A | B \u2227X) .\nTheorem 14 and Corollary 15 tell us that plausibilities are essentially just probabilities, following the classical definition of probability as the ratio of favorable cases to all cases. That is, our four Requirements, based entirely on preserving existing properties of CPL, lead us to identify finite-set probability theory as the uniquely determined extension of CPL to a logic of plausible reasoning."}, {"heading": "8. Consistency of Requirements", "text": "An issue that must be addressed for any axiomatic development is whether its content is vacuous by virtue of there not existing any mathematical structure satisfying the given axioms. If our Requirements are inconsistent\u2014if there does not exist any plausibility function (\u00b7 | \u00b7) for which the Requirements all hold\u2014then Theorem 14 is trivially true, and our entire exercise is pointless. We now show that this is not the case, by exhibiting a specific plausibility function that satisfies all the Requirements.\nTheorem 14 provides an obvious candidate for this plausibility function. However, that theorem (and the results leading up to it) cannot help in proving that the Requirements can be satisfied, as they are consequences of assuming that one already has some plausibility function satisfying the Requirements.\nTheorem 16. R1\u2013R4 are consistent. In particular, suppose that for any formula A and satisfiable formula X we define\nA | X = #T (A \u2227X) #T (X) ,\nwhere T = \u03c3 JA,XK; then R1\u2013R4 all hold. Proof. Consider any finite set of symbols S \u2287 T . If S contains k additional symbols beyond those in T then #S(X) = 2k#T (X) and #S (A \u2227X) = 2k#T (A \u2227X), hence\nA | X = #S (A \u2227X) #S (X) .\nThus we may use any superset of the symbols appearing in A and X when evaluating A | X.\nWe now consider each of the Requirements in turn. R1. LetX \u2261 Y and A \u2261XB and S = \u03c3 JA,B,X, Y K. Then #S(X) = #S(Y ) and #S (A \u2227X) = #S (B \u2227X) = #S (B \u2227 Y ), hence A | X = B | Y . R2. Let Y be (s\u2194 E) \u2227 X, where s is a propositional symbol not in S = \u03c3 JA,X,EK. Let S\u2032 = S \u222a{s}. Each truth assignment on S satisfying X can be extended to a truth assignment on S\u2032 satisfying Y in exactly one way, therefore #S\u2032(Y ) = #S(X). Likewise, #S\u2032 (A \u2227 Y ) = #S (A \u2227X). Hence A | Y = A | X.\nR3. Let S = \u03c3 JA,XK, S\u2032 = \u03c3 JY K, and T = S \u222a S\u2032. Since S and S\u2032 are disjoint, we have\n#T (Y \u2227X) = #S\u2032(Y )#S(X) #T (A \u2227 Y \u2227X) = #S\u2032(Y )#S (A \u2227X)\nand hence A | X = A | Y \u2227X. R4. Choose (P,\u2264P) to be (Q01,\u2264). Suppose that X is satisfiable and let S = \u03c3 JA,B,XK. If A \u227aX B then all truth assignments satisfying both A and X also satisfy B, and there is some truth assignment satisfying both B and X that does not satisfy A. Hence #S (A \u2227X) < #S (B \u2227X), yielding A | X < B | X."}, {"heading": "9. Discussion", "text": ""}, {"heading": "9.1. The classical definition of probability", "text": "The classical definition of probability goes back to Cardano in the mid 16th Century [4, Chapter 14]; perhaps its clearest statement was given by Laplace [15]:\nThe probability of an event is the ratio of the number of cases favorable to it, to the number of possible cases, when there is nothing to make us believe that one case should occur rather than any other, so that these cases are, for us, equally possible.\nThis definition fell out of favor with the rise of both frequentist and subjective interpretations of probability. Theorem 14 takes us back to the beginnings of probability theory, validating the classical definition and sharpening it. We can now say that a \u201cpossible case\u201d is simply a truth assignment satisfying the premise X. The phrase \u201cthese cases are, for us, equally possible,\u201d which arguably makes the definition circular, may simply be dropped as unnecessary. The phrase \u201cthere is nothing to make us believe that one case should occur rather than any other\u201d means that we possess no additional information that, if conjoined with our premise, would expand the satisfying truth assignments by differing multiplicities.\nWe shall illustrate this subtle but important point with Bertrand\u2019s \u201cBox Paradox\u201d [2]. There are three identical boxes in a row, each with two drawers. One of the boxes, call it GG, has gold coins in both drawers; one box, call it SS, has silver coins in both drawers; and the remaining box, call it GS, has a gold coin in one drawer and a silver coin in the other. Not knowing which is which, you open the first drawer of the second box, and observe that it contains a gold coin; what is the probability that the other drawer also holds a gold coin?\nThis problem is often resolved by appeal to Bayes\u2019 Rule, yielding a probability of 2/3. Let\u2019s apply Theorem 14 instead. A na\u00efve analysis, using only information about the second box itself, gives a probability of 1/2: the second box must be either GG or GS (two cases), and since the first drawer contains a gold coin, the second drawer also contains a gold coin only if the second box is GG (one case). But this ignores the (seemingly irrelevant) information we have about the first and third boxes. Table 1 gives an exhaustive list of all possible cases when the other boxes are included. We see that the case \u201csecond box is GS\u201d gets expanded into two cases, while the case \u201csecond box is GG\u201d gets expanded into four cases, thereby invalidating the na\u00efve analysis. Using the expanded table gives the correct answer of 2/3."}, {"heading": "D11 D12 D21 D22 D31 D32", "text": ""}, {"heading": "9.2. Uniform versus non-uniform probabilities", "text": "One concern about Theorem 14 may be that it mandates the uniform distribution on \u2126, the induced sample space of truth assignments satisfying the premise X. But what other reasonable option is there? Remember that the premise X contains all the information to which we have access in determining our probability distribution. There is no implicit third argument to the plausibility function that varies from one problem domain to another. \u2126 is just the reification of X as a set\u2014X tells us that one of the elements of \u2126 is the correct description of the situation, and that is all it tells us. It gives us no information by which we could favor one of these possibilities over another.\nYet non-uniform distributions are the norm in practical applications of probability theory, and one may ask where they come from. The \u201cBox Paradox\u201d example illustrates one answer: via marginalization. A uniform distribution at the finest level of granularity can correspond to a nonuniform distribution at coarser levels obtained by considering the induced sample space for some subset of the symbols in \u03c3 JA,XK.\nFor a more complete answer, let\u2019s consider Carnap\u2019s objection to the uniform distribution. He defines a confirmation function c\u2020 for LN based on a uniform distribution over state-descriptions, and notes that if a1, . . . , ak, ak+1 are distinct individual constants and \u03c0 is a monadic predicate (property), then\nc\u2020 (\u03c0 (ak+1) , \u03c0 (a1) \u2227 \u00b7 \u00b7 \u00b7 \u2227 \u03c0 (ak)) = 1\n2\nfor any k < N . He concludes [5, p. 565],\nThus the choice of c\u2020 as the degree of confirmation would be tantamount to the principle never to let our past experiences influence our expectations for the future.\nYet Carnap encounters this problem with c\u2020 for precisely the same reason that he cannot find a uniquely determined confirmation function. As Jaynes writes [13, p. 279],\nCarnap was seeking the general inductive rule (i.e., the rule by which, given the record of past results, one can make the best possible\nprediction of future ones). But. . . he never rises to the level of seeing that different inductive rules correspond to different prior information. It seems to us obvious. . . that this is the primary fact controlling induction, without which the problem cannot even be stated, much less solved; there is no \u2018general inductive rule.\u2019 Yet neither the term \u2018prior information\u2019 nor the concept ever appears in Carnap\u2019s exposition.\nThis prior information belongs in the premise, and Carnap chooses not to include it there, as discussed in Section 2.3 and Section 3.4.\nAs an example of such prior information, consider Carnap\u2019s proposed confirmation function c\u2217 and associated measure function m\u2217, for a language having a single monadic predicate \u03c0. Let us write xi for the atomic sentence \u03c0 (ai), where ai is the i-th individual constant. Then m\u2217 is equivalent to defining the joint distribution\n\u03b8 \u223c Uniform(0, 1) xi \u223c Bernoulli(\u03b8) independently for all i\nand marginalizing out \u03b8. That is, give \u03b8 a uniform distribution over the interval (0, 1), then independently give each xi a probability \u03b8 of being true.\nWe now construct a propositional formula that expresses an arbitarily close approximation of this prior information. Let I and K be large, positive integers. Consider the xi, 1 \u2264 i \u2264 I, as propositional symbols. Let hk, 0 \u2264 k \u2264 K, have the intended interpretation \u201c\u03b8 = k/K.\u201d Let us imagine that individual i may be in any of K distinct fine-grained states, and let sij , 1 \u2264 j \u2264 K, have the intended interpretation that individual i is in state j. Finally, define X to be the conjunction of the following (K2 +K + 1)I + 1 formulas:\n\u3008h0, . . . , hK\u3009 \u3008si1, . . . , siK\u3009 for 1 \u2264 i \u2264 I hk \u2227 sij \u2192 lijk for 1 \u2264 i \u2264 I, 1 \u2264 j \u2264 K, 0 \u2264 k \u2264 K\nwhere\nlijk = { xi if j \u2264 k \u00acxi if j > k.\nThat is, exactly one of the hk is true; for each i, exactly one of the sij is true; and if hk is true then each xi is true in k out of the K possible states for individual i. Using Theorem 14 we then have\nP (xi | hk \u2227X) = k/K for all i independently P (hk | X) = 1/ (k + 1) .\nThis illustrates the general lesson: non-uniform probabilities arise by introducing latent variables, including in the premise information that links the latent variables to observables, and then marginalizing out latent variables."}, {"heading": "9.3. Infinite domains", "text": "How might one extend these results to infinite domains, which are required for the bulk of practical applications of probability theory? Jaynes proposes a finite sets policy [13, p. 43]:\nIt is very important to note that our consistency theorems have been established only for probabilities assigned on finite sets of propositions. In principle, every problem must start with such finite-set probabilities; extension to infinite sets is permitted only when this is the result of a well-defined and well-behaved limiting process from a finite set.\nIn the same vein, he writes [13, p. 663],\nIn probability theory, it appears that the only safe procedure known at present is to derive our results first by strict application of the rules of probability theory on finite sets of propositions; then, after the finite-set result is before us, observe how it behaves as the number of propositions increases indefinitely.\nAs an example, consider P ( y < (1\u2212 x)2 | x, y \u2208 [0, 1) \u2227 y < x2 ) . We can con-\nsider this to be the limiting value of P (An | Xn) as n\u2192\u221e, where the queries An and premises Xn are defined as follows:\n1. Symbols ai and bi, for 1 \u2264 i \u2264 n, are intended to mean i \u2212 1 \u2264 nx < i and i\u2212 1 \u2264 ny < i respectively.\n2. Let An be \u2228 (i,j)\u2208K (ai \u2227 bj) where K = { (i, j) : j/n \u2264 (1\u2212 i/n)2 } .\n3. Let Xn be \u2228 (i,j)\u2208L (ai \u2227 bj) where L = { (i, j) : j/n \u2264 (i/n)2 } .\nFigure 9.1 illustrates Xn \u2227 An in black and Xn \u2227 \u00acAn in gray for n = 30. As n\u2192\u221e, An tends in the limit to the desired query \u201cy < (1\u2212 x)2\u201d and Xn tends in the limit to the desired premise \u201cy < x2,\u201d with x, y \u2208 [0, 1) implicit in the problem encoding.\nThough straightforward, it would be tedious to have to explicitly construct the limiting process and find the limiting value every time we considered a probability involving an infinite domain. Modern probability theory is based on measure theory, so it should be no surprise that measure theory provides the tools to automate this process of constructing a sequence of finite approximations that converge to a limit. We will not attempt to provide a full account of this large topic. By way of illustration, however, we will discuss one particularly simple case. We only sketch things out here; see Appendix Appendix A for more details.\nConsider the Cantor set of infinite binary sequences B\u03c9, where B = {0, 1}. Enumerating the elements of S as s1, s2, . . ., we can consider B\u03c9 to be the set of truth assignments on S if we identify a truth assignment \u03c1 with the infinite sequence w such that wi = \u03c1 (si) for all i. We write C and \u00b5C for the Borel\nFigure 9.1: Approximating P\n( y < (1\u2212 x)2 | y < x2 ) with n = 30\n\u03c3-algebra on B\u03c9 and Borel measure on C respectively, which may be considered a uniform distribution over B\u03c9. Defining\n[A] = {w \u2208 B\u03c9 : w satisfies A}\nfor any A \u2208 \u03a6 (S), and\nPr ( A\u0303; X\u0303, \u00b5 ) = \u00b5 ( A\u0303 \u2229 X\u0303 ) \u00b5 ( X\u0303 )\nfor any two measurable sets A\u0303, X\u0303 and measure \u00b5 with \u00b5 ( X\u0303 ) > 0, we find that\nP (A | X) = Pr ([A]; [X], \u00b5C) .\nFinally, Theorem 26 (Appendix Appendix A) states that for any measurable sets A\u0303, X\u0303 \u2208 C with \u00b5C ( X\u0303 ) > 0 there exists a sequence of formulas Ai \u2208 \u03a6 (S)\nand Xi \u2208 \u03a6+ (S) such that\n\u00b5C ( [Ai]4A\u0303 ) \u2192 0\n\u00b5C ( [Xi]4X\u0303 ) \u2192 0\nP (Ai | Xi)\u2192 Pr ( A\u0303; X\u0303, \u00b5C ) as i \u2192 \u221e, where 4 stands for set difference. That is, Jaynes\u2019s \u201cwell-defined and well-behaved limiting process\u201d is guaranteed to exist under the conditions of the Theorem, and Pr ( A\u0303; X\u0303, \u00b5C ) is the limiting probability.\nNow we turn to the space \u2126 = Bm \u00d7 [0, 1)n. We write D for the powerset of Bm (the maximal \u03c3-algebra on Bm) and define \u00b5D(A\u0303) = \u2223\u2223\u2223A\u0303\u2223\u2223\u2223 /2m for A\u0303 \u2208 D.\nWe write B and \u00b5B for the Borel \u03c3-algebra on [0, 1)n and Borel measure on B, respectively. Let A = \u03c3 (D \u00d7 B) be the product \u03c3-algebra of D and B, and let \u00b5A = \u00b5D \u00d7 \u00b5B be the product measure of \u00b5D and \u00b5B. The measure \u00b5A may be considered a uniform distribution over Bm\u00d7 [0, 1)n, with \u00b5A ( A\u0303\u00d7 B\u0303\n) being\u2223\u2223\u2223A\u0303\u2223\u2223\u2223 /2m times the n-dimensional hypervolume of B\u0303.\nThe set B\u22171\u03c9 of binary sequences ending in an infinite sequence of 1\u2019s is a measurable set of measure 0. Let us define I = B\u03c9 \\B\u22171\u03c9 to be all infinite binary sequences except this measure-0 set. Define the function f : I\u2192 \u2126 as\nf (w) = (f0(w), r (f1(w)) , . . . , r (fn(w)))\nf0(w) = w1 \u00b7 \u00b7 \u00b7wm fj(w) = v1v2 \u00b7 \u00b7 \u00b7 where vi = wm+\u03b9(i,j), for j 6= 0\nr(v) = \u221e\u2211 i=1 2\u2212ivi\n\u03b9(i, j) = j + (i\u2212 1)n.\nThat is, applying the mapping f amounts to interpreting symbol sm+\u03b9(i,j), for i \u2265 1 and 1 \u2264 j \u2264 n, as the i-th bit in the infinite binary expansion of xj \u2208 [0, 1), or more precisely, as the proposition \u201c \u230a 2ixj \u230b mod 2 = 1.\u201d We interleave n infinite sequences into one sequence by mapping index i of sequence j to index \u03b9(i, j) of the combined sequence. Using symbols sm+1 through sm+\u03b9(k,n) we can express any subspace of [0, 1)n at a granularity of hypercubes of length 2\u2212k on each side, and we can make this granularity as fine as desired by choosing k sufficiently large.\nThe function f is a bijection between I and \u2126. (We excluded B\u22171\u03c9 to ensure this, as dyadic rationals m/2n have two possible binary expansions.) Furthermore, both f and f\u22121 are measurable: f\u22121(A) \u2208 C and f\u22121(A) \u2286 I whenever A \u2286 A, and f(B) \u2208 A whenever B \u2208 C and B \u2286 I. Finally, f is measurepreserving: \u00b5C ( f\u22121(A) ) = \u00b5A (A) whenever A \u2208 A. This guarantees that\nPr ( A\u0303; X\u0303, \u00b5A ) = Pr ( f\u22121 ( A\u0303 ) ; f\u22121 ( X\u0303 ) , \u00b5C ) .\nTherefore, we can apply Theorem 26 and find that for any measurable sets A\u0303, X\u0303 \u2208 A with \u00b5A ( X\u0303 ) > 0 there exist sequences of formulas Ai and Xi, with\nXi satisfiable, such that\n\u00b5C ( [Ai]4f\u22121 ( A\u0303 )) \u2192 0\n\u00b5C ( [Xi]4f\u22121 ( X\u0303 )) \u2192 0\nP (Ai | Xi)\u2192 Pr ( A\u0303; X\u0303, \u00b5A ) as i\u2192\u221e.\nIn the example given at the beginning of this section, we have m = 0, n = 2, and\nA\u0303 = { (x, y) \u2208 [0, 1)2 : y < (1\u2212 x)2 }\nX\u0303 = { (x, y) \u2208 [0, 1)2 : y < x2 } .\nThe above results tell us that we don\u2019t need to explicitly construct the sequence of approximating formulas for this example; it is guaranteed to exist, and the limiting probability is\nPr ( A\u0303; X\u0303, \u00b5A ) =\n\u222b 1 0 min ( x2, (1\u2212 x)2 ) dx\u222b 1\n0 x2dx\n= 1\n4 .\nAs another example, let us revisit and generalize the inductive model described in Section 9.2:\n\u03b8 \u223c Distr (F ) xi \u223c Bernoulli(\u03b8) independently for all 1 \u2264 i \u2264 I\nwhere Distr(F ) is the distribution on the unit interval with cdf F , which we take to be continuous (and hence invertible). Doing a change of variables and augmenting with latent variables si, the above is equivalent to\np \u223c Uniform(0, 1) \u03b8 = F\u22121(p)\nsi \u223c Uniform(0, 1)\nxi = { 1 if si < \u03b8 0 otherwise\nafter marginalizing out p and s. We have independent uniform distributions on p and each si, plus equations relating each xi to p and si; hence the above is equivalent to using as premise the measurable set\nX\u0303 = { (x, p, s) \u2208 BI \u00d7 [0, 1)1+I : xi = 1\u21d4 si < F\u22121 (p) for all 1 \u2264 i \u2264 I } ,\nagain using the \u03c3-algebra A and measure \u00b5A, with m = I and n = I + 1. For any measurable A\u0303 we are again guaranteed that Pr ( A\u0303; X\u0303, \u00b5A ) is the limiting\nprobability obtained from a sequence of approximating formulas Ai and Xi. This is not a complete solution to handling infinite problem domains. For instance, in the example above we used BI (with finite I) instead of B\u03c9, because \u00b5A ( X\u0303 ) \u2192 0 as I \u2192 \u221e. In addition, the measure \u00b5C on C and encoding of\nreal numbers used above works well for a bounded interval like [0, 1) but does not suffice for unbounded intervals, such as all of R. For such cases we need alternative measures on C and corresponding analogs to Theorem 26, along with alternative encodings for these domains.\nOther work that remains to be done on this topic includes the following:\n1. Finding a general method of constructing the needed sequence of approximating formulas for any computable probability measure [10, 22].\n2. Extending our language of propositional formulas to express measurable sets beyond just the cylinder sets, while ensuring that P (A | X) remains computable, as is appropriate for a logical system.\nWe have made some initial investigations of these open issues and believe that they can be resolved."}, {"heading": "10. Conclusion", "text": "We have strengthened the case for probability theory as the uniquely determined extension of classical propositional logic to a logic of plausible reasoning. Our proof relies on a small and simple set of requirements such a logic must satisfy. These requirements are harder to dispute than those of previous such efforts because every one of the requirements is motivated by a desire to retain in our extended logic some property of CPL. A crucial distinction between our approach and similar previous work is that A | X depends only on the explicit arguments A and X, and not on any other domain-specific or problem-specific information; any such relevant information must be included in the premise X. This makes the plausibility function a legitimate analog of the logical consequence relation: the truth or falsity of X |= A likewise depends only on X and A, and not on any implicit domain-specific or problem-specific information.\nR2 (invariance under definition of new symbols) in conjunction with R1 (logical equivalence) turns out to have far-reaching implications. It yields invariance under renaming of propositional symbols and, in fact, a fully general invariance under change-of-variable transformations. Most importantly, it implies that A | X is a function only of #S (A \u2227X) and #S(X) for any S containing all the symbols used in A and X. R3 (invariance under addition of irrelevant information) excludes Carnap\u2019s system, which comes pre-supplied with dependencies between propositions rather than letting any dependencies be specified in the premise. Adding R3 implies that A | X is a function of the ratio of #S (A \u2227X) to #S(X).\nFinally, with R4 we made use of the underappreciated fact that CPL already comes equipped with an inherent plausibility ordering on propositions, for any given premise. The invariances of R1\u2013R3 \u201cstitch together\u201d these partial orderings for distinct premises, and we find that we have an order-preserving isomorphism P between the set of plausibilities P and the set of rational probabilities Q01. The numeric value we find for P (A | X) recreates the classical definition of probability, but in a sharper, clearer form with the troublesome circularity excised, and as a theorem rather than as a definition. The \u201cpossible cases\u201d are identified as truth assignments satisfying the premise, and the meaning of \u201cequally possible cases\u201d is simply that we have no additional information that would expand the satisfying truth assignments by differing multiplicities.\nWe addressed two possible concerns about our result: that it seems to allow only uniform probabilities, and that it yields probabilities only for finite\ndomains. We showed how non-uniform probabilities arise via the introduction of latent variables, along with information in the premise linking these latent variables to the observables. Following Jaynes, we proposed that probabilities for infinite domains be obtained via a well-defined and well-behaved limiting process, and demonstrated how measure theory can automate the construction of such limiting processes in at least some cases."}, {"heading": "Appendix A. Measure Theory", "text": ""}, {"heading": "Appendix A.1. Some results from measure theory", "text": "We assume the reader is already familiar with the basic concepts of measure theory: an algebra, a \u03c3-algebra, a measurable set, the \u03c3-algebra \u03c3(A) generated by an algebra A, a measurable function, a measure on an algebra or \u03c3-algebra, and a \u03c3-finite measure. Billingsley [3] and Tao [19] are good references. Here we highlight some results we will use.\nA measure on an algebra A can always be consistently extended to a measure on \u03c3 (A) [3, Theorem 11.3]:\nTheorem 17. If \u00b5 is a measure on an algebra A then \u00b5 extends to a measure on \u03c3 (A), that is, there exists a measure \u00b5\u2032 on \u03c3 (A) such that \u00b5(A) = \u00b5\u2032(A) for all A \u2208 A. If \u00b5 is \u03c3-finite then \u00b5\u2032 is unique, and is also \u03c3-finite.\nIn many cases of interest the elements of a \u03c3-algebra can be approximated arbitrarily closely by sets from the generating algebra [3, Theorem 11.4]:\nTheorem 18. If A is an algebra on \u2126, \u00b5 is a \u03c3-finite measure on \u03c3 (A), and B \u2208 \u03c3 (A) with \u00b5 (B) < \u221e, then for every > 0 there exists some A \u2208 A such that \u00b5 (A4B) < .\nWe use the following measure-related properties of set differences A4B, which we state without proof:\nProperty 19. For any measure \u00b5 on an algebra A and any A,B \u2208 A,\n|\u00b5(A)\u2212 \u00b5(B)| \u2264 \u00b5 (A4B) .\nProperty 20. For any measure \u00b5 on an algebra A and any A1, A2, X1, X2 \u2208 A,\n\u00b5 ((A1 \u2229X1)4 (A2 \u2229X2)) \u2264 \u00b5 (A14A2) + \u00b5 (X14X2) ."}, {"heading": "Appendix A.2. Constructing the \u201cwell-defined and well-behaved limiting process\u201d", "text": "To avoid confusion between propositional formulas and measurable sets, in this section we will generally decorate the names of measurable sets with a tilde (A\u0303, B\u0303, etc.) and leave the names of propositional formulas undecorated (A, B, etc.)\nThe Borel \u03c3-algebra and Borel measure for the Cantor set B\u03c9 are constructed as follows:\nDefinition 21. A cylinder set is a subset of B\u03c9 of the form cyl (n,C) , CB\u03c9 for some C \u2286 Bn. C0 is the collection of all cylinder sets. This set is an algebra, and the Borel \u03c3-algebra for B\u03c9 is C , \u03c3 (C0), the \u03c3-algebra generated by C0.\nCylinder sets are the basis of a topology on B\u03c9 in which the open sets are any finite or countable union of cylinder sets, and this is why we call C the Borel \u03c3-agebra for B\u03c9.\nDefinition 22. The Borel measure for C is the measure \u00b5C such that\n\u00b5C (cyl (n,C)) = 2 \u2212n |C|\nfor any n \u2265 0 and C \u2286 Bn.\nThe definition above is unambiguous because cyl(n,C) = cyl(n + m,C \u2032) if and only if C \u2032 = CBm. Note that \u00b5C is trivially \u03c3-finite, since B\u03c9 itself is a cylinder set and \u00b5C (B\u03c9) is finite. By Theorem 17 \u00b5C is uniquely defined once we define its value on cylinder sets.\nLet us enumerate the elements of S as s1, s2, . . . and identify a sequence w \u2208 B\u03c9 with the truth assignment \u03c1 on S such that \u03c1 (si) = wi for all i; then every propositional formula corresponds to a cylinder set:\nDefinition 23. If A is a propositional formula then [A] is the set of w \u2208 B\u03c9 that satisfy A (considered as truth assignments.)\nNote that [A] = cyl(n,C) and \u00b5C ([A]) = 2\u2212n#S(A), where \u03c3 JAK \u2286 S = {s1, . . . , sn} and C is the set of w \u2208 Bn that satisfy A. Likewise, every cylinder set corresponds to a propositional formula:\nLemma 24. For any cylinder set A\u0303 there is a formula A \u2208 \u03a6 (S) such that A\u0303 = [A].\nProof. Let A\u0303 = cyl (n,C) and define the propositional formula A as A = \u2228 c\u2208C Ac\nAc = n\u2227 i=1 Li,ci\nLi,0 = \u00acsi Li,1 = si\nIt is straightforward to see that [A] = A\u0303.\nWe can define an analog to P (A | X), but for measurable sets:\nDefinition 25. Let A be a \u03c3-algebra and \u00b5 a measure on A. For any A\u0303, X\u0303 \u2208 A with \u00b5 ( X\u0303 ) > 0, define\nPr ( A\u0303; X\u0303, \u00b5 ) = \u00b5 ( A\u0303 \u2229 X\u0303 ) \u00b5 ( X\u0303 ) .\nWe then find that\nP (A | X) = 2 \u2212n#S (A \u2227X) 2\u2212n#S (X) = Pr ([A]; [X], \u00b5C)\nwhere we choose n to be large enough that \u03c3 JA,XK \u2286 S = {s1, . . . , sn}. We use this fact to show that Jaynes\u2019s \u201cwell-defined and well-behaved limiting process\u201d is guaranteed to exist for measurable sets:\nTheorem 26. Let A\u0303, X\u0303 \u2208 C, with \u00b5C ( X\u0303 ) > 0. Then there exists a sequence\nof formulas Ai \u2208 \u03a6 (S) and Xi \u2208 \u03a6+ (S) such that 1. limi\u2192\u221e \u00b5C ( [Ai]4A\u0303 ) = 0.\n2. limi\u2192\u221e \u00b5C ( [Xi]4X\u0303 ) = 0.\n3. limi\u2192\u221e P (Ai | Xi) = Pr ( A\u0303; X\u0303, \u00b5C ) .\nProof. Let i, i \u2265 1 be any decreasing sequence of positive numbers whose limit is 0, with 1 < \u00b5C ( X\u0303 ) . Using Theorem 18 and Lemma 24 we can define\nAi = some A \u2208 \u03a6 (S) such that \u00b5C ( [A]4A\u0303 ) < i\nXi = some X \u2208 \u03a6 (S) such that \u00b5C ( [X]4X\u0303 ) < i\n1 and 2 in the theorem statement follow directly from these definitions. From Property 19 we have\u2223\u2223\u2223\u00b5C ([Xi])\u2212 \u00b5C (X\u0303)\u2223\u2223\u2223 \u2264 \u00b5C ([X]4X\u0303) < i < \u00b5C (X\u0303) and so \u00b5C ([Xi]) > 0, i.e., Xi is satisfiable. Property 19 also gives us\nlim i\u2192\u221e \u00b5C ([Xi]) = \u00b5C\n( X\u0303 ) .\nProperty 20 gives us\n\u00b5C ( [Ai \u2227Xi]4 ( A\u0303 \u2229 X\u0303 )) < 2 i\nand then Property 19 yields\nlim i\u2192\u221e\n\u00b5C ([Ai \u2227Xi]) = \u00b5C ( A\u0303 \u2229 X\u0303 ) .\nFinally we have\nlim i\u2192\u221e P (Ai | Xi) = lim i\u2192\u221e \u00b5C ([Ai \u2227Xi]) \u00b5C ([Xi]) = \u00b5C\n( A\u0303 \u2229 X\u0303 ) \u00b5C ( X\u0303 ) = Pr(A\u0303; X\u0303, \u00b5C) ."}], "references": [{"title": "Lectures on Functional Equations and Their Applications", "author": ["J. Acz\u00e9l"], "venue": null, "citeRegEx": "1", "shortCiteRegEx": "1", "year": 1996}, {"title": "Probability and Measure, Third Edition", "author": ["P. Billingsley"], "venue": null, "citeRegEx": "3", "shortCiteRegEx": "3", "year": 1995}, {"title": "Logical Foundations of Probability (2nd edition)", "author": ["R. Carnap"], "venue": null, "citeRegEx": "5", "shortCiteRegEx": "5", "year": 1962}, {"title": "The Continuum of Inductive Methods", "author": ["R. Carnap"], "venue": null, "citeRegEx": "6", "shortCiteRegEx": "6", "year": 1952}, {"title": "Bridging the intuition gap in Cox\u2019s Theorem: A Jaynesian argument for universality.", "author": ["A. Clayton", "T. Waddington"], "venue": "International Journal of Approximate Reasoning", "citeRegEx": "7", "shortCiteRegEx": "7", "year": 2017}, {"title": "The philosophical significance of Cox\u2019s theorem.", "author": ["M. Colyvan"], "venue": "International Journal of Approximate Reasoning", "citeRegEx": "8", "shortCiteRegEx": "8", "year": 2004}, {"title": "Probability, frequency and reasonable expectation.", "author": ["R.T. Cox"], "venue": "American Journal of Physics", "citeRegEx": "9", "shortCiteRegEx": "9", "year": 1946}, {"title": "A computable approach to measure and integration theory.", "author": ["A. Edalat"], "venue": "Information and Computation", "citeRegEx": "10", "shortCiteRegEx": "10", "year": 2009}, {"title": "A Counterexample to Theorems of Cox and Fine.", "author": ["J.Y. Halpern"], "venue": "Journal of Artificial Intelligence Research", "citeRegEx": "11", "shortCiteRegEx": "11", "year": 1999}, {"title": "Technical addendum: Cox\u2019s Theorem revisited.", "author": ["J.Y. Halpern"], "venue": "Journal of Artificial Intelligence Research", "citeRegEx": "12", "shortCiteRegEx": "12", "year": 1999}, {"title": "Probability Theory: The Logic of Science", "author": ["E.T. Jaynes"], "venue": null, "citeRegEx": "13", "shortCiteRegEx": "13", "year": 2003}, {"title": "Notes on Logic and Set Theory (1st edition)", "author": ["P.T. Johnstone"], "venue": null, "citeRegEx": "14", "shortCiteRegEx": "14", "year": 1987}, {"title": "The Uncertain Reasoner\u2019s Companion: A Mathematical Perspective", "author": ["J.B. Paris"], "venue": null, "citeRegEx": "16", "shortCiteRegEx": "16", "year": 1994}, {"title": "Mathematics and Plausible Reasoning: Vol 2: Patterns of Plausible Inference", "author": ["G. P\u00f3lya"], "venue": null, "citeRegEx": "17", "shortCiteRegEx": "17", "year": 1954}, {"title": "Comments on constructing a logic of plausible inference: a guide to Cox\u2019s Theorem, by Kevin S", "author": ["G. Shafer"], "venue": "Van Horn.\u201d International Journal of Approximate Reasoning", "citeRegEx": "18", "shortCiteRegEx": "18", "year": 2004}, {"title": "An Introduction to Measure Theory. American Mathematical Society", "author": ["T. Tao"], "venue": null, "citeRegEx": "19", "shortCiteRegEx": "19", "year": 2011}, {"title": "Rational Descriptions, Decisions, and Designs", "author": ["M. Tribus"], "venue": null, "citeRegEx": "20", "shortCiteRegEx": "20", "year": 1969}, {"title": "Constructing a logic of plausible inference: a guide to Cox\u2019s Theorem.", "author": ["K.S. Van Horn"], "venue": "International Journal of Approximate Reasoning", "citeRegEx": "21", "shortCiteRegEx": "21", "year": 2003}, {"title": "Representations of measurable sets in computable measure theory.", "author": ["K. Weihrauch", "N.R. Tavana"], "venue": "Logical Methods in Computer Science", "citeRegEx": "22", "shortCiteRegEx": "22", "year": 2014}], "referenceMentions": [{"referenceID": 13, "context": "This view is grounded in the work of P\u00f3lya [17] and Cox [9], especially the latter.", "startOffset": 43, "endOffset": 47}, {"referenceID": 6, "context": "This view is grounded in the work of P\u00f3lya [17] and Cox [9], especially the latter.", "startOffset": 56, "endOffset": 59}, {"referenceID": 6, "context": "Whereas X |= A means that A (the conclusion) is a logical consequence of X (the premise), we write A | X for \u201cthe reasonable credibility of the proposition A (the query) when the proposition X (the premise) is known to be true\u201d (paraphrasing Cox [9].", "startOffset": 246, "endOffset": 249}, {"referenceID": 0, "context": "there is an order-preserving isomorphism P between the set of plausibility values P and the set of rational probabilities Q \u2229 [0, 1]; 2.", "startOffset": 126, "endOffset": 132}, {"referenceID": 6, "context": "Cox [9] proposes a handful of intuitively-appealing, qualitative requirements for any system of plausible reasoning, and shows that these requirements imply that any such system is just probability theory in disguise.", "startOffset": 4, "endOffset": 7}, {"referenceID": 0, "context": "interval [0, 1] such that A | X, after mapping from plausibilities to [0, 1], respects the laws of probability.", "startOffset": 9, "endOffset": 15}, {"referenceID": 0, "context": "interval [0, 1] such that A | X, after mapping from plausibilities to [0, 1], respects the laws of probability.", "startOffset": 70, "endOffset": 76}, {"referenceID": 0, "context": "Over the years Cox\u2019s arguments have been refined by others [1, 13, 16, 20, 21], making explicit some requirements that were only implicit in Cox\u2019s original presentation, and replacing some of the requirements with slightly less demanding assumptions than those used in Cox\u2019s original proof.", "startOffset": 59, "endOffset": 78}, {"referenceID": 10, "context": "Over the years Cox\u2019s arguments have been refined by others [1, 13, 16, 20, 21], making explicit some requirements that were only implicit in Cox\u2019s original presentation, and replacing some of the requirements with slightly less demanding assumptions than those used in Cox\u2019s original proof.", "startOffset": 59, "endOffset": 78}, {"referenceID": 12, "context": "Over the years Cox\u2019s arguments have been refined by others [1, 13, 16, 20, 21], making explicit some requirements that were only implicit in Cox\u2019s original presentation, and replacing some of the requirements with slightly less demanding assumptions than those used in Cox\u2019s original proof.", "startOffset": 59, "endOffset": 78}, {"referenceID": 16, "context": "Over the years Cox\u2019s arguments have been refined by others [1, 13, 16, 20, 21], making explicit some requirements that were only implicit in Cox\u2019s original presentation, and replacing some of the requirements with slightly less demanding assumptions than those used in Cox\u2019s original proof.", "startOffset": 59, "endOffset": 78}, {"referenceID": 17, "context": "Over the years Cox\u2019s arguments have been refined by others [1, 13, 16, 20, 21], making explicit some requirements that were only implicit in Cox\u2019s original presentation, and replacing some of the requirements with slightly less demanding assumptions than those used in Cox\u2019s original proof.", "startOffset": 59, "endOffset": 78}, {"referenceID": 17, "context": "One version of the requirements [21] may be summarized as follows:", "startOffset": 32, "endOffset": 36}, {"referenceID": 0, "context": "The set of plausibility triples (y1, y2, y3) where y1 = A1 | X, y2 = A2 | A1\u2227X, and y3 = A3 | A2 \u2227A1 \u2227X for some A1, A2, A3, and X, is dense in [0, 1].", "startOffset": 144, "endOffset": 150}, {"referenceID": 14, "context": "For example, Shafer [18] objects to C1, C3, and C5; Halpern [11, 12] questions C4; and Colyvan [8] objects to C2 on the basis that it presumes the law of the excluded middle.", "startOffset": 20, "endOffset": 24}, {"referenceID": 8, "context": "For example, Shafer [18] objects to C1, C3, and C5; Halpern [11, 12] questions C4; and Colyvan [8] objects to C2 on the basis that it presumes the law of the excluded middle.", "startOffset": 60, "endOffset": 68}, {"referenceID": 9, "context": "For example, Shafer [18] objects to C1, C3, and C5; Halpern [11, 12] questions C4; and Colyvan [8] objects to C2 on the basis that it presumes the law of the excluded middle.", "startOffset": 60, "endOffset": 68}, {"referenceID": 5, "context": "For example, Shafer [18] objects to C1, C3, and C5; Halpern [11, 12] questions C4; and Colyvan [8] objects to C2 on the basis that it presumes the law of the excluded middle.", "startOffset": 95, "endOffset": 98}, {"referenceID": 4, "context": "(Some variants [7, 13, 21] of Cox\u2019s Theorem allow X to be an undefined \u201cstate of information\u201d to which we may add additional propositional information.", "startOffset": 15, "endOffset": 26}, {"referenceID": 10, "context": "(Some variants [7, 13, 21] of Cox\u2019s Theorem allow X to be an undefined \u201cstate of information\u201d to which we may add additional propositional information.", "startOffset": 15, "endOffset": 26}, {"referenceID": 17, "context": "(Some variants [7, 13, 21] of Cox\u2019s Theorem allow X to be an undefined \u201cstate of information\u201d to which we may add additional propositional information.", "startOffset": 15, "endOffset": 26}, {"referenceID": 4, "context": "Clayton and Waddington: bridging the intution gap In a recent paper, Clayton and Waddington [7] seek to \u201cbridge the intuition gap\u201d in Cox\u2019s Theorem by proposing alternative requirements they argue are more intuitively reasonable, and then proving C4 and the strictness of F in C5 as theorems.", "startOffset": 92, "endOffset": 95}, {"referenceID": 10, "context": "\u2022 Jaynes [13] argues that, if one\u2019s background information is \u201cindifferent\u201d between two propositions, then they should be assigned equal plausibility.", "startOffset": 9, "endOffset": 13}, {"referenceID": 2, "context": "Carnap: logical probability Carnap [5] undertakes an extensive investigation of \u201clogical probability.", "startOffset": 35, "endOffset": 38}, {"referenceID": 6, "context": "Unlike Cox [9], Carnap makes no attempt to derive the laws of probability from more fundamental considerations; instead, his \u201cconventions on adequacy\u201d [5, p.", "startOffset": 11, "endOffset": 14}, {"referenceID": 3, "context": "He later [5, Preface to Second Edition][6] proposes instead an entire family of confirmation functions c\u03bb parameterized by a positive number \u03bb.", "startOffset": 39, "endOffset": 42}, {"referenceID": 8, "context": "Halpern [11, 12] claims to demonstrate a counterexample to Cox\u2019s Theorem by examining a finite problem domain, but his argument presumes that there is a different plausibility function for every problem domain.", "startOffset": 8, "endOffset": 16}, {"referenceID": 9, "context": "Halpern [11, 12] claims to demonstrate a counterexample to Cox\u2019s Theorem by examining a finite problem domain, but his argument presumes that there is a different plausibility function for every problem domain.", "startOffset": 8, "endOffset": 16}, {"referenceID": 6, "context": "Others [9, 16] seem to presume a single plausibility function, but with domain-specific information serving as an implicit extra argument3.", "startOffset": 7, "endOffset": 14}, {"referenceID": 12, "context": "Others [9, 16] seem to presume a single plausibility function, but with domain-specific information serving as an implicit extra argument3.", "startOffset": 7, "endOffset": 14}, {"referenceID": 4, "context": "A third interpretation [7, 13, 21] presumes a single plausibility function with all relevant information about the problem domain encapsulated in the second argument, the \u201cstate of information.", "startOffset": 23, "endOffset": 34}, {"referenceID": 10, "context": "A third interpretation [7, 13, 21] presumes a single plausibility function with all relevant information about the problem domain encapsulated in the second argument, the \u201cstate of information.", "startOffset": 23, "endOffset": 34}, {"referenceID": 17, "context": "A third interpretation [7, 13, 21] presumes a single plausibility function with all relevant information about the problem domain encapsulated in the second argument, the \u201cstate of information.", "startOffset": 23, "endOffset": 34}, {"referenceID": 4, "context": "3 (translation invariance) [7], which they motivate via Jaynes\u2019s \u201cindifference\u201d criterion [13, p.", "startOffset": 27, "endOffset": 30}, {"referenceID": 0, "context": "If R1\u2013R4 hold then for all r, r\u2032 \u2208 Q01 , Q \u2229 [0, 1] we have \u03a51 (r) = \u03a51 (r \u2032)\u21d4 r = r\u2032 \u03a51 (r) <P \u03a5 (r \u2032)\u21d4 r < r\u2032.", "startOffset": 45, "endOffset": 51}, {"referenceID": 7, "context": "Finding a general method of constructing the needed sequence of approximating formulas for any computable probability measure [10, 22].", "startOffset": 126, "endOffset": 134}, {"referenceID": 18, "context": "Finding a general method of constructing the needed sequence of approximating formulas for any computable probability measure [10, 22].", "startOffset": 126, "endOffset": 134}, {"referenceID": 1, "context": "Billingsley [3] and Tao [19] are good references.", "startOffset": 12, "endOffset": 15}, {"referenceID": 15, "context": "Billingsley [3] and Tao [19] are good references.", "startOffset": 24, "endOffset": 28}], "year": 2017, "abstractText": "We consider the question of extending propositional logic to a logic of plausible reasoning, and posit four requirements that any such extension should satisfy. Each is a requirement that some property of classical propositional logic be preserved in the extended logic; as such, the requirements are simpler and less problematic than those used in Cox\u2019s Theorem and its variants. As with Cox\u2019s Theorem, our requirements imply that the extended logic must be isomorphic to (finite-set) probability theory. We also obtain specific numerical values for the probabilities, recovering the classical definition of probability as a theorem, with truth assignments that satisfy the premise playing the role of the \u201cpossible cases.\u201d", "creator": "LaTeX with hyperref package"}}}