{"id": "1706.10268", "review": {"conference": "nips", "VERSION": "v1", "DATE_OF_SUBMISSION": "30-Jun-2017", "title": "SafetyNets: Verifiable Execution of Deep Neural Networks on an Untrusted Cloud", "abstract": "inference using deep resource information prove often desired. ibm cloud web healthcare is a very demanding medium. however, this raises and fundamental conflict of communication. how ends a partner be sure that some victim has completed inference correctly? even lazy cloud simulator might use a simpler but fully credible model because reduce its own computational load, or worse, also modify the inference results tailored to the client. organizations derive safetynets, new result termed promises more untrusted server ( the cloud ) typically provide a session with sufficiently correct sql proof proving the correctness of inference analyses that they represent regarding behalf of the client. so, safetynets develops web implements a specialized rational access ( ip ) analysis for rapid execution targeting a class of connected neural networks, mac. e., those that can be represented unlike arithmetic graphs. our empirical advantages on three - vertex four - connected deep neural networks demonstrate the reaction - time costs of safetynets for both our same browser simulation are marginal. safetynets simulate any incorrect computations of the expected network by integrating voice provider with theoretical gains, while achieving brush - of - not - art accuracy along the mnist digit recognition ( 35. 24 % ) and actual speech recognition tasks ( 75. 22 % ).", "histories": [["v1", "Fri, 30 Jun 2017 16:47:16 GMT  (101kb,D)", "http://arxiv.org/abs/1706.10268v1", null]], "reviews": [], "SUBJECTS": "cs.LG cs.CR", "authors": ["zahra ghodsi", "tianyu gu", "siddharth garg"], "accepted": true, "id": "1706.10268"}, "pdf": {"name": "1706.10268.pdf", "metadata": {"source": "CRF", "title": "SafetyNets: Verifiable Execution of Deep Neural Networks on an Untrusted Cloud", "authors": ["Zahra Ghodsi", "Tianyu Gu", "Siddharth Garg"], "emails": ["sg175}@nyu.edu"], "sections": [{"heading": "1 Introduction", "text": "Recent advances in deep learning have shown that multi-layer neural networks can achieve state-ofthe-art performance on a wide range of machine learning tasks. However, training and performing inference on neural networks can be computationally expensive. For this reason, several commercial vendors have begun offering \u201cmachine learning as a service\" (MLaaS) solutions that allow clients to outsource machine learning computations, both training and inference, to the cloud.\nWhile promising, the MLaaS model (and outsourced computing, in general) raises immediate security concerns, specifically relating to the integrity (or correctness) of computations performed by the cloud and the privacy of the client\u2019s data [15]. This paper focuses on the former, i.e., the question of integrity. Specifically, how can a client perform inference using a deep neural network on an untrusted cloud, while obtaining strong assurance that the cloud has performed inference correctly?\nIndeed, there are compelling reasons for a client to be wary of a third-party cloud\u2019s computations. For one, the cloud has a financial incentive to be \u201clazy.\" A lazy cloud might use a simpler but less accurate model, for instance, a single-layer instead of a multi-layer neural network, to reduce its computational costs. Further the cloud could be compromised by malware that modifies the results sent back to the client with malicious intent. For instance, the cloud might always mis-classify a certain digit in a digit recognition task, or allow unauthorized access to certain users in a face recognition based authentication system.\nThe security risks posed by cloud computing have spurred theoretical advances in the area of verifiable computing (VC) [19]. The idea is to enable a client to provably (and cheaply) verify that an untrusted server has performed computations correctly. To do so, the server provides to the client (in addition\nar X\niv :1\n70 6.\n10 26\n8v 1\n[ cs\n.L G\n] 3\n0 Ju\nn 20\nto the result of computation) a mathematical proof of the correctness of the result. The client rejects, with high probability, any incorrectly computed results (or proofs) provided by the server, while always accepting correct results (and corresponding proofs) 1. VC techniques aim for the following desirable properties: the size of the proof should be small, the client\u2019s verification effort must be lower than performing the computation locally, and the server\u2019s effort in generating proofs should not be too high.\nThe advantage of proof-based VC is that it provides unconditional, mathematical guarantees on the integrity of computation performed by the server. Alternative solutions for verifiable execution require the client to make trust assumptions that are hard for the client to independently verify. Trusted platform modules [7], for instance, require the client to place trust on the hardware manufacturer, and assume that the hardware is tamper-proof. Audits based on the server\u2019s execution time [14] require precise knowledge of the server\u2019s hardware configuration and assume, for instance, that the server is not over-clocked.\nClient (verifier)\nUntrusted Server\n(prover)digit=4 5\nchallenge 1\nresponse 1\nRandom Challenge\nVerify\nExecute Neural Network\nCompute Response\nchallenge n\nresponse n\n...\nRandom Challenge\nReject\nCompute Response\nInput Image\neject\nprover, and y is the neural network\u2019s classification output for each image in the batch. The prover performs the computation and sends the verifier a purported result y\u2032 (which is not equal to y if the prover cheats). The verifier and prover then engage in n rounds of interaction. In each round, the verifier sends the prover a randomly picked challenge, and the prover provides a response based on the IP protocol. The verifier accepts that y\u2032 is indeed equal to f(x) if it is satisfied with the prover\u2019s response in each round, and rejects otherwise.\nA major criticism of IP systems (and, indeed, all existing VC techniques) when used for verifying general-purpose computations is that the prover\u2019s overheads are large, often orders of magnitude more than just computing f(x) [19]. Recently, however, Thaler [17] showed that certain types of computations admit IP protocols with highly efficient verifiers and provers, which lays the foundations for the specialized IP protocols for deep neural networks that we develop in this paper.\nPaper Contributions. This paper introduces SafetyNets, a new (and to the best of our knowledge, the first) approach for verifiable execution of deep neural networks on untrusted clouds. Specifically, SafetyNets composes a new, specialized IP protocol for the neural network\u2019s activation layers with Thaler\u2019s IP protocol for matrix multiplication to achieve end-to-end verifiability, dramatically reducing the bandwidth costs versus a naive solution that verifies the execution of each layer of the neural network separately.\nSafetyNets applies to a certain class of neural networks that can be represented as arithmetic circuits that perform computations over finite fields (i.e., integers modulo a large prime p). Our implementation of SafetyNets addresses several practical challenges in this context, including the choice of the prime p, its relationship to accuracy of the neural network, and to the verifier and prover run-times.\nEmpirical evaluations on the MNIST digit recognition and TIMIT speech recognition tasks illustrate that SafetyNets enables practical, low-cost verifiable outsourcing of deep neural network execution without compromising classification accuracy. Specifically, the client\u2019s execution time is 8\u00d7-80\u00d7 lower than executing the network locally, the server\u2019s overhead in generating proofs is less than 5%, and the client/server exchange less than 8 KBytes of data during the IP protocol. SafetyNets\u2019s security guarantees ensure that a client can detect any incorrect computations performed by a malicious\n1Note that the SafetyNets is not intended to and cannot catch any inherent mis-classifications due to the model itself, only those that result from incorrect computations of the model by the server.\nserver with probability vanishingly close to 1. At the same time, SafetyNets achieves state-of-the-art classification accuracies of 99.4% and 75.22% on the MNIST and TIMIT datasets, respectively."}, {"heading": "2 Background", "text": "In this section, we begin by reviewing necessary background on IP systems, and then describe the restricted class of neural networks (those that can be represented as arithmetic circuits) that SafetyNets handles."}, {"heading": "2.1 Interactive Proof Systems", "text": "Existing IP systems proposed in literature [5, 9, 17, 18] use, at their heart, a protocol referred to as the sum-check protocol [13] that we describe here in some detail, and then discuss its applicability in verifying general-purpose computations expressed as arithmetic circuits.\nSum-check Protocol Consider a d-degree n-variate polynomial g(x1, x2, . . . , xn), where each variable xi \u2208 Fp (Fp is the set of all natural numbers between zero and p\u2212 1, for a given prime p) and g : Fnp \u2192 Fp. The prover P seeks to prove the following claim:\ny = \u2211\nx1\u2208{0,1} \u2211 x2\u2208{0,1} . . . \u2211 xn\u2208{0,1} g(x1, x2, . . . , xn) (1)\nthat is, the sum of g evaluated at 2n points is y. P and V now engage in a sum-check protocol to verify this claim. In the first round of the protocol, P sends the following unidimensional polynomial\nh(x1) = \u2211\nx2\u2208{0,1} \u2211 x3\u2208{0,1} . . . \u2211 xn\u2208{0,1} g(x1, x2, . . . , xn) (2)\nto V in the form of its coefficients. V checks if h(0) + h(1) = y. If yes, it proceeds, otherwise it rejects P\u2019s claim. Next, V picks a random value q1 \u2208 Fp and evaluates h(q1) which, based on Equation 2, yields a new claim:\nh(q1) = \u2211\nx2\u2208{0,1} \u2211 x3\u2208{0,1} . . . \u2211 xn\u2208{0,1} g(q1, x2, . . . , xn). (3)\nV now recursively calls the sum-check protocol to verify this new claim. By the final round of the sum-check protocol, P returns the value g(q1, q2, . . . , qn) and the V checks if this value is correct by evaluating the polynomial by itself. If so, V accepts the original claim in Equation 1, otherwise it rejects the claim. Lemma 2.1. [2] V rejects an incorrect claim by P with probability greater than (1\u2212 ) where = ndp is referred to as the soundness error.\nIPs for Verifying Arithmetic Circuits In their seminal work, Goldwasser et al. [9] demonstrated how sum-check can be used to verify the execution of arithmetic circuits using an IP protocol now referred to as GKR. An arithmetic circuit is a directed acyclic graph of computation over elements of a finite field Fp in which each node can perform either addition or multiplication operations (modulo p). While we refer the reader to [9] for further details of GKR, one important aspect of the protocol bears mention.\nGKR organizes nodes of an arithmetic circuit into layers; starting with the circuit inputs, the outputs of one layer feed the inputs of the next. The GKR proof protocol operates backwards from the circuit outputs to its inputs. Specifically, GKR uses sum-check to reduce the prover\u2019s assertion about the circuit output into an assertion about the inputs of the output layer. This assertion is then reduced to an assertion about the inputs of the penultimate layer, and so on. The protocol continues iteratively till the verifier is left with an assertion about the circuit inputs, which it checks on its own. The layered nature of GKR\u2019s prover aligns almost perfectly with the structure of a multi-layer neural network and motivates the use of an IP system based on GKR for SafetyNets."}, {"heading": "2.2 Neural Networks as Arithmetic Circuits", "text": "As mentioned before, SafetyNets applies to neural networks that can be expressed as arithmetic circuits. This requirement places the following restrictions on the neural network layers.\nQuadratic Activations The activation functions in SafetyNets must be polynomials with integer coefficients (or, more precisely, coefficients in the field Fp). The simplest of these is the elementwise quadratic activation function whose output is simply the square of its input. Other commonly used activation functions such as ReLU, sigmoid or softmax activations are precluded, except in the final output layer. Prior work has shown that neural networks with quadratic activations have the same representation power as networks those with threshold activations and can be efficiently trained [6, 12].\nSum Pooling Pooling layers are commonly used to reduce the network size, to prevent overfitting and provide translation invariance. SafetyNets uses sum pooling, wherein the output of the pooling layer is the sum of activations in each local region. However, techniques such as max pooling [10] and stochastic pooling [20] are not supported since max and divisions operations are not easily represented as arithmetic circuits.\nFinite Field Computations SafetyNets supports computations over elements of the field Fp, that is, integers in the range {\u2212p\u221212 , . . . , 0, . . . , p\u22121 2 }. The inputs, weights and all intermediate values computed in the network must lie in this range. Note that due to the use of quadratic activations and sum pooling, the values in the network can become quite large. In practice, we will pick large primes to support these large values. We note that this restriction applies to the inference phase only; the network can be trained with floating point inputs and weights. The inputs and weights are then re-scaled and quantized, as explained in Section 3.3, to finite field elements.\nWe note that the restrictions above are shared by a recently proposed technique, CryptoNets [8], that seeks to perform neural network based inference on encrypted inputs so as to guarantee data privacy. However, Cryptonets does not guarantee integrity and compared to SafetyNets, incurs high costs for both the client and server (see Section 4.3 for a comparison). Conversely, SafetyNets is targeted towards applications where integrity is critical, but does not provide privacy."}, {"heading": "2.3 Mathematical Model", "text": "An L layer neural network with the constraints discussed above can be modeled, without loss of generality, as follows. The input to the network is x \u2208 Fn0\u00d7bp , where n0 is the dimension of each input and b is the batch size. Layer i \u2208 [1, L] has ni output neurons2, and is specified using a weight matrix wi\u22121 \u2208 Fni\u00d7ni\u22121p , and biases bi\u22121 \u2208 Fnip .\nThe output of Layer i \u2208 [1, L], yi \u2208 Fni\u00d7bp is:\nyi = \u03c3quad(wi\u22121.yi\u22121 + bi\u221211 T ) \u2200i \u2208 [1, L\u2212 1]; yL = \u03c3out(wL\u22121.yL\u22121 + bL\u221211T ), (4)\nwhere \u03c3quad(.) is the quadratic activation function, \u03c3out(.) is the activation function of the output layer, and 1 \u2208 Fbp is the vector of all ones. We will typically use softmax activations in the output layer. We will also find it convenient to introduce the variable zi \u2208 Fni+1\u00d7bp defined as\nzi = wi.yi + bi1 T \u2200i \u2208 [0, L\u2212 1]. (5)\nThe model captures both fully connected and convolutional layers; in the latter case the weight matrix is sparse. Further, without loss of generality, all successive linear transformations in a layer, for instance sum pooling followed by convolutions, are represented using a single weight matrix.\nWith this model in place, the goal of SafetyNets is to enable the client to verify that yL was correctly computed by the server. We note that as in prior work [18], SafetyNets amortizes the prover and verifier costs over batches of inputs. If the server incorrectly computes the output corresponding to any input in a batch, the verifier rejects the entire batch of computations."}, {"heading": "3 SafetyNets", "text": "We now describe the design and implementation of our end-to-end IP protocol for verifying execution of deep networks. The SafetyNets protocol is a specialized form of the IP protocols developed by\n2The 0th layer is defined to be input layer and thus y0 = x.\nThaler [17] for verifying \u201cregular\" arithmetic circuits, that themselves specialize and refine prior work [5]. The starting point for the protocol is a polynomial representation of the network\u2019s inputs and parameters, referred to as a multilinear extension.\nMultilinear Extensions Consider a matrix w \u2208 Fn\u00d7np . Each row and column of w can be referenced using m = log2(n) bits, and consequently one can represent w as a function W : {0, 1}m \u00d7 {0, 1}m \u2192 Fp. That is, given Boolean vectors t,u \u2208 {0, 1}m, the function W (t,u) returns the element of w at the row and column specified by Boolean vectors t and u, respectively.\nA multi-linear extension of W is a polynomial function W\u0303 : Fmp \u00d7 Fmp \u2192 Fp that has the following two properties: (1) given vectors t,u \u2208 Fmp such that W\u0303 (t,u) =W (t,u) for all points on the unit hyper-cube, that is, for all t,u \u2208 {0, 1}m; and (2) W\u0303 has degree 1 in each of its variables. In the remainder of this discussion, we will use X\u0303 , Y\u0303i and Z\u0303i and W\u0303i to refer to multi-linear extensions of x, yi, zi, and wi, respectively, for i \u2208 [1, L]. We will also assume, for clarity of exposition, that the biases, bi are zero for all layers. The supplementary draft describes how biases are incorporated. Consistent with the IP literature, the description of our protocol refers to the client as the verifier and the server as the prover.\nProtocol Overview The verifier seeks to check the result yL provided by the prover corresponding to input x. Note that yL is the output of the final activation layer which, as discussed in Section 2.2, is the only layer that does not use quadratic activations, and is hence not amenable to an IP.\nInstead, in SafetyNets, the prover computes and sends zL\u22121 (the input of the final activation layer) as a result to the verifier. zL\u22121 has the same dimensions as yL and therefore this refinement has no impact on the server to client bandwidth. Furthermore, the verifier can easily compute yL = \u03c3out(zL\u22121) locally.\nNow, the verifier needs to check whether the prover computed zL\u22121 correctly. As noted by Vu et al. [18], this check can be replaced by a check on whether the multilinear extension of zL\u22121 is correctly computed at a randomly picked point in the field, with minimal impact on the soundness error. That is, the verifier picks two vectors, qL\u22121 \u2208 Flog(nL)p and rL\u22121 \u2208 Flog(b)p at random, evaluates Z\u0303L\u22121(qL\u22121, rL\u22121), and checks whether it was correctly computed using a specialized sum-check protocol for matrix multiplication due to Thaler [17] (described in Section 3.1).\nSince zL\u22121 depends on wL\u22121 and yL\u22121, sum-check yields assertions on the values of W\u0303L\u22121(qL\u22121, sL\u22121) and Y\u0303L\u22121(sL\u22121, rL\u22121), where sL\u22121 \u2208 Flog(nL\u22121)p is another random vector picked by the verifier during sum-check.\nW\u0303L\u22121(qL\u22121, sL\u22121) is an assertion about the weight of the final layer. This is checked by the verifier locally since the weights are known to both the prover and verifier. Finally, the verifier uses our specialized sum-check protocol for activation layers (described in Section 3.2) to reduce the assertion on Y\u0303L\u22121(sL\u22121, rL\u22121) to an assertion on Z\u0303L\u22122(qL\u22122, sL\u22122). The protocol repeats till it reaches the input layer and produces an assertion on X\u0303(s0, r0), the multilinear extension of the input x. The verifier checks this locally. If at any point in the protocol, the verifier\u2019s checks fail, it rejects the prover\u2019s computation. Next, we describe the sum-check protocols for matrix multiplication and activation that SafetyNets uses."}, {"heading": "3.1 Sum-check for Matrix Multiplication", "text": "Since zi = wi.yi (recall we assumed zero biases for clarity), we can check an assertion about the multilinear extension of zi evaluated at randomly picked points qi and ri by expressing Z\u0303i(qi, ri) as [17]:\nZ\u0303i(qi, ri) = \u2211\nj\u2208{0,1}log(ni) W\u0303i(qi, j).Y\u0303i(j, ri) (6)\nNote that Equation 6 has the same form as the sum-check problem in Equation 1. Consequently the sum-check protocol described in Section 2.1 can be used to verify this assertion. At the end of the sum-check rounds, the verifier will have assertions on W\u0303i which it checks locally, and Y\u0303i which is checked using the sum-check protocol for quadratic activations described in Section 3.2.\nThe prover run-time for running the sum-check protocol in layer i is O(ni(ni\u22121 + b)), the verifier\u2019s run-time is O(nini\u22121) and the prover/verifier exchange 4 log(ni) field elements."}, {"heading": "3.2 Sum-check for Quadratic Activation", "text": "In this step, we check an assertion about the output of quadratic activation layer i, Y\u0303i(si, ri), by writing it in terms of the input of the activation layer as follows:\nY\u0303i(si, ri) = \u2211\nj\u2208{0,1}log(ni),k\u2208{0,1}log(b) I\u0303(si, j)I\u0303(ri,k)Z\u0303\n2 i\u22121(j,k), (7)\nwhere I\u0303(., .) is the multilinear extension of the identity matrix. Equation 7 can also be verified using the sum-check protocol, and yields an assertion about Z\u0303i\u22121, i.e., the inputs to the activation layer. This assertion is in turn checked using the protocol described in Section 3.1.\nThe prover run-time for running the sum-check protocol in layer i is O(bni), the verifier\u2019s runtime is O(log(bni)) and the prover/verifier exchange 5 log(bni) field elements. This completes the theoertical description of the SafetyNets specialized IP protocol. Lemma 3.1. The SafetyNets verifier rejects incorrect computations with probability greater than (1\u2212 ) where = 3b \u2211L i=0 ni p is the soundness error.\nIn practice, with p = 261 \u2212 1 the soundness error < 1230 for practical network parameters and batch sizes."}, {"heading": "3.3 Implementation", "text": "The fact that SafetyNets operates only on elements in a finite field Fp during inference imposes a practical challenge. That is, how do we convert floating point inputs and weights from training into field elements, and how do we select the size of the field p?\nLet w\u2032i \u2208 Rni\u22121\u00d7ni and b\u2032i \u2208 Rni be the floating point parameters obtained from training for each layer i \u2208 [1, L]. We convert the weights to integers by multiplying with a constant \u03b2 > 1 and rounding, i.e., wi = b\u03b2w\u2032ie. We do the same for inputs with a scaling factor \u03b1, i.e., x = b\u03b1x\u2032e. Then, to ensure that all values in the network scale isotropically, we must set bi = b\u03b12 i\u22121 \u03b2(2\ni\u22121+1)b\u2032ie. While larger \u03b1 and \u03b2 values imply lower quantization errors, they also result in large values in the network, especially in the layers closer to the output. Similar empirical observations were made by the CryptoNets work [8]. To ensure accuracy the values in the network must lie in the range [\u2212p\u221212 , p\u22121 2 ]; this influences the choice of the prime p. On the other hand, we note that large primes increase the verifier and prover run-time because of the higher cost of performing modular additions and multiplications.\nAs in prior works [5, 17, 18], we restrict our choice of p to Mersenne primes since they afford efficient modular arithmetic implementations, and specifically to the primes p = 261 \u2212 1 and p = 2127 \u2212 1. For a given p, we explore and different values of \u03b1 and \u03b2 and use the validation dataset to the pick the ones that maximize accuracy while ensuring that the values in the network lie within [\u2212p\u221212 , p\u22121 2 ]."}, {"heading": "4 Empirical Evaluation", "text": "In this section, we present empirical evidence to support our claim that SafetyNets enables low-cost verifiable execution of deep neural networks on untrusted clouds without compromising classification accuracy."}, {"heading": "4.1 Setup", "text": "Datasets We evaluated SafetyNets on three classifications tasks. (1) Handwritten digit recognition on the MNIST dataset, using 50,000 training, 10,000 validation and 10,000 test images. (2) A more challenging version of digit recognition, MNIST-Back-Rand, an artificial dataset generated by inserting a random background into MNIST image [1]. The dataset has 10,000 training, 2,000\nvalidation and 50,000 test images. ZCA whitening is applied to the raw dataset before training and testing [4]. (3) Speech recognition on the TIMIT dataset, split into a training set with 462 speakers, a validation set with 144 speakers and a testing set with 24 speakers. The raw audio samples are pre-processed as described by [3]. Each example includes its preceding and succeeding 7 frames, resulting in a 1845-dimensional input in total. During testing, all labels are mapped to 39 classes [11] for evaluation.\nNeural Networks For the two MNIST tasks, we used a convolutional neural network same as [21] with 2 convolutional layers with 5 \u00d7 5 filters, a stride of 1 and a mapcount of 16 and 32 for the first and second layer respectively. Each convolutional layer is followed by quadratic activations and 2 \u00d7 2 sum pooling with a stride of 2. The fully connected layer uses softmax activation. We refer to this network as CNN-2-Quad. For TIMIT, we use a four layer network described by [3] with 3 hidden, fully connected layers with 2000 neurons and quadratic activations. The output layer is fully connected with 183 output neurons and softmax activation. We refer to this network as FcNN-3-Quad. Since quadratic activations are not commonly used, we compare the performance of CNN-2-Quad and FcNN-3-Quad with baseline versions in which the quadratic activations are replaced by ReLUs. The baseline networks are CNN-2-ReLU and FcNN-3-ReLU.\nThe hyper-parameters for training are selected based on the validation datasets. The Adam Optimizer is used for CNNs with learning rate 0.001, exponential decay and dropout probability 0.75. The AdaGrad optimizer is used for FcNNs with a learning rate of 0.01 and dropout probability 0.5. We found that norm gradient clipping was required for training the CNN-2-Quad and FcNN-3-Quad networks, since the gradient values for quadratic activations can become large.\nOur implementation of SafetyNets uses Thaler\u2019s code for the IP protocol for matrix multiplication [17] and our own implementation of the IP for quadratic activations. We use an Intel Core i7-4600U CPU running at 2.10 GHz for benchmarking."}, {"heading": "4.2 Classification Accuracy of SafetyNets", "text": "SafetyNets places certain restrictions on the activation function (quadratic) and requires weights and inputs to be integers (in field Fp). We begin by analyzing how (and if) these restrictions impact classification accuracy/error. Figure 2 compares training and test error of CNN-2-Quad/FcNN-3-Quad versus CNN-2-ReLU/FcNN-3-ReLU. For all three tasks, the networks with quadratic activations are competitive with networks that use ReLU activations. Further, we observe that the networks with quadratic activations appear to converge faster during training, possibly because their gradients are larger despite gradient clipping.\nNext, we used the scaling and rounding strategy proposed in Section 3.3 to convert weights and inputs to integers. Table 1 shows the impact of scaling factors \u03b1 and \u03b2 on the classification error and maximum values observed in the network during inference for MNIST-Back-Rand. The validation error drops as \u03b1 and \u03b2 are increased. On the other hand, for p = 261 \u2212 1, the largest value allowed is 1.35\u00d7 1018; this rules out \u03b1 and \u03b2 greater than 64, as shown in the table. For MNIST-Back-Rand, we pick \u03b1 = \u03b2 = 16 based on validation data, and obtain a test error of 4.67%. Following a similar methodology, we obtain a test error of 0.63% for MNIST (p = 261 \u2212 1) and 25.7% for TIMIT (p = 2127 \u2212 1). We note that SafetyNets does not support techniques such as Maxout [10] that have\ndemonstrated lower error on MNIST (0.45%). Ba et al. [3] report an error of 18.5% for TIMIT using an ensemble of nine deep neural networks, which SafetyNets might be able to support by verifying each network individually and performing ensemble averaging at the client-side.\n4.3 Verifier and Prover Run-times\n0.1\n1\n10\n100\n1000\n28 29 210 211 212\nR un\nni ng\nT im\ne (s\n)\nInput Batch Size\nFcNN-Quad-3 Exe Time Additional Prover Time Verifier Time\nverifier exchange less than 8 KBytes of data during the IP protocol for a batch size of 2048, which is negligible (less than 2%) compared to the bandwidth required to communicate inputs and outputs back and forth. In all settings, the soundness error , i.e., the chance that the verifier fails to detect incorrect computations by the server is less than 1230 , a negligible value. We note SafetyNets has significantly lower bandwidth costs compared to an approach that separately verifies the execution of each layer using only the IP protocol for matrix multiplication.\nA recent and closely related technique, CryptoNets [8], uses homomorphic encryption to provide privacy, but not integrity, for neural networks executing in the cloud. Since SafetyNets and CryptoNets target different security goals a direct comparison is not entirely meaningful. However, from the data presented in the CryptoNets paper, we note that the client\u2019s run-time for MNIST using a CNN similar to ours and an input batch size b = 4096 is about 600 seconds, primarily because of the high cost of encryptions. For the same batch size, the client-side run-time of SafetyNets is less than 10 seconds. From this rough comparison, it appears that integrity is a more practically achievable security goal than privacy."}, {"heading": "5 Conclusion", "text": "In this paper, we have presented SafetyNets, a new framework that allows a client to provably verify the correctness of deep neural network based inference running on an untrusted clouds. Building upon the rich literature on interactive proof systems for verifying general-purpose and specialized computations, we designed and implemented a specialized IP protocol tailored for a certain class of deep neural networks, i.e., those that can be represented as arithmetic circuits. We showed that placing these restrictions did not impact the accuracy of the networks on real-world classification tasks like digit and speech recognition, while enabling a client to verifiably outsource inference to the cloud at low-cost. For our future work, we will apply SafetyNets to deeper networks and extend it to address both integrity and privacy. There are VC techniques [16] that guarantee both, but typically come at higher costs."}], "references": [{"title": "Computational complexity: a modern approach", "author": ["S. Arora", "B. Barak"], "venue": "Cambridge University Press", "citeRegEx": "2", "shortCiteRegEx": null, "year": 2009}, {"title": "Do deep nets really need to be deep? In Advances in neural information processing systems", "author": ["J. Ba", "R. Caruana"], "venue": "pages 2654\u20132662", "citeRegEx": "3", "shortCiteRegEx": null, "year": 2014}, {"title": "An analysis of single-layer networks in unsupervised feature learning", "author": ["A. Coates", "A. Ng", "H. Lee"], "venue": "Proceedings of the fourteenth international conference on artificial intelligence and statistics, pages 215\u2013223", "citeRegEx": "4", "shortCiteRegEx": null, "year": 2011}, {"title": "Verifying computations with streaming interactive proofs", "author": ["G. Cormode", "J. Thaler", "K. Yi"], "venue": "Proceedings of the VLDB Endowment, pages 25\u201336", "citeRegEx": "5", "shortCiteRegEx": null, "year": 2011}, {"title": "Globally optimal training of generalized polynomial neural networks with nonlinear spectral methods", "author": ["A. Gautier", "Q.N. Nguyen", "M. Hein"], "venue": "pages 1687\u20131695", "citeRegEx": "6", "shortCiteRegEx": null, "year": 2016}, {"title": "Non-interactive verifiable computing: Outsourcing computation to untrusted workers", "author": ["R. Gennaro", "C. Gentry", "B. Parno"], "venue": "Annual Cryptology Conference, pages 465\u2013482", "citeRegEx": "7", "shortCiteRegEx": null, "year": 2010}, {"title": "Cryptonets: Applying neural networks to encrypted data with high throughput and accuracy", "author": ["R. Gilad-Bachrach", "N. Dowlin", "K. Laine", "K. Lauter", "M. Naehrig", "J. Wernsing"], "venue": "pages 201\u2013210", "citeRegEx": "8", "shortCiteRegEx": null, "year": 2016}, {"title": "Delegating computation: interactive proofs for muggles", "author": ["S. Goldwasser", "Y.T. Kalai", "G.N. Rothblum"], "venue": "Proceedings of the fortieth annual ACM symposium on Theory of computing, pages 113\u2013122", "citeRegEx": "9", "shortCiteRegEx": null, "year": 2008}, {"title": "Maxout networks", "author": ["I.J. Goodfellow", "D. Warde-Farley", "M. Mirza", "A. Courville", "Y. Bengio"], "venue": "arXiv preprint arXiv:1302.4389", "citeRegEx": "10", "shortCiteRegEx": null, "year": 2013}, {"title": "Speaker-independent phone recognition using hidden markov models", "author": ["K.-F. Lee", "H.-W. Hon"], "venue": "IEEE Transactions on Acoustics, Speech, and Signal Processing, 37(11):1641\u20131648", "citeRegEx": "11", "shortCiteRegEx": null, "year": 1989}, {"title": "On the computational efficiency of training neural networks", "author": ["R. Livni", "S. Shalev-Shwartz", "O. Shamir"], "venue": "Advances in Neural Information Processing Systems, pages 855\u2013863", "citeRegEx": "12", "shortCiteRegEx": null, "year": 2014}, {"title": "Algebraic methods for interactive proof systems", "author": ["C. Lund", "L. Fortnow", "H. Karloff", "N. Nisan"], "venue": "Journal of the ACM (JACM), pages 859\u2013868", "citeRegEx": "13", "shortCiteRegEx": null, "year": 1992}, {"title": "Distributed execution with remote audit", "author": ["F. Monrose", "P. Wyckoff", "A.D. Rubin"], "venue": "NDSS, 99:3\u20135", "citeRegEx": "14", "shortCiteRegEx": null, "year": 1999}, {"title": "Towards the science of security and privacy in machine learning", "author": ["N. Papernot", "P. McDaniel", "A. Sinha", "M. Wellman"], "venue": "arXiv preprint arXiv:1611.03814", "citeRegEx": "15", "shortCiteRegEx": null, "year": 2016}, {"title": "Pinocchio: Nearly practical verifiable computation", "author": ["B. Parno", "J. Howell", "C. Gentry", "M. Raykova"], "venue": "Security and Privacy (SP), 2013 IEEE Symposium on, pages 238\u2013252. IEEE", "citeRegEx": "16", "shortCiteRegEx": null, "year": 2013}, {"title": "Time-optimal interactive proofs for circuit evaluation", "author": ["J. Thaler"], "venue": "Advances in Cryptology\u2013 CRYPTO 2013, pages 71\u201389", "citeRegEx": "17", "shortCiteRegEx": null, "year": 2013}, {"title": "A hybrid architecture for interactive verifiable computation", "author": ["V. Vu", "S. Setty", "A.J. Blumberg", "M. Walfish"], "venue": "Security and Privacy (SP), 2013 IEEE Symposium on, pages 223\u2013237", "citeRegEx": "18", "shortCiteRegEx": null, "year": 2013}, {"title": "Verifying computations without reexecuting them", "author": ["M. Walfish", "A.J. Blumberg"], "venue": "Communications of the ACM, 58(2):74\u201384", "citeRegEx": "19", "shortCiteRegEx": null, "year": 2015}, {"title": "Stochastic pooling for regularization of deep convolutional neural networks", "author": ["M.D. Zeiler", "R. Fergus"], "venue": "arXiv preprint arXiv:1301.3557", "citeRegEx": "20", "shortCiteRegEx": null, "year": 2013}, {"title": "Convexified convolutional neural networks", "author": ["Y. Zhang", "P. Liang", "M.J. Wainwright"], "venue": "arXiv preprint arXiv:1609.01000", "citeRegEx": "21", "shortCiteRegEx": null, "year": 2016}], "referenceMentions": [{"referenceID": 13, "context": "While promising, the MLaaS model (and outsourced computing, in general) raises immediate security concerns, specifically relating to the integrity (or correctness) of computations performed by the cloud and the privacy of the client\u2019s data [15].", "startOffset": 240, "endOffset": 244}, {"referenceID": 17, "context": "The security risks posed by cloud computing have spurred theoretical advances in the area of verifiable computing (VC) [19].", "startOffset": 119, "endOffset": 123}, {"referenceID": 5, "context": "Trusted platform modules [7], for instance, require the client to place trust on the hardware manufacturer, and assume that the hardware is tamper-proof.", "startOffset": 25, "endOffset": 28}, {"referenceID": 12, "context": "Audits based on the server\u2019s execution time [14] require precise knowledge of the server\u2019s hardware configuration and assume, for instance, that the server is not over-clocked.", "startOffset": 44, "endOffset": 48}, {"referenceID": 3, "context": "The work in this paper leverages powerful VC techniques referred to as interactive proof (IP) systems [5, 9, 17, 18].", "startOffset": 102, "endOffset": 116}, {"referenceID": 7, "context": "The work in this paper leverages powerful VC techniques referred to as interactive proof (IP) systems [5, 9, 17, 18].", "startOffset": 102, "endOffset": 116}, {"referenceID": 15, "context": "The work in this paper leverages powerful VC techniques referred to as interactive proof (IP) systems [5, 9, 17, 18].", "startOffset": 102, "endOffset": 116}, {"referenceID": 16, "context": "The work in this paper leverages powerful VC techniques referred to as interactive proof (IP) systems [5, 9, 17, 18].", "startOffset": 102, "endOffset": 116}, {"referenceID": 17, "context": "A major criticism of IP systems (and, indeed, all existing VC techniques) when used for verifying general-purpose computations is that the prover\u2019s overheads are large, often orders of magnitude more than just computing f(x) [19].", "startOffset": 225, "endOffset": 229}, {"referenceID": 15, "context": "Recently, however, Thaler [17] showed that certain types of computations admit IP protocols with highly efficient verifiers and provers, which lays the foundations for the specialized IP protocols for deep neural networks that we develop in this paper.", "startOffset": 26, "endOffset": 30}, {"referenceID": 3, "context": "Existing IP systems proposed in literature [5, 9, 17, 18] use, at their heart, a protocol referred to as the sum-check protocol [13] that we describe here in some detail, and then discuss its applicability in verifying general-purpose computations expressed as arithmetic circuits.", "startOffset": 43, "endOffset": 57}, {"referenceID": 7, "context": "Existing IP systems proposed in literature [5, 9, 17, 18] use, at their heart, a protocol referred to as the sum-check protocol [13] that we describe here in some detail, and then discuss its applicability in verifying general-purpose computations expressed as arithmetic circuits.", "startOffset": 43, "endOffset": 57}, {"referenceID": 15, "context": "Existing IP systems proposed in literature [5, 9, 17, 18] use, at their heart, a protocol referred to as the sum-check protocol [13] that we describe here in some detail, and then discuss its applicability in verifying general-purpose computations expressed as arithmetic circuits.", "startOffset": 43, "endOffset": 57}, {"referenceID": 16, "context": "Existing IP systems proposed in literature [5, 9, 17, 18] use, at their heart, a protocol referred to as the sum-check protocol [13] that we describe here in some detail, and then discuss its applicability in verifying general-purpose computations expressed as arithmetic circuits.", "startOffset": 43, "endOffset": 57}, {"referenceID": 11, "context": "Existing IP systems proposed in literature [5, 9, 17, 18] use, at their heart, a protocol referred to as the sum-check protocol [13] that we describe here in some detail, and then discuss its applicability in verifying general-purpose computations expressed as arithmetic circuits.", "startOffset": 128, "endOffset": 132}, {"referenceID": 0, "context": "[2] V rejects an incorrect claim by P with probability greater than (1\u2212 ) where = nd p is referred to as the soundness error.", "startOffset": 0, "endOffset": 3}, {"referenceID": 7, "context": "[9] demonstrated how sum-check can be used to verify the execution of arithmetic circuits using an IP protocol now referred to as GKR.", "startOffset": 0, "endOffset": 3}, {"referenceID": 7, "context": "While we refer the reader to [9] for further details of GKR, one important aspect of the protocol bears mention.", "startOffset": 29, "endOffset": 32}, {"referenceID": 4, "context": "Prior work has shown that neural networks with quadratic activations have the same representation power as networks those with threshold activations and can be efficiently trained [6, 12].", "startOffset": 180, "endOffset": 187}, {"referenceID": 10, "context": "Prior work has shown that neural networks with quadratic activations have the same representation power as networks those with threshold activations and can be efficiently trained [6, 12].", "startOffset": 180, "endOffset": 187}, {"referenceID": 8, "context": "However, techniques such as max pooling [10] and stochastic pooling [20] are not supported since max and divisions operations are not easily represented as arithmetic circuits.", "startOffset": 40, "endOffset": 44}, {"referenceID": 18, "context": "However, techniques such as max pooling [10] and stochastic pooling [20] are not supported since max and divisions operations are not easily represented as arithmetic circuits.", "startOffset": 68, "endOffset": 72}, {"referenceID": 6, "context": "We note that the restrictions above are shared by a recently proposed technique, CryptoNets [8], that seeks to perform neural network based inference on encrypted inputs so as to guarantee data privacy.", "startOffset": 92, "endOffset": 95}, {"referenceID": 16, "context": "We note that as in prior work [18], SafetyNets amortizes the prover and verifier costs over batches of inputs.", "startOffset": 30, "endOffset": 34}, {"referenceID": 15, "context": "Thaler [17] for verifying \u201cregular\" arithmetic circuits, that themselves specialize and refine prior work [5].", "startOffset": 7, "endOffset": 11}, {"referenceID": 3, "context": "Thaler [17] for verifying \u201cregular\" arithmetic circuits, that themselves specialize and refine prior work [5].", "startOffset": 106, "endOffset": 109}, {"referenceID": 16, "context": "[18], this check can be replaced by a check on whether the multilinear extension of zL\u22121 is correctly computed at a randomly picked point in the field, with minimal impact on the soundness error.", "startOffset": 0, "endOffset": 4}, {"referenceID": 15, "context": "That is, the verifier picks two vectors, qL\u22121 \u2208 FL p and rL\u22121 \u2208 F p at random, evaluates Z\u0303L\u22121(qL\u22121, rL\u22121), and checks whether it was correctly computed using a specialized sum-check protocol for matrix multiplication due to Thaler [17] (described in Section 3.", "startOffset": 232, "endOffset": 236}, {"referenceID": 15, "context": "yi (recall we assumed zero biases for clarity), we can check an assertion about the multilinear extension of zi evaluated at randomly picked points qi and ri by expressing Z\u0303i(qi, ri) as [17]: Z\u0303i(qi, ri) = \u2211", "startOffset": 187, "endOffset": 191}, {"referenceID": 6, "context": "Similar empirical observations were made by the CryptoNets work [8].", "startOffset": 64, "endOffset": 67}, {"referenceID": 3, "context": "As in prior works [5, 17, 18], we restrict our choice of p to Mersenne primes since they afford efficient modular arithmetic implementations, and specifically to the primes p = 2 \u2212 1 and p = 2 \u2212 1.", "startOffset": 18, "endOffset": 29}, {"referenceID": 15, "context": "As in prior works [5, 17, 18], we restrict our choice of p to Mersenne primes since they afford efficient modular arithmetic implementations, and specifically to the primes p = 2 \u2212 1 and p = 2 \u2212 1.", "startOffset": 18, "endOffset": 29}, {"referenceID": 16, "context": "As in prior works [5, 17, 18], we restrict our choice of p to Mersenne primes since they afford efficient modular arithmetic implementations, and specifically to the primes p = 2 \u2212 1 and p = 2 \u2212 1.", "startOffset": 18, "endOffset": 29}, {"referenceID": 2, "context": "ZCA whitening is applied to the raw dataset before training and testing [4].", "startOffset": 72, "endOffset": 75}, {"referenceID": 1, "context": "The raw audio samples are pre-processed as described by [3].", "startOffset": 56, "endOffset": 59}, {"referenceID": 9, "context": "During testing, all labels are mapped to 39 classes [11] for evaluation.", "startOffset": 52, "endOffset": 56}, {"referenceID": 19, "context": "Neural Networks For the two MNIST tasks, we used a convolutional neural network same as [21] with 2 convolutional layers with 5 \u00d7 5 filters, a stride of 1 and a mapcount of 16 and 32 for the first and second layer respectively.", "startOffset": 88, "endOffset": 92}, {"referenceID": 1, "context": "For TIMIT, we use a four layer network described by [3] with 3 hidden, fully connected layers with 2000 neurons and quadratic activations.", "startOffset": 52, "endOffset": 55}, {"referenceID": 15, "context": "Our implementation of SafetyNets uses Thaler\u2019s code for the IP protocol for matrix multiplication [17] and our own implementation of the IP for quadratic activations.", "startOffset": 98, "endOffset": 102}, {"referenceID": 8, "context": "We note that SafetyNets does not support techniques such as Maxout [10] that have", "startOffset": 67, "endOffset": 71}, {"referenceID": 1, "context": "[3] report an error of 18.", "startOffset": 0, "endOffset": 3}, {"referenceID": 6, "context": "A recent and closely related technique, CryptoNets [8], uses homomorphic encryption to provide privacy, but not integrity, for neural networks executing in the cloud.", "startOffset": 51, "endOffset": 54}, {"referenceID": 14, "context": "There are VC techniques [16] that guarantee both, but typically come at higher costs.", "startOffset": 24, "endOffset": 28}], "year": 2017, "abstractText": "Inference using deep neural networks is often outsourced to the cloud since it is a computationally demanding task. However, this raises a fundamental issue of trust. How can a client be sure that the cloud has performed inference correctly? A lazy cloud provider might use a simpler but less accurate model to reduce its own computational load, or worse, maliciously modify the inference results sent to the client. We propose SafetyNets, a framework that enables an untrusted server (the cloud) to provide a client with a short mathematical proof of the correctness of inference tasks that they perform on behalf of the client. Specifically, SafetyNets develops and implements a specialized interactive proof (IP) protocol for verifiable execution of a class of deep neural networks, i.e., those that can be represented as arithmetic circuits. Our empirical results on threeand four-layer deep neural networks demonstrate the run-time costs of SafetyNets for both the client and server are low. SafetyNets detects any incorrect computations of the neural network by the untrusted server with high probability, while achieving state-of-the-art accuracy on the MNIST digit recognition (99.4%) and TIMIT speech recognition tasks (75.22%).", "creator": "LaTeX with hyperref package"}}}