{"id": "1708.00805", "review": {"conference": "ICML", "VERSION": "v1", "DATE_OF_SUBMISSION": "2-Aug-2017", "title": "Variational Generative Stochastic Networks with Collaborative Shaping", "abstract": "we develop an approach to modelling generative models based on unrolling a variational auto - analysis into a markov chain, substantially altering peptide chain's product using a technique inspired towards recent discussions allowing approximate bayesian techniques. we show that the global minimizer of any resulting objective then eliminated when the analytical formulation reproduces conditional dependency distribution. thereby enhance global control its frequency gradient of tree samples, this add a comprehensive term describing algebraic techniques used for overcoming certain types of policy search in evolutionary learning. we see analytic results highlighting learning mean and fuzzy approaches which overlap where our technique offers state - of - the - art skills, prove therefore useful from a qualitative point of view.", "histories": [["v1", "Wed, 2 Aug 2017 15:55:40 GMT  (4588kb,D)", "http://arxiv.org/abs/1708.00805v1", "Old paper, from ICML 2015"]], "COMMENTS": "Old paper, from ICML 2015", "reviews": [], "SUBJECTS": "cs.LG", "authors": ["philip bachman", "doina precup"], "accepted": true, "id": "1708.00805"}, "pdf": {"name": "1708.00805.pdf", "metadata": {"source": "META", "title": "Variational Generative Stochastic Networks with Collaborative Shaping", "authors": ["Philip Bachman", "Doina Precup"], "emails": ["PHIL.BACHMAN@GMAIL.COM", "DPRECUP@CS.MCGILL.CA"], "sections": [{"heading": "1. Introduction", "text": "Significant research effort has been directed towards developing models capable of effectively synthesizing samples from complicated distributions. We propose an approach to this problem whose goal is two-fold. We want to learn a distribution which is practically indistinguishable from the target distribution and we also want training, inference and sampling to be efficient. Our approach can be viewed as a class of Generative Stochastic Networks (GSNs) (Bengio et al., 2014). We show that any model trained with the walkback procedure (Bengio et al., 2013) is encompassed by our approach. Instead of using denoising autoencoders, we leverage recent variational methods for deep, directed generative models, e.g. (Kingma & Welling, 2014; Rezende et al., 2014; Mnih & Gregor, 2014), and build our approach starting from variational auto-encoders. By feeding the output of such an auto-encoder back into it-\nProceedings of the 32nd International Conference on Machine Learning, Lille, France, 2015. JMLR: W&CP volume 37. Copyright 2015 by the author(s).\nself, we construct a Markov chain whose stationary distribution provably (in the non-parametric, infinite-data limit) converges to the target distribution.\nAs an alternative to the walkback procedure for training GSNs, we propose an approach based on recent work in Approximate Bayesian Computation. We partner a generative model with a function approximator that estimates the log-density ratio between the model-generated distribution and the target distribution, in what can be seen as a collaborative alternative to the adversarial approaches in (Gutmann et al., 2014a;b; Goodfellow et al., 2014). We show that the global minimizer of the resulting objective (in the non-parametric, infinite-data limit) is achievable only when the model distribution matches the target distribution.\nTo control the model complexity, we introduce a regularization term close in spirit to reinforcement learning methods such as relative entropy policy search (Peters et al., 2010) and other approaches which depend on a notion of \u201cnatural system dynamics\u201d, e.g. (Todorov, 2009). Specifically, we re-weigh the standard KL(posterior || prior) term that appears in the variational free-energy. For a generative model p(x) = \u2211 z p(x|z)p(z), with latent variables z \u2208 Z , this approach provides a direct mechanism for trading complexity in p(x) against the ability to exactly reproduce the training distribution whenever most of the complexity in p(x) is captured by the latent variables. E.g. if p(x|z) is an isotropic Gaussian whose mean varies with z, but whose variance is the same for all z, restricting KL(p(z|x) || p(z)) to be small for all x forces p(x) to be approximately an isotropic Gaussian.\nOur models permit efficient generation of independent samples, efficient generation of sequences of samples representing \u201clocally-coherent\u201d random walks along the data manifold, and efficient evaluation of a variational lowerbound on the log-likelihood assigned to arbitrary inputs. We show that our approach produces models which significantly outperform the GSNs in (Bengio et al., 2014) and the adversarial networks in (Goodfellow et al., 2014) in terms of test-set log-likelihood and qualitative behavior.\nar X\niv :1\n70 8.\n00 80\n5v 1\n[ cs\n.L G\n] 2\nA ug\n2 01"}, {"heading": "2. Background", "text": "This section provides a summary of prior work on denoising auto-encoders and Generative Stochastic Networks, which constitute the basis of our model."}, {"heading": "2.1. Generalized Denoising Auto-encoders", "text": "In the Generalized Denoising Auto-encoder (DAE) framework (Bengio et al., 2013), one trains a reconstruction distribution p\u03b8(x|x\u0303) to match the conditional distribution P(x|x\u0303) implicit in an infinite set of pairs {(x1, x\u03031), ..., (xn, x\u0303n)} generated by drawing each xi \u2208 X from the target distribution D and then generating each x\u0303i \u2208 X by applying some stochastic corruption process q\u03c6(x\u0303|x) to xi. Given q\u03c6 and p\u03b8, where \u03b8 and \u03c6 denote parameters of the two distributions, one can construct a Markov chain over x \u2208 X by iteratively sampling a point xt from p\u03b8(xt|x\u0303t\u22121) and then sampling a point x\u0303t from q\u03c6(x\u0303t|xt). The chain is initialized at t = 0 by sampling x0 directly fromD and its transition operator T\u03b8(xt|xt\u22121) can be computed by marginalizing over x\u0303t\u22121.\nGiven a few small assumptions on the forms of q\u03c6 and p\u03b8, and the larger assumption that p\u03b8(x|x\u0303) provides a consistent estimator of P(x|x\u0303) as the number of training samples x \u223c D goes to infinity, it was shown in (Bengio et al., 2013) that the Markov chain constructed from the iterative process described above will be ergodic and have a stationary distribution \u03c0\u03b8 which matches D (i.e. \u2200x, \u03c0\u03b8(x) = D(x)). All of the discussion in (Bengio et al., 2013) assumed that both xi and x\u0303i for each training pair (xi, x\u0303i) were from the same space X , although this was not required for their proofs. The Generative Stochastic Network (GSN) framework (Bengio et al., 2014) thus made the jump of assuming a corruption process q\u03c6(zt|xt\u22121, zt\u22121). This extends the Generalized DAE framework by introducing a latent space Z 6= X , and by allowing the current latent state zt to depend on the previous latent state zt\u22121 (in addition to its dependence on the previous observable state xt\u22121). Figures 2 (a) and (b) illustrate the graphical models corresponding to Generalized DAEs and GSNs."}, {"heading": "2.2. Training with Walkback", "text": "A method called walkback training was proposed for Generalized DAEs in (Bengio et al., 2013) and used again for GSNs in (Bengio et al., 2014). The motivation for walkback training was to mitigate difficulties encountered in practical, finite-data settings, where many values for the latent variables z \u2208 Z that were rarely (if ever) visited during training would appear when sampling from the resulting Markov chain. The difficulties stem primarily from a desire to make the corruption process q\u03c6 induce a conditional distribution P(x|z) which is roughly unimodal over x given\nAlgorithm 1 Walkback for a General GSN Input: data sample x, corruptor q\u03c6, reconstructor p\u03b8 Initialize an empty training pair list Pxz = { } Set z\u0302 to some initial vector in Z . for i = 1 to kburn\u2212in do\nSample z\u030c from q\u03c6(z|x, z\u0302) then set z\u0302 to z\u030c. end for Set x\u0302 to x. for i = 1 to kroll\u2212out do\nSample z\u030c from q\u03c6(z|x\u0302, z\u0302) then set z\u0302 to z\u030c. Sample x\u030c from p\u03b8(x|z\u0302) then set x\u0302 to x\u030c. Add pair (x, z\u0302) to Pxz .\nend for Return: Pxz .\nany particular z (because this makes it easier to model with p\u03b8(x|z)), which fights against the possibility that D contains multiple well-separated modes (which would necessitate a relatively non-local corruption process, able to \u201ccarve out\u201d reliable paths between these modes during training).\nThe walkback procedure can be interpreted as a \u201cwrapper\u201d function which takes the corruption process q\u03c6 and the reconstruction distribution p\u03b8, and then samples from a process W(z|x; q\u03c6, p\u03b8) which procedurally generates a distribution over z \u2208 Z given any x \u2208 X , as shown in Alg. 1. For example, in the original GSN paper (Bengio et al., 2014), the reconstruction distribution p\u03b8(x|z) for a GSN which emulates Gibbs sampling in a Deep Boltzmann Machine was trained on pairs (x, z) sampled from the walkback process described in Alg 1. The returned set of pairs Pxz can be viewed as containing data (x, z\u0302) \u223c W(z|x; q\u03c6, p\u03b8), where W is specified procedurally rather than directly. The reconstruction distribution p\u03b8(x|z) is then trained to approximate the conditional Pxz(x|z) implicit in the pairs generated via Alg. 1."}, {"heading": "3. Simple Generative Stochastic Networks", "text": "We define a \u201cSimple GSN\u201d as any GSN in which the corruption process renders zt independent of zt\u22121 given xt\u22121. Simple GSNs thus represent the minimal, direct extension of Generalized DAEs to corruption processes that may produce outputs in a different space from their inputs. Fig. 1(c) shows the structure of a simple GSN based on iteratively sampling from a walkback process W(z|x; q\u03c6, p\u03b8) and a reconstruction distribution p\u03b8(x|z). The Simple GSN model is in fact quite general, and covers all GSNs trained with a walkback procedure. We now give versions of the theorems from (Bengio et al., 2013) modified for Simple GSNs, which show that training with enough data and with sufficiently powerful function approximators p\u03b8/q\u03c6 produces a Markov chain whose asymp-\ntotic distribution exists and matches the target distribution.\nTheorem 1. If p\u03b8(x|z) is a consistent estimator of the true conditional distribution P(x|z) and the transition operator T\u03b8(xt+1|xt) that samples zt from q\u03c6(zt|xt) and xt+1 from p\u03b8(xt+1|zt) defines an ergodic Markov chain, then as the number of examples used to train p\u03b8(x|z) goes to infinity (i.e. as p\u03b8(x|z) converges to P(x|z)), the asymptotic distribution of the Markov chain defined by T\u03b8 converges to the target distribution D.\nThe proof is a direct translation of the proof for Theorem 1 in (Bengio et al., 2013), but with zs replacing x\u0303s. Briefly, drawing an initial x from D and then sampling alternately from q\u03c6(z|x) and P(x|z) is equivalent to sampling from a Gibbs chain for the joint distribution over (xi, zi) generated by repeatedly sampling xi \u223c D and zi \u223c q\u03c6(z|xi). Ergodicity guarantees the existence of an asymptotic distribution for the Markov chain. Since p\u03b8(x|z) converges to the true P(x|z), the asymptotic distribution of the chain converges to the marginal distribution of x in the Gibbs chain, which is just D(x). Corollary 2. Let X be a set in which every pair of points is connected by a finite-length path contained in X . Suppose that for each x \u2208 X there exists a \u201cshell\u201d set Sx \u2286 X such that all paths between x and any point in X \\ Sx pass through some point in Sx whose shortest path to x has length > 0. Suppose that \u2200x\u2032 \u2208 Sx \u222a {x},\u2203zxx\u2032 such that q\u03c6(zxx\u2032 |x) > 0 and p\u03b8(x\u2032|zxx\u2032) > 0. Then, the Markov chain with transition operator T\u03b8(xt+1|xt) =\u2211 z p\u03b8(xt+1|z)q\u03c6(z|xt) is ergodic.\nProof. The chain is aperiodic because the assumptions imply that \u2200x,\u2203zxx such that q\u03c6(zxx|x) > 0 and p\u03b8(x|zxx) > 0, so T\u03b8(xt+1 = x|xt = x) > 0. To show that the chain is irreducible, note that by assumption, \u2200x\u2032 \u2208 Sx, T (xt+1 = x\u2032|xt = x) > 0. For any x\u2032 6\u2208 Sx, consider the short-\nest path from x to x\u2032 and note that \u2203y \u2208 Sx on this path such that the shortest path between x and y is > 0 and T\u03b8(xt+1 = y|xt = x) > 0. Hence, T (xt+1 = x\u2032|xt = x) > 0, as the path x \u2192 x\u2032 can be decomposed into a finite sequence of finite-length segments, each with nonzero transition probability. Because the chain is over a finite state space it is also positive recurrent. As the chain is aperiodic, irreducible, and positive recurrent, it is also ergodic.\nThe restricted dependency structure of Simple GSNs lets us avoid some complications faced by the proofs in (Bengio et al., 2014). Our proof of Corollary 2 also avoids reliance on an ball, which does not work correctly in discrete or discontinuous spaces, in which paths starting at x with length > may contain no \u201csegments\u201d overlapping with the set of all paths starting at x with length \u2264 . Training p\u03b8(x|z) for any GSN using samples generated by walkback as described in Algorithm 1 corresponds to training a Simple GSN built around the reconstruction distribution p\u03b8 and corruption processW(z|x; q\u03c6, p\u03b8). The key observation here is that the samples in Pxz generated by Algorithm 1 are obtained by relating multiple sampled latent variables z\u0302 back to the single observable variable x given as input. In order to train p\u03b8 to be consistent with the joint distribution over (x, z) pairs generated by the Markov chain constructed from p\u03b8 and q\u03c6(zt|xt\u22121, zt\u22121), it would actually be necessary to train p\u03b8 on pairs (xt\u22121, zt) generated by explicitly unrolling the chain. In Sec. 5 we present a mechanism based on Approximate Bayesian Computation that allows training p\u03b8 directly on the pairs (xt\u22121, zt) generated by unrolling a GSN\u2019s Markov chain and applying backpropagation through time (BPTT).\nWalkback can be viewed as an effective way to construct a more dispersed distribution over the latent space Z than\nwould be provided by the original corruption process q\u03c6. Though not explicitly stated in the existing work on GSNs, it seems that balancing between maximizing dispersion of the corruption process and the ease of modeling the reconstruction distribution p\u03b8 plays a role for GSNs analogous to balancing between minimizing the KL divergence KL(q\u03c6(z|x)||p(z)) and maximizing the expected conditional log-likelihood Ez\u223cq\u03c6(z|x) log p\u03b8(x|z) when training a generative model p\u03b8(x) with variational methods, or balancing between following the \u201cnatural dynamics\u201d of the system and optimizing reward in policy search (Peters et al., 2010; Todorov, 2009). The next section expands on this relation."}, {"heading": "4. Variational Simple GSNs", "text": "We now develop a Simple GSN which can efficiently generate \u201clocally-coherent\u201d random walks along the manifold described by the target distribution D, efficiently generate independent (approximate) samples from the target distributionD, and efficiently evaluate a lower-bound on the loglikelihood assigned by the model to arbitrary inputs. We do this by replacing the denoising auto-encoders in existing examples of Generalized DAEs and GSNs with variational auto-encoders (Kingma & Welling, 2014; Rezende et al., 2014), while reinterpreting the two competing terms in the variational free-energy F (see Eq. 2) as representing an explicit trade-off between the dispersion of q\u03c6(z|x) and the ease of modeling p\u03b8(x|z). Suppose that, in addition to p\u03b8(x|z) and q\u03c6(z|x), we also have access to a distribution p\u2217(z) over Z (which could be learned or fixed a priori). Given these three distributions, we can define the derived distribution p\u03b8(x; p\u2217) such that p\u03b8(x; p\u2217) = \u2211 z p\u03b8(x|z)p\u2217(z), and the variational freeenergyF(x; q\u03c6, p\u03b8, p\u2217), which provides an upper-bound on the negative log-likelihood of x \u2208 X under p\u03b8(x; p\u2217): F(x; q\u03c6, p\u03b8, p\u2217) = (1) = \u2212\n\u2211 z [q\u03c6(z|x) log p\u03b8(x|z)] + KL(q\u03c6(z|x)||p\u2217(z))\n\u2265 \u2212 log p\u03b8(x; p\u2217) (2) A step-by-step derivation is provided in the Appendix.\nGiven F(x; q\u03c6, p\u03b8, p\u2217), we can maximize a lower-bound on the expected log-likelihood of samples x \u223c D under the model p\u03b8(x; p\u2217) by minimizing:\nEx\u223cD F(x; q\u03c6, p\u03b8, p\u2217) = (3) Ex\u223cD [\nE z\u223cq\u03c6(z|x)\n[\u2212 log p\u03b8(x|z)] + KL(q\u03c6(z|x)||p\u2217(z)) ]\nIt is useful to compare this to the objective for Generalized DAEs, i.e. Eq. 4 in (Bengio et al., 2013):\nL(\u03b8) = E x\u223cD,x\u0303\u223cq\u03c6(z\u0303|z) [\u2212 log p\u03b8(x|x\u0303) + \u03bb\u2126(\u03b8, x, x\u0303)] (4)\nin which \u2126(\u03b8, x, x\u0303) is a regularization term for controlling the capacity of p\u03b8 when the number of available samples x \u223c D is finite. The basic training process for both Eq. 3 and 4 can be described as follows: draw a sample x \u223c D, apply a random corruption to get z/x\u0303 \u223c q\u03c6(\u00b7|x), then adjust the parameters to reduce \u2212 log p\u03b8(x|\u00b7) and an added regularization term. Training with walkback simply changes the x\u0303 \u223c q\u03c6(z\u0303|z) in Eq. 4 to x\u0303 \u223c W(x\u0303|x; p\u03b8, q\u03c6). We consider the objective in Eq. 3 from a GSN perspective and treat it as comprising two terms: a reconstruction error\u2212 log p\u03b8(x|\u00b7) and a dispersion maximization term KL(q\u03c6(\u00b7|x) || p\u2217). Based on a desire to keep q\u03c6 welldispersed for all x \u2208 X , and to keep the degree of the dispersion relatively consistent across x \u2208 X , we replace the basic KL term in Eq. 3 with the following:\n\u03bb ( KL(q\u03c6(\u00b7|x)||p\u2217) + \u03b3([KL(q\u03c6(\u00b7|x)||p\u2217)\u2212 K\u0304]+)2 ) , (5) in which K\u0304 = Ex\u223cX KL(q\u03c6(\u00b7|x)||p\u2217) and [\u00b7]+ indicates positive rectification, i.e. clamping all negative values to 0. This penalizes both the magnitude and variance of the per-example KL, while avoiding any pressure to increase KL. We make this modification to allow tighter control over the trade-off between reconstruction fidelity and dispersion of the corruption process. Although re-weighting the KL term in Eq. 3 may seem odd to those already familiar with variational methods, we emphasize that the freeenergy F(x; q\u03c6, p\u03b8, p\u2217) from Eq. 2 still provides a valid upper-bound on \u2212 log p\u03b8(x; p\u2217). The appendix provides further discussion of this variational free-energy."}, {"heading": "5. Collaborative Generative Networks", "text": "In this section we take a step back and present a general method for shaping the distribution G produced by a generative model g\u03b8 to be practically indistinguishable from a target distribution D. In Section 6 we combine this method with variational Simple GSNs to directly train unrolled Markov chains. The general approach of estimating the parameters of g\u03b8 to minimize some computable measure of dissimilarity between G and D is called Approximate Bayesian Computation. Examples of Approximate Bayesian Computation include spectral methods based on the \u201cmethod of moments\u201d, which learn the parameters of g\u03b8 so as to match some of the statistical moments of G to the corresponding moments observed in an empirical sample from D, and more recent approaches based on minimizing the ability of some classifier to distinguish between G and D (Gutmann et al., 2014a;b; Goodfellow et al., 2014). Motivated by the recent empirical success of this latter approach in training deep generative models (Goodfellow et al., 2014), we develop a related approach which offers improved stability and a simpler proof of correctness.\nWe define an objective for jointly optimizing a generator function g\u03b8 and a guide function f\u03c8 which shapes the distribution G produced by g\u03b8 to match a target distribution D. Our method can be interpreted as a collaboration between g\u03b8 and f\u03c8 , in contrast with the adversarial approach presented in (Goodfellow et al., 2014). It is based on optimizing a term which encourages f\u03c8 to approximate the log-density-ratio log D(x)G(x) for x \u2208 X while also using f\u03c8 as a guidance signal for redistributing the mass emitted by g\u03b8. Our objective comprises two parts: one optimized by f\u03c8 and the other optimized by g\u03b8. We show that g\u03b8 and f\u03c8 can simultaneously minimize their respective objectives if and only if \u2200x, G(x) = D(x) and f\u03c8(x) = log D(x)G(x) = 0. The objective Lf for f\u03c8 is the basic logistic regression loss for a binary classifier which assumes equal prior probability for the positive class D and the negative class G, i.e.:\nLf = E x\u223cD [b(f\u03c8(x))] + E x\u223cG [b(\u2212f\u03c8(x))] (6)\nwhere b(f) = log(exp(\u2212f) + 1) is the binomial deviance loss. The objective Lg for g\u03b8 is based on, e.g., a one-sided absolute value loss:\nLg = E x\u223cG [|f\u03c8(x)| \u00b7 I[f\u03c8(x) < 0]] (7)\nin which I[\u00b7] is a binary indicator function. Theorem 3. The objectives Lf and Lg are simultaneously optimized with respect to f\u03c8 and g\u03b8 if and only if \u2200x \u2208 X ,G(x) = D(x) and f\u03c8(x) = log D(x)G(x) = 0.\nProof. By definition of Lf , it is minimized w.r.t. f\u03c8 if and only if \u2200x, f\u03c8(x) = log D(x)G(x) (Hastie et al., 2008). If Lf is minimized w.r.t. f\u03c8 then we know furthermore that either \u2200x, f\u03c8(x) = log D(x)G(x) = 0 or \u2203x s.t. f\u03c8(x) = log D(x) G(x) > 0 and \u2203x\u2032 s.t. f\u03c8(x\u2032) = log D(x \u2032)\nG(x\u2032) < 0. The former situation results in Lg = 0. The latter situation results in Lg > 0, because |f\u03c8(x)| \u00b7 I[f\u03c8(x) < 0] \u2265 0 with equality only when f\u03c8(x) \u2265 0. Thus, whenever Lf is optimized w.r.t. f\u03c8 , Lg can obtain its minimum possible value of 0 if and only if \u2200x, D(x) = G(x).\nNote that this proof works for any Lg which involves an expectation (w.r.t. x \u223c G) over a quantity which is everywhere non-negative and equal to 0 if and only if f\u03c8(x) \u2265 0. We leave a detailed investigation of the relative merits of the various possible Lg for future work. The key characteristic that distinguishes our objective from (Goodfellow et al., 2014) is that, given a fixed guide function f\u03c8 , our objective for the generator g\u03b8 pushes the mass in over-dense regions of G towards zero-contours of f\u03b8 while leaving the mass in under-dense regions unmoved.\nIn contrast, the adversarial objective in (Goodfellow et al., 2014) drives all mass emitted by g\u03b8 towards local maxima of f\u03c8 . These local maxima will typically correspond to points in X , while the zero-contours sought by our objective will correspond to regions in X . We can also incorporate additional terms in Lg , under the restriction that the added terms are minimized when \u2200x, D(x) = G(x). E.g. moment matching terms for matching the mean and covariance of x \u223c G with those of x \u223c D can be included to help avoid the occasional empirical \u201ccollapses\u201d of G that were described in (Goodfellow et al., 2014)."}, {"heading": "6. Generating Random Walks on Manifolds", "text": "We now combine the variational Simple GSNs from Sec. 4 with the collaborative mechanism from Sec. 5. Our goal is to directly train the Markov chain constructed by unrolling the variational Simple GSN to produce locally-contiguous walks along the manifold of the target distributionD, and to have the asymptotic distribution of the chain approximate D. The collaborative mechanism described in Sec. 5 pairs a generator g\u03b8 with a guide function f\u03c8 . For the generator, we propose using a variational Simple GSN, which we unroll into a Markov chain by initializing with a sample x0 \u223c D and then repeatedly generating {x1, ..., xt, ..., xn} by sampling zt \u223c q\u03c6(z|xt) xt+1 \u223c p\u03b8(x|zt). In other words, we self-loop a variational auto-encoder by piping its output back into its input. The unrolled joint system is depicted in Fig. 2. In practice, we implement p\u03b8, q\u03c6 and the guide function f\u03c8 using neural networks, whose specific architectures are described further in Sec. 7."}, {"heading": "7. Experiments", "text": "We now present tests examining the behavior of our models on the MNIST and TFD datasets. We chose these datasets\nto allow direct comparison with (Bengio et al., 2014) and (Goodfellow et al., 2014).\nOur first tests with MNIST data examined the benefits of training using the unrolled collaborative mechanism in Fig. 2. We represented q\u03c6 and p\u03b8 using neural networks with two hidden layers of 1500 rectified-linear units and we set the latent space Z to R64. We used a Gaussian with identity covariance for the prior distribution p\u2217(x). The output layer of q\u03c6 produced two vectors in R64, one representing the mean of a Gaussian distribution over Z and the other representing the element-wise log-variances of the distribution. Given this q\u03c6/p\u2217, KL(q\u03c6(z|x)||p\u2217) was easy to compute analytically, and its gradients with respect to \u03c6 were readily available. We interpreted p\u03b8(x|z) as a factored Bernoulli distribution, with Rao-Blackwellisation over the possible binarizations of each x. I.e., the output layer of p\u03b8 produced a vector in R784, which was then passed through a sigmoid to get x\u0302. We minimized \u2212 log p\u03b8(x|z) = \u2212sum(x log x\u0302+ (1\u2212x) log(1\u2212 x\u0302)), where denotes element-wise multiplication and we sum the vector entries. The gradients of \u2212 log p\u03b8(x|z) w.r.t. \u03b8 were directly available, and we backpropped through sampling z \u223c q\u03c6(z|x) to get gradients w.r.t. \u03c6 using the techniques in (Kingma & Welling, 2014; Rezende et al., 2014).\nWe used a Maxout network (Goodfellow et al., 2013) with two hidden layers of 1200 units in 300 groups of 4 for the guide function f\u03c8 . For Lg in Eq. 7, we used a halfrectified elastic-net (Zou & Hastie, 2005), with the linear and quadratic parts weighted equally. We unrolled our chains for 6 steps. The distributions D and G for training f\u03c8 according to Eq. 6 were given by the MNIST training set and the xi emitted by the unrolled chains. We passed gradients through the unrolled computation graph via BPTT.\nWe performed model updates using gradients computed from mini-batches of 100 distinct examples from the training set, each of which was passed through the model for 5 samples from q\u03c6(z|x). We trained using plain SGD. We pre-trained p\u03b8 and q\u03c6 as a variational autoencoder (VAE) for 100k updates by running the model in Fig. 1(c) out to x1. After 100k VAE updates we \u201cforked\u201d the model into a \u201cmulti-step guided\u201d model and a \u201cone-step VAE\u201d model and performed a further 100k updates to each of the now-independent models. We implemented our models in Python using the THEANO library (Bergstra et al., 2010). Code implementing the models described in this paper is available online at: github.com/Philip-Bachman/ICML-2015. The code provides full details on learning rates and other hyperparameters.\nFig. 3 illustrates the significantly improved long-run sampling behavior of chains trained with unrolling. The chains in Fig. 3 start at the top left and run from left-to-right and top-to-bottom. The true samples from D used to initialize the chains are in the top-left corners of (a)/(b). We downsampled the samples emitted by these chains 5x for this figure. Training with unrolling and collaborative guidance allows the chain to continually generate clean samples while exhibiting rapid mixing between the modes of the target distribution. Without explicit unrolling during training, the chain can only perform a few steps before degrading into samples that are well-separated from the target distribution. Qualitatively, the samples generated by the model trained with collaboratively-guided unrolling compare favourably with those presented for GSNs in (Bengio et al., 2014).\nFor our second tests with the MNIST images, we used networks with roughly the same structure as in our first tests but we set Z to R50, we used 1000 units in each of the hidden layers in q\u03c6/p\u03b8, and we used a Gaussian reconstruction distribution p\u03b8(x|z). To effect this final change, we interpreted the vector produced by the output layer of p\u03b8 as the mean of a Gaussian distribution over X and we shared a single \u201cbias\u201d parameter across all z to model the elementwise log-variance of p\u03b8(x|z). We thus modeled the target distribution using an infinite mixture of isotropic Gaussians, with the mixture weights of each Gaussian fixed a priori and with their individual locations and shared scale adjusted to match the training data.\nFor Fig. 4(a)-(d), we trained a pair of models. We trained the first model with \u03bb = 4 and \u03b3 = 0.1 in Eq. 5. We refer to this model as ORK, for over-regularized KL. We trained the second model to minimize the basic free energy in Eq. 2. We refer to this model as VAR. As in our first MNIST experiments, we initialized each model with pretraining by running the model in Fig. 1(c) a single step. We performed 80k pre-training updates using mini-batches\nand SGD updates as described for our first experiments. We then performed another 120k updates by unrolling the chains for 6 steps following the graph in Fig. 2. The guide function f\u03c8 was trained as in our first experiments.\nFig. 4 illustrates interesting behaviors of the ORK and VAR models. We found that the ORK model with strong regularization on KL(q\u03c6(z|x)||p\u2217(z)) was able to significantly out-perform the VAR model according to the Gaussian Parzen density estimator (GPDE) test described in (Breuleux et al., 2011)1. On the test set, the best ORK model scored 265, which compares favorably to the 214 in (Bengio et al., 2014) and the 225 in (Goodfellow et al., 2014). The best VAR model scored 220. The peak performance by this metric occurred much earlier in training for the VAR model than for the ORK model. Using the same network architecture, but with \u03bb in Eq. 5 increased to 24, our approach achieved a score of 330 on the GPDE test.\nInterestingly, the GPDE log-likelihood bound began to decrease rapidly beyond a certain point in training. However, the variational bound continued to increase. Qualitatively, this behavior is clearly reflected in the samples shown in Fig. 4(d), which we drew directly from the models by sampling from their priors p\u2217(x). Samples generated from the ORK model remain reasonable throughout training, but eventually suffer on the GPDE bound due to excess \u201csharpness\u201d. Samples drawn from the VAE model after 150k updates, when the VAE model significantly outperforms the ORK model in terms of the variational bound, are hardly recognizable as handwritten digits. In effect, the model is concentrating its posterior mass, as given by q\u03c6(z|x), on increasingly small regions of Z , in exchange for significant reductions in the reconstruction cost \u2212 log p\u03b8(x|z). This seems to lead to most of the mass of p\u2217(z) falling on zs which have little or no mass under any of the q\u03c6(z|x). By forcing the q\u03c6(z|x) to be more dispersed over Z , our added KL terms in Eq. 5 help mitigate this issue, albeit at the cost of less precise reconstruction of any particular digit. The scatter plots in Fig. 4 illustrate the evolution of the GPDE/variational bounds over the course of training and the trade-off between reconstruction cost and posterior KL that is obtained by the ORK and VAR models.\nWe performed analogous tests with the TFD dataset, which comprises 48x48 grayscale images of frontal faces in various expressions. We made a few changes from the second set of MNIST tests. We expanded the hidden layers of the networks representing q\u03c6/p\u03b8 to 2000 rectified-linear units each and we expanded the latent space Z to R100. We pre-\n1Briefly, this test approximates the distribution of a generative model by drawing 10k samples from the model and then using those samples as the mixture means for a uniformly-weighted mixture of 10k Gaussians, with a shared isotropic variance selected for the mixture components based on a validation set\nprocessed the images to have pixel intensities in the range [0...1], as in (Bengio et al., 2014; Goodfellow et al., 2014). We extended the pre-training phase to 150k updates and the unrolled, collaboratively-guided phase was reduced to 60k updates. Interestingly, in these tests the ORK model did not suffer significantly in terms of the variational bound, while achieving dramatically improved performance on the GPDE bound. For comparison, best previous results on the GPDE bound for this dataset are 2050 (Goodfellow et al., 2014) and 2110 (Bengio et al., 2013). Our ORK model scored 2060 on the test set using a GPDE variance selected on the validation set. When we increased \u03bb for the ORK model from 5 to 30, the GPDE score increased to 2130."}, {"heading": "8. Discussion", "text": "We presented an approach for learning generative models belonging to a simple subset of GSNs, using variational auto-encoders as building blocks. We generated Markov chains by looping the output of these auto encoders back into the input, and trained them to generate random walks along a target manifold, based on feedback from a guide function trained to discriminate between samples emitted by the chain and samples drawn from the data manifold. A key conceptual contribution of our approach is that we run the generative process as an unrolled Markov chain according to its a natural dynamics, i.e. the same way we want to run it \u201cin the wild\u201d, and then correct differences between exhibited and desired behavior by providing direct feedback about their magnitude and location (instead of trying to force the behavior in some way during the generation process). The experimental evaluation demonstrates that this direct approach is beneficial in practice.\nIn the long run, we believe it will be interesting to focus on interpreting our method from a reinforcement learning point of view. In this case, the \u201cease of modeling\u201d the posterior distribution p(x|z) can be viewed as a reward to be maximized, and may be easily replaced or augmented with other sources of reward. The current approach of using back propagation through time for the training could also be replaced by more efficient methods based on eligibility traces. While we only considered generating random walks over manifolds in this paper, in future work we would like to apply our approach to modeling distributions over observed trajectories on manifolds, e.g., as seen in speech, video, motion capture, and other sequential data."}, {"heading": "Acknowledgements", "text": "Funding for this work was provided by NSERC. The authors would also like to thank the anonymous reviewers for providing helpful feedback."}], "references": [{"title": "Generalized denoising auto-encoders as generative models", "author": ["Bengio", "Yoshua", "Yao", "Li", "Alain", "Guillaume", "Vincent", "Pascal"], "venue": "In Advances in Neural Information Processing Systems (NIPS),", "citeRegEx": "Bengio et al\\.,? \\Q2013\\E", "shortCiteRegEx": "Bengio et al\\.", "year": 2013}, {"title": "A cpu and gpu math expression compiler", "author": ["J. Bergstra", "O. Breuleux", "F. Bastien", "P. Lamblin", "R. Pascanu", "G. Desjardins", "J. Turian", "D. Warde-Farley", "Bengio", "Y. Theano"], "venue": "In Python for Scientific Computing Conference (SciPy),", "citeRegEx": "Bergstra et al\\.,? \\Q2010\\E", "shortCiteRegEx": "Bergstra et al\\.", "year": 2010}, {"title": "Quickly generating representative samples from an rbmderived process", "author": ["Breuleux", "Olivier", "Bengio", "Yoshua", "Vincent", "Pascal"], "venue": "Neural Computation,", "citeRegEx": "Breuleux et al\\.,? \\Q2011\\E", "shortCiteRegEx": "Breuleux et al\\.", "year": 2011}, {"title": "Generative adversarial nets", "author": ["Goodfellow", "Ian J", "Pouget-Abadie", "Jean", "Mirza", "Mehdi", "Xu", "Bing", "Warde-Farley", "David", "Ozair", "Sherjil", "Courville", "Aaron", "Bengio", "Yoshua"], "venue": "In Advances in Neural Information Processing Systems (NIPS),", "citeRegEx": "Goodfellow et al\\.,? \\Q2014\\E", "shortCiteRegEx": "Goodfellow et al\\.", "year": 2014}, {"title": "Classifier abc", "author": ["Gutmann", "Michael U", "Dutta", "Ritabrata", "Kaski", "Samuel", "Corander", "Jukka"], "venue": "In MCMSki IV (posters),", "citeRegEx": "Gutmann et al\\.,? \\Q2014\\E", "shortCiteRegEx": "Gutmann et al\\.", "year": 2014}, {"title": "Likelihood-free inference via classification", "author": ["Gutmann", "Michael U", "Dutta", "Ritabrata", "Kaski", "Samuel", "Corander", "Jukka"], "venue": "In arXiv:1407.4981v1 [stat.CO],", "citeRegEx": "Gutmann et al\\.,? \\Q2014\\E", "shortCiteRegEx": "Gutmann et al\\.", "year": 2014}, {"title": "Elements of Statistical Learning II", "author": ["Hastie", "Trevor", "Friedman", "Jerome", "Tibshirani", "Robert"], "venue": null, "citeRegEx": "Hastie et al\\.,? \\Q2008\\E", "shortCiteRegEx": "Hastie et al\\.", "year": 2008}, {"title": "Auto-encoding variational bayes", "author": ["Kingma", "Diederik P", "Welling", "Max"], "venue": "In International Conference on Learning Representations (ICLR),", "citeRegEx": "Kingma et al\\.,? \\Q2014\\E", "shortCiteRegEx": "Kingma et al\\.", "year": 2014}, {"title": "Neural variational inference and learning", "author": ["Mnih", "Andriy", "Gregor", "Karol"], "venue": "In International Conference on Machine Learning (ICML),", "citeRegEx": "Mnih et al\\.,? \\Q2014\\E", "shortCiteRegEx": "Mnih et al\\.", "year": 2014}, {"title": "Relative entropy policy search", "author": ["Peters", "Jan", "Mulling", "Karen", "Altun", "Yasemin"], "venue": "In AAAI,", "citeRegEx": "Peters et al\\.,? \\Q2010\\E", "shortCiteRegEx": "Peters et al\\.", "year": 2010}, {"title": "Stochastic backpropagation and approximate inference in deep generative models", "author": ["Rezende", "Danilo", "Mohamed", "Shakir", "Wierstra", "Daan"], "venue": "In International Conference on Machine Learning (ICML),", "citeRegEx": "Rezende et al\\.,? \\Q2014\\E", "shortCiteRegEx": "Rezende et al\\.", "year": 2014}, {"title": "Efficient computation of optimal action", "author": ["Todorov", "Emanuel"], "venue": "Proceedings of the National Academy of Science (PNAS),", "citeRegEx": "Todorov and Emanuel.,? \\Q2009\\E", "shortCiteRegEx": "Todorov and Emanuel.", "year": 2009}, {"title": "Regularization and variable selection via the elastic net", "author": ["Zou", "Hui", "Hastie", "Trevor"], "venue": "Journal of the Royal Statistical Society, B.,", "citeRegEx": "Zou et al\\.,? \\Q2005\\E", "shortCiteRegEx": "Zou et al\\.", "year": 2005}], "referenceMentions": [{"referenceID": 0, "context": "We show that any model trained with the walkback procedure (Bengio et al., 2013) is encompassed by our approach.", "startOffset": 59, "endOffset": 80}, {"referenceID": 10, "context": "(Kingma & Welling, 2014; Rezende et al., 2014; Mnih & Gregor, 2014), and build our approach starting from variational auto-encoders.", "startOffset": 0, "endOffset": 67}, {"referenceID": 3, "context": "We partner a generative model with a function approximator that estimates the log-density ratio between the model-generated distribution and the target distribution, in what can be seen as a collaborative alternative to the adversarial approaches in (Gutmann et al., 2014a;b; Goodfellow et al., 2014).", "startOffset": 250, "endOffset": 300}, {"referenceID": 9, "context": "To control the model complexity, we introduce a regularization term close in spirit to reinforcement learning methods such as relative entropy policy search (Peters et al., 2010) and other approaches which depend on a notion of \u201cnatural system dynamics\u201d, e.", "startOffset": 157, "endOffset": 178}, {"referenceID": 3, "context": ", 2014) and the adversarial networks in (Goodfellow et al., 2014) in terms of test-set log-likelihood and qualitative behavior.", "startOffset": 40, "endOffset": 65}, {"referenceID": 0, "context": "In the Generalized Denoising Auto-encoder (DAE) framework (Bengio et al., 2013), one trains a reconstruc-", "startOffset": 58, "endOffset": 79}, {"referenceID": 0, "context": "Given a few small assumptions on the forms of q\u03c6 and p\u03b8, and the larger assumption that p\u03b8(x|x\u0303) provides a consistent estimator of P(x|x\u0303) as the number of training samples x \u223c D goes to infinity, it was shown in (Bengio et al., 2013) that the Markov chain constructed from the iterative process described above will be ergodic and have a stationary distribution \u03c0\u03b8 which matches D (i.", "startOffset": 214, "endOffset": 235}, {"referenceID": 0, "context": "All of the discussion in (Bengio et al., 2013) assumed that both xi and x\u0303i for each training pair (xi, x\u0303i) were from the same space X , although this was not required for their proofs.", "startOffset": 25, "endOffset": 46}, {"referenceID": 0, "context": "A method called walkback training was proposed for Generalized DAEs in (Bengio et al., 2013) and used again for GSNs in (Bengio et al.", "startOffset": 71, "endOffset": 92}, {"referenceID": 0, "context": "We now give versions of the theorems from (Bengio et al., 2013) modified for Simple GSNs, which show that training with enough data and with sufficiently powerful function approximators p\u03b8/q\u03c6 produces a Markov chain whose asymp-", "startOffset": 42, "endOffset": 63}, {"referenceID": 0, "context": "The proof is a direct translation of the proof for Theorem 1 in (Bengio et al., 2013), but with zs replacing x\u0303s.", "startOffset": 64, "endOffset": 85}, {"referenceID": 9, "context": "Though not explicitly stated in the existing work on GSNs, it seems that balancing between maximizing dispersion of the corruption process and the ease of modeling the reconstruction distribution p\u03b8 plays a role for GSNs analogous to balancing between minimizing the KL divergence KL(q\u03c6(z|x)||p(z)) and maximizing the expected conditional log-likelihood Ez\u223cq\u03c6(z|x) log p\u03b8(x|z) when training a generative model p\u03b8(x) with variational methods, or balancing between following the \u201cnatural dynamics\u201d of the system and optimizing reward in policy search (Peters et al., 2010; Todorov, 2009).", "startOffset": 549, "endOffset": 585}, {"referenceID": 10, "context": "We do this by replacing the denoising auto-encoders in existing examples of Generalized DAEs and GSNs with variational auto-encoders (Kingma & Welling, 2014; Rezende et al., 2014), while reinterpreting the two competing terms in the variational free-energy F (see Eq.", "startOffset": 133, "endOffset": 179}, {"referenceID": 0, "context": "4 in (Bengio et al., 2013):", "startOffset": 5, "endOffset": 26}, {"referenceID": 3, "context": "Examples of Approximate Bayesian Computation include spectral methods based on the \u201cmethod of moments\u201d, which learn the parameters of g\u03b8 so as to match some of the statistical moments of G to the corresponding moments observed in an empirical sample from D, and more recent approaches based on minimizing the ability of some classifier to distinguish between G and D (Gutmann et al., 2014a;b; Goodfellow et al., 2014).", "startOffset": 367, "endOffset": 417}, {"referenceID": 3, "context": "Motivated by the recent empirical success of this latter approach in training deep generative models (Goodfellow et al., 2014), we develop a related approach which offers improved stability and a simpler proof of correctness.", "startOffset": 101, "endOffset": 126}, {"referenceID": 3, "context": "Our method can be interpreted as a collaboration between g\u03b8 and f\u03c8 , in contrast with the adversarial approach presented in (Goodfellow et al., 2014).", "startOffset": 124, "endOffset": 149}, {"referenceID": 6, "context": "f\u03c8 if and only if \u2200x, f\u03c8(x) = log D(x) G(x) (Hastie et al., 2008).", "startOffset": 44, "endOffset": 65}, {"referenceID": 3, "context": "The key characteristic that distinguishes our objective from (Goodfellow et al., 2014) is that, given a fixed guide function f\u03c8 , our objective for the generator g\u03b8 pushes the mass in over-dense regions of G towards zero-contours of f\u03b8 while leaving the mass in under-dense regions unmoved.", "startOffset": 61, "endOffset": 86}, {"referenceID": 3, "context": "In contrast, the adversarial objective in (Goodfellow et al., 2014) drives all mass emitted by g\u03b8 towards local maxima of f\u03c8 .", "startOffset": 42, "endOffset": 67}, {"referenceID": 3, "context": "moment matching terms for matching the mean and covariance of x \u223c G with those of x \u223c D can be included to help avoid the occasional empirical \u201ccollapses\u201d of G that were described in (Goodfellow et al., 2014).", "startOffset": 183, "endOffset": 208}, {"referenceID": 3, "context": ", 2014) and (Goodfellow et al., 2014).", "startOffset": 12, "endOffset": 37}, {"referenceID": 10, "context": "\u03c6 using the techniques in (Kingma & Welling, 2014; Rezende et al., 2014).", "startOffset": 26, "endOffset": 72}, {"referenceID": 1, "context": "We implemented our models in Python using the THEANO library (Bergstra et al., 2010).", "startOffset": 61, "endOffset": 84}, {"referenceID": 2, "context": "on the validation set log-likelihood provided by the Gaussian Parzen density estimator described in (Breuleux et al., 2011) and the", "startOffset": 100, "endOffset": 123}, {"referenceID": 2, "context": "We found that the ORK model with strong regularization on KL(q\u03c6(z|x)||p\u2217(z)) was able to significantly out-perform the VAR model according to the Gaussian Parzen density estimator (GPDE) test described in (Breuleux et al., 2011)1.", "startOffset": 205, "endOffset": 228}, {"referenceID": 3, "context": ", 2014) and the 225 in (Goodfellow et al., 2014).", "startOffset": 23, "endOffset": 48}, {"referenceID": 3, "context": "1], as in (Bengio et al., 2014; Goodfellow et al., 2014).", "startOffset": 10, "endOffset": 56}, {"referenceID": 3, "context": "For comparison, best previous results on the GPDE bound for this dataset are 2050 (Goodfellow et al., 2014) and 2110 (Bengio et al.", "startOffset": 82, "endOffset": 107}, {"referenceID": 0, "context": ", 2014) and 2110 (Bengio et al., 2013).", "startOffset": 17, "endOffset": 38}], "year": 2017, "abstractText": "We develop an approach to training generative models based on unrolling a variational autoencoder into a Markov chain, and shaping the chain\u2019s trajectories using a technique inspired by recent work in Approximate Bayesian computation. We show that the global minimizer of the resulting objective is achieved when the generative model reproduces the target distribution. To allow finer control over the behavior of the models, we add a regularization term inspired by techniques used for regularizing certain types of policy search in reinforcement learning. We present empirical results on the MNIST and TFD datasets which show that our approach offers state-of-the-art performance, both quantitatively and from a qualitative point of view.", "creator": "LaTeX with hyperref package"}}}