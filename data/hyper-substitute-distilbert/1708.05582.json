{"id": "1708.05582", "review": {"conference": "arxiv", "VERSION": "v1", "DATE_OF_SUBMISSION": "18-Aug-2017", "title": "Agree to Disagree: Improving Disagreement Detection with Dual GRUs", "abstract": "regression presentation presents models for varying agreement / disagreement besides specific discussions. unfortunately this work predictions show that following observing a siamese simulation architecture we resolve the discussions, economists no doubt need to rely on emotion - coupled tools how facilitate the meta thread knowledge. we evaluate our model vs existing online discussion papers - abcd, iac and hp. experimental results incorporating our dataset show that only fusing lexical and other embedding problems, initial formula incorporates quality state probability the database performance averages 0. 9 average f1 score. we also show that the model trained on abcd dataset originated naturally on relatively smaller print papers ( named while awtp ).", "histories": [["v1", "Fri, 18 Aug 2017 12:34:11 GMT  (765kb,D)", "http://arxiv.org/abs/1708.05582v1", "In Proc. 7th Affective Computing and Intelligent Interaction (ACII'17), San Antonio, TX, USA, Oct. 23-26, 2017"]], "COMMENTS": "In Proc. 7th Affective Computing and Intelligent Interaction (ACII'17), San Antonio, TX, USA, Oct. 23-26, 2017", "reviews": [], "SUBJECTS": "cs.CL", "authors": ["sushant hiray", "venkatesh duppada"], "accepted": false, "id": "1708.05582"}, "pdf": {"name": "1708.05582.pdf", "metadata": {"source": "CRF", "title": "Agree to Disagree: Improving Disagreement Detection with Dual GRUs", "authors": ["Sushant Hiray", "Venkatesh Duppada"], "emails": ["sushant.hiray@seernet.io,", "venkatesh.duppada@seernet.io"], "sections": [{"heading": "1. Introduction", "text": "The rise of various discussion forums and social media websites has given people a lot of avenues to express their opinions. As multiple people join a particular discussion, participants often agree or disagree with views presented by others. Mining the agreement and disagreement (denoted (dis)agreement) signals helps detect presence of disputes, ideological stance of the participants [1] and unravel beliefs shaping the opinion in general. This can further be useful for detecting subgroups [2] [3], analyzing how well a new product is being received or analyzing the mood to predict the trends on stock markets [4].\nIn this work, we explore a Siamese [5] inspired deep neural network to detect the presence of (dis)agreement in online discussions between two posts, the quote and the response (Q-R pairs [6]). In this framework, the same neural network encoder is applied to two input sentences individually, so that both of the two sentences are encoded into sentence vectors in the same embedding space. Prior work in this problem primarily focused on using handcrafted features to exploit the meta thread structure. We show that by training on a sufficiently large dataset (ABCD) we can bypass the need for designing handcrafted features. Thus, the classifier can be used for (dis)agreement detection between any two posts, even when the underlying hierarchical relationship between the Q-R pairs isn\u2019t available. To the best of our knowledge, this is the first work to investigate detection of (dis)agreement using sentence based encoding.\n\u2217 These authors contributed equally to this work\nWe detect (dis)agreement by performing a 3-way classification (agreement/disagreement/none) between the Q-R pairs on several existing annotated datasets. Due to the lack of a standard dataset, some prior work focused primarily on 2-way classification (agreement/disagreement).\nIn the following sections, we first discuss related work. Section 3 describes the datasets used for evaluation. Section 4 describes the various features used in the classifier. In section 5, we explain the model architecture. Section 6 details the experiments performed and their corresponding results. Section 7 performs error analysis on the results from the proposed system. Finally, we conclude in section 8 and suggest relevant future work."}, {"heading": "2. Related Work", "text": "Previous work in this field focused a lot on spoken dialogues. [7], [8], [9] used spurt level agreement annotations from the ICSI corpus [10]. [11] presents detection of agreements in multi-party conversations using the AMI meeting corpus [12]. [13] presents a conditional random field based approach for detecting agreement/disagreement between speakers in English broadcast conversations\nRecently, researchers have turned their attention towards (dis)agreement detection in online discussions. The prior work was geared towards performing 2-way classification of agreement/disagreement. [14] used various sentiment, emotional and durational features to detect local and global (dis)agreement in discussion forums. [15] performed (dis)agreement on annotated posts from the Internet Argument Corpus (IAC) [6]. They investigated various manual labelled features, which are however difficult to reproduce as they are not annotated in other datasets. To benchmark the results, we\u2019ve also incorporated the IAC corpus in our experiments. Quite recently, [16] proposed a 3-way classification by exploiting meta-thread structures and accommodation between participants. They also proposed a naturally occurring dataset ABCD (Agreement by Create Debaters) which was about 25 times larger than prior existing corpus. We\u2019ve trained our classifier on this larger dataset. [17] proposed (dis)agreement detection with an isotonic Conditional Random Fields (isotonic CRF) based sequential model. [18] proposed features motivated by theoretical predictions to perform (dis)agreement detection. However, they\u2019ve used hand-crafted patterns as features and these features miss\n978-1-5386-0680-3/17/$31.00 c\u00a92017 IEEE\nar X\niv :1\n70 8.\n05 58\n2v 1\n[ cs\n.C L\n] 1\n8 A\nug 2\n01 7\nfew real world scenarios reducing the performance of the classifier.\n(Dis)agreement detection is related to other similar NLP tasks like stance detection and argument mining but is not exactly the same. Stance detection is the task of identifying whether the author of the text is in favor or against or neutral towards a target, while argument mining focuses on tasks like automatic extraction of arguments from free text, argument proposition classification and argumentative parsing [19] [20]. Recently there are studies on how people back up their stances when arguing where comments are classified as either attacking or supporting a set of pre-defined arguments [21]. These tasks (stance detection, argument mining) are not independent but have some common features because of which they are benefited by common building blocks like sentiment detection, textual entailment and sentence similarity [21] [22]."}, {"heading": "3. Data", "text": "In this work, we focus on 3-way classification (agreement/disagreement/none) between quote-response (Q-R) pairs for 3 prior existing in-domain datasets. These are described in the subsequent sub-sections."}, {"heading": "3.1. Agreement by Create Debaters (ABCD)", "text": "The ABCD corpus [16] was curated from Create Debate website1 where users can start a debate by asking a question. Although the website can support open ended as well as multiple sided debates, the corpus comprises only of the for-against debates. The corpus is annotated as follows: the side label corresponding to each post (response) determines whether the user agrees or disagrees with the previous post (quote). If the authors of both the posts are different, then they agree if the side labels are same or otherwise disagree. If the authors of both the posts is same, it is labeled as none as it implies that it is in continuation of the previous post. Also, the first post in a debate is usually setting up the premise of the debate, so it doesn\u2019t have a side attached to it. Hence all the Q-R pairs with the quote as the first post are labeled as none. Table 1 shows example Q-R pairs for each label type."}, {"heading": "3.2. Agreement in Wikipedia Talk Pages (AWTP)", "text": "AWTP [23] is formatted in the same way as ABCD. Post-reply pairs are manually annotated with their (dis)agreement stance. Also additional mode information indicates the manner in which agreement or disagreement is expressed. The datasource for AWTP comprised primarily of Wikipedia Talk Pages and LiveJournal postings. Table 2 provides additional statistics for the corpus.\n1. http://www.createdebate.com/"}, {"heading": "3.3. Internet Argument Corpus (IAC)", "text": "The Internet Argument Corpus (IAC) [6] is a collection of corpora for research in political debate on internet forums. It consists of \u223c11,000 discussions, \u223c390,000 posts, and some \u223c73,000,000 words. It includes topic annotations, response characterizations, and stance. The 4forum posts were annotated using Mechanical Turk. The annotators were provided with a Q-R pair and they indicated the level of (dis)agreement on a scale of [-5, 5]. However, not all posts in a thread were annotated for (dis)agreement and roughly 6000 valid Q-R pairs were extracted. In accordance with prior work of this corpus [15], [16], [18], we converted the scalar values into corresponding (dis)agreement as follows: [-5, -1] is tagged as disagreement, [-1, 1] is tagged as none, [1, 5] is tagged as agreement. In case multiple annotators have tagged the same post, we combine them as follows. None annotations are ignored unless there are no other (dis)agreement tags. In all other cases, average annotation score is used as the final score of the post."}, {"heading": "4. Feature Extraction", "text": "In this section we briefly mention the features experimented in this work."}, {"heading": "4.1. Word Vectors", "text": "In the recent times distributed representations of words [24] (word2vec [25], GloVe [26]) has shown promise in many NLP tasks and is the driver for success of deep learning in NLP [27]. Word vectors encode semantics in low dimensional space and can be used efficiently for various NLP tasks [28] [29]. For this task of (dis)agreement classification, we use GloVe embeddings of 300 dimensions trained on Common Crawl with 840 billion tokens, 2.2 million vocabulary."}, {"heading": "4.2. Lexicons", "text": "We used affect, sentiment, emotion, opinion lexicons for feature extraction because in many of the online discussions forums people tend to argue with emotion and opinion about a particular topic to convey their stance or belief. Making use of these affect lexicons will help us in classifying if a response (dis)agrees with quote or not. Prior work [14] using these lexicons have shown them to give good results. Among lexical features we used the following.\nAFINN [30] word list are manually rated for valence with an integer between -5 (Negative Sentiment) and +5 (Positive Sentiment). Bing Liu [31] opinion lexicon extract opinion on customer reviews. +/-EffectWordNet [32] by MPQA group are sense level lexicons. The NRC Affect Intensity [33] lexicons provide real valued affect intensity. NRC Word-Emotion Association Lexicon [34] contains 8 sense level associations (anger, fear, anticipation, trust, surprise, sadness, joy, and disgust) and 2 sentiment level associations (negative and positive). Expanded NRC WordEmotion Association Lexicon [35] expands the NRC wordemotion association lexicon for twitter specific language. NRC Hashtag Emotion Lexicon [36] contains emotion word associations computed on emotion labeled twitter corpus via Hashtags. NRC Hashtag Sentiment Lexicon and Sentiment140 Lexicon [37] contains sentiment word associations computed on twitter corpus via Hashtags and Emoticons. SentiWordNet [38] assigns to each synset of WordNet three sentiment scores: positivity, negativity, objectivity. Negation lexicons collections are used to count the total occurrence of negative words. The Linguistic Inquiry Word Count (LIWC) [39] categorizes the words we use in everyday language to reveal our thoughts, feelings, personality, and motivations.\nFor each word in the sentence we calculate various metrics using these lexicons like number of negation words in a sentence, average negative and positive sentiment of the sentence etc. and use these as lexical feature vector to the system. The lexicon feature extractor was inspired from [40]."}, {"heading": "5. System Description", "text": "The task of (dis)agreement classification from Q-R pair comes under a much broader category of sentence pair modelling. A lot of NLP tasks like natural language inference,\ntextual entailment, answer selection, paraphrase identification etc involve modelling a pair of sentences so that they perform well on a particular task or multitude of such tasks [41]. For this task we used an architecture which is inspired by Siamese network [5] and Stanford Natural Language Inference model [42] with identical networks encoding Q-R pair.\nFor each Q-R pair we extract two sets of features. First, GloVe word embeddings are fed to Gated Recurrent Units [43] to create a sentence embedding. Second, from each text a lexical feature vector is extracted as mentioned in subsection 4.2. Both these sentence embeddings from Q-R pairs are concatenated and then fed into fully connected layers to do 3 way classification. Figure 1 show the architecture of our model."}, {"heading": "5.1. System Parameters", "text": "We have used relu non-linearity, dropout [44] for regularization and batch normalization [45] for accelerating training. The network is optimized with adam [46] optimizer with learning rate of 0.001. We have plotted sequence length of Q-R pairs in Figure 2 to better estimate the maximum sequence length for GRU layer. The average sequence length of quotes and responses is 46.28 and 64.935 respectively. The Impact of maximum sequence length of the text input to GRUs is computed and can be found in section 6. We used keras [47] deep learning framework to train our models."}, {"heading": "6. Experiments", "text": "In this section, we evaluate our model on 3-way (dis)agreement classification. The general settings of the model have been defined in sub-section 5.1. In the upcoming sub-sections, we explore the variants of our model and compare our model with the state of the art models on benchmark datasets from section 3."}, {"heading": "6.1. Features Used", "text": "We implemented three variants of the architecture: only lexical features are used, only GloVe embeddings are used and finally where both of them are used. As is evident and hypothesized, the model trained with lexical and word embeddings gave the best results. It is interesting to see that using just the lexicons, the model beat the previous best model which signifies the importance of lexical features. However, using only lexicons as features will suffer from all the disadvantages of any bag-of-words model. This is primarily because it cannot encode the temporal nature of language. This is where gated recurrent units or in general recurrent neural networks come into play. GRU\u2019s can successfully encode the temporal nature. Thus, by fusing both the GRU encoded embeddings and the lexicons, we achieved the state of the art results on the ABCD dataset by beating the previous best model\u2019s [16] average F1 score with margin of 4% percentage. Table 3 compares variants of the proposed system with the existing state of the art."}, {"heading": "6.2. Maximum Input Sequence Length", "text": "We investigate the impact of varying the maximum input sequence length in Table 4. The results highlight some interesting insights. Since we are dealing with discussion posts, the average post size is larger than a few sentences. Hence, as we increase the maximum sequence length, the increase\nin performance is justified. However, once we increase the size after a certain threshold, a lot of the input sequences need to be padded with zeroes, thus causing a drop in performance."}, {"heading": "6.3. Transfer Learning", "text": "In the recent times, with the availability of huge amount of data a new paradigm in machine learning called Transfer Learning [48] has come into play. Transfer learning is the improvement of learning in a new task through the transfer of knowledge from a related task that has already been learned. Here we\u2019ve applied transfer learning technique to smaller datasets and achieved competitive results. Table 5 and 6 enlist the results of various model architectures explored for testing the effectiveness of transferring learning from ABCD dataset to the smaller annotated datasets IAC and AWTP. The variants explored are as follows. Direct, where the model trained on ABCD model (referred as pretrained model) is tested directly on the smaller dataset. Tuning: the model is seeded with the weights from the pretrained model and trained with the smaller dataset. Transfer: The last 2 layers from the pre-trained model are stripped and replaced with new dense layers of size 100 and 50 and the model is trained on the smaller dataset. Re-train last 2/3 layers: All but last-2/3 layers of the pre-trained model are frozen and the remaining layers are trained on the smaller dataset."}, {"heading": "7. Error Analysis", "text": "The ABCD dataset is scraped from online debate forum, Create Debate and is automatically labelled. This way of collecting Q-R pairs is not perfect and suffers from the following problems: people may be on the same/different side of debate but disagree/agree on some points (example 1 in Table 7) as the sides are for topic level not post or sentence level, off-topic social chitter-chatter on debate forum (example 2 in Table 7) etc. Our analysis indicated that in quite a few cases, the error in classification was in fact a case of incorrect label."}, {"heading": "8. Conclusion", "text": "We have trained a deep neural network with fusion of lexical and word vector based features to achieve state of the art results on 3-way (dis)agreement classification on the largest (dis)agreement classification dataset available till date (ABCD corpus). We\u2019ve shown that by using this model, we no longer need to rely on hand-crafted features to exploit the meta-thread structure. We\u2019ve also shown the benefit of transfer learning from pre-trained model on large corpora to achieve competitive results on small domain datasets. Till date, the research for (dis)agreement classification has not moved at the pace comparable to some other NLP tasks primarily because of unavailability of large standard dataset. Although ABCD dataset is large enough it suffers from many issues as it uses naturally occuring labels. We plan to enhance the ABCD dataset by performing semi-supervised tagging of labels by training models on hand-annotated\ndatasets. With the availability of a large standard dataset for (dis)agreement classification, we can try various recent advanced state of the art architectures for modelling sentences pairs [41], [49] to further improve the performance."}], "references": [{"title": "Recognizing stances in online debates", "author": ["S. Somasundaran", "J. Wiebe"], "venue": "Proceedings of the Joint Conference of the 47th Annual Meeting of the ACL and the 4th International Joint Conference on Natural Language Processing of the AFNLP: Volume 1-Volume 1. Association for Computational Linguistics, 2009, pp. 226\u2013234.", "citeRegEx": "1", "shortCiteRegEx": null, "year": 2009}, {"title": "Detecting subgroups in online discussions by modeling positive and negative relations among participants", "author": ["A. Hassan", "A. Abu-Jbara", "D. Radev"], "venue": "Proceedings of the 2012 joint conference on empirical methods in natural language processing and computational natural language learning. Association for Computational Linguistics, 2012, pp. 59\u201370.", "citeRegEx": "2", "shortCiteRegEx": null, "year": 2012}, {"title": "Subgroup detection in ideological discussions", "author": ["A. Abu-Jbara", "M. Diab", "P. Dasigi", "D. Radev"], "venue": "Proceedings of the 50th Annual Meeting of the Association for Computational Linguistics: Long Papers- Volume 1. Association for Computational Linguistics, 2012, pp. 399\u2013409.", "citeRegEx": "3", "shortCiteRegEx": null, "year": 2012}, {"title": "Twitter mood predicts the stock market", "author": ["J. Bollen", "H. Mao", "X. Zeng"], "venue": "Journal of computational science, vol. 2, no. 1, pp. 1\u20138, 2011.", "citeRegEx": "4", "shortCiteRegEx": null, "year": 2011}, {"title": "Signature verification using a\u201d siamese\u201d time delay neural network", "author": ["J. Bromley", "I. Guyon", "Y. LeCun", "E. S\u00e4ckinger", "R. Shah"], "venue": "Advances in Neural Information Processing Systems, 1994, pp. 737\u2013 744.", "citeRegEx": "5", "shortCiteRegEx": null, "year": 1994}, {"title": "A corpus for research on deliberation and debate.", "author": ["M.A. Walker", "J.E.F. Tree", "P. Anand", "R. Abbott", "J. King"], "venue": "in LREC,", "citeRegEx": "6", "shortCiteRegEx": "6", "year": 2012}, {"title": "Detection of agreement vs. disagreement in meetings: Training with unlabeled data", "author": ["D. Hillard", "M. Ostendorf", "E. Shriberg"], "venue": "Proceedings of the 2003 Conference of the North American Chapter of the Association for Computational Linguistics on Human Language Technology: companion volume of the Proceedings of HLT-NAACL 2003\u2013short papers-Volume 2. Association for Computational Linguistics, 2003, pp. 34\u201336.", "citeRegEx": "7", "shortCiteRegEx": null, "year": 2003}, {"title": "Identifying agreement and disagreement in conversational speech: Use of bayesian networks to model pragmatic dependencies", "author": ["M. Galley", "K. McKeown", "J. Hirschberg", "E. Shriberg"], "venue": "Proceedings of the 42nd Annual Meeting on Association for Computational Linguistics. Association for Computational Linguistics, 2004, p. 669.", "citeRegEx": "8", "shortCiteRegEx": null, "year": 2004}, {"title": "Agreement/disagreement classification: Exploiting unlabeled data using contrast classifiers", "author": ["S. Hahn", "R. Ladner", "M. Ostendorf"], "venue": "Proceedings of the Human Language Technology Conference of the NAACL, Companion Volume: Short Papers. Association for Computational Linguistics, 2006, pp. 53\u201356.", "citeRegEx": "9", "shortCiteRegEx": null, "year": 2006}, {"title": "The icsi meeting corpus", "author": ["A. Janin", "D. Baron", "J. Edwards", "D. Ellis", "D. Gelbart", "N. Morgan", "B. Peskin", "T. Pfau", "E. Shriberg", "A. Stolcke"], "venue": "Acoustics, Speech, and Signal Processing, 2003. Proceedings.(ICASSP\u201903). 2003 IEEE International Conference on, vol. 1. IEEE, 2003, pp. I\u2013I.", "citeRegEx": "10", "shortCiteRegEx": null, "year": 2003}, {"title": "Agreement detection in multiparty conversation", "author": ["S. Germesin", "T. Wilson"], "venue": "Proceedings of the 2009 international conference on Multimodal interfaces. ACM, 2009, pp. 7\u201314.", "citeRegEx": "11", "shortCiteRegEx": null, "year": 2009}, {"title": "The ami meeting corpus", "author": ["I. McCowan", "J. Carletta", "W. Kraaij", "S. Ashby", "S. Bourban", "M. Flynn", "M. Guillemot", "T. Hain", "J. Kadlec", "V. Karaiskos"], "venue": "Proceedings of the 5th International Conference on Methods and Techniques in Behavioral Research, vol. 88, 2005.", "citeRegEx": "12", "shortCiteRegEx": null, "year": 2005}, {"title": "Detection of agreement and disagreement in broadcast conversations", "author": ["W. Wang", "S. Yaman", "K. Precoda", "C. Richey", "G. Raymond"], "venue": "Proceedings of the 49th Annual Meeting of the Association for Computational Linguistics: Human Language Technologies: short papers-Volume 2. Association for Computational Linguistics, 2011, pp. 374\u2013378.", "citeRegEx": "13", "shortCiteRegEx": null, "year": 2011}, {"title": "Unifying local and global agreement and disagreement classification in online debates", "author": ["J. Yin", "P. Thomas", "N. Narang", "C. Paris"], "venue": "Proceedings of the 3rd Workshop in Computational Approaches to Subjectivity and Sentiment Analysis. Association for Computational Linguistics, 2012, pp. 61\u201369.", "citeRegEx": "14", "shortCiteRegEx": null, "year": 2012}, {"title": "How can you say such things?!?: Recognizing disagreement in informal political argument", "author": ["R. Abbott", "M. Walker", "P. Anand", "J.E. Fox Tree", "R. Bowmani", "J. King"], "venue": "Proceedings of the Workshop on Languages in Social Media. Association for Computational Linguistics, 2011, pp. 2\u201311.", "citeRegEx": "15", "shortCiteRegEx": null, "year": 2011}, {"title": "I couldn\u2019t agree more: The role of conversational structure in agreement and disagreement detection in online discussions.", "author": ["S. Rosenthal", "K. McKeown"], "venue": "in SIGDIAL Conference,", "citeRegEx": "16", "shortCiteRegEx": "16", "year": 2015}, {"title": "Improving agreement and disagreement identification in online discussions with a socially-tuned sentiment lexicon", "author": ["L. Wang", "C. Cardie"], "venue": "arXiv preprint arXiv:1606.05706, 2016.", "citeRegEx": "17", "shortCiteRegEx": null, "year": 2016}, {"title": "Topic independent identification of agreement and disagreement in social media dialogue", "author": ["A. Misra", "M.A. Walker"], "venue": "Conference of the Special Interest Group on Discourse and Dialogue, 2013, p. 920.", "citeRegEx": "18", "shortCiteRegEx": null, "year": 2013}, {"title": "Automatic detection of arguments in legal texts", "author": ["M.-F. Moens", "E. Boiy", "R.M. Palau", "C. Reed"], "venue": "Proceedings of the 11th international conference on Artificial intelligence and law. ACM, 2007, pp. 225\u2013230.", "citeRegEx": "19", "shortCiteRegEx": null, "year": 2007}, {"title": "Argumentation mining: the detection, classification and structure of arguments in text", "author": ["R.M. Palau", "M.-F. Moens"], "venue": "Proceedings of the 12th international conference on artificial intelligence and law. ACM, 2009, pp. 98\u2013107.", "citeRegEx": "20", "shortCiteRegEx": null, "year": 2009}, {"title": "Back up your stance: Recognizing arguments in online discussions.", "author": ["F. Boltuzic", "J. Snajder"], "venue": "in ArgMining@ ACL,", "citeRegEx": "21", "shortCiteRegEx": "21", "year": 2014}, {"title": "Stance and sentiment in tweets", "author": ["S.M. Mohammad", "P. Sobhani", "S. Kiritchenko"], "venue": "ACM Transactions on Internet Technology (TOIT), vol. 17, no. 3, p. 26, 2017.", "citeRegEx": "22", "shortCiteRegEx": null, "year": 2017}, {"title": "Annotating agreement and disagreement in threaded discussion.", "author": ["J. Andreas", "S. Rosenthal", "K. McKeown"], "venue": "LREC,", "citeRegEx": "23", "shortCiteRegEx": "23", "year": 2012}, {"title": "Word representations: a simple and general method for semi-supervised learning", "author": ["J. Turian", "L. Ratinov", "Y. Bengio"], "venue": "Proceedings of the 48th annual meeting of the association for computational linguistics. Association for Computational Linguistics, 2010, pp. 384\u2013394.", "citeRegEx": "24", "shortCiteRegEx": null, "year": 2010}, {"title": "Distributed representations of words and phrases and their compositionality", "author": ["T. Mikolov", "I. Sutskever", "K. Chen", "G.S. Corrado", "J. Dean"], "venue": "Advances in neural information processing systems, 2013, pp. 3111\u20133119.", "citeRegEx": "25", "shortCiteRegEx": null, "year": 2013}, {"title": "Glove: Global vectors for word representation.", "author": ["J. Pennington", "R. Socher", "C.D. Manning"], "venue": "in EMNLP, vol", "citeRegEx": "26", "shortCiteRegEx": "26", "year": 2014}, {"title": "Deep visual-semantic alignments for generating image descriptions", "author": ["A. Karpathy", "L. Fei-Fei"], "venue": "Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition, 2015, pp. 3128\u2013 3137.", "citeRegEx": "27", "shortCiteRegEx": null, "year": 2015}, {"title": "Improving distributional similarity with lessons learned from word embeddings", "author": ["O. Levy", "Y. Goldberg", "I. Dagan"], "venue": "Transactions of the Association for Computational Linguistics, vol. 3, pp. 211\u2013225, 2015.", "citeRegEx": "29", "shortCiteRegEx": null, "year": 2015}, {"title": "A new anew: Evaluation of a word list for sentiment analysis in microblogs", "author": ["F.\u00c5. Nielsen"], "venue": "arXiv preprint arXiv:1103.2903, 2011.", "citeRegEx": "30", "shortCiteRegEx": null, "year": 2011}, {"title": "Mining and summarizing customer reviews", "author": ["M. Hu", "B. Liu"], "venue": "Proceedings of the tenth ACM SIGKDD international conference on Knowledge discovery and data mining. ACM, 2004, pp. 168\u2013177.", "citeRegEx": "31", "shortCiteRegEx": null, "year": 2004}, {"title": "+/-effectwordnet: Sense-level lexicon acquisition for opinion inference.", "author": ["Y. Choi", "J. Wiebe"], "venue": "in EMNLP,", "citeRegEx": "32", "shortCiteRegEx": "32", "year": 2014}, {"title": "Word affect intensities", "author": ["S.M. Mohammad"], "venue": "arXiv preprint arXiv:1704.08798, 2017.", "citeRegEx": "33", "shortCiteRegEx": null, "year": 2017}, {"title": "Emotions evoked by common words and phrases: Using mechanical turk to create an emotion lexicon", "author": ["S.M. Mohammad", "P.D. Turney"], "venue": "Proceedings of the NAACL HLT 2010 workshop on computational approaches to analysis and generation of emotion in text. Association for Computational Linguistics, 2010, pp. 26\u201334.", "citeRegEx": "34", "shortCiteRegEx": null, "year": 2010}, {"title": "Determining word\u2013emotion associations from tweets by multi-label classification", "author": ["F. Bravo-Marquez", "E. Frank", "S.M. Mohammad", "B. Pfahringer"], "venue": "WI\u201916. IEEE Computer Society, 2016, pp. 536\u2013 539.", "citeRegEx": "35", "shortCiteRegEx": null, "year": 2016}, {"title": "Using hashtags to capture fine emotion categories from tweets", "author": ["S.M. Mohammad", "S. Kiritchenko"], "venue": "Computational Intelligence, vol. 31, no. 2, pp. 301\u2013326, 2015.", "citeRegEx": "36", "shortCiteRegEx": null, "year": 2015}, {"title": "Nrc-canada: Building the state-of-the-art in sentiment analysis of tweets", "author": ["S.M. Mohammad", "S. Kiritchenko", "X. Zhu"], "venue": "arXiv preprint arXiv:1308.6242, 2013.", "citeRegEx": "37", "shortCiteRegEx": null, "year": 2013}, {"title": "Sentiwordnet 3.0: An enhanced lexical resource for sentiment analysis and opinion mining.", "author": ["S. Baccianella", "A. Esuli", "F. Sebastiani"], "venue": "in LREC,", "citeRegEx": "38", "shortCiteRegEx": "38", "year": 2010}, {"title": "The psychological meaning of words: Liwc and computerized text analysis methods", "author": ["Y.R. Tausczik", "J.W. Pennebaker"], "venue": "Journal of language and social psychology, vol. 29, no. 1, pp. 24\u201354, 2010.", "citeRegEx": "39", "shortCiteRegEx": null, "year": 2010}, {"title": "Seernet at emoint-2017: Tweet emotion intensity estimator", "author": ["V. Duppada", "S. Hiray"], "venue": "Proceedings of the Workshop on Computational Approaches to Subjectivity, Sentiment and Social Media Analysis (WASSA), Copenhagen, Denmark, 2017.", "citeRegEx": "40", "shortCiteRegEx": null, "year": 2017}, {"title": "Abcnn: Attention-based convolutional neural network for modeling sentence pairs", "author": ["W. Yin", "H. Sch\u00fctze", "B. Xiang", "B. Zhou"], "venue": "arXiv preprint arXiv:1512.05193, 2015.", "citeRegEx": "41", "shortCiteRegEx": null, "year": 2015}, {"title": "A large annotated corpus for learning natural language inference", "author": ["S.R. Bowman", "G. Angeli", "C. Potts", "C.D. Manning"], "venue": "arXiv preprint arXiv:1508.05326, 2015.", "citeRegEx": "42", "shortCiteRegEx": null, "year": 2015}, {"title": "Empirical evaluation of gated recurrent neural networks on sequence modeling", "author": ["J. Chung", "C. Gulcehre", "K. Cho", "Y. Bengio"], "venue": "arXiv preprint arXiv:1412.3555, 2014.", "citeRegEx": "43", "shortCiteRegEx": null, "year": 2014}, {"title": "Dropout: a simple way to prevent neural networks from overfitting.", "author": ["N. Srivastava", "G.E. Hinton", "A. Krizhevsky", "I. Sutskever", "R. Salakhutdinov"], "venue": "Journal of Machine Learning Research,", "citeRegEx": "44", "shortCiteRegEx": "44", "year": 2014}, {"title": "Batch normalization: Accelerating deep network training by reducing internal covariate shift", "author": ["S. Ioffe", "C. Szegedy"], "venue": "International Conference on Machine Learning, 2015, pp. 448\u2013456.", "citeRegEx": "45", "shortCiteRegEx": null, "year": 2015}, {"title": "Adam: A method for stochastic optimization", "author": ["D. Kingma", "J. Ba"], "venue": "arXiv preprint arXiv:1412.6980, 2014.", "citeRegEx": "46", "shortCiteRegEx": null, "year": 2014}, {"title": "Keras", "author": ["F. Chollet"], "venue": "https://github.com/fchollet/keras, 2015.", "citeRegEx": "47", "shortCiteRegEx": null, "year": 2015}, {"title": "A survey on transfer learning", "author": ["S.J. Pan", "Q. Yang"], "venue": "IEEE Transactions on knowledge and data engineering, vol. 22, no. 10, pp. 1345\u20131359, 2010.", "citeRegEx": "48", "shortCiteRegEx": null, "year": 2010}, {"title": "Bilateral multi-perspective matching for natural language sentences", "author": ["Z. Wang", "W. Hamza", "R. Florian"], "venue": "arXiv preprint arXiv:1702.03814, 2017.", "citeRegEx": "49", "shortCiteRegEx": null, "year": 2017}], "referenceMentions": [{"referenceID": 0, "context": "Mining the agreement and disagreement (denoted (dis)agreement) signals helps detect presence of disputes, ideological stance of the participants [1] and unravel beliefs shaping the opinion in general.", "startOffset": 145, "endOffset": 148}, {"referenceID": 1, "context": "This can further be useful for detecting subgroups [2] [3], analyzing how well a new product is being received or analyzing the mood to predict the trends on stock markets [4].", "startOffset": 51, "endOffset": 54}, {"referenceID": 2, "context": "This can further be useful for detecting subgroups [2] [3], analyzing how well a new product is being received or analyzing the mood to predict the trends on stock markets [4].", "startOffset": 55, "endOffset": 58}, {"referenceID": 3, "context": "This can further be useful for detecting subgroups [2] [3], analyzing how well a new product is being received or analyzing the mood to predict the trends on stock markets [4].", "startOffset": 172, "endOffset": 175}, {"referenceID": 4, "context": "In this work, we explore a Siamese [5] inspired deep neural network to detect the presence of (dis)agreement in online discussions between two posts, the quote and the response (Q-R pairs [6]).", "startOffset": 35, "endOffset": 38}, {"referenceID": 5, "context": "In this work, we explore a Siamese [5] inspired deep neural network to detect the presence of (dis)agreement in online discussions between two posts, the quote and the response (Q-R pairs [6]).", "startOffset": 188, "endOffset": 191}, {"referenceID": 6, "context": "[7], [8], [9] used spurt level agreement annotations from the ICSI corpus [10].", "startOffset": 0, "endOffset": 3}, {"referenceID": 7, "context": "[7], [8], [9] used spurt level agreement annotations from the ICSI corpus [10].", "startOffset": 5, "endOffset": 8}, {"referenceID": 8, "context": "[7], [8], [9] used spurt level agreement annotations from the ICSI corpus [10].", "startOffset": 10, "endOffset": 13}, {"referenceID": 9, "context": "[7], [8], [9] used spurt level agreement annotations from the ICSI corpus [10].", "startOffset": 74, "endOffset": 78}, {"referenceID": 10, "context": "[11] presents detection of agreements in multi-party conversations using the AMI meeting corpus [12].", "startOffset": 0, "endOffset": 4}, {"referenceID": 11, "context": "[11] presents detection of agreements in multi-party conversations using the AMI meeting corpus [12].", "startOffset": 96, "endOffset": 100}, {"referenceID": 12, "context": "[13] presents a conditional random field based approach for detecting agreement/disagreement between speakers in English broadcast conversations Recently, researchers have turned their attention towards (dis)agreement detection in online discussions.", "startOffset": 0, "endOffset": 4}, {"referenceID": 13, "context": "[14] used various sentiment, emotional and durational features to detect local and global (dis)agreement in discussion forums.", "startOffset": 0, "endOffset": 4}, {"referenceID": 14, "context": "[15] performed (dis)agreement on annotated posts from the Internet Argument Corpus (IAC) [6].", "startOffset": 0, "endOffset": 4}, {"referenceID": 5, "context": "[15] performed (dis)agreement on annotated posts from the Internet Argument Corpus (IAC) [6].", "startOffset": 89, "endOffset": 92}, {"referenceID": 15, "context": "Quite recently, [16] proposed a 3-way classification by exploiting meta-thread structures and accommodation between participants.", "startOffset": 16, "endOffset": 20}, {"referenceID": 16, "context": "[17] proposed (dis)agreement detection with an isotonic Conditional Random Fields (isotonic CRF) based sequential model.", "startOffset": 0, "endOffset": 4}, {"referenceID": 17, "context": "[18] proposed features motivated by theoretical predictions to perform (dis)agreement detection.", "startOffset": 0, "endOffset": 4}, {"referenceID": 18, "context": "Stance detection is the task of identifying whether the author of the text is in favor or against or neutral towards a target, while argument mining focuses on tasks like automatic extraction of arguments from free text, argument proposition classification and argumentative parsing [19] [20].", "startOffset": 283, "endOffset": 287}, {"referenceID": 19, "context": "Stance detection is the task of identifying whether the author of the text is in favor or against or neutral towards a target, while argument mining focuses on tasks like automatic extraction of arguments from free text, argument proposition classification and argumentative parsing [19] [20].", "startOffset": 288, "endOffset": 292}, {"referenceID": 20, "context": "Recently there are studies on how people back up their stances when arguing where comments are classified as either attacking or supporting a set of pre-defined arguments [21].", "startOffset": 171, "endOffset": 175}, {"referenceID": 20, "context": "These tasks (stance detection, argument mining) are not independent but have some common features because of which they are benefited by common building blocks like sentiment detection, textual entailment and sentence similarity [21] [22].", "startOffset": 229, "endOffset": 233}, {"referenceID": 21, "context": "These tasks (stance detection, argument mining) are not independent but have some common features because of which they are benefited by common building blocks like sentiment detection, textual entailment and sentence similarity [21] [22].", "startOffset": 234, "endOffset": 238}, {"referenceID": 15, "context": "The ABCD corpus [16] was curated from Create Debate website1 where users can start a debate by asking a question.", "startOffset": 16, "endOffset": 20}, {"referenceID": 22, "context": "AWTP [23] is formatted in the same way as ABCD.", "startOffset": 5, "endOffset": 9}, {"referenceID": 5, "context": "The Internet Argument Corpus (IAC) [6] is a collection of corpora for research in political debate on internet forums.", "startOffset": 35, "endOffset": 38}, {"referenceID": 4, "context": "The annotators were provided with a Q-R pair and they indicated the level of (dis)agreement on a scale of [-5, 5].", "startOffset": 106, "endOffset": 113}, {"referenceID": 14, "context": "In accordance with prior work of this corpus [15], [16], [18], we converted the scalar values into corresponding (dis)agreement as follows: [-5, -1] is tagged as disagreement, [-1, 1] is tagged as none, [1, 5] is tagged as agreement.", "startOffset": 45, "endOffset": 49}, {"referenceID": 15, "context": "In accordance with prior work of this corpus [15], [16], [18], we converted the scalar values into corresponding (dis)agreement as follows: [-5, -1] is tagged as disagreement, [-1, 1] is tagged as none, [1, 5] is tagged as agreement.", "startOffset": 51, "endOffset": 55}, {"referenceID": 17, "context": "In accordance with prior work of this corpus [15], [16], [18], we converted the scalar values into corresponding (dis)agreement as follows: [-5, -1] is tagged as disagreement, [-1, 1] is tagged as none, [1, 5] is tagged as agreement.", "startOffset": 57, "endOffset": 61}, {"referenceID": 0, "context": "In accordance with prior work of this corpus [15], [16], [18], we converted the scalar values into corresponding (dis)agreement as follows: [-5, -1] is tagged as disagreement, [-1, 1] is tagged as none, [1, 5] is tagged as agreement.", "startOffset": 176, "endOffset": 183}, {"referenceID": 0, "context": "In accordance with prior work of this corpus [15], [16], [18], we converted the scalar values into corresponding (dis)agreement as follows: [-5, -1] is tagged as disagreement, [-1, 1] is tagged as none, [1, 5] is tagged as agreement.", "startOffset": 203, "endOffset": 209}, {"referenceID": 4, "context": "In accordance with prior work of this corpus [15], [16], [18], we converted the scalar values into corresponding (dis)agreement as follows: [-5, -1] is tagged as disagreement, [-1, 1] is tagged as none, [1, 5] is tagged as agreement.", "startOffset": 203, "endOffset": 209}, {"referenceID": 23, "context": "In the recent times distributed representations of words [24] (word2vec [25], GloVe [26]) has shown promise in many NLP tasks and is the driver for success of deep learning in NLP [27].", "startOffset": 57, "endOffset": 61}, {"referenceID": 24, "context": "In the recent times distributed representations of words [24] (word2vec [25], GloVe [26]) has shown promise in many NLP tasks and is the driver for success of deep learning in NLP [27].", "startOffset": 72, "endOffset": 76}, {"referenceID": 25, "context": "In the recent times distributed representations of words [24] (word2vec [25], GloVe [26]) has shown promise in many NLP tasks and is the driver for success of deep learning in NLP [27].", "startOffset": 84, "endOffset": 88}, {"referenceID": 26, "context": "In the recent times distributed representations of words [24] (word2vec [25], GloVe [26]) has shown promise in many NLP tasks and is the driver for success of deep learning in NLP [27].", "startOffset": 180, "endOffset": 184}, {"referenceID": 27, "context": "Word vectors encode semantics in low dimensional space and can be used efficiently for various NLP tasks [28] [29].", "startOffset": 110, "endOffset": 114}, {"referenceID": 13, "context": "Prior work [14] using these lexicons have shown them to give good results.", "startOffset": 11, "endOffset": 15}, {"referenceID": 28, "context": "AFINN [30] word list are manually rated for valence with an integer between -5 (Negative Sentiment) and +5 (Positive Sentiment).", "startOffset": 6, "endOffset": 10}, {"referenceID": 29, "context": "Bing Liu [31] opinion lexicon extract opinion on customer reviews.", "startOffset": 9, "endOffset": 13}, {"referenceID": 30, "context": "+/-EffectWordNet [32] by MPQA group are sense level lexicons.", "startOffset": 17, "endOffset": 21}, {"referenceID": 31, "context": "The NRC Affect Intensity [33] lexicons provide real valued affect intensity.", "startOffset": 25, "endOffset": 29}, {"referenceID": 32, "context": "NRC Word-Emotion Association Lexicon [34] contains 8 sense level associations (anger, fear, anticipation, trust, surprise, sadness, joy, and disgust) and 2 sentiment level associations (negative and positive).", "startOffset": 37, "endOffset": 41}, {"referenceID": 33, "context": "Expanded NRC WordEmotion Association Lexicon [35] expands the NRC wordemotion association lexicon for twitter specific language.", "startOffset": 45, "endOffset": 49}, {"referenceID": 34, "context": "NRC Hashtag Emotion Lexicon [36] contains emotion word associations computed on emotion labeled twitter corpus via Hashtags.", "startOffset": 28, "endOffset": 32}, {"referenceID": 35, "context": "NRC Hashtag Sentiment Lexicon and Sentiment140 Lexicon [37] contains sentiment word associations computed on twitter corpus via Hashtags and Emoticons.", "startOffset": 55, "endOffset": 59}, {"referenceID": 36, "context": "SentiWordNet [38] assigns to each synset of WordNet three sentiment scores: positivity, negativity, objectivity.", "startOffset": 13, "endOffset": 17}, {"referenceID": 37, "context": "The Linguistic Inquiry Word Count (LIWC) [39] categorizes the words we use in everyday language to reveal our thoughts, feelings, personality, and motivations.", "startOffset": 41, "endOffset": 45}, {"referenceID": 38, "context": "The lexicon feature extractor was inspired from [40].", "startOffset": 48, "endOffset": 52}, {"referenceID": 39, "context": "A lot of NLP tasks like natural language inference, textual entailment, answer selection, paraphrase identification etc involve modelling a pair of sentences so that they perform well on a particular task or multitude of such tasks [41].", "startOffset": 232, "endOffset": 236}, {"referenceID": 4, "context": "For this task we used an architecture which is inspired by Siamese network [5] and Stanford Natural Language Inference model [42] with identical networks encoding Q-R pair.", "startOffset": 75, "endOffset": 78}, {"referenceID": 40, "context": "For this task we used an architecture which is inspired by Siamese network [5] and Stanford Natural Language Inference model [42] with identical networks encoding Q-R pair.", "startOffset": 125, "endOffset": 129}, {"referenceID": 41, "context": "First, GloVe word embeddings are fed to Gated Recurrent Units [43] to create a sentence embedding.", "startOffset": 62, "endOffset": 66}, {"referenceID": 42, "context": "We have used relu non-linearity, dropout [44] for regularization and batch normalization [45] for accelerating training.", "startOffset": 41, "endOffset": 45}, {"referenceID": 43, "context": "We have used relu non-linearity, dropout [44] for regularization and batch normalization [45] for accelerating training.", "startOffset": 89, "endOffset": 93}, {"referenceID": 44, "context": "The network is optimized with adam [46] optimizer with learning rate of 0.", "startOffset": 35, "endOffset": 39}, {"referenceID": 45, "context": "We used keras [47] deep learning framework to train our models.", "startOffset": 14, "endOffset": 18}, {"referenceID": 15, "context": "Thus, by fusing both the GRU encoded embeddings and the lexicons, we achieved the state of the art results on the ABCD dataset by beating the previous best model\u2019s [16] average F1 score with margin of 4% percentage.", "startOffset": 164, "endOffset": 168}, {"referenceID": 15, "context": "System Precision Recall Weighted F1 Score SOTA [16] 0.", "startOffset": 47, "endOffset": 51}, {"referenceID": 46, "context": "In the recent times, with the availability of huge amount of data a new paradigm in machine learning called Transfer Learning [48] has come into play.", "startOffset": 126, "endOffset": 130}, {"referenceID": 15, "context": "Model Precision Recall Weighted F1 Score SOTA [16] 0.", "startOffset": 46, "endOffset": 50}, {"referenceID": 15, "context": "Model Precision Recall Weighted F1 Score SOTA [16] 0.", "startOffset": 46, "endOffset": 50}, {"referenceID": 39, "context": "With the availability of a large standard dataset for (dis)agreement classification, we can try various recent advanced state of the art architectures for modelling sentences pairs [41], [49] to further improve the performance.", "startOffset": 181, "endOffset": 185}, {"referenceID": 47, "context": "With the availability of a large standard dataset for (dis)agreement classification, we can try various recent advanced state of the art architectures for modelling sentences pairs [41], [49] to further improve the performance.", "startOffset": 187, "endOffset": 191}], "year": 2017, "abstractText": "This paper presents models for detecting agreement/disagreement in online discussions. In this work we show that by using a Siamese inspired architecture to encode the discussions, we no longer need to rely on hand-crafted features to exploit the meta thread structure. We evaluate our model on existing online discussion corpora ABCD, IAC and AWTP. Experimental results on ABCD dataset show that by fusing lexical and word embedding features, our model achieves the state of the art performance of 0.804 average F1 score. We also show that the model trained on ABCD dataset performs competitively on relatively smaller annotated datasets (IAC and", "creator": "LaTeX with hyperref package"}}}