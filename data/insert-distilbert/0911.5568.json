{"id": "0911.5568", "review": {"conference": "arxiv", "VERSION": "v1", "DATE_OF_SUBMISSION": "30-Nov-2009", "title": "Acquisition d'informations lexicales \\`a partir de corpus C\\'edric Messiant et Thierry Poibeau", "abstract": "all this paper is about creating automatic acquisition of lexical information from corpora, especially subcategorization acquisition.", "histories": [["v1", "Mon, 30 Nov 2009 08:07:16 GMT  (41kb)", "http://arxiv.org/abs/0911.5568v1", "3 pages"]], "COMMENTS": "3 pages", "reviews": [], "SUBJECTS": "cs.CL cs.AI", "authors": ["c\\'edric messiant", "thierry poibeau"], "accepted": false, "id": "0911.5568"}, "pdf": {"name": "0911.5568.pdf", "metadata": {"source": "CRF", "title": "Acquisition d\u2019informations lexicales a\u0300 partir de corpus", "authors": ["C\u00e9dric Messiant", "Thierry Poibeau"], "emails": [], "sections": [{"heading": null, "text": "Acquisition d\u2019informations lexicales \u00e0 partir de corpus\nC\u00e9dric Messiant, Thierry Poibeau Laboratoire d\u2019Informatique de Paris-Nord"}, {"heading": "Introduction", "text": "L\u2019existence de gros corpus (plusieurs millions de mots) et d\u2019analyseurs syntaxiques performants fait qu\u2019il est actuellement possible d\u2019extraire automatiquement des connaissances \u00e0 large couverture sur les mots et les constructions associ\u00e9es, directement \u00e0 partir de corpus. Cette d\u00e9marche permet d\u2019obtenir des lexiques tr\u00e8s complets \u00e0 moindre co\u00fbt, avec \u00e9galement des informations sur la fr\u00e9quence et la productivit\u00e9 de diff\u00e9rentes constructions, c\u2019est-\u00e0-dire des donn\u00e9es difficilement calculables \u00e0 la main. Depuis une quinzaine d\u2019ann\u00e9es, plusieurs syst\u00e8mes ont ainsi \u00e9t\u00e9 con\u00e7us afin d\u2019extraire automatiquement des informations sur la construction de mots essentiels du lexique, en g\u00e9n\u00e9ral les verbes. On peut citer les travaux de (Brent (1993), Manning (1993), Briscoe and Carroll (1997), Korhonen (2002), Schulte im Walde (2002) parmi de nombreux autres. Nous avons nous-m\u00eames r\u00e9alis\u00e9 un syst\u00e8me du m\u00eame type pour le fran\u00e7ais, avec une premi\u00e8re exp\u00e9rience qui s\u2019appuie sur le corpus Le Monde (200 millions de mots, 1990\u20131999) et sur l\u2019analyseur Syntex (Bourigault, 2007) pour inf\u00e9rer des connaissances sur la souscat\u00e9gorisation de plus de 3000 verbes (Messiant et Poibeau, 2008 ; Messiant 2008). Le processus se d\u00e9compose en 3 grandes \u00e9tapes : 1) on rassemble d\u2019abord l\u2019ensemble des occurrences du verbe consid\u00e9r\u00e9 ainsi que tous ses compl\u00e9ments, 2) on fait ensuite l\u2019inventaire de toutes les constructions possibles pour le verbe consid\u00e9r\u00e9 et enfin, 3) les constructions les plus rares sont \u00e9limin\u00e9es, \u00e0 partir de l\u2019hypoth\u00e8se qu\u2019un nombre trop faible d\u2019occurrences est le r\u00e9v\u00e9lateur d\u2019une erreur d\u2019analyse (simple rencontre de surface). Tous les syst\u00e8mes reposent sur cette architecture, m\u00eame s\u2019ils varient quant \u00e0 la finesse de l\u2019analyse consid\u00e9r\u00e9e ou des strat\u00e9gies de filtrage utilis\u00e9es.\nQuelques difficult\u00e9s r\u00e9currentes des approches \u00e0 base de corpus Malgr\u00e9 les avantages d\u00e9crits, l\u2019approche n\u2019est pas sans inconv\u00e9nient. Comme elle se fonde sur des outils automatiques qui ne sont pas parfaits, les ressources ainsi constitu\u00e9es sont sujettes \u00e0 erreur et doivent imp\u00e9rativement \u00eatre r\u00e9vis\u00e9es \u00e0 la main. Il faut en outre un nombre d\u2019occurrences suffisant pour qu\u2019il soit possible d\u2019inf\u00e9rer une information pertinente, ce qui veut dire qu\u2019il y a un manque criant d\u2019information pour tous les items lexicaux peu fr\u00e9quents en corpus si on s\u2019en tient \u00e0 des analyses de ce type (cf. le \u201dsparse problem\u201d en anglais). Par ailleurs, on voit que certaines constructions sont difficiles \u00e0 capter tandis que d\u2019autres brouillent l\u2019analyse. D\u2019un c\u00f4t\u00e9, les expressions semi-fig\u00e9es (cf. concept d\u2019entrenchment dans les grammaires cognitives, Croft et Cruse 2004) ne sont pas rep\u00e9r\u00e9es en tant que telles ; de l\u2019autre, certains compl\u00e9ments sont fortement pr\u00e9sents avec certains verbes : ils sont alors analys\u00e9s comme arguments alors qu\u2019il s\u2019agit clairement de modifieurs. Enfin, les r\u00e9alisations de surface ne permettent pas de diff\u00e9rencier certains compl\u00e9ments (cf. \u2026donner un livre \u00e0 Marie vs \u2026donner un livre \u00e0 Marseille). Il y a l\u00e0 une divergence majeure avec la description linguistique qui met au premier plan ces diff\u00e9rents \u00e9l\u00e9ments, particuli\u00e8rement dans le cadre des linguistiques dites cognitives."}, {"heading": "Des pistes d\u2019am\u00e9lioration", "text": "Nous pensons que ces probl\u00e8mes ne remettent pas en cause l\u2019acquisition \u00e0 partir de corpus en tant que telle mais qu\u2019ils montrent les limites des approches employ\u00e9es jusqu\u2019\u00e0 maintenant\ndonne dans l\u2019absolu une bonne approximation du probl\u00e8me consid\u00e9r\u00e9 (\u00e0 savoir, acqu\u00e9rir des informations sur la sous-cat\u00e9gorisation syntaxique). Cependant, le point de vue est tr\u00e8s r\u00e9ducteur car il se limite \u00e0 une vue partant du verbe, sans tenir compte d\u2019autres contraintes ext\u00e9rieures. Pour r\u00e9soudre ces probl\u00e8mes, il est donc n\u00e9cessaire de complexifier le mod\u00e8le de base. Nous consid\u00e9rons la langue comme \u00e9tant soumises \u00e0 un ensemble de contraintes qu\u2019il est possible de mod\u00e9liser statistiquement. Ce point n\u2019est pas nouveau en soi et on le trouve sous de nombreuses formes dans la litt\u00e9rature (e.g. Shieber 1992 ; Blache 2001) . Cependant, sur le plan informatique, en acquisition de connaissances notamment, cette id\u00e9e n\u2019a \u00e9t\u00e9 compl\u00e8tement explor\u00e9e \u00e0 ce jour. Une meilleure prise en compte des contraintes \u00e0 l\u2019\u0153uvre permettrait une mod\u00e9lisation plus fine de la sous-cat\u00e9gorisation verbale et ainsi une acquisition de meilleure qualit\u00e9. Le lien entre le verbe et ses compl\u00e9ments, couramment pris en compte dans les approches ci-dessus comme nous l\u2019avons montr\u00e9, est pertinent mais insuffisant dans ce contexte. La prise en compte de la dispersion des t\u00eates nominales des compl\u00e9ments ou des t\u00eates des compl\u00e9ments pr\u00e9positionnels permet de beaucoup mieux caract\u00e9riser les s\u00e9quences vis\u00e9es (c\u2019est-\u00e0-dire qu\u2019il est possible de calculer automatiquement la dispersion des noms en position de compl\u00e9ment apr\u00e8s un verbe donn\u00e9, au \u00e0 l\u2019inverse un lien fort entre un verbe et un nom, pour former une expression plus ou moins fig\u00e9e comme prendre en compte\u2014 ceci permet de retrouver des colligations, pour reprendre le terme de Firth, 1968). En int\u00e9grant ces \u00e9l\u00e9ments lors de l\u2019analyse, l\u2019acquisition de sch\u00e9mas de sous-cat\u00e9gorisation devient beaucoup plus fine dans la mesure o\u00f9 le processus permet d\u2019int\u00e9grer la notion de figement d\u2019un c\u00f4t\u00e9, de libert\u00e9 de d\u00e9placement et de caract\u00e9risation s\u00e9mantique des modifieurs de l\u2019autre (Fabre et Bourigault, 2008). Enfin, l\u2019approche ne peut se passer d\u2019une validation manuelle. Plut\u00f4t que de rel\u00e9guer celle-ci \u00e0 un stade ultime, quand la machine ne peut plus rien, il semble beaucoup plus profitable de consulter l\u2019utilisateur pendant le processus d\u2019acquisition, afin de lui permettre de guider le processus lui-m\u00eame. Il est en outre possible de rep\u00e9rer des verbes plus rares et de faire des propositions de cadres de sous-cat\u00e9gorisation, qui semblent pertinents \u00e0 partir du moment o\u00f9 l\u2019analyse repose sur quelques phrases dont l\u2019analyse semble correcte (phrases courtes qui peuvent \u00eatre analys\u00e9es avec un bon degr\u00e9 de certitude). Enfin, en dernier recours, il est n\u00e9cessaire de consulter directement l\u2019utilisateur quand les connaissances disponibles en corpus restent insuffisantes."}, {"heading": "En guise de conclusion", "text": "On ne saurait inf\u00e9rer un comportement cognitif \u00e0 partir de ce sch\u00e9ma d\u2019acquisition, mais on peut quand m\u00eame remarquer la plausibilit\u00e9 d\u2019un jeu de contraintes multiple, l\u2019influence de la notion de fr\u00e9quence, et le recours ultime au dictionnaire quand on ignore le sens d\u2019un mot. A part pour ce dernier point, l\u2019acquisition met au premier plan la notion de contexte, ce qui semble \u00e9galement conforme \u00e0 la r\u00e9alit\u00e9 observ\u00e9e. On remarquera juste que la notion de contexte ne se limite pas au corpus dans la r\u00e9alit\u00e9, d\u2019o\u00f9 le recours n\u00e9cessaire \u00e0 une interactivit\u00e9 plus forte quand on proc\u00e8de \u00e0 une acquisition simplement \u00e0 base de corpus, par rapport au processus d\u2019acquisition du langage chez l\u2019enfant, d\u2019une grande complexit\u00e9 et o\u00f9 l\u2019information multimodale joue un r\u00f4le primordial."}], "references": [{"title": "Les Grammaires de Propri\u00e9t\u00e9s : des contraintes pour le traitement automatique des langues naturelles", "author": ["Blache", "Philippe"], "venue": null, "citeRegEx": "Blache and Philippe,? \\Q2001\\E", "shortCiteRegEx": "Blache and Philippe", "year": 2001}, {"title": "Un analyseur syntaxique op\u00e9rationnel : SYNTEX. M\u00e9moire d\u2019Habilitation, Universit\u00e9 de Toulouse-le-Mirail", "author": ["Bourigault", "Didier"], "venue": null, "citeRegEx": "Bourigault and Didier,? \\Q2007\\E", "shortCiteRegEx": "Bourigault and Didier", "year": 2007}, {"title": "From Grammar to Lexicon: Unsupervised Learning of Lexical Syntax", "author": ["Brent", "Michael R"], "venue": "Computational Linguistics,", "citeRegEx": "Brent and R.,? \\Q1993\\E", "shortCiteRegEx": "Brent and R.", "year": 1993}, {"title": "Automatic extraction of subcategorization from corpora", "author": ["Briscoe", "Ted", "Carroll", "John"], "venue": "Proceedings of the Meeting of the Association for Computational Linguistics,", "citeRegEx": "Briscoe et al\\.,? \\Q1997\\E", "shortCiteRegEx": "Briscoe et al\\.", "year": 1997}, {"title": "Cognitive linguistics. (Cambridge Textbooks in Linguistics.)", "author": ["Croft", "William et D.A. Cruse"], "venue": null, "citeRegEx": "Croft and Cruse,? \\Q2004\\E", "shortCiteRegEx": "Croft and Cruse", "year": 2004}, {"title": "A synopsis of linguistic theory", "author": ["Firth", "John R"], "venue": "Selected Papers of J.R. Firth", "citeRegEx": "Firth and R.,? \\Q1968\\E", "shortCiteRegEx": "Firth and R.", "year": 1968}, {"title": "Subcategorization Acquisition. PhD thesis publi\u00e9e sous la r\u00e9f", "author": ["Korhonen", "Anna"], "venue": "Technical Report UCAM-CL-TR-530. Computer Laboratory, University de Cambridge", "citeRegEx": "Korhonen and Anna,? \\Q2002\\E", "shortCiteRegEx": "Korhonen and Anna", "year": 2002}, {"title": "Automatic Acquisition of a Large Subcategorization Dictionary from Corpora", "author": ["Manning", "Christopher D"], "venue": "Proceedings of the Meeting of the Association for Computational Linguistics,", "citeRegEx": "Manning and D.,? \\Q1993\\E", "shortCiteRegEx": "Manning and D.", "year": 1993}, {"title": "ASSCI: A Subcategorization Frames Acquisition System for French Verbs", "author": ["Messiant", "C\u00e9dric"], "venue": "Proceedings of the Conference of the Association for Computational Linguistics (ACL, Student Research Workshop),", "citeRegEx": "Messiant and C\u00e9dric,? \\Q2008\\E", "shortCiteRegEx": "Messiant and C\u00e9dric", "year": 2008}, {"title": "LexSchem: A Large Subcategorization Lexicon for French Verbs", "author": ["C\u00e9dric Messiant", "Anna Korhonen", "Thierry Poibeau"], "venue": "Proceedings Language Resources and Evaluation Conference (LREC). Marrakech", "citeRegEx": "Messiant et al\\.,? \\Q2008\\E", "shortCiteRegEx": "Messiant et al\\.", "year": 2008}, {"title": "A Subcategorisation Lexicon for German Verbs induced from a Lexicalised PCFG", "author": ["Schulte im Walde", "Sabine"], "venue": "Proceedings Language Resources and Evaluation Conference (LREC). Las Palmas de Gran Canaria,", "citeRegEx": "Walde and Sabine,? \\Q2002\\E", "shortCiteRegEx": "Walde and Sabine", "year": 2002}, {"title": "Constraint-based Grammar Formalisms", "author": ["Shieber", "Stuart"], "venue": null, "citeRegEx": "Shieber and Stuart,? \\Q1992\\E", "shortCiteRegEx": "Shieber and Stuart", "year": 1992}], "referenceMentions": [], "year": 2009, "abstractText": "Introduction L\u2019existence de gros corpus (plusieurs millions de mots) et d\u2019analyseurs syntaxiques performants fait qu\u2019il est actuellement possible d\u2019extraire automatiquement des connaissances \u00e0 large couverture sur les mots et les constructions associ\u00e9es, directement \u00e0 partir de corpus. Cette d\u00e9marche permet d\u2019obtenir des lexiques tr\u00e8s complets \u00e0 moindre co\u00fbt, avec \u00e9galement des informations sur la fr\u00e9quence et la productivit\u00e9 de diff\u00e9rentes constructions, c\u2019est-\u00e0-dire des donn\u00e9es difficilement calculables \u00e0 la main. Depuis une quinzaine d\u2019ann\u00e9es, plusieurs syst\u00e8mes ont ainsi \u00e9t\u00e9 con\u00e7us afin d\u2019extraire automatiquement des informations sur la construction de mots essentiels du lexique, en g\u00e9n\u00e9ral les verbes. On peut citer les travaux de (Brent (1993), Manning (1993), Briscoe and Carroll (1997), Korhonen (2002), Schulte im Walde (2002) parmi de nombreux autres. Nous avons nous-m\u00eames r\u00e9alis\u00e9 un syst\u00e8me du m\u00eame type pour le fran\u00e7ais, avec une premi\u00e8re exp\u00e9rience qui s\u2019appuie sur le corpus Le Monde (200 millions de mots, 1990\u20131999) et sur l\u2019analyseur Syntex (Bourigault, 2007) pour inf\u00e9rer des connaissances sur la souscat\u00e9gorisation de plus de 3000 verbes (Messiant et Poibeau, 2008 ; Messiant 2008). Le processus se d\u00e9compose en 3 grandes \u00e9tapes : 1) on rassemble d\u2019abord l\u2019ensemble des occurrences du verbe consid\u00e9r\u00e9 ainsi que tous ses compl\u00e9ments, 2) on fait ensuite l\u2019inventaire de toutes les constructions possibles pour le verbe consid\u00e9r\u00e9 et enfin, 3) les constructions les plus rares sont \u00e9limin\u00e9es, \u00e0 partir de l\u2019hypoth\u00e8se qu\u2019un nombre trop faible d\u2019occurrences est le r\u00e9v\u00e9lateur d\u2019une erreur d\u2019analyse (simple rencontre de surface). Tous les syst\u00e8mes reposent sur cette architecture, m\u00eame s\u2019ils varient quant \u00e0 la finesse de l\u2019analyse consid\u00e9r\u00e9e ou des strat\u00e9gies de filtrage utilis\u00e9es.", "creator": "PScript5.dll Version 5.2.2"}}}